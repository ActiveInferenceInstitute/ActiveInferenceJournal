start	end	sentNum	speaker	confidence	text
6010	6570	1	A	0.93108	Greetings.
6650	10954	2	B	0.96	All right, well, our next session. Hey, Bert.
11002	11898	3	B	0.72616	Greetings.
12074	12414	4	B	0.95359	Great.
12452	13102	5	B	0.95819	Hey, how you doing?
13156	13790	6	B	0.96641	Good, good.
13860	14718	7	C	0.99894	Very well.
14884	20106	8	A	0.99996	Our next session is with Bert DeVries, Dmitri Bagaev, and Bart Van Erp.
20218	25246	9	A	0.99408	It's going to be called towards User Friendly Design of Synthetic Active inference agents.
25428	31910	10	A	0.99	And I know a lot of people are super excited to see this really practical and cutting edge work.
31980	35560	11	A	0.99036	So to you, Bert, and just let us know how we can support.
36570	37720	12	B	0.58609	Okay, great.
38650	39926	13	B	1	Is my audio good?
40028	41434	14	A	0.83954	Yep, sounds good.
41632	44300	15	B	0.56155	Okay, then I'm going to share my screen.
46430	48042	16	B	0.76	I hope I picked the right one.
48096	50826	17	B	1	I don't work with zoom quite often.
51008	51866	18	B	0.99443	Looks good.
51968	52522	19	B	0.79615	Looks good.
52576	52854	20	B	0.83643	Yeah.
52912	53502	21	B	0.78	All right.
53636	54320	22	B	0.60153	Super.
55250	59514	23	B	0.98999	Well, thanks a lot, Daniel, for hosting this symposium.
59562	60986	24	B	0.67408	I've been watching some talks.
61018	62094	25	B	0.99356	It's really amazing.
62292	66830	26	B	0.97	And we feel privileged to get a chance to present ourselves.
66990	73410	27	B	0.99943	So we are also, just like a few others before us, interested in developing a toolbox for active inference.
73830	81574	28	B	0.86	And so this picture, or she kind of shows what we're about or what we are interested in.
81692	88898	29	B	0.99996	So here's a lady on the left hand side, and I'm going to try to get a laser pointer.
88994	95194	30	B	1	And she has this idea about a rewarding behavior for a vacuum cleaning robot, right?
95232	98438	31	B	0.99996	So she's writing down she has a textual expression.
98614	105902	32	B	0.91208	Move around the apartment, apply suction until the floor is clean, do not touch objects, and when done, return to the dog.
105956	107422	33	B	0.9999	So that's not so hard.
107476	114880	34	B	0.97142	I'm going to rate that with one star out of three stars in terms of difficulty level to specify that.
115670	118722	35	B	0.99986	But that's not enough to program this robot, right?
118776	129650	36	B	1	Because what she really needs to do now is to specify a generative model and there's effectors and actuators, right.
129720	134582	37	B	1	The robot has to move around, apply suction until the floor is clean.
134636	136870	38	B	0.99985	So there are sensors, probably a camera.
137370	138866	39	B	1	Do not touch objects.
138898	141102	40	B	0.47	Or maybe there has to be object recognition.
141266	146666	41	B	0.99999	This is a really difficult task to come up with this generative model here.
146768	156830	42	B	1	And on top of that, she has to specify this kind of rewarding behavior in terms now of probability distributions of this generative model.
156900	158494	43	B	0.99918	So very difficult.
158612	174930	44	B	0.73831	I'm going to rate that with two stars because the next thing she has to do for this model is to specify the inference procedure to do actually active inference and free energy minimization in real time for this complex model.
175000	177442	45	B	1	And really that's almost impossible, right?
177496	187078	46	B	0.99997	Only a few specialists can really write a procedure for variational free energy minimization in some very difficult model.
187244	193426	47	B	0.99992	So what we are about what we've been working on is to try to automate the inference task.
193458	195302	48	B	0.99995	So get rid of the three stars.
195446	202554	49	B	1	And yes, she will still have to specify her model, but in the long term, we try to get away from that.
202592	205786	50	B	0.99998	So in the long term, we hope we will get a toolbox.
205818	229490	51	B	1	And now we're talking 510 years, right, where a textual description would be enough to specify some initial model with an initial prior and everything else is just automated inference, learning of states, parameters, structural adaptation of the model, even maybe based on her feedback updating the prior.
229650	238306	52	B	0.65091	So that's long term for now, we would be very happy if we could just automate the inference task.
238498	244218	53	B	0.99805	So why is it so difficult to specify inference for an active inference agent?
244304	249500	54	B	0.99966	Well, we have so many competing KPIs, right?
250110	261390	55	B	0.99998	We want to do this for large model scopes, not just for ABCD models, but maybe there's also continuous variables and hierarchical models, right?
261460	263450	56	B	0.8	It must be very user friendly.
263610	268740	57	B	0.9306	We really don't want her to worry about robustness of her code.
269350	278874	58	B	0.99999	We don't want her to worry about whether two variables have conjugate relationships adaptivity.
278942	282006	59	B	0.96952	We want to update states, parameters, maybe even the model.
282108	298134	60	B	1	The model structure has to be low power because these ancients often run on edge devices, so they run on their battery powered has to be in real time because you can't learn how to ride a bike if there's no real time reasoning.
298262	302586	61	B	1	And on top of that, you actually want to minimize variational frequency, right?
302608	307930	62	B	1	You want to do it at least as good or at least in a neighborhood of if you would do a manual derivation.
308010	311694	63	B	0.99	And some of these decidorata bite each other, right?
311732	320962	64	B	0.98708	If you want to minimize variational free energy, but you have to do it in real time and on low power that kind of bites each other, right?
321016	328966	65	B	0.99946	So these are difficult KPIs that they're all important.
329068	334440	66	B	1	You can't just take one out because then the whole system wouldn't work.
335130	350358	67	B	0.82511	So when you read papers on active inference, you often also read and now we implement variation of minimization and that can be done by message passing on a graph.
350454	356670	68	B	1	And I want to clarify first why it has to be done by message passing on the graph.
357010	361294	69	B	0.59	I do that by giving a very short answer and then do an example.
361412	373474	70	B	1	The short answer is that Bayesian inference involves computing very large sum of products, like what you see here on the left hand side.
373592	380274	71	B	0.97255	Here's a product AC, ADBC, and then we sum them AC plus ad and so forth.
380322	381846	72	B	0.99997	This is a sum of products.
382028	391160	73	B	1	Now, we know by the Distributive law that this here on the left hand side can also be computed as on the right hand side.
391610	395766	74	B	0.99917	If I multiply this out, I get a times C plus a times D and so forth.
395878	400714	75	B	0.54791	This is a product of sums and they're exactly the same thing.
400912	410026	76	B	1	The only difference is that to compute the left hand side takes four additions sorry, four multiplications and three additions.
410138	415270	77	B	1	To compute the right hand side takes two additions and only one multiplication.
415450	420994	78	B	0.99802	So on the right hand side is much cheaper to compute than the left hand side.
421192	438434	79	B	0.99999	Normally when we write down marginalization and Beijing inference, we write things down as in the left hand side what message passing does on the graph, it will automatically convert that into much cheaper to evaluate product of sums.
438562	441420	80	B	1	And I'll give an example of that.
443470	450650	81	B	0.99947	So here is an example model F of seven variables x one, x two through x seven.
450800	457642	82	B	1	And this model happens to be factorized FA of x one, FB, x two and so forth.
457786	462186	83	B	0.8	Now, we can draw this factorization as a graph.
462378	471086	84	B	0.99	And what we do, and this is called a Farney style factor graph, what we do is for each factor FA, we allocate a node.
471118	474526	85	B	0.99953	So FB gets a node and FC gets a node.
474718	479170	86	B	1	And we associate the variables in our system with the edge.
479330	485158	87	B	1	And an edge is connected to a node if that variable is an argument of that function.
485244	491142	88	B	0.99991	So FC is a function of x one, x two, x three.
491276	499530	89	B	1	And that means that FC connects to the edges x one, x two, x three, and FD is only a function of x four.
499600	503510	90	B	0.99999	So FD only connects to the edge x four.
503680	514400	91	B	0.99988	So what you can see in this graph is this graph is nothing but a visualization of the factorization assumptions that we have for this model.
515350	530440	92	B	0.98	Now, if I'm interested in a big marginalization task and I integrate out over all variables but x three, so x one, x two, x four and so forth through x seven, I'm interested in this.
531290	551834	93	B	0.99959	Then taking advantage of this factorization, I can rewrite basically this sum of product into a product of sums as below here, what you will see here below this computes exactly the same thing.
551872	554670	94	B	0.99994	But I've made use of this distributive law.
554820	560766	95	B	0.5554	For instance, FC contains no x four, no x five.
560868	564270	96	B	1	So I moved it over the summation sign to the left.
564420	569858	97	B	1	And FB also doesn't contain x four, x five, x six, seven.
569944	572100	98	B	1	So I moved it all the way to the left.
572550	587462	99	B	1	And when you do that, you are left here with an expression where I only sum over two variables and here I have to sum over six variables and here over two, and here over two.
587596	602778	100	B	0.99999	So you can imagine if each variable, let's say x one, x two, if each variable has ten interesting values that you need to sum over, then I have here the original marginalization problem.
602864	613902	101	B	1	I have ten to the power six, so a million terms, and here in red I have 100 terms and here I have 100 and here I have 100.
613956	618418	102	B	0.99999	So here I have 300 terms and here I have 1 million terms.
618584	629014	103	B	0.99993	So it's an enormous reduction in computational complexity when we make use of this distributive law.
629132	638722	104	B	1	Now, it turns out that if you write this out, you can associate these intermediate factors with messages on the graph.
638786	641862	105	B	0.99887	It's just an interpretation, a visual interpretation.
642006	656894	106	B	0.55571	It's as if FC receives a message from FA and FB receive or FC receives a message from FB and computes an outgoing message MU x three.
657012	658686	107	B	0.99	And the same thing for Fe.
658788	669138	108	B	0.99898	So Fe receives a message from its neighboring factors, FD and FF and computes an outgoing message, x three.
669304	683880	109	B	0.77598	So what you see here is that the entire marginalization process can be represented as basically computing a few messages on a graph and multiplying some of these messages with each other.
684650	690478	110	B	1	And that's how you can do Bayesian inference and also how you can do variational free energy minimization.
690674	706410	111	B	0.9996	So this works in factorized models, but I would say even stronger if your model is not factorized and you have a lot of variables, there is just no way you can do proper inference.
706490	714042	112	B	0.99993	So any serious model is factorized, like the brain is almost sparse, is almost empty.
714106	720574	113	B	0.98629	We have, what is it, about 10 billion neurons, and each neuron connects to a few thousand other neurons.
720622	726366	114	B	0.99972	So if I would draw the graph, that graph is almost empty, it is hugely sparse.
726478	731590	115	B	0.8	And so there is no other way to do inference in the brain than by message passing.
732170	737000	116	B	0.99989	So that's why message passing, just because it's more effective than anything else.
738650	742822	117	B	1	Now then the issue is which message do you compute?
742886	744810	118	B	0.99997	How do you compute messages?
745550	748874	119	B	0.99966	Because there are different ways of doing it right.
748912	761774	120	B	0.96	And we also read in active inference papers, you can do this by variational message passing, or expectation maximization, or belief propagation and variational LaPlace and all these terms.
761972	768830	121	B	1	It turns out that there is an umbrella framework for all these methods passing frameworks.
768910	774686	122	B	1	And that umbrella framework is called Constraint better free energy minimization.
774878	781430	123	B	1	And I will try to illustrate it by this slide.
781850	784050	124	B	0.99639	So here I have this graph.
784130	796426	125	B	0.99966	This is just an example graph where my generative model is basically factorized in FA, FB, FC, FD and Fe.
796608	798362	126	B	1	And I've also written that here.
798416	800940	127	B	0.99993	So this now is the variational free energy.
801710	805422	128	B	1	Now, I haven't made any assumption on Q of X.
805476	808894	129	B	0.99998	So Q of X is still Q of x one, x two, x three.
808932	814910	130	B	0.83032	It's just a joint overall variables and it doesn't have any factorization assumption.
815910	825602	131	B	1	It makes sense to also assume that the posterior kind of follows the factorization assumption of the prior, namely of the generative model.
825736	842854	132	B	0.97275	So if we make that assumption and that means we're going to make the assumption that QX is also now a product of QAS of X of A, where QAS of X of A stands for beliefs over nodes.
842902	854986	133	B	1	What I mean by that is that Q of B is a posterior belief over this node, meaning it's a posterior belief over the edges that connect to this node.
855098	873890	134	B	1	Just like FB is a function of x one, x two, x four, that's if you will, the prior or the generative model, then Q of B, the variational posterior for this node will also depend on x one, x two, x four, and on no other factors.
874470	886498	135	B	0.99998	If you just do that, then you will count some of the variables double because x one is part of the belief over FA, but also part of the belief over FB.
886674	892806	136	B	0.99978	So we just have to discount that by dividing by beliefs over edges.
892998	908910	137	B	0.99982	That means that I make now an assumption that my posterior beliefs is divided into local beliefs over notes and local beliefs over edges over variables.
909570	911994	138	B	0.99999	This will make things a lot simpler.
912042	926450	139	B	0.99997	In fact, if my graph is a tree and I did the tree here, and I would do message passing on that tree and I could suppose I could do that perfectly, everything is linear gaussian, then I get perfect Bayesian inference.
927030	928514	140	B	0.99999	There is no approximation.
928562	930386	141	B	0.99998	So this is a good assumption.
930578	946010	142	B	1	Sometimes it's still very hard to compute a message because even the single messages that come out of these nodes, they're still integrals or summations, and in particular the integrals may be a problem.
946080	948266	143	B	0.99997	We may not have an analytical answer.
948448	953814	144	B	0.99883	So what we sometimes do is add additional assumptions.
953942	965270	145	B	0.99466	We'll say, well, the posterior belief over FD, I can't compute it in general, but I'm going to just assume now that it's a gaussian that makes it easier.
965450	988360	146	B	1	Or we can make an extra factorization assumption and say the posterior belief over FB, which is really a belief over the joint x one, x two, x four is going to be broken into independent belief over x one and belief over x two and x four.
990810	996686	147	B	0.81939	These additional assumptions, if I impose them as well, this is what I recall.
996738	1004222	148	B	0.9	Now, if I all substituted here in Q of x, I get what's called a constrained beth free energy.
1004356	1007386	149	B	0.99973	This is the same Beth as in the Oppenheimer movie.
1007418	1010560	150	B	0.99604	This is Hans Bethe, where it's named after.
1013730	1033238	151	B	0.99988	We have a graph now that is highly factorized and we have local beliefs over notes and over and they're indicated with red and we have additional constraints in green.
1033324	1037346	152	B	0.53543	They could be Gaussians or mean field constraints or other constraints.
1037458	1041814	153	B	1	And now we will assume constraints that make it possible to compute all the messages.
1041862	1045750	154	B	1	And now we can just automate this by making different assumptions.
1045830	1054106	155	B	0.99997	We can turn this into expectation maximization or belief propagation or hybrid forms thereof.
1054138	1058526	156	B	0.7084	We can turn it into any relevant message passing algorithm that you've heard of.
1058628	1064160	157	B	0.99919	So this is a very nice umbrella framework that basically encompasses everything.
1066070	1075940	158	B	0.8475	We've written a pretty large paper on this in the Entropy Journal where you can read all the math on how this works.
1077430	1084674	159	B	0.99778	So we've talked about why message passing, namely because it's the most effective way of doing inference.
1084722	1096726	160	B	0.68	And we've talked about which messages to compute, namely we turn our variational free energy into something called a constraint, better free energy and then we can compute messages.
1096838	1102102	161	B	1	The only thing that's left is, well, when do we pass these messages?
1102246	1103946	162	B	0.99977	What is the sequence of messages?
1103978	1105520	163	B	0.98988	Which one comes first?
1105890	1110400	164	B	0.99	And this is where we see a lot of papers, right?
1111730	1114586	165	B	1	You have to write control flow, what's called control flow.
1114618	1118734	166	B	1	You have to say, okay, here is my algorithm for active inference.
1118782	1120370	167	B	1	First I specify a model.
1120520	1133910	168	B	0.99997	Then let's do inference for every time step, collect a new observation, update the state, update the desired future, and so forth, compute expected free energy, select the policy, et cetera.
1135610	1137510	169	B	0.99998	This kind of program.
1137660	1142598	170	B	1	The problem with active inferences is that there is nested for loops in here.
1142684	1145894	171	B	0.73939	Here's a for loop, and here's another for loop.
1145942	1152486	172	B	1	And for each of these policies, I'm going to have to go into the future, so I'm going to have another time loop.
1152518	1155178	173	B	0.99993	So it is for loops, in for loops, in for loops.
1155274	1160186	174	B	0.99992	This will completely explode in terms of computational complexity.
1160378	1167742	175	B	0.99941	So as a result, some very clever people have written very clever algorithms of doing this much faster.
1167806	1176770	176	B	0.99604	Sophisticated inference, branching time active inference, dynamic programming EFE are recent proposals for doing this very clever.
1177190	1186150	177	B	0.99999	In the end, all of these proposals come down to a particular just a message passing schedule.
1187530	1193866	178	B	0.99999	Once we commit to message passing on the graph as our inference procedure, it's the only thing that's going on.
1194048	1202966	179	B	0.98	And all of this sophisticated inference and branching time active inference, all it does is it schedules the messages.
1202998	1206270	180	B	1	It says first this message, then this message, then this message.
1206420	1210714	181	B	0.98	I don't mean that as a slight to these algorithms.
1210762	1211530	182	B	0.99826	They're very clever.
1211610	1219390	183	B	1	And as we've seen in the presentation by Aswin Paul, you get huge improvements if you go from regular inference to sophisticated inference.
1219550	1228600	184	B	0.99999	But it's good to realize that these algorithms just specify in a graph which message comes after which message.
1229850	1238690	185	B	0.99072	So here's an example of a graph and a message sequence.
1238770	1248586	186	B	0.98836	Here's message one, then message two, and message three goes up, and then we go from FC to FF, and here's message five, and then we go to Fe.
1248688	1255790	187	B	1	And this could correspond this sequence to dynamic time programming EFE or sophisticated inference.
1256530	1268802	188	B	0.99987	There are a couple of problems with this approach, which basically with having the user to specify a clever algorithm, first of all, you have to be a specialist to do it right.
1268856	1270660	189	B	0.74366	Only these are very clever people.
1271030	1282470	190	B	0.99999	That means that if we let it leave it to say to an engineer in a company, well, it's a high probability he's not going to get it right.
1282540	1283990	191	B	0.99985	That's very unfortunate.
1284570	1292902	192	B	0.99997	But there is another issue, and that is that in a sense, it's a global variable in the message passing schedule.
1292966	1299430	193	B	1	All nodes are visited, because if a node would not be visited, then we shouldn't have it in the graph.
1299510	1305754	194	B	1	And that means if one node crashes, basically the message passing schedule is invalid.
1305802	1307520	195	B	1	I have to reset my system.
1308290	1320690	196	B	1	And if you fly a drone, if it's deployed and it's out in the field and a node crashes, a transistor burns out, and I have to totally reset now my system, I have to compute a new message passing schedule.
1321510	1325378	197	B	0.99554	Then you're not doing inference and your drone flies into the wall.
1325544	1327578	198	B	0.99999	So this is not robust.
1327774	1334866	199	B	0.93	And it also for the same reason we may actually want to take out a node.
1335058	1340350	200	B	0.9999	We may want to prune a node, we want to do structural adaptation.
1340530	1348182	201	B	0.99	And we can't do structural adaptation because we have to reset the system, recompute a message passing schedule.
1348326	1358378	202	B	0.99882	So this procedural style where an engineer specifies which message comes after this message has some disadvantages.
1358474	1359962	203	B	0.99944	It's not very robust.
1360106	1365190	204	B	0.82	And if you want to do it very clever, you have to be really a specialist.
1365370	1371330	205	B	0.89316	So a better system is what we call reactive message passing.
1371910	1379830	206	B	0.97	And it's very related to what was in the first session called the actor model.
1379980	1383686	207	B	0.91685	Keith Duggar had a nice presentation on the actor model.
1383868	1390366	208	B	0.90133	So what we will do is we will say we will not have a global message passing schedule.
1390498	1394374	209	B	1	The engineer will not specify anything anymore.
1394502	1402234	210	B	1	The inference code that an engineer will have to write is just say, react to any free energy minimization opportunity.
1402432	1404894	211	B	0.83092	In other words, there is no inference code.
1404932	1406510	212	B	0.86622	It's completely automated.
1407010	1415414	213	B	1	And we will replace this global message passing schedule by local triggering inside the node.
1415482	1422340	214	B	0.99925	So each node is now just an autonomous system that's interested in minimizing its free energy.
1422950	1425966	215	B	1	It can do so by sending out messages.
1426158	1428482	216	B	1	And when will it do so?
1428536	1440602	217	B	0.99998	Well, it receives messages, and then when it looks at these messages and it feels like, oh, there is an opportunity for me to minimize free energy by or expected free energy energy by sending out a message.
1440656	1452780	218	B	0.99436	Then we'll send out a message and each node will do so by itself asynchronously so you get parallel distributed processing, or concurrent processing, as Keith called it.
1453490	1463710	219	B	0.99988	In principle, you could play this game on many computers at the same time, and so you get tremendous advantages.
1465510	1468114	220	B	1	First of all, you don't have to write difficult code.
1468232	1475780	221	B	1	Second of all, you can do multithreading or you can run it on multiple computers at the same time.
1477510	1491258	222	B	0.86	And there's also robustness advantages because if a node crashes, then there's nothing that stops the system from just finding another path, right?
1491344	1497722	223	B	0.9999	If this node crashes, this path from here's message three, this path now doesn't work.
1497776	1502570	224	B	0.99991	So I cannot send anything to Fe anymore from X.
1502720	1504782	225	B	0.99995	Well, then I just sent a new message here.
1504836	1505630	226	B	0.99997	Why not?
1505780	1515302	227	B	0.80193	It's like when water falls down a mountain and it zigzags its way down into the value and you halfway put up an obstruction.
1515386	1520126	228	B	0.89	It just finds another path, not the preferred path.
1520318	1526722	229	B	0.92421	This has to find, well, the second best path, because the first path has been obstructed, right?
1526776	1529954	230	B	1	And that's what's going to happen in this system as well, right?
1529992	1531700	231	B	0.99993	That's just how nature works.
1532150	1537074	232	B	1	It tries to find the best path, the easiest path, and if that's not available, then we do the second best path.
1537122	1540638	233	B	1	And that's also what you can do with reactive message passing.
1540754	1542406	234	B	0.99553	So you can prune nodes.
1542438	1548118	235	B	1	You can do structural adaptation, and it's far more robust.
1548294	1556014	236	B	1	And you can also do chance encounters with other drones, right?
1556132	1563262	237	B	0.99888	Drones that get close can start communicating with each other, and when they fire away, they stop communicating with each other.
1563316	1578920	238	B	1	And this is no problem, because you can basically change who change nodes can change on the fly, who they communicate to and who they want to listen to.
1580890	1589490	239	B	0.99984	That's the way nature works, and also how it works when we do reactive programming and reactive message passing.
1589650	1598620	240	B	0.99324	So, in summary, we're interested in automating inference, in active inference agents, right?
1599150	1604522	241	B	0.99999	Because it's an operation that's basically only for experts.
1604586	1619762	242	B	1	And this active inference technology is not going to be successful unless we get more people, let's say, democracies it, and we get competent engineers being able to develop good agents, right?
1619816	1625154	243	B	1	You shouldn't have to be a top specialist in the world to develop an active inference agent.
1625352	1633218	244	B	1	Now, in order to automate inference, you must do message passing, and I've talked about that for efficiency.
1633394	1636280	245	B	0.94202	I've also talked about which messages to pass.
1636970	1645734	246	B	1	Not necessarily do you have to follow this framework, but constrained better Free energy framework is very convenient.
1645782	1657546	247	B	0.4831	It's an umbrella framework that basically goes over all the interesting other message passing computations.
1657738	1664270	248	B	0.65039	When message passing, reactive message passing, it's fully automated, so you don't have to write any code anymore.
1664690	1669226	249	B	0.99996	In principle, you can do parallel distributed processing.
1669258	1670850	250	B	0.56137	It's robust structural changes.
1670920	1672782	251	B	1	You can learn new inference pathways.
1672846	1675860	252	B	0.98745	So lots of advantages here.
1676230	1679140	253	B	0.94	Now, how do we do it?
1679750	1685190	254	B	1	I like to introduce a toolbox that we've been working on called ARX infer.
1685770	1689794	255	B	0.99	And we do that with my lab here at the university.
1689842	1693434	256	B	0.99776	I'm here in Eindhoven in the south of the Netherlands, and we have a lab.
1693552	1695082	257	B	0.87	The lab is called BIS lab.
1695136	1704126	258	B	0.99305	Here are postdocs and assistant professors and PhD students, and we've been working on this for many years.
1704308	1713390	259	B	0.98	And some of these, like Albert and Ismail and Tyce, have written dissertations.
1714210	1718270	260	B	0.99	And our best work, we have consolidated that in a toolbox.
1719010	1721286	261	B	0.98	And the toolbox is called Arcs infer.
1721338	1725198	262	B	0.98	And if you want to have a look, you can go to the website, arcsinfer.
1725294	1726050	263	B	0.55273	ML.
1726470	1733042	264	B	0.88	And Arctinfur works in the way that I've just discussed.
1733106	1734562	265	B	1	It does message passing.
1734626	1737638	266	B	0.84	It tries to minimize constraint, better free energy.
1737804	1742950	267	B	0.76946	That means it can come up with all kinds of message passing algorithms.
1744590	1752634	268	B	0.96	It will do it in a reactive way, and it will try to do it in real time and low power and all the KPIs that we're talking about.
1752672	1759386	269	B	1	Now, it's, of course, not done, but it's functional and like to show some demos.
1759418	1768610	270	B	0.99	And I will leave it to Dimitri and Bart, who are two advanced PhD students in my lab to show the demos.
1770710	1774370	271	B	0.98961	So I'm going to stop sharing.
1777350	1778100	272	A	0.99981	Awesome.
1778490	1779394	273	A	0.98338	Thank you, Bert.
1779442	1780150	274	A	0.99974	Great talk.
1780220	1780840	275	B	0.5627	Sure.
1782490	1783558	276	C	0.99996	Can you hear?
1783724	1784102	277	B	0.73646	Yeah.
1784156	1784760	278	B	0.24406	Yeah.
1785290	1785750	279	C	0.57403	Okay.
1785820	1788038	280	C	1	I will try to share my screen.
1788204	1788920	281	B	0.48998	Okay.
1790010	1791820	282	C	0.99843	So you should see it now.
1792430	1793420	283	A	0.99337	Looks good.
1793950	1797846	284	C	0.56744	Okay, so, yeah, hello to everyone, I'm Dmitry
1797878	1814266	285	C	0.08427	Bagaev. So I'm a PhD student in Bioslab in Einhoven University of Technology, and yes, I have a small presentation about actual software developments in so over the past few years, we have significantly improved our tools.
1814378	1823790	286	C	0.99	And basically my entire PhD was dedicated to implement this idea, which Beard was talking about, like implementing the variation of reactive message passing.
1823870	1830630	287	C	0.95	And in this presentation, I just want to show you what you can actually do using this theory under the hood.
1831930	1837794	288	C	0.61774	Okay, so basically, in order to automate active inference, we need to automate Bayesian inference.
1837842	1846054	289	C	0.97	And we have already a lot of solutions for that, such as Pyro NumPy, which is funded by Google, Info.
1846102	1850460	290	C	1	Net is funded by Microsoft, turing is in July, PIMC, and many, many.
1851470	1857886	291	C	0.76	And basically these solutions are really good and they're really good at prototyping as well.
1857988	1864474	292	C	0.98848	But our goal is eventually to be able to deploy these kind of systems, not just prototype.
1864602	1869810	293	C	1	And we are really focusing on these particular properties for this automated Bayesian inference.
1870230	1874846	294	C	0.99364	So it must be low power, adaptive, real time scalable.
1874958	1881810	295	C	1	It also must be user friendly at the end and must support a large scope of models if we want it to be useful.
1883750	1893058	296	C	0.85113	In Bioslab, we want to build such a software with such nice properties and it's always about trade offs, right?
1893084	1903340	297	C	0.99641	So we do something better in one particular domain and maybe other software libraries, they might be better in a different domain, but we are really focusing on this particular property.
1904430	1907754	298	C	0.93	And so, yes, I will reiterate a little bit Bert's presentation.
1907802	1909102	299	C	0.99357	So how do we achieve this?
1909156	1926210	300	C	0.92147	So imagine we have an environment and we have an agent, and the agent takes some actions and the agent basically what he needs is to come up with some sort of good enough probabilistic model of its environment in order to do patient inference.
1926870	1936520	301	C	1	And in our framework, we encode the model as a factor graph, which not only models the observations, but also actions and desired future.
1937930	1949126	302	C	1	And this approach allows us to decompose these complex relationships between variables and hidden states into some kind of structure and local blocks.
1949318	1952490	303	C	1	And it's not a black box anymore.
1953250	1958138	304	C	1	And the model itself may have some sort of background motivation interpretation.
1958234	1970802	305	C	1	It may encode your prior knowledge about some particular physical system and the locality of these blocks basically allows you to scale to millions of variables and hidden states.
1970936	1978450	306	C	1	It allows you to pre optimize it maybe, or maybe use some sort of different approximation strategies in different places.
1978970	1983094	307	C	0.98997	So it allows a lot of very nice properties as well.
1983292	1988978	308	C	0.62	And we use reactive message passing to run actual variational Bayesian inference.
1989154	1995020	309	C	0.6	It uses reactive programming under the hood to minimize the approximation to the variational free energy.
1995470	2000540	310	C	0.99	And yes, as Bert also mentioned, it's very much related to actor model.
2002510	2005118	311	C	0.94	And basically in Ariks and fur.
2005204	2016080	312	C	1	You can think of different nodes as actors themselves and they have basically one single purpose is to send a variational message that minimizes free energy.
2016610	2022366	313	C	0.99997	This is a very short and very high level description, but it is essentially what is happening under lipid.
2022478	2034246	314	C	0.9999	So we are not treating different agents which interact with each other as actors, but we also treat the actual components of the underlying model as actors themselves.
2034428	2036866	315	C	0.73196	It's like a very hierarchical structure.
2036978	2042250	316	C	0.77444	So this is the main central idea of this inference.
2043790	2049500	317	C	0.80996	So here for example, first example, we can do an inference in a dynamical system.
2050110	2054430	318	C	0.99998	This example, which is quite old already, I think it's like two years ago.
2054580	2065866	319	C	0.99952	So we track a position of the object given some noisy measurements which are indicated by green dots, the actual real signal, we cannot observe it, but we just can plot.
2065898	2072318	320	C	1	It is shown as blue and the inferred signal is shown as red and the data set is infinite.
2072414	2076980	321	C	1	The inference end just reacts on it and does not assume any particular data size.
2077430	2080020	322	C	0.78713	Simply reacts in your observation as soon as possible.
2080810	2084760	323	C	0.80716	Yeah, I'm actually not sure how smoothly Zoom shares my screen.
2085370	2092220	324	C	0.99997	Maybe you can see it's a bit lagging in the animations, I'm not sure because maybe zoom does not share it on a full frame rate.
2093070	2098982	325	C	0.78	And also on the right hand side you can see how we define models in our framework.
2099046	2101050	326	C	0.9999	We use Julia as a programming language.
2102910	2108206	327	C	0.99951	Basically, this is everything that you need to define this particular model and run inference on a data set.
2108388	2114250	328	C	1	And actually I literally spent more days to plot it instead of inference.
2114330	2121650	329	C	0.97634	So inference was an easiest part for me, plotting was way much harder to relate to user friendliness.
2123030	2128354	330	C	1	And we actually have plans to improve our model specification language, make it even easier.
2128402	2138870	331	C	0.99269	So now for technical reasons, we have some auxiliary statements in the model specification language, but we are working to improve that and make it even easier.
2141130	2149094	332	C	0.77698	This is another example which is similar to the previous one, that uses much more complex and linear dynamical system of the double pendulum.
2149222	2157470	333	C	0.95	And the system is chaotic and we can observe only a small part of it with a lot of noise, also indicated as a green dots.
2158290	2172020	334	C	1	And nevertheless, given good enough model, you can infer the other hidden states with pretty much high precision and the code needed for that is also relatively short.
2175510	2182390	335	C	0.99999	We also have examples with active inference agents that interact with their environment.
2183050	2191338	336	C	0.9994	So the left up shows mountain car problem, very famous problem.
2191504	2201820	337	C	0.96	The left bottom side shows an active inference agent which tries to control the inverted pendulum from falling in the windy conditions it reacts in wind.
2202510	2208218	338	C	0.82032	We also have a demo of an agent that controls a pendulum in an ever changing environment.
2208394	2215342	339	C	0.99955	So on the right side you see a pendulum with an engine and engine has limited power and.
2215396	2220450	340	C	1	The agent itself needs to reach the goal and the goal is indicated as a red circle.
2222470	2227326	341	C	0.99998	Basically, in this demo we can change the environment in real time and see how the agent reacts.
2227438	2237474	342	C	0.99994	So we can change the mass of the pebble among its length or the amount of noise in the measurements, or we can change the goal, we can change maximum engine power, et cetera.
2237602	2246410	343	C	0.99995	So the agent will still try to infer the best possible course of actions in order to reach its goal and it just never stops reacting.
2248110	2256254	344	C	0.94874	It's also actually possible to restrict engine power such that it will not longer possible to reach the goal, right?
2256292	2258080	345	C	0.99941	But the agent will still try.
2260050	2280550	346	C	0.99999	We have other cool demos with smart navigation and collision avoidance which are still under active research and the code for them is not available publicly it will be soon available, but for example in this example we can define a set of agents with their boundaries and a set of their destinations.
2280890	2284710	347	C	1	And we can see how they try to resolve their routes altogether.
2287050	2290558	348	C	1	And we can have some static obstacles in the map.
2290674	2300570	349	C	0.99951	We can see how agents can find their most optimal path in order to reach their goals and avoid any possible collision.
2301630	2308382	350	C	1	And it's also not necessary to have static obstacles, the obstacles themselves may move.
2308516	2317614	351	C	0.61967	So on this demo we have hundreds of agents that navigate through a map of obstacles that move from bottom to top to the circles or obstacles.
2317742	2325730	352	C	0.73	And agents are depicted as small dots and they need to go from left to right, basically avoid any sort of collision.
2327670	2341898	353	C	1	And as I also mentioned, we want to perform efficient and real time inference, but we also to do it like low power, low performance on low performance devices such as Raspberry, Pi or Coolpy as an example.
2342064	2348630	354	C	0.98	And we have some results of successfully running the Bayesian audio source separation, for example, on coolpy.
2348790	2356910	355	C	0.99614	So it is actually possible we try to run active inference agents also on Coolpy.
2357410	2374786	356	C	0.98189	So as the aforementioned inverted pendulum, and as I mentioned, we also need to have a large model scope and basically RICS infer has not been designed to solve any of the aforementioned problems.
2374888	2383590	357	C	0.99951	Specifically, we have a large set of different examples in our repository, different models, different data, different inference constraints.
2384250	2393506	358	C	0.99998	We have examples for linear regression, hidden Markov model altogether, grace model hierarchy models, misheard models, Gaussian process and so, right?
2393548	2395930	359	C	0.83562	So this approach is very versatile.
2396670	2416642	360	C	0.99	And for example, if you compare it with sort of a conventional software libraries where you let's say have a library that solves a common filter, might be a very great library, maybe super fast, have top performance works great and very reliable, super good.
2416696	2422034	361	C	0.99962	But then you are constrained by this particular model common filtering, right?
2422072	2424020	362	C	1	And you can't really change it much.
2424630	2437042	363	C	0.99604	In Ericsson Fur we are free to define our own models which we can pretty much easily define a model that essentially would act equivalently to common filtering equation.
2437186	2447500	364	C	0.63	And so basically in the demo that I showed before about object tracking, it was essentially a common filter but was written in a probabilistic model.
2449470	2453282	365	C	0.99328	So yeah, that was my small addition to Bear's presentation.
2453446	2459550	366	C	0.94253	So our software is free MIT license and it's open source available on GitHub.
2460530	2466062	367	C	0.92125	Yeah, and we would be happy thanks to be able to present where we would be happy to answer.
2466196	2468080	368	C	0.9991	Any, thanks.
2474760	2475508	369	A	0.70901	Awesome.
2475674	2478100	370	A	0.71	All right, I'll just ask a quick question.
2478170	2491000	371	A	0.99992	In the chat Marco asks sorry if I missed it are the collision avoidance demos real time adapting to other agents behavior or is it a collectively pre computed path?
2493020	2500412	372	C	0.9936	So basically they are not super real time, they're kind of fast to compute this path, like maybe 5 seconds or so.
2500546	2503292	373	C	0.53758	But we are basically working to make it real time.
2503346	2509228	374	C	0.99998	So we know what is the problem, we know where to improve and we will make it real time.
2509314	2511090	375	C	0.62268	Yes, almost.
2513220	2514224	376	A	0.64036	Next question.
2514342	2517404	377	A	0.79969	Do you have some comparative data with other methods?
2517452	2528736	378	A	1	And just more generally, what kinds of benchmarks or when you're talking with industry in different settings, what are people looking for that killer app of active inference?
2528768	2532200	379	A	0.99	Or what are they looking for their key measures?
2534140	2547500	380	C	0.98958	So I personally have a big paper about comparison with sampling based methods like HMC and also in my PhD thesis, there will be a comparison with nuts, also other sampling based methods.
2548240	2555790	381	C	0.98099	So, long story short, sampling based methods cannot really run this kind of sophisticated inference in real time.
2556240	2557852	382	C	0.35498	They're very time consuming.
2557916	2562992	383	C	1	They do not really scale well to large problems which is really needed for active inference agents.
2563046	2570870	384	C	0.99999	Because if you have a large environment, very complicated, you will have a lot of unknown variables in your model.
2573480	2580230	385	C	0.99999	There is a paper that compares and basically we show that our approach scales much, much better.
2580540	2593770	386	C	0.99864	So I personally run on just a regular MacBook laptop, I run the model with 2 million unknown variables and it was quite fast.
2594620	2609090	387	C	0.98916	With sampling based methods you may find yourself in a model with like 100 variables and then you wait like 2 hours or something and then it turns out that your chain did not converge or something like that.
2611860	2612368	388	A	0.83609	Cool.
2612454	2619712	389	A	0.99812	Yeah, it's people commenting in the chat like how far message passing and factor graphs have come.
2619766	2626884	390	A	0.92	And so to Bias Lab and to Bert at all, we definitely appreciate this exciting line of research.
2627002	2637896	391	A	0.99	I mean, there's so much to learn there and sometimes looking at the equations, it can seem like it's like written in stone and just sort of the beginning and the end is, you know, variational free energy.
2638078	2643012	392	A	0.99999	But then in your presentations you're really showing like no, we are hands on.
2643166	2648824	393	A	0.99997	That's where we get the interpretability, the modularity, that's where it really is implemented.
2648952	2652072	394	A	1	And it's like an information logistics challenge.
2652216	2655730	395	A	0.99942	It's not like an esoteric philosophy question at that point.
2656740	2658400	396	B	0.99983	No, indeed.
2659620	2664144	397	B	1	I should say it's taken us we are no geniuses, right.
2664182	2676356	398	B	0.9974	So our lab exists more than eight years, and you see all the people in the lab, it's taken us many years with lots of wrong directions to get this to work to where it's now.
2676458	2678560	399	B	0.99983	So it's a very long path.
2678720	2699096	400	B	0.99963	But at this moment, I'm pretty confident that at some point in the future and we don't want to say in three months or in one year, but we will be able to write a toolbox that will allow people to design a generative model and just press a button and forget about the inference.
2699128	2700984	401	B	1	You don't have to worry about inference anymore.
2701032	2707170	402	B	1	It will be fast and automated, and that will happen, and it will happen within a few years.
2708980	2711644	403	B	0.62	And maybe somebody else will write an even better toolbox.
2711772	2719190	404	B	0.99947	But I'm pretty confident that even our toolbox will be able to do that.
2720680	2727012	405	B	0.99581	People talk about, why don't we have the success of deep learning and generative AI, right?
2727066	2737492	406	B	0.99365	Well, they have the success because of big data availability of big data, big computers and toolboxes TensorFlow and all the successes.
2737636	2742808	407	B	0.99995	We don't need big data because agents collect their own data in the field.
2742894	2750728	408	B	0.99897	We don't need big computers, active influence agents, they manage their power resources.
2750904	2760240	409	B	0.99994	But we need a really good toolbox because programming an active inference agent, programming the inference by hand is just not doable.
2760660	2765570	410	B	0.99715	So we need a really good toolbox that really automates this.
2766260	2770772	411	B	0.98784	We hope Arcs Infer will be one of the first toolboxes to do that.
2770826	2777430	412	B	1	I am sure that other people will also be working on it, and better toolboxes will come about.
2778200	2783210	413	B	0.98984	But I think the optimistic message is that it will happen.
2784300	2796904	414	B	0.67	And once we have a toolbox like that, then we can actually a large community can start building agents, and we can actually show deployable agents in the field that they work.
2796942	2801292	415	B	0.92	And they work better than reinforcement learning agent or whatever is out there.
2801346	2801950	416	B	0.99394	Right.
2802560	2806850	417	B	0.99981	So I think that's a very positive and hopeful message.
2808020	2808992	418	A	0.99872	It's what we expect.
2809046	2810220	419	A	0.99956	It's what we prefer.
2810380	2811090	420	B	0.98005	Yeah.
2812900	2815730	421	A	1	Any last comments from either of you?
2819240	2820084	422	B	0.96607	Comments from us?
2820122	2832120	423	B	0.98949	No, I'm just very happy to get the opportunity, and yeah, I want to everybody can download this toolbox.
2833340	2839240	424	B	1	I think at this moment, you still should be a programmer to work with the toolbox.
2839580	2846940	425	B	1	And I hope you're friendly, because it's not totally polished in the way that we want.
2847010	2848172	426	B	0.99948	But it's coming, right?
2848226	2848684	427	B	0.99937	It's coming.
2848722	2857484	428	B	0.99984	In the next years, there will be a good toolbox for almost everybody to use, but people that are interested, even people that are interested to work.
2857522	2870290	429	B	0.99994	Here at Biaslab, we have an open position for PhD students, so we're happy to receive emails from people that are interested to work with us.
2872420	2872896	430	C	0.99985	Thank you.
2872918	2874720	431	A	0.48068	Dimitri, anything in closing?
2876420	2877344	432	C	0.99059	No, just that.
2877382	2880248	433	C	0.99922	Thank you again for possibility to present.
2880374	2881850	434	C	0.99274	Super nice to be here.
2882860	2883368	435	A	0.99996	Cool.
2883454	2883704	436	C	0.99989	Yeah.
2883742	2898890	437	A	0.99784	Well, later in the year, we will be discussing your two part recent work, and so we're going to be getting a lot into the details, and I hope that people in the institute and the ecosystem will be as excited as we all are.
2899420	2900410	438	A	0.99994	Thank you.
2900860	2901480	439	B	0.99619	Thank you.
2901550	2901796	440	B	0.99685	Bye.
