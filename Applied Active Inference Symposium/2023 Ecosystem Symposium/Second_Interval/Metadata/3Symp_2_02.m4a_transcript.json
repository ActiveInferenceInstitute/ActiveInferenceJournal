Arguments count: 4
docLabel, inSentDir, inSentFile '3Symp_2_02', '.', '3Symp_2_02_3Symp_2_02.wav.sentences.csv'
outDir: '.'
speakers File: '/mnt/d/Documents/FEP-AI/Active Inference Podcast/AllSpeakers.csv'
Column names are DocLabel, Speaker Label, Displayed Speaker Name, Full Speaker Name, First Turn, RangeFrom, RangeTo, Notes, , , , 
to write-open sentPubPath:
./3Symp_2_02_3Symp_2_02.wav.sentences.csv_transcript.txt
paragTimes
dict_keys([])

to read-open inSentPath:
./3Symp_2_02_3Symp_2_02.wav.sentences.csv
Sentence headers: start	end	sentNum	speaker	confidence	text

00:08 Daniel:
And it's a great segue from collective behavior in surprise minimizing agents to collective behavior in surprise minimizing agents, I guess.
In writeToMD, lineCount: 0, textOut: And it's a great segue from collective behavior in surprise minimizing agents to collective behavior in surprise minimizing agents, I guess.
And it's a great segue from collective behavior in surprise minimizing agents to collective behavior in surprise minimizing agents, I guess.
before writeToSrt(text: And it's a great segue from collective behavior in surprise minimizing agents to collective behavior in surprise minimizing agents, I guess., srtPosCount: 0, srtSpeaker: Daniel, srtStartTime: 8140, srtEndTime: 19570
after writeToSrt(text: And it's a great segue from collective behavior in surprise minimizing agents to collective behavior in surprise minimizing agents, I guess., srtPosCount: 4, srtSpeaker: Daniel, srtStartTime: 8140, srtEndTime: 19570
19940
Welcome, Conor.
In writeToMD, lineCount: 4, textOut: Welcome, Conor.
Welcome, Conor.
before writeToSrt(text: Welcome, Conor., srtPosCount: 4, srtSpeaker: , srtStartTime: 19940, srtEndTime: 21200
after writeToSrt(text: Welcome, Conor., srtPosCount: 5, srtSpeaker: , srtStartTime: 19940, srtEndTime: 21200
00:21 Conor:
Hey.
In writeToMD, lineCount: 5, textOut: Hey.
Hey.
before writeToSrt(text: Hey., srtPosCount: 5, srtSpeaker: Conor, srtStartTime: 21700, srtEndTime: 22112
after writeToSrt(text: Hey., srtPosCount: 6, srtSpeaker: Conor, srtStartTime: 21700, srtEndTime: 22112
22166
Sorry, I just turned on my audio, so I just heard the last thing you said.
In writeToMD, lineCount: 6, textOut: Sorry, I just turned on my audio, so I just heard the last thing you said.
Sorry, I just turned on my audio, so I just heard the last thing you said.
before writeToSrt(text: Sorry, I just turned on my audio, so I just heard the last thing you said., srtPosCount: 6, srtSpeaker: , srtStartTime: 22166, srtEndTime: 25984
after writeToSrt(text: Sorry, I just turned on my audio, so I just heard the last thing you said., srtPosCount: 8, srtSpeaker: , srtStartTime: 22166, srtEndTime: 25984
26102
Yeah.
In writeToMD, lineCount: 8, textOut: Yeah.
Yeah.
before writeToSrt(text: Yeah., srtPosCount: 8, srtSpeaker: , srtStartTime: 26102, srtEndTime: 26432
after writeToSrt(text: Yeah., srtPosCount: 9, srtSpeaker: , srtStartTime: 26102, srtEndTime: 26432
26486
Hey, welcome.
In writeToMD, lineCount: 9, textOut: Hey, welcome.
Hey, welcome.
before writeToSrt(text: Hey, welcome., srtPosCount: 9, srtSpeaker: , srtStartTime: 26486, srtEndTime: 27810
after writeToSrt(text: Hey, welcome., srtPosCount: 10, srtSpeaker: , srtStartTime: 26486, srtEndTime: 27810
28420
Yes, thanks.
In writeToMD, lineCount: 10, textOut: Yes, thanks.
Yes, thanks.
before writeToSrt(text: Yes, thanks., srtPosCount: 10, srtSpeaker: , srtStartTime: 28420, srtEndTime: 29570
after writeToSrt(text: Yes, thanks., srtPosCount: 11, srtSpeaker: , srtStartTime: 28420, srtEndTime: 29570
00:30 Daniel:
Um, we're looking forward to your presentation.
In writeToMD, lineCount: 11, textOut: Um, we're looking forward to your presentation.
Um, we're looking forward to your presentation.
before writeToSrt(text: Um, we're looking forward to your presentation., srtPosCount: 11, srtSpeaker: Daniel, srtStartTime: 30060, srtEndTime: 33268
after writeToSrt(text: Um, we're looking forward to your presentation., srtPosCount: 13, srtSpeaker: Daniel, srtStartTime: 30060, srtEndTime: 33268
33364
Multi agent active inference and multiscale alignment, current developments and challenges.
In writeToMD, lineCount: 13, textOut: Multi agent active inference and multiscale alignment, current developments and challenges.
Multi agent active inference and multiscale alignment, current developments and challenges.
before writeToSrt(text: Multi agent active inference and multiscale alignment, current developments and challenges., srtPosCount: 13, srtSpeaker: , srtStartTime: 33364, srtEndTime: 38788
after writeToSrt(text: Multi agent active inference and multiscale alignment, current developments and challenges., srtPosCount: 16, srtSpeaker: , srtStartTime: 33364, srtEndTime: 38788
38884
So feel free to share your screen or proceed however you prefer.
In writeToMD, lineCount: 16, textOut: So feel free to share your screen or proceed however you prefer.
So feel free to share your screen or proceed however you prefer.
before writeToSrt(text: So feel free to share your screen or proceed however you prefer., srtPosCount: 16, srtSpeaker: , srtStartTime: 38884, srtEndTime: 43400
after writeToSrt(text: So feel free to share your screen or proceed however you prefer., srtPosCount: 18, srtSpeaker: , srtStartTime: 38884, srtEndTime: 43400
00:44 Conor:
Great, thanks.
In writeToMD, lineCount: 18, textOut: Great, thanks.
Great, thanks.
before writeToSrt(text: Great, thanks., srtPosCount: 18, srtSpeaker: Conor, srtStartTime: 44060, srtEndTime: 44804
after writeToSrt(text: Great, thanks., srtPosCount: 19, srtSpeaker: Conor, srtStartTime: 44060, srtEndTime: 44804
44862
And before I start, because I've had issues with my voice saturating, like my microphone saturating, how's my audio?
In writeToMD, lineCount: 19, textOut: And before I start, because I've had issues with my voice saturating, like my microphone saturating, how's my audio?
And before I start, because I've had issues with my voice saturating, like my microphone saturating, how's my audio?
before writeToSrt(text: And before I start, because I've had issues with my voice saturating, like my microphone saturating, how's my audio?, srtPosCount: 19, srtSpeaker: , srtStartTime: 44862, srtEndTime: 52056
after writeToSrt(text: And before I start, because I've had issues with my voice saturating, like my microphone saturating, how's my audio?, srtPosCount: 22, srtSpeaker: , srtStartTime: 44862, srtEndTime: 52056
52088
Is it clipping at all?
In writeToMD, lineCount: 22, textOut: Is it clipping at all?
Is it clipping at all?
before writeToSrt(text: Is it clipping at all?, srtPosCount: 22, srtSpeaker: , srtStartTime: 52088, srtEndTime: 53036
after writeToSrt(text: Is it clipping at all?, srtPosCount: 23, srtSpeaker: , srtStartTime: 52088, srtEndTime: 53036
53058
Or does this sound okay?
In writeToMD, lineCount: 23, textOut: Or does this sound okay?
Or does this sound okay?
before writeToSrt(text: Or does this sound okay?, srtPosCount: 23, srtSpeaker: , srtStartTime: 53058, srtEndTime: 54444
after writeToSrt(text: Or does this sound okay?, srtPosCount: 24, srtSpeaker: , srtStartTime: 53058, srtEndTime: 54444
00:54 Daniel:
This is good and I'm watching it.
In writeToMD, lineCount: 24, textOut: This is good and I'm watching it.
This is good and I'm watching it.
before writeToSrt(text: This is good and I'm watching it., srtPosCount: 24, srtSpeaker: Daniel, srtStartTime: 54642, srtEndTime: 56704
after writeToSrt(text: This is good and I'm watching it., srtPosCount: 26, srtSpeaker: Daniel, srtStartTime: 54642, srtEndTime: 56704
00:56 Conor:
Okay, perfect.
In writeToMD, lineCount: 26, textOut: Okay, perfect.
Okay, perfect.
before writeToSrt(text: Okay, perfect., srtPosCount: 26, srtSpeaker: Conor, srtStartTime: 56902, srtEndTime: 57888
after writeToSrt(text: Okay, perfect., srtPosCount: 27, srtSpeaker: Conor, srtStartTime: 56902, srtEndTime: 57888
57974
Thank you.
In writeToMD, lineCount: 27, textOut: Thank you.
Thank you.
before writeToSrt(text: Thank you., srtPosCount: 27, srtSpeaker: , srtStartTime: 57974, srtEndTime: 58850
after writeToSrt(text: Thank you., srtPosCount: 28, srtSpeaker: , srtStartTime: 57974, srtEndTime: 58850
60980
I will share my screen.
In writeToMD, lineCount: 28, textOut: I will share my screen.
I will share my screen.
before writeToSrt(text: I will share my screen., srtPosCount: 28, srtSpeaker: , srtStartTime: 60980, srtEndTime: 62690
after writeToSrt(text: I will share my screen., srtPosCount: 29, srtSpeaker: , srtStartTime: 60980, srtEndTime: 62690
66020
Share this one.
In writeToMD, lineCount: 29, textOut: Share this one.
Share this one.
before writeToSrt(text: Share this one., srtPosCount: 29, srtSpeaker: , srtStartTime: 66020, srtEndTime: 67328
after writeToSrt(text: Share this one., srtPosCount: 30, srtSpeaker: , srtStartTime: 66020, srtEndTime: 67328
01:07 Daniel:
The one thing I'll note oh, yes.
In writeToMD, lineCount: 30, textOut: The one thing I'll note oh, yes.
The one thing I'll note oh, yes.
before writeToSrt(text: The one thing I'll note oh, yes., srtPosCount: 30, srtSpeaker: Daniel, srtStartTime: 67494, srtEndTime: 69072
after writeToSrt(text: The one thing I'll note oh, yes., srtPosCount: 31, srtSpeaker: Daniel, srtStartTime: 67494, srtEndTime: 69072
01:09 Conor:
OK.
In writeToMD, lineCount: 31, textOut: OK.
OK.
before writeToSrt(text: OK., srtPosCount: 31, srtSpeaker: Conor, srtStartTime: 69126, srtEndTime: 69500
after writeToSrt(text: OK., srtPosCount: 32, srtSpeaker: Conor, srtStartTime: 69126, srtEndTime: 69500
01:09 Daniel:
It's just JF symbolic implementation does not use statistical distributions.
In writeToMD, lineCount: 32, textOut: It's just JF symbolic implementation does not use statistical distributions.
It's just JF symbolic implementation does not use statistical distributions.
before writeToSrt(text: It's just JF symbolic implementation does not use statistical distributions., srtPosCount: 32, srtSpeaker: Daniel, srtStartTime: 69590, srtEndTime: 75280
after writeToSrt(text: It's just JF symbolic implementation does not use statistical distributions., srtPosCount: 35, srtSpeaker: Daniel, srtStartTime: 69590, srtEndTime: 75280
75440
It uses the symbolic and the logical inference.
In writeToMD, lineCount: 35, textOut: It uses the symbolic and the logical inference.
It uses the symbolic and the logical inference.
before writeToSrt(text: It uses the symbolic and the logical inference., srtPosCount: 35, srtSpeaker: , srtStartTime: 75440, srtEndTime: 80748
after writeToSrt(text: It uses the symbolic and the logical inference., srtPosCount: 37, srtSpeaker: , srtStartTime: 75440, srtEndTime: 80748
80784
And now we're going to move back into the distributional space, and it will be awesome to see similarities and differences.
In writeToMD, lineCount: 37, textOut: And now we're going to move back into the distributional space, and it will be awesome to see similarities and differences.
And now we're going to move back into the distributional space, and it will be awesome to see similarities and differences.
before writeToSrt(text: And now we're going to move back into the distributional space, and it will be awesome to see similarities and differences., srtPosCount: 37, srtSpeaker: , srtStartTime: 80784, srtEndTime: 88004
after writeToSrt(text: And now we're going to move back into the distributional space, and it will be awesome to see similarities and differences., srtPosCount: 41, srtSpeaker: , srtStartTime: 80784, srtEndTime: 88004
88132
So thank you, Conor, to you for the presentation.
In writeToMD, lineCount: 41, textOut: So thank you, Conor, to you for the presentation.
So thank you, Conor, to you for the presentation.
before writeToSrt(text: So thank you, Conor, to you for the presentation., srtPosCount: 41, srtSpeaker: , srtStartTime: 88132, srtEndTime: 91480
after writeToSrt(text: So thank you, Conor, to you for the presentation., srtPosCount: 43, srtSpeaker: , srtStartTime: 88132, srtEndTime: 91480
01:32 Conor:
And thank you, Daniel, for the introduction and for inviting me, as well as big thank you to the other organizers of the Third Applied Active Influence Symposium.
In writeToMD, lineCount: 43, textOut: And thank you, Daniel, for the introduction and for inviting me, as well as big thank you to the other organizers of the Third Applied Active Influence Symposium.
And thank you, Daniel, for the introduction and for inviting me, as well as big thank you to the other organizers of the Third Applied Active Influence Symposium.
before writeToSrt(text: And thank you, Daniel, for the introduction and for inviting me, as well as big thank you to the other organizers of the Third Applied Active Influence Symposium., srtPosCount: 43, srtSpeaker: Conor, srtStartTime: 92860, srtEndTime: 101740
after writeToSrt(text: And thank you, Daniel, for the introduction and for inviting me, as well as big thank you to the other organizers of the Third Applied Active Influence Symposium., srtPosCount: 48, srtSpeaker: Conor, srtStartTime: 92860, srtEndTime: 101740
102560
Yeah, I'm really happy to be here to present.
In writeToMD, lineCount: 48, textOut: Yeah, I'm really happy to be here to present.
Yeah, I'm really happy to be here to present.
before writeToSrt(text: Yeah, I'm really happy to be here to present., srtPosCount: 48, srtSpeaker: , srtStartTime: 102560, srtEndTime: 105340
after writeToSrt(text: Yeah, I'm really happy to be here to present., srtPosCount: 50, srtSpeaker: , srtStartTime: 102560, srtEndTime: 105340
105490
So.
In writeToMD, lineCount: 50, textOut: So.
So.
before writeToSrt(text: So., srtPosCount: 50, srtSpeaker: , srtStartTime: 105490, srtEndTime: 105804
after writeToSrt(text: So., srtPosCount: 51, srtSpeaker: , srtStartTime: 105490, srtEndTime: 105804
105842
My name is Conor Heins.
In writeToMD, lineCount: 51, textOut: My name is Conor Heins.
My name is Conor Heins.
before writeToSrt(text: My name is Conor Heins., srtPosCount: 51, srtSpeaker: , srtStartTime: 105842, srtEndTime: 107144
after writeToSrt(text: My name is Conor Heins., srtPosCount: 52, srtSpeaker: , srtStartTime: 105842, srtEndTime: 107144
107192
I'm a PhD student at the Max Planck Institute of Animal Behavior.
In writeToMD, lineCount: 52, textOut: I'm a PhD student at the Max Planck Institute of Animal Behavior.
I'm a PhD student at the Max Planck Institute of Animal Behavior.
before writeToSrt(text: I'm a PhD student at the Max Planck Institute of Animal Behavior., srtPosCount: 52, srtSpeaker: , srtStartTime: 107192, srtEndTime: 110940
after writeToSrt(text: I'm a PhD student at the Max Planck Institute of Animal Behavior., srtPosCount: 54, srtSpeaker: , srtStartTime: 107192, srtEndTime: 110940
111100
And I'm also a researcher at the Versus AI research lab.
In writeToMD, lineCount: 54, textOut: And I'm also a researcher at the Versus AI research lab.
And I'm also a researcher at the Versus AI research lab.
before writeToSrt(text: And I'm also a researcher at the Versus AI research lab., srtPosCount: 54, srtSpeaker: , srtStartTime: 111100, srtEndTime: 115872
after writeToSrt(text: And I'm also a researcher at the Versus AI research lab., srtPosCount: 56, srtSpeaker: , srtStartTime: 111100, srtEndTime: 115872
115926
R D lab.
In writeToMD, lineCount: 56, textOut: R D lab.
R D lab.
before writeToSrt(text: R D lab., srtPosCount: 56, srtSpeaker: , srtStartTime: 115926, srtEndTime: 117090
after writeToSrt(text: R D lab., srtPosCount: 57, srtSpeaker: , srtStartTime: 115926, srtEndTime: 117090
117780
So I'm going to do something a little bit, I guess, unconventional for people in my position.
In writeToMD, lineCount: 57, textOut: So I'm going to do something a little bit, I guess, unconventional for people in my position.
So I'm going to do something a little bit, I guess, unconventional for people in my position.
before writeToSrt(text: So I'm going to do something a little bit, I guess, unconventional for people in my position., srtPosCount: 57, srtSpeaker: , srtStartTime: 117780, srtEndTime: 123300
after writeToSrt(text: So I'm going to do something a little bit, I guess, unconventional for people in my position., srtPosCount: 60, srtSpeaker: , srtStartTime: 117780, srtEndTime: 123300
123370
Like, I'm a junior researcher coming to the end of my PhD.
In writeToMD, lineCount: 60, textOut: Like, I'm a junior researcher coming to the end of my PhD.
Like, I'm a junior researcher coming to the end of my PhD.
before writeToSrt(text: Like, I'm a junior researcher coming to the end of my PhD., srtPosCount: 60, srtSpeaker: , srtStartTime: 123370, srtEndTime: 126112
after writeToSrt(text: Like, I'm a junior researcher coming to the end of my PhD., srtPosCount: 62, srtSpeaker: , srtStartTime: 123370, srtEndTime: 126112
126176
So usually when I give a talk, I would present on my own research, like what I've been up to for the last ten years working on.
In writeToMD, lineCount: 62, textOut: So usually when I give a talk, I would present on my own research, like what I've been up to for the last ten years working on.
So usually when I give a talk, I would present on my own research, like what I've been up to for the last ten years working on.
before writeToSrt(text: So usually when I give a talk, I would present on my own research, like what I've been up to for the last ten years working on., srtPosCount: 62, srtSpeaker: , srtStartTime: 126176, srtEndTime: 134648
after writeToSrt(text: So usually when I give a talk, I would present on my own research, like what I've been up to for the last ten years working on., srtPosCount: 66, srtSpeaker: , srtStartTime: 126176, srtEndTime: 134648
134734
But instead of that, I'm actually going to talk about given the motivation of the symposium, I'm going to talk about something that's more of an overview or perspective on the current state of the field in multiscale active inference or multi agent active inference and what, in my opinion, we need to do to move forward as a field.
In writeToMD, lineCount: 66, textOut: But instead of that, I'm actually going to talk about given the motivation of the symposium, I'm going to talk about something that's more of an overview or perspective on the current state of the field in multiscale active inference or multi agent active inference and what, in my opinion, we need to do to move forward as a field.
But instead of that, I'm actually going to talk about given the motivation of the symposium, I'm going to talk about something that's more of an overview or perspective on the current state of the field in multiscale active inference or multi agent active inference and what, in my opinion, we need to do to move forward as a field.
before writeToSrt(text: But instead of that, I'm actually going to talk about given the motivation of the symposium, I'm going to talk about something that's more of an overview or perspective on the current state of the field in multiscale active inference or multi agent active inference and what, in my opinion, we need to do to move forward as a field., srtPosCount: 66, srtSpeaker: , srtStartTime: 134734, srtEndTime: 154764
after writeToSrt(text: But instead of that, I'm actually going to talk about given the motivation of the symposium, I'm going to talk about something that's more of an overview or perspective on the current state of the field in multiscale active inference or multi agent active inference and what, in my opinion, we need to do to move forward as a field., srtPosCount: 75, srtSpeaker: , srtStartTime: 134734, srtEndTime: 154764
154882
02:34 I think that's very resonant with the kind of motivations and the title, indeed, of this symposium.
In writeToMD, lineCount: 75, textOut: I think that's very resonant with the kind of motivations and the title, indeed, of this symposium.
I think that's very resonant with the kind of motivations and the title, indeed, of this symposium.
before writeToSrt(text: I think that's very resonant with the kind of motivations and the title, indeed, of this symposium., srtPosCount: 75, srtSpeaker: , srtStartTime: 154882, srtEndTime: 161852
after writeToSrt(text: I think that's very resonant with the kind of motivations and the title, indeed, of this symposium., srtPosCount: 78, srtSpeaker: , srtStartTime: 154882, srtEndTime: 161852
161996
So I'm going to give a general analysis of what multiscale active inference is, why it's important.
In writeToMD, lineCount: 78, textOut: So I'm going to give a general analysis of what multiscale active inference is, why it's important.
So I'm going to give a general analysis of what multiscale active inference is, why it's important.
before writeToSrt(text: So I'm going to give a general analysis of what multiscale active inference is, why it's important., srtPosCount: 78, srtSpeaker: , srtStartTime: 161996, srtEndTime: 167808
after writeToSrt(text: So I'm going to give a general analysis of what multiscale active inference is, why it's important., srtPosCount: 81, srtSpeaker: , srtStartTime: 161996, srtEndTime: 167808
167974
I'm going to provide a brief analysis of its formal basis as it currently stands, and then what we need to develop in this kind of subdiscipline of active inference, multiscale active inference, to really make it rigorous and really to actually reap the benefits of what it promises.
In writeToMD, lineCount: 81, textOut: I'm going to provide a brief analysis of its formal basis as it currently stands, and then what we need to develop in this kind of subdiscipline of active inference, multiscale active inference, to really make it rigorous and really to actually reap the benefits of what it promises.
I'm going to provide a brief analysis of its formal basis as it currently stands, and then what we need to develop in this kind of subdiscipline of active inference, multiscale active inference, to really make it rigorous and really to actually reap the benefits of what it promises.
before writeToSrt(text: I'm going to provide a brief analysis of its formal basis as it currently stands, and then what we need to develop in this kind of subdiscipline of active inference, multiscale active inference, to really make it rigorous and really to actually reap the benefits of what it promises., srtPosCount: 81, srtSpeaker: , srtStartTime: 167974, srtEndTime: 184760
after writeToSrt(text: I'm going to provide a brief analysis of its formal basis as it currently stands, and then what we need to develop in this kind of subdiscipline of active inference, multiscale active inference, to really make it rigorous and really to actually reap the benefits of what it promises., srtPosCount: 88, srtSpeaker: , srtStartTime: 167974, srtEndTime: 184760
186220
So generally, active inference has been used a lot to design agents that can solve problems, plan, and just generally emulate behavior that we deem intelligent, which includes things like risk sensitive decision making, intrinsic motivations to resolve uncertainty, and finally, from a more scientific standpoint, the ability to furnish a process theory about how biological brains actually might work.
In writeToMD, lineCount: 88, textOut: So generally, active inference has been used a lot to design agents that can solve problems, plan, and just generally emulate behavior that we deem intelligent, which includes things like risk sensitive decision making, intrinsic motivations to resolve uncertainty, and finally, from a more scientific standpoint, the ability to furnish a process theory about how biological brains actually might work.
So generally, active inference has been used a lot to design agents that can solve problems, plan, and just generally emulate behavior that we deem intelligent, which includes things like risk sensitive decision making, intrinsic motivations to resolve uncertainty, and finally, from a more scientific standpoint, the ability to furnish a process theory about how biological brains actually might work.
before writeToSrt(text: So generally, active inference has been used a lot to design agents that can solve problems, plan, and just generally emulate behavior that we deem intelligent, which includes things like risk sensitive decision making, intrinsic motivations to resolve uncertainty, and finally, from a more scientific standpoint, the ability to furnish a process theory about how biological brains actually might work., srtPosCount: 88, srtSpeaker: , srtStartTime: 186220, srtEndTime: 214050
after writeToSrt(text: So generally, active inference has been used a lot to design agents that can solve problems, plan, and just generally emulate behavior that we deem intelligent, which includes things like risk sensitive decision making, intrinsic motivations to resolve uncertainty, and finally, from a more scientific standpoint, the ability to furnish a process theory about how biological brains actually might work., srtPosCount: 99, srtSpeaker: , srtStartTime: 186220, srtEndTime: 214050
215140
03:35 But in a lot of the theoretical work on active inference from the last ten years or ten plus years, really, there's also alongside all the kind of practical building adaptive agents, there's a claim that active inference is inherently or intrinsically multiscale from the very get go.
In writeToMD, lineCount: 99, textOut: But in a lot of the theoretical work on active inference from the last ten years or ten plus years, really, there's also alongside all the kind of practical building adaptive agents, there's a claim that active inference is inherently or intrinsically multiscale from the very get go.
But in a lot of the theoretical work on active inference from the last ten years or ten plus years, really, there's also alongside all the kind of practical building adaptive agents, there's a claim that active inference is inherently or intrinsically multiscale from the very get go.
before writeToSrt(text: But in a lot of the theoretical work on active inference from the last ten years or ten plus years, really, there's also alongside all the kind of practical building adaptive agents, there's a claim that active inference is inherently or intrinsically multiscale from the very get go., srtPosCount: 99, srtSpeaker: , srtStartTime: 215140, srtEndTime: 233348
after writeToSrt(text: But in a lot of the theoretical work on active inference from the last ten years or ten plus years, really, there's also alongside all the kind of practical building adaptive agents, there's a claim that active inference is inherently or intrinsically multiscale from the very get go., srtPosCount: 107, srtSpeaker: , srtStartTime: 215140, srtEndTime: 233348
233434
It is a multiscale framework.
In writeToMD, lineCount: 107, textOut: It is a multiscale framework.
It is a multiscale framework.
before writeToSrt(text: It is a multiscale framework., srtPosCount: 107, srtSpeaker: , srtStartTime: 233434, srtEndTime: 235044
after writeToSrt(text: It is a multiscale framework., srtPosCount: 108, srtSpeaker: , srtStartTime: 233434, srtEndTime: 235044
235092
It's not just about building single agents.
In writeToMD, lineCount: 108, textOut: It's not just about building single agents.
It's not just about building single agents.
before writeToSrt(text: It's not just about building single agents., srtPosCount: 108, srtSpeaker: , srtStartTime: 235092, srtEndTime: 237610
after writeToSrt(text: It's not just about building single agents., srtPosCount: 110, srtSpeaker: , srtStartTime: 235092, srtEndTime: 237610
238380
So it's really whenever we write down a single active inference agent, what we're implicitly implying is also a nested hierarchy of active inference agents both below and above.
In writeToMD, lineCount: 110, textOut: So it's really whenever we write down a single active inference agent, what we're implicitly implying is also a nested hierarchy of active inference agents both below and above.
So it's really whenever we write down a single active inference agent, what we're implicitly implying is also a nested hierarchy of active inference agents both below and above.
before writeToSrt(text: So it's really whenever we write down a single active inference agent, what we're implicitly implying is also a nested hierarchy of active inference agents both below and above., srtPosCount: 110, srtSpeaker: , srtStartTime: 238380, srtEndTime: 249192
after writeToSrt(text: So it's really whenever we write down a single active inference agent, what we're implicitly implying is also a nested hierarchy of active inference agents both below and above., srtPosCount: 115, srtSpeaker: , srtStartTime: 238380, srtEndTime: 249192
249336
So colloquially, you'll often see this in papers as the idea that there's Markov blankets all the way down Markov blanket is a statistical structure that's very kind of intrinsic to the definition of agents as they are defined under active inference.
In writeToMD, lineCount: 115, textOut: So colloquially, you'll often see this in papers as the idea that there's Markov blankets all the way down Markov blanket is a statistical structure that's very kind of intrinsic to the definition of agents as they are defined under active inference.
So colloquially, you'll often see this in papers as the idea that there's Markov blankets all the way down Markov blanket is a statistical structure that's very kind of intrinsic to the definition of agents as they are defined under active inference.
before writeToSrt(text: So colloquially, you'll often see this in papers as the idea that there's Markov blankets all the way down Markov blanket is a statistical structure that's very kind of intrinsic to the definition of agents as they are defined under active inference., srtPosCount: 115, srtSpeaker: , srtStartTime: 249336, srtEndTime: 264028
after writeToSrt(text: So colloquially, you'll often see this in papers as the idea that there's Markov blankets all the way down Markov blanket is a statistical structure that's very kind of intrinsic to the definition of agents as they are defined under active inference., srtPosCount: 122, srtSpeaker: , srtStartTime: 249336, srtEndTime: 264028
264044
So I'm not going to get into defining that.
In writeToMD, lineCount: 122, textOut: So I'm not going to get into defining that.
So I'm not going to get into defining that.
before writeToSrt(text: So I'm not going to get into defining that., srtPosCount: 122, srtSpeaker: , srtStartTime: 264044, srtEndTime: 265904
after writeToSrt(text: So I'm not going to get into defining that., srtPosCount: 124, srtSpeaker: , srtStartTime: 264044, srtEndTime: 265904
266022
I'm kind of assuming that there's a more disciplinarian audience there, but I'm sure other talks, for instance, can provide better clarity.
In writeToMD, lineCount: 124, textOut: I'm kind of assuming that there's a more disciplinarian audience there, but I'm sure other talks, for instance, can provide better clarity.
I'm kind of assuming that there's a more disciplinarian audience there, but I'm sure other talks, for instance, can provide better clarity.
before writeToSrt(text: I'm kind of assuming that there's a more disciplinarian audience there, but I'm sure other talks, for instance, can provide better clarity., srtPosCount: 124, srtSpeaker: , srtStartTime: 266022, srtEndTime: 273004
after writeToSrt(text: I'm kind of assuming that there's a more disciplinarian audience there, but I'm sure other talks, for instance, can provide better clarity., srtPosCount: 128, srtSpeaker: , srtStartTime: 266022, srtEndTime: 273004
273052
So yeah, Markov blanket's active inference all the way down, all the way up.
In writeToMD, lineCount: 128, textOut: So yeah, Markov blanket's active inference all the way down, all the way up.
So yeah, Markov blanket's active inference all the way down, all the way up.
before writeToSrt(text: So yeah, Markov blanket's active inference all the way down, all the way up., srtPosCount: 128, srtSpeaker: , srtStartTime: 273052, srtEndTime: 277428
after writeToSrt(text: So yeah, Markov blanket's active inference all the way down, all the way up., srtPosCount: 131, srtSpeaker: , srtStartTime: 273052, srtEndTime: 277428
277594
04:37 And at any given scale, crucially, the free energy minimizing dynamics, or the active inference dynamics are kind of claimed to be aligned with or parallel to the free energy minimizing gradients at the level below and above.
In writeToMD, lineCount: 131, textOut: And at any given scale, crucially, the free energy minimizing dynamics, or the active inference dynamics are kind of claimed to be aligned with or parallel to the free energy minimizing gradients at the level below and above.
And at any given scale, crucially, the free energy minimizing dynamics, or the active inference dynamics are kind of claimed to be aligned with or parallel to the free energy minimizing gradients at the level below and above.
before writeToSrt(text: And at any given scale, crucially, the free energy minimizing dynamics, or the active inference dynamics are kind of claimed to be aligned with or parallel to the free energy minimizing gradients at the level below and above., srtPosCount: 131, srtSpeaker: , srtStartTime: 277594, srtEndTime: 292100
after writeToSrt(text: And at any given scale, crucially, the free energy minimizing dynamics, or the active inference dynamics are kind of claimed to be aligned with or parallel to the free energy minimizing gradients at the level below and above., srtPosCount: 137, srtSpeaker: , srtStartTime: 277594, srtEndTime: 292100
292260
So the claim is that as agents are doing their thing and doing active inference at one level, it both entails and is constrained by active inference processes of the macro agent that they're participating in.
In writeToMD, lineCount: 137, textOut: So the claim is that as agents are doing their thing and doing active inference at one level, it both entails and is constrained by active inference processes of the macro agent that they're participating in.
So the claim is that as agents are doing their thing and doing active inference at one level, it both entails and is constrained by active inference processes of the macro agent that they're participating in.
before writeToSrt(text: So the claim is that as agents are doing their thing and doing active inference at one level, it both entails and is constrained by active inference processes of the macro agent that they're participating in., srtPosCount: 137, srtSpeaker: , srtStartTime: 292260, srtEndTime: 305756
after writeToSrt(text: So the claim is that as agents are doing their thing and doing active inference at one level, it both entails and is constrained by active inference processes of the macro agent that they're participating in., srtPosCount: 143, srtSpeaker: , srtStartTime: 292260, srtEndTime: 305756
305858
So I'm a cell that's part of a tissue as well as the micro agents that comprise them.
In writeToMD, lineCount: 143, textOut: So I'm a cell that's part of a tissue as well as the micro agents that comprise them.
So I'm a cell that's part of a tissue as well as the micro agents that comprise them.
before writeToSrt(text: So I'm a cell that's part of a tissue as well as the micro agents that comprise them., srtPosCount: 143, srtSpeaker: , srtStartTime: 305858, srtEndTime: 311440
after writeToSrt(text: So I'm a cell that's part of a tissue as well as the micro agents that comprise them., srtPosCount: 146, srtSpeaker: , srtStartTime: 305858, srtEndTime: 311440
311510
I am a free energy minimizing cellular agent comprised of organelles that are also minimizing free energy.
In writeToMD, lineCount: 146, textOut: I am a free energy minimizing cellular agent comprised of organelles that are also minimizing free energy.
I am a free energy minimizing cellular agent comprised of organelles that are also minimizing free energy.
before writeToSrt(text: I am a free energy minimizing cellular agent comprised of organelles that are also minimizing free energy., srtPosCount: 146, srtSpeaker: , srtStartTime: 311510, srtEndTime: 317650
after writeToSrt(text: I am a free energy minimizing cellular agent comprised of organelles that are also minimizing free energy., srtPosCount: 149, srtSpeaker: , srtStartTime: 311510, srtEndTime: 317650
318440
So this kind of constrained neat nested gradient descent on free energy is part of the story of multiscale active inference.
In writeToMD, lineCount: 149, textOut: So this kind of constrained neat nested gradient descent on free energy is part of the story of multiscale active inference.
So this kind of constrained neat nested gradient descent on free energy is part of the story of multiscale active inference.
before writeToSrt(text: So this kind of constrained neat nested gradient descent on free energy is part of the story of multiscale active inference., srtPosCount: 149, srtSpeaker: , srtStartTime: 318440, srtEndTime: 327920
after writeToSrt(text: So this kind of constrained neat nested gradient descent on free energy is part of the story of multiscale active inference., srtPosCount: 153, srtSpeaker: , srtStartTime: 318440, srtEndTime: 327920
328000
And it also crucially, assumes that these dynamics are aligned, correlated cooperative across these different scales.
In writeToMD, lineCount: 153, textOut: And it also crucially, assumes that these dynamics are aligned, correlated cooperative across these different scales.
And it also crucially, assumes that these dynamics are aligned, correlated cooperative across these different scales.
before writeToSrt(text: And it also crucially, assumes that these dynamics are aligned, correlated cooperative across these different scales., srtPosCount: 153, srtSpeaker: , srtStartTime: 328000, srtEndTime: 334372
after writeToSrt(text: And it also crucially, assumes that these dynamics are aligned, correlated cooperative across these different scales., srtPosCount: 157, srtSpeaker: , srtStartTime: 328000, srtEndTime: 334372
334516
So I should mention that there is a formal argument made more recently, I would say in the last five years, about how this is possible.
In writeToMD, lineCount: 157, textOut: So I should mention that there is a formal argument made more recently, I would say in the last five years, about how this is possible.
So I should mention that there is a formal argument made more recently, I would say in the last five years, about how this is possible.
before writeToSrt(text: So I should mention that there is a formal argument made more recently, I would say in the last five years, about how this is possible., srtPosCount: 157, srtSpeaker: , srtStartTime: 334516, srtEndTime: 342484
after writeToSrt(text: So I should mention that there is a formal argument made more recently, I would say in the last five years, about how this is possible., srtPosCount: 161, srtSpeaker: , srtStartTime: 334516, srtEndTime: 342484
342622
05:42 And it relies on an apparatus from statistical physics called the Renormalization group.
In writeToMD, lineCount: 161, textOut: And it relies on an apparatus from statistical physics called the Renormalization group.
And it relies on an apparatus from statistical physics called the Renormalization group.
before writeToSrt(text: And it relies on an apparatus from statistical physics called the Renormalization group., srtPosCount: 161, srtSpeaker: , srtStartTime: 342622, srtEndTime: 347852
after writeToSrt(text: And it relies on an apparatus from statistical physics called the Renormalization group., srtPosCount: 164, srtSpeaker: , srtStartTime: 342622, srtEndTime: 347852
347986
This basically allows you to analytically identify shared symmetries energy and conservation laws at different scales in a given system that's comprised of subsystems and subsystems, so on infinitum.
In writeToMD, lineCount: 164, textOut: This basically allows you to analytically identify shared symmetries energy and conservation laws at different scales in a given system that's comprised of subsystems and subsystems, so on infinitum.
This basically allows you to analytically identify shared symmetries energy and conservation laws at different scales in a given system that's comprised of subsystems and subsystems, so on infinitum.
before writeToSrt(text: This basically allows you to analytically identify shared symmetries energy and conservation laws at different scales in a given system that's comprised of subsystems and subsystems, so on infinitum., srtPosCount: 164, srtSpeaker: , srtStartTime: 347986, srtEndTime: 362188
after writeToSrt(text: This basically allows you to analytically identify shared symmetries energy and conservation laws at different scales in a given system that's comprised of subsystems and subsystems, so on infinitum., srtPosCount: 170, srtSpeaker: , srtStartTime: 347986, srtEndTime: 362188
362284
So there's a formal argument specifically made in a free energy principle for a particular physics monograph in 2019 that applies the renormalization group apparatus to multivariate stochastic differential equations that are kind of the equivalent of agents.
In writeToMD, lineCount: 170, textOut: So there's a formal argument specifically made in a free energy principle for a particular physics monograph in 2019 that applies the renormalization group apparatus to multivariate stochastic differential equations that are kind of the equivalent of agents.
So there's a formal argument specifically made in a free energy principle for a particular physics monograph in 2019 that applies the renormalization group apparatus to multivariate stochastic differential equations that are kind of the equivalent of agents.
before writeToSrt(text: So there's a formal argument specifically made in a free energy principle for a particular physics monograph in 2019 that applies the renormalization group apparatus to multivariate stochastic differential equations that are kind of the equivalent of agents., srtPosCount: 170, srtSpeaker: , srtStartTime: 362284, srtEndTime: 380128
after writeToSrt(text: So there's a formal argument specifically made in a free energy principle for a particular physics monograph in 2019 that applies the renormalization group apparatus to multivariate stochastic differential equations that are kind of the equivalent of agents., srtPosCount: 177, srtSpeaker: , srtStartTime: 362284, srtEndTime: 380128
380314
So you can apply that framework to certain sorts of coupled stochastic differential equations that exhibit Markov blanketed sparse coupling structure.
In writeToMD, lineCount: 177, textOut: So you can apply that framework to certain sorts of coupled stochastic differential equations that exhibit Markov blanketed sparse coupling structure.
So you can apply that framework to certain sorts of coupled stochastic differential equations that exhibit Markov blanketed sparse coupling structure.
before writeToSrt(text: So you can apply that framework to certain sorts of coupled stochastic differential equations that exhibit Markov blanketed sparse coupling structure., srtPosCount: 177, srtSpeaker: , srtStartTime: 380314, srtEndTime: 390628
after writeToSrt(text: So you can apply that framework to certain sorts of coupled stochastic differential equations that exhibit Markov blanketed sparse coupling structure., srtPosCount: 182, srtSpeaker: , srtStartTime: 380314, srtEndTime: 390628
390724
And you can kind of prove analytically that there are going to be nested systems of Markov blankets and that they're all in some sense minimizing three energies at their own scales.
In writeToMD, lineCount: 182, textOut: And you can kind of prove analytically that there are going to be nested systems of Markov blankets and that they're all in some sense minimizing three energies at their own scales.
And you can kind of prove analytically that there are going to be nested systems of Markov blankets and that they're all in some sense minimizing three energies at their own scales.
before writeToSrt(text: And you can kind of prove analytically that there are going to be nested systems of Markov blankets and that they're all in some sense minimizing three energies at their own scales., srtPosCount: 182, srtSpeaker: , srtStartTime: 390724, srtEndTime: 401064
after writeToSrt(text: And you can kind of prove analytically that there are going to be nested systems of Markov blankets and that they're all in some sense minimizing three energies at their own scales., srtPosCount: 187, srtSpeaker: , srtStartTime: 390724, srtEndTime: 401064
401112
So I'll get more into that argument later, but I just want to mention that as I define multiscale active inference that there is a formal argument that's related to it.
In writeToMD, lineCount: 187, textOut: So I'll get more into that argument later, but I just want to mention that as I define multiscale active inference that there is a formal argument that's related to it.
So I'll get more into that argument later, but I just want to mention that as I define multiscale active inference that there is a formal argument that's related to it.
before writeToSrt(text: So I'll get more into that argument later, but I just want to mention that as I define multiscale active inference that there is a formal argument that's related to it., srtPosCount: 187, srtSpeaker: , srtStartTime: 401112, srtEndTime: 411170
after writeToSrt(text: So I'll get more into that argument later, but I just want to mention that as I define multiscale active inference that there is a formal argument that's related to it., srtPosCount: 192, srtSpeaker: , srtStartTime: 401112, srtEndTime: 411170
412180
06:52 So this slide I just put together to demonstrate the idea of nested free energy minimizing processes visually.
In writeToMD, lineCount: 192, textOut: So this slide I just put together to demonstrate the idea of nested free energy minimizing processes visually.
So this slide I just put together to demonstrate the idea of nested free energy minimizing processes visually.
before writeToSrt(text: So this slide I just put together to demonstrate the idea of nested free energy minimizing processes visually., srtPosCount: 192, srtSpeaker: , srtStartTime: 412180, srtEndTime: 418268
after writeToSrt(text: So this slide I just put together to demonstrate the idea of nested free energy minimizing processes visually., srtPosCount: 195, srtSpeaker: , srtStartTime: 412180, srtEndTime: 418268
418364
So at a given scale, we can think of an agent as occupying some point in its free energy landscape indicated by this red orb, which represents, say, its configuration, its beliefs, and its actions.
In writeToMD, lineCount: 195, textOut: So at a given scale, we can think of an agent as occupying some point in its free energy landscape indicated by this red orb, which represents, say, its configuration, its beliefs, and its actions.
So at a given scale, we can think of an agent as occupying some point in its free energy landscape indicated by this red orb, which represents, say, its configuration, its beliefs, and its actions.
before writeToSrt(text: So at a given scale, we can think of an agent as occupying some point in its free energy landscape indicated by this red orb, which represents, say, its configuration, its beliefs, and its actions., srtPosCount: 195, srtSpeaker: , srtStartTime: 418364, srtEndTime: 430752
after writeToSrt(text: So at a given scale, we can think of an agent as occupying some point in its free energy landscape indicated by this red orb, which represents, say, its configuration, its beliefs, and its actions., srtPosCount: 201, srtSpeaker: , srtStartTime: 418364, srtEndTime: 430752
430896
And it performs active inference and in doing so minimizes its free energy.
In writeToMD, lineCount: 201, textOut: And it performs active inference and in doing so minimizes its free energy.
And it performs active inference and in doing so minimizes its free energy.
before writeToSrt(text: And it performs active inference and in doing so minimizes its free energy., srtPosCount: 201, srtSpeaker: , srtStartTime: 430896, srtEndTime: 435272
after writeToSrt(text: And it performs active inference and in doing so minimizes its free energy., srtPosCount: 203, srtSpeaker: , srtStartTime: 430896, srtEndTime: 435272
435326
So it changes the position of that ball on that landscape.
In writeToMD, lineCount: 203, textOut: So it changes the position of that ball on that landscape.
So it changes the position of that ball on that landscape.
before writeToSrt(text: So it changes the position of that ball on that landscape., srtPosCount: 203, srtSpeaker: , srtStartTime: 435326, srtEndTime: 438388
after writeToSrt(text: So it changes the position of that ball on that landscape., srtPosCount: 205, srtSpeaker: , srtStartTime: 435326, srtEndTime: 438388
438484
And that is all we mean when we say active inference.
In writeToMD, lineCount: 205, textOut: And that is all we mean when we say active inference.
And that is all we mean when we say active inference.
before writeToSrt(text: And that is all we mean when we say active inference., srtPosCount: 205, srtSpeaker: , srtStartTime: 438484, srtEndTime: 440788
after writeToSrt(text: And that is all we mean when we say active inference., srtPosCount: 207, srtSpeaker: , srtStartTime: 438484, srtEndTime: 440788
440884
That corresponds to the agent doing inference and doing action and kind of getting to the fixed point of its local free energy landscape.
In writeToMD, lineCount: 207, textOut: That corresponds to the agent doing inference and doing action and kind of getting to the fixed point of its local free energy landscape.
That corresponds to the agent doing inference and doing action and kind of getting to the fixed point of its local free energy landscape.
before writeToSrt(text: That corresponds to the agent doing inference and doing action and kind of getting to the fixed point of its local free energy landscape., srtPosCount: 207, srtSpeaker: , srtStartTime: 440884, srtEndTime: 449560
after writeToSrt(text: That corresponds to the agent doing inference and doing action and kind of getting to the fixed point of its local free energy landscape., srtPosCount: 211, srtSpeaker: , srtStartTime: 440884, srtEndTime: 449560
449720
The multi agent case is simply when we add more of these processes.
In writeToMD, lineCount: 211, textOut: The multi agent case is simply when we add more of these processes.
The multi agent case is simply when we add more of these processes.
before writeToSrt(text: The multi agent case is simply when we add more of these processes., srtPosCount: 211, srtSpeaker: , srtStartTime: 449720, srtEndTime: 453544
after writeToSrt(text: The multi agent case is simply when we add more of these processes., srtPosCount: 213, srtSpeaker: , srtStartTime: 449720, srtEndTime: 453544
453592
So there's other agents usually assumed to be similar agents, and the word similarity, let's put an asterisk on that.
In writeToMD, lineCount: 213, textOut: So there's other agents usually assumed to be similar agents, and the word similarity, let's put an asterisk on that.
So there's other agents usually assumed to be similar agents, and the word similarity, let's put an asterisk on that.
before writeToSrt(text: So there's other agents usually assumed to be similar agents, and the word similarity, let's put an asterisk on that., srtPosCount: 213, srtSpeaker: , srtStartTime: 453592, srtEndTime: 460848
after writeToSrt(text: So there's other agents usually assumed to be similar agents, and the word similarity, let's put an asterisk on that., srtPosCount: 217, srtSpeaker: , srtStartTime: 453592, srtEndTime: 460848
460934
And they're all sitting at different points in their own free energy landscapes.
In writeToMD, lineCount: 217, textOut: And they're all sitting at different points in their own free energy landscapes.
And they're all sitting at different points in their own free energy landscapes.
before writeToSrt(text: And they're all sitting at different points in their own free energy landscapes., srtPosCount: 217, srtSpeaker: , srtStartTime: 460934, srtEndTime: 464880
after writeToSrt(text: And they're all sitting at different points in their own free energy landscapes., srtPosCount: 220, srtSpeaker: , srtStartTime: 460934, srtEndTime: 464880
465540
The position of their local red ball is maybe in a different place.
In writeToMD, lineCount: 220, textOut: The position of their local red ball is maybe in a different place.
The position of their local red ball is maybe in a different place.
before writeToSrt(text: The position of their local red ball is maybe in a different place., srtPosCount: 220, srtSpeaker: , srtStartTime: 465540, srtEndTime: 469270
after writeToSrt(text: The position of their local red ball is maybe in a different place., srtPosCount: 222, srtSpeaker: , srtStartTime: 465540, srtEndTime: 469270
470760
So the claim of multiscale active inference is that as we link these multiple active inference agents together, so they can actually exchange information like observations and actions with each other, what we automatically get is some kind of superagent that is also minimizing variation of free energy and is in some sense an emergent or Supervenient active inference agent.
In writeToMD, lineCount: 222, textOut: So the claim of multiscale active inference is that as we link these multiple active inference agents together, so they can actually exchange information like observations and actions with each other, what we automatically get is some kind of superagent that is also minimizing variation of free energy and is in some sense an emergent or Supervenient active inference agent.
So the claim of multiscale active inference is that as we link these multiple active inference agents together, so they can actually exchange information like observations and actions with each other, what we automatically get is some kind of superagent that is also minimizing variation of free energy and is in some sense an emergent or Supervenient active inference agent.
before writeToSrt(text: So the claim of multiscale active inference is that as we link these multiple active inference agents together, so they can actually exchange information like observations and actions with each other, what we automatically get is some kind of superagent that is also minimizing variation of free energy and is in some sense an emergent or Supervenient active inference agent., srtPosCount: 222, srtSpeaker: , srtStartTime: 470760, srtEndTime: 494232
after writeToSrt(text: So the claim of multiscale active inference is that as we link these multiple active inference agents together, so they can actually exchange information like observations and actions with each other, what we automatically get is some kind of superagent that is also minimizing variation of free energy and is in some sense an emergent or Supervenient active inference agent., srtPosCount: 232, srtSpeaker: , srtStartTime: 470760, srtEndTime: 494232
494366
08:14 And I say the word, we automatically get a superagent with an asterisk because there may be some conditions on that mapping from local to global that have to be elucidated.
In writeToMD, lineCount: 232, textOut: And I say the word, we automatically get a superagent with an asterisk because there may be some conditions on that mapping from local to global that have to be elucidated.
And I say the word, we automatically get a superagent with an asterisk because there may be some conditions on that mapping from local to global that have to be elucidated.
before writeToSrt(text: And I say the word, we automatically get a superagent with an asterisk because there may be some conditions on that mapping from local to global that have to be elucidated., srtPosCount: 232, srtSpeaker: , srtStartTime: 494366, srtEndTime: 505240
after writeToSrt(text: And I say the word, we automatically get a superagent with an asterisk because there may be some conditions on that mapping from local to global that have to be elucidated., srtPosCount: 237, srtSpeaker: , srtStartTime: 494366, srtEndTime: 505240
505400
So we'll come back to that in a bit.
In writeToMD, lineCount: 237, textOut: So we'll come back to that in a bit.
So we'll come back to that in a bit.
before writeToSrt(text: So we'll come back to that in a bit., srtPosCount: 237, srtSpeaker: , srtStartTime: 505400, srtEndTime: 507648
after writeToSrt(text: So we'll come back to that in a bit., srtPosCount: 238, srtSpeaker: , srtStartTime: 505400, srtEndTime: 507648
507814
But in short, I think the definition of multiscale active inference is very eloquently put in this paper by Rafael Kaufman, Pranav Gupta, and Jacob Taylor.
In writeToMD, lineCount: 238, textOut: But in short, I think the definition of multiscale active inference is very eloquently put in this paper by Rafael Kaufman, Pranav Gupta, and Jacob Taylor.
But in short, I think the definition of multiscale active inference is very eloquently put in this paper by Rafael Kaufman, Pranav Gupta, and Jacob Taylor.
before writeToSrt(text: But in short, I think the definition of multiscale active inference is very eloquently put in this paper by Rafael Kaufman, Pranav Gupta, and Jacob Taylor., srtPosCount: 238, srtSpeaker: , srtStartTime: 507814, srtEndTime: 518540
after writeToSrt(text: But in short, I think the definition of multiscale active inference is very eloquently put in this paper by Rafael Kaufman, Pranav Gupta, and Jacob Taylor., srtPosCount: 242, srtSpeaker: , srtStartTime: 507814, srtEndTime: 518540
518620
I think Rafael Kaufman is actually going to be on the panel later.
In writeToMD, lineCount: 242, textOut: I think Rafael Kaufman is actually going to be on the panel later.
I think Rafael Kaufman is actually going to be on the panel later.
before writeToSrt(text: I think Rafael Kaufman is actually going to be on the panel later., srtPosCount: 242, srtSpeaker: , srtStartTime: 518620, srtEndTime: 522516
after writeToSrt(text: I think Rafael Kaufman is actually going to be on the panel later., srtPosCount: 244, srtSpeaker: , srtStartTime: 518620, srtEndTime: 522516
522698
And this line from their paper is a really nice, I think, just summary of what it is.
In writeToMD, lineCount: 244, textOut: And this line from their paper is a really nice, I think, just summary of what it is.
And this line from their paper is a really nice, I think, just summary of what it is.
before writeToSrt(text: And this line from their paper is a really nice, I think, just summary of what it is., srtPosCount: 244, srtSpeaker: , srtStartTime: 522698, srtEndTime: 528580
after writeToSrt(text: And this line from their paper is a really nice, I think, just summary of what it is., srtPosCount: 247, srtSpeaker: , srtStartTime: 522698, srtEndTime: 528580
528730
So I'll just read it out loud.
In writeToMD, lineCount: 247, textOut: So I'll just read it out loud.
So I'll just read it out loud.
before writeToSrt(text: So I'll just read it out loud., srtPosCount: 247, srtSpeaker: , srtStartTime: 528730, srtEndTime: 530448
after writeToSrt(text: So I'll just read it out loud., srtPosCount: 248, srtSpeaker: , srtStartTime: 528730, srtEndTime: 530448
530544
The upshot is that in theory, any active inference agent at one Spaciotemporal scale could be simultaneously composed of nested active inference agents at the scale below and constituent of a larger active inference agent at the scale above it.
In writeToMD, lineCount: 248, textOut: The upshot is that in theory, any active inference agent at one Spaciotemporal scale could be simultaneously composed of nested active inference agents at the scale below and constituent of a larger active inference agent at the scale above it.
The upshot is that in theory, any active inference agent at one Spaciotemporal scale could be simultaneously composed of nested active inference agents at the scale below and constituent of a larger active inference agent at the scale above it.
before writeToSrt(text: The upshot is that in theory, any active inference agent at one Spaciotemporal scale could be simultaneously composed of nested active inference agents at the scale below and constituent of a larger active inference agent at the scale above it., srtPosCount: 248, srtSpeaker: , srtStartTime: 530544, srtEndTime: 544536
after writeToSrt(text: The upshot is that in theory, any active inference agent at one Spaciotemporal scale could be simultaneously composed of nested active inference agents at the scale below and constituent of a larger active inference agent at the scale above it., srtPosCount: 255, srtSpeaker: , srtStartTime: 530544, srtEndTime: 544536
544638
In effect, active inference allows you to pick a composite system or agent A that you want to understand.
In writeToMD, lineCount: 255, textOut: In effect, active inference allows you to pick a composite system or agent A that you want to understand.
In effect, active inference allows you to pick a composite system or agent A that you want to understand.
before writeToSrt(text: In effect, active inference allows you to pick a composite system or agent A that you want to understand., srtPosCount: 255, srtSpeaker: , srtStartTime: 544638, srtEndTime: 550108
after writeToSrt(text: In effect, active inference allows you to pick a composite system or agent A that you want to understand., srtPosCount: 258, srtSpeaker: , srtStartTime: 544638, srtEndTime: 550108
550274
And it will be generally true that both that agent A is an approximate global minimizer of free energy at the scale at which that agent reliably persists, and that agent A is composed of subsystems A, sub I that are approximate local minimizers with free energy.
In writeToMD, lineCount: 258, textOut: And it will be generally true that both that agent A is an approximate global minimizer of free energy at the scale at which that agent reliably persists, and that agent A is composed of subsystems A, sub I that are approximate local minimizers with free energy.
And it will be generally true that both that agent A is an approximate global minimizer of free energy at the scale at which that agent reliably persists, and that agent A is composed of subsystems A, sub I that are approximate local minimizers with free energy.
before writeToSrt(text: And it will be generally true that both that agent A is an approximate global minimizer of free energy at the scale at which that agent reliably persists, and that agent A is composed of subsystems A, sub I that are approximate local minimizers with free energy., srtPosCount: 258, srtSpeaker: , srtStartTime: 550274, srtEndTime: 569316
after writeToSrt(text: And it will be generally true that both that agent A is an approximate global minimizer of free energy at the scale at which that agent reliably persists, and that agent A is composed of subsystems A, sub I that are approximate local minimizers with free energy., srtPosCount: 265, srtSpeaker: , srtStartTime: 550274, srtEndTime: 569316
569418
09:29 So that is the claim as I'm going to continue evaluating in this talk, and I think it's just a great reference point to make, okay, that's what multiscale active inference is.
In writeToMD, lineCount: 265, textOut: So that is the claim as I'm going to continue evaluating in this talk, and I think it's just a great reference point to make, okay, that's what multiscale active inference is.
So that is the claim as I'm going to continue evaluating in this talk, and I think it's just a great reference point to make, okay, that's what multiscale active inference is.
before writeToSrt(text: So that is the claim as I'm going to continue evaluating in this talk, and I think it's just a great reference point to make, okay, that's what multiscale active inference is., srtPosCount: 265, srtSpeaker: , srtStartTime: 569418, srtEndTime: 583396
after writeToSrt(text: So that is the claim as I'm going to continue evaluating in this talk, and I think it's just a great reference point to make, okay, that's what multiscale active inference is., srtPosCount: 270, srtSpeaker: , srtStartTime: 569418, srtEndTime: 583396
583498
Why is it important?
In writeToMD, lineCount: 270, textOut: Why is it important?
Why is it important?
before writeToSrt(text: Why is it important?, srtPosCount: 270, srtSpeaker: , srtStartTime: 583498, srtEndTime: 584504
after writeToSrt(text: Why is it important?, srtPosCount: 271, srtSpeaker: , srtStartTime: 583498, srtEndTime: 584504
584622
Why do we actually care about that?
In writeToMD, lineCount: 271, textOut: Why do we actually care about that?
Why do we actually care about that?
before writeToSrt(text: Why do we actually care about that?, srtPosCount: 271, srtSpeaker: , srtStartTime: 584622, srtEndTime: 586104
after writeToSrt(text: Why do we actually care about that?, srtPosCount: 272, srtSpeaker: , srtStartTime: 584622, srtEndTime: 586104
586142
That sounds philosophically nice and beautiful visually, but why is that important?
In writeToMD, lineCount: 272, textOut: That sounds philosophically nice and beautiful visually, but why is that important?
That sounds philosophically nice and beautiful visually, but why is that important?
before writeToSrt(text: That sounds philosophically nice and beautiful visually, but why is that important?, srtPosCount: 272, srtSpeaker: , srtStartTime: 586142, srtEndTime: 590424
after writeToSrt(text: That sounds philosophically nice and beautiful visually, but why is that important?, srtPosCount: 275, srtSpeaker: , srtStartTime: 586142, srtEndTime: 590424
590542
So there's a ton of actually really important implications of this, both for the engineering and the natural sciences.
In writeToMD, lineCount: 275, textOut: So there's a ton of actually really important implications of this, both for the engineering and the natural sciences.
So there's a ton of actually really important implications of this, both for the engineering and the natural sciences.
before writeToSrt(text: So there's a ton of actually really important implications of this, both for the engineering and the natural sciences., srtPosCount: 275, srtSpeaker: , srtStartTime: 590542, srtEndTime: 596248
after writeToSrt(text: So there's a ton of actually really important implications of this, both for the engineering and the natural sciences., srtPosCount: 279, srtSpeaker: , srtStartTime: 590542, srtEndTime: 596248
596424
First of all, the namesake of this symposium, I assume inspired by this recent paper by Karl Frison and all about enacting ecosystems of parenthetically shared intelligence.
In writeToMD, lineCount: 279, textOut: First of all, the namesake of this symposium, I assume inspired by this recent paper by Karl Frison and all about enacting ecosystems of parenthetically shared intelligence.
First of all, the namesake of this symposium, I assume inspired by this recent paper by Karl Frison and all about enacting ecosystems of parenthetically shared intelligence.
before writeToSrt(text: First of all, the namesake of this symposium, I assume inspired by this recent paper by Karl Frison and all about enacting ecosystems of parenthetically shared intelligence., srtPosCount: 279, srtSpeaker: , srtStartTime: 596424, srtEndTime: 608396
after writeToSrt(text: First of all, the namesake of this symposium, I assume inspired by this recent paper by Karl Frison and all about enacting ecosystems of parenthetically shared intelligence., srtPosCount: 284, srtSpeaker: , srtStartTime: 596424, srtEndTime: 608396
608508
So this is the third applied active inference symposium.
In writeToMD, lineCount: 284, textOut: So this is the third applied active inference symposium.
So this is the third applied active inference symposium.
before writeToSrt(text: So this is the third applied active inference symposium., srtPosCount: 284, srtSpeaker: , srtStartTime: 608508, srtEndTime: 611404
after writeToSrt(text: So this is the third applied active inference symposium., srtPosCount: 286, srtSpeaker: , srtStartTime: 608508, srtEndTime: 611404
611452
So to really make this resonate with the applied aspect, let's make this very concrete.
In writeToMD, lineCount: 286, textOut: So to really make this resonate with the applied aspect, let's make this very concrete.
So to really make this resonate with the applied aspect, let's make this very concrete.
before writeToSrt(text: So to really make this resonate with the applied aspect, let's make this very concrete., srtPosCount: 286, srtSpeaker: , srtStartTime: 611452, srtEndTime: 616684
after writeToSrt(text: So to really make this resonate with the applied aspect, let's make this very concrete., srtPosCount: 289, srtSpeaker: , srtStartTime: 611452, srtEndTime: 616684
616812
If we can figure out this multiscale endeavor, then we can actually engineer distributed systems of multiaging intelligence where local agents, in doing their own little local active inference processes, are also cooperatively instantiating a global agent that's also performing active inference.
In writeToMD, lineCount: 289, textOut: If we can figure out this multiscale endeavor, then we can actually engineer distributed systems of multiaging intelligence where local agents, in doing their own little local active inference processes, are also cooperatively instantiating a global agent that's also performing active inference.
If we can figure out this multiscale endeavor, then we can actually engineer distributed systems of multiaging intelligence where local agents, in doing their own little local active inference processes, are also cooperatively instantiating a global agent that's also performing active inference.
before writeToSrt(text: If we can figure out this multiscale endeavor, then we can actually engineer distributed systems of multiaging intelligence where local agents, in doing their own little local active inference processes, are also cooperatively instantiating a global agent that's also performing active inference., srtPosCount: 289, srtSpeaker: , srtStartTime: 616812, srtEndTime: 634628
after writeToSrt(text: If we can figure out this multiscale endeavor, then we can actually engineer distributed systems of multiaging intelligence where local agents, in doing their own little local active inference processes, are also cooperatively instantiating a global agent that's also performing active inference., srtPosCount: 297, srtSpeaker: , srtStartTime: 616812, srtEndTime: 634628
634724
10:34 This has huge computational potential, of course, compared to kind of the state of the art predominant methods for artificial intelligence, which are deep learning, which really is about propagating global information through an entire computation graph.
In writeToMD, lineCount: 297, textOut: This has huge computational potential, of course, compared to kind of the state of the art predominant methods for artificial intelligence, which are deep learning, which really is about propagating global information through an entire computation graph.
This has huge computational potential, of course, compared to kind of the state of the art predominant methods for artificial intelligence, which are deep learning, which really is about propagating global information through an entire computation graph.
before writeToSrt(text: This has huge computational potential, of course, compared to kind of the state of the art predominant methods for artificial intelligence, which are deep learning, which really is about propagating global information through an entire computation graph., srtPosCount: 297, srtSpeaker: , srtStartTime: 634724, srtEndTime: 650168
after writeToSrt(text: This has huge computational potential, of course, compared to kind of the state of the art predominant methods for artificial intelligence, which are deep learning, which really is about propagating global information through an entire computation graph., srtPosCount: 304, srtSpeaker: , srtStartTime: 634724, srtEndTime: 650168
650264
So although you could argue back propagation is local in some sense, it's really not local in the way that multiscale active inference progresses to be local.
In writeToMD, lineCount: 304, textOut: So although you could argue back propagation is local in some sense, it's really not local in the way that multiscale active inference progresses to be local.
So although you could argue back propagation is local in some sense, it's really not local in the way that multiscale active inference progresses to be local.
before writeToSrt(text: So although you could argue back propagation is local in some sense, it's really not local in the way that multiscale active inference progresses to be local., srtPosCount: 304, srtSpeaker: , srtStartTime: 650264, srtEndTime: 658336
after writeToSrt(text: So although you could argue back propagation is local in some sense, it's really not local in the way that multiscale active inference progresses to be local., srtPosCount: 309, srtSpeaker: , srtStartTime: 650264, srtEndTime: 658336
658438
So if we can figure out how to actually engineer multiscale active inference, it will have really tremendous implications for the study of artificial intelligence just from that pure engineering standpoint.
In writeToMD, lineCount: 309, textOut: So if we can figure out how to actually engineer multiscale active inference, it will have really tremendous implications for the study of artificial intelligence just from that pure engineering standpoint.
So if we can figure out how to actually engineer multiscale active inference, it will have really tremendous implications for the study of artificial intelligence just from that pure engineering standpoint.
before writeToSrt(text: So if we can figure out how to actually engineer multiscale active inference, it will have really tremendous implications for the study of artificial intelligence just from that pure engineering standpoint., srtPosCount: 309, srtSpeaker: , srtStartTime: 658438, srtEndTime: 669300
after writeToSrt(text: So if we can figure out how to actually engineer multiscale active inference, it will have really tremendous implications for the study of artificial intelligence just from that pure engineering standpoint., srtPosCount: 315, srtSpeaker: , srtStartTime: 658438, srtEndTime: 669300
669640
It'll be cheaper.
In writeToMD, lineCount: 315, textOut: It'll be cheaper.
It'll be cheaper.
before writeToSrt(text: It'll be cheaper., srtPosCount: 315, srtSpeaker: , srtStartTime: 669640, srtEndTime: 670896
after writeToSrt(text: It'll be cheaper., srtPosCount: 316, srtSpeaker: , srtStartTime: 669640, srtEndTime: 670896
671008
In one word, it'll be computationally energetically, memory wise.
In writeToMD, lineCount: 316, textOut: In one word, it'll be computationally energetically, memory wise.
In one word, it'll be computationally energetically, memory wise.
before writeToSrt(text: In one word, it'll be computationally energetically, memory wise., srtPosCount: 316, srtSpeaker: , srtStartTime: 671008, srtEndTime: 674320
after writeToSrt(text: In one word, it'll be computationally energetically, memory wise., srtPosCount: 318, srtSpeaker: , srtStartTime: 671008, srtEndTime: 674320
674400
Cheaper.
In writeToMD, lineCount: 318, textOut: Cheaper.
Cheaper.
before writeToSrt(text: Cheaper., srtPosCount: 318, srtSpeaker: , srtStartTime: 674400, srtEndTime: 674864
after writeToSrt(text: Cheaper., srtPosCount: 319, srtSpeaker: , srtStartTime: 674400, srtEndTime: 674864
674912
A lot cheaper.
In writeToMD, lineCount: 319, textOut: A lot cheaper.
A lot cheaper.
before writeToSrt(text: A lot cheaper., srtPosCount: 319, srtSpeaker: , srtStartTime: 674912, srtEndTime: 675940
after writeToSrt(text: A lot cheaper., srtPosCount: 320, srtSpeaker: , srtStartTime: 674912, srtEndTime: 675940
676440
Secondly, from a kind of more natural sciences motivation, which is kind of where I'm coming from, I'm doing a PhD in biology, so I'm interested in questions about actual real systems in nature.
In writeToMD, lineCount: 320, textOut: Secondly, from a kind of more natural sciences motivation, which is kind of where I'm coming from, I'm doing a PhD in biology, so I'm interested in questions about actual real systems in nature.
Secondly, from a kind of more natural sciences motivation, which is kind of where I'm coming from, I'm doing a PhD in biology, so I'm interested in questions about actual real systems in nature.
before writeToSrt(text: Secondly, from a kind of more natural sciences motivation, which is kind of where I'm coming from, I'm doing a PhD in biology, so I'm interested in questions about actual real systems in nature., srtPosCount: 320, srtSpeaker: , srtStartTime: 676440, srtEndTime: 688340
after writeToSrt(text: Secondly, from a kind of more natural sciences motivation, which is kind of where I'm coming from, I'm doing a PhD in biology, so I'm interested in questions about actual real systems in nature., srtPosCount: 325, srtSpeaker: , srtStartTime: 676440, srtEndTime: 688340
688500
Just the idea of being able to get super specific and rigorous about phrases like emergent intelligence, emergent computation, collective intelligence, superorganism that's often thrown around.
In writeToMD, lineCount: 325, textOut: Just the idea of being able to get super specific and rigorous about phrases like emergent intelligence, emergent computation, collective intelligence, superorganism that's often thrown around.
Just the idea of being able to get super specific and rigorous about phrases like emergent intelligence, emergent computation, collective intelligence, superorganism that's often thrown around.
before writeToSrt(text: Just the idea of being able to get super specific and rigorous about phrases like emergent intelligence, emergent computation, collective intelligence, superorganism that's often thrown around., srtPosCount: 325, srtSpeaker: , srtStartTime: 688500, srtEndTime: 699484
after writeToSrt(text: Just the idea of being able to get super specific and rigorous about phrases like emergent intelligence, emergent computation, collective intelligence, superorganism that's often thrown around., srtPosCount: 331, srtSpeaker: , srtStartTime: 688500, srtEndTime: 699484
699522
11:39 We're talking about social insects, right?
In writeToMD, lineCount: 331, textOut: We're talking about social insects, right?
We're talking about social insects, right?
before writeToSrt(text: We're talking about social insects, right?, srtPosCount: 331, srtSpeaker: , srtStartTime: 699522, srtEndTime: 701516
after writeToSrt(text: We're talking about social insects, right?, srtPosCount: 333, srtSpeaker: , srtStartTime: 699522, srtEndTime: 701516
701618
These are terms that you hear thrown around in many different scientific disciplines that deal with multi agent systems, network systems.
In writeToMD, lineCount: 333, textOut: These are terms that you hear thrown around in many different scientific disciplines that deal with multi agent systems, network systems.
These are terms that you hear thrown around in many different scientific disciplines that deal with multi agent systems, network systems.
before writeToSrt(text: These are terms that you hear thrown around in many different scientific disciplines that deal with multi agent systems, network systems., srtPosCount: 333, srtSpeaker: , srtStartTime: 701618, srtEndTime: 709852
after writeToSrt(text: These are terms that you hear thrown around in many different scientific disciplines that deal with multi agent systems, network systems., srtPosCount: 337, srtSpeaker: , srtStartTime: 701618, srtEndTime: 709852
709996
But none of these terms, to my knowledge, have really rigorous or precise conditions.
In writeToMD, lineCount: 337, textOut: But none of these terms, to my knowledge, have really rigorous or precise conditions.
But none of these terms, to my knowledge, have really rigorous or precise conditions.
before writeToSrt(text: But none of these terms, to my knowledge, have really rigorous or precise conditions., srtPosCount: 337, srtSpeaker: , srtStartTime: 709996, srtEndTime: 714796
after writeToSrt(text: But none of these terms, to my knowledge, have really rigorous or precise conditions., srtPosCount: 340, srtSpeaker: , srtStartTime: 709996, srtEndTime: 714796
714908
Multiscale active inference is a kind of framework that's in the position to provide those rigorous definitions and conditions.
In writeToMD, lineCount: 340, textOut: Multiscale active inference is a kind of framework that's in the position to provide those rigorous definitions and conditions.
Multiscale active inference is a kind of framework that's in the position to provide those rigorous definitions and conditions.
before writeToSrt(text: Multiscale active inference is a kind of framework that's in the position to provide those rigorous definitions and conditions., srtPosCount: 340, srtSpeaker: , srtStartTime: 714908, srtEndTime: 721712
after writeToSrt(text: Multiscale active inference is a kind of framework that's in the position to provide those rigorous definitions and conditions., srtPosCount: 344, srtSpeaker: , srtStartTime: 714908, srtEndTime: 721712
721776
So from a scientific standpoint, it could really lend a lot of potential and usefulness for other scientific disciplines.
In writeToMD, lineCount: 344, textOut: So from a scientific standpoint, it could really lend a lot of potential and usefulness for other scientific disciplines.
So from a scientific standpoint, it could really lend a lot of potential and usefulness for other scientific disciplines.
before writeToSrt(text: So from a scientific standpoint, it could really lend a lot of potential and usefulness for other scientific disciplines., srtPosCount: 344, srtSpeaker: , srtStartTime: 721776, srtEndTime: 730396
after writeToSrt(text: So from a scientific standpoint, it could really lend a lot of potential and usefulness for other scientific disciplines., srtPosCount: 348, srtSpeaker: , srtStartTime: 721776, srtEndTime: 730396
730528
And finally, another pragmatic motivation.
In writeToMD, lineCount: 348, textOut: And finally, another pragmatic motivation.
And finally, another pragmatic motivation.
before writeToSrt(text: And finally, another pragmatic motivation., srtPosCount: 348, srtSpeaker: , srtStartTime: 730528, srtEndTime: 732788
after writeToSrt(text: And finally, another pragmatic motivation., srtPosCount: 350, srtSpeaker: , srtStartTime: 730528, srtEndTime: 732788
732884
There's loads of fields that are obsessed with designing and engineering systems where local, selfish individual behavior can lead when networked appropriately to some desired collective outcome.
In writeToMD, lineCount: 350, textOut: There's loads of fields that are obsessed with designing and engineering systems where local, selfish individual behavior can lead when networked appropriately to some desired collective outcome.
There's loads of fields that are obsessed with designing and engineering systems where local, selfish individual behavior can lead when networked appropriately to some desired collective outcome.
before writeToSrt(text: There's loads of fields that are obsessed with designing and engineering systems where local, selfish individual behavior can lead when networked appropriately to some desired collective outcome., srtPosCount: 350, srtSpeaker: , srtStartTime: 732884, srtEndTime: 745940
after writeToSrt(text: There's loads of fields that are obsessed with designing and engineering systems where local, selfish individual behavior can lead when networked appropriately to some desired collective outcome., srtPosCount: 355, srtSpeaker: , srtStartTime: 732884, srtEndTime: 745940
746020
And these disciplines really want to figure out how to engineer that properly.
In writeToMD, lineCount: 355, textOut: And these disciplines really want to figure out how to engineer that properly.
And these disciplines really want to figure out how to engineer that properly.
before writeToSrt(text: And these disciplines really want to figure out how to engineer that properly., srtPosCount: 355, srtSpeaker: , srtStartTime: 746020, srtEndTime: 749480
after writeToSrt(text: And these disciplines really want to figure out how to engineer that properly., srtPosCount: 358, srtSpeaker: , srtStartTime: 746020, srtEndTime: 749480
749560
So this goes from the design of financial markets and trading systems all the way down to how do you design a multiplayer video game?
In writeToMD, lineCount: 358, textOut: So this goes from the design of financial markets and trading systems all the way down to how do you design a multiplayer video game?
So this goes from the design of financial markets and trading systems all the way down to how do you design a multiplayer video game?
before writeToSrt(text: So this goes from the design of financial markets and trading systems all the way down to how do you design a multiplayer video game?, srtPosCount: 358, srtSpeaker: , srtStartTime: 749560, srtEndTime: 757170
after writeToSrt(text: So this goes from the design of financial markets and trading systems all the way down to how do you design a multiplayer video game?, srtPosCount: 362, srtSpeaker: , srtStartTime: 749560, srtEndTime: 757170
758100
So that's kind of just motivating.
In writeToMD, lineCount: 362, textOut: So that's kind of just motivating.
So that's kind of just motivating.
before writeToSrt(text: So that's kind of just motivating., srtPosCount: 362, srtSpeaker: , srtStartTime: 758100, srtEndTime: 760364
after writeToSrt(text: So that's kind of just motivating., srtPosCount: 363, srtSpeaker: , srtStartTime: 758100, srtEndTime: 760364
760412
12:40 Why is multiscale active inference even interesting?
In writeToMD, lineCount: 363, textOut: Why is multiscale active inference even interesting?
Why is multiscale active inference even interesting?
before writeToSrt(text: Why is multiscale active inference even interesting?, srtPosCount: 363, srtSpeaker: , srtStartTime: 760412, srtEndTime: 763010
after writeToSrt(text: Why is multiscale active inference even interesting?, srtPosCount: 365, srtSpeaker: , srtStartTime: 760412, srtEndTime: 763010
763460
So then the question, of course, becomes, is the multiscale active inference claim actually true?
In writeToMD, lineCount: 365, textOut: So then the question, of course, becomes, is the multiscale active inference claim actually true?
So then the question, of course, becomes, is the multiscale active inference claim actually true?
before writeToSrt(text: So then the question, of course, becomes, is the multiscale active inference claim actually true?, srtPosCount: 365, srtSpeaker: , srtStartTime: 763460, srtEndTime: 768436
after writeToSrt(text: So then the question, of course, becomes, is the multiscale active inference claim actually true?, srtPosCount: 368, srtSpeaker: , srtStartTime: 763460, srtEndTime: 768436
768538
Are all multi agent active inference systems comprised of and themselves comprise nested hierarchy of free energy minimization agents?
In writeToMD, lineCount: 368, textOut: Are all multi agent active inference systems comprised of and themselves comprise nested hierarchy of free energy minimization agents?
Are all multi agent active inference systems comprised of and themselves comprise nested hierarchy of free energy minimization agents?
before writeToSrt(text: Are all multi agent active inference systems comprised of and themselves comprise nested hierarchy of free energy minimization agents?, srtPosCount: 368, srtSpeaker: , srtStartTime: 768538, srtEndTime: 776950
after writeToSrt(text: Are all multi agent active inference systems comprised of and themselves comprise nested hierarchy of free energy minimization agents?, srtPosCount: 372, srtSpeaker: , srtStartTime: 768538, srtEndTime: 776950
777320
A glance at a smattering of other scientific disciplines that specifically deal with multiple agents, multiple interests, collective phenomena like coordination, group behavior, collective intelligence.
In writeToMD, lineCount: 372, textOut: A glance at a smattering of other scientific disciplines that specifically deal with multiple agents, multiple interests, collective phenomena like coordination, group behavior, collective intelligence.
A glance at a smattering of other scientific disciplines that specifically deal with multiple agents, multiple interests, collective phenomena like coordination, group behavior, collective intelligence.
before writeToSrt(text: A glance at a smattering of other scientific disciplines that specifically deal with multiple agents, multiple interests, collective phenomena like coordination, group behavior, collective intelligence., srtPosCount: 372, srtSpeaker: , srtStartTime: 777320, srtEndTime: 789028
after writeToSrt(text: A glance at a smattering of other scientific disciplines that specifically deal with multiple agents, multiple interests, collective phenomena like coordination, group behavior, collective intelligence., srtPosCount: 378, srtSpeaker: , srtStartTime: 777320, srtEndTime: 789028
789204
A glance at all those disciplines would naively suggest that the answer is no.
In writeToMD, lineCount: 378, textOut: A glance at all those disciplines would naively suggest that the answer is no.
A glance at all those disciplines would naively suggest that the answer is no.
before writeToSrt(text: A glance at all those disciplines would naively suggest that the answer is no., srtPosCount: 378, srtSpeaker: , srtStartTime: 789204, srtEndTime: 792988
after writeToSrt(text: A glance at all those disciplines would naively suggest that the answer is no., srtPosCount: 380, srtSpeaker: , srtStartTime: 789204, srtEndTime: 792988
793074
So there's things like frustration in thermodynamic systems game theory, the very existence of zero sum games and mass equilibria bandwagon effects when we're talking about social networks and opinion dynamics.
In writeToMD, lineCount: 380, textOut: So there's things like frustration in thermodynamic systems game theory, the very existence of zero sum games and mass equilibria bandwagon effects when we're talking about social networks and opinion dynamics.
So there's things like frustration in thermodynamic systems game theory, the very existence of zero sum games and mass equilibria bandwagon effects when we're talking about social networks and opinion dynamics.
before writeToSrt(text: So there's things like frustration in thermodynamic systems game theory, the very existence of zero sum games and mass equilibria bandwagon effects when we're talking about social networks and opinion dynamics., srtPosCount: 380, srtSpeaker: , srtStartTime: 793074, srtEndTime: 807200
after writeToSrt(text: So there's things like frustration in thermodynamic systems game theory, the very existence of zero sum games and mass equilibria bandwagon effects when we're talking about social networks and opinion dynamics., srtPosCount: 386, srtSpeaker: , srtStartTime: 793074, srtEndTime: 807200
807780
Sacrifices for the common good, which we see in different contexts in biology, like in the context of kin selection, but also in the context of arguably cell death in a tissue.
In writeToMD, lineCount: 386, textOut: Sacrifices for the common good, which we see in different contexts in biology, like in the context of kin selection, but also in the context of arguably cell death in a tissue.
Sacrifices for the common good, which we see in different contexts in biology, like in the context of kin selection, but also in the context of arguably cell death in a tissue.
before writeToSrt(text: Sacrifices for the common good, which we see in different contexts in biology, like in the context of kin selection, but also in the context of arguably cell death in a tissue., srtPosCount: 386, srtSpeaker: , srtStartTime: 807780, srtEndTime: 818480
after writeToSrt(text: Sacrifices for the common good, which we see in different contexts in biology, like in the context of kin selection, but also in the context of arguably cell death in a tissue., srtPosCount: 391, srtSpeaker: , srtStartTime: 807780, srtEndTime: 818480
819300
These are all basically plenty of systems where local constraints and global constraints or desires or free energy gradients, whatever you want to call them, come into direct conflict.
In writeToMD, lineCount: 391, textOut: These are all basically plenty of systems where local constraints and global constraints or desires or free energy gradients, whatever you want to call them, come into direct conflict.
These are all basically plenty of systems where local constraints and global constraints or desires or free energy gradients, whatever you want to call them, come into direct conflict.
before writeToSrt(text: These are all basically plenty of systems where local constraints and global constraints or desires or free energy gradients, whatever you want to call them, come into direct conflict., srtPosCount: 391, srtSpeaker: , srtStartTime: 819300, srtEndTime: 828752
after writeToSrt(text: These are all basically plenty of systems where local constraints and global constraints or desires or free energy gradients, whatever you want to call them, come into direct conflict., srtPosCount: 396, srtSpeaker: , srtStartTime: 819300, srtEndTime: 828752
828896
13:48 So the obvious example that I listed at the top of these bullets is the idea of geometric frustration that we see in Icing systems with very low temperature.
In writeToMD, lineCount: 396, textOut: So the obvious example that I listed at the top of these bullets is the idea of geometric frustration that we see in Icing systems with very low temperature.
So the obvious example that I listed at the top of these bullets is the idea of geometric frustration that we see in Icing systems with very low temperature.
before writeToSrt(text: So the obvious example that I listed at the top of these bullets is the idea of geometric frustration that we see in Icing systems with very low temperature., srtPosCount: 396, srtSpeaker: , srtStartTime: 828896, srtEndTime: 838356
after writeToSrt(text: So the obvious example that I listed at the top of these bullets is the idea of geometric frustration that we see in Icing systems with very low temperature., srtPosCount: 400, srtSpeaker: , srtStartTime: 828896, srtEndTime: 838356
838468
So these Icing models basically describe lattices of Ferromagnets that are happy when they're pointing in the same direction as their neighboring Ferromagnets and they can be in an up or a down state.
In writeToMD, lineCount: 400, textOut: So these Icing models basically describe lattices of Ferromagnets that are happy when they're pointing in the same direction as their neighboring Ferromagnets and they can be in an up or a down state.
So these Icing models basically describe lattices of Ferromagnets that are happy when they're pointing in the same direction as their neighboring Ferromagnets and they can be in an up or a down state.
before writeToSrt(text: So these Icing models basically describe lattices of Ferromagnets that are happy when they're pointing in the same direction as their neighboring Ferromagnets and they can be in an up or a down state., srtPosCount: 400, srtSpeaker: , srtStartTime: 838468, srtEndTime: 849372
after writeToSrt(text: So these Icing models basically describe lattices of Ferromagnets that are happy when they're pointing in the same direction as their neighboring Ferromagnets and they can be in an up or a down state., srtPosCount: 406, srtSpeaker: , srtStartTime: 838468, srtEndTime: 849372
849506
So basically the magnet can be pointing up or pointing down.
In writeToMD, lineCount: 406, textOut: So basically the magnet can be pointing up or pointing down.
So basically the magnet can be pointing up or pointing down.
before writeToSrt(text: So basically the magnet can be pointing up or pointing down., srtPosCount: 406, srtSpeaker: , srtStartTime: 849506, srtEndTime: 853068
after writeToSrt(text: So basically the magnet can be pointing up or pointing down., srtPosCount: 408, srtSpeaker: , srtStartTime: 849506, srtEndTime: 853068
853154
And these global systems are defined by a global energy function and the whole system is in some sense trying to minimize that global energy function.
In writeToMD, lineCount: 408, textOut: And these global systems are defined by a global energy function and the whole system is in some sense trying to minimize that global energy function.
And these global systems are defined by a global energy function and the whole system is in some sense trying to minimize that global energy function.
before writeToSrt(text: And these global systems are defined by a global energy function and the whole system is in some sense trying to minimize that global energy function., srtPosCount: 408, srtSpeaker: , srtStartTime: 853154, srtEndTime: 860880
after writeToSrt(text: And these global systems are defined by a global energy function and the whole system is in some sense trying to minimize that global energy function., srtPosCount: 412, srtSpeaker: , srtStartTime: 853154, srtEndTime: 860880
861030
But sometimes you'll find cases in these collective systems where this little spin in the middle cannot be happy because they're getting conflicting information from two neighbors.
In writeToMD, lineCount: 412, textOut: But sometimes you'll find cases in these collective systems where this little spin in the middle cannot be happy because they're getting conflicting information from two neighbors.
But sometimes you'll find cases in these collective systems where this little spin in the middle cannot be happy because they're getting conflicting information from two neighbors.
before writeToSrt(text: But sometimes you'll find cases in these collective systems where this little spin in the middle cannot be happy because they're getting conflicting information from two neighbors., srtPosCount: 412, srtSpeaker: , srtStartTime: 861030, srtEndTime: 869804
after writeToSrt(text: But sometimes you'll find cases in these collective systems where this little spin in the middle cannot be happy because they're getting conflicting information from two neighbors., srtPosCount: 417, srtSpeaker: , srtStartTime: 861030, srtEndTime: 869804
869852
I want to be pointing up in blue like the agent on the left, but I also want to be pointing down like the agent on the right.
In writeToMD, lineCount: 417, textOut: I want to be pointing up in blue like the agent on the left, but I also want to be pointing down like the agent on the right.
I want to be pointing up in blue like the agent on the left, but I also want to be pointing down like the agent on the right.
before writeToSrt(text: I want to be pointing up in blue like the agent on the left, but I also want to be pointing down like the agent on the right., srtPosCount: 417, srtSpeaker: , srtStartTime: 869852, srtEndTime: 876676
after writeToSrt(text: I want to be pointing up in blue like the agent on the left, but I also want to be pointing down like the agent on the right., srtPosCount: 421, srtSpeaker: , srtStartTime: 869852, srtEndTime: 876676
876778
So this is a system that's collectively finding some fixed point of its global free energy, but it's actually leading to a local conflict where this agent is not at a point where it can do anything to make itself happy or minimize its free energy further.
In writeToMD, lineCount: 421, textOut: So this is a system that's collectively finding some fixed point of its global free energy, but it's actually leading to a local conflict where this agent is not at a point where it can do anything to make itself happy or minimize its free energy further.
So this is a system that's collectively finding some fixed point of its global free energy, but it's actually leading to a local conflict where this agent is not at a point where it can do anything to make itself happy or minimize its free energy further.
before writeToSrt(text: So this is a system that's collectively finding some fixed point of its global free energy, but it's actually leading to a local conflict where this agent is not at a point where it can do anything to make itself happy or minimize its free energy further., srtPosCount: 421, srtSpeaker: , srtStartTime: 876778, srtEndTime: 891108
after writeToSrt(text: So this is a system that's collectively finding some fixed point of its global free energy, but it's actually leading to a local conflict where this agent is not at a point where it can do anything to make itself happy or minimize its free energy further., srtPosCount: 428, srtSpeaker: , srtStartTime: 876778, srtEndTime: 891108
891204
14:51 So just from even the basic glance at Ferromagnetic lattices, we already see instances where local and global gradients or local and global optima are not aligned in the right way.
In writeToMD, lineCount: 428, textOut: So just from even the basic glance at Ferromagnetic lattices, we already see instances where local and global gradients or local and global optima are not aligned in the right way.
So just from even the basic glance at Ferromagnetic lattices, we already see instances where local and global gradients or local and global optima are not aligned in the right way.
before writeToSrt(text: So just from even the basic glance at Ferromagnetic lattices, we already see instances where local and global gradients or local and global optima are not aligned in the right way., srtPosCount: 428, srtSpeaker: , srtStartTime: 891204, srtEndTime: 905150
after writeToSrt(text: So just from even the basic glance at Ferromagnetic lattices, we already see instances where local and global gradients or local and global optima are not aligned in the right way., srtPosCount: 433, srtSpeaker: , srtStartTime: 891204, srtEndTime: 905150
905600
So given all this, the burden of proof for multiscale active inference is still on us.
In writeToMD, lineCount: 433, textOut: So given all this, the burden of proof for multiscale active inference is still on us.
So given all this, the burden of proof for multiscale active inference is still on us.
before writeToSrt(text: So given all this, the burden of proof for multiscale active inference is still on us., srtPosCount: 433, srtSpeaker: , srtStartTime: 905600, srtEndTime: 910656
after writeToSrt(text: So given all this, the burden of proof for multiscale active inference is still on us., srtPosCount: 436, srtSpeaker: , srtStartTime: 905600, srtEndTime: 910656
910678
So we need to show that collective active inference systems generically do align again across scales.
In writeToMD, lineCount: 436, textOut: So we need to show that collective active inference systems generically do align again across scales.
So we need to show that collective active inference systems generically do align again across scales.
before writeToSrt(text: So we need to show that collective active inference systems generically do align again across scales., srtPosCount: 436, srtSpeaker: , srtStartTime: 910678, srtEndTime: 917260
after writeToSrt(text: So we need to show that collective active inference systems generically do align again across scales., srtPosCount: 439, srtSpeaker: , srtStartTime: 910678, srtEndTime: 917260
917340
And maybe if we can put an X across the word generically and it's not some automatic condition, if they don't, then at least we have to establish exactly the conditions in which they do.
In writeToMD, lineCount: 439, textOut: And maybe if we can put an X across the word generically and it's not some automatic condition, if they don't, then at least we have to establish exactly the conditions in which they do.
And maybe if we can put an X across the word generically and it's not some automatic condition, if they don't, then at least we have to establish exactly the conditions in which they do.
before writeToSrt(text: And maybe if we can put an X across the word generically and it's not some automatic condition, if they don't, then at least we have to establish exactly the conditions in which they do., srtPosCount: 439, srtSpeaker: , srtStartTime: 917340, srtEndTime: 928470
after writeToSrt(text: And maybe if we can put an X across the word generically and it's not some automatic condition, if they don't, then at least we have to establish exactly the conditions in which they do., srtPosCount: 444, srtSpeaker: , srtStartTime: 917340, srtEndTime: 928470
930140
So anecdotally we do actually have some conditions.
In writeToMD, lineCount: 444, textOut: So anecdotally we do actually have some conditions.
So anecdotally we do actually have some conditions.
before writeToSrt(text: So anecdotally we do actually have some conditions., srtPosCount: 444, srtSpeaker: , srtStartTime: 930140, srtEndTime: 934040
after writeToSrt(text: So anecdotally we do actually have some conditions., srtPosCount: 446, srtSpeaker: , srtStartTime: 930140, srtEndTime: 934040
934460
There seem to be some kind of basic ingredients to get collective active inference to work.
In writeToMD, lineCount: 446, textOut: There seem to be some kind of basic ingredients to get collective active inference to work.
There seem to be some kind of basic ingredients to get collective active inference to work.
before writeToSrt(text: There seem to be some kind of basic ingredients to get collective active inference to work., srtPosCount: 446, srtSpeaker: , srtStartTime: 934460, srtEndTime: 940632
after writeToSrt(text: There seem to be some kind of basic ingredients to get collective active inference to work., srtPosCount: 449, srtSpeaker: , srtStartTime: 934460, srtEndTime: 940632
940766
So one is that we basically need agents to exchange actions and sensations across some kind of Markov blanket.
In writeToMD, lineCount: 449, textOut: So one is that we basically need agents to exchange actions and sensations across some kind of Markov blanket.
So one is that we basically need agents to exchange actions and sensations across some kind of Markov blanket.
before writeToSrt(text: So one is that we basically need agents to exchange actions and sensations across some kind of Markov blanket., srtPosCount: 449, srtSpeaker: , srtStartTime: 940766, srtEndTime: 947544
after writeToSrt(text: So one is that we basically need agents to exchange actions and sensations across some kind of Markov blanket., srtPosCount: 452, srtSpeaker: , srtStartTime: 940766, srtEndTime: 947544
947672
This is not really a condition.
In writeToMD, lineCount: 452, textOut: This is not really a condition.
This is not really a condition.
before writeToSrt(text: This is not really a condition., srtPosCount: 452, srtSpeaker: , srtStartTime: 947672, srtEndTime: 949224
after writeToSrt(text: This is not really a condition., srtPosCount: 453, srtSpeaker: , srtStartTime: 947672, srtEndTime: 949224
949272
This is almost more part of what it means to be an agent.
In writeToMD, lineCount: 453, textOut: This is almost more part of what it means to be an agent.
This is almost more part of what it means to be an agent.
before writeToSrt(text: This is almost more part of what it means to be an agent., srtPosCount: 453, srtSpeaker: , srtStartTime: 949272, srtEndTime: 952220
after writeToSrt(text: This is almost more part of what it means to be an agent., srtPosCount: 455, srtSpeaker: , srtStartTime: 949272, srtEndTime: 952220
952370
15:52 So having Markov blanket separation between agents is just another way of saying we have multiple agents in our system rather than a single agent if you're violating the Markov blanket property.
In writeToMD, lineCount: 455, textOut: So having Markov blanket separation between agents is just another way of saying we have multiple agents in our system rather than a single agent if you're violating the Markov blanket property.
So having Markov blanket separation between agents is just another way of saying we have multiple agents in our system rather than a single agent if you're violating the Markov blanket property.
before writeToSrt(text: So having Markov blanket separation between agents is just another way of saying we have multiple agents in our system rather than a single agent if you're violating the Markov blanket property., srtPosCount: 455, srtSpeaker: , srtStartTime: 952370, srtEndTime: 963184
after writeToSrt(text: So having Markov blanket separation between agents is just another way of saying we have multiple agents in our system rather than a single agent if you're violating the Markov blanket property., srtPosCount: 461, srtSpeaker: , srtStartTime: 952370, srtEndTime: 963184
963302
So internal states of one agent are not allowed to see the internal states or external states of another agent.
In writeToMD, lineCount: 461, textOut: So internal states of one agent are not allowed to see the internal states or external states of another agent.
So internal states of one agent are not allowed to see the internal states or external states of another agent.
before writeToSrt(text: So internal states of one agent are not allowed to see the internal states or external states of another agent., srtPosCount: 461, srtSpeaker: , srtStartTime: 963302, srtEndTime: 969904
after writeToSrt(text: So internal states of one agent are not allowed to see the internal states or external states of another agent., srtPosCount: 464, srtSpeaker: , srtStartTime: 963302, srtEndTime: 969904
970022
Then you're kind of cheating because you're kind of saying it's actually one agent.
In writeToMD, lineCount: 464, textOut: Then you're kind of cheating because you're kind of saying it's actually one agent.
Then you're kind of cheating because you're kind of saying it's actually one agent.
before writeToSrt(text: Then you're kind of cheating because you're kind of saying it's actually one agent., srtPosCount: 464, srtSpeaker: , srtStartTime: 970022, srtEndTime: 973188
after writeToSrt(text: Then you're kind of cheating because you're kind of saying it's actually one agent., srtPosCount: 467, srtSpeaker: , srtStartTime: 970022, srtEndTime: 973188
973274
And what you're doing is information sharing within the brain of a single agent.
In writeToMD, lineCount: 467, textOut: And what you're doing is information sharing within the brain of a single agent.
And what you're doing is information sharing within the brain of a single agent.
before writeToSrt(text: And what you're doing is information sharing within the brain of a single agent., srtPosCount: 467, srtSpeaker: , srtStartTime: 973274, srtEndTime: 977476
after writeToSrt(text: And what you're doing is information sharing within the brain of a single agent., srtPosCount: 470, srtSpeaker: , srtStartTime: 973274, srtEndTime: 977476
977658
The second condition, which is something that's often hallucinated more anecdotally and not really formally, is this idea that agents need to have some kind of shared narrative or shared hidden states or censor space in their generative model.
In writeToMD, lineCount: 470, textOut: The second condition, which is something that's often hallucinated more anecdotally and not really formally, is this idea that agents need to have some kind of shared narrative or shared hidden states or censor space in their generative model.
The second condition, which is something that's often hallucinated more anecdotally and not really formally, is this idea that agents need to have some kind of shared narrative or shared hidden states or censor space in their generative model.
before writeToSrt(text: The second condition, which is something that's often hallucinated more anecdotally and not really formally, is this idea that agents need to have some kind of shared narrative or shared hidden states or censor space in their generative model., srtPosCount: 470, srtSpeaker: , srtStartTime: 977658, srtEndTime: 990120
after writeToSrt(text: The second condition, which is something that's often hallucinated more anecdotally and not really formally, is this idea that agents need to have some kind of shared narrative or shared hidden states or censor space in their generative model., srtPosCount: 477, srtSpeaker: , srtStartTime: 977658, srtEndTime: 990120
990270
So I've worked a lot on collective active inference systems, just simulating agents and trying to get them to do interesting things together.
In writeToMD, lineCount: 477, textOut: So I've worked a lot on collective active inference systems, just simulating agents and trying to get them to do interesting things together.
So I've worked a lot on collective active inference systems, just simulating agents and trying to get them to do interesting things together.
before writeToSrt(text: So I've worked a lot on collective active inference systems, just simulating agents and trying to get them to do interesting things together., srtPosCount: 477, srtSpeaker: , srtStartTime: 990270, srtEndTime: 998764
after writeToSrt(text: So I've worked a lot on collective active inference systems, just simulating agents and trying to get them to do interesting things together., srtPosCount: 481, srtSpeaker: , srtStartTime: 990270, srtEndTime: 998764
998882
And my intuitions and experience do agree with this basic fact.
In writeToMD, lineCount: 481, textOut: And my intuitions and experience do agree with this basic fact.
And my intuitions and experience do agree with this basic fact.
before writeToSrt(text: And my intuitions and experience do agree with this basic fact., srtPosCount: 481, srtSpeaker: , srtStartTime: 998882, srtEndTime: 1002556
after writeToSrt(text: And my intuitions and experience do agree with this basic fact., srtPosCount: 483, srtSpeaker: , srtStartTime: 998882, srtEndTime: 1002556
1002658
If the agents don't have any similarity in what they're representing or trying to achieve, then it's kind of like trying to fit a square peg into a circular hole.
In writeToMD, lineCount: 483, textOut: If the agents don't have any similarity in what they're representing or trying to achieve, then it's kind of like trying to fit a square peg into a circular hole.
If the agents don't have any similarity in what they're representing or trying to achieve, then it's kind of like trying to fit a square peg into a circular hole.
before writeToSrt(text: If the agents don't have any similarity in what they're representing or trying to achieve, then it's kind of like trying to fit a square peg into a circular hole., srtPosCount: 483, srtSpeaker: , srtStartTime: 1002658, srtEndTime: 1011180
after writeToSrt(text: If the agents don't have any similarity in what they're representing or trying to achieve, then it's kind of like trying to fit a square peg into a circular hole., srtPosCount: 487, srtSpeaker: , srtStartTime: 1002658, srtEndTime: 1011180
1011260
So this is really nicely elucidated in one of the earliest cases in this paper, a Duet for One by first and Fritz in 2015, where they show that for two agents to really align, they kind of have to have a shared generative model and then you can get kind of this nice synchronized behavior.
In writeToMD, lineCount: 487, textOut: So this is really nicely elucidated in one of the earliest cases in this paper, a Duet for One by first and Fritz in 2015, where they show that for two agents to really align, they kind of have to have a shared generative model and then you can get kind of this nice synchronized behavior.
So this is really nicely elucidated in one of the earliest cases in this paper, a Duet for One by first and Fritz in 2015, where they show that for two agents to really align, they kind of have to have a shared generative model and then you can get kind of this nice synchronized behavior.
before writeToSrt(text: So this is really nicely elucidated in one of the earliest cases in this paper, a Duet for One by first and Fritz in 2015, where they show that for two agents to really align, they kind of have to have a shared generative model and then you can get kind of this nice synchronized behavior., srtPosCount: 487, srtSpeaker: , srtStartTime: 1011260, srtEndTime: 1027860
after writeToSrt(text: So this is really nicely elucidated in one of the earliest cases in this paper, a Duet for One by first and Fritz in 2015, where they show that for two agents to really align, they kind of have to have a shared generative model and then you can get kind of this nice synchronized behavior., srtPosCount: 495, srtSpeaker: , srtStartTime: 1011260, srtEndTime: 1027860
1028280
17:08 Again, though, these things like what does similarity mean?
In writeToMD, lineCount: 495, textOut: Again, though, these things like what does similarity mean?
Again, though, these things like what does similarity mean?
before writeToSrt(text: Again, though, these things like what does similarity mean?, srtPosCount: 495, srtSpeaker: , srtStartTime: 1028280, srtEndTime: 1031284
after writeToSrt(text: Again, though, these things like what does similarity mean?, srtPosCount: 497, srtSpeaker: , srtStartTime: 1028280, srtEndTime: 1031284
1031322
What does a shared narrative actually mean?
In writeToMD, lineCount: 497, textOut: What does a shared narrative actually mean?
What does a shared narrative actually mean?
before writeToSrt(text: What does a shared narrative actually mean?, srtPosCount: 497, srtSpeaker: , srtStartTime: 1031322, srtEndTime: 1033136
after writeToSrt(text: What does a shared narrative actually mean?, srtPosCount: 499, srtSpeaker: , srtStartTime: 1031322, srtEndTime: 1033136
1033178
Formally, mathematically, those things have not been initiated yet.
In writeToMD, lineCount: 499, textOut: Formally, mathematically, those things have not been initiated yet.
Formally, mathematically, those things have not been initiated yet.
before writeToSrt(text: Formally, mathematically, those things have not been initiated yet., srtPosCount: 499, srtSpeaker: , srtStartTime: 1033178, srtEndTime: 1036376
after writeToSrt(text: Formally, mathematically, those things have not been initiated yet., srtPosCount: 501, srtSpeaker: , srtStartTime: 1033178, srtEndTime: 1036376
1036398
So right now, a lot of the building of these collective systems is based on our intuitions and kind of engineering things using some vague guidelines like, oh, they should have a shared sensor space, but there's no mathematical conditions or guarantees about what degree of similarity is needed between two agents models to get the intended dynamics.
In writeToMD, lineCount: 501, textOut: So right now, a lot of the building of these collective systems is based on our intuitions and kind of engineering things using some vague guidelines like, oh, they should have a shared sensor space, but there's no mathematical conditions or guarantees about what degree of similarity is needed between two agents models to get the intended dynamics.
So right now, a lot of the building of these collective systems is based on our intuitions and kind of engineering things using some vague guidelines like, oh, they should have a shared sensor space, but there's no mathematical conditions or guarantees about what degree of similarity is needed between two agents models to get the intended dynamics.
before writeToSrt(text: So right now, a lot of the building of these collective systems is based on our intuitions and kind of engineering things using some vague guidelines like, oh, they should have a shared sensor space, but there's no mathematical conditions or guarantees about what degree of similarity is needed between two agents models to get the intended dynamics., srtPosCount: 501, srtSpeaker: , srtStartTime: 1036398, srtEndTime: 1056216
after writeToSrt(text: So right now, a lot of the building of these collective systems is based on our intuitions and kind of engineering things using some vague guidelines like, oh, they should have a shared sensor space, but there's no mathematical conditions or guarantees about what degree of similarity is needed between two agents models to get the intended dynamics., srtPosCount: 510, srtSpeaker: , srtStartTime: 1036398, srtEndTime: 1056216
1056408
And finally, we have to have at least some agreement between the generative model of each agent and the generative process, which is really the behavior of the other agents generating their data.
In writeToMD, lineCount: 510, textOut: And finally, we have to have at least some agreement between the generative model of each agent and the generative process, which is really the behavior of the other agents generating their data.
And finally, we have to have at least some agreement between the generative model of each agent and the generative process, which is really the behavior of the other agents generating their data.
before writeToSrt(text: And finally, we have to have at least some agreement between the generative model of each agent and the generative process, which is really the behavior of the other agents generating their data., srtPosCount: 510, srtSpeaker: , srtStartTime: 1056408, srtEndTime: 1068048
after writeToSrt(text: And finally, we have to have at least some agreement between the generative model of each agent and the generative process, which is really the behavior of the other agents generating their data., srtPosCount: 515, srtSpeaker: , srtStartTime: 1056408, srtEndTime: 1068048
1068134
So this is kind of related to the previous point about having shared generative models.
In writeToMD, lineCount: 515, textOut: So this is kind of related to the previous point about having shared generative models.
So this is kind of related to the previous point about having shared generative models.
before writeToSrt(text: So this is kind of related to the previous point about having shared generative models., srtPosCount: 515, srtSpeaker: , srtStartTime: 1068134, srtEndTime: 1072736
after writeToSrt(text: So this is kind of related to the previous point about having shared generative models., srtPosCount: 518, srtSpeaker: , srtStartTime: 1068134, srtEndTime: 1072736
1072848
But just to be very specific, the physics of the space that transfers your actions to my observations that physics can't be dramatically crazily different than how our generative models represent those physics.
In writeToMD, lineCount: 518, textOut: But just to be very specific, the physics of the space that transfers your actions to my observations that physics can't be dramatically crazily different than how our generative models represent those physics.
But just to be very specific, the physics of the space that transfers your actions to my observations that physics can't be dramatically crazily different than how our generative models represent those physics.
before writeToSrt(text: But just to be very specific, the physics of the space that transfers your actions to my observations that physics can't be dramatically crazily different than how our generative models represent those physics., srtPosCount: 518, srtSpeaker: , srtStartTime: 1072848, srtEndTime: 1086708
after writeToSrt(text: But just to be very specific, the physics of the space that transfers your actions to my observations that physics can't be dramatically crazily different than how our generative models represent those physics., srtPosCount: 524, srtSpeaker: , srtStartTime: 1072848, srtEndTime: 1086708
1086804
So if we took two fish with the same generative model of each other and they normally would school together in a fish tank, but we throw them in a volcano or shoot them out into outer space they won't.
In writeToMD, lineCount: 524, textOut: So if we took two fish with the same generative model of each other and they normally would school together in a fish tank, but we throw them in a volcano or shoot them out into outer space they won't.
So if we took two fish with the same generative model of each other and they normally would school together in a fish tank, but we throw them in a volcano or shoot them out into outer space they won't.
before writeToSrt(text: So if we took two fish with the same generative model of each other and they normally would school together in a fish tank, but we throw them in a volcano or shoot them out into outer space they won't., srtPosCount: 524, srtSpeaker: , srtStartTime: 1086804, srtEndTime: 1098456
after writeToSrt(text: So if we took two fish with the same generative model of each other and they normally would school together in a fish tank, but we throw them in a volcano or shoot them out into outer space they won't., srtPosCount: 530, srtSpeaker: , srtStartTime: 1086804, srtEndTime: 1098456
1098488
18:18 School together.
In writeToMD, lineCount: 530, textOut: School together.
School together.
before writeToSrt(text: School together., srtPosCount: 530, srtSpeaker: , srtStartTime: 1098488, srtEndTime: 1099100
after writeToSrt(text: School together., srtPosCount: 531, srtSpeaker: , srtStartTime: 1098488, srtEndTime: 1099100
1099170
Because then the generative process is so dramatically deviating from the way they are representing that physics, the way their generative model is constructed.
In writeToMD, lineCount: 531, textOut: Because then the generative process is so dramatically deviating from the way they are representing that physics, the way their generative model is constructed.
Because then the generative process is so dramatically deviating from the way they are representing that physics, the way their generative model is constructed.
before writeToSrt(text: Because then the generative process is so dramatically deviating from the way they are representing that physics, the way their generative model is constructed., srtPosCount: 531, srtSpeaker: , srtStartTime: 1099170, srtEndTime: 1107432
after writeToSrt(text: Because then the generative process is so dramatically deviating from the way they are representing that physics, the way their generative model is constructed., srtPosCount: 535, srtSpeaker: , srtStartTime: 1099170, srtEndTime: 1107432
1107576
So these are, again just ingredients, kind of guidelines or anecdotes.
In writeToMD, lineCount: 535, textOut: So these are, again just ingredients, kind of guidelines or anecdotes.
So these are, again just ingredients, kind of guidelines or anecdotes.
before writeToSrt(text: So these are, again just ingredients, kind of guidelines or anecdotes., srtPosCount: 535, srtSpeaker: , srtStartTime: 1107576, srtEndTime: 1111052
after writeToSrt(text: So these are, again just ingredients, kind of guidelines or anecdotes., srtPosCount: 537, srtSpeaker: , srtStartTime: 1107576, srtEndTime: 1111052
1111116
But there's nothing really rigorous behind these conditions.
In writeToMD, lineCount: 537, textOut: But there's nothing really rigorous behind these conditions.
But there's nothing really rigorous behind these conditions.
before writeToSrt(text: But there's nothing really rigorous behind these conditions., srtPosCount: 537, srtSpeaker: , srtStartTime: 1111116, srtEndTime: 1113836
after writeToSrt(text: But there's nothing really rigorous behind these conditions., srtPosCount: 539, srtSpeaker: , srtStartTime: 1111116, srtEndTime: 1113836
1113948
They're more like a list of best practices.
In writeToMD, lineCount: 539, textOut: They're more like a list of best practices.
They're more like a list of best practices.
before writeToSrt(text: They're more like a list of best practices., srtPosCount: 539, srtSpeaker: , srtStartTime: 1113948, srtEndTime: 1116080
after writeToSrt(text: They're more like a list of best practices., srtPosCount: 541, srtSpeaker: , srtStartTime: 1113948, srtEndTime: 1116080
1116580
So now let's get on to actual rigorous stuff.
In writeToMD, lineCount: 541, textOut: So now let's get on to actual rigorous stuff.
So now let's get on to actual rigorous stuff.
before writeToSrt(text: So now let's get on to actual rigorous stuff., srtPosCount: 541, srtSpeaker: , srtStartTime: 1116580, srtEndTime: 1119056
after writeToSrt(text: So now let's get on to actual rigorous stuff., srtPosCount: 543, srtSpeaker: , srtStartTime: 1116580, srtEndTime: 1119056
1119158
So, the first real rigorous attempt to show that multiscale active inference generally works is in one section of this free energy principle for a particular physics monograph from 2019.
In writeToMD, lineCount: 543, textOut: So, the first real rigorous attempt to show that multiscale active inference generally works is in one section of this free energy principle for a particular physics monograph from 2019.
So, the first real rigorous attempt to show that multiscale active inference generally works is in one section of this free energy principle for a particular physics monograph from 2019.
before writeToSrt(text: So, the first real rigorous attempt to show that multiscale active inference generally works is in one section of this free energy principle for a particular physics monograph from 2019., srtPosCount: 543, srtSpeaker: , srtStartTime: 1119158, srtEndTime: 1129184
after writeToSrt(text: So, the first real rigorous attempt to show that multiscale active inference generally works is in one section of this free energy principle for a particular physics monograph from 2019., srtPosCount: 548, srtSpeaker: , srtStartTime: 1119158, srtEndTime: 1129184
1129312
So it leverages this apparatus I mentioned earlier, the Renormalization group operator, to basically show how one can successively coarse grain multivariate stochastic differential equations that admit sparse coupling between their state variables.
In writeToMD, lineCount: 548, textOut: So it leverages this apparatus I mentioned earlier, the Renormalization group operator, to basically show how one can successively coarse grain multivariate stochastic differential equations that admit sparse coupling between their state variables.
So it leverages this apparatus I mentioned earlier, the Renormalization group operator, to basically show how one can successively coarse grain multivariate stochastic differential equations that admit sparse coupling between their state variables.
before writeToSrt(text: So it leverages this apparatus I mentioned earlier, the Renormalization group operator, to basically show how one can successively coarse grain multivariate stochastic differential equations that admit sparse coupling between their state variables., srtPosCount: 548, srtSpeaker: , srtStartTime: 1129312, srtEndTime: 1142884
after writeToSrt(text: So it leverages this apparatus I mentioned earlier, the Renormalization group operator, to basically show how one can successively coarse grain multivariate stochastic differential equations that admit sparse coupling between their state variables., srtPosCount: 555, srtSpeaker: , srtStartTime: 1129312, srtEndTime: 1142884
1143012
So the main result in my mind that connects these renormalization group results to multiscale active inference is the fact that the Lagrangian of the system at one scale can be expressed as a function of the Lagrangian at other scales.
In writeToMD, lineCount: 555, textOut: So the main result in my mind that connects these renormalization group results to multiscale active inference is the fact that the Lagrangian of the system at one scale can be expressed as a function of the Lagrangian at other scales.
So the main result in my mind that connects these renormalization group results to multiscale active inference is the fact that the Lagrangian of the system at one scale can be expressed as a function of the Lagrangian at other scales.
before writeToSrt(text: So the main result in my mind that connects these renormalization group results to multiscale active inference is the fact that the Lagrangian of the system at one scale can be expressed as a function of the Lagrangian at other scales., srtPosCount: 555, srtSpeaker: , srtStartTime: 1143012, srtEndTime: 1157516
after writeToSrt(text: So the main result in my mind that connects these renormalization group results to multiscale active inference is the fact that the Lagrangian of the system at one scale can be expressed as a function of the Lagrangian at other scales., srtPosCount: 562, srtSpeaker: , srtStartTime: 1143012, srtEndTime: 1157516
1157548
And that applies in a scale invariant fashion that is the main kind of output or the main benefit of using a renormalization group apparatus.
In writeToMD, lineCount: 562, textOut: And that applies in a scale invariant fashion that is the main kind of output or the main benefit of using a renormalization group apparatus.
And that applies in a scale invariant fashion that is the main kind of output or the main benefit of using a renormalization group apparatus.
before writeToSrt(text: And that applies in a scale invariant fashion that is the main kind of output or the main benefit of using a renormalization group apparatus., srtPosCount: 562, srtSpeaker: , srtStartTime: 1157548, srtEndTime: 1167852
after writeToSrt(text: And that applies in a scale invariant fashion that is the main kind of output or the main benefit of using a renormalization group apparatus., srtPosCount: 566, srtSpeaker: , srtStartTime: 1157548, srtEndTime: 1167852
1167996
19:27 So you can kind of think of Lagrangian like the generative model.
In writeToMD, lineCount: 566, textOut: So you can kind of think of Lagrangian like the generative model.
So you can kind of think of Lagrangian like the generative model.
before writeToSrt(text: So you can kind of think of Lagrangian like the generative model., srtPosCount: 566, srtSpeaker: , srtStartTime: 1167996, srtEndTime: 1171236
after writeToSrt(text: So you can kind of think of Lagrangian like the generative model., srtPosCount: 568, srtSpeaker: , srtStartTime: 1167996, srtEndTime: 1171236
1171418
It's a physics term, but it's related to the generative model of the agents that comprise the system and therefore also their free energy.
In writeToMD, lineCount: 568, textOut: It's a physics term, but it's related to the generative model of the agents that comprise the system and therefore also their free energy.
It's a physics term, but it's related to the generative model of the agents that comprise the system and therefore also their free energy.
before writeToSrt(text: It's a physics term, but it's related to the generative model of the agents that comprise the system and therefore also their free energy., srtPosCount: 568, srtSpeaker: , srtStartTime: 1171418, srtEndTime: 1178420
after writeToSrt(text: It's a physics term, but it's related to the generative model of the agents that comprise the system and therefore also their free energy., srtPosCount: 572, srtSpeaker: , srtStartTime: 1171418, srtEndTime: 1178420
1178570
So in terms of active inference, it means that this reasoning of the renormalization group can be used to smoothly move between the models of individual agents at one scale and the model of a collective or larger agent at a different scale or a smaller scale for that matter.
In writeToMD, lineCount: 572, textOut: So in terms of active inference, it means that this reasoning of the renormalization group can be used to smoothly move between the models of individual agents at one scale and the model of a collective or larger agent at a different scale or a smaller scale for that matter.
So in terms of active inference, it means that this reasoning of the renormalization group can be used to smoothly move between the models of individual agents at one scale and the model of a collective or larger agent at a different scale or a smaller scale for that matter.
before writeToSrt(text: So in terms of active inference, it means that this reasoning of the renormalization group can be used to smoothly move between the models of individual agents at one scale and the model of a collective or larger agent at a different scale or a smaller scale for that matter., srtPosCount: 572, srtSpeaker: , srtStartTime: 1178570, srtEndTime: 1192712
after writeToSrt(text: So in terms of active inference, it means that this reasoning of the renormalization group can be used to smoothly move between the models of individual agents at one scale and the model of a collective or larger agent at a different scale or a smaller scale for that matter., srtPosCount: 580, srtSpeaker: , srtStartTime: 1178570, srtEndTime: 1192712
1192846
And the nice thing about it is general for all kinds of dynamics and thus generative models, it doesn't depend heavily on the form of the stochastic differential equations that form your system.
In writeToMD, lineCount: 580, textOut: And the nice thing about it is general for all kinds of dynamics and thus generative models, it doesn't depend heavily on the form of the stochastic differential equations that form your system.
And the nice thing about it is general for all kinds of dynamics and thus generative models, it doesn't depend heavily on the form of the stochastic differential equations that form your system.
before writeToSrt(text: And the nice thing about it is general for all kinds of dynamics and thus generative models, it doesn't depend heavily on the form of the stochastic differential equations that form your system., srtPosCount: 580, srtSpeaker: , srtStartTime: 1192846, srtEndTime: 1203550
after writeToSrt(text: And the nice thing about it is general for all kinds of dynamics and thus generative models, it doesn't depend heavily on the form of the stochastic differential equations that form your system., srtPosCount: 586, srtSpeaker: , srtStartTime: 1192846, srtEndTime: 1203550
1205120
The issues with it is that there's not a global link to Bayesian mechanics and active inference.
In writeToMD, lineCount: 586, textOut: The issues with it is that there's not a global link to Bayesian mechanics and active inference.
The issues with it is that there's not a global link to Bayesian mechanics and active inference.
before writeToSrt(text: The issues with it is that there's not a global link to Bayesian mechanics and active inference., srtPosCount: 586, srtSpeaker: , srtStartTime: 1205120, srtEndTime: 1210796
after writeToSrt(text: The issues with it is that there's not a global link to Bayesian mechanics and active inference., srtPosCount: 589, srtSpeaker: , srtStartTime: 1205120, srtEndTime: 1210796
1210828
It's still all done in the traditional physics formalism.
In writeToMD, lineCount: 589, textOut: It's still all done in the traditional physics formalism.
It's still all done in the traditional physics formalism.
before writeToSrt(text: It's still all done in the traditional physics formalism., srtPosCount: 589, srtSpeaker: , srtStartTime: 1210828, srtEndTime: 1213804
after writeToSrt(text: It's still all done in the traditional physics formalism., srtPosCount: 591, srtSpeaker: , srtStartTime: 1210828, srtEndTime: 1213804
1213852
So we don't actually have an explicit link to local inference and global inference.
In writeToMD, lineCount: 591, textOut: So we don't actually have an explicit link to local inference and global inference.
So we don't actually have an explicit link to local inference and global inference.
before writeToSrt(text: So we don't actually have an explicit link to local inference and global inference., srtPosCount: 591, srtSpeaker: , srtStartTime: 1213852, srtEndTime: 1218684
after writeToSrt(text: So we don't actually have an explicit link to local inference and global inference., srtPosCount: 594, srtSpeaker: , srtStartTime: 1213852, srtEndTime: 1218684
1218732
Although if you know the connection between the Lagrangian and the generative model and the free energy, then you can make that connection.
In writeToMD, lineCount: 594, textOut: Although if you know the connection between the Lagrangian and the generative model and the free energy, then you can make that connection.
Although if you know the connection between the Lagrangian and the generative model and the free energy, then you can make that connection.
before writeToSrt(text: Although if you know the connection between the Lagrangian and the generative model and the free energy, then you can make that connection., srtPosCount: 594, srtSpeaker: , srtStartTime: 1218732, srtEndTime: 1224800
after writeToSrt(text: Although if you know the connection between the Lagrangian and the generative model and the free energy, then you can make that connection., srtPosCount: 598, srtSpeaker: , srtStartTime: 1218732, srtEndTime: 1224800
1224880
But it's not actually made explicitly for us in this part of the monograph.
In writeToMD, lineCount: 598, textOut: But it's not actually made explicitly for us in this part of the monograph.
But it's not actually made explicitly for us in this part of the monograph.
before writeToSrt(text: But it's not actually made explicitly for us in this part of the monograph., srtPosCount: 598, srtSpeaker: , srtStartTime: 1224880, srtEndTime: 1228848
after writeToSrt(text: But it's not actually made explicitly for us in this part of the monograph., srtPosCount: 600, srtSpeaker: , srtStartTime: 1224880, srtEndTime: 1228848
1228944
20:28 It also requires the assumption that the generative model and the generative process are identical at the local level that's related to how the Lagrangian is defined.
In writeToMD, lineCount: 600, textOut: It also requires the assumption that the generative model and the generative process are identical at the local level that's related to how the Lagrangian is defined.
It also requires the assumption that the generative model and the generative process are identical at the local level that's related to how the Lagrangian is defined.
before writeToSrt(text: It also requires the assumption that the generative model and the generative process are identical at the local level that's related to how the Lagrangian is defined., srtPosCount: 600, srtSpeaker: , srtStartTime: 1228944, srtEndTime: 1236852
after writeToSrt(text: It also requires the assumption that the generative model and the generative process are identical at the local level that's related to how the Lagrangian is defined., srtPosCount: 605, srtSpeaker: , srtStartTime: 1228944, srtEndTime: 1236852
1236916
That's also restrictive assumption.
In writeToMD, lineCount: 605, textOut: That's also restrictive assumption.
That's also restrictive assumption.
before writeToSrt(text: That's also restrictive assumption., srtPosCount: 605, srtSpeaker: , srtStartTime: 1236916, srtEndTime: 1238436
after writeToSrt(text: That's also restrictive assumption., srtPosCount: 606, srtSpeaker: , srtStartTime: 1236916, srtEndTime: 1238436
1238468
That's probably not realistic in my opinion.
In writeToMD, lineCount: 606, textOut: That's probably not realistic in my opinion.
That's probably not realistic in my opinion.
before writeToSrt(text: That's probably not realistic in my opinion., srtPosCount: 606, srtSpeaker: , srtStartTime: 1238468, srtEndTime: 1240532
after writeToSrt(text: That's probably not realistic in my opinion., srtPosCount: 608, srtSpeaker: , srtStartTime: 1238468, srtEndTime: 1240532
1240676
And then finally, there's something about kind of spatiotemporal segregation of scales.
In writeToMD, lineCount: 608, textOut: And then finally, there's something about kind of spatiotemporal segregation of scales.
And then finally, there's something about kind of spatiotemporal segregation of scales.
before writeToSrt(text: And then finally, there's something about kind of spatiotemporal segregation of scales., srtPosCount: 608, srtSpeaker: , srtStartTime: 1240676, srtEndTime: 1246036
after writeToSrt(text: And then finally, there's something about kind of spatiotemporal segregation of scales., srtPosCount: 611, srtSpeaker: , srtStartTime: 1240676, srtEndTime: 1246036
1246148
So we need to make assumptions about how fast random fluctuations are at one scale relative to another scale in order to justify kind of coarse grading or forgetting about certain states as you move between scales.
In writeToMD, lineCount: 611, textOut: So we need to make assumptions about how fast random fluctuations are at one scale relative to another scale in order to justify kind of coarse grading or forgetting about certain states as you move between scales.
So we need to make assumptions about how fast random fluctuations are at one scale relative to another scale in order to justify kind of coarse grading or forgetting about certain states as you move between scales.
before writeToSrt(text: So we need to make assumptions about how fast random fluctuations are at one scale relative to another scale in order to justify kind of coarse grading or forgetting about certain states as you move between scales., srtPosCount: 611, srtSpeaker: , srtStartTime: 1246148, srtEndTime: 1258172
after writeToSrt(text: So we need to make assumptions about how fast random fluctuations are at one scale relative to another scale in order to justify kind of coarse grading or forgetting about certain states as you move between scales., srtPosCount: 617, srtSpeaker: , srtStartTime: 1246148, srtEndTime: 1258172
1258236
And that's also something that you could argue.
In writeToMD, lineCount: 617, textOut: And that's also something that you could argue.
And that's also something that you could argue.
before writeToSrt(text: And that's also something that you could argue., srtPosCount: 617, srtSpeaker: , srtStartTime: 1258236, srtEndTime: 1260732
after writeToSrt(text: And that's also something that you could argue., srtPosCount: 619, srtSpeaker: , srtStartTime: 1258236, srtEndTime: 1260732
1260796
Current research into collective dynamics challenges that assumption about how fast noise is at one scale relative to the next.
In writeToMD, lineCount: 619, textOut: Current research into collective dynamics challenges that assumption about how fast noise is at one scale relative to the next.
Current research into collective dynamics challenges that assumption about how fast noise is at one scale relative to the next.
before writeToSrt(text: Current research into collective dynamics challenges that assumption about how fast noise is at one scale relative to the next., srtPosCount: 619, srtSpeaker: , srtStartTime: 1260796, srtEndTime: 1269670
after writeToSrt(text: Current research into collective dynamics challenges that assumption about how fast noise is at one scale relative to the next., srtPosCount: 623, srtSpeaker: , srtStartTime: 1260796, srtEndTime: 1269670
1270680
So now I'm going to discuss quickly another small contingent of active inference research that is attempted to address this mapping between local and global inference processes.
In writeToMD, lineCount: 623, textOut: So now I'm going to discuss quickly another small contingent of active inference research that is attempted to address this mapping between local and global inference processes.
So now I'm going to discuss quickly another small contingent of active inference research that is attempted to address this mapping between local and global inference processes.
before writeToSrt(text: So now I'm going to discuss quickly another small contingent of active inference research that is attempted to address this mapping between local and global inference processes., srtPosCount: 623, srtSpeaker: , srtStartTime: 1270680, srtEndTime: 1279632
after writeToSrt(text: So now I'm going to discuss quickly another small contingent of active inference research that is attempted to address this mapping between local and global inference processes., srtPosCount: 628, srtSpeaker: , srtStartTime: 1270680, srtEndTime: 1279632
1279776
So what I want to kind of just generally say with this presentation and to our community is that the kind of approach taken in these two papers, first of all, active inference model of collective intelligence and spin glass systems as collective active inference.
In writeToMD, lineCount: 628, textOut: So what I want to kind of just generally say with this presentation and to our community is that the kind of approach taken in these two papers, first of all, active inference model of collective intelligence and spin glass systems as collective active inference.
So what I want to kind of just generally say with this presentation and to our community is that the kind of approach taken in these two papers, first of all, active inference model of collective intelligence and spin glass systems as collective active inference.
before writeToSrt(text: So what I want to kind of just generally say with this presentation and to our community is that the kind of approach taken in these two papers, first of all, active inference model of collective intelligence and spin glass systems as collective active inference., srtPosCount: 628, srtSpeaker: , srtStartTime: 1279776, srtEndTime: 1291668
after writeToSrt(text: So what I want to kind of just generally say with this presentation and to our community is that the kind of approach taken in these two papers, first of all, active inference model of collective intelligence and spin glass systems as collective active inference., srtPosCount: 635, srtSpeaker: , srtStartTime: 1279776, srtEndTime: 1291668
1291764
21:31 This is one of the types of research I think we really need to move active inference, multiscale active inference forward.
In writeToMD, lineCount: 635, textOut: This is one of the types of research I think we really need to move active inference, multiscale active inference forward.
This is one of the types of research I think we really need to move active inference, multiscale active inference forward.
before writeToSrt(text: This is one of the types of research I think we really need to move active inference, multiscale active inference forward., srtPosCount: 635, srtSpeaker: , srtStartTime: 1291764, srtEndTime: 1298648
after writeToSrt(text: This is one of the types of research I think we really need to move active inference, multiscale active inference forward., srtPosCount: 639, srtSpeaker: , srtStartTime: 1291764, srtEndTime: 1298648
1298814
So I'm not trying to be too biased because I am the first author on the second of those papers, but I'll also be the first one to point out the limitation.
In writeToMD, lineCount: 639, textOut: So I'm not trying to be too biased because I am the first author on the second of those papers, but I'll also be the first one to point out the limitation.
So I'm not trying to be too biased because I am the first author on the second of those papers, but I'll also be the first one to point out the limitation.
before writeToSrt(text: So I'm not trying to be too biased because I am the first author on the second of those papers, but I'll also be the first one to point out the limitation., srtPosCount: 639, srtSpeaker: , srtStartTime: 1298814, srtEndTime: 1305112
after writeToSrt(text: So I'm not trying to be too biased because I am the first author on the second of those papers, but I'll also be the first one to point out the limitation., srtPosCount: 644, srtSpeaker: , srtStartTime: 1298814, srtEndTime: 1305112
1305256
But benefits wise, I think these approaches are really important because they formally relate a local generative model at one scale to a global generative model at a different scale.
In writeToMD, lineCount: 644, textOut: But benefits wise, I think these approaches are really important because they formally relate a local generative model at one scale to a global generative model at a different scale.
But benefits wise, I think these approaches are really important because they formally relate a local generative model at one scale to a global generative model at a different scale.
before writeToSrt(text: But benefits wise, I think these approaches are really important because they formally relate a local generative model at one scale to a global generative model at a different scale., srtPosCount: 644, srtSpeaker: , srtStartTime: 1305256, srtEndTime: 1315100
after writeToSrt(text: But benefits wise, I think these approaches are really important because they formally relate a local generative model at one scale to a global generative model at a different scale., srtPosCount: 649, srtSpeaker: , srtStartTime: 1305256, srtEndTime: 1315100
1315180
So really tie, how do the parameters of one model relate to a course grade model?
In writeToMD, lineCount: 649, textOut: So really tie, how do the parameters of one model relate to a course grade model?
So really tie, how do the parameters of one model relate to a course grade model?
before writeToSrt(text: So really tie, how do the parameters of one model relate to a course grade model?, srtPosCount: 649, srtSpeaker: , srtStartTime: 1315180, srtEndTime: 1319524
after writeToSrt(text: So really tie, how do the parameters of one model relate to a course grade model?, srtPosCount: 652, srtSpeaker: , srtStartTime: 1315180, srtEndTime: 1319524
1319642
And these are really good steps in the direction of a formal theory of collective intelligence that goes from local intelligences to global intelligence.
In writeToMD, lineCount: 652, textOut: And these are really good steps in the direction of a formal theory of collective intelligence that goes from local intelligences to global intelligence.
And these are really good steps in the direction of a formal theory of collective intelligence that goes from local intelligences to global intelligence.
before writeToSrt(text: And these are really good steps in the direction of a formal theory of collective intelligence that goes from local intelligences to global intelligence., srtPosCount: 652, srtSpeaker: , srtStartTime: 1319642, srtEndTime: 1329140
after writeToSrt(text: And these are really good steps in the direction of a formal theory of collective intelligence that goes from local intelligences to global intelligence., srtPosCount: 657, srtSpeaker: , srtStartTime: 1319642, srtEndTime: 1329140
1330200
However, there's still issues with these.
In writeToMD, lineCount: 657, textOut: However, there's still issues with these.
However, there's still issues with these.
before writeToSrt(text: However, there's still issues with these., srtPosCount: 657, srtSpeaker: , srtStartTime: 1330200, srtEndTime: 1331988
after writeToSrt(text: However, there's still issues with these., srtPosCount: 659, srtSpeaker: , srtStartTime: 1330200, srtEndTime: 1331988
1332074
One of them is that they only deal with issue with inference at the global level, not active inference.
In writeToMD, lineCount: 659, textOut: One of them is that they only deal with issue with inference at the global level, not active inference.
One of them is that they only deal with issue with inference at the global level, not active inference.
before writeToSrt(text: One of them is that they only deal with issue with inference at the global level, not active inference., srtPosCount: 659, srtSpeaker: , srtStartTime: 1332074, srtEndTime: 1337876
after writeToSrt(text: One of them is that they only deal with issue with inference at the global level, not active inference., srtPosCount: 662, srtSpeaker: , srtStartTime: 1332074, srtEndTime: 1337876
1337988
So both these papers concern with a bunch of local active inference agents that cooperate to form a global inference agent, like a passive baying agent, rather than an active inference agent.
In writeToMD, lineCount: 662, textOut: So both these papers concern with a bunch of local active inference agents that cooperate to form a global inference agent, like a passive baying agent, rather than an active inference agent.
So both these papers concern with a bunch of local active inference agents that cooperate to form a global inference agent, like a passive baying agent, rather than an active inference agent.
before writeToSrt(text: So both these papers concern with a bunch of local active inference agents that cooperate to form a global inference agent, like a passive baying agent, rather than an active inference agent., srtPosCount: 662, srtSpeaker: , srtStartTime: 1337988, srtEndTime: 1348588
after writeToSrt(text: So both these papers concern with a bunch of local active inference agents that cooperate to form a global inference agent, like a passive baying agent, rather than an active inference agent., srtPosCount: 667, srtSpeaker: , srtStartTime: 1337988, srtEndTime: 1348588
1348674
And it's also unclear whether the systems studying these papers are actually very generic.
In writeToMD, lineCount: 667, textOut: And it's also unclear whether the systems studying these papers are actually very generic.
And it's also unclear whether the systems studying these papers are actually very generic.
before writeToSrt(text: And it's also unclear whether the systems studying these papers are actually very generic., srtPosCount: 667, srtSpeaker: , srtStartTime: 1348674, srtEndTime: 1354472
after writeToSrt(text: And it's also unclear whether the systems studying these papers are actually very generic., srtPosCount: 670, srtSpeaker: , srtStartTime: 1348674, srtEndTime: 1354472
1354536
22:34 Like the results are generic to studying collective intelligence in general, or they're nice formal arguments, but they're only applicable to these specific systems.
In writeToMD, lineCount: 670, textOut: Like the results are generic to studying collective intelligence in general, or they're nice formal arguments, but they're only applicable to these specific systems.
Like the results are generic to studying collective intelligence in general, or they're nice formal arguments, but they're only applicable to these specific systems.
before writeToSrt(text: Like the results are generic to studying collective intelligence in general, or they're nice formal arguments, but they're only applicable to these specific systems., srtPosCount: 670, srtSpeaker: , srtStartTime: 1354536, srtEndTime: 1362924
after writeToSrt(text: Like the results are generic to studying collective intelligence in general, or they're nice formal arguments, but they're only applicable to these specific systems., srtPosCount: 675, srtSpeaker: , srtStartTime: 1354536, srtEndTime: 1362924
1362972
So we still don't have something that's even more kind of zoomed out and abstract than these, which tend to be a little bit case specific.
In writeToMD, lineCount: 675, textOut: So we still don't have something that's even more kind of zoomed out and abstract than these, which tend to be a little bit case specific.
So we still don't have something that's even more kind of zoomed out and abstract than these, which tend to be a little bit case specific.
before writeToSrt(text: So we still don't have something that's even more kind of zoomed out and abstract than these, which tend to be a little bit case specific., srtPosCount: 675, srtSpeaker: , srtStartTime: 1362972, srtEndTime: 1370772
after writeToSrt(text: So we still don't have something that's even more kind of zoomed out and abstract than these, which tend to be a little bit case specific., srtPosCount: 679, srtSpeaker: , srtStartTime: 1362972, srtEndTime: 1370772
1370906
And finally, the actual scale transcendence that we're doing in these papers is still relegated to really one step.
In writeToMD, lineCount: 679, textOut: And finally, the actual scale transcendence that we're doing in these papers is still relegated to really one step.
And finally, the actual scale transcendence that we're doing in these papers is still relegated to really one step.
before writeToSrt(text: And finally, the actual scale transcendence that we're doing in these papers is still relegated to really one step., srtPosCount: 679, srtSpeaker: , srtStartTime: 1370906, srtEndTime: 1377652
after writeToSrt(text: And finally, the actual scale transcendence that we're doing in these papers is still relegated to really one step., srtPosCount: 683, srtSpeaker: , srtStartTime: 1370906, srtEndTime: 1377652
1377706
We're not doing the full multiscale infinite scale regression that something like Renormalization group promises.
In writeToMD, lineCount: 683, textOut: We're not doing the full multiscale infinite scale regression that something like Renormalization group promises.
We're not doing the full multiscale infinite scale regression that something like Renormalization group promises.
before writeToSrt(text: We're not doing the full multiscale infinite scale regression that something like Renormalization group promises., srtPosCount: 683, srtSpeaker: , srtStartTime: 1377706, srtEndTime: 1385720
after writeToSrt(text: We're not doing the full multiscale infinite scale regression that something like Renormalization group promises., srtPosCount: 686, srtSpeaker: , srtStartTime: 1377706, srtEndTime: 1385720
1386380
So that's kind of the current overview of what I think are the most promising directions in multiscale active inference.
In writeToMD, lineCount: 686, textOut: So that's kind of the current overview of what I think are the most promising directions in multiscale active inference.
So that's kind of the current overview of what I think are the most promising directions in multiscale active inference.
before writeToSrt(text: So that's kind of the current overview of what I think are the most promising directions in multiscale active inference., srtPosCount: 686, srtSpeaker: , srtStartTime: 1386380, srtEndTime: 1392148
after writeToSrt(text: So that's kind of the current overview of what I think are the most promising directions in multiscale active inference., srtPosCount: 690, srtSpeaker: , srtStartTime: 1386380, srtEndTime: 1392148
1392244
And I'm aware on time, sorry, five minutes.
In writeToMD, lineCount: 690, textOut: And I'm aware on time, sorry, five minutes.
And I'm aware on time, sorry, five minutes.
before writeToSrt(text: And I'm aware on time, sorry, five minutes., srtPosCount: 690, srtSpeaker: , srtStartTime: 1392244, srtEndTime: 1394844
after writeToSrt(text: And I'm aware on time, sorry, five minutes., srtPosCount: 692, srtSpeaker: , srtStartTime: 1392244, srtEndTime: 1394844
1394882
So I'm going to quickly try to go through what I think are really promising directions to push in terms of multiscale active inference and kind of intuition pumps that I think will help us study these systems in a way that's different and also actually better informed by other research disciplines.
In writeToMD, lineCount: 692, textOut: So I'm going to quickly try to go through what I think are really promising directions to push in terms of multiscale active inference and kind of intuition pumps that I think will help us study these systems in a way that's different and also actually better informed by other research disciplines.
So I'm going to quickly try to go through what I think are really promising directions to push in terms of multiscale active inference and kind of intuition pumps that I think will help us study these systems in a way that's different and also actually better informed by other research disciplines.
before writeToSrt(text: So I'm going to quickly try to go through what I think are really promising directions to push in terms of multiscale active inference and kind of intuition pumps that I think will help us study these systems in a way that's different and also actually better informed by other research disciplines., srtPosCount: 692, srtSpeaker: , srtStartTime: 1394882, srtEndTime: 1413580
after writeToSrt(text: So I'm going to quickly try to go through what I think are really promising directions to push in terms of multiscale active inference and kind of intuition pumps that I think will help us study these systems in a way that's different and also actually better informed by other research disciplines., srtPosCount: 700, srtSpeaker: , srtStartTime: 1394882, srtEndTime: 1413580
1413740
So the general idea that I'd like to put forward is that misaligned gradients can actually be a good thing.
In writeToMD, lineCount: 700, textOut: So the general idea that I'd like to put forward is that misaligned gradients can actually be a good thing.
So the general idea that I'd like to put forward is that misaligned gradients can actually be a good thing.
before writeToSrt(text: So the general idea that I'd like to put forward is that misaligned gradients can actually be a good thing., srtPosCount: 700, srtSpeaker: , srtStartTime: 1413740, srtEndTime: 1420308
after writeToSrt(text: So the general idea that I'd like to put forward is that misaligned gradients can actually be a good thing., srtPosCount: 703, srtSpeaker: , srtStartTime: 1413740, srtEndTime: 1420308
1420394
23:40 So it's actually sometimes good when local free energy gradients are misaligned with global gradients.
In writeToMD, lineCount: 703, textOut: So it's actually sometimes good when local free energy gradients are misaligned with global gradients.
So it's actually sometimes good when local free energy gradients are misaligned with global gradients.
before writeToSrt(text: So it's actually sometimes good when local free energy gradients are misaligned with global gradients., srtPosCount: 703, srtSpeaker: , srtStartTime: 1420394, srtEndTime: 1426528
after writeToSrt(text: So it's actually sometimes good when local free energy gradients are misaligned with global gradients., srtPosCount: 706, srtSpeaker: , srtStartTime: 1420394, srtEndTime: 1426528
1426624
So sometimes the global system will actually do better if the local systems are performing worse.
In writeToMD, lineCount: 706, textOut: So sometimes the global system will actually do better if the local systems are performing worse.
So sometimes the global system will actually do better if the local systems are performing worse.
before writeToSrt(text: So sometimes the global system will actually do better if the local systems are performing worse., srtPosCount: 706, srtSpeaker: , srtStartTime: 1426624, srtEndTime: 1432748
after writeToSrt(text: So sometimes the global system will actually do better if the local systems are performing worse., srtPosCount: 709, srtSpeaker: , srtStartTime: 1426624, srtEndTime: 1432748
1432864
So this is something you could call multiscale conflict, where the free energy minimizing processes at one scale are actually doing bad, quote unquote, but it's because they're being driven by some higher scale process that is doing well.
In writeToMD, lineCount: 709, textOut: So this is something you could call multiscale conflict, where the free energy minimizing processes at one scale are actually doing bad, quote unquote, but it's because they're being driven by some higher scale process that is doing well.
So this is something you could call multiscale conflict, where the free energy minimizing processes at one scale are actually doing bad, quote unquote, but it's because they're being driven by some higher scale process that is doing well.
before writeToSrt(text: So this is something you could call multiscale conflict, where the free energy minimizing processes at one scale are actually doing bad, quote unquote, but it's because they're being driven by some higher scale process that is doing well., srtPosCount: 709, srtSpeaker: , srtStartTime: 1432864, srtEndTime: 1445260
after writeToSrt(text: So this is something you could call multiscale conflict, where the free energy minimizing processes at one scale are actually doing bad, quote unquote, but it's because they're being driven by some higher scale process that is doing well., srtPosCount: 716, srtSpeaker: , srtStartTime: 1432864, srtEndTime: 1445260
1445410
So rather than trying to always avoid constructing processes like this, I think this kind of frustration, to use the analogy from statistical physics, can actually be an inspiration for what we should investigate further because it actually might be key to facilitating optimality at different scales.
In writeToMD, lineCount: 716, textOut: So rather than trying to always avoid constructing processes like this, I think this kind of frustration, to use the analogy from statistical physics, can actually be an inspiration for what we should investigate further because it actually might be key to facilitating optimality at different scales.
So rather than trying to always avoid constructing processes like this, I think this kind of frustration, to use the analogy from statistical physics, can actually be an inspiration for what we should investigate further because it actually might be key to facilitating optimality at different scales.
before writeToSrt(text: So rather than trying to always avoid constructing processes like this, I think this kind of frustration, to use the analogy from statistical physics, can actually be an inspiration for what we should investigate further because it actually might be key to facilitating optimality at different scales., srtPosCount: 716, srtSpeaker: , srtStartTime: 1445410, srtEndTime: 1462160
after writeToSrt(text: So rather than trying to always avoid constructing processes like this, I think this kind of frustration, to use the analogy from statistical physics, can actually be an inspiration for what we should investigate further because it actually might be key to facilitating optimality at different scales., srtPosCount: 724, srtSpeaker: , srtStartTime: 1445410, srtEndTime: 1462160
1464260
The reason I put this forward is because there's loads of research, just recent research in the last several years that are suggesting that actually making local agents more frustrated or more unhappy might coincidentally or not coincidentally lead to better collective or global outcomes.
In writeToMD, lineCount: 724, textOut: The reason I put this forward is because there's loads of research, just recent research in the last several years that are suggesting that actually making local agents more frustrated or more unhappy might coincidentally or not coincidentally lead to better collective or global outcomes.
The reason I put this forward is because there's loads of research, just recent research in the last several years that are suggesting that actually making local agents more frustrated or more unhappy might coincidentally or not coincidentally lead to better collective or global outcomes.
before writeToSrt(text: The reason I put this forward is because there's loads of research, just recent research in the last several years that are suggesting that actually making local agents more frustrated or more unhappy might coincidentally or not coincidentally lead to better collective or global outcomes., srtPosCount: 724, srtSpeaker: , srtStartTime: 1464260, srtEndTime: 1480768
after writeToSrt(text: The reason I put this forward is because there's loads of research, just recent research in the last several years that are suggesting that actually making local agents more frustrated or more unhappy might coincidentally or not coincidentally lead to better collective or global outcomes., srtPosCount: 732, srtSpeaker: , srtStartTime: 1464260, srtEndTime: 1480768
1480864
24:40 So this is expressed in various forms in various bodies of work.
In writeToMD, lineCount: 732, textOut: So this is expressed in various forms in various bodies of work.
So this is expressed in various forms in various bodies of work.
before writeToSrt(text: So this is expressed in various forms in various bodies of work., srtPosCount: 732, srtSpeaker: , srtStartTime: 1480864, srtEndTime: 1484448
after writeToSrt(text: So this is expressed in various forms in various bodies of work., srtPosCount: 734, srtSpeaker: , srtStartTime: 1480864, srtEndTime: 1484448
1484554
One of the biggest patterns I've noticed is the study of collective behavioral systems over the last several decades is the idea that local noise and local Dysregulation can often facilitate global coherence or global coordination.
In writeToMD, lineCount: 734, textOut: One of the biggest patterns I've noticed is the study of collective behavioral systems over the last several decades is the idea that local noise and local Dysregulation can often facilitate global coherence or global coordination.
One of the biggest patterns I've noticed is the study of collective behavioral systems over the last several decades is the idea that local noise and local Dysregulation can often facilitate global coherence or global coordination.
before writeToSrt(text: One of the biggest patterns I've noticed is the study of collective behavioral systems over the last several decades is the idea that local noise and local Dysregulation can often facilitate global coherence or global coordination., srtPosCount: 734, srtSpeaker: , srtStartTime: 1484554, srtEndTime: 1497224
after writeToSrt(text: One of the biggest patterns I've noticed is the study of collective behavioral systems over the last several decades is the idea that local noise and local Dysregulation can often facilitate global coherence or global coordination., srtPosCount: 740, srtSpeaker: , srtStartTime: 1484554, srtEndTime: 1497224
1497352
And where multiscale active inference has something to say, in my opinion, is in framing this benefit of local frustration in terms of a misalignment of free energy gradients.
In writeToMD, lineCount: 740, textOut: And where multiscale active inference has something to say, in my opinion, is in framing this benefit of local frustration in terms of a misalignment of free energy gradients.
And where multiscale active inference has something to say, in my opinion, is in framing this benefit of local frustration in terms of a misalignment of free energy gradients.
before writeToSrt(text: And where multiscale active inference has something to say, in my opinion, is in framing this benefit of local frustration in terms of a misalignment of free energy gradients., srtPosCount: 740, srtSpeaker: , srtStartTime: 1497352, srtEndTime: 1507452
after writeToSrt(text: And where multiscale active inference has something to say, in my opinion, is in framing this benefit of local frustration in terms of a misalignment of free energy gradients., srtPosCount: 745, srtSpeaker: , srtStartTime: 1497352, srtEndTime: 1507452
1507596
So it may be that actually temporary misalignment local free energy gradients from global ones may facilitate the descent to fix points in the global free energy landscape that satisfy everyone at all scales.
In writeToMD, lineCount: 745, textOut: So it may be that actually temporary misalignment local free energy gradients from global ones may facilitate the descent to fix points in the global free energy landscape that satisfy everyone at all scales.
So it may be that actually temporary misalignment local free energy gradients from global ones may facilitate the descent to fix points in the global free energy landscape that satisfy everyone at all scales.
before writeToSrt(text: So it may be that actually temporary misalignment local free energy gradients from global ones may facilitate the descent to fix points in the global free energy landscape that satisfy everyone at all scales., srtPosCount: 745, srtSpeaker: , srtStartTime: 1507596, srtEndTime: 1520016
after writeToSrt(text: So it may be that actually temporary misalignment local free energy gradients from global ones may facilitate the descent to fix points in the global free energy landscape that satisfy everyone at all scales., srtPosCount: 751, srtSpeaker: , srtStartTime: 1507596, srtEndTime: 1520016
1520128
So I'm basically expressing an idea that's been known in various communities like Stochastic optimization and Stochastic resonance theory for decades.
In writeToMD, lineCount: 751, textOut: So I'm basically expressing an idea that's been known in various communities like Stochastic optimization and Stochastic resonance theory for decades.
So I'm basically expressing an idea that's been known in various communities like Stochastic optimization and Stochastic resonance theory for decades.
before writeToSrt(text: So I'm basically expressing an idea that's been known in various communities like Stochastic optimization and Stochastic resonance theory for decades., srtPosCount: 751, srtSpeaker: , srtStartTime: 1520128, srtEndTime: 1527888
after writeToSrt(text: So I'm basically expressing an idea that's been known in various communities like Stochastic optimization and Stochastic resonance theory for decades., srtPosCount: 755, srtSpeaker: , srtStartTime: 1520128, srtEndTime: 1527888
1527984
But I think we as active inference practitioners have a new and potentially useful perspective to shed on that, using the language of active inference and free energy minimization and Bayesian inference in general.
In writeToMD, lineCount: 755, textOut: But I think we as active inference practitioners have a new and potentially useful perspective to shed on that, using the language of active inference and free energy minimization and Bayesian inference in general.
But I think we as active inference practitioners have a new and potentially useful perspective to shed on that, using the language of active inference and free energy minimization and Bayesian inference in general.
before writeToSrt(text: But I think we as active inference practitioners have a new and potentially useful perspective to shed on that, using the language of active inference and free energy minimization and Bayesian inference in general., srtPosCount: 755, srtSpeaker: , srtStartTime: 1527984, srtEndTime: 1538520
after writeToSrt(text: But I think we as active inference practitioners have a new and potentially useful perspective to shed on that, using the language of active inference and free energy minimization and Bayesian inference in general., srtPosCount: 761, srtSpeaker: , srtStartTime: 1527984, srtEndTime: 1538520
1538670
So instead of thinking of accelerating optimization by just adding noise to the system, we can think of exactly how to design local generative models such that there's an optimal misalignment of local and global gradients or local and global generative models in a way that facilitates everyone in the long run actually facilitating or minimizing their free energy.
In writeToMD, lineCount: 761, textOut: So instead of thinking of accelerating optimization by just adding noise to the system, we can think of exactly how to design local generative models such that there's an optimal misalignment of local and global gradients or local and global generative models in a way that facilitates everyone in the long run actually facilitating or minimizing their free energy.
So instead of thinking of accelerating optimization by just adding noise to the system, we can think of exactly how to design local generative models such that there's an optimal misalignment of local and global gradients or local and global generative models in a way that facilitates everyone in the long run actually facilitating or minimizing their free energy.
before writeToSrt(text: So instead of thinking of accelerating optimization by just adding noise to the system, we can think of exactly how to design local generative models such that there's an optimal misalignment of local and global gradients or local and global generative models in a way that facilitates everyone in the long run actually facilitating or minimizing their free energy., srtPosCount: 761, srtSpeaker: , srtStartTime: 1538670, srtEndTime: 1558590
after writeToSrt(text: So instead of thinking of accelerating optimization by just adding noise to the system, we can think of exactly how to design local generative models such that there's an optimal misalignment of local and global gradients or local and global generative models in a way that facilitates everyone in the long run actually facilitating or minimizing their free energy., srtPosCount: 771, srtSpeaker: , srtStartTime: 1538670, srtEndTime: 1558590
1560320
26:00 So yeah, that's just kind of like something I'm putting out there.
In writeToMD, lineCount: 771, textOut: So yeah, that's just kind of like something I'm putting out there.
So yeah, that's just kind of like something I'm putting out there.
before writeToSrt(text: So yeah, that's just kind of like something I'm putting out there., srtPosCount: 771, srtSpeaker: , srtStartTime: 1560320, srtEndTime: 1563184
after writeToSrt(text: So yeah, that's just kind of like something I'm putting out there., srtPosCount: 773, srtSpeaker: , srtStartTime: 1560320, srtEndTime: 1563184
1563222
I'm investigating it now in my own work, but I have no real results on that.
In writeToMD, lineCount: 773, textOut: I'm investigating it now in my own work, but I have no real results on that.
I'm investigating it now in my own work, but I have no real results on that.
before writeToSrt(text: I'm investigating it now in my own work, but I have no real results on that., srtPosCount: 773, srtSpeaker: , srtStartTime: 1563222, srtEndTime: 1566496
after writeToSrt(text: I'm investigating it now in my own work, but I have no real results on that., srtPosCount: 775, srtSpeaker: , srtStartTime: 1563222, srtEndTime: 1566496
1566518
But I just wanted to put that out there in this venue because I think it maybe will inspire other people to think in a similar way.
In writeToMD, lineCount: 775, textOut: But I just wanted to put that out there in this venue because I think it maybe will inspire other people to think in a similar way.
But I just wanted to put that out there in this venue because I think it maybe will inspire other people to think in a similar way.
before writeToSrt(text: But I just wanted to put that out there in this venue because I think it maybe will inspire other people to think in a similar way., srtPosCount: 775, srtSpeaker: , srtStartTime: 1566518, srtEndTime: 1573350
after writeToSrt(text: But I just wanted to put that out there in this venue because I think it maybe will inspire other people to think in a similar way., srtPosCount: 779, srtSpeaker: , srtStartTime: 1566518, srtEndTime: 1573350
1573960
So just to conclude, now, multiscale active inference, I would say, is still largely based on theoretical or philosophical descriptions and illustrious simulations, but we're still lacking a formal theory.
In writeToMD, lineCount: 779, textOut: So just to conclude, now, multiscale active inference, I would say, is still largely based on theoretical or philosophical descriptions and illustrious simulations, but we're still lacking a formal theory.
So just to conclude, now, multiscale active inference, I would say, is still largely based on theoretical or philosophical descriptions and illustrious simulations, but we're still lacking a formal theory.
before writeToSrt(text: So just to conclude, now, multiscale active inference, I would say, is still largely based on theoretical or philosophical descriptions and illustrious simulations, but we're still lacking a formal theory., srtPosCount: 779, srtSpeaker: , srtStartTime: 1573960, srtEndTime: 1585160
after writeToSrt(text: So just to conclude, now, multiscale active inference, I would say, is still largely based on theoretical or philosophical descriptions and illustrious simulations, but we're still lacking a formal theory., srtPosCount: 785, srtSpeaker: , srtStartTime: 1573960, srtEndTime: 1585160
1585740
There's some theory in terms of the renormalization group arguments of the monograph, but they're still, in my opinion, a bit underdeveloped, a little under demonstrated and relying on some restrictive assumptions like the fast and slow fluctuations, the identity between generative model, generative process.
In writeToMD, lineCount: 785, textOut: There's some theory in terms of the renormalization group arguments of the monograph, but they're still, in my opinion, a bit underdeveloped, a little under demonstrated and relying on some restrictive assumptions like the fast and slow fluctuations, the identity between generative model, generative process.
There's some theory in terms of the renormalization group arguments of the monograph, but they're still, in my opinion, a bit underdeveloped, a little under demonstrated and relying on some restrictive assumptions like the fast and slow fluctuations, the identity between generative model, generative process.
before writeToSrt(text: There's some theory in terms of the renormalization group arguments of the monograph, but they're still, in my opinion, a bit underdeveloped, a little under demonstrated and relying on some restrictive assumptions like the fast and slow fluctuations, the identity between generative model, generative process., srtPosCount: 785, srtSpeaker: , srtStartTime: 1585740, srtEndTime: 1602510
after writeToSrt(text: There's some theory in terms of the renormalization group arguments of the monograph, but they're still, in my opinion, a bit underdeveloped, a little under demonstrated and relying on some restrictive assumptions like the fast and slow fluctuations, the identity between generative model, generative process., srtPosCount: 793, srtSpeaker: , srtStartTime: 1585740, srtEndTime: 1602510
1603200
There's a few more recent papers, those two by Kaufman at all and then by myself on spingglass systems that have attempted particular proofs of multi scale Bayesian inference systems in particular situations, but their generality is still not known and not proven.
In writeToMD, lineCount: 793, textOut: There's a few more recent papers, those two by Kaufman at all and then by myself on spingglass systems that have attempted particular proofs of multi scale Bayesian inference systems in particular situations, but their generality is still not known and not proven.
There's a few more recent papers, those two by Kaufman at all and then by myself on spingglass systems that have attempted particular proofs of multi scale Bayesian inference systems in particular situations, but their generality is still not known and not proven.
before writeToSrt(text: There's a few more recent papers, those two by Kaufman at all and then by myself on spingglass systems that have attempted particular proofs of multi scale Bayesian inference systems in particular situations, but their generality is still not known and not proven., srtPosCount: 793, srtSpeaker: , srtStartTime: 1603200, srtEndTime: 1618956
after writeToSrt(text: There's a few more recent papers, those two by Kaufman at all and then by myself on spingglass systems that have attempted particular proofs of multi scale Bayesian inference systems in particular situations, but their generality is still not known and not proven., srtPosCount: 800, srtSpeaker: , srtStartTime: 1603200, srtEndTime: 1618956
1619068
So what I'm kind of trying to conclude with is by saying we need to incorporate findings from other disciplines related to the role of noise, conflict and frustration in facilitating, not subverting collective intelligence or collective coordination.
In writeToMD, lineCount: 800, textOut: So what I'm kind of trying to conclude with is by saying we need to incorporate findings from other disciplines related to the role of noise, conflict and frustration in facilitating, not subverting collective intelligence or collective coordination.
So what I'm kind of trying to conclude with is by saying we need to incorporate findings from other disciplines related to the role of noise, conflict and frustration in facilitating, not subverting collective intelligence or collective coordination.
before writeToSrt(text: So what I'm kind of trying to conclude with is by saying we need to incorporate findings from other disciplines related to the role of noise, conflict and frustration in facilitating, not subverting collective intelligence or collective coordination., srtPosCount: 800, srtSpeaker: , srtStartTime: 1619068, srtEndTime: 1633828
after writeToSrt(text: So what I'm kind of trying to conclude with is by saying we need to incorporate findings from other disciplines related to the role of noise, conflict and frustration in facilitating, not subverting collective intelligence or collective coordination., srtPosCount: 807, srtSpeaker: , srtStartTime: 1619068, srtEndTime: 1633828
1634004
27:14 And I think we can really benefit by looking at these other disciplines to help us build a really powerful formal theory of multiscale active inference.
In writeToMD, lineCount: 807, textOut: And I think we can really benefit by looking at these other disciplines to help us build a really powerful formal theory of multiscale active inference.
And I think we can really benefit by looking at these other disciplines to help us build a really powerful formal theory of multiscale active inference.
before writeToSrt(text: And I think we can really benefit by looking at these other disciplines to help us build a really powerful formal theory of multiscale active inference., srtPosCount: 807, srtSpeaker: , srtStartTime: 1634004, srtEndTime: 1642916
after writeToSrt(text: And I think we can really benefit by looking at these other disciplines to help us build a really powerful formal theory of multiscale active inference., srtPosCount: 811, srtSpeaker: , srtStartTime: 1634004, srtEndTime: 1642916
1643028
And finally, I think we need to set the goalpost for what counts as a formal proof of multiscale active inference.
In writeToMD, lineCount: 811, textOut: And finally, I think we need to set the goalpost for what counts as a formal proof of multiscale active inference.
And finally, I think we need to set the goalpost for what counts as a formal proof of multiscale active inference.
before writeToSrt(text: And finally, I think we need to set the goalpost for what counts as a formal proof of multiscale active inference., srtPosCount: 811, srtSpeaker: , srtStartTime: 1643028, srtEndTime: 1648856
after writeToSrt(text: And finally, I think we need to set the goalpost for what counts as a formal proof of multiscale active inference., srtPosCount: 814, srtSpeaker: , srtStartTime: 1643028, srtEndTime: 1648856
1648968
And once we get there, once we're saying, okay, this counts as proof, this is satisfying, how can we use that to actually do the hardest part, in my opinion, which is engineering actual multiscale active inference systems that are intelligent and minimizing free energy at multiple scales.
In writeToMD, lineCount: 814, textOut: And once we get there, once we're saying, okay, this counts as proof, this is satisfying, how can we use that to actually do the hardest part, in my opinion, which is engineering actual multiscale active inference systems that are intelligent and minimizing free energy at multiple scales.
And once we get there, once we're saying, okay, this counts as proof, this is satisfying, how can we use that to actually do the hardest part, in my opinion, which is engineering actual multiscale active inference systems that are intelligent and minimizing free energy at multiple scales.
before writeToSrt(text: And once we get there, once we're saying, okay, this counts as proof, this is satisfying, how can we use that to actually do the hardest part, in my opinion, which is engineering actual multiscale active inference systems that are intelligent and minimizing free energy at multiple scales., srtPosCount: 814, srtSpeaker: , srtStartTime: 1648968, srtEndTime: 1664720
after writeToSrt(text: And once we get there, once we're saying, okay, this counts as proof, this is satisfying, how can we use that to actually do the hardest part, in my opinion, which is engineering actual multiscale active inference systems that are intelligent and minimizing free energy at multiple scales., srtPosCount: 822, srtSpeaker: , srtStartTime: 1648968, srtEndTime: 1664720
1666020
Yeah, so with that, I'm going to conclude looks like I'm just on time.
In writeToMD, lineCount: 822, textOut: Yeah, so with that, I'm going to conclude looks like I'm just on time.
Yeah, so with that, I'm going to conclude looks like I'm just on time.
before writeToSrt(text: Yeah, so with that, I'm going to conclude looks like I'm just on time., srtPosCount: 822, srtSpeaker: , srtStartTime: 1666020, srtEndTime: 1669824
after writeToSrt(text: Yeah, so with that, I'm going to conclude looks like I'm just on time., srtPosCount: 824, srtSpeaker: , srtStartTime: 1666020, srtEndTime: 1669824
1669862
So, yeah, thank you again for the invitation to present, and I'd like to thank a bunch of people who are listed here and beyond who have influenced my thinking and kind of my opinions.
In writeToMD, lineCount: 824, textOut: So, yeah, thank you again for the invitation to present, and I'd like to thank a bunch of people who are listed here and beyond who have influenced my thinking and kind of my opinions.
So, yeah, thank you again for the invitation to present, and I'd like to thank a bunch of people who are listed here and beyond who have influenced my thinking and kind of my opinions.
before writeToSrt(text: So, yeah, thank you again for the invitation to present, and I'd like to thank a bunch of people who are listed here and beyond who have influenced my thinking and kind of my opinions., srtPosCount: 824, srtSpeaker: , srtStartTime: 1669862, srtEndTime: 1679700
after writeToSrt(text: So, yeah, thank you again for the invitation to present, and I'd like to thank a bunch of people who are listed here and beyond who have influenced my thinking and kind of my opinions., srtPosCount: 829, srtSpeaker: , srtStartTime: 1669862, srtEndTime: 1679700
1680600
If there's time, I'm happy to take any questions.
In writeToMD, lineCount: 829, textOut: If there's time, I'm happy to take any questions.
If there's time, I'm happy to take any questions.
before writeToSrt(text: If there's time, I'm happy to take any questions., srtPosCount: 829, srtSpeaker: , srtStartTime: 1680600, srtEndTime: 1683050
after writeToSrt(text: If there's time, I'm happy to take any questions., srtPosCount: 831, srtSpeaker: , srtStartTime: 1680600, srtEndTime: 1683050
28:06 Daniel:
Awesome.
In writeToMD, lineCount: 831, textOut: Awesome.
Awesome.
before writeToSrt(text: Awesome., srtPosCount: 831, srtSpeaker: Daniel, srtStartTime: 1686700, srtEndTime: 1687450
after writeToSrt(text: Awesome., srtPosCount: 832, srtSpeaker: Daniel, srtStartTime: 1686700, srtEndTime: 1687450
1687980
Great talk.
In writeToMD, lineCount: 832, textOut: Great talk.
Great talk.
before writeToSrt(text: Great talk., srtPosCount: 832, srtSpeaker: , srtStartTime: 1687980, srtEndTime: 1690104
after writeToSrt(text: Great talk., srtPosCount: 833, srtSpeaker: , srtStartTime: 1687980, srtEndTime: 1690104
1690222
I'll just give a few seconds if anybody wants to type in a question.
In writeToMD, lineCount: 833, textOut: I'll just give a few seconds if anybody wants to type in a question.
I'll just give a few seconds if anybody wants to type in a question.
before writeToSrt(text: I'll just give a few seconds if anybody wants to type in a question., srtPosCount: 833, srtSpeaker: , srtStartTime: 1690222, srtEndTime: 1694430
after writeToSrt(text: I'll just give a few seconds if anybody wants to type in a question., srtPosCount: 835, srtSpeaker: , srtStartTime: 1690222, srtEndTime: 1694430
1694800
Also, it's really cool.
In writeToMD, lineCount: 835, textOut: Also, it's really cool.
Also, it's really cool.
before writeToSrt(text: Also, it's really cool., srtPosCount: 835, srtSpeaker: , srtStartTime: 1694800, srtEndTime: 1695932
after writeToSrt(text: Also, it's really cool., srtPosCount: 836, srtSpeaker: , srtStartTime: 1694800, srtEndTime: 1695932
1695986
Like, aswin in the previous session was highlighting Pymdp and just the way in which we enact the collective intelligence.
In writeToMD, lineCount: 836, textOut: Like, aswin in the previous session was highlighting Pymdp and just the way in which we enact the collective intelligence.
Like, aswin in the previous session was highlighting Pymdp and just the way in which we enact the collective intelligence.
before writeToSrt(text: Like, aswin in the previous session was highlighting Pymdp and just the way in which we enact the collective intelligence., srtPosCount: 836, srtSpeaker: , srtStartTime: 1695986, srtEndTime: 1707080
after writeToSrt(text: Like, aswin in the previous session was highlighting Pymdp and just the way in which we enact the collective intelligence., srtPosCount: 840, srtSpeaker: , srtStartTime: 1695986, srtEndTime: 1707080
1707160
Different people seeing a paper where an analytical formalization is introduced, and then there's still so much work to get it to the package, and then so much more work to take it to the last mile.
In writeToMD, lineCount: 840, textOut: Different people seeing a paper where an analytical formalization is introduced, and then there's still so much work to get it to the package, and then so much more work to take it to the last mile.
Different people seeing a paper where an analytical formalization is introduced, and then there's still so much work to get it to the package, and then so much more work to take it to the last mile.
before writeToSrt(text: Different people seeing a paper where an analytical formalization is introduced, and then there's still so much work to get it to the package, and then so much more work to take it to the last mile., srtPosCount: 840, srtSpeaker: , srtStartTime: 1707160, srtEndTime: 1718192
after writeToSrt(text: Different people seeing a paper where an analytical formalization is introduced, and then there's still so much work to get it to the package, and then so much more work to take it to the last mile., srtPosCount: 845, srtSpeaker: , srtStartTime: 1707160, srtEndTime: 1718192
1718256
And I think your presentation really checked a lot of those boxes.
In writeToMD, lineCount: 845, textOut: And I think your presentation really checked a lot of those boxes.
And I think your presentation really checked a lot of those boxes.
before writeToSrt(text: And I think your presentation really checked a lot of those boxes., srtPosCount: 845, srtSpeaker: , srtStartTime: 1718256, srtEndTime: 1722100
after writeToSrt(text: And I think your presentation really checked a lot of those boxes., srtPosCount: 847, srtSpeaker: , srtStartTime: 1718256, srtEndTime: 1722100
1722920
I'll just read a question and then that will just be an appetizer for our continued discussion.
In writeToMD, lineCount: 847, textOut: I'll just read a question and then that will just be an appetizer for our continued discussion.
I'll just read a question and then that will just be an appetizer for our continued discussion.
before writeToSrt(text: I'll just read a question and then that will just be an appetizer for our continued discussion., srtPosCount: 847, srtSpeaker: , srtStartTime: 1722920, srtEndTime: 1730556
after writeToSrt(text: I'll just read a question and then that will just be an appetizer for our continued discussion., srtPosCount: 850, srtSpeaker: , srtStartTime: 1722920, srtEndTime: 1730556
1730688
So Marco Lynn asked, do you expect the inferentially connected dynamics to exhibit behavior akin to theories of multi body systems?
In writeToMD, lineCount: 850, textOut: So Marco Lynn asked, do you expect the inferentially connected dynamics to exhibit behavior akin to theories of multi body systems?
So Marco Lynn asked, do you expect the inferentially connected dynamics to exhibit behavior akin to theories of multi body systems?
before writeToSrt(text: So Marco Lynn asked, do you expect the inferentially connected dynamics to exhibit behavior akin to theories of multi body systems?, srtPosCount: 850, srtSpeaker: , srtStartTime: 1730688, srtEndTime: 1741320
after writeToSrt(text: So Marco Lynn asked, do you expect the inferentially connected dynamics to exhibit behavior akin to theories of multi body systems?, srtPosCount: 854, srtSpeaker: , srtStartTime: 1730688, srtEndTime: 1741320
1741660
And to what extent can we transfer insights from that multi body of work?
In writeToMD, lineCount: 854, textOut: And to what extent can we transfer insights from that multi body of work?
And to what extent can we transfer insights from that multi body of work?
before writeToSrt(text: And to what extent can we transfer insights from that multi body of work?, srtPosCount: 854, srtSpeaker: , srtStartTime: 1741660, srtEndTime: 1746350
after writeToSrt(text: And to what extent can we transfer insights from that multi body of work?, srtPosCount: 856, srtSpeaker: , srtStartTime: 1741660, srtEndTime: 1746350
1747280
29:07 And then second question, just for our thinking and learning from Marco, have you explored integrating work on self organized criticality with multi scale active inference or other frameworks?
In writeToMD, lineCount: 856, textOut: And then second question, just for our thinking and learning from Marco, have you explored integrating work on self organized criticality with multi scale active inference or other frameworks?
And then second question, just for our thinking and learning from Marco, have you explored integrating work on self organized criticality with multi scale active inference or other frameworks?
before writeToSrt(text: And then second question, just for our thinking and learning from Marco, have you explored integrating work on self organized criticality with multi scale active inference or other frameworks?, srtPosCount: 856, srtSpeaker: , srtStartTime: 1747280, srtEndTime: 1761372
after writeToSrt(text: And then second question, just for our thinking and learning from Marco, have you explored integrating work on self organized criticality with multi scale active inference or other frameworks?, srtPosCount: 861, srtSpeaker: , srtStartTime: 1747280, srtEndTime: 1761372
1761436
Who can provide more flexible frameworks or assumptions for a generic notion of multiscale dynamics?
In writeToMD, lineCount: 861, textOut: Who can provide more flexible frameworks or assumptions for a generic notion of multiscale dynamics?
Who can provide more flexible frameworks or assumptions for a generic notion of multiscale dynamics?
before writeToSrt(text: Who can provide more flexible frameworks or assumptions for a generic notion of multiscale dynamics?, srtPosCount: 861, srtSpeaker: , srtStartTime: 1761436, srtEndTime: 1766940
after writeToSrt(text: Who can provide more flexible frameworks or assumptions for a generic notion of multiscale dynamics?, srtPosCount: 864, srtSpeaker: , srtStartTime: 1761436, srtEndTime: 1766940
1767100
Great questions.
In writeToMD, lineCount: 864, textOut: Great questions.
Great questions.
before writeToSrt(text: Great questions., srtPosCount: 864, srtSpeaker: , srtStartTime: 1767100, srtEndTime: 1768130
after writeToSrt(text: Great questions., srtPosCount: 865, srtSpeaker: , srtStartTime: 1767100, srtEndTime: 1768130
1768820
I hope that we can continue, have you back anytime, or just continue to collaborate in the ecosystem.
In writeToMD, lineCount: 865, textOut: I hope that we can continue, have you back anytime, or just continue to collaborate in the ecosystem.
I hope that we can continue, have you back anytime, or just continue to collaborate in the ecosystem.
before writeToSrt(text: I hope that we can continue, have you back anytime, or just continue to collaborate in the ecosystem., srtPosCount: 865, srtSpeaker: , srtStartTime: 1768820, srtEndTime: 1774812
after writeToSrt(text: I hope that we can continue, have you back anytime, or just continue to collaborate in the ecosystem., srtPosCount: 868, srtSpeaker: , srtStartTime: 1768820, srtEndTime: 1774812
1774876
So thank you for the epic talk, Conor, and good luck finishing your PhD.
In writeToMD, lineCount: 868, textOut: So thank you for the epic talk, Conor, and good luck finishing your PhD.
So thank you for the epic talk, Conor, and good luck finishing your PhD.
before writeToSrt(text: So thank you for the epic talk, Conor, and good luck finishing your PhD., srtPosCount: 868, srtSpeaker: , srtStartTime: 1774876, srtEndTime: 1778880
after writeToSrt(text: So thank you for the epic talk, Conor, and good luck finishing your PhD., srtPosCount: 870, srtSpeaker: , srtStartTime: 1774876, srtEndTime: 1778880
29:39 Conor:
Thanks a lot, Daniel.
In writeToMD, lineCount: 870, textOut: Thanks a lot, Daniel.
Thanks a lot, Daniel.
before writeToSrt(text: Thanks a lot, Daniel., srtPosCount: 870, srtSpeaker: Conor, srtStartTime: 1779300, srtEndTime: 1780404
after writeToSrt(text: Thanks a lot, Daniel., srtPosCount: 871, srtSpeaker: Conor, srtStartTime: 1779300, srtEndTime: 1780404
1780452
Yeah, I'll talk to you soon.
In writeToMD, lineCount: 871, textOut: Yeah, I'll talk to you soon.
Yeah, I'll talk to you soon.
before writeToSrt(text: Yeah, I'll talk to you soon., srtPosCount: 871, srtSpeaker: , srtStartTime: 1780452, srtEndTime: 1781720
after writeToSrt(text: Yeah, I'll talk to you soon., srtPosCount: 872, srtSpeaker: , srtStartTime: 1780452, srtEndTime: 1781720
29:41 Daniel:
Talk to you soon.
In writeToMD, lineCount: 872, textOut: Talk to you soon.
Talk to you soon.
before writeToSrt(text: Talk to you soon., srtPosCount: 872, srtSpeaker: Daniel, srtStartTime: 1781870, srtEndTime: 1782550
after writeToSrt(text: Talk to you soon., srtPosCount: 873, srtSpeaker: Daniel, srtStartTime: 1781870, srtEndTime: 1782550
Processed 238 sentences.
