start	end	speaker	sentiment	confidence	text
13740	14290	A	0.546256959438324	You.
16260	19056	A	0.6467900276184082	All right, the next session is going.
19078	24640	B	0.9114217162132263	To be the final session of this symposium.
25140	32130	B	0.9910100698471069	It's been a really incredible journey, and I think this final session is going to be great as well.
32500	52672	B	0.6695536971092224	So we have a whole panel here, and people can use their cameras, even though I'm not if they want to welcome everyone, I'll just introduce the facilitator, Kurt Jamungol.
52756	73504	B	0.9788864850997925	So Kurt is a legend in the active ecosystem and has done incredible work with a variety of researchers and curious individuals in the space, so we could think of no one better to host this conversation and bring it all together.
73702	76630	B	0.8556404113769531	So, Kurt, I'll pass it to you.
77320	79472	B	0.8518095016479492	You'll keep an eye on the live chat.
79536	82992	B	0.8288456797599792	Anyone can call it if they need any supports.
83056	86912	B	0.8786917924880981	Otherwise, thanks, everybody, for joining.
86976	90624	B	0.49584823846817017	And we don't see you yet, Kurt.
90672	93896	A	0.7427205443382263	But yeah, it would it be all right if I left and then came right back?
93918	95480	A	0.9549046158790588	For whatever reason, my camera is not working.
95550	96072	B	0.9471787214279175	Sounds good.
96126	96776	B	0.9471787214279175	Sounds good.
96878	99800	A	0.6979724168777466	Okay, I'll be right back in about 25 seconds.
103200	104990	B	0.9277077317237854	Well, welcome, everyone.
109310	111420	B	0.6559551954269409	We will get started in just a second.
120590	126970	A	0.7930432558059692	It's so odd.
127130	128638	A	0.69130539894104	I apologize for that.
128724	132080	A	0.6967682242393494	Okay, well, you can hear my voice, at least.
132470	136100	A	0.5176910161972046	Yes, just give me a moment.
139030	139778	A	0.5399965047836304	Boy.
139944	146902	A	0.5823925137519836	Okay, well, we'll do what we can.
147036	154102	A	0.7005799412727356	Okay, so you all can't see me, but that's all right.
154236	160810	A	0.5035338997840881	So we have this all star panel here today, which to me means my invitation must have been a mistake, but I'll take it.
160880	162950	A	0.9003056883811951	Thank you to the active inference institutes.
163030	166730	A	0.8119474053382874	And I'll go around this virtual zoom table and introduce everyone briefly.
167150	178714	A	0.6442325711250305	Karl Friston is the welcome Principal Research Fellow and Scientific Director at the welcome Trust Center for Neuroimaging and professor of Neurology at University College London.
178842	181630	A	0.8950273394584656	He's also the chief scientist at Versus.
182290	187266	A	0.8867915272712708	Anna Lempke is chief of the Stanford Addiction Medical sorry.
187368	191134	A	0.9239404797554016	Medicine dual diagnosis clinic at Stanford University.
191262	196790	A	0.8049786686897278	Her popular books include Drug Dealer, MD and Dopamine Nation.
197450	203222	A	0.9264920353889465	Raphael Kaufman is CTO of Digital Gaia and the onboard sorry.
203276	208970	A	0.9151431918144226	And is on the board of directors of the Active Inference Institute.
209390	219530	A	0.8876410126686096	Bert DeVries is a professor at Eindhoven University of Technology, where he directs the Bias Lab research team and also works with industry.
220130	236820	A	0.9354766607284546	Guillaume Dumas is an associate professor in computational psychiatry of the Faculty of Medicine at the University of Montreal and the Director of the Precision, Psychiatry and Social Physiology Laboratory in Chu St.
237510	238162	A	0.509212851524353	Sorry.
238296	240002	A	0.7655705213546753	In the Chu St.
240056	241522	A	0.8918501734733582	Justine Research Center.
241656	253458	A	0.8573818802833557	He's also affiliated with Mila or Mila, which is Quebec's Artificial Intelligence Institute and other art, science and consciousness service initiatives.
253554	260918	A	0.866432785987854	My name is Kurt Chamongle, and I use my background in mathematical physics to analyze various theories of everything that are proposed.
261014	270534	A	0.881076455116272	These include both the theoretical physics side of grand unification with gravity and dualities other schemes, as well as attempting to understand what constitutes consciousness.
270662	276000	A	0.7991447448730469	You can find the podcast by typing in theories of everything onto YouTube or whatever podcast catcher you have.
276610	278206	A	0.7903327941894531	So my question to everyone.
278308	284738	A	0.5519987344741821	The initial question is what have you been working on in the past few months and what excites you about it?
284904	288590	A	0.83394455909729	We'll start with Bert.
288670	293490	A	0.9021093249320984	You seem to be smiling and your name sounds like mine.
337210	337960	C	0.584351658821106	Okay.
338670	342734	C	0.7050955295562744	All right, so my name is Bertovis, and yeah.
342772	347470	C	0.8920880556106567	I lead a lab in an electrical engineering department.
347890	351502	C	0.869953989982605	And so our lab is called Bislab, as you mentioned.
351636	358500	C	0.5809937715530396	So we are interested in Bayesian inference in general, but more specifically in doing it as fast as possible.
359030	369602	C	0.6253718733787537	That has lots of applications outside active inference, also for signal processing and other control systems, but definitely, of course, also for active inference.
369746	388090	C	0.7141080498695374	So half our work over the past few months, but even over the past few years has been on developing a toolbox to support or to get as far as we can go with trying to do real time Bayesian inference or real time free energy minimization and trying it in applications.
388990	396966	C	0.6331325769424438	So that's the work that I try to lead a team of PhD students who do the real work.
397008	402480	C	0.7550334334373474	Of course, I walk around with a cup of coffee, but that's what they've been working on.
404070	404482	A	0.7671424746513367	Great.
404536	406500	A	0.7888386249542236	And Professor Lemke, please.
409270	426920	D	0.6638500690460205	Yeah, well, what I've been working on in the last, I don't know, year or so is spending a lot of time thinking about how it is that a faith framework in particular surrendered to a higher power, improves people's lives.
427610	434054	D	0.5411825776100159	And I've been really struggling to come up with a way of talking about this that is inclusive.
434182	447710	D	0.7746949791908264	Thinking about it, talking about it, it gets to a kind of core piece of it that I'm interested in, which is not so much whether or not God exists and what the proof is or not of whether God exists.
448050	456740	D	0.847765326499939	But really, what is it that changes in people's lives when they undergo a spiritual transformation, when they surrender to a higher power?
457830	461940	D	0.4690961539745331	Why do their lives get better when they do get better?
462310	466430	D	0.6522552967071533	And I'm really new to the active inference world.
466520	470930	D	0.6180239319801331	Daniel Friedman is the one who's introduced me to these ideas.
471010	481180	D	0.9746067523956299	I'm really excited about the ways in which the whole active inference model might help me at least think about what's going on.
482990	484314	D	0.5440005660057068	I'm that's what I'm working on.
484352	487500	D	0.6050700545310974	It's a little weird, but that's what I'm interested in.
488830	489290	A	0.7671424746513367	Great.
489360	495310	A	0.5914442539215088	Professor Friston, you're muted.
496690	499150	E	0.826417088508606	Yes, that's going to be the title of my next book.
499220	506240	E	0.570745050907135	Karl, you're on mute retro from the possibly the future.
507910	515698	E	0.8481144905090332	I generally work on what I'm told to work on, so I'm just trying to list what I've been working on in the past few months.
515864	516894	E	0.49438121914863586	Interestingly.
517022	533930	E	0.5220291614532471	It actually starts with Daniel Friedman and his fascination, along with Axel constant for evolutionary explanations that speak to many of the scale free issues that we've been hearing about in the prior session.
534430	536650	E	0.7473595142364502	So that's what I was working on, really.
536720	551658	E	0.7578225135803223	A scale free approach to understanding temporary nested processes as free energy minimizing processes as a kind of active inference and how that would lead to a variational synthesis of evolution.
551834	576600	E	0.6572445631027222	And then I was told to work on belief sharing by Mahault and colleagues at Versus and worked on that in the context of synthetic language and tried to establish a really simple proof of principle that communication was an emergent property of any free ensemble, free energy minimizing system.
577690	599950	E	0.5186305642127991	And just to open brackets, just to make the observation, it struck me time and time again during the session today how important communication is, whether we're talking about Bert's passing messages or responding to you've got a new posterior, or we're talking about the kind of communication that Mahault was talking about.
600020	601726	E	0.7007039785385132	Well, everybody's been talking about.
601828	612770	E	0.7340999841690063	It does seem to be really, indeed, the Gaia notion of overconnectivity and too much communication or the wrong kind of communication.
613830	626200	E	0.5772852897644043	It does strike me that's quite central to both the theme of the workshop and the specific presentations that we've heard.
626570	648634	E	0.6767929196357727	And then in the past few weeks, working on stuff I think that Bert would be more interested in, which is fast and frugal message passing schemes that enable the evaluation of the expected free energy, not to suffer from the limitations imposed by deep tree searches.
648682	673602	E	0.8034086227416992	So possibly Ashwin has spoken about this earlier on, but you're using ideas from dynamic programming, backwards induction to try and take the pressure off the message passing to get fast and efficient evaluations of the expected free energy in sort of single unit, single agent active inference.
673746	675480	E	0.8652929067611694	What have I been doing this week?
676650	677720	E	0.4924672842025757	Can't remember.
678490	679960	E	0.8270268440246582	That's what I've been doing.
680830	681386	A	0.7671424746513367	Great.
681488	683500	A	0.8616679310798645	Raphael kaufman, please.
688880	690030	A	0.733344554901123	Just a moment.
693200	694750	A	0.8461761474609375	Can everyone else hear?
695680	696430	A	0.584351658821106	Okay.
699800	700980	F	0.8440161347389221	What about now?
701130	702580	A	0.8782029747962952	Yeah, great.
702650	703590	F	0.6345008015632629	Yeah, thanks.
704200	705830	F	0.6601378321647644	It's contagious, I think.
706200	712520	F	0.6417183876037598	So I've also been drinking a lot of coffee as I've been caring for my now nine month old daughter.
714060	715188	A	0.94339519739151	Congratulations.
715364	715992	F	0.8529649972915649	Thank you.
716046	741352	F	0.7686552405357361	So aside from sleep deprivation, what I've been doing is I told you guys about this in the session earlier today, but in a nutshell, we've been working on what we call the Gaia Protocol, or the Gaia network, which is this open approach for building a common engine.
741506	763592	F	0.7118635177612305	Think of it as a common runtime and a common language with the building blocks of shared decision making in the context of the Med crisis, and getting to a set of building blocks for decision making that don't kill us all.
763646	765290	C	0.6104795336723328	So that's kind of it.
766140	769480	A	0.8334886431694031	Rafael, how much coffee is a lot of coffee?
770620	776140	F	0.5720207095146179	Well, it's espresso, so I don't think it's quite comparable to American coffee.
776960	777870	A	0.4896697998046875	All right.
778400	780990	A	0.7470812797546387	And Guillaume dumas, please.
781520	782316	G	0.7282710075378418	Yes, sure.
782418	783630	G	0.8097810745239258	Can you hear me?
784080	784830	A	0.46103888750076294	Yes.
785280	786028	G	0.584351658821106	Okay.
786194	792944	G	0.6052775382995605	So in the context of active inference, I have mostly focused on, well, the two big topics of my lab.
792982	796236	G	0.8166347146034241	So precision psychiatry and social physiology.
796268	796608	C	0.617027759552002	So.
796694	816120	G	0.8615449070930481	On the precision psychiatry side, ninka Boyton presented earlier in this symposium our work on trying to model theory of mind to being able to evaluate, through digital phenotyping, the level of sophistication of interaction in patients with neurodevelopmental disorders.
816460	829180	G	0.6697223782539368	And that connect with also our interest in the social mind and how we can connect our understanding of how we deal with other people but with also ourselves.
829600	847996	G	0.7501189112663269	And so that connect with other work at the mila, with deep learning architecture, with higher order function in humans, where we're trying to combine different theories of consciousness, such as global neural workspace and attention schema theory.
848028	854816	G	0.8154160976409912	And in the context of attention schema theory, there is this kind of recycling of self and other mechanisms.
854848	859396	G	0.6920166611671448	So that's one big work.
859498	864820	G	0.9194371700286865	And on the other side, I'm very interested also in multi agent systems.
864900	880200	G	0.503976047039032	And so with Natalie Castell, who's going to join us soon, we've been working on creativity and the emergence of cultural norms in multi agent systems with the idea of applying that to climate action.
880360	897948	G	0.5806682705879211	And also a new project that is starting here with NFRF of a big Canadian project on Indigenous knowledge and how we can think about new narrative around AI and typically a less solipsistic and individualistic way of dealing with AI.
898124	901590	G	0.8287525177001953	So that's the two main field of research.
902600	910260	A	0.656550407409668	Can you explain what you mean by less solidistic, less solipsistic when it comes to AI.
911900	925008	G	0.7576858401298523	The Californian view of AI, because the narrative is mainly driven by us and California right now tends to circle around optimization profits.
925124	933400	G	0.6645341515541077	I mean, even OpenAI states that AGI is about optimizing profitable human tasks.
933480	936460	G	0.5233241319656372	They put like profitable in their definition.
937460	945040	G	0.7997086048126221	In the case of Indigenous systems of knowledge, we are more talking about community sustainability.
945780	951280	G	0.6129034757614136	And the view already only in the application is less individualistic.
951440	963732	G	0.6483770608901978	But also in the cognitive science point of view, we have the outcore computationalism that could say the brain is just like a computer in a very restrictive sense.
963866	984412	G	0.8174822330474854	And so AI, like, typically those transformers that are massively used right now are kind of like brain in a VAT in a very silicon sense, while we are embodied systems that are constituted by our interaction with others.
984466	994800	G	0.7315102219581604	And so, in a way, how we can think about artificial intelligence in this kind of more co constitutive way and through a developmental and cultural lens.
996740	1003620	A	0.7850463390350342	Okay, now, speaking of the brain as a computer, we frequently hear in these circles the brain as a predictive machine.
1004120	1008820	A	0.5146048665046692	So where does this, the quote unquote brain as a predictive machine have its limits?
1009160	1016200	A	0.8584623336791992	And also, is that to be interpreted as implying conscious experience is a predictive machine as well?
1016350	1017672	A	0.722832977771759	And if not, why not?
1017806	1023930	A	0.8665798902511597	So I think, Karl, you'd be a great person to start this off, and then we'll go around the table again.
1025200	1032220	E	0.8743769526481628	Yeah, I was mindful of Mao's presentation the past half hour and the notion of temporal thickness.
1033440	1039756	E	0.8299325704574585	I'm sure that's got a lot to do with the necessary conditions for the kind of consciousness.
1039868	1043810	E	0.8433344960212708	I'm guessing you're referring to that freedom from the moment.
1044820	1057156	E	0.859218955039978	And if one reads prediction in its sort of psychological or protension nature in terms of being able to predict what will happen in the future.
1057338	1072250	E	0.7701190710067749	I think that's going to be sort of a key bright line between things that do not possess certain kind of sentience and things that do.
1072620	1085720	E	0.7444800734519958	And that bright line just rests basically upon well, from perspective of active inference having a generative model that includes the consequences of your own actions in the future.
1085890	1096956	E	0.6290242075920105	So just by having consequences you're now talking about the future and the consequences in the future now become random variables.
1096988	1099072	E	0.6952297687530518	Therefore you have to infer them.
1099206	1107350	E	0.7524362802505493	Which leads you directly to the notion of planning as inference, which means that bright line is just a difference between things that plan and do not plan.
1108120	1132124	E	0.8278401494026184	And I would guess that that's where you probably want to start in terms of foregrounding the role of prediction as being an aspect of self organization and its sort of reading under active inference that characterizes conscious things from non conscious things, namely the ability to plan.
1132242	1133470	E	0.722870945930481	Does that make sense?
1136820	1138048	A	0.7952554821968079	I have follow up questions.
1138134	1145680	A	0.927812397480011	We'll get to them at some point, but for now, Anna, do you have any comments on that and Bert as well afterward?
1148100	1153968	D	0.7457993626594543	Well, I'm new to this field so I'm just familiarizing myself even with the language.
1154144	1157348	D	0.8103116750717163	But I can respond to the question.
1157434	1172808	D	0.5861801505088806	The brain is a predictive machine in terms of the work that I do clinically and the kind of psychopathology that I see when I'm working with patients, I work primarily with narrative, the stories that they tell about their lives.
1172974	1197292	D	0.7083298563957214	And one of the recurring themes I've seen through my work is that when patients tell stories in which they are perpetually the victims of other people's actions or the world, that tends to be a predictive model for them so that they will then go out into the world and unconsciously create scenarios which will perpetuate their victimhood.
1197436	1211876	D	0.6410427093505859	And that part of getting into wellness is to stop seeing themselves as entirely the victim of other people or circumstance, instead begin to appreciate what they contribute to their life problems.
1212058	1235064	D	0.49603208899497986	So I guess when I think of the limits of the brain as a predictive machine, I think in some ways one of the big limits is that it's a very powerful predictive machine that actually allows us to subsequently shape what actually happens to us and or our perceptions of what happens to us, which then can perpetuate a false narrative.
1235192	1238860	D	0.8282172083854675	And I'll just give one small example from my own life.
1239010	1252068	D	0.9779384136199951	I've had my conflicts with my mother and one of my beefs about her is that she's a very poor communicator and that whenever I email her I either get a cryptic response or no response at all and it drives me crazy.
1252234	1264264	D	0.5530189871788025	And about five years ago she sent an email, asked me some questions, I wrote her back and responded and it was clear to me that that required yet a response from her which I never got.
1264462	1271656	D	0.9515433311462402	And that then perpetuated my narrative about her as a very poor communicator and many other negative things.
1271838	1278044	D	0.6646522283554077	And then about three months after I sent that email, I found the email in my draft box.
1278162	1281212	D	0.6046048402786255	So I had never actually responded to my mother's email.
1281266	1282940	D	0.7159135937690735	I hadn't actually sent the email.
1283090	1304710	D	0.43397149443626404	And that was, for me, just a personal, wonderful example of the ways in which our actions can actually be manipulated to support our models and perpetuate falsehoods about the world that we live in.
1305880	1306340	A	0.5664746165275574	Right.
1306410	1310452	A	0.8990362882614136	And I have a quick question, Bert, just for Anna before we get to you.
1310506	1312148	A	0.6330185532569885	So you use the word narrative there.
1312234	1313968	A	0.7953996658325195	How are you defining the word narrative?
1314064	1315208	A	0.8440266847610474	Is it the same as model?
1315294	1316644	A	0.8670375943183899	Is it a sequence of events?
1316692	1319480	A	0.8186929821968079	Like, what is the specific definition of narrative?
1319900	1322264	D	0.6223752498626709	I never really thought about it in those terms.
1322382	1340080	D	0.5947608947753906	But when I talk about narrative, I'm talking about the stories that people tell about their lives, because that's sort of my data and also about models, because what I've discovered about self narrative is it's not just a way to organize the past.
1340150	1342512	D	0.5767313838005066	It also becomes a roadmap for the future.
1342646	1350290	D	0.8533887267112732	That's the language that I use, but I see it maps very nicely onto Ural's language of modeling the world.
1351380	1351952	A	0.5826064348220825	I see.
1352006	1353510	A	0.7500569820404053	Professor DeVries, please.
1354520	1362550	C	0.5975810289382935	Yeah, it's clear that the ability to predict is the essence of intelligent decision making.
1363720	1365324	C	0.8345221281051636	Yeah, I have a different background.
1365392	1365624	C	0.5664746165275574	Right.
1365662	1368824	C	0.703447699546814	I'm not a psychiatrist, so I think about these things in different way.
1368862	1378584	C	0.57535320520401	The thing that I think about when I think about prediction is I would assume that brain predicts far ahead, that things get less accurate.
1378632	1378892	C	0.5664746165275574	Right.
1378946	1383032	C	0.8208757638931274	If I predict that I want to go three quarters around a roundabout.
1383096	1390160	C	0.6267518997192383	I don't care about the centimeter where my car goes when I'm around there, I just want to get in the right lane.
1390660	1398520	C	0.5141312479972839	And I would assume that the brain doesn't takes less computations if you care about things less precisely.
1398700	1401030	C	0.6760947704315186	But that's very hard in a computer.
1402520	1411232	C	0.9650958180427551	This is what kind of kills us, I think, in our current way of implementing active inference.
1411376	1420788	C	0.6554989814758301	When we want to predict a deep hat, we don't care about the accuracy, but we don't know how to do it much cheaper when things are less accurate.
1420964	1426590	C	0.49320563673973083	And so that's a problem that we need to be working on.
1429920	1446370	C	0.622557520866394	It might be a key to building or to scaling up active entrance agents if we can actually compute messages that we want to know that we don't care about, if they are less precise, that we also spend much less computation on them.
1448440	1449092	A	0.8529649972915649	Thank you.
1449146	1450580	A	0.8094198703765869	Now, Professor Kaufman.
1453480	1456150	F	0.7257062196731567	I am not a professor, but I'll answer anyway.
1457400	1458576	F	0.8537778258323669	Can just call me Rafa.
1458608	1459460	E	0.8004083633422852	Rafa.
1459800	1460212	F	0.5491447448730469	Yeah.
1460266	1472100	F	0.9749183654785156	So there's so many really interesting avenues here, and it's not often that I get the pleasure of discussing this kind of stuff with this kind of diverse crowd.
1472260	1479724	F	0.7522839307785034	But I've been interested in these questions for a pretty long time.
1479762	1504932	F	0.7926997542381287	And I think what comes to mind is how active inference at the lens, for instance, it enables us to get another sense of what nondualist views on consciousness are saying when they get us experientially to notice the difference.
1504986	1517370	F	0.6832460165023804	Between what we actually perceive and between the different various different processes or things that are going on in our head and our tendency to lump them all together into the same okay.
1518940	1521690	F	0.727687418460846	This is my experience that I'm immersed in.
1523360	1543490	F	0.814418613910675	So noticing being able to notice the difference between the process of perceiving and acting and to an extent, it's automated, and the narrative or the various narratives that are going on in parallel in my head, whether I'm aware of them or not.
1545140	1562650	F	0.8207150101661682	And our ability to just put kind of seemingly arbitrary manner levels on top of it, to try to make sense of it all and to force that experience of having multiple narratives and multiple framings going on at the same time make sense of that experience.
1565900	1566328	A	0.598741352558136	In a.
1566334	1570184	F	0.7491323947906494	Way that aligns with our presuppositions about how things are.
1570302	1573530	F	0.9840096235275269	So I think that's super interesting.
1573840	1587004	F	0.892612099647522	I also want to highlight that this view of consciousness as being kind of defined by having a narrative or an internal model that's about self or that at least is about self.
1587042	1599520	F	0.5014256834983826	And that leads, as Karl said, to planning this inference that's actually, like, super deflationary in a way that people are not used to thinking about exciting.
1599860	1610932	F	0.9338898062705994	It's opening the doors to all sorts of exciting interdisciplinary conversations to be had on the basis of at least, I feel like, better, less talking past each other than we've ever had.
1610986	1612470	F	0.9873176217079163	So I'm excited about that.
1613640	1617316	A	0.6308251619338989	And how is it that you're using the word deflationary there, Karl?
1617348	1620104	A	0.8265026211738586	I remember I asked you about that when we had our podcast together.
1620222	1622152	A	0.8390515446662903	But Rafael, similar question.
1622206	1623912	A	0.6470807194709778	So you said deflationary view.
1623966	1630812	A	0.7193171977996826	When we have narratives of self, do you mean us to something that consciousness is much more than sorry.
1630866	1632700	F	0.6947083473205566	Much, yeah.
1632850	1643520	F	0.6588971614837646	It's not necessarily much less than in the subjective sense, but it's perhaps much less than in the scientific sense.
1643590	1665896	F	0.8039006590843201	So one example of not saying exactly that, but maybe something close to what Daniel Dennett calls hetero phenomenology, which is basically the statement that the sum of what one can say scientifically about consciousness is is equal to what?
1665918	1680648	F	0.8204652070999146	Can be studied and modeled and theorized and communicated and learned and agreed upon on the basis of objective data about what people, including you, but also other people say about their experience and, of course, what can be measured.
1680664	1682108	F	0.781432569026947	Up neuro, correlates and whatever.
1682194	1691052	F	0.7286196947097778	Which is not the same as not necessarily the same as our experience of what we think is our direct experience of being conscious.
1691116	1691344	A	0.5664746165275574	Right.
1691382	1702164	F	0.8280847668647766	So one way to look at it is that the science of consciousness doesn't necessarily have to put the primacy on people.
1702282	1708432	F	0.7213393449783325	For instance, people saying they have qualia, that we thought in that sense it's deflationary.
1708496	1709110	F	0.5664746165275574	Right.
1711500	1719770	F	0.5286905765533447	You have to explain why people believe they have qualia, not why people have qualia because it's not necessarily a scientific truth that people have.
1720220	1723880	A	0.7831058502197266	Right, Professor Dumas.
1724720	1725468	G	0.46103888750076294	Yes.
1725634	1736636	G	0.5621182918548584	Well, on the limits of brain as predictive machine, well, we should be always careful to not move from one map territory fallacy to another one for sure.
1736818	1742700	G	0.744515061378479	So we need to be skeptics and avoid to refine the methods.
1742860	1759296	G	0.8454223871231079	And well, this World symposium show how this metaphor is super useful and fruitful, but I can see like two main limits or at least things where we should be careful.
1759408	1775272	G	0.6148088574409485	So following what Professor Lemke said in psychiatry, I think the looping effects and the way people picture themselves can be very unpredictable.
1775336	1793968	G	0.8701149821281433	And so the way we think about the brain as a predictive machine think prediction for patients would have different signification of what we mean by predictive machines in the context of active inference and in general.
1794054	1817496	G	0.6694559454917908	Also, I can see that certain psychologists or anthropologists would have a big appeal all of a sudden for active inference and free energy principles, but taking the words as directly what they think the word mean, where we need to be careful in the way to communicate it.
1817598	1849372	G	0.5017774701118469	And typically following also what Professor Debris said about prediction as being super important for decision making, I think we should be careful about the weirdness of cognitive science and how it doesn't necessarily expand to non Western educated industrialized country, where maybe the cultural value is not about optimization of your decision making or your profit.
1849516	1852704	G	0.7782270908355713	And so that's the first thing where I think we should be careful.
1852752	1869224	G	0.8241757154464722	It's more like a matter of how to communicate the theory in that case, not necessarily a limit of the theory itself, but the second one is about the equivalents or not with other.
1869422	1879420	G	0.871843159198761	Like, I can see we had Mahault Albasan talking about category theory.
1879760	1894480	G	0.8287652730941772	And I'm very curious about right now among the different frameworks that are out there, how can we define what is equivalent or not with active inference to be able to see those limits?
1895460	1911596	G	0.7991946339607239	Maybe we are leaving what happened with quantum mechanics in the early 20th century with different interpretation, with different tools to model quantum mechanics, and here with artificial intelligence and cognitive neuroscience, we have also all those frameworks.
1911728	1926430	G	0.7914246916770935	And I think the limitation would be then to not take this interpretation as the only one, but try to have a cross talk and a differential diagnosis of which one is the best for explaining what.
1928800	1934092	A	0.707947850227356	Okay, now my role is the moderator, but I would like you all to speak to one another.
1934146	1937132	A	0.6413599848747253	So I'm going to ask a question that will serve as well.
1937186	1946032	A	0.7093033790588379	You each will speak on it, but as the other person is speaking sorry, as the other people are speaking, just think, okay, is there a question that I have or is there a comment that I have?
1946166	1964596	A	0.830904483795166	So the question is what are some of the recent advancements or breakthroughs in your respective fields that you find particularly promising and well recent, let's say 2020 till now so we'll start off with Raphael you're smiling and you look like.
1964618	1968040	F	0.8237090110778809	You'Re champion I was thinking what is my field?
1968110	1968296	C	0.7360090017318726	Right?
1968318	1968890	E	0.6113757491111755	Because.
1970620	1989452	F	0.9877817630767822	We'Re very much in the last mile of applying the wonderful stuff that y'all come up with and making it useful on the so I'm extraordinarily excited about research like what Bird is doing.
1989586	2005970	F	0.512067973613739	And I feel like, as Gion was saying, we're also starting to see some convergence on different ways to get.
2007780	2008096	A	0.5319188237190247	At.
2008118	2015480	F	0.8113257884979248	Least the same shape of answers and in some cases, even to the same result.
2015630	2036952	F	0.8239786624908447	So one example of this is work that Chris Fields, Karl and others have been doing on the quantum basically explaining quantum information theory and how it relates to the free energy principle.
2037016	2111476	F	0.49699312448501587	Looking at the free energy principle as the classical limit of quantum information theory and I don't pretend to understand all of it, but as somebody who is coming from a quantum physics background just being alive to see this kind of conversions happening which as I mean, as Guillaume said, we've been at this business of post classical what the hell is going on for over a century now and it's nice to be at a time where again we're starting to talk less past each other and that's from a theoretical perspective, from a practical perspective, I think just finding that we have all the building blocks to create fast, interpretable, reliable and aligned decision making systems which includes AI systems, autonomous systems that have all those characteristics and that it turns out that all the things that the reinforcement learning and deep net neural networks people talk were very hard or impossible are sort of in the realm of what we can do looking at things from an active inference lens and vice versa.
2111508	2130184	F	0.75188809633255	A lot of things that active inference models have incorporated so far, it turns out if you toss in a neural network approximator here and borrow some other massively parallel computation techniques, it also becomes feasible.
2130232	2132460	F	0.7955597639083862	So it's converging.
2133760	2134220	E	0.5491447448730469	Yeah.
2134290	2153590	A	0.829599142074585	For me, what's remarkable is that there's so many domains of what we thought was exclusively human or would be exclusively human for decades that in just the past couple years robots or computers seem to be just as good, if not exceeding us.
2153960	2160404	A	0.7278201580047607	And I don't know if that's promising or worrisome, but anyhow Karl, please, if you don't mind answering the question.
2160442	2161124	A	0.6858871579170227	And then we'll go.
2161162	2163380	A	0.8178945779800415	Anna then Bert and then Dumas.
2165500	2174110	E	0.6314936876296997	Actually, just reflecting upon one of your observations I think it's very difficult to identify one thing.
2175680	2183576	E	0.934545636177063	In a sense, what is impressive is the diversity of advances and applications.
2183768	2217060	E	0.8450528383255005	And I just say that because that's what I was thinking over the past 6 hours, just listening to your amazing presentation after presentation and just noting how diverse and yet there's this common thread, this common commitment, basically stating our curiosity and using the tools that naturalize, that kind of sense making, curious behavior and communication that inherit from sort of either maths or category theory or as Ralph notes now, quantum information theory.
2217140	2220164	E	0.7289225459098816	But just to pick up on a couple of things which are relevant to this conversation.
2220292	2234984	E	0.43560582399368286	So the work with Chris Fields, it sounds lovely and exciting to bring quantum mechanics into active inference, but that's not the move that I think Chris is really wanting to champion.
2235112	2253780	E	0.5135847926139832	The move, I think, is something that we've all been addressing in one way or another, which is leveraging the scale free aspects of this principled approach to self organization and hopefully self organization to some kind of generalized synchrony.
2254200	2258132	E	0.8474562764167786	So that's where the quantum information theory gets into the game.
2258186	2259332	E	0.5533563494682312	It is scale free.
2259386	2264520	E	0.8331851959228516	And indeed, he will go further and say it's completely background free and everything is constructed.
2265260	2274792	E	0.8702588081359863	So I think that's a lovely move, because once you've gone scale free, you then start to ask deep questions about how you couple one scale to another scale.
2274856	2278316	E	0.6409935355186462	And in a sense, ecosystems is just that.
2278418	2283736	E	0.8245048522949219	How do the denizens of an ecosystem, how is it constituted?
2283768	2284936	E	0.8251475095748901	How is it co constructed?
2284968	2286092	E	0.8510364294052124	What is the structure of it?
2286146	2289500	E	0.8323556184768677	These are all questions about how one scale links to another scale.
2289580	2294560	E	0.7889525890350342	So I think there have been lots of advances in that direction in many, many different fronts.
2295060	2305856	E	0.8292843699455261	And you can read that either in terms of coupling, difference of spatial or spatial scales, but probably more importantly, sort of temporal scales.
2305968	2313720	E	0.7224085330963135	And you see that wherever you look, you'll just come back to what do you mean by a narrative?
2314140	2318920	E	0.7715957760810852	It is exactly I think, as I said, it's just a plan.
2318990	2320248	E	0.7324681282043457	It's just a story.
2320414	2323624	E	0.8598216772079468	But notice the story has a temporal aspect to it.
2323742	2328808	E	0.8122191429138184	I have narratives about being a good person, being a good father, being a good scientist.
2328904	2337330	E	0.6997592449188232	I also have narratives about I want my cup of coffee, or I have to go look after the I don't, but Ralph has to go look after the child.
2337940	2342556	E	0.7780696153640747	So we've all got narratives at very, very different timescales.
2342588	2353040	E	0.6801955103874207	And of course, if you're I just came back to Bert's example of I'm an autonomous vehicle and I'm sentient and we're five years into the future, and I have to drive around the roundabout.
2353200	2370520	E	0.8716956377029419	What temporal scale and what kind of temporal course grading to define the narratives necessary with narratives would be appropriate for that kind of situation and the ensuing planning.
2374000	2375532	E	0.779402494430542	Short answer to your question.
2375666	2378140	E	0.727013349533081	I think there have been many, many advances.
2380800	2388610	E	0.7900251746177673	I think what they've had in common is basically transcending either different domains, but in particular different scales of application.
2389060	2391772	E	0.6691170334815979	I also agree with the notion.
2391836	2401844	E	0.7784853577613831	Well, another I think, important and pragmatic advance is something that Bert mentioned, which is democratization of this technology.
2402042	2408550	E	0.5663818120956421	I think Ralph also hinted at this is the time you start using this for the common good.
2410520	2410884	E	0.617027759552002	So.
2410922	2416020	E	0.796932578086853	I think things like RX infer and PMDP.
2416380	2422168	E	0.903775155544281	And I didn't know about the Gaia project, but it sounds as though there's been great advances there as well.
2422254	2432172	E	0.6584360003471375	So this kind of democratization, I think, is really important, this sort of socialization where everybody can play and start to sort of not talk past each other.
2432226	2436880	E	0.9510683417320251	I think that's a very important advance.
2437540	2441436	A	0.8281492590904236	And did you say the word scale invariance or scale independence?
2441628	2443484	E	0.779459536075592	I said scale invariant.
2443612	2446290	E	0.5143372416496277	I actually said scale free, and I shouldn't have done that.
2449640	2451956	E	0.7879590392112732	I said scale free.
2452058	2468568	E	0.8464593887329102	So the idea that you can apply exactly the same mechanics and literally, for example, say, from Bert's perspective, the same kind of message passing at different space time scales or at different levels in a hierarchical model.
2468654	2498690	E	0.7474462389945984	So I've actually got a question for Bert in terms of reactive message passing, because reactive means that you don't have to prescribe the scheduling, but in addressing the problems or the issues that entailed, by having to specify the scheduling of talking or of message passing, you're bound to deal with time.
2499060	2509888	E	0.7965519428253174	And in a scale invariant context, or nested with nested scales, for example, you have to deal with the separation of temporal scales.
2509984	2518616	E	0.5882410407066345	So I think there's going to be a very important generic question, which technically Bert will have been thinking about furiously for the past few years.
2518718	2537580	E	0.8401943445205688	But I think implicitly, we're all going to have to be addressing soon, which is, how do you put the timing of your messages when you make a move or when you listen to a patient, or when you actually pass a message on a Factograph?
2539620	2548656	E	0.822932779788971	How are we going to be able to put the separation of timescales into the architecture in a way that speaks to this scale?
2548688	2562040	E	0.8726298213005066	Invariance the Gear project, for example, how do you integrate live feed from traffic flow sensors with fluctuations in the climate?
2563340	2581180	E	0.841113805770874	This kind of data comes at very, very different temporal scales and yet has to be assimilated and modeled in a way that also, I think, has to know due courtesy to that separation of temporal scales.
2582320	2587390	A	0.8943748474121094	Bert, could you please recapitulate the question for the audience and then begin to answer it?
2588480	2590812	C	0.6095885634422302	Okay, yeah.
2590866	2608500	C	0.5113097429275513	The issue is active instance agents are nested agents, and the higher levels supposed to operate on a larger temporal scale, but they are also working at a lower resolution.
2609320	2614932	C	0.4916129410266876	If you look far ahead, you don't care as much about precision, not at a centimeter level.
2614986	2625310	C	0.6510142683982849	When I go around about, I don't care at the centimeter where I land, but for the next few milliseconds, I do care because it may mean the difference between getting in the ditch or not.
2628720	2639730	C	0.5608474016189575	So the higher level, I want to look very deep ahead, but I don't want to send every millisecond a message to go to look, let's say, a minute ahead.
2640740	2645010	C	0.6955823302268982	So I need to space it out a lot, but then I may miss things.
2646020	2650192	C	0.7125462889671326	So preferably you would just send inaccurate messages.
2650256	2660164	C	0.5691452026367188	But that only works if you actually have a method to also, let's say, use less computational power to compute a less accurate message.
2660282	2663050	C	0.7869123816490173	And we're not good at that yet.
2665340	2687410	C	0.6244184374809265	What we are thinking about is there's a new field or a new field, but there's a field called probabilistic numerics where we are used in math to just compute everything very precisely or as precise as possible and do not care about how much computation we spend on it.
2687860	2694960	C	0.6435624957084656	So in probabilistic numerics, I hope we can leverage this for message computations.
2696020	2704356	C	0.5541487336158752	I would like to spend, let's say, proportionally less computational power on the accuracy of a message.
2704458	2712090	C	0.8280029296875	One way possibly would be to consider a message a latent variable that has uncertainty by itself.
2713260	2719610	C	0.5654563307762146	But I don't have a totally clear answer for Karl because we haven't solved that either.
2720220	2746588	C	0.860064685344696	But there is a problem in, let's say, what we do on our computers were so completely different from computers, let's say, from the from the from the brain, that, yeah, we are spending we're spending just too many computations on messages that in the end are very inaccurate.
2746764	2751430	C	0.8706517815589905	And that's a problem in what we do on our computers currently.
2754120	2754532	A	0.5491447448730469	Yeah.
2754586	2759940	C	0.5323997139930725	So I don't know how we go what you want to do with this on the higher level.
2760010	2771000	C	0.693727433681488	If you want to look maybe ten times farther ahead and spend about the same amount of computation on the lower level, that's sort of our goal.
2772460	2775370	C	0.5395083427429199	But we don't have an answer for that either at the moment.
2778080	2782670	A	0.7162620425224304	Anna so please feel free to comment on or ask a question to.
2784080	2790272	D	0.8267790675163269	I don't I don't have anything to contribute, unfortunately, to how computers work.
2790326	2797200	D	0.7533106803894043	But I can tell you that this idea of temporal scales is something that we face often in our work with patients.
2797780	2811040	D	0.569412350654602	For example, addicted patients are very focused on short term rewards and, in fact, their ability to control how they feel in the moment, that is partially what drives the addiction.
2811120	2823876	D	0.708125650882721	So when I try to adopt Ural's language of minimizing surprise or minimizing free entropy, that's one of the things that people are trying to do on a short term scale when they become addicted.
2823988	2839344	D	0.4528071880340576	So I have a young woman who's addicted to nitrous oxide, which has a very fast onset of intoxication over the order of seconds and a very fast offset, and she says that that's exactly what she likes about it, because she's controlling it second by second.
2839542	2855284	D	0.7493017315864563	So when we work with patients to get them out of that short temporal horizon, we actually rely more and more on action and having them change something in their lives, namely abstain from their drug of choice for long.
2855322	2873160	D	0.5334945917129517	Enough to kind of completely reset their brains and to allow them to see this longer temporal, because when they're chasing this short control, they're actually not able to see themselves in the longer narrative arc of their lives.
2873310	2876344	D	0.7550296783447266	So that's what comes to mind for me.
2876382	2883420	D	0.6717214584350586	I don't think it's going to be helpful to people who are trying to build computers, but that's the kinds of interventions that I make with humans.
2884080	2885820	A	0.7161883115768433	I have a question about that.
2885970	2896940	A	0.6028270721435547	So you mentioned control in the short term, and you've also mentioned that you study the positive effects of having a higher power in your life or surrender.
2897020	2897312	A	0.584351658821106	Okay.
2897366	2900900	A	0.6161553859710693	I kind of gave the punchline away by saying surrendering to the higher power.
2901050	2902740	A	0.6062564253807068	Where I was going was, okay.
2902810	2908372	A	0.7430284023284912	What's the association between seeing yourself in the largest time frame and a higher power?
2908506	2917320	A	0.5804163813591003	And then also is there something that is akin to giving up control when you look farther and farther into the future?
2917390	2923464	D	0.9301907420158386	Such a great yeah, that's at the heart of what I'm very interested in, because it's a real paradox, right?
2923582	2930300	D	0.7936991453170776	It's this kind of locus of control within ourselves that really, in modern culture, we think is a great thing.
2930450	2935368	D	0.8781896233558655	But when that's taken to an extreme and one example of that is addictive behaviors.
2935464	2938268	D	0.9679427146911621	It's very bad for people and for communities.
2938444	2960244	D	0.6105451583862305	And so what can pull people out of that is this kind of surrender to a higher power, giving up that locus of control, locating that locus of control outside themselves, not necessarily like in a theistic sense one of the things that they talk about in Alcoholics Anonymous, for example, is you don't have to believe in God.
2960442	2961910	D	0.7593351602554321	It's just not you.
2962440	2963760	D	0.5635535717010498	You're not driving it.
2963850	2987260	D	0.7217504382133484	And so I would be very curious, from the perspective of Ural's understanding of active inference and the free energy principle and how the brain works, why is it that sort of embracing our inability to control what happens in our lives can actually be the very source of healing, especially embedded in this really kind of over controlled?
2987700	2991276	D	0.7532509565353394	I would even go so far as to say endemically narcissistic culture.
2991388	2992908	D	0.6569117903709412	I'm really curious.
2993084	2996928	D	0.8535829782485962	I don't want to take the conversation in a direction please.
2997014	2998412	A	0.8634811639785767	That's a fantastic question.
2998486	3001590	A	0.8318261504173279	So if anyone has a comment on that, please.
3005860	3015956	F	0.8249262571334839	I have some thoughts, and I think this applies both at the personal level and at the global level.
3016058	3030292	F	0.7930698990821838	And I think it has to do with my quote from earlier by Edward Fulbrook that if you're falling from a plane, yes, maybe an altimeter and some instruments might be useful, but what you really need is a parachute.
3030356	3030584	F	0.7360090017318726	Right?
3030622	3042540	F	0.8225628733634949	So we have this presupposition that whatever framing we have operating in our day to day is going to be, okay.
3042610	3043496	F	0.7029157876968384	This is the right framing.
3043528	3056908	F	0.7283757925033569	And it tends to be this rational, scientific framing of very linear cause and consequence for most stuff.
3057074	3070144	F	0.46244534850120544	And it turns out that even if you inspect our day to day behavior, bigger, more complicated models are not necessarily better, which is where we get the success of heuristics under bounded computation.
3070192	3071540	F	0.7364460229873657	Bounded rationality.
3072360	3085300	F	0.6435132622718811	And if you scale it up to 8 billion humans interacted in resource constrained planet, a world of possibilities, but also of challenges.
3085380	3089690	F	0.5277861952781677	Then we have to drastically lower.
3091660	3092024	G	0.6009463667869568	Our.
3092062	3095708	F	0.8459546566009521	Bar for, yes, how much macro we have.
3095794	3101256	F	0.7528987526893616	But also even where does information gathering reach diminishing returns?
3101288	3104440	F	0.7749046683311462	Where does modeling reach diminishing returns?
3104600	3111904	F	0.786560595035553	There's a whole literature in the business world about the expected value of information, how much you should actually invest.
3112102	3128520	F	0.7324157357215881	Also in science is also known as optimal experiment design, where basically acknowledging that you have limited budget in terms of how much you can act and how much you can probe and how much time you can spend thinking about stuff.
3128670	3149004	F	0.5062406063079834	And I think what we're doing when we feel like, burned out or exhausted from overthinking, we're innately feeling that, okay, we've gone too high and we need to give ourselves a vacation, give ourselves some free time here.
3149122	3165536	F	0.6507271528244019	I think that doing this principle in a principled way, we're just not just like, taking the heuristics and the signals that we inherit from evolution, but actually being able to figure out collaboratively and with some rigor.
3165648	3176548	F	0.6260085105895996	Okay, we don't need to know exactly how many degrees the world is going to warm by 2000 and 2100.
3176714	3183512	F	0.6929219961166382	In order to know that maybe it's a good idea to start doing something about the amount of carbon in the atmosphere or whatever.
3183566	3184170	F	0.7360090017318726	Right?
3184700	3193710	F	0.8038889169692993	And so I think this leads to this idea of a real knowledge economy and of things like abstraction as a service.
3196000	3214230	F	0.7679895758628845	How can you actually build in these kind of sophisticated, sophisticated translation layers that take some of this burden from ourselves as individuals and even as organizations, right?
3214600	3219990	F	0.575900673866272	And just put it out in the world as value added services, which is what they are.
3221640	3227610	A	0.7626532912254333	And Guillaume, if you have any statements or questions or retorts, then please feel free.
3228220	3229160	G	0.6345008015632629	Yeah, thanks.
3229310	3236360	G	0.5777106285095215	Now, I was still also thinking about the recent breakthrough post 2020 in Action France.
3237900	3243390	G	0.9631535410881042	To me, there were theoretical progress that were very interesting.
3243760	3251820	G	0.8782802224159241	We heard already about the formalism maturity at the mathematical level between multiscale and scale free aspects.
3252980	3258288	G	0.9669592976570129	I really liked also the development of a more multi agent perspective of active insurance.
3258374	3266432	G	0.9686573147773743	It's very interesting, especially like, for instance, seeing multi agent systems.
3266496	3281016	G	0.8679249286651611	We just heard about even society as a wall, like as many as one system or many as many subsystems, and how we can use maybe those formalisms to also deal with policy making.
3281198	3287480	G	0.9497786164283752	That's very interesting venue and the emergence of norms, culture and ideas also.
3287550	3297660	G	0.6341057419776917	Because one thing that I'm still struggling with in the case of active insurance models is like how to get outside the checkerboard.
3298800	3308192	G	0.6954205632209778	You can put a lot in the model, a priory, and how you make the model, creating new stuff that is not becked inside.
3308326	3317120	G	0.9352271556854248	At the first and on that one very interesting breakthrough was the application of active inference to morphogenesis.
3317200	3322720	G	0.949702262878418	I really like the work that has been done on that and on the technical aspects.
3322800	3346828	G	0.847442090511322	I think the two main focus that I love are all the deep active inference and how to scale up active inference because it's a strong limitation for the adoption of the formalism if it's not scaled enough compared to other framework like deep learning and then the link with empirical data.
3346914	3355090	G	0.9566718935966492	I really like, for instance, the work of Ryan Smith and how to connect with electrophysiology and clinical data.
3355460	3368900	G	0.5633556842803955	And I think it's also something very important to anchor the theory in the real world and have falsifiability and empirical validation of those models.
3369640	3372630	A	0.8545347452163696	And what are some of the applications of active inference to.
3375640	3376196	G	0.6590757966041565	So?
3376298	3378424	G	0.6216351389884949	Well, I'm not the expert here.
3378462	3380664	G	0.5568253397941589	Karl would be the best to answer that.
3380702	3391020	G	0.7919391393661499	But I was referring to the work with Michael Levin and how a model can help to create a sort of embryogenesis.
3392560	3397310	G	0.5619913935661316	So maybe, Karl, you can explain better than me, please.
3398720	3405984	E	0.5102192163467407	I don't have a reputation for explaining things very clearly, but yeah, that's absolutely right.
3406182	3432276	E	0.6766906976699829	It was just at work with Michael Evan and colleagues showing that you can get quite expressive and bimimetic pattern formation and movement of different cells into an organization often described in terms of morphogenesis simply by communicating your beliefs.
3432468	3436804	E	0.6264755725860596	So I'm coming back to this sort of cross cutting theme of communication.
3436932	3453568	E	0.8587870597839355	So if you just broadcast your beliefs and you're a little cell and there are a little ensemble of cells, and they all have the shared generative model that includes if I was in this position, I would sense that.
3453734	3465812	E	0.5905413627624512	Now, they all have exactly the same generative model, the same predictions, the same expectations, and they're all broadcasting their beliefs about where they are.
3465946	3480360	E	0.8068655133247375	And the free energy minimizing solution is just when they're all in a place such that they receive signals that they would expect to receive when they're in this place.
3480510	3486424	E	0.8223617672920227	And of course, if that is the same for everybody, there's only one arrangement where each cell finds its place.
3486462	3500940	E	0.7469518184661865	So basically, knowing your place is an emergent property of making the world mutually predictable through, yeah, a deflationary account of morphogenesis.
3502080	3507212	E	0.7213598489761353	But Gim, I thought one of your units is precision psychiatry.
3507276	3510684	E	0.8737520575523376	So I thought you're going to talk about precision, so I'm going to do a Guillem.
3510732	3515344	E	0.8930467963218689	Now, he talked about morphogenesis, I'm going to talk about precision.
3515392	3515990	E	0.522394597530365	Now.
3516760	3527500	E	0.9192489385604858	I think that's a really nice way just to pick up on themes which everybody's just mentioned, in particular the pathology of precision.
3527680	3537796	E	0.8714636564254761	And by precision you can read precision in the sense that Bert was talking about in terms of do you use an unsigned integer or a double?
3537988	3541624	E	0.8600202202796936	How much can I coarse grain to my numeric representation?
3541752	3551472	E	0.8640922904014587	Or you can use it in terms of coarse grading in the sense of the renormalization group chunking things in hours or years as opposed to milliseconds and minutes.
3551606	3561260	E	0.8815034627914429	Or you can look at it in terms of a statistician describing the reliability or the inverse variance of a signal.
3561340	3570848	E	0.7711184024810791	And of course we have to estimate that when I say we I mean your agents and statisticians and act accordingly.
3570944	3590750	E	0.552243173122406	And certainly in the work of Ryan Smith on addiction, much of the sort of mathematical explanation for these addictive locked in OCD like phenomena rests upon a failure to get that course grading that precision estimation right.
3592480	3613830	E	0.6674178242683411	The reason I wonder whether it be just worthwhile revisiting addiction and psychopathology or certainly pathology of behavior from the point of view of getting precision wrong and certainly assigning too much precision to low level processing, which is what Bert wants to avoid doing.
3615080	3628564	E	0.5648032426834106	It just strikes me that that kind of story also has mileage in terms of why we are in a state of paralysis when it comes to climate change because I also noticed, Guillermo, that you talked about climate action.
3628612	3632984	E	0.7236334085464478	I've never heard that before, but that seems to me to be the important thing.
3633102	3636340	E	0.6038588881492615	Why isn't there any climate, Anna?
3636420	3640952	E	0.6448652148246765	You know, it'll be like you going to the clinic and finding someone with Parkinson's disease.
3641016	3642910	E	0.7201746702194214	Why isn't this person moving?
3644960	3656576	E	0.6302475929260254	And interestingly, the computational explanation for Parkinson's disease is assigning too much precision to the evidence that you're not moving before you move.
3656758	3674096	E	0.7077995538711548	So if you can't ignore the fact that nothing is changing, all your prior beliefs, your predictions that I am going to stand up or going to initiate walking, don't get a looking because they are immediately cancelled because you've assigned too much precision to the lower level processing.
3674208	3693310	E	0.6115350723266602	And I'm just wondering whether that kind of pathology is exactly what Ralph is trying to reverse by having models at hand, recommendations at hand that provide a more coarse grained view of things, a deeper view.
3696160	3698030	A	0.8806780576705933	Anna, would you like to comment on?
3699680	3717170	D	0.7062744498252869	I love this idea of the pathology of precision because I think it manifests in so many different ways not just among my patient population but I think it's almost like a cultural sickness, in a way.
3718280	3726240	D	0.6440631151199341	The ways in which we seem, like obsessed with certain types of data and we're missing the big picture.
3726320	3728596	D	0.8539292216300964	So I'm going to think more about that.
3728618	3730200	D	0.5938931703567505	I'm going to read more about it.
3730350	3732004	D	0.9592452049255371	I really appreciate the discussion.
3732052	3734568	D	0.8820180296897888	It's interesting for me and Adam when.
3734574	3744476	A	0.5900130867958069	You'Re referring to the pathology of precision, do you mean so in a more conscious sense that we're over evaluating something that we don't need to?
3744658	3757890	A	0.5001717805862427	Whereas, Karl, you're referring to it in an unconscious sense like the brain is putting too much precision on something because in Parkinson's it's not like you consciously are putting precision in a place.
3759220	3763212	D	0.8457247018814087	Well, I think you could look at it sort of like in both cases.
3763276	3767728	D	0.7902886867523193	When I think about addiction, people aren't doing it consciously.
3767824	3775460	D	0.5592389702796936	It's that they really do see this as adaptive and healthy and also even on some level that they can't do otherwise.
3775880	3780392	D	0.9112194776535034	And they're not able to see the true impact of their drug use on their lives.
3780446	3784036	D	0.8792465329170227	They're genuinely not able to see the negative consequences.
3784228	3789100	D	0.6518481969833374	And that's what contributes to getting caught in that vortex.
3789440	3794712	D	0.8716732859611511	But I mean, you could also see it as part of what's happened culturally.
3794776	3802572	D	0.7810426950454712	Like, for example, the whole wellness industrial complex, the way that we now count ourselves through all these different devices.
3802636	3813192	D	0.6015042066574097	And if we could just count our breathing and count our heart rate and take supplements, then we would somehow reach some levitating state of precise wellness.
3813356	3818550	D	0.5058466196060181	I don't know, this is all kind of new ideas for me.
3819160	3819940	A	0.9033102989196777	That's interesting.
3820010	3825892	A	0.8381814360618591	So you believe that we can be inundated with health data and that's detrimental to us?
3826026	3826904	D	0.5544491410255432	Oh, absolutely.
3827022	3828650	D	0.5968801379203796	I see that all the time.
3829260	3835290	A	0.8387527465820312	So for me, I used to have maybe I'll take this out of the well, this is going out live.
3835740	3840436	A	0.8122221827507019	Okay, let me figure out how to say this diplomatically.
3840468	3845480	A	0.8719610571861267	I used to have a device that would measure my heart rate, let's say that and my sleep.
3845560	3851996	A	0.8906213045120239	And instead of improving my sleep, it led to me becoming obsessed with it and then noticing, oh, I didn't sleep well.
3852098	3857888	A	0.8867899179458618	I must not be feeling good today as well because apparently there's a high connection between how your sleep quality and.
3857894	3864096	D	0.6374050378799438	How well you plus added to that the other layer that I should be able to control it.
3864198	3864656	D	0.5664746165275574	Right.
3864758	3873750	D	0.71177077293396	So with all of this data and information, I should be able to, I don't know, reduce free entropy or whatever, reduce surprise, as you guys talk about.
3874920	3891470	D	0.7173566222190857	And I think that's obviously that only goes so far and then can actually contribute to our misery because why aren't we all levitating like the Buddha or whatever when we have all these tools and we can pay attention to all this data?
3893040	3896940	A	0.7012215256690979	I see this also with people who have productivity tools.
3897600	3900392	A	0.6593425273895264	Not only that, but mechanical keyboards.
3900456	3910060	A	0.7774641513824463	Let's say the reason why I don't have a mechanical keyboard, even though I think I'd love it, is because I know that why the heck do I care about the clicking sound of a keyboard?
3910140	3915700	A	0.7824024558067322	But if I got one, then I'd be like, well, what's the difference between clicking sound A versus clicking sound B versus clicking sound C?
3915770	3923792	A	0.4624984860420227	And I'd become obsessed with the trappings of productivity that is sharpening, so called sharpening the axe rather than cutting down the tree.
3923936	3926336	A	0.5735738277435303	There's this phrase that is apocryphal.
3926368	3937320	A	0.750272810459137	And it said it's attributed to, I think, Lincoln, which is that he'd spend 80% of his time or half the time sharpening the knife than cutting the tree.
3938780	3943032	A	0.5045545697212219	And then this is just echoed in productivity circles, but it can't be the case.
3943166	3945288	A	0.6985852122306824	Why would you spend so much time sharpening your axe?
3945304	3947352	A	0.7893106341362	Like, look at anyone who cuts down a tree with an axe.
3947416	3950700	A	0.5004327297210693	Most of the time they're not doing that anyhow.
3951140	3957810	A	0.8496293425559998	So if anyone has any comments on what was just said, please can I.
3958260	3961808	C	0.8237723112106323	Just talk what I find exciting in my field about access?
3961894	3975220	C	0.5969645380973816	Sure, yes, I read it's a long time ago, but there was a paper and it's about that it says, well, active inference is not really a scientific loop because it's biased.
3976520	3983290	C	0.9424859881401062	And I read that, and the sound of the paper was kind of so it's not good.
3983660	3987796	C	0.5728622078895569	But I think active inference is maybe not a science loop.
3987828	3991976	C	0.668626606464386	It's an engineering loop because there's bias, and we need bias in engineering.
3992008	3992764	C	0.741153359413147	We need to make stuff.
3992802	3993644	C	0.7160129547119141	We need to build stuff.
3993682	3995128	C	0.581762969493866	We need to have a bias.
3995304	3997832	C	0.7963520288467407	So it's an engineering design cycle.
3997976	4000670	C	0.735687255859375	I see that everywhere around me.
4002100	4009084	C	0.8592832088470459	And active inference could be a complete breakthrough in in engineering.
4009132	4009730	C	0.5664746165275574	Right.
4010260	4014316	C	0.8751546144485474	The fields around me are signal processing.
4014348	4022180	C	0.8099072575569153	I am myself in a signal processing department or group, and everybody builds algorithms.
4022680	4023764	C	0.5945829749107361	For us.
4023962	4027048	C	0.8389108777046204	In active inference agents, it's inference over states.
4027214	4030740	C	0.7773320078849792	Then the floor below me, they build control systems.
4030820	4032680	C	0.6289231181144714	Well, it's inference over actions.
4033100	4036040	C	0.800794780254364	Then other people are working on machine learning.
4036110	4037880	C	0.6395280957221985	It's inference over parameters.
4038940	4042024	C	0.7268259525299072	Active inference could be and you like this, Kurt.
4042072	4049368	C	0.5532838702201843	It's a very deflationary view on engineering, because everything is just inference.
4049544	4073396	C	0.7354980111122131	And so rather than building algorithms everywhere, if we become really good at implementing minimization, we will be able to build a great engineering design cycles, and we'll be engineering better machines for medical procedures or for other things that are important.
4073578	4078500	C	0.9265850782394409	So it has a tremendous application potential in engineering.
4079480	4086980	C	0.7163891196250916	In engineering, and I think in many fields, people have sort of drifted in different directions.
4087140	4088924	C	0.7656853199005127	Control theorists have.
4089042	4093784	C	0.7544459104537964	I mean, they do almost the same thing as signal processing people, but they speak a different language.
4093832	4094430	E	0.522394597530365	Now.
4098480	4109250	C	0.7000057697296143	Signal processing people, it's a completely different group for the machine learning people, but it's all information processing, and this field can bring it together.
4112980	4124672	C	0.6009672284126282	But the thing is that in order to make it successful in engineering, we need to build an application that impresses.
4124736	4125444	C	0.7360090017318726	Right?
4125642	4127984	C	0.5031108856201172	It's not like a TicTacToe thing.
4128122	4134840	C	0.47968336939811707	It really needs to impress people, needs to be better than some other control systems.
4135180	4144652	C	0.6367529630661011	But once we do that, I think there is tremendous application potential because there haven't been enormous breakthroughs in signal processing and control.
4144706	4150510	C	0.5075213313102722	The last big breakthrough, I think, was Kalmont filtering, and this was 1960s.
4152580	4157600	C	0.5213162302970886	It's kind of funny that the essence of what we do in active influence is also carbon filtering.
4160180	4166560	C	0.9488848447799683	I think there's tremendous opportunities for what we do here for engineering.
4168520	4170390	C	0.9707399010658264	That's why it's exciting to me.
4171880	4174672	A	0.9134047627449036	Anna, do you mind expanding on what you said about acting?
4174736	4177736	A	0.7603315711021423	And therapists should be helping their patients with that.
4177918	4179272	D	0.4803182780742645	Oh, sure.
4179406	4179896	D	0.6117218732833862	Just so.
4179918	4194940	D	0.6473096609115601	I mean, one of my critiques of mental health treatment today is that there's not enough encouragement of patients to actually go and act differently in the world as a way of gathering data.
4195010	4204864	D	0.6521879434585571	Instead, it often ends up being kind of this world building between therapists and patients, not necessarily ultimately adaptive in the world.
4204902	4208816	D	0.8695582151412964	So I was really just kind of responding to what Raft was saying, that we need to act in the world.
4208838	4218896	D	0.518301248550415	I think that's more true now in modern rich nations than ever before because we are so incredibly sedentary and interacting.
4218928	4224212	D	0.4727707505226135	Of course we're interacting with a virtual world, and that's good and bad.
4224266	4228250	D	0.7886316776275635	But I think we need to be actually acting in the world.
4231100	4234228	A	0.8329582810401917	And so there's different forms of therapy.
4234324	4240776	A	0.9007386565208435	As you know, there's talk therapy, and then there's also cognitive behavioral therapy or psychotherapy and sort of talk therapy.
4240968	4245592	A	0.836136519908905	But cognitive behavioral therapy, as far as I understand, focuses on the actions.
4245656	4246780	A	0.644618809223175	Is that incorrect?
4248400	4250632	A	0.840114951133728	It also focuses on model buildings.
4250696	4255628	D	0.762590765953064	On the cognition, again, treating addiction.
4255804	4262172	D	0.5670552253723145	You're not going to really get that far with cognitive behavioral therapy or anything that's focused on just emotions and cognitions.
4262236	4273430	D	0.6908456683158875	People have to go out and actually try stop using their stopping their substance or their addictive behaviors and gather data from that experience and then come back and process it.
4275960	4284680	A	0.8503068089485168	So, Anna, in your field and this question will go to everyone, but in your field and what you study, where is the largest gap that you would like to see closed?
4285660	4289372	D	0.9028589725494385	Well, I mean, we're facing a huge mental health crisis now.
4289426	4296344	D	0.9078037738800049	We have more and more young people coming in with depression, anxiety, suicidality, addictions of all sorts.
4296392	4304124	D	0.5790303945541382	And these are not necessarily people who are struggling by virtue of trauma or socioeconomic disparity.
4304172	4307372	D	0.5354462265968323	These are people who have really privileged lives in many instances.
4307436	4312624	D	0.584118127822876	So it's really a puzzle what is going on for people.
4312662	4318912	D	0.828203558921814	And I think a big part of it is the fact that people are not having embodied experiences.
4318976	4322070	D	0.6878002882003784	They're not having experiences in the world.
4323320	4331880	D	0.6902710199356079	And also the experiences that they are having are these kinds of very quick fixes and fast pleasures.
4334300	4335316	A	0.8453422784805298	Are you noticing?
4335428	4347432	D	0.5617285370826721	I think the co created sort of models through healthier communication that allow people to feel part of a community and also to have truthful co created narratives.
4347576	4352030	D	0.6879606246948242	Trying to use the language here, I think that's really important.
4352480	4355424	D	0.6738364100456238	So, for example, one of the things Bert mentioned, what he's excited about?
4355462	4367204	D	0.9735788106918335	One of the things I'm excited about in the field of addiction medicine is mutual support and the proliferation of things like Alcoholics Anonymous, but also other mutual help groups, a lot of them existing now online.
4367402	4380650	D	0.5708804726600647	And the way that people are together creating healthier narratives and acted together to counteract a lot of the unhealthy narratives that I think are driving a lot of decision making today.
4382860	4395470	A	0.49604037404060364	I wanted to know, is there a correlation between the rise in mental health or, sorry, mental illness or mental health issues, whatever we want to call it, and a certain trait of people?
4396720	4400188	A	0.6795987486839294	Is it affecting the population the same?
4400274	4405616	A	0.5236015319824219	So the whole population is raised 20% in terms of how many mental health issues they have per year?
4405718	4408752	A	0.595541775226593	Or is it affecting people who deal with abstractions more and more?
4408806	4414704	A	0.7676200270652771	So, for instance, we're talking over zoom and some people study abstractions just like us.
4414822	4422912	A	0.8183950185775757	And then there are some people whose work it is to do something physical like running or swim?
4423056	4427140	A	0.7288474440574646	Is it affecting everyone equally or are you noticing that there's some broad trend?
4427640	4438330	D	0.8522568345069885	Well, the broad trends that are out there are just correlational, but the more time that people spend in the virtual world, the more likely they are to suffer from depression, anxiety and other mental health problems.
4439820	4452560	D	0.6888889670372009	People haven't really been able to narrow that down to specific content, but they have been able to save just the sheer amount of time that spending that you're spending online increases your risk for certain poor mental health outcomes.
4455060	4455712	A	0.584351658821106	Okay.
4455846	4462144	A	0.8498967885971069	Now, Karl well, again, if anyone has any comments or questions, please just raise your physical hand.
4462182	4466390	A	0.5831347703933716	I can see raph ralph raphael sorry.
4466840	4486410	F	0.553649365901947	I was just going to say that I think another notable trend is, and I just saw somebody say this on YouTube just yesterday, that young people are disproportionately affected by things like climate grief because they're the ones that are going to be alive to deal with it.
4488160	4503344	F	0.8384222984313965	And I think that applies more generally that Peter Sanghi already like 30 years or something ago, wrote about the Inescapable Network of neutrality, the reality that what we do affects each other.
4503462	4503888	F	0.7360090017318726	Right?
4503974	4509680	F	0.5950109362602234	And we took advantage of this huge resource buffer that's called the biosphere.
4512340	4512752	A	0.6189414262771606	And.
4512806	4520244	F	0.7005786895751953	Earth to pretend that it didn't for quite a long time and got a lot of mileage out of it.
4520282	4541950	F	0.43813711404800415	But now we're at a point where there's a whole generation of people that are coming to grips with the fact that I'm going to stop myself from saying a square word, but oh my God, we actually need to change everything about everything that we do and we need to do it fast.
4543200	4544350	F	0.608309805393219	By the way.
4548400	4555004	F	0.8098418116569519	It's not just what we do out there, it's also what we do inside, how we get ready for how to show up for life internally.
4555052	4555216	E	0.7360090017318726	Right?
4555238	4558204	F	0.7028414607048035	So no wonder that it has that impact.
4558252	4565280	F	0.553006649017334	Like myself, I've dealt with anxiety and a lot of other things.
4565430	4570676	F	0.8205774426460266	We've had conversations about what are we doing bringing a daughter into this world and all these kinds of things.
4570698	4576810	F	0.6593267917633057	And I think it's only natural that it's coming to a head in this way right now.
4578860	4582970	A	0.6081175208091736	Naom you have your hand up and I can't see yes.
4584060	4599550	G	0.7083476781845093	Yeah, it's connect with what has just been so and your initial question about the gaps that needs to be closed, I think like a scale free model of health and mental health particularly would be great.
4600820	4618468	G	0.5121433734893799	We are in silos, in biomedical research and the fact that someone is having depression can come from interacting genes as much as interacting people and also is related to climate change and so on.
4618554	4637572	G	0.665270209312439	So how we can have a new health systems that doesn't deal with those silos and integrate those different scales, to me it's like really a big challenge, but a challenge that current models and work that we can see going that direction.
4637636	4638936	G	0.9597502946853638	And I'm very enthusiastic.
4638968	4639790	C	0.7633740901947021	About that?
4642240	4643180	A	0.6153408288955688	Bert.
4648030	4648780	C	0.5491447448730469	Yeah.
4651550	4662830	C	0.7995573878288269	In my field in engineering, active inference is not understood because almost all papers are written by neuroscientists and they're hard to read.
4662980	4666862	C	0.9891300201416016	So I was really happy to hear today that.
4666916	4673022	C	0.8912635445594788	And I think it's Sanjeev Namjoshi who is writing an engineering book on active inference.
4673166	4675460	C	0.8521652221679688	So I think that will really help.
4676550	4696758	C	0.8869121074676514	That, together with the availability of good toolboxes for implementing active inference, should make a lot of engineers much more enthusiastic about active inference because it's not something that is not understood at the moment in engineering circles.
4696854	4700060	C	0.9814662933349609	So I hope that the book will be good.
4700590	4702640	C	0.9533345699310303	I'm enthusiastic about that.
4704530	4712400	A	0.7689710259437561	And Karl, where are some gaps in your research that you'd like to see?
4716630	4717566	E	0.7140780687332153	More than gaps?
4717598	4722690	E	0.6201133131980896	There's a whole empty space out there yet to be explored.
4723110	4762990	E	0.646523118019104	But in terms of what seems to be emerging from the session and specifically the past few answers, it does seem to be important to have this very generic just to take Bert's sort of line that this is just one deflationary simple and probably the right way to understand stuff and to make recommendations or to describe people's actions, possibly to themselves in a therapeutic context.
4763570	4769630	E	0.5304107069969177	And as such, it should be push button technology and it should be democratized and socialized.
4769710	4773730	E	0.7301254868507385	And I think that's the challenge, practically.
4774070	4777300	E	0.5427367687225342	And 1 may ask, why would you want to do that?
4777610	4782710	E	0.7967162728309631	For me, there are two clear imperatives.
4783290	4791846	E	0.603139340877533	One is very abstract, and it's not really within my comfort zone, and the other one is in my comfort zone.
4791878	4806240	E	0.6927672624588013	But the one that's outside my comfort zone is this notion of interactivity and hyperconnectivity and the metacrisis that we heard about.
4807490	4819860	E	0.8546994924545288	And Aguim also referred to this in terms of what he was trying to distinguish between a Californian notion of optimality and another kind, another way forward.
4820390	4828130	E	0.591606616973877	And to me, it's a stark contrast with growth is good versus sustainability.
4828710	4833138	E	0.692709743976593	And of course, the math of the free energy principle is just about sustainability.
4833234	4842618	E	0.7792748212814331	It's just a description of the physics of systems, random, dynamical systems that self organize to some non equilibrium steady state.
4842784	4844300	E	0.5485090613365173	That is what we are.
4844750	4859150	E	0.5530500411987305	So for me, there's something deeply, if you like, apt about the free energy principle and its chronologies, such as active inference in application to ecosystems and lived ecosystems and realized ecosystems.
4859650	4877746	E	0.7731978893280029	So if those basic principles can be brought back into globalization, into the market, into fintech, into social media, into politics, into climate action, I think that would be a good thing.
4877928	4882520	E	0.8319275379180908	I'm just mindful this struck me in a number of the presentations today.
4882970	4894102	E	0.5055342316627502	You remember before, Bert was saying, if you look at the brain, which is a really lovely example of a self organizing system to a non equilibrium steady state, then it's empty.
4894166	4895226	E	0.7982829809188843	And what did he mean by that?
4895248	4897062	E	0.5956296920776367	What he didn't mean you were empty headed.
4897206	4901290	E	0.5546423196792603	What he meant was it's incredibly sparsely connected.
4901810	4917278	E	0.5764952898025513	Now, that tells you immediately that a pathology of connectivity is hyperconnectivity overconnectivity, which immediately, well, it made me very alert to the presentation of the metacrisis.
4917374	4936738	E	0.5446527600288391	That one of the first three things that was underwrote the metacrisis or the current crisis we're tending with is a destruction of that sparse, delicate connectivity that defines thingness and defines ensembles of things technically in terms of Markov blankets.
4936834	4946758	E	0.5207929611206055	So if we want a world in which lots of different things can coexist in some kind of generalized synchrony in a sustainable way, you need fast connectivity.
4946934	4951210	E	0.9027766585350037	And the pathology, the thing that will destroy that, is overconnectivity.
4951810	4964318	E	0.5004756450653076	So it seems to be very important that we get that into play in terms of machine learning, artificial intelligence, politics, fintech, climate change.
4964404	4972498	E	0.6800390481948853	And the only way it's going to get there is epistemically by equipping people to actually build their own little models and ask their own questions.
4972584	4976100	E	0.5552878975868225	You can't tell people this they've got to learn they've got to learn it for themselves.
4976730	4980680	E	0.4955330789089203	Just very quickly, I'm sure we've only got a couple of minutes left.
4983690	4997210	E	0.7544403076171875	The other agenda, which I'm more familiar with is exactly Anna's and Guillaume's agenda, which is making this work in the context of neurology and psychiatry.
4997630	5014000	E	0.8190183639526367	So if you can democratize and socialize this way of describing things so that people can now build models of their particular patient in the other use of precision psychiatry, I suspect that Guillum's unit was called after.
5014550	5023150	E	0.786765456199646	So it's a personalized medicine that is really personalized in the sense that you actually have your digital twin of your behavior.
5023310	5025060	E	0.5767486691474915	And then you've got that.
5025510	5042374	E	0.6603867411613464	You optimize your digital twin to become a model of your patient, and then you can start to do experiments on that model, behavioral interventions, or even share that model very much in the spirit of CBT with the patient and say, look, this is you.
5042412	5044186	E	0.6139060258865356	This is what would happen if you went out and did this.
5044208	5046860	E	0.6253259181976318	And this is what would happen if you went out and did that.
5048910	5049866	E	0.7547193765640259	To my mind.
5049968	5070402	E	0.8588453531265259	And indeed, that was the initial motivation for much of this work, was actually to build observation models of psychiatric conditions, to work out both the pharmacological and physiological basis and the disruption of the pathology of precision and message.
5070456	5086366	E	0.8191548585891724	Passing on the factographs that are our brain even though they are very empty on the one hand, but also get that behavior, that key thing that Anna was talking about the active engagement with the lived world into that model and hence active inference.
5086478	5109630	E	0.7064670324325562	And just to conclude that that activity, that sort of physical engagement, that embodiment, that sort of for ease and everything else, I think it's really coming to a head now in terms of people after, the large language model, after the Chat GPT moment, the bounce back has been what's missing?
5110530	5111582	E	0.6884991526603699	What's not there?
5111636	5116180	E	0.6578648686408997	And of course, what is not there is agency and embodied engagement with the world.
5116790	5139080	E	0.6612338423728943	And that's why I think there's still a lot of work to be done in bringing artificial intelligence read as active inference in a way that matters to people who people who can make a difference, which is basically everybody, but specifically politicians and doctors and engineers and the like.
5140810	5146502	A	0.8372821807861328	So you all now have 30 seconds to 60 seconds to speak directly to the audience.
5146646	5150762	A	0.8782069087028503	What is the message that you what closing message do you have?
5150816	5153210	A	0.6071764826774597	You're speaking directly to someone who's listening.
5153290	5154750	A	0.7059744596481323	They're a curious person.
5154900	5156650	A	0.7288098931312561	They're interested in active inference.
5156730	5162602	A	0.8489736318588257	They also want to lead better lives, hopefully, and do something propitious.
5162746	5165300	A	0.8459857106208801	So what message do you have for them?
5166790	5168820	A	0.8342101573944092	Anna, we'll start with you.
5171720	5172580	D	0.4846998453140259	Gosh.
5173080	5200392	D	0.6509241461753845	I'm just going to say what pops into my mind right now is that one of the things I have learned from my patients who are trying to get into recovery from severe addictions is something that they call the set aside prayer where they set aside all of the notions that they have about how the world works and try to be completely open and receptive to information coming into their minds.
5200536	5221172	D	0.7618436217308044	And I think that's just a wonderful frame or concept for all of us living in the world to periodically just take a moment and take these models and just say everything I think I know about the world, I'm going to temporarily suspend it, and I'm just going to be open.
5221306	5228420	D	0.5151410102844238	And when that happens, we can be present and learn in a way that it's not possible when we're just trying to reinforce our models.
5229480	5229988	A	0.7671424746513367	Great.
5230074	5230800	A	0.7758762240409851	Fantastic.
5230880	5231632	A	0.7391055226325989	And Bert.
5231696	5232296	A	0.6858871579170227	And then we'll go.
5232318	5232724	A	0.5521734356880188	Karl.
5232772	5235720	A	0.8741974234580994	And then Raph and then Guillaume.
5237260	5239912	C	0.9881481528282166	Well, I just enjoyed today very much.
5239966	5249368	C	0.6727719306945801	I thought there was a lot of material, both for people from, let's say, psychology, neuroscience, but also for engineers.
5249464	5256384	C	0.9571990370750427	So if you haven't watched some of the talks, go look through the schedule, because some of the talks were really good, I think.
5256422	5257970	C	0.9811996221542358	So I really enjoyed that.
5258500	5261008	C	0.7291527390480042	And then, yeah, what should I tell people?
5261174	5262368	C	0.7474294304847717	Go work out.
5262534	5263484	C	0.8261957168579102	Do a lot of sports.
5263532	5264690	C	0.8742085695266724	It's good for you.
5269560	5270404	E	0.5491447448730469	Yeah.
5270602	5273910	E	0.7092474102973938	Sorry, I was going to make a joke, but I can't because it wouldn't be.
5275240	5283290	E	0.9407445788383484	So I'm going to use my 30 seconds just to thank Daniel and his team for this.
5284140	5294488	E	0.649468183517456	If you want something to do, you should go and watch the live streams and get involved with this ecosystem.
5294584	5308240	E	0.975069522857666	I hadn't seen that paper being presented before, but I was really impressed with the Active Institute and its openness and its welcoming attitude and vision, like the Smithsonian.
5309140	5312988	E	0.6741364002227783	So if you want to pursue these ideas, get involved.
5313084	5320272	E	0.7407614588737488	And if you haven't got time, just make sure you attend next year's Active Inference Institute celebration.
5320416	5321780	E	0.737889289855957	But thank you, Daniel.
5322920	5325012	A	0.7984785437583923	Raphael yeah.
5325066	5330468	F	0.5686554908752441	So I'll second what Karl said and follow on with it's.
5330484	5353180	F	0.7756162881851196	An invitation not just to participate in the Active Defense Institute, but also the invitation to participate in building this Gaia tractor, this new way of doing things that acknowledges the value of growth, and also the value of sustainability, joins it all together in this thing called regeneration.
5353520	5358184	F	0.738808274269104	And it really is a collective effort.
5358232	5359900	F	0.5435721278190613	It's a collective learning effort.
5362020	5366276	F	0.8759250640869141	And this also, by the way, also applies to the panelists as well.
5366378	5367188	F	0.6888490915298462	I think.
5367354	5376372	F	0.8883850574493408	Obviously, what Bert and Karl are doing, it has immediate things that have to do with what we're after.
5376426	5388260	F	0.547717273235321	But one of the main things that we keep discussing is also like this the inter subjectivity and the importance of being able to operate well as humans together.
5388330	5391752	F	0.8358797430992126	And that connects directly to cognitive science in psychiatry.
5391896	5415436	F	0.7300773859024048	And so everybody that wants to be engaged and be a part of building a better world should be thinking about what am I doing as an individual or as employee of organization or as a researcher or as a leader or as a family member, what am I doing?
5415558	5422436	F	0.8334357142448425	How does it contribute to this new non equilibrium set of state?
5422538	5424516	F	0.6642447113990784	So, yeah, that's kind of it.
5424538	5427270	F	0.6629053950309753	I probably blew through the 60 seconds, but here it is.
5428060	5436904	G	0.9030579924583435	And Guillaume, well, I would thanks also, all of you for the discussion and the organizer for what they are doing.
5436942	5445416	G	0.9832131266593933	Indeed, the work of the Active Inference Institute is very laudable and interesting from an open science perspective.
5445448	5446936	G	0.881547749042511	They are really embodying.
5446968	5450012	G	0.946533739566803	That so big kudos to them.
5450146	5455088	G	0.5344222784042358	And well, the Frieze was saying to do sport is good for you.
5455174	5459932	G	0.5656788349151611	I'm not very good at sports, but some say that science is a team sport.
5459996	5466224	G	0.552769124507904	So at least have a good team perspective when doing science.
5466272	5470470	G	0.9097157120704651	And being kind to each other would be the best advice to everyone.
5472520	5474230	A	0.8225735425949097	Well, thank you.
5475720	5476820	B	0.7565318942070007	You get yours too.
5476890	5480250	B	0.8409625291824341	Somebody else has to come in from outside the Markov blanket, though.
5481660	5484036	A	0.8194192051887512	Well, I wanted to just thank you, Daniel.
5484148	5485540	A	0.8880262970924377	Thank you, Daniel.
5485700	5490500	A	0.8869516849517822	And Raphael and also Karl and Anna and Bert and Yom.
5490580	5492716	A	0.9763413667678833	This was tremendous amount of fun.
5492898	5496744	A	0.5923120975494385	And well, I hope I get to speak to you all individually.
5496872	5502190	A	0.7032280564308167	And as usual, I have way more questions than we were able to get to.
5502800	5504044	A	0.9195932745933533	Thank you all.
5504242	5504990	F	0.6283750534057617	Thanks.
5505840	5506684	F	0.8529649972915649	Thank you.
5506802	5507790	B	0.8613404035568237	Thanks everyone.
5508400	5510104	B	0.5733881592750549	Farewell to the panelists.
5510232	5510812	E	0.5566248297691345	You're all.
5510866	5512220	B	0.9090889096260071	Welcome back anytime.
5513440	5515380	B	0.9550157189369202	Thanks everybody, for watching.
5515490	5516390	B	0.6368565559387207	Be watching.
5516760	5525664	B	0.5184981226921082	Right now we're about to head over to the discord and hang out and talk a little more if you want to, and then stay involved, get involved.
5525792	5527748	B	0.7429341673851013	So till next time.
5527914	5528480	A	0.5137446522712708	Bye.
