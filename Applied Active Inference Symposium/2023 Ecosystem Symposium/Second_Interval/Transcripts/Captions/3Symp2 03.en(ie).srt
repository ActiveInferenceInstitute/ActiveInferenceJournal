1
00:00:00,359 --> 00:00:03,199
all right

2
00:00:05,940 --> 00:00:08,820
greetings all right well our next

3
00:00:08,820 --> 00:00:12,300
session hey hey Bert greetings

4
00:00:12,300 --> 00:00:14,280
great how are you doing good good very

5
00:00:14,280 --> 00:00:15,059
well

6
00:00:15,059 --> 00:00:17,220
um our next session is with bird device

7
00:00:17,220 --> 00:00:20,580
Dimitri bagayev and Bart van Erp it's

8
00:00:20,580 --> 00:00:22,740
going to be called towards user-friendly

9
00:00:22,740 --> 00:00:24,720
design of synthetic active inference

10
00:00:24,720 --> 00:00:27,480
agents and I know a lot of people are

11
00:00:27,480 --> 00:00:30,119
super excited to see this really

12
00:00:30,119 --> 00:00:32,759
practical and Cutting Edge work so to

13
00:00:32,759 --> 00:00:35,100
you Bert and just let us know how we can

14
00:00:35,100 --> 00:00:36,600
support

15
00:00:36,600 --> 00:00:40,680
okay great uh well is my audio good yep

16
00:00:40,680 --> 00:00:44,040
sounds good okay then I'm gonna share my

17
00:00:44,040 --> 00:00:46,739
screen uh

18
00:00:46,739 --> 00:00:48,719
I hope I picked the right one I don't

19
00:00:48,719 --> 00:00:52,079
work it's Zoom quite often looks good it

20
00:00:52,079 --> 00:00:55,140
looks good yep all right super

21
00:00:55,140 --> 00:00:57,719
um well thanks a lot to Daniel for for

22
00:00:57,719 --> 00:01:00,239
hosting this uh Symposium I've been

23
00:01:00,239 --> 00:01:02,100
watching some talks it's really amazing

24
00:01:02,100 --> 00:01:05,400
and uh we really we feel privileged to

25
00:01:05,400 --> 00:01:07,619
get the chance to present ourselves so

26
00:01:07,619 --> 00:01:09,780
we are also just like a few others

27
00:01:09,780 --> 00:01:11,640
before is interested in developing a

28
00:01:11,640 --> 00:01:13,920
toolbox for active inference

29
00:01:13,920 --> 00:01:17,760
and so this picture or it kind of shows

30
00:01:17,760 --> 00:01:18,900
what we're

31
00:01:18,900 --> 00:01:20,820
um what we're about or what we're

32
00:01:20,820 --> 00:01:23,700
interested in so here's a lady on the

33
00:01:23,700 --> 00:01:26,100
left hand side and

34
00:01:26,100 --> 00:01:27,420
um we're gonna

35
00:01:27,420 --> 00:01:30,119
try to get a laser pointer and she has

36
00:01:30,119 --> 00:01:33,600
this idea about a rewarding behavior for

37
00:01:33,600 --> 00:01:36,000
a vacuum cleaning robot right so she's

38
00:01:36,000 --> 00:01:37,799
writing down she has a textual

39
00:01:37,799 --> 00:01:39,900
expression but move around the apartment

40
00:01:39,900 --> 00:01:42,420
apply suction until the floor is clean

41
00:01:42,420 --> 00:01:45,180
do not touch objects and when don't

42
00:01:45,180 --> 00:01:47,400
return to the dog so that that's not so

43
00:01:47,400 --> 00:01:50,520
hard I'm gonna rate that with one star

44
00:01:50,520 --> 00:01:52,259
out of three stars in terms of difficult

45
00:01:52,259 --> 00:01:55,560
difficulty level to specify that

46
00:01:55,560 --> 00:01:58,320
but that's not enough to program these

47
00:01:58,320 --> 00:02:00,000
robots right because what she really

48
00:02:00,000 --> 00:02:02,939
needs to do now is to specify a

49
00:02:02,939 --> 00:02:06,299
generative model and uh that you know

50
00:02:06,299 --> 00:02:09,479
the there is effectors and actuators

51
00:02:09,479 --> 00:02:12,420
right the robot has to move around apply

52
00:02:12,420 --> 00:02:15,360
suction until the floor is clean so the

53
00:02:15,360 --> 00:02:18,480
sensors probably a camera do not touch

54
00:02:18,480 --> 00:02:20,459
objects so maybe there has to be object

55
00:02:20,459 --> 00:02:23,099
recognition this is a really difficult

56
00:02:23,099 --> 00:02:25,680
task to come up with this generative

57
00:02:25,680 --> 00:02:28,680
model here and on top of that

58
00:02:28,680 --> 00:02:31,860
she has to specify this kind of

59
00:02:31,860 --> 00:02:34,140
rewarding behavior in terms now of

60
00:02:34,140 --> 00:02:36,300
probability distributions of this

61
00:02:36,300 --> 00:02:39,120
generative model so very difficult I'm

62
00:02:39,120 --> 00:02:40,560
going to rate that with two stars

63
00:02:40,560 --> 00:02:42,720
because

64
00:02:42,720 --> 00:02:45,060
the next thing she has to do for this

65
00:02:45,060 --> 00:02:47,220
model is to specify the inference

66
00:02:47,220 --> 00:02:49,800
procedure to do actually active

67
00:02:49,800 --> 00:02:52,379
inference and freelanci minimization in

68
00:02:52,379 --> 00:02:53,400
real time

69
00:02:53,400 --> 00:02:56,459
or this complex model and really that's

70
00:02:56,459 --> 00:02:59,540
almost impossible right only a few

71
00:02:59,540 --> 00:03:02,940
Specialists can really write a procedure

72
00:03:02,940 --> 00:03:04,319
for for variational free energy

73
00:03:04,319 --> 00:03:06,540
minimization in some very difficult

74
00:03:06,540 --> 00:03:09,780
model so what we are about what we've

75
00:03:09,780 --> 00:03:12,599
been working on is to try to automate

76
00:03:12,599 --> 00:03:14,580
the inference task so get rid of the

77
00:03:14,580 --> 00:03:17,459
three stars and yes she will still have

78
00:03:17,459 --> 00:03:20,159
to specify her model but in the long

79
00:03:20,159 --> 00:03:23,220
term we try to get away from that so in

80
00:03:23,220 --> 00:03:25,500
the long term we hope we will get a

81
00:03:25,500 --> 00:03:27,720
toolbox and now we're talking five ten

82
00:03:27,720 --> 00:03:31,440
years right where a textual description

83
00:03:31,440 --> 00:03:33,780
would be enough to specify some initial

84
00:03:33,780 --> 00:03:36,959
model with an initial prior and

85
00:03:36,959 --> 00:03:39,060
everything else is just automated

86
00:03:39,060 --> 00:03:42,120
inference learning of States parameters

87
00:03:42,120 --> 00:03:44,280
structural adaptation of the model even

88
00:03:44,280 --> 00:03:48,360
maybe based on her feedback updating uh

89
00:03:48,360 --> 00:03:52,440
the the prior so that's long term uh for

90
00:03:52,440 --> 00:03:55,140
now we would be very happy if we could

91
00:03:55,140 --> 00:04:00,060
just automate the inference uh task so

92
00:04:00,060 --> 00:04:02,459
um why why is it so difficult to specify

93
00:04:02,459 --> 00:04:04,560
inference for an active inference agents

94
00:04:04,560 --> 00:04:07,819
well we have so many competing

95
00:04:07,819 --> 00:04:11,519
kpis right we we uh we want to do this

96
00:04:11,519 --> 00:04:15,180
for large model Scopes not just for ABCD

97
00:04:15,180 --> 00:04:17,720
models but maybe there's also continuous

98
00:04:17,720 --> 00:04:19,738
variables and

99
00:04:19,738 --> 00:04:22,440
biological models right must be very

100
00:04:22,440 --> 00:04:24,960
user friendly you really don't want her

101
00:04:24,960 --> 00:04:29,220
to worry about robustness of her code

102
00:04:29,220 --> 00:04:30,960
um we don't want her to worry about

103
00:04:30,960 --> 00:04:32,880
whether

104
00:04:32,880 --> 00:04:36,180
um two variables are have coinji good

105
00:04:36,180 --> 00:04:38,220
relationships right

106
00:04:38,220 --> 00:04:40,320
um adaptivity we want to update States

107
00:04:40,320 --> 00:04:42,540
parameters maybe even the model the

108
00:04:42,540 --> 00:04:45,060
model structure has to be low power

109
00:04:45,060 --> 00:04:48,180
because these angels often run on edge

110
00:04:48,180 --> 00:04:50,759
devices all right so they run on their

111
00:04:50,759 --> 00:04:53,340
battery powered has to be in real time

112
00:04:53,340 --> 00:04:55,979
because you can't learn how to ride a

113
00:04:55,979 --> 00:04:58,139
bike if there's no real-time reasoning

114
00:04:58,139 --> 00:05:01,259
and on top of that you actually want to

115
00:05:01,259 --> 00:05:03,000
minimize variation of reality right you

116
00:05:03,000 --> 00:05:04,740
want to do it at least as good or at

117
00:05:04,740 --> 00:05:06,780
least in a neighborhood of if you would

118
00:05:06,780 --> 00:05:09,720
do a manual derivation and some of these

119
00:05:09,720 --> 00:05:11,880
this is a rather bite each other right

120
00:05:11,880 --> 00:05:14,520
if you uh you want to minimize

121
00:05:14,520 --> 00:05:16,740
variational free energy but you have to

122
00:05:16,740 --> 00:05:19,259
do it in real time and on low power yeah

123
00:05:19,259 --> 00:05:21,479
that kind of bites each other right so

124
00:05:21,479 --> 00:05:23,340
these are

125
00:05:23,340 --> 00:05:27,600
difficult kpis that we we want to yeah

126
00:05:27,600 --> 00:05:30,000
we they're all important you can't just

127
00:05:30,000 --> 00:05:31,380
take one out

128
00:05:31,380 --> 00:05:33,180
um because then the whole system

129
00:05:33,180 --> 00:05:35,520
wouldn't work

130
00:05:35,520 --> 00:05:37,320
um so

131
00:05:37,320 --> 00:05:40,860
um when you read papers on active

132
00:05:40,860 --> 00:05:44,039
inference you often also read and now we

133
00:05:44,039 --> 00:05:46,259
Implement variation variety minimization

134
00:05:46,259 --> 00:05:49,380
and that can be done by message passing

135
00:05:49,380 --> 00:05:53,639
on a graph and I want to clarify first

136
00:05:53,639 --> 00:05:56,039
why it has to be done by message passing

137
00:05:56,039 --> 00:05:57,539
on the graph

138
00:05:57,539 --> 00:05:58,919
um I'll do that by giving a very short

139
00:05:58,919 --> 00:06:00,120
answer

140
00:06:00,120 --> 00:06:02,960
and then do an example the short answer

141
00:06:02,960 --> 00:06:08,759
is that Bayesian inference involves

142
00:06:08,759 --> 00:06:11,340
um Computing very large sum of products

143
00:06:11,340 --> 00:06:13,199
like what you see here on the left hand

144
00:06:13,199 --> 00:06:16,160
side here's a product AC

145
00:06:16,160 --> 00:06:19,800
adbc and then we send them in AC plus 80

146
00:06:19,800 --> 00:06:21,840
and so forth this is a sum of products

147
00:06:21,840 --> 00:06:26,039
now we know by the distributive law that

148
00:06:26,039 --> 00:06:28,380
this here on the left hand side can also

149
00:06:28,380 --> 00:06:31,860
be computed as on the right hand side If

150
00:06:31,860 --> 00:06:34,259
I multiply this out I get a times C plus

151
00:06:34,259 --> 00:06:36,900
a times D and so forth this is a product

152
00:06:36,900 --> 00:06:39,000
of sums and there

153
00:06:39,000 --> 00:06:41,819
exactly the same thing the only

154
00:06:41,819 --> 00:06:44,400
difference is that to compute the left

155
00:06:44,400 --> 00:06:47,160
hand side takes four additions sorry

156
00:06:47,160 --> 00:06:49,979
four multiplications and three additions

157
00:06:49,979 --> 00:06:52,919
to compute the right hand side takes two

158
00:06:52,919 --> 00:06:54,300
additions and one only one

159
00:06:54,300 --> 00:06:57,600
multiplication so on the right hand side

160
00:06:57,600 --> 00:07:00,240
is much cheaper to compute in the left

161
00:07:00,240 --> 00:07:03,259
hand side normally when we write down

162
00:07:03,259 --> 00:07:05,819
marginalization and the Asian inference

163
00:07:05,819 --> 00:07:08,639
we we write things down in the as in the

164
00:07:08,639 --> 00:07:11,460
left hand side what message passing does

165
00:07:11,460 --> 00:07:13,500
on the graph it will automatically

166
00:07:13,500 --> 00:07:16,919
convert that into much deeper to

167
00:07:16,919 --> 00:07:20,099
evaluate product of sums and I'll give

168
00:07:20,099 --> 00:07:22,259
an example of that

169
00:07:22,259 --> 00:07:23,460
um

170
00:07:23,460 --> 00:07:27,900
so here is an uh an example Model F of

171
00:07:27,900 --> 00:07:31,319
seven variables X1 X2 through X7 and

172
00:07:31,319 --> 00:07:34,319
this model happens to be factorized F A

173
00:07:34,319 --> 00:07:39,300
of X1 fbx2 and so forth now we can draw

174
00:07:39,300 --> 00:07:42,479
this factorization in a as a graph

175
00:07:42,479 --> 00:07:44,699
and what we do and this is called a

176
00:07:44,699 --> 00:07:46,919
Forney style Factor graph what we do is

177
00:07:46,919 --> 00:07:51,300
for each factor F A we allocate a node

178
00:07:51,300 --> 00:07:54,780
so FB gets a note and FC gets a note

179
00:07:54,780 --> 00:07:58,020
and we associate the variables in our

180
00:07:58,020 --> 00:08:00,720
system with the edge and an edge is

181
00:08:00,720 --> 00:08:03,780
connected to a node if that variable is

182
00:08:03,780 --> 00:08:07,440
an argument of that function so FC is a

183
00:08:07,440 --> 00:08:12,060
function of F of X1 X2 X 3 and that

184
00:08:12,060 --> 00:08:14,880
means that FC connects to the edges X1

185
00:08:14,880 --> 00:08:20,039
X2 X3 and FD is only a function of X4 so

186
00:08:20,039 --> 00:08:24,419
if D only connects to the edge X4 so

187
00:08:24,419 --> 00:08:26,580
what you can see in this graph is this

188
00:08:26,580 --> 00:08:28,500
graph is nothing but

189
00:08:28,500 --> 00:08:31,399
a visualization of the factorization

190
00:08:31,399 --> 00:08:35,339
assumptions that we have for this model

191
00:08:35,339 --> 00:08:37,860
now if I'm interested in a big

192
00:08:37,860 --> 00:08:41,820
marginalization a task integrate out

193
00:08:41,820 --> 00:08:47,220
over all variables but X3 so X1 X2 X4

194
00:08:47,220 --> 00:08:49,680
and so forth through X7 I'm interested

195
00:08:49,680 --> 00:08:51,540
in this

196
00:08:51,540 --> 00:08:52,860
um then

197
00:08:52,860 --> 00:08:55,800
making taking advantage of this

198
00:08:55,800 --> 00:08:58,560
factorization I can rewrite this sum

199
00:08:58,560 --> 00:09:03,620
this basically this sum of product into

200
00:09:03,620 --> 00:09:09,060
a product of sums as as below here what

201
00:09:09,060 --> 00:09:10,980
you will see here below this computes

202
00:09:10,980 --> 00:09:13,080
exactly the same thing but I've made use

203
00:09:13,080 --> 00:09:16,519
of this distributive law for instance

204
00:09:16,519 --> 00:09:22,080
FC contains no X4 no X5 so I moved it

205
00:09:22,080 --> 00:09:25,080
over the summation sign to the left and

206
00:09:25,080 --> 00:09:30,660
FB also doesn't contain X4 X5 x67 so I

207
00:09:30,660 --> 00:09:32,760
moved it all the way to the left

208
00:09:32,760 --> 00:09:35,700
and when you do that you are left here

209
00:09:35,700 --> 00:09:38,279
with an expression

210
00:09:38,279 --> 00:09:42,480
where I only some some over two two

211
00:09:42,480 --> 00:09:44,519
variables and here I have to sum over

212
00:09:44,519 --> 00:09:46,860
six variables and here over two and here

213
00:09:46,860 --> 00:09:49,920
over two so you can imagine if each

214
00:09:49,920 --> 00:09:53,760
variable let's say so X1 X2 if each

215
00:09:53,760 --> 00:09:56,399
variable has 10 interesting values that

216
00:09:56,399 --> 00:09:57,959
you need to sum over

217
00:09:57,959 --> 00:10:00,180
then I have here

218
00:10:00,180 --> 00:10:03,360
the original marginalization problem I

219
00:10:03,360 --> 00:10:06,240
have 10 to the power 6 so a million

220
00:10:06,240 --> 00:10:08,940
terms and here

221
00:10:08,940 --> 00:10:12,000
in red I have 100 terms and here I have

222
00:10:12,000 --> 00:10:14,940
100 and here I have 100 so here I have

223
00:10:14,940 --> 00:10:18,060
300 terms and here I have 1 million

224
00:10:18,060 --> 00:10:20,820
terms so is it it's an enormous

225
00:10:20,820 --> 00:10:23,240
reduction in computational

226
00:10:23,240 --> 00:10:24,920
complexity

227
00:10:24,920 --> 00:10:28,620
when we make use of this distributive

228
00:10:28,620 --> 00:10:31,860
law now it turns out that if you write

229
00:10:31,860 --> 00:10:36,000
this out you can associate these these

230
00:10:36,000 --> 00:10:38,459
intermediate factors with messages on

231
00:10:38,459 --> 00:10:40,620
the graph it's just an interpretation a

232
00:10:40,620 --> 00:10:43,860
visual interpretation it's as if

233
00:10:43,860 --> 00:10:45,720
FC

234
00:10:45,720 --> 00:10:49,140
receives a message from fa and FB

235
00:10:49,140 --> 00:10:51,839
receive or FC receives the message from

236
00:10:51,839 --> 00:10:55,260
X from FB and computes an outgoing

237
00:10:55,260 --> 00:10:58,740
message mu X3 and the same thing for Fe

238
00:10:58,740 --> 00:11:01,680
so Fe receives a message from a

239
00:11:01,680 --> 00:11:04,920
neighboring factors FD and FF and

240
00:11:04,920 --> 00:11:07,640
computes an outgoing message

241
00:11:07,640 --> 00:11:12,660
or X3 so what you see here is that the

242
00:11:12,660 --> 00:11:15,660
entire marginalization process can be

243
00:11:15,660 --> 00:11:18,899
represented as basically Computing a few

244
00:11:18,899 --> 00:11:20,820
messages on a graph

245
00:11:20,820 --> 00:11:22,860
and multiplying some of these messages

246
00:11:22,860 --> 00:11:25,500
with each other and and and and that's

247
00:11:25,500 --> 00:11:27,540
how you can do base in inference and

248
00:11:27,540 --> 00:11:29,399
also how you can do variational free

249
00:11:29,399 --> 00:11:33,959
energy minimization so this works in

250
00:11:33,959 --> 00:11:38,220
um in factorized models but I would say

251
00:11:38,220 --> 00:11:40,140
even stronger if your model is not

252
00:11:40,140 --> 00:11:42,180
factorized and you have a lot of

253
00:11:42,180 --> 00:11:45,300
variables uh there is just no way you

254
00:11:45,300 --> 00:11:48,240
can do proper inference so any serious

255
00:11:48,240 --> 00:11:51,000
model is factorized like the brain is

256
00:11:51,000 --> 00:11:54,779
almost sparse is is almost empty we have

257
00:11:54,779 --> 00:11:58,019
well is it about 10 billion neurons and

258
00:11:58,019 --> 00:11:59,940
each neuron connects to a few thousand

259
00:11:59,940 --> 00:12:02,519
other neurons so if I would draw the

260
00:12:02,519 --> 00:12:04,800
graph that graph is almost empty it is

261
00:12:04,800 --> 00:12:08,700
hugely sparse and so there is no other

262
00:12:08,700 --> 00:12:10,620
way to do inference in the brain than by

263
00:12:10,620 --> 00:12:12,540
message passing

264
00:12:12,540 --> 00:12:14,519
um so that's why message passing just

265
00:12:14,519 --> 00:12:16,200
because it's more effective than

266
00:12:16,200 --> 00:12:18,500
anything else

267
00:12:18,500 --> 00:12:22,440
now then the issue is which message do

268
00:12:22,440 --> 00:12:25,920
you compute how do you compute messages

269
00:12:25,920 --> 00:12:28,320
um because there are different ways of

270
00:12:28,320 --> 00:12:30,360
doing it right and we also read in

271
00:12:30,360 --> 00:12:32,160
active inference papers you can do this

272
00:12:32,160 --> 00:12:34,339
by variational message passing or

273
00:12:34,339 --> 00:12:37,440
expectation maximization or belief

274
00:12:37,440 --> 00:12:39,240
propagation and

275
00:12:39,240 --> 00:12:42,360
variational LaPlace and all these terms

276
00:12:42,360 --> 00:12:46,260
turns out that there is a an umbrella

277
00:12:46,260 --> 00:12:48,300
framework for all these methods passing

278
00:12:48,300 --> 00:12:50,700
Frameworks and that umbrella framework

279
00:12:50,700 --> 00:12:53,220
is called constraint better

280
00:12:53,220 --> 00:12:56,459
free energy minimization and I try I

281
00:12:56,459 --> 00:12:57,920
will try to

282
00:12:57,920 --> 00:13:02,040
illustrate that by uh well by this slide

283
00:13:02,040 --> 00:13:05,160
so here I have this graph this is just

284
00:13:05,160 --> 00:13:06,980
an example graph

285
00:13:06,980 --> 00:13:11,839
where my generative model is basically

286
00:13:11,839 --> 00:13:17,399
factorizing F A FB FC of dnfe and I've

287
00:13:17,399 --> 00:13:19,560
also written that here so this now is

288
00:13:19,560 --> 00:13:21,779
the variation of free energy

289
00:13:21,779 --> 00:13:25,260
now I haven't made any assumption on Q

290
00:13:25,260 --> 00:13:29,399
of X so Q of X is still Q of X1 X2 X3 is

291
00:13:29,399 --> 00:13:32,820
just a joint overall variables and it

292
00:13:32,820 --> 00:13:34,079
doesn't have any factorization

293
00:13:34,079 --> 00:13:36,120
assumption

294
00:13:36,120 --> 00:13:39,240
um it makes sense to also assume that

295
00:13:39,240 --> 00:13:41,940
the posterior kind of follows the

296
00:13:41,940 --> 00:13:43,920
factorization Assumption of the prior

297
00:13:43,920 --> 00:13:47,339
namely of the generative model so if we

298
00:13:47,339 --> 00:13:49,260
make that assumption

299
00:13:49,260 --> 00:13:51,959
and that means we're going to make the

300
00:13:51,959 --> 00:13:55,320
assumption that Q X is also now a

301
00:13:55,320 --> 00:13:57,180
product of qas

302
00:13:57,180 --> 00:14:01,620
of X of a where qas of X of a stands for

303
00:14:01,620 --> 00:14:04,320
beliefs over notes what I mean by that

304
00:14:04,320 --> 00:14:08,220
is that Q of B is a is a posterior

305
00:14:08,220 --> 00:14:10,760
belief over this node meaning it's a

306
00:14:10,760 --> 00:14:13,800
posterior belief over the edges that

307
00:14:13,800 --> 00:14:17,700
connect to these nodes just like FB is a

308
00:14:17,700 --> 00:14:20,760
function of X1 X2 X

309
00:14:20,760 --> 00:14:23,220
4 that's if you will the prior or the

310
00:14:23,220 --> 00:14:26,279
generative model then Q of B the

311
00:14:26,279 --> 00:14:28,500
variational posterior for this node will

312
00:14:28,500 --> 00:14:32,839
also depend on X1 X2 X4 and on no other

313
00:14:32,839 --> 00:14:36,660
factors if you just do that then you

314
00:14:36,660 --> 00:14:39,720
will count some of the variables double

315
00:14:39,720 --> 00:14:43,380
because X1 is part of the belief over F

316
00:14:43,380 --> 00:14:47,399
A but also part of the belief over FB so

317
00:14:47,399 --> 00:14:49,860
we just have to Discount that by

318
00:14:49,860 --> 00:14:53,760
dividing by beliefs over edges that

319
00:14:53,760 --> 00:14:57,240
means that I make now an assumption

320
00:14:57,240 --> 00:15:01,680
that my posterior believes is

321
00:15:01,680 --> 00:15:05,639
is is divided into local beliefs over

322
00:15:05,639 --> 00:15:08,100
notes and local beliefs over edges over

323
00:15:08,100 --> 00:15:09,540
variables

324
00:15:09,540 --> 00:15:12,779
this will make things a lot simpler in

325
00:15:12,779 --> 00:15:16,860
fact if my graph is a tree and it is a

326
00:15:16,860 --> 00:15:19,560
tree here and I would do message passing

327
00:15:19,560 --> 00:15:21,600
on that tree and I could suppose I could

328
00:15:21,600 --> 00:15:23,579
do that perfectly everything is linear

329
00:15:23,579 --> 00:15:25,800
gaussian then I get perfect Bayesian

330
00:15:25,800 --> 00:15:28,980
inference there is no approximation so

331
00:15:28,980 --> 00:15:32,100
this is a good assumption sometimes it's

332
00:15:32,100 --> 00:15:33,959
still very hard to compute a message

333
00:15:33,959 --> 00:15:35,279
because

334
00:15:35,279 --> 00:15:38,660
even the the the the the single message

335
00:15:38,660 --> 00:15:41,040
that come out of these nodes the still

336
00:15:41,040 --> 00:15:44,100
integrals or summations and in

337
00:15:44,100 --> 00:15:46,019
particular the integrals may be a

338
00:15:46,019 --> 00:15:47,760
problem we may not have an analytical

339
00:15:47,760 --> 00:15:51,480
answer so what we sometimes do is add

340
00:15:51,480 --> 00:15:53,100
additional

341
00:15:53,100 --> 00:15:56,279
um assumptions we'll say well the

342
00:15:56,279 --> 00:15:59,519
posterior belief over FD I can't compute

343
00:15:59,519 --> 00:16:01,139
it in general

344
00:16:01,139 --> 00:16:03,420
but I'm gonna just assume now that it's

345
00:16:03,420 --> 00:16:06,300
a gaussian that makes it easier or we

346
00:16:06,300 --> 00:16:08,399
can make an extra factorization

347
00:16:08,399 --> 00:16:09,959
assumption

348
00:16:09,959 --> 00:16:13,260
and say the posterior belief over FB

349
00:16:13,260 --> 00:16:16,320
which is really a belief over the joint

350
00:16:16,320 --> 00:16:20,420
X1 X2 X4 is going to be broken into

351
00:16:20,420 --> 00:16:25,380
uh um independent belief over X1 and in

352
00:16:25,380 --> 00:16:26,940
the belief over

353
00:16:26,940 --> 00:16:29,880
um X2 and X4

354
00:16:29,880 --> 00:16:30,740
um

355
00:16:30,740 --> 00:16:34,920
these additional assumptions if I impose

356
00:16:34,920 --> 00:16:36,839
them as well this is what I will call

357
00:16:36,839 --> 00:16:39,899
now if I if I if I all substituted here

358
00:16:39,899 --> 00:16:42,540
in Q of X I get what's called a

359
00:16:42,540 --> 00:16:45,180
constrained beta-free energy this is the

360
00:16:45,180 --> 00:16:47,459
same death as in the Oppenheimer movie

361
00:16:47,459 --> 00:16:50,339
this is Hans beta where it's named after

362
00:16:50,339 --> 00:16:51,899
and

363
00:16:51,899 --> 00:16:53,820
um so

364
00:16:53,820 --> 00:16:56,360
we have a graph now

365
00:16:56,360 --> 00:17:00,839
that that is highly factorized and we

366
00:17:00,839 --> 00:17:02,480
have

367
00:17:02,480 --> 00:17:07,079
local beliefs over notes and over

368
00:17:07,079 --> 00:17:09,660
um over edges and they're indicated with

369
00:17:09,660 --> 00:17:11,819
with red and we have additional

370
00:17:11,819 --> 00:17:14,040
constraints in green there could be

371
00:17:14,040 --> 00:17:16,559
gaussians or mean field constraints or

372
00:17:16,559 --> 00:17:19,859
other constraints and now we will assume

373
00:17:19,859 --> 00:17:21,059
constraint that make it possible to

374
00:17:21,059 --> 00:17:22,679
compute all the messages and now we can

375
00:17:22,679 --> 00:17:24,959
just automate this by making different

376
00:17:24,959 --> 00:17:27,179
assumptions we can turn this into

377
00:17:27,179 --> 00:17:30,059
expectation maximization or belief

378
00:17:30,059 --> 00:17:32,280
propagation or

379
00:17:32,280 --> 00:17:32,820
um

380
00:17:32,820 --> 00:17:35,280
hybrid forms are off we can turn it into

381
00:17:35,280 --> 00:17:37,620
any relevant message passing algorithm

382
00:17:37,620 --> 00:17:40,020
that you've heard of so this is a very

383
00:17:40,020 --> 00:17:42,960
nice umbrella framework that basically

384
00:17:42,960 --> 00:17:46,320
encompasses everything and and there is

385
00:17:46,320 --> 00:17:49,260
a we've written a pretty large paper

386
00:17:49,260 --> 00:17:51,059
on this

387
00:17:51,059 --> 00:17:53,700
um in the in entropy Journal where you

388
00:17:53,700 --> 00:17:57,200
can read all the math on how this works

389
00:17:57,200 --> 00:18:00,240
so we've talked about why message

390
00:18:00,240 --> 00:18:02,700
passing namely because it's the most

391
00:18:02,700 --> 00:18:05,160
effective way of doing it inference and

392
00:18:05,160 --> 00:18:06,900
we've talked about which messages to

393
00:18:06,900 --> 00:18:08,760
compute namely

394
00:18:08,760 --> 00:18:10,679
we turn our

395
00:18:10,679 --> 00:18:12,900
variational free energy into something

396
00:18:12,900 --> 00:18:14,760
called a constrained better free energy

397
00:18:14,760 --> 00:18:17,400
and then we can compute messages the

398
00:18:17,400 --> 00:18:20,940
only thing that's left is well when do

399
00:18:20,940 --> 00:18:23,100
we pass these messages right what is the

400
00:18:23,100 --> 00:18:25,080
sequence of messages which one comes

401
00:18:25,080 --> 00:18:25,980
first

402
00:18:25,980 --> 00:18:27,360
and

403
00:18:27,360 --> 00:18:29,760
um this is where we see a lot of papers

404
00:18:29,760 --> 00:18:30,840
right

405
00:18:30,840 --> 00:18:31,559
um

406
00:18:31,559 --> 00:18:34,020
you have the right control flow what's

407
00:18:34,020 --> 00:18:36,419
good control flow you have to say okay

408
00:18:36,419 --> 00:18:38,520
here is my algorithm for active

409
00:18:38,520 --> 00:18:41,100
inference first I specify a model then

410
00:18:41,100 --> 00:18:43,320
let's do inference for every time step

411
00:18:43,320 --> 00:18:45,780
collect a new observation update the

412
00:18:45,780 --> 00:18:48,960
state update the desired future

413
00:18:48,960 --> 00:18:51,720
right and so forth compute expected free

414
00:18:51,720 --> 00:18:55,140
energy select the policy Etc

415
00:18:55,140 --> 00:18:58,799
um this kind of program the problem with

416
00:18:58,799 --> 00:19:01,200
active inferences is that there is

417
00:19:01,200 --> 00:19:03,600
nested for Loops in here here's a for

418
00:19:03,600 --> 00:19:06,600
Loop and here's another for Loop and for

419
00:19:06,600 --> 00:19:09,179
each of these policies I'm going to have

420
00:19:09,179 --> 00:19:11,580
to go into uh the future so I'm going to

421
00:19:11,580 --> 00:19:13,380
have another time Loop so it is for

422
00:19:13,380 --> 00:19:15,780
Loops in four Loops in for Loops this

423
00:19:15,780 --> 00:19:17,700
will completely explode in terms of

424
00:19:17,700 --> 00:19:19,140
computational

425
00:19:19,140 --> 00:19:23,520
complexity so as a result some very

426
00:19:23,520 --> 00:19:25,980
clever people have written very clever

427
00:19:25,980 --> 00:19:27,900
algorithms of doing this much faster

428
00:19:27,900 --> 00:19:30,960
sophisticated inference branching time

429
00:19:30,960 --> 00:19:33,179
active influence dynamic programming efe

430
00:19:33,179 --> 00:19:36,299
our recent proposals for doing this very

431
00:19:36,299 --> 00:19:37,320
clever

432
00:19:37,320 --> 00:19:41,460
in the end all of these proposals come

433
00:19:41,460 --> 00:19:44,660
down to a particular just a message

434
00:19:44,660 --> 00:19:47,160
passing schedule

435
00:19:47,160 --> 00:19:50,039
um once we commit to message passing on

436
00:19:50,039 --> 00:19:51,900
the graph as our inference procedure

437
00:19:51,900 --> 00:19:54,780
it's the only thing that's going on and

438
00:19:54,780 --> 00:19:56,520
all of this

439
00:19:56,520 --> 00:19:59,160
or sophisticated inference and granting

440
00:19:59,160 --> 00:20:02,160
time active inference all it does is it

441
00:20:02,160 --> 00:20:04,140
schedules the messages it says the first

442
00:20:04,140 --> 00:20:06,000
this message then this message then this

443
00:20:06,000 --> 00:20:09,960
message I don't mean that as a slide to

444
00:20:09,960 --> 00:20:12,120
these algorithms they're very clever and

445
00:20:12,120 --> 00:20:14,039
as we've seen in the presentation by

446
00:20:14,039 --> 00:20:16,260
asvine Paul you get huge improvements if

447
00:20:16,260 --> 00:20:17,820
you go from regular inference to

448
00:20:17,820 --> 00:20:20,700
sophisticated inference but it's good to

449
00:20:20,700 --> 00:20:22,799
realize that

450
00:20:22,799 --> 00:20:25,919
these algorithms just specify in the

451
00:20:25,919 --> 00:20:28,080
graph which message comes after which

452
00:20:28,080 --> 00:20:29,880
message

453
00:20:29,880 --> 00:20:32,220
um so here's an example

454
00:20:32,220 --> 00:20:35,100
here's an example of a graph and a

455
00:20:35,100 --> 00:20:37,200
message

456
00:20:37,200 --> 00:20:38,039
um

457
00:20:38,039 --> 00:20:40,500
sequence here's a message one then

458
00:20:40,500 --> 00:20:43,200
message H2 and message three goes up and

459
00:20:43,200 --> 00:20:46,559
then we go from FC to f f and here it

460
00:20:46,559 --> 00:20:49,260
matches five and then we go to Fe and

461
00:20:49,260 --> 00:20:51,559
this could correspond the sequence to

462
00:20:51,559 --> 00:20:54,299
Dynamic time programming efe or

463
00:20:54,299 --> 00:20:56,820
sophisticated inference

464
00:20:56,820 --> 00:20:58,799
um there are a couple of problems with

465
00:20:58,799 --> 00:21:00,840
this approach which we could basically

466
00:21:00,840 --> 00:21:04,440
with with having the user to specify a

467
00:21:04,440 --> 00:21:06,419
clever algorithm first of all

468
00:21:06,419 --> 00:21:08,340
you have to be a specialist to do it

469
00:21:08,340 --> 00:21:10,559
right only these are very clever people

470
00:21:10,559 --> 00:21:14,580
so so that means that um if we let it

471
00:21:14,580 --> 00:21:17,160
leave it to

472
00:21:17,160 --> 00:21:18,900
um let's say to an engineer in a company

473
00:21:18,900 --> 00:21:21,059
it's it's well it's the higher

474
00:21:21,059 --> 00:21:22,620
probability is not going to get it right

475
00:21:22,620 --> 00:21:24,960
that's very unfortunate

476
00:21:24,960 --> 00:21:27,900
um but there's another issue and that is

477
00:21:27,900 --> 00:21:29,940
that in it in a sense it's a global

478
00:21:29,940 --> 00:21:31,440
variable

479
00:21:31,440 --> 00:21:33,419
um in the message passing schedule all

480
00:21:33,419 --> 00:21:36,059
nodes are visited because if a node

481
00:21:36,059 --> 00:21:38,700
would not be visited then we shouldn't

482
00:21:38,700 --> 00:21:40,860
have it in the graph and that means if

483
00:21:40,860 --> 00:21:44,159
one node crashes basically the message

484
00:21:44,159 --> 00:21:46,559
passing schedule is invalid I have to

485
00:21:46,559 --> 00:21:48,480
reset my system

486
00:21:48,480 --> 00:21:50,580
and if you fly a drone if it's deployed

487
00:21:50,580 --> 00:21:53,039
and it's out in the field and a node

488
00:21:53,039 --> 00:21:56,520
crashes a transistor burns out and I

489
00:21:56,520 --> 00:21:58,320
have to totally reset now my system I

490
00:21:58,320 --> 00:22:00,179
have to compute a new message passing

491
00:22:00,179 --> 00:22:01,559
schedule

492
00:22:01,559 --> 00:22:03,179
um then you're not doing inference and

493
00:22:03,179 --> 00:22:05,100
you know in your drone flies into the

494
00:22:05,100 --> 00:22:09,120
wall so this is not robust and it also

495
00:22:09,120 --> 00:22:12,059
for very this the same reason we may

496
00:22:12,059 --> 00:22:14,940
actually want to take out a node we

497
00:22:14,940 --> 00:22:17,280
might we may want to prune a lot we

498
00:22:17,280 --> 00:22:20,100
might want to do structural adaptation

499
00:22:20,100 --> 00:22:21,780
and

500
00:22:21,780 --> 00:22:23,700
we can't do structural adaptation

501
00:22:23,700 --> 00:22:26,039
because we have to reset the system

502
00:22:26,039 --> 00:22:29,039
recompute a message passing schedule so

503
00:22:29,039 --> 00:22:32,340
this procedural style where an engineer

504
00:22:32,340 --> 00:22:35,640
app purely specifies which message comes

505
00:22:35,640 --> 00:22:37,559
after this message has some

506
00:22:37,559 --> 00:22:40,799
disadvantages it's not very robust and

507
00:22:40,799 --> 00:22:42,600
it's uh if you want to do it very clever

508
00:22:42,600 --> 00:22:46,980
you have to be really a specialist so a

509
00:22:46,980 --> 00:22:50,280
better system is what we call a reactive

510
00:22:50,280 --> 00:22:52,080
message passing

511
00:22:52,080 --> 00:22:56,700
and it's very related to what was in the

512
00:22:56,700 --> 00:22:59,580
first session uh called the the actor

513
00:22:59,580 --> 00:23:01,919
model Keith Duggar had a nice

514
00:23:01,919 --> 00:23:04,020
presentation on the actor model

515
00:23:04,020 --> 00:23:07,679
so what we will do is we will say we

516
00:23:07,679 --> 00:23:09,960
will not have a global message passing

517
00:23:09,960 --> 00:23:12,480
schedule the engineer will not space

518
00:23:12,480 --> 00:23:15,480
specify anything anymore the inference

519
00:23:15,480 --> 00:23:17,640
code that an engineer will have to write

520
00:23:17,640 --> 00:23:21,000
is just say react to any free energy

521
00:23:21,000 --> 00:23:23,460
minimization opportunity in other words

522
00:23:23,460 --> 00:23:25,440
there is no inference code it's

523
00:23:25,440 --> 00:23:27,059
completely automated

524
00:23:27,059 --> 00:23:28,559
and

525
00:23:28,559 --> 00:23:31,620
um we will replace This Global message

526
00:23:31,620 --> 00:23:34,559
passing schedule by local triggering

527
00:23:34,559 --> 00:23:37,679
inside the note so each node is now just

528
00:23:37,679 --> 00:23:40,320
an autonomous autonomous system that's

529
00:23:40,320 --> 00:23:42,440
interested in minimizing its free energy

530
00:23:42,440 --> 00:23:45,980
uh it can do so by sending out messages

531
00:23:45,980 --> 00:23:50,100
and when will it do so well it receives

532
00:23:50,100 --> 00:23:52,500
messages I mean it feels when it looks

533
00:23:52,500 --> 00:23:54,120
at these messages and it feels like oh

534
00:23:54,120 --> 00:23:55,799
there is an opportunity for me to

535
00:23:55,799 --> 00:23:57,360
minimize free energy

536
00:23:57,360 --> 00:24:00,299
buy or expect the free entry by sending

537
00:24:00,299 --> 00:24:02,039
out the message then will send out a

538
00:24:02,039 --> 00:24:05,460
message and each node will do so by

539
00:24:05,460 --> 00:24:08,159
itself asynchronously so you get

540
00:24:08,159 --> 00:24:10,320
parallel distributed processing or

541
00:24:10,320 --> 00:24:13,559
concurrent processing as Keys called it

542
00:24:13,559 --> 00:24:16,440
um in principle you could play this game

543
00:24:16,440 --> 00:24:20,280
on many uh computers at the same time uh

544
00:24:20,280 --> 00:24:25,280
and so you get tremendous uh advantages

545
00:24:25,280 --> 00:24:27,480
first of all you don't have to write

546
00:24:27,480 --> 00:24:30,240
difficult code second of all you can do

547
00:24:30,240 --> 00:24:33,840
multi-threading or you can you can run

548
00:24:33,840 --> 00:24:35,400
it on multiple computers at the same

549
00:24:35,400 --> 00:24:36,480
time

550
00:24:36,480 --> 00:24:40,980
and so and there's also robustness

551
00:24:40,980 --> 00:24:42,659
um

552
00:24:42,659 --> 00:24:45,419
um uh advantages because if a note

553
00:24:45,419 --> 00:24:49,140
crashes then there's nothing that stops

554
00:24:49,140 --> 00:24:50,580
the system from just finding another

555
00:24:50,580 --> 00:24:53,880
path right if if this node crashes this

556
00:24:53,880 --> 00:24:56,760
path from here's message three at this

557
00:24:56,760 --> 00:24:59,220
path Now doesn't work so I cannot send

558
00:24:59,220 --> 00:25:02,520
anything to Fe anymore from uh no from X

559
00:25:02,520 --> 00:25:04,919
well then I just sent a new message here

560
00:25:04,919 --> 00:25:08,340
why not it's like when water

561
00:25:08,340 --> 00:25:11,340
falls down a mountain and it zigzags its

562
00:25:11,340 --> 00:25:13,679
way down into the value and you have

563
00:25:13,679 --> 00:25:16,080
where you put up an obstruction it just

564
00:25:16,080 --> 00:25:18,120
finds another path

565
00:25:18,120 --> 00:25:21,840
um not the preferred path this has to

566
00:25:21,840 --> 00:25:24,360
find well the the second the second best

567
00:25:24,360 --> 00:25:26,039
path because the first path has been

568
00:25:26,039 --> 00:25:27,960
obstructed right and that's that's

569
00:25:27,960 --> 00:25:29,700
what's going to happen in this system as

570
00:25:29,700 --> 00:25:32,279
well right that's just how nature works

571
00:25:32,279 --> 00:25:34,200
it tries to find the best path the

572
00:25:34,200 --> 00:25:35,580
easiest path and if that's not available

573
00:25:35,580 --> 00:25:37,559
then we do the second best pass and

574
00:25:37,559 --> 00:25:39,360
that's also what you can do with

575
00:25:39,360 --> 00:25:41,820
reactive message passing so you can

576
00:25:41,820 --> 00:25:43,980
prove notes you can do structural

577
00:25:43,980 --> 00:25:45,720
adaptation

578
00:25:45,720 --> 00:25:49,440
um and it's far more robust and you can

579
00:25:49,440 --> 00:25:53,100
also get uh let's do um chance

580
00:25:53,100 --> 00:25:55,980
encounters with other drones right

581
00:25:55,980 --> 00:25:58,080
drones that get close can start

582
00:25:58,080 --> 00:26:00,900
communicating with each other and when

583
00:26:00,900 --> 00:26:02,760
they're far away they stop communicating

584
00:26:02,760 --> 00:26:04,860
with each other and this is no problem

585
00:26:04,860 --> 00:26:09,240
because you can basically change

586
00:26:09,240 --> 00:26:11,640
who changed

587
00:26:11,640 --> 00:26:13,279
um

588
00:26:13,279 --> 00:26:16,080
nodes can change on the Fly who they

589
00:26:16,080 --> 00:26:18,240
communicate to and who they want to

590
00:26:18,240 --> 00:26:22,020
listen to and so that's that's the way

591
00:26:22,020 --> 00:26:24,840
data works and also how it works when we

592
00:26:24,840 --> 00:26:26,700
do a reactive

593
00:26:26,700 --> 00:26:29,820
um programming area with message passing

594
00:26:29,820 --> 00:26:32,760
so in summary

595
00:26:32,760 --> 00:26:35,100
we're interested in automating inference

596
00:26:35,100 --> 00:26:38,900
in um active influence agents right

597
00:26:38,900 --> 00:26:42,419
because it's an operation that's

598
00:26:42,419 --> 00:26:46,260
basically only for for experts and this

599
00:26:46,260 --> 00:26:48,779
active inference technology is not going

600
00:26:48,779 --> 00:26:51,240
to be successful unless you get more

601
00:26:51,240 --> 00:26:54,360
people uh let's democratize it and we

602
00:26:54,360 --> 00:26:58,080
get competent Engineers being able to

603
00:26:58,080 --> 00:27:00,600
develop good agents right you shouldn't

604
00:27:00,600 --> 00:27:02,640
have to be a top specialists in the

605
00:27:02,640 --> 00:27:04,679
world to develop an active inference

606
00:27:04,679 --> 00:27:08,880
agent now in order to automate

607
00:27:08,880 --> 00:27:11,400
inference you must do message passing

608
00:27:11,400 --> 00:27:12,600
and I've talked about that for

609
00:27:12,600 --> 00:27:15,179
efficiency I've also talked about which

610
00:27:15,179 --> 00:27:17,039
messages to pass

611
00:27:17,039 --> 00:27:19,620
not necessarily do you have to follow

612
00:27:19,620 --> 00:27:22,919
this framework but constrained better

613
00:27:22,919 --> 00:27:25,919
free energy framework is very convenient

614
00:27:25,919 --> 00:27:27,480
it's an umbrella framework that

615
00:27:27,480 --> 00:27:29,340
basically

616
00:27:29,340 --> 00:27:30,179
um

617
00:27:30,179 --> 00:27:34,340
goes over all the interesting other

618
00:27:34,340 --> 00:27:38,760
messages passing computations when Nas

619
00:27:38,760 --> 00:27:40,559
is passing a reactiveness is passing

620
00:27:40,559 --> 00:27:42,720
it's fully automated so you don't have

621
00:27:42,720 --> 00:27:44,880
to write any code anymore

622
00:27:44,880 --> 00:27:48,000
in principle it's come it's you can do

623
00:27:48,000 --> 00:27:49,740
parallel distributed processing it's

624
00:27:49,740 --> 00:27:51,539
robust to structural changes you can

625
00:27:51,539 --> 00:27:53,880
learn new inference Pathways so lots of

626
00:27:53,880 --> 00:27:56,340
lots of advantages here

627
00:27:56,340 --> 00:27:57,659
now

628
00:27:57,659 --> 00:28:00,120
how do we do it

629
00:28:00,120 --> 00:28:02,520
um I'd like to introduce a toolbox that

630
00:28:02,520 --> 00:28:05,820
we've been working on uh called RX infer

631
00:28:05,820 --> 00:28:09,539
and we do that with my lab here at the

632
00:28:09,539 --> 00:28:11,520
University I'm here in Eindhoven in the

633
00:28:11,520 --> 00:28:13,260
south of the Netherlands and we have a

634
00:28:13,260 --> 00:28:17,059
lab the lab is called bislab here are

635
00:28:17,059 --> 00:28:21,059
postdocs and assisted professors and PhD

636
00:28:21,059 --> 00:28:23,220
students and we've been working on this

637
00:28:23,220 --> 00:28:27,419
for many years and some of these

638
00:28:27,419 --> 00:28:28,080
um

639
00:28:28,080 --> 00:28:31,440
like Albert and Ismail and thanks

640
00:28:31,440 --> 00:28:33,980
um have written dissertations

641
00:28:33,980 --> 00:28:36,960
and our best work we have Consolidated

642
00:28:36,960 --> 00:28:39,059
that in a toolbox

643
00:28:39,059 --> 00:28:41,700
and the toolbox is called RX infer and

644
00:28:41,700 --> 00:28:43,740
you can if you want to have a look you

645
00:28:43,740 --> 00:28:46,980
can go to the website archiver.ml

646
00:28:46,980 --> 00:28:50,779
um and asking for that our confer Works

647
00:28:50,779 --> 00:28:53,159
uh in the way that I've just discussed

648
00:28:53,159 --> 00:28:55,679
it does message passing it tries to

649
00:28:55,679 --> 00:28:57,539
minimize constraining better free energy

650
00:28:57,539 --> 00:29:00,299
that means it it can come up with all

651
00:29:00,299 --> 00:29:04,020
kinds of uh message passing algorithms

652
00:29:04,020 --> 00:29:07,860
um it will do it in a reactive way and

653
00:29:07,860 --> 00:29:10,440
they'll try to do it in real time and

654
00:29:10,440 --> 00:29:12,419
low power and all the kpis that we're

655
00:29:12,419 --> 00:29:13,919
talking about now it's of course not

656
00:29:13,919 --> 00:29:18,299
done but um it's functional and like to

657
00:29:18,299 --> 00:29:20,899
show some demos and I will

658
00:29:20,899 --> 00:29:24,059
leave it to Dimitri and Bart who are two

659
00:29:24,059 --> 00:29:27,779
Advanced PC students in my lab to show

660
00:29:27,779 --> 00:29:30,320
the demos

661
00:29:30,899 --> 00:29:33,720
so I'm gonna stop

662
00:29:33,720 --> 00:29:36,440
sharing

663
00:29:37,500 --> 00:29:42,360
awesome thank you great talk sure

664
00:29:42,360 --> 00:29:45,480
uh can you hear me yeah yeah

665
00:29:45,480 --> 00:29:50,279
okay I will try to share my screen okay

666
00:29:50,279 --> 00:29:52,559
so you should see it now

667
00:29:52,559 --> 00:29:54,000
looks good

668
00:29:54,000 --> 00:29:57,600
okay so yeah hello uh to everyone uh I'm

669
00:29:57,600 --> 00:30:00,059
uh Dimitri bag so I'm a PhD student in

670
00:30:00,059 --> 00:30:01,740
bioslap and I'm from the University of

671
00:30:01,740 --> 00:30:04,320
Technology uh and yes I have a small

672
00:30:04,320 --> 00:30:06,659
presentation about the actual software

673
00:30:06,659 --> 00:30:09,240
developments and bias lab and yeah so

674
00:30:09,240 --> 00:30:12,240
all over the past few years we have

675
00:30:12,240 --> 00:30:15,000
significantly improved our tools and

676
00:30:15,000 --> 00:30:17,460
basically my entire PhD was dedicated to

677
00:30:17,460 --> 00:30:19,919
implement the this idea which Bert was

678
00:30:19,919 --> 00:30:22,380
talking about uh like implementing the

679
00:30:22,380 --> 00:30:23,940
variational reactive message possible

680
00:30:23,940 --> 00:30:25,679
and in this presentation I just want to

681
00:30:25,679 --> 00:30:28,559
show you what you can actually do uh

682
00:30:28,559 --> 00:30:31,799
using this Theory under the hood

683
00:30:31,799 --> 00:30:35,279
okay so basically in order to automate

684
00:30:35,279 --> 00:30:36,659
active inference right we need to

685
00:30:36,659 --> 00:30:38,760
automate Bayesian influence and we have

686
00:30:38,760 --> 00:30:40,860
uh we have already a lot of solutions

687
00:30:40,860 --> 00:30:44,520
for that as I just Stan pyro numpyre

688
00:30:44,520 --> 00:30:46,740
which is funded by Google internet is

689
00:30:46,740 --> 00:30:49,200
funded by Microsoft Turing is in July

690
00:30:49,200 --> 00:30:52,820
IMC and many many so uh and basically

691
00:30:52,820 --> 00:30:54,960
these Solutions are really really good

692
00:30:54,960 --> 00:30:56,880
so uh and they're really good at

693
00:30:56,880 --> 00:31:00,000
prototyping as well our goal is

694
00:31:00,000 --> 00:31:02,460
eventually to be able to deploy this

695
00:31:02,460 --> 00:31:05,279
kind of systems not just prototype and

696
00:31:05,279 --> 00:31:06,720
we are really focusing on this

697
00:31:06,720 --> 00:31:08,760
particular properties for this ultimate

698
00:31:08,760 --> 00:31:12,299
Invasion inference uh so it must be low

699
00:31:12,299 --> 00:31:15,539
power adaptive real-time scalable it

700
00:31:15,539 --> 00:31:17,340
also must be user friendly at the end

701
00:31:17,340 --> 00:31:19,559
and it must support the large scope of

702
00:31:19,559 --> 00:31:22,760
models if you want it to be useful

703
00:31:22,760 --> 00:31:26,399
so and in bias lab we want to build such

704
00:31:26,399 --> 00:31:30,559
a software uh with such nice properties

705
00:31:30,559 --> 00:31:33,480
and it's always about Traders right so

706
00:31:33,480 --> 00:31:35,100
we do something better in one particular

707
00:31:35,100 --> 00:31:37,140
domain and maybe other software

708
00:31:37,140 --> 00:31:39,480
libraries they might be better in a

709
00:31:39,480 --> 00:31:41,520
different domain so but we are really

710
00:31:41,520 --> 00:31:44,159
focusing on this particular properties

711
00:31:44,159 --> 00:31:47,039
uh and so yes I will reiterate a little

712
00:31:47,039 --> 00:31:48,779
bit best presentation so how do we

713
00:31:48,779 --> 00:31:50,760
achieve this so we have imagine we have

714
00:31:50,760 --> 00:31:53,520
an environment and we have an agent uh

715
00:31:53,520 --> 00:31:55,020
and the agent allowed to take some

716
00:31:55,020 --> 00:31:57,720
actions and the agent basically what he

717
00:31:57,720 --> 00:32:00,480
needs is to come up with some sort of

718
00:32:00,480 --> 00:32:02,580
good enough probabilistic model of its

719
00:32:02,580 --> 00:32:03,779
environment

720
00:32:03,779 --> 00:32:06,600
in order to do patient inference

721
00:32:06,600 --> 00:32:09,360
uh and in our framework we encode the

722
00:32:09,360 --> 00:32:11,520
model as a factor graph which not only

723
00:32:11,520 --> 00:32:15,000
models the observations but also actions

724
00:32:15,000 --> 00:32:17,539
and desired future

725
00:32:17,539 --> 00:32:20,820
uh and this this approach allows us to

726
00:32:20,820 --> 00:32:23,279
decompose the this complex relationships

727
00:32:23,279 --> 00:32:26,460
between variables and hidden States into

728
00:32:26,460 --> 00:32:28,919
some kind of structure and local blocks

729
00:32:28,919 --> 00:32:31,440
uh and it's not a block it's not a black

730
00:32:31,440 --> 00:32:34,679
box anymore so uh and the model itself

731
00:32:34,679 --> 00:32:36,120
may have some sort of background

732
00:32:36,120 --> 00:32:39,419
motivation interpretation it may encode

733
00:32:39,419 --> 00:32:41,340
your prior knowledge about some

734
00:32:41,340 --> 00:32:43,200
particular physical system

735
00:32:43,200 --> 00:32:46,559
uh and the locality of these blocks

736
00:32:46,559 --> 00:32:49,080
basically allows you to scale to

737
00:32:49,080 --> 00:32:50,880
millions of variables and hidden States

738
00:32:50,880 --> 00:32:53,399
it allows you to pre-optimize it maybe

739
00:32:53,399 --> 00:32:55,520
or maybe use like some sort of different

740
00:32:55,520 --> 00:32:57,659
approximation strategies in different

741
00:32:57,659 --> 00:33:01,440
places uh so it allows a lot of very

742
00:33:01,440 --> 00:33:03,600
nice properties as well

743
00:33:03,600 --> 00:33:06,480
and we use reactive message passing to

744
00:33:06,480 --> 00:33:08,159
run uh actual variational version

745
00:33:08,159 --> 00:33:11,279
inference it uses reactive programming

746
00:33:11,279 --> 00:33:13,140
under the hood to minimize the

747
00:33:13,140 --> 00:33:14,700
approximation to the variation of the

748
00:33:14,700 --> 00:33:17,820
energy and yes as berdos mentioned it's

749
00:33:17,820 --> 00:33:22,399
it's very much related to actor model

750
00:33:22,399 --> 00:33:26,039
and basically indirect transfer you can

751
00:33:26,039 --> 00:33:28,380
think of different nodes as actors

752
00:33:28,380 --> 00:33:29,760
themselves

753
00:33:29,760 --> 00:33:32,460
uh so and they have basically one single

754
00:33:32,460 --> 00:33:34,620
purpose is to send a variational message

755
00:33:34,620 --> 00:33:36,539
that minimizes for energy

756
00:33:36,539 --> 00:33:38,760
uh this is a very short and very high

757
00:33:38,760 --> 00:33:40,799
level description but it is essentially

758
00:33:40,799 --> 00:33:44,519
what is happening so we are not treating

759
00:33:44,519 --> 00:33:47,580
different agents which interact with

760
00:33:47,580 --> 00:33:49,980
each other as actors but we also treat

761
00:33:49,980 --> 00:33:52,260
the the actual components of the

762
00:33:52,260 --> 00:33:54,779
underlying model as actors themselves

763
00:33:54,779 --> 00:33:57,000
it's like a very hierarchical structure

764
00:33:57,000 --> 00:34:01,260
so this is the main central idea of of

765
00:34:01,260 --> 00:34:03,600
this inference

766
00:34:03,600 --> 00:34:06,840
uh so here for example a first example

767
00:34:06,840 --> 00:34:08,879
we can do an inference in a dynamical

768
00:34:08,879 --> 00:34:11,760
system and this example which is quite

769
00:34:11,760 --> 00:34:13,619
old already I think it's like two years

770
00:34:13,619 --> 00:34:16,679
ago so we we track a position of the

771
00:34:16,679 --> 00:34:18,359
object given some noisy measurements

772
00:34:18,359 --> 00:34:22,379
which are indicated by Green Dots the

773
00:34:22,379 --> 00:34:24,899
actual real signal we cannot observe it

774
00:34:24,899 --> 00:34:27,540
but we just can plot it uh estron is

775
00:34:27,540 --> 00:34:30,000
blue and the invert signal is shown as

776
00:34:30,000 --> 00:34:32,699
red and the data set is infinite the

777
00:34:32,699 --> 00:34:34,739
inference and just reacts on it and does

778
00:34:34,739 --> 00:34:37,159
not assume on any particular data size

779
00:34:37,159 --> 00:34:39,359
simply reacts in your observation as

780
00:34:39,359 --> 00:34:40,619
soon as possible

781
00:34:40,619 --> 00:34:42,719
uh yeah I'm actually not sure how

782
00:34:42,719 --> 00:34:46,080
smoothly Zoom shares my screen uh maybe

783
00:34:46,080 --> 00:34:48,239
you can see it a bit lagging in the

784
00:34:48,239 --> 00:34:49,980
animations I'm not sure because maybe

785
00:34:49,980 --> 00:34:51,899
Zoom does not share it on a full frame

786
00:34:51,899 --> 00:34:53,280
rate

787
00:34:53,280 --> 00:34:55,260
um and also on the right hand side you

788
00:34:55,260 --> 00:34:58,500
can see how we Define models uh in our

789
00:34:58,500 --> 00:35:00,240
framework we use jewelry as a

790
00:35:00,240 --> 00:35:01,880
programming language

791
00:35:01,880 --> 00:35:04,619
and so basically this is everything that

792
00:35:04,619 --> 00:35:06,180
you need to Define this particular model

793
00:35:06,180 --> 00:35:09,240
and run inference on a data set and

794
00:35:09,240 --> 00:35:11,820
actually I like really spend more days

795
00:35:11,820 --> 00:35:14,760
to plot it instead of in France right so

796
00:35:14,760 --> 00:35:17,280
inference was was an easy easiest part

797
00:35:17,280 --> 00:35:19,680
from approaching was way much harder

798
00:35:19,680 --> 00:35:22,520
relate to user friendliness

799
00:35:22,520 --> 00:35:25,560
so and we actually have plans to improve

800
00:35:25,560 --> 00:35:28,020
our model specification language make it

801
00:35:28,020 --> 00:35:30,119
even easier so now for technical reasons

802
00:35:30,119 --> 00:35:32,760
we have some auxiliary statements and

803
00:35:32,760 --> 00:35:34,859
model specification language but we are

804
00:35:34,859 --> 00:35:38,339
working to improve that and make it even

805
00:35:38,339 --> 00:35:39,960
easier

806
00:35:39,960 --> 00:35:41,280
uh

807
00:35:41,280 --> 00:35:43,619
this is another example which is similar

808
00:35:43,619 --> 00:35:45,960
to the previous one but uses much more

809
00:35:45,960 --> 00:35:48,119
complex and linear dynamical system of

810
00:35:48,119 --> 00:35:50,520
the double pendulum and the system is

811
00:35:50,520 --> 00:35:53,760
chaotic and we can observe on this small

812
00:35:53,760 --> 00:35:56,460
part of it a lot of noise also indicated

813
00:35:56,460 --> 00:35:58,020
as a green dots

814
00:35:58,020 --> 00:36:00,800
uh and nonetheless given

815
00:36:00,800 --> 00:36:04,260
given good enough model uh you can infer

816
00:36:04,260 --> 00:36:06,839
the other hidden states with pretty much

817
00:36:06,839 --> 00:36:10,320
High precision and the code needed for

818
00:36:10,320 --> 00:36:15,380
that is also relatively short and yeah

819
00:36:15,480 --> 00:36:19,200
we also have uh examples with active

820
00:36:19,200 --> 00:36:21,359
inference agents that interact with

821
00:36:21,359 --> 00:36:22,800
their environment

822
00:36:22,800 --> 00:36:25,380
uh so the left uh

823
00:36:25,380 --> 00:36:29,460
it's left up shows uh yeah Mountain

824
00:36:29,460 --> 00:36:32,220
curve problem very famous problem the

825
00:36:32,220 --> 00:36:34,200
left bottom side shows an active

826
00:36:34,200 --> 00:36:36,599
inference agent which tries to control

827
00:36:36,599 --> 00:36:39,300
the inverted pendulum from falling in

828
00:36:39,300 --> 00:36:42,780
the windy conditions the tracks and wind

829
00:36:42,780 --> 00:36:44,760
we also have a demo of an agent that

830
00:36:44,760 --> 00:36:47,520
controls a pendulum in an ever-changing

831
00:36:47,520 --> 00:36:50,640
environment so on the right side you see

832
00:36:50,640 --> 00:36:52,560
a pendulum with an engine and an engine

833
00:36:52,560 --> 00:36:54,900
has engine has limited power

834
00:36:54,900 --> 00:36:57,780
and the agent itself needs to reach the

835
00:36:57,780 --> 00:36:59,940
goal and the goal is indicated as a red

836
00:36:59,940 --> 00:37:02,240
circle so and

837
00:37:02,240 --> 00:37:04,740
basically in this demo we can change the

838
00:37:04,740 --> 00:37:06,599
environment in real time and see how the

839
00:37:06,599 --> 00:37:08,760
agent reacts so you can change the mass

840
00:37:08,760 --> 00:37:11,099
of the pendulum on its slang for the

841
00:37:11,099 --> 00:37:13,980
amount of noise in the measurements or

842
00:37:13,980 --> 00:37:15,780
we can change the goal we can change

843
00:37:15,780 --> 00:37:18,300
maximum engine power Etc right so the

844
00:37:18,300 --> 00:37:20,700
agent will still try to infer the best

845
00:37:20,700 --> 00:37:23,220
possible course of actions in order to

846
00:37:23,220 --> 00:37:25,800
reach its goal and it just never stops

847
00:37:25,800 --> 00:37:28,079
reacting

848
00:37:28,079 --> 00:37:30,440
um it's it's also actually possible to

849
00:37:30,440 --> 00:37:33,960
restrict ancient power such that it will

850
00:37:33,960 --> 00:37:36,180
no not longer possible to reach the goal

851
00:37:36,180 --> 00:37:39,320
right but the agent would still try

852
00:37:39,320 --> 00:37:42,960
uh we have other cool demos with smart

853
00:37:42,960 --> 00:37:46,380
navigation and collision avoidance uh

854
00:37:46,380 --> 00:37:48,119
which are still under active research

855
00:37:48,119 --> 00:37:50,160
and the code for them is not available

856
00:37:50,160 --> 00:37:52,260
publicly it will be soon available but

857
00:37:52,260 --> 00:37:55,380
for example in this example we can

858
00:37:55,380 --> 00:37:57,240
define a set of Agents with their

859
00:37:57,240 --> 00:37:59,460
boundaries and a set of their

860
00:37:59,460 --> 00:38:02,640
destinations so and we can see how they

861
00:38:02,640 --> 00:38:06,540
try to resolve their Roots all together

862
00:38:06,540 --> 00:38:07,200
um

863
00:38:07,200 --> 00:38:10,079
and we can have some static obstacles in

864
00:38:10,079 --> 00:38:13,020
the map we can see how agents can find

865
00:38:13,020 --> 00:38:15,839
their most optimal path

866
00:38:15,839 --> 00:38:18,839
in order to reach their goals and avoid

867
00:38:18,839 --> 00:38:21,320
any possible Collision

868
00:38:21,320 --> 00:38:23,940
and it's also not necessary to have

869
00:38:23,940 --> 00:38:27,119
static obstacles uh the obstacles

870
00:38:27,119 --> 00:38:30,000
themselves may move so in this demo we

871
00:38:30,000 --> 00:38:32,820
have hundreds of agents that navigate

872
00:38:32,820 --> 00:38:35,099
through a map of obstacles that move

873
00:38:35,099 --> 00:38:37,140
from bottom to top to the circles or

874
00:38:37,140 --> 00:38:40,260
obstacles and agents are depicted as

875
00:38:40,260 --> 00:38:42,900
small dots and they need to go from left

876
00:38:42,900 --> 00:38:45,240
to right basically avoid any sort of

877
00:38:45,240 --> 00:38:47,220
pollution

878
00:38:47,220 --> 00:38:50,820
uh and as I also mentioned we want to

879
00:38:50,820 --> 00:38:52,740
perform efficient and real-time

880
00:38:52,740 --> 00:38:55,260
inference but we also do it like low

881
00:38:55,260 --> 00:38:57,900
power low performance uh on low

882
00:38:57,900 --> 00:39:00,180
performance devices such as Raspberry Pi

883
00:39:00,180 --> 00:39:03,300
or coolpy as an example and we have some

884
00:39:03,300 --> 00:39:05,820
results of successful in running uh the

885
00:39:05,820 --> 00:39:07,500
Bayesian audio Source separation for

886
00:39:07,500 --> 00:39:10,079
example on cool Pi so it is actually

887
00:39:10,079 --> 00:39:13,440
possible we also run active we try to

888
00:39:13,440 --> 00:39:16,260
run active inference agents also on

889
00:39:16,260 --> 00:39:20,040
coolpy so as the aforementioned inverted

890
00:39:20,040 --> 00:39:21,440
pendulum

891
00:39:21,440 --> 00:39:23,160
and

892
00:39:23,160 --> 00:39:25,079
as I mentioned

893
00:39:25,079 --> 00:39:29,220
we also need to have a large model scope

894
00:39:29,220 --> 00:39:31,980
and basically RX infer has not been

895
00:39:31,980 --> 00:39:33,960
designed to solve any of the

896
00:39:33,960 --> 00:39:36,599
aforementioned problems specifically

897
00:39:36,599 --> 00:39:38,520
we have a large set of different

898
00:39:38,520 --> 00:39:40,980
examples in our repository different

899
00:39:40,980 --> 00:39:42,300
models different data different

900
00:39:42,300 --> 00:39:44,040
influence constraints

901
00:39:44,040 --> 00:39:46,380
uh we have examples for linear

902
00:39:46,380 --> 00:39:48,060
regression hidden Markov Model Auto

903
00:39:48,060 --> 00:39:50,640
regress model hierarchy models mixture

904
00:39:50,640 --> 00:39:53,520
models gaussian process and so on so

905
00:39:53,520 --> 00:39:56,760
right so this approach is very versatile

906
00:39:56,760 --> 00:40:00,060
and for example if you

907
00:40:00,060 --> 00:40:02,880
um if you compare it with sort of a

908
00:40:02,880 --> 00:40:05,220
conventional software libraries where

909
00:40:05,220 --> 00:40:07,200
you let's say have a library that solves

910
00:40:07,200 --> 00:40:09,060
a common filter might be a very great

911
00:40:09,060 --> 00:40:11,579
Library maybe super fast have top

912
00:40:11,579 --> 00:40:13,920
performance works great and very

913
00:40:13,920 --> 00:40:15,119
reliable

914
00:40:15,119 --> 00:40:17,820
uh it's super good but then you are

915
00:40:17,820 --> 00:40:20,460
constrained by by this particular model

916
00:40:20,460 --> 00:40:22,859
common filtering right and you can't

917
00:40:22,859 --> 00:40:25,400
really change it much

918
00:40:25,400 --> 00:40:29,240
we we are free to Define our own models

919
00:40:29,240 --> 00:40:31,800
uh which we can pretty much easily

920
00:40:31,800 --> 00:40:33,720
Define a model that essentially would

921
00:40:33,720 --> 00:40:36,599
act equivalently to Common filtering

922
00:40:36,599 --> 00:40:38,700
equation and so basically in the demo

923
00:40:38,700 --> 00:40:40,500
that I showed before about object

924
00:40:40,500 --> 00:40:42,839
tracking it was essentially a common

925
00:40:42,839 --> 00:40:43,980
filter

926
00:40:43,980 --> 00:40:47,160
that was written in a in a probabilistic

927
00:40:47,160 --> 00:40:49,140
model

928
00:40:49,140 --> 00:40:52,200
uh so yeah that was my small addition to

929
00:40:52,200 --> 00:40:55,079
this presentation so our software is

930
00:40:55,079 --> 00:40:57,960
free it's an MIT license and it's open

931
00:40:57,960 --> 00:41:00,240
source available on GitHub

932
00:41:00,240 --> 00:41:03,540
uh yeah and we would be happy thanks to

933
00:41:03,540 --> 00:41:05,400
be able to present where we would be

934
00:41:05,400 --> 00:41:09,920
happy to answer any questions thanks

935
00:41:12,180 --> 00:41:14,960
awesome

936
00:41:15,000 --> 00:41:17,700
awesome all right I'll just ask a quick

937
00:41:17,700 --> 00:41:19,980
question in the chat

938
00:41:19,980 --> 00:41:22,619
Marco asks

939
00:41:22,619 --> 00:41:24,900
sorry if I missed it are the collision

940
00:41:24,900 --> 00:41:27,540
avoidance demos real time adapting to

941
00:41:27,540 --> 00:41:29,220
other agents Behavior or is it a

942
00:41:29,220 --> 00:41:32,720
collectively pre-computed path

943
00:41:33,240 --> 00:41:35,880
um so basically they are not uh super

944
00:41:35,880 --> 00:41:38,099
real time they're kind of fast to

945
00:41:38,099 --> 00:41:39,839
compute this path but maybe five seconds

946
00:41:39,839 --> 00:41:42,599
or so but we're basically working to

947
00:41:42,599 --> 00:41:44,820
make it real time so we know what is the

948
00:41:44,820 --> 00:41:47,460
problem we know where to improve

949
00:41:47,460 --> 00:41:50,339
and we will make it feel bad yes

950
00:41:50,339 --> 00:41:53,400
almost almost like

951
00:41:53,400 --> 00:41:55,440
next question do you have some

952
00:41:55,440 --> 00:41:57,960
comparative data with other methods and

953
00:41:57,960 --> 00:42:00,000
just more generally what kinds of

954
00:42:00,000 --> 00:42:02,520
benchmarks or what when you're talking

955
00:42:02,520 --> 00:42:04,619
with industry in different settings what

956
00:42:04,619 --> 00:42:07,800
are people like looking for that killer

957
00:42:07,800 --> 00:42:09,599
app of active inference or what are they

958
00:42:09,599 --> 00:42:13,920
looking for their key measures

959
00:42:13,920 --> 00:42:16,260
uh so I personally have a big paper

960
00:42:16,260 --> 00:42:19,200
about the comparison with sampling based

961
00:42:19,200 --> 00:42:23,220
methods like HMC and also in my PhD this

962
00:42:23,220 --> 00:42:25,079
result there will be a comparison if not

963
00:42:25,079 --> 00:42:29,280
also other sampling based methods uh so

964
00:42:29,280 --> 00:42:31,680
long story short sampling based methods

965
00:42:31,680 --> 00:42:33,900
cannot really run uh this kind of

966
00:42:33,900 --> 00:42:36,119
sophisticated inference in real time

967
00:42:36,119 --> 00:42:38,640
uh they're very time consuming they do

968
00:42:38,640 --> 00:42:40,740
not really scale well to large problems

969
00:42:40,740 --> 00:42:42,420
which is really needed for active

970
00:42:42,420 --> 00:42:44,400
influences because if you have like a

971
00:42:44,400 --> 00:42:46,560
large environment very complicated you

972
00:42:46,560 --> 00:42:49,619
will have you will have a lot of unknown

973
00:42:49,619 --> 00:42:53,940
variables in your model uh so yeah so

974
00:42:53,940 --> 00:42:56,520
there is a paper that compares and

975
00:42:56,520 --> 00:42:58,380
basically we show that yeah our approach

976
00:42:58,380 --> 00:43:01,859
scales much much better so I personally

977
00:43:01,859 --> 00:43:05,180
run on just just a regular MacBook

978
00:43:05,180 --> 00:43:08,660
laptop I run the model with 2 million uh

979
00:43:08,660 --> 00:43:12,060
unknown variables plus and it was like

980
00:43:12,060 --> 00:43:15,240
quite quite fast and then and if

981
00:43:15,240 --> 00:43:17,760
sampling based methods you may you may

982
00:43:17,760 --> 00:43:19,980
find yourself in the model with like 100

983
00:43:19,980 --> 00:43:21,780
variables and then you wait like two

984
00:43:21,780 --> 00:43:24,300
hours or something and then it turns out

985
00:43:24,300 --> 00:43:28,020
that your chain did not converge so uh

986
00:43:28,020 --> 00:43:30,980
or something like that

987
00:43:31,980 --> 00:43:34,560
cool yeah it's um people commenting in

988
00:43:34,560 --> 00:43:37,500
the chat like how far message passing

989
00:43:37,500 --> 00:43:41,040
and Factor graphs have come and so to to

990
00:43:41,040 --> 00:43:43,380
bias lab and to Bert at all we

991
00:43:43,380 --> 00:43:44,520
definitely

992
00:43:44,520 --> 00:43:46,680
appreciate this exciting line of

993
00:43:46,680 --> 00:43:48,420
research I mean there's so much to learn

994
00:43:48,420 --> 00:43:50,400
there and sometimes looking at the

995
00:43:50,400 --> 00:43:52,440
equations it can seem like it's like

996
00:43:52,440 --> 00:43:54,720
written in stone and just sort of the

997
00:43:54,720 --> 00:43:56,400
beginning and the end is you know

998
00:43:56,400 --> 00:43:59,099
variational free energy but then in your

999
00:43:59,099 --> 00:44:00,720
presentations you're really showing like

1000
00:44:00,720 --> 00:44:04,020
no we we are Hands-On that's where we

1001
00:44:04,020 --> 00:44:06,180
get the interpretability the modularity

1002
00:44:06,180 --> 00:44:08,700
that's where it really is implemented

1003
00:44:08,700 --> 00:44:11,400
and it's like an information Logistics

1004
00:44:11,400 --> 00:44:13,800
challenge it's not like an esoteric

1005
00:44:13,800 --> 00:44:16,980
philosophy question at that point

1006
00:44:16,980 --> 00:44:19,800
no no in indeed and I mean I

1007
00:44:19,800 --> 00:44:22,859
I should say it's uh it's taken us I

1008
00:44:22,859 --> 00:44:25,619
mean we're no Geniuses right so our lab

1009
00:44:25,619 --> 00:44:28,200
exists more than eight years and and you

1010
00:44:28,200 --> 00:44:30,119
see all the people in the lab it's taken

1011
00:44:30,119 --> 00:44:33,060
us many many many years with lots of

1012
00:44:33,060 --> 00:44:35,700
wrong directions to get this to work to

1013
00:44:35,700 --> 00:44:38,359
where it's now so it's a very long path

1014
00:44:38,359 --> 00:44:42,060
but the the at this moment I'm pretty

1015
00:44:42,060 --> 00:44:44,640
confident that at some point in the

1016
00:44:44,640 --> 00:44:47,339
future and I don't want to put a uh I

1017
00:44:47,339 --> 00:44:48,839
don't want to say in three months or one

1018
00:44:48,839 --> 00:44:52,440
year but it we will be able to write a

1019
00:44:52,440 --> 00:44:54,780
toolbox that will allow people to design

1020
00:44:54,780 --> 00:44:56,700
a generative model and just press a

1021
00:44:56,700 --> 00:44:59,040
button and and forget about the

1022
00:44:59,040 --> 00:45:00,420
influence you don't have to worry about

1023
00:45:00,420 --> 00:45:02,400
infants anymore it will be

1024
00:45:02,400 --> 00:45:05,520
fast and automated and that will happen

1025
00:45:05,520 --> 00:45:07,400
and it will happen within a few years

1026
00:45:07,400 --> 00:45:10,500
and uh and maybe somebody else will

1027
00:45:10,500 --> 00:45:12,839
write an even better toolbox but I'm

1028
00:45:12,839 --> 00:45:14,960
pretty confident that even our Toolbox

1029
00:45:14,960 --> 00:45:18,300
will be able to do that so

1030
00:45:18,300 --> 00:45:21,240
um and I think that yeah you know people

1031
00:45:21,240 --> 00:45:24,780
talk about uh so why don't we have the

1032
00:45:24,780 --> 00:45:26,280
success of deep learning and generative

1033
00:45:26,280 --> 00:45:29,280
AI right well if they have the success

1034
00:45:29,280 --> 00:45:32,099
because of a big data availability of

1035
00:45:32,099 --> 00:45:34,640
Big Data big computers and toolboxes

1036
00:45:34,640 --> 00:45:38,280
tensorflow and all the successes we

1037
00:45:38,280 --> 00:45:40,740
don't need big data because agents

1038
00:45:40,740 --> 00:45:42,839
collect their own data on or in the

1039
00:45:42,839 --> 00:45:45,119
filter we don't need big computers

1040
00:45:45,119 --> 00:45:47,700
active interest agents

1041
00:45:47,700 --> 00:45:49,920
you know they they manage their power

1042
00:45:49,920 --> 00:45:51,119
resources

1043
00:45:51,119 --> 00:45:53,099
but we need a really good toolbox

1044
00:45:53,099 --> 00:45:54,980
because

1045
00:45:54,980 --> 00:45:57,300
programming and active inference agent

1046
00:45:57,300 --> 00:45:59,280
programming the influence by hand is

1047
00:45:59,280 --> 00:46:00,599
just not doable

1048
00:46:00,599 --> 00:46:04,140
so we need a really good toolbox that

1049
00:46:04,140 --> 00:46:06,300
really automates this

1050
00:46:06,300 --> 00:46:08,160
we hope uh

1051
00:46:08,160 --> 00:46:10,140
our example will be one of the first two

1052
00:46:10,140 --> 00:46:13,140
boxes to do that I am sure that other

1053
00:46:13,140 --> 00:46:15,720
people uh will also be working on it and

1054
00:46:15,720 --> 00:46:18,480
and better toolboxes will come about

1055
00:46:18,480 --> 00:46:20,839
um but I think the the optimistic

1056
00:46:20,839 --> 00:46:24,300
message is that it will happen right uh

1057
00:46:24,300 --> 00:46:26,760
and and once we have a toolbox like that

1058
00:46:26,760 --> 00:46:28,859
then we can actually a large community

1059
00:46:28,859 --> 00:46:31,260
can start building agents and we can

1060
00:46:31,260 --> 00:46:32,579
actually show

1061
00:46:32,579 --> 00:46:33,960
uh

1062
00:46:33,960 --> 00:46:36,180
Deployable agents in the fields right

1063
00:46:36,180 --> 00:46:38,339
that they work and they work better than

1064
00:46:38,339 --> 00:46:40,260
the reinforcement floating agent or

1065
00:46:40,260 --> 00:46:42,780
whatever is out there right

1066
00:46:42,780 --> 00:46:44,940
um so that's I think that's a very

1067
00:46:44,940 --> 00:46:48,240
positive and hopeful message

1068
00:46:48,240 --> 00:46:50,160
it's what we expect it's what we prefer

1069
00:46:50,160 --> 00:46:52,980
yeah yeah yeah

1070
00:46:52,980 --> 00:46:57,560
any last comments from either of you

1071
00:46:59,280 --> 00:47:01,260
um from comments from us no no we just

1072
00:47:01,260 --> 00:47:03,839
I'm just very happy to uh well to get

1073
00:47:03,839 --> 00:47:07,020
the opportunity and uh yeah I want to uh

1074
00:47:07,020 --> 00:47:09,420
so yeah

1075
00:47:09,420 --> 00:47:13,440
um everybody can download this toolbox

1076
00:47:13,440 --> 00:47:15,960
um I think you at this moment you still

1077
00:47:15,960 --> 00:47:18,599
should be a programmer to work with the

1078
00:47:18,599 --> 00:47:19,680
toolbox

1079
00:47:19,680 --> 00:47:22,500
and I hope you're friendly because you

1080
00:47:22,500 --> 00:47:25,800
know it's not uh totally polished

1081
00:47:25,800 --> 00:47:27,960
any way that we want but it's coming

1082
00:47:27,960 --> 00:47:30,119
right it's coming in the next year there

1083
00:47:30,119 --> 00:47:31,800
will be a good toolbox for for almost

1084
00:47:31,800 --> 00:47:34,260
everybody to use but people that are

1085
00:47:34,260 --> 00:47:35,640
interested

1086
00:47:35,640 --> 00:47:37,680
even people that are interested to work

1087
00:47:37,680 --> 00:47:39,480
here at buying slab we have open

1088
00:47:39,480 --> 00:47:43,500
position uh for PhD students so uh um

1089
00:47:43,500 --> 00:47:47,099
we're happy to uh yeah to receive

1090
00:47:47,099 --> 00:47:48,900
emails from people that are interested

1091
00:47:48,900 --> 00:47:52,040
to have to work with us

1092
00:47:52,619 --> 00:47:56,599
thank you Dimitri anything in closing

1093
00:47:56,640 --> 00:47:59,400
no just that thank you yeah again for

1094
00:47:59,400 --> 00:48:01,560
possibility to present super nice to be

1095
00:48:01,560 --> 00:48:03,000
here

1096
00:48:03,000 --> 00:48:05,460
cool yeah well later in the year we will

1097
00:48:05,460 --> 00:48:08,940
be discussing your two-part recent work

1098
00:48:08,940 --> 00:48:11,400
and so we're going to be getting a lot

1099
00:48:11,400 --> 00:48:14,579
into the details and I I hope that

1100
00:48:14,579 --> 00:48:16,260
people in The Institute in the ecosystem

1101
00:48:16,260 --> 00:48:19,319
will be as excited as we all are so

1102
00:48:19,319 --> 00:48:24,319
thank you okay thank you bye-bye

