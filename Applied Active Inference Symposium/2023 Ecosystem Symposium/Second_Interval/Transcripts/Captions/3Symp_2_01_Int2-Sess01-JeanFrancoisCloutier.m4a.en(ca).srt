1
00:00:04,980 --> 00:00:08,600
Hello and welcome,

2
00:00:08,670 --> 00:00:11,530
everyone. Welcome back. This is the

3
00:00:11,900 --> 00:00:14,836
second interval of the third applied

4
00:00:14,868 --> 00:00:17,188
active inference symposium at the active

5
00:00:17,204 --> 00:00:20,296
inference institute on August 22,

6
00:00:20,478 --> 00:00:24,216
2023. This is going to be

7
00:00:24,318 --> 00:00:28,772
another packed and exciting interval,

8
00:00:28,916 --> 00:00:31,196
and we're kicking it off with Jean

9
00:00:31,228 --> 00:00:33,616
Francois Cloutier, a Collective of

10
00:00:33,638 --> 00:00:36,816
theorizers First Steps. So, JF, thank

11
00:00:36,838 --> 00:00:39,712
you for joining and to you for this

12
00:00:39,766 --> 00:00:41,744
presentation. And if anybody has

13
00:00:41,782 --> 00:00:44,196
questions for this presentation or any

14
00:00:44,218 --> 00:00:46,436
of the others, please just put it in the

15
00:00:46,458 --> 00:00:48,916
live chat and I'll do it. I can. So

16
00:00:48,938 --> 00:00:50,310
thanks. JF. To you.

17
00:00:54,900 --> 00:00:58,624
Thank you, Daniel. I'm a software

18
00:00:58,672 --> 00:01:01,968
engineer at a company called Smart Rent,

19
00:01:02,144 --> 00:01:04,404
where I write software for smart home

20
00:01:04,442 --> 00:01:07,540
systems. I also work on a research

21
00:01:07,610 --> 00:01:09,436
project at the Active Inference

22
00:01:09,488 --> 00:01:11,992
Institute called the Robotics and

23
00:01:12,046 --> 00:01:16,330
Embodied Project. My current focus

24
00:01:16,700 --> 00:01:19,556
is unsupervised learning in active

25
00:01:19,588 --> 00:01:22,984
inference agents. In my presentation

26
00:01:23,032 --> 00:01:25,244
today, which is titled A Collective of

27
00:01:25,282 --> 00:01:28,492
theorizers First Steps, I'll first start

28
00:01:28,546 --> 00:01:31,310
with a brief recap of the project,

29
00:01:32,000 --> 00:01:35,120
then dive into recent progress,

30
00:01:35,540 --> 00:01:38,272
and then I'll conclude with what I see

31
00:01:38,326 --> 00:01:40,930
as the next steps of the project.

32
00:01:43,780 --> 00:01:46,656
Well, since 2017, I've been

33
00:01:46,678 --> 00:01:49,700
experimenting with Lego robots and

34
00:01:49,850 --> 00:01:53,030
models of cognition. I do this

35
00:01:53,720 --> 00:01:56,676
for my own education, because,

36
00:01:56,858 --> 00:01:59,360
like I think most of us, I understand

37
00:01:59,450 --> 00:02:02,776
something better when I build it. What

38
00:02:02,798 --> 00:02:06,776
you see here is my latest robot model.

39
00:02:06,958 --> 00:02:09,944
It's a rover. It has a whole bunch of

40
00:02:09,982 --> 00:02:13,592
sensors and a number of effectors

41
00:02:13,656 --> 00:02:16,604
actuators. As a matter of fact, those

42
00:02:16,642 --> 00:02:18,312
sensors and actuators can be understood

43
00:02:18,376 --> 00:02:21,836
as forming the marker blanket of my

44
00:02:21,938 --> 00:02:22,860
robot.

45
00:02:26,330 --> 00:02:29,490
Last year, I presented at the symposium

46
00:02:29,650 --> 00:02:32,694
about the history of the project, its

47
00:02:32,812 --> 00:02:36,310
then status, and its ambitions.

48
00:02:36,730 --> 00:02:39,610
I presented a cognitive model that

49
00:02:39,680 --> 00:02:42,634
implemented predictive processing from

50
00:02:42,672 --> 00:02:44,954
an active inference perspective. So

51
00:02:44,992 --> 00:02:47,514
there were generative models, there was

52
00:02:47,632 --> 00:02:49,094
predictions, there was prediction

53
00:02:49,142 --> 00:02:52,910
errors. And these

54
00:02:52,980 --> 00:02:55,326
generative models animated the robots so

55
00:02:55,348 --> 00:02:58,430
that they would roam, avoid obstacles,

56
00:02:58,850 --> 00:03:02,446
observe their companion, and also, in a

57
00:03:02,468 --> 00:03:05,202
very simplistic way, build a theory of

58
00:03:05,256 --> 00:03:09,842
mind of the other robot. They could from

59
00:03:09,896 --> 00:03:13,394
observations infer that the other

60
00:03:13,432 --> 00:03:15,554
robot had detected food, food being

61
00:03:15,592 --> 00:03:18,566
presented here as a sheet of paper on

62
00:03:18,588 --> 00:03:22,134
the floor, and then would kind of try

63
00:03:22,172 --> 00:03:24,326
to track the other robot to also get to

64
00:03:24,348 --> 00:03:27,734
the food and fun stuff like this.

65
00:03:27,932 --> 00:03:31,870
The implementation combined multi

66
00:03:31,890 --> 00:03:34,006
processing and functional computing.

67
00:03:34,038 --> 00:03:37,194
There was nothing probabilistic in the

68
00:03:37,232 --> 00:03:38,250
implementation.

69
00:03:40,830 --> 00:03:43,114
I thought maybe we'd see them in action.

70
00:03:43,162 --> 00:03:44,814
That's what's presented last year. But

71
00:03:44,852 --> 00:03:47,840
just to get a sense of what they do,

72
00:03:48,450 --> 00:03:51,754
I have two robots here, one named Karl

73
00:03:51,802 --> 00:03:54,018
and Andy. I named them before I knew I

74
00:03:54,024 --> 00:03:56,290
was going to present at the conference.

75
00:03:57,350 --> 00:04:01,362
So they benefited from a number

76
00:04:01,416 --> 00:04:04,862
of training sessions. They learned

77
00:04:04,926 --> 00:04:09,746
how to find which policies

78
00:04:09,858 --> 00:04:12,374
would achieve their goals better than

79
00:04:12,412 --> 00:04:16,150
others. And one here on the left.

80
00:04:16,300 --> 00:04:19,818
Found the food rather right away but

81
00:04:19,904 --> 00:04:23,354
got closer to the pedestal where the

82
00:04:23,392 --> 00:04:25,594
beacon is that simulates the scent of

83
00:04:25,632 --> 00:04:29,226
food feared was getting into

84
00:04:29,248 --> 00:04:32,558
a collision and then backs off in a

85
00:04:32,564 --> 00:04:35,774
hurry as we'll see the other

86
00:04:35,812 --> 00:04:40,046
robot observes all this, sees the

87
00:04:40,068 --> 00:04:42,186
robot backing off as being in a panic

88
00:04:42,298 --> 00:04:46,274
and decides to share this

89
00:04:46,312 --> 00:04:48,850
emotion and backs up as well.

90
00:04:49,000 --> 00:04:51,540
So fun stuff.

91
00:04:58,180 --> 00:05:00,696
From the beginning I've implemented

92
00:05:00,748 --> 00:05:02,276
different cognition models but they all

93
00:05:02,298 --> 00:05:03,924
have in common the fact that they

94
00:05:03,962 --> 00:05:06,390
implement a society of mind.

95
00:05:07,160 --> 00:05:09,376
So what is a society of mind? A society

96
00:05:09,408 --> 00:05:14,504
of mind is a concept by which the

97
00:05:14,542 --> 00:05:19,060
mind is not a monolithic structure

98
00:05:19,220 --> 00:05:23,160
but a composition of simple actors,

99
00:05:23,520 --> 00:05:25,804
independent actors that interact with

100
00:05:25,842 --> 00:05:29,852
each other in simple ways. That view

101
00:05:29,906 --> 00:05:32,536
of the mind was put forth by Marvin

102
00:05:32,568 --> 00:05:35,544
Minsky 50 years ago. So this is not

103
00:05:35,602 --> 00:05:36,320
recent.

104
00:05:40,290 --> 00:05:43,742
Again, what I presented last year was a

105
00:05:43,796 --> 00:05:46,602
society of mind containing a hierarchy

106
00:05:46,666 --> 00:05:49,854
of, I call them cognition actors. Each

107
00:05:49,892 --> 00:05:51,454
cognition actor is an independent

108
00:05:51,502 --> 00:05:54,770
process, each one has a scope,

109
00:05:57,510 --> 00:06:00,146
a level of abstraction as well. So for

110
00:06:00,168 --> 00:06:01,614
example, you would have a cognition

111
00:06:01,662 --> 00:06:03,794
actor that's concerned with the location

112
00:06:03,842 --> 00:06:07,142
of food and it would have

113
00:06:07,196 --> 00:06:09,302
beliefs and perceptions about food

114
00:06:09,356 --> 00:06:12,246
location and these would feed into a

115
00:06:12,268 --> 00:06:14,662
higher level cognition actor, let's say

116
00:06:14,796 --> 00:06:17,770
food approach which is concerned about

117
00:06:17,840 --> 00:06:20,726
getting closer to the food and so forth

118
00:06:20,758 --> 00:06:22,966
and so on. These cognition actors

119
00:06:23,158 --> 00:06:25,866
communicate again in simple ways. This

120
00:06:25,888 --> 00:06:27,838
is the society of mind and they

121
00:06:27,844 --> 00:06:30,426
communicate by emitting predictions,

122
00:06:30,538 --> 00:06:33,022
predictions about the beliefs of other

123
00:06:33,076 --> 00:06:36,302
cognition actors and they communicate by

124
00:06:36,436 --> 00:06:38,542
emitting prediction errors. When

125
00:06:38,596 --> 00:06:40,994
predictions made about their beliefs by

126
00:06:41,032 --> 00:06:45,122
others are inaccurate that

127
00:06:45,256 --> 00:06:49,182
leads to connection actors processing

128
00:06:49,246 --> 00:06:53,138
these prediction errors and combining

129
00:06:53,154 --> 00:06:55,000
them with their own predictions to

130
00:06:55,450 --> 00:06:59,410
create an updated set of perceptions

131
00:06:59,570 --> 00:07:02,502
that are synthesized into beliefs. And

132
00:07:02,556 --> 00:07:05,862
these beliefs lead to actions

133
00:07:05,926 --> 00:07:09,398
in order to eliminate negative beliefs

134
00:07:09,574 --> 00:07:13,766
or validate positive beliefs. Now it's

135
00:07:13,798 --> 00:07:15,926
from the interactions of all these kung

136
00:07:15,958 --> 00:07:19,354
fu actors that seemingly purposeful

137
00:07:19,482 --> 00:07:23,658
behaviors emerge. So that was successful

138
00:07:23,754 --> 00:07:26,190
but learning was very limited.

139
00:07:27,170 --> 00:07:31,170
This hierarchy of cognition actors

140
00:07:31,510 --> 00:07:34,722
was given, was predefined and

141
00:07:34,776 --> 00:07:38,242
the only learning that a robot would

142
00:07:38,296 --> 00:07:42,270
do was to discover which action policies

143
00:07:42,430 --> 00:07:45,430
tended to be more effective.

144
00:07:49,950 --> 00:07:53,130
So clearly my robots are not monolithic

145
00:07:54,350 --> 00:07:55,900
active inference agents.

146
00:07:57,630 --> 00:08:01,742
So the question is why would I use

147
00:08:01,796 --> 00:08:04,734
a society of mind architecture? Well,

148
00:08:04,852 --> 00:08:08,480
because I subscribe to the

149
00:08:09,490 --> 00:08:12,530
notion that all intelligence is

150
00:08:12,680 --> 00:08:16,034
collective intelligence. This paper

151
00:08:16,152 --> 00:08:20,354
makes the argument quite cogently and

152
00:08:20,552 --> 00:08:22,446
I'm going to cite a number of papers

153
00:08:22,478 --> 00:08:26,198
which were important to the evolution of

154
00:08:26,204 --> 00:08:28,280
my thinking. This is one of them.

155
00:08:30,810 --> 00:08:33,302
This paper sees intelligence as a

156
00:08:33,356 --> 00:08:36,778
process, not a property. It's a process

157
00:08:36,864 --> 00:08:40,250
enacted by the interacting parts

158
00:08:40,590 --> 00:08:42,746
as opposed to again, a property of

159
00:08:42,768 --> 00:08:46,746
individuals. So society of mind is

160
00:08:46,848 --> 00:08:51,006
basically that it's actually a

161
00:08:51,028 --> 00:08:55,118
number of interacting processes that

162
00:08:55,204 --> 00:08:58,954
together from which emerge apparently

163
00:08:59,002 --> 00:09:02,082
intelligent behaviors. Now my own

164
00:09:02,136 --> 00:09:04,146
personal current definition of

165
00:09:04,168 --> 00:09:07,518
intelligence is self sustaining,

166
00:09:07,694 --> 00:09:10,386
inactive sense making. Sense making is

167
00:09:10,408 --> 00:09:13,300
really important by autonomous agent

168
00:09:13,850 --> 00:09:17,650
system in a dissipative and dynamic

169
00:09:17,730 --> 00:09:22,134
environment and this guides all

170
00:09:22,172 --> 00:09:24,920
the work I do in this project.

171
00:09:27,230 --> 00:09:30,378
Now, if you want a description, a

172
00:09:30,384 --> 00:09:34,250
detailed description of where my

173
00:09:34,320 --> 00:09:38,414
project stood a year ago, there's a

174
00:09:38,452 --> 00:09:40,286
paper that was published that I

175
00:09:40,308 --> 00:09:43,454
published on Xenodo, which you can look

176
00:09:43,492 --> 00:09:44,080
up.

177
00:09:47,380 --> 00:09:50,496
Now, over the last year, I wanted to

178
00:09:50,518 --> 00:09:54,020
move away from a pre built a given

179
00:09:54,090 --> 00:09:58,224
society of mind and toward a learned

180
00:09:58,272 --> 00:10:02,052
society of mind. I wanted to see if I

181
00:10:02,106 --> 00:10:05,192
could program an autonomous robot to

182
00:10:05,246 --> 00:10:08,104
evolve its society of mind through its

183
00:10:08,142 --> 00:10:10,680
interactions with its environment.

184
00:10:11,580 --> 00:10:13,716
Now, one might think that programming

185
00:10:13,828 --> 00:10:20,796
autonomy is an oxymoron would

186
00:10:20,818 --> 00:10:22,396
be a good point, but I don't think it

187
00:10:22,418 --> 00:10:26,828
is. If if the program

188
00:10:26,914 --> 00:10:30,936
I write and install my robot imparts

189
00:10:31,128 --> 00:10:34,444
constitutive autonomy, which is enable

190
00:10:34,492 --> 00:10:36,512
the robot to constitute its own

191
00:10:36,566 --> 00:10:39,932
identity, and if it imparts adaptivity,

192
00:10:39,996 --> 00:10:43,840
which enable the robot to modify

193
00:10:43,920 --> 00:10:45,988
itself from its interactions with the

194
00:10:45,994 --> 00:10:50,804
environment, then I think that the

195
00:10:50,842 --> 00:10:54,820
robot will be truly autonomous.

196
00:10:55,820 --> 00:10:59,784
Now, for autonomy to

197
00:10:59,822 --> 00:11:01,332
exist inherently in the robot,

198
00:11:01,396 --> 00:11:04,820
something in the robot must be at stake.

199
00:11:04,980 --> 00:11:08,744
And in this case, it's the survival

200
00:11:08,872 --> 00:11:11,710
of the robot society of mind. Now,

201
00:11:12,960 --> 00:11:15,372
the physical structure of the robot is

202
00:11:15,426 --> 00:11:18,876
not at stake. Its survival is

203
00:11:18,898 --> 00:11:20,624
not at stake, unless, of course, it

204
00:11:20,662 --> 00:11:24,290
falls off a shelf. But as I intend to

205
00:11:24,740 --> 00:11:27,504
have my robot develop its society of

206
00:11:27,542 --> 00:11:31,168
mind from experiences, I also expect

207
00:11:31,254 --> 00:11:33,616
that if it fails, that this society of

208
00:11:33,638 --> 00:11:37,684
mine will perish in its attempt to grow

209
00:11:37,882 --> 00:11:41,076
and sustain itself. So that's what's at

210
00:11:41,098 --> 00:11:44,452
stake going

211
00:11:44,506 --> 00:11:48,296
forward in this project is the

212
00:11:48,318 --> 00:11:50,410
survival of the robot society of mind.

213
00:11:51,260 --> 00:11:54,664
This survival would be an expression of

214
00:11:54,702 --> 00:11:58,516
being. By doing, the robot will

215
00:11:58,558 --> 00:12:00,204
need to act and interact in its

216
00:12:00,242 --> 00:12:03,020
environment in order to survive.

217
00:12:03,360 --> 00:12:05,884
Now, whatever sense it's going to make

218
00:12:05,922 --> 00:12:08,120
of its environment will then be grounded

219
00:12:08,200 --> 00:12:11,992
in this survival imperative. In essence,

220
00:12:12,136 --> 00:12:15,016
the robot society of mine will have skin

221
00:12:15,048 --> 00:12:18,092
in the game. If this weren't the case,

222
00:12:18,146 --> 00:12:20,504
then sense making would actually reside

223
00:12:20,552 --> 00:12:22,708
somewhere else. It would reside in in

224
00:12:22,714 --> 00:12:25,044
the mind of the programmer, in my mind

225
00:12:25,082 --> 00:12:27,316
as I observe the robots. But I would

226
00:12:27,338 --> 00:12:30,580
like the sense making to be grounded in

227
00:12:30,650 --> 00:12:33,670
the survival of the robot's mind itself.

228
00:12:34,780 --> 00:12:38,250
So that's key. Now,

229
00:12:38,780 --> 00:12:41,416
what do I mean by an evolving and

230
00:12:41,438 --> 00:12:44,136
growing society of mind? So instead of

231
00:12:44,158 --> 00:12:46,984
the given society of mind, which I

232
00:12:47,022 --> 00:12:48,540
showed earlier,

233
00:12:50,480 --> 00:12:54,348
I want the cognition actors to be

234
00:12:54,434 --> 00:12:58,188
created to connect with each other

235
00:12:58,354 --> 00:13:00,864
dynamically through interactions with

236
00:13:00,902 --> 00:13:04,464
the environment. So I want an

237
00:13:04,502 --> 00:13:08,684
active, self organizing, self optimizing

238
00:13:08,812 --> 00:13:11,136
collective of cognition actors. Now, is

239
00:13:11,158 --> 00:13:12,884
this feasible? Well, that's a big

240
00:13:12,922 --> 00:13:16,596
question. In trying to

241
00:13:16,618 --> 00:13:19,940
answer this question, I'll be also

242
00:13:20,010 --> 00:13:22,564
answering questions like what must be

243
00:13:22,602 --> 00:13:25,224
given a priori and what can be

244
00:13:25,262 --> 00:13:27,544
discovered? Well, I already have

245
00:13:27,582 --> 00:13:31,032
elements of an answer. I know that the

246
00:13:31,086 --> 00:13:34,324
sensors and the effectors

247
00:13:34,452 --> 00:13:38,184
and the primitive

248
00:13:38,232 --> 00:13:40,556
cognition actors that wrap them will be

249
00:13:40,578 --> 00:13:42,408
given. This will be like what you're

250
00:13:42,424 --> 00:13:45,516
born with, basically. And there might be

251
00:13:45,698 --> 00:13:49,736
a metacognition actor which role

252
00:13:49,768 --> 00:13:52,384
will be to oversee and guide the

253
00:13:52,422 --> 00:13:55,836
evolution of all other cognition actors.

254
00:13:55,868 --> 00:13:58,160
But that's my hypothesis.

255
00:14:00,580 --> 00:14:03,604
I can imagine a test environment for my

256
00:14:03,642 --> 00:14:06,724
robot that will test its ability to

257
00:14:06,762 --> 00:14:08,740
survive. I can imagine, for example,

258
00:14:08,810 --> 00:14:12,128
that as the robot

259
00:14:12,304 --> 00:14:14,820
moves around or computes,

260
00:14:15,400 --> 00:14:18,928
it uses a limited store of energy it's

261
00:14:18,944 --> 00:14:22,372
stimulated. And that store of energy is

262
00:14:22,426 --> 00:14:25,584
replenished when the robot consumes

263
00:14:25,632 --> 00:14:28,092
food. And that would be by being on top

264
00:14:28,146 --> 00:14:31,596
of pieces of paper, colored pieces of

265
00:14:31,618 --> 00:14:34,716
paper on the floor. And I'm going to

266
00:14:34,738 --> 00:14:36,476
make sure that it needs two sources of

267
00:14:36,498 --> 00:14:38,476
food in order to survive. That would be

268
00:14:38,498 --> 00:14:40,316
represented by a yellow paper and a

269
00:14:40,338 --> 00:14:42,336
green paper, for example. So that to

270
00:14:42,358 --> 00:14:44,764
prevent the robot from just simply

271
00:14:44,812 --> 00:14:47,024
finding one source of food and just

272
00:14:47,142 --> 00:14:50,704
stationing itself over it. So the

273
00:14:50,742 --> 00:14:52,728
environment will also contain obstacles.

274
00:14:52,844 --> 00:14:55,012
So the robot will need to learn how to

275
00:14:55,066 --> 00:14:58,400
navigate, avoid obstacles, locate

276
00:14:58,480 --> 00:15:01,364
different sources of food, get to them,

277
00:15:01,482 --> 00:15:05,040
and make sure that it alternate between

278
00:15:05,130 --> 00:15:07,816
various sources of food in order to

279
00:15:07,838 --> 00:15:11,096
survive. And the society of mind that

280
00:15:11,118 --> 00:15:15,524
will evolve, will hopefully evolve

281
00:15:15,572 --> 00:15:18,796
to successfully do this. Else if it

282
00:15:18,818 --> 00:15:21,484
doesn't, then it will shrink as

283
00:15:21,522 --> 00:15:25,740
resources disappear and essentially

284
00:15:26,080 --> 00:15:29,870
die. So that's what it's at stake for

285
00:15:30,340 --> 00:15:31,520
this robot.

286
00:15:33,620 --> 00:15:36,336
Now, this effort employs a number of

287
00:15:36,358 --> 00:15:40,124
frameworks, and by framework,

288
00:15:40,172 --> 00:15:42,900
I mean a useful system of concept and

289
00:15:42,970 --> 00:15:45,956
constraints that guide the

290
00:15:45,978 --> 00:15:48,884
implementation. Well, there's obviously

291
00:15:49,082 --> 00:15:51,216
the free energy principle and the Active

292
00:15:51,248 --> 00:15:53,220
inference framework.

293
00:15:55,800 --> 00:15:59,004
However, I see this, the Acactive

294
00:15:59,072 --> 00:16:02,740
Inference, as an as if framework.

295
00:16:02,900 --> 00:16:06,712
It describes the what what must be

296
00:16:06,766 --> 00:16:10,924
achieved in this case, reduction of

297
00:16:11,042 --> 00:16:13,740
the agents, variational, free energy.

298
00:16:13,890 --> 00:16:16,364
But it doesn't guide me as to the

299
00:16:16,402 --> 00:16:19,368
implementation, how to build the robot.

300
00:16:19,464 --> 00:16:23,196
For this, I need as is frameworks.

301
00:16:23,388 --> 00:16:26,992
And I'll be using two

302
00:16:27,046 --> 00:16:29,072
frameworks, one which I've been using

303
00:16:29,126 --> 00:16:30,640
since the beginning of the project,

304
00:16:30,710 --> 00:16:33,510
which is the Actor model.

305
00:16:34,200 --> 00:16:38,070
The Actor model views computation as

306
00:16:39,720 --> 00:16:43,236
a diversity of processes, processes that

307
00:16:43,258 --> 00:16:45,108
are independent, have their own private

308
00:16:45,124 --> 00:16:48,104
internal state, and who communicate with

309
00:16:48,142 --> 00:16:50,680
one another strictly through messages.

310
00:16:51,900 --> 00:16:54,564
Yesterday in Enterprise One, Keith

311
00:16:54,612 --> 00:16:58,190
Duggar presented on the Actor model and

312
00:16:58,960 --> 00:17:00,956
made the case that we should use the

313
00:17:00,978 --> 00:17:02,536
actor model to implement active

314
00:17:02,568 --> 00:17:05,256
inference agents. Well, I wholeheartedly

315
00:17:05,288 --> 00:17:09,144
agree with them. The other framework

316
00:17:09,192 --> 00:17:12,160
that I'm going to be using is a special

317
00:17:12,230 --> 00:17:14,816
case of symbolic AI called the App

318
00:17:14,838 --> 00:17:16,864
Perception Engine. And much of the

319
00:17:16,902 --> 00:17:19,808
presentation will be about the App

320
00:17:19,814 --> 00:17:21,440
Perception Engine and its

321
00:17:21,510 --> 00:17:22,560
implementation.

322
00:17:24,840 --> 00:17:28,484
So here's where we are is the project is

323
00:17:28,522 --> 00:17:31,776
located at the intersection of Active

324
00:17:31,808 --> 00:17:35,336
Inference as a domain, the Wet and

325
00:17:35,438 --> 00:17:38,244
Society of Mind as an architecture,

326
00:17:38,372 --> 00:17:41,880
and symbolic AI as a form of computing.

327
00:17:42,460 --> 00:17:45,304
So that's where the project is, at this

328
00:17:45,342 --> 00:17:46,280
intersection.

329
00:17:49,040 --> 00:17:53,704
So where to begin? So I want to dive

330
00:17:53,752 --> 00:17:57,244
into a more extensive form

331
00:17:57,282 --> 00:18:00,008
of learning. And the first step,

332
00:18:00,194 --> 00:18:03,660
logically, is to learn how to predict.

333
00:18:03,820 --> 00:18:08,060
So I want to enable

334
00:18:08,220 --> 00:18:11,756
a single cognition actor.

335
00:18:11,868 --> 00:18:13,344
We'll start with a single cognition

336
00:18:13,392 --> 00:18:16,756
actor to learn how to make sense of its

337
00:18:16,778 --> 00:18:19,792
local environment, its so called unvelt.

338
00:18:19,936 --> 00:18:22,820
And making sense implies,

339
00:18:24,280 --> 00:18:28,020
at a minimum, to be able to predict

340
00:18:28,180 --> 00:18:30,616
incoming sensations. So it needs to

341
00:18:30,638 --> 00:18:32,040
learn to predict.

342
00:18:36,650 --> 00:18:40,614
So what will be given to a cognition

343
00:18:40,662 --> 00:18:44,700
actor? Well, there will be a history of

344
00:18:45,470 --> 00:18:49,638
sensations broken into discrete

345
00:18:49,814 --> 00:18:53,594
units of time. So time n minus

346
00:18:53,642 --> 00:18:56,222
three and N minus two, n minus one time

347
00:18:56,276 --> 00:18:58,320
n, which is the present moment.

348
00:19:00,450 --> 00:19:02,154
So these would be remembered

349
00:19:02,202 --> 00:19:05,346
observations. And then what we want to

350
00:19:05,368 --> 00:19:08,180
get out of this is the ability to

351
00:19:08,550 --> 00:19:11,714
predict the next incoming set

352
00:19:11,752 --> 00:19:15,634
of sensations at time t equals n plus

353
00:19:15,672 --> 00:19:18,680
one, n plus two. And for this,

354
00:19:19,530 --> 00:19:21,430
to be able to predict future

355
00:19:21,500 --> 00:19:23,942
observations, we need some kind of

356
00:19:23,996 --> 00:19:27,254
predictor function that is learned from

357
00:19:27,292 --> 00:19:30,810
the remembered observation. Now,

358
00:19:30,880 --> 00:19:33,162
this predictive capability can be built

359
00:19:33,216 --> 00:19:36,442
in two very general ways. One is from

360
00:19:36,496 --> 00:19:40,166
statistics, so doing pattern analysis

361
00:19:40,278 --> 00:19:43,262
and being able to predict what's most

362
00:19:43,316 --> 00:19:46,478
probable, which is the standard current

363
00:19:46,564 --> 00:19:50,014
machine learning approach. Or we could

364
00:19:50,052 --> 00:19:53,854
predict from an understanding of the

365
00:19:53,892 --> 00:19:56,846
observations by developing a causal

366
00:19:56,878 --> 00:20:00,754
model of

367
00:20:00,792 --> 00:20:03,970
what produced these sensations,

368
00:20:04,470 --> 00:20:06,850
and from this understanding,

369
00:20:07,450 --> 00:20:10,710
predict what rationally should be

370
00:20:10,780 --> 00:20:12,120
observed next.

371
00:20:16,070 --> 00:20:19,620
So this is all about sense making.

372
00:20:19,990 --> 00:20:23,686
And now what is sense making? How do I

373
00:20:23,708 --> 00:20:27,622
understand sense making? Well,

374
00:20:27,676 --> 00:20:29,586
to rationally predict incoming sensory

375
00:20:29,618 --> 00:20:32,694
inputs, one must make sense of them.

376
00:20:32,732 --> 00:20:34,760
That's what making sense means to me.

377
00:20:35,150 --> 00:20:37,974
And to make sense of sensory inputs

378
00:20:38,102 --> 00:20:41,558
means to derive meaningful experiences

379
00:20:41,654 --> 00:20:44,346
from them. It's not just data, it's not

380
00:20:44,368 --> 00:20:47,158
just pieces of data. There must be

381
00:20:47,184 --> 00:20:50,094
meaningful experiences. And by

382
00:20:50,132 --> 00:20:53,546
experience, I mean a conceptualization

383
00:20:53,658 --> 00:20:57,006
of the sensations and a unification of

384
00:20:57,028 --> 00:21:00,578
them in time and space. So making sense

385
00:21:00,744 --> 00:21:04,654
of these inputs will mean to produce

386
00:21:04,702 --> 00:21:06,674
meaningful experiences that are

387
00:21:06,712 --> 00:21:09,074
conceptualizations and unifications of

388
00:21:09,112 --> 00:21:11,634
the sensations. Now, an experience is

389
00:21:11,672 --> 00:21:14,806
meaningful if it is

390
00:21:14,828 --> 00:21:18,006
underwritten by a causal model. So the

391
00:21:18,028 --> 00:21:21,862
experience is

392
00:21:21,916 --> 00:21:24,790
perceived as the consequences of a

393
00:21:24,940 --> 00:21:28,070
latent generative model, generative

394
00:21:28,150 --> 00:21:30,330
process that we have modeled.

395
00:21:31,070 --> 00:21:33,626
And I want meaning to be inherent to the

396
00:21:33,648 --> 00:21:35,706
agent. And that only happens if the

397
00:21:35,728 --> 00:21:39,134
agent is truly autonomous and if this

398
00:21:39,172 --> 00:21:41,034
meaning is grounded in the survival

399
00:21:41,082 --> 00:21:43,630
imperative, as discussed earlier.

400
00:21:46,210 --> 00:21:49,422
So how does experiencing work? How can

401
00:21:49,476 --> 00:21:51,540
that be put into computer code?

402
00:21:52,150 --> 00:21:54,370
Surprisingly for this, we refer to the

403
00:21:54,440 --> 00:21:58,126
philosophy of Emmanuel Kant. Emmanuel

404
00:21:58,158 --> 00:22:00,126
Kant took a reverse engineering

405
00:22:00,158 --> 00:22:03,862
approach, asking himself what must

406
00:22:03,916 --> 00:22:06,360
entities do to achieve experience?

407
00:22:07,930 --> 00:22:10,502
This is akin to the free energy

408
00:22:10,556 --> 00:22:12,886
principles high Road, which can be

409
00:22:12,908 --> 00:22:15,946
paraphrased as what must organisms do to

410
00:22:15,968 --> 00:22:18,214
maintain their existence? So Emmanuel

411
00:22:18,262 --> 00:22:22,010
Kong tried to reverse engineer

412
00:22:23,630 --> 00:22:24,650
cognition,

413
00:22:27,730 --> 00:22:30,510
asking himself what's the minimal

414
00:22:30,850 --> 00:22:33,370
cognitive apparatus needed by an entity

415
00:22:33,450 --> 00:22:37,120
to have experiences? And that

416
00:22:37,730 --> 00:22:41,006
he documented in his critique of pure

417
00:22:41,038 --> 00:22:44,130
reason. Just a little parenthesis.

418
00:22:45,270 --> 00:22:47,298
The meaning of the title Critique of

419
00:22:47,304 --> 00:22:49,986
Pure Reason is not what I thought it

420
00:22:50,008 --> 00:22:53,234
was. It actually translates more closely

421
00:22:53,282 --> 00:22:56,310
to the case for April. Cognition

422
00:22:57,130 --> 00:22:59,478
critique is a legal term is where you

423
00:22:59,484 --> 00:23:02,134
make your case and pure reason we

424
00:23:02,172 --> 00:23:04,710
translate nowadays. April cognition.

425
00:23:05,070 --> 00:23:08,650
So his work

426
00:23:08,720 --> 00:23:10,906
wanted to establish what must happen to

427
00:23:10,928 --> 00:23:13,238
create an experience that's coherent,

428
00:23:13,414 --> 00:23:15,500
that is unified in time and space,

429
00:23:17,090 --> 00:23:20,718
and to reverse engineer cognition as a

430
00:23:20,804 --> 00:23:23,774
system that is both complete and

431
00:23:23,892 --> 00:23:26,030
essential, that is minimal.

432
00:23:31,100 --> 00:23:34,988
Okay, so I'm going to try to

433
00:23:34,994 --> 00:23:39,240
give you the postage stamp version

434
00:23:39,320 --> 00:23:43,368
of Emmanuel Kant's theory

435
00:23:43,544 --> 00:23:45,984
focusing on the Synthetic Unity of

436
00:23:46,022 --> 00:23:48,448
Apperception. Well, first of all,

437
00:23:48,534 --> 00:23:50,608
there's the real world, which is outside

438
00:23:50,694 --> 00:23:53,296
of our direct experience. It's the

439
00:23:53,318 --> 00:23:56,850
pneumonia. It's forever hidden from us

440
00:23:58,120 --> 00:24:01,700
as an as is reality,

441
00:24:02,040 --> 00:24:06,016
but it impinges on our sensorium.

442
00:24:06,048 --> 00:24:08,116
And then so we have a number of

443
00:24:08,138 --> 00:24:11,640
intuitions, sight, sound, touch, smell

444
00:24:12,380 --> 00:24:15,720
that are initially separate,

445
00:24:16,220 --> 00:24:19,572
and then we need to network

446
00:24:19,636 --> 00:24:21,976
them, connect them both in time and in

447
00:24:21,998 --> 00:24:27,996
space. In space is

448
00:24:28,098 --> 00:24:32,184
sound. And the sight describing

449
00:24:32,232 --> 00:24:36,320
a single thing is

450
00:24:36,390 --> 00:24:39,970
one thing behind or inside another.

451
00:24:41,300 --> 00:24:43,760
And in time, is this happening before,

452
00:24:43,910 --> 00:24:46,370
after something else?

453
00:24:47,220 --> 00:24:50,564
And then at a higher level, meaning is

454
00:24:50,602 --> 00:24:53,680
given to these networked, intuitions,

455
00:24:53,760 --> 00:24:57,652
sensations via concepts and

456
00:24:57,706 --> 00:25:00,068
judgments, rules which are

457
00:25:00,154 --> 00:25:03,192
generalizations as to what can and

458
00:25:03,246 --> 00:25:04,330
cannot be.

459
00:25:05,980 --> 00:25:08,090
And this is what we experience.

460
00:25:12,720 --> 00:25:15,996
Now, it turns out that synthetic

461
00:25:16,028 --> 00:25:19,728
Unity of Apperception is a

462
00:25:19,734 --> 00:25:22,690
blueprint for automating sense making.

463
00:25:25,540 --> 00:25:27,820
It's kind of interesting, I think, that

464
00:25:27,910 --> 00:25:29,972
18th century philosophy would be

465
00:25:30,106 --> 00:25:33,956
relevant to 21st century technology

466
00:25:34,058 --> 00:25:37,990
development. And this is what happened

467
00:25:38,840 --> 00:25:42,008
and was published by Richard Evans and

468
00:25:42,094 --> 00:25:44,724
all in the paper Making Sense of Sensory

469
00:25:44,772 --> 00:25:48,216
Input, where they developed the App

470
00:25:48,238 --> 00:25:51,956
Perception Engine. They took synthetic

471
00:25:51,988 --> 00:25:53,624
Unity of Apperception as software

472
00:25:53,672 --> 00:25:56,440
requirements and successfully

473
00:25:56,520 --> 00:25:59,996
implemented them into a piece of

474
00:26:00,018 --> 00:26:01,692
software, the App Perception Engine,

475
00:26:01,826 --> 00:26:05,980
and applied it to a number of exercises

476
00:26:08,100 --> 00:26:11,184
where they got a very good result. So

477
00:26:11,222 --> 00:26:14,524
the App Session Engine is in an instance

478
00:26:14,572 --> 00:26:16,620
of machine learning. It's unsupervised

479
00:26:16,700 --> 00:26:19,188
machine learning, and it operates on

480
00:26:19,274 --> 00:26:22,580
very small data sets and

481
00:26:22,650 --> 00:26:25,952
generates human readable generative

482
00:26:26,016 --> 00:26:28,756
models. When I read the paper, I

483
00:26:28,778 --> 00:26:31,176
realized, well, that's exactly what my

484
00:26:31,198 --> 00:26:32,810
robot needed.

485
00:26:34,700 --> 00:26:37,096
So what does an app perception engine

486
00:26:37,198 --> 00:26:41,764
do? Well, given a sequence of observed

487
00:26:41,892 --> 00:26:45,768
states, it finds

488
00:26:45,864 --> 00:26:49,896
a generative model that can recreate

489
00:26:50,008 --> 00:26:52,664
past states but most importantly,

490
00:26:52,792 --> 00:26:56,960
predict future states. And the state is

491
00:26:57,030 --> 00:27:00,480
defined as a set of simultaneous

492
00:27:01,060 --> 00:27:04,160
observations, sensations, intuitions.

493
00:27:07,740 --> 00:27:12,440
So an apperception engine searches

494
00:27:12,600 --> 00:27:15,464
for a causal theory that can recreate

495
00:27:15,512 --> 00:27:17,932
observations. I say searches because

496
00:27:18,066 --> 00:27:21,356
this causal theory is not determined by

497
00:27:21,378 --> 00:27:24,512
the observations. It has to be found.

498
00:27:24,566 --> 00:27:29,010
It has to be discovered. But once

499
00:27:30,500 --> 00:27:34,520
it is found, then it can be validated

500
00:27:34,700 --> 00:27:37,348
against the observations and see if it

501
00:27:37,354 --> 00:27:41,444
can recreate them and augment them into

502
00:27:41,482 --> 00:27:44,390
the future as well as into the past.

503
00:27:47,100 --> 00:27:49,880
So what is a causal theory?

504
00:27:50,780 --> 00:27:54,952
A causal theory is a logic program that

505
00:27:55,006 --> 00:27:56,920
has a number of components.

506
00:27:59,180 --> 00:28:02,332
In the causal theory, there will be the

507
00:28:02,386 --> 00:28:04,732
objects and the predicates from the

508
00:28:04,786 --> 00:28:07,516
observed relations. So from the

509
00:28:07,538 --> 00:28:09,932
observations, we can extract what

510
00:28:09,986 --> 00:28:11,852
objects were observed and what

511
00:28:11,906 --> 00:28:13,584
properties of these objects were

512
00:28:13,622 --> 00:28:15,420
observed and maybe what relationships

513
00:28:15,580 --> 00:28:18,176
these objects were observed. That's the

514
00:28:18,198 --> 00:28:21,612
start. Then we have latent object types,

515
00:28:21,676 --> 00:28:24,496
objects and predicates. So we may want

516
00:28:24,518 --> 00:28:26,976
to imagine causal theory, imagines

517
00:28:27,168 --> 00:28:30,116
hidden objects, maybe hidden types of

518
00:28:30,138 --> 00:28:33,044
objects and maybe hidden properties and

519
00:28:33,082 --> 00:28:35,620
relationships between objects,

520
00:28:36,200 --> 00:28:38,728
latent meaning unobserved. And given

521
00:28:38,814 --> 00:28:44,520
both the observed and unobserved objects

522
00:28:45,020 --> 00:28:49,488
and predicates, it derives

523
00:28:49,604 --> 00:28:52,236
rules, first of all constraints on those

524
00:28:52,258 --> 00:28:54,476
predicates, what's permissible. So for

525
00:28:54,498 --> 00:28:58,860
example, being in front of A

526
00:28:58,930 --> 00:29:02,524
cannot be in front of B and at the same

527
00:29:02,562 --> 00:29:04,928
time behind B. So an object cannot be in

528
00:29:04,934 --> 00:29:08,016
front of another and behind it. So there

529
00:29:08,038 --> 00:29:10,704
are constraints on predicates and then

530
00:29:10,742 --> 00:29:13,824
there are rules that apply to any

531
00:29:13,862 --> 00:29:17,396
simultaneous sets of observations, what

532
00:29:17,578 --> 00:29:20,004
they must conform to. Then there are

533
00:29:20,042 --> 00:29:22,996
rules that given a state, will infer the

534
00:29:23,018 --> 00:29:25,584
next state and then maybe some initial

535
00:29:25,632 --> 00:29:29,512
state from which we can run

536
00:29:29,646 --> 00:29:31,240
the causal theory.

537
00:29:33,020 --> 00:29:36,520
So what makes a causal theory unified?

538
00:29:37,180 --> 00:29:38,488
Well, first of all it needs to be

539
00:29:38,494 --> 00:29:40,136
unified in order to make sense of the

540
00:29:40,158 --> 00:29:42,984
observation. There are various

541
00:29:43,032 --> 00:29:45,304
dimensions. So if a causal theory

542
00:29:45,352 --> 00:29:47,276
involves a number of objects, all these

543
00:29:47,298 --> 00:29:49,304
objects must be directly or indirectly

544
00:29:49,352 --> 00:29:51,452
related. There's no object that just

545
00:29:51,506 --> 00:29:53,536
floats in space totally independent of

546
00:29:53,558 --> 00:29:55,344
the other objects, so they must all be

547
00:29:55,382 --> 00:29:59,360
related. So they're spatially unified.

548
00:29:59,780 --> 00:30:02,796
All predicates that make up the causal

549
00:30:02,828 --> 00:30:05,588
theory, like on,

550
00:30:05,674 --> 00:30:08,740
off, behind, in front, they must be

551
00:30:08,890 --> 00:30:12,564
constrained so that, for example, in

552
00:30:12,602 --> 00:30:15,332
front cannot be at the same time as

553
00:30:15,386 --> 00:30:18,744
behind or that a light cannot be both

554
00:30:18,862 --> 00:30:21,876
turned on and turned off. So there's

555
00:30:21,908 --> 00:30:25,716
some restrictions on the predicates

556
00:30:25,828 --> 00:30:29,144
and that creates conceptual unity. And

557
00:30:29,182 --> 00:30:31,244
then there's static unity where all

558
00:30:31,282 --> 00:30:33,164
simultaneous relations must satisfy the

559
00:30:33,202 --> 00:30:35,484
static rules, and temporal unity, where

560
00:30:35,522 --> 00:30:38,348
all the states must be sequenced by

561
00:30:38,514 --> 00:30:41,820
causal rules. We'll see examples.

562
00:30:43,700 --> 00:30:47,104
So let's start

563
00:30:47,142 --> 00:30:51,072
with an example here of a set

564
00:30:51,126 --> 00:30:53,132
of observations. What we are observing

565
00:30:53,196 --> 00:30:56,324
are two lights and the lights can

566
00:30:56,362 --> 00:30:59,876
either be at any discrete moment in

567
00:30:59,898 --> 00:31:04,150
time, either on or off. So here we have

568
00:31:04,680 --> 00:31:09,496
a sequence of observations and

569
00:31:09,598 --> 00:31:12,984
one moment in time. The first light was

570
00:31:13,022 --> 00:31:15,930
off and the second light was on. Then

571
00:31:16,860 --> 00:31:18,920
the first light was on, the second light

572
00:31:18,990 --> 00:31:19,930
was off,

573
00:31:22,400 --> 00:31:26,252
then both were on, et cetera. And I

574
00:31:26,306 --> 00:31:29,820
put the gray bars there to show that

575
00:31:29,890 --> 00:31:31,816
maybe the observations are incomplete.

576
00:31:31,848 --> 00:31:33,696
So at one stage we can only see the

577
00:31:33,718 --> 00:31:35,664
second light or there may be other

578
00:31:35,702 --> 00:31:37,776
lights or other objects that we do not

579
00:31:37,798 --> 00:31:39,760
see, but that's what we observe.

580
00:31:42,870 --> 00:31:47,170
So you feed these observations

581
00:31:49,190 --> 00:31:52,138
in discrete time into the apperception

582
00:31:52,174 --> 00:31:55,366
engine and the perception engine

583
00:31:55,468 --> 00:31:59,500
searches for a causal theory that

584
00:31:59,950 --> 00:32:03,222
when applied to an initial condition,

585
00:32:03,286 --> 00:32:06,314
let's say that light A is off and light

586
00:32:06,352 --> 00:32:10,182
B is on. It will create a trace

587
00:32:10,246 --> 00:32:16,318
of recreated observations. That cover

588
00:32:16,484 --> 00:32:19,834
is a superset, matches the initial

589
00:32:19,882 --> 00:32:22,974
observations. And if this happens, then

590
00:32:23,012 --> 00:32:26,514
our causal theory is a good one. Now,

591
00:32:26,632 --> 00:32:29,986
the causal theory may infer the

592
00:32:30,008 --> 00:32:32,574
existence of hidden objects, hidden

593
00:32:32,622 --> 00:32:35,026
relations, and whatnot it may actually

594
00:32:35,128 --> 00:32:36,100
need to.

595
00:32:38,330 --> 00:32:42,530
So here's an example of a causal theory

596
00:32:42,690 --> 00:32:44,694
that is generated by my own

597
00:32:44,732 --> 00:32:46,306
implementation of the App perception

598
00:32:46,338 --> 00:32:50,050
engine. Because I re implemented the App

599
00:32:50,060 --> 00:32:52,026
perception engine as described in the

600
00:32:52,048 --> 00:32:54,620
paper by Richard Evans and all,

601
00:32:55,310 --> 00:32:59,034
and I ran it

602
00:32:59,072 --> 00:33:02,054
on the set of observations about lights

603
00:33:02,102 --> 00:33:05,374
on two lights, one on, one off at any

604
00:33:05,412 --> 00:33:08,814
point in time. And it came up with

605
00:33:08,852 --> 00:33:11,086
it found a result. It found the result

606
00:33:11,188 --> 00:33:14,980
in 64 seconds. It was a perfect match.

607
00:33:15,430 --> 00:33:19,502
And it actually invented

608
00:33:19,566 --> 00:33:22,094
a relationship, which it called thread

609
00:33:22,142 --> 00:33:25,566
One, which we can let's

610
00:33:25,598 --> 00:33:27,522
imagine that it actually means connects

611
00:33:27,586 --> 00:33:31,234
to. And it found a static

612
00:33:31,282 --> 00:33:34,774
rule and a causal rule. It said that a

613
00:33:34,812 --> 00:33:37,894
light is on at any moment in time.

614
00:33:37,932 --> 00:33:40,966
A light is on if a light that connects

615
00:33:40,998 --> 00:33:44,854
to it is off. And it found a causal rule

616
00:33:44,982 --> 00:33:48,966
that said a light turns

617
00:33:48,998 --> 00:33:52,666
off if it connects

618
00:33:52,698 --> 00:33:55,280
to another light that was also off.

619
00:33:55,970 --> 00:33:59,054
So that's how the lights change over

620
00:33:59,092 --> 00:34:01,886
time, the status of on and off. And it

621
00:34:01,908 --> 00:34:03,534
came up with initial conditions that

622
00:34:03,572 --> 00:34:07,234
said that, well, A connects to,

623
00:34:07,352 --> 00:34:08,898
first of all, that there's an object

624
00:34:08,984 --> 00:34:11,154
one, a light called object one that we

625
00:34:11,192 --> 00:34:14,274
don't see, but is there, we imagine is

626
00:34:14,312 --> 00:34:17,590
there, that A connects to it. The light

627
00:34:17,660 --> 00:34:20,022
object one connects to B, and the light

628
00:34:20,076 --> 00:34:23,126
B connects to object one. So that's the

629
00:34:23,148 --> 00:34:25,190
causal rule that it discovered.

630
00:34:27,770 --> 00:34:30,986
Now, if we run this causal rule, we

631
00:34:31,008 --> 00:34:34,138
produce a trace. And as you

632
00:34:34,144 --> 00:34:36,074
can see, the trace matches the

633
00:34:36,112 --> 00:34:39,354
observation. It adds a new object.

634
00:34:39,552 --> 00:34:43,102
So the coverage being excellent, being

635
00:34:43,156 --> 00:34:45,386
perfect in this case, and our causal

636
00:34:45,418 --> 00:34:47,646
theory is a good one. It's actually a

637
00:34:47,668 --> 00:34:50,686
perfect one. It's not necessarily the

638
00:34:50,708 --> 00:34:51,760
only one, though.

639
00:34:54,230 --> 00:34:57,646
So is this causal theory unified?

640
00:34:57,838 --> 00:35:01,566
So going back to Dr. Kant's requirement

641
00:35:01,678 --> 00:35:04,654
of synthetic unity, of Apperception,

642
00:35:04,782 --> 00:35:07,654
not every causal theory will do, though

643
00:35:07,692 --> 00:35:11,174
it may predict correctly, it may

644
00:35:11,212 --> 00:35:14,710
not be meaningful unless it is unified.

645
00:35:17,560 --> 00:35:20,824
Well, we saw the four

646
00:35:20,862 --> 00:35:22,744
dimensions of unification. Is it

647
00:35:22,942 --> 00:35:26,420
spatially unified? Well, all our objects

648
00:35:26,580 --> 00:35:30,340
are connected directly or indirectly

649
00:35:30,420 --> 00:35:33,630
to each other. That's good.

650
00:35:34,720 --> 00:35:37,916
So we have spatial unification. Do we

651
00:35:37,938 --> 00:35:39,676
have conceptual unification? So we have

652
00:35:39,698 --> 00:35:41,836
this new predicate. We have two

653
00:35:41,858 --> 00:35:44,670
predicates, right? Pred One, which we

654
00:35:45,380 --> 00:35:48,064
translate to, connects to, and then the

655
00:35:48,102 --> 00:35:50,384
predicate that says whether the light is

656
00:35:50,422 --> 00:35:53,484
on or off. Well, we have a constraint

657
00:35:53,532 --> 00:35:57,684
that says that a light can

658
00:35:57,722 --> 00:35:59,908
only be connected to one other light.

659
00:35:59,994 --> 00:36:03,684
So pred one has a constraint on it

660
00:36:03,722 --> 00:36:08,576
that says it's

661
00:36:08,768 --> 00:36:12,944
exclusive. So an object cannot pred

662
00:36:12,992 --> 00:36:15,064
one to two objects cannot connect to two

663
00:36:15,102 --> 00:36:17,016
objects. That's a constraint that was

664
00:36:17,038 --> 00:36:18,676
discovered and part of the causal

665
00:36:18,708 --> 00:36:22,120
theory. And also implicitly,

666
00:36:24,620 --> 00:36:28,136
the on relation of the predicate

667
00:36:28,248 --> 00:36:31,016
has the value on or off, and it cannot

668
00:36:31,048 --> 00:36:33,816
be both at the same time. So it's

669
00:36:33,848 --> 00:36:36,764
conceptually unified. Is it statically

670
00:36:36,812 --> 00:36:40,044
unified? Are the static

671
00:36:40,092 --> 00:36:42,944
rules obeyed. Well, for example, the

672
00:36:42,982 --> 00:36:46,592
static rule would say that given that B

673
00:36:46,726 --> 00:36:50,772
connects to A, if B is off,

674
00:36:50,906 --> 00:36:54,116
then A must be on. So if you look at any

675
00:36:54,298 --> 00:36:57,204
place where B is off, a is going to be

676
00:36:57,242 --> 00:37:00,096
on. And you could do that for every

677
00:37:00,218 --> 00:37:03,208
other light and relationships between

678
00:37:03,294 --> 00:37:05,844
lights. So they all obey the static

679
00:37:05,892 --> 00:37:08,250
rule. And the causal rule says,

680
00:37:09,580 --> 00:37:12,244
for example, here, that if B connects to

681
00:37:12,302 --> 00:37:16,220
A, then if A was off, then B must turn

682
00:37:16,290 --> 00:37:20,220
off. So if you look at B, let's say

683
00:37:20,370 --> 00:37:21,790
B was off.

684
00:37:25,680 --> 00:37:29,552
Yeah, I'm sorry, if B connects to

685
00:37:29,606 --> 00:37:30,210
A,

686
00:37:33,060 --> 00:37:36,480
and yes, and if A

687
00:37:36,550 --> 00:37:39,716
was off, B must be off.

688
00:37:39,818 --> 00:37:43,156
So if A was off, B becomes off

689
00:37:43,258 --> 00:37:45,684
the next step. So that's correct as

690
00:37:45,722 --> 00:37:49,648
well. So statistically we are

691
00:37:49,754 --> 00:37:52,730
true, and temporarily we are true.

692
00:37:53,500 --> 00:37:57,384
We are unified. And of course, that we

693
00:37:57,422 --> 00:38:00,200
get a thumbs up from Dr. Kant,

694
00:38:01,260 --> 00:38:05,164
our causal theory is unified. Thus it

695
00:38:05,202 --> 00:38:08,236
makes sense of the observations of the

696
00:38:08,258 --> 00:38:11,532
sensory inputs. Now,

697
00:38:11,586 --> 00:38:16,584
it's no accident that Kant

698
00:38:16,632 --> 00:38:18,296
would be would figure in an active

699
00:38:18,328 --> 00:38:20,910
inference project. There is a link

700
00:38:21,440 --> 00:38:23,916
between active inference and Kant, and

701
00:38:23,938 --> 00:38:26,376
it runs through the celebrated 19th

702
00:38:26,408 --> 00:38:29,584
century German engineer Herman

703
00:38:29,632 --> 00:38:33,264
von Hemholz. He was a disciple of Kant

704
00:38:33,392 --> 00:38:35,904
and he developed the theory of visual

705
00:38:35,952 --> 00:38:38,656
perception that operationalized Kant's

706
00:38:38,688 --> 00:38:40,376
epistemology. And in fact, it

707
00:38:40,398 --> 00:38:43,224
anticipates predictive processing. In

708
00:38:43,262 --> 00:38:46,564
1995, Peter Day and Jeff

709
00:38:46,612 --> 00:38:49,284
Hinton developed the Helmholtz machine.

710
00:38:49,332 --> 00:38:52,808
Name is in his hunter. It is a

711
00:38:52,814 --> 00:38:54,536
type of artificial neural network that's

712
00:38:54,568 --> 00:38:56,750
trained to create a generative model

713
00:38:57,200 --> 00:38:59,404
from an original set of data. And it can

714
00:38:59,442 --> 00:39:01,324
account for the hidden structure of the

715
00:39:01,362 --> 00:39:04,696
data. So as you

716
00:39:04,738 --> 00:39:07,868
see, there's a link which is discussed

717
00:39:07,884 --> 00:39:09,856
and elaborated in this paper, which is

718
00:39:09,878 --> 00:39:13,168
very interesting paper. All right,

719
00:39:13,254 --> 00:39:16,748
so close parentheses.

720
00:39:16,924 --> 00:39:18,544
So we've looked at the App Perception

721
00:39:18,592 --> 00:39:20,532
engine from the perspective of

722
00:39:20,666 --> 00:39:24,596
philosophy. So now let's look

723
00:39:24,618 --> 00:39:25,904
at it through the lens of machine

724
00:39:25,952 --> 00:39:26,550
learning.

725
00:39:29,660 --> 00:39:31,640
The observations constitute a training

726
00:39:31,710 --> 00:39:35,160
set. It's a very small one. And the

727
00:39:35,230 --> 00:39:38,904
Appetition engine is the

728
00:39:39,022 --> 00:39:41,924
learning algorithm. And what is learned,

729
00:39:41,972 --> 00:39:44,140
the output is a causal theory.

730
00:39:46,000 --> 00:39:50,088
So the learning process is unsupervised

731
00:39:50,184 --> 00:39:54,156
logical inferencing, and the

732
00:39:54,178 --> 00:39:57,164
output is a human readable logic

733
00:39:57,212 --> 00:40:00,476
program. So we see here that there's

734
00:40:00,508 --> 00:40:05,504
some profound differences with the

735
00:40:05,542 --> 00:40:07,476
more popular form of machine learning in

736
00:40:07,498 --> 00:40:10,070
that the training set is really small,

737
00:40:11,800 --> 00:40:16,356
that the product of the

738
00:40:16,378 --> 00:40:20,260
learning is actually a human readable

739
00:40:20,340 --> 00:40:23,450
artifact, in this case, a logic program.

740
00:40:25,500 --> 00:40:27,770
So this is the training set.

741
00:40:29,340 --> 00:40:33,100
As inputted lights

742
00:40:33,920 --> 00:40:38,428
led, a turned off at

743
00:40:38,594 --> 00:40:42,140
time one, b turned on at time one,

744
00:40:42,290 --> 00:40:45,612
a turned on at time two, b turned off at

745
00:40:45,666 --> 00:40:48,256
time two, et cetera, et cetera. So

746
00:40:48,278 --> 00:40:52,528
that's the training set and

747
00:40:52,614 --> 00:40:56,396
you feed this into the perception

748
00:40:56,428 --> 00:41:00,484
engine's algorithm and out comes a

749
00:41:00,682 --> 00:41:04,228
causal theory. So in a

750
00:41:04,234 --> 00:41:06,468
little bit more details what the

751
00:41:06,554 --> 00:41:09,664
algorithm is and does. First, it

752
00:41:09,722 --> 00:41:13,608
extracts the observed object

753
00:41:13,694 --> 00:41:15,656
extent objects, the object types and

754
00:41:15,678 --> 00:41:18,216
predicates from the observations. So we

755
00:41:18,238 --> 00:41:21,896
have on, we have object A, object B.

756
00:41:21,998 --> 00:41:24,136
We have led as an object type. So that's

757
00:41:24,168 --> 00:41:25,804
all part of the observations and that

758
00:41:25,842 --> 00:41:29,020
becomes part of the extent vocabulary.

759
00:41:29,440 --> 00:41:33,500
Then the application engine imagines

760
00:41:34,400 --> 00:41:38,400
unobserved objects, types and predicates

761
00:41:38,980 --> 00:41:40,892
for the relationships and properties,

762
00:41:40,956 --> 00:41:43,516
and that becomes a latent vocabulary.

763
00:41:43,548 --> 00:41:46,960
So there's a step of imagination. Then,

764
00:41:47,030 --> 00:41:50,196
using the combined vocabulary, both the

765
00:41:50,218 --> 00:41:53,152
extent and latent vocabulary combined,

766
00:41:53,296 --> 00:41:56,532
it looks for a unified causal theory, a

767
00:41:56,586 --> 00:41:58,704
set of constraints, rules and initial

768
00:41:58,752 --> 00:42:05,016
conditions that obey the

769
00:42:05,038 --> 00:42:09,524
constraints of synthetic unity

770
00:42:09,572 --> 00:42:13,276
of apperception. Once it has this

771
00:42:13,298 --> 00:42:14,904
causal theory and with initial

772
00:42:14,952 --> 00:42:17,176
conditions, it applies the causal theory

773
00:42:17,208 --> 00:42:19,276
to these conditions and produces a

774
00:42:19,298 --> 00:42:22,408
trace. It recreates observations

775
00:42:22,504 --> 00:42:25,340
if you want and augments them and

776
00:42:25,410 --> 00:42:28,496
extends them into the future. Now it

777
00:42:28,518 --> 00:42:30,288
looks at this trace and compares it with

778
00:42:30,294 --> 00:42:32,460
the initial observations for coverage

779
00:42:32,540 --> 00:42:34,956
and decides if this is a good causal

780
00:42:34,988 --> 00:42:37,340
theory or not. Then it also looks at the

781
00:42:37,350 --> 00:42:39,812
causal theory complexity, how many

782
00:42:39,866 --> 00:42:42,368
rules, how complex are the rules, et

783
00:42:42,384 --> 00:42:44,948
cetera, and measures for complexity. So

784
00:42:44,954 --> 00:42:48,496
if we have a choice between two causal

785
00:42:48,528 --> 00:42:51,400
theories of equivalent coverage,

786
00:42:51,820 --> 00:42:55,048
the App Perception Engine will select

787
00:42:55,134 --> 00:42:57,716
the least complex one using Occam's

788
00:42:57,748 --> 00:42:59,784
Razor. Now, if you look at this

789
00:42:59,822 --> 00:43:02,796
algorithm, you'll see that the boxes in

790
00:43:02,818 --> 00:43:07,420
green are not deterministic.

791
00:43:07,840 --> 00:43:09,804
This is where search happens. We can

792
00:43:09,842 --> 00:43:12,892
posit different kinds of objects. We can

793
00:43:13,026 --> 00:43:16,236
find different kinds of rules. So this

794
00:43:16,258 --> 00:43:18,110
is where search happens.

795
00:43:19,360 --> 00:43:23,040
Now, app perception is implemented using

796
00:43:23,110 --> 00:43:27,212
logic inference. Actually, it uses three

797
00:43:27,286 --> 00:43:29,556
forms of logic inference. There's the

798
00:43:29,578 --> 00:43:31,364
one that we're more familiar with,

799
00:43:31,482 --> 00:43:34,576
which is deduction, where given rules

800
00:43:34,608 --> 00:43:38,212
and causes, we infer the effects. Then

801
00:43:38,266 --> 00:43:40,576
there's induction. Where given causes

802
00:43:40,608 --> 00:43:42,536
and effect, we look for the rules. This

803
00:43:42,558 --> 00:43:45,480
is what science does, right? Looking for

804
00:43:45,550 --> 00:43:47,876
rules that would account for effects

805
00:43:47,908 --> 00:43:50,004
given the causes. Then there's

806
00:43:50,052 --> 00:43:52,792
abduction, where given the rules and

807
00:43:52,846 --> 00:43:54,776
given what we observe the effects,

808
00:43:54,888 --> 00:43:57,004
we're looking for the causes. In this

809
00:43:57,042 --> 00:43:58,344
case, we're looking for the latent

810
00:43:58,392 --> 00:44:00,856
objects, the latent relationships

811
00:44:00,888 --> 00:44:04,076
between these objects. And then you can

812
00:44:04,098 --> 00:44:06,412
combine both abduction and induction,

813
00:44:06,476 --> 00:44:08,892
where you're given effects, essentially

814
00:44:08,956 --> 00:44:10,400
observations, and you're looking for

815
00:44:10,470 --> 00:44:13,008
both causes and rules, which is what the

816
00:44:13,014 --> 00:44:16,016
App Perception Engine does. And this is

817
00:44:16,038 --> 00:44:19,316
where in the algorithm, these kinds of

818
00:44:19,338 --> 00:44:22,704
inferences are at play. So positing

819
00:44:22,752 --> 00:44:24,660
latent objects, that's a form of

820
00:44:24,730 --> 00:44:28,032
abduction, imagining causes,

821
00:44:28,176 --> 00:44:30,172
finding the rules, well, that's clearly

822
00:44:30,336 --> 00:44:33,476
a form of induction. And then applying

823
00:44:33,508 --> 00:44:36,888
the rules of a

824
00:44:36,894 --> 00:44:40,580
causal theory to some initial conditions

825
00:44:40,660 --> 00:44:42,196
to create a trace, well, that's

826
00:44:42,228 --> 00:44:44,476
deduction. We have the causes, the

827
00:44:44,498 --> 00:44:46,120
initial conditions, we have the rules,

828
00:44:46,200 --> 00:44:48,828
causal theory, and then we produce a

829
00:44:48,834 --> 00:44:51,544
trace, the effects. So that's deduction.

830
00:44:51,592 --> 00:44:54,332
So the App Perception Engine uses all

831
00:44:54,386 --> 00:44:57,260
forms of logical inference.

832
00:44:58,800 --> 00:45:01,884
Now, just a reminder that the output of

833
00:45:01,922 --> 00:45:04,656
the App Perception Engine, that is what

834
00:45:04,678 --> 00:45:07,688
is learned is actually human readable.

835
00:45:07,884 --> 00:45:11,524
You may want to compare that to a

836
00:45:11,562 --> 00:45:17,040
large array of floating points produced

837
00:45:17,120 --> 00:45:20,904
by traditional, the more popular form.

838
00:45:20,942 --> 00:45:23,240
Of machine learning nowadays. So here,

839
00:45:23,310 --> 00:45:25,464
this is what's actually produced by the

840
00:45:25,502 --> 00:45:27,736
app reception engine. As it runs on a

841
00:45:27,758 --> 00:45:31,656
set of observations, it produces a

842
00:45:31,678 --> 00:45:35,060
logic program that is human readable.

843
00:45:35,220 --> 00:45:36,636
When you look at it, the only thing you

844
00:45:36,658 --> 00:45:40,396
need to kind of guess is what is

845
00:45:40,418 --> 00:45:42,044
meant by pred one. And if you think,

846
00:45:42,082 --> 00:45:44,044
well, maybe it means connects to maybe

847
00:45:44,082 --> 00:45:47,216
the lights are connected underneath a

848
00:45:47,238 --> 00:45:51,120
board out of sight of

849
00:45:51,270 --> 00:45:52,480
the observer.

850
00:45:54,580 --> 00:45:57,148
But finding a unified causal theory is

851
00:45:57,254 --> 00:46:00,436
hard. So we have to guess what the

852
00:46:00,458 --> 00:46:02,916
latent objects and predicates are. What

853
00:46:02,938 --> 00:46:05,844
are the hidden lights, what are the

854
00:46:05,882 --> 00:46:07,968
hidden relationships between lights?

855
00:46:08,064 --> 00:46:10,436
And we have to discover what constraints

856
00:46:10,468 --> 00:46:13,736
might apply on the predicates and what

857
00:46:13,758 --> 00:46:15,576
are the initial conditions from which we

858
00:46:15,598 --> 00:46:18,248
want to recreate a trace. What are the

859
00:46:18,254 --> 00:46:21,492
static rules that apply to simultaneous

860
00:46:21,556 --> 00:46:23,436
observations? And then what are the

861
00:46:23,458 --> 00:46:27,196
causal rules that given observations at

862
00:46:27,218 --> 00:46:30,668
time T will predict observations at time

863
00:46:30,754 --> 00:46:33,550
T plus one? This is hard.

864
00:46:34,080 --> 00:46:36,396
As a matter of fact, it's non

865
00:46:36,588 --> 00:46:39,520
polynomially hard. The search space

866
00:46:39,590 --> 00:46:42,096
grows exponentially with the size of the

867
00:46:42,118 --> 00:46:46,444
input, which is the size of the extent

868
00:46:46,492 --> 00:46:49,876
and latent vocabulary. So just

869
00:46:49,898 --> 00:46:53,044
like in chess, you can't predict to the

870
00:46:53,082 --> 00:46:55,076
end the consequence of a move because of

871
00:46:55,098 --> 00:46:57,716
common turbo explosion. With the app

872
00:46:57,738 --> 00:46:59,596
perception engine, you cannot

873
00:46:59,728 --> 00:47:01,752
systematically traverse the entire space

874
00:47:01,806 --> 00:47:04,248
of possible causal theories to find a

875
00:47:04,254 --> 00:47:06,970
good one because it's impossibly large.

876
00:47:09,740 --> 00:47:11,896
So the job of the apperception engine is

877
00:47:11,918 --> 00:47:13,756
to find a causal theory in a

878
00:47:13,858 --> 00:47:16,140
ridiculously large haystack.

879
00:47:17,520 --> 00:47:21,176
How to do this? In my implementation,

880
00:47:21,368 --> 00:47:25,536
I follow the

881
00:47:25,558 --> 00:47:28,736
recommendations and I follow also the

882
00:47:28,758 --> 00:47:31,836
implementation in Richard Evans'paper

883
00:47:32,028 --> 00:47:34,450
by breaking the search space into

884
00:47:35,060 --> 00:47:38,592
chunks. First there's a region

885
00:47:38,656 --> 00:47:41,616
and the region says so how many latent

886
00:47:41,648 --> 00:47:43,296
object types, objects and predicates

887
00:47:43,328 --> 00:47:45,684
will we allow? So what is the limit of

888
00:47:45,722 --> 00:47:49,344
imagination of the cognition

889
00:47:49,392 --> 00:47:52,248
actors that is trying to apperceive a

890
00:47:52,254 --> 00:47:54,536
causal theory? What are the limits of

891
00:47:54,558 --> 00:47:57,160
its imagination? And within that region

892
00:47:58,380 --> 00:48:00,440
of bounded imagination,

893
00:48:01,180 --> 00:48:05,240
we carve it into templates

894
00:48:05,400 --> 00:48:07,324
where we say, okay, we're going to use

895
00:48:07,442 --> 00:48:10,616
these latent objects types, these latent

896
00:48:10,648 --> 00:48:13,164
objects. And so basically, what

897
00:48:13,202 --> 00:48:15,068
vocabulary, specific vocabulary we're

898
00:48:15,084 --> 00:48:16,736
going to be using? We're going to use

899
00:48:16,758 --> 00:48:18,690
object one. We're going to use object

900
00:48:19,060 --> 00:48:22,668
pred one on top of the observed

901
00:48:22,844 --> 00:48:26,544
on predicate and observed A

902
00:48:26,582 --> 00:48:29,428
and B lights. And we're going to set the

903
00:48:29,434 --> 00:48:32,564
maximum complexity on the rules and see

904
00:48:32,602 --> 00:48:35,636
if we can find causal theories that fit

905
00:48:35,658 --> 00:48:38,228
this template. So this is a carving up

906
00:48:38,234 --> 00:48:41,184
of the search space and having broken

907
00:48:41,232 --> 00:48:44,184
the search space into regions and

908
00:48:44,222 --> 00:48:48,244
templates, we have scopes

909
00:48:48,292 --> 00:48:51,560
in which to apply Heuristics. Now. Why

910
00:48:51,630 --> 00:48:54,344
heuristics? Because the systematic

911
00:48:54,392 --> 00:48:57,592
traversal cannot be done in reasonable

912
00:48:57,656 --> 00:49:01,016
time. There's just too many candidate

913
00:49:01,128 --> 00:49:03,948
causal theories to look at to find a

914
00:49:03,954 --> 00:49:06,320
good one. So we use Heuristics.

915
00:49:08,260 --> 00:49:11,024
We find ways of maybe getting to a good

916
00:49:11,062 --> 00:49:13,916
solution faster at the risk of missing

917
00:49:13,948 --> 00:49:17,424
it. But at least we'll have an

918
00:49:17,462 --> 00:49:20,144
answer or no answer in a reasonable

919
00:49:20,192 --> 00:49:22,308
amount of time. And there's a number of

920
00:49:22,394 --> 00:49:25,044
heuristics that I've implemented in my

921
00:49:25,082 --> 00:49:26,704
implementation of the app assetron

922
00:49:26,752 --> 00:49:29,316
engine. Well, there's time boxing. At

923
00:49:29,338 --> 00:49:30,952
some point, you'd spend no more than

924
00:49:31,006 --> 00:49:33,176
this amount of time looking into a

925
00:49:33,198 --> 00:49:36,436
region or into a template. There's

926
00:49:36,468 --> 00:49:38,344
multitasking. Well, the problem is

927
00:49:38,382 --> 00:49:39,956
actually, as they say, embarrassingly

928
00:49:39,988 --> 00:49:42,356
parallel. You can explore multiple

929
00:49:42,388 --> 00:49:43,756
regions and multiple templates in

930
00:49:43,778 --> 00:49:46,556
parallel and so make good use of a

931
00:49:46,578 --> 00:49:50,428
multicore computer. You want to

932
00:49:50,434 --> 00:49:51,884
make sure you don't repeat yourself. So

933
00:49:51,922 --> 00:49:54,412
you don't want to traverse the same

934
00:49:54,466 --> 00:49:57,036
region twice or look at the same causal

935
00:49:57,068 --> 00:50:00,560
theory twice. You want to satisfy

936
00:50:01,060 --> 00:50:03,520
maybe a good enough theory is just fine.

937
00:50:03,590 --> 00:50:05,520
We don't want to look for the perfect

938
00:50:05,590 --> 00:50:07,730
one necessarily. We may not have time.

939
00:50:08,740 --> 00:50:10,900
You want to fail early. If you're in a

940
00:50:10,970 --> 00:50:13,108
region where nothing good is found, you

941
00:50:13,114 --> 00:50:16,036
may want to leave it quite quickly at

942
00:50:16,058 --> 00:50:18,964
the risk of maybe not finding a good one

943
00:50:19,002 --> 00:50:21,956
that is just over the horizon. But you

944
00:50:21,978 --> 00:50:24,068
want to be impatient. You want to throw

945
00:50:24,084 --> 00:50:27,416
the dice. You may want to kind

946
00:50:27,438 --> 00:50:29,656
of mix it up so that every time you run

947
00:50:29,678 --> 00:50:31,144
the app Perception Engine on the same

948
00:50:31,182 --> 00:50:34,956
problem, you may find a

949
00:50:34,978 --> 00:50:38,396
different solution first. You want

950
00:50:38,418 --> 00:50:41,372
to go for the simpler solution first.

951
00:50:41,506 --> 00:50:42,940
You may not want to try everything,

952
00:50:43,010 --> 00:50:45,856
just sample some. You want to start with

953
00:50:45,958 --> 00:50:49,040
the easiest part of the search base

954
00:50:49,110 --> 00:50:51,936
first, be judicious and so forth and so

955
00:50:51,958 --> 00:50:54,236
on. And most importantly, be selective.

956
00:50:54,348 --> 00:50:57,984
So reject any causal theory that would

957
00:50:58,022 --> 00:51:00,736
fail the constraints of unity of

958
00:51:00,758 --> 00:51:03,750
apperception. With all these in place,

959
00:51:07,080 --> 00:51:08,816
my implementation of the app Perception

960
00:51:08,848 --> 00:51:11,544
Engine gives pretty good results. So

961
00:51:11,582 --> 00:51:13,876
here I did a run. This is not cherry

962
00:51:13,908 --> 00:51:16,616
picked. I decided to do one series of

963
00:51:16,638 --> 00:51:19,668
seven runs and collect

964
00:51:19,684 --> 00:51:23,484
the data and show it. And in this

965
00:51:23,522 --> 00:51:25,596
run, I set up the apparition engine to

966
00:51:25,618 --> 00:51:28,648
only accept a perfect causal theory,

967
00:51:28,744 --> 00:51:31,884
one that would produce a trace that

968
00:51:31,922 --> 00:51:35,836
totally covers the observation. And I

969
00:51:35,858 --> 00:51:39,292
did seven runs. The first one succeeded,

970
00:51:39,356 --> 00:51:42,288
found it in 4 seconds. The second one,

971
00:51:42,374 --> 00:51:44,496
it took 102 seconds. So there's some

972
00:51:44,518 --> 00:51:46,784
randomization in the order in which

973
00:51:46,822 --> 00:51:48,276
things have searched if luck is

974
00:51:48,298 --> 00:51:51,460
involved. As I said, the third one,

975
00:51:51,530 --> 00:51:53,510
1 second, that was pretty cool.

976
00:51:55,400 --> 00:51:59,460
The fourth one, well, took 204 seconds,

977
00:51:59,800 --> 00:52:03,704
then 90, 612, 99. So quite

978
00:52:03,822 --> 00:52:06,424
a good distribution here. Now, I said,

979
00:52:06,462 --> 00:52:07,944
okay, I'm going to run the app

980
00:52:07,982 --> 00:52:10,472
Perception Engine again on the same

981
00:52:10,606 --> 00:52:12,744
training set that I showed earlier,

982
00:52:12,792 --> 00:52:15,630
those two lights. But this time I said,

983
00:52:16,960 --> 00:52:23,244
I'm going to accept the theory that has

984
00:52:23,282 --> 00:52:28,304
85% or more coverage. So it

985
00:52:28,342 --> 00:52:31,888
recreates the observations well enough,

986
00:52:32,054 --> 00:52:35,548
but not perfectly. And I time boxed

987
00:52:35,564 --> 00:52:37,696
it to 30 seconds. So you have 30 seconds

988
00:52:37,728 --> 00:52:40,724
to find it. Go. The first run,

989
00:52:40,842 --> 00:52:44,470
it find a causal theory with 75%

990
00:52:45,080 --> 00:52:47,760
accuracy immediately.

991
00:52:47,920 --> 00:52:50,292
Then the same accuracy, same coverage.

992
00:52:50,356 --> 00:52:53,832
10 seconds. 11 seconds. It hit 29

993
00:52:53,886 --> 00:52:57,336
seconds. It found a perfect one.

994
00:52:57,518 --> 00:53:00,056
Then eleven, it found 87% coverage and

995
00:53:00,078 --> 00:53:01,688
stopped right there. That's good enough.

996
00:53:01,774 --> 00:53:05,132
75 again, 100% is the first one it found

997
00:53:05,186 --> 00:53:09,416
above 85 in 18 seconds and 75% 0 second.

998
00:53:09,448 --> 00:53:11,928
So a good distribution again, so we're

999
00:53:11,944 --> 00:53:14,108
getting into reasonable times. We're not

1000
00:53:14,114 --> 00:53:15,456
talking about hours here, we're talking

1001
00:53:15,478 --> 00:53:18,624
about seconds. And I'm hoping to do

1002
00:53:18,662 --> 00:53:20,992
further optimizations and bring it down

1003
00:53:21,046 --> 00:53:24,016
to something even smaller so that a

1004
00:53:24,038 --> 00:53:27,168
cognition actor can say, I want to

1005
00:53:27,174 --> 00:53:28,720
make sense of these observations,

1006
00:53:30,980 --> 00:53:33,316
query the apperception engine, and get

1007
00:53:33,338 --> 00:53:36,468
an answer, a causal theory within maybe

1008
00:53:36,554 --> 00:53:38,630
a couple of seconds. That's my hope.

1009
00:53:40,440 --> 00:53:42,768
Now, something interesting here. It so

1010
00:53:42,794 --> 00:53:44,856
happens that what makes it hard for the

1011
00:53:44,878 --> 00:53:46,376
app perception engine to find a good

1012
00:53:46,398 --> 00:53:49,336
causal theory is formally equivalent to

1013
00:53:49,358 --> 00:53:51,528
what makes cognitive science as a whole

1014
00:53:51,614 --> 00:53:54,268
hard. And this paper here makes the case

1015
00:53:54,434 --> 00:53:57,020
and proves the case quite cogently.

1016
00:53:58,640 --> 00:54:04,368
So cognizant

1017
00:54:04,384 --> 00:54:07,044
science wants to find models, functions

1018
00:54:07,092 --> 00:54:11,016
or algorithms that explain,

1019
00:54:11,118 --> 00:54:14,372
account for situated behaviors.

1020
00:54:14,436 --> 00:54:18,010
So you feed into

1021
00:54:19,280 --> 00:54:22,588
the cognitive science machine pairs of

1022
00:54:22,674 --> 00:54:24,796
situations and behaviors, and you want

1023
00:54:24,818 --> 00:54:27,004
to come out of it a model, an

1024
00:54:27,042 --> 00:54:30,152
explanation, a function, or an algorithm

1025
00:54:30,296 --> 00:54:32,450
that accounts for it.

1026
00:54:33,220 --> 00:54:36,832
Well, the paper makes the case

1027
00:54:36,886 --> 00:54:40,464
that if the explanation is

1028
00:54:40,502 --> 00:54:44,460
to be bounded in size, then the

1029
00:54:44,470 --> 00:54:46,804
problem is computable, but it's not

1030
00:54:46,842 --> 00:54:48,496
tractable in the sense meaning that it's

1031
00:54:48,528 --> 00:54:50,548
combinatorially explosive. But once you

1032
00:54:50,554 --> 00:54:54,164
have a solution, it is computable and

1033
00:54:54,202 --> 00:54:56,712
tractable to verify that the solution is

1034
00:54:56,766 --> 00:55:00,744
good, that it accounts for the

1035
00:55:00,782 --> 00:55:02,936
data that you're trying to understand.

1036
00:55:03,118 --> 00:55:05,156
Well, this is equivalent, formally

1037
00:55:05,188 --> 00:55:06,724
equivalent to what the app perception

1038
00:55:06,772 --> 00:55:07,850
engine is doing.

1039
00:55:11,200 --> 00:55:14,300
My implementation was done in prologue.

1040
00:55:14,800 --> 00:55:17,016
I will not go into the details. It's

1041
00:55:17,048 --> 00:55:19,196
about 1000 lines of prologue. I'll just

1042
00:55:19,218 --> 00:55:21,348
say that prologue is a programming

1043
00:55:21,384 --> 00:55:25,212
language that use deductive inference

1044
00:55:25,356 --> 00:55:27,424
as its model of computation with

1045
00:55:27,462 --> 00:55:31,424
backtracking. So essentially it

1046
00:55:31,462 --> 00:55:34,268
searches for a solution and will

1047
00:55:34,454 --> 00:55:38,432
backtrack if it took the wrong branch

1048
00:55:38,496 --> 00:55:41,796
if you want. And we'll look for

1049
00:55:41,898 --> 00:55:45,636
a different way of satisfying a line of

1050
00:55:45,658 --> 00:55:49,336
the program. So let's just say

1051
00:55:49,358 --> 00:55:52,170
that it makes traversing a search space.

1052
00:55:53,340 --> 00:55:55,096
We get traversing a search brains for

1053
00:55:55,118 --> 00:55:57,768
free when we program in prologue. I

1054
00:55:57,774 --> 00:55:59,388
won't go into any more details, but you

1055
00:55:59,394 --> 00:56:02,956
can see some prologue code here. And the

1056
00:56:02,978 --> 00:56:06,776
fun thing is that a prologue

1057
00:56:06,808 --> 00:56:09,816
program is akin to a logical description

1058
00:56:09,848 --> 00:56:12,656
of the problem it's trying to solve. I

1059
00:56:12,678 --> 00:56:17,004
think it's very cool. And prologue

1060
00:56:17,052 --> 00:56:19,312
environment was augmented by something

1061
00:56:19,366 --> 00:56:22,016
called constraint handling rules, which

1062
00:56:22,038 --> 00:56:23,984
is an extension to prologue that adds

1063
00:56:24,032 --> 00:56:26,868
abductive reasoning. So basically in the

1064
00:56:26,874 --> 00:56:28,964
program, you can say, assume this is

1065
00:56:29,002 --> 00:56:35,396
true until proven otherwise, and the

1066
00:56:35,418 --> 00:56:39,516
CHR rules are there to verify

1067
00:56:39,568 --> 00:56:42,824
if it can be proven otherwise. So,

1068
00:56:43,022 --> 00:56:44,712
again, I'm not asking you to understand

1069
00:56:44,766 --> 00:56:46,536
this code at all, but I want you to

1070
00:56:46,558 --> 00:56:48,636
realize that this code is the code that

1071
00:56:48,658 --> 00:56:51,500
actually executes a causal theory,

1072
00:56:52,240 --> 00:56:54,156
both the static and causal rules to

1073
00:56:54,178 --> 00:56:57,016
build traces. It is that small. It's

1074
00:56:57,048 --> 00:56:59,500
very powerful. So combining prologue and

1075
00:56:59,570 --> 00:57:03,564
CHR, I found extraordinarily powerful.

1076
00:57:03,612 --> 00:57:05,568
I'm very excited about it. I'm a

1077
00:57:05,574 --> 00:57:08,480
programmer. Next steps.

1078
00:57:08,900 --> 00:57:12,800
Well, next steps, now that we've solved

1079
00:57:13,560 --> 00:57:17,460
individual learning by cognitive actors,

1080
00:57:17,960 --> 00:57:23,670
well, I want to move to beliefs from

1081
00:57:24,040 --> 00:57:27,732
sensations and to policies to validate

1082
00:57:27,796 --> 00:57:29,800
or eliminate beliefs.

1083
00:57:31,820 --> 00:57:34,168
A lot of these beliefs actually fall out

1084
00:57:34,174 --> 00:57:35,944
of our perception. Latent objects and

1085
00:57:35,982 --> 00:57:37,944
latent relationships and properties can

1086
00:57:37,982 --> 00:57:40,108
be considered as beliefs. Then there are

1087
00:57:40,114 --> 00:57:41,996
other kinds of beliefs that can be

1088
00:57:42,178 --> 00:57:45,500
obtained from what's been perceived.

1089
00:57:46,800 --> 00:57:50,190
There will be introspective beliefs that

1090
00:57:52,580 --> 00:57:56,524
communicate how the cognition

1091
00:57:56,572 --> 00:57:59,228
actor is doing in terms of competence,

1092
00:57:59,404 --> 00:58:05,220
predictionary rates, how well its

1093
00:58:05,290 --> 00:58:08,372
apperception is doing, and whether

1094
00:58:08,426 --> 00:58:11,584
it is engaging with other cognition

1095
00:58:11,632 --> 00:58:14,772
actors. Is it relevant? I will have

1096
00:58:14,826 --> 00:58:17,604
feelings which will provide normativity

1097
00:58:17,732 --> 00:58:21,368
to these beliefs. So if feelings are

1098
00:58:21,534 --> 00:58:24,920
signals of risk to homeostasis,

1099
00:58:25,340 --> 00:58:28,120
loss of resources, physical damage,

1100
00:58:28,620 --> 00:58:30,276
too many prediction errors so that's

1101
00:58:30,308 --> 00:58:33,676
anger, pain, and fear and feelings will

1102
00:58:33,698 --> 00:58:38,024
taint beliefs over time and tainted

1103
00:58:38,072 --> 00:58:41,436
beliefs, good beliefs,

1104
00:58:41,468 --> 00:58:44,396
bad beliefs will want to be eliminated

1105
00:58:44,428 --> 00:58:48,336
or validated through policies that

1106
00:58:48,358 --> 00:58:50,092
will be synthesized by the cognition

1107
00:58:50,156 --> 00:58:53,570
actor. And each cognition actor will

1108
00:58:54,760 --> 00:58:58,180
make available to others its API.

1109
00:58:59,320 --> 00:59:01,476
What predictions can be made about the

1110
00:59:01,498 --> 00:59:03,172
beliefs of this cognition actor? What

1111
00:59:03,226 --> 00:59:07,316
actions are available to others to

1112
00:59:07,338 --> 00:59:11,036
be asked of the cognition

1113
00:59:11,088 --> 00:59:14,920
actor? And then as cognition actors

1114
00:59:16,700 --> 00:59:20,184
connect to one another, as the

1115
00:59:20,302 --> 00:59:22,216
conjunction actors form the umbelt of

1116
00:59:22,238 --> 00:59:26,376
other cognition actors, then a

1117
00:59:26,398 --> 00:59:27,516
conjunction actor will be able to

1118
00:59:27,538 --> 00:59:29,596
predict the beliefs of others, will be

1119
00:59:29,618 --> 00:59:33,084
able to compose policies

1120
00:59:33,132 --> 00:59:35,276
made out of actions that are implemented

1121
00:59:35,308 --> 00:59:37,920
by other cognition actors. And

1122
00:59:37,990 --> 00:59:41,216
eventually, we'll have a society of

1123
00:59:41,238 --> 00:59:44,240
mind, which is a bunch of intersecting

1124
00:59:45,160 --> 00:59:50,000
boom belts. So that's

1125
00:59:50,160 --> 00:59:54,324
it. So I see the

1126
00:59:54,362 --> 00:59:57,192
society of mine is a complex system of

1127
00:59:57,246 --> 01:00:00,504
collective theorizers. And I'm going to

1128
01:00:00,542 --> 01:00:02,952
try going further with this project to

1129
01:00:03,006 --> 01:00:05,572
answer the question if collective

1130
01:00:05,716 --> 01:00:08,576
theorizers can self organize to actively

1131
01:00:08,628 --> 01:00:12,572
sustain itself. So thank you to

1132
01:00:12,626 --> 01:00:14,444
the Active Inference Institute for

1133
01:00:14,482 --> 01:00:16,744
inviting me to present and for providing

1134
01:00:16,792 --> 01:00:19,036
a home for this project and for the

1135
01:00:19,058 --> 01:00:20,948
constant support and encouragement.

1136
01:00:21,144 --> 01:00:23,856
I'll see you later on Discord. Thank

1137
01:00:23,878 --> 01:00:26,864
you. Awesome. Thank you,

1138
01:00:26,902 --> 01:00:30,476
JF. Just to conclude the session, I'll

1139
01:00:30,508 --> 01:00:33,756
read two questions and let's

1140
01:00:33,948 --> 01:00:35,968
maybe address them in an upcoming

1141
01:00:36,064 --> 01:00:38,596
Robotics and embodied meeting. So if

1142
01:00:38,618 --> 01:00:39,988
you're excited about this project,

1143
01:00:40,074 --> 01:00:42,944
certainly we all are and about symbolic

1144
01:00:42,992 --> 01:00:45,204
active inference, join the Discord and

1145
01:00:45,242 --> 01:00:46,548
participate in the Robotics and

1146
01:00:46,554 --> 01:00:48,724
Embodied. But I'll drop these two

1147
01:00:48,762 --> 01:00:50,388
questions from David Williams in the

1148
01:00:50,394 --> 01:00:53,124
Chat, who wrote, one, how important is

1149
01:00:53,162 --> 01:00:55,060
conducting this work in real world

1150
01:00:55,130 --> 01:00:57,856
versus simulation? And two, what tools

1151
01:00:57,888 --> 01:00:59,196
or components are missing in the

1152
01:00:59,218 --> 01:01:01,470
robotics toolkit to make this research

1153
01:01:01,920 --> 01:01:03,916
easier and better? I know those are

1154
01:01:03,938 --> 01:01:05,096
things that you have a lot of thoughts

1155
01:01:05,128 --> 01:01:07,368
on, so I'll look forward to discussing

1156
01:01:07,384 --> 01:01:09,580
with you more. Thank you, JF.

1157
01:01:11,760 --> 01:01:13,580
Thank you. Peace.

1158
01:01:15,920 --> 01:01:16,910
All right.

1159
01:01:19,600 --> 01:01:20,090
See you.


