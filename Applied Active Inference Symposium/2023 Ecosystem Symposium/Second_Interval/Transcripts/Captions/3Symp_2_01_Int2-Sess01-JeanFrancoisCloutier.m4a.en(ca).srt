1
00:00:07,493 --> 00:00:09,008
Daniel: Hello and welcome, everyone.

2
00:00:09,018 --> 00:00:10,119
Welcome back.

3
00:00:10,134 --> 00:00:13,495
This is the second interval of the third

4
00:00:13,495 --> 00:00:17,865
applied active inference symposium at the

5
00:00:17,865 --> 00:00:21,226
active inference institute on August 22,

6
00:00:21,226 --> 00:00:22,298
2023.

7
00:00:23,407 --> 00:00:26,722
This is going to be another packed and

8
00:00:26,722 --> 00:00:29,045
exciting interval, and we're kicking it

9
00:00:29,045 --> 00:00:32,327
off with Jean Francois Cloutier, a

10
00:00:32,327 --> 00:00:35,659
Collective of theorizers First Steps.

11
00:00:35,668 --> 00:00:38,976
So, JF, thank you for joining and to you

12
00:00:38,976 --> 00:00:40,153
for this presentation.

13
00:00:40,167 --> 00:00:42,388
And if anybody has questions for this

14
00:00:42,388 --> 00:00:45,632
presentation or any of the others, please

15
00:00:45,632 --> 00:00:47,871
just put it in the live chat and I'll do

16
00:00:47,871 --> 00:00:48,906
it.

17
00:00:48,909 --> 00:00:48,958
I can.

18
00:00:48,966 --> 00:00:49,048
So thanks, JF.

19
00:00:49,051 --> 00:00:50,126
To you.

20
00:00:54,584 --> 00:00:56,750
JF: Thank you, Daniel.

21
00:00:57,874 --> 00:01:00,544
I'm a software engineer at a company

22
00:01:00,544 --> 00:01:03,845
called Smart Rent, where I write software

23
00:01:03,845 --> 00:01:05,029
for smart home systems.

24
00:01:06,111 --> 00:01:08,383
I also work on a research project at the

25
00:01:08,383 --> 00:01:11,634
Active Inference Institute called the

26
00:01:11,634 --> 00:01:13,851
Robotics and Embodied Project.

27
00:01:14,960 --> 00:01:18,318
My current focus is unsupervised learning

28
00:01:18,318 --> 00:01:20,563
in active inference agents.

29
00:01:21,681 --> 00:01:25,010
In my presentation today, which is titled

30
00:01:25,010 --> 00:01:28,346
A Collective of theorizers First Steps, I'

31
00:01:28,346 --> 00:01:31,675
'll first start with a brief recap of the

32
00:01:31,675 --> 00:01:34,995
project, then dive into recent progress,

33
00:01:34,995 --> 00:01:38,324
and then I'll conclude with what I see as

34
00:01:38,324 --> 00:01:40,589
the next steps of the project.

35
00:01:43,873 --> 00:01:47,024
Well, since 2017, I've been experimenting

36
00:01:47,024 --> 00:01:51,061
with Lego robots and models of cognition.

37
00:01:51,061 --> 00:01:51,062
.

38
00:01:51,068 --> 00:01:55,103
I do this for my own education, because,

39
00:01:55,103 --> 00:01:58,135
like I think most of us, I understand

40
00:01:58,135 --> 00:02:01,106
something better when I build it.

41
00:02:02,114 --> 00:02:06,150
What you see here is my latest robot

42
00:02:06,150 --> 00:02:06,157
model.

43
00:02:06,159 --> 00:02:08,172
It's a rover.

44
00:02:08,174 --> 00:02:11,208
It has a whole bunch of sensors and a

45
00:02:11,208 --> 00:02:14,237
number of effectors actuators.

46
00:02:15,243 --> 00:02:17,269
As a matter of fact, those sensors and

47
00:02:17,269 --> 00:02:20,295
actuators can be understood as forming

48
00:02:20,295 --> 00:02:22,318
the marker blanket of my robot.

49
00:02:26,353 --> 00:02:29,388
Last year, I presented at the symposium

50
00:02:29,388 --> 00:02:33,422
about the history of the project, its

51
00:02:33,422 --> 00:02:36,452
then status, and its ambitions.

52
00:02:36,456 --> 00:02:39,481
I presented a cognitive model that

53
00:02:39,481 --> 00:02:42,511
implemented predictive processing from an

54
00:02:42,511 --> 00:02:44,534
active inference perspective.

55
00:02:44,535 --> 00:02:47,560
So there were generative models, there

56
00:02:47,560 --> 00:02:49,583
was predictions, there was prediction

57
00:02:49,583 --> 00:02:50,589
errors.

58
00:02:50,591 --> 00:02:53,627
And these generative models animated the

59
00:02:53,627 --> 00:02:57,659
robots so that they would roam, avoid

60
00:02:57,659 --> 00:03:00,635
obstacles, observe their companion, and

61
00:03:00,635 --> 00:03:03,669
also, in a very simplistic way, build a

62
00:03:03,669 --> 00:03:07,703
theory of mind of the other robot.

63
00:03:07,704 --> 00:03:10,738
They could from observations infer that

64
00:03:10,738 --> 00:03:14,772
the other robot had detected food, food

65
00:03:14,772 --> 00:03:17,806
being presented here as a sheet of paper

66
00:03:17,806 --> 00:03:21,840
on the floor, and then would kind of try

67
00:03:21,840 --> 00:03:24,874
to track the other robot to also get to

68
00:03:24,874 --> 00:03:27,907
the food and fun stuff like this.

69
00:03:27,909 --> 00:03:30,937
The implementation combined multi

70
00:03:30,937 --> 00:03:34,969
processing and functional computing.

71
00:03:34,970 --> 00:03:37,999
There was nothing probabilistic in the

72
00:03:37,999 --> 00:03:38,012
implementation.

73
00:03:40,037 --> 00:03:43,060
I thought maybe we'd see them in action.

74
00:03:43,061 --> 00:03:44,075
That's what's presented last year.

75
00:03:44,075 --> 00:03:48,111
But just to get a sense of what they do,

76
00:03:48,111 --> 00:03:51,146
I have two robots here, one named Karl

77
00:03:51,146 --> 00:03:52,156
and Andy.

78
00:03:52,157 --> 00:03:54,178
I named them before I knew I was going to

79
00:03:54,178 --> 00:03:56,192
present at the conference.

80
00:03:57,202 --> 00:04:01,180
So they benefited from a number of

81
00:04:01,180 --> 00:04:03,200
training sessions.

82
00:04:03,205 --> 00:04:07,248
They learned how to find which policies

83
00:04:07,248 --> 00:04:11,289
would achieve their goals better than

84
00:04:11,289 --> 00:04:13,299
others.

85
00:04:13,303 --> 00:04:16,331
And one here on the left.

86
00:04:16,332 --> 00:04:20,371
Found the food rather right away but got

87
00:04:20,371 --> 00:04:24,409
closer to the pedestal where the beacon

88
00:04:24,409 --> 00:04:27,444
is that simulates the scent of food

89
00:04:27,444 --> 00:04:31,482
feared was getting into a collision and

90
00:04:31,482 --> 00:04:34,519
then backs off in a hurry as we'll see

91
00:04:34,519 --> 00:04:38,557
the other robot observes all this, sees

92
00:04:38,557 --> 00:04:42,597
the robot backing off as being in a panic

93
00:04:42,597 --> 00:04:46,633
and decides to share this emotion and

94
00:04:46,633 --> 00:04:48,658
backs up as well.

95
00:04:49,659 --> 00:04:51,684
So fun stuff.

96
00:04:58,751 --> 00:05:00,712
From the beginning I've implemented

97
00:05:00,712 --> 00:05:02,735
different cognition models but they all

98
00:05:02,735 --> 00:05:04,755
have in common the fact that they

99
00:05:04,755 --> 00:05:06,773
implement a society of mind.

100
00:05:07,781 --> 00:05:08,798
So what is a society of mind?

101
00:05:08,798 --> 00:05:13,839
A society of mind is a concept by which

102
00:05:13,839 --> 00:05:16,879
the mind is not a monolithic structure

103
00:05:16,879 --> 00:05:20,916
but a composition of simple actors,

104
00:05:20,916 --> 00:05:24,955
independent actors that interact with

105
00:05:24,955 --> 00:05:27,986
each other in simple ways.

106
00:05:28,994 --> 00:05:32,030
That view of the mind was put forth by

107
00:05:32,030 --> 00:05:34,057
Marvin Minsky 50 years ago.

108
00:05:34,057 --> 00:05:36,072
So this is not recent.

109
00:05:40,112 --> 00:05:43,144
Again, what I presented last year was a

110
00:05:43,144 --> 00:05:46,178
society of mind containing a hierarchy of,

111
00:05:46,178 --> 00:05:49,203
, I call them cognition actors.

112
00:05:49,205 --> 00:05:53,243
Each cognition actor is an independent

113
00:05:53,243 --> 00:05:57,284
process, each one has a scope, a level of

114
00:05:57,284 --> 00:05:59,306
abstraction as well.

115
00:05:59,306 --> 00:06:01,269
So for example, you would have a

116
00:06:01,269 --> 00:06:04,297
cognition actor that's concerned with the

117
00:06:04,297 --> 00:06:07,321
location of food and it would have

118
00:06:07,321 --> 00:06:09,345
beliefs and perceptions about food

119
00:06:09,345 --> 00:06:12,370
location and these would feed into a

120
00:06:12,370 --> 00:06:14,397
higher level cognition actor, let's say

121
00:06:14,397 --> 00:06:17,423
food approach which is concerned about

122
00:06:17,423 --> 00:06:20,450
getting closer to the food and so forth

123
00:06:20,450 --> 00:06:21,463
and so on.

124
00:06:21,463 --> 00:06:24,493
These cognition actors communicate again

125
00:06:24,493 --> 00:06:25,506
in simple ways.

126
00:06:25,506 --> 00:06:28,531
This is the society of mind and they

127
00:06:28,531 --> 00:06:30,556
communicate by emitting predictions,

128
00:06:30,556 --> 00:06:33,582
predictions about the beliefs of other

129
00:06:33,582 --> 00:06:36,609
cognition actors and they communicate by

130
00:06:36,609 --> 00:06:38,631
emitting prediction errors.

131
00:06:38,631 --> 00:06:42,670
When predictions made about their beliefs

132
00:06:42,670 --> 00:06:45,706
by others are inaccurate that leads to

133
00:06:45,706 --> 00:06:48,738
connection actors processing these

134
00:06:48,738 --> 00:06:52,777
prediction errors and combining them with

135
00:06:52,777 --> 00:06:55,809
their own predictions to create an

136
00:06:55,809 --> 00:06:59,842
updated set of perceptions that are

137
00:06:59,842 --> 00:07:02,811
synthesized into beliefs.

138
00:07:02,812 --> 00:07:05,845
And these beliefs lead to actions in

139
00:07:05,845 --> 00:07:09,881
order to eliminate negative beliefs or

140
00:07:09,881 --> 00:07:11,907
validate positive beliefs.

141
00:07:12,912 --> 00:07:15,945
Now it's from the interactions of all

142
00:07:15,945 --> 00:07:18,976
these kung fu actors that seemingly

143
00:07:18,976 --> 00:07:21,003
purposeful behaviors emerge.

144
00:07:22,011 --> 00:07:25,040
So that was successful but learning was

145
00:07:25,040 --> 00:07:26,051
very limited.

146
00:07:27,061 --> 00:07:31,101
This hierarchy of cognition actors was

147
00:07:31,101 --> 00:07:34,138
given, was predefined and the only

148
00:07:34,138 --> 00:07:38,177
learning that a robot would do was to

149
00:07:38,177 --> 00:07:43,220
discover which action policies tended to

150
00:07:43,220 --> 00:07:45,243
be more effective.

151
00:07:49,289 --> 00:07:53,325
So clearly my robots are not monolithic

152
00:07:53,325 --> 00:07:55,348
active inference agents.

153
00:07:57,365 --> 00:08:01,340
So the question is why would I use a

154
00:08:01,340 --> 00:08:03,369
society of mind architecture?

155
00:08:04,371 --> 00:08:08,415
Well, because I subscribe to the notion

156
00:08:08,415 --> 00:08:12,455
that all intelligence is collective

157
00:08:12,455 --> 00:08:14,471
intelligence.

158
00:08:15,481 --> 00:08:18,511
This paper makes the argument quite

159
00:08:18,511 --> 00:08:21,543
cogently and I'm going to cite a number

160
00:08:21,543 --> 00:08:24,574
of papers which were important to the

161
00:08:24,574 --> 00:08:26,598
evolution of my thinking.

162
00:08:26,599 --> 00:08:28,612
This is one of them.

163
00:08:30,637 --> 00:08:34,674
This paper sees intelligence as a process,

164
00:08:34,674 --> 00:08:35,688
, not a property.

165
00:08:35,689 --> 00:08:39,723
It's a process enacted by the interacting

166
00:08:39,723 --> 00:08:42,756
parts as opposed to again, a property of

167
00:08:42,756 --> 00:08:43,768
individuals.

168
00:08:44,777 --> 00:08:49,819
So society of mind is basically that it's

169
00:08:49,819 --> 00:08:52,853
actually a number of interacting

170
00:08:52,853 --> 00:08:56,895
processes that together from which emerge

171
00:08:56,895 --> 00:09:00,873
apparently intelligent behaviors.

172
00:09:00,875 --> 00:09:04,912
Now my own personal current definition of

173
00:09:04,912 --> 00:09:08,950
intelligence is self sustaining, inactive

174
00:09:08,950 --> 00:09:09,964
sense making.

175
00:09:09,965 --> 00:09:13,001
Sense making is really important by

176
00:09:13,001 --> 00:09:17,041
autonomous agent system in a dissipative

177
00:09:17,041 --> 00:09:21,081
and dynamic environment and this guides

178
00:09:21,081 --> 00:09:24,118
all the work I do in this project.

179
00:09:27,142 --> 00:09:30,173
Now, if you want a description, a

180
00:09:30,173 --> 00:09:34,211
detailed description of where my project

181
00:09:34,211 --> 00:09:37,246
stood a year ago, there's a paper that

182
00:09:37,246 --> 00:09:41,285
was published that I published on Xenodo,

183
00:09:41,285 --> 00:09:44,310
which you can look up.

184
00:09:47,343 --> 00:09:51,381
Now, over the last year, I wanted to move

185
00:09:51,381 --> 00:09:54,418
away from a pre built a given society of

186
00:09:54,418 --> 00:09:58,457
mind and toward a learned society of mind.

187
00:09:58,457 --> 00:09:59,459
.

188
00:09:59,460 --> 00:10:02,433
I wanted to see if I could program an

189
00:10:02,433 --> 00:10:05,469
autonomous robot to evolve its society of

190
00:10:05,469 --> 00:10:09,503
mind through its interactions with its

191
00:10:09,503 --> 00:10:10,516
environment.

192
00:10:11,525 --> 00:10:15,564
Now, one might think that programming

193
00:10:15,564 --> 00:10:19,605
autonomy is an oxymoron would be a good

194
00:10:19,605 --> 00:10:22,639
point, but I don't think it is.

195
00:10:24,653 --> 00:10:28,693
If if the program I write and install my

196
00:10:28,693 --> 00:10:32,729
robot imparts constitutive autonomy,

197
00:10:32,729 --> 00:10:35,769
which is enable the robot to constitute

198
00:10:35,769 --> 00:10:39,804
its own identity, and if it imparts

199
00:10:39,804 --> 00:10:43,841
adaptivity, which enable the robot to

200
00:10:43,841 --> 00:10:47,881
modify itself from its interactions with

201
00:10:47,881 --> 00:10:51,919
the environment, then I think that the

202
00:10:51,919 --> 00:10:54,957
robot will be truly autonomous.

203
00:10:55,967 --> 00:10:59,006
Now, for autonomy to exist inherently in

204
00:10:59,006 --> 00:11:03,987
the robot, something in the robot must be

205
00:11:03,987 --> 00:11:04,998
at stake.

206
00:11:04,999 --> 00:11:08,034
And in this case, it's the survival of

207
00:11:08,034 --> 00:11:10,059
the robot society of mind.

208
00:11:11,060 --> 00:11:15,108
Now, the physical structure of the robot

209
00:11:15,108 --> 00:11:17,128
is not at stake.

210
00:11:17,129 --> 00:11:20,152
Its survival is not at stake, unless, of

211
00:11:20,152 --> 00:11:22,170
course, it falls off a shelf.

212
00:11:22,171 --> 00:11:25,207
But as I intend to have my robot develop

213
00:11:25,207 --> 00:11:29,242
its society of mind from experiences, I

214
00:11:29,242 --> 00:11:32,277
also expect that if it fails, that this

215
00:11:32,277 --> 00:11:35,308
society of mine will perish in its

216
00:11:35,308 --> 00:11:39,343
attempt to grow and sustain itself.

217
00:11:40,350 --> 00:11:44,390
So that's what's at stake going forward

218
00:11:44,390 --> 00:11:47,428
in this project is the survival of the

219
00:11:47,428 --> 00:11:50,453
robot society of mind.

220
00:11:51,462 --> 00:11:54,493
This survival would be an expression of

221
00:11:54,493 --> 00:11:55,499
being.

222
00:11:55,500 --> 00:11:58,535
By doing, the robot will need to act and

223
00:11:58,535 --> 00:12:02,511
interact in its environment in order to

224
00:12:02,511 --> 00:12:03,520
survive.

225
00:12:03,523 --> 00:12:06,551
Now, whatever sense it's going to make of

226
00:12:06,551 --> 00:12:08,577
its environment will then be grounded in

227
00:12:08,577 --> 00:12:10,596
this survival imperative.

228
00:12:10,599 --> 00:12:13,627
In essence, the robot society of mine

229
00:12:13,627 --> 00:12:15,649
will have skin in the game.

230
00:12:16,655 --> 00:12:18,675
If this weren't the case, then sense

231
00:12:18,675 --> 00:12:20,697
making would actually reside somewhere

232
00:12:20,697 --> 00:12:21,701
else.

233
00:12:21,701 --> 00:12:23,726
It would reside in in the mind of the

234
00:12:23,726 --> 00:12:26,752
programmer, in my mind as I observe the

235
00:12:26,752 --> 00:12:26,758
robots.

236
00:12:26,758 --> 00:12:29,787
But I would like the sense making to be

237
00:12:29,787 --> 00:12:32,816
grounded in the survival of the robot's

238
00:12:32,816 --> 00:12:33,826
mind itself.

239
00:12:34,837 --> 00:12:36,849
So that's key.

240
00:12:37,864 --> 00:12:40,899
Now, what do I mean by an evolving and

241
00:12:40,899 --> 00:12:43,922
growing society of mind?

242
00:12:43,923 --> 00:12:47,962
So instead of the given society of mind,

243
00:12:47,962 --> 00:12:50,996
which I showed earlier, I want the

244
00:12:50,996 --> 00:12:54,036
cognition actors to be created to connect

245
00:12:54,036 --> 00:12:58,071
with each other dynamically through

246
00:12:58,071 --> 00:13:01,049
interactions with the environment.

247
00:13:03,060 --> 00:13:06,094
So I want an active, self organizing,

248
00:13:06,094 --> 00:13:09,129
self optimizing collective of cognition

249
00:13:09,129 --> 00:13:10,137
actors.

250
00:13:10,138 --> 00:13:12,150
Now, is this feasible?

251
00:13:12,151 --> 00:13:13,164
Well, that's a big question.

252
00:13:15,188 --> 00:13:18,219
In trying to answer this question, I'll

253
00:13:18,219 --> 00:13:21,249
be also answering questions like what

254
00:13:21,249 --> 00:13:24,279
must be given a priori and what can be

255
00:13:24,279 --> 00:13:26,290
discovered?

256
00:13:26,291 --> 00:13:28,313
Well, I already have elements of an

257
00:13:28,313 --> 00:13:28,318
answer.

258
00:13:28,319 --> 00:13:33,366
I know that the sensors and the effectors

259
00:13:33,366 --> 00:13:38,410
and the primitive cognition actors that

260
00:13:38,410 --> 00:13:41,439
wrap them will be given.

261
00:13:41,440 --> 00:13:43,461
This will be like what you're born with,

262
00:13:43,461 --> 00:13:43,466
basically.

263
00:13:43,468 --> 00:13:47,506
And there might be a metacognition actor

264
00:13:47,506 --> 00:13:51,543
which role will be to oversee and guide

265
00:13:51,543 --> 00:13:54,578
the evolution of all other cognition

266
00:13:54,578 --> 00:13:55,587
actors.

267
00:13:55,588 --> 00:13:58,611
But that's my hypothesis.

268
00:14:00,575 --> 00:14:03,607
I can imagine a test environment for my

269
00:14:03,607 --> 00:14:06,635
robot that will test its ability to

270
00:14:06,635 --> 00:14:07,643
survive.

271
00:14:07,644 --> 00:14:11,684
I can imagine, for example, that as the

272
00:14:11,684 --> 00:14:15,725
robot moves around or computes, it uses a

273
00:14:15,725 --> 00:14:19,768
limited store of energy it's stimulated.

274
00:14:20,771 --> 00:14:23,803
And that store of energy is replenished

275
00:14:23,803 --> 00:14:25,828
when the robot consumes food.

276
00:14:25,829 --> 00:14:28,856
And that would be by being on top of

277
00:14:28,856 --> 00:14:31,886
pieces of paper, colored pieces of paper

278
00:14:31,886 --> 00:14:32,897
on the floor.

279
00:14:34,909 --> 00:14:35,929
And I'm going to make sure that it needs

280
00:14:35,929 --> 00:14:37,948
two sources of food in order to survive.

281
00:14:38,949 --> 00:14:39,967
That would be represented by a yellow

282
00:14:39,967 --> 00:14:41,985
paper and a green paper, for example.

283
00:14:41,986 --> 00:14:44,013
So that to prevent the robot from just

284
00:14:44,013 --> 00:14:46,039
simply finding one source of food and

285
00:14:46,039 --> 00:14:49,062
just stationing itself over it.

286
00:14:49,063 --> 00:14:51,089
So the environment will also contain

287
00:14:51,089 --> 00:14:52,096
obstacles.

288
00:14:52,097 --> 00:14:55,127
So the robot will need to learn how to

289
00:14:55,127 --> 00:14:58,153
navigate, avoid obstacles, locate

290
00:14:58,153 --> 00:15:01,124
different sources of food, get to them,

291
00:15:01,124 --> 00:15:04,155
and make sure that it alternate between

292
00:15:04,155 --> 00:15:07,182
various sources of food in order to

293
00:15:07,182 --> 00:15:08,192
survive.

294
00:15:08,193 --> 00:15:12,236
And the society of mind that will evolve,

295
00:15:12,236 --> 00:15:16,277
will hopefully evolve to successfully do

296
00:15:16,277 --> 00:15:17,285
this.

297
00:15:17,288 --> 00:15:22,330
Else if it doesn't, then it will shrink

298
00:15:22,330 --> 00:15:26,372
as resources disappear and essentially

299
00:15:26,372 --> 00:15:26,378
die.

300
00:15:27,380 --> 00:15:30,417
So that's what it's at stake for this

301
00:15:30,417 --> 00:15:31,424
robot.

302
00:15:33,445 --> 00:15:36,478
Now, this effort employs a number of

303
00:15:36,478 --> 00:15:40,513
frameworks, and by framework, I mean a

304
00:15:40,513 --> 00:15:43,549
useful system of concept and constraints

305
00:15:43,549 --> 00:15:46,579
that guide the implementation.

306
00:15:47,585 --> 00:15:50,611
Well, there's obviously the free energy

307
00:15:50,611 --> 00:15:52,633
principle and the Active inference

308
00:15:52,633 --> 00:15:53,641
framework.

309
00:15:55,667 --> 00:15:59,701
However, I see this, the Acactive

310
00:15:59,701 --> 00:16:02,677
Inference, as an as if framework.

311
00:16:02,678 --> 00:16:06,713
It describes the what what must be

312
00:16:06,713 --> 00:16:10,752
achieved in this case, reduction of the

313
00:16:10,752 --> 00:16:13,787
agents, variational, free energy.

314
00:16:13,788 --> 00:16:16,813
But it doesn't guide me as to the

315
00:16:16,813 --> 00:16:19,843
implementation, how to build the robot.

316
00:16:19,844 --> 00:16:23,881
For this, I need as is frameworks.

317
00:16:23,883 --> 00:16:26,914
And I'll be using two frameworks, one

318
00:16:26,914 --> 00:16:29,948
which I've been using since the beginning

319
00:16:29,948 --> 00:16:33,983
of the project, which is the Actor model.

320
00:16:33,983 --> 00:16:33,984
.

321
00:16:34,991 --> 00:16:37,023
The Actor model views computation as a

322
00:16:37,023 --> 00:16:40,055
diversity of processes, processes that

323
00:16:40,055 --> 00:16:43,087
are independent, have their own private

324
00:16:43,087 --> 00:16:47,121
internal state, and who communicate with

325
00:16:47,121 --> 00:16:50,156
one another strictly through messages.

326
00:16:51,168 --> 00:16:54,198
Yesterday in Enterprise One, Keith Duggar

327
00:16:54,198 --> 00:16:57,228
presented on the Actor model and made the

328
00:16:57,228 --> 00:17:00,198
case that we should use the actor model

329
00:17:00,198 --> 00:17:03,227
to implement active inference agents.

330
00:17:03,229 --> 00:17:06,253
Well, I wholeheartedly agree with them.

331
00:17:06,257 --> 00:17:09,289
The other framework that I'm going to be

332
00:17:09,289 --> 00:17:13,320
using is a special case of symbolic AI

333
00:17:13,320 --> 00:17:15,348
called the App Perception Engine.

334
00:17:15,349 --> 00:17:18,375
And much of the presentation will be

335
00:17:18,375 --> 00:17:21,403
about the App Perception Engine and its

336
00:17:21,403 --> 00:17:22,415
implementation.

337
00:17:24,438 --> 00:17:28,474
So here's where we are is the project is

338
00:17:28,474 --> 00:17:31,507
located at the intersection of Active

339
00:17:31,507 --> 00:17:34,538
Inference as a domain, the Wet and

340
00:17:34,538 --> 00:17:38,573
Society of Mind as an architecture, and

341
00:17:38,573 --> 00:17:41,608
symbolic AI as a form of computing.

342
00:17:42,614 --> 00:17:45,642
So that's where the project is, at this

343
00:17:45,642 --> 00:17:46,652
intersection.

344
00:17:49,679 --> 00:17:50,691
So where to begin?

345
00:17:50,692 --> 00:17:55,744
So I want to dive into a more extensive

346
00:17:55,744 --> 00:17:57,768
form of learning.

347
00:17:58,769 --> 00:18:01,745
And the first step, logically, is to

348
00:18:01,745 --> 00:18:03,766
learn how to predict.

349
00:18:03,768 --> 00:18:10,835
So I want to enable a single cognition

350
00:18:10,835 --> 00:18:11,847
actor.

351
00:18:11,848 --> 00:18:14,876
We'll start with a single cognition actor

352
00:18:14,876 --> 00:18:17,903
to learn how to make sense of its local

353
00:18:17,903 --> 00:18:19,927
environment, its so called unvelt.

354
00:18:19,929 --> 00:18:24,975
And making sense implies, at a minimum,

355
00:18:24,975 --> 00:18:29,002
to be able to predict incoming sensations.

356
00:18:29,002 --> 00:18:29,002
.

357
00:18:29,002 --> 00:18:32,005
So it needs to learn to predict.

358
00:18:36,009 --> 00:18:40,013
So what will be given to a cognition

359
00:18:40,013 --> 00:18:40,013
actor?

360
00:18:40,013 --> 00:18:45,018
Well, there will be a history of

361
00:18:45,018 --> 00:18:50,023
sensations broken into discrete units of

362
00:18:50,023 --> 00:18:51,024
time.

363
00:18:51,024 --> 00:18:54,027
So time n minus three and N minus two, n

364
00:18:54,027 --> 00:18:57,030
minus one time n, which is the present

365
00:18:57,030 --> 00:18:58,031
moment.

366
00:19:00,027 --> 00:19:03,030
So these would be remembered observations.

367
00:19:03,030 --> 00:19:03,030
.

368
00:19:04,031 --> 00:19:07,034
And then what we want to get out of this

369
00:19:07,034 --> 00:19:10,037
is the ability to predict the next

370
00:19:10,037 --> 00:19:14,041
incoming set of sensations at time t

371
00:19:14,041 --> 00:19:17,044
equals n plus one, n plus two.

372
00:19:17,044 --> 00:19:20,047
And for this, to be able to predict

373
00:19:20,047 --> 00:19:23,050
future observations, we need some kind of

374
00:19:23,050 --> 00:19:26,053
predictor function that is learned from

375
00:19:26,053 --> 00:19:29,056
the remembered observation.

376
00:19:30,057 --> 00:19:33,060
Now, this predictive capability can be

377
00:19:33,060 --> 00:19:35,062
built in two very general ways.

378
00:19:35,062 --> 00:19:38,065
One is from statistics, so doing pattern

379
00:19:38,065 --> 00:19:42,069
analysis and being able to predict what's

380
00:19:42,069 --> 00:19:45,072
most probable, which is the standard

381
00:19:45,072 --> 00:19:48,075
current machine learning approach.

382
00:19:48,075 --> 00:19:53,080
Or we could predict from an understanding

383
00:19:53,080 --> 00:19:57,084
of the observations by developing a

384
00:19:57,084 --> 00:20:01,082
causal model of what produced these

385
00:20:01,082 --> 00:20:06,087
sensations, and from this understanding,

386
00:20:06,087 --> 00:20:09,090
predict what rationally should be

387
00:20:09,090 --> 00:20:12,093
observed next.

388
00:20:16,097 --> 00:20:19,100
So this is all about sense making.

389
00:20:19,100 --> 00:20:23,104
And now what is sense making?

390
00:20:23,104 --> 00:20:25,105
How do I understand sense making?

391
00:20:27,108 --> 00:20:29,110
Well, to rationally predict incoming

392
00:20:29,110 --> 00:20:32,113
sensory inputs, one must make sense of

393
00:20:32,113 --> 00:20:32,113
them.

394
00:20:32,113 --> 00:20:34,115
That's what making sense means to me.

395
00:20:35,116 --> 00:20:38,119
And to make sense of sensory inputs means

396
00:20:38,119 --> 00:20:41,122
to derive meaningful experiences from

397
00:20:41,122 --> 00:20:42,123
them.

398
00:20:42,123 --> 00:20:45,126
It's not just data, it's not just pieces

399
00:20:45,126 --> 00:20:46,127
of data.

400
00:20:46,127 --> 00:20:48,129
There must be meaningful experiences.

401
00:20:48,129 --> 00:20:51,132
And by experience, I mean a

402
00:20:51,132 --> 00:20:55,136
conceptualization of the sensations and a

403
00:20:55,136 --> 00:20:58,139
unification of them in time and space.

404
00:20:58,139 --> 00:21:02,137
So making sense of these inputs will mean

405
00:21:02,137 --> 00:21:05,140
to produce meaningful experiences that

406
00:21:05,140 --> 00:21:08,143
are conceptualizations and unifications

407
00:21:08,143 --> 00:21:10,145
of the sensations.

408
00:21:10,145 --> 00:21:13,148
Now, an experience is meaningful if it is

409
00:21:13,148 --> 00:21:16,151
underwritten by a causal model.

410
00:21:17,152 --> 00:21:21,156
So the experience is perceived as the

411
00:21:21,156 --> 00:21:25,160
consequences of a latent generative model,

412
00:21:25,160 --> 00:21:30,165
, generative process that we have modeled.

413
00:21:30,165 --> 00:21:30,165
.

414
00:21:31,166 --> 00:21:33,168
And I want meaning to be inherent to the

415
00:21:33,168 --> 00:21:34,169
agent.

416
00:21:34,169 --> 00:21:36,171
And that only happens if the agent is

417
00:21:36,171 --> 00:21:39,174
truly autonomous and if this meaning is

418
00:21:39,174 --> 00:21:42,177
grounded in the survival imperative, as

419
00:21:42,177 --> 00:21:43,178
discussed earlier.

420
00:21:46,181 --> 00:21:48,183
So how does experiencing work?

421
00:21:48,183 --> 00:21:51,186
How can that be put into computer code?

422
00:21:52,187 --> 00:21:54,189
Surprisingly for this, we refer to the

423
00:21:54,189 --> 00:21:57,192
philosophy of Emmanuel Kant.

424
00:21:57,192 --> 00:22:00,189
Emmanuel Kant took a reverse engineering

425
00:22:00,189 --> 00:22:03,192
approach, asking himself what must

426
00:22:03,192 --> 00:22:06,195
entities do to achieve experience?

427
00:22:07,196 --> 00:22:10,199
This is akin to the free energy

428
00:22:10,199 --> 00:22:12,201
principles high Road, which can be

429
00:22:12,201 --> 00:22:15,204
paraphrased as what must organisms do to

430
00:22:15,204 --> 00:22:17,206
maintain their existence?

431
00:22:17,206 --> 00:22:21,210
So Emmanuel Kong tried to reverse

432
00:22:21,210 --> 00:22:26,215
engineer cognition, asking himself what's

433
00:22:26,215 --> 00:22:31,220
the minimal cognitive apparatus needed by

434
00:22:31,220 --> 00:22:35,224
an entity to have experiences?

435
00:22:35,224 --> 00:22:40,229
And that he documented in his critique of

436
00:22:40,229 --> 00:22:41,230
pure reason.

437
00:22:41,230 --> 00:22:44,233
Just a little parenthesis.

438
00:22:45,234 --> 00:22:48,237
The meaning of the title Critique of Pure

439
00:22:48,237 --> 00:22:50,239
Reason is not what I thought it was.

440
00:22:51,240 --> 00:22:54,242
It actually translates more closely to

441
00:22:54,242 --> 00:22:55,244
the case for April.

442
00:22:55,244 --> 00:22:58,247
Cognition critique is a legal term is

443
00:22:58,247 --> 00:23:01,244
where you make your case and pure reason

444
00:23:01,244 --> 00:23:03,246
we translate nowadays.

445
00:23:03,246 --> 00:23:04,247
April cognition.

446
00:23:05,248 --> 00:23:08,251
So his work wanted to establish what must

447
00:23:08,251 --> 00:23:12,255
happen to create an experience that's

448
00:23:12,255 --> 00:23:15,258
coherent, that is unified in time and

449
00:23:15,258 --> 00:23:19,262
space, and to reverse engineer cognition

450
00:23:19,262 --> 00:23:23,266
as a system that is both complete and

451
00:23:23,266 --> 00:23:26,269
essential, that is minimal.

452
00:23:31,274 --> 00:23:35,278
Okay, so I'm going to try to give you the

453
00:23:35,278 --> 00:23:40,283
postage stamp version of Emmanuel Kant's

454
00:23:40,283 --> 00:23:45,288
theory focusing on the Synthetic Unity of

455
00:23:45,288 --> 00:23:47,290
Apperception.

456
00:23:47,290 --> 00:23:49,292
Well, first of all, there's the real

457
00:23:49,292 --> 00:23:51,294
world, which is outside of our direct

458
00:23:51,294 --> 00:23:52,294
experience.

459
00:23:52,295 --> 00:23:53,296
It's the pneumonia.

460
00:23:53,296 --> 00:23:59,302
It's forever hidden from us as an as is

461
00:23:59,302 --> 00:24:05,302
reality, but it impinges on our sensorium.

462
00:24:05,302 --> 00:24:06,303
.

463
00:24:06,303 --> 00:24:09,305
And then so we have a number of

464
00:24:09,305 --> 00:24:12,309
intuitions, sight, sound, touch, smell

465
00:24:12,309 --> 00:24:16,313
that are initially separate, and then we

466
00:24:16,313 --> 00:24:20,317
need to network them, connect them both

467
00:24:20,317 --> 00:24:22,319
in time and in space.

468
00:24:23,320 --> 00:24:28,325
In space is sound.

469
00:24:29,326 --> 00:24:34,331
And the sight describing a single thing

470
00:24:34,331 --> 00:24:39,336
is one thing behind or inside another.

471
00:24:41,338 --> 00:24:44,341
And in time, is this happening before,

472
00:24:44,341 --> 00:24:46,343
after something else?

473
00:24:47,344 --> 00:24:50,347
And then at a higher level, meaning is

474
00:24:50,347 --> 00:24:54,351
given to these networked, intuitions,

475
00:24:54,351 --> 00:24:58,355
sensations via concepts and judgments,

476
00:24:58,355 --> 00:25:01,352
rules which are generalizations as to

477
00:25:01,352 --> 00:25:04,355
what can and cannot be.

478
00:25:05,356 --> 00:25:08,359
And this is what we experience.

479
00:25:12,363 --> 00:25:16,367
Now, it turns out that synthetic Unity of

480
00:25:16,367 --> 00:25:20,371
Apperception is a blueprint for

481
00:25:20,371 --> 00:25:22,373
automating sense making.

482
00:25:25,376 --> 00:25:28,379
It's kind of interesting, I think, that

483
00:25:28,379 --> 00:25:31,382
18th century philosophy would be relevant

484
00:25:31,382 --> 00:25:34,385
to 21st century technology development.

485
00:25:35,386 --> 00:25:38,389
And this is what happened and was

486
00:25:38,389 --> 00:25:41,392
published by Richard Evans and all in the

487
00:25:41,392 --> 00:25:44,395
paper Making Sense of Sensory Input,

488
00:25:44,395 --> 00:25:48,399
where they developed the App Perception

489
00:25:48,399 --> 00:25:49,400
Engine.

490
00:25:49,400 --> 00:25:53,404
They took synthetic Unity of Apperception

491
00:25:53,404 --> 00:25:57,408
as software requirements and successfully

492
00:25:57,408 --> 00:26:01,406
implemented them into a piece of software,

493
00:26:01,406 --> 00:26:04,409
, the App Perception Engine, and applied

494
00:26:04,409 --> 00:26:08,413
it to a number of exercises where they

495
00:26:08,413 --> 00:26:10,415
got a very good result.

496
00:26:10,415 --> 00:26:13,418
So the App Session Engine is in an

497
00:26:13,418 --> 00:26:15,420
instance of machine learning.

498
00:26:15,420 --> 00:26:19,424
It's unsupervised machine learning, and

499
00:26:19,424 --> 00:26:22,427
it operates on very small data sets and

500
00:26:22,427 --> 00:26:25,430
generates human readable generative

501
00:26:25,430 --> 00:26:26,431
models.

502
00:26:27,432 --> 00:26:30,435
When I read the paper, I realized, well,

503
00:26:30,435 --> 00:26:32,437
that's exactly what my robot needed.

504
00:26:34,439 --> 00:26:37,442
So what does an app perception engine

505
00:26:37,442 --> 00:26:37,442
do?

506
00:26:38,442 --> 00:26:43,448
Well, given a sequence of observed states,

507
00:26:43,448 --> 00:26:47,452
, it finds a generative model that can

508
00:26:47,452 --> 00:26:52,457
recreate past states but most importantly,

509
00:26:52,457 --> 00:26:55,460
, predict future states.

510
00:26:55,460 --> 00:26:59,464
And the state is defined as a set of

511
00:26:59,464 --> 00:27:02,461
simultaneous observations, sensations,

512
00:27:02,461 --> 00:27:04,463
intuitions.

513
00:27:07,466 --> 00:27:11,470
So an apperception engine searches for a

514
00:27:11,470 --> 00:27:14,473
causal theory that can recreate

515
00:27:14,473 --> 00:27:16,475
observations.

516
00:27:16,475 --> 00:27:19,478
I say searches because this causal theory

517
00:27:19,478 --> 00:27:22,481
is not determined by the observations.

518
00:27:23,482 --> 00:27:24,483
It has to be found.

519
00:27:24,483 --> 00:27:25,484
It has to be discovered.

520
00:27:26,485 --> 00:27:30,489
But once it is found, then it can be

521
00:27:30,489 --> 00:27:34,493
validated against the observations and

522
00:27:34,493 --> 00:27:38,497
see if it can recreate them and augment

523
00:27:38,497 --> 00:27:43,502
them into the future as well as into the

524
00:27:43,502 --> 00:27:44,503
past.

525
00:27:47,506 --> 00:27:49,508
So what is a causal theory?

526
00:27:50,509 --> 00:27:54,513
A causal theory is a logic program that

527
00:27:54,513 --> 00:27:56,515
has a number of components.

528
00:27:59,518 --> 00:28:02,515
In the causal theory, there will be the

529
00:28:02,515 --> 00:28:05,518
objects and the predicates from the

530
00:28:05,518 --> 00:28:06,519
observed relations.

531
00:28:06,519 --> 00:28:09,522
So from the observations, we can extract

532
00:28:09,522 --> 00:28:11,524
what objects were observed and what

533
00:28:11,524 --> 00:28:13,526
properties of these objects were observed

534
00:28:13,526 --> 00:28:15,528
and maybe what relationships these

535
00:28:15,528 --> 00:28:17,530
objects were observed.

536
00:28:17,530 --> 00:28:18,531
That's the start.

537
00:28:18,531 --> 00:28:21,534
Then we have latent object types, objects

538
00:28:21,534 --> 00:28:22,535
and predicates.

539
00:28:23,535 --> 00:28:26,539
So we may want to imagine causal theory,

540
00:28:26,539 --> 00:28:29,542
imagines hidden objects, maybe hidden

541
00:28:29,542 --> 00:28:31,544
types of objects and maybe hidden

542
00:28:31,544 --> 00:28:34,547
properties and relationships between

543
00:28:34,547 --> 00:28:37,550
objects, latent meaning unobserved.

544
00:28:38,550 --> 00:28:41,554
And given both the observed and

545
00:28:41,554 --> 00:28:45,558
unobserved objects and predicates, it

546
00:28:45,558 --> 00:28:49,562
derives rules, first of all constraints

547
00:28:49,562 --> 00:28:53,566
on those predicates, what's permissible.

548
00:28:53,566 --> 00:28:57,570
So for example, being in front of A

549
00:28:57,570 --> 00:29:01,568
cannot be in front of B and at the same

550
00:29:01,568 --> 00:29:03,570
time behind B.

551
00:29:03,570 --> 00:29:06,573
So an object cannot be in front of

552
00:29:06,573 --> 00:29:07,574
another and behind it.

553
00:29:07,574 --> 00:29:10,577
So there are constraints on predicates

554
00:29:10,577 --> 00:29:13,580
and then there are rules that apply to

555
00:29:13,580 --> 00:29:16,583
any simultaneous sets of observations,

556
00:29:16,583 --> 00:29:19,586
what they must conform to.

557
00:29:19,586 --> 00:29:22,589
Then there are rules that given a state,

558
00:29:22,589 --> 00:29:26,593
will infer the next state and then maybe

559
00:29:26,593 --> 00:29:29,596
some initial state from which we can run

560
00:29:29,596 --> 00:29:31,598
the causal theory.

561
00:29:33,599 --> 00:29:36,603
So what makes a causal theory unified?

562
00:29:37,604 --> 00:29:39,606
Well, first of all it needs to be unified

563
00:29:39,606 --> 00:29:40,607
in order to make sense of the observation.

564
00:29:40,607 --> 00:29:41,607
.

565
00:29:41,608 --> 00:29:43,610
There are various dimensions.

566
00:29:43,610 --> 00:29:45,612
So if a causal theory involves a number

567
00:29:45,612 --> 00:29:47,614
of objects, all these objects must be

568
00:29:47,614 --> 00:29:49,616
directly or indirectly related.

569
00:29:49,616 --> 00:29:51,618
There's no object that just floats in

570
00:29:51,618 --> 00:29:53,620
space totally independent of the other

571
00:29:53,620 --> 00:29:56,623
objects, so they must all be related.

572
00:29:56,623 --> 00:29:59,626
So they're spatially unified.

573
00:29:59,626 --> 00:30:03,624
All predicates that make up the causal

574
00:30:03,624 --> 00:30:06,627
theory, like on, off, behind, in front,

575
00:30:06,627 --> 00:30:10,631
they must be constrained so that, for

576
00:30:10,631 --> 00:30:13,634
example, in front cannot be at the same

577
00:30:13,634 --> 00:30:17,638
time as behind or that a light cannot be

578
00:30:17,638 --> 00:30:20,641
both turned on and turned off.

579
00:30:20,641 --> 00:30:24,645
So there's some restrictions on the

580
00:30:24,645 --> 00:30:27,648
predicates and that creates conceptual

581
00:30:27,648 --> 00:30:28,649
unity.

582
00:30:28,649 --> 00:30:31,652
And then there's static unity where all

583
00:30:31,652 --> 00:30:33,654
simultaneous relations must satisfy the

584
00:30:33,654 --> 00:30:36,657
static rules, and temporal unity, where

585
00:30:36,657 --> 00:30:38,659
all the states must be sequenced by

586
00:30:38,659 --> 00:30:39,660
causal rules.

587
00:30:40,661 --> 00:30:41,662
We'll see examples.

588
00:30:43,664 --> 00:30:49,670
So let's start with an example here of a

589
00:30:49,670 --> 00:30:52,673
set of observations.

590
00:30:52,673 --> 00:30:55,676
What we are observing are two lights and

591
00:30:55,676 --> 00:30:59,680
the lights can either be at any discrete

592
00:30:59,680 --> 00:31:02,677
moment in time, either on or off.

593
00:31:02,677 --> 00:31:06,681
So here we have a sequence of

594
00:31:06,681 --> 00:31:11,686
observations and one moment in time.

595
00:31:11,686 --> 00:31:13,688
The first light was off and the second

596
00:31:13,688 --> 00:31:14,689
light was on.

597
00:31:15,690 --> 00:31:19,694
Then the first light was on, the second

598
00:31:19,694 --> 00:31:23,698
light was off, then both were on, et

599
00:31:23,698 --> 00:31:24,699
cetera.

600
00:31:25,700 --> 00:31:28,703
And I put the gray bars there to show

601
00:31:28,703 --> 00:31:30,705
that maybe the observations are

602
00:31:30,705 --> 00:31:31,706
incomplete.

603
00:31:31,706 --> 00:31:33,708
So at one stage we can only see the

604
00:31:33,708 --> 00:31:36,711
second light or there may be other lights

605
00:31:36,711 --> 00:31:38,713
or other objects that we do not see, but

606
00:31:38,713 --> 00:31:39,714
that's what we observe.

607
00:31:42,717 --> 00:31:46,721
So you feed these observations in

608
00:31:46,721 --> 00:31:50,725
discrete time into the apperception

609
00:31:50,725 --> 00:31:54,729
engine and the perception engine searches

610
00:31:54,729 --> 00:31:59,734
for a causal theory that when applied to

611
00:31:59,734 --> 00:32:03,732
an initial condition, let's say that

612
00:32:03,732 --> 00:32:07,736
light A is off and light B is on.

613
00:32:07,736 --> 00:32:10,739
It will create a trace of recreated

614
00:32:10,739 --> 00:32:12,741
observations.

615
00:32:12,741 --> 00:32:17,746
That cover is a superset, matches the

616
00:32:17,746 --> 00:32:20,749
initial observations.

617
00:32:20,749 --> 00:32:23,752
And if this happens, then our causal

618
00:32:23,752 --> 00:32:25,754
theory is a good one.

619
00:32:25,754 --> 00:32:28,757
Now, the causal theory may infer the

620
00:32:28,757 --> 00:32:31,760
existence of hidden objects, hidden

621
00:32:31,760 --> 00:32:35,764
relations, and whatnot it may actually

622
00:32:35,764 --> 00:32:36,765
need to.

623
00:32:38,767 --> 00:32:41,770
So here's an example of a causal theory

624
00:32:41,770 --> 00:32:43,772
that is generated by my own

625
00:32:43,772 --> 00:32:46,775
implementation of the App perception

626
00:32:46,775 --> 00:32:46,775
engine.

627
00:32:46,775 --> 00:32:49,778
Because I re implemented the App

628
00:32:49,778 --> 00:32:53,782
perception engine as described in the

629
00:32:53,782 --> 00:32:57,786
paper by Richard Evans and all, and I ran

630
00:32:57,786 --> 00:33:00,783
it on the set of observations about

631
00:33:00,783 --> 00:33:04,787
lights on two lights, one on, one off at

632
00:33:04,787 --> 00:33:06,789
any point in time.

633
00:33:07,790 --> 00:33:09,792
And it came up with it found a result.

634
00:33:10,793 --> 00:33:13,796
It found the result in 64 seconds.

635
00:33:13,796 --> 00:33:14,797
It was a perfect match.

636
00:33:15,798 --> 00:33:19,802
And it actually invented a relationship,

637
00:33:19,802 --> 00:33:23,806
which it called thread One, which we can

638
00:33:23,806 --> 00:33:26,809
let's imagine that it actually means

639
00:33:26,809 --> 00:33:28,811
connects to.

640
00:33:29,812 --> 00:33:32,815
And it found a static rule and a causal

641
00:33:32,815 --> 00:33:32,815
rule.

642
00:33:33,816 --> 00:33:37,820
It said that a light is on at any moment

643
00:33:37,820 --> 00:33:37,820
in time.

644
00:33:37,820 --> 00:33:41,824
A light is on if a light that connects to

645
00:33:41,824 --> 00:33:42,825
it is off.

646
00:33:42,825 --> 00:33:47,830
And it found a causal rule that said a

647
00:33:47,830 --> 00:33:52,835
light turns off if it connects to another

648
00:33:52,835 --> 00:33:55,838
light that was also off.

649
00:33:55,838 --> 00:33:59,842
So that's how the lights change over time,

650
00:33:59,842 --> 00:34:01,838
, the status of on and off.

651
00:34:01,838 --> 00:34:03,840
And it came up with initial conditions

652
00:34:03,840 --> 00:34:06,843
that said that, well, A connects to,

653
00:34:06,843 --> 00:34:09,846
first of all, that there's an object one,

654
00:34:09,846 --> 00:34:11,848
a light called object one that we don't

655
00:34:11,848 --> 00:34:14,851
see, but is there, we imagine is there,

656
00:34:14,851 --> 00:34:16,853
that A connects to it.

657
00:34:16,853 --> 00:34:19,856
The light object one connects to B, and

658
00:34:19,856 --> 00:34:21,858
the light B connects to object one.

659
00:34:22,859 --> 00:34:24,861
So that's the causal rule that it

660
00:34:24,861 --> 00:34:25,862
discovered.

661
00:34:27,864 --> 00:34:30,867
Now, if we run this causal rule, we

662
00:34:30,867 --> 00:34:32,869
produce a trace.

663
00:34:33,870 --> 00:34:36,873
And as you can see, the trace matches the

664
00:34:36,873 --> 00:34:36,873
observation.

665
00:34:37,874 --> 00:34:39,876
It adds a new object.

666
00:34:39,876 --> 00:34:42,879
So the coverage being excellent, being

667
00:34:42,879 --> 00:34:45,882
perfect in this case, and our causal

668
00:34:45,882 --> 00:34:46,883
theory is a good one.

669
00:34:46,883 --> 00:34:48,885
It's actually a perfect one.

670
00:34:49,886 --> 00:34:51,888
It's not necessarily the only one, though.

671
00:34:51,888 --> 00:34:51,888
.

672
00:34:54,891 --> 00:34:57,894
So is this causal theory unified?

673
00:34:57,894 --> 00:35:00,891
So going back to Dr.

674
00:35:00,891 --> 00:35:03,894
Kant's requirement of synthetic unity, of

675
00:35:03,894 --> 00:35:06,897
Apperception, not every causal theory

676
00:35:06,897 --> 00:35:10,901
will do, though it may predict correctly,

677
00:35:10,901 --> 00:35:13,904
it may not be meaningful unless it is

678
00:35:13,904 --> 00:35:14,905
unified.

679
00:35:17,908 --> 00:35:20,911
Well, we saw the four dimensions of

680
00:35:20,911 --> 00:35:21,912
unification.

681
00:35:21,912 --> 00:35:24,915
Is it spatially unified?

682
00:35:24,915 --> 00:35:27,918
Well, all our objects are connected

683
00:35:27,918 --> 00:35:31,922
directly or indirectly to each other.

684
00:35:32,923 --> 00:35:33,924
That's good.

685
00:35:34,925 --> 00:35:36,927
So we have spatial unification.

686
00:35:37,928 --> 00:35:39,930
Do we have conceptual unification?

687
00:35:39,930 --> 00:35:41,932
So we have this new predicate.

688
00:35:41,932 --> 00:35:42,933
We have two predicates, right?

689
00:35:43,934 --> 00:35:46,937
Pred One, which we translate to, connects

690
00:35:46,937 --> 00:35:49,939
to, and then the predicate that says

691
00:35:49,939 --> 00:35:51,942
whether the light is on or off.

692
00:35:51,942 --> 00:35:55,946
Well, we have a constraint that says that

693
00:35:55,946 --> 00:35:58,949
a light can only be connected to one

694
00:35:58,949 --> 00:35:59,950
other light.

695
00:35:59,950 --> 00:36:06,951
So pred one has a constraint on it that

696
00:36:06,951 --> 00:36:09,954
says it's exclusive.

697
00:36:10,954 --> 00:36:12,957
So an object cannot pred one to two

698
00:36:12,957 --> 00:36:15,960
objects cannot connect to two objects.

699
00:36:15,960 --> 00:36:17,962
That's a constraint that was discovered

700
00:36:17,962 --> 00:36:19,964
and part of the causal theory.

701
00:36:19,964 --> 00:36:23,968
And also implicitly, the on relation of

702
00:36:23,968 --> 00:36:27,972
the predicate has the value on or off,

703
00:36:27,972 --> 00:36:32,977
and it cannot be both at the same time.

704
00:36:32,977 --> 00:36:35,980
So it's conceptually unified.

705
00:36:35,980 --> 00:36:37,982
Is it statically unified?

706
00:36:38,982 --> 00:36:41,986
Are the static rules obeyed.

707
00:36:41,986 --> 00:36:45,990
Well, for example, the static rule would

708
00:36:45,990 --> 00:36:49,994
say that given that B connects to A, if B

709
00:36:49,994 --> 00:36:52,997
is off, then A must be on.

710
00:36:52,997 --> 00:36:55,000
So if you look at any place where B is

711
00:36:55,000 --> 00:36:57,002
off, a is going to be on.

712
00:36:57,002 --> 00:37:00,999
And you could do that for every other

713
00:37:00,999 --> 00:37:03,002
light and relationships between lights.

714
00:37:03,002 --> 00:37:06,005
So they all obey the static rule.

715
00:37:06,005 --> 00:37:10,009
And the causal rule says, for example,

716
00:37:10,009 --> 00:37:13,012
here, that if B connects to A, then if A

717
00:37:13,012 --> 00:37:16,015
was off, then B must turn off.

718
00:37:16,015 --> 00:37:21,020
So if you look at B, let's say B was off.

719
00:37:21,020 --> 00:37:21,020
.

720
00:37:25,024 --> 00:37:32,031
Yeah, I'm sorry, if B connects to A, and

721
00:37:32,031 --> 00:37:39,038
yes, and if A was off, B must be off.

722
00:37:39,038 --> 00:37:43,042
So if A was off, B becomes off the next

723
00:37:43,042 --> 00:37:44,042
step.

724
00:37:44,043 --> 00:37:46,045
So that's correct as well.

725
00:37:47,046 --> 00:37:50,049
So statistically we are true, and

726
00:37:50,049 --> 00:37:52,051
temporarily we are true.

727
00:37:53,052 --> 00:37:55,054
We are unified.

728
00:37:55,054 --> 00:37:58,057
And of course, that we get a thumbs up

729
00:37:58,057 --> 00:37:59,058
from Dr.

730
00:37:59,058 --> 00:38:03,056
Kant, our causal theory is unified.

731
00:38:04,057 --> 00:38:07,060
Thus it makes sense of the observations

732
00:38:07,060 --> 00:38:09,062
of the sensory inputs.

733
00:38:11,064 --> 00:38:14,067
Now, it's no accident that Kant would be

734
00:38:14,067 --> 00:38:18,071
would figure in an active inference

735
00:38:18,071 --> 00:38:19,072
project.

736
00:38:19,072 --> 00:38:22,075
There is a link between active inference

737
00:38:22,075 --> 00:38:25,078
and Kant, and it runs through the

738
00:38:25,078 --> 00:38:29,082
celebrated 19th century German engineer

739
00:38:29,082 --> 00:38:30,083
Herman von Hemholz.

740
00:38:31,084 --> 00:38:33,086
He was a disciple of Kant and he

741
00:38:33,086 --> 00:38:36,089
developed the theory of visual perception

742
00:38:36,089 --> 00:38:39,092
that operationalized Kant's epistemology.

743
00:38:39,092 --> 00:38:39,092
.

744
00:38:39,092 --> 00:38:41,094
And in fact, it anticipates predictive

745
00:38:41,094 --> 00:38:42,095
processing.

746
00:38:42,095 --> 00:38:46,099
In 1995, Peter Day and Jeff Hinton

747
00:38:46,099 --> 00:38:49,102
developed the Helmholtz machine.

748
00:38:49,102 --> 00:38:51,103
Name is in his hunter.

749
00:38:52,105 --> 00:38:54,107
It is a type of artificial neural network

750
00:38:54,107 --> 00:38:56,109
that's trained to create a generative

751
00:38:56,109 --> 00:38:58,111
model from an original set of data.

752
00:38:58,111 --> 00:39:00,107
And it can account for the hidden

753
00:39:00,107 --> 00:39:01,108
structure of the data.

754
00:39:03,110 --> 00:39:05,112
So as you see, there's a link which is

755
00:39:05,112 --> 00:39:08,115
discussed and elaborated in this paper,

756
00:39:08,115 --> 00:39:11,118
which is very interesting paper.

757
00:39:12,119 --> 00:39:16,123
All right, so close parentheses.

758
00:39:16,123 --> 00:39:19,126
So we've looked at the App Perception

759
00:39:19,126 --> 00:39:21,128
engine from the perspective of philosophy.

760
00:39:21,128 --> 00:39:21,128
.

761
00:39:22,129 --> 00:39:25,131
So now let's look at it through the lens

762
00:39:25,131 --> 00:39:26,133
of machine learning.

763
00:39:29,136 --> 00:39:31,138
The observations constitute a training

764
00:39:31,138 --> 00:39:32,139
set.

765
00:39:32,139 --> 00:39:33,140
It's a very small one.

766
00:39:34,141 --> 00:39:39,146
And the Appetition engine is the learning

767
00:39:39,146 --> 00:39:40,147
algorithm.

768
00:39:40,147 --> 00:39:43,150
And what is learned, the output is a

769
00:39:43,150 --> 00:39:44,151
causal theory.

770
00:39:46,152 --> 00:39:50,157
So the learning process is unsupervised

771
00:39:50,157 --> 00:39:54,161
logical inferencing, and the output is a

772
00:39:54,161 --> 00:39:57,164
human readable logic program.

773
00:39:58,165 --> 00:40:02,163
So we see here that there's some profound

774
00:40:02,163 --> 00:40:06,167
differences with the more popular form of

775
00:40:06,167 --> 00:40:10,171
machine learning in that the training set

776
00:40:10,171 --> 00:40:14,175
is really small, that the product of the

777
00:40:14,175 --> 00:40:18,179
learning is actually a human readable

778
00:40:18,179 --> 00:40:23,184
artifact, in this case, a logic program.

779
00:40:25,186 --> 00:40:27,188
So this is the training set.

780
00:40:29,190 --> 00:40:34,195
As inputted lights led, a turned off at

781
00:40:34,195 --> 00:40:38,199
time one, b turned on at time one, a

782
00:40:38,199 --> 00:40:43,204
turned on at time two, b turned off at

783
00:40:43,204 --> 00:40:47,208
time two, et cetera, et cetera.

784
00:40:47,208 --> 00:40:53,214
So that's the training set and you feed

785
00:40:53,214 --> 00:40:57,218
this into the perception engine's

786
00:40:57,218 --> 00:41:02,217
algorithm and out comes a causal theory.

787
00:41:03,218 --> 00:41:06,221
So in a little bit more details what the

788
00:41:06,221 --> 00:41:08,223
algorithm is and does.

789
00:41:08,223 --> 00:41:11,226
First, it extracts the observed object

790
00:41:11,226 --> 00:41:14,229
extent objects, the object types and

791
00:41:14,229 --> 00:41:17,232
predicates from the observations.

792
00:41:17,232 --> 00:41:21,236
So we have on, we have object A, object B.

793
00:41:21,236 --> 00:41:21,236
.

794
00:41:21,236 --> 00:41:23,238
We have led as an object type.

795
00:41:23,238 --> 00:41:26,241
So that's all part of the observations

796
00:41:26,241 --> 00:41:28,243
and that becomes part of the extent

797
00:41:28,243 --> 00:41:29,243
vocabulary.

798
00:41:29,244 --> 00:41:32,247
Then the application engine imagines

799
00:41:32,247 --> 00:41:36,251
unobserved objects, types and predicates

800
00:41:36,251 --> 00:41:40,255
for the relationships and properties, and

801
00:41:40,255 --> 00:41:43,258
that becomes a latent vocabulary.

802
00:41:43,258 --> 00:41:46,261
So there's a step of imagination.

803
00:41:46,261 --> 00:41:50,265
Then, using the combined vocabulary, both

804
00:41:50,265 --> 00:41:55,270
the extent and latent vocabulary combined,

805
00:41:55,270 --> 00:41:59,274
, it looks for a unified causal theory, a

806
00:41:59,274 --> 00:42:03,272
set of constraints, rules and initial

807
00:42:03,272 --> 00:42:07,276
conditions that obey the constraints of

808
00:42:07,276 --> 00:42:10,279
synthetic unity of apperception.

809
00:42:12,281 --> 00:42:14,283
Once it has this causal theory and with

810
00:42:14,283 --> 00:42:16,285
initial conditions, it applies the causal

811
00:42:16,285 --> 00:42:19,288
theory to these conditions and produces a

812
00:42:19,288 --> 00:42:19,288
trace.

813
00:42:20,289 --> 00:42:23,292
It recreates observations if you want and

814
00:42:23,292 --> 00:42:26,295
augments them and extends them into the

815
00:42:26,295 --> 00:42:26,295
future.

816
00:42:27,296 --> 00:42:30,299
Now it looks at this trace and compares

817
00:42:30,299 --> 00:42:32,301
it with the initial observations for

818
00:42:32,301 --> 00:42:34,303
coverage and decides if this is a good

819
00:42:34,303 --> 00:42:35,304
causal theory or not.

820
00:42:36,305 --> 00:42:38,307
Then it also looks at the causal theory

821
00:42:38,307 --> 00:42:41,310
complexity, how many rules, how complex

822
00:42:41,310 --> 00:42:43,312
are the rules, et cetera, and measures

823
00:42:43,312 --> 00:42:44,313
for complexity.

824
00:42:44,313 --> 00:42:48,317
So if we have a choice between two causal

825
00:42:48,317 --> 00:42:52,320
theories of equivalent coverage, the App

826
00:42:52,320 --> 00:42:55,324
Perception Engine will select the least

827
00:42:55,324 --> 00:42:58,327
complex one using Occam's Razor.

828
00:42:58,327 --> 00:43:02,325
Now, if you look at this algorithm, you'

829
00:43:02,325 --> 00:43:06,329
'll see that the boxes in green are not

830
00:43:06,329 --> 00:43:07,330
deterministic.

831
00:43:07,330 --> 00:43:09,332
This is where search happens.

832
00:43:09,332 --> 00:43:11,334
We can posit different kinds of objects.

833
00:43:12,335 --> 00:43:14,337
We can find different kinds of rules.

834
00:43:14,337 --> 00:43:18,341
So this is where search happens.

835
00:43:19,342 --> 00:43:22,345
Now, app perception is implemented using

836
00:43:22,345 --> 00:43:24,347
logic inference.

837
00:43:24,347 --> 00:43:27,350
Actually, it uses three forms of logic

838
00:43:27,350 --> 00:43:28,351
inference.

839
00:43:29,351 --> 00:43:31,354
There's the one that we're more familiar

840
00:43:31,354 --> 00:43:34,357
with, which is deduction, where given

841
00:43:34,357 --> 00:43:37,360
rules and causes, we infer the effects.

842
00:43:37,360 --> 00:43:39,362
Then there's induction.

843
00:43:39,362 --> 00:43:41,364
Where given causes and effect, we look

844
00:43:41,364 --> 00:43:42,365
for the rules.

845
00:43:42,365 --> 00:43:44,367
This is what science does, right?

846
00:43:44,367 --> 00:43:47,370
Looking for rules that would account for

847
00:43:47,370 --> 00:43:49,372
effects given the causes.

848
00:43:49,372 --> 00:43:51,374
Then there's abduction, where given the

849
00:43:51,374 --> 00:43:53,376
rules and given what we observe the

850
00:43:53,376 --> 00:43:56,379
effects, we're looking for the causes.

851
00:43:56,379 --> 00:43:58,381
In this case, we're looking for the

852
00:43:58,381 --> 00:44:00,377
latent objects, the latent relationships

853
00:44:00,377 --> 00:44:02,379
between these objects.

854
00:44:02,379 --> 00:44:05,382
And then you can combine both abduction

855
00:44:05,382 --> 00:44:07,384
and induction, where you're given effects,

856
00:44:07,384 --> 00:44:09,386
, essentially observations, and you're

857
00:44:09,386 --> 00:44:12,389
looking for both causes and rules, which

858
00:44:12,389 --> 00:44:14,391
is what the App Perception Engine does.

859
00:44:15,392 --> 00:44:18,395
And this is where in the algorithm, these

860
00:44:18,395 --> 00:44:21,398
kinds of inferences are at play.

861
00:44:21,398 --> 00:44:24,401
So positing latent objects, that's a form

862
00:44:24,401 --> 00:44:27,404
of abduction, imagining causes, finding

863
00:44:27,404 --> 00:44:30,407
the rules, well, that's clearly a form of

864
00:44:30,407 --> 00:44:31,408
induction.

865
00:44:32,409 --> 00:44:35,412
And then applying the rules of a causal

866
00:44:35,412 --> 00:44:39,416
theory to some initial conditions to

867
00:44:39,416 --> 00:44:42,419
create a trace, well, that's deduction.

868
00:44:43,419 --> 00:44:44,421
We have the causes, the initial

869
00:44:44,421 --> 00:44:47,424
conditions, we have the rules, causal

870
00:44:47,424 --> 00:44:49,426
theory, and then we produce a trace, the

871
00:44:49,426 --> 00:44:50,427
effects.

872
00:44:50,427 --> 00:44:51,428
So that's deduction.

873
00:44:51,428 --> 00:44:54,431
So the App Perception Engine uses all

874
00:44:54,431 --> 00:44:57,434
forms of logical inference.

875
00:44:58,435 --> 00:45:01,432
Now, just a reminder that the output of

876
00:45:01,432 --> 00:45:04,435
the App Perception Engine, that is what

877
00:45:04,435 --> 00:45:07,438
is learned is actually human readable.

878
00:45:07,438 --> 00:45:12,443
You may want to compare that to a large

879
00:45:12,443 --> 00:45:16,447
array of floating points produced by

880
00:45:16,447 --> 00:45:20,451
traditional, the more popular form.

881
00:45:20,451 --> 00:45:22,453
Of machine learning nowadays.

882
00:45:22,453 --> 00:45:24,455
So here, this is what's actually produced

883
00:45:24,455 --> 00:45:26,457
by the app reception engine.

884
00:45:26,457 --> 00:45:30,461
As it runs on a set of observations, it

885
00:45:30,461 --> 00:45:33,464
produces a logic program that is human

886
00:45:33,464 --> 00:45:35,466
readable.

887
00:45:35,466 --> 00:45:37,468
When you look at it, the only thing you

888
00:45:37,468 --> 00:45:40,471
need to kind of guess is what is meant by

889
00:45:40,471 --> 00:45:41,472
pred one.

890
00:45:41,472 --> 00:45:44,475
And if you think, well, maybe it means

891
00:45:44,475 --> 00:45:47,478
connects to maybe the lights are

892
00:45:47,478 --> 00:45:50,481
connected underneath a board out of sight

893
00:45:50,481 --> 00:45:52,483
of the observer.

894
00:45:54,485 --> 00:45:57,488
But finding a unified causal theory is

895
00:45:57,488 --> 00:45:57,488
hard.

896
00:45:57,488 --> 00:46:00,485
So we have to guess what the latent

897
00:46:00,485 --> 00:46:02,487
objects and predicates are.

898
00:46:02,487 --> 00:46:05,490
What are the hidden lights, what are the

899
00:46:05,490 --> 00:46:07,492
hidden relationships between lights?

900
00:46:08,493 --> 00:46:10,495
And we have to discover what constraints

901
00:46:10,495 --> 00:46:12,497
might apply on the predicates and what

902
00:46:12,497 --> 00:46:15,500
are the initial conditions from which we

903
00:46:15,500 --> 00:46:17,502
want to recreate a trace.

904
00:46:17,502 --> 00:46:20,505
What are the static rules that apply to

905
00:46:20,505 --> 00:46:22,507
simultaneous observations?

906
00:46:22,507 --> 00:46:25,510
And then what are the causal rules that

907
00:46:25,510 --> 00:46:29,514
given observations at time T will predict

908
00:46:29,514 --> 00:46:32,516
observations at time T plus one?

909
00:46:32,517 --> 00:46:33,518
This is hard.

910
00:46:34,519 --> 00:46:36,521
As a matter of fact, it's non

911
00:46:36,521 --> 00:46:38,523
polynomially hard.

912
00:46:38,523 --> 00:46:41,526
The search space grows exponentially with

913
00:46:41,526 --> 00:46:45,530
the size of the input, which is the size

914
00:46:45,530 --> 00:46:48,533
of the extent and latent vocabulary.

915
00:46:49,534 --> 00:46:51,536
So just like in chess, you can't predict

916
00:46:51,536 --> 00:46:54,539
to the end the consequence of a move

917
00:46:54,539 --> 00:46:56,541
because of common turbo explosion.

918
00:46:57,541 --> 00:46:59,544
With the app perception engine, you

919
00:46:59,544 --> 00:47:01,540
cannot systematically traverse the entire

920
00:47:01,540 --> 00:47:04,543
space of possible causal theories to find

921
00:47:04,543 --> 00:47:06,545
a good one because it's impossibly large.

922
00:47:06,545 --> 00:47:06,545
.

923
00:47:09,548 --> 00:47:12,551
So the job of the apperception engine is

924
00:47:12,551 --> 00:47:15,554
to find a causal theory in a ridiculously

925
00:47:15,554 --> 00:47:16,555
large haystack.

926
00:47:17,556 --> 00:47:18,557
How to do this?

927
00:47:19,558 --> 00:47:23,562
In my implementation, I follow the

928
00:47:23,562 --> 00:47:27,566
recommendations and I follow also the

929
00:47:27,566 --> 00:47:31,570
implementation in Richard Evans'paper by

930
00:47:31,570 --> 00:47:36,574
breaking the search space into chunks.

931
00:47:36,575 --> 00:47:38,577
First there's a region and the region

932
00:47:38,577 --> 00:47:41,580
says so how many latent object types,

933
00:47:41,580 --> 00:47:44,582
objects and predicates will we allow?

934
00:47:44,583 --> 00:47:47,586
So what is the limit of imagination of

935
00:47:47,586 --> 00:47:50,589
the cognition actors that is trying to

936
00:47:50,589 --> 00:47:53,592
apperceive a causal theory?

937
00:47:53,592 --> 00:47:55,594
What are the limits of its imagination?

938
00:47:55,594 --> 00:47:58,597
And within that region of bounded

939
00:47:58,597 --> 00:48:02,595
imagination, we carve it into templates

940
00:48:02,595 --> 00:48:06,599
where we say, okay, we're going to use

941
00:48:06,599 --> 00:48:10,603
these latent objects types, these latent

942
00:48:10,603 --> 00:48:11,604
objects.

943
00:48:11,604 --> 00:48:13,606
And so basically, what vocabulary,

944
00:48:13,606 --> 00:48:15,608
specific vocabulary we're going to be

945
00:48:15,608 --> 00:48:16,608
using?

946
00:48:16,609 --> 00:48:17,610
We're going to use object one.

947
00:48:17,610 --> 00:48:21,614
We're going to use object pred one on top

948
00:48:21,614 --> 00:48:26,619
of the observed on predicate and observed

949
00:48:26,619 --> 00:48:27,620
A and B lights.

950
00:48:28,620 --> 00:48:30,623
And we're going to set the maximum

951
00:48:30,623 --> 00:48:33,626
complexity on the rules and see if we can

952
00:48:33,626 --> 00:48:35,628
find causal theories that fit this

953
00:48:35,628 --> 00:48:36,629
template.

954
00:48:36,629 --> 00:48:40,633
So this is a carving up of the search

955
00:48:40,633 --> 00:48:43,636
space and having broken the search space

956
00:48:43,636 --> 00:48:46,639
into regions and templates, we have

957
00:48:46,639 --> 00:48:50,643
scopes in which to apply Heuristics.

958
00:48:50,643 --> 00:48:50,643
Now.

959
00:48:51,644 --> 00:48:52,645
Why heuristics?

960
00:48:53,646 --> 00:48:56,649
Because the systematic traversal cannot

961
00:48:56,649 --> 00:48:58,651
be done in reasonable time.

962
00:48:58,651 --> 00:49:01,648
There's just too many candidate causal

963
00:49:01,648 --> 00:49:04,651
theories to look at to find a good one.

964
00:49:04,651 --> 00:49:06,653
So we use Heuristics.

965
00:49:08,655 --> 00:49:11,658
We find ways of maybe getting to a good

966
00:49:11,658 --> 00:49:14,661
solution faster at the risk of missing it.

967
00:49:14,661 --> 00:49:14,661
.

968
00:49:14,661 --> 00:49:17,664
But at least we'll have an answer or no

969
00:49:17,664 --> 00:49:21,668
answer in a reasonable amount of time.

970
00:49:21,668 --> 00:49:23,670
And there's a number of heuristics that I'

971
00:49:23,670 --> 00:49:25,672
've implemented in my implementation of

972
00:49:25,672 --> 00:49:27,674
the app assetron engine.

973
00:49:27,674 --> 00:49:29,676
Well, there's time boxing.

974
00:49:29,676 --> 00:49:31,678
At some point, you'd spend no more than

975
00:49:31,678 --> 00:49:33,680
this amount of time looking into a region

976
00:49:33,680 --> 00:49:35,682
or into a template.

977
00:49:36,683 --> 00:49:37,684
There's multitasking.

978
00:49:37,684 --> 00:49:39,686
Well, the problem is actually, as they

979
00:49:39,686 --> 00:49:40,687
say, embarrassingly parallel.

980
00:49:40,687 --> 00:49:43,690
You can explore multiple regions and

981
00:49:43,690 --> 00:49:46,692
multiple templates in parallel and so

982
00:49:46,692 --> 00:49:48,695
make good use of a multicore computer.

983
00:49:49,696 --> 00:49:51,698
You want to make sure you don't repeat

984
00:49:51,698 --> 00:49:51,698
yourself.

985
00:49:51,698 --> 00:49:54,701
So you don't want to traverse the same

986
00:49:54,701 --> 00:49:57,703
region twice or look at the same causal

987
00:49:57,703 --> 00:49:58,705
theory twice.

988
00:49:58,705 --> 00:50:01,702
You want to satisfy maybe a good enough

989
00:50:01,702 --> 00:50:03,704
theory is just fine.

990
00:50:03,704 --> 00:50:05,706
We don't want to look for the perfect one

991
00:50:05,706 --> 00:50:06,707
necessarily.

992
00:50:06,707 --> 00:50:07,708
We may not have time.

993
00:50:08,709 --> 00:50:10,711
You want to fail early.

994
00:50:10,711 --> 00:50:12,713
If you're in a region where nothing good

995
00:50:12,713 --> 00:50:15,716
is found, you may want to leave it quite

996
00:50:15,716 --> 00:50:18,719
quickly at the risk of maybe not finding

997
00:50:18,719 --> 00:50:20,721
a good one that is just over the horizon.

998
00:50:20,721 --> 00:50:21,722
.

999
00:50:21,722 --> 00:50:23,724
But you want to be impatient.

1000
00:50:23,724 --> 00:50:24,725
You want to throw the dice.

1001
00:50:25,725 --> 00:50:28,729
You may want to kind of mix it up so that

1002
00:50:28,729 --> 00:50:30,731
every time you run the app Perception

1003
00:50:30,731 --> 00:50:34,735
Engine on the same problem, you may find

1004
00:50:34,735 --> 00:50:36,737
a different solution first.

1005
00:50:37,738 --> 00:50:40,741
You want to go for the simpler solution

1006
00:50:40,741 --> 00:50:41,742
first.

1007
00:50:41,742 --> 00:50:43,744
You may not want to try everything, just

1008
00:50:43,744 --> 00:50:44,745
sample some.

1009
00:50:44,745 --> 00:50:47,748
You want to start with the easiest part

1010
00:50:47,748 --> 00:50:50,751
of the search base first, be judicious

1011
00:50:50,751 --> 00:50:52,753
and so forth and so on.

1012
00:50:52,753 --> 00:50:54,755
And most importantly, be selective.

1013
00:50:54,755 --> 00:50:57,758
So reject any causal theory that would

1014
00:50:57,758 --> 00:51:00,755
fail the constraints of unity of

1015
00:51:00,755 --> 00:51:01,756
apperception.

1016
00:51:02,757 --> 00:51:04,759
With all these in place, my

1017
00:51:04,759 --> 00:51:07,762
implementation of the app Perception

1018
00:51:07,762 --> 00:51:11,766
Engine gives pretty good results.

1019
00:51:11,766 --> 00:51:13,768
So here I did a run.

1020
00:51:13,768 --> 00:51:14,769
This is not cherry picked.

1021
00:51:14,769 --> 00:51:18,773
I decided to do one series of seven runs

1022
00:51:18,773 --> 00:51:22,777
and collect the data and show it.

1023
00:51:22,777 --> 00:51:25,780
And in this run, I set up the apparition

1024
00:51:25,780 --> 00:51:28,783
engine to only accept a perfect causal

1025
00:51:28,783 --> 00:51:31,785
theory, one that would produce a trace

1026
00:51:31,785 --> 00:51:33,788
that totally covers the observation.

1027
00:51:34,789 --> 00:51:37,792
And I did seven runs.

1028
00:51:37,792 --> 00:51:40,795
The first one succeeded, found it in 4

1029
00:51:40,795 --> 00:51:40,795
seconds.

1030
00:51:41,796 --> 00:51:43,798
The second one, it took 102 seconds.

1031
00:51:43,798 --> 00:51:45,800
So there's some randomization in the

1032
00:51:45,800 --> 00:51:47,802
order in which things have searched if

1033
00:51:47,802 --> 00:51:48,803
luck is involved.

1034
00:51:48,803 --> 00:51:52,807
As I said, the third one, 1 second, that

1035
00:51:52,807 --> 00:51:53,808
was pretty cool.

1036
00:51:55,810 --> 00:51:59,814
The fourth one, well, took 204 seconds,

1037
00:51:59,814 --> 00:52:01,810
then 90, 612, 99.

1038
00:52:01,810 --> 00:52:05,814
So quite a good distribution here.

1039
00:52:05,814 --> 00:52:08,817
Now, I said, okay, I'm going to run the

1040
00:52:08,817 --> 00:52:10,819
app Perception Engine again on the same

1041
00:52:10,819 --> 00:52:13,822
training set that I showed earlier, those

1042
00:52:13,822 --> 00:52:13,822
two lights.

1043
00:52:14,823 --> 00:52:19,828
But this time I said, I'm going to accept

1044
00:52:19,828 --> 00:52:24,833
the theory that has 85% or more coverage.

1045
00:52:24,833 --> 00:52:25,834
.

1046
00:52:25,834 --> 00:52:30,839
So it recreates the observations well

1047
00:52:30,839 --> 00:52:33,842
enough, but not perfectly.

1048
00:52:33,842 --> 00:52:36,845
And I time boxed it to 30 seconds.

1049
00:52:36,845 --> 00:52:38,847
So you have 30 seconds to find it.

1050
00:52:38,847 --> 00:52:38,847
Go.

1051
00:52:39,848 --> 00:52:44,853
The first run, it find a causal theory

1052
00:52:44,853 --> 00:52:47,856
with 75% accuracy immediately.

1053
00:52:47,856 --> 00:52:50,859
Then the same accuracy, same coverage.

1054
00:52:50,859 --> 00:52:51,860
10 seconds.

1055
00:52:51,860 --> 00:52:52,861
11 seconds.

1056
00:52:52,861 --> 00:52:54,863
It hit 29 seconds.

1057
00:52:54,863 --> 00:52:57,866
It found a perfect one.

1058
00:52:57,866 --> 00:52:59,868
Then eleven, it found 87% coverage and

1059
00:52:59,868 --> 00:53:00,863
stopped right there.

1060
00:53:00,863 --> 00:53:01,864
That's good enough.

1061
00:53:01,864 --> 00:53:05,868
75 again, 100% is the first one it found

1062
00:53:05,868 --> 00:53:09,872
above 85 in 18 seconds and 75% 0 second.

1063
00:53:09,872 --> 00:53:11,874
So a good distribution again, so we're

1064
00:53:11,874 --> 00:53:13,876
getting into reasonable times.

1065
00:53:13,876 --> 00:53:15,878
We're not talking about hours here, we're

1066
00:53:15,878 --> 00:53:16,879
talking about seconds.

1067
00:53:16,879 --> 00:53:18,881
And I'm hoping to do further

1068
00:53:18,881 --> 00:53:21,884
optimizations and bring it down to

1069
00:53:21,884 --> 00:53:24,886
something even smaller so that a

1070
00:53:24,886 --> 00:53:27,890
cognition actor can say, I want to make

1071
00:53:27,890 --> 00:53:30,893
sense of these observations, query the

1072
00:53:30,893 --> 00:53:33,896
apperception engine, and get an answer, a

1073
00:53:33,896 --> 00:53:36,899
causal theory within maybe a couple of

1074
00:53:36,899 --> 00:53:37,900
seconds.

1075
00:53:37,900 --> 00:53:38,901
That's my hope.

1076
00:53:40,903 --> 00:53:42,905
Now, something interesting here.

1077
00:53:42,905 --> 00:53:44,907
It so happens that what makes it hard for

1078
00:53:44,907 --> 00:53:46,909
the app perception engine to find a good

1079
00:53:46,909 --> 00:53:49,912
causal theory is formally equivalent to

1080
00:53:49,912 --> 00:53:51,914
what makes cognitive science as a whole

1081
00:53:51,914 --> 00:53:51,914
hard.

1082
00:53:52,914 --> 00:53:54,917
And this paper here makes the case and

1083
00:53:54,917 --> 00:53:57,919
proves the case quite cogently.

1084
00:53:58,921 --> 00:54:04,921
So cognizant science wants to find models,

1085
00:54:04,921 --> 00:54:10,927
, functions or algorithms that explain,

1086
00:54:10,927 --> 00:54:14,931
account for situated behaviors.

1087
00:54:14,931 --> 00:54:18,935
So you feed into the cognitive science

1088
00:54:18,935 --> 00:54:22,939
machine pairs of situations and behaviors,

1089
00:54:22,939 --> 00:54:26,943
, and you want to come out of it a model,

1090
00:54:26,943 --> 00:54:29,946
an explanation, a function, or an

1091
00:54:29,946 --> 00:54:32,949
algorithm that accounts for it.

1092
00:54:33,950 --> 00:54:36,953
Well, the paper makes the case that if

1093
00:54:36,953 --> 00:54:40,956
the explanation is to be bounded in size,

1094
00:54:40,956 --> 00:54:43,960
then the problem is computable, but it's

1095
00:54:43,960 --> 00:54:46,963
not tractable in the sense meaning that

1096
00:54:46,963 --> 00:54:49,966
it's combinatorially explosive.

1097
00:54:49,966 --> 00:54:52,969
But once you have a solution, it is

1098
00:54:52,969 --> 00:54:55,972
computable and tractable to verify that

1099
00:54:55,972 --> 00:54:58,975
the solution is good, that it accounts

1100
00:54:58,975 --> 00:55:01,972
for the data that you're trying to

1101
00:55:01,972 --> 00:55:02,973
understand.

1102
00:55:03,974 --> 00:55:04,975
Well, this is equivalent, formally

1103
00:55:04,975 --> 00:55:06,977
equivalent to what the app perception

1104
00:55:06,977 --> 00:55:07,978
engine is doing.

1105
00:55:11,982 --> 00:55:14,985
My implementation was done in prologue.

1106
00:55:14,985 --> 00:55:16,987
I will not go into the details.

1107
00:55:16,987 --> 00:55:18,989
It's about 1000 lines of prologue.

1108
00:55:18,989 --> 00:55:21,992
I'll just say that prologue is a

1109
00:55:21,992 --> 00:55:24,995
programming language that use deductive

1110
00:55:24,995 --> 00:55:26,997
inference as its model of computation

1111
00:55:26,997 --> 00:55:28,999
with backtracking.

1112
00:55:29,000 --> 00:55:33,004
So essentially it searches for a solution

1113
00:55:33,004 --> 00:55:37,008
and will backtrack if it took the wrong

1114
00:55:37,008 --> 00:55:39,010
branch if you want.

1115
00:55:40,011 --> 00:55:43,014
And we'll look for a different way of

1116
00:55:43,014 --> 00:55:46,017
satisfying a line of the program.

1117
00:55:48,019 --> 00:55:50,021
So let's just say that it makes

1118
00:55:50,021 --> 00:55:52,023
traversing a search space.

1119
00:55:53,024 --> 00:55:55,026
We get traversing a search brains for

1120
00:55:55,026 --> 00:55:57,028
free when we program in prologue.

1121
00:55:57,028 --> 00:55:59,030
I won't go into any more details, but you

1122
00:55:59,030 --> 00:56:00,025
can see some prologue code here.

1123
00:56:00,025 --> 00:56:04,029
And the fun thing is that a prologue

1124
00:56:04,029 --> 00:56:08,033
program is akin to a logical description

1125
00:56:08,033 --> 00:56:11,036
of the problem it's trying to solve.

1126
00:56:12,037 --> 00:56:13,038
I think it's very cool.

1127
00:56:14,039 --> 00:56:17,042
And prologue environment was augmented by

1128
00:56:17,042 --> 00:56:20,045
something called constraint handling

1129
00:56:20,045 --> 00:56:22,047
rules, which is an extension to prologue

1130
00:56:22,047 --> 00:56:25,050
that adds abductive reasoning.

1131
00:56:25,050 --> 00:56:29,054
So basically in the program, you can say,

1132
00:56:29,054 --> 00:56:33,057
assume this is true until proven

1133
00:56:33,057 --> 00:56:37,062
otherwise, and the CHR rules are there to

1134
00:56:37,062 --> 00:56:41,066
verify if it can be proven otherwise.

1135
00:56:41,066 --> 00:56:44,068
So, again, I'm not asking you to

1136
00:56:44,068 --> 00:56:46,071
understand this code at all, but I want

1137
00:56:46,071 --> 00:56:49,074
you to realize that this code is the code

1138
00:56:49,074 --> 00:56:51,076
that actually executes a causal theory,

1139
00:56:51,076 --> 00:56:54,079
both the static and causal rules to build

1140
00:56:54,079 --> 00:56:55,080
traces.

1141
00:56:55,080 --> 00:56:56,081
It is that small.

1142
00:56:56,081 --> 00:56:57,082
It's very powerful.

1143
00:56:57,082 --> 00:57:01,080
So combining prologue and CHR, I found

1144
00:57:01,080 --> 00:57:03,082
extraordinarily powerful.

1145
00:57:03,082 --> 00:57:05,084
I'm very excited about it.

1146
00:57:05,084 --> 00:57:06,085
I'm a programmer.

1147
00:57:07,086 --> 00:57:08,087
Next steps.

1148
00:57:08,087 --> 00:57:13,092
Well, next steps, now that we've solved

1149
00:57:13,092 --> 00:57:18,097
individual learning by cognitive actors,

1150
00:57:18,097 --> 00:57:22,101
well, I want to move to beliefs from

1151
00:57:22,101 --> 00:57:27,106
sensations and to policies to validate or

1152
00:57:27,106 --> 00:57:29,108
eliminate beliefs.

1153
00:57:31,110 --> 00:57:33,112
A lot of these beliefs actually fall out

1154
00:57:33,112 --> 00:57:34,113
of our perception.

1155
00:57:34,113 --> 00:57:37,116
Latent objects and latent relationships

1156
00:57:37,116 --> 00:57:39,118
and properties can be considered as

1157
00:57:39,118 --> 00:57:39,118
beliefs.

1158
00:57:39,118 --> 00:57:42,121
Then there are other kinds of beliefs

1159
00:57:42,121 --> 00:57:44,123
that can be obtained from what's been

1160
00:57:44,123 --> 00:57:45,124
perceived.

1161
00:57:46,125 --> 00:57:51,130
There will be introspective beliefs that

1162
00:57:51,130 --> 00:57:55,134
communicate how the cognition actor is

1163
00:57:55,134 --> 00:57:58,137
doing in terms of competence,

1164
00:57:58,137 --> 00:58:02,135
predictionary rates, how well its

1165
00:58:02,135 --> 00:58:07,140
apperception is doing, and whether it is

1166
00:58:07,140 --> 00:58:11,144
engaging with other cognition actors.

1167
00:58:12,145 --> 00:58:13,146
Is it relevant?

1168
00:58:13,146 --> 00:58:16,149
I will have feelings which will provide

1169
00:58:16,149 --> 00:58:18,151
normativity to these beliefs.

1170
00:58:18,151 --> 00:58:22,155
So if feelings are signals of risk to

1171
00:58:22,155 --> 00:58:26,159
homeostasis, loss of resources, physical

1172
00:58:26,159 --> 00:58:29,162
damage, too many prediction errors so

1173
00:58:29,162 --> 00:58:33,166
that's anger, pain, and fear and feelings

1174
00:58:33,166 --> 00:58:37,170
will taint beliefs over time and tainted

1175
00:58:37,170 --> 00:58:40,173
beliefs, good beliefs, bad beliefs will

1176
00:58:40,173 --> 00:58:44,177
want to be eliminated or validated

1177
00:58:44,177 --> 00:58:47,180
through policies that will be synthesized

1178
00:58:47,180 --> 00:58:50,183
by the cognition actor.

1179
00:58:51,184 --> 00:58:55,188
And each cognition actor will make

1180
00:58:55,188 --> 00:58:58,191
available to others its API.

1181
00:58:59,192 --> 00:59:01,188
What predictions can be made about the

1182
00:59:01,188 --> 00:59:02,189
beliefs of this cognition actor?

1183
00:59:02,189 --> 00:59:07,194
What actions are available to others to

1184
00:59:07,194 --> 00:59:11,198
be asked of the cognition actor?

1185
00:59:12,199 --> 00:59:15,202
And then as cognition actors connect to

1186
00:59:15,202 --> 00:59:18,205
one another, as the conjunction actors

1187
00:59:18,205 --> 00:59:22,209
form the umbelt of other cognition actors,

1188
00:59:22,209 --> 00:59:25,212
, then a conjunction actor will be able

1189
00:59:25,212 --> 00:59:29,216
to predict the beliefs of others, will be

1190
00:59:29,216 --> 00:59:32,219
able to compose policies made out of

1191
00:59:32,219 --> 00:59:35,222
actions that are implemented by other

1192
00:59:35,222 --> 00:59:37,224
cognition actors.

1193
00:59:37,224 --> 00:59:41,228
And eventually, we'll have a society of

1194
00:59:41,228 --> 00:59:45,232
mind, which is a bunch of intersecting

1195
00:59:45,232 --> 00:59:46,233
boom belts.

1196
00:59:47,234 --> 00:59:50,237
So that's it.

1197
00:59:51,238 --> 00:59:55,242
So I see the society of mine is a complex

1198
00:59:55,242 --> 00:59:59,246
system of collective theorizers.

1199
00:59:59,246 --> 01:00:02,193
And I'm going to try going further with

1200
01:00:02,193 --> 01:00:04,887
this project to answer the question if

1201
01:00:04,887 --> 01:00:07,651
collective theorizers can self organize

1202
01:00:07,651 --> 01:00:09,078
to actively sustain itself.

1203
01:00:10,131 --> 01:00:12,365
So thank you to the Active Inference

1204
01:00:12,365 --> 01:00:15,626
Institute for inviting me to present and

1205
01:00:15,626 --> 01:00:17,893
for providing a home for this project and

1206
01:00:17,893 --> 01:00:19,075
for the constant support and

1207
01:00:19,075 --> 01:00:20,192
encouragement.

1208
01:00:21,212 --> 01:00:23,439
I'll see you later on Discord.

1209
01:00:23,455 --> 01:00:24,542
Thank you.

1210
01:00:25,643 --> 01:00:26,713
Daniel: Awesome.

1211
01:00:26,728 --> 01:00:27,872
Thank you, JF.

1212
01:00:27,892 --> 01:00:31,201
Just to conclude the session, I'll read

1213
01:00:31,201 --> 01:00:33,494
two questions and let's maybe address

1214
01:00:33,494 --> 01:00:37,820
them in an upcoming Robotics and embodied

1215
01:00:37,820 --> 01:00:38,907
meeting.

1216
01:00:38,913 --> 01:00:40,131
So if you're excited about this project,

1217
01:00:40,131 --> 01:00:42,343
certainly we all are and about symbolic

1218
01:00:42,343 --> 01:00:44,550
active inference, join the Discord and

1219
01:00:44,550 --> 01:00:46,773
participate in the Robotics and Embodied.

1220
01:00:46,773 --> 01:00:46,789
.

1221
01:00:46,794 --> 01:00:49,020
But I'll drop these two questions from

1222
01:00:49,020 --> 01:00:51,245
David Williams in the Chat, who wrote,

1223
01:00:51,245 --> 01:00:53,465
one, how important is conducting this

1224
01:00:53,465 --> 01:00:56,702
work in real world versus simulation?

1225
01:00:56,710 --> 01:00:58,944
And two, what tools or components are

1226
01:00:58,944 --> 01:01:00,597
missing in the robotics toolkit to make

1227
01:01:00,597 --> 01:01:03,812
this research easier and better?

1228
01:01:03,826 --> 01:01:05,001
I know those are things that you have a

1229
01:01:05,001 --> 01:01:06,181
lot of thoughts on, so I'll look forward

1230
01:01:06,181 --> 01:01:08,316
to discussing with you more.

1231
01:01:08,329 --> 01:01:09,457
Thank you, JF.

1232
01:01:11,674 --> 01:01:12,764
JF: Thank you.

1233
01:01:12,777 --> 01:01:13,856
Daniel: Peace.

1234
01:01:15,090 --> 01:01:16,189
JF: All right.

1235
01:01:19,458 --> 01:01:20,507
Daniel: See you.

