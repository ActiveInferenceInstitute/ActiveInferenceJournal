1
00:00:06,004 --> 00:00:06,564
Daniel: Greetings.

2
00:00:06,644 --> 00:00:10,101
Bert: All right, well, our next session.

3
00:00:10,101 --> 00:00:10,194
Hey, Bert.

4
00:00:11,199 --> 00:00:11,288
Greetings.

5
00:00:12,306 --> 00:00:12,340
Great.

6
00:00:12,344 --> 00:00:13,408
Hey, how you doing?

7
00:00:13,414 --> 00:00:13,477
Good, good.

8
00:00:13,484 --> 00:00:14,570
Dmitry: Very well.

9
00:00:14,587 --> 00:00:17,831
Daniel: Our next session is with Bert

10
00:00:17,831 --> 00:00:20,101
DeVries, Dmitri Bagaev, and Bart Van Erp.

11
00:00:20,101 --> 00:00:20,108
.

12
00:00:20,119 --> 00:00:22,320
It's going to be called towards User

13
00:00:22,320 --> 00:00:24,516
Friendly Design of Synthetic Active

14
00:00:24,516 --> 00:00:25,622
inference agents.

15
00:00:25,640 --> 00:00:27,883
And I know a lot of people are super

16
00:00:27,883 --> 00:00:30,152
excited to see this really practical and

17
00:00:30,152 --> 00:00:31,287
cutting edge work.

18
00:00:31,294 --> 00:00:34,552
So to you, Bert, and just let us know how

19
00:00:34,552 --> 00:00:35,652
we can support.

20
00:00:36,753 --> 00:00:37,868
Bert: Okay, great.

21
00:00:38,961 --> 00:00:39,088
Is my audio good?

22
00:00:40,098 --> 00:00:41,239
Daniel: Yep, sounds good.

23
00:00:41,259 --> 00:00:43,479
Bert: Okay, then I'm going to share my

24
00:00:43,479 --> 00:00:44,525
screen.

25
00:00:46,738 --> 00:00:48,899
I hope I picked the right one.

26
00:00:48,904 --> 00:00:50,177
I don't work with zoom quite often.

27
00:00:51,195 --> 00:00:51,281
Looks good.

28
00:00:51,291 --> 00:00:52,347
Looks good.

29
00:00:52,352 --> 00:00:52,380
Yeah.

30
00:00:52,386 --> 00:00:53,444
All right.

31
00:00:53,458 --> 00:00:54,526
Super.

32
00:00:55,619 --> 00:00:58,921
Well, thanks a lot, Daniel, for hosting

33
00:00:58,921 --> 00:00:59,045
this symposium.

34
00:00:59,050 --> 00:01:00,598
I've been watching some talks.

35
00:01:01,601 --> 00:01:02,709
It's really amazing.

36
00:01:02,729 --> 00:01:05,038
And we feel privileged to get a chance to

37
00:01:05,038 --> 00:01:06,182
present ourselves.

38
00:01:06,198 --> 00:01:09,428
So we are also, just like a few others

39
00:01:09,428 --> 00:01:11,652
before us, interested in developing a

40
00:01:11,652 --> 00:01:13,839
toolbox for active inference.

41
00:01:13,881 --> 00:01:17,242
And so this picture, or she kind of shows

42
00:01:17,242 --> 00:01:20,514
what we're about or what we are

43
00:01:20,514 --> 00:01:21,655
interested in.

44
00:01:21,667 --> 00:01:25,001
So here's a lady on the left hand side,

45
00:01:25,001 --> 00:01:28,301
and I'm going to try to get a laser

46
00:01:28,301 --> 00:01:28,387
pointer.

47
00:01:28,396 --> 00:01:31,684
And she has this idea about a rewarding

48
00:01:31,684 --> 00:01:34,956
behavior for a vacuum cleaning robot,

49
00:01:34,956 --> 00:01:35,015
right?

50
00:01:35,019 --> 00:01:37,264
So she's writing down she has a textual

51
00:01:37,264 --> 00:01:38,340
expression.

52
00:01:38,357 --> 00:01:41,596
Move around the apartment, apply suction

53
00:01:41,596 --> 00:01:43,823
until the floor is clean, do not touch

54
00:01:43,823 --> 00:01:45,007
objects, and when done, return to the dog.

55
00:01:45,007 --> 00:01:45,008
.

56
00:01:45,009 --> 00:01:47,023
So that's not so hard.

57
00:01:47,024 --> 00:01:50,053
I'm going to rate that with one star out

58
00:01:50,053 --> 00:01:53,080
of three stars in terms of difficulty

59
00:01:53,080 --> 00:01:54,098
level to specify that.

60
00:01:55,106 --> 00:01:57,128
But that's not enough to program this

61
00:01:57,128 --> 00:01:58,136
robot, right?

62
00:01:58,137 --> 00:02:02,114
Because what she really needs to do now

63
00:02:02,114 --> 00:02:05,148
is to specify a generative model and

64
00:02:05,148 --> 00:02:09,186
there's effectors and actuators, right.

65
00:02:09,187 --> 00:02:12,211
The robot has to move around, apply

66
00:02:12,211 --> 00:02:14,235
suction until the floor is clean.

67
00:02:14,236 --> 00:02:16,258
So there are sensors, probably a camera.

68
00:02:17,263 --> 00:02:18,278
Do not touch objects.

69
00:02:18,278 --> 00:02:20,294
Or maybe there has to be object

70
00:02:20,294 --> 00:02:21,300
recognition.

71
00:02:21,302 --> 00:02:24,330
This is a really difficult task to come

72
00:02:24,330 --> 00:02:26,356
up with this generative model here.

73
00:02:26,357 --> 00:02:29,385
And on top of that, she has to specify

74
00:02:29,385 --> 00:02:32,414
this kind of rewarding behavior in terms

75
00:02:32,414 --> 00:02:35,443
now of probability distributions of this

76
00:02:35,443 --> 00:02:36,457
generative model.

77
00:02:36,458 --> 00:02:38,474
So very difficult.

78
00:02:38,475 --> 00:02:41,502
I'm going to rate that with two stars

79
00:02:41,502 --> 00:02:44,531
because the next thing she has to do for

80
00:02:44,531 --> 00:02:46,559
this model is to specify the inference

81
00:02:46,559 --> 00:02:49,588
procedure to do actually active inference

82
00:02:49,588 --> 00:02:52,618
and free energy minimization in real time

83
00:02:52,618 --> 00:02:54,638
for this complex model.

84
00:02:55,639 --> 00:02:57,659
And really that's almost impossible,

85
00:02:57,659 --> 00:02:57,663
right?

86
00:02:57,664 --> 00:03:00,637
Only a few specialists can really write a

87
00:03:00,637 --> 00:03:03,666
procedure for variational free energy

88
00:03:03,666 --> 00:03:06,699
minimization in some very difficult model.

89
00:03:06,699 --> 00:03:07,700
.

90
00:03:07,702 --> 00:03:09,727
So what we are about what we've been

91
00:03:09,727 --> 00:03:12,752
working on is to try to automate the

92
00:03:12,752 --> 00:03:13,764
inference task.

93
00:03:13,764 --> 00:03:15,782
So get rid of the three stars.

94
00:03:15,784 --> 00:03:18,811
And yes, she will still have to specify

95
00:03:18,811 --> 00:03:20,838
her model, but in the long term, we try

96
00:03:20,838 --> 00:03:22,855
to get away from that.

97
00:03:22,855 --> 00:03:25,880
So in the long term, we hope we will get

98
00:03:25,880 --> 00:03:25,887
a toolbox.

99
00:03:25,887 --> 00:03:28,918
And now we're talking 510 years, right,

100
00:03:28,918 --> 00:03:31,946
where a textual description would be

101
00:03:31,946 --> 00:03:34,977
enough to specify some initial model with

102
00:03:34,977 --> 00:03:37,008
an initial prior and everything else is

103
00:03:37,008 --> 00:03:40,036
just automated inference, learning of

104
00:03:40,036 --> 00:03:43,068
states, parameters, structural adaptation

105
00:03:43,068 --> 00:03:46,097
of the model, even maybe based on her

106
00:03:46,097 --> 00:03:49,124
feedback updating the prior.

107
00:03:49,126 --> 00:03:53,161
So that's long term for now, we would be

108
00:03:53,161 --> 00:03:56,197
very happy if we could just automate the

109
00:03:56,197 --> 00:03:58,212
inference task.

110
00:03:58,214 --> 00:04:01,181
So why is it so difficult to specify

111
00:04:01,181 --> 00:04:04,212
inference for an active inference agent?

112
00:04:04,213 --> 00:04:08,256
Well, we have so many competing KPIs,

113
00:04:08,256 --> 00:04:09,264
right?

114
00:04:10,271 --> 00:04:13,303
We want to do this for large model scopes,

115
00:04:13,303 --> 00:04:16,332
, not just for ABCD models, but maybe

116
00:04:16,332 --> 00:04:19,361
there's also continuous variables and

117
00:04:19,361 --> 00:04:21,383
hierarchical models, right?

118
00:04:21,384 --> 00:04:23,404
It must be very user friendly.

119
00:04:23,405 --> 00:04:26,437
We really don't want her to worry about

120
00:04:26,437 --> 00:04:28,457
robustness of her code.

121
00:04:29,463 --> 00:04:33,503
We don't want her to worry about whether

122
00:04:33,503 --> 00:04:36,531
two variables have conjugate

123
00:04:36,531 --> 00:04:38,558
relationships adaptivity.

124
00:04:38,559 --> 00:04:40,578
We want to update states, parameters,

125
00:04:40,578 --> 00:04:42,589
maybe even the model.

126
00:04:42,590 --> 00:04:44,618
The model structure has to be low power

127
00:04:44,618 --> 00:04:47,646
because these ancients often run on edge

128
00:04:47,646 --> 00:04:50,672
devices, so they run on their battery

129
00:04:50,672 --> 00:04:52,699
powered has to be in real time because

130
00:04:52,699 --> 00:04:55,725
you can't learn how to ride a bike if

131
00:04:55,725 --> 00:04:58,750
there's no real time reasoning.

132
00:04:58,752 --> 00:05:00,714
And on top of that, you actually want to

133
00:05:00,714 --> 00:05:02,735
minimize variational frequency, right?

134
00:05:02,736 --> 00:05:04,756
You want to do it at least as good or at

135
00:05:04,756 --> 00:05:06,776
least in a neighborhood of if you would

136
00:05:06,776 --> 00:05:07,789
do a manual derivation.

137
00:05:08,790 --> 00:05:10,816
And some of these decidorata bite each

138
00:05:10,816 --> 00:05:11,826
other, right?

139
00:05:11,827 --> 00:05:14,853
If you want to minimize variational free

140
00:05:14,853 --> 00:05:16,878
energy, but you have to do it in real

141
00:05:16,878 --> 00:05:19,905
time and on low power that kind of bites

142
00:05:19,905 --> 00:05:20,919
each other, right?

143
00:05:21,919 --> 00:05:26,977
So these are difficult KPIs that they're

144
00:05:26,977 --> 00:05:28,999
all important.

145
00:05:29,000 --> 00:05:32,030
You can't just take one out because then

146
00:05:32,030 --> 00:05:34,054
the whole system wouldn't work.

147
00:05:35,060 --> 00:05:38,091
So when you read papers on active

148
00:05:38,091 --> 00:05:42,130
inference, you often also read and now we

149
00:05:42,130 --> 00:05:45,166
implement variation of minimization and

150
00:05:45,166 --> 00:05:49,203
that can be done by message passing on a

151
00:05:49,203 --> 00:05:50,213
graph.

152
00:05:50,214 --> 00:05:53,245
And I want to clarify first why it has to

153
00:05:53,245 --> 00:05:56,276
be done by message passing on the graph.

154
00:05:57,279 --> 00:05:59,306
I do that by giving a very short answer

155
00:05:59,306 --> 00:06:01,262
and then do an example.

156
00:06:01,264 --> 00:06:04,293
The short answer is that Bayesian

157
00:06:04,293 --> 00:06:07,327
inference involves computing very large

158
00:06:07,327 --> 00:06:11,362
sum of products, like what you see here

159
00:06:11,362 --> 00:06:13,384
on the left hand side.

160
00:06:13,385 --> 00:06:17,421
Here's a product AC, ADBC, and then we

161
00:06:17,421 --> 00:06:20,452
sum them AC plus ad and so forth.

162
00:06:20,453 --> 00:06:21,468
This is a sum of products.

163
00:06:22,470 --> 00:06:25,500
Now, we know by the Distributive law that

164
00:06:25,500 --> 00:06:28,531
this here on the left hand side can also

165
00:06:28,531 --> 00:06:31,561
be computed as on the right hand side.

166
00:06:31,565 --> 00:06:33,589
If I multiply this out, I get a times C

167
00:06:33,589 --> 00:06:35,607
plus a times D and so forth.

168
00:06:35,608 --> 00:06:38,637
This is a product of sums and they're

169
00:06:38,637 --> 00:06:40,656
exactly the same thing.

170
00:06:40,658 --> 00:06:43,685
The only difference is that to compute

171
00:06:43,685 --> 00:06:46,713
the left hand side takes four additions

172
00:06:46,713 --> 00:06:49,740
sorry, four multiplications and three

173
00:06:49,740 --> 00:06:50,749
additions.

174
00:06:50,750 --> 00:06:52,776
To compute the right hand side takes two

175
00:06:52,776 --> 00:06:55,802
additions and only one multiplication.

176
00:06:55,803 --> 00:06:58,833
So on the right hand side is much cheaper

177
00:06:58,833 --> 00:07:00,799
to compute than the left hand side.

178
00:07:01,801 --> 00:07:03,821
Normally when we write down

179
00:07:03,821 --> 00:07:06,851
marginalization and Beijing inference, we

180
00:07:06,851 --> 00:07:08,879
write things down as in the left hand

181
00:07:08,879 --> 00:07:11,906
side what message passing does on the

182
00:07:11,906 --> 00:07:14,936
graph, it will automatically convert that

183
00:07:14,936 --> 00:07:17,966
into much cheaper to evaluate product of

184
00:07:17,966 --> 00:07:18,974
sums.

185
00:07:18,975 --> 00:07:21,003
And I'll give an example of that.

186
00:07:23,024 --> 00:07:26,059
So here is an example model F of seven

187
00:07:26,059 --> 00:07:30,096
variables x one, x two through x seven.

188
00:07:30,097 --> 00:07:34,132
And this model happens to be factorized

189
00:07:34,132 --> 00:07:37,166
FA of x one, FB, x two and so forth.

190
00:07:37,167 --> 00:07:41,204
Now, we can draw this factorization as a

191
00:07:41,204 --> 00:07:42,211
graph.

192
00:07:42,213 --> 00:07:45,240
And what we do, and this is called a

193
00:07:45,240 --> 00:07:48,269
Farney style factor graph, what we do is

194
00:07:48,269 --> 00:07:51,300
for each factor FA, we allocate a node.

195
00:07:51,300 --> 00:07:54,334
So FB gets a node and FC gets a node.

196
00:07:54,336 --> 00:07:57,364
And we associate the variables in our

197
00:07:57,364 --> 00:07:59,381
system with the edge.

198
00:07:59,382 --> 00:08:01,348
And an edge is connected to a node if

199
00:08:01,348 --> 00:08:04,373
that variable is an argument of that

200
00:08:04,373 --> 00:08:05,381
function.

201
00:08:05,382 --> 00:08:10,432
So FC is a function of x one, x two, x

202
00:08:10,432 --> 00:08:11,441
three.

203
00:08:11,442 --> 00:08:14,472
And that means that FC connects to the

204
00:08:14,472 --> 00:08:17,502
edges x one, x two, x three, and FD is

205
00:08:17,502 --> 00:08:19,525
only a function of x four.

206
00:08:19,525 --> 00:08:23,564
So FD only connects to the edge x four.

207
00:08:23,566 --> 00:08:26,597
So what you can see in this graph is this

208
00:08:26,597 --> 00:08:29,627
graph is nothing but a visualization of

209
00:08:29,627 --> 00:08:32,656
the factorization assumptions that we

210
00:08:32,656 --> 00:08:34,673
have for this model.

211
00:08:35,683 --> 00:08:37,708
Now, if I'm interested in a big

212
00:08:37,708 --> 00:08:41,741
marginalization task and I integrate out

213
00:08:41,741 --> 00:08:44,775
over all variables but x three, so x one,

214
00:08:44,775 --> 00:08:47,805
x two, x four and so forth through x

215
00:08:47,805 --> 00:08:50,833
seven, I'm interested in this.

216
00:08:51,842 --> 00:08:54,873
Then taking advantage of this

217
00:08:54,873 --> 00:08:58,913
factorization, I can rewrite basically

218
00:08:58,913 --> 00:09:02,893
this sum of product into a product of

219
00:09:02,893 --> 00:09:06,932
sums as below here, what you will see

220
00:09:06,932 --> 00:09:10,976
here below this computes exactly the same

221
00:09:10,976 --> 00:09:11,988
thing.

222
00:09:11,988 --> 00:09:14,013
But I've made use of this distributive

223
00:09:14,013 --> 00:09:14,016
law.

224
00:09:14,018 --> 00:09:20,069
For instance, FC contains no x four, no x

225
00:09:20,069 --> 00:09:20,077
five.

226
00:09:20,078 --> 00:09:23,105
So I moved it over the summation sign to

227
00:09:23,105 --> 00:09:24,112
the left.

228
00:09:24,113 --> 00:09:27,149
And FB also doesn't contain x four, x

229
00:09:27,149 --> 00:09:29,168
five, x six, seven.

230
00:09:29,169 --> 00:09:32,190
So I moved it all the way to the left.

231
00:09:32,195 --> 00:09:35,228
And when you do that, you are left here

232
00:09:35,228 --> 00:09:39,262
with an expression where I only sum over

233
00:09:39,262 --> 00:09:42,297
two variables and here I have to sum over

234
00:09:42,297 --> 00:09:46,333
six variables and here over two, and here

235
00:09:46,333 --> 00:09:47,344
over two.

236
00:09:47,345 --> 00:09:50,378
So you can imagine if each variable, let'

237
00:09:50,378 --> 00:09:54,412
's say x one, x two, if each variable has

238
00:09:54,412 --> 00:09:57,444
ten interesting values that you need to

239
00:09:57,444 --> 00:10:00,416
sum over, then I have here the original

240
00:10:00,416 --> 00:10:02,437
marginalization problem.

241
00:10:02,438 --> 00:10:06,475
I have ten to the power six, so a million

242
00:10:06,475 --> 00:10:10,510
terms, and here in red I have 100 terms

243
00:10:10,510 --> 00:10:13,548
and here I have 100 and here I have 100.

244
00:10:13,549 --> 00:10:17,580
So here I have 300 terms and here I have

245
00:10:17,580 --> 00:10:18,594
1 million terms.

246
00:10:18,595 --> 00:10:21,629
So it's an enormous reduction in

247
00:10:21,629 --> 00:10:26,671
computational complexity when we make use

248
00:10:26,671 --> 00:10:29,699
of this distributive law.

249
00:10:29,701 --> 00:10:32,733
Now, it turns out that if you write this

250
00:10:32,733 --> 00:10:35,766
out, you can associate these intermediate

251
00:10:35,766 --> 00:10:38,796
factors with messages on the graph.

252
00:10:38,797 --> 00:10:40,818
It's just an interpretation, a visual

253
00:10:40,818 --> 00:10:41,828
interpretation.

254
00:10:42,829 --> 00:10:46,874
It's as if FC receives a message from FA

255
00:10:46,874 --> 00:10:50,917
and FB receive or FC receives a message

256
00:10:50,917 --> 00:10:55,962
from FB and computes an outgoing message

257
00:10:55,962 --> 00:10:56,978
MU x three.

258
00:10:57,979 --> 00:10:58,996
And the same thing for Fe.

259
00:10:58,997 --> 00:11:01,969
So Fe receives a message from its

260
00:11:01,969 --> 00:11:05,002
neighboring factors, FD and FF and

261
00:11:05,002 --> 00:11:09,041
computes an outgoing message, x three.

262
00:11:09,042 --> 00:11:12,073
So what you see here is that the entire

263
00:11:12,073 --> 00:11:14,096
marginalization process can be

264
00:11:14,096 --> 00:11:17,127
represented as basically computing a few

265
00:11:17,127 --> 00:11:20,158
messages on a graph and multiplying some

266
00:11:20,158 --> 00:11:23,188
of these messages with each other.

267
00:11:24,196 --> 00:11:26,214
And that's how you can do Bayesian

268
00:11:26,214 --> 00:11:28,233
inference and also how you can do

269
00:11:28,233 --> 00:11:30,254
variational free energy minimization.

270
00:11:30,256 --> 00:11:34,292
So this works in factorized models, but I

271
00:11:34,292 --> 00:11:37,327
would say even stronger if your model is

272
00:11:37,327 --> 00:11:40,358
not factorized and you have a lot of

273
00:11:40,358 --> 00:11:44,392
variables, there is just no way you can

274
00:11:44,392 --> 00:11:46,413
do proper inference.

275
00:11:46,414 --> 00:11:50,449
So any serious model is factorized, like

276
00:11:50,449 --> 00:11:53,482
the brain is almost sparse, is almost

277
00:11:53,482 --> 00:11:54,489
empty.

278
00:11:54,490 --> 00:11:56,513
We have, what is it, about 10 billion

279
00:11:56,513 --> 00:11:58,537
neurons, and each neuron connects to a

280
00:11:58,537 --> 00:12:00,495
few thousand other neurons.

281
00:12:00,496 --> 00:12:03,525
So if I would draw the graph, that graph

282
00:12:03,525 --> 00:12:06,553
is almost empty, it is hugely sparse.

283
00:12:06,554 --> 00:12:08,575
And so there is no other way to do

284
00:12:08,575 --> 00:12:10,599
inference in the brain than by message

285
00:12:10,599 --> 00:12:11,605
passing.

286
00:12:12,611 --> 00:12:14,631
So that's why message passing, just

287
00:12:14,631 --> 00:12:16,655
because it's more effective than anything

288
00:12:16,655 --> 00:12:17,659
else.

289
00:12:18,676 --> 00:12:21,707
Now then the issue is which message do

290
00:12:21,707 --> 00:12:22,718
you compute?

291
00:12:22,718 --> 00:12:24,737
How do you compute messages?

292
00:12:25,745 --> 00:12:28,771
Because there are different ways of doing

293
00:12:28,771 --> 00:12:28,778
it right.

294
00:12:28,778 --> 00:12:31,803
And we also read in active inference

295
00:12:31,803 --> 00:12:33,829
papers, you can do this by variational

296
00:12:33,829 --> 00:12:36,850
message passing, or expectation

297
00:12:36,850 --> 00:12:38,877
maximization, or belief propagation and

298
00:12:38,877 --> 00:12:41,907
variational LaPlace and all these terms.

299
00:12:41,909 --> 00:12:44,938
It turns out that there is an umbrella

300
00:12:44,938 --> 00:12:47,967
framework for all these methods passing

301
00:12:47,967 --> 00:12:48,977
frameworks.

302
00:12:48,978 --> 00:12:51,004
And that umbrella framework is called

303
00:12:51,004 --> 00:12:53,025
Constraint better free energy

304
00:12:53,025 --> 00:12:54,036
minimization.

305
00:12:54,038 --> 00:13:00,034
And I will try to illustrate it by this

306
00:13:00,034 --> 00:13:01,044
slide.

307
00:13:01,048 --> 00:13:04,070
So here I have this graph.

308
00:13:04,071 --> 00:13:08,115
This is just an example graph where my

309
00:13:08,115 --> 00:13:13,162
generative model is basically factorized

310
00:13:13,162 --> 00:13:16,194
in FA, FB, FC, FD and Fe.

311
00:13:16,195 --> 00:13:18,213
And I've also written that here.

312
00:13:18,213 --> 00:13:20,234
So this now is the variational free

313
00:13:20,234 --> 00:13:20,239
energy.

314
00:13:21,246 --> 00:13:24,279
Now, I haven't made any assumption on Q

315
00:13:24,279 --> 00:13:25,283
of X.

316
00:13:25,284 --> 00:13:28,313
So Q of X is still Q of x one, x two, x

317
00:13:28,313 --> 00:13:28,318
three.

318
00:13:28,319 --> 00:13:31,346
It's just a joint overall variables and

319
00:13:31,346 --> 00:13:33,369
it doesn't have any factorization

320
00:13:33,369 --> 00:13:34,378
assumption.

321
00:13:35,388 --> 00:13:38,415
It makes sense to also assume that the

322
00:13:38,415 --> 00:13:40,435
posterior kind of follows the

323
00:13:40,435 --> 00:13:43,461
factorization assumption of the prior,

324
00:13:43,461 --> 00:13:45,485
namely of the generative model.

325
00:13:45,486 --> 00:13:49,523
So if we make that assumption and that

326
00:13:49,523 --> 00:13:53,561
means we're going to make the assumption

327
00:13:53,561 --> 00:13:57,601
that QX is also now a product of QAS of X

328
00:13:57,601 --> 00:14:00,576
of A, where QAS of X of A stands for

329
00:14:00,576 --> 00:14:02,598
beliefs over nodes.

330
00:14:02,599 --> 00:14:06,631
What I mean by that is that Q of B is a

331
00:14:06,631 --> 00:14:09,664
posterior belief over this node, meaning

332
00:14:09,664 --> 00:14:12,695
it's a posterior belief over the edges

333
00:14:12,695 --> 00:14:14,719
that connect to this node.

334
00:14:15,720 --> 00:14:18,752
Just like FB is a function of x one, x

335
00:14:18,752 --> 00:14:21,782
two, x four, that's if you will, the

336
00:14:21,782 --> 00:14:24,815
prior or the generative model, then Q of

337
00:14:24,815 --> 00:14:27,846
B, the variational posterior for this

338
00:14:27,846 --> 00:14:30,879
node will also depend on x one, x two, x

339
00:14:30,879 --> 00:14:33,908
four, and on no other factors.

340
00:14:34,914 --> 00:14:37,946
If you just do that, then you will count

341
00:14:37,946 --> 00:14:40,976
some of the variables double because x

342
00:14:40,976 --> 00:14:43,006
one is part of the belief over FA, but

343
00:14:43,006 --> 00:14:46,034
also part of the belief over FB.

344
00:14:46,036 --> 00:14:49,068
So we just have to discount that by

345
00:14:49,068 --> 00:14:52,097
dividing by beliefs over edges.

346
00:14:52,099 --> 00:14:57,141
That means that I make now an assumption

347
00:14:57,141 --> 00:15:01,124
that my posterior beliefs is divided into

348
00:15:01,124 --> 00:15:05,160
local beliefs over notes and local

349
00:15:05,160 --> 00:15:08,199
beliefs over edges over variables.

350
00:15:09,205 --> 00:15:11,229
This will make things a lot simpler.

351
00:15:12,230 --> 00:15:14,256
In fact, if my graph is a tree and I did

352
00:15:14,256 --> 00:15:17,281
the tree here, and I would do message

353
00:15:17,281 --> 00:15:19,308
passing on that tree and I could suppose

354
00:15:19,308 --> 00:15:22,334
I could do that perfectly, everything is

355
00:15:22,334 --> 00:15:24,358
linear gaussian, then I get perfect

356
00:15:24,358 --> 00:15:26,374
Bayesian inference.

357
00:15:27,380 --> 00:15:28,394
There is no approximation.

358
00:15:28,395 --> 00:15:30,413
So this is a good assumption.

359
00:15:30,415 --> 00:15:33,446
Sometimes it's still very hard to compute

360
00:15:33,446 --> 00:15:36,471
a message because even the single

361
00:15:36,471 --> 00:15:39,500
messages that come out of these nodes,

362
00:15:39,500 --> 00:15:41,529
they're still integrals or summations,

363
00:15:41,529 --> 00:15:45,559
and in particular the integrals may be a

364
00:15:45,559 --> 00:15:46,569
problem.

365
00:15:46,570 --> 00:15:48,592
We may not have an analytical answer.

366
00:15:48,594 --> 00:15:52,634
So what we sometimes do is add additional

367
00:15:52,634 --> 00:15:53,647
assumptions.

368
00:15:53,648 --> 00:15:56,676
We'll say, well, the posterior belief

369
00:15:56,676 --> 00:15:59,705
over FD, I can't compute it in general,

370
00:15:59,705 --> 00:16:02,676
but I'm going to just assume now that it'

371
00:16:02,676 --> 00:16:05,702
's a gaussian that makes it easier.

372
00:16:05,704 --> 00:16:09,740
Or we can make an extra factorization

373
00:16:09,740 --> 00:16:12,777
assumption and say the posterior belief

374
00:16:12,777 --> 00:16:16,814
over FB, which is really a belief over

375
00:16:16,814 --> 00:16:20,851
the joint x one, x two, x four is going

376
00:16:20,851 --> 00:16:24,890
to be broken into independent belief over

377
00:16:24,890 --> 00:16:28,933
x one and belief over x two and x four.

378
00:16:30,957 --> 00:16:33,988
These additional assumptions, if I impose

379
00:16:33,988 --> 00:16:36,016
them as well, this is what I recall.

380
00:16:36,017 --> 00:16:40,049
Now, if I all substituted here in Q of x,

381
00:16:40,049 --> 00:16:43,080
I get what's called a constrained beth

382
00:16:43,080 --> 00:16:44,091
free energy.

383
00:16:44,093 --> 00:16:46,111
This is the same Beth as in the

384
00:16:46,111 --> 00:16:47,123
Oppenheimer movie.

385
00:16:47,123 --> 00:16:50,149
This is Hans Bethe, where it's named

386
00:16:50,149 --> 00:16:50,155
after.

387
00:16:53,186 --> 00:16:57,226
We have a graph now that is highly

388
00:16:57,226 --> 00:17:02,214
factorized and we have local beliefs over

389
00:17:02,214 --> 00:17:07,262
notes and over and they're indicated with

390
00:17:07,262 --> 00:17:12,310
red and we have additional constraints in

391
00:17:12,310 --> 00:17:13,322
green.

392
00:17:13,323 --> 00:17:15,344
They could be Gaussians or mean field

393
00:17:15,344 --> 00:17:17,363
constraints or other constraints.

394
00:17:17,364 --> 00:17:19,384
And now we will assume constraints that

395
00:17:19,384 --> 00:17:21,402
make it possible to compute all the

396
00:17:21,402 --> 00:17:21,407
messages.

397
00:17:21,408 --> 00:17:23,429
And now we can just automate this by

398
00:17:23,429 --> 00:17:25,447
making different assumptions.

399
00:17:25,448 --> 00:17:28,477
We can turn this into expectation

400
00:17:28,477 --> 00:17:32,510
maximization or belief propagation or

401
00:17:32,510 --> 00:17:34,530
hybrid forms thereof.

402
00:17:34,531 --> 00:17:36,552
We can turn it into any relevant message

403
00:17:36,552 --> 00:17:38,574
passing algorithm that you've heard of.

404
00:17:38,575 --> 00:17:41,604
So this is a very nice umbrella framework

405
00:17:41,604 --> 00:17:44,631
that basically encompasses everything.

406
00:17:46,650 --> 00:17:49,681
We've written a pretty large paper on

407
00:17:49,681 --> 00:17:52,716
this in the Entropy Journal where you can

408
00:17:52,716 --> 00:17:55,748
read all the math on how this works.

409
00:17:57,763 --> 00:18:00,733
So we've talked about why message passing,

410
00:18:00,733 --> 00:18:03,760
, namely because it's the most effective

411
00:18:03,760 --> 00:18:04,776
way of doing inference.

412
00:18:04,777 --> 00:18:07,803
And we've talked about which messages to

413
00:18:07,803 --> 00:18:09,829
compute, namely we turn our variational

414
00:18:09,829 --> 00:18:12,852
free energy into something called a

415
00:18:12,852 --> 00:18:14,878
constraint, better free energy and then

416
00:18:14,878 --> 00:18:16,897
we can compute messages.

417
00:18:16,898 --> 00:18:20,929
The only thing that's left is, well, when

418
00:18:20,929 --> 00:18:22,950
do we pass these messages?

419
00:18:22,952 --> 00:18:23,969
What is the sequence of messages?

420
00:18:23,969 --> 00:18:25,984
Which one comes first?

421
00:18:25,988 --> 00:18:29,002
And this is where we see a lot of papers,

422
00:18:29,002 --> 00:18:30,003
right?

423
00:18:31,004 --> 00:18:33,006
You have to write control flow, what's

424
00:18:33,006 --> 00:18:34,007
called control flow.

425
00:18:34,007 --> 00:18:36,009
You have to say, okay, here is my

426
00:18:36,009 --> 00:18:38,011
algorithm for active inference.

427
00:18:38,011 --> 00:18:40,013
First I specify a model.

428
00:18:40,013 --> 00:18:43,016
Then let's do inference for every time

429
00:18:43,016 --> 00:18:45,018
step, collect a new observation, update

430
00:18:45,018 --> 00:18:48,021
the state, update the desired future, and

431
00:18:48,021 --> 00:18:51,024
so forth, compute expected free energy,

432
00:18:51,024 --> 00:18:53,026
select the policy, et cetera.

433
00:18:55,028 --> 00:18:57,030
This kind of program.

434
00:18:57,030 --> 00:19:00,027
The problem with active inferences is

435
00:19:00,027 --> 00:19:02,029
that there is nested for loops in here.

436
00:19:02,029 --> 00:19:05,032
Here's a for loop, and here's another for

437
00:19:05,032 --> 00:19:05,032
loop.

438
00:19:05,032 --> 00:19:08,035
And for each of these policies, I'm going

439
00:19:08,035 --> 00:19:10,037
to have to go into the future, so I'm

440
00:19:10,037 --> 00:19:12,039
going to have another time loop.

441
00:19:12,039 --> 00:19:14,041
So it is for loops, in for loops, in for

442
00:19:14,041 --> 00:19:15,042
loops.

443
00:19:15,042 --> 00:19:18,045
This will completely explode in terms of

444
00:19:18,045 --> 00:19:20,047
computational complexity.

445
00:19:20,047 --> 00:19:23,050
So as a result, some very clever people

446
00:19:23,050 --> 00:19:25,052
have written very clever algorithms of

447
00:19:25,052 --> 00:19:27,054
doing this much faster.

448
00:19:27,054 --> 00:19:30,057
Sophisticated inference, branching time

449
00:19:30,057 --> 00:19:33,060
active inference, dynamic programming EFE

450
00:19:33,060 --> 00:19:36,063
are recent proposals for doing this very

451
00:19:36,063 --> 00:19:36,063
clever.

452
00:19:37,064 --> 00:19:40,067
In the end, all of these proposals come

453
00:19:40,067 --> 00:19:44,071
down to a particular just a message

454
00:19:44,071 --> 00:19:46,073
passing schedule.

455
00:19:47,074 --> 00:19:49,076
Once we commit to message passing on the

456
00:19:49,076 --> 00:19:51,078
graph as our inference procedure, it's

457
00:19:51,078 --> 00:19:53,080
the only thing that's going on.

458
00:19:54,080 --> 00:19:56,083
And all of this sophisticated inference

459
00:19:56,083 --> 00:20:00,081
and branching time active inference, all

460
00:20:00,081 --> 00:20:02,083
it does is it schedules the messages.

461
00:20:02,083 --> 00:20:04,085
It says first this message, then this

462
00:20:04,085 --> 00:20:06,087
message, then this message.

463
00:20:06,087 --> 00:20:09,090
I don't mean that as a slight to these

464
00:20:09,090 --> 00:20:10,091
algorithms.

465
00:20:10,091 --> 00:20:11,092
They're very clever.

466
00:20:11,092 --> 00:20:13,094
And as we've seen in the presentation by

467
00:20:13,094 --> 00:20:16,097
Aswin Paul, you get huge improvements if

468
00:20:16,097 --> 00:20:17,098
you go from regular inference to

469
00:20:17,098 --> 00:20:19,100
sophisticated inference.

470
00:20:19,100 --> 00:20:22,103
But it's good to realize that these

471
00:20:22,103 --> 00:20:25,106
algorithms just specify in a graph which

472
00:20:25,106 --> 00:20:28,109
message comes after which message.

473
00:20:29,110 --> 00:20:35,116
So here's an example of a graph and a

474
00:20:35,116 --> 00:20:38,119
message sequence.

475
00:20:38,119 --> 00:20:41,122
Here's message one, then message two, and

476
00:20:41,122 --> 00:20:44,125
message three goes up, and then we go

477
00:20:44,125 --> 00:20:46,127
from FC to FF, and here's message five,

478
00:20:46,127 --> 00:20:48,129
and then we go to Fe.

479
00:20:48,129 --> 00:20:51,132
And this could correspond this sequence

480
00:20:51,132 --> 00:20:53,134
to dynamic time programming EFE or

481
00:20:53,134 --> 00:20:55,136
sophisticated inference.

482
00:20:56,137 --> 00:20:59,140
There are a couple of problems with this

483
00:20:59,140 --> 00:21:02,137
approach, which basically with having the

484
00:21:02,137 --> 00:21:05,140
user to specify a clever algorithm, first

485
00:21:05,140 --> 00:21:07,142
of all, you have to be a specialist to do

486
00:21:07,142 --> 00:21:08,143
it right.

487
00:21:08,143 --> 00:21:10,145
Only these are very clever people.

488
00:21:11,146 --> 00:21:14,149
That means that if we let it leave it to

489
00:21:14,149 --> 00:21:17,152
say to an engineer in a company, well, it'

490
00:21:17,152 --> 00:21:21,156
's a high probability he's not going to

491
00:21:21,156 --> 00:21:22,157
get it right.

492
00:21:22,157 --> 00:21:23,158
That's very unfortunate.

493
00:21:24,159 --> 00:21:27,162
But there is another issue, and that is

494
00:21:27,162 --> 00:21:30,165
that in a sense, it's a global variable

495
00:21:30,165 --> 00:21:32,167
in the message passing schedule.

496
00:21:32,167 --> 00:21:35,170
All nodes are visited, because if a node

497
00:21:35,170 --> 00:21:37,172
would not be visited, then we shouldn't

498
00:21:37,172 --> 00:21:39,174
have it in the graph.

499
00:21:39,174 --> 00:21:42,177
And that means if one node crashes,

500
00:21:42,177 --> 00:21:45,179
basically the message passing schedule is

501
00:21:45,179 --> 00:21:45,180
invalid.

502
00:21:45,180 --> 00:21:47,182
I have to reset my system.

503
00:21:48,183 --> 00:21:50,185
And if you fly a drone, if it's deployed

504
00:21:50,185 --> 00:21:52,187
and it's out in the field and a node

505
00:21:52,187 --> 00:21:55,190
crashes, a transistor burns out, and I

506
00:21:55,190 --> 00:21:57,192
have to totally reset now my system, I

507
00:21:57,192 --> 00:21:59,194
have to compute a new message passing

508
00:21:59,194 --> 00:22:00,189
schedule.

509
00:22:01,190 --> 00:22:03,192
Then you're not doing inference and your

510
00:22:03,192 --> 00:22:05,194
drone flies into the wall.

511
00:22:05,194 --> 00:22:07,196
So this is not robust.

512
00:22:07,196 --> 00:22:11,200
And it also for the same reason we may

513
00:22:11,200 --> 00:22:14,203
actually want to take out a node.

514
00:22:15,204 --> 00:22:18,207
We may want to prune a node, we want to

515
00:22:18,207 --> 00:22:20,209
do structural adaptation.

516
00:22:20,209 --> 00:22:23,212
And we can't do structural adaptation

517
00:22:23,212 --> 00:22:25,214
because we have to reset the system,

518
00:22:25,214 --> 00:22:28,217
recompute a message passing schedule.

519
00:22:28,217 --> 00:22:31,220
So this procedural style where an

520
00:22:31,220 --> 00:22:34,223
engineer specifies which message comes

521
00:22:34,223 --> 00:22:38,227
after this message has some disadvantages.

522
00:22:38,227 --> 00:22:38,227
.

523
00:22:38,227 --> 00:22:39,228
It's not very robust.

524
00:22:40,229 --> 00:22:42,231
And if you want to do it very clever, you

525
00:22:42,231 --> 00:22:45,234
have to be really a specialist.

526
00:22:45,234 --> 00:22:48,237
So a better system is what we call

527
00:22:48,237 --> 00:22:51,240
reactive message passing.

528
00:22:51,240 --> 00:22:55,244
And it's very related to what was in the

529
00:22:55,244 --> 00:22:59,248
first session called the actor model.

530
00:22:59,248 --> 00:23:02,245
Keith Duggar had a nice presentation on

531
00:23:02,245 --> 00:23:03,246
the actor model.

532
00:23:03,246 --> 00:23:07,249
So what we will do is we will say we will

533
00:23:07,249 --> 00:23:09,252
not have a global message passing

534
00:23:09,252 --> 00:23:10,253
schedule.

535
00:23:10,253 --> 00:23:13,256
The engineer will not specify anything

536
00:23:13,256 --> 00:23:14,257
anymore.

537
00:23:14,257 --> 00:23:17,260
The inference code that an engineer will

538
00:23:17,260 --> 00:23:19,262
have to write is just say, react to any

539
00:23:19,262 --> 00:23:22,265
free energy minimization opportunity.

540
00:23:22,265 --> 00:23:24,267
In other words, there is no inference

541
00:23:24,267 --> 00:23:24,267
code.

542
00:23:24,267 --> 00:23:26,269
It's completely automated.

543
00:23:27,269 --> 00:23:30,273
And we will replace this global message

544
00:23:30,273 --> 00:23:33,276
passing schedule by local triggering

545
00:23:33,276 --> 00:23:35,278
inside the node.

546
00:23:35,278 --> 00:23:38,281
So each node is now just an autonomous

547
00:23:38,281 --> 00:23:41,283
system that's interested in minimizing

548
00:23:41,283 --> 00:23:42,285
its free energy.

549
00:23:42,285 --> 00:23:45,288
It can do so by sending out messages.

550
00:23:46,289 --> 00:23:48,291
And when will it do so?

551
00:23:48,291 --> 00:23:50,293
Well, it receives messages, and then when

552
00:23:50,293 --> 00:23:53,296
it looks at these messages and it feels

553
00:23:53,296 --> 00:23:55,298
like, oh, there is an opportunity for me

554
00:23:55,298 --> 00:23:57,300
to minimize free energy by or expected

555
00:23:57,300 --> 00:23:59,302
free energy energy by sending out a

556
00:23:59,302 --> 00:24:00,297
message.

557
00:24:00,297 --> 00:24:03,300
Then we'll send out a message and each

558
00:24:03,300 --> 00:24:06,303
node will do so by itself asynchronously

559
00:24:06,303 --> 00:24:08,305
so you get parallel distributed

560
00:24:08,305 --> 00:24:11,308
processing, or concurrent processing, as

561
00:24:11,308 --> 00:24:12,309
Keith called it.

562
00:24:13,310 --> 00:24:17,314
In principle, you could play this game on

563
00:24:17,314 --> 00:24:20,317
many computers at the same time, and so

564
00:24:20,317 --> 00:24:23,320
you get tremendous advantages.

565
00:24:25,322 --> 00:24:27,324
First of all, you don't have to write

566
00:24:27,324 --> 00:24:28,325
difficult code.

567
00:24:28,325 --> 00:24:31,328
Second of all, you can do multithreading

568
00:24:31,328 --> 00:24:34,331
or you can run it on multiple computers

569
00:24:34,331 --> 00:24:35,332
at the same time.

570
00:24:37,334 --> 00:24:41,338
And there's also robustness advantages

571
00:24:41,338 --> 00:24:44,341
because if a node crashes, then there's

572
00:24:44,341 --> 00:24:48,345
nothing that stops the system from just

573
00:24:48,345 --> 00:24:51,348
finding another path, right?

574
00:24:51,348 --> 00:24:54,351
If this node crashes, this path from here'

575
00:24:54,351 --> 00:24:57,354
's message three, this path now doesn't

576
00:24:57,354 --> 00:24:57,354
work.

577
00:24:57,354 --> 00:25:01,352
So I cannot send anything to Fe anymore

578
00:25:01,352 --> 00:25:02,353
from X.

579
00:25:02,353 --> 00:25:04,355
Well, then I just sent a new message here.

580
00:25:04,355 --> 00:25:04,355
.

581
00:25:04,355 --> 00:25:05,356
Why not?

582
00:25:05,356 --> 00:25:08,359
It's like when water falls down a

583
00:25:08,359 --> 00:25:11,362
mountain and it zigzags its way down into

584
00:25:11,362 --> 00:25:14,365
the value and you halfway put up an

585
00:25:14,365 --> 00:25:15,366
obstruction.

586
00:25:15,366 --> 00:25:18,369
It just finds another path, not the

587
00:25:18,369 --> 00:25:20,371
preferred path.

588
00:25:20,371 --> 00:25:22,373
This has to find, well, the second best

589
00:25:22,373 --> 00:25:25,376
path, because the first path has been

590
00:25:25,376 --> 00:25:26,377
obstructed, right?

591
00:25:26,377 --> 00:25:28,379
And that's what's going to happen in this

592
00:25:28,379 --> 00:25:29,380
system as well, right?

593
00:25:29,380 --> 00:25:31,382
That's just how nature works.

594
00:25:32,383 --> 00:25:33,384
It tries to find the best path, the

595
00:25:33,384 --> 00:25:35,386
easiest path, and if that's not available,

596
00:25:35,386 --> 00:25:37,388
, then we do the second best path.

597
00:25:37,388 --> 00:25:39,390
And that's also what you can do with

598
00:25:39,390 --> 00:25:40,391
reactive message passing.

599
00:25:40,391 --> 00:25:42,393
So you can prune nodes.

600
00:25:42,393 --> 00:25:46,397
You can do structural adaptation, and it'

601
00:25:46,397 --> 00:25:48,399
's far more robust.

602
00:25:48,399 --> 00:25:52,403
And you can also do chance encounters

603
00:25:52,403 --> 00:25:56,406
with other drones, right?

604
00:25:56,407 --> 00:25:57,408
Drones that get close can start

605
00:25:57,408 --> 00:26:00,405
communicating with each other, and when

606
00:26:00,405 --> 00:26:02,407
they fire away, they stop communicating

607
00:26:02,407 --> 00:26:03,408
with each other.

608
00:26:03,408 --> 00:26:07,412
And this is no problem, because you can

609
00:26:07,412 --> 00:26:11,416
basically change who change nodes can

610
00:26:11,416 --> 00:26:15,420
change on the fly, who they communicate

611
00:26:15,420 --> 00:26:18,423
to and who they want to listen to.

612
00:26:20,425 --> 00:26:24,429
That's the way nature works, and also how

613
00:26:24,429 --> 00:26:27,432
it works when we do reactive programming

614
00:26:27,432 --> 00:26:29,434
and reactive message passing.

615
00:26:29,434 --> 00:26:33,438
So, in summary, we're interested in

616
00:26:33,438 --> 00:26:37,442
automating inference, in active inference

617
00:26:37,442 --> 00:26:38,443
agents, right?

618
00:26:39,444 --> 00:26:42,446
Because it's an operation that's

619
00:26:42,446 --> 00:26:44,449
basically only for experts.

620
00:26:44,449 --> 00:26:47,452
And this active inference technology is

621
00:26:47,452 --> 00:26:50,455
not going to be successful unless we get

622
00:26:50,455 --> 00:26:53,458
more people, let's say, democracies it,

623
00:26:53,458 --> 00:26:57,462
and we get competent engineers being able

624
00:26:57,462 --> 00:26:59,464
to develop good agents, right?

625
00:26:59,464 --> 00:27:02,461
You shouldn't have to be a top specialist

626
00:27:02,461 --> 00:27:04,463
in the world to develop an active

627
00:27:04,463 --> 00:27:05,464
inference agent.

628
00:27:05,464 --> 00:27:08,467
Now, in order to automate inference, you

629
00:27:08,467 --> 00:27:11,470
must do message passing, and I've talked

630
00:27:11,470 --> 00:27:13,472
about that for efficiency.

631
00:27:13,472 --> 00:27:15,474
I've also talked about which messages to

632
00:27:15,474 --> 00:27:16,475
pass.

633
00:27:16,475 --> 00:27:19,478
Not necessarily do you have to follow

634
00:27:19,478 --> 00:27:22,481
this framework, but constrained better

635
00:27:22,481 --> 00:27:25,484
Free energy framework is very convenient.

636
00:27:25,484 --> 00:27:25,484
.

637
00:27:25,484 --> 00:27:30,489
It's an umbrella framework that basically

638
00:27:30,489 --> 00:27:34,493
goes over all the interesting other

639
00:27:34,493 --> 00:27:37,496
message passing computations.

640
00:27:37,496 --> 00:27:39,498
When message passing, reactive message

641
00:27:39,498 --> 00:27:42,501
passing, it's fully automated, so you don'

642
00:27:42,501 --> 00:27:44,503
't have to write any code anymore.

643
00:27:44,503 --> 00:27:47,506
In principle, you can do parallel

644
00:27:47,506 --> 00:27:49,508
distributed processing.

645
00:27:49,508 --> 00:27:50,509
It's robust structural changes.

646
00:27:50,509 --> 00:27:52,511
You can learn new inference pathways.

647
00:27:52,511 --> 00:27:55,514
So lots of advantages here.

648
00:27:56,515 --> 00:27:59,518
Now, how do we do it?

649
00:27:59,518 --> 00:28:02,515
I like to introduce a toolbox that we've

650
00:28:02,515 --> 00:28:05,518
been working on called ARX infer.

651
00:28:05,518 --> 00:28:08,521
And we do that with my lab here at the

652
00:28:08,521 --> 00:28:09,522
university.

653
00:28:09,522 --> 00:28:11,524
I'm here in Eindhoven in the south of the

654
00:28:11,524 --> 00:28:13,526
Netherlands, and we have a lab.

655
00:28:13,526 --> 00:28:15,528
The lab is called BIS lab.

656
00:28:15,528 --> 00:28:17,530
Here are postdocs and assistant

657
00:28:17,530 --> 00:28:20,533
professors and PhD students, and we've

658
00:28:20,533 --> 00:28:24,537
been working on this for many years.

659
00:28:24,537 --> 00:28:29,541
And some of these, like Albert and Ismail

660
00:28:29,541 --> 00:28:33,546
and Tyce, have written dissertations.

661
00:28:34,547 --> 00:28:36,549
And our best work, we have consolidated

662
00:28:36,549 --> 00:28:38,551
that in a toolbox.

663
00:28:39,551 --> 00:28:41,554
And the toolbox is called Arcs infer.

664
00:28:41,554 --> 00:28:43,556
And if you want to have a look, you can

665
00:28:43,556 --> 00:28:45,558
go to the website, arcsinfer.

666
00:28:45,558 --> 00:28:46,559
ML.

667
00:28:46,559 --> 00:28:51,564
And Arctinfur works in the way that I've

668
00:28:51,564 --> 00:28:53,565
just discussed.

669
00:28:53,566 --> 00:28:54,567
It does message passing.

670
00:28:54,567 --> 00:28:56,569
It tries to minimize constraint, better

671
00:28:56,569 --> 00:28:57,570
free energy.

672
00:28:57,570 --> 00:29:00,567
That means it can come up with all kinds

673
00:29:00,567 --> 00:29:02,569
of message passing algorithms.

674
00:29:04,571 --> 00:29:07,574
It will do it in a reactive way, and it

675
00:29:07,574 --> 00:29:09,576
will try to do it in real time and low

676
00:29:09,576 --> 00:29:12,579
power and all the KPIs that we're talking

677
00:29:12,579 --> 00:29:12,579
about.

678
00:29:12,579 --> 00:29:16,583
Now, it's, of course, not done, but it's

679
00:29:16,583 --> 00:29:19,586
functional and like to show some demos.

680
00:29:19,586 --> 00:29:22,589
And I will leave it to Dimitri and Bart,

681
00:29:22,589 --> 00:29:26,593
who are two advanced PhD students in my

682
00:29:26,593 --> 00:29:28,595
lab to show the demos.

683
00:29:30,597 --> 00:29:34,601
So I'm going to stop sharing.

684
00:29:37,604 --> 00:29:38,605
Daniel: Awesome.

685
00:29:38,605 --> 00:29:39,606
Thank you, Bert.

686
00:29:39,606 --> 00:29:40,607
Great talk.

687
00:29:40,607 --> 00:29:40,607
Bert: Sure.

688
00:29:42,609 --> 00:29:43,610
Dmitry: Can you hear?

689
00:29:43,610 --> 00:29:44,611
Bert: Yeah.

690
00:29:44,611 --> 00:29:44,611
Yeah.

691
00:29:45,612 --> 00:29:45,612
Dmitry: Okay.

692
00:29:45,612 --> 00:29:48,614
I will try to share my screen.

693
00:29:48,615 --> 00:29:48,615
Bert: Okay.

694
00:29:50,616 --> 00:29:51,618
Dmitry: So you should see it now.

695
00:29:52,619 --> 00:29:53,620
Daniel: Looks good.

696
00:29:53,620 --> 00:29:57,623
Dmitry: Okay, so, yeah, hello to everyone,

697
00:29:57,623 --> 00:29:57,624
, I'm Dmitry

698
00:29:57,624 --> 00:30:00,621
Bagaev. So I'm a PhD student in Bioslab

699
00:30:00,621 --> 00:30:03,624
in Einhoven University of Technology, and

700
00:30:03,624 --> 00:30:06,627
yes, I have a small presentation about

701
00:30:06,627 --> 00:30:09,630
actual software developments in so over

702
00:30:09,630 --> 00:30:12,633
the past few years, we have significantly

703
00:30:12,633 --> 00:30:14,635
improved our tools.

704
00:30:14,635 --> 00:30:16,637
And basically my entire PhD was dedicated

705
00:30:16,637 --> 00:30:19,640
to implement this idea, which Beard was

706
00:30:19,640 --> 00:30:21,642
talking about, like implementing the

707
00:30:21,642 --> 00:30:23,644
variation of reactive message passing.

708
00:30:23,644 --> 00:30:26,647
And in this presentation, I just want to

709
00:30:26,647 --> 00:30:28,649
show you what you can actually do using

710
00:30:28,649 --> 00:30:30,651
this theory under the hood.

711
00:30:31,652 --> 00:30:34,655
Okay, so basically, in order to automate

712
00:30:34,655 --> 00:30:36,657
active inference, we need to automate

713
00:30:36,657 --> 00:30:37,658
Bayesian inference.

714
00:30:37,658 --> 00:30:40,661
And we have already a lot of solutions

715
00:30:40,661 --> 00:30:44,664
for that, such as Pyro NumPy, which is

716
00:30:44,664 --> 00:30:46,667
funded by Google, Info.

717
00:30:46,667 --> 00:30:48,669
Net is funded by Microsoft, turing is in

718
00:30:48,669 --> 00:30:50,671
July, PIMC, and many, many.

719
00:30:51,672 --> 00:30:54,675
And basically these solutions are really

720
00:30:54,675 --> 00:30:56,677
good and they're really good at

721
00:30:56,677 --> 00:30:57,678
prototyping as well.

722
00:30:57,678 --> 00:31:00,675
But our goal is eventually to be able to

723
00:31:00,675 --> 00:31:03,678
deploy these kind of systems, not just

724
00:31:03,678 --> 00:31:04,679
prototype.

725
00:31:04,679 --> 00:31:06,681
And we are really focusing on these

726
00:31:06,681 --> 00:31:08,683
particular properties for this automated

727
00:31:08,683 --> 00:31:09,684
Bayesian inference.

728
00:31:10,685 --> 00:31:13,688
So it must be low power, adaptive, real

729
00:31:13,688 --> 00:31:14,689
time scalable.

730
00:31:14,689 --> 00:31:17,692
It also must be user friendly at the end

731
00:31:17,692 --> 00:31:19,694
and must support a large scope of models

732
00:31:19,694 --> 00:31:21,696
if we want it to be useful.

733
00:31:23,698 --> 00:31:26,701
In Bioslab, we want to build such a

734
00:31:26,701 --> 00:31:30,705
software with such nice properties and it'

735
00:31:30,705 --> 00:31:33,708
's always about trade offs, right?

736
00:31:33,708 --> 00:31:34,709
So we do something better in one

737
00:31:34,709 --> 00:31:36,711
particular domain and maybe other

738
00:31:36,711 --> 00:31:38,713
software libraries, they might be better

739
00:31:38,713 --> 00:31:41,716
in a different domain, but we are really

740
00:31:41,716 --> 00:31:43,718
focusing on this particular property.

741
00:31:44,719 --> 00:31:46,721
And so, yes, I will reiterate a little

742
00:31:46,721 --> 00:31:47,722
bit Bert's presentation.

743
00:31:47,722 --> 00:31:49,724
So how do we achieve this?

744
00:31:49,724 --> 00:31:51,726
So imagine we have an environment and we

745
00:31:51,726 --> 00:31:54,729
have an agent, and the agent takes some

746
00:31:54,729 --> 00:31:57,732
actions and the agent basically what he

747
00:31:57,732 --> 00:32:00,729
needs is to come up with some sort of

748
00:32:00,729 --> 00:32:02,731
good enough probabilistic model of its

749
00:32:02,731 --> 00:32:05,734
environment in order to do patient

750
00:32:05,734 --> 00:32:06,735
inference.

751
00:32:06,735 --> 00:32:09,738
And in our framework, we encode the model

752
00:32:09,738 --> 00:32:12,741
as a factor graph, which not only models

753
00:32:12,741 --> 00:32:15,744
the observations, but also actions and

754
00:32:15,744 --> 00:32:16,745
desired future.

755
00:32:17,746 --> 00:32:20,749
And this approach allows us to decompose

756
00:32:20,749 --> 00:32:23,752
these complex relationships between

757
00:32:23,752 --> 00:32:26,755
variables and hidden states into some

758
00:32:26,755 --> 00:32:29,758
kind of structure and local blocks.

759
00:32:29,758 --> 00:32:32,761
And it's not a black box anymore.

760
00:32:33,762 --> 00:32:35,764
And the model itself may have some sort

761
00:32:35,764 --> 00:32:38,767
of background motivation interpretation.

762
00:32:38,767 --> 00:32:41,770
It may encode your prior knowledge about

763
00:32:41,770 --> 00:32:43,772
some particular physical system and the

764
00:32:43,772 --> 00:32:46,775
locality of these blocks basically allows

765
00:32:46,775 --> 00:32:49,778
you to scale to millions of variables and

766
00:32:49,778 --> 00:32:50,779
hidden states.

767
00:32:50,779 --> 00:32:53,782
It allows you to pre optimize it maybe,

768
00:32:53,782 --> 00:32:55,784
or maybe use some sort of different

769
00:32:55,784 --> 00:32:57,786
approximation strategies in different

770
00:32:57,786 --> 00:32:58,787
places.

771
00:32:58,787 --> 00:33:01,784
So it allows a lot of very nice

772
00:33:01,784 --> 00:33:03,786
properties as well.

773
00:33:03,786 --> 00:33:05,788
And we use reactive message passing to

774
00:33:05,788 --> 00:33:08,791
run actual variational Bayesian inference.

775
00:33:08,791 --> 00:33:08,791
.

776
00:33:09,792 --> 00:33:11,794
It uses reactive programming under the

777
00:33:11,794 --> 00:33:13,796
hood to minimize the approximation to the

778
00:33:13,796 --> 00:33:15,798
variational free energy.

779
00:33:15,798 --> 00:33:18,801
And yes, as Bert also mentioned, it's

780
00:33:18,801 --> 00:33:20,803
very much related to actor model.

781
00:33:22,805 --> 00:33:25,808
And basically in Ariks and fur.

782
00:33:25,808 --> 00:33:27,810
You can think of different nodes as

783
00:33:27,810 --> 00:33:30,813
actors themselves and they have basically

784
00:33:30,813 --> 00:33:32,815
one single purpose is to send a

785
00:33:32,815 --> 00:33:35,818
variational message that minimizes free

786
00:33:35,818 --> 00:33:36,819
energy.

787
00:33:36,819 --> 00:33:38,821
This is a very short and very high level

788
00:33:38,821 --> 00:33:40,823
description, but it is essentially what

789
00:33:40,823 --> 00:33:42,825
is happening under lipid.

790
00:33:42,825 --> 00:33:45,828
So we are not treating different agents

791
00:33:45,828 --> 00:33:48,831
which interact with each other as actors,

792
00:33:48,831 --> 00:33:50,833
but we also treat the actual components

793
00:33:50,833 --> 00:33:53,836
of the underlying model as actors

794
00:33:53,836 --> 00:33:54,837
themselves.

795
00:33:54,837 --> 00:33:56,839
It's like a very hierarchical structure.

796
00:33:56,839 --> 00:34:01,838
So this is the main central idea of this

797
00:34:01,838 --> 00:34:02,839
inference.

798
00:34:03,840 --> 00:34:06,843
So here for example, first example, we

799
00:34:06,843 --> 00:34:09,846
can do an inference in a dynamical system.

800
00:34:09,846 --> 00:34:09,846
.

801
00:34:10,847 --> 00:34:12,849
This example, which is quite old already,

802
00:34:12,849 --> 00:34:14,851
I think it's like two years ago.

803
00:34:14,851 --> 00:34:16,853
So we track a position of the object

804
00:34:16,853 --> 00:34:19,856
given some noisy measurements which are

805
00:34:19,856 --> 00:34:22,859
indicated by green dots, the actual real

806
00:34:22,859 --> 00:34:24,861
signal, we cannot observe it, but we just

807
00:34:24,861 --> 00:34:25,862
can plot.

808
00:34:25,862 --> 00:34:28,865
It is shown as blue and the inferred

809
00:34:28,865 --> 00:34:31,868
signal is shown as red and the data set

810
00:34:31,868 --> 00:34:32,869
is infinite.

811
00:34:32,869 --> 00:34:34,871
The inference end just reacts on it and

812
00:34:34,871 --> 00:34:36,873
does not assume any particular data size.

813
00:34:36,873 --> 00:34:36,873
.

814
00:34:37,874 --> 00:34:39,876
Simply reacts in your observation as soon

815
00:34:39,876 --> 00:34:40,876
as possible.

816
00:34:40,877 --> 00:34:43,880
Yeah, I'm actually not sure how smoothly

817
00:34:43,880 --> 00:34:44,881
Zoom shares my screen.

818
00:34:45,882 --> 00:34:47,884
Maybe you can see it's a bit lagging in

819
00:34:47,884 --> 00:34:49,886
the animations, I'm not sure because

820
00:34:49,886 --> 00:34:51,888
maybe zoom does not share it on a full

821
00:34:51,888 --> 00:34:52,889
frame rate.

822
00:34:53,890 --> 00:34:55,892
And also on the right hand side you can

823
00:34:55,892 --> 00:34:58,895
see how we define models in our framework.

824
00:34:58,895 --> 00:34:58,895
.

825
00:34:59,895 --> 00:35:01,892
We use Julia as a programming language.

826
00:35:02,893 --> 00:35:04,895
Basically, this is everything that you

827
00:35:04,895 --> 00:35:06,897
need to define this particular model and

828
00:35:06,897 --> 00:35:08,899
run inference on a data set.

829
00:35:08,899 --> 00:35:11,902
And actually I literally spent more days

830
00:35:11,902 --> 00:35:14,905
to plot it instead of inference.

831
00:35:14,905 --> 00:35:17,908
So inference was an easiest part for me,

832
00:35:17,908 --> 00:35:20,911
plotting was way much harder to relate to

833
00:35:20,911 --> 00:35:21,912
user friendliness.

834
00:35:23,914 --> 00:35:25,916
And we actually have plans to improve our

835
00:35:25,916 --> 00:35:27,918
model specification language, make it

836
00:35:27,918 --> 00:35:28,919
even easier.

837
00:35:28,919 --> 00:35:30,921
So now for technical reasons, we have

838
00:35:30,921 --> 00:35:33,924
some auxiliary statements in the model

839
00:35:33,924 --> 00:35:35,926
specification language, but we are

840
00:35:35,926 --> 00:35:38,929
working to improve that and make it even

841
00:35:38,929 --> 00:35:38,929
easier.

842
00:35:41,932 --> 00:35:43,934
This is another example which is similar

843
00:35:43,934 --> 00:35:45,936
to the previous one, that uses much more

844
00:35:45,936 --> 00:35:47,938
complex and linear dynamical system of

845
00:35:47,938 --> 00:35:49,940
the double pendulum.

846
00:35:49,940 --> 00:35:51,942
And the system is chaotic and we can

847
00:35:51,942 --> 00:35:54,945
observe only a small part of it with a

848
00:35:54,945 --> 00:35:56,947
lot of noise, also indicated as a green

849
00:35:56,947 --> 00:35:57,948
dots.

850
00:35:58,949 --> 00:36:01,946
And nevertheless, given good enough model,

851
00:36:01,946 --> 00:36:04,949
, you can infer the other hidden states

852
00:36:04,949 --> 00:36:08,953
with pretty much high precision and the

853
00:36:08,953 --> 00:36:11,956
code needed for that is also relatively

854
00:36:11,956 --> 00:36:12,957
short.

855
00:36:15,960 --> 00:36:18,963
We also have examples with active

856
00:36:18,963 --> 00:36:21,966
inference agents that interact with their

857
00:36:21,966 --> 00:36:22,967
environment.

858
00:36:23,968 --> 00:36:28,973
So the left up shows mountain car problem,

859
00:36:28,973 --> 00:36:31,976
, very famous problem.

860
00:36:31,976 --> 00:36:33,978
The left bottom side shows an active

861
00:36:33,978 --> 00:36:36,981
inference agent which tries to control

862
00:36:36,981 --> 00:36:39,984
the inverted pendulum from falling in the

863
00:36:39,984 --> 00:36:41,986
windy conditions it reacts in wind.

864
00:36:42,987 --> 00:36:44,989
We also have a demo of an agent that

865
00:36:44,989 --> 00:36:47,992
controls a pendulum in an ever changing

866
00:36:47,992 --> 00:36:48,993
environment.

867
00:36:48,993 --> 00:36:51,996
So on the right side you see a pendulum

868
00:36:51,996 --> 00:36:54,999
with an engine and engine has limited

869
00:36:54,999 --> 00:36:55,000
power and.

870
00:36:55,000 --> 00:36:57,002
The agent itself needs to reach the goal

871
00:36:57,002 --> 00:37:00,999
and the goal is indicated as a red circle.

872
00:37:00,999 --> 00:37:00,999
.

873
00:37:02,001 --> 00:37:04,003
Basically, in this demo we can change the

874
00:37:04,003 --> 00:37:06,005
environment in real time and see how the

875
00:37:06,005 --> 00:37:07,006
agent reacts.

876
00:37:07,006 --> 00:37:09,008
So we can change the mass of the pebble

877
00:37:09,008 --> 00:37:11,010
among its length or the amount of noise

878
00:37:11,010 --> 00:37:14,013
in the measurements, or we can change the

879
00:37:14,013 --> 00:37:16,015
goal, we can change maximum engine power,

880
00:37:16,015 --> 00:37:17,016
et cetera.

881
00:37:17,016 --> 00:37:20,019
So the agent will still try to infer the

882
00:37:20,019 --> 00:37:22,021
best possible course of actions in order

883
00:37:22,021 --> 00:37:25,024
to reach its goal and it just never stops

884
00:37:25,024 --> 00:37:26,025
reacting.

885
00:37:28,027 --> 00:37:30,029
It's also actually possible to restrict

886
00:37:30,029 --> 00:37:33,032
engine power such that it will not longer

887
00:37:33,032 --> 00:37:36,035
possible to reach the goal, right?

888
00:37:36,035 --> 00:37:38,037
But the agent will still try.

889
00:37:40,039 --> 00:37:42,041
We have other cool demos with smart

890
00:37:42,041 --> 00:37:45,044
navigation and collision avoidance which

891
00:37:45,044 --> 00:37:47,046
are still under active research and the

892
00:37:47,046 --> 00:37:50,049
code for them is not available publicly

893
00:37:50,049 --> 00:37:52,051
it will be soon available, but for

894
00:37:52,051 --> 00:37:55,054
example in this example we can define a

895
00:37:55,054 --> 00:37:58,057
set of agents with their boundaries and a

896
00:37:58,057 --> 00:38:00,053
set of their destinations.

897
00:38:00,053 --> 00:38:03,056
And we can see how they try to resolve

898
00:38:03,056 --> 00:38:04,057
their routes altogether.

899
00:38:07,060 --> 00:38:09,062
And we can have some static obstacles in

900
00:38:09,062 --> 00:38:10,063
the map.

901
00:38:10,063 --> 00:38:14,067
We can see how agents can find their most

902
00:38:14,067 --> 00:38:17,070
optimal path in order to reach their

903
00:38:17,070 --> 00:38:20,073
goals and avoid any possible collision.

904
00:38:21,074 --> 00:38:24,077
And it's also not necessary to have

905
00:38:24,077 --> 00:38:26,079
static obstacles, the obstacles

906
00:38:26,079 --> 00:38:28,081
themselves may move.

907
00:38:28,081 --> 00:38:30,083
So on this demo we have hundreds of

908
00:38:30,083 --> 00:38:33,086
agents that navigate through a map of

909
00:38:33,086 --> 00:38:35,088
obstacles that move from bottom to top to

910
00:38:35,088 --> 00:38:37,090
the circles or obstacles.

911
00:38:37,090 --> 00:38:40,093
And agents are depicted as small dots and

912
00:38:40,093 --> 00:38:42,095
they need to go from left to right,

913
00:38:42,095 --> 00:38:45,098
basically avoid any sort of collision.

914
00:38:47,100 --> 00:38:50,103
And as I also mentioned, we want to

915
00:38:50,103 --> 00:38:53,105
perform efficient and real time inference,

916
00:38:53,105 --> 00:38:55,108
, but we also to do it like low power,

917
00:38:55,108 --> 00:38:58,110
low performance on low performance

918
00:38:58,110 --> 00:39:00,107
devices such as Raspberry, Pi or Coolpy

919
00:39:00,107 --> 00:39:01,108
as an example.

920
00:39:02,109 --> 00:39:04,111
And we have some results of successfully

921
00:39:04,111 --> 00:39:06,113
running the Bayesian audio source

922
00:39:06,113 --> 00:39:08,115
separation, for example, on coolpy.

923
00:39:08,115 --> 00:39:12,119
So it is actually possible we try to run

924
00:39:12,119 --> 00:39:16,123
active inference agents also on Coolpy.

925
00:39:17,124 --> 00:39:20,127
So as the aforementioned inverted

926
00:39:20,127 --> 00:39:23,130
pendulum, and as I mentioned, we also

927
00:39:23,130 --> 00:39:26,133
need to have a large model scope and

928
00:39:26,133 --> 00:39:29,136
basically RICS infer has not been

929
00:39:29,136 --> 00:39:32,139
designed to solve any of the

930
00:39:32,139 --> 00:39:34,141
aforementioned problems.

931
00:39:34,141 --> 00:39:37,144
Specifically, we have a large set of

932
00:39:37,144 --> 00:39:39,146
different examples in our repository,

933
00:39:39,146 --> 00:39:41,148
different models, different data,

934
00:39:41,148 --> 00:39:43,150
different inference constraints.

935
00:39:44,151 --> 00:39:46,153
We have examples for linear regression,

936
00:39:46,153 --> 00:39:48,155
hidden Markov model altogether, grace

937
00:39:48,155 --> 00:39:51,158
model hierarchy models, misheard models,

938
00:39:51,158 --> 00:39:53,160
Gaussian process and so, right?

939
00:39:53,160 --> 00:39:55,162
So this approach is very versatile.

940
00:39:56,163 --> 00:39:59,166
And for example, if you compare it with

941
00:39:59,166 --> 00:40:02,163
sort of a conventional software libraries

942
00:40:02,163 --> 00:40:05,166
where you let's say have a library that

943
00:40:05,166 --> 00:40:08,169
solves a common filter, might be a very

944
00:40:08,169 --> 00:40:12,173
great library, maybe super fast, have top

945
00:40:12,173 --> 00:40:15,176
performance works great and very reliable,

946
00:40:15,176 --> 00:40:16,177
, super good.

947
00:40:16,177 --> 00:40:19,180
But then you are constrained by this

948
00:40:19,180 --> 00:40:21,182
particular model common filtering,

949
00:40:21,182 --> 00:40:22,183
right?

950
00:40:22,183 --> 00:40:24,184
And you can't really change it much.

951
00:40:24,185 --> 00:40:27,188
In Ericsson Fur we are free to define our

952
00:40:27,188 --> 00:40:30,191
own models which we can pretty much

953
00:40:30,191 --> 00:40:33,193
easily define a model that essentially

954
00:40:33,193 --> 00:40:35,196
would act equivalently to common

955
00:40:35,196 --> 00:40:37,198
filtering equation.

956
00:40:37,198 --> 00:40:39,200
And so basically in the demo that I

957
00:40:39,200 --> 00:40:42,203
showed before about object tracking, it

958
00:40:42,203 --> 00:40:45,205
was essentially a common filter but was

959
00:40:45,205 --> 00:40:47,208
written in a probabilistic model.

960
00:40:49,210 --> 00:40:51,212
So yeah, that was my small addition to

961
00:40:51,212 --> 00:40:53,214
Bear's presentation.

962
00:40:53,214 --> 00:40:56,217
So our software is free MIT license and

963
00:40:56,217 --> 00:40:59,220
it's open source available on GitHub.

964
00:41:00,215 --> 00:41:02,217
Yeah, and we would be happy thanks to be

965
00:41:02,217 --> 00:41:05,220
able to present where we would be happy

966
00:41:05,220 --> 00:41:06,221
to answer.

967
00:41:06,221 --> 00:41:08,223
Any, thanks.

968
00:41:14,229 --> 00:41:15,230
Daniel: Awesome.

969
00:41:15,230 --> 00:41:18,233
All right, I'll just ask a quick question.

970
00:41:18,233 --> 00:41:18,233
.

971
00:41:18,233 --> 00:41:21,236
In the chat Marco asks sorry if I missed

972
00:41:21,236 --> 00:41:24,239
it are the collision avoidance demos real

973
00:41:24,239 --> 00:41:27,242
time adapting to other agents behavior or

974
00:41:27,242 --> 00:41:31,245
is it a collectively pre computed path?

975
00:41:33,247 --> 00:41:35,250
Dmitry: So basically they are not super

976
00:41:35,250 --> 00:41:37,252
real time, they're kind of fast to

977
00:41:37,252 --> 00:41:39,254
compute this path, like maybe 5 seconds

978
00:41:39,254 --> 00:41:40,255
or so.

979
00:41:40,255 --> 00:41:42,257
But we are basically working to make it

980
00:41:42,257 --> 00:41:43,258
real time.

981
00:41:43,258 --> 00:41:45,260
So we know what is the problem, we know

982
00:41:45,260 --> 00:41:48,263
where to improve and we will make it real

983
00:41:48,263 --> 00:41:49,264
time.

984
00:41:49,264 --> 00:41:51,266
Yes, almost.

985
00:41:53,268 --> 00:41:54,269
Daniel: Next question.

986
00:41:54,269 --> 00:41:56,271
Do you have some comparative data with

987
00:41:56,271 --> 00:41:57,272
other methods?

988
00:41:57,272 --> 00:41:59,274
And just more generally, what kinds of

989
00:41:59,274 --> 00:42:02,271
benchmarks or when you're talking with

990
00:42:02,271 --> 00:42:04,273
industry in different settings, what are

991
00:42:04,273 --> 00:42:07,276
people looking for that killer app of

992
00:42:07,276 --> 00:42:08,277
active inference?

993
00:42:08,277 --> 00:42:11,280
Or what are they looking for their key

994
00:42:11,280 --> 00:42:12,281
measures?

995
00:42:14,283 --> 00:42:16,285
Dmitry: So I personally have a big paper

996
00:42:16,285 --> 00:42:19,288
about comparison with sampling based

997
00:42:19,288 --> 00:42:21,290
methods like HMC and also in my PhD

998
00:42:21,290 --> 00:42:24,293
thesis, there will be a comparison with

999
00:42:24,293 --> 00:42:27,296
nuts, also other sampling based methods.

1000
00:42:28,297 --> 00:42:30,299
So, long story short, sampling based

1001
00:42:30,299 --> 00:42:33,302
methods cannot really run this kind of

1002
00:42:33,302 --> 00:42:35,304
sophisticated inference in real time.

1003
00:42:36,305 --> 00:42:37,306
They're very time consuming.

1004
00:42:37,306 --> 00:42:39,308
They do not really scale well to large

1005
00:42:39,308 --> 00:42:41,310
problems which is really needed for

1006
00:42:41,310 --> 00:42:42,311
active inference agents.

1007
00:42:43,312 --> 00:42:45,314
Because if you have a large environment,

1008
00:42:45,314 --> 00:42:48,317
very complicated, you will have a lot of

1009
00:42:48,317 --> 00:42:50,319
unknown variables in your model.

1010
00:42:53,322 --> 00:42:55,324
There is a paper that compares and

1011
00:42:55,324 --> 00:42:58,327
basically we show that our approach

1012
00:42:58,327 --> 00:43:00,323
scales much, much better.

1013
00:43:00,323 --> 00:43:04,327
So I personally run on just a regular

1014
00:43:04,327 --> 00:43:08,331
MacBook laptop, I run the model with 2

1015
00:43:08,331 --> 00:43:12,335
million unknown variables and it was

1016
00:43:12,335 --> 00:43:13,336
quite fast.

1017
00:43:14,337 --> 00:43:17,340
With sampling based methods you may find

1018
00:43:17,340 --> 00:43:19,342
yourself in a model with like 100

1019
00:43:19,342 --> 00:43:22,345
variables and then you wait like 2 hours

1020
00:43:22,345 --> 00:43:25,348
or something and then it turns out that

1021
00:43:25,348 --> 00:43:28,351
your chain did not converge or something

1022
00:43:28,351 --> 00:43:29,352
like that.

1023
00:43:31,354 --> 00:43:32,355
Daniel: Cool.

1024
00:43:32,355 --> 00:43:35,358
Yeah, it's people commenting in the chat

1025
00:43:35,358 --> 00:43:38,361
like how far message passing and factor

1026
00:43:38,361 --> 00:43:39,362
graphs have come.

1027
00:43:39,362 --> 00:43:42,365
And so to Bias Lab and to Bert at all, we

1028
00:43:42,365 --> 00:43:45,368
definitely appreciate this exciting line

1029
00:43:45,368 --> 00:43:46,369
of research.

1030
00:43:47,369 --> 00:43:49,371
I mean, there's so much to learn there

1031
00:43:49,371 --> 00:43:51,374
and sometimes looking at the equations,

1032
00:43:51,374 --> 00:43:53,376
it can seem like it's like written in

1033
00:43:53,376 --> 00:43:55,378
stone and just sort of the beginning and

1034
00:43:55,378 --> 00:43:57,380
the end is, you know, variational free

1035
00:43:57,380 --> 00:43:57,380
energy.

1036
00:43:58,381 --> 00:44:00,377
But then in your presentations you're

1037
00:44:00,377 --> 00:44:03,380
really showing like no, we are hands on.

1038
00:44:03,380 --> 00:44:05,382
That's where we get the interpretability,

1039
00:44:05,382 --> 00:44:07,384
the modularity, that's where it really is

1040
00:44:07,384 --> 00:44:08,385
implemented.

1041
00:44:08,385 --> 00:44:11,388
And it's like an information logistics

1042
00:44:11,388 --> 00:44:12,389
challenge.

1043
00:44:12,389 --> 00:44:14,391
It's not like an esoteric philosophy

1044
00:44:14,391 --> 00:44:15,392
question at that point.

1045
00:44:16,393 --> 00:44:18,395
Bert: No, indeed.

1046
00:44:19,396 --> 00:44:22,399
I should say it's taken us we are no

1047
00:44:22,399 --> 00:44:24,401
geniuses, right.

1048
00:44:24,401 --> 00:44:26,403
So our lab exists more than eight years,

1049
00:44:26,403 --> 00:44:29,406
and you see all the people in the lab, it'

1050
00:44:29,406 --> 00:44:32,409
's taken us many years with lots of wrong

1051
00:44:32,409 --> 00:44:35,412
directions to get this to work to where

1052
00:44:35,412 --> 00:44:36,413
it's now.

1053
00:44:36,413 --> 00:44:38,415
So it's a very long path.

1054
00:44:38,415 --> 00:44:41,418
But at this moment, I'm pretty confident

1055
00:44:41,418 --> 00:44:44,421
that at some point in the future and we

1056
00:44:44,421 --> 00:44:47,424
don't want to say in three months or in

1057
00:44:47,424 --> 00:44:50,427
one year, but we will be able to write a

1058
00:44:50,427 --> 00:44:53,430
toolbox that will allow people to design

1059
00:44:53,430 --> 00:44:55,432
a generative model and just press a

1060
00:44:55,432 --> 00:44:59,436
button and forget about the inference.

1061
00:44:59,436 --> 00:45:00,431
You don't have to worry about inference

1062
00:45:00,431 --> 00:45:00,431
anymore.

1063
00:45:01,432 --> 00:45:03,434
It will be fast and automated, and that

1064
00:45:03,434 --> 00:45:06,437
will happen, and it will happen within a

1065
00:45:06,437 --> 00:45:07,438
few years.

1066
00:45:08,439 --> 00:45:10,441
And maybe somebody else will write an

1067
00:45:10,441 --> 00:45:11,442
even better toolbox.

1068
00:45:11,442 --> 00:45:15,446
But I'm pretty confident that even our

1069
00:45:15,446 --> 00:45:19,450
toolbox will be able to do that.

1070
00:45:20,451 --> 00:45:23,454
People talk about, why don't we have the

1071
00:45:23,454 --> 00:45:26,457
success of deep learning and generative

1072
00:45:26,457 --> 00:45:27,457
AI, right?

1073
00:45:27,458 --> 00:45:30,460
Well, they have the success because of

1074
00:45:30,460 --> 00:45:32,463
big data availability of big data, big

1075
00:45:32,463 --> 00:45:35,466
computers and toolboxes TensorFlow and

1076
00:45:35,466 --> 00:45:37,468
all the successes.

1077
00:45:37,468 --> 00:45:40,471
We don't need big data because agents

1078
00:45:40,471 --> 00:45:42,473
collect their own data in the field.

1079
00:45:42,473 --> 00:45:46,476
We don't need big computers, active

1080
00:45:46,476 --> 00:45:49,480
influence agents, they manage their power

1081
00:45:49,480 --> 00:45:50,481
resources.

1082
00:45:50,481 --> 00:45:53,484
But we need a really good toolbox because

1083
00:45:53,484 --> 00:45:56,487
programming an active inference agent,

1084
00:45:56,487 --> 00:45:59,490
programming the inference by hand is just

1085
00:45:59,490 --> 00:46:00,485
not doable.

1086
00:46:00,485 --> 00:46:03,488
So we need a really good toolbox that

1087
00:46:03,488 --> 00:46:05,490
really automates this.

1088
00:46:06,491 --> 00:46:08,493
We hope Arcs Infer will be one of the

1089
00:46:08,493 --> 00:46:10,495
first toolboxes to do that.

1090
00:46:10,495 --> 00:46:13,498
I am sure that other people will also be

1091
00:46:13,498 --> 00:46:16,501
working on it, and better toolboxes will

1092
00:46:16,501 --> 00:46:17,502
come about.

1093
00:46:18,503 --> 00:46:21,506
But I think the optimistic message is

1094
00:46:21,506 --> 00:46:23,508
that it will happen.

1095
00:46:24,509 --> 00:46:26,511
And once we have a toolbox like that,

1096
00:46:26,511 --> 00:46:29,514
then we can actually a large community

1097
00:46:29,514 --> 00:46:32,517
can start building agents, and we can

1098
00:46:32,517 --> 00:46:35,520
actually show deployable agents in the

1099
00:46:35,520 --> 00:46:36,521
field that they work.

1100
00:46:36,521 --> 00:46:39,524
And they work better than reinforcement

1101
00:46:39,524 --> 00:46:41,526
learning agent or whatever is out there.

1102
00:46:41,526 --> 00:46:41,526
Right.

1103
00:46:42,527 --> 00:46:45,530
So I think that's a very positive and

1104
00:46:45,530 --> 00:46:46,531
hopeful message.

1105
00:46:48,532 --> 00:46:48,533
Daniel: It's what we expect.

1106
00:46:49,533 --> 00:46:50,535
It's what we prefer.

1107
00:46:50,535 --> 00:46:51,536
Bert: Yeah.

1108
00:46:52,537 --> 00:46:55,540
Daniel: Any last comments from either of

1109
00:46:55,540 --> 00:46:55,540
you?

1110
00:46:59,544 --> 00:47:00,539
Bert: Comments from us?

1111
00:47:00,539 --> 00:47:04,543
No, I'm just very happy to get the

1112
00:47:04,543 --> 00:47:07,546
opportunity, and yeah, I want to

1113
00:47:07,546 --> 00:47:12,551
everybody can download this toolbox.

1114
00:47:13,552 --> 00:47:16,555
I think at this moment, you still should

1115
00:47:16,555 --> 00:47:19,558
be a programmer to work with the toolbox.

1116
00:47:19,558 --> 00:47:19,558
.

1117
00:47:19,558 --> 00:47:23,561
And I hope you're friendly, because it's

1118
00:47:23,561 --> 00:47:26,565
not totally polished in the way that we

1119
00:47:26,565 --> 00:47:26,565
want.

1120
00:47:27,565 --> 00:47:28,567
But it's coming, right?

1121
00:47:28,567 --> 00:47:28,567
It's coming.

1122
00:47:28,567 --> 00:47:31,569
In the next years, there will be a good

1123
00:47:31,569 --> 00:47:33,572
toolbox for almost everybody to use, but

1124
00:47:33,572 --> 00:47:35,574
people that are interested, even people

1125
00:47:35,574 --> 00:47:37,576
that are interested to work.

1126
00:47:37,576 --> 00:47:41,580
Here at Biaslab, we have an open position

1127
00:47:41,580 --> 00:47:44,583
for PhD students, so we're happy to

1128
00:47:44,583 --> 00:47:47,586
receive emails from people that are

1129
00:47:47,586 --> 00:47:50,589
interested to work with us.

1130
00:47:52,591 --> 00:47:52,591
Dmitry: Thank you.

1131
00:47:52,591 --> 00:47:54,593
Daniel: Dimitri, anything in closing?

1132
00:47:56,595 --> 00:47:57,596
Dmitry: No, just that.

1133
00:47:57,596 --> 00:47:59,598
Thank you again for possibility to

1134
00:47:59,598 --> 00:48:00,593
present.

1135
00:48:00,593 --> 00:48:01,594
Super nice to be here.

1136
00:48:02,595 --> 00:48:03,596
Daniel: Cool.

1137
00:48:03,596 --> 00:48:03,596
Dmitry: Yeah.

1138
00:48:03,596 --> 00:48:06,599
Daniel: Well, later in the year, we will

1139
00:48:06,599 --> 00:48:09,602
be discussing your two part recent work,

1140
00:48:09,602 --> 00:48:11,604
and so we're going to be getting a lot

1141
00:48:11,604 --> 00:48:14,607
into the details, and I hope that people

1142
00:48:14,607 --> 00:48:16,609
in the institute and the ecosystem will

1143
00:48:16,609 --> 00:48:18,611
be as excited as we all are.

1144
00:48:19,612 --> 00:48:20,613
Thank you.

1145
00:48:20,613 --> 00:48:21,614
Bert: Thank you.

1146
00:48:21,614 --> 00:48:21,614
Bye.

