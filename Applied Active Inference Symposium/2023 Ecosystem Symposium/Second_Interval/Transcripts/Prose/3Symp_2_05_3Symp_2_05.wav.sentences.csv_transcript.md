
00:16 _Daniel:_
Welcome,
Raf, also co author on the paper.

00:20 _Raf:_
So how are you doing?
I'm good.
What about you?

00:27 _Daniel:_
Pretty good.
Other than this brief interval of white light, I'm just hanging out.

00:35 _Raf:_
Fantastic.
So I'm trying to figure out here how I can.
I'm using a different slide software, so I need to make sure that I can pull this up in the right way.
So give me just a quick second.

00:47 _Daniel:_
Yeah, great.

00:50 _Raf:_
Cool.

00:50 _Daniel:_
So just just to read off what's coming while you figure that out.
So right now we have Ralph Kaufman, and this presentation is going to be Gaia, an active powered network for planetary scale sense making.
Following this 30 minutes presentation, we'll have Avel Gwynen Carlo on embedded Normativity.
That looks perfect.

01:13 That's perfect.

01:16 _Raf:_
Awesome.

01:17 _Daniel:_
All right.
Thanks, Raf, to you.

01:20 _Raf:_
Thank you.

01:21 All right, I was going to try to see if I could blow this up to full screen, but.

01:27 _Daniel:_
I got it on the stream.
Looks good on the stream.
Go for it.

01:32 _Raf:_
Cool.

01:33 So I'm just pulling up my notes here.
All right, so let me just test that this moves.
Did I just move the slide?

01:46 Great.
Cool.
All right, so as I said, hi, everyone.
It's a huge pleasure to be here and thank you so much to Daniel and everybody else in the Institute for organizing this.
I'm going to talk about what I think is the single most important application of active entrance.

02:01 Not as a detriment to the others, but it's sort of upstream of everything else.
And that is how do the 8 billion of us humans make sense of what's going on in our planet and all scales?
And how do we use that understanding to survive as a species?
So this presentation here is a bit of a technical presentation and it has a lot of content.
It's going to move pretty fast and assume that you're familiar with some concepts, but I'm going to try to leave time for Q A at the end.

02:33 So first of all, I'm going to talk about the motivation behind what we're doing, in particular the concepts of the meta crisis and the third attractor.
Then I'll give an overview of our network architecture and the application so far and cover the many remaining challenges.
And last but not least, I plan to convince you that this is the single most important thing you could ever be working on.
And I'm doing this because we need your help.
So that's a taster of what we have.

03:00 As I said, let's jump right into it with the motivation.
And what greater motivation could there be?
If you haven't heard of the metacrisis, it's a term that it's originally from Doctor Who, but it was borrowed by thinker called Daniel Schmuckenberger to talk about the total risk for humanity and the biosphere that is posed by the combination of three factors.
The first being the increasing interconnectedness of everything from climate to food security to national security.
To biodiversity and everything in between.

03:35 The second being the risks associated with self evolving technology, including runaway artificial intelligence and the third being the increasing omnipresence of coordination failures personified as the god of coordination failures moloch.
And so the combination of these three factors as hypothesized by Schmuckenberger will lead to either one of two attractors, one of them being chaotic breakdown of all structure and the second being a reversal to oppressive authoritarian control.
And obviously both of those qualify as that in my book, I assume in yours as well.
So the question of course is can we actually find a third attractor that is positive sum as opposed to negative sum?
And rather the question is can we design it?

04:27 So what I claim, and what we as the Guy Consortium claim, is that yes we can and we can design this attractor.

04:37 The design goal is basically to build resilience and stabilization into our biosocial economic system and to do this subject to multilevel system constraints like the planetary boundaries desirability, meaning it has to be something that people actually want so they will help it happen.
So it needs to preserve standards of living and so on.
And it needs to be feasible, it needs to be achievable from our current initial conditions.
And of course there's a lot of design complicators in the mix, some of which partial observation, there's a lot of information asymmetry going on, there's a lot of uncertainty about how the pieces of the world system work from a scientific perspective, there's obvious computability constraints associated to this.

05:25 And last but not least, you can't really control what happens.
In most cases we can only create incentives, recommendations and nudges.
So easy, right?

05:38 Of course it's not easy, but we think we can do it if we apply the sum of the principles from cybernetics that we already know and apply them in a decentralized positive sum composable way.
So what we're talking about here is decentralized network, a decentralized hybrid AI human network for planetary scale decision support and automation.

06:03 It recognizes that we will have human and artificial agents interacting by the billions in an open network.
Its goal is to facilitate both continuance or model alignment and coherence or goal alignment at multiple levels or scales up to the global scale, meaning the survival of the system as a whole.
It will need to feature built in incentives and governance and it will need to be privacy preserving, intrinsically.
So the below listed participants are participants, founders of the consortium.

06:39 I'm going to talk about it later.

06:42 So this is the framing, this is the motivation for what we're doing.
And now I'm going to give a whirlwind tour of the architecture so far and I'm going to cover mostly what we've built, the version of this architecture that we've built so far, thinking about this explicitly.
And then I'm going to talk about how this connects to other architectures that already exist in the world, just very briefly.
So we've been framing this as an architecture for building decentralized digital twins, which are local models of real world systems that run in network.
And the role that such digital twins play is that they help us understand the costs and benefits of strategies and projects that happen in the real world.

07:28 And in our organization, Digital Gaia, we started out caring primarily about agroecology.
So how do you actually make better decisions, meaning better recommendations, negotiations, valuations, investments into a farm, into a forest, into bio landscape, to make it better, to make it more likely to survive and thrive.

07:55 So, as practical implementation, it needs to tackle several real world challenges.
First of all, it needs to handle distributed, non IID data.
Data is sparse.

08:10 It's heterogeneous, it's private, it's potentially unreliable.
It needs to enable localized collaborative forecasting and planning, personalized planning and privacy preserving.
It needs to accept the fact that it won't be able to directly control, but only recommended nudge, as we discussed.
And the outline of what we came up with is this concept of the Guy Network, which is a mesh of AI agents called natural entities, or Ants for short, that act as proxies for real world systems.
Each ant runs on an engine called Tengor, which it uses to inquire, learn, plan, and allocate resources.

08:52 And ants communicate in a language called the Guy Protocol.

08:57 They use this language to independently interact with their environments and each other.
And if we do this right I'll show a bit more of this later, but if we do this right, the Guy network's behavior approximates a single composite agent that handles, that interacts with and couples with its global environment.
Cool.
So just to give you an overview of how this works under the hood, the Fangor engine is really the heart of our architecture.

09:27 And the core loop that is mentioned here is a typical active inference loop.
But to make this work in very heterogeneous and distributed context, there's lots of work involved.
So just some highlights that I think are going to be particularly interesting for this crowd.
First of all, so as I said, the same core engine needs to be able to work for very heterogeneous contexts.
So each agent has access to a library of generative models.

09:52 And these models are specified using a Python based probabilistic programming DSL, and they declare what context they're appropriate for using a shared ontology.

10:02 Using that ontology, Fangorn can then select the most appropriate model to use online, given the configurations, like project configurations and the kinds of observational data available.
So using a model that's appropriate for farm or for forest, what kind of farm, what kind of forest, what kind of ecosystem, what kind of their context energy project I'm going to get into the examples right now because there's more on the applications later on.
So we end up with a network of heterogeneous agents, but that's okay.
They actually form a single model in a formal sense because they're all connected hierarchically by a system of hyperparators.

10:49 And this means that Fangor needs to support inference of generic hierarchical generative models.
And we actually do this automatically using approximate posteriors with structural constraints.
And so we have this global model that connects all the nodes and describes general facts that apply over multiple contexts.

11:09 And this means the whole network needs to jointly perform inference over this global model using a peer to peer or federated algorithm.
So initially the way this works is initially the network sets the global posterior to be the same as the global prior.

11:24 Each node then independently performs local optimization of the variational free energy and then passes the parameters of the new global solution to the peers in the network where they use it as a hyperprior.
And this works over a broad range of topologies and under pretty general constraints.
And by the way, I'd like to mention that there's a lot of overlap and interaction between the stuff that I'm talking about here and some of the other presentations that you're seeing today and I wasn't able to reference them explicitly in this talk, but I'm sure you're going to see the connections cool.
So what it turns out is that the shared parameters that represent our global model are effectively stored by the network stored in a federated parameter store, meaning that each node stores their own local parameters, they're private stuffed about their own local context and multiple nodes store copies of the global parameters.

12:21 And this architecture, because it supports heterogeneous local models, it actually allows us to introduce another kind of nodes which we call ant mood nodes.

12:31 These are nodes that aggregate scientific and empirical information using a meta analysis model.
And we actually are able to use that meta analysis model to constrain our project level models or ants using quote unquote imported knowledge that wasn't directly observed by them, which is left to right in this picture.
But this actually also goes two ways.
So empirical findings from the project, what actually works on the ground for this particular project also informs the ant modes posteriors which is the right to left.
And so we actually have a complete cycle of science and empirics all implemented using hierarchical active inference.

13:12 So finally, just among the global parameters that network learns by federated inference are the precisions associated with data coming from the different data providers.

13:23 And this gives each node a way to consume data without trusted ground truth and basically to learn together which sources they can rely on it for what?
This is just some of more core features.
We're working on integrating many other capabilities into this architecture.
Not going to go through all of this, but basically what we're finding is that we have all the building blocks to turn this into a full feature decision network complete with its own internal knowledge economy, meaning that contributions get attributed and rewarded in proportion to the free energy reduction that they afford.

14:02 Cool.
So, jumping into applications, as I mentioned, our main focus as an organization has been on modeling agroecological projects like regenerative agriculture and agroforestry.
And this exercises all the constraints that we've talked about so far.
So again, I'm not going to go into full detail, but just to give an overview of what is the anatomy of generative model for a farm or forest.

14:27 So start at the bottom right with observables that are things that we can measure about that ecosystem, about that local context like the plant count and size, vegetation indices from satellite data and so on.

14:40 These are linked to latent states which form a nonlinear dynamical system that's parameterized by the policy the the things that modulate the latent states like agricultural interventions and practices.
You can think of the timing of planting and harvesting, what kinds of crops or trees get planted, what products like pesticides get applied or not, and more as well as covariates.
So external events like weather, physical risks, wildfire, drought and so on.
And so there's some scientific and measurement parameters that go into this as well.
Things like the effect sizes of the various actions and covariance.

15:25 And these local parameters are conditionally dependent on a set of global parameters which, as we discussed, they link information between different ends and different sources of knowledge.

15:39 The same global parameters are used in the meta analysis model and they actually establish the link between what is found to happen on the ground and what is reported in the literature.
I'm not going to go into this because I think I'm going to run a bit long, but basically the concept is that we have these project nodes that correspond to many farms and they're each on independent nodes in the network that are also connected to this common metaanalysis model.
And together these nodes, they incorporate academic studies, expert knowledge and locally relevant context.
They do so privately, so only processing the local data locally and through this parameter sharing they actually jointly and iteratively estimate the global posterior in a cycle forever, for as long as there is new data about the project, as long as there's new studies and new expert knowledges.

16:40 So all of this is happening basically in an online way.

16:45 And again, the topology can vary, but the principles remain the same.
So, just to show a little bit of how this works, this is just two epochs of the global posteriors and this is just location and scale for two parameters the slope and the intercept of the relationship between a vegetation index and the tree biomass in one given hectare of forest.
And as you can see, this converges pretty quickly.
It's comparable to local only methods.
And just to highlight how this can be used, also the limits of how this can be used to estimate source reliability.

17:29 Here's a really successful example at the left.
It's pretty straightforward to use this to estimate reliability of satellite data.
And for other cases, like very local, very context specific data, you actually need more data or more data from more independent sources that we had in this demo here.

17:52 Another very useful use case of this is, as we discussed, we don't have direct control over what happens at a form.
We can only recommend and nudge often.

18:02 We also like a node gets sued up, gets sued up for an existing project that has already happened and we want to find out what actions were taken in the past.
And the same generative model can be used to estimate what happened in the past.
In this example, it infers when planting started and when harvests started for different fields.
So bringing it all together.
One of the applications that we've been using, we've been working on it actually uses all this machinery together to validate claims about projects performance and to estimate future performance.

18:39 We've deployed this in real world projects.
The examples here in this photo are by are relevant to Agroforestry farms in Colombia.
And we found that this actually helps the project developers and their funders to come to a shared understanding of how successful the project is, how much it's worth in terms of its impact and its fundability, whether it should be scaled up or needs to change course.

19:08 What is the quality of the strategy versus other potential strategies for natural regeneration and so on?
So it's actually useful on the ground for decision making in this context.

19:18 Cool.
So finally I want to talk about the end state and going back to our original motivation of solving everything.
I forgive you for your thinking.
This is nice.
But hey, we've been kind of in this downward spiral towards the metacrisis for a long time and what you're telling me doesn't even come close to solving everything.

19:40 And you're right, there's a lot of moving pieces that need to be built and connected.
But here's the good news.
We can do this.
There's no mystery here and we don't need perfection.
I love this quote from Edward Fulbrook that says that to define a policy, we don't need exact empirical measures or optimality, if one jumps from an airplane, it may be nice to have an ultimate, but what one really needs is a parachute.

20:08 So there is only so much that we can get in terms of diminishing returns.
What we should be refocusing on is creating and refining solutions everywhere and connecting them everywhere.
And you might be thinking about how does this actually scale to global goals and how does this actually get used for scalably building into the fabric of decisions in our society.
So about scaling to global goals, I again won't be able to get into the details, but maybe Connor mentioned this in his presentation earlier.
We have actually some proof of concepts that we can actually build active agents that are made of active agents.

20:51 So we've shown in this paper here that a collective of interacting active agents is able to perform approximate inference at the ensemble level.
And that this further that this happens through specific mechanisms that are mediated by cognitive capabilities like theory of mind and goal alignment.

21:13 They work together to improve collective performance by eliminating ambiguity through actively exploiting diversity.
So that's one.
And the other question is how do we actually build this kind of stuff into not just these ad hoc decisions, but into really the fabric of decision making that is our global economic system.

21:39 So, talking about here work that I did with Casper Hesp, this is a game that highlights the ability of ants just like the ones that we just described to infer true system state and use it to credibly incentivize long term positive outcomes in an externality happy scenario.
This theme we were able to show that it works even with adversarial bot strategies and even with high uncertainty and intentional misinformation.
So you can actually get these ends to work with budgets and incentives to drive decision making that internalize externalities and compensates for collusion and generates long term positive outcomes.

22:29 That's not all.
There are other solutions that have been around for longer than ours that apply similar principles to global decision making problems in the real world at scale.

22:40 This is one case study from our partners at Cognizance that they developed for the COVID pandemic and this is not using Active infrastormalism.
This is a combination of traditional recurrent neural networks for prediction and evolutionary optimization for prescription.
And it's actually able to achieve some pretty amazing stuff.
It discovers a pareto front between prevention of cases and economic cost.
It's also a showcase for hybrid human AI intelligence.

23:13 They did an initial version of this model, then they launched an XPRIZE, they got a bunch of contributions for other models and then they did a meta model that discovered a better pareto front and even better.
This tool has actually been used to advise policy in the real world.

23:31 So it's actually very exciting that we're working with them and connecting the dots, because we need to connect the dots, we need to bring it all together.
This illustration here is just, I think, a subset of the effects of the climate change crisis, which is just one aspect of the metacrisis on humans, on our society and the economy.
And so we actually need to be able to deploy solutions that work across many different domains and to connect these dots.

24:05 This means two things.
The first is interoperability aligning decisions across context so that we don't get unintended consequences.
And second is reusability so being able to transport and transfer learning and structure across contexts.
So for instance, using that evolutionary approach from the COVID example in our agricultural context or in many other possible contexts, and this takes the form of libraries, of components, APIs and so forth.

24:33 So that's what we're working on.

24:35 So we're launching this consortium.
We just put up the website a few minutes ago, and we have the goal of having a minimal but functionally complete implementation by the end of next year.
And this is an open project.
We are working on this at our organization called Digital Guy, but we're also launching this open consortium that welcomes contributors from anywhere, both active inference experts and non experts.
And we need a lot of contributors.

25:03 We need all of you because this is the most important thing that we could ever be working on together.
And we need your help to tackle the many remaining challenges.
So if you want to help us build the planetary brain, please go to Gaiaconsortium.org or reach out to me.
You know where to find me.
And together we can design, build, and learn what it takes to achieve planetary regeneration.

25:25 Thank you.

25:29 _Daniel:_
Barath.
Thanks for the great presentation.
I'll post the link to Gaia Consortium into the YouTube live chat.
But let me get a few quick questions in.
So here we go.

25:47 First question.
This is from Marco Lynn.

25:57 I agree with the critical importance of such a project.
How will you deal with the challenges of scaling given the dependence on real world entities like humans, dependence on real world entities like humans for major metacrisis domains such as geopolitics, sociocultural fragmentation, and other particularly hard sense making domains?

26:18 _Raf:_
First of all hi, Marco.
Yeah, thanks for the question.
And I 100% agree that I'm not claiming that this is sufficient.
I'm just claiming that it's necessary.
We do have a lot of ideas and a lot of energy that we want to put into exactly what you described, how to weave what we're doing into the existing incentive landscapes, whether they're market incentives or policy incentives.

26:48 But ultimately, this needs to be an enabler.
This needs to meet people where they are.
And we need to be cognizant that change is not going to happen overnight, at least not right now.
Right.
Typically these things take a while to mature and then they snap into place.

27:06 And we're already finding some of this happening in some of the domains that we're working on where nothing happened for a very long time and then bam, hockey stick.
And we believe that the same can happen pretty much anywhere.

27:20 So we're very optimistic.

27:22 _Daniel:_
Great.
What are currently the greatest challenges for Gaia as an organization?

27:27 I love that kind of ambiguous question, like, is that the Gaia Consortium as an organization or is it Gaia?
But let's hear both.
What are the greatest challenges or frictions for the Consortium and for the bigger picture.

27:42 _Raf:_
Going to I'm not going to talk about the technical stuff for change.
I'm going to talk about the more meta stuff.
And it's actually very related to what your previous presentation, Daniel, about that paper about the Institute talked about.
And it's really related to building out this common, what we were calling the common cognitive kernel for sense making and decision making and relatedly breaking through this culture of sort of suspicion and surf wars and getting people trying to stake their claim to something.
So we are, and always have been extremely open, but it's kind of hard anyway to build trust.

28:34 So we're aware that it's going to take a while to build this trust with everybody.
And I think the only answer to that is really to be as participatory and transparent as possible.

28:50 Also being humble and knowing where we don't have the answer and asking people to help us.

29:02 _Daniel:_
Awesome.
Any closing words or thoughts?

29:09 _Raf:_
Well, if there are no further questions, again, I thank you all for paying attention and I'm going to be reaching out a lot more.
You're going to hear a lot more about this consortium.
As I said, it was just formed.
They just put up a website in time for this presentation.
By the way, thanks so much to Mahi and of course, Steve and everybody else who's been part of forming and getting this ball to start rolling.

29:42 We are very early stage, very formative, and still very client.
So I just gave you my perspective on a bunch of these things, the shape of it that has come from our work on this so far, and even not all of it.
Just a piece that we could cover in 20 minutes or so.
But we are very plural.

30:11 We want to engage with you on different paths, forward, different opportunities to build things, to experiment, to connect the dots, to learn together.

30:24 And ultimately, we really just want to provide a platform, a convening space, a protocol in the classic sense of the world, a word of a shared language, a shared means of communication, a shared means of understanding, to find together what we need to do to actually build this third attractor.

30:47 _Daniel:_
Awesome call Gaia trim tab.

30:50 _Raf:_
Thank you exactly.
Thanks so much, Daniel, and see you guys soon.

30:56 _Daniel:_
Bye bye.

31:00 All right.

31:04 What a cool presentation.
