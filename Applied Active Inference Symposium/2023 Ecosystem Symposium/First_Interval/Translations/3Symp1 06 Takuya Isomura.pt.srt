1
00:00:00,000 --> 00:00:01,800
estrangeiro,

2
00:00:01,800 --> 00:00:04,500
obrigado por participar até a próxima, até a próxima,

3
00:00:04,500 --> 00:00:05,580


4
00:00:05,580 --> 00:00:09,140
muito obrigado, tchau, tudo

5
00:00:14,280 --> 00:00:17,058
bem,

6
00:00:20,640 --> 00:00:24,500
saudações incríveis para a Coreia

7
00:00:24,500 --> 00:00:27,300
até a próxima, até a próxima,

8
00:00:27,300 --> 00:00:29,279
você pode

9
00:00:29,279 --> 00:00:31,859
silenciar a transmissão ao vivo ou desligar a

10
00:00:31,859 --> 00:00:33,480
outra transmissão ao vivo, mas sim, obrigado por

11
00:00:33,480 --> 00:00:35,399
participar,

12
00:00:35,399 --> 00:00:39,059
sim, uh, obrigado  por, uh, convidar, obrigado

13
00:00:39,059 --> 00:00:42,019
por isso,

14
00:00:43,800 --> 00:00:46,399
sim, bem,

15
00:00:46,440 --> 00:00:48,239
temos

16
00:00:48,239 --> 00:00:53,039
uns 35 ou 38 minutos, então

17
00:00:53,039 --> 00:00:55,199
seria incrível ter sua

18
00:00:55,199 --> 00:00:57,739
apresentação

19
00:00:58,860 --> 00:01:02,460
certa para

20
00:01:03,239 --> 00:01:05,880
o momento,

21
00:01:05,880 --> 00:01:08,539
bem,

22
00:01:10,380 --> 00:01:14,880
você pode ver meu poço,

23
00:01:14,880 --> 00:01:18,500
mas eu vi o PowerPoint,

24
00:01:20,220 --> 00:01:23,220
ok,

25
00:01:23,220 --> 00:01:27,659
você pode ver meu  tela uh perfeito perfeito

26
00:01:27,659 --> 00:01:29,820
ok

27
00:01:29,820 --> 00:01:33,659
então vamos começar sim obrigado

28
00:01:33,659 --> 00:01:38,280
ok oh então uh obrigado por uh uh

29
00:01:38,280 --> 00:01:41,759
organizar este maravilhoso simpósio

30
00:01:41,759 --> 00:01:45,479
hoje eu gostaria de falar sobre uh

31
00:01:45,479 --> 00:01:48,000
relação entre rede neural canônica

32
00:01:48,000 --> 00:01:52,200
e uh inferência ativa uh e

33
00:01:52,200 --> 00:01:56,280
possível extensão uh ou  moderno, uh,

34
00:01:56,280 --> 00:01:59,460
social na inteligência compartilhada usando

35
00:01:59,460 --> 00:02:04,880
redes neurais canônicas, então vamos começar,

36
00:02:08,160 --> 00:02:11,220
como você sabe, o princípio da energia livre

37
00:02:11,220 --> 00:02:13,980
é proposto por um estande livre de carros

38
00:02:13,980 --> 00:02:16,920
que afirma que o

39
00:02:16,920 --> 00:02:19,200
aprendizado da percepção e a opção de todos os

40
00:02:19,200 --> 00:02:21,840
organismos biológicos são determinados para minimizar a

41
00:02:21,840 --> 00:02:24,720
variação da energia como  um proxy tratável

42
00:02:24,720 --> 00:02:28,260
para minimização de surpresa e por este uh

43
00:02:28,260 --> 00:02:31,580
processo uh organismos podem realizar

44
00:02:31,580 --> 00:02:34,800
uh inferência paracional de Pequim ou

45
00:02:34,800 --> 00:02:36,900
estados minerais externos

46
00:02:36,900 --> 00:02:40,379
e este é este desenho animado apenas mostra um

47
00:02:40,379 --> 00:02:43,860
exemplo de configuração típica sob o

48
00:02:43,860 --> 00:02:46,640
princípio de energia livre inferência ativa aqui

49
00:02:46,640 --> 00:02:49,920
há um estado oculto uh no

50
00:02:49,920 --> 00:02:52,920
mundo externo e apenas uma parte deste

51
00:02:52,920 --> 00:02:58,319
estado pode ser observável para uh nosso

52
00:02:58,319 --> 00:03:00,959
agente esta doca

53
00:03:00,959 --> 00:03:04,319
e esta transformação é feita por um

54
00:03:04,319 --> 00:03:06,060
parâmetro do modelo genético Wise

55
00:03:06,060 --> 00:03:08,660
parametrizado por Theta

56
00:03:08,660 --> 00:03:12,780
e para o estado oculto o agente

57
00:03:12,780 --> 00:03:17,459
precisa reconstruir a cópia do

58
00:03:17,459 --> 00:03:21,060
estado externo  chamado relevo posterior

59
00:03:21,060 --> 00:03:24,239
e esta otimização é feita

60
00:03:24,239 --> 00:03:27,900
minimizando uma energia livre variacional

61
00:03:27,900 --> 00:03:31,860
e o parâmetro também é otimizado

62
00:03:31,860 --> 00:03:35,099
minimizando a energia livre para obter um

63
00:03:35,099 --> 00:03:37,379
modelo gerador que represente esta

64
00:03:37,379 --> 00:03:40,560
relação um aspecto interessante da

65
00:03:40,560 --> 00:03:42,299


66
00:03:42,299 --> 00:03:44,819
influência ativa do transplante de energia livre é sua aplicação na

67
00:03:44,819 --> 00:03:48,000
otimização de  ação aqui nosso agente

68
00:03:48,000 --> 00:03:51,239
tem alguma preferência anterior C e para

69
00:03:51,239 --> 00:03:54,860
obter esta observação no futuro o

70
00:03:54,860 --> 00:03:59,280
agente pode selecionar a ação que

71
00:03:59,280 --> 00:04:02,640
minimiza a energia livre esperada no

72
00:04:02,640 --> 00:04:05,580
futuro para

73
00:04:05,580 --> 00:04:09,540
obter o resultado mais previsível

74
00:04:09,540 --> 00:04:14,280
e finalmente selecionando uh

75
00:04:14,280 --> 00:04:16,019
ações que minimizam a

76
00:04:16,019 --> 00:04:19,738
frequência esperada  ele pode obter o feed,

77
00:04:19,738 --> 00:04:23,160
então esta é uma configuração típica na

78
00:04:23,160 --> 00:04:25,919
questão da infraestrutura ativa é qual é o

79
00:04:25,919 --> 00:04:28,680
substrato do substantivo neural que pode implementar

80
00:04:28,680 --> 00:04:31,500
esse processo, de modo que esse é o nosso

81
00:04:31,500 --> 00:04:34,500
interesse e para resolver esse problema,

82
00:04:34,500 --> 00:04:38,520
propomos uma teoria como segue, aqui

83
00:04:38,520 --> 00:04:41,880
consideramos que uh  o mundo externo é

84
00:04:41,880 --> 00:04:45,120
parametrizado caracterizado por um conjunto de

85
00:04:45,120 --> 00:04:50,580
variáveis ​​​​como esta aqui esta é uma

86
00:04:50,580 --> 00:04:53,940
expectativa posterior e

87
00:04:53,940 --> 00:04:57,600
como indica o estado oculto no

88
00:04:57,600 --> 00:05:01,440
Excel ou Delta indica a ação

89
00:05:01,440 --> 00:05:05,460
do agente ou decisão e o Theta

90
00:05:05,460 --> 00:05:08,820
uh indica um parâmetro e o Lambda

91
00:05:08,820 --> 00:05:14,580
é um  hiperparâmetro, então aqueles uh definidos ou

92
00:05:14,580 --> 00:05:18,240
mais parâmetros ou variáveis ​​​​caracterizam

93
00:05:18,240 --> 00:05:22,940
um modelo de generalidade e uh energia livre a

94
00:05:22,940 --> 00:05:25,560
variação da energia é definida como uma

95
00:05:25,560 --> 00:05:28,800
função da sequência de observação

96
00:05:28,800 --> 00:05:31,620
e do estado externo e sua

97
00:05:31,620 --> 00:05:33,900
minimização indica a inferência da

98
00:05:33,900 --> 00:05:36,419
equação operacional variacional da energia livre

99
00:05:36,419 --> 00:05:38,880
uh da

100
00:05:38,880 --> 00:05:42,780
mesma forma nós  considere uma dinâmica de

101
00:05:42,780 --> 00:05:45,919
rede neural e consideramos que uma

102
00:05:45,919 --> 00:05:48,900
dinâmica é caracterizada por um estado

103
00:05:48,900 --> 00:05:52,320
dessas variáveis ​​​​aqui x indica que a

104
00:05:52,320 --> 00:05:55,199
taxa de disparo da atividade neural nos

105
00:05:55,199 --> 00:05:56,780


106
00:05:56,780 --> 00:06:01,080
neurônios da área intermediária e o indicador Y próximo à

107
00:06:01,080 --> 00:06:04,020
atividade dos neurônios de rádio de saída e W

108
00:06:04,020 --> 00:06:07,919
aqui é um peso sináptico  e o Phi é

109
00:06:07,919 --> 00:06:10,680
o outro qualquer outro parâmetro livre que

110
00:06:10,680 --> 00:06:13,740
caracteriza a rede neural e

111
00:06:13,740 --> 00:06:17,060
consideramos que a dinâmica da rede neural é

112
00:06:17,060 --> 00:06:19,979
caracterizada pela minimização de alguma

113
00:06:19,979 --> 00:06:23,520
função de custo aqui esta é uma função

114
00:06:23,520 --> 00:06:26,220
do O e do estado interno do Phi da

115
00:06:26,220 --> 00:06:28,500
rede neural e

116
00:06:28,500 --> 00:06:32,039
sua minimização  indicam a

117
00:06:32,039 --> 00:06:34,500
geração da dinâmica da rede neural

118
00:06:34,500 --> 00:06:37,740
incluindo a atividade e a

119
00:06:37,740 --> 00:06:41,940
plasticidade e nossa teoria indica uh

120
00:06:41,940 --> 00:06:45,500
equivalência entre as duas funções, o que

121
00:06:45,500 --> 00:06:49,979
significa que para qualquer rede neural que

122
00:06:49,979 --> 00:06:52,380
minimize algum erro funcional de custo

123
00:06:52,380 --> 00:06:55,620
existe um modelo genético que satisfaz se

124
00:06:55,620 --> 00:06:59,720
chamarmos de Air, o que significa que  uh uh,

125
00:06:59,720 --> 00:07:01,940
a

126
00:07:01,940 --> 00:07:05,340
recaptura da dinâmica externa é uma

127
00:07:05,340 --> 00:07:08,580
característica inerente de qualquer sistema neural

128
00:07:08,580 --> 00:07:13,319
que, para tal dinâmica, então esta é uma

129
00:07:13,319 --> 00:07:16,680
previsão interessante, mas as outras duas

130
00:07:16,680 --> 00:07:17,780
estruturas,

131
00:07:17,780 --> 00:07:21,780
então eu gostaria de apresentar algum

132
00:07:21,780 --> 00:07:24,180
exemplo analiticamente interativo para

133
00:07:24,180 --> 00:07:28,620
entender uh esse relacionamento formalmente,

134
00:07:28,620 --> 00:07:31,759
então primeiro consideramos  uma arquitetura muito simples,

135
00:07:31,759 --> 00:07:35,280
isso é representado por um

136
00:07:35,280 --> 00:07:39,660
Pome DP sem qualquer transição de estágio, então

137
00:07:39,660 --> 00:07:43,220
ela não pegou s é simplesmente

138
00:07:43,220 --> 00:07:46,319
gerado pela distribuição do ano de voo D

139
00:07:46,319 --> 00:07:52,620
e é um estado binário, mas

140
00:07:52,620 --> 00:07:56,160
consideramos um vetor de estados binários, então

141
00:07:56,160 --> 00:08:00,240
é um  A fábrica fatorial de estrutura e

142
00:08:00,240 --> 00:08:03,900
uh observação também é um

143
00:08:03,900 --> 00:08:08,220
vetor binário e a transformação de s para

144
00:08:08,220 --> 00:08:11,160
O é caracterizada pela

145
00:08:11,160 --> 00:08:16,979
distribuição categórica uh usando uma matriz regular a

146
00:08:16,979 --> 00:08:20,099
e a inferência variacional de Pequim

147
00:08:20,099 --> 00:08:22,919
indica a inversão deste

148
00:08:22,919 --> 00:08:27,180
processo generativo assim,

149
00:08:27,180 --> 00:08:29,660
resolvendo o funcional de energia livre apropriado

150
00:08:29,660 --> 00:08:33,599
obtemos aqueles

151
00:08:33,599 --> 00:08:37,219
resumos posteriores que são ótimos no

152
00:08:37,219 --> 00:08:40,140
sentido bayesiano,

153
00:08:40,140 --> 00:08:42,479
por outro lado, para a rede neural

154
00:08:42,479 --> 00:08:46,920
consideramos tal estrutura uh aqui a

155
00:08:46,920 --> 00:08:50,040
parte superior indica a geração de sinal

156
00:08:50,040 --> 00:08:52,560
no mundo externo e a

157
00:08:52,560 --> 00:08:55,320
rede neural compreende apenas uma única camada

158
00:08:55,320 --> 00:08:59,880
aqui atividade de  camada de saída gerada

159
00:08:59,880 --> 00:09:02,540
por uma soma relacionada de

160
00:09:02,540 --> 00:09:06,839
entrada sensorial ou ponderada pela

161
00:09:06,839 --> 00:09:10,440
matriz sináptica W e então caracterizamos esta

162
00:09:10,440 --> 00:09:12,120
rede neural

163
00:09:12,120 --> 00:09:14,339
no próximo slide,

164
00:09:14,339 --> 00:09:18,360
então uh para modelar a rede neural neural ou

165
00:09:18,360 --> 00:09:19,700
neurônio

166
00:09:19,700 --> 00:09:22,760
começamos considerando a

167
00:09:22,760 --> 00:09:27,600
equação do projeto que é o uh quatro uh que

168
00:09:27,600 --> 00:09:30,839
compreende  quatro equações diferenciais e

169
00:09:30,839 --> 00:09:33,959
esta é uma equação não linear muito complicada

170
00:09:33,959 --> 00:09:37,500
e embora seja uma barricada

171
00:09:37,500 --> 00:09:40,260
possível, então consideramos alguma redução

172
00:09:40,260 --> 00:09:43,880
dessas equações, então um

173
00:09:43,880 --> 00:09:47,279
método de redução típico

174
00:09:47,279 --> 00:09:52,080
é a prática, por exemplo, M aqui é muito

175
00:09:52,080 --> 00:09:55,019
mais rápido do que outras variáveis, então isso pode

176
00:09:55,019 --> 00:09:59,580
ser substituído por seu ponto fixo ou

177
00:09:59,580 --> 00:10:04,080
sabe-se que H e menos um, desculpe,

178
00:10:04,080 --> 00:10:09,480
sabe-se que H e 1 menos s n é a

179
00:10:09,480 --> 00:10:13,620
têm uma dinâmica semelhante, então podemos

180
00:10:13,620 --> 00:10:17,339
considerar uma nova variável efetiva U para

181
00:10:17,339 --> 00:10:19,700
caracterizar essas duas

182
00:10:19,700 --> 00:10:23,459
variáveis ​​e então obtemos  para a

183
00:10:23,459 --> 00:10:28,019
equação positiva como esta, então esta é

184
00:10:28,019 --> 00:10:31,820
uma classe famosa de modelo de rede neural

185
00:10:31,820 --> 00:10:36,180
que inclui o bem conhecido modelo fixo de visão

186
00:10:36,180 --> 00:10:40,820
e concordância uh ou outro

187
00:10:40,820 --> 00:10:44,160
modelo de rede neural contínua e nós

188
00:10:44,160 --> 00:10:49,860
modificamos esses modelos para derivar um

189
00:10:49,860 --> 00:10:52,740
modelo neural canônico, então  esta é uma

190
00:10:52,740 --> 00:10:56,220
definição de um modelo de rede neural canônico

191
00:10:56,220 --> 00:10:59,459
aqui a

192
00:10:59,459 --> 00:11:02,579
corrente de fuga é caracterizada pela

193
00:11:02,579 --> 00:11:06,000
função sumóide do barramento em vez de uma

194
00:11:06,000 --> 00:11:08,940
função cúbica que é adotada no

195
00:11:08,940 --> 00:11:12,060
modelo nagma do Fitview e também

196
00:11:12,060 --> 00:11:15,180
consideramos uma conexão uh

197
00:11:15,180 --> 00:11:18,980
conexão sináptica e esta parte indica uma

198
00:11:18,980 --> 00:11:22,820
entrada sináptica  de uma camada sensorial

199
00:11:22,820 --> 00:11:28,440
através de matrizes de peso uh e pode-se

200
00:11:28,440 --> 00:11:31,800
considerar que W1 indica

201
00:11:31,800 --> 00:11:34,320
sinapse excitatória e sinapse de inventário indicador w0

202
00:11:34,320 --> 00:11:37,579
e os

203
00:11:37,579 --> 00:11:40,140
limiares adaptativos de moletom que são função

204
00:11:40,140 --> 00:11:45,180
de WR e w0 agora, curiosamente, quando

205
00:11:45,180 --> 00:11:47,880
consideramos um ponto fixo desta

206
00:11:47,880 --> 00:11:51,480
equação diferencial, obtemos um

207
00:11:51,480 --> 00:11:54,899
poço  -conhecido modelo de codificação vermelha com a

208
00:11:54,899 --> 00:11:58,500
função de ativação sigmoider, o

209
00:11:58,500 --> 00:12:01,920
que significa que, uh, podemos dizer que, em

210
00:12:01,920 --> 00:12:03,920
certo sentido, esse modelo canônico de rede neural

211
00:12:03,920 --> 00:12:08,940
é uma aproximação do que você pode

212
00:12:08,940 --> 00:12:12,540
ter na equação e seu

213
00:12:12,540 --> 00:12:16,140
nível de aproximação é,

214
00:12:16,140 --> 00:12:19,380
em certo sentido, entre o realista

215
00:12:19,380 --> 00:12:22,920
modelo e o modelo de codificação vermelha mais simplificado,

216
00:12:22,920 --> 00:12:26,640
então basicamente consideramos esse tipo

217
00:12:26,640 --> 00:12:30,120
de modelo de rede neural e no próximo

218
00:12:30,120 --> 00:12:31,700
slide

219
00:12:31,700 --> 00:12:35,279
consideramos qual é a função de custo plausível

220
00:12:35,279 --> 00:12:39,000
para esse modelo de rede neural,

221
00:12:39,000 --> 00:12:42,360
então novamente

222
00:12:42,360 --> 00:12:45,600
escrevemos a mesma equação para o

223
00:12:45,600 --> 00:12:49,079
modelo de rede neural canônica que representa

224
00:12:49,079 --> 00:12:52,620
a atividade dos neurônios Vetor de

225
00:12:52,620 --> 00:12:53,579
neurônios

226
00:12:53,579 --> 00:12:58,079
e consideramos uma função de custo para esta

227
00:12:58,079 --> 00:13:00,180
equação diferencial que pode ser

228
00:13:00,180 --> 00:13:02,600
obtida simplesmente

229
00:13:02,600 --> 00:13:07,200
calculando a integral do

230
00:13:07,200 --> 00:13:12,300
lado direito desta equação e obtemos este

231
00:13:12,300 --> 00:13:15,779
tipo de função de custo para rede neural

232
00:13:15,779 --> 00:13:18,660
esta é uma função de custo portátil biológica

233
00:13:18,660 --> 00:13:20,760
no sentido de que sua

234
00:13:20,760 --> 00:13:22,860
derivada derivou uma atividade de rede neural

235
00:13:22,860 --> 00:13:26,700
que possui um certo vírus

236
00:13:26,700 --> 00:13:28,139
chamado probabilidade.

237
00:13:28,139 --> 00:13:29,779
Além disso,

238
00:13:29,779 --> 00:13:33,899
se considerarmos uma derivada desta

239
00:13:33,899 --> 00:13:36,480
função de custo em relação ao peso sinóptico

240
00:13:36,480 --> 00:13:41,700
w, obteremos uma

241
00:13:41,700 --> 00:13:45,300
regra convencional de plasticidade sináptica que segue a lei hepia

242
00:13:45,300 --> 00:13:47,339


243
00:13:47,339 --> 00:13:51,260
uh por outro  mão para a

244
00:13:51,540 --> 00:13:54,060
inferência de Pequim, primeiro definimos o

245
00:13:54,060 --> 00:13:57,779
modelo de generalidade, uh, como no

246
00:13:57,779 --> 00:14:03,720
slide anterior e, uh, derivamos o desculpe,

247
00:14:03,720 --> 00:14:07,500
derivamos uma energia variacional para

248
00:14:07,500 --> 00:14:10,620
uh, determinado modelo genético, então esta variação

249
00:14:10,620 --> 00:14:14,639
de energia livre é derivada, uh, do

250
00:14:14,639 --> 00:14:19,019
modelo Palm DP no uh anterior  slide

251
00:14:19,019 --> 00:14:23,100
e sua minimização indica uh a

252
00:14:23,100 --> 00:14:26,279
floresta de Pequim e a corrida,

253
00:14:26,279 --> 00:14:30,740
então formamos uma

254
00:14:30,920 --> 00:14:34,860
correspondência formal entre um

255
00:14:34,860 --> 00:14:38,300
componente dessas duas funções de custo

256
00:14:38,300 --> 00:14:42,920
como esta, então este uh vetor de bloco

257
00:14:42,920 --> 00:14:46,260
corresponde formalmente a este vetor de bloco

258
00:14:46,260 --> 00:14:49,040
que representa a expectativa posterior

259
00:14:49,040 --> 00:14:53,160
e este logaritmo corresponde a este

260
00:14:53,160 --> 00:14:54,600
logaritmo

261
00:14:54,600 --> 00:14:59,459
e na verdade esta matriz pode ser

262
00:14:59,459 --> 00:15:02,339
representada como a matriz de bloco

263
00:15:02,339 --> 00:15:06,019
assim e é um produto DOT

264
00:15:06,019 --> 00:15:09,600
corresponde a este cálculo e

265
00:15:09,600 --> 00:15:12,620
finalmente uh esses cinco

266
00:15:12,620 --> 00:15:16,320
naturalmente correspondem a isso uh carregue o

267
00:15:16,320 --> 00:15:20,880
logotipo do estado anterior então o que significa que

268
00:15:20,880 --> 00:15:24,540
uh porque a função de custo uh mesmo

269
00:15:24,540 --> 00:15:28,519
é derivada uh

270
00:15:28,519 --> 00:15:31,860
fornece o a

271
00:15:31,860 --> 00:15:33,540


272
00:15:33,540 --> 00:15:37,980
sua derivada fornece a alguma

273
00:15:37,980 --> 00:15:39,600
[Música]

274
00:15:39,600 --> 00:15:44,120
desculpe porque a função de custo é

275
00:15:44,120 --> 00:15:48,420
formalmente equivalente é derivada uh é

276
00:15:48,420 --> 00:15:52,820
uh desculpe é um resultado de uh

277
00:15:52,820 --> 00:15:56,339
derivada também correspondendo entre

278
00:15:56,339 --> 00:16:00,839
si então o que significa que uh para  qualquer

279
00:16:00,839 --> 00:16:04,500
equação interativa nesta forma uh,

280
00:16:04,500 --> 00:16:06,839
há uma

281
00:16:06,839 --> 00:16:09,899
equação de inferência bayesiana correspondente, esta é uma equação

282
00:16:09,899 --> 00:16:13,860
que calcula o div posterior do

283
00:16:13,860 --> 00:16:17,579
estado do hélio e este

284
00:16:17,579 --> 00:16:20,519
formato de equação do processo sináptico corresponde ao aprendizado

285
00:16:20,519 --> 00:16:23,820
ou parâmetro do modelo generativo e,

286
00:16:23,820 --> 00:16:27,120
além disso, ao estabelecer esta

287
00:16:27,120 --> 00:16:30,480
relação, podemos considerar  a

288
00:16:30,480 --> 00:16:33,360
engenharia reversa do modelo genético a partir de

289
00:16:33,360 --> 00:16:37,399
dados empíricos aqui uh este uh

290
00:16:37,399 --> 00:16:38,959
esquemático

291
00:16:38,959 --> 00:16:43,380
resume nossa abordagem para a

292
00:16:43,380 --> 00:16:45,899
engenharia reversa do modelo generativo e

293
00:16:45,899 --> 00:16:48,060
primeiro registramos a atividade neural e

294
00:16:48,060 --> 00:16:50,880
atribuímos a rede neural Canon can para

295
00:16:50,880 --> 00:16:54,779
explicar esses dados obtidos e

296
00:16:54,779 --> 00:16:57,240
calculando a integral que obtivemos  uma

297
00:16:57,240 --> 00:16:59,660
função de custo para esta rede canônica

298
00:16:59,660 --> 00:17:03,540
e pela equivalência matemática que

299
00:17:03,540 --> 00:17:05,900
estabelecemos podemos

300
00:17:05,900 --> 00:17:09,000
identificar automaticamente um modelo genético e

301
00:17:09,000 --> 00:17:11,760
energia livre operacional livre que corresponde

302
00:17:11,760 --> 00:17:16,079
a esta arquitetura de rede neural tão

303
00:17:16,079 --> 00:17:20,059
interessantemente este é um agente Bayesiano

304
00:17:20,059 --> 00:17:24,020
que é um tipo de que é uma espécie de

305
00:17:24,020 --> 00:17:27,179
inteligência artificial, mas o mais importante é que

306
00:17:27,179 --> 00:17:30,299
esta inteligência artificial é formalmente

307
00:17:30,299 --> 00:17:33,660
derivada de dados empíricos, então podemos

308
00:17:33,660 --> 00:17:37,520
dizer que este agente é uma

309
00:17:37,520 --> 00:17:39,960
inteligência biométrica de compartilhamento ativo que segue

310
00:17:39,960 --> 00:17:42,960
o princípio da pré-energia

311
00:17:42,960 --> 00:17:46,440
e então sua derivada em relação a

312
00:17:46,440 --> 00:17:49,520
um parâmetro de

313
00:17:49,520 --> 00:17:52,919
algoritmos de prótese sináptica derivados posteriormente

314
00:17:52,919 --> 00:17:55,860
que seguem o  a minimização da energia livre

315
00:17:55,860 --> 00:18:00,600
e sua integral de tempo podem prever o

316
00:18:00,600 --> 00:18:03,720
processo de execução dos dados originais da rede neural da rede neural, o

317
00:18:03,720 --> 00:18:04,880


318
00:18:04,880 --> 00:18:07,380


319
00:18:07,380 --> 00:18:11,820
que significa que se a

320
00:18:11,820 --> 00:18:14,700
liberdade for um princípio estiver correta, então

321
00:18:14,700 --> 00:18:17,100
esta previsão deve funcionar,

322
00:18:17,100 --> 00:18:20,640
deve funcionar e deve ser capaz de

323
00:18:20,640 --> 00:18:24,900
prever o resultado disso

324
00:18:24,900 --> 00:18:29,820
dados neurais sem fazer referência aos dados

325
00:18:29,820 --> 00:18:34,200
em si, então nossa estratégia é, em resumo,

326
00:18:34,200 --> 00:18:37,460
nossa estratégia é

327
00:18:37,460 --> 00:18:41,760
reconstruir o modelo genético apenas a partir dos

328
00:18:41,760 --> 00:18:46,200
dados iniciais com dados iniciais semelhantes

329
00:18:46,200 --> 00:18:50,160
antes de aprender e então prever o

330
00:18:50,160 --> 00:18:52,520
processo de execução ou executar a curva

331
00:18:52,520 --> 00:18:56,880
que este sistema neural neural deve

332
00:18:56,880 --> 00:18:58,260
siga

333
00:18:58,260 --> 00:19:02,460
usando o princípio da energia livre e

334
00:19:02,460 --> 00:19:05,640
compare ou examine onde esta

335
00:19:05,640 --> 00:19:09,179
previsão está correta, comparando os

336
00:19:09,179 --> 00:19:13,559
dados reais após a execução e a

337
00:19:13,559 --> 00:19:16,200
previsão pelo princípio da frequência

338
00:19:16,200 --> 00:19:19,200
e se esta previsão estiver correta, então

339
00:19:19,200 --> 00:19:22,320
indica a validade preditiva do

340
00:19:22,320 --> 00:19:25,200
princípio da energia livre  e a configuração

341
00:19:25,200 --> 00:19:26,520
foi considerada

342
00:19:26,520 --> 00:19:27,600
correta,

343
00:19:27,600 --> 00:19:31,440
então aplicamos essa estratégia à

344
00:19:31,440 --> 00:19:34,679
rede neural in vitro, então aqui essa

345
00:19:34,679 --> 00:19:37,320
rede neural in vitro é estimulada, uh,

346
00:19:37,320 --> 00:19:40,460
usando a forma do processo genitivo DP

347
00:19:40,460 --> 00:19:44,460
definido no slide anterior, então

348
00:19:44,460 --> 00:19:47,360
há duas fontes ocultas que são

349
00:19:47,360 --> 00:19:51,660
sinais binários e elas são  mistura e eles

350
00:19:51,660 --> 00:19:56,600
são misturados para gerar uh 32

351
00:19:56,600 --> 00:20:01,860
streaming sensorial, esses também são binários

352
00:20:01,860 --> 00:20:06,780
e este é um experimento geral,

353
00:20:06,780 --> 00:20:09,600
estimulando neurônios in vitro que

354
00:20:09,600 --> 00:20:13,020
eles geram uma resposta de pico de Spike e

355
00:20:13,020 --> 00:20:16,880
essas rimas indicam uma

356
00:20:16,880 --> 00:20:23,460
resposta de pico de alta densidade, então nós Obed que uh

357
00:20:23,460 --> 00:20:27,260
em alguns  neurônio,

358
00:20:27,480 --> 00:20:30,360
a especificidade da resposta

359
00:20:30,360 --> 00:20:34,799
é então descobrimos que, uh,

360
00:20:34,799 --> 00:20:37,820
para alguns neurônios, a

361
00:20:37,820 --> 00:20:41,539
resposta era alta para o

362
00:20:41,539 --> 00:20:43,440


363
00:20:43,440 --> 00:20:47,700
sinal Source One uh em comparação com o sinal source2

364
00:20:47,700 --> 00:20:54,179
e se observarmos a transição desses

365
00:20:54,179 --> 00:20:58,700
neurônios, descobrimos que, embora

366
00:20:58,700 --> 00:21:03,360
removamos o deslocamento uh na primeira

367
00:21:03,360 --> 00:21:08,340
sessão uh  para definir essas atividades como

368
00:21:08,340 --> 00:21:14,120
zero, mas vemos que esses neurônios

369
00:21:14,120 --> 00:21:17,940
se auto-organizam para responder alto quando a

370
00:21:17,940 --> 00:21:21,960
fonte um é um, mas não, uh,

371
00:21:21,960 --> 00:21:27,080
mas esses neurônios respondem em nível baixo baixo

372
00:21:27,080 --> 00:21:32,100
quando a fonte um é zero, o que

373
00:21:32,100 --> 00:21:35,940
significa que a atividade neural por meio

374
00:21:35,940 --> 00:21:39,860
da resposta dos neurônios  uh foi uh

375
00:21:39,860 --> 00:21:43,380
consistente com nossa

376
00:21:43,380 --> 00:21:46,679
previsão teórica de que a nova atividade serve

377
00:21:46,679 --> 00:21:48,840
organizada para codificar a

378
00:21:48,840 --> 00:21:52,559
expectativa posterior do estado de hélio e também

379
00:21:52,559 --> 00:21:54,720
descobrimos que algum outro grupo de neurônios

380
00:21:54,720 --> 00:21:58,020
responde preferencialmente à Fonte dois,

381
00:21:58,020 --> 00:22:01,500
mas não à Fonte Um,

382
00:22:01,500 --> 00:22:07,980
então perguntamos, ok, então encontramos

383
00:22:07,980 --> 00:22:11,100
que as expectativas posteriores codificadas pela

384
00:22:11,100 --> 00:22:13,080
atividade neural e a próxima pergunta

385
00:22:13,080 --> 00:22:16,260
o que há de outro e de outro

386
00:22:16,260 --> 00:22:20,520
substrato neuronal e então perguntamos se

387
00:22:20,520 --> 00:22:24,600
apenas se a

388
00:22:24,980 --> 00:22:29,900
prioridade sobre o estado oculto é igual ao

389
00:22:29,900 --> 00:22:33,179
grau efetivo igual ao

390
00:22:33,179 --> 00:22:37,220
limiar de disparo de um modelo de atividade neural

391
00:22:37,220 --> 00:22:41,220
Modelo de rede uh  então se o servidor estiver

392
00:22:41,220 --> 00:22:43,860
correto esta correspondência correspondente

393
00:22:43,860 --> 00:22:48,600
deve existir para verificar isso uh nós

394
00:22:48,600 --> 00:22:52,980
primeiro simulamos um agente de Pequim e quando

395
00:22:52,980 --> 00:22:55,799
avaliamos a

396
00:22:55,799 --> 00:23:00,240
prioridade do agente de Pequim uh a

397
00:23:00,240 --> 00:23:03,980
inferência foi atenuada como eu esperava

398
00:23:03,980 --> 00:23:09,080
e avisamos que quando enterramos o

399
00:23:09,080 --> 00:23:12,179
nível excitatório  da rede neural in vitro

400
00:23:12,179 --> 00:23:15,120
usando a

401
00:23:15,120 --> 00:23:19,799
manipulação farmacológica, também descobrimos que uh

402
00:23:19,799 --> 00:23:22,919
a atenuação da atenuação da

403
00:23:22,919 --> 00:23:24,299
inferência, o

404
00:23:24,299 --> 00:23:27,720
que é consistente com nossa

405
00:23:27,720 --> 00:23:30,320
previsão teórica de que o

406
00:23:30,320 --> 00:23:34,740
limite financeiro codifica a prioridade ou

407
00:23:34,740 --> 00:23:38,100
com o estado oculto

408
00:23:38,100 --> 00:23:42,419
e a seguir consideramos se a

409
00:23:42,419 --> 00:23:46,200
plasticidade sinérgica seguiu o livre

410
00:23:46,200 --> 00:23:50,720
princípio de energia perguntando se o

411
00:23:50,720 --> 00:23:54,140
princípio de frequência pode prever a

412
00:23:54,140 --> 00:23:57,659
auto-organização qualitativa de

413
00:23:57,659 --> 00:23:59,780


414
00:23:59,780 --> 00:24:01,400


415
00:24:01,400 --> 00:24:05,580
dados neurais subsequentes, uh, subsequentes,

416
00:24:05,580 --> 00:24:10,140
então aqui modelamos uma rede neural neural neural

417
00:24:10,140 --> 00:24:12,840
como esta, há dois uh

418
00:24:12,840 --> 00:24:15,240
neurônios Ensemble que codificam a Fonte Um

419
00:24:15,240 --> 00:24:20,700
e a Fonte dois e primeiro calculamos  o

420
00:24:20,700 --> 00:24:25,400
peso sináptico efetivo dessas uh

421
00:24:25,400 --> 00:24:28,820
redes uh usando

422
00:24:28,820 --> 00:24:32,039
cadeias de conexão convencionais conforme a abordagem mencionada

423
00:24:32,039 --> 00:24:37,500
e o ponto do gráfico uh igualação final no

424
00:24:37,500 --> 00:24:38,480


425
00:24:38,480 --> 00:24:42,120
cenário do arquivo ou energia livre teoricamente calculada,

426
00:24:42,120 --> 00:24:42,960


427
00:24:42,960 --> 00:24:45,179


428
00:24:45,179 --> 00:24:49,400
então esta é uma trajetória de MP Curry estimativa de

429
00:24:49,400 --> 00:24:51,020


430
00:24:51,020 --> 00:24:54,240
graus de sinapse processo sináptico eficaz

431
00:24:54,240 --> 00:24:58,440
sináptico  conectividade e conforme

432
00:24:58,440 --> 00:25:02,840
previsto, uh, essas mudanças

433
00:25:02,840 --> 00:25:08,059
reduzem a energia livre

434
00:25:08,159 --> 00:25:13,039
e aqui calculamos esse

435
00:25:13,039 --> 00:25:16,080
cenário de energia livre teoricamente previsto

436
00:25:16,080 --> 00:25:21,179
usando apenas os dados das primeiras 10 sessões, para que

437
00:25:21,179 --> 00:25:24,480
isso

438
00:25:24,480 --> 00:25:29,039
indique alguma previsão

439
00:25:29,039 --> 00:25:32,580
da auto-organização

440
00:25:32,580 --> 00:25:36,960
e, uh, para uma previsão mais explícita, uh,

441
00:25:36,960 --> 00:25:41,460
nós  então simulei uma nova atividade e

442
00:25:41,460 --> 00:25:43,919
plasticidade usando o princípio da frequência

443
00:25:43,919 --> 00:25:46,039
aqui

444
00:25:46,039 --> 00:25:50,460
nós uh aqui a cor mais brilhante indica

445
00:25:50,460 --> 00:25:54,779
a previsão de uh dados uh sem

446
00:25:54,779 --> 00:25:59,159
se referir aos dados de atividade então

447
00:25:59,159 --> 00:26:00,779
essas linhas uh

448
00:26:00,779 --> 00:26:03,419
seguem exatamente esse gradiente de frequência

449
00:26:03,419 --> 00:26:05,100


450
00:26:05,100 --> 00:26:09,320
e descobrimos que essa trajetória prevista

451
00:26:09,320 --> 00:26:11,000


452
00:26:11,000 --> 00:26:16,700
é um título  título correlacionado com esses

453
00:26:16,700 --> 00:26:20,220


454
00:26:20,220 --> 00:26:21,840
pesos sinápticos efetivos estimados empiricamente

455
00:26:21,840 --> 00:26:26,039
e a taxa anterior é uh prática,

456
00:26:26,039 --> 00:26:30,240
então indica que no princípio

457
00:26:30,240 --> 00:26:31,500
pode

458
00:26:31,500 --> 00:26:34,919
uh prever quantitativamente a

459
00:26:34,919 --> 00:26:37,500
colonização em série nesta configuração, então

460
00:26:37,500 --> 00:26:40,919
indica alguma previsibilidade do

461
00:26:40,919 --> 00:26:44,039
princípio de frequência neste setor

462
00:26:44,039 --> 00:26:47,820
e então também consideramos  a modelagem

463
00:26:47,820 --> 00:26:51,779
da modulação neural uh

464
00:26:51,779 --> 00:26:54,900
usando inferência ativa é bem conhecido

465
00:26:54,900 --> 00:26:58,559
que o processo sináptico é modificado por

466
00:26:58,559 --> 00:27:02,760
vários fatores como a dopamina ou outros

467
00:27:02,760 --> 00:27:05,340
ativos de aprendizagem que registram a serotonina e assim por

468
00:27:05,340 --> 00:27:06,059
diante

469
00:27:06,059 --> 00:27:09,840
e uma propriedade interessante dessas

470
00:27:09,840 --> 00:27:14,700
modulações que mesmo assim a dopamina foi

471
00:27:14,700 --> 00:27:15,779
adicionada

472
00:27:15,779 --> 00:27:17,299
após a

473
00:27:17,299 --> 00:27:21,679
plasticidade associativa foi  estabelecido

474
00:27:21,679 --> 00:27:25,980
que pode alterar o resultado da plasticidade

475
00:27:25,980 --> 00:27:29,340
de uma maneira post-hoc ou menos respectiva,

476
00:27:29,340 --> 00:27:31,860
então está

477
00:27:31,860 --> 00:27:35,760
impressionado alguma associação com a

478
00:27:35,760 --> 00:27:39,419
recompensa e decisões anteriores, então modelamos

479
00:27:39,419 --> 00:27:42,059
esse processo usando rede neural canônica,

480
00:27:42,059 --> 00:27:45,480
então aqui modelamos

481
00:27:45,480 --> 00:27:46,880
a

482
00:27:46,880 --> 00:27:51,659
modulação Hulk da plasticidade ABN usando

483
00:27:51,659 --> 00:27:56,940
uh, esse tipo de uh equação plástica e

484
00:27:56,940 --> 00:27:59,760
também consideramos a

485
00:27:59,760 --> 00:28:03,659
estrutura da rede neural recorrente e fora da Coreia para

486
00:28:03,659 --> 00:28:06,179
esta rede e consideramos que a

487
00:28:06,179 --> 00:28:12,299
modulação ocorreu nesta conectividade

488
00:28:13,980 --> 00:28:19,200
uma camada e então encontramos uh

489
00:28:19,200 --> 00:28:23,600
funções de custo que podem derivar essas

490
00:28:23,600 --> 00:28:26,940
equações diferenciais e então  formou um

491
00:28:26,940 --> 00:28:29,520


492
00:28:29,520 --> 00:28:33,299
modelo variacional correspondente para energia e modelo genético, o que significa que este

493
00:28:33,299 --> 00:28:35,279
tipo de atividade de rede neural

494
00:28:35,279 --> 00:28:37,919
incluindo modulação de plasticidade sinusal

495
00:28:37,919 --> 00:28:41,940
segue exatamente o princípio de energia livre

496
00:28:41,940 --> 00:28:43,159
e

497
00:28:43,159 --> 00:28:45,380
algum tipo de

498
00:28:45,380 --> 00:28:47,400
modelo de homogeneidade

499
00:28:47,400 --> 00:28:53,480
e usando isso mostramos que esta

500
00:28:53,480 --> 00:28:55,940


501
00:28:55,940 --> 00:28:58,980
rede neural biológica acessível  modelo com modulação e

502
00:28:58,980 --> 00:29:01,799
peso e plasticidade pode resolver algum

503
00:29:01,799 --> 00:29:06,360
tipo de tarefa de recompensa atrasada, como tarefa de labirinto

504
00:29:06,360 --> 00:29:07,980


505
00:29:07,980 --> 00:29:10,140
e, finalmente, gostaríamos de

506
00:29:10,140 --> 00:29:12,659
discutir uma possível extensão desta

507
00:29:12,659 --> 00:29:16,080
estrutura para a inteligência social moderna,

508
00:29:16,080 --> 00:29:21,960
para inferir nossas

509
00:29:21,960 --> 00:29:26,580
especificidades, uh uh, nós  precisamos selecionar uma

510
00:29:26,580 --> 00:29:28,860
abordagem para criar um modelo de generalidade ou

511
00:29:28,860 --> 00:29:32,760
ou nossos parceiros, dependendo de nossa

512
00:29:32,760 --> 00:29:36,480
presença, para que isso possa ser feito pelo

513
00:29:36,480 --> 00:29:39,299
esquema de seleção de modelo principal e

514
00:29:39,299 --> 00:29:42,380
propusemos anteriormente um modelo que pode

515
00:29:42,380 --> 00:29:48,419
prever as múltiplas formas válidas usando

516
00:29:48,419 --> 00:29:49,640


517
00:29:49,640 --> 00:29:53,279
um grande modelo generativo que  compreende

518
00:29:53,279 --> 00:29:58,080
vários modelos genéticos e este filme

519
00:29:58,080 --> 00:29:59,520
mostra uh

520
00:29:59,520 --> 00:30:03,440
previsão de

521
00:30:04,620 --> 00:30:07,919
previsão de uh músicas

522
00:30:07,919 --> 00:30:13,640
então assim uh este moderno 93

523
00:30:13,640 --> 00:30:17,940
identifica qual modelo gigante é o melhor

524
00:30:17,940 --> 00:30:21,600
ocorrido explicou uma determinada entrada sensorial

525
00:30:21,600 --> 00:30:25,860
e este processo indica que o e

526
00:30:25,860 --> 00:30:26,760


527
00:30:26,760 --> 00:30:30,360
o modelo pode inserir corretamente o

528
00:30:30,360 --> 00:30:32,399
apropriado  modelo

529
00:30:32,399 --> 00:30:36,539
e então imitar a música

530
00:30:36,539 --> 00:30:39,000
por sua própria ação,

531
00:30:39,000 --> 00:30:40,140


532
00:30:40,140 --> 00:30:42,299
embora no trabalho anterior não tenhamos

533
00:30:42,299 --> 00:30:46,500
discutido um substrato neuronal detalhado

534
00:30:46,500 --> 00:30:51,059
para este modelo de geografia de mistura, agora

535
00:30:51,059 --> 00:30:55,039
podemos considerar a

536
00:30:55,039 --> 00:30:58,559
arquitetura correspondente, por exemplo,

537
00:30:58,559 --> 00:31:03,000
se considerarmos a modulação do módulo

538
00:31:03,000 --> 00:31:05,480
neural  módulo por

539
00:31:05,480 --> 00:31:09,779
neuromodulador como dopamina como um

540
00:31:09,779 --> 00:31:13,620
filtro de atenção e esse

541
00:31:13,620 --> 00:31:16,860
filtro de atenção pode ser explicado por uh

542
00:31:16,860 --> 00:31:19,820
três fatores pesados ​​​​e grupo em execução

543
00:31:19,820 --> 00:31:22,799
introduzem o introduzido no

544
00:31:22,799 --> 00:31:28,620
slide anterior, então novamente esta modulação

545
00:31:28,620 --> 00:31:33,919
funciona como a modulação post-hoc sem

546
00:31:33,919 --> 00:31:37,080
plasticidade mais pesada no passado  e esta modulação

547
00:31:37,080 --> 00:31:38,659
pode

548
00:31:38,659 --> 00:31:42,080
otimizar cada modelo para representar um

549
00:31:42,080 --> 00:31:46,440
modelo de generalidade, um geral, uh, uma música

550
00:31:46,440 --> 00:31:48,320
daquela

551
00:31:48,320 --> 00:31:52,140
maneira mutuamente independente, então, através

552
00:31:52,140 --> 00:31:56,039
deste processo, é possível aprender

553
00:31:56,039 --> 00:31:59,100
modelos genéticos múltiplos, uh, de uma

554
00:31:59,100 --> 00:32:02,820
maneira virtualmente possível, então, em resumo, descobrimos

555
00:32:02,820 --> 00:32:05,340
que a dinâmica de  redes neurais canônicas

556
00:32:05,340 --> 00:32:07,679
que minimizam a função de custo

557
00:32:07,679 --> 00:32:12,299
podem ser lidas como uma minimização na

558
00:32:12,299 --> 00:32:15,000
variação de energia, isso indica que um

559
00:32:15,000 --> 00:32:17,880
princípio de frequência é uma explicação

560
00:32:17,880 --> 00:32:21,960
para esse tipo de rede neural e

561
00:32:21,960 --> 00:32:27,120
também validamos essa previsão usando alguma

562
00:32:27,120 --> 00:32:31,440
configuração individual, mostrando isso

563
00:32:31,440 --> 00:32:33,480
e mostrando que  amigo como

564
00:32:33,480 --> 00:32:36,240
princípio pode qualificar e

565
00:32:36,240 --> 00:32:38,399
prever quantitativamente a auto-organização da

566
00:32:38,399 --> 00:32:42,720
subsequente uh plasticidade usando apenas os

567
00:32:42,720 --> 00:32:44,880
dados iniciais

568
00:32:44,880 --> 00:32:49,380
e como modelagem podemos estender uh

569
00:32:49,380 --> 00:32:53,460
aquela modelagem de rede canônica uh para

570
00:32:53,460 --> 00:32:54,320
a

571
00:32:54,320 --> 00:32:57,840
geração de opção outro planejamento através

572
00:32:57,840 --> 00:33:01,020
da modulação atrasada de pesado e

573
00:33:01,020 --> 00:33:02,399
plasticidade

574
00:33:02,399 --> 00:33:06,179
e  finalmente discutimos a possibilidade

575
00:33:06,179 --> 00:33:10,640
de estender este modelo canônico para Modern,

576
00:33:10,640 --> 00:33:15,919
a inteligência social ou compartilhada

577
00:33:15,919 --> 00:33:20,840
para interagir com parceiros completos da Mars,

578
00:33:20,840 --> 00:33:25,140
então essas são todas as minhas palestras, obrigado por

579
00:33:25,140 --> 00:33:28,380
ouvir, uh, isso é um reconhecimento ao nosso

580
00:33:28,380 --> 00:33:31,799
colaborador e às descobertas e nossa

581
00:33:31,799 --> 00:33:35,360
unidade agora está recrutando uh

582
00:33:35,360 --> 00:33:37,679
pesquisadores, então se você estiver interessado em uma

583
00:33:37,679 --> 00:33:40,399
verificação gratuita,

584
00:33:41,460 --> 00:33:43,860
incrível, obrigado pela apresentação

585
00:33:43,860 --> 00:33:46,500
para kuya,

586
00:33:46,500 --> 00:33:49,140
farei apenas algumas perguntas rápidas

587
00:33:49,140 --> 00:33:50,700
no chat ao vivo e algumas outras

588
00:33:50,700 --> 00:33:54,360
coisas que surgirem, então Dave disse que

589
00:33:54,360 --> 00:33:57,480
takuya usou a frase depois que a plasticidade

590
00:33:57,480 --> 00:33:59,399
foi  estabelecido

591
00:33:59,399 --> 00:34:03,240
se o grupo dele foi capaz de modificar o EG, aumentar a

592
00:34:03,240 --> 00:34:06,059
plasticidade ou ele está dizendo apenas que

593
00:34:06,059 --> 00:34:10,159
foi demonstrado que existe plasticidade

594
00:34:10,918 --> 00:34:12,960
ou

595
00:34:12,960 --> 00:34:16,320
sim, não tenho certeza se entendi

596
00:34:16,320 --> 00:34:19,800
corretamente sua pergunta, mas uh, esses

597
00:34:19,800 --> 00:34:23,639
grupos mostraram que uh, o grupo mostrou

598
00:34:23,639 --> 00:34:25,918
que a dopamina

599
00:34:25,918 --> 00:34:29,879
adiciona dopamina  depois de dois segundos após a

600
00:34:29,879 --> 00:34:32,399


601
00:34:32,399 --> 00:34:36,359
ocorrência da associação pode mudar a

602
00:34:36,359 --> 00:34:40,800
magnitude da rusticidade, então

603
00:34:40,800 --> 00:34:42,960
sem

604
00:34:42,960 --> 00:34:45,960
uh como dizer uh

605
00:34:45,960 --> 00:34:50,280
se a dopamina é esta adição foi antes

606
00:34:50,280 --> 00:34:54,119
desta associação então o nível de processabilidade

607
00:34:54,119 --> 00:34:59,220
é baixo, mas uh depois como uma

608
00:34:59,220 --> 00:35:02,760
edição de dopamina após a associação pode  mudar

609
00:35:02,760 --> 00:35:07,280
este nível pode aumentar a plasticidade

610
00:35:07,280 --> 00:35:12,060
assim ou assim, o que indica

611
00:35:12,060 --> 00:35:15,859
a ferramenta de modulação post-hoc.

612
00:35:16,440 --> 00:35:19,859
Acho que isso responde

613
00:35:19,859 --> 00:35:20,760
bem, pelo que

614
00:35:20,760 --> 00:35:23,040


615
00:35:23,040 --> 00:35:25,440
você está animado ou quais são

616
00:35:25,440 --> 00:35:26,480
suas

617
00:35:26,480 --> 00:35:30,839
esperanças ou sentimentos sobre onde

618
00:35:30,839 --> 00:35:33,000
está o ecossistema de inferência de oitava  e para onde

619
00:35:33,000 --> 00:35:34,859
iremos nos próximos meses e

620
00:35:34,859 --> 00:35:37,040
anos,

621
00:35:39,480 --> 00:35:41,880
mas sinto muito, uh

622
00:35:41,880 --> 00:35:45,480
de novo, então é apenas com o que você está

623
00:35:45,480 --> 00:35:47,579
animado além de suas próprias

624
00:35:47,579 --> 00:35:49,619
direções de pesquisa com o que você está animado

625
00:35:49,619 --> 00:35:52,859
no ecossistema de inferência ativa,

626
00:35:52,859 --> 00:35:58,320
sim, então é claro que One Direction é o

627
00:35:58,320 --> 00:36:01,320
a modelagem da

628
00:36:01,320 --> 00:36:06,359
interação social, que é uma

629
00:36:06,359 --> 00:36:09,839
arquitetura muito mais rica do que a

630
00:36:09,839 --> 00:36:12,480
interação entre o

631
00:36:12,480 --> 00:36:15,960
ambiente estático, então se ambos os Alcorões asiáticos entre

632
00:36:15,960 --> 00:36:19,320
si, então muitos

633
00:36:19,320 --> 00:36:21,900
fenômenos interessantes podem ser observados, então estamos

634
00:36:21,900 --> 00:36:25,740
entusiasmados com os fenômenos modernos dos Zords

635
00:36:25,740 --> 00:36:29,400
usando consulta de vírus  plausível uh

636
00:36:29,400 --> 00:36:33,320
Modelo de rede neural de rede através

637
00:36:33,320 --> 00:36:36,980
desta equivalência

638
00:36:37,800 --> 00:36:39,240
incrível

639
00:36:39,240 --> 00:36:43,220
qualquer último comentário

640
00:36:46,500 --> 00:36:50,420
qualquer outro comentário que você queira fazer

641
00:36:56,880 --> 00:36:58,980
incrível

642
00:36:58,980 --> 00:37:01,800
obrigado novamente pela apresentação e as

643
00:37:01,800 --> 00:37:04,079
pessoas deveriam conferir a transmissão ao vivo 51

644
00:37:04,079 --> 00:37:06,599
onde você e eu conversamos algumas outras vezes

645
00:37:06,599 --> 00:37:09,119
e entramos em alguns dos  detalhes sobre

646
00:37:09,119 --> 00:37:10,859
esse trabalho, realmente há muita coisa

647
00:37:10,859 --> 00:37:14,000
lá, é realmente emocionante,

648
00:37:15,060 --> 00:37:16,920
obrigado,

649
00:37:16,920 --> 00:37:18,720
tudo bem, obrigado, até a

650
00:37:18,720 --> 00:37:22,079
próxima, tchau, até a próxima,

651
00:37:22,079 --> 00:37:24,920
tchau,

652
00:37:28,920 --> 00:37:31,920
estrangeiro

