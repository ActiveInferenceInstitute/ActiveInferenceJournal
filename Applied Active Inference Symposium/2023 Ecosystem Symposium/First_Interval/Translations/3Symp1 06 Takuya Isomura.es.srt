1
00:00:00,000 --> 00:00:01,800
extranjero,

2
00:00:01,800 --> 00:00:04,500
gracias por unirte hasta la próxima, hasta la próxima,

3
00:00:04,500 --> 00:00:05,580


4
00:00:05,580 --> 00:00:09,140
muchas gracias, adiós, está

5
00:00:14,280 --> 00:00:17,058
bien,

6
00:00:20,640 --> 00:00:24,500
fantásticos saludos a Corea,

7
00:00:24,500 --> 00:00:27,300
hasta la próxima, hasta la próxima,

8
00:00:27,300 --> 00:00:29,279
puedes

9
00:00:29,279 --> 00:00:31,859
silenciar la transmisión en vivo o apagar la

10
00:00:31,859 --> 00:00:33,480
otra transmisión en vivo, pero sí, gracias por

11
00:00:33,480 --> 00:00:35,399
unirte,

12
00:00:35,399 --> 00:00:39,059
sí, gracias.  por invitar, gracias

13
00:00:39,059 --> 00:00:42,019
por ello, sí,

14
00:00:43,800 --> 00:00:46,399
bueno,

15
00:00:46,440 --> 00:00:48,239
tenemos

16
00:00:48,239 --> 00:00:53,039
un poco de 35 o 38 minutos, así que

17
00:00:53,039 --> 00:00:55,199
sería increíble tener tu

18
00:00:55,199 --> 00:00:57,739
presentación

19
00:00:58,860 --> 00:01:02,460
correcta, así que en

20
00:01:03,239 --> 00:01:05,880
el momento, bueno, ¿

21
00:01:05,880 --> 00:01:08,539


22
00:01:10,380 --> 00:01:14,880
puedes ver mi? Bueno,

23
00:01:14,880 --> 00:01:18,500
pero vi PowerPoint,

24
00:01:20,220 --> 00:01:23,220
¿vale? ¿

25
00:01:23,220 --> 00:01:27,659
Puedes ver mi?  pantalla uh perfecto perfecto

26
00:01:27,659 --> 00:01:29,820
vale

27
00:01:29,820 --> 00:01:33,659
entonces empecemos sí gracias

28
00:01:33,659 --> 00:01:38,280
vale oh entonces uh gracias por

29
00:01:38,280 --> 00:01:41,759
organizar este maravilloso Simposio

30
00:01:41,759 --> 00:01:45,479
hoy Me gustaría hablar sobre la

31
00:01:45,479 --> 00:01:48,000
relación entre la red neuronal canónica

32
00:01:48,000 --> 00:01:52,200
y la inferencia activa uh y su

33
00:01:52,200 --> 00:01:56,280
posible extensión uh o  moderno uh

34
00:01:56,280 --> 00:01:59,460
social sobre la inteligencia compartida usando

35
00:01:59,460 --> 00:02:04,880
redes neuronales canónicas, así que comencemos,

36
00:02:08,160 --> 00:02:11,220
como usted sabe, el principio de energía libre

37
00:02:11,220 --> 00:02:13,980
es propuesto por un soporte independiente del automóvil

38
00:02:13,980 --> 00:02:16,920
que establece que el

39
00:02:16,920 --> 00:02:19,200
aprendizaje de la percepción y la opción de todos los

40
00:02:19,200 --> 00:02:21,840
organismos biológicos están determinados a minimizar la

41
00:02:21,840 --> 00:02:24,720
variación de energía como  un proxy manejable

42
00:02:24,720 --> 00:02:28,260
para la minimización de sorpresas y mediante este

43
00:02:28,260 --> 00:02:31,580
proceso los organismos pueden realizar

44
00:02:31,580 --> 00:02:34,800
inferencias paracionales de Beijing o

45
00:02:34,800 --> 00:02:36,900
estados minerales externos

46
00:02:36,900 --> 00:02:40,379
y esta es esta caricatura solo muestra un

47
00:02:40,379 --> 00:02:43,860
ejemplo de configuración típica bajo el

48
00:02:43,860 --> 00:02:46,640
principio de energía libre inferencia activa aquí

49
00:02:46,640 --> 00:02:49,920
hay un estado oculto en el

50
00:02:49,920 --> 00:02:52,920
mundo externo y solo una parte de este

51
00:02:52,920 --> 00:02:58,319
estado puede ser observable para nuestro

52
00:02:58,319 --> 00:03:00,959
agente, este muelle

53
00:03:00,959 --> 00:03:04,319
y esta transformación se realiza mediante un

54
00:03:04,319 --> 00:03:06,060
parámetro del modelo genético Wise

55
00:03:06,060 --> 00:03:08,660
parametrizado por Theta

56
00:03:08,660 --> 00:03:12,780
y para el estado oculto, el agente

57
00:03:12,780 --> 00:03:17,459
necesita reconstruir la copia del

58
00:03:17,459 --> 00:03:21,060
estado externo.  llamado alivio posterior

59
00:03:21,060 --> 00:03:24,239
y esta optimización se realiza

60
00:03:24,239 --> 00:03:27,900
minimizando una energía libre variacional

61
00:03:27,900 --> 00:03:31,860
y el parámetro también se optimiza

62
00:03:31,860 --> 00:03:35,099
minimizando la energía libre para obtener un

63
00:03:35,099 --> 00:03:37,379
modelo generador que represente esta

64
00:03:37,379 --> 00:03:40,560
relación. Un aspecto interesante de la

65
00:03:40,560 --> 00:03:42,299


66
00:03:42,299 --> 00:03:44,819
influencia activa del trasplante de energía libre es su aplicación a la

67
00:03:44,819 --> 00:03:48,000
optimización de  acción aquí nuestro agente

68
00:03:48,000 --> 00:03:51,239
tiene cierta preferencia antes de C y para

69
00:03:51,239 --> 00:03:54,860
obtener esta observación en el futuro el

70
00:03:54,860 --> 00:03:59,280
agente puede seleccionar la acción que

71
00:03:59,280 --> 00:04:02,640
minimice la energía libre esperada en el

72
00:04:02,640 --> 00:04:05,580
futuro para

73
00:04:05,580 --> 00:04:09,540
obtener el resultado más predecible

74
00:04:09,540 --> 00:04:14,280
y finalmente seleccionando

75
00:04:14,280 --> 00:04:16,019
acciones que minimicen la

76
00:04:16,019 --> 00:04:19,738
frecuencia esperada.  puede obtener la alimentación,

77
00:04:19,738 --> 00:04:23,160
por lo que esta es una configuración típica de la

78
00:04:23,160 --> 00:04:25,919
infraestructura activa. La pregunta es cuál es el

79
00:04:25,919 --> 00:04:28,680
sustrato neuronal que puede implementar

80
00:04:28,680 --> 00:04:31,500
este proceso, de modo que ese es nuestro

81
00:04:31,500 --> 00:04:34,500
interés y para abordar este tema

82
00:04:34,500 --> 00:04:38,520
proponemos una teoría de la siguiente manera, aquí

83
00:04:38,520 --> 00:04:41,880
consideramos que uh  El mundo externo está

84
00:04:41,880 --> 00:04:45,120
parametrizado caracterizado por un conjunto de

85
00:04:45,120 --> 00:04:50,580
variables como este aquí, esto es una

86
00:04:50,580 --> 00:04:53,940
expectativa posterior y

87
00:04:53,940 --> 00:04:57,600
como indica el estado oculto en

88
00:04:57,600 --> 00:05:01,440
Excel o Delta indica la acción

89
00:05:01,440 --> 00:05:05,460
del agente o decisión y Theta

90
00:05:05,460 --> 00:05:08,820
uh indica un parámetro y Lambda

91
00:05:08,820 --> 00:05:14,580
es un  hiperparámetro, por lo que esos

92
00:05:14,580 --> 00:05:18,240
parámetros o variables establecidos caracterizan

93
00:05:18,240 --> 00:05:22,940
un modelo de generalidad y la variación de energía libre

94
00:05:22,940 --> 00:05:25,560
de la energía se define como una

95
00:05:25,560 --> 00:05:28,800
función de la secuencia de observación

96
00:05:28,800 --> 00:05:31,620
y el estado externo y su

97
00:05:31,620 --> 00:05:33,900
minimización indica la inferencia de la

98
00:05:33,900 --> 00:05:36,419
ecuación operativa de energía libre variacional

99
00:05:36,419 --> 00:05:38,880
de manera

100
00:05:38,880 --> 00:05:42,780
similar  Consideremos una dinámica de

101
00:05:42,780 --> 00:05:45,919
red neuronal y consideramos que una

102
00:05:45,919 --> 00:05:48,900
dinámica se caracteriza por un estado de

103
00:05:48,900 --> 00:05:52,320
esas variables aquí x indica que la

104
00:05:52,320 --> 00:05:55,199
actividad neuronal tasa de disparo en las neuronas del

105
00:05:55,199 --> 00:05:56,780
área media

106
00:05:56,780 --> 00:06:01,080
y el indicador Y cerca de la

107
00:06:01,080 --> 00:06:04,020
actividad de las radioneuronas de salida y W

108
00:06:04,020 --> 00:06:07,919
aquí es un peso sináptico  y Phi es

109
00:06:07,919 --> 00:06:10,680
el otro, cualquier otro parámetro libre que

110
00:06:10,680 --> 00:06:13,740
caracterice la red neuronal y

111
00:06:13,740 --> 00:06:17,060
consideramos que la dinámica de la red neuronal se

112
00:06:17,060 --> 00:06:19,979
caracteriza por la minimización de alguna

113
00:06:19,979 --> 00:06:23,520
función de costo. Aquí esta es una función

114
00:06:23,520 --> 00:06:26,220
del O y el estado interno de Phi de la

115
00:06:26,220 --> 00:06:28,500
red neuronal y

116
00:06:28,500 --> 00:06:32,039
yo es su minimización.  indican la

117
00:06:32,039 --> 00:06:34,500
generación de la dinámica de la red neuronal

118
00:06:34,500 --> 00:06:37,740
que incluye tanto la actividad como la

119
00:06:37,740 --> 00:06:41,940
plasticidad y nuestra teoría indica una

120
00:06:41,940 --> 00:06:45,500
equivalencia entre las dos funciones, lo que

121
00:06:45,500 --> 00:06:49,979
significa que para cualquier red neuronal que

122
00:06:49,979 --> 00:06:52,380
minimice algún error de costo funcional

123
00:06:52,380 --> 00:06:55,620
existe un modelo genético que satisface si

124
00:06:55,620 --> 00:06:59,720
llamamos Aire, lo que significa que  uh uh,

125
00:06:59,720 --> 00:07:01,940
la

126
00:07:01,940 --> 00:07:05,340
recaptura de la dinámica externa es una

127
00:07:05,340 --> 00:07:08,580
característica inherente de cualquier sistema neuronal

128
00:07:08,580 --> 00:07:13,319
que para dicha dinámica, por lo que esta es una

129
00:07:13,319 --> 00:07:16,680
predicción interesante, pero las otras dos

130
00:07:16,680 --> 00:07:17,780
estructuras,

131
00:07:17,780 --> 00:07:21,780
así que me gustaría presentar algún

132
00:07:21,780 --> 00:07:24,180
ejemplo analíticamente interactuable para

133
00:07:24,180 --> 00:07:28,620
comprender esta relación formalmente,

134
00:07:28,620 --> 00:07:31,759
así que primero consideramos  una arquitectura muy simple,

135
00:07:31,759 --> 00:07:35,280
esto está representado por un

136
00:07:35,280 --> 00:07:39,660
Pome DP sin ninguna transición de etapa, por lo que

137
00:07:39,660 --> 00:07:43,220
no tomó s, simplemente se

138
00:07:43,220 --> 00:07:46,319
genera mediante la distribución del año de vuelo D

139
00:07:46,319 --> 00:07:52,620
y es un estado binario, pero

140
00:07:52,620 --> 00:07:56,160
consideramos un vector de estados binarios, por lo que

141
00:07:56,160 --> 00:08:00,240
es un  La fábrica factorial de estructura y la

142
00:08:00,240 --> 00:08:03,900
observación uh también es un

143
00:08:03,900 --> 00:08:08,220
vector binario y la transformación de s a

144
00:08:08,220 --> 00:08:11,160
O se caracteriza por una

145
00:08:11,160 --> 00:08:16,979
distribución categórica. El uso de una Matriz a regular

146
00:08:16,979 --> 00:08:20,099
y la inferencia variacional de Beijing

147
00:08:20,099 --> 00:08:22,919
indican la inversión de este

148
00:08:22,919 --> 00:08:27,180
proceso generativo como este, por lo que

149
00:08:27,180 --> 00:08:29,660
resolviendo el funcional de energía libre apropiado

150
00:08:29,660 --> 00:08:33,599
obtenemos ese

151
00:08:33,599 --> 00:08:37,219
resumen posterior que es óptimo en el

152
00:08:37,219 --> 00:08:40,140
sentido bayesiano,

153
00:08:40,140 --> 00:08:42,479
por lo que, por otro lado, para la red neuronal

154
00:08:42,479 --> 00:08:46,920
consideramos dicha estructura. Aquí la

155
00:08:46,920 --> 00:08:50,040
parte superior indica la generación de señales

156
00:08:50,040 --> 00:08:52,560
en el mundo externo y la

157
00:08:52,560 --> 00:08:55,320
red neuronal comprende solo una capa

158
00:08:55,320 --> 00:08:59,880
aquí, actividad de  capa de salida generada

159
00:08:59,880 --> 00:09:02,540
por una suma relacionada de

160
00:09:02,540 --> 00:09:06,839
entrada sensorial o ponderada por la

161
00:09:06,839 --> 00:09:10,440
Matriz sináptica W y luego caracterizamos esta

162
00:09:10,440 --> 00:09:12,120
red neuronal

163
00:09:12,120 --> 00:09:14,339
en la siguiente diapositiva,

164
00:09:14,339 --> 00:09:18,360
por lo que para modelar la red neuronal o

165
00:09:18,360 --> 00:09:19,700
neurona

166
00:09:19,700 --> 00:09:22,760
comenzamos considerando la

167
00:09:22,760 --> 00:09:27,600
ecuación del proyecto, que es el uh cuatro uh que

168
00:09:27,600 --> 00:09:30,839
comprende  cuatro ecuaciones diferenciales y

169
00:09:30,839 --> 00:09:33,959
esta es una ecuación no lineal muy complicada

170
00:09:33,959 --> 00:09:37,500
y aunque es una barricada

171
00:09:37,500 --> 00:09:40,260
posible, consideramos alguna reducción

172
00:09:40,260 --> 00:09:43,880
de estas ecuaciones, por lo que se practica un

173
00:09:43,880 --> 00:09:47,279
método de reducción típico,

174
00:09:47,279 --> 00:09:52,080
por ejemplo, M aquí es mucho

175
00:09:52,080 --> 00:09:55,019
más rápido que otras variables, por lo que esto puede

176
00:09:55,019 --> 00:09:59,580
ser reemplazado con su punto fijo o se

177
00:09:59,580 --> 00:10:04,080
sabe que H y menos uno lo siento, se

178
00:10:04,080 --> 00:10:09,480
sabe que H y 1 menos s n

179
00:10:09,480 --> 00:10:13,620
tienen una dinámica similar, por lo que podemos

180
00:10:13,620 --> 00:10:17,339
considerar una nueva variable efectiva U para

181
00:10:17,339 --> 00:10:19,700
caracterizar esas dos

182
00:10:19,700 --> 00:10:23,459
variables y luego obtenemos  a la

183
00:10:23,459 --> 00:10:28,019
ecuación positiva como esta, esta es

184
00:10:28,019 --> 00:10:31,820
una clase famosa de modelo de red neuronal

185
00:10:31,820 --> 00:10:36,180
que incluye el conocido

186
00:10:36,180 --> 00:10:40,820
modelo de vista y acuerdo fijo u otro

187
00:10:40,820 --> 00:10:44,160
modelo de red neuronal continua y

188
00:10:44,160 --> 00:10:49,860
modificamos esos modelos para derivar un

189
00:10:49,860 --> 00:10:52,740
modelo neuronal canónico, por lo que  Esta es una

190
00:10:52,740 --> 00:10:56,220
definición de un modelo de red neuronal canónica.

191
00:10:56,220 --> 00:10:59,459
Aquí la

192
00:10:59,459 --> 00:11:02,579
corriente de fuga se caracteriza por una

193
00:11:02,579 --> 00:11:06,000
función sumoide en el bus en lugar de una

194
00:11:06,000 --> 00:11:08,940
función cúbica que se adopta en el

195
00:11:08,940 --> 00:11:12,060
modelo de Nagma de Fitsview y también

196
00:11:12,060 --> 00:11:15,180
consideramos una conexión sináptica

197
00:11:15,180 --> 00:11:18,980
y esta parte indica una

198
00:11:18,980 --> 00:11:22,820
entrada sináptica.  desde una capa sensorial

199
00:11:22,820 --> 00:11:28,440
a través de matrices de peso uh y se puede

200
00:11:28,440 --> 00:11:31,800
considerar que W1 indica

201
00:11:31,800 --> 00:11:34,320
sinapsis excitatoria y w0 indica

202
00:11:34,320 --> 00:11:37,579
sinapsis de inventario y los

203
00:11:37,579 --> 00:11:40,140
umbrales adaptativos de sudadera que son función

204
00:11:40,140 --> 00:11:45,180
de WR y w0 ahora, curiosamente, cuando

205
00:11:45,180 --> 00:11:47,880
consideramos un punto fijo de esta

206
00:11:47,880 --> 00:11:51,480
ecuación diferencial obtenemos una

207
00:11:51,480 --> 00:11:54,899
buena  -modelo de codificación roja conocido con la

208
00:11:54,899 --> 00:11:58,500
función de activación sigmoider, lo

209
00:11:58,500 --> 00:12:01,920
que significa que podemos decir que, en

210
00:12:01,920 --> 00:12:03,920
cierto sentido, este modelo de red neuronal canónica

211
00:12:03,920 --> 00:12:08,940
es una aproximación de lo que puede

212
00:12:08,940 --> 00:12:12,540
tener la ecuación y su

213
00:12:12,540 --> 00:12:16,140
nivel de aproximación es,

214
00:12:16,140 --> 00:12:19,380
en cierto sentido, entre lo realista.

215
00:12:19,380 --> 00:12:22,920
modelo y el modelo de codificación roja más simplificado,

216
00:12:22,920 --> 00:12:26,640
por lo que básicamente consideramos este tipo

217
00:12:26,640 --> 00:12:30,120
de modelo de red neuronal y en la siguiente

218
00:12:30,120 --> 00:12:31,700
diapositiva

219
00:12:31,700 --> 00:12:35,279
consideramos cuál es la función de costo plausible

220
00:12:35,279 --> 00:12:39,000
para este modelo de red neuronal,

221
00:12:39,000 --> 00:12:42,360
por lo que nuevamente

222
00:12:42,360 --> 00:12:45,600
escribimos la misma ecuación para el

223
00:12:45,600 --> 00:12:49,079
modelo de red neuronal canónica que representa

224
00:12:49,079 --> 00:12:52,620
la actividad de las neuronas Vector de

225
00:12:52,620 --> 00:12:53,579
neuronas

226
00:12:53,579 --> 00:12:58,079
y consideramos una función de costo para esta

227
00:12:58,079 --> 00:13:00,180
ecuación diferencial que se puede

228
00:13:00,180 --> 00:13:02,600
obtener simplemente

229
00:13:02,600 --> 00:13:07,200
calculando la integral del

230
00:13:07,200 --> 00:13:12,300
lado derecho de esta ecuación y obtenemos este

231
00:13:12,300 --> 00:13:15,779
tipo de función de costo para la red neuronal.

232
00:13:15,779 --> 00:13:18,660
Esta es la función de costo biológica portátil.

233
00:13:18,660 --> 00:13:20,760
en el sentido de que su

234
00:13:20,760 --> 00:13:22,860
derivada derivó una actividad de red neuronal

235
00:13:22,860 --> 00:13:26,700
que tiene un cierto virus

236
00:13:26,700 --> 00:13:28,139
llamado probabilidad;

237
00:13:28,139 --> 00:13:29,779
además,

238
00:13:29,779 --> 00:13:33,899
si consideramos una derivada de esta

239
00:13:33,899 --> 00:13:36,480
función de costo con respecto al peso sinóptico

240
00:13:36,480 --> 00:13:41,700
w obtenemos una

241
00:13:41,700 --> 00:13:45,300
regla de plasticidad sináptica convencional que sigue la ley de hepia

242
00:13:45,300 --> 00:13:47,339


243
00:13:47,339 --> 00:13:51,260
uh por el otro  Para la

244
00:13:51,540 --> 00:13:54,060
inferencia de Beijing, primero definimos el

245
00:13:54,060 --> 00:13:57,779
modelo de generalidad, como en la

246
00:13:57,779 --> 00:14:03,720
diapositiva anterior, y luego derivamos lo siento,

247
00:14:03,720 --> 00:14:07,500
luego derivamos una energía variacional para

248
00:14:07,500 --> 00:14:10,620
el modelo genético dado, por lo que esta variación

249
00:14:10,620 --> 00:14:14,639
de la energía libre se deriva del

250
00:14:14,639 --> 00:14:19,019
modelo Palm DP en el modelo anterior.  La diapositiva

251
00:14:19,019 --> 00:14:23,100
y su minimización indican uh el

252
00:14:23,100 --> 00:14:26,279
bosque de Beijing y la carrera,

253
00:14:26,279 --> 00:14:30,740
por lo que formamos

254
00:14:30,920 --> 00:14:34,860
correspondencias formales entre un

255
00:14:34,860 --> 00:14:38,300
componente de esas dos funciones de costos

256
00:14:38,300 --> 00:14:42,920
como esta, por lo que este vector de bloque uh

257
00:14:42,920 --> 00:14:46,260
corresponde formalmente a este vector de bloque

258
00:14:46,260 --> 00:14:49,040
que representa la expectativa posterior

259
00:14:49,040 --> 00:14:53,160
y este logaritmo corresponde a este

260
00:14:53,160 --> 00:14:54,600
logaritmo.

261
00:14:54,600 --> 00:14:59,459
y en realidad esta matriz se puede

262
00:14:59,459 --> 00:15:02,339
representar como una matriz de bloques como

263
00:15:02,339 --> 00:15:06,019
esta y es un producto DOT que

264
00:15:06,019 --> 00:15:09,600
corresponde a este cálculo y

265
00:15:09,600 --> 00:15:12,620
finalmente, estos cinco

266
00:15:12,620 --> 00:15:16,320
corresponden naturalmente a esto, carga el

267
00:15:16,320 --> 00:15:20,880
logotipo del estado anterior, lo que significa que,

268
00:15:20,880 --> 00:15:24,540
porque la función de costo es la misma.

269
00:15:24,540 --> 00:15:28,519
es derivada uh

270
00:15:28,519 --> 00:15:31,860
proporciona la

271
00:15:31,860 --> 00:15:33,540


272
00:15:33,540 --> 00:15:37,980
su derivada proporciona algo

273
00:15:37,980 --> 00:15:39,600
[Música]

274
00:15:39,600 --> 00:15:44,120
lo siento porque la función de costo es

275
00:15:44,120 --> 00:15:48,420
formalmente equivalente es derivada uh es uh lo

276
00:15:48,420 --> 00:15:52,820
siento es un resultado de uh

277
00:15:52,820 --> 00:15:56,339
derivada también se corresponden entre

278
00:15:56,339 --> 00:16:00,839
sí, lo que significa que uh para  cualquier

279
00:16:00,839 --> 00:16:04,500
ecuación interactiva en esta forma,

280
00:16:04,500 --> 00:16:06,839
hay una

281
00:16:06,839 --> 00:16:09,899
ecuación de inferencia bayesiana correspondiente, esta es una ecuación

282
00:16:09,899 --> 00:16:13,860
que calcula la división posterior del

283
00:16:13,860 --> 00:16:17,579
estado de helio y este

284
00:16:17,579 --> 00:16:20,519
formato de ecuación del proceso sináptico corresponde al aprendizaje

285
00:16:20,519 --> 00:16:23,820
o parámetro del modelo generativo y,

286
00:16:23,820 --> 00:16:27,120
además, al establecer esta

287
00:16:27,120 --> 00:16:30,480
relación podemos considerar  la

288
00:16:30,480 --> 00:16:33,360
ingeniería inversa del modelo genético a partir de

289
00:16:33,360 --> 00:16:37,399
datos empíricos aquí, este

290
00:16:37,399 --> 00:16:38,959
esquema

291
00:16:38,959 --> 00:16:43,380
resume nuestro enfoque para realizar

292
00:16:43,380 --> 00:16:45,899
ingeniería inversa del modelo generativo y

293
00:16:45,899 --> 00:16:48,060
primero registramos la actividad neuronal y

294
00:16:48,060 --> 00:16:50,880
asignamos la red neuronal de Canon para

295
00:16:50,880 --> 00:16:54,779
explicar los datos obtenidos y

296
00:16:54,779 --> 00:16:57,240
calculando la integral que obtuvimos.  una

297
00:16:57,240 --> 00:16:59,660
función de costo para esta red canónica

298
00:16:59,660 --> 00:17:03,540
y por la equivalencia matemática que

299
00:17:03,540 --> 00:17:05,900
establecimos podemos

300
00:17:05,900 --> 00:17:09,000
identificar automáticamente un modelo genético y

301
00:17:09,000 --> 00:17:11,760
energía libre operativa libre que corresponden

302
00:17:11,760 --> 00:17:16,079
a esta arquitectura de red neuronal.

303
00:17:16,079 --> 00:17:20,059
Curiosamente, este es un agente bayesiano,

304
00:17:20,059 --> 00:17:24,020
que es un tipo de

305
00:17:24,020 --> 00:17:27,179
inteligencia artificial, pero lo más importante es que

306
00:17:27,179 --> 00:17:30,299
esta inteligencia artificial se

307
00:17:30,299 --> 00:17:33,660
deriva formalmente de datos empíricos, por lo que podemos

308
00:17:33,660 --> 00:17:37,520
decir que este agente es una

309
00:17:37,520 --> 00:17:39,960
inteligencia biométrica activa que sigue

310
00:17:39,960 --> 00:17:42,960
el principio de preenergía

311
00:17:42,960 --> 00:17:46,440
y luego su derivada con respecto a

312
00:17:46,440 --> 00:17:49,520
un parámetro posterior,

313
00:17:49,520 --> 00:17:52,919
derivados de algoritmos de prótesis sinápticas

314
00:17:52,919 --> 00:17:55,860
que siguen el  La minimización de energía libre

315
00:17:55,860 --> 00:18:00,600
y su integral de tiempo pueden predecir el

316
00:18:00,600 --> 00:18:03,720
proceso de ejecución de los datos de la red neuronal original,

317
00:18:03,720 --> 00:18:04,880


318
00:18:04,880 --> 00:18:07,380


319
00:18:07,380 --> 00:18:11,820
lo que significa que si la

320
00:18:11,820 --> 00:18:14,700
libertad es un principio es correcto, entonces

321
00:18:14,700 --> 00:18:17,100
esta predicción debería

322
00:18:17,100 --> 00:18:20,640
funcionar y debería poder

323
00:18:20,640 --> 00:18:24,900
predecir el resultado de esto.

324
00:18:24,900 --> 00:18:29,820
datos neuronales sin hacer referencia a los datos

325
00:18:29,820 --> 00:18:34,200
en sí, por lo que nuestra estrategia es, en resumen,

326
00:18:34,200 --> 00:18:37,460
nuestra estrategia es que

327
00:18:37,460 --> 00:18:41,760
reconstruimos el modelo genético solo a partir de los

328
00:18:41,760 --> 00:18:46,200
datos iniciales con datos iniciales similares

329
00:18:46,200 --> 00:18:50,160
antes de aprender y luego predecimos el

330
00:18:50,160 --> 00:18:52,520
proceso de ejecución o la curva

331
00:18:52,520 --> 00:18:56,880
que debería ejecutar este sistema neuronal.

332
00:18:56,880 --> 00:18:58,260
siga

333
00:18:58,260 --> 00:19:02,460
utilizando el principio de energía libre y

334
00:19:02,460 --> 00:19:05,640
compare o examine dónde

335
00:19:05,640 --> 00:19:09,179
es correcta esta predicción comparando los

336
00:19:09,179 --> 00:19:13,559
datos reales después de ejecutar y la

337
00:19:13,559 --> 00:19:16,200
predicción por el principio de frecuencia

338
00:19:16,200 --> 00:19:19,200
y si esta predicción es correcta, entonces

339
00:19:19,200 --> 00:19:22,320
indica la validez predictiva del

340
00:19:22,320 --> 00:19:25,200
principio de energía libre  y la configuración

341
00:19:25,200 --> 00:19:26,520
se consideró

342
00:19:26,520 --> 00:19:27,600
correcta,

343
00:19:27,600 --> 00:19:31,440
así que aplicamos esta estrategia a la

344
00:19:31,440 --> 00:19:34,679
red neuronal in vitro, por lo que aquí esta

345
00:19:34,679 --> 00:19:37,320
red neuronal in vitro se estimula

346
00:19:37,320 --> 00:19:40,460
usando el proceso genitivo de la forma DP

347
00:19:40,460 --> 00:19:44,460
definido en la diapositiva anterior, por lo que

348
00:19:44,460 --> 00:19:47,360
hay dos fuentes ocultas que son

349
00:19:47,360 --> 00:19:51,660
señales binarias y son  mezcla y se

350
00:19:51,660 --> 00:19:56,600
mezclan para generar 32

351
00:19:56,600 --> 00:20:01,860
transmisiones sensoriales, esos también son binarios

352
00:20:01,860 --> 00:20:06,780
y este es un experimento general al

353
00:20:06,780 --> 00:20:09,600
estimular neuronas in vitro que

354
00:20:09,600 --> 00:20:13,020
generan una respuesta de pico y

355
00:20:13,020 --> 00:20:16,880
esas rimas indican una

356
00:20:16,880 --> 00:20:23,460
respuesta de pico de alta densidad, así que obedecimos que,

357
00:20:23,460 --> 00:20:27,260
en algunos  neurona,

358
00:20:27,480 --> 00:20:30,360
la especificidad de la respuesta

359
00:20:30,360 --> 00:20:34,799
es, por lo que descubrimos que,

360
00:20:34,799 --> 00:20:37,820
para algunas neuronas, la

361
00:20:37,820 --> 00:20:41,539
respuesta era alta a la

362
00:20:41,539 --> 00:20:43,440


363
00:20:43,440 --> 00:20:47,700
señal de la Fuente Uno en comparación con la señal de la Fuente2

364
00:20:47,700 --> 00:20:54,179
y si vemos la transición de esas

365
00:20:54,179 --> 00:20:58,700
neuronas, descubrimos que aunque

366
00:20:58,700 --> 00:21:03,360
eliminamos el desplazamiento en la primera

367
00:21:03,360 --> 00:21:08,340
sesión.  para establecer esas actividades

368
00:21:08,340 --> 00:21:14,120
en cero, pero vemos que esas neuronas

369
00:21:14,120 --> 00:21:17,940
autoorganizadas responden alto cuando la

370
00:21:17,940 --> 00:21:21,960
fuente uno es uno, pero no uh,

371
00:21:21,960 --> 00:21:27,080
pero esas neuronas responden a un nivel bajo

372
00:21:27,080 --> 00:21:32,100
cuando la fuente uno es cero, lo que

373
00:21:32,100 --> 00:21:35,940
significa que esa actividad neuronal a través de

374
00:21:35,940 --> 00:21:39,860
las neuronas responde  Fue

375
00:21:39,860 --> 00:21:43,380
consistente con nuestra

376
00:21:43,380 --> 00:21:46,679
predicción teórica de que la nueva actividad se

377
00:21:46,679 --> 00:21:48,840
organiza para codificar la

378
00:21:48,840 --> 00:21:52,559
expectativa posterior del estado de helio y también

379
00:21:52,559 --> 00:21:54,720
descubrimos que algún otro grupo de neuronas

380
00:21:54,720 --> 00:21:58,020
responde preferentemente a la Fuente dos

381
00:21:58,020 --> 00:22:01,500
pero no a la Fuente Uno,

382
00:22:01,500 --> 00:22:07,980
entonces preguntamos, está bien, entonces encontramos

383
00:22:07,980 --> 00:22:11,100
que las expectativas posteriores codificadas por la

384
00:22:11,100 --> 00:22:13,080
actividad neuronal y la siguiente pregunta

385
00:22:13,080 --> 00:22:16,260
qué es lo otro, qué pasa con otro

386
00:22:16,260 --> 00:22:20,520
sustrato neuronal y luego preguntamos

387
00:22:20,520 --> 00:22:24,600
si la

388
00:22:24,980 --> 00:22:29,900
prioridad sobre el estado oculto es igual al

389
00:22:29,900 --> 00:22:33,179
grado efectivo igual al

390
00:22:33,179 --> 00:22:37,220
umbral de activación de un modelo de actividad neuronal

391
00:22:37,220 --> 00:22:41,220
Modelo de red uh  Entonces, si el servidor es

392
00:22:41,220 --> 00:22:43,860
correcto,

393
00:22:43,860 --> 00:22:48,600
debería existir la correspondencia correspondiente para verificar esto.

394
00:22:48,600 --> 00:22:52,980
Primero simulamos un agente de Beijing y cuando

395
00:22:52,980 --> 00:22:55,799
evaluamos la

396
00:22:55,799 --> 00:23:00,240
prioridad del agente de Beijing, la

397
00:23:00,240 --> 00:23:03,980
inferencia se atenuó como esperaba

398
00:23:03,980 --> 00:23:09,080
y advertimos que cuando enterramos el

399
00:23:09,080 --> 00:23:12,179
nivel excitador.  de la red neuronal in vitro

400
00:23:12,179 --> 00:23:15,120
mediante el uso de

401
00:23:15,120 --> 00:23:19,799
manipulación farmacológica también encontramos que

402
00:23:19,799 --> 00:23:22,919
la atenuación de la

403
00:23:22,919 --> 00:23:24,299
inferencia

404
00:23:24,299 --> 00:23:27,720
es consistente con nuestra

405
00:23:27,720 --> 00:23:30,320
predicción teórica de que el

406
00:23:30,320 --> 00:23:34,740
umbral de Finanzas codifica la prioridad o

407
00:23:34,740 --> 00:23:38,100
con el estado oculto

408
00:23:38,100 --> 00:23:42,419
y luego consideramos si la

409
00:23:42,419 --> 00:23:46,200
plasticidad sinérgica siguió a la libre

410
00:23:46,200 --> 00:23:50,720
principio de energía al preguntar si el

411
00:23:50,720 --> 00:23:54,140
principio de frecuencia puede predecir la

412
00:23:54,140 --> 00:23:57,659
autoorganización cualitativa de

413
00:23:57,659 --> 00:23:59,780


414
00:23:59,780 --> 00:24:01,400


415
00:24:01,400 --> 00:24:05,580
datos neuronales posteriores,

416
00:24:05,580 --> 00:24:10,140
por lo que aquí modelamos una

417
00:24:10,140 --> 00:24:12,840
red neuronal neuronal como esta, hay dos

418
00:24:12,840 --> 00:24:15,240
neuronas de conjunto que codifican la Fuente uno

419
00:24:15,240 --> 00:24:20,700
y la Fuente dos y primero calculamos  el

420
00:24:20,700 --> 00:24:25,400
peso sináptico efectivo de esas

421
00:24:25,400 --> 00:24:28,820
redes usando

422
00:24:28,820 --> 00:24:32,039
cadenas de conexión convencionales como el enfoque mencionado

423
00:24:32,039 --> 00:24:37,500
y el punto de la trama final equivalen al

424
00:24:37,500 --> 00:24:38,480


425
00:24:38,480 --> 00:24:42,120
panorama del archivo o energía libre calculada teóricamente,

426
00:24:42,120 --> 00:24:42,960


427
00:24:42,960 --> 00:24:45,179
por lo que

428
00:24:45,179 --> 00:24:49,400
esta es una trayectoria de MP Curry

429
00:24:49,400 --> 00:24:51,020


430
00:24:51,020 --> 00:24:54,240
grados de sinapsis estimados proceso sináptico efectivo

431
00:24:54,240 --> 00:24:58,440
proceso sináptico  conectividad y como

432
00:24:58,440 --> 00:25:02,840
se predijo, esos cambios

433
00:25:02,840 --> 00:25:08,059
reducen la energía libre

434
00:25:08,159 --> 00:25:13,039
y aquí calculamos este

435
00:25:13,039 --> 00:25:16,080
panorama de energía libre teóricamente predicho solo

436
00:25:16,080 --> 00:25:21,179
usando los datos de las primeras 10 sesiones para que

437
00:25:21,179 --> 00:25:24,480
esto

438
00:25:24,480 --> 00:25:29,039
indique alguna predicción

439
00:25:29,039 --> 00:25:32,580
de la autoorganización

440
00:25:32,580 --> 00:25:36,960
y, para una predicción más explícita,

441
00:25:36,960 --> 00:25:41,460
luego simulé una nueva actividad y

442
00:25:41,460 --> 00:25:43,919
plasticidad usando el principio de frecuencia

443
00:25:43,919 --> 00:25:46,039
aquí,

444
00:25:46,039 --> 00:25:50,460
aquí, el color más brillante indica

445
00:25:50,460 --> 00:25:54,779
la predicción de los datos, sin

446
00:25:54,779 --> 00:25:59,159
hacer referencia a los datos de actividad, por lo que

447
00:25:59,159 --> 00:26:00,779
estas líneas

448
00:26:00,779 --> 00:26:03,419
siguen exactamente este gradiente de frecuencia

449
00:26:03,419 --> 00:26:05,100


450
00:26:05,100 --> 00:26:09,320
y descubrimos que esta trayectoria predicha

451
00:26:09,320 --> 00:26:11,000


452
00:26:11,000 --> 00:26:16,700
es un título.  El título se correlaciona con estos

453
00:26:16,700 --> 00:26:20,220


454
00:26:20,220 --> 00:26:21,840
pesos sinápticos efectivos estimados empíricamente

455
00:26:21,840 --> 00:26:26,039
y la tasa anterior es una práctica,

456
00:26:26,039 --> 00:26:30,240
por lo que indica que, en principio,

457
00:26:30,240 --> 00:26:31,500
puede

458
00:26:31,500 --> 00:26:34,919
predecir cuantitativamente la

459
00:26:34,919 --> 00:26:37,500
colonización en serie en esta configuración, por lo que

460
00:26:37,500 --> 00:26:40,919
indica cierta previsibilidad del

461
00:26:40,919 --> 00:26:44,039
principio de frecuencia en este sector

462
00:26:44,039 --> 00:26:47,820
y luego también consideramos.  En el modelado

463
00:26:47,820 --> 00:26:51,779
de la modulación neuronal,

464
00:26:51,779 --> 00:26:54,900
utilizando la inferencia activa, es bien sabido

465
00:26:54,900 --> 00:26:58,559
que el proceso sináptico se modifica por

466
00:26:58,559 --> 00:27:02,760
varios factores como la dopamina u otros

467
00:27:02,760 --> 00:27:05,340
activos de aprendizaje que registran la serotonina, etc.,

468
00:27:05,340 --> 00:27:06,059


469
00:27:06,059 --> 00:27:09,840
y una propiedad interesante de esas

470
00:27:09,840 --> 00:27:14,700
modulaciones es que, aun así, la dopamina se

471
00:27:14,700 --> 00:27:15,779
agregó

472
00:27:15,779 --> 00:27:17,299
después de que se agregó la

473
00:27:17,299 --> 00:27:21,679
plasticidad asociativa.  establecido que

474
00:27:21,679 --> 00:27:25,980
puede cambiar el resultado de la plasticidad

475
00:27:25,980 --> 00:27:29,340
de una manera post-hoc o menos respectiva,

476
00:27:29,340 --> 00:27:31,860
por lo que

477
00:27:31,860 --> 00:27:35,760
impresiona alguna asociación con la

478
00:27:35,760 --> 00:27:39,419
recompensa y las decisiones pasadas, por lo que modelamos

479
00:27:39,419 --> 00:27:42,059
este proceso usando una red neuronal canónica,

480
00:27:42,059 --> 00:27:45,480
por lo que aquí modelamos

481
00:27:45,480 --> 00:27:46,880
la

482
00:27:46,880 --> 00:27:51,659
modulación de Hulk de la plasticidad ABN usando

483
00:27:51,659 --> 00:27:56,940
Este tipo de ecuación plástica y

484
00:27:56,940 --> 00:27:59,760
también consideramos la

485
00:27:59,760 --> 00:28:03,659
estructura de la red neuronal recurrente y fuera de Corea para

486
00:28:03,659 --> 00:28:06,179
esta red y consideramos que la

487
00:28:06,179 --> 00:28:12,299
modulación ocurrió en esta

488
00:28:13,980 --> 00:28:19,200
capa de conectividad y luego encontramos

489
00:28:19,200 --> 00:28:23,600
funciones de costo que pueden derivar esas

490
00:28:23,600 --> 00:28:26,940
ecuaciones diferenciales y luego  formó un

491
00:28:26,940 --> 00:28:29,520


492
00:28:29,520 --> 00:28:33,299
modelo variacional correspondiente para energía y genético, lo que significa que este

493
00:28:33,299 --> 00:28:35,279
tipo de actividad de red neuronal,

494
00:28:35,279 --> 00:28:37,919
incluida la modulación de la plasticidad sinusal,

495
00:28:37,919 --> 00:28:41,940
sigue exactamente el principio de energía libre

496
00:28:41,940 --> 00:28:43,159
y

497
00:28:43,159 --> 00:28:45,380
algún tipo de

498
00:28:45,380 --> 00:28:47,400
modelo de homogeneidad

499
00:28:47,400 --> 00:28:53,480
y al usar esto demostramos que esta

500
00:28:53,480 --> 00:28:55,940


501
00:28:55,940 --> 00:28:58,980
red neuronal biológicamente accesible  Un modelo con modulación,

502
00:28:58,980 --> 00:29:01,799
pesadez y plasticidad puede resolver algún

503
00:29:01,799 --> 00:29:06,360
tipo de tarea de recompensa retrasada, como una tarea de laberinto,

504
00:29:06,360 --> 00:29:07,980


505
00:29:07,980 --> 00:29:10,140
y luego, finalmente, nos gustaría

506
00:29:10,140 --> 00:29:12,659
discutir una posible extensión de este

507
00:29:12,659 --> 00:29:16,080
marco a la inteligencia social moderna,

508
00:29:16,080 --> 00:29:21,960
para inferir nuestros detalles

509
00:29:21,960 --> 00:29:26,580
específicos, uh, uh, nosotros.  Necesitamos seleccionar un

510
00:29:26,580 --> 00:29:28,860
enfoque para crear un modelo de generalidad

511
00:29:28,860 --> 00:29:32,760
o nuestros socios dependiendo de nuestra

512
00:29:32,760 --> 00:29:36,480
asistencia, por lo que esto se puede hacer mediante el

513
00:29:36,480 --> 00:29:39,299
esquema de selección de modelo principal y

514
00:29:39,299 --> 00:29:42,380
previamente propusimos un modelo que puede

515
00:29:42,380 --> 00:29:48,419
predecir las múltiples formas válidas usando

516
00:29:48,419 --> 00:29:49,640


517
00:29:49,640 --> 00:29:53,279
un gran modelo generativo que  comprende

518
00:29:53,279 --> 00:29:58,080
múltiples modelos genéticos y esta película

519
00:29:58,080 --> 00:29:59,520
muestra la

520
00:29:59,520 --> 00:30:03,440
predicción de la

521
00:30:04,620 --> 00:30:07,919
predicción de canciones,

522
00:30:07,919 --> 00:30:13,640
así que este 93 moderno

523
00:30:13,640 --> 00:30:17,940
identifica qué modelo gigante es el mejor,

524
00:30:17,940 --> 00:30:21,600
explicó una entrada sensorial determinada

525
00:30:21,600 --> 00:30:25,860
y este proceso indica que

526
00:30:25,860 --> 00:30:26,760


527
00:30:26,760 --> 00:30:30,360
el modelo puede ingresar correctamente la información

528
00:30:30,360 --> 00:30:32,399
apropiada.  modelo

529
00:30:32,399 --> 00:30:36,539
y luego imitar la canción

530
00:30:36,539 --> 00:30:39,000
por su propia acción,

531
00:30:39,000 --> 00:30:40,140
por lo que

532
00:30:40,140 --> 00:30:42,299
aunque en el trabajo anterior no

533
00:30:42,299 --> 00:30:46,500
discutimos un sustrato neuronal detallado

534
00:30:46,500 --> 00:30:51,059
para este modelo de geografía mixta, ahora

535
00:30:51,059 --> 00:30:55,039
podemos considerar la

536
00:30:55,039 --> 00:30:58,559
arquitectura correspondiente, por ejemplo,

537
00:30:58,559 --> 00:31:03,000
si consideramos la modulación del módulo

538
00:31:03,000 --> 00:31:05,480
neuronal.  módulo por

539
00:31:05,480 --> 00:31:09,779
neuromodulador como la dopamina como un

540
00:31:09,779 --> 00:31:13,620
filtro de atención y este

541
00:31:13,620 --> 00:31:16,860
filtro de atención se puede explicar por

542
00:31:16,860 --> 00:31:19,820
tres factores pesados ​​y grupo de carrera

543
00:31:19,820 --> 00:31:22,799
introducen lo introducido en la

544
00:31:22,799 --> 00:31:28,620
diapositiva anterior, por lo que nuevamente esta modulación

545
00:31:28,620 --> 00:31:33,919
funciona como modulación post-hoc sin

546
00:31:33,919 --> 00:31:37,080
plasticidad más pesada pasada  y esta modulación

547
00:31:37,080 --> 00:31:38,659
puede

548
00:31:38,659 --> 00:31:42,080
optimizar cada modelo para representar un

549
00:31:42,080 --> 00:31:46,440
modelo de generalidad, un general, una canción

550
00:31:46,440 --> 00:31:48,320
de esa

551
00:31:48,320 --> 00:31:52,140
manera mutuamente independiente, por lo que a través de

552
00:31:52,140 --> 00:31:56,039
este proceso es posible aprender

553
00:31:56,039 --> 00:31:59,100
múltiples modelos genéticos de una

554
00:31:59,100 --> 00:32:02,820
manera virtualmente posible, por lo que, en resumen, encontramos

555
00:32:02,820 --> 00:32:05,340
que la dinámica de  Las redes neuronales canónicas

556
00:32:05,340 --> 00:32:07,679
que minimizan la función de costo se

557
00:32:07,679 --> 00:32:12,299
pueden leer como una minimización en la

558
00:32:12,299 --> 00:32:15,000
variación de energía, indica que un

559
00:32:15,000 --> 00:32:17,880
principio de frecuencia es una explicación

560
00:32:17,880 --> 00:32:21,960
para este tipo de red neuronal y

561
00:32:21,960 --> 00:32:27,120
también validamos esta predicción usando alguna

562
00:32:27,120 --> 00:32:31,440
configuración individual mostrando eso

563
00:32:31,440 --> 00:32:33,480
y mostrando que  amigo como

564
00:32:33,480 --> 00:32:36,240
principio puede calificar y

565
00:32:36,240 --> 00:32:38,399
predecir cuantitativamente la autoorganización de la

566
00:32:38,399 --> 00:32:42,720
plasticidad posterior solo usando los

567
00:32:42,720 --> 00:32:44,880
datos iniciales

568
00:32:44,880 --> 00:32:49,380
y como modelado podemos extender

569
00:32:49,380 --> 00:32:53,460
esos modelos de red canónicos a

570
00:32:53,460 --> 00:32:54,320
la

571
00:32:54,320 --> 00:32:57,840
generación de opciones otra planificación a través de

572
00:32:57,840 --> 00:33:01,020
la modulación retardada de pesado y

573
00:33:01,020 --> 00:33:02,399
plasticidad

574
00:33:02,399 --> 00:33:06,179
y  finalmente discutimos la posibilidad

575
00:33:06,179 --> 00:33:10,640
de extender este modelo canónico a

576
00:33:10,640 --> 00:33:15,919
la inteligencia social o compartida moderna

577
00:33:15,919 --> 00:33:20,840
para interactuar con socios completos de Marte,

578
00:33:20,840 --> 00:33:25,140
así que esas son todas mis charlas, gracias por

579
00:33:25,140 --> 00:33:28,380
escuchar, esto es un reconocimiento a nuestro

580
00:33:28,380 --> 00:33:31,799
colaborador y los hallazgos, y nuestra

581
00:33:31,799 --> 00:33:35,360
unidad ahora está reclutando.

582
00:33:35,360 --> 00:33:37,679
investigadores, así que si están interesados ​​en

583
00:33:37,679 --> 00:33:40,399
verificar gratis,

584
00:33:41,460 --> 00:33:43,860
increíble, gracias por la presentación

585
00:33:43,860 --> 00:33:46,500
a kuya.

586
00:33:46,500 --> 00:33:49,140
um, solo haré algunas preguntas rápidas

587
00:33:49,140 --> 00:33:50,700
del chat en vivo y algunas otras

588
00:33:50,700 --> 00:33:54,360
cosas que surjan, por lo que Dave dice que

589
00:33:54,360 --> 00:33:57,480
Takuya usó la frase después de que la plasticidad

590
00:33:57,480 --> 00:33:59,399
fuera  establecido, si

591
00:33:59,399 --> 00:34:03,240
su grupo fue capaz de modificar EG, aumentar la

592
00:34:03,240 --> 00:34:06,059
plasticidad o está diciendo simplemente que

593
00:34:06,059 --> 00:34:10,159
se demostró que hay plasticidad

594
00:34:10,918 --> 00:34:12,960
o

595
00:34:12,960 --> 00:34:16,320
sí, no estoy seguro de haber entendido

596
00:34:16,320 --> 00:34:19,800
correctamente su pregunta, pero esos

597
00:34:19,800 --> 00:34:23,639
grupos mostraron que el grupo mostró

598
00:34:23,639 --> 00:34:25,918
que la dopamina

599
00:34:25,918 --> 00:34:29,879
agrega dopamina.  después de dos segundos después de que

600
00:34:29,879 --> 00:34:32,399


601
00:34:32,399 --> 00:34:36,359
ocurrió la asociación, puede cambiar la

602
00:34:36,359 --> 00:34:40,800
magnitud de la rusticidad, así que

603
00:34:40,800 --> 00:34:42,960
sin

604
00:34:42,960 --> 00:34:45,960
uh, cómo decirlo, uh,

605
00:34:45,960 --> 00:34:50,280
si la dopamina es esta adición antes de

606
00:34:50,280 --> 00:34:54,119
esta asociación, entonces el nivel de procesidad

607
00:34:54,119 --> 00:34:59,220
es bajo, pero después, como dopamina, la

608
00:34:59,220 --> 00:35:02,760
edición después de la asociación puede  cambiar

609
00:35:02,760 --> 00:35:07,280
este nivel puede aumentar la plasticidad

610
00:35:07,280 --> 00:35:12,060
de esta manera o así, lo que indica

611
00:35:12,060 --> 00:35:15,859
la herramienta de modulación post-hoc.

612
00:35:16,440 --> 00:35:19,859
Creo que eso responde,

613
00:35:19,859 --> 00:35:20,760
bueno, ¿

614
00:35:20,760 --> 00:35:23,040


615
00:35:23,040 --> 00:35:25,440
qué te entusiasma o cuáles son

616
00:35:25,440 --> 00:35:26,480
tus

617
00:35:26,480 --> 00:35:30,839
esperanzas o sentimientos sobre dónde

618
00:35:30,839 --> 00:35:33,000
se encuentra el ecosistema de inferencia de octava?  y hacia dónde

619
00:35:33,000 --> 00:35:34,859
nos dirigimos en los próximos meses y

620
00:35:34,859 --> 00:35:37,040
años,

621
00:35:39,480 --> 00:35:41,880
pero lo siento mucho, de

622
00:35:41,880 --> 00:35:45,480
nuevo, así que es solo qué te

623
00:35:45,480 --> 00:35:47,579
entusiasma además de tus propias

624
00:35:47,579 --> 00:35:49,619
direcciones de investigación, qué te

625
00:35:49,619 --> 00:35:52,859
entusiasma en el ecosistema de inferencia activa,

626
00:35:52,859 --> 00:35:58,320
sí, así que, por supuesto, One Direction es el

627
00:35:58,320 --> 00:36:01,320
el modelado de la

628
00:36:01,320 --> 00:36:06,359
interacción social, que es una

629
00:36:06,359 --> 00:36:09,839
arquitectura mucho más rica que la

630
00:36:09,839 --> 00:36:12,480
interacción entre el

631
00:36:12,480 --> 00:36:15,960
entorno estático, por lo que si ambos Corán asiáticos se relacionan entre

632
00:36:15,960 --> 00:36:19,320
sí, se

633
00:36:19,320 --> 00:36:21,900
pueden observar muchos fenómenos interesantes, por lo que estamos

634
00:36:21,900 --> 00:36:25,740
entusiasmados con los fenómenos modernos de Zords que

635
00:36:25,740 --> 00:36:29,400
utilizan la consulta de virus.  plausible uh

636
00:36:29,400 --> 00:36:33,320
Modelo de red neuronal de red a través de

637
00:36:33,320 --> 00:36:36,980
esta equivalencia

638
00:36:37,800 --> 00:36:39,240
increíble

639
00:36:39,240 --> 00:36:43,220
cualquier último comentario

640
00:36:46,500 --> 00:36:50,420
cualquier otro comentario que quieras hacer

641
00:36:56,880 --> 00:36:58,980
increíble

642
00:36:58,980 --> 00:37:01,800
gracias nuevamente por la presentación y la

643
00:37:01,800 --> 00:37:04,079
gente debería ver la transmisión en vivo 51

644
00:37:04,079 --> 00:37:06,599
donde tú y yo hablamos algunas otras veces

645
00:37:06,599 --> 00:37:09,119
y entramos en algunas de las  detalles sobre

646
00:37:09,119 --> 00:37:10,859
ese trabajo hay realmente hay mucho

647
00:37:10,859 --> 00:37:14,000
allí es realmente emocionante

648
00:37:15,060 --> 00:37:16,920
gracias de

649
00:37:16,920 --> 00:37:18,720
acuerdo gracias hasta la

650
00:37:18,720 --> 00:37:22,079
próxima adiós hasta la próxima

651
00:37:22,079 --> 00:37:24,920
adiós

652
00:37:28,920 --> 00:37:31,920
extranjero

