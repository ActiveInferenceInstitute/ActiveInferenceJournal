1
00:00:00,000 --> 00:00:01,800
Ausländisch

2
00:00:01,800 --> 00:00:04,500
Danke, dass Sie dabei sind. Bis zum nächsten Mal.

3
00:00:04,500 --> 00:00:05,580


4
00:00:05,580 --> 00:00:09,140
Vielen Dank. Tschüss.

5
00:00:14,280 --> 00:00:17,058
Alles klar,

6
00:00:20,640 --> 00:00:24,500
tolle Grüße nach Korea.

7
00:00:24,500 --> 00:00:27,300
Bis zum nächsten Mal. Bis zum nächsten Mal.

8
00:00:27,300 --> 00:00:29,279
Sie können

9
00:00:29,279 --> 00:00:31,859
den Live-Stream stummschalten oder den

10
00:00:31,859 --> 00:00:33,480
anderen Live-Stream ausschalten, aber ja, danke, dass Sie

11
00:00:33,480 --> 00:00:35,399
dabei sind.

12
00:00:35,399 --> 00:00:39,059
Ja, äh, danke  Für die Einladung, vielen Dank

13
00:00:39,059 --> 00:00:42,019
dafür. Ja,

14
00:00:43,800 --> 00:00:46,399
ähm,

15
00:00:46,440 --> 00:00:48,239
wir haben

16
00:00:48,239 --> 00:00:53,039
ein bisschen 35 oder 38 Minuten, also

17
00:00:53,039 --> 00:00:55,199
wäre es toll, wenn Ihre

18
00:00:55,199 --> 00:00:57,739
Präsentation

19
00:00:58,860 --> 00:01:02,460
richtig wäre, also in

20
00:01:03,239 --> 00:01:05,880
dem Moment, äh,

21
00:01:05,880 --> 00:01:08,539


22
00:01:10,380 --> 00:01:14,880
können Sie mich sehen,

23
00:01:14,880 --> 00:01:18,500
aber ich habe PowerPoint gesehen,

24
00:01:20,220 --> 00:01:23,220
okay, äh,

25
00:01:23,220 --> 00:01:27,659
können Sie meine sehen?  Bildschirm, äh, perfekt, perfekt,

26
00:01:27,659 --> 00:01:29,820
okay,

27
00:01:29,820 --> 00:01:33,659
also sollen wir anfangen? Ja, danke,

28
00:01:33,659 --> 00:01:38,280
okay, oh, dann, danke, dass Sie

29
00:01:38,280 --> 00:01:41,759


30
00:01:41,759 --> 00:01:45,479
heute dieses wunderbare Symposium organisiert haben. Ich würde gerne über die

31
00:01:45,479 --> 00:01:48,000
Beziehung zwischen kanonischem neuronalem

32
00:01:48,000 --> 00:01:52,200
Netzwerk und aktiver Inferenz und

33
00:01:52,200 --> 00:01:56,280
mögliche Erweiterung sprechen  Moderne äh

34
00:01:56,280 --> 00:01:59,460
soziale auf der gemeinsamen Intelligenz unter Verwendung

35
00:01:59,460 --> 00:02:04,880
kanonischer neuronaler Netze, also fangen wir damit an,

36
00:02:08,160 --> 00:02:11,220
äh, wie Sie wissen, wird das Prinzip der freien Energie

37
00:02:11,220 --> 00:02:13,980
von einem autofreien

38
00:02:13,980 --> 00:02:16,920
Stand vorgeschlagen, der besagt, dass

39
00:02:16,920 --> 00:02:19,200
Wahrnehmungslernen und -option aller biologischen

40
00:02:19,200 --> 00:02:21,840
Organismen dazu bestimmt sind, die

41
00:02:21,840 --> 00:02:24,720
Variation von Energie zu minimieren  ein nachvollziehbarer Stellvertreter

42
00:02:24,720 --> 00:02:28,260
für die Minimierung von Überraschungen, und durch diesen

43
00:02:28,260 --> 00:02:31,580
Prozess können Organismen

44
00:02:31,580 --> 00:02:34,800
parationale Beijing-Inferenzen oder

45
00:02:34,800 --> 00:02:36,900
externe Mineralzustände durchführen.

46
00:02:36,900 --> 00:02:40,379
Dies ist dieser Cartoon, der nur ein

47
00:02:40,379 --> 00:02:43,860
Beispiel für einen typischen Aufbau unter dem

48
00:02:43,860 --> 00:02:46,640
Prinzip der freien Energie zeigt. Aktive Inferenz. Hier

49
00:02:46,640 --> 00:02:49,920
gibt es einen verborgenen Zustand  Die

50
00:02:49,920 --> 00:02:52,920
äußere Welt und nur ein Teil dieses

51
00:02:52,920 --> 00:02:58,319
Zustands kann für unseren Agenten beobachtbar sein.

52
00:02:58,319 --> 00:03:00,959


53
00:03:00,959 --> 00:03:04,319
Diese Transformation erfolgt durch einen

54
00:03:04,319 --> 00:03:06,060
genetischen Modellparameter, der

55
00:03:06,060 --> 00:03:08,660
durch Theta parametrisiert wird,

56
00:03:08,660 --> 00:03:12,780
und für den verborgenen Zustand

57
00:03:12,780 --> 00:03:17,459
muss der Agent die Kopie des

58
00:03:17,459 --> 00:03:21,060
externen Zustands rekonstruieren  Dies wird als hinteres Relief bezeichnet

59
00:03:21,060 --> 00:03:24,239
und diese Optimierung erfolgt durch

60
00:03:24,239 --> 00:03:27,900
Minimierung einer variierenden freien Energie

61
00:03:27,900 --> 00:03:31,860
und eines Parameters, der ebenfalls durch

62
00:03:31,860 --> 00:03:35,099
Minimierung der freien Energie optimiert wird, um ein

63
00:03:35,099 --> 00:03:37,379
Erzeugungsmodell zur Darstellung dieser

64
00:03:37,379 --> 00:03:40,560
Beziehung zu erhalten. Ein interessanter Aspekt des

65
00:03:40,560 --> 00:03:42,299
aktiven Einflusses der Transplantation freier Energie

66
00:03:42,299 --> 00:03:44,819
ist seine Anwendung auf die

67
00:03:44,819 --> 00:03:48,000
Optimierung von  Hier hat unser Agent

68
00:03:48,000 --> 00:03:51,239
eine gewisse Präferenz vor C und um

69
00:03:51,239 --> 00:03:54,860
diese Beobachtung in der Zukunft zu erhalten,

70
00:03:54,860 --> 00:03:59,280
kann der Agent die Aktion auswählen, die

71
00:03:59,280 --> 00:04:02,640
die erwartete freie Energie in der

72
00:04:02,640 --> 00:04:05,580
Zukunft minimiert, um

73
00:04:05,580 --> 00:04:09,540
das vorhersehbarste

74
00:04:09,540 --> 00:04:14,280
Ergebnis zu erhalten, und schließlich

75
00:04:14,280 --> 00:04:16,019
Aktionen auswählen, die die erwartete

76
00:04:16,019 --> 00:04:19,738
Häufigkeit minimieren  Es kann den Feed erhalten,

77
00:04:19,738 --> 00:04:23,160
also ist dies ein typisches Setup für die aktive

78
00:04:23,160 --> 00:04:25,919
Infrastruktur. Die Frage ist, was das

79
00:04:25,919 --> 00:04:28,680
neuronale Substantivsubstrat ist, das

80
00:04:28,680 --> 00:04:31,500
diesen Prozess implementieren kann. Das ist also unser

81
00:04:31,500 --> 00:04:34,500
Interesse. Um dieses Problem anzugehen,

82
00:04:34,500 --> 00:04:38,520
schlagen wir eine Theorie wie folgt vor. Wir

83
00:04:38,520 --> 00:04:41,880
gehen davon aus, dass äh  Die äußere Welt wird

84
00:04:41,880 --> 00:04:45,120
parametrisiert und durch eine Reihe von

85
00:04:45,120 --> 00:04:50,580
Variablen wie diese gekennzeichnet. Hier handelt es sich um eine

86
00:04:50,580 --> 00:04:53,940
hintere Erwartung, und

87
00:04:53,940 --> 00:04:57,600
der verborgene Zustand in

88
00:04:57,600 --> 00:05:01,440
Excel oder Delta zeigt die Aktion

89
00:05:01,440 --> 00:05:05,460
des Agenten oder die Entscheidung an, und Theta

90
00:05:05,460 --> 00:05:08,820
zeigt einen Parameter an und Lambda

91
00:05:08,820 --> 00:05:14,580
ist a  Hyperparameter, also jene etwa festgelegten

92
00:05:14,580 --> 00:05:18,240
Parameter oder Variablen, die

93
00:05:18,240 --> 00:05:22,940
ein allgemeines Modell charakterisieren, und die Variation der freien Energie

94
00:05:22,940 --> 00:05:25,560
der Energie wird als eine

95
00:05:25,560 --> 00:05:28,800
Funktion der Beobachtungssequenz

96
00:05:28,800 --> 00:05:31,620
und des externen Zustands definiert und ihre

97
00:05:31,620 --> 00:05:33,900
Minimierung zeigt die Schlussfolgerung der

98
00:05:33,900 --> 00:05:36,419
Variationsbetriebsgleichung der freien Energie an,

99
00:05:36,419 --> 00:05:38,880
uh

100
00:05:38,880 --> 00:05:42,780
ähnlich wie wir  Betrachten Sie eine Dynamik eines

101
00:05:42,780 --> 00:05:45,919
neuronalen Netzwerks und wir gehen davon aus, dass eine

102
00:05:45,919 --> 00:05:48,900
Dynamik durch einen Zustand

103
00:05:48,900 --> 00:05:52,320
dieser Variablen gekennzeichnet ist. Hier gibt x die

104
00:05:52,320 --> 00:05:55,199
Feuerrate der neuronalen Aktivität bei den Neuronen im

105
00:05:55,199 --> 00:05:56,780
mittleren Bereich an,

106
00:05:56,780 --> 00:06:01,080
und der Y-Indikator ist die nahe

107
00:06:01,080 --> 00:06:04,020
Aktivität der Ausgangsradioneuronen, und W

108
00:06:04,020 --> 00:06:07,919
ist hier ein synaptisches Gewicht  und der Phi ist

109
00:06:07,919 --> 00:06:10,680
der andere beliebige andere freie Parameter, der

110
00:06:10,680 --> 00:06:13,740
das neuronale Netzwerk charakterisiert, und wir gehen

111
00:06:13,740 --> 00:06:17,060
davon aus, dass die Dynamik des neuronalen Netzwerks

112
00:06:17,060 --> 00:06:19,979
durch die Minimierung einer

113
00:06:19,979 --> 00:06:23,520
Kostenfunktion gekennzeichnet ist. Dies ist eine Funktion des

114
00:06:23,520 --> 00:06:26,220
internen Zustands O und des Phi des

115
00:06:26,220 --> 00:06:28,500
neuronalen Netzwerks und

116
00:06:28,500 --> 00:06:32,039
seine Minimierung  geben die

117
00:06:32,039 --> 00:06:34,500
Erzeugung neuronaler Netzwerkdynamik an, die

118
00:06:34,500 --> 00:06:37,740
sowohl Aktivität als auch

119
00:06:37,740 --> 00:06:41,940
Plastizität umfasst, und unsere Theorie zeigt eine

120
00:06:41,940 --> 00:06:45,500
Äquivalenz zwischen den beiden Funktionen an, was

121
00:06:45,500 --> 00:06:49,979
bedeutet, dass es für jedes neuronale Netzwerk, das

122
00:06:49,979 --> 00:06:52,380
einen Kostenfunktionsfehler minimiert,

123
00:06:52,380 --> 00:06:55,620
ein genetisches Modell gibt, das erfüllt, wenn

124
00:06:55,620 --> 00:06:59,720
wir Luft nennen, was bedeutet

125
00:06:59,720 --> 00:07:01,940
Die

126
00:07:01,940 --> 00:07:05,340
Rückeroberung externer Dynamiken ist ein

127
00:07:05,340 --> 00:07:08,580
inhärentes Merkmal jedes neuronalen Systems,

128
00:07:08,580 --> 00:07:13,319
das für solche Dynamiken eine

129
00:07:13,319 --> 00:07:16,680
interessante Vorhersage ist, aber die beiden anderen

130
00:07:16,680 --> 00:07:17,780
Strukturen.

131
00:07:17,780 --> 00:07:21,780
Ich möchte daher ein

132
00:07:21,780 --> 00:07:24,180
analytisch interagierbares Beispiel vorstellen, um

133
00:07:24,180 --> 00:07:28,620
diese Beziehung formal zu verstehen,

134
00:07:28,620 --> 00:07:31,759
also betrachten wir sie zunächst  Dies ist eine sehr einfache

135
00:07:31,759 --> 00:07:35,280
Architektur, die durch eine

136
00:07:35,280 --> 00:07:39,660
Pome-DP ohne Stufenübergang dargestellt wird, sodass

137
00:07:39,660 --> 00:07:43,220
sie keine s benötigt. Sie wird einfach

138
00:07:43,220 --> 00:07:46,319
durch die Flugjahrverteilung D generiert

139
00:07:46,319 --> 00:07:52,620
und ist ähm, es ist ein binärer Zustand, aber wir

140
00:07:52,620 --> 00:07:56,160
betrachten einen Vektor von binären Zuständen, also

141
00:07:56,160 --> 00:08:00,240
ist es ein  Die faktorielle Fabrik der Struktur und

142
00:08:00,240 --> 00:08:03,900
uh-Beobachtung ist ebenfalls ein binärer

143
00:08:03,900 --> 00:08:08,220
Vektor, und die Transformation von s nach

144
00:08:08,220 --> 00:08:11,160
O wird durch die kategoriale

145
00:08:11,160 --> 00:08:16,979
Verteilung uh unter Verwendung einer regulären Matrix a

146
00:08:16,979 --> 00:08:20,099
und einer Variations-Peking-Inferenz charakterisiert, um

147
00:08:20,099 --> 00:08:22,919
die Umkehrung dieses

148
00:08:22,919 --> 00:08:27,180
generativen Prozesses wie folgt anzuzeigen, indem

149
00:08:27,180 --> 00:08:29,660
die entsprechende Funktion der freien Energie gelöst wird

150
00:08:29,660 --> 00:08:33,599
Wir erhalten den hinteren

151
00:08:33,599 --> 00:08:37,219
Brief, der im Bayes'schen Sinne optimal ist.

152
00:08:37,219 --> 00:08:40,140


153
00:08:40,140 --> 00:08:42,479
Andererseits betrachten wir für ein neuronales Netzwerk eine

154
00:08:42,479 --> 00:08:46,920
solche Struktur. Der obere

155
00:08:46,920 --> 00:08:50,040
Teil zeigt hier die Signalerzeugung

156
00:08:50,040 --> 00:08:52,560
in der Außenwelt an und das neuronale

157
00:08:52,560 --> 00:08:55,320
Netzwerk umfasst hier nur eine einzige Schicht

158
00:08:55,320 --> 00:08:59,880
Aktivität  Ausgabeschicht, die

159
00:08:59,880 --> 00:09:02,540
durch eine entsprechende Summe

160
00:09:02,540 --> 00:09:06,839
sensorischer Eingaben erzeugt oder durch die synaptische

161
00:09:06,839 --> 00:09:10,440
Matrix W gewichtet wird, und wir charakterisieren dann dieses

162
00:09:10,440 --> 00:09:12,120
neuronale Netzwerk

163
00:09:12,120 --> 00:09:14,339
in der nächsten Folie.

164
00:09:14,339 --> 00:09:18,360
Um ein neuronales neuronales Netzwerk oder Neuron zu modellieren,

165
00:09:18,360 --> 00:09:19,700


166
00:09:19,700 --> 00:09:22,760
beginnen wir mit der Betrachtung der

167
00:09:22,760 --> 00:09:27,600
Projektgleichung, die die uh vier uh

168
00:09:27,600 --> 00:09:30,839
umfasst  Vier-Differentialgleichung und

169
00:09:30,839 --> 00:09:33,959
dies ist eine sehr komplizierte nichtlineare

170
00:09:33,959 --> 00:09:37,500
Gleichung und obwohl es eine Barrikade

171
00:09:37,500 --> 00:09:40,260
möglich ist, ziehen wir eine gewisse Reduktion

172
00:09:40,260 --> 00:09:43,880
dieser Gleichungen in Betracht, sodass eine typische

173
00:09:43,880 --> 00:09:47,279
Reduktionsmethode in der

174
00:09:47,279 --> 00:09:52,080
Praxis ist. Beispielsweise ist M hier viel

175
00:09:52,080 --> 00:09:55,019
schneller als andere Variablen, sodass dies möglich ist

176
00:09:55,019 --> 00:09:59,580
durch seinen Fixpunkt ersetzt werden oder es

177
00:09:59,580 --> 00:10:04,080
ist bekannt, dass H und minus eins leider

178
00:10:04,080 --> 00:10:09,480


179
00:10:09,480 --> 00:10:13,620
eine ähnliche Dynamik haben, sodass wir

180
00:10:13,620 --> 00:10:17,339
eine neue effektive Variable U in Betracht ziehen können, um

181
00:10:17,339 --> 00:10:19,700
diese beiden

182
00:10:19,700 --> 00:10:23,459
Variablen zu charakterisieren, und dann erhalten wir  Auf die

183
00:10:23,459 --> 00:10:28,019
positive Gleichung wie diese handelt es sich also um

184
00:10:28,019 --> 00:10:31,820
eine berühmte Klasse neuronaler Netzwerkmodelle,

185
00:10:31,820 --> 00:10:36,180
die das bekannte feste Ansichts-

186
00:10:36,180 --> 00:10:40,820
und Übereinstimmungsmodell uh oder andere uh

187
00:10:40,820 --> 00:10:44,160
kontinuierliche neuronale Netzwerkmodelle umfasst, und wir

188
00:10:44,160 --> 00:10:49,860
modifizieren diese uh-Modelle, um

189
00:10:49,860 --> 00:10:52,740
so ein kanonisches neuronales Modell abzuleiten  Dies ist eine

190
00:10:52,740 --> 00:10:56,220
Definition eines kanonischen neuronalen

191
00:10:56,220 --> 00:10:59,459
Netzwerkmodells. Hier

192
00:10:59,459 --> 00:11:02,579
wird der Leckstrom durch eine

193
00:11:02,579 --> 00:11:06,000
Bussumoidfunktion anstelle einer kubischen

194
00:11:06,000 --> 00:11:08,940
Funktion charakterisiert, die im

195
00:11:08,940 --> 00:11:12,060
Fitsview-Nagma-Modell übernommen wird. Außerdem

196
00:11:12,060 --> 00:11:15,180
betrachten wir eine Verbindung oder eine synaptische

197
00:11:15,180 --> 00:11:18,980
Verbindung, und dieser Teil weist auf einen

198
00:11:18,980 --> 00:11:22,820
synaptischen Eingang hin  Von einer sensorischen Schicht

199
00:11:22,820 --> 00:11:28,440
über uh-Gewichtsmatrizen und man kann

200
00:11:28,440 --> 00:11:31,800
davon ausgehen, dass W1 eine erregende

201
00:11:31,800 --> 00:11:34,320
Synapse und w0 eine Indikatorinventar-

202
00:11:34,320 --> 00:11:37,579
Synapse und die Sweatshirt-

203
00:11:37,579 --> 00:11:40,140
Adaptivschwellen anzeigen, die eine Funktion

204
00:11:40,140 --> 00:11:45,180
von WR und w0 sind. Interessanterweise erhalten wir nun, wenn wir

205
00:11:45,180 --> 00:11:47,880
einen Fixpunkt dieser

206
00:11:47,880 --> 00:11:51,480
Differentialgleichung betrachten, eine Quelle

207
00:11:51,480 --> 00:11:54,899
-bekanntes rotes Codierungsmodell in Verbindung mit der

208
00:11:54,899 --> 00:11:58,500
Sigmoid-Aktivierungsfunktion,

209
00:11:58,500 --> 00:12:01,920
was bedeutet, dass wir sagen können, dass

210
00:12:01,920 --> 00:12:03,920
dieses kanonische neuronale Netzwerkmodell in gewissem Sinne

211
00:12:03,920 --> 00:12:08,940
eine Annäherung an das ist, was Sie mit

212
00:12:08,940 --> 00:12:12,540
der Gleichung haben können, und dass sein Näherungsgrad

213
00:12:12,540 --> 00:12:16,140


214
00:12:16,140 --> 00:12:19,380
in gewissem Sinne zwischen dem Realistischen liegt

215
00:12:19,380 --> 00:12:22,920
Modell und das einfachste Red-Coding-

216
00:12:22,920 --> 00:12:26,640
Modell, daher betrachten wir grundsätzlich diese Art

217
00:12:26,640 --> 00:12:30,120
von neuronalem Netzwerkmodell und auf der nächsten

218
00:12:30,120 --> 00:12:31,700
Folie

219
00:12:31,700 --> 00:12:35,279
betrachten wir, was die plausible

220
00:12:35,279 --> 00:12:39,000
Kostenfunktion für dieses neuronale Netzwerkmodell ist.

221
00:12:39,000 --> 00:12:42,360
Daher schreiben wir erneut

222
00:12:42,360 --> 00:12:45,600
dieselbe Gleichung für das kanonische

223
00:12:45,600 --> 00:12:49,079
neuronale Netzwerkmodell, die darstellt

224
00:12:49,079 --> 00:12:52,620
die Aktivität von Neuronen Vektor von

225
00:12:52,620 --> 00:12:53,579
Neuronen

226
00:12:53,579 --> 00:12:58,079
und wir betrachten eine Kostenfunktion für diese

227
00:12:58,079 --> 00:13:00,180
Differentialgleichung, die

228
00:13:00,180 --> 00:13:02,600
durch einfache

229
00:13:02,600 --> 00:13:07,200
Berechnung des Integrals der rechten

230
00:13:07,200 --> 00:13:12,300
Seite dieser Gleichung erhalten werden kann, und erhalten diese

231
00:13:12,300 --> 00:13:15,779
Art von Kostenfunktion für neuronale Netzwerke.

232
00:13:15,779 --> 00:13:18,660
Dies ist eine biologisch tragbare

233
00:13:18,660 --> 00:13:20,760
Kostenfunktion  in dem Sinne, dass seine

234
00:13:20,760 --> 00:13:22,860
Ableitung eine neuronale Netzwerkaktivität ableitet,

235
00:13:22,860 --> 00:13:26,700
die einen bestimmten Virus

236
00:13:26,700 --> 00:13:28,139
namens Wahrscheinlichkeit aufweist.

237
00:13:28,139 --> 00:13:29,779


238
00:13:29,779 --> 00:13:33,899
Wenn wir außerdem eine Ableitung dieser

239
00:13:33,899 --> 00:13:36,480
Kostenfunktion in Bezug auf das synoptische Gewicht W betrachten,

240
00:13:36,480 --> 00:13:41,700
erhalten wir eine konventionelle synaptische

241
00:13:41,700 --> 00:13:45,300
Plastizitätsregel, die andererseits dem Hepia-Gesetz folgt

242
00:13:45,300 --> 00:13:47,339


243
00:13:47,339 --> 00:13:51,260
Für die

244
00:13:51,540 --> 00:13:54,060
Beijing-Inferenz definieren wir zunächst das

245
00:13:54,060 --> 00:13:57,779
Allgemeingültigkeitsmodell wie auf der vorherigen

246
00:13:57,779 --> 00:14:03,720
Folie und

247
00:14:03,720 --> 00:14:07,500
leiten dann die Variationsenergie für

248
00:14:07,500 --> 00:14:10,620
das gegebene genetische Modell ab, sodass diese Variation

249
00:14:10,620 --> 00:14:14,639
der freien Energie aus dem

250
00:14:14,639 --> 00:14:19,019
Palm-DP-Modell in der vorherigen Folie abgeleitet wird  Folie

251
00:14:19,019 --> 00:14:23,100
und ihre Minimierung zeigen äh den

252
00:14:23,100 --> 00:14:26,279
Pekinger Wald und den Lauf an,

253
00:14:26,279 --> 00:14:30,740
also haben wir eine

254
00:14:30,920 --> 00:14:34,860
formale Entsprechung zwischen einer

255
00:14:34,860 --> 00:14:38,300
Komponente dieser beiden Kostenfunktionen wie folgt gebildet,

256
00:14:38,300 --> 00:14:42,920
sodass dieser äh Blockvektor

257
00:14:42,920 --> 00:14:46,260
formal diesem Blockvektor entspricht,

258
00:14:46,260 --> 00:14:49,040
der die hintere Erwartung darstellt,

259
00:14:49,040 --> 00:14:53,160
und dieser Logarithmus diesem Logarithmus entspricht

260
00:14:53,160 --> 00:14:54,600


261
00:14:54,600 --> 00:14:59,459
und tatsächlich kann diese Matrix

262
00:14:59,459 --> 00:15:02,339
als Blockmatrix dargestellt werden,

263
00:15:02,339 --> 00:15:06,019
und es ist ein DOT-Produkt, das

264
00:15:06,019 --> 00:15:09,600
dieser Berechnung entspricht, und

265
00:15:09,600 --> 00:15:12,620
schließlich äh, diese fünf

266
00:15:12,620 --> 00:15:16,320
entsprechen natürlich diesem äh, laden Sie das

267
00:15:16,320 --> 00:15:20,880
Logo von State Prior, was bedeutet, dass

268
00:15:20,880 --> 00:15:24,540
äh, weil die Kostenfunktion äh gleich ist

269
00:15:24,540 --> 00:15:28,519
Es ist eine Ableitung, äh,

270
00:15:28,519 --> 00:15:31,860
liefert die

271
00:15:31,860 --> 00:15:33,540


272
00:15:33,540 --> 00:15:37,980
seine Ableitung liefert die einige

273
00:15:37,980 --> 00:15:39,600
[Musik] Tut mir

274
00:15:39,600 --> 00:15:44,120
leid, weil die Kostenfunktionen

275
00:15:44,120 --> 00:15:48,420
formal äquivalent sind, es ist eine Ableitung, äh, es tut mir

276
00:15:48,420 --> 00:15:52,820
leid, es ist ein Ergebnis von äh,

277
00:15:52,820 --> 00:15:56,339
Derivat, es entspricht auch

278
00:15:56,339 --> 00:16:00,839
einander, was bedeutet, dass äh für  Jede

279
00:16:00,839 --> 00:16:04,500
interaktive Gleichung in dieser Form, äh, es

280
00:16:04,500 --> 00:16:06,839
gibt eine entsprechende Bayes'sche

281
00:16:06,839 --> 00:16:09,899
Inferenzgleichung. Dies ist eine Gleichung,

282
00:16:09,899 --> 00:16:13,860
die den hinteren Teil des

283
00:16:13,860 --> 00:16:17,579
Heliumzustands berechnet, und dieses synaptische

284
00:16:17,579 --> 00:16:20,519
Prozessgleichungsformat entspricht dem Lernen

285
00:16:20,519 --> 00:16:23,820
oder Parameter des generativen Modells.

286
00:16:23,820 --> 00:16:27,120
Darüber hinaus können wir durch die Festlegung dieser

287
00:16:27,120 --> 00:16:30,480
Beziehung berücksichtigen  Das Reverse

288
00:16:30,480 --> 00:16:33,360
Engineering des genetischen Modells aus

289
00:16:33,360 --> 00:16:37,399
empirischen Daten hier äh, dieses uh

290
00:16:37,399 --> 00:16:38,959
Schema

291
00:16:38,959 --> 00:16:43,380
fasst unseren Ansatz zum Reverse

292
00:16:43,380 --> 00:16:45,899
Engineering des generativen Modells zusammen und wir

293
00:16:45,899 --> 00:16:48,060
zeichnen zunächst die neuronale Aktivität auf und

294
00:16:48,060 --> 00:16:50,880
weisen das neuronale Netzwerk von Canon zu, um

295
00:16:50,880 --> 00:16:54,779
diese erhaltenen Daten zu erklären und durch

296
00:16:54,779 --> 00:16:57,240
Berechnung des Integrals, das wir erhalten haben  Eine

297
00:16:57,240 --> 00:16:59,660
Kostenfunktion für dieses kanonische Netzwerk

298
00:16:59,660 --> 00:17:03,540
und durch die mathematische Äquivalenz, die wir

299
00:17:03,540 --> 00:17:05,900
festgestellt haben, können wir automatisch

300
00:17:05,900 --> 00:17:09,000
ein genetisches Modell und freie

301
00:17:09,000 --> 00:17:11,760
operative freie Energie identifizieren, die

302
00:17:11,760 --> 00:17:16,079
dieser Architektur des neuronalen Netzwerks entsprechen.

303
00:17:16,079 --> 00:17:20,059
Interessanterweise handelt es sich hierbei um einen Bayes'schen Agenten,

304
00:17:20,059 --> 00:17:24,020
der eine Art davon ist

305
00:17:24,020 --> 00:17:27,179
Künstliche Intelligenz, aber wichtig ist, dass

306
00:17:27,179 --> 00:17:30,299
diese künstliche Intelligenz formal

307
00:17:30,299 --> 00:17:33,660
aus empirischen Daten abgeleitet ist, sodass wir

308
00:17:33,660 --> 00:17:37,520
sagen können, dass es sich bei diesem Agenten um eine biometrische

309
00:17:37,520 --> 00:17:39,960
aktive Anteilintelligenz handelt, die

310
00:17:39,960 --> 00:17:42,960
dem Vorenergieprinzip

311
00:17:42,960 --> 00:17:46,440
und dann ihrer Ableitung in Bezug auf

312
00:17:46,440 --> 00:17:49,520
einen Parameter folgt. Später

313
00:17:49,520 --> 00:17:52,919
abgeleitete synaptische Prothesenalgorithmen

314
00:17:52,919 --> 00:17:55,860
folgen dem  Die Minimierung der freien Energie

315
00:17:55,860 --> 00:18:00,600
und ihr Zeitintegral können den

316
00:18:00,600 --> 00:18:03,720
laufenden Prozess der ursprünglichen neuronalen

317
00:18:03,720 --> 00:18:04,880


318
00:18:04,880 --> 00:18:07,380


319
00:18:07,380 --> 00:18:11,820
Netzwerkdaten vorhersagen. Das heißt, wenn die

320
00:18:11,820 --> 00:18:14,700
Freiheit ein Prinzip ist, das korrekt ist, sollte

321
00:18:14,700 --> 00:18:17,100
diese Vorhersage funktionieren

322
00:18:17,100 --> 00:18:20,640
und in der Lage sein,

323
00:18:20,640 --> 00:18:24,900
das Ergebnis vorherzusagen  neuronale

324
00:18:24,900 --> 00:18:29,820
Daten, ohne sich auf die Daten selbst zu beziehen,

325
00:18:29,820 --> 00:18:34,200
also ist unsere Strategie, ähm, zusammenfassend besteht

326
00:18:34,200 --> 00:18:37,460
unsere Strategie darin, dass wir das

327
00:18:37,460 --> 00:18:41,760
genetische Modell nur aus den

328
00:18:41,760 --> 00:18:46,200
Anfangsdaten mit ähnlichen Anfangsdaten rekonstruieren,

329
00:18:46,200 --> 00:18:50,160
bevor wir lernen, und dann den

330
00:18:50,160 --> 00:18:52,520
laufenden Prozess oder die Kurve vorhersagen,

331
00:18:52,520 --> 00:18:56,880
die dieses neuronale System ausführen sollte

332
00:18:56,880 --> 00:18:58,260


333
00:18:58,260 --> 00:19:02,460
Verwenden Sie anschließend das Prinzip der freien Energie und

334
00:19:02,460 --> 00:19:05,640
vergleichen oder prüfen Sie, ob diese

335
00:19:05,640 --> 00:19:09,179
Vorhersage korrekt ist. Vergleichen Sie dazu die

336
00:19:09,179 --> 00:19:13,559
tatsächlichen Daten nach dem Lauf mit der

337
00:19:13,559 --> 00:19:16,200
Vorhersage nach dem Frequenzprinzip.

338
00:19:16,200 --> 00:19:19,200
Wenn diese Vorhersage korrekt ist,

339
00:19:19,200 --> 00:19:22,320
zeigt dies die prädiktive Gültigkeit des

340
00:19:22,320 --> 00:19:25,200
Prinzips der freien Energie an  und der Aufbau

341
00:19:25,200 --> 00:19:26,520
wurde als

342
00:19:26,520 --> 00:19:27,600
in Ordnung erachtet,

343
00:19:27,600 --> 00:19:31,440
also wenden wir diese Strategie auf das

344
00:19:31,440 --> 00:19:34,679
neuronale In-vitro-Netzwerk an. Hier wird dieses neuronale In-

345
00:19:34,679 --> 00:19:37,320
vitro-Netzwerk

346
00:19:37,320 --> 00:19:40,460
mithilfe des

347
00:19:40,460 --> 00:19:44,460
in der vorherigen Folie definierten Form-DP-Genitivprozesses stimuliert, sodass es

348
00:19:44,460 --> 00:19:47,360
zwei versteckte Quellen gibt, die binäre

349
00:19:47,360 --> 00:19:51,660
Signale sind, und das sind sie auch  Mischung und sie

350
00:19:51,660 --> 00:19:56,600
werden gemischt, um äh 32

351
00:19:56,600 --> 00:20:01,860
sensorische Strömungen zu erzeugen. Diese sind ebenfalls binär

352
00:20:01,860 --> 00:20:06,780
und dies ist ein Übersichtsexperiment, äh,

353
00:20:06,780 --> 00:20:09,600
indem sie in vitro Neuronen stimulieren, die eine

354
00:20:09,600 --> 00:20:13,020
Spike-Spike-Reaktion erzeugen, und

355
00:20:13,020 --> 00:20:16,880
diese Reime deuten auf eine Spike-

356
00:20:16,880 --> 00:20:23,460
Spike-Reaktion mit hoher Dichte hin, also haben wir das

357
00:20:23,460 --> 00:20:27,260
in einigen bemerkt  Neuron ist

358
00:20:27,480 --> 00:20:30,360
die Antwortspezifität

359
00:20:30,360 --> 00:20:34,799
so, dass wir festgestellt haben, dass die

360
00:20:34,799 --> 00:20:37,820


361
00:20:37,820 --> 00:20:41,539
Reaktion einiger Neuronen auf das Signal von

362
00:20:41,539 --> 00:20:43,440
Quelle Eins im

363
00:20:43,440 --> 00:20:47,700
Vergleich zum Signal von Quelle2 hoch war,

364
00:20:47,700 --> 00:20:54,179
und wenn wir den Übergang dieser

365
00:20:54,179 --> 00:20:58,700
Neuronen sehen, haben wir festgestellt, dass wir

366
00:20:58,700 --> 00:21:03,360
den Offset bei der ersten

367
00:21:03,360 --> 00:21:08,340
Sitzung entfernen  Um diese Aktivitäten auf

368
00:21:08,340 --> 00:21:14,120
Null zu setzen, sehen wir, dass diese Neuronen

369
00:21:14,120 --> 00:21:17,940
sich selbst so organisieren, dass sie hoch reagieren, wenn

370
00:21:17,940 --> 00:21:21,960
Quelle eins eins ist, aber nicht,

371
00:21:21,960 --> 00:21:27,080
aber diese Neuronen reagieren auf einen niedrigen niedrigen Pegel,

372
00:21:27,080 --> 00:21:32,100
wenn Quelle eins null ist, was

373
00:21:32,100 --> 00:21:35,940
bedeutet, dass diese neuronalen Aktivitäten durch

374
00:21:35,940 --> 00:21:39,860
die Neuronen reagieren  Das stimmte

375
00:21:39,860 --> 00:21:43,380
mit unserer theoretischen

376
00:21:43,380 --> 00:21:46,679
Vorhersage überein, dass neue Aktivitäten dazu

377
00:21:46,679 --> 00:21:48,840
dienen, die hintere

378
00:21:48,840 --> 00:21:52,559
Erwartung des Heliumzustands zu kodieren, und wir haben auch

379
00:21:52,559 --> 00:21:54,720
herausgefunden, dass eine andere Gruppe von Neuronen

380
00:21:54,720 --> 00:21:58,020
bevorzugt auf Quelle zwei,

381
00:21:58,020 --> 00:22:01,500
aber nicht auf Quelle eins reagiert.

382
00:22:01,500 --> 00:22:07,980
Also fragen wir, okay, dann haben wir herausgefunden

383
00:22:07,980 --> 00:22:11,100
Diese hinteren Erwartungen werden durch

384
00:22:11,100 --> 00:22:13,080
neuronale Aktivität kodiert und die nächste Frage ist,

385
00:22:13,080 --> 00:22:16,260
was sonst noch ist, was ist mit anderen neuronalen

386
00:22:16,260 --> 00:22:20,520
Substraten, und wir fragen dann, ob wir

387
00:22:20,520 --> 00:22:24,600
nur dann fragen, ob die

388
00:22:24,980 --> 00:22:29,900
Priorität des verborgenen Zustands gleich dem

389
00:22:29,900 --> 00:22:33,179
effektiven Grad ist, der der

390
00:22:33,179 --> 00:22:37,220
Auslöseschwelle eines Netzwerkmodells für neuronale Aktivität entspricht

391
00:22:37,220 --> 00:22:41,220
Wenn also der Server

392
00:22:41,220 --> 00:22:43,860
korrekt ist, sollte diese entsprechende Korrespondenz

393
00:22:43,860 --> 00:22:48,600
vorhanden sein, um dies zu überprüfen. Wir haben

394
00:22:48,600 --> 00:22:52,980
zuerst einen Peking-Agenten simuliert und als

395
00:22:52,980 --> 00:22:55,799
wir die

396
00:22:55,799 --> 00:23:00,240
Priorität des Peking-Agenten bewertet haben,

397
00:23:00,240 --> 00:23:03,980
wurde die Schlussfolgerung abgeschwächt, wie ich erwartet hatte,

398
00:23:03,980 --> 00:23:09,080
und wir haben dies gewarnt, als wir die Erregungsebene begraben haben

399
00:23:09,080 --> 00:23:12,179


400
00:23:12,179 --> 00:23:15,120
Mithilfe der pharmakologischen

401
00:23:15,120 --> 00:23:19,799
Manipulation des in vitro neuronalen Netzwerks haben wir auch herausgefunden, dass

402
00:23:19,799 --> 00:23:22,919
die Abschwächung die Abschwächung der

403
00:23:22,919 --> 00:23:24,299
Folgerung ist,

404
00:23:24,299 --> 00:23:27,720
was mit unserer

405
00:23:27,720 --> 00:23:30,320
theoretischen Vorhersage übereinstimmt, dass die

406
00:23:30,320 --> 00:23:34,740
Finanzschwelle Priorität oder

407
00:23:34,740 --> 00:23:38,100
den verborgenen Zustand kodiert,

408
00:23:38,100 --> 00:23:42,419
und als nächstes überlegen wir, ob die

409
00:23:42,419 --> 00:23:46,200
synergetische Plastizität der freien folgte

410
00:23:46,200 --> 00:23:50,720
Energieprinzip, indem wir fragen, ob das

411
00:23:50,720 --> 00:23:54,140
Frequenzprinzip die

412
00:23:54,140 --> 00:23:57,659
qualitative Selbstorganisation

413
00:23:57,659 --> 00:23:59,780


414
00:23:59,780 --> 00:24:01,400


415
00:24:01,400 --> 00:24:05,580
nachfolgender neuronaler Daten vorhersagen kann.

416
00:24:05,580 --> 00:24:10,140
Hier modellieren wir also ein neuronales neuronales neuronales

417
00:24:10,140 --> 00:24:12,840
Netzwerk wie folgt: Es gibt zwei

418
00:24:12,840 --> 00:24:15,240
Ensemble-Neuronen, die Quelle Eins

419
00:24:15,240 --> 00:24:20,700
und Quelle Zwei kodieren, und wir berechnen zuerst  Das

420
00:24:20,700 --> 00:24:25,400
effektive synaptische Gewicht dieser uh

421
00:24:25,400 --> 00:24:28,820
Netzwerke unter Verwendung eines konventionellen

422
00:24:28,820 --> 00:24:32,039
Verbindungsstrings, wie oben erwähnt,

423
00:24:32,039 --> 00:24:37,500
und der Plotpunkt uh final entsprechen der

424
00:24:37,500 --> 00:24:38,480


425
00:24:38,480 --> 00:24:42,120
Dateilandschaft oder der theoretisch berechneten freien

426
00:24:42,120 --> 00:24:42,960
Energie,

427
00:24:42,960 --> 00:24:45,179


428
00:24:45,179 --> 00:24:49,400
also ist dies eine Flugbahn der von MP Curry

429
00:24:49,400 --> 00:24:51,020
geschätzten

430
00:24:51,020 --> 00:24:54,240
Synapsengrade des effektiven synaptischen

431
00:24:54,240 --> 00:24:58,440
Prozesses synaptisch  Konnektivität und wie

432
00:24:58,440 --> 00:25:02,840
vorhergesagt verringern diese Änderungen

433
00:25:02,840 --> 00:25:08,059
die freie Energie

434
00:25:08,159 --> 00:25:13,039
und hier haben wir diese theoretisch

435
00:25:13,039 --> 00:25:16,080
vorhergesagte freie Energielandschaft nur unter

436
00:25:16,080 --> 00:25:21,179
Verwendung der Daten der ersten 10 Sitzungen berechnet, sodass

437
00:25:21,179 --> 00:25:24,480
dies auf

438
00:25:24,480 --> 00:25:29,039
eine gewisse Vorhersage der Selbstorganisation hindeutet

439
00:25:29,039 --> 00:25:32,580


440
00:25:32,580 --> 00:25:36,960
und für eine explizitere Vorhersage

441
00:25:36,960 --> 00:25:41,460
wir  Dann simulierten wir eine neue Aktivität und

442
00:25:41,460 --> 00:25:43,919
Plastizität unter Verwendung des Frequenzprinzips.

443
00:25:43,919 --> 00:25:46,039


444
00:25:46,039 --> 00:25:50,460
Hier zeigt die hellere Farbe

445
00:25:50,460 --> 00:25:54,779
die Vorhersage von Daten an, ohne sich

446
00:25:54,779 --> 00:25:59,159
auf Aktivitätsdaten zu beziehen.

447
00:25:59,159 --> 00:26:00,779
Diese Linien

448
00:26:00,779 --> 00:26:03,419
folgen also genau diesem Frequenzgradienten

449
00:26:03,419 --> 00:26:05,100


450
00:26:05,100 --> 00:26:09,320
und wir haben festgestellt, dass diese vorhergesagte

451
00:26:09,320 --> 00:26:11,000
Flugbahn

452
00:26:11,000 --> 00:26:16,700
ein Titel ist  Der Titel korreliert mit diesen

453
00:26:16,700 --> 00:26:20,220
empirisch geschätzten effektiven synaptischen

454
00:26:20,220 --> 00:26:21,840
Gewichten

455
00:26:21,840 --> 00:26:26,039
und der früheren Rate ist äh Praxis,

456
00:26:26,039 --> 00:26:30,240
was darauf hinweist, dass im Prinzip

457
00:26:30,240 --> 00:26:31,500


458
00:26:31,500 --> 00:26:34,919
die serielle

459
00:26:34,919 --> 00:26:37,500
Kolonisierung in diesem Aufbau quantitativ vorhergesagt werden kann, was auf

460
00:26:37,500 --> 00:26:40,919
eine gewisse Vorhersagbarkeit des

461
00:26:40,919 --> 00:26:44,039
Frequenzprinzips in diesem Sektor hinweist,

462
00:26:44,039 --> 00:26:47,820
und dann berücksichtigen wir auch  Bei der Modellierung

463
00:26:47,820 --> 00:26:51,779
der neuronalen Modulation unter

464
00:26:51,779 --> 00:26:54,900
Verwendung aktiver Inferenz ist bekannt,

465
00:26:54,900 --> 00:26:58,559
dass der synaptische Prozess durch

466
00:26:58,559 --> 00:27:02,760
verschiedene Faktoren wie Dopamin oder andere

467
00:27:02,760 --> 00:27:05,340
Lernmittel, die Serotonin aufzeichnen, usw. modifiziert wird,

468
00:27:05,340 --> 00:27:06,059


469
00:27:06,059 --> 00:27:09,840
und eine interessante Eigenschaft dieser

470
00:27:09,840 --> 00:27:14,700
Modulationen ist, dass Dopamin

471
00:27:14,700 --> 00:27:15,779


472
00:27:15,779 --> 00:27:17,299
nach der

473
00:27:17,299 --> 00:27:21,679
assoziativen Plastizität hinzugefügt wurde  Es wurde festgestellt, dass es

474
00:27:21,679 --> 00:27:25,980
das Ergebnis der Plastizität

475
00:27:25,980 --> 00:27:29,340
post-hoc oder weniger entsprechend ändern kann,

476
00:27:29,340 --> 00:27:31,860
sodass es

477
00:27:31,860 --> 00:27:35,760
einen gewissen Zusammenhang mit der

478
00:27:35,760 --> 00:27:39,419
Belohnung und früheren Entscheidungen gibt. Daher modellieren wir

479
00:27:39,419 --> 00:27:42,059
diesen Prozess mithilfe eines kanonischen neuronalen

480
00:27:42,059 --> 00:27:45,480
Netzwerks. Hier modellieren wir

481
00:27:45,480 --> 00:27:46,880
die

482
00:27:46,880 --> 00:27:51,659
Hulk-Modulation der ABN-Plastizität mithilfe eines kanonischen neuronalen Netzwerks

483
00:27:51,659 --> 00:27:56,940
Äh, diese Art von äh plastischer Gleichung und

484
00:27:56,940 --> 00:27:59,760
wir betrachten auch die wiederkehrende neuronale

485
00:27:59,760 --> 00:28:03,659
Netzwerkstruktur und aus Korea für

486
00:28:03,659 --> 00:28:06,179
dieses Netzwerk und wir gehen davon aus, dass die

487
00:28:06,179 --> 00:28:12,299
Modulation auf dieser Konnektivitätsebene stattgefunden hat

488
00:28:13,980 --> 00:28:19,200
und dann haben wir äh Kostenfunktionen gefunden,

489
00:28:19,200 --> 00:28:23,600
die diese Differentialgleichungen ableiten können

490
00:28:23,600 --> 00:28:26,940
und dann  hat eine

491
00:28:26,940 --> 00:28:29,520
entsprechende Variation für Energie und ein

492
00:28:29,520 --> 00:28:33,299
genetisches Modell gebildet, was bedeutet, dass diese

493
00:28:33,299 --> 00:28:35,279
Art einer neuronalen Netzwerkaktivität,

494
00:28:35,279 --> 00:28:37,919
einschließlich der Modulation der Sinusplastizität,

495
00:28:37,919 --> 00:28:41,940
genau dem Prinzip der freien Energie

496
00:28:41,940 --> 00:28:43,159
und

497
00:28:43,159 --> 00:28:45,380
einer Art

498
00:28:45,380 --> 00:28:47,400
Homogenitätsmodell folgt,

499
00:28:47,400 --> 00:28:53,480
und indem wir dies verwenden, zeigen wir, dass dieses uh

500
00:28:53,480 --> 00:28:55,940
biologisch zugängliche

501
00:28:55,940 --> 00:28:58,980
neuronale Netzwerk ist  Ein Modell mit Modulation,

502
00:28:58,980 --> 00:29:01,799
Schwere und Plastizität kann eine

503
00:29:01,799 --> 00:29:06,360
Art verzögerte Belohnungsaufgabe wie eine Labyrinthaufgabe lösen,

504
00:29:06,360 --> 00:29:07,980


505
00:29:07,980 --> 00:29:10,140
und schließlich möchten wir

506
00:29:10,140 --> 00:29:12,659
eine mögliche Erweiterung dieses

507
00:29:12,659 --> 00:29:16,080
Rahmenwerks auf die moderne soziale

508
00:29:16,080 --> 00:29:21,960
Intelligenz diskutieren, um auf unsere

509
00:29:21,960 --> 00:29:26,580
Besonderheiten schließen zu können  Wir müssen einen

510
00:29:26,580 --> 00:29:28,860
Ansatz zur Erstellung eines allgemeinen Modells

511
00:29:28,860 --> 00:29:32,760
oder unserer Partner in Abhängigkeit von unserer

512
00:29:32,760 --> 00:29:36,480
Teilnahme auswählen, damit dies durch das Hauptmodellauswahlschema erfolgen kann,

513
00:29:36,480 --> 00:29:39,299
und wir haben

514
00:29:39,299 --> 00:29:42,380
zuvor ein Modell vorgeschlagen, das

515
00:29:42,380 --> 00:29:48,419
die mehreren gültigen Formen mithilfe

516
00:29:48,419 --> 00:29:49,640


517
00:29:49,640 --> 00:29:53,279
eines großen generativen Modells vorhersagen kann  umfasst

518
00:29:53,279 --> 00:29:58,080
mehrere genetische Modelle und dieser Film

519
00:29:58,080 --> 00:29:59,520
zeigt die

520
00:29:59,520 --> 00:30:03,440
Vorhersage der

521
00:30:04,620 --> 00:30:07,919
Vorhersage von äh Liedern,

522
00:30:07,919 --> 00:30:13,640
also wie dieser äh, diese modernen 93

523
00:30:13,640 --> 00:30:17,940
identifizieren, welches Riesenmodell am besten ist,

524
00:30:17,940 --> 00:30:21,600
erklärt eine gegebene sensorische Eingabe

525
00:30:21,600 --> 00:30:25,860
und dieser Prozess zeigt an, dass

526
00:30:25,860 --> 00:30:26,760


527
00:30:26,760 --> 00:30:30,360
das Modell das Richtige korrekt eingeben kann

528
00:30:30,360 --> 00:30:32,399
Modellieren

529
00:30:32,399 --> 00:30:36,539
und dann das Lied

530
00:30:36,539 --> 00:30:39,000
durch seine eigene Aktion imitieren.

531
00:30:39,000 --> 00:30:40,140


532
00:30:40,140 --> 00:30:42,299
Obwohl wir in der vorherigen Arbeit kein

533
00:30:42,299 --> 00:30:46,500
detailliertes neuronales Substrat

534
00:30:46,500 --> 00:30:51,059
für dieses Mischungsgeographiemodell besprochen haben, können wir jetzt

535
00:30:51,059 --> 00:30:55,039
die

536
00:30:55,039 --> 00:30:58,559
entsprechende Architektur berücksichtigen,

537
00:30:58,559 --> 00:31:03,000
wenn wir beispielsweise die Modulation neuronaler Module berücksichtigen

538
00:31:03,000 --> 00:31:05,480
Modul durch

539
00:31:05,480 --> 00:31:09,779
Neuromodulator wie Dopamin es als

540
00:31:09,779 --> 00:31:13,620
Aufmerksamkeitsfilter und dieser Aufmerksamkeitsfilter

541
00:31:13,620 --> 00:31:16,860
kann durch äh

542
00:31:16,860 --> 00:31:19,820
drei Faktor schwere und laufende Gruppe erklärt werden, die

543
00:31:19,820 --> 00:31:22,799
in der vorherigen Folie eingeführt wurden,

544
00:31:22,799 --> 00:31:28,620
also ist diese Modulation wiederum eine

545
00:31:28,620 --> 00:31:33,919
Funktion wie die Post-hoc-Modulation ohne

546
00:31:33,919 --> 00:31:37,080
stärkere Plastizität  und diese Modulation

547
00:31:37,080 --> 00:31:38,659
kann

548
00:31:38,659 --> 00:31:42,080
jedes Modell optimieren, um ein

549
00:31:42,080 --> 00:31:46,440
allgemeines Modell, ein allgemeines äh, ein Lied

550
00:31:46,440 --> 00:31:48,320
auf diese

551
00:31:48,320 --> 00:31:52,140
gegenseitig unabhängige Weise darzustellen, so dass

552
00:31:52,140 --> 00:31:56,039
es durch diesen Prozess möglich ist,

553
00:31:56,039 --> 00:31:59,100
mehrere genetische Modelle äh auf praktisch

554
00:31:59,100 --> 00:32:02,820
mögliche Weise zu lernen, so dass wir zusammenfassend festgestellt haben,

555
00:32:02,820 --> 00:32:05,340
dass die Dynamik von  Kanonische neuronale

556
00:32:05,340 --> 00:32:07,679
Netze, die die Kostenfunktion minimieren,

557
00:32:07,679 --> 00:32:12,299
können als Minimierung

558
00:32:12,299 --> 00:32:15,000
der Energieschwankung gelesen werden. Dies weist darauf hin, dass ein

559
00:32:15,000 --> 00:32:17,880
Frequenzprinzip eine Erklärung

560
00:32:17,880 --> 00:32:21,960
für diese Art von neuronalen Netzen ist. Wir

561
00:32:21,960 --> 00:32:27,120
validieren diese Vorhersage auch anhand eines

562
00:32:27,120 --> 00:32:31,440
individuellen Aufbaus, indem wir das zeigen

563
00:32:31,440 --> 00:32:33,480
und indem wir das zeigen  Freund als

564
00:32:33,480 --> 00:32:36,240
Prinzip kann

565
00:32:36,240 --> 00:32:38,399
die Selbstorganisation der

566
00:32:38,399 --> 00:32:42,720
nachfolgenden uh-Plastizität nur unter Verwendung der

567
00:32:42,720 --> 00:32:44,880
Ausgangsdaten qualifizieren und quantitativ vorhersagen,

568
00:32:44,880 --> 00:32:49,380
und als Modellierung können wir

569
00:32:49,380 --> 00:32:53,460
diese kanonische Netzwerkmodellierung uh auf

570
00:32:53,460 --> 00:32:54,320
die

571
00:32:54,320 --> 00:32:57,840
Optionsgenerierung einer anderen Planung über

572
00:32:57,840 --> 00:33:01,020
die verzögerte Modulation von Schwere und

573
00:33:01,020 --> 00:33:02,399
Plastizität erweitern

574
00:33:02,399 --> 00:33:06,179
und  Schließlich haben wir eine Möglichkeit besprochen,

575
00:33:06,179 --> 00:33:10,640
dieses kanonische Modell auf moderne

576
00:33:10,640 --> 00:33:15,919
soziale oder gemeinsame Intelligenz auszudehnen,

577
00:33:15,919 --> 00:33:20,840
um mit Mars-Vollpartnern zu interagieren. Das

578
00:33:20,840 --> 00:33:25,140
sind also alle meine Vorträge. Danke fürs

579
00:33:25,140 --> 00:33:28,380
Zuhören. Das ist eine Anerkennung für unseren

580
00:33:28,380 --> 00:33:31,799
Mitarbeiter und die Ergebnisse, und unsere

581
00:33:31,799 --> 00:33:35,360
Einheit rekrutiert jetzt

582
00:33:35,360 --> 00:33:37,679
Forscher also, wenn Sie daran interessiert sind,

583
00:33:37,679 --> 00:33:40,399
kostenlos nachzuschauen,

584
00:33:41,460 --> 00:33:43,860
großartig. Vielen Dank für die Präsentation

585
00:33:43,860 --> 00:33:46,500
an Kuya.

586
00:33:46,500 --> 00:33:49,140
Ähm, ich werde nur ein paar kurze Fragen

587
00:33:49,140 --> 00:33:50,700
aus dem Live-Chat stellen und ein paar andere

588
00:33:50,700 --> 00:33:54,360
Dinge, die auftauchen, also sagt Dave, dass

589
00:33:54,360 --> 00:33:57,480
Takuya den Ausdruck nach „Plastizität“ verwendet hat  Es wurde festgestellt, dass

590
00:33:57,480 --> 00:33:59,399


591
00:33:59,399 --> 00:34:03,240
seine Gruppe in der Lage war, EG zu modifizieren und die Plastizität zu erhöhen,

592
00:34:03,240 --> 00:34:06,059
oder sagt er lediglich, dass

593
00:34:06,059 --> 00:34:10,159
gezeigt wurde, dass es Plastizität gibt,

594
00:34:10,918 --> 00:34:12,960
oder

595
00:34:12,960 --> 00:34:16,320
ja, ich bin nicht sicher, ob ich

596
00:34:16,320 --> 00:34:19,800
Ihre Frage richtig verstehe, aber äh, diese

597
00:34:19,800 --> 00:34:23,639
Gruppen zeigten, dass äh, die Gruppe zeigte,

598
00:34:23,639 --> 00:34:25,918
dass Dopamin Dopamin

599
00:34:25,918 --> 00:34:29,879
hinzufügt  Nach zwei Sekunden, nachdem

600
00:34:29,879 --> 00:34:32,399
die Assoziation

601
00:34:32,399 --> 00:34:36,359
stattgefunden hat, kann sich das Ausmaß der

602
00:34:36,359 --> 00:34:40,800
Rustizität ändern, also

603
00:34:40,800 --> 00:34:42,960
ohne äh,

604
00:34:42,960 --> 00:34:45,960
wie soll man sagen, äh,

605
00:34:45,960 --> 00:34:50,280
wenn Dopamin dieser Zusatz vor

606
00:34:50,280 --> 00:34:54,119
dieser Assoziation war, dann ist der Prozessitätsgrad

607
00:34:54,119 --> 00:34:59,220
niedrig, aber äh danach, wie eine Dopamin-

608
00:34:59,220 --> 00:35:02,760
Ausgabe nach der Assoziation kann  Wenn Sie

609
00:35:02,760 --> 00:35:07,280
dieses Niveau ändern, kann die Plastizität

610
00:35:07,280 --> 00:35:12,060
so oder so erhöht werden, was auf

611
00:35:12,060 --> 00:35:15,859
das Post-hoc-

612
00:35:16,440 --> 00:35:19,859
Modulationstool hinweist. Ich denke, das beantwortet die Frage,

613
00:35:19,859 --> 00:35:20,760
ähm,

614
00:35:20,760 --> 00:35:23,040


615
00:35:23,040 --> 00:35:25,440
worauf freuen Sie sich oder was sind

616
00:35:25,440 --> 00:35:26,480
Ihre

617
00:35:26,480 --> 00:35:30,839
Hoffnungen oder Gefühle hinsichtlich der Lage des Oktav-

618
00:35:30,839 --> 00:35:33,000
Inferenz-Ökosystems?  und wohin

619
00:35:33,000 --> 00:35:34,859
wir in den kommenden Monaten und Jahren gehen,

620
00:35:34,859 --> 00:35:37,040


621
00:35:39,480 --> 00:35:41,880
aber es tut mir so leid,

622
00:35:41,880 --> 00:35:45,480
also nochmal, es geht nur darum, worauf Sie sich

623
00:35:45,480 --> 00:35:47,579
freuen, abgesehen von Ihren eigenen

624
00:35:47,579 --> 00:35:49,619
Forschungsrichtungen. Worauf freuen Sie sich

625
00:35:49,619 --> 00:35:52,859
im aktiven Inferenz-Ökosystem?

626
00:35:52,859 --> 00:35:58,320
Ja, natürlich ist One Direction die

627
00:35:58,320 --> 00:36:01,320
Die Modellierung der

628
00:36:01,320 --> 00:36:06,359
sozialen Interaktion ist also eine weitaus

629
00:36:06,359 --> 00:36:09,839
reichhaltigere Architektur als die

630
00:36:09,839 --> 00:36:12,480
Interaktion zwischen der statischen

631
00:36:12,480 --> 00:36:15,960
Umgebung. Wenn also beide asiatischen Koran miteinander interagieren,

632
00:36:15,960 --> 00:36:19,320


633
00:36:19,320 --> 00:36:21,900
können viele interessante Phänomene beobachtet werden, sodass wir uns

634
00:36:21,900 --> 00:36:25,740
über moderne Zords-

635
00:36:25,740 --> 00:36:29,400
Phänomene mit Virenabfrage freuen  plausibel, äh,

636
00:36:29,400 --> 00:36:33,320
Netzwerk-Neuronales Netzwerkmodell durch

637
00:36:33,320 --> 00:36:36,980
diese Äquivalenz,

638
00:36:37,800 --> 00:36:39,240
großartig,

639
00:36:39,240 --> 00:36:43,220
alle letzten Kommentare,

640
00:36:46,500 --> 00:36:50,420
alle anderen Kommentare, die Sie machen möchten,

641
00:36:56,880 --> 00:36:58,980
großartig.

642
00:36:58,980 --> 00:37:01,800
Nochmals vielen Dank für die Präsentation und die

643
00:37:01,800 --> 00:37:04,079
Leute sollten sich den Live-Stream 51 ansehen,

644
00:37:04,079 --> 00:37:06,599
in dem Sie und ich uns ein paar Mal unterhalten

645
00:37:06,599 --> 00:37:09,119
und auf einige davon eingegangen sind  Details zu

646
00:37:09,119 --> 00:37:10,859
dieser Arbeit gibt es wirklich, da gibt es eine Menge, es

647
00:37:10,859 --> 00:37:14,000
ist wirklich aufregend. Vielen Dank,

648
00:37:15,060 --> 00:37:16,920


649
00:37:16,920 --> 00:37:18,720
alles klar, danke, bis zum

650
00:37:18,720 --> 00:37:22,079
nächsten Mal, bis zum nächsten Mal, bis zum nächsten Mal, tschüss,

651
00:37:22,079 --> 00:37:24,920


652
00:37:28,920 --> 00:37:31,920
Ausländer

