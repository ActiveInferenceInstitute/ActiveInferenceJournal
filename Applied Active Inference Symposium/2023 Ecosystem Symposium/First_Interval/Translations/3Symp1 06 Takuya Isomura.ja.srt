1
00:00:00,000 --> 00:00:01,800
外国人、

2
00:00:01,800 --> 00:00:04,500
次回まで参加してくれて

3
00:00:04,500 --> 00:00:05,580


4
00:00:05,580 --> 00:00:09,140
ありがとう、また会いましょう、本当にありがとう、さようなら、次回会えるまで

5
00:00:14,280 --> 00:00:17,058


6
00:00:20,640 --> 00:00:24,500
韓国に素晴らしいご挨拶、

7
00:00:24,500 --> 00:00:27,300


8
00:00:27,300 --> 00:00:29,279


9
00:00:29,279 --> 00:00:31,859
ライブストリームをミュートしたり、

10
00:00:31,859 --> 00:00:33,480
他のライブストリームをオフにしたりできますが、はい、

11
00:00:33,480 --> 00:00:35,399
参加してくれてありがとう、

12
00:00:35,399 --> 00:00:39,059
はい、ありがとう ええと、招待してくれてありがとうございます、

13
00:00:39,059 --> 00:00:42,019


14
00:00:43,800 --> 00:00:46,399
ええと、あと

15
00:00:46,440 --> 00:00:48,239


16
00:00:48,239 --> 00:00:53,039
35 分か 38 分ほど時間がありますので、

17
00:00:53,039 --> 00:00:55,199


18
00:00:55,199 --> 00:00:57,739
プレゼンテーションを

19
00:00:58,860 --> 00:01:02,460
正しく行うことができたら素晴らしいでしょう、

20
00:01:03,239 --> 00:01:05,880
その瞬間、ええと、

21
00:01:05,880 --> 00:01:08,539


22
00:01:10,380 --> 00:01:14,880
私の井戸が見えますが、パワーポイントを見ました、わかりまし

23
00:01:14,880 --> 00:01:18,500


24
00:01:20,220 --> 00:01:23,220


25
00:01:23,220 --> 00:01:27,659
た、ええと私のものが見えますか スクリーン えー、完璧、

26
00:01:27,659 --> 00:01:29,820
完璧、

27
00:01:29,820 --> 00:01:33,659
それでは始めましょうか はい、ありがとう、わかりました、

28
00:01:33,659 --> 00:01:38,280
それでは、えー、

29
00:01:38,280 --> 00:01:41,759
この素晴らしいえーシンポジウムを開催していただきありがとうございます、

30
00:01:41,759 --> 00:01:45,479
今日は、えー、

31
00:01:45,479 --> 00:01:48,000
正規ニューラル

32
00:01:48,000 --> 00:01:52,200
ネットワークとえー、能動的推論との関係、えー、

33
00:01:52,200 --> 00:01:56,280
拡張の可能性についてお話したいと思います。 現代のええと、

34
00:01:56,280 --> 00:01:59,460


35
00:01:59,460 --> 00:02:04,880
標準的なニューラル ネットワークを使用した共有知性に関する社会です。それでは、それで始めましょう。

36
00:02:08,160 --> 00:02:11,220
ご存知のとおり、フリー エネルギー

37
00:02:11,220 --> 00:02:13,980
原理は、

38
00:02:13,980 --> 00:02:16,920


39
00:02:16,920 --> 00:02:19,200
すべての生物有機体の知覚学習と選択が、

40
00:02:19,200 --> 00:02:21,840


41
00:02:21,840 --> 00:02:24,720
エネルギーの変動を最小限に抑えるように決定されていると述べている車のフリー スタンドによって提案されています。

42
00:02:24,720 --> 00:02:28,260
驚きの最小化のための扱いやすい代用物であり、この

43
00:02:28,260 --> 00:02:31,580
プロセスによって、えー、生物は、えー、パラ合理的な

44
00:02:31,580 --> 00:02:34,800
北京推論または

45
00:02:34,800 --> 00:02:36,900
外部鉱物状態を実行できます。

46
00:02:36,900 --> 00:02:40,379
これがこの漫画です。

47
00:02:40,379 --> 00:02:43,860
自由エネルギー原理の能動的推論の下での典型的なセットアップの一例を示しています。

48
00:02:43,860 --> 00:02:46,640
ここには、

49
00:02:46,640 --> 00:02:49,920
隠れた状態があります。

50
00:02:49,920 --> 00:02:52,920
外界とこの状態の一部だけが、えー、

51
00:02:52,920 --> 00:02:58,319
私たちのエージェントにとって観察可能です、

52
00:02:58,319 --> 00:03:00,959
このドックと

53
00:03:00,959 --> 00:03:04,319
この変換は、

54
00:03:04,319 --> 00:03:06,060


55
00:03:06,060 --> 00:03:08,660
シータによってパラメーター化された遺伝子モデル パラメーターによって行われ、

56
00:03:08,660 --> 00:03:12,780
隠れた状態のエージェントは

57
00:03:12,780 --> 00:03:17,459


58
00:03:17,459 --> 00:03:21,060
外部状態のコピーを再構築する必要があります 後方レリーフと呼ばれる

59
00:03:21,060 --> 00:03:24,239
この最適化は、

60
00:03:24,239 --> 00:03:27,900
変分自由エネルギーを最小化することによって行われ、

61
00:03:27,900 --> 00:03:31,860
パラメータも自由エネルギーを最小化することによって最適化され、

62
00:03:31,860 --> 00:03:35,099


63
00:03:35,099 --> 00:03:37,379
この関係を表す生成モデルを取得します。

64
00:03:37,379 --> 00:03:40,560


65
00:03:40,560 --> 00:03:42,299
自由エネルギー移植のアクティブな

66
00:03:42,299 --> 00:03:44,819
影響の興味深い側面は、それを最適化に適用することです。

67
00:03:44,819 --> 00:03:48,000
ここでのアクションは、エージェントが

68
00:03:48,000 --> 00:03:51,239
C より前に何らかの優先順位を持っており、

69
00:03:51,239 --> 00:03:54,860
将来この観測結果を取得するために

70
00:03:54,860 --> 00:03:59,280
エージェントは、

71
00:03:59,280 --> 00:04:02,640
将来の予想される自由エネルギーを最小化するアクションを選択して、

72
00:04:02,640 --> 00:04:05,580


73
00:04:05,580 --> 00:04:09,540
最も予測可能な結果を​​取得し

74
00:04:09,540 --> 00:04:14,280
、最後に

75
00:04:14,280 --> 00:04:16,019
予想される頻度を最小化するアクションを選択することによって決定します。

76
00:04:16,019 --> 00:04:19,738
フィードを取得できる

77
00:04:19,738 --> 00:04:23,160
ので、これはアクティブなインフラストラクチャでの典型的なセットアップです。

78
00:04:23,160 --> 00:04:25,919
質問は、このプロセスを

79
00:04:25,919 --> 00:04:28,680
実装できる神経名詞基質は何であるかということです。

80
00:04:28,680 --> 00:04:31,500
これが私たちの

81
00:04:31,500 --> 00:04:34,500
興味であり、この問題に対処するために、

82
00:04:34,500 --> 00:04:38,520
次のような理論を提案します。ここでは、

83
00:04:38,520 --> 00:04:41,880
ええと考えます。 外界は、次の

84
00:04:41,880 --> 00:04:45,120


85
00:04:45,120 --> 00:04:50,580
ような一連の変数によって特徴付けられるパラメータ化されています。ここでは、これは

86
00:04:50,580 --> 00:04:53,940
事後期待であり、

87
00:04:53,940 --> 00:04:57,600


88
00:04:57,600 --> 00:05:01,440
Excel の隠れた状態が示すように、デルタはエージェントのアクション

89
00:05:01,440 --> 00:05:05,460
または決定を示し、シータ

90
00:05:05,460 --> 00:05:08,820
はパラメータを示し、ラムダ

91
00:05:08,820 --> 00:05:14,580
は ハイパーパラメータですので、これらの設定された

92
00:05:14,580 --> 00:05:18,240
パラメータまたは変数は

93
00:05:18,240 --> 00:05:22,940
一般性モデルを特徴付け、

94
00:05:22,940 --> 00:05:25,560
エネルギーの自由エネルギー変動は一連の観察

95
00:05:25,560 --> 00:05:28,800


96
00:05:28,800 --> 00:05:31,620
と外部状態の関数として定義され、その

97
00:05:31,620 --> 00:05:33,900
最小化は変分自由エネルギー操作方程式の推論を示します。

98
00:05:33,900 --> 00:05:36,419


99
00:05:36,419 --> 00:05:38,880


100
00:05:38,880 --> 00:05:42,780


101
00:05:42,780 --> 00:05:45,919
ニューラル ネットワークのダイナミクスを考えます。

102
00:05:45,919 --> 00:05:48,900
ダイナミクスはこれらの変数の状態によって特徴付けられると考えます。

103
00:05:48,900 --> 00:05:52,320
ここで、x は中間領域ニューロン

104
00:05:52,320 --> 00:05:55,199
でのニューロン活動の発火率を示し

105
00:05:55,199 --> 00:05:56,780


106
00:05:56,780 --> 00:06:01,080
、Y インジケーターは

107
00:06:01,080 --> 00:06:04,020
出力無線ニューロンの活動に近いことを示します。

108
00:06:04,020 --> 00:06:07,919
ここでの W はシナプスの重みです そして、ファイは、

109
00:06:07,919 --> 00:06:10,680


110
00:06:10,680 --> 00:06:13,740
ニューラル ネットワークを特徴付けるその他の自由パラメータであり、

111
00:06:13,740 --> 00:06:17,060
ニューラル ネットワークのダイナミクスは、

112
00:06:17,060 --> 00:06:19,979
あるコスト関数の最小化によって特徴付けられると考えられます。

113
00:06:19,979 --> 00:06:23,520
ここで、これは、ニューラル ネットワーク

114
00:06:23,520 --> 00:06:26,220
の内部状態の O とファイの関数であり、

115
00:06:26,220 --> 00:06:28,500


116
00:06:28,500 --> 00:06:32,039
最小化です これは、活動と可塑性の両方を含む

117
00:06:32,039 --> 00:06:34,500
ニューラル ネットワーク ダイナミクスの生成を示してい

118
00:06:34,500 --> 00:06:37,740


119
00:06:37,740 --> 00:06:41,940
ます。そして、私たちの理論は、

120
00:06:41,940 --> 00:06:45,500
2 つの関数が等価であることを示しています。これは、

121
00:06:45,500 --> 00:06:49,979


122
00:06:49,979 --> 00:06:52,380
コスト関数誤差を最小限に抑えるニューラル ネットワークには、

123
00:06:52,380 --> 00:06:55,620


124
00:06:55,620 --> 00:06:59,720
Air と呼ぶと満たされる遺伝的モデルが存在することを意味します。 ええと、

125
00:06:59,720 --> 00:07:01,940


126
00:07:01,940 --> 00:07:05,340
外部ダイナミクスの再捕捉は、そのようなダイナミクスの場合、

127
00:07:05,340 --> 00:07:08,580
ニューラル システムに固有の機能です。したがって、

128
00:07:08,580 --> 00:07:13,319
これは

129
00:07:13,319 --> 00:07:16,680
興味深い予測ですが、他の 2 つの

130
00:07:16,680 --> 00:07:17,780
構造体なので、

131
00:07:17,780 --> 00:07:21,780


132
00:07:21,780 --> 00:07:24,180


133
00:07:24,180 --> 00:07:28,620
この関係を形式的に理解するために、分析的に対話可能な例を紹介したいと思います。

134
00:07:28,620 --> 00:07:31,759
非常に単純な

135
00:07:31,759 --> 00:07:35,280
アーキテクチャです。これは、

136
00:07:35,280 --> 00:07:39,660
ステージ遷移のない Pome DP によって表されます。したがって、

137
00:07:39,660 --> 00:07:43,220
彼女は s を取得しませんでした。単純に

138
00:07:43,220 --> 00:07:46,319
飛行年分布 D によって生成されます。

139
00:07:46,319 --> 00:07:52,620
これはバイナリ状態ですが、

140
00:07:52,620 --> 00:07:56,160
バイナリ状態のベクトルを考慮します。

141
00:07:56,160 --> 00:08:00,240
構造の階乗ファクトリーと

142
00:08:00,240 --> 00:08:03,900
観測結果もバイナリ

143
00:08:03,900 --> 00:08:08,220
ベクトルであり、s から O への変換は、

144
00:08:08,220 --> 00:08:11,160


145
00:08:11,160 --> 00:08:16,979
正規行列 a を使用するカテゴリカル分布

146
00:08:16,979 --> 00:08:20,099
と変分北京推論によって特徴付けられます。

147
00:08:20,099 --> 00:08:22,919


148
00:08:22,919 --> 00:08:27,180
このような生成プロセスの反転は、

149
00:08:27,180 --> 00:08:29,660
適切な自由エネルギー汎関数を解くことによって示されます。

150
00:08:29,660 --> 00:08:33,599


151
00:08:33,599 --> 00:08:37,219


152
00:08:37,219 --> 00:08:40,140
ベイズ的な意味で最適な事後ブリーフが得られるので、

153
00:08:40,140 --> 00:08:42,479
一方でニューラル ネットワークについては

154
00:08:42,479 --> 00:08:46,920
そのような構造を考慮します。えー、ここの

155
00:08:46,920 --> 00:08:50,040
上部は外界での信号の生成を示し

156
00:08:50,040 --> 00:08:52,560
、ニューラル

157
00:08:52,560 --> 00:08:55,320
ネットワークはここでのアクティビティの単一層のみで構成されます。

158
00:08:55,320 --> 00:08:59,880


159
00:08:59,880 --> 00:09:02,540
関連する感覚入力の合計によって生成されるか、

160
00:09:02,540 --> 00:09:06,839
シナプス マトリックス W によって重み付けされた出力層です。

161
00:09:06,839 --> 00:09:10,440


162
00:09:10,440 --> 00:09:12,120


163
00:09:12,120 --> 00:09:14,339
次のスライドでこのニューラル ネットワークの特徴を説明します。

164
00:09:14,339 --> 00:09:18,360
つまり、ニューラル ニューラル ネットワークまたはニューロンをモデル化するために、

165
00:09:18,360 --> 00:09:19,700


166
00:09:19,700 --> 00:09:22,760
プロジェクト方程式を検討することから始めます。

167
00:09:22,760 --> 00:09:27,600


168
00:09:27,600 --> 00:09:30,839
4 つの微分方程式であり、

169
00:09:30,839 --> 00:09:33,959
これは非常に複雑な非線形

170
00:09:33,959 --> 00:09:37,500
方程式であり、これはバリケードである

171
00:09:37,500 --> 00:09:40,260
可能性がありますが、

172
00:09:40,260 --> 00:09:43,880
これらの方程式のいくつかの縮小を考慮します。そのため、典型的な

173
00:09:43,880 --> 00:09:47,279
縮小方法は

174
00:09:47,279 --> 00:09:52,080
実践です。たとえば、ここでの M は

175
00:09:52,080 --> 00:09:55,019
他の変数よりもはるかに高速であるため、これは次のようになります。

176
00:09:55,019 --> 00:09:59,580
固定点で置き換えるか、

177
00:09:59,580 --> 00:10:04,080
H とマイナス 1 が知られています。申し訳ありませんが、

178
00:10:04,080 --> 00:10:09,480
H と 1 マイナス s n は

179
00:10:09,480 --> 00:10:13,620
同様のダイナミクスを持つことが知られているため、これら 2 つの変数を特徴付ける

180
00:10:13,620 --> 00:10:17,339
新しい有効変数 U を考慮することができ

181
00:10:17,339 --> 00:10:19,700


182
00:10:19,700 --> 00:10:23,459
、次の結果が得られます。

183
00:10:23,459 --> 00:10:28,019
このような正の方程式になるので、これはよく

184
00:10:28,019 --> 00:10:31,820


185
00:10:31,820 --> 00:10:36,180
知られている固定ビュー

186
00:10:36,180 --> 00:10:40,820
と一致モデル、またはその他の

187
00:10:40,820 --> 00:10:44,160
連続ニューラル ネットワーク モデルを含む有名なクラスのニューラル ネットワーク モデルであり、

188
00:10:44,160 --> 00:10:49,860
これらのモデルを修正して

189
00:10:49,860 --> 00:10:52,740
正規ニューラル モデルを導出します。 これは

190
00:10:52,740 --> 00:10:56,220
正準ニューラル ネットワーク モデルの定義です。

191
00:10:56,220 --> 00:10:59,459
ここでの

192
00:10:59,459 --> 00:11:02,579
リーク電流は、fitsview ナグマ モデルで採用されている 3 次関数ではなく、バスの sumoid 関数によって特徴付けられます。

193
00:11:02,579 --> 00:11:06,000


194
00:11:06,000 --> 00:11:08,940


195
00:11:08,940 --> 00:11:12,060
また、

196
00:11:12,060 --> 00:11:15,180
接続、つまりシナプス

197
00:11:15,180 --> 00:11:18,980
接続も考慮され、この部分は

198
00:11:18,980 --> 00:11:22,820
シナプス入力を示します。 感覚層

199
00:11:22,820 --> 00:11:28,440
からええと重み行列を介して、

200
00:11:28,440 --> 00:11:31,800
W1 は興奮性シナプスを示し

201
00:11:31,800 --> 00:11:34,320
、w0 指標はインベントリ

202
00:11:34,320 --> 00:11:37,579
シナプスと

203
00:11:37,579 --> 00:11:40,140


204
00:11:40,140 --> 00:11:45,180
WR と w0 の関数であるスウェットシャツの適応閾値を示すと考えることができます。興味深いことに、

205
00:11:45,180 --> 00:11:47,880
この微分方程式の固定点を考慮すると、

206
00:11:47,880 --> 00:11:51,480


207
00:11:51,480 --> 00:11:54,899
井戸が得られます。  - シグモイダー活性化関数を使用した既知のレッド コーディング モデル。

208
00:11:54,899 --> 00:11:58,500
つまり、

209
00:11:58,500 --> 00:12:01,920


210
00:12:01,920 --> 00:12:03,920
この標準的なニューラル ネットワーク モデルは、ある意味では方程式が

211
00:12:03,920 --> 00:12:08,940
得られるものの近似であり

212
00:12:08,940 --> 00:12:12,540
、その近似

213
00:12:12,540 --> 00:12:16,140
レベルは、

214
00:12:16,140 --> 00:12:19,380
ある意味で現実的なレベルの間であると言えます。

215
00:12:19,380 --> 00:12:22,920
モデルと最も単純化されたレッド コーディング

216
00:12:22,920 --> 00:12:26,640
モデルなので、基本的にこのタイプ

217
00:12:26,640 --> 00:12:30,120
のニューラル ネットワーク モデルを検討します。次のスライドでは、

218
00:12:30,120 --> 00:12:31,700


219
00:12:31,700 --> 00:12:35,279


220
00:12:35,279 --> 00:12:39,000
このニューラル ネットワーク モデルの妥当なコスト関数は何かを検討します。

221
00:12:39,000 --> 00:12:42,360
そこで、もう一度、

222
00:12:42,360 --> 00:12:45,600
正規ニューラル ネットワーク モデルに対して同じ方程式を書きます。

223
00:12:45,600 --> 00:12:49,079


224
00:12:49,079 --> 00:12:52,620
ニューロンの活動 ニューロンのベクトルで

225
00:12:52,620 --> 00:12:53,579


226
00:12:53,579 --> 00:12:58,079
あり、この微分方程式のコスト関数を検討します。この微分

227
00:12:58,079 --> 00:13:00,180
方程式は、

228
00:13:00,180 --> 00:13:02,600


229
00:13:02,600 --> 00:13:07,200


230
00:13:07,200 --> 00:13:12,300
この方程式の右側の積分を単純に計算することで得られ、

231
00:13:12,300 --> 00:13:15,779
ニューラル ネットワークのこのタイプのコスト関数を取得します。

232
00:13:15,779 --> 00:13:18,660
これは生物学的ポータブル コスト

233
00:13:18,660 --> 00:13:20,760
関数です。 その

234
00:13:20,760 --> 00:13:22,860
導関数が、確率と呼ばれる

235
00:13:22,860 --> 00:13:26,700
特定のウイルスを持つニューラルネットワーク活動を導き出したという意味で、

236
00:13:26,700 --> 00:13:28,139


237
00:13:28,139 --> 00:13:29,779
さらに、

238
00:13:29,779 --> 00:13:33,899
このコスト関数の導関数を

239
00:13:33,899 --> 00:13:36,480
シノプティックウェイト

240
00:13:36,480 --> 00:13:41,700
w に関して考慮すると、ヘピアの法則に従う従来のシナプス

241
00:13:41,700 --> 00:13:45,300
可塑性ルールが得られます。

242
00:13:45,300 --> 00:13:47,339


243
00:13:47,339 --> 00:13:51,260


244
00:13:51,540 --> 00:13:54,060
北京推論に手を出します。最初に

245
00:13:54,060 --> 00:13:57,779
前のスライドのように一般性モデルを定義し、

246
00:13:57,779 --> 00:14:03,720
それから申し訳ありませんが、

247
00:14:03,720 --> 00:14:07,500


248
00:14:07,500 --> 00:14:10,620
与えられた遺伝モデルの変分エネルギーを導き出します。したがって、この

249
00:14:10,620 --> 00:14:14,639
自由エネルギーの変化は、えー、

250
00:14:14,639 --> 00:14:19,019
前のスライドのパーム DP モデルから導出されます。 スライド

251
00:14:19,019 --> 00:14:23,100
とその最小化は、ああ、

252
00:14:23,100 --> 00:14:26,279
北京の森とランニングを示します。

253
00:14:26,279 --> 00:14:30,740
そこで、このように

254
00:14:30,920 --> 00:14:34,860


255
00:14:34,860 --> 00:14:38,300
これら 2 つのコスト関数のコンポーネント間の正式な対応関係を形成しました。その

256
00:14:38,300 --> 00:14:42,920
ため、このブロック ベクトルは、

257
00:14:42,920 --> 00:14:46,260


258
00:14:46,260 --> 00:14:49,040
事後期待を表すこのブロック ベクトルに正式に対応し

259
00:14:49,040 --> 00:14:53,160
、この対数はこの対数に対応します。

260
00:14:53,160 --> 00:14:54,600


261
00:14:54,600 --> 00:14:59,459
そして実際には、この行列は次の

262
00:14:59,459 --> 00:15:02,339
ようにブロック行列として表すことができ、

263
00:15:02,339 --> 00:15:06,019
これは

264
00:15:06,019 --> 00:15:09,600
この計算に対応する DOT 積です。そして

265
00:15:09,600 --> 00:15:12,620
最後に、これらの 5 つは

266
00:15:12,620 --> 00:15:16,320
当然これに対応します。えー、

267
00:15:16,320 --> 00:15:20,880
前の状態のロゴをロードします。つまり、

268
00:15:20,880 --> 00:15:24,540
コスト関数が同じであるためです。

269
00:15:24,540 --> 00:15:28,519
それは導関数です えー、

270
00:15:28,519 --> 00:15:31,860


271
00:15:31,860 --> 00:15:33,540


272
00:15:33,540 --> 00:15:37,980
その導関数は を提供します いくつかの

273
00:15:37,980 --> 00:15:39,600
[音楽]

274
00:15:39,600 --> 00:15:44,120
申し訳ありませんが、コスト関数は

275
00:15:44,120 --> 00:15:48,420
形式的には同等であるため、それは導関数です えー、

276
00:15:48,420 --> 00:15:52,820
申し訳ありません、それは a です、それは導関数の結果です、

277
00:15:52,820 --> 00:15:56,339
それは相互に対応している

278
00:15:56,339 --> 00:16:00,839
ので、つまり、ええと

279
00:16:00,839 --> 00:16:04,500
この形式のインタラクティブな方程式は、

280
00:16:04,500 --> 00:16:06,839
対応するベイズ推論方程式があります。

281
00:16:06,839 --> 00:16:09,899
これはヘリウム

282
00:16:09,899 --> 00:16:13,860
の事後 div を計算する方程式です。状態

283
00:16:13,860 --> 00:16:17,579
とこのシナプス プロセス

284
00:16:17,579 --> 00:16:20,519
方程式の形式は、

285
00:16:20,519 --> 00:16:23,820
生成モデルの学習またはパラメーターに対応します。

286
00:16:23,820 --> 00:16:27,120
さらに、この関係を確立することで、次のことを

287
00:16:27,120 --> 00:16:30,480
考慮できます。 経験的データ

288
00:16:30,480 --> 00:16:33,360
からの遺伝子モデルのリバース エンジニアリングは、

289
00:16:33,360 --> 00:16:37,399
ここにあります。えー、この

290
00:16:37,399 --> 00:16:38,959
図は、

291
00:16:38,959 --> 00:16:43,380


292
00:16:43,380 --> 00:16:45,899
生成モデルをリバース エンジニアリングするアプローチを要約しています。

293
00:16:45,899 --> 00:16:48,060
最初にニューラル活動を記録し、

294
00:16:48,060 --> 00:16:50,880
キャノン缶ニューラル ネットワークを割り当てて、

295
00:16:50,880 --> 00:16:54,779
この得られたデータを説明し、

296
00:16:54,779 --> 00:16:57,240
得られた積分を計算します。

297
00:16:57,240 --> 00:16:59,660
この標準ネットワークのコスト関数であり

298
00:16:59,660 --> 00:17:03,540
、

299
00:17:03,540 --> 00:17:05,900
確立した数学的等価性によって、このニューラル ネットワーク アーキテクチャに対応する

300
00:17:05,900 --> 00:17:09,000
遺伝モデルと自由

301
00:17:09,000 --> 00:17:11,760
操作自由エネルギーを自動的に識別できます。

302
00:17:11,760 --> 00:17:16,079


303
00:17:16,079 --> 00:17:20,059
興味深いことに、これはベイジアン エージェントの

304
00:17:20,059 --> 00:17:24,020
一種です。

305
00:17:24,020 --> 00:17:27,179
人工知能ですが重要なのは、

306
00:17:27,179 --> 00:17:30,299
この人工知能は正式に

307
00:17:30,299 --> 00:17:33,660
経験的データから導出されたものであるため、

308
00:17:33,660 --> 00:17:37,520
このエージェントは、エネルギー前原理に

309
00:17:37,520 --> 00:17:39,960
従う生体認証アクティブシェアインテリジェンスであり、

310
00:17:39,960 --> 00:17:42,960


311
00:17:42,960 --> 00:17:46,440
その後、

312
00:17:46,440 --> 00:17:49,520
パラメーター事後

313
00:17:49,520 --> 00:17:52,919
派生シナプスプロテーゼアルゴリズムに従うその派生であると言えます。

314
00:17:52,919 --> 00:17:55,860
自由エネルギーの最小化

315
00:17:55,860 --> 00:18:00,600
とその時間積分は、

316
00:18:00,600 --> 00:18:03,720
元のニューラル

317
00:18:03,720 --> 00:18:04,880
ネットワークの

318
00:18:04,880 --> 00:18:07,380
ニューラル ネットワーク

319
00:18:07,380 --> 00:18:11,820
データの実行プロセスを予測できます。つまり、

320
00:18:11,820 --> 00:18:14,700
自由が原則である場合、

321
00:18:14,700 --> 00:18:17,100
この予測は

322
00:18:17,100 --> 00:18:20,640
機能するはずであり、

323
00:18:20,640 --> 00:18:24,900
この結果を予測できるはずです。

324
00:18:24,900 --> 00:18:29,820
データ自体を参照せずにニューラルデータを使用する

325
00:18:29,820 --> 00:18:34,200
ため、私たちの戦略は、要約すると、

326
00:18:34,200 --> 00:18:37,460


327
00:18:37,460 --> 00:18:41,760


328
00:18:41,760 --> 00:18:46,200


329
00:18:46,200 --> 00:18:50,160
学習前に初期データと同様の初期データのみから遺伝モデルを再構築し、その後、このニューラルニューラルシステムが実行すべき

330
00:18:50,160 --> 00:18:52,520
実行プロセスまたは実行曲線を予測することです。

331
00:18:52,520 --> 00:18:56,880


332
00:18:56,880 --> 00:18:58,260


333
00:18:58,260 --> 00:19:02,460
自由エネルギー原理を使用して追跡し、

334
00:19:02,460 --> 00:19:05,640
この予測がどこで正しいかを比較または検討します。 えー、

335
00:19:05,640 --> 00:19:09,179


336
00:19:09,179 --> 00:19:13,559
実行後の実際のデータと

337
00:19:13,559 --> 00:19:16,200
周波数原理による予測を比較して

338
00:19:16,200 --> 00:19:19,200
、この予測が正しければ、

339
00:19:19,200 --> 00:19:22,320


340
00:19:22,320 --> 00:19:25,200
自由エネルギー原理の予測の妥当性を示します。 設定は

341
00:19:25,200 --> 00:19:26,520


342
00:19:26,520 --> 00:19:27,600
問題ないと考えられた

343
00:19:27,600 --> 00:19:31,440
ので、この戦略を in vitro ニューラル ネットワークに適用します。

344
00:19:31,440 --> 00:19:34,679
ここで、この in

345
00:19:34,679 --> 00:19:37,320
vitro ニューラル ネットワークは、前のスライドで定義した

346
00:19:37,320 --> 00:19:40,460
DP 属生プロセスの形式を使用して刺激されます。

347
00:19:40,460 --> 00:19:44,460
つまり、

348
00:19:44,460 --> 00:19:47,360
バイナリ信号である 2 つの隠れたソースがあり、

349
00:19:47,360 --> 00:19:51,660
それらは次のようになります。 混合物であり、それらは

350
00:19:51,660 --> 00:19:56,600
混合されて32の感覚ストリーミングを生成します。

351
00:19:56,600 --> 00:20:01,860
これらもバイナリであり、

352
00:20:01,860 --> 00:20:06,780
これは概要実験です。

353
00:20:06,780 --> 00:20:09,600
体外ニューロンを刺激することによって、

354
00:20:09,600 --> 00:20:13,020
スパイクスパイク応答を生成し、

355
00:20:13,020 --> 00:20:16,880
それらの韻は高密度

356
00:20:16,880 --> 00:20:23,460
スパイク応答を示しているため、

357
00:20:23,460 --> 00:20:27,260
いくつかの点でそれに従うことになります。 ニューロンの

358
00:20:27,480 --> 00:20:30,360
応答特異性

359
00:20:30,360 --> 00:20:34,799
は、

360
00:20:34,799 --> 00:20:37,820
あるニューロンの

361
00:20:37,820 --> 00:20:41,539
応答が

362
00:20:41,539 --> 00:20:43,440
ソース 1 の信号に対して

363
00:20:43,440 --> 00:20:47,700
ソース 2 の信号と比較して高いことがわかりました。

364
00:20:47,700 --> 00:20:54,179
これらのニューロンの遷移を見ると、

365
00:20:54,179 --> 00:20:58,700


366
00:20:58,700 --> 00:21:03,360
最初のセッションでオフセットを削除しても、ええとわかることがわかりました。

367
00:21:03,360 --> 00:21:08,340
これらの活動をゼロに設定します

368
00:21:08,340 --> 00:21:14,120
が、ソース 1 が 1 の場合、これらのニューロンは

369
00:21:14,120 --> 00:21:17,940
自己組織化されて高レベルに応答しますが、

370
00:21:17,940 --> 00:21:21,960


371
00:21:21,960 --> 00:21:27,080


372
00:21:27,080 --> 00:21:32,100
ソース 1 が 0 の場合、

373
00:21:32,100 --> 00:21:35,940
それらのニューロンは低レベルで応答することがわかります。これは、ニューロンの応答を介したニューロン活動が意味します。

374
00:21:35,940 --> 00:21:39,860
これは、

375
00:21:39,860 --> 00:21:43,380


376
00:21:43,380 --> 00:21:46,679
新しい活動がヘリウム状態の

377
00:21:46,679 --> 00:21:48,840
事後期待をエンコードするために組織化されているという理論的予測と一致していました。

378
00:21:48,840 --> 00:21:52,559
また、

379
00:21:52,559 --> 00:21:54,720
他のグループのニューロンが

380
00:21:54,720 --> 00:21:58,020
ソース 2 に優先的に反応するが、

381
00:21:58,020 --> 00:22:01,500
ソース 1 には反応しないこともわかりました。

382
00:22:01,500 --> 00:22:07,980
それで、わかりましたと尋ねると、次のことがわかりました。

383
00:22:07,980 --> 00:22:11,100


384
00:22:11,100 --> 00:22:13,080
神経活動によってエンコードされた事後期待、そして次の質問は、

385
00:22:13,080 --> 00:22:16,260
他のものは何か、他の神経基質についてはどうなのか、そして

386
00:22:16,260 --> 00:22:20,520


387
00:22:20,520 --> 00:22:24,600


388
00:22:24,980 --> 00:22:29,900
隠れた状態に関する優先度が

389
00:22:29,900 --> 00:22:33,179


390
00:22:33,179 --> 00:22:37,220
神経活動モデルの発火閾値に等しい有効度に等しいかどうかを尋ねます

391
00:22:37,220 --> 00:22:41,220
ネットワークモデル うーん サーバーが

392
00:22:41,220 --> 00:22:43,860
正しい場合、これを確認するために対応する対応が

393
00:22:43,860 --> 00:22:48,600
存在する必要があります えー、

394
00:22:48,600 --> 00:22:52,980
最初に北京エージェントをシミュレートし、

395
00:22:52,980 --> 00:22:55,799


396
00:22:55,799 --> 00:23:00,240
北京エージェントの優先順位を評価すると、

397
00:23:00,240 --> 00:23:03,980
予想どおり推論が弱まり

398
00:23:03,980 --> 00:23:09,080
、興奮レベルを埋めたときに警告しました

399
00:23:09,080 --> 00:23:12,179


400
00:23:12,179 --> 00:23:15,120
薬理学的操作を使用した in vitro ニューラル ネットワークの解析では、

401
00:23:15,120 --> 00:23:19,799


402
00:23:19,799 --> 00:23:22,919
減衰が推論の減衰であることもわかりました。

403
00:23:22,919 --> 00:23:24,299


404
00:23:24,299 --> 00:23:27,720
これは、

405
00:23:27,720 --> 00:23:30,320


406
00:23:30,320 --> 00:23:34,740
財務しきい値が優先順位または隠れ状態をエンコードするという理論的予測と一致します。

407
00:23:34,740 --> 00:23:38,100


408
00:23:38,100 --> 00:23:42,419
次に、

409
00:23:42,419 --> 00:23:46,200
相乗的可塑性が自由な状態に従うかどうかを検討します。

410
00:23:46,200 --> 00:23:50,720
エネルギー原理は、

411
00:23:50,720 --> 00:23:54,140
周波数原理が後続のニューラル データ

412
00:23:54,140 --> 00:23:57,659
の定性的自己組織化を予測できるかどうかを尋ねることによって行われます。

413
00:23:57,659 --> 00:23:59,780


414
00:23:59,780 --> 00:24:01,400


415
00:24:01,400 --> 00:24:05,580


416
00:24:05,580 --> 00:24:10,140
そこで、このようなニューラル ニューラル ニューラル ネットワークをモデル化します。

417
00:24:10,140 --> 00:24:12,840


418
00:24:12,840 --> 00:24:15,240
ソース 1 とソース 2 をエンコードする 2 つのアンサンブル ニューロンがあり

419
00:24:15,240 --> 00:24:20,700
、最初に計算します。

420
00:24:20,700 --> 00:24:25,400
えー、それらのネットワークの有効シナプス重み えー、

421
00:24:25,400 --> 00:24:28,820


422
00:24:28,820 --> 00:24:32,039
前述したような従来の接続文字列を使用したアプローチ

423
00:24:32,039 --> 00:24:37,500
とプロット ドット えー最終的には

424
00:24:37,500 --> 00:24:38,480
ファイル

425
00:24:38,480 --> 00:24:42,120
ランドスケープまたは理論的に計算された自由

426
00:24:42,120 --> 00:24:42,960
エネルギーに相当します

427
00:24:42,960 --> 00:24:45,179


428
00:24:45,179 --> 00:24:49,400
これは MP カリーの

429
00:24:49,400 --> 00:24:51,020
推定

430
00:24:51,020 --> 00:24:54,240
シナプス グレードの軌跡です 効果的なシナプス

431
00:24:54,240 --> 00:24:58,440
プロセス シナプス 接続性と

432
00:24:58,440 --> 00:25:02,840
予測どおり、これらの変化は

433
00:25:02,840 --> 00:25:08,059
自由エネルギーを減少させます。

434
00:25:08,159 --> 00:25:13,039
ここでは、

435
00:25:13,039 --> 00:25:16,080


436
00:25:16,080 --> 00:25:21,179
最初の 10 セッション データのみを使用して、

437
00:25:21,179 --> 00:25:24,480
この理論的に予測された自由エネルギーの状況を計算しました。これは、

438
00:25:24,480 --> 00:25:29,039


439
00:25:29,039 --> 00:25:32,580
自己組織化の予測を示すものであり

440
00:25:32,580 --> 00:25:36,960
、より明確な予測については、

441
00:25:36,960 --> 00:25:41,460
次に、

442
00:25:41,460 --> 00:25:43,919
周波数原理を使用して、新しい活動と可塑性をシミュレートしました。

443
00:25:43,919 --> 00:25:46,039
ここ

444
00:25:46,039 --> 00:25:50,460
で、明るい色は、活動データを参照せ

445
00:25:50,460 --> 00:25:54,779
ずに、えー、データの予測を示します。

446
00:25:54,779 --> 00:25:59,159
そのため、

447
00:25:59,159 --> 00:26:00,779
これらの線は、えー、

448
00:26:00,779 --> 00:26:03,419
この周波数勾配に正確に従っており

449
00:26:03,419 --> 00:26:05,100


450
00:26:05,100 --> 00:26:09,320
、この予測された

451
00:26:09,320 --> 00:26:11,000
軌跡が

452
00:26:11,000 --> 00:26:16,700
タイトルであることがわかりました。 タイトルはこの

453
00:26:16,700 --> 00:26:20,220
経験的に推定された有効シナプス

454
00:26:20,220 --> 00:26:21,840
重みと相関しており、

455
00:26:21,840 --> 00:26:26,039
初期のレートは実践的なものである

456
00:26:26,039 --> 00:26:30,240
ため、原理的には

457
00:26:30,240 --> 00:26:31,500


458
00:26:31,500 --> 00:26:34,919


459
00:26:34,919 --> 00:26:37,500
この設定での連続コロニー形成を定量的に予測できることを示し

460
00:26:37,500 --> 00:26:40,919
ているため、このセクターでの周波数原理のある程度の予測可能性を示しており

461
00:26:40,919 --> 00:26:44,039


462
00:26:44,039 --> 00:26:47,820
、その後、次のことも考慮します

463
00:26:47,820 --> 00:26:51,779


464
00:26:51,779 --> 00:26:54,900
能動推論を使用した神経変調のモデリング シナプス

465
00:26:54,900 --> 00:26:58,559
プロセスが

466
00:26:58,559 --> 00:27:02,760
ドーパミンやセロトニンなどを記録する他の学習資産などのさまざまな要因によって変更されることはよく知られていますが、

467
00:27:02,760 --> 00:27:05,340


468
00:27:05,340 --> 00:27:06,059


469
00:27:06,059 --> 00:27:09,840
それらの変調の興味深い特性の1つは、

470
00:27:09,840 --> 00:27:14,700
それでもドーパミンが

471
00:27:14,700 --> 00:27:15,779


472
00:27:15,779 --> 00:27:17,299


473
00:27:17,299 --> 00:27:21,679
結合可塑性の後に追加されたということです。 事後的またはそれ以下の方法で

474
00:27:21,679 --> 00:27:25,980
可塑性の結果を変更できることが確立されている

475
00:27:25,980 --> 00:27:29,340


476
00:27:29,340 --> 00:27:31,860
ため、

477
00:27:31,860 --> 00:27:35,760


478
00:27:35,760 --> 00:27:39,419
報酬と過去の決定との関連付けが印象付けられるため、

479
00:27:39,419 --> 00:27:42,059
標準ニューラル ネットワークを使用してこのプロセスをモデル化します。そこで、

480
00:27:42,059 --> 00:27:45,480
ここでは

481
00:27:45,480 --> 00:27:46,880


482
00:27:46,880 --> 00:27:51,659
ABN 可塑性のハルク変調を次の方法でモデル化します。

483
00:27:51,659 --> 00:27:56,940
ああ、このタイプのプラスチック方程式、そして

484
00:27:56,940 --> 00:27:59,760


485
00:27:59,760 --> 00:28:03,659


486
00:28:03,659 --> 00:28:06,179
このネットワークの韓国発のリカレント ニューラル ネットワーク構造も考慮し、

487
00:28:06,179 --> 00:28:12,299
この接続層で変調が発生したと考え、

488
00:28:13,980 --> 00:28:19,200


489
00:28:19,200 --> 00:28:23,600
その微分方程式を導出できるコスト関数を見つけました。

490
00:28:23,600 --> 00:28:26,940


491
00:28:26,940 --> 00:28:29,520
エネルギーと遺伝モデルの対応する変分を形成しました。

492
00:28:29,520 --> 00:28:33,299
つまり、洞可塑性の調節を含むこの

493
00:28:33,299 --> 00:28:35,279
種のニューラル ネットワーク活動は、

494
00:28:35,279 --> 00:28:37,919


495
00:28:37,919 --> 00:28:41,940
自由エネルギー原理

496
00:28:41,940 --> 00:28:43,159
と

497
00:28:43,159 --> 00:28:45,380
ある種の

498
00:28:45,380 --> 00:28:47,400
均一性モデルに正確に従っていることを意味します。

499
00:28:47,400 --> 00:28:53,480
これを使用することで、この

500
00:28:53,480 --> 00:28:55,940
生物学的にアプローチ可能な

501
00:28:55,940 --> 00:28:58,980
ニューラル ネットワークが存在することを示します。 変調と

502
00:28:58,980 --> 00:29:01,799
重さと可塑性を備えたモデルは、

503
00:29:01,799 --> 00:29:06,360
迷路タスクのようなある種の遅延報酬タスクを解決できます。

504
00:29:06,360 --> 00:29:07,980


505
00:29:07,980 --> 00:29:10,140
そして最後に、

506
00:29:10,140 --> 00:29:12,659
このフレームワークを

507
00:29:12,659 --> 00:29:16,080
現代の社会

508
00:29:16,080 --> 00:29:21,960
知性へと拡張する可能性について議論したいと思います。つまり、具体的な問題を推測するためです。 私たちは

509
00:29:21,960 --> 00:29:26,580


510
00:29:26,580 --> 00:29:28,860


511
00:29:28,860 --> 00:29:32,760


512
00:29:32,760 --> 00:29:36,480
出席状況に応じて一般性モデルまたはパートナーを作成するアプローチを選択する必要があります。そのため、これはメジャー モデル選択スキームによって実行できます。

513
00:29:36,480 --> 00:29:39,299


514
00:29:39,299 --> 00:29:42,380
以前、1 つの大きな生成モデルを

515
00:29:42,380 --> 00:29:48,419
使用して複数の有効な形式を予測できるモデルを提案しました。

516
00:29:48,419 --> 00:29:49,640


517
00:29:49,640 --> 00:29:53,279


518
00:29:53,279 --> 00:29:58,080
複数の遺伝子モデルで構成されており、この映画は、

519
00:29:58,080 --> 00:29:59,520


520
00:29:59,520 --> 00:30:03,440


521
00:30:04,620 --> 00:30:07,919


522
00:30:07,919 --> 00:30:13,640
えー、歌の予測の予測を示しています。このように、この現代の 93 は、

523
00:30:13,640 --> 00:30:17,940
どの巨大なモデルが最も優れ

524
00:30:17,940 --> 00:30:21,600
ているかを特定します。与えられた感覚入力を説明し、

525
00:30:21,600 --> 00:30:25,860
このプロセスは、

526
00:30:25,860 --> 00:30:26,760


527
00:30:26,760 --> 00:30:30,360
モデルが適切な情報を正しく入力できることを示します。

528
00:30:30,360 --> 00:30:32,399
モデルを作成

529
00:30:32,399 --> 00:30:36,539
し、

530
00:30:36,539 --> 00:30:39,000
独自のアクションで歌を模倣する

531
00:30:39,000 --> 00:30:40,140
ため、

532
00:30:40,140 --> 00:30:42,299
前の研究ではこの混合地理学モデルの

533
00:30:42,299 --> 00:30:46,500
詳細なニューロン基板について議論しませんでしたが、

534
00:30:46,500 --> 00:30:51,059
今では、

535
00:30:51,059 --> 00:30:55,039


536
00:30:55,039 --> 00:30:58,559
たとえばモジュールニューラルの変調を考慮すると、対応するアーキテクチャを検討できるようになります。

537
00:30:58,559 --> 00:31:03,000


538
00:31:03,000 --> 00:31:05,480


539
00:31:05,480 --> 00:31:09,779
ドーパミンなどの神経調節物質によるモジュールであり、注意フィルターとして使用されます。

540
00:31:09,779 --> 00:31:13,620
この注意

541
00:31:13,620 --> 00:31:16,860
フィルターは、えー、

542
00:31:16,860 --> 00:31:19,820
3 つのファクターヘビーとランニンググループで説明できます。

543
00:31:19,820 --> 00:31:22,799
前のスライドで紹介したものです。

544
00:31:22,799 --> 00:31:28,620
つまり、このモジュレーションは、

545
00:31:28,620 --> 00:31:33,919
過去のより重い可塑性を持たないポストホックモジュレーションとして機能します。

546
00:31:33,919 --> 00:31:37,080
この変調は、

547
00:31:37,080 --> 00:31:38,659


548
00:31:38,659 --> 00:31:42,080


549
00:31:42,080 --> 00:31:46,440


550
00:31:46,440 --> 00:31:48,320


551
00:31:48,320 --> 00:31:52,140
相互に独立した方法で 1 つの一般性モデル、1 つの一般性モデル、1 つの曲を表現するように各モデルを最適化することができます。したがって、

552
00:31:52,140 --> 00:31:56,039
このプロセスを通じて、

553
00:31:56,039 --> 00:31:59,100
仮想的に可能な方法で複数の遺伝的モデルを学習することが可能です。

554
00:31:59,100 --> 00:32:02,820
つまり、

555
00:32:02,820 --> 00:32:05,340
要約すると、

556
00:32:05,340 --> 00:32:07,679
コスト関数を最小化する正準ニューラル ネットワークは、

557
00:32:07,679 --> 00:32:12,299


558
00:32:12,299 --> 00:32:15,000
エネルギーの変動の最小化として読み取ることができます。これは、

559
00:32:15,000 --> 00:32:17,880
周波数原理が

560
00:32:17,880 --> 00:32:21,960
このタイプのニューラル ネットワークの説明であることを示します。

561
00:32:21,960 --> 00:32:27,120
また、それを示し、次のことを示すことによって、いくつかの個別の設定を使用してこの予測を検証します。

562
00:32:27,120 --> 00:32:31,440


563
00:32:31,440 --> 00:32:33,480
友人は

564
00:32:33,480 --> 00:32:36,240
原則として、初期データ

565
00:32:36,240 --> 00:32:38,399


566
00:32:38,399 --> 00:32:42,720
のみを使用してその後の可塑性の自己組織化を定量的に予測することができ

567
00:32:42,720 --> 00:32:44,880


568
00:32:44,880 --> 00:32:49,380
、モデリングとして

569
00:32:49,380 --> 00:32:53,460
これらの標準的なネットワークモデリングをオプション生成に拡張し、

570
00:32:53,460 --> 00:32:54,320


571
00:32:54,320 --> 00:32:57,840


572
00:32:57,840 --> 00:33:01,020
重さと可塑性の遅延変調を介して別の計画を作成できます。

573
00:33:01,020 --> 00:33:02,399


574
00:33:02,399 --> 00:33:06,179
最後に、私たちは

575
00:33:06,179 --> 00:33:10,640


576
00:33:10,640 --> 00:33:15,919


577
00:33:15,919 --> 00:33:20,840
火星のフルパートナーと対話する

578
00:33:20,840 --> 00:33:25,140
ためのソーシャルまたは共有インテリジェンスを現代に拡張する可能性について話し合いました。これで私の話はすべてです、

579
00:33:25,140 --> 00:33:28,380
聞いてくれてありがとう、これは私たちの

580
00:33:28,380 --> 00:33:31,799
協力者と調査結果、そして私たちの

581
00:33:31,799 --> 00:33:35,360
ユニットが現在募集中であることを認めます

582
00:33:35,360 --> 00:33:37,679
研究者なので、興味があるなら

583
00:33:37,679 --> 00:33:40,399
無料でチェックしてください

584
00:33:41,460 --> 00:33:43,860


585
00:33:43,860 --> 00:33:46,500
kuya さんのプレゼンテーションに感謝します

586
00:33:46,500 --> 00:33:49,140
ええと、ライブチャットからいくつかの簡単な質問と、他にも思いついたことをいくつか質問します。

587
00:33:49,140 --> 00:33:50,700


588
00:33:50,700 --> 00:33:54,360
それで Dave は、

589
00:33:54,360 --> 00:33:57,480
takuya が可塑性が失われた後にこのフレーズを使用したと言っています。

590
00:33:57,480 --> 00:33:59,399


591
00:33:59,399 --> 00:34:03,240
彼のグループがEGを修正して可塑性を増加させることができたということは確立されていますか、それとも彼は

592
00:34:03,240 --> 00:34:06,059
単に

593
00:34:06,059 --> 00:34:10,159
可塑性があることが示されたと言っているだけですか、それともええ、

594
00:34:10,918 --> 00:34:12,960


595
00:34:12,960 --> 00:34:16,320


596
00:34:16,320 --> 00:34:19,800
あなたの質問を正しく理解したかどうかわかりませんが、ええと、それらの

597
00:34:19,800 --> 00:34:23,639
グループは、えー、そのグループはドーパミンがドーパミンを追加することを示しました

598
00:34:23,639 --> 00:34:25,918


599
00:34:25,918 --> 00:34:29,879


600
00:34:29,879 --> 00:34:32,399
関連付けが

601
00:34:32,399 --> 00:34:36,359
発生してから 2 秒後には、素朴さの大きさが変化する可能性があるので、ええと、

602
00:34:36,359 --> 00:34:40,800


603
00:34:40,800 --> 00:34:42,960


604
00:34:42,960 --> 00:34:45,960


605
00:34:45,960 --> 00:34:50,280
ドーパミンがこの追加が

606
00:34:50,280 --> 00:34:54,119
この関連付けの前にあった場合、処理レベルは

607
00:34:54,119 --> 00:34:59,220
低いですが、

608
00:34:59,220 --> 00:35:02,760
関連付け後のドーパミン版として、ええと言うことができません。

609
00:35:02,760 --> 00:35:07,280
このレベルを変更すると、このようにまたはこのように可塑性が増加する可能性があるので、

610
00:35:07,280 --> 00:35:12,060


611
00:35:12,060 --> 00:35:15,859
ポストホックモジュレーション

612
00:35:16,440 --> 00:35:19,859
ツールを示しています。これでうまく答えたと思います。

613
00:35:19,859 --> 00:35:20,760


614
00:35:20,760 --> 00:35:23,040


615
00:35:23,040 --> 00:35:25,440
何に興奮しているか、オクターブ推論エコシステムがどのような状況にあるのか

616
00:35:25,440 --> 00:35:26,480


617
00:35:26,480 --> 00:35:30,839
についての希望や感情は何ですか

618
00:35:30,839 --> 00:35:33,000
そして、

619
00:35:33,000 --> 00:35:34,859
今後数か月、数年で私たちはどこに向かっているのですが、

620
00:35:34,859 --> 00:35:37,040


621
00:35:39,480 --> 00:35:41,880
申し訳ありませんが、

622
00:35:41,880 --> 00:35:45,480
またそうです、それでは、

623
00:35:45,480 --> 00:35:47,579
自分の研究の方向性以外に何に興奮していますか、

624
00:35:47,579 --> 00:35:49,619


625
00:35:49,619 --> 00:35:52,859
アクティブ推論エコシステムで何に興奮していますか、

626
00:35:52,859 --> 00:35:58,320
はい、もちろんワン・ダイレクションです。

627
00:35:58,320 --> 00:36:01,320
えー、

628
00:36:01,320 --> 00:36:06,359
社会的相互作用のモデリングなので、静的環境間の相互作用

629
00:36:06,359 --> 00:36:09,839
よりもはるかに豊かなアーキテクチャなので、

630
00:36:09,839 --> 00:36:12,480


631
00:36:12,480 --> 00:36:15,960
両方のアジアのコーランがお互いにあれば、

632
00:36:15,960 --> 00:36:19,320
えー、多くの興味深い

633
00:36:19,320 --> 00:36:21,900
現象が観察できるので、

634
00:36:21,900 --> 00:36:25,740


635
00:36:25,740 --> 00:36:29,400
ウイルスクエリを使用した現代のえー、ゾード現象に興奮しています。 この等価性による妥当性のある

636
00:36:29,400 --> 00:36:33,320
ネットワーク ニューラル ネットワーク モデル

637
00:36:33,320 --> 00:36:36,980


638
00:36:37,800 --> 00:36:39,240
素晴らしい

639
00:36:39,240 --> 00:36:43,220
最後のコメント 素晴らしい

640
00:36:46,500 --> 00:36:50,420
コメント

641
00:36:56,880 --> 00:36:58,980


642
00:36:58,980 --> 00:37:01,800
もう一度プレゼンテーションに感謝します。

643
00:37:01,800 --> 00:37:04,079
ライブ ストリーム 51 をチェックしてください。

644
00:37:04,079 --> 00:37:06,599
そこでは、あなたと私は他にも数回話して、

645
00:37:06,599 --> 00:37:09,119
いくつかの内容に踏み込みました。

646
00:37:09,119 --> 00:37:10,859
その仕事の詳細 本当にたくさんあります、

647
00:37:10,859 --> 00:37:14,000
本当に刺激的です、ありがとう、

648
00:37:15,060 --> 00:37:16,920


649
00:37:16,920 --> 00:37:18,720


650
00:37:18,720 --> 00:37:22,079
わかった、ありがとう、また今度ね、バイバイ、また今度ね、

651
00:37:22,079 --> 00:37:24,920
バイバイ

652
00:37:28,920 --> 00:37:31,920
外国人

