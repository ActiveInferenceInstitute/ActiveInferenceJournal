start	end	sentNum	speaker	confidence	text
2010	2800	1	A	0.89	All right.
4930	11754	2	A	0.99	And on to the last session of the first interval.
11882	13310	3	A	0.62267	Greetings, Nynke!
19860	20960	4	A	0.99919	Greetings.
21380	21888	5	B	0.99887	Hello.
21974	22944	6	B	0.99999	Good morning.
23142	24770	7	A	0.99989	Yes, good morning.
26580	27890	8	A	0.99967	How goes it?
29380	31370	9	B	0.9987	Yeah, I'm doing fine, thanks.
33260	36730	10	A	0.99999	Would you like to present and then we'll discuss?
38220	40184	11	B	0.99992	Yes, that sounds like a good idea.
40382	41130	12	B	0.99939	Great.
43200	44350	13	B	0.96799	Let's see.
46400	58212	14	B	0.99777	Just going to share my screenplay.
58356	59050	15	B	0.65862	Yes.
65600	67260	16	B	0.99989	Can you see the presentation?
68720	69710	17	A	0.99986	Not yet.
70240	71084	18	B	0.99531	Okay.
71282	72780	19	B	0.94678	See flex.
75120	75628	20	A	0.99355	Yes.
75714	76670	21	A	0.99983	Looks perfect.
77520	78690	22	B	0.99507	Okay, great.
81460	81920	23	B	0.96271	Yeah.
81990	82976	24	B	0.56056	Should I just start?
83078	88780	25	A	0.99982	Yeah, go for as long as you want, and then anyone can ask questions in the live chat, and I'll write down some things, too.
88870	89460	26	A	0.99498	Thank you.
89530	90550	27	B	0.5915	Okay, great.
91800	92260	28	B	0.85628	Yeah.
92330	100084	29	B	0.99	So my presentation today will be on advances in machine theory of mind and theory of mind.
100122	108244	30	B	0.99612	Sophistication I'm currently a student at the University of Amsterdam and finishing my master's thesis on this topic.
108292	122830	31	B	0.98	And I'll be giving a broad overview of current machine theory of mind and an idea or concept for an active inference approach based on previous work related to active inference theory of mind.
124160	131340	32	B	0.88	So to start okay, sorry.
133330	142180	33	B	0.64	So for a global overview, we'll start with giving a short basic definition of what theory of mind is and how it's been used.
142870	156790	34	B	0.63695	Then I'll give you a global overview of current approaches to designing machine theory of mind, including evasion approaches, approaches using Biphysical models, et cetera.
157370	166230	35	B	0.96376	Then I'll zoom into active inference models of theory of mind and social intelligence and collective intelligence more broadly.
167370	170258	36	B	1	And I'll get into the issue of theory of mind.
170284	186480	37	B	0.57746	Sophistication, which is basically the depth of recursivity of beliefs that you can have about another person's mental states and their thoughts or beliefs or goals about you.
187970	193250	38	B	0.95	And then we'll get into the issue of how to implement recursive beliefs.
193750	201170	39	B	1	And as an example, we'll discuss Bayesian theory of mind with K levels of depth.
201670	216902	40	B	1	And then we'll get into the more specific paradigm that I'm using right now to build a theory of mind model, which is based on a very simple model of the matching panning paradigm.
217046	227770	41	B	1	So we'll talk a little bit about that, and then we'll get into the model itself and current ideas for implementing theory of mind sophistication using active inference.
228770	232800	42	B	0.96	So first of all, what is theory of mind?
233170	245060	43	B	0.68992	Theory of mind has been introduced by the very famous paper by Primac and Woodcherf in 1978, I think it was called does the Chimpanzee Have a Theory of Mind?
245750	256550	44	B	1	And they define theory of mind as the ability to impute mental states to himself and others as a system of inferences.
257770	274410	45	B	1	And they say system of inferences of this kind is properly viewed as a theory, first, because such states are not directly observable, and second, because the system can be used to make predictions specifically about the behavior of other organisms.
274990	277878	46	B	1	And I think there's already a lot in this definition.
277974	302130	47	B	1	And a lot of authors looking at theory of mind right now still use the same view of theory of mind as a theory, a structured theory of different kinds of mental states such as goals, beliefs and desires that facilitate the prediction of observable behavior in other agents such as facial expressions, movement or speech.
304230	328330	48	B	0.99	And I find it very interesting how much this aligns with maybe a predictive processing view of social cognition, but also how weird it is that this theory, theory of theory of mind is still so widespread in the theory of mind literature, modeling literature.
328690	338960	49	B	0.96	So there's been some discussion on whether you can properly regard theory of mind as a theory and if so, what kind of theory it is.
339330	348130	50	B	0.98	So within the philosophy of mind, there's been basically two mainstreams or main perspectives on theory of mind.
348200	358090	51	B	0.99779	According to the classic theory, theory of Tom, theory of mind is a causal theory of how these internal mental states generate other agents'behaviors.
358190	361560	52	B	0.74	So it's the same kind of view that we just saw.
362890	380400	53	B	1	And then the opposite side is called simulation theory of theory of mind, which posits that we use the same kind of cognitive and neurological resources for understanding and predicting other agents as those that we use for understanding the self.
380770	383882	54	B	1	And simulation theory can also take on different forms.
384026	386334	55	B	0.94	The sun is coming up next to them.
386372	390320	56	B	0.6	So that's why I'm based in light at the moment.
391170	394034	57	B	0.99853	But basically there are lots of versions of this.
394072	398980	58	B	0.99836	Some posit that we use the same kind of action prediction mechanisms for ourselves as for others.
399670	414194	59	B	1	And there is this new version of simulation theory that Gordon proposes in 2021 which very broadly says that we have the same kind of theory for other agents for ourselves.
414242	424490	60	B	0.87	So there's this general theory for what it means to be an agent that is refined at different stages to facilitate context sensitive predictions in social interactions.
428030	436670	61	B	0.78	So this is also interesting to look at when you model theory of mind, what you think theory of mind is and how it is specifically implemented.
437250	443018	62	B	1	So why would we be interested in creating computational models of theory of mind?
443204	449138	63	B	1	So I think there are three important reasons why this is very relevant at the moment.
449224	454130	64	B	1	First of all, there is a technical reason or the reason of technological advancement.
454810	466230	65	B	0.79153	There's been some proposals that argue for the development of artificial social intelligence.
466830	469420	66	B	0.77	Oh wait, yes.
469870	489550	67	B	1	So the technical reason for developing computational models of theory of mind is to improve artificial social intelligence, especially as we start to live in a world in which research on human AI interaction becomes more relevant.
490930	511670	68	B	0.99	And that's been this paper Bob Williams, for example, that's argued that improving artificial social intelligence is needed for successful AI human cooperation and it could improve communication, trust and maybe also value alignment.
513050	516126	69	B	0.99998	By utilizing theory of mind for value alignment.
516178	532160	70	B	0.97	For example, there is a very strong foundational reason to study social cognition generally and the evolution of social cognition through in silica hypothesis testing and clarifying the conceptual boundaries of theory of mind.
533890	550850	71	B	1	One great example for this is research by Devane ETL, which used a computational model of recursive theory of mind compared to alternative models to study different cognitive strategies in non human primates.
551910	562870	72	B	1	And they find no evidence for the hypothesis that theory of mind sophistication involved with an increase in herd size, but they do find a correlation with, for example, neocortex ratio.
564010	571130	73	B	1	So in this way, theory of mind models can give us some insight into the evolution of social cognition.
571950	595490	74	B	1	On the clinical side, theory of mind models can be used to understand relevant social variations in clinical populations, for example, through computational phenotyping and diagnostics and by studying social behavior in groups that have some difficulty with social interactions.
596630	610470	75	B	1	And groups that show some kind of variation in social cognition, such as people with autism spectrum, people in the autistic spectrum, people with ADHD or schizophrenia.
610970	620474	76	B	1	So I hope that with some of these reasons, I convinced you that modeling theory of mind is very relevant at the moment.
620672	623260	77	B	0.97	And there have been a lot of people already on this.
624270	639870	78	B	0.66	And I've created this very global overview of some approaches that are representative or some models that are representative of their more general approaches.
641590	658390	79	B	0.8045	There's this brain Tom model which aims to basically build up clear mind abilities and abilities facilitating social interaction from the bottom up using Biphysical models of neural firings.
659850	662450	80	B	0.92617	That's why I've placed it on the dynamic scale.
662530	683470	81	B	0.97	So I've tried to align these modeling approaches along the axes of how they treat time, how broad their description is from the individual level to maybe describing more broader social and cultural processes and along the level of description from the molecular biophysical to the behavioral.
684450	703890	82	B	1	And one thing you can see is that there is a lot of work based on invasion inference and active inference that moves along that has relevant ties to the molecular and neurobiological level but moves along the lines of making behavioral and cognitive predictions.
705050	716040	83	B	1	And there are very little models that really also formalize the concrete implementation of theory of mind.
716990	733366	84	B	0.96	And there is also, I think, this need for connecting this dynamic implementational level to individual level social cognition and putting that in the context of social interaction more generally.
733558	748594	85	B	0.99	So some of the representational approaches that I selected are the TOMNET, which basically uses neural network embeddings to train reinforcement learning agents.
748792	764562	86	B	0.99947	We have Ktom, which is a Bayesian recursive model which I'll come back to later, some or theory of mind with self other modeling uses multiagent reinforcement learning with goal inference.
764706	778540	87	B	1	And we have the more theoretical active inference model of implicit cultural learning called thinking through other minds, which could be seen as an alternative or a redefinition of theory of mind.
781250	793300	88	B	0.62778	Okay, so to sum up, we have this stream of biophysical models, most notably Brain Tom, which was developed by Zhao et al.
793990	821290	89	B	1	And its strengths are its neurobiological plausibility at making dynamic predictions about neural activation in populations that are associated with theory of mind abilities and its weaknesses is that it's quite computational and costly and it's probably difficult to implement in an interactional setting.
823550	839550	90	B	0.86089	There are some deep learning models such as Tomnets by Rabinovitz and Self other modeling which I just mentioned that are also quite neurobiologically plausible and also make some dynamic predictions.
840210	874618	91	B	1	But there is this strong danger of shortcuts, which has been addressed in deep learning models, that the task might not be solved by learning the relevant ability of being able to infer another agent's goals or beliefs, but just by learning simple lower level associations between, for example, the perspective or how another agent stands and where, for example, a food reward would be.
874704	888270	92	B	1	So there are a lot of ways to solve the task and there's this finding that deep learning models sometimes use these kinds of shortcuts so that's something that's needed to be addressed.
889570	905222	93	B	0.9995	Then there are some Bayesian belief based models such as K Tom for Recursive theory of Mind and Beijing Tom which was originally developed by Baker et al.
905276	929600	94	B	0.99959	In 2011 and its strengths are that it's quite efficient, it's very easy to interpret and its weaknesses are that the road to the implementational level is longer and it requires many priors and there's this question about whether it's scalable because of the prior specifications that you have to give.
932450	944100	95	B	0.9958	Okay, so as one of the I think the interesting newer developments on a theory of mind wait, yes.
946630	959878	96	B	0.95248	Is Hierarchical active Inference for collaborative agents which has been recently published and Haika is based on the Asian theory of mine by Baker et al.
960044	983790	97	B	0.99992	But it adds this formalization of belief resonance which is the incorporation of beliefs about another's intentions with top down predictions and this influence of these other agents beliefs are modulated by susceptibility parameter which controls this influence.
985170	996340	98	B	0.99	And what I find I think it's important to note here that they use an approach based on active inference but they don't use the free energy principle for example.
997510	1002702	99	B	1	So they do couple perception and action but just in a different way using a karma filter.
1002766	1014150	100	B	1	So the way they formalize this is slightly different but I think the overall structure can still be informing or inspiring for active inference methods.
1015950	1034720	101	B	0.97	So what is interesting about their simulation results is that they show that agent that there is some emergent collaboration on tasks for low values of the susceptibility parameter without any explicit planning or communication needed.
1035250	1055750	102	B	0.98	And this means that they improve upon the original Bayesian model, which explored different sort of overall plans for all of the agents, which means that an agent employing Bayesian Tom would need to reason about the roles of all of the other agents, which was very costly.
1056170	1065640	103	B	0.98	And the authors wanted to improve on that to model maybe on the fly coordination, which is more spontaneous and takes less time.
1066650	1073980	104	B	1	And they also show that incorporating belief resonance has a very positive effect in scenarios in which there's unbalanced information.
1074750	1084720	105	B	0.99995	They did this simulation, the overcooked domain in which agents have to collaborate on different cooking tasks and the goal is basically the order, the cooking order.
1085170	1089920	106	B	0.97	And then the intention would be any kind of action that has to do with completing the order.
1090930	1103650	107	B	1	And they show that incorporating the leaf resonance seems to be especially useful in situations with unbalanced information which, for example, one agent knows the order and the other doesn't.
1104170	1120650	108	B	0.93	And these agents develop some kind of leader follower dynamic in which one is more susceptible to the other agent's intentions and one agent attends more to the evidence from the environment.
1121390	1133870	109	B	1	And this also aligns with what we know about your mind mainly being employed in situations in which there is some asymmetry in what the agents know about the environment.
1134210	1137230	110	B	1	So I thought that was very insightful.
1141090	1152260	111	B	0.99589	Okay, so I'm going to go into some active inference approaches that I think are relevant for developing active inference theory of mind.
1152630	1166742	112	B	1	First of all, there's this very broad proposal on inculturation and non development thinking for other minds, a variational approach to cognition and culture, which we'll go into a little bit.
1166876	1175610	113	B	0.74903	We'll go into Castle and HAF's paper on ideas for spreading a free energy proposal for cumulative cultural dynamics.
1176510	1178658	114	B	0.50214	We'll go into Kaufman et al's.
1178694	1186990	115	B	0.98972	Model on collective intelligence and finally also the proposal by Mutusis et al.
1187060	1190080	116	B	1	On Beijing inferences about the self and others.
1193100	1207900	117	B	0.62314	Okay, so first of all, I am starting with beta inference about the self and others because it gives a very sort of broad introduction to, I think, predictive social cognition.
1208320	1234340	118	B	1	And that's also why I've added this figure on the right that is from the Tam Thoughts and paper in 2018, which explores the predictive social brain and what kind of features seem to be relevant for categorizing and understanding others behaviors.
1236920	1254644	119	B	0.89866	Some figure on the right, you see that there is this space, this trade space, which is ordered by power, sociality and balance, and that constraints the state space which seems to be ordered by rationality, social impact and balance.
1254772	1261340	120	B	0.87	Of course, these are just correlations, but these futures seem to be most predictive of what they're seeing in the brain.
1262560	1276480	121	B	0.97	And you can see that there is this sort of basically a very strong top down constraint of the possibility space in which you interpret other people's actions.
1277060	1289252	122	B	1	And you can also see that based on another agent's actions, you learn something about where they fall within that space in a given context and also where they fall in that trade space.
1289306	1300104	123	B	0.64476	What kind of so at the same time, you might have already have some priorities on what kind of a person this is, but you're also learning about it.
1300302	1308472	124	B	0.76	You might also have some priors on how someone behaves when they're mad, for example, or when they're sociable versus unsociable.
1308616	1311384	125	B	0.99	And all these kinds of priors informative priors.
1311432	1321440	126	B	0.82276	They inform your predictions in the context, and they make this task much more manageable of predicting other people's behaviors on the fly.
1322740	1343130	127	B	0.98	And I think that links very well back to Mutuses proposal, which is basically that inferences about the self and others at different timescales facilitates interpersonal minimization of surprise and thereby optimal social decision making.
1346460	1363260	128	B	0.92	And these self and other representations that facilitate personal minimization of surprise could be seen as representations that inform our inferences and predictions on the fly.
1366720	1384064	129	B	1	I think it's also important to mention that one of the main key points of their paper is that self representation, so beliefs about how beliefs about the self can facilitate interpersonal minimization of surprise.
1384112	1399080	130	B	0.99	So even what I think about me and how I represent that, while communicating, will facilitate the other person's optimal decision making at that moment, maybe by providing the right kind of information that they need to optimize.
1400140	1409032	131	B	0.84803	Okay, so to the next two interesting papers, ideas Worth spreading and an active inference model of collective intelligence.
1409176	1417580	132	B	0.99	So the key idea, I think, for both of these papers is the emergence of group behaviors from local interactions.
1417920	1427840	133	B	0.98	For Caston Hess, this is the global group behaviors cultural transmission or transmission of beliefs and norms.
1428180	1434980	134	B	0.99	And they describe this process as the mutual achievement of actively inferring agents through communication.
1435400	1442128	135	B	0.65	And theory of mind is one of the many mechanisms that facilitate this process of achievement.
1442304	1443590	136	B	1	So that's the link.
1444040	1458680	137	B	1	And they show that the spread of certain kinds of beliefs through a group can be modeled just by making agents interact in diadic groups and stimuli.
1459100	1460116	138	B	0.20566	Kaufman et al.
1460158	1486230	139	B	0.98951	Show that you can create a system of free energy minimizing agents with some minimal properties of social intelligence, such as the ability to assess how self similar another agent is to themselves, the ability to infer another agent's intentions, and the ability to align their goals to another agent, more or less.
1486760	1498520	140	B	1	And they show that if you put all of these agents together in those diets, they don't only minimize free energy on the dietic scale, but they also minimize free energy as a collective.
1499500	1515580	141	B	1	And thereby, this is a very simple model of how adaptive behaviors, group adaptive group behaviors, could emerge from agents with very simple social abilities.
1530020	1557240	142	B	0.98827	Okay, so now we get to thinking through other minds, which is not technically a proposal for theory of mind, but it's a proposal for how social cognition shapes inculturation more generally and what kind of abilities agents need to facilitate this kind of normation.
1559340	1572060	143	B	1	And I think it's a very interesting proposal because I think it highlights an important function of social behavior more generally.
1572720	1581680	144	B	1	And you could even see it as a way to redefine theory of mind as more of an interactional concept than as an individual level cognitive ability.
1583220	1596260	145	B	1	So, according to this proposal, thinking through other minds is a property of multiple interacting minimizing agents and a process by which agents infer other agents expectations.
1596840	1613160	146	B	1	And based on this, the authors propose a definition of enculturation as a process of learning social expectations through the selective patterning of attention that guides agents towards relevant affordances within their social and cultural niche.
1614460	1621532	147	B	0.99891	I'm not sure if you're all familiar with the concept of affordances but it was quite hyped up a couple of years ago.
1621586	1633272	148	B	0.88797	In general it is defined as relational construct denoting possibilities for action offered by an environment that are code determined also by an agent's interest, goals and abilities.
1633416	1647140	149	B	0.97	So I think that the standard example for this is when you are thirsty, a glass of water might appear as an affordance or you might not consciously or might also tend to it otherwise.
1647960	1653540	150	B	0.69	And cultural affordances in this sense are epistemic affordances.
1654360	1663160	151	B	0.72	So affordances that give you some epistemic value that have come to stand out as reliable and relevant based on a history of culture information they encode.
1663580	1668300	152	B	1	And good examples for this are different kinds of signs of traffic signs.
1668720	1683520	153	B	0.99976	We learn what they mean from a young age and we sort of inherited the symbolism of the traffic signs and they guide our intention towards points in traffic and they regulate our behaviors.
1685940	1705248	154	B	1	So when you look at the complete proposal, it sketches how the regulation of social behavior depends on the learning of shared norms and expectations and also how this connects to utilizing cultural affordances and thinking through other minds.
1705424	1717070	155	B	0.59957	As this profits interactional processing, in which agents learn to infer each other's expectations to optimize collective behavior and decision making.
1718480	1726524	156	B	0.98787	Okay, so from these interesting active inference and broader proposals of fear of mind we get to the issue of form.
1726562	1730544	157	B	0.54528	Sophistication in active inference so what is fear of mind?
1730582	1739312	158	B	0.99842	Sophistication a short recap it's the depth of reclusivity that can be utilized for fear of mind of the form.
1739366	1765640	159	B	1	I think that they think that I think, and it has been found that agents generally use a reclusivity of between zero and four and that humans, humans ability for recursive belief reasoning is generally limiting but in principle, formally this could go on forever.
1767120	1780430	160	B	0.96	And one way to implement this kind of sort of arbitrarily recursive belief inference is proposed by Vada et al.
1781200	1796148	161	B	0.9162	Uses a Bayesian model of sophisticated theory of minds with Ktom agents and provides simulations in which K tom agents play against agents that are just one level of recursivity under them.
1796234	1802352	162	B	0.98	And this model has been used for a lot of interesting simulation experiments.
1802416	1803190	163	B	1	For example.
1804380	1830690	164	B	0.30271	Devane Et Al Showed that in a trade based analysis but with agents having a fixed depth of theory of mind reclusivity there is a specific distribution of agents with level one tom and level two tom that could provide an evolutionary advantage compared to populations with larger proportions of serotonin three tom agents.
1831140	1843220	165	B	1	So they look at the adaptive properties of systems with different kinds of ratios of theory of my sophistication.
1844600	1857184	166	B	0.99	And in another experiment, which is a state based analysis for Joe et al.
1857242	1874380	167	B	0.73013	Showed that if you use computational phenotyping on autistic individuals, this shows reduced sensitivity to task framing and strategy switching within the game that they'll be using and theoretical line sophistication.
1876640	1883100	168	B	1	So these are just some interesting applications for theoretical mind sophistication.
1883760	1898416	169	B	1	And the promise of modeling theoretical mind sophistication would be that you could investigate how people flexibly switch between different social strategies while solving a social task.
1898608	1909172	170	B	1	And one of them would be to increase the depth of fear of my sophistication or decrease it depending also on what you think about the other agent's.
1909236	1910360	171	B	0.94452	Sophistication.
1914140	1921870	172	B	1	So what I've been working on at the moment is an active inference model of social prediction during the Matching pennies game.
1924080	1933132	173	B	1	The matching pennies game is a game farm economics with a very simple format.
1933196	1934076	174	B	0.99994	There are two rules.
1934108	1936044	175	B	0.81	You have the guesser and the challenger.
1936172	1939744	176	B	1	The challenger hides a penny in one of the two hands.
1939942	1948656	177	B	1	The guesser needs to guess which hand, if the guesser is correct, they win, if the guesser is wrong, be challenger wins.
1948848	1952580	178	B	0.99982	This game has some logical equivalents.
1953800	1958964	179	B	1	One version of the game makes both of the agents select heads or tails.
1959012	1964708	180	B	0.59	So the challenger selects heads or tails and the getter guesses the tests or tails.
1964884	1967820	181	B	0.98796	But both have the same formal structure.
1968640	1977788	182	B	0.93	And psychological experiments of subjects performing this task have shown that there is a strong social framing effect in the Matching Pennies game.
1977874	1988050	183	B	0.93	So participants will behave and perform differently depending on whether they're seeing that they're playing against a human agent versus an AI for example.
1990980	2007876	184	B	0.8506	Additionally, a comparison of Ketone and other computational strategies that were fitted on experimental data of subjects playing the game revealed that participants seem to use fear of mind when playing the game.
2007978	2023180	185	B	0.99	So there is a strong indication that theory of mind use does play a role in the Matching pennies game and that social framing will influence the social strategy that's being employed by the players.
2025440	2031744	186	B	1	So this is the very simple zero sum architecture for the Matching pennies game.
2031942	2049510	187	B	1	And I included beliefs about self choices as also kind of monetary self states beliefs about other agents choices on whether the agent thinks the opposing agent has hidden the penny left or right.
2050040	2053140	188	B	0.56	And then the agent also tracks the war dates.
2055020	2072670	189	B	0.99942	Since the game in this setting is devised in a way in which the agents both make an observation simultaneously and then all of the observations are revealed, this set up made sense so just going to drink a little water.
2078260	2095108	190	B	1	The outcome modalities or observations that the agents have are its own choice observations, the choice observations of the opposite agent and the reward observations and the possibility the action space is very limited.
2095284	2112750	191	B	0.9	The seeker can choose to seek left or right and the hider which is the same as the challenger before, has the possibility of hiding penny left or right and the reward is uncontrollable since it depends on both agents choices at the same time.
2116240	2116556	192	B	0.92201	Yeah.
2116578	2129628	193	B	0.73	So this is sort of a summary of the architecture that I just described and this is another visualization of this setup.
2129724	2141780	194	B	0.99	And you can see here that if you look at the likelihoods the reward mapping for the seeker is just the opposite as for the hider.
2142920	2155160	195	B	1	And I think that this simple setup is very suited for studying fear of mind in these kinds of simple competitive interactions.
2157600	2182772	196	B	0.9443	Okay, so if you wanted to study the use of theoretical bind sophistication in the matching penny scheme using active inference, I ran into a couple of challenges and one of them was how to steer the problem of recurring s.
2182906	2189110	197	B	1	So how can we make a difference between the focal agent and the other agents?
2189960	2204504	198	B	0.99995	If we try to model the other agents within one agent, especially if you want to introduce or formalize desperate cave reclusivity, you can't just make one agent simulate the other agent simulating their self.
2204622	2221330	199	B	0.89402	There needs to be some kind of sort of structure that distinguishes the self inferential mechanism, a self learning mechanism from what the agent focal agent thinks the other agent is thinking and seeing and doing.
2222340	2229728	200	B	1	And I think the gentleman with the bowler hat by firster in 2003 is a good example for this problem.
2229814	2244624	201	B	0.55	So the basic setting is that our world is populated by beings like ourselves experiencing themselves as a subject, as the focal point of their world, with their own thoughts and feelings.
2244672	2248600	202	B	1	And they all think that they're the one and only subject.
2250780	2252344	203	B	0.99994	But there can't all be.
2252382	2259100	204	B	1	So there needs to be sort of either an outside focal point or one ultimate main subject.
2261600	2281890	205	B	0.98	I think more practically, the questions that arise from this example are how do we distinguish between focal agents and simulated agents and how can we simulate other agents in a way that is computationally efficient and maybe uses the same kinds of resources that the agent already has?
2287120	2304736	206	B	1	So I actually had a lab meeting at the Theoretical Neurobiology Lab a while ago and we were brainstorming about this issue and one of the ideas that came up was to use sophisticated inference for period mind.
2304918	2312870	207	B	1	So in this case, an active inference formulation of belief recursivity could be used for modeling recursive period, line.
2315960	2343790	208	B	0.99992	Basically, serious planning using predictions about the other agents into account would consist of evaluating all the kinds of hypothetical scenarios, all kinds of counterfactuals on how your actions might influence their beliefs and their actions and so on and so on.
2345440	2347980	209	B	1	So this would be one road to go into.
2348050	2353440	210	B	0.99999	But this would also mean that all these counterfeituals would need to be evaluated.
2353860	2367060	211	B	1	So I was thinking is there a sort of more efficient way to sort of use these kinds of either internal simulations or kind of special evaluation?
2368680	2378276	212	B	1	And the current approach I'm working on, which I'm also sort of still developing.
2378308	2388910	213	B	0.79	So I'm very much open to feedback and comments on how this could work and possible alternative approaches at this point.
2389600	2398188	214	B	0.99997	But the general idea would be to create a partial internal simulation of the other agent's control mechanism.
2398364	2442750	215	B	0.97	So taking the learning mechanism of an active inference agent as sort of the definition of what the focal agent is, that is the agent that perceives and learns and infers from the environment and what the agent does when predicting the observations of the other agent or the predicting the other agent's behavior is basically performing partial simulation about what it thinks the other agent preferences are and what it thinks that the other agent strategy is, which is encoded by the transition from state to state.
2445120	2459860	216	B	1	And one of the potential ways in which you could include reclusivity in this way is that you pretend that you have control over the other agent's actions and you predict the other states.
2459930	2486300	217	B	1	You predict self states, you evaluate the state action probabilities, choose the most valuable action based on that distribution, simulate the other states that come forth and simulate the self states that come forth.
2487040	2497730	218	B	0.97	And then you have a new and then this can be used for the next round of action selection by the other model.
2498580	2512230	219	B	1	So in this case, only the per preferences and the agent specific transition probabilities would be needed as sort of information on the other agent.
2512760	2525860	220	B	1	And because you also want to include some kind of learning about the other agent strategies, one of the things you could implement would be learning also the Bay metrics.
2526380	2544220	221	B	0.99	So having sort of the specific having the agents accumulate as evidence about these state transitions over time to also better predict the other agents potential actions.
2546420	2570032	222	B	0.87	The basic principle would be to simulate control from the perspective of the other agents and the recusivity comes into play when you simulate the other when you've already simulated the others predicted actions and predicted other states and you've simulated your own actions as a consequence of those simulated actions.
2570176	2582010	223	B	1	You can feed that back into the other model to predict what they would do if they thought that you were in the state that you were in.
2583100	2598850	224	B	0.94	And I think that could be a way to develop repressivity in a way that does not need complete simulations of parallel agents within the same system.
2600340	2617540	225	B	1	And of course there should be some kind of temporal discounting subparameter that discounts evidence based on the simulated planning horizon that is defined by the K number of steps.
2618600	2645260	226	B	1	So yeah, this is sort of a conceptual outline of how you could implement because the fear of mind using active inference we haven't been able to perform simulations using this yet, but we're working on that and we're very much open to discussions on this and technical comments on how to improve on this outline.
2646640	2657536	227	B	1	And one of sort of the open questions that we are still thinking about is how to make the agent effectively infer the depth of reclusivity of the other agent in.
2657558	2658480	228	B	0.89	A setting.
2659080	2659492	229	B	0.52436	Yeah.
2659546	2670470	230	B	0.99418	Special thanks to Guillaume Dumas, who will also be there at a panel, I think, in session two, who's supervising me during this project.
2671080	2691420	231	B	0.84646	Thanks to the PPSP labor, I'm doing my internship to Rudy Said, who's also working on a related project, the Pi MDP team, for that great coding package that I'm using, and for Kofristen for his feedback and ideas on my previous presentations.
2696200	2697940	232	B	0.99993	Thank you very much for listening.
2699580	2700330	233	B	0.57164	Cool.
2702140	2703620	234	A	0.99984	Great presentation.
2703780	2712970	235	A	0.99995	Very comprehensive review of a lot of the different theory of mind options out there.
2714560	2719000	236	A	0.99957	Well, if anyone has questions, they can write it in live chat.
2719160	2720680	237	A	0.99998	What do you want to explore?
2720760	2724770	238	A	1	Or can I ask a question or what would be fun for you?
2728740	2735040	239	B	0.55085	I'm blinded by the light at this point, so I can't easily read from my screen.
2735110	2741484	240	B	1	So maybe it would be nice if you could read out the questions that are the live chat.
2741612	2741904	241	B	0.76448	Sure.
2741942	2743030	242	A	0.85	Oh, yeah, sure.
2743640	2753288	243	A	0.99909	Well, first one part I found interesting, you mentioned that people play differently when they are playing a human or when they believe that they're playing a human.
2753454	2757240	244	A	1	So what is that like?
2757390	2764350	245	A	0.99999	What is the difference in play when we believe that we're playing another person?
2775920	2808820	246	B	0.91809	If I look at the original paper, there is one study on this, and then they did the computational phenotyping study using Ktom and alternative strategies, and they showed that if you use the social framing condition, that subjects will more probably employ figure five strategies compared to other simple reward based strategies.
2809160	2814100	247	B	1	So maybe those strategies could better be described using some kind of reward learning mechanism.
2816140	2822490	248	B	0.95682	What the difference in their overall sort of trajectory of choices is, I don't know.
2825740	2826116	249	A	0.97007	Yeah.
2826158	2831912	250	A	0.7	A few themes then that you brought up that came up earlier in the session.
2831976	2839984	251	A	0.99	So one was using Pymdp and sophisticated inference, which Aspen Paul gave a walkthrough on.
2840182	2862980	252	A	0.98	And this question about recursivity and about the way in which you can on one hand talk about abstractly like K Recursivity, yet the biological system doesn't implement that kind of a logic.
2864360	2866328	253	A	0.78707	Could you maybe describe a little bit again?
2866414	2881150	254	A	0.99998	How does the structure that you laid out for the generative model capture some of those features of recursivity without falling into the trap of just theory of mind all the way down?
2883360	2883724	255	B	0.72044	Yes.
2883762	2904580	256	B	0.9	So my general idea was to simulate the other agent's action prediction based on learning about the transition probabilities for what we think how the other agents face transition.
2905960	2920250	257	B	1	And then if you've predicted what the other agent would do, you can use that as a prior for calculating action dependent expected states.
2921340	2928620	258	B	1	And based on those evaluating those expected states, you simulate your own choice mechanism.
2930560	2940720	259	B	1	And I think in principle, you could use this recursive simulation indefinitely.
2942820	2956450	260	B	0.99984	But also, it's also devised in a way that it uses the same kind of sort of just the architecture of the focal agent.
2956820	2976176	261	B	1	So the other idea was to just use internal simulations all the way down and but that would be very cognitively implausible and yeah, I think it's a very good question, because why would you even need to formalize belief?
2976228	2977996	262	B	0.88322	reclusivity all the way down.
2978098	3000400	263	B	0.86467	If in end effect, people only use tom with a set sort of maximal depth and the fact that we use fear of mind with a maximum depth might also be sort of a hint that he might also use a different or what we do might also be described by a different strategy.
3003060	3006230	264	B	0.93	So yeah, I'm not sure if that's an answer to your question.
3008440	3032344	265	A	0.99914	Yeah, well when I saw this and some of the other generative models you mentioned maybe here like you pretend like you can control the other person's mind and that's kind of the fundamental weaving of action into the inference challenge and then that uses expected free energy just like any other policy selection.
3032472	3053488	266	A	1	So it's like pragmatic value would be bringing that controllable state your social partner's mind or beliefs bringing them into alignment with your preferences is pragmatic and then learning more about them is epistemic.
3053664	3069672	267	A	1	And so then that might enable some theory of mind like behavior where it's like when you don't know enough to put the squeeze on then you have a kind of open ended learning and curiosity and question driven theory of mind.
3069806	3094640	268	A	0.99998	But then once one has enough to kind of exploit rather than explore then without necessarily even updating the model or engaging any deeper recursivity or strategic shifting you could get social behavior that's oriented towards control and pragmatic value rather than just like learning and questioning.
3096740	3098832	269	B	0.99994	Yeah, I think you're very right.
3098966	3120950	270	B	1	The idea was also to enable the agent to maybe first use strategies that are more useful in gathering evidence about the kinds of strategies that the other agent is using before exploiting thing what you've learned about the other agent and.
