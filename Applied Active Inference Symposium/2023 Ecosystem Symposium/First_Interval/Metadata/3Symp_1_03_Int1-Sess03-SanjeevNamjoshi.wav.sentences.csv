start	end	sentNum	speaker	confidence	text
410	17710	1	A	0.79	All right, the next presentation is by Sanjeev Namjoshi, and this presentation is going to be called developing next gen Active Inference Tools, broadening Accessibility, Educational Resources, and the Software Ecosystem.
22440	28470	2	A	0.60583	I'm going to start this talk right now.
32720	35612	3	B	1.0	Hello everyone, and thank you for being here.
35746	37768	4	B	0.99997	My name is Sanjeev Namjoshi.
37864	38796	5	A	0.95545	I'm just going to restart it.
38818	40876	6	B	0.54832	Machine learning engineer working at the AI.
40908	43680	7	A	1.0	Services firm just because it's a little quiet.
47310	49500	8	A	0.94	All right, restarting the talk.
56140	58972	9	B	1.0	Hello everyone, and thank you for being here.
59106	69840	10	B	0.99999	My name is Sanjeev Namjoshi, and I'm a machine learning engineer working at the AI services firm Kung Fu AI, where I primarily focus on computer vision projects.
70340	80240	11	B	1.0	Today I'm going to be talking to you about my progress toward providing greater accessibility, visibility, and knowledge of active inference and the free energy principle.
80820	94696	12	B	0.87714	I'm excited to be presenting this material at the active inference symposium this year because the idea of an enacted ecosystem of shared intelligence perfectly captures the philosophy that underlies the projects I'm currently engaged with.
94878	109820	13	B	0.99549	I've spent the last seven months on sabbatical for my job to work exclusively on an active inference textbook and related tools, presenting chapter presentations, code reviews, and receiving feedback weekly at the active inference institute.
110640	119096	14	B	1.0	The institute has provided a space where interdisciplinary research can flourish as the connections and influences of active inference spread to other fields.
119208	125872	15	B	1.0	It has consistently fostered the spirit of collaboration and shared intelligence that I wish to embody in my own work.
125926	134980	16	B	1.0	As part of this ecosystem, I intend to continue closely working with the Institute to provide materials that will bring active inference to a much wider readership.
135480	152440	17	B	0.71	I originally chose this project when I saw the great potential in the active inference field and couldn't help but make a comparison to the state of deep learning in 2006, when neural networks were one of just many possible models rather than the dominant choice in academia and in industry.
153660	164430	18	B	1.0	This, of course, all changed in 2006 when Hinton and his colleagues released the Deep Belief Network paper, which is generally understood as the start of deep learning as we understand it today.
165040	175810	19	B	1.0	After some hardware innovations and the release of the Wellknown ImageNet Library, we started to see coverage and success of AI in the news as well as in academic research.
176260	186500	20	B	0.99997	But in 2012, deep learning truly provided its value with AlexNet, and for the first time, deep learning achieved better than human performance on image detection tasks.
188440	189892	21	B	0.99978	But this was just the start.
190026	194468	22	B	0.61794	What followed was a proliferation of deep learning all across industry and research.
194634	203370	23	B	0.7947	I've added in some Wellknown milestones just to highlight the explosion of progress in deep learning in the last decade, though there is so much more here that we could discuss.
203900	206644	24	B	0.99994	So what about the state of active inference as a field?
206782	211260	25	B	0.98303	From my perspective, active inference lies in the same position as deep learning.
211330	229280	26	B	1.0	In 2006, influential and on the brink of exploding in popularity, this paper which is from contributors at the Active Inference Institute, shows the current growth of publications in the institute and its community in active inference.
229620	234820	27	B	1.0	In the last three years, the active inference field has seen a number of important milestones.
235560	239876	28	B	0.99998	Here I show just a few that broaden the scope and attention to the field.
240058	244196	29	B	0.99999	We had the first International workshop on Active Inference in 2020.
244378	249924	30	B	0.99999	We had the first active inference symposium and the founding of the active inference institute.
250052	252090	31	B	1.0	Then called the active inference lab.
252700	269760	32	B	0.99999	We had the release of the Par at all 2022 textbook and the Pymdp Python package, and I see myself now as perfectly poised to bring active inference to greater visibility and attention.
270180	280348	33	B	0.99999	This is in part because of the current academic interest in deep reinforcement learning and generative modeling working alongside the institution and other organizations.
280444	292340	34	B	0.99669	My aim here is to provide some of the fundamental materials to capture the attention and notice of machine learning researchers and students to bridge this gap to bring active inference into its renaissance.
295000	302120	35	B	1.0	To this end, I've been working for the past seven months on Sabbatical to finish work on a comprehensive textbook.
302620	320620	36	B	1.0	The aim of the textbook is to provide the tools to bring active inference to a wider audience, primarily those in machine learning research and applied fields such as robotics, and to decrease the challenge in learning the material largely by separating it from much of the neuroscience background that is usually a prerequisite.
321600	337940	37	B	0.64146	This decrease in prerequisites means labs will have to spend less time helping students becoming acquainted with the field, and researchers outside of neuroscience will find this book an accessible entry point that uses terminology familiar to machine learning rather than neuroscience and fMRI image analysis.
338920	342980	38	B	1.0	All derivations are in one place currently in the field.
343050	353320	39	B	1.0	Many derivations are spread across different papers, even behavioral papers instead of just technical ones, and it's hard to know where to look if you want to understand a particular equation or concept.
354620	363660	40	B	0.99999	Part of the success of deep learning in the last decade has come directly from focusing on narrow improvements to specific aspects of the modeling.
364000	374880	41	B	0.9996	There are many open questions in areas of research, such as how to prune policy trees, exploring second order optimization rules for state and parameter updates, and scaling active inference.
375620	385060	42	B	1.0	The increased accessibility for researchers would also lead to many new industry applications, such as autonomous vehicles, robotics, video game design, and AI.
385880	395880	43	B	1.0	The textbook would also put a spotlight on Bayesian mechanics and invite contributors and contributions from researchers as this exciting nascent field grows and develops.
397420	408424	44	B	1.0	Part Four is largely a literature review and can be very helpful to those writing about active inference from fields such as philosophy, psychology, sociology, and many others.
408622	425490	45	B	1.0	And the historical context sections that are part of this book provide a lot of that context, as Active Inference is built upon decades of research in neuroscience, psychology, and many other fields, and also draws upon current work in many fields that have emerged in the last 25 to 30 years.
426740	435190	46	B	0.99998	Finally, LaTech reproducibility may offer interesting ways to rearrange the book and integrate it with the code for an online only experience.
439960	444868	47	B	0.97	Now I'd like to share with you some of the progress of my textbook and the general structure.
445044	447748	48	B	0.73	The textbook is divided into four parts.
447924	451860	49	B	1.0	The first part introduces fundamental concepts to set the stage.
452020	463900	50	B	1.0	In particular, I have focused here on presenting wellknown statistical ideas from the perspective of an agent modeling its environment, who states it must infer from an observed noisy signal.
464720	476720	51	B	1.0	The second part focuses on continuous and discrete state space formulations of active inference, where the algorithm of focus for the continuous state space formulation is active generalized filtering.
477140	488420	52	B	0.99999	Part three, which I'll begin writing in a couple of months, focuses on a sketch of Bayesian mechanics and the required background designed with the knowledge this field is still dynamically, changing and evolving.
488920	500280	53	B	0.99997	Here I will focus on some of the fundamental concepts and ideas, as well as code simulations to allow readers to get a deeper and more intuitive understanding of some of these challenging ideas.
501020	510348	54	B	0.99997	Finally, part four is a systematic literature review that covers all the various applications and extensions to active inference that have been innovated in the last six to eight years.
510514	519650	55	B	0.99998	These applications include things like robotics, all the behavioral modeling and neuropsychiatry, and human and animal behavior, theory of mind, and so on.
520660	535350	56	B	1.0	The extensions talk about how applications of active inference can be used to talk about dynamic systems more generally, and apply to things like ecosystems and to economies and other types of things like governance, and so on.
536840	544920	57	B	0.99997	As of this week, the rough drafts of part one and two are complete, and ten chapters have been presented to the Active Inference Institute.
545740	551640	58	B	1.0	In support of this textbook are four separate tools that I will discuss over the next few slides.
553260	560620	59	B	0.9994	But before I do that, I would like to first highlight some special aspects and features of my approach to this textbook.
564400	571948	60	B	1.0	The major focus is on writing this book for a machine learning audience or students learning in this and adjacent areas.
572124	574736	61	B	0.84928	Neuroscience is out of scope for this book.
574918	586500	62	B	0.60776	Many of the recommended and even optional prerequisites that are shown here are typically known by undergraduate students in science and engineering and certainly by graduate students in these fields.
586840	605800	63	B	0.70518	Nonetheless, the book is written to be readable by those that desire to focus on everything that is, the math, the code, the concepts, those that just want to focus on the math but are not interested in implementation, and even those that may skim over the math and just try to understand the ideas intuitively.
609520	620816	64	B	1.0	One thing that's very important to me in trying to express these ideas clearly is by spending a lot of time working on typesetting and style, which is very important to successful learning.
620918	625460	65	B	0.99997	So I would spend a lot of time attempting to make my work clear and readable.
626520	643000	66	B	1.0	To this end, I have margins which collect specific key terms for references later, which you can see in some of these figures that are shown here, and these terms will eventually correspond to the ontology project ongoing at the Active inference institute.
644220	652460	67	B	0.99965	Margins also provide further explanation to accompany the text, and this will be useful to readers who want more detail and explanation.
654080	658324	68	B	0.99781	There's a large focus on building an intuitive understanding of the concepts.
658472	662732	69	B	0.99998	For example, importantly, all algorithms are explained from scratch.
662876	668336	70	B	0.89	In this book, we typically start with a description of the agent environment modeling problem.
668518	676096	71	B	0.99999	We then start the book with a univariate case, extended the multivariate case, then we introduce variational inference.
676208	685960	72	B	0.99999	We add dynamics, generalized coordinates where applicable, hierarchical models, action and also learning and other modifications we might add to our models.
687820	701324	73	B	0.97738	We have a very big focus on figures clearly walking the reader through the text and giving detailed visualizations of important concepts and in terms of how the textbook is set up.
701362	711650	74	B	0.91	The early part of the book focuses on basic concepts such as hidden state estimation, that is, estimating the conditional distribution of a latent variable given some observed data.
712660	733700	75	B	0.64	The aim here is to explain the modeling paradigm in the context of an agent attempting to infer the states of the environment, that is, the interaction between a generative model and a generative process, a perspective that differs from the Bayesian inference style that is normally taught in universities and many introductory textbooks.
735340	752510	76	B	0.99951	Typically, introductory textbooks on Bayesian inference focus on parameter estimation or learning, and part one introduces the expectation maximization algorithm as a way to explain the connection and separation between hidden state inference on the one hand and parameter learning on the other.
754400	769010	77	B	0.93083	Additionally, a large focus has been placed on variational inference, which is explained in detail, and the book features a catalog of all the different forms of variational free energy and expected free energy in the literature and how they can all be derived from one another.
771720	787320	78	B	0.99	The book also covers Rau and Ballard style predictive coding terms and ideas such as key ideas such as prediction error minimization as well as clear and intuitive explanations of fundamental concepts such as surprisal.
788220	802136	79	B	1.0	The textbook focuses heavily on building intuition through derivation and the general flow of most of the chapters is to set up the problem that needs to be solved which is defining an interaction between the agent and the environment.
802328	819200	80	B	0.99995	Showing the elements needed to solve it, which is usually random variables and parameters that form a joint distribution or generative model replacing probability distributions with their algebraic formulations and then moving through the algebra to a final analytic or gradient based equation.
819940	823216	81	B	1.0	The readers should be able to recognize most equations in the literature.
823328	835130	82	B	0.9999	Upon reading this book, I'm also making extensive usage of Bayesian networks and other types and styles of graphical models such as factor graphs will appear in part four.
836380	856620	83	B	0.99998	There are hundreds of custom figures that have been created so far, and the figures are detailed to give the readers a deep understanding of the different types of content that is covered throughout the books, and also summarizes much of the information and equations that are pervasive throughout the active inference literature.
858560	866800	84	B	0.99996	Another important focus of the textbook is that many of the models that are presented are also shown in pseudocode, which should aid the reader in implementation.
867780	872716	85	B	0.98	And finally, each chapter is filled with numerous what I call experiments.
872828	879600	86	B	0.98	And these experiments correspond to the Jupyter notebook and try to show the application of a concept in a simulated environment.
879760	882596	87	B	0.97652	So a lot of these experiments start out by generating data.
882698	893624	88	B	0.99774	So we have some kind of generative process and then we have that data passed to a generative model or the agent which then attempts to either perceive and learn from that data and even act on it.
893822	907276	89	B	0.95	And the example that's shown on the right margin here, this is just a perception problem on a continuous grid which has been divided into pieces for the purpose of the simulation, but represents a continuous state space.
907458	915308	90	B	1.0	And the agent in the bottom left corner, shown as a mouse, has a prior belief about where some reward food is and its environment.
915404	928068	91	B	0.99999	But it then needs to perceive from sensory data that it observes the true location of that reward or food which is obscured or occluded in some way by the mist that's shown in that figure.
928234	940250	92	B	0.99993	So these types of experiments give the reader a better sense of how to apply these statistical ideas to a real world situation so we can understand how it might apply to some kind of autonomous agent.
942860	959440	93	B	0.99937	Next, I'd like to cover and shift my attention toward Jupyter notebooks and videos and like to note that upon publication of the textbook these Jupyter notebooks will be released on GitHub and should be fully reproducible using Docker and other version handling tools.
960740	971364	94	B	1.0	One of the big emphasis on the Jupyter notebooks is it has to be a direct correspondence between the equations and explanations in the code and in the text.
971562	976500	95	B	0.99986	This will build a direct understanding and show applications of the concepts explained.
978360	984890	96	B	0.99729	Notebooks are filled with simulations and visualizations many that appear in the main text.
987020	995588	97	B	0.67	And in addition to that, I have also over the last seven months been presenting chapter presentations to the Active Inference Institute.
995764	1010210	98	B	0.99995	So far, a draft version of the first ten chapters of the book have been recorded at the Active Inference Institute and these are just some sample slides that I've prepared that try to explain these concepts in great detail.
1011060	1016976	99	B	1.0	In the final stages of writing this textbook, video lectures will be re recorded and released alongside the book.
1017158	1024100	100	B	1.0	I also plan to create detailed code walkthrough videos that walk through the different examples in the Jupyter notebooks.
1026280	1038360	101	B	1.0	Now I'd like to talk about a few planned future resources I'd like to work on after the book is complete, or toward the final stages of the book to have further support and educational tools.
1039980	1060568	102	B	0.99997	Some of these planned future resources include a software suite in Python to enable an alternative learning approach for those who do not wish to learn about the algorithms from scratch, and this will expand the possible landscape of engagement as Pymdp already exists.
1060664	1078180	103	B	1.0	I will not be working on a discrete statespace Python package, but I'd like to fill the space for things like active generalized filtering, and also just an availability of different types of simulations of Bayesian mechanics as it's currently defined today, or at least the different versions and varieties of some of those key concepts.
1079400	1092516	104	B	0.63553	I'm also very much interested in interactive learning, and my aim would be to have these preset simulations concepts that are explained in text, with various simulations interspersed in the form of plots and demos and other visualizations.
1092708	1106750	105	B	1.0	And the idea would be that the user could manipulate sliders and knobs to tweak various parameters that would help aid in learning as they get a feel for how these systems behave, especially ones most of these systems we talk about are dynamics, so seeing how they change over time.
1110420	1120748	106	B	1.0	The Active Inference Institute has made tremendous progress in the past couple of years to provide a collaborative environment for researchers and for students of active inference.
1120924	1134010	107	B	1.0	I hope to be part of this ecosystem as I continue to support the spirit of accessibility and collaboration, and I'm excited to continue to contribute to this ecosystem of shared intelligence and look forward to what we can build together.
1138380	1152250	108	B	1.0	I would like to thank the Active Inference Institute for hosting my presentations, code reviews, and feedback sessions and inviting me to present at the symposium, and also thank my employer, Kung Fu AI, for letting me take time off to write for the past seven months.
1153100	1155352	109	B	0.99981	Please feel free to contact me at any time.
1155486	1161436	110	B	1.0	Email is the easiest way, but I'm also available on the active inference institute discord.
1161628	1168288	111	B	0.99977	If you would like access to the textbook and related materials, please send an email requesting access and I can get you set up.
1168454	1169904	112	B	0.99	And that's all I have for today.
1169942	1171010	113	B	0.99961	Thank you very much.
1175080	1175828	114	A	0.99887	Awesome.
1175994	1176532	115	A	0.97	All right.
1176586	1177440	116	A	0.99978	Thank you, Sanjeev.
