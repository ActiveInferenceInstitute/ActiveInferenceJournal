SPEAKER_00:
is carl hello welcome back everyone i'm here with alex auroria we may have carl join we may have someone else join if you want to join maybe write it in the youtube live chat and maybe i'll email you a link otherwise write some questions

However, to kick things off, Alex, feel free to say hello and start in.

And, and I know that there's things that we can explore together.


SPEAKER_01:
Sure.

You just picked it back to me and I was saying to you, all right, well, I'll, I'll just introduce myself.

Cause I'm not entirely sure how most of the audience, if they know of who I am.

So I'm Alex.

I am a computational neuroscientist and cognitive scientist.

who has worked for inactive inference and specifically predictive coding versions of it for quite some time.

I'm Carl's friend and collaborator.

Some of you might be aware of more of our recent arguments of mortal computation, which is a corollary or a new corollary or another corollary of the free energy principle.

Yeah, and I'm all about what's wrong with deep learning and machine intelligence.

And I'm usually the guy you go to if you want to attack back propagation of errors, large language models, transformers.

Kind of relates to a lot of the discussion I was able to catch snippets of earlier today.

So if you want me to help dismantle what's the problem with deep learning, that can be fun too.

So that, at least if nothing else, everyone now knows who I am.

Carl needs no introduction.


SPEAKER_00:
Maybe start off with that while I try to figure out why he cannot join.


SPEAKER_01:
Okay.

What part of that do you want me to... I mean, I can go into manifesto, but I'm not sure that's what this panel should be about.


SPEAKER_00:
Maybe beginning with a five-minute manifesto, and then there will be some questions, and we'll see where we get.


SPEAKER_01:
Well, maybe to try to make it useful to the audience for the moment, although I wasn't intending the panel to be focused about that, maybe one thing that we can talk about is there was this discussion during the active inference workshop about metabolism and sort of instilling a homeostatic metabolic drive, a survival almost orientation to machine intelligence.

Carl and I have now been arguing for probably now about more than a year since our paper came out,

Yeah, around November, actually, start of November, talking about another way to redesign, reformulate, to use Mao's earlier wording, intelligence itself, particularly machine intelligence.

And so, mortal computation without, again, for those that might not be familiar, actually, my friend Jeff also, like two years ago, introduced this phrase, the idea that computation

or intelligent calculations and substrate uh are in biological natural systems are entangled and it's very hard to divorce those two concepts uh whereas computer science and a lot of like what chat gpt is or large language models or your favorite deep gpt structure is immortal

which is the idea that we can copy that program, including its weak tensors and its encoded knowledge, and place it on any GPU server you want, and it'll behave roughly the same.

There's nothing inherent about its physical instantiation in this universe that dictates or shapes or necessarily embodies it, right?

And so there's this move to embodiment.

By the way, active inference in the free energy principle has

all of these characteristics, mortal computation, which is, again, the concept I explained earlier, Carl and I sort of recast it.

We strongly redid it and said that, because while Jeff didn't want to necessarily directly explore it, we put it as

it's just basically thinking of the free energy principle and taking it to its natural extreme conclusion which is that machine intelligence systems because they are inherently bound to their substrate must focus on this survival objective right and the free energy principle and one of its ways to talk about it uh basically is saying you know we have a markup blanket or a nested system of markup blankets and our goal

in this universe is to protect those internal states yet interact vicariously with our external states and so that eventually gives us our ultimate goal which is to prevent ourselves from disintegration into a heat bath it's a very physics form of thinking about identity and identity construction

But this is kind of what's centrally missing in basically all of machine intelligence.

Is this the completely right path to go?

There's plenty of criticisms and I'm not one to say that there's only one direction we need to go if we ever want something like artificial general intelligence.

But this might be a path worth exploring.

It also addresses the energy efficiency arguments I was hearing earlier discussed.

uh transformers particularly in large language models are uh grossly negligent of their energy costs they have oftentimes have the carbon footprint of a large city and that's actually now out of date as you know carl and i wrote that about a year ago um there's even discussions i find kind of humorous by individuals i'm not going to particularly name saying we should be powering now

these transformers and large language models with nuclear power plants.

And so we're kind of going down the rabbit hole of let's just burn as much of our resources as we can to just get this particular type of intelligence

I argue very strongly narrow AI and we're cheating ourselves of looking and embracing actually energy efficiency which would lead us towards the real grand goal of green AI because global climate change is clearly and empirically a thing and we should be a little worried

So, mortal computation sort of helps steer everything into sort of what I would argue, hopefully, maybe in multiple years time, the emergence of a whole new field.

As I consider, or at least my personal take, I'd love to have, you know, heard Carl, wherever he might be, but I envision actually mortal computation is not just like the framework and definitions that Carl and I talked about, which kind of take free energy

uh and active inference to the strongest conclusion to a naturalistic machine intelligence but maybe perhaps a new domain of thought of biomimetic intelligence and where everyone else can come together and play in this really interesting space and there's a lot to unpack there but i don't think we want to make this about that uh there's plenty of talks i've given including active inference institute we've had a podcast actually i think it was right

when the paper came out so for those that are interested i just recommend you to go to the youtube channel and watch wonderful videos that dan led oh is there is there a new link okay sure

Was I just blabbing there to no one?


SPEAKER_00:
No, that was perfect.

We just hot swapped.


SPEAKER_01:
Okay, I was trying to buy Carl.

Welcome, Carl.

We were talking about you.

Okay.


SPEAKER_00:
Thank you for the overview on mortal computation.

And it was a highlight of the year.

carl with the evening sunset now how um goes it wait i don't hear you oh continue sorry it's all good carl continue

You hear me now?

Yep.


SPEAKER_02:
Excellent.

Yeah, I'm sorry about that.

I got locked out.

I was paying the price for enjoying myself for the first two hours, I guess.

I really enjoyed the intervening sessions and look forward to sort of commenting about some of the cross-cutting things.


SPEAKER_00:
Yes, okay.

Alex, mute.

It's a little noisier on Jitsi.

And then Carl, also a little quiet, but we hear you.

So what were the themes that connected the presentations that you were in or otherwise?


SPEAKER_02:
One thing that struck me, can you hear me all right now?

Excellent.

There are lots of little golden nuggets throughout all the presentations, but one cross-cutting theme was this notion of community that emerged in various guises, such as the notion of commons that was the subject of a lot of the exchanges in the first

presentation and then the notion of community that was a denouement of the workshop and then the notion of coherence and synchronization and

narrative social um science accounts of that and how that might be formalized in terms of um joint free energy minimization ensembles of agents you know finding a coherent communal um and empowered free energy minima so yeah i feel i i i felt that that was a common theme sort of focusing um much less upon um

individual agents but what happens when you have a an ecosystem of agents um and what principles um can be brought to the table to understand interactions or ensembles of agents so i i have a number of uh yeah lots of things came to mind i was trying as a physicist to sort of um rewrite

all of these wonderful concepts in a mathematical way or a physics way.

So, for example, I was thinking about the importance of commons and it struck me that one way that we could motivate the choice of capital C

for prior preferences would be that these are the common goals and the C characteristic states that are shared between multiple agents and of course the last presentation took us through some of the

mechanisms and the capital c circular capital c causality um that leads to this capital c coherence so you know which originally was meant to be constraints in the sense of a constrained maximum entropy principle um or cost in that you know in a reinforcement learning uh reinforcement learning setting but coming back of course all this started when i was hearing about commons

and how it underwrote communities.


SPEAKER_00:
It is very interesting how development and the presentations have proceeded a lot more about the communication and somewhat of the multi-agent coordination as opposed to a longer memory train for individuals or deeper prospection for one individual.

And in a way the renormalization method brought a clarity or a rigor to what had already been qualitatively explored

from 2013 and life as we know it and all these other works that we're talking about multi-scale systems and about blankets of blankets and within this year to make it timely we start to see some of the ways

in which that compositionality can actually be brought into the generative models that we've seen i mean it looks like the textbook figure 4.3 and the nested models and now that's actually the motif that gives a way of looking at a multiplicity at the

more inactive level as having a unity at a higher level.

Alex and you're designing your work, how does the single agent or multi agents design come into play?


SPEAKER_01:
Yeah, you can hear me?

Okay, good.

Yeah, I was having mic troubles earlier.

Well, so it's kind of interesting.

I think I've spent most of my career at the SQL agent level in the sense that I want to build

I don't think we have right the single agent, and I think it's kind of important to sort of scope that out from an architectural learning perspective.

I'm very much a fan of like Carl's arguments, and I echo them myself a lot, which is the idea of the inference learning and structural time scales.

I still think we have a lot to do.

But if I were to say how in my research, the multi-agent approach really comes into play.

Well, I do think a lot in terms of assemblies or ensembles, right?

Putting together multiple circuits.

I'm a huge proponent of another type of this comes from cognitive science called the common model of cognition.

I'm not sure how many in the audience are familiar with it, but it's sort of like a generic

print that has emerged over the last several decades of cognitive science to say that we can think about and take our current knowledge from neurophysiology and cognitive studies that brain has these rough levels of organization different types of memory we have the motor cortex we have the base ganglia we have all these very important structures and we can start appending to them some functionality

and so in that sense that's where I think of multiple agents right because you can start breaking apart using uh again Carl and I've argued this the moon field approximation uh there's natural mean field approximations that emerge through the result of evolution where you have these little sub structures that communicate with each other um obviously the sparse connectivity that Carl mentioned in his talk this morning is uh kind of indicative of how these

little substructures emerge and then communicate and perform sort of like what Marvin Minsky would have said, you know, sort of a society of mind.

Right.

So it's kind of a callback to that.

And I think in that regard, I often one branch of my work often tries to highlight, emphasize, bring forth that notion of cognitive blueprinting or cognitive structure, because then we can start filling in the pieces with what we know about neurobiology

Like, for example, I use predictive coding quite a bit to fill in those gaps.

And so I think in that sense, I think a lot of interacting subsystems, you can think of those as agents.

And then my final comment, without letting myself blab too much, I have worked in neuroevolution.

So there is another scale above this, which is you do need to account for how

multiple mortal computers or multiple agents interact with each other.

And so I think in that regard, I have done some work with very simplified agents where you can kind of abstract away the neuroscience and just say, I want to look at these little tiny systems that interact and then we can modify them through genetic algorithms

and neuroevolution so there is a little bit of that like higher level uh societal kind of learning i have looked at that and i think a big challenge just to bring it to the audience for the panel is uh merging those time scales in a in a coherent and efficient way i still think

well there has been good work i know daniel you work on and colony optimization as well and other types of kind of aggregate algorithms i think bringing those time scales together and really interacting with what we currently know about single agents even like the common model of cognition and going back to the highest level which is this multi-agent evolutionary time scale is a grand challenge and how do we of course affect


SPEAKER_00:
simulate those in a way that anyone can play with this i think is a big challenge and yeah and i think i'll kind of stop there before i go hold down more radicals neuroevolution and neural darwinism something carl and and others have also explored it's like they're all and then the multiple nested time scales

multiple nested spatial scales it's like there's this attractor to want to come back and find the unifying patterns and and it's and how those can be applied is kind of an exciting question i'll read one question in the chat so feel free to give a thought or take it any direction david highland wrote

you view mortal and do you view mortal and immortal computation as binary categories or are they more like two points along a spectrum i actually want carl to answer that i mean i could give something but i really want to hear your thoughts on


SPEAKER_01:
it's your favorite subject though it's designed i know but i'm actually really curious if you think of it as a spectrum because remember the conversation we've had with mike levin and chris fields and we've been sort of debating you know how important it is to lean into mortality versus immortality do you think that there could possibly be anything in between because i honestly

you know i think of it kind of more rigid i'll just give my answers that and i firmly think we need to like focus on mortal computation but do you think that there can be a hybrid in between so sorry to turn it on you but i'm very curious to know your thoughts um i mean my my instinctual answer is no um having said that i am sure that you can


SPEAKER_02:
present some description of mortal computation in terms of immortal algorithms.

I mean, I'm just thinking back to sort of

um the trilogy due to david ma but does that mean that these kinds of descriptions are apt um for simulating reproducing understanding um or describing the actual process uh i i suspect not they may be at one level of description they may be but when it comes to um

applying the principles, usually in computer simulations, I suspect that that just would not work.

Because Daniel and I were wrestling with Zoom and other communication things, we may have missed whether you've taken people through the key distinction between mortal and immortal computation.

Alex, did you just want to briefly rehearse the two cardinal views of the distinction between mortal and immortal computation?


SPEAKER_01:
I did.

I just wasn't sure if anyone heard me.

So I wasn't sure what was going on from Zoom.


SPEAKER_02:
Yeah, I mean, certainly from the point of view of the free energy principle, the free energy principle is a description of a random dynamical system.

And as such, it is a system that constitutes the world, the lived world, perhaps not the lived world, but certainly a mortal world that has characteristic timescales and therefore

the free energy principle and everything that ensues from that, including active inference, rests upon that primary assumption that you are describing a process, a mortal process, a process that could have a physics, although

the actual free energy principle itself is almost pre-physics.

So you have to derive basic mechanics and classical mechanics and quantum mechanics from the existence, the mortality of this process cast in terms of time evolving systems.

So in that sense, there is no such thing as immortal computation.

But I also, I don't know if you said it out loud, but I also liked your more playful take on mortal versus immortal, that if software was immortal,

and it had some autopoetic aspect to it, then it wouldn't care about dying.

So there would be no incentive to have characteristic states coming back to another big C. So in that sense, there cannot be immortal computation simply because that is removing the definitional

uh stipulative definitional aspect of the characteristic states that we are trying to describe through the field principle and active inference and specific um very variants of that such as uh predictive coding but now just picking up on this uh cross-cutting cc theme uh you also um um celebrated that with common cognitive models so again we've got this uh this sort of notion of commonality and uh

And you asked the question, you know, how would one apply these notions and, if you like, sort of naturalize the common cognitive model under a less anthropomorphic or functionalist active inference account?

And you gave the answer implicit in your question, which is how would you simulate these things?

And I think Daniel asked the same question.

Indeed, the whole point of this symposium is about applications.

So I just want to put questions to the two of you.

I was impressed with the very clear distinction between agent-based modeling and the common cognitive equivalent, where the agents, the members of the ensemble,

were actually, for example, active inference agents.

That seems to me a very big move and a very difficult thing to actually do.

Most of the literature I know in this area has at most taken baby steps into having ensembles of true agents with authentic agency in the sense that they can plan.

So I'm now limiting the notion of an agent

beyond a thermostat or a virus to those kinds of systems that um have in mind or part of their generative model the consequences of their their actions so they can be future pointing and they can plan and select from alternative policies uh because the numerics and the you know the the practical difficulties of actually simulating

uh doing agent-based modeling for example um with authentic agents in the mix in the ecosystem um i think is you know um is a really important challenge and a really important distinction between classical agent-based models where you put lots of thermostats or rents attractors together and see what happens and of course they have a synchronization manifold and you can certainly wax lyrical about um generalized synchrony and and joint free energy minimization

of a generic sort, but I think that misses the point and I think Mao was making that part of the multiple loops of circular causality in cultural niche construction, for example, really does rest upon the capacity of any individual within an ensemble

to act given they have selected a particular course of action, a particular path into the future, which they have beliefs about the consequences of.

And then, you know, to me, that is an authentic kind of agent.

So, you know, I mean, perhaps, well, both of you, but Daniel, I mean, your ethology background, are you aware of anybody who's actually sort of,

bitten the bullet that was introduced to us during the workshop and actually started creating active inference agents that actually plan and learn from each other and carve out their own wallington landscapes you know finding those sort of joint joint minima


SPEAKER_00:
I don't know specific citation, but certainly you've given a research direction and it reminded me of in the shared pretensions work where thinking about what does a shared ensemble, what would it be for a planning ensemble or for a collective?

It could be a shared

protension as in there's the same plan disseminated across the ant nest mates it could be that they have different maybe non-overlapping but complementary parts that would be shared it could be having a shared reference but they could have different plans or it could even be a shared consequence without even a shared reference

So there's so many ways in which, especially when we consider ensembles that are heterogeneous, they have different kinds of umwelts, different kinds of ways of engaging with the niche.

and possibly some common niche, as well as some uniquely accessible components.

There's so many flavors of ensemble that I can only, hopelessly or helpfully, try to think about what tools and infrastructure and coordination would even give us a grasp to be able to sweep or design or visualize across that

Otherwise, we might be locked in way too early to what it means for the ensemble to have a collective pretension.

And then that's not going to apply to every ant species.

And if it can't even apply to all the ants out there, then it's not going to work for aliens.


SPEAKER_02:
Alex, can I just respond to that and then ask for your view on that one?

So that is a really important point, isn't it?

One of the big takeaways for me on our paper on the variational synthesis, applying the renormalization group to the coupling of evolutionary to phenotypic time scales, was that it was not feasible or appropriate to talk about conspecifics in isolation, that you had to have

all the varieties of predators and preys and things that are not even animate and not even agents in the mix to actually derive the non-equilibrium steady states at particular scales, which speaks directly, it is not

useful to, if you like, take the idealized gas mentality of 20th century physics and now apply it to agent-based modeling to assume that all the agents are exchangeable and are identical in some sense and then are converging on some common narrative

or some common, is not the right way to simulate these things.

You can't do predator-prey relationships.

For example, you can't have even simple economic games.

But furthermore, when people talk about depletion of resources, you actually have to model the resource, whether it's oxygen, food, or water, as the things in that ecosystem.

So I think that's a really important observation which just speak to the challenge

of using numerical studies to test out some of the hypotheses that we've been exposed to.

If one just pursues agent-based modeling without introducing that heterogeneity, I think one is making exactly the same mistake that people make when they apply equilibrium physics to non-equilibrium systems.

a true gas is not an ideal gas and it only has the kinds of properties and breaks detailed balance and expresses non-equilibria in virtue of the fact that there is no exchangeability you can't assume that every atom or every agent in our context is exchangeable with it with every other agent


SPEAKER_00:
and to connect again to commons and and that model of well within the firm we assume cooperativity and hierarchy in the market we have a flatness and a competitiveness and then there's this commons that has sort of elements of each so then i think about doing ecosystem modeling it'd be like well we have within the ant colony we assume cooperativity possibly hierarchy

among ant colonies you have red and tooth and claw and competition and then it's like but can there be a unifying framework that would have the two genotypes and two phenotypes and two species and two adjacent niches and keep on adding in

these levels of distinction and seeing all those different variables in their joint evolution across multiple time scales rather than the concatenation of

a cooperative hierarchical game within a lateral competitive game.

It's like capturing what those models get the width and the height of, but bringing it into a framework where it's being seen as just one joint evolving process.

So C is the letter of the day.


SPEAKER_02:
Alex, can you speak to Cs and Fels and what that kind of heterogeneity and structured diversity would look like from the point of view of a tissue, for example, or an organ?

Okay, wait, what was the C word you said?

I just didn't hear you.


SPEAKER_00:
It's any word starting with the letter C you can use, but you have to.


SPEAKER_01:
Oh, I have to use... Okay, this is the game.

Community.

I'm going to pick that one just because it starts with C.

So, okay, Carl threw in organs and organelles, but I'm going to push that aside for just a minute to address, I think, one of the questions I heard emerge from yours and Carl's discussion, which was, is there anything like what you are arguing for, which is avoiding the mistakes?

And by the way, predator prey model came immediately as you were speaking, Carl.

about these classical models that assumed interchangeable agents.

And is there anything that looks at these heterogeneous systems or heterogeneous agent interactions?

And a couple of thoughts.

I don't think there's anything like directly what we would want.

And I think that ties or centers around even the arguments you and I and many others in the community are making about why it's difficult to showcase why active inference is so important, even for places like machine intelligence.

But I did write some thoughts quickly.

So I do think the first thing that came to mind, weirdly enough, was an application in the world of machine intelligence where they had some environment where they had a community of, even though I say it with slight distaste, large language models or chat GPTs or GPTs that had some extra modality put to them.

And they had this little community.

Now it was a virtual, very simplified niche, if you will.

But the idea is that they could observe this community.

And so these different GPTs would, and I can try to dig up the paper and send it to Daniel later.

It's one of my students that actually pointed it out to me.

They would assign different roles.

They had different personalities, if you will.

And I know that they investigated that to some degree.

Now, of course,

and i'm not sure what degree of maybe perhaps light reinforcement learning be introduced but there is something like that and there is slight baby steps if you will uh in investigating some notion of embody multi-embodied agent systems i think the ai community is still

sort of barely starting to embrace embodiment, let alone inactivism and let alone embeddedness, which is the idea of a community to go back to the C word of multiple agents interacting with each other and investigating how do social norms emerge or

cultural norms and cultural constraints and relationships at this more global level.

So I think there is a little bit of those sparks of that thought, and obviously I might not be aware of further follow-ups.

Another place that I at least see the potential of no longer having these interchangeable particle-like agents is in multi-agent robotics.

I know that they have done things like soccer competitions and they have these little, and again, each of those robots, they are the embodiment of what you and I want, which is a version of a mortal computer.

So it's a little like assembly of mortal computers and there's a cooperative nature.

So, and then a competitive nature.

So you get a little bit of a very constrained

real physical real world niche um obviously it's in the constraints of it's a soccer game or some very simple tasks so i know in multi-agent robotics there is some development along this path and it'd be wonderful to have like a hardcore because i'm more of a simulation roboticist a hardcore roboticist to talk to us about the state of multi-agent robotics i think that's the place where you could begin to test

uh hypotheses and kind of or theories that are constructed even from an active inference point of view uh into these real world robotic multi-assemblies you know and they have like we could analyze the competition cooperative dynamics i think that's our best bet in terms of what maybe exists at the closest to literal agents that aren't just

very simplified, even though they make simplifications in robotics, too, in order to have a little brain in there that does something meaningful.

Usually learning is turned off, which is my own criticism of robotics.

And I think the last comment I wanted to make

And again, getting back to the notions of what we need.

So again, you and I have a fondness, I think, for some of cybernetics.

And cybernetics has this notion of complex emergent systems.

And you have little building blocks at one level that follow their own physics or their own physical laws.

And then they maybe assemble or emerge into these higher level building blocks that are subject to their own laws.

And then you have bottom up and top down causation.

which is a notion that you know comes from cybernetics and we always talk about that but then i think about like santa you you might be familiar with the santa fe institute and all their wonderful work like uh what was it not just a herbert simon but uh uh john holland

and all the wonderful work on complex adaptive systems.

But they always did, at the end of the day, when they simulated it, they did the particle thing, those interchangeable particle simulation, and then tried to analyze those convergence properties or those emergent rhythms or patterns that emerge in those systems.

with no, to my knowledge, and I did study complex adaptive systems a while ago, not with that heterogeneity and let alone any of the complex agents that we could begin to design today, even with deep learning, regardless of its limitations.

And so I think that that,

maybe even turns into an answer to your question, highlights an open opportunity, maybe revisiting and recasting notions of cybernetics and complex adaptive systems in this idea of, well, can we actually build more complex agents?

for example, that actually have neural substrate structures or something that we can simulate and then learn to acquire their own characteristics in their niche.

I think the reason that maybe a lot of people avoid it or maybe why I don't perceive development in that direction is the problem also of niche.

And you and I also had, not to try to highlight this paper, but in the appendix, we talked about the body niche problem.

And that is this issue that you need a niche.

If you don't have a niche and you're designing these agents independently like deep learning typically does to apply to any niche, you're missing really half the problem, which is understanding the physical laws and how do we simulate them such that people can then play with those models.

Maybe you don't have access to a xenobot like Michael Levin does.

or I don't have access to organize, though I wish I did.

But maybe we can simulate these.

And so I think that we need the community, maybe this is a call to the community, to develop viable niches, virtual morphologies, virtual areas that we can then connect these agents and then simulate many of them and try to analyze and understand do the things we predict

even with these interchangeable particle models, apply to these heterogeneous communities that might emerge.

And again, I guess that just to wrap up, and I promise I'm done, you brought up organelles and organs, and I think that highlights something that I wish I had more easy access to rather than being put into this position where I'm only I need to build it, which is

you know these virtual organ systems or virtual organ organelles and trying to understand how these dynamical systems interact and then I can kind of take that as that's my body or that's where my mark and I can kind of start to put some instantiation of Markov blankets and then say okay I want to distill maybe a neural circuit maybe I put in a predictive coding model into this kind of virtual morphology so I can analyze and understand does

do these interactions of the timescales actually come through when we actually build physical instantiations of these models?

I think that's going to be one of the biggest roadblocks to even my dreams of mortal computation, which is this notion of

something that we can actually work with that gets as close as we can to reality without reality and a niche.

Because once you have those problems solved and you can start building multi and if you have efficient way to simulate them.

And I'm sure lots of people that are watching might be worried because it's very hard to simulate real physical systems.

let alone allow machine intelligence researchers to play with them.

So I blabbed a little bit there, but does that sort of give you something to bite on based on your question?

Something to chew on?


SPEAKER_00:
Something to consider?

In the last little bit, I'll ask some questions.

So I'm going to read one from the live chat, and then anyone else will just do some quick, fun, random questions, sort of like sampling from the uncertainties, expressed uncertainties of our live chat colleagues.

Okay, Pablo FM wrote, is playing a simulation acquiring knowledge slash experiences through simulation of scenarios?

And how can we use active inference to do games?

How do you fellows make your active inference work playful and fun, if or when?


SPEAKER_02:
Let you go, Carl.

You go first.

I'm not sure if there are two questions there.

a practical answer to why you might want to instantiate a simulation environment with active inference agents, or indeed just a single agent in the spirit of computational phenotyping, but I think probably more interesting in the context of communities of agents.

in the spirit of this sort of cognitive agent-based modeling, is the ability to parameterize the priors of the agents to best explain or replicate legacy data from a particular ecosystem, be it financial, epidemiological, meteorological, purely ethological,

And having optimised the parameters, you then roll out into the future.

And in rolling out into the future, you now have the opportunity to have a grounded, in principle, Bayes optimal plus inactivism and embeddement estimate of what is likely to happen in the future.

Again, in the spirit of weather forecasting.

But of course, this becomes much more...

useful when you have control of the systems of financial market forecasting or epidemiological forecasting or climate change forecasting, assuming that there's a substantive anthropomorphic, anthropological contribution to climate and all the other factors that pertain to

resilience and uh resistance to things you know health and the like um as soon as you can intervene then once you've got a digital twin of this ecosystem that has been optimized in relation to um the past data in the sense that this now has the highest model evidence or marginal likelihood in relation to that legacy data

you've then got an opportunity to do scenario modeling with interventions so you can now ask questions what would happen if we cut this supply chain what would happen if we impose this lockdown in this viral pandemic what would happen and so on and so forth furthermore because you've got

uncertainty in the mix, because this is effectively going to be using variation procedures that we use in active inference to actually simulate the behavior that best matches the legacy data.

You've also got for free uncertainty quantifications.

And not only can you say, if I intervene on this system and did this,

then we would, I can predict that in six months time or in six years time that, and I can give you base incredible intervals over that.

Moreover, you can now apply the principles of active inference to roll out under different interventions, which now become policies and evaluate the expected free energy of each policy and select the one under the constraints, the common, the characteristic outcomes that you commit to at this point in time.

And you can now use this scheme to make recommendations.

on the basis of the relative probability of this sequence of interventions versus that sequence of interventions.

So I think there are great practical importances of being able to put these principles in silico and basically do evolution very, very quickly so that tomorrow you can read the consequences probabilistically of evolution in this setting and that setting where the setting is actually something that we can intervene on.

or even if we can't, just to know the consequences of our collective behaviour today.

So I think that's why you might want to invest in these applications.

With the fun and having and play, I think that's a different issue.

I think that's basically one way of looking at the

the way that authentic agents behave under under the free energy principle which is basically to explore and gather the right kind of evidence that provides literally evidence for their generative models of their world um which basically entails novelty seeking

But now complement this with this basic model reduction we've been talking about, also trying to find the minimal explanation for the data and the evidence that has been secured by exploratory playful behaviour arriving at particular insights, which those are hard moments that say, oh, I see, it's just one of those, or this one thing explains all of this playfully acquired data.

And perhaps that kind of mechanism may be a really important aspect

of the communal cognitive agent-based, I can't quite remember the acronym.

It was very nicely laid out in one of the, I have to go back and look at the live stream.


SPEAKER_00:
A follow-up question from the live chat.

Arnaud wrote, I agree with the approach to calibrate to pass data and forecast, but it's already quite challenging for current models that only have a few parameters to be calibrated.

How then does one calibrate prior beliefs of millions of agents?

I'm talking about epidemiology and economic models.


SPEAKER_02:
Sorry, I've got to give a technical answer before Alex gives a more detailed answer.

It's only difficult because 99% of agent-based modeling uses the sample distribution.

You do not do that.

You use variational.

You actually simulate and roll out the probability distributions themselves using variational calculus.

And that means that what was yesterday really difficult agent-based modeling and certainly epidemiological modeling now becomes really trivial, orders of magnitude more efficient.

What you have to take care of is exactly the thing that Daniel was highlighting before, which is the heterogeneity.

You need to put that into the mix and this manifests in a number of ways.

So when you apply variational procedures to effectively roll out population density, probability density distributions over various states of being, am I infected?

Am I staying at home?

have I died?

You have to make sure that the heterogeneity is part of the generative model.

So this is sometimes called stratification.

So for example, in epidemiological models, you'd have eight bands for different age groups.

And if you notice the way that

the epidemiological data was generated.

It was usually age segregated so that people could stratify their models.

Another way in which this heterogeneity becomes absolutely crucial when you come to agent-based modeling in the context of epidemiological or infectious disease modeling is called overdispersion.

Now, overdispersion is the fact that you get heavy-tailed distributions that inherit from the heterogeneity.

So you get this for free once you put heterogeneity into the model.

But it does mean for every, if you like, subgroup of the population, you do introduce more parameters.

But remember, the number of parameters

doesn't really matter it's the amount of time that you take to effectively invert your model and if you try and do that using sampling based approaches which is currently the the norm you could take literally weeks to do something whereas if you use variational procedures then you could do that within within minutes so it's a really important question a very practical one


SPEAKER_00:
Yeah, to restate, direct variational inference on beliefs about ensembles themselves being variational belief inference on agent-level semantic beliefs rather than sample from the sample what the agents are sampling.


SPEAKER_02:
Yeah, you're invoking the twist.

Yes.

How on earth can you model a variation density over things that have variation densities?

You can do it under the furniture pencil room because the only observable things about an agent are on its Markov blanket.

of course they are not belief structures so there is a lawful relationship between you can if you like simulate cognitive agents using traditional agent-based approaches but what you have to do is to amortize or to basically work out the mapping between the history of what something sees

and what it actually does.

But in principle, you can do it by marginalising out the beliefs of the agent, in principle.

And that's why I'm so intrigued by this distinction, because that will be a challenge.


SPEAKER_00:
alex and then carl just in our last minutes here what would you say was a favorite memory or moment in theory and practice for active inference this year and then what are you excited about for next year


SPEAKER_01:
I'll go first.

So a favorite memory of active inference.

Let me think quickly.

Well, I mean, I'm going to be a little biased just to give a highlight and a shout out and everyone will get to share in that memory if you stick around after the round table is actually some of the results from one of my PhD students, Viet, and he's going to give a talk soon.

And the idea is that

One of the things I was proud of is he's been working in the area of robotics, which I think is a really good playground.

As difficult and hard as it is to democratize for everyone to work with robotics, I think it really shows you how far we need to go.

And I think that's a good place to make strong advances in active inference.

And one of my memories is that I remember him kind of showing me, because he's working with partially observable Markov decision processes and how difficult and unaddressable or lightly addressed it is in the field of working with raw sensory data to try to construct these continuous models.

And I remember him showing me some of his models rolled out trajectories in the future.

And I'm always kind of

and a fondness in my heart for generative models and i remember him playing out sort of these robotic memories of this robot trying to you know fantasize where it would want to go to kind of like move this block or to knock a ball towards the globe so that was one of those moments where we were really proud because the idea is we actually we actually made a breakthrough

uh in actually showing that we can construct a very robust framework that applied across all these robotic control problems and so i was immensely proud of that and so i think my students drive a lot of some of my fond memories um and uh and then we got uh chris buckley shout out to him uh to you know uh kind of give us his insights into our work too and it was a really really nice work and so i think the best way to say it is stick around if you want to know how that all works

I was really proud of that.

So that was one of my favorite memories of the year.


SPEAKER_00:
Awesome.

Carl, with the last words, a fun memory and a direction or an excitement for next year.


SPEAKER_02:
Right.

I'm not going to tell you about my most fun moments.

That's very personal.

But my excitement for next year is to see whether any of your hairs go grey after you do the monstrous summary of these, not only these symposia, but all the meetings.

Because for those people who don't know, Daniel has to run this almost single-handedly.

non-stop for a marathon sometimes 10 hours at a time i don't know how he does it at least unless you're using hair dye you're you're stuck you're standing up physically remarkably well sir so i just see how long that lasts thank you carl i look forward to the marathon changing continuing and flourishing in the coming year we appreciate you daniel thank you guys it's been awesome


SPEAKER_00:
Okay.

Thanks a lot.

See you soon.

Nice talking to you guys.

Bye, everyone.