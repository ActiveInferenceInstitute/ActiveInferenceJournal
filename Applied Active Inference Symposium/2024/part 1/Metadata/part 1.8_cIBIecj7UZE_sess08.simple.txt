SPEAKER_01:
okay the next talk is going to be by bradley alicia and colleagues purposefully non-standard cybernetics an alternative to purpose-driven control this is going to be a one-hour pre-recorded talk so thank you enjoy


SPEAKER_00:
Hello, my name is Dr. Bradley Elisaia, and on behalf of Jesse Parent, Morgan Huff, and Amanda Nelson, we're from the Orthogonal Research and Education Laboratory and the Cybernetics Interest Group, and I'm going to talk to you today about purposefully non-standard cybernetics, an alternative to purpose-driven control.

So we start with a question.

What is the definition of behavior?

This has varied throughout history.

According to the behaviorists, behavior was identified as a reflex elicited by stimulus associations, the consequence of reinforcement, and the current motivational state.

If we go forward to the cognitivists, which is more or less the modern view, they would say that behavior is a set of internal mental states that are responsible for observable behaviors.

with goal-directed end states.

Now, it's of note that both behaviorist and cognitivist views involve feedback.

This leads to learning, a notion of what constitutes a state, and predictive capacity.

So we start with this paper, Rosenbluth et al.

in 1943, Behavior, Purpose, and Teleology, published in the Philosophy of Science, and it's a formative paper in the field of cybernetics.

So in that paper they have this typology of behavioral classifications.

So we're going to return to this typology throughout the talk and we're going to think about how we can reorganize this typology.

But it basically defines behavior as a set of nested things.

The red text, non-classes, or they're basically all other things other than the black thing that we'll be talking about at each rung of this typology.

So behavior is active.

It's purposeful.

It involves feedback, which implies some sort of teleology.

or end goal.

It's also predictive, which involves extrapolation and involves an order of prediction.

So you might have first order, second order, or third order prediction.

So to understand what teleology is and where it comes from, we start at the Middle Ages where teleology was the end state or the end goal of some behavioral process.

It was thought of as divine causation.

We then move forward to teleology as natural causation.

Then it branches off into two directions, and the first was the vitalism of Bergson

and evolution by natural selection, made famous by Darwin.

Leading from Darwin's work, we had Ernst Marr, who talked about teleonomy, which is purpose versus history, and we'll talk a little bit about that later in the talk.

Kind of discontinuous to this are two different streams.

So the first at the top is where behavior is viewed as habit.

That's by William James and Thorndike.

That leads us to the molecular antiteleology of Francis Crick.

And feedback is complexity, which is summarized by control theory and dynamical systems.

At the bottom is our target paper that we just talked about.

These are the views of Rosenbluth and Weiner, and this is feedback relative to a goal.

This led us to cognitive science and reinforcement learning, or at least the modern versions of this, where people talk about goal-directed behavior, and variations on that in molecular biology, such as molecular vitalism,

and the TAME and UAL methodologies of Levin, Jablanka, and Ginsburg.

So we'll talk about a couple of papers here and frame some of this in context.

So if we think about behavior, it's essentially a form of functionalism.

In the first paper here, Roddy and Germain, they argue that functionalism is a pre-scientific

So they actually argue that the whole idea of functionalism is something that comes from this era of divine causality.

Biology is not designed, so why should we expect a function?

And this is something that, of course, maybe is assumed about function, that it comes from some sort of design or comes from some sort of divine intervention.

On the other hand, teleonomic systems are defined by spatial and temporal information and constant iterations over states.

So we do have these teleonomic systems, but include modern components.

Only select behaviors can be defined as selection of a goal or derived from signals from the goal.

So that means that we can't necessarily paint behavior with a broad brush of teleology.

Only some behaviors may be teleological and others may be not.

Not all behaviors, and this includes biological and machine behaviors, are goal-selecting.

And while goal-directed behaviors seem to be purposeful, and it may be true that some of these behaviors that are known as goal-directed are purposeful, are there developmental and evolutionary antecedents?

So are those ancestral behaviors or those basal behaviors or behaviors that occur earlier in development, are those also purposeful?

And the answer may be no.

So Rosenbluth et al.

defined behavior as any change in an agent with respect to its surroundings.

This is much broader than the neuroscience psychological definition, and it's a contrast between all behaviors and a subset of purposeful behaviors.

So if a behavior is put under some sort of selection, or if a behavior is selection of something in the environment, this might lead us to a subset of voluntary behaviors, which then some of those may be purposeful.

And so purposeful behaviors is actually a subset of all behaviors.

To demonstrate this, we see that clocks, both mechanical and biological, are not purposeful, because there is no final aspirational state.

Mechanical clocks can keep time, and you can set an alarm on them, but that alarm is imposed by the outside, and it's not a property of that behavior in and of itself.

Furthermore, a biological clock runs via physiological processes like a circadian rhythm,

And it can be entrained by external light, but that again is not a final aspirational state.

More generally, teleology requires a signal from a goal.

So it's some sort of signal from a goal that's specific to that behavior and purposes progress to that goal.

So again, with our example of circadian rhythms, it's entrained by light, but that light itself is not a goal.

It's just something that's out in the environment and the system entrains itself to it.

We can also see this with brains.

in that brains produce behavioral outputs, but the exact mechanism is hard to pinpoint.

And this is the Rust and Liddell article that we saw earlier.

And this asks the question, signal from what to goal?

So there's a signal coming from something to a goal, but it's not clear what that is.

This is something one of our coauthors, Jesse Parent works on.

This is a frontier map for teleology and related complexity theory concepts.

So the data from this is drawn from the Complex World Book by Bob Krakauer.

This is published in 2024.

And it kind of goes over three different concepts that are interrelated.

So we have teleology, organized complexity, and emergence.

And so you can see that our paper Rosenbluth 1943 is at the top.

And this is sort of the first paper that talks about teleology.

in sort of a scientific and in a manner of complexity.

And so this is the first paper that talks about teleology as a property of complexity and of complex systems.

So a lot of papers were influenced by Rosenbluth.

This teleology was inherited by Wiener's book Cybernetics and Control in 1948.

Two other papers, Adaptive Systems by John Holland in 1962, and Organizations in Complexity, also in 1962.

The Good Regulator, of course, in 1970 inherited this concept, but it also inherited another concept from Organizations in Complexity

which is organized complexity.

A good regulator then passes down this concept of teleology to the book Order and Chaos in 1993.

And there's a direct link between Rosenbluth 1943 and the tame concept of Mike 11 in 2022.

Now, going back to the concept of organized complexity, this comes from Organizations and Complexity.

The Good Regulator in 1970 and the Autopoiesis paper in 1974 both share this intellectual lineage.

The Autopoiesis paper lends that organized complexity concept to this paper on deceptivity in 1982, into this book Order and Chaos in 1993, and then to the TAME concept in 2022.

Finally, we have emergence, which starts with the paper by Anderson, More is Different, in 1972, inherited by the autopoiesis paper in 1974, in turn inherited by the dissipativity paper in 1982, in turn inherited by Order and Chaos in 1993.

So you can see that we have not just teleology as a concept, in which we've kind of talked about already, but also a number of other related concepts.

This is Levin, this is the TAME paper, and then Jablanka and Ginsburg, this is the UAL paper.

And so Levin proposes the TAME or technological approach to mind everyone.

Levin's principle here is it's cognition all the way down.

We can see cognition in terms of minds, we can see cognition in terms of molecular phenomena, we can see cognition everywhere in between.

And so behaviors, all of those behaviors are cognitive to some extent.

And as a result, we get these diverse minds that have these different goal-directed competencies that allow those systems to achieve embodied agency.

So in Levin's approach, teleology is a very important concept.

not just for cognitive type behaviors, but behaviors that go all the way down to the molecular scale and maybe even down to the quantum scale.

Second, teleology is a means to explain why agents develop towards goals.

And so, you know, we can look at agents such as artificial agents, simple organisms like bacteria, and we can see that teleology is a way to explain and learn how to move towards goals.

The next paper is this UAL paper by Jablanka et al.

And in that paper, they propose a concept called unlimited associative learning.

And this concept is a minimal marker for consciousness.

So in this paper, they also champion teleology as an intrinsic reinforcement system.

You have this internally regulated model in service of attaining external goals.

And teleology plays a role in attaining goals.

So again, in both cases, there's a strong tendency to talk about goals

strong tendency towards teleology but we might ask the question is behavior at these different scales and any sort of behavior that's sort of motivated towards some sort of function teleological and purposeful or is it simply a product of the history of the system so you know we could talk about teleology and purpose and we've kind of set this up that you know this is something that has kind of come out of the natural study of behavior but sometimes you know we don't

really fully, you know, sometimes we ascribe teleology and purpose to things that maybe are just simply a product of the history of a system.

First example I want to give is the Belousov-Zhabotinsky reaction or the BZ reaction.

And at the lower left you can see an image of the BZ reaction.

And this is a deterministic internal model that we can model with differential equations and we can solve those differential equations and get interesting solutions.

that produces a chaotic behavioral output, or the dynamics of the system, which are sort of the unfolding history of the system.

So if we take an example of some sort of chemical soup,

we can achieve the Lefsov-Zhabotinsky reactions or BZ reactions by setting up this sort of set of differential equations, these ordinary differential equations, setting up an initial condition, and we get these spiral waves and swirl rings that result.

And so if we have slight variations in the initial condition, we end up with very different systems, very different types of patterns in these systems

And we can describe this with ODEs.

And one might say, OK, there's a purpose to this.

But the purpose isn't necessarily clear when you run this simulation again and again with different types of initial conditions.

There's a chaotic behavior at a variational dynamical output.

So this is an example of the tip trajectories of BZ waves.

This is from a paper I brought in Engel in 1993.

And it shows how there's a lot of variation

in the pattern but there's a sort of um you know constant aspect of the pattern in terms of the tip trajectories so one might say okay the purpose is to produce these tip director trajectories instead of the actual pattern and the interactions which may be true but then of course you know that's something that i want you to think about as we go through the rest of this talk

We can also plug the Belousov-Zhabotinsky reaction into a cybernetic model with higher-level feedbacks.

And so I talk about this in this Dimensions and Morphogenesis lecture on the DivaWarm YouTube channel.

And what I'm getting at in that talk is that there are different dimensions of morphogenesis.

There's one-dimensional morphogenesis, two-dimensional morphogenesis, higher-dimensional morphogenesis.

and so you see this kind of output and so i'm asking the question here is this purposeful or is this a product of sort of a chemical a dynamical chemical system with a history and so we can also look at this as a cybernetic model where we have feedbacks and we have other sorts of complexity and you know we can fit it also into that behavioral uh typology of rosenbluth

Okay, another example is this thing called an allostasis machine.

So an allostasis machine is basically the output of an internal model.

And so an internal model, of course, as we talked about, is something that has some sort of capacity for memory and learning, and maybe some sort of output that looks behavioral or cognitive in some way.

So what we can do is we can take this internal model.

We can have an oscillator, which is a stochastic process or a deterministic process, depending on our oscillator.

And we can have a memory with capacity.

So we have this oscillator that produces an output.

And we have sensory information that can drive the oscillator forward.

This output creates a trajectory, which is an interaction between noisy perturbations and a historical trajectory that's shown as a red line.

And the historical trajectory is stored in the internal model as a memory with a capacity.

So as this red line unfolds, there's a memory of it in the internal model, and it responds to external perturbations which drive

this red line in different directions and the oscillator tries to recover to the original state and so you get these dynamics that may look purposeful but really have this stochastic and adaptive component we get more into this aspect of dynamical control systems we're looking at intrinsic motivation in dynamical control systems so this is this tiamkin paper in prx life and so in this paper they talk about how you might model

maybe something like an allostasis machine as a set of actions generated without a specific reward signal so in this paper they talk about that as intrinsic motivation they model this with

X of T states and A of T actions.

So an action maps to a number of states, and this results in a trajectory forced by observation stochasticity.

This is entropy.

So you produce the trajectory.

There's an observation that you have, and that's the entropy of the system.

And so you maximize actions that increase susceptibility rather than entropy.

These are noisy observations that we do in perfect observational states.

And you can compare arbitrary length sequences of such sequences in the future.

This gives your internal model the ability to sort of integrate information and to find sort of solutions to problems.

The idea is that you have the system that can work towards a goal, but it isn't driven by any sort of teleology.

It's just driven by this memory component and the stochastic component.

that's all you need a number of other papers here that i'm going to talk about i'm going to put this in the framework of anticipatory systems from our paper on teleonomy and benny and friston so to get to this we need to re kind of reformulate our behavioral typology so remember we talked about behaviors having these different components we have these non-classes so in this case we're going from behavior to active behavior

a purposeful behavior, but that's contrasted with historical or Markovian behavior.

Then we have feedback, prediction, and order of prediction.

And so Ernst Marr refined the Rosenbluth et al.

teleological category into two parts, purposeful, agentic, and historical Markovian.

So if we go back to the Benny and Friston paper, they talk about the free energy principle is managing different forms of goal-directedness.

and how you need negative feedback to attain homeostasis.

There's purpose in cases where the goal is known, which is a Markovian system, and surprise was minimized, which results in uncertainty, then we can expect purpose.

Purpose isn't really just some sort of magical thing, or it's not some sort of thing that requires a strict goal.

It's just certain conditions under which our behavioral trajectory exists.

We can also look at anticipatory systems.

It's the Louis paper.

And this anticipatory systems come from a generative model with depth.

So this is where we have temporal aspects of the system that lead us to teleology.

So it's more that the teleology is the history of the system.

And this depth comes from an internal model.

So basically, if we go back to the internal model, we have some process that generates behavior.

We have this memory.

The memory is basically something that stores everything that the system has experienced.

And that's how we get to rheology.

To kind of understand this a little bit more, we want to distinguish between a Markovian system and a non-Markovian system.

So a Markovian system is where you have inter-arrival times.

So there's a series of things coming in in time.

This is exponentially distributed.

In this diagram, we have sensory information coming in.

We have some sort of encoding.

This encoding is a binary channel of noise where we have these lines that represent some sort of sensory input or perturbation of the system.

And inter-arrival time is the area between these lines.

So the inter-arrival time is obviously not

equidistant in this example, but it's in between the red and blue lines or the red and red lines.

And so we can take those in our arrival times.

And if they're exponentially distributed, we have a Markovian system.

If they're not, then we have a non-Markovian system.

And so we've kind of developed this distinction between Markovian and non-Markovian sensory information and how that relates to an information measure in our Gibsonian information work.

so gibsonian information is a markovian but can also be non-markovian information processing system and the citation is here so going back to that behavioral typology we have active purposeful feedback prediction and order of prediction feedback is everything that is circular and non-transitive this is the present past and future where behavioral is controlled by a margin of error corrections

of agent location the time t relative to a goal position or state and so if we think about this in terms of a feed forward process feed forward process is where the past is your input present is your process and the future is your output in feedback however it's a little bit different your input comes in the past and then you have this present state here and then you have feedback which is the past and that loops back to your input which means that your input is now the future

And so the future is actually present with past feedback.

So you see the loop here.

You have input to the present.

You have this feedback, which is the past, and it goes to the future.

So now you have this future state before the present state.

And if that keeps going out, you get this output with alternative futures.

So your feedback loop can be positive or negative.

And in this case, it doesn't matter.

What we're interested in is sort of the order of past, present, and future.

So we end up with this input.

We go to the present.

We go to the past.

We go to the future.

We go back to the present.

So we're sort of interdigitating different types of causality here.

Instead of just having this past, present, and future aspect to things, we have this sort of convoluted aspect of past, present, and future.

We can go back to our historical map.

we recall that non-teleological things can be characterized as feedback as complexity.

And so there are two papers here that talk about PID control that kind of get us at that idea.

So PID control is proportional integral derivative control.

And if we think back to our example of chemotaxis and phototaxis, we find that PID control can be applied to chemotaxis and other types of biological control.

So this is the Balteria-Buckley paper.

They talk about this in terms of variational free energy minimization given a linear generative model.

They talk about PID control resembling a reflex arc type mechanism.

So this is the reflex arc we find in sensory motor control.

And the free energy principle provides a more direct account of control.

This is where we don't have any hidden states in the process of proprioception.

So they're focusing on proprioception, but they also talk about chemotaxis.

And so they kind of give us this sort of variational free energy interpretation of this.

In GU et al., which is a more engineering take on this, the PI and PD components, or the proportional integral and the proportional derivative components, and directed network synchronization are all sort of components of this control mechanism.

In particular, the PI and PD components of PID define present, past, and future components in an internal model control system.

We can then also start to think of feedback as complexity in terms of non-linearity and complexity as well.

So this paper by Westerberg et al., Stimulus History, Not Expectation, Drives Sensory Prediction Errors in the Mammalian Cortex.

This is from the Barrow Archives.

So the authors frame this in terms of predictive coding.

So predictive coding explains cortical responses in two ways.

a feedforward model where an internal model of expected events occurs, or in terms of an internal model of expected events, or a feedforward approach.

and a calculation of prediction error for unexpected stimuli or a feedback approach.

The latter are actually global oddballs, which defy expectations in a local context.

So in mouse and macaque, which are their two model organisms, they see two types of signal.

They see a normal response, where the internal model is matched by less stimuli, and a global oddball response, which emerges as a higher-order response to the storm.

We also can look at this non-linearity in terms of behavioral output in general, and then burstiness or non-normality of health.

So this paper, Burstiness of Human Physical Activities and Their Characterization and Quantifying Cholesterol Sway Dynamics Using Burstiness in Interim and Time Distributions kind of gets at both

this aspect of Markovian systems and a behavioral system that exhibits sort of nonlinear complexity.

Both papers focus on the burstiness of postural sway.

In postural sway, we have this paradigm where someone stands on a plate and that plate is a force plate that measures

or the center of mass of the individual.

And then we can measure this and we get this nice dynamical trajectory that has different features that we can analyze.

So it's a behavioral output that exhibits a lot of nonlinear characteristics and dynamical characteristics.

Takeuchi and Sano focuses on burstiness and postural sway in terms of adult housework and children's play behaviors.

They studied physical activities of children between ages two and five, and they found that burstiness is not an acquired feature, it's something that's innate.

Burstiness is present in healthy individuals, not in people with movement disorders or impairments.

They also looked at inter-event time distributions and associated fluctuations.

So we talked about inter-event times

as being key to Markovian and non-Markovian systems.

They found that they're bursty, so they're these stochastic signals that have a noise component, and sometimes this is a function of someone trying to maintain their balance, and sometimes it's just noise that's generated by the nervous system that's added to the stochastic signal.

In both cases, this is not goal-directed.

It's generated by a physiological system.

It's a very complex behavioral signal.

And it's not explainable by either a Poisson or Gaussian model, which means that it has this very complex set of features.

So if we do some experimental cybernetics on this, we can find that if we have the right internal model, we can produce some very interesting output signals or behavioral signals.

some of these kind of look like they could be teleological but they're not this is just simply running some stochastic say one example is just a pure stochastic signal the other one is having a stochastic signal with feedback that then takes that signal and integrates it at a later date so what we have here are two field forward processes one is a purely stochastic signal in blue on the left and then the other is a some signal that is stochastic the way of that signal or the

signal on the right so on the right we have the blue signal you can kind of see it under the red signal so the red signal is the one that's bursty and it's just basically where at random intervals we sum previous output and we add it to the present output so we end up with these bursts and so the delay which is this sum signal that we

that represent our bursts is the buildup of the input signal.

It produces these bursts or what we might call avalanches.

And so we can see that we can produce these nonlinear signals from a simple internal model.

So this is the classic Copiel paper from 1982.

It actually has a couple of interesting things to say of cybernetic oriented things.

So we have this feed forward, which is where you have a process that goes from A to B to C to D.

And we also have these systems that have strong back couplings.

So we have a process that goes from A to B to C to D, but then we have these back couplings from D to C, C to B, to B to A. And so what's more likely to be the case of actual sort of complex behavior is not the feed forward signal, but the strong back coupling.

And this is where we have ubiquitous feedback.

Strong back coupling can be intractable to analysis, but produces the most interesting aspect of network interactions.

And strong back coupling produces things like collective behavior, emergent properties, stochastic outputs, and nonlinear outputs or avalanches, which we saw in our

experimental cybernetics a few slides back we can think about feedback and we talked about this relationship between past present and future a few slides back and we also talked about maybe some of these types of behaviors that are non-random but maybe structured in a certain way and we can think about feedback just sort of revisit the idea of feedback that rosenbluth at all gave us which is that feedback was purposeful

so we can ask the question is feedback purposeful or simply non-random and so we can think of past present and future relationships as a trip around the feedback loop namely that we can take our input we can take the present and have a feedback loop that gives us past information into a new present when we get a new time point and that ends up giving us a future

that can then be recycled.

So this has implications for prediction.

We can go past, present, future to prediction, or we can have inputs that produce these sort of differently ordered past, present, futures and use that as the output.

So feedback mechanisms, reorder processes, systems with a lot of feedback aren't teleology per se.

Maybe they produce outputs that look teleological, but they're not teleological.

And so going back to the different orders of prediction, which were kind of like the final output of our behavioral typology, what are the different orders of prediction?

Well, we have our first, second, third, and fourth.

We're higher order feedback, so we can have these feedbacks that have past, present, future, but we can nest them together so that we can have

a past of a past of a past contributing to the present or to the future.

And so that's really interesting because what it's suggesting is these higher level feedbacks maybe are also not teleological, but there's some sort of memory or maybe there's some sort of, um,

you know, inter-event interval in the way it's structured.

So there's some structural aspect of feedback that might be really interesting.

That isn't teleological per se, but given some of these other examples, might have some structural significance.

So if we build a cybernetic model that is really kind of complex and has a lot of interlocked feedbacks and things like that, we can get some really interesting results.

so our different types of higher order feedback you know we can kind of think of these in terms of the derivatives of position so the derivatives of position revisiting that from undergraduate physics you have velocity acceleration jerk snap crackle pop and these are just where you start with velocity and you get a derivative of velocity which is acceleration

you get a derivative of acceleration, which is jerk, and so on.

And these can be thought of in this way of having these higher order feedbacks or these reordering as a past, present, future to give you these really complex dynamics.

In cases of derivatives of position and feedback, feedback, if it goes farther into the past,

the effects persist further into the future.

So if we go back a couple of feedback loops nested on top of one another and we introduce that to the new present or the new future, those effects persist further into the future.

So we get these really long-term effects in a dynamical system instead of just being local.

How does this translate into the neural correlates of behavior?

Well, we go back to our idea about behavior sort of being naturally teleological, and we have to think about like kind of how we kind of assume that behavior does magic things.

So if we get a behavior like this, entire order feedbacks, it tends to resemble the sort of magical aspect.

It could be something like emergence.

It could be something like

burstiness or something like a set of avalanches that occur.

And so these are things that, you know, give us really interesting dynamics but are no more sort of magical or teleological than any other kind of behavior.

And so more fully connected systems are perspective or might be sentient or conscious.

That's sort of the idea of those magic things.

So, you know, we don't want to misattribute sentience or consciousness to something that isn't.

And of course, this is something that we've had a problem with with modern AI systems, that people think they're sentient or conscious when in fact they just have this higher order feedback in this sort of

you know, behavior that isn't necessarily what people think it is.

Magic things or, you know, what we talk about, like complexity, results from embodied function.

A good example of this is kinematic chains, which we'll talk about in a little bit.

And now we introduce this concept of convolutional cybernetic architectures or CCAs.

And so we go back to our behavioral typology and we ask the question, can we better understand that we're

of purpose or meaning and feedback or temporal order.

So here we have active behavior, purposeful behavior, TOA logical behavior, and the non-classes of those are non-purposeful or random behavior and non-feedback or non-TOA logical behavior, respectively.

we're going to reorder this behavioral classification where now we have non-prediction leading to the order of complexity rather than prediction leading to the order of prediction so we start off with behavior that's active instead of passive then we have non-purposeful or random behavior instead of purposeful and non non-active or passive and purposeful are now non-classes

Then we have feedback, which is non-teleological versus feedback, which is teleological.

Teleological feedback is now the non-class.

Non-teleological feedback is now the path to the order of complexity.

And then instead of prediction being extrapolation, we'll have non-prediction, which is also extrapolation.

And then we have our order of complexity, first, second, and third order.

So the more feedback we have, the more complexity.

So this is an example of a convolutional cybernetic architecture.

We basically have this toy example where we have an input and an output.

The input is 000, the output is 111.

And we have these boxes which process

present to the future.

And then our feedbacks give us like some past state and it feeds it back to the future or the present.

So we have ubiquitous feedbacks here.

We have some feed forward elements.

We have elements of feedback that do certain things to the sequence.

And the question we ask here is what is the maximum number of steps needed to transform the sequence from zero, zero, zero, one, one, one.

So we start with 0, 0, 0.

We put that in.

We kind of move to our feedback loop.

Our feedback loop does certain things

to the sequence, and then we end up with 1, 1, 1.

We actually want to know what the maximum number of steps is because we want to know, you know, how far we can go through these different feedback loops and get our answer.

This can also be restated in terms of temporal phases, past, present, and future.

So we also have more explicitly this input of the present

We have the future as an output.

And then we have these different loops that give us past information.

And again, we're interested in getting the most diverse information possible.

And so this is, again, this maximal loop that we're looking for.

So we're trying to get the most variety out of these convolutional cybernetic architectures instead of trying to find the most efficient path or the tightest path or the most goal-directed path.

We can further understand this or restate this in terms of semantic components.

So we can talk about this in terms of symbols, reference and understanding, symbol being the input,

reference being the feedback or part of the feedback loop, and then understanding being the output.

And so we want to accumulate as many references as possible for our symbol so that we get an output of understanding.

And again, it's the variety that counts.

not optimizing the process or trying to find a goal directed aspect to this.

So we think about how these CCAs are assembled.

We can look at the different components of feedback and then we can start to assemble these more complex structures.

So let's look at first order feedback.

So CCA has input.

And in this case, we're looking at past, present, future and maybe alternative futures and things like that, and they all produce a predictive output.

So first-order feedback would be an input going to a future, going to the present, and naturally the future is just like the present plus the past, so the present comes in as input.

It's passed to this feedback, which is the past.

The present and past are added to the future, and then the output is some sort of predictive input.

So again, we have this reordering of past, present, future in the first-order feedback.

If we have a feedforward-only case,

we have input, which leads to the present, which leads to some complex output.

But of course, as a feed-forward only system,

We just only get the benefit of having the present.

We don't get to talk about the past and the future.

It's just like every input results in an output, and that output then is complex output within any context.

Then if we put together a larger set of feedback loops, we can see this sort of convolved mixed feedback, where we have first-order feedback, second-order feedback, and a feed-forward component.

So these are all different components producing two different complex outputs.

So we have an input that gives us the present.

We get a first-order feedback that gives us some past, and we add those together to a future state that produces complex output.

We can also have a feedforward part of that, where the input goes to the present, and then the present is a part of that state.

And then we might have a second-order feedback where we have an input, which is the present.

It passes a first-order feedback loop to the past and another first-order or second-order feedback loop to the past.

And those can both be combined into the present, which is then informing a future state, which involves a longer memory, which has more information.

And that gives us another complex output.

But we also have this path from the second-order feedback up to an alternative future, which then gets passed out as a complex output.

So you see what we have here is we have an input that goes to the present.

We sub-reference the past.

We sub-reference the past again, and that gives us an alternative future.

So this happens for every cycle.

So you end up with these three different types of complex output.

And given this topology, we can end up with these different types of characterizations of the system.

Remember, again, with this convolution, what we're introducing is this variety, which is actually a concept from the Evergood regulator theorem.

and a lot of the work of W.R.

Ashby.

So we're dealing with producing the maximum amount of variety.

So we need variety to control systems.

So this is actually, overall the appearance of purpose is replaced with an ensemble of positive and negative feedback elements with diffuse effects.

So remember that we need to have not only a single closed loop feedback, but we need to have multiple feedbacks and maybe some open loop feedbacks in there.

so we can have maximize a variety so the imperatives of such a network are to gain processes or to maximize the number of processes and this leads us to maximizing variety and of course variety was a concept that was introduced by W.R.

Ashby in the Everton Regulator Theorem and he talked about how variety is necessary for control

but it also creates the conditions for adaptability, modularity, and modifiability.

So we have systems that are both not purposeful, but they also have this sort of imperative for control, but also for other types of conditions in a system that allow it to adapt.

be modular, and be modifiable.

And so we can also add in polarity.

We can have different types of effects resulting from feedback.

As we talked about, if we reorder past, present, and future,

That's all well and good, but this also has relevance to different types of processes that result in systems.

So in complex systems, we have these different effects like avalanches, runaway feedbacks, and dampened feedback.

These are non-linearities.

And we saw an example of avalanches earlier.

in our experimental cybernetics and that can result from a number of feedbacks of different polarity and this can produce unpredictable instability

We can have things like runaway feedbacks, which are basically just the product of positive feedback, and that can lead to mass instability.

And we can also have something like dampened feedback, which is a negative, overly negative feedback, which sometimes makes things more controllable.

And so we can have these effects that result from these processes that have a polarity that lead to these different complex systems phenomena.

that then lead to things that are maybe look they look purely illogical or purposeful but they're actually just the products of complexity and so if we kind of go back and look at like how we can model things like connectionist learning and reinforcement learning with cybernetics we can actually take the equations of connectionism and reinforcement learning and put them into this sort of cybernetic system so this is where you know we want to take

modern learning systems or artificial learning systems and understand them using cybernetic approaches and maybe apply them into these kind of CCAs.

And so this is congruent with Hopefield and Sutton's alternative viewpoint.

which is that the weights of a network are reinforced by the activity and selection of previous inputs.

So this is where we have, we're looking at Q-learning here, and we're looking at connectionist learning, and we're looking at sort of the widths, equations are structured, and we're thinking about how, you know, we can get learning from these

uh systems of equations and you know this is a dynamical system you know as much as a learning system so we want to understand kind of how this is how this works and so we started a random set of weights and like structured due to selection

We start at a random set of weights and lack of structure due to selection.

We proceed to a structured set of weights and optimal policies.

Unwittingly, we kind of move from a Markovian system to a non-Markovian deterministic system.

And so there's a trick question here, which is how do we go from something that does not resemble purpose

something that is purposeful?

The answer is that purpose is a post hoc determination.

So we can model this as habits with weights.

So we have this input, we have these outputs, and we have this CCA that has polarity.

And we can have habits that serve as the inputs, and the weights are the polarity.

And we have non-teleological behavior in a directed graph.

So this directed graph kind of moves towards the endpoints, the outputs,

And so the lesson here is that purpose is basically whatever we determine these outputs to be.

So when we observe a behavior, a behavior is generated by these CCA graphs.

We interpret the output the way we'd like to interpret it.

And as I said before, we can have these different outputs that look purposeful or they look purely logical, but that's just really a post hoc determination.

Then we move to Weiner's alternative viewpoint.

more of a cybernetics guy, and he also has an alternative viewpoint.

And his viewpoint focuses on communication and information, which have both a control layer and a semantic layer.

So again, we have to go back to the past, present, and future formulation.

So instead of thinking about this in terms of polarity, we want to think about this in terms of not just the control, but the semantics as well.

And so we have

this past present and future we have an input which is the past we have a future which is the present with past feedback we have the present so the present goes to the past goes to the future but the future also moves to a present where there's a present with past and future components and then an output so if we run this in time if we run this as a dynamical system we end up with this the present being sort of

know it's not really additive but it's basically you're concatenating things on the present with information from the past and you're informing a future trajectory and you're you can actually generate alternate futures of the system from this and so this there's a control layer a semantic layer and this gives us information about the system

both in terms of contingencies and synergies.

So connectivity and ordering provides both contingencies, which is that nodes depend on other nodes, and synergies for nodes working together.

So in this model, we can't knock out any one node and have the system work.

We can't knock out the feedback and have this sort of rich self-reference.

We can only have a feed forward model and we've seen that that's much less interesting.

We also can't knock out the future and we can't knock out the present.

We have to kind of continue with all of our nodes

But also these nodes working together produce this synergistic trajectory that gives us rich information about time.

It gives us this present, it gives us a future, but it also gives us these intermediate states where we get past feedback and we get integration of those.

This stands in contrast to the imperative of purpose in teleology.

Is cybernetic control and behavior purposeful?

Or is stochastic activity tempered by recursively recombined temporal ordering?

And so this is, again, one of the CCAs.

And a CCA is also a series of steps that add recursive functionality.

So sometimes if we think about this in terms of our internal model memory, this is memory with sub-referential power.

So it allows us to have a memory again where we can reference the past of a past of a past and it informs the future of the present and adding present into future and things like that.

This creates a hierarchical system and high degrees of intentional order.

So again, we can add these things together or we can run these CCAs and we can produce this memory with sub-referential power and the output can look very organized and hierarchical.

But the thing that produced that output is not necessarily ordered, and it's not necessarily, there's no overarching goal or any other sort of information going into it.

So once again, thinking about habit and purposeful behavior, we have this paper, Creatures of Habit, the Neuroscience of Habit and Purposeful Behavior.

This was published in Biological Psychiatry.

This is where they talk about animal behaviors being composed of habitual and goal-directed categories.

Habitual is non-teleological, but goal-directed is teleological.

They provide this sort of breakdown where you have teleological versus non-teleological behaviors and deterministic versus stochastic behaviors.

We think about teleological and deterministic behaviors, we get goal-directed behaviors.

Those are things like reaching for a target or...

moving towards a goal but of course we know that some of these types of goal-seeking behaviors are chemo like chemotaxis or phototaxis are stochastic and so if we have teleological and stochasticity we might have something like chemotaxis or phototaxis we have something that's non-teleological and deterministic we have habitual

So we have something that's habitual.

It's not moving towards a goal, but it's deterministic.

Something like scratching or like a reflex.

If you have non-teleological and stochastic behavior, however, we know that that looks something like a random walk.

So we can actually characterize these different behaviors on this one.

The problem with chemotaxis, and I put a question mark on the table.

So chemotaxis, for example, which is a movement along a chemical gradient, we already established that that was not teleological.

The goal-directedness in that case is due to the environment, not the internal model.

And so we can look to gibsonian information or we can look towards sort of thinking about why it's not teleological.

But it also doesn't resemble a random walk.

So that provides us with a problem, which is where does this fit into this typology?

So a clue to kind of where chemotaxis and phototaxis fits into that typology

comes from this paper, Brain-like Neurodynamics Through Behavioral Control Develop the Reinforcement Learning.

And this is from the bioarchive from this year.

Kotel et al.

tests two scenarios, supervised or extant, and reinforcement or developmental learning.

So we have extant and developmental learning.

Only reinforcement learning produces goal-directed behavior and neural activity similar to biology.

It provides robust short-term behavioral adaptations to perturbations

And it produces an emergence of policies that are not purposeful in and of themselves, but lead to things that look the part.

So this is reminiscent of our CCAs.

It's also reminiscent of our discussion of chemotaxis and phototaxis.

Building a CCA from a small motif is a form of purposelessness or purposelessness reinforcement.

You build up to function and sometimes useless structures, and that's okay.

Another example of non-purposeful behavior that kind of fits into our CCA model comes from fetal substrate cycles in biochemistry.

And so this is the paper of stochastic amplification and signaling in enzymatic fetal cycles through noise-induced bistability with oscillations.

This is from PNAS.

So this is where we describe these futile cycles as these feedback loops where you have an input of energy.

There's an enzymatic reaction and you get nothing that comes out except entropy or heat.

So you basically don't have an output.

Your output is entropy.

It's heat.

And of course, this is a problem because we expect there to be an output.

We expect this reaction to actually do something.

And in fact, it's creating heat, but it seems like that's a lot of work for just heat.

So we have a biochemical pathway, which is a closed loop feedback.

It does thermodynamic work for no reason.

Heat is produced through an energetic input, but we don't get any biochemical products.

And this seems like it's a waste of energy, that it has no purpose, but it's actually important for regulation and other processes.

It produces complex higher order dynamics or amplification effects throughout a greater biochemical system.

So if we go from convolution to order, we can see that the evolution of cybernetic control is a causally recursive chain of contingencies.

And so here we look at the contingencies in a CCA.

We go from one to two to three.

and then that's a feed forward system and then we can go from one to two to three prime to four which it feeds back to two and gives us this output four prime or we can go from one to two to three to four there's one to two to three prime to four to five to six to seven which is an output so we have these different outputs from these different numbered boxes and we have these resulting processes

So let's take 3' as an example.

3' is dependent on 2 and 1, and once feedback is operational, 4 and 5.

So 4 and 5 actually do feedback to 3', which of course is a dependency.

So if you knock that dependency out, you lose your entire functionality of that part of the network.

7, on the other hand, which is another output at the top, is dependent upon 6, 5, 4, 3', 2, and 1.

There's no feedback from delay.

So you can see the different types of order and how there's a lot of recursive chains that lead to contingencies.

So again, if we think about our feudal cycle, our feudal cycle is like something at the bottom.

Our herald or feedback is like something at the top of this diagram.

And our alternate outputs are at the right.

And they are, of course, maximizing for variety.

And so if we think about the evolution of cybernetic control as a causally recursive chain of contingencies, we can think about the kinematic chain, which is where we have these dependencies.

So D is affected by the activities of A, B, and C. We get this chain.

This is this robotic arm that extends out across two joints.

and the activity in d with kinematic is constrained by a b and c and so we can describe it in that way if we go back to these kinds of contingencies we know that seven is constrained by its intermediates and thus it is with the kinematic chain in in the kinematic chain we can do this in a linear fashion we can add on conditionals as convoluted cyber as the convoluted cybernetic network evolves

This restricts the system to a deterministic path.

Behaviorally, this leads to interesting consequences for developing sensory motor loop.

And a kinematic chain is basically sensory motor physics with contingency.

So here are examples of a kinematic chain in robotics that we can think about.

embodied robotics here where we have these control systems for these kinematic chains, maybe a CCA where we have different types of morphologies, and we can design them appropriately.

We can design them appropriately.

We can design behaviors that aren't purposeful, aren't teleological, but still give us behaviors that look intelligent.

You can also think about purposeful behavior in 4E cognition.

So our approach to purposeful behavior

can be applied to 4E cognition.

So we have these different types of cognition, some of them being embodied, some of them being embedded, some of them being extended, which means outside the brain, and some of them being inactive.

If we put this in the framework of Rosenbluth et al.

's behavioral classification, does 4E force us to rethink that behavioral classification as we did in a

number of instances in this talk.

Now there's one insight of 4E that's interesting to us, which is that the morphology and environment of a system is more important than its internal model.

So we've been talking about internal models and how these CCAs model the internal state of behavior and how that shows that in a lot of cases teleology and purpose are sort of illusory.

But if morphology and environment are more important than the internal model,

then maybe we need to incorporate our CCAs or recast our CCAs in terms of morphology and environment as well as an internal state.

And in fact, our CCAs do that to some extent, but it's sort of a way to put this behavioral classification on its head.

And so in the case of 4E, purpose is not ascribed to a mind.

Feedback is diffuse and complex.

Prediction in its highest orders are not teleological.

They must be open-ended.

We talked about this in a paper from 2023, MRL Society Interface Focus.

So what is behavior?

What are its properties?

So yeah, we're kind of revisiting what Rosenbluth talked about.

We're looking at a number of examples from neuroscience and from psychology and from other areas, animal behavior, robotics.

And we kind of break down kind of what we're looking at here.

Behavior can be intentionality.

It can be goal-directed and supervised.

And so these are things like control systems, pair-order cognition.

And of course, some of those are goal-directed.

Some of those are regulated complexity.

Then we have rich, higher-order, complex dynamics.

And those are things like BZ reactions, which we talked about.

And embryogenesis, which we didn't really talk about, but also qualifies in that category.

So these are outputs of dynamical systems.

We also have connectivity and convolution, which are things like connectionism, avalanches, and open-ended learning.

And then finally, we have behaviors that are hardwired but recursive.

So with our CCAs, we're modeling some hardwired behaviors in a recursive fashion.

We also talked about this in terms of non-Markovian systems and habitual behaviors.

We want to go beyond the standard of teleological and purposeful behavior.

So a standard way of thinking about behavioral regulation is that inputs are deterministic and outputs or collective outputs should be closed-ended.

So if we expand the basic

feedback model, we get an interconnected network of retro-causal ordering.

So this is something that we're seeing in the CCA where we talk about the order of causality, past, present, future.

We have this basic causal feedback model, but if we expand that out, we get much richer retro-causal ordering, which leads to, of course, to variety, but it also leads to these interesting paradoxes and interesting effects of higher order feedback.

Behavior is often open-ended, and this can be characterized by embodied dynamics, unpredictable, which can be characterized by chaotic dynamics, non-normal, which can be characterized by non-Markovian behaviors, consistence, avalanches of different types, power law dynamics, and so forth, and variational, which means that it's characterized by multiple goals and redundancies.

And so this requires a reassessment of Rosenbluth and his typology and has wider consequences for the practice of active inference.

Thank you for your attention.

One of our co-authors, Jesse Parent, produced a lengthy blog post on the Rosenbluth et al.

paper, talks about its enduring insights and its context in cybernetics.

And then we have two papers we talked about in the talk from our group, Allostasis Machines and A Primer in Gibsonian Information.


SPEAKER_01:
So I thank you for your attention.