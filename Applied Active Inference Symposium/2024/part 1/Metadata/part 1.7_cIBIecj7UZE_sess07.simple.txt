SPEAKER_00:
okay welcome back welcome back hi denise thank you for for joining and looking forward to your presentation so take it away oh thank you so much and thank you for having me today um today i am going to talk about the potential impact of decentralized ai through active inference and spatial web technologies

And what we're really going to be discussing is the potential aspects of this next era of computing.

It'll be incorporating a lot of the research that you're hearing about here over the next three days.

And in my talk, decentralized AI is taking a main focal point here.

And there's a couple of aspects in technologies that are evolving right now that I think it's really important to be aware of.

um and they factor into uh what i'm going to be talking about today so one of the main uh things that is occurring right now is our internet is evolving we have a new protocol layer that's layering right on top of the other protocols that are part of the same internet that we're talking across today the difference is is what these

protocols, HSTP hyperspace transaction protocol and hyperspace modeling language is the programming language.

What these are going to enable is for us to have programmable spaces.

So instead of just programming pages in domains with content, we are going to be able to program digital twin spaces of anything.

And this is going to enable context to be baked into everything in every space.

So all of the attributes about various things in various spaces and nested ecosystems and all of their interrelationships to each other.

So one of the things this is going to enable is active inference agents to be distributed across our Internet.

And I see this as the next wave of innovation.

And through active inference, these agents will be aware of each other and the network.

They'll be able to sense the world in real time and learn from each other.

And this is going to provide unprecedented levels of interoperability.

So what we're talking about here is first principles, automated systems, and distributed collective intelligence.

So first, let's look at the challenges in traditional centralized AI structures or architectures.

Centralized processing constraints, you have high energy demands and scalability issues, limited adaptability to real-time changes, and we're all familiar with the limitations of

these deep learning models.

They require massive amounts of labeled data and processing power.

They have limited ability to generalize across different tasks and environments.

AI models lack adaptability to real world complexity.

They're only good for one thing at a time, optimized for one type of an output.

And they lack interpretability and transparency in decision making.

They have high computational resources leading to high costs and inefficiency, and they struggle with generalization across different scales and tasks.

Now we need decentralized AI and decentralization really matters because it increases resilience and scalability for autonomous systems.

It reduces reliance on central servers and data hubs, and it enables autonomy across distributed networks.

So this bridge is the gap in AI.

We move beyond centralized AI for scalable autonomous systems that can operate independently and locally.

Now, we're all familiar with this guy here, Dr. Carl Friston, and he gave a great talk first thing this morning on

renormalizing general genitive models.

So what I'm going to be talking about are various components in some emerging technologies along with active inference that potentially realize this research paper designing ecosystems of intelligence from first principles.

Now,

You know, this paper was published in December of 22, and it really laid out a new framework for autonomous intelligence that mimics self-organized systems of nested intelligence found in nature.

And in this paper, it described a cyber-physical ecosystem of natural and synthetic sense-making in which humans are integral participants, what we called shared intelligence.

And in the paper, it says this vision is premised on active inference, a formulation of adaptive behavior that can be read as a physics of intelligence, and which inherits the physics of self-organization

And in this context, we understand intelligence as the capacity to accumulate evidence for a generative model of one's sensed world, also known as self-evidencing.

And at the end of the abstract for this paper, they also note, we also consider

the kinds of communication protocols that must be developed to enable such an ecosystem of intelligences and motivate the development of a shared hyperspatial modeling language and transaction protocol as a first and key steps towards such an ecology.

So what I'm proposing in this and what is proposed through all of this technology together with all of the various parties that are involved in building these components is that the future of AI is shared, distributed, and multiscale, an entirely new kind of autonomous intelligence able to overcome the limitations of machine learning AI.

And as we know from understanding active inference, this AI is knowable, explainable, and capable of human governance.

And it operates in a naturally efficient way.

There's no big data requirement.

And it's based on the same mechanics as biological intelligence.

It learns in the same way as humans.

So what I want to do is start with the Spatial Web Protocol first, because this is kind of the framework for these agents to be able to have this distributed intelligence structure.

So what is the Spatial Web Protocol?

It's just the evolution of our internet into spatial domains.

So people refer to it as Web 3.0.

It's just the next evolution of the internet.

But this protocol has become a global standard, a new global standard.

For the last four years, this standard has been in development with the IEEE, which is the largest core standards body in the world.

Back in 2020, they deemed the Spatial Web Protocol a public imperative, which is their highest designation.

And this summer it was voted and approved as the new global standard.

And it's in the final administrative cycle with the IEEE before it becomes public.

So there's a couple of things that are happening with this.

Through HSML, the programming language for this new protocol,

All emerging technology, whether it's IoT or AR, VR, distributed ledger technology, all of these technologies, they're all going to be able to converge across the internet because they will have a common language for interoperability.

And in that, you also have a language that AI can understand.

and communicate together and communicate with these various aspects of technology as well.

So this is going to produce the next era of computing and Deloitte called it back in 2020.

So it's the next evolution of the internet and it's going to be empowered by active inference AI.

now just to kind of understand what this means for the internet let's take a look at what a website domain is today with the world wide web a domain basically contains a website and these websites they serve up content so whether it's you know images or video or audio or you know information data um that is what websites are capable of of doing

Now a spatial web domain is quite different because a spatial web domain could be anything in any space, right?

And it can be programmable.

A spatial web domain is an entity with a persistent identity through time that has rights and credentials.

So you're talking about going from a library of pages in our internet to the internet of everything.

And HSML becomes a common language for everything.

So it provides unprecedented levels of interoperability between all current emerging and legacy technologies.

It's a programming language that bridges communication between people, places, and things laying the foundation for a real time world model for autonomous systems.

And what you have are programmable spaces.

HSML is a cipher for context.

Anything inside of any space is uniquely identifiable and programmable within a digital twin of Earth, producing a model for data normalization.

And from this we get adaptive intelligence automation, security through geo-encoded governance, multi-network interoperability, and it enables all smart technologies to function together within a unified system.

And then this produces a knowledge graph and digital twins of anything, everything.

potentially our planet.

So as this knowledge graph grows within the programming of all of these spaces across the network, you get this universal domain graph that enables a digital twin of our planet and all nested systems and entities within it.

We get nested ecosystems.

There will be intelligent agents, both human and synthetic, across this network.

They will be sensing and perceiving continuously evolving environments, making sense of the changes, updating their internal model and what they know to be true at any given moment, and acting on the new information that they receive.

So why do we need a spatial internet protocol?

Well, the increasingly graph-like nature of global data, the opportunity for automation and autonomic activities using context-aware cognitive AI, the need for composable systems and applications including the governance of such systems,

the intrinsic need for secure transactions, the rise of machine learning and neural network computation and edge computing, the need for explainable AI and robotic governance, and the rise of IoT and sensor mesh.

And some of the guiding principles of the spatial web standards are spatiality, representing information as locations and relations in hyperspace,

Ownership, users own their data and digital property.

Security, secure data collection, transmission, and storage.

Privacy, individual control over digital identity and personal data.

Trust, reliable, permission-driven validation of users, assets, and spaces.

interoperability seamless navigation and asset transfer across spaces and responsibility creating technology ethically for the benefit of humanity and what what has become of these global standards is a socio-technical standard so the spatial web is a socio-technical system of systems uh takes into the account the um

So the development of the spatial web must address both technological as well as sociological considerations.

Sociotechnical standards integrate and balance the technical, social, physical, and legal use of technology.

And the spatial web standard is a sociotechnical standard.

And what this results in is multiple scale cognitive computing.

So the spatial web plays the role of a collective nervous system for smart infrastructure.

It hosts cognitive computing, inference, perception, learning, and action selection.

By combining and abstracting distributed information, the spatial web enables the formation of complex ideas and facilitates decision-making.

Cognitive computing occurs at multiple scales in the spatial web.

Individual nodes host cognitive computing functions, and networks of nodes collectively perform emergent cognitive computing.

So HSML, hyperspace modeling language, it's a human and machine readable modeling language and semantic data ontology schema.

There are some key elements to it.

There are entities, activities, agents, contracts, channels, credentials, domains, and it includes hyperspace and time.

So, HSML enables the expression and automated execution of legal, financial, and physical activities in the spatial web.

All of these entities are identifiable and knowable by these intelligent agents through this language throughout the network.

Now let's look for a second at the agent aspect, agents and activities.

So agents, and that can be human agents or synthetic agents, but these agents are entities that sense, respond, maintain a model of their environment, and take actions to achieve goals.

And the activities that occur, they're single actions or partially ordered sets of actions that are performed by the agents and they unfold over time.

So agents interact with domains and other agents to perform activities in the spatial web.

So what the Spatial Web facilitates is a distributed ecosystem of intelligence.

If you look at current state-of-the-art AIs, they're siloed applications, they're built for optimizing specific outcomes, and they're really unable to communicate their knowledge frictionlessly and collaborate with other AIs.

But this facilitates an ecosystem of intelligence that is a self-evolving system.

It's learning moment to moment and upgrading its world model.

And in that way, it mimics biology while also enabling general intelligence.

So this is shared intelligence at the edge of everything.

So how active inference works in the spatial web, it enables real-time decision-making.

You have agents that are predicting and adapting to their environment from their frame of reference in the network.

They're continuously learning from their environment, enabling real-time adaptation.

And unlike traditional AI, which relies on pre-programmed rules and static models, Active Inference continuously updates its models based on new data, allowing it to adapt in real time.

So these Active Inference agents would seamlessly communicate in real time with each other, sharing their knowledge and perspectives and learning from each other.

These active inference agents excel in handling complex, uncertain environments by continuously minimizing uncertainty.

In fact, they can quantify their level of uncertainty, and this makes them suitable for applications where conditions are constantly changing.

So decentralized AI

takes the processing to the edge, to the edge devices.

You have a distribution of processing and power.

Superpowered GPUs are not required.

The processing can take place on local devices throughout the network with infrastructure that already exists, like your laptop or your mobile device or devices that haven't even been invented yet.

But we're already seeing a lot of those kinds of devices coming into play.

with Apple Vision Pro and the metal glasses and different aspects of these technologies.

The processing takes place on these local devices throughout the network.

You have faster response times and reduced network congestion, and it uses real live data, real time data from IoT sensors, machines, and ever changing context that's embedded in the network.

So this is the sensory information that's coming in for these active inference agents so that they can, you know,

do the perform this action perception feedback loop and continually update their model of the world of their environment from their frame of reference and it eliminates the need to tether to a giant database active inference agents throughout the network learn and adapt from their own frame of reference within the network

enhance data privacy by minimizing centralized storage, and it minimizes complexity.

It uses the right data in the moment for the task at hand.

And with HSTP, with hyperspace transaction protocol, there's natural guardrails included in this framework.

So it creates a secure, ethical, and user-centric environment for AI applications, fostering trust and reliability in digital interactions.

You have data privacy and sovereignty, transparency and explainability, security and authentication, bias mitigation, ethical AI guidelines, interoperability and standardization, user empowerment and control, accountability and governance, safety and reliability, dynamic policy enforcement.

And what this results in is an intelligence at scale through this network of distributed intelligence.

It enables the cognitive architecture of the collective intelligence of multiples of agents that continuously communicate, coordinate, and collaborate with each other.

You have individual and specialized intelligences together on a common network, speaking a common language , efficient and powerful cross communication to perform tasks, regulate systems,

and address problems in real time, and it scales up and grows in tandem with humans.

Through HSML, we can take human laws and guidelines, make them programmable for these agents to understand and abide by in real time.

So we're talking about unprecedented levels of cooperation between human and machine intelligence.

And what you get then is an ever evolving collective intelligence.

Decentralization is an imperative for intelligence at scale.

These agents represent scores of people from all over the world sharing their individual and specialized knowledge.

all coming together on a common network.

It's based on each agent's own world model.

You have unique perspectives from whatever frame of reference within the network, nested ecosystems and levels of self-organization, and collective shared intelligence.

The idea is that anybody can impart their knowledge and their wisdom into these agents

from wherever they are in the world and this actually acts to preserve all of the uh cultural differences all of the um the belief differences the governing styles um you know people whether they're in kenya or singapore or anywhere else in the world they should be able to create these agents to solve their local problems and then share that with the world because then these agents can share

their intelligence with each other so the spatial web protocol enables a decentralized secure and interoperable web with the potential to profoundly transform global industries and everyday human life now let's dive into um

kind of the potential that exists for this idea of RGMs, these renormalizing generative models, and the spatial web.

We heard a great talk this morning by Dr. Friston.

He talked a lot about the science behind these RGMs.

I'm going to kind of maybe break down some of the aspects of how these work

as leading up to then what they can do potentially within this architecture.

So with our GMs,

One of the interesting things is that it's a universal architecture.

They're a unified scale-free framework for AI that's capable of reasoning, learning, and decision-making.

And they can generalize across multiple tasks, handling small and large-scale data efficiently.

They combine perception, learning, and planning into a single system.

And they can be used to learn scalable architecture over space and time.

similar to human thinking.

They require significantly less training data than traditional models while achieving superior results.

So what are these RGMs?

They're a new class of AI models based on active inference.

They use renormalization to simplify complex data into hierarchical structures, and they operate on the free energy principle to minimize uncertainty and adapt in real time.

So the significance is that they represent a leap forward from traditional deep learning methods.

They reduce data requirements and improve efficiency.

And it's one single framework for all applications.

The science behind RGMs, renormalization, and multiscale learning.

Renormalization is a technique from physics that's used to simplify complex systems to maintain consistency at different scales.

And RGMs break down data into multiscale representations.

hierarchical structures, RGMs are actively learning from small details to large patterns simultaneously.

And they analyze like with an example would be like an RGM can analyze an image by recognizing edges, then objects, then scenes, and understanding the concepts at every at every scale.

So key innovations and advantages of RGMs, why they're superior to traditional models.

They learn efficiently with less data.

It's a unified system that handles perception and planning simultaneously.

And they understand conceptual relationships, not just patterns.

And they can adapt to new environments with minimal training.

Aspects of them are scale-free modeling, renormalization,

discrete representation, hierarchical structures, fast structure learning, unified perception and planning, and explicit handling of uncertainty.

So if you look at how the brain processes data,

We perform core screening all the time when we're learning, right?

We break down sensory data into hierarchical patterns that help us focus on the most relevant information, kind of this chunking of concepts to grasp different aspects of whatever it is that we're learning or focusing on in the moment.

And RGMs can mimic this approach by processing data hierarchically, focusing on important patterns.

So it's a first principles approach using a way to simplify models without losing important information.

They can model space and time dimensions like we do and can learn the causal structure of information.

And it helps handle large scale problems efficiently using less data and less energy.

Now, when you consider scale-free modeling,

Scale-free modeling, these RGMs, they operate across different scales.

So from very fine details to high level complex systems.

So unlike deep learning, which struggles when moving between small and large scale problems, this scale-free architecture allows RGMs to seamlessly work on a variety of problems, including small data problems and large scale strategic planning.

So when you're thinking of the concept of scale-free,

This is a great example here of a green apple.

You can see the green apple as a concept of just pixels in an image or a volumetric object or on a branch on a tree or in an orchard.

And the way that these RGMs can model these conceptual understandings of things is it can understand all different scales of what a green apple is.

When you think of the supply chain or factory operations or anything like that, these agents can understand what's happening across the manufacturing line on a very local level, but also what's happening across the entire distribution line throughout the entire system.

They can predict both short-term movements and long-term outcomes.

you know, the fine details as well as larger outcomes with the high level complex systems all at the same time.

And they don't lose accuracy when switching between local and global data scales.

so hierarchical modeling in rgms hierarchical data processing rgms process at multiple levels of abstraction from fine-grained details to high-level concepts they use recursive learning they continually loop over data learning at each level continually refining their understanding of concepts as they process new information and

you get hierarchical representations that they build models of the world by zooming in and out of different layers of detail and this is similar to how human cognition processes both micro and macro scales so you know think about when you're when you're thinking about

concept of driving a car if you're talking to somebody about driving a car or you know you're you're focused on the aspect of driving you're not thinking about the car as all of its various parts that make up that complex system like the brakes and the steering wheel and the seats and the every aspect of the engine you just call it a car right because that's all you need to know in the moment for whatever whatever your

doing with that concept and so this is kind of a similar idea and this layered approach allows rdms to understand complex multi-scale problems without requiring vast data sets so conceptual modeling for decision making

Um, RGMs then focus on conceptual modeling versus just mere pattern recognition.

Um, deep learning can recognize patterns, but struggles with conceptual understanding.

It can recognize correlations without understanding relationships.

And it can recognize patterns, but it doesn't understand the underlying meaning.

And RGMs, on the other hand, focus on conceptual modeling.

They capture multi-scale hierarchical structured concepts that represent both fine-grained and abstract features.

It builds a hierarchical understanding of the world, capturing cause and effect relationships.

So RGMs understand the why behind patterns, not just the what.

and the key difference rgms are not just a better generative ai but a transformative ai framework that builds a hierarchical understanding of the world rgms can reason about cause and effect relationships making decisions based on conceptual understanding that are more aligned with real world outcomes so how do rgms leverage active inference

by incorporating active inference, active learning, and active selection while incorporating real-time data to adapt its predictions and actions.

So what you get is real-time learning.

They adjust their beliefs based on new sensory input, making decisions on the fly, optimizing both learning and decision-making processes.

And they also are able to have unified perception and planning so deep learning typically separates perception like recognizing an object from planning like deciding an action.

RGMs can combine both in a unified model.

They handle both within the single model and learn concepts that guide both recognition and future decisions.

So for example, you can have an autonomous robot that can recognize a door handle and also plan how to open it using the same model.

So what does all this have to do with the spatial web architecture?

So the potential that I see with RGMs is that the nature of how they work fits very well with the nature of this architecture within the spatial web.

And just to kind of bring you back to what I was talking about earlier, you have hyperspace transaction protocol.

This manages data flow between interconnected systems, and it facilitates interoperability between different AI systems.

and the hyperspace modeling language provides a common language for these systems enabling computable context and decision making and it provides a shared framework for context aware decision making so this protocol aims to create a standardized way for different technologies and ai systems to interact and share information across programmable spaces within our global internet

And this unified model, this becomes a unified model for diverse applications, handling complex multi-scale systems through unified perception and planning.

It's a single framework that can handle multimodal tasks.

So you have versatility.

They can perform across multiple applications, whether it's object recognition, natural language processing, strategic planning, using a single universal model, and it reduces the complexity.

It integrates the data analysis, the perception, and the strategy execution, which is the planning within one model.

So you have cost savings.

It reduces the need for multiple specialized AI models.

It streamlines system management and saves resources.

So how the spatial web enhances the RGM capabilities, the combination of this scale-free active inference with the spatial web protocol could enable seamless integration of the physical and digital.

These protocols allow RGMs to operate across distributed networks.

exchanging insights and information between physical and digital environments, enabling more sophisticated IoT applications.

Context-aware computing through the spatial web, RGMs would operate in context-aware environments.

These agents adjust their behavior based on the physical and digital surroundings.

And interoperability.

Multiple RGMs, these active inference agents and autonomous systems, can operate in different environments, whether it's your home, smart city, businesses, and they could communicate, collaborate, and coordinate actions through the hyperspace transaction protocol.

They're energy efficient distributed intelligence.

Instead of relying on centralized energy intensive data centers, intelligence could be distributed across networks of smaller, more efficient devices.

And this creates a nested ecosystem similar to a Holon architecture.

And if you're not familiar with what a Holon is, it's something that can be both a whole in and of itself and also part of a larger system.

The spatial web and RGMs would form a nested ecosystem where each node in the network, whether it's a domain, device, agent, or subsystem, functions as a holon.

It's autonomous, yet interconnected, contributing to a larger system's goals.

as part of the larger interconnected network, like a smart city infrastructure.

Your smart home could contribute data to your neighborhood grid, which informs the city infrastructure decisions all while functioning independently.

If you look at this picture here of part of

a supply chain image, you know, each item packed inside of each of those boxes is a whole in and of itself, but it's subject to and it's part of the larger system, the box, the box is subject to the trucks that are moving it and distributing it, or, you know, whatever's happening within the factory with those boxes, and then that factory itself

is its own whole that is subject to a larger ecosystem of the entire supply chain as a whole.

So when you're looking at what this next era of computing really enables, it's just nested ecosystems that can be empowered by this natural intelligence.

And Active Inference AI and the Spatial Web Protocol can work together to create sophisticated, adaptive systems at various scales.

So RGMs for autonomy and self-organization.

With recursivity, the scale-free models naturally form a nested hierarchy.

Each level of abstraction in the model is complete in and of itself, and yet part of a larger whole.

Autonomy and cooperation.

Active inference agents exhibit both autonomy in their decision-making and the ability to cooperate with other agents.

and self-organization the renormalization technique in introduced in the paper allows the system to dynamically organize information at different levels of conceptualization similar to the self-organizing nature of uh holonic systems or these in these nested ecosystems so

This last part, I want to explore the transformative potential of decentralized AI for the future of intelligent systems.

So the impact of distributed collective intelligence, the impact on this next era of computing would be enhanced problem solving and innovation, increased efficiency and scalability, democratization of knowledge and technology, resilience and robustness,

enhanced decision-making, personalized and context-aware services, ethical and responsible AI, collaborative platforms and ecosystems, enhanced learning and education, empowered communities, accelerated scientific research, and environmental and sustainability solutions.

and the implications for future systems and society, the convergence of RGMs and the spatial web could transform industries, enabling decentralized context-aware systems that operate with minimal human intervention.

industries that could be impacted smart cities you would have autonomous systems that improve efficiency at all levels global supply chains rgms could optimize processes from local shipping to global networks

Personal to critical systems homeostasis.

So whether it's personal devices or critical infrastructure, a continuum of intelligent adaptive systems can maintain homeostasis at each level.

In our healthcare systems, personalized treatment by integrating real-time data from wearables and medical records.

Education, we can have AI-driven adaptive learning systems that evolve with student needs.

And environmental management, we can have ecological systems that could be modeled and managed more effectively from individual habitats to global systems, balancing local interventions with global goals.

And the future of AI and human civilization, the development of renormalizing generative models within the scope of active inference and the spatial web promises to have far-reaching implications.

More adaptive AI.

These systems are highly adaptable, capable of operating in new environments with minimal training.

Efficient edge computing.

RGMs enhance the power of AI on devices like smartphones and IoT sensors, reducing the need for large data centers.

Improved human AI interaction.

With explicit uncertainty models, these systems interact naturally with humans,

seeking clarifications as needed.

Safer AI systems, they recognize and handle novel or ambiguous situations reliably, preventing catastrophic failures in unfamiliar scenarios so they can fail gracefully.

and accelerated scientific discovery rgms expedite research in fields like genomics and climate science by rapidly identifying patterns and formulating plausible hypotheses thereby guiding further experimentation so the key takeaway here is that uh all of the all of this research and all of these technologies together can provide us with a future where ai systems

can interact seamlessly with the physical world autonomously optimizing operations and improving human lives so um yeah there's my website i have a podcast and i'll stop sharing now thank you denise awesome

I don't know what time, how are we on time?


SPEAKER_01:
We have 15 minutes and I'll read some of the questions in the live chat.

Okay, sure.

I'll start with Pablo who wrote, how will all of this affect the gamification of processes in organizations?


SPEAKER_00:
Well, I mean, the interesting thing is through HSML, all of these emerging technologies are going to converge together and become interoperable in ways that we've not experienced before.

We've had this...

vision of this augmented reality existence, but the framework hasn't been there.

This is going to provide that framework.

I think when you're talking about gamification in every aspect, it'll probably become a natural part of our existence and how we move through our day, how we interact with

with our work with uh brands with you know anything um you know I I think that there's going to be a lot of of really interesting ways to kind of perpetuate that


SPEAKER_01:
Cool.

There's a lot of great questions in the chat.

So I'll read one from Tin Tin.

So they wrote, it's impressive.

The obvious question I have is of alignment of this system in terms of that alien message from Eliezer Yudkowsky, for example.

And then they clarified what that exactly is.

So the key idea there is that simulated agents evolve and came to think faster than their creators.

So at a moment, they took control to ensure their own survivability.

It's the question of how to ensure that way more intelligent and faster systems keep aligned with our values.


SPEAKER_00:
right and so one of the things that uh is really interesting to me about this is through hsml we can actually collaborate with these systems in the sense that we can take human laws and guidelines and make them programmable so these agents can understand and abide in real time and you know um

versus uh who you know dr carl friston is is their chief scientist um they were involved in a a program called flying forward 2020 and and they were doing a lot of uh testing around this and because it was it involved a drone project that i i don't know there were multiple countries throughout europe it was with the european union that were involved and

testing whether they could program in laws around airspace laws and things like that.

They did all kinds of scenarios of medical supply delivery, perimeter security, all kinds of things.

What they found was through HSML, you could actually program these guidelines and these agents abide by them.

I think we are going to experience this unprecedented level of

cooperation and collaboration so we can grow in tandem with these agents and their intelligence.

And I think that we can also take some

solace in the fact of how active inference works and how our human knowledge grows, I think we're going to see a similar pattern with this knowledge among these agents.

This is just me speaking from my own perception and perspective of this.

But

you know, they're going to be dealing with real time data and with a real grounding of these program spaces.

And those are the things that are going to be operating off of to make their decisions, right?

Whereas if you look at a human, you know,

we have so many other variables going on and every when we learn through active inference it's a very subjective uh growth that's why you can have you know multiple children growing up in the same household and they all experience things differently right but when you have these agents and they're getting this they're getting they're learning through actual tangible programmed information i think there's a stability there as well

that makes sense and and and again that's just my own uh you know interpretation and feeling around this and i could be i could be wrong but you know just kind of throwing that out there that's how we move forward yeah okay next question from david highland who wrote


SPEAKER_01:
Thank you for the informative presentation, Denise.

Can you share any thoughts or information about the ownership model for agents?

Is it a decentralized market?

How do we decide which parts are public goods?


SPEAKER_00:
yeah so with the protocol with a with hyperspace transaction protocol um because so it's interesting it really shifts to this uh kind of self-sovereign identity uh aspect of the internet because right now think about how web domains work you know if you want to interact with a web domain all the transactions are taking place under the umbrella of whatever centralized organization

owns that domain and you have two choices you can either say yes you can have all my data and you can decide what to do with it all or i don't want you to but then i'm opting out of being able to engage with your domain

Well, in the spatial web, because now transactions can be at every touch point of every entity within the network, then permissions can be programmed in a very nuanced way, right?

So it really puts that back in the hands of the user.

of the entity within it.

You can program guardrails around certain aspects of data while allowing permissions and freer accessibility for other aspects of data.

So whether you're talking about a business, they can guardrail off their data, they can guardrail off certain aspects of it for certain departments of employees, some for their customer base, some for

partnerships whatever right um and we're going to be able to do that kind of thing too and the thing with this is this takes into account time the passing of time so you can set expirations on permissions as well so I think we're going to have a lot more self-sovereign control in this in this area


SPEAKER_01:
yeah that's a part that really excites and piques me as well like with the web domain or the email domain it'd be like saying well on one hand we're not going to look in your email let's just go with that for now but we do or don't accept

letters from this area so it's kind of all or nothing and it's based upon like you pointed out the the custodianship of the all or none permission based around what boxes you can send where whereas

having a more nuanced way to talk directly about belief sharing means that instead of just like plugging the usb into the port there could be even a active inference negotiation around what elements to share how to share when to expire all these other features which can can help like incrementally build rapport and and add

the relationship instead of doing all or none which can be just very prone to false positive or false negative in cyber physical interactions yeah you're so right daniel yeah so

do you think about learning trajectories and paths i know it's a interest of all of ours i guess like what what can we do to be learning and thinking about all these things well um so you know i i had i actually have put together a series of courses um to kind of give people a a real um


SPEAKER_00:
kind of a prerequisite knowledge understanding of what this transition looks like and the different components and what it means from all aspects of like, you know, basic understanding of active inference and

the free energy principle and the spatial web technologies to decentralized AI, what does that mean?

Convergence of all this tech across the network, what does that look like?

Safe AI, how does active inference benefit that?

And then RGMs, let's look a little closer at that.

And what I try to do is I try to

take the complex ideas but make them more understandable so that people can really wrap their heads around the these concepts and then they can go dive into the more technical aspects of it and i know you with the institute you have a lot of technical knowledge there so i think that you know between resources like you know some of my resources your resources and then i'm sure there are resources out there that maybe i'm not even aware of and

I think there's going to be more and more resources available around this, modeling these agents, building out

you know these these spaces uh within the network um I know that versus is going to be launching a platform that'll be the first interface for the public around this technology and I think it's coming to the public at the end of first quarter next year and with that there will be tools where people will be able to build these agents as applications within the network and and you know I think

At that point, it's going to get really exciting.

Um, so yeah, I, I just think over the next six months, we're going to see a lot coming about with this.

And if anybody is interested in the courses I've put together, you know, you can, you can visit my, uh, my website and, and sign up for them.

Uh, they're not available yet, but they'll be available very shortly, uh, within the next week or two.

So, yeah.


SPEAKER_01:
Cool.

Okay.

Her last question asked the same thing that I asked Alex and Carl earlier.

What is a fun or a memorable moment from learning and applying Active Inference this year?

And then if you haven't already mentioned it, what's something that you're excited for next year?


SPEAKER_00:
This year, honestly, I think that I have been on this learning journey in creating this course material around it.

And at the same time, I've been building community and kind of having them be my test guinea pigs around it and stuff.

So there's been this whole learning aspect for me around building this educational material.

So it has been a constant feedback loop.

And next year, I'm just very excited about the potential of building these agents and what that means and how we can tackle some of the problems and the issues and the challenges that we have through this new exciting technology and this framework.


SPEAKER_01:
Well, thank you for all of your great learnings and digested and sharings and all the ways that what you talked about today, I think, connected a lot of the dots from hearing Carl's more technical view on the RGM on through what does it mean to have multi-agent decentralized as opposed to just building up one agent.

So thank you again, Denise.


SPEAKER_00:
Thank you, Daniel.

Thanks for having me.

Thanks everybody.

Bye.