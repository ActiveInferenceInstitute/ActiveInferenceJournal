SPEAKER_00:
All right.

The next video is going to be 28 minutes long.

It's from Mauro Albarracin, Sustainability Under Active Inference.

Hi, everyone.

My name is Mauro Albarracin, a PhD candidate at the Université du Québec à Montréal and Director of Research Strategy Adverses.

Today, I'm going to be talking to you about budding work on sustainability under active inference, which gets started with multiple authors that I listed down below, starting from the core components and scaling up to a computational model.

We are pursuing this research and multiple collaborations at Versys around sustainability.

Ultimately, this is meant to charter a path to much larger projects.

So feel free to reach out if you want to collaborate.

let's begin with the most fundamental aspect of sustainability namely resilience resilience refers to an agent or system's ability to persist and adapt in the face of challenges or perturbations under active inference resilience is a multi-faceted concept involving different strategies that allow a system to maintain or recover functional stability

Resilience can be broken down into three core components, inertia, elasticity, and plasticity.

So let's start by defining inertia.

It describes an agent's capacity to resist change when subjected to external disturbances.

It really is the stability and robustness of a system.

In active inference, inertia is represented by high precision beliefs, which can be thought of as highly confident low entropy beliefs about the system's current state.

Inertia is reflected in the precision weighing of prediction errors.

Higher precision implies stronger resistance to updating beliefs.

Maintaining a stable state means that precision is implemented as a scaling factor.

So here, higher precision really implies increased resistance to change.

The problem is that inertia alone makes systems brittle errors.

They cannot adapt.

So then we move to the second component, elasticity.

Elasticity describes the system's ability to return to characteristic or attractor states after a perturbation.

It corresponds to the concept of homeostasis, so the capacity to adaptively recover.

In active inference, elasticity is expressed in terms of an agent's ability to minimize free energy and seek stable states.

It can be mapped onto the relaxation back to attractor states, which is driven by minimizing free energy as the system follows a trajectory.

In doing so, it restores the system to a preferred state, analogous to returning to an attractive plant.

So for example, in nature, biological systems really exhibit elasticity through homeostatic feedback mechanisms like temperature regulation or blood glucose balance.

These systems have the ability to change, but they ultimately return to where they were without necessarily learning.

And this may yield the same errors and ultimately can crack under pressure, much like a rubber band pulled too hard.

So let's move on to the third component, plasticity.

It refers to the expansion of an agent's repertoire of adaptive states.

It allows systems to adapt not only by returning to previous states, but also by exploring new states, enhancing robustness.

So in active inference, plasticity is related to functional redundancy and structural degeneracy, having multiple pathways to achieve the same outcome.

Structural degeneracy means that you have different components perform overlapping roles, allowing the system to adapt to novel challenges, but we will dig into this a little later.

So here plasticity is captured through posterior beliefs that can change flexibly based on new sensory input, or structure learning, if you actually add a new state.

We can use the variational density such that the agent can represent a diverse range of potential states, maintaining a dynamic model of its environment.

Think, for example, of neural plasticity, where different neural circuits can adapt to perform similar function after damage.

To understand how plasticity comes into play, we really have to hone in on certain key concepts underlying it.

So complexity refers to the uncertainty or diversity of system dynamics.

In active inference, complexity is associated with the range of possible states an agent must consider.

Complexity is linked to entropy.

of the system state distribution.

Higher entropy reflects greater uncertainty and the number of potential states the agent must account for.

Variational free energy is a way of balancing two important things, how complex our beliefs are and how accurately they match what we observe.

we can balance this in a formula that goes F equals the difference between the complexity of updating our beliefs and how accurately these beliefs predict what we observe.

So in this formula, the first part, VKL, measures the complexity or the cost of updating our beliefs to align with reality.

The second part, written as EQ, represents how well our current beliefs can predict the observations we make.

So we said we were going to turn to degeneracy and redundancy, and I'm obviously here leveraging work by Noor and Carl Friston.

For degeneracy, what we're considering is that the presence of different components are capable of fulfilling similar roles within a system.

In her paper, they talked about, for example, left hand, right hand.

And redundancy means that you have similar components performing the same function, which enhances robustness against failure.

The redundancy here involves overlapping functions in state transition matrices B, which indicates similar transitions across different states.

And degeneracy can be quantified by the entropy of the posterior distribution, which represents the number of alternative configurations that lead to similar outcomes.

And so managing complexity through diverse beliefs really means that the agents can adapt to changing conditions.

Degeneracy means the agent can switch strategy when one pathway becomes unavailable, which promotes adaptation.

And redundancy ensures the continuity of function when certain components fail, which adds resilience to the system.

So degeneracy here helps reduce the complexity cost by distributing probabilities across multiple states, thus maintaining low free energy and supporting robustness in diverse conditions.

But while resilience is really critical for maintaining stability, it doesn't fully capture the dynamic interaction between systems and their environments.

Resilience focuses on an agent's ability to withstand or recover from perturbations, but it lacks insights into the broader system dynamics.

Without considering systemic interdependencies, focusing solely on resilience can lead to short-term adaptation without promoting long-term stability.

This is work that Mark Miller and Ines Cipollito have written a lot about.

So for sustainability, we really need that systems not only adapt, but also ensure the long-term viability of their environment and resource base.

We can, through active inference, integrate resilience and sustainability and show the need for system-wide coordination for harmonious interaction.

As Carl likes to say,

Active inference really is just the story of resilient and sustainable systems.

So let's define sustainability a little more.

Sustainability is defined as the enduring capacity to meet needs without depleting crucial resources.

And here resources is taken a little more liberally.

We can expand beyond material resources and encompass social, ecological, and system dynamics.

Sustainable systems are those that persist over time and do so in a manner that promotes stability and health across all dimensions, environmental, economic, and social.

We achieve this under active inference by enhancing long term adaptability and interconnectedness across multiple scales.

Sustainability emphasizes the creation of conditions that allow

for continued adaptation without exhausting resources, effectively ensuring that all parts of the system work cohesively to support resource renewal and plasticity.

So sustainability can be framed as optimizing the expected free energy over deep temporal scales, which is work that Caspar Hesp has pioneered.

balancing immediate needs with long-term system viability.

So the optimization of expected free energy can be represented as F of expected S and A equals the risk plus the ambiguity of F expected S and A.

So RISC quantifies the divergence between the predicted paths, i.e.

the future states of the system, given an action sequence and past observations, and the preferred paths, which are ideally sustainable and align with long-term goals.

This encourages the system to pursue states that meet its sustainability preferences over time.

Ambiguity measures the expected uncertainty in mapping states to observations, and it ensures that the system continuously learns about its own dynamics and the environment.

This helps the system reduce uncertainty and improve its predictive dynamics over time.

The components of expected free energy balance the drive to fulfill preferences with the need to minimize uncertainty.

This balance supports plastic responses that enable the system to adapt to change, but also actively guide itself towards more sustainable and self-organizing configurations over extended timescales, ensuring resilience at both individual and collective levels.

But sustainability isn't just about survival, or at least it's not a simple story.

It must incorporate eudaimonic well-being focused on growth, fulfillment, and development, and hedonic well-being, which captures immediate satisfaction.

So in active inference, this means that the system should balance present experiences with long-term strategies that enhance overall capacity for adaptive growth.

So when we talk about eudaimonic well-being, we represent growth and the system's ability to find diverse beneficial states.

And it aligns with long-term sustainability by ensuring that agents survive and thrive through extended adaptability and resource renewal.

It represents the growth and system's ability to achieve its long-term goals.

This concept aligns with active inference because it emphasizes long-term sustainability by optimizing internal models that allow agents to find those beneficial states.

And so within active inference, agents act to minimize expected free energy, which involves the balance as we saw between risk minimization, which means that the outcomes are aligned with the agent's preferences and ambiguity minimization, which ensures that the learning continuously happens.

that's what enables the agent to grow and thrive and so eudaimonic well-being can be conceptualized as the successful maintenance of favorable states and the expansion of the system's potential allowing it to reach higher order goals over extended time horizons

And so this behavior reflects structured learning wherein agents adapt to changes in the environment by restructuring their internal models, which lead to growth in a diverse set of beneficial states.

Now, hedonic well-being involves immediate moment-to-moment satisfaction, which is necessary to maintain ongoing motivation and effective response to environmental demands.

focuses on immediate satisfaction and so the agent's capacity to respond adaptively to current needs.

It can be seen in active inference as the system's ability to reduce momentary free energy and maximize instantaneous rewards.

We can see this at the lower level say of higher approval models.

So you minimize prediction errors in the present, you seek sensory states that satisfy immediate needs or preferences like finding food to satisfy hunger,

And this corresponds to reducing free energy associated with specific observations.

The internal reward or momentary satisfaction that the agent achieves after fulfilling immediate needs corresponds to the agent reaching a preferred state as predicted by its internal.

This is crucial for maintaining motivation and ensuring effective responses to environmental demand.

Here, we also have to factor interdependencies within the system.

These interdependencies can be represented through mutual information equations, which ultimately quantify the connections between different components.

The plasticity at individual levels translate to the sustainability of the entire system, aligning short-term actions with long-term goals.

so sustainability is an emergent property that depends on the balance between all elements in the system this really involves presenting resource depletion maintaining well-being and promoting resilience through self-organization and learning so it's a continuous effort to increase resource redundancy and avoid over exploitation thereby ensuring sustainable practices over time you can think of it as avoiding the local minimum

sustainability of a system depends on harmonious interactions among its different components, which range from individual agents to the broader collective.

This means that the system must align both internal and external goals to ensure stability over extended periods, enhancing resilience and sustainability.

And so, for example, the resilience components of inertia, elasticity and plasticity will work synergistically to support adaptive actions that contribute to sustainable outcomes.

The emergent stability is promoted through decentralized interactions where each component of the system self-organizes and responds to environmental feedback, which reduces the complexity and increases adaptive capacity and allows the system to maintain a dynamic but stable equilibrium, also sometimes referred to as omioressis.

So we can think of attractor states which emerge as agents minimize their variational free energy over time.

And this process supports the alignment of internal models with the environmental demands, ensuring that agents remain adaptive while reinforcing the renewal of resources and overall system well-being.

So these are all nice ideas, and we think they hold up mathematically, but we wanted to test them out.

And obviously, this is the beginning of the journey.

So we built a small and very simple agent-based model to illustrate sustainability under active inference at the level of one single agent within one environment.

This is extremely simple and the following studies will cover more.

So the model here simulates an agent managing food consumption in different environments to ensure long-term resource availability.

Our objective was to show that the agent's goal is to maximize well-being while ensuring resource sustainability over time.

And this involves balancing immediate needs with future availability of resources.

So we started with a validation case.

In this case, the agent makes decisions based on current food availability without affecting future availability.

And so the agent observes food and decides whether to consume or not based on its current state and prior preferences.

So we have the generative model, we have hidden states representing food availability and satiety.

Preference C, which included a strong preference for satiety while maintaining food availability.

As you can see, these two preferences are technically contradicting.

And so in a static environment, which was the first case, the agent's decisions are really straightforward.

They just maximize short-term well-being without needing to manage resource dynamics.

So as you can see in the tiny little plots here, we can see that the agent's behavior, specifically whether the agent chooses to eat or not over a series of time steps.

And so the middle plot shows that the amount of food over time, which is represented as food left.

And the last bottom plot shows that you represent the agent's level of satiety or how satisfied and full the agent feels over time.

Higher values indicate higher levels of satiety.

And so the agent has a strong preference for high satiety.

Since food is continuously available, the agent keeps eating at the beginning, which increases its satiety level.

And since the environment is static, the food remains available indefinitely.

And so the agent successfully increases its satiety.

We then wanted to show whether or not what we did was just an artifact of the simplicity of the model.

So we screwed with its matrices.

And so incorrect matrices caused the agent to misjudge the effect of eating, which leads to an unstable satiety level.

And so we showed how errors in perception and action models can significantly impact the ability of an agent to achieve stable and desirable states, even in an extremely simple setup.

So then we tried something a little more complicated, which is a dynamic environment where the strategies have to change.

So the environment changes based on the agent's actions.

So resources deplete when consumed, but replenish over time when not used.

And so the agent's challenge was that it had to learn to balance consumption with replenishments, which effectively had to demonstrate some degree of sustainable behavior.

So the model includes the transition matrix that maps the state of food available based on the agent's actions and expected free energy here.

Minimization guides the agent to consider future state and ensure resource availability.

So this was the case.

As you can see, it hasn't changed much.

The only thing that has changed is the dynamics of the environment and the ability for the agent to ultimately learn those dynamics.

So the agent had to adopt adaptive strategies that balanced immediate rewards with long-term stability.

And this was showing us how active inference can foster sustainable behaviors in fluctuating environments.

So when we look at this plot, we could see that the agent has learning turned on or not.

And we wanted to see whether an agent that didn't learn did just as well as an agent who learned just to see again, whether it was an artifact of the simplicity of our model.

And also the agent can die if the resources are depleted and it is not satiated over time it dies, which ethically might not have been the best thing to do, but whatever.

So agents that have learning quickly improve their survival times by refining their internal models and strategies.

And so the rapid improvement really shows that learning enables them to find efficient and sustainable ways to interact with their environment.

Without learning, there is no significant increase in survival time as they are unable to really adapt their behavior based on past experiences.

So they end up in suboptimal decision loops, leading to a lower average survival.

So we can really show that learning is crucial for agents' ability to adapt, which in turn allows for a longer, more sustainable presence in the environment and ultimately

also the environment's ability to actually be sustainable in itself.

The agent overcomes initial limitations and eventually converges to strategies that maximize their survival, which really shows the power of dynamic adaptation in certain environments.

We saw that the agent's behavior in both static and dynamic environments really shows how wellbeing can be optimized while maintaining resource availability.

And in the dynamic environment, the agent learns to moderate consumption.

It is able to understand the trade-off between immediate satisfaction and future resource sustainability.

The agent has the ability to

create adaptive strategies that align with the principles of resilience and sustainability.

And so here, our model illustrates in a very, very minimal way how minimizing free energy can lead to behaviors that promote long-term viability rather than short-term gains.

And so these simple models are just laying the groundwork for modeling more complex systems, such as ecosystems or urban environments, where sustainability requires coordinated interactions between multiple agents and resources.

So to recap, we started by understanding resilience with inactive inference.

We broke it down to inertia, elasticity, and plasticity.

We then explored sustainability, building on resilience, and we incorporated well-being as a critical component.

We demonstrated how agents can balance immediate needs and future viability, achieving sustainability, again, all through active influence.

And so it maps systems that can adapt, sustain, and thrive by balancing short-term adaptation with long-term sustainability.

We still need to show how active inference can effectively be scaled to real world applications involving multiple interacting agents and resources, involving the ability for the environment to fully deplete and therefore how to actually manage such possible patterns and how agents might learn over different areas.

We have to transition from theoretical models to more practical implications that involve challenges in data acquisition, model complexity, computational scalability.

We also need to factor mutual interactions and the effects of each subsystem on each other and the larger systems such that they promote more resilience and plasticity.

So all of this is extremely seminal.

We have to move further and actually demonstrate in much larger scale and more complex

simulations, these ideas.

But it has critical potential applications.

Achieving all this, we can use active inference to model and predict adaptive strategies for mitigating climate impacts at different scales, or improve decision-making processes in organizations, enhancing resilience and sustainability in economic and social contexts.

So active inference can be extended to other complex adaptive system, and we can support initiatives aimed at fostering sustainability in healthcare, agriculture, and urban planning, which is work that again, Mark Miller and Ben White, Tineshi Polito are really pushing forward.

So thank you for listening and I hope you enjoyed.