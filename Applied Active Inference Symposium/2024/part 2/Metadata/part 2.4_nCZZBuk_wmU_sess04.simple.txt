SPEAKER_01:
hello welcome back we're here with shanna dobson discussing descent conditions on hyperphantasia a new model of self-information looking forward to this presentation followed by questions at the end so thank you shanna super looking forward to this hey daniel great thank you for the invitation i'm excited to present these new ideas on hyperphantasia so i hope this relates to someone and thank you all for listening


SPEAKER_00:
So a small outline, I'll be discussing the fantasia spectrum and its two extremes, afantasia and hyperfantasia.

And then we're going to discuss what I'm calling the memory continuum.

Then we're going to review what I've been calling the oneiric self, constructed as the profinite set.

Then we're going to review Grothendieck's one categorical theory of dissent.

And then I'm going to try to present a new model of categorical mental imagery from the hyperphantasia perspective using, I think, these very beautiful categorical sheave techniques of specifically Grothendieck dissent.

So dissent theory is a super powerful tool.

And I hope you all like what I'm trying to do there.

Then we'll pause at what are called descent conditions on hyperphantasia, pretty much how the sheaves work, and why I think sheaves are really good for something like hyperphantasia, which is characterized by pretty vivid mental imagery and profound episodic memory recall.

And then last, we're going to actually model surprisal itself or self-information functorially as a category of descent data.

So if you've been following my work, I tend to like to categorify

everything and so uh we'll see if we can actually categorify hyperphantasia all right cool so i'm just going to start with the the big results because it's going to take me a while to get there so i always start with the main idea so pretty much i'm going to categorify episodic memories as we're called fibered categories and then so the idea is that you're going to fix a particular memory m and you're going to study memories over that memory

So this is in the vein of hybrid categories.

So hybrid categories are very beautiful.

They're almost like parameterized categories.

And so hybrid categories, particular category over a fixed category C.

So for me, episodic memories seem fibered.

They seem like they're memories over memories, as I think selfhood is fibered.

So I've given many talks on that.

Clive Waring, the famous case of having both a retrograde and anterograde amnesia.

Clive has about a six second working memory with purely semantic memory.

Not a lot of personal memory besides remembering his wife, but everything else, not so much.

So the selfhood of Clive is in question.

What's the perception, the frequency of perception of Clive?

I think that's very, very tricky stuff.

So if selfhood itself is fiber, we're going to consider these categories of memories over a fixed memory.

So I have the idea to use descent to actually represent hyperphantasia.

So the idea is that you have these memory sheaves that are satisfying descent.

And to satisfy descent means that they form a stack, which is a very particular sheaf that takes values and categories and not sets.

Okay.

And so then this pair at the end, this F star phi, which I'll describe in these maps, is going to be what we call the categorical descent datum.

So I call it, this is our sheafy surprisal.

So if you could sheafify surprisal or self-information, I think you do it this way.

So surprisal would be constructed as the sheafification of memory.

All right.

So, and you would say, uh, there exists the following, uh, the descent conditions on Fantasia and it would be those.

Cool.

All right.

So let's start with the Fantasia spectrum.

Oh, sorry.

So this is what I'm going to get to.

Um, I think they're pretty good ideas.

And then, uh, so let's actually dive into.

Fantasia itself, which I think is very, very, very beautiful topic.

So what is Fantasia?

What is this Fantasia spectrum?

And so it has to do with the characteristic of, you know, creatures having visual imagery.

And so the Fantasia spectrum itself is a relatively novel neuropsychological spectrum used to classify to what extent an individual constructs mental imagery and visual imagination.

which is quite strange.

We're so used to it, but it's very strange that you have these pictures, quote, in your mind.

Where do they actually exist?

And this fantasia spectrum, so this ability to imagine visually, has two extremes, and they are quite extreme.

So aphantasia is characterized by the absence of mental imagery, and hyperphantasia, characterized by

profound, extraordinary mental imagery, heightened visual imagination, so detailed and vibrant, imitates reality.

I myself seem to fall on this scale.

And the reason, again, I know this is that one of my dear colleagues introduced me to the spectrum and said, Shanna, I think we were writing a paper together and said, actually, I think we went on opposite sides of the spectrum.

Everyone knows I told this story.

And together, I think we've written

like the most amazing things okay all right so let's start on the aphantasia side so when you say when you know the tendency to say lack you know it seems to say something negative but it's not really so aphantasia is just characterized by the absence of just particularly mental imagery doesn't mean all imagery so it is an image-free mind but it has conceptual imagination okay

So if you were to say, so the imagination of anyone who falls on this classification, it involves other senses and abstract concepts besides visual imagery and sensory details.

So perhaps the way of thinking and visualizing is analytical.

So everybody knows my little girl Artemis.

I talk about her a lot.

So if I was aphantasiac with respect to saying someone said,

you know, how do you imagine Artemis?

And I would say, well, I cannot mentally picture Artemis, but I can think about the idea of Artemis.

And there's Artemis, right?

So perhaps like her fluffy tail and her being white, like wouldn't actually appear to my mind, but I would think about the idea of Artemis and I think about it very deeply, right?

So contrast this to what is hyperphantasia?

So hyperphantasia is characterized by sort of extraordinarily vivid mental imagery and heightened visual imagination and also episodic recall.

Heightened sensory details in episodic memory.

So Shana, what was your first ice cream cone?

And there's, you know, just lush sort of dolly-like exquisite imagery that comes out of that.

So detailed and vibrant imitates reality that you actually say, well, which one?

Which one is quote more real?

The one quote in my head or the one like outside of my head?

Tricky.

And so I can actually picture Artemis so vividly as if I'm really seeing her in real life.

And so for episodic memory, these are personal memories sort of based on sensory perceptual data of which mental imagery is a particular form.

So that is why hyperphantasia and the

and how you recall episodic memory are so incredibly linked.

So with this, I've started thinking about sort of the distance to and from memories.

So this is a concept that I think would be exciting to explore, which is why I'm doing it.

And so if you ask yourself a strange question, like what is the distance to a memory?

Normally people would call this a timestamp.

That happened to you three weeks ago, something like that.

What happened to you then is not what's happening to you now.

We call this a timestamp, sort of a way that you can mentally file away an event and to keep it a little distant from you.

So, but I have a question.

So for hyperphantasics, what if there were no distance to a memory?

I find this to be the case for myself.

People say, well, that happened then.

That happened then, it's not happening now.

I sort of have a problem with that sort of thinking, that sort of logic.

I question the timestamp that people are using to actually say a statement like that.

But let's imagine, what if there was no distance to actual memory?

Would that mean that it's always happening?

it mean that it was always happening well what if that distance were actually not measured by sort of the counting numbers or the real numbers with a linear ordering before or after so this is sort of the profound leave i want everyone to try to imagine so an event happened to me two weeks ago if you were thinking according to the sort of like standard number line you would say well two weeks ago

was before like now it's like now is the zero point and so you know normally events with a timestamp have a linear ordering that happened then this is happening now that was yesterday this is today so i just want to ask like what if that distance were actually changed the metric on that distance was actually changed so if there was no linear ordering about before or after this would be very curious so for me the distance seems the distance to and from memory seems more like it's a

p-adic.

So I invite everyone to sort of try to think of the distance to memories as more non-Archimedean in the sense that there is no before or after.

So if you've been following my work, I'm pretty enchanted by the p-adic numbers and things like this.

And so the p-adic numbers actually have no sense of linear ordering.

They are kind of more fractal-like.

Now, this property that you're sort of just zooming in, but there's no notion of bigger than or greater than.

And I think that would actually be very interesting to try to evaluate memory on a timestamp of something that's not bigger or less than.

So my claim is that the distance of, or to, or from memory is p-adic.

And that's going to lead me down this exploration.

So the second concept I want to talk about that I've been playing around with is the idea of a memory continuum.

So I want to ask the question, what is the space of memories?

If anybody saw the latest Blade Runner, you see there's the memory maker.

She's in charge of actually making movies and movies and memories.

And she's actually sort of kept away because she says she can't really leave this prism that she's in.

But she's charged with making memories.

So I want to ask the question, what is the space of memories?

So you have them.

My great colleague Chris Fields and I are always asking the question, why do you experience memories?

It'd be very interesting to find the first creature who experienced a memory.

Not why you have them, but why do you experience them?

All right.

So what is this space of them?

If you were to actually put them in a category, you could.

I was actually more interested in, if you dive a little bit into that, well, what is the actually topology on the memory space?

Could you actually cover it with something?

Can you think about memories in terms of open sets?

Are memories topological?

Do they sort of intersect, which it sounds like they do?

What sort of properties do they have?

And so to think about memories mathematically, I think it's kind of a new idea.

So not only what is the space of memories, but what is actually the shape of memories?

What do these actually feel like, look like?

And so I want to actually think about the concept like, can you actually mathematize the duration of memories?

How long do they last?

Some memories seem to have expiration dates, and some memories seem to be holographic.

I'm really interested in how memories last.

how long they would actually last if they were actually considered with a different metric.

So for myself, I notice a certain density of memories.

And what do I mean by that?

So density in the mathematical sense, not heaviness of densities.

Although that would be interesting, like some memories are so heavy, they'd probably implode.

Some memories are sort of big, light, they'd float in the bathtub.

So the density of memory is, I'm not talking about the physical property, but what is often called emotional valence sort of has this positive, this plus minus charge associated with experiential memory.

So if memories can act like sort of black holes, or memories are sort of like black holes, they can literally warp

the thinking, if you think about it.

So black holes, you know, actually intend to, if there's very, I mean, they're dynamical, but when they're rotational, when they're rotating and things and spewing out these plasma jets, they can actually warp the space time around them.

I've always been fascinated by that.

I seem to have memories that do the same thing.

So if they warp the thinking, what happens?

Well, any object can be turned into a black hole.

I just have to squish it and be on its Schwarzschild radius.

So memories as objects, something to be like to think about.

So density in the sense of, OK, like a teaspoon of a memory that was as heavy as a black hole would do something, but not that kind of density.

I want to talk about the mathematical density of memories.

What would that even mean?

So if you take density from the standard form where you normally prove that the rationals are dense in the real numbers, this is the sort of density that I want to think about.

So the rationals are dense in the real numbers, which means that between any two real numbers, you can always find a rational number, which means between any two real numbers, you can always find a real number.

So that seems like a light statement, but then it sort of gets terrifying to know that between any two real numbers, you'll always find another one.

Unlike the property, say, for counting numbers or the positive integers, between the integer, the positive integers 2 and 3, I will not find another integer.

But between the real numbers, I will.

So I thought, hmm, for me, it seems sort of the same.

Between memory A and memory B, there seems to exist a memory C. And I can continue this forever, it seems.

For me, between any two memories, there is another one and another one.

I can always find another one.

So the memory density and the memory continuum, I think, is something that could be looked at as a hyperphantasia until I run out of memories.

So between any two memories, there is another one and another one.

I can always find another one until I run out of memories.

But that's where the hyperphantasia kicks in.

between any two memories there exists a hyperphantasia memory right so this hyperphantasia for me is a sort of memory continuum so um one of my brilliant colleagues at art center constructed this beautiful image which i think for me actually shows me um this is sort of what i think about as a hyperphantasia right so the density of memory that

I could be brushing my hair inside that memory of me brushing my hair with my favorite brush.

There's more memories inside my hair, memories inside of memories, inside of memories, inside of memories, right?

And it just keeps going on and on and on and on.

So I want to play around with another concept called miso memory that I've been thinking about.

So is there actually a duration issue with the density of memories, whereas the real numbers always exist?

If I'm talking about between any two memories, there's another one.

How long does that last?

The real numbers seem to always exist.

Seems that between any two real numbers, I will always find something.

But what about memories?

Not sure about that.

What is memory at the MISO scale?

So this is a scale that Daniel and I, we've been having talks about.

So sort of between the micro and the macro, you have this MISO, which is sort of this slippery sort of interstitial happenings.

And so what is memory at that scale?

I'm very curious.

Is memory just the thing that sort of comes through with the macro side?

What would MISO mean in terms of that?

Is this like an almost memory?

So I have almost memories at the MISO scale, but then what does that mean?

So what would a MISO memory actually be?

Well,

Thinking in terms of density would allow more variations of what memory looks like.

So sometimes you have memories that aren't quite out of the oven yet.

You have some memories that have been mixed.

Some memories are fluid.

Some memories can phase change.

And so I really think it's really important to think about the density of memories by opening up this new scale.

So sort of from microcircuitry of neuronal processes, micro memory.

This is sort of what I'm interested in.

So for me, memories feel non-Archimedean, since I'm going back to the p-adic metric.

It's a fantastic metric, in my opinion.

So the p-adic number system, again, just a brief recall, is a non-Archimedean system that is the completion of the rational numbers q under the p-adic metric.

Repeated notes of prime number.

Interestingly, so this is sort of the Oz-like property of these numbers.

So p-adic numbers are close if their difference is a high power of p.

P-adic notions have no notion of linear ordering.

Their shape resembles a self-similar set.

That's the fractal language I was talking about.

Okay, so just a little more technical.

So again, for me, the memories feel non-Archimedean.

And so informally, the ring of P-adic integers Zp are written in base P, and they admit infinite expansions to the left of the decimal point.

So p-adic integers take this form of sort of the sum a n p n, where a n is between 0 and p. Addition multiplication performed on the p-adic integers with the sort of carrying method used to add ordinary ones.

So the p-adic metric introduces a non-Archimedean norm on the rational numbers.

And the fun part of this, fun fact, is that for a non-Archimedean norm on the rationals, every point of an open ball is actually the center.

So I want to think about that.

Instead of actually having like a canonical center in the Archimedean case, every point of an open ball is the center.

So this sort of what some would call a disorientation, maybe it's sort of a superpower.

This could be the space from which hypermemory is made.

The fact that every point in this open ball would be centered.

So really, what metric are you using?

Do hyperphantasics and aphantasics use different metrics on the topology of the memory space?

This is what I'm interested in.

So are they using different distances to and from memory?

So at best, you'd probably just have isomorphism classes of these timestamps instead of, I'll just say, yeah.

So for me, memories feel also profinite.

This is a concept you've been following me.

I talk about a lot.

I'm inspired by Schultz's work.

So a profinite set, also called a stone space, is a compact Hallsdorff totally disconnected topological space.

I've been enchanted by these for a little bit.

It's also defined as an inverse limit of finite sets.

That's our notation of the inverse limit of our SI for SI finite.

So the smallest, what is called light, so a light pro-finite set, everybody, is just a countable inverse Lomit finite sets.

And so the smallest infinite pro-finite set, it's actually called the one-point compactification of the integers.

So you go all the way through the integers and you adjoin infinity.

And then also the Cantor set, which I'll talk about in a little bit more.

All right, so fractality is this concept that I'm studying for my thesis work.

And fractals are such strange, beautiful creatures.

They actually sit between Berkovich spaces, which are famous rigid analytic spaces, and the p-attics.

So they're between these.

And the p-attics are totally disconnected.

So Berkovich spaces are these topological spaces, like I just said, in the setting of non-Archimedean analytic geometry.

So fractals are sort of in between.

And so fractals have this property.

It's very difficult to define what a fractal is.

So there's been some contention about the definitions back and forth.

But everyone agrees that fractals have one property, that they're self-similar at all scales.

So I want to ask if memories are self-similar.

What would it mean to actually have that?

What is the shape of memories in something like the dream space?

So we're going to call that the Oneiric self-memories.

What does it actually mean to have the memory space in an Oneiric setting?

We're going to explore that in just a little bit.

So memories seem local.

confined to some sort of particular area, but they also seem met up, right?

So in some great work with my brilliant colleagues, Hector Manrique and Michael Walker,

We're trying to figure out sort of a, you know, how would you construct the oniric self?

I had this idea like, hmm, I think you could struct the oniric self as itself as a profinite set.

And so what we're looking at here is the different topologies and like on the memory space in the waking state and in the sleep state and actually the construction of selfhood in the dream space and then selfhood in the waking state.

So just to quote one of our passages here.

So we say, in stark contrast, the oneiric state events occur disconnected from one another in a profinite space that's compact, hostile, topological, so namely a profinite stone space, where events dreamt by our oneiric self are not stored relative to linear time.

So hence, a plausible model for dream time would be a ring of p at integer zp considered as a topological space.

So we're trying to figure out an event in a waking state and an event in a sleep state.

These seem to be stored differently and to construct different narratives of personhood.

That was Hector's idea.

How do I construct the notion of self in a waking state versus self in a dream state?

self in a dream state you know that you can be here and then you're all of a sudden you're uh you're you know flying with uh like falco and then all of a sudden you're at erewhon these are my dreams and um the question is you can get from one place to another very very very quickly instantaneous um or you seem to be nowhere in particular at no time

And so the question was, if I had all these events happening in my dream space and I couldn't store them as dream, I may start having waking state fights with people who did stuff to me in my dreams.

I'm like, Daniel, how did you do that to me?

And he's like, Janet, that never happened in the waking state.

I'm like, oh, okay.

So you have this very separate storage space, which keeps dream things there, and you're not constructing.

the sense of waking self based on the dream state events.

Beautiful idea.

And so why did I say, OK, let's construct the dream state as a profanity set?

Well, the Hasdorff criterion ensures that there's no simultaneous experience occurring in the oneiric dream state.

You need to keep these events separated.

So every point in the profanity space uniquely represents an event that has occurred oneirically.

um simultaneous experience is something that i'm after as well in my my work with my brilliant colleague robert pretner also my work with chris fields um so what would it mean to have a simultaneous experience that is something um that we're still working on more like that that is that is a waking dream but so you want to have these events being uh hausdorff they're kept separate in the dream state so you don't have a sort of an inception going on thank you christopher noel all right

So the total disconnectedness condition actually accounts for a crucial difference between awake time and dream time.

So Chris and I had this idea that a key aspect of the construction of waking time, however, is the assumption that between any two distinct events experienced by some agent A, other things happened, non-agent specific events occurred that A did not experience that some other agent B may have experienced.

Okay, so in the waking state, between any two distinct events experienced, say I'm agent A, and I'm giving this lovely talk for everyone listening, and then I'm going to go give another talk.

And so the fact that in between these two talks for me, something else happened to Daniel.

And Vince in the Oneiric state, though, I think don't have this property.

They're actually totally disconnected so that you wouldn't have this notion that between any two things that happened for me, something else happened to somebody else.

All right, so canonical sample of a profinite set is the actual Cantor ternary set.

So do I have an image of this?

Okay, yeah.

So the ternary set is constructed iteratively as an infinite process from an infinite process.

I take this closed interval 0, 1 represented by the solid red line.

And what I do is I actually remove the open middle third from the actual closed interval 0, 1.

leaving me with two intervals remaining so i actually have two line segments closed zero to one third union at two thirds to one and what do i do i do it again so i remove the open middle third leaving me with the you know um remaining line segments

And I continue this process infinitely.

So the Cantor set actually consists of all the points that remain that are never deleted from the original interval.

You can see there's end points of the line segments that are never deleted.

And so beautifully, that Cantor set is actually uncountably infinite.

So it's the scary infinity having the same number of points as the closed interval 0, 1, right?

So shown here is just the first seven steps of the infinite construction.

It's always nice to be defined as an infinite process.

So this is the Cantor set.

And so the points that remain are sort of like this Cantor dust.

you add them all up it's the scary infinity okay so this canter ternary set is nowhere dense has no interior points and it also has measure zero so it's considered negligible small so back to our um uh back to our paper so like so if the oniric self is composed of these events that occur in a stone space um then the oniric self would be like canter dust everyone and negligible

So the self-similarity of the Cantor set, it's sort of like fractal, and it could experience what we're calling these time loops by the urinary cell.

But of course, the cerebral neuronal microcircuitry is yet to be demonstrated, which maintains alternative storage systems, right?

So do you have these alternative storage system?

And what causes the switching between them?

How do you actually know to file event A as a dream event

and keep it separate from event B. So strange.

And what would happen if this actually sort of flipped?

All right.

Okay.

So the self-similarity, the Cantor set, I'll just show you this image, is the fact that there is a, like the Cantor set is similar to itself upon magnification and translation of its pieces.

so if you look at this highlighted piece pink and that i have like the pink highlighted piece so you can have two copies of that diminished by a factor of a third and translated produces the original c right so very strange that these this set is self-similar and that's why i think it's actually very curious but the self-similarity is what i'm interested in in the actual memory space cool

all right so let's get just a little technical and then i'll wrap up all right so this new model is going to be based on these categorical sheaves like i showed the final the main results in the first slide so the idea is to model for hyperphantasics um model episodic memories as light profinite sets which means these countable inverse limits of pro of um of finite sets

So then we're going to actually use a claim, a theorem that Chris and I have in our paper, that entropic categorizations are actually condensed sense.

I'll recall all these terminologies.

And then reframe recall in terms of representable functors.

So I think recall could have a very beautiful form in terms of representability.

And I'll go over that functor.

Then you want to construct hyperphantasia by adjunction, and hyperphantasia would be constructed as surprisal.

So phantasia itself is sort of like self-information, and so self-information by the way of the actual visual spectrum, or if you're a phantasia.

So then you would reframe further these memory sets as categorical sheaves and put the descent conditions on them.

And then you'll model self-information as a category of dissent.

Okay.

So it's like, firstly, everybody always asks me, why sheaves?

You know, like, why are you so fascinated by these things?

Well, I really believe and support Grothendieck's work.

So Alexander Grothendieck always said that it was sufficient to study the category of sheaves on a topological space.

So he is so brilliant.

He really revolutionized just algebraic geometry, descent theory, really beautiful things.

order to comprehend the topological space so all you need is a category of sheaves on the topological space love that so she's enabled what well they enable this local analysis of the space they assign data to open sets you don't really get this local global phenomenon a lot and then the category of sheaves on the space actually encapsulates its geometric properties like cohomology groups these capture topological invariants

and structure.

So the category of sheaves on a site is actually called a Grothendieck topos.

A site is going to be a category with a topology.

So unlike a topological space but a categorical version of this.

So a Grothendieck and particularly a Grothendieck topology on a category is going to be a set of morphisms which act like the open sets or the covers of a topological space.

So this Grothendieck topology is going to be very rich and

I just think he was really onto something here.

All right, so a site.

Let's define that real quick.

So a site is a category equipped with a Grothendieck topology.

And so given a Grothendieck topology J and a small category C, you can define the category of sheaves on C relative to J, which is this SHC comma J. And this is a reflective subcategory of the category COFF.

of sets, that's a functor category, of pre-sheaves on C. And so reflective subcategory refers to the image maps reflecting each other.

So this, you're going to have this functor from C to the category of sheaves of C relative to J, given by what's called the composite of the UNITA embedding, which I've talked about before, with the reflection, that's called, or the sheafification.

And so this composite functor is going to be fully faithful, which means injective and surjective on the omsets.

If and only if all the representable pre-sheaves, which are these set-valued functors, are actually sheaves.

So descent is going to be the sort of generalization of the sheave condition from pre-sheaves on these higher categories.

So a topology with this property is really importantly called subcanonical.

So let's define a profinite set.

A finite set is actually a compact Hausdorff totally disconnected set, as I said.

So it's defined as an inverse limits of finite sets.

So let's just talk about what an inverse limit is.

So you have some sort of index set, I. And so the pair, this pairing is going to be a partially ordered set.

And so say we're working in groups and group HOMs.

So we'll let this AI be a family of groups.

Suppose we have a family of homomorphisms.

Fij, note the map, goes Aj to Ai for all i less than or equal to ij with.

So Fii is going to be the identity on Ai.

And then Fik is Fij precomposed with Fjk.

And so this pair, Ai, Fi, is going to be an inverse system of groups and morphisms.

And so the inverse limit is actually a subgroup of the direct product of the Ais.

so you construct a as the inverse limit which is all the a's in this um in this direct product such that so ai is fij aj so fij of aj is pulling out the ai component

Okay.

All right.

So a little technical.

Sorry about that.

Right.

So light for a finite set is actually just going to be, I'll just make this nice.

So light for a finite set is just a countable limit of finite sets.

Right.

So you can define it in terms of size, weight, but countable sounds good.

So again, an example of a light for a finite set, the finite sets are the smallest infinite for a finite set is the one point compactification of the integers.

And also the Cantor set.

All right.

So let's go back to what a condensed set is, and then I will be done in about 10 minutes.

Okay.

So what is a condensed set?

So remember Schultz and Klaassen, they had this idea of like, how do I define a sheaf over a point?

Super revolutionary, very cool idea.

So there's condensed sets and there's light condensed sets.

And so a light condensed set, it's a sheaf on the category of light per finite sets.

So

This is not a Hartshorn sheaf.

This is a categorical sheaf.

So you write it as this.

So light condensed sets are actually sheaves on the category of finite sets.

And so they have this proposition that there's a more general way of thinking about these.

A sheaf on a category is normally a set-valued functor.

So you let condenseC denote the category of condensed objects of C, where C is a small category.

And then, so the condenseC can be represented as a category of small sheaves on C. Great.

So what we need is this, the equivalently condition.

So condenseC can be represented as a representable functor, which takes this form C off to set.

All right.

So here's the cool part, right?

So to summarize, we're trying to get an episodic memory as forgetful functors.

All right.

So if you model memories as these profanite sets and you reframe recall as left, working as left junction, which is kind of like an inverse map.

So we recall

the famous proposition that any set valued functor with the left adjoint is actually represented.

That's powerful.

So what is a forgetful functor, right?

So it's a math that sort of forgets some sort of structure in the original space.

I think memory is all about forgetful functors.

What do I need in this moment?

What do I not need?

Short-term memory, long-term memory, personal, semantic.

You're eliding something in order to create meaning.

So the forgetful functor, for instance, from compact Hausdorff topological spaces into all topological spaces, we'll call this functor U, has a left adjoint.

You can informally call it an inverse map from the topological spaces to the compact Hausdorff topological spaces.

And it sends a general topological space to a compact Hausdorff topological space.

This is very beautiful.

It's called a stone check compactification.

And it comes up in the work with profinite sets.

Right, so the stone check compactification is in general very large, but this is sort of like an example of what you're forgetting, right?

Yeah, I'll just say that, right?

So you're like forgetting the compact condition and to get to topological spaces, right?

Okay, so let's get just a little technical, but I'll just kind of go quickly through these slides.

So why is Grothendieck interested in descent theory?

What is this, right?

So kind of a scary definition, but it's okay.

So the theory of descent can most aptly be characterized as, so from the point of view of infinity category theory, which I've given some talks on.

So descent is a study of generalizing the sheave condition on pre-sheave, right?

So I mean, pre-sheave is a tool for tracking this local data.

And sheafifying it pretty much means you're giving very strict gluing conditions on these things.

So you want to study the generalization of that sheaf condition on pre-sheaves to pre-sheaves with values in higher categories.

So that's why we're calling this the infinity category point of view.

So those higher pre-sheaves that satisfy descent are called infinity stacks.

And so again, I think like gluing and recall or like gluing, sheaf gluing would be a nice

Mathematization of vivid,

profound imagery that imitates reality.

That's what I'm saying.

So I think it's in the gluing conditions where the hyperphantasia works.

Okay.

So more generally, descent theory studies the existence and uniqueness of an object in a higher category, provided some inverse image functor, which produces an object in some other category.

So you can sort of reconstruct the object from a higher category itself.

I'll just say this.

All right.

So the non-uniqueness is normally parameterized by equipping this object, F star u, with an additional gluing data, which we'll call gazai.

So this pair is called a descent datum.

So you have a reconstruction procedure of u from the actual data.

And so that's actually called a descent.

Okay, so the section of descending is formalized as what is called a descent condition.

So again, getting this F star map.

So you have an object U and a higher category CX and an inverse image functor, right?

So F star is just an inverse image functor.

from the higher category to a not a lower category c y okay so think of f star as an inverse image function that's what we're looking for so inverse image pulling this thing back and then this gluing data okay that's what we're looking for so to get very beautiful with this you could say every infinity one category of infinity one sheaves is a sub infinity one topos of the infinity one topos of pre-sheaves on a small category

So once again, that's something an object that you have is reconstructed from another object.

So it's this sort of like local to global phenomenon.

Right.

I will say

Each infinity topos is a reflective subcategory and a localization, which is sort of like a way of saying adding inverses of an infinity one category and a collection of morphisms which are sent to equivalences by the left adjoint of the inclusion.

So precisely those objects such that the pre-sheaves are precisely the local objects, this is an isomorphism in the homotopy category.

Homotopy investigates these continuous deformations of objects.

So the descent condition is how you actually descend from the higher category down.

So hyperphantasia is going to be this particular reflection, localization.

That's what I'm thinking.

Another one of my colleagues did this self-portrait of herself in a black hole.

This is sort of like, for me, what I think about as descent as a hyperphantasia.

You have a memory upon memory between any two memories, you have another memory.

So memory of self, memory of what I was, memory of what I could be.

Since there is no linear ordering, the time for the memory space can go both ways, I think.

And so having like spaghettification in the black hole and having redshift around the black hole and time sort of stopping,

But then you have that layered on the sense of self.

So I think for someone like me, if you're like, oh, describe yourself, it'd be something like this.

And so the image itself has so many layers just sort of on it.

So descent ingredients would be something like, so a more gentle way of saying this is that

that descent has a somewhat formidable reputation, as you can see, amongst algebraic geometers and almost everybody.

So in fact, it simply says that under certain conditions, homomorphisms between quasi-coherent sheaves, which is just sort of like a sheaf of modules over the structure sheave of a ring space,

We have a structure that conditions, sorry, that homomorphisms on the quasi-coherent sheets can be constructed locally and then actually glued together if they satisfy a certain compatibility condition.

And then while the quasi coherent sheaves themselves can be constructed locally and glued together by isomorphisms, that satisfies something.

So going from local to global is actually the same notion that I was saying earlier in the category theory sense of reconstructing data from higher category to a lower category.

All right.

So you have this notion of category theory, of a category in which descent theory works.

And these categories are actually known as stacks, right?

So what you really want to say is that in working in descent, you naturally work in fiber categories.

So that's why I said, you know, you want to fix a certain memory m and consider this set of memories over m. And so you actually call a fiber category as a generalization of a functor.

It's called a lax 2 functor or a pseudofunctor.

And then a pre-sheaf is going to be a functor.

A pre-stack is a fibered category.

And a stack is a category of sheaves on the site.

So this is how everything sort of works.

So you associate with a fibered category, oversee the data for a pseudofunctor.

And then so stacks are going to be the correct generalization of sheaves.

And you're going to get this nice notion of the sheaf of categories.

so if you want to actually say um so in a nicer way like what does descent mean when you're gonna you're gonna hear this everywhere like in that sort of literature and arithmetic geometry uh so to say you know descent for quasi-coherent sheaves these certain these sheaves of modules um or to say something satisfies descent you're going to say quasi-coherent sheaves satisfy descent with respect to

A particular topology, FPQC, stands for phase, really flat, quality, compact, just a specific topology in the gluing map.

To say something satisfies descent is to say that they form a stack.

That's all we're going for.

So when you say that the memory sets satisfy descent, I mean that you can actually stackify them.

So this word subcanonical is, again, very powerful.

I want to mention it one more time.

And I'm talking about the topology on the memory space.

I'm hoping that you need something that's like the topology needs to be sub canonical.

OK, so topology on a category is called sub canonical.

Every representable functor on C is a sheaf with respect to the topology.

So every representable functor

is a sheaf.

And then a subcanonical site is a category endowed with a subcanonical topology.

So a fun fact, because this is fun.

The name subcanonical comes from the fact that on a category C, there's topology known as the canonical topology.

This is the finest topology in which every representable functor is a sheaf.

Very beautiful.

So these concepts of subcanonical, I think, can be infused very beautifully into this notion of surprisal

So what does it mean to sheafify a functor?

So the construction of the sheafification of a pre-sheaf on sets on a topological space can be generalized.

I'll just say, so to sheafify a functor, we're just going to add the sort of categorical definition of what restriction map is.

In the interest of time, I'm just going to go over this.

All right.

So if C is a site,

and F from C-optic sets as a functor, then we're going to say that FA, C-optic set, is a sheafification of F, an amorphism from F to a sheaf factors uniquely through FA.

These are diagrams.

So there exists a sheafification up to FA, which is unique up to a canonical isomorphism.

This is the thing that I'm actually using in my work.

OK.

This is technical.

You don't need this.


UNKNOWN:
OK.


SPEAKER_00:
So let's get to the descent condition.

So why is this actually important?

Again, why am I looking at descending or pulling back memories?

Because I think that's what leads to the vividness and also the notion that there is no distance between these things.

So let C be a site.

A fibered category over C should be thought of as a functor from C to the category of categories.

So you fix a category, we want to look at the category of categories over that category.

So a stack is, morally,

a sheaf of categories of C. All right.

So if C is a site, the functor from C optoset, we also consider it as a category, vibrant insets.

Big note that f is a pre-stack if and only if it is a, it's called a separated functor, but f is a stack if and only if it is a sheep.

So this is the reason why you need, this is the reason why I'm working with like sheeps and what it means that if something satisfies descent, sheep becomes a stack.

okay so um there's an archetypal example of descent that you work with the category of continuous maps and that category is fibered over topological spaces by this functor p sends each continuous map to its co-domain

And then, so suppose that F goes from X to U, and G, Y to U. These are two objects in the category of continuous maps, mapping the same object in the topological spaces.

So you want to construct a continuous map phi from X to Y over U?

Yes.

Okay.

So I don't want to talk about this.

Okay.

So in this, because I'm already out of time.

So in the new model, the idea is, again, if you categorify these episodic memories as these fiber categories I've been showing, fix a memory, look at the set of memories over this.

And then so episodic memories would seem to be fibered in the sense that they lie over each other.

And so it's this sort of stack that I'm sort of interested in.

So memories stack for the hyperphantasia

And this sort of stacking-ness is what leads to the vividness.

So the descent conditions would be the following.

You use descent to represent hyperphantasia, memory, sheaves, satisfy descent.

And then this pair f star phi would actually be the categorical descent data.

So therefore, if you actually use this stackification method, then you get a surprisal as a sheafification of memory, right?

And so what you can do is this, right?

So the way that, so I have some results that I'm sort of thinking of.

And so you construct this functor from the category topological spaces over a profinite set.

And then you just get the

final, the ideas, right?

So there's a specific topology called the pro-attel topology, which is sort of like the attel topology for specific morphisms.

And that topology is a subcanonical.

So based on some of Schulz's very powerful theorems and his work on perfectoid spaces, remember the subcanonical topology is very important that every representable functor is a sheath.

So Schulz has this lemma that says the fibrid category is sending any perfectoid space to the category of locally finite three OX modules, the structure sheet, is a stack on the v-site, this is called the v-typology, on the perfectoid space.

Okay, so using these

using that Lemma and his other work on the V-typology, I thought, okay, we're just going to sort of shift these to the memory setting.

So I'm going to say let Y be a condensed set of episodic memories, and the functor which assigns to an extremely disconnected space is a profinite set.

The category Y over S is a stack for the protel topology.

So this right here would be the way of actually showing that

showing the actual descent conditions on the episodic memories.

Second claim, I recall topological space is a condensed set number, which is a sheep of sets on the Protel site.

The fiber category sending any X?

in the category of continuous maps to the category of locally free, locally finite free OX modules.

This would be a stack on the Protol site on condensed C. So on the actual condensed, the category condensed sets on C. All right.

So these results would be, how do you actually get, how do you sheafify the memory space?

And these themselves would be the descent conditions on Fantasia.

So these two claims would be actually like my new model of self-information would be, okay, you construct surprisal in this sheet condition and surprisal is actually just how far stacked your memory space is and rethinking surprisal in terms of descent, in terms of what I can recall back.

Because if I could actually theoretically recall everything, I think I would have no surprisal, you know, and I'll just say thank you.

Okay.


SPEAKER_01:
it was amazing shana thank you in the last minutes i'll quickly ask some of the great questions in the live chat okay i'll begin with the one and only dean who wrote if p attic as non-linear

Do we suspend the concept of next?

Do we begin at a place of all?

With all as our moves starter, do we need thresholds?

i.e.

all puzzle pieces are present and each is connected regardless of order of application, all pieces simply fit.


SPEAKER_00:
Wow, go Dean.

Yeah, I don't know if Dean's still there.

Yeah, Dean, please respond.

That's a great idea.

Do you get rid of the idea next?

Yeah, I think so.

I think so.

That would be pretty phenomenal.

Does this happen next or does it happen at the same time?

So Dean, yeah, do you mean like all in the sense of... It's not that everything happens at once.

I like your idea of all.

I think all can be zoomed into.

And so, yeah, abandoning the notion of next, that does sound a little radical, doesn't it?

Yeah, there would be nothing next.

It's more sort of like it's more now.

So I don't know if you're abandoning it.

You're just sort of, it's phase changing.

I love Dean.

Such a good question.


SPEAKER_01:
To the next question by Bert, who wrote, what about memories of imagined objects or events?


SPEAKER_00:
Yeah.

So Bert, that's actually what I'm trying to like poke at here.

Memory of an imagined event.

So if you're like me that between any two memories, there's another one.

And then between any two memories, there's like a hyperphantasia memory.

I don't know.

I'm starting to call into question like memory of an imagination, imagination of memory.

And so how do you work that sort of discursively?

And also,

Like, does the event get, like, when does, when, when are you, when, like, are you able to realize that the memory of that thing was imagined?

I don't know.

But yeah, I think the questions that you're asking is sort of the mess that I'm in on this MISO scale.

On this MISO scale, when does the memory of the imagined object turn into the memory of like a real object?

And so I think, Bert, you're in the same space that I'm in.

Why is it that the thing you call memory is just the thing that comes out and it's in the macro world?

But Daniel, I don't know.

What does it mean to have a memory of something imagined?


SPEAKER_01:
Would we even know?


SPEAKER_00:
I like your language there, Bert.

I'll just say thanks.

I'll look into that because on the hyperphantasia scale, I'm not sure if I'm doing that all the time.

So, you know, Meisner acting says you're living truthfully under imaginary circumstances.

I think this is pretty much people all the time.

But yeah, yeah, yeah.

So in what, and that's why we're interested in these sheaves, in what layer does the imagination, the imagined object flip into?

Okay, that didn't happen.

Store it over there.


SPEAKER_01:
Okay, and...

a question string of questions from sonia who wrote could this lead to a typology of how hyperfantastics quote picture conceptuality a space of abstractions and how a-fantastics

Afantastics conceptualize or perceive complex visual situations.

Do afantastics abstract infinitely into the future?

No gru-blean spatio-temporal ambiguities possible, and hyper-fantastics hold gru-blean for experience all the time, implying a different type of spatio-temporality or conception of infinity.


SPEAKER_00:
yes sonia sonia hey all right yeah grublin like okay that's yeah fantastical i love that yeah yeah yeah so um yeah sure what whatever you're calling your spatial temporal uh construct and whatever that space is yeah i think um absolutely has to do with um the topology the typology of how your memory space is constructed yeah so on the aphantasia side you will have no problem

working with just the idea of the space.

You aren't, in a sense, limited by trying to perceive the visualization of a tesseract.

Well, this is a 4D spatial object.

I can't perceive that.

But as an aphantasic, I can go in the infinite process of working on the idea of the tesseract, which Sonia does so well.

Sonia is the master of discursivity on taking a concept and just looking at every possible part of it and how it reflects on itself.

um and so i think both of these both of these extremes are going to work with the uh absolute reflection of these two spaces so yeah the topology of something like an aphantasia in the memory space and the topology of a hyperphantasia memory space absolutely is going to reflect um just like based on something that's taught reflect your spatial temporal um

like construct, but also I think I'm interested in like the frequency of the spatial temporal concept construct that you're working with.

And then even that itself would have like an expiration date.

So I love that space time for an aphantasia is totally different than space time for the hyperphantasia.


SPEAKER_01:
Okay, last question with a short answer.

Dave Douglas wrote, are a phantastics actually devoid of imagery, blind from birth would be considered separately given that their fantasies are kinesthetic?

Or do they, quote, fail to access their fantasies?


SPEAKER_00:
Oh, I love that.

Yeah, that's great.

So again, I'm more versed on the hyperphantasic side, which is why I went that way.

I like that.

Feeling to access their fantasies.

And again, and so I don't think any of this is sort of like negative by any means.

They sort of, you can say they go beyond visualization.

Why do I only need to see in the 400, 700 nanometer range?

So I think they could be actualizing their own fantasies in the analytic, in the fact that they don't need to actually be hindered by a visual representation.

that they can access it through the idea of it.

So say Artemis was my fantasy or something, okay, that I don't have to like visualize her.

It's weird, but that I can, the idea of Artemis, I have immediate access to.

So I really like that claim, but I also think it's not a failure in any way.

I think they're actually getting the fantasy on the idea front.

Such good questions.


SPEAKER_01:
Thank you, Shana.

It's been a great year with MathArt and all of our colleagues.

So looking forward to how this all continues.

Thanks a lot.


SPEAKER_00:
Thank you so much.

Thank you so much, Dino.