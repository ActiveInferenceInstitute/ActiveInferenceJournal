SPEAKER_00:
all right hello and welcome it is august 5th 2024 this is active info ant stream double one point one new stream series just dropped and this is where we're headed today we're going to be doing linguistic analysis on fully synthetic all by all dissertations

going to go into a lot more detail on what that means but just quickly at the top level each of these points in a principal component semantic space is a written dissertation shifting from one field to another following on on the lab of mike levin at all who who worked on the field shift one this is field shift two it does quite a few different things

And for example, this data point is the actual term frequency usage distribution on synthetic negotiation to synthetic quantum computation.

I'll talk more about what the synthetic part means.

This is like a PhD dissertation that's going from negotiation to quantum computation.

And here we have similarity clustering across in all by all of different domains.

We're going to be going to a lot of different places and ways.

Let's just start with this text file.

Off the bat, super excited for this.

It's been really rapidly developing.

I'm using cursor 0.39, came out just a few days ago.

Even better than the prior ones.

So let's start this off right.

I'm going to push 3000 files to a major Git release.

This is going to take a few minutes.

Once it pushes, push that now.

All right.

Once that pushes, then I'm going to come over to Zenodo and make a new release on GitHub.

So first just want to, while that's loading, you can see it on the top of the page.

Zenodo makes it super easy to connect GitHub repos

via Zenodo who offers DOIs, digital object identifiers.

So active inference is right here.

Once the GitHub push is completed, then we'll make a release of the repo.

And then that will get a new DOI and archive it on Zenodo.

So that's really awesome.

So just a few different tools using Zenodo for publishing for DOI, GitHub for a code.

And let's reload it, see if we're in.

one minute ago, active inference stream 001.

So now let's make a new release.

This is going to be number 01.1, needs a tag, 1.01 during the stream.

Publish it.

1.1 is published.

Reload on Zenodo.

And it'll probably take a few minutes, but that's pretty cool because then it'll also have the DOI coming from Zenodo and the archiving.

So maybe we'll check back there later.

Okay.

Let us go to

These are, it's in the background.

It's translating the dissertations into Sanskrit and Arabic in the background.

So hence these new files being added, but we're going to get all there.

Okay.

Start with the GitHub push.

Done.

Reload and confirm.

Update.

Make the GitHub update.

We did that.

And we're using cursor 0.39.

Came out a few days ago.

Okay.

For backup.

There's a page in the active block for its coda.

So it summarizes a little bit about field shift.

So I'm doing this, that's right now, August 5th, 16 UTC.

The code's in active inference, just uploaded now.

What field shift two is doing right now is generating thousands of these all by all domain A to domain B.

And I borrow this term and develop in the same tradition from Mike Levin et al's work.

So here's the paper here.

Machine Learning for Hypothesis Generation in Biology and Medicine, Exploring the Latent Space of Neuroscience and Developmental Bioelectricity.

O'Brien et al.

Levin.

So they briefly, let's see if the figures look bigger.

briefly describe how ai is playing an important and pervasive role in the scientific process they talk about analogies and isomorphisms between for example the neural synapse and the cellular junction bioelectrically and chemically considered they talk about some even broader quote functional invariance between neuroscience and developmental biology so that sounds kind of cool promising of course metaphor

Here's the BART-based domain translator.

This relates to taking material from one content and then putting it into an encoder, gets decoded.

And here they provide the outline of a GPT-4-based domain translator.

So neuroscience concepts and developmental biology concepts are juxtaposed.

I'll show what their data looked like in a second.

And they used that.

They also had annotators.

They had several person annotators and they tested how well were the ideas that it came up with.

They just showed that a few of the kinds of cases that they tested and then did some preliminary go-type analyses looking at like, were these hypotheses better than a uniform random distribution?

So that was really inspiring.

And I had shared previously with Mike Levin, the sort of mikelevin.py from elsewhere in the research methods folder.

So I thought that was pretty cool.

Let's look at field shift one, and then we're gonna go through field shift two.

So what field shift one is, first, I brought the whole paper's plain text in because then I can use this and say, what would field shift one think about this?

And then here's what their data sets look like.

So they had one expression.

So many memories come to mind.

So many pattern memories come to the body.

So they have a kind of expression from the neuroscience domain and then an expression that's analogous, deemed to be analogous from the developmental biology frame.

So I started playing with that and playing with that and playing with that.

So here's where we got to.

I'll start with what are called domains.

So this is in field shift two now.

Domains I have here, ATM transactions, biology, blockchain, Buckminster Fuller, chemistry, cognitive security, cooking, entomology, fabric, free energy principle, active inference, healthcare, hospitality, hymenoptera, that's the ants, the bees, and the wasps, and the sawflies, logistics, mitochondrial biology, negotiation, neuroscience, prediction matter expertise,

quantum computation, spatial web, traditional wisdom, William Blake, and we can make another synthetic domain.

So if anybody is in the chat and they want to request a domain, I will see if we can make it on the fly.

I'll show what it looks like.

But while somebody is posting a fun domain to add, it can be as narrow.

It could be entering the third digit of the pin in the ATM transaction.

or it could be like that corner but not this corner because a domain it's it could be an ism it could be a kind of a person it could be an entity so it significantly generalizes on what i had above with the entities but here's what the structure of these files are so the first line with a hashtag is saying what the domain is just its name

Then there are several dozens to several hundred examples and questions.

Also, depending on the situation and how it was generated and all this other things here, like a fact.

So chemistry may have definitions, examples.

All right.

Vladimir wrote intelligent soft matter.

Excellent.

I will add this.

So new file.

Synthetic.

intelligence soft matter dot md okay hashtag intelligence soft matter control okay so control a control k inline editing using cloud 3.5 sonic

we're in the domain folder, new file that was just created.

In the syntactic style of at cooking, say synthetic, these are, I just wanna pick a few of the synthetics at Markdown, at Markdown, transaction at Hemanoptera, synthetic chemistry.

Let's just see if one is enough.

Please write many relevant professional concise statements and questions related to intelligent soft matter.

that's why i described these knowledge bases as synthetic because they're being entirely synthesized in the file i'm not bringing in any transcripts or any factual databases i'm just saying generate likely expressions giving the the topic so it'll take a while i've i've way way rate limited the um cursor so here we go definitions

Example, definition, example, fact.

Intelligent soft matter often incorporates nanomaterials to enhance functionality and responsiveness.

Okay, so looks good.

Control A, Control K. Please, so now it knows exactly the format too.

Please add many relevant examples and questions.

but the semantics of what are broadly there are already defined.

So let's just let it do one more pass.

Then this is perfect because it'll expand our domains from 22 to 23.

Okay, I'll add one more for Michael Lennon.

Then with the 24, we'll push the 24 through the whole outline.

Here's the visualization.

Here's what's gonna happen.

First, we're going to generate the input domains.

That's where we're gonna have 24 of them in this case.

Then we're gonna generate pro shifted domains.

These are just gonna be like concatenated text files that will get sent off to the LLM.

It doesn't have to be its own script or anything like that.

But what the shift domains.py does is it's going to send this concatenated list of all by all domain shifts.

So basically prompt, then domain A, then domain B. Shift domains is going to send that to open API, open AI, API, get back a shifted domain.

The shifted domain is going to get prompted again to the LLM and it will say, make a dissertation outline with this structure.

So there's a dissertation outline for each all by all.

Then from the outline, generate it.

Then this is another LLM step.

Then from the draft, improve it, LOL, draft.

Then translate it into a variety of languages and just on the language side,

This is what that will look like.

Translated dissertations.

Here's the folders.

Spanish, Sanskrit, Russian, Punjabi, Portuguese, Navajo.

It's really interesting what it says for different languages.

What it will and won't do.

And then at any of these steps, we're basically just talking about a folder of markdown files.

So we can use a variety of language, meta analytic methods, and use those kinds of landscapes for our own use.

Okay.

Back to soft matter.

Okay.

I just wrote, please add many relevant examples and questions.

So these can be, you could add in more factual information or specific information.

So now we're up to, let me go, field shift two, just refresh the folder.

Inputs and outputs, domain.

Okay, let's add the one that Michael Lennon said.

Just do this and then we'll push both of those on through the all-by-all.

Non-science ways of knowing.

In the syntactic style of ats,

intelligent soft matter when we just generated same request here's intelligent soft matter in the file structure yeah and this is like

gets fascinating with, well, what does the LLM slash pipeline think are likely salient, acceptable, safe responses to asking about this or that?

Thank you for the gift, Upcycle Club, who wrote StigmaG ant emoji.

All right.

72 statements.

Interesting, citizen science initiatives.

We'll just do one more expansion, add many more relevant examples and questions.

All right, then we're gonna, with those 24 domains, then we're gonna push through it all by all.

But previously we had 22 domains, and so that generated 484 pro-shifted domains.

So let's look at these files

This is just a concatenated file.

So here's the prompt.

It's gonna say, whoa.

The prompt is, you're an expert, follow these steps for the domain transposition.

There's 12 steps and here's the output.

Okay, here's domain, go.

here's the synthetic statements on atm transactions all of them then at a roughly equal length here now where domain b is chemistry so then this is going to be atm isomorphies transposed onto chemistry

So it's like the way that people might think about things and the reverse.

So gripper and gripped, push and pull, swapping, perspective swapping, there and back, back and out.

All right, now we have 24.

Okay, so kind of come along in the cursor and in the file structure.

So first thing, in the terminal, just clear.

ls in the directory with these scripts so we go to the visualization first we had the input domains generate pro shift domains okay total domains processed 24 to the output directory

Okay, now we're at 576 pro shifted domains.

Okay.

Now we're ready to do the domain shift.

Shift underscore domains.

Okay, it skips files that it had already output.

So while it's doing that first domain shift,

While it's doing that first domain shift, and it'll report the timing of which one it did, Dean asked in the chat, can you explain field shift in a scale friendly as compared to a scale free perspective?

Let's revisit that, but it's a great question.

It makes me think of tilt shift photography, depth of field.

So here's what happened.

The ones that we already had, the 484 of the 576,

those were skipped so then we got to the first new field shift and we'll look at the script also but it's nothing more than the text file plus open ai synthetic neuroscience so neuroscience concepts transposed onto intelligent soft matter next new one was so that took 22 seconds they're taking up 19 to 23 seconds now

in the inputs, outputs, reload it.

So pro shifted domains is 576.

That's our cap.

But in the shifted domain SD file, we're at 487 because we finished three.

So that is going to keep plugging.

Meanwhile, it was just translating the background to have more.

Now, just we can already start to push

We'll run it again later to catch up, but we can already take the next step with the 488 shifted domains.

Okay, so pull back to the visualization.

What does the shifted domain look like?

And then how are we gonna use that to write the dissertation outline?

So here let's look at logistics applied to Hymenoptera.

So every single all by all was just the concatenation of you're a prompt expert.

You're about to do this domain shift.

Here's domain A, here's domain B, make the shift.

So here's what the shift domain yields.

So deep analysis of domain A. And this could be structured with systems thinking, Lentron Colley, George Movis, et cetera, et cetera, et cetera.

It would be awesome.

And there's many more structured.

That's been one of the most surprising learnings overall of the last like year.

Five days is, yeah, there's some structured ways to do cognitive modeling, claims analysis, rhetorical analysis, all these kinds of concepts.

However, especially with cursor in the game, there's so much that can already be brought forth with this rough or fuzzy probabilistic blob and hope strategy.

So domain A, deep analysis.

Domain B. Separate analyses.

Identification of isomorphies.

Isomorphies.

Sorry.

Unidentify isomorphism, so similarities in structure, between A and B. Transposition of fundamental elements.

Novel hypotheses and theory.

Ant colony supply chain management.

Develop a new lexicon.

Who's on first?

Outline a research agenda, envision revolutionizing education, identify technological innovations, anticipate resistance limitations, propose interdisciplinary collaborations, construct a compelling narrative.

So those were the 12 sections from the prompt.

So that's why these shifted responses are just responding to the structure that was

suggested by the prompt.

So now we're going to go from those shifted domains, which are just kind of like fact sheet type reports.

Now we're gonna go from the shifted domain to the dissertation outline generator.

Dissertation tab, outline generator.

Similar, where the dissertation output file already exists,

It skips it.

Now it's going to be writing an outline.

So now let's go to what, let's look at the dissertation outline script.

All right.

So first generate pro shift domains just really fast.

Logging.

Cursor, incredible for helping logging and bugging and debugging.

Here's the concatenation prompt.

Domain A, domain B.

Please prepare yourself to make a shift domain.

Here's domain A, here's domain B for all domains.

That outputs that concatenation.

Okay, now we go to the outline generator.

Dean asks, are those AB isomorphisms assumed stable?

It's a great question.

Put it this way, if you didn't change the text file and you ran the same computer

would give probabilistically within that envelope the same quote results which may or may not reflect how things actually were of course you can make synthetic domain you can make custom domains you can do harry potter you could make different um domains that also don't have anything to do with anything so maybe you could say this is this is the platonic solid domain this is just very few expressions very accurate

all right outline generator again logging getting the open ai api key this is kept in in like two ways in the dot env environment file and dot llm keys dot key both of them are in the git ignore

So you can put private, and I won't open them on the stream, but then it enables the scripts to use the API.

So you can just change that one file, like figure out what your API key is, put it into one of these kinds of files, and then basically there's a way to do it.

So generate the dissertation outline.

This one, I used another method relatively.

So instead of, whereas in the, in this concatenator, I set the prompt as a variable,

and then just concatenated three variables so there could be different prompts put in there like it could go a lot of different other ways just to at the at the outset because the prompt here is going to sort of direct how everything it's more upstream whereas in the dissertation outline generator now here's the structure of the dissertation by adding many sections even if it only gives like one to three sentences in each of the sections it's still going to have a good length

So it just says, you're creating a comprehensive groundbreaking PhD dissertation plan for a newly shifted domain.

This domain represents a fusion, et cetera.

These could be on new lines, it doesn't really matter.

Your task is to create a detailed, expansive, intellectually rigorous dissertation plan that articulates, et cetera.

Long line.

using the provided shifted domain description so that's that kind of like fact sheet report like here's how logistics could apply to hymenoptera develop a massive dissertation then here's the structure expected that's it then it concatenates it with the so that fixed prompt plus the um

shifted domain that yields shifted domain dissertation outline so now this is starting to get bumped up from 484 to 493 so let's look at one of these new shifted domains outlines so let's look at see if any have been written for the matter yet

Let's see which ones have just been written most recently.

Okay.

Synthetic hospitality to synthetic intelligent soft matter.

So this could be a hospitality lab saying, let's go into soft matter.

Could be the soft matter lab saying, let's go into hospitality.

But look at this one and the other flipped.

Okay.

So.

Personalization serves quality and sustainability from hospitality.

The research aims to redefine the capabilities of soft materials, creating responsive user-centric designs that adapt to environmental stimuli.

So background on the shifted domain, novelty, overarching questions.

So again, this is the direction of going, how can the principles of guest experience be applied to the design and functionality of intelligent soft materials?

Whereas the text file that says intelligent soft matter to hospitality will say, what can we learn from intelligent soft matter that will help us in the hospitality questions and situations?

Then it has all the structures.

Okay, new theoretical constructs emerging from the shift.

So these are actually sometimes super funny.

And there could be sections like add more puns and memes and everything, but responsive experience theory.

User interactions with materials can enhance functionality and satisfaction.

Like the material, it's not like its properties are just a priori and fixed.

They're interactive.

So there's a relationship with responsivity.

Materials quality assurance model, a framework for assessing intelligent materials based on user experience metrics.

Again, let in the all by all landscape, let that be the starting point.

But if it's a variant or if it's like,

another way to go, then that's just the starting point.

So that just gets the conversation going.

Methods, ethical, personalized soft matter, quality metrics for materials, smart integration, sustainable design principle, interdisciplinary implications, practical applications, future research, conclusion.

Let's look at another recent one.

Okay, entomology to non-science ways of knowing dissertation plan.

How can the principles of entomology inform personal development, community resilience?

What new theoretical constructs emerge from the intersection of entomology and non-science ways of knowing?

In what ways can this shifted domain influence educational practices, societal structures?

metamorphosis as transformation, social structures and community, communication models, ecological wisdom, et cetera.

Thank you, Michael and Dean.

Great comments.

All right.

So back to the visualization.

So that was generating the dissertation outline.

Next, dissertationgenerator.py.

same logic skipping the files that already existed let's look at what the dissertation looks like so shifted dissertations 484 that was the starting number so these were the ones that were there earlier how about cooking

to free energy principle active inference.

By analyzing how flavor profiles, cooking techniques, and culinary fusion can be understood through predictive coding and variational free energy, this research seeks to redefine culinary arts and enhance the dining experience.

How can culinary practices be modeled as adaptive systems that minimize free energy?

What role do predictive coding and variational free energy play in the development of flavor profiles and cooking techniques?

In what ways can this interdisciplinary approach influence culinary education, etc.?

New theoretical constructs.

Culinary systems as adaptive systems.

The role of sensory feedback.

Okay.

here 36 seconds it also includes the self i didn't exclude the the a shift to a so that's actually another informative loop about about what's there all right but now we have some new ones refresh okay

Neuroscience to non-science ways of knowing.

The significance of this research lies in its innovative approach to knowledge integration, challenging traditional boundaries between science and non-science by leveraging insights from neuroscience, et cetera, et cetera, et cetera.

How can principles from neuroscience be applied to understand and enhance cultural practices?

How?

What are the implications of cultural neuroplasticity for community resilience and adaptation?

How do cultural narratives function as symbolic messengers that influence emotional states and behavior?

What interdisciplinary methodologies can be developed to facilitate this integration of knowledge?

History, Ramon y Cajal, non-science ways of knowing.

New theoretical constructs, cultural neuroplasticity theory.

Maybe it's drawn from somewhere, maybe it's just a synthesis.

Symbolic transmission hypothesis.

Whatever is in the schema for the dissertation, it will write something with that output.

There's a few situations where, especially in translation and things, we'll say, oh, I don't really do that.

Okay.

Let's just carry on in the pipeline.

then that that's the dissertation draft so this should maybe be dissertation draft generator but obviously it's all a draft so the dissertation improver okay so it's it you can open a new terminal window if you want to have another open um edge with the api but um

let's um just terminate the one that's shifting the domains so that's how many we'll we'll just carry forth okay all right dissertation improver skips the ones that are already written it's gonna now it's hitting new ones that are also getting pumped in from here this could be coordinated like a lot uh

right dissertation improver okay this could be iterative there could be different rounds of commentary so that was again one of the most shocking slash interesting things was um on on two different domains so at the structure at the level of sections of a document like structuring modular publishing and all these kinds of efforts

and at the level of structuring like agents and reviewers and critique and actor network models so here's where both of those i was surprised on for the document composition there's very good adherence to this to the prompts

like I'm using here.

Like every single PhD outline uses the exact one that's requested.

So you could add more sections and add the token length and everything, add different sections.

You could request a different kind of document structured with certain subsections that like do or don't make sense with relationship to your input folder.

So yes, it's very strong and interesting to pursue the

strongly composable document composition.

However, using clear prompts is giving documents with good structure.

And then on this level of like multi-agent science, science agents, writing, massive writing, all these kinds of things, there's a lot of like flow and like, what if this went to here and that went to here?

And I think, again, that's very interesting.

And Jakob Smekal and I wrote the generative research teams, the GRTs that discusses a lot.

And it was exciting, okay, how to active inference agents and other kinds of intelligences work together, ecosystem of shared intelligence, AOS, the active entity ontology for science back in the DeSci 2022 days, all those kinds of directions, like let's have some kind of interoperable, strong message passing.

And again, I think that is going to be a strong and a vital element, but here with the total cost of millions of tokens still under the tens of cents,

at least using cursor it's been easier to just do all by all all by all all by all and just filter folders of markdown files

but then just do another combinatoric explosion and then filter down.

And also there's an interesting connection there with how that kind of relates to abductive inference and the two-stroke engine with generating and then winnowing.

So that's actually super interesting too, because it turns out, I'm not saying, well, if we connected this one to Blake and that fabric science, it's like just blast filter if needed.

But if it's not even needed, if it's just text files and it's only a few hundreds to hundreds of thousands,

Should be fine.

So dissertation improvement.

You're a world-class academic writer tasked with improving an existing PhD dissertation.

Enhance it in these 10 ways.

Follow these guidelines.

Like only add things, make it better, make tables, add hypotheses, enhance the language.

You could, you know, whatever it happens to be.

Here's the dissertation to improve.

insert dissertation in the concatenated file please do it now so here's improving dissertation chemistry to soft matter so some of these it's like and again this is what the language analyses show um like

in the semantic spaces in their own different ways, whether at the syntactic or the semantic side is like, okay, chemistry to chemistry or chemistry to quantum or chemistry to soft matter, those might like cluster closer.

And that's the exact kind of thing that we do measure and analyze.

And this is just a representative image here because you can imagine all kinds of linguistic analysis there.

So let's go to the improved dissertations.

this slightly um increases their length i didn't analyze the distribution but like they're all kind of like over 20 mostly so shifted dissertations that was the input improved once let's do let's just look at one that was already things oh well blockchain to logistics everyone knows about that one it's like okay

How about ATM transaction to Bucky Fuller?

By transposing the efficiency, accessibility, and security of ATM transactions into Fuller's framework of sustainable design systems thinking, this research aims to develop a novel model for resource management and service delivery.

The proposed Dymaxion kiosk, it's like new post Fuller term just dropped, will serve as a practical application of this model.

addressing global challenges through community engagement and innovation technology okay dean says michael says it's hilarious and yet strangely educational absolutely

And I think another thread to pull on is like, this is simpler.

It's so different, you know, catastrophically different than 2014 to 2019 doing my PhD with limited computer field work, less video chatting, but it's easier to just handle the folder slash different.

So it's just, it's all, you know, different is different.

And then Dean says, can you build an information mutation at some specific level?

Would that help the what ifs over the derivative intersection?

Yeah, that's like, someone just says like, this is just like pulling a crank.

Like you're just like moving strings of pasta forward and then they're just gonna be all headed for the trash pile.

But what you could do is you could be like, okay, like, okay, cooking to logistics.

That's kind of interesting.

Maybe there's a grant program or there's like a PhD student applicant volunteer who thinks this is like funny and then synthetic cooking logistics.

So, but it's just a text file.

So now later we're gonna translate this, but you could change this and just say, we're redacting this part, you know, replacing that one with that part.

I'm not gonna save it.

But you can change this or you could write another script that says mutate.

And it just does any kind of mutation to any subset of these text files.

Okay.

So then back to the visualization.

Now it's translated.

Dissertation.

Translation.

Again, it's so cheap per translation, below cents per operation.

So here's translation.

Here's the list of languages.

We're going to look into the folder and just see what it outputs for some of these.

translated dissertations so by language folder okay here's neuroscience to William Blake in Bengali can't read it

Chemistry onto itself in Hindi.

OK.

Languages with data sets that are large.

Have strong complete translations.

We can tell just by looking at the file sizes here.

So for Hindi they're all 34 ish.

Here we have a range.

Which is interesting.

So here's a smaller one.

Here's very small.

I cannot provide a translation of an entire PhD dissertation into Navajo.

Here's a longer one.

Translating a PhD dissertation into Navajo while maintaining high academic quality and technical accuracy is a complex task that requires deep understanding of both languages and the subject

Below is a translation of the provided dissertation into Navajo following the guidelines you specified.

Neuroscience onto cognitive security.

So here it's like, I won't, but then I did 14.

Here's a 4.3.

Okay.

It's going to be hard.

It's a complex task.

However, I can provide a sample translation of a portion of the dissertation to demonstrate how this can be approached.

Please note that due to the limitations of this platform, which one?

I will provide a translation of the executive summary and introduction sections only.

Okay.

So that's a glimpse into how it could be translated.

So just in the file size, you can see heterogeneity and both side-ism when there's little information.

Similarly, Sami, there's a 228 version.

Let's read it.

I can't do it.

And then an even smaller version.

I can't do it.

But the ones with a lot of training data, they have large consistent file sizes.

So here it is also logging, taking one minute, less than a cent per translation.

Skip the ones that I had done, 72, 67, 58.

All right.

uh language analysis last thing then we'll just do some other random uh improvements and look at super chats and everything michael lennon says i feel like i'm witnessing a shifting a pushing of the boundaries of what does science knowledge work in the near future thank you michael thank you i'm super happy to be able to share this uh

and for it to be open source and for there to be so many affordances for people to contribute and for work and clone all right language analysis

let's well let's just see what we have running right now okay so this now this one is um finished so you right now the orchestration like you you kind of have to comb over the folder a few times or you could do let it all shift then let it all write the outline etc or you could add multiple um multi-thread computing but

these kinds of things are what cursor at all are incredible on it's like selecting a piece of code and then just saying ctrl k or ctrl shift l saying make this run on n processors and then there are ways that it will do it well okay so from the terminal again clear okay

synthetic domains or it could have been real data or any kind of data all these are just text file outputs you can mutate them arbitrarily at every single step no need for agent orchestration just good old bioinformatics style text file

input domains but not saying that that there wouldn't be cases where you'd have higher efficiency etc with more nuanced approaches and different things input domains they were fully synthetic in this case we had start 22 then we bumped it to 24 with vladimir and michael's suggestion concatenate prep optional step if you want you can just batch these two shift domains makes the situation report on the shift

Write the dissertation outline according to how you say it is.

Generate the draft from the outline.

Improve it once, expand it, add unique hypotheses, et cetera.

Now translate to N languages in their own folder.

And then last script for now, just the language analysis.

Oh, now it's called meta-analysis shifted dissertation.

All right, so it's running in the terminal processing text.

So this is a local computation.

This is not using the AI or open API, etc.

You define the input and the output folder.

So here we're going to be looking at the analysis for the first dissertation draft, but you just change the input folder and you can make it look at any folder.

These are just examples of linguistic analyses.

Again, I just control A and just like add more relevant, interesting visual outputs to each folder or make a new kind of folder or make me something that will reflect my curiosity about X.

Okay, so the script on the prior version slash on disk, quote disk, is here running.

But now we're also live editing.

So we're confirming that the prior version works.

It's kind of like a little nano git because then if I accept these green edits and just rerun it right away, either it'll continue to run or it'll not.

Okay, so now it's added networks, interactive, and dendrograms.

Will they work?

Let's find out.

Scanning over the parts that are just not being touched.

But there's times where it will just say, oh, deletes a huge block of code.

Or there's times where it just does things that move you in circles.

But you get to see a lot of code, and it's a well-structured code, at least to this non-professional programmer's cursor enhanced way.

So it's a simpler semantic layer, whereas programming, when it got lost in the obscurity of where the bracket is closing, it gets really down there.

Okay, so I'm just gonna close that prior version, clear, save the script.

So if this works, then we'll see new things popping up in this analysis dissertations.

So if that will pop up in these new folders, but here's what these folders have now.

So this is principal component analysis.

K-means clustering.

Matrix decomposition methods, t-SNE.

Not saying these are the most like performance or anything, so many visual improvements, but just to say those are clustering methods.

Oh, this one will, the axes may need to be adjusted depending on how many like terms are in there.

Okay, top terms.

Okay, top 30 terms across all documents.

Okay.

This is just the PCA kind of L that we saw before, but there's a shading, like a 95% density.

So this could be used like, okay, what's that one, that one, that one, and that one, or like, you know, and, and then, then there's the PCA interpretability methods, which look like, so here's, here's.

Okay.

here's pc1 and pc2 these are these are linear decompositions and and variance quote explanation so here pca component one so this explains the greatest linear fraction of the variance just to kind of pull back one more step on the pcas every time you take a pc

you're explaining more variance.

That's what it's called.

It's not in the causal sense.

It's the correlational kind of explanation here.

But you're always going to explain more variance because you can always get some.

But then you look at the accumulation curve of the explained variance and say, okay, maybe, you know, and then you could either calculate like, oh, this is the optimum, or we only have space for three, but it's good to know that it's only 18%.

Okay, so here's one and two, each data point is a written outline.

So written, file names can be improved.

So negotiation is highly weighted on this and quantum is negative.

So documents that use negotiation, negotiators, conflict, strategies, resolution, these are to the right on PC1, documents that mention quantum to the left.

PC2, which is the y-axis is negative.

associated with the use of the word quantum and, for example, not the word culinary or mitochondrial.

Let's say, okay, yeah, quantum is up and to the right, et cetera.

So that's kind of what these plots are showing.

But then landscapes, and so, oh, what would be right here?

What would be like that one?

Okay.

Term loadings, let's see if it works.

Okay, specific terms, here's again, quantum is low on PC1, high on PC2.

Negotiation is slightly high on PC2, very far outlier.

You might get more resolution like on this analysis by just excluding these three terms, but this is just one way to do the analysis.

Okay, it's still chugging along, but yeah, you can extract what are the terms that are in each principal component.

So that's the kind of semantic space.

okay let's see while the visualization method um is running so so like here the translations are just chugging along chemistry to cooking in portuguese chemistry to cooking bengali now just looping through these languages okay

All right, so to return to this kind of overall one, but we'll watch the visual script run.

Okay, end to end, all by all, field shifting, domains can be synthetic or et cetera.

Dissertation outlining, expansion into the draft, draft improvement, draft translation, meta-analytic methods.

These are shown in the visualization.

But the visualization was just like, control A, control K, make ASCII art for this.

I think combining it with the grant methods that are in another corner of this repo here,

that's one adjacency upcoming developments okay incorporation of the entity and organization cognitive model so just again this was on the sort of how structured does a cognitive model need to be it was like here's fields dot py chris fields now these are not even real quotes

necessarily but they were drawn from these six i draw the six interviews in here's friston bucky fuller deborah gordon etc and yes there's other people thrown in so it's it's nowhere near um anything like a structured cognitive model let alone like the kinds of real speaker sorted transcripts that many people in organizations have this was just taking a few podcasts with these people

and then just distilling it and this this we can go into it like another time where we can add an entity if somebody wants uh there again there are these condensed quotes but depending on how you prompt it okay giving a vision or in a plotting here but let's see if it output anything else these are these like dot pys pseudocode ish quotey now they could be interoperable if you had a schema defined

maybe a PhD student could work on that, but then they can also be loose.

But bringing the entity and saying, okay, how could these two entities, like this organization and this person or these two people or these two organizations, these three, concatenate their entity models?

Like we can even do this and then say, how could they refract through this shifted PhD dissertation to that grant?

Well, if you can compose it, it's at least plausible.

Okay.

Entity and organization cognitive models, integration of grant proposals per research method, secure funding for PhD projects and just sort of, you know, more.

uh explain like i am dot dot dot so we could concatenate a prompt that's like um explain this shifted um about the dissertation that's applying atm transactions to cognitive security explain that like it's this kind of event to this person

it never is gonna at least be interesting and funny when it shows okay okay thank you michael for your great comments always very insightful okay so then we could do how would you explain this to dot dot dot and then that generalizes oh 17 18 19 20

But then, so what does the model think about how you should explain something?

And then it's like, well, let's call multiple models if they're getting so, so, so available.

Now, that's the whole deeper questions about like externalities, et cetera.

Grant methods, okay.

Just as a brief recap, well, I'll put the, in the live chat, here's the field shift coda.

Here's the grant method.

So this is from prior.

So this kind of goes through what the grant concatenation methods do.

I'm not going to go through it on this stream, but they're in the same research methods folder.

Okay.

Yeah, and any other things.

So maybe one, we can try one suggestion that somebody has.

Like one analysis or a new domain or a new entity or like let's just do one random thing.

You can support the project and earmark donations at donate.activeinference.institute.

Future streams, oh, this will be, there's actually a few other interesting topics while people are thinking about what else to say.

Okay, P3IF, there are some pretty extensive P3IF methods in the repo.

It'll be a later Act-Inf Ant stream, but check it out if you look at the repo.

It would be awesome to have, if someone sees like an adjacency or if they see something that they can add to like section nine, any of these kinds of like frameworks, that could be awesome.

And then we go, oh, make a Kafka database that sends messages to the Coda API to write these grants and then post it through MatterBridge to Discord.

Then developing the active inference kernel of the InferAnt repo.

So Python, PyMDP, et cetera, Julia, Rx, Infer, other languages.

There are several other languages.

Section I. Okay.

Here was just one sort of thought on the multiply scale science.

So this is just using just a sort of standard academic ontology here.

a phd student is like one dissertation contains multiple papers which was how it was uh concisely described to me then a principal investigator has a lab with multiple dissertations overlapping serially

organizational scale is to have multiple labs within one organization and then above the organizational scale especially in an online context it is a spaceship earth situation and that's part of this um grand science spaceship earth journey um one tiny step for an epistemic forager one giant leap for antkind

Flower Poem.

Okay, this is gonna be a short Tennyson poem.

So the kind of background on this was Buckminster Fuller was on the editor team for this journal called T-Square, later known as Shelter.

And Frank Lloyd Wright wrote this article about how all may plant flowers.

And then I looked that up as a title and found that it came from this poem.

So then also, it's going to be awesome to see how the cursor can enrich this too.

Okay, The Flower by Alfred Tennyson.

once in a golden hour i cast to earth a seed up there came a flower the people said a weed to and fro they went through my garden bower and muttering discontent cursed me and my flower

Then it grew so tall it wore a crown of light, but thieves from over the wall stole the seed by night, sowed it far and wide, by every town and tower, till all the people cried, splendid is the flower.

Read my little fable, he that runs may read.

Most can raise the flowers now, for all have got the seed.

And some are pretty enough, and some are poor indeed, and now again the people call it but a weed."

And then I did this one time, but I'll see where it goes this time.

explain this in the just discuss this in the context of open source it said some really funny things

But then the way that kind of connected to the doing and the learning and the foraging and then also the planting, planting experiments, collaborations, really proceeding on grants, like not just planting the seed, but there's the foraging and attending and being attended to and planting and or foraging for having and or being able to have the seed.

However, that doesn't mean every foraging trip, etc.

Okay.

So open source, you know, from back in the day.

The seed is dismissed.

Resistance from proprietary software.

Success?

The theft of the seed at night might symbolize how proprietary companies sometimes adopt open source principles or code without fully embracing the open ethos.

People use it.

Anyone can use it.

The final stanza reflects the reality of the open source ecosystem.

Not all projects or forks are of equal quality.

What was once novel may become commonplace or even dismissed again.

Wow.

Okay.

Thank you, all the chatters.

Let's do one more kind of permutation.

Let's do the explain like I am X. So we just saw the outline generator.

Let's go to one that has a fixed prompt.

It'll be simpler.

take the copy, rename it, explainer.

Control shift L, go on to the right side.

It could be done in line too, but just sometimes it's more deliberative on the right side.

Adopt this script to be an explain like I am blank analogous to the list of target languages.

Make it eg target audiences.

michael wrote angus deaton nobel for econometrics warned recently about hidden power dynamics behind quantified models helping with the inter-humaning around the tech e.g uncovering hidden power or fussing forward through competing interests is key thank you michael oh yeah if anyone has uh something for in the uh 10 to 30 minutes total

Let's see how far this explainer goes and then anything else or like comments or questions that people want there.

Okay.

So it changed target languages to target audiences.

Keep the API key.

Here's translate dissertation.

Here's explain dissertation.

So replace target languages with target audience.

Renamed translate to explain.

Updated the prompt.

Updated file naming, adjusted log message and print statements.

It's like, what?

You did what?

Accept it.

Okay, let's tune the... Well, first, let's just see if there are any other visuals.

That script halted.

Shannon diversity indices.

So this is the font of course can be fixed, but this is kind of interesting.

This may just be a random draw, but still within the documents, some have a higher and a lower Shannon diversity of term usage.

So maybe those are more interesting or have more combinations.

Heatmap, term frequency heatmap.

Okay, yeah.

Y-axis, you know, scale could probably be improved, but there are some things there.

Correlation matrices.

Interactive, nothing output.

It just halted.

It just, maybe it's too big of a jump.

Networks, halted.

PCA, 3D, in and out.

Think outside the box.

What box?

Quantum negotiations.

This showed the vector that we kind of looked at with the loadings.

Variance accumulation.

No vector, just the data.

Again, this is just PCA.

This was taken from the grant processing pipeline.

So it was, you could look at the heat maps of different entities, top terms, just across all documents, word clouds didn't output.

Okay.

Let's if there's any target audience, uh, let's see if we can do just a couple.

So we get a few across each.

Let's have curious five year old.

Oh, autocomplete curious.

It's just like that with the syntax and the autocomplete.

But I'll edit this down to a few, but also anyone should write in the chat and we can include a few creative target audiences.

skeptic well studied and highly motivated skeptic college students undecided on their major

Michael Lennon writes some additional dashboard indicators, epistemic forging adjacency.

Oh yeah.

Additional audience types.

Okay.

Yeah.

I'll wait.

I'll wait a few minutes.

Okay.

Then let's, let's just look at the prompt that it's going to throw.

I don't want people to write that for a minute.

Okay.

So now the functions explain dissertation.

So now here's the prompt template fixed prompt.

Your world-class educator tasked with explaining PhD dissertation to a target audience.

Maintain accuracy while adopting the explanation.

Maintain integrity, dignity, mutual dignity, and accuracy while adopting the explanation to the audience's type of understanding.

and broader personness adjust language these are this is where it gets triply interesting with how people really think about the topics the model training and this and how it's processed adjust this is just we won't go into deep editing this but this is just what it comes up with as the likeliest thing that you would say to generalize across explanations as a concept

Okay.

Thank you, Michael.

Let's do.

Curious five-year-old.

Okay.

We can go rich or we can just go more simple and general.

I'm going to just... Well, this one, PhD student.

Then college student.

So we have five-year-old.

How about high school senior undecided on whether or where to go to college.

So we have five, 17...

PhD student, advanced professional, advanced technical professional.

Okay.

Python three, dissertation explainer.

Okay.

bug.

That was the one shot.

So then here's maybe we need to fix the input outputs.

Let's go from

original oh it's not original dissertation so that's that's like it's just like there it didn't take the file structure into strong account um but in many many cases it does it just that's where it so while it's kind of thinking that's just because it's saying from original because i used the word original but then it didn't know which one of these so let's go to make it the shifted dissertations improved once

Explaining dissertation to a curious five-year-old.

Boom.

Cursor's gotten better and better in every version, truly.

And these are some of the minor things that, you know,

whether it's whether how its cursor side or the LLM side, just the way that it's doing web search for best practices and able to parse some of these just arcane syntax.

It's incredible.

All right.

They are coming out into explain dissertations.

We'll let a few accumulate.

Okay.

The goal, this script doesn't really work, or this overview now needs to adopt slightly, but the goal of this was to make, like, let's see, also, this is one other thing, is sometimes it helps to manually resync the index.

That's the vector embedding that Cursor is using under the hood.

So it won't be able to, on index code, it will not be able to find.

So I, even if you do add new files here, now it's synced it.

So now, control K, let's just do it.

I think control shift L. Update this to reflect the folder.

structure, input, outputs, functions, et cetera, of everything now.

Hundreds of changed files.

So it's processing on that.

The dissertation explanation proceeds.

Let's update this.

So here's another example.

Little minor limitation, but it'll be handled.

It just pops in and out of the text formatting.

This is something that's very challenging to resolve actually in general.

It's in and out of text, in text, in text.

Especially if it's all plain text.

See, like, this is fantastical.

There are no such.

However, these are partially accurate.

There aren't the explanations.

So it's like wildly admixed combinations of close, technical, very subtle errors on through just like totally believable, but also, and then just like, okay, here's how you run the script.

It's like, no, it's not.

Rejected.

Okay, explanations.

All right, five-year-old.

Okay, first it's starting with, all right, so let's do, okay, the

neuroscience to we're applying neuroscience methods to biology for a five-year-old so this is maybe like someone mike levin's love from that original field shift paper like neuroscience concepts on to developmental biology okay what's the big idea understanding how nature and brains work together what's the big idea

Imagine if nature, like a big park with lots of plants and animals, works a bit like a brain.

This project called a dissertation, etc.

Why is it important?

Questions we want to answer.

What we found out before.

Found out about brains.

We found out about biology.

Those are the from and the to domains.

Same strategy.

New ideas.

Nature can change.

Learning from experience.

Neuro concepts applied to ecosystem.

But I remember the paper, like what can ecosystems learn?

And it's always coming up.

And then so it's like stabilize the metaphor, raise the water level on the metaphors overall and the kind of take the water table to be like this for every all by all.

How are we gonna learn more?

What we'll discover, why it matters, what's next?

Let's keep exploring, even little emojis.

Okay, now let's go to high school.

It's still in the it's still okay.

Let's let's go to PhD neuroscience to cooking written more in a high school textbook.

Style, background, significance and novelty, overarching research questions, literature review, overview of neural networks.

Table one.

I don't know how you pronounce some of these tables in conversation.

58, perceptron.

Okay, historical development, the culinary arts, current state of the art.

Here's the gaps and opportunities.

Pretty long.

This is looking more like, well, this was for a PhD student.

So this is more like, here's the kind of brief on each of the sections of the dissertation.

Neuroscience to cooking.

Let's see if this one has similar.

Okay, this is like sharing your overall outline for like quals or something.

High school senior.

Okay, so this could be the same one we looked at with cooking, but now for the high school senior.

Yeah.

What if cooking was not just an art, but a science?

Because it's neuroscience to cooking.

Background, significance, simpler questions, but still broadly like the structure of the dissertation.

Here's what the chapters are about.

but with just one sentence instead of like several paragraphs there.

However, it's structured like a dissertation.

yeah okay let's do a few mills 8102 wrote i love these wild mashups i bet there's plenty of gold in this approach oh so so now we're just pushing like kind of trickling the next few through but let's let's go to the shifted once so these this is these are you know the ones that have been improved once in a certain way so let's do

Blake applied to logistics.

So this one was super fun.

Again, I just wrote, make expressions about William Blake and add about his mythology.

By examining the parallels within Blake's emphasis on creativity, spirituality, and social critique where the challenge is faced in modern logistics, the research seeks to establish a new paradigm term, the Blakean model of logistics that prioritizes visionary approaches to supply chain management.

Okay, William Blake's life.

How can Blake's concept of imagination and contraries inform innovative practices in logistics?

And then if someone's like, well, what about this other important concept?

It's like, first off, maybe it would have selected from it.

Second off, add that to the original synthetic domain.

And then that topic will come up in approaches.

what ways can a spiritual approach to work enhance ethical considerations in supply chain management what frameworks can be developed to balance efficiency and sustainability in logistics blake's accurate birth and death because it was included in the factual claims the blakian model of logistics duality framework balancing competing priorities in supply chain management

methodologies, statistic make usually a kind of mixed method, like through structured prompt or any of these way more advanced methods, access to the literature, et cetera.

You could have it be proposing specific hypotheses.

It could even be writing the code for, for the preregistration and everything sustainability.

Okay.

The Blake ones are fun.

Um,

Let's quickly look at the prediction matter expertise domain just because it's the outlier domain.

So this is part of the long-running deanticalism with the subject matter expertise like the domains and then prediction matter expertise as this kind of like orthogonal dimension.

So for this one, I did copy in a few of our specific papers.

like about Alison Baugh, the way finding.

So there was a few.

Then I just said, just expand on this concept of prediction matter expertise, come up with mottos, come up with memes, switching gears like a PME pro.

When in doubt, synthesize it out.

Predicting the future, one cross-disciplinary insight at a time.

So questions, examples, so it just invents all these examples.

So that one is sort of like, that's the paradox with the PME as an SME, but let's see what one of those might look like.

Okay, so this is healthcare principles applied to PME.

So PME is what needs to be transformed

by establishing a robust framework for user experience, quality metrics, and tech-driven solutions.

Predictive analytics, patient-centric.

How can we map healthcare situations to prediction matters?

Healthcare, how about something with the spatial web?

cognitive security to the spatial web cooking to the spatial web.

Examining how principles from the culinary domain can enhance user experience design in digital environments.

How can what works for restaurants as as places and times and experiences work for spatial web?

How about

prediction matter expertise to spatial web.

And then again, it's like, oh, I would have said something different.

First off, we can have many branches of people's models, but also then just we edit the source document.

This seems to highlight just a predictive statistics and adaptability angle.

But then the language analysis can be like on these, and then you can do it on the explanations.

And one of the interesting and I think helpful ways to think about a few of these operations that are happening is like the principal component analysis on the term frequency uses, so let me pull that one up and then

So here, term frequencies are being used within and across documents.

So in this situation, if you had X dissertations in the folder, and then you're going to translate into a bunch of different languages like L.

so if you cluster on syntax like term usage then the languages are going to cluster together because they're using terms that are like exclusive to one language or another character sets even if you clustered on semantics then the dissertation would cluster together across languages which convey

in in the case of an accurate translation like similar ish semantics so that's basically the difference between syntax and semantics and that's something that's really opened up with these methods is what what i've been showing with the term frequency type analyses syntax based methods they're still very cool and there's actually a lot of information in them

However, what cursor, especially with the language models overall are enabling is just like arbitrary semantic discussion.

So thank you, Michael.

Explain the at field shift overall to a clamp.

Okay, advanced technical, here we go.

Neuroscience to blockchain for advanced technical professional.

foundational work, proposed integrative mile model, neuro chain, adaptive consensus, learning smart contracts, mixed method, case studies, surveys, interviews, simulations, analytical approaches.

So here's

That's the explanation script is running.

Oh, here's the clam.

You're nestled in your cozy ocean bed and suddenly the water around you starts to change.

That's a bit like what field shift does, but for researchers studying the world above the waves.

Field shift is a special tool that helps scientists understand how the environment is changing.

Interesting.

Field shift collects a lot of data about the environment, like temperature, rainfall, and plant growth.

It's like...

What?

So that's kind of the funny, again, the huge range of what comes out in different contexts.

Let's look at a few more random dissertations.

these are the ones that were made more recently but we halted that one let's just look at one or two more okay william blake oh we looked at a blake one already but we haven't looked at a let's look at one fep see this whole fep applied to x this is like

I hope broadening the scope, it's like, it's not just A to B for FEP to that.

The immediately available adjacency space is domains to the second power, for starter, even before imposing other more high dimensional aspects for interdisciplinary from to to.

But then there's other structures of synthesis, other kinds of patterns that can be emulated, but this is just the from to to.

So we have whatever expressions and claims we put in about FEP and ACT-INF that fit in with the LLM schema slash length and attributes, this is the starting point or a starting point for some of those discussions.

So here's FEP mitobiology.

Transposing the free energy principle to mitochondrial function.

How can predictive coding and active inference be applied to mitochondrial function?

Different methods, like that would relate to the actual working it out.

FEP to an ATM transaction.

It transcends the immediate context of self-service banking.

It holds broader implications for adaptive systems and technology and user experience design.

First principles for the ATM.

FEP to quantum, something that is happening.

So in the context and or in the files or

It may FEP, Fristin.

How can the concept of VFE be applied to optimize quantum algorithms?

In what ways do generative models and FEP correspond to quantum states and quantum computation?

What are the implications of active inference for the measurement processes in quantum systems?

Okay.

FEP to cooking.

How does predictive coding and active inference apply to flavor development in culinary practices?

In what ways can generative models inform the evolution of cuisines and culinary fusion?

What educational frameworks can be developed to integrate FEP concepts into culinary training?

So the last edit I want to make is just to update the read me and then push that so that it is accurate for when, and then I can update the description in the code or in the YouTube or where all the folders are.

If anyone has a last comment, though, please feel free to ask a comment or question.

Position 10 slow request.

So even when I'm way over 500.

Oh, also, here's what else is amazing.

I'm gonna reload the page.

I don't think anything will show.

I've spent $12 on this whole phase of the project.

First API call I made was on August 1st to GPT-4.

I was like, okay, that's the best model, right?

wrote two of like the two of the first step, first two shifted domains, stopped it, wait five minutes, reload, I was like, oh no, well, that was $3.

Oh, $1.50, it's like, okay.

And then I looked up, I asked Perplexity, I was like, what are the costs and everything?

And what's the best one for large stock?

It's like, oh, GPT-4-0, it's like, okay.

so that's two dollars today and then yesterday when when i went through all the uh i mean when it was going through all the uh like 484 whatever it was that was three dollars then activity number of tokens so now it's hidden too fast but that's even just with a couple python terminals here's gpd4 mini

that was 11 million 11.7 million tokens for three dollars so token's not exactly a word but like this is on the order depending on on everything et cetera et cetera I don't know but it's it's it's not it's not 10 10x and it's not a tenth so it's an incredible amount of text processing

today, 6.8 million tokens for $2.41, $2.42.

And then Cursor,

So Cursor, I'm paying $20 a month.

This is just to describe the methodological and the kind of financial, not the time side, but just like Cursor's $20 a month for the 500 fast requests.

But then the slow ones are not that bad.

So I don't know how it is not with that at all, but it's clearly worth that and beyond.

Then the API calls for open AI.

Some colleagues shared the open router.

I think it's a great idea to like improve the LLM handling, make that more flexible, be able to do that locally, et cetera.

But just to use what was working now for several dollars to create these all by alls, do the shift, make the outline.

Write the draft, improve the draft, translate to arbitrary.

Control K, add the explainer into the visualization.

All right, any last comments and then I'll end it and push it after this.

It just says, no.

Maybe if I don't call it.

explanations still okay curious five-year-old let's see little blake neuroscience blockchain chemistry okay neuroscience to blake

This special study looks at a famous artist and poet named William Blake and how his ideas are like the way our brains talk to each other.

How can we think about Blake's ideas like a brain?

What can we learn from mixing brain science and stories?

Here?

Again?

No.

Well, I guess it isn't to be right now.

Check for any last, read me.

And the folder structure may slightly change.

These are all just early working folders.

I think fonts underneath research, underneath methods, underneath one, this might be a good source for longer reference to like grants and to structure that better.

But already in the research methods folder, this is where all the grants methods are.

But that's kind of grant methods 1.0.

So we can make it kind of grant methods 2.0, field shift, plus, plus, plus, field shift three.

And that would maybe with more flexibility, like select a prop, select the entity combination, maybe select the order.

And then we could just, we could get rolling on many fronts.

Whereas actually like, you know, in its own meta way, this was manual with heavy augmentation for a lot of all by all considered as text files, but structurally manually derived.

So it could be distilled and improved.

Okay.

I'll just wait one more minute to read anything people write while I end the stream and push the GitHub.

It's going to be an active project at the Institute for the Active Inferent Project, so people can contribute asynchronously with questions, issues, documentation on the Coda pages in the GitHub.

If someone wants to work on this or integrate it with some other way, please just contact me.

We can figure out the right

institute related or just other arrangements and add a bunch of pieces to all of this and just part of the beauty of the the code and the open source system is like it it hopefully can ratchet the function like this doesn't do at all but now this is a starting point and the outputs even if you don't run any code at all in the github

you can still see the outputs.

So I'll push it.

We'll look at the GitHub final and push prepare methods, research field shift to everything's in here, inputs, outputs, shifted dissertations.

Control F, you know, just whatever you want to search for.

Blake.

It'll search on both sides.

Blake to neuroscience.

Here it is.

Translated dissertations.

Sanskrit.

Here it is.

I don't know.

Cool.

All right.

Thank you, Upcycle.

Thank you, Mills8102.

Thank you, Andrew.

Yeah.

All right.

Well, we're live.

The calls go on.

So I hope people who are interested share it and the repo and the video.

And let's do InfraAnt streams.

to develop so many of these fractal functionalities of this repo that has long been in the Institute's domain.

Andrew wrote, wondering if a separate 10-ish minute setup tutorial on how to reproduce the cursor Python GitHub integration would be helpful for others to contribute.

Yeah, yeah, great suggestion.

Like make the issue on the GitHub and then I'll make it an issue then we'll get it to it.

Cool, all right, thank you, bye.