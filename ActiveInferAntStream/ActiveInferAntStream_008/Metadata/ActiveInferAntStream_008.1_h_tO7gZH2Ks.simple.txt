SPEAKER_01:
All right, welcome to Active Inference stream number 8.1.

It's December 15th, 2024.

I'm going to start with a GitHub push to the GitHub repo.

Active Inference Institute slash start.

While we have Meanwhile, Cursor, current version 0.43, translating curricula in the background, visualizing learning paths, having our agenda up.

So thanks for joining.

If you're watching live, definitely write some interesting things in the chat and I'll look to re-enter it into the stream.

All right, here we are.

Symbols greetings.

Good evening, Jeff.

Again, this is in GitHub repository, Active Inference Institute slash start.

The idea here was to build on some prior perplexity and LLM based methods that we've worked on in different projects earlier in the year and kind of continue with this all by all theme across domains and backgrounds intersecting with onboarding and curricula for active inference.

This is more than just a translation tool.

It's a framework for understanding and optimizing how knowledge flows through different perspectives.

Modular treatment of topics and perspectives enables flexible application.

Okay.

So first, where are we headed to in terms of the output?

Then let's look at the scripts that are using Perplexity even now to go through it.

So the written curricula are in English and then they're being translated in chunks to other languages.

So here's

a synthetic biologist background introduction curriculum to active inference translated into japanese and this is more than 1400 lines long that's what it looks like in cursor let's reload the repo it's still writing this very large initial push

we'll look at what the markdowns look like in a few minutes that's the translated curriculum the written curricula there's two sets of audiences that we'll trace back to that it's drawing upon the first with just their names are individual specific people

or different audience profile.

We'll get to how that's specified, like a high school student and a middle school student.

These are different audiences or different synthetic knowledge domains that are constructed.

We'll again, look into them like cooking.

So this is a complete curriculum implicitly in English for somebody in the cooking industry.

conduct workshops where participants develop new recipes using active inference algorithms, predicting food safety risks.

Those are the different domains.

So this pipeline that we're about to go through uses perplexity.ai, large language model, LLM interface API to do research on entities

specific or groups of entities and different synthetic domains.

We'll look at how they're defined.

Pool those researches.

Those are done in step one.

Step two, write introductions.

Again, going to call perplexity to write out those curricula in chunks in English.

three does visualization of a few different kinds on those generated curricula four translates into languages right now these languages are uncommented out there's more languages you can just comment uh or uncomment

I will show my perplexity balance at the beginning of the stream and then we'll see how much it changes on during the stream.

Okay, $67.68 in the perplexity bank.

Using the small here on their model card,

page I'm using the llama 3.1 sonar small 128 online this is the same context length as these more larger parameter models just from short testing though it's faster and it's cheaper so 67 68 okay all right

So where we're going is this, now let's look at the visualizations on those curricula from step three, then look at the scripts.

Okay.

First metrics.

So this is for each of those

It's just translating chunks in the background that can be multi-threaded, but it can also cause more API trouble than it's worth.

Okay.

So this is for each is a comma separated file.

Open it in LibreOffice.

this is some word count information on in the sections in the paragraphs descriptive statistics on curricula metric this file is some summary statistics on those 37 written curricula in terms of the mean and the average and all of that of those descriptive statistics

metrics distribution.png has those descriptive document statistics for those 37 curricula okay content analysis this is principal component analysis pca analysis

on 13 cumulative percent of the variance in the term frequency so it's interesting that the entities are all clustered or more closely clustered over here or at least some of them key concepts top 20 concepts word cloud

similarity matrices with hierarchical clustering so here that this um dendrogram does sort of visually and at the hierarchy monofily uh topological clustering method confirming this cluster for example something or there's this relationship logistics with whatever it is

spatial web topic distribution this looks like the rows are the loading in the different 37 curricula the topics are top top seven topics and they're

presentation across interesting that shioka works in fashion and so there's a connection with the fabric we can see if that pops up again different topic okay and topic summaries topic one so this is the one that has this loading across these different fields

Okay, then there's concept maps and learning paths.

Here's the concept maps.

These are just starting points.

All of these are just starting point draft outputs, but they can be updated from the underlying information.

So here's for Chris Fields.

For the curricula generated for Chris Fields,

this is a eigenvector centrality network topic graph in different communities high school student concept map let's see this one

free energy principle looks like it's in this one orange community variational minimize inference active energy there's the blue neural biology decision organismal tool making maybe these have use maybe not middle school student but cool nonetheless

That's concept map and here are learning paths.

These are just okay.

We'll see how this one's looks like a very example applications are central connected this hub and spoke way to the these high school student path.

Somebody with a background in ATM transactions.

AI-powered ATMs.

Case study two.

Personalized user interface.

Biology graph.

Bucky Fuller.

Ephemeralization.

Biomimicry.

cooking data on flavor profiles and ingredient interactions food safety training predict the flavor profile for a given combination of ingredients entomology insect behavior and biology

So at least in the ballpark.

Those are the meta-analysis visualizations.

Let's just look at one of those written curricula files then into the scripts.

So let's look at video games.

Let's see if the GitHub push is done.

okay yeah write any questions or write a topic in the chat I'll try to re-enter it let's look at high school students and a video game

high school students in 2025 source high school student worldview key knowledge gaps cultural linguistic considerations conceptual bridges so this top part okay now getting into some topics

Predictive coding.

Further reading learning pathway.

Learning environment OK.

And this is for.

Now let's see the video game.

Game design.

game mechanics narrative designed user experience agile programming game integrating active inference into game development dynamic difficulty adjustment mental health same example used in the high school case here's the curriculum content so it's about it's two and it's it's it's separate in two there's the

domain analysis and then there's the curriculum content and then they're just concatenated to get that marked down so here's the curriculum itself so let's see that has welcome message relevance value proposition

Connection to existing domain knowledge.

Overview of learning journey.

Success stories and examples.

Conceptual foundations.

Core active inference concepts using domain analogies.

Mathematical principles with domain relevant examples.

Practical applications in domain context.

Integration with existing domain frameworks.

Case studies in the domain.

Dynamic difficulty adjustment narrative generation.

For GIMP.

Interactive examples and exercises.

Some of these interactive ones are TBD, but at least they're scoped there.

Technical framework.

Mathematical formalization using domain notation.

That's kind of interesting.

Maybe could use the letter set or domain of some given config.

Computational aspects with domain tools.

Utilize game engines such as Unreal Engine or Unity for integrating AI driven mechanics.

Implementation considerations, practical applications, domain specific use case, implementation, advanced topics, brain computer interface, virtual reality, augmented reality, PCI, VR, AR, research direction, collaboration possibility, further readings, books, practical implementation steps, addressing

potential questions conclusion references okay let's just briefly look at that for Blake and then look at scripts


SPEAKER_00:
All right, to the scripts.


SPEAKER_01:
Let's look at how some of the translations look.

Translated curriculum, Russian, synthetic biology.

Okay, these sections are empty.

Repeating.

Repeating.

English.

Back to Russian.

English.

Code.

Russian.

Back to English.

Okay, Hindi language.

somebody with the rsa cryptographic background okay repeating not filling out sections this could just be a prompt error doing the json or um nuanced approaches to documents blocks of docs these kinds of approaches that'll add a lot of value this is the big blob method the all by all folder script method

okay here are the scripts okay there's two scripts with a beginning prefix one underscore research domain and research entity

so there's domain and entity folders each of these script ones will iterate over the markdown files in the synthetic domains and within each entity subfolder just the py so the idea here is whether it's a purely synthetic python

just say generate statements looking like a high school student from chrisfields.py or just fields.py format and then those can be versions that's the pure synthetic llm based approach there's also generating transcripts from videos so these were like transcripts from chris fields giving different lectures different papers different podcast appearances

could have one to many, could be all the literature of a researcher, it could be they could bring in their private nodes, you could be using a local LLM, or none, generate these PYs that are used.

So the PYs are the pseudocode

quote, this is not a PY file, representations of key attributes, quotes, perspectives.

It can be written in structured lists, so basically just a bullet point list, all the way on through having, here for Carl Friston, I think there's some numerical estimates for some, panpsychism 0.7.

So then it can have also these other expressivities with the pseudocode at the semantic layer.

Or these could interface with, they could have some sort of schema to be used in a more structured way as well.

And these are just transcripts and other things that are dropped into a folder, markdowns.

And then just within here, given the markdowns in this folder,

add comprehensive accurate statements to this py that's that's what is um like the entity specific or the audience specific payload or context is the single py in each of these subfolders whereas for the domains these domains um there's for for the context here there's basically two kinds there's free energy principle and active inference dot md which is just examples facts

explanations definitions facts questions about active inference and about other domains so here's the synthetic hymenoptera so ants bees wasps and soft lies and then to to add on to this just i'll use control i to use the agent mode in the current cursor so this is only available to at this time i believe the anthropic models

but it uses specific code functions and it can do a few different interesting things.

So early days for this, but pretty cool.

So here add questions, accurate facts, examples, information on the coming off the road.

So I can be done from a blank slide, right?

Blank.

text file, or it can be versioned like more, and this could also be in a JSON format, or it could be export from a database, but it's just having these semantic little nuggets and examples.

So let's see how it edits synthetic hymenoptera.

Okay, so now it's adding, adding sections.

Key questions about Hymenoptera, scientific facts, advanced behaviors in Hymenoptera, evolutionary adaptations in Hymenoptera, conservation, environmental impact.

human interactions with Habanactra.

So that would be included the next time that script one is run.

And when script one is run, it outputs into these domain and audience research files.

The output is as both a JSON and a markdown.

This request, let's look at the prompt in one,

says generate generalize this domain content and identify aspects of their audience characteristics analyze this domain content to understand the typical industry professionals background knowledge and perspective according to these structured responses for that domain so this is the research domain the research entity question

says generate a comprehensive analysis for this audience and also it can inject in the fep factual information itself to or you know saying factual just in the sense of empirical from what can can be versioned right here so both of those um output these research reports so here's the high school student research report this is the background analysis

So it's just researching the different characteristics and situation for communicating with the average professional from that domain or that audience about active inference.

Okay, that's one.

Two, so here also go to this CodeViz cool tool.

So this is the Codeviz code analysis.

Let's do it on two.

I hope it's.

Let's redo it for here.

Yeah.


SPEAKER_00:
Help us fully analyze.


SPEAKER_01:
code visualization tool meanwhile okay it loads in the api key um okay so let's look at the graphical flow api key is loaded with this function file is loaded with this function load file

Extract Sections extracts subsections from these different splitting signals.

Generate Section Prompt takes that chunk, its name and its content, and the FEP information, and responds to that section's need given the FEP content.

with these constraints, create a thorough version.

So this concatenates, this is the Madlib, the pre-pro prompt that concatenates the information and gives a format.

Again, there's other ways to do this.

Get perplexity response calls the perplexity API, again, using the LAMA 3.1 small, sonar small,

Save section saves one section.

Concatenate section puts them back together.

Save complete curriculum saves the concatenated output.

Process research file iterates through the sections.

Here's the main.

So this is what is going to be now visualized in the graph.

logging setup occurs script directory and the llm keys are pointed to base directory for future file references is named audience in the domain those two different research directories the location of the fep active information and the output direction

the directories are made that need to be made.

So setup logging, main initializes setup logging.

Let's see if these other methods, so these are just definitions.


SPEAKER_00:
Perplexity API


SPEAKER_01:
is called.

Perplexity API is loaded.

That's the next function that's called.

Process the research file with these methods.

extract the section parse markdown content into discrete curriculum section for processing for each section extracted generate the section prompt make the concatenated

a query to be sent to perplexity that is the um madlib component that's being iterated over and the active fep factual part or empirical part and the format output component and the system prompt but that's the same for all here that

pre pro prompt or whatever we call it concatenated final payload assembled is sent through the get perplexity response that passes then to the save file operations

And here are the outputs.

So kind of cool.

I'm sure there's other ways to use this really interestingly.

We can copy it in different formats.

There's mermaid format there.

Okay, so that's two.

It goes through the sections of the personalized curriculum overview and then seeks to generate that material.

Let's analyze the next number three.

uh four is another perplexity script this one as alluded to earlier there's a target languages at the top if it's uncommented it'll be iterated over so that's what's happening right now it's synthetic astronomy German language

here on the synthetic astronomy run.

Then it'll do Russian, Portuguese, Swahili, Tagalog, and then uncomment or comment the ones that you want iterated over.

This is some font mapping.

this has analogous mad living curriculum content in English maybe for some languages it would be better to just go direct to the language too but here there can be a repeat it could be a curated of one and shifted to another um format content and language and the chunking into 4 000 characters

Okay, let's look at the code that is on three.


SPEAKER_00:
Okay.


SPEAKER_01:
collects the curricula, pre-processes them, analyzes their content, generates the descriptive statistic metrics on the curricula, over curricula.

Here's a dependency check for the visualization components.

Here's a decorator for plotting safely.

plot safely decorator at plot safely this is a decorator being applied to plot content analysis plot safely applied to plot learning paths plot concept maps those are the three folders that are shown

in the beginning curriculum visualizations there's the metrics initial output then there's these three plot safely sections concept mapped content analysis learning paths okay looks like it's still processing the three

Let's do another GitHub push, add a few more languages.


SPEAKER_00:
Push to GitHub 67, 68.


SPEAKER_01:
reloading perplexity seeing how much just this one thread of continuous chugging with the so that was a 65 cents usd from having one thread continually run for however long that was so a couple dollars an hour for one thread and each

Let's just do it the LLM way.

Copy in some logs.

Run chat.


SPEAKER_00:
How long does each of these?


SPEAKER_01:
Cloud 3.5 Sonnet 2024 1022 coming through.

So between 9 and 23 seconds.

And there are probably better translation models.

Okay.

This one's still processing.

Maybe it'll get there.

If you're watching live though, ask a question.

Otherwise, I'll just sort of review everything.


SPEAKER_00:
Okay.


SPEAKER_01:
so to review where this is at what can it do well we can learn a lot by putting in specific or general entities or domains it could be the people at this conference at this exact time dot md it could be entity in organization

It could be a specific person at an organization or a group at an organization.

You can add your own using whatever background supporting files projected onto a PUI.

Synthetic domains.

Entities.

Research them.

the research prompt could be extended or the research output could be used even by itself it's in the domain research in the json and the markdown to write introduction splits the

personalized domain or audience research and writes that curriculum for them resulting in the written curricula.

So again, here's, let's go to the high school student.


SPEAKER_00:
Written curricula.


SPEAKER_01:
High school student.

versionable curricula and research on bridging to their background or situation.

People can continue to update this and add some high schools.

That's analyzed in three.

Visually.

and translated in four so hopefully these are useful starting points by themselves they're just files you can download uh and send to somebody you can use the github repo start to request collaboration access make a merge and pull all that fun stuff become a collaborator um

this was kind of it's all in the languages folder so we could have some other top level folders of course this is just a new repo so lots of ways we can go with it um i'll look now to the to do but if anyone's watching live wants to make a comment or request otherwise i'll go to the to do organize a few of those add a few more things that have come up see what anyone writes in the chat um

OK.

OK.

Researcher integration.

Implement ORCID API integration.

ORCID and other identity API integrations.

get research profile information on researchers in open source databases have data interfaces visual interfaces for people adding information publication scraping of course we're legal

research domain analysis this could be using perplexity with internet to to look for other context on the fields of somebody's research apps as scraped and submitted it could be some other research design researcher profile structure so this is maybe where it could connect with something like uh within or across organizational platform different user profiles

validations.

Okay, so this is developing researcher entity, domains, researchers.

So that's the first improve our handling and structuring and ingress

and accounting for of entity audience information and synthetic domain information database implementation clarify design and clarify documents database schema

entity relationships what works at part of co-authored with metadata structure version control system so versioning information uh knowing which person's information was used for which input to which model at what parameterization at what time Etc Influent database connectors

I'm not sure what scale some of this query optimization and caching becomes relevant and economical, probably eventually.

Data validation, definitely important.

Okay.

So this has to do with having a better structured, instead of the all by all, blob by blob, folder by folder, inch by inch approach here.

having some better structured database.

And I guess it goes into it here in phase three, which let's just look at that one.

Use Fabric

or maybe another agent orchestration or kind of computing or task framework.

But one of the previous streams used Fabric and there may be others to research here.

But again, use that database with more of an expressive pattern language, templated procedural operational nuanced approach.

Like if we only want to do

one language and one background right now, the fastest way to do it is to comment out all the languages except for that one in the file and then remove temporarily everything from the domains and the entities except for the one that you wanted.

But that might work to get one done.

But if we wanted to have each of them done in a custom way, then having some more expressive, reproducible, composable, pre-rendering layer for these operational traces, that would be important.

Back to phase two here, as it laid out.

Application extensions, okay.

Organizational support.

organizational configuration system so different templates maybe having a single config folder with its own versioning where the branding or the logo or the styles and the document formats for a given organization could all be handled there so it sort of could be plug and play and separate out the entity background for example from the

organization config and this is more like an interactive interface direction but to build out better some of these analytics and visualizations within and across curricula and then have a static output dashboards or interactive dashboards using some kind of business intelligence tool use catechism framework templated structure question answer answer format

Grant writing system.

So this gets more into the document genre, modular writing, compositional writing with human and LLM and all that happening.

Okay, phase three.

that was the pattern languages for more expressive task execution model improvement more expressive model so that could be a better it could be using the perplexity API with a different call it could be replacing that with some other analogous LLM a colleague has provided me some information on using it but if somebody wants to help

update these methods so that they call some other longer context window llm or something then just make the change

multimodal support that could be really interesting making and receiving images yeah parallelization memory management wasn't an issue on this old laptop with cursor because the llms were via perplexity but maybe at some scale interactive live demo interactive tutorials community features monitoring and maintenance resource usage reporting dashboard

Documentation.

OK, prioritization and some notes.

Yeah, pretty interesting what it comes up with.

Let's improve the documentation a little bit.

And then see if anyone writes something interesting in the chat.

And then maybe do some one other random feature and then call it for this one.

Scroll up and improve, vent, and add concise, new, accurate information directly in best sections to this reading.

Oh.

thought we were talking about synthetic commentopter let's see where it goes with it though and then we'll return to the readme that was with control i composer while that one's going chat improve at readme adding new accurate sections so even though it's like in the same window

They're different.

Composer is a little better.


SPEAKER_00:
Okay.


SPEAKER_01:
Now make thoughtful, contributive,

accurate additions to readme for how far we've gotten and only that far the chat a little bit of back and forth in and out of the code

sections composer i found just doesn't get into those sorts of issues bug finder this looks funny i think it's it uses a custom cost so it one time it estimated it at like 30 to do this it's like there's bugs for free outside and in the code okay now updating the readme

okay focusing a little bit on the hymenoptera but okay current domain so this is like very hymenoptera related not very helpful for the readme project start a new composer trace re-index cursor sometimes it does it on its own other times just to double check

Okay, then let's also do greet me.


SPEAKER_00:
Hello, Aubrey Walters.


SPEAKER_01:
Okay, this Python virtualization is probably not needed, so that's a little bit indented.

Not useful information.

I like the built with heart.

Really just always shows it's just such a fractal ride.

Sometimes it's so good.

Sometimes it really can be insidious over different timescales.


SPEAKER_00:
These parts were accurate.

Yeah.


SPEAKER_01:
I hope that people find the primary artifacts to be useful like if you have a friend who is of a certain expertise and a certain language then if it's not already here add it to one of the scripts or make the request

so that you can send a translated curriculum just sends okay here's a bunch of different backgrounds in Portuguese for somebody who wants to use that so I'll continue to let this one run for now

um probably doing a multi-threaded or some other way would be better or for some of the languages it seems to be leaving a significant number of blanks so maybe i won't do all of it let's just do one sort of semi-manual llm so here translate read me into spanish

Output in.


SPEAKER_00:
Make me Spanish.


SPEAKER_01:
OK.

The documents folder move in the.

Stream agenda.

And do one baseball.


SPEAKER_00:
Yep.

Looks pretty.


SPEAKER_01:
OK, so I was just translating it into one language manually.


SPEAKER_00:
Push GitHub.

Alright.


SPEAKER_01:
Now in baseball.

for edification and more please help write intricate imbricated deep lore for baseball american 1920s memorable moments describing the at read me and all it entails for

this given where it is all comma all let's see what format it does and then we'll say um continue continue to make more crystalline and prescience

and accurate deep lore specifics, specifications, minor particulars.

For more baseball deep lore and specific reference with the README and FVP

synthetic quote all by all folder script kitty style terminal interface synthetic intelligence in the format of long quote who's on first wow

okay let's see but it has some knowledge graph analysis of the 1920s in baseball okay that will be useful metric analysis baseball's Quantum Leap batting average contextualization home run frequency analysis pitching effectiveness metrics fielding position evolution hmm

getting there is still the entire dialogue retaining all the gestalt and specifics only entirely being in the quote who's on first

style of dialogue all details must be retained and with more linguistic cultural baseball esoterica and actualities

This dialogue serves as a meta commentary on how baseball's complexity mirrors the fundamental principles of both

Remove anything that is not dialogue.

Incorporate everything into the Who's On first dialectical file retaining all semantics and reference.

Alright, once we get to this, or I'll just trim this first part.

We'll push it on GitHub.

Read it.

See if anyone has a comment.

End.

I'll distill everything into pure Abbott and Costello style dialogue.

Incorporating all the historical, technical, and theoretical content through their exchange.

Thank you, Claude.


SPEAKER_00:
Okay, that looks good.


SPEAKER_01:
Documents.

Baseball.


SPEAKER_00:
All right.


SPEAKER_01:
who's minimizing free energy on first a complete baseball metaphysics let me tell you about the 1920s Yankees Costello most complex predictive processing system in baseball history fine but first tell me who's on first base now you're talking who's been minimizing free energy on first since the dead ball era the dead what era before they put cork in the balls when who was still optimizing his predictive model

What are you talking about?

Who's on first?

Exactly.

Been there since 1920.

Right after Ray Chapman's tragic prediction error with Carl Mays.

I don't know anything about Ray Chapman.

No, no.

I don't know is our shortstop.

Working on coupled predictive models with what on second?

What's on second?

Naturally.

Part of Murderer's Row Hierarchical Bayesian Network.

Beautiful statistical anomaly, that 1927 infield.

Look, all I want to know is the fella's name on first base.

Who?

Been there since Miller-Huggins optimized the team's variational free energy state.

Miller who?

No.

Huggins managed who?

Changed the whole generative model of the game.

Revolutionized how tomorrow predicts today's pitching patterns.

What about today?

No.

What's on second?

Today's our Bayesian belief coordinator in the bullpen with tomorrow.

Tomorrow?

Best predictive pitcher in the league.

learned everything from Walter Johnson's precision weighted curveball processing Johnson he's pitching no he's retired but his generative models still influencing tomorrow's pitch selection Paradigm then who's pitching today no who's maintaining his Markov blanket on first today's updating his beliefs in the bullpen and tomorrow's starting starting what

The hierarchical processing of batter prediction errors, of course.

Just like how Ruth transformed from pitcher to slugger through active inference.

Ruth?

Now we're getting somewhere.

He's on first?

No, who's on first?

Ruth's busy minimizing league-wide surprise with his home run variational distributions.

Home run what?

Statistical revolution, my boy.

Change the whole predictive processing of the sport.

Why, before Ruth optimized his generative model,

Never mind, Ruth.

Who's playing first base?

Now you're getting it.

Who's been optimizing first base defense since they standardized the cork-centered baseball's predictive parameters?

I don't care about cork.

What's the guy's name on first?

No.

What's calculating joint probability distributions with seconds with I don't know?

You don't know?

No.

I don't know is integrating radio broadcast feedback with what to minimize spectator surprise?

Radio?

Sure.

Whole new layer of cultural free energy minimization.

Why, when Miller-Huggins first implemented his platooning strategy... Clutch his head.

Just, who's on first base?

Exactly.

Who's maintaining optimal spatial predictions while Gehrig's generative model emerges through pattern recognition?

Gehrig?

He's on first?

No, no.

He's still learning from Hu's free energy minimization techniques, part of the farm system's hierarchical knowledge structure.

The farm?

Beautiful example of organizational active inference.

Whole network of coupled predictive models, just like our start system's curriculum generation.

Start what?

No.

What's busy with defensive shifts on second?

Start our knowledge network analyzer, just like how tomorrow predicts today's relief appearances.

The dialogue continues through extra innings, recursively embedding the entire history of 1920s baseball, active inference theory, and knowledge network analysis into an ever more complex web of who's on first style misunderstandings.


SPEAKER_00:
Okay, great.

Great dialogue.


SPEAKER_01:
I'll just look over the to-dos one more time, see if anyone has any last comments.

Okay, let her contributing.


SPEAKER_00:
Code of conduct.


SPEAKER_01:
So control K, inline the script.

Control L, chat.

Control I, composer.

But you can be using all three at once.

Just deleting everything except for the structure here.

add a to do section for completing the all by all for all.

Audience names and languages.

Then if if somebody wants to plug in their own perplexity API and do it, get it working in their own hands, push the updates.

We could also.

add in to do for better methods for recognizing which combinations are already done or being able to override that.


SPEAKER_00:
All right.

Fine.


SPEAKER_01:
All right.

I hope this is useful.

I'll push the final GitHub push.


SPEAKER_00:
right good luck symbols greetings have a good one bye