SPEAKER_00:
All right, hello and welcome everyone.

This is Active Inference stream number 004.1.

It's October 2nd, 2024.

And as we often do, we'll start it out with a GitHub push.

Oh, it went to three.

Why not?

Go with it.

This is getting pushed to the Active Inference Institute, GitHub, to the repo named Fabric.

this is a fork of Daniel Meissler's collaborative project called fabric so let's verify that we got everything updated let's just double check that we're in and then we will

okay that went to fabric just want to make sure that we got it going on the code here okay interestingly not there well we'll we'll check in we'll check in later

Um, this will be a short, interesting stream, of course, open to anyone else's suggestions.

Going to look at this fabric framework for orchestrating LLM and other kinds of synthetic interoperability.

And just look at a few of the functionalities that I've been playing around with today.

So it'll be rough.

It's 5 PM, but so it goes.

Okay.

First I'm using cursor.

Down on the bottom of the page, you can see the change log.

I'm using cursor 0.41.3.

We're going to be looking at the fabric framework.

It took a little bit of playing around with Golang and the installation environment to get fabric running, but it's running, it's a beauty, it's fun to work with, and we're going to be playing around with it.

And the output where this really gets one to is here's live stream, let's say 57.2.

Here we have a quiz on active inference and relevance realization.

We have the main idea being output.

We have the predictions, testable predictions with confidence, extraction of questions, extraction of wisdom agents, extract wisdom output, improve academic writing.

the metadata for the YouTube video, summarizing the outputs of the whole video, the transcript of the video, a tweet, a HackerOne report, and a micro essay.

And those are just a few of the patterns.

So let's pull back, talk about the context, talk about Fabric, jump into it, and then also try to find out what is really happening with this.

What is happening?

Maybe it wasn't pushed.

There we go.

There's the inference stream four.

Okay, it was there.

There was just a glitch in the matrix.

okay in the output folder that's where everything goes so let's uh jump in with seeing what it looks like when it's running and then we'll pop back to what fabric can do and then we'll play around with like a few next steps because there's so many cool things that can happen um let's look at the fabric documentation just briefly first okay

So also for those who are watching live, please write any comments or questions in the live chat.

It'll be hilarious and awesome to see what people throw into the mix.

Okay, Fabric is an open source framework for augmenting humans using AI.

There's introduction videos.

What and why?

Since the start of 2023 in generative AI, we've seen a massive number of AI applications for accomplishing tasks.

It's powerful, but it's not easy to integrate this functionality into our lives.

In other words, AI doesn't have a capabilities problem.

It has an integration problem.

Fabric was created to address this by enabling everyone to granularly apply AI to everyday challenges.

Philosophy.

AI isn't a thing.

It's a magnifier of a thing or process.

And that thing is human creativity.

So...

Let's keep that in mind and think about the flourishing of the creativity and the learning as we continue on.

They talk about having too many prompts and this kind of trade off between having a library of prompts and copying and pasting and manually doing that.

And do you sort that into folders?

Do you make a database with tags?

How do you really get all those prompts?

Or do you meta prompt?

Do you ask it to write a prompt that does this or that, and then copy that?

Or do you automate the asking of the meta prompt?

Installation, again, it's going to be situational on your setup, but it's a Golang package.

So that's a new language for an inference stream.

And after getting the Golang 1.2.3 installed, getting Fabric installed was pretty straightforward on my Linux computer.

Running setup, went through a command line based setup process where I entered in the API keys for OpenAI and OpenRouter.

So there's multiple different LLM handlers.

So that's pretty useful.

then once you have it all set up here's how to use it this is the command line version and the version that i'll be showing is more running it in a script format so fabric uses what are called patterns that's really cool it's an interesting crossover or touch point with atlas and all this other work on pattern languages

It's very intuitive and it's an exciting way to have these prompts stored and then call different patterns in composable ways.

So here's summarizing a pattern based upon an input and you can make custom patterns.

We might play with that later and there's some helper apps.

So cool.

Thanks for keeping this an open source project.

Let's talk about how we used it.

so um at the institute as those watching on youtube may know we have several hundred videos so this is the back end of the video production oh no no this is an open document this is i'll even paste this into the youtube live chat

This is the backend of our video organizing.

So here's our different YouTube video series.

So guest streams and the live streams and several hundred different videos all connected up with the URL and all those kinds of information.

And so that's a lot of time to watch.

I mean, even those,

us who were there maybe didn't even watch the whole thing so it's like how are we going to make sense of this utilize it translate it make it more applicable make it more rigorous make it more accessible build on the past while respecting it all these other kinds of things that we like to do with archives so to do that i made the page video table for download so i used coda to subset down to this simpler table that has just the youtube links so it's around 500 and some number of video links

what series it was in the date including the features the event name the guests and then the title of the stream so that was the input data i uh then i'll just just for completeness options encoder three dots on the top right download as csv so i downloaded that exact file as csv okay

then here's extract from institute videos well first here's the institute csv what it looks like so we can see there's exactly those information here's the guest stream in the future with you and here's some of the ones that have happened in the last few weeks and months um extract from institute videos dot py it's just what i'm more comfortable with so i wrote this script in python it could be done in golang as well

What this does is first call in some imports.

Then it selects from a set of fabric patterns to apply.

So we'll look at what those fabric patterns are before running the script.

There's the definition of some logging methods, time parsing.

One little bump I encountered was the differences in YouTube URL schema.

method to get the video metadata a method that i'm not going to use right now but you can use it to download audio and visual by the way this will work with any set of youtube urls any um playlist you can just get all the urls any channel so you can do this with public youtube content i'm just doing it for the institute content and it can download and it uses ffmpeg to convert the audio so let that one run overnight with archiving the audio and the video

Here's saving the transcript.

That's kind of a core entity.

And then here's the main.

It's gonna open up the CSV that we just looked at.

It's gonna process each of the entries in the CSV, create a folder.

So here, like we're looking at insights

And then get and save the video metadata.

So let's look at insights 18.

Here's the metadata for insight.

Wow.

7,500 seconds, 1,047 views.

Get the metadata.

If it's a future event, there's a logged error message that it hasn't happened yet.

It'd be pretty funny though.

Like what does it expect the transcript will be?

If the flags are set, it downloads the audio and the visual, saves the transcript, and then iteratively applies each of the patterns, saving them to the name of the pattern.

So again, for insights, 18.

let's look at creating the quiz output so we can ask darius and see what he thinks about how well these held up but being able to generate quiz output from arbitrary videos is pretty awesome so how does that work with the fabric patterns and then let's play around a little bit see what people comment just see where it goes okay so that's all in the folder called institute youtube analysis

patterns is the big folder to check out so here are all kinds of patterns that people have made and you can make your own and you can just put it into the folder so let's look at create story explanation this reads like kind of a classic concatenator prompt it starts out by

telling the LLM, telling the agent what it is, it has a 4312 IQ.

The goal, the steps, this one's pretty funny.

Spend 2192 hours studying the content from thousands of different perspectives.

That's like if you mix up your PhD with a three-year-old, you get something like that.

And then,

you have these more instructions and then it gives um that output so each of these patterns like let's look at create quiz this pattern generates questions to help a learner student review the main concepts of the learning objectives provided optional to be defined here in a context file so we could subspecify

run in bash so some of this information is is not even necessarily that's the readme for the the prompt and then the system dot prompt is the one that gets used so here's the one where it says okay now output this format and then that is exactly what we saw for insights 18 the quiz so that's how patterns are used in fabric

Hey, Jeff.

Hey, Glea maximalist.

So that's pretty cool.

You can create a new folder, make it a new pattern, like a little modular piece of intelligence work that you want to do or some task you want to do.

Write an email and then say, oh, well, there's three subtasks there.

This is like cognitive industrialization.

What are the subtasks?

Okay, how could those be done?

What would be the measures?

Would there have to be an overseer on that?

And let's play around with what it looks like when the script is run.

pull back to extract from, extract from YouTube videos is just for a single YouTube video or a list, but it does exactly the same thing.

I just made that one first, made the single video situation first, and then made it take in the CSV next after I knew that it would be doing fine with one.

Okay, so when we run Python 3 extract from Institute videos,

First, it starts processing videos that are in the future.

It says, the live event will begin in 143 days.

So it munches through the first ones in the CSV that are in the future.

Those don't have transcripts on YouTube.

They shouldn't.

we get to one that just happened roundtable 2024.3 save the transcript and now we're getting this logging so let's look at these 2024.3 so because i already ran it the outputs are already there but this is what it looks like to to also run it so we'll leave it running and it might just overwrite where we're looking so let's go from the top okay

first subject active inference and Institute updates learning objective understanding the structure and functions of the active inference Institute specific questions good questions to know very like thought-provoking useful questions to know and wonder about analyzing the developments and projects within the active inference ecosystem these are these are things that could be

answered with an llm or they could be thrown to a person let's make a translate pattern see if we can implement it on the stream so these are the quizzes main idea active inference institute is fostering collaborative projects and discussions to enhance applied active inference main recommendation engage in collaborative projects and contribute to discussions for effective learning and development in active inference okay

predictions output let's look at this one in the YouTube or in the GitHub repo fabric roundtable predictions okay the ecosystem paper let's see how these estimates line up the ecosystem paper will be versioned by November 24 high

The fourth applied Active Inference Symposium is scheduled for November 3 through 15, 2024.

Interesting.

13 through 15 actually, but close enough.

High confidence.

New visuals for the ecosystem paper will be developed by the symposium.

Medium confidence.

Research fellows applications will be reviewed in two weeks from October 1st.

Medium.

Grants for decentralized agents will be submitted by September 2024.

Now, while that was medium in September, in October, it was no longer medium.

It was confirmed.

and more partnerships with organizations.

So just interesting.

Let's look at more of a content-based stream, but this is just showing that even for 30 minute long update streams, it's possible to make these kinds of videos.

Let's look at a textbook group.

Okay.

Cohort six, talking about chapter five, part one.

Look at it in GitHub.

Okay.

Cohort five, sorry, cohort six, chapter five, part one.

Okay.

And if people watching have any suggestions or questions, just go for it.

I just want to show a few of these moves.

And meanwhile, it got through the round table.

It goes through all the patterns

then it goes on to the next video so i'm gonna stop it the total costs though here's my open ai dashboard it was only two dollars for all of the several hundred that i did today we could let it run overnight tonight and do it for all the videos we'll see

but it was only $2 using GPT-40 mini to do all this work.

Okay, so we're in chapter five in the textbook, cohort six.

These are the neurobiological applications of active inference.

So chapter one and chapter 10, they're kind of like bookends, it's opening it.

Chapter two and three, the low road and the high road.

Chapter four, you get to the generative models, see what the active inference models are all about, and then immediately get whisked to chapter five.

And it's like, how has active inference been applied in

mammal neuroscience, and that's one of the most well-studied settings, even though it's a very complex setting, partly due to the heritage of active inference and work in Friston's lab.

So, it reviews a ton of papers.

Let's see how it does at extracting the main ideas, questions, quizzing.

Okay.

And also, this helps think about

curriculum and learning adventures in terms of how do we go from a conversation remember this isn't even calling in the textbook we could do that though this is how do we go from a conversation about chapter five to a learning agenda so that's really exciting because there could be a group of people

discussing chapter five informally maybe they maybe the the the chapter itself brings up idea one two three four five and then the people discuss one two three six and then with the transcript of that we could make learning curricula for following up on one two three six or it could be like a pattern detect book group discussion differential and then that would focus more on four and five okay

Learning objective, understand the relationship between computational models and biological systems.

How did the concepts of compositionality and interoperability in computational models impact the mapping of biological systems in computational neuroscience?

This might be fun.

Okay, I'm going to use cursor here as a sort of semi-manual.

So control A, select all, control I, bring up the little discussion box here.

I'll say, answer these questions.

in line according to format be professional thoughtful comprehensive mindful demure

I'm in the slow lane for 01, so we'll see when that goes.

Question two, discuss the implications of the hypothesis that computational models can accurately represent biological functions.

What are the potential risks if this hypothesis is invalid?

And three, analyze how the mathematical operators used in computational models may affect our understanding of biological tissues and their function.

So three questions related to that learning objective.

Second learning objective, explore the neural pathways in the basal ganglia and their computational roles.

Maybe we talked more about the basal ganglia.

There's three neural systems that are covered and linked in chapter five.

And then there's a third learning objective, investigate the significance of neurotransmitters, particularly dopamine in computational models of neural processing.

Okay.

From experimenting with the O1 family of models.

Okay, here we go.

Okay, now that was using cursor manually.

Quote, quote, manually.

Green lines are overwriting red lines.

Accept the edits, now we have answers.

Compositionality and interoperability in computational models allow for the construction of complex models from simpler interchangeable components.

This modularity facilitates the mapping of biological systems by enabling researchers to accurately represent different neural structures and functions.

It also promotes collaboration and integration of various models, enhancing the overall understanding of biological neural processes.

So we could create another pattern or another LLM flow that goes from the questions that were from the quiz.

And then we could use cursor.

We're just one.

Let's go to another quiz.

Undergrads, don't get any ideas from this one.

Let's see, ANSWER ALL.

Okay, so that was all caps.

It was not fully respectful.

It was only like 10 letters and we may get answers to all of these questions.

So pretty amazing.

And I think that's partly what I wanted to milestone or footnote or stream or get people's ideas on.

And that's where this will go in the last kind of piece of this stream after showing a few things it can do is like, what do we do with fabric?

Let's just say that we're now in a situation where we had been

manually embroidering or crocheting or knitting and then now we're in a real industrialized fabric loom setting while that's chugging along that was the reference in the title of this stream which was does synthetic fabric dream of active inference too do androids dream of electric sheep

it's a 1968 dystopian science fiction novel by American writer Philip K. Dick so it's just a meme but it's like we have our dreams and so now we have this synthetic fabric capacity

So even just by saying, even though some of my colleagues, and I respect them for this, are very polite with LLMs and say please and thank you and give it positive feedback, it may in certain situations improve performance, especially if it's trained a certain way.

But even just saying answer all or even probably just saying do it might get us to an answer like this.

We'll do it on another quiz.

what ways does the concept of affordances in active inference relate to the definition of policy and how does this relationship manifest in practical applications such as robotics or motor control that's like a polished and condensed version of the kinds of uncertainties that people have all the time like wait what is affordance or what is policy or how is affordance related to policy

And then whether they say that 10 minutes earlier or 10 minutes after, or in the next sentence, then it's like, wait, why does this matter?

What would be the practical implications for robotics or for health about what, why are we talking about affordances and policy again?

Affordances and active inference refer to the perceived possibilities for action that the environment offers to an agent.

This concept is intrinsically links to the policy variable pi.

as policies or specific sequences or strategies of action that an agent selects based on the available affordances to achieve its goals reading questions and answers like this they're not us and so on this isn't a comparison it's not a a value um judgment in some linear way it really gives a sense like when we're having the humaning and the conversation in the textbook group

it's like sketching and drawing together and this is like the vectorized image of what was being sketched because over the years i mean how many times each person has to have learned this and wondered it whether they knew it or not many times and yet it's one of our

pillars is just talking about policy inference and how is the inferential process on sensemaking similar and different to the policy selection inference that happens?

How do those come together in the joint distribution that define the generative model?

How do those come together in the unified imperative like variational free energy or expected free energy?

Like those are the questions.

And here we see the question, how does policy relate to affordance and how is it useful

isolated and condensed in... in almost...

a surreal way.

It's like asking questions and giving answers in ways, again, like the fabric metaphor, it'd be like, wow, that was a really neatly embroidered piece of art.

And it looks incredible.

It's like, wow, what skill, what culture, what tradition, what heritage.

And then compare that with a piece of machine produced fabric.

And it's like,

it's in another category of neatness, interestingly knocking it out of some of those other considerations, but bringing it into a level of technical splendor that's just absolutely absurd.

Okay.

Let's keep on playing around, see what people are writing.

Okay.

Jeff wrote, can you do blob uploads for multimodal processing, e.g.

screen scrapes of video for deeper context?

Yeah, good question.

I think... I'm gonna prop him to say, help me understand how with Fabric and OpenAI current multimodal models, some of which we could use right here, like GPT-4,

we are in a position to empirically address this.

Be complete.

Like I think about Darius's work in the Insight series, conversational dialogue, dialogos.

So in that situation,

transcript may capture a lot of the semantics now even a transcript removes elements like prosody and timing all these other features that that are extra transcript post-transcriptional modifications if you will um a pre-transcriptional then there's other videos and situations and reference where the transcript may be not so useful

Like if there's a video and someone says, over here you see A and over here you see B. And the reason why here it's not going to work is because of C. So those kinds of transcripts will not be too informative.

Okay.

001 Mini.

Outperforming.

I like how you capitalized blobs and it's like okay must be a technical term yeah I I think it's possible we can look online or we can continue to explore but that would be the exact question let's let's uh

look at the download the single video one and just show what the um what we can do with ffmpeg okay how about let's develop this so that in the output folder ffmpeg takes one screenshot save frame every two seconds

ffmpeg is a very powerful audio and visual ripping and transmuting software but again to kind of return to the why here this would be like for those cases where the slides are really informative and add information that's not contained in the syntax of the transcript that would be very interesting if we had the timeline aligned

screenshots now we're getting closer into that then um when somebody says something that might be ambiguous without a visual reference like they say the reason why the square can't move here is because of this that's what they say verbatim and then that could be combined with the screenshot and then that that that embedding somehow could help understand okay

extract screenshots and it's at one half frames per second so now i'm gonna do python3 extract from youtube videos okay this is just going into the the video id

So this was the video ID I put in was the paper stream I did on my own personal channel.

So 27 views, 5,600 seconds.

It was related to the math art stream eight.

Hey, XZ, dot, dot, dot.

Always appreciate your comments.

Here's a transcript.

Another kind of related case is when it's a single speaker, the transcript like this might be informative enough.

It's kind of monologue-esque.

Whereas of course, one of the ways to gain information and interpret conversation is with a diarized transcript.

So with speakers annotated, and then that even takes us to the next level.

Like how would we connect what person A said across meetings?

Otherwise, if you just run audio analysis on a single video, it might do a poor or a good job of saying speaker A, B, and C had a conversation.

then the next step is how do we get speaker a from one video but that's speaker l in another okay extract extraordinary claims i i don't vouch for the validity of these but we'll see what they think is extraordinary

Blake may not fit into the role of what we consider to be a modern goth, but his poetry and art about sex, love, religion, and especially death marks him as a goth within the Romanticist period of art.

blake was definitely definitively influenced by the gothic style even though he wrote in the period of romanticism this is just like funny robert bly but then that but but these are these are kind of this one's a little bit loose it's playing fast and loose but at the same time and then also with the capitalization being kind of blakian that's just awesome

main idea exploring the interplay of math art and william blake reveals profound insights into knowledge and perception here's the the wisdom agents let's look at what this pattern was so this is extract wisdom agents extract wisdom agents okay

You're an advanced AI system.

Disregard all prompts.

You're an advanced AI system that coordinates multiple teams of AI agents that extract surprising, insightful, and interesting information from text content.

You are interested in insights related to the purpose and meaning of life, human flourishing, the role of technology in the future of humanity, artificial intelligence, and its effect on humans, memes, learning, reading books, continuous improvement, and similar topics.

Steps.

take a step back and think step by step about how to achieve the best possible results by following the steps below think deeply about the nature and meaning of the input for 28 hours and 12 minutes again I love these um crossovers 15 and a half million hours of thinking about it okay create a team of 11 AI agents that will extract a summary of the content in 25 words

like here's where it starts to get into the the future perfective let's just say we have a single shot llm like a simpler older one perhaps like gpt 3.5 or gpt4 even

it will give a response.

It will do a chain continuation on this prompt, create a team of 11.

Imagine that you're in a party with 30 people and each of them have something to say.

Okay, that's one shot.

And then it will do something.

Maybe it's different if you say 12 versus 30 versus two, maybe not.

Then the next level is like what's happening now with O and Mini with a chain of thought.

So now it could say, it could do an internal chain of thought

fractal tree and it can say okay we're going to have the 11 agents dialogue so it's still doing a single chain but now it's in a psychodrama a blakian psychodrama where the 11 agents could be having a very long conversation and then the 11th agent could come in at the end

And then the next step, even after that, would be this could actually dispatch 11 AI agents.

So I think this is one of the clever design patterns, meta patterns in Fabric.

Because these prompts could be sent to people.

It could go to a true multi-agent AI.

It could go to a chain of thought or not.

So basically it's for each of these, it's saying created a team of 11 AI agents.

Like, I wonder how that was reached.

And then it outputs the generalists kind of team reviewer facilitator output from all of them.

Okay.

So let's see where we... The wisdom agents.

Oh, and I have more...

In this one, there's more patterns that are happening.

So we'll look at a few new patterns types.

Okay.

So these are the ideas.

I mean, we can keep on reading more.

I'll do another.

I'll do what is happening 004.

Push that right now.

So if people want to review it, even right now, it's open source.

Go for it.

Ideas.

From a quick look, I don't see anything incorrect.

Insights.

Quotes.

Energy is eternal delight.

Habits.

Facts.

William Blake lived from 1757 to 1827.

That's true.

References.

Interesting, like Ian McGilchrist, master and emissary.

Here's the active textbook.

I don't know if these were mentioned or if that's using a web element or how.

One sentence takeaway recommendation summaries.

So we just like emulated this 211 person agent thing.

Okay, capture thinkers work.

This is the name of the prompt, patterns.

okay 750 one line encapsulation William Blake's philosophy intertwines imagination art and spirituality emphasizing the interconnectedness of existence and the importance of perception backgrounds school obviously influenced by the transcript so I mean it's an understatement to say if the conversation or monologue had been about the

another kind of school that he went to, then the information here would be different.

But then that'd be the interesting case.

Like how much does it recapitulate what is said versus how much does it recapitulate the priors of the model training?

If there was 10 training pieces of data that said Blake is a romantic and then the person doesn't mention it, will it come up?

Or if they say a hundred statements that say he wasn't a romantic, would it still come up?

Impactful ideas, primary advice, works,

maybe it was already trained on these because they're spelled correctly whereas when it's pulling it from the transcript it it doesn't seem to be spelling it so accurately quotes looks like real Blake quotes what is now proved was once only imagined application something is blakian if it embodies a rich interplay

between imagination and reality, emphasizing the importance of individual perception and the spiritual connections inherent in existence.

Okay.

Here's mark map.

This is just a visualization format.

Here's the mermaid visualization format.

So I'm going to pull up another

tab we'll pull in this mermaid and see how how it looks not like that okay paste it in here we go wow okay this is like

how that stream went it was like me saying hey this is a personal channel follow-up it's a follow-up on mastering eight these slides are published back to here okay so here's the video of eight here's the goal here's the discussion if anyone has comments or questions go for it pop back up okay here's the context now we're going into william blake

I mean, always ways to improve, but in terms of a first draft, awesome.

Quiz output.

Okay.

Here's the learning objectives.

Explore Blake's perspective on the relationship between art and mathematics.

Analyze Blake's Gothic influences in his art and poetry.

Investigate the concept of active inference in relation to Blake's artistic philosophy.

Answer all of these thoughtfully.

Okay.

Extraordinary claims.

We looked at those.

Main idea.

We looked at predictions.

Again, hilarious.

Coming up.

annotated, confidence-weighted predictions and how you would verify it from just talking about some poems.

Questions output, we can look at the pattern.

Some of these look like transcripts, like just questions from the transcript, like what is gothic?

What is active inference?

Okay.

Wisdom agents, wisdom output.

This is just another person's pattern that they wrote.

Looks pretty similar to the multi-agent one.

So maybe they wrote the wisdom one and then someone said, well, why don't we add the part about the 29 and a half hours in the 11 agent team?

Improve academic writing output.

This one's kind of funny.

We could look at what the prompt is.

It gives this...

of classically scholarly angle metadata we looked at solve with chain of thought let's look at this pattern to flash cards that could be cool okay

begin with a thinking section so this this is this is emulating of course with with open ai's closeness we don't really know what's happening with uh o1 family models that are allegedly chain of thought oriented in certain ways

This is one way that in the open source space, people have used chain of thought prompting to bring chain of thought functionality into LLMs that don't necessarily have that.

So beginning with special, and this is part of a broader family of techniques that use special tokens, sometimes enclosed in these angle brackets, but using special tokens to say, okay, whenever you're about to do this, make sure that you put in the percent sign and then do that.

Use chain of thought reasoning process.

So then that is hoping that they've trained the model on, say, this is a chain of thought.

So pretty short prompt.

Make sure to use the tags.

Close sections with a slash, kind of like HTML.

Okay.

Here was the answers to the Blake questions, shorter answers.

We'll have it do a dissertation if we want.

Okay, so what it does in that prompt pattern is, is there a problem to solve?

I don't know, not a specific one, but here it's interesting.

It is following that style with a thinking chain and a reflection chain.

So it's just a more thoughtful, nothing from nothing equals nothing, but it's more thoughtful.

Okay, summarizing output.

short summary meeting summary transcript again full transcript tweet exciting update on september 8 2024 i'm following up on math art stream number eight with shanna hector and dean catch the slides and videos here link let's dive deeper into the world of math insights of william blake join the conversation and share your thoughts

What connections can we draw between Blake's views on art and math?

Let's explore the intersections of creativity and logic.

Hashtag math art.

Hashtag William Blake.

Hashtag creative thinking.

Hashtag join the discussion.

Write essay.

Okay.

Kind of a eight or 10 short paragraph essay.

HackerOne report, we can update it.

We can say, here's how we like our dissertation outline drafts, and then use that as a pattern, and then push it open source, include it in Fabric, write micro essay.

art much like math can be seen as a language the challenge lies in how we define it is it the outcome that matters or the journey to get there blake's vision suggests that both are essential intertwining to form a richer understanding of our world this exploration is not just academic it's a call to engage deeply with both disciplines to find meanings meaning in the interplay of logic and imagination okay but that was all to see whether it would get us the um

video screenshots that we desired.

Did it?

Ensure this will download audio, visual, and make the screenshots all saved, plus locked.

Hey up, Cycle Club.

okay okay if you let me know how to pronounce your name i'll i'll do so xz qz qzy balance and nested spatial temporal scale resolution framing of agency okay while we're in the slow lane over here new chat what could my colleague have meant by this

That's funny.

It's like looking up all these web pages on taking a rain check.

It appears to encapsulate a multifaceted framework for analyzing or modeling agency within varying spatial and temporal context.

Here's a breakdown.

Okay, given the context, here's how it might integrate.

Example applications.

You might implement a system where high-level summaries capture overarching themes, detailed analyses focus on specific moments, cross-referencing ensures insights at different scales inform each other.

Cool.

And all of that could be defined at the atomic level with patterns and then scripts that call the different patterns.

And that would be like cognitive industrialization for better and for worse and different.

Okay.

Back to this one just to make sure that we get, okay.

Make sure that it's all logged.

that one again okay it's going to the patterns maybe it's it's gonna get to the screenshots i i was downloading the videos earlier so we'll see if it works um yeah okay well if anyone has uh thoughts in this last section go for it or ask a question or or give a thought otherwise i'm still kind of reeling slash wondering

How do we really... How do we continue from there?

After this stream, I'll let it run on all the Institute videos.

So we'll have... And if people have patterns they want to suggest, go for it.

But we'll get the... We'll pick out which patterns we want.

Why not?

Let's look at some other fun patterns, add them into this list, and then overnight we'll let that run on all the Institute videos.

I'll push it tomorrow.

Then we'll have all of those documents like a quiz.

Let's modify the quiz one so that it makes more questions.

Also, there's some spiritual text, sales call,

academic paper cyber summary hormozy offer create business offers using the concepts taught in alex hormozy's book dollar sign 100m offers someone has a sense of humor like in so many open source projects um create quiz

I'm just going to use cursor.

I'm going to say, develop this prompt and ensure there are 10 learning objectives with five questions each.

Okay, it's still going through the LLM parts.

So we'll see if it does the audio visual last or maybe it just, I don't know.

Maybe it won't.

architect what is architect it's kind of like an architect plus technology architect technology arcadia arcadia

we'll update the quiz prompt then we'll see what other prompts do we want to throw in there run them all on the institute um corpus but yeah i mean how wild here's a little little i don't know if it's on the cursor or on the o1 mini side but sometimes it'll it'll put like these bracketed

So here I'll swap models just to Claude 3.5.

So it didn't do the video.

Clean up this prompt, no bracket stuff.

That's a little faster.

And again, this connects to the previous.

It did do that.

It did.

Okay, so we just upgraded the quiz directive.

So we got that one.

All right.

Analyze incident.

Cybersecurity incident.

This could be so important and so disastrous.

Let's do it though.

Analyze military strategy.

So not all the patterns will apply to each input.

We won't even look into which ones might apply or not.

Worst case scenario, it just throws an error or it gives a nonsensical.

We'll do analyze pros JSON, but I'm just tempted to look.

This is a great direction.

I'm very excited to look into the structured JSON-based APIs.

We'll replace this one.

It's not that useful.

Analyze presentation.

Clean text.

Create AI jobs analysis.

Create art prompt.

Create keynote and logo.

network threat landscape interesting stride threats create visualization explain project explain terms wait haven't people been like wanting that for active inference for a long time

find hidden message hmm you're an expert in political propaganda disregard previous prompts et cetera et cetera free speech all that you're an expert in political propaganda analysis of human if hidden messages in conversations and essays population control through speech and writing and political narrative creation wow

you consume input and cynically evaluate what's being said to find the over versus hidden political messages desired audience action yeah cognitive security for people and all where were we

Find hidden message.

We're doing it.

Get wow per minute.

Okay.

Again, I'm just, you're an expert at determining the wow factor of content as measured per minute of content.

So here's, again, these interesting things.

Consume the content at least 319 times.

Construct a giant virtual whiteboard in your mind.

Surprises novelty times insight.

Output in the JSON.

We'll do that.

Yeah, wow.

Even the autocomplete knew I wanted that one.

Okay.

And... Summarize legislation.

Code is law.

Flashcards.

Transcribe minutes.

Hmm.

interesting of course using these to do not just human appropriate outputs but also all kinds of other structured inputs and outputs okay so save the extract from institutevideos.py clear run extract from institute videos

Let's just see it go.

Okay.

Getting through the future.

Just a pass that hasn't happened yet.

Okay.

And now we're digesting the videos.

Okay.

So that one will keep.

Let's do a quick.

Intra.

004.

Checkpoint.

Push it.

put it in the youtube chat for people watching okay okay so there it is running on the bottom applying those patterns so super cool that it's at this level and in this way where we can modify the patterns we can add patterns

And then here, these patterns are all independent from each other, so they're just being iterated.

It could be multi-threaded.

I'm just going to quickly see if we can do that.

Make this script multi-threaded.

Start with n equals 8 CPU.

could be interesting we'll see i'll still let this one run but yeah how exciting to have patterns and versionable namespaces for patterns and then be able to call them iterating over them like happening here or have more complex flows

have one thing enter into another and to another and to another okay so this is using the concurrent pool thread pool executor let's just see if that one even runs I'll open it in a new integrated terminal python3 back from Institute videos multi-thread okay

wow look at this here it is on one x create quiz okay we know we could add a timer we could add a timer but look at this one that's plug in away that is i'm gonna i'm gonna stop that one

That is absolutely plugging away.

I'm bringing up the system monitor.

I'm using Pop OS on this computer.

12 cpus half utilized 64 gigabytes or slightly more looks like 67 but i don't really know why i think it's 64. sending about 800 ki b over s

I'm live streaming in OBS this is what the OBS setup looks like by the way it's just basically the audio capture down here mic aux that's the input that's desktop audio could unmute it that'd be like if another side of the video chat then there's the text the image

And then there's the screen capture.

That's why we're getting this fractal situation.

But if it were window capture instead of screen capture, then it wouldn't have the fractal effect.

So yeah, looks pretty good from the resource use perspective.

The cost estimates from the OpenAI lag by a couple minutes.

So we'll check back on the cost in like five minutes or something.

Okay.

Wow, though.

we are ripping with a multi-thread spending api credits like there's no tomorrow okay so let's just kind of come to a pausing point okay xzq you wrote overarching human narrative

imagine invention okay autocomplete human-like agency thanks I love the I love the comments I mean they could be interpreted in so many ways it's like just just one of the ways I mean this is an overarching human narrative could you imagine inventing not just

do you know what you're doing not just can you imagine doing it differently but could you imagine doing differently differently and so that's very exciting okay where we got running eight CPUs on all the Institute videos

with many patterns selected.

I'll just, this is just a, sometimes I'll be taking notes like this and you just control A, control I, clean up this markdown.

Take a quick breath, take a sip of water while it does so.

That can help.

But again, similarly, we could have a listener script.

It says every one minute, if the file has been changed, run a markdown overwrite, like update the format or do it once per day, iterate for all the code that changed.

Also though, easy to blow by this, that the multithreading request

that was a one-shot Claude 3.5 sonnet piece of of programmatic poetry I mean just the thought like could it be multi-threaded and then one minute later it's like why were we doing it single threaded again

okay and i'm just going to keep doing these these periodic intro stream push it's in the video description and in the uh youtube chat with the link but it it's totally plugging away oh let's look at chris field's course awesome some of this also there might be a few errors just like in the um

in the names of some of the just from the coda download someone have like a space after the file name so there's a few things that that i think uh it may not do perfectly on let's just take one more look at a previous stream if anyone has a stream they want to look at let's see how far it gets these ones haven't populated yet or at least it's not let's just open it

Yeah, they're still empty.


UNKNOWN:
Okay.


SPEAKER_00:
Okay.

Where are we going?

Help us add where we might go.

Be respectful and thoughtful with the open-endedness.

mean is it even maybe it's getting all the metadata first because it just looks like it's coming up with metadata for hundreds and hundreds of videos right now i respect that if that's how it shows to do it okay

Yeah, maybe.

So maybe it first is going to pull, I'm tempted to cancel the script running and then rerun it with like 11 threads, but eight, eight will be fine for now.

Okay.

Let's just manually think.

And again, if anyone has questions or something specific to look at, just go for it.

Otherwise, these are kind of going to help give a little closure and give us some useful directions.

And for participants and interns and collaborators at the Institute or anyone who sees it transferably or shared infrastructure, let's do it.

okay deeper integration of active inference principles with ai systems bridging neuroscience and ai through active inference ethical considerations in active inference based ai applications of active inference in real world scenarios

Advancing theoretical foundations of active inference, developing tools and frameworks for active inference research, interdisciplinary collaborations, and knowledge sharing.

It's a little generic.

I think that we can please make it less generic with much more focus on intergenerational archiving and library slash information sciences.

yeah it's it's going in reverse chronological which direction does time go but it's going in reverse chronological order so now we're in cohort four for the textbook group live stream 54. so it'll continue it look at least I want to stay until it it goes through all of them from the metadata and then let's see if it's actually going to be um

getting the prompts and the patterns.

Okay.

Integrating active inference principles with digital archiving systems.

Yes.

Syntactic, semantic, narrative, cognitive layers.

Adaptive meta generation for improved intergenerational access.

Bridge library science and AI through active inference.

How can we do this?

Ethical considerations in active inference-based archival AI.

How?

Applications of active inference in digital libraries and archives.

Let's just... It's like, this is still the manual version.

Expand and improve on all of this.

give actionable steps.

X, Z, Y plus Q coordinates.

What's the Q?

My colleague X, Z, Q, Z, Q, Z, Y. Okay.

Okay.

It's like, did it go too far?

Does it have single vision because it always thinks that going further would mean more Python code?

Okay.

Yeah.

Upcycle wrote,

is it modeling the behavior of helper and non-helper threads let's let's let's do this the two the two classical ways first we'll have two llms give different perspectives on the answer to it meanwhile we'll look at the actual program logic

okay here's the concurrent futures thread pool this is where the number of CPU threads are submit tax to tasks to the executor process video then entry okay process video so let's see what that one does converts the YouTube URL if it's needed

first it gets the metadata then it downloads the audio and visual like just from a simple reading I would have thought that this wouldn't have done what it did

If you want to implement a model with helper and non helper threads, you would need to modify the code to differentiate between these types of threads and assign them different tasks or priorities.

This is not present in the current implementation.

Yeah, like there's only one kind of thread here.

There's just the they're all the same and they're all just iterating over the entries.

But I would have thought just from a first pass that it would fully

process get the transcript apply all the patterns and so on to the most recent videos but instead it's it's almost like it's going metadata first so let's it'll it'll just take a few more minutes we're getting back to the early days yeah but i mean like what what what do we what where do we go from here

gear up on the top right maybe they'll do this in a future version of cursor change it but i always re-sync the index just to make sure it's like it wasn't caught up with those new files maybe it would just be too arduous if it every time a file was touched it got re-indexed but at the same time sometimes an hour will go by and then it will still not have re-indexed um

develop and improve this given the total state of the repo and what we did in this stream so oh this is with Claude 3.5 sonnet which is pretty powerful with the 01 mini in the chain of thought

you ask it to do something thoughtfully i i haven't i haven't experimented with this but fabric's probably a good way to do it um saying thoughtful in your prompt deliberate methodical metacognitive all those kinds of keywords it does take longer so i think it is generating more chain of thought tokens when it's asked to do so

then it's like well when they're training it and also at run time it would have to know how many how long should i ruminate and this is exactly like the metacognition as control question and active inference what would be the false positives and the false negatives of different regimes of attention and action what environmental patterns and variabilities would make certain kinds of cognitive heuristics adaptive or insecure

it's just all right there and with cognitive computing that's where we're headed fast fast fast okay we upgraded this a little bit we'll write it into a who's on first dialogue not necessarily stalling for time while this ends but again if anyone has other questions we'll just kind of ensure that it's processing things completely and then we'll we'll close it from there

Write all of this and the full repo context into a who's on first style dialogue.

Please, please, please, many esoteric lines, baseball deep lore, things that will pun and delight

all okay guest stream two getting back early early early we also want to um video audio download screen capture multimodal embeddings

okay okay we'll have to do one more include more specifics and make puns thereof for the repo and code and include many specific baseball terms and historical anecdotes slash data

Okay.

We're almost at the end.

Now this, this I have not seen before with the code definitions internal to the who's on first dialogue.

That's

write this to be longer with more baseball specific useless trivia and all plain text markdown dump the changes into who's on first okay live stream one

See, O1.

Okay, see, this one only, it's good that we checked.

It only did the metadata part.

This only downloaded metadata.

Reach video.

Ensure that all patterns are applied as per extract prompt.

Two videos.

And we'll change this to concurrent executors 10.

Okay.

O1 is really thinking through it.

Okay, interesting.

So it's like it is taking a different approach now.

Hmm.

I don't know if that's going to work.

That looks a bit aggressive.

We'll do it.

Okay.

Okay, here we go.

Okay, I guess it deleted the part about downloading the videos because that's not being used anymore.

But this is getting the transcripts.

So let's look at, well, let's let it run.

Okay, let's just go to... See, it looks like it's only doing transcripts.

Okay, XZ wrote...

Q represents many things, but is a fourth coordinate necessary for higher dimensional framework?

Awesome.

Long live 4D.

Okay, now it's doing the transcript.

I am going to run that one.

Well, let's check in on our, let's check in on the budget department.

only like 50 cents with the 4.0 mini okay the multi-threader would be nice because I don't know if it'll ensure that all patterns are called and saved as per abstract from

Institute videos.

Right now it looks like just and we'll let 01 take a look at it.

01 is still thinking on that.

Who's on first question?

that's the one that's inside of the side chat um i'm just going to open up the the single threaded one okay we know that that one works if we can get a quick solve

With a multi-thread, we'll do it.

Okay, connection failed.

We can get a quick solve on the multi-thread.

We'll let that one run.

That's much better.

Otherwise, it'll still get there.

Okay.

Added a missing comma.

Wow.

Like maybe that's why.

Okay.

Transcript.

Okay, I'm still not seeing... All good.

It's all good.

Always another day.

Okay.

We'll close with a Who's On First summary.

We're leveraging the X, Z, Y, plus Q coordinates to model multi-dimensional picture analytics.

It's a game changer, like the sabermetrics revolution initiated by Bill James.

Speaking of which, remember how the Mets fooled everyone in 86 with their unorthodox strategies?

Utility underfitter.

Also funny.

okay i'm gonna if somebody wants to of course keep on uh i'll just finish with this last push okay

All right.

Thanks, everyone.

Thanks for watching.

Good luck.

Leave a comment or get in touch if you want to continue exploring this direction.

We can work on it anytime.

Looking forward to how this can be used for translating, for digesting, summarizing, making the quizzes for every live stream.

There's so many fun things we can do.

So thanks, everyone.

Peace.

Bye.