[
  {
    "start": 7.237,
    "end": 33.177,
    "text": " all right it's september 3rd 2025 this is active inference stream 15.1 been a little bit but we're back we're in the start repo start.activeinference.institute and this should be a very fun multi-level stream right off the bat this is where we're going to get through today i'm running run.sh from the top of the repo",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 33.157,
    "end": 58.455,
    "text": " and several functionalities are shown which we're going to go through the first is the system checkup the second is an environment setup step the third is the generation of custom curriculum this is going to use lom's generative ai to write custom active inference onboarding curricula depending on a given audience or entity and then translate that into whatever language you want and then the fourth",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 58.891,
    "end": 63.499,
    "text": " option is the Repository Manager where we will clone into a variety of repos.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 64.1,
    "end": 67.606,
    "text": "So, I am going to get a few of those cooking.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 68.748,
    "end": 70.611,
    "text": "Welcome this fine evening.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 70.771,
    "end": 73.776,
    "text": "Looking forward to everyone's comments and questions.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 73.796,
    "end": 77.743,
    "text": "First, in this one, I'm gonna get the repository cloning going.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 79.057,
    "end": 84.829,
    "text": " clone the available repositories, and get that going in the background.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 86.032,
    "end": 98.297,
    "text": "Then I'm going to open up another run.sh instance, .slash run sh.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 99.07,
    "end": 105.416,
    "text": " On the second one, I'm going to start up a custom curriculum generator.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 105.816,
    "end": 112.082,
    "text": "As soon as somebody types in the live chat a given entity that they'd like to see, I'll add in another one as well.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 113.023,
    "end": 114.764,
    "text": "So let's get in there.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 115.084,
    "end": 117.507,
    "text": "We will go to three, generate curricula.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 121.73,
    "end": 124.973,
    "text": "Initializing the epistemic and pragmatic aspects of consciousness.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 127.355,
    "end": 129.077,
    "text": "Connecting to the free energy principle.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 130.238,
    "end": 147.69,
    "text": " okay here we go what this interactive curriculum generator gives us is uh some options some interactive options for what kind of domain we want to do research into and what",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 148.953,
    "end": 151.877,
    "text": " audience we wanna tailor the material to and what language.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 152.418,
    "end": 158.227,
    "text": "So we'll start out with either entering an existing domain like physics or we can add a new domain.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 158.828,
    "end": 166.259,
    "text": "This is gonna be coffee tasting.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 169.945,
    "end": 170.926,
    "text": "Yes, it's a new domain.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 171.607,
    "end": 173.951,
    "text": "Target entities, we can pick a given entity.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 174.792,
    "end": 176.935,
    "text": "We'll go with,",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 179.108,
    "end": 204.222,
    "text": " Tulsi Gabbard just as the first listed entity there and then we can pick a target language and we'll go with Ancient Greek okay it's a new language that's fine all right coffee tasting Tulsi Gabbard Ancient Greek yes proceed with that",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 204.826,
    "end": 208.693,
    "text": " Okay, while that's proceeding, check in on the cloning.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 209.073,
    "end": 214.022,
    "text": "This is going into the clones subfolder under SRC.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 215.344,
    "end": 225.602,
    "text": "And that is cloning into a variety of repos, some of which are explored in other streams, others which I've made some major updates to over the previous few days.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 225.886,
    "end": 228.389,
    "text": " So we're going to look into some in a little bit more detail.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 229.05,
    "end": 230.652,
    "text": "Let's pull back to this agenda.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 231.293,
    "end": 233.155,
    "text": "So again, welcome.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 233.435,
    "end": 237.5,
    "text": "This is the start slash here, a map and what might happen next.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 238.722,
    "end": 240.624,
    "text": "There's a repo that goes along with this.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 242.206,
    "end": 243.608,
    "text": "Just expanded the browser window.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 244.789,
    "end": 254.121,
    "text": "This repo is at github.com slash Active Inference Institute slash start.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 255.35,
    "end": 268.522,
    "text": " and it is an advanced AI powered system for creating personalized active inference and free energy principle curricula and more and much more.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 269.603,
    "end": 275.949,
    "text": "It's also connected with a documentation local and cloud hosted documentation strategy.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 275.969,
    "end": 285.137,
    "text": "So active inference institute.github.io slash start will give you some hosted documents and also they will pop up locally.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 286.012,
    "end": 288.297,
    "text": " And some quick links are shown.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 289.579,
    "end": 292.966,
    "text": "To run the experience, you can do dot slash run dot sh.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 293.407,
    "end": 293.969,
    "text": "That's what we did.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 294.189,
    "end": 306.455,
    "text": "Or let's open up another window and use the other top level run script, which is dot slash run underscore docs.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 307.076,
    "end": 307.176,
    "text": "Oops.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 311.915,
    "end": 314.382,
    "text": " dot slash run underscore docs.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 315.466,
    "end": 324.473,
    "text": "So what that's going to do is run the document checking and rendering, preparing any packages that are needed along the way,",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 325.651,
    "end": 334.74,
    "text": " And then pop up here in the browser window is a locally rendered at IP address 127.0.0.1 port 8003.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 335.701,
    "end": 351.017,
    "text": "So this is the locally implemented server for documents, or you can look at the exact same material in the GitHub document pages.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 352.668,
    "end": 378.996,
    "text": " so we'll keep that in mind and we'll kill the dock runner okay just crashed okay we're back",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 402.5,
    "end": 404.372,
    "text": " All right.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 406.305,
    "end": 406.587,
    "text": "So, so",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 408.305,
    "end": 409.387,
    "text": " We're live in the stream.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 409.587,
    "end": 414.995,
    "text": "I look forward to anyone's comments and let's just go over what is going to happen.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 415.636,
    "end": 417.619,
    "text": "First, what is the start here repo?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 417.879,
    "end": 422.005,
    "text": "Well, this is just to get it out in an inference stream and show a little bit of the behind the scenes.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 422.727,
    "end": 430.839,
    "text": "But this repo, broadly speaking, gives an interactive and well-linked landing page into the Active Inference ecosystem and institute.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 431.58,
    "end": 434.464,
    "text": "Now, elsewhere, we have some",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 436.688,
    "end": 450.158,
    "text": " welcome page that has a lot more interactive material and a lot of hyperlinks to our living document, but there isn't any code execution in Coda.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 450.965,
    "end": 474.103,
    "text": " so what i've been working on is this start repo which has a little bit more of a seamless experience in terms of not just linking to resources but actually making a repo that runs them so this repo gives a fun interactive matrix themed uh landing page into the institute and ecosystem",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 474.083,
    "end": 479.331,
    "text": " It renders, as we've seen, into local documentation as well as updated GitHub pages.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 480.512,
    "end": 483.176,
    "text": "It uses generative AI to write custom curriculum.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 483.897,
    "end": 485.339,
    "text": "We'll see if that worked.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 485.7,
    "end": 487.062,
    "text": "That looks like it's still going.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 489.045,
    "end": 492.77,
    "text": "And it also helps us clone and deploy repositories.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 493.371,
    "end": 498.218,
    "text": "So, for example, what we have clones, while that was all happening,",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 499.177,
    "end": 518.215,
    "text": " is ActiveInference.jl, which I have made a fork in some modifications to, Axiom, which is the recent open source architecture by Versys, Cerebrum, which is the linguistic approach to modeling case systems and other linguistic aspects in models,",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 518.195,
    "end": 530.77,
    "text": " the cognitive repo which is a large underlying obsidian formatted markdown knowledge repository that you can open up with foam or in obsidian",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 532.252,
    "end": 537.92,
    "text": " Generalized Notation Notation for notation and metaprogramming with generative models.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 538.822,
    "end": 549.437,
    "text": "LeanNiche, which has been a bit of a fun collaboration with Jason Larkin, and we've been using the Lean Theorem Prover to explore a few aspects of probabilistic dynamical systems in the FEP.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 550.478,
    "end": 554.985,
    "text": "PyMDP, which I've made some heavy modifications to that we'll go through.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 555.758,
    "end": 573.345,
    "text": " RxInfer examples, also a fork of which I've heavily modified, and template repo, which is a repo for setting up a scientific paper rendering pipeline involving code and figures and equations and all that.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 573.663,
    "end": 583.915,
    "text": " So this is just an example, you can add more repos to get cloned in, but Start is hosting all of these different repositories as options to download in.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 584.616,
    "end": 595.789,
    "text": "So those repos just mentioned, and many other implementations exist, can help bring together open source implementation type frameworks.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 595.769,
    "end": 600.134,
    "text": " like PyMP, Active.jl, RxInfer.jl, Axiom, etc.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 600.895,
    "end": 607.883,
    "text": "And all kinds of emerging tools, be they related to synthetic intelligence, LLM, etc.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 608.383,
    "end": 618.175,
    "text": "And also anything that you want to bring in in terms of adding in another custom repo or just having another repo in this clones folder.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 618.415,
    "end": 620.157,
    "text": "Attack of the clones!",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 621.419,
    "end": 641.284,
    "text": " that is a cool setup landing page nexus there's a few themes and ideas that i think we'll revisit but what i will do next is look at these themes get a first pass on the themes",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 641.416,
    "end": 645.584,
    "text": " Then we will look at some of this custom generated curriculum material.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 646.647,
    "end": 656.006,
    "text": "Then we will turn to the pyMDP and actinf.jl forks where I have made the most of the modifications.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 656.647,
    "end": 657.99,
    "text": "So, themes and ideas.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 658.29,
    "end": 659.172,
    "text": "Start here now.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 659.152,
    "end": 688.939,
    "text": " or actin for surf whatever you prefer just jumping in active is about action and perception it's about inbound outbound about joint distributions for agents and niche gripper gripped duck rabbit all this kind of stuff that we're always talking about and in our own learning and application and contribution journeys we just start here now or there now or then if that's a better one",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 689.425,
    "end": 715.77,
    "text": " but it is about doing it is about starting where and how you are not waiting for something else to be the case unless that's where and how you are cartographic pluralism the name of the stream is a map not the map it is a map it's not the only map it's gonna version even during the stream and also cartographic realism cognitive realism",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 717.067,
    "end": 746.297,
    "text": " open source intelligence ecosystems and we're talking about ecosystems that are we're mapping the ecosystem in terms of sharing links and resources and signposts so we're mapping the ecosystem of maps of minds like mice people ant colonies llm that map months or not might might map another mind there or it could just map something",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 747.83,
    "end": 754.329,
    "text": " We're mapping the ecosystem of maps of mines, generative models, that do mapping.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 756.596,
    "end": 759.685,
    "text": "There are multiple implementation frameworks for active inference.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 759.705,
    "end": 762.092,
    "text": "There are many ways to build up along the low road.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 763.237,
    "end": 766.943,
    "text": " We see that just by the juxtaposition of all of these implementation frameworks right here.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 767.664,
    "end": 775.135,
    "text": "And with GNN, we'll even have each of them implementing, where possible, some of the exact same models and state spaces.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 776.016,
    "end": 782.967,
    "text": "So even for a given state space, there might be one or more accessible ways to implement it with different trade-offs.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 782.987,
    "end": 787.253,
    "text": "So implementations do not negate each other in active inference.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 788.752,
    "end": 795.1,
    "text": " shipping the docks and docking the shipment whether we approach this from a vibe coding or kind of uh",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 796.649,
    "end": 821.229,
    "text": " developer perspective or just the relationship between making sure that we're documented all along the way and documenting what we ship and shipping the docs and this idea of notes to navigation and the ways to include the things that we're noting along the way in our field work and get through some really dense sites in one sitting.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 822.251,
    "end": 822.471,
    "text": "Okay.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 824.088,
    "end": 824.929,
    "text": " We cloned the repos.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 825.389,
    "end": 826.931,
    "text": "Let's close that window.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 830.034,
    "end": 831.735,
    "text": "All right.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 831.755,
    "end": 832.736,
    "text": "Let's exit the matrix.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 834.898,
    "end": 842.446,
    "text": "So the generated content there is in the learning data.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 843.827,
    "end": 844.808,
    "text": "So the domain research.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 847.33,
    "end": 851.074,
    "text": "Here's the coffee tasting research that was using perplexity.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 853.973,
    "end": 867.898,
    "text": " I will push this to GitHub just so we can look at this a little bit in a rendered form.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 879.235,
    "end": 905.277,
    "text": " here was inference stream 8.1 that was from December 15th 2024 and that was uh oh it was uh 8.1 symbols greetings and that was the first iteration of the start repo okay so here's the audience research here's Tulsi Gabbard",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 906.623,
    "end": 910.368,
    "text": " We also have that domain research with the coffee tasting research.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 912.611,
    "end": 914.433,
    "text": "And then here's the written curriculum.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 916.315,
    "end": 919.66,
    "text": "Here's the Tulsi Gabbard curriculum.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 920.3,
    "end": 924.005,
    "text": "Here's the complete Tulsi curriculum.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 928.25,
    "end": 935.82,
    "text": "So it includes a little bit of information on the person's background, their motivation, what kinds of core materials we're going to share with them,",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 936.29,
    "end": 939.816,
    "text": " what kinds of assessments, how to connect it to the person's background.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 942.159,
    "end": 953.497,
    "text": "So this is just a starting point for, of course, that person or for any person or for the system that generates it, but it gives some really fun and exciting starting points.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 954.479,
    "end": 957.083,
    "text": "So let's see, a little William Blake.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 957.063,
    "end": 978.615,
    "text": " backgrounds again it's to be discussed explored played with how much do you want to meet william blake where he's at versus just have a sort of um attractor that isn't personalized so it's not that there's a oh wow look at this look at this gibberish part",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 984.89,
    "end": 1005.852,
    "text": " incredible um it and uh then we have the translations so that is in translated curriculum it looks like the the translation stage is pretty slow i didn't run it by default but we can see that there's these translations of copy roasting and so on okay",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1007.789,
    "end": 1031.417,
    "text": " here we go starting to look a little bit at the uh live chats by way of oh it's still writing the uh still writing some of the material okay so let's go to some of the live chats",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1034.857,
    "end": 1057.911,
    "text": " okay so dean hello deed wrote i have no technical background with any of these repos but i do want to take advantage of the curriculum generator what's my first step do i need to learn how priors with active no you don't need to have priors with active",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1058.077,
    "end": 1079.747,
    "text": " you need to have it just this is this starting point clone this repo start find out from help or ai or videos how to use github clone the repo go to the environment example file copy it into a file called dot env",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1080.706,
    "end": 1089.637,
    "text": " that just then add in in the real ENV, which is your secret file, add in the API keys for at least perplexity in OpenRouter.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1091.579,
    "end": 1101.752,
    "text": "Then top level of the repo, .slash run.sh.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1103.673,
    "end": 1125.175,
    "text": " it's going to go through these setup phase these this is not a loading screen I think we can put we can put different custom messages there I wouldn't say it's overly dramatic okay then when it pops up here we are in that interactive terminal three generate curricula",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1130.622,
    "end": 1143.475,
    "text": " So we'll just get this chugging along because it'll take a little bit in the background while we address the other one of your comments, Dean, and look at some of the repos themselves.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1143.495,
    "end": 1144.917,
    "text": "Okay, select domain.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1145.818,
    "end": 1155.027,
    "text": "Let's do islands navigation using boats.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1159.968,
    "end": 1185.672,
    "text": " yes new domain target entity this is it could be skipped or you can come up with another entity um i'll do bill gates created us a new entity uh employee at microsoft and",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1188.47,
    "end": 1218.021,
    "text": " just call them a common character target language in here we'll do ancient latin yes create that new one proceed all right so that's all that takes and a little bit of time to generate a new curriculum and this is just the version that we have today so future versions you can imagine a a graphical interface or um",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1220.718,
    "end": 1248.936,
    "text": " we can even make that right now so here add another script in this folder called generate curriculum GUI which pops up a simple browser window",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1251.599,
    "end": 1276.965,
    "text": " with the same fields and information as the interactive terminal one yielding a GUI for custom active inference curriculum generation and then while it is working it says",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1279.308,
    "end": 1293.929,
    "text": " working with status bar estimate, and then when final results are ready, it shows them in GUI.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1295.672,
    "end": 1296.573,
    "text": "Thanks, GPT-5.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1296.593,
    "end": 1305.366,
    "text": "All right, so we have the Bill Gates curriculum developing in the background.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1306.561,
    "end": 1319.684,
    "text": " And meanwhile, I'm going to quickly review a few of these forks of cloned repos that I've been working on over the last few days, and we'll keep an eye out on anyone's comments, questions, and live chat.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1320.806,
    "end": 1321.667,
    "text": "All right, so here we go.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1324.313,
    "end": 1326.797,
    "text": " Well, there's several interesting ones.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1326.817,
    "end": 1327.819,
    "text": "They're all very interesting.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1328.5,
    "end": 1331.465,
    "text": "But I want to show mainly the PyMDP.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1331.625,
    "end": 1333.729,
    "text": "So this is all within this PyMDP fork.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1334.991,
    "end": 1343.185,
    "text": "And just to show where this is in the browser, this is the doxology.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1343.585,
    "end": 1348.393,
    "text": "So my personal GitHub account fork of PyMDP.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1348.414,
    "end": 1349.916,
    "text": "And the branch...",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1354.486,
    "end": 1378.452,
    "text": " is called textbook so all that information is is open source available okay but here we'll look at it through the interface of start opened up in cursor and we are in cursor 1.59 okay so couple of modifications and things in this textbook",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1378.718,
    "end": 1386.973,
    "text": " First is the examples from PyMDP, which is just a copy over from the examples",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1387.848,
    "end": 1393.015,
    "text": " like the agent demo and grid world, copy them over in their most minimal form.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1393.896,
    "end": 1414.024,
    "text": "And then the examples from pyMDP underscore modified, which is where modified versions of the scripts are made that output more data and more visualizations than the notebook forms do.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1414.004,
    "end": 1423.421,
    "text": " So if you want to, the output of all of the scripts are run there.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1424.402,
    "end": 1434.46,
    "text": "So purely just for getting a better handle on the PyMDP examples and to understand what they look like.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1435.25,
    "end": 1454.114,
    "text": " that examples from PyMDP modified is pretty cool, pretty useful, very open to further developments that people can do in, of course, the PyMDP examples in the underlying repo or their own Forex or improving and making these examples more flexible.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1455.175,
    "end": 1463.265,
    "text": "But the examples, so just examples, is where I have made 12 new examples",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1463.566,
    "end": 1466.033,
    "text": " they get run by this script called runAll.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1467.417,
    "end": 1473.495,
    "text": "So runAll.sh will run these 12 scripts and here are the outputs.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1474.037,
    "end": 1477.086,
    "text": "So this is about to be like a rapid,",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1477.201,
    "end": 1497.167,
    "text": " review kind of like the 2022 part all textbook that brings together the fundamentals of probability and the bayes rule in module one and two then module three four five and six are related to sense making and perception",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1498.109,
    "end": 1502.476,
    "text": " Module 7, 8, and 9 are about active inference, policy inference.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1503.377,
    "end": 1511.731,
    "text": "And then examples 10, 11, 12 are relating to the POMDP, the partially observable Markov decision process.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1512.472,
    "end": 1514.515,
    "text": "So here's what the outputs look like.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1515.187,
    "end": 1516.248,
    "text": " starting from one.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1517.069,
    "end": 1517.931,
    "text": "Probability basics.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1518.712,
    "end": 1522.617,
    "text": "This is going to talk about a few different distribution types.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1523.598,
    "end": 1538.237,
    "text": "So here's a categorical distribution on the top, three discreetly different options, the Gaussian or normal distribution in the center row, and then a Poisson or a rate parameterized distribution on the bottom.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1538.297,
    "end": 1542.342,
    "text": "And each of those are shown in three different forms.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1544.313,
    "end": 1570.017,
    "text": " terms of three different parameterizations so it's like categorical you're talking about things that differ discreetly and all of them across the categories sum to one and that could be like a third a third a third or it could be bimodal or it could be peaked gaussian you can move around on the x-axis or you can make it narrower or wider that's variance or precision and then this is a few of the different lambda parameterizations that was solved",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1575.65,
    "end": 1599.75,
    "text": " in module 2 bayes rule there is this is a summary of the information gain and variational free energy for two different settings the first setting is the classic medical diagnosis setting where there's a prior belief about how likely a disease is to be present which could be the population",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1600.355,
    "end": 1618.667,
    "text": " overall frequency it could be some other prior belief and then there's a test which has a 90 percent sensitivity true positive and a 95 percent specificity true negative and so when you get a positive test conditioned upon the observation of a positive test",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1619.423,
    "end": 1632.043,
    "text": " not to overly simplify, but the frequentist says, I mean, 90 or 95% that the person has the disease because that's what the accuracy of the test is.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1632.403,
    "end": 1634.787,
    "text": "So that's what the most likely outcome is.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1635.568,
    "end": 1647.827,
    "text": "Whereas here with the base, we can see, well, depending on your prior, that's gonna update what happens when you update after the posterior.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1648.938,
    "end": 1657.606,
    "text": " So that's shown here, and then in the sequential example is weather, where you don't know whether it is raining or not.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1658.087,
    "end": 1667.576,
    "text": "I guess you're trapped inside of a bunker or something, and you're just seeing whether umbrellas or no umbrellas are going with people walking by.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1668.537,
    "end": 1675.063,
    "text": "So you have an initial prior, 70% likely to be sunny, and then you see sequences of umbrellas or not.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1676.444,
    "end": 1680.488,
    "text": " So that's kind of background statistics, good info to know.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1680.508,
    "end": 1681.172,
    "text": "Module three.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1683.751,
    "end": 1687.936,
    "text": " and the sort of cousin of three, refactored three.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1688.837,
    "end": 1691.28,
    "text": "These have to do with observation models in PyMDP.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1692.342,
    "end": 1701.633,
    "text": "So these are ways sometimes called the A matrix or the ambiguity matrix, where you have the mapping between observations and latent states.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1702.053,
    "end": 1706.759,
    "text": "And that can be like the identity matrix, which is to say a noiseless perfect mapping.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1706.859,
    "end": 1712.086,
    "text": "So basically just like a Markov decision process, not a partially observable MDP.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1712.907,
    "end": 1713.167,
    "text": "Or",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1713.755,
    "end": 1717.858,
    "text": " different levels of noise off diagonal symmetric matrices all these different things",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1718.564,
    "end": 1729.802,
    "text": " State inference uses the infer.states method of PyMDP to use variational methods to update priors into posteriors given observations.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1730.703,
    "end": 1742.763,
    "text": "Sequential inference in the fifth module is a little bit more about different patterns of sequential evidence accumulation, which is worth going into.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1743.844,
    "end": 1745.567,
    "text": "So for example,",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1749.935,
    "end": 1773.141,
    "text": " initially we have a uniform prior over latent state a b or c one third each first time step we see observation zero this updates our belief that it's 80 15.5 second observation time step comes in it's zero again we increase our posterior belief",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1774.707,
    "end": 1776.03,
    "text": " from 0.8 to 0.96.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1776.511,
    "end": 1779.036,
    "text": "Then third observation coming in, observation one.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1779.337,
    "end": 1780.9,
    "text": "So then that goes from 0.03 to 0.22.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1781.742,
    "end": 1785.249,
    "text": "And for each of these, we can calculate the information gain per update.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1785.409,
    "end": 1788.396,
    "text": "We can look at the components of the variational free energy.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1788.937,
    "end": 1792.244,
    "text": "We can look at the validation of the normalization in pi MDP.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1793.807,
    "end": 1794.268,
    "text": "That's five.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1798.045,
    "end": 1820.56,
    "text": " six is a beginning point for a multi-factor example so here there's two independent factors there's the weather and the location so three possible locations two factor two um uh options for the weather factor and then that sets up six possibilities and so there's different beliefs over joint states okay so that's getting through the sense making stuff",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1821.265,
    "end": 1823.048,
    "text": " 7, 8, 9 are about action inference.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1823.308,
    "end": 1838.11,
    "text": "So 7 gets you a little bit familiar with the B matrix or the transition matrix in terms of it being modeling from two latent states, but no action selection yet.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1839.052,
    "end": 1846.516,
    "text": " 8 is going to go into action selection using preferences and pragmatic value in the expected free energy.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1846.536,
    "end": 1850.83,
    "text": "So this setting, there are three different options for location.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1851.291,
    "end": 1852.555,
    "text": "Left, center, and right.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1854.323,
    "end": 1866.132,
    "text": " the C or the preference variable is set so that the left has a negative preference, it's disfavorable, the center is neutral, and the right has a positive preference value.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1866.974,
    "end": 1870.442,
    "text": "And then we can see how conditioned upon your starting state,",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1870.422,
    "end": 1898.472,
    "text": " different moves have different pragmatic value here the epistemic value is zero for all and then we can see how softmax over the negative expected free energy yields updated action posterior probabilities that get sampled from from the same action prior which is the habit or the e matrix so for example if you're starting in the left",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1899.937,
    "end": 1925.438,
    "text": " state then move left which in this situation keeps you in the left or stay they lead to the same expected outcome observation so they are equally likely to be selected whereas right has a higher preference zero higher than negative two so that has a higher it's more expected to be the case this is how we",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1925.418,
    "end": 1954.665,
    "text": " get preference and goal-oriented behavior without a reward distribution or reinforcement learning to training data is we have things do what they expect they they change their mind and change the world to observe what they expect here starting in the center it's especially disfavored to go to the left somewhat disfavored to stay highly favored to go right and then for starting in the right position we see that there's again the same",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1955.067,
    "end": 1978.78,
    "text": " normalized probability of selecting either moving right which is staying or staying which is analogous to the starting on the left situation and staying left so that is the eighth module which gets in and also this is a separate one in eight talking about like different preference distributions for the sweet lever and the health conscious taster",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1982.168,
    "end": 2002.354,
    "text": " tm1tap wrote wtf is going on here and why is it recommended to me yeah let me know when you find out okay ninth module is a similar example where uh i don't think the coloration on the heat maps is all perfect",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2003.515,
    "end": 2008.199,
    "text": " The epistemic status of all of this is functional and improvable.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2008.7,
    "end": 2014.385,
    "text": "So I'm sure you and our Synthetic Intelligence viewers will find many places to improve.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2015.446,
    "end": 2019.97,
    "text": "Please make that contribution, make that GitHub request.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2019.99,
    "end": 2030.94,
    "text": "So here we're in a situation where there's four states and the left three are equally neutrally preferable and the right state is preferable.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2032.169,
    "end": 2049.668,
    "text": " So then we can see that just from reactive planning, we rarely end up with a reward, but if we're able to plan and look ahead, we can, it's a trivial example, but it's just demonstrating how the expected free energy is used for pragmatic value.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2049.688,
    "end": 2059.138,
    "text": "And then 10, 11, 12 go through the POMDP example and shows the matrices and",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2059.878,
    "end": 2089.429,
    "text": " how that state space gets set up and then how beliefs evolve through time what action and observation sequences happen 10 is the T-Maze setting 11 is the grid world some blank visualizations there grid world setting and 12 is another T-Maze",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2090.388,
    "end": 2092.65,
    "text": " with a bit more and different information.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2094.412,
    "end": 2099.597,
    "text": "So that is intended to be a useful resources.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2099.737,
    "end": 2105.042,
    "text": "Again, that's the doxology fork of the pyMDP repo textbook folder.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2106.003,
    "end": 2111.608,
    "text": "Examples are the 12 examples that I wrote up with help, obviously.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2112.569,
    "end": 2117.273,
    "text": "And then the examples from pyMDP modified, if you wanna stick closer to the",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2119.345,
    "end": 2126.191,
    "text": " general purpose examples in PyMDP, then those are the ones to go with.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2126.693,
    "end": 2126.954,
    "text": "Okay?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2128.219,
    "end": 2129.524,
    "text": "Let's see how the",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2138.482,
    "end": 2144.389,
    "text": " Okay, let's go over to the updates in ActiveInference.jl.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2144.629,
    "end": 2154.901,
    "text": "So Active.jl here, this is a Julia-based package, and I have also made a textbook branch and subfolder.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2155.982,
    "end": 2160.087,
    "text": "So in this case, there are five examples.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2160.548,
    "end": 2162.65,
    "text": "So it's structured a little bit differently.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2162.63,
    "end": 2166.253,
    "text": " The first example has to do with the mathematical foundations.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2166.934,
    "end": 2170.517,
    "text": "Second example, this is just another, just a slightly different learning path.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2171.358,
    "end": 2174.501,
    "text": "Second module has to do with the variational free energy.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2175.282,
    "end": 2176.863,
    "text": "Third example, expected free energy.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2177.844,
    "end": 2181.248,
    "text": "Fourth example is going to use the POMDP.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2183.71,
    "end": 2187.013,
    "text": "Fifth example, hierarchical inference and multi-agent coordination.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2187.674,
    "end": 2189.115,
    "text": "And here's what the outputs look like.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2190.056,
    "end": 2191.337,
    "text": "So first the foundations.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2206.353,
    "end": 2231.736,
    "text": " that curriculum generation is still happening in the background it's pretty slow okay so here's the from the foundations module in the active jl repo fork pretty old computer i'm running it from pop os",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2236.829,
    "end": 2243.98,
    "text": " Okay, maybe it'll be better to... Let's look at it within the browser.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2246.925,
    "end": 2247.406,
    "text": "Textbook.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2251.993,
    "end": 2252.394,
    "text": "Output.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2261.808,
    "end": 2262.229,
    "text": "Okay.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2267.575,
    "end": 2269.559,
    "text": " So there's the information theory.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2270.662,
    "end": 2272.345,
    "text": "So here we have four different distributions.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2272.566,
    "end": 2273.468,
    "text": "Observation comes in.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2274.249,
    "end": 2276.995,
    "text": "And then we have KL divergences calculated.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2277.035,
    "end": 2279.501,
    "text": "I'll just do it here.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2280.022,
    "end": 2281.585,
    "text": "VFE, the seconds unit.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2294.609,
    "end": 2323.114,
    "text": " yeah a little slow but c'est la vie like it's faster to load it through github than to load it in the ide tragic here is the uh vfe perceptual inference state inference process",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2332.038,
    "end": 2333.361,
    "text": " We'll just let that one load.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2333.721,
    "end": 2333.962,
    "text": "Okay.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2339.472,
    "end": 2348.57,
    "text": "Similar examples in the EFE module.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2349.652,
    "end": 2352.898,
    "text": "We have analogous examples for the EFE.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2355.038,
    "end": 2379.544,
    "text": " and same as the pomdp and the uh multi-agent so kind of fun and then we'll look at the multi-agent trajectory okay we'll get this here we go so this is a uh multi-agent grid world",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2380.739,
    "end": 2394.321,
    "text": " MetaGrid is probably a better framework for doing this kind of collective foraging multi-agents situation.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2394.341,
    "end": 2396.003,
    "text": "I'll just bring that up in the browser.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2399.589,
    "end": 2401.732,
    "text": "Yeah, David Blumen et al.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2402.734,
    "end": 2404.637,
    "text": "MetaGrid is better.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2405.984,
    "end": 2417.116,
    "text": " if you actually want to make like these kind of role-playing game meets collective foraging, multi-agent, flexible, active, reinforcement learning settings.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2417.917,
    "end": 2419.459,
    "text": "Okay, here we go.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2419.859,
    "end": 2421.281,
    "text": "Now the GUI has popped up.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2421.321,
    "end": 2424.424,
    "text": "So this was again prompted, just that was a two-shot prompt.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2424.524,
    "end": 2429.73,
    "text": "First just said make a GUI for what does the same thing as the typing.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2431.246,
    "end": 2458.502,
    "text": " so let's domain nursing entity elon musk language russian so there we go all right just to close off there if you really want to do a multi-agent setting and you want something that's really performing professional metagrid or some other option is probably a better choice but",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2458.988,
    "end": 2474.334,
    "text": " the whole point of what's happening here is we can look at the expected free energy values and posterior beliefs and all this kind of stuff, and we can connect with how we learn and apply these implementation frameworks.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2475.957,
    "end": 2479.663,
    "text": "Okay, so that works.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2482.175,
    "end": 2488.141,
    "text": " Alright, now I'm going to return to Dean's previous questions and his new one.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2488.882,
    "end": 2498.653,
    "text": "So yeah, if anyone else has any ideas or questions or they want to see something happen.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2501.055,
    "end": 2503.558,
    "text": "Okay.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2503.578,
    "end": 2505.28,
    "text": "Whose map am I building?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2509.816,
    "end": 2511.057,
    "text": " Whose map am I building?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2511.698,
    "end": 2514.281,
    "text": "The curriculum that modifies a current mind model.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2515.663,
    "end": 2519.968,
    "text": "So a map outside both the curriculum designer and the curriculum subject.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2522.17,
    "end": 2526.135,
    "text": "Is the limit of my self-organization my ability to generate effective prompts?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2526.856,
    "end": 2531.281,
    "text": "It seems like I'm giving most of the organization tasks over to the processing agent, which isn't me.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2531.461,
    "end": 2531.701,
    "text": "True?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2531.741,
    "end": 2533.123,
    "text": "And then he wrote,",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2536.951,
    "end": 2539.196,
    "text": " I see the AI generating and organizing.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2539.997,
    "end": 2542.543,
    "text": "Shouldn't I practice these tasks too?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2543.244,
    "end": 2545.99,
    "text": "Yeah, these are huge questions.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2546.01,
    "end": 2551.441,
    "text": "They're definitely things that I've been thinking about over these last few days working on it.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2551.521,
    "end": 2556.411,
    "text": "Let me have a sip of water and I'll think about what tack to enter here.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2572.118,
    "end": 2597.535,
    "text": " shouldn't you practice those tasks too well to the extent that we're going to be normative here pedagogically yeah i think that you should one should i should etc generate and organize and while the ai is doing a lot of the terminal generating and organizing in terms of writing the actual curriculum itself",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2597.515,
    "end": 2604.945,
    "text": " First off, those are just intended to be intermediate artifacts produced for curation and secondary refinement.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2605.545,
    "end": 2617.621,
    "text": "So it's not that it's generating the final word, it's generating a blob of clay that might be close or far from your vision.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2618.662,
    "end": 2624.029,
    "text": "And it is organizing things in a way that has to be quite strongly typed in order to",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2624.819,
    "end": 2647.637,
    "text": " find exact like to use the the entity research on uh some data to use the the entity research on barry bonds yes it has to be organized into the right fields and all of that but there's a higher level organization",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2648.866,
    "end": 2667.735,
    "text": " that is organizing that kind of syntactic organization and then there's the the syntax and the semantics of generating these systems that do this thing and that is its own kind of spring training practice um",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2669.96,
    "end": 2674.304,
    "text": " Is the limit of my self-organization my ability to generate effective prompts?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2675.285,
    "end": 2678.788,
    "text": "Yeah, there's a lot of layers to look at that question at.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2678.828,
    "end": 2692.782,
    "text": "In some ways, you can ask for an effective prompt on some, you can ask for a kind of prompt, like write a good prompt for doing this.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2693.803,
    "end": 2698.347,
    "text": "And that's like off-sourcing more of your exact semantics",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2700.638,
    "end": 2719.226,
    "text": " in exchange for what might yield a more compliance output, especially structurally, but only you are going to be able to generate what you can do.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2721.189,
    "end": 2728.84,
    "text": "However, aren't we seeing that with even a few words or an image, it's possible to,",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2731.098,
    "end": 2755.367,
    "text": " mimic quite well it seems like i'm giving most of the organization tasks over to the processing agent which isn't me yeah i think that well at first i wonder to what extent was that thought in the calculator days or in the steam engine days or in the early automobile days or the video recorder days or the excel early days or whatever it is",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2756.984,
    "end": 2759.026,
    "text": " We are doing different things.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2759.947,
    "end": 2760.208,
    "text": "Okay.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2760.648,
    "end": 2763.291,
    "text": "Is limiting my self-organization my ability to generate effective prompts?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2763.311,
    "end": 2764.713,
    "text": "Short answer, no.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2765.714,
    "end": 2770.34,
    "text": "Prompt skill helps, but the ceiling on self-organization is set more by your systems than by phrasing alone.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2772.042,
    "end": 2773.243,
    "text": "How do you raise the ceiling?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2774.985,
    "end": 2776.687,
    "text": "Define artifacts plus DOD.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2776.787,
    "end": 2778.449,
    "text": "Probably not that one, but interesting.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2779.37,
    "end": 2780.972,
    "text": "Add tight loops.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2780.992,
    "end": 2781.653,
    "text": "Use scaffolds.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2782.073,
    "end": 2783.134,
    "text": "Externalize context.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2783.175,
    "end": 2785.337,
    "text": "That's kind of the context engineering angle.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2786.853,
    "end": 2787.914,
    "text": " Stable interfaces.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2788.615,
    "end": 2789.656,
    "text": "Automate verification.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2790.797,
    "end": 2792.359,
    "text": "Prompts are one lever in that system.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2792.499,
    "end": 2793.781,
    "text": "Useful, but not the limiting factor.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2798.166,
    "end": 2798.326,
    "text": "Hmm.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2804.353,
    "end": 2804.553,
    "text": "Huh.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2805.894,
    "end": 2807.076,
    "text": "Bill Gates' SAT score.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2809.318,
    "end": 2813.603,
    "text": "Um... Yes.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2815.355,
    "end": 2816.717,
    "text": " The GUI is still plugging away.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2818.099,
    "end": 2819.301,
    "text": "MetaGrid for multi-agents.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2821.545,
    "end": 2824.75,
    "text": "Translations into custom languages.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2832.322,
    "end": 2842.999,
    "text": "Local and GitHub documents for a lot of machine readability, and we can translate these documents into other languages as well.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2846.708,
    "end": 2857.02,
    "text": " Okay, then just briefly the last of the implementation framework where I've been adding a lot of work is in the SRC clones.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2861.345,
    "end": 2862.967,
    "text": "It didn't clone RxInfer.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2863.027,
    "end": 2867.653,
    "text": "I'll just show it in the browser.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2870.333,
    "end": 2886.148,
    "text": " here in the research folder on my branch or my fork of RxInfer examples are several fun methods related to RxInfer generalized coordinates",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2886.23,
    "end": 2899.35,
    "text": " hierarchical Gaussian filter, integration with LLM, the POMDP, the infinite data stream situation, visualization methods, and then here's one that I will show, which is the Manim package.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2900.371,
    "end": 2914.212,
    "text": "So people may be familiar with the three blue, one brown math education channel.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2916.031,
    "end": 2920.758,
    "text": " who makes videos like this.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2923.682,
    "end": 2926.285,
    "text": "And there's a open source package called Manim.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2929.61,
    "end": 2940.105,
    "text": "And so I use the Manim package to go through all of the Rx and Fur examples.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2940.966,
    "end": 2944.03,
    "text": "So it's like we have this kind of like mini documentary",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2946.507,
    "end": 2953.418,
    "text": " procedurally generated starting point for each of the models in Arcs and Fur.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2953.678,
    "end": 2955.461,
    "text": "So there's two different styles of model.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2957.004,
    "end": 2961.871,
    "text": "One of them is going to have a... I'm just picking two random examples.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2964.275,
    "end": 2967.3,
    "text": "There's the...",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2969.339,
    "end": 2979.154,
    "text": " there's the source code that's just going to have this source code kind of pop up on screen, and then there's the dot graph.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2979.174,
    "end": 2987.907,
    "text": "So it's not going to display in the... But it's a good starting point.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2988.408,
    "end": 2998.283,
    "text": "So extra usable setup utilities and examples in ActiveJL, RxInfer, .jl, and in PyMDP.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2999.849,
    "end": 3023.865,
    "text": " uh recapitulating the examples in those repos and adding these textbook folders and each of those are just cloned sub repos within this start repo the start repo",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3025.381,
    "end": 3035.295,
    "text": " has the ability to generate more materials like we're seeing, and then also it has this starthere.md.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3036.397,
    "end": 3038.62,
    "text": "So the idea is, welcome.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3039.621,
    "end": 3044.849,
    "text": "This is a simple, actionable landing page into the Active Inference ecosystem and institute centered on this repository.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3045.27,
    "end": 3047.933,
    "text": "If you only read one file to begin, make it this one.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3048.915,
    "end": 3050.477,
    "text": "Why this repo exists?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3051.014,
    "end": 3051.736,
    "text": " Learning by doing.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3052.317,
    "end": 3055.445,
    "text": "Generate, visualize, and translate curriculum content grounded in real data.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3055.846,
    "end": 3056.628,
    "text": "Build end-to-end.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3057.009,
    "end": 3057.51,
    "text": "No mocks.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3057.751,
    "end": 3060.097,
    "text": "Real IO, reproducible scripts, and tests.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3060.839,
    "end": 3062.382,
    "text": "And contribute to the ecosystem.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3062.583,
    "end": 3065.21,
    "text": "Improve docs, scripts, and learning materials for the broader community.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3066.052,
    "end": 3066.894,
    "text": "Here's a bunch of links.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3067.555,
    "end": 3068.618,
    "text": "The Obsidian link.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3072.428,
    "end": 3099.651,
    "text": " is the one is the live sync version of the cognitive repo so if you want to play around in this kind of knowledge graph that's the cognitive repo you can just clone it in open it locally uh this here.md talks about a few things you can do with the repo and then talks about how you set up the repo with the uv package manager and run the run docs and the run",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3102.601,
    "end": 3106.62,
    "text": " Also just a starting point, but gets a lot of it there.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3106.87,
    "end": 3133.047,
    "text": " and you can always go to welcome or obsidian for that kind of multimedia linked living document style however i think that uh the start repo is filling a critical service and role in the open source ecosystem which is this kind of meta repository management having set up scripts",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3133.027,
    "end": 3158.764,
    "text": " that install uv if you don't have it then use uv to set up the environment and then use that set up environment to clone repos forks of those repos which themselves have setup scripts and uh so here's the setup.sh within the pyMDP fork",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3160.162,
    "end": 3188.835,
    "text": " So by running this sequence of setup scripts, you will go from either a click or just one line entered into this cloned repo all the way on through having checked files that run and do different aspects that are important for understanding conceptually and building an active inference.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3194.317,
    "end": 3198.903,
    "text": " So here's the Axiom repo by Versus.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3199.724,
    "end": 3210.298,
    "text": "And then we can just go right in there and just say, okay, run the Axiom repo right from here.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3214.043,
    "end": 3220.932,
    "text": "I have a private fork of Axiom as well, but let's just see what happens with one-shotting it here.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3233.197,
    "end": 3261.195,
    "text": " Okay, so talked about the repo, about how it can generate material, talked about a few of these implementation strategies, covered up for these three, PyMDP, ActiveJL, RxInferJL, about the forks that I have been working on that are facilitating setup and examples.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3263.369,
    "end": 3285.732,
    "text": " for a later date maybe with the GNN Lean Niche Cerebrum and I think it takes us right up to the edge so just for that one line now we are running Axiom",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3289.66,
    "end": 3292.984,
    "text": " So it's playing that video game, Explode.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3293.225,
    "end": 3293.885,
    "text": "I don't know what that is.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3295.487,
    "end": 3296.969,
    "text": "But it's a video game.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3298.431,
    "end": 3308.163,
    "text": "And that's the beauty of when a repository has its own setup materials and reproducibility.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3308.284,
    "end": 3314.732,
    "text": "Now we can just clone Axiom and run it.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3316.854,
    "end": 3317.355,
    "text": "So like,",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3319.681,
    "end": 3335.226,
    "text": " so many cool ways to compose across repos cross render in and out of repos public repos private repos",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3341.45,
    "end": 3352.266,
    "text": " There's RxInfer examples with neural networks, a lot of work across different repos in LLMs and other AI methods.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3352.286,
    "end": 3368.169,
    "text": "So for those who are curious or soon to be curious about how do you learn and apply synthetic intelligence and active inference, that's why we have a map.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3369.371,
    "end": 3370.292,
    "text": "Start slash here.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3374.474,
    "end": 3375.715,
    "text": " And then feedback along the way.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3376.416,
    "end": 3378.358,
    "text": "Just what parts were challenging?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3378.478,
    "end": 3380.159,
    "text": "Which parts were awesome?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3380.179,
    "end": 3380.7,
    "text": "What'd you like?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3380.78,
    "end": 3382.221,
    "text": "Where did you get held up?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3383.022,
    "end": 3384.043,
    "text": "Did you like being held up?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3384.063,
    "end": 3386.105,
    "text": "Where would you have wanted something different?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3387.066,
    "end": 3398.317,
    "text": "And then either raise your hand and give the feedback or reduce your uncertainty by making that change yourself and figure out how to fix it on your own local version.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3398.377,
    "end": 3404.042,
    "text": "And you'll be contributing to open source software in no time.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3416.003,
    "end": 3419.409,
    "text": " Okay, let's see how that educational material went while Axiom is running.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3432.193,
    "end": 3433.135,
    "text": "We'll do it through GitHub.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3457.246,
    "end": 3460.43,
    "text": " Okay, just pushing it.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3460.45,
    "end": 3460.771,
    "text": "All right.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3465.137,
    "end": 3465.718,
    "text": "Thank you, Dean.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3475.972,
    "end": 3476.933,
    "text": "Oh, it's in data.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3477.694,
    "end": 3479.056,
    "text": "It used to be in the learning folder.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3479.156,
    "end": 3479.376,
    "text": "Okay.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3480.458,
    "end": 3481.319,
    "text": "Audience research.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3484.724,
    "end": 3486.426,
    "text": "Translate a curriculum.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3490.237,
    "end": 3494.544,
    "text": " We'll just look at it in the browser.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3498.23,
    "end": 3498.871,
    "text": "Translated.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3498.931,
    "end": 3506.564,
    "text": "Okay.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3506.584,
    "end": 3509.068,
    "text": "Here's the, from one minute ago, ancient Greek.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3509.949,
    "end": 3515.839,
    "text": "So here's the Myrmecology curriculum for active inference translated into ancient Greek.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3517.979,
    "end": 3524.569,
    "text": " I will leave it to a speaker or reader to evaluate.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3528.615,
    "end": 3531.259,
    "text": "Here's the audience research as a JSON.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3532.961,
    "end": 3542.335,
    "text": "And then here's the written curriculum for those domains and entities.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3543.116,
    "end": 3546.501,
    "text": "So let's see, we have the Elon Musk and the",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3550.244,
    "end": 3552.008,
    "text": " island navigation using boat.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3563.974,
    "end": 3566.72,
    "text": "Then I'll just see if there's any last comments, otherwise that'll be it.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3569.045,
    "end": 3569.586,
    "text": "Okay.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3570.68,
    "end": 3593.346,
    "text": " again we can update the prompts we can have mermaid diagrams we could have more links we can base it off of uh whatever material is put into synthetic fep active this is the material that's used to generate so that that can be versioned",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3596.752,
    "end": 3616.482,
    "text": " and yes careers and educational foundations in island navigation wow perplexity or open router i don't know which one of them is yielding it probably the open router look at some of these",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3622.756,
    "end": 3652.543,
    "text": " i think it's using uh like the llama scout 4 or something like that but whoa as recorded class expenses valued everyone machine gron blind likewise quotes request conscious integrity understand entered podcast associates straw credential",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3653.57,
    "end": 3657.236,
    "text": " All right.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3658.398,
    "end": 3679.071,
    "text": "I'll just wait one minute unless anyone has a final comment or question.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3679.81,
    "end": 3686.756,
    "text": " As usual, I hope this is interesting or fun for you.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3686.776,
    "end": 3695.024,
    "text": "I put all of these out in the open source spirit for people's feedback, their commenting, their engagement.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3695.044,
    "end": 3697.366,
    "text": "There's a lot of fractal ways to contribute.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3698.167,
    "end": 3703.011,
    "text": "You could make your own repo and then we can have it cloned in.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3703.952,
    "end": 3708.096,
    "text": "Or you could make a pull request or raise an issue",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3709.072,
    "end": 3733.29,
    "text": " right here in the repo so that is all for tonight i will leave to you to do the who's on first and all of the uh dramatic readings and everything just wanted to get that out there hope that this is a place where you can say where should i go where do i return",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3735.16,
    "end": 3749.288,
    "text": " and we can make these links accessible rigorous applicable so thanks for watching along and uh enjoy",
    "speaker": "SPEAKER_00"
  }
]