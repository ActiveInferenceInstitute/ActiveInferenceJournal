SPEAKER_01:
All right, welcome to Active in France stream number 3.1 on systems.

It's August 31st, 2024.

As usual, I'll begin it with fetching the origin, committing many, many updates, pushing them.

And while that's writing, here's what's going to happen.

We're going to be talking about systems within systems and also whatever else we end up exploring.

touching upon some developments in the code base related to William Blake, FOIA, Freedom of Information Act, cognitive sovereignty, and the PyMDP social learning.

We'll start it off by making an initial GitHub push.

I'll pop everything down below so we can delete from here.

GitHub push looks done.

Let's reload the repo, double check it's there.

And we see pushes now.

So we're triple checked live.

Alright, made the GitHub push.

In this opening, the purpose of this stream, or at least one of them, is to explore various views on implementations of and interactions with systems.

Let's start by going through several code-based developments that I have prepared to show.

Please, at any time, feel free to write in the live chat a question or a comment or idea.

So I'll go through these three and then another fourth section.

At that point, conclude.

along the way or at the end just write in the live chat if anything is like off with what you're seeing or if you have questions or ideas

Okay, we are in folder 0, context, systems, and we'll start in the William Blake folder.

We're going to look at, through some code methods, William Blake's mentions of systems, talk about some relevances for modern systems design, and look at the applications in the code base.

Okay, so within the William Blake folder,

There are several scripts and there are several folders.

William Blake Resources contains files like additional references, just bibliography, hundreds of relevant citations, Blake's works by year, and table of contents to Erdmann.

Then there's the Erdmann-edited complete works of Blake and letters, which is 29,000 lines, and the poems, which is 8,200 lines.

As a reminder, in cursor, all of the code base is indexed, whatever the type is.

So there's nothing to resync here.

Let's double check though.

And I'm using cursor 0.40.3.

So 40.3.

Okay.

So a lot of ways to jump in.

The poems are great, and this is also just the plain text.

This is not the illuminated printing.

I'll start with blakementions.py.

Right click, open in the integrated terminal, Python 3, blakementions.py.

What this is going to do is look at the target terms in the top of the document system.

That's our focus, but also just to show that it's a little more general, reason and loss.

Logging is done.

And for each of the terms in the target terms, where the term is mentioned, ignoring case,

three lines before and three lines after get joined into a snippet and that gets saved into an output file.

So here's across that document of Erdeman, which there can be typos, there can be all other sorts of little textual artifacts, not everything's included, not all the works remained, et cetera, et cetera, et cetera.

but we can explore okay these are the mentions of system in blake there's nine of them from this poll until a system was formed etc i must create a system or be enslaved by another man's striving with systems to deliver individuals from those systems fixing their systems permanent by mathematic power to govern the evil by good and states abolish systems

And here begins the system of moral virtue named Rahab.

No grand work can have them, they produce system and monotony.

Before I begin engraving them, as it will enable me also to regulate a system of working that will be uniform from beginning to end.

So that's kind of a cool way to jump in and noting that there's many more mentions of these characters, Artisan and Los, but same principle applies.

These are just much longer documents with snippets.

Often it's like reading through Blake, there's all these entities, all these things are being mentioned.

And so these two entity extraction methods use a simpler method,

which is just basically looking for capitalized, this is a regex, that finds basically capitalized words, single or pairs, whether at a line start or not, that start with capitalization, and then it goes through and counts it.

The entity extraction with spaCy uses this package for slightly more advanced entity recognition.

But in any case, what these end up doing is they output into the analysis section,

These plots are just example plots, but we can see, for example, here's a top 10 entities, here's entity frequency, histogram.

And so this counts the number of entities of each time that the entities are mentioned.

So it kind of just sweeps through, finds the capitalized, and the analysis is just doing some basic summary statistics on that.

So that's just kind of a fun way to jump in and explore how many entities are done and just striving with systems.

Okay, that's part one on William Blake.

Let's go to Social Sciences and Active Inference.

Okay, so this initially comes from Andrew Pashea's awesome work at the IC2S2 conference, where he made a workshop, Active Agents and Active Inference Approach to Agent-Based Modeling in the Social Sciences.

He made it in a Google CoLab notebook, which is awesome, very accessible, and allows people to get active inference, multi-agent network learning simulations working in their browser.

That's awesome.

Notebooks are, again, great for just one click running in a browser.

However, they can get pretty unwieldy because you have these linear documents that can sprawl on and on and on, and it's hard to know what has been run and not and so on.

And so 27 days ago, I made a contribution just to take his Colab notebook and copy it into a single .py.

So that just took his great, as far as I understand, manually written code, about 1500 lines of code, and just brought it into a single Python script so it could be run as a script.

And then what I did over the previous day or two, having some fun conversations with Andrew in Discord, is broke it up across a bunch of different scripts

So there's a main.py.

This is also, it's more than just broken up.

There's also many other changes and developments, sometimes to the point where it was like just going through hands and minds and AIs, and it's like, wait, what is even happening?

But this was just a, again, experimental play.

Main calls all the aspects of the simulation.

and then the utilities are broken up across math data analysis agents creating them in the matrices and their networks active inference such as the active inference loop itself and then the visualizations

This is pretty cool.

Again, it's a really helpful PyMDP styled way to work with what Andrew made, which is this awesome multi-agent communication network simulation.

There's agents in sub networks and the output of this in the current output folder.

There's a couple methods that just visualize the matrices of the different agents.

So A-matricy, that's A for ambiguity, that maps between observations and hidden states.

So here there's three observations and then there's three hidden states.

If it were perfect sensory recognition, you'd see only ones on the diagonals and zero elsewhere.

That's when the partially observable Markov process can be treated as a fully observable Markov process.

B is where action comes into play.

That's where it becomes a Markov decision process with a policy decision around which slice of B to pick.

C is a vector that describes preference that comes into play with the pragmatic value in the expected free energy calculations.

And D is an initial prior on hidden state.

E is the habit vector, which describes the prior probabilities on action selection.

F, this is just showing the F at the very beginning.

I think it's just given a tiny value for the variational free energy just to make sure it's all initialized.

And G, not sure what's even happening here.

That's for expected free energy for planning.

And not that this was tuned or even really checked super deeply for concurrence with the initial simulation, but these are fitness of the solutions of the agents across two different graph topologies.

Here's a heat map looking at the correlations of some summary statistics of these simulations.

There's average fitness, max fitness, and min of the agents, and then fitness improvements.

The variables have, of course, total correlation with themselves, but there's some interesting patterns.

Here, there is some sweeping across error rate and C improvement, preference learning A after every X time steps.

Distribution of fitness improvement by network type.

Again, kind of interesting, possibly the case that the small world network leads to better fitness improvements.

Average fitness over trials by network type.

Here we see the random and the small world and their average fitness changing.

I think this might reflect why by the end of the 160 trials, they have an equivalent average fitness.

However, the small world improves more.

Most improved topology.

And let's see, max fitness versus min fitness, just a few scattered data points.

The simulation's extensively logged and traced, and it's just really cool.

Let's just try so that we can explore a little bit on the interpretability side.

Control A, Control Shift L, that's going into the sidebar.

And we'll ask

comprehensively explain this simulation, all the components and methods, all about how exactly active inference is being applied here.

This is the sidebar chat.

One thing, I'm also out of fast requests, so I really don't know how fast Cursor is going to process this.

Control I, this floating composer window is an incredible development.

It enables pretty easy editing across multiple files, which can get really far ranging.

So it's definitely like a check and find out what's happening, but it can do some amazing things.

And I think that later in the stream, when we get to more code editing, we'll definitely be using the composer a lot.

Okay.

The script sets up and runs a simulation using active inference principles.

It involves initializing matrices, creating an agent, running inference loops, and visualizing results.

The main components include logging, agent setup, running simulations, and processing results.

We have imports and logging, path setups and constants,

initialization, fitness data initialization, visualization and inference loop, visualization, full sweep of the simulation.

Full sweep simulation runs a full sweep simulation across multiple trials.

Results processing final visualization.

active inference application active inference is applied to the following steps one agent initialization the agent is initialized with matrices that represent its beliefs about the world that's the joint distribution agents are mapped represented compositional cognitive cartography about their beliefs about observations hidden states and policies action selection in the world the agent runs an inference loop

where it updates its beliefs and actions based on observations and internal models three learning and adaptation the agent adapts its internal models as matrices based on the learning parameters and observations and four simulation and visualization and now it's also pulling in real links to PLOS for example here and a medium tutorial that is all legs

medium tutorial from 2018 on active inference cool okay let's just go a little bit further here we're using GPT 4.0 we can ask how does the specific implementation of active inference here in utils underscore active inference

differ from other agent-based models give comprehensive, concise answer, also conveying why slash how slash where slash when, quote, free energy calculations are specifically coming into play.

it was a great question someone brought up in the institute discord pretty recently about well how does active inference differ from embodiment haven't people been thinking about perception action in terms of their unity for a long time let's kind of ask a variant of that question

Implementation of active inference in the UTILS script differs from other agent-based models primarily in the use of the free energy principle to guide agent behavior.

Here's a comprehensive yet concise explanation.

Key differences from other agent-based models.

One, free energy minimization.

Agents minimize a quantity called free energy, which is a measure of the difference between predicted and actual sensory inputs.

This drives both perception, updating belief, change your mind, and action, selecting actions to minimize future free energy, expected free energy, change the world.

Other models, us, them.

Other models, traditional agent-based models often use predefined rules, heuristics, or reinforcement learning to guide agent behavior.

Two, regarding belief updating.

In active inference, agents are continuously updating their beliefs using Bayesian inference, integrating new sensory data to minimize the variational free energy.

Other models, belief updating may not be as central or they may use different mechanisms like state transitions or key learning.

Three, action selection.

In active inference, actions are selected to minimize expected free energy, G, which includes both the expected surprise and uncertainty about future states.

Equation 2.6 in the 2022 textbook.

Other models.

Actions are often selected based on maximizing rewards or following predefined strategies.

Cool.

Nice.

Free energy calculations and active inference.

Where and how free energy is calculated?

One agent initialization.

That's the ABCDE.

Here's action sampling.

Agents sample actions based on their current beliefs and the goal of minimizing expected free energy.

Free energy update.

Agent.update free energy.

Agents update their free energy based on the new observation and actions taken.

And during each time step the script tracks various metrics including average expected free energy list and variational free energy list.

Why free energy is important?

Oh wow.

Perception and action.

Free energy unifies perception and action under a single framework.

By minimizing free energy, agents improve their models of the world and select actions that reduce uncertainty and prediction error.

Adaptation.

This approach allows agents to adapt to changing environments dynamically as they continuously update their beliefs and actions to minimize free energy and some code.

Comparison of models.

Reinforcement learning focuses on maximizing cumulative reward.

Rule-based models use predefined rules.

Evolutionary algorithms use population-based search methods, which Nassim and I recently have explored in the traveling salesperson problem and the ant colony optimization.

So pretty cool.

Thanks, Andrew, for making the original open source educational materials.

Let's go a little bit deeper into PyMDP Poll.

Okay, here we're in Systems, Active Inference.

So PyMDP Pull, it's a super fun script.

I hope that PyMDP learners, respecters out there, give it a try.

Let's open it in the integrated terminal.

Python 3, PyMDP Pull.

Here's what this does.

First, it clones into the specific repo of PyMDP.

Then it lists all the methods.

and it rolls through all the methods in the submodules and it writes it to pyMDP methods.markdown.

So this is a markdown file that is, let's see, 2,500 lines long.

But how cool.

These are all the pyMDP methods listed.

Documentation really matters.

Here's the arguments for pyMDP.agents, which is in the agent submodule.

So here we can see the full arguments, the arity of the agent and example usage.

This is not being generated by LLM.

This is just being pulled from the doc strings and the information that's in the PyMDP package.

So again, those contributions, the questions that people ask really do matter.

Here's PyMDP algorithms run MMP, that's marginal message passing for updating marginal posterior beliefs.

it might be buried somewhere who knows where in a script and here it is brought out for all to see in terms of the parameters that are used and what it returns so it's like wow this is really a cool way to study and learn any package but here just in the pyMdp setting like 1000 lines later

imdp.control.updatePosteriorPolicy is full factorized.

Here we see, okay, we have ABC, a factor, all these arguments.

What does it do?

And this is the doc string, not LLM generated.

But this is awesome for helping read what the doc strings are, not by scanning through and seeing the plain text of the code, but rather by being able to look and say like, hmm, okay, what were the comments written?

But

With PyMDP, we could also pretend for a second like we are going to use some LLMs for development.

Here, we'll use command I. We'll say update and professionalize these methods without altering function.

For example, with comprehensive doc strings, we're missing.

Andrew in a live chat wrote amazing work, Daniel.

Thank you for presenting my work and more importantly, expanding on the original goal, open source learning, open source resources.

Totally.

OK.

So here we're going to update and then we'll put in like a special word or just kind of like a weird symbol.

But if we ran the.

mdp pull again it would pull the whole pmdp cleanly so it won't include our updates also cursor doesn't at this time do very well it says above 400 lines

Certainly it gives mixed results.

Once you get like over 500 or 1000 lines, it does give mixed results.

For example, sometimes it'll do a fix like up near the top of the document.

OK, we're about to find out.

It'll do a fix up at the top and then it'll be like OK and then delete the rest.

So here it just showing this is like LLM augmented development on.

Now this is funny because what it did for the doc strings to the underlying functions was it peeped into the summary we already had and now it's re-entering the doc string in terms of what it has for parameters

and returns so again not saying that's the right way to update but this starts to get into looking really cool like oh maybe there could be like unified formats for what the doc strings are and we could use the active inference ontology in a really coherent way and have the inputs and outputs and the arguments of each of the functions

That's important for translation learning and for our accessibilities also for machine sense making.

So pretty cool.

I'm going to delete the pyMDP repo version here.

And that's where we got to with pyMDP poll.py and studying the pyMDP library.

Okay.

Into part three, cognitive sovereignty.

Okay.

So, Cognitive Sovereignty and Active Inference in the State of Exception.

This was a paper that I wrote in October last year, and the paper provides an analysis of Giorgio Agamben's book Homo Sacre in the Tradition of Active Inference.

I'll just read this first paragraph.

Homo Sacre articulates the relationship between bare life and political existence in Western politics and metaphysics.

Agamben argues that politics is founded on the inclusive exclusion of bare life

where natural biological life, the physiology and cognition of the body, but reading later and more I understood it's not simply only that, is politicized only through its exclusion as an exception.

Drawing on Aristotle's definition of man as a political animal, Agamben traces the historical development of this structure and its continuation in modern biopolitics.

So in this paper, which was super fun to write and I got helpful feedback from colleagues as well,

First, I reviewed my reading of Homo Sacre and some of the logic of sovereignty, drew an illusion between normal politics and the state of exception to normal and revolutionary science in the Kuhnian paradigm,

then played off this kind of fully synthetic concept synthetic intelligence to explore cognitive sovereignty and then considered a situation that we were modeling where active inference agents are having a normal political scenario then there's a crisis which induces a state of exception and then three terms from the active inference ontology but this is kind of a mad lib plug and play

affordances and how that changes during the state of exception variational free energy in terms of bare life and expected free energy in terms of the sovereign's agency during the state of exception and then wrote an active state for its model sovereign agency in the state of exception and gave some pseudo code so it was a fun paper to write reviewed some of this humanities and political sciences scholarship and then got to some pseudo code

earlier LLMs of October 2023.

And then, okay, what could we do next?

Well, we could include a bunch of other topics.

And then we could also actually make functions.

We could make the functions that are described, and we could go from Active Stateference, the sketch above, to Active Governance.

For example, multi-agent setting, cognitive security, quantum cognitive sovereignty, all these kinds of fun topics.

following a recipe a meta recipe that we've seen many many times first what I did is I brought in the cognitive sovereignty paper so I just copied in the full paper 280 lines because one line is like a whole paragraph it's about the number of tokens anyway but the new line thing this is kind of a cool feature um then

i basically just did control a for all control k and then i prompted i said okay write a specification for what the model actually is and so it describes okay will you describe the state space this is kind of like chapter six from the 2022 textbooks what is the hierarchical nature if any how do we think about precision on what

Variational free energy, expected free energy.

What is the state of exception?

What is triggering the state of exception?

How do we build a generative model, generative process?

What algorithms do we need?

How do we think about the multi-agent setting?

How do we think about cognitive security?

And then how do we think optionally about quantum exceptions and extensions?

Scenario generation, validation, ethical considerations.

So this is a technical spec.

provides a comprehensive blueprint for implementing an active inference generative model to study cognitive sovereignty and states of exception.

It incorporates key concepts from the original paper while providing concrete implementation details and extensions.

Then I kind of asked it to go one more step and said, make a technical prospectus for this project.

And again, this is a smaller, but pretty similar.

So those resources are there.

And then just go to the gear and then features, resync.

I don't know how often it resyncs by itself, but it's just good to know.

Okay, we're all caught up.

Okay, now let's open up the script.

So main.py is going to do some pretty cool stuff.

And these are like meta patterns that are just so useful.

There's a config.json that has the parameters.

Here, it's just the input and output directories.

And then how many time steps before the crisis are we gonna simulate?

And then how many time steps after the crisis are we gonna simulate?

There's a utilities that contains the different kinds of class and function definitions.

And then main is going to call in three steps, also printing each line of the output in real time.

Main is going to call one, two, three.

So first it's going to run one, generate an entity library.

We'll look at the structure of that.

Two, it's going to run the simulation.

according to the config and then three it's going to perform a simulation analysis also based upon the config but I don't think there's any analysis free parameters but it could be so python3 in the terminal main.py running one so let's look at the outputs to terminal

Generating Entity Library for Cognitive Sovereignty Simulation.

It saves in entitylibrary.json to the output folder to look at through these.

There's 15 entities.

There's five kinds of entities.

We got government, corporation, NGOs, media, and citizen groups.

And then we have entity one, two, three for each type.

it starts out where government one is in power all the others are not in power okay now it's running the simulation the simulation actually runs like super fast but it takes a few seconds to plot one of the figures let's just look at the entity library while it's running okay so here's how each entity is described um

these are well spaced matrices that describe the transitions amongst five different states the five different states are in power so that's when you start or when you gain power then there's three kind of continuously varying states this is just a five state discrete model

high medium and low power so this is kind of like close to being in power medium power and then low power and then there's homo sacer which is the category for that which can be killed with impunity explored in the book of the same name so here we go let's look back to the terminal then we'll look over all the other outputs okay

ran the simulation, visualized.

This is the step that takes the longest just by visualization methods, but it's a big figure.

Entity traces are recorded.

Then the simulation analysis is run.

So, okay, let's look at the analysis plain text summary, but it'll get more colorful.

So we see, okay, state volatility.

These are just volatility levels.

Like government one has the lowest variance through time, probably because for the first 200 time steps, it just stayed in power.

Whereas the other ones were bouncing around during phase one.

here uh most common states so let's see here's the most common states before and after the crisis like corporation one was most commonly in low power but then afterwards it was most commonly in the homo sacer state or so on and then this top

state percentages.

So here's corporation two.

Here's it before it was bouncing between high, medium and low power.

These are just random matrices.

So it's not super surprising that they're roughly being drawn, but here we see like citizen group one was spending more of its time in a low power situation.

But then after the crisis, it was spending, you know, 18% of the time in the high power 39 in the homeless acre.

Okay.

here's the traces of the visualization so it's a little bit condensed we could run one for like 10 time steps if you want to see the bouncing around oh but very interestingly this could be a slightly different one actually that lineup so that was the government one got displaced in the crisis some new group maybe that's media two but it just happens to be a very similar color but it is a different one that comes in

Here's the results of the simulation, many, many thousands of lines.

Here we see the overall occupancy of the different states.

So we had one out of 15 were in power before, and one out of 15 stayed in power after.

It's a different one.

And then here's like the introduction.

In this kind of toy situation, there was no homo sacer before the crisis, but then it opened up like this niche.

um state percentages the visualizations are a little bit fun they have their own charm to them but here we see like government one was spending a hundred percent of its time before in power and then after it has but these are overlapping bar charts that could be just visually clarified um but we can see like which one was most like media 2 was spending 100 of the power after

okay this is the big figure so each row is an entity and then let's look at these b matrices so here all start out at baseline and government one is just given the power initially but at baseline you stay in homoseker if you're already there but no one starts there so no one is there initially

and you stay in power if you're already there again same thing one is just given it so the others that aren't in power are just bouncing around in this sub matrix between high medium and low so these are transition matrices just markov chain processes then once the crisis happens there's two kinds of states

there's empowered and disempowered so for all entities once you're empowered like there's no secondary changes in power structure in this simulation once you're in power you stay there when you're empowered you just stay in power when you're disempowered now you can this is from to two once you're disempowered so that means like you're not the sovereign after the state of exception has begun from

two so here if you are if you happen to just for that first time step be in power then you get kicked to high power with one that's what they all have that one there and then now you're exploring this four sub matrix amongst high medium low and homo sager so kind of cool

gives a starting point and we could possibly fuse that with PyMDP because in the paper, the definition of sovereignty, cognitive sovereignty, was for one's own EFE to influence the VFE of others.

So when the political operativities of one agent influence the bare life of another, that's the state of exception.

That's political agency.

so that was the cognitive sovereignty simulation it's like cursor and the llm probably could have gotten there a year ago a little bit less than a year ago so it's like not that this simulation was implausible it's just accelerating more and more with going from even the pseudocode i don't know how much it was needed

because it was itself just sort of giving a few sketches so cool okay we'll possibly return and add py mdp like meanwhile if anyone in the live chat has a request or a thought um otherwise we'll look at this fourth section and then we'll recap look at all these suggestions like did you mean eternal return is that what you meant

Okay, FOIA.

Let's bring in a kind of realist twist.

So in other, there's all these different frameworks and different kinds of systems, hence systems within systems.

And let's go to FOIA.

All right.

United States Freedom of Information Act is a pivotal federal statute enacted in 1966 designed to ensure transparency and accountability in government operations by granting public access to federal agency records.

Key technical details include its enactment purpose, scope, request process, exemptions, appeals and litigation, fees,

electronic FOIA there was a 1996 eFOIA amendment mandating the electronic availability of certain records in the establishment of electronic reading rooms whoa and annual reports FOIA is an essential mechanism for fostering government transparency and accountability enabling the public to remain informed about governmental actions and decisions okay so there's a few different scripts in here there's a main.py

This is just a wrapper that's gonna call several of these other scripts, but let's look through them.

So FOIA utils,

First, it loads an API key from the .env file.

So as brought up before in the context of LLM APIs, gitignore is at the top level of the repo.

And here you can specify types of files like file extensions and also whole subfolders.

Like when we clone in other big repos, we don't need to then push those as if they were kind of ours, that kind of breaks the git chain, but we see .env here.

So what happens in utils is it's going to load in using the .env Python package, the API key.

via API key.

So each person is going to get in their API key and mine is in here.

I'm not going to show it on the stream, but then when you make your API request, it will use your API key and then you can keep your .env with your secret keys for LLMs or for the government or whatever it is.

And you know that it's not going to get pushed to GitHub like when you do a push.

Utils has different utilities.

Here are some example FOIA calls that are just like more formulaic.

There's an analysis and a markdown translator.

And then agency year,

has a start and an end year so here we did 2000 to 2025 but I also explored doing like 1200 to 2400 just thousands of years that we wouldn't expect but you never know and then also about a few days ago when I initially did this I got rate limited so I had to have some email correspondences to restore my access but that itself was fun and interesting

then i used llm i just would copy this let's just see can shift here just selecting this ctrl k just to bring in just that part add any missing agencies okay let's just see if and i just did that several times just to to get a bunch of agencies i i don't even know these may not even be real let's see if any are added here okay more agencies

like okay now now you've gone too far let's just see really quick usda aphis this sounds agricultural yeah animal and plant health inspection service that's real kind of like aphid some of these it's like really though

See that JMMFL doesn't seem to be an actual one, but regardless, that's just going to still get called.

So again, it takes the start and end year and all the departments listed.

We could do a hashtag out or we could change to all agencies.

We could say list of just departments.

then just delete that if we only wanted major departments or of course you could just delete the ones you don't want and then just say okay only interested in nsf for this year okay um it it sorts it alphabetically converts it to dictionary and then it fetches this utility if if we were you know but this is a common move so so i might as well just show it select all and then

did i but it wasn't really needed because even just pulling up i control i with the composer it already brought in this script then i'm just going to again just for for doubling check add into the context window for utils move all the methods defined in at foia underscore agency year to foia underscore utils

and invoke them properly here so expected behavior would be it's going to delete red lines are going to show up from 93 to 108 and then we'll be able to check and again this is why being able to here it is it's drafting on these two sub tabs and then let's see how it goes so

whoa so but it can go too far so it it may for like i'm not going to accept this edit this time just because i know it's already working this looks like it might have gone too far but if it's a um what what it usually does or what you can get it to prompt to do is just

pull methods that are defined with def, pull them into utils.

Like what it would manually look like would be copying in control X, cutting out def, putting that to FOIA utils, and then ensuring that the FOIA agency year from FOIA utils is pulling in batch and save annual reports.

That'll still work.

Okay, so what is this output?

Clear the terminal.

We're still in cognitive sovereignty.

I'm just going to trash that terminal.

Right click.

Open an integrated terminal.

Python 3.

Let's just do main.

Okay, so main we didn't update, but again, this is what it looks like to debug.

Just

put it into the composer fix it meanwhile let's call the foia agency here accept it again looking is probably a good thing to do it's like it's not just like not looking before crossing the street it's like

not looking when making stochastic edits to your phd dissertation which is live code but c'est la vie okay there we go so even without intervention foia agency year okay so what it's doing is it maybe we're getting rate limited i'm not sure um for each of those departments it's saving

these outputs so we'll keep watching what's happening live I'm not sure maybe this is going to be about to be a huge one but first it checks if we already have that exact combination of agency and year then I concatenate in the file name this is just one way to do it could be done like way better ways um the date that it was pulled that's 2024 8 20. um

I'm not sure if that last piece the time but then the middle piece here is like 19 characters because for this one like 2000 DOI let's just look at it let's look at a um let's look at the USDA okay so 2005 it's 19 characters long you're going to see a lot of 19s because 19 just says report not found so if you request what what was the annual report for the USDA in like the year 3400

probably it's not found on that server not saying it's not there but then we can see okay here's 2010 annual report okay interesting but we got it so this is their foia metadata as far as i totally understand this is all open information i am not doing anything other than just calling the foia api

So we can see how many characters are there.

And then it's like 2024 and 2025 are back to 19 characters because those reports are not there.

Not sure, like it'll be interesting to see what comes out here.

Okay, but I'm just gonna kill it.

Clear.

And then let's call FOIA to markdown.

So here it's gonna make a FOIA markdown folder.

So it's just iterating over all the reports.

It's giving a lot of errors.

Maybe we could debug it, but we'll see.

Let's go to DOE.

So here's the 19 character one, report not found.

But here's the 43.

Okay, now this is looking a little bit more readable.

Let's make a new script called FOIA

secondary MV processing dot py.

It's already in the context window.

I'll add into the window a markdown that we know has a lot of characters.

So we'll do DOE 2008

let's try without specific reference to a file it would work with reference to a specific file but just make sure that it doesn't over fit there let's say given markdown documents in dot slash that means this folder foia underscore markdown slash folder and all sub folders right

secondary processing algorithm that reads in and improves formatting and conciseness saving all outputs to a folder dot slash

FOIA secondary markdowns, slash, open parenthesis, make it if it is not there.

Recapitulating folder nested topology.

Thank you.

I'm curious to see because it's not going to do an LLM call.

But if you'll recall back to InfraAnt Stream 1 and the kinds of LLM API augmentations that were possible, then we could imagine, okay, now iterate over all these reports and do LLM summary or do translation or explain it to this person.

Okay, let's just see how it goes.


UNKNOWN:
All right.


SPEAKER_01:
Clear.

We're in the FOIA folder.

Here's secondary MD processing.

Python 3, FOIA tab.

It goes to the point where it's ambiguous and then secondary MD processing.

Okay.

No module BS4.

Some people might know ways to fix this, but let's just see what it recommends.

Okay.

adds some i'll just accept it clear run it again error beautiful soup four is not installed installing it now so this is what's so fun and collaborative is like oh okay i came across that friction and then just within a few seconds okay but now no one else will hit that exact friction okay interesting so let's look at what it's doing

OK, this is processing from ones that are that are like just kind of empty in.

So we'll see what those maybe those have a different format.

But it'll get through them.

OK, it just looks like it's spacing it out.

But you know.

What's wrong with that?

And then let's see when it goes through the subfolders or what happens then.

Okay, it's almost done with the ones that were just in the folder itself.

Meanwhile, this is like the last section that I had prepared to go through.

So please write any comments or questions or ideas in the live chat, and then we can play around a little bit and do a little more developments.

Okay, here we go, OIP.

Okay, okay.

okay okay not okay oip might be an exception okay let's see another one hud okay so 19 okay this is the report not found and here's okay okay okay you know is this helpful possibly

Would LLM being used in this loop be helpful?

Yeah, probably.

Okay.

Just pull this off screen for a split second.

But api.data.gov.

I mean, this is what USA OS is.

Like when we think about what is USAOS?

Well, interestingly, I'm getting some very strange internet patterns from the other window, which I'm not going to show.

But let's just end that one and see if I can pull up USAOS.


SPEAKER_00:
Wow.

very interesting.


SPEAKER_01:
Here, I've just navigated over here.

But here's from my personal page drawing from Kirby earner, USA OS, but it's like, has it ever been more API oriented to interface with speak program, utilize the USA operating system?

Not sure.

Okay, clear it.

Close the terminal.

I'm going to delete the markdowns because those can be regenerated, but I'll leave the responses that already came in just because those are information.

It's just kind of like, it's an API call that anyone could have made.

I'm just listing them there.

So that was the FOIA.

Okay.

All right.

All right.

Okay.

Let's recap.

There was a couple sections here going from the end to the first.

Most recently, we looked at this Freedom of Information Act API call scraping, processing, handling pathway and explored with the gitignore.

how you can put your own personal API key into .env.

You need an email address to sign up.

And then that's a way where like many people can collaborate on the open source tooling while also keeping their API keys secret.

That's the FOIA.

Then we looked at in folder nine under other, and then we looked at two different, well, I guess three folders within zero context systems.

Now here going in forward chronological order, we looked at William Blake's work, entity extraction, some processing, and some snippets from Blake for augmented Blake friends.

Looked at cognitive sovereignty, skipping to the third one of the first three.

talked about how this meta recipe for bringing in a resource folder, asking it to write a technical spec or a prospectus, and then writing software that's very well structured and articulated for further development

with utilities and mains and configs and how that resulted in some pretty interesting outputs, like just about looking about transition matrices and setting us up to integrate with PyMDP, which we very well could do if someone mentions it in the live chat in the coming minutes.

And then lastly, in the active inference system section, the PyMDP pull method, and I'll leave the PyMDP methods up.

Let's just...

intra stream 003 push it and then let's read pi mdp methods in in its natural context that was one hour ago reload the page reload the page now it says now zero context systems active inference pi mdp methods

This is like getting into, oh wow, this is like kind of nicely formatted.

This is like something you could take on a nice trip.

Okay.

Andrew Pache is writing a few things in the chat.

I'll wait a few seconds while you type out some more ideas.

Anyone else though, again, please write any ideas.

And for a couple of minutes here, let's just chill.

see what else we can explore and learn and do.

Actually, while people are writing, I'm just going to do a quick overview on what is in these different folders.

So starting in Xero, computer languages, this is a language named BrainFuck.

This is a BrainFuck implementation of Active Inference.

Famously an obscure, arcane, bizarre coding language, but why not?

Right?

It's all just semantics.

Then we have BrainFuck, Active Inference, Golang, Thing, Agent Definition, Java, Active Inference, Perl, Julia.

In Julia, it's not done yet, but Cobus E has done incredible work on visualization and many, many other things.

And so I was working to get a script working that would render the kinds of images that he's doing and do a bunch of other stuff, but that's just in progress.

Rust, and then like hilarious stuff like active shellference.

I mean, this is a shell script that does active inference.

This is really highlighting the semantics and the syntax and the space between and the kinds of pole jumping that we can do back and forth.

Specs and prompts, some early documents, meta and formats.

bioinformant systems folder.

We have Active Inference, Cognitive Sovereignty, IC2S2, and William Blake we went into today, P3IF, and some of the bolts, business, legal, operating, technical, social.

These were explored in some other streams about legal engineering and the 3Rs and all of that.

So that's the zero context folder.

That's setting context.

Here's in prepare.

This is a fun folder.

It has a ton of, it has config,

with all these configurations for an ANT active inference multi-agent simulation.

Then there's meta config that configs the config, and then there's meta meta config that configures the meta config.

We have cognitive security, cryptography, digital twin design processing, digital twin metaphysics,

metaphysics spec generator this is the speculative realism coding at play nested systems systems within systems invoking the category theory networking pheromones the pheromone ontology the quantum pheromone environment and then a little bit of culinary delight with the salt fat acid heats pomdp methods

This is where there's a variety of methods that are developed with LLMs and research methods, learning, education.

Also, please contribute to everything.

And then things, here's different things, including a generic, generic, generic, generic, logged, constructed thing.

So context, again, is just sort of like a bunch of different things that contextualize for us and for Shirley Cursor.

One is preparing with configs and the things definition and the methods definition.

Then two goes into operate.

Here is planning, rendering a plan, executing the rendered plan of a simulation, and having situational ant awareness along the way.

That's the actual operativity of the simulation.

Then we have measurements, measuring the simulation.

Four, reporting on the measurements of the simulation.

Five, following up and specifying and executing the follow-up on the reporting of the simulation.

Six is an API for meta and format for knowledge.

I don't have too much in here.

Seven and eight,

are not there and then nine is this meta pattern where we clone in the GitHub repos or the GitHub users for a given domain like the brain these the brain API and then bring them in reindex cursor then program

and then we can delete the original repos so that that that's a fun way for if there's like something that people want to integrate there's a few multi-agent llm techniques and like agi related things that would be pretty interesting maybe for a future one so that's the active inference package okay thank you andrew i'm gonna copy what you wrote in

okay let's go back to zero systems 3.1 okay let's just do 003.2.md as if there was the dot two okay

Andrew wrote, quick thought on Act-Inf, PyMDP, Cursor, AI integration flow.

One, build out working scripts plus add to repo, e.g.

example, social sciences.

Two, Cursor reads working script repo to aid in building, recreating new simulation.

Use Cursor's help as much as possible.

To finish the simulation, do manually what it can cannot.

It's Horizon.

Three, rinse and repeat.

We hit the limits of the currently existing LLMs along the way, but we build the repo and available academic simulations resources as we go while improving the repo's ability to provide cursor with useful information for improving next script building iteration.

I believe this is what you're proposing, just exercising my own understanding of it here, smiley face.

Okay, thank you, Andrew.

I'm gonna delete that last one.

Now, let us do this.

Control A, Control K.

operationalize this into a comprehensive development plan for what I will immediately do after your response, comma, LLM.

I don't know if it's been explored whether saying things like thank you or speaking to it a certain way help.

Awesome.

Okay.


SPEAKER_00:
Okay.

Okay.


SPEAKER_01:
Make a new folder called augmented active inference.

Okay, let's just try this.

Here we're in 3.2.md.

So we just took a few super chats from Andrew and spec'd it out.

Okay, so create a new GitHub repo.

Doesn't need to be a GitHub repo.

Build working scripts.

Cursor AI integration, documentation and testing, iteration improvement, next steps, continuous integration.

Okay.

Control A, Control I. It wasn't necessary.

It's like the whole file and lines one through 62, but that's the whole thing.

But it's just, it's a habit.

What can I say?

Do all of this, making all the files needed

Saving the new files as created in dot slash augmented active inference.

Okay.

Let's see.

Certainly.

Okay.

It looks like it's doing that in the top level repo of the whole inference, but we'll bring this in and we'll just replace this folder that we made.

Okay.

Drag in.

Here we go.

Okay.


SPEAKER_00:
Reset.

Reset.


SPEAKER_01:
This is just because I rug pulled where it had written it and moved it.

Okay, here we go.

Okay, script overview.

SocialScienceSim.py implements a basic social science simulation using PyMDP.

Okay.

Save it, close it.

SocialScience, okay.

From PyMDP import agent inference learning.

Social agents, okay.

I'm going to run pyMDP pull just so that we have the actual pyMDP repo.

Actually, let's see if we don't need that first.

Okay.

We're in the augmented.

Okay.

Social agent run simulation.

Okay.

Utils.py.

Process, visualize, calculate, tests.

Cool.

Unit testing.

All right.

Open it with integrated terminal.

So we're all the way deep.

We're deep into this cursor augmented situation.

Python 3, social science sim.

Okay.

Nothing happened.

Here, control I. Add extensive logging here and in the whole, just here.

So we can have better understanding and achieve in this folder the aims of 003.2.

Pull it.

Okay.

Certainly, I'll enhance the logging in the socialsciencesim.py script to provide a more comprehensive... Oh!

Okay.

Okay.

Looks good.

Now, add the utils into the context.

Probably not necessary, but...

move all methods to at utils dot py and invoke them here that's what i was trying to do earlier so let's just see what it does now

So it deleted these definitional statements and then we see it added them into utils.

Save it, close the utils.

The README for this repo.

All right, let's just quickly, let's just push it.

Augmentation push.

Then let's read the README in its natural habitat.

okay augmented active inference read me oh interesting okay it was empty because it wasn't saved in its place reload the page here it is okay active cursor integration the integration of active inference principles with cursor ai for social science simulations

Okay.

Now, clear it up.

We're in social science sim.

Make all needed improvements to achieve the aims of readme.

move all method definitions to at utils.py and invoke them here.

Let's see, it's doing this.

I believe this will be fixed in a future version, but sometimes it'll be like,

going all the way back up the repo there might be a way to to to do this just better with how the paths are handled let's just see what happens when we run it first okay cannot import name agent from py mdp fix this but we know that it has access to py mdp methods.markdown

So this is the one that's like the study guide for what PyMVDP does.

Now, for a human, human ant, reading this document, as mentioned earlier, it's probably great for trains, long car rides, you know, dark rooms, all these kinds of places where you might want to read something, just really pay attention to it, but it's the perfect high density semantics that will be helpful here.

Let's just accept whatever it did, see if it did better, and then if not, we'll give it a little help.

No module named pyMdp.agents.

That's a new error.

Fix this.

So let's just keep on finding and quashing some bugs.

And let's just see if like, can we get to a pyMdp with, we haven't brought in the pyMdp repo, but it will work if we pull, if we clone in the repo, then we can explicitly invoke the functions.

PyMdp has no attribute agent.

Okay, so we could be going around circles or not.

I apologize for the confusion.

It's like, no, no, I wasn't confused.

You don't need to apologize.

I think that this composer functionality, again, super cool.

And there's also probably ways to use it a lot better because it has a whole another view layover that I'm not really even exploring at this time.

Okay, cannot import util.

So when it's one kind of line of flight,

and just like quashing bugs that seem to be of a similar ilk, I'll keep it rolling in the same Composer.

But then when it's a different vector and we're going to do a pivot, then we can do a new one.

Okay.

No module, PyMDP distributions.

So it's kind of fixing a series of errors related to accurately calling PyMDP sub-modules.

This could be like super PyMDP file structure specific, but nonetheless, that's where we are.

Okay, okay, okay.

This version implements a simplified version of SimpleAgent using only NumPy.

We've replaced the PyMDP specific operations with basic NumPy.

Let's see what it looks like.

Wow.

Like, so then it's like, then who was semantics?

If it takes the POMDP semantics, you know, was it all what?

Okay.

Okay.

Okay, got some plotting Matlib plot errors, but I can see from the top, okay, that it was doing stuff.

So in social science, sim.py.

Save all terminal logs to a file log.txt.

Save all output files slash visualizations

to a folder in this folder output slash make the folder if not there.

Claude 3.5 Sonic doing it today.

okay accept it save it clear it clear your terminal double up run it okay got an unexpected argument exit here we go we have agent one and agent zero receiving observations updating beliefs taking actions amazing see here it just put that over here

So let's look at this one.

This is in the correct location.

This one is 100 lines long.

This one is

because like it's seven lines long just implement that one little stub but then it did it in the wrong place I don't know if that's I'm just using it weirdly or if it's just getting confused because we're really deep in this nested repo if you just do kind of like one project per repo like William Blake repo cognitive sovereignty repo then the embedding is faster there's less context but

That's kind of the delight also, is all this mixed interactive semantics.

OK, clear.

Run it again.

We're going to get probably the same error.

Oh, well.

But where did it save the logs to?

Ensure all terminal outputs are saved in this folder to log.txt.

Then we'll move all the methods.

Also, just for context, here's the system prompt that I give cursor.

Use professional, functional, modular, concise, elegant, interpretable Python.

Use comprehensive logging to terminal and all other programming best practices.

I'm going to delete that part because maybe it's over-learning on that.


SPEAKER_00:
except save it, clear it, clear it, run it.

Okay, now we got to this area.

Fix this.


SPEAKER_01:
Okay, we'll progress a little bit further on this, bring in a few PyMDP methods.

Till then though, if anyone wants to... See, again, now it's editing social science SIM utilities in the outer folder.

So it's like, why?

But if anyone writes a live chat with like a thought or a question, we can definitely do it.

Okay.

Also, again, we know that we'd be able to bring in the full clone in PyMDP and then just explicitly reference it.

And it's like, that's not even a bad strategy, but let's see if we can do it without cloning in the repo.

So move all methods to at fills.py and invoke properly here.


SPEAKER_00:
Okay.

Okay.

Okay.


SPEAKER_01:
Accept it, save it.

I'm going to copy in just another message that Andrew wrote and read it here.

FYI, with appreciation to the work being done by both the SPM and Pi8DMP, MDP, which is heavily based on SPM, I can confirm via hours of repo cross-referencing there's no easy route from either of these.

You can't get there from here.

packages and their dependencies to an easy ready-to-go simulation builder already simulating two agents even before inspecting the script logic awesome big feet thank you awesome andrew cool okay but another way we could do this would be oh simulation results okay there's three agents they're taking actions over time just by calling this

Okay, now let's see what happens.

Let's just re-index cursor, make sure that we're in the right spot.

So here it's all the files that we touched.

It needs to re-index.

It might do a little mini re-indexing when you call something into local context, but I don't know.

Okay.

Bring it into the composer.

Now, update this, update and extend

these methods invoking where possible at pyMDP methods.

So that's the one that we've been looking at and enjoying, which is it's like the doc strings and the input output for all these pyMDP functions.

Okay, let's see how it does.

it drafts it up here so here's like where the generation is happening and then once it finishes this v1 draft then it runs through okay and it goes through again second pass it's kind of like a measure twice cut once situation

Okay.

Save it.

Clear Composer.

Social agents.

Here we see ABC.

It's like QPI.

This is actually doing the expected free energy based model updating for A and B. Okay.

Now over here, comprehensively develop.

I'm using the control K version here just for a little flavor.

Using the at utils.py

to achieve the mission of 003.2 maybe there's a way to do in the system prompt like just say

And this is also where programming practice and expertise and all this comes into play.

Maybe there's a way to make sure that we always call the run script main, and then we always call the utils, like utils underscore, and then the type of utils.

Then we could have a system prompt that's like,

I only like to run scripts called .main myself.

And please ensure that utils underscore asterisk are comprehensive and, you know, make it so that Carl Friston would smile upon it.

Clear.

Social science sim.

Okay.

Can't import name control.

New errors.

Fix it.

script overview meanwhile while the control i is going control k develop this given all we know now accept whatever it says clear run it again reset that one's done accept it pop back to social science sim can't import inference new one fix it meanwhile back to 3.2

develop this given what we know now okay see here now utils again is going to the wrong place we'll get it there let's just see what it does okay okay

Okay.

Oh, create contribution guidelines for potential collaborators set up a project wiki for detailed documentation tutorial.

Consider presenting the project at relevant conferences or meetups, like the fourth applied active inference symposium from November 13 to 15 2024.

Possibly, let's just say develop section nine, comprehensively, comma,

absurdly comma professionally then we'll pop back to the simulator okay okay okay all right it's all about nine now wow okay talk about cart before the horse it's like

why why not just focus on section nine aren't you interested in like subsections reject it it's okay we know it would okay okay

okay andrew wrote typically infer policies and sample action functions are called separately albeit often adjacently as pi vp the lom seemed to realize it could combine them into a single function flow okay let me say now given at so then andrew wrote subject to change of course point is fascinating to see how the llm might make optimizations not inherent to the original libraries i mean

yes that's that's very characteristically understated yes it suggests stuff that's like it's an adjacency in like dimension 754 but for a given person it's like it might pop up to your awareness in a moment it might not

But even if what popped up in your awareness were like awesome, epic, professional, modular, absurd, great, every single second, or you're doing it 10 times a second, it's like you still might never just riff enough, let alone capture and do that kind of cosmic fishing.

Explain this comprehensively.

Okay, so now wall control L is going.

Reset it.

Let's add in the utils.

Run it, but we know it's going to give an error.

Add it to the composer.

Fix this with reference slash modification only to the local folder.

Okay.

Combining InvertPolicy sample action functions into a single function or flow can streamline the simulation process.


SPEAKER_00:
Clear it.

Run it.

No module PyMDP at all.

Fix this.


SPEAKER_01:
It's making a lot of changes.

Again, there's so many ways to do the professional programming.

This is just one sort of Pythonic strategy.

Okay, now it's bringing in PyMDP these units.

Save it.

Clear it, double up, run.

Can't import name inference.

Fix it.

Also, it's like we could have just added, well, it can't import inference.

But maybe inference doesn't even exist.

Those are a few of the situations.

See, now it might just be kind of floundering right here.

Let's see.

No module pyMDP.Core.

Let's just go over to pyMDP and just see what they are.

But this is getting pretty specific in the pyMDP's folder and submodule structure.

yeah just maybe uh 10 to 30 more minutes but if people have comments or questions please just go for it okay so there it's just saying you know what ignore that core mention run it okay cannot import inference and delete it

cannot import control we let's just accept importing pi mdp period fix this however yeah okay andrew wrote inference algos etc do exist but the dependency structure is highly complex yeah

Okay, I... Okay.

Okay.

Okay.

Let's do a little... Let's do some radical PyMDP surgery.

Here, okay.

CD double dot, pop up a level.

LS, that's what's there.

CD double dot, pop up a level, LS.

There's better ways to do this.

I'm just showing one way to do it.

CD active inference.

Now we're in active inference, not the augmented one.

Okay.

Reload our LLMs, get them ready.

Okay.

Python 3, pyMdppool.

Clone in pyMdp.

Okay.

Okay, here we go.

New script.

This is gonna be called pyMdp underscore flatten dot py.

Okay.

Here, given all the functions in pyMdp package, iterate over the entire Python package.

Write a script that will iterate over the entire Python package

pulling out all Python method slash entity definitions, e.g.

across and through modules, sub folders, et cetera, and output a mega, I won't use that, output a text file

PyMDP methods flat dot py, which, let's do PyMDP utils.

PyMDP all utils, which contains verbatim all PyMDP methods for the calling.

Okay, so we're going to generate the script here that's going to flatten PyMDP.

Okay, again, it pulled it up here.

Copy it, PyMDP flatten, paste it in.

Okay.

Okay, like if this works on one shot.

Okay, there's pyMDP flatten.

Python three, pyMDP underscore flatten.

Okay, what do you think?

Extract definitions, AST walk, process package main.

All right.


SPEAKER_00:
Okay.


SPEAKER_01:
Okay.

A little bit of weirdness just because of IO operations on closed file.

That could be just due to something weird about how I opened the


SPEAKER_00:
Okay.


SPEAKER_01:
Extracted 24 definitions.

Alright.

Alright.

Looking good.

Ensure that this

script iterates through all folders and sub folders within dot slash py mdp now it let's just see os walk

Accept it, save it, clear it, double up, run it.

24 definitions.

Still, I am only getting 24 definitions.

There should be hundreds.

Now this, even if we get to hundreds, it won't be the right output, right?

Because like there's going to be a method defined in utils and I expect there'll be a similar one in slash jacks slash utils.

Okay.

Clear, double up, run it.

Okay.

okay look in this very folder comma my colleague there are subfolders in what was cloned by

That output there is the whole PyMDP script.

That's what we need the whole team to look through so we can get all hundreds of methods to make a flattened

single mega utils file for simpler referencing.

Remember, we're just Netsmace.

The script is looking at the installed PyMD package instead of locally cloned repo.

There we go.

But why didn't you just say so?

Now, there we go.

456 to all utils.

Okay, now I'm gonna pull this back into the scripts.

Well done cursor, take a quick breather.

Okay, clear CD double dot, pull up CD augmented, enter LS, CD scripts, LS, go over to cursor,

Double check it's all re-indexed.

Delete the original pyMDP.


SPEAKER_00:
There it is, new files.

We'll just make sure it gets them all.


SPEAKER_01:
456 definitions, says Andrew, incroyable.

that's like exactly how i feel it's like what what oh for abjus incroyable day okay social science sim add in to this context window imdp underscore all utils

Develop this multi-agent social simulation given all methods fully defined in imdp underscore all utils dot py in this folder.

Okay, meanwhile, well, let's let it edit, then we'll... Okay.

Okay, it's kind of writing it in the Composer window.

Again, this might just be a tiny cursor bug.

It'll be like, there it is, there's my answer, but it's like, well, no.

So it doesn't suggest a code edit.

So I'm going to say, suggest all those code edits to social science sim.

It's like, oh, I'm sorry.

Yep.

Pretty cool.

Okay, now this is where it's doing the composer mode correctly.

It opens up a second tab, then it writes all those code edits there, and then it'll rescan this one and say, well, this was my updated draft and this was the original draft.

So now it pulls in.

Let's see how this does.

fix this, remove the need to ask about version if that is simpler.


SPEAKER_00:
Okay.


SPEAKER_01:
utils.py it's because it's calling both the utils and well let's just rename this one utils yeah rename this utils well first let's just delete the ones that we had

do well if we call it utils old it might get confused okay utils.py then social science sim utils import star okay fix this removing the need for the method

or invoking it or writing it if it is missing.

But then here's the deal.

Utils.py, which is the flattened all, it's 20,000 lines long.

So then it'll have a hard time reaching in and making the targeted edit to something in here.

See, it might just be like, oh, we don't need that one.

Let's see.

It might just be like, let's delete 19.9 out of the 20,000 lines.

Okay.

I filed too long.

See, edit command is limited to files at most around 400 lines long.

So then it just cancels it.

So I get that.

I get that.

all piMDP utils.

Social science sim from all piMDP utils.

Save it.

Write this so that it only uses functions defined in at all piMDP utils.

it imports everything which is perfect.

Don't change that.

Use the PyMDP methods to make this multi-agent simulation that initializes, simulates, and visualizes a social multi-agent setting.

we'll do a few more minutes if anyone has like comments or questions let's see them also again it's defining methods here so see what it does

Social agent now uses agent from pyMDP along with random A, B, et cetera.

Okay.

Okay.

Remove the need for unit test.

Not sure what that is, we can like look.

that's the unit testing methods I understand see but like do you like philosophically do you let's just ask it not that what it says will be an answer philosophically would you say that you fully understand

this script and all it implies?

Kind of a trick question because it's like, all it implies?

Okay.

Accept it, clear it, double run it.

Okay, let's try it.

Here's what it says.

Did you mean, okay, yes, I did mean Python 3.

okay so okay well there's the answer for whether it thinks it understands it but that's like that's like something for people to consider like this is why i leave the same composer window running really make sure that social science sim does not need any unit test stuff at all

Hmm.

Okay, but meanwhile, new side chat just dropped.

Write a hilarious, age-appropriate, esoteric, lore-laden, who's on first, style dialogue for fully explaining

allegorically to someone familiar with reinforcement learning, everything happening in this active inference multi-agent simulation

Ensure many baseball history historical references, comma as well.


SPEAKER_00:
OK.


SPEAKER_01:
Update this so that it runs with just.

Python 3 social science sim.py no command line arguments.

I think I accidentally terminated the... Let's do sonnet.

I think it does sometimes funnier who's on first dialogue.

Okay, we have two sonnets working for us.

Here...

We got the baseball dialogue, slow position 12.

Okay.

Okay, out of the command line arguments, now we can call it the way we want.

Accept it, save it, reset it, clear it, double up, run it.

What did I say, Sonnet?

Ensure that unit test is not required at all.

I never... This is something I've never said before.

I never want to see that bug again.

Meanwhile, who's on first.md?


SPEAKER_00:
Okay.

Okay.

Let's not get ahead of ourself.

Save it, clear it, double up.


SPEAKER_01:
Fix it.

And remember what I said last time.

see if we can do like a couple more see if we fix it and then otherwise we'll close with um reading the who's on first summary and then at the end of that i will read any comments that people have or questions that they have asked in the meanwhile and that will conclude in for ant stream three no no you don't have to apologize i just said remember what i said

Let's just see if cursor has self-awareness.

Fix this in a way where you, cursor, don't give me that error.


SPEAKER_00:
Okay.

Let's see how that goes.

Okay.


SPEAKER_01:
Control shift L. Andrew wrote, restructuring a library that's taken years of development and various programmers to develop, not to mention everything contributed to its SPM precursor.

Can it be done in a few sittings?

And I'll say, that's what my OC file too long.

To avoid cursor, I'll make it more.

So we'll leave it there.

We'll push the update.

So updates, not all fully working.

The sem antics are basically there though for any and all to build upon and help through.

Okay, we'll push that.

structure this for professional markdown viewing that's what my friend andrew said prepare a total response to him that is respectful and age appropriate okay

going to read the response to andrew then we're going to push andrew i appreciate your perspective on this you're absolutely right that restructuring a library with years of development history and contributions from multiple programmers is significant undertaking it's not something to be taken lightly or rushed through dot dot dot dot dot what are your thoughts this is kind of like

Hold on there, partner.

Slow down.

Restructure PyMDP by flattening it and squeezing it?

Okay.

Close it.

Save it.

Close it.

We did what we did.

Save it.

Close it.

Clear it.

Close the terminal.

Clear it again.

Close it.

Goodbye, cursor for today.

who is on first question in tarot bang then we'll read it there and then i'll look at any live chats augmented

Docs.

Okay, here we go.

It always does the 27 Yankees.

Okay.

Hey Costello, have you heard about this new active inference multi-agent simulation?

It's like the 1927 Yankees of AI.

The 1927 Yankees?

You mean with Babe Ruth and Lou Gehrig?

No, no, I'm talking about Social Agent and its teammates.

They're like the murderer's row of artificial intelligence.

Wait, who's on first in this simulation?

No, who's not in this simulation?

We got Social Agent on first, Observation at second, and Action at third.

Okay, so who's Social Agent?

Exactly, Social Agent's on first, just like our old pal, Who.

I'm asking you, who's Social Agent?

No, no.

Social Agent is like Babe Ruth.

He's the heavy hitter of the simulation.

He's got a random A matrix and B matrix, just like the Bambino had his legendary bat and glove.

So, Social Agent has a bat and glove?

No, he's got beliefs and policies.

The A matrix is his belief about how observations relate to hidden states, like how the babe could read a picture.

The B matrix is his belief about how actions change the world, like how Ruth knew just where to swing to hit it out of the park.

All right, what about second base?

You said observations there?

That's right.

Observation is like Earl Combs, the Yankee center fielder.

Always watching, always observing.

In the simulation, Observation feeds information to Social Agent just like Combs fed balls to his teammates.

And actions on 3rd?

You've got it!

Action is like Tony Lazzeri, the Yankees' clutch hitter.

When Social Agent needs to make a move, Action steps up to the plate.

So, how do they play together?

Well, it's like a perfectly executed double play.

No, triple play.

Social Agent uses his A and B matrices to infer the best action, just like Ruth sizing up a pitch.

Then action takes that inference and makes a move, like Lazeri turning a double play.

Meanwhile, Observation is constantly updating the game state like Combs tracking fly balls in the outfield.

But what's the goal of this game?

Huh, that's where it gets interesting.

The goal is to maximize expected free energy, which is like trying to win the World Series of Cognition.

It's all about minimizing surprise and uncertainty, just like how the 27 Yankees minimize their opponent's chances of winning.

So they're trying to predict what's going to happen?

Exactly.

It's like they're playing interdimensional chess while everyone else is playing checkers.

They're not just reacting to the environment, they're actively trying to shape it.

Just like how Babe Ruth called his shots.

This is making my head spin more than a Dizzy Dean curveball.

Okay, that's hilarious.

Don't worry, Costello, just remember.

In this game, every agent is trying to be the Babe Ruth of their own cognitive world series.

They're not just learning from rewards like in old school reinforcement learning, they're actively inferring the best way to play the game of life.

I think I need to go sit in the bullpen and think about this for a while.

That's the spirit.

Just like how active inference agents are always updating their models, you're updating your understanding.

You'll be a cognitive hall of famer in no time.

Conclusion.

This allegorical explanation aims to provide an intuitive understanding

the active inference multi-agent simulation by drawing parallels with baseball concepts and the legendary 1927 new york yankees team it highlights key components such as the social agent observation action as well as core concepts like belief updating and free energy minimization all right

Thanks everyone for watching.

That was super fun.

Hopefully you enjoyed some of these methods and demonstrations.

It's all happening at the Active Inference Institute slash Active Inference Repo.

Everything we looked at is open sourced and pushed.

It would be awesome for anyone to use, play, extend further, come participate, have fun.

All right.

Thanks.


SPEAKER_00:
Bye.