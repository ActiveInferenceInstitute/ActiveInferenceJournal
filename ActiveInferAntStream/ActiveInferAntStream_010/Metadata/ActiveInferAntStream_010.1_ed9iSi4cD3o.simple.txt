SPEAKER_00:
all right we're live welcome everyone it's february 7th 2025 and we are in active info ant stream 11. looking forward to a lot of feedback interactivity and plain text fun and learning all the pushes during the stream are going to be going to the repo doxology slash cognitive

and let's get right into it.

All right, so previously on Active Inference Streams, we've heavily featured the cursor development environment tool, and that's gonna continue to be used as well as seen a little bit with Codeviz, and that's gonna come into play again.

And in this stream for plain text, surprise, education and delight, we're going to be working a lot with Obsidian.

So Obsidian,

at the repo or website obsidian.md is a plain text note linking software open source and it is going to facilitate us doing some truly awesome things with plain text repos and playing back and forth between cursor and obsidian is going to go really far so here in the obsidian window

On the left side, we're looking at the same file that on GitHub can be found here, and in Cursor can be found here.

So we have two local versions of inference stream 10.md.

So if we delete something, like starting with a GitHub push, save it in Cursor, that's going to be gone in Obsidian.

Obsidian uses a linking style where two brackets

open up the ability to make a linker.

So that is going to be reflected visually in this graph version.

So before we go too deep in, this is some incipient, exciting, relevant development work.

It's semi-structured, so don't let the graph and the weave

make too much light of the fact that if we zoom out, of course there's more to paint into than not.

And looking forward to people's collaboration and contributions.

You can head over to the repo while the stream's happening or afterwards, or if you're watching live, definitely put some funny questions and ideas into the live chat and we'll bring them into the repo and that will weave that way.

Big picture, we're going to be in some ways that were not really even possible a few years ago, integrating theoretical foundations, writing them on the fly and connecting with practical implementations.

So we can delete that and then we can see, okay, now we just updated a plain text file.

So let's just make that push just for fun.

Okay, where do you even begin?

so welcome an overview of obsidian usage so this could have been typed in manually like this two brackets obsidian usage when we click on that link it's like wikipedia we head over to this article

And there's going to be links in the article.

The ones that are brightened are the ones where there is a page and the ones that are dim, there's no page yet.

And so if we click on that, it makes that page at the top level of the repo.

So we don't need that at this point, but let's look a little bit at Obsidian usage.

And this is a Markdown format.

Everything is these plain text Markdown files.

Okay, so file names link directly.

File name, vertical line, alias uses custom text if you want it to say something different than the file name.

And here we have some machine readable information.

And then over on the graph side, we can filter down and try to see what's in the neighborhood of Obsidian usage.

going to be a lot of active inference generative models in this stream as well but first i just wanted to start this way so here we are and when we have our cursor there we get this colorful highlight of obsidian usage and everything that it's linked to in the plain text gets rendered as an edge here so we can drag around that play with that okay okay obsidian usage plain text benefits let's check out plain text benefits wow

version control, knowledge management, machine readability, research benefits, all these different benefits, which cursor wrote entirely for me, and we'll get to how and where that happened.

Okay, back to the top level and let's carry on with the stream.

So previous streams, we've been using different synthetic intelligence and live chat methodologies for having a great time learning about what other than active inference and the free energy principle.

So let's check out those articles.

Again, these were written entirely using cursor.

So what that looked like was, let's head over to knowledge base

mathematics, we can go over to some active inference article.

So here's the plain text article.

This is it in Obsidian.

So here we have everything from software examples to could be anything.

If we want to use AI to update this active inference article, bring it in with control I to the composer mode.

And then we can say, add

fantastic, comprehensive, relevant length and structured type of new sections to the Active Inference article.

Now if we head over to Active Inference,

We see it's connected to a whole variety of different terms and topics and ideas.

So very cool how also by embedding a Docs section, there's a lot of Obsidian style also just picking up from context.

So here is Claude, 3.5 Sonnet 2024-1022.

I've added four major new sections to the active inference article.

So here in the green are these new sections that just got added.

Again, you'll remember from earlier inference streams where anything above like 200 lines of code was getting cut off.

Now we're into the 1400 lines of code.

So that was pretty simple edit, we'll accept it, but it changes the graph and you can watch cursor modifying files

and then it's popping up and the graph topology is evolving.

So here's free energy principle.

And these gray nodes are all hypothetical links.

So they're linked kind of in a preemptive way.

We can turn on to just existing files if we want to look at the more dense weaving of, okay, well, how about variational calculus?

This comes up like all the time.

All right.

Here we have different math, different examples, different applications of variational inference.

And these on a line by line basis can be vetted in different ways and researched by different individuals.

So if it were like tags, I'll add a tag, whatever it is.

And then that can be versioned.

And if people disagree, they can use the other version of the plain text file.

Hey, Andrew, yeah, there's going to be some really fun applications here.

Okay, so let's now go to the agenda.

So free energy principle article, just briefly, also super long article with all of this machine readable information.

we're going to explore, explore a bunch of fun plain text and that change.

So here's where we are.

Here's stream 10 connected to active and FEP.

And then when we delete this line, it disconnects.

Um,

Briefly going to go through the doc part of the repo to show a little bit of the meta structure on the cognitive repo.

And then we're going to get into POMDPs, partially observable Markov decision processes, our favorite kind of Drosophila model creature for active inference and ants and biofirms and more.

Oh brother.

So here we go.

First into the

This config folder looks empty.

Could have been, it's a simulation config.

We'll leave it there for now.

Maybe it's not even important.

Okay, here's a documentation roadmap.

Here it is in cursor.

Here's documentation in Obsidian and a README for the documentation.

Some of this might seem like overkill.

However, as long as it's accurate and gives linking valid structure, this is incredibly effective with Cursor and Composer.

So first API, that's not really being used at this point, but there's a lot of discussion around agent APIs.

And so having these comprehensively linked versions of files in plain text, super powerful, but not really going to come into play here.

Concepts, this is just documentation for concepts.

So that are relevant for the package, but not scientific concepts per se, more like concepts that are relevant for the documentation at a meta level.

So that when we say, well, we're really interested in machine readability, that kind of semantics is going to get across just fine.

But if we provide a ton of linking,

so that machine readability is a full knowledge node, then it can be even more effective and it can have these mermaid diagrams.

So then when we're giving a talk and we're going, well, free energy principle, we want to have reproducibility and research integrity.

And that's why we're studying this cognitive phenomena with machine readability.

Those are just paths just around the horn, six, four, three, double play.

examples these are some examples of documentation again it's really not the most exciting afternoon reading per se but it gets really far with helping cursor guides these are guides for different micro standard operating protocols for cursor and agents and these can be taken out to extreme levels of intensity so again

It could be followed by a person, or it can just be used with these absurd levels of hierarchical dispatch.

Research.

Here's an example of a research plan that was written for the ant colony simulation that we might look at later.

Templates.

These are template for different folders of the knowledge base repo component.

that we'll go to in a second, and then tools.

So here's some hints for cursor and the cursor files information

that help development in this augmented niche.

And it can be used also to list other autonomous AI tooling.

So it could be like search literature database or drive numerical belief from natural language.

Any of these things that people have been exploring for years and also using Obsidian.

So let's just make that file longer.

Obsidian usage, make this Obsidian

use file much comprehensively longer and with some relevant linked files, make them fully.

So this is using the agent mode, which right now only exists for the Claude family, I believe.

However, we may expect and prefer not so long when many of these models from the OpenAI family, from the Google, from various other labs,

are useful and integration with local language models, all these kinds of things are more and more useful and possible every day.

So I'm in the slow usage tier in the slow lane right now because of what has been happening over the last several days.

We'll just let that cook.

Maybe it'll make some changes while we're looking at it, but let's carry on for now.

Okay.

That was just the documentation folder.

structured approaches for building documentation and advancing documentation from any current state and forensically reconstructing documentation.

These are some truly incredible opportunities.

Okay.

Now we get into the knowledge base itself.

Things is where we're going to see the active inference models, but I want to walk through these top sections because they're really fun.

Okay.

Let's go over to systems theory.

So here's systems theory.

We can see already that it's going to link to cognitive phenomena.

It's going to link to swarm intelligence.

It's going to link to an index file.

So here's a short linker article on systems theory.

And we can follow some of these links, like how about information theory?

And we can follow this all written iteratively through cursor and every single line could be checked.

There could be a person, there could be any number of other approaches.

Here's what the Obsidian update is doing.

So it's like, okay.

And it gets it that we're within an Obsidian repo.

So here now it's updating the Obsidian documentation for itself.

There's probably some points of diminishing return, but it just wrote several hundred lines.

And then now it's going, okay, well, let's make a new linked file for network analysis.

So here it created this whole new file for network analysis, very, of course, meta, since this is what's happening over here.

And that can be done in multiple different maneuvers

by one press here so these are new articles that it's writing okay back to the knowledge base here are the different areas citations i've left empty citation format and bringing in full text that's a whole nother topic not not for this repo this time

there's agents, which is documentation on specific agents.

So here it's a full article, O and S space, O I added just manually as an example of one that we can

uh build right now s space this is a whole article with linkages on s latent state or hidden state so we can have mega connections with the active inference ontology and this helps entrench different understandings so that when it's like a matrix here's exactly what the structure is this is a repeat giving multiple explanations so

It is wild times.

For years, it's like, well, what really is the A matrix?

Or what is the, or how are different ways to write it?

Or what letter should we use?

Or what's the most interesting?

It's like, we're kind of in a position now where it's more about the underlying

entrenchment of understanding plus perhaps we could say the crystallized or classically modified understanding of each of these variables and then the more fluid situational and contextual deployment of these structures so let's have the o space article get written

So in agents, generic POMDP, O space.

Here, write the O space article fully about the observation space.

Okay.

So now we're looking at this graphical relational matrix

describing the knowledge network describing a POMDP structure.

So here in the POMDP structure, it's like, hey, when I say POMDP, these are the components that I mean.

So OSpace was empty, it's still getting written, but we're going to see the graph structure change.

Let's see if we can catch it live changing.

Now OSpace has been written,

234 lines so it relates to all these other topics so there's like a two-way mapping okay i guess observation it does relate to this concept of observation structure should we have an extensive human human experience debating whether or not observation structure should be its own page or this page or that page or the first slide in your presentation or this or that it's like maybe not

but having it as a hypothetical node that we can continue to unpack iteratively and crawl through, it's another level and type of post Wikipedia knowledge engineering.

But maybe bringing back the relevance for Wiki and plain text collaborative design tools as well.

So here we are in O,

Now we can see the structure of the POMDP fleshing out.

So we were looking through the generic POMDP documentations, like levels of documentation that I don't even know have been seen for some of these topics, because we can always just go into a given matrix, vastly expand the comprehensive article on B matrix.

These are the kinds of thrilling articles that I'm sure many of the listeners and viewers and live chatters love to write in their spare time.

But now we are getting assistance with writing these fun articles.

Let's look at the B matrix.

And it's going to be evolving its topology.

So that's the POMDP.

We also have continuous time agent that we'll get to.

Citations, again, there's none at this point.

Cognitive.

Cognitive, there's a variety of cognitive mechanisms or cognitive phenomena.

This is very similar to the work we did in the Atlas project at CogSec related to pattern languages for cognitive phenomena.

So here...

the cognitive phenomena so here's the improved extended article on the b matrix so there's more connections to computational topics more connections to how we like to see it implemented more math foundations and then someone can spin it however they want like you know the classic write the who's on first

to understand the B matrix from a perspective where I don't know much math past middle school.

So custom generative multi-language, multimodal educational materials is in the game.

Updates, push it to GitHub.

So it interpreted that perhaps because of the previous context with writing a new knowledge format.

So it's going to write a new document called bmatrixbasics.

So we'll see what it comes up with there.

Cognitive phenomena.

Let's see it in cursor.

Cognitive phenomena.

Here we'll use control K so we can do inline coding.

We'll say vastly add

phenomena to this list.

Here's bmatrix basics.

Here could be matrix basics.

Fun, relatable blogs of any format to work through and ask about.

Back in the cognitive phenomena world, still in slow request lane, but we have 500

lines of cognitive phenomena some of them we already have nodes pages for others we don't but you could imagine iteratively applying prompts where there is a page with no information please write that comprehensively vastly excellently professionally etc so that'll update cognitive phenomena um but back to the cognitive phenomena folder we have all these

kind of like, here's an empty one, but all of these on demand articles.

So almost surely trained on a variety of articles about ants and collective behavior, for example.

But at the same time, this is coming up with machine-readable schema and ontologies that you could have all the myrmecologists in the world in a room and what they know of might come up with a very high correlation of these terms.

And then it's always possible to just add more terms.

If someone says, well, it's like, well, they really came up with a new term that should go here.

And then that's where you can just add the new term directly and then build on the page.

And then you have the page template and then it links to the documentation and so on.

So cognitive phenomena, just a bunch of times I iteratively applied a few prompts

just to get it to make these kind of Wiki-style articles on all these different topics, whether more as a linker, which is good for making like a beachhead into a new epistemic frontier, or a more advanced article that has visualizations.

I think for the Cognitive Phenomenal one, I was just interested to get it to link as much as possible, which is why it has this list format.

But then you say,

For every single bullet point, expand that section so that it has three sentences.

And then next prompt.

Every sentence, split it to reify the main point with an example.

That's the cognitive section.

Okay, mathematics.

So here, it's pretty fun because the LaTeX rendering is so nice.

We can look at belief updating, math, code, connections.

How about compute expected free energy?

Well, here's the definition of expected free energy in terms of epistemic value and pragmatic value.

So we have this more wiki documentation page, but then when in the active inference page, it says it's going to use expected free energy.

And then that is linked strongly to the expected free energy page.

And here's what we expect from expected free energy.

So then when I prompt somewhere else, something like make an active inference model or make an active inference POMDP model of this or that situation, these highways and byways are right there to trace it back to where we have a human interpretable

versionable document.

So again, the era of like, what is the best way to convey expected free energy?

It's like after what's happened in the last 48 hours, in my experience, I would say in plain text, accurately, coherently, professionally, et cetera.

And then with this generative layer around it,

that is able to recognize the query and then connect it to what's relevant to generate.

But if we just dip our ladle into a given LLM and say what is expected free energy, it might give us a totally valid response.

It might give us a semi-memorized response from a paper.

It might come to a emergent synthetic definition from several papers, finding a semantic interpolation that might be a better version.

So it's not that anything else that's not what I'm showing here is ineffective.

It's that if someone's like, I like this notation system, or this should be included, we can just very modularly put that right into the plain text.

So then if we want it explained and say,

Explain this for me as a enthusiast of topic X. Maybe it'll make a new file.

We'll just see if it gives a funny shout.

Just, you know, what does it even think these symbols mean?

I don't know.

All of us are learning.

But again, these are linked topics.

And so I was...

just studying and learning, going, okay, well, okay, so free energy, okay, we can ask.

It could be in here.

Add a section conveying at a big technical picture level what makes something a free energy.

Who hasn't had that question?

So we just keep adding information.

So a B matrix enthusiast.

Whoa.

Okay.

Let's look at the B matrix enthusiast briefly.

That is in the generic POMDP guides as it basically should be.

Here's the basics.

Here's the who's on first style blog, not dialogue.

And then here's the B matrix enthusiast.

If you've ever been fascinated by how things change over time, whether it's weather patterns, stock markets, or even your favorite video game characters movement, you're already thinking about state transitions.

The B matrix is a powerful tool that helps us understand and predict these changes.

Why it's cool.

And then it's like, it is so cool.

Each of these topics really is so cool.

And we move around them, through them, in them, on them, all that.

We could write all the rest of the generic POMDP enthusiast.

files comprehensively, fully, and lightheartedly.

It probably doesn't even need the accurate information to be also in the Obsidian repo, but it's like, if this is the stuff that we've already looked at, then it definitely doesn't hurt.

And then it's on the cognitive repo.

Anyone can just download this repo

as well as make their own, all of this, open source, great times, and then supercharge their own LLM use so that if we say make a who's on first dialog about an elephant that is using a B matrix to build a bridge, but if we already have elephant B matrix build a bridge,

who's on first as their own nodes in a graph, then it's just gonna be so much better and so much more reproducible.

Observation space.

It's like, how cool and fun.

Okay, back to the repo, then we'll get through these guides and into the simulation section.

So again, these are like on-demand learning articles

that can't be necessarily taken at 100% accuracy.

However, the same could be said for any documents.

And these have the ability to just interactively make diagrams, links.

So for example, the path integral work.

This is some recent work in Active Inference and FEP that no one is born doing.

So how can we learn this?

Well, there's going into a search engine and trying to find documents based upon backlinking or semantic similarity, and then reading the primary words that were on that page.

There's trying to find a textbook.

Maybe you have physical access.

Maybe you have digital access.

Or we can kind of spin out a neighborhood, like I did several times next to the path integral.

So connect path integral to the FEP.

and then okay well it's in plain text here but I think if it were clearly linked there just little nano edit I didn't even have to know about the path integral didn't have to write the paper but just that's a little modular edit that changes the topology of the network that

helps everyone learn and apply all these topics.

So it's like, or what is an action principle?

These are just things that can be asked in.

So here's the O space enthusiast.

Okay, it wrote A, S, and O.

Here's what makes something a free energy.

So interestingly, this is a common error.

It also deletes a bunch.

Rest of content remains unchanged.

So we'll reject that edit.

But some of these things are just little, little road bumps on the speed run.

Here's the cognitive phenomena.

We said add phenomena to the list.

Okay.

Again, here's a long edit that it, the control K mode does that sometimes.

So look for that.

But these ones, we just added dozens of articles.

And then we can have an iterative prompt or an iterative script that says, go to cognitive phenomena, check to see if the linked file is comprehensively written, make it better, use an internet search or use your local information thoughtfully, whatever it happens to be.

And you're just expanding your knowledge base, which you can start from scratch, or you could pull what is in this repo already.

Okay, so that's the math learning component.

How is the Taylor series related to the continuous time agents operation in generalized coordinates?

Also something that many have wondered.

These are specific questions that it's like, okay, that was a question about Taylor series expansion, generalized coordinates, continuous time active inference agents.

Those are

on one hand, big lifts initially, but on the other hand, they fit so nicely into our working memory and certainly into the context window of these synthetic intelligence artifacts.

So we can ask those questions either directly.

Let's ask that exact question in a new Composer window and see what happens.

How does a

How does a continuous time agent in Active Inference use Taylor series expansion for

navigation and intelligence in generalized coordinates that question could also just be typed into or spoken to any other llm interface but here first off we could be working totally offline and locally

with a local LLM and these plain text open source files, or we can be using whatever it is that's happening here.

So again, just like, what are we uncertain about?

What are we curious about?

What would be learning and on the edge for us?

And then metacognition, we state that.

That's an action coming from us.

And then write it.

Don't just let that uncertainty dissipate.

And then like, okay, I have this reflex, like it looks hard.

This looks like it's going to be hard to read and learn.

So at that point, it's like, is this a lift that I'm ready to make at this nano moment?

Am I ready to read about this?

Or is it like good enough to know that there is an answer and maybe dump it into a text file for later?

Or maybe I'm still struggling with this.

Can it be made into a who's on first style dialogue, etc.

?

so that's the math uh and that's the knowledge base part so this could contain summaries or semantic embeddings or full texts for different citations and different resources here i just did totally ab initio from nothing of all of these articles related to fun topics okay moving on past the knowledge base

Here we get into the SRC or source file.

Here is where we can start to explore reliable dis-intermediated calling of abstractions for operational approaches to active inference systems engineering.

So this is a dispatch.

It's kind of like calling operator.

Let's see it in cursor.

Okay.

Here, we're looking at the Active Inference Dispatcher.

First, let's just look over in the graphical view.

What's the neighborhood of the Active Inference Dispatcher?

So these are just some related topics.

Okay, what the active inference dispatcher does is it picks up at the linguistic semantics of the active inference ontology and then creates runners through dispatch that send off to implementational methods.

So if we say, I want to have an agent that uses variational free energy on perception for updated sensemaking.

And then you can imagine whether we ask or state or it asks us, it's like, okay, let's do a binary state space.

So it could be zeros or ones coming in for observations.

And then later we want to add or change that to be in a continuous state space, like between zero and one, but also for those continuous values.

We would still want to be able to use the semantic dispatch

of variational free energy, but under the hood, it's doing a different kind of implementation because of it, for example, being continuous versus discrete.

So that's what this dispatch intermediation is doing.

And similarly, like for the bio firm, this is a canvas.

This is a nice feature of Obsidian.

Take whole articles and lay them out like this, as well as link them to non-articles.

Similarly for the bio firm in the dispatch.

Here is kind of like an interface between the high level semantics, qualitative, linguistic, and specific opinionations and routes for lower level implementations.

Someone says, I want a red adaptive, funny sedan.

Someone doesn't need to say, what is the chemistry of the red paint such that it has this wavelength of light under it?

It's just like, well, we could list out multiple options or one option.

Or you could just hard code and say, oh, when people say red, they mean this exact kind of iron oxide.

You could.

You might not be wrong in a given situation.

You might not be wrong in a whole variety of situations, but...

it's not the most general systems design approach.

So these SRC files are like a repo of tools that we want to use

four different kinds of methods that come into play, like matrix operations.

So then there can be a matrix operation like transpose matrix.

And let's just say that there's two methods at our disposal and one of them works well for small matrices and one if it's a big one.

So then in the outside of the SRC folder at the semantic level,

someone can say, transpose this matrix at this point in the program's logic.

And then the dispatcher sends that to whichever implementation is most relevant, given some other criteria.

So that's a little bit of a stub folder.

It's not a ton in there, but the dispatch concept is going to be critical, and it's an example of something that's enabled by the Active Inference Ontology.

Okay, templates, agent template, belief templates, these allow a variety of things.

Again, they're just examples of templates, but since the nodes in Obsidian being plain text files can also be anything, templates can be wildly useful because then they're used for so many things.

Okay, now let's get into some of the code sections for tests.

All right.

So Obsidian, maybe there's some way to configure it differently.

I just don't have set up right now, but it doesn't display Python files.

So here we can see that in the tests folder and in the GitHub repo, all the files are there, but Obsidian focuses on the markdown.

So pros and cons to that, but it's all good.

Let's...

open it and see what this does.

Okay, this is a test suite.

Okay, made some errors.

Start a new Compose window and while it's fixing that, let's look at the outputs.

So these are some package level tests.

Just doing some matrix visualizations

different kinds of simple visualizations and analyses.

So not super complex, but the testing framework is actually slightly more complex than that.

So it can be used in a variety of ways.

All right, now we get into the things.

This is exciting because

It also is pleasantly surprising truly how rapidly and absurdly some of these programming capacities are advancing.

So I'm going to start with possibly the most useful of the things here, which is the generic POMDP while it's fixing the tests over there.

Also in the settings, there's YOLO mode.

where you can allow the commands to be run.

So here it's both able to propose and then run and then get the terminal feedback and then continue to iterate in this closed loop.

So the agent mode is like an order of magnitude or more faster and now it finished all the tests.

Great.

Here's what we did.

But that might've taken me several key presses.

I know, I know.

Several key presses to get to even that.

And maybe I would have said something in between that would have stymied it.

Or maybe there was a place where it gets itself into a cul-de-sac and I could have come into play.

But suffice to say in this situation for doing a hierarchical debug on the testing infrastructure for a whole package,

I would not have been able to do that with just one click, even in cursor a couple of weeks ago, probably.

Okay, let's go to the generic POMDP.

So this is an example of using generalized notation notation, GNN, for specification, rendering, implementation, execution, analysis, visualization of active inference generative models.

This is building in a very fun way on the work with Jakob from several years ago and a lot of contributions and questions people have had since for making these

obvious, either manually crafted or LLM based transformations of specifications into plain text formats that we can then render different kinds of models from.

So here up top,

The lower parts, some of them are not used at this stage in this version that I'm putting out.

Others are used to specify visualizations.

So this is kind of like a whole generative model level config, like learning parameters, inference parameters.

But the minimal config stuff is up at the top, which is the state spaces.

So here we have, and this gets back to our O space enjoyer, B matrix enthusiast, and so on.

We are stating the number of discrete options for observations, O space,

the number of discrete latent spaces how many actions at each time step the agent has how many total time steps the simulation is going to run for the planning horizon for the simulation which is how many time scales is the agent going to combinatorically do policy proposals for um and some other features so where this is going to go and then we'll run it is here's the the plots

So here's an overview of our agents.

Here's a five by four A matrix up on the top left.

Here's just one action from the B matrix, but we can look at the whole B matrix, three actions.

These are the B matrices for each of those three actions.

Pick like a slice.

C, just in this visualization, it's through time, like time step zero, one, two, three, four.

because I did have preference learning fully operative and wanted to prune it back to simplify it just a little bit.

So now it can graph C preferences through time, constraints, costs, but it's fixed through time.

D is our prior on those four hidden states.

So that's flat.

And then E, our prior on policy, and that's initially flat.

Okay.

So these are just the sub components

different outputs from different belief updating through the 10, the action distributions.

But the visualization that is new even to how I've seen what it could output in the last several weeks is here, we're looking at three affordances per time step.

And then we have the pragmatic and epistemic components, which are the expected free energy, hashtag look at that article, playing out through each of the time steps.

So here's a four planning horizon.

And this is like, do you go low, medium, or high?

And then here's low, low, low, low.

Here's low, medium, high, low.

So let's run it.

So in other words, this is the whole policy tree rollout for a generic POMDP planner just from using generalized notation to notation in a well-structured niche with some of these open source components, not even using PyMDP or any other kind of technique.

So let's make a new generic POMDP.

Let's do...

six observations projecting onto three latent states with two actions for 15 time steps with a planning horizon of five.

Okay, here, first, what it does is it does a sequential test suite.

where it starts a testing session using the testing infrastructure.

Then it goes through and logs these sub fully realized models.

Like let's build the matrix and test the size.

Let's build it, test the size, visualize it.

And so this helps iteratively building and coding as well.

Or let's just do one belief update and then see if it went the direction we thought it was going to go.

now it runs through and now it's running the full pomdp and then it's going to be outputting so previously there was um five four and three five observations four latent states three affordances which is why we saw that trifurcation in the policy rollout visualizations now

Here, here we see policy bifurcation because there's two affordances per time step.

So here we have low and high.

We have low, low, low, high, low.

And so this is a way to see the expected free energy and the components of expected free energy for a whole policy tree rollout.

I don't know if that has been done even of a few weeks ago.

And as kind of expected, the ambiguity rises, at least in how this is visualized.

So that took 76 seconds.

for running this testing suite that ran an informative sequence of events that began with just testing whether the machinery was in order, then went on through building some of the sub-componentry, operating them for short periods of time, and then working its way up to ultimately something that is

outrageously useful for the active inference, which is holographic representations of policy tree rollouts with defined epistemic and pragmatic value components and their balance.

So that's a generic POMDP.

And then to not leave Obsidian out in the cold, here's the README

Here the README is written like software style, but we could improve it like that.

So then we have a clear link going from, well, here's the README for how the POMDB is applied in that folder.

And then here's the bigger concept, A matrix.

It's like, what about the A matrix?

Oh yeah.

It defines the mapping between hidden states, the S space and observations, the O space.

What's the S space?

Oh yeah, it looks like that.

So it is just tracing around all of these different

aspects of the total semantic space but we've juxtaposed here docs which are the ultra-implementational or meta-implementational examples and concepts for this repo as repo then there's the knowledge base ranging from the statistical mathematical foundations on through the agent level documentation

and including both technical definitions like what is a b matrix technical as you want it to get and then what is an educational curriculum for every single possible of this for every single possible of that and then through the src dispatch center we can have these implementations

that can be used in a super standalone way or in a really integrated way.

So let's just look at a few of the other implementations.

This is also a kind of generative model that I've never built before.

And it's in the continuous time setting.

Okay.

So this one, we're in the continuous time setting and let's get the test started.

So running the test suite in the continuous time setting, let's see what it looks like over in Obsidian.

Okay, here's the continuous generic model.

So just like that generic POMDP was for discrete time, discrete state spaces, partially observable Markov decision processes, generalizations including planning, and other cognitive phenomena, hashtag cognitive phenomena, here is continuous time, continuous state space, active inference agents.

The agent learns and operates in continuous domains using modern deep learning techniques while adhering to active inference principles.

So it's going to have these techniques.

And again, because it was in a little code corner,

The README reads more like a GitHub README than a Obsidian, but we can quickly evolve that by saying, also write a mega Obsidian style, densely linked, comprehensive, continuous time model here, connecting to, and I'll just drag in docs, a whole folder and knowledge base.

So let's see what it writes there.

But meanwhile, back in the test lands.

So initialization, shift operation, sensory mapping, just the perceptual sense-making elements of the continuous time situation.

Then one time step of Taylor series expansion, one free energy computation, one belief consistency check, and then several more sophisticated

tests leading on through ultimately to Taylor expansions in generalized state space.

So here the model has, I'll just pick some random variables.

This might slow down the computation vastly.

Two latent states, three observations, four orders for the generalized coordinates, 0.01 time step for integration,

Let's rerun the tests.

So that took 94 seconds to run the test suite with that previous one.

So meanwhile, over in continuous time active inference.

So here's the Obsidian style article that it wrote on what we asked it to write about.

So let's check out the neighborhood of that article.

Here's our big knowledge network and see if we can find, and there's the red dot.

So here's continuous time active inference, and here's how it's obsidian linked to all these topics.

Continuous time active inference, free energy principle.

Okay, all right, now we'll start the tests.

But meanwhile, let's look at the outputs from the previous continuous time testing.

Okay, I'm not even sure what these may yield.

Okay.

Some pre-flight checks on sensory mapping.

How accurate was just our input versus output?

Was there even the right correlation direction for sensory mapping?

Shift operate.

I don't know what these numbers mean in the JSON format, but you can ask, please improve the tests.

of continuous time agents to yield many more visualizations.

But while we're looking at the previous versions of the code,

phase space predictions now maybe this was just when when there was only one or two orders for the model we could have just been fitting free energy generalized coordinates to a point which might be overkill maybe we could have just identified the point but some of these visualizations like being able to identify the gradient following and the solenoidal isocontour following

in a continuous face space.

Okay, this GIF looks like it opened for a second though.

It was just showing, well, let's see.

Okay, that took 104 seconds.

So we slightly, there's this GIF.

It was being rewritten while we were looking at it.

Okay, so maybe it was just a weird corner of state space.

Maybe there's some misimplementation of something.

Maybe it doesn't, but you know,

We're in the ballpark.

Harmonic motion.

Okay.

Maneuvers in state and phase spaces.

And Taylor series expansions.

So this looks like it's doing a two order expansion with a position, which is like the first moment of a Taylor series.

And then the first derivative, the velocity.

And again, maybe these numbers are hard coded.

Maybe the implementation is not perfect.

Maybe it's not general, c'est la vie, so on.

But the infrastructure is in place for building these things.

Okay, now the test suite has been graciously added with these several hundred lines.

We don't even need to type it in.

We could have said, continue to run that by yourself.

Okay, I'm gonna just briefly show the other things, the biofirm and the ant colony, and then open to whatever ideas and questions people have in the chat for which obsidian neighborhood should we build out

which things should we build for coding, like here?

Okay, first, Ant Colony.

This one was almost in one shot.

I just said, write a README and then fully, totally, actually implement an Ant Colony active inference multi-agent simulation.

So the kind of thing that was years of wheel spinning in 2017, 18, 19, 20, 21 is being semi-autonomously one-shotted by just a hope and a dream.

Let's just see what it output.

I don't know if it has run.

Basically, it spins out the schema for a whole multi-agent simulation.

Now, is this going to be compliant with insert your own favorite multi-agent framework?

No, not necessarily.

However, if in the documentation we had a documentation for that and it was linked to multi-agents as one of the ways to do it or the way to do it, then it would be structured that way.

Let's just see if it's already operative.

ant colony.

We'll run setup just to see if it needs that.

Okay, maybe it needs commands.

Let's just see if simulation works.

Okay.

It's running the tests for the continuous generic

case over off to the side but it's like and then already you can see how what i'm doing and showing with only one and a half autonomous agents at any given time it's already like the farmers market local organic low throughput version because why not just have this dispatching truly programmatically without a graphical interface or why not have it um

in any number of other pretty adjacent ways, using the computer operator, using just a headless machine, using just GitHub agents, so many ways to do it.

Okay, so now it is proceeding through the extended test suite with the continuous time setting.

But let's just pivot over to the ant colony to see if we can get some ant GIFs on screen.

ensure that running this really does fully implement the total ant colony simulation yielding sophisticated analysis and many hilarious .gif so we'll see where it gets on the ant colony but meanwhile over in the biofirm land so

BioFirm.

I, in one sentence, summarized our work on the BioFirm project and said, write or read me and then spin out totally according to how it could be, make it happen.

Something like that.

So it's a homeostatic control model, BioFirm, using active inference principles for bioregion management.

This implementation demonstrates how active inference can be used for maintaining system stability through partial observations.

So the biofirm implements a POMDP building copiously off of, of course, the simple and the generic things already in the adjacent folder and all the knowledge docs that we already looked at.

It's gonna use a POMDP to do this bioregional homeostasis.

The model aims to maintain system in homeostatic range by one, making observation from a simplified three-state observation space.

Or we could combine homeostatic bioregional nested stewardship with the generic POMDP.

So then it could be a different observation space, but just to fix it for this current time.

Two, inferring the true underlying five-state environment.

So here, and meanwhile, ant colony autonomous operation ongoing.

Here, there's three observations we're getting.

Like, we're getting high, medium, low from the thermometer.

And then there's five latent states.

So it could be

off one end or off the other end, and then there's also these sort of threshold regions on the lower and the upper bounds.

Or you could have five observations and three latent states.

That's why we need these plain text formats, and that's why we've been developing them for years, because it isn't enough to just say, well, let's put it at three.

Again, you may be more than right in a given situation, but the bigger picture is doing meta parameter sweeping

across configuration spaces for even what one agent's cognitive model is structurally, let alone quantitatively.

So three, the biofirm selects then actions from a set of three, decrease, maintain, or increase to keep the system in the desired state.

So it continues to go through.

Here's some of the technical elements.

Let's read this, read me in...

Obsidian.

So similarly, this one could be enriched with visualizations and all of that, make it a little bit less like a code readme, a little bit more Obsidian formatted.

And what it runs

Let's look at some of the outputs from the biofirm.

Granger causality, transfer entropy on network, convergent cross mapping, not sure what this one would be, causal impact, not sure if it's calculated accurately or in any specific way, but this brings us back to the dispatch operator.

causal impact doesn't just have one formalism.

That's why there was a great work in a live stream with like the 18 different definitions of surprise.

So then all of those can be held up.

And then there's a dispatch that mediates the semantic use of the term surprise.

and might calculate all 18.

Or maybe seven of them only apply to discrete, so if it's continuous, then they're just not going to be calculated.

Or there's some other preference, or you pick a random one, or you pick a different one, or you can pass it as an argument, like which surprise concepts are we working with?

But all of that is only plausible within this space where we have the dis-intermediation of the dispatch caller.

Okay, causal intervention restoration.

We can look at the logic of what these simulations do.

Okay, those look all like the same kind of plots, just with different interventions possibly.

Okay, fractal active inference.

Detrended fractal analysis, DFA analysis.

Hurst exponents, looking at the roughness of a path.

looking at correlation, scale-free correlation dimensions, looking at the fractal power spectrum, intervention management in the fractal setting.

This looks like still mainly in time, but maybe this is spatial.

then here's free energy terms.

Again, maybe today, this isn't exactly the perfect representation or calculation, but already with a self-improving dispatch agents and operator were wildly further than we were a few weeks ago.

Okay, hierarchical active inference, we could say make an obsidian file that represents the topology of the biofirm simulation.

Okay, information interventions on networks.

Let's add like an earth plotting component or something.

But it just okay, that one looked interesting.

So some, some simulation, some oscillatory simulation is happening across three scales, interaction, efficacies, and strengths.

This one could be like a Pokemon character.

We could evaluate like farm works, different kinds of interventions and treatments and contexts.

These are attractor landscapes.

We can dig down.

We said for every single method used in the bio firm, write a mega amazingly linked article with Obsidian format.

Okay, briefly sidebar over with the ants.

So it got 25 calls deep and then cursor, please ping us at hi at cursor.com if you think we should increase this limit.

I would like to imagine the limit being increased.

If you need more tool calls, please give the agent feedback and ask it to continue.

How relatable.

Let's just run it from the terminal again.

Fix this comprehensively.

Okay, so now while Dr. Claude is working on the ants, let's continue with the bioform.

Okay, eigenvalues for stability detection on dynamical landscapes.

Valid, relevant analyses.

Okay.

Looks like a vector field representation.

Are these points accurate?

They look pretty similar, but maybe we were in a configuration set where they went similar.

Okay, and then this is almost at the end of the outputs from the biofirm.

Wow.

If we are to take a plain reading of this, we have heat map coded intensities, blue, low, yellow, high.

Then in four semi-discretized

chapters across these 120 scales through time, there are these repeating diffraction patterns.

Something is happening.

Very optical illusion.

Like it's just a straight line across here, but when I look at it, it looks like a sine wave.

And wavelet power band analyses.

So the kinds of background questions that somebody might have, like how does variational free energy come to matter in this biofirm implementation?

That's a great generative AI direction venture.

And then there's also all of these development, the vibe coding, all these different development directions, like now please do this for this region, or please now I have this many of this sensor and this many of this actuator.

so that's uh where the biofirm got i uh played around with this biofirm specific active dispatcher so let's just take one quick look at what the dispatch looks like here we can use different inference methods so we might want to sample from a distribution but even from the very same distribution we might want to also do a variational belief update

depending on what we had at hand at a moment.

So again, that is where this dispatch, this intermediation comes into play where it lets

a high level understanding of active inference, like reflected by the ontology, be applied through the strong engineering of how the dispatch maps from the ontological semantics on through the implementational pragmatics.

So here are these different dispatch calls

And this is, again, just to keep it local with an Active Inference Dispatch template.

But as more and more things get made and tested and open source explored, you can imagine that in the SRC, it's possible to work out some very generic dispatch methods.

okay so um in the last part of this stream we will sort of half-heartedly see if we can get this mega ant colony simulation going as it continues to spiral and uh self-talk but meanwhile let's

Push GitHub update, take a sip of water, and then if anybody has any questions or ideas, definitely write them in the live chat.

Okay, let's make a new thing.

Path network.

Okay.

Okay, I'll write out the prompt that I eventually want to use.

We'll see if the Ants agent gets where it needs to be in the next minute while writing this prompt.

Then we'll let it finish, and then we'll dispatch this prompt to see if we can one-shot a thing that...

does something so okay see this part of the the zero lag okay milliseconds of lag between applying the edits on a whole folder and then running it again and then instantly picking up with error so that's like where vibe coding is about the vibes for us humans but

It's a different vibe for this operator over here.

So, okay, here we are in path network.

We want a simulation where an arbitrary topology randomly initially generated.

Okay, here we go.

Did we get there with the ants?

25, we hit the limit again.

Do we roll the die one more time?

It's tempting.

Fix this comprehensively and totally run the ant simulation.

Okay, let's let it, just one more.

And then let's write out what we want for the path network.

Meanwhile, though, for anyone watching live, write any ideas or thoughts for what we could do for the obsidian knowledge elements or for some kind of active inference simulation.

We could do anything.

We could front run, we could back run, we could backfill, frontfill, any of those.

We want a simulation where an arbitrary topology randomly initially generated

of nodes reflecting their communicative, effective, causal, mutual influence is generated and simulated.

Each node is a

continuous time, active inference agents.

Different nodes can have different

relations with the same underlying inference methods, for example, difference time deltas of integration, different levels of Taylor series expansion for generalized coordinate coordination,

inference, anticipatory inference.

At a big picture level, it is like there are nested sine waves that are the level of water in the world.

all of the nodes are like ships or towers that are doing this real-time inference on how much to ascend or descend in order to stay with in

tolerable limited range of the overall B level, which floats all boats.

So we're looking for this absolute total simulation.

We know you can do this.

We expect you to do this all in iteratively, thoughtfully, one-shotting this whole issue with initially writing a markdown

obsidian style schema centerpiece and then actually comprehensively proceeding from there given the arc of development outlined in that very same

Initial markdown mega prospectus.

Okay.

And simulation another day.

New agent.

Okay.

Make it happen.

thank you okay here we go all right while that is on slow mode we'll keep watching it from the side

Okay.

So here initially as requested, it first lays out a file structure for this package, sub package, informed package, core components.

Okay.

Continuous time, active inference agent, network topology, environmental dynamics, inference methods.

Okay.

Phase one.

So made the requirements text file.

Now phase one.

Like it is moving quickly through these phases.

Let us briefly return to the live stream top level.

Okay.

We in this agenda did talk about active inference.

We talked about free energy principle a little bit and gave ample cross linkings and applicable strategies for those wanting to model within.

We talked in terms of the things about the continuous generic model and the generic POMDP.

There's also a simple POMDP, which is, let's just quickly look at the output.

This is just for learning the basic POMDP.

This is

a useful learning resource, and it just gives a example of an Active Inference POMDP agent that you can ask questions about and all of that.

It doesn't use any other packages or anything else like that.

And there was the generic one.

Then there was the ant colony simulation that our agent was still repeatedly hitting his head against the wall 25 or more times against.

Then there's the biofirm, which was doing the active inference fractal.

Okay, CodeVis.

Let's do a quick CodeVis with our, we have one free flow.

So, okay.

Okay.

Let's say

Given the totality of the situation, what would you honestly, comprehensively say about the topology and geometry of the package?

OK, we're going to see what colorviz does here.

We talked a lot about the POMDP and the matrices.

Looked at some of the implementations for the matrices.

Talked a little bit about the testing paradigm and the runner and the dispatch operator paradigm.

Practical.

These examples, I guess, are places where it could be applied, but they weren't applied today.

Visualization methods, we saw a bunch of visuals.

Future directions, extended functionality, performance optimization, additional test cases, documentation improvements.

Community engagement, contribution guidelines, issue tracking, feature requests, collaboration opportunities.

Okay.

Repo information, next steps.

references and notes so jump through that okay here's well let's look at first codevis while okay path network looks like it's basically done so let us uh okay it still is generating codevis let's see what happens with

Path network.

Okay.

Okay.

Just running the requirements installation script.

Okay.

Looks like either it's not going to work or it will work.

And the example.

Okay.

Python 3.

Okay.

Okay.

comprehensively continue to fully develop the example so that running that one line in terminal alone fully logs totally and outputs safely all the visualizations.

And okay, Andrew wrote,

Broad intentionally semi vague question.

What do you think about using your repo for generating simulating environments?

You've already spoken on it, but what's next?

What's still obscure?

Good question.

So

It still takes its time.

I think that it will be interesting.

This is not in response to the question, but just obsidian link is the topology of the obsidian network is only strictly which use the obsidian linking the double bracket format.

so that's great it's also slightly different than a hypertext link it's slightly different than other kinds of links that might exist so it's not the only way to link but it's cool that um it's so amenable to cursors creativity and it could be in a more advanced setting flipped out with other

plain text benefits or other linking paradigms.

So just to say that Codeviz, which I am excited for the development of, I believe it offers a contrasting possibilities for structural and topological investigation of complex knowledge bases.

And I'm really curious to see how it goes with their development of labeled edges and some other features, because it could give us these kinds of systems diagrams, hopefully, that would complement different kinds of static analysis and knowledge-based style linking amongst componentry.

So two files might not be...

linked to each other through Obsidian, but they might be very, very related from an actual functional perspective.

So if those kinds of hidden functional relations can be inferred with Codeviz, and then meanwhile, we could use plain text style strategies for knowledge-based linking and change among plain text formats,

It would be wonderful.

Okay.

Let's see where we can get with the path network.

See where we might get with the environment.

And then see if anyone else has funny or interesting ideas from live chat.

Okay.

Okay, looks like now it uses a shell script to run.

Let's just look at it first.

Sets up a Python virtual environment, installs dependencies, runs the simulation.

Let's just see if we can run the simulation by itself.

Okay.

right okay while agent is fixing the simulation yeah generating and simulating environments i think here we have a lot of fun research and work i guess uh my broad intentionally semi-vague question is are we not just talking about the other side of the coin

I mean, single or multi-agent design is like what we've chosen to ladle out from the total scenario.

And if we're going to be talking about what we've ladled out and what we have left unladled,

and we're looking at it from both sides and perspective swapping, then the difference between environmental modeling and agent modeling is going to blur, yet still remain in practice totally precise.

But for Alice and Bob interacting across the interface, whether a third party observer or one or the other asserts themselves to be

the environment or the agent, or they both think they're this one or that one, or they both think the other is that or the other.

I don't think from a category theory slash systems engineering slash Markov blanket perspective, it's going to matter too much implementationally.

So

Rhetorically, or for a given audience or domain, their entire understanding may hinge on what the agent and what the environment is, what scale, what side of the wall, and all that.

However, that wouldn't necessarily break any symmetries regarding the formalism.

OK, and.

Now we're back with the path network.

Clear it.

Run the example.

Okay.

This is a common error.

It will often use a certain visualization backend initially that doesn't work on my computer or doesn't work on Linux or something like that.

And then it figures out, oh, we're going to use this other visualization backend.

But that's where...

having this mega documentation.

So it's like, when I say visualize, here's what I mean by that.

Or when I say, make it like a GIF, here's some good code for doing that.

So then instead of being loosely associatively dipping into the LLM semantic space, there's an in context option for transfer learning, okay?

Let's just roll the die again and run it cleanly.

Thank you for the question, Andrew.

Gomez, thank you for joining.

Appreciate that.

XCQ, thank you.

Hello to you as well.

Okay, let's see what it output.

Wow.

Okay, 15 agents.

Looks like they all converged to this height.

Network topology.

Water level distribution.

So this is the occupancy histogram of what through the simulation's duration, where it was at.

So as those watching live or rewatching can see,

started just a couple minutes ago with that kind of long esoteric-ish prompt and then we just had to one or two times just say fix it and then on the third try we're totally in the game now

Comprehensively improve this, have a configuration file at top level of folder for easy modification, ensure there are many kinds and comprehensive approaches to visualization, including

animations.

That's good.

Okay, XCQ wrote, what's the game?

okay environment as third parent very interesting okay let's look at this config file while path network looks through how it's going to implement it okay we have number of nodes connectivity fraction

weighted connectivity dynamic topology true or false topology update interval then we have by interesting analogy possibly to the micro meso macro three layer nested simulation from the biofirm we have these three nested sine wave components these are like three hierarchical dynamical continuous components and then

total time steps, save intervals, agent parameters.

For a sine wave, Taylor approximation of two might be totally enough because basically just following the gradient.

But then you could imagine, depending on the inertia of the agents,

maybe it can't turn fast enough.

And so that's interesting, like which of the small, medium, and large sine waves will, depending on the delta t, the step integration that each agent does, there's so many interesting dynamics.

Again, so many that kind of the move is these plain text generative formats

because they are wildly deterministically and probabilistically interactive.

Okay.

Let's let it finish its process.

Yeah, it's like detecting what Linux subtype I'm using.

I'll never tell you.

And that might be relevant, but again, plain text, GitHub repo.

Use it or whatever.

Alright, so we'll delete those outputs.

Okay, got some ways along and then maybe it doesn't have this package.

Wow though, yeah, a lot of fun, hopefully useful.

People can go to the doxology cognitive repo

But this is just something that took a few hours over the last several days.

So for those interested in the possibility for collaboration on this through the Active Inference Institute, let's do that in a real repo that's not just many, many sandboxes.

We can copy stuff out.

You can just copy all the Markdown files for Obsidian

and transfer it over, we can set up that knowledge repo and we can organize it in different ways.

So for those who are like, huh, maybe this could accelerate my learning or research.

With the time that you save from that acceleration, maybe consider getting involved or contributing because we can do a lot together and we can de-risk together in ways we couldn't alone either.

So again, if this is interesting or you think like, but I just was looking for a blog that now I see I could just generate locally.

or semi-locally.

If those are interesting or feelings that you have, then I encourage you to collaborate and get involved with Active Inference Institute and community.

Because again, this is just ad hoc

surfing the edge of cursor and my own arbitrary studies but with our own curiosities and expertises we can have some information environments that have never been seen before

So it's taken a kind of virtual environment strategy

I don't know if that's because it's using some graphical visualization method, but again, not to always return to it.

That is where the disintermediation dispatch operator would come into play, is here's what packages I like to use for this, or here's how you set up a virtual environment this way, or in the cursor rules, never set up a virtual environment, always do it this way.

Or install package, or don't install packages, but then install package could be a page.

And then it could be like, here's what install packages looks like in Julia.

Here's what it looks like in Python.

Here's what it looks like in this other language.

And then those kinds of articles,

can just be like, you may search and never find the perfect blog explaining how package installation is similar or different in Go, Julia, and Python.

or choose your fourth one or whatever.

The content might be there.

It might be behind paywalls or never created.

It might be tracking and cookies.

It might be unhealthy in other ways.

It might do all kinds of weird stuff.

Not that what is output from the LLM either should have the instantaneous ring of truth.

However,

It's trained on a lot of that material, and so it gets us far in this plain text setting.

And then if something doesn't work, we'll either know or we won't, or we'll know when we know, and then we can fix it in the plain text format.

Wrapper, okay, let's see.

So just that you can only have one of these composers, but the chat, even though it's very functionally similar, we can do that, so.

Let's make one more random thing.

Let's just do a baseball game.

Here we'll use O3 Mini just to use a different model.

comprehensively write a simulation manifesto for a baseball game active inference simulation this one see this one's now it's downloading torch 766 megabytes so that's where it's it's some overkill is happening so i'm gonna just stop that one but it could happen

plain text, but again, chat and non-Clawed models often output their text like here, which is like, okay, that was, that would have passed for amazing a month ago, but we're in the point where having it in the composer,

Just this is a useful contrast.

So O3Mini in chat, that's the control shift L. It did sort of write this summary and action plan for the baseball simulation manifesto.

But

I think we can expect that the Agent Mode Claw 3.5 is going to be doing a whole lot more.

Okay, X, Z, Q, Z, Q, Z, Y, wrote.

Interesting.

I note that the wrapper is within the hierarchical structure.

Cool.

All right.

With that, I will make a last push.

And then if anybody has any last comments, I'll read them from live chat.

Okay, last push.

There's the repo, ending of the stream.

There's a lot of fun display methods, too.

Or plain text can be processed, and you can use NetworkX, you could use Cytoscape, but the Obsidian one is pretty sweet.

Brief little OBS fractal for the fractal enjoyers.

Okay.

Thank you, Andrew.

Yes, also looking forward to collaborate with the knowledge graph and more.

XCQ, the play happens in the field in which the agent is outside of.

Life is a ballgame.

All right.

Thank you all.

Till the next stream.

Enjoy the repo.

Get involved.

Have fun.

Act in first serve.

Leave a comment.

See what happens in your own hands and more.

Thank you.

Bye.