SPEAKER_00:
It's July 10th, 2023.

This is Daniel Friedman from the Active Inference Institute.

I'm just going to give an example usage of a few things that we did today at the Active Inference Journal with the ChatGPT code interpreter functionality.

so for a little bit of context the active inference journal picks up where the live streams leave off we do speech to text language processing manual automated curation integrating language models always working on publishing pipelines open science and as soon as we saw that we had access to the code interpreter today one thought was to head over to our live stream organizing full data which has a bunch of information on the dates times

types of streams, guests, title of the stream, number of the stream, any associated papers, and some other information.

And we wanted to analyze this information and just get some descriptive statistics and also take it in a few different directions and see where we could go with it.

So here in coda.io table options,

three dots on the upper right, downloaded it as a CSV, and then brought it in to ChatGPT for Code Interpreter.

So I began by asking it to be an expert code interpreter, and then asked for some visualizations by uploading this CSV that had been downloaded from our previous Coda page.

Some description along with a code was provided.

We started with some word cloud visualizations.

Now maybe not the exact visualization that one would want, but could always fine tune it.

So an incredible first start.

Different guests, little bit of a chart needing some tuning, but again, downloadable, presented with code.

I asked for a principal component analysis

And it brought up a suggestion about one hot encoding, but also the caveat that that might not yield meaningful results.

I said, go for it however you see best.

The code was provided.

a PCA was downloadable.

I asked for some information about the semantic loading of what those principal components were associated with, and some caveats and opportunities were raised.

I asked for the language model to just proceed with whatever visualization it thought was best, made a heat map.

However,

unknown has the highest frequency and so i asked for the heat map to be re-visualized without the unknown column and that gave us a lot finer resolution to see which guests were repeatedly in which different live stream series

I asked about which guests are most strongly associated with which streams and to ask for a visualization.

Bar chart was displayed of different guests here with colors across by different types of streams.

Asked for a word cloud of the topics of their streams and the code was provided.

Here, in the initial word clouds, it only used the type of the stream.

So for Chris Fields, we had his course, Physics as Information Processing.

For Avel, we had the ongoing course, Active Inference for the Social Sciences.

For Ander, who's the course assistant.

For Chris Fields, we saw the same information as Chris Fields.

And for Maxwell, who had only ever joined for live stream and guest stream, this was most associated word.

These terms were downloaded and I asked for them to be output more directly.

Again, this kind of sparse cloud.

And so I asked for a correction.

The word cloud should be person specific and based upon the titles of streams they are in.

That's what we discussed, not the stream series.

And so this actually did bring in for some fields

some of those topics that were discussed.

I asked for some general statistical comparisons on the data.

It brought up that a chi-square might be a better first option.

I said go for doing as many chi-squares as your heart desires.

It shows the code from SciPy for chi-squared tests and

a p-value that's in the negative 150 second order of magnitude we have an association between series and guests unsurprising then i took things in a little different direction and asked for a comprehensive professional phd dissertation integrating all the information above

This PhD dissertation proposal was very focused on using live stream data to approach the research process in quite a general scale.

So it was actually a bit too general because I was looking for something a bit more particular, even though this was a great nine chapter proposal.

So I asked for a more technical dissertation that focuses on the theoretical and practical aspects of active inference and the free energy principle.

And so this got a lot closer to where I want to be investigating patterns and dynamics and live stream data through the lens of active inference and the free energy principle.

And so here we begin with some

situational awareness around live streaming as a rapidly growing phenomena and begin to introduce the topic and the reasons why live stream data are useful or at least give us a useful perspective to swap into about active inference some interesting sections so definitely a lot of areas for future work

but natural language is not all, and this visualization capacity looked really powerful.

So I asked for a graphical abstract for that dissertation as a PNG in the browser to make sure that it was going to be visible and not just downloadable.

So here we see a really meta word cloud analysis.

In fact, this is a simple word cloud, but nice kind of summaries of the chapters would be good for presentations.

I asked to make a Bayesian graph that visualizes the core ideas and claims of the dissertation.

In this graph, blue nodes represent the main inputs.

Orange nodes represent the analytical methods used.

Word cloud analysis, PCA analysis, co-occurrence analysis, chi-square test.

So here we have these four analytical methods being used in relationship to free energy principle, active inference, and live stream data, all of it combining into the green node with the findings.

I asked for this Bayesian graph to be re-rendered using the motifs of cybernetic systems like input output relationships, semantic information flows, and hierarchical metacognitive nesting.

And a slightly rearranged graph was displayed.

In an updated graph, live stream data is positioned at the top as the primary input to the system.

Active inference and free energy principle nodes are positioned at the same level, representing parallel foundational concepts.

The analytical methods are positioned in the middle, representing the processing or transformation layer of the system.

The findings node is positioned at the bottom

as the output of the system.

The arrows represent semantic information flows with the direction of the arrow indicating the flow of information or influence.

The graph illustrates the hierarchical nesting of the system and highlights the input-output relationships and flow of information.

So I asked, write an agent-based modeling framework of a sophisticated cognitive agent that engages in an epistemic activity sufficient to generate the kinds of patterns discussed all above.

qualitatively an agent-based modeling framework was provided agent definition environment definition active inference in the free energy principle good coarse-grained communication of the active inference ontology generation of patterns

And of course, I went next to the visualizations and have so many more directions that are probably really fruitful for you and I to explore.

But alas, I reached my current usage cap for GPT-4.

I can continue with the default model now or try again in about an hour.

So I thought I'd make this nice summary video because

even just on a first run this has been highly interesting and i welcome everyone who wants to explore and learn more to get involved at the active inference institute or check out what we're up to in the journal here's some next steps that kind of present themselves following this video

to characterize our journal process and improve our visualization, automation, editing.

So we have a multi-step process at the journal that helps us go from a YouTube live stream on through the audio and markdown editing to translation and rendering and publishing.

So how can we improve this and how can we

work better in language translations and subtitles?

How can we integrate language models and transformer models?

How can we input, process, and output markdown files better?

How can we integrate with DOI, digital object identifier, and DCI publishing affordances?

We already do this through GitHub and Zenodo.

But maybe there's some other ways that we could get some publishing affordances going.

And yeah, we'll look forward to how things develop in this area.

And again, there's a lot of ways to get involved at the journal.

If anything that we've discussed, if any of the topics of the live streams are interesting to you and you want to get involved at the journal,

where we archive and curate and improve those transcripts, make them part of the citable discourse, then we're looking forward to hearing from you.

So, bye.