start	end	speaker	confidence	start time	text from AssemblyAI	corrected text	speaker name	bad phrase	bad phrase	bad phrase
39287	55757	DANIEL FRIEDMAN	0.62	00:39	All right, hello everyone. Welcome. This is ActInf livestream number 51 one. We are in the second discussion of this paper, canonical Neural Networks perform Active Inference. Welcome to the active inference institute.	All right, hello everyone. Welcome. This is ActInf livestream number 51 one. We are in the second discussion of this paper, “Canonical Neural Networks Perform Active Inference. Welcome to the Active Inference Institute.				
55922	104877	Daniel	0.90665	00:55	We're a participatory online institute that is communication, learning and practicing applied active inference. You can find us on this slide and this is recorded in an archived livestream. So please provide us feedback so we can improve our work. All backgrounds and perspectives are welcome and we'll follow good video etiquette for live streams, head over active inference.org to learn more about the institute and how to participate in projects and learning groups. All right, we're in ActInf livestream number 51 one, and having our first nonsolo discussion on this paper, canonical Neural Networks perform active inference and really appreciative that you've joined today.	We're a participatory online institute that is communicating, learning and practicing applied Active Inference. You can find us on this slide and this is recorded in an archived livestream. So please provide us feedback so we can improve our work. All backgrounds and perspectives are welcome and we'll follow good video etiquette for live streams, head over ActiveInference.org to learn more about the institute and how to participate in projects and learning groups. All right, we're in ActInf Livestream number 51 Dot One, and having our first nonsolo discussion on this paper, “Canonical Neural Networks Perform Active Inference, and really appreciative that you've joined today.				
104970	142262	Daniel	0.59279	01:44	It's going to be a great discussion. We'll begin with introductions. I'll say hello and then please just jump in however you'd like. And we can start by setting some context. So I'm Daniel, I'm a researcher in California, and I was interested in this paper because we've been talking a lot about active inference from a variety of different perspectives, from the more fundamental math and physics to some applications, philosophy, embodiment, all these really interesting threads.	It's going to be a great discussion. We'll begin with introductions. I'll say hello and then please just jump in however you'd like. And we can start by setting some context. So I'm Daniel, I'm a researcher in California, and I was interested in this paper because we've been talking a lot about active inference from a variety of different perspectives, from the more fundamental math and physics to some applications, philosophy, embodiment, all these really interesting threads.				
142412	168550	Daniel	0.92	02:22	And this paper seems to make a really clear meaningful contribution and connection by connecting active inference entities and this approach of modeling to neural networks which are in daily use globally. So thought it was a fascinating connection and really appreciate that we can talk about this today. So to you and welcome.	And this paper seems to make a really clear meaningful contribution and connection by connecting active inference entities and this approach of modeling to neural networks which are in daily use globally. So thought it was a fascinating connection and really appreciate that we can talk about this today. So to you and welcome. Go forward, Takuya, however you'd like to introduce and say hello. 				
174375	196370	Daniel	0.97963	02:54	Go forward, Takuya, however you'd like to introduce and say hello. Yeah. Hi. I'm Tafia Isomura, neuroscientist in Lique Brain Science Institute in Japan. I'm particularly interested in universal characterization of neural network and brain using mathematical techniques.	Yeah. Hi. I'm Takua Isomura, neuroscientist in RIKEN Brain Science Institute in Japan. I'm particularly interested in universal characterization of neural network and brain using mathematical techniques.				
196535	224337	TAKUYA ISOMURA	0.65677	03:16	So this work I believe important as a link between active brain forest aspect, Bayesian aspect of the brain, and the dynamics system aspect of the neural network. So I'm very happy to join this discussion session. Thank you for invitation. Nice to meet you. Nice to meet you as well.	So this work is I believe important as a link between active brain formal aspects, Bayesian aspect of the brain, and the dynamics system aspect of the neural network. So I'm very happy to join this discussion session. Thank you for invitation. Nice to meet you. 				
226350	289935	Daniel	0.99	03:46	The first thing you added, the universal characterization of neural networks. What is the universal characterization of neural networks? Why is it being pursued in this area of research? So, as a narrow sense, my gain aim of this paper is that so, you know, people active inference lab communication to characterize brain activity, behavior, so on, so on, but which would be different from conventional neural network. So there is a crossover program which is associated with conventional neural network and it is not very clear whether all characterization of computational neural network can be explained by activity infrastructure principle or not.	Nice to meet you as well. The first thing you added, the universal characterization of neural networks. What is the universal characterization of neural networks? Why is it being pursued in this area of research? So, as a narrow sense, my gain aim of this paper is that so, you know, people active inference lab communication to characterize brain activity, behavior, so on, so on, but which would be different from conventional neural network. So there is a crossover program which is associated with conventional neural network and it is not very clear whether all characterization of computational neural network can be explained by activity infrastructure principle or not.				
290042	342250	Takuya	0.86937	04:50	So here universal characterization means that characterization of every aspect of conventional neural network which is a kind of dynamics system derived as association between biological phenomena and simple mathematics. Car formula using gift card, using differential equations as the broad sense. I think universal characterization means that well, it is a characterization of brain intelligence, but it's a big picture and the paper particular address is only one aspect of the Bull picture.	So here universal characterization means that characterization of every aspect of conventional neural network which is a kind of dynamics system derived as association between biological phenomena and simple mathematics. Car formula using gift card, using differential equations as the broad sense. I think universal characterization means that well, it is a characterization of brain intelligence, but it's a big picture and the paper particular address is only one aspect of the big picture.				
346200	371487	Daniel	0.95	05:46	All right? So it'll be great to pull back to really understand what synthesis is happening. So I'm going to ask what makes a neural network model a neural network model and what makes active inference lab model an active inference model? Is this synthesis and connection you've made true? Because of what?	All right? So it'll be great to pull back to really understand what synthesis is happening. So I'm going to ask what makes a neural network model a neural network model and what makes active inference lab model an active inference model? Is this synthesis and connection you've made true? Because of what?				
374175	422187	Takuya	0.93901	06:14	Because basically what we show is the mathematical equivalence between the formulation of canonical neural networks and the formulation active inference lab in the sense that we show that as possible neural networks can be characterized by minimization of some biological plausible cost function. And we show that that cost function can be least as variational based on inference and a particular cross of gentlemen model in terms of well known partially observable position process.	Because basically what we show is the mathematical equivalence between the formulation of canonical neural networks and the formulation active inference lab in the sense that we show that as possible neural networks can be characterized by minimization of some biological plausible cost function. And we show that that cost function can be least as variational based on inference and a particular cross of gentlemen model in terms of well known partially observable position process.				
426000	447087	Daniel	0.64195	07:06	Alright, shall we perhaps walk through some of the sections of the paper? It would be awesome. Just for each of these sections, maybe the numbered and the lettered sections. What does the section aim to show and why was it there in the paper?	Alright, shall we perhaps walk through some of the sections of the paper? It would be awesome. Just for each of these sections, maybe the numbered and the lettered sections. What does the section aim to show and why was it there in the paper?				
457125	476787	Takuya	0.52315	07:37	Briefly it's over, right? So briefly. So first we introduce so the gain issue main program, our interest, which is relationship.	Briefly it's over, right? So briefly. So first we introduce so the gain issue main program, our interest, which is relationship.				
480975	553895	Takuya	0.61074	08:00	We try to make a formal ring between neural network and active reinforcements that gain program background. And then we first formulate the equivalence, mathematical equivalence, in a very Brea manner. So in the first section in results, we formulate the relationship using complete craft serum, which is well known statistical theorem proposed very long time ago. And using that we link a general form of neural network with a general form of variational data impress. But a problem is that this characterization does not address a specific generative model which is crucial to characterize a specific model, specific neural network dynamics.	We try to make a formal ring between neural network and active reinforcements that gain program background. And then we first formulate the equivalence, mathematical equivalence, in a very Brea manner. So in the first section in results, we formulate the relationship using complete craft serum, which is well known statistical theorem proposed very long time ago. And using that we link a general form of neural network with a general form of variational data impress. But a problem is that this characterization does not address a specific generative model which is crucial to characterize a specific model, specific neural network dynamics.				
553985	589150	Takuya	0.50049	09:13	So in the following sections, we characterize the problem using Pomodb or partially observable Markosition process and link that model with a particular class force canonical neural network. And then we simulated we use the simulation to propagate that property in terms of some major tasks.	So in the following sections, we characterize the problem using Pomodb or partially observable Markosition process and link that model with a particular class force canonical neural network. And then we simulated we use the simulation to propagate that property in terms of some major tasks.				
595000	625015	Daniel	0.94	09:55	All right, thank you for this. Could we talk about the complete class theorem? So what is the scope of the complete class theorem and why was it the relevant set of the neural networks to pursue or the right way to frame it? Thank you for asking that. So I like the slide you showed last week's video.	All right, thank you for this. Could we talk about the complete class theorem? So what is the scope of the complete class theorem and why was it the relevant set of the neural networks to pursue or the right way to frame it? Thank you for asking that. So I like the slide you showed last week's video.				
625182	707940	Takuya	0.47195	10:25	So computer cross theorem basically indicates the relationship between some crossover decision rule and vision in France. Here a crucial keyword is admissible decision rule, which is a rule which is as good as other decision rules or at least at one point better than other decision rules. So simply speaking, adomissibility indicates in some sense it is the best rule for some aspect. And usually we characterize such a goodness using cost function, loss function or risk function. And here what we did is we established some association with this type of loss function or risk function with canonical neural network which is we call cost function or biotic roles Costa function or neural network.	So computer cross theorem basically indicates the relationship between some crossover decision rule and vision in France. Here a crucial keyword is admissible decision rule, which is a rule which is as good as other decision rules or at least at one point better than other decision rules. So simply speaking, adomissibility indicates in some sense it is the best rule for some aspect. And usually we characterize such a goodness using cost function, loss function or risk function. And here what we did is we established some association with this type of loss function or risk function with canonical neural network which is we call cost function or biotic roles Costa function or neural network.				
708120	768350	Takuya	0.56917	11:48	So our assumption is that neural network minimize cost function. So if it active the inclination and it is virusly active some sort of optimality so we can say it is adommissible with respect to that cost function. So the beauty of complete cross theorem is that if we find some admissible decision rule then automatically we can say that it is based on inference in terms of some Bayesian Costa function with gentlemen model a priori beliefs. So this computer chaos theorem is crucial as abstract characterization of the relationship between conventional neural network architecture, dynamics and variational. Beijing influence.	So our assumption is that neural network minimize cost function. So if it active the inclination and it is virusly active some sort of optimality so we can say it is adommissible with respect to that cost function. So the beauty of complete cross theorem is that if we find some admissible decision rule then automatically we can say that it is based on inference in terms of some Bayesian Costa function with gentlemen model a priori beliefs. So this computer chaos theorem is crucial as abstract characterization of the relationship between conventional neural network architecture, dynamics and variational. Beijing influence.				
771650	836175	Daniel	0.49	12:51	All right, thank you. What does it mean when you said it was biologically plausible of a loss function? The term is a little bit arbitrary because in this paper we mean by probability in the sense that this neural network model can be derived from realistic neural model through some approximation. And so here barricade probability, suggest means probability as a neural model or synaptic processing model. And if this cost function loss function can derive such a plausible algorithm, then we can say that this cost function is barely plausible.	All right, thank you. What does it mean when you said it was biologically plausible of a loss function? The term is a little bit arbitrary because in this paper we mean by probability in the sense that this neural network model can be derived from realistic neural model through some approximation. And so here barricade probability, suggest means probability as a neural model or synaptic processing model. And if this cost function loss function can derive such a plausible algorithm, then we can say that this cost function is barely plausible.				
839525	883050	Daniel	0.71853	13:59	So what is the distinction between those neural and synaptic components in the loss function or what equation to look at? You mean distinction between dynamics and synaptic? Yeah. What is the distinction between them and how is it represented in the equations? Okay, basically neuropathivity equation means differentiate equation about a variable that represents firing intensity or some sort of variables associated with the firing.	So what is the distinction between those neural and synaptic components in the loss function or what equation to look at? You mean distinction between dynamics and synaptic? Yeah. What is the distinction between them and how is it represented in the equations? Okay, basically neuropathivity equation means differentiate equation about a variable that represents firing intensity or some sort of variables associated with the firing.				
883625	959625	Takuya	0.9989	14:43	On the other hand, dusty equation means an update rule about the synaptic weight or synaptic strengths which is a connection between two neurons. And beauty of this formulation proposed in this paper is that we characterize both heuristic equations synaptic procedure equations in terms of gradient descent on a same cost function, common cost function. So we can say that if we consider the partial derivative of some cost function with respect to new activity, then it's derived by gradient descent rule about if we consider a partial derivative of chaos function errors with respect to synaptic weights, then we derive a prosthesis rule.	On the other hand, dusty equation means an update rule about the synaptic weight or synaptic strengths which is a connection between two neurons. And beauty of this formulation proposed in this paper is that we characterize both heuristic equations synaptic procedure equations in terms of gradient descent on a same cost function, common cost function. So we can say that if we consider the partial derivative of some cost function with respect to new activity, then it's derived by gradient descent rule about if we consider a partial derivative of chaos function errors with respect to synaptic weights, then we derive a prosthesis rule.				
970187	978312	Daniel	1	16:10	Are those the only two aspects of a neural network or why are those the two key aspects?	Are those the only two aspects of a neural network or why are those the two key aspects?				
980837	1060362	Takuya	0.51	16:20	It is a main, I think it's the main body of the neural activity. If we consider some inference running or action exhibit by neural networks in the sense that neural activity correspond to fast dynamics, fast gradient dynamics mix and scientific processes indicate through dynamics that minimize least function and cost function. But in general, we can consider any aspects, any variables associated with your method. For example, at least what we show in the paper is any free parameter which may be associated with firing threshold or although we don't discuss in this paper it would be possible to add other variables related to neural network. For example, here we ignored contribution of Griad factor but it would be possible to add the Griar factor in this correlation or any other aspect of virus corporate neural network.	It is a main, I think it's the main body of the neural activity. If we consider some inference running or action exhibit by neural networks in the sense that neural activity correspond to fast dynamics, fast gradient dynamics mix and scientific processes indicate through dynamics that minimize least function and cost function. But in general, we can consider any aspects, any variables associated with your method. For example, at least what we show in the paper is any free parameter which may be associated with firing threshold or although we don't discuss in this paper it would be possible to add other variables related to neural network. For example, here we ignored contribution of Griad factor but it would be possible to add the Griar factor in this correlation or any other aspect of virus corporate neural network.				
1064612	1107237	Daniel	0.93201	17:44	That's very interesting and it speaks also to a general separation of time scales. For example in different multi scale systems or in the renormalization group where it's describing some minimal multi time scale system where the faster time scale can be seen as perception like a slower time scale can be seen as more learning like. And then in some hierarchical model what's learning of one time scale can be perceptual for a slower time scale? So it's a very nice generalization.	That's very interesting and it speaks also to a general separation of time scales. For example in different multi scale systems or in the renormalization group where it's describing some minimal multi time scale system where the faster time scale can be seen as perception like a slower time scale can be seen as more learning like. And then in some hierarchical model what's learning of one time scale can be perceptual for a slower time scale? So it's a very nice generalization.				
1112387	1141362	Daniel	1	18:32	Are there any examples of decision rules that will help us think about the action components of what the neural network is doing? Because it may be more familiar to think about digit characterization and image classification, some kind of classical tasks for neural networks. But how does the decision rule play out in the context of neural networks?	Are there any examples of decision rules that will help us think about the action components of what the neural network is doing? Because it may be more familiar to think about digit characterization and image classification, some kind of classical tasks for neural networks. But how does the decision rule play out in the context of neural networks?				
1144187	1167387	Takuya	0.86	19:04	Okay, so in this paper we basically assume a closed loop so comprising a neural network part and environmental part. So Neuron receives sensor input from environment and provide some feedback to the environment.	Okay, so in this paper we basically assume a closed loop so comprising a neural network part and environmental part. So Neuron receives sensor input from environment and provide some feedback to the environment.				
1171787	1222362	Takuya	0.80081	19:31	Even with the example of classification, we can say that output correspond to classification output, which is kind of generative model relevant. Example would be, for example, controlling agent like a robot control or any kind of control errors. Decision making tasks. For example, when we encounter some choice tasks, we need to advertise, for example, left or right or something. Any kind of such a decision can be associated with the admissibility or admissible decision.	Even with the example of classification, we can say that output correspond to classification output, which is kind of generative model relevant. Example would be, for example, controlling agent like a robot control or any kind of control errors. Decision making tasks. For example, when we encounter some choice tasks, we need to advertise, for example, left or right or something. Any kind of such a decision can be associated with the admissibility or admissible decision.				
1227050	1238175	Daniel	0.69648	20:27	So what would an example of an inadmissible or admissible strategy be in the decision making task?	So what would an example of an inadmissible or admissible strategy be in the decision making task?				
1240850	1248962	Takuya	0.33222	20:40	Admissibility usually characterized by loss function or risk function.	Admissibility usually characterized by loss function or risk function.				
1252925	1270500	Takuya	0.67062	20:52	Here admissivity indicates that there is another decision rule which is at least one point better than the forecast decision rule.	Here admissivity indicates that there is another decision rule which is at least one point better than the forecast decision rule.				
1272575	1311000	Takuya	0.54836	21:12	Simply speaking in Adobe CBD indicates that decision rule is not good relatively. Let's just say our decision rule is we always turn right. Is that an example of a decision rule? Because there might be settings where that is strictly effective and the simplest rule whereas there's other settings where that's going to be tragic. So what does it mean to be admissible for an agent in light of different environmental contexts?	Simply speaking in Adobe CBD indicates that decision rule is not good relatively. Let's just say our decision rule is we always turn right. Is that an example of a decision rule? Because there might be settings where that is strictly effective and the simplest rule whereas there's other settings where that's going to be tragic. So what does it mean to be admissible for an agent in light of different environmental contexts?				
1312250	1355625	Takuya	0.58704	21:52	That's an interesting point. So even with such a too much simplified rule it can be admissible under some particular situation, particular loss function. For example, the rulers that always turn right maybe the best under some situation, right? So the relationship of admissibility or enough adommissibility depends on both agent characteristics and environmental characteristics.	That's an interesting point. So even with such a too much simplified rule it can be admissible under some particular situation, particular loss function. For example, the rulers that always turn right maybe the best under some situation, right? So the relationship of admissibility or enough adommissibility depends on both agent characteristics and environmental characteristics.				
1359350	1362300	Daniel	0.99131	22:39	What aspects of the environment.	What aspects of the environment.				
1364975	1389225	Takuya	0.59821	22:44	For example? For example, if that decision group matches the structure architecture of environment then maybe that decision always downright active the shortest past under some situation, some environment.	For example? For example, if that decision group matches the structure architecture of environment then maybe that decision always downright active the shortest past under some situation, some environment.				
1391675	1408500	Daniel	0.95488	23:11	How does this admissibility help us think about like overfitting and how does it help us think about the way that different practices are used for neural networks to prevent them from being over fit in practice?	How does this admissibility help us think about like overfitting and how does it help us think about the way that different practices are used for neural networks to prevent them from being over fit in practice?				
1410725	1424100	Takuya	0.72985	23:30	Well, strictly admissivity is characterized with the Bayesian risk.	Well, strictly admissivity is characterized with the Bayesian risk.				
1430225	1512900	Takuya	0.99197	23:50	We cannot observe a hidden states of the environment, only we can observe is a part of the entire universe. So the question is an important question is what is the best choice under such a limited information? Limited information? So this Bayesian list adoissibility or computer credit theorem tell us that well known, only the well known Bayesian framework achieved the adommissible decision. Which means that in this aspects Bayesian optimization give us a least choice strategy, otherwise we overfit or find the suboptima evolution.	We cannot observe a hidden states of the environment, only we can observe is a part of the entire universe. So the question is an important question is what is the best choice under such a limited information? Limited information? So this Bayesian list adoissibility or computer credit theorem tell us that well known, only the well known Bayesian framework achieved the adommissible decision. Which means that in this aspects Bayesian optimization give us a least choice strategy, otherwise we overfit or find the suboptima evolution.				
1513700	1527662	Takuya	0.84003	25:13	So it's a nice association, nice linkage between the decision, but is a good decision about the decision and more established statistical inference. Freedom work.	So it's a nice association, nice linkage between the decision, but is a good decision about the decision and more established statistical inference. Freedom work.				
1531137	1605752	Daniel	0.93512	25:31	Thank you, that's very helpful. So we're reducing our uncertainty and risk about hidden states in the environment. So in the special case where the entire environment is observable without errors like a chess game, then there's an equivalence between correlation of risk or loss on observables or on hidden states. But they're not really hidden, but they are environmental states. Whereas any amount of uncertainty in the mapping between observations and hidden states, which is usually shown as a in the partially observable Markov decision process, any amount of uncertainty about unobserved or partially observed environmental states enables you to fit your uncertainty optimally about that hidden state and fit that uncertainty simply with the gradient descent.	Thank you, that's very helpful. So we're reducing our uncertainty and risk about hidden states in the environment. So in the special case where the entire environment is observable without errors like a chess game, then there's an equivalence between correlation of risk or loss on observables or on hidden states. But they're not really hidden, but they are environmental states. Whereas any amount of uncertainty in the mapping between observations and hidden states, which is usually shown as a in the partially observable Markov decision process, any amount of uncertainty about unobserved or partially observed environmental states enables you to fit your uncertainty optimally about that hidden state and fit that uncertainty simply with the gradient descent.				
1605932	1636375	Daniel	0.89	26:45	And by doing so, you don't overfit a model of observables, which might be the fallacy or the issue with simply doing descriptive statistics you might get an infinitely small variance with a frequentist estimate because you have 1000 data points. So the variance from a descriptive statistics perspective might be very small.	And by doing so, you don't overfit a model of observables, which might be the fallacy or the issue with simply doing descriptive statistics you might get an infinitely small variance with a frequentist estimate because you have 1000 data points. So the variance from a descriptive statistics perspective might be very small.				
1641012	1671550	Daniel	0.99	27:21	I think it speaks very much to why neural networks are useful in practice from training with limited data sets because that's an empirical observation that they don't entirely over fit. But also I'm sure there's ways to construct them that are overfit. Yeah, overfit will occur if we select some optimal priorities. For example.	I think it speaks very much to why neural networks are useful in practice from training with limited data sets because that's an empirical observation that they don't entirely over fit. But also I'm sure there's ways to construct them that are overfit. Yeah, overfit will occur if we select some optimal priorities. For example.				
1673712	1726857	Takuya	0.71018	27:53	Well, I'm not sure if it is overfit in the sense what you mentioned because if we select some priorities then the Bayesian function itself changes and the neural networks that try to fit to that Costa function. So cost function minimization will be achieved agent such a situation. But that solution is not good for our original help us. That's the tricky part. Yeah, that is reminiscent of some discussions we've had discussing like driving off a cliff or blowing up is also reducing free energy.	Well, I'm not sure if it is overfit in the sense what you mentioned because if we select some priorities then the Bayesian function itself changes and the neural networks that try to fit to that Costa function. So cost function minimization will be achieved agent such a situation. But that solution is not good for our original help us. That's the tricky part. Yeah, that is reminiscent of some discussions we've had discussing like driving off a cliff or blowing up is also reducing free energy.				
1726935	1767902	Daniel	0.90308	28:46	Like dropping up a building reduces your potential energy. And so there are potentially decisionmaking or strategic trajectories that do for some time horizon minimize free energy, perhaps even or maybe even guaranteed better than some longer time horizon. Because if the shortterm strategies were somehow better than the longterm horizon. It would be difficult to imagine because the long term horizon would be at least as good as a shortterm strategy. So that speaks to the challenges of planning in action.	Like dropping up a building reduces your potential energy. And so there are potentially decisionmaking or strategic trajectories that do for some time horizon minimize free energy, perhaps even or maybe even guaranteed better than some longer time horizon. Because if the shortterm strategies were somehow better than the longterm horizon. It would be difficult to imagine because the long term horizon would be at least as good as a shortterm strategy. So that speaks to the challenges of planning in action.				
1768007	1777000	Daniel	0.7137	29:28	So how is planning addressed in modern neural networks and how does this work help us think about that?	So how is planning addressed in modern neural networks and how does this work help us think about that?				
1779837	1783162	Takuya	0.61552	29:39	That's another very important aspect.	That's another very important aspect.				
1785612	1852075	Takuya	1	29:45	I have to say that this framework addresses planning aspect, but that planning is not necessarily the optimal solution in the sense that what we interested in is optimization or learning under limited structure. The structure is characterized by here Prosperia neural networks. So yeah, planning occurred by association between risk in the future and our decision in the past. Here we model that aspects using delayed moderation of scientific activity mediated by some neuromodurator or neurotransmitters. This is the model.	I have to say that this framework addresses planning aspect, but that planning is not necessarily the optimal solution in the sense that what we interested in is optimization or learning under limited structure. The structure is characterized by here Prosperia neural networks. So yeah, planning occurred by association between risk in the future and our decision in the past. Here we model that aspects using delayed moderation of scientific activity mediated by some neuromodurator or neurotransmitters. This is the model.				
1858812	1876837	Takuya	0.81	30:58	This is model as the risk factor and the heavy product holding the neural network.	This is model as the risk factor and the heavy product holding the neural network.				
1881987	1906537	Daniel	0.94	31:21	All right, I'm going to ask a great question from the chat and then we'll look at the figures a little closer. So ML Don wrote a question stuck in my mind for a long time. Could you please put it to rest? Do we need to have knowledge about all states possible actions and sensory inputs for active inference?	All right, I'm going to ask a great question from the chat and then we'll look at the figures a little closer. So ML Don wrote a question stuck in my mind for a long time. Could you please put it to rest? Do we need to have knowledge about all states possible actions and sensory inputs for active inference?				
1910812	1964812	Takuya	0.76562	31:50	Well, you mean if you seek the exact solution, exact optimal solution, then maybe more information would help you to find that. But under some ideal assumptions then the is not necessary to achieve the optimal solution. I'm not sure if I correctly answer your point. So just to restate it. Of course, knowing all the state's possible actions and sensory inputs, it's not a bad thing.	Well, you mean if you seek the exact solution, exact optimal solution, then maybe more information would help you to find that. But under some ideal assumptions then the is not necessary to achieve the optimal solution. I'm not sure if I correctly answer your point. So just to restate it. Of course, knowing all the state's possible actions and sensory inputs, it's not a bad thing.				
1964950	2012225	Daniel	0.87043	32:44	Worst case, there's some computational complexity, trade offs, but the problem becomes fully stateable. But I think ML Dawn is asking about cases where you don't know all of the state spaces or potentially even the dimension or the semantics of hidden states, active states, sensory inputs and why not even add cognitive states? So in not just partially observed but partially known state spaces, how are these address in neural networks and how does active inference help us think about it?	Worst case, there's some computational complexity, trade offs, but the problem becomes fully stateable. But I think ML Dawn is asking about cases where you don't know all of the state spaces or potentially even the dimension or the semantics of hidden states, active states, sensory inputs and why not even add cognitive states? So in not just partially observed but partially known state spaces, how are these address in neural networks and how does active inference help us think about it?				
2017762	2060062	Takuya	0.82	33:37	Okay, I think the question is about how can we separate those states? Like sensory function interface entorhinal, how can. We separate not just in principle have these states be separated, but deal with the fact that some of these states we might have good knowledge on and some states like the hidden states we might not even know, like we don't know the dimension of the cause vector in the world. I see.	Okay, I think the question is about how can we separate those states? Like sensory function interface entorhinal, how can. We separate not just in principle have these states be separated, but deal with the fact that some of these states we might have good knowledge on and some states like the hidden states we might not even know, like we don't know the dimension of the cause vector in the world. I see.				
2062525	2156975	Takuya	0.99	34:22	In terms of dimension, there is a statistical technique to estimate the dimensionality, for example via information criteria like I agent information criteria, based information criteria, all them try to info estimate plausible dimension about the environmental hidden states. There is an analogy with those information criteria and version of free energy minimization. So with version of free energy inclination we can identify the plausible model structure which in principle involves the dimension aspect. But in terms of Neural network in this paper we don't carefully consider about the dimensionality optimization because we first define the number of neurons and don't change during the training. But in principle we can consider the change in the number of neurons which is associated with the neurogenesis adult neurogenesis or development during the developmental stage.	In terms of dimension, there is a statistical technique to estimate the dimensionality, for example via information criteria like I agent information criteria, based information criteria, all them try to info estimate plausible dimension about the environmental hidden states. There is an analogy with those information criteria and version of free energy minimization. So with version of free energy inclination we can identify the plausible model structure which in principle involves the dimension aspect. But in terms of Neural network in this paper we don't carefully consider about the dimensionality optimization because we first define the number of neurons and don't change during the training. But in principle we can consider the change in the number of neurons which is associated with the neurogenesis adult neurogenesis or development during the developmental stage.				
2157475	2166125	Takuya	0.99	35:57	That would be an important expansion of this direction.	That would be an important expansion of this direction.				
2173450	2225350	Daniel	0.59968	36:13	That's very interesting. Here's a remark. Well, one note is equation one summarizes a lot of what you've been describing. There's a parallelism or a concordance being drawn between the loss function of Neural networks and the variational free energy of the parameterized model there. So to come back to these processes that influence learning which we could think of as the Neural network becoming more fit from a loss function perspective or the variational Bayesian partially Observable Markov decision process entity generative model encoding better at doing what it does.	That's very interesting. Here's a remark. Well, one note is equation one summarizes a lot of what you've been describing. There's a parallelism or a concordance being drawn between the loss function of Neural networks and the variational free energy of the parameterized model there. So to come back to these processes that influence learning which we could think of as the Neural network becoming more fit from a loss function perspective or the variational Bayesian partially Observable Markov decision process entity generative model encoding better at doing what it does.				
2225487	2303750	Daniel	0.87628	37:05	So there's the firing rate on the Neural network side, the synaptic plasticity at a slower time scale which we discussed a little earlier. And then now there's a third time scale with the birth and death of new cells and maybe even new layers. And that kind of multiscale temporal structuring is not intrinsic to the Bayes graph to represent multiple nested timescales in a Bayesian graph in the act of inference literature it's more common to make a hierarchically nested model, right? And just say that the time handling on one level is happening more rapidly with respect to clock time than deeper nested, slower models. Whereas the Neural formulation allows us to deal with multiple ongoing active states without appealing to hierarchical nesting, which is a very important feature.	So there's the firing rate on the Neural network side, the synaptic plasticity at a slower time scale which we discussed a little earlier. And then now there's a third time scale with the birth and death of new cells and maybe even new layers. And that kind of multiscale temporal structuring is not intrinsic to the Bayes graph to represent multiple nested timescales in a Bayesian graph in the act of inference literature it's more common to make a hierarchically nested model, right? And just say that the time handling on one level is happening more rapidly with respect to clock time than deeper nested, slower models. Whereas the Neural formulation allows us to deal with multiple ongoing active states without appealing to hierarchical nesting, which is a very important feature.				
2311450	2382787	Takuya	0.65814	38:31	Well, both distinctions will be possible. So without hierarchical or with higher car modeling so even with hierarchical modeling, the optimization of dimensionality should be possible. It would be possible. But in other distinctions we can consider that a population of Neural models so one has a single layer, another has two layers, three layers, four layers. And consider the probability of network architectures associated with Costa minimization and a particular environment which is in principle have the same computational architectures with the hierarchy model.	Well, both distinctions will be possible. So without hierarchical or with higher car modeling so even with hierarchical modeling, the optimization of dimensionality should be possible. It would be possible. But in other distinctions we can consider that a population of Neural models so one has a single layer, another has two layers, three layers, four layers. And consider the probability of network architectures associated with Costa minimization and a particular environment which is in principle have the same computational architectures with the hierarchy model.				
2386800	2440900	Daniel	0.94273	39:46	Very interesting. Yes, perhaps I over generalized or speculated because I thought about how one could have a 100 timestep POMDP that also performs multiscale behavior potentially extremely wastefully, but at least it could in principle. And similarly, within a neuron there could be another Neural network or some other structure approximated by that. So they almost both enable hierarchical and non hierarchical model modeling as you described, but in very different ways that lead to very different implementations.	Very interesting. Yes, perhaps I over generalized or speculated because I thought about how one could have a 100 timestep POMDP that also performs multiscale behavior potentially extremely wastefully, but at least it could in principle. And similarly, within a neuron there could be another Neural network or some other structure approximated by that. So they almost both enable hierarchical and non hierarchical model modeling as you described, but in very different ways that lead to very different implementations.				
2444025	2503212	Takuya	0.79544	40:44	Yes. I think this brings us to the topic of forward and reverse engineering. So you talked a lot about reverse engineering. What is reverse engineering and what is forward engineering and what has been done in these areas of engineering? Okay, I'm not an expert in this process, but I believe that liver here means your characterization of the blueprint of some device or machine from data observable information like activity or action behavior of some agent.	Yes. I think this brings us to the topic of forward and reverse engineering. So you talked a lot about reverse engineering. What is reverse engineering and what is forward engineering and what has been done in these areas of engineering? Okay, I'm not an expert in this process, but I believe that liver here means your characterization of the blueprint of some device or machine from data observable information like activity or action behavior of some agent.				
2504400	2595250	Takuya	0.93846	41:44	Goal is identification of blueprint and the crucially here blueprint correspond to generative models because once we define generative model, we can Deneve evolution, anthropology algorithm, running inference algorithm and any behavior of the agent. So here reverse means that we first observe some activity of agent and its mechanism is still unknown for us, but we can estimate its mechanism using that activity by identifying the most plausible guarantee model which can minimize some Costa function or risk function when we feed the data to the model. So, on the other hand, for the engineering would be more mainstream, way fast defined model blueprint gently model then drive everything including parasite functional running algorithms and behavior action prediction algorithm.	Goal is identification of blueprint and the crucially here blueprint correspond to generative models because once we define generative model, we can Deneve evolution, anthropology algorithm, running inference algorithm and any behavior of the agent. So here reverse means that we first observe some activity of agent and its mechanism is still unknown for us, but we can estimate its mechanism using that activity by identifying the most plausible guarantee model which can minimize some Costa function or risk function when we feed the data to the model. So, on the other hand, for the engineering would be more mainstream, way fast defined model blueprint gently model then drive everything including parasite functional running algorithms and behavior action prediction algorithm.				
2599875	2628250	Daniel	0.85908	43:19	So, by reverse engineering neural networks, we're observing some already parameterized neural network and then fitting a POMDP to it. To what extent is it possible to take a given POMDP and create a neural network that performs that inference?	So, by reverse engineering neural networks, we're observing some already parameterized neural network and then fitting a POMDP to it. To what extent is it possible to take a given POMDP and create a neural network that performs that inference?				
2632875	2761790	Takuya	0.77	43:52	Okay, in this paper or in the following paper, what we consider is a strategy that we first feed empirical data whether force neural response data to BioScale prosper neural network model which is similar to a conventional model fitting approach where we have differential equation data and differential equation to explain the behavior with the minimum prediction. So now, a virtue of this framework we established is that we can naturally transform such neural network architecture with the very known partially observable markup action process architecture. Because for any kind of canonical neural network there is a cost function. So we Deneve cost function through neuroactive decision which is opposite with the conventional way we define cost function derived algorithm and then we use the formal equivalence between neural network Costa function and variant queen energy. So now transform the journal architecture to Beijing model architectures and once we characterize vital energy, there should be some general that define that informational energy functional.	Okay, in this paper or in the following paper, what we consider is a strategy that we first feed empirical data whether force neural response data to BioScale prosper neural network model which is similar to a conventional model fitting approach where we have differential equation data and differential equation to explain the behavior with the minimum prediction. So now, a virtue of this framework we established is that we can naturally transform such neural network architecture with the very known partially observable markup action process architecture. Because for any kind of canonical neural network there is a cost function. So we Deneve cost function through neuroactive decision which is opposite with the conventional way we define cost function derived algorithm and then we use the formal equivalence between neural network Costa function and variant queen energy. So now transform the journal architecture to Beijing model architectures and once we characterize vital energy, there should be some general that define that informational energy functional.				
2761970	2800062	Takuya	0.49666	46:01	So in particular, in this example, canon network nicely correspond to well known across macquarlin process. So, by using this procedure, we identify a plausible home DP architecture which correspond to observed activity data.	So in particular, in this example, canon network nicely correspond to well known across macquarlin process. So, by using this procedure, we identify a plausible home DP architecture which correspond to observed activity data.				
2809337	2855862	Daniel	0.62355	46:49	Well, let's stay on this last point. So, after all those transformations, first the measurements of neurons using that data to fit the neural network and then by virtue of the relationships unpacked in the paper, transforming the neural network in the left side of figure one into a particular form of the P-O-M DP. So first, what are the constraints on that form of the P-O-M DP? Is this a little corner of model space or what are the space of acceptable P-O-M DPS?	Well, let's stay on this last point. So, after all those transformations, first the measurements of neurons using that data to fit the neural network and then by virtue of the relationships unpacked in the paper, transforming the neural network in the left side of figure one into a particular form of the P-O-M DP. So first, what are the constraints on that form of the P-O-M DP? Is this a little corner of model space or what are the space of acceptable P-O-M DPS?				
2858012	2943750	Takuya	0.58	47:38	That totally depends on what kind of neural network model you are considering. So for example, in this paper we discussed about a particular crossover from DP in which each state takes either zero or one. So it's very restricted compared to the general form of homedp. But we consider a factorization so in the sense that although each but we consider a vector of observation, a vector of hidden states where each element correspond to one single one hot vector but as an entire state it can represent high dimension discrete state space. And this architectures nicely correspond to neural network architectures because usually each neuron takes either zero one or some value continuous variable between zero and one.	That totally depends on what kind of neural network model you are considering. So for example, in this paper we discussed about a particular crossover from DP in which each state takes either zero or one. So it's very restricted compared to the general form of homedp. But we consider a factorization so in the sense that although each but we consider a vector of observation, a vector of hidden states where each element correspond to one single one hot vector but as an entire state it can represent high dimension discrete state space. And this architectures nicely correspond to neural network architectures because usually each neuron takes either zero one or some value continuous variable between zero and one.				
2944262	3036600	Takuya	0.69869	49:04	So we use this association to characterize a particular OMDP which correspond to neural networks, and this follows a particular mini field approximation, approximation or approximation in generative model because we associate posterior belief in this particular homo DP with the neural activity, which means that posterior of action also has a factorization architecture in the sense that we don't fully consider about the second order statistics between neurons activity and activity, which is outside of this poem. RASM. So each neuron activity correspond to posterior expectation about a particular element of the state and we don't consider the joint posterior property of all state.	So we use this association to characterize a particular OMDP which correspond to neural networks, and this follows a particular mini field approximation, approximation or approximation in generative model because we associate posterior belief in this particular homo DP with the neural activity, which means that posterior of action also has a factorization architecture in the sense that we don't fully consider about the second order statistics between neurons activity and activity, which is outside of this poem. RASM. So each neuron activity correspond to posterior expectation about a particular element of the state and we don't consider the joint posterior property of all state.				
3040700	3096812	Takuya	0.57342	50:40	So although this is a implication, we see this Asia impress, but otherwise, for example, we can consider any recurrent network architectures which correspond to state to transition metrics and it would be possible to extend this architecture to higher call structure in the sense that it is straightforward. Consider a tree structure or any kind of higher car structure by assumptions that some neurons connect to other neuron but not connect to other neurons. So this is Lamme as considering the higher car structure in general.	So although this is a implication, we see this Asia impress, but otherwise, for example, we can consider any recurrent network architectures which correspond to state to transition metrics and it would be possible to extend this architecture to higher call structure in the sense that it is straightforward. Consider a tree structure or any kind of higher car structure by assumptions that some neurons connect to other neuron but not connect to other neurons. So this is Lamme as considering the higher car structure in general.				
3103675	3168800	Daniel	0.5473	51:43	That's very interesting. It's commonly remarked in the base graphs that they represent the connections amongst random variables and there's a relationship between their computability and their sparsity. The sparsity structure as in which variables do or do not influence each other makes the problem tractable through factorization and just kind of conceptually like if every one of a thousand variables or an unknown number of large variables if it was all by all the number of parameters to fit on that connectivity matrix would be very high. So statistical power would be very low for any given edge. Whereas the more and more constrained you make the connectivity of the variables, the more statistical power you have to resolve or kind of spend on fitting those edges like in a structural equation.	That's very interesting. It's commonly remarked in the base graphs that they represent the connections amongst random variables and there's a relationship between their computability and their sparsity. The sparsity structure as in which variables do or do not influence each other makes the problem tractable through factorization and just kind of conceptually like if every one of a thousand variables or an unknown number of large variables if it was all by all the number of parameters to fit on that connectivity matrix would be very high. So statistical power would be very low for any given edge. Whereas the more and more constrained you make the connectivity of the variables, the more statistical power you have to resolve or kind of spend on fitting those edges like in a structural equation.				
3169300	3265537	Daniel	0.97329	52:49	But you might be losing sight of the unknown unknowns by constraining yourself to a very limited or fallacious topology of the variables. So there's this kind of structure learning statistical inference question in the Bayes graphs then on the neural side from the biological much of neuroscience is about understanding how the firing rate, connectivity patterns and other factors Hohwy the structure of those neural systems and their function like form and function enable adequate inference and inference on action. So it's like in both of those areas or really like in neural network artificial and neural networks and in variational. DAGs the discussion is about how the structure and the fine tuning work together to generate function and about some of the statistical or biological challenges of balancing different needs while also constraining the cost in terms of materials and biometabolism. So it's a very rich interoception that is being explored here.	But you might be losing sight of the unknown unknowns by constraining yourself to a very limited or fallacious topology of the variables. So there's this kind of structure learning statistical inference question in the Bayes graphs then on the neural side from the biological much of neuroscience is about understanding how the firing rate, connectivity patterns and other factors Hohwy the structure of those neural systems and their function like form and function enable adequate inference and inference on action. So it's like in both of those areas or really like in neural network artificial and neural networks and in variational. DAGs the discussion is about how the structure and the fine tuning work together to generate function and about some of the statistical or biological challenges of balancing different needs while also constraining the cost in terms of materials and biometabolism. So it's a very rich interoception that is being explored here.				
3269462	3272787	Daniel	0.94379	54:29	If these models can really be moving back and forth.	If these models can really be moving back and forth.				
3278137	3282587	Takuya	0.77	54:38	In the sense that back and forth.	In the sense that back and forth.				
3285487	3319412	Daniel	0.99858	54:45	Moving back and forth, like there's some imprints of the model that is implementation independent or like some interlingua or some semantics or compatibility, I don't really know. I mean, that's something we can explore is like what is it that is such that one could forward engineer and then reverse engineer and have like kind of an expectation maximization between these two areas. So what is it that's being solved?	Moving back and forth, like there's some imprints of the model that is implementation independent or like some interlingua or some semantics or compatibility, I don't really know. I mean, that's something we can explore is like what is it that is such that one could forward engineer and then reverse engineer and have like kind of an expectation maximization between these two areas. So what is it that's being solved?				
3325087	3426425	Takuya	0.73947	55:25	Yes, important point, for example, about you is that we can use the knowledge of Bayesian inference to explain your activity dynamics, which is crucial because people often say that characterizing neurodynamics is no straightforward, we may obtain some solution on your net dynamics, but the meaning of that dynamics in terms of the functional aspect is very unclear. We don't know the meaning of connectivity strength matrices and what is the learning of the threshold factor, so on and so on those de Vries from the modern physiological phenomena. But it is not necessary to have clear linkage to functional exploration. So explanation of function of the brain. But once we transform translate this dynamics into Bayesian inference, then we can explain every functional aspect of the neural network diagrams architecture in terms of where established Bayesian inference under a particular crossover Bayesian model, in this case palm DP model.	Yes, important point, for example, about you is that we can use the knowledge of Bayesian inference to explain your activity dynamics, which is crucial because people often say that characterizing neurodynamics is no straightforward, we may obtain some solution on your net dynamics, but the meaning of that dynamics in terms of the functional aspect is very unclear. We don't know the meaning of connectivity strength matrices and what is the learning of the threshold factor, so on and so on those de Vries from the modern physiological phenomena. But it is not necessary to have clear linkage to functional exploration. So explanation of function of the brain. But once we transform translate this dynamics into Bayesian inference, then we can explain every functional aspect of the neural network diagrams architecture in terms of where established Bayesian inference under a particular crossover Bayesian model, in this case palm DP model.				
3428287	3457937	Takuya	0.79756	57:08	So now it turns out that synaptic strength correspond to a matrix B matrix, which are very established culture meaning. So yeah, this is useful to explain neuronsynatic property in terms of established statistics.	So now it turns out that synaptic strength correspond to a matrix B matrix, which are very established culture meaning. So yeah, this is useful to explain neuronsynatic property in terms of established statistics.				
3464287	3547175	Takuya	0.96118	57:44	Also, for the people in active inference lab site, it would be helpful to understand the neuronounce master straight about particular active interface model model. So I think it related to forward modeling. But finally to discuss with discuss about the border service rate of that forward model, we need to address the neural network architecture service property. So in that case, we can transform a particular force DP invasion modeling to a neural network architecture using this relationship and then get prediction about the substrate. So if we have this based on model, this particular quantity in this model should be it would be possible using.	Also, for the people in active inference lab site, it would be helpful to understand the neuronounce master straight about particular active interface model model. So I think it related to forward modeling. But finally to discuss with discuss about the border service rate of that forward model, we need to address the neural network architecture service property. So in that case, we can transform a particular force DP invasion modeling to a neural network architecture using this relationship and then get prediction about the substrate. So if we have this based on model, this particular quantity in this model should be it would be possible using.				
3554737	3593412	Daniel	0.68	59:14	Oh, it's all good. Can you just repeat the last 20 seconds? Yes. So in the last part I mentioned about first we define the Bayesian model and then can predict what is the neural net substrates that correspond to that particular Beijing model. So this will be useful to identify the biological quantities that correspond to a quantity in Beijing.	Oh, it's all good. Can you just repeat the last 20 seconds? Yes. So in the last part I mentioned about first we define the Bayesian model and then can predict what is the neural net substrates that correspond to that particular Beijing model. So this will be useful to identify the biological quantities that correspond to a quantity in Beijing.				
3593487	3594125	Takuya	0.36832	59:53	Chaos.	Chaos.				
3603562	3662237	Daniel	0.54383	1:00:03	There's a lot there. It makes me think about the inference of implementation and. Heuristics in the computational setting, which is often in the extreme disembodied, and the biological setting, which is in the extreme entirely embodied. And for a given generative model, the kinds of computational heuristics that can be applied include a whole host of different strategies ranging from sampling to tree exploration and branching to paralyzing the data architectures and all these other kinds of disparate strategies and software packages and implementations.	There's a lot there. It makes me think about the inference of implementation and. Heuristics in the computational setting, which is often in the extreme disembodied, and the biological setting, which is in the extreme entirely embodied. And for a given generative model, the kinds of computational heuristics that can be applied include a whole host of different strategies ranging from sampling to tree exploration and branching to paralyzing the data architectures and all these other kinds of disparate strategies and software packages and implementations.				
3664387	3736550	Daniel	0.96435	1:01:04	But on the biological side, what is needed is something that's very simple but also very inscrutable, which is a given pattern of interactions must embody that calculation. So that might mean that it can add three digit numbers, but it can't add two digit numbers under some constraints. But what isn't accessible to that kind of morphological, biological or like form and functional computing, what's not accessible are the tree branching, the database decentralization, like they're a different set of heuristics. Right. But they're both very useful when we're thinking about making sentience artifacts or benefiting simply from the explainability across both sides of this figure.	But on the biological side, what is needed is something that's very simple but also very inscrutable, which is a given pattern of interactions must embody that calculation. So that might mean that it can add three digit numbers, but it can't add two digit numbers under some constraints. But what isn't accessible to that kind of morphological, biological or like form and functional computing, what's not accessible are the tree branching, the database decentralization, like they're a different set of heuristics. Right. But they're both very useful when we're thinking about making sentience artifacts or benefiting simply from the explainability across both sides of this figure.				
3738562	3775422	Takuya	0.64	1:02:18	Yeah. So you now address an important point. So Homistry, it is very nontrivial whether there is a corresponding valve car architecture force any given Bayesian architectures. I believe it is impossible to design biography architectures to respond to arbitrary Bayesian architectures. So only a limited aspect of region model can be implemented in a vertical plausible manner.	Yeah. So you now address an important point. So Homistry, it is very nontrivial whether there is a corresponding valve car architecture force any given Bayesian architectures. I believe it is impossible to design biography architectures to respond to arbitrary Bayesian architectures. So only a limited aspect of region model can be implemented in a vertical plausible manner.				
3775542	3785237	Takuya	0.85	1:02:55	And that point is crucial as capitalization of biological network. Biological brain.	And that point is crucial as capitalization of biological network. Biological brain.				
3789412	3796112	Takuya	0.61	1:03:09	Yeah. Wow. Well, just to kind of touch again on this forward in reverse engineering.	Yeah. Wow. Well, just to kind of touch again on this forward in reverse engineering.				
3798412	3848000	Takuya	0.55183	1:03:18	For. A given POMDP if we're willing to compose it within a certain class, which might be quite general still, but some class of PMDP, as written. On the paper. We may be able to have a neural network architecture that would be very amenable to deep learning, low energy computing, pretraining various features. And then on the other side, for a given artificial neural network that we come across in the wild or a model of neural dynamics that we fit using a neural network model.	For. A given POMDP if we're willing to compose it within a certain class, which might be quite general still, but some class of PMDP, as written. On the paper. We may be able to have a neural network architecture that would be very amenable to deep learning, low energy computing, pretraining various features. And then on the other side, for a given artificial neural network that we come across in the wild or a model of neural dynamics that we fit using a neural network model.				
3848737	3914122	Daniel	0.8918	1:04:08	So something in a neuroscience laboratory that model can have interpretability corresponding to the variables of a given POMDP. And just to kind of give one more point on how that's going deeper than, for example, statistical parametric mapping SPM. So let's just assume that the neural network we're dealing with is fit from brain data from some lucky Kant, right? Now, what would be possible or prior to this line of work or without this line of work, one could fit a neural dynamics model and then do all kinds of analyses, like power analyses on the different frequency spectra and say, look at the average firing rate or the correlation coefficients of firing rate. So fit the firing rates and the synaptic Plasticities and store all that data.	So something in a neuroscience laboratory that model can have interpretability corresponding to the variables of a given POMDP. And just to kind of give one more point on how that's going deeper than, for example, statistical parametric mapping SPM. So let's just assume that the neural network we're dealing with is fit from brain data from some lucky Kant, right? Now, what would be possible or prior to this line of work or without this line of work, one could fit a neural dynamics model and then do all kinds of analyses, like power analyses on the different frequency spectra and say, look at the average firing rate or the correlation coefficients of firing rate. So fit the firing rates and the synaptic Plasticities and store all that data.				
3914305	3974687	Daniel	0.74	1:05:14	And then we could just pick a POMDP that we've seen in the literature without any reference to the neural network and optimize the POMDP. And then we could say well, it turns out that when the POMDP o is high there's increased theta power in this firing pattern. So it's like comparing the descriptive statistics from the neural model to the descriptive summary statistics of the POMDP decision making model. However, with this formal connection there is actually an interpretability to the unobserved neural states which are what are being inferred from the fMRI measurement, from the EEG measurements and so on. Those underlying variables have a specific interpretability in relationship to the structure of the P-O-M DP.	And then we could just pick a POMDP that we've seen in the literature without any reference to the neural network and optimize the POMDP. And then we could say well, it turns out that when the POMDP o is high there's increased theta power in this firing pattern. So it's like comparing the descriptive statistics from the neural model to the descriptive summary statistics of the POMDP decision making model. However, with this formal connection there is actually an interpretability to the unobserved neural states which are what are being inferred from the fMRI measurement, from the EEG measurements and so on. Those underlying variables have a specific interpretability in relationship to the structure of the P-O-M DP.				
3981337	4051262	Takuya	0.67	1:06:21	Right? So yeah, that's also very interesting important aspect. So what you said is I think more conventional strategy and it is also formally related to model comparison aspect. So we usually think various modeling and identify or select what is the best model to explain a given data. And this reverse engineering idea involves such a model comparison aspect in the sense that we try to find the model with the best expandability which should we have the identical functionality, right directory address, the exact same Costa function architectures using the information natural transformation.	Right? So yeah, that's also very interesting important aspect. So what you said is I think more conventional strategy and it is also formally related to model comparison aspect. So we usually think various modeling and identify or select what is the best model to explain a given data. And this reverse engineering idea involves such a model comparison aspect in the sense that we try to find the model with the best expandability which should we have the identical functionality, right directory address, the exact same Costa function architectures using the information natural transformation.				
4051687	4060025	Takuya	0.97269	1:07:31	So it should be up to explain the neural data in the Bayesian sense.	So it should be up to explain the neural data in the Bayesian sense.				
4062412	4125362	Daniel	0.64	1:07:42	Yeah, one can imagine how that would transform the way that current neuroimaging studies and technologies describe what it is about the measurement that provides information about the cognition model. So, to give another related example, let's just say a person was wearing an EEG headset and a previous study had shown that increased alphaband activity was associated with this behavior. That's comparing a descriptive statistic of the observations of the sensor and correlating the summarized observable to some other variable like anxiety or performance on a behavior.	Yeah, one can imagine how that would transform the way that current neuroimaging studies and technologies describe what it is about the measurement that provides information about the cognition model. So, to give another related example, let's just say a person was wearing an EEG headset and a previous study had shown that increased alphaband activity was associated with this behavior. That's comparing a descriptive statistic of the observations of the sensor and correlating the summarized observable to some other variable like anxiety or performance on a behavior.				
4127512	4208687	Daniel	0.93	1:08:47	In contrast, an unobserved variable in this setting the actual underlying neural state is being correlated to some semantic generative models component. So it's no longer necessarily that any single frequency band would be associated more or less with a given outcome, but it's actually some hidden state variability which gains the interpretability across this transformation. Which is a subtle point, but it speaks to how broadly the equivalents would reinterpret empirical neuroimaging results as well as a variety of artificial neural network experiments and diagnostics where people do lesion studies and double knockouts on artificial neural networks.	In contrast, an unobserved variable in this setting the actual underlying neural state is being correlated to some semantic generative models component. So it's no longer necessarily that any single frequency band would be associated more or less with a given outcome, but it's actually some hidden state variability which gains the interpretability across this transformation. Which is a subtle point, but it speaks to how broadly the equivalents would reinterpret empirical neuroimaging results as well as a variety of artificial neural network experiments and diagnostics where people do lesion studies and double knockouts on artificial neural networks.				
4211062	4287512	Daniel	0.96202	1:10:11	So anywhere where somebody with awareness sees that a neural network, artificial or biological, is having summary features described and correlated to something that's more semantic in a quest for meaning may now have a different approach that involves formalizing. The model explicitly in terms of unobserved hidden states with a cost function akin to a variational free energy minimizing risk bounding surprise on the Unobservables. So even though the unobservables were modeled in a sense in the other conventional strategy like neural activity is a variable in fMRI experiments, it's underlying the bold signal. Yet this formalism concordance is a more coherent and powerful connection.	So anywhere where somebody with awareness sees that a neural network, artificial or biological, is having summary features described and correlated to something that's more semantic in a quest for meaning may now have a different approach that involves formalizing. The model explicitly in terms of unobserved hidden states with a cost function akin to a variational free energy minimizing risk bounding surprise on the Unobservables. So even though the unobservables were modeled in a sense in the other conventional strategy like neural activity is a variable in fMRI experiments, it's underlying the bold signal. Yet this formalism concordance is a more coherent and powerful connection.				
4295362	4335607	Takuya	0.19353	1:11:35	Lib sold. So you now address this very important point. So first to address that so we need to clarify about what is a program, consider here. So this is a program Socalled metabasian problem in the sense that researchers try to infer or estimate neuro activity or brain activity which infer the external world dynamics. Right.	Lib sold. So you now address this very important point. So first to address that so we need to clarify about what is a program, consider here. So this is a program Socalled metabasian problem in the sense that researchers try to infer or estimate neuro activity or brain activity which infer the external world dynamics. Right.				
4335685	4404967	Takuya	0.68179	1:12:15	So neuron or brain environment and we research brain activity. So there are two step processes. So this sort of meta Bay is quite tricky intractable because sometimes London variable becomes posterior about other aspects. So I think there is some established approach about metabolism. But this paper provides some alternative in the sense that we separate two programs by saying that here what we import is simply neural network dynamics which is shown in the left hand side of this figure.	So neuron or brain environment and we research brain activity. So there are two step processes. So this sort of meta Bay is quite tricky intractable because sometimes London variable becomes posterior about other aspects. So I think there is some established approach about metabolism. But this paper provides some alternative in the sense that we separate two programs by saying that here what we import is simply neural network dynamics which is shown in the left hand side of this figure.				
4405165	4477250	Takuya	0.81765	1:13:25	So we feed data to conventional neural network model which is a simple differential creation. But thanks to this formal recovery between neural network dynamics and home VP behavior, then we can transform the resulting neural network architectures or dynamics into the page and in force in some sense post Hog mana. So we nicely avoid the directory addressing the meta agent program but obtain the same kind of solution in that sense. Yes, with combining with brain activity recording Lieke de Boer imaging. Yeah, we can estimate a plausible neural network model in the right hand side and we can transform that to home DB in the right hand side.	So we feed data to conventional neural network model which is a simple differential creation. But thanks to this formal recovery between neural network dynamics and home VP behavior, then we can transform the resulting neural network architectures or dynamics into the page and in force in some sense post Hog mana. So we nicely avoid the directory addressing the meta agent program but obtain the same kind of solution in that sense. Yes, with combining with brain activity recording Lieke de Boer imaging. Yeah, we can estimate a plausible neural network model in the right hand side and we can transform that to home DB in the right hand side.				
4480537	4514150	Daniel	0.99164	1:14:40	Awesome. I'm going to show an image and ask a question from Dave in the chat. So, Dave made this image, it's the right side of figure one that we've just been looking at with the variational Bayesian information and he wrote the arc shown as impinging on the S self arc. Is this intentional? If so, it could represent tuning or modulation of the feedback of S into itself.	Awesome. I'm going to show an image and ask a question from Dave in the chat. So, Dave made this image, it's the right side of figure one that we've just been looking at with the variational Bayesian information and he wrote the arc shown as impinging on the S self arc. Is this intentional? If so, it could represent tuning or modulation of the feedback of S into itself.				
4517587	4551137	Daniel	0.77268	1:15:17	Do you have a thought on this? It's attention? Yes. I think it's related to the usual formulation of home DP architecture and active inference concept in the sense that our decision or policy in the usual setting modify the state transition matrix b matrix.	Do you have a thought on this? It's attention? Yes. I think it's related to the usual formulation of home DP architecture and active inference concept in the sense that our decision or policy in the usual setting modify the state transition matrix b matrix.				
4553662	4587062	Takuya	0.68515	1:15:53	Here, delta is an alternative of policy of agent. So basically the director indicates stated transition metrics under a particular decision which agent made. In that sense, what the agent changes is state transition metrics, not state itself directly. That's why we use this illustration.	Here, delta is an alternative of policy of agent. So basically the director indicates stated transition metrics under a particular decision which agent made. In that sense, what the agent changes is state transition metrics, not state itself directly. That's why we use this illustration.				
4589362	4606550	Daniel	0.99309	1:16:29	Awesome. Very subtle but important point, which is when we look at the classical POMDP formulation. So here we'll look at a version shown in figure two. I'll just bring just figure two in.	Awesome. Very subtle but important point, which is when we look at the classical POMDP formulation. So here we'll look at a version shown in figure two. I'll just bring just figure two in.				
4609312	4629500	Daniel	0.99839	1:16:49	Could you describe what you just did about the role of the B matrix in influencing how hidden states change and how that is where our policies have impact? And also please, how do the top and the bottom of figure two differ?	Could you describe what you just did about the role of the B matrix in influencing how hidden states change and how that is where our policies have impact? And also please, how do the top and the bottom of figure two differ?				
4633087	4730462	Takuya	0.66	1:17:13	Okay, so in the usual correlation under active inference with palm DB structure. So we for us to consider the prior inference and depending on the prior preference, we compute the expect free energy and its minimization provide the policy and the policy moderate state transition. So now in the upper Brea, we instead use the builder which is the option of the agent. So here option or decision was made for each timestep so that unlike the conventional formation, we have a sequence of delta and for each time step delta moderates active states cognition matrix B. So B is a matrix that transformed hidden state in the previous step to the current time step and its moderation indicate that under a specific decision rule.	Okay, so in the usual correlation under active inference with palm DB structure. So we for us to consider the prior inference and depending on the prior preference, we compute the expect free energy and its minimization provide the policy and the policy moderate state transition. So now in the upper Brea, we instead use the builder which is the option of the agent. So here option or decision was made for each timestep so that unlike the conventional formation, we have a sequence of delta and for each time step delta moderates active states cognition matrix B. So B is a matrix that transformed hidden state in the previous step to the current time step and its moderation indicate that under a specific decision rule.				
4731637	4844087	Takuya	0.84723	1:18:51	For example, if this F indicates our cognition in the virtual environment with the Gold decision move forward. But if we choose the no go decision, then it unchanged. So such a moderation of state transition was made by choosing debuta and the lower part correspond to Beijing inference made by Bayesian agent. So basically there is a symmetry between a third part and roar part because we assume that this Beijing agent has a plausible guarantee model which nicely correspond to given environment defined in the above upper part in this figure. But one interesting thing asymmetry is that to model this particular canonical neural network, we don't consider an arrow or link from delta posteria to S posteria which is in the environment data moderate S in the next step through P matrix moderation.	For example, if this F indicates our cognition in the virtual environment with the Gold decision move forward. But if we choose the no go decision, then it unchanged. So such a moderation of state transition was made by choosing debuta and the lower part correspond to Beijing inference made by Bayesian agent. So basically there is a symmetry between a third part and roar part because we assume that this Beijing agent has a plausible guarantee model which nicely correspond to given environment defined in the above upper part in this figure. But one interesting thing asymmetry is that to model this particular canonical neural network, we don't consider an arrow or link from delta posteria to S posteria which is in the environment data moderate S in the next step through P matrix moderation.				
4845187	4873037	Takuya	0.92	1:20:45	In this particular Bay jets which formally correspond to a canonical neural network, we don't consider that it is correspond to an absence of the projection from output layer to the middle layer.	In this particular Bay jets which formally correspond to a canonical neural network, we don't consider that it is correspond to an absence of the projection from output layer to the middle layer.				
4879087	4879850	Takuya	0.69	1:21:19	Okay.	Okay.				
4885837	4940375	Daniel	0.99	1:21:25	This is from the 2020 paper, but it shows the neural network architectures, the two layer architectures. So could you restate the top and the bottom of figure two in the 22 paper and connect it to why it's important that you're studying two layer neural network models? I miss you. Yeah, can you just connect the asymmetry between the top and the bottom on figure two with the two layer neural network architectures? You said that the asymmetry, there's no direct link between.	This is from the 2020 paper, but it shows the neural network architectures, the two layer architectures. So could you restate the top and the bottom of figure two in the 22 paper and connect it to why it's important that you're studying two layer neural network models? I miss you. Yeah, can you just connect the asymmetry between the top and the bottom on figure two with the two layer neural network architectures? You said that the asymmetry, there's no direct link between.				
4947475	5012965	Takuya	0.5	1:22:27	This is another story. So in the previous paper there is only output or concept layer because we basically consider a single layer feedforward network. So my apologies for some confusion about the network architectures in the 2020 paper. So now upper part of this network architectures correspond to environmental generative process and only a lower part correspond to single foot feed for neural network architectures. So now this part is identical to a map from O to S.	This is another story. So in the previous paper there is only output or concept layer because we basically consider a single layer feedforward network. So my apologies for some confusion about the network architectures in the 2020 paper. So now upper part of this network architectures correspond to environmental generative process and only a lower part correspond to single foot feed for neural network architectures. So now this part is identical to a map from O to S.				
5013057	5017625	Takuya	0.18507	1:23:33	OSS area in the 2022 papers.	OSS area in the 2022 papers.				
5023225	5078887	Daniel	0.85	1:23:43	Okay, so on the top of figure two is the actual generative process. It's the true structure of causation in the environment, which is to say that actions delta actually influence how states change through time via B delta. The generative process through the A matrix emits observations, sequences of observations. And here on the bottom with a mirrored structure is the generative model of the entity. So what's the relevance of the arrows and the more force factor graph structure on the bottom?	Okay, so on the top of figure two is the actual generative process. It's the true structure of causation in the environment, which is to say that actions delta actually influence how states change through time via B delta. The generative process through the A matrix emits observations, sequences of observations. And here on the bottom with a mirrored structure is the generative model of the entity. So what's the relevance of the arrows and the more force factor graph structure on the bottom?				
5080675	5088275	Takuya	0.89	1:24:40	The arrow indicates active inference.	The arrow indicates active inference.				
5090425	5171230	Takuya	0.59978	1:24:50	So it's a flow of the information in the sense that to calculate in the step two, we use the information of step two conversation and step one's posterior expectation about hidden states. So those two determine the s two's expectation. Usually in the following graph, we consider retrospective arrow so in the sense that s three also affect the s two inference. But this corresponds to Bayesian smoother in the sense that we update every time step simultaneously to better inference. However, what we consider here is more filtering approach in the sense that for each step we compute the latest hidden states and then we don't change any other states in the past.	So it's a flow of the information in the sense that to calculate in the step two, we use the information of step two conversation and step one's posterior expectation about hidden states. So those two determine the s two's expectation. Usually in the following graph, we consider retrospective arrow so in the sense that s three also affect the s two inference. But this corresponds to Bayesian smoother in the sense that we update every time step simultaneously to better inference. However, what we consider here is more filtering approach in the sense that for each step we compute the latest hidden states and then we don't change any other states in the past.				
5171427	5178712	Takuya	0.94488	1:26:11	So that's why we don't consider the arrow from future to the past.	So that's why we don't consider the arrow from future to the past.				
5182337	5253150	Daniel	0.99774	1:26:22	Awesome. Yeah. Just to highlight that in the Bayesian smoothing approach, it's kind of like fitting a spline because it takes the whole time series and it fits the smoothest possible line or the line whose smoothness is on the AIC BIC frontier. But here on the bottom with the almost pseudocode implementation provided by the Force Factor graph, which was demonstrated to be equivalent with the Bayesian graph in the 2017 work with Friston, Par and de Vries. This architectures is reflecting a filtering scheme like a common filter or just generalized Bayesian filtering through time, where estimates are being carried forward and changed time point to time point, such that the decision rules, or the updates perhaps more accurately, are defined between time points.	Awesome. Yeah. Just to highlight that in the Bayesian smoothing approach, it's kind of like fitting a spline because it takes the whole time series and it fits the smoothest possible line or the line whose smoothness is on the AIC BIC frontier. But here on the bottom with the almost pseudocode implementation provided by the Force Factor graph, which was demonstrated to be equivalent with the Bayesian graph in the 2017 work with Friston, Par and de Vries. This architectures is reflecting a filtering scheme like a common filter or just generalized Bayesian filtering through time, where estimates are being carried forward and changed time point to time point, such that the decision rules, or the updates perhaps more accurately, are defined between time points.				
5253662	5287875	Daniel	0.98	1:27:33	And the total time series does not have to be loaded into memory or remembered at once. And then the Bayesian filtering approach has the asymmetry with a different consideration of action. So why again is it that action is considered differently in the Bayesian filtering approach on the bottom of the generative models than the consideration of action in the generative process.	And the total time series does not have to be loaded into memory or remembered at once. And then the Bayesian filtering approach has the asymmetry with a different consideration of action. So why again is it that action is considered differently in the Bayesian filtering approach on the bottom of the generative models than the consideration of action in the generative process.				
5291162	5312100	Takuya	0.76	1:28:11	That correspond to lack of cognition from Y to X in the figure one? Or probably a figure four is helpful to that relationship.	That correspond to lack of cognition from Y to X in the figure one? Or probably a figure four is helpful to that relationship.				
5317487	5347812	Daniel	0.8	1:28:37	Four? Yeah. This is an example network architecture comprising input Brea, output Brea. What we consider is information flow from sensory to middle Brea and middle area have a self connection, recurrent connection and middle area project to output layer. So there is no connection from all output layer to middle layer.	Four? Yeah. This is an example network architecture comprising input Brea, output Brea. What we consider is information flow from sensory to middle Brea and middle area have a self connection, recurrent connection and middle area project to output layer. So there is no connection from all output layer to middle layer.				
5348387	5374662	Takuya	0.56	1:29:08	Right. So that's why we don't consider the link from data in the bottom layer of the figure to posterior. So this is different from true generative process in the environment.	Right. So that's why we don't consider the link from data in the bottom layer of the figure to posterior. So this is different from true generative process in the environment.				
5377975	5417300	Takuya	0.99	1:29:37	This is a kind of simplification. So because our purpose is identifying the plausible Bayesian model which correspond to this type of neural network canonical network. So in other words, this neural network uses approximation about that point or use limited form of palm DP scheme.	This is a kind of simplification. So because our purpose is identifying the plausible Bayesian model which correspond to this type of neural network canonical network. So in other words, this neural network uses approximation about that point or use limited form of palm DP scheme.				
5423700	5459862	Daniel	0.98217	1:30:23	Thanks. So could you describe W-V-K and Gamma? Just what is the biological or functional interpretation of those variables? What brain regions or what processes or pathologies do they map to? Okay, so basically, WVK, synaptic strength is in the form of matrix and active inference.	Thanks. So could you describe W-V-K and Gamma? Just what is the biological or functional interpretation of those variables? What brain regions or what processes or pathologies do they map to? Okay, so basically, WVK, synaptic strength is in the form of matrix and active inference.				
5464875	5549200	Takuya	0.96217	1:31:04	They represent connection in the different layer or different architectures in the sense that W means forward connectivity from sensory Laje to middle Laje, k correspond to recurrent network recurrent connectivity and V correspond to projection from middle Brea to output layer. So in this paper, we don't discuss the relation to brain anatomy in detail, but what one can consider analogy, for example, say x corresponds to several cortex activity and Y, for example correspond to cerebral wrong in the sense that it determines the action. So it is considered that in the cerebrum there is a signal that represents choice. This is joined for examples goal no go decision made in cergram.	They represent connection in the different layer or different architectures in the sense that W means forward connectivity from sensory Laje to middle Laje, k correspond to recurrent network recurrent connectivity and V correspond to projection from middle Brea to output layer. So in this paper, we don't discuss the relation to brain anatomy in detail, but what one can consider analogy, for example, say x corresponds to several cortex activity and Y, for example correspond to cerebral wrong in the sense that it determines the action. So it is considered that in the cerebrum there is a signal that represents choice. This is joined for examples goal no go decision made in cergram.				
5551575	5626750	Takuya	0.629	1:32:31	It's analogous to this particular architectures. On the other hand, in the several cortex we compute the sensory information to generate some inference, prediction and planning the way it is computer by this recurrent network. In this particular modeling, although we don't separate brain region in detail, but this recurrent network is sufficient this graph of recurrent network is sufficient to characterize any type brain architecture in the sense that we can design any higher car or mutually connected architecture using a generic crossover recurrent network by changing weight.	It's analogous to this particular architectures. On the other hand, in the several cortex we compute the sensory information to generate some inference, prediction and planning the way it is computer by this recurrent network. In this particular modeling, although we don't separate brain region in detail, but this recurrent network is sufficient this graph of recurrent network is sufficient to characterize any type brain architecture in the sense that we can design any higher car or mutually connected architecture using a generic crossover recurrent network by changing weight.				
5634750	5688240	Daniel	0.99127	1:33:54	Awesome. So the middle layer we can think of as like the cognition stuff. It's the internal states when we talk about perception, cognition, action in the active scheme or even in the sandwich model of cognition, perception, cognition action. So W is describing how those sensory inputs either in one step or composably in multiple steps become processed to these internal representation of hidden external causes inferred external states. And so these are the states that have that sigma relationship and a generalized synchrony with external states.	Awesome. So the middle layer we can think of as like the cognition stuff. It's the internal states when we talk about perception, cognition, action in the active scheme or even in the sandwich model of cognition, perception, cognition action. So W is describing how those sensory inputs either in one step or composably in multiple steps become processed to these internal representation of hidden external causes inferred external states. And so these are the states that have that sigma relationship and a generalized synchrony with external states.				
5688407	5746812	Daniel	0.98	1:34:48	The sigma and the generalized synchrony are not discussed in your paper, but it connects to other work and the recurrent connections are facilitating attention or waiting of the stimuli. This is the recurrent learning loop and the relationship of the A between observations and hidden state estimates. And then a different kind of modulation comes Hinton play between the hidden state estimate of the internal states state and the action selection. So what is gamma corresponding to? And why is the gamma modulation between layers two and three differing functionally from the k synaptic modulation of one and two?	The sigma and the generalized synchrony are not discussed in your paper, but it connects to other work and the recurrent connections are facilitating attention or waiting of the stimuli. This is the recurrent learning loop and the relationship of the A between observations and hidden state estimates. And then a different kind of modulation comes Hinton play between the hidden state estimate of the internal states state and the action selection. So what is gamma corresponding to? And why is the gamma modulation between layers two and three differing functionally from the k synaptic modulation of one and two?				
5747850	5833587	Takuya	0.67	1:35:47	Yeah, so K matrix basically formally correspond to B matrix in the Bayesian information. So we rotate the information about the prediction, right, our narrator or our expectation about the next state based on the previous state. On the other hand, Laurel gamma is quite different from such a computation. Gamma basically means risk function, which is in principle can we use arbitrary risk function. So this is a part of generative models we designed and the rule of risk function in generative model formulation is attention form of generative models depending on that value of gamma which examples retrospective moderation of evaluation of task decisions given an outcome in the future.	Yeah, so K matrix basically formally correspond to B matrix in the Bayesian information. So we rotate the information about the prediction, right, our narrator or our expectation about the next state based on the previous state. On the other hand, Laurel gamma is quite different from such a computation. Gamma basically means risk function, which is in principle can we use arbitrary risk function. So this is a part of generative models we designed and the rule of risk function in generative model formulation is attention form of generative models depending on that value of gamma which examples retrospective moderation of evaluation of task decisions given an outcome in the future.				
5835225	5905362	Takuya	1	1:37:15	In terms of neural network, of course it corresponds to some neural modulation. For example, Dopaminergic moderation is famous in the literature which moderates the activity and fluxicity of various brain vision. But we particularly focus on Dopaminergic or any kind of neuromoduration of cyanogic prosthesis in the output trigger which may correspond to Cergram. So in the Serbram neural activity or processes moderated by Dopaminergic, input from is used as the optimization action rule, decision rule or sometimes attention help us.	In terms of neural network, of course it corresponds to some neural modulation. For example, Dopaminergic moderation is famous in the literature which moderates the activity and fluxicity of various brain vision. But we particularly focus on Dopaminergic or any kind of neuromoduration of cyanogic prosthesis in the output trigger which may correspond to Cergram. So in the Serbram neural activity or processes moderated by Dopaminergic, input from is used as the optimization action rule, decision rule or sometimes attention help us.				
5909212	5990877	Daniel	0.97696	1:38:29	Awesome. Very interesting because in some previous papers and models that we've looked at, attention is dealt with as policy selection on mental states. So internal action selection, it's an action like variable describing attention and awareness and even metacognition. And so that connects the role of Dopamine in motor decision making seen in many Dyskinesias but also with the role of Dopamine in seemingly nonmotor based decisionmaking like gambling or investing where it doesn't seem to immediately translate to a given motor sequence. Yet it has analogous computational characteristics and the comorbidities and the side effects of different drugs that affect the Dopamine neurophysiology are known to have carryover in terms of like the rigidity or excessivity of motor and decision making aspects.	Awesome. Very interesting because in some previous papers and models that we've looked at, attention is dealt with as policy selection on mental states. So internal action selection, it's an action like variable describing attention and awareness and even metacognition. And so that connects the role of Dopamine in motor decision making seen in many Dyskinesias but also with the role of Dopamine in seemingly nonmotor based decisionmaking like gambling or investing where it doesn't seem to immediately translate to a given motor sequence. Yet it has analogous computational characteristics and the comorbidities and the side effects of different drugs that affect the Dopamine neurophysiology are known to have carryover in terms of like the rigidity or excessivity of motor and decision making aspects.				
5990907	6035900	Daniel	0.86092	1:39:50	So it's like interesting that Dopamine has long been understood to have that parallel role in attention as cognitive action and motor action and that was established empirically through modifications of Dopamine signaling and also had been modeled analogously with computational neuroscience. And this is providing again a slightly different interpretation of that very well studied Dofaminergic modulation of attention and policy.	So it's like interesting that Dopamine has long been understood to have that parallel role in attention as cognitive action and motor action and that was established empirically through modifications of Dopamine signaling and also had been modeled analogously with computational neuroscience. And this is providing again a slightly different interpretation of that very well studied Dofaminergic modulation of attention and policy.				
6040837	6051887	Takuya	0.8773	1:40:40	Yes. In addition to that, I believe another important aspects is correlation of scientific processing by document.	Yes. In addition to that, I believe another important aspects is correlation of scientific processing by document.				
6075850	6085387	Daniel	0.61029	1:41:15	Do you want to show something or yeah. Can you see this paper?	Do you want to show something or yeah. Can you see this paper?				
6087475	6102412	Takuya	0.55	1:41:27	I sent you a chat. If you can't, I'll send you a PDF. Okay, let me see. I'll look at it up now.	I sent you a chat. If you can't, I'll send you a PDF. Okay, let me see. I'll look at it up now.				
6107425	6170190	Daniel	0.91	1:41:47	All right. The paper is a critical time window for Dopamine actions on the structural plasticity of dendritic spines from 2014 byagasha. So what is interesting about this paper. Yeah, it basically explained conversation of plasticity by Dopamine, which is common but crucial point of this paper is that it shows that it proved that Dopaminezic input can moderate after hebion prosthesis is established. So this paper showed that they add domain logic input for about 2 seconds after or several seconds after the Hebbian process is established.	All right. The paper is a critical time window for Dopamine actions on the structural plasticity of dendritic spines from 2014 byagasha. So what is interesting about this paper. Yeah, it basically explained conversation of plasticity by Dopamine, which is common but crucial point of this paper is that it shows that it proved that Dopaminezic input can moderate after hebion prosthesis is established. So this paper showed that they add domain logic input for about 2 seconds after or several seconds after the Hebbian process is established.				
6170220	6245437	Takuya	0.82213	1:42:50	But such a post hoc moderation, post hoc introduction of heterotopamagic Impetu is sufficient to change the past capacity which may be associated with the Costa hoc evolution of our past decisions. So by decision making we of course changes the changes the weight matrix by through trust 50. But to evaluate the goodness or badness of our decision, we need to see observe the future outcome which is propagated by for example, Dopamine. And this paper nicely show empirically that Dopamine actually can change the past evaluation, maybe after such a psychic level, very local level, ecoscopic level.	But such a post hoc moderation, post hoc introduction of heterotopamagic Impetu is sufficient to change the past capacity which may be associated with the Costa hoc evolution of our past decisions. So by decision making we of course changes the changes the weight matrix by through trust 50. But to evaluate the goodness or badness of our decision, we need to see observe the future outcome which is propagated by for example, Dopamine. And this paper nicely show empirically that Dopamine actually can change the past evaluation, maybe after such a psychic level, very local level, ecoscopic level.				
6252250	6303862	Daniel	0.85886	1:44:12	So there's a short term window, the critical time window that they're describing. But there's some window. Yeah, some window by which dopamine potentially unrelated to the initial heavy and plasticity events, right. Where secondary dopamine signaling or not secondary just after the initial fact, potentially of a different valence or the same valence can synergize or cancel the plasticity formed in the moment. Exactly.	So there's a short term window, the critical time window that they're describing. But there's some window. Yeah, some window by which dopamine potentially unrelated to the initial heavy and plasticity events, right. Where secondary dopamine signaling or not secondary just after the initial fact, potentially of a different valence or the same valence can synergize or cancel the plasticity formed in the moment. Exactly.				
6305425	6312862	Takuya	0.7	1:45:05	And this is not limited to Dopamine, but other neuro moderator can also do this.	And this is not limited to Dopamine, but other neuro moderator can also do this.				
6318250	6333575	Daniel	0.88741	1:45:18	Well, on one hand, how does this change our understanding of animal neurophysiology? And then I guess, on the other hand, how does this influence how we would design sentient artifacts.	Well, on one hand, how does this change our understanding of animal neurophysiology? And then I guess, on the other hand, how does this influence how we would design sentient artifacts.				
6342625	6351112	Takuya	0.92198	1:45:42	For both animals and artificial agent?	For both animals and artificial agent?				
6353350	6415100	Takuya	0.7	1:45:53	One important message I free with us. So this tells us possible simple architectures to make learning. This is association between past decision and future reward or any risk factors, which is otherwise computed by computing forward prediction by iterating some computational, this is a usual way to predict the future event and then select the option. But using this property, biological property, which is observed in experiment, we can design, we can imagine other simpler architecture to make a planning.	One important message I free with us. So this tells us possible simple architectures to make learning. This is association between past decision and future reward or any risk factors, which is otherwise computed by computing forward prediction by iterating some computational, this is a usual way to predict the future event and then select the option. But using this property, biological property, which is observed in experiment, we can design, we can imagine other simpler architecture to make a planning.				
6417250	6440600	Takuya	0.7134	1:46:57	So for both animals and synthetic Bayesian agent, it provides an alternative explanation about the association between our past decision and the future risk and the optimization of our decision to maximize, reward or minimize risk.	So for both animals and synthetic Bayesian agent, it provides an alternative explanation about the association between our past decision and the future risk and the optimization of our decision to maximize, reward or minimize risk.				
6445075	6478500	Daniel	0.91343	1:47:25	Well, one interesting note is we spoke earlier about the difference between the Bayesian smoothing all at once approach and the Bayesian filtering step by step approach. Now, if one had infinite knowledge and computational resources, the Bayesian smoothing approach is the way to go. Like, you don't want the decision rule for investment. You want to look at the whole time series past, present and future, and know the best moments to have made the trades. I mean, there's no comparison.	Well, one interesting note is we spoke earlier about the difference between the Bayesian smoothing all at once approach and the Bayesian filtering step by step approach. Now, if one had infinite knowledge and computational resources, the Bayesian smoothing approach is the way to go. Like, you don't want the decision rule for investment. You want to look at the whole time series past, present and future, and know the best moments to have made the trades. I mean, there's no comparison.				
6478575	6507895	Daniel	0.96121	1:47:58	You're going to do better with the Bayesian smoothing. However, it's just implausible computationally and because it requires total memory of the past and knowledge of the future. So that's what motivates the development of Bayesian filtering approaches, which are tractable and calculable through time. Yet with this time delayed modulation. Part.	You're going to do better with the Bayesian smoothing. However, it's just implausible computationally and because it requires total memory of the past and knowledge of the future. So that's what motivates the development of Bayesian filtering approaches, which are tractable and calculable through time. Yet with this time delayed modulation. Part.				
6507972	6562837	Daniel	1	1:48:27	Of the Bayesian smoothing strength comma back into play. It doesn't enable true anticipation of future states, but that's what the expected free energy does. However, the delayed neuromodulation allows for reconsideration of a window of past states. And so in that way it corresponds to like a slightly deeper filter, not just a filter of a time step of one, but a filter of like a rolling window of five or with some decay. And you don't want that window to be too big because if the window were ten minutes, then too many contrasting stimuli would get piled together.	Of the Bayesian smoothing strength comma back into play. It doesn't enable true anticipation of future states, but that's what the expected free energy does. However, the delayed neuromodulation allows for reconsideration of a window of past states. And so in that way it corresponds to like a slightly deeper filter, not just a filter of a time step of one, but a filter of like a rolling window of five or with some decay. And you don't want that window to be too big because if the window were ten minutes, then too many contrasting stimuli would get piled together.				
6563350	6622400	Daniel	0.95	1:49:23	The Dopamine level would just converge to a mean field average. But there's some time decay or time constant on the post hoc modulation where that neuromodulatory signal is actually a parameter of interest. And that's not an infinitely long or infinitely short window, but it's some niche dependent amount of time. And that's a very interpretable and first principles interpretation of the computational role of neuromodulators in a way that is also consistent with all these other concordances we've been exploring. So it's quite an interesting connection back, I guess, in our final minutes of this discussion.	The Dopamine level would just converge to a mean field average. But there's some time decay or time constant on the post hoc modulation where that neuromodulatory signal is actually a parameter of interest. And that's not an infinitely long or infinitely short window, but it's some niche dependent amount of time. And that's a very interpretable and first principles interpretation of the computational role of neuromodulators in a way that is also consistent with all these other concordances we've been exploring. So it's quite an interesting connection back, I guess, in our final minutes of this discussion.				
6626850	6653800	Daniel	0.67372	1:50:26	What are you? Well, maybe go to the beginning at the end, which I meant to ask earlier, but it's a good way that we can sort of close today and look forward, which is how did you come to this line of research specifically studying neural networks in this way with Karl Friston and your colleagues?	What are you? Well, maybe go to the beginning at the end, which I meant to ask earlier, but it's a good way that we can sort of close today and look forward, which is how did you come to this line of research specifically studying neural networks in this way with Karl Friston and your colleagues?				
6658275	6695725	Takuya	0.42795	1:50:58	So, yes, so my interest was the characterization of Barricade network. So my first motivation is to make biologically plausible artificial intelligence. But to achieve that, we need to know about biological brain or biological neural networking.	So, yes, so my interest was the characterization of Barricade network. So my first motivation is to make biologically plausible artificial intelligence. But to achieve that, we need to know about biological brain or biological neural networking.				
6701100	6716725	Takuya	0.54	1:51:41	In these several years, I collaborated with the doctor professor Californiston to study about his salary principal after doing forest.	In these several years, I collaborated with the doctor professor Californiston to study about his salary principal after doing forest.				
6721125	6796887	Takuya	0.73057	1:52:01	My question during that period was the priority principle, is everything about the biological possible neural network or is there another aspect that can characterize the virus car neural network? So it is non trivial. It was non trivial. So that's why I tried to start from characterizing the neural network first. So our strategy is not considering the way of implementing any Bayesian algorithm as the brain architectures, but my interest is rather characterization of a given vertical network in terms of some other things.	My question during that period was the priority principle, is everything about the biological possible neural network or is there another aspect that can characterize the virus car neural network? So it is non trivial. It was non trivial. So that's why I tried to start from characterizing the neural network first. So our strategy is not considering the way of implementing any Bayesian algorithm as the brain architectures, but my interest is rather characterization of a given vertical network in terms of some other things.				
6797400	6818575	Takuya	0.99	1:53:17	One possible way is of course based on inference free energy transplant reinforce. So that's why I start from characterizing power's network. But just defining neural network architecture is insufficient.	One possible way is of course based on inference free energy transplant reinforce. So that's why I start from characterizing power's network. But just defining neural network architecture is insufficient.				
6821625	6899435	Takuya	0.58	1:53:41	It is not tractable, it is far beyond the computational tractability as the mathematical analysis. And we need some assumptions or some trick to increase the tractability. One day I came up with an idea that in which we consider that both new activity and fastest follow the same cost function gradient. This is very much an allergy with physical system like Lagrangian information geometry, Hamiltonian formation. So usually we consider some energy landscape and design plausible trajectory as the evolution of some principle of minimum action or restruction.	It is not tractable, it is far beyond the computational tractability as the mathematical analysis. And we need some assumptions or some trick to increase the tractability. One day I came up with an idea that in which we consider that both new activity and fastest follow the same cost function gradient. This is very much an allergy with physical system like Lagrangian information geometry, Hamiltonian formation. So usually we consider some energy landscape and design plausible trajectory as the evolution of some principle of minimum action or restruction.				
6899630	7003675	Takuya	0.83048	1:54:59	So we imagine that what if we applied such idea to computational neural network or biological neural networks to characterize their dynamics in the first principle, that's the first computational step to come up with this framework. And finally we noticed that it is not easy to connect the Newtonian dynamics with this type of neural activity study because neural activification not necessary to be a second order differential equation, but rather it is fast order and considering many things. Then we finally use a Costa function proposal in the papers, which is not necessary to have a former identity with the so called lavalier in the Newtonian physics, but it is rather plausible as the rule or underlying mechanism of such type of network.	So we imagine that what if we applied such idea to computational neural network or biological neural networks to characterize their dynamics in the first principle, that's the first computational step to come up with this framework. And finally we noticed that it is not easy to connect the Newtonian dynamics with this type of neural activity study because neural activification not necessary to be a second order differential equation, but rather it is fast order and considering many things. Then we finally use a Costa function proposal in the papers, which is not necessary to have a former identity with the so called lavalier in the Newtonian physics, but it is rather plausible as the rule or underlying mechanism of such type of network.				
7011800	7028912	Daniel	0.99249	1:56:51	Awesome. Well, it has been quite an interesting dot one. I really appreciate everything you've shared today. Is there anything else you want to add at this point? Otherwise we'll talk again.	Awesome. Well, it has been quite an interesting dot one. I really appreciate everything you've shared today. Is there anything else you want to add at this point? Otherwise we'll talk again.				
7030325	7044400	Takuya	0.68	1:57:10	Yeah, I already speak a role. Thank you. Alright, talk to you later. Bye. Thank you very much for a nice discussion.	Yeah, I already speak a role. Thank you. Alright, talk to you later. Bye. Thank you very much for a nice discussion.				
