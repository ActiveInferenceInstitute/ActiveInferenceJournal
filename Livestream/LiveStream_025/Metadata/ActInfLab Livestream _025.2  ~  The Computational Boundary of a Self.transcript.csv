"Speaker Name","Start Time","End Time","Transcript"
"Speaker 1","00;00;05;20","00;00;32;00","Hello, everyone. Welcome to Acton Slab Livestream number 25.2 today is July 13th 20, 21. And we're going to be talking about this paper, the computational boundary of a self developmental bio electricity drives, multicellularity and skill free cognition. We are here with the author, Mike Levin. We are a participatory online lab that is communicating, learning and practicing applied active inference."
"Speaker 1","00;00;32;11","00;00;55;22","You can find us at the links here on this page. This is a recorded and an archived live stream. So please provide us with feedback so that we can improve our work. All backgrounds and perspectives are welcome here and we will be following good video etiquette for live streams here. At the short link, you'll find all the live streams that we've done so far, and we're going to have a new series of live streams coming up in the next semester."
"Speaker 1","00;00;56;29","00;01;11;18","So we're going to be jumping off here with the author discussing this paper, and we will just do a brief round of introductions. I am Blue Knight and I am an independent research consultant based out of New Mexico."
"Speaker 2","00;01;14;27","00;01;25;18","My name is Sarah Davis. I'm a master's philosophy student at this point, past engineer and science artist just generally interested in how the world works. Michael."
"Speaker 3","00;01;26;16","00;01;38;04","Yeah, I'm Mike Lemon. I am professor in the biology department at Tufts University. I run the Allen discount center at Tufts, and I'm also in the associate faculty of the Peace Institute at Harvard."
"Speaker 1","00;01;40;01","00;01;50;26","Cool. So so what is something that you're excited to talk about today or something that you liked or remembered about the paper? Maybe give a heads up."
"Speaker 2","00;01;53;00","00;02;17;01","I'm the most interesting through line for me in all of Michael's work that I've looked at is this connection or this maybe tension. I don't know the way that the morphology plays with electricity. Just, yeah, which one's in the driver's seat or some kind of like understand how those two work together awesome."
"Speaker 1","00;02;17;01","00;02;22;27","Is there any, like, burning questions that you have that you want to start off with or otherwise I can just start, oh."
"Speaker 2","00;02;24;04","00;02;29;12","Now I can like that is going to happen down the road, that particular focus. So we yeah."
"Speaker 1","00;02;30;05","00;02;40;16","OK, so here we are on the paper we're going to be discussing today. How do multiple nested skills of individuality work yeah."
"Speaker 3","00;02;41;09","00;03;00;11","So I want to preface this by saying that and maybe, maybe this is obvious, but I just want to say that all of this is very much a work in progress. So I'm going to tell you what I think about these things, but I certainly am not claiming that this is all worked out or that I'm not going to change my mind at some point or that this is not going to develop in some fashion."
"Speaker 3","00;03;00;11","00;03;32;26","This is under under constant or constant work. So I think the fundamentals of all this are simply that there are multiple inter penetrating systems at different scales that are all present simultaneously. All of which can be profitably looked at as, as, as individuals. And so this diagram here sort of it looks like all it's saying is the mere fact of physical structures."
"Speaker 3","00;03;32;28","00;04;02;02","If you look you see organisms and within that you've got organs and cells. So so that's not the you know, that's sort of not the whole point of this. The point isn't merely that they're arranged this way, but that you've got some units and or some units have themselves some units, all of which are selves. And what I mean by them being selves is that the central claim of the paper is that they are to some extent so so not, not binary, but on, on a continuum of of agency, they are to some extent goal directed agents."
"Speaker 3","00;04;02;04","00;04;21;19","So they're trying to achieve certain things. And so when I say that they're nested, all of this simply means that you can have systems where the different parts are all actively trying to achieve various things in their own spaces. And we should talk about that. That's an important part that developed since this paper was written is this idea of different action spaces of these things are working in."
"Speaker 3","00;04;22;24","00;04;42;03","But, but they're nested in the sense that I think just because a higher level system requires the ball or is pursuing a goal, that doesn't mean the lower systems aren't doing it. And all of these things are in fact simultaneously doing our best to pursue various kinds of goals. So that's what I meant by multiple nested individuals."
"Speaker 1","00;04;43;10","00;05;09;16","Awesome. So is there a total 100% of individuality that gets partitioned? And something that I've been really interested in is how is information passed forward and backward across levels? Like is there some kind of course screening or like salience like dominates the information to pass forward. So how does that kind of information flow work?"
"Speaker 3","00;05;10;09","00;05;32;26","Yeah, so so the scaling and the relationship between layers is of course one of the most interesting things here. So one of the things we are currently trying to do both experimentally and with modeling, is to really show some very tight examples because this paper is largely qualitative, but we're now trying to show some very specific examples where where we can, we can actually track the scaling."
"Speaker 3","00;05;32;26","00;06;04;04","So so you have lower level subunits. So let's say you have cells that have only local metabolic goals. So all they know how to do is pursue some some energy level in a kind of homeostasis to stay alive. And so the question is how do you connect those in a way that is then going to give rise to a larger agent that has much larger scale goals that can be working towards a state of affairs and to be actually stressed by the failure to reach a state of affairs that is way bigger than any individual cell."
"Speaker 3","00;06;04;12","00;06;24;18","And so I'm not sure that there is any kind of conservation here in the sense that there's only a total amount that you sort of have to partition that among the levels. And that's all that there is. I mean, I'm not sure that's I would I would make that claim. I think that the total amount of individuality can change over time and it can rise and fall."
"Speaker 3","00;06;24;21","00;06;56;22","In fact, the boundaries between the different agents in chicken can grow and shrink. That was a significant part of the paper talking about that and why there's a couple there's a couple of interesting things that get passed upwards. And so to see it definitely kind of force screening in the sense that if you are a system whose arts are themselves competent in getting various things done despite changing conditions and so on, they're not just the hardwired mechanisms of actually competent to pursue specific outcomes despite perturbations."
"Speaker 3","00;06;57;07","00;07;20;12","What it means is that the larger system is now working in a much easier space in the sense that if it doesn't have to micro-manage all the micro states that that the individual pieces are doing, but it can rely on those components to get there, to get their job done, then what you're really working in is a much is a much lower dimensional, simpler space where problem solving gets easier."
"Speaker 3","00;07;20;17","00;07;46;03","And just as a simple biological example, you know, we now know that for example, in the in the temple, if you if you activate a signal that triggers if it happens to be by electric signal, that triggers AI information in another part of the embryo, let's say on the tail, then all kinds of interesting things will happen. It will it will build an AI, it will recruit cells that you never directly manipulate."
"Speaker 3","00;07;46;03","00;08;01;14","And so it's a local self-organization process that I will form, even though it's sitting in the middle of muscle instead of in the brain where it belongs. All of these things are going to happen anyway if you are if you're the larger and by the way, those temples can then see out of that, even though it's on the tail instead of in the head."
"Speaker 3","00;08;01;22","00;08;20;05","So if you are a system that needs to solve some problems in terms of I've got some ideas and I need to do this behavior that I'm doing. So if you don't have to micromanage all of those components and saying each cell of that I where exactly is going to go, what exactly it's going to attach to and so on."
"Speaker 3","00;08;20;13","00;08;43;23","If there is an effector that you have access to in Affordance, maybe that says build an AI and use larger systems don't need to know how that's going to happen. You can just trust that that is going to happen under a wide range of conditions. You have a much simpler space to work in in the problem solving. That's one of the things we're doing now is trying to map out some of the different spaces in which all these different agents are actually solving problems."
"Speaker 3","00;08;44;18","00;09;00;24","And trying to define what that what that means. It is also one of the things that gets passed up is this is this course horsetrading because of the lower level competency. So that's, I think, the key thing. And maybe we'll get to talking about what that does for evolution, because I think it's massively important."
"Speaker 1","00;09;03;07","00;09;04;05","No, sir."
"Speaker 2","00;09;04;07","00;09;45;22","I don't have a unfortunately they moved to change the interface. So I don't know where the hand is anymore in this. But one question that keeps coming up for me and in all the different realms of discussion about this is like, well, in particular with the bio electricity part, you use the word subroutine when you were talking about we think we're starting to understand that the whatever components works of how this works and and and also related to these nested bubbles and things like this, I, I just keep wondering if it's your sense from all of this work that you've done that in nature in, in in the communication between these levels, that there's any"
"Speaker 2","00;09;45;22","00;10;05;03","amount of abstraction or semantic layer that's needed for, for that to happen between levels and also with the electricity like subroutine implies that there's some kind of semantics that something has to rest on and that just keeps coming back to me. Do you have any sense about that?"
"Speaker 3","00;10;05;18","00;10;32;16","Yeah. So, so a couple of things. It's so one thing about electricity is that by electricity I think is interesting, not because it's in some sense of, you know, magical or there's some there's some things, you know, sort of being uniquely better about by electricity than biomechanical or biochemical modes of interaction. What I think is really interesting about electricity is that that is what is being used."
"Speaker 3","00;10;32;16","00;10;58;21","And, and perhaps these other modes, too, are too we don't know. But but electricity for sure is being used as the computational medium by which the lower levels bind together into higher level cognition. So all world of the higher systems, cognition, whatever level it may have. So what the electricity allows us to do is to directly peek into that computation."
"Speaker 3","00;10;58;21","00;11;14;23","And so I think that's why it's interesting, which is no surprise. I mean, that's exactly what people do of neural decoding. That's exactly what they hope, right, is that by tracking the electricity, they learn something about the information content of the global system. What is the, the animal or the or the human thinking about it. So it's exactly the same here."
"Speaker 3","00;11;14;23","00;11;44;17","So that's what's unique about electricity. And I think that what evolution discovered very early on is that and then it capitalize on that by pivoting it into into neural kinds of systems. And we do it in our computational devices and so on. Is that what evolution found really, really early is around the time of bacterial biofilms actually, is that now tricity is a is a great way to process information, to integrate information across distance and to do computations that shouldn't be a surprise to anybody."
"Speaker 3","00;11;45;01","00;12;12;15","So I don't know if I would claim that it has any kind of a formal syntax at these levels or anything like that. But what it definitely does to is a kind of when I say some routine, what I'm mostly leaning on is this idea of modularity, but not just modularity in form, because that's been discussed a lot in evolutionary developmental biology, but actually modularity of function."
"Speaker 3","00;12;12;24","00;12;33;21","So so the key that the thing the thing about a good subroutine is that you're going to when you activate the similar scheme, you can move along and assume that everything that's necessary to get that job done, given whatever local conditions or current events or whatever else is happening, that subroutine is going to encapsulate everything that's needed to get it done."
"Speaker 3","00;12;33;21","00;13;02;01","Meaning it's it's not just it's the difference between super people who code, it's the difference between sort of macro substitution where all you're doing is just, you know, it's a shorthand for a bunch of hard wired steps which plopping in. I don't think that's the, the magic here at all. I think what it is, is, is it's a degree of competency and that's subroutine routine to get something accomplished and that that has really, really important implications for involve ability and so on."
"Speaker 3","00;13;02;13","00;13;30;07","And what the by electricity allows you to do is to basically to have to have a language in which the system can call up such and such circuits with specific behaviors at different points or at different times. So that makes it that makes it really, really powerful. But the question of whether it has any kind of a flaw or all syntax or anything like that, I don't have a good answer for that."
"Speaker 2","00;13;31;07","00;13;56;01","I don't even mean like a formal syntax. It's it's almost like that. And this also holds true between these layers of these nested layers of organism or whatever. If there's if you have a sense that there's any abstraction there's any abstraction layer needed. And I guess you kind of answered it maybe by saying that electricity is this medium on, which things communicate or."
"Speaker 2","00;13;56;11","00;14;03;19","But yeah, anyway, that is I don't think it's an easy it's like easy to answer question, but that's the theme that keeps coming back to me."
"Speaker 3","00;14;03;19","00;14;30;23","So I think there's a lot of abstraction in the sense of in I don't know if this captures what you're asking about, but there's a lot of abstraction in the sense of generalization. In terms of another way to another way to say this is of bring me voltage itself. Let's just start with that. Voltage itself is an abstraction for cells because in fact people will often ask, I say there's a biological signal."
"Speaker 3","00;14;30;28","00;14;37;24","They say, Well, is it the potassium level? Is it the sodium level? Like what? You know, is it the particular ion channel gene in."
"Speaker 2","00;14;38;08","00;14;39;13","The jaws of the current?"
"Speaker 3","00;14;39;13","00;14;57;25","Yeah, yeah. And in particular with so so the cool thing about biometrics is that that question has been answered and we know, we know the answer. It's neither of those things. So, so it's the pattern of voltage that is specific for the downstream effects. And it doesn't matter how, with very rare exceptions, it doesn't matter how you got to that voltage."
"Speaker 3","00;14;58;00","00;15;17;09","So you can use sodium channels, you can use potassium channels, chloride. What don't you use? All those micro details don't matter at all because what the collective is feeding off of is the spatial temporal distribution of voltage. And you can get exactly the same results with sodium or potassium chloride as long as you're, you know, you're driving the rate mortgage payments."
"Speaker 3","00;15;17;16","00;15;41;25","The voltage itself is a really cool abstraction because it means that all the downs, the underlying mechanisms are free to diverge in evolution. You want to swap out a potassium channel for a sodium channel. You can do that as long as you've got the right functional properties so that your, you know, your overall pattern, not state. And we use that quite often in our regenerative medicine application for the really convenient so."
"Speaker 3","00;15;41;26","00;15;54;29","So yeah, so so the biometric code itself, it's definitely an abstraction over what the micro states in terms of specific ions or the specific channel genes that got you there thanks."
"Speaker 1","00;15;57;02","00;15;58;16","Stephen, did you want to say hello?"
"Speaker 4","00;15;59;02","00;16;27;02","Yes, hello. Hi. Hi Michael. Thanks for joining us. You know, I was curious, we had a really interesting Chris Field gave us a really good insight into the quantum context reality idea of how things could build up from different sort of space states, very small levels and active inference often uses non equilibrium. Steady state attractors is kind of a way to look at some sort of statistics between the scales."
"Speaker 4","00;16;27;02","00;16;53;04","You know, there's some sort of flux or slow that's inferred and I find it really useful thinking about it with this code idea that you bring to the table because there's more it's more of an idea of a distinct swarm mean going into a structure and some sort of system that might emerge from that which is sometimes lost when it's very much in the math."
"Speaker 4","00;16;54;17","00;17;17;12","And I'm curious whether when you think about these, the biometric effects and the same sort of question came up with quantum contextual as you may be, is, is, is there more of a distinct style at which there's a coherence? You know, like you've got the cell membrane, then you've got a coherence around which the bio electrics can operate, so to speak."
"Speaker 4","00;17;17;12","00;17;45;15","And then you might have another distinct level at which the biometrics can operate, which is maybe more at the more grid dated idea of steady state statistical sort of manifold. So I was wondering if what your thoughts are about how and where there's sort of chaos at which the bio electrics become particularly coherent, if that even happens yeah."
"Speaker 3","00;17;45;20","00;18;15;18","I mean, so so again, prefacing this by saying that the bio electrics is not an essential part of the story in except insofar as I think Morphogenesis is a is a nice example of an unconventional agent within which to play with these kind of ideas, you know, so it's and so what I would like to do, and this is some framework that I've been developing recently, is to get away from the standard sorts of living creatures that we're used to."
"Speaker 3","00;18;15;18","00;18;44;10","Right. So so the products of that one trace of evolution in the biosphere on Earth, and to go beyond that and to look at the space of possible agents, of space of possible bodies and the space of possible minds that those bodies will support and think think more broadly. So in doing that, what I think the biometrics in morphogenesis, I think that morphogenesis is a nice example of an unconventional agent that lets us see how the framework is to be practically applied."
"Speaker 3","00;18;44;18","00;18;59;13","Right? So so people say, okay, this is all well and good, but what you know, what use is it? That's OK. Let's, let's apply it to a specific thing that really no one thinks of as a as a cognitive agent. I'm going to show you how all this stuff maps and why it's useful like a bench and it helps to do experiments."
"Speaker 3","00;18;59;13","00;19;27;04","So so if we if we accept that morphogenesis is kind of a test case for and there are many others, it's certainly not unique, but it's a test case or an unconventional place to find agency and all of that and to test out how well this theory helps. So then what's cool about fire electricity is that it actually allows us to tell a very specific, mechanistic, testable, empirically useful story about how the information flow happens and how the level scale."
"Speaker 3","00;19;27;14","00;19;47;16","But it's just one, you know, it's just that it just happens to be how the more genetic self does things and there are plenty of other interesting cells that wouldn't have anything to do with biology visually. Make that make that clear. Right. The bio tricity is not so you know, some sort of essential element that's always going to be present whenever we apply these things."
"Speaker 3","00;19;47;16","00;20;08;08","It just sort of it's central to this, to that, to the example case that I've trotted out, which is which is morphogenesis. Now, having said that, biologists and it's definitely multi scale because you have you have you have five electric dynamics in organelles and on very small scale, you have the resting potential across the cell membrane, which is mainly what we study."
"Speaker 3","00;20;08;19","00;20;34;26","But those scale into tissues and you have global electrical fields which are driven by transient ethereal potentials on the scale of tissues and organs, which other people like Menzel and many other people study. And then past that you have whole animal like whole body scale fields as well. So all of these different levels exist some of them more and some less rely on bio electricity."
"Speaker 3","00;20;34;26","00;20;44;12","But yeah, it's relevant in this particular unconventional agent, it's relevant to all the scales that we just we know coming out."
"Speaker 4","00;20;44;12","00;21;03;21","That's really helpful. Thanks. And and would you say that the cone concept could be extrapolated to other types of motifs? Or Western blanket type ideas? And I just wonder what your thoughts on that or whether that just confuses things. You try that, but."
"Speaker 3","00;21;04;00","00;21;24;29","No, I don't think it confuses now. I should I'll say I'm sure. No, I mean, I like Carl's ideas very much. I'm by no means an expert on the map, and I'm not going to pretend that I understand all that. But I think that the thing about some of these kind of diagrams is they're not to be they're not meant to be unique or exhaustive."
"Speaker 3","00;21;25;06","00;21;49;11","So was the goal of this originally this this came about a couple of years ago at a Templeton meeting where we were asked to brainstorm ways to define almost the sort of idea in space where you're you're able to compare directly really diverse intelligences right. So so things where you don't you can't just measure all their brains and then see how they you know, how they shake out."
"Speaker 3","00;21;49;12","00;22;21;00","It's really, really diverse intelligence. And so that's what I tried to come up with is a scale. And it's all focused around the spatial temporal scale of the goals that any given agent can work towards and the scale of state of affairs that can be that can stress out that agents when they're not being met, so on as a way to pick on something that I think is central to all agents, no matter what they're made up, no matter how they got there, involve design combinations, computers, whatever, wherever they came from, whatever they are."
"Speaker 3","00;22;21;05","00;22;42;18","What is essential to them and I think this this goal directed to split, but this is compatible with all kinds of other systems. So you could overlay on top of this almost anything else that you thought was critical about being an engine. It just start adding dimensions, you know, and absolutely right now you can you can just you can this this is compatible with all sorts of things."
"Speaker 3","00;22;42;18","00;22;51;22","This is not meant to rule out any other anybody else's, you know, favorite and favorite framework. This thing, it captures one slice of what's essential about being ourself."
"Speaker 4","00;22;54;07","00;23;23;03","Thanks. That's really useful as you can I just one more thing. I just was actually very interested in this. I do a lot of work with community psychology so there's this challenge of going from the sound. There's like the self and then this society social, but the intersubjective kind of group dynamics. Is this a big problem because it's like a big hole because and this I find this really useful because a lot of stuff which talks about how groups they often try to project out into the future as if it's a light beam that you could measure."
"Speaker 4","00;23;23;03","00;23;57;28","Whereas here it's much more like it sits in in the swarm in, I like to think the bottom of the cones, almost the swarming dynamics that go down into the past, you've got the kind of structure of the cell that's emerged and then the system that's able to go into temporal depth in the future and the code. And I think that that offers a nice way to think about group dynamics, particularly maybe the more ironically the more challenging group dynamics where there isn't a coherent single narrative."
"Speaker 4","00;23;58;12","00;24;00;10","So there might be applications there."
"Speaker 3","00;24;00;25","00;24;29;08","Yeah, this is this is super, super interesting. And I should I should say one of the things about the code and we had a discussion about this yesterday and pronounced us pointed out that my phone compared to Mikulski's font is upside down. Right. It's and the reason I did it this way was because if you think about where in any any given agent the only thing the given agent is really certain of at the at the moment is what's going on right now."
"Speaker 3","00;24;29;15","00;24;47;18","So your future obviously is uncertain and when you're trying to predict so so let's say you're trying to manage goals and you're trying to predict you've got some predictive capacity going forward that predicts which capacity doesn't get better over time and gets worse over time. Right. You're you're sort of exponentially more uncertain about what's going to happen later on."
"Speaker 3","00;24;47;18","00;25;15;24","So your ability to pursue those goals in the future gets smaller and smart. Same thing goes back in the past. Or you could argue that that's linear and not exponential. But again, what you're doing at any given moment in time is inferring what your past was from the engrams of memory that are available to you. They might be a brain, they might be a stick magick, a medium that you live in, you know, within if you're in a different command college or whatever, it's going to be you've got some kind of material in which you leave, which in which events leave memories."
"Speaker 3","00;25;15;24","00;25;46;02","They leave traces at any given moment. You are reading those traces recalling them and reconstructing what you think the past was. That's your only evidence for what? The past. You know what actually happens and so and so and so and so. We've been going backwards. My calling comes down because your ability to go backwards in time and be certain of what went on and what are one of the facts on which you can now build your goal directed strategy going forward become more and more uncertain going back."
"Speaker 3","00;25;46;08","00;26;10;27","So so that's why my you know, my colons are upside down so to speak, because also because there's no particular reason to test to map exactly on houses formalism. But but I think it's close that just because that that that your level of certainty is highest right now both in space and time. When you step away from that, it rapidly, you know, at least for all of us rapidly it gets smaller."
"Speaker 1","00;26;12;26","00;26;32;05","Yeah. We were really actually talking about this last week in our discussion and we were kind of thinking about this as like an information coming because you have the most information about your environment at this point in space and less information as you go forward and backward in time. So do you think that that might be the correct way to think about it?"
"Speaker 3","00;26;33;01","00;27;02;26","So so that's true and that that's absolutely true. It's definitely also an information point. But I want to be clear about this because this diagram is not a diagram of what you can sense or how far your reflectors range this is. This is the that what you just said about the information certainty is the consequences of that are that you also have a limited cone in what the diagram really is supposed to show, which is the scale of the goals towards which you can work."
"Speaker 3","00;27;03;09","00;27;29;18","So so because the information is smaller, your ability to pursue goals towards how far into the future are actively doing it, it just it just becomes limited, right? Your your ability to do so. So it's sort of a secondary consequence of that. But I just want to be clear that this this is not meant to be fundamentally a picture of information, certainty of sensory capacity of effector range or anything like that."
"Speaker 3","00;27;29;18","00;27;33;10","This is this is a diagram in in goal space."
"Speaker 1","00;27;34;11","00;27;55;01","Nice. So one of the other ways I've been thinking about it is kind of like a possibility cone. So like as you progress forward into the future, we all are left with one possibility and that's like death, right? So your goal at that moment is death. And similarly in the past, like we all come from a single celled like, you know, fertilization event."
"Speaker 1","00;27;55;01","00;28;03;14","And so like we all started an event and ended an event and like the maximum possibility is, is now. So what do you think about that?"
"Speaker 3","00;28;05;18","00;28;33;07","Yeah, I mean, so so that's a really interesting point, right? And people talk about, you know, great transitions in in in cognition along the continuum and so on. And so I think one great cognition and a great transition is the following. You know, if you are a creature with a horizon with with a with a cognitive horizon, of, you know, a half an hour, your goldfish or something, I don't know if this is factually true, but, you know, you're so you're some sort of form that has a cognitive horizon of a half an hour."
"Speaker 3","00;28;33;07","00;29;08;09","Right. What that means is that all of your major goals, survival and these other things, they're totally achievable. Right, because they're just completely plausible that you are going to make it for that half hour that you can project forward if you are a human in your cognitive mores. Your goals are, you know, I don't know, world peace or your buildings that, you know, the larger things you are for the first time, perhaps along the Earth's lineage anyway, you are able to to to comprehend goals that you have no chance whatsoever of achieving because you because you because you have a limited lifespan."
"Speaker 3","00;29;08;16","00;29;28;00","So now that's and that's that's a really sharp transition, you know, kind of an emergent transition because for the first time, you are able to undertake goals that, you know, you are not going to complete guarantee. Right. Whereas the fish, I mean, you'll get eaten that maybe you won't, but suddenly plausible that you you know that you live for the half hour that you can see forward for that humans have."
"Speaker 3","00;29;28;07","00;29;50;06","And so I suspect that this is this is sort of way above my pay grade to know details about this. But I suspect this drives a lot of the weird the facts about human psychology because you now have this fundamental stressor that other creatures don't have because you are able to foresee all these goals that you are definitely not going to meet."
"Speaker 3","00;29;50;15","00;30;00;19","And that's that's a novel you know, sort of a conflict between the different modules that that doesn't doesn't exist for anything for most other creatures."
"Speaker 1","00;30;02;16","00;30;37;14","Yeah, that's really interesting. You know, something that I might be like uniquely human is like this possibility to see past like the cone of our own existence, like into the future with these, like, future possibilities or future goal states. And also, like, backwards into the past in like a historical sense. So we all like look at history. So I don't know, I like thinking about like, you know, I was reading your recent paper this integrating evolutionary developmental thinking into scale for you biology, this fit with this field."
"Speaker 1","00;30;38;10","00;30;59;24","And I know like when we spoke yesterday, you mentioned you were integrating these ideas maybe into your next paper. But in that paper, you guys were kind of blurring the boundary really between the processes of evolution and development. And, you know, phylogenetic memory that's contained of DNA and results revolution like transforms into this unheard genetic."
"Speaker 3","00;30;59;24","00;31;25;01","Yeah, yeah, definitely. So so there's a couple of really interesting things related to that evolution that we we can talk about. And that's that's something I'm working on now. And this thing should be done in a couple of weeks. See, to two things. Number one, one of the things, but one of the amazing things about biological hardware that it's given to us by evolution is that it is there's a default way."
"Speaker 3","00;31;25;01","00;31;55;03","By that I mean cells with their genomically determined proteins where they have there's a default and a pretty robust, consistent default outcome. Right. And so so embryo can fish embryos make fish and so on. But there's an incredible amount of plasticity there so that those exact same cells genetically, while that sort of hardware results in are in fact in other types of environments, that are able to make completely novel features."
"Speaker 3","00;31;55;03","00;32;19;06","Right. And so some of this sort of synthetic synthetic biology, synthetic morphology is already showing this is our zone, a bunch of things like this, and there'll be tons more going forward. That one central one. One thing that's interesting about those novel creatures is that you don't have a long history of so specific selection in frozen accidents and all this, you know, fiber genetics to lean on."
"Speaker 3","00;32;19;06","00;32;53;22","When you ask why do they do certain things right? So for every normal animal in the biosphere, you say, why is this thing, you know, green and why does it fly and how come it has these antenna? The answer is always the same. Well, because for millions of years the ancestors were selected for this thing the fact that we can take those embryos and those cells so cells from, from, from those kind of animals and put them together into a new creature that has goals and behaviors, morphological goals, behavioral goals, physiological goals that basically appear overnight, you know, within 2448 hours they sort of show up."
"Speaker 3","00;32;54;21","00;33;18;01","And then the, then the question is where did these things come from? Because what they didn't do was to be honed over millions of years by specific selection pressures. So, so that, that's very interesting to me. To me aspect of the plasticity here that it is not, you know, the history doesn't necessarily determine them other than the default that, you know, sort of varies and where does that come from?"
"Speaker 3","00;33;18;07","00;33;36;15","And then there's the whole thing which I don't know. You can tell me if you want to dove deeper into this or not, but the whole the fact that you have multiple layers and that you have competency going down, you know, sort of all the way down has massive implications for why evolution works so fancy. Right? Why why?"
"Speaker 3","00;33;36;15","00;33;42;21","Actually, anything is able to evolve on on the timescale that we see. So I think, you know, if you're interested we could we could get into that."
"Speaker 1","00;33;43;01","00;33;45;01","Yeah, that's great. Why don't we unpack that?"
"Speaker 3","00;33;45;22","00;34;15;21","OK, yeah. Let's, let's, let's let's talk about that a little bit. Imagine imagine two kinds of creatures. And you've got one kind of creature where the genome has a pretty direct influence over what the anatomy is going to be. It's I mean, everything is hardwired. And so in some sense. And so let's say let's let's let's visualize. You've got let's let's say it's a you know, it's a frog of some kind and and there's the genome and it makes a frog and that's what it gets."
"Speaker 3","00;34;15;21","00;34;38;19","And so now now imagine evolution is sort of searching the space. And now there's a mutation and the mutation does two things because most mutations do multiple things. Let's say we got a mutation that this two things, it moves the eyes off kilter. Right. And it also has some really beneficial effects somewhere else. You know, it helps with some other thing as most mutations are appropriate."
"Speaker 3","00;34;38;19","00;35;00;12","So it's it's it's a reasonable and reasonable conjecture. If you're if your animal is the hardwired kind, the eyes are in the wrong place, nothing works you the evolution never gets to explore the positive benefits of this other mutation because the thing's going to be dead, you know, it's just it's just not a workable animal anymore. The fitness is very low."
"Speaker 3","00;35;00;14","00;35;18;22","It's gone and so you most if you think about these kind of hardwired things, it's the same when I when I first started, you know, 100 years ago, when I first heard about how evolutionary algorithms are supposed to work, this idea that I've got a system that doesn't, then we start throwing random changes in anybody that's written any code that crazy."
"Speaker 3","00;35;18;22","00;35;40;15","Of course, everything's going get worse, not better. That's never going to work. Now imagine imagine a different now of course it works, but it takes it takes massive amounts of time. And so there's always the difficulty of all the complex things. Now, imagine what we actually have the actual and I'll explain the biological example. That's when you have you have a temple and the temple has to move all of its organs."
"Speaker 3","00;35;40;15","00;36;02;14","Craniofacial organs are on to become a fraud. So the jaws have to come out, the nostrils move the eyes move forward. Everything, all this stuff moves around. And you could have a hard wired animal in which every every organ moves in the right direction, a particular distance. And that's it, right? And that's that's your hardwired thing that actually is not what animals work."
"Speaker 3","00;36;02;14","00;36;25;17","So so if we into what we did a few years ago as we made what we call these Picasso temples, the idea is to make these tadpoles, everything's in the wrong place. The eyes are on the back of the head. The mouth is off to the side. The nostrils right here, like just France. Mr. Potato scrambled. So if it was a hardwired system, then all of these things would move the traditional amount in the traditional direction and everything would be way off because you're starting in the wrong spot."
"Speaker 3","00;36;26;02","00;36;43;25","Instead, what happens is that all of these organs move in novel paths and they keep moving, and sometimes they overshoot and have to come back, but they keep moving until they build a correct frog face and then they stop. So now that system. So so what the genetics actually gives you? It doesn't it doesn't somehow give you a hardwired set of movements."
"Speaker 3","00;36;43;25","00;37;12;18","What it does do is give you an error minimization scheme that can progressively deform the system until the error from some sort of set point. And we've been studying what this point is. We talk about that until the error from at some point gets to an exceptionally low level. So what you have here is a competent instead of breeding facial organs that are going to move around and get to where they need to go, even if they start off in the wrong position."
"Speaker 3","00;37;12;23","00;37;30;09","So now look at what happens with evolution, right? You got your mutation. The eyes in the jaws now are off in the wrong place. But now you've got this benefit somewhere else. The thing is, the eyes and the jaws are going to get fixed. You don't need to worry about that because they're going to they know where they belong and they're going to get there, even though they start out in the wrong position."
"Speaker 3","00;37;30;23","00;37;53;24","So that aspect of that negative aspect of that mutation gets hidden from selection for a while anyway, because it eventually will catalyze into into the genome itself. But but for a while, it gets hidden from selection, allowing evolution to explore the benefits of the other benefits of that mutation. So so here's the all in summary. Here's, here's what this means."
"Speaker 3","00;37;53;24","00;38;26;03","The fact that you have competent subunits and they're competent morphologically the competent physiologically we can talk about what that means. The fact that they're all competent means that we the fitness landscape is much less rugged. It's much it's much smoother it means that your the effects of mutations are much more linear, meaning that you can you can examine each consequence independent because the other consequences can be masked by by things, but by the local environment being off, it doesn't matter."
"Speaker 3","00;38;26;18","00;38;47;01","It'll still get where they need to go and connect and so on. So so it makes it makes the search process way more easier by by allowing you to and it gives you patients. It means that evolution doesn't have to solve every problem at once. You don't have to wait until you find a mutation that gives you a positive impact and leaves the eyes where they need to be."
"Speaker 3","00;38;47;10","00;39;13;29","You don't need to wait for that. If you can, you can grab the first mutation you find. It gives you the positive impact because the thing will get taken care of because because those 7 minutes or so is what raises the IQ of the whole system. The search becomes so much a much smarter search, and it has some patients it's able to see linearly instead of it sort of highly mechanics stuff, all of the consequences and some patients and its moods, the fitness landscape."
"Speaker 3","00;39;14;05","00;39;34;17","So I think when you can count on you are you are components to do some of the heavy lifting. You don't have to micromanage all of it. The evolutionary search gets massively more efficient and now it starts to become a little more plausible that we actually see this this amazing biosphere actually evolves by a process of random mutation."
"Speaker 1","00;39;35;25","00;39;59;28","Nice. So in that same paper, you talk about random mutation, but then you also describe this kind of modularity of gene groups and the possibility of entire gene families like the hearts cluster duplicating and driving the major evolutionary transitions. Is this the sort of nonrandom process sort of ergot the city breaking with perhaps like nonlinear effects when these entire clusters?"
"Speaker 3","00;39;59;28","00;40;25;29","Yeah, I hesitate to say too much because I don't think much is known there that I can say definitively. I think that, you know, this whole issue of random and non random mutations is very controversial. Obviously, I suspect that there is a notion of mutation of of evolutionary search that's not quite blind. So some people often will argue, you know, either they most people nowadays say evolution is completely blind."
"Speaker 3","00;40;26;04","00;40;48;17","You know, it just that makes these mutations, whatever happens, is not because of any directionality in the search stage. And then and then, you know, you have you have people who think that it's directed towards a specific outcome. I think there is a there's a sort of in-between scenario where it's definitely not directed in the sense that you can see far forward in the search space."
"Speaker 3","00;40;48;25","00;41;20;01","But it doesn't have to be completely blind in that maybe what it has and this this comes out of some discussions I've had with both Chris Fields and Richard Watson, that that maybe instead of a point in fitness space, what you really have is a little bit of a vector. You have almost like a comet trail, right? And then it gives you a little bit of a little bit of information about direction and about, you know, and, and, and you can imagine I mean, I can sort of design in my head an epic genetic system of marking things on the DNA that give you a little bit of information."
"Speaker 3","00;41;20;01","00;41;38;14","Well, what was this, a wheel last time? Right. So that you can sort of say, well, I've been turning it I've been turning this knob in this direction and things are going well. So maybe I want to turn. It's more of that kind of thing. And it's totally made up. I'm not saying that we know that biology actually doesn't just mean maybe maybe it doesn't, that maybe synthetic biology maybe we implement something, you know, just for the first time we engineer it."
"Speaker 3","00;41;39;00","00;41;52;04","But I think it's possible to make a system that does that. Then maybe collections of genes and some of the complex chromatin epigenetics that go on, maybe they're part of that process. But this is this is total conjecture at this point."
"Speaker 1","00;41;53;01","00;42;09;28","So, Sarah, they have a question, but I'm going to use my moderator's privilege here and just ask, do you think that this vector driven mutation could be perhaps driven by active inference, some kind of vector between exploration and exploitation happening yeah."
"Speaker 3","00;42;09;28","00;42;45;26","And so and so one of the things that that we've we talked about, I mean, that that I'm going to write after this next thing is, is is really at the on this idea that maybe the whole evolutionary evolutionary lineage of a particular of particular the animal plant or whatever it is, maybe that's the maybe that's an agent as well, just stretched out massively over space such that each at any given point in time, all of the all of the existing examples of that species are in fact hypotheses about the space."
"Speaker 3","00;42;45;26","00;43;11;04","Right. And that what you're doing, what what you're doing is you're constantly generating genomes as, as hypotheses. And some of those genomes are proving to be some of those hypotheses are proving good and some are not. And then the next, you know, sort of the next set of genomes is not completely random, but it's in some way a part of this part of the active inference of this giant sort of, you know, virtual agent."
"Speaker 3","00;43;11;05","00;43;17;17","Right. So I think there's a story to be told like that, but it's way more hand-waving than details at this point."
"Speaker 1","00;43;18;03","00;43;19;13","Awesome. Thanks, Sarah."
"Speaker 2","00;43;20;04","00;43;49;15","Yeah, my comment is now maybe a little bit stale, but I think I'll I'll put it out there anyway, just for the sake of making the saying something concrete, because a lot of this feels a bit abstract like and I'm hoping I'm even remembering this anecdote. Right. But I remember learning that some gene once upon a time that gave us an extra water cone or I allowed us better color reception also was the same gene that showed up our ability to make our own vitamin C."
"Speaker 2","00;43;50;06","00;44;16;15","And if that's correct, if I'm remembering that correct, that's such an interesting example of of yeah, of course is an example of the fact that genes do multiple things. But it was kind of like, isn't that coincidental? You know, that that this that that gene is is doing, you know, both something for the eye, but then also making it so that you can get your own vitamin C, you know, by looking at fruit."
"Speaker 2","00;44;16;15","00;44;24;18","And I just thought that was that that kept coming to me as an example of what you guys are talking about, but it's still sort of think so."
"Speaker 1","00;44;24;19","00;44;41;06","And sorry for making your comments still Stephen yeah."
"Speaker 4","00;44;41;06","00;45;08;22","Sort of following on is this you have this idea of like the goals space or theological space in a way that's really interesting. And then with that exploit or explore, I wonder if there's a time when there's there's there's a thought about when things are very directed and of course, our Western thinking, we we tend to think about nice pointy cone where we go into the future."
"Speaker 4","00;45;08;22","00;45;37;08","We because we see the world around us and we maybe have like a a distinctive trajectory because we kind of we construct in our world more and more, which is probably part of our problem and make it the way we want it to be. Whereas specifically, if you look at indigenous cultures, they would have no encyclical, the more strictly cool approach, which would go through seven generations or different levels of generations and would be attuning to the environment."
"Speaker 4","00;45;37;08","00;46;16;04","And I'm kind of curious whether and again, this might be where we don't really know, but is there a point at which there's a generally trying to come back or maintain in the Anastasia's the kind of the cyclical pattern that is where we want to go to and is there a time where it's like, OK, we're, we're branching out now, like we've made a jump and we're going to try and inscribe our environment at different scales in the body out to sort of now maintain some new kind of steady state attractor and how that might fit with this yeah."
"Speaker 3","00;46;16;04","00;46;39;24","I mean, I think I think you're absolutely right in that some future version of this is going to have to be able to deal with goals that are not only not static, meaning they're cyclical, but also goals that are themselves, you know, let's say second order goals. Like if like my my goal is it's a derivative. My, my goal is to get better at something."
"Speaker 3","00;46;39;24","00;47;04;01","It's not a particular level that I'm looking for, but I want a particular slope of some variable being rates or something like that. So so you're absolutely right. I started out with the simplest you know, this is sort of the hydrogen atom of this thing. So I started out with something very simple that it's homeostatic as in your your goal is, is to achieve a particular region in whatever space you're solving."
"Speaker 3","00;47;04;01","00;47;19;15","Problems and be that more for space or physiological space. Your goal is to find that region and sit there. And that, of course, is not all there is to life. Obviously, that's just the first kind of I just do that for simplicity because I want to tackle everything at once and there needs to be a lot done here before we get to that point."
"Speaker 3","00;47;20;06","00;47;49;13","But yeah, you're absolutely right. Your goal stayed in that space may not be a point of maybe some interesting, bigger, bigger, bigger shape and this thing. And I just want to I wanted to say something about these goal spaces because I think it's interesting to point this out. So one of the in this in a way, this all came out of a meeting of diverse intelligences and so the one thing I've been thinking about is what what is intelligence and what are these teachers actually trying to do?"
"Speaker 3","00;47;49;29","00;48;09;26","And OK, so so we have lots of examples of problem solving in three dimensional space, right? So you've got, you know, crows and monkeys and everything else. And they're running around and trying to solve problems by moving around in three dimensional space. But all the different subunits of the of bodies are solving problems in other kinds of spaces."
"Speaker 3","00;48;09;26","00;48;30;21","So we talked about more physics. So if you are an AI in the head of a frog, you are working in a space of possible configurations of where you are relative to everything else and you are trying to move and act in a way that is going to to to acquire to a particular region of more of a space that describes that that the correct branch."
"Speaker 3","00;48;30;21","00;48;54;29","And that's that's where you're trying to land there's also a physiological space. So I'll just give you a simple example of this that we found recently. So so these, these flat worms, this plant area you take these plant area and you throw them in barium, OK, so solution apparently. Now what happens is the barium is a nonselective potassium channel blocker it blocks all the potassium channels, all the cells freak out there."
"Speaker 3","00;48;55;10","00;49;15;27","Their heads literally explode right over overnight. Their heads just degenerate. They're not if you take those clean area and you leave them in fresh barium over the next ten, 20 days, what they will do is they will build new heads that are completely barium. And since it couldn't care less, no problem at all, they live in barium just fine."
"Speaker 3","00;49;16;05","00;49;52;28","So we asked a simple question and not now because the answer has to be this, but just because that's the tool that that was available. We asked the simple question What is transcription only different about barium adapted heads from normal hits, right? So what genes are different differently expressed in these in these heads? And so what you find out is that out of tens of thousands of genes that these one area have they managed to regulate a very small number on the order of a couple of dozen that allow them now to do their business despite the fact that potassium is no longer usable for them so now this is incredible because think about the"
"Speaker 3","00;49;52;28","00;50;14;03","problem that they're solving. And in my head I always visualize like one of those nuclear reactor control rooms with buttons everywhere. So each button is a different gene. You can what are you going to do? You have a physiological stressor. You can't pass potassium, everything. Everything's going to happen. You have some tens of thousands of genes that you could turn on and all the combinatorics are astronomical."
"Speaker 3","00;50;14;13","00;50;39;28","You don't have time to trying them all. You don't even have time for gradient descent. You don't reproduce fast enough. It's not like bacteria where you could say, well, they're all random, and then somebody will survive and repopulate. They don't they don't divide that fast. You don't have time for any kind of evolutionary explanation within some small number of days, you have to hone in on a small number of genes, knowing that if you just start randomly flipping them up and down, you're going to make things worse."
"Speaker 3","00;50;39;28","00;51;00;11","Long before you make them better. You're going to kill everything off. You just randomly start. So now the other important fact about this is that you never see barium in the wild. So there's no evolutionary history of being good at surviving in barium because they don't see there. So now to me, this is an amazing example of problem solving in a high dimensional virtual space."
"Speaker 3","00;51;00;11","00;51;29;20","You've got this, you've got this physiological space, and your problem is, is your your problem is physiological, your effectors are transcriptional largely. Of course, you have physiological factors too, but you're trying to walk in this, in this space and you have to somehow map. And it's unbelievable how they do this. You somehow have to map you are effectors in transcriptional space to what's happening to you in physiological space and then rapidly get to a a workable, a workable region."
"Speaker 3","00;51;29;24","00;51;49;27","So, so bad. That gives you an idea of what of what we're talking about, right? These spaces can be transcriptional, physiological, all kinds and these things, and they solve their problems. And you and like you pointed out, the correct the thing you're trying to achieve may not be a point. There's certainly not a point in that space, but it may not even be a static area."
"Speaker 3","00;51;49;27","00;52;01;27","It may be sort of I would like to sort of wander in this kind of weird loop. That's that's my goal is to wander and sort of weirdly shape the track. Yeah. Well, we'll get to that. This is just first step."
"Speaker 4","00;52;02;28","00;52;38;19","Just just one. Oh, so just just it's just one question. Following up from that, just before so if I'm right, what you're saying is gradient descent, because that would have to come so from where you are and slowly keep incrementing you there's somehow some there's some go states. I mean the maybe there's some evolutionary history, even if it's not barium, something like barium but somehow it's not it's not only coming from adjacent possibilities, it's somehow jumping ahead is that what you're saying?"
"Speaker 3","00;52;39;03","00;52;54;02","So so the first thing I'm saying is that I don't have any idea how it works. Right. So so I do not I am not claiming I have a good model for what's going on here. But but I think you're onto something, which is that I think and I think we talked about this a few minutes ago, which was abstraction and generalization."
"Speaker 3","00;52;54;02","00;53;13;16","I think you exactly right. I think what the system is able to do is to say, OK, I don't know what this barium is, but I've been terribly depolarize before. It was an epileptic kind of a thing. And this is an awful lot like that. So I'm going to generalize what just happened to this other thing that I do know how to deal with."
"Speaker 3","00;53;13;22","00;53;36;18","Right. And I'm going to move in that direction. So that's my that's my gut feeling. I don't have a solid model for this. That's not been proven in any way. But I have a feeling that you're that that's where the answer is going to be. It's going to be that and that it's able to do this because it is able to recognize this physiological problem as an instance of a larger class of things for which it does know how to do."
"Speaker 3","00;53;37;04","00;54;10;15","And I think that when we talk about intelligence for all of these agents, what we're really saying is it's your ability to navigate these various spaces efficiently and without getting trapped in local minima that they kill you. Right. Being being able to step in temporarily you know, it's that patience. It's that it's that being able to step away from the direct line to your goal to then come around and and get I have an idea sometimes when I talk about this, I have a picture of business of there's a fence and there's a couple of dogs on either side of the fence, and they're just trying to get at each other."
"Speaker 3","00;54;10;15","00;54;35;26","Right. There's a hole in the fence four feet away so they can do it. The problem is a temporarily requires you to get away from get further from your goal. Right? So that ability you're trapped in this local, local, local maximum and that your intelligence is is directly proportional to your ability to temporarily get further from your goal in order to actually get into a better position later on part of the IQ."
"Speaker 3","00;54;36;01","00;54;46;08","But I think the other part of that IQ is this kind of generalization. Right. And I think you're right. I think that's probably what this going to end up explaining next."
"Speaker 2","00;54;46;10","00;55;20;05","Sarah Yeah. This is great. I this is this question is probably out of bounds. But if you have any thoughts on it, then great. If not pass. I mean, this the the cone type diagram and the the a general Helios that it assumes. I'm just wondering if you feel like there's any applicability to to non general type phenomena like complex systems or hurricanes or whatever because in just when we're just talking about abstraction."
"Speaker 2","00;55;21;18","00;55;25;19","Yeah. I'm just wondering if you have any thoughts about where that can go anywhere."
"Speaker 3","00;55;25;27","00;55;49;28","Yeah. So, so the thing I'll say about that and I'm sure in this is this is not, you know, this is the kind of thing that's probably not, not, not, not a lot of people will agree with this, but this is my view. I need to say nonessential presupposes that you can draw a binary sharp line. Right. And between things that are agents and things that are not I don't really believe in that."
"Speaker 3","00;55;49;28","00;56;13;20","I think that's the view that gets us into a lot of trouble by looking at these looking for these sharp lines. I think that all there is is a degree of agency, and I'm not sure we aren't. We talked about yesterday whether there's such a thing as zero. I don't actually I'm not even sure there's a zero. But certainly there are there are things that are very very sort of non, you know, very, very low levels of agency and and things that are very high."
"Speaker 3","00;56;13;20","00;56;29;15","And everything is a smooth continuum. So now then, so so then then then the question is, OK, so what do you do with hurricanes and things like this? So I drew and this will be this, you know, in the next in the next paper, there's a thing. There's a thing that I call it's an axis of persuade ability."
"Speaker 3","00;56;30;03","00;56;45;15","And it's so it's sort of related to then it's intentional since in the following way, there's that there's a there's a continuum and for any given system. So so my claim is that it's an empirical problem. You can't say whether something is or is not an age. And lots of people do. They'll say why and that's not an issue."
"Speaker 3","00;56;45;22","00;57;08;24","I think you can't say that until you've done the empirical work. And the empirical work looks like this all the way. The question is this as an engineer. So this is very much an engineering perspective as an engineer, how much work do you have to do? What do you need to know about the system and what kind of work do you have to do to be able to control and predict its outcome?"
"Speaker 3","00;57;09;00","00;57;26;24","So I just give you a couple of examples. All the way on the left, you have things that are like mechanical clocks. So if you're dealing with a system that's like a mechanical clock, you know, you can put it on the left of this of this diagram because you are not going to reason with it. You are not going to train it, you're not going to be able to punish it."
"Speaker 3","00;57;26;24","00;57;48;22","You're not going to be able to rewrite it's goal states. You have to you have to know how it works and you have to micro-manage the hardware and you have to make you have to rewire the physics of it to get it to do something else. OK, then we on from that. You have something like a thermostat and with a thermostat you're also not going to reason or punish with it or punish it."
"Speaker 3","00;57;49;06","00;58;06;28","But there is a separate set point. And if you want the room to be kept in a different temperature range, you don't have to rewire the thermostat. You can change the set point. So as in and this has massive implications for regenerative medicine, we can we can talk about the way you relate to the system is quite a bit different now."
"Speaker 3","00;58;06;28","00;58;31;08","After that, you might get to systems that have preferences in the sense that you can actually train them, meaning you can provide rewards and punishments they will change their behavior because what you're doing is you're relying on them to be a kind of learning system because they're able to do associative learning so they associate certain things you've done to them with things that they did, and they will change their behavior."
"Speaker 3","00;58;31;15","00;59;01;06","So now this means that we can now, now think of what this means, you know, humanity has been training animals for, I don't know, 10,000 years, whatever, with knowing nothing about neuroscience, it means that you don't actually have to know what's going on inside your system. You don't need that micro level hardware information. What you all you need is to, to, to know that that animal, that that system is actually a is that it has that level of agency that it's susceptible to this kind of interaction."
"Speaker 3","00;59;01;10","00;59;28;08","And how do you know? You don't know until you've tried. So we have no idea. So one of the things we're doing now with Charles Abrams, who's a behaviorist of the scientist, where we're actually writing a how to manual know how to paper on if you are given some sort of weird new synthetic system, how do you know where along that and there's actually has a bunch of a bunch of experiments that you do to figure out where you are along this path so you can go further."
"Speaker 3","00;59;28;16","00;59;46;28","And there are other systems where you know nothing about what's inside. And in fact, the amount of energy that it takes to manipulate them is tiny because you can you can give them reasons as opposed to causes. And you can you can give them information and they will act on this information and do various things, this source for sophisticated agents."
"Speaker 3","00;59;47;08","01;00;10;17","So all that is to say the question of where something like a hurricane lands on this, on this, on the spectrum, I think we need to really resist the urge to just make pronouncements, you know, sort of armchair pronouncements about that. And we need to ask a simple question, which type of manipulation is that system amenable to? And when you find out, then you know, how much agency it has."
"Speaker 3","01;00;10;21","01;00;34;18","Now, I'll give you a simple example of how this works. We and other people have done something similar. You think about gene regulatory networks. So gene regulatory networks are a quintessential example of a of a dynamical system. It's deterministic and all of that. And one of the things we asked is we we simply said how do we know where on this spectrum it lands?"
"Speaker 3","01;00;34;23","01;00;53;01","Let's just try to train it and see what happens. Then it turns out and this is so we did this computationally and now we're sort of starting to do this at the bench. We simply asked the question, could gene regulatory networks have associative learning capacity? And that means that you could do interesting things. You can do Pavlov's dogs experiment."
"Speaker 3","01;00;53;06","01;01;22;05","So you have a gene regulatory network. You have some stimulus that causes it to do something. So you have your unconditioned stimulus that causes a response. You have this other thing that's a that's a neutral stimulus that normally doesn't do anything. You pair presentations of the U.S. and the neutral stimulus together. And after a while, what you might find is that now take away the the structure, the original unconditioned stimulus and use the neutral stimulus."
"Speaker 3","01;01;22;05","01;01;54;12","So that's not enough to trigger the response because there's an associated memory that forms in the network, right? So now we actually try this in the sense that we took a bunch of known gene regulatory networks from literature. We made an algorithm that basically checks for associative learning. And lo and behold, we found two things we found that there are six different kinds of memories of these things can do, including associative memories for many of them, and that the biological networks have way more memories than you find in random, random networks that you would just randomly concoct."
"Speaker 3","01;01;54;12","01;02;12;11","So apparently the the directly or indirectly selection lives that. So that's just an example of what you would do under this view with with dynamical systems. Right? That that you would think, oh, you know, these are trouble theses are the agents who aren't. But I think that's where we get in trouble because we try to draw a sharp line."
"Speaker 3","01;02;12;18","01;02;30;15","I think the answer is there's somewhere on the line. It could be way over on the left or not. And you find out when you figure out what kind of intervention and strategy fails, you have the most predictive power with the least amount of action thanks."
"Speaker 1","01;02;30;15","01;03;03;18","So we talked yesterday kind of about, you know, cells that are contiguous and they're just like connections. And so this this concept of like a shared information making up an individual or like what constitutes the boundary, you know, if cells are connected via them. And like you talked about how if there's a calcium molecule inside myself I don't know if it's from for me or from my neighbor because we share this kind of hole between us."
"Speaker 1","01;03;04;02","01;03;30;25","And so I just wonder if if there's some degree of information sharing or some kind of like proximal like level, does it have to be immediately contiguous to, you know, have that same like cognitive capacity or like over a longer distance? Can this also function like, for example, if I get some kind of like necrotizing flesh in my leg, is my toe necessarily going to know like what's going on with my leg?"
"Speaker 1","01;03;30;25","01;03;58;23","It's going to take a while for that signal to diffuse over such a long distance. So so where is that? Like the boundary or container space for this kind of information sharing that has to occur to make this cognitive, cognitive individual like a whole a whole thing by itself. So I don't know if you can say a little bit more about that yeah."
"Speaker 3","01;03;58;29","01;04;20;03","Yeah. The biggest is so. So I think so I think one thing that I really need to improve in this whole thing for next time is a better visualization than I frankly don't yet know how to do it because this this way of visualizing it looks very physical. It looks like what the cone is, is that the cone, is that the edge of the cells that are connected?"
"Speaker 3","01;04;20;03","01;04;57;01","Right. It sort of gives this idea that that what you're measuring is the actual physical boundary of the system. And that's not quite what I'm trying to get across because what what and this is actually let's just think about the cells in the in the cancer versus multicellularity. Right. Which is a nice example of how this works. When you have a bunch of cells and they get together and they're going to build a kidney, be the size of the at least the spatial size of that of of of that particular region, is going to be roughly the size of the thing they're working towards."
"Speaker 3","01;04;57;01","01;05;13;02","It's going to be the size of that kidney. Right. That's the project. They're all working on each individual cells. No idea what a kidney is, but the collective intelligence of that group of cells, it has a goal. It's trying to build a kidney. If you try to deviated from that goal, it will do its best to take it back and do it anyway."
"Speaker 3","01;05;13;25","01;05;36;05","So what you would be measuring there is the the size of the of the state that it's trying to achieve, not necessarily this where the edges of the of the now there's certainly some relationship there because in this particular example, what you need, as you said, what enables the cells to work together is the fact that they're electrically coupled into one and chemically coupled into one giant network."
"Speaker 3","01;05;36;05","01;05;58;08","So so there's some relationship, but it's not quite always the edge. Right. You know what I mean? And the same thing with the individual cells. There's a it's, it's, it's related, but it's not exactly the same thing when one cell defects. So let's say an oncogene turns on the cell closes all the directions disconnects with its neighbors. And now that computational boundary is literally just that one cell."
"Speaker 3","01;05;58;17","01;06;17;14","Again, it's not quite at the edge of the cell because if you look at the scale of things the cell is trying to manage, it's a little bit bigger than that because it also really cares about some of the you know, the nutrients, the waste, the specifics, the prey, whatever, whatever else is going on. Right at that. It's right."
"Speaker 3","01;06;17;19","01;06;35;21","So it's not quite at the cell boundary. So I just want to make that clear. That this diagram isn't meant to be an anatomical the colon is meant to be a map. Exactly. On the anatomy. It's a corner of the states that the thing is trying to actively manage yeah."
"Speaker 1","01;06;35;21","01;06;37;13","I think that the cones were inflicted by us."
"Speaker 3","01;06;37;13","01;06;55;25","So yeah, but you're absolutely right. And as soon as you did that, I realized that it would be bigger because that has to be right. Do those two diagrams eventually have to be right? And so there has to be there has to be a way to. So I think, I don't know. Might make it visual imagination doesn't. Great."
"Speaker 3","01;06;55;25","01;07;04;03","I have to I have to think a little bit more about a better way to kind of represent that. But but, you know, of course, you're right. Those two things have to come together yes."
"Speaker 1","01;07;04;03","01;07;04;19","Stephen."
"Speaker 4","01;07;06;01","01;07;41;26","Yeah. I was just so following on from what you were saying is often as well as useful when we think of entities and processes and maybe scaling up to more psychological goals. But you know, we often think about this is this person and this is that what these entities diagnosed as and this entity and it's all kind of and there's a lot more now move towards what's the process but then what kind of processes do we have on that continuum just like we zoom out with the hurricane, you know, you maybe you got a static entity like a rock and then you've got you kind of systems, some of which could be mechanical, like a"
"Speaker 4","01;07;41;26","01;08;10;10","clock but then you sort of hit structures. There's some sort of structure like a I don't know, like a skeleton or a network of processes coming together then you get into them, which is what I find really interesting with the what you do is the sort of nonlinear swarming dynamics, you know, and it's sort of and I was wondering how when you think of, you know, you've got a body and I'm a body and I'm trying to work in my space around me."
"Speaker 4","01;08;11;03","01;08;35;14","So I see things in my environment out there and I can interact to some extent depending on what my available processes are for me in my structures. And then there's other stuff inside which to some extent I kind of have to let take care of themselves unless I want to try to myself or do some sort of internal mutilation or something."
"Speaker 4","01;08;35;20","01;08;44;22","So I'm curious about how this entity process dynamic going in and out can be thought of."
"Speaker 3","01;08;45;08","01;09;08;20","Yeah, well, I want to I want to say a couple of things. And again, this is sort of the going going too far extreme. But I think I think it might be relevant when you say you are this body sort of in the sense that we are talking to the verbal entity there, but there are all sorts of other entities there that we're not hearing from that in."
"Speaker 3","01;09;08;20","01;09;31;13","So so we know that from split brain patients, right? We know that after a year on the right side of the brain, you can communicate with it'll give you opinions that the verbal patient part of the patient doesn't agree with don't know anything about. Right. So that would be really interesting. I also think about multiple personality. You know, they call it the multiple personality disorder."
"Speaker 3","01;09;31;13","01;09;56;05","But but but the reality is, you know, a single a single brain body system apparently can post any number of distinct and how in how I am I'm not I'm not an expert in this area. So I don't know how psychologically deep some of these other personalities go. But enough that you can have a conversation, certainly enough that you can have a conversation with them, which means they're doing better than all of the A.I. that we've ever produced."
"Speaker 3","01;09;56;12","01;10;19;19","Right. And they and in fact, I read once I forget where it was. But there was an interesting comment from a of a therapist who was asked. He was he was he was asked to deal with a multiple personality patient, and he was talking about integration. And he was, you know, about the goal of the therapy was going to integrate because the first three disruptive for them, for the individual."
"Speaker 3","01;10;19;19","01;10;47;14","And we're going to we're going to integrate all of these into one. And one of the personalities said to that patient integration, you're going to kill me, right? That's what you're talking about. I thought you were a doctor. What are we talking about here? And so, you know, he was outraged that that that there was going to be this integration of kind of of of of what at least ostensibly you've got this entity that certainly passes the jury test and is and is not happy about the fact that you're about to integrate it in a way basically."
"Speaker 3","01;10;47;14","01;11;07;21","Right So that's you know, I think that goes back to this idea that we're in into penetrating set of selves. And we tend to only hear from the verbal one. So there's all kinds of other ones in there that are competing and cooperating and everything else. And the other thing I can say about this, though, that's more questions than answers I guess."
"Speaker 3","01;11;07;25","01;11;32;00","But the other thing that I think that's interesting is that you're you're right in the sense that the one kind of entity that we have direct experience, which is the verbal you know, sort of one that presumably we share, is completely ignorant of most of the things that are going on there. And so the space that you're working with nicely coarse grains over all kinds of stuff, you know, your liver function and everything else, you don't need to micromanage all this."
"Speaker 3","01;11;32;08","01;11;54;14","However, there are techniques that will add axes to your options. Space so if you would like to learn to also consciously control your heart rate or your skin temperature or whatever you can do biofeedback, there are tools that will enable you to cross that that boundary and you will now have a new axis in your options space that you never had before."
"Speaker 3","01;11;54;19","01;12;12;28","Do you want it? I don't know. There's a good reason why more. Mostly you don't use it. That's a good to sort of simplify your space. But, you know, there was a there was an and there was a cool experiment where they they measured the temperature between a rats ears and they gave it a reward proportional to the difference in temperature."
"Speaker 3","01;12;12;28","01;12;33;11","And so rats readily learned to to get their ears of 25 degrees Celsius with something different between their ears to get the reward. So now that's amazing for a number of reasons. One is that, okay, now, now you've added in a factor in your space that is is this physiological blood flight obviously are they doing that you didn't have before."
"Speaker 3","01;12;33;11","01;12;54;26","The other thing, of course, is the credit assignment there you are your rat and you just got some reward. And so well, let me see, why did I get that so well, my tail was pointing up and my left fingers are clenched and my whiskers are going. Which of those things actually were right? So so this is we still have a practice in machine learning is how living things are so good at figuring out what exactly they're being rewarded for."
"Speaker 3","01;12;55;03","01;13;21;26","Small number of trials actually. So which you can I think I think you can break through that at least to some extent and you know, break through and actually even further. Right. So there are claims that certain types of mental practices will have effects on their immune system, for example. Right. So you can I think you can go pretty far down right from you if you wanted to add these these kinds of things to your options for is."
"Speaker 4","01;13;23;08","01;13;55;16","Interesting actually just bouncing on that going. That's really helpful. Actually, I've not even thought about that but that that different parts of us ties in with there's this big push all the time. If you say that integrate integrate integrate and actually when you sell out because I do a lot of work with multi service service providers say in Africa or other countries where there are any you tend to find that any type of transdisciplinary projects has the problem about whichever regime of attention or field of practice voice is in at that time."
"Speaker 4","01;13;55;26","01;14;27;08","And then then when we talk about integrated it normally means they dominate. And what about configuring? So think about this idea of configuring different fields of practice, different ways or different ways of knowing, and also ways the other voice is, is strategic conversation. With communities. You don't normally get a voice, you know, something in the state space beyond what the actors who've got the job in the agency know and it's this sort of ties in a little bit."
"Speaker 4","01;14;27;10","01;14;51;13","We do what you're talking about here. So I think it's quite interesting in the sense of can we can because in a way the biology is and trying to integrate it is actually configuring and allowing things to be but it has a ways is still no there differently logical spaces and either just let it get on with it or yeah it knows where and when to get involved I suppose is the thing."
"Speaker 3","01;14;51;24","01;15;21;22","Yeah I mean so so so I think I think the the one way of looking at that this is to ask what are the optimal policies for know for this finding so so on. So I just, you know, I'll give you an example. So, so in the case of, in the case of multicellularity, we say, OK, individual cells are pretty cool but when they connect junctions into a multicellular collective, they can do these, these marvelous things and they resist cancer."
"Speaker 3","01;15;21;22","01;15;43;08","And, you know, and turning off the connection and becoming becoming a cancer cell and going metastatic is this is bad. And so what you would really like to do is to reconnect these cells back. And so the thing is that, right, that that tightly coupling individual units into a global entity avails you of all kinds of interesting things, right?"
"Speaker 3","01;15;43;08","01;16;04;01","So it raises the IQ of the whole industry, all kinds of capabilities. Fine. But one of the things that gets lost when you do that is that the larger system now, now can dominate the goals of the lower system. And in fact, the larger system may have very little care for the goals of the welfare of the subunit."
"Speaker 3","01;16;04;08","01;16;28;06","You know, when was the last time you worried about all the skin cells you're shedding, right? You just you you you're going to do what you're going to do. And if you lose some skin cells, you no problem. So what that suggests is that maximally maximizing out this connectivity into some giant Borg like, you know, thing is, is and obviously it's been you know, it's kind of been attempted on the social sphere."
"Speaker 3","01;16;28;06","01;17;02;08","We know how that turns out. So you want to that somewhere in between there, there's a there's an optimal policy, right where I hope there may not you know, there may be maybe there's some no go theorem and that since there is no good policy. But but I hope that somewhere in there there's a good policy that allows us to reap the rewards of appropriate kinds of large scale organization without a sort of blanket collectivism that that that completely sort of wipes out the the the needs of the of the lower level subunit."
"Speaker 3","01;17;02;18","01;17;36;01","So that, I hope is a is an empirical question that we should we should be looking for what kind of policies give us that optimize the various things we want to optimize. Josh Longo and I plan to grant at one point for this human flood, this human flourishing program, I think it's actually an empirical question. Can we identify the optimal policies that preserve the needs of the subunits and reap the rewards of becoming a greater whole nice."
"Speaker 1","01;17;37;10","01;18;08;11","So I learned this word yesterday, Gregor. It's the occult concept representing a distinct nonphysical entity that arises from a collective group of people. And I thought it was really cool. And and I think of this concept of emergence. So, like, at what level does this collective kind of body form and I don't know if you've read the Information Theory of Individuality Paper by David Krakauer, but we really think about, you know, emergence you know, like the emergence causing the formation of the collective entity."
"Speaker 1","01;18;08;11","01;18;23;29","But then there also has to be like some kind of downward causation at some, some point in there like so is there there's this some kind of like critical point, like a phase transition that starts to occur or when does that kind of start to happen that that bidirectional information flow?"
"Speaker 3","01;18;25;11","01;19;04;15","Yeah, for sure. I mean, I think this this in particular is interesting because I thought about this a little while ago that you know, especially people who are interested in this kind of stuff, you know, and you can think about the really old concept of group karma, right? This idea that that not only you have your own individual cause and effect that you're causing, but but in a strong sense, the group of which you are a part has its own right cause and effect that is that is as real as so so that idea and I don't know how many thousands of years old that idea is, I think it is an amazing, amazingly prescient"
"Speaker 3","01;19;04;15","01;19;42;13","because in Western science is that the collective intelligent, right. The science of collective intelligence and this idea that. Right. The group can be a swarm, whatever can be an ancient on its own is relatively recent. Right. That people are sort of taking that seriously in science. But I think I think that kind of thinking must have been extremely old because there are these traditions that take it very seriously, that the group is not just a heap of stuff, but it actually has its own agency in the sense that it can even be the subject of blame and reward in the sense of, you know, the sense of like reward of punishment or whatever, that that's"
"Speaker 3","01;19;42;13","01;19;51;14","a very strong view of group agency that I think we've only, you know, scientifically we've only really appreciated recently. So I think that's that's that's pretty cool, actually."
"Speaker 2","01;19;52;25","01;20;13;28","Random random linguistic thing here that Greg or I was thinking about egregious and egregious in my mind is like out of bounds, you know? But yet Aggregor is or is not that it's the opposite. It's almost like a group thing. Maybe, maybe some somebody else can think about that differently. But I thought that was an interesting conflict."
"Speaker 3","01;20;14;09","01;20;14;29","Yep. Yep."
"Speaker 1","01;20;15;01","01;20;40;25","Very interesting so I think about this concept of collective karma a lot and really kind of whether or not like I have free will and in the present, like in terms of am I just some kind of computation like my like, you know, just because I've been doing active in France and so am I just my generative model that like effectively I can't make any decision because of my model."
"Speaker 1","01;20;40;25","01;21;07;23","Like whatever input I'm getting at that moment, I have to decide based on, on the condition of my model at that time. And I think about collective karma much in the same way and whether or not there exists some kind of, of agency in the present or not. Like if, if all the things that just made me who I am right now have just led ultimately to, to be where I am and in collective karma, too."
"Speaker 1","01;21;07;23","01;21;27;13","It's like a hurricane. That group of people caused that hurricane to happen. Like they created the causes for the collective karma, for the hurricane to come so I don't know, it's something that that is really intriguing to me. And, you know, I don't know if you want to maybe elaborate a little bit more on that."
"Speaker 3","01;21;28;01","01;21;57;22","Yeah. Yeah. And so and so 22 thoughts about that. One is that this goes back to this idea of, of space is in the different spaces that each of your each of the subunits is, is working in one way that and after after I drew this code and I realized that it kind of looked like the special relativity code and all that, some other and some other pieces of relativity sort of started started popping into my head in this idea of deforming the space around you."
"Speaker 3","01;21;57;22","01;22;14;24","Right. So if you're a mass you to form the space around you, which in turn alters your next possible movements and the possible movements of the other masses around you. Right. So by deforming that by your actions, you are deforming the possible the possibility space for, for, for your, for yourself, for things next to you, for your components and so on."
"Speaker 3","01;22;15;00","01;22;35;24","And so one thing that I think happens is that these larger systems deform the action space for their lower systems so that to them that all they have to do is roll downhill in effect. And so if you zoom in, so this gets back to I'm going to connect this back to your point about karma and action and choices and so on."
"Speaker 3","01;22;36;03","01;22;53;00","When you zoom in, all you see is physics. Then you see, then you say, oh, well, this, this is general. Of course, that's what it's doing. That's all it could do. All the gradients are pointing this way. That's what it has to do. But the reason it can be it can do that is and still get to some global goal is because the higher level system has already deform that space."
"Speaker 3","01;22;53;09","01;23;14;21","So I see this and how am I going to draw this? That's a different story. But when I see all these different levels as deforming their simpler space that they're working in, which then changes the options space for their subunits so that they can they don't have to be as smart. This is the this is sort of Dennis idea of, you know, progressively dumber robots, all the way down that works."
"Speaker 3","01;23;14;25","01;23;31;13","If each system makes it so that so that the lower level systems don't have to do quite as much of the work. And there's a stupid example I always go to from from your being from the common everyday life. If, if, if you ever had a friend who tried to stop smoking and they like the smoking thing, one of the things they might do is put their car keys in."
"Speaker 3","01;23;31;13","01;23;44;18","But it's really hard to get to why? Because they know that when they, you know, at midnight, when they want to smoke, they're not going to feel like going hunting for the keys. And then they're fine. And then and then that's that. So, so what they're doing is you now what you're doing this you're doing this to your future self, right?"
"Speaker 3","01;23;44;18","01;24;01;12","You're deforming the space for your future self in that case, consciousness. And of course we all do things unconsciously do. But in that case you're consciously deforming the action space for your future self in order to so that you can be on autopilot at that point. Right. You don't have to have the willpower at midnight that I'm going to not do this."
"Speaker 3","01;24;01;17","01;24;24;29","It's I've already somebody who's already sort of twisted the space for you so that you're going to get your keys. It's just too high of a barrier and forget. So great. So so I think, I think that, that, that that deformation of these action spaces is a really important way in which lower and higher level systems relate. The lower level systems simplify the action space for the higher level system because they're competent."
"Speaker 3","01;24;24;29","01;24;48;05","So the higher level system doesn't need all the dimensions. And the higher system bends the space of the lower system to make things easier to get to. And that and that goes back to your other point that that you just made about in the moment of, of, of, of taking actions in the moment that are the consequence of all the pressures that you have set up and other things have set up for you where."
"Speaker 3","01;24;48;06","01;25;21;13","Yeah, I see. This is also if we think about well, in the sense of free will or decision making or whatever, I see this again this like four dimensional block where each one of us at any point in time is a slice of it. And if you zoom in on that one, that, that self left that exists at that one time slice your your free will so to speak is is limited to none because at that moment on the local scale you are going to do whatever the local forces have arranged that you're going to do."
"Speaker 3","01;25;21;14","01;25;48;27","Right. And this is one like a simple example is that you control what your next thought is going to be. You really think your next thought is going to be whatever it is. So at the local level, at the local level, when you zoom in here, you know, there's there's there's no no useful sense of freedom there. However, if you zoom out on the long scale, what you what is true, I think, is that you can take actions with repeated actions, whether they be practice or whatever they're going to be."
"Speaker 3","01;25;49;03","01;26;13;19","You can take repeated actions that alter your cognitive causal structure so that over time you have made changes. And so so no, you can't control the next thought you're going to have now, but you can control what percentage of your thoughts are negative or whatever, whatever it is down, down the line. Right. So so to me, that question of of choice and freedom is very much relative to what scale you're asking."
"Speaker 3","01;26;13;19","01;26;28;17","Martin, zoom in to the to the to the Lola, you know, to that to the physics in that sort of short time scale. You know, I don't think there's any useful sense of that. But over the long term, absolutely. Because you can make changes both in your environment, your own structure that will get you to a different place."
"Speaker 1","01;26;31;21","01;26;33;24","Thanks, Stephen."
"Speaker 4","01;26;33;26","01;27;00;04","Yeah, this is really helpful, actually, to think about this way and just as I was saying there about this sort of almost transcendental or the the way we often think of things being excluded, egregious is Sarah was saying and and when we we need to move beyond the inner outer, you know, there's an inner thought process and there's an outer world."
"Speaker 4","01;27;00;04","01;27;21;21","But the two are linked, like we say. So with active inference, the idea is that I don't necessarily purely have a module of those codes in my head. I got an action model for how to draw them. I haven't got the whole thing that can be dumped down like a data source, but I have a way to do that, which ties in and I was one."
"Speaker 4","01;27;21;21","01;28;04;28","And when you mentioned there about looking at the future, one thing that adds active inference hasn't really done is it. So it talks about, say, the car keys example is, is, is the sequence which something might have to happen to get to the future. Being disrupted, which is kind of that quantum sexuality idea. It was normally an activated because they talk about the initial construction or the nation modification but not just about modifying itself is modifying the trajectories you might say through that niche which that that gives you more near time possibilities for like sculpting what can happen when it can happen."
"Speaker 4","01;28;04;28","01;28;37;20","So that I think that's quite useful I was wondering how how you see that relationships in niche construction and weather and models being sort of embedded in the world. I so systems are really models in the world that we then read or interact with and use in our structures. How do we how do we link up that kind of code with the kind of niche construction that's maybe being used in other areas?"
"Speaker 4","01;28;37;20","01;28;38;17","Active inference."
"Speaker 3","01;28;39;29","01;29;03;16","Yeah. Yeah. I mean, so that's that's a very difficult question. I can sort of address a small part of it, I think at this point. And I can, you know, I mean, I think one of the key questions of all of this is to what extent when we look at systems and we see the dimensions with let's just do the third person case first and then we'll talk about that."
"Speaker 3","01;29;03;16","01;29;31;07","I think the first person case that you're designing. So when we look at a system and we make a map of it, it's problem solving and some space and it's goal directed activity in some space, the question is, is that in any sense objective in the meaning meaning could we could we make a case that that that model of that space is better or the best or is is there an infinity of ways to look at it?"
"Speaker 3","01;29;31;14","01;30;01;24","And in particular, how does that relate to now the first person perspective of that system itself? What is the space look like? It's a little bit like, you know, the whole room melting, right where you're sort of in some space. What does it look like to you and Chris feels? They made a really nice example in our computational meeting a couple of weeks ago where you said, imagine, imagine a bacterium and there's some sugar gradient that the bacterium is in and it's you know, it wants to have more energy."
"Speaker 3","01;30;02;03","01;30;23;29","So now one thing we are tempted to do is to draw a space where by rotating its flagella or whatever else, this thing is going to move up the gradient. But there's something else it can do, which is that it can turn on a gene for an enzyme that lets it use a completely different sugar or let it use that sugar better or something else that solves that same problem with an effective route."
"Speaker 3","01;30;24;01","01;30;40;07","That to us is an entirely different space. So so so we look at this and we say, Ah, that solution has a problem in, in physical space and it has a solution. And Transcriptional says if you're a bacterium, is there any sense in which those are not part of the same space? I mean, I have no idea what it's about."
"Speaker 3","01;30;40;07","01;31;14;11","Obviously, what it's like to be that bacterium. One could make an argument that our just dissection of these things as two different spaces is is totally biased because that's where scientists that we like to look at things, that's the bacterium. Both of those are effectors that live together. That's kind of a mix. It's almost like, you know, it's almost like, you know, you can ask about isms or a PC, a right if if you have principal component analysis where you're learning about your world and you're going to end up with a picture of what the axes are that don't necessarily make any sense to us looking at the system, right?"
"Speaker 3","01;31;14;12","01;31;39;19","You find you get the you get these components that you know, these control knobs. And we look at how what's the what is doing what but, but, but, but to the system, those are efficient ways to build an axis. And people like Robert Brenner and Don Hoffman have these models of cognitive systems from scratch sort of building these worlds through these virtual spaces for themselves that you don't actually know what space that you're in."
"Speaker 3","01;31;40;12","01;32;19;01","So I think there is a research agenda there, which is can we build some sort of appliance, meaning some sort of, I don't know, machine learning thing or something that will try to extract these in a I'm not going to say I'm biased, but at least unsupervised manner that can we build an agency detector? Can we build something that looks at a system and says, I tell you what, if you assume this access, this access and this access, then I can paint you a really efficient search strategy that will allow you to predict what the system is going to do next, because you could view this as problem solving in this space."
"Speaker 3","01;32;19;08","01;32;54;01","Right? And maybe, maybe it generates a palette of solutions like that in this one that's head and shoulders above the others. And you say, fine, that's my scientific theory of what's going on here and maybe. Right. And maybe that works. And so that's that's that's a research kind of agenda for the future. And the other cool thing about that is if you if you do that, of course, one thing you might want to do is then build a more sophisticated synthetic intelligence by sticking that thing in basically closing the loop and sticking that that module inside the agent itself."
"Speaker 3","01;32;54;02","01;33;17;03","And here's why I'm saying all animals, I think, you know, at least past a certain point, certainly have agency detectors. This is why we love our visual systems, love symmetry and so on, because you really want to know, looking out into the world, you really want to know what are the passive elements and what are the other agents that might be, you that you might communicate with, that you might convince them to do something else."
"Speaker 3","01;33;17;16","01;33;37;23","So so we are constantly estimating, you know, theory of mind, right. And agency for all the things we're looking at because because that helps you get around your view. You need to know if it's if it's a rock or if it's something that's just going to come eat you no matter what or if it's a constant effect that you might actually lie to and or you don't have a relationship or whatever, you're going to do some sort of complicated interaction."
"Speaker 3","01;33;37;23","01;34;02;16","Right. So we're all we're all trying to gauge that and probably where what, what, what one of the things that kind of module also does is turn inwards to tell you stories about yourself. And the reason we know that exists is because of confabulation. So just as a simple example as this is a modern there are older examples from the brain split brain studies, but the modern example, there's there's somebody who's got an electrode."
"Speaker 3","01;34;02;16","01;34;20;04","And this was an actual experiment that was done in epilepsy or something. And they put an electrode in their brain and they in his brain didn't happen to land in an area that when you're stimulated, it stimulates laughter. The person just starts laughing. Right? So, so, so you're sitting there. So this, this person is sitting there talking to you and having a serious conversation with the doctor."
"Speaker 3","01;34;20;08","01;34;38;16","Somebody's off scene pushes the button, the person starts laughing. The doctor says to him, Why are you laughing? 0% of the time, the answer is, geez, I don't know. I was super weird. I was all series and suddenly my mouth starts. I think that never happens. What happens is the person says, Oh, I came up with a funny story and I was just thinking of a funny thing, right?"
"Speaker 3","01;34;38;22","01;35;06;18","So what happens is and this has been, you know, I'm not the first person to point this out, that we are massively unaware of lots of stuff that goes on in there. And we have a module apparently whose job it is to tell coherent stories about what that all adds up to. So not not just turning outwards to see what kind of agents we see out there, but actually to look inwards and come up with plausible explanations that, no, you're not an automaton because somebody pushed the button."
"Speaker 3","01;35;06;26","01;35;41;13","And that's not that that's not a preferred explanation. The preferred explanation is you're an agent you come up with funny stories and sometimes they make you laugh. That's a better solution. So so so we have this. So so if we had such a thing, we could imagine already piece by piece starting to put this together into what might be a fairly sophisticated cognitive system that has a bit of metacognition and a bit of much like all of us, sort of faulty access to what it is that we're doing and all these kind of interesting things nice."
"Speaker 1","01;35;41;29","01;36;04;18","So I'm going to kind of take it back to this time Space Cube, because I just really can't wrap my mind around the fact that if you slice up the cube, I think about it like a like a confocal Z stack. So if you have a slice that's the present, if I can't change this slice, like, you know, you can take a projection of the confocal image and look at the whole picture."
"Speaker 1","01;36;04;18","01;36;21;26","If I can't change this one slice, how is it that I'm going to change the future right? So all the slices up until this point lead me to make this current existing slice and then do I can I change at any point in the future? I don't see how that's possible if I can't change the point in the present."
"Speaker 1","01;36;21;26","01;36;56;26","So are we just like I think about we had Shana Dobson and Chris Fields on and we were talking about express, you know, compressing and expanding in time and space and just time and all kinds of context. Like, is that even a construct or how does it work? And like non activity and time and all that stuff. So I don't know what if you want to maybe unpack that a little bit for me because I'm just not kind of seeing the possibility of of this changing the future without being able to change the present yeah."
"Speaker 3","01;36;57;02","01;37;20;06","It's totally possible. And so and so for sure, I'm not going to try to make the argument that we have a, a mature theory of, of, of, you know, free will effect of that kind. I don't think we do. But and I think you're absolutely right in that, that, that is in fact a really critical point if, if, if, if your freedom in each slice zero, then many times zero it's still zero."
"Speaker 3","01;37;20;06","01;37;40;28","Right. So two totally, totally true. I think we can make two moves. And again, this is this is super early. I I'm not claiming this is in any way going to survive careful, careful thought into the future. I I mean, we can make two shifts. One shift is that I think it's again then that, you know, I'm like a broken record with this stuff."
"Speaker 3","01;37;41;03","01;38;04;13","But I think I think that binary this winery distinction between you have freedom or you do not, I think that's wrong. So so I think what you have, it goes by amounts. So so you may have very little you know, if you're if you're if you're a mechanical clock, you have very little. And if you are some other type of living thing, you may have more and then you may have more than that."
"Speaker 3","01;38;04;28","01;38;27;10","So then what you have is and this is super, super amateurish. But but just to kind of visualize what I see is the kind of addition that you get in calculus where you start with extremely tiny things that are kind of zero but not really. And eventually they add up to something right. That's how I see it. That's how I think that what you have at each point is a teeny tiny amount."
"Speaker 3","01;38;27;10","01;38;49;21","And if you look close at basically it's an epsilon that's not worth talking about. It's basically you don't happen, but it isn't quite zero. And over time, that mental effort, whatever that is that you put into, you know, working on your free will earn your kindness or whatever you're working on over time, it integrates into an area even though you're integrating infinitely thin strips."
"Speaker 3","01;38;49;21","01;39;06;09","Like that's that's the vision that I have in my head, that if we just do away with the fact that it's actually zero, that I don't think it's actually zero, then you can build up something over time and you can and you can magnify and if, you know, I'll say one more thing, which is, you know, if we're going to if we're going to abuse physics like this, right."
"Speaker 3","01;39;06;09","01;39;27;20","Which is I mean, I realized so I completely informal and whatever I forget if we're going to use it, I'll make I'll make one more one more analogy. If you think about what is the what is a minimal level of agency so so so sometimes people ask me like, well, is there a zero on your on your continuum, right?"
"Speaker 3","01;39;27;20","01;39;49;25","Is there an actual zero? I'm like, what's the minimum? What is the smallest and saying, OK, if you're going to pick if you're going to design the absolute minimal piece that still has some non zero agency, what does it need? I feel like it needs two things it needs some minimal amount of decision making that isn't obviously caused by local causes."
"Speaker 3","01;39;50;00","01;40;21;11","Right? It needs at least something that is that that reaches outward in terms of space or time or complexity or something that isn't obviously a locally determined you know, and this necessity that that's one. And the second thing it needs is some amount of goal directed activity, something that looks like a goal directed activity. So so once you said that, it seems to me that that individual particles already have this right because because quantum indeterminacy gives you the first one at least action principles give you the."
"Speaker 3","01;40;21;26","01;40;40;08","So you've already got that. And so now when you so so I think and again, this is amateur ish as far as the physics goes, but my gut feeling is that there isn't this zero that you already start with some minimal amount and now you can do one of two things. You can see that you got these particles you can do one of two things."
"Speaker 3","01;40;40;08","01;41;07;07","You can you can make a rock out of them. So you aggregate them in one way, which basically gets rid of all those nice properties and it and, and it ends up having having, you know, very low agency. It doesn't, you know, it just it just aggregates all of it in a way that doesn't do anything useful. Or if you're if you're alive, you can you can amplify those properties and end up, you know, further down on the on the continuum."
"Speaker 3","01;41;07;15","01;41;23;17","So that's kind of my fuzzy story at the moment is that I think we start off at nonzero and then you can either stay there if you don't have the right organization or you can amplify the hell out of it and get you to get to be more general."
"Speaker 1","01;41;26;19","01;41;49;01","Nice things. I definitely think that non zero is the right answer. So we've got maybe like 15 minutes left and you know, I just, there's some closing thoughts, some room for some last minute questions. Sarah or Stephen, do you have any last minute things you want to ask no."
"Speaker 2","01;41;49;01","01;41;52;27","My head is sufficiently exploded now."
"Speaker 4","01;41;52;29","01;42;21;02","I think I think that was a I mean, I think with a lot to think about because we've covered an awful lot of territory. But I think I think it's I was interesting to see that you're bringing the this and I know Carl Christian talks about that and so I suppose one last bit would be would you call yourself a non-dual monastic in the way that Carl talks about that idea?"
"Speaker 4","01;42;21;17","01;42;27;21","Or is that something a bit different or maybe not even relevant in this context?"
"Speaker 3","01;42;27;27","01;43;01;01","Yeah, that's that's a good that's a good question. So so I hesitate to put a name on it for two reasons. Number one, everything that we've talked about so far has been very much from a functional third person perspective. So so we haven't really touched the so-called hard problem of consciousness or what. So in order in the thing is nothing that I said touches this question of why is it like to be something that's one of these systems, right?"
"Speaker 3","01;43;01;11","01;43;19;20","So from that perspective, assuming that we believe, I mean, some people, you know, we'll say that that's a non problem and that there is no such thing and whatever, but I'm not 100% convinced of that actually in from so so so there are there that I do think there's a hard problem and I don't have anything that addresses it."
"Speaker 3","01;43;19;20","01;43;47;01","And so I don't know what that puts me in the other the other thing is that I have a lot of sort of kind of psychic sympathies in the following way. So I think that if you scale down if so so so what's the one reason people don't like pants. I guess if I can if it means that you know, it means that you think that rocks you have hopes and dreams like the rest of us."
"Speaker 3","01;43;47;01","01;44;11;16","OK, so that's obviously not what I'm saying. The reason people go to that to that extreme is because they've scaled down the structures that are needed for agency, but they haven't scaled down the expectation. So or so. Yes, it's silly to think that rocks and that rocks at the same hopes and dreams that we do. However, if you scale both sides of the equation, I'm not at all sure why."
"Speaker 3","01;44;11;17","01;44;37;03","Again, if you don't if you're not into binary classifications, it is conscious or it's not that I think it's definitely right. So if the nominal consciousness is a kind of continuing to I don't see any reason why there couldn't be a tiny bit of something that's super hard for us. To imagine because we're used to a much, much bigger level of perception and consciousness that that isn't associated with a lot of other systems."
"Speaker 3","01;44;37;03","01;45;07;06","So we normally that, you know, that the people who normally work in cognitive science is never bias as is highly conscious. So it's also I have a lot of kind of sympathies on that from mainly because I don't buy this binary distinction. And we can talk about there's actually interesting I don't even and I'll tell you why basically bioengineering and the kinds of things that are possible now are they are really dissolving a lot of things that seem to be sharp categories before."
"Speaker 3","01;45;07;12","01;45;30;03","And I'm not even sure at this point that the kind of distinction between first person and third person knowledge is even sharper. And I'll just I'll just draw you a simple picture and I preface this by saying I made a picture of this and I sent it to a well known philosopher and it was horrible, horrible. And, and, and I'm not, not useful, but we'll see what we'll see what you think."
"Speaker 3","01;45;31;00","01;45;50;15","Imagine that you're looking at there's a brain and there's a micro physiology being done some electrodes stuck in there and it's being processed that you're in, you're on the outside, you're the scientist, you're on the outside. You're looking at that data. Uncontroversially third person, right? You have no idea what it's like to be that subject. You are studying some signals that come off of it."
"Speaker 3","01;45;50;18","01;46;11;08","Right now, what we do is we change this. We change the scenario a little bit, and what we do is we take some of those interfaces that they have these interfaces for the blind that either go on your tongue or they go sometimes in your retina. But basically they turn camera signals into something that's directly plugged into your brain with electrodes."
"Speaker 3","01;46;11;13","01;46;41;20","OK, so now we take that set up and instead of a camera, we plug it directly into the electrophysiology apparatus. So now what you're receiving is you're receiving a heavily processed signal, but it's coming directly from that brain into your brain. And what's interesting is that people who use these kind of sensory augmentation devices, they will eventually report that it's just like seeing they do they learn to get around like the electric lollipop it's this thing you stick on your tongue and it shocks your tongue in a way that maps onto the pixels of a camera."
"Speaker 3","01;46;41;20","01;47;12;24","Right. And they say, oh, it's just like seeing it. So so OK, so now you've moved. So, you know, it's like it's sort of third person, but, you know, it's maybe like 2.5 person or something. And then you can do another experiment. You can say, well, what we're going to do is instead of using all this like heavily electric, you know, all this electronics and processing in between, we're just going to connect the brains and we can and we can do this."
"Speaker 3","01;47;12;24","01;47;35;00","And the reason we know we can do this is that there are conjoined twins whose brains are in fact, connected so that there's no, you know, sort of sort of clumsy electronic interface in the middle. The brains are directly connected. And so now is that OK, so if I'm now if my brain is now connected to this other person having the experience, it's sort of is that still third person?"
"Speaker 3","01;47;35;06","01;47;49;08","And then you ask the question, yeah, but in your own brain. So some people say that's an aberrant, you know, that's an average case, but in your own brain, you've got pieces of the brain that have to talk to each other. You're not an indivisible monad of some type, right? You are a bunch of pieces that also have to talk to each other."
"Speaker 3","01;47;49;13","01;48;06;03","So the left side has to talk to the right side, in fact, to the front parts of the brain. You are any way pieces of the brain having to talk to each other and somehow that ends up being first person. So now what we've just done is built a continuum where you can smoothly and we can fill in anywhere between these two systems."
"Speaker 3","01;48;06;03","01;48;27;04","I can fill in as sort of finely as you want, and you can smoothly move from from first person experience to third person science because the bioengineering tells you that you can do it. So so I'm not even sure that's, you know, sure that's a distinction. So I you know, it's hard to say. Anyway, that's a long winded answer to your question."
"Speaker 2","01;48;29;05","01;48;54;14","Well, I, I was going to ask one question now and asked another one. This makes me think, you know, like related to course screening, related to layers and levels of different organisms, like just what you the kind of example you just laid out makes me question whether you can even stratify in that way or whether it makes sense to stratify in that way."
"Speaker 2","01;48;55;29","01;49;27;05","But let me go back to something we didn't cover, and I heard it on your podcast and you ended with a question related to moral philosophy or ethics. I guess not even I don't know the distinction there, but yeah, I mean, when, you know, if you're coming from the perspective of not believing in a binary between, right, you said it better than I did, living non-living, whatever my agent versus not."
"Speaker 2","01;49;28;13","01;49;42;28","And then you're making things like xeno bots. It's like that kind of if that's if you held those two views of not believing in the binary, then there it seems like there really wouldn't be an ethical question. And so I'm wondering where your, where your thinking is along that."
"Speaker 3","01;49;43;15","01;50;03;04","Yeah. No, no, I think I think there's definitely an ethical question and I think it's not quite what we think it is, but in the I'll tell you what it is, but let's just let's just take a step back. So, so long before anybody made zettabytes, we made humans right know, the old fashioned way. And so this is like, you know, then it's the competence of our comprehension, right?"
"Speaker 3","01;50;03;04","01;50;22;24","So we have no idea how it worked before for, you know, hundreds of thousands of years we made other humans, and so we take care of them as best we can most of the time, sometimes not really very well, you know, so, so, so we already did that then we make all sorts of animals in terms of food production and other things."
"Speaker 3","01;50;23;00","01;50;42;28","We make hybrids, so we make mules that are animals that never existed. Before, right. We make we've made new, new plants. So, so so the first thing that's really critical and often the reason I'm sort of sensitized to all this is the people all say, Oh my God, you're making zettabytes. It's a new like, let's not let's not forget what we've already been doing."
"Speaker 3","01;50;42;28","01;51;02;21","Right? And let's let's be super clear that that is a massive problem with the food industry. Right? This long before we get to worrying about zettabytes is all kinds of things that that we need to fix. So I just want to be clear. I kind of want to be clear that that we've already been making animals and in fact other humans for which we sometimes take good responsibility and sometimes we don't."
"Speaker 3","01;51;03;08","01;51;31;05","I think I think this is absolutely raises an ethical problem. An ethical problem is the following. When we when we go to synthetic biology, and bioengineering seminars, there's usually now a session that's about ethics. In the session goes like this somebody will show a brain organ made of human cells and someone will say, oh, my God, that you shouldn't be doing that."
"Speaker 3","01;51;31;14","01;51;45;02","And somebody else will say, well, let's just see how much like a human brain it is. And then they and then people spend a couple of hours arguing about whether it is or is not enough, like a human brain that they need to worry about it. And maybe they end up saying it's fine, or maybe they end up saying it's not fine."
"Speaker 3","01;51;45;02","01;52;09;21","But I think that much bigger issue is that whether or not something looks anything like a human brain is a very poor guide to how much you need to worry about it. And in the past, the way that you the way that we would figure out whether or not how much moral responsibility we had for a particular system went roughly like this, you would sort of look at it."
"Speaker 3","01;52;09;21","01;52;28;29","And if it was squishy and warm and furry, you would say, yeah. And if it was metallic and, you know, and it came from an assembly line, you'd say, do what you want, no problem. Right. So so to say, two things used to be a guide. And even that we didn't do so well. We can't obviously with those principles."
"Speaker 3","01;52;28;29","01;52;51;12","But, but, but two things that used to be a guide were where did it come from? Did it involve or was it designed and what is it when is it made up? And it was a and that was pretty good, right? You could because if it was evolved, you could look on sort of the tree of life and you could say it's a worm, but we don't need to shell out any forms when we do these experiments."
"Speaker 3","01;52;51;12","01;53;07;19","Or you could say it's a frog. I need to fill out a lot of forms before we can do experiments for it. But then that's works because you have because you know something about that, that lineage and you make some sort of guesses about where things are. And then if it's an octopus, people really don't know what to do and so on."
"Speaker 3","01;53;08;09","01;53;35;29","All of that is going completely out the window, right? So in the next in the next couple of decades, we are going to be surrounded by and this is another thing that I'm writing on the options space of possible creatures we're talking about hybrids, cyborgs, hybrids. There's a million different ways to recombine, evolved, designed, living, non-living and software agents into new forms that have never existed before."
"Speaker 3","01;53;36;07","01;53;54;08","So what something looks like is no guide to what the commission is, where it came from, meaning if all through design is going to be a bad question, because half of the stuff we're building with, it's now evolved and so on, all of the things, you know, it's just a machine versus all, you know, it's a nice mammal."
"Speaker 3","01;53;54;11","01;54;16;27","All of that stuff is going to go out the window. So to me, the ethical problem is much bigger than just asking about whether something is like a human brain that what we really are going to need is a new ethical system for learning how to deal with agents that look nothing like us and that don't look like anything we've ever seen before, and yet are going to have all sorts of cognitive capacities."
"Speaker 3","01;54;17;07","01;54;33;02","And we have to let go of categories like machine, like robot, like all these other things that really don't mean anything, then they never did but before. But it was fine in the past. It's no longer useful. And that that's the ethical that's the ethical problem."
"Speaker 1","01;54;35;25","01;54;47;05","Wow. So great. So I'm going to go stare at a wall and try to integrate this information. It was a lot of oh, thank you so much for coming on."
"Speaker 3","01;54;48;13","01;54;54;03","Thank you so much. Yeah, this was really fun. Yeah. Great, great, great discussion. Thank you so much. Thank."
