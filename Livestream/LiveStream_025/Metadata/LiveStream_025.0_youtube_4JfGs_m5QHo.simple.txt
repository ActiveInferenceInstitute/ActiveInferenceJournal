SPEAKER_03:
Go for it.


SPEAKER_00:
Hello, everyone.

Welcome to Acton Flab live stream number 25.0.

Today is July 1st, 2021, and we're going to be talking about this paper, The Computational Boundary of a Self, Developmental Bioelectricity Drives Multicellularity and Scale-Free Cognition.

I'm Blue, and I'm here with Daniel.

Awesome.

So welcome to the Active Inference Lab, everyone.

We are a participatory online lab that is communicating, learning, and practicing applied active inference.

You can find us at the links here on this page.

This is a recorded and archived livestream, so please provide us with feedback so that we can improve our work.

All backgrounds and perspectives are welcome here.

We will be following good video etiquette for livestreams.

Here at the short link, you will find all of the live streams and different series that we do in the communications unit of the Active Inference Lab.

And today we're doing the contextualizing paper, the dot zero video for two upcoming discussions in the first half of July 2021 on the 6th and the 13th, when we have discussions 25.1 and 25.2 on this paper and hopefully the author joining.

Today in ACT-INF Lab Livestream number 25.0, we're going to be trying to set some context and give an introduction to the following paper, The Computational Boundary of a Self, Developmental Bioelectricity Drives Multicellularity and Scale-Free Cognition.

by Mike Levin.

And this video is just an introduction to some of the ideas.

It's not a review or a final word.

It's kind of like a three way intersection where we have people who might be within the active inference community looking to be exposed to some different areas like developmental biology or cognitive science.

And then another group of people who are coming from the developmental biology or cognitive science background and curious about active inference.

And then also we hope that this is exciting and interesting even for people who are not familiar with active inference or developmental biology or cognitive science.

We will hopefully try to connect it with some broader questions.

So we're going to walk through some of the aims and claims of the paper, the abstract and the roadmap, and bring a few big questions and some key points of the paper so that whether you read the paper or not, you'll hopefully be in a good spot to ask questions and learn more.

And of course, in the dot one and two videos in the coming weeks, we'll be discussing the same paper.

So save and submit your questions and let us know if you'd like to participate or contribute in any way.

So here we are on the paper itself.

That's a screenshot of the cover and the aims and claims.

And I'll read them so that then, Daniel, you can give a first thought on what you thought was cool or what you thought was important about the paper.

So the aims and claims of the paper.

First, they define individuals and selves in a way that facilitates taxonomy, comparison, and communication with evolved, created, biological, artificial, and exobiological agents.

He says, I propose a fundamental definition of an individual based on the ability to pursue goals at an appropriate level of scale and organization and suggest a formalism for defining and comparing the cognitive capacities of highly diverse types of agents.

Second, he proposes a plausible naturalistic framework for the evolutionary scale-up of cognition from the earliest origins of life, hypothesizing about the forces that drove it and the major transitions along the continuum.

And the goal of this research program is to show how complex agency and goal-directedness evolves naturally from ancient mechanisms.

So, Daniel, what do you think about that?


SPEAKER_04:
Nice work.

I thought the paper was pretty exciting because it touches on just so many big topics like goal setting and agency, cognition and natural and artificial systems, multi-scale systems.

And then it links it in a way that people might not expect, which is through developmental biology and bioelectricity, which are kind of like processes that these life forms or other forms create.

engage in so to be able to connect things that are awesome about systems that matter like again their goal seeking nature their ability to do cognition and then connect that to a process theory it's kind of what we're all about in active inference connecting the cool features of the world to process theories that are tractable


SPEAKER_00:
Cool, so moving on to the abstract, I'll read the first part, and then you can read the next slide.

So all epistemic agents physically consist of parts that must somehow comprise an integrated cognitive self.

Biological individuals consist of subunits, organs, cells, and molecular networks that are themselves complex and competent in their own native contexts.

How do coherent biological individuals result from the activity of smaller subagents?

To understand the evolution and function of metazoan creatures, bodies, and minds, it is essential to conceptually explore the origin of multicellularity and the scaling of basal cognition of individual cells into a coherent, larger organism.

So I find this line of research truly fascinating and really a burning question for me is how information is consolidated or prioritized across skills, whether it's core screening or salience or something else.

So do you want to read the next part?


SPEAKER_04:
Yep, just one thought on that, and it's going to be a theme that's returned to.

It's that cognition or agency doesn't just blink into existence at a larger level of analysis.

It's actually composed of smaller cognitive units, and so it's kind of like cognition all the way down.

That helps us integrate across scales, but also recognize what's special about larger levels of organization, like culture.

So part two of the abstract.

In this article, I synthesize ideas in cognitive science, evolutionary biology, and developmental physiology towards a hypothesis about the origin of individuality, scale-free cognition.

I propose a fundamental definition of an individual based upon the ability to pursue goals at an appropriate level of scale and organization and suggest a formalism for defining and comparing the cognitive capacities of highly diverse types of agents.

Any self is demarcated by a computational surface, the spatial-temporal boundary of events that it can measure, model, and try to affect.

The surface sets a functional boundary, a cognitive light cone, which defines the scale and limits of its cognition.

I hypothesize that higher-level, goal-directed activity and agency, resulting in larger cognitive boundaries, evolves from the primal homeostatic drive of living things to reduce stress, the difference between current conditions and life-optimal conditions.


SPEAKER_00:
So I like this goal-directed aspect of this, and it really kind of implies to me that it's biological.

Cognition has to be biological.

But I wonder about what is the goal of molecules in their organization, right?

Is that a goal-directed activity, like the protons and neutrons and electrons want to reduce their uncertainty about where they are in space?

Or how does it work at a non-biological level?

Makes me wonder that.


SPEAKER_04:
Or strain.

Strain and stress.

Those are things we psychologically experience, but then you can have, you know, like a ring with four carbons.

It's under strain.

And the carbons, they seek to do what?

Well, get into a less stressed position, like an unstrained arrangement.


SPEAKER_00:
For sure.

The next part.

The mechanisms of developmental bioelectricity, the ability of all cells to form electrical networks to process information, suggest a plausible set of gradual evolutionary steps that naturally lead from physiological homeostasis in single cells to memory, prediction, and ultimately complex cognitive agents via scale up of the basic drive of infotaxis.

Recent data on the molecular mechanisms of preneural bioelectricity suggest a model of how increasingly sophisticated cognitive functions emerge smoothly from cell-to-cell communication used to guide embryogenesis and regeneration.

This set of hypotheses provides a novel perspective on numerous phenomena such as cancer and makes several unique testable predictions for interdisciplinary research that have implications not only for evolutionary developmental biology, but also for biomedicine and perhaps artificial intelligence and exobiology.

Do you have any thoughts on that, Daniel?


SPEAKER_04:
I guess it's just cool to see development and cognition come onto equal grounding because there was ecology, evolution, and development, eco, evo, devo, and then it's sort of, that's natural things happening.

And then often cognition and especially computational perspectives on cognition are seen as unnatural or designed.

And so again, all of these pieces are going to be woven together with a few pieces like bioelectricity and light cones that maybe people aren't expecting.


SPEAKER_00:
Cool.

So the roadmap of the paper, we're going to go through the introduction, then the paper is broken up into lots of different parts.

What is a self?

How do you define an individual?

Body patterning, cognition, multicellularity versus cancer, defining individuation from a cognitive perspective, the agent's evolutionary backstory, conclusion, future outlook, discussion, and then some predictions and research program.

And then in the end, what does it feel like to be a pancreas?

Which I renamed that part, but maybe you changed it back.

So we'll see.

Do you want to read over the keywords?


SPEAKER_04:
So here's the provided keywords were development, bioelectricity, and the related gap junctions, primitive cognition, and our favorite active inference.


SPEAKER_00:
So development, I like this quote from Seth Smith, Seth Mary and Maynard Smith, which I can never say Oris's last name.

I feel bad.

Sorry, Oris.

Developmental biology can be seen as the study of how information in the genome is translated into the adult structure and evolutionary biology of how the information came to be there in the first place.

So that's a kind of cool definition of development.

Do you have any thoughts on that?


SPEAKER_04:
It reminds me of earlier discussions we had about Tinbergen's four whys, which are kind of related to Aristotle's four whys.

It's like, why is there a foot?

Well, the easy sort of material answer is because there's matter in the shape of a foot.

But maybe you want to know something that's historical.

And over really long periods of time, it's a story about evolution, how the foot came to be selected on through time.

But development is just right there in the middle where it's the story for that individual, how that foot came to be.

Thanks, Sed.

Blue, could you turn down my mic?

It apparently is a little loud and distorted.

Thank you for the feedback.

Yeah, if anybody has comments on, like, the audio, Blue's doing an awesome job of first broadcaster role.

So thanks, Sed.


SPEAKER_00:
Cool.

All right.

Hopefully that's a little bit better.

All right.

Bioelectricity.

So this is a quote from the paper.

Developmental bioelectricity is the ubiquitous exchange of slowly changing ion-based voltage signals within and among cells.

All cells are electrically active and modern neurons evolved from preneural precursors that were already reaping the benefits of ionic signaling for computation.

Ionic signaling for computation.

So there's some ion channels.

I like that cool digital image of ion channels in cells.

And of course, this painting by Alex Gray isn't officially bioelectricity, but whenever I think of the word bioelectricity, I always think of this picture.

Do you have any thoughts there?


SPEAKER_04:
To connect the developmental aspect to what is mentioned here about the cells being electrically active,

the neural tissue arises during development from neuroectoderm.

So before there was sort of an inner layer of these electrically specialized cells, the ones that we call neurons, there was an outer layer.

And we see that recapitulated in embryogenesis when the neural tube is closed.

So that's combining sort of

Ontogeny recapitulates phylogeny, which is just to say that the development of the organism carries some resonance with the way that the organism evolved through time.

And then just to remind that every cell has those pumps that maintain charge.

Maybe not all of them are involved in rapid fire signaling, but to maintain ionic gradients and therefore bioelectric gradients is essentially what cells do with their membranes.


SPEAKER_00:
Cool.

And awesome segue into talking about gap junctions.

So this is something that's near and dear to my heart with my neuroscience background.

So gap junctions were originally attributed to neurons.

That's it.

Gap junctions are there at the synapse, and they facilitate the electrical signaling between neural cells.

But really, they're channels that permit cell-to-cell transfer of ions directly

And they were originally described in nerve and muscle, but they're really found in virtually all cells that are present in solid tissues.

And then I just did a quick, like, brief lookup of a recent review of gap junctions, and it's cool.

Like, they're involved in all kinds of...

um things right like so cell proliferation immune response migration optosis carcinogenesis hyper hyper proliferative skin disorders lymphatic vessel diseases inflammatory lung diseases that's like asthma liver injury and neoplastic disorders that's also cancer so i thought that that was kind of a neat um thing any thoughts on this one daniel


SPEAKER_04:
Just that active inference helps us think about how agents communicate and interact.

So if there's two cells and they have totally disjoint membranes, then they can both modify a niche in common.

So they could pump ions in and out of the fluid, like the extracellular matrix that's surrounding the cells.

So there's a common niche that they're sharing.

That's like the least connected they could be.

And then there are also ways in which they can have a long-term connection with a higher throughput.

So we're seeing a lot of these ideas of communication where you can talk about these two agents now directly exchanging information with each other as their electrochemical niche, rather than just jointly modifying the shared fluid that they're in.

Cool.


SPEAKER_02:
Okay, next.


SPEAKER_00:
All right, primitive cognition.

Let's see if I can play this video.

Did you want me to play it?


SPEAKER_04:
Sure, if it works on your side.


SPEAKER_00:
Let's see it.

Perfect.


SPEAKER_04:
Role of actin in cell motility.

Stunning 3D animation.

Maybe we don't need the sound, but nice.

Well, what is written in the paper is the emerging field known as basal cognition tracks the evolutionary history of learning and decision-making processes beginning from the dynamic problem-solving capacities of cellular and subcellular forms.

Many examples of memory, anticipation, context-dependent decision-making and learning are exhibited by organisms from yeast and bacteria to plants and somatic cells.


SPEAKER_00:
Cool.

So down at the bottom, what does cognition or intelligent behavior look like across scales?

Where and how does cognition arise?

And how does it develop or evolve convergent and divergent features?

And where does active inference come into play?


SPEAKER_04:
I think that first question is fun, because it's a little easy to off the cuff, just say, well,

I don't recognize the intelligence of a cell because it's not doing an undergrad course or it's not doing skillful performance like we talked about in a previous discussion.

So will we have a human centric conception of intelligence tied up with all of our cultural understandings?

Or is there something about intelligent behavior that might help us recognize it across scales?

And that's what turns us to these fundamentals like memory, anticipation, context-dependent decision-making.

And then once we open up to that functional level of intelligent behavior and cognition,

We start seeing it everywhere.

And so instead of just seeing these cells and their behavior as taking part of an intelligent system that, again, only blinks into existence at the top level, they're in and of themselves intelligent actors.


SPEAKER_02:
Awesome.

Let's see.


SPEAKER_00:
The video got me locked in here, sorry.

How about that?

You want to take us through that slide, Daniel?


SPEAKER_04:
Yep.

So it's written in the paper.

I propose... We'll come back to homeostasis in a second.

At the top, it's written...

Developmental bioelectricity is the ubiquitous exchange of slowly changing ion-based voltage signals within and among cells.

All cells are electrically active and we talked about that just a few slides ago.

How ancient are these mechanisms?

How early was bioelectric coordination exploited by evolution?

so this is raising the notion that early cognition was biomechanical it was biophysical it involved morphological computation like we saw on the previous slide with the movie of cells but also electrical affordances existed from the beginning and so if biophysical affordances existed from the beginning and allowed for cognition to arise

Then it makes just as much sense to say that electrical affordances for cells to communicate and do these types of cognitive processes also were exploited very early in evolution.

So primitive meaning at a smaller level, but also earlier on and suggesting that it's bioelectric was one of the earlier mechanisms of cognition is pretty cool.


SPEAKER_00:
And I like this quote from the paper that says, the ability to operate toward a region and state space may be the primitive origin of complex cognitive systems that can entertain counterfactuals, which is to remember or anticipate events that are not occurring right now.

So we'll touch back on homeostasis.

But how are the goals related to homeostasis?

How does bioelectricity play a role in homeostasis?

And I think we come back around to that.


SPEAKER_04:
On 17, I wanted to give an example about where bioelectricity and development came together with cognition.

And for some people, genetic reductionism makes it so that, you know, the story is not complete until we know what gene is involved.

And I think that they'd find this recent 2021 paper from Drosophila fruit flies to be really interesting because what they do with a series of experiments is actually demonstrate the importance of membrane depolarization, which is to say bioelectric capacity in

Gene regulatory networks.

So like HH and PTC are proteins that are produced by loci in the DNA.

And they're part of feedback loops involving the depolarization of membranes.

So they show that regulation of that membrane potential has an important role in signaling hedgehog.

And that there's a mutually reinforcing relationship between these two processes.

And then what does that allow?

Well, it allows morphological computation of this developing disc of the fly that later turns into the wing.

And so there's advantages and disadvantages.

Like with diffusible molecules, there's a tremendous amount of expressivity with what that molecule is.

Like you have an infinite number of hormone possibilities, but

But on the other hand, it's very slowly diffusing and maybe you can only signal a short range.

On the other hand, there's only like one electricity.

There's not like the blue membrane potential and the pink membrane potential as parallel membrane potential.

There's only one membrane potential.

So it's kind of a big knob to turn.

However, as shown here, it really does play a functional role in stabilizing gene regulatory networks.

If you were missing that part of the puzzle, it would be as incomplete as if you were missing a critical signaling molecule.

So I suspect that as it advances,

the kind that are going to be referenced in this paper, advances in being able to visualize and track and manipulate bioelectric fields become more accessible, that more and more systems that were thought to be purely chemical or purely mechanical, I think that there'll be a more important role for bioelectricity.


SPEAKER_00:
Right.

It is like one big surface, one membrane potential.

So you have one membrane and that's like the differentiator, right?

Between that's the boundary, right?

Is what is enclosed or encapsulated in the membrane versus what is not.

Okay, so here we are, active inference.

This is the final keyword.

And I pulled this image out from the Active Inference Lab, a previous live stream that we did with Ines and Thomas.

So this is the free energy principle of computationalism and realism, a tragedy.

And so this is just the basic action perception loop.

So you have active states, external states, sensory states, and internal states.

And so both of the active states and the sensory states are the blanket states, right?

So you have the internal can act on the external via these two blanket states.

So this is all of the sensory perception of the organism and the degree on which they're able to act on the environment.

Do you want to add any thoughts here, Daniel?


SPEAKER_04:
Just that active inference is a unifying framework for thinking about perception, cognition, and action.

And it does that in a scale-free way that's grounded in Bayesian statistics and physics.

So it's going to be deployed as a way to help us look for different kinds of behavior across scales.

Because the internal state could be internal to a cell, it could be internal to a tissue, internal to the organism.

etc.

It's that expressivity of the active inference framework that is going to come into play in the paper.


SPEAKER_00:
Awesome.

And it's a process, a scale-free process.

OK.

Active inference, as brought up in this paper, the author says, agents scaled up by evolving from basic homeostatic loops driven by active inference, surprise minimization, via addition of delays, which are memory, anticipation, which is inference, and networks,

spatially distributed processing that enables learning and progressive abstraction or generalization from the data.

Gathering into larger collectives with optimal information structure also improves the computational, i.e., predictive capabilities and gives rise to functional relationships such as memories, encoded goal states, test-operate, test-exit loops that exist over and above any individual member.

These levels coexist, enabling numerous coherent selves of different scales

to be implemented by any collection of living matter?

That's intense.


SPEAKER_04:
One of the other pieces about active inference that differentiates it from a framework like reinforcement learning is right there, that there's the minimization of surprise.

And in order to minimize surprise through time, you kind of have to be doing two things that at first pass don't seem like they're going to facilitate each other, which is the pursuit of what you already know is going to be useful.

That's called pragmatic value, as well as the pursuit of sampling things that will be informative.

That's epistemic value.

And so in active inference, the way that agents through deep time minimize their surprise about perception

That's what's referenced in the top paragraph about perceptual control theory.

The way that the agents minimize their surprise about their future expectations of perception is going to be by jointly working on pragmatic and epistemic aspects of their behavior and thinking about what behavior is going to be minimizing free energy in terms of kind of existing on the optimal trade-off where you're

performing, but also learning.

So these are a few features of active inference that differentiate it.

And then if we think about like a growth cone of a neuron, is it doing reinforcement learning?

Is it doing reward maximization?

It just barely makes sense.

But once we start to think about surprise minimization, like it's a dad with an evolutionary prior, it expects to connect to a neuromuscular junction, then maybe some of its searching behavior makes more sense.


SPEAKER_00:
And in the top section, also the author, you know, states that the sensory input layer is what enables active inference to operate.

So because there's receptors and channels that that's the perception, the perception for a cell.

Yeah.

Anyway, just thought I'd add that in.

Okay.


SPEAKER_03:
Greetings, Sarah.


SPEAKER_00:
Hi, Sarah.

Daniel, do you want to read these core assumptions and I'll fix the thing.

Thank you.


SPEAKER_04:
Classic.

So I'm only going to read the two highlighted parts here because these are paragraphs that people want more detail on.

They can definitely read the paper to learn more about.

There's three core assumptions that are laid out really clearly.

So I appreciated that about this paper, that it makes clear assumptions and shows how those assumptions come into play.

And then basically there's two avenues for disagreeing, I guess.

One would be, I think those are invalid assumptions, but they're properly applied.

Or one can think that there are valid assumptions, but improperly applied.

And so that helps structure discussion with the contents of the paper.

So the first core assumption is a commitment to evolution.

Every capacity has a natural history and emerged from simpler variants.

I guess also evolution can proceed through a reduction of complexity.

So eventually it had to have emerged from simpler variants, but in the short time, I guess it could have emerged from more complex variants.

But the commitment to evolution means the commitment to the dispelling of magical thinking and not looking for some sort of a metaphysical answer to our physical questions.

And the second assumption is

of the three is it is assumed that all metaphors are to be judged by their utility in driving scientific progress, and there is not a binary categorization of scientific pictures which should be taken literally or not, which can be decided a priori.

So we're not going around with post-it notes saying what's real or what's not.

We're using utility as a guiding metric.

We can actually just take a quick visualization and then Sarah, you can say hello and give any thoughts if you'd like.

But we previously in live stream 15 and 20 talked a lot about this continuum from realism to instrumentalism.

Like is active inference the territory itself?

That's realism.

We're really describing what's really there when we make an active inference model.

Or instrumentalism on the right side here is like active inference as a map.

We're just using it as something that could be used to capture some features of a system and then used instrumentally like a model.

Then here we've introduced this third vector of utility, which is like, okay, whether it's the map or the territory, orthogonal to that is, is it useful?

And so this is a space that's describing not just where we can think about active inference existing, but also ways to evaluate different models.

Not that one is better than the other, but these are just different dimensions that models exist on.


SPEAKER_00:
Yeah, I thought that was cool.


SPEAKER_04:
So Sarah, how goes it?


SPEAKER_03:
Okay, maybe go to the third core assumption.


SPEAKER_00:
On to the third one.

So much of the discussion centers around goals related to teleology, a hotly debated topic.

Here, goal-directedness is taken in the non-magical cybernetic engineering and control theory sense of a feedback system that operates to maximize some specific state of affairs which can be modeled as a dynamical system with attractors in its state space.

Okay.


SPEAKER_04:
So to reiterate these three assumptions, the first one is evolution.

The second one is utility.

And the third one is a non-magical sense of goal-directedness.

So these three assumptions play nice with each other.

And then they also lead directly to this final statement that except for a few briefer marks at the end,

No claims about consciousness defined rapidly as first-person experience or sense of self as qualia are made.

All the examples concern functional, third-person, objective capacities, computation, and behaviors.

So we're kind of like outside of systems, looking at them as an investigator,

This isn't about the first-person perspective, and there's always so much fascination and interest in what consciousness is, but in a way, these three assumptions go a really long distance towards just saying, hey, let's look at the system's behavior as we observe it rather than as we imagine it to be like.

So that's at least a starting point for a great discussion.

Before we jump into the figures, Sarah, do you want to...

Do you have any thoughts or say hello?


SPEAKER_01:
Sure, yeah.

I'm kind of coming in pretty disoriented, but I've tried to follow Michael's work quite a bit, and I'm enjoying discussing it from whatever angle comes up.

And, oh, I don't know, background, who cares?

I'm in philosophy right now.

Yeah, that's all.


SPEAKER_03:
nice well any slide you want to chime in on is great so i have to find the slides okay they're yeah anyway um


SPEAKER_04:
Go for figure one, Blue, if you want.


SPEAKER_00:
Sure.

So this is a continuum of cognitive powers.

And this is just the first part of the figure.

We'll show the next part in the next slide.

So this is a TOTE, which is Test Operate Test Exit Loop, which is a schema of a basic homeostatic cycle.

So the author says that by continuously taking action to minimize the distance, the difference and error between the current state of affairs and a set point describing a different possible future state of affairs, it enables a system to pursue goals despite perturbations from the outside world and intrinsic noise.

So this is I thought, cool, like, you know, the first like possible counterfactual, like, yes, it's 75 degrees, and I have plenty of sodium and potassium and, you know, calcium, but but what if I don't always what if it's not always this way, right?

What if what if it my state changes?

So like that the first counterfactual maybe enabled this kind of homeostatic feedback loop.

I thought that that was a neat idea put forward in the paper.

So how is this related to active inference or systems engineering, Daniel?


SPEAKER_04:
Well, the terminology reminded me a lot more of engineering than we often see, like sensors and actuators.

It makes it sound like it's going to be a robot.

And also this like test exit sounds like we're going to be doing sort of software evaluation.

But we can pretty clearly see the skeleton of action perception loops, whether it's framed as it was a couple of slides ago with internal external states and then blanket states.

Or here, where you basically have the difference between the desired and expected value leading to policy selection, not shown here, leading to action.

Actions cause events in the environments on the yonder side of the blanket, and then the state of the external environment influences the measurements on the inbound side, which are again contrasted with the idealized state, and that leads to another round of action selection.

So this is an engineering way of laying out the TOTE test operate test exit loop.

But who knows?

We're able to jump from Active Inference pretty nicely into a more engineering frame.

And so perhaps engineering could be integrated closely into Active Inference.


SPEAKER_00:
Yeah, it seems like the blanket states, like the sensors and actuators, like our, you know, the action perception part are here in the middle.

And so it kind of reminds me of the active inference loop, like diagram that we showed earlier.

So it's interesting.

Next part, do you want to go through this one, Daniel?


SPEAKER_04:
Yeah, so in figure 1b, the caption reads that the scale is showing how different types of activity and systems can be ranked according to their degree of purposeness.

So again, think about purpose in the third person, not the first person.

It's not the sense of purpose, but more what I believe Hofstetter called the anti-spexus-nish.

I'm not sure how to pronounce it, but it was like, think about the most mindless behavior, and then

push away from that.

And that's what you can call purposeful rather than imagining that there's like this pure crystallized purposeful behavior.

And it sort of goes from bottom to top in terms of the degree of purpose ability.

And on the bottom we see basically just action that doesn't appear to have any kind of sense or purpose to it, like maybe gas molecules bumping around.

then we progress through higher and higher levels of feedback loops and then each one of these brackets it's kind of like a distinction so like starting the left behavior you can take the right branch or the bottom branch passive behavior like a ball that's being thrown or active behavior okay active behavior is it going to be non-random um or random like

Many things are random, but is it a wind-up toy that's just doing something that is not appearing to be too purposeful?

And you continue up and up the branch, choosing the higher branch each time until you get to these first and second order predictions and higher order recursive logics, which are seen as higher and higher levels of purpose.


SPEAKER_00:
Cool.

Do you have any thoughts, Sarah?

OK.

Daniel, do you want to take this one?


SPEAKER_04:
What is an individual?

Well, there's so many ways to go about this, and as an ant researcher, that's always the debate.

Like, okay, is the individual the six-legged next mate?

And then that makes the colony like a society or a super individual, or...

is the colony of the individual and then the nascent is like the tissue.

So there's a lot of discussion around what constitutes an individual and how would you determine where the boundaries of individual individuality are and that

A piece I just referenced about establishing the bounds can be done in a few different ways.

One of them would be looking at where information theory is strongest or where information flows are occurring.

That's the information theory of individuality.

And here we're going to take a cognitive perspective on individuation.

And McCulloch is quoted so early in the neural network days.

The definition in the paper is, I propose a definition of an individual based upon its information processing structure, the scales and types of goals that a system can pursue defines slash determines the boundaries and contents of the putative agent.

So it's an informational lens on what constitutes an individual.

Like we can say that individual people become maybe an individual mob, just one mob, not multiple mobs when they start integrating information differently, or when they start pursuing different kinds of goals in a different way.

And it touches on these big questions, like why does it matter how we define individual as well as what other ways of thinking about individuality exists.


SPEAKER_00:
Yeah, it's intense, right?

So not only like in the information theory of individuality, is it like the most concentrated information, but it's also like that bi-directional information flow, right?

Is how Krakauer and that group, the defined individuality in that paper.

And so that's super interesting to me.

Like at what point is there downward causation in an aggregate?

Like...

So at that point, that is like the crux for how they talked about individuality, which is, I mean, it makes sense to me, right?

Like, you know, my brain tells my foot to kick the ball, or I decide I want to kick the ball, and so my body then acts accordingly.

But it's really interesting to think about when that emerges, that downward causation in a system.

Anyway, something I think a lot about, probably too much.


SPEAKER_03:
What about you, Tara?


SPEAKER_01:
Yeah, that is actually one of the few papers I actually have read.

And I like went with a highlighter and everything.

And I always wonder on on I was looking through the math on that and actually learned a lot about like math I didn't even think was possible yet.

But it was it was binary in a sense.

It was digital.

And I'm never clear about when that matters and when it doesn't in these kinds of models.

So that's one thing that came up for me.


SPEAKER_04:
Sounds good.


SPEAKER_00:
Next slide.


SPEAKER_04:
Figure 2.

No, it's not The Sims.

It's a cone of individuation.

And in 2A is this sort of cone-based representation of individuality that's going to be returning in a few different guises in the paper.

and on the plane going out in different directions from a central point is like the zone of influence or the extent of the system's ability to perceive act plan and then piercing that coming up and down in the z dimension is going from the past to the future and so

This is a cool way to look at how multi-scale systems or what are called compound intelligences down there on the bottom right exist.

So we can use this kind of a cone representation to look at single cognitive agents and potentially contrast them, like in part B, where we have a tick with what's hypothesized to be like a smaller scope spatially in the now, as well as a shorter temporal scope in the past and future, compare a tick with a human, and then also ask maybe about what kinds of other

cognitive forms exist, and then these cones can be composed really nicely.

So like on the example on the bottom right with an ant colony, again, controversial to say that the ant is the organism when potentially the colony is the organism.

That's why I usually call them a nestmate.

But we can see how the nestmates are inside of the colony within this cone.

And so the colony pushes out the boundaries

of what these ants can do.

So they're kind of like on different parts of the spatial plane in the current moments.

And then the colony is something that is cognitively able to move beyond the time horizon of an individual nestmate by virtue of its collective organization and information processing.


SPEAKER_00:
This is cool, and something that we talked about a lot offline in preparation for this and preparing the slides is the inversion of the typical light cone.

So maybe, Daniel, you want to walk us through this light cone, and then we can maybe go back to the other one.


SPEAKER_04:
Yeah, so this is a similar light cone notion, and it's just that instead of having the two cups meeting mouth-to-mouth and then coming pinched off in small time,

Another way that light cones have been represented is actually with the current moments, like the eye of the needle, like an hourglass, the pinch point.

And then in the past and in the future are the set of states that influence a given point and then the set of states it influences.

So let's think about that butterfly flapping its wings in the here and now.

So if you go back one time step,

the air molecules that might influence it are like one layer of air molecule away.

And as you go back and back and back, more and more spatial extents matters for the state of the butterfly in the moment.

And then similarly, one time step in the future

the butterfly's flapping is only able to influence a small zone proximal to the insect, whereas further and further out into the future, more and more spatial extents might be modified because of the actions that happen in the here and now.

And then this is a Lee Kors cabinet, a joke on a liquor cabinet, but it's a paper that actually uses this kind of an approach to do modeling of empirical data and to fit machine learning models, which we can talk about going forward.

Why and how do you get a speed up of certain kinds of simulations or data fitting by approaching it like a light cone?


SPEAKER_00:
So it's just interesting, the axes here, and this is kind of how I'm used to seeing these represented, are time and space, right?

So in physical space, I am physically in this space that I am at right now.

And it's interesting, as you go forward in time, given enough hours, I could theoretically fly from New Mexico to Singapore.

But for right now, I'm kind of limited to my house or my block, or I don't have point-to-point transport.

So I always like the way that Mike represents this light cone, like in this way, like in the inverse, it's like time and space and, you know, it starts in a very broad space.

And it proceeds to a very narrow space.

And it's like, of course, in the past, like if I go to my distant past, like I came out of an egg that was in my mother's uterus, right?

Like, so in my mother's womb, like I came, that's where I came from.

I was in that one point.

And I've gone all kinds of places, I guess, until now, but I'm not, I don't feel like I'm many places now.

And I also don't feel like I'm going to be many places in the future.

So I'm interested to talk to Mike when he comes on to the live stream about the way that this is represented, because it's very different.

Do you guys have any more thoughts on that?


SPEAKER_01:
Yeah, I have one.

I mean, it seems to me he's almost trying to do, he's almost trying to take the case of the light cone and look at a particular ambition that you might have at this point in time

And then, and then can you carry out that ambition through time?

And as you get further and further, you realize there's all these impediments, you know, that, that come in your way.

And so it's this like one access is the ability to envision, um, what it is you want to do.

And the other act access is the ability to enact it is the ability to, well, even control or whatever your environment, any number of things that are required to enact, uh, this, this vision that you have.

And that's interesting.

Interesting access transformation.


SPEAKER_04:
Agreed.

The light cone that looks more like an hourglass is kind of related to our limited degrees of freedom in the current moment.

but it you know expanding out into the future of what we can influence and then the the diamond shape that we see in figure two is more like our zone of what can be cognized which goes beyond what we can influence in the current moment because there's some future time when you won't be able to imagine you know you know as as the the curtains close on life

and it narrows in and it's like smaller and smaller and then there's some point where your capacity to influence is actually kind of toned out and so there are two complementary ways to look at the same thing although it's interesting i want to say because i uh you know like


SPEAKER_01:
You look at that, like, there could be some inner supervening or intervening thing where it actually helps you that you never considered in this in this cone of possibility.

So you become wider, like really, it's just the winding road, right?


SPEAKER_00:
For sure.

All right, moving on, let's go to 28.


SPEAKER_04:
This is sort of taking the light cone.

There's just one and a half more slides that take the light cone in a little bit of a different, more physical direction.

But again, it's all part of a continued conversation.

So we can look at the now.

That's the middle of those three layers where there's two different individuals, Sally and friend N. So it's like two of those are at different points now.

And so then we look over on the time cone on the right.

And so Agent N is, you know, Nick, that's the one that we're focusing on.

And now, at the same time, they're at the same moment, but they're in different points in space.

So from the point of view of N, S is a space-like point.

But then in the same spot,

in the future or the past f or p in the same location you know the same address 20 minutes ago is time like and the same address 20 minutes in the future is also time like but then on the edges of this cone is like light which i i don't know the physics behind but i think it's kind of a cool idea that space and time have this

boundary nature and that there's things that are more space, like, like things that are instantaneously at the same moment, but in different spaces and more time, like the pure case being the same location at a different time.

But then it's like, Oh, I'll meet you in 20 minutes, two blocks away.

That's like moving through both space and time.

And maybe light does that in a kind of unique way.

So that was just one way that in relativity,

that they talk about light cones, and indeed the light cone concept is a physicist's concept.


SPEAKER_00:
That's really cool to think about, like, that light is the boundary between space and time.

That's kind of a neat thought.


SPEAKER_04:
Yes.

And then on 29, I just wanted to pull one again, the details going beyond me and this discussion, but here in a recent paper that explored how you could do simulations using light cones.

And so this is not just like sort of a metaphor, a cognitive heuristic.

This is something that you can use for large-scale data analysis.

And so the way which I alluded to earlier in which you can speed up a simulation potentially by using the light cone is by having a point that you're focusing on, and then you only need to consider one time point in the past at a radius of one spatially, two time points in the past, a radius of two spatially, three to three out.

And so it helps you reduce the space of what you need to calculate from all versus all

to the idea of calculating more and more out in more and more past steps and more and more out as you go into the future.

So that's because in the physical interpretation, there's a speed of propagation through a media.

So things don't happen instantaneously.

So that's like light moving through a media at the speed of light.

And then in the case of information propagation, it's similar.

Like if you wanted to focus on a given person and their role on an informational network, you would maybe make like an informational cone instead of needing to calculate all by all at every single time steps.

So it just made us curious about how active inference related to light cones.

So how can we apply this to some of the simulation models that we've already seen?

And then just what does the past of the light cone represent?

What is the current moment?

What's the future?

Just fun, eternal questions.


SPEAKER_00:
Cool.

Ah, so I made this slide.

This is funny.

This light cone I actually showed when I gave a seminar at Mike Levin's lab a couple years ago.

It's from Andrew Gallimore's paper, Restructuring Consciousness, the Psychedelic State in the Light of Integrated Information Theory.

But I was thinking about this in terms of shrinking and expanding the boundary of the self, which the author discusses a lot in the paper here.

And just like how that would change your effective light cone, right?

Like, so if you have your self boundary, it's like a limited light cone, like the darker one that's shown in this figure on the right.

And if you expand the boundary of yourself, it expands your light cone.

So it made me think of that as we were talking, as he was talking, as Mike was talking about the

shrinking and expanding the boundary of the self in the paper.

And so I'm really curious, here's a couple of quotes from the paper about boundary establishment and maintenance.

So he says, the surrounding body becomes an informational shield or Markov blanket for the stem cell.

And this is, he references Carl Friston's 2013 paper.

And so I wonder about like the Markov blanket.

And I think that, you know, Daniel, this is something you and I have talked about as well about the Markov blanket, like being the defining boundary for the individual and like how, I mean, things must pop in and out of a Markov blanket, right?

Like if I think about the cells that are in my skin layer, right?

Like,

I mean, I'm losing them all the time and new ones are constantly being added.

So there's no distinct hard line to be drawn.

So like under, like how do things pop in and out of a Markov blanket?

Like, and what do you, can you like just have like peripheral boundary nodes on the edges there?

Like I've talked before also about like the difference between like your fingernail and your cuticle.

Like there's like a small tiny layer that doesn't know whether it's a fingernail or a cuticle.

So it's like,

How do you, like, have these, like, boundaries, right?

Anyway, another quote from the paper.

Crucially, by organizing into a partial electrochemical and informational pool or synctitium.

Somebody say that for me, please.


SPEAKER_04:
Sincidium.


SPEAKER_00:
Sincidium.

There we go.

All of the cells are able to measure and detect events occurring within the same boundary, creating a larger individual that emerges from the collective.

And I think this quote was like in reference to

the gap junctions and how they expand that electrochemical pool by like, they open up like some, like they pull the plug on the electrochemical gradient.

And so it kind of enables this like cell linkage.

So that's one one way that, you know, boundaries are maybe established, but any thoughts on this, guys?


SPEAKER_04:
We'll come back to it.

I think I have a few thoughts on where the Markov blankets come into play through time.


SPEAKER_00:
Cool.

All right.

So homeostasis, which we promised to come back to.

So what evolutionary pressures led cognitive boundaries to expand?

This is from the paper.

And the author proposes that the atom of this cognitive hierarchy is homeostasis.

So reactive homeostasis evolves into predictive allostasis under the pressure to predict signals from the environment and other elements of the biosphere.

And that's like what I was talking about earlier about the first like counterfactual about, you know, what if it's not always 76 degrees and full of nutrients in my environment?

How can I regulate that, reduce my uncertainty about future availability of the supplies that I need?


SPEAKER_04:
And also there's this nice progression from homeostasis.

So that's sort of like similar, you know, same homeostasis.

It's the thermometer is trying to get within the bound.

But the best way to stay within the bounds when the environment is changing is actually to not just be reactive, but to be proactive or predictive.

And then what's the best way to be proactive?

Well, it's to have increasingly rich generative models of the niche.

If you know that nighttime is coming, you're going to be able to take really good predictive behavior right now for tonight.

If you know that winter is coming at a larger timescale, it's another level of you being able to make adaptive decisions.

So what looks like homeostasis sometimes is,

can actually just be very skillful predictive allostasis.


SPEAKER_00:
Do you have any thoughts, Sarah, on that?

Cool.

Okay, so this one is memory and scale-free cognition and active inference.

So, I don't know, I just had some thoughts here, like memory as a gene regulatory network, and this is kind of something that not really was stated in this paper, but really, like,

You know, it's our evolutionary memory of, like, where we've been before and how we've come to regulate and, you know, work within our environmental condition and, like, also memory as a process.

Like, I don't know.

I think about that.

Like, where is it stored?

Is it externalized into the niche?

Like, we do a lot of niche modification.

And so...

i don't know um it's interesting to think about our our ram and our rom in um in like a biological sense so it's the author says a second step in the simplest homeostatic loop is the inclusion of a richer set of hidden layers in the neural network sense so these are additional biochemical nodes between sensors and effectors of a given system that enable a degree of memory

And importantly, memory can serve as the beginning of modularity because learning essentially groups diverse stimuli into compressed representations.

Complex states of affairs become remembered as compact biophysical engrams.

This is the essence of the kind of modularity when a simple biophysical event kicks off the formation of a complex morphogenetic cascade, such as building a hand in embryogenesis.


SPEAKER_04:
one nice point there is the difference between modularity and memory about how they enable each other it's sort of like if everything is being mixed in one cup there can't be a memory of different colors okay well if you have two separated cups you can remember two different colors and so on so memory can serve as the beginning of modularity is saying that it's this um relationship between things becoming distinct

and being remembered through time.

Distinctness carried through time is memory.

You can remember a longer number when you have more modularity that's being propagated through time.


SPEAKER_00:
And then the paper on the right is an older Friston paper talking about memory, attention, and salience, and active inference, where they described memory, working memory, as a process of evidence accumulation in a temporarily structured hierarchy.

So I guess like going back through deep time, like that's where the gene regulatory network kind of comes in as a process, right?

Like the process of evolution.

And that's like the working memory there.

Anyway.


SPEAKER_04:
And just to give one note there on the multi-scale active inference models, sometimes the way that memory is being modeled in active inference is as a state variable that changes at a slower rate.

And so within the longer time scale model, we have a shorter time scale model.

And then that can be modeled from setting to setting as memory carrying over.

And so it relates to this idea that the larger cognitive system is able to also act over longer timescales as well as reach back with a deeper memory.

Because if you have the kind of short-term model that's just standalone, it's like a memoryless process.

But if that has inherited from a hierarchical model, the state from a previous click of the model, it's memory.

And then if it's able to imagine one more click out into the future, it's goal planning.

It's anticipation.

And so in active inference, one of the ways that we integrate memory and planning

together is by thinking about hierarchically nested models.


SPEAKER_00:
So also I wonder what role memory plays in policy selection.

Like I remember every summer when I go to Scotland, it is cold, right?

Like, I mean, I live in New Mexico.

It's like 120 degrees Fahrenheit.

So every summer I remember that when I go to Scotland, it's cold.

So now it's my policy to bring a jacket when I go, right?

So even though it's the summertime and I wouldn't normally do that.

So is that memory also ever modeled in the policy selection, Daniel?


SPEAKER_04:
It's a good question.

I wonder if you can plan to forget, or I'll make a note, I'll plan to remember.

I'd say active inference just gives us a way to think about all those different affordances that real cognitive systems have, like offloading memory to the niche through external computation, or in terms of what you just described.

But that's a good question we can ask.


SPEAKER_00:
Right.

I don't actually even need to remember that it's cold in Scotland because, you know, I can just ask Google.

They will tell me the weather and it will be cold in Scotland.

So if I just remember to, you know, check my cognitive offloading device, then I don't even need to remember to drink a chocolate when I go.

Yep.


SPEAKER_01:
Okay, next.

I have one random thought.

Maybe it comes up in another slide, but this question that Michael Levin has about how does it know when to stop in terms of cell growth and morphogenesis, if it's the case that it's connected to memory in the way that he's suggesting, then maybe it's related to information flow.

I guess that's maybe obvious given the focus of this.

But it is interesting, you know, it's like the cells are just like, oh, we've got to now become multi-bodied or, you know, or become social rather than individual in order to store memory.

Like there's this funny, like, break point.


SPEAKER_00:
Yeah, I didn't see the stop mechanism really brought up in this paper, but I have seen it.

So I'm not really sure where it ties in here.


SPEAKER_02:
Mm-hmm.


SPEAKER_00:
Figure three?


SPEAKER_01:
I mean, if you call it a morphogenic cascade, you know, it's like, well, we're born, we grow, we grow to a certain point, and then we shrivel and die.

So it's like, how does that connect to memory and information?

It's kind of suggested.


SPEAKER_04:
Yep.

So figure three is looking at a sort of cell's eye view of that time cone.

And now we're going to step away from, you know, is it a time diamond or is it a time cone?

And we're going to think about the trajectory of a given cell.

Go back to the assumptions of the paper, though.

This isn't about whether the cell is experiencing things.

It's not what it's like to be a cell.

It's about how the cell has a given spatial extent in A. It has a given spatial extent that can be thought of as having a memory.

It inherits a history through time.

And then also has an anticipation zone in the future.

it can do anticipation and memory as a sole agent or it can interact socially so what happens when it interacts socially with other agents like itself well it expands the spatial dimension in the now that's what's being called integrated spatial perception

And that allows it to have expanded memory in the past.

Like if each of your five friends have a book, then there's more memory as a group because there's more books.

And then also the ability to extend the anticipation into the future.

And then this part I just highlighted in blue is

Joining into communication networks allows the cell to have temporarily delayed access to the information obtained by neighboring cells.

This is where the time cone comes into play.

It's not that when something is perceived by one of these cells off on the fringe, the focal cell doesn't instantly hear about it.

They hear about it one time step later.

So that's where the time cone comes into play.

Because from the point of view of this focal cell, just assuming that information moves one cell per unit of time, then at zero time points, its radius is one.

one time point away, its ability to integrate sense is one more radius away.

And so you can keep on clicking back and that's reflecting a broader and broader zone of memory, or you can carry it forward with a broader and broader zone of influences or of states that it can affect.

And so the resulting larger individual, and again, individual is being used cognitively here, not like evolutionarily,

is formed with a cognitive world that's unified by the cell's sharing of information across time and space.

So, no teleportation and no time travel.

The limitations of propagation of information in our physical universe means that from the point of any given cell or agent, it's existing in this time-cone-like structure.


SPEAKER_00:
Yeah, that was like the expanding the boundary of the self and like kind of like what happens, like the time cone is expanded.

And you know what, this just makes me think of, well, first, I just want to remind everyone that this like cell-cell communication is like what gap junctions facilitate because they're really connecting all cells and solid tissues.

Um, but, but really I thought about, you know, the old adage that you are your company.

And like, if you think about, you know, your five, like closest friends and that like communication, like network that you have, like you hear about, you know, world events or events that are relevant to their lives, it might be relevant to you.

Like you hear about it one time step later and just how like, you know, your cognitive like boundary is expanded by like your inner circle.

I don't know.

Made me think of that.


SPEAKER_01:
Yep.

Hey, Blue, can you just re-highlight or talk about the cell tension that you were just mentioning?


SPEAKER_00:
yeah so that was earlier in the talk it was one of the keywords so let me just go back to that slide um so here uh these gap junctions so they they are they were originally you know categorized in like neural tissue and uh and muscle you know to facilitate like rapid communication but they're really present in every cell and solid tissue and they they just perform

Not ion exchange, but it's like passive diffusion of ions so that it's like almost a shared intercellular space.


SPEAKER_01:
So would it be safe to call that a kind of a information bottleneck?

I just wonder.


SPEAKER_00:
So maybe not as much of a bottleneck as it is like it pokes a hole in the informational boundary.


SPEAKER_04:
The more rapidly, let's just say that the gap junction, so the no gap junction, it takes three time steps for the signal.

One time step to release the molecule, one for it to diffuse, one for it to be perceived.

So every three units of time, you're getting a radius expanding out by one.

Now let's just say that a gap junction allows one time step, the direct diffusion.

So then the time cone is expanding wider.

because the diffusion from the target cell is able to sweep out a larger time cone.

Whereas if, again, if it took three units of time for every one of diffusion, it'd be like a narrower time cone.

So rapid communication, which is never instant, allows that time cone to access more memory into the presence and then influence more broadly

And so bottleneck is sort of like thinking like a bottleneck is a constraint relative to the width of the bottle.

But in the context of a gap junction, it's actually like a channel or an opening for information transmission.


SPEAKER_00:
So if you think about it in terms of like your inner circle of friends, imagine like you can wait for your friend to call you up and tell you this exciting new event or like you can have a wiretap into their house.

So like the gap junction is like having a wiretap into their house.

So like you always know like what is going on.


SPEAKER_01:
Okay, what I'm also searching for another analogy that's just saying to the stuff I've been looking at lately.

Do you think it's fair to analysis to You know, a compression function like, you know, if you take a picture of the classic neural net, you know, a bunch of notes here, just a few in the center of the hidden layer and then expand it out with with it better be a fair analogy for a jet gas junction.


SPEAKER_00:
Yeah, I'm not seeing it.

Sorry.

Okay.


SPEAKER_04:
Okay, I would just, to recover it, I would just say the transmission is like a compressed form of, it's like a little sampling of the chemical milieu from one cell being passed to the other.

If there was no bottleneck,

no compression of information, they would be just in one unit.

They'd be in one Markov blanket.

And so there's this trade-off where if you totally isolate, the rate of information propagation is low.

The modularity is very high though.

On the other hand, with total integration, you can't have memory because you don't have modularity.

However, you do have instantaneous or close to that transmission.

And then the gap junction exists at this kind of sweet spot that allows for modularity with narrow channels of communication, which is what Shannon was studying in the first place.


SPEAKER_00:
Cool.


SPEAKER_04:
So the figure... Okay.


SPEAKER_00:
So figure three, I think we just popped on the cone.

Is that true?


SPEAKER_04:
Yeah, that's just a...

draw the connection between the figure of two with the time diamonds, time cone, and then just this figure.


SPEAKER_00:
Cool.


SPEAKER_04:
Okay.

Figure four.

Go ahead.

Figure three, the slide that we just had was as things build out.

That was the point of view of the agent building out, and now it's like things fall apart.

So figure four, we see a sort of rehearsal in B of what we saw previously, which is that that target cell, it's combining sensory information that's enabling it to detect patterns more rapidly, getting a big picture.

That's what it says in B. And therefore missing information can be anticipated by this pattern seeking drive.

But what happens when things go wrong?

That's in C, where this bottom right cell, the green one, has gone rogue.

It has stopped communicating in a way that was participating in this broader sense-making, and it has shrunk its sensory radius down.

And so in doing so, it reduced the cognitive capacity of the other four cells.

it has reduced its own sphere of influence, and it's also introduced this adversarial dynamic potentially over evolutionary or developmental timescales.


SPEAKER_00:
Cool.

Any more thoughts on that one?


SPEAKER_01:
Yeah, it reminds me of a friend I know, but


SPEAKER_04:
no otherwise it also reminds me about how cancer research is starting to think more about the niche and the signaling between cancer and non-cancer cells like cancer cells need to call down healthy blood vessels they need to prevent healthy immune response from taking them out

And so it's like cancer as a dialectic or as a relationship between agents with different goals, again, not the experience of the goal, but acting as if it has a goal, that third person cybernetic teleology.

And so that helps us make sense of all these disparate features of cancer by thinking about internal and external states, information propagation, et cetera.


SPEAKER_01:
Do you think it would be right or off to think about the one possible place where that could go wrong happening at the gap junction?

Like the gap junction would no longer function as a good

sampler compression thing, which I know you don't agree with the analogy, but something like that.

I don't know what's happening in that research area, but does that make any sense?


SPEAKER_00:
Yeah, we talked about gap junctions earlier and their involvement in neoplasticity and all kinds of other disorders.

So definitely.


SPEAKER_04:
I just found this really nice paper called Gap Junctions in Cancer Communicating for 50 Years.

And the abstract starts with 50 years ago, tumor cells were found to lack electrical coupling, leading to the hypothesis that loss of direct intracellular communication is commonly associated with cancer progression and onset.

So that's pretty interesting.

It's like when you shut down the lines of communication, like between two countries,

Are those two countries having an improving relationship or is that like the last time that they spoke before war?

So closing down the embassy, shutting down the gap junction, it doesn't bode well for sort of amicable resolution to conflict or communication.

That's why it's so important to maintain the avenues of communication.

even when there is an adversarial relationship because things can always get worse you can always shut down the communication which will make the generative models and the incentives and the goals diverge even more cool i don't know just all of a sudden you go into politics and i'm like oh yeah but wait a minute anyway

but we should shut down.

They're bad.

We should shut down.


SPEAKER_01:
No, I wasn't thinking that, but if you keep the channel open, you also stand more chance of injury by way of keeping the channel open.

So, yeah.


SPEAKER_04:
Keep the channel open until you shouldn't.

This is just a fun discussion for a little bit on the evolutionary anachronism, which means just something that's happening at a different time than it's expected, like a feature from the past that gets brought back, like

an evolutionary reversion.

And so in the paper, it's described that this is a breakdown of multicellularity and highlights the fact that the scale of the structure which cells work to maintain can change rapidly from cooperation towards an entire organ system or body to

that's a healthy organism, to the level of a single cell.

So instead of seeing cancer just mechanistically as a derangement of signaling or a derangement of replication and DNA reproduction of a cell,

We can think about it informationally and cognitively and cybernetically.

Like the cell has changed its cybernetic horizon from the goals of the organism to its own local goals.

And so this concept of an evolutionary anachronism and how even in the current day, we can study anachronism.

An example is with avocados, a tasty fruit.

And as per the Wikipedia, it says avocados are exceptionally fatty fruits with seeds far too large to be successfully dispersed by any wild animal presently alive in the Americas.

And so that is a paper of Janssen and Martin in the 80s.

which was actually talking about the ecology of large animal plant interactions of animals that we've never directly seen.

But it's like if you know that there is a really large seed and you know that there's seed dispersing mammals, then it can lead you to hypothesize that there was a seed disperser that was large enough to eat avocados whole.

And so we can look at anachronism in the current moments

and help us retrace the past.

So just like the avocado is an anachronistic trait with such a large seed given to the current ecology, not the past ecology, we can see cancer as this anachronistic reversion to a previous mode of information integration and goal setting that it's like it's inappropriate in the context of the goals of the body, but

not necessarily within the goals of a single cell that just wakes up one day, it's like, wow, I'm bathed in glucose, I should replicate.

So can't blame that.


SPEAKER_00:
Also, like the cancer, a lot of the markers in cancer cells are really like, it's like a developmental reversion.

So not sure if you guys are aware of that or not.

But it's like they they revert to like a more immature cellular phenotype.

And so that that I mean, it's literally like going back to the past.

So interesting.


SPEAKER_04:
Yep, stemminess.


SPEAKER_00:
Yes, stemminess.


SPEAKER_01:
Are there, like, degrees of reversion?

Like, is there something to be learned from the degree of reversion?


SPEAKER_00:
The degree of stem celliness?

I'm not sure.


SPEAKER_04:
One thing that comes to mind there is there's some cancers where the it goes back to like a stem cell of that tissue.

So like it's like a white blood cell cancer that like replicates a lot of white blood cells.

But when there is a cancer in a reproductive organ, sometimes it's like called a teratoma because it can have like hair and nails and stuff like that, because it's actually pulled back so far that it can then differentiate on all the pathways totipotent cell, rather than a reversion up from being like a healthy reproducing white blood cell precursor to just a higher

like a white blood cell stem lineage but it doesn't pull back all the way to including ectoderm whereas if it was in um you know a reproductive cell then it could do that cool biofilms do you want to take this one daniel

Yep.

So I think the key point here is that bacteria have ion channels just like metazoans do.

Dopamine, GPCRs, the proteins that signal between neurons, those are not innovations of mammals.

They're not innovations of vertebrates.

Those kinds of channels and diffusible molecules are cellular.

They're panacellular.

And so what's being shown here is just like in previous figures, we saw one kind of eukaryotic cell, right?

You knew because it had a nucleus.

We had one eukaryote connecting with a few other eukaryotes.

Well, here we have one prokaryote connecting with other prokaryotes to do the exact same thing, which is increase its sensory capacity.

Again, not instantaneously, but think time cone, light cone.

And so in the same way that the eukaryotic cells form a cognitive individual through their associations and affordances, such as the gap junctions bacteria, when they form a biofilm can also form a larger cognitive integrated individual.

And you can still say, well, but from an evolutionary point of view, the unit of selection is the single bacteria.

Okay.

But that's the evolutionary individuality definition.

And when we use the cognitive individuality definition, we see a lot of the similarities between a multicellular organism's tissue and then a multicellular biofilm tissue.


SPEAKER_00:
Even not in a biofilm, I mean, bacteria have an incredible ability to like, I mean, it's like antibiotic resistance, right?

Like they do plasmid exchange, which isn't like their chromosomal DNA, but it's like small little snips of DNA.

Like they just like have a handshake.

Like it's like a bacterial handshake.

Like now I'm going to give you some antibiotic resistance too.

Like we spread germs like COVID and bacteria to one another.

They spread like plasmids to one another.

which which confer different properties you know and then we select for this like antibiotic resistance through the use of all of our like antibacterials and so only bacteria that have these little plasmids are survive it's really interesting so even outside of a biofilm they do some some kind of um you know communication and like cognitive expansion of their self in like the way that we do with our inner circle of friends nice

Cool.

All right.

Key ideas.

I just highlighted a few of these like points, but there's a huge box in the paper.

So we'll just read through the highlighted parts here.

I'll take this one.

So first, a unified integrated cognitive self or individual can be defined with respect to the integrated ability to pursue specific goals via a homeostatic process that resists perturbations.

Second, an agent's cognitive world can be quantified and characterized, enabling comparison with others regardless of their material implementation, by estimating the spatio-temporal boundaries of its area of concern, the volume in space and time over which the agent is able to take measurements, exert influence, and functionally link disparate events, learning, and association.

Three, the borders of the temporal and spatial events of which a given system is capable of measuring and acting map out a cognitive light cone, a boundary in the informational space of a mind.

So estimating the spatio-temporal boundaries of an agent is something I find particularly interesting.

So I just put that in as a question at the bottom.

Do you want to read some of the next ones, Daniel?


SPEAKER_04:
Yep, so these are some key ideas four, five, six.

So four, cancer is a reversible shrinking of the computational boundary of a biosystem.

Pretty tantalizing there with the reversible.

I'm sure that's something that a lot of people would like to see.

Maybe the idea is you remind the rogue agents about bigger goal.

Like, hey, you know, I know you're hungry, but we wait in line at this restaurant so that everybody gets what

takes care of them.

And maybe that helps remove the cancerous restaurateur.

Five, agents scaled up by evolving from basic homeostatic loops driven by active inference, which is surprise minimization, by the addition of delays, which are memory, anticipation, which is inference, inference has planning as inference, and networks, which is spatially distributed processing, enabling learning and progressive abstraction generalization from data.

That's pretty cool to see active inference and elaborations of active inference at the heart of this future electrical evo, eco-devo.

It's like saying you start with action and perception, and then you can carry that forward in time, planning, anticipation.

have an extended trail of memory.

That's the past.

And then you can also expand spatially.

But again, the spatial isn't instantaneous.

There's a propagation speed in the media.

And so even laterally, similar agents interact through this light cone way.

So nice to see where active inference plays into light cones there.

And then six, infotaxis, the drive for better actionable intelligence about the regularities and patterns in the world and in the agent's own mechanisms, encourages cells to connect in groups via signaling.

This is another area where active inference has a lot to say and is a value add relative to a reward-only framework like reinforcement learning.

Because, again, what drives the bacteria to coalesce and to work together?

Maybe it's reward, but then you have to appeal to this idea that they're maximizing reward with their behavior.

It's a stay or leave and all this kind of stuff.

Infotaxis helps us understand that the way to get good actionable intelligence, which is kind of like active inference, AI right there, is to make your actions exist on the tradeoff frontier, like the Pareto optimal tradeoff.

between getting it done right now and expanding your epistemic boundaries.

Sometimes the right move is to contact somebody who knows better or to go to a website that might inform you better.

And so it's actually a useful action in the moment to arrange to get better information later.

And so active inference helps us think about how these different needs are traded off by organisms.


SPEAKER_00:
Cool.

All right.

So seven, collecting into, oh, I can't do it.

Syncytium.

Syncytium.

Syncytium?

Did I do it?

Okay.

Collecting into a syncytium enables all of the cells to share the same data and access the same memories.

That's pretty awesome.

You must assimilate.

It's like the Borg.

Sorry, Star Wars nerd.

Okay, also greed, eight.

Greed at the single cell level for information, infotaxis, drives cooperativity as each unit expands its measurement boundary, communication with neighbors, and thus inevitably becomes part of a bigger self with bigger set points serving as homeostatic attractors.

So I think active inference also has a role to play here

in this um cooperativity so like i can reduce my uncertainty about my environment by cooperating with people who have the same goal that i have right like or cooperating becoming part of a group you know and and therefore our efforts make a bigger effort or bigger

Anyway, less surprise when I'm in a bigger group because it expands that light cone, right?

And then nine, there is a fundamental symmetry between anatomical control mechanisms and cognitive mechanisms.

And I think that this was discussed in terms of bioelectricity in the paper.

Do you guys have anything to add?


SPEAKER_04:
One thought on that is cooperation arising at a higher level.

So that just reminds me of like, if you're looking through a microscope and you saw a cell a eat cell B you go, I mean, adversarial relationship, right?

Could there be anything more directly adversarial?

And then you pull back and it's a white blood cell, you know, that's attacking a cancer cell.

So it's cooperative at a higher level, but it can look adversarial at a low level.

And so what does that map onto in different systems?

Can we reimagine conflict and tension as actually playing a stabilizing or cooperative role at a larger scale?

Can interpersonal differences in perspective or disagreements lead to a cooperative or regenerative collective?

This is what we hopefully move towards.


SPEAKER_00:
I saw some pigeons procreating yesterday while I was out walking around in my neighborhood and it definitely looked adversarial.

It looked very, very adversarial, but they're cooperating at a higher level.

Looks can be deceiving.

Okay.


SPEAKER_01:
Definitely.

I was thinking of a case where like if a tiger attacked me, I should just assume that it's like an information transfer that needs to happen.

I don't know.

Come get peace with it.


SPEAKER_04:
Oh, it's like in The Selfish Gene by Dawkins.

He says, yeah, why would you go beyond the gene?

It doesn't make any sense.

Would you have mammals doing kind acts for each other?

Just look at the lion eating the gazelle.

How could that possibly be a collaborative relationship?

And then I thought, what if those two populations stabilize each other through deep time?

And they can't coexist.

And then they actually persist better both because of that one act.

So who's to say.


SPEAKER_01:
But just one thing, like if, if that is all the case, you know, if this is all like, whatever, man, the universe becoming like, why would it be that we had such a hard time with it?

Like, shouldn't it, shouldn't there be some mechanism that allows me to just be like, Oh, okay, cool.

You know, like, I don't get that.


SPEAKER_04:
I think the mechanism is narrative, cognitively.

It might play out differently in different systems.

But agree to disagree, it's a narrative that we can both agree on.

We're cooperating at that narrative level.

Doesn't mean that we don't disagree.

In fact, we entrench that we disagree.

But we're agreeing at a higher level.


SPEAKER_00:
Cool.

Do you want to read the next ones?


SPEAKER_04:
So yeah, just a few of the key points from 10, 11, 12.

10, bioelectric integration helped evolve control strategies and cognitive content across the continuum from chemical networks to human minds.

11, the key points here were that there's a scale invariance with how different systems make decisions.

and that we can, across different systems, study how the cybernetic processes of learning and parameter optimization are implemented by a large number of units pursuing infotaxis and homeostatic goals, aka pragmatic value and epistemic value.

And twelve, a conceptual unification is proposed in this paper as scale-free cognition, and

then it's talked about how these boundaries between different subunits are a major control mob between itself and the world like the cell is doing the same stuff whether it's part of an organism or part of a cancer but it's actually this control knob like what are the limits of the cognitive individual that sets the cell up to act a certain way or another

and uh then a reminder at the very end from a utilitarian perspective that the most appropriate level of analysis is to be determined empirically aha but was empiricism determined empirically and that is said to be the level that facilitates prediction control with the least effort by the experimenter or by the system itself what if they disagree

and gives rise to a unified understanding that drives the most novel, robust research programs at the bench.

Nice.

If it doesn't advance your career as a scientist, then it's not the case.


SPEAKER_00:
This was you, Daniel.

Active inference and multiscale communication.


SPEAKER_04:
Just wanted to capture a little bit about multiscale systems and Actim.

So here we have nested systems.

So top left, that's an ant brain.

That's a picture that Sasha took of an ant brain that came from a Pogo ant.

And then there's the colony with a bunch of nest mates driving food around.

And then the colony is embedded within an ecosystem.

So within one nested system, within these time diamonds that are sort of nested inside of each other, we can think about how the internal state of one

is linked to the external state being the next level up.

Like the internal state is the brain and the external niche to the brain is the body.

Okay, now the body and the brain are the internal state for what?

The colony.

And then the colony is like the internal state for the ecological niche.

So that's something that we've seen before with how active inference helps us understand and model and simulate

hierarchically nested systems but also we can think about interactions at the same scale like collective behavior collective intelligence as occurring when at the same type of agents they're interacting like laterally and so that's this teal arrow that's where you have two agents there are they're each other's external state so active inference helps us zoom up and out and down and in and then it also helps us go laterally and then

Not to repeat it too many times, but the lateral transmission isn't instantaneous.

It's dynamic, it happens through time, which means that we don't need to look at all lateral interactions, just the time cone.


SPEAKER_00:
Cool.

Predictions and research program.

There was a big list here, so I just pulled a few of them out.

I'll read some of these off, which are a lot of them questions.

So is there a quantifiable sense in which biological systems model themselves?

Can an in silico evolutionary system be built containing both genetic and physiological components which simulates the scheme described above, homeostasis and infotaxis, and illustrates the emergence of different scales of cognitive horizons over time?

Can we directly observe the evolution of multicellular goals from networking of agents with single-cell homeostatic goals?

Might there be higher level effects on the physiological boundaries of the cognitive subagents within the body from exposure to psychedelics, which have long been claimed to expand transpersonal boundaries or induce ego death?

The analogies between geometric spaces and cognitive ones need to be explored further, as is beginning to be done via geometric information theory.

Time diamond, anyone?

Definitely.

I think that there's a lot of room to go here.

Will complex engineered systems set novel goals?

And if so, how?

It is a prediction of this view that adaptive useful robotics will require components that are themselves competent and goal seeking.

that is super interesting also um because really as an intelligent you know being capable of cognition so are all of my parts so if we're going to really import you know give rise to intelligent life intelligent artificial life we have to start with intelligent artificial components i think that's super cool and also goals we can't we can't just say well let's just build you know


SPEAKER_04:
a bigger car or a bigger computer.

I mean, what do we want this intelligence design system to be intelligence in the service of or in the way of?

And it's a disaster waiting to build capacity without goal.


SPEAKER_00:
For sure.

Do you want to read some more of these?


SPEAKER_04:
Yep, so the second set of predictions.

So this is where Mike is setting out a little bit of his agenda.

The next work in this subfield, just, you know, the subfield, each of the fields, they're modular.

They have their own disciplinary histories, their own disciplinary anticipation.

But this subfield should focus on the discovery of bioelectric communication-inducing technology.

So just like once we had chemical biology, people were really excited about finding drugs that bound to proteins.

Well, now that we're aware of bioelectricity, let's think about manipulations and measurements of bioelectricity.

Two, it's a prediction that it's possible to induce the formation of metazoan-like bodies in an otherwise unicellular organism by forcing the expression of appropriate electrogenic proteins in gap junctions.

So he's trying to get towards some unique predictions and experiments.

prediction that transcriptomic, which means gene expression, analyses of regeneration events from bacterial biofilms, plants, and metazoan models of limb regeneration should show consistent use of electrogenic proteins in the events that enable cooperation towards self-limiting morphogenetic cascades.

So it's kind of like the structure, informational or cognitive structure of

of recovery and repair might have some similarities across systems that wouldn't immediately be seen as similar otherwise.

Scale-free cognition hypothesis suggests that multi-human systems, cough, cough, remote teams, could have their own degree of cognition.

So as we always say, things that the brain knows that the neuron doesn't, things that the colony knows that the ant's nest mate doesn't, there's got to be things that remote teams or any other kind of team know that individual participants don't know.

And then the exobiology question is, given a novel life form or just a novel form,

How does one know when successful communication has taken place?

And that's an interesting question for a lot of you, xeno slash exobiologists.


SPEAKER_00:
SETI, anyone?

Cool, next slide.

So this is in the section, what it feels like to be a pancreas, but I really pulled the point that kind of hit home for me the most out of the section and the final point that Mike makes in the paper.

So I'll just read this off.

It is striking that the process which Zen practice is meant to reverse, attachment to past memories and high valence for future expectations or fears, is precisely the process suggested to be responsible for the creation of complex selves.

with a capital S. It is unclear whether it is beneficial or even possible to truly live in the moment and let go of past memories and future expectations.

But anyone who succeeded in doing this would achieve precisely what Zen promises, the dissolution of the self.

And the final sentence of the paper, which I just loved, recreating the unification into and liberation from larger scale unifying unifying selves with a capital S would be a true pinnacle of synthetic biology and artificial intelligence engineering.

Wow.

It was a good paper.

So just key questions at the end.

What might a good understanding of this work enable?

What are the unique predictions and implications of this work?

What are the next steps for FEP and active inference in relation to this work?

What are the goals of this research, and what are you still curious about?

So we will be thinking of all of these things as we get ready to do 25.1 and 25.2 over the next couple weeks.

So thank you for participating.

There is a feedback form for feedback, and you can get in touch with Active Inference Lab at all of these links on this slide.


SPEAKER_04:
Nice work, Blue.

Great job with your first broadcasting and facilitating on this one.

It was really fun.

So yeah, anyone's welcome to participate or contribute to our lab activities.

asynchronously, synchronously, we'll figure out the right performance for you.

So thanks, Sarah, also for joining.

Thanks again, Blue.


SPEAKER_02:
Cool.