SPEAKER_03:
three two one hello and welcome to active inference lab live stream number 27.0 it's august 23rd 2021 and we're going to be discussing the paper active inference applicability to different types of social organization explained through reference to industrial engineering and quality management

So welcome to the Active Inference Lab.

We are a participatory online lab that is communicating, learning, and practicing applied active inference.

You can find us at the links here on this slide.

This is a recorded and archived livestream, so please provide us with feedback so that we can improve on our work.

All backgrounds and perspectives are welcome, and we'll be following video etiquette for livestreams.

At the short link, you can find the roadmap of the upcoming discussions that we're going to be having.

And these are going to be group discussions on August 24th, tomorrow, and then August 31st for number 27.1 and 2.

And hopefully the author will be joining us for both discussions.

And we have some openings in the coming weeks if you want to join for a session or if you want to recommend somebody who should join.

Today in ActiveStream 27.0, we're gonna be learning and discussing about this paper with the aforementioned long title by Stephen Fox, and the link is here.

And just like a lot of the other .Zero videos, all of them, this video is just an introduction for some of the ideas.

It's not a review or a final word.

It's kind of always this assemblage of all of the participants here just modifying the slides and going down a few avenues that we thought were interesting.

setting up some questions to discuss in the dot one and dot two.

So we'll go over the aims and the claims of the paper and the abstract and roadmap and then talk about keywords, then go through the figures and tables.

So if you want to participate in these group discussions tomorrow or the following week, then just let us know or save and submit your questions and get in touch with us if you want to participate.

So we can just start with hello, and then it will be cool to hear from both of you what drew you to the paper or what made you interested in talking about it.

I'm Daniel and I'm in California.

So whoever wants to go first.


SPEAKER_00:
I'm Blue and I'm an independent research consultant in New Mexico.

And I liked this paper.

It was a really like refreshing, kind of interesting and very readable perspective compared to a lot of the other papers.

And it made some links with industrial engineering, which I thought was interesting and kind of like a new take on active inference and FEP.


SPEAKER_01:
I'm Dean.

I'm up here in Calgary.

And what I found interesting about the paper is just looking at it through the lens of engineering's priors, I guess, in terms of what they would hold up as active inference just because of what they do every single day.

And again,

That kind of juxtaposed with the social piece was really interesting to me because not to overgeneralize, but when you're focusing on how to break something down, you don't tend to look at the whole.

So I thought that was really interesting to try to pull those two things together and make them coherent.


SPEAKER_03:
I agree.

There's that discussion of the interfaces between the engineered system and the actual way it's used in the niche, which I think we're going to return to when we're talking about like a bookshelf.

So the paper is the title of the link are shown here.

And I guess maybe do either of you want to just read the first two aims and claims?

Sure.


SPEAKER_00:
So the principal contribution of this paper is to relate active inference theory to everyday practice in social organization.

Active inference is a corollary of the free energy principle

which formalizes cognition in the auto poetic organization of living systems that resist the second law of thermodynamics by occupying a limited repertoire of states, thus persisting as bounded self-organizing systems over time.


SPEAKER_03:
okay and then i'll read the last two then anyone can give a thought it is explained throughout the paper how industrial engineering and quality management better enable social organization to occupy a limited number of states in order to persist as a bounded self-organizing systems over time rather than dissipating into their surrounding environment

Although previous papers by others have encompassed active inference up to the levels of socio-cultural cognition, this is the first paper to address active inference in everyday organizational practice, including industrial engineering and quality management.

So the paper is setting up to be just like one more plank towards applying active inference, bridging some of the practices that are already in use in the fields that we're going to be exploring, like the quality management and industrial engineering, and then sort of the adjacent possible for what kinds of systems could exist in those domains.

Sometimes we have a more mathematical paper or more philosophical paper.

This one's going to use a lot more of the jargon.

And like Dean said, the priors of engineering.

So that's why it's kind of cool to hear about it.


SPEAKER_01:
Daniel, can I add something to that?


SPEAKER_03:
Yep.


SPEAKER_01:
Yeah, I just think it's interesting that I think we...

to use a bridging metaphor is seems just to be a really easy thing to do.

And then I think what the paper in terms of the aims and the claims does is tries to point out where that

that connection might exist.

And we can always argue whether or not it exists in all situations at all times.

But I do think that there are some times, again, when we can hold a static connection between an idea at one scale and an idea at another scale.

And so not all scales allow for that or have those affordances, but sometimes they do.

So I mean, that part of it,

Maybe what we need to do is separate the times when the metaphor works and when it doesn't.


SPEAKER_03:
Agreed.

Being utilitarian implies some sort of utility metric.

Having a preference for reward or for preferred states implies those being defined, maybe.

And also, I think this will come up in this paper because it's all about which are the useful metrics to check up on useful policies to pursue.

Okay, so does anyone want to read abstract one?


SPEAKER_01:
I'll read it.

Active inference is a physics of life process theory of perception, action, and learning that's applicable to natural and artificial agents.

In the paper, active inference theory is related to different types of practice.

In social organization, here the term social organization is used to clarify that this paper does not encompass organization in biological systems.

Rather, the paper addresses active inference in social organization that utilizes industrial engineering, quality management, and artificial intelligence alongside human intelligence.

Social organization referred to in this paper can be in private companies, public institutions, other for-profit or not-for-profit organizations, and any combination of them.

The relevance of active inference theory is explained in terms of variation of free energy, prediction errors, generative models, and Markov blankings.


SPEAKER_03:
Pretty interesting.

I think usually when we talk about these multi-scale perspectives on institutions, cities, societies, it's always like the entire edifice, all of the niche and everything that's moving in it is part of this one biological organism.

Right.

or at least biological co-regulating system.

And here it's very explicit that it's trimming the biological component from the engineered component.

It's kind of like the car and then the passenger.

So then instead of just saying, well, the car and the passenger are part of the same extended cognitive niche, because that's one way to look at that situation.

Like it's an extended affordance that the driver has.

Another way to think of it is by making a very clean partitioning, recognizing that there's still this emergent function, like cars don't drive themselves, but you can still parse out the individual who's using the car from the design process of making the car.


SPEAKER_01:
And one thing to add to that, if you haven't read Lucy, and I'll always kill her last name, Lucy Sukman, S-U-C-H-M-A-N.

She's got a book out many years ago that I think has still got some incredible shelf life.

It's called...

It's reconfiguring the human machine interface.

And if you haven't read it, it's a fantastic book in terms of looking at how her case study is how people walk up to a photocopy machine for the first time where the engineers are trying to make it intuitive and how the human interface with that isn't always necessarily something that you can engineer for.

So something to consider if you're looking at this idea.


SPEAKER_00:
If I could just give another thought, I think that the uncoupling of social organization from biological organization is kind of a really unique and fresh perspective.

compared to some of the other papers that we've looked at.

Especially considering that it is biological organization because it's happening in biological creatures, but it's an interesting partition that the author creates to make it known that it's not talking about hierarchical organization in structures or societies.


SPEAKER_03:
Yeah, so we don't need to worry about what's inside of the tissues and go into the biological organization.

Okay, I'll read the second abstract and then anyone can give a thought.

Active inference theory is most relevant to the social organization of work that is highly repetitive.

By contrast, there are more challenges involved in applying active inference theory for social organization of less repetitive endeavors such as one of a kind projects.

These challenges need to be addressed in order for active inference to provide a unifying framework for different types of social organization employing human and artificial intelligence.


SPEAKER_00:
So I have a thought on that.

It might be somewhat controversial, but, um, you know, so I think that, um, the highly repetitive, so, I mean, I think about active inference in terms of exploration and exploitation, and I think like, it really depends on, on where your generative model rests, right?

So like, as the generative model, like the model of the organization, or is it the model of the individual?

Because I think that, um, doing a highly repetitive project that reminds me of exploitation.

where a one-off project can be exploration.

So you can still update your model depending on exploring some new avenue by this little side project, but you come back to updating your model, the model of your business, yourself, the way that you work, your organization, with knowledge about how to do processes in a one-off kind of process.


SPEAKER_03:
I agree.

especially because we talk about it a lot in the context of generating strategic novelties, perhaps, and those are seemingly less repetitive, but...

there's going to be some further clarification on that and also this points to this uh yeah exciting areas like one shot learning or like true structural novelty and active inference models that's something that we've talked about in other areas like how do you know when to be tweaking the knobs of the parameters as you currently have them set up versus expand a hidden state into two types of hidden state or something like that again thinking about what the system is realistically or from this instrumentalist way

okay the roadmap is written out here and it's a we're going to go through it in rough order it introduces in each of these sections one of the kind of key ideas or principles the variational free energy prediction errors generative models markov blankets and survival

And then in section seven, active inference is proposed as a unifying framework.

So this is kind of one of those classic paper layouts with some disciplinary sections, one through N disciplinary sections.

And then the next section is active inference as a unifying framework.

And then the next section is like challenges or current research directions.

And then a concluding section, maybe with a more call to action or more philosophical liftoff.

There were a bunch of keywords and I think we're going to get to all of them.

So two columns of keywords.

Let me shrink the video.


UNKNOWN:
Yeah.


SPEAKER_03:
Two columns of keyword.

Okay.

So first active inference.

It's in the title of the paper and here's how it's written in the paper.

Who wants to read the large text here?


SPEAKER_00:
I got it.

Active inference is the physics of life process theory of perception, action, and learning.

Active inference generates predictions.

Active inference predictions are based on knowledge learned from past situations and perceptions of present situations.

Active inference minimizes errors between actions that are planned through the inference of predictions and what happens when the planned actions are taken.


SPEAKER_03:
So this is the first lines of the paper, right?

In the introduction, that's how it begins with, you know, active inference is the first word.

So that's sort of the opening shot and it's just a cool framing to bring it out as a physics of life process theory

yet this isn't about biological organization so it's almost like recognizing the origins and some of the motivations for the kind of modeling that active inference provides yet making another later decision to partition the system of interest a certain way so cool framing and then the uh next lines so kind of shrinking that definition of active inference um

This is because prediction errors cause unwanted surprises, which individually or accumulatively can threaten survival by going beyond the limited number of states in which survival is possible.

By contrast, minimizing prediction errors facilitates survival through least action.

So this is also linking up several of those key terms that are going to be section headers later, but it's just this idea that

predictions about the external world, especially if they incorporate preferences that are optimistic, help reduce the complexity of deciding which actions to take.

And then the way that that gets operationalized is with the process theory of prediction error minimization, which is a real-time estimate of how good the generative model is performing.

And then just add anything or...

say more here but it's just an interesting topic how it's described as the principle of survival through least action so what is this principle of least action and how do we reconcile active biological agents as being in one way participating under this survival through least action even if it's just a misnomer what does that really mean

And then how does survival through least action contrast or overlap with more familiar phrasing, probably survival of the fittest?

Like, is the survival of the fittest the survival of the least active?

Or how should we read this relationship between maybe Darwinian conceptions of fitness and which individuals survive versus this physics-based framing of survival through least action under the principles of least action?

Stationary action principle.


SPEAKER_01:
Can I add something, Daniel?


SPEAKER_03:
Yeah.


SPEAKER_01:
Yeah, so I think it's interesting that you, depending on how you define each of these terms, that you can sort of transfer or oscillate across frame, what a frame is, which to me is identifying a focal point, maybe a margin or a limit, and what a fit is, what goes inside the other, like glove and hand or hand and glove.

And I think sometimes we talk about a niche fit,

But that's different than what the frame of the niche is.

So the fact that we're sort of ping-ponging back and forth between the two, I just wonder whether or not we're looking at the same thing or if we realize we're looking at two things at once.


SPEAKER_03:
Nice.

Continuing on with the introduction.

It's written, active inference is a corollary of the free energy principle, FEP, which formalizes cognition of the autopoietic organization of living systems.

Within FEP, active systems must occupy a limited repertoire of states.

This requires minimizing the long-term average of surprise associated with sensory exchanges with the world.

Minimizing surprise enables them to resist a natural tendency to disorder.

So this just kind of relates to some questions like how do framings for this sort of active intelligent behavior what other framings exist and how do we think about broad concepts like reward preference and curiosity and surprise in active inference.

And then the last paragraph then, any thoughts or not?

Surprise rests on predictions about sensations, which depend on an internal generative model of the world.

In particular, although surprise cannot be measured directly, a free energy bound on surprise can be, suggesting that agents minimize free energy by changing their predictions about what sensory inputs will come from actions, or by changing the predicted sensory inputs through changing action.

This just reminds me of the kind of fundamental pairing in Active Inference where the ways that you can go down that free energy gradient are either by updating parameters of your internal model, learning, development, or by updating action states, which is through action.

Because you can't control external states directly, and you can't control the incoming sensory data directly.

then all you can do is control those two states that are under your control, the internal states and the action states.

All right, another term was the Markov blanket.

So anyone want to just like give what's the Markov 101 or what's a way in which Markov blankets came into play in this paper or in another context?


SPEAKER_00:
So Markov blankets are essentially the boundary or how a system creates a boundary and how you can define essentially like a non-equilibrium steady state system with a Markov blanket.

I thought it was an interesting play in this paper and I think maybe we'll unpack it here later on in the intro video.


SPEAKER_03:
We just, in number 26, talked a bunch about Markov blankets.

So, suffice to say that it's still open exactly which cases, which sense of the Markov blanket is meant on this continuum from analytical and mathematical with Markov, the OG blanket.

the Bayesian statistical generalization by Pearl and others, and then this partitioning into incoming sensory and outgoing active states of the blanket by Friston and others, and then how that exactly relates to all these other topics that we're discussing.

Okay, I'll play the video at 46 seconds.

Blue, what was exciting to you about this?


SPEAKER_00:
So this is the video from the Tesla AI day that just happened last week.

And this is, it's a humanoid robot that Tesla is going to attempt to design.

And so I just put this definition of artificial intelligence from, like, Google, and it said, the theory and development of computer systems able to perform tasks that normally require human intelligence, such as visual perception, speech recognition, decision-making, and translation between languages.

And so, spoiler alert, this is actually not a robot.

This is actually, like, a person, but he made it, you know, look like a robot that was getting up and then, like, bam, I'm going to dance.

But I think, like, that kind of...

movement and perception about space, that kind of spatial awareness is something that's still very much a challenge for AI.

So that's why I threw this video in there.


SPEAKER_03:
Agreed.

Will be interesting to see how they do processing and what kinds of algorithms and hardware and software end up being used for real time robotics systems.

Any comments on artificial intelligence or anything, Dean?


SPEAKER_01:
Again, I don't spend a whole lot of time on this, because to me, artificial intelligence is always a post hoc domain.

Even this example, can we create a copy of this?

I mean, it's already been done by something, and now we're trying to re-engineer it or redevelop it, as opposed to what active inference is, which is the inclusion of ad hoc.

the what if.

So, I mean, if they can get artificial intelligence to a place that it's including what if, in the truest sense of all possibilities, then I'd probably be quite excited or scared.

I'm not sure which.


SPEAKER_03:
Nice.

So some other keywords were social and organization.

And one of the goal statements of the paper was, this paper is intended to contribute to bridging the gap between theoretical papers in active inference theory, which have been reported to be too opaque to be understood widely, and potential application opportunities in the multi-intelligence social organization,

that being social organization that employs human intelligence and different types of artificial intelligence.

So, and whoever put this image, what did it mean or represent in the context of the paper?


SPEAKER_00:
So I just looked, so I didn't, I don't know that it's necessarily really in the context of the paper, but I started to look into like, how are societies organized, right?

And so this is like, I just was doing some Googling and I thought that this was an interesting paper and the title and the author there in the small print, if you're able to read them, but this is like a state organization, right?

And it describes the fascist media model as focusing on community and culture.

And it describes the communist media model as focusing on state bureaucracy and the liberal media model as focusing on market exchange, which I just thought was interesting and just kind of an interesting way to, I don't know, reflect on societal organization and what is the central theme there.


SPEAKER_03:
And it's kind of in line with that partitioning of the kind of the car from the user, because not included here are like the human users.

This is kind of everything but the eyes on the TV.

This is just partitioning the structure of the organization as an engineered object.

So that's a cool similarity.


SPEAKER_01:
Yeah.

So we just had a guest stream and Pranev and Raphael, even they were debating, can we say that something that's an emergent property in an individual, which is then something that we can test as an emergent property within a dyad, can also become an emergent property within these high variability states?

And even they couldn't agree completely.

that there's some sort of a parallel.

I think we know that on these high variability states like a social organization, afterwards, again, we can take an account of what it became, but it's really hard to know where it's going, even if you break it down into a,

communist or a fascist direction.

It's telling us, like you say, what direction down the highway the car is going.

But beyond that, it's still a lot of guessing.


SPEAKER_03:
Yep.

So I guess that's where industrial engineering comes into play for that designing for that car on the highway.

Industrial engineering involves applying methods such as task analysis and job design in order to predict results, evaluate results and improve results from processes during their development.

The application of industrial engineering has been progressing around the world since the 1900s.

So.

wasn't an area I was too familiar with.

I saw a lot of mention of the 99 out of 100 and the three standard deviations and then halt the process.

So that kind of just was an interesting thing to hear about.

Any thoughts or we can continue on?

Okay, I guess a related field of industrial engineering is quality management.

And so this is a type of system that involves, I guess, hardware and software and behavioral protocols.

Quality management systems, QMS, involve documenting processes which have been developed through industrial engineering as process specifications, work procedures, et cetera, monitoring processes for conformance to specifications, et cetera, and using observations of non-conformances to inform the further development of processes.

Both industrial engineering and QMS are focused on the continuous improvement of processes.

The application of industrial engineering has been progressing around the world since the 1900s and quality management since the 1950s.

Any thoughts on that?


SPEAKER_00:
Just having been a business owner, it's a process.


SPEAKER_03:
Yep, definitely makes me think about precision of measurement changing and then...

what can be measured and then what can be measured gets entrapped and then what can be regulated becomes gamed and all these sort of complex ways that assessment of performance fits one into local versus global optima.


SPEAKER_01:
You can also see how instructionalism got systematized.


SPEAKER_03:
yep, if there's a way to do it and this is the way that's approved, even if the later becomes like an improvement in the protocol or some sort of change in the context, maybe it can't be utilized because it's not part of the approved version.

And so there's no simple answer there because you can't just say, well, okay, accept all changes.

And then if you just say, okay, we'll have a small bar for making edits.

It's like, there's no perfect trade-off point with the false positives and the false negatives.

especially for situations that truly are ambiguous, which is why we fall back to these approaches that put us at the kind of functional inflection point of the pragmatic and epistemic outcomes, which is like active inference, rather than just pursuing reward over short term or over some other timeframe.

But common to all these different frameworks for control theory is basically statistical process control.

So maybe whoever made this slide, was it?

Yep, Blue, go for it.


SPEAKER_00:
So statistical process control is a collection of tools and techniques used to measure and analyze process data in order to characterize the behavior of our processes and achieve process control.

And so in the paper, I don't know how much we'll get into it here, but the paper really describes statistical process control and gives a figure similar to this.

So you have normal process variation, which they described as six sigma deviation from whatever is optimal.

So there's the optimal, which is like the green line, and then three sigmas to the up and three sigmas to the down as to like an over or under estimate of your target.

And then any time that you have a process that deviates from the Six Sigma range, you have the special cause variation.

And so in the business schema that I'm familiar with, at least, which is minimal, but some,

You do this root cause analysis.

Why is there this special cause variation?

What happened in that one circumstance?

We have to go and analyze that instance to find out why it was outside of the sigma deviation because that's an unacceptable data point at that point.


SPEAKER_03:
Nice.

Good explanation.


SPEAKER_00:
How about thermodynamic entropy?

also um this was also me but um it's a quantity representing the unavailability of a system's thermal energy for conversion into mechanical work often interpreted as the degree of disorder or randomness in the system uh and so you know there's the the law of thermodynamics that says that entropy in the universe is always increasing so um becoming going from

more ordered to less ordered or so from highly ordered to more disordered which this kind of shows in this example uh things spreading apart and like it's like you would if you left town for two years and you came back and found that your house was a mess that wouldn't really be surprising like even if you left it clean even if you know i mean just things deteriorate and fall apart and dust goes in and whatever rodents creep around and stuff like that and it's that apparent


SPEAKER_03:
and empirical local organization of matter like into bones and flesh and life and whatnot and also the always and only co-occurrence of that kind of local organization of energy with cybernetic or anticipatory behavior

That's what motivates a kind of framework that is going to, on one hand, work for particles, but also work for active particles and all of the continuum between.

So that's why there's all these different cognitive structures as well as physical structures that are being linked together through basically physics.

And by hooking to free energy principle and variational methods and all these other areas of math and physics, then it puts active inference just like one step closer towards embodiment on some of those different pathways.

Okay.

Information, theoretic entropy.


SPEAKER_00:
So this is the Shannon entropy as it's often referred to because it was, I think, first described by Claude Shannon.

But I always put Maxwell's demon here when I'm thinking about relating thermodynamic energy and informational entropy.

And I think, was it Alex Kiefer wrote a paper that really we did in one of the live streams that really kind of outlined how these are connected with the Helmholtz distribution.

And so if you really want to dig deeper into these relationships.

That's a good way to do it.

But I always think about, you know, so Maxwell's Demon is the idea that, you know, if you have molecules like shown on the left here in this box and you have two sides of the box and there's a partition in the center and like, you know, they're cold and hot molecules.

So if you knew which molecule was hot and which molecule was cold, so if a demon is sitting there who can see is the molecule hot or cold and only lets the hot ones go through to the right and only lets the cold ones go through to the left, and every time he opens the partition, effectively that is work.

And so just kind of conceptually...

That shows that the relationship between information and work, the more information you have, the less work you have to do, maybe.

So that's kind of the relationship that I think about in my mind.

And then there's a formal definition of Shannon entropy down below.

But it's usually given in informational context as a measure of surprise, as we've talked about on the live stream many times.

and they relate information as negative entropy.

So it's the reverse, surprise is the reverse of surprise, or sorry, information is the reverse of surprise.


SPEAKER_03:
Cool, thanks for the explanation.

Dean, any thoughts on that?


SPEAKER_01:
Yeah, one of the things I... I mean, I love this.

Thanks, Blue.


SPEAKER_03:
Thank you for that explanation.


SPEAKER_01:
It's really good.

So one of the people I'm reading right now is a guy by the name of Dan Siegel and his book about the mind.

And what he talks about is...

When people are at dis-ease, so not an easy state, but when they're struggling with something, he talks about the fact that there's one of two ends of a continuum, be it blue and red, in this example.

One end is chaos and the other is rigidity.

And so from an information theoretic entropy state, are we stuck?

Are we bored?

Are we feeling trapped?

Or are we being overwhelmed or underwhelmed?

meaning we're not in that in-between state.

And so I think there's a lot that can be done if we get a basic understanding of Maxwell's demon without sort of getting stared off by it.


SPEAKER_03:
Cool.

It's almost like, yeah, what would these particles and their temperature represent if they were, I don't know, ideas or something more related to inference rather than just particles, because we're always looking at that intersection between the physical systems and the informational systems.


UNKNOWN:
All right.


SPEAKER_03:
variational free energy.

So this keyword was defined in the paper as the difference between predicted sensory inputs and actual sensory inputs when monitoring processes.

VFE increases as the difference increases between what is predicted to happen if actions are taken and what does happen when those actions are taken.

The more prediction errors there are, the more thermodynamic energy will be consumed amidst the thermodynamic entropy of remedial actions, corrective actions, restorative actions, and firefighting.

This will leave less thermodynamic energy available for doing productive work comprising productive actions.

Thus, if the variational free energy is high, then thermodynamic entropy, e.g.

energy not available for doing productive work, will be high, and the thermodynamic free energy, e.g.

energy available for doing productive work, will be low.

Hence, variational free energy can have an inverse relationship to thermodynamic free energy.

This is because the bigger a prediction error, which can be considered in terms of bigger VFE, the smaller can be the thermodynamic free energy available to do productive work.

So this is a pretty interesting passage.

Did either of you have a thought on it?

it's exploring this thermo-info nexus in a little bit of a different way.

And on one hand, it's kind of confusing that the variational free energy is going to be the opposite of the thermodynamic free energy.

But it's almost like, what is happening here?

And it just...

to see that they have a negative relationship.

It's like if the engine were perfectly anticipatory and super efficient, it would be carrying out a ton of work.

If it's moving in a super spurious heat producing way,

then the product, lot of variational free energy, a lot of surprising observations relative to functional operation of the motor, then your capacity to perform work to capture those very noisy vibrations is low.

And so a lot of the underlying

potential becomes dissipated rather than used to perform kind of useful inference, useful action.

So not sure if that's a correct mapping, but I think it'll be cool to talk to the author because this is a very fascinating idea about how different formalizations of free energy actually relate to modeling processes.

Yeah, Blue.


SPEAKER_00:
So it's like, I really thought this is kind of what made me think of Maxwell's demon, right?

So it was interesting because, you know, the variational free energy, when we talk about minimizing free energy, we always think about like as minimizing surprise, right?

So if we minimize surprise, then we don't have to do all this thermodynamic energy, like the firefighting that they talked about.

And I think that the paper, when we get into the five whys and that figure, I think we'll

elaborate a little bit more on that but um the it's just interesting because we don't have to output as much work and that's kind of what made me think about about maxwell's demon and kind of why i snuck that in there um but yeah you're right i don't know like you know i think that the relationship between um infodynamics and thermodynamics is still very much being defined there's a lot of very recent research um that's looking closely at how those two uh relate to one another nice do you


SPEAKER_01:
Yeah, I just, I immediately said to myself, I really want my autonomic nervous system to work, and I don't want to have to think about it, because a lot of the mechanical things are dependent on that.

So I'm not sort of pulling apart what the claim is here, but I think...

If you read that, you're kind of saying, okay, a lot of the surprise you're not even aware of because your autonomic nervous system is functioning correctly.


SPEAKER_03:
Great.

point there it's almost like a surprise variational surprise does not equate to attention or even especially the conscious awareness of attention in a human psychological situation so it's totally possible that like the difference in pressure sensing depending on your body's posture that's completely normalized out that's recalibrated for the expectations of body position

without coming to our attention, unless we bring it to our attention.

So that and many other similar examples.


SPEAKER_00:
So Dean, I love how you're like not able to stay outside of the biological partition.


SPEAKER_01:
Well, I just, I'm not, again, I'm not, I want to be able to create with this stuff.

I mentioned that.

And so to me, it's,

To willfully ignore that is hard for me to do.

I'm not saying it's not possible.

I'm not saying it's the right thing to do here.

I'm just struggling to let go of it.

I want to let go of it, but I'm having a hard time with it.


SPEAKER_00:
Well, and I think for all of us, you know, the urge to apply to every system is very strong.


SPEAKER_01:
Right.


SPEAKER_03:
Here's table one.

So here's the mapping of a bunch of different sets of terms from active inference constructs, and then thinking about how they're applied in industrial engineering and quality management practice.

So variational free energy, which we just were talking about, is the difference between the predicted sensory inputs and actual sensory inputs.

the variational free energy upper bound as well as its lower bound is basically the range in which that system is working well.

It's like the loaves of bread are within the calibration range and we can just keep on pumping them out.

Precision weighting has to do with which aspects of the process are monitored with which level of precision.

For example, which width of a part has to be machined in fractions of a millimeter versus other tolerances.

And then the expected free energy is the expected energy between the preferred sensory inputs from process operation and the actual sensory inputs.

So the variational free energy is the difference between the prediction and the actual.

So you have some generative model of your data center, and then you have the generative model of the temperature through time, and then the comparison with the actual.

But here it's about the preferred

versus the actual.

So that's like we recognize that it is warmer than we would like it to be, which is why we're conditioning our policy in the long range towards getting back to that zone.

But for now, we need to also have an accurate sensor measurement.

So that's also a nice juxtaposition that's not always finessed in other papers.

The next, in all these keywords, the first set were about free energy and precision and how these terms are calculated relative to one another.

The second set of terms in table one is some of the key terms of Bayesian statistics.

So just to read only the constructs, and these are also really helpful because we're as a lab thinking about what are the core terms of active inference?

What are the definitions that are general enough to be really,

educational but also not too limiting or prioritize one sense over another for example so the bayesian terms that would be found in any other course or textbook on bayesian statistics prior expected posterior actual posterior preferred posterior and prediction error so that kind of puts the predictive processing as a uh under the umbrella of bayesian statistics okay

The next set of terms in the table was related to this dichotomy of two different types of inference.

So epistemic inference was defined as updating the definitions of process during process improvement based upon analysis of nonconformance reports, whereas instrumental inference is updating which actions will be included in the process during process improvement.

So this is sort of like epistemic knowledge based.

This is about updating the knowledge based upon especially the times where things don't go right.

And then this is like policy inference, action planning as inference, because it's like instrumentally is actually like about what the instrument is gonna do.

So, and then the last, oh, okay.

Any thoughts on these terms?

Okay, then the next set of terms in table one was Markov blanket, internal state and external state.

So definitely check out number 14, number 26, a few of the other live streams to learn more about the Markov blanket.

And this is a figure from DaCosta et al, 2021.

The blanket is here the boundary state between the internal state of the social organization

So those are the ones and the external state of the environment when operating processes are defined in the quality management system.

then what are those internal states?

Those are the social or organizational processes developed during industrial engineering for minimum risk in the process environment.

And then the external state is the environment.

So that's kind of mapping the Markov blanket, kind of the car, the interfaces and outside the car, or maybe that's not the perfect mapping, but I think that's kind of what is being suggested.

And then the last,

few terms of table one are four of just the general constructs, general principles that are also section headers and important topics, risk, ambiguity, principle of least action, and principle of survival.

Dean?


SPEAKER_01:
Yeah, so I think all of this ties into a way of looking at the world through rows and columns, which is fine.

I mean, it's a good place to try to look at things and analyze them, but

Not everybody creates off of that because not everybody is necessarily looking for a precision forward view.

Sometimes you're experimenting and you're making all kinds of mistakes and learning from that as well.

And so, again, you just want to see this for what it is.

It's nothing wrong with it, but it's not the only way.

That's all.


SPEAKER_03:
Blue, anything?

Okay, so then there's the figures.

And these will recall some of the key terms we talked about earlier.

uh the text says as shown in figure one spc charts these statistical process control charts have upper and lower control limits and processes need to remain within these limits processes that go outside the limits do not meet specifications that define intended states so left side good top of the drake meme right side bad bottom of the drake meme not working

okay figure two is this five wise so it's written out here more textually if you want to pause it and look at it and here it's more graphical so do either of you want to give a thought on the five wise or okay well the scenario that's laid out is uh

kind of working backwards from why there was a not reliable organization.

And the five whys, it's actually not related to Aristotle's four whys.

But that would have been a nice opportunity.

Maybe there's a four by five matrix.

But these five whys are referring to needing to go back kind of five layers, or like five

derivatives up the chain, asking what led to a high reliability organization being unreliable.

So the general case of this sort of cascading failure in terms of variational free energy.

So the general phrasing is that there's high,

uncertainty, high entropy in work instructions.

So the IKEA instructions are not accessible enough to many people or the radio is really blurry so people can't hear what letters are being said.

And then that makes the variational free energy high because of prediction errors, which then leads to unproductive actions.

So then you're scanning on the radio because you can't quite lock on.

And then that's consuming energy.

And then that ends up reducing your battery so that you can't do what you actually need to do.

And then the case in this truck driver incident is that the truck driver is getting ambiguous signals.

logistical data.

So this itself is a policy communication from like, you know, some cloud mapping service or the company that's contracting the trucker.

And then this leads to the driver having increased spatial uncertainty getting lost, which leads them to drive around unproductively.

So they don't have enough fuel to efficiently complete the deliveries that are important.

And so here's the graphical layout of the five whys showing with that example, how on the bottom is the truck drivers getting the bad info.

And then that surfaces after sort of several repercussions in terms of the structure of multi-level decision-making and active inference, how we can...

use this framework which maybe is used in industry and map it onto the states of decision making from active inference perspective but notice that there's no reward here it's not well drivers uh minimize their reward about this or you know risk on this or maximize their reward on this so it just shows how this sort of um framework

has a different framing than people might expect if the only machine learning model they were aware of was machine learning and specifically reward reinforcement learning.

Dean?


SPEAKER_01:
Yeah, and it isn't just industrial.

You can be like me and jump in the car with two of my friends who are both emergency doctors and you're heading off to the ski hill and at some point the conversation comes around to there are no accidents in the world.

And, of course, being emergency doctors, they see the outcomes of accidents

events happening to people and so their perspective is there's always a way of being able to go back and see all the parts of the decision branch and how it arrived in front of them and them having to sort of put the pieces back together again but again i don't i don't know that necessarily that that means that randomness doesn't come into play and there isn't a

certain part of this where the variation simply can't be um calculated in but i still go skiing with them i don't i don't just just dislike them or defriend them so anyway yeah


SPEAKER_03:
it just reminds me of like when I dropped a hard drive and then I thought, well, I guess this is the one in a hundred hard drives that fails every year.

Yes, but it was also the one time that I dropped it.

So there's always this sort of like N equals one way to uncouple

cause and effect or potentially actionable consequence to the not reliability of your organization.

But then also there's this designing for the statistics when they decide to make a recall or not based upon, you know, the relative amount of failure versus the relative amount of, you know, legal changes needed, something like that.


SPEAKER_01:
So that's where you talked earlier about including co-occurrence instead of just only giving time over to the sequential aspect of this.


SPEAKER_03:
Yep.

So figure three frames the quality management systems, the QMS, the quality manual as a generative model comprising beliefs about processes.

So it's interesting because it could be seen as just a cookbook, recipe book, instruction book, but it's being at least deployed in a generative capacity

And instead of just like saying, you know, whip the eggs for five minutes and then until they're frothy or, you know, until they are this, make peaks.

It's like, we expect it to make peaks.

Whip it until your expectation is achieved.

It's a different way to get to that same outcome.

Now, which one's gonna be more resilient?

If it says five minutes and there's no peaks, then what do you do?

Do you add something?

Do you keep on going?

Whereas if you have a precision seeking process, maybe you can be resilient to it if it only takes two minutes and you don't overdo it.

And the example of something being correct, like 99 out of 100 times is just used, I think, just repeatedly in the paper.

Just it could be calibrated differently.

And I'm sure it's situational.

It's just sort of like shorthanded 99 out of 100.

But yeah, it is defining these QMS in terms of the active states.

So what should be done?

You know, pipette 50 microliters of fluid into the little tube, and then you monitor something about the process.

And then that leads to this feedback cycle between the quality management review, and then that being in kind of co-evolution with the industrial engineering itself.

And then that leads to the update of the process in the quality manual in step four, so that then there's kind of like, okay, if it's too low after your first pipette, then do a little bit more pipetting.

And then they keep on protecting that 99% functional outcome at each of those nodes that are bifurcating out.

Okay, any thoughts?

I'm not going to read this whole thing, but the top part talks about this design for assembly.

And one of the principles is to make parts either symmetrical or clearly asymmetrical.

So nothing in the uncanny valley.

This is done so that it is immediately and unequivocally apparent how a part is to be put into sub-assembly.

And this is the famous IKEA catalog aesthetic.

and how that made furniture building like fun and accessible for some people, I guess.

And then in this second quote, it is kind of thinking about that IKEA paradigm.

Although furniture companies may not be considering their industrial engineering in terms of minimizing variational free energy, it is apparent that its aim is to minimize errors between what it intends to people to see when looking at its furniture kits and what people do see when looking at its furniture kits.

So it's sort of like the goal should be to make it look like it looks on the sale room floor or like it looks like in your imagination after you see the advertising.

And then if you can see those flat pieces of wood and you can see that instruction booklet and you can see the policy, then you're going to be not surprised.

You're going to be satisfied because your preference was to have like the couch there.

So just kind of a cool example that highlights how

Our preferences aren't just over temperature.

We often talk about those kinds of examples, but we can also have preferences for having affordances or niche modifications.

Like we can have a preference to have a handle on something.

And then that kind of relates us to this like behavioral economics under active inference.

Like what makes somebody expect there to be a new couch in their living room?

And then what makes them drive out and pick it up on the weekend and everything?

And then...

It's this kind of idea that the supply chain is this extended uncertainty reducer and it's like bringing stuff to you.

And then there's this notion in this computational industrial case and in the at home case where the assembly information that's provided is a policy decision from the people who are making the product.

And then that really relates to like participation in making that product.

If it's all pre-compiled, then there's no affordance for participation versus having like a culture of people working through it for many different ways.

And then this was just the funny example of the interface, which said, although there may be little risk in furniture assembly, this can be followed by much ambiguity in furniture installation.

So in other words, it's not just about what's on this brochure.

Because predetermining all the possible prediction errors in fixing the assembled furniture to walls in millions of different buildings around the world is very challenging.

And so there's this difference between the assembly information, like how do you just assemble the system of interest, which is just the internal and blanket states of the new shelf,

What's the difference between that information, how to build the bookshelf, and then the operations?

Like, oh, well you didn't tell me that I couldn't kick it from the side.

It's like, you just told me how to build it.

You didn't say that I couldn't use it this way.

And then, so how do you design for internal coherence versus designing for interoperability with sort of unknown unknowns and all these different types of entities that the system's gonna interact with on the blanket, on the interface?

So it's not just the Ikea booklet, but I thought that was kind of an interesting notion that even just building it wasn't really the end of the story because then people take their perfectly built bookshelf and then just like staple it to the wall the wrong way and like ruins both.

So Dean?


SPEAKER_01:
Yeah, and then, I don't know if you can see this, but then how do you account for this?

How do you account for somebody who took a piece of olive wood, any random piece of olive wood and turned it into something

like this right so it's not there's no there's no billy there's no way of deconstructing this you just have to pick up you have to pick up something that is a mark off blanket it's it's as it's pre-carved and then you have to be able to pull out what you think is in that and how do you how do you engineer that

Well, it's a completely different process.

So I think as people, we're capable of doing both.

And I'd love to talk to the author about how you do this kind of work when there's certain results that are...

are available and are part of the active inference model.

So it'll be a nice contrast tomorrow.

Yeah.


SPEAKER_03:
Yep.

Nice.

Good point.

Like where's artisanship and craft in this phrasing?

So here's an example using that case of the bookshelf or the cupboard being bolted to a wall.

And this also gets at that partition between the part of the system that you can design and then the part of the system that is not being considered.

So here, the internal states, and this is kind of interesting.

It'll be cool to see who is there alive to talk about this sort of embodiment aspect.

The internal state is the person's embodied prior knowledge of fixing assembled cupboards to walls.

And depending on what they know about carpentry, if they're just totally watching the YouTube video and then letting it rip versus if they're experienced, with different materials, they're gonna take actions and that's gonna modify the niche, which is the external state, the room to which the cupboard will be fixed.

And that's going to be reflected in what the person perceives.

then it's just cool like the here maybe there's multiple ways to interpret the center it's like there's the wall blocking like external blocking state then there's like the affordance block where the tools are inadequate like you know you need the the hex wrench of size seven and you only have the size four so you just can't do it even if you know how to do it and there's times where even if you have the right tool it's like it's too rusty to do it

so there's like it's just a cool example and shows a little bit of that that horseshoe theory again between philosophy and engineering where they're both radically focused on embodiment and pragmatics okay

Then the next section after four is seven, active inference as a unifying framework.

And so basically they write, an important application of active inference theory can be as a unifying framework for a social organization framework summarized in figure five, which we'll look at in a second, operated through quality management systems, QMS, via interoperability protocols at an upper level of multi-tier enterprise architecture.

So before we look at figure five,

It's just like, how does active inference serve as a unifying framework in some of these areas that we've been talking about for the last months?

Like we've heard people use this integrating word to talk about active in action and perception, engineering, biology, communication, cyber physical systems, remote teams, et cetera.

So just it's being used a little bit in a different way here.

So let's see figure five and then you can give any thoughts on it.

Here, organizational active inference is again being mapped onto this sense, internal, action, external loop, this kind of a circular loop.

The internal states are the organization's belief.

Just like in figure four, it was the person's embodied beliefs, here it's the organization's embodied beliefs embodied in the QMS, which is again being framed as beliefs over processes and states.

That results in human and artificial intelligence employed to fulfill specifications, procedures, etc.

So these can be actions that are taken by APIs or bots or by people.

This acts upon the external states, which lead to perceptions of sensory states, which could be the temperature in the room,

It could be the pH of the wine.

It could be the number of sales on the course.

So then they do industrial engineering on this loop as an organization in relationship to integrating perception and action through internal state updating, pretty much just like we've been talking about for all these other active inference systems.

Any thoughts?

Okay.

Table 2 writes, there can be many reasons why pragmatics subsumes semantics and leads to prediction errors.

For example, inept priors and inept preferred posteriors can come from lock-ins, path dependencies, and success traps, which place emphasis on past experiences over new information.

Individuals may seek to survive by learning from filtered information that supports the preconception of groups, which they believe can support their individual survival, rather than seek information that supports the efficient reduction of prediction errors in external states.

So it's almost like you can't prefer what you prefer so much.

Otherwise, you're going to, I don't know, maybe follow that local band all the way to a local end instead of sometimes coming out of that local organizer, local local attractor.

And any want to go for this blue?

Yeah.


SPEAKER_00:
Yeah.

It just, it seemed like just confirmation bias, right?

You seek to survive by learning the information that supports the preconceptions of groups.

Right.

So that's like, you know, I believe this, my, my, can, can my group believe this?

Like, I don't know.

That's that.


SPEAKER_03:
Yeah.

This is a cool table.

It's like, okay.

So in the perception phase of active inference,

You can have a top-down error based upon inept priors, so you can believe the wrong thing about what you should expect to see, or you can have the sensor be influenced, interesting about e.g.

emotion, but that's, I guess, being phrased as a bottom-up way that perception can be modified.

And then in the intermediary, intermediate, it's bounded rationality.

So that's kind of like a compromise between what you think is possible and magical realism.

Then the action phase also can be run aground by inept, focusing on basically poor outcomes.

Like if you're aiming for five degrees off of shooting a free throw, then you're going to miss the free throws, right?

And then that also your attention could be affected by poor signal to noise ratio, like if you couldn't see where the hoop was.

And just interesting how like it's being really methodically broken down the sources of where the error can come from.

And then also in table three, there's a nice distinction

And it relates to that notion that active inference would be potentially very effective for repetitive processes, but potentially not as effective for one-of-a-kind processes.

And so the repetitive processes are like mass production, and then the one-of-a-kind processes are like the project production.

So right off the bat, it's kind of like, well, how individual does a project need to be before it's not best modeled by active inference?

And then it just talks about how Markov blankets, generative models, prediction error, and variational free energy play out in both of these two areas.

So that would definitely be something for people to like read through the table and then mention it and give a specific example or question to the author because this is like super informative and a cool combinatoric way to look at how ideas are related.

So yeah, Dean and then Blip.


SPEAKER_01:
So when I'm looking at this, and I don't know if this is helpful or if this just makes it even more turbid, but if one hand of this is the ability to frame something so that we know what's in, what we're looking at versus what we're not looking at, and if the other hand is how we match, essentially if you go back to table two and this, table three and the figure, the matching is what's superordinate and what's subordinate, what's inside of what,


SPEAKER_00:
Those are the two hands.


SPEAKER_01:
That still doesn't tell us what is going on in between, which I think is the fit piece.

which from a thinking standpoint is, am I fitting now hand in glove, meaning is my glove size large or is it glove in hand?

Does the glove I need serve the purpose because I'm skiing or because I'm foraging or I'm water skiing, right?

So between framing and matching,

is this fit question.

All three of them are different things.

The fit is in between these other two things.

And even if we make a great table, even if we make sure that we got the right headings and right definitions underneath, it still doesn't talk about, is it glove in hand or hand in glove?

And I think for people who want to actually use active inference,

They want to be able to not get stuck conflating fit with frame or conflating fit with match.

They want to put those two parameters, the frame and the match on the outside, and then see what happens in the middle based on what those parameters are.

I think that's the struggle for most people

trying to gain entree into, well, how does this active inference thing actually work?

It works different all the time.

That's the point of the Markov blanket.

It's the potential to be able to invert at will that I think laying it out this way helps.

It gets you like 90% of the way there, but it doesn't really tell you what you could do with it as opposed to what just happened.


SPEAKER_03:
Very interesting.

Dean?

Lou?


SPEAKER_00:
So, like, just kind of this piggybacks right off of what Dean was saying, like the Markov blanket, and even here in the first line of this table,

you know, the Markov blankets are hard when they're shifting, right?

And this is something that we've talked about in other live streams in other contexts, like shifting, overlapping, my Markov blanket, interacting with your Markov blanket.

I think that, you know, the underlying mathematics to support those kinds of arguments are kind of missing still, or not missing, but still being worked out is probably more correct than

But, but I do think that Markov blankets do change.

I mean, even if I just think about like my brain as, you know, Markov blanket, like cells die, cells are born.

And I know that that's very controversial in the neuroscience field, but, but cells are actually born.

So, so, I mean, there's, there's constantly this, this turnover of,

who belongs inside the Markov blanket and any kind of, you know, organizational structure has that shift.

It's not like the boundary of the Markov blanket has to be, has to retain some kind of flexibility.

And, and so that, you know, is, is seen here in this, in this

first line.

And also, whose generative model is it?

So this is kind of another something that I was like, hmm.

So the quality management solution, or the QMS, right?

I maybe got the abbreviation wrong.

But that is the generative model.

But who does it belong to?

Does it belong to the process?

Does it belong to, and this is maybe my deficiency in my understanding of

industrial engineering, because I'm just not familiar with the jargon.

But like, is it the process that gets the quality management solution?

Or is it the organization that has the quality management?

Or is it like some kind of subunit?

Is it a team?

So I'm just kind of unsure about they talk about this is the generative model, but like, whose model is it?

And like, so depending on on how that's answered, and we'll have the author on so we can ask them, but depending on how that's answered,

you know, these one-of-a-kind processes, as I said earlier, can maybe be used to update the generative model in a very explorative kind of way.


SPEAKER_03:
Nice.

So here's just for a few implications and bigger questions.

So here's just a quote.

Markov blankets are not features of real-world systems.

Rather, they are an intuitive post hoc ascriptions

Rather, they are intuitive post-hoc descriptions made in order to model real-world systems.

Hence, any description of a Markov blanket is subjective and can be changed over time as the modeler's focus changes and or as real-world systems change in the opinion of the modeler.

Thus, as summarized by phrases such as the map is not the territory, Markov blankets, da-da-da-da-da-da-da.

And then also, this is a funny line.

It has been argued in relation to Markov blankets and other important constructs in active inference theory that the math is not the territory.

wherever you heard that one before.

But this is like kind of the ultimate instrumental take.

It's making a clean distinction between map and territory, between the utility-driven use of active inference and claims about what the system really is.

And then this, just the last line, but it's an interesting quote, but I'll just read the last line is, move to the slides.

Hence, the ascription of Markov blankets could be a recurring challenge throughout project production, which may only be resolved by reference to decisions made in courts of law long after the project is completed.

Just maybe think about, I don't know, maybe like the Bay Bridge being built in the Bay Area in California and like, you know, it was years later and it happened differently and I'm sure some companies were bought and sold and all the morphing of the organization and the physical modification of the project and the personnel changing over

all of that which is sort of this on one hand it's an n equals one unique enacted situation but then on the other hand there's principles for engineering it well and uh

Sometimes the process is itself wondering about how it's organized, and then sometimes you can't even know until it's after it's done.

So that's just kind of cool and funny.

Another quote, this is sort of taking a take on philosophy from the engineering perspective.

Exactly how beliefs are updated in embodied cognition is a topic of ongoing research, which involves specialist mathematics to describe relationships between prior probabilities and posterior probabilities.

By contrast, updating beliefs through active inference in industrial engineering and quality management involves applying well-established practical methods.

In particular, planning what should happen by active inference involves developing processes through applying industrial engineering techniques.

So it's sort of like we know what our policy affordances and mechanism of updating our affordances are.

That's our discipline.

And so more broader question is what are the implications for generalized frameworks like embodied cognition or active inference

What are the implications when they interface with disciplinary or project-specific one-time work?

And then how does active inference get simplified in the context of industrial engineering?

And how does work in the disciplines become linked in a bidirectional conversation to the broader body of knowledge?

Just general questions.

Any thoughts?

Okay, Dean, yeah, go for it.

Dean, you're muted.

Yeah, I can't hear you, Dean.

Oh, yeah.


SPEAKER_01:
Sorry.


SPEAKER_03:
Yeah, continue.


SPEAKER_01:
No, my bad.

Whether we're talking about the Bay Bridge as do we have the proper glove in hand?

or whether we're talking about instrumentalism, do I actually have a precise fit of glove for my hand?

I think what we have to be aware of is that both of those questions come up post hoc.

I tried on the glove and it worked, or maybe the design of the Bay Bridge should have been different given the contextual circumstances.

All I'm curious about is, so before the Bay Bridge is built, before I fit one of two questions into that glove-hand relationship, am I aware of how that can be seen post hoc or ad hoc?

conscious of the fact of where I'm taking this active inference model.

And as Lou pointed out earlier, whose is it?

And now just as importantly, when is it?

When is that question being asked in the context of what the product is?

Because if we're gonna talk about social organizations as the product,

Active inference allows us to look on both sides of that.

So as long as we're including the when in terms of discovering fit, I think we're actually using active inference in terms of what its potential is.

That's all.


SPEAKER_03:
Nice comment.


SPEAKER_01:
Little philosophy.

Not like we need that, but I'm just throwing it in there.


SPEAKER_03:
Yeah, that's cool.

So then here's another quote.

In terms of the explore-exploit dynamic, project production involves much more exploration than exploitation.

Hence, more wayfinding than navigation is involved.

In particular, wayfinding involves the ability to create novel routes which are based...

on understanding a wider frame of reference than navigating along a preset route.

Wayfinding involves creating novel routes through changing situations by making non-conscious reference to subjective prior knowledge and conscious subjective reference to current situations and semantic information.

That's pretty dense, but pretty fascinating because it does point at this kind of like repetitive.

Then you can just write out the directions and follow them in a little bit more of a rule following way.

And then the extreme case being like a train, like the Cal train just went from San Francisco to San Jose, just went.

And it was like, it had, you know, the affordance to speed up or slow down.

But then when there's the bushwhacking or the wayfinding here,

then there's almost like novelty of path.

And then there's higher novelties like introducing a new tool or climbing to the top of a tree to see further.

But there's just this path finding novelty that is really important for all kinds of these applications.

So just...

raises the question that'll be cool to discuss about like how does active inference uh juxtapose or interface with sense making and wayfinding um explore exploit the pragmatic epistemic distinction and then the way that the models are fit with accuracy minus complexity just how does that come together in active any thoughts or good yep dean


SPEAKER_01:
Yeah, because wayfinding is my niche.

I was just so happy that he pulled these two references.

If you haven't read work of 95 and 96 here, I strongly recommend it because he's pulled out two fantastic references in terms of...

things you could look at in terms of what that exploration piece actually is.

They're both fantastic, especially the 95.

I've read both of them and they're both excellent examples within the context of what he's trying to talk about in terms of implications.

So I just wanted to do a clap for that one because I thought, glad he brought the wayfinding piece into this.


SPEAKER_03:
cool yeah the 95 is finding the way a critical discussion of anthropological theories of human spatial orientation with reference to reindeer herders of north eastern europe and western siberia 2009 and then the second article is humans use predictive gaze strategies to target waypoints for steering 2019. so it's kind of interesting because um

And especially having adapted a visual foraging model to a Stigma G pheromone deposition model in the active inference paper, it has drawn out this contrast between two extremes of foraging, both which can have a pragmatic and an epistemic component.

There's like skin in the game, ant body on the ground where you're physically moving.

you're hurting and you have to go somewhere to find out how it is there versus visual foraging or visual scanning is sort of like you have the cost of movement, of course, but it's not like where your eye is, is directly paying a cost in most cases.

So it's kind of cool to see that the way finding and the sense making comes into play on these two extremes with a niche modifying body on the ground, as well as with a scanning approach.

Okay, another quote, won't read the whole thing, but basically we can imagine after hearing all of this that the prediction error is something that you want to minimize for effective business operation.

So a large prediction error could lead to the company dissipating, for example, through its internal resources being scattered into an external state by being taken into the possession of its unpaid suppliers.

So that's a Markov blanket dissolution via court-mediated bankruptcy proceeding.

um alternatively the company could be acquired and merged into one of its large unpaid suppliers that seeks to move up the value chain from tier 1 to oem manufacturer in the case of acquisition and merger the description of markov blankets would need to be changed in legal documents

So that just totally set off my Scott David alarm and made me think about the ways that the Markov blankets can be designed, the managing synthetic externalities, seeing law as a niche modification and as a technology in and of itself, but also one that can

facilitate other technologies coming into existence or being hindered as we see all the time.

And then he uses the acronym BOLTS, business, operational, legal, technical, social.

And then the bigger question is like, how can we see active inference serve in a de-risking or recovery capacity?

then how can we reframe existing or emerging practices for resilience in terms of active inference so this is like a 1980 style merger and acquisition framed in the markov blanket framework but what does the d5 active inference model look like what does the smart contract active inference model look like these will be like really interesting questions and how they're going to intersect with formal laws as well as the codas law

Any comments?

Okay.

And then I think the last point was just

In the further directions of the paper, further refinement of active inference constructs is needed to enable wide application to social organization employing human and artificial intelligence.

Apropos, the practical examples in the paper can provide starting points for research into the challenges of ascribing Markov blankets, defining generative models, handling pragmatics, and modeling variational free energy in real-world social organization.

And that's an idea that we touched on in our 2020 paper, Active Inference and Behavior Engineering for Teams, which is that in the case of remote teams, then

the entire structure can be observed through the sensory data that's sent to a user and then the actions that are received, for example, on either side of an interface or either side of a blockchain wallet.

So for remote teams, because they're defined digitally, we have access to the entire state space, so to speak, of sensory and active states.

Whereas for trying to do the active inference model of people in a physical boardroom, that's always gonna be complicated, even if you have a really effective way to get body position out of the cameras in the room, for example.

So just kind of cool to think about industrial design or engineering, all these different ideas we talked about in terms of online, as well as physical engineering.

So not just like cars and stuff.

Those are hardware and software as well.

So we kind of just close by saying, what?

People can give their last thoughts, Blue and Dean, just what would a good understanding enable?

What are some good unique predictions or implications or areas that this line of research might be addressing?

What are the next steps for this kind of research?

The goals of the research, and then also just what you're curious about asking the author tomorrow and in the following week.


SPEAKER_00:
Yeah, I think I've laid out some questions today that I hope I don't forget for tomorrow.

But I definitely think that active inference in systems, in organizations and social structures is definitely important.

along with the validation of your model through other models, like through the models of other people and through this confirmation bias, like, oh, my model must be good because you have a model that's like my model.

So I think that this existence can help to really set boundaries and definitions

on how we really form social structures, not just businesses.

And I mean, in businesses, there's kind of a hierarchical component.

But I mean, also like society as a whole, we form these social structures

structures and how does the social morphogenesis really take place?

So I think really the author puts out a good, you know, way of kind of delving into social morphogenesis, even through like quality management and industrial engineering, but it's definitely first steps.


SPEAKER_03:
Dean, any final comments?


SPEAKER_01:
I'm really looking forward to talking to the author because

I think at the end of the day, rather than

What's the word here?

Rather than exploring why these mappings have been put together in this paper, I'm kind of curious now about trying to figure out, so when did these parallels sort of form in his mind and get to a place where he could take a lot of this background information?

Because he's really cleverly and thoroughly sourced here.

When did he sort of put these two things together as a reflection of one another?

And where does he see that going forward?


SPEAKER_03:
Totally agreed.

It's a single author paper that reflects a really deep understanding and probably a lot of experience presenting and thinking about this and maybe even applying it.

So those are all super interesting areas to find out about.

All right.

Well, Blue, Dean, thanks.

That was epic.

Thanks for all the help on the slides and on the stream.

So that was great.

We'll talk to everybody in the .1 and .2 or later.

So bye.


SPEAKER_01:
Thanks, Dan.