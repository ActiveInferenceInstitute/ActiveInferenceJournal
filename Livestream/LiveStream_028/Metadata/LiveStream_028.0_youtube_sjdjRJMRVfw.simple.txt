SPEAKER_04:
Hello and welcome to the Active Inference Lab.

It's Active Lab live stream number 28.0 on September 6, 2021.

We're going to be talking about the paper Towards a Computational Phenomenology of Mental Action, Modeling Meta-Awareness and Attentional Control with Deep Parametric Active Inference.

welcome to the active inference lab we are a participatory online lab that is communicating learning and practicing applied active inference you can find us at the links on this page this is a recorded and archived live stream so please provide us with feedback so that we can improve on our work all backgrounds and perspectives are welcome here and we'll be following good video etiquette for live streams thanks a ton blue and steven and dean nice fun to have a dot zero crew together

here you'll see a slightly updated version of the upcoming streams calendar which you can get at from this short link here uh september 7th and 14th we're going to be discussing this paper we're going to be discussing in this one and then we don't have a paper for 29 and then we have some papers set with authors for all of october

Also, check out the tabs to see other series other than the Tuesday paper-centric walkthroughs.

And of course, anyone's welcome to co-organize an event or to be the guest for one of these types of streams.

All right, so today in 28.0, we're going to be just learning and discussing this paper that was already mentioned by Sanvid Smith, Hesp, Mattout, Fristin, Lutz, and Ramstedt.

out only a few weeks ago, which is kind of cool to see.

And there's going to be a ton to talk about.

It's a super interesting paper.

And if you want to participate in 28.1 or 2, you should get in touch.

Otherwise, if it's after that time, then check out those videos and maybe find another one to participate in.

But I'm just looking forward to hearing what you all were excited about.

By way of introduction, just...

Want to hear from everybody and what was exciting to them about this paper or made them want to join for the .Zero.


SPEAKER_00:
If I go first, Daniel.

Yeah, thanks.

I'm really excited or interested to see them moving beyond a computational approach to neurophenomenology, which I've seen before, and into this broader idea of what they're calling computational phenomenology, which

Well, it's a bolder claim and has more relevance potentially to other applications, which I'm interested in and applied active inference context.

So, you know, we'll see how that bold claim can be applied.


SPEAKER_04:
Nice.


SPEAKER_01:
Okay.

So for me, I thought it was like ultra meta.

The paper really got into the hierarchical levels of organization, which I'm always excited to see and talk about.


SPEAKER_02:
For me, it was the fact that I am doing some writing right now and I am interested in the idea that there is a way of putting this into some sort of a geometric relationship as well as the computational relationship.


SPEAKER_04:
Cool.

Okay.

The paper is, let me just reframe it, is Towards Computational Phenomenology of Mental Action, Modeling Meta-Awareness and Attentional Control with Deep Parametric Active Inference in Neuroscience of Consciousness, published about two weeks ago, 27th of August.

Does someone want to read the three aims of the paper?


SPEAKER_01:
Sure, go ahead.

The three aims are to explicitly model meta-awareness, to account for the computational consequences of meta-awareness on cognitive control, and lastly, to provide a computational account of mental covert action.


SPEAKER_04:
Okay.

And then maybe the second part?


SPEAKER_01:
Sure.

Formally speaking, the crucial thing to note about these cognitive processes is that they are about other such processes.

The deployment and control of attentional states and processes, for instance, are quintessentially a higher level ability.

Such states and processes monitor and modulate other, typically lower level perceptual states.

Third order, higher level processes in turn oversee these attentional processes.

we can be aware of our attention being grabbed and make a deliberate decision to focus our attention elsewhere.

It would seem then that effective self-regulation of attention depends on the ability to access, evaluate, and control the quality of these attentional processes themselves, in the same way that attentional processes are necessary to consciously access, assess, and control lower-level perceptual states.


SPEAKER_04:
interesting areas.

It's just interesting to see that the kind of framework that helps a robot navigate, now it's being used in a little bit of a different way, like nesting within ourself and coming closer to our experience and other things which often are said to be unable to be directly observed.

So it's quite a cool topic.

Dean or Steven, any thoughts or do either of you want to read the first abstract?


SPEAKER_02:
I got a quick thought before we get to the abstract.

In the introduction of the paper, I want to just read this really quickly.

It's in the paper, but computational terms, the central place of confidence and reliability and effective self-regulation speaks to the key role of precision.

or inverse variance of implicit beliefs.

And then they talk about probabilistic and posterior Bayesian beliefs that describe a probability distribution over some latent quality.

But this was the thing that I found really interesting.

Bayesian beliefs about Bayesian beliefs can, in certain situations, become propositional

and the way that they are estimated, optimized, and controlled.

Precisions, in a nutshell, quantify our confidence in our beliefs, say how confident we are about what we know about states of the world, about their relationship to our observations, or about how these states change over time.

Being able to place numbers around that, as soon as I read that and saw it in relationship to a proposition, I found that really interesting and was really curious to see now, so how is that thread going to play out?

Now, it wasn't part of the three things that were in the previous slide, but I think it was really important and something that was, it has to be a name or a claim of the paper because it's pretty fascinating.


SPEAKER_04:
good call it's almost like a background assumption whether uh post hoc justified by empirical appeal or not that precision is what matters which is kind of the other side of the coin from uncertainty like high precision means low uncertainty and vice versa and sometimes they're framed as so I think totally agree that is a claim of the paper okay Stephen want to go for abstract one yeah


SPEAKER_00:
OK.

Meta-awareness refers to the capacity to explicitly notice the current content of consciousness and has been identified as a key component for the successful control of cognitive states, such as the deliberative direction of attention.

This paper proposes a formal model of meta-awareness and attentional control using hierarchical active inference.

To do so, we cast mental action as policy selection over higher level cognitive states and add a further hierarchical level to model meta-awareness states that modulate the expected confidence or precision in the mapping between observations and hidden cognitive states.


SPEAKER_04:
nice yeah there's a lot of uh terms some of which we're going to go into in the keyword section but pretty distilled down description of their contribution and we're going to unpack it more okay

Abstract 2, we simulate the example of mind wandering and its regulation during a task involving sustained selective attention on a perceptual object.

This provides a computational case study for an inferential architecture that is apt to enable the emergence of these central components of human phenomenology, namely the ability to access and control cognitive states.

We propose that this approach can be generalized to other cognitive states, and hence, this paper provides the first steps towards the development of a computational phenomenology of mental action, and more broadly of our ability to monitor and control our own cognitive states.

Future steps of this work will focus on fitting the model with qualitative behavioral and neural data.

Okay, cool topics.

Any thoughts, or we can move on?


SPEAKER_02:
First steps, that's the emphasis here, just first steps.


SPEAKER_04:
Yep, I'm pretty excited to get to this, the generalized model of mental action because it's like...

almost like the new tool enables asking about phenomena that we already know.

And then it reveals a whole new state space of kind of then the model feeding back to the kinds of regimes of attention that we designed for ourself or niche modifications or information inputs.

okay roadmap so this paper has an interesting layout it is just an introduction that brings up the non-active inference sections related to the scientific study of mental action and about how it's been computationally modeled outside of active inference then there's a methodology paper that first has more of a model building

narrative and then the empirical results from a simulation that has a few different layers of

detail layered on it.

It's not just one single model.

There's a few little variants that help get at which parts of the model are contributing which behavior and why.

Then they have a more general discussion and give some directions for future research.

And that's where some of these big claims about computational phenomenology go.

And then there's a conclusion.

So any thoughts on the roadmap?


SPEAKER_00:
Yeah, I think that this gives a good sense of the way that they're trying to enter into this space, looking at the opacity and transparency of phenomenology and trying to sort of bring back that neuro-phenomenology into this wider phenomenology.

So by sort of looking at the experience.

Now, the question that sort of comes up with this is,

Because obviously a lot of the work here with Rampstead and others has been around embodied cognition and stuff like that.

So they're sort of going into this idea of trying to set it up so that they can target phenomenology while still keeping it around mental states and cognition.

So there's an interesting, I don't know, ontological dance they're trying to find a way through here, which I think is kind of interesting.


SPEAKER_04:
Any other comments on the roadmap?

Okay.

So the keywords were free energy principle, active inference, neuro phenomenology, metacognition, opacity, transparency, focused attention, mind wandering, and mindfulness.

So perhaps blue with FEP.


SPEAKER_01:
sure this slide i pulled out of the live stream 15.0 so the free energy principle is based on three aspects the observation of self-organization which brings us to the second aspect which is that living organisms can be described as stochastic dynamical systems possessing attractors

And then lastly, the states in which the self-organizing system is at a point in time can be identified by the interactive role they play within the multi-level self-organization scheme.

And then this is related to, in the slide from 14.0, multi-scale systems, ensembles, info thermodynamics, and variational Bayesian inference.

which I thought was applicable here as we're going through this hierarchical awareness, meta-awareness.


SPEAKER_04:
Cool.

Yeah, Stephen, and then I'll go up there.


SPEAKER_00:
Yeah.

Well, yeah, I think this is good to characterize this.

And also, I know that Maxwell mentioned how that multilevel graph, he's kind of gone back on it a bit, but it does show that whole question.

It's a really good diagram to show both that there is this multilevel nested

sort of multi-scale thing going on and also it's kind of a contested it's a contested or kind of evolving part of the whole field because it's uh people are sort of putting out things and then they're maybe backtracking a little bit and so i think um yeah i think it's quite a good thing to bring up


SPEAKER_04:
Definitely not a settled area.

That's why it's so fun to just have these discussions on the topic because even the paper is not the end result.

It was first steps.

And we're gonna see in this discussion, the multi-scale system is almost like psychologically nested or mentally nested

within one agent whereas previously we've been talking a lot about multi-scale systems in the context of you know a bunch of ants making the colony a bunch of communicating individuals making the community so it's like that's like multi-scale systems out and getting spatially bigger and this is kind of getting more ephemeral but also having this very interesting influence on the lower level models

So for active inference, the keyword, we can look at what the authors wrote because

always cool to see just how did they define this how did they frame what active inference is for this paper and they wrote that at the root of these advances is a biologically plausible neurocognitive and behavioral modeling framework called active inference active inference provides us with a bayesian mechanics that is the mechanics of knowledge driven action and active perception which explains from first principles how autonomous agents can thrive within their ever-changing environments

Active inference descends from and is closely related to Bayesian brain theory and predictive coding.

And then this green one I thought was very interesting in how they said it was active inference casts perception, learning, and action as essentially being in the same game, that of gathering evidence for the model that underwrites the existence of the agent.

So just on the diagram that we've seen with the four different kinds of nodes, with the blanket states of in and outgoing, and the internal and external states, to say that the three that constitute the organism, let's say, are all in the same game, just brings sort of a unity of action and inference to

we think about the very least other systems that already have this structure like input output systems which some people speculate describe all classes of systems or computational systems so it's just like the way that they made that clear of active inference without tying it to a specific model implementation i thought was very well set steven and also this does give a flexibility as knowledge evolves um


SPEAKER_00:
Because as Mark Soames has been talking about, the way attention may be moved around more at the base of the brain, using more kind of

attentional biological you know inactive questions that wouldn't necessarily be a problem for this because this this modeling isn't completely tied to some sort of frontal cortex model of thought it's kind of it's broader so i think that's that's quite interesting and to say how they're using the term behavioral modeling the framework and they've sort of

Yeah, the way they positioned it, because they haven't gone the whole way and talked about biological and gone down the full multi-scale biology route.

They've kept it kind of in the brain, but they've brought in that behavioral element, which I think neurophenomenology maybe doesn't do as much.


SPEAKER_04:
Good segue.

Blue, want to describe this one?


SPEAKER_01:
Sure.

So neurophenomenology, in the words of the authors...

Neurophenomenology has been described as the search for generative passages between the neurobiological, phenomenological, and mathematical levels of description, going beyond the description of mere isomorphisms between these levels toward mutual epistemological and methodological accountability and cross-fertilization.

Neurophenomenology aims to bridge the gap between these kinds of data via the formal metaphysically neutral levels of the description provided by mathematics and computational work.

And I pulled this cartoon out of this paper because I thought it was kind of a neat perspective and visual on neurophenomenology.

So it talks about the biological structures as predetermining the world of the organism and then neurophenomenology as a praxis between the first person account that the organism has

and the neural descriptions of these structures.

So that was kind of the point of this.


SPEAKER_04:
Nice find.

Very interesting figure.

Looks kind of like a sci-fi human novel, but it's kind of cool.

Okay.

To talk about one specific kind of neurophenomenology, like a first-person experience that is desired to be modeled, potentially even in a computational direction,

Here, they're focusing on this metacognition aspect.

So just the yellow parts, they wrote, we define meta-awareness in this context as the ability to explicitly notice the current content of a conscious episode.

For our purposes, as discussed in the text, we define states of meta-awareness as those third order, which we'll get to, states of the system that are about and enable the opacity of second order attentional states.

Metacognitive states thus function analogously to attentional states, which enable the opacity of first order perceptual states.

So it's going to be a three layer nesting doll.

The role that the second model plays over the first is going to be analogous to the role that the third model plays over the second.

But that doesn't mean its dynamics are going to play out in the exact same way.

And then this last part was very interesting.

Like mental action refers to goal-directed internal behavior without necessarily having a direct consequence on the external environment, e.g.

as though muscular action.

A paradigmatic example of mental action is covert attention.

So what an interesting topic, you know, the whole think of X or don't think of X. I won't play any language games on the live stream, but many of those exist and they have to do with inducing mental action.

So that's just so interesting that that's what this framework is going to be exploring.

Okay.

Stephen, go for it.


SPEAKER_00:
Yeah.

And without, you know, putting too much pressure on the paper to go further, but is it that question of, um,

skill performance and the phenomenology of being in the flow or being in a state of sense making, it'd be interesting how that neurobiological phenomenology, phenomenological passages can extend out into some of that kind of work, which is obviously highly complex, but then, you know, these might give us clues.

So that's good.


SPEAKER_04:
Yep, cool.

And then this is just, I found this link.

Trailblazing ants show hints of metacognition when seeking food.

And recent research has shown that bees, when faced with a difficult task, simply opt out of doing it, a behavior that may be interpreted as a form of metacognition, at least computationally.

Now it seems that ants might be capable of a similar mental feat despite their tiny, simple brain.

So it's like, what computational attributes are we going to assign to, oh, but that's just how bark is, or that's just how ants are versus this variable is the one that we're experiencing because of this.


SPEAKER_02:
that's just kind of a topic that's going to come up probably multiple times okay how about transparency and opacity what does it mean in someone's words or reading here can i can i bring out a little different angle to this i mean i understand that how the contrast of transparency and opacity works but when i was bringing when i was trying to figure this out to help somebody who was walking into a situation

oriented to a lot of the data around them that they would otherwise be overwhelmed with.

One of the things we talked about was the difference between liminality and just getting a generalized sense of the orientation space and then limitality, sort of filling in the details and getting an understanding where the edges are so that you don't bump into them and hurt yourself.

And so I get the transparency and opacity piece and how it's explained in the paper.

But for a person who's trying to move from the generalized to the more specific, I think

I think it's the opacity piece speaks clearly to the difference between that and something that's clear.

But I also think that the details get filled in when you can have an understanding what the limits are and not just limitlessly understand that it's now in your field of awareness, which is how they're describing this, which is your, where's your focus?

Where's your attention?


SPEAKER_04:
angstine i put this goldfish meme it's the story about the goldfish and what is water and the elder one is aware of water and then the younger ones are unaware of the water that they swim in cough cough and then it's kind of like the two mental extremes like water is opaque you can think of the water being like cloudy to this fish

Maybe it has a different vision.

So then it can see that there's a drop off in vision.

It infers that it's in opaque water.

So water is something that it can ask about the conditions of.

Whereas the small fish in this example, it's clear.

It's like transparent.

So they're seeing through it.

Ergo, it's transparent to them.

So they're imperceptible.

So the green ones are accessible to the system.

You're aware of it.

It's like water that has an opaque tint.

And then the transparent means like you just can't differentiate it experientially.

And that's a philosophical framework by, I think, Metzinger, which has probably been influential.

Right.


SPEAKER_00:
Yeah, highly influential, I think, and increasingly so.

I think this could be pushed a bit further because I think it's okay to state this as almost a philosophical piece, but...

bringing in stuff like mental space psychology which hasn't really been incorporated in this area but you know these subconscious um sort of opaque or transparent um awarenesses um are um part of our could be part of a deeper way of knowing if we assume that

thinking is through our senses if sense if actually the process of the brain is not all in the box but it's recapitulating stuff through the sensory world around us even in the subconscious that would tie in quite well with this but also give a bit more of a computational grounding


SPEAKER_02:
The other thing too, Daniel, if you'd have written the words opaque and transparent in a white-colored font with that white background, they'd still be opaque, but we wouldn't see them on the white background.

And so that's, again, where...


SPEAKER_04:
Nice.

Good call.


SPEAKER_02:
In order to be able to bring the idea forward, it isn't just a comparison of transparency to something that actually has a sense of tangibility.

There's this other part of it that we'll pick it up because there is a contrast.

There is some differentiation.

It doesn't always just have to be that something's clear and something has depth.


SPEAKER_04:
Thank you, Stephen.


SPEAKER_00:
Yeah, that's a really good point.

And actually that can extend as well to the size of the space you're in.

So if you start to imagine the relationships or these kind of subconscious senses of how close or far certain ideas are, that changes depending on the size of the actual room you're in.

And I imagine the different colours of the room, the lighting in the room as well might affect, I haven't really thought about this before, it might affect the transparent states as well because there may be some sort of

calibration going on you know so it might be quite profound to be in a blue room in terms of what your transparent states end up recapitulating so that's interesting we'll come back to i think a niche modification and design of regime of attention who made this slide or what did it mean to anyone


SPEAKER_01:
So this was mine.

The focused action I thought was like an interesting keyword.

The authors didn't use it once if you search the paper.

And then as a Google search, you search for focused action and you get all kinds of life coaching, which is like, whoa, okay.

I don't think that that's maybe the intention here.

So this is just...

the typical active inference loop where you have internal states, perception, external states, and action that are all connected and partitioned by a Markov blanket.

So I'm extrapolating based on what I think that the authors mean.

Here, low precision is unfocused.

And it's low precision also in terms of perception.

Because perception is also when you register, you just saw something.

They talked about the oddball.

And you're seeing an image, seeing an image, seeing an image.

And then all of a sudden, the image is different.

And it's like, oh, I wasn't even paying attention to what I was seeing at all.

So it's that perception can also have this kind of unfocused quality.

So I related this to like a low precision kind of perception or action as unfocused and where it's high precision, where you're focused on what you should be focused on, that's focused.


SPEAKER_04:
Thanks.

Just one note on that is under the reward paradigm, plus minus valence, avoid approach, a sort of forward and backward linear mindset, we can say, oh, well, not just do we diagnose happiness or sadness or on a linear scale, but it's a goal.

And so just what are the aspects of our experience or of just the outcomes of systems that can be said to be related to focus and attention and action?

So how about just mind wandering since it's a related topic?


SPEAKER_01:
Sure, this is, so here, these are different papers.

And so mind wandering has been explored in several different contexts, but specifically like the figure on the left is by Wanda Huck,

Hasselkamp and she studies she's at the mind-life Institute so studies directly meditation and the effects on the brain and here it just kind of shows the different brain regions that are activated during meditation or

Also, it's like where you have awareness and then your mind is wandering.

You become aware that your mind is wandering and then you shift your mindset back to like, oh, I better be paying attention to my meditation, for example, focusing on my breath or whatever.

And then you have a state of focus again.

And this kind of contrasting neural model of mind wandering, this is a 2016 paper.

And here, they discuss this in a very different way.

So when I think about mind wandering, it's easy to think about in the context of meditation.

But here, they describe like, okay, if you're focused on a task, that's on task.

and then mind wandering is actually pursuit of internal goals which i thought was interesting like you're still focused but you're focused on your shopping list or whatever like internal thing that you're you want to focus on even though you're like this is like mind wandering and then they call this off focus

is epistemic exploration, or this is like the exploratory, like where your mind, what I think of as mind wandering, they call this off focus.

And so I thought that that was kind of a different paradigm and not something that I'm used to hearing, like where you're just, where you catch yourself, like, why was I thinking about red balloons and frogs with three legs?

Like where you just find yourself in this intellectual state, like, what am I thinking about?

Or why was I even thinking that?

Whereas mind wandering is like, you really are thinking about like,

something else that's like you should be thinking about, but it's not exploratory, which I thought was kind of interesting.


SPEAKER_04:
Cool.

The things I'd say about that on the bottom right, first, it doesn't look like there's a transition from the bottom left to the bottom right.

So it could just be that the dynamics, the attractor dynamics of this dynamical system are such that when you just down project these massive data sets of neuroimaging, you get certain transition dynamics, which is totally the case.

Like you're sleepy before you fall asleep and then different people

accelerate or have different dynamics but there is kind of a trajectory um so that was one point was these could be very nuanced states and then the space and the transitions that exist or don't can be important and the second thing is that the y-axis has to do with some neuroactivity some neuro marker where it's low in the bottom two and high in the middle one but then the x-axis is behavioral results so the idea would be that there might be some correlation

between like, wow, it was like they did 30 seconds of really good task.

And then there was 15 seconds where they totally didn't do the task or it was variable.

And then if you found a neural change that was like immediately preceding that or after it or during it, that's the kind of cross data set connections that this research is getting towards.

But instead of just putting this into the broad framework of dynamical systems and statistics,

Now we have a process theory like active inference to explore some of the dynamics that give rise to those patterns.

So blue and then D.


SPEAKER_01:
So interestingly, there is a correspondence.

So it does map what was found.

And I had to read into the paper to kind of find this out.

But the mind wandering in the left image does map actually to the mind wandering in the image on the right.

Or the brain regions are super similar.

So I read to just make sure that there was some cohesion there.

And there is.

So it's interesting to me to think about this off task.

What is off task versus mind wandering?

And what...

For me, if you're meditating and you're not focused on the thing, you're off task.

But it's, I don't know, super interesting.

I just wanted to clarify that one point, though, that there is a cohesion there.


SPEAKER_04:
Thanks, Blue.


SPEAKER_01:
Dean?


SPEAKER_02:
Yeah, I used to have to work with people who were at a real... I got to be polite because I'm being recorded.

They had a real joy out of...

looking at time on task.

This was something that they found really, really important.

And so if you were task designing, you were supposed to be able to create something in your design scheme that would keep people focused all the time.

And in the meantime, there's a whole bunch of

interesting papers that have come out in terms of creativity and tangential thinking and mind wandering as an actual gift for taking what's in the task and making it your own.

Like if you're mind wandering, you're not, it's not a disconnected thought that you're having unless you're really being distracted by something.

the video game or the music or whatever, it's usually something tangential to the task at hand.

And it's essentially an embodying exercise.

So I think this is good stuff just because I think lots of times mind wandering, if you're focused on how many minutes was a person focused or concentrated is seen as a negative when from creative stance, it's a really important thing to do.


SPEAKER_04:
Thank you, Dean.

And then Stephen.


SPEAKER_00:
Yeah, I think it's useful to see a transition, some sort of transition state between the regime of attention where you're on task and a regime of attention where you're mind-wandering.

So I think that opens up

um questions of how things you know liminal spaces between states and um the need to like if you're always coming back on task yeah it would and you're not getting beyond that

state of losing focus um and that that could be a problem I mean it could be a problem with the mind wandering doesn't get back on task as well I suppose but uh so I think that's um that that would that would make a lot of sense I think nice how about um mindfulness so just the yellow part and then blue or anyone can give a thought on what they added um or um


SPEAKER_04:
Mindfulness, for the purpose of this work, they're going to focus on regulatory cognitive control strategies in which an agent seeks to control their mental states by becoming aware of the state as a cognitive process, as opposed to regulation strategies where one remains engrossed in the contents of the state.

This style of regulation is central in mindfulness related intervention where patients learn to change their relation to thoughts and emotions rather than change the thoughts and emotions themselves.

So this is pretty interesting.

So becoming aware of the state as a cognitive process is like,

this is a thought, I'm having a thought.

There's many, many praxis, many knowledge traditions built around this, which you can mention or have people with experience talk about.

And the alternative is like, when you feel X, feel the X and be the X. That's sort of the opposite cue.

So we're thinking like mental action, cues for action, like cues for a sport, Dean's favorite topic.

And then there's cues for mental action that are verbal or have other modes of being delivered.

And what are the cues for mental action that leads to different regimes of attention, like Stephen said?

And then how are the measurements that we're going to make from different modalities going to inform that study and the kind of modeling that integrates across them, which we'll get to as well.

Stephen?


SPEAKER_00:
Yeah, this is a useful piece here.

It's good to distinguish between, I mean, often children, for instance, there's now more emphasis on mindfulness.

There's that big push to just get them busy, you know, make them do sports, make them do this, make them do the other.

So they're so busy with something they can't think about anything else, but actually saying to them, okay, you're going to be in a space where you could think of other things and you're going to work on

how to not focus on other things has some benefits.

I think there's some slight downsides of that if someone's got trauma, because then it opens up the space for those things to be coming into play.

So I suppose, I think this is really helpful to see where they're going.

And it'll be interesting to know

um how this plays out because there's always a danger if someone tries to scale this type of work because it's it's also easier to use the insights from this type of work to try and capture someone's attention at scale or capture many people's attention by using some of the levers here as much as it is for the person on the inside to be able to resist all the distractions and the the flashes of light that they keep getting exposed to in their daily life thanks steven blue


SPEAKER_01:
Yeah, kind of.

I want to just follow what Stephen said.

So I don't know that the children or even like us adults being constantly exposed to flashing blue light, like the smartphone, like instant dopamine addiction, you know, fulfillment thing is necessarily the opposite of...

Mindfulness, I think that that filling is maybe the elimination of boredom, which you can have mindfulness with boredom or mindfulness while doing nothing and mindfulness while not doing nothing.

So you can have actually not sitting in mindfulness meditation, but retain through, this is called like meditation practice, the meditation off the mat, right?

So like there's the conscious placement of the mind during the meditation session, but then when it's over, you carry that into your daily life.

by constantly asking yourself, where is your mind?

That's the image I put in about the old Pixie song, where is my mind?

So there is the ability to carry mindfulness.

Even if you're very busy, you can still practice mindfulness in your daily life without taking time to sit on the cushion.

So I think we are starving our children of boredom, which maybe is, I'm more focused on or more worried about a lack of creativity

Because I think that that boredom process where your mind is really wandering to red balloons and frogs with three legs, that is where the creative nature tends to bubble up.


SPEAKER_04:
Awesome.

And I won't mention the person's name, but I hope that they've emailed us.

They have emailed us, so I hope they talk more about it.

But they've related these aspects of active inference to the yoga of action, karma yoga, and basically the way that action exists in the world.

So I hope...

not what my knowledge area is.

So I look forward to learning about that though.

So before we jump into the paper, this has been a nice long background because there's a lot to say and it's pretty interesting.

Look at this fun April 1st, April Fool's Day with Steven and Blue and I.

But they write in this paper that the key technical innovation presented in the paper is an extension of the active inference framework derived from the work of Hesp et al.

2021, which was the paper that we discussed in live stream number 19.

So if you want kind of the kernel of what this discussion is about, then check out number 19.0 and 0.1 and 0.2.

And we were talking then about affect.

and about the way that that made deep agents so listen there to learn more and now we're going to be doing a few of the similar things seeing some similar figures so it's a good background listen okay figure one does anyone want to give a first description it says in the caption a probabilistic graphical model showing a basic generative model for moment-to-moment perception

Okay, so the observation O is going to be used across different layers, but here is the model of perception.

So we can debate whether it's realism or not later, but this is kind of like the retina or the sensor of the camera O. It's like, did a photon hit it or not?

This is an observable that you measure with a sensor.

s at each level is going to be a hidden state so-called because it's not directly observed but it's inferred from observations through a which is a mapping so like this could be day and night and this could be photon hitting versus no photon hitting and then you can imagine the mapping there

But we'll see how they nest and get more complex than that.

And then D is the initiator.

It's a prior over hidden states, which turns out to be important because as you compute the likelihood of different hidden states being the case, moment to moment or through time, you need to start with an idea of essentially how likely certain states are and how closely they map to observations.

That's the kernel of the Bayesian modeling that we're going to elaborate a lot

like multiple successive times.

But this is the underlying system that can be thought of like photons hitting the receptor and a mapping to underlying states as influenced at least initially by a prior.

Okay, any comments on one?

Or we can go to the next generalization in two.

okay so two is a base graph showing a basic generative model of perception with precision so it has the same terms and you know dsao as above dsao but now there's a new node and each shape just at a first pass represents some value that can be taken by a variable

And then an edge that connects two states is like a relationship between them.

And there's different kinds of nodes and there's different kinds of edges slightly in how they influence each other, but they just mean that they influence each other.

And that's important because the edges actually in the grand scheme are very sparse.

It's not an all by all model.

So this model is extremely more tractable to compute than like an all by all matrix of just estimating the coefficients of how related terms are.

So it's a very constrained model space, but it still describes a lot of system.

And the second figure adds in this gamma sub A, which is the precision, which is one over the uncertainty.

So just as we had talked about those being two sides of the coin earlier,

This is like uncertainty slash precision, depending on which way you want to think about it.

High uncertainty, you're really unsure, that's low precision and vice versa, but it still maps onto the sensory outcome.

In both these cases, after the sensory outcome occurs,

then there's uh an update the prior becomes the posterior after getting a precision weighted updating and that's just how bayesian updating works so this is a bayesian scheme for updating that initially doesn't include a precision on the a and now it does include a precision on the a any thoughts on two before three


SPEAKER_00:
Yeah, I think it's interesting.

It's good to know that the expected precision is tied to the likelihood mapping.

It doesn't try and tie itself directly to the state.

It's in the way that the state is being... So that helps to really notice that and make that clear because that...

gives the logic a little bit more of clarity.

I think that's often a bit that's not teased out as often as it has been here.

That's quite useful.

Awesome.


SPEAKER_04:
Cool.

And what else is interesting?

So good observation that the uncertainty is connected only to the mapping.

So it's not uncertainty about the state.

It's about the mapping in this formulation.

Now we're going to see a similar move and two things happen in figure three to bring that previous model into this kind of twice generalized space of generative models of action and perception.

The first thing is that now there's observations through time versus at a moment with just one observation.

So subscript one, two, three, through time, three time steps.

Then here's that DSAO stack.

And then B is the transition matrix between states through time.

So we've talked about that on other streams before.

And then again, a similar move, just like you pointed out, Steven, how the uncertainty or like the intervention in this case, the policy pie, it's actually modulating the transition mappings rather than the states themselves.

So,

I'm sure that has very interesting computational properties that I don't know the details of.

But I think that's some components that make it amenable perhaps to message passing or to the variational inference methods.

But that's definitely an interesting observation that you made.

It's true.

It happens again here in a totally different way.

And then pi, the policy selection.

is influenced by preferences which play into the calculation as expected free energy as well as this baseline prior e so we've seen this one before and this is how policies are selected over um for the next time step based upon the um expectations of

hidden states and observations through time in relationship to priors, e, how they're apt to perform before starting this sequence of events, and then the way that they calculate their preferences over observation states, which also relates to how you said the body-centric inference.


SPEAKER_00:
This might be a question, Daniel, for them, but it says preferences over outcomes, and it goes into the expected free energy.

Is that almost like different ways you could weight the way the expected free energy terms are presented, you know, over maybe Hamilton's least action versus...

resolving, you know, would they be doing something like that?

I'm not sure we can answer that, but does that make sense?


SPEAKER_04:
It's a preference for sensory states.

And then we saw in the model stream one with Ryan Smith, like if you wanted to have a very weak preference in the matrix, it would be like one versus 1.1.

I'm just making those numbers up, but the point is like they're relatively close.

It's like a 60-40 election so that the preference is very weak.

And then you could also set it up to 100 versus one.

then if you think about that like when you're just totally thirsty and you're willing to engage in all kinds of actions that's how you could computationally put in direction as well as magnitude of preferences over outcome some people that describes you know maybe some individuals have a broad sensory tolerance others have a narrow sensory tolerance or preference so that's so you got you so it's almost like you can you can narrow you can either open up or narrow down


SPEAKER_00:
the amounts of options that are going to be available by saying the gap here.


SPEAKER_04:
And then in the absence of preference, if you don't have a preference for pheromone, it's just going to be a diffusion walk.

So that's how preference plays into the decision-making, but also other pieces do too.

Okay.

So then here, here's where we introduce this second nested layer with the deep generative model of mental action.

So here the same DSAO is recapitulated from the orange, but then the O is split into two nodes.

One is an estimate of the state, but also it's passing or connecting to the precision, the uncertainty.

So the features that were being discussed like up until figure three,

as being just part of how the inference was performed are now still doing the same exact role.

They're just being emitted by the state through the A, S sub one of two, like the second level in parentheses, through the A matrix at the second level.

And then that's resulting in these two outputs.

So this could be like a nested layer of thinking or a nested layer of concurrent programming or a nested layer of formality, Dean.


SPEAKER_02:
I'm going to get the author to make sure that I'm getting this right.

But before, something I remember from what Casper talked about with his effective piece.

And then there's a figure five, which we'll get to.

But to me...

The figures one, two, and three aspect of this are the unplannable parts of it.

The figure four does ask the question, why am I, or yes, why am I trying to pay attention to?

It's kind of the transition space.

And then the figure five is where we could actually do some planning because we're saying to ourselves, now pay attention.

because we're putting that second order, we're paying ideas to ideas piece.

So I think up until this point, up until figure four, it was unplannable what we're modeling.

At figure four, we start to transition, and then in figure five, we can actually incorporate a plan if we so choose, if that's part of our policy.


SPEAKER_04:
Nice point, these are really helpful labels, like pie at the first level, what am I trying to do?

So in the case of the light hitting the receptor and then is it day or night?

When we introduce policy, that would be like, should I swivel the cart, move my sunflower head left or right, move my camera left or right under the preference for light.

Now, if you didn't have preference, it wouldn't matter, right?

If you don't know where you're going, it doesn't matter where you go.

But if you have a preference vector that gets increasingly stringent, you're gonna pursue

those policies that will lead to getting the observations that are in line with your preference now here the second level so this is again what am i perceiving what am i trying to do that's the motor cart with a visual receptor and then here the hidden state

And again, it's just the same exact placement analogously the first layer is what am I paying attention to?

And the policy is a policy over attentions.

So that's what makes this model nesting outside of the smaller perceptual level model.

So Blue, did you wanna say something or no?

Okay, then Steven, go for it.


SPEAKER_00:
So it's treating the precision

And it's somehow merging that with the states and pushing that through another matrix and probably doing that.

I know Ryan Smith talks about a cycle of six in terms of when they model.

They go through six.

It will iterate through six.

And then the next level will just sample the sixth, the sixth, the sixth, the sixth data point, so to speak, in the faster data going below.

But I'm not sure how does that work with the two being combined?

The two are combined basically to give you the higher O2, is that right?


SPEAKER_04:
So I don't know about the six specifically, but here you can see like at the first time point of the slower model, this is like the hour hand, there's like the estimation or inference over states one, two, and three.

everything about them like what's the hidden state and the mapping and the observation which you can then conditionalize the inference on a subset of those variables but that's what the whole model is and then then it's like you're estimating at time one about time one two and three and then at time two you're also estimating over that trajectory but the slower hand is like the hour hand

Okay, continue.

Because I think this is where five is where you're getting at, Dean.

It's totally the contribution of the paper.

So they summarize as saying that they make three, and this is, the 19 has sped all for a lot of this structure.

They summarize that they make three novel contributions to parametrically deep active inference models of cognitive control.

The first contribution is to stipulatively

define attentional and meta-awareness states as the mechanism of opacity control at different hierarchical levels.

The second is to provide a formal definition of attentional and meta-awareness control via an account of higher level policy selection.

The third is to formally demonstrate the relationship between meta-awareness states and the capacity for deliberate attentional control.

we're gonna look at the model in figure five, and that's still gonna be like sort of the abstract skeleton of the model.

And then there's gonna be a simulation results.

So that was kind of all the background actually to their primary contribution.

Now in figure five, we see this explicitly three layer model.

and this is the primary contribution is this model topology and architecture and then the interpretation of the higher order states in terms of the opacity transparency and then eventually a more generalized perspective on mental action

and bring this all together with a model that does basically the same trick around the second layer as happened around the first layer so these layer one and layer two are the exact same from figure four and now there's this third green layer where the states are asking the unobservable question how aware of my how aware am i of where my attention is

then the policy question is am i trying to maintain awareness of my attentional state or something like that we can get at what exact wording these parameters map onto but totally interesting tape and structure of the model in question so any thoughts or what was exciting to people about figure five stephen and then anyone else


SPEAKER_00:
Yeah, it's exciting to see.

It's got some similarities to the valence, the deeply felt effect.

Valence has been a higher level sort of calibration.

I suppose in a way they might try and find a way to put those two together.

When you say I'm aware of where my attention is,

Well, what kind of awareness is that awareness?

Is it a feeling?

It feels good or is it something else?

So, yeah, nice.


SPEAKER_04:
Dean or Blue, otherwise we can.


SPEAKER_02:
I just want to say a couple of quick things.

So the way that they laid the paper out, this made a really good case for why they were focusing on the transparency and the opacity piece.

And they don't make any claims around whether or not

person who's looking at a white page with white text written on it can actually see that white text or whether or not the size of the font is so large that you're only seeing one pixel in the letter A on that page so you can't even see the A but I think both of those things matter when we're talking about attention as well how can you pay attention to something where you can't see the contrast or how can you pay attention to something where the proportions are so out of whack that they just don't make any sense to you

Now I know they're not talking about that here, but it would seem to me that that would also be a part of where this computational piece would be really, really helpful because to a learner, sometimes it's easy to see the tunnel within the mountain.

Sometimes it's really, really hard to be able to pick something up off the page when it's either way out of proportion or there isn't any contrast.

So I just wanted to kind of, I want to, I want to give the authors credit and I think, I hope, I think I know where they're going next.


SPEAKER_04:
Thanks.

Yeah.

Cool.

Let's go into the little one cul-de-sac of the formalities that is kind of interesting.

And then we can also ask the authors to explain a little bit more to us, but just to get at how does this S state sub T so through time across time points at the second level.

So that's going to be what we're focused on is how this

is kind of at the intersection of perhaps you could even say the bottom up and the top down signaling or at the very least it's at sort of a um you know mid-level street in the scale of streets of variables from local neighborhoods like down here in the bottom cluster to sort of regional hubs to this broader

connection that is happening at an even slower or deeper time scalar way we're kind of looking at this middle piece as a as perhaps an example of again how factors from bottom up and top down interact and then it's kind of like legos maybe it can be generalized from there and you can say okay let's nest this within that or see what happens if you connect over here but they write mathematically the attentional and meta awareness state inference is calculated based upon three sources of evidence

read prior beliefs so this is the B and the S at layer two so those are um like what is previously influencing that layer specifically so that's what happened before at that layer direct perceptual evidence e.g the metacognitive observation of one's attentional state blue

And then orange, ascending evidence based on the precision beliefs of the level below.

So maybe that's where

If you just opened your eyes in the morning and it was too bright and you don't have the resolution, now you can't make the good mapping between fine-grained details because your resolution from a sensory perspective, like the precision is adapted for a different regime of environmental regularities.

So there's perhaps many ways to model this.

So then they say something that was kind of interesting.

For the ascending messages from the continuous expected precision to the discrete states,

we use Bayesian model reduction,

for the derivation C frist in 2018 to evaluate the marginal likelihood under the priors associated with each higher level state.

This gives in the case of the attentional evidence, for example, and then the equation that has these components that were here.

So it sounds probably extremely technical, but it's a pretty interesting topic that we'll look at just in another slide, because it is really important to understand how this bottom-up continuous info becomes translated to discreetly different states.

And then this is just to note that this is like the general structure of the model, which you could imagine is also computer variables, but then they preset two mental states associated with just specific parameters that they chose.

So especially the simulation is just like a parameter combination.

It's not all the possible dimensions one could explore.

So that was just to note.

So here's, oh yeah, Steven, go for it before we go to model reduction.


SPEAKER_00:
I think this is helpful to think about

how that top level has that impact.

So you can imagine, you know, you wake up sometimes, say you're at home and you wake up and it's just, and slowly you just, you see the room you expect to see, okay?

And there's the other times when you wake up and you've gone away and there's that jolt because the prior expectations were still locked into like, you're dreaming about waking up at home or you're sort of, but you're not at home, right?

And there's that.

So it's almost like you're fulfilling your expectations.

These higher level could just start to,

percolate out as you enter into certain states or into certain rooms.

So I think that's quite a nice way of thinking top-up, top-down, bottom-up, and that being about perception as well.


SPEAKER_04:
Cool, nice point.

Deep priors, narrative priors, how did I get here with sensory priors at the moment-to-moment?

So here's the paper with Friston, Parr, and Zeidman from 2018-19, Bayesian Model Reduction.

So

The yellow parts are highlighted, but just one green part and then kind of a takeaway here is we consider structured learning and hierarchical or empirical base

that can be regarded as a metaphor for neurobiological processes like abductive reasoning.

So I know that that's what we're kind of excited about and the paper that we brought up of Majeed Beni, but that's super interesting.

Like just to kind of skip to the last sentence, how are they going to be using model comparison of Bayesian models to explore abductive reasoning?

One takeaway, but really would be great to have people who know more about this topic have a little bit more insight would be like we can compare Bayesian models that only vary in their priors.

It's really easy to compare the similar structures of models

that just vary in like whether they think it's gonna be a Gaussian centered at five or centered at seven.

There's a lot of tools that help you very rapidly compare that.

But if you have two totally disparate model, two programming languages, they're predicting different things, it's really hard to compare them.

So the frequentist comparisons can be very intractable as well as sampling and simulation based ones that are just like brute force, or they can have stringent requirements like the hierarchical likelihood ratio test

is only applicable to certain subsets of frequentist modeling.

So structure learning is hard.

What is the structure of causation?

What's the structure of the data, the shape of the data, Dean, like you brought up?

So how can we frame this question and challenge about learning about structure of data in terms of model comparison or updating of priors amongst models that have similar structures but just different quantitative variables?

And so Bayesian model reduction is a way that you can do this kind of structured learning.

And one loose analogy is the lasso regression, which tries to restrict to a very small set of few strong factors in a data set that might have like many weakly interacting factors.

It kind of truncates the distribution and just says like, give me the most relevant ones.

And if it's just massively interacting, then, you know, so be it.

And that kind of a regression is going to have a similar use, which is to converge upon a smaller number of things that are really informative while keeping the model also similar, which should be reminiscent of like the Bayesian information criteria, AIC as well.

And then here's in that paper,

And it relates to what we read earlier.

How do you go from quantitative continuous estimates, in this case coming from perceptual updating of that retina sensor, how do we plug in from the continuous and map to categorical a discrete selection of models?

So mapping from continuous to continuous, you can just do like a dilation or some other function mapping, but it gets a little bit different when you want to map between these worlds of continuous and discrete.

And it turns out that the way it works is that inference is performed within and among a family of models, Bayesian models, that are using parameters like quantitative difference in parameters to describe structural connections between variables.

so here's like let's just say that black is zero and white is one then here's like all the combinations of linear models that were used to generate the different models so this is the exhaustive frequentist approach and then

Here, what's happening is the Bayesian model is estimating the relevance of each of up to 20 parameters, and then estimating a credible interval, which is 90% in this case.

90% of the time it's within this interval, we think, or that's where it's likely to be under some value of stringency.

That's the red blur.

And then you prune the ones that are like not significantly different from zero.

So it doesn't mean that they're not zero or they're not playing a role or the proteins don't touch, but it means that you can actually structurally simplify the relationship between variables.

So that's moving from continuous evidence about models of a discrete family to a reduced model that could potentially be extremely parsimonious.

so that's just the bayesian model reduction but that's like i guess a sub component of this paper so wanting to know more about how it comes into play or if there's an analogous process on the generative way down okay any thoughts on that or just that was one little section well i was just thinking i mean i'm not sure if i've


SPEAKER_00:
got this potentially right but i can see this brings in the idea of how action can be used to think like in creative abductive work you you know you can start to actually create entropy or create confusion to create some possible outcomes and that the art of

the creative process isn't necessarily the creation of random novel ideas.

It's being able to prune back.

I think it comes a bit back to that idea of that task-related off-focus mind-wandering, you know, the ability to then go backwards and forwards.

And that might tie in with this ability here to do this.

I'm not sure, but it sounds like this would tie into that somehow.

Cool.

We'll ask the authors.


SPEAKER_04:
OK, nice.

Onto the simulations.

Also, people can just leave when they need to.

This section is going to provide the simulation results that show how the model described in the previous section engenders opacity transparency phenomenology.

So outputs of the model that recapitulate some of the dynamics that have been described in other experiments.

And then they're going to use that agent with a three-layer generative model.

Okay, so first was just the... Any thoughts on what the simulation is or just to contextualize it before we talk more about it?

Okay.

The code is available.

It's a Colab book.

It's pretty cool.

It makes a lot of the graphs.

So nice work for the authors.

Maybe we can walk through it or ask about certain parts.

But cool that it's an interactive notebook.

Okay.

Anyone want to describe seven?


SPEAKER_01:
Sure, I will.

So here it says, just the yellow part, it says, in the first half of the trial, the agent is in the focused state, which confers a higher precision, i.e.

the agent is generally more confident about how their observations map onto states.

In the second half of the trial, the precision drops as the agent moves into the distracted state.

As a result, their beliefs about latent states are updated more slowly.

So this is kind of like, I wasn't really paying attention.

Did I just see a car flash in front of me?

I don't really know because I wasn't really paying attention.

Whereas if you're focused on the screen and watching the car, you see every flash and you know exactly when it flashed.


SPEAKER_04:
nice way to put it blue so the blue is what um happened it's like a tone like a lower piece even like a lower tone versus a higher tone that happens some frequency of the time and then um it is just this is a agent that's artificially held with a total focus state for the lighter half and then it just switches instantly and we're exploring how this s at the first level so to go back to figure five

that's the perception is s at the first level and then that is an estimate that's changing through time and so um when it's focused it's like higher highs and sharper and lower lows and then distracted states just more like wait what stuff's more just spread out and it maybe has a different recovery or similar speed but lower to rise so that's how they say that um

That's how they make their claims about the way that the attentional state influences A1.

By making the likelihood mapping more or less informative.

Because if it's uninformative, the likelihood mapping, then why does the sensory input matter?

Go with your gut.

But if it's very precise, you want to go with what your lying eyes are telling you.

And that is reflecting in figure eight, this phenomenological cycle.

So these can be discrete just via that mechanism of like the continuous to discrete estimation.

And they write that this is the diagram of the phenomenological cycle that occurs during sustained attention tasks.

The process cycles through being focused, becoming distracted, becoming aware of this distraction, and then refocusing.

So it's cool because it looks like internal-external states in a way.

And action-intense states, like it's a OODA loop, or there's so many other four-fold models.

But what are we actually looking at here?

We're looking at the dynamics of that attractor state as it wanders.

So I feel like since both of you have thought about attention or awareness, maybe what did this look like or what does this mean to you?


SPEAKER_02:
Do you think that we attend through steps all the time?

I know that for the simulation, they want to be able to see that in order to be able to do the calculations.

But do you think people do that?


SPEAKER_01:
So I think that the shift from focused to distracted is maybe not discrete.

That might be more of a continuous shift.

transition but definitely like as soon as i'm aware that i'm distracted like the attention gets redirected like that is a the awareness of distraction is a discrete like bam oh and then the redirection of attention is is also like i can replace it and then i'm focused again but then the transition so it's just this top left corner where it's a little fuzzy for me


SPEAKER_04:
I really agree with that, Blue.

Like, awareness of distraction to redirection of attention, that's like, you know, the eye of Mordor.

It just goes somewhere else, okay?

But then the distracted to the awareness of distraction is actually that same, but it's the eye, the cognitive, metacognitive eye of Mordor turning its eye on a lower level estimate.

So I agree that actually this, from noon to six, it looks, it's pretty interesting how it maps, but then...

do we think about focus and distraction as part of a continuum of a single variable or is this like in a yeah is there can you wobble or is there like more dimensions to just being super strongly obsessively doing something how far do you pull back what if you have to you know put down the first pen to pick up a different pen you're pulling back from the goal but you're moving towards it so that's the kind of deep policy questions that are so cool that we're raising blue


SPEAKER_01:
Well, so it's cool because here it's this gamma function, right?

Like, so the gamma is the precision.

And so just by changing the gamma and like you can change the gamma incrementally, however you want to change the gamma, like 0.01, 0.1, 0.0001.

And then by changing that gamma, you can really get that shift like computationally from focus to distracted by just by changing that precision metric.

Yeah.


SPEAKER_04:
Yep.

And I mean, that's kind of imagine the little headband when people are paying attention and what do you do?

So here I copied the left side of I think five and then just laid it next to here.

So these are the questions that again, each layer is asking.

The blue layer is like the perception layer.

and related to the policy that's going to get those perceptions in line with preferences.

So moving the cart back and forth to be in the right amount of light.

Then hidden mental states are about paying attention.

And then what influences the precision and emits a precision variable and an observable at a higher level, just like A sub one at the second level.

Here's like A three.

And here's now the slow one, but it's happening actually at every time point.

So again, you could probably elaborate this in various ways and ask like how many time steps of action are calculated per attentional state?

How many attentional states are calculated per metacognitive state?

Are they all in the flow?

It's so interesting.

So here, then they also put down the specific matrices.

I assume the ones that we'll see in this video

Colab notebook.

These are just like the parameters that are going to illustrate some of the dynamics that are going to be interesting for the fields.

But again, these are parameters that could be learned or updated or could reflect not just a two by two option.

All right.

So maybe even copying this guy out again.

Here, figure 10.

Yes.

Okay.

so here are the three layers of the model and so the bottom layer is playing the oddball Paradigm so it's like listening to like regular tones and then once in every x percent there's a differential tone but also that could be like which one of these security events is anomalous or which one of these trades would be effective amidst the prior that 90 are probably not so

It starts off focused and all systems are normal on the sensory side.

And it gets distracted, it returns to being focused.

This is the true state at each level is the dot.

So the bottom layer is like the percept of the sound.

This is the attention, this is the meta awareness.

And then this you see at the change point from being distracted to focus, there's a switch point in the third level.

So then everything's normal, the sensory level, and then it's distracted.

And then the oddball happens at 21 or something.

And then that like flips it.

It says, flips it back into attention.

And then that continues and it stays in that state.

until an event happens.

And so this is just simulating out the dynamics, but the idea with this kind of a graph is that we can scan along and look at how changes in one level either are influencing each other statistically, causally within our model, not necessarily about the real world, but just literally causally because we specified it in our model and then do parameter fitting and be like, whoa, we can explain 95% of the variance in this behavioral data set, even though we didn't observe

the red or the orange we observed this or their task variability but then we have enough data points from enough individuals and from time series of this individual and then start to add in some other measurements and there's a lot of data to do inference on these higher order states about any comments on 10.

Okay.


SPEAKER_01:
I'm just thinking, so sorry.

I'm just thinking about how this is going to be used, like...

by companies to keep you working.

Like, I just can't help but, like, think about thinking about that.

Like, are you paying attention?

Are you not paying attention?

Can we give you an oddball to make you pay attention?

Like, you're sitting at work and all of a sudden, like, oh, shit, I wasn't even paying attention.

So, yeah, like that.

I think about that.

And it's kind of scary and it's kind of, I don't know, it's real.


SPEAKER_02:
think blue if people actually tried to do that I think they would be more misinformed than they would be informed as I said for half a dozen years I work with people who whose goal was to pull apart and sort of get a better understanding of this time on task piece and they're no closer today to understanding it then

They were a decade ago and they spent a lot of time on it because I don't know that this literally maps into an appreciation or understanding of what on task versus off task is.

There's tangents to tasking.

And I don't think that this really gives us a sense of what that is.

I think the blue layer does speak to the unplannable.

I think that the middle layer does speak to transition.

And I think the top of green red does speak to plannable.

But if somebody in an organization

thinks that they're going to have a better sense of how they're going to determine whether a person was on task or not, I say good luck with that.


SPEAKER_01:
So I actually have a colleague that's developing a way to determine if a person's in the flow state or not, which is very different, very interesting, like with physiological.

So attentional is different.

Like, are you paying attention versus are you in flow?

And it's really interesting.

And they've got some decent results so far.


SPEAKER_02:
Yeah, well, they can count the number of saccades or saccades.

And I've looked at the whole visual memory thing and all of that literature.

And they're still not getting any closer to understanding when a person is on or off task because they want to break it down to that kind of a binary.

I say, let them continue to do that because

I'm not sure if it's nefarious, but I think it has the potential to become that.

So I'd like them to go and spend all their time on it because they're not going to figure it out.

Keep them distracted.


SPEAKER_04:
Oh, Dean, laying down breadcrumbs.

I love it.


SPEAKER_02:
Carry on.


SPEAKER_04:
Figure nine is going to be that same cycle of four that we were talking about on eight.

And now in addition to just the sort of qualitative label, we're gonna map that onto the structure of the model that we were discussing.

So here, like the redirection of attention is being framed as policy two, pi at the second level.

So where's the action?

Pi at the second level is this orange one here on figure five.

So that is influencing what one is paying attention to through time.

And then that is being mapped to here.

And similarly, you can read through and just work through the combinatorics here of what these map to from a dynamical systems perspective.

Like while it's in a parameter neighborhood or regime or attractor state,

or manifold that's in one area in a distracted state, described by a wide range of continuous parameters that map onto the categorical distinction of the true state being distracted, but the perception being that one is focused.

So just work through what these distinctions are.

It's pretty interesting.

Yeah, anything to add on that?

It's kind of cool.

Okay.

11 is going to be another kind of... Just like in 7, they had the attention at the second layer at one parameter level, and then they just, like, turned down the dimmer.

In figure...

11 they're going to have a high meta awareness and then turn down the dimmer to the low meta awareness at the s3 so recapitulating the way that they added this third layer to hespedal 2021 they're recapitulating figure seven in how they vary the parameters changing through time but now you can see the dynamics are totally different like the spiking between focus and distraction is actually happening faster during the period of fixed high meta awareness

Whereas during the period of low meta awareness, actually it's like there's longer intervals.

It's like, whoa, what just happened?

I was having low meta awareness.

The time just flew by.

Or maybe there's another interpretation, but it's just a nice plot that gets at how just a parameter combination can give us insight into the structure of the model.

So we kind of have the graphical doorway, the programming doorway, then this is like the outcome oriented

data science way, because this is just input in a model.

It's just in a machine learning notebook.

It doesn't really even explicitly invoke the graphical structure that we just have been talking about the whole time, but it is that embodied in a simulation.

All right, Dean?


SPEAKER_02:
No, I got to talk to the author tomorrow because it brings up the thing about... Is it tomorrow?

I'm pretty sure it's... Yes.

I'm going to want to bring up what I...

You should talk about it as a crosswalk analogy.

I'm just going to leave it at that.


SPEAKER_04:
I can see you being a great crosswalk guard.

you wait so figure 12 this is kind of the last figure i thought this was an awesome figure and one i i know that we'll return to many times a based graph of a deep generative model of mental action generalized over all precision parameters so now that attentional state

likelihood mapping is going from potentially a binary state like we saw here focused or not i mean uh yeah um the likelihood mapping kind of like the dark side of the moon album cover can emit like five simultaneous outputs it can output a tuple or a vector from a computational perspective perspective and it can output what we talked about here

but it can also emit an uncertainty and potentially even other things connecting to multiple of these lower level parameters.

So now there can be an uncertainty over the priors, whereas in the previous simulations, D just stood alone and there wasn't uncertainty around it.

So it's just sort of taking the next step and just being like, okay, if we went from estimating the valence

with the actual like plus or minus, are things going better or worse than expected?

And we just said, okay, what's the sister of valence, reward?

The sister is the uncertainty and the precision and their relationship.

So now this paper, that's why it builds on HESP 2021, because it fills in the other compliment there, which is the precision modulation by higher level states, rather than the valence modulation by higher level states.

How well are things going?

And then that insight to generalize into the variation from a top-down level has strong precedent in Bayesian modeling where it's related to like the parametric empirical Bayes and hierarchical Bayes.

So big.

A lot of philosophical questions about what a parameter means, challenges in implementing it, but this is a relatively generalizing step in the publications.

Oh yeah, exactly that.

It's the same higher level affective states applied to the likelihood precision rather than model precision.

And then, note that this evidence is only available when higher level likelihood precisions is non-zero, i.e.

when the state is opaque to some degree.

As a result, the transparency opacity distinction can be directly related to the evidence calculation.

so she thought what does that mean or just interesting like we don't notice something and then we do so it's kind of like it's transparent and then it becomes opaque and we observe it in this model it puts us over threshold of observation that takes us off task as defined by policy

Okay, on to the implications and bigger questions.

So, Blue, go for it.


SPEAKER_01:
Well, so just to your last point, like, I wonder if, you know, have you ever felt so focused you're distracted?

Like, that's a common thing for me, and maybe it's focused on the wrong task, but it's also, like, you're focused to the exclusion of everything else.

So I just wonder how that goes into this transparency, opacity, like...

Gradient, maybe?

So anyway, and then, yeah, on to implications and bigger questions.

So I think about, oh, sorry, go ahead.

Did you have something, some response?

Dean?

Oh.


SPEAKER_04:
Go for it, though.


SPEAKER_01:
So, yeah.

So implications and bigger questions.

So here I like when so I obviously got one during this discussion about being so focused that you're that you're not paying attention.

But also if we're talking about adding hierarchical levels.

So I wonder about here, beyond meta-awareness, I wonder about collective consciousness.

Like, so is there, you know, when you realize that you're part of a collective, and then when the collective develops some kind of meta-consciousness, like, so it makes me think about that and about maybe how to model something like that.

Maybe in ants, for example, because there's the individual level, and then there's definitely, like, the society structural level, the consciousness of the colony, maybe.

And also, you know, simulation theory, like...

So at what level, becoming aware that we're in a simulation, where does that fit into the hierarchical nesting of this deep meta-awareness?


SPEAKER_04:
Funny stuff.

Wouldn't have thought that that's where we would get, you know, but that's kind of what it has come to.

Any thoughts on that, Dean, before we go to the next slide?


SPEAKER_02:
No, I think it ties in nicely with the, what do we metacognize over?

And I'm going to bring up the crosswalk tomorrow.


SPEAKER_04:
Yep.

So this future of phenomenology slash neuro phenomenology, just whatever we want to call it.

Here's just a few angles on what is slash has and will happened.

There's multimodal brain measurements, OSPM, where art thy sting.

but just it lays out in 2007 and earlier, but in that textbook and in the online documentation, kind of generalized frameworks for harmonizing across different modalities of neuroimaging, behavioral imaging, hidden state modeling.

So a lot of the seeds are in SPM.

What we can talk about integrating now, other than in a laboratory setting like EEG and fMRI at the same time together, but increasingly, even at home, physiological sensors,

wearables, cameras, and environmental sensors, the capacity for models that involve multiple humans and finding the synchronies and attunements amongst them under environmental changes.

And this is like the work of Hyperscanning and Guillaume Dumas and a lot of other people in that field.

Thinking about cyber physical systems, like what if the state is inside the head purportedly of a human?

Is that different than if this state is purportedly inside of a software?

Which ones get to be affect?

Which ones get to be what standing?

And then also it helps us and always is important, maybe you'll go here with who and why and how, Dean, but,

really just all these axes that phenomenology has been addressed from developmental multicultural neurodiversity a lot of historical perspectives that also is continuing to weave together and not being said to be obsolete or simplified by a computational model yeah if you want to know more phenomenology go and read some sean gallagher

nice don't know about that but it sounds cool yeah anything there or last okay then here was just one paper that kind of came out just on a closing note like how it connects out maybe to other areas this was um looking at behaviors across a bunch of different fruit fly species drosophila

And then here's the big figure or one of them, kind of mapping, just like you might map genes being correlated or might map neural activations to be correlated across different regions of the brain, those same matrix methods, tensor methods, fundamentally, covariance estimation,

can be used to study different kinds of relationships.

So earlier, we saw the neural activity and the behavior.

Here, the heat map is like behavior to behavior.

They're looking for pure behavioral co-variation.

But then what's really cool about this paper is that they use several techniques from information theory, which we see all the time in FEP, information, thermo, cool, going that way, but then also puts it explicitly in a comparative evolutionary framework.

So this is really moving towards models that can just very seamlessly integrate different kinds of data as easy as integrating the same kind of data, just the matrix is type A of data by type B of data rather than type A by type A. So these kinds of models that cross data input types

need to be connected to broader traditions, like thinking about development, ecology, evolution.

And it's just also interesting how these fields, which are increasingly data rich, are gonna be using different cutting edge theoretical frameworks.

So that's just one closing thought about where's evolution in this?

Where's development?

Where's, what are we doing?

All these components that discussion elicits.

So any last thoughts?

Otherwise, thanks, Blue and Steven and Dean, because this was fun to work on, and I think we all got to learn a lot here.


SPEAKER_03:
Yeah.

Definitely.


SPEAKER_04:
More tomorrow.

Yep, I know.

We've just been so not on top.

Okay.

All right.

Thank you again.

Thanks, everyone, for watching.

Peace out.

Bye.