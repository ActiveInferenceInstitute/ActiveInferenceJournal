SPEAKER_02:
okay hello everyone welcome to the active inference lab to an active inference live stream with john boyk this is going to be great it's our second of these interactive discussions on the sequence of papers that john has written

And today we're going to be hearing about motivation and strategy as well as active inference, of course, a lot.

So I'm Daniel Friedman.

I'm a postdoc in California, and I'm going to pass it to John to introduce himself, lead us into this second discussion while I share the Jamboard link with our live participants.

So, John, thanks again for coming on and please take it away.


SPEAKER_00:
All right.

Daniel, thanks for having me on again.

This is great.

All right.

So my name is John Boyk.

I'm a courtesy faculty at Oregon State University Environmental Sciences graduate program.

And we're here in this series of talks.

This is the second in the series to talk about the series of three papers that I recently published in the journal Sustainability.

The topic is societal transformation, in particular, the de novo development of new societal

and so on.

And last week, as maybe you can see on the Jamboard now, last week we started with the first part, which was on worldview.

The topic, the title is Science-Driven Societal Transformation Part One, Worldview.

And we didn't actually get through that, so we're going to pick up a few tail end ideas there and then hopefully start on the second paper, Part Two, which is subtitled Motivation and Strategy.

encourage people to download the papers.

They're open access, so everyone can get them for free.

Page two, perhaps?

Yep.

Okay.

So just for more information about the project, about the links for the papers, for other links, there's a bunch of

little articles that you could look at if you're interested.

There's also an interactive model.

You could go to the Principled Societies Project website, and the address is given there.

So further information, if you need it, you can find it there.


SPEAKER_02:
Cool.


SPEAKER_00:
Three?


SPEAKER_02:
All right, three.


SPEAKER_00:
Okay.

All right, so we didn't get through the first, through the paper all the way in our first talk.

So there's a few things that I'd like to catch up on before we move on to paper part two.

We touched on active inference in our last talk, but we didn't really get around to discussing it.

So I want to say a few words about active inference itself, a little bit of a description about it for those who are not familiar.

And then we have the topics of cooperation and communication and the concept that complex organisms have complex needs.

And then on to some practical implications, and this is really the main thing I wanted to finish up with, is that in part one, I provide some kind of high-level sort of abstract concepts.

And I would imagine that the reader in certain places might be wondering, why are we discussing this?

What does this have to do with actually building new societal systems?

So I want to talk about

a little bit of the practical implications of all of this kind of abstract, all these abstract notions that we've been working with.

So I would like to just recall just a few ideas from our last talk.

And one is that, I claim at least, that a society has an intrinsic purpose.

And by intrinsic purpose, I really mean a biological purpose

eons of evolution.

And that intrinsic purpose is the same purpose that every living organism has.

So every living organism has this purpose, whether that's a bacteria or a human.

And then I also claim that society is an organism that can be seen as an organism, can be viewed as an organism.

And a society has the same intrinsic purpose.

So if our task is to develop new

are we and who are we building this for?

And what is the purpose of if we were to build a new societal system, new economic system, for example, what would be the purpose?

And if we know the purpose, then we can take the remaining, the next step and say, okay, we know what an economic system is supposed to do.

We know what a governance system is supposed to do.

So is this new design, design A, design B, is it fit for purpose?

That's the concept is that if we're going to design new societal systems de novo from scratch, then we ought to have an idea of what they are supposed to do and then how we might measure their fitness.

So that we can determine, did we, did we create something that is fit for purpose and which one of these options, which one of these designs might be more fit for purpose than others.

All right.

So that's, that's kind of where we're going here.

And, uh, so the, the, uh, I claim that the intrinsic purpose of a society and organism, any organism or any organism is to achieve and maintain vitality, which is accomplished through, uh, largely through cognition and cooperation.

And so to maintain and achieve vitality for who?

And that who I claim is the extended self.

So the extent this, all of us are enmeshed in our world, enmeshed in our environment, enmeshed in a society with each other.

And if we're speaking of a body, then the extended self is those

interactions with this necessary and vital interactions with the rest of the world.

So the extended self then is the self that extends to other people to, to societies to other societies to the environment, the local environment, the global environment, the biosphere.

So then in that sense, then if our purpose is to achieve and maintain vitality,

Our purpose is to achieve, achieve and maintain vitality for that larger extended self that really goes all the way to the biosphere where all of life is in this together.

All of life is connected in one.

And and all of life is doing this thing, doing this thing of acting to achieve and maintain vitality.

And over eons of evolution, we get this amazing

world of life and whales and Sequoia trees and ecosystems and all these T trees talking to fungi in the ground and plants talking to each other and beads doing their thing with flowers and each other.

And I mean, it's just like amazing coordination and communication and cooperation happening between species and within a species and within a

all of ourselves.

So I would say that if we're going to create a better society or create new systems that lead to a better society, then the task will be to fulfill our intrinsic purpose, which in a way means to simply get with the program.

That is, get with the program of what all of life is doing around us.

Just align with what life is doing.

And then we will, you know, we'd be off to a good start if we can do that.

All right, so that's the purpose.

And then at the bottom of that slide, I just highlight the word wisdom because it is reasonable.

You know, we think of wise action as something that is, you know, widely beneficial and

action that is aware of the needs of others and is useful action.

But that is what we're talking about.

We're talking about

of of taking actions that help to fulfill our intrinsic purpose and really by definition i would say that would be wise actions so in that sense we're aiming at a wisdom society a society where wisdom is valued and discussed and sought after and you know and and hopefully one in which uh individuals and groups and others institutions that act

Okay, so I do ask the question there at the bottom, can wisdom be rigorously defined?

Now, often it's a term that is just generically applied to actions that some people feel are useful or appear to be useful.

But if we're going to build new societal systems and we're going to have some sense of,

fitness for these systems, and the systems are in some way supposed to help us to act with wisdom and to facilitate action with wisdom, then perhaps there is some way actually to rigorously define wisdom or to know when actions are wise.

And I would say then that leads us right into the concept of active inference.

Because

active inference, we might say that actions that reduce uncertainty and maintain, you know, reduce expected uncertainty about our thriving or survival or survival into the future, those are beneficial actions.

And then again, by definition, they're wise actions.

So there might be some way to actually talk about wisdom in the same sentence as fitness.


SPEAKER_02:
the two concepts two concepts concepts must be closely related okay john can i ask i have two things i wrote down so one was cognition and when we talk about multi-scale cognition especially with a computational or a modeling bent it's easy to get caught up with cognition being a really mechanical process but i liked how you brought it to wisdom

And so it's like, if we're gonna be a cognitive system or if that's a framework we're taking, are we gonna be calculators and just do zero through nine calculations or will there be wisdom in the system?

And that kind of brings me to the question, which is clarifying wisdom is a big opportunity, but also there are risks and uncertainties.

So here in 2021, looking forward potentially to some type of wisdom transformation,

what can we cling to and how can we follow wisdom?

Because it sounds like a great idea, but then how will we know it in the mist?


SPEAKER_00:
Right, right.

Okay, so I'll talk to your first point first.

Excellent.

So I want to emphasize that we're not talking about building a society of robotic, you know, linear thinking, logical thinking.

organisms you know that's not really what humans are anyway that's what no organisms are you know we every organism has uh you know some degree of complexity of of its of itself and uh humans are very complex and we'll talk about the complexity of human needs in a moment but this it's life is not all about logic

And it is partly about, you know, a good share of it is about heart and intuition and all the other emotion and all the other aspects that come to play in what it means to be human.

So I'll repeat something I had said earlier too, is, you know, if we are to build better societal systems, better societies, those would be societies that would help us

Help us be true to ourselves more, true to our hearts more, true to our deepest longings more.

So I'm certainly not talking about building a society of people doing logic or computational logic or something like that.

It's not at all what this is about.

This is about being more human, more ourselves, more capable of making wise decisions, right?


SPEAKER_02:
Yep.


SPEAKER_00:
And I think some of these ideas from over that have been developed, say in the last 10 years of science, ideas from complex systems science, ideas from cognitive science, ideas from active inference, ideas from evolutionary biology and some others, we're in a much better position today to be talking about how might we do this?

How might we build systems that actually recognize the full


SPEAKER_02:
human the full society the full the full interactions and then and then help provide guidance of how that how that might best be done right yeah just one quick point on that is people have talked about general systems theory and about how we could simulate or choose utilitarian outcomes or all these different ideas that have been percolating for truly thousands of years in many cultures

What's different?

Well, in your pocket, there's something that can simulate not the universe, but it can do calculations that complement human abilities in a really potentially beneficial way.

That's different.

It's on a continuum with other extended cognitive elements like books and communications, telecommunications, media, and things like that.

But we're in a computational and a conceptual phase that's totally novel.

And so we need to consider classical critiques like it can't be done, it won't be done amidst the truly ongoing changes.


SPEAKER_00:
That's right.

Exponentially expanding critiques.

capacities for computation.

But your point is very well taken.

Again, I do not mean that we're going to have computers deciding our every action.

That's not at all what I'm talking about.

I'm talking about becoming more human and using the tools that we have available to extend our computation and help us to understand better the complexities of the world around us.

Right, so this is humans taking advantage of all the tools they have to become more themselves and better and wiser and better decision-making, better decision-makers.

Okay, so that's what we're gonna cover today, this first part, and then we'll move on to part two.

All right, next slide.


SPEAKER_02:
All right, four.


SPEAKER_00:
So this is a slide on active inference.

And I just want to, again, for those who maybe are not too familiar with the concept, I want to give a kind of a brief overview.


SPEAKER_02:
Excellent.


SPEAKER_00:
Carl Friston, obviously, is one of the main forces behind this concept.

He's been working on it for well over a decade now.

There's a little image there on the left of the slide that I'll just say a few words about.

So we can talk about two components to the universe, the universe at large, and then some individual that is, in some sense, separate from the universe.

Right?

is something that is that can be demarcated from the rest of its background so for the moment we'll say there's we're going to draw a circle around the individual and then the rest of the world is going to be outside that circle so the rest of the universe has hidden states it has a you could say it has kind of a gym in a sense a generative model of how it works how it functions when it is when it has

is acted upon by an individual.

It responds in some way.

In a sense, it has a model to do that.

And the individual has a model of what the individual, how it understands the larger picture.

Now, obviously, the universe is bigger than a human mind.

So there is no way that a human mind is ever going to understand every little detail about the universe.

That's impossible.

So a human then, or really any individual, is faced with this problem of trying to act in a universe that is far more complex, far more complicated, and dangerous at times.

So how do you act under uncertainty?

That's the problem of humans and other organisms.

How do you make good decisions under uncertainty?

And that's certainly the problem for society too.

So, uh, a, uh, when we talk about separating the individual from the rest of the universe, we're talking statistically, we're talking about independence from the rest of the universe.

And in this line of thinking, uh, that independence is granted by what's called a Markov blanket.

So the individual knows its own beliefs or it has its own beliefs.

And it can choose actions and it can receive sensations from the world.

So it can act and it can observe the result of its actions.

and then the universe on the other half universe is impacted by actions and then changes in some way has some dynamics and then that leads to sensations for the individual and then the individual receives those sensations so we have kind of a circular pattern going on here where the uh the individual acts

say it this way, the individual receives sensations after some action, receives sensations from the universe.

And then it can do really one of two things.

It can alter its beliefs about the world.

Maybe the sensations tell the individual that it was wrong in some way.

So maybe one option then is for the individual to update its beliefs about the world.

That's new here.

Or it can take some kind of action.

to better fit its experience to how it understands the world.

So if I'm cold, if my sensation is being cold, my action might be to put on a coat so that I don't freeze to death.

I can bring the world, try to align the world with what I expect the world to, what I expect of myself, what I expect of my own condition, and how I expect the world to act.

So that's kind of the two options we have available.

We can update our understanding and beliefs about the world, and we can choose actions.

So that's really the gist of what that picture is.

And then over on the right-hand side, I have a few equations that sort of puts that into kind of a formulative way.

So the first one that was just

But the concept is that because I'm an individual and because I don't, I can't actually know what the generative process of the universe is.

I can only know my sensations and my actions.

I would like to reduce the surprise that appears.

Like I don't, you know, it's surprising to me if I'm cold and sick and hungry and

I don't want those kinds of surprises.

I want some certainty about me existing into the future.

But the trouble is, I don't know what the world's model is.

So I have to essentially create my own version of it.

That's the density Q in this model.

I'm going to create my best guess as to how the universe works.

And the universe has the density P in this equation.

And I'm going to do something actually that is not really common in data science.

So if any data scientists are listening, you ought to be probably very familiar with these concepts already.

This is a variational inference.

So it's a technique widely used in data science to

solve problems and that's the central idea is you have some complicated density P and you don't really know how to deal with it.

So you instead choose a much simpler density Q that is better behaved and then you work with that.

And the whole idea is if you bring Q closer and closer to P,

then you'll be closer and closer to actually having a model, a real model of the world.

So just in that term for the elbow, the evidence lower bound, it's called in data science, there's a KL term, a KL divergence term, and that just simply means that term will go to zero as P and Q come closer.

And the other term there, log P,

Uh, that is really, uh, just, uh, the negative of that is called surprise.

So, uh, um, you, the agent, uh, would like to reduce the surprise that it, it, uh, uh, recognizes experiences and, uh, and doing, and one way to do that is to, uh, is to also bring the,

the densities P and Q closer.

So you get a good model of the universe and you act in a way that is consistent with your understanding of the universe and you update your beliefs as necessary to have a better model of the universe.

And if you do all of that, your surprise about how the universe acts and your surprise about maintaining yourself into the future will be reduced.

So that functional is called a free energy functional, and the whole concept in active inference is to use this action updating, observing from the universe what the sensations are, and then going in a circle and updating an action, and updating an action, updating an action observation, updating an action observation.

The idea is to reduce dysfunctional free energy.

And that, Friston would say, claims that this is what all organisms are doing.

This is what life is doing.

And if this doing so leads to really all the structural diversity that we

in our universe the ecologies and ecosystems and organisms and cooperating cells within a human body and all of that is has become what it has become through a process through this free energy minimization process so in a sense if we wanted to somehow talk rigorously about wisdom

It would be in some sense, at least from this perspective, it would be wise actions and learning activities and explorations.

Wisdom is the kind of equivalent to reducing expected free energy.

I just want to make just a few other notes.

So what we really want to do is reduce expected free energy.

Like what will happen, you know, a tiger is running at me, I could run, I could fight, I could jump on a car, I could jump in a car, I could do all these things.

I have these options, paths, these paths I could take, these decisions I could take.

Which of them is going to be best for me in the long run?

Or in the short run.

And so that requires expectations of free energy over possible decisions in the future.

And that becomes quite complicated.

None of that is really in this slide, but I do want to realize that that's there.


SPEAKER_02:
John, I wanna lock in two really key points that you touched on here and then ask a question.

So the first thing you said on this slide is active inference is about the reduction of uncertainty.

So that's in direct contrast with the human as an economic maximizer or an optimizer of the reward, or that we're trying to do some sort of optimization, maximization on an outcome.

It's a process based reduction of uncertainty that Active Inference highlights.

And so, of course, you're highlighting the outcomes that we want to see.

Those are our values, our preferences and our predictions, we hope.

But we're going about it with a process based and uncertainty reduction based lens rather than simply like numbers going to go up.

We got to get there.

So that's the richness.

of just, if nothing else, all the critiques of active environments aside, to focus on the process and the reduction of uncertainty is really powerful.

And the second lock-in is you immediately went from the reduction of uncertainty to collective behavior.

And it's like, there's things that the brain knows that a neuron doesn't, like how to speak English.

And there's things the colony knows and does that the ant nest mate doesn't.

So part of this is about realizing, well, there's things surely society knows with all of our diversity and all of our different skills that an individual doesn't.

So what does it look like to take that seriously that the cognitive systems are not just nested internally?

Like, well, the brain, the brain region, the neural circuit, the neuron, the organelle.

Yeah, you can go down, but you can go out and it's not just a cope.

And so what that looks like is a really important point.

So the two things there, reduction of uncertainty with active inference and multi-scale cognitive systems, and it's really important points.

Good, or can I ask the question?


SPEAKER_00:
No, excellent, excellent.

Yeah, go ahead.


SPEAKER_02:
I'm just trying to catch up because you say a lot of awesome points in each of these breakdowns.

And the question is really...

What kinds, this is on the Jamboard, what kinds of social processes or data are promising for active inference modeling?

Let's just say now, maybe in the future we'll license other deployments, but right now, like what kind of data would you be curious to collect or find out about?

We may talk about it later in the economic or social context, but what kind of data types are we thinking about making active inference models of?


SPEAKER_00:
yeah okay so to answer that question I'm going to ask that question in about two more slides so I'm going to ask that very question to you and to the viewers out there but I can give you just one example okay we can come back to it but go for an example yeah I'll give one example because I also want to emphasize something else that you also

that if we're talking about expected uncertainty that implies that we are anticipatory so I just want to underline that every organism is anticipatory every organism is doing this reducing free energy and you know from this view and that requires anticipation of what the future will be and so

So anticipation, or you might call it forecasting, forecasting is central to our well-being, our continued existence.

I'm forecasting that if I see a tiger coming towards me, that I'm going to be its lunch if I don't do something.

So if we don't think clearly about what's going to happen next,

then cognition is there is no hardly any cognition.


SPEAKER_02:
yeah just one one short comment on that is anticipation and anticipatory systems has been discussed in many other contexts like cybernetics and active inference helps us walk from this very simple beginning you said okay there's an inside and outside if you don't have that you know need to think a little bit more clearly about the system or something like that but we can start with the simplest and then we can build it out to the sophisticated affective inference with the affective charge and all these other modern models

But we're starting with this loop, which is why we always come back to these kinds of figures and why it's really important that you're making it at this level.


SPEAKER_00:
Right.

Good.

So just so we can ask the question, all right, if the situation is, you know, tell me, like, what kinds of things would us want to be good at forecasting?

Actually, I'll ask this question in a few slides so we don't have to go too far into it now, but let's just take, say, governance or leaders, political leaders.

If a political leader is good at understanding what's coming next, what the future is going to be, then great.

Then the political leader can say, hey, we better do something because

if we don't this thing is going to happen right but as a society today do we actually remember those predictions do we in any way like you know score accuracy of people's predictions or the predictions of science or the predictions of organizations is there like how does society today remember remember that predictions have been made and now the future is has

evolved and come about and how, who was good at, who was good at anticipating the future, who, who excels, uh, uh, what, what, what, what organization or political group or whatever, who who's been really good at understanding what's going to come next.

Right.

So that's just, I'll just leave that open question because it gets the mind working out that you can think of all kinds of ways that we don't do a good job of

of remembering and anticipating today.


SPEAKER_02:
just to ask a question from the chat um someone wrote does john use active inference mathematical framework in his work for merely descriptive purposes so potentially as opposed to generative or like real-time decision making so where does where are you right now or where do you want to be with uh respect to using active inference to describe simulate make decision support etc right right yeah a good question so uh and maybe maybe the


SPEAKER_00:
So the series has just been published.

The series proposes a R&D program that society could undertake.

And it is conceptual at the moment.

The whole program is conceptual.

It's not been funded.

I mean, you're

In a sense, you're looking at it.

This is it.

It's the three papers and our conversation and whatever other people have to add to this.

This is where we're at.

We're obviously focusing or I'm focusing now on the big picture conceptual ideas because that has to happen before you actually get into the nuts and bolts.

How do we use this?

But I would guess and I would expect that if this project moves forward, then at some point we'll be talking about the numerous ways that society uses information and how it remembers and how it anticipates and what models might be used for different kinds of anticipation and, you know, how do the nuts and bolts of

And I hope we get a chance to go there.

That would be fantastic.


SPEAKER_02:
We'll lay it out as likely, and then we'll make it happen.


SPEAKER_00:
Okay.


SPEAKER_02:
There we go.


SPEAKER_00:
All right.

So that's that slide.

Let's go on to the next.


SPEAKER_02:
Sounds good.

Five.


SPEAKER_00:
Yeah.

And maybe two before we move off the last slide.

I do want to say that Active Inference has this wonderful part of it that I'm very attracted to,

And that is that it provides a way for an organism acting in its environment to play it by ear, to learn as it goes, to have a process of learning and a goal for learning and action that can evolve over time, right?

So if we were going to program an active inference robot, we would not be

do that, five points.

Now, find a way to act in the world where you maximize the number of points you can get.

It's not really like that.

And the world is, in a real setting, the world is far too complex for someone to pre-program how many points you get for certain activities or reaching certain goals, right?

So an intelligent agent has to be able to alter its understanding of the world

and its goals at the same time.

And we'll talk about this again.

But to balance exploitation of what it knows already, to use what it knows about the current situation, and exploration, jumping into new

new unknowns, considering new proposals, considering new rearrangements.

So active inference and really the structural development and evolution of all of life and ecosystems and cells and communications between organisms and all of that is kind of built on this balance between exploitation and exploration.

um you could even think of that in terms of like in modern day society to a degree you could even think of it in terms of liberal political versus conservative political in their best sense that is you know conservative political might be more more interested in relying on tradition and exploiting the current knowledge and perhaps a liberal might be more interested in exploring new ideas and

and taking leaps into the unknown to learn something new and do something better, to improve a process, to change a process.

So decision making is very much a balance between those two exploitation, exploration, and active inference provides a mechanism by which that can occur quite naturally.

and i won't even go into detail to say that an action model and reducing uncertainty on that helps you act in unknown unknowns i think it's something exactly unknown unknowns that's correct yeah of which there are plenty all right now slide five uh uh this is i guess this is following up on active inference just a bit um and i think we've talked on most of these things uh the um

Yeah, I think we have.

Great.

The whole point is to resolve expected uncertainty.

Great.

Okay, good.

Next slide.

Six.

All right.

I just want to touch just a few ideas on cooperation and communication.

Actually, cooperation and communication go hand in hand.

They may have even evolved together possibly.

So cooperation really is almost the rule in our world.

Life cooperates in so many ways, so many ways.

And the more we study it, the more we realize how deep the cooperation is within a species, between species, between trees and fungus, within ecosystems, between ecosystems.

it's just cooperation is everywhere and as i said last in our last show if you want evidence of it that is if you want mind-blowing evidence of cooperation to just think of your own body the trillion or so cells that are cooperating to for you to be what you are right so um it's a cooperation exists everywhere and it is

nearly impossible without communication.

Like, you cannot cooperate with someone if you don't communicate.

And the richer the communication, at least potentially, the richer the cooperation.

And obviously, by cooperation, I mean, by communication, I mean honest communication.

Dishonest communication is hardly communication, right?

So we're talking

Um, so it's interesting though, that, you know, like to take your body, for example, you have all these trillion cells and they don't have to cooperate.

I mean, there's, you know, they can not cooperate and sometimes they don't cooperate with each other and they can act independently to some degree.

Right.

So there's always throughout the universe, there's this tension between, uh, what cooperation provides

and what the individual you know what the individual might want to how it might want to behave if it were just left to its own to its own right so why would anything cooperate and and the kind of the big picture answered that question is because it reduces expected uncertainty it's again it reduces free energy so

by cooperation, an organism can assure itself of survival.

It can make its survival easier.

It can make communication easier.

It can, you know, have all these benefits, right?

So nevertheless, every given moment is this, there's this tenuous balance between, you know, do I continue to cooperate in this sphere or not?

And who is, and at what,

to what extent do I cooperate?

Do I cooperate within my family and or in my community and or in my society and or between societies?

At what level am I interested in cooperating?

And the

know the answer the general answer that question is i am interested in cooperating at every level in which uncertain my uncertainty is reduced my my vitality is ensured my uncertainty is reduced right so across the layers across scales but we do see this examples of when cooperation fails and one example that i like to

transform cells start to not cooperate with their milieu, with their tissues, with their environment.

So my question for listeners is, so we have an idea of what cooperation means, and then what is the opposite of cooperation?

Like you might think,

Okay.

Well, the opposite of cooperation is selfishness.

And I would, I would suggest, you know, maybe in certain circumstances that seems pretty clear, but in a more general sense, maybe that's not the opposite of cooperation, right?

Maybe, maybe there's almost always cooperation and what changes is the extent of self of the agent or, you know, the organism that's that, that has taken the action.

For example,

Cancer cells cooperate with, you know, they cooperate with each other at least.

So, um, and they, and they might cooperate within their, you know, within their very small tumor milieu.

There's a lot of communication that happens between cancer cells.

Once a cancer forms, there's tremendous communication that goes on between cancer cells.

So maybe it's not, maybe it's not so useful for us to think of cooperation versus selfishness.

but rather cooperation as a scale, scales of cooperation in extent.

Like, am I cooperating with my immediate family, or am I cooperating with societies that are far-flung and halfway across the world, right?

To the degree that we understand ourself

to be extended, we are cooperating with ourself.

I mean, you have to understand that, right?

If I understand that I am part of this environment, this ecology, then any actions I take to benefit the ecology are actions that I take to benefit myself, right?

So if my sense of self is extended out to the world,

to the, or to the degree that it's extended up to the world.

I am interested in cooperating with myself to better myself, to reduce my overall uncertainty.

Right?

So cancer perhaps is, it's not really a matter of being selfish, perhaps like I can't, you know, people say cancers are really selfish.

They're just gonna, they're just gonna, um, um, you know, only pay attention to what's good for them.

Yeah, but they're cooperating.

They're cooperating with a smaller group.

And because they're cooperating with a smaller group and because their extent of self is reduced, their capacity for cognition is reduced.

And, you know, we're talking, we're just kind of anthropomorphic here, but, you know, they would have, a small tumor would have a more difficult time understanding the long-term effects, their long-term effects, because their cognitive apparatus

is to a small set of cells versus the human body, which has the full cooperation of the brain and the feet and the hands and the understanding and the capacity to use your mouth to ask others what's going to happen next, right?

So the more you extend into the world and are cooperating with the world, the larger your cognitive capacity, the larger your problem-solving capacity, and the better you will be at

understanding in the long term, you know, the outcomes of your actions and how that's going to affect your own, you know, how it's going to affect you as an individual and you as an extended self.

Okay.

So I got a little off there, but you know, I'm just saying cooperation is everywhere and it's all about communication and shared computational capacity and shared decision-making the

potential for more

cognitive capacity and better decision-making.


SPEAKER_02:
Great.

The only point I'd make here as a ant researcher and have thought about conflict and cooperation across scales is that it's really a story we're telling about a certain outcome.

Like when the white blood cell eats a cancer cell, is that altruism at the higher level?

Is it a conflict at the lower level?

So it's a scale dependent and it's often a perspectival narrative that we're telling about what cooperation is.

And it's just like yin and yang.

There's a compliment between what we call cooperation and communication.

They're like the good guy and the bad guy.

They come into existence when we have fitness and free energy to dissipate.

So we need a story that allows us to act

in that gray zone instead of um getting fatalistic about competition or getting utopian about cooperation because this is not going to be necessarily a smooth and lovey-dovey ride with cooperation nor is it in the body so it's like a very nice nuanced way and that's why we fall back to active inference rather than an ism or a specific metaphor of choice like the selfish gene


SPEAKER_00:
Right, right.

Excellent.

Yeah.

And just to just to underline that this project is not about asking people to behave like super altruistically or something like that, or to cooperate, you know, beyond what would be natural, that that would never work, it would fail, it would fail, because that's not what that's not how it works.

That's not how what life is doing.

That's not how life is working.

So you know, we just really just need to be be

set up our systems, set up our processes, set up our societal decision making, you know, ways we go about making decisions, and just align ourselves with what we actually are and what life is actually doing.

And that means that there is a continual conflict between cooperation and

you know, not cooperation, between kind of an individualism and a more cooperative stance.

That's just like there's an ongoing conflict between exploitation and exploration, between, you know, conservative and liberal, between old information, the value of old information and the value of new information.

This is a, all of this is a dance, it's a dynamic dance, right?

So, but there is a sweet

place to hover a sphere to hover in where you're balancing old and new exploitation exploration conservative liberal you're balancing them and because you're on that in that sweet spot in that critical area you're able to do about the best that any organism could do

and the magnificence of life is the proof of that.


SPEAKER_02:
Awesome.

Through seven, speaking of life.


SPEAKER_00:
Right.

So in our last talk, I had mentioned that complexity is, you can think of it, at least in a certain way, you can think of it as problem-solving capacity.

Organisms complexify, environments complexify, ecologies complexify in order to solve ever more difficult, challenging problems.

So it is not true that complexity is just a path to chaos and failure.

Systems do fail.

I mean, obviously that does happen.

There's complex systems that can fail.

So humans are complex.

Of all the organisms on the planet, we're pretty complex.

We have complex brains.

We have complex cognitive processes.

We think about what might happen in 1,000 years, and we're concerned about what might happen in 1,000 years.

That's enormously complex, say, compared to a bacteria that doesn't have a central nervous system.

So because we're complex,

organisms in general, that the more complex an organism is, the more complex its needs.

The more feelers it has out in the universe, the more extended it is into the universe in a sense.

And that is certainly true for humans.

And this table has some needs according to Maslow.

And I just want to mention these as an example, not that these are the needs we should focus on, but just as an example of

I think he has maybe nine or eight or nine of there, I think.

But affection, we want to be loved and we want to love both.

We want to share friendships.

It makes us happy to do that.

We want to be creative.

We want to create things.

We want to build skills.

We want to have freedom to associate things.

with whom we want to associate and freedom to move about and look around and poke around and look under things we we you know we want to participate we want to cooperate we we want to understand we want to learn learning is fun you know hopefully learning is fun we we want the rest when we're tired we want to get some exercise we want to move about you know we need to relax sometimes like all these things

uh, this is, these are, if we can call these core human needs, these speak to something that I've, I think briefly mentioned the last, uh, talk, which, which is called essential variables.

So if an organism is, if its purpose, intrinsic purpose is to maintain vitality into the future, well, you know, what, what are those variables?

that are important in maintaining vitality you know like you can think you can think of a few important things right off the top of the bat like fresh water to drink you know clean air to breathe the food to shelter you know like you could start to think of what some of these essential variables might be but i would like to suggest that some of these core human needs somehow fit into the concept of essential variables humans need to be humans need affection you we will be sick

if we don't have affection, right?

We will be sick if we don't have freedom.

We will be ill.

And we won't be able to, and we won't be able to solve, we won't be able to be good problem solvers in our environment if we're hampered by lack of meeting essential variables.

We'll be worse.

So the point of all that is when we think about

a complex organism like a human, we can think about complex needs and then we can think about, okay, so now it's starting to become clear when we're reducing uncertainty, we're reducing uncertainty about these essential variables, which might touch on things like the eight or so, nine core needs that I'm listing.

So I want to, for example, I want to have, I don't want to be uncertain that

I will be loved in the future or that I'll have food to eat or that I'll be able to move about freely.

I would like to be fairly certain that I'm going to have those freedoms.

I'm going to have these needs met.

Again, then we're not talking about some big computational calculator thing for this project.

This is about heart and soul.

being a human, even more human than society allows us to be today.

Like, you know, society is not set up.

Our society is not set up to focus on providing for these complex human needs, right?

I mean, we have poverty.

We have billions of people in poverty in the world.

And that's already, like, all kinds of needs are not met because someone doesn't have the, you know, the...

financial capacity to do what they need to do, right?

So we can, there's one last thing on this slide, this little phrase that I like to use is the solving problems that matter, right?

So society might solve all kinds of problems.

For example, if I work for a manufacturer that is producing some like, you know, let's say,

some commercial relatively useless product that people are buying because commercialism is pushed.

Maybe I'm solving the immediate problem of making an income so that I can pay my rent.

But beyond that, am I solving problems that matter?

I don't have a good example.

Maybe someone else does.

something useless there was a book there was a book there was a book about that a while ago and they had a phrase but i forget exactly what his phrase was well i don't know if it was a family-friendly phrase but i think i know it but yeah i don't think it was i hesitate to say it because it wasn't family friendly


SPEAKER_02:
You know, it's like, you know, whose team, our team, like that kind of a call and response, like which problems, the ones that matter.

I mean, then what does it mean to matter?

Well, that's our preferences and our affordances.

And then as far as cases where the work or the problem doesn't matter, there's times where the person might think that the problem matters.

But when you pull back, it's actually a nonlinear response where even if it does matter, the issue that they're concerned about,

that their effort may not be the most efficacious.

And this isn't going to go back to another optimization.

You must be engaged in the most efficacious because we're actually putting space for play and identity and participation, understanding all these attributes that aren't just some simple cybernetic like action selection, but it's really important to keep this as our guiding light.

It's the problems.

And those are the salient ones, the ones that matter, but we need to be informed by our values.


SPEAKER_00:
Yeah.

And obviously we're talking high level here.

We're,

we're trying to give a context for this whole thing of what could society be and how would we go about measuring fitness and w you know, what is this society supposed to accomplish and for whom?

And then we have to talk about the, you know, these, these high level concepts because they can be guides for us, right?

So the, just the phrase solving problems that matter, it can be a useful guide because it reminds us, Oh yeah, what, what matters and what am I doing with my life and what are we doing in society with our lives?

Are we doing things, are we solving problems that matter?

And obviously there's a whole bunch of enormous problems that we're not solving, right?

Like climate change and other things.

If society was solving problems that matter, there would be like enormous armies of biologists and other people, ecologists and field workers and all kinds of people focusing on the problems that matter most.

for happiness and survival.

And currently in today's world, you know, that is heating up to be climate change and biodiversity loss and, you know, ecological destruction and pollution and groundwater depletion and like all the things that were pushed, you know, all the damage we've done to our world.

Certainly cleaning those problems up ought to be

among the problems that matter.

Okay, so there we go.

I think one last thing on this slide.

So over in the bottom right, I bring the topic of culture in, and I just want to just say a word about culture from an active inference viewpoint.

So, you know, at its best, culture is a remembering of what is important.

to teach not only to teach new people, to teach new young adults as they mature what's important, but also to offload some of the computational burden that individuals would otherwise face.

So if I have to figure out everything for myself from scratch as an organizer,

For me, if my peers point me in the right direction, give me some indication of what's dangerous, what's not dangerous, what's important, what's not important, give me some guidance, I can learn so much faster if I have some good guidance.

Also, if I can just rely on culture to like, okay, my culture does this thing,

And I'm not going to maybe even think about it too deeply because I'm, you know, like if my culture is good, it's maybe reflecting in some capacity this importance of putting attention on those things that matter.

So now we've now talked about two important things here, actually, culture and how culture relates to to reduction of uncertainty overall, and then also attention and the role of culture in directing attention.

So those are themes that we'll be coming back on.

Nice.

So attention and essential variables, you know, like those go together, right?

If we're not paying attention to essential variables, then our whole free energy minimization thing is not functioning correctly, right?

Because we have to put attention on those things that are important.

Okay.

All right.

Next.

All right.

So now we get to the slide where I get to ask you and any listeners, like, what does this mean practically?

So we've talked about all these high level concepts.

We've given some context for, you know, for who we are and what we might need and what a societal system is supposed to do.

And those were all fairly high level discussions.

And now maybe it's time just to talk a little bit about what that might actually mean in a practical sense.

So the title of the slide is Practical Indications.

But down at the bottom, I have also known as, how do you solve problems?

Because the two are the same thing.

This is the question.

How do we solve?

How do we solve problems?

How do we focus on, if we're good at solving problems, how do we do it?

And obviously, if we're going to build new societal systems, we want to build societal systems that help us, that facilitate our problem-solving capacity, facilitate our capacity to reduce uncertainty, expected uncertainty, right?

So I'm just going to list some things, and maybe on the first read of this, we can just acknowledge, like, okay, yeah, that's how we solve problems.

Number one there, we gather data.

We sense our world, you know, obviously, right?

That's how an organism solves a problem and even knows that there's a problem to solve for that matter.

And we remember, we remember what we did maybe last week or last year.

We remember how we solved something before.

We remember that this situation is dangerous and we might want to avoid it in the future.

So we remember, remember, we anticipate or make forecasts.

And we've already talked about the importance of anticipation for cognition in any organism and cooperate.

We cooperate with those around us.

We have a,

problem to solve and we get some help.

Maybe we solve it together.

We work together.

We build a house together.

We build a jumbo jet together.

We do all these things together.

We farm together.

So cooperation is one way to solve a problem.

And then what does cooperation entail?

Well, it requires that we maybe as a group, we reward

about cooperation and it's pretty, you know, there's some really good ideas, pretty clear ideas, basic ideas of when, how do you actually facilitate cooperation and what makes cooperation go down the toilet, right?

So if your communication really helps cooperation, rewarding pro-social behavior, transparency helps cooperation, fairness helps cooperation, like all these, we know all these things, right?

from common experiences in life and also from studies in game theory and other fields.

So solve a problem, we cooperate, we communicate, we direct attention.

There's that word attention again.

We direct our attention to those things that matter.

We learn from our actions and observations.

So we update our models of things when we realize like, oh no, I guess the world doesn't work that way.

I should, I should learn something, but the world is a little more, it works differently than I was anticipating or had thought before.

Uh, and then we act to reduce expected uncertainty.

We experiment, we, we, we have goal directed activities or actions where we try to, that's the exploitation aspect.

And then we also have the exploration aspect action for epistemic gain.

And again, then we have this exploration versus exploitation trade off.

So I'm just saying what I think everyone already understands.

I'm just making a list here.

But now the question is, okay, fine, so that's how we solve problems.

How do each of these play out in a societal system setting?

So, you know, I think if we wanted to, we won't because we don't have time, but I think if we wanted to, we could list like 500 ways any of these play out or maybe should play out or could play out.

in a healthy society, a society that's good at solving problems.

I had already mentioned one earlier.

So let's just say on the topic of anticipation, wouldn't it be reasonable to somehow remember and pay attention to who is good at anticipating the future?

certain political figure or, you know, certain organization is, is that turns out to have a really good track record of accurately predicting what's going to happen next, well, then maybe we want to pay attention to them and pay more attention to them to then to others who have a terrible track record of, of predicting what's going to happen next, you know, like if a politician says, Oh, if you do this, if you do a then B is going to happen.

Well, you know, if

By and large, those kinds of predictions are wrong, then, you know, politicians probably not worth much.

But not just in politics.

Obviously, we anticipate and, like, for example, that's what science does.

Science is, you know, awash with trying to figure out how the world works and what's going to happen next.

and uh so so that's another area that we could you know a healthy society might really support the scientific uh you know the scientific endeavor and pay attention to what scientists are saying like for example with climate change and other things you know if the whole scientific world is saying hey this is serious you gotta pay you gotta do something about it well then maybe a healthy society would actually do something about it right um honesty and honesty i'm just picking out the

for numerous hours about how any of these might play out in a real setting, right?

Honesty, so look at the amount of dishonest information or manipulated information that is flowing around us today in this world.

You know, why is that?

I mean, obviously a healthy society would want to share honest and valid information,

Let's call it quality information.

Good models are built on quality information.

So here's a question.

Why in our world, why is there so much disinformation?

And I would suggest that at least some of it is due to the fact that individuals and organizations, corporations are

fantastically rewarded for putting out dishonest information, right?

I mean, just think of a thief.

I can call you up in a phone scam and if I can convince you that I'm your bank and I need your account number, then I can have enormous rewards for being dastardly dishonest to you.

But, but it's true.

I mean, maybe that's an extreme example, but it's true in just ordinary examples of business and life that one can be rewarded greatly or being fairly dishonest or, you know, putting out something less than quality information.

And then you gotta, then you gotta ask, okay, well then if, if then, you know, like we don't want, society doesn't want to reward antisocial anti,

anti-transparent, anti-honest behavior?

How would a society reward pro-social, honest behavior?

Maybe a society could become more transparent.

So transparency, obviously, would be a part of this.

But I'm sort of honing in.

I don't know if you can tell, but I'm sort of honing in just on this little question.

about how do we reward behaviors in this world as a society?

And then that suddenly brings up the question of how does an economic system work and how do we view money and how do we view income and how do we use money and income in our lives?

And is there some way that we could reinvent an economy and reinvent money so that

whatever we need to reinvent so that we're actually day to day, moment to moment, we're rewarding cooperative pro-social behavior and honest behavior.

So like, how do we do that?

Now I have some ideas on how to do that, but that's in the part three of the paper.

So we'll get to them later.

So I don't want to go much further on this, but I'm just suggesting that

that we could spend, you know, each of these could raise a hundred ideas of how to, what we could do in a healthier society to improve our capacity for group problem solving.


SPEAKER_02:
Nice points.

Good for nine?


SPEAKER_00:
Yeah, I always think I am, but hold on one second.

On the right-hand side of slide eight are a few other ideas.

So, you know, obviously we've done

measuring the fitness of them so um you know how do we how do that's a that's also a general answer to this question of how do we build a society that is more fit well we actually measure things that are important and we score them and we share that information widely so we know how we're doing so we know so we can evaluate either our systems or our organizations or our institutions or society at large or those kinds of things so metrics are important

I already mentioned science and critical thinking are important.

So that touches on the educational system, for example.

A healthy educational system would really value critical thinking and would train individuals to be critical thinkers at an early age, I would think.

And then obviously then removing the barriers to cooperation.

This society has enormous barriers to cooperation.

I might want to

Here's just one example out of what could be a million examples.

Say that I wanted to use my life's energy, my work time, my 40 hours of work a week to make the world a better place.

I want to jump in and I want to, I don't know, let's say I want to teach kids, little children.

Maybe I want to be a good teacher.

Well, that's great.

Fantastic.

But if I do that, I have to pay a financial penalty.

I could become a banker instead.

So suppose those are my two choices.

I could become a banker or a finance person or something, or I could become a teacher.

Well, society is going to reward me greatly for being a banker or a finance person.

And it's going to not reward me very well for being a teacher.

I might want to cooperate.

I might want to work for the betterment of humankind.

But if I do, there's a good chance I'm going to be relatively poor.

You know, like I pay a heavy price for that.

And that's just a barrier to cooperation.

We should design systems so that cooperation becomes the default, easy, no, like duh, duh, do it this way because it's good for everyone.

It's good for you.

And

Sure, you want to teach?

Well, great.

Come on in.

Here's opportunities for you to teach, and you're not going to pay a penalty for becoming a teacher.

This is going to be easy.

If you want to be a teacher and help young children learn better, great.

Here's wonderful opportunities, and you're not going to have to pay a penalty for doing that.

We're going to actually just the opposite.

We're going to reward you for doing that.

Okay, now we're done with slide nine or slide eight.


SPEAKER_02:
That was good tonight.


SPEAKER_00:
OK.

So the only thing I really want to say about this slide is that this concept of the societal systems as a cognitive architecture, probably somewhere in the literature, there's something talking about that in some sense.

But I think maybe, I don't know if it's as kind of like pointed as I'm making it in this series.

And there and there really is no name for what is what is the name for the set of societal systems that helps the society that facilitates societal cognition?

What is the name of that?

And there isn't a name, you know, it's it's not an economic system.

And it's not a governance system, because that's just those are just some systems that are that have their own connotations.

So what is the name of this whole set of integrated systems that helps society to think?

Well, there is no name.

I mean, there is no formal name.

And so you can't look at if you're going to search in the literature on this topic, there's no there's no term to search for.

And so I thought maybe it'd be useful if I try to suggest some terms at least.

And I suggest the term societal cognitive architecture for the general the general idea that societal systems are a cognitive architecture for society.

But then for the more specific

developing de novo systems to be good at facilitating societal cognition, I suggest the term SAILS, Societal Active Inference and Learning Systems.

I mean, maybe there's some other better term, I don't know, but I threw together this one.

So it's SAILS that I'm interested in developing, new designs of societal systems that

facilitating societal cognition.

So, you know, if one of these terms catch on, maybe then in the future we'll be able to, if we're interested in the topic, we can actually do a search on Google and we'll find, you know, a hundred papers or a thousand papers on some of these topics.


SPEAKER_02:
Well, just one quick note on that.

It points to the need for improved cognitive architecture, such as knowledge management tools that help us collaborate and find information semantically, like information is for our experience, because you're right, it is fragmented and therefore unproductive across truly different disciplines and different jargons, different languages as well.

Unscanned documents, things that are just only on someone's notepad, just it's all over the place.


SPEAKER_00:
Right, and sometimes a thing doesn't really exist until you name it, and then it sort of exists for the larger, it can exist for the larger society.

So I'm naming this because maybe if we name it, we can talk about it, you know.

Yes.

The other problem there is like when I go to, it would be much easier for me to just throw out a term like cognitive social, cognitive societal architecture.

And if people understood that term, then I wouldn't have to spend a half hour


SPEAKER_02:
to explain what it is that i'm talking about right so terms terms can help if we have a shared understanding of what their meaning is what what is not sales because it's a you know what is what's not part of the function of the body how do we differentiate what is apart from that instead of this just being the one-to-one wrapper around economics governance legal etc etc


SPEAKER_00:
Right, right, right.

Good point.

And I really my, my, my use of the term sales, I'm suggesting it for use, really in this de novo design, you know, process of creating new systems.

So quite true, the the, you know, the cognitive, the concepts of cognition that we've been talking about, they are universal,

So it is true that we're kind of focusing on just sales as a term for the kind of R&D project, R&D projects to move forward that might look at the de novo designs of new systems.


SPEAKER_02:
Just the pun, traveling salesperson.

It's a problem.

You know, it's a hard problem, actually.


SPEAKER_00:
The traveling salesperson problem.


SPEAKER_02:
Yes, it is.


SPEAKER_00:
All right.

So with that, we are ready to move on to the actual talk.


SPEAKER_02:
Cool.

Drum roll, please.


SPEAKER_00:
Drum roll.


SPEAKER_02:
Awesome.

The second part, you know, this is a different media.

We're kind of spilling above and beyond what you've wrote in the papers because the three papers are the version of reference.

That's where people will cite.

But actually in this increasingly digitized and citable world,

Perhaps the things that you're sharing with us, as well as even the anonymous content that people produce on a jam board or live chat, like this all becomes part of how we produce our uncertainty and act.


SPEAKER_00:
Yeah.

Yeah.

And, and hopefully it becomes part of the record and part of the useful record for, for moving forward on some of these concepts.

Okay, so part one was all about worldview, there was, you know, high level discussions, high level topics about what creates worldview, and how what kind of worldview would be useful in the setting for developing new systems.

And then now we're moving on to the more nuts and bolts of things a little bit more in the sense of why are we even motivated to transform and, and

we do want to develop new systems what kind of strategy you know what like it's it's not enough just to come up with some great design it has to be viable in the sense that it can be implemented there has to be some way to actually use these ideas actually live these ideas and if there's not then we're sort of wasting our time so strategy is

R&D program.

So yeah, so I'm going to be in part two, I talk about really, I try to argue a given narrative in part two, that I try to argue that transformation is prudent, given the risks we face, attractive given its potential benefits, and achievable, given the current political, financial and social constraints.

So that's what I hope to accomplish in this paper.

And that's what I hope to accomplish in this

this talk too.

All right.

So on the question of motivation, like why transform?

We touched on some of these ideas in our first talk.

But I would just like to point out that we face a host of extremely difficult problems, climate change being one of them.

Climate change, biodiversity loss, groundwater depletion, soils depletion,

poverty, financial uncertainty.

In that sense, debt might play into that role.

If you make a list of all the very serious problems that humanity faces, it's kind of a long list.

Migration, and then one problem causes another.

So climate change is certainly likely

almost certainly will increase the number of refugees trying to cross borders, people living without homes that are fleeing areas that don't have enough water or are not livable or things like that.

So one problem causes the other, and what everyone is fearful of happening is that you have this collection of 10 or 20 really serious problems, and then something happens to flare one of them up

And then suddenly that problem, you know, transfers to other problems.

And then you have, uh, just one, you know, like everything's connected.

So if one part of our global society gives sway, it could be that, uh, everything starts to kind of fall apart.

So, uh, there is a fear of that and there is a need to address these problems independently.

And then also in a holistic sense.

And I would like to emphasize that these problems we face are, in a sense, symptoms, not really problems in and of themselves.

They're symptoms of a failure of society up to today, a failure to address the needs of the society, a failure to reduce uncertainty, a failure to do exactly what we were talking about in the previous part of this talk.

Right, so climate change is because we fail to take action.

We've known about climate change for 60 years, I don't know.

I mean, like it's been in the scientific world, like in a major way, major agreement on the implications and the basic processes and what it means to society.

That's been talked about, there was, you know,

the scientific world was on this 30 years ago and talking about it and writing papers and having, you know, so, so we didn't, society didn't listen and it didn't.

And I would say it didn't listen for a reason because if it had listened to those warnings, it society would have had to have changed.

And there are elements of society that are doing well.

and are maybe not so interested in changing behaviors and especially changing power distributions, right?

So the people that, the powers that more or less guide society were not interested in dealing with our serious problems because they have gotten worse over the last 50 years or whatever.

These problems have amplified.

If you don't solve a problem, it tends to fester and get larger.

That's exactly what's happened.

Now we're at the period of not only will climate change, you know, is climate change going to affect the GDP?

That's the yes.

Or if not millions or billions of people, it's life and death for our species.

We have to deal with this in some kind of bold way or we won't have children on this planet in, you know, whatever, in 50 years, 100 years, 200 years.

Humans won't be a thing.

So that's how I say that because that's how badly society has failed us.

We are at the brink of falling off a cliff.

Maybe we already fell off a cliff and we just don't quite realize it yet.

What kind of healthy organism puts itself and commits suicide?

What healthy system commits suicide?

None, really.


SPEAKER_02:
Only the phoenix.


SPEAKER_00:
Yeah, only the phoenix, yeah.

And, you know, maybe it worked out for that one okay.

It sort of rose, I guess, and maybe we'll do the same.

But, you know, my point is that the serious problems we face are all symptoms of our lack of cognitive capacity at the societal level.

And there have been solutions to all these problems for decades.

distribution of power in society and they're just people weren't willing to do that okay so um so in this paper that well on this call for transformational change so i am i'm trying to i'm calling for transformational change right now but i'm not alone so this this idea of we need bold change this

most of the scientific world really and most of the global policy making world and a large section of the global public is all realizing that we are in deep trouble and we need to change not incrementally not slowly but rapidly and deeply and across every aspect of society so i'll just use the words this is uh from the 2019 global assessment from the

IPBES, the UN, as they, in their words, they say current national global programs are insufficient to avoid, you know, and they call for a transformational change.

They use the word transformational and they define it as a fundamental system wide reorganization across technological, economic, social factors,

including paradigms, goals, and values.

I mean, essentially, you know, enormous fundamental change in how we understand ourselves, how we understand the world, how we behave, what we do for a living, how industry works, how consumerism works, what products we make, how we recycle, like how much energy we use, how, where we get our energy.

So I think maybe, I don't wanna put words in the UN's mouth, but I think maybe they were really still kind of talking about, you know, like improving current systems.

steps within our governance systems we can take bold steps within our economic systems financial systems we can do better there's ways that we can do better I would like to very much agree with that there are ways we can do better we should we should I would I would put that under the category of reform we should do everything in our power to reform the existing systems because that is the quickest bang for the buck I mean we can do more that isn't imperative that we act and put our energies behind

reforming as best we can the existing systems, working within existing systems and reforming them so they can do a better job so that we can reach some kind of transformation even within existing systems.

But this proposed R&D program and my interests are beyond that.

So I'm not, you know, my interest here is not in reform, not in improving capitalism, for example,

or representative democracy.

It is in building de novo systems from the ground up that are fit for purpose as we've been talking about.

So, you know, that's what I mean when I say societal transformation.

I mean shifting to building, testing, and shifting to new systems.

And, you know, we're familiar with these kind of concepts when we download software in the software world.

Uh, there, the terms are usually, uh, updates.

So like, you know, I'm going to update my software, minor improvement.

I'm going to upgrade my software to a new version.

I'm going to get, you know, version four instead of version three.

So that's kind of like big reform.

I'm going to get an upgrade.

Then migration.

So I'm going to do, I don't even like this, this company or this product.

I'm going to switch to open source.

and I'm gonna use the Linux operating system or some other, I'm gonna do something else.

I'm gonna use some entirely new system because the old one really doesn't work very well.

So my focus is on this, you know, is on migration, the testing development and implementation of de novo design societal systems.

Okay, so I think, you know, and science driven,

attitude.

Okay, so lots of people calling for transformational change, and that's what this paper is about.

Transformation understood as migration to new systems.

On slide 12, I think maybe, I mean, others might disagree, but I think maybe this is the first series in the literature that, in the science literature, that really lays out an R&D program that aims to tackle this de novo design of new systems.

I don't, I've not seen any others that are kind of comparable.

So I think we're maybe, you know, paving new ground here, perhaps, at least I hope.

I want to emphasize something we talked about in the last talk, that this is, we're talking about second-order science as opposed to first-order science.

So first-order science, again, is what we normally think of as science.

Someone is doing experiments.

They're detached from the experiment.

The scientist is detached.

They set it up.

They let the experiment run.

They don't interfere.

They just record what happened.

And hopefully, they gain some knowledge from doing so.

Fantastic stuff.

Most of science is all first-order science.

It's wonderful.

But for these kinds of problems, for this kind of problem that

requires what is called second-order science and there's a in my series I cite the work by phase you know on this topic and that's a great article I recommend that to everyone it's in the paper so you can get it there but he describes what they actually said hey it's a long list of authors describe what they mean by a second-order science and why it's important and they just

learning to learn.

We're learning to build new systems that help us to learn and build new systems, right?

We want to excel at learning.

That's the whole concept of this.

We want a society that excels at learning and problem solving and adaptation, and we're

And we're in the process of learning to build new systems that produce this effect.

So it's kind of a meta learning science, meta learning process.

And just in general, the second order science is the focus is on process.

The effort is value driven.

And the scientists are participants along with stakeholders who together learn.

So it's quite different from first-order science, and it's exactly the kind of science I think that is necessary for this larger meta-learning project.

In the paper, I talk about six overarching systems.

I just want to say that's what we're focused on here.

So economic, governance, legal, health, analytical, and educational systems.

Those are the ones I've chosen to focus on.

And each of them can be split down further, like in my terminology, the economic system also includes a monetary system and a financial system and so on.

And each of these can be split down further.

So that's what we're doing.

We're trying to develop designs for each of these that are integrated, not just, hey, let's just build a new economic system and leave everything else and change.

We'll do the economic system first.

That's not the point of the process.

The idea is how can we build a


SPEAKER_02:
helps us to achieve these goals and it's really a nice dovetailing with development is what organisms do that's embryonic development or colony level development or the niche being modified so it's like research and development research information foraging um

whatever we want to think about information foraging to mean here with research or just search, but it's like we already have design latent within potentially even the structures we have.

So how are we going to pull out of the tailspin if that's what we're in to build towards developing a healthier trajectory?


SPEAKER_00:
That's right.

We're in the process of evolution, you know, and every organism is evolving exactly as you said and developing.

So we're just being a part of that.

And, you know, quite a sensible part of that, I might add, too.

It's kind of like, oh, we're faced with severe problems that we might have a masked eye off of humans or go extinct because of.

So let me think.

What would be a good idea?

Oh, let's think about doing things differently.

Let's try to build a different way to live our lives.

You know, that's just kind of like, duh, that's a good idea.

Let's find a better way to live our lives and be more cooperative and have a healthier world

That's an excellent idea.

OK, so this is kind of a warm-up to what's coming in the paper.

I speak a lot about local community.

And I just want to emphasize, or I want to explain what that means a little bit.

So for one thing, I call society an organism or a superorganism and a cognitive organism at that.

And by society, I mean really a society

I'm interested in local communities for some reasons that will become clear shortly.

Local community might be just like a fraction of a city, not even a full city and not even a political body, not like a formal political body, but a group of people who in this case are particularly interested in participating in trying out and field testing and using some of these new systems that we're talking about developing.

Uh, you know, let's say, uh, when I say, uh, local community, let's say, uh, a group of a thousand people or more could be, could be larger, but not, not necessarily even a city and certainly not a nation.

Okay.

So, um, so I said that the UN and others are, this is slide 13 that the UN and others are

have come out with strong language calling for transformational change, which I think, again, you know, for many folks involved there, I think maybe their idea really is more what I would call reform.

Again, very, very important.

But it might help here to talk about why reform might not be enough.

Like why, you know, if the UN and other agencies and

Other groups are really putting up some great proposals for reform and improvement of existing systems.

Why am I interested in developing new systems?

Why don't we just do reform?

If that'll do the trick, why bother with more?

And there's numerous reasons that I lay out in paper number two of why I think transformation, new system development is necessary.

And to start with,

And as we've kind of been saying here, you can look at the world and the problems that we face with climate change and biodiversity loss and others, and you can suspect that current systems are incapable, maybe incapable of preventing widespread catastrophe and securing our continued vitality.

Really, the report card doesn't look good for existing systems.

They've done a rather crappy job of protecting the human health and the environment to the extent that we now face perhaps in our lifetime or soon after perhaps a mass die off of humans or even extinction of humans.

So why would we think that they're capable now suddenly of acting differently?

good excellent to do reform i don't want to talk anyone out of the reform efforts because they're absolutely important but i am suggesting that maybe we should have a plan b in case plan a doesn't work out so well so uh you know transformation this is a this is a plan b in a sense and in the end might turn out to be better than plan a even if reform is useful and helpful plan b might turn out to be the better bet so you kind of catch it on both ends there

So I'll just talk about a few things I mentioned in the paper of why evidence of current systems being incapable of preventing a widespread catastrophe.

So one is the Paris Agreement.

And then this is quoting from one of the UN studies, I believe.

It says, ambitions are broadly consistent with cost-effective pathways that result in a global warming of about three degrees by 2100.

So in a practical sense, if the Paris Agreement were interactive, that's sort of where it would lead to.

It is clearly, it is maybe an important agreement, but not enough, not nearly enough, it looks like.

And if indeed we were to reach about three degrees centigrade change from historical levels,

That's already in the iffy category of like, you know, how do humans, do we even have a civilization if we reach three degrees?

You know, it's an iffy question.

Maybe we do, maybe we find a way to deal with it and get by, or maybe we don't.

Maybe that's already way too much.

And also, the reform efforts don't adequately address certain structural problems that we face.

income and wealth divisions in the world.

Most of the reform efforts are not looking at how we can not have billionaires, but rather have everyone more or less equally engaged in the economic sphere and in a sense, having economic power to make decisions in this world.

So even if reform efforts are useful and good, I hope they are, maybe they won't be enough and maybe they won't even touch deeply on some topics that really need to be addressed.

So I argue, this section covers several pages, but in the end I argue that even if reform efforts are useful and helpful and they're successful for what they're shooting for,

they're still likely to leave societies hampered in their capacity to learn and adapt with many unsolved problems to address.

For example, even right now, even at one, wherever we're at, I'm not sure what degree we're at right now over historical levels, but still below two degrees, maybe we're 1.3, I don't know what it is.

Already there's nations that are, you know, there's island nations that are not able to

handle this, you know, like people are already starting to have to relocate and every indication is that that's just going to become worse and worse.

So even if we keep it below 1.5 degrees or we keep it below 2 degrees, the warming, we're going to have severe problems, social problems, economic problems, environmental problems, ecologic problems, and somehow we're going to have to deal with this harsher world

than even harsher than today, you know, more dangerous than today and more strained than today, more stressful than today.

And I'm suggesting that the best way to deal with a future world that is stressful and uncertain, highly uncertain and difficult is to become really good at problem solving.

Isn't, I mean, that's how you would go about it.

That's, you would be, if you can, you would become really good

at acting in an uncertain world and making wise decisions so that you don't have to suffer any more than is necessary.

Yeah, so that's, you know, like there would be, even if reform is successful, it would still be useful to develop, to become better at problem solving.

And I think that there's great opportunity

as a whole society hasn't even really tried to become a good problem solver, like, you know, in a, in a focused science driven way, we've never really put our mind to this and we can put our mind to it.

And I think that would be tremendous improvements that we could make.

That's, you know, that's why I wrote the series is because I think we could do so much better than we're doing today, which is not very well.

Um, let's see anything else on this slide.

Yes.

Down in the lower right-hand corner, I have a kind of a long list of things that we need to do and I won't read it now, but you know, we basically have to remake everything from what we make, how we make it, how we use it, where it goes, how it's disposed of, how we treat each other, how we cooperate, who we cooperate.

I mean, just like deep transformation from across every aspect of human life and human social life.

So, uh,

you know, to me at least, it's inconceivable that existing systems could even come close to the level of transformation that is actually not only needed, but would be beneficial.

Like, it would be really beneficial if societies became good at problem-solving and adaptation.

And it's pretty much inconceivable, to me at least, that existing systems and

beneficial.


SPEAKER_02:
I think this is really great.

I'm just looking for a natural pause point for where we would want to be.

What do you think about doing 14, going through it, taking our time, and then

this r d program being the pickup point for our third session i know we're going slow you're going on some great boomerangs so it's awesome but let's walk through leaving somebody at the end of the second discussion what would an r d program be that would meet the scope and the type of these challenges and then three is going to be like you want to know what it is go there


SPEAKER_00:
Yeah.

And I think for listeners, Daniel and I have been talking about, you know, there's a lot of material to unpack here.

So I think we're going to have more than three videos, but we'll figure out what the dates will be for them so that we can go through the whole thing, you know, carefully.

Perfect.

Okay.

So we'll end on slide 14 then.

And maybe to start, I would just

proposal for a new R&D program aimed at de novo development of new systems.

But other people might come up with another proposal.

Like, you know, mine maybe is just one of many possible ways to go about the R&D program for new proposals.

And I would welcome, I would hope even, that it would be fantastic if there were, you know, 20 projects happening around the world

I've aimed at this same thing and that we, and that each of these projects was cooperating with each other so that we can learn from each other and, and move forward, you know, in the most efficient and useful, most useful way.

So that's one of the reasons that I made this desert data list is like, what would be if other, if, if, if there's going to be multiple R and D programs, or even if it's just my, this, just this one that I put out,

know what what would be a good what what has to be included in the r d program you know what which which what should be there so that we would know that it's a you know like a reasonably complete one and so that we could we could compare r d programs so if i propose this one and someone else proposes another one we can compare say on number five uh number five develops new integrated systems that span all six of these major societal systems economic

if someone else proposes one that it's only focused on economic systems well there's a way to just distinguish between the two r d programs so that's uh that's that's part of my purpose here of laying this out and then it's also also the purpose that um you will see as you read the series that i i talk about each one of these so this is just in a sense it's a

It's a index to the larger series.


SPEAKER_02:
And also one point is that a scientist might say, you need to do A, B, and C to really study, you know, the mosquito's wing.

And then of course they measure A, B, and C. So of course they solve the mosquito's wing.

But actually you're laying out a protocol for evaluating policy across scales and then putting up almost like a retort to yourself, at least initially, that you believe could be held against this rubric.

like a report card and then again where a policy is better on 0.5 or 11 or whatever it be we can make that decision in a way or we can version the rubric so this isn't just setting the target or painting the target texas sharpshooter paint the target after you wrote the paper hypothesizing after the results are known harking this is like laying out where we do want it to go


SPEAKER_00:
Right, exactly.

Exactly.

And, and I hope that that we refined it together as a community refined this list so that we hone it better even.

Maybe there's some things I left out or some things I should have said, or things I said I didn't need to say who knows, but I'm sure it could be improved.

So we don't have much time and I won't go I won't go into detail on these but

Maybe I'll just, just to give a flavor, I'll just talk about a few scattering here.

So obviously, number one, if you're talking about an R&D program, it might help to actually provide some information about the scale of the intended effect.

I mean, are we thinking that this R&D program is going to build new systems for one particular city or for a nation or for whatever?

if it's successful, right?

What is the scale?

And what are the costs?

What are the risks?

How much money is this whole thing gonna take?

And we'll talk about that, money we'll talk about in the next talk.

Based on second order science, which I've mentioned already,

Number three, it has a theory of change.

Like, fine, you tested a new system, you built it, you get great computer simulation models, great.

Now, what do we do with it?

How would you ever take that idea and make it real, implement it in a real society somewhere?

How does that work?

And where is the blowback going to be?

Where is the pressure going to be against it?

What might go wrong?

So that should be in there, theory of change.

Number five, it develops integrated, I claim that it's important that it develops integrated systems across all six of the major ones, because if it doesn't, if you build a governance system independent from an economic system and you're still using the old economic system, it's not gonna work very well, because they're gonna be at odds with each other, not integrated.

Six describes the purpose of a siloed system.

What in the world is this supposed to do?

How do we know it even worked?

What have we measured fitness?

What was it supposed to accomplish and how can we evaluate it on what it did accomplish or what it's supposed to?

um how does cognition play like in this whole series as well focused on societal cognition maybe some other ph maybe some other r d program doesn't even use the word cognition maybe they have an entirely different way to think about what a society is and how it does and what the purpose is so if so you know it'd be good to say so uh makes the work freely available to the public so that

It's not a proprietary project at all.

Number eight, it develops flexible options that the public can choose from.

There is no one size fits all solution.

I mean, that wouldn't be very wise at all.

Societies have to have flexibility in how they act, what they implement, what they choose.

So hopefully the program would develop a smorgasbord of ideas.

possibilities that could be useful in different settings.

Number 11 addresses the cultural changes.

What kind of educational changes, for example, would be necessary to make this work?

There would be substantial ones, actually, because you build a new system.

For one thing, you would have to explain or educate people on how the new system even goes together and how it works and how would you know if it's not working, you know, all those kinds of questions.

Number 12, if new systems are implemented in multiple locations, is that information shared between them?

How does that work?

Is each independent or are they communicating or is this all part of a larger plan to have multiple tests going on at the same time or are those just independent things that come and go as they do?

Obviously, number 13, develop systems that are fair and just and that is reasonable.

And number 14, what are the expected impacts?

When you do simulations for this new system, how does it look for energy use and waste generation and climate change and biodiversity loss?

What are we going to get if we build these?

How is it going to go?

What is the likely outcome of these things?

So that's just a few ideas, a few topics that would be important to address in any R&D program, and I've tried my best to address them here.

And even in just three papers, you know, like some of these are addressed in just a few sentences or a few paragraphs somewhere in the papers because, you know, you would really need a book, I think, or a series of books to really do a thorough job on all of these.


SPEAKER_02:
Well, you know what I kind of saw almost when you have this list is like a GitHub or a versioned open source repository where people can fork the rubrics they like, they can add more challenges, they can go into detail.

What do you mean by fair?

What do you mean that they're just?

Well, those are things that we actually inactive inference we can get down to.

And that's not to say that we're going to be carving out the human.

It means that we're going to be designing for ourselves.

and for whoever's on board.

And just like the shipmakers make it for those who are on the ship, but the ship is part of society.

There's going to be a ship with sails.

So I think there'll be such interesting conversations because really you could...

fractal into yeah, seven, what is the role of information?

I mean, I went to a conference today on only a fragment of that.

So of course seven is going to be a big topic, but it's, it's, it's third order science.

Well, you did with laying out the second order criticism paradigm.

So it's quite interesting to read about and learn.


SPEAKER_00:
Yeah.

You know, speaking of, uh, speaking of a repository,

At the very least, you need a language and a means of communications that you can convey.

If I have an idea for new systems, I need to convey that to the rest of the world in some way to convey it to you.

Maybe you have your own idea of what a new system would look like.

How do we convey that idea?

How do we convey a complicated idea to each other so that we know what each other is talking about, and then we can start to do tests on them or figure out which one works better in what situations?


SPEAKER_02:
a way to communicate a way to present the information so that we can understand what each other is saying just one kind of closing metaphor or at least thought that comes to mind is like let's say two people like a movie one person said i love the special effects the other one says the special effects were super cheesy i thought the story the other person says i didn't even i don't like movies but i like the book

So everyone can like the movie, and the point is they're aligned on action.

They might even want to hang out together.

They might be part of a fan club.

They might have a product related to the movie.

But if the problem is framed as, okay, come to consensus on why you like this movie, we cannot personalize the solution.

So everybody can have a different understanding of why they like the movie that's playing out in front of our eyes.

And if it's about which part of this movie do you like or not like,

we're going to be arguing a lot.

And if it's like, which movies should we watch?

Potentially that's a different question or how should we reduce uncertainty about the movie that we should watch?

There's a lot of ways to frame it that I would hope would be new.


SPEAKER_00:
Yeah, I think so.

I think so.

Yeah.

Yeah.

Maybe we should leave it there and we'll pick up more next time.


SPEAKER_02:
John, thanks so much again.

I'm going to just re-upload this video in case there's any weirdness with the live stream.

So it'll be high quality and just we'll be in touch about planning these upcoming sessions, but we will know that we will meet next week on April 20th at 3 p.m.

Pacific PDT for the third session of N of bleep.

Okay.

Sounds good.

See you later, John.


SPEAKER_00:
Peace.


SPEAKER_01:
Okay.


SPEAKER_02:
Bye.

Bye.