SPEAKER_00:
Hello, everyone.

Welcome to the Active Inference live stream.

This is Act-Inf Stream 5.2.

It is October 6th, 2020.

First time listeners or not, welcome to Team Calm.

We are an experiment in online team communication and learning related to Active Inference.

You can find us on Twitter at Inference Active.

You can email us at ActiveInference at gmail.com, on Keybase at our public team, or on YouTube.

This is a recorded and an archived livestream, so please provide us feedback, live participants as well as viewers, so that we can improve our work.

All backgrounds and perspectives are welcome here.

And also just as far as video etiquette goes, please mute if there's noise in your background and raise your hand so that we can use the stack to hear from everyone.

As mentioned, we are here in ACT InfoStream 5.2 and here's a little bit about how today is going to go.

First, we're gonna have our regular warmup section where we'll do some intros and we'll check in with a few questions.

Last time in Act Imp Stream 5.1, we did a pretty broad overview summary of the paper, went through the figures, the goals, the abstract.

And today in the follow-up discussion part two, we're gonna be going through, first off, any questions or comments that people want to address.

And then after we've exhausted that, or if we're excited just to get to the other topics, we'll go right ahead.

We will...

Return to the debate about internalism versus externalism, because that is in some ways what the broader scholastic tradition that the paper is involved in is about.

We'll talk about Markov blankets.

We'll talk about what it means to be internal and what it means to be generative.

We'll talk about changing one's mind.

We'll talk about free energy minimization.

We'll talk about some of the limits of cognition in science.

And then we'll hopefully return to the figures, especially figure six and mechanistic differences in different multi-scale systems.

So here we are in the introduction section.

For this intro section, please introduce yourself and your location.

Just say a quick hello and a short introduction if you would like, and then pass it to someone else.

I'll go first.

I'm Daniel Friedman.

I'm in Davis right now, and I will pass it to Stephen.


SPEAKER_07:
Hello, I'm Stephen.

I'm in Toronto right now and very excited about being here today.

I'm going to pass it to Alex.


SPEAKER_05:
Hello, I'm Alex.

Today I'm in Moscow as well as usually.

Hello everybody.

And I pass it to Ivan.

Hi, my name is Ivan.

I'm from Moscow also.

And I pass it to Alejandra.


SPEAKER_02:
Hello, hello everybody.

My name is Alejandra.

And also as usual I'm here in Mexico.

And I pass it to Sasha.


SPEAKER_04:
Hi, good morning, everybody.

I am, as usual, in Davis, California.

And I'm looking forward to this conversation.

And I pass it to Maxwell.


SPEAKER_01:
Hey, everyone.

I'm Maxwell Ramstad.

Happy to be joining this conversation from sunny Montreal in Canada.

And I'll pass it to Shannon.


SPEAKER_03:
Hi everyone, I'm Shannon and I'm currently in South Dakota.


SPEAKER_00:
Awesome, does that get through everyone?

Yep, a nice small tight group today.

Thanks everyone for coming in.

So let's go through our warmup questions and we would love to hear from all of you on these.

The first warmup question is what got you excited for today's discussion?

What brought you to the followup discussion?

and people can raise their hand, all start.

What got me excited was that second phase of interacting with the paper, which is beyond just at a first pass what was said in the paper and what the figures represented to tie it to deeper questions and to deeper ideas.


SPEAKER_07:
Yeah, Stephen?

Yeah, what really excited me was a lot of stuff that came up last week.

So that was really useful and I got some new insights.

But I'd say I saw a potential way that it was moving towards this multi-method approach.

potential to bring together different ways of thinking and practices.

So I'm interested in how the kind of different levels sort of can come together in different ways and privilege different types of scales in ways which are actually quite practical and useful.

So that was really, really interesting.


SPEAKER_00:
Cool.

And we'll definitely talk about how the different scales come to bear.

If anyone else wants to raise their hand, otherwise I'll just go to the second discussion question, which is if at all, how have you updated your beliefs on multi-scale integration since the last conversation?

I think that was a question from Sasha.

So maybe I'll go to her while other people are raising their hand while she unmutes.


SPEAKER_04:
Um,

Yeah, that was a bit of a cheeky question.

But I think we got into a lot of interesting topics last week.

And really getting into the philosophy of science, that was really interesting for me.

And it's a topic I hope to explore, especially in thinking about different levels of

how to create the appropriate system for studying cognition and where to draw that boundary.

Something I'm interested for figuring out in my own work with studying neuroscience and development, and just really enjoyed hearing everyone's perspective as well.

So my update was that philosophy of science is really critical to the practicality of experimental design.


SPEAKER_00:
Yeah, there's in many of these papers and ideas, there's us experiencing the system.

We're apparently only experiencing our individual cognition, but then what does it really mean to be experiencing individual cognition?

Anyone else wanna have a thought on that?

And also I'll just put up the third question is what would be something that you'd like to clarify or explore in today's conversation?


SPEAKER_03:
so shannon i'm really curious about um this idea that the mind is skull bound while also giving cognition um to extended systems that like extend beyond the mind especially in like being in a neuroscience lab and like what i am interested in studying and explaining is how the brain is involved with some cognitive process while also understanding

and not minimizing the role that the body or the environment plays.


SPEAKER_00:
Agreed.

Within the Markov blanket of this conversation that we're having, there's some sort of distributed cognition at play, but who or what is experiencing that and what are the dynamics of that type of cognition?

Does anyone else want to have any thoughts on these questions or we can just start going through some of these quotes and ideas?

Okay, I'm just going to go into it.

So here we are in Multiscale Integration Beyond Internalism and Externalism, a 2019 paper.

Last week in 5.1, we went through it pretty broadly.

Today, we're going to follow up on some key quotations, some key ideas, go through the figures again in this sort of spiraling back at a higher level, wanting to understand what is on the table, what are the implications of what is being discussed.

The goals of the paper, just to rehearse them, were to make explicit this description of the boundaries of cognitive systems as being multiscale.

And so when we think that the boundaries of cognitive systems are nested and multiple, and the implication of this to the authors is that cognition has no fixed or essential boundaries,

And where that sort of took me as far as the slides go was what were the implications of taking multiscale integration seriously?

And how does free energy principle and free energy minimization fit into all of this?

So first, is there anything that people just want to raise as something to address or think about before we jump into some of these topics?

If not, just feel free to write it down and we'll return to it soon.

Okay.

For the first topic, yes, Steven, go ahead.


SPEAKER_07:
Just one thing that I think might be good to mention that came up is this idea of how we privilege certain levels and maybe then end up just stuck at that level, like a psychological level or a behavioral level or whatever.

So

There's an implication, I think, in this to think about the levels, which is kind of maybe some way a bit of an abstract thing when across all the levels and how do we actually privilege in some sort of intentional way the levels that are going to be sort of looked at as the kind of active inference engines that are most relevant.

So that's something that came up for me.


SPEAKER_00:
Yeah, I would actually like to follow up and ask you, we talk about this privilege level of analysis and recall Dennis Noble's paper.

What does it mean to privilege one level of analysis?

Or is that something that is just a priori to be avoided?

Or do we want to privilege larger systems, smaller systems?

How do we give each player in the system its due respect?

And where does that fit in with this vocabulary of privileging one level of analysis?


SPEAKER_07:
I was wondering whether that's where that active, dynamic kind of structure that's at play might come in.

I was thinking that there's this sense that you've got kind of the overall kind of dynamics of the system, but there are key places where...

And there's something, I think Shannon mentioned this last week in terms of the certain levels which are most relevant in terms of how the dynamics are yielding some systemic kind of act, which is appropriate at the particular spatial temporal level.

um sort of speeds or distances which are relevant for the study or the experiment or the practice which is being looked at so i suppose in some ways you have to start to come back from the other directions at some point um assuming you're moving more and more towards practice and say okay what's the what what is it that the the kind of intentionality of the researchers


SPEAKER_00:
Cool.

And we'll return to this idea about, are we looking at the dynamics, at the causal structure of the system?

Are those the same thing?

Here, we're going to talk for a little bit about the big philosophical question, which is internalism versus externalism.

So I'll start with just a definition of the topic from encyclopedia.com.

And here it's about epistemology, but there's analogous dichotomies in other areas.

They write, internalism in epistemology is a thesis about the nature of epistemic normativity or the sort of normativity that is involved in the evaluation of cognition.

Specifically, internalists claim that the epistemically normative status of a belief is entirely determined by factors that are relevantly internal to the believer's perspective on things, perhaps skullbound, as Shannon said.

By contrast, externalists in epistemology deny this.

The externalist says that the epistemic status of a belief is not entirely determined by factors that are internal to the believer's perspective.

And that with the spy versus spy to represent that they're sort of playing off of each other.

They don't totally disagree, these two viewpoints.

We can see with this graphic from a 2010 paper by Linnaean Steiner.

they represented externalism and internalism.

And I just thought this was an interesting figure because it showed to what extent these two schools of thoughts basically agree.

They basically agree that there is an organism that is part of a coupling device, like the body, let's just say, and through actions,

there's action on the environment the environment provides sensations to the organism and that's the action perception loop so that's sort of what we agree on between these two sides where is there disagreement well the two main things on this figure where we can see disagreement are first off what the externalist sees as happening inside of the organism to a large extent is strategy

Whereas the internalist sees the organism as making representations about the world.

And then another difference that's reflected on this figure is that perception, the wavy line, is in the internalist's view inside of the organism.

It's skull bound.

It's happening downstream of the representation.

Whereas for the externalist, the perception is coming from the interaction between the organism's strategies and the environmental causality.

And that was something I was sort of just thinking, well, doesn't perception still happen inside, even if there's an important role for perceptions outside?

And so just looking at this graphic or just thinking about where you stand at this moment, would you say that you're an internalist and or an externalist?

Just looking at these graphics, does one of them seem more or less consonant with your stance on how ecologically embedded systems are in the world or

Does there seem to be something that's missing from one of these sides or the other?


SPEAKER_03:
If and or is a real choice and we can pick and, then definitely have you both.


SPEAKER_00:
What makes you want to take and in this divide?


SPEAKER_03:
I feel like I want to answer that question at the end of our discussion.


SPEAKER_00:
Perfect.

I might as well.

It's why I threw in the and and why the spy versus spy are shaking hands, because the whole topic and the discussion in some senses is we're moving beyond internalism and externalism.

This may or may not be a false dichotomy.

And then the question would be, well, why has this false dichotomy, if it is attracted so much attention or tension?

what is going to be the framework that is going to step beyond internalism and externalism and potentially provide a satisfying resolution to all of the similarities and the differences that these two models present with.

So again, the action perception loop doesn't seem like there's broad disagreement on those topics.

However, there seems to be a few key issues that are up for debate, such as whether perception happens

purely internally, or whether perception is related to feedback with the environment, and then whether what organisms are doing is best thought of as representational or as strategic.

Stephen?


SPEAKER_07:
I think also those diagrams, there is also that piece in the diagram where they kind of make out that they're directly

causality and the environment they've got a direct relationship to.

Because in some ways your actions, if we see that as really you've got access to your proprioceptive signals and your sensations are kind of your ongoing stream of data, that

That link to the environment, I'd say, is a lot less... I think both of these two approaches rely on there being quite an idea that my action is touching the environment, as opposed to my action being a kind of set of proprioceptive signals which I sort of am inferring something from, and my sensations are the environment.

You know, this idea that I see the world, as opposed to having to piece together a whole load of...

non-linear data over time so i suppose there is a kind of maybe a challenge to that part of the um of the two ways of looking at externalism and internalism that's been done in the past shannon i suppose um that's true too so you said like there's a sense in which i touch the world um stephen and i think phenomenologically there's a sense that i touch and i experience the world


SPEAKER_03:
But if I'm thinking about the brain, the thing that the neuron perceives is not the world.

It's the signals that have been translated into electrical and chemical impulses.

And that's where, like, I really want to know how the brain works.

I got to be internalist about it.

But if I want to know how I experience the world, then there's a lot more externalism that you can allow in.


SPEAKER_00:
Good points, and also we'll return later on in the conversation to what kind of experiments would be differentiating.

How will we reduce our uncertainty about the strengths and weaknesses of these two options?

Maxwell?


SPEAKER_01:
I just want to point out that our agenda in this paper was sort of to dispel the isms of internal and external ism, right?

So, I mean, the idea is sort of that, well, cognitive science for most of its, you know, from its inception to basically the heuristically like the late 80s was an internalist program.

And then externalist approaches started appearing in the late 80s and 90s, you know, that emphasize things like embodiment, you know, the fact that cognition is grounded in the operations of a body.

And then you saw the appearance of theses in philosophy like the extended mind thesis or the extended cognition thesis, which is a strong metaphysical claim that says, well, actually, the realizers of cognitive processes spill over into the environment.

So that if you're going to draw a boundary around the cognitive system, you have to include external components, environmental components as realizers of these processes.

And the kind of hard line externalist position is basically kind of the traditional inactivist position.

It's the equal partners principle, which essentially says cognition is always necessarily a loop between internal structures like the brain and action and external structures like the ones in the environment that we're interacting with.

and uh our view on that was that um any essentialist position about the boundaries of cognition which which is to say any position that says okay well we can define a necessary and sufficient set of conditions such that we can identify whether this or that you know is a bit of cognition and whether it's internal or external to some you know the organism's boundary that any essentialist position

of that sort, is going to be wrongheaded, that there's not kind of a one-size-fits-all way to cut up systems.

So basically we're making two kind of ontological claims about the boundaries of cognition, which is that they're multiple and that they're nested.

So they're multiple in the sense that depending on what you want to explain, then the relevant boundaries might be around a cluster of cells in the brain, or it might be the brain itself, or some region of the brain, or maybe it's the brain-body system.

So it depends.

And then the epistemological point, which is precisely that it depends on our explanatory interests.

So it may be that...

If you want to explain, for example, daydreaming or some other kind of phenomenon, well, you're mostly going to be appealing to brain processes.

But if you want to explain sport performance, then this loop thing is going to be the most important.

And importantly, the point of the article is that the free energy principle gives us reason to think that we shouldn't.

take these strong essentialist positions.

There's a way around them and a way of being more ecumenical and flexible about where we situate these boundaries.


SPEAKER_00:
Very nice.

I agree.

And hopefully that's where this discussion will take people is beyond the dogma towards the specifics of the situation.

And I also was thinking about like dreaming versus action.

Are these internalist versus externalist stances challenged by actionless experience like a dream or is a dream?

Are they going to couch that as some type of experience?

And you know what?

enough with that let's just look for a framework that will help us deal with the specifics of the situation so speaking of internal and external and how they're treated under the free energy principle let's talk a little bit about markov blankets so three kinds of markov blankets are shown on this slide

There's a quote in the paper that the Markov blankets are a result of the system's dynamics.

And two twin questions that I wanted to raise and think about were, what if we compare two systems that have the same components but different dynamics?

And the sort of inverse of that question, which is two systems that have different components but the same dynamics.

And so especially if we think about the Markov blankets,

boundary shielding internal states, so black box around some level of analysis, all we're able to see are the emitted states.

So the dynamics of the emitted states may be similar, even though there's two different underlying realities.

So two different computers, different hardware, but then they're able to run the same program at the same speed.

And then the other side of the question would be, okay, you can have the same computer with the same underlying componentry, but then it might be involved in multiple different kinds of dynamics.

So how does that fit with the Markov blanket?

What is the Markov blanket really tracking?

Is it tracking the inputs and the outputs of the objective system?

Is it tracking the inputs and the outputs of us measuring the system?


SPEAKER_01:
Well, so one thing to highlight just before we really get started is that I think too much emphasis has been placed on the literature, in part, I mean, in my own work also, on the Markov blanket on its own.

Markov blankets are very common and explanatorily uninteresting just on their own for the most part.

So I mean, a Markov blanket, you have a set of random variables.

You want to see whether this and that one are independent.

Well, the Markov blanket is the set of random variables that renders them independent in the sense that basically they're

that conditioned on the existence of this other set of variables than these two are statistically independent in terms of like their, yeah.

So that's cool, but there are Markov blankets everywhere, right?

So you can think of like the present as a Markov blanket between the past and the future, for example.

It's a very general thing.

In the context that we're talking here,

The Markov blankets get their explanatory purchase when you combine it with the other kind of moving parts of the free energy principle formalism, which are the non-equilibrium steady state slash generative model thing.

So basically the Markov blanket tells you which set of states kind of belong to the system and which don't.

And then the non-equilibrium steady state density tells you, well, what is the basically like the set of correlated values that these states can have such that the phenotype is maintained.

And it's the two together that really get you the explanatory power of the free energy principle.

Sort of like where the system is and what it is.

The where kind of answered by the Markov blanket thing.

and the what answered by the generative model aspect of it.

So the Markov blanket itself, in the free energy principle stuff, you get it from a sparsity constraints on the flow

So basically, this means, I know it sounds technical, but it basically means that all of the states of the system are flowing.

They're changing dynamically.

They're moving around in the state space.

The system is moving around in its state space.

And basically, when we say sparsity conditions on the flow, it's that some variables don't affect the change of other variables, so that the rate of change

of one variable with respect to some other set of variables is a relevant kind of way of measuring the influence of one set of variables on another.

And I mean, the general idea is if conditioned on some set of variables, the rate of change of one variable relative to the other is zero, then you can say that there's an independence statistically.

So the way that the blankets are constructed is by analyzing the dependencies structure of the flow and then saying, okay, well, the dynamics themselves seem to carve out these kind of independencies.

So it's a dynamical notion.

And I'm emphasizing that because the dynamics themselves are premised on the whole generative model aspect of it.

So it all kind of moves together.

And you don't get the free energy stuff just out of Markov blankets.


SPEAKER_00:
Shannon?


SPEAKER_03:
Yeah, following up on that, I think there's a way to rephrase these two questions in that the first question, comparing systems with the same components but different dynamics, is asking sort of how the same set of components, if you give them a different set of initial conditions, can exhibit completely different behaviors or come to embody different

phenotypes in a certain niche.

And the second question, what if they have different components, but they have the same dynamics, is a question of multiple realizability, where you could have the same sort of computation or something enacted with different components.

And these questions together, I think, highlight the importance of if you have this Markov blanket over time, this sort of like system of interest over time, the importance of the way that system is structured.

and the function between, we could say, the different nodes underneath the Markov blanket.

And that's more important than the actual physical stuff it's made out of, maybe.

And back to the first question, the role of the environment in affecting the internal states of that system.


SPEAKER_00:
Cool, thank you, and well stated and tied back to these other questions about multiple realizations.

The follow-up question to that was just in which ways the blanket is tracking just the pure observations of the system versus the causal relationships.

And you gave a great example about how, depending on the initial conditions, that means that the conditional dependencies in the systems may be very different.

And so in those cases, the Markov blankets are different.

And in some senses, this is an implication of saying that the boundaries of cognition are context dependent because it shouldn't surprise us that the Markov blanket, and we will get to the generative model and internal states soon, but it shouldn't surprise us that the boundaries change because there's times where the cognitive process is happening in different causal ways or different spatial skills.

Steven.


SPEAKER_07:
Yeah, I think also this might be where that challenge with the mind and the environment, because we talk about what mental processes or what environmental processes, but what's the constituents that are being put together in terms of like the morphology or the actual, you know, am I engaging my muscles in my hand, and that has, you know, the hand is...

constructed so it's not just my feeling of my phenotype about how I should act it's not like my knowing of my phenotype it's like my actual biological engineering is going to enable certain things to happen you know unlike a chimpanzee or something like that there's certain things I can just do so there's this middle bit which you know we're able to adapt and adjust through our cognition

and say what gets brought online between the environment and the sensorium.

So that's the bit that kind of really complicates things, but obviously seems to be really relevant.

I think sometimes it gets lost when it gets kind of more theoretical.


SPEAKER_00:
Yep, let's look at this very provocative quote, which is, in this sense, cognitive science might be understood as the study of generative models and processes.

It is the business of modeling the correlational or causal structure of actions and observations of the organism.

The generative model, then, is not the vehicle of something like content or mutual information.

Instead, it is the tool that we use to study cognitive systems as an explanatory model, and indeed, perhaps more speculatively, the guide or path living systems entail and follow to stay alive as control systems.

So in both of these quotes, there is some pretty interesting notions from a cognitive science perspective.

And also it hints at this way that the Markov blanket or that the active inference idea, it not only is how organisms are in their environment.

And so that's referring to this path that living systems follow to stay alive.

In other words, that that's what the animals are doing or that's what the bacteria is doing.

But also it's the tool that we use to study cognitive systems.

And I thought it was pretty interesting that it was first and foremost and unambiguously presented as a tool that we use to study systems.

And then perhaps more speculatively, it was a guide that living systems follow to stay alive.

So, Maxwell, yeah, I'm curious just about that breakdown.


SPEAKER_01:
yeah to give you some context this this uh this paper multi-scale integration um the schrodinger answering schrodinger's question and a tale of two densities were all originally the same paper uh that we split up into different lumps uh with answer answering schrodinger's question being the more kind of theoretical mathematical statement and then these two other papers being kind of philosophical explorations of the consequences of all this

So over the past few months it's become clearer to me what's going on here.

And I have a paper on this now which has been published in Entropy with Ineshi Polito and Carl Friston.

It's called Is the Free Energy Principle a Formal Theory of Semantics?

And yes is the answer to that question.

And basically I've been playing around with the idea that there are kind of two levels of instrumentalism

uh that are at play here so instrumentalism broadly speaking in the philosophy of science is the view that well the work of science happens by leveraging scientific models and getting them to do some interesting explanatory work explaining the variance in our data and stuff like that so

An instrumentalist would claim that scientific models aren't literal descriptions of the universe but a kind of useful tool that we as scientists use to explain the main causal features of the phenomena around us.

So there's a first level then that you can be instrumentalist about the free energy principle.

And I think that on a good day when I wake up on the right side of the bed, I'm an instrumentalist about scientific models.

Science is about, I think, comparing models of data with theoretical and formal models, ultimately.

And these can be read in a very, very large way.

So on a bad day, I'm a realist, or I have a realist bent, and I really think that these models are getting at something like the true causal structure of reality.

But that's, I think, scientific hubris, maybe, or whatever.

But anyway, so there's this kind of meta level

this philosophy of science kind of instrumentalism level.

And I think that there's a debate there.

Some of my close friends and collaborators think that the FEP is finally a literal theory of how brains process information.

So it's not just a metaphor or an as-if thing, but it's really this is how it happened.

All this is independent.

from what the the theory the free energy principle itself says and so the more controversial claim but i think increasingly i think this is the only way to really interpret what the math does like coherently uh what the free energy principle is in a sense

is a statement about how organisms are able to exploit, use, or leverage the statistical structure of their bodies in motion to generate patterns of adaptive behavior.

So from that point of view, you know, regardless of what your position is at the meta level or the philosophy of science level, at the theoretical level, what the FEP is telling you is that organisms are exploiting a model effectively that they are,

a statistical model that they embody in order to generate patterns of adaptive behavior.

So that was the, that's the clarify.

Increasingly, I think that, you know, double instrumentalism, I'm all about this nested stuff, right?

So instrumentalism nested within instrumentalism is probably the right way to approach these questions.

But it definitely for sure,

At the theory level, the free energy principle is an instrumentalist theory of cognition, regardless of whether we're realist about the ontology that it might entail.


SPEAKER_00:
Thanks for that clarification and kind of reading between the citations there.

And I also really agree with that.

It's sort of like, well, we've tuned into the idea that it really is about our model of the world and about us in relationship with the world.

And now people just say, well, how is the world really?

And then the free energy principle saying, well, it's really about the feedback between the organism and the environment.

And then.

we still want something to pin down to that's really how it is.

But that's the instrumentalism of science is whether you use optimal foraging theory or an economic theory or some other theory, that doesn't change what the system is doing.

The bacteria doesn't know, doesn't care what version of which theoretical framework you're using or what papers you have or haven't read.

It's doing what it does.

And

The free energy principle is saying that what it does is, as you had just described, leveraging the bodies in motion, though also I have some questions about where thought fits into that.

And that's really it.

It's really us in feedback, understanding our environment to guide skillful action.

And you can't just cut the loop there and say, well, but then what is just what is really happening?

It's really what's happening.

And the real implications of that are, as you described.

So if there's no other comments on this slide, I'm going to go to this next few points about what is internal and what is generative.

So first was a very interesting quote in the latter part of the paper, and they wrote,

First, we take issue with the claim that under the free energy principle, the generative model is something internal to the organism.

So they're dissenting from the opinion that the generative model is something that is merely internal, i.e.

that the generative model comprises neuronal vehicles or any other vehicles, I guess like cars.

Rather, the generative model is a mathematical construct that explains how the quantities embodied by the system's architecture change to transcribe, that is, update beliefs about, the causes of the system's sensory observation.

What should be at stake in the debate between the internalists and externalists is the status of the guess that the organism embodies.

namely the posterior beliefs encoded by internal states, and whether this guess does or does not constitute the limits of cognition, understood as the avoidance of surprisal or informational homeostasis.

So my question here was, if the internal states are not generative models, or another way to say, if the generative model is not something that's just internal to the organism, what are the internal states?

And then the other side of that question is, well, then what or where is this generative model playing out?


SPEAKER_01:
So I can answer that.

I think it's a lot simpler than it might seem initially.

So in machine learning, if you have a bunch of variables, some of which are hidden, some of which are observable,

and you write a joint probability distribution over all of those variables, then that joint probability distribution or density is called a generative model.

So it's called generative because by representing all of the statistical relations between all of the different variables as this big joint density, you're effectively able to generate the outcomes or the data that you would expect

contingent on these causal relations actually holding between all of the different variables that you're talking about.

So just from a mathematical point of view, this joint density is never represented explicitly anywhere in the brain in the free energy active inference approaches.

Typically, this whole joint density, in all of these kind of more formal models, what you'll typically see is like,

one big probability distribution written on the left-hand side of an equation, p over all of the states that you're trying to look at.

Often these will be states and precisions and all these things.

And then is equal to some big product of likelihood and priors.

And so what's actually encoded in the brain has to do with these likelihoods and priors.

So the idea is that there is a generative model.

at play, but it's only at play in the dynamics.

The generative model is sort of like the wave of falling dominoes.

The wave itself is only present in the kind of motion or dynamics of the domino pile falling.

So what we're kind of proposing here, and we'll be discussing this a bit more in the next weeks with A Tale of Two Densities, the paper which is specifically about this, but

The idea here is what body states actually encode are posterior estimates.

So posterior estimates of the value of states.

Your body is basically your best ongoing guess as to what's causing your sensory states.

And yeah, the generative model itself

is the point of reference for the dynamics.

So if you think about it, what is this joint probability distribution thing?

Well, it's essentially a kind of surface

that the system is moving around over or equivalently that describes the probability of finding the system in a given state at random if you're just sampling it.

And what it's telling you is the allowable covariations between all of the values of the variables that make up the system such that the phenotype is maintained.

So speaking a bit loosely perhaps, this generative model thing

just is the phenotype of the organism in this kind of broad statistical sense of harnessing all of the possible uh you know combinations of states that are compatible with the continued existence of the organism um so i mean it's a bit it's a bit um it's a bit uh hard to grasp i'll admit uh but at least the mathematics of it kind of look like that


SPEAKER_00:
Thanks for that explanation.

And it's why we're here is to really dive into some of these key issues.

I think just

Reflecting on the pieces that I'm taking away from this is one is that the free energy principle is describing how scientists investigate systems or investigators of any kind.

And then, as was put perhaps more speculatively, is what is actually happening in the system.

But in some sense, that's secondary because it's so important to be clear about how we're approaching the system.

So instead of saying, oh, well, it's an optimal forager.

It's like, no, I'm studying the ants foraging within an optimal foraging framework.

No one can take that away from me.

And then whether the ant is doing optimal foraging or some other thing, it's almost a secondary question because it's so critical to be clear about our perspective.

And then the second piece is this internal and external

uh debate or whatever it is tension between those two stances is to be clear about where the generative model and um is and what it is and isn't and also it's just a map in territory distinction so let's look at a few more quotes from this paper

Here's a quote.

The generative model is a statistical construct, aka that means by people, that transcribes the expected sensory causal regularities in the process generating sensory states.

The generative model is used to model the set of viable phenotypic statistical relations, such as preferences and action policies, that must be brought forth by the organism in active inference.

In short, a model of a viable state of being for the organism.

Through active inference, internal states are tuned, and this tuning changes its posterior belief, and hence the organism's best guess about what caused its sensation that usually include its own actions.

In other words, a generative model can be used to understand how organisms are able to track or infer their own behavior.

And one key part there is that the best guess doesn't mean the one that's closest to reality per se.

It means it's the most action oriented or evolutionarily relevant guess.

So the best guess for a loud noise isn't just doing inference on the location of the noise or on the exact type of object that caused it.

The best guess when you're doing inference on policy is actually about how the body should change its dynamics.

And then the question that I raised here is just how does a multi-scale generative model work in the brain or in a social group?

And can there be a generative model without action or behavior or external states being influenced so heavily?

Maybe these are things that we can return to later if no one has any comments now.


SPEAKER_07:
So yeah, Steven?

One thing I've been interested in is if you're looking at someone's generative model, what's the best place to look at it?

In a way, if I was to look at someone's physical states and how that's compatible with their existence in the environment, is that a good read on their generative model as much as looking in the brain?

If the states that I'm in constitute my generative model's best guess of how I should be in the world,

In a way, that is a window into what my organism level cognition is.

I don't know whether thinking is the right term.


SPEAKER_01:
Oh yeah, I agree with that.

Well, if you look at a lot of the active inference modeling that's based on the partially observable Markov decision process implementation,

For the most part, it's a behavioral modeling framework.

What you're trying to do when you're tuning your generative model is to get your behavioral profile to align with some data that you're generating.

Behavior on some task of some sort.

The connection to the neuro stuff is a bit more elaborate.

We rely on auxiliary hypotheses and other work that suggest that these precisions are being estimated here, these prediction errors are being generated here, and so on.

If you want to, you can use a fitted generative model to make predictions about the neural substrates that you would expect to be engaged in this or that task.

And that can help guide, you know, fMRI and EEG experimental design to kind of probe into like specific brain regions that you think might be involved.

So you get into this kind of circular experimental design thing if you want to do the brain aspect.

But actually these techniques are more easily used for behavioral modeling because you don't have to make all these assumptions about brain structure.


SPEAKER_00:
Yeah, just one comment on there, and this was clarified by reading the SPM statistical parametric mapping textbook.

The generative models were used extensively to rather than just do descriptive statistics on the very complicated data structure of neuroimaging.

What was being done in the SPM approach was a generative model of brain states was being used as a generative model for the data.

And so, again, that's that instrumentalism of the scientific kind that just from the purely statistical, like, how am I going to write this paper perspective?

having a generative model or having the brain regions connected in a generative model that generates data given certain hypotheses about how brain regions are connected, that turns out to be a lot more tractable to study and it allows you to do model comparisons in a very, very direct way.

And then,

maybe the activity of what those brain regions are doing is itself making a generative model, a Cartesian theater or something like that.

It'd be wild and amazing if true, and also wild and amazing if the bold, the brain oxygen level dependent signal captured that.

But at the very least, and again, this is sort of retreating to the scientific instrumentalism, at the very least, it's a way that we can investigate the changes in the dynamics of those systems.

And so...


SPEAKER_01:
Yeah, absolutely.

I mean, this is the duality of techniques that we use, right?

On the one hand, there's dynamical causal modeling, which as you're pointing out, Dan, doesn't assume that the process that you're modeling is itself an active inference process, although it could.

So, you know, this is the technique that we use in fMRI data analysis, for example, and it's also the technique that has been used recently by Carl Friston's group to model the spread of coronavirus.

Which, you know, you could think that, you know, maybe corona itself is an active inference type thing, but you don't need to make that assumption to use this modeling strategy and try to extract, you know, using what the corona studies do essentially.

is take a bunch of raw data, like a raw number of infected, a raw number of deaths from corona, and use that as data that you're essentially trying to then write a generative model of and fit the generative model to the time series effectively to kind of extract the causal structure of the disease process in this case that's leading to the data that we're observing.

Yeah, active inference modeling can be combined with this, but makes the assumption that the agents that we're modeling are all performing a kind of active inference, variational inference thing.


SPEAKER_07:
Nice.

Stephen?

I think this also links nicely.

I do a lot of spatial cognition and how, so we think about, oh, I see something.

When I see something within this direction, there's actually a recent paper I saw where people who've lost their hearing, who are deaf, basically,

the brain region for their vision, it actually maps out wider and has less resolution in the middle because they no longer can hear things coming in from their sides.

They can't perceive things by listening to something that comes into their auditory field.

So they have to expand out

their visual field and so this this this sense of like how we bring in our sensorium because we can hear all around us but only for a certain distance we can see a long way but only in a certain direction and it could some of those another paper i've heard about where people would touch their nose it could be because you're trying to think through smell it's like you know like you sniff out a problem

So you've got this kind of like the modality, like just when you try and feel your way into a problem and ground yourself, you don't ground yourself with your eyes, right?

You ground yourself with your bottom or whatever it is.

And you hear the field or you listen to the field or you see the future or you sniff out wrongdoing or you taste, there's a bad taste in my mouth about, so this is kind of interesting because

these these are kind of mechanisms that are kind of just pure sensorum but there's also this kind of um the way those sensorum relate spatially into the environment and couple um you know what sort of statistical parameters are they relating to so yeah i thought that's kind of fits in with what you're saying


SPEAKER_00:
Yep, thanks for that.

And just to give one last comment on this generative versus a descriptive model, what reality hands us, the CSV that it hands the scientist or the images that it hands us from our sensory observations,

We could go just from the data and just identify, keep on going upstream until we have a model of the world.

And that's sort of correlation all the way down.

You can say, well, it was big and red, and you can keep on carrying that correlation between bigness and redness, but it's always just going to be correlational.

And then the other approach would be to go this back and forth between the observations and then an actual generative model where let's just say big and red cause each other, or there's a hidden cause that causes big and red to exist.

And then through expectation maximization, EM algorithms or other approaches,

fitting that generative model gives us a lot of power.

And it's very computationally tractable to fit the causal relationships that could generate the observed data.

And so the expectation maximization algorithm is a good starting point for people who want to learn more about this in the scientific instrumentalist perspective for the next Alejandra.


SPEAKER_02:
So, yeah, I was I was thinking this

I don't know how to say, maybe it's correct to say a boundary between this autopoietic process, thinking in a cell, for example, when we can talk about a generative model and allostasis processes on the other side, like only homeostatic processes.

So when you can

like observe a cell and okay this autopoiesis processes are driven by a generative model or they are just like more reactive and homeostatic I don't know but I was all the week long I was thinking if

there is like a boundary or any distinction or just to make an inference about metabolic changes in order to maintain these desired states or just react and compensate them.

I don't know, but I'm quite confused when taking this autoprojected theory about living things and then thinking about generative models inside this theory.

So I don't know if I'm clear.


SPEAKER_01:
I thought that was pretty clear.

I mean, so I should, you know,

provide the caveat that most inactivists, I think, vehemently disagree with me about this.

But my hot take on this is that the free energy principle completely kind of subsumes autopoietic inactivism, meaning that everything that an autopoietic inactivist can do within their framework, we can do better.

And the reason for that is that, well, so autopoiesis, right, is self-production.

And my understanding, at least, of this for having, I consider myself a kind of reformed inactivist.

This was like my main thing for a while until I stumbled upon the free energy principle.

So inactivists kind of start from the idea of autopoiesis, autonomy, and then kind of work out like how it works.

and what you can say on the basis of autopoyesis.

So the free energy stuff is cool, I think, because it explains to you how the autopoyesis gets established to begin with.

I mean, I haven't written about this, but I kind of feel like

like what Active Inference is doing is putting the adaptive loop first, right?

Rather than just saying, hey, look, there's this Markov boundary, you know, like an inactivist would, hey, look, there's this autopoietic boundary that's kind of producing itself.

Like the Active Inference framework is asking, so what is the set of processes that have to be in play such that a boundary can be maintained over time?

And then the generative model is really just kind of, it's a probability density over all of the states that are kind of

it's secluded behind the Markov blanket and that basically tells you, okay, well, so what are the values of these, uh, states behind the blanket that are allowable?

So look at a very simple, uh, example of this is, uh, so let's consider my, the boundary of my skin, you know, as the kind of organismic boundary for a second.

Well, uh, one of my internal states is core body temperature and my generative model has a kind of normative density.

over this state which says 36.5 degrees Celsius with a very small variance.

And when I'm detecting a discrepancy from that kind of preferred data point, I initiate action to bring myself back to that preferred data point.

So it's getting cold now, so I might put on a parka if I'm trending in the kind of negative direction.

I mean, the point about allostasis and homeostasis is interesting.

I think it's increasingly been worked out by people like Andrew Corcoran and Jacob Howie.

But I mean, like, you know, homeostasis is all about what I just said, right?

So you have a preferred data vector, and you're trying to get yourself as close as possible to that data vector, where that data vector is often going to be something like, okay, well, my body temperature or whatever.

Allostasis is about the control of that data vector, especially in response to stress and environments that are basically frustrating your desire for certain kinds of data.

I actually have a paper that we've been preparing for like a year and something now with Irene Arnaldo and Casper Hesp and Andrew.

Precisely on this issue, the paper is about depression as an allostatic disorder.

So the idea that, you know, if you need to continuously be involved in an allostatic process where you're always away from your kind of default data distribution that you would prefer, then it leads to basically a kind of inflammatory condition where you're kind of accumulating a chronic inflammation effectively from having to stay far away from your preferred kind of homeostatic set point.


SPEAKER_02:
Yeah, just adding something about that, and thank you, Maxwell.

Actually, I was, well, I am now a reform and activist also.

And thank you for that paper, the two-tail densities.


SPEAKER_01:
Thank you for reading it.


SPEAKER_02:
Yeah, but I don't know what you all think, but...

Is there still any space to reactive processes without inference?


SPEAKER_00:
Maybe I'll speak to the metabolism of angle on the reactive and on the predictive coding side.

Sorry, not predictive coding, just predictive modeling.


SPEAKER_01:
So we can think about like... And I just quickly... The one second response to this is like, well,

Inference here just means tuning statistical structure.

So it's nothing like, you know, that paper, A Tale of Two Densities, tries to make this point, I think.

The free energy formulation doesn't really, it's a bit counterintuitive, but it doesn't necessarily require you to explicitly compute and represent a prediction error in the way that predictive coding might, for example.

If you look at the math of it, the free energy only ever exists in the dynamics, and by that I mean,

the updates.

So you really just need a target data structure and some sensory data.

And that's enough to engage in active inference, if you're able to compute the difference between the two.

Yeah, and then it's just gradient descent.

If you have a mechanism that's in place that can track and keep a lid on that discrepancy, then you're engaging in active inference.

Like, it doesn't need to be, like, this explicit kind of computation.

So, you know, from that point of view, I'm always kind of shocked at the response of an activist to this kind of framework because I think it's everything that an activist would want, right?

Like, it doesn't involve explicit computation.

Whatever information, theoretic quantities are involved only exist in the dynamics.

I mean, you know...


SPEAKER_00:
Nice.

And just that last closing point on the metabolism and also to tie it to semiotics.

So a sugar molecule touching the tongue, it's through a receptor which transmits through neural signaling that sweetness and that might elicit in a reactive way the secretion of insulin.

But also insulin gets secreted in advance of a meal as well as in a circadian rhythmic way.

pattern that is adaptive over evolutionary time.

And so there's this meaning making of the sensory inputs of the sweetness of sugar isn't necessarily related to an impending spike.

In fact, artificial sweeteners are example that the sweet taste or the activation of that receptor doesn't necessarily entail a subsequent increase, although in our evolved history it did.

And so there's space in that whole

uh mechanism with the tongue and with the blood sugar and the pancreas there's space for reactive integration of stimuli through semiotics as well as for the predictive secretion of insulin in advance of a meal um i'm gonna go to the next slide because we're coming along pretty nicely so here i just found some funny you know memes about changing your mind and mind over matter and stuff

And the questions I put on here was first with a quote and then two questions.

The quote was, under the free energy principle, the system's posterior belief is refined or tuned under the generative model through a process of variational approximate Bayesian inference, and it becomes a tight bound on the true posterior belief it aspires to.

And so this sort of aspirational belief

uh way of phrasing what systems are trying to do it's not just that it wants to uh change its body temperature to be healthy it aspires to it um i was wondering what people thought about how might these bayesian posterior beliefs be related to consciously held beliefs or thoughts and then where might variously things like affirmations meditation education or propaganda fit into this

So all of these involve sensory as well as thought processes.

How do we figure that these Bayesian beliefs, which may or may not be consciously held, how does that relate?

Why can't we just change our mind to understanding the free energy principle or change our mind to

be different and these memes sort of suggest that it is possible.

And there's entire industries built around telling people, if you can change your mind, you can change your life.

But what actually enables someone to change their mind so that they can change their life?

And how should we think about that in this multi-scale, uh, cognitive framework, Steven.


SPEAKER_07:
This actually ties quite nicely into some of the work around mental space psychology.

If you've got a metaphor, like a metaphor can be a construct in a way which is a bit like the body, but we have like a mental model of how things fit together.

And if that metaphor is still the same, I can update my beliefs fairly quickly, right?

I can, if I'm still in my kind of like scientific chemistry paradigm or whatever,

can update my beliefs the challenge is when I have to transform or update my paradigm and reintegrate into a new metaphor so you've got this this in the way like you saying here this so this this idea of being able to do approximate Bayesian inference

kind of is quite quick and quite easy to do if you're recalibrating posteriors and sensory data and that into you know like the sense that like we're all working together you know and we're all going to try and work this team together and then if it shifts to being like I'm the boss now I've never been a boss before suddenly everyone has to do what I need to tell them

now suddenly my whole mental model of what it means to be at work has shifted now that can be something then that i have to do like doctors you have to learn your practice you have to relearn what that means because you have to reconfigure and then you can start to work at speed again so i think this this is quite quite a nice way to tie that together


SPEAKER_00:
Yeah, these are really just thoughts to raise.

We'll move on.

But just I wondered, okay, well, if the body is some, you know, if my arm is aspiring to be this length or aspiring to have, you know, this ratio of muscle to fat or something like that, where do our conscious beliefs fit into that?

And are those upstream of our phenotype?

Are they downstream?

Are they themselves a phenotype?

How do mental states influence our physical states and action?


SPEAKER_01:
I think it depends what you mean by conscious.


SPEAKER_00:
What do you mean by conscious?


SPEAKER_01:
Look, if by conscious you mean a form of reflexive access, then what you need there is a temporally or parametrically deep architecture.

So by that I mean, by temporally deep I mean that you don't want just a generative model that anticipates the next kind of data point that you'll be sensing, but you want the generative model that's capable of entertaining like temporally deep counterfactual like observations contingent on courses of action.

So you might think that if a system is able to

entertain possible counterfactual futures contingent on courses of action, then it would be more conscious than something that couldn't do that.

So our preferred approach recently is parametric depth.

We've been exploring this since a paper that actually was just accepted in neural computation called Deeply Felt Affect.

And so in that paper what we do is effectively induce a hierarchical model that is able to make inferences about its own inferences.

So by that I mean this model takes at a second layer of the generative model, it takes as its data for inference, like its observable states, the posterior state and precision estimations at the lower level.

So from that point of view, what these systems are able to do is have a rudimentary form of self-access, where they are able not just to make inferences about what's causing their data patterns, but inferences about their own inferences and how much they trust them.

So from that point of view, that might also get you slowly closer and closer to something like consciousness.

in the access consciousness sense of like, you know, having a kind of nested or reflexive access to states of your own being.

If you're talking about phenomenal consciousness, I think all bets are off.

I have no idea.

No idea whatsoever.

You know, hard problem.


SPEAKER_00:
That's a tough one.


SPEAKER_01:
It's a very hard problem.


SPEAKER_00:
Yep.

Well, it's just things to raise.

Let's go on to Alejandro.


SPEAKER_02:
Yeah, I was reading this image that if you can change your mind, you can change your life.

Maybe I can read this sentence the way around.

If you can change your life, you can change your mind.

In terms in this active engagement with

with the world.

So if you want to think differently, behave differently, it's not just a desire.

You have to do it.

So then considering that cognition is relational.

So all these Markov blankets and Markov blankets of Markov blankets.

So going up to your consciousness.

So by bodily interactions, I think is the only way you can

change your mind and be conscious about it.

So.


SPEAKER_00:
Sure, Sasha.


SPEAKER_04:
Yeah, I like that restatement of that, that fun phrase, if you can change your life, then you can change your mind, because that just reminds me, I mean, the reason we have all these sayings is because it is really hard to enact behavioral change and

it shouldn't be easy to change your mind because then you wouldn't have learning and memory and you wouldn't have these patterns that your life depended on.

And so thinking about what it means to change your mind or update your priors about something, like if I want to have a different lifestyle or exercise more or something like that, it's not just as simple as deciding that, then you actually have to follow through.

And so how to make that loop easier, um, to complete going from changing your actions to then updating your beliefs.

It's kind of like taking, it's like starting to take the first step before you know, which direction you're moving in.


SPEAKER_00:
Shannon.


SPEAKER_03:
I think this also brings in, um, so like Vygotsky or Piaget's work where you have your cognition scaffolded by an external teacher role.

And like once you're developed, you're not a child anymore.

The scaffolding role comes through propaganda or education or affirmations that are put forth by whatever our sociocultural group is or whatever our social media algorithms are throwing at us.

And so in as much as changing your behavior or changing your life,

can change your mind, also changing the way that you interact with the particular, the particular regime of attention, like the particular social group that you engage with, or that you are nudged to engage with through interactions on social media, or even just regular news media, all sort of like nudge in less volitional ways, your like Bayesian posterior beliefs in terms of

like conscious higher level beliefs about the world.


SPEAKER_00:
Agreed.

Well said.

It's not enough just to say I'm the kind of person who runs every morning because if you're not running, then you're going to be not having your sensory input aligned with your even stated beliefs.

So it takes actually the action to make that connection.

Steven?


SPEAKER_07:
Yeah, I think this is also like, I know if anyone's, you know, when you walk into a cathedral, it's like if you want someone to feel a sense of awe and start to take their consciousness up to the heavens, you know, walk into a 400 foot high cathedral and it will do a lot to you, you know?

And so it's the way that, and it's not necessarily anyone there saying you should believe in God or not straight away anyway, right?


SPEAKER_00:
Yep, let's go through these last few slides because we'll also try to get that figure in.

So just some brief notes on free energy minimization.

A quote from the paper was, under the free energy principle, cognition is what the recognition density or living system does, i.e.

changing to elude surprises and maintaining informational homeostasis by minimizing free energy.

and the way one studies cognition.

So there we're again returning to this double instrumentalism, and we're going to return to this again in our subsequent week's discussions on A Tale of Two Densities.

And the way one studies cognition, i.e.

what the system does, is by developing, simulating, and analyzing the possible generative models that explain how the recognition density of interest, the system of interest, changes so as to attain the minimal free energy.

The mechanics of belief is the only causally relevant aspect of the variational free energy.

The free energy may or may not exist.

What is at stake is the causal consequences of the action-guiding beliefs of organism and groups of organisms, which are harnessed and finessed in the generative model.

What matters is that organisms are organized such that they instantiate such a prior to guide their actions.

And it's not an accident that organism and organization and organ are all related.

And just to show some brief images from a very nice Active Inference tutorial.

Here we can see that there's a generative process on the top.

It's a forest, I guess.

And it is moving through true states.

But those true states are hidden.

And so that's whether or not it's real, that's what's happening.

And observations, the O, are being emitted.

And that's the partially observable Markov model, which we, again, will return to later.

And then what the organism is involved in are changing its own state through time of its generative model with all these caveats and richness that we've been discussing and the actions end up influencing the state or not.

And then that in the next time step provides new observations that update the model.

And then just to look for a second at where free energy fits into this so that like in each of our discussions, we can kind of bridge from the experiential components to the practice, to the scientific theory, and a little bit of the math.

What is being shown here is that if the organism wants to be minimizing its surprise,

And Maxwell, you can fill me in or correct here.

If the organism wants to be minimizing its surprise, which is on the Y axis, and the less surprising, the better, given a adaptive generative model of the world, what it can actually do instead of just on the left side, this function of expectation, that's the blue line.

The way to minimize this is actually to try minimizing the free energy.

And the free energy is a lot more tractable to compute.

And it turns out that it is strictly bounded in a way where by minimizing the free energy, you go quite a long way to minimizing your surprise because they're very closely related in a mathematical sense.


SPEAKER_01:
Well, I mean, we have to keep in mind that what's going on here is that the organism is trying to sample the environment

such that the new data that it's receiving is consistent with its preferences about data.

So it's not just a retrospective kind of let's try to fit a model to this data.

It's about a kind of forward-looking kind of sampling strategy.

This is why we, in this other paper that we'll be discussing next week, we argue that this whole framework is inactive fundamentally.

Basically, you can cast any action whatsoever in terms of trying to bring about a preferred data structure.

If you want to wax a little philosophical, you can even relate this to a phenomenology.

I said I have no idea how this active inference stuff relates to phenomenology, but my suspicion

this is pure speculation, but my suspicion is that phenomenal properties kind of correlate with the observable states.

So that it's really like the patterns of observation that you're receiving at any time kind of feel like something.

And then there's like an interpretation of that feeling, which is more like the access dimension.

So that might go some way towards kind of resolving some of these issues.

But yeah, from that point of view, like,

the organism is trying to get to the phenomenology that it prefers, which I think is kind of amenable to, you know, some, some cool, like properly phenomenological kind of accounts of what's going on.

I mean, you know, Deleuze makes this point in, I forget which one of these, but you know, like what is desire, right?

Well, desire is the desire for a certain constellation of things, right?

It's not just like for a thing, at least in Deleuze's thing, like it's,

It's like, you know, you're, you're looking for like, you're looking to inactive inferences, you're, you're looking to sample a data structure that's sort of consistent with the way of being that you are, you know?


SPEAKER_00:
Uh, yeah.

Yeah.

And if you, uh, people want different things and yes, agreed.

It's a constellation, not just obtaining that singular object, Steven.


SPEAKER_07:
Yeah, I could ask you a quick question, Maxwell.

I was wondering, is there, like, a shift from, like, active inference dynamics to, as a kind of a way of thinking, to active inference as sense-making?

Like, does sense... Like, is it active inference all the way up and sense-making all the way at the organism level, or is there a transition when you'd use... It depends.


SPEAKER_01:
Again, it depends whether you mean this more kind of explicit sense-making or this more... If by sense-making you just mean, like,

in like interacting intelligently and by that i mean like adaptively appropriately or whatever with an environment then it's all the way up and all the way down in effect like cells and you know cells in a body and people at a at a dinner table are trying to do the same kind of thing um

I think for the more kind of reflexive, explicit forms of sense-making that you're concerned with in your practice, you would need some kind of layered system.

So sense-making in that sense has more to do with our narrative stuff that was discussed a few weeks ago.

It has more to do with creating these kind of overarching inferential structures that make sense of your phenomenal flow effectively.


SPEAKER_07:
Yeah, actually that makes sense in the sense that I've – one thing that bugs me at the higher levels – well, not higher levels, but these – is people just use the word sense-making.

Like they're using the media at the moment to talk about wicked problems and all of this.

But what does sense-making mean when it's not –

an actual thing that someone's doing so like you either have to say like narrative sense making okay i'm taking narratives and making sense of it i'm you know tends to just be this word now that's become trendy but it oh yeah and in fact some inactivists are even pushing back on it to say that well it doesn't really mean very much uh dan huto and eric nian have these really nice critiques of like the sense making paradigm sasha


SPEAKER_04:
My follow-up question to that is, what isn't sense-making?


SPEAKER_01:
Well, again, it depends, I guess, on how we want to define it.

basically active inference describes more specifically the behavior of systems that are actually driven in some non-trivial way by uh like the beliefs that they encode about an external environment and you might see this as a continuum thing but i mean there's a sense in which like if a rock is trying to predict its environment and act in a way that you know minimizes this

divergence between well it's not a very good model right i mean it doesn't do very much uh so i mean this might be a graded thing in the sense that like you know a uh like things that are not sense making are things that don't seem to reflect this kind of intelligent you know adaptation to the constraints of an environment like a rock right uh

But for people like Stephen who mean something very specific and I think more psychological and meaningful and loaded, if that's what we mean by sense-making, then the vast majority of what we would call sense-making under the other definition doesn't fall under it.

So you really need a very specific kind of system that's able to engage in a very specific form of inference.

Unfortunately, I'm going to have to leave at this point.


SPEAKER_00:
Thanks, Maxwell.

See you soon.


SPEAKER_01:
Thank you very much, everyone.

This was very fun.

Bye.


SPEAKER_07:
Also, there's this sense of sense-breaking or sense-finding.

So it could be that sense-making is okay.

And it works, makes sense at the shorter timescales.

Participatory sense-making is like this ongoing knowing how to act.

But then when you get to these higher levels, like sense-making really is more like you've made, there's retrospective sense-making,

which is really what ends up being what people think about sense-making at scale, is how do I make sense of how I should have acted?

But if you can get someone to, that normally is it because, so that either means someone's just doing something habitual or tacit knowledge where they're in the flow and you're trying to unpack the sense-making that allowed them to do that, but that's not accessible because you're so in the flow, so you need to have some form of sense-breaking

And then there's a sense finding, which I would say is more like active inference, because you're more consciously trying to repurpose your posterior beliefs and your sensory data to try and assemble some sort of understanding of what's even going on.

It might be that point of stuckness.

You know, they talk about stuckness.

So stuckness is...

Once you're trying to get to sense-making, but while you're stuck,

you may need to go off and do a bit of foraging.

So it's interesting.


SPEAKER_00:
Cool.

Let's just go through these last few thoughts and then we'll just go to figure six because we had talked last time about seeing it.

So on this slide, we are going to be asking, are there limits on the kind of cognition that we can study as humans because of our own individual cognitive processes and where does collective cognition play into this?

Which systems are we in a position to understand and how would we know?

How would we do metacognition as individuals or groups about what approaches for which systems will be valuable?

And then in the future experiments and in the implications of, okay, we've moved beyond internalism and externalism, all these other isms, what is that going to mean for our practice as scientists or as investigators of cognitive systems?

And what would be the implications of knowing?

I'm just going to raise them just so we can get them on there, but maybe for another time or in the closing thoughts.

And then there was this idea in the paper, the relevant boundaries of cognition depend on the level being characterized and the explanatory interests that guide investigation.

So we can return to this general question, where are the relevant boundaries for cognition and how would we know if we're too internal or too external?

And then in the paper they wrote, in other words, drawing the bounds of cognition means defining the recognition density of the system of interest and identifying a generative model that explains changes in that system that follow variational Bayesian inference.

And I believe it was Sasha who asked, isn't this the same argument that is used for holism or reductionism?

For example, they'll say something like, we'll know when we've gotten to too large of a scale of analysis or too small of a scale of analysis because our model will break or it will be inadequate or intractable.

So how do we get beyond that paradigm of we'll know it when we see it or can we ever understand?

get beyond the paradigm of we'll know it when we see it guided by a certain framework because we are in feedback with our models so just things to think about and then i think let's just briefly look at figure six and then have some closing thoughts so figure one was about markov blankets figure two went into the action perception loop and introduced some of the equations of fep those were unpacked a bit in figure 2b

Figure 3 was operational closure in graphs.

Figure 4 was a schematic illustration of autocatalysis, which is like autopoiesis for metabolism.

Figure 5 was that fractal Markov blanket showing that as you zoom into the broccoli, you see that it's Markov all the way down.

And here we are in figure six.

So if anyone wants to have any comments on six because we had said that we were going to approach it in this discussion, they can just raise their hand.

But the way I would walk through this figure first is by reading the caption.

And what the caption suggested was that it's going to be something like a developmental morphogenesis scenario.

So these are not naive cells.

It's really important to take that evolutionary perspective.

The organism is an arrangement that's a developmental outcome that isn't just an arbitrary developmental state.

It's one that has lasted through many generations, been fine-tuned acutely.

so these aren't just naive little cells wandering around spontaneously um coming to this arrangement that's shown in figure f um it's uh rather a very carefully selected set of expectations about which extracellular target signals like diffusible morphogens

the cell expects to see.

And so it knows that if it just pursues its expectation of the target signal extracellularly, it will be taking part of a larger developmental outcome that is evolutionarily adapted.

So the cell doesn't need to have a cognitive awareness of that, but we can think about this like an anterior to posterior gradient of some diffusible morphogen.

And what's happening, each of these traces on figure A and B and C are through time on the X axis showing like what one cell ends up experiencing, whether it's its expectation of a morphogen.

Again, that's the sensory input in this model or its action reflected by its ability to move.

Then in figure D, we see the free energy of the system first slightly rise, but then immediately start converging down, down, down, down, down, which reflects overall that there's an increased precision in the ensemble, in the aggregate of these cells as they sort of jostle into place and come into an arrangement that minimizes their surprise about what extracellular target signal they should be perceiving.

And what we see is that even though there's no higher level coordination per se, the agents end up converging on this solution that reflects the target morphology.

In this case, it looks like, I don't know, kind of a upside down light bulb or something.

Not sure what shape that would be.

But you can see how each of these different colored cells is able to be uniquely determining where its position is.

Like the green cell, it can be thinking something like, I want to be close to blue, but far from yellow and totally far from red.

The blue cell might be thinking something like, I want to have an intermediate level of the green and the yellow signal.

And then the red cells might be thinking something like, I want to have mostly red signal and then in decreasing order, yellow, blue, green.

and then depending on what the instantaneous perception is of those diffusible morphogens the cells can either uh update their generative model of the world through movement that's the morphogenesis component or by changing their generative model which isn't actually happening like there's no learning and adaptation within this model but over evolutionary time

it will end up being the case that developmental trajectories that robustly enable high fitness morphologies to arise will be selected for.

So that's sort of my short take on figure six.

Any comments or thoughts on that?

Cool, just because we're basically out of time, I'll just say thanks everyone for participating, and we'll have a closing thought as well.

We're gonna provide a follow-up form for our live participants.

I'll put that in the chat in a second.

We request feedback, suggestion, and questions from all of our viewers and our participants.

And we just hope that people stay in communication with us and keep watching.

Next week and the following week, we're going to be talking about A Tale of Two Densities, which is the paper that we mentioned a few times today.

And yeah, it's going to be a great discussion next two weeks as well.

So if anyone has any closing thoughts on the discussion, while I post the link in here, they're free to go ahead.

If any thoughts, otherwise that was a great discussion.


SPEAKER_04:
Cool.

Yeah.

Thank you for the discussion.


SPEAKER_00:
That was great.

Awesome.

Thank you.

In that case, I am going to terminate the live stream.

Thanks everyone for participating and for watching.

We'll see you in the next two weeks for number six, a tale of two.