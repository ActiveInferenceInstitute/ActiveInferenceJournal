1
00:00:08,000 --> 00:00:08,880
好的，

2
00:00:08,880 --> 00:00:11,759
你好，欢迎大家观看主动

3
00:00:11,759 --> 00:00:13,200
推理直播

4
00:00:13,200 --> 00:00:15,120
这是主动推理直播，

5
00:00:15,120 --> 00:00:17,279
编号 8.0，

6
00:00:17,279 --> 00:00:20,640
现在是 2020 年 11 月 4 日

7
00:00:20,640 --> 00:00:23,920
，我是丹尼尔·弗里德曼，我今天将进行

8
00:00:23,920 --> 00:00:28,000
单独的情境化讨论，

9
00:00:28,000 --> 00:00:30,960
欢迎来到 teamcom，大家我们

10
00:00:30,960 --> 00:00:33,280
是在线实验

11
00:00:33,280 --> 00:00:35,200
与主动推理相关的团队交流学习和实践

12
00:00:35,200 --> 00:00:37,200
您可以

13
00:00:37,200 --> 00:00:38,960
在我们的推特帐户

14
00:00:38,960 --> 00:00:40,640


15
00:00:40,640 --> 00:00:43,360
inferenceactive 在我们的

16
00:00:43,360 --> 00:00:45,120
公钥基础团队

17
00:00:45,120 --> 00:00:48,160
或我们的 youtube 频道上找到

18
00:00:48,160 --> 00:00:49,120


19
00:00:49,120 --> 00:00:51,360


20
00:00:51,360 --> 00:00:53,120
我们 这样我们就可以

21
00:00:53,120 --> 00:00:54,719
改进我们的工作

22
00:00:54,719 --> 00:00:56,559
，欢迎所有背景和观点在

23
00:00:56,559 --> 00:00:58,559
这里，

24
00:00:58,559 --> 00:01:00,719
就直播的视频礼仪而言，如果

25
00:01:00,719 --> 00:01:02,160
您的背景中有噪音，

26
00:01:02,160 --> 00:01:03,440
请举手，这样我们就可以听到

27
00:01:03,440 --> 00:01:05,680
每个人使用尊重的言语行为

28
00:01:05,680 --> 00:01:06,880
等，

29
00:01:06,880 --> 00:01:10,159
所以首先宣布的是

30
00:01:10,159 --> 00:01:12,400
我们已经为 2020 年所有会议选择了其余肌动蛋白流的论文以及日期

31
00:01:12,400 --> 00:01:13,200
和时间

32
00:01:13,200 --> 00:01:15,200


33
00:01:15,200 --> 00:01:17,119


34
00:01:17,119 --> 00:01:19,759
2020 年剩余时间的 gs 将从

35
00:01:19,759 --> 00:01:22,159
太平洋标准时间上午 7 点 30 分到上午 9 点进行

36
00:01:22,159 --> 00:01:24,240
，论文将阅读第

37
00:01:24,240 --> 00:01:26,159
8 篇正在扩展主动推理，

38
00:01:26,159 --> 00:01:27,439
这

39
00:01:27,439 --> 00:01:30,400
就是 8.0 的内容，这

40
00:01:30,400 --> 00:01:33,119
将在 11 月 10 日和 17 日

41
00:01:33,119 --> 00:01:34,960
发表，论文 9 将是 投射

42
00:01:34,960 --> 00:01:36,560
意识模型和现象

43
00:01:36,560 --> 00:01:39,200
自我 2018 年论文

44
00:01:39,200 --> 00:01:41,759
论文 10 将成为脚本的变体

45
00:01:41,759 --> 00:01:42,880
方法

46
00:01:42,880 --> 00:01:45,200
论文 11 是复杂的主动

47
00:01:45,200 --> 00:01:47,119
推理有效信息抱歉

48
00:01:47,119 --> 00:01:48,880
模拟

49
00:01:48,880 --> 00:01:51,840
想象未来事件的预期有效动态

50
00:01:51,840 --> 00:01:53,280
，你可以看到所有这些事件的日期

51
00:01:53,280 --> 00:01:55,119


52
00:01:55,119 --> 00:01:57,360
如果您有可能

53
00:01:57,360 --> 00:01:58,799
参加，

54
00:01:58,799 --> 00:02:00,719
并且如果您有一个时区或

55
00:02:00,719 --> 00:02:02,159
您想要参加的活动类型，请不时留出

56
00:02:02,159 --> 00:02:04,240
此处未反映的情况，只需让我们知道

57
00:02:04,240 --> 00:02:06,479
，我们的推特地址

58
00:02:06,479 --> 00:02:07,680
就可以了，

59
00:02:07,680 --> 00:02:10,959
所以这就是活动中将要发生的事情

60
00:02:10,959 --> 00:02:14,800
流 8.0 这个

61
00:02:14,800 --> 00:02:17,120
本次演讲的目标是

62
00:02:17,120 --> 00:02:20,000
为 8.1 和 8.2 设置上下文，

63
00:02:20,000 --> 00:02:21,040
这将在

64
00:02:21,040 --> 00:02:23,360
同一篇论文中扩展主动推理 这

65
00:02:23,360 --> 00:02:24,560
是

66
00:02:24,560 --> 00:02:27,760
alex chance baltierri seth 和 buckley

67
00:02:27,760 --> 00:02:29,200
于 2019

68
00:02:29,200 --> 00:02:35,040
年撰写的论文，存档 1911.10601

69
00:02:35,040 --> 00:02:36,800
该视频是

70
00:02:36,800 --> 00:02:38,879
对其中一些想法的背景的介绍，它

71
00:02:38,879 --> 00:02:39,599
不是评论

72
00:02:39,599 --> 00:02:42,000
或最终结论，我绝对

73
00:02:42,000 --> 00:02:43,920
只是通过阅读论文和研究学到了很多东西

74
00:02:43,920 --> 00:02:47,440
对于这个

75
00:02:47,440 --> 00:02:50,080
演示，我的想法是，这个视频将把

76
00:02:50,080 --> 00:02:52,080
shantz 论文的

77
00:02:52,080 --> 00:02:55,040
数学、符号和词汇的一些想法背景化，

78
00:02:55,040 --> 00:02:56,640


79
00:02:56,640 --> 00:02:58,480
并且视频应该可以访问，

80
00:02:58,480 --> 00:03:00,480
尽管这也希望是很酷

81
00:03:00,480 --> 00:03:03,680
的前沿研究

82
00:03:03,680 --> 00:03:06,159
和妙语，不用担心 如果它还

83
00:03:06,159 --> 00:03:07,680
没有意义或含义

84
00:03:07,680 --> 00:03:08,879


85
00:03:08,879 --> 00:03:11,599
尚不清楚，那么主动推理是可扩展的并且

86
00:03:11,599 --> 00:03:12,720
它也是同源的，

87
00:03:12,720 --> 00:03:14,640
因此它

88
00:03:14,640 --> 00:03:15,920


89
00:03:15,920 --> 00:03:18,640


90
00:03:18,640 --> 00:03:21,440
类似于控制理论或机器学习等类似空间

91
00:03:21,440 --> 00:03:25,120
中的其他常见算法，并且可能比 8.0 中的其他常见算法更可取 第一

92
00:03:25,120 --> 00:03:28,879
部分将介绍

93
00:03:28,879 --> 00:03:30,560
他们在本文中使用的所有关键字的背景

94
00:03:30,560 --> 00:03:33,040
，

95
00:03:33,040 --> 00:03:35,599
然后讨论他们提供的目标 tract

96
00:03:35,599 --> 00:03:37,680
和 roadmap

97
00:03:37,680 --> 00:03:40,959
然后 8.0 的第二部分将是

98
00:03:40,959 --> 00:03:42,879
关键方程注释

99
00:03:42,879 --> 00:03:44,879
和引文演练，我们

100
00:03:44,879 --> 00:03:46,000
将像 80 20 那样做。

101
00:03:46,000 --> 00:03:48,959
所以大多数符号大部分

102
00:03:48,959 --> 00:03:49,840
含义但

103
00:03:49,840 --> 00:03:52,959
不是所有部分不是所有符号

104
00:03:52,959 --> 00:03:55,920
和 然后讨论图 1 和图

105
00:03:55,920 --> 00:03:56,400
2

106
00:03:56,400 --> 00:03:58,400
以及它们代表什么以及它们如何

107
00:03:58,400 --> 00:04:00,799
支持论文的结论

108
00:04:00,799 --> 00:04:04,640
，然后在 8.1 和 8.2 中，我们将聚

109
00:04:04,640 --> 00:04:06,720
在一起讨论同一篇论文，

110
00:04:06,720 --> 00:04:08,560
所以保存并提交您的问题或将

111
00:04:08,560 --> 00:04:10,319
它们作为评论和

112
00:04:10,319 --> 00:04:12,560
如果你想参与这个

113
00:04:12,560 --> 00:04:15,920
，那就联系吧，让我们从关键词开始

114
00:04:15,920 --> 00:04:17,680


115
00:04:17,680 --> 00:04:19,839


116
00:04:19,839 --> 00:04:21,199


117
00:04:21,199 --> 00:04:23,040


118
00:04:23,040 --> 00:04:25,280
关于那个领域，

119
00:04:25,280 --> 00:04:28,080
希望它们是人工智能

120
00:04:28,080 --> 00:04:28,800


121
00:04:28,800 --> 00:04:31,759
机器学习，他们还提到了

122
00:04:31,759 --> 00:04:33,040
强化学习

123
00:04:33,040 --> 00:04:36,000
和基于模型的强化学习

124
00:04:36,000 --> 00:04:36,560
，然后是

125
00:04:36,560 --> 00:04:38,320
系统、控制和

126
00:04:38,320 --> 00:04:40,240
信息 理论，然后是一个不在

127
00:04:40,240 --> 00:04:40,479


128
00:04:40,479 --> 00:04:42,479
纸上但我们可以在这里添加的关键字，

129
00:04:42,479 --> 00:04:43,840
当然是主动推理和自由

130
00:04:43,840 --> 00:04:45,280
能原理，

131
00:04:45,280 --> 00:04:48,639
所以这些关键字中的每一个肯定

132
00:04:48,639 --> 00:04:49,680
你可以有一个

133
00:04:49,680 --> 00:04:52,720
课程或一个博士学位，所以

134
00:04:52,720 --> 00:04:54,240
它们中的每一个都是 将获得

135
00:04:54,240 --> 00:04:56,160
一张幻灯片，

136
00:04:56,160 --> 00:04:58,960
因此当然要更深入地研究提到的资源

137
00:04:58,960 --> 00:04:59,600


138
00:04:59,600 --> 00:05:02,560
或找到其他教授这些

139
00:05:02,560 --> 00:05:04,000
技术的课程，因为它们有很多

140
00:05:04,000 --> 00:05:05,280


141
00:05:05,280 --> 00:05:07,120


142
00:05:07,120 --> 00:05:08,560
内容

143
00:05:08,560 --> 00:05:10,479
使用数学和这篇研究

144
00:05:10,479 --> 00:05:12,240
论文，只知道其他

145
00:05:12,240 --> 00:05:14,080
人对这些主题的

146
00:05:14,080 --> 00:05:15,120


147
00:05:15,120 --> 00:05:18,560


148
00:05:18,560 --> 00:05:21,840


149
00:05:21,840 --> 00:05:24,160


150
00:05:24,160 --> 00:05:25,120


151
00:05:25,120 --> 00:05:27,280


152
00:05:27,280 --> 00:05:29,199


153
00:05:29,199 --> 00:05:31,759
看法也是如此 人类

154
00:05:31,759 --> 00:05:33,280
和动物，

155
00:05:33,280 --> 00:05:36,240
所以即使使用这个定义，或者

156
00:05:36,240 --> 00:05:37,680
我将在一秒钟内得到的替代定义，

157
00:05:37,680 --> 00:05:38,479


158
00:05:38,479 --> 00:05:41,280
我们可以说人工智能在今天

159
00:05:41,280 --> 00:05:42,240
2020 年的结果

160
00:05:42,240 --> 00:05:45,039
是什么 产生地图政策

161
00:05:45,039 --> 00:05:47,039
个人和集体政策

162
00:05:47,039 --> 00:05:49,120
推荐引擎 它产生

163
00:05:49,120 --> 00:05:51,280
加密技术和安全性

164
00:05:51,280 --> 00:05:53,440
它与分类算法

165
00:05:53,440 --> 00:05:55,039
和影响我们

166
00:05:55,039 --> 00:05:58,800


167
00:05:58,800 --> 00:06:01,600
所有人的事物

168
00:06:01,600 --> 00:06:02,960
有关 他们的

169
00:06:02,960 --> 00:06:06,000
自然世界和一切都是自然

170
00:06:06,000 --> 00:06:09,520
的，因为它存在于世界中，因此通过

171
00:06:09,520 --> 00:06:11,759
假设存在一种人工类型

172
00:06:11,759 --> 00:06:13,120
的认知

173
00:06:13,120 --> 00:06:15,759
，这种认知在某种程度上是独特的，而不是

174
00:06:15,759 --> 00:06:17,199


175
00:06:17,199 --> 00:06:20,400
由人类制定的扩展或嵌入，这会做

176
00:06:20,400 --> 00:06:21,840
一些不是很有帮助的事情，而且

177
00:06:21,840 --> 00:06:24,000
其他一些很好的

178
00:06:24,000 --> 00:06:26,720
讨论这个话题只是为了

179
00:06:26,720 --> 00:06:28,319
让它朝着积极的方向发展

180
00:06:28,319 --> 00:06:30,000


181
00:06:30,000 --> 00:06:31,919


182
00:06:31,919 --> 00:06:35,360


183
00:06:35,360 --> 00:06:36,720


184
00:06:36,720 --> 00:06:38,720


185
00:06:38,720 --> 00:06:41,600
使用计算机进行统计，但

186
00:06:41,600 --> 00:06:43,520
基本上是笔和纸

187
00:06:43,520 --> 00:06:45,759
可以慢慢完成的事情，所以关于

188
00:06:45,759 --> 00:06:47,440
矩阵计算的事情 e 关于

189
00:06:47,440 --> 00:06:51,680
用计算机对大数据进行统计的

190
00:06:51,680 --> 00:06:54,560
另一种方式，今天的人工智能

191
00:06:54,560 --> 00:06:55,280
就像

192
00:06:55,280 --> 00:06:57,919
人类在循环中人工智能，所以人类在

193
00:06:57,919 --> 00:06:59,520
循环中人工智能可以

194
00:06:59,520 --> 00:07:02,160
描述地图或推荐引擎，以

195
00:07:02,160 --> 00:07:04,400
强调它在使用过程中一直是人类代理

196
00:07:04,400 --> 00:07:05,039


197
00:07:05,039 --> 00:07:07,120
可供性以及

198
00:07:07,120 --> 00:07:08,720
希望在设计者

199
00:07:08,720 --> 00:07:10,479
认为的

200
00:07:10,479 --> 00:07:13,039
另一种人工智能措辞中可能会

201
00:07:13,039 --> 00:07:13,599
有所帮助，

202
00:07:13,599 --> 00:07:16,400
并且也将人类在

203
00:07:16,400 --> 00:07:17,199
决定

204
00:07:17,199 --> 00:07:19,039
如何使用它以及如何设计它方面的作用居中，这是

205
00:07:19,039 --> 00:07:20,560
智能增强，它

206
00:07:20,560 --> 00:07:22,400
澄清了作为我们谁被

207
00:07:22,400 --> 00:07:24,400
增强或 甚至比人工智能更笼统的

208
00:07:24,400 --> 00:07:26,080
措辞只是人类

209
00:07:26,080 --> 00:07:27,280
技术利基

210
00:07:27,280 --> 00:07:28,639
，它还包括

211
00:07:28,639 --> 00:07:30,720
我们利基的物理方面，例如我们

212
00:07:30,720 --> 00:07:32,400
在 7.2 中讨论的内容，

213
00:07:32,400 --> 00:07:34,240
但这将

214
00:07:34,240 --> 00:07:35,680
包括不

215
00:07:35,680 --> 00:07:37,759
只是在硅芯片和

216
00:07:37,759 --> 00:07:39,280
他们的交互，人工智能

217
00:07:39,280 --> 00:07:42,960
捕获了所有正确的机器学习，

218
00:07:42,960 --> 00:07:46,000
所以机器学习

219
00:07:46,000 --> 00:07:47,840
有很多话要说，这是一个很大的领域，

220
00:07:47,840 --> 00:07:49,039
但主要的

221
00:07:49,039 --> 00:07:51,440
机器学习顶部

222
00:07:51,440 --> 00:07:52,800
在本文中发挥作用的 ics

223
00:07:52,800 --> 00:07:55,199
是强化学习和

224
00:07:55,199 --> 00:07:57,199
基于模型的强化学习，

225
00:07:57,199 --> 00:08:01,039
因此简单的强化学习器

226
00:08:01,039 --> 00:08:04,560
是环境中的

227
00:08:04,560 --> 00:08:06,000
代理，代理

228
00:08:06,000 --> 00:08:08,800
采取行动，作用于

229
00:08:08,800 --> 00:08:09,520
环境

230
00:08:09,520 --> 00:08:12,240
，然后环境发回

231
00:08:12,240 --> 00:08:14,000
状态和奖励

232
00:08:14,000 --> 00:08:15,759
，所以有时 它直接发回

233
00:08:15,759 --> 00:08:17,199
状态

234
00:08:17,199 --> 00:08:20,080
，然后

235
00:08:20,080 --> 00:08:21,039


236
00:08:21,039 --> 00:08:23,280
通过代理的感知层理解奖励，其他

237
00:08:23,280 --> 00:08:24,960
时候环境直接将奖励发

238
00:08:24,960 --> 00:08:27,599


239
00:08:27,599 --> 00:08:29,520
回基于模型的强化学习

240
00:08:29,520 --> 00:08:31,840
建立的地方，这是通过

241
00:08:31,840 --> 00:08:34,080
引入这个模型，这里用红色勾勒出来

242
00:08:34,080 --> 00:08:35,039


243
00:08:35,039 --> 00:08:38,320
在这些类型的基于模型的

244
00:08:38,320 --> 00:08:39,440
强化学习中，

245
00:08:39,440 --> 00:08:41,599
而不是学习这些

246
00:08:41,599 --> 00:08:42,880


247
00:08:42,880 --> 00:08:46,640
成功行为和

248
00:08:46,640 --> 00:08:49,440
奖励之间的简单原始联系以及学习作为行为

249
00:08:49,440 --> 00:08:50,640
相关性

250
00:08:50,640 --> 00:08:53,040
，基于模型的强化学习者

251
00:08:53,040 --> 00:08:54,800
能够拥有一个模型，

252
00:08:54,800 --> 00:08:57,279
例如，跑步现在很痛苦，

253
00:08:57,279 --> 00:08:58,640
但后来 我以后会感觉好些

254
00:08:58,640 --> 00:09:01,360
，所以它允许一个人

255
00:09:01,360 --> 00:09:03,600
追求目标

256
00:09:03,600 --> 00:09:06,640
为了达到

257
00:09:06,640 --> 00:09:08,800
更大的长期目标，帽子会暂时呃不愉快，所以想想在一个

258
00:09:08,800 --> 00:09:10,560
小迷宫中你知道

259
00:09:10,560 --> 00:09:13,680
不仅要贪婪地走向出口，而且

260
00:09:13,680 --> 00:09:15,040
要后退一步

261
00:09:15,040 --> 00:09:18,080
向前迈出两步，所以

262
00:09:18,080 --> 00:09:20,160
相似之处在于代理人是

263
00:09:20,160 --> 00:09:22,000
在环境中或在环境中采取行动，并且

264
00:09:22,000 --> 00:09:24,000
他们的行动源于

265
00:09:24,000 --> 00:09:25,760
作为行动模型的政策，

266
00:09:25,760 --> 00:09:28,080
所以什么是可能的，什么是不可能的，这些可能

267
00:09:28,080 --> 00:09:29,200


268
00:09:29,200 --> 00:09:32,000
与有机体

269
00:09:32,000 --> 00:09:33,120
实际可以或不能做的事情

270
00:09:33,120 --> 00:09:35,519
同时发生，但至少它是

271
00:09:35,519 --> 00:09:37,440
最终被这个

272
00:09:37,440 --> 00:09:40,160
有机体实现的东西 代理

273
00:09:40,160 --> 00:09:41,440
根据

274
00:09:41,440 --> 00:09:43,040
他们从环境

275
00:09:43,040 --> 00:09:45,760
中得到的奖励以直接的方式或以象征性的方式

276
00:09:45,760 --> 00:09:48,800
或以他们学习的基于模型的方式修改他们的行动策略，

277
00:09:48,800 --> 00:09:51,680
或者使用贝叶斯措辞他们

278
00:09:51,680 --> 00:09:52,800
更新他们的模型，

279
00:09:52,800 --> 00:09:54,080
所以 无论如何，它将是

280
00:09:54,080 --> 00:09:55,600
计算的，因为我们将

281
00:09:55,600 --> 00:09:57,279
使用计算机和

282
00:09:57,279 --> 00:10:00,080
数学来描述它，但是贝叶斯主义者

283
00:10:00,080 --> 00:10:00,800
会说，

284
00:10:00,800 --> 00:10:03,440
就像先验更新了证据以

285
00:10:03,440 --> 00:10:05,279
生成 p  osterior

286
00:10:05,279 --> 00:10:06,560
并且有多种方法

287
00:10:06,560 --> 00:10:08,320
可以完成这种学习或更新

288
00:10:08,320 --> 00:10:09,519
另一个相似之处是

289
00:10:09,519 --> 00:10:11,519
环境向代理发送奖励或信号，

290
00:10:11,519 --> 00:10:13,200


291
00:10:13,200 --> 00:10:16,399
而要考虑的一个辩论或问题领域

292
00:10:16,399 --> 00:10:16,880


293
00:10:16,880 --> 00:10:19,200
是观察奖励或奖励

294
00:10:19,200 --> 00:10:20,800


295
00:10:20,800 --> 00:10:22,320
如何 自我学习奖励

296
00:10:22,320 --> 00:10:23,920
有机器学习算法也

297
00:10:23,920 --> 00:10:25,920
有这种方法

298
00:10:25,920 --> 00:10:28,320
，然后观察是否象征

299
00:10:28,320 --> 00:10:29,120
或

300
00:10:29,120 --> 00:10:30,959
表明奖励或者我们

301
00:10:30,959 --> 00:10:32,399
如何认为这些是

302
00:10:32,399 --> 00:10:34,160
强化学习和行为

303
00:10:34,160 --> 00:10:35,040
算法

304
00:10:35,040 --> 00:10:38,079
可以应用于两者的方式 抽象数据

305
00:10:38,079 --> 00:10:40,000
分类

306
00:10:40,000 --> 00:10:41,440
方法聚类和类似的

307
00:10:41,440 --> 00:10:43,839
事情以及直接的行动计划

308
00:10:43,839 --> 00:10:45,279
，事实证明，主动

309
00:10:45,279 --> 00:10:46,640
推理将与强化学习相关，

310
00:10:46,640 --> 00:10:48,240
这是一种有趣的方式，这就是

311
00:10:48,240 --> 00:10:50,560
为什么作者

312
00:10:50,560 --> 00:10:53,760
现在在现代背景下将它作为关键字

313
00:10:53,760 --> 00:10:55,200


314
00:10:55,200 --> 00:10:58,720
学习将使用

315
00:10:58,720 --> 00:11:00,720
例如神经网络来实现，在这种

316
00:11:00,720 --> 00:11:02,720
情况下，我们有 环境

317
00:11:02,720 --> 00:11:05,839
将状态发送到代理上的状态 s

318
00:11:05,839 --> 00:11:07,680
，这将通过

319
00:11:07,680 --> 00:11:10,000
某种深度神经网络 dnn 并

320
00:11:10,000 --> 00:11:13,440
导致一些策略选择，

321
00:11:13,440 --> 00:11:15,200
因此神经网络位于代理内部，

322
00:11:15,200 --> 00:11:16,800
这是我们可以

323
00:11:16,800 --> 00:11:19,839
使用可用的基本软件实现它的一种方式

324
00:11:19,839 --> 00:11:21,440
这允许某些类型的

325
00:11:21,440 --> 00:11:24,320
可扩展性，因为我们知道

326
00:11:24,320 --> 00:11:26,240


327
00:11:26,240 --> 00:11:28,240
我们的参数有多少模型，我们的

328
00:11:28,240 --> 00:11:31,360
模型有多少，

329
00:11:31,360 --> 00:11:33,279
以及它的有效性如何之间存在关系，然后

330
00:11:33,279 --> 00:11:35,120
它还允许非 - 线性

331
00:11:35,120 --> 00:11:38,160
推理不仅仅是一个简单的线性

332
00:11:38,160 --> 00:11:40,480
回归器

333
00:11:40,480 --> 00:11:42,800
，有时是小的，有时

334
00:11:42,800 --> 00:11:44,480
是大的 theta 用于参数，但

335
00:11:44,480 --> 00:11:46,000
我们稍后会谈到

336
00:11:46,000 --> 00:11:48,320
，神经网络可以是无模型的，

337
00:11:48,320 --> 00:11:49,519
所以它可以

338
00:11:49,519 --> 00:11:52,240
放开 找到

339
00:11:52,240 --> 00:11:53,440
数据中的模式，

340
00:11:53,440 --> 00:11:56,880
或者它可以使用基础模型，

341
00:11:56,880 --> 00:11:58,720
因此如果某种类型的事件是

342
00:11:58,720 --> 00:12:00,399
优先事项，则更有

343
00:12:00,399 --> 00:12:02,480
可能使用这些观察

344
00:12:02,480 --> 00:12:06,480
来衡量 另一种

345
00:12:06,560 --> 00:12:09,760


346
00:12:09,760 --> 00:12:11,680
现代强化学习的一个例子是这个q

347
00:12:11,680 --> 00:12:13,519
学习，它最近被用于一些游戏

348
00:12:13,519 --> 00:12:15,040
和一些类似的事情，

349
00:12:15,040 --> 00:12:16,000


350
00:12:16,000 --> 00:12:18,240
洞察力只是另一种方式，

351
00:12:18,240 --> 00:12:19,120
它

352
00:12:19,120 --> 00:12:22,560
是通过映射提示表

353
00:12:22,560 --> 00:12:25,360
，它是状态动作的映射 和

354
00:12:25,360 --> 00:12:26,399
奖励，

355
00:12:26,399 --> 00:12:29,040
这样就可以映射你当前的

356
00:12:29,040 --> 00:12:30,639
状态和你的行为，

357
00:12:30,639 --> 00:12:32,000
就像哦，我累了，但我会继续

358
00:12:32,000 --> 00:12:33,680
跑步，因为它是有回报的，

359
00:12:33,680 --> 00:12:36,959
让我们说，但是以某种数学方式

360
00:12:36,959 --> 00:12:39,040
，然后这里也代表了深度 q 学习

361
00:12:39,040 --> 00:12:40,240


362
00:12:40,240 --> 00:12:42,320
再一次，它不仅仅是一张桌子，

363
00:12:42,320 --> 00:12:43,920
而是一个神经网络，如此

364
00:12:43,920 --> 00:12:46,240
现代的内部只是

365
00:12:46,240 --> 00:12:49,120
用深度学习的东西替换任何其他统计模块

366
00:12:49,120 --> 00:12:50,639


367
00:12:50,639 --> 00:12:52,959
，呃，这显然允许出现一些

368
00:12:52,959 --> 00:12:55,360
更细微的政策

369
00:12:55,360 --> 00:12:56,880
，然后只是一张幻灯片就扔了

370
00:12:56,880 --> 00:12:58,480
如果你想看的话，你可以暂停

371
00:12:58,480 --> 00:13:00,000
一下，但它来自一篇名为深度强化学习的论文

372
00:13:00,000 --> 00:13:01,120


373
00:13:01,120 --> 00:13:02,880
，它显示了与多少

374
00:13:02,880 --> 00:13:04,959
不同领域相关的深度

375
00:13:04,959 --> 00:13:05,519


376
00:13:05,519 --> 00:13:07,360
所以这些是问题的结构

377
00:13:07,360 --> 00:13:09,360
以及

378
00:13:09,360 --> 00:13:12,160
本文使用这些关键字所涉及的领域

379
00:13:12,160 --> 00:13:13,519


380
00:13:13,519 --> 00:13:16,560
好吧，让我们从这个

381
00:13:16,560 --> 00:13:18,240
基于模型的强化学习框架开始

382
00:13:18,240 --> 00:13:21,040
，然后讨论系统和控制，

383
00:13:21,040 --> 00:13:24,480
所以在这个框架中，我们可以看看

384
00:13:24,480 --> 00:13:26,560
基于模型的强化学习

385
00:13:26,560 --> 00:13:28,880
和绿色的绿色和蓝色的无模型

386
00:13:28,880 --> 00:13:30,639
强化学习，所以无模型

387
00:13:30,639 --> 00:13:31,200
再次

388
00:13:31,200 --> 00:13:32,880
是从经验到策略的直接映射

389
00:13:32,880 --> 00:13:34,560


390
00:13:34,560 --> 00:13:36,959
，越来越抽象的

391
00:13:36,959 --> 00:13:38,720
基于模型的强化学习是

392
00:13:38,720 --> 00:13:40,240
基于经验的监督学习

393
00:13:40,240 --> 00:13:41,360


394
00:13:41,360 --> 00:13:43,600
到过渡模型的更新

395
00:13:43,600 --> 00:13:44,880
世界的生成模型

396
00:13:44,880 --> 00:13:46,959
，然后使用它来实施

397
00:13:46,959 --> 00:13:48,480
某种规划过程，

398
00:13:48,480 --> 00:13:52,079
从而产生一些政策选择，

399
00:13:52,079 --> 00:13:54,880
因此控制系统理论是关于

400
00:13:54,880 --> 00:13:57,279
在不确定性中规划行动，

401
00:13:57,279 --> 00:13:58,880
因为你必须为行动制定计划，并且

402
00:13:58,880 --> 00:14:00,639
会有各种不确定性

403
00:14:00,639 --> 00:14:02,480
不确定性

404
00:14:02,480 --> 00:14:04,480
有时它们是彼此的隐喻

405
00:14:04,480 --> 00:14:05,839
这些方法在其他时候是可

406
00:14:05,839 --> 00:14:07,120
转移的

407
00:14:07,120 --> 00:14:09,360
，一个系统将面临

408
00:14:09,360 --> 00:14:11,519
一种类型的

409
00:14:11,519 --> 00:14:13,839
挑战，但它

410
00:14:13,839 --> 00:14:15,920
包括混乱的系统，如双摆

411
00:14:15,920 --> 00:14:18,000
随机多尺度部分

412
00:14:18,000 --> 00:14:19,040
观察到的噪声

413
00:14:19,040 --> 00:14:22,160
等，所以如果你不能采取行动，你就无法

414
00:14:22,160 --> 00:14:23,920
控制你 只能观察，这

415
00:14:23,920 --> 00:14:25,279
就是

416
00:14:25,279 --> 00:14:28,720
控制理论与统计

417
00:14:28,720 --> 00:14:30,880
数据的真正区别，因为统计数据是描述性的，

418
00:14:30,880 --> 00:14:34,000
但系统和控制方法

419
00:14:34,000 --> 00:14:35,519
更倾向于

420
00:14:35,519 --> 00:14:37,600


421
00:14:37,600 --> 00:14:39,279
以一种可以干预的方式理解系统的动态，

422
00:14:39,279 --> 00:14:39,680


423
00:14:39,680 --> 00:14:41,519
因此明确地建模这个规划过程

424
00:14:41,519 --> 00:14:43,519
和政策

425
00:14:43,519 --> 00:14:46,720
然后当然还有

426
00:14:46,720 --> 00:14:48,800
很多这些模型中不存在的警告

427
00:14:48,800 --> 00:14:50,320
是战略

428
00:14:50,320 --> 00:14:53,680
公理，即不行动可以是行动的一种形式，

429
00:14:53,680 --> 00:14:55,040


430
00:14:55,040 --> 00:14:56,959
所以这里的总结是我们希望

431
00:14:56,959 --> 00:14:58,720
有一个数学

432
00:14:58,720 --> 00:15:02,560
模型来讨论

433
00:15:02,560 --> 00:15:05,279
系统如何具有 监督或塑造他们的

434
00:15:05,279 --> 00:15:07,040
自我，他们的行动可供性，他们的

435
00:15:07,040 --> 00:15:08,480
系统和他们的世界

436
00:15:08,480 --> 00:15:11,040
，这是很好的监管者，也有

437
00:15:11,040 --> 00:15:11,680
这个

438
00:15:11,680 --> 00:15:14,000
行动政策计划如此有监督的

439
00:15:14,000 --> 00:15:14,880
学习

440
00:15:14,880 --> 00:15:17,760
是关于监督你的输入并

441
00:15:17,760 --> 00:15:19,279
适当地更新你

442
00:15:19,279 --> 00:15:21,360
的世界生成模型

443
00:15:21,360 --> 00:15:22,720
，然后你

444
00:15:22,720 --> 00:15:26,000
的世界生成模型是什么，它将是关于这个

445
00:15:26,000 --> 00:15:29,040
政策选择的，这里有一个更

446
00:15:29,040 --> 00:15:32,160
经典的控制理论图，它的

447
00:15:32,160 --> 00:15:33,040
方式是

448
00:15:33,040 --> 00:15:35,199
系统测量元件控制器和

449
00:15:35,199 --> 00:15:37,279
效应器是相关的，

450
00:15:37,279 --> 00:15:40,480
好吧，信息论是

451
00:15:40,480 --> 00:15:42,560
另一个关键字，所以可能

452
00:15:42,560 --> 00:15:43,600
还有

453
00:15:43,600 --> 00:15:47,199
500 小时的 youtube 观看

454
00:15:47,199 --> 00:15:49,040
信息论，关于

455
00:15:49,040 --> 00:15:51,360
很多不同的领域，你可以说很多，

456
00:15:51,360 --> 00:15:54,480
嗯，一种简单的表达方式就是

457
00:15:54,480 --> 00:15:55,360
信息

458
00:15:55,360 --> 00:15:57,360
是减少不确定性

459
00:15:57,360 --> 00:15:58,880
是否可行，

460
00:15:58,880 --> 00:16:00,160
因此它不必与

461
00:16:00,160 --> 00:16:02,560
控制理论联系起来它可以只是纯粹的

462
00:16:02,560 --> 00:16:04,560
描述性，就像获取

463
00:16:04,560 --> 00:16:07,839
一些 dna 链信息的香农熵

464
00:16:07,839 --> 00:16:09,839
总是上下文相关的它是

465
00:16:09,839 --> 00:16:11,680
相关的它依赖于模型

466
00:16:11,680 --> 00:16:12,800
有很多 对

467
00:16:12,800 --> 00:16:16,079
这种对信息论的幼稚香农解释

468
00:16:16,079 --> 00:16:18,800
的批评有时是 d 信息的

469
00:16:18,800 --> 00:16:20,480
测量或比较

470
00:16:20,480 --> 00:16:22,560
具有挑战性，例如，如果您

471
00:16:22,560 --> 00:16:24,240
计算

472
00:16:24,240 --> 00:16:26,000


473
00:16:26,000 --> 00:16:28,160
同一个岛上昆虫和植物的生物多样性的熵，它们

474
00:16:28,160 --> 00:16:29,680
不一定具有相同的规模

475
00:16:29,680 --> 00:16:31,279
等等等等

476
00:16:31,279 --> 00:16:34,320
，呃，有很多地区

477
00:16:34,320 --> 00:16:36,959
信息理论涉及符号学

478
00:16:36,959 --> 00:16:39,120
和语义测量理论

479
00:16:39,120 --> 00:16:43,360
动态系统和信号处理

480
00:16:43,360 --> 00:16:45,519
减少不确定性也不是

481
00:16:45,519 --> 00:16:46,800
真理，因为当然

482
00:16:46,800 --> 00:16:49,839
存在错误和精确的

483
00:16:49,839 --> 00:16:51,600
估计，并且在许多情况下，对外部状态的精确估计

484
00:16:51,600 --> 00:16:52,959
并不能真正促进

485
00:16:52,959 --> 00:16:56,079
有效行动

486
00:16:56,079 --> 00:16:58,160
其他相关领域是信息的

487
00:16:58,160 --> 00:16:59,519
量化

488
00:16:59,519 --> 00:17:03,600
存储和通信

489
00:17:03,600 --> 00:17:05,280
前面提到的测量比较

490
00:17:05,280 --> 00:17:07,199
你如何

491
00:17:07,199 --> 00:17:08,959
通过时间存储和传输信息

492
00:17:08,959 --> 00:17:10,240
，就像记忆

493
00:17:10,240 --> 00:17:12,400
一样你如何通信是关于

494
00:17:12,400 --> 00:17:14,079
通过时间

495
00:17:14,079 --> 00:17:14,720
和空间

496
00:17:14,720 --> 00:17:19,199
协议传输信息进行通信

497
00:17:19,199 --> 00:17:23,679
以及系统收集信息的时间

498
00:17:23,679 --> 00:17:25,839
减少了它对世界的不确定性

499
00:17:25,839 --> 00:17:28,559
状态或原因或关系

500
00:17:28,559 --> 00:17:30,400
它可以促进

501
00:17:30,400 --> 00:17:32,480
有效政策模型的更新，因此

502
00:17:32,480 --> 00:17:32,960


503
00:17:32,960 --> 00:17:35,679
在某些情况下（但不是所有情况）

504
00:17:35,679 --> 00:17:37,039
采取行动，当行动有效时，

505
00:17:37,039 --> 00:17:40,320
它可能是有益的、可持续的或

506
00:17:40,320 --> 00:17:42,000
高度适合的，

507
00:17:42,000 --> 00:17:43,760
您可以通过多种方式考虑这种情况

508
00:17:43,760 --> 00:17:45,600
成功取决于机制

509
00:17:45,600 --> 00:17:48,000
规模系统

510
00:17:48,000 --> 00:17:50,480
，然后通过这种奖励更新参数，

511
00:17:50,480 --> 00:17:52,000


512
00:17:52,000 --> 00:17:54,000
因此无论是植物的哪些基因型

513
00:17:54,000 --> 00:17:55,440


514
00:17:55,440 --> 00:17:58,880
在某个利基市场中成功，

515
00:17:58,880 --> 00:18:00,720
还是哪种计算机病毒

516
00:18:00,720 --> 00:18:02,000
变异得最好

517
00:18:02,000 --> 00:18:03,679
，这是一种学习斜线

518
00:18:03,679 --> 00:18:05,919
发展进化过程

519
00:18:05,919 --> 00:18:07,120
最终我们想要

520
00:18:07,120 --> 00:18:09,600
朝着整合的方向

521
00:18:09,600 --> 00:18:12,240


522
00:18:12,240 --> 00:18:13,919


523
00:18:13,919 --> 00:18:16,160


524
00:18:16,160 --> 00:18:17,679


525
00:18:17,679 --> 00:18:19,280


526
00:18:19,280 --> 00:18:21,039


527
00:18:21,039 --> 00:18:22,640
发展 因为

528
00:18:22,640 --> 00:18:25,520
当我们再次减少

529
00:18:25,520 --> 00:18:25,919
对

530
00:18:25,919 --> 00:18:27,919
因果关系和统计规则的不

531
00:18:27,919 --> 00:18:29,520
确定性时

532
00:18:29,520 --> 00:18:32,080
我们可以制定更好的政策，所以让

533
00:18:32,080 --> 00:18:33,120
我们掌握

534
00:18:33,120 --> 00:18:35,120
一些基本的信息论概念

535
00:18:35,120 --> 00:18:36,720
，同时引入条件的概念，

536
00:18:36,720 --> 00:18:37,600


537
00:18:37,600 --> 00:18:40,880
所以符号 a 垂直线 b

538
00:18:40,880 --> 00:18:43,440
表示给定的 b 所以

539
00:18:43,440 --> 00:18:44,559
垂直

540
00:18:44,559 --> 00:18:47,840
线之后的部分是你的部分 '以 a 的 h 为条件

541
00:18:47,840 --> 00:18:48,400


542
00:18:48,400 --> 00:18:50,080
是信息内容

543
00:18:50,080 --> 00:18:51,919


544
00:18:51,919 --> 00:18:55,440
，随机变量 a 以单位或位为单位有多令人惊讶

545
00:18:55,440 --> 00:18:56,640


546
00:18:56,640 --> 00:18:59,200
，只是将这两个

547
00:18:59,200 --> 00:19:00,480
项目符号点结合起来

548
00:19:00,480 --> 00:19:03,200
，给定 b 的 h 是以 b 为条件的 a 的信息

549
00:19:03,200 --> 00:19:04,080
内容，

550
00:19:04,080 --> 00:19:06,720
对不起，有 a

551
00:19:06,720 --> 00:19:08,880


552
00:19:08,880 --> 00:19:12,320
分号 b 的信息上的拼写错误

553
00:19:12,320 --> 00:19:14,400
是 a 和 b 之间的互信息，

554
00:19:14,400 --> 00:19:15,600
因此

555
00:19:15,600 --> 00:19:17,919
如下

556
00:19:17,919 --> 00:19:20,080
文维恩图上的这些单一重叠空间所示

557
00:19:20,080 --> 00:19:23,200
，然后还有三重重叠

558
00:19:23,200 --> 00:19:25,280
，您还可以有重叠和

559
00:19:25,280 --> 00:19:26,320
条件，

560
00:19:26,320 --> 00:19:28,160
这样的方式 我们将要考虑

561
00:19:28,160 --> 00:19:30,160
的数学有点像

562
00:19:30,160 --> 00:19:30,720
嵌套

563
00:19:30,720 --> 00:19:34,000
运算，它包含不同类型的

564
00:19:34,000 --> 00:19:35,840
转换和潜力，

565
00:19:35,840 --> 00:19:37,679
并且有很多很酷的

566
00:19:37,679 --> 00:19:39,120
信息领域 heory

567
00:19:39,120 --> 00:19:42,480
james gleek 是一位伟大的作家，

568
00:19:42,480 --> 00:19:45,679
这本书中间的石头是一个

569
00:19:45,679 --> 00:19:49,120
很好的介绍，然后这本书

570
00:19:49,120 --> 00:19:50,320
买了一个尼尔，

571
00:19:50,320 --> 00:19:52,640
算法信息动力学也是

572
00:19:52,640 --> 00:19:53,440
一个很酷的

573
00:19:53,440 --> 00:19:56,960
应用程序和理论，所以让我们

574
00:19:56,960 --> 00:19:58,720
回到幻灯片的一个小变体。

575
00:19:58,720 --> 00:20:00,640
我们已经研究过

576
00:20:00,640 --> 00:20:05,200
这种不活跃与贝叶斯

577
00:20:05,200 --> 00:20:08,080
二分法的区别，最终活跃

578
00:20:08,080 --> 00:20:09,840
的将试图

579
00:20:09,840 --> 00:20:11,919
整合到不活跃的世界观中，我们

580
00:20:11,919 --> 00:20:14,159
在世界上有代理人，他们正在

581
00:20:14,159 --> 00:20:17,440
行动和感知的退出联系中制定

582
00:20:17,440 --> 00:20:18,799


583
00:20:18,799 --> 00:20:21,200
这种交互的结果

584
00:20:21,200 --> 00:20:23,679
是来自嵌入代理的具身的和生态的行动

585
00:20:23,679 --> 00:20:26,480
序列或策略，

586
00:20:26,480 --> 00:20:27,280
他们

587
00:20:27,280 --> 00:20:31,039
使斜线是他们的行为，

588
00:20:31,039 --> 00:20:33,360
现在从

589
00:20:33,360 --> 00:20:35,039
控制理论的角度再上一层

590
00:20:35,039 --> 00:20:38,240
到代理，我们可以看到

591
00:20:38,240 --> 00:20:40,720
代理的感觉状态在 在

592
00:20:40,720 --> 00:20:43,280
输入方面，他们有他们

593
00:20:43,280 --> 00:20:44,480
的世界因果模型

594
00:20:44,480 --> 00:20:46,960
，然后他们的政策模型在

595
00:20:46,960 --> 00:20:48,480
某种意义上可能像

596
00:20:48,480 --> 00:20:50,480
一个集成单元，或者我们不会得到

597
00:20:50,480 --> 00:20:52,640


598
00:20:52,640 --> 00:20:56,080
稍后我们可以将其与

599
00:20:56,080 --> 00:20:56,640
贝叶斯

600
00:20:56,640 --> 00:20:59,520
结构表示主义视图对齐，因此

601
00:20:59,520 --> 00:21:00,400
在此

602
00:21:00,400 --> 00:21:02,960
视图中，您拥有数据观察

603
00:21:02,960 --> 00:21:04,720
，这些观察是模型中的基本级别

604
00:21:04,720 --> 00:21:07,120
观察或参数

605
00:21:07,120 --> 00:21:09,679
，然后通过识别模型

606
00:21:09,679 --> 00:21:11,919
更新超参数

607
00:21:11,919 --> 00:21:12,720
导致

608
00:21:12,720 --> 00:21:15,600
数据的生成模型，

609
00:21:15,600 --> 00:21:16,240


610
00:21:16,240 --> 00:21:20,080
这种期望最大化方案

611
00:21:20,080 --> 00:21:21,919
导致

612
00:21:21,919 --> 00:21:23,360
多层次模型的统计收敛，

613
00:21:23,360 --> 00:21:25,600
因此

614
00:21:25,600 --> 00:21:26,799
代表

615
00:21:26,799 --> 00:21:29,039
世界的代表性结构，因此可能是

616
00:21:29,039 --> 00:21:30,320
结构部分

617
00:21:30,320 --> 00:21:33,679
，然后将其排列起来，我们可以

618
00:21:33,679 --> 00:21:37,520
想想那个模型，它是一个贝叶斯

619
00:21:37,520 --> 00:21:40,720
控制代理，假设

620
00:21:40,720 --> 00:21:42,720
它会有感觉状态什么

621
00:21:42,720 --> 00:21:43,919
是我的

622
00:21:43,919 --> 00:21:46,559
机器人传感器检测什么是

623
00:21:46,559 --> 00:21:49,600
因果模型，这对机器人的姿势意味着什么

624
00:21:49,600 --> 00:21:51,679
，然后是策略

625
00:21:51,679 --> 00:21:53,200
选择我们将如何

626
00:21:53,200 --> 00:21:58,000
纠正所以 这些呃两者都可以

627
00:21:58,000 --> 00:22:00,320
是虚线的这两个边

628
00:22:00,320 --> 00:22:01,919
可以是

629
00:22:01,919 --> 00:22:05,200
内部一致的，我们想要

630
00:22:05,200 --> 00:22:06,960
retu 回答这个问题，即

631
00:22:06,960 --> 00:22:07,600


632
00:22:07,600 --> 00:22:09,120
自由能原理和主动

633
00:22:09,120 --> 00:22:10,320
推理将如何说明

634
00:22:10,320 --> 00:22:10,880


635
00:22:10,880 --> 00:22:12,640
世界与主体之间的关系，

636
00:22:12,640 --> 00:22:14,799


637
00:22:14,799 --> 00:22:16,960
因此我们有行动和感知，我们

638
00:22:16,960 --> 00:22:18,640
希望它们在这种利基概念中是对称的，

639
00:22:18,640 --> 00:22:19,760


640
00:22:19,760 --> 00:22:22,480
我们 '''''''''''''''''''''''0H 谈过我们

641
00:22:22,480 --> 00:22:23,120
希望

642
00:22:23,120 --> 00:22:25,520
让自由能原理成为

643
00:22:25,520 --> 00:22:26,640


644
00:22:26,640 --> 00:22:29,360
我们希望以

645
00:22:29,360 --> 00:22:31,280
多尺度主动推理

646
00:22:31,280 --> 00:22:35,039


647
00:22:35,039 --> 00:22:37,919


648
00:22:37,919 --> 00:22:38,799


649
00:22:38,799 --> 00:22:41,360
视角建立在其之上的公理集的 为

650
00:22:41,360 --> 00:22:43,039
实现这一目标而构建，

651
00:22:43,039 --> 00:22:46,480
因此主动推理 1.0 并向

652
00:22:46,480 --> 00:22:49,120
在斜线上

653
00:22:49,120 --> 00:22:50,480
纠正我的任何这些部分的人们开放，

654
00:22:50,480 --> 00:22:51,440
这只是非常

655
00:22:51,440 --> 00:22:55,360
粗略的时代级别主动推理 1.0

656
00:22:55,360 --> 00:22:57,760
是

657
00:22:57,760 --> 00:23:00,240
一种基于

658
00:23:00,240 --> 00:23:04,159
自由能原理的机器学习类型算法的实现 以及

659
00:23:04,159 --> 00:23:06,960
不活跃的方法，它与

660
00:23:06,960 --> 00:23:08,720
当地感官状态和政策的协调相关，

661
00:23:08,720 --> 00:23:09,440


662
00:23:09,440 --> 00:23:11,440
所以它有点像

663
00:23:11,440 --> 00:23:12,480
无模型

664
00:23:12,480 --> 00:23:15,360
强化 nt 学习者，它专注于

665
00:23:15,360 --> 00:23:16,960
非常离散的案例，

666
00:23:16,960 --> 00:23:20,080
所以就像在网格上一样

667
00:23:20,080 --> 00:23:23,120
，它使用了非常简单的期望

668
00:23:23,120 --> 00:23:25,200
最大化算法，并且

669
00:23:25,200 --> 00:23:27,440
具有相对较短的空间和/

670
00:23:27,440 --> 00:23:28,240
或时间

671
00:23:28,240 --> 00:23:31,440
范围或深度，它更像是一个

672
00:23:31,440 --> 00:23:34,799
呃让我看看我的

673
00:23:34,799 --> 00:23:38,559
视频 不知道这里发生了什么，

674
00:23:38,960 --> 00:23:41,200


675
00:23:42,799 --> 00:23:45,840
对不起，

676
00:23:46,960 --> 00:23:50,159
所以我要

677
00:23:50,159 --> 00:23:53,520
重新添加我的相机，

678
00:24:02,840 --> 00:24:05,840
对不起，

679
00:24:07,360 --> 00:24:11,360
好吧，无论如何，c'est la vie 是

680
00:24:11,360 --> 00:24:15,039
活跃的 2.0 将

681
00:24:15,039 --> 00:24:17,760
时间深度和利基交互添加

682
00:24:17,760 --> 00:24:20,240
到具有长期规划阶段的方程中，

683
00:24:20,240 --> 00:24:23,440
并且还添加了 在

684
00:24:23,440 --> 00:24:25,679
代理嵌入的这方面，并将

685
00:24:25,679 --> 00:24:28,000
效价和学习的概念引入

686
00:24:28,000 --> 00:24:29,200


687
00:24:29,200 --> 00:24:32,159
到公式中，这

688
00:24:32,159 --> 00:24:34,159
就是主动推理 3.0

689
00:24:34,159 --> 00:24:37,600
及更高版本的发展方向，因此他们

690
00:24:37,600 --> 00:24:38,240
一直在

691
00:24:38,240 --> 00:24:40,880
朝着学习和影响以及行动的

692
00:24:40,880 --> 00:24:43,520
复杂或反事实

693
00:24:43,520 --> 00:24:43,919
方面发展

694
00:24:43,919 --> 00:24:46,960
这是一个引文

695
00:24:46,960 --> 00:24:49,039
，然后它的另一个方向

696
00:24:49,039 --> 00:24:50,080


697
00:24:50,080 --> 00:24:52,080
反映在这个缩放主动

698
00:24:52,080 --> 00:24:53,200
推理论文中

699
00:24:53,200 --> 00:24:55,200
，它将介绍

700
00:24:55,200 --> 00:24:56,400
高维

701
00:24:56,400 --> 00:24:59,200
数据 连续变量探索利用

702
00:24:59,200 --> 00:25:00,000
行为

703
00:25:00,000 --> 00:25:02,559
以及与强化学习

704
00:25:02,559 --> 00:25:04,240
和大规模工作的同源性，

705
00:25:04,240 --> 00:25:07,919
所以对我来说，阅读这篇论文就像英雄的旅程，

706
00:25:07,919 --> 00:25:10,000
因为这只是

707
00:25:10,000 --> 00:25:11,919
一个完成故事的框架，

708
00:25:11,919 --> 00:25:13,919
所以这就是扩展主动

709
00:25:13,919 --> 00:25:16,000
推理

710
00:25:16,000 --> 00:25:18,799
之旅 所以它开始于对冒险的呼吁，

711
00:25:18,799 --> 00:25:19,760


712
00:25:19,760 --> 00:25:22,799
这是一个问题，我们如何

713
00:25:22,799 --> 00:25:25,200
通过主动推理来模拟复杂的控制任务，

714
00:25:25,200 --> 00:25:26,640


715
00:25:26,640 --> 00:25:27,840
这是转型的开始，

716
00:25:27,840 --> 00:25:30,240
挑战在于

717
00:25:30,240 --> 00:25:31,679
诱惑

718
00:25:31,679 --> 00:25:34,240
应该去睡觉还是

719
00:25:34,240 --> 00:25:35,120
应该阅读

720
00:25:35,120 --> 00:25:38,320
弗里斯滕的

721
00:25:38,320 --> 00:25:40,960
参考书目助手来了 进入图片这里是

722
00:25:40,960 --> 00:25:42,799
亚历克，

723
00:25:42,799 --> 00:25:45,120
当我们阅读时，我们有一个变革性的时刻

724
00:25:45,120 --> 00:25:46,720
，当我们

725
00:25:46,720 --> 00:25:49,919
理解论文扩展主动推理时，

726
00:25:49,919 --> 00:25:50,880
我们就会

727
00:25:50,880 --> 00:25:52,880
从黑暗到光明，从

728
00:25:52,880 --> 00:25:54,640
强化学习到主动

729
00:25:54,640 --> 00:25:55,440
推理，

730
00:25:55,440 --> 00:25:59,200
从失败到控制，一路走来，我们

731
00:25:59,200 --> 00:26:02,000
收到了会议的礼物 新朋友

732
00:26:02,000 --> 00:26:04,159
讨论

733
00:26:04,159 --> 00:26:06,880
对系统有影响的酷想法并制作

734
00:26:06,880 --> 00:26:07,840
冷杉 st 和

735
00:26:07,840 --> 00:26:11,440
meme 当然让我们来看看论文，

736
00:26:11,440 --> 00:26:14,240
因此扩展主动推理是论文提出本文

737
00:26:14,240 --> 00:26:15,360
的目标

738
00:26:15,360 --> 00:26:18,400
是因为我们提出了一个

739
00:26:18,400 --> 00:26:20,400
主动推理模型，该模型适用

740
00:26:20,400 --> 00:26:22,320
于我们模型构建的

741
00:26:22,320 --> 00:26:24,799
具有连续状态和动作的高维控制任务

742
00:26:24,799 --> 00:26:27,200
在之前尝试

743
00:26:27,200 --> 00:26:28,880
通过包含

744
00:26:28,880 --> 00:26:30,640
有效的规划算法

745
00:26:30,640 --> 00:26:32,000
以及模型不确定性的量化和主动

746
00:26:32,000 --> 00:26:34,159
解决来扩展主动推理的过程中，

747
00:26:34,159 --> 00:26:35,440
我们的模型做出了两个主要

748
00:26:35,440 --> 00:26:37,600
贡献，首先我们

749
00:26:37,600 --> 00:26:39,360
证明了完整的主动

750
00:26:39,360 --> 00:26:41,279
推理构造可以扩展

751
00:26:41,279 --> 00:26:43,440
到 rl 文献

752
00:26:43,440 --> 00:26:45,279
这涉及扩展先前

753
00:26:45,279 --> 00:26:46,960
的深度主动推理模型以包括

754
00:26:46,960 --> 00:26:49,600
模型不确定性和预期信息增益

755
00:26:49,600 --> 00:26:51,600
第二我们强调

756
00:26:51,600 --> 00:26:53,120
主动推理最先进的

757
00:26:53,120 --> 00:26:53,840
方法

758
00:26:53,840 --> 00:26:56,880
与基于模型的强化学习之间的重叠，因此

759
00:26:56,880 --> 00:26:58,960
这里的非主动推理措辞

760
00:26:58,960 --> 00:27:01,840
是 我们如何将主动推理应用于

761
00:27:01,840 --> 00:27:03,760
具有挑战性的控制任务

762
00:27:03,760 --> 00:27:05,520
并将其连接起来 正式到强化

763
00:27:05,520 --> 00:27:08,480
学习，所以摘要是

764
00:27:08,480 --> 00:27:11,760
在强化学习中 代理经常

765
00:27:11,760 --> 00:27:13,600
在部分观察和

766
00:27:13,600 --> 00:27:15,120
不确定的环境中运行

767
00:27:15,120 --> 00:27:17,360
基于模型的强化学习

768
00:27:17,360 --> 00:27:19,520
表明，这最好

769
00:27:19,520 --> 00:27:21,440
通过学习和

770
00:27:21,440 --> 00:27:24,720
利用世界的概率模型来实现

771
00:27:24,720 --> 00:27:26,240
主动推理

772
00:27:26,240 --> 00:27:28,080
是认知和认知领域新兴的规范框架

773
00:27:28,080 --> 00:27:29,760
计算神经科学

774
00:27:29,760 --> 00:27:31,919
提供了一个统一的解释，说明

775
00:27:31,919 --> 00:27:34,480
生物代理如何

776
00:27:34,480 --> 00:27:37,039
在这个框架上实现这一点 推理学习和

777
00:27:37,039 --> 00:27:37,600
行动

778
00:27:37,600 --> 00:27:39,360
源于一个单一的命令，以

779
00:27:39,360 --> 00:27:41,039
最大化世界共享利基的贝叶斯证据，

780
00:27:41,039 --> 00:27:43,919


781
00:27:43,919 --> 00:27:46,480
但是迄今为止，该过程的实现

782
00:27:46,480 --> 00:27:48,080
仅限于低

783
00:27:48,080 --> 00:27:50,559
维 和理想化的情况

784
00:27:50,559 --> 00:27:53,600
，我们提出了

785
00:27:53,600 --> 00:27:55,679
一种适用于高维任务的主动推理的工作实现，其

786
00:27:55,679 --> 00:27:57,279


787
00:27:57,279 --> 00:27:58,320
原理结果

788
00:27:58,320 --> 00:28:00,960
证明证明了有效的探索和

789
00:28:00,960 --> 00:28:02,080


790
00:28:02,080 --> 00:28:04,320
样本效率在

791
00:28:04,320 --> 00:28:06,799
强大的无模型基线上下降

792
00:28:06,799 --> 00:28:08,880
了一个数量级 结果证明了

793
00:28:08,880 --> 00:28:11,360
大规模应用主动推理的可行性，

794
00:28:11,360 --> 00:28:13,360
并突出了

795
00:28:13,360 --> 00:28:14,640
主动推理

796
00:28:14,640 --> 00:28:16,640
与当前基于模型的

797
00:28:16,640 --> 00:28:18,240
强化学习方法之间的操作

798
00:28:18,240 --> 00:28:21,600
同源性，所以对于你们中的一些人来说，

799
00:28:21,600 --> 00:28:25,039
这可能是很多新想法，其他人

800
00:28:25,039 --> 00:28:28,320
可能会在那里认识到很多，所以

801
00:28:28,320 --> 00:28:30,480
让我们只是 为

802
00:28:30,480 --> 00:28:31,679
我们如何从

803
00:28:31,679 --> 00:28:34,960
a 到 z 制定路线图，然后希望

804
00:28:34,960 --> 00:28:37,600
它可以从所有这些不同的角度变得平易近人，第一

805
00:28:37,600 --> 00:28:38,240


806
00:28:38,240 --> 00:28:41,600
部分

807
00:28:41,600 --> 00:28:44,000
是介绍，第二部分是关于

808
00:28:44,000 --> 00:28:45,279
主动推理

809
00:28:45,279 --> 00:28:47,919
，在第三领域所做的工作

810
00:28:47,919 --> 00:28:48,399


811
00:28:48,399 --> 00:28:49,760
是 我们将

812
00:28:49,760 --> 00:28:51,440
在本次

813
00:28:51,440 --> 00:28:55,279
讨论中关注的模型和 3.1 是生成

814
00:28:55,279 --> 00:28:56,840
模型和识别

815
00:28:56,840 --> 00:28:59,279
分布，它们是 p 和 q

816
00:28:59,279 --> 00:29:00,880
模型，

817
00:29:00,880 --> 00:29:02,480
然后是学习和

818
00:29:02,480 --> 00:29:04,240
推理策略选择

819
00:29:04,240 --> 00:29:06,080
轨迹采样和预期自由

820
00:29:06,080 --> 00:29:08,000
能的部分

821
00:29:08,000 --> 00:29:09,760
作为完全

822
00:29:09,760 --> 00:29:11,600
观察模型的一部分，这些部分是我们

823
00:29:11,600 --> 00:29:12,240


824
00:29:12,240 --> 00:29:15,840
今天不会深入讨论的部分，然后是相关的

825
00:29:15,840 --> 00:29:17,039


826
00:29:17,039 --> 00:29:20,799
实验 涉及到探索和开发

827
00:29:20,799 --> 00:29:22,880
以及与

828
00:29:22,880 --> 00:29:25,039
探索

829
00:29:25,039 --> 00:29:26,880
策略比较和连续控制任务上的性能比较相关的两个数字，

830
00:29:26,880 --> 00:29:28,720


831
00:29:28,720 --> 00:29:31,200
然后是与以前工作的关系，

832
00:29:31,200 --> 00:29:32,240
特别是

833
00:29:32,240 --> 00:29:33,760
基于深度主动推理模型的

834
00:29:33,760 --> 00:29:35,520
强化学习和信息

835
00:29:35,520 --> 00:29:35,919
增益

836
00:29:35,919 --> 00:29:38,840
理论，然后有一个讨论和

837
00:29:38,840 --> 00:29:40,559


838
00:29:40,559 --> 00:29:42,879
结论 正确的

839
00:29:44,000 --> 00:29:47,360
这句话，你可以

840
00:29:47,360 --> 00:29:51,440
停下来阅读全文

841
00:29:51,440 --> 00:29:52,799


842
00:29:52,799 --> 00:29:55,279


843
00:29:55,279 --> 00:29:57,200


844
00:29:57,200 --> 00:29:59,279


845
00:29:59,279 --> 00:30:01,039


846
00:30:01,039 --> 00:30:02,960
动作

847
00:30:02,960 --> 00:30:03,919
空间

848
00:30:03,919 --> 00:30:06,000
意味着它不能直接

849
00:30:06,000 --> 00:30:07,919


850
00:30:07,919 --> 00:30:09,520
应用于强化学习基准中考虑的高维状态和连续动作，

851
00:30:09,520 --> 00:30:10,880


852
00:30:10,880 --> 00:30:12,720
因此这就是为什么在作者的措辞中没有比较基于主动

853
00:30:12,720 --> 00:30:13,919
推理离散

854
00:30:13,919 --> 00:30:16,000
状态的学习器的原因之一

855
00:30:16,000 --> 00:30:17,120


856
00:30:17,120 --> 00:30:20,320
是使用

857
00:30:20,320 --> 00:30:22,240
的强化学习基准

858
00:30:22,240 --> 00:30:23,760


859
00:30:23,760 --> 00:30:25,600
测试适当的

860
00:30:25,600 --> 00:30:27,840
不同强化学习

861
00:30:27,840 --> 00:30:31,360
控制理论算法的有效性或有效性

862
00:30:31,360 --> 00:30:33,279
是连续任务，就像

863
00:30:33,279 --> 00:30:35,039
我们将在图中讨论的那种

864
00:30:35,039 --> 00:30:37,679
，因此本文要做的是

865
00:30:37,679 --> 00:30:39,520
采用一种称为

866
00:30:39,520 --> 00:30:41,440
摊销推理的方法，我们将

867
00:30:41,440 --> 00:30:44,080
对此进行更多讨论

868
00:30:44,080 --> 00:30:46,720
稍微利用函数逼近器，

869
00:30:46,720 --> 00:30:47,200
即

870
00:30:47,200 --> 00:30:48,960
神经网络来参数化

871
00:30:48,960 --> 00:30:50,240
分布，

872
00:30:50,240 --> 00:30:51,919
然后将自由能

873
00:30:51,919 --> 00:30:53,520
相对于函数逼近器的参数而

874
00:30:53,520 --> 00:30:55,039
不是

875
00:30:55,039 --> 00:30:57,120
变分参数本身最小化

876
00:30:57,120 --> 00:30:59,200
，然后它们重申每个

877
00:30:59,200 --> 00:31:01,679
部分和三个

878
00:31:01,679 --> 00:31:04,240
是符号参考 表

879
00:31:04,240 --> 00:31:06,159
不是每个单独的

880
00:31:06,159 --> 00:31:09,440
参数，尤其

881
00:31:09,440 --> 00:31:12,720
是分布的统计参数

882
00:31:12,720 --> 00:31:15,440
和很多后面的部分，但这

883
00:31:15,440 --> 00:31:15,760


884
00:31:15,760 --> 00:31:17,760
是我们将

885
00:31:17,760 --> 00:31:18,960


886
00:31:18,960 --> 00:31:22,960
在接下来的幻灯片中看到的参数类型，

887
00:31:22,960 --> 00:31:26,080
我们真的

888
00:31:26,080 --> 00:31:28,799
可以看看什么

889
00:31:28,799 --> 00:31:30,480
该模型将涵盖的许多主题

890
00:31:30,480 --> 00:31:33,120
都是如此，例如时代政策

891
00:31:33,120 --> 00:31:34,000
nt

892
00:31:34,000 --> 00:31:36,000
它试图估计

893
00:31:36,000 --> 00:31:37,600
的状态和真正的状态随着

894
00:31:37,600 --> 00:31:38,799
时间的推移它会涉及到

895
00:31:38,799 --> 00:31:40,399
观察

896
00:31:40,399 --> 00:31:41,519
我们有点

897
00:31:41,519 --> 00:31:44,159


898
00:31:44,159 --> 00:31:45,279


899
00:31:45,279 --> 00:31:48,320
看到我们之前讨论过的强化学习算法的很多成分所以

900
00:31:48,320 --> 00:31:48,880
让我们

901
00:31:48,880 --> 00:31:53,360
谈论这个摊销的推理

902
00:31:53,360 --> 00:31:55,360
这里是他们写的作者的

903
00:31:55,360 --> 00:31:56,480
机会

904
00:31:56,480 --> 00:31:58,240
摊销推理过程

905
00:31:58,240 --> 00:31:59,760
提供了几个好处

906
00:31:59,760 --> 00:32:01,600
例如参数的数量

907
00:32:01,600 --> 00:32:03,519
相对于

908
00:32:03,519 --> 00:32:04,960


909
00:32:04,960 --> 00:32:06,320
数据的大小保持不变并且可以

910
00:32:06,320 --> 00:32:08,080
通过单次前向传递

911
00:32:08,080 --> 00:32:09,840
来实现推理 网络而不是让我们说

912
00:32:09,840 --> 00:32:12,080
反向传播训练

913
00:32:12,080 --> 00:32:14,240
此外，虽然

914
00:32:14,240 --> 00:32:16,320
关于变量的编码信息量是固定

915
00:32:16,320 --> 00:32:17,840
的，但变量之间的条件关系

916
00:32:17,840 --> 00:32:20,080
可以

917
00:32:20,080 --> 00:32:21,840
在等式三中任意复杂，我们将得到转换

918
00:32:21,840 --> 00:32:23,200


919
00:32:23,200 --> 00:32:26,640
分布数据的参数本身就是

920
00:32:26,640 --> 00:32:28,799
随机变量 当前上下文

921
00:32:28,799 --> 00:32:30,159
这些参数是

922
00:32:30,159 --> 00:32:32,159


923
00:32:32,159 --> 00:32:34,000
这种方法的神经网络

924
00:32:34,000 --> 00:32:35,679
允许量化这些参数的不确定性

925
00:32:35,679 --> 00:32:37,200
，并将学习作为

926
00:32:37,200 --> 00:32:38,559
变分推理

927
00:32:38,559 --> 00:32:40,240
的过程，theta 的先验概率

928
00:32:40,240 --> 00:32:41,919
由标准高斯给出，它

929
00:32:41,919 --> 00:32:44,080
在学习过程中就像一个正则化器

930
00:32:44,080 --> 00:32:47,120
，这只是谈论自由

931
00:32:47,120 --> 00:32:48,960
能如何 将用于选择

932
00:32:48,960 --> 00:32:49,519
操作

933
00:32:49,519 --> 00:32:52,240
策略，所以这个摊销

934
00:32:52,240 --> 00:32:54,640
推理是什么，为什么要使用它

935
00:32:54,640 --> 00:32:56,320
底部的这些论文有

936
00:32:56,320 --> 00:32:58,480
更多的信息，但是在摊销

937
00:32:58,480 --> 00:33:01,039
推理中，使用的参数数量

938
00:33:01,039 --> 00:33:03,039
是灵活的，你可以有一个小的或

939
00:33:03,039 --> 00:33:04,320
大的 模型，

940
00:33:04,320 --> 00:33:07,440
但它的好处是您还可以

941
00:33:07,440 --> 00:33:07,919


942
00:33:07,919 --> 00:33:11,200
将模型的大小设置为

943
00:33:11,200 --> 00:33:13,519
即使输入更多数据也不会改变，

944
00:33:13,519 --> 00:33:15,519
这样您就可以在您知道

945
00:33:15,519 --> 00:33:16,080


946
00:33:16,080 --> 00:33:18,799
计算能力有限或

947
00:33:18,799 --> 00:33:20,480
使用非常大但

948
00:33:20,480 --> 00:33:24,320
定义模型大小以在

949
00:33:24,320 --> 00:33:27,760
更大规模的网络上实现让我们再说

950
00:33:27,760 --> 00:33:29,120
一遍，模型可以通过

951
00:33:29,120 --> 00:33:30,799
单次前向传递而不是更

952
00:33:30,799 --> 00:33:32,000
复杂的游戏进行训练，

953
00:33:32,000 --> 00:33:35,440
并且

954
00:33:35,440 --> 00:33:37,279
当你可以设计神经网络时，还有所有这些自由度，

955
00:33:37,279 --> 00:33:38,559
因为有很多

956
00:33:38,559 --> 00:33:40,320
方法可以用

957
00:33:40,320 --> 00:33:42,799
神经网络来

958
00:33:42,799 --> 00:33:45,519


959
00:33:45,519 --> 00:33:49,279


960
00:33:49,519 --> 00:33:52,000
实现

961
00:33:52,000 --> 00:33:52,799
描述的

962
00:33:52,799 --> 00:33:55,919
是一个部分观察到的马尔可夫决策

963
00:33:55,919 --> 00:33:59,279
过程，所以这些

964
00:33:59,279 --> 00:34:01,399
是定义这种以

965
00:34:01,399 --> 00:34:03,840
有机体为中心的方法的关键变量，让我们

966
00:34:03,840 --> 00:34:05,600
在每个时间步 t 说，这样人们很

967
00:34:05,600 --> 00:34:07,360
容易记住环境的真实状态

968
00:34:07,360 --> 00:34:08,480
，即

969
00:34:08,480 --> 00:34:10,480
s 帽子意味着它是

970
00:34:10,480 --> 00:34:11,760
真实的状态，而

971
00:34:11,760 --> 00:34:13,359
这些状态是重要的

972
00:34:13,359 --> 00:34:14,879
事情，

973
00:34:14,879 --> 00:34:17,119
就像公共汽车会撞到我还是

974
00:34:17,119 --> 00:34:18,560
不会撞到我可以说，

975
00:34:18,560 --> 00:34:20,320
但它们可能是其他各种东西，

976
00:34:20,320 --> 00:34:21,918
所以我们保持一般性

977
00:34:21,918 --> 00:34:24,800
，然后 s hat sub t 所以随着

978
00:34:24,800 --> 00:34:26,079
时间的推移，真实状态

979
00:34:26,079 --> 00:34:28,239
存在于具有一定维度的状态空间中，

980
00:34:28,239 --> 00:34:29,760


981
00:34:29,760 --> 00:34:33,280
并且还有与 um this p

982
00:34:33,280 --> 00:34:35,760
s 相关的真实状态的真实转换动态

983
00:34:35,760 --> 00:34:37,119


984
00:34:37,119 --> 00:34:40,480
戴着帽子 t 给出

985
00:34:40,480 --> 00:34:42,719
了以前的时间和动作，所以

986
00:34:42,719 --> 00:34:44,079
这就是说

987
00:34:44,079 --> 00:34:46,560
系统的时间演变与

988
00:34:46,560 --> 00:34:48,719
真正的戴着帽子 t 的人

989
00:34:48,719 --> 00:34:50,399
是相关的让我看看我是否真的

990
00:34:50,399 --> 00:34:53,598
可以得到激光

991
00:34:54,000 --> 00:34:57,440
是的

992
00:34:57,440 --> 00:35:00,560
与当前时间

993
00:35:00,560 --> 00:35:02,800
和上一个时间以及动作有关

994
00:35:02,800 --> 00:35:05,839
，并且也具有维度，

995
00:35:05,839 --> 00:35:07,839
并且代理无法访问

996
00:35:07,839 --> 00:35:09,359
环境的真实状态，但

997
00:35:09,359 --> 00:35:11,920
可能会收到观察结果，所以哦

998
00:35:11,920 --> 00:35:12,800
观察，

999
00:35:12,800 --> 00:35:14,880
这是一个很好的简单观察，并且那些具有

1000
00:35:14,880 --> 00:35:16,240
一定的

1001
00:35:16,240 --> 00:35:17,520
生成到实际

1002
00:35:17,520 --> 00:35:20,160
观察分布 t 的维度，这

1003
00:35:20,160 --> 00:35:20,960
与

1004
00:35:20,960 --> 00:35:23,440
观察如何

1005
00:35:23,440 --> 00:35:24,720
以世界的真实状态为条件有关，所以如果外面真的很

1006
00:35:24,720 --> 00:35:25,920
阳光，

1007
00:35:25,920 --> 00:35:27,520
那么

1008
00:35:27,520 --> 00:35:29,440
如果你这样看

1009
00:35:29,440 --> 00:35:32,800
太阳，你真的会得到光子 是因为代理

1010
00:35:32,800 --> 00:35:34,320
只能从世界获得观察结果而不是

1011
00:35:34,320 --> 00:35:35,920
绝对真理

1012
00:35:35,920 --> 00:35:37,680
代理必须根据他们

1013
00:35:37,680 --> 00:35:38,960
对

1014
00:35:38,960 --> 00:35:42,079
状态的信念进行操作

1015
00:35:42,079 --> 00:35:43,440


1016
00:35:43,440 --> 00:35:45,599
关于真实环境状态的真实性，就像

1017
00:35:45,599 --> 00:35:46,800
戴帽子一样

1018
00:35:46,800 --> 00:35:49,280
，然后在

1019
00:35:49,280 --> 00:35:51,280
没有斜体的真实动力学

1020
00:35:51,280 --> 00:35:53,920
和

1021
00:35:53,920 --> 00:35:56,720
总是用斜体的动力学模型之间存在差异，这是

1022
00:35:56,720 --> 00:35:58,560
这些方程如何

1023
00:35:58,560 --> 00:36:00,480
联系在这里是主动

1024
00:36:00,480 --> 00:36:01,839
推理发挥作用的地方

1025
00:36:01,839 --> 00:36:04,400
主动推理提出 代理

1026
00:36:04,400 --> 00:36:06,880
实施更新

1027
00:36:06,880 --> 00:36:10,320
他们世界的生成模型，所以斜体

1028
00:36:10,320 --> 00:36:12,640
p 表示观察世界的模型状态世界的

1029
00:36:12,640 --> 00:36:14,079


1030
00:36:14,079 --> 00:36:17,200
政策和参数，

1031
00:36:17,200 --> 00:36:18,000


1032
00:36:18,000 --> 00:36:20,000
其中波浪号是随

1033
00:36:20,000 --> 00:36:21,280
时间变化的变量序列，

1034
00:36:21,280 --> 00:36:23,040
因此这些是随时间变化的观察和

1035
00:36:23,040 --> 00:36:25,119
状态，  pi 是

1036
00:36:25,119 --> 00:36:26,880
策略，如果我有每天跑步的策略，

1037
00:36:26,880 --> 00:36:28,960
那么我对

1038
00:36:28,960 --> 00:36:30,560
时间的观察将看起来像这样

1039
00:36:30,560 --> 00:36:34,240
你可以想象一个和

1040
00:36:34,240 --> 00:36:38,240
带有斜体的 theta um 属于更大

1041
00:36:38,240 --> 00:36:40,640
版本的 theta 大写 theta 并且

1042
00:36:40,640 --> 00:36:42,079
表示参数 生成

1043
00:36:42,079 --> 00:36:43,520
模型本身是随机

1044
00:36:43,520 --> 00:36:44,560
变量

1045
00:36:44,560 --> 00:36:46,800
，并且代理保持识别

1046
00:36:46,800 --> 00:36:48,560
分布 这就像 p 和 q，

1047
00:36:48,560 --> 00:36:51,760
所以请注意状态的 p 和 q，

1048
00:36:51,760 --> 00:36:52,560


1049
00:36:52,560 --> 00:36:55,920
以及世界的政策和 theta

1050
00:36:55,920 --> 00:36:58,400
参数，它们代表

1051
00:36:58,400 --> 00:36:59,359
代理

1052
00:36:59,359 --> 00:37:02,000
对其状态政策和

1053
00:37:02,000 --> 00:37:04,800
模型参数

1054
00:37:04,960 --> 00:37:08,000
的信念，所以在这一

1055
00:37:08,000 --> 00:37:10,880
部分中，我们将看看 在 p 模型中

1056
00:37:10,880 --> 00:37:13,200
记住它是 ps 和 qs

1057
00:37:13,200 --> 00:37:17,359
所以 p 是一个代理实现

1058
00:37:17,359 --> 00:37:19,359
，这就是为什么它是

1059
00:37:19,359 --> 00:37:22,640
斜体的观察模型，通过

1060
00:37:22,640 --> 00:37:23,200
时间

1061
00:37:23,200 --> 00:37:25,280
o 与波浪号状态通过时间 s

1062
00:37:25,280 --> 00:37:26,320
与波浪号

1063
00:37:26,320 --> 00:37:29,920
策略和模型参数所以这

1064
00:37:29,920 --> 00:37:30,400
就是

1065
00:37:30,400 --> 00:37:33,520
这个 模型是

1066
00:37:33,520 --> 00:37:35,280
关于它的，它是由我们关心的代理实现的，这

1067
00:37:35,280 --> 00:37:37,280


1068
00:37:37,280 --> 00:37:39,839
就是这些行中的每一行所说的，所以

1069
00:37:39,839 --> 00:37:40,640


1070
00:37:40,640 --> 00:37:43,040
等式左侧的第一行表示 p

1071
00:37:43,040 --> 00:37:43,839
，这

1072
00:37:43,839 --> 00:37:46,400
是我们在顶部大的

1073
00:37:46,400 --> 00:37:47,680


1074
00:37:47,680 --> 00:37:51,440
函数等于

1075
00:37:51,440 --> 00:37:54,640
概率

1076
00:37:54,640 --> 00:37:57,760
参数模型 theta 把这些

1077
00:37:57,760 --> 00:38:00,000
去掉，那么策略的概率是所以

1078
00:38:00,000 --> 00:38:01,599
如果我不可能

1079
00:38:01,599 --> 00:38:03,440
跳一千英尺那么它就

1080
00:38:03,440 --> 00:38:05,680
不会成为我的概率分布的一部分，

1081
00:38:05,680 --> 00:38:07,359
如果它我 这是我跳一千英尺的能力的一部分，

1082
00:38:07,359 --> 00:38:09,280
然后我会在

1083
00:38:09,280 --> 00:38:09,839
我的

1084
00:38:09,839 --> 00:38:13,280
政策估计中考虑它，然后是大

1085
00:38:13,280 --> 00:38:16,079
pi，这有点像 sigma 如何将

1086
00:38:16,079 --> 00:38:16,400


1087
00:38:16,400 --> 00:38:20,000
东西相加 pi 将东西相乘，所以这就是说

1088
00:38:20,000 --> 00:38:20,400


1089
00:38:20,400 --> 00:38:22,320
随着时间的推移将它全部

1090
00:38:22,320 --> 00:38:23,680
相乘 从一开始 t

1091
00:38:23,680 --> 00:38:26,960
等于 1 并通过时间观察

1092
00:38:26,960 --> 00:38:30,320
o 的代理模型 p

1093
00:38:30,320 --> 00:38:31,760
通过时间观察

1094
00:38:31,760 --> 00:38:33,760
给定的状态通过时间所以第一

1095
00:38:33,760 --> 00:38:35,359
部分就是

1096
00:38:35,359 --> 00:38:38,720


1097
00:38:38,720 --> 00:38:41,760
假设我很健康我看到这个

1098
00:38:41,760 --> 00:38:44,800
状态的概率是多少 然后

1099
00:38:44,800 --> 00:38:48,160
在每个时间点乘以

1100
00:38:48,160 --> 00:38:52,320
状态 s t

1101
00:38:52,320 --> 00:38:55,520
以先前状态和

1102
00:38:55,520 --> 00:38:56,480
先前策略

1103
00:38:56,480 --> 00:38:59,359
以及模型的参数为条件的方式，因此

1104
00:38:59,359 --> 00:39:00,000
所有这些事物

1105
00:39:00,000 --> 00:39:02,880
如何通过时间相乘乘以

1106
00:39:02,880 --> 00:39:03,440


1107
00:39:03,440 --> 00:39:06,880
第一次通过描述这么大

1108
00:39:06,880 --> 00:39:08,880
顶部的方程是 os pi theta 的总模型，

1109
00:39:08,880 --> 00:39:10,079


1110
00:39:10,079 --> 00:39:13,280
然后

1111
00:39:13,280 --> 00:39:16,320
通过时间模型深入研究这个 p 的观察值

1112
00:39:16,320 --> 00:39:17,200


1113
00:39:17,200 --> 00:39:18,960


1114
00:39:18,960 --> 00:39:20,240


1115
00:39:20,240 --> 00:39:22,880


1116
00:39:22,880 --> 00:39:23,359


1117
00:39:23,359 --> 00:39:25,599
给定状态估计的观测值 el

1118
00:39:25,599 --> 00:39:26,560


1119
00:39:26,560 --> 00:39:30,240
又是一个正态分布，

1120
00:39:30,240 --> 00:39:33,200
随着时间的推移，观测值具有

1121
00:39:33,200 --> 00:39:34,000
一定的

1122
00:39:34,000 --> 00:39:37,040
均值和方差 mu 和 sigma 具有

1123
00:39:37,040 --> 00:39:39,920
一定的参数 this lambda 和

1124
00:39:39,920 --> 00:39:40,880


1125
00:39:40,880 --> 00:39:44,160
这两个类似

1126
00:39:44,160 --> 00:39:47,440
的变量的双重元组一起

1127
00:39:47,440 --> 00:39:51,359
构成了这个函数 lambda

1128
00:39:51,359 --> 00:39:53,599
所以方式 我们将估计

1129
00:39:53,599 --> 00:39:54,640
这些平均

1130
00:39:54,640 --> 00:39:56,960
变体可能是最小二乘也可能不是

1131
00:39:56,960 --> 00:39:57,920
最小二乘 它可能

1132
00:39:57,920 --> 00:40:01,040
不是 l2 范数 我们可以

1133
00:40:01,040 --> 00:40:02,880
在这里使用函数方法 这是

1134
00:40:02,880 --> 00:40:06,720
对摊销的洞察力

1135
00:40:07,119 --> 00:40:09,920
状态概率

1136
00:40:09,920 --> 00:40:10,880


1137
00:40:10,880 --> 00:40:12,800
代理如何的概率转换模型

1138
00:40:12,800 --> 00:40:14,480
认为随着时间的

1139
00:40:14,480 --> 00:40:17,520
推移状态与先前时间的有条件的两个 um

1140
00:40:17,520 --> 00:40:19,760
状态和先前时间的政策相关联

1141
00:40:19,760 --> 00:40:20,880
，然后世界的参数

1142
00:40:20,880 --> 00:40:21,839


1143
00:40:21,839 --> 00:40:24,000


1144
00:40:24,000 --> 00:40:25,280


1145
00:40:25,280 --> 00:40:27,520


1146
00:40:27,520 --> 00:40:29,839
与具有不同

1147
00:40:29,839 --> 00:40:33,200
下标的另一个 mu 和 sigma 的另一个状态正态分布相关，对于

1148
00:40:33,200 --> 00:40:36,640
那些 mu 和 sigma，我们

1149
00:40:36,640 --> 00:40:40,240
对 uh 州和政策如何相关的 sub theta 很感兴趣，

1150
00:40:40,240 --> 00:40:43,760


1151
00:40:43,760 --> 00:40:47,119
所以这是另一种公正的分类 估计发生

1152
00:40:47,119 --> 00:40:48,000


1153
00:40:48,000 --> 00:40:50,640
的不同类型事件的方差的方法，

1154
00:40:50,640 --> 00:40:51,359


1155
00:40:51,359 --> 00:40:53,280
因此将感官输入加权

1156
00:40:53,280 --> 00:40:54,400


1157
00:40:54,400 --> 00:40:56,240
在一起 状态估计

1158
00:40:56,240 --> 00:40:57,680


1159
00:40:57,680 --> 00:41:01,839
分布再次是由函数

1160
00:41:01,839 --> 00:41:06,480
p 估计的 theta 给出

1161
00:41:06,480 --> 00:41:09,680
为均值为零的正态分布，

1162
00:41:09,680 --> 00:41:11,200


1163
00:41:11,200 --> 00:41:14,480
我相信这个协方差单位矩阵

1164
00:41:14,480 --> 00:41:17,839
呃，我认为这只是反映

1165
00:41:17,839 --> 00:41:20,720
了一种中性的启动方法或

1166
00:41:20,720 --> 00:41:21,920
正则化，但

1167
00:41:21,920 --> 00:41:25,920
我对此不是 100 确定

1168
00:41:25,920 --> 00:41:28,400
，这反映了策略的

1169
00:41:28,400 --> 00:41:29,839
概率模型

1170
00:41:29,839 --> 00:41:33,119
与这个

1171
00:41:33,119 --> 00:41:35,520
最大函数相关，所以它是一个 sigma，但它是

1172
00:41:35,520 --> 00:41:36,319
与

1173
00:41:36,319 --> 00:41:39,359
统计模型中的 sigma 平方不同

1174
00:41:39,359 --> 00:41:42,079
，它是我们将在后面部分讨论的策略的负预期自由能的软最大函数，

1175
00:41:42,079 --> 00:41:42,720


1176
00:41:42,720 --> 00:41:46,160


1177
00:41:46,160 --> 00:41:48,960


1178
00:41:48,960 --> 00:41:50,800


1179
00:41:50,800 --> 00:41:54,800
所以这是我们的 p 让我们看看 q

1180
00:41:54,800 --> 00:41:57,839
q 是这个代理识别

1181
00:41:57,839 --> 00:41:59,040
分布 q

1182
00:41:59,040 --> 00:42:01,359
通过时间策略和模型参数以斜体表示状态

1183
00:42:01,359 --> 00:42:03,359


1184
00:42:03,359 --> 00:42:06,720
这是如何定义的，

1185
00:42:06,720 --> 00:42:08,720
所以 q 是

1186
00:42:08,720 --> 00:42:10,240
参数 theta

1187
00:42:10,240 --> 00:42:11,920
multi 的概率 乘以策略 pi 的概率

1188
00:42:11,920 --> 00:42:14,240
，然后在 q

1189
00:42:14,240 --> 00:42:17,359
的所有时间中与时间相乘

1190
00:42:17,359 --> 00:42:20,480
，这是给定观察的状态模型，

1191
00:42:20,480 --> 00:42:22,880


1192
00:42:22,880 --> 00:42:26,480
所以以前

1193
00:42:26,640 --> 00:42:30,319
我们观察到 p-o-s 第二行

1194
00:42:30,319 --> 00:42:30,800
这里

1195
00:42:30,800 --> 00:42:34,880
是给定状态的观察概率，

1196
00:42:38,240 --> 00:42:41,359
现在我们有 um q s o

1197
00:42:41,359 --> 00:42:44,880
所以这个 是另一种方式

1198
00:42:44,880 --> 00:42:48,000
，theta

1199
00:42:48,240 --> 00:42:50,720
中的两个是正态分布，就像我们

1200
00:42:50,720 --> 00:42:51,599
之前看到的那样

1201
00:42:51,599 --> 00:42:54,079
，其均值和方差参数

1202
00:42:54,079 --> 00:42:56,319
与

1203
00:42:56,319 --> 00:42:59,520
策略相同，并且与给定观察值的状态的 q 模型相同

1204
00:42:59,520 --> 00:43:01,280


1205
00:43:01,280 --> 00:43:04,000


1206
00:43:04,400 --> 00:43:08,720
，结果证明那些 mu 和

1207
00:43:08,720 --> 00:43:10,960
sigma 也将有一个函数

1208
00:43:10,960 --> 00:43:14,160
来近似它们，

1209
00:43:14,720 --> 00:43:16,960
以便使主动推理适用

1210
00:43:16,960 --> 00:43:18,240
于强化学习中考虑的任务类型，

1211
00:43:18,240 --> 00:43:19,839


1212
00:43:19,839 --> 00:43:22,400
作者将奖励信号

1213
00:43:22,400 --> 00:43:23,200


1214
00:43:23,200 --> 00:43:25,200
观察视为单独模态中的观察，

1215
00:43:25,200 --> 00:43:27,520
以便将生成模型扩展到

1216
00:43:27,520 --> 00:43:28,160
包括

1217
00:43:28,160 --> 00:43:31,200
一个额外的标量高斯，这是标量的

1218
00:43:31,200 --> 00:43:32,800
另一个

1219
00:43:32,800 --> 00:43:34,800
奖励值，例如

1220
00:43:34,800 --> 00:43:36,960
奖励观察的单个数字 s

1221
00:43:36,960 --> 00:43:38,800
在均值上有一个单位方差

1222
00:43:38,800 --> 00:43:41,119
，这允许他们包装这个神经

1223
00:43:41,119 --> 00:43:42,400
网络

1224
00:43:42,400 --> 00:43:45,119
，它是状态的 uh f sub alpha，

1225
00:43:45,119 --> 00:43:46,480
就像这个奖励

1226
00:43:46,480 --> 00:43:47,920
完全连接的神经网络与

1227
00:43:47,920 --> 00:43:49,119
他们将要训练的参数，

1228
00:43:49,119 --> 00:43:50,079


1229
00:43:50,079 --> 00:43:52,160
所以这真的是 形式

1230
00:43:52,160 --> 00:43:54,640
同源性源于基于模型的

1231
00:43:54,640 --> 00:43:56,079
强化

1232
00:43:56,079 --> 00:43:58,720
学习，现在我们拥有与本讨论

1233
00:43:58,720 --> 00:44:01,440
前面指定的几乎相同的架构，

1234
00:44:01,440 --> 00:44:05,599
其中代理状态

1235
00:44:05,599 --> 00:44:09,040
是感官输入，然后通过此 dnn 运行，

1236
00:44:09,040 --> 00:44:10,000


1237
00:44:10,000 --> 00:44:12,319
并导致

1238
00:44:12,319 --> 00:44:13,599
策略

1239
00:44:13,599 --> 00:44:16,560
或 奖励，但它有点

1240
00:44:16,560 --> 00:44:17,839
不同，但这就是

1241
00:44:17,839 --> 00:44:20,960
我们如何看到许多相同的同调，

1242
00:44:20,960 --> 00:44:24,319
所以

1243
00:44:24,319 --> 00:44:27,040
当新的观察被采样时，学习者会做什么

1244
00:44:27,040 --> 00:44:27,839


1245
00:44:27,839 --> 00:44:29,520
代理更新识别分布的参数

1246
00:44:29,520 --> 00:44:31,200


1247
00:44:31,200 --> 00:44:34,480
以最小化变分自由能或 f

1248
00:44:34,480 --> 00:44:38,160
所以 f 观察

1249
00:44:38,160 --> 00:44:42,319
是期望 嗯好吧好吧

1250
00:44:42,319 --> 00:44:44,480
让我先读完这使得

1251
00:44:44,480 --> 00:44:45,440


1252
00:44:45,440 --> 00:44:47,520
这个 f 要做的是让

1253
00:44:47,520 --> 00:44:48,800
识别分布 函数

1254
00:44:48,800 --> 00:44:51,440
q 收敛于

1255
00:44:51,440 --> 00:44:53,920
难以处理的后验分布

1256
00:44:53,920 --> 00:44:56,720
p 的近似值，从而实现了一种易于处理

1257
00:44:56,720 --> 00:44:58,800
的近似贝叶斯推理

1258
00:44:58,800 --> 00:45:02,079
形式，所以 f 的

1259
00:45:02,079 --> 00:45:04,240
o 随时间与波浪号是随时间

1260
00:45:04,240 --> 00:45:05,119
变化

1261
00:45:05,119 --> 00:45:07,040
的观察自由能，

1262
00:45:07,040 --> 00:45:08,319


1263
00:45:08,319 --> 00:45:12,000
所以这种神奇的自由能是什么？

1264
00:45:12,000 --> 00:45:13,920
在

1265
00:45:13,920 --> 00:45:15,200
这种情况下，

1266
00:45:15,200 --> 00:45:18,000
它只是这个方程，它是

1267
00:45:18,000 --> 00:45:19,839
一个以特定识别模型为条件的

1268
00:45:19,839 --> 00:45:22,720
期望，这是对 q 的期望，这

1269
00:45:22,720 --> 00:45:23,280
将

1270
00:45:23,280 --> 00:45:26,960
与这个 um s

1271
00:45:26,960 --> 00:45:30,160
pi 策略和 theta 参数

1272
00:45:30,160 --> 00:45:34,560
uh 变量有关，这个期望

1273
00:45:34,560 --> 00:45:35,760
是什么，

1274
00:45:35,760 --> 00:45:37,520
这就是一切 这将在

1275
00:45:37,520 --> 00:45:38,960
方括号中

1276
00:45:38,960 --> 00:45:41,040
这个期望将是

1277
00:45:41,040 --> 00:45:43,119
自然对数

1278
00:45:43,119 --> 00:45:46,319
ln 这是一种将

1279
00:45:46,319 --> 00:45:48,640
关于最大化模型拟合优度的问题

1280
00:45:48,640 --> 00:45:50,000


1281
00:45:50,000 --> 00:45:52,319
转化为最小化负数的方法

1282
00:45:52,319 --> 00:45:53,440
有时

1283
00:45:53,440 --> 00:45:55,920
自然法则可以提供一些帮助

1284
00:45:55,920 --> 00:45:56,720


1285
00:45:56,720 --> 00:45:58,880
期望将是

1286
00:45:58,880 --> 00:46:00,880
识别模型

1287
00:46:00,880 --> 00:46:03,599
的自然对数减去基因的自然对数 rative

1288
00:46:03,599 --> 00:46:04,240


1289
00:46:04,240 --> 00:46:06,720
模型同样是我们

1290
00:46:06,720 --> 00:46:07,760
提示我们可以学习

1291
00:46:07,760 --> 00:46:09,280
的部分，然后是被

1292
00:46:09,280 --> 00:46:10,880
描述为难以处理的部分 p

1293
00:46:10,880 --> 00:46:13,359
结果证明这个期望

1294
00:46:13,359 --> 00:46:15,440
总是大于或等于

1295
00:46:15,440 --> 00:46:18,720
观察的 p 的自然对数，

1296
00:46:18,720 --> 00:46:21,599
所以这就是 p

1297
00:46:21,599 --> 00:46:24,000
观察似然模型

1298
00:46:24,000 --> 00:46:26,079
通过随着时间的推移最小化观察的自由能

1299
00:46:26,079 --> 00:46:27,760


1300
00:46:27,760 --> 00:46:29,839
代理启发式

1301
00:46:29,839 --> 00:46:31,760
地收敛于这个棘手的 p

1302
00:46:31,760 --> 00:46:34,960
分布，因为

1303
00:46:34,960 --> 00:46:38,079
q 仅超过国家的

1304
00:46:38,079 --> 00:46:40,960
政策和参数，并且 p

1305
00:46:40,960 --> 00:46:42,640
确实包括并关注

1306
00:46:42,640 --> 00:46:44,079
观察结果

1307
00:46:44,079 --> 00:46:46,640
这允许 代理要做的

1308
00:46:46,640 --> 00:46:48,319
是专注于通过队列对相关

1309
00:46:48,319 --> 00:46:50,079
的状态、策略和

1310
00:46:50,079 --> 00:46:52,319
参数进行建模

1311
00:46:52,319 --> 00:46:55,520
，然后可能

1312
00:46:55,520 --> 00:46:58,960
在该模型中使用数学斜线非活动行为来

1313
00:46:58,960 --> 00:47:01,119
有吸引力地包含条件或

1314
00:47:01,119 --> 00:47:02,800
从其观察中学习，

1315
00:47:02,800 --> 00:47:04,800
这样我们就可以带来以前的知识

1316
00:47:04,800 --> 00:47:06,400
就像贝叶斯模型

1317
00:47:06,400 --> 00:47:07,359
允许的一样，

1318
00:47:07,359 --> 00:47:10,240
但也有办法处理稀疏

1319
00:47:10,240 --> 00:47:11,359
或密集 信息，

1320
00:47:11,359 --> 00:47:14,240
因为它是

1321
00:47:14,480 --> 00:47:18,000
好的，关键的主动推理还

1322
00:47:18,000 --> 00:47:19,599
提出，代理的目标和

1323
00:47:19,599 --> 00:47:21,440
欲望在生成

1324
00:47:21,440 --> 00:47:23,520
模型中被编码为有利观察的先验偏好，

1325
00:47:23,520 --> 00:47:24,640


1326
00:47:24,640 --> 00:47:28,000
即 37 摄氏度自由能下的血液温度，

1327
00:47:28,000 --> 00:47:29,839
然后提供了一个代理，

1328
00:47:29,839 --> 00:47:31,920
说明一些观察是多么令人惊讶，即不太可能

1329
00:47:31,920 --> 00:47:34,160
在 代理模型

1330
00:47:34,160 --> 00:47:36,319
在最小化方程 1 的同时提供了一个

1331
00:47:36,319 --> 00:47:38,000
估计，说明我们的一些观察结果是多么令人惊讶，

1332
00:47:38,000 --> 00:47:39,760
它不能

1333
00:47:39,760 --> 00:47:41,040
直接减少数量，

1334
00:47:41,040 --> 00:47:44,240
所以在这里方程 1 我们定义了 f

1335
00:47:44,240 --> 00:47:46,720
是什么，但它只是 f 是什么的定义和

1336
00:47:46,720 --> 00:47:47,839
界限

1337
00:47:47,839 --> 00:47:51,359
它不能直接减少这个

1338
00:47:51,359 --> 00:47:53,280
数量 所以它与政策并没有真正的

1339
00:47:53,280 --> 00:47:54,960
关系，

1340
00:47:54,960 --> 00:47:58,720
因为

1341
00:47:58,720 --> 00:48:01,200
实现这一目标的直接方法必须通过行动改变他们的

1342
00:48:01,200 --> 00:48:03,280
观察，

1343
00:48:03,280 --> 00:48:05,280
以最小化变分自由

1344
00:48:05,280 --> 00:48:07,040
能，确保最小

1345
00:48:07,040 --> 00:48:07,599


1346
00:48:07,599 --> 00:48:10,160


1347
00:48:10,160 --> 00:48:12,880
化观察概率模型的意外负自然对数

1348
00:48:12,880 --> 00:48:14,720
或最大化贝叶斯

1349
00:48:14,720 --> 00:48:16,240
模型证据

1350
00:48:16,240 --> 00:48:19,440
p 通过时间的观察 由于

1351
00:48:19,440 --> 00:48:20,079
自由能

1352
00:48:20,079 --> 00:48:21,920
提供了意外的上限，

1353
00:48:21,920 --> 00:48:23,599
即等式一个

1354
00:48:23,599 --> 00:48:26,160
主动推理因此建议

1355
00:48:26,160 --> 00:48:27,680
代理选择策略

1356
00:48:27,680 --> 00:48:29,520
以最小化预期的

1357
00:48:29,520 --> 00:48:30,960


1358
00:48:30,960 --> 00:48:34,000
自由能幻想 g 其中

1359
00:48:34,000 --> 00:48:36,160
给定策略 pi 在未来某个

1360
00:48:36,160 --> 00:48:38,240
时间

1361
00:48:38,240 --> 00:48:41,760
的预期自由能将被定义为 所以

1362
00:48:41,760 --> 00:48:44,880
我们想做的不仅仅是更新

1363
00:48:44,880 --> 00:48:47,839
我们的内部模型来限制我们

1364
00:48:47,839 --> 00:48:49,359
对观察的惊讶我们不只是想

1365
00:48:49,359 --> 00:48:51,119
适应世界的统计描述模型

1366
00:48:51,119 --> 00:48:52,160


1367
00:48:52,160 --> 00:48:53,920
我们想要减少未来的不确定性，

1368
00:48:53,920 --> 00:48:55,920
这是一个未来的时间点 t

1369
00:48:55,920 --> 00:48:59,440
tau 通过我们现在采用的策略 pi

1370
00:48:59,440 --> 00:49:00,960


1371
00:49:00,960 --> 00:49:02,960
这个可最小化的预期自由能

1372
00:49:02,960 --> 00:49:04,880
函数 fancy

1373
00:49:04,880 --> 00:49:07,599
g 将接受

1374
00:49:07,599 --> 00:49:08,800
策略选择

1375
00:49:08,800 --> 00:49:11,680
和未来时间步长的参数所以 fancy g

1376
00:49:11,680 --> 00:49:12,640
fancy pi

1377
00:49:12,640 --> 00:49:15,760
fancy t 这就是这种情况下的自由能函数

1378
00:49:15,760 --> 00:49:17,920


1379
00:49:17,920 --> 00:49:21,680
和

1380
00:49:21,680 --> 00:49:24,319
优化将

1381
00:49:24,319 --> 00:49:25,599
允许有效行动的

1382
00:49:25,599 --> 00:49:27,599
值将被定义为

1383
00:49:27,599 --> 00:49:28,720


1384
00:49:28,720 --> 00:49:31,760
与 q 模型相关的期望值

1385
00:49:31,760 --> 00:49:34,720
这是关于

1386
00:49:34,720 --> 00:49:37,119
给定政策模型的观察状态和参数，所以

1387
00:49:37,119 --> 00:49:39,359
鉴于我的政策是这样的，

1388
00:49:39,359 --> 00:49:42,720
那么世界的状态和转变将如何

1389
00:49:42,720 --> 00:49:43,599


1390
00:49:43,599 --> 00:49:46,960
出现，这将

1391
00:49:46,960 --> 00:49:50,400
是括号中这个数量的期望，

1392
00:49:50,400 --> 00:49:51,280


1393
00:49:51,280 --> 00:49:53,760
它将成为状态的对数 和

1394
00:49:53,760 --> 00:49:54,640
参数，

1395
00:49:54,640 --> 00:49:58,079
所以这是 s sub t 的 q

1396
00:49:58,079 --> 00:50:01,359
和给定策略的参数，

1397
00:50:01,359 --> 00:50:04,480
所以这就是我将处于什么状态以及

1398
00:50:04,480 --> 00:50:06,960
我会怎么想

1399
00:50:06,960 --> 00:50:10,000
嗯，可能这些只是

1400
00:50:10,000 --> 00:50:10,400


1401
00:50:10,400 --> 00:50:12,960
首先通过口头解释，

1402
00:50:12,960 --> 00:50:15,119
只看数学，但

1403
00:50:15,119 --> 00:50:18,810
什么状态

1404
00:50:18,810 --> 00:50:20,000


1405
00:50:20,000 --> 00:50:23,359
考虑到我的政策，我现在在[音乐]中的参数，所以如果我

1406
00:50:23,359 --> 00:50:25,599
每天出去散步，它将如何

1407
00:50:25,599 --> 00:50:27,119
影响我的

1408
00:50:27,119 --> 00:50:29,200
状态我的模型当时必须是什么

1409
00:50:29,200 --> 00:50:30,319


1410
00:50:30,319 --> 00:50:32,880
，然后那个数量减去自然对

1411
00:50:32,880 --> 00:50:34,000
数 p

1412
00:50:34,000 --> 00:50:36,400
模型中给定策略的观察状态，

1413
00:50:36,400 --> 00:50:38,000
所以我们

1414
00:50:38,000 --> 00:50:40,000
想要的部分实际上是观察

1415
00:50:40,000 --> 00:50:43,520
值是正确的值，但我们能做的

1416
00:50:43,520 --> 00:50:46,480
就是嗯，只是根据

1417
00:50:46,480 --> 00:50:48,960
策略

1418
00:50:50,160 --> 00:50:53,760
和 g 值来调节状态 总是大于

1419
00:50:53,760 --> 00:50:54,240


1420
00:50:54,240 --> 00:50:55,760
负数，即等式二的最后一部分，

1421
00:50:55,760 --> 00:50:57,599
然后

1422
00:50:57,599 --> 00:50:59,040


1423
00:50:59,040 --> 00:51:01,599
是这个 q 的负期望，这是以政策为条件的观察结果

1424
00:51:01,599 --> 00:51:03,599
，这

1425
00:51:03,599 --> 00:51:08,319
就像事情实际上会变成

1426
00:51:08,319 --> 00:51:10,880
生成模型的这个对数部分的 um，

1427
00:51:10,880 --> 00:51:11,920
即

1428
00:51:11,920 --> 00:51:14,319
给出的观察结果 政策

1429
00:51:14,319 --> 00:51:15,760
就是事情的发展方向，

1430
00:51:15,760 --> 00:51:18,160
所以也许还有其他解释

1431
00:51:18,160 --> 00:51:18,800
或其他

1432
00:51:18,800 --> 00:51:20,240
部分非常关键，但我

1433
00:51:20,240 --> 00:51:22,000
认为这是关键的

1434
00:51:22,000 --> 00:51:25,119
表述之一，即存在一个

1435
00:51:25,119 --> 00:51:29,119
与政策相关的优化问题

1436
00:51:29,119 --> 00:51:32,240
，可以用变分的方式

1437
00:51:32,240 --> 00:51:35,520
表达 受到

1438
00:51:35,520 --> 00:51:36,960
类似自由能的

1439
00:51:36,960 --> 00:51:40,000
策略的限制，可以

1440
00:51:40,000 --> 00:51:43,440
轻松地估计一些

1441
00:51:43,440 --> 00:51:46,720
其他函数 q 与基本上我们想知道的相关的东西

1442
00:51:46,720 --> 00:51:47,760
，

1443
00:51:47,760 --> 00:51:50,319


1444
00:51:50,319 --> 00:51:51,440
这就像

1445
00:51:51,440 --> 00:51:54,559
好的观察，我查看我的

1446
00:51:54,559 --> 00:51:58,160
比特币钱包并且有 15 个比特币

1447
00:51:58,160 --> 00:52:01,200
我有什么政策 如果只有一个人知道，就可以

1448
00:52:01,200 --> 00:52:03,680
看到这种观察或反

1449
00:52:03,680 --> 00:52:06,160
事实存在

1450
00:52:06,160 --> 00:52:08,880
，这就是为什么会有

1451
00:52:08,880 --> 00:52:09,839
这种易处理的

1452
00:52:09,839 --> 00:52:12,800
有界方程可能我我

1453
00:52:12,800 --> 00:52:13,839
认为

1454
00:52:13,839 --> 00:52:16,960
这里有很多话要说，亚历克和其他任何人我都会很

1455
00:52:16,960 --> 00:52:18,000
感激任何其他

1456
00:52:18,000 --> 00:52:20,800
输入，但这只是一个阅读它的

1457
00:52:20,800 --> 00:52:21,680
好，

1458
00:52:21,680 --> 00:52:23,920
所以这是我

1459
00:52:23,920 --> 00:52:25,440
想在那个深度水平上经历的大部分部分

1460
00:52:25,440 --> 00:52:27,280
但随后只是

1461
00:52:27,280 --> 00:52:29,680
传达其他部分以及他们为论文所做的工作

1462
00:52:29,680 --> 00:52:30,400
，

1463
00:52:30,400 --> 00:52:32,160
而不是深入每个方程

1464
00:52:32,160 --> 00:52:33,599
，然后讨论数字，

1465
00:52:33,599 --> 00:52:36,960
所以 3.2 是学习和推理

1466
00:52:36,960 --> 00:52:37,760
部分

1467
00:52:37,760 --> 00:52:41,119
，为了实际实施

1468
00:52:41,119 --> 00:52:43,520
这个优化方案，因为它被布置

1469
00:52:43,520 --> 00:52:44,160


1470
00:52:44,160 --> 00:52:46,079
事实证明，必须有一个更新

1471
00:52:46,079 --> 00:52:47,599
过程，

1472
00:52:47,599 --> 00:52:49,760
所以它会是一种呃坚持

1473
00:52:49,760 --> 00:52:51,359
已经奏效的东西，还是会

1474
00:52:51,359 --> 00:52:51,760
成为

1475
00:52:51,760 --> 00:52:53,760
新奇搜索那些

1476
00:52:53,760 --> 00:52:54,880
是优化

1477
00:52:54,880 --> 00:52:56,720
算法必须导航

1478
00:52:56,720 --> 00:52:59,040
权衡的东西 隐含的 uh

1479
00:52:59,040 --> 00:53:00,880
根据不同的问题采用不同的策略

1480
00:53:00,880 --> 00:53:02,079


1481
00:53:02,079 --> 00:53:05,599
，因此本节定义了如何随时间定义这个

1482
00:53:05,599 --> 00:53:09,280
f uh 变分自由能

1483
00:53:09,280 --> 00:53:11,119


1484
00:53:11,119 --> 00:53:12,720
，我不打算介绍

1485
00:53:12,720 --> 00:53:14,559
实现细节 b  ut alex

1486
00:53:14,559 --> 00:53:17,520
alec 如果你知道

1487
00:53:17,520 --> 00:53:19,119
向我们展示了一个模拟或类似的东西会很酷

1488
00:53:19,119 --> 00:53:20,880
，

1489
00:53:20,880 --> 00:53:23,920
呃 3.3 是关于策略选择的，

1490
00:53:23,920 --> 00:53:25,280
这是他们

1491
00:53:25,280 --> 00:53:27,440
在主动推理下写的内容 策略选择

1492
00:53:27,440 --> 00:53:29,040
是通过更新策略的 q 来实现的，

1493
00:53:29,040 --> 00:53:31,040
以最大限度地减少

1494
00:53:31,040 --> 00:53:33,200
花式 f 的自由能

1495
00:53:33,200 --> 00:53:35,440
考虑到政策

1496
00:53:35,440 --> 00:53:37,280
最小化预期自由能的先验信念，

1497
00:53:37,280 --> 00:53:41,040
即政策的 p 与

1498
00:53:41,040 --> 00:53:44,240
此选择相关 soft max 与

1499
00:53:44,240 --> 00:53:47,920
um 负 g 负 uh

1500
00:53:47,920 --> 00:53:51,280
政策空间的预期自由能

1501
00:53:51,280 --> 00:53:53,359
与

1502
00:53:53,359 --> 00:53:55,920
等式 3 中指定的短自由

1503
00:53:55,920 --> 00:53:57,359
能最小化

1504
00:53:57,359 --> 00:54:02,079
时 uh  q 策略的分布

1505
00:54:02,079 --> 00:54:05,599
与最优自由能相同

1506
00:54:05,599 --> 00:54:08,160


1507
00:54:08,160 --> 00:54:10,000


1508
00:54:10,000 --> 00:54:13,200


1509
00:54:13,200 --> 00:54:14,800


1510
00:54:14,800 --> 00:54:16,240


1511
00:54:16,240 --> 00:54:19,200


1512
00:54:19,200 --> 00:54:20,720


1513
00:54:20,720 --> 00:54:22,720
所以这就像连接四个

1514
00:54:22,720 --> 00:54:25,520
你可以用完或井字游戏

1515
00:54:25,520 --> 00:54:26,160
你可以用完

1516
00:54:26,160 --> 00:54:27,839
每一个选项 在

1517
00:54:27,839 --> 00:54:29,599
该分支点的游戏

1518
00:54:29,599 --> 00:54:31,680
计算每个可能结果的绝对值

1519
00:54:31,680 --> 00:54:33,520


1520
00:54:33,520 --> 00:54:35,920
，然后做出选择，但是在

1521
00:54:35,920 --> 00:54:37,760
连续动作空间中存在

1522
00:54:37,760 --> 00:54:39,839
无限策略，这意味着需要一种替代

1523
00:54:39,839 --> 00:54:41,040
方法

1524
00:54:41,040 --> 00:54:42,960
，这是一个非常酷的句子，因为它

1525
00:54:42,960 --> 00:54:45,200
确实很好

1526
00:54:45,200 --> 00:54:47,599
地传达了实际上连续动作

1527
00:54:47,599 --> 00:54:48,240


1528
00:54:48,240 --> 00:54:50,720
即使对于单个变量来说，空间也是一个真正

1529
00:54:50,720 --> 00:54:51,680
不同的领域，而

1530
00:54:51,680 --> 00:54:54,400
不是让我们说囚徒困境

1531
00:54:54,400 --> 00:54:55,119


1532
00:54:55,119 --> 00:54:58,160
游戏有时，呃

1533
00:54:58,160 --> 00:55:00,160
，算法中几乎没有重叠，这就是为什么本文

1534
00:55:00,160 --> 00:55:02,880
实际上提前反映了这一点，并且

1535
00:55:02,880 --> 00:55:06,079
在第 3.4 节轨迹采样中有更多细节，

1536
00:55:06,079 --> 00:55:09,200
所以现在如何

1537
00:55:09,200 --> 00:55:10,559
你是从

1538
00:55:10,559 --> 00:55:12,400


1539
00:55:12,400 --> 00:55:15,200
政策和其他变量之间的

1540
00:55:15,200 --> 00:55:16,720


1541
00:55:16,720 --> 00:55:17,920


1542
00:55:17,920 --> 00:55:21,119


1543
00:55:21,119 --> 00:55:21,520


1544
00:55:21,520 --> 00:55:23,520


1545
00:55:23,520 --> 00:55:25,599
分布

1546
00:55:25,599 --> 00:55:27,839
关系开始的吗

1547
00:55:27,839 --> 00:55:29,680
对于任何具体的政策，

1548
00:55:29,680 --> 00:55:31,599
他们必须首先评估 预期的

1549
00:55:31,599 --> 00:55:33,680
未来信念取决于该政策，

1550
00:55:33,680 --> 00:55:37,440
所以呃，

1551
00:55:37,440 --> 00:55:40,559
在这种规范框架中，

1552
00:55:40,559 --> 00:55:42,480
你不能真正承担，这是一个次要辩论，我们

1553
00:55:42,480 --> 00:55:44,480
肯定可以讨论人类在多大程度上

1554
00:55:44,480 --> 00:55:45,119


1555
00:55:45,119 --> 00:55:46,880
认知这些经验，但

1556
00:55:46,880 --> 00:55:48,160
我们只是要

1557
00:55:48,160 --> 00:55:50,160
有点用故意的立场

1558
00:55:50,160 --> 00:55:51,760
和机器学习控制理论采取的那种，

1559
00:55:51,760 --> 00:55:52,160


1560
00:55:52,160 --> 00:55:55,359
但因此相信它

1561
00:55:55,359 --> 00:55:57,200
不一定是认知的，

1562
00:55:57,200 --> 00:55:58,400
我们只是在考虑代理

1563
00:55:58,400 --> 00:56:00,319
想要做什么来成功，

1564
00:56:00,319 --> 00:56:02,240
但基本上如果代理没有

1565
00:56:02,240 --> 00:56:03,920


1566
00:56:03,920 --> 00:56:06,400
该政策的预期未来信念序列，

1567
00:56:06,400 --> 00:56:08,160
他们将非常难以

1568
00:56:08,160 --> 00:56:09,599
承担它，

1569
00:56:09,599 --> 00:56:12,559
并且转换事实是过渡

1570
00:56:12,559 --> 00:56:13,359


1571
00:56:13,359 --> 00:56:14,880
模型是概率性的

1572
00:56:14,880 --> 00:56:16,480
，并且过渡模型或

1573
00:56:16,480 --> 00:56:17,599
随机变量的参数会

1574
00:56:17,599 --> 00:56:19,440
导致未来轨迹上的分布，

1575
00:56:19,440 --> 00:56:21,040


1576
00:56:21,040 --> 00:56:23,520
而不是仅仅玩 我们正在考虑的每一个可能的

1577
00:56:23,520 --> 00:56:24,640
国际象棋走法，

1578
00:56:24,640 --> 00:56:27,280
我们如何拟合

1579
00:56:27,280 --> 00:56:28,559


1580
00:56:28,559 --> 00:56:31,200
一种更高级的模型以及国际象棋

1581
00:56:31,200 --> 00:56:32,480
仍然是离散的，所以

1582
00:56:32,480 --> 00:56:35,040
l  et's choose 我们将看到一个具体的

1583
00:56:35,040 --> 00:56:35,760
例子，

1584
00:56:35,760 --> 00:56:38,319
但这只是

1585
00:56:38,319 --> 00:56:38,880


1586
00:56:38,880 --> 00:56:42,799
这个数字后面的连续优化，但这就像

1587
00:56:42,799 --> 00:56:45,680


1588
00:56:45,680 --> 00:56:46,880
国际象棋游戏中未来分支点的分布，

1589
00:56:46,880 --> 00:56:49,280
所以无论它是离散的还是连续的，

1590
00:56:49,280 --> 00:56:50,880
你仍然可以有这个

1591
00:56:50,880 --> 00:56:51,839
不

1592
00:56:51,839 --> 00:56:54,559
确定性元素 状态空间中未来轨迹的分布范围，

1593
00:56:54,559 --> 00:56:55,440


1594
00:56:55,440 --> 00:56:59,040
因此存在几种方法

1595
00:56:59,040 --> 00:57:01,119
来近似

1596
00:57:01,119 --> 00:57:02,559
不确定轨迹

1597
00:57:02,559 --> 00:57:04,480
的传播，例如，一种可以完全忽略不确定性

1598
00:57:04,480 --> 00:57:06,160
并传播分布的均值，

1599
00:57:06,160 --> 00:57:07,280


1600
00:57:07,280 --> 00:57:09,440
或者可以显式传播分布的完整

1601
00:57:09,440 --> 00:57:11,440
统计数据，

1602
00:57:11,440 --> 00:57:13,680
因此这些是一种 两种极端

1603
00:57:13,680 --> 00:57:15,839
方法其中之一就是说是的，

1604
00:57:15,839 --> 00:57:17,680
集成建模正在跟踪平均值

1605
00:57:17,680 --> 00:57:19,200
，所以我将继续前进

1606
00:57:19,200 --> 00:57:19,920


1607
00:57:19,920 --> 00:57:22,160
，然后另一种方法基本上是

1608
00:57:22,160 --> 00:57:23,359
保持

1609
00:57:23,359 --> 00:57:25,359
对整个分布的总结，并将其

1610
00:57:25,359 --> 00:57:26,880
用作正在学习的内容

1611
00:57:26,880 --> 00:57:29,520


1612
00:57:29,520 --> 00:57:32,400
在当前的工作中，它使用了一种

1613
00:57:32,400 --> 00:57:33,359
粒子方法

1614
00:57:33,359 --> 00:57:35,839
，即蒙特卡洛 基于采样的

1615
00:57:35,839 --> 00:57:36,960
方案

1616
00:57:36,960 --> 00:57:39,680
样本被特别传播，我们

1617
00:57:39,680 --> 00:57:41,119
考虑

1618
00:57:41,119 --> 00:57:43,680


1619
00:57:43,680 --> 00:57:44,480


1620
00:57:44,480 --> 00:57:48,799
从立方体数据中提取的参数分布数据中的这个大 b 样本，

1621
00:57:49,280 --> 00:57:52,960
这些部分传达了如何

1622
00:57:52,960 --> 00:57:54,480


1623
00:57:54,480 --> 00:57:56,480
在模型中完成策略选择的信息，以及如何

1624
00:57:56,480 --> 00:57:58,400
探索策略适应度环境以

1625
00:57:58,400 --> 00:57:59,040


1626
00:57:59,040 --> 00:58:00,319
实现 对轨迹的预测控制，

1627
00:58:00,319 --> 00:58:02,240
因此

1628
00:58:02,240 --> 00:58:05,440
通过时间实施的政策必须

1629
00:58:05,440 --> 00:58:06,720
涉及一些

1630
00:58:06,720 --> 00:58:10,480
预测控制元素，好吧，

1631
00:58:10,480 --> 00:58:14,079
然后是第 3.5 节 3.6 节，

1632
00:58:14,079 --> 00:58:17,200
所以第 3.5 节有计算这个

1633
00:58:17,200 --> 00:58:18,960
预期自由能

1634
00:58:18,960 --> 00:58:22,480
值的详细信息，正如标题可能

1635
00:58:22,480 --> 00:58:24,480
在本节中暗示的那样，他们描述了如何

1636
00:58:24,480 --> 00:58:25,599
评估 负 g

1637
00:58:25,599 --> 00:58:29,520
表示他们使用这种

1638
00:58:29,520 --> 00:58:31,760
符号方便来谈论

1639
00:58:31,760 --> 00:58:33,200
向前发展的政策的政策，

1640
00:58:33,200 --> 00:58:36,720
所以就像一个裸馅饼，

1641
00:58:36,720 --> 00:58:40,240


1642
00:58:40,240 --> 00:58:43,440
而不是与时间状态 um 和

1643
00:58:43,440 --> 00:58:44,559
不确定性

1644
00:58:44,559 --> 00:58:47,599
以及负预期自由能有关的上标

1645
00:58:47,599 --> 00:58:48,400
这就是

1646
00:58:48,400 --> 00:58:49,839
我们试图在这里得到的

1647
00:58:49,839 --> 00:58:51,760
负g

1648
00:58:51,760 --> 00:58:54,880
是e 等于随着时间的推移这种负

1649
00:58:54,880 --> 00:58:56,480
预期自由能

1650
00:58:56,480 --> 00:58:59,520
的总和，然后

1651
00:58:59,520 --> 00:59:03,599
这就是分解，

1652
00:59:03,599 --> 00:59:06,720
不是我的领域，但我

1653
00:59:06,720 --> 00:59:09,440
认为这意味着

1654
00:59:09,440 --> 00:59:10,480
分解

1655
00:59:10,480 --> 00:59:13,760
成这个状态信息博弈

1656
00:59:13,760 --> 00:59:16,640
增益和外在价值分量，所以

1657
00:59:16,640 --> 00:59:18,240
这种分解为探索

1658
00:59:18,240 --> 00:59:19,200
和利用

1659
00:59:19,200 --> 00:59:21,920
组件或其他一些

1660
00:59:21,920 --> 00:59:22,960


1661
00:59:22,960 --> 00:59:25,520


1662
00:59:25,520 --> 00:59:26,799


1663
00:59:26,799 --> 00:59:29,040


1664
00:59:29,040 --> 00:59:30,480


1665
00:59:30,480 --> 00:59:34,079
折衷方案 呃似乎表现为

1666
00:59:34,079 --> 00:59:36,480
模型精度受到模型

1667
00:59:36,480 --> 00:59:37,359
复杂性的惩罚，或者

1668
00:59:37,359 --> 00:59:40,640
这个加上这总是

1669
00:59:40,640 --> 00:59:42,640
等式中的两个部分是不是只有

1670
00:59:42,640 --> 00:59:44,960
一个项可以是三个项

1671
00:59:44,960 --> 00:59:48,000
在这里它是三个项但是嗯

1672
00:59:48,000 --> 00:59:52,000
或四个所以我不完全是 确定

1673
00:59:52,000 --> 00:59:55,280
为什么有时它有或多或少的术语，

1674
00:59:55,280 --> 00:59:58,319
但这就是我很好奇的原因，

1675
00:59:58,319 --> 01:00:01,119
然后在 3.6 中，他们编写

1676
01:00:01,119 --> 01:00:01,760


1677
01:00:01,760 --> 01:00:04,000
了前面部分中介绍的模型作为

1678
01:00:04,000 --> 01:00:06,079
最通用的公式，适用

1679
01:00:06,079 --> 01:00:07,760
于部分 o 在接下来的观察和完全

1680
01:00:07,760 --> 01:00:09,599
观察的环境

1681
01:00:09,599 --> 01:00:11,200
中，我们为完全观察的情况描述了一个

1682
01:00:11,200 --> 01:00:13,119
充满毛皮的

1683
01:00:13,119 --> 01:00:15,040
实现，

1684
01:00:15,040 --> 01:00:16,880


1685
01:00:16,880 --> 01:00:19,119
为未来的工作留下了对部分观察的情况的分析，

1686
01:00:19,119 --> 01:00:21,680
所以它只是

1687
01:00:21,680 --> 01:00:23,040
完全观察的情况

1688
01:00:23,040 --> 01:00:26,160
的另一个包装，有部分观察，

1689
01:00:26,160 --> 01:00:28,160
所以他们 决定使用一些基准

1690
01:00:28,160 --> 01:00:29,599
来帮助

1691
01:00:29,599 --> 01:00:32,480
他们基本上进行全面观察，

1692
01:00:32,480 --> 01:00:33,200
这不像

1693
01:00:33,200 --> 01:00:35,599
作弊他们将要

1694
01:00:35,599 --> 01:00:36,240
描述

1695
01:00:36,240 --> 01:00:38,240
的示例有点像

1696
01:00:38,240 --> 01:00:39,440
在棍子上平衡餐盘，

1697
01:00:39,440 --> 01:00:40,880
所以在这种情况下，您确实可以全面

1698
01:00:40,880 --> 01:00:42,640
观察模型

1699
01:00:42,640 --> 01:00:45,440
所以仅仅因为你不能很好地控制嗯嗯

1700
01:00:45,440 --> 01:00:46,079


1701
01:00:46,079 --> 01:00:47,760
它可能会或可能不会给定

1702
01:00:47,760 --> 01:00:49,119
一定的棒和

1703
01:00:49,119 --> 01:00:52,079
运动反射时间，但至少

1704
01:00:52,079 --> 01:00:53,520
你可以观察到一切，所以

1705
01:00:53,520 --> 01:00:55,200
还有无法观察到的控制理论

1706
01:00:55,200 --> 01:00:56,960
问题，然后是

1707
01:00:56,960 --> 01:00:58,160
系统的问题 实际上

1708
01:00:58,160 --> 01:01:00,160
就像餐盘一样可以理解和控制，

1709
01:01:00,160 --> 01:01:01,599
但

1710
01:01:01,599 --> 01:01:03,760
你只会得到扭曲或恶意的

1711
01:01:03,760 --> 01:01:04,640


1712
01:01:04,640 --> 01:01:06,319
信息 其他那些您可以获得完美

1713
01:01:06,319 --> 01:01:08,000
信息但仅在时间点

1714
01:01:08,000 --> 01:01:09,599
上的游戏，并且

1715
01:01:09,599 --> 01:01:10,960
有很多不同的方式可以

1716
01:01:10,960 --> 01:01:12,640
发挥作用，但这就是

1717
01:01:12,640 --> 01:01:15,680
模型中可以切换的部分

1718
01:01:15,680 --> 01:01:17,520


1719
01:01:17,520 --> 01:01:19,200
，这也是我的 认为听到任何作者的意见会很

1720
01:01:19,200 --> 01:01:20,799
有趣，

1721
01:01:20,799 --> 01:01:22,880


1722
01:01:22,880 --> 01:01:26,240
所以在第 4 节中，他们

1723
01:01:26,240 --> 01:01:28,799
进行了一些实验，这

1724
01:01:28,799 --> 01:01:29,760


1725
01:01:29,760 --> 01:01:32,720
是他们论文的结果阶段，他们

1726
01:01:32,720 --> 01:01:34,400
描述了他们如何调查

1727
01:01:34,400 --> 01:01:37,280
提出的主动

1728
01:01:37,280 --> 01:01:39,040
推理模型是否可以成功推广

1729
01:01:39,040 --> 01:01:41,200
在没有奖励观察的情况下进行

1730
01:01:41,200 --> 01:01:43,440
探索，即探索，所以

1731
01:01:43,440 --> 01:01:45,119
对于无模型

1732
01:01:45,119 --> 01:01:45,760


1733
01:01:45,760 --> 01:01:47,520
强化学习者来说，真正困难的是，当

1734
01:01:47,520 --> 01:01:48,799
它没有得到奖励时，

1735
01:01:48,799 --> 01:01:50,720
它做得不好，不能很好地探索，

1736
01:01:50,720 --> 01:01:52,000


1737
01:01:52,000 --> 01:01:54,960
因为它没有获胜，并且两个

1738
01:01:54,960 --> 01:01:56,799
是否 模型可以

1739
01:01:56,799 --> 01:01:58,319
在

1740
01:01:58,319 --> 01:02:00,559
具有挑战性的连续控制任务（即

1741
01:02:00,559 --> 01:02:02,400
开发）上实现良好的性能和高样本效率，因此这就是需要

1742
01:02:02,400 --> 01:02:04,240
跟踪的东西

1743
01:02:04,240 --> 01:02:06,079
我们分别评估模型的这两个方面，将

1744
01:02:06,079 --> 01:02:07,760


1745
01:02:07,760 --> 01:02:08,400
它们的联合

1746
01:02:08,400 --> 01:02:10,400
性能分析，即探索

1747
01:02:10,400 --> 01:02:12,000
利用困境

1748
01:02:12,000 --> 01:02:14,319
留给未来的工作，所以再次

1749
01:02:14,319 --> 01:02:15,039


1750
01:02:15,039 --> 01:02:17,440
在纯用例中分别展示

1751
01:02:17,440 --> 01:02:18,480
它，表明它可以做任何一个

1752
01:02:18,480 --> 01:02:20,079
，然后它会像

1753
01:02:20,079 --> 01:02:21,760
他们两个之间的权衡或

1754
01:02:21,760 --> 01:02:23,680
最终将调解这种权衡的包装层

1755
01:02:23,680 --> 01:02:25,839


1756
01:02:25,839 --> 01:02:27,599
他们要做的探索任务

1757
01:02:27,599 --> 01:02:29,839
被称为山地车

1758
01:02:29,839 --> 01:02:33,039
，你是这个山谷底部的一辆小车

1759
01:02:33,039 --> 01:02:34,079


1760
01:02:34,079 --> 01:02:37,200
你可以用前进踏板向前推，

1761
01:02:37,200 --> 01:02:40,480
或者你可以

1762
01:02:40,480 --> 01:02:43,039
用倒车踏板推动倒车，但

1763
01:02:43,039 --> 01:02:44,880
你没有足够强大的引擎

1764
01:02:44,880 --> 01:02:47,760
来一次就到达黄旗，

1765
01:02:47,760 --> 01:02:48,000


1766
01:02:48,000 --> 01:02:50,160
就像你在底部

1767
01:02:50,160 --> 01:02:51,280
山上，

1768
01:02:51,280 --> 01:02:53,599
你的自行车处于三七档，但你

1769
01:02:53,599 --> 01:02:55,280
可以稍微上去一点，然后回来

1770
01:02:55,280 --> 01:02:56,880
一点，所以在这里你必须

1771
01:02:56,880 --> 01:02:58,640
探索并找出一种策略来

1772
01:02:58,640 --> 01:03:00,480
帮助你越来越多地探索

1773
01:03:00,480 --> 01:03:02,640
，以便 goi 获得足够的速度

1774
01:03:02,640 --> 01:03:04,079
爬上左边的小山，以便获得

1775
01:03:04,079 --> 01:03:07,359
黄色的平坦，然后他们将要谈论的漏洞利用任务

1776
01:03:07,359 --> 01:03:10,079


1777
01:03:10,079 --> 01:03:11,119
是双重的，

1778
01:03:11,119 --> 01:03:12,960
还有倒立摆任务，所以

1779
01:03:12,960 --> 01:03:14,480
这里我们仍然是一辆小推车

1780
01:03:14,480 --> 01:03:17,119
或类似的东西，我们可以

1781
01:03:17,119 --> 01:03:18,799
在轨道上向前或向后移动

1782
01:03:18,799 --> 01:03:21,200
，然后是我们

1783
01:03:21,200 --> 01:03:21,920
试图保持

1784
01:03:21,920 --> 01:03:23,599
直立的钟摆，这就像

1785
01:03:23,599 --> 01:03:25,520
一根棍子上的餐盘，

1786
01:03:25,520 --> 01:03:27,920
然后是漏斗任务，这是一个

1787
01:03:27,920 --> 01:03:29,119
跳跃

1788
01:03:29,119 --> 01:03:32,400
运动协调任务，所以让我们

1789
01:03:32,400 --> 01:03:33,920
看看他们实际上做了什么 对于这

1790
01:03:33,920 --> 01:03:34,240
两个

1791
01:03:34,240 --> 01:03:37,200
实验中的每一个，然后查看主动

1792
01:03:37,200 --> 01:03:39,520
推理学习器如何与

1793
01:03:39,520 --> 01:03:43,039
其他算法叠加，因此山地车

1794
01:03:43,039 --> 01:03:45,440
示例是

1795
01:03:45,440 --> 01:03:47,039
位于两座山之间的一维轨道，

1796
01:03:47,039 --> 01:03:48,640
目标是在右侧开车上山，

1797
01:03:48,640 --> 01:03:50,160
但汽车的引擎是

1798
01:03:50,160 --> 01:03:51,520
不够强壮，无法一次爬山

1799
01:03:51,520 --> 01:03:52,720


1800
01:03:52,720 --> 01:03:55,359


1801
01:03:55,359 --> 01:03:56,880


1802
01:03:56,880 --> 01:03:58,799


1803
01:03:58,799 --> 01:03:59,200


1804
01:03:59,200 --> 01:04:02,319


1805
01:04:02,319 --> 01:04:05,359
代码在 openai 网站上，在

1806
01:04:05,359 --> 01:04:07,280
他们的 github.com 上

1807
01:04:07,280 --> 01:04:10,880
链接在这里，所以它可以真正

1808
01:04:10,880 --> 01:04:13,520
被看到和使用并用作

1809
01:04:13,520 --> 01:04:14,160
标准，

1810
01:04:14,160 --> 01:04:16,240
所以看起来很酷不

1811
01:04:16,240 --> 01:04:17,440
知道这个资源

1812
01:04:17,440 --> 01:04:20,559
用于标准化不同的学习

1813
01:04:20,559 --> 01:04:21,760
算法

1814
01:04:21,760 --> 01:04:25,039
所以 主动推理代理

1815
01:04:25,039 --> 01:04:28,240
如何做得好它在这个测试中做得很好，

1816
01:04:28,240 --> 01:04:29,839
否则他们不会

1817
01:04:29,839 --> 01:04:32,640
写论文和阅读这些图的方式

1818
01:04:32,640 --> 01:04:33,280


1819
01:04:33,280 --> 01:04:35,119
um a b 和 c 将具有相同的

1820
01:04:35,119 --> 01:04:36,880
x 和 y 轴，

1821
01:04:36,880 --> 01:04:40,480
所以我把地图

1822
01:04:40,480 --> 01:04:43,520
与 左上角的引擎，

1823
01:04:43,520 --> 01:04:46,480
所以它映射到

1824
01:04:46,480 --> 01:04:46,960
左下角的

1825
01:04:46,960 --> 01:04:50,319
面板a上，所以位置

1826
01:04:50,319 --> 01:04:51,599
与x轴有关，

1827
01:04:51,599 --> 01:04:53,760
这就是小火车向左

1828
01:04:53,760 --> 01:04:55,280
多远和向右多远

1829
01:04:55,280 --> 01:04:57,839
，然后 速度

1830
01:04:57,839 --> 01:04:58,720


1831
01:04:58,720 --> 01:05:01,359
是它是否静止为零，无论

1832
01:05:01,359 --> 01:05:03,200
它是向右

1833
01:05:03,200 --> 01:05:04,640
移动还是向左负移动，

1834
01:05:04,640 --> 01:05:05,280


1835
01:05:05,280 --> 01:05:08,240
所以

1836
01:05:08,240 --> 01:05:09,680


1837
01:05:09,680 --> 01:05:13,680
无论我猜是哪种方式都追求动量的奖励代理最终都会

1838
01:05:13,680 --> 01:05:16,400
获得大约 0.02 的最大速度

1839
01:05:16,400 --> 01:05:17,039
方式

1840
01:05:17,039 --> 01:05:20,079
和th  en 仅像 0.7 或

1841
01:05:20,079 --> 01:05:22,960
任何方向移动一样，epsilon

1842
01:05:22,960 --> 01:05:25,599
贪婪代理确实设法学习了一个

1843
01:05:25,599 --> 01:05:26,880
短程策略

1844
01:05:26,880 --> 01:05:29,760
，我们可以看到它

1845
01:05:29,760 --> 01:05:31,760
在一侧更进一步

1846
01:05:31,760 --> 01:05:34,400
，它确实需要一些罕见的偏移

1847
01:05:34,400 --> 01:05:34,960
进入

1848
01:05:34,960 --> 01:05:37,760
稍高的速度状态，但在

1849
01:05:37,760 --> 01:05:38,880
最后，它

1850
01:05:38,880 --> 01:05:41,440
并没有真正走得太远，就像它

1851
01:05:41,440 --> 01:05:42,000


1852
01:05:42,000 --> 01:05:44,079
在上坡时学会了如何上坡，

1853
01:05:44,079 --> 01:05:46,400
但这仅在有限程度上有所帮助，

1854
01:05:46,400 --> 01:05:48,799
而实施的主动推理模型

1855
01:05:48,799 --> 01:05:49,599


1856
01:05:49,599 --> 01:05:52,480
不仅在 um 状态空间内具有更广泛的采样

1857
01:05:52,480 --> 01:05:53,280


1858
01:05:53,280 --> 01:05:55,760
在 100 个 epoch 之后进行转换，

1859
01:05:55,760 --> 01:05:56,960


1860
01:05:56,960 --> 01:06:00,960
但它们的位置

1861
01:06:00,960 --> 01:06:03,760
扩展到 x 中

1862
01:06:03,760 --> 01:06:04,000


1863
01:06:04,000 --> 01:06:06,079
更高的范围以及 y 中更高的速度分布

1864
01:06:06,079 --> 01:06:07,599
范围，

1865
01:06:07,599 --> 01:06:10,640
因此

1866
01:06:10,640 --> 01:06:12,640


1867
01:06:12,640 --> 01:06:14,559
通过成为积极的推理学习者而

1868
01:06:14,559 --> 01:06:15,839
不是通过

1869
01:06:15,839 --> 01:06:19,119
epsilon 贪婪或只是 一种

1870
01:06:19,119 --> 01:06:21,280
基于无模型奖励

1871
01:06:21,280 --> 01:06:25,520


1872
01:06:25,520 --> 01:06:27,599
的类型 论文中提出的第二个优化示例是这个

1873
01:06:27,599 --> 01:06:29,440
hopper v2 再次不知道这个

1874
01:06:29,440 --> 01:06:30,799
资源

1875
01:06:30,799 --> 01:06:34,160
所以这个很有趣

1876
01:06:34,160 --> 01:06:36,799
描述为使

1877
01:06:36,799 --> 01:06:37,839
二维单腿机器人

1878
01:06:37,839 --> 01:06:40,400
尽可能快地向前跳跃并且

1879
01:06:40,400 --> 01:06:42,079
代码也在那里

1880
01:06:42,079 --> 01:06:43,520


1881
01:06:43,520 --> 01:06:45,599


1882
01:06:45,599 --> 01:06:47,359


1883
01:06:47,359 --> 01:06:50,960


1884
01:06:50,960 --> 01:06:52,799
首先这张图片有很多角度，上面

1885
01:06:52,799 --> 01:06:54,000


1886
01:06:54,000 --> 01:06:57,039
有一个棋盘，嗯，

1887
01:06:57,039 --> 01:07:00,079
它让我想起了一些

1888
01:07:00,079 --> 01:07:03,200
进化计算的模拟器，

1889
01:07:03,200 --> 01:07:05,039
比如 linux 和类似的东西，

1890
01:07:05,039 --> 01:07:06,799
你可以拥有这些块状的外星人，这些外星人

1891
01:07:06,799 --> 01:07:08,000
会复制并

1892
01:07:08,000 --> 01:07:10,160
占用大量的计算资源

1893
01:07:10,160 --> 01:07:11,200
只是

1894
01:07:11,200 --> 01:07:12,720
相互冲突，有时

1895
01:07:12,720 --> 01:07:14,079
只是轮廓，有时是

1896
01:07:14,079 --> 01:07:16,000
具有这种背景和平面图的 3d 块，

1897
01:07:16,000 --> 01:07:18,079


1898
01:07:18,079 --> 01:07:20,640
但在这里，我们正在发展的是

1899
01:07:20,640 --> 01:07:22,240
控制策略，而不是

1900
01:07:22,240 --> 01:07:24,960
代表基因型的染色体，或者

1901
01:07:24,960 --> 01:07:25,920
我们只是说

1902
01:07:25,920 --> 01:07:28,000
但实际上 相似之处

1903
01:07:28,000 --> 01:07:30,000
在于遗传算法和遗传

1904
01:07:30,000 --> 01:07:30,640
算法

1905
01:07:30,640 --> 01:07:33,119
随机搜索的这种思想，因为

1906
01:07:33,119 --> 01:07:34,559
有时这些控制策略的

1907
01:07:34,559 --> 01:07:35,520
优化方式

1908
01:07:35,520 --> 01:07:38,000
ed 实际上是通过涉及

1909
01:07:38,000 --> 01:07:39,839
诸如遗传搜索算法之类的步骤

1910
01:07:39,839 --> 01:07:41,440
来切换它们的大量

1911
01:07:41,440 --> 01:07:42,319
参数，

1912
01:07:42,319 --> 01:07:43,680
所以有一些有趣的

1913
01:07:43,680 --> 01:07:45,839
相似之处，我只是认为这是一个

1914
01:07:45,839 --> 01:07:47,039
很酷的例子

1915
01:07:47,039 --> 01:07:49,599
，它是运动行为控制的交叉点，

1916
01:07:49,599 --> 01:07:50,240


1917
01:07:50,240 --> 01:07:53,280
也是复杂的状态状态

1918
01:07:53,280 --> 01:07:53,920
空间

1919
01:07:53,920 --> 01:07:56,000
估计 甚至是一个

1920
01:07:56,000 --> 01:07:57,200
不活跃的

1921
01:07:57,200 --> 01:07:59,119
uh 甚至可能体现的方法的开始，

1922
01:07:59,119 --> 01:08:00,960
因为在某种程度

1923
01:08:00,960 --> 01:08:03,760
的运动复杂性中，它将

1924
01:08:03,760 --> 01:08:05,680
隐含在系统中

1925
01:08:05,680 --> 01:08:07,680
并分布在

1926
01:08:07,680 --> 01:08:09,920
系统中，就像其他系统一样，

1927
01:08:09,920 --> 01:08:11,039


1928
01:08:11,039 --> 01:08:13,280
如果它有 500 块肌肉和 这是一条人的

1929
01:08:13,280 --> 01:08:15,839
腿，它会有某种呃张

1930
01:08:15,839 --> 01:08:17,520
拉整体结构，

1931
01:08:17,520 --> 01:08:19,198
以某种方式保持平衡，促进

1932
01:08:19,198 --> 01:08:21,439
某些类型的行动，但不是其他类型的行动，所以

1933
01:08:21,439 --> 01:08:22,719
非常有趣的

1934
01:08:22,719 --> 01:08:25,839
选择我想从

1935
01:08:25,839 --> 01:08:28,238
任何作者或其他人那里听到

1936
01:08:28,238 --> 01:08:29,600
什么是 其他

1937
01:08:29,600 --> 01:08:32,158
很酷的基准测试其他

1938
01:08:32,158 --> 01:08:32,960
控制

1939
01:08:32,960 --> 01:08:35,198
系统问题有趣或

1940
01:08:35,198 --> 01:08:36,640


1941
01:08:36,640 --> 01:08:39,520
适用的社交版本或网络 工作

1942
01:08:39,520 --> 01:08:41,920
或基于通信的版本，

1943
01:08:41,920 --> 01:08:44,880
所以结果

1944
01:08:45,198 --> 01:08:47,679
如何，所以这里是如何查看这些

1945
01:08:47,679 --> 01:08:48,238


1946
01:08:48,238 --> 01:08:50,479
图表 x 轴是时代，所以这只是

1947
01:08:50,479 --> 01:08:52,238
通过时间的采样，即尝试了多少

1948
01:08:52,238 --> 01:08:52,719


1949
01:08:52,719 --> 01:08:55,439
代参数，

1950
01:08:55,439 --> 01:08:56,640
这里红线

1951
01:08:56,640 --> 01:08:59,920
表示相同 时间间隔，因此

1952
01:08:59,920 --> 01:09:03,359
c 和 d 与 epoch 1 到

1953
01:09:03,359 --> 01:09:04,000
100 相关

1954
01:09:04,000 --> 01:09:05,359
，这实际上

1955
01:09:05,359 --> 01:09:07,520


1956
01:09:07,520 --> 01:09:10,640


1957
01:09:10,640 --> 01:09:12,479


1958
01:09:12,479 --> 01:09:13,839


1959
01:09:13,839 --> 01:09:16,880
是针对 um 压缩的 所以我们可以

1960
01:09:16,880 --> 01:09:18,640
讨论相同的现象

1961
01:09:18,640 --> 01:09:20,960
，参考钟摆观察 a 和 c

1962
01:09:20,960 --> 01:09:24,238
以及料斗中的 b 和 d 并且在这

1963
01:09:24,238 --> 01:09:25,600
两种情况下

1964
01:09:25,600 --> 01:09:28,399
放大或缩小很

1965
01:09:28,399 --> 01:09:29,040
明显

1966
01:09:29,040 --> 01:09:32,080
的是动作和 y 轴是

1967
01:09:32,080 --> 01:09:33,120
奖励，就像

1968
01:09:33,120 --> 01:09:34,640
在料斗任务中你能走多远

1969
01:09:34,640 --> 01:09:36,238
，然后在倒立

1970
01:09:36,238 --> 01:09:37,439
摆任务

1971
01:09:37,439 --> 01:09:40,560
中，在给定策略

1972
01:09:40,560 --> 01:09:42,479
的特定参数组合的

1973
01:09:42,479 --> 01:09:46,158
情况下，你的时间大约保持不变，在这两种情况

1974
01:09:46,158 --> 01:09:49,359
下，奖励都会急剧增加

1975
01:09:49,359 --> 01:09:52,799
对于主动推理代理，并且

1976
01:09:52,799 --> 01:09:56,320


1977
01:09:56,320 --> 01:09:57,520


1978
01:09:57,520 --> 01:10:00,480
在前 100 个

1979
01:10:00,480 --> 01:10:01,679
甚至前

1980
01:10:01,679 --> 01:10:04,159
几个 epoch 内进行一些采样后立即开始爬升，这可能是因为

1981
01:10:04,159 --> 01:10:05,760


1982
01:10:05,760 --> 01:10:09,360
uh 小车的状态空间较低，因为小车所

1983
01:10:09,360 --> 01:10:09,760
能做的

1984
01:10:09,760 --> 01:10:11,040
就是向前和向后移动

1985
01:10:11,040 --> 01:10:12,800
像gas和break之类的政策

1986
01:10:12,800 --> 01:10:13,520


1987
01:10:13,520 --> 01:10:15,679
，这都是摆锤的物理原理

1988
01:10:15,679 --> 01:10:16,880


1989
01:10:16,880 --> 01:10:18,239


1990
01:10:18,239 --> 01:10:20,000


1991
01:10:20,000 --> 01:10:21,600


1992
01:10:21,600 --> 01:10:23,440


1993
01:10:23,440 --> 01:10:25,440
在玩的参数

1994
01:10:25,440 --> 01:10:28,400
我没有复制出确切的数字，但是

1995
01:10:28,400 --> 01:10:29,679
还有更多，所以

1996
01:10:29,679 --> 01:10:32,800
它需要更多的时间

1997
01:10:32,800 --> 01:10:33,679
，从零

1998
01:10:33,679 --> 01:10:36,880
到 um 可能是 40，

1999
01:10:36,880 --> 01:10:38,719
其中平均值就像没有真正

2000
01:10:38,719 --> 01:10:40,560
起飞，这

2001
01:10:40,560 --> 01:10:42,719
与 ddpg，您

2002
01:10:42,719 --> 01:10:44,400
可以阅读更多关于我只是不打算讨论

2003
01:10:44,400 --> 01:10:45,440
这个

2004
01:10:45,440 --> 01:10:48,080
算法是什么我只是相信

2005
01:10:48,080 --> 01:10:49,600
好吧作者使用了一些有意义

2006
01:10:49,600 --> 01:10:50,480


2007
01:10:50,480 --> 01:10:53,679
的东西让我们听听任何人 e 关于

2008
01:10:53,679 --> 01:10:56,000
可以测试哪些其他替代方案，

2009
01:10:56,000 --> 01:10:57,280
所以这些都是我

2010
01:10:57,280 --> 01:10:59,280


2011
01:10:59,280 --> 01:11:02,560
不喜欢文学但肯定会

2012
01:11:02,560 --> 01:11:03,280
欢迎

2013
01:11:03,280 --> 01:11:05,040
机器学习领域某人的评论的

2014
01:11:05,040 --> 01:11:06,560


2015
01:11:06,560 --> 01:11:08,400
事情，以及主动推理的令人印象深刻或有用的

2016
01:11:08,400 --> 01:11:10,400
演示 或者

2017
01:11:10,400 --> 01:11:11,280


2018
01:11:11,280 --> 01:11:15,280


2019
01:11:15,280 --> 01:11:18,320
在这种框架中进行控制理论模拟意味着什么

2020
01:11:18,320 --> 01:11:20,000
还使用

2021
01:11:20,000 --> 01:11:21,600
了哪些

2022
01:11:21,600 --> 01:11:24,000
这些倒立摆和

2023
01:11:24,000 --> 01:11:24,560
料斗

2024
01:11:24,560 --> 01:11:27,920
任务的当前最新技术我不知道，

2025
01:11:27,920 --> 01:11:32,159
但它会很棒 如果有人确实知道，

2026
01:11:32,159 --> 01:11:34,480
只是为了结束

2027
01:11:34,480 --> 01:11:36,400
与以前工作的关系，

2028
01:11:36,400 --> 01:11:39,199
好吧，这是来自他们的结束部分

2029
01:11:39,199 --> 01:11:40,960
，这可能是一个

2030
01:11:40,960 --> 01:11:44,480
纪律问题，但通常

2031
01:11:44,480 --> 01:11:46,800
它就像一个讨论部分，但如果它

2032
01:11:46,800 --> 01:11:48,320
是与以前工作的关系，我

2033
01:11:48,320 --> 01:11:49,520
会期望它

2034
01:11:49,520 --> 01:11:51,280
多一点语境化

2035
01:11:51,280 --> 01:11:55,280
，放在论文的前面

2036
01:11:55,280 --> 01:11:57,520


2037
01:11:57,520 --> 01:11:58,320


2038
01:11:58,320 --> 01:12:00,400


2039
01:12:00,400 --> 01:12:02,800


2040
01:12:02,800 --> 01:12:05,040
他们编写的主动推理的工作建立在这些

2041
01:12:05,040 --> 01:12:06,800
先前模型的基础上，通过将模型

2042
01:12:06,800 --> 01:12:09,199
不确定性纳入其主动分辨率

2043
01:12:09,199 --> 01:12:10,800
我们扩展了先前的点估计

2044
01:12:10,800 --> 01:12:12,560
模型以包括

2045
01:12:12,560 --> 01:12:14,480
参数的完整分布并更新预期的

2046
01:12:14,480 --> 01:12:15,760
自由能函数

2047
01:12:15,760 --> 01:12:17,679
，从而主动最小化这些分布中的不确定性

2048
01:12:17,679 --> 01:12:19,840


2049
01:12:19,840 --> 01:12:21,600
这使我们的实现

2050
01:12:21,600 --> 01:12:23,199
与认知和计算神经科学文献中主动推理的规范模型保持一致，

2051
01:12:23,199 --> 01:12:24,320


2052
01:12:24,320 --> 01:12:26,400


2053
01:12:26,400 --> 01:12:29,120
所以这几乎就像说是的，

2054
01:12:29,120 --> 01:12:29,679


2055
01:12:29,679 --> 01:12:32,320
而且它使我们能够评估

2056
01:12:32,320 --> 01:12:34,640


2057
01:12:34,640 --> 01:12:36,239
在缩放的主动推理

2058
01:12:36,239 --> 01:12:38,320
框架下进行主动探索的可行性，将模型应用于 与以前的模型相比，

2059
01:12:38,320 --> 01:12:40,320
控制任务更复杂

2060
01:12:40,320 --> 01:12:42,400
并获得更高的样本效率

2061
01:12:42,400 --> 01:12:43,920
，

2062
01:12:43,920 --> 01:12:45,840
所以这有点像说我们已经使

2063
01:12:45,840 --> 01:12:47,840
这个主动推理模型更

2064
01:12:47,840 --> 01:12:50,000
接近它

2065
01:12:50,000 --> 01:12:53,280
在定性神经行为领域中的推测

2066
01:12:53,280 --> 01:12:55,360
，我认为这是一个很好的理由

2067
01:12:55,360 --> 01:12:56,800
正确阅读不 w

2068
01:12:56,800 --> 01:12:58,960
因为它确实非常适合我们在变分生态学

2069
01:12:58,960 --> 01:13:01,280
讨论中对行为

2070
01:13:01,280 --> 01:13:04,320
和嗯

2071
01:13:04,320 --> 01:13:07,679
神经生物学的

2072
01:13:07,679 --> 01:13:10,560
讨论，所以这是在模拟

2073
01:13:10,560 --> 01:13:13,280
方面它是如何变成这种方式的，

2074
01:13:13,280 --> 01:13:15,280
所以这很酷，因为深度

2075
01:13:15,280 --> 01:13:16,560
主动推理现在可以

2076
01:13:16,560 --> 01:13:17,440


2077
01:13:17,440 --> 01:13:19,199
通过 本文中介绍的这些类型的模型

2078
01:13:19,199 --> 01:13:20,880


2079
01:13:20,880 --> 01:13:23,120
，以前就像哦，是的，我想

2080
01:13:23,120 --> 01:13:25,199
如果它是深度主动推理，那么

2081
01:13:25,199 --> 01:13:27,040
它将适应叙述

2082
01:13:27,040 --> 01:13:28,640
，现在这是一种框架

2083
01:13:28,640 --> 01:13:30,400
，哦，是的，我们可以

2084
01:13:30,400 --> 01:13:31,600
通过时间谈论叙述

2085
01:13:31,600 --> 01:13:35,520
这个框架可以我们

2086
01:13:35,520 --> 01:13:38,000
他们再次解决的第二个领域论文的另一个关键词

2087
01:13:38,000 --> 01:13:39,199


2088
01:13:39,199 --> 01:13:42,000
是基于模型的强化学习

2089
01:13:42,000 --> 01:13:42,960
在当前工作中我们

2090
01:13:42,960 --> 01:13:45,120
选择贝叶斯神经网络以

2091
01:13:45,120 --> 01:13:47,199
确保与主动推理框架所支持的变分原理的一致性，

2092
01:13:47,199 --> 01:13:48,719


2093
01:13:48,719 --> 01:13:49,679


2094
01:13:49,679 --> 01:13:51,679
但请注意集成可以是 做

2095
01:13:51,679 --> 01:13:53,360
了一些小的修改后明确地贝叶斯，

2096
01:13:53,360 --> 01:13:54,480


2097
01:13:54,480 --> 01:13:57,920
所以他们讨论了几个

2098
01:13:57,920 --> 01:13:59,679
与强化者的同源性 t learning

2099
01:13:59,679 --> 01:14:01,840
and specific amortized inference

2100
01:14:01,840 --> 01:14:03,040
实际上有一个引用

2101
01:14:03,040 --> 01:14:06,159
是我从

2102
01:14:06,159 --> 01:14:07,520
幻灯片上的一篇论文中摘录的，它

2103
01:14:07,520 --> 01:14:09,280
谈到了

2104
01:14:09,280 --> 01:14:10,480
你如何能感觉到这

2105
01:14:10,480 --> 01:14:13,040
就像一个免费的情况，只需

2106
01:14:13,040 --> 01:14:14,159
包装一个 函数

2107
01:14:14,159 --> 01:14:15,679
围绕这些参数的估计，

2108
01:14:15,679 --> 01:14:17,600
因为它就像是一个

2109
01:14:17,600 --> 01:14:19,120
神经网络，我正在实现一个神经

2110
01:14:19,120 --> 01:14:20,560
网络，所以我有额外

2111
01:14:20,560 --> 01:14:22,800
的自由度来学习非线性策略，

2112
01:14:22,800 --> 01:14:26,000
但是论文认为

2113
01:14:26,000 --> 01:14:28,800
实际上你受到了限制，因为

2114
01:14:28,800 --> 01:14:30,400
函数 正在估计

2115
01:14:30,400 --> 01:14:32,320
这个高斯结果的均值和方差

2116
01:14:32,320 --> 01:14:34,080


2117
01:14:34,080 --> 01:14:37,520
，因此它实际上并没有释放一定

2118
01:14:37,520 --> 01:14:41,920
程度的输出

2119
01:14:41,920 --> 01:14:44,960
表达能力，而是

2120
01:14:44,960 --> 01:14:48,080
一种

2121
01:14:48,080 --> 01:14:48,640


2122
01:14:48,640 --> 01:14:51,120
在当前计算硬件上实现的可定义和可扩展的方式

2123
01:14:51,120 --> 01:14:52,560
来实现这个

2124
01:14:52,560 --> 01:14:54,719
大规模的铅笔和纸问题 估计

2125
01:14:54,719 --> 01:14:56,159


2126
01:14:56,159 --> 01:14:58,400
超复杂

2127
01:14:58,400 --> 01:15:00,640
高维状态空间的高斯均值和方差，但这

2128
01:15:00,640 --> 01:15:02,239
仍然是它正在做的事情，

2129
01:15:02,239 --> 01:15:05,440
所以超级感兴趣 ting 的东西，

2130
01:15:05,440 --> 01:15:09,520
嗯，还有这里的注释，合奏

2131
01:15:09,520 --> 01:15:11,679
可以是明确的贝叶斯，所以有

2132
01:15:11,679 --> 01:15:14,320
各种各样的变体和口味

2133
01:15:14,320 --> 01:15:16,320
，所以

2134
01:15:16,320 --> 01:15:19,360
任何在这些领域的爱好者或

2135
01:15:19,360 --> 01:15:22,159
专家我都会欣赏

2136
01:15:22,159 --> 01:15:23,199
他们

2137
01:15:23,199 --> 01:15:26,080
对这意味着什么或为什么会这样的看法

2138
01:15:26,080 --> 01:15:26,800
重要或

2139
01:15:26,800 --> 01:15:30,640
有趣，然后信息增益

2140
01:15:30,640 --> 01:15:34,400
，这也是关键词之一，因此

2141
01:15:34,400 --> 01:15:36,960
确定可扩展和有效的

2142
01:15:36,960 --> 01:15:38,719
探索策略仍然是

2143
01:15:38,719 --> 01:15:40,320
强化

2144
01:15:40,320 --> 01:15:41,280
学习

2145
01:15:41,280 --> 01:15:43,440
无模型方法（例如贪婪或

2146
01:15:43,440 --> 01:15:45,440
博尔兹曼选择规则

2147
01:15:45,440 --> 01:15:48,800
分页质子肖恩博士）中的关键开放问题之一

2148
01:15:48,800 --> 01:15:51,520
在动作选择过程中利用噪声或

2149
01:15:51,520 --> 01:15:52,960
在奖励统计中利用不确定性，

2150
01:15:52,960 --> 01:15:55,840
更有效的方法

2151
01:15:55,840 --> 01:15:57,280
是构建一个世界模型，

2152
01:15:57,280 --> 01:15:58,800
允许代理评估

2153
01:15:58,800 --> 01:16:00,400
它访问和未访问过的状态空间的哪些部分，

2154
01:16:00,400 --> 01:16:01,440


2155
01:16:01,440 --> 01:16:02,960
这允许测量诸如

2156
01:16:02,960 --> 01:16:04,400
数量 用于探索的预测错误或预测

2157
01:16:04,400 --> 01:16:04,640
或

2158
01:16:04,640 --> 01:16:05,920
改进的数量

2159
01:16:05,920 --> 01:16:08,159
还可以，

2160
01:16:08,159 --> 01:16:10,640
如果学习模型影响不大 合法地或

2161
01:16:10,640 --> 01:16:12,320
明确地捕获概率

2162
01:16:12,320 --> 01:16:12,960


2163
01:16:12,960 --> 01:16:14,880
特征，这就是利基的统计

2164
01:16:14,880 --> 01:16:16,239
规律，然后

2165
01:16:16,239 --> 01:16:17,760
可以使用信息论测量

2166
01:16:17,760 --> 01:16:19,600
来指导探索

2167
01:16:19,600 --> 01:16:22,560
，所以这里有很多话要说，最后

2168
01:16:22,560 --> 01:16:24,960


2169
01:16:24,960 --> 01:16:27,360
引入信息增益真的很有趣，

2170
01:16:27,360 --> 01:16:28,239


2171
01:16:28,239 --> 01:16:30,880
这就是它所说的

2172
01:16:30,880 --> 01:16:31,840


2173
01:16:31,840 --> 01:16:34,560
主动推理的学习模型以及

2174
01:16:34,560 --> 01:16:36,719
探索与世界生成模型相关联的方式，

2175
01:16:36,719 --> 01:16:38,400
从而

2176
01:16:38,400 --> 01:16:40,560
促进行动不仅朝着

2177
01:16:40,560 --> 01:16:42,480
直接奖励的那种

2178
01:16:42,480 --> 01:16:44,719
无模型 rl

2179
01:16:44,719 --> 01:16:48,719
也不仅仅是

2180
01:16:48,719 --> 01:16:51,520
像我喜欢跑步的嗯深度模型奖励

2181
01:16:51,520 --> 01:16:53,679
马拉松，因为它是健康的，我不

2182
01:16:53,679 --> 01:16:55,840
知道你说它不健康，只是

2183
01:16:55,840 --> 01:16:57,920
它的心态可以帮助一个人

2184
01:16:57,920 --> 01:17:03,600
肯定到达那里，然后嗯，

2185
01:17:03,600 --> 01:17:05,040
这就是说我们实际上

2186
01:17:05,040 --> 01:17:06,640
可以更进一步

2187
01:17:06,640 --> 01:17:10,159
，我们可以用一个深度生成

2188
01:17:10,159 --> 01:17:11,040
模型

2189
01:17:11,040 --> 01:17:13,679
来说明什么 一个可能正在做的我们可以

2190
01:17:13,679 --> 01:17:15,040
最大限度地提高精度

2191
01:17:15,040 --> 01:17:16,800
，这可能是你在

2192
01:17:16,800 --> 01:17:19,199
你知道的超 ultr 中听到的 一个

2193
01:17:19,199 --> 01:17:22,800
um 致力于一个类似这样的领域，

2194
01:17:22,800 --> 01:17:26,080
这就是我的方式和身份，

2195
01:17:26,080 --> 01:17:28,480
从这个意义上说，它会超越

2196
01:17:28,480 --> 01:17:30,000
这个整体哦，好吧

2197
01:17:30,000 --> 01:17:31,920
，每天这么多英里对我来说是健康的，这是

2198
01:17:31,920 --> 01:17:33,840
一个很大的动力，它

2199
01:17:33,840 --> 01:17:36,480
可能是一个多 -规模的事情，嗯，只是一个

2200
01:17:36,480 --> 01:17:37,280
例子

2201
01:17:37,280 --> 01:17:39,280
，我绝对知道你知道，即使对

2202
01:17:39,280 --> 01:17:40,560
我来说，它只是在生活中发生了变化，

2203
01:17:40,560 --> 01:17:42,880
所以它只是展示了它

2204
01:17:42,880 --> 01:17:45,040
与你的利基你的背景你的

2205
01:17:45,040 --> 01:17:46,719
社会关系

2206
01:17:46,719 --> 01:17:49,840
这么多其他领域的关系，

2207
01:17:49,840 --> 01:17:51,679
只是为了接近一个想法 关于

2208
01:17:51,679 --> 01:17:54,400
这个信息，

2209
01:17:54,400 --> 01:17:57,360
嗯，信息增益起初让我感到惊讶，

2210
01:17:57,360 --> 01:17:58,560
因为我想尝试

2211
01:17:58,560 --> 01:18:01,040
将所有这些与信息论联系起来

2212
01:18:01,040 --> 01:18:04,000
，我意识到它是

2213
01:18:04,000 --> 01:18:05,760
关于减少目标参数的不确定性

2214
01:18:05,760 --> 01:18:06,480


2215
01:18:06,480 --> 01:18:07,920
信息是关于减少你

2216
01:18:07,920 --> 01:18:09,840
对事物的不确定性

2217
01:18:09,840 --> 01:18:11,679
，它只是为了减少我们的

2218
01:18:11,679 --> 01:18:13,600
不确定其他

2219
01:18:13,600 --> 01:18:16,400
事物或更具体的

2220
01:18:16,400 --> 01:18:18,480
事物是多尺度模型

2221
01:18:18,480 --> 01:18:20,400
，其中包含一些我们

2222
01:18:20,400 --> 01:18:22,080
可能非常熟悉的属性 h 喜欢

2223
01:18:22,080 --> 01:18:23,600
观察模型

2224
01:18:23,600 --> 01:18:26,880
一些与奖励模型同源的方面，

2225
01:18:26,880 --> 01:18:30,880
比如偏好

2226
01:18:30,880 --> 01:18:33,280
模型，让我们说，但是一些

2227
01:18:33,280 --> 01:18:34,239
方面

2228
01:18:34,239 --> 01:18:37,280
可能主要是新的，可能是

2229
01:18:37,280 --> 01:18:39,040
关于自由能的部分

2230
01:18:39,040 --> 01:18:42,800
，然后是我理解的那个领域

2231
01:18:42,800 --> 01:18:46,080
与另一种类型的

2232
01:18:46,080 --> 01:18:48,640
信息论和模型选择

2233
01:18:48,640 --> 01:18:51,280
以及变分框架有关，所以如果这

2234
01:18:51,280 --> 01:18:52,159
是一个

2235
01:18:52,159 --> 01:18:55,360
任何人都可以深入了解的领域，

2236
01:18:55,360 --> 01:18:57,120
我认为这很酷，也许我们可以

2237
01:18:57,120 --> 01:18:58,640
尝试解开我

2238
01:18:58,640 --> 01:19:01,280
不确定它是什么样子的，但嗯

2239
01:19:01,280 --> 01:19:02,400
肯定

2240
01:19:02,400 --> 01:19:04,960
我想知道并

2241
01:19:04,960 --> 01:19:06,560
注意 p 和 q 的一些事情，

2242
01:19:06,560 --> 01:19:08,159
感谢 alec 的一些

2243
01:19:08,159 --> 01:19:10,480
电子邮件讨论，以澄清论文的一些

2244
01:19:10,480 --> 01:19:11,520
方面，

2245
01:19:11,520 --> 01:19:15,199
因为嗯，这很有趣

2246
01:19:15,199 --> 01:19:16,159
，我认为有很多

2247
01:19:16,159 --> 01:19:18,719
含义以及我们可以应用哪些系统

2248
01:19:18,719 --> 01:19:21,520
这是近期

2249
01:19:21,520 --> 01:19:22,480
或中期

2250
01:19:22,480 --> 01:19:26,080
如此大量有趣的东西，我们将在

2251
01:19:26,080 --> 01:19:29,440
2020 年 11 月 10 日

2252
01:19:29,440 --> 01:19:29,840


2253
01:19:29,840 --> 01:19:34,239
和 17 日太平洋标准时间上午 7 点 30 分讨论这个问题

2254
01:19:34,239 --> 01:19:38,560
，我认为就是这样

2255
01:19:38,560 --> 01:19:43,600
让我们看看是的，一个结束的

2256
01:19:43,600 --> 01:19:45,280
想法我们所能拥有的只是一个

2257
01:19:45,280 --> 01:19:46,960
与行动交织在一起的空间的深度生成模型，

2258
01:19:46,960 --> 01:19:47,679


2259
01:19:47,679 --> 01:19:49,440
因此我们探索的参数

2260
01:19:49,440 --> 01:19:50,880
是在

2261
01:19:50,880 --> 01:19:53,679
成功和最佳信息之间进行权衡的参数，

2262
01:19:53,679 --> 01:19:54,960
有时我们担心

2263
01:19:54,960 --> 01:19:57,440
我们会转向成功 这可能

2264
01:19:57,440 --> 01:19:59,040
不是最佳信息，

2265
01:19:59,040 --> 01:20:00,400
其他时候我们

2266
01:20:00,400 --> 01:20:02,000
以一种可能不成功的方式获得大量信息，

2267
01:20:02,000 --> 01:20:03,040


2268
01:20:03,040 --> 01:20:04,880
但总体而言，我们很好地管理了这种权衡，

2269
01:20:04,880 --> 01:20:07,520
这就是我们如何做到这一点，

2270
01:20:07,520 --> 01:20:09,760
如此出色的工作，每个人都非常感谢

2271
01:20:09,760 --> 01:20:10,960
倾听，

2272
01:20:10,960 --> 01:20:14,880
继续努力 感谢您的参与，

2273
01:20:14,880 --> 01:20:17,280
我们确实为现场参与者提供了后续表格

2274
01:20:17,280 --> 01:20:18,800


2275
01:20:18,800 --> 01:20:21,199
，如果有人有反馈

2276
01:20:21,199 --> 01:20:21,840


2277
01:20:21,840 --> 01:20:25,120
、建议或问题，

2278
01:20:25,120 --> 01:20:28,480
您可以与我们保持联系，

2279
01:20:28,480 --> 01:20:31,679
并在该

2280
01:20:31,679 --> 01:20:34,159
参数重新参数化技巧和

2281
01:20:34,159 --> 01:20:36,080
该论文中的幻灯片上再上一张幻灯片，那就太好了

2282
01:20:36,080 --> 01:20:39,600
除此之外，感谢您的聆听

2283
01:20:39,600 --> 01:20:43,040
和忍受呃异常

2284
01:20:43,040 --> 01:20:46,080
相机错误，但是

2285
01:20:46,080 --> 01:20:48,520
是的，我期待着 2020 年底

2286
01:20:48,520 --> 01:20:49,679


2287
01:20:49,679 --> 01:20:51,440
到来 通过所有这些很酷的

2288
01:20:51,440 --> 01:20:53,280
讨论，

2289
01:20:53,280 --> 01:20:55,280
我们希望有一些新的参与者上

2290
01:20:55,280 --> 01:20:56,560
线，

2291
01:20:56,560 --> 01:20:59,040
或者带来一些

2292
01:20:59,040 --> 01:21:00,239
我们没有考虑过的新观点，

2293
01:21:00,239 --> 01:21:02,960
或者从初学者的

2294
01:21:02,960 --> 01:21:03,920
角度

2295
01:21:03,920 --> 01:21:06,639
从任意数量的领域作为

2296
01:21:06,639 --> 01:21:07,120
起点来讨论它

2297
01:21:07,120 --> 01:21:09,040
让我们知道这是

2298
01:21:09,040 --> 01:21:10,560


2299
01:21:10,560 --> 01:21:13,679
我们一直很高兴听到的那种东西，

2300
01:21:13,679 --> 01:21:17,679
所以祝您在 11 月和 2020 赛季结束时

2301
01:21:17,679 --> 01:21:21,120
一切顺利，我们期待

2302
01:21:21,120 --> 01:21:26,880
与您交谈，再见

