1
00:00:08,000 --> 00:00:08,880
muy bien,

2
00:00:08,880 --> 00:00:11,759
hola y bienvenidos a todos a la

3
00:00:11,759 --> 00:00:13,200
transmisión en vivo de inferencia activa,

4
00:00:13,200 --> 00:00:15,120
esta es la transmisión en vivo de inferencia activa

5
00:00:15,120 --> 00:00:17,279
número

6
00:00:17,279 --> 00:00:20,640
8.0, es el 4 de noviembre de 2020

7
00:00:20,640 --> 00:00:23,920
y soy daniel friedman, hoy haré una

8
00:00:23,920 --> 00:00:28,000
discusión de contextualización en solitario,

9
00:00:28,000 --> 00:00:30,960
bienvenidos a teamcom, todos somos un

10
00:00:30,960 --> 00:00:33,280
experimento en línea.  El

11
00:00:33,280 --> 00:00:35,200
aprendizaje y la práctica de la comunicación en equipo relacionados con la

12
00:00:35,200 --> 00:00:37,200
inferencia activa nos pueden encontrar

13
00:00:37,200 --> 00:00:38,960
en nuestra cuenta de Twitter en

14
00:00:38,960 --> 00:00:40,640
inferenceactive en

15
00:00:40,640 --> 00:00:43,360
activeinference gmail.com en nuestro

16
00:00:43,360 --> 00:00:45,120
equipo de base de clave pública

17
00:00:45,120 --> 00:00:48,160
o en nuestro canal de youtube Esta es una

18
00:00:48,160 --> 00:00:49,120


19
00:00:49,120 --> 00:00:51,360
transmisión en vivo grabada y archivada, así que

20
00:00:51,360 --> 00:00:53,120
envíenos sus comentarios  para que podamos

21
00:00:53,120 --> 00:00:54,719
mejorar nuestro trabajo,

22
00:00:54,719 --> 00:00:56,559
todos los antecedentes y perspectivas son

23
00:00:56,559 --> 00:00:58,559
bienvenidos aquí y en lo que respecta a

24
00:00:58,559 --> 00:01:00,719
la etiqueta de video para transmisiones en vivo silenciar si

25
00:01:00,719 --> 00:01:02,160
hay ruido en el fondo

26
00:01:02,160 --> 00:01:03,440
levantar la mano para que podamos escuchar a

27
00:01:03,440 --> 00:01:05,680
todos usar un comportamiento de habla respetuoso,

28
00:01:05,680 --> 00:01:06,880
etc.

29
00:01:06,880 --> 00:01:10,159
así que primero el anuncio es  que

30
00:01:10,159 --> 00:01:12,400
hemos elegido los papeles y las fechas

31
00:01:12,400 --> 00:01:13,200
y el tiempo

32
00:01:13,200 --> 00:01:15,200
para el resto de las corrientes de actina para

33
00:01:15,200 --> 00:01:17,119
2020 todas reunidas  gs

34
00:01:17,119 --> 00:01:19,759
para el resto de 2020 será

35
00:01:19,759 --> 00:01:22,159
de 7:30 a 9:00 pst

36
00:01:22,159 --> 00:01:24,240
y los periódicos leerán el número

37
00:01:24,240 --> 00:01:26,159
ocho está escalando la inferencia activa de eso se tratará

38
00:01:26,159 --> 00:01:27,439
este

39
00:01:27,439 --> 00:01:30,400
8.0 y

40
00:01:30,400 --> 00:01:33,119
eso será el 10 y 17 de noviembre el

41
00:01:33,119 --> 00:01:34,960
artículo 9 será  el

42
00:01:34,960 --> 00:01:36,560
modelo de conciencia proyectiva y la

43
00:01:36,560 --> 00:01:39,200
individualidad fenoménica un artículo de 2018 el

44
00:01:39,200 --> 00:01:41,759
artículo 10 va a ser un

45
00:01:41,759 --> 00:01:42,880
enfoque variacional de los guiones el

46
00:01:42,880 --> 00:01:45,200
artículo 11 es una inferencia activa sofisticada

47
00:01:45,200 --> 00:01:47,119
información efectiva lo siento

48
00:01:47,119 --> 00:01:48,880
simulando dinámicas efectivas anticipatorias

49
00:01:48,880 --> 00:01:51,840
de imaginar eventos futuros

50
00:01:51,840 --> 00:01:53,280
y puede ver las fechas en que todos estos

51
00:01:53,280 --> 00:01:55,119
eventos son tan

52
00:01:55,119 --> 00:01:57,360
reserve a veces si es posible para

53
00:01:57,360 --> 00:01:58,799
usted participar

54
00:01:58,799 --> 00:02:00,719
y si tiene una zona horaria o tipo de

55
00:02:00,719 --> 00:02:02,159
evento que desea hacer que no se

56
00:02:02,159 --> 00:02:04,240
refleja aquí, solo háganoslo saber

57
00:02:04,240 --> 00:02:06,479
y está nuestra dirección de Twitter,

58
00:02:06,479 --> 00:02:07,680


59
00:02:07,680 --> 00:02:10,959
así que esto es lo que sucederá en

60
00:02:10,959 --> 00:02:14,800
activo  flujo 8.0 este

61
00:02:14,800 --> 00:02:17,120
el objetivo de esta charla será

62
00:02:17,120 --> 00:02:20,000
establecer el contexto para 8.1 y 8.2

63
00:02:20,000 --> 00:02:21,040
que estarán en este

64
00:02:21,040 --> 00:02:23,360
mismo papel escalando la inferencia activa  este

65
00:02:23,360 --> 00:02:24,560
es un artículo de

66
00:02:24,560 --> 00:02:27,760
alex chance baltierri seth y hebilla

67
00:02:27,760 --> 00:02:29,200
de 2019

68
00:02:29,200 --> 00:02:35,040
con el archivo 1911.10601

69
00:02:35,040 --> 00:02:36,800
el video es una introducción al

70
00:02:36,800 --> 00:02:38,879
contexto de algunas de estas ideas no es

71
00:02:38,879 --> 00:02:39,599
una revisión

72
00:02:39,599 --> 00:02:42,000
o una última palabra definitivamente aprendí

73
00:02:42,000 --> 00:02:43,920
mucho solo leyendo el artículo e

74
00:02:43,920 --> 00:02:47,440
investigando  para esta presentación,

75
00:02:47,440 --> 00:02:50,080
la idea es que este video

76
00:02:50,080 --> 00:02:52,080
contextualice algunas de las ideas

77
00:02:52,080 --> 00:02:55,040
matemáticas, notación y vocabulario del

78
00:02:55,040 --> 00:02:56,640
artículo de Shantz,

79
00:02:56,640 --> 00:02:58,480
y el video debe ser accesible,

80
00:02:58,480 --> 00:03:00,480
aunque también es de esperar que esta sea

81
00:03:00,480 --> 00:03:03,680
una investigación genial y de vanguardia

82
00:03:03,680 --> 00:03:06,159
y el remate y no se preocupe.  si

83
00:03:06,159 --> 00:03:07,680
aún no tiene sentido o las

84
00:03:07,680 --> 00:03:08,879
implicaciones aún no están claras

85
00:03:08,879 --> 00:03:11,599
es que la inferencia activa es escalable y

86
00:03:11,599 --> 00:03:12,720
también es homóloga,

87
00:03:12,720 --> 00:03:14,640
por lo que es similar y potencialmente

88
00:03:14,640 --> 00:03:15,920
preferible a otros

89
00:03:15,920 --> 00:03:18,640
algoritmos comunes en un espacio similar

90
00:03:18,640 --> 00:03:21,440
como la teoría de control o el aprendizaje automático,

91
00:03:21,440 --> 00:03:25,120
por lo que en 8.0  la primera

92
00:03:25,120 --> 00:03:28,879
sección será información general sobre todas

93
00:03:28,879 --> 00:03:30,560
las palabras clave que usaron

94
00:03:30,560 --> 00:03:33,040
en este documento que proporcionaron y

95
00:03:33,040 --> 00:03:35,599
luego hablará sobre los objetivos de los abdominales

96
00:03:35,599 --> 00:03:37,680
y el mapa de ruta,

97
00:03:37,680 --> 00:03:40,959
entonces la segunda parte de 8.0 será el

98
00:03:40,959 --> 00:03:42,879


99
00:03:42,879 --> 00:03:44,879
tutorial de anotación y citas de ecuaciones clave y

100
00:03:44,879 --> 00:03:46,000
vamos a hacer como el 80

101
00:03:46,000 --> 00:03:48,959
20. así que la mayor parte de la notación la mayor parte del

102
00:03:48,959 --> 00:03:49,840
significado pero

103
00:03:49,840 --> 00:03:52,959
no todas las secciones no todos los símbolos

104
00:03:52,959 --> 00:03:55,920
y  luego hable sobre la figura 1 y la figura

105
00:03:55,920 --> 00:03:56,400
2

106
00:03:56,400 --> 00:03:58,400
y lo que representan y cómo eso

107
00:03:58,400 --> 00:04:00,799
respalda las conclusiones del documento

108
00:04:00,799 --> 00:04:04,640
y luego en 8.1 y 8.2 todos nos

109
00:04:04,640 --> 00:04:06,720
reuniremos para discutir el mismo documento,

110
00:04:06,720 --> 00:04:08,560
así que guarde y envíe sus preguntas o

111
00:04:08,560 --> 00:04:10,319
póngalas como un comentario y  entonces póngase en contacto

112
00:04:10,319 --> 00:04:12,560
si desea participar en este

113
00:04:12,560 --> 00:04:15,920
bien, así que comencemos con las palabras clave,

114
00:04:15,920 --> 00:04:17,680
estas fueron solo las palabras clave que

115
00:04:17,680 --> 00:04:19,839
proporcionó el documento, así que pensaría en ellas,

116
00:04:19,839 --> 00:04:21,199
estos son los temas en los que

117
00:04:21,199 --> 00:04:23,040
esta investigación será

118
00:04:23,040 --> 00:04:25,280
vanguardista.  con respecto a ese campo, es de

119
00:04:25,280 --> 00:04:28,080
esperar que sean

120
00:04:28,080 --> 00:04:28,800


121
00:04:28,800 --> 00:04:31,759
aprendizaje automático de inteligencia artificial y también mencionen el

122
00:04:31,759 --> 00:04:33,040
aprendizaje por

123
00:04:33,040 --> 00:04:36,000
refuerzo y el aprendizaje por refuerzo basado en modelos

124
00:04:36,000 --> 00:04:36,560
y luego los

125
00:04:36,560 --> 00:04:38,320
sistemas y el control y la información

126
00:04:38,320 --> 00:04:40,240
.  eory y luego una palabra clave que no estaba en

127
00:04:40,240 --> 00:04:40,479
el

128
00:04:40,479 --> 00:04:42,479
documento, pero que podemos agregar aquí es, por

129
00:04:42,479 --> 00:04:43,840
supuesto, la inferencia activa y el

130
00:04:43,840 --> 00:04:45,280
principio de energía libre,

131
00:04:45,280 --> 00:04:48,639
por lo que

132
00:04:48,639 --> 00:04:49,680
definitivamente podría tener un

133
00:04:49,680 --> 00:04:52,720
curso o un doctorado en

134
00:04:52,720 --> 00:04:54,240
cada una de estas palabras clave, por lo que cada uno de ellos es  voy a obtener

135
00:04:54,240 --> 00:04:56,160
una diapositiva, así que,

136
00:04:56,160 --> 00:04:58,960
por supuesto, profundice en los recursos

137
00:04:58,960 --> 00:04:59,600
mencionados

138
00:04:59,600 --> 00:05:02,560
o encuentre otros cursos que enseñen estas

139
00:05:02,560 --> 00:05:04,000
técnicas porque hay mucho en ellos,

140
00:05:04,000 --> 00:05:05,280
solo

141
00:05:05,280 --> 00:05:07,120
voy a revisarlos de una manera que se desarrolle

142
00:05:07,120 --> 00:05:08,560
hacia donde estamos  yendo

143
00:05:08,560 --> 00:05:10,479
con las matemáticas y con este

144
00:05:10,479 --> 00:05:12,240
trabajo de investigación y solo sé que también hay

145
00:05:12,240 --> 00:05:14,080
perspectivas de otras personas sobre estos temas,

146
00:05:14,080 --> 00:05:15,120


147
00:05:15,120 --> 00:05:18,560
así que la primera

148
00:05:18,560 --> 00:05:21,840
wikipedia de inteligencia artificial cuando revisamos por última

149
00:05:21,840 --> 00:05:24,160
vez decía que la inteligencia artificial

150
00:05:24,160 --> 00:05:25,120
o IA

151
00:05:25,120 --> 00:05:27,280
es inteligencia que es demostrada por

152
00:05:27,280 --> 00:05:29,199
máquinas a diferencia de la

153
00:05:29,199 --> 00:05:31,759
inteligencia natural que se muestra  por humanos

154
00:05:31,759 --> 00:05:33,280
y animales, por

155
00:05:33,280 --> 00:05:36,240
lo que incluso usando esta definición o tal vez

156
00:05:36,240 --> 00:05:37,680
una alternativa a la que llegaré en un

157
00:05:37,680 --> 00:05:38,479
segundo

158
00:05:38,479 --> 00:05:41,280
, podemos decir que el resultado de ai hoy en

159
00:05:41,280 --> 00:05:42,240
2020

160
00:05:42,240 --> 00:05:45,039
es  da como resultado políticas de mapas

161
00:05:45,039 --> 00:05:47,039
políticas individuales y colectivas

162
00:05:47,039 --> 00:05:49,120
motores de recomendación da como resultado

163
00:05:49,120 --> 00:05:51,280
técnicas de encriptación y seguridad

164
00:05:51,280 --> 00:05:53,440
se relaciona con algoritmos de clasificación

165
00:05:53,440 --> 00:05:55,039
y cosas que nos influyen

166
00:05:55,039 --> 00:05:58,800
a todos.

167
00:05:58,800 --> 00:06:01,600


168
00:06:01,600 --> 00:06:02,960
su

169
00:06:02,960 --> 00:06:06,000
mundo natural y todo es natural

170
00:06:06,000 --> 00:06:09,520
en el sentido de que existe en el mundo y, por lo tanto, al

171
00:06:09,520 --> 00:06:11,759
postular que hay un tipo artificial

172
00:06:11,759 --> 00:06:13,120
de cognición

173
00:06:13,120 --> 00:06:15,759
que de alguna manera es uh distinta en lugar de

174
00:06:15,759 --> 00:06:17,199
extendida o incrustada

175
00:06:17,199 --> 00:06:20,400
promulgada por humanos hace algunas cosas

176
00:06:20,400 --> 00:06:21,840
que no son muy útiles y hay

177
00:06:21,840 --> 00:06:24,000
Ha habido excelentes

178
00:06:24,000 --> 00:06:26,720
otras discusiones sobre este tema solo para

179
00:06:26,720 --> 00:06:28,319
moverlo en una dirección positiva

180
00:06:28,319 --> 00:06:30,000
, solo diría que a menudo otras

181
00:06:30,000 --> 00:06:31,919
frases pueden ser más útiles

182
00:06:31,919 --> 00:06:35,360
que llamarlo ai, así que aquí hay un ejemplo de

183
00:06:35,360 --> 00:06:36,720
lo que vamos a hablar mucho

184
00:06:36,720 --> 00:06:38,720
hoy: estadísticas de computadoras,

185
00:06:38,720 --> 00:06:41,600
así que  usar computadoras para hacer estadísticas, pero

186
00:06:41,600 --> 00:06:43,520
básicamente cosas que el lápiz y el papel

187
00:06:43,520 --> 00:06:45,759
podrían hacer lentamente, por lo que las cosas que tienen que ver con los

188
00:06:45,759 --> 00:06:47,440
cálculos de matrices son  e sobre

189
00:06:47,440 --> 00:06:51,680
estadísticas con computadoras en big data

190
00:06:51,680 --> 00:06:54,560
otra forma en que se puede significar ai hoy

191
00:06:54,560 --> 00:06:55,280
es como

192
00:06:55,280 --> 00:06:57,919
humano en el ciclo ai así que humano en el

193
00:06:57,919 --> 00:06:59,520
ciclo ai podría describir

194
00:06:59,520 --> 00:07:02,160
un mapa o un motor de recomendación para

195
00:07:02,160 --> 00:07:04,400
enfatizar que es una agencia humana en todo momento

196
00:07:04,400 --> 00:07:05,039


197
00:07:05,039 --> 00:07:07,120
en el uso  posibilidades y, con

198
00:07:07,120 --> 00:07:08,720
suerte, en lo que los diseñadores

199
00:07:08,720 --> 00:07:10,479
consideraron

200
00:07:10,479 --> 00:07:13,039
otra frase de IA que puede ser

201
00:07:13,039 --> 00:07:13,599
útil

202
00:07:13,599 --> 00:07:16,400
y también centrar el papel del ser humano en

203
00:07:16,400 --> 00:07:17,199
decidir

204
00:07:17,199 --> 00:07:19,039
cómo usarlo y cómo diseñarlo es

205
00:07:19,039 --> 00:07:20,560
el aumento de inteligencia que

206
00:07:20,560 --> 00:07:22,400
aclara que como nosotros que somos

207
00:07:22,400 --> 00:07:24,400
aumentados o  incluso una redacción más general

208
00:07:24,400 --> 00:07:26,080
que ai sería solo el

209
00:07:26,080 --> 00:07:27,280
nicho tecnológico humano

210
00:07:27,280 --> 00:07:28,639
que también incluiría

211
00:07:28,639 --> 00:07:30,720
aspectos físicos de nuestro nicho, por ejemplo, de lo que

212
00:07:30,720 --> 00:07:32,400
hablamos en 7.2,

213
00:07:32,400 --> 00:07:34,240
pero eso incluiría efectos que

214
00:07:34,240 --> 00:07:35,680
no son

215
00:07:35,680 --> 00:07:37,759
simplemente en el tipo de chips de silicio y

216
00:07:37,759 --> 00:07:39,280
sus interacciones que ai

217
00:07:39,280 --> 00:07:42,960
captura todo el aprendizaje automático correcto,

218
00:07:42,960 --> 00:07:46,000
por lo que el aprendizaje automático hay muchas

219
00:07:46,000 --> 00:07:47,840
cosas que decir al respecto, es un área grande,

220
00:07:47,840 --> 00:07:49,039
pero el principal

221
00:07:49,039 --> 00:07:51,440
aprendizaje automático es superior  Los ics que entran en

222
00:07:51,440 --> 00:07:52,800
juego en este documento

223
00:07:52,800 --> 00:07:55,199
son el aprendizaje por refuerzo y el

224
00:07:55,199 --> 00:07:57,199
aprendizaje por refuerzo basado en modelos,

225
00:07:57,199 --> 00:08:01,039
por lo que el aprendiz por refuerzo simple

226
00:08:01,039 --> 00:08:04,560
es un agente en un entorno y el

227
00:08:04,560 --> 00:08:06,000
agente

228
00:08:06,000 --> 00:08:08,800
realiza acciones que actúan en el

229
00:08:08,800 --> 00:08:09,520
entorno

230
00:08:09,520 --> 00:08:12,240
y luego el entorno devuelve

231
00:08:12,240 --> 00:08:14,000
estados y recompensas

232
00:08:14,000 --> 00:08:15,759
y, a veces,  devuelve solo

233
00:08:15,759 --> 00:08:17,199
estados directamente

234
00:08:17,199 --> 00:08:20,080
y luego la recompensa se entiende a

235
00:08:20,080 --> 00:08:21,039
través de una capa

236
00:08:21,039 --> 00:08:23,280
de percepción por parte del agente; otras veces,

237
00:08:23,280 --> 00:08:24,960
el entorno devuelve directamente la recompensa

238
00:08:24,960 --> 00:08:27,599


239
00:08:27,599 --> 00:08:29,520
donde el aprendizaje por refuerzo basado en modelos se

240
00:08:29,520 --> 00:08:31,840
basa en la introducción

241
00:08:31,840 --> 00:08:34,080
de este modelo que se describe en rojo

242
00:08:34,080 --> 00:08:35,039
aquí.

243
00:08:35,039 --> 00:08:38,320
y en estos tipos de aprendizaje por refuerzo basado en modelos, en

244
00:08:38,320 --> 00:08:39,440


245
00:08:39,440 --> 00:08:41,599
lugar de aprender estos, la conexión simple y

246
00:08:41,599 --> 00:08:42,880
cruda

247
00:08:42,880 --> 00:08:46,640
entre el comportamiento exitoso y la

248
00:08:46,640 --> 00:08:49,440
recompensa y el aprendizaje de que, como una correlación de comportamiento,

249
00:08:49,440 --> 00:08:50,640


250
00:08:50,640 --> 00:08:53,040
el alumno por refuerzo basado en modelos

251
00:08:53,040 --> 00:08:54,800
puede tener un modelo de

252
00:08:54,800 --> 00:08:57,279
oh, por ejemplo, correr es doloroso ahora,

253
00:08:57,279 --> 00:08:58,640
pero luego  me sentiré mejor más

254
00:08:58,640 --> 00:09:01,360
tarde y entonces le permite a uno

255
00:09:01,360 --> 00:09:03,600
perseguir metas t  que son transitoriamente,

256
00:09:03,600 --> 00:09:06,640
uh, desagradables para alcanzar

257
00:09:06,640 --> 00:09:08,800
objetivos a más largo plazo, así que piense en un

258
00:09:08,800 --> 00:09:10,560
pequeño laberinto, ya sabe, tratando de llegar

259
00:09:10,560 --> 00:09:13,680
no solo con avidez hacia la salida, sino

260
00:09:13,680 --> 00:09:15,040
tratando de dar un paso atrás

261
00:09:15,040 --> 00:09:18,080
para dar dos pasos adelante, por lo que las

262
00:09:18,080 --> 00:09:20,160
similitudes son que los agentes son  actuando

263
00:09:20,160 --> 00:09:22,000
sobre o dentro del medio ambiente y que

264
00:09:22,000 --> 00:09:24,000
sus acciones surgen de políticas que

265
00:09:24,000 --> 00:09:25,760
son modelos de acción,

266
00:09:25,760 --> 00:09:28,080
por lo que lo que es y no es probable y eso

267
00:09:28,080 --> 00:09:29,200
puede ser

268
00:09:29,200 --> 00:09:32,000
concurrente con lo que el organismo

269
00:09:32,000 --> 00:09:33,120
realmente puede o no puede hacer

270
00:09:33,120 --> 00:09:35,519
, pero al menos es  lo que

271
00:09:35,519 --> 00:09:37,440
termina siendo implementado por este

272
00:09:37,440 --> 00:09:40,160
organismo los agentes modifican sus

273
00:09:40,160 --> 00:09:41,440
políticas de acción en función de

274
00:09:41,440 --> 00:09:43,040
la recompensa que obtienen del entorno, ya sea

275
00:09:43,040 --> 00:09:45,760
de forma directa, simbólica

276
00:09:45,760 --> 00:09:48,800
o basada en modelos, aprenden

277
00:09:48,800 --> 00:09:51,680
o, para usar la frase bayesiana,

278
00:09:51,680 --> 00:09:52,800
actualizan su modelo

279
00:09:52,800 --> 00:09:54,080
para que  en cualquier caso,

280
00:09:54,080 --> 00:09:55,600
será computacional porque

281
00:09:55,600 --> 00:09:57,279
usaremos computadoras y

282
00:09:57,279 --> 00:10:00,080
matemáticas para describirlo, pero luego los bayesianos

283
00:10:00,080 --> 00:10:00,800
dirían que

284
00:10:00,800 --> 00:10:03,440
los antecedentes se actualizaron con evidencia para

285
00:10:03,440 --> 00:10:05,279
generar el p  osterior

286
00:10:05,279 --> 00:10:06,560
y hay varias formas en que este

287
00:10:06,560 --> 00:10:08,320
aprendizaje o actualización se puede hacer

288
00:10:08,320 --> 00:10:09,519
otra similitud es que el

289
00:10:09,519 --> 00:10:11,519
entorno envía recompensas o señales

290
00:10:11,519 --> 00:10:13,200
al agente

291
00:10:13,200 --> 00:10:16,399
y un área de debate o pregunta para

292
00:10:16,399 --> 00:10:16,880
pensar

293
00:10:16,880 --> 00:10:19,200
es la observación la recompensa o cómo

294
00:10:19,200 --> 00:10:20,800
es la recompensa

295
00:10:20,800 --> 00:10:22,320
es el  aprender en sí mismo la recompensa

296
00:10:22,320 --> 00:10:23,920
hay algoritmos de aprendizaje automático que también

297
00:10:23,920 --> 00:10:25,920
tienen ese tipo de enfoque

298
00:10:25,920 --> 00:10:28,320
y luego la observación simboliza

299
00:10:28,320 --> 00:10:29,120
o señala

300
00:10:29,120 --> 00:10:30,959
la recompensa o cómo pensamos que

301
00:10:30,959 --> 00:10:32,399
esas son las formas en que el

302
00:10:32,399 --> 00:10:34,160
aprendizaje por refuerzo y los

303
00:10:34,160 --> 00:10:35,040
algoritmos de comportamiento

304
00:10:35,040 --> 00:10:38,079
se pueden aplicar a ambos  la clasificación de datos abstractos se

305
00:10:38,079 --> 00:10:40,000


306
00:10:40,000 --> 00:10:41,440
acerca a la agrupación y cosas por el estilo

307
00:10:41,440 --> 00:10:43,839
, así como a los planes directos de acción,

308
00:10:43,839 --> 00:10:45,279
y resulta que la inferencia activa

309
00:10:45,279 --> 00:10:46,640
se relacionará con el

310
00:10:46,640 --> 00:10:48,240
aprendizaje por refuerzo de una manera interesante, por eso

311
00:10:48,240 --> 00:10:50,560
los autores lo convirtieron en una palabra

312
00:10:50,560 --> 00:10:53,760
clave ahora mismo en un contexto moderno, este

313
00:10:53,760 --> 00:10:55,200
refuerzo  el aprendizaje

314
00:10:55,200 --> 00:10:58,720
se va a implementar con una

315
00:10:58,720 --> 00:11:00,720
red neuronal, por ejemplo, que en este

316
00:11:00,720 --> 00:11:02,720
caso tenemos t  El entorno

317
00:11:02,720 --> 00:11:05,839
envía el estado a estado en el

318
00:11:05,839 --> 00:11:07,680
agente y eso pasará por

319
00:11:07,680 --> 00:11:10,000
algún tipo de red neuronal profunda dnn y dará como

320
00:11:10,000 --> 00:11:13,440
resultado una selección de políticas

321
00:11:13,440 --> 00:11:15,200
para que las redes neuronales estén dentro del agente,

322
00:11:15,200 --> 00:11:16,800
esa es una forma en que podemos implementarlo

323
00:11:16,800 --> 00:11:19,839
básicamente con el software que está disponible.

324
00:11:19,839 --> 00:11:21,440
y eso permite algunos tipos de

325
00:11:21,440 --> 00:11:24,320
escalabilidad en el sentido de que

326
00:11:24,320 --> 00:11:26,240
sabemos cómo va a haber una relación

327
00:11:26,240 --> 00:11:28,240
entre cuántos modelos tienen nuestros parámetros

328
00:11:28,240 --> 00:11:31,360
, cuántos, qué tan grande es nuestro modelo y

329
00:11:31,360 --> 00:11:33,279
qué tan efectivo será y

330
00:11:33,279 --> 00:11:35,120
luego también permite no  -La

331
00:11:35,120 --> 00:11:38,160
inferencia lineal no es solo un regresor lineal simple

332
00:11:38,160 --> 00:11:40,480
, digamos,

333
00:11:40,480 --> 00:11:42,800
y a veces se usa el theta pequeño y a veces

334
00:11:42,800 --> 00:11:44,480
el grande para los parámetros, pero

335
00:11:44,480 --> 00:11:46,000
llegaremos a eso más adelante

336
00:11:46,000 --> 00:11:48,320
y la red neuronal puede estar libre de modelos,

337
00:11:48,320 --> 00:11:49,519
por lo que puede

338
00:11:49,519 --> 00:11:52,240
dejarse suelto para  Encuentre los patrones

339
00:11:52,240 --> 00:11:53,440
en los datos

340
00:11:53,440 --> 00:11:56,880
o puede usar un modelo subyacente,

341
00:11:56,880 --> 00:11:58,720
por lo que si un cierto tipo de evento es una

342
00:11:58,720 --> 00:12:00,399
prioridad, es mucho más probable que

343
00:12:00,399 --> 00:12:02,480
ese tipo de observaciones se pueda usar

344
00:12:02,480 --> 00:12:06,480
para pesar más.  Ted way,

345
00:12:06,560 --> 00:12:09,760
un ejemplo de otro

346
00:12:09,760 --> 00:12:11,680
aprendizaje de refuerzo moderno es este q

347
00:12:11,680 --> 00:12:13,519
learning, que se usó recientemente para algunos juegos

348
00:12:13,519 --> 00:12:15,040
y algunos tipos de cosas por el estilo,

349
00:12:15,040 --> 00:12:16,000


350
00:12:16,000 --> 00:12:18,240
y la idea es solo otra forma de

351
00:12:18,240 --> 00:12:19,120


352
00:12:19,120 --> 00:12:22,560
hacerlo mediante el mapeo de la tabla de referencia,

353
00:12:22,560 --> 00:12:25,360
que es el mapeo de la acción del estado.  y

354
00:12:25,360 --> 00:12:26,399
recompensa por

355
00:12:26,399 --> 00:12:29,040
lo que estaría mapeando su

356
00:12:29,040 --> 00:12:30,639
estado actual y su comportamiento y que diga

357
00:12:30,639 --> 00:12:32,000
como oh estoy cansado pero voy a seguir

358
00:12:32,000 --> 00:12:33,680
corriendo porque es gratificante

359
00:12:33,680 --> 00:12:36,959
digamos pero de alguna manera matemática

360
00:12:36,959 --> 00:12:39,040
y luego el aprendizaje q profundo también

361
00:12:39,040 --> 00:12:40,240
representado aquí es

362
00:12:40,240 --> 00:12:42,320
cuando, de nuevo, no es solo una tabla,

363
00:12:42,320 --> 00:12:43,920
sino una red neuronal, así que el

364
00:12:43,920 --> 00:12:46,240
interior moderno simplemente reemplaza cualquier otro

365
00:12:46,240 --> 00:12:49,120
módulo estadístico con algo de aprendizaje

366
00:12:49,120 --> 00:12:50,639


367
00:12:50,639 --> 00:12:52,959
profundo y eso permite que surjan aparentemente algunas

368
00:12:52,959 --> 00:12:55,360
políticas más matizadas

369
00:12:55,360 --> 00:12:56,880
y luego solo una diapositiva solo para vomitar

370
00:12:56,880 --> 00:12:58,480
allí puede hacer una pausa si quiere

371
00:12:58,480 --> 00:13:00,000
mirarlo, pero es de un artículo llamado

372
00:13:00,000 --> 00:13:01,120
aprendizaje de refuerzo profundo

373
00:13:01,120 --> 00:13:02,880
y muestra la profundidad de cuántas

374
00:13:02,880 --> 00:13:04,959
áreas diferentes se relacionan.  d

375
00:13:04,959 --> 00:13:05,519
a,

376
00:13:05,519 --> 00:13:07,360
este es el tipo de estructura de

377
00:13:07,360 --> 00:13:09,360
los problemas y las áreas a las que se

378
00:13:09,360 --> 00:13:12,160
dirige este documento con estas

379
00:13:12,160 --> 00:13:13,519
palabras clave,

380
00:13:13,519 --> 00:13:16,560
bien, comencemos con este

381
00:13:16,560 --> 00:13:18,240
marco de aprendizaje por refuerzo basado en modelos

382
00:13:18,240 --> 00:13:21,040
y luego hablemos sobre sistemas y control

383
00:13:21,040 --> 00:13:24,480
para que en este marco podamos ver  el

384
00:13:24,480 --> 00:13:26,560
aprendizaje por refuerzo basado en modelos

385
00:13:26,560 --> 00:13:28,880
y el modelo verde, verde y azul

386
00:13:28,880 --> 00:13:30,639
el aprendizaje por refuerzo libre, por lo que el modelo

387
00:13:30,639 --> 00:13:31,200
libre de nuevo

388
00:13:31,200 --> 00:13:32,880
es el mapeo directo de la experiencia

389
00:13:32,880 --> 00:13:34,560
a la política

390
00:13:34,560 --> 00:13:36,959
y el

391
00:13:36,959 --> 00:13:38,720
aprendizaje por refuerzo basado en modelos cada vez más abstracto se basa

392
00:13:38,720 --> 00:13:40,240
en el aprendizaje supervisado de la

393
00:13:40,240 --> 00:13:41,360
experiencia

394
00:13:41,360 --> 00:13:43,600
en actualizaciones para el modelo de transición

395
00:13:43,600 --> 00:13:44,880
modelo generativo del mundo

396
00:13:44,880 --> 00:13:46,959
y luego usarlo para implementar algún

397
00:13:46,959 --> 00:13:48,480
tipo de proceso de planificación que

398
00:13:48,480 --> 00:13:52,079
resulte en una selección de políticas,

399
00:13:52,079 --> 00:13:54,880
por lo que la teoría de los sistemas de control se trata de

400
00:13:54,880 --> 00:13:57,279
planificar para la acción en medio de la incertidumbre

401
00:13:57,279 --> 00:13:58,880
porque hay que planificar para la acción

402
00:13:58,880 --> 00:14:00,639
y va a haber incertidumbre

403
00:14:00,639 --> 00:14:02,480
y hay varios tipos de  incertidumbre a

404
00:14:02,480 --> 00:14:04,480
veces son metáforas el uno del

405
00:14:04,480 --> 00:14:05,839
otro veces  los métodos son

406
00:14:05,839 --> 00:14:07,120
transferibles

407
00:14:07,120 --> 00:14:09,360
otras veces un sistema sufrirá de

408
00:14:09,360 --> 00:14:11,519
un tipo de estos desafíos

409
00:14:11,519 --> 00:14:13,839
frente a otro, pero incluye sistemas

410
00:14:13,839 --> 00:14:15,920
que son caóticos como un péndulo doble

411
00:14:15,920 --> 00:14:18,000
estocástico multiescala

412
00:14:18,000 --> 00:14:19,040
observado parcialmente ruidoso,

413
00:14:19,040 --> 00:14:22,160
etc., así que si no puede actuar, no puede

414
00:14:22,160 --> 00:14:23,920
controlarlo  solo puede observar y eso es

415
00:14:23,920 --> 00:14:25,279
realmente lo que diferencia la

416
00:14:25,279 --> 00:14:28,720
teoría del control de solo la estadística

417
00:14:28,720 --> 00:14:30,880
porque la estadística es descriptiva,

418
00:14:30,880 --> 00:14:34,000
pero los sistemas y los enfoques de control están

419
00:14:34,000 --> 00:14:35,519
más orientados a

420
00:14:35,519 --> 00:14:37,600
comprender la dinámica de los

421
00:14:37,600 --> 00:14:39,279
sistemas de una manera que se puede intervenir

422
00:14:39,279 --> 00:14:39,680


423
00:14:39,680 --> 00:14:41,519
para modelar este proceso de planificación y

424
00:14:41,519 --> 00:14:43,519
la política de manera explícita

425
00:14:43,519 --> 00:14:46,720
y  luego también, por supuesto, la advertencia de que

426
00:14:46,720 --> 00:14:48,800
no está presente en muchos de estos modelos es

427
00:14:48,800 --> 00:14:50,320
el axioma estratégico de

428
00:14:50,320 --> 00:14:53,680
que la no acción puede ser una forma de

429
00:14:53,680 --> 00:14:55,040
acción,

430
00:14:55,040 --> 00:14:56,959
por lo que el resumen aquí es que queremos

431
00:14:56,959 --> 00:14:58,720
tener un

432
00:14:58,720 --> 00:15:02,560
modelo matemático, una forma de hablar sobre cómo

433
00:15:02,560 --> 00:15:05,279
un sistema tiene  para supervisar o modelarse a

434
00:15:05,279 --> 00:15:07,040
sí mismos, sus capacidades de acción y su

435
00:15:07,040 --> 00:15:08,480
sistema y su mundo, bueno,

436
00:15:08,480 --> 00:15:11,040
ese es el buen regulador y también tienen

437
00:15:11,040 --> 00:15:11,680
este

438
00:15:11,680 --> 00:15:14,000
plan de política de acción, por lo que el aprendizaje supervisado

439
00:15:14,000 --> 00:15:14,880


440
00:15:14,880 --> 00:15:17,760
se trata de supervisar su entrada y

441
00:15:17,760 --> 00:15:19,279
actualizar adecuadamente su

442
00:15:19,279 --> 00:15:21,360
modelo generativo del mundo

443
00:15:21,360 --> 00:15:22,720
y luego cuál es su modelo

444
00:15:22,720 --> 00:15:26,000
generativo para el mundo, será sobre esta

445
00:15:26,000 --> 00:15:29,040
selección de política y aquí hay un

446
00:15:29,040 --> 00:15:32,160
diagrama de teoría de control más clásico con la

447
00:15:32,160 --> 00:15:33,040
forma en que  el

448
00:15:33,040 --> 00:15:35,199
elemento de medición del sistema, el controlador y el

449
00:15:35,199 --> 00:15:37,279
efector están relacionados,

450
00:15:37,279 --> 00:15:40,480
toda la teoría de la información correcta,

451
00:15:40,480 --> 00:15:42,560
otra palabra clave, por lo que probablemente haya

452
00:15:42,560 --> 00:15:43,600
otras

453
00:15:43,600 --> 00:15:47,199
500 horas de youtube para ver sobre la

454
00:15:47,199 --> 00:15:49,040
teoría de la información y mucho que podría decir sobre

455
00:15:49,040 --> 00:15:51,360
muchas áreas diferentes,

456
00:15:51,360 --> 00:15:54,480
um, una forma simple de expresarlo es esa

457
00:15:54,480 --> 00:15:55,360
información

458
00:15:55,360 --> 00:15:57,360
es la reducción de la incertidumbre, ya

459
00:15:57,360 --> 00:15:58,880
sea procesable o no,

460
00:15:58,880 --> 00:16:00,160
por lo que no tiene que estar conectado a la

461
00:16:00,160 --> 00:16:02,560
teoría de control, puede ser puramente

462
00:16:02,560 --> 00:16:04,560
descriptivo, como tomar la

463
00:16:04,560 --> 00:16:07,839
entropía de Shannon de alguna hebra de ADN, la

464
00:16:07,839 --> 00:16:09,839
información siempre es contextual, es

465
00:16:09,839 --> 00:16:11,680
relacional, depende del modelo,

466
00:16:11,680 --> 00:16:12,800
hay muchos  críticas de este

467
00:16:12,800 --> 00:16:16,079
tipo de interpretación ingenua de Shannon

468
00:16:16,079 --> 00:16:18,800
de la teoría de la información a veces un  d la

469
00:16:18,800 --> 00:16:20,480
medición o la comparación de la

470
00:16:20,480 --> 00:16:22,560
información es un desafío, como si

471
00:16:22,560 --> 00:16:24,240
calcula la entropía de la

472
00:16:24,240 --> 00:16:26,000
biodiversidad de insectos

473
00:16:26,000 --> 00:16:28,160
y plantas en la misma isla, no están

474
00:16:28,160 --> 00:16:29,680
necesariamente en la misma escala,

475
00:16:29,680 --> 00:16:31,279
etcétera, etcétera,

476
00:16:31,279 --> 00:16:34,320
y hay muchas áreas que

477
00:16:34,320 --> 00:16:36,959
La teoría de la información toca aspectos como la

478
00:16:36,959 --> 00:16:39,120
semiótica y la semántica.

479
00:16:39,120 --> 00:16:43,360


480
00:16:43,360 --> 00:16:45,519


481
00:16:45,519 --> 00:16:46,800


482
00:16:46,800 --> 00:16:49,839


483
00:16:49,839 --> 00:16:51,600


484
00:16:51,600 --> 00:16:52,959


485
00:16:52,959 --> 00:16:56,079


486
00:16:56,079 --> 00:16:58,160
otras áreas relacionadas son la

487
00:16:58,160 --> 00:16:59,519
cuantificación, el

488
00:16:59,519 --> 00:17:03,600
almacenamiento y la comunicación de información,

489
00:17:03,600 --> 00:17:05,280
la comparación de medidas mencionada

490
00:17:05,280 --> 00:17:07,199
anteriormente, cómo almacena

491
00:17:07,199 --> 00:17:08,959
y transmite información a través del tiempo,

492
00:17:08,959 --> 00:17:10,240
es como la memoria,

493
00:17:10,240 --> 00:17:12,400
cómo se comunica, se trata de

494
00:17:12,400 --> 00:17:14,079
transmitir información a través del tiempo

495
00:17:14,079 --> 00:17:14,720
y el espacio,

496
00:17:14,720 --> 00:17:19,199
protocolos para la comunicación

497
00:17:19,199 --> 00:17:23,679
y cuándo la información recopilada por un sistema.

498
00:17:23,679 --> 00:17:25,839
reduce su incertidumbre sobre el mundo

499
00:17:25,839 --> 00:17:28,559
s  estados o causas o

500
00:17:28,559 --> 00:17:30,400
relaciones puede facilitar la actualización de

501
00:17:30,400 --> 00:17:32,480
modelos de políticas eficaces y, por lo tanto, la

502
00:17:32,480 --> 00:17:32,960
acción

503
00:17:32,960 --> 00:17:35,679
en algunos casos, pero no en todos los casos y cuando

504
00:17:35,679 --> 00:17:37,039
la acción es

505
00:17:37,039 --> 00:17:40,320
eficaz puede ser gratificante o sostenible o de

506
00:17:40,320 --> 00:17:42,000
alta aptitud hay varias formas en que

507
00:17:42,000 --> 00:17:43,760
se puede pensar en ese tipo de  un

508
00:17:43,760 --> 00:17:45,600
éxito dependiendo del mecanismo del

509
00:17:45,600 --> 00:17:48,000
sistema escalado

510
00:17:48,000 --> 00:17:50,480
y luego los parámetros se actualizan mediante

511
00:17:50,480 --> 00:17:52,000
esta recompensa,

512
00:17:52,000 --> 00:17:54,000
así que si se trata de qué genotipos de la

513
00:17:54,000 --> 00:17:55,440
planta

514
00:17:55,440 --> 00:17:58,880
tienen éxito en un determinado nicho o

515
00:17:58,880 --> 00:18:00,720
si se trata de qué virus informático está

516
00:18:00,720 --> 00:18:02,000
mutando

517
00:18:02,000 --> 00:18:03,679
mejor, es este tipo de

518
00:18:03,679 --> 00:18:05,919
proceso de evolución de desarrollo de barra de aprendizaje  que, en

519
00:18:05,919 --> 00:18:07,120
última instancia, queremos avanzar

520
00:18:07,120 --> 00:18:09,600
hacia una integración de

521
00:18:09,600 --> 00:18:12,240
todos los derechos solo para hablar un poco más

522
00:18:12,240 --> 00:18:13,919
sobre la teoría de la información y también

523
00:18:13,919 --> 00:18:16,160
introdujimos esta notación condicional

524
00:18:16,160 --> 00:18:17,679
solo para aquellos que pueden o no haberla

525
00:18:17,679 --> 00:18:19,280
visto antes

526
00:18:19,280 --> 00:18:21,039
¿por qué estamos hablando

527
00:18:21,039 --> 00:18:22,640
aquí de la teoría de la información?  porque

528
00:18:22,640 --> 00:18:25,520
nuevamente cuando reducimos nuestra incertidumbre

529
00:18:25,520 --> 00:18:25,919
acerca de las

530
00:18:25,919 --> 00:18:27,919
relaciones causales y el

531
00:18:27,919 --> 00:18:29,520
registro estadístico  ularidades en el mundo

532
00:18:29,520 --> 00:18:32,080
podemos promulgar mejores políticas, así que controlemos

533
00:18:32,080 --> 00:18:33,120


534
00:18:33,120 --> 00:18:35,120
algunos conceptos básicos de la teoría de la información,

535
00:18:35,120 --> 00:18:36,720
pero también introduzcamos esta noción de un

536
00:18:36,720 --> 00:18:37,600
condicional,

537
00:18:37,600 --> 00:18:40,880
por lo que la notación una línea vertical b

538
00:18:40,880 --> 00:18:43,440
significa una b dada, por lo que la parte después de la

539
00:18:43,440 --> 00:18:44,559
línea vertical

540
00:18:44,559 --> 00:18:47,840
es la parte que usted  estamos condicionando en h de

541
00:18:47,840 --> 00:18:48,400
a

542
00:18:48,400 --> 00:18:50,080
es el contenido de información cuán

543
00:18:50,080 --> 00:18:51,919
sorprendente

544
00:18:51,919 --> 00:18:55,440
es la variable aleatoria a en unidades o en

545
00:18:55,440 --> 00:18:56,640
bits

546
00:18:56,640 --> 00:18:59,200
y solo para combinar estos dos

547
00:18:59,200 --> 00:19:00,480
puntos

548
00:19:00,480 --> 00:19:03,200
h de un b dado es el

549
00:19:03,200 --> 00:19:04,080
contenido de información de

550
00:19:04,080 --> 00:19:06,720
a condicionado en b lo siento, hay un  el error tipográfico

551
00:19:06,720 --> 00:19:08,880
en la

552
00:19:08,880 --> 00:19:12,320
información de un punto y coma

553
00:19:12,320 --> 00:19:14,400
b es la información mutua entre a

554
00:19:14,400 --> 00:19:15,600
y b, por lo que se

555
00:19:15,600 --> 00:19:17,919
muestra en este tipo de espacios superpuestos únicos

556
00:19:17,919 --> 00:19:20,080
en el diagrama de Venn a continuación

557
00:19:20,080 --> 00:19:23,200
y luego también hay una superposición triple

558
00:19:23,200 --> 00:19:25,280
y también puede tener superposición y

559
00:19:25,280 --> 00:19:26,320
condicionales

560
00:19:26,320 --> 00:19:28,160
así que el camino  que vamos a

561
00:19:28,160 --> 00:19:30,160
pensar en las matemáticas es algo así como

562
00:19:30,160 --> 00:19:30,720


563
00:19:30,720 --> 00:19:34,000
operaciones anidadas que contienen diferentes tipos de

564
00:19:34,000 --> 00:19:35,840
transformaciones y potencial

565
00:19:35,840 --> 00:19:37,679
y hay muchas áreas interesantes de

566
00:19:37,679 --> 00:19:39,120
información t  la teoría de

567
00:19:39,120 --> 00:19:42,480
james gleek es un gran escritor y

568
00:19:42,480 --> 00:19:45,679
este libro de stone in the middle es una

569
00:19:45,679 --> 00:19:49,120
buena introducción y luego este libro

570
00:19:49,120 --> 00:19:50,320
compra un neil en toda

571
00:19:50,320 --> 00:19:52,640
la dinámica de la información algorítmica también es

572
00:19:52,640 --> 00:19:53,440
una

573
00:19:53,440 --> 00:19:56,960
aplicación y una teoría geniales, así que volvamos

574
00:19:56,960 --> 00:19:58,720
a una pequeña variante de una diapositiva

575
00:19:58,720 --> 00:20:00,640
que  He visto algo antes de

576
00:20:00,640 --> 00:20:05,200
cuál es esta

577
00:20:05,200 --> 00:20:08,080
división de dicotomía inactiva versus bayesiana que, en última instancia,

578
00:20:08,080 --> 00:20:09,840
activa va a tratar de integrar,

579
00:20:09,840 --> 00:20:11,919
por lo que en la cosmovisión inactiva tenemos al

580
00:20:11,919 --> 00:20:14,159
agente en el mundo y están actuando

581
00:20:14,159 --> 00:20:17,440
en este nexo de salida de acción y

582
00:20:17,440 --> 00:20:18,799
percepción

583
00:20:18,799 --> 00:20:21,200
y el  El resultado de esta interacción es

584
00:20:21,200 --> 00:20:23,679
la

585
00:20:23,679 --> 00:20:26,480
secuencia de acción o política incorporada y ecológica de un

586
00:20:26,480 --> 00:20:27,280
agente incrustado que hace que la

587
00:20:27,280 --> 00:20:31,039
barra sea su comportamiento y

588
00:20:31,039 --> 00:20:33,360
solo para ir un nivel más ahora desde la

589
00:20:33,360 --> 00:20:35,039
perspectiva de la teoría del control

590
00:20:35,039 --> 00:20:38,240
hacia el agente, podemos ver que el agente

591
00:20:38,240 --> 00:20:40,720
tiene los estados sensoriales en  en

592
00:20:40,720 --> 00:20:43,280
el lado de entrada, entonces tienen su

593
00:20:43,280 --> 00:20:44,480
modelo causal del mundo

594
00:20:44,480 --> 00:20:46,960
y luego su modelo de política, en cierto

595
00:20:46,960 --> 00:20:48,480
sentido, estos podrían ser como

596
00:20:48,480 --> 00:20:50,480
una unidad integrada o no, obtendremos

597
00:20:50,480 --> 00:20:52,640
allí más tarde

598
00:20:52,640 --> 00:20:56,080
y luego podemos alinear eso con la

599
00:20:56,080 --> 00:20:56,640


600
00:20:56,640 --> 00:20:59,520
vista representacional estructural bayesiana, por lo que

601
00:20:59,520 --> 00:21:00,400
en esta

602
00:21:00,400 --> 00:21:02,960
vista tiene los datos, la observación,

603
00:21:02,960 --> 00:21:04,720
que es una especie de observaciones de nivel base

604
00:21:04,720 --> 00:21:07,120
o parámetros en el modelo

605
00:21:07,120 --> 00:21:09,679
y luego, a través de un modelo de reconocimiento,

606
00:21:09,679 --> 00:21:11,919
se actualizan los hiperparámetros que

607
00:21:11,919 --> 00:21:12,720
da como resultado

608
00:21:12,720 --> 00:21:15,600
un modelo generativo de los datos y este

609
00:21:15,600 --> 00:21:16,240
tipo

610
00:21:16,240 --> 00:21:20,080
de esquema de maximización de expectativas

611
00:21:20,080 --> 00:21:21,919
da como resultado la convergencia estadística

612
00:21:21,919 --> 00:21:23,360
de un modelo de niveles múltiples

613
00:21:23,360 --> 00:21:25,600
que representa, por lo tanto, las

614
00:21:25,600 --> 00:21:26,799


615
00:21:26,799 --> 00:21:29,039
estructuras representacionales del mundo, por lo tanto, la

616
00:21:29,039 --> 00:21:30,320
parte estructural

617
00:21:30,320 --> 00:21:33,679
tal vez y luego solo para alinearlo podemos

618
00:21:33,679 --> 00:21:37,520
piense en ese modelo que es un

619
00:21:37,520 --> 00:21:40,720
agente de control bayesiano digamos

620
00:21:40,720 --> 00:21:42,720
que va a tener estados sensoriales cuál

621
00:21:42,720 --> 00:21:43,919
es mi

622
00:21:43,919 --> 00:21:46,559
sensor de robot detectando cuál es el

623
00:21:46,559 --> 00:21:49,600
modelo causal para lo que eso significa para la

624
00:21:49,600 --> 00:21:51,679
pose del robot y luego la

625
00:21:51,679 --> 00:21:53,200
selección de políticas cómo vamos a

626
00:21:53,200 --> 00:21:58,000
corregir entonces  estos, eh, ambos pueden ser

627
00:21:58,000 --> 00:22:00,320
estos dos lados de la línea discontinua

628
00:22:00,320 --> 00:22:01,919
pueden ser

629
00:22:01,919 --> 00:22:05,200
internamente consistentes y queremos

630
00:22:05,200 --> 00:22:06,960
retu  En cuanto a esta pregunta, que trata sobre

631
00:22:06,960 --> 00:22:07,600
cómo

632
00:22:07,600 --> 00:22:09,120
el principio de energía libre y la

633
00:22:09,120 --> 00:22:10,320
inferencia activa van a decir algo

634
00:22:10,320 --> 00:22:10,880
sobre

635
00:22:10,880 --> 00:22:12,640
la relación entre el mundo y

636
00:22:12,640 --> 00:22:14,799
los

637
00:22:14,799 --> 00:22:16,960
agentes, tenemos acción y percepción y

638
00:22:16,960 --> 00:22:18,640
queremos que sean simétricos en este tipo

639
00:22:18,640 --> 00:22:19,760
de

640
00:22:19,760 --> 00:22:22,480
concepto de nicho.  He hablado de que

641
00:22:22,480 --> 00:22:23,120
queremos que

642
00:22:23,120 --> 00:22:25,520
el principio de la energía libre sea un

643
00:22:25,520 --> 00:22:26,640


644
00:22:26,640 --> 00:22:29,360
conjunto axiomático que queremos construir en la parte superior con una

645
00:22:29,360 --> 00:22:31,280


646
00:22:31,280 --> 00:22:35,039
perspectiva de inferencia activa de múltiples escalas. Aquí es hacia donde

647
00:22:35,039 --> 00:22:37,919
queremos avanzar. ¿Cómo ha

648
00:22:37,919 --> 00:22:38,799


649
00:22:38,799 --> 00:22:41,360
entrado la inferencia activa en esta brecha y  creado

650
00:22:41,360 --> 00:22:43,039
para este objetivo, por

651
00:22:43,039 --> 00:22:46,480
lo que la inferencia activa 1.0 y

652
00:22:46,480 --> 00:22:49,120
abierta a las personas que se basan en la barra que

653
00:22:49,120 --> 00:22:50,480
me corrige en cualquiera de estas partes aquí,

654
00:22:50,480 --> 00:22:51,440
esto es solo

655
00:22:51,440 --> 00:22:55,360
un nivel de época muy aproximado, la inferencia activa 1.0

656
00:22:55,360 --> 00:22:57,760
es una implementación de un

657
00:22:57,760 --> 00:23:00,240
algoritmo de tipo de aprendizaje automático que se basa en

658
00:23:00,240 --> 00:23:04,159
el principio de energía libre como  así como el

659
00:23:04,159 --> 00:23:06,960
enfoque inactivista y relaciona la

660
00:23:06,960 --> 00:23:08,720
sintonía de los estados y políticas sensoriales locales

661
00:23:08,720 --> 00:23:09,440
,

662
00:23:09,440 --> 00:23:11,440
por lo que de esa manera es como el

663
00:23:11,440 --> 00:23:12,480
modelo de refuerzo libre.

664
00:23:12,480 --> 00:23:15,360
nt Learner y se centró en

665
00:23:15,360 --> 00:23:16,960
casos muy discretos,

666
00:23:16,960 --> 00:23:20,080
como en una cuadrícula, por ejemplo,

667
00:23:20,080 --> 00:23:23,120
y usó

668
00:23:23,120 --> 00:23:25,200
algoritmos de maximización de expectativas bastante simples y

669
00:23:25,200 --> 00:23:27,440
tenía un

670
00:23:27,440 --> 00:23:28,240


671
00:23:28,240 --> 00:23:31,440
alcance o profundidad espacial o temporal de

672
00:23:31,440 --> 00:23:34,799
rango

673
00:23:34,799 --> 00:23:38,559
relativamente corto.  no estoy seguro de lo que sucedió aquí,

674
00:23:38,960 --> 00:23:41,200
um, lo

675
00:23:42,799 --> 00:23:45,840
siento,

676
00:23:46,960 --> 00:23:50,159
así que voy a

677
00:23:50,159 --> 00:23:53,520
volver a agregar mi cámara, lo

678
00:24:02,840 --> 00:24:05,840
siento, está

679
00:24:07,360 --> 00:24:11,360
bien, c'est la vie de

680
00:24:11,360 --> 00:24:15,039
todos modos, active 2.0 agregó

681
00:24:15,039 --> 00:24:17,760
profundidad temporal e interacciones de nicho

682
00:24:17,760 --> 00:24:20,240
en las ecuaciones con una

683
00:24:20,240 --> 00:24:23,440
fase de planificación a más largo plazo y también agregó  en este

684
00:24:23,440 --> 00:24:25,679
aspecto de integración del agente e

685
00:24:25,679 --> 00:24:28,000
introdujo la idea de valencia y

686
00:24:28,000 --> 00:24:29,200
aprendizaje en

687
00:24:29,200 --> 00:24:32,159
la formulación y aquí es

688
00:24:32,159 --> 00:24:34,159
donde van la inferencia activa 3.0

689
00:24:34,159 --> 00:24:37,600
y más allá, por lo que una dirección en la que han

690
00:24:37,600 --> 00:24:38,240
estado yendo

691
00:24:38,240 --> 00:24:40,880
es hacia el aprendizaje y el afecto y los

692
00:24:40,880 --> 00:24:43,520
aspectos sofisticados o contrafácticos

693
00:24:43,520 --> 00:24:43,919
de la

694
00:24:43,919 --> 00:24:46,960
acción.  aquí hay una cita

695
00:24:46,960 --> 00:24:49,039
y luego otra dirección hacia la que se

696
00:24:49,039 --> 00:24:50,080
dirigía se

697
00:24:50,080 --> 00:24:52,080
refleja en este documento de inferencia activa de escala

698
00:24:52,080 --> 00:24:53,200


699
00:24:53,200 --> 00:24:55,200
que presentará la idea de

700
00:24:55,200 --> 00:24:56,400
los datos de alta dimensión

701
00:24:56,400 --> 00:24:59,200
las variables continuas exploran el

702
00:24:59,200 --> 00:25:00,000
comportamiento de explotación y

703
00:25:00,000 --> 00:25:02,559
también la homología con el aprendizaje por refuerzo

704
00:25:02,559 --> 00:25:04,240
y el trabajo a escala,

705
00:25:04,240 --> 00:25:07,919
así que para mí fue como el viaje del héroe al

706
00:25:07,919 --> 00:25:10,000
leer este documento porque es solo

707
00:25:10,000 --> 00:25:11,919
un marco para una historia completa,

708
00:25:11,919 --> 00:25:13,919
así que este es el viaje de inferencia activa de escala

709
00:25:13,919 --> 00:25:16,000


710
00:25:16,000 --> 00:25:18,799
así que comienza con un llamado a la

711
00:25:18,799 --> 00:25:19,760
aventura,

712
00:25:19,760 --> 00:25:22,799
que es la pregunta: ¿cómo podemos modelar

713
00:25:22,799 --> 00:25:25,200
tareas de control complejas con inferencia activa?

714
00:25:25,200 --> 00:25:26,640


715
00:25:26,640 --> 00:25:27,840
Aquí está el comienzo de la

716
00:25:27,840 --> 00:25:30,240
transformación. El desafío está en la

717
00:25:30,240 --> 00:25:31,679
tentación.

718
00:25:31,679 --> 00:25:34,240
¿Debería uno irse a dormir o

719
00:25:34,240 --> 00:25:35,120
debería leer

720
00:25:35,120 --> 00:25:38,320
la bibliografía de Fristen?

721
00:25:38,320 --> 00:25:40,960
Llega el ayudante.  en la imagen aquí está

722
00:25:40,960 --> 00:25:42,799
alec

723
00:25:42,799 --> 00:25:45,120
tenemos un momento transformador cuando

724
00:25:45,120 --> 00:25:46,720
leemos y cuando entendemos

725
00:25:46,720 --> 00:25:49,919
el papel escalando la inferencia activa luego

726
00:25:49,919 --> 00:25:50,880
tenemos nuestro

727
00:25:50,880 --> 00:25:52,880
movimiento de la oscuridad a la luz del

728
00:25:52,880 --> 00:25:54,640
aprendizaje reforzado a la inferencia activa

729
00:25:54,640 --> 00:25:55,440


730
00:25:55,440 --> 00:25:59,200
de la falta de control en el camino

731
00:25:59,200 --> 00:26:02,000
recibimos el regalo de la reunión  nuevos amigos

732
00:26:02,000 --> 00:26:04,159
discutiendo ideas geniales que

733
00:26:04,159 --> 00:26:06,880
tienen impacto en los sistemas y haciendo

734
00:26:06,880 --> 00:26:07,840
abeto  st y memes,

735
00:26:07,840 --> 00:26:11,440
por supuesto, así que vayamos al artículo,

736
00:26:11,440 --> 00:26:14,240
así que escalar la inferencia activa es el artículo,

737
00:26:14,240 --> 00:26:15,360
el objetivo del artículo

738
00:26:15,360 --> 00:26:18,400
se presenta a medida que presentamos un modelo

739
00:26:18,400 --> 00:26:20,400
de inferencia activa que es aplicable

740
00:26:20,400 --> 00:26:22,320
en tareas de control de alta dimensión

741
00:26:22,320 --> 00:26:24,799
con estados continuos y acciones

742
00:26:24,799 --> 00:26:27,200
que construye nuestro modelo  Tras intentos previos

743
00:26:27,200 --> 00:26:28,880
de escalar la inferencia activa mediante la inclusión de

744
00:26:28,880 --> 00:26:30,640
un algoritmo de planificación eficiente, así

745
00:26:30,640 --> 00:26:32,000
como la cuantificación y

746
00:26:32,000 --> 00:26:34,159
resolución activa de la incertidumbre del modelo,

747
00:26:34,159 --> 00:26:35,440
nuestro modelo hace dos contribuciones principales:

748
00:26:35,440 --> 00:26:37,600
primero, mostramos

749
00:26:37,600 --> 00:26:39,360
que la construcción de inferencia activa completa

750
00:26:39,360 --> 00:26:41,279
se puede escalar a los tipos de tareas

751
00:26:41,279 --> 00:26:43,440
consideradas en el  En la literatura de rl,

752
00:26:43,440 --> 00:26:45,279
esto implicó ampliar los modelos anteriores

753
00:26:45,279 --> 00:26:46,960
de inferencia activa profunda para incluir la

754
00:26:46,960 --> 00:26:49,600
incertidumbre del modelo y la ganancia de información esperada. En

755
00:26:49,600 --> 00:26:51,600
segundo lugar, destacamos la superposición entre

756
00:26:51,600 --> 00:26:53,120
el

757
00:26:53,120 --> 00:26:53,840
enfoque

758
00:26:53,840 --> 00:26:56,880
de vanguardia de la inferencia activa y el aprendizaje por refuerzo basado en modelos, por lo que

759
00:26:56,880 --> 00:26:58,960
la frase de inferencia no activa aquí

760
00:26:58,960 --> 00:27:01,840
es  ¿Cómo podemos aplicar la inferencia activa a

761
00:27:01,840 --> 00:27:03,760
tareas de control desafiantes

762
00:27:03,760 --> 00:27:05,520
y conectarlo  formalmente al

763
00:27:05,520 --> 00:27:08,480
aprendizaje por refuerzo, por lo que lo abstracto estaba

764
00:27:08,480 --> 00:27:11,760
en el aprendizaje por refuerzo. Los agentes a menudo

765
00:27:11,760 --> 00:27:13,600
operan en entornos inciertos y parcialmente observados. El

766
00:27:13,600 --> 00:27:15,120


767
00:27:15,120 --> 00:27:17,360
aprendizaje por refuerzo basado en modelos

768
00:27:17,360 --> 00:27:19,520
sugiere que esto se logra mejor

769
00:27:19,520 --> 00:27:21,440
aprendiendo y explotando un

770
00:27:21,440 --> 00:27:24,720
modelo probabilístico del mundo.

771
00:27:24,720 --> 00:27:26,240


772
00:27:26,240 --> 00:27:28,080


773
00:27:28,080 --> 00:27:29,760
neurociencia computacional

774
00:27:29,760 --> 00:27:31,919
que ofrece una explicación unificadora de cómo

775
00:27:31,919 --> 00:27:34,480
los agentes biológicos logran esto

776
00:27:34,480 --> 00:27:37,039
en este marco, el aprendizaje por inferencia y la

777
00:27:37,039 --> 00:27:37,600
acción

778
00:27:37,600 --> 00:27:39,360
emergen de un solo imperativo para

779
00:27:39,360 --> 00:27:41,039
maximizar la evidencia bayesiana para un

780
00:27:41,039 --> 00:27:43,919
nicho compartido del mundo;

781
00:27:43,919 --> 00:27:46,480
sin embargo, las implementaciones de este

782
00:27:46,480 --> 00:27:48,080
proceso hasta ahora se han restringido a dimensiones bajas.

783
00:27:48,080 --> 00:27:50,559
y situaciones idealizadas

784
00:27:50,559 --> 00:27:53,600
aquí presentamos una implementación

785
00:27:53,600 --> 00:27:55,679
de trabajo de inferencia activa que se aplica a

786
00:27:55,679 --> 00:27:57,279
tareas de alta dimensión con resultados de prueba de

787
00:27:57,279 --> 00:27:58,320
principio que

788
00:27:58,320 --> 00:28:00,960
demuestran una exploración eficiente y

789
00:28:00,960 --> 00:28:02,080
una disminución de orden de magnitud

790
00:28:02,080 --> 00:28:04,320
en la eficiencia de la muestra sobre

791
00:28:04,320 --> 00:28:06,799
líneas de base sólidas sin modelo.

792
00:28:06,799 --> 00:28:08,880
los resultados demuestran la viabilidad

793
00:28:08,880 --> 00:28:11,360
de aplicar la inferencia activa a escala

794
00:28:11,360 --> 00:28:13,360
y resaltan las homologías operativas

795
00:28:13,360 --> 00:28:14,640
entre la inferencia activa

796
00:28:14,640 --> 00:28:16,640
y los enfoques basados en modelos actuales para refor

797
00:28:16,640 --> 00:28:18,240
ar el aprendizaje, de acuer

798
00:28:18,240 --> 00:28:21,600
o, para algunos de usted

799
00:28:21,600 --> 00:28:25,039
s pueden ser muchas ideas nuevas, otros puede

800
00:28:25,039 --> 00:28:28,320
reconocer muchas allí, así que s

801
00:28:28,320 --> 00:28:30,480
lo  diseñar el mapa de ruta sobre cómo

802
00:28:30,480 --> 00:28:31,679
vamos a pasar de la

803
00:28:31,679 --> 00:28:34,960
a a la z y luego, con

804
00:28:34,960 --> 00:28:37,600
suerte, será accesible desde todos estos

805
00:28:37,600 --> 00:28:38,240


806
00:28:38,240 --> 00:28:41,600
ángulos diferentes, la sección uno

807
00:28:41,600 --> 00:28:44,000
es una introducción y la dos trata sobre

808
00:28:44,000 --> 00:28:45,279
la inferencia activa

809
00:28:45,279 --> 00:28:47,919
y el trabajo que se ha realizado en el área

810
00:28:47,919 --> 00:28:48,399
tres

811
00:28:48,399 --> 00:28:49,760
es  el modelo en el que nos vamos

812
00:28:49,760 --> 00:28:51,440
a centrar en esta

813
00:28:51,440 --> 00:28:55,279
discusión y 3.1 es el

814
00:28:55,279 --> 00:28:56,840
modelo generativo y la

815
00:28:56,840 --> 00:28:59,279
distribución de reconocimiento esos son los modelos p y q

816
00:28:59,279 --> 00:29:00,880


817
00:29:00,880 --> 00:29:02,480
luego hay una sección sobre aprendizaje e

818
00:29:02,480 --> 00:29:04,240
inferencia selección de políticas

819
00:29:04,240 --> 00:29:06,080
muestreo de trayectoria y energía libre esperada

820
00:29:06,080 --> 00:29:08,000


821
00:29:08,000 --> 00:29:09,760
también  como una sección sobre el

822
00:29:09,760 --> 00:29:11,600
modelo totalmente observado, esas son las secciones en las

823
00:29:11,600 --> 00:29:12,240
que no profundizaremos

824
00:29:12,240 --> 00:29:15,840
hoy, luego están los

825
00:29:15,840 --> 00:29:17,039
experimentos

826
00:29:17,039 --> 00:29:20,799
relacionados  ted a exploración y explotación

827
00:29:20,799 --> 00:29:22,880
y las dos figuras relacionadas con la

828
00:29:22,880 --> 00:29:25,039
comparación de estrategias de exploración y

829
00:29:25,039 --> 00:29:26,880
la comparación de rendimiento en

830
00:29:26,880 --> 00:29:28,720
tareas de control continuo

831
00:29:28,720 --> 00:29:31,200
luego la relación con el trabajo previo

832
00:29:31,200 --> 00:29:32,240
específicamente

833
00:29:32,240 --> 00:29:33,760
modelo de inferencia activo profundo

834
00:29:33,760 --> 00:29:35,520
aprendizaje reforzado basado y

835
00:29:35,520 --> 00:29:35,919


836
00:29:35,919 --> 00:29:38,840
teoría de ganancia de información luego hay una discusión y

837
00:29:38,840 --> 00:29:40,559
conclusión

838
00:29:40,559 --> 00:29:42,879
todo  bien,

839
00:29:44,000 --> 00:29:47,360
esta cita que puede hacer

840
00:29:47,360 --> 00:29:51,440
una pausa para leerla en su totalidad, solo voy a

841
00:29:51,440 --> 00:29:52,799
retomar el

842
00:29:52,799 --> 00:29:55,279
final del párrafo superior, mientras que este

843
00:29:55,279 --> 00:29:57,200
enfoque, el trabajo anterior, proporciona un

844
00:29:57,200 --> 00:29:59,279
marco elegante para evaluar

845
00:29:59,279 --> 00:30:01,039
la energía libre esperada, solo se puede

846
00:30:01,039 --> 00:30:02,960
aplicar en estado discreto y

847
00:30:02,960 --> 00:30:03,919
espacios de acción,

848
00:30:03,919 --> 00:30:06,000
lo que significa que no es directamente aplicable a

849
00:30:06,000 --> 00:30:07,919
los estados de alta dimensión y las

850
00:30:07,919 --> 00:30:09,520
acciones continuas consideradas en

851
00:30:09,520 --> 00:30:10,880
los puntos de referencia del aprendizaje por refuerzo,

852
00:30:10,880 --> 00:30:12,720
por lo que esta es una de las razones por las que

853
00:30:12,720 --> 00:30:13,919
los

854
00:30:13,919 --> 00:30:16,000
estudiantes basados en estados discretos de inferencia activa no se han compa

855
00:30:16,000 --> 00:30:17,120
ado en la

856
00:30:17,120 --> 00:30:20,320
redacción del autor es que los p

857
00:30:20,320 --> 00:30:22,240
ntos de referencia del aprendizaje por refuerzo que s

858
00:30:22,240 --> 00:30:23,760
utilizan  para probar

859
00:30:23,760 --> 00:30:25,600
la adecuación  La rapidez o la eficacia de

860
00:30:25,600 --> 00:30:27,840
diferentes

861
00:30:27,840 --> 00:30:31,360
algoritmos de teoría de control de aprendizaje por refuerzo

862
00:30:31,360 --> 00:30:33,279
son tareas continuas como las que

863
00:30:33,279 --> 00:30:35,039
hablaremos en las figuras

864
00:30:35,039 --> 00:30:37,679
, por lo que lo que este artículo va a hacer es

865
00:30:37,679 --> 00:30:39,520
emplear un enfoque llamado

866
00:30:39,520 --> 00:30:41,440
inferencia amortizada del que

867
00:30:41,440 --> 00:30:44,080
hablaremos más  en un poco

868
00:30:44,080 --> 00:30:46,720
que utiliza aproximadores funcionales,

869
00:30:46,720 --> 00:30:47,200
es decir,

870
00:30:47,200 --> 00:30:48,960
redes neuronales para parametrizar

871
00:30:48,960 --> 00:30:50,240
distribuciones,

872
00:30:50,240 --> 00:30:51,919
la energía libre se minimiza con

873
00:30:51,919 --> 00:30:53,520
respecto a los parámetros de los

874
00:30:53,520 --> 00:30:55,039
aproximadores de función, no los

875
00:30:55,039 --> 00:30:57,120
parámetros variacionales en sí mismos

876
00:30:57,120 --> 00:30:59,200
y luego reafirman lo que cada una de las

877
00:30:59,200 --> 00:31:01,679
secciones y tres son

878
00:31:01,679 --> 00:31:04,240
aquí es una referencia de notación  hoja

879
00:31:04,240 --> 00:31:06,159
no son todos los

880
00:31:06,159 --> 00:31:09,440
parámetros, especialmente los

881
00:31:09,440 --> 00:31:12,720
parámetros estadísticos, que son distributivos

882
00:31:12,720 --> 00:31:15,440
y muchas de las secciones posteriores también, pero este

883
00:31:15,440 --> 00:31:15,760
es

884
00:31:15,760 --> 00:31:17,760
el tipo de parámetros que vamos

885
00:31:17,760 --> 00:31:18,960
a ver

886
00:31:18,960 --> 00:31:22,960
en las próximas diapositivas y

887
00:31:22,960 --> 00:31:26,080
realmente podemos

888
00:31:26,080 --> 00:31:28,799
ver qué  muchos de los

889
00:31:28,799 --> 00:31:30,480
temas que el modelo va a cubrir

890
00:31:30,480 --> 00:31:33,120
son, por ejemplo, la política de la

891
00:31:33,120 --> 00:31:34,000
era  no

892
00:31:34,000 --> 00:31:36,000
los estados que está tratando de estimar

893
00:31:36,000 --> 00:31:37,600
y los estados verdaderos con los sombreros

894
00:31:37,600 --> 00:31:38,799
va a ser a través del tiempo va a

895
00:31:38,799 --> 00:31:40,399
involucrar observaciones

896
00:31:40,399 --> 00:31:41,519
, estamos viendo muchos de los

897
00:31:41,519 --> 00:31:44,159
ingredientes de los

898
00:31:44,159 --> 00:31:45,279
algoritmos de aprendizaje por refuerzo de los

899
00:31:45,279 --> 00:31:48,320
que hablábamos antes, así que

900
00:31:48,320 --> 00:31:48,880
vamos a

901
00:31:48,880 --> 00:31:53,360
hablar sobre esta inferencia amortizada

902
00:31:53,360 --> 00:31:55,360
esto es lo que escriben la posibilidad del autor de

903
00:31:55,360 --> 00:31:56,480


904
00:31:56,480 --> 00:31:58,240
amortizar el procedimiento de inferencia

905
00:31:58,240 --> 00:31:59,760
ofrece varios beneficios,

906
00:31:59,760 --> 00:32:01,600
por ejemplo, la cantidad de

907
00:32:01,600 --> 00:32:03,519
parámetros permanece constante con respecto

908
00:32:03,519 --> 00:32:04,960
al tamaño

909
00:32:04,960 --> 00:32:06,320
de los datos y la inferencia se puede

910
00:32:06,320 --> 00:32:08,080
lograr a través de un solo paso hacia adelante

911
00:32:08,080 --> 00:32:09,840
de  la red en lugar de, digamos, el

912
00:32:09,840 --> 00:32:12,080
entrenamiento de propagación hacia atrás,

913
00:32:12,080 --> 00:32:14,240
además, mientras que la cantidad de información

914
00:32:14,240 --> 00:32:16,320
codificada sobre las variables es fija,

915
00:32:16,320 --> 00:32:17,840
la relación condicional entre las

916
00:32:17,840 --> 00:32:20,080
variables puede ser arbitrariamente compleja

917
00:32:20,080 --> 00:32:21,840
en la ecuación tres, en la que llegaremos a los

918
00:32:21,840 --> 00:32:23,200
parámetros de la distribución de transición. Los

919
00:32:23,200 --> 00:32:26,640
datos son en sí mismos

920
00:32:26,640 --> 00:32:28,799
variables aleatorias en  el contexto actual

921
00:32:28,799 --> 00:32:30,159
estos parámetros son los pesos de un

922
00:32:30,159 --> 00:32:32,159
red neuronal Si

923
00:32:32,159 --> 00:32:34,000
este enfoque permite cuantificar la incertidumbre

924
00:32:34,000 --> 00:32:35,679
sobre estos parámetros

925
00:32:35,679 --> 00:32:37,200
y proyectar el aprendizaje como un proceso de

926
00:32:37,200 --> 00:32:38,559
inferencia variacional,

927
00:32:38,559 --> 00:32:40,240
la probabilidad previa de theta está dada

928
00:32:40,240 --> 00:32:41,919
por un gaussiano estándar que actúa como un

929
00:32:41,919 --> 00:32:44,080
regularizador durante el

930
00:32:44,080 --> 00:32:47,120
aprendizaje y esto solo habla de cómo la

931
00:32:47,120 --> 00:32:48,960
energía libre  se va a usar para seleccionar la

932
00:32:48,960 --> 00:32:49,519


933
00:32:49,519 --> 00:32:52,240
política de acción, entonces, ¿qué es esta inferencia amortizada?

934
00:32:52,240 --> 00:32:54,640
¿Por qué se usa?

935
00:32:54,640 --> 00:32:56,320
Estos documentos en la parte inferior tienen mucha

936
00:32:56,320 --> 00:32:58,480
más información, pero en la inferencia amortizada,

937
00:32:58,480 --> 00:33:01,039
la cantidad de parámetros utilizados

938
00:33:01,039 --> 00:33:03,039
es flexible, puede tener un tamaño pequeño o

939
00:33:03,039 --> 00:33:04,320
grande.  modelo,

940
00:33:04,320 --> 00:33:07,440
pero lo bueno de esto es que también puede

941
00:33:07,440 --> 00:33:07,919


942
00:33:07,919 --> 00:33:11,200
configurar el tamaño del modelo para que no cambie

943
00:33:11,200 --> 00:33:13,519
incluso cuando se ingresan más datos, lo

944
00:33:13,519 --> 00:33:15,519
que le permite entrenar en dispositivos que

945
00:33:15,519 --> 00:33:16,080
sabe que

946
00:33:16,080 --> 00:33:18,799
tendrán una potencia computacional limitada o usarán

947
00:33:18,799 --> 00:33:20,480
un tamaño muy grande pero

948
00:33:20,480 --> 00:33:24,320
tamaño de modelo definido para implementar en

949
00:33:24,320 --> 00:33:27,760
redes de mayor escala, digamos

950
00:33:27,760 --> 00:33:29,120
nuevamente que el modelo se puede entrenar con un

951
00:33:29,120 --> 00:33:30,799
solo pase hacia adelante en lugar de

952
00:33:30,799 --> 00:33:32,000
juegos más complejos

953
00:33:32,000 --> 00:33:35,440
y th  y también existe todo este grado de

954
00:33:35,440 --> 00:33:37,279
libertad cuando se puede diseñar la

955
00:33:37,279 --> 00:33:38,559
red neuronal porque hay muchos

956
00:33:38,559 --> 00:33:40,320
enfoques que se pueden implementar con

957
00:33:40,320 --> 00:33:42,799
las redes neuronales,

958
00:33:42,799 --> 00:33:45,519
el marco general en el que van

959
00:33:45,519 --> 00:33:49,279
a estar pensando para todo este

960
00:33:49,519 --> 00:33:52,000
viaje matemático en el que estamos.  describir

961
00:33:52,000 --> 00:33:52,799


962
00:33:52,799 --> 00:33:55,919
es un proceso de decisión de Markov parcialmente observado

963
00:33:55,919 --> 00:33:59,279
, por lo que estas son las variables clave

964
00:33:59,279 --> 00:34:01,399
que definirán este

965
00:34:01,399 --> 00:34:03,840
enfoque centrado en el organismo, digamos

966
00:34:03,840 --> 00:34:05,600
en cada paso de tiempo t para que sea

967
00:34:05,600 --> 00:34:07,360
fácil recordar el verdadero estado del

968
00:34:07,360 --> 00:34:08,480
medio ambiente que es

969
00:34:08,480 --> 00:34:10,480
s con un  sombrero sombrero significa que es el

970
00:34:10,480 --> 00:34:11,760
estado real y

971
00:34:11,760 --> 00:34:13,359
los estados son

972
00:34:13,359 --> 00:34:14,879
las cosas importantes que son

973
00:34:14,879 --> 00:34:17,119
como si el autobús me va a atropellar o no

974
00:34:17,119 --> 00:34:18,560
me va a atropellar, digamos,

975
00:34:18,560 --> 00:34:20,320
pero podrían ser varias otras cosas,

976
00:34:20,320 --> 00:34:21,918
así que lo mantenemos en general

977
00:34:21,918 --> 00:34:24,800
y luego eso  s hat sub t por lo que los estados reales a

978
00:34:24,800 --> 00:34:26,079
través del tiempo

979
00:34:26,079 --> 00:34:28,239
existen en un espacio de estado con una cierta

980
00:34:28,239 --> 00:34:29,760
dimensionalidad

981
00:34:29,760 --> 00:34:33,280
y también hay una

982
00:34:33,280 --> 00:34:35,760
dinámica de transición real de los estados reales que está

983
00:34:35,760 --> 00:34:37,119
relacionada con

984
00:34:37,119 --> 00:34:40,480
um esto p s  con un sombrero t dados

985
00:34:40,480 --> 00:34:42,719
los tiempos anteriores y la acción por lo

986
00:34:42,719 --> 00:34:44,079
que está diciendo que

987
00:34:44,079 --> 00:34:46,560
la evolución temporal del sistema el

988
00:34:46,560 --> 00:34:48,719
real con un sombrero t

989
00:34:48,719 --> 00:34:50,399
está relacionado déjame ver si realmente puedo

990
00:34:50,399 --> 00:34:53,598
obtener el láser

991
00:34:54,000 --> 00:34:57,440
sí el s de t con un sombrero

992
00:34:57,440 --> 00:35:00,560
está relacionado con el tiempo actual

993
00:35:00,560 --> 00:35:02,800
y el tiempo anterior y las acciones

994
00:35:02,800 --> 00:35:05,839
y eso también tiene una dimensionalidad

995
00:35:05,839 --> 00:35:07,839
y los agentes no tienen acceso al

996
00:35:07,839 --> 00:35:09,359
estado real del entorno, pero en su

997
00:35:09,359 --> 00:35:11,920
lugar pueden recibir observaciones, por lo que las

998
00:35:11,920 --> 00:35:12,800


999
00:35:12,800 --> 00:35:14,880
observaciones son buenas y fáciles y tienen un

1000
00:35:14,880 --> 00:35:16,240
cierto  dimensionalidad que se

1001
00:35:16,240 --> 00:35:17,520
generan en una

1002
00:35:17,520 --> 00:35:20,160
distribución de observación real t que está

1003
00:35:20,160 --> 00:35:20,960
relacionada con la

1004
00:35:20,960 --> 00:35:23,440
forma en que las observaciones están condicionadas en los

1005
00:35:23,440 --> 00:35:24,720
estados reales del mundo, por lo que si hace mucho

1006
00:35:24,720 --> 00:35:25,920
sol

1007
00:35:25,920 --> 00:35:27,520
afuera, realmente obtendrás fotones

1008
00:35:27,520 --> 00:35:29,440
si miras el sol

1009
00:35:29,440 --> 00:35:32,800
como tal, um nuevamente esto  es porque los agentes

1010
00:35:32,800 --> 00:35:34,320
solo obtienen observaciones y no la

1011
00:35:34,320 --> 00:35:35,920
verdad absoluta del mundo, los

1012
00:35:35,920 --> 00:35:37,680
agentes deben operar según sus creencias

1013
00:35:37,680 --> 00:35:38,960
sobre los estados, por lo

1014
00:35:38,960 --> 00:35:42,079
que sin sombrero a través del tiempo, esos tienen

1015
00:35:42,079 --> 00:35:43,440
una cierta dimensión  realidad

1016
00:35:43,440 --> 00:35:45,599
sobre los verdaderos estados ambientales como

1017
00:35:45,599 --> 00:35:46,800
con un sombrero

1018
00:35:46,800 --> 00:35:49,280
y luego hay una diferencia entre

1019
00:35:49,280 --> 00:35:51,280
la verdadera dinámica sin

1020
00:35:51,280 --> 00:35:53,920
cursiva y el modelo de la dinámica

1021
00:35:53,920 --> 00:35:56,720
que siempre está en cursiva

1022
00:35:56,720 --> 00:35:58,560
y así es como se vinculan esas ecuaciones

1023
00:35:58,560 --> 00:36:00,480
aquí es donde

1024
00:36:00,480 --> 00:36:01,839
entra en juego

1025
00:36:01,839 --> 00:36:04,400
la inferencia activa propone la inferencia activa  que los agentes

1026
00:36:04,400 --> 00:36:06,880
implementan una actualización de un modelo generativo

1027
00:36:06,880 --> 00:36:10,320
de su mundo en cursiva

1028
00:36:10,320 --> 00:36:12,640
p eso significa el modelo del mundo de las

1029
00:36:12,640 --> 00:36:14,079
observaciones

1030
00:36:14,079 --> 00:36:17,200
establece las políticas y los parámetros del

1031
00:36:17,200 --> 00:36:18,000
mundo

1032
00:36:18,000 --> 00:36:20,000
donde la tilde es la secuencia de

1033
00:36:20,000 --> 00:36:21,280
variables a través del tiempo

1034
00:36:21,280 --> 00:36:23,040
entonces esas son las observaciones y los estados a

1035
00:36:23,040 --> 00:36:25,119
través del tiempo y  pi es la política

1036
00:36:25,119 --> 00:36:26,880
como si tuviera la política de ejecutar

1037
00:36:26,880 --> 00:36:28,960
todos los días, entonces mis observaciones a lo largo del

1038
00:36:28,960 --> 00:36:30,560
tiempo se verán

1039
00:36:30,560 --> 00:36:34,240
así, puede imaginar que uno y theta

1040
00:36:34,240 --> 00:36:38,240
um con cursiva pertenece a una versión más grande

1041
00:36:38,240 --> 00:36:40,640
de theta capital theta y eso

1042
00:36:40,640 --> 00:36:42,079
denota parámetros de  el

1043
00:36:42,079 --> 00:36:43,520
modelo generativo que son en sí mismas variables aleatorias

1044
00:36:43,520 --> 00:36:44,560


1045
00:36:44,560 --> 00:36:46,800
y también agentes mantienen una

1046
00:36:46,800 --> 00:36:48,560
distribución de reconocimiento  esto es como p y q,

1047
00:36:48,560 --> 00:36:51,760
así que tenga en cuenta las p y q de los estados a

1048
00:36:51,760 --> 00:36:52,560
través del tiempo

1049
00:36:52,560 --> 00:36:55,920
y las políticas y los

1050
00:36:55,920 --> 00:36:58,400
parámetros theta del mundo que representan las

1051
00:36:58,400 --> 00:36:59,359


1052
00:36:59,359 --> 00:37:02,000
creencias del agente sobre las políticas de sus estados y los

1053
00:37:02,000 --> 00:37:04,800
parámetros del modelo,

1054
00:37:04,960 --> 00:37:08,000
así que en esta

1055
00:37:08,000 --> 00:37:10,880
parte vamos a ver  en el modelo p,

1056
00:37:10,880 --> 00:37:13,200
recuerde que es ps y qs,

1057
00:37:13,200 --> 00:37:17,359
por lo que p es una implementación de agente

1058
00:37:17,359 --> 00:37:19,359
, por eso está en

1059
00:37:19,359 --> 00:37:22,640
cursiva un modelo de las observaciones a través del

1060
00:37:22,640 --> 00:37:23,200
tiempo

1061
00:37:23,200 --> 00:37:25,280
o con los estados de tilde a través del tiempo s

1062
00:37:25,280 --> 00:37:26,320
con una

1063
00:37:26,320 --> 00:37:29,920
política de tilde y parámetros del modelo, así que eso es

1064
00:37:29,920 --> 00:37:30,400
lo que

1065
00:37:30,400 --> 00:37:33,520
esto  de lo que se trata el modelo

1066
00:37:33,520 --> 00:37:35,280
y lo implementa el agente que

1067
00:37:35,280 --> 00:37:37,280
nos importa

1068
00:37:37,280 --> 00:37:39,839
esto es lo que dice cada una de estas líneas, por lo que

1069
00:37:39,839 --> 00:37:40,640
la primera línea

1070
00:37:40,640 --> 00:37:43,040
en el lado izquierdo de la ecuación dice p,

1071
00:37:43,040 --> 00:37:43,839
que es

1072
00:37:43,839 --> 00:37:46,400
esa función que tenemos en grande en la

1073
00:37:46,400 --> 00:37:47,680
parte superior

1074
00:37:47,680 --> 00:37:51,440
es equivalente a la

1075
00:37:51,440 --> 00:37:54,640
probabilidad  modelo de

1076
00:37:54,640 --> 00:37:57,760
los parámetros theta sacarlos

1077
00:37:57,760 --> 00:38:00,000
entonces la probabilidad de la política es entonces

1078
00:38:00,000 --> 00:38:01,599
si no es posible para mí

1079
00:38:01,599 --> 00:38:03,440
saltar mil pies entonces no va a

1080
00:38:03,440 --> 00:38:05,680
ser parte de mi distribución de probabilidad

1081
00:38:05,680 --> 00:38:07,359
si yo  es parte de mi poder para saltar

1082
00:38:07,359 --> 00:38:09,280
mil pies, entonces lo consideraré en

1083
00:38:09,280 --> 00:38:09,839
mis

1084
00:38:09,839 --> 00:38:13,280
estimaciones de política y luego el gran

1085
00:38:13,280 --> 00:38:16,079
pi es algo así como cómo sigma suma

1086
00:38:16,079 --> 00:38:16,400


1087
00:38:16,400 --> 00:38:20,000
cosas pi multiplica cosas y entonces esto

1088
00:38:20,000 --> 00:38:20,400
dice

1089
00:38:20,400 --> 00:38:22,320
multiplique todo a través del tiempo

1090
00:38:22,320 --> 00:38:23,680
comenzando  desde el principio, t

1091
00:38:23,680 --> 00:38:26,960
es igual a uno y mire la p

1092
00:38:26,960 --> 00:38:30,320
el modelo de agente de o a

1093
00:38:30,320 --> 00:38:31,760
través del tiempo observaciones a través del tiempo

1094
00:38:31,760 --> 00:38:33,760
estados dados a través del tiempo, por lo que la primera

1095
00:38:33,760 --> 00:38:35,359
parte es

1096
00:38:35,359 --> 00:38:38,720
cuál es la probabilidad de dado que estoy

1097
00:38:38,720 --> 00:38:41,760
um saludable que estoy viendo este

1098
00:38:41,760 --> 00:38:44,800
estado y  entonces eso se multiplica

1099
00:38:44,800 --> 00:38:48,160
en cada punto de tiempo por las

1100
00:38:48,160 --> 00:38:52,320
formas en que los estados están

1101
00:38:52,320 --> 00:38:55,520
condicionados por los estados anteriores y las

1102
00:38:55,520 --> 00:38:56,480
políticas anteriores

1103
00:38:56,480 --> 00:38:59,359
y los parámetros del modelo, entonces cómo

1104
00:38:59,359 --> 00:39:00,000
todas esas cosas

1105
00:39:00,000 --> 00:39:02,880
están vinculadas multiplicadas a lo largo del tiempo

1106
00:39:02,880 --> 00:39:03,440
es

1107
00:39:03,440 --> 00:39:06,880
lo que en un primer paso describe este gran

1108
00:39:06,880 --> 00:39:08,880
ecuación en la parte superior el modelo total de

1109
00:39:08,880 --> 00:39:10,079
os pi

1110
00:39:10,079 --> 00:39:13,280
theta luego

1111
00:39:13,280 --> 00:39:16,320
para sumergirse en este p de observaciones

1112
00:39:16,320 --> 00:39:17,200
estados dados a

1113
00:39:17,200 --> 00:39:18,960
través del modelo de tiempo que el agente

1114
00:39:18,960 --> 00:39:20,240
implementa

1115
00:39:20,240 --> 00:39:22,880
n notación n grande significa normal y esto

1116
00:39:22,880 --> 00:39:23,359
es decir

1117
00:39:23,359 --> 00:39:25,599
el mod  el de observaciones dadas las

1118
00:39:25,599 --> 00:39:26,560
estimaciones de estado

1119
00:39:26,560 --> 00:39:30,240
es una distribución normal nuevamente

1120
00:39:30,240 --> 00:39:33,200
con observaciones a través del tiempo con una

1121
00:39:33,200 --> 00:39:34,000
cierta

1122
00:39:34,000 --> 00:39:37,040
media y varianza mu y sigma con

1123
00:39:37,040 --> 00:39:39,920
cierto parámetro este lambda y

1124
00:39:39,920 --> 00:39:40,880
juntos

1125
00:39:40,880 --> 00:39:44,160
estos dos este tipo de tupla doble

1126
00:39:44,160 --> 00:39:47,440
de variables

1127
00:39:47,440 --> 00:39:51,359
constituyen esta función lambda

1128
00:39:51,359 --> 00:39:53,599
entonces la forma  que vamos a estimar

1129
00:39:53,599 --> 00:39:54,640
estas

1130
00:39:54,640 --> 00:39:56,960
variantes medias pueden o no ser un mínimo

1131
00:39:56,960 --> 00:39:57,920
cuadrado podría

1132
00:39:57,920 --> 00:40:01,040
no ser una norma l2 podríamos

1133
00:40:01,040 --> 00:40:02,880
usar un enfoque funcional aquí esa es

1134
00:40:02,880 --> 00:40:06,720
la idea de la amortización

1135
00:40:07,119 --> 00:40:09,920
la probabilidad de estados esa

1136
00:40:09,920 --> 00:40:10,880
probabilidad

1137
00:40:10,880 --> 00:40:12,800
modelo de transición de cómo el agente

1138
00:40:12,800 --> 00:40:14,480
cree que los estados a lo largo del

1139
00:40:14,480 --> 00:40:17,520
tiempo están vinculados a dos estados um condicionales

1140
00:40:17,520 --> 00:40:19,760
en un momento anterior y la política en un

1141
00:40:19,760 --> 00:40:20,880
momento anterior y luego los parámetros del

1142
00:40:20,880 --> 00:40:21,839
mundo

1143
00:40:21,839 --> 00:40:24,000
se relacionan con otra distribución normal

1144
00:40:24,000 --> 00:40:25,280


1145
00:40:25,280 --> 00:40:27,520
de estados a lo largo del tiempo con otro mu

1146
00:40:27,520 --> 00:40:29,839
y sigma con un

1147
00:40:29,839 --> 00:40:33,200
subíndice diferente y para

1148
00:40:33,200 --> 00:40:36,640
esos mu  y sigma tenemos f

1149
00:40:36,640 --> 00:40:40,240
um con el sub theta de cómo se relacionan los

1150
00:40:40,240 --> 00:40:43,760
estados y las políticas,

1151
00:40:43,760 --> 00:40:47,119
así que este es otro tipo  de forma de

1152
00:40:47,119 --> 00:40:48,000
estimar

1153
00:40:48,000 --> 00:40:50,640
la varianza de los diferentes tipos de

1154
00:40:50,640 --> 00:40:51,359
eventos que

1155
00:40:51,359 --> 00:40:53,280
suceden, por lo tanto, sopesar las entradas sensoriales

1156
00:40:53,280 --> 00:40:54,400


1157
00:40:54,400 --> 00:40:56,240
juntas, la distribución de estimaciones de estado

1158
00:40:56,240 --> 00:40:57,680


1159
00:40:57,680 --> 00:41:01,839
se estima nuevamente mediante una función

1160
00:41:01,839 --> 00:41:06,480
p de theta se da

1161
00:41:06,480 --> 00:41:09,680
como una distribución normal con una media de

1162
00:41:09,680 --> 00:41:11,200
cero y esta

1163
00:41:11,200 --> 00:41:14,480
matriz de identidad de covarianza creo

1164
00:41:14,480 --> 00:41:17,839
y creo que esto solo refleja

1165
00:41:17,839 --> 00:41:20,720
un enfoque de inicio neutral o

1166
00:41:20,720 --> 00:41:21,920
regularización, pero

1167
00:41:21,920 --> 00:41:25,920
no estoy 100 seguro de eso

1168
00:41:25,920 --> 00:41:28,400
y refleja que el

1169
00:41:28,400 --> 00:41:29,839
modelo de probabilidad de las

1170
00:41:29,839 --> 00:41:33,119
políticas está relacionado con esta

1171
00:41:33,119 --> 00:41:35,520
función máxima, por lo que es un sigma pero es

1172
00:41:35,520 --> 00:41:36,319
no es lo mismo

1173
00:41:36,319 --> 00:41:39,359
que sigma al cuadrado en un modelo estadístico

1174
00:41:39,359 --> 00:41:42,079
y es la función soft max de la

1175
00:41:42,079 --> 00:41:42,720


1176
00:41:42,720 --> 00:41:46,160
energía libre negativa esperada de la política de la

1177
00:41:46,160 --> 00:41:48,960
que hablaremos en una

1178
00:41:48,960 --> 00:41:50,800
sección posterior,

1179
00:41:50,800 --> 00:41:54,800
así que esa fue nuestra p veamos q

1180
00:41:54,800 --> 00:41:57,839
q es esta distribución de reconocimiento de agente

1181
00:41:57,839 --> 00:41:59,040
la  q con la cursiva

1182
00:41:59,040 --> 00:42:01,359
de los estados a través de la política de tiempo y los

1183
00:42:01,359 --> 00:42:03,359
parámetros del modelo

1184
00:42:03,359 --> 00:42:06,720
, así es como se define,

1185
00:42:06,720 --> 00:42:08,720
por lo que q es la probabilidad de los

1186
00:42:08,720 --> 00:42:10,240
parámetros theta

1187
00:42:10,240 --> 00:42:11,920
multi  aplicado por la probabilidad de las

1188
00:42:11,920 --> 00:42:14,240
políticas pi y luego esa misma

1189
00:42:14,240 --> 00:42:17,359
multiplicación a través del tiempo para todo el tiempo

1190
00:42:17,359 --> 00:42:20,480
de q que es el modelo de estados dadas las

1191
00:42:20,480 --> 00:42:22,880
observaciones

1192
00:42:22,880 --> 00:42:26,480
por lo que anteriormente

1193
00:42:26,640 --> 00:42:30,319
habíamos observado p-o-s la segunda línea

1194
00:42:30,319 --> 00:42:30,800
aquí

1195
00:42:30,800 --> 00:42:34,880
probabilidad de las observaciones dados los estados

1196
00:42:38,240 --> 00:42:41,359
ahora tenemos um q s o

1197
00:42:41,359 --> 00:42:44,880
entonces esto  es algo así como ir en sentido contrario

1198
00:42:44,880 --> 00:42:48,000
dos de theta

1199
00:42:48,240 --> 00:42:50,720
es una especie de distribución normal como

1200
00:42:50,720 --> 00:42:51,599
vimos antes

1201
00:42:51,599 --> 00:42:54,079
con sus parámetros de media y varianza

1202
00:42:54,079 --> 00:42:56,319
igual que la política

1203
00:42:56,319 --> 00:42:59,520
y igual que el modelo q

1204
00:42:59,520 --> 00:43:01,280
de los estados dadas las

1205
00:43:01,280 --> 00:43:04,000
observaciones

1206
00:43:04,400 --> 00:43:08,720
y resulta que esos  mu y

1207
00:43:08,720 --> 00:43:10,960
sigma también tendrán un funcional que los

1208
00:43:10,960 --> 00:43:14,160
aproximará, de

1209
00:43:14,720 --> 00:43:16,960
modo que para hacer una inferencia activa aplicable

1210
00:43:16,960 --> 00:43:18,240
a los tipos de tareas que se

1211
00:43:18,240 --> 00:43:19,839
consideran en el aprendizaje por refuerzo,

1212
00:43:19,839 --> 00:43:22,400
los autores trataron las observaciones de las señales de recompensa

1213
00:43:22,400 --> 00:43:23,200


1214
00:43:23,200 --> 00:43:25,200
como observaciones en una modalidad separada, de

1215
00:43:25,200 --> 00:43:27,520
modo que se extiende el modelo generativo a

1216
00:43:27,520 --> 00:43:28,160
incluya

1217
00:43:28,160 --> 00:43:31,200
un gaussiano escalar adicional, por lo que ese es

1218
00:43:31,200 --> 00:43:32,800
otro

1219
00:43:32,800 --> 00:43:34,800
valor de recompensa de los escalares como un solo

1220
00:43:34,800 --> 00:43:36,960
número sobre la observación de recompensa  s con una

1221
00:43:36,960 --> 00:43:38,800
varianza de unidad en la media

1222
00:43:38,800 --> 00:43:41,119
y eso les permite envolver esta red neuronal

1223
00:43:41,119 --> 00:43:42,400


1224
00:43:42,400 --> 00:43:45,119
que es uh f sub alfa de los estados

1225
00:43:45,119 --> 00:43:46,480
que es como esta

1226
00:43:46,480 --> 00:43:47,920
red neuronal completamente conectada de recompensa con los

1227
00:43:47,920 --> 00:43:49,119
parámetros que luego van a

1228
00:43:49,119 --> 00:43:50,079
entrenar,

1229
00:43:50,079 --> 00:43:52,160
así que ahí es realmente donde el  La homología formal que

1230
00:43:52,160 --> 00:43:54,640
surge del aprendizaje por refuerzo basado en modelos

1231
00:43:54,640 --> 00:43:56,079


1232
00:43:56,079 --> 00:43:58,720
es que ahora tenemos más o menos la misma

1233
00:43:58,720 --> 00:44:01,440
arquitectura que se especificó anteriormente

1234
00:44:01,440 --> 00:44:05,599
en esta discusión donde el estado del agente

1235
00:44:05,599 --> 00:44:09,040
es luego de la entrada sensorial que se ejecuta a través de

1236
00:44:09,040 --> 00:44:10,000
este dnn

1237
00:44:10,000 --> 00:44:12,319
y que da como resultado esta salida de la

1238
00:44:12,319 --> 00:44:13,599
política

1239
00:44:13,599 --> 00:44:16,560
o  la recompensa, pero es un poco

1240
00:44:16,560 --> 00:44:17,839
diferente, pero así es

1241
00:44:17,839 --> 00:44:20,960
como vemos muchas de las mismas homologías,

1242
00:44:20,960 --> 00:44:24,319
entonces, ¿qué hacen los

1243
00:44:24,319 --> 00:44:27,040
alumnos a medida que se muestrean nuevas observaciones? Los

1244
00:44:27,040 --> 00:44:27,839


1245
00:44:27,839 --> 00:44:29,520
agentes actualizan los parámetros de la

1246
00:44:29,520 --> 00:44:31,200
distribución de reconocimiento

1247
00:44:31,200 --> 00:44:34,480
para minimizar la energía libre variacional o f

1248
00:44:34,480 --> 00:44:38,160
para que la f  de la observación es

1249
00:44:38,160 --> 00:44:42,319
la expectativa um está bien

1250
00:44:42,319 --> 00:44:44,480
déjame terminar de leer primero esto hace que

1251
00:44:44,480 --> 00:44:45,440


1252
00:44:45,440 --> 00:44:47,520
lo que esta f va a hacer es

1253
00:44:47,520 --> 00:44:48,800
distribuir el reconocimiento  bution

1254
00:44:48,800 --> 00:44:51,440
q convergen hacia una aproximación de

1255
00:44:51,440 --> 00:44:53,920
la distribución posterior intratable

1256
00:44:53,920 --> 00:44:56,720
p, implementando así una forma manejable

1257
00:44:56,720 --> 00:44:58,800
de inferencia bayesiana aproximada,

1258
00:44:58,800 --> 00:45:02,079
así que f de

1259
00:45:02,079 --> 00:45:04,240
o a través del tiempo con una tilde es la

1260
00:45:04,240 --> 00:45:05,119


1261
00:45:05,119 --> 00:45:07,040
energía libre variacional de las observaciones a través del

1262
00:45:07,040 --> 00:45:08,319
tiempo,

1263
00:45:08,319 --> 00:45:12,000
entonces, ¿qué es esta energía libre

1264
00:45:12,000 --> 00:45:13,920
mágica no mágica?  es solo esta ecuación en

1265
00:45:13,920 --> 00:45:15,200
este

1266
00:45:15,200 --> 00:45:18,000
caso es una expectativa que está condicionada

1267
00:45:18,000 --> 00:45:19,839
a un modelo de reconocimiento específico

1268
00:45:19,839 --> 00:45:22,720
que es esta expectativa de q

1269
00:45:22,720 --> 00:45:23,280
que estará

1270
00:45:23,280 --> 00:45:26,960
relacionada con esta

1271
00:45:26,960 --> 00:45:30,160
política de um s pi y los parámetros theta

1272
00:45:30,160 --> 00:45:34,560
uh variables de qué va a ser esta expectativa

1273
00:45:34,560 --> 00:45:35,760


1274
00:45:35,760 --> 00:45:37,520
eso es todo  eso está a punto de estar entre

1275
00:45:37,520 --> 00:45:38,960
corchetes

1276
00:45:38,960 --> 00:45:41,040
esta expectativa va a ser el

1277
00:45:41,040 --> 00:45:43,119
registro natural

1278
00:45:43,119 --> 00:45:46,319
que es una forma de convertir una

1279
00:45:46,319 --> 00:45:48,640
pregunta sobre maximizar la bondad

1280
00:45:48,640 --> 00:45:50,000
del ajuste de un modelo

1281
00:45:50,000 --> 00:45:52,319
en minimizar lo negativo a

1282
00:45:52,319 --> 00:45:53,440
veces hay algunas

1283
00:45:53,440 --> 00:45:55,920
formas en que la ley natural puede ayudar  la

1284
00:45:55,920 --> 00:45:56,720


1285
00:45:56,720 --> 00:45:58,880
expectativa va a ser el logaritmo natural del

1286
00:45:58,880 --> 00:46:00,880
modelo de reconocimiento

1287
00:46:00,880 --> 00:46:03,599
menos el logaritmo natural del gen

1288
00:46:03,599 --> 00:46:04,240
modelo rativo,

1289
00:46:04,240 --> 00:46:06,720
así que de nuevo esa es la parte en la que indicamos

1290
00:46:06,720 --> 00:46:07,760
que podemos aprender

1291
00:46:07,760 --> 00:46:09,280
y luego la parte p que se

1292
00:46:09,280 --> 00:46:10,880
caracteriza como

1293
00:46:10,880 --> 00:46:13,359
intratable, resulta que esta expectativa

1294
00:46:13,359 --> 00:46:15,440
siempre es mayor o igual que el

1295
00:46:15,440 --> 00:46:18,720
logaritmo natural de p de las observaciones,

1296
00:46:18,720 --> 00:46:21,599
así que esa es la justa  el modelo p de probabilidad de las

1297
00:46:21,599 --> 00:46:24,000
observaciones

1298
00:46:24,000 --> 00:46:26,079
al minimizar la energía libre de las

1299
00:46:26,079 --> 00:46:27,760
observaciones a lo largo del tiempo,

1300
00:46:27,760 --> 00:46:29,839
el agente converge heurísticamente

1301
00:46:29,839 --> 00:46:31,760
hacia esta distribución p intratable

1302
00:46:31,760 --> 00:46:34,960
dado que

1303
00:46:34,960 --> 00:46:38,079
q está solo sobre las

1304
00:46:38,079 --> 00:46:40,960
políticas y parámetros del estado y que p

1305
00:46:40,960 --> 00:46:42,640
realmente incluye y se enfoca en las

1306
00:46:42,640 --> 00:46:44,079
observaciones

1307
00:46:44,079 --> 00:46:46,640
lo que esto permite  lo que debe hacer el agente

1308
00:46:46,640 --> 00:46:48,319
es enfocarse en modelar

1309
00:46:48,319 --> 00:46:50,079
los estados y las políticas y los

1310
00:46:50,079 --> 00:46:52,319
parámetros que son relevantes a través de la cola

1311
00:46:52,319 --> 00:46:55,520
y luego potencialmente usar el

1312
00:46:55,520 --> 00:46:58,960
comportamiento inactivo de la barra matemática en este modelo para

1313
00:46:58,960 --> 00:47:01,119
incluir de manera atractiva la condición o

1314
00:47:01,119 --> 00:47:02,800
aprender de sus observaciones

1315
00:47:02,800 --> 00:47:04,800
para que podamos traer conocimiento previo  a

1316
00:47:04,800 --> 00:47:06,400
la mesa al igual que los modelos bayesianos

1317
00:47:06,400 --> 00:47:07,359
permiten,

1318
00:47:07,359 --> 00:47:10,240
pero también tienen una forma de lidiar con escaso

1319
00:47:10,240 --> 00:47:11,359
o denso  la información

1320
00:47:11,359 --> 00:47:14,240
como está

1321
00:47:14,480 --> 00:47:18,000
bien la inferencia crucialmente activa también

1322
00:47:18,000 --> 00:47:19,599
propone que las metas y los

1323
00:47:19,599 --> 00:47:21,440
deseos de un agente están codificados en el

1324
00:47:21,440 --> 00:47:23,520
modelo generativo como preferencias previas por

1325
00:47:23,520 --> 00:47:24,640
observaciones favorables,

1326
00:47:24,640 --> 00:47:28,000
es decir, la temperatura de la sangre a 37 grados centígrados,

1327
00:47:28,000 --> 00:47:29,839
la energía libre proporciona un indicador de

1328
00:47:29,839 --> 00:47:31,920
cuán sorprendentes, es decir, improbables

1329
00:47:31,920 --> 00:47:34,160
, son algunas observaciones bajo el  El modelo del agente

1330
00:47:34,160 --> 00:47:36,319
mientras minimiza la ecuación 1 proporciona una

1331
00:47:36,319 --> 00:47:38,000
estimación de cuán sorprendentes son algunas de nuestras

1332
00:47:38,000 --> 00:47:39,760
observaciones, no puede reducir la

1333
00:47:39,760 --> 00:47:41,040
cantidad directamente,

1334
00:47:41,040 --> 00:47:44,240
así que aquí en la ecuación uno definimos qué

1335
00:47:44,240 --> 00:47:46,720
era f, pero es solo una definición y un

1336
00:47:46,720 --> 00:47:47,839
límite

1337
00:47:47,839 --> 00:47:51,359
de lo que es f, no puede reducir esta

1338
00:47:51,359 --> 00:47:53,280
cantidad directamente.  por lo tanto, no está realmente

1339
00:47:53,280 --> 00:47:54,960
relacionado con la

1340
00:47:54,960 --> 00:47:58,720
política, ya que los enfoques directos

1341
00:47:58,720 --> 00:48:01,200
para lograr esto, los agentes deben cambiar sus

1342
00:48:01,200 --> 00:48:03,280
observaciones a través de la acción,

1343
00:48:03,280 --> 00:48:05,280
actuando para minimizar la energía libre variacional,

1344
00:48:05,280 --> 00:48:07,040
asegura la minimización de la

1345
00:48:07,040 --> 00:48:07,599
sorpresa,

1346
00:48:07,599 --> 00:48:10,160
logaritmo natural negativo del

1347
00:48:10,160 --> 00:48:12,880
modelo de probabilidad de las observaciones

1348
00:48:12,880 --> 00:48:14,720
o la maximización de la

1349
00:48:14,720 --> 00:48:16,240
evidencia del modelo bayesiano

1350
00:48:16,240 --> 00:48:19,440
p  de observaciones a través del tiempo  dado que

1351
00:48:19,440 --> 00:48:20,079
la energía libre

1352
00:48:20,079 --> 00:48:21,920
proporciona un límite superior a la sorpresa

1353
00:48:21,920 --> 00:48:23,599
que era la ecuación uno,

1354
00:48:23,599 --> 00:48:26,160
la inferencia activa propone que los

1355
00:48:26,160 --> 00:48:27,680
agentes seleccionen la política

1356
00:48:27,680 --> 00:48:29,520
para minimizar la energía libre esperada

1357
00:48:29,520 --> 00:48:30,960


1358
00:48:30,960 --> 00:48:34,000
fantasía g donde la energía libre esperada

1359
00:48:34,000 --> 00:48:36,160
para una política determinada pi en algún momento futuro

1360
00:48:36,160 --> 00:48:38,240


1361
00:48:38,240 --> 00:48:41,760
se definirá  de modo

1362
00:48:41,760 --> 00:48:44,880
que queremos hacer algo más que simplemente actualizar

1363
00:48:44,880 --> 00:48:47,839
nuestro modelo interno para limitar nuestra sorpresa

1364
00:48:47,839 --> 00:48:49,359
en nuestras observaciones, no solo

1365
00:48:49,359 --> 00:48:51,119
queremos ajustarnos al modelo de descriptor estadístico

1366
00:48:51,119 --> 00:48:52,160
del mundo

1367
00:48:52,160 --> 00:48:53,920
, queremos reducir la incertidumbre en el

1368
00:48:53,920 --> 00:48:55,920
futuro, que es un punto de tiempo futuro  t

1369
00:48:55,920 --> 00:48:59,440
tau a través de la política pi que tomamos

1370
00:48:59,440 --> 00:49:00,960
ahora

1371
00:49:00,960 --> 00:49:02,960
esta función de energía libre esperada minimizable

1372
00:49:02,960 --> 00:49:04,880
fantasía

1373
00:49:04,880 --> 00:49:07,599
g va a tomar en los argumentos de la

1374
00:49:07,599 --> 00:49:08,800
selección de política

1375
00:49:08,800 --> 00:49:11,680
y el paso de tiempo futuro así que fantasía g

1376
00:49:11,680 --> 00:49:12,640
fantasía pi

1377
00:49:12,640 --> 00:49:15,760
fantasía t esa es la función de energía libre

1378
00:49:15,760 --> 00:49:17,920
en este caso

1379
00:49:17,920 --> 00:49:21,680
y  cuál

1380
00:49:21,680 --> 00:49:24,319
será el valor cuya optimización va a

1381
00:49:24,319 --> 00:49:25,599
permitir una acción efectiva y

1382
00:49:25,599 --> 00:49:27,599
cuál es la

1383
00:49:27,599 --> 00:49:28,720
expectativa

1384
00:49:28,720 --> 00:49:31,760
que va a estar relacionada con el modelo q

1385
00:49:31,760 --> 00:49:34,720
que se trata de estos estados de observación

1386
00:49:34,720 --> 00:49:37,119
y parámetros dados modelos de políticas,

1387
00:49:37,119 --> 00:49:39,359
dado que mi política es esta,

1388
00:49:39,359 --> 00:49:42,720
entonces, ¿cómo aparecerán los estados y las transiciones

1389
00:49:42,720 --> 00:49:43,599
del

1390
00:49:43,599 --> 00:49:46,960
mundo y será la

1391
00:49:46,960 --> 00:49:50,400
expectativa de esta cantidad que está entre

1392
00:49:50,400 --> 00:49:51,280


1393
00:49:51,280 --> 00:49:53,760
paréntesis, será el registro de estados?  y

1394
00:49:53,760 --> 00:49:54,640
parámetros,

1395
00:49:54,640 --> 00:49:58,079
así que ese es el q de los s sub t

1396
00:49:58,079 --> 00:50:01,359
y parámetros dada la política,

1397
00:50:01,359 --> 00:50:04,480
así que esos son los estados en los que estaré y

1398
00:50:04,480 --> 00:50:06,960
qué pensaré sobre

1399
00:50:06,960 --> 00:50:10,000
um en el camino, potencialmente estas son

1400
00:50:10,000 --> 00:50:10,400
solo

1401
00:50:10,400 --> 00:50:12,960
explicaciones verbales de primer paso, solo

1402
00:50:12,960 --> 00:50:15,119
mire las matemáticas, pero

1403
00:50:15,119 --> 00:50:18,810
¿qué estados  y los parámetros en los que estoy ahora

1404
00:50:18,810 --> 00:50:20,000
[Música]

1405
00:50:20,000 --> 00:50:23,359
en un momento futuro dada mi política, así que si

1406
00:50:23,359 --> 00:50:25,599
salgo a caminar todos los días, ¿cómo influirá en

1407
00:50:25,599 --> 00:50:27,119
mis

1408
00:50:27,119 --> 00:50:29,200
estados? ¿Cuál tiene que ser mi modelo en

1409
00:50:29,200 --> 00:50:30,319
ese momento?

1410
00:50:30,319 --> 00:50:32,880
y luego esa cantidad menos el logaritmo natural

1411
00:50:32,880 --> 00:50:34,000
de  p

1412
00:50:34,000 --> 00:50:36,400
los estados de observación en el modelo

1413
00:50:36,400 --> 00:50:38,000
dado la política, por lo que esa es la parte que

1414
00:50:38,000 --> 00:50:40,000
queremos que las observaciones sean

1415
00:50:40,000 --> 00:50:43,520
los valores correctos, pero lo que podemos hacer

1416
00:50:43,520 --> 00:50:46,480
es simplemente condicionar los estados a la

1417
00:50:46,480 --> 00:50:48,960
política

1418
00:50:50,160 --> 00:50:53,760
y ese valor g  siempre es mayor que

1419
00:50:53,760 --> 00:50:54,240
el

1420
00:50:54,240 --> 00:50:55,760
negativo, que es esta última parte de la

1421
00:50:55,760 --> 00:50:57,599
ecuación dos, entonces la expectativa negativa

1422
00:50:57,599 --> 00:50:59,040


1423
00:50:59,040 --> 00:51:01,599
de esta q, que son las observaciones

1424
00:51:01,599 --> 00:51:03,599
condicionadas a la política, así es

1425
00:51:03,599 --> 00:51:08,319
como resultarán las cosas en realidad, um

1426
00:51:08,319 --> 00:51:10,880
de esta parte logarítmica del modelo generativo,

1427
00:51:10,880 --> 00:51:11,920
que son

1428
00:51:11,920 --> 00:51:14,319
las observaciones dadas  la política así es

1429
00:51:14,319 --> 00:51:15,760
como funcionarán las cosas,

1430
00:51:15,760 --> 00:51:18,160
así que tal vez haya otras interpretaciones

1431
00:51:18,160 --> 00:51:18,800
u otras

1432
00:51:18,800 --> 00:51:20,240
partes que sean realmente críticas, pero

1433
00:51:20,240 --> 00:51:22,000
creo que esta es una de las formulaciones clave,

1434
00:51:22,000 --> 00:51:25,119
que es que hay un

1435
00:51:25,119 --> 00:51:29,119
problema de optimización relacionado con la política

1436
00:51:29,119 --> 00:51:32,240
que se puede expresar de una manera variacional

1437
00:51:32,240 --> 00:51:35,520
que va a  estar limitado a través de una

1438
00:51:35,520 --> 00:51:36,960


1439
00:51:36,960 --> 00:51:40,000
estrategia similar a la energía libre para

1440
00:51:40,000 --> 00:51:43,440
estimar de manera manejable alguna

1441
00:51:43,440 --> 00:51:46,720
otra función q algo relacionado con

1442
00:51:46,720 --> 00:51:47,760
eso

1443
00:51:47,760 --> 00:51:50,319
de básicamente lo que querríamos saber,

1444
00:51:50,319 --> 00:51:51,440
que es como está

1445
00:51:51,440 --> 00:51:54,559
bien, la observación de que miro en mi

1446
00:51:54,559 --> 00:51:58,160
billetera bitcoin y hay 15 bitcoins,

1447
00:51:58,160 --> 00:52:01,200
¿cómo qué política tengo?  tomar para

1448
00:52:01,200 --> 00:52:03,680
ver esa observación o para que exista ese contrafactual

1449
00:52:03,680 --> 00:52:06,160


1450
00:52:06,160 --> 00:52:08,880
si solo uno supiera que es por eso que existe

1451
00:52:08,880 --> 00:52:09,839
este control

1452
00:52:09,839 --> 00:52:12,800
ecuación delimitable potencialmente i i

1453
00:52:12,800 --> 00:52:13,839
creo que hay mucho que

1454
00:52:13,839 --> 00:52:16,960
decir aquí y alec y cualquier otra persona

1455
00:52:16,960 --> 00:52:18,000
agradecería cualquier otra

1456
00:52:18,000 --> 00:52:20,800
contribución, pero eso fue solo una lectura,

1457
00:52:20,800 --> 00:52:21,680
está bien,

1458
00:52:21,680 --> 00:52:23,920
así que esa era la mayor parte de la parte por la que

1459
00:52:23,920 --> 00:52:25,440
quería pasar a ese nivel de

1460
00:52:25,440 --> 00:52:27,280
profundidad  pero luego solo para transmitir

1461
00:52:27,280 --> 00:52:29,680
las otras secciones y lo que hacen para

1462
00:52:29,680 --> 00:52:30,400
el documento,

1463
00:52:30,400 --> 00:52:32,160
pero no entrar tanto en cada ecuación

1464
00:52:32,160 --> 00:52:33,599
y luego hablar sobre las figuras,

1465
00:52:33,599 --> 00:52:36,960
por lo que 3.2 es la sección de aprendizaje e inferencia

1466
00:52:36,960 --> 00:52:37,760


1467
00:52:37,760 --> 00:52:41,119
y para implementar realmente

1468
00:52:41,119 --> 00:52:43,520
este esquema de optimización tal como se presenta

1469
00:52:43,520 --> 00:52:44,160


1470
00:52:44,160 --> 00:52:46,079
resulta que tiene que haber un

1471
00:52:46,079 --> 00:52:47,599
proceso de actualización, entonces

1472
00:52:47,599 --> 00:52:49,760
, ¿va a ser una especie de apegarse

1473
00:52:49,760 --> 00:52:51,359
a lo que ha funcionado o va a

1474
00:52:51,359 --> 00:52:51,760
ser una

1475
00:52:51,760 --> 00:52:53,760
búsqueda de novedades? Ese es el tipo de cosas

1476
00:52:53,760 --> 00:52:54,880
que los

1477
00:52:54,880 --> 00:52:56,720
algoritmos de optimización tienen que navegar por las

1478
00:52:56,720 --> 00:52:59,040
compensaciones que son  implícita uh

1479
00:52:59,040 --> 00:53:00,880
con diferentes estrategias dependiendo de

1480
00:53:00,880 --> 00:53:02,079
diferentes problemas

1481
00:53:02,079 --> 00:53:05,599
, por lo que esta sección define cómo esta

1482
00:53:05,599 --> 00:53:09,280
f uh energía libre variacional se define a

1483
00:53:09,280 --> 00:53:11,119
través del tiempo

1484
00:53:11,119 --> 00:53:12,720
y no voy a cubrir los

1485
00:53:12,720 --> 00:53:14,559
detalles de implementación b  ut, alex

1486
00:53:14,559 --> 00:53:17,520
alec, sería genial si

1487
00:53:17,520 --> 00:53:19,119
nos mostraras una simulación o algo así.

1488
00:53:19,119 --> 00:53:20,880


1489
00:53:20,880 --> 00:53:23,920
uh 3.3 trata sobre la selección de políticas. Esto es

1490
00:53:23,920 --> 00:53:25,280
lo que escriben

1491
00:53:25,280 --> 00:53:27,440
en inferencia activa. La selección de políticas

1492
00:53:27,440 --> 00:53:29,040
se logra actualizando q

1493
00:53:29,040 --> 00:53:31,040
de la política para minimizar la

1494
00:53:31,040 --> 00:53:33,200
energía libre en fantasía f

1495
00:53:33,200 --> 00:53:35,440
dada la creencia previa de que las políticas

1496
00:53:35,440 --> 00:53:37,280
minimizan la energía libre esperada,

1497
00:53:37,280 --> 00:53:41,040
es decir, la p de la política está relacionada con

1498
00:53:41,040 --> 00:53:44,240
esta elección, el máximo suave relacionado con la

1499
00:53:44,240 --> 00:53:47,920
um negativa g negativa uh

1500
00:53:47,920 --> 00:53:51,280
la energía libre esperada de los espacios de política

1501
00:53:51,280 --> 00:53:53,359
con cortos,

1502
00:53:53,359 --> 00:53:55,920
como se especifica en la ecuación tres, la

1503
00:53:55,920 --> 00:53:57,359
energía libre se minimiza

1504
00:53:57,359 --> 00:54:02,079
cuando la uh  q la distribución de la política

1505
00:54:02,079 --> 00:54:05,599
es la misma que la energía libre

1506
00:54:05,599 --> 00:54:08,160
óptima minimizando la expectativa de políticas a

1507
00:54:08,160 --> 00:54:10,000
través de políticas como la

1508
00:54:10,000 --> 00:54:13,200
selección de política óptima de energía libre

1509
00:54:13,200 --> 00:54:14,800
para espacios de acción discretos con

1510
00:54:14,800 --> 00:54:16,240
horizontes temporales cortos

1511
00:54:16,240 --> 00:54:19,200
básicamente g de la política puede evaluarse

1512
00:54:19,200 --> 00:54:20,720
en su totalidad considerando cada

1513
00:54:20,720 --> 00:54:22,720
política posible  entonces eso es como conectar cuatro

1514
00:54:22,720 --> 00:54:25,520
, podrías agotarte o tic-tac-toe

1515
00:54:25,520 --> 00:54:26,160
, puedes agotar

1516
00:54:26,160 --> 00:54:27,839
todas las opciones para th  Los juegos en

1517
00:54:27,839 --> 00:54:29,599
ese punto de bifurcación

1518
00:54:29,599 --> 00:54:31,680
calculan el valor absoluto de

1519
00:54:31,680 --> 00:54:33,520
cada resultado posible

1520
00:54:33,520 --> 00:54:35,920
y luego hacen su elección; sin embargo, en

1521
00:54:35,920 --> 00:54:37,760
los espacios de acción continua hay

1522
00:54:37,760 --> 00:54:39,839
infinitas políticas, lo que significa que se requiere un enfoque alternativo.

1523
00:54:39,839 --> 00:54:41,040


1524
00:54:41,040 --> 00:54:42,960
Esa es una oración realmente genial porque

1525
00:54:42,960 --> 00:54:45,200
realmente transmite bien

1526
00:54:45,200 --> 00:54:47,599
que en realidad la acción continua.

1527
00:54:47,599 --> 00:54:48,240
el espacio,

1528
00:54:48,240 --> 00:54:50,720
incluso para una sola variable, es un

1529
00:54:50,720 --> 00:54:51,680
dominio realmente diferente

1530
00:54:51,680 --> 00:54:54,400
que, digamos, el juego del dilema del prisionero

1531
00:54:54,400 --> 00:54:55,119


1532
00:54:55,119 --> 00:54:58,160
. A veces, casi no hay superposición

1533
00:54:58,160 --> 00:55:00,160
en los algoritmos.

1534
00:55:00,160 --> 00:55:02,880


1535
00:55:02,880 --> 00:55:06,079


1536
00:55:06,079 --> 00:55:09,200


1537
00:55:09,200 --> 00:55:10,559
¿pasa de tener simplemente esta

1538
00:55:10,559 --> 00:55:12,400
relación de distribución entre las

1539
00:55:12,400 --> 00:55:15,200
políticas y otras variables, como las

1540
00:55:15,200 --> 00:55:16,720
relacionadas con los modelos generativos del

1541
00:55:16,720 --> 00:55:17,920
mundo

1542
00:55:17,920 --> 00:55:21,119
y los modelos de observación, cómo

1543
00:55:21,119 --> 00:55:21,520
van a

1544
00:55:21,520 --> 00:55:23,520
llegar allí para evaluar desde la

1545
00:55:23,520 --> 00:55:25,599
distribución hasta la política específica

1546
00:55:25,599 --> 00:55:27,839
para evaluar la energía libre esperada?

1547
00:55:27,839 --> 00:55:29,680
para cualquier política específica

1548
00:55:29,680 --> 00:55:31,599
primero tienen que evaluar  las

1549
00:55:31,599 --> 00:55:33,680
creencias futuras esperadas condicionan esa política,

1550
00:55:33,680 --> 00:55:37,440
por lo que uno no puede realmente

1551
00:55:37,440 --> 00:55:40,559
emprender en este tipo de marco normativo

1552
00:55:40,559 --> 00:55:42,480
, es un debate secundario que

1553
00:55:42,480 --> 00:55:44,480
definitivamente podemos tener sobre hasta qué punto

1554
00:55:44,480 --> 00:55:45,119


1555
00:55:45,119 --> 00:55:46,880
los humanos los experimentan cognitivamente, pero

1556
00:55:46,880 --> 00:55:48,160
solo vamos a  tipo de

1557
00:55:48,160 --> 00:55:50,160
ir con él con la postura intencional

1558
00:55:50,160 --> 00:55:51,760
y el tipo de teoría de control de aprendizaje automático

1559
00:55:51,760 --> 00:55:52,160


1560
00:55:52,160 --> 00:55:55,359
toma pero y así creencias no es

1561
00:55:55,359 --> 00:55:57,200
necesariamente cognitivo

1562
00:55:57,200 --> 00:55:58,400
, solo estamos pensando en lo que el agente

1563
00:55:58,400 --> 00:56:00,319
quiere hacer para tener éxito,

1564
00:56:00,319 --> 00:56:02,240
pero básicamente si el agente no tiene

1565
00:56:02,240 --> 00:56:03,920
un  secuencia esperada de

1566
00:56:03,920 --> 00:56:06,400
creencias futuras para esa política

1567
00:56:06,400 --> 00:56:08,160
será extremadamente difícil para ellos llevarla a

1568
00:56:08,160 --> 00:56:09,599
cabo

1569
00:56:09,599 --> 00:56:12,559
y el trans um el hecho de que el

1570
00:56:12,559 --> 00:56:13,359


1571
00:56:13,359 --> 00:56:14,880
modelo de transición es probabilístico y los

1572
00:56:14,880 --> 00:56:16,480
parámetros del modelo de transición o las

1573
00:56:16,480 --> 00:56:17,599
variables aleatorias

1574
00:56:17,599 --> 00:56:19,440
inducen una distribución sobre las trayectorias futuras,

1575
00:56:19,440 --> 00:56:21,040
por lo que en

1576
00:56:21,040 --> 00:56:23,520
lugar de simplemente jugar

1577
00:56:23,520 --> 00:56:24,640


1578
00:56:24,640 --> 00:56:27,280
estamos pensando en cómo encajar

1579
00:56:27,280 --> 00:56:28,559
un

1580
00:56:28,559 --> 00:56:31,200
tipo de modelo más avanzado en cada movimiento de ajedrez posible, bueno, el ajedrez

1581
00:56:31,200 --> 00:56:32,480
sigue siendo discreto, así que

1582
00:56:32,480 --> 00:56:35,040
l  Elijamos, veremos un ejemplo específico,

1583
00:56:35,040 --> 00:56:35,760


1584
00:56:35,760 --> 00:56:38,319
pero esto es solo una optimización continua

1585
00:56:38,319 --> 00:56:38,880
más adelante

1586
00:56:38,880 --> 00:56:42,799
en estas cifras, pero esto es como

1587
00:56:42,799 --> 00:56:45,680
tener una distribución sobre

1588
00:56:45,680 --> 00:56:46,880
puntos de ramificación futuros en un juego de ajedrez,

1589
00:56:46,880 --> 00:56:49,280
por lo que, ya sea discreto o

1590
00:56:49,280 --> 00:56:50,880
continuo, aún puede tener este elemento de

1591
00:56:50,880 --> 00:56:51,839
incertidumbre

1592
00:56:51,839 --> 00:56:54,559
de  un rango de distribución sobre trayectorias futuras

1593
00:56:54,559 --> 00:56:55,440


1594
00:56:55,440 --> 00:56:59,040
en espacios de estado, por lo que existen varios enfoques

1595
00:56:59,040 --> 00:57:01,119
para aproximar la propagación de

1596
00:57:01,119 --> 00:57:02,559
trayectorias inciertas,

1597
00:57:02,559 --> 00:57:04,480
por ejemplo, uno puede ignorar la incertidumbre por

1598
00:57:04,480 --> 00:57:06,160
completo y propagar la media de la

1599
00:57:06,160 --> 00:57:07,280
distribución

1600
00:57:07,280 --> 00:57:09,440
o uno puede propagar explícitamente las

1601
00:57:09,440 --> 00:57:11,440
estadísticas completas de la distribución

1602
00:57:11,440 --> 00:57:13,680
para que sean una especie de  dos

1603
00:57:13,680 --> 00:57:15,839
enfoques extremos, uno de ellos es simplemente decir que sí

1604
00:57:15,839 --> 00:57:17,680
, el modelado de conjuntos está rastreando la media

1605
00:57:17,680 --> 00:57:19,200
, por lo que voy a seguir avanzando

1606
00:57:19,200 --> 00:57:19,920


1607
00:57:19,920 --> 00:57:22,160
y luego la alternativa es básicamente

1608
00:57:22,160 --> 00:57:23,359
mantener un resumen

1609
00:57:23,359 --> 00:57:25,359
de toda la distribución y usar eso

1610
00:57:25,359 --> 00:57:26,880
como lo que está aprendiendo  la

1611
00:57:26,880 --> 00:57:29,520
población

1612
00:57:29,520 --> 00:57:32,400
en el trabajo actual se utiliza un

1613
00:57:32,400 --> 00:57:33,359
enfoque de partículas

1614
00:57:33,359 --> 00:57:35,839
mediante el cual un monte carlo tan  esquema basado en muestreo las

1615
00:57:35,839 --> 00:57:36,960


1616
00:57:36,960 --> 00:57:39,680
muestras se propagan en particular

1617
00:57:39,680 --> 00:57:41,119
consideramos

1618
00:57:41,119 --> 00:57:43,680
esta gran b muestras de los

1619
00:57:43,680 --> 00:57:44,480


1620
00:57:44,480 --> 00:57:48,799
datos de distribución de parámetros que se extraen de los datos del cubo

1621
00:57:49,280 --> 00:57:52,960
estas secciones transmiten cómo se logra la información sobre la

1622
00:57:52,960 --> 00:57:54,480
selección de políticas

1623
00:57:54,480 --> 00:57:56,480
en el modelo y cómo

1624
00:57:56,480 --> 00:57:58,400
se explora el panorama de idoneidad de políticas

1625
00:57:58,400 --> 00:57:59,040
para

1626
00:57:59,040 --> 00:58:00,319
implementar  control predictivo en las

1627
00:58:00,319 --> 00:58:02,240
trayectorias, por lo que la

1628
00:58:02,240 --> 00:58:05,440
política a lo largo del tiempo implementada debe

1629
00:58:05,440 --> 00:58:06,720
involucrar algún elemento

1630
00:58:06,720 --> 00:58:10,480
de control predictivo, está bien,

1631
00:58:10,480 --> 00:58:14,079
luego está la sección um 3.5 3.6

1632
00:58:14,079 --> 00:58:17,200
entonces 3.5 tiene detalles sobre cómo calcular este

1633
00:58:17,200 --> 00:58:18,960


1634
00:58:18,960 --> 00:58:22,480
valor de energía libre esperado como el título podría sugerir

1635
00:58:22,480 --> 00:58:24,480
en esta sección describen cómo

1636
00:58:24,480 --> 00:58:25,599
evaluar  g negativa

1637
00:58:25,599 --> 00:58:29,520
para una política en la que han utilizado esta

1638
00:58:29,520 --> 00:58:31,760
conveniencia notacional para hablar sobre

1639
00:58:31,760 --> 00:58:33,200
políticas que avanzan,

1640
00:58:33,200 --> 00:58:36,720
así que simplemente lo hicieron como un pastel desnudo en

1641
00:58:36,720 --> 00:58:40,240
lugar de este superíndice superior que

1642
00:58:40,240 --> 00:58:43,440
tiene que ver con los estados de tiempo um y la

1643
00:58:43,440 --> 00:58:44,559
incertidumbre

1644
00:58:44,559 --> 00:58:47,599
y la energía libre negativa esperada

1645
00:58:47,599 --> 00:58:48,400
que es lo que

1646
00:58:48,400 --> 00:58:49,839
estamos tratando de obtener aquí con la

1647
00:58:49,839 --> 00:58:51,760
g negativa

1648
00:58:51,760 --> 00:58:54,880
es e  igual a la suma de estas

1649
00:58:54,880 --> 00:58:56,480
energías libres negativas esperadas a lo largo del

1650
00:58:56,480 --> 00:58:59,520
tiempo y luego ahí es

1651
00:58:59,520 --> 00:59:03,599
donde hay una descomposición que

1652
00:59:03,599 --> 00:59:06,720
no es mi área, pero

1653
00:59:06,720 --> 00:59:09,440
creo que lo que significa es que hay una

1654
00:59:09,440 --> 00:59:10,480
descomposición

1655
00:59:10,480 --> 00:59:13,760
en esta ganancia de juego de información de estado

1656
00:59:13,760 --> 00:59:16,640
y un componente de valor extrínseco, entonces

1657
00:59:16,640 --> 00:59:18,240
este tipo de se descompone en componentes de exploración

1658
00:59:18,240 --> 00:59:19,200
y explotación

1659
00:59:19,200 --> 00:59:21,920
o alguna otra compensación

1660
00:59:21,920 --> 00:59:22,960
vemos esto mucho

1661
00:59:22,960 --> 00:59:25,520
con este g negativo me encantaría si

1662
00:59:25,520 --> 00:59:26,799
alguien pudiera

1663
00:59:26,799 --> 00:59:29,040
hablar un poco por qué esto es o si

1664
00:59:29,040 --> 00:59:30,480
siempre es el caso

1665
00:59:30,480 --> 00:59:34,079
pero siempre  uh, parece presentarse como

1666
00:59:34,079 --> 00:59:36,480
precisión del modelo penalizada por la

1667
00:59:36,480 --> 00:59:37,359
complejidad del modelo o

1668
00:59:37,359 --> 00:59:40,640
esto más esto son siempre dos

1669
00:59:40,640 --> 00:59:42,640
partes en la ecuación ¿Alguna vez es solo

1670
00:59:42,640 --> 00:59:44,960
un término pueden ser tres términos

1671
00:59:44,960 --> 00:59:48,000
aquí son tres términos pero qué um

1672
00:59:48,000 --> 00:59:52,000
o cuatro así que no estoy exactamente  seguro

1673
00:59:52,000 --> 00:59:55,280
por qué a veces tiene más o menos términos,

1674
00:59:55,280 --> 00:59:58,319
pero eso es lo que tengo curiosidad,

1675
00:59:58,319 --> 01:00:01,119
entonces en 3.6 escriben el modelo

1676
01:00:01,119 --> 01:00:01,760
presentado

1677
01:00:01,760 --> 01:00:04,000
en las secciones anteriores sirve como la

1678
01:00:04,000 --> 01:00:06,079
formulación más general aplicable en

1679
01:00:06,079 --> 01:00:07,760
ambos parcialmente o  entornos observados y completamente

1680
01:00:07,760 --> 01:00:09,599
observados

1681
01:00:09,599 --> 01:00:11,200
a continuación, describimos una

1682
01:00:11,200 --> 01:00:13,119
implementación llena de

1683
01:00:13,119 --> 01:00:15,040
implementación fur para el caso completamente observado

1684
01:00:15,040 --> 01:00:16,880
dejando un análisis del

1685
01:00:16,880 --> 01:00:19,119
caso parcialmente observado para el trabajo futuro, por

1686
01:00:19,119 --> 01:00:21,680
lo que es solo otra envoltura alrededor del

1687
01:00:21,680 --> 01:00:23,040
caso completamente observado

1688
01:00:23,040 --> 01:00:26,160
para tener las observaciones parciales y

1689
01:00:26,160 --> 01:00:28,160
así  decidió usar algunos puntos de referencia

1690
01:00:28,160 --> 01:00:29,599
que les facilitaron

1691
01:00:29,599 --> 01:00:32,480
básicamente tener una observación total y

1692
01:00:32,480 --> 01:00:33,200
esto no es como

1693
01:00:33,200 --> 01:00:35,599
hacer trampa, los ejemplos que van a

1694
01:00:35,599 --> 01:00:36,240
describir

1695
01:00:36,240 --> 01:00:38,240
son como equilibrar un

1696
01:00:38,240 --> 01:00:39,440
plato de comida en un palo,

1697
01:00:39,440 --> 01:00:40,880
por lo que en ese caso tienes una

1698
01:00:40,880 --> 01:00:42,640
observación total del modelo.

1699
01:00:42,640 --> 01:00:45,440
así que solo porque no puede controlar,

1700
01:00:45,440 --> 01:00:46,079


1701
01:00:46,079 --> 01:00:47,760
bueno, puede o no ser posible dado un

1702
01:00:47,760 --> 01:00:49,119
cierto

1703
01:00:49,119 --> 01:00:52,079
tiempo de reflejo del palo y del motor, pero al

1704
01:00:52,079 --> 01:00:53,520
menos puede observar todo, por lo que

1705
01:00:53,520 --> 01:00:55,200
también hay problemas de teoría de control no observables

1706
01:00:55,200 --> 01:00:56,960
y luego hay algunos en los que el

1707
01:00:56,960 --> 01:00:58,160
sistema  en realidad es

1708
01:00:58,160 --> 01:01:00,160
comprensible y controlable como el

1709
01:01:00,160 --> 01:01:01,599
plato de la cena,

1710
01:01:01,599 --> 01:01:03,760
pero solo obtiene información distorsionada o maliciosa

1711
01:01:03,760 --> 01:01:04,640


1712
01:01:04,640 --> 01:01:06,319
.  otros en los que obtienes

1713
01:01:06,319 --> 01:01:08,000
información perfecta, pero solo en puntos de tiempo y

1714
01:01:08,000 --> 01:01:09,599
hay un juego en curso,

1715
01:01:09,599 --> 01:01:10,960
de muchas maneras diferentes en las que eso

1716
01:01:10,960 --> 01:01:12,640
puede desarrollarse, pero eso es

1717
01:01:12,640 --> 01:01:15,680
algo así como las partes del modelo

1718
01:01:15,680 --> 01:01:17,520
que pueden cambiarse

1719
01:01:17,520 --> 01:01:19,200
y eso es lo que también yo  creo que será

1720
01:01:19,200 --> 01:01:20,799
interesante escuchar a cualquiera de los

1721
01:01:20,799 --> 01:01:22,880
autores,

1722
01:01:22,880 --> 01:01:26,240
así que en la sección 4

1723
01:01:26,240 --> 01:01:28,799
realizan algunos experimentos y esta es una

1724
01:01:28,799 --> 01:01:29,760
especie de

1725
01:01:29,760 --> 01:01:32,720
fase de resultados de su artículo y

1726
01:01:32,720 --> 01:01:34,400
describen cómo investigan

1727
01:01:34,400 --> 01:01:37,280
si el

1728
01:01:37,280 --> 01:01:39,040
modelo de inferencia activa propuesto puede promover con éxito

1729
01:01:39,040 --> 01:01:41,200
exploración en ausencia de observaciones de recompensa

1730
01:01:41,200 --> 01:01:43,440
, es decir, exploración, así que eso es

1731
01:01:43,440 --> 01:01:45,119
lo que es realmente difícil para el modelo de

1732
01:01:45,119 --> 01:01:45,760


1733
01:01:45,760 --> 01:01:47,520
aprendices de refuerzo libre es

1734
01:01:47,520 --> 01:01:48,799
cuando no obtiene la

1735
01:01:48,799 --> 01:01:50,720
recompensa, no lo hace muy bien, no puede explorar

1736
01:01:50,720 --> 01:01:52,000
muy bien

1737
01:01:52,000 --> 01:01:54,960
porque no está ganando y dos si

1738
01:01:54,960 --> 01:01:56,799
el  el modelo puede lograr un buen rendimiento

1739
01:01:56,799 --> 01:01:58,319
y una alta eficiencia de la muestra en

1740
01:01:58,319 --> 01:02:00,559
tareas de control continuo desafiantes, es decir,

1741
01:02:00,559 --> 01:02:02,400
explotación, por lo que eso es lo que requiere el

1742
01:02:02,400 --> 01:02:04,240
seguimiento de algo  ing

1743
01:02:04,240 --> 01:02:06,079
evaluamos estos dos aspectos del

1744
01:02:06,079 --> 01:02:07,760
modelo por separado, dejando el análisis de

1745
01:02:07,760 --> 01:02:08,400
su

1746
01:02:08,400 --> 01:02:10,400
desempeño conjunto, es decir, el

1747
01:02:10,400 --> 01:02:12,000
dilema de explotación de exploración

1748
01:02:12,000 --> 01:02:14,319
para el trabajo futuro, así que nuevamente muéstrelo por

1749
01:02:14,319 --> 01:02:15,039
separado

1750
01:02:15,039 --> 01:02:17,440
en el tipo de caso de uso puro, muestre

1751
01:02:17,440 --> 01:02:18,480
que puede hacer cualquiera de los dos

1752
01:02:18,480 --> 01:02:20,079
y luego será algo así como  una

1753
01:02:20,079 --> 01:02:21,760
compensación entre los dos o una

1754
01:02:21,760 --> 01:02:23,680
capa envolvente que terminará mediando en

1755
01:02:23,680 --> 01:02:25,839
esta compensación, está

1756
01:02:25,839 --> 01:02:27,599
bien, la tarea de exploración que van

1757
01:02:27,599 --> 01:02:29,839
a hacer se llama carro de montaña

1758
01:02:29,839 --> 01:02:33,039
y eres un pequeño carro en el fondo de

1759
01:02:33,039 --> 01:02:34,079
este valle

1760
01:02:34,079 --> 01:02:37,200
y puede empujar hacia adelante con

1761
01:02:37,200 --> 01:02:40,480
el pedal de avance o puede

1762
01:02:40,480 --> 01:02:43,039
empujar hacia atrás con un pedal de marcha atrás

1763
01:02:43,039 --> 01:02:44,880
y no tiene un motor lo suficientemente fuerte

1764
01:02:44,880 --> 01:02:47,760
para llegar a la bandera amarilla con solo

1765
01:02:47,760 --> 01:02:48,000


1766
01:02:48,000 --> 01:02:50,160
un intento, es como si estuviera en la parte inferior de la

1767
01:02:50,160 --> 01:02:51,280
colina y estás en la

1768
01:02:51,280 --> 01:02:53,599
marcha tres siete en tu bicicleta, pero

1769
01:02:53,599 --> 01:02:55,280
puedes subir un poco y retroceder un

1770
01:02:55,280 --> 01:02:56,880
poco, así que aquí tienes que

1771
01:02:56,880 --> 01:02:58,640
explorar y encontrar una estrategia que

1772
01:02:58,640 --> 01:03:00,480
te ayude a explorar más y más

1773
01:03:00,480 --> 01:03:02,640
para poder  obtener suficiente velocidad por goi  subiendo

1774
01:03:02,640 --> 01:03:04,079
esta colina izquierda para obtener

1775
01:03:04,079 --> 01:03:07,359
un plano amarillo y luego las tareas de explotación de las

1776
01:03:07,359 --> 01:03:10,079
que van a estar hablando

1777
01:03:10,079 --> 01:03:11,119
son

1778
01:03:11,119 --> 01:03:12,960
dobles, está la tarea del péndulo invertido, así que

1779
01:03:12,960 --> 01:03:14,480
aquí todavía somos un carrito pequeño

1780
01:03:14,480 --> 01:03:17,119
o algo así y podemos

1781
01:03:17,119 --> 01:03:18,799
avanzar o retroceder en una pista

1782
01:03:18,799 --> 01:03:21,200
y luego está el péndulo que estamos

1783
01:03:21,200 --> 01:03:21,920
tratando de mantener en

1784
01:03:21,920 --> 01:03:23,599
posición vertical y eso es como el

1785
01:03:23,599 --> 01:03:25,520
plato de comida en un palo,

1786
01:03:25,520 --> 01:03:27,920
luego está la tarea de la tolva, que es una

1787
01:03:27,920 --> 01:03:29,119


1788
01:03:29,119 --> 01:03:32,400
tarea de coordinación motora de salto, así que veamos

1789
01:03:32,400 --> 01:03:33,920
lo que realmente hicieron  para cada uno de estos

1790
01:03:33,920 --> 01:03:34,240
dos

1791
01:03:34,240 --> 01:03:37,200
experimentos y luego ver cómo el

1792
01:03:37,200 --> 01:03:39,520
alumno de inferencia activa se comparó con

1793
01:03:39,520 --> 01:03:43,039
otros algoritmos, por lo que el ejemplo del automóvil de montaña

1794
01:03:43,039 --> 01:03:45,440
es una pista unidimensional ubicada

1795
01:03:45,440 --> 01:03:47,039
entre dos montañas, el

1796
01:03:47,039 --> 01:03:48,640
objetivo es subir la montaña a la

1797
01:03:48,640 --> 01:03:50,160
derecha, sin embargo, el motor del automóvil es  no es

1798
01:03:50,160 --> 01:03:51,520
lo suficientemente fuerte como para escalar la montaña en un

1799
01:03:51,520 --> 01:03:52,720
solo paso

1800
01:03:52,720 --> 01:03:55,359
similar a lo que establece la única forma de

1801
01:03:55,359 --> 01:03:56,880
tener éxito es conducir de un lado a otro para

1802
01:03:56,880 --> 01:03:58,799
generar impulso, así que lo bueno de

1803
01:03:58,799 --> 01:03:59,200


1804
01:03:59,200 --> 01:04:02,319
esto pensé que era eso  el

1805
01:04:02,319 --> 01:04:05,359
código estaba en el sitio de openai y en

1806
01:04:05,359 --> 01:04:07,280
su

1807
01:04:07,280 --> 01:04:10,880
enlace github.com está aquí, por lo que realmente se podía

1808
01:04:10,880 --> 01:04:13,520
ver, jugar y usar como un

1809
01:04:13,520 --> 01:04:14,160
estándar,

1810
01:04:14,160 --> 01:04:16,240
por lo que parece genial. No sabía

1811
01:04:16,240 --> 01:04:17,440
sobre este recurso

1812
01:04:17,440 --> 01:04:20,559
para estandarizar diferentes

1813
01:04:20,559 --> 01:04:21,760
algoritmos de aprendizaje,

1814
01:04:21,760 --> 01:04:25,039
así que  ¿Cómo le fue bien al agente de inferencia activo? Le

1815
01:04:25,039 --> 01:04:28,240
fue bien en esta prueba; de lo

1816
01:04:28,240 --> 01:04:29,839
contrario, no habrían

1817
01:04:29,839 --> 01:04:32,640
hecho el papel y la forma de leer estos

1818
01:04:32,640 --> 01:04:33,280
gráficos

1819
01:04:33,280 --> 01:04:35,119
um a b y c van a tener el mismo

1820
01:04:35,119 --> 01:04:36,880
eje x e y,

1821
01:04:36,880 --> 01:04:40,480
así que puse el mapa

1822
01:04:40,480 --> 01:04:43,520
con  el motor en la parte superior

1823
01:04:43,520 --> 01:04:46,480
izquierda, por lo que se mapea en el panel inferior

1824
01:04:46,480 --> 01:04:46,960
izquierdo

1825
01:04:46,960 --> 01:04:50,319
y, por lo tanto, la posición está relacionada

1826
01:04:50,319 --> 01:04:51,599
con el eje x

1827
01:04:51,599 --> 01:04:53,760
y así es qué tan lejos a la izquierda y

1828
01:04:53,760 --> 01:04:55,280
qué tan lejos a la derecha

1829
01:04:55,280 --> 01:04:57,839
va ese pequeño vagón de tren y luego  la

1830
01:04:57,839 --> 01:04:58,720
velocidad

1831
01:04:58,720 --> 01:05:01,359
es si está en reposo cero, si

1832
01:05:01,359 --> 01:05:03,200
se mueve positivamente hacia la derecha o

1833
01:05:03,200 --> 01:05:04,640
si se mueve negativamente hacia la

1834
01:05:04,640 --> 01:05:05,280
izquierda,

1835
01:05:05,280 --> 01:05:08,240
por lo que el agente de recompensa que simplemente

1836
01:05:08,240 --> 01:05:09,680
persigue el impulso de

1837
01:05:09,680 --> 01:05:13,680
cualquier manera, supongo que solo termina

1838
01:05:13,680 --> 01:05:16,400
obteniendo una velocidad máxima de alrededor de 0.02 en

1839
01:05:16,400 --> 01:05:17,039
cualquiera  camino

1840
01:05:17,039 --> 01:05:20,079
y th  es solo se mueve como .7 o algo

1841
01:05:20,079 --> 01:05:22,960
en cualquier dirección, el

1842
01:05:22,960 --> 01:05:25,599
agente codicioso de épsilon logra aprender una

1843
01:05:25,599 --> 01:05:26,880
política de corto alcance

1844
01:05:26,880 --> 01:05:29,760
que podemos ver lo lleva un poco

1845
01:05:29,760 --> 01:05:31,760
más hacia un lado

1846
01:05:31,760 --> 01:05:34,400
y toma algunas raras excursiones

1847
01:05:34,400 --> 01:05:34,960
a

1848
01:05:34,960 --> 01:05:37,760
regímenes de velocidad ligeramente más altos, pero en

1849
01:05:37,760 --> 01:05:38,880
al final, eh

1850
01:05:38,880 --> 01:05:41,440
, realmente no llega demasiado lejos como si

1851
01:05:41,440 --> 01:05:42,000


1852
01:05:42,000 --> 01:05:44,079
aprende a ir cuesta arriba cuando va cuesta arriba,

1853
01:05:44,079 --> 01:05:46,400
pero eso solo ayuda en una medida limitada,

1854
01:05:46,400 --> 01:05:48,799
mientras que el modelo de inferencia activa

1855
01:05:48,799 --> 01:05:49,599
implementado

1856
01:05:49,599 --> 01:05:52,480
no solo tiene una muestra más amplia

1857
01:05:52,480 --> 01:05:53,280
dentro del

1858
01:05:53,280 --> 01:05:55,760
espacio de estado de um  conversiones después de 100

1859
01:05:55,760 --> 01:05:56,960
épocas,

1860
01:05:56,960 --> 01:06:00,960
pero su posición se

1861
01:06:00,960 --> 01:06:03,760
extiende a un rango mucho más alto en x

1862
01:06:03,760 --> 01:06:04,000
y

1863
01:06:04,000 --> 01:06:06,079
también a un rango de distribución de velocidad más alto

1864
01:06:06,079 --> 01:06:07,599
en y,

1865
01:06:07,599 --> 01:06:10,640
por lo que fue más capaz de salir de esta

1866
01:06:10,640 --> 01:06:12,640
pequeña

1867
01:06:12,640 --> 01:06:14,559
zanja siendo un aprendiz de inferencia activo

1868
01:06:14,559 --> 01:06:15,839
que siendo

1869
01:06:15,839 --> 01:06:19,119
épsilon codicioso o simplemente  una especie de modelo

1870
01:06:19,119 --> 01:06:21,280
basado en la recompensa gratuita, de acuerdo,

1871
01:06:21,280 --> 01:06:25,520
el segundo

1872
01:06:25,520 --> 01:06:27,599
ejemplo de optimización presentado en el documento es este

1873
01:06:27,599 --> 01:06:29,440
hopper v2 nuevamente, no sabía sobre este

1874
01:06:29,440 --> 01:06:30,799
recurso,

1875
01:06:30,799 --> 01:06:34,160
por lo que este es interesante, es

1876
01:06:34,160 --> 01:06:36,799
descrito como hacer que un robot bidimensional con

1877
01:06:36,799 --> 01:06:37,839
una sola pierna

1878
01:06:37,839 --> 01:06:40,400
salte hacia adelante lo más rápido posible y el

1879
01:06:40,400 --> 01:06:42,079
código también está ahí.

1880
01:06:42,079 --> 01:06:43,520


1881
01:06:43,520 --> 01:06:45,599


1882
01:06:45,599 --> 01:06:47,359


1883
01:06:47,359 --> 01:06:50,960


1884
01:06:50,960 --> 01:06:52,799
hay tantos ángulos en esto primero,

1885
01:06:52,799 --> 01:06:54,000
solo esta imagen

1886
01:06:54,000 --> 01:06:57,039
con un tablero de ajedrez

1887
01:06:57,039 --> 01:07:00,079
, me recordó a algunos

1888
01:07:00,079 --> 01:07:03,200
simuladores de computación evolutiva

1889
01:07:03,200 --> 01:07:05,039
como para linux y cosas así donde

1890
01:07:05,039 --> 01:07:06,799
podrías tener estos extraterrestres en bloques que

1891
01:07:06,799 --> 01:07:08,000
se replicarían y

1892
01:07:08,000 --> 01:07:10,160
consumirían una tonelada de recursos computacionales

1893
01:07:10,160 --> 01:07:11,200
y simplemente

1894
01:07:11,200 --> 01:07:12,720
chocan entre sí y, a veces,

1895
01:07:12,720 --> 01:07:14,079
era solo el contorno, otras veces eran

1896
01:07:14,079 --> 01:07:16,000
bloques en 3D con este tipo de fondo

1897
01:07:16,000 --> 01:07:18,079
y un plano de planta,

1898
01:07:18,079 --> 01:07:20,640
pero aquí y lo que estamos evolucionando son

1899
01:07:20,640 --> 01:07:22,240
estrategias de control, no

1900
01:07:22,240 --> 01:07:24,960
cromosomas que representan genotipos o

1901
01:07:24,960 --> 01:07:25,920
, digamos,

1902
01:07:25,920 --> 01:07:28,000
pero en realidad  una similitud es esta idea

1903
01:07:28,000 --> 01:07:30,000
del algoritmo genético y la

1904
01:07:30,000 --> 01:07:30,640


1905
01:07:30,640 --> 01:07:33,119
búsqueda estocástica del algoritmo genético porque a veces la

1906
01:07:33,119 --> 01:07:34,559
forma en que se optimizan estas políticas de

1907
01:07:34,559 --> 01:07:35,520
control  ed

1908
01:07:35,520 --> 01:07:38,000
es en realidad a través de pasos que involucran

1909
01:07:38,000 --> 01:07:39,839
cosas como algoritmos de búsqueda genética

1910
01:07:39,839 --> 01:07:41,440
que cambian grandes conjuntos de sus

1911
01:07:41,440 --> 01:07:42,319
parámetros,

1912
01:07:42,319 --> 01:07:43,680
por lo que hay algunos

1913
01:07:43,680 --> 01:07:45,839
paralelismos interesantes y esto solo pensé que era un

1914
01:07:45,839 --> 01:07:47,039
ejemplo genial

1915
01:07:47,039 --> 01:07:49,599
y en la intersección del

1916
01:07:49,599 --> 01:07:50,240


1917
01:07:50,240 --> 01:07:53,280
control del comportamiento motor pero también

1918
01:07:53,280 --> 01:07:53,920


1919
01:07:53,920 --> 01:07:56,000
estimación del espacio de estado complejo  incluso los comienzos de un

1920
01:07:56,000 --> 01:07:57,200


1921
01:07:57,200 --> 01:07:59,119
enfoque inactivo uh y tal vez incluso incorporado

1922
01:07:59,119 --> 01:08:00,960
porque en algún nivel

1923
01:08:00,960 --> 01:08:03,760
de complejidad del movimiento va a estar

1924
01:08:03,760 --> 01:08:05,680
implícito en el sistema

1925
01:08:05,680 --> 01:08:07,680
y distribuido en él al igual que otros

1926
01:08:07,680 --> 01:08:09,920
sistemas que tiene alguna noción de sus

1927
01:08:09,920 --> 01:08:11,039
propias posibilidades

1928
01:08:11,039 --> 01:08:13,280
si tuviera 500 músculos y  era una

1929
01:08:13,280 --> 01:08:15,839
pierna humana, tendría algún tipo de

1930
01:08:15,839 --> 01:08:17,520
estructura de tensegridad que la mantuviera

1931
01:08:17,520 --> 01:08:19,198
equilibrada de una manera que facilitara

1932
01:08:19,198 --> 01:08:21,439
algunos tipos de acciones pero no otras,

1933
01:08:21,439 --> 01:08:22,719
una opción tan interesante que

1934
01:08:22,719 --> 01:08:25,839
me gustaría saber de

1935
01:08:25,839 --> 01:08:28,238
algún autor o de otras personas como

1936
01:08:28,238 --> 01:08:29,600
lo que son  otros

1937
01:08:29,600 --> 01:08:32,158
puntos de referencia que son geniales qué otros

1938
01:08:32,158 --> 01:08:32,960


1939
01:08:32,960 --> 01:08:35,198
problemas de sistemas de control son interesantes o

1940
01:08:35,198 --> 01:08:36,640
aplicables

1941
01:08:36,640 --> 01:08:39,520
qué pasa con las versiones sociales o de red

1942
01:08:39,520 --> 01:08:41,920
versiones trabajadas o basadas en la comunicación,

1943
01:08:41,920 --> 01:08:44,880
entonces, ¿cuáles fueron los resultados?

1944
01:08:45,198 --> 01:08:47,679
Está bien, así que aquí está cómo mirar estos

1945
01:08:47,679 --> 01:08:48,238
gráficos,

1946
01:08:48,238 --> 01:08:50,479
el eje x es la época, así que eso es solo

1947
01:08:50,479 --> 01:08:52,238
el muestreo a través del tiempo, así es como se prueban

1948
01:08:52,238 --> 01:08:52,719
muchas

1949
01:08:52,719 --> 01:08:55,439
generaciones de parámetros y

1950
01:08:55,439 --> 01:08:56,640
aquí las líneas rojas

1951
01:08:56,640 --> 01:08:59,920
indican lo mismo  intervalo de tiempo, por lo que

1952
01:08:59,920 --> 01:09:03,359
c y d están relacionados con las épocas 1 a

1953
01:09:03,359 --> 01:09:04,000
100

1954
01:09:04,000 --> 01:09:05,359
y eso en realidad está comprimido

1955
01:09:05,359 --> 01:09:07,520
contra um una

1956
01:09:07,520 --> 01:09:10,640
unidad uh muy pequeña en a y b y a

1957
01:09:10,640 --> 01:09:12,479
y c respectivamente son para este

1958
01:09:12,479 --> 01:09:13,839
péndulo invertido y um b

1959
01:09:13,839 --> 01:09:16,880
y d son para la tarea de la tolva  entonces podemos

1960
01:09:16,880 --> 01:09:18,640
hablar sobre los mismos fenómenos mirando

1961
01:09:18,640 --> 01:09:20,960
a y c en referencia al péndulo

1962
01:09:20,960 --> 01:09:24,238
y b y d en la tolva y en

1963
01:09:24,238 --> 01:09:25,600
ambos casos

1964
01:09:25,600 --> 01:09:28,399
acercando o alejando lo que es bastante

1965
01:09:28,399 --> 01:09:29,040
evidente

1966
01:09:29,040 --> 01:09:32,080
es que el acto y el eje y es  la recompensa,

1967
01:09:32,080 --> 01:09:33,120
así que

1968
01:09:33,120 --> 01:09:34,640
en la tarea de la tolva es qué tan lejos está

1969
01:09:34,640 --> 01:09:36,238
llegando y luego en la

1970
01:09:36,238 --> 01:09:37,439
tarea del péndulo invertido

1971
01:09:37,439 --> 01:09:40,560
se trata de, um, su tiempo mantenido dada

1972
01:09:40,560 --> 01:09:42,479
una cierta combinación de parámetros para la

1973
01:09:42,479 --> 01:09:46,158
política y en ambos casos

1974
01:09:46,158 --> 01:09:49,359
la recompensa aumenta considerablemente.

1975
01:09:49,359 --> 01:09:52,799
para el agente de inferencia activo y

1976
01:09:52,799 --> 01:09:56,320
también inmediatamente uh comienza a subir

1977
01:09:56,320 --> 01:09:57,520
después de un

1978
01:09:57,520 --> 01:10:00,480
muestreo dentro de los primeros 100 o incluso

1979
01:10:00,480 --> 01:10:01,679
los primeros uh

1980
01:10:01,679 --> 01:10:04,159
varias épocas probablemente debido al

1981
01:10:04,159 --> 01:10:05,760
espacio de estado más bajo

1982
01:10:05,760 --> 01:10:09,360
del carro uh porque todo lo que el carro puede

1983
01:10:09,360 --> 01:10:09,760
hacer

1984
01:10:09,760 --> 01:10:11,040
es moverse hacia adelante y hacia atrás tiene un

1985
01:10:11,040 --> 01:10:12,800
política sobre eso, como gasolina, descanso y

1986
01:10:12,800 --> 01:10:13,520
cosas

1987
01:10:13,520 --> 01:10:15,679
así, todo está cocinado en la física

1988
01:10:15,679 --> 01:10:16,880
del péndulo.

1989
01:10:16,880 --> 01:10:18,239
Me pregunto si hay una

1990
01:10:18,239 --> 01:10:20,000
tarea de volcado de doble péndulo invertido, por cierto, eso

1991
01:10:20,000 --> 01:10:21,600
sería algo interesante

1992
01:10:21,600 --> 01:10:23,440
y, en la tarea de la tolva, hay

1993
01:10:23,440 --> 01:10:25,440
varias más.  parámetros en

1994
01:10:25,440 --> 01:10:28,400
juego no copié el número exacto, pero

1995
01:10:28,400 --> 01:10:29,679
hay varios más, por

1996
01:10:29,679 --> 01:10:32,800
lo que toma un par de épocas más reflejadas

1997
01:10:32,800 --> 01:10:33,679
por el cero

1998
01:10:33,679 --> 01:10:36,880
a um tal vez 40 donde

1999
01:10:36,880 --> 01:10:38,719
el promedio es como no

2000
01:10:38,719 --> 01:10:40,560
despegar realmente y esto se

2001
01:10:40,560 --> 01:10:42,719
contrasta con el  ddpg, sobre el que

2002
01:10:42,719 --> 01:10:44,400
puede leer más, simplemente no voy

2003
01:10:44,400 --> 01:10:45,440
a entrar en qué es este

2004
01:10:45,440 --> 01:10:48,080
algoritmo, solo confié, está bien,

2005
01:10:48,080 --> 01:10:49,600
los autores usaron algo que tiene

2006
01:10:49,600 --> 01:10:50,480


2007
01:10:50,480 --> 01:10:53,679
sentido, escuchemos a cualquiera  e sobre qué otras

2008
01:10:53,679 --> 01:10:56,000
alternativas podrían probarse, por

2009
01:10:56,000 --> 01:10:57,280
lo que todas serían cosas en

2010
01:10:57,280 --> 01:10:59,280
las que no estoy

2011
01:10:59,280 --> 01:11:02,560
tan al tanto de la literatura, pero definitivamente

2012
01:11:02,560 --> 01:11:03,280
agradecería

2013
01:11:03,280 --> 01:11:05,040
los comentarios de alguien del

2014
01:11:05,040 --> 01:11:06,560
campo del aprendizaje automático y

2015
01:11:06,560 --> 01:11:08,400
lo que sería una demostración impresionante o útil

2016
01:11:08,400 --> 01:11:10,400
de inferencia activa  o

2017
01:11:10,400 --> 01:11:11,280
qué

2018
01:11:11,280 --> 01:11:15,280
significaría hacer una simulación de teoría de control

2019
01:11:15,280 --> 01:11:18,320
en este tipo de marco, qué más

2020
01:11:18,320 --> 01:11:20,000
se usó,

2021
01:11:20,000 --> 01:11:21,600
qué más es el estado actual

2022
01:11:21,600 --> 01:11:24,000
del arte para estas tareas de péndulo invertido y

2023
01:11:24,000 --> 01:11:24,560
tolva

2024
01:11:24,560 --> 01:11:27,920
, simplemente no lo sé,

2025
01:11:27,920 --> 01:11:32,159
pero sería genial.  si alguien lo sabe,

2026
01:11:32,159 --> 01:11:34,480
solo para cerrar la relación

2027
01:11:34,480 --> 01:11:36,400
con el trabajo anterior,

2028
01:11:36,400 --> 01:11:39,199
está bien, esto es de su sección de cierre, lo

2029
01:11:39,199 --> 01:11:40,960
que tal vez sea una

2030
01:11:40,960 --> 01:11:44,480
cuestión disciplinaria, pero a

2031
01:11:44,480 --> 01:11:46,800
menudo es como una sección de discusión, pero si tuviera una

2032
01:11:46,800 --> 01:11:48,320
relación con el trabajo anterior,

2033
01:11:48,320 --> 01:11:49,520
lo habría esperado.  ser un

2034
01:11:49,520 --> 01:11:51,280
poco más contextualizador

2035
01:11:51,280 --> 01:11:55,280
y al principio del documento,

2036
01:11:55,280 --> 01:11:57,520
pero se lee más como una discusión

2037
01:11:57,520 --> 01:11:58,320
relacionada con

2038
01:11:58,320 --> 01:12:00,400
la inferencia activa profunda que es así a

2039
01:12:00,400 --> 01:12:02,800
través del tiempo  de inferencia activa

2040
01:12:02,800 --> 01:12:05,040
escriben nuestro trabajo se basa en estos

2041
01:12:05,040 --> 01:12:06,800
modelos anteriores incorporando la

2042
01:12:06,800 --> 01:12:09,199
incertidumbre del modelo en su resolución activa

2043
01:12:09,199 --> 01:12:10,800
ampliamos los modelos de estimación puntual anteriores

2044
01:12:10,800 --> 01:12:12,560
para incluir distribuciones completas

2045
01:12:12,560 --> 01:12:14,480
sobre parámetros y actualizamos el

2046
01:12:14,480 --> 01:12:15,760
funcional de energía libre esperado de

2047
01:12:15,760 --> 01:12:17,679
modo que la incertidumbre en estas

2048
01:12:17,679 --> 01:12:19,840
distribuciones se minimice activamente

2049
01:12:19,840 --> 01:12:21,600
esto pone nuestra implementación en línea

2050
01:12:21,600 --> 01:12:23,199
con los modelos canónicos de

2051
01:12:23,199 --> 01:12:24,320
inferencia activa de la

2052
01:12:24,320 --> 01:12:26,400
literatura de neurociencia cognitiva y computacional,

2053
01:12:26,400 --> 01:12:29,120
por lo que es casi como decir sí, uno

2054
01:12:29,120 --> 01:12:29,679
más,

2055
01:12:29,679 --> 01:12:32,320
además, nos permite evaluar la

2056
01:12:32,320 --> 01:12:34,640
viabilidad de la exploración activa

2057
01:12:34,640 --> 01:12:36,239
bajo el marco de inferencia activa escalada

2058
01:12:36,239 --> 01:12:38,320
aplicar el modelo a

2059
01:12:38,320 --> 01:12:40,320
tareas de control más complejas

2060
01:12:40,320 --> 01:12:42,400
y obtener una mayor eficiencia de la muestra en

2061
01:12:42,400 --> 01:12:43,920
relación con los modelos anteriores,

2062
01:12:43,920 --> 01:12:45,840
por lo que es como decir que hemos hecho que

2063
01:12:45,840 --> 01:12:47,840
este modelo de inferencia activa se acerque más a

2064
01:12:47,840 --> 01:12:50,000
lo que se ha especulado que es

2065
01:12:50,000 --> 01:12:53,280
en el ámbito neuroconductual cualitativo, lo

2066
01:12:53,280 --> 01:12:55,360
cual creo que es una buena razón para estarlo

2067
01:12:55,360 --> 01:12:56,800
leyendo bien no  w

2068
01:12:56,800 --> 01:12:58,960
porque encaja muy bien con nuestras

2069
01:12:58,960 --> 01:13:01,280
discusiones sobre el comportamiento

2070
01:13:01,280 --> 01:13:04,320
y de, um,

2071
01:13:04,320 --> 01:13:07,679
neurobiología en las discusiones sobre ecología variacional,

2072
01:13:07,679 --> 01:13:10,560
así que esto está en el

2073
01:13:10,560 --> 01:13:13,280
lado de la simulación, cómo llega a ser de esta manera,

2074
01:13:13,280 --> 01:13:15,280
así que esto es genial porque

2075
01:13:15,280 --> 01:13:16,560
la inferencia activa profunda ahora se puede

2076
01:13:16,560 --> 01:13:17,440
implementar a

2077
01:13:17,440 --> 01:13:19,199
través de  este tipo de modelos que se

2078
01:13:19,199 --> 01:13:20,880
presentan en este documento

2079
01:13:20,880 --> 01:13:23,120
y anteriormente era como, oh sí, supongo que

2080
01:13:23,120 --> 01:13:25,199
si se tratara de una inferencia activa profunda, entonces

2081
01:13:25,199 --> 01:13:27,040
se acomodaría a las narrativas

2082
01:13:27,040 --> 01:13:28,640
y ahora este es el tipo de marco

2083
01:13:28,640 --> 01:13:30,400
en el que oh sí, bien, podríamos hablar sobre la

2084
01:13:30,400 --> 01:13:31,600
narrativa a través del tiempo

2085
01:13:31,600 --> 01:13:35,520
en  este marco podría ser la segunda

2086
01:13:35,520 --> 01:13:38,000
área que abordan nuevamente otra palabra clave

2087
01:13:38,000 --> 01:13:39,199
para el artículo

2088
01:13:39,199 --> 01:13:42,000
es aprendizaje por refuerzo basado en modelos en

2089
01:13:42,000 --> 01:13:42,960
el trabajo actual

2090
01:13:42,960 --> 01:13:45,120
optamos por redes neuronales bayesianas para

2091
01:13:45,120 --> 01:13:47,199
garantizar la coherencia con los

2092
01:13:47,199 --> 01:13:48,719
principios variacionales propugnados por el

2093
01:13:48,719 --> 01:13:49,679
marco de inferencia activa,

2094
01:13:49,679 --> 01:13:51,679
pero tenga en cuenta que los conjuntos pueden ser  hecho

2095
01:13:51,679 --> 01:13:53,360
explícitamente bayesiano con modificaciones menores,

2096
01:13:53,360 --> 01:13:54,480


2097
01:13:54,480 --> 01:13:57,920
por lo que hablaron de varias homologías

2098
01:13:57,920 --> 01:13:59,679
para reforzar  t el aprendizaje

2099
01:13:59,679 --> 01:14:01,840
y la inferencia específicamente amortizada

2100
01:14:01,840 --> 01:14:03,040
, en realidad hay una cita

2101
01:14:03,040 --> 01:14:06,159
que saqué de uno de los

2102
01:14:06,159 --> 01:14:07,520
documentos que están en la diapositiva y que

2103
01:14:07,520 --> 01:14:09,280
hablaba sobre

2104
01:14:09,280 --> 01:14:10,480
cómo podría tener la sensación de que esto es

2105
01:14:10,480 --> 01:14:13,040
como una situación de ganar gratis con solo

2106
01:14:13,040 --> 01:14:14,159
envolver un  funcional en

2107
01:14:14,159 --> 01:14:15,679
torno a la estimación de estos

2108
01:14:15,679 --> 01:14:17,600
parámetros porque es como, oh, es una

2109
01:14:17,600 --> 01:14:19,120
red neuronal, estoy implementando una

2110
01:14:19,120 --> 01:14:20,560
red neuronal, por lo que tengo un grado adicional

2111
01:14:20,560 --> 01:14:22,800
de libertad para aprender políticas no lineales,

2112
01:14:22,800 --> 01:14:26,000
pero luego el documento argumentó que en

2113
01:14:26,000 --> 01:14:28,800
realidad estás limitado porque el

2114
01:14:28,800 --> 01:14:30,400
funcional  está estimando

2115
01:14:30,400 --> 01:14:32,320
la media y la varianza en este

2116
01:14:32,320 --> 01:14:34,080
resultado gaussiano

2117
01:14:34,080 --> 01:14:37,520
y, por lo tanto, en realidad no libera un

2118
01:14:37,520 --> 01:14:41,920
grado de expresividad de salida

2119
01:14:41,920 --> 01:14:44,960
, sino

2120
01:14:44,960 --> 01:14:48,080
una forma definible y escalable de

2121
01:14:48,080 --> 01:14:48,640
implementar

2122
01:14:48,640 --> 01:14:51,120
en el hardware computacional actual una forma

2123
01:14:51,120 --> 01:14:52,560
de implementar este

2124
01:14:52,560 --> 01:14:54,719
enorme problema de lápiz y papel  de

2125
01:14:54,719 --> 01:14:56,159
estimar la media gaussiana y la

2126
01:14:56,159 --> 01:14:58,400
varianza de

2127
01:14:58,400 --> 01:15:00,640
espacios de estado de alta dimensión súper súper complejos, pero eso

2128
01:15:00,640 --> 01:15:02,239
sigue siendo lo que está haciendo, por lo que es

2129
01:15:02,239 --> 01:15:05,440
súper interesante  ting cosas y

2130
01:15:05,440 --> 01:15:09,520
um también la nota aquí de que los conjuntos

2131
01:15:09,520 --> 01:15:11,679
podrían ser explícitamente bayesianos, por lo que con

2132
01:15:11,679 --> 01:15:14,320
todos los tipos de variantes y sabores

2133
01:15:14,320 --> 01:15:16,320
que presenta,

2134
01:15:16,320 --> 01:15:19,360
cualquiera que sea un entusiasta o un

2135
01:15:19,360 --> 01:15:22,159
experto en estas áreas agradecería

2136
01:15:22,159 --> 01:15:23,199
su perspectiva

2137
01:15:23,199 --> 01:15:26,080
sobre lo que eso significa o por qué esto es

2138
01:15:26,080 --> 01:15:26,800
importante o

2139
01:15:26,800 --> 01:15:30,640
interesante entonces ganancia de información

2140
01:15:30,640 --> 01:15:34,400
y esta también fue una de las palabras clave, por lo que

2141
01:15:34,400 --> 01:15:36,960
identificar

2142
01:15:36,960 --> 01:15:38,719
estrategias de exploración escalables y eficientes sigue siendo una de

2143
01:15:38,719 --> 01:15:40,320
las preguntas abiertas clave en el

2144
01:15:40,320 --> 01:15:41,280
aprendizaje por refuerzo

2145
01:15:41,280 --> 01:15:43,440
métodos sin modelos como las

2146
01:15:43,440 --> 01:15:45,440
reglas de elección voraz o boltzmann

2147
01:15:45,440 --> 01:15:48,800
paginación dr proton sean  Utilizar

2148
01:15:48,800 --> 01:15:51,520
ruido en el proceso de selección de acciones o

2149
01:15:51,520 --> 01:15:52,960
incertidumbre en las

2150
01:15:52,960 --> 01:15:55,840
estadísticas de recompensa. Un enfoque más poderoso

2151
01:15:55,840 --> 01:15:57,280
es construir un modelo del mundo que le

2152
01:15:57,280 --> 01:15:58,800
permita al agente evaluar qué

2153
01:15:58,800 --> 01:16:00,400
partes del espacio de estado ha visitado y qué partes

2154
01:16:00,400 --> 01:16:01,440
no ha visitado.

2155
01:16:01,440 --> 01:16:02,960
Esto permite medidas como la

2156
01:16:02,960 --> 01:16:04,400
cantidad.  de error de predicción o predicción

2157
01:16:04,400 --> 01:16:04,640
o

2158
01:16:04,640 --> 01:16:05,920
mejora que se utilizará para la

2159
01:16:05,920 --> 01:16:08,159
exploración está bien genial

2160
01:16:08,159 --> 01:16:10,640
si el modelo de aprendizaje imp.  captura lícita o

2161
01:16:10,640 --> 01:16:12,320
explícitamente las

2162
01:16:12,320 --> 01:16:12,960
características probabilísticas,

2163
01:16:12,960 --> 01:16:14,880
por lo que son las regularidades estadísticas

2164
01:16:14,880 --> 01:16:16,239
de un nicho, luego

2165
01:16:16,239 --> 01:16:17,760
las medidas teóricas de la información se pueden

2166
01:16:17,760 --> 01:16:19,600
usar para guiar la exploración,

2167
01:16:19,600 --> 01:16:22,560
por lo que hay mucho que decir aquí y es

2168
01:16:22,560 --> 01:16:24,960
muy

2169
01:16:24,960 --> 01:16:27,360
interesante incorporar la ganancia de información al

2170
01:16:27,360 --> 01:16:28,239
final,

2171
01:16:28,239 --> 01:16:30,880
realmente lo que está diciendo es esto  modelo aprendido

2172
01:16:30,880 --> 01:16:31,840


2173
01:16:31,840 --> 01:16:34,560
de inferencia activa y la forma en que la

2174
01:16:34,560 --> 01:16:36,719
exploración está ligada al modelo generativo

2175
01:16:36,719 --> 01:16:38,400
del mundo de tal manera que la acción se

2176
01:16:38,400 --> 01:16:40,560
facilita no solo hacia la

2177
01:16:40,560 --> 01:16:42,480
gratificación directa que es una especie

2178
01:16:42,480 --> 01:16:44,719
de modelo libre rl

2179
01:16:44,719 --> 01:16:48,719
ni simplemente hacia la gratificación del modelo profundo um

2180
01:16:48,719 --> 01:16:51,520
que es como me encanta correr

2181
01:16:51,520 --> 01:16:53,679
maratones porque es saludable, no estoy

2182
01:16:53,679 --> 01:16:55,840
diciendo que no es saludable,

2183
01:16:55,840 --> 01:16:57,920
solo es la mentalidad lo que ayuda a uno a

2184
01:16:57,920 --> 01:17:03,600
llegar allí con seguridad y luego, um,

2185
01:17:03,600 --> 01:17:05,040
esto está diciendo que en realidad podemos ir a

2186
01:17:05,040 --> 01:17:06,640
otro nivel más allá de

2187
01:17:06,640 --> 01:17:10,159
eso, podemos decir con un modelo generativo profundo

2188
01:17:10,159 --> 01:17:11,040


2189
01:17:11,040 --> 01:17:13,679
de lo que  es probable que uno esté haciendo, podemos

2190
01:17:13,679 --> 01:17:15,040
maximizar la precisión,

2191
01:17:15,040 --> 01:17:16,800
que puede ser algo que escuche entre

2192
01:17:16,800 --> 01:17:19,199
los que conoce ultra ultr  un

2193
01:17:19,199 --> 01:17:22,800
um comprometido de un área algo como

2194
01:17:22,800 --> 01:17:26,080
esto es cómo y quién soy,

2195
01:17:26,080 --> 01:17:28,480
en ese sentido sería ir más allá de

2196
01:17:28,480 --> 01:17:30,000
todo esto, oh, bueno, esta cantidad de

2197
01:17:30,000 --> 01:17:31,920
millas por día es saludable para mí, lo cual es

2198
01:17:31,920 --> 01:17:33,840
una gran motivación,

2199
01:17:33,840 --> 01:17:36,480
podría ser un multi  -escala cosa um solo un

2200
01:17:36,480 --> 01:17:37,280
ejemplo

2201
01:17:37,280 --> 01:17:39,280
y definitivamente sé que sabes que incluso para

2202
01:17:39,280 --> 01:17:40,560
mí ha cambiado como a lo

2203
01:17:40,560 --> 01:17:42,880
largo de la vida, así que solo muestra cómo se

2204
01:17:42,880 --> 01:17:45,040
relaciona con tu nicho, tu contexto, tus

2205
01:17:45,040 --> 01:17:46,719
relaciones sociales,

2206
01:17:46,719 --> 01:17:49,840
muchas otras áreas y

2207
01:17:49,840 --> 01:17:51,679
solo para cerrar un pensamiento  en

2208
01:17:51,679 --> 01:17:54,400
esta información nuevamente,

2209
01:17:54,400 --> 01:17:57,360
um, la ganancia de información me sorprendió al

2210
01:17:57,360 --> 01:17:58,560
principio porque estaba tratando de

2211
01:17:58,560 --> 01:18:01,040
conectar todo esto con la teoría de la información

2212
01:18:01,040 --> 01:18:04,000
y me di cuenta de que de lo que se trata es de

2213
01:18:04,000 --> 01:18:05,760
reducir la incertidumbre sobre los

2214
01:18:05,760 --> 01:18:06,480
parámetros objetivo.

2215
01:18:06,480 --> 01:18:07,920


2216
01:18:07,920 --> 01:18:09,840


2217
01:18:09,840 --> 01:18:11,679


2218
01:18:11,679 --> 01:18:13,600
incertidumbre acerca de otra

2219
01:18:13,600 --> 01:18:16,400
cosa o más específicamente de que

2220
01:18:16,400 --> 01:18:18,480
otra cosa sea un modelo de múltiples escalas

2221
01:18:18,480 --> 01:18:20,400
que incluya algunos atributos con los que

2222
01:18:20,400 --> 01:18:22,080
probablemente estemos bastante familiarizados  Me gusta el

2223
01:18:22,080 --> 01:18:23,600
modelo de observación,

2224
01:18:23,600 --> 01:18:26,880
algunos aspectos que son homólogos a

2225
01:18:26,880 --> 01:18:30,880
un modelo de recompensa, como una especie de

2226
01:18:30,880 --> 01:18:33,280
modelo de preferencia, digamos, pero luego algunos

2227
01:18:33,280 --> 01:18:34,239
aspectos que son

2228
01:18:34,239 --> 01:18:37,280
principalmente nuevos y esa podría ser la

2229
01:18:37,280 --> 01:18:39,040
parte sobre la energía libre

2230
01:18:39,040 --> 01:18:42,800
y luego esa área como yo lo entiendo.

2231
01:18:42,800 --> 01:18:46,080
está relacionado con otro tipo de teoría de la

2232
01:18:46,080 --> 01:18:48,640
información y selección de modelos

2233
01:18:48,640 --> 01:18:51,280
y el marco variacional, por lo que si esa

2234
01:18:51,280 --> 01:18:52,159
es un área en la

2235
01:18:52,159 --> 01:18:55,360
que alguien tiene una idea,

2236
01:18:55,360 --> 01:18:57,120
creo que es genial, tal vez podríamos

2237
01:18:57,120 --> 01:18:58,640
intentar desempacar eso, no estoy

2238
01:18:58,640 --> 01:19:01,280
seguro de cómo se ve, pero definitivamente

2239
01:19:01,280 --> 01:19:02,400


2240
01:19:02,400 --> 01:19:04,960
algo sobre lo que me preguntaba y teniendo en cuenta

2241
01:19:04,960 --> 01:19:06,560
las p y las q, y

2242
01:19:06,560 --> 01:19:08,159
gracias a alec por un poco del

2243
01:19:08,159 --> 01:19:10,480
discurso del correo electrónico sobre aclarar algunos

2244
01:19:10,480 --> 01:19:11,520
aspectos del documento

2245
01:19:11,520 --> 01:19:15,199
porque, um, fue bastante interesante

2246
01:19:15,199 --> 01:19:16,159
y creo que hay muchas

2247
01:19:16,159 --> 01:19:18,719
implicaciones y qué sistemas podemos

2248
01:19:18,719 --> 01:19:21,520
aplicar.  esto para próximamente o en

2249
01:19:21,520 --> 01:19:22,480
el mediano plazo,

2250
01:19:22,480 --> 01:19:26,080
así que toneladas de cosas interesantes,

2251
01:19:26,080 --> 01:19:29,440
hablaremos de esto el 10 de noviembre de 2020

2252
01:19:29,440 --> 01:19:29,840
y

2253
01:19:29,840 --> 01:19:34,239
el 17 a las 7:30 a. m. hora del Pacífico

2254
01:19:34,239 --> 01:19:38,560
y creo que eso es todo y

2255
01:19:38,560 --> 01:19:43,600
veamos, sí, un pensamiento final,

2256
01:19:43,600 --> 01:19:45,280
todo lo que podemos tener es un modelo generativo profundo

2257
01:19:45,280 --> 01:19:46,960
del espacio entrelazado con la

2258
01:19:46,960 --> 01:19:47,679
acción, de

2259
01:19:47,679 --> 01:19:49,440
modo que los parámetros que exploramos sean

2260
01:19:49,440 --> 01:19:50,880
los que están en el equilibrio entre el

2261
01:19:50,880 --> 01:19:53,679
éxito y la información óptima. A

2262
01:19:53,679 --> 01:19:54,960
veces,

2263
01:19:54,960 --> 01:19:57,440
tememos virar hacia el éxito.  que puede

2264
01:19:57,440 --> 01:19:59,040
no ser óptimamente informativo

2265
01:19:59,040 --> 01:20:00,400
otras veces nos estamos informando

2266
01:20:00,400 --> 01:20:02,000
mucho de una manera que puede no tener

2267
01:20:02,000 --> 01:20:03,040
éxito,

2268
01:20:03,040 --> 01:20:04,880
pero en general manejamos bien esa compensación,

2269
01:20:04,880 --> 01:20:07,520
así es como hemos llegado hasta aquí, un

2270
01:20:07,520 --> 01:20:09,760
gran trabajo, muchas gracias a todos por

2271
01:20:09,760 --> 01:20:10,960
escuchar,

2272
01:20:10,960 --> 01:20:14,880
sigan así.  gracias por

2273
01:20:14,880 --> 01:20:17,280
participar, proporcionamos formularios de seguimiento para los

2274
01:20:17,280 --> 01:20:18,800
participantes en vivo

2275
01:20:18,800 --> 01:20:21,199
y sería increíble si alguien tuviera

2276
01:20:21,199 --> 01:20:21,840
comentarios,

2277
01:20:21,840 --> 01:20:25,120
sugerencias o

2278
01:20:25,120 --> 01:20:28,480
preguntas, puede mantenerse en comunicación con nosotros

2279
01:20:28,480 --> 01:20:31,679
y subir una diapositiva más sobre ese

2280
01:20:31,679 --> 01:20:34,159
truco de reparametrización de parámetros y

2281
01:20:34,159 --> 01:20:36,080
las diapositivas de ese papel pero

2282
01:20:36,080 --> 01:20:39,600
aparte de eso, gracias por escuchar

2283
01:20:39,600 --> 01:20:43,040
y por soportar el error anómalo de la

2284
01:20:43,040 --> 01:20:46,080
cámara, pero

2285
01:20:46,080 --> 01:20:48,520
sí, espero con ansias que llegue el final de

2286
01:20:48,520 --> 01:20:49,679


2287
01:20:49,679 --> 01:20:51,440
2020  Con todas estas interesantes

2288
01:20:51,440 --> 01:20:53,280
discusiones que tendremos,

2289
01:20:53,280 --> 01:20:55,280
nos encantaría tener nuevos participantes en

2290
01:20:55,280 --> 01:20:56,560
línea

2291
01:20:56,560 --> 01:20:59,040
o aportar nuevas perspectivas que

2292
01:20:59,040 --> 01:21:00,239
no hemos considerado

2293
01:21:00,239 --> 01:21:02,960
o hablar sobre ello desde la

2294
01:21:02,960 --> 01:21:03,920
perspectiva

2295
01:21:03,920 --> 01:21:06,639
de un principiante desde cualquier número de campos como punto de

2296
01:21:06,639 --> 01:21:07,120
partida.

2297
01:21:07,120 --> 01:21:09,040
solo háganos saber que ese es el tipo de

2298
01:21:09,040 --> 01:21:10,560
cosas

2299
01:21:10,560 --> 01:21:13,679
que siempre apreciamos escuchar, así que

2300
01:21:13,679 --> 01:21:17,679
tenga un buen mes de noviembre y el final de la

2301
01:21:17,679 --> 01:21:21,120
temporada 2020 y esperamos

2302
01:21:21,120 --> 01:21:26,880
hablar con usted, adiós

