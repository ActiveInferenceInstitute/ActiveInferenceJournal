1
00:00:07,359 --> 00:00:08,000
hello

2
00:00:08,000 --> 00:00:10,320
and welcome everyone to the active

3
00:00:10,320 --> 00:00:11,840
inference live stream

4
00:00:11,840 --> 00:00:14,880
this is act imp stream 8.1

5
00:00:14,880 --> 00:00:19,199
it is november 10 2020

6
00:00:19,199 --> 00:00:22,400
welcome to teamcom everyone we are an

7
00:00:22,400 --> 00:00:24,800
experiment in online team communication

8
00:00:24,800 --> 00:00:26,960
learning and practice related to active

9
00:00:26,960 --> 00:00:28,000
inference

10
00:00:28,000 --> 00:00:30,519
you can find us at our website

11
00:00:30,519 --> 00:00:32,079
activeinference.org

12
00:00:32,079 --> 00:00:35,680
you can find us at our twitter at email

13
00:00:35,680 --> 00:00:38,640
our public key base team or on youtube

14
00:00:38,640 --> 00:00:39,040
this

15
00:00:39,040 --> 00:00:41,040
is a recorded and an archived live

16
00:00:41,040 --> 00:00:42,559
stream so please provide us with

17
00:00:42,559 --> 00:00:43,120
feedback

18
00:00:43,120 --> 00:00:45,840
so that we can improve our work all

19
00:00:45,840 --> 00:00:47,840
backgrounds and perspectives are

20
00:00:47,840 --> 00:00:49,760
welcome here and as far as video

21
00:00:49,760 --> 00:00:52,320
etiquette for live streams go

22
00:00:52,320 --> 00:00:53,680
mute yourself if there's noise in your

23
00:00:53,680 --> 00:00:55,920
background raise your hands so that we

24
00:00:55,920 --> 00:00:58,160
can hear from everybody on the stack and

25
00:00:58,160 --> 00:01:01,199
use respectful speech behavior etcetera

26
00:01:01,199 --> 00:01:04,239
today we are excitingly in act image

27
00:01:04,239 --> 00:01:06,000
stream 8.1

28
00:01:06,000 --> 00:01:07,680
and it's going to go a little something

29
00:01:07,680 --> 00:01:09,680
like this we're going to start with some

30
00:01:09,680 --> 00:01:11,119
intros and warm-ups

31
00:01:11,119 --> 00:01:12,640
and then we'll get to the sections of

32
00:01:12,640 --> 00:01:14,159
8.1

33
00:01:14,159 --> 00:01:17,119
in 8.1 as well as 8.2 we're going to be

34
00:01:17,119 --> 00:01:19,200
discussing the paper scaling active

35
00:01:19,200 --> 00:01:20,000
inference by

36
00:01:20,000 --> 00:01:23,040
chance at all in 2019 thanks to blue for

37
00:01:23,040 --> 00:01:24,880
the suggestion of the paper

38
00:01:24,880 --> 00:01:27,200
we're gonna go through the goals the

39
00:01:27,200 --> 00:01:29,200
abstract and the roadmap

40
00:01:29,200 --> 00:01:31,600
and then we'll have a little notation

41
00:01:31,600 --> 00:01:32,400
and math

42
00:01:32,400 --> 00:01:35,119
overview we'll also take a look at the

43
00:01:35,119 --> 00:01:37,439
figures with a special focus on

44
00:01:37,439 --> 00:01:39,360
what each figure is showing or

45
00:01:39,360 --> 00:01:42,000
representing or invoking

46
00:01:42,000 --> 00:01:45,119
in today's discussion 8.1 and

47
00:01:45,119 --> 00:01:47,040
next week's discussion 8.2 we're going

48
00:01:47,040 --> 00:01:48,799
to be discussing this same paper

49
00:01:48,799 --> 00:01:50,799
so save and submit your questions and

50
00:01:50,799 --> 00:01:52,000
also get in touch

51
00:01:52,000 --> 00:01:54,320
with us if you want to participate for

52
00:01:54,320 --> 00:01:56,000
the rest of 2020 we're going to be

53
00:01:56,000 --> 00:01:56,799
discussing

54
00:01:56,799 --> 00:01:59,520
this paper 8 as well as 9 10 and 11

55
00:01:59,520 --> 00:02:01,119
which you can learn more about by

56
00:02:01,119 --> 00:02:02,399
checking our twitter

57
00:02:02,399 --> 00:02:04,960
so check it out there all right here we

58
00:02:04,960 --> 00:02:06,640
are in the intros

59
00:02:06,640 --> 00:02:10,080
welcome again shannon i'll kick out

60
00:02:10,080 --> 00:02:13,360
other so for the introductions

61
00:02:13,360 --> 00:02:14,239
we'll go around

62
00:02:14,239 --> 00:02:16,400
and just introduce yourself and your

63
00:02:16,400 --> 00:02:17,280
location

64
00:02:17,280 --> 00:02:20,080
and we'll uh roll with it as people gain

65
00:02:20,080 --> 00:02:20,800
and uh

66
00:02:20,800 --> 00:02:23,280
lose the chat so just say hello in a

67
00:02:23,280 --> 00:02:24,239
short introduction

68
00:02:24,239 --> 00:02:26,560
and then pass it to somebody else i'm

69
00:02:26,560 --> 00:02:28,640
daniel i'm in california

70
00:02:28,640 --> 00:02:32,239
and i will pass it to blue

71
00:02:32,239 --> 00:02:35,440
hi i'm blue and i am in southern new

72
00:02:35,440 --> 00:02:36,000
mexico

73
00:02:36,000 --> 00:02:39,519
in las cruces and i will pass it to

74
00:02:39,519 --> 00:02:41,920
sasha

75
00:02:43,599 --> 00:02:46,959
hi i'm sasha i'm also in california

76
00:02:46,959 --> 00:02:51,840
and i will pass it to yvonne

77
00:02:52,239 --> 00:02:55,280
hello my name is ivan i'm

78
00:02:55,280 --> 00:02:57,920
in moscow russia and i pass it to

79
00:02:57,920 --> 00:02:59,840
alejandra

80
00:02:59,840 --> 00:03:02,080
i think she disappeared for a second so

81
00:03:02,080 --> 00:03:03,280
let's go to alex

82
00:03:03,280 --> 00:03:05,840
okay

83
00:03:06,400 --> 00:03:09,840
hello i'm alex i'm also in moscow russia

84
00:03:09,840 --> 00:03:13,040
so welcome everybody

85
00:03:13,040 --> 00:03:16,000
cool and alejandra has been on before so

86
00:03:16,000 --> 00:03:17,920
hopefully we know her but when she jumps

87
00:03:17,920 --> 00:03:18,480
back in

88
00:03:18,480 --> 00:03:21,519
we can hear from her so for these

89
00:03:21,519 --> 00:03:23,440
warm-up questions and also it's pretty

90
00:03:23,440 --> 00:03:26,239
cool to have a slightly smaller panel so

91
00:03:26,239 --> 00:03:27,840
i'm really looking forward to hearing

92
00:03:27,840 --> 00:03:29,280
everyone's perspective

93
00:03:29,280 --> 00:03:30,959
on what they got out of the paper what

94
00:03:30,959 --> 00:03:32,480
they brought to the paper

95
00:03:32,480 --> 00:03:34,720
it'll be really cool to hear about so

96
00:03:34,720 --> 00:03:35,760
the first question

97
00:03:35,760 --> 00:03:38,560
is what made you excited to read this

98
00:03:38,560 --> 00:03:39,360
paper

99
00:03:39,360 --> 00:03:42,959
and or to learn about these topics

100
00:03:42,959 --> 00:03:45,440
so while people are raising their hand

101
00:03:45,440 --> 00:03:46,959
and feel free to do so

102
00:03:46,959 --> 00:03:49,120
something that initially made me excited

103
00:03:49,120 --> 00:03:50,799
to read this paper was just about

104
00:03:50,799 --> 00:03:52,319
learning how active inference could be

105
00:03:52,319 --> 00:03:53,920
applied to the kinds of problems that

106
00:03:53,920 --> 00:03:55,599
people apply other machine learning

107
00:03:55,599 --> 00:03:56,720
algorithms to

108
00:03:56,720 --> 00:04:01,680
so that's a starting point blue

109
00:04:01,680 --> 00:04:04,879
so i pitched this paper i um hadn't like

110
00:04:04,879 --> 00:04:06,480
thoroughly

111
00:04:06,480 --> 00:04:08,799
like digested it when i when i picked it

112
00:04:08,799 --> 00:04:09,680
i had read

113
00:04:09,680 --> 00:04:12,720
um the first author's other paper in

114
00:04:12,720 --> 00:04:14,720
class computational biology but like

115
00:04:14,720 --> 00:04:16,160
applying um

116
00:04:16,160 --> 00:04:17,839
like agent-based models and like

117
00:04:17,839 --> 00:04:19,199
modeling parameters

118
00:04:19,199 --> 00:04:22,400
to uh active inference was was like

119
00:04:22,400 --> 00:04:24,160
really what intrigued me and

120
00:04:24,160 --> 00:04:27,040
the um this paper i especially liked

121
00:04:27,040 --> 00:04:28,960
because of the ability to apply it in a

122
00:04:28,960 --> 00:04:31,199
continuous framework as a as opposed to

123
00:04:31,199 --> 00:04:31,840
like something

124
00:04:31,840 --> 00:04:33,520
in discrete time steps and i thought

125
00:04:33,520 --> 00:04:35,040
that that's that was significant and

126
00:04:35,040 --> 00:04:36,960
important

127
00:04:36,960 --> 00:04:39,040
cool welcome alejandra do you want to

128
00:04:39,040 --> 00:04:41,199
just give your quick intro and say hi up

129
00:04:41,199 --> 00:04:44,000
never mind uh anyone else want to add

130
00:04:44,000 --> 00:04:46,240
something that made them excited to

131
00:04:46,240 --> 00:04:47,919
learn about this topic or read about the

132
00:04:47,919 --> 00:04:50,240
paper

133
00:04:51,360 --> 00:04:52,960
yeah thanks again for the suggestion

134
00:04:52,960 --> 00:04:54,720
blue the second question

135
00:04:54,720 --> 00:04:57,919
is what is your experience or background

136
00:04:57,919 --> 00:04:58,880
with computers

137
00:04:58,880 --> 00:05:01,840
slash computational modeling and what is

138
00:05:01,840 --> 00:05:02,560
something

139
00:05:02,560 --> 00:05:04,560
interesting that you've been learning

140
00:05:04,560 --> 00:05:07,440
about or studying recently in the area

141
00:05:07,440 --> 00:05:09,600
and i think that my goal with this

142
00:05:09,600 --> 00:05:11,600
question was to

143
00:05:11,600 --> 00:05:14,880
show to our listener viewers

144
00:05:14,880 --> 00:05:16,800
that there's many computational

145
00:05:16,800 --> 00:05:18,479
backgrounds that intersect

146
00:05:18,479 --> 00:05:20,720
in active inference so it's a community

147
00:05:20,720 --> 00:05:21,840
that includes some

148
00:05:21,840 --> 00:05:23,840
people who are really on the cutting

149
00:05:23,840 --> 00:05:26,000
edge of the computational modeling

150
00:05:26,000 --> 00:05:28,080
and that's what we see reflected in this

151
00:05:28,080 --> 00:05:29,520
paper so

152
00:05:29,520 --> 00:05:31,919
big props to everybody who is reading

153
00:05:31,919 --> 00:05:34,000
and talking about it because it is

154
00:05:34,000 --> 00:05:35,600
at the cutting edge of that type of

155
00:05:35,600 --> 00:05:37,680
machine learning research but also

156
00:05:37,680 --> 00:05:39,800
there's this deep tradition of

157
00:05:39,800 --> 00:05:41,360
action-oriented research

158
00:05:41,360 --> 00:05:43,440
and embodied cognition and so many other

159
00:05:43,440 --> 00:05:44,960
areas that

160
00:05:44,960 --> 00:05:47,600
might not necessarily entail a

161
00:05:47,600 --> 00:05:49,360
computational background or even a

162
00:05:49,360 --> 00:05:51,039
computational approach in how they're

163
00:05:51,039 --> 00:05:51,759
studied

164
00:05:51,759 --> 00:05:53,759
until this type of intersectional

165
00:05:53,759 --> 00:05:55,360
research so

166
00:05:55,360 --> 00:05:58,240
does anyone want to just something that

167
00:05:58,240 --> 00:05:59,280
they've been learning about

168
00:05:59,280 --> 00:06:01,840
in computers or what type of computer

169
00:06:01,840 --> 00:06:04,639
modeling have they had experience with

170
00:06:04,639 --> 00:06:08,160
so i can start a lot of my computer

171
00:06:08,160 --> 00:06:10,960
work had been in bioinformatics which

172
00:06:10,960 --> 00:06:12,639
does deal with computers but it's very

173
00:06:12,639 --> 00:06:14,000
different kinds of

174
00:06:14,000 --> 00:06:16,080
questions than the machine learning

175
00:06:16,080 --> 00:06:18,319
community however increasingly there's

176
00:06:18,319 --> 00:06:20,000
application of machine learning

177
00:06:20,000 --> 00:06:22,240
to bioinformatics so this was just kind

178
00:06:22,240 --> 00:06:23,680
of like a different perspective

179
00:06:23,680 --> 00:06:25,919
on machine learning outside of the

180
00:06:25,919 --> 00:06:28,240
biological context that i had mainly

181
00:06:28,240 --> 00:06:30,800
seen it in

182
00:06:31,919 --> 00:06:33,600
and i'll just throw up the third

183
00:06:33,600 --> 00:06:35,039
question in case anyone wants to

184
00:06:35,039 --> 00:06:37,199
answer that one which is what kinds of

185
00:06:37,199 --> 00:06:38,240
problems might

186
00:06:38,240 --> 00:06:40,319
machine learning based upon active

187
00:06:40,319 --> 00:06:41,280
inference be

188
00:06:41,280 --> 00:06:43,919
applied to so you can just raise your

189
00:06:43,919 --> 00:06:44,880
hand if you

190
00:06:44,880 --> 00:06:48,639
yep go ahead sasha

191
00:06:48,639 --> 00:06:51,120
yeah i would say i guess to some of all

192
00:06:51,120 --> 00:06:52,800
these questions is a very limited

193
00:06:52,800 --> 00:06:55,039
experience in working with computers

194
00:06:55,039 --> 00:06:57,759
uh but my background is in neuroscience

195
00:06:57,759 --> 00:06:59,360
and i'm always curious

196
00:06:59,360 --> 00:07:02,880
to um learn what

197
00:07:02,880 --> 00:07:06,639
uh machine learning um has to offer

198
00:07:06,639 --> 00:07:08,319
for understanding the process of

199
00:07:08,319 --> 00:07:11,440
learning and how that can link back to

200
00:07:11,440 --> 00:07:14,479
neurobiology concepts um and

201
00:07:14,479 --> 00:07:16,800
so i'm interested in understanding these

202
00:07:16,800 --> 00:07:17,599
equations

203
00:07:17,599 --> 00:07:20,800
and having uh a better grasp on

204
00:07:20,800 --> 00:07:23,840
um what the relationships are like

205
00:07:23,840 --> 00:07:26,319
cool because learning is really a

206
00:07:26,319 --> 00:07:28,240
biologically inspired

207
00:07:28,240 --> 00:07:30,479
topic it's based upon learning in

208
00:07:30,479 --> 00:07:32,720
organisms or the kind of control that

209
00:07:32,720 --> 00:07:34,479
organisms enact in their environment

210
00:07:34,479 --> 00:07:36,960
and that's not even getting into the

211
00:07:36,960 --> 00:07:38,720
whole neural network

212
00:07:38,720 --> 00:07:42,240
slash actual brain debacle so definitely

213
00:07:42,240 --> 00:07:44,479
these kinds of learning questions any

214
00:07:44,479 --> 00:07:45,919
other thoughts on

215
00:07:45,919 --> 00:07:48,400
this one

216
00:07:50,319 --> 00:07:52,639
blue

217
00:07:53,680 --> 00:07:56,160
so like you my background is like

218
00:07:56,160 --> 00:07:58,080
bioinformatics but i've like branched

219
00:07:58,080 --> 00:07:58,400
out

220
00:07:58,400 --> 00:08:00,000
since like getting out of my doctoral

221
00:08:00,000 --> 00:08:01,759
research into like

222
00:08:01,759 --> 00:08:03,039
doing all kinds of different

223
00:08:03,039 --> 00:08:05,520
computational and agent-based

224
00:08:05,520 --> 00:08:08,160
modeling type applications even quantum

225
00:08:08,160 --> 00:08:10,160
computing a little bit

226
00:08:10,160 --> 00:08:13,680
this system particularly um

227
00:08:13,680 --> 00:08:15,599
interests me because like sasha i'm

228
00:08:15,599 --> 00:08:17,039
interested in learning like how things

229
00:08:17,039 --> 00:08:17,759
learn

230
00:08:17,759 --> 00:08:20,000
but also like from the beyond brain

231
00:08:20,000 --> 00:08:20,800
perspective

232
00:08:20,800 --> 00:08:23,280
like stay in biology but think about

233
00:08:23,280 --> 00:08:24,879
biological systems

234
00:08:24,879 --> 00:08:27,120
just at a very simple level like slime

235
00:08:27,120 --> 00:08:28,479
modes or something like this

236
00:08:28,479 --> 00:08:30,560
how do these systems learn right because

237
00:08:30,560 --> 00:08:32,159
still there's some element of learning

238
00:08:32,159 --> 00:08:34,000
that happens and when you can kind of

239
00:08:34,000 --> 00:08:37,200
deconstruct it into like a computational

240
00:08:37,200 --> 00:08:40,000
like model then you can start to like

241
00:08:40,000 --> 00:08:40,719
recognize

242
00:08:40,719 --> 00:08:43,279
input output into simpler biological

243
00:08:43,279 --> 00:08:46,720
systems beyond the brain

244
00:08:47,200 --> 00:08:49,240
cool and let's return to that

245
00:08:49,240 --> 00:08:50,640
multi-scale

246
00:08:50,640 --> 00:08:54,080
cognition when we're a little bit later

247
00:08:54,080 --> 00:08:55,920
on but i wrote that down so we can

248
00:08:55,920 --> 00:08:57,519
definitely return there any last

249
00:08:57,519 --> 00:08:59,440
thoughts on the warm-ups before we get

250
00:08:59,440 --> 00:09:01,920
into the paper

251
00:09:01,920 --> 00:09:05,360
cool all right so today we are going to

252
00:09:05,360 --> 00:09:07,440
be talking about this scaling active

253
00:09:07,440 --> 00:09:09,200
inference paper which is an archive

254
00:09:09,200 --> 00:09:10,320
paper

255
00:09:10,320 --> 00:09:13,440
and the paper presents its goal as

256
00:09:13,440 --> 00:09:16,399
or what it does as we present a model of

257
00:09:16,399 --> 00:09:18,080
active inference that is applicable in

258
00:09:18,080 --> 00:09:20,160
high dimensional control tasks with both

259
00:09:20,160 --> 00:09:22,320
continuous states and actions

260
00:09:22,320 --> 00:09:24,240
our model builds upon previous attempts

261
00:09:24,240 --> 00:09:26,080
to scale active inference by including

262
00:09:26,080 --> 00:09:27,760
an efficient planning algorithm

263
00:09:27,760 --> 00:09:29,519
as well as the quantification and active

264
00:09:29,519 --> 00:09:32,000
resolution of model uncertainty

265
00:09:32,000 --> 00:09:33,279
our model makes two primary

266
00:09:33,279 --> 00:09:35,040
contributions first

267
00:09:35,040 --> 00:09:36,880
we showed that the full active inference

268
00:09:36,880 --> 00:09:38,720
construct can be scaled to the kinds of

269
00:09:38,720 --> 00:09:40,640
tasks considered in the reinforcement

270
00:09:40,640 --> 00:09:41,839
learning literature

271
00:09:41,839 --> 00:09:43,839
this involved extending previous models

272
00:09:43,839 --> 00:09:45,519
of deep active inference to include

273
00:09:45,519 --> 00:09:47,360
model uncertainty and expected

274
00:09:47,360 --> 00:09:48,880
information gain

275
00:09:48,880 --> 00:09:50,640
second we highlighted the overlap

276
00:09:50,640 --> 00:09:52,080
between active inference and

277
00:09:52,080 --> 00:09:52,959
state-of-the-art

278
00:09:52,959 --> 00:09:54,959
approaches to model-based reinforcement

279
00:09:54,959 --> 00:09:57,279
learning welcome back alejandra

280
00:09:57,279 --> 00:10:00,399
and some of these topics were introduced

281
00:10:00,399 --> 00:10:01,200
or at least

282
00:10:01,200 --> 00:10:03,839
initially brought up in the act in

283
00:10:03,839 --> 00:10:06,000
stream 8.0 so if you're

284
00:10:06,000 --> 00:10:08,240
a little bit just unsure what is model

285
00:10:08,240 --> 00:10:09,920
based versus non-model based

286
00:10:09,920 --> 00:10:11,279
reinforcement learning or

287
00:10:11,279 --> 00:10:13,200
what is reinforcement learning or what

288
00:10:13,200 --> 00:10:14,640
is machine learning it's all

289
00:10:14,640 --> 00:10:16,880
good there's kind of a sequence of ideas

290
00:10:16,880 --> 00:10:18,399
that you can follow to understand

291
00:10:18,399 --> 00:10:20,880
why this paper is so exciting and just

292
00:10:20,880 --> 00:10:23,040
go to active stream 8.0 if you're

293
00:10:23,040 --> 00:10:25,760
curious the way that we can phrase what

294
00:10:25,760 --> 00:10:27,920
the big goal or question of the paper is

295
00:10:27,920 --> 00:10:30,640
in terms of non-active inference

296
00:10:30,640 --> 00:10:31,680
vocabulary

297
00:10:31,680 --> 00:10:33,760
would be how can we apply active

298
00:10:33,760 --> 00:10:36,320
inference to challenging control tasks

299
00:10:36,320 --> 00:10:38,240
and like blue mentioned these are the

300
00:10:38,240 --> 00:10:40,720
ones that often involve continuous

301
00:10:40,720 --> 00:10:42,160
decisions being made

302
00:10:42,160 --> 00:10:45,200
so like turning up a dial um or down or

303
00:10:45,200 --> 00:10:46,079
steering wheel

304
00:10:46,079 --> 00:10:47,760
rather than like chess or checkers or

305
00:10:47,760 --> 00:10:50,720
connect four or the mario kart example

306
00:10:50,720 --> 00:10:53,040
which now i will never forget and then

307
00:10:53,040 --> 00:10:54,320
how to connect these

308
00:10:54,320 --> 00:10:56,640
continuous challenging control tasks

309
00:10:56,640 --> 00:10:58,640
which have elements of planning and all

310
00:10:58,640 --> 00:11:00,160
these other things happening

311
00:11:00,160 --> 00:11:02,320
and connect these tasks formally to

312
00:11:02,320 --> 00:11:04,880
reinforcement learning

313
00:11:04,880 --> 00:11:06,720
any thoughts or questions on the goal of

314
00:11:06,720 --> 00:11:08,560
the paper

315
00:11:08,560 --> 00:11:10,959
cool so the abstract which we'll just

316
00:11:10,959 --> 00:11:11,760
run through

317
00:11:11,760 --> 00:11:15,120
is in reinforcement learning rl agents

318
00:11:15,120 --> 00:11:16,720
operate in partially observed and

319
00:11:16,720 --> 00:11:18,399
uncertain environments

320
00:11:18,399 --> 00:11:20,560
isn't that the truth model based

321
00:11:20,560 --> 00:11:22,399
reinforcement learning suggests that

322
00:11:22,399 --> 00:11:24,640
this control of these partially observed

323
00:11:24,640 --> 00:11:25,760
and uncertain environments

324
00:11:25,760 --> 00:11:27,680
is best achieved by learning and

325
00:11:27,680 --> 00:11:29,680
exploiting a probabilistic model of the

326
00:11:29,680 --> 00:11:30,399
world

327
00:11:30,399 --> 00:11:32,720
so just to be clear this is what

328
00:11:32,720 --> 00:11:34,640
traditional model-based reinforcement

329
00:11:34,640 --> 00:11:35,519
learning is

330
00:11:35,519 --> 00:11:38,079
model-free or unsupervised reinforcement

331
00:11:38,079 --> 00:11:39,920
learning would be learning the very very

332
00:11:39,920 --> 00:11:41,920
direct relationships between outcomes

333
00:11:41,920 --> 00:11:42,800
like reward

334
00:11:42,800 --> 00:11:44,720
and states model-based reinforcement

335
00:11:44,720 --> 00:11:46,560
learning abstracts a little bit above

336
00:11:46,560 --> 00:11:47,040
that

337
00:11:47,040 --> 00:11:49,279
and it considers how learning occurs on

338
00:11:49,279 --> 00:11:51,760
a probabilistic model of the world

339
00:11:51,760 --> 00:11:53,680
active inference is an emerging

340
00:11:53,680 --> 00:11:55,040
normative framework

341
00:11:55,040 --> 00:11:56,399
in cognitive and computational

342
00:11:56,399 --> 00:11:58,399
neuroscience that offers a unifying

343
00:11:58,399 --> 00:12:00,880
account of how biological agents achieve

344
00:12:00,880 --> 00:12:02,560
this control

345
00:12:02,560 --> 00:12:05,200
in this framework inference learning and

346
00:12:05,200 --> 00:12:05,760
action

347
00:12:05,760 --> 00:12:08,000
emerge from a single imperative that

348
00:12:08,000 --> 00:12:09,360
maximizes the bayesian

349
00:12:09,360 --> 00:12:12,240
evidence for a niched model of the world

350
00:12:12,240 --> 00:12:13,440
and so

351
00:12:13,440 --> 00:12:15,279
learning inference and action are all

352
00:12:15,279 --> 00:12:16,800
part of the organisms

353
00:12:16,800 --> 00:12:18,240
generative model and we're going to see

354
00:12:18,240 --> 00:12:20,160
how that gets specified and how it plays

355
00:12:20,160 --> 00:12:21,839
out

356
00:12:21,839 --> 00:12:24,480
the challenge is that implementations of

357
00:12:24,480 --> 00:12:26,639
this process this integration between

358
00:12:26,639 --> 00:12:28,800
inference and action if you will have

359
00:12:28,800 --> 00:12:30,560
thus far been restricted to low

360
00:12:30,560 --> 00:12:32,800
dimensional and idealized situations

361
00:12:32,800 --> 00:12:35,040
so this could be for example playing a

362
00:12:35,040 --> 00:12:36,399
very simple game

363
00:12:36,399 --> 00:12:39,440
or doing a two by two matrix like a

364
00:12:39,440 --> 00:12:41,600
prisoner's dilemma or there are other

365
00:12:41,600 --> 00:12:43,279
cases where active inference has been

366
00:12:43,279 --> 00:12:43,760
used

367
00:12:43,760 --> 00:12:45,920
for slightly higher dimensional but

368
00:12:45,920 --> 00:12:48,079
still quite idealized situations like

369
00:12:48,079 --> 00:12:50,959
reading from a known set of options

370
00:12:50,959 --> 00:12:53,279
here we present a working implementation

371
00:12:53,279 --> 00:12:54,399
of active inference

372
00:12:54,399 --> 00:12:56,320
that applies to higher dimensional tasks

373
00:12:56,320 --> 00:12:58,000
with proof of principle results

374
00:12:58,000 --> 00:13:00,240
demonstrating efficient exploration and

375
00:13:00,240 --> 00:13:01,519
an order of magnitude

376
00:13:01,519 --> 00:13:03,519
increase in sample efficiency over

377
00:13:03,519 --> 00:13:05,600
strong model-free baselines

378
00:13:05,600 --> 00:13:07,440
so just by reading that we can look

379
00:13:07,440 --> 00:13:09,120
forward to some improvements

380
00:13:09,120 --> 00:13:11,839
on classical algorithms and as far as

381
00:13:11,839 --> 00:13:12,399
this

382
00:13:12,399 --> 00:13:14,639
magnitude increasing sample efficiency

383
00:13:14,639 --> 00:13:16,320
the reason why they're focused on sample

384
00:13:16,320 --> 00:13:16,959
efficiency

385
00:13:16,959 --> 00:13:19,200
is because these distributions that we

386
00:13:19,200 --> 00:13:20,079
want to understand

387
00:13:20,079 --> 00:13:22,720
the shape of are not just like a simple

388
00:13:22,720 --> 00:13:23,519
curve

389
00:13:23,519 --> 00:13:25,360
there's a lot of dimensions to them and

390
00:13:25,360 --> 00:13:27,600
they're very rugged so small changes can

391
00:13:27,600 --> 00:13:28,639
change your height

392
00:13:28,639 --> 00:13:31,040
so to speak quite a lot which means that

393
00:13:31,040 --> 00:13:32,160
the challenge

394
00:13:32,160 --> 00:13:34,720
is to sample effectively not get trapped

395
00:13:34,720 --> 00:13:36,880
in one area or not to over sample one

396
00:13:36,880 --> 00:13:40,000
region at the cost of another

397
00:13:40,000 --> 00:13:41,920
our results demonstrate the feasibility

398
00:13:41,920 --> 00:13:44,160
of applying active inference at scale

399
00:13:44,160 --> 00:13:46,480
and highlight the operational homologies

400
00:13:46,480 --> 00:13:48,160
between active inference and current

401
00:13:48,160 --> 00:13:50,160
model based approaches to reinforcement

402
00:13:50,160 --> 00:13:51,360
learning so

403
00:13:51,360 --> 00:13:52,959
what would be the implications of that

404
00:13:52,959 --> 00:13:54,720
well it'd be pretty epic

405
00:13:54,720 --> 00:13:57,279
if all of the hype and buzz that we hear

406
00:13:57,279 --> 00:13:57,760
about

407
00:13:57,760 --> 00:13:59,360
machine learning or reinforcement

408
00:13:59,360 --> 00:14:01,360
learning or all the places where we know

409
00:14:01,360 --> 00:14:02,000
reinforcement

410
00:14:02,000 --> 00:14:04,320
learning gets applied ranging from

411
00:14:04,320 --> 00:14:06,160
recommendation algorithms to

412
00:14:06,160 --> 00:14:08,959
maps to just all these types of things

413
00:14:08,959 --> 00:14:09,760
could

414
00:14:09,760 --> 00:14:11,680
active inference play a role in that and

415
00:14:11,680 --> 00:14:13,279
what what would that do for our

416
00:14:13,279 --> 00:14:14,160
conception

417
00:14:14,160 --> 00:14:16,480
of these kinds of algorithms and there's

418
00:14:16,480 --> 00:14:17,920
probably a lot of directions to take

419
00:14:17,920 --> 00:14:18,480
that but

420
00:14:18,480 --> 00:14:20,800
that's the equivalence is if there is a

421
00:14:20,800 --> 00:14:21,680
homology

422
00:14:21,680 --> 00:14:24,240
and potentially even a superiority of

423
00:14:24,240 --> 00:14:25,839
active inference techniques in certain

424
00:14:25,839 --> 00:14:27,839
cases over reinforcement learning

425
00:14:27,839 --> 00:14:29,519
then it liberates us from some of the

426
00:14:29,519 --> 00:14:31,680
baggage of the straightforward model

427
00:14:31,680 --> 00:14:32,399
based

428
00:14:32,399 --> 00:14:34,079
reinforcement learning or the critiques

429
00:14:34,079 --> 00:14:36,160
of reinforcement learning but also opens

430
00:14:36,160 --> 00:14:38,160
the door to some new ways to implement

431
00:14:38,160 --> 00:14:39,839
strategies and understand the systems

432
00:14:39,839 --> 00:14:41,839
that we're working with

433
00:14:41,839 --> 00:14:44,959
cool so the paper has a

434
00:14:44,959 --> 00:14:47,839
pretty clear road map this is like

435
00:14:47,839 --> 00:14:48,560
driving

436
00:14:48,560 --> 00:14:52,160
on highway 10 in new mexico and there's

437
00:14:52,160 --> 00:14:55,440
a introduction section uh the

438
00:14:55,440 --> 00:14:57,760
relationship to further work is actually

439
00:14:57,760 --> 00:14:59,600
section 5 which we'll get to in a second

440
00:14:59,600 --> 00:15:01,760
but the paper begins with an

441
00:15:01,760 --> 00:15:04,000
introduction and a consideration

442
00:15:04,000 --> 00:15:07,440
of active inference as a topic

443
00:15:07,440 --> 00:15:09,920
it then moves directly to the model and

444
00:15:09,920 --> 00:15:11,120
lays it out

445
00:15:11,120 --> 00:15:15,600
in the six subsections 3.1 through 3.6

446
00:15:15,600 --> 00:15:17,440
from a mathematical perspective we're

447
00:15:17,440 --> 00:15:19,600
going to be focusing primarily on

448
00:15:19,600 --> 00:15:23,120
one two and three because those are the

449
00:15:23,120 --> 00:15:24,399
parts that we've

450
00:15:24,399 --> 00:15:26,000
heard the most about and they're the

451
00:15:26,000 --> 00:15:28,160
most relatable so the generative model

452
00:15:28,160 --> 00:15:30,320
and the recognition distribution are the

453
00:15:30,320 --> 00:15:31,360
p and the q

454
00:15:31,360 --> 00:15:33,199
mind your p's and q's and this is

455
00:15:33,199 --> 00:15:34,959
everything that we've been talking about

456
00:15:34,959 --> 00:15:37,120
with the two directions between the

457
00:15:37,120 --> 00:15:38,480
agent and the world

458
00:15:38,480 --> 00:15:40,079
and the weather we think about that in

459
00:15:40,079 --> 00:15:42,079
the bayesian structural computationalist

460
00:15:42,079 --> 00:15:43,519
perspective or the inactivist

461
00:15:43,519 --> 00:15:44,399
perspective

462
00:15:44,399 --> 00:15:46,240
the whole tale of two densities

463
00:15:46,240 --> 00:15:48,639
integrating internalism and externalism

464
00:15:48,639 --> 00:15:50,720
all these things come together in 3.1

465
00:15:50,720 --> 00:15:51,680
3.2

466
00:15:51,680 --> 00:15:53,040
learning and inference is where we're

467
00:15:53,040 --> 00:15:54,800
going to draw the

468
00:15:54,800 --> 00:15:57,120
bow together with reinforcement learning

469
00:15:57,120 --> 00:15:58,480
and about other machine learning

470
00:15:58,480 --> 00:15:59,440
algorithms

471
00:15:59,440 --> 00:16:01,680
3.3 is where we're going to come closer

472
00:16:01,680 --> 00:16:03,040
to control theory

473
00:16:03,040 --> 00:16:04,320
because we're going to be talking about

474
00:16:04,320 --> 00:16:06,160
setting policies for action

475
00:16:06,160 --> 00:16:10,160
then 3.456 hopefully when alec is here

476
00:16:10,160 --> 00:16:12,720
next week we'll have a little bit uh

477
00:16:12,720 --> 00:16:13,759
more detail there

478
00:16:13,759 --> 00:16:16,480
maybe we could even see a simulation or

479
00:16:16,480 --> 00:16:17,759
hear about some of the degrees of

480
00:16:17,759 --> 00:16:18,320
freedom

481
00:16:18,320 --> 00:16:20,240
that the authors had in the model why

482
00:16:20,240 --> 00:16:22,399
they chose to do what they did

483
00:16:22,399 --> 00:16:24,959
the part that will be very cool as an

484
00:16:24,959 --> 00:16:26,240
experimental biologist

485
00:16:26,240 --> 00:16:28,880
is the experimental section and here

486
00:16:28,880 --> 00:16:30,399
it's an interesting approach

487
00:16:30,399 --> 00:16:33,519
to do one set of tasks that conveys

488
00:16:33,519 --> 00:16:35,920
exploration of a state space and another

489
00:16:35,920 --> 00:16:37,920
set of tasks that conveys exploitation

490
00:16:37,920 --> 00:16:38,880
so they're saying like

491
00:16:38,880 --> 00:16:40,639
this model has two hands you know it's

492
00:16:40,639 --> 00:16:42,240
good at exploring but it's good at

493
00:16:42,240 --> 00:16:43,920
exploiting as well

494
00:16:43,920 --> 00:16:45,839
then there's the connection to previous

495
00:16:45,839 --> 00:16:47,839
work and the three areas that they

496
00:16:47,839 --> 00:16:49,440
tie it most directly to with the

497
00:16:49,440 --> 00:16:51,360
keywords as well as in this closing

498
00:16:51,360 --> 00:16:52,079
section

499
00:16:52,079 --> 00:16:54,480
are related to deep active inference

500
00:16:54,480 --> 00:16:56,160
which in contrast to

501
00:16:56,160 --> 00:16:58,399
i guess shallow active inference would

502
00:16:58,399 --> 00:17:00,160
mean that you're not just minimizing

503
00:17:00,160 --> 00:17:02,079
your surprise about your instantaneous

504
00:17:02,079 --> 00:17:02,880
sensory

505
00:17:02,880 --> 00:17:05,199
information but you have a deep or a

506
00:17:05,199 --> 00:17:06,720
counter factual model that goes through

507
00:17:06,720 --> 00:17:08,480
time so that's like the example of

508
00:17:08,480 --> 00:17:10,079
taking a jacket even though you're not

509
00:17:10,079 --> 00:17:12,240
cold yet that's deep active inference

510
00:17:12,240 --> 00:17:14,000
you're reducing your surprise about

511
00:17:14,000 --> 00:17:16,000
future states of your temperature

512
00:17:16,000 --> 00:17:17,599
under a generative model where if you go

513
00:17:17,599 --> 00:17:18,959
outside and it's cold you're going to

514
00:17:18,959 --> 00:17:19,599
get cold

515
00:17:19,599 --> 00:17:21,119
but shallow active inference would be

516
00:17:21,119 --> 00:17:22,799
like you wouldn't put on the jacket or

517
00:17:22,799 --> 00:17:24,160
you wouldn't even take it with you

518
00:17:24,160 --> 00:17:25,599
because it wouldn't be a relevant

519
00:17:25,599 --> 00:17:27,839
affordance in the one second time frame

520
00:17:27,839 --> 00:17:29,440
but it actually is relevant in the one

521
00:17:29,440 --> 00:17:30,960
second time frame under a deep

522
00:17:30,960 --> 00:17:32,960
degenerative model of temperature

523
00:17:32,960 --> 00:17:34,559
the second to our model-based

524
00:17:34,559 --> 00:17:35,760
reinforcement learning which we've

525
00:17:35,760 --> 00:17:37,600
mentioned a few times and information

526
00:17:37,600 --> 00:17:38,320
gain

527
00:17:38,320 --> 00:17:40,720
information is reduction of uncertainty

528
00:17:40,720 --> 00:17:42,559
and when we're reducing our uncertainty

529
00:17:42,559 --> 00:17:44,320
about environmental causes

530
00:17:44,320 --> 00:17:46,799
it helps us plan better actions but we

531
00:17:46,799 --> 00:17:48,480
also need to reduce our uncertainty

532
00:17:48,480 --> 00:17:50,160
about which actions to take

533
00:17:50,160 --> 00:17:52,080
and that's called policy and that's what

534
00:17:52,080 --> 00:17:54,400
link relates us here to control theory

535
00:17:54,400 --> 00:17:57,360
then there's a discussion and conclusion

536
00:17:57,360 --> 00:17:58,400
okay before we

537
00:17:58,400 --> 00:18:01,120
jump into the math and the actual

538
00:18:01,120 --> 00:18:02,640
sections are there any

539
00:18:02,640 --> 00:18:06,320
thoughts or questions on the roadmap

540
00:18:09,520 --> 00:18:13,039
all right here is a partial

541
00:18:13,039 --> 00:18:16,640
notation reference and i just separated

542
00:18:16,640 --> 00:18:18,240
them onto two sides

543
00:18:18,240 --> 00:18:19,919
and so if you're only going to look at a

544
00:18:19,919 --> 00:18:21,440
few parameters

545
00:18:21,440 --> 00:18:23,360
if your parameter overload hits in at

546
00:18:23,360 --> 00:18:25,520
six the ones on the left are the

547
00:18:25,520 --> 00:18:26,480
important ones

548
00:18:26,480 --> 00:18:27,760
these are the ones that will help you

549
00:18:27,760 --> 00:18:29,840
get eighty percent of what is happening

550
00:18:29,840 --> 00:18:30,720
and then the next

551
00:18:30,720 --> 00:18:32,400
ten percent are the ones on the right

552
00:18:32,400 --> 00:18:33,919
and then there's a few other ones which

553
00:18:33,919 --> 00:18:35,360
aren't on this page that are

554
00:18:35,360 --> 00:18:37,280
more like the esoteric statistical

555
00:18:37,280 --> 00:18:38,480
parameters

556
00:18:38,480 --> 00:18:41,440
the big parameter is s with a hat just

557
00:18:41,440 --> 00:18:42,080
like sasha

558
00:18:42,080 --> 00:18:44,640
with a hat and that's the true state of

559
00:18:44,640 --> 00:18:45,679
the environment

560
00:18:45,679 --> 00:18:47,760
so s with a hat is what is actually

561
00:18:47,760 --> 00:18:49,360
trying to be predicted

562
00:18:49,360 --> 00:18:51,120
and that's like the actual temperature

563
00:18:51,120 --> 00:18:52,960
of the environment or the actual amount

564
00:18:52,960 --> 00:18:54,000
of sunlight

565
00:18:54,000 --> 00:18:56,559
but that's not what the agent is able to

566
00:18:56,559 --> 00:18:57,760
track directly

567
00:18:57,760 --> 00:18:59,760
it's able to make an estimate of the

568
00:18:59,760 --> 00:19:01,120
environmental state

569
00:19:01,120 --> 00:19:02,720
and you can imagine there's times where

570
00:19:02,720 --> 00:19:04,240
that's an easy estimate to make there's

571
00:19:04,240 --> 00:19:06,320
times where it's a hard estimate to make

572
00:19:06,320 --> 00:19:08,080
and then this is the difference between

573
00:19:08,080 --> 00:19:09,600
the discrete and the continuous case

574
00:19:09,600 --> 00:19:10,320
would be

575
00:19:10,320 --> 00:19:12,160
if the state that you're estimating is

576
00:19:12,160 --> 00:19:14,080
isn't day or night it's a zero or one

577
00:19:14,080 --> 00:19:15,919
that's a discrete case a continuous case

578
00:19:15,919 --> 00:19:17,440
would be like what is the

579
00:19:17,440 --> 00:19:19,520
amount of light and that's a continuous

580
00:19:19,520 --> 00:19:21,200
variable so there's a lot more options a

581
00:19:21,200 --> 00:19:21,840
lot more

582
00:19:21,840 --> 00:19:24,640
shades of gray infinite of them that's s

583
00:19:24,640 --> 00:19:27,039
is the agent's internal ongoing

584
00:19:27,039 --> 00:19:28,799
estimate of this environmental state

585
00:19:28,799 --> 00:19:30,160
that it's trying to track

586
00:19:30,160 --> 00:19:31,760
and we can think about it with just one

587
00:19:31,760 --> 00:19:33,840
s or there could be multiple s's like

588
00:19:33,840 --> 00:19:36,320
is it humid or is it dry that's one axis

589
00:19:36,320 --> 00:19:38,240
another one is it light or dark

590
00:19:38,240 --> 00:19:40,799
o are the observations so in the case of

591
00:19:40,799 --> 00:19:42,240
light being estimated

592
00:19:42,240 --> 00:19:44,559
that would be like the observations of

593
00:19:44,559 --> 00:19:45,840
light on the retina

594
00:19:45,840 --> 00:19:47,440
in the case of temperature it's like a

595
00:19:47,440 --> 00:19:49,360
thermometer reading

596
00:19:49,360 --> 00:19:53,120
a are the policy actions by the agent

597
00:19:53,120 --> 00:19:56,480
and those are arising from pi

598
00:19:56,480 --> 00:20:00,320
which is a policy and a policy is like

599
00:20:00,320 --> 00:20:02,720
a layer above action so for example

600
00:20:02,720 --> 00:20:03,840
action would be

601
00:20:03,840 --> 00:20:06,799
moving my left foot my policy would be

602
00:20:06,799 --> 00:20:09,039
if i hear this sound then i move my left

603
00:20:09,039 --> 00:20:09,600
foot

604
00:20:09,600 --> 00:20:11,760
another policy would be i always move my

605
00:20:11,760 --> 00:20:12,799
left foot

606
00:20:12,799 --> 00:20:14,000
and so there's different kinds of

607
00:20:14,000 --> 00:20:16,240
policies that can be very nuanced they

608
00:20:16,240 --> 00:20:17,280
can be conditional

609
00:20:17,280 --> 00:20:18,799
they can be related to each other or

610
00:20:18,799 --> 00:20:20,240
they can be very straightforward and

611
00:20:20,240 --> 00:20:21,760
stand alone

612
00:20:21,760 --> 00:20:24,400
t with italics is the time steps of the

613
00:20:24,400 --> 00:20:25,760
model so this is just a

614
00:20:25,760 --> 00:20:27,360
modeling parameter that's going to come

615
00:20:27,360 --> 00:20:29,760
up again and again and it has to do with

616
00:20:29,760 --> 00:20:32,000
how time is measured in terms of epochs

617
00:20:32,000 --> 00:20:34,480
or states or continually okay then just

618
00:20:34,480 --> 00:20:35,440
to the right side

619
00:20:35,440 --> 00:20:37,919
we have little and big theta and a

620
00:20:37,919 --> 00:20:38,720
little theta

621
00:20:38,720 --> 00:20:41,280
is often used just to mean a parameter

622
00:20:41,280 --> 00:20:42,640
of the generative model

623
00:20:42,640 --> 00:20:44,720
and the bigger theta is like the space

624
00:20:44,720 --> 00:20:45,919
of all the parameters

625
00:20:45,919 --> 00:20:48,799
so those are kind of used similarly then

626
00:20:48,799 --> 00:20:49,679
lambda

627
00:20:49,679 --> 00:20:50,960
is related to the likelihood

628
00:20:50,960 --> 00:20:52,720
distribution it relates some of the

629
00:20:52,720 --> 00:20:54,320
statistical parameters

630
00:20:54,320 --> 00:20:57,679
and then f is the free energy and

631
00:20:57,679 --> 00:21:00,480
this represents like if you could be on

632
00:21:00,480 --> 00:21:00,880
this

633
00:21:00,880 --> 00:21:03,440
super smooth variational optimization

634
00:21:03,440 --> 00:21:04,559
landscape

635
00:21:04,559 --> 00:21:06,960
just with just as if you would really

636
00:21:06,960 --> 00:21:07,919
want to be following

637
00:21:07,919 --> 00:21:10,799
s hat but you actually have to follow s

638
00:21:10,799 --> 00:21:12,080
with free energy

639
00:21:12,080 --> 00:21:15,200
if we could be following f then we'd be

640
00:21:15,200 --> 00:21:16,960
doing perfectly you just strictly cannot

641
00:21:16,960 --> 00:21:18,400
do any better than that

642
00:21:18,400 --> 00:21:20,880
however we can't directly track f so we

643
00:21:20,880 --> 00:21:21,600
have to track

644
00:21:21,600 --> 00:21:23,760
g which is the expectation of free

645
00:21:23,760 --> 00:21:25,280
energy which we'll also

646
00:21:25,280 --> 00:21:28,799
be able to look at okay any

647
00:21:28,799 --> 00:21:31,360
thoughts or questions on notation anyone

648
00:21:31,360 --> 00:21:33,679
seeing similar notation to

649
00:21:33,679 --> 00:21:36,159
another field or a difference is there

650
00:21:36,159 --> 00:21:37,600
something that we want to

651
00:21:37,600 --> 00:21:39,280
that you'd imagine that a control theory

652
00:21:39,280 --> 00:21:45,840
model would have that isn't in here

653
00:21:46,559 --> 00:21:48,559
all right anyone can just raise their

654
00:21:48,559 --> 00:21:50,400
hand at any time i'm not sure where

655
00:21:50,400 --> 00:21:54,400
several of our colleagues have gone to

656
00:21:54,559 --> 00:21:56,880
let's start by thinking about the

657
00:21:56,880 --> 00:21:57,600
generative

658
00:21:57,600 --> 00:22:01,039
model so this is a generative model p

659
00:22:01,039 --> 00:22:03,760
of a bunch of variables and this is

660
00:22:03,760 --> 00:22:04,640
going to be

661
00:22:04,640 --> 00:22:07,679
kind of like what the organism is slash

662
00:22:07,679 --> 00:22:10,240
does we're going to leave for a second

663
00:22:10,240 --> 00:22:11,440
some of these

664
00:22:11,440 --> 00:22:14,640
uh avenues that can be arising with the

665
00:22:14,640 --> 00:22:17,039
niche symmetry which we've talked about

666
00:22:17,039 --> 00:22:19,200
in the context of yellow bloombergs and

667
00:22:19,200 --> 00:22:20,799
actual constance work

668
00:22:20,799 --> 00:22:22,640
and there's the a lot of other things

669
00:22:22,640 --> 00:22:24,640
that we've brought up let's just try to

670
00:22:24,640 --> 00:22:26,559
isolate what's really relevant which is

671
00:22:26,559 --> 00:22:28,559
that the agent is doing some type of an

672
00:22:28,559 --> 00:22:30,480
implementation or is some kind of an

673
00:22:30,480 --> 00:22:31,679
implementation

674
00:22:31,679 --> 00:22:34,000
of a generative model of a couple of

675
00:22:34,000 --> 00:22:35,200
things at once

676
00:22:35,200 --> 00:22:38,080
it's generating a model of observations

677
00:22:38,080 --> 00:22:39,760
through time the tilde on top of a

678
00:22:39,760 --> 00:22:40,960
variable means through time

679
00:22:40,960 --> 00:22:43,039
so observations through time and states

680
00:22:43,039 --> 00:22:44,080
through time

681
00:22:44,080 --> 00:22:47,039
you can think of as a function of policy

682
00:22:47,039 --> 00:22:47,600
choices

683
00:22:47,600 --> 00:22:50,720
pi and parameters of the model theta

684
00:22:50,720 --> 00:22:52,640
so for example one of my parameters in

685
00:22:52,640 --> 00:22:54,080
my theta is like

686
00:22:54,080 --> 00:22:57,200
um if i get hit by a bike then it's

687
00:22:57,200 --> 00:22:58,000
going to hurt

688
00:22:58,000 --> 00:23:00,240
and then i my generative model is like

689
00:23:00,240 --> 00:23:02,559
under the policy of looking both ways to

690
00:23:02,559 --> 00:23:03,360
cross the road

691
00:23:03,360 --> 00:23:05,200
i predict that my states will include

692
00:23:05,200 --> 00:23:06,799
not being hit by a bike and so i won't

693
00:23:06,799 --> 00:23:08,320
have any pain observations

694
00:23:08,320 --> 00:23:10,960
under that same policy you could imagine

695
00:23:10,960 --> 00:23:12,559
other types of state and observation

696
00:23:12,559 --> 00:23:13,600
predictions

697
00:23:13,600 --> 00:23:16,559
and then there are a few subsequent

698
00:23:16,559 --> 00:23:17,600
mathematical

699
00:23:17,600 --> 00:23:20,960
details about the insides of this

700
00:23:20,960 --> 00:23:21,760
equation

701
00:23:21,760 --> 00:23:23,919
it's a little bit bracketed no pun

702
00:23:23,919 --> 00:23:25,440
intended and the top

703
00:23:25,440 --> 00:23:28,159
and that's a shorthand and then we can

704
00:23:28,159 --> 00:23:29,200
explore

705
00:23:29,200 --> 00:23:31,440
and unpack it a few more levels so like

706
00:23:31,440 --> 00:23:33,360
on that first row

707
00:23:33,360 --> 00:23:37,360
we can see that that p o s pi theta

708
00:23:37,360 --> 00:23:40,640
those um uh relationships

709
00:23:40,640 --> 00:23:42,720
can be unpacked on the other side of the

710
00:23:42,720 --> 00:23:44,720
equal sign the right hand side

711
00:23:44,720 --> 00:23:47,120
to like just the probability of the

712
00:23:47,120 --> 00:23:48,640
parameters existing

713
00:23:48,640 --> 00:23:50,320
and then just the probability of the

714
00:23:50,320 --> 00:23:52,559
policy existing multiplied by

715
00:23:52,559 --> 00:23:54,720
this big other thing so why would that

716
00:23:54,720 --> 00:23:56,400
be the case and we won't go through all

717
00:23:56,400 --> 00:23:57,600
them in this detail but i think this

718
00:23:57,600 --> 00:23:58,799
one's really helpful

719
00:23:58,799 --> 00:24:01,039
to understand for active inference and

720
00:24:01,039 --> 00:24:02,240
people just raise your

721
00:24:02,240 --> 00:24:04,240
hand if you want to talk but just to

722
00:24:04,240 --> 00:24:05,679
keep it like informational

723
00:24:05,679 --> 00:24:07,360
and fun i'll just keep going until

724
00:24:07,360 --> 00:24:09,679
somebody wants to ask a question

725
00:24:09,679 --> 00:24:13,200
so the reason why p of pi

726
00:24:13,200 --> 00:24:15,679
is there the probability of the policy

727
00:24:15,679 --> 00:24:16,559
is like

728
00:24:16,559 --> 00:24:19,600
if the policy is unrealistic you don't

729
00:24:19,600 --> 00:24:21,200
even want to consider it you want to

730
00:24:21,200 --> 00:24:22,000
basically

731
00:24:22,000 --> 00:24:24,720
take unlikely policies impossible or

732
00:24:24,720 --> 00:24:26,400
implausible policies

733
00:24:26,400 --> 00:24:29,360
and systematically not consider them so

734
00:24:29,360 --> 00:24:30,880
if if i'm trying to get out of the way

735
00:24:30,880 --> 00:24:32,320
of the incoming bike

736
00:24:32,320 --> 00:24:34,880
and i'm spending a lot of my time or my

737
00:24:34,880 --> 00:24:37,360
clock cycles or a lot of my cognitive

738
00:24:37,360 --> 00:24:39,039
infrastructure on

739
00:24:39,039 --> 00:24:40,960
action strategies that involve me doing

740
00:24:40,960 --> 00:24:42,080
a spider-man and

741
00:24:42,080 --> 00:24:44,240
swinging from a building it's it's so

742
00:24:44,240 --> 00:24:45,919
implausible that it's probably not going

743
00:24:45,919 --> 00:24:47,200
to be effective

744
00:24:47,200 --> 00:24:48,799
so we want to have something in our

745
00:24:48,799 --> 00:24:50,640
model that represents likely

746
00:24:50,640 --> 00:24:52,640
or possible policies being considered a

747
00:24:52,640 --> 00:24:54,159
little bit more richly than

748
00:24:54,159 --> 00:24:56,960
impli implausible policies and similarly

749
00:24:56,960 --> 00:24:58,240
for p of data

750
00:24:58,240 --> 00:24:59,600
which is a little more abstract because

751
00:24:59,600 --> 00:25:01,360
it's just a parameter of the model but

752
00:25:01,360 --> 00:25:02,880
it's like saying if it's an unlikely

753
00:25:02,880 --> 00:25:04,640
parameter state it's also not worth

754
00:25:04,640 --> 00:25:05,760
thinking too much about

755
00:25:05,760 --> 00:25:07,440
i don't need to plan for it being

756
00:25:07,440 --> 00:25:09,600
negative 40 in california

757
00:25:09,600 --> 00:25:11,279
however our russian colleagues might

758
00:25:11,279 --> 00:25:12,960
need to plan for that so it's going to

759
00:25:12,960 --> 00:25:13,360
be

760
00:25:13,360 --> 00:25:15,520
niche dependent and contextual whether

761
00:25:15,520 --> 00:25:17,039
they need to plan for it or

762
00:25:17,039 --> 00:25:20,799
not okay now let's go into this big pi

763
00:25:20,799 --> 00:25:24,080
uh notation on the right side of the

764
00:25:24,080 --> 00:25:25,520
right-hand side of the first

765
00:25:25,520 --> 00:25:27,840
line of equations this is kind of like a

766
00:25:27,840 --> 00:25:29,039
sigma sigma

767
00:25:29,039 --> 00:25:31,919
adds up the elements of a series so like

768
00:25:31,919 --> 00:25:32,559
sigma

769
00:25:32,559 --> 00:25:34,480
of you know one plus one over two plus

770
00:25:34,480 --> 00:25:36,080
one over four or something

771
00:25:36,080 --> 00:25:38,400
and the pi is like a big multiplier and

772
00:25:38,400 --> 00:25:40,240
it's saying from the first time step t

773
00:25:40,240 --> 00:25:42,799
equals one through all of the time steps

774
00:25:42,799 --> 00:25:44,000
big t

775
00:25:44,000 --> 00:25:46,000
do this calculation what is the

776
00:25:46,000 --> 00:25:48,320
calculation well it's the probability of

777
00:25:48,320 --> 00:25:51,520
observations given states so in that's

778
00:25:51,520 --> 00:25:53,039
observation at a certain time given the

779
00:25:53,039 --> 00:25:54,640
state at that time so it's like

780
00:25:54,640 --> 00:25:57,200
if this my estimate of the state not s

781
00:25:57,200 --> 00:25:57,840
hat just

782
00:25:57,840 --> 00:26:00,480
s with no hat if my observat if my state

783
00:26:00,480 --> 00:26:01,919
is getting hit by a bike

784
00:26:01,919 --> 00:26:03,200
there's going to be a very likely

785
00:26:03,200 --> 00:26:05,039
observation of it hurting now that

786
00:26:05,039 --> 00:26:06,480
doesn't say whether it's likely that i'm

787
00:26:06,480 --> 00:26:08,080
getting hit by a bike it's just that

788
00:26:08,080 --> 00:26:10,080
it is the case if it is that state then

789
00:26:10,080 --> 00:26:11,520
there's going to be this observation

790
00:26:11,520 --> 00:26:13,360
so that's the mapping between

791
00:26:13,360 --> 00:26:14,880
observations and states

792
00:26:14,880 --> 00:26:17,200
but it's observations probability

793
00:26:17,200 --> 00:26:17,919
conditional

794
00:26:17,919 --> 00:26:19,919
with a straight line on the state being

795
00:26:19,919 --> 00:26:21,120
a certain way

796
00:26:21,120 --> 00:26:22,880
okay that's the first part and the

797
00:26:22,880 --> 00:26:24,880
second part is the probability of

798
00:26:24,880 --> 00:26:28,880
that state arising conditional on

799
00:26:28,880 --> 00:26:31,279
the previous state and the previous

800
00:26:31,279 --> 00:26:33,039
policy and the parameter

801
00:26:33,039 --> 00:26:35,600
and so again with this like bike model

802
00:26:35,600 --> 00:26:36,159
it's like

803
00:26:36,159 --> 00:26:38,320
what is the probability of my estimated

804
00:26:38,320 --> 00:26:39,200
state s of t

805
00:26:39,200 --> 00:26:41,440
at that time being hit by a bike given

806
00:26:41,440 --> 00:26:43,919
that i wasn't being hit by a bike before

807
00:26:43,919 --> 00:26:46,159
and my policy was looking both ways and

808
00:26:46,159 --> 00:26:48,159
my theta model parameters tell me that

809
00:26:48,159 --> 00:26:49,520
if i look both ways

810
00:26:49,520 --> 00:26:51,520
it's really likely that i'll stay safe

811
00:26:51,520 --> 00:26:52,559
for example

812
00:26:52,559 --> 00:26:54,240
but stay safe isn't what's directly

813
00:26:54,240 --> 00:26:56,159
specified by the model theta

814
00:26:56,159 --> 00:26:58,400
it's actually specifying the likelihood

815
00:26:58,400 --> 00:27:01,120
that a given policy and state mapping

816
00:27:01,120 --> 00:27:03,200
are going to relate into the future with

817
00:27:03,200 --> 00:27:04,320
a certain state

818
00:27:04,320 --> 00:27:07,520
and then separately we can consider what

819
00:27:07,520 --> 00:27:10,080
observations arise given a state

820
00:27:10,080 --> 00:27:13,200
so it's a little bit like just

821
00:27:13,200 --> 00:27:15,520
showing our work or being very clear

822
00:27:15,520 --> 00:27:17,039
with what is the actual state of the

823
00:27:17,039 --> 00:27:17,440
world

824
00:27:17,440 --> 00:27:20,159
s hat what's the estimated state s what

825
00:27:20,159 --> 00:27:20,960
are the

826
00:27:20,960 --> 00:27:23,520
um mappings between policies states and

827
00:27:23,520 --> 00:27:25,520
future states that's the right side

828
00:27:25,520 --> 00:27:27,360
then what's the mapping between

829
00:27:27,360 --> 00:27:29,760
observation observations and states in

830
00:27:29,760 --> 00:27:31,200
that first part

831
00:27:31,200 --> 00:27:34,880
okay any thoughts or questions because

832
00:27:34,880 --> 00:27:36,240
the rest just kind of

833
00:27:36,240 --> 00:27:39,679
continues from here in a similar

834
00:27:39,679 --> 00:27:43,279
way um okay

835
00:27:43,279 --> 00:27:45,120
we'll just keep on you know write down

836
00:27:45,120 --> 00:27:47,360
any cool questions that are

837
00:27:47,360 --> 00:27:50,880
coming to mind yvonne yeah go ahead

838
00:27:50,880 --> 00:27:53,520
well you're muted first but yes then

839
00:27:53,520 --> 00:27:54,080
continue

840
00:27:54,080 --> 00:27:56,720
uh thank you could you please explain

841
00:27:56,720 --> 00:27:58,159
one more time what

842
00:27:58,159 --> 00:28:03,279
the small theta is it's a parameter of

843
00:28:03,279 --> 00:28:06,320
its parameter of

844
00:28:06,320 --> 00:28:09,520
the generative model but what is it yes

845
00:28:09,520 --> 00:28:12,640
great question so we can actually

846
00:28:12,640 --> 00:28:15,279
list we can go just just to show it in

847
00:28:15,279 --> 00:28:16,000
the context

848
00:28:16,000 --> 00:28:19,360
of the paper

849
00:28:19,440 --> 00:28:21,679
and this by the way is in 3.1 but it

850
00:28:21,679 --> 00:28:23,120
introduces

851
00:28:23,120 --> 00:28:28,080
some of the other equations earlier

852
00:28:28,880 --> 00:28:33,440
the theta are the details of the model

853
00:28:33,440 --> 00:28:36,399
that relate the transition distribution

854
00:28:36,399 --> 00:28:36,720
so

855
00:28:36,720 --> 00:28:38,559
here we're looking at the states and the

856
00:28:38,559 --> 00:28:39,919
previous policy

857
00:28:39,919 --> 00:28:42,399
the s t minus 1 and pi of t minus 1 and

858
00:28:42,399 --> 00:28:43,440
how given

859
00:28:43,440 --> 00:28:45,760
theta it maps onto s of t so what is

860
00:28:45,760 --> 00:28:46,480
theta

861
00:28:46,480 --> 00:28:47,679
just from looking at the equation what

862
00:28:47,679 --> 00:28:49,440
is theta going to be telling us it's

863
00:28:49,440 --> 00:28:50,640
going to be telling us

864
00:28:50,640 --> 00:28:54,799
how to map t minus 1's state and policy

865
00:28:54,799 --> 00:28:58,159
state estimate and policy to the time

866
00:28:58,159 --> 00:29:00,960
t states so let's just imagine that it

867
00:29:00,960 --> 00:29:02,000
were a linear

868
00:29:02,000 --> 00:29:05,039
model so i had a linear y equals mx

869
00:29:05,039 --> 00:29:07,600
plus b and that was how we were going to

870
00:29:07,600 --> 00:29:08,080
map

871
00:29:08,080 --> 00:29:10,480
forward just totally a simple way to do

872
00:29:10,480 --> 00:29:11,200
it then

873
00:29:11,200 --> 00:29:13,919
theta would be like a vector containing

874
00:29:13,919 --> 00:29:14,480
m

875
00:29:14,480 --> 00:29:17,520
and b or theta would

876
00:29:17,520 --> 00:29:20,000
the the domain how many dimensions of

877
00:29:20,000 --> 00:29:20,640
the model

878
00:29:20,640 --> 00:29:22,960
there are is how tall theta is going to

879
00:29:22,960 --> 00:29:24,480
be in a sense

880
00:29:24,480 --> 00:29:26,559
but theta are the parameters of the

881
00:29:26,559 --> 00:29:28,240
model that

882
00:29:28,240 --> 00:29:31,679
say what the transition distribution is

883
00:29:31,679 --> 00:29:34,960
so uh yeah if it was a linear model then

884
00:29:34,960 --> 00:29:37,120
theta is kind of like a wrapper around

885
00:29:37,120 --> 00:29:38,720
the parameters of a linear model which

886
00:29:38,720 --> 00:29:39,520
is the slope

887
00:29:39,520 --> 00:29:42,559
m and then the elevation b

888
00:29:42,559 --> 00:29:44,880
if this were a neural network with a

889
00:29:44,880 --> 00:29:46,640
million parameters then theta would have

890
00:29:46,640 --> 00:29:48,320
a million parameters

891
00:29:48,320 --> 00:29:50,080
but it's kind of specifying the

892
00:29:50,080 --> 00:29:51,360
likelihood that

893
00:29:51,360 --> 00:29:54,480
the s of t minus 1 and pi of t minus one

894
00:29:54,480 --> 00:29:57,760
map onto s of t so let's just say that

895
00:29:57,760 --> 00:30:00,799
theta were one it just always map to one

896
00:30:00,799 --> 00:30:02,960
for some reason then it's like whatever

897
00:30:02,960 --> 00:30:04,480
these two are

898
00:30:04,480 --> 00:30:06,000
it's gonna map to one that's like you

899
00:30:06,000 --> 00:30:08,159
know f of x equals one yeah

900
00:30:08,159 --> 00:30:09,840
that's the parameter that's the simplest

901
00:30:09,840 --> 00:30:11,520
possible model is whatever the previous

902
00:30:11,520 --> 00:30:12,799
states and policy are

903
00:30:12,799 --> 00:30:15,600
we just map to one the next one would be

904
00:30:15,600 --> 00:30:16,080
f

905
00:30:16,080 --> 00:30:19,919
of uh x equals you know

906
00:30:19,919 --> 00:30:22,320
insert your model there and so it is a

907
00:30:22,320 --> 00:30:23,600
statistical point

908
00:30:23,600 --> 00:30:25,679
about what's a parameter of a model and

909
00:30:25,679 --> 00:30:27,600
like aren't these all parameters aren't

910
00:30:27,600 --> 00:30:29,120
they all variables aren't they all

911
00:30:29,120 --> 00:30:30,480
random variables

912
00:30:30,480 --> 00:30:32,000
aren't they all going to be variables in

913
00:30:32,000 --> 00:30:35,039
my python code yes to all of them

914
00:30:35,039 --> 00:30:36,399
and that's why there's a little bit of

915
00:30:36,399 --> 00:30:38,480
nuance and that's actually why we go

916
00:30:38,480 --> 00:30:40,480
into the details here because you can

917
00:30:40,480 --> 00:30:42,159
get pretty tangled up

918
00:30:42,159 --> 00:30:44,559
and confused in the gray zone with

919
00:30:44,559 --> 00:30:45,360
what's a

920
00:30:45,360 --> 00:30:47,440
estimator and what what is the what is

921
00:30:47,440 --> 00:30:49,200
the scientist estimating what is the

922
00:30:49,200 --> 00:30:49,760
organism

923
00:30:49,760 --> 00:30:51,360
estimating and a lot of times when we

924
00:30:51,360 --> 00:30:52,799
just look at it it's a little bit

925
00:30:52,799 --> 00:30:53,760
clearer

926
00:30:53,760 --> 00:30:56,080
and we can think about a few layers of

927
00:30:56,080 --> 00:30:57,200
unpacking with

928
00:30:57,200 --> 00:30:59,679
the top most level of understanding is

929
00:30:59,679 --> 00:31:00,720
this

930
00:31:00,720 --> 00:31:04,880
uh big p top equation then we can unpack

931
00:31:04,880 --> 00:31:06,000
it and define

932
00:31:06,000 --> 00:31:07,840
well what does that really mean how do

933
00:31:07,840 --> 00:31:09,279
we pull out the likelihood of the

934
00:31:09,279 --> 00:31:11,039
parameters like the likelihood of theta

935
00:31:11,039 --> 00:31:12,640
from the likelihood of policy

936
00:31:12,640 --> 00:31:15,120
from this time dependent series how do

937
00:31:15,120 --> 00:31:17,600
we define the distribution of p

938
00:31:17,600 --> 00:31:19,760
of o of t given s of t like the second

939
00:31:19,760 --> 00:31:21,279
line and so

940
00:31:21,279 --> 00:31:23,440
uh each of these we get continue

941
00:31:23,440 --> 00:31:25,039
unpacking and then each of them gets

942
00:31:25,039 --> 00:31:26,000
specified

943
00:31:26,000 --> 00:31:28,559
in functions in programming which

944
00:31:28,559 --> 00:31:29,279
hopefully we'll

945
00:31:29,279 --> 00:31:32,399
hear from alec about next week and there

946
00:31:32,399 --> 00:31:35,279
sometimes it becomes another level of

947
00:31:35,279 --> 00:31:36,000
clarity

948
00:31:36,000 --> 00:31:37,760
when you look at the function definition

949
00:31:37,760 --> 00:31:39,279
and you can say oh this function is

950
00:31:39,279 --> 00:31:42,720
actually taking in variable a b and c

951
00:31:42,720 --> 00:31:44,640
and then instead of seeing them as just

952
00:31:44,640 --> 00:31:46,399
o sub t s sub t

953
00:31:46,399 --> 00:31:48,320
the variable's name could be states

954
00:31:48,320 --> 00:31:49,519
through time

955
00:31:49,519 --> 00:31:51,600
or there might be a more descriptive

956
00:31:51,600 --> 00:31:53,440
name so i know that especially if you

957
00:31:53,440 --> 00:31:55,440
haven't looked at these equations for a

958
00:31:55,440 --> 00:31:56,399
long time

959
00:31:56,399 --> 00:31:59,279
or uh perhaps many equations for a long

960
00:31:59,279 --> 00:31:59,679
time

961
00:31:59,679 --> 00:32:01,360
sometimes like you get halfway down the

962
00:32:01,360 --> 00:32:03,039
pages like what what is mu

963
00:32:03,039 --> 00:32:05,760
of theta again but it is referring to

964
00:32:05,760 --> 00:32:07,039
something specific

965
00:32:07,039 --> 00:32:09,760
it's just a little bit of a shorthand to

966
00:32:09,760 --> 00:32:10,720
make sure that

967
00:32:10,720 --> 00:32:13,440
uh it fits visibly in a containable

968
00:32:13,440 --> 00:32:14,640
space

969
00:32:14,640 --> 00:32:16,880
so any other thoughts but good question

970
00:32:16,880 --> 00:32:19,679
there with the parameters

971
00:32:19,679 --> 00:32:22,399
so just one of the other um yeah yeah

972
00:32:22,399 --> 00:32:24,720
sasha go ahead

973
00:32:24,720 --> 00:32:26,880
um yeah thank you that was really useful

974
00:32:26,880 --> 00:32:28,000
to walk through those steps

975
00:32:28,000 --> 00:32:30,159
especially with the bike example and it

976
00:32:30,159 --> 00:32:32,000
um kind of brings to mind

977
00:32:32,000 --> 00:32:35,039
uh cases of

978
00:32:35,039 --> 00:32:36,960
when something is very unlikely to

979
00:32:36,960 --> 00:32:38,159
happen but

980
00:32:38,159 --> 00:32:41,919
the um but it's certain to have uh

981
00:32:41,919 --> 00:32:43,760
really bad outcomes so like

982
00:32:43,760 --> 00:32:46,159
uh you know it's really going to hurt if

983
00:32:46,159 --> 00:32:47,440
you get hit by a bike

984
00:32:47,440 --> 00:32:49,919
versus things that are very likely to

985
00:32:49,919 --> 00:32:51,120
happen but

986
00:32:51,120 --> 00:32:54,158
don't have uh

987
00:32:54,559 --> 00:32:56,240
but are not certain of having a bad

988
00:32:56,240 --> 00:32:58,640
outcome like i don't know um

989
00:32:58,640 --> 00:33:01,679
stubbing your toe on something um and so

990
00:33:01,679 --> 00:33:02,880
these are things that are weighted

991
00:33:02,880 --> 00:33:04,799
differently in in a model

992
00:33:04,799 --> 00:33:07,919
uh based on the certainty of

993
00:33:07,919 --> 00:33:10,240
uh and severity of the outcome so i

994
00:33:10,240 --> 00:33:11,440
think that's really cool that this is

995
00:33:11,440 --> 00:33:14,000
all incorporated into one model

996
00:33:14,000 --> 00:33:16,559
yeah and when we specify why we're

997
00:33:16,559 --> 00:33:18,320
making certain decisions

998
00:33:18,320 --> 00:33:20,080
first we're just laying these equations

999
00:33:20,080 --> 00:33:21,840
out to describe our little control

1000
00:33:21,840 --> 00:33:23,840
theory robot playing mario kart or

1001
00:33:23,840 --> 00:33:25,440
playing control theory games on

1002
00:33:25,440 --> 00:33:28,000
n64 but what if people had a little bit

1003
00:33:28,000 --> 00:33:29,440
more nuanced discussion

1004
00:33:29,440 --> 00:33:31,760
on collective decision-making topics

1005
00:33:31,760 --> 00:33:33,600
like somebody thinks well i think it's

1006
00:33:33,600 --> 00:33:34,799
totally unlikely

1007
00:33:34,799 --> 00:33:36,399
that the minimum miles per gallon of

1008
00:33:36,399 --> 00:33:38,159
cars could be 40 miles

1009
00:33:38,159 --> 00:33:40,720
by 2030 and someone else says that's

1010
00:33:40,720 --> 00:33:41,519
super likely

1011
00:33:41,519 --> 00:33:42,960
actually it's totally possible it's

1012
00:33:42,960 --> 00:33:44,960
totally likely i think that it can be

1013
00:33:44,960 --> 00:33:46,559
done or i think that this other

1014
00:33:46,559 --> 00:33:48,080
policy that you're suggesting is

1015
00:33:48,080 --> 00:33:49,600
implausible or

1016
00:33:49,600 --> 00:33:51,600
that it will have a bad outcome and so

1017
00:33:51,600 --> 00:33:53,679
people can disagree on whether a policy

1018
00:33:53,679 --> 00:33:54,000
is

1019
00:33:54,000 --> 00:33:56,399
actualizable or not for various reasons

1020
00:33:56,399 --> 00:33:57,760
it might come across as an ethical

1021
00:33:57,760 --> 00:33:59,519
constraint or a legal constraint or

1022
00:33:59,519 --> 00:34:01,919
logistical whatever it happens to be but

1023
00:34:01,919 --> 00:34:03,039
for whatever reason

1024
00:34:03,039 --> 00:34:06,320
that p of pi is low for them and then

1025
00:34:06,320 --> 00:34:08,079
we could unpack that and say okay all

1026
00:34:08,079 --> 00:34:09,199
these different elements are there

1027
00:34:09,199 --> 00:34:10,800
depending on the situation

1028
00:34:10,800 --> 00:34:12,320
and then somebody else might say i'm

1029
00:34:12,320 --> 00:34:14,719
with you on that outcome being unlikely

1030
00:34:14,719 --> 00:34:15,839
i just don't think it's that big of a

1031
00:34:15,839 --> 00:34:16,239
deal

1032
00:34:16,239 --> 00:34:17,679
saying oh yep i think that that kind of

1033
00:34:17,679 --> 00:34:19,440
a tsunami will happen once every 100

1034
00:34:19,440 --> 00:34:20,320
years

1035
00:34:20,320 --> 00:34:22,560
but i think that my transition matrix

1036
00:34:22,560 --> 00:34:25,280
from tsunami damage to being repaired

1037
00:34:25,280 --> 00:34:26,560
it just says that that's an easy

1038
00:34:26,560 --> 00:34:28,320
transition so we don't really need to

1039
00:34:28,320 --> 00:34:29,918
plan so heavily around it because when

1040
00:34:29,918 --> 00:34:31,359
it does happen we'll be able to rebuild

1041
00:34:31,359 --> 00:34:32,560
quickly for example

1042
00:34:32,560 --> 00:34:34,399
so these just allow us to give a little

1043
00:34:34,399 --> 00:34:35,679
bit more detail

1044
00:34:35,679 --> 00:34:38,719
into our infrastructure really our

1045
00:34:38,719 --> 00:34:40,399
architecture of decision making

1046
00:34:40,399 --> 00:34:41,599
and so i think blue that's definitely

1047
00:34:41,599 --> 00:34:42,800
where we can take it back to this

1048
00:34:42,800 --> 00:34:44,719
multiple scales of decision making

1049
00:34:44,719 --> 00:34:45,599
question

1050
00:34:45,599 --> 00:34:46,639
just to look through a couple of these

1051
00:34:46,639 --> 00:34:49,359
other equations before we move to q

1052
00:34:49,359 --> 00:34:51,359
here is the probability model of

1053
00:34:51,359 --> 00:34:53,119
observations given states

1054
00:34:53,119 --> 00:34:55,359
and so again that's like if the state my

1055
00:34:55,359 --> 00:34:57,040
estimated state not s hat

1056
00:34:57,040 --> 00:34:59,119
if my estimated state is getting hit by

1057
00:34:59,119 --> 00:35:00,560
a bike or stubbing my toe the

1058
00:35:00,560 --> 00:35:02,640
observations will be such and such in my

1059
00:35:02,640 --> 00:35:03,920
appropriate receptors

1060
00:35:03,920 --> 00:35:05,680
and that is given by a normal

1061
00:35:05,680 --> 00:35:07,599
distribution which means big

1062
00:35:07,599 --> 00:35:11,040
n on the variable o of t

1063
00:35:11,040 --> 00:35:14,480
and semicolon parameterized by mu

1064
00:35:14,480 --> 00:35:16,560
and sigma squared which are the mean and

1065
00:35:16,560 --> 00:35:17,920
the variance

1066
00:35:17,920 --> 00:35:19,760
and then those together mu and sigma

1067
00:35:19,760 --> 00:35:21,680
squared it turns out that those are the

1068
00:35:21,680 --> 00:35:23,119
hard parts to estimate

1069
00:35:23,119 --> 00:35:25,040
just like the problem or the challenge

1070
00:35:25,040 --> 00:35:26,880
of doing a linear regression on a

1071
00:35:26,880 --> 00:35:28,560
billion data points would be estimating

1072
00:35:28,560 --> 00:35:30,079
the mean and the variance

1073
00:35:30,079 --> 00:35:31,839
so you could fit the mean by adding up

1074
00:35:31,839 --> 00:35:33,520
all the numbers and then dividing it by

1075
00:35:33,520 --> 00:35:34,880
the amount of numbers

1076
00:35:34,880 --> 00:35:36,160
and for fitting the variance you could

1077
00:35:36,160 --> 00:35:37,920
use like a least squares model

1078
00:35:37,920 --> 00:35:40,320
but still that would be the computation

1079
00:35:40,320 --> 00:35:42,079
that you could do on pen and paper but

1080
00:35:42,079 --> 00:35:43,760
would just be very hard

1081
00:35:43,760 --> 00:35:45,760
in this case we're going to be doing

1082
00:35:45,760 --> 00:35:46,880
what is called

1083
00:35:46,880 --> 00:35:49,760
a amortized learning or a functional a

1084
00:35:49,760 --> 00:35:51,440
functional is like a function of another

1085
00:35:51,440 --> 00:35:52,320
function

1086
00:35:52,320 --> 00:35:54,480
and what we're going to be doing is

1087
00:35:54,480 --> 00:35:55,440
estimating

1088
00:35:55,440 --> 00:35:58,800
these statistical parameters with

1089
00:35:58,800 --> 00:36:01,200
this function lambda and then we're

1090
00:36:01,200 --> 00:36:03,040
going to fit the neural network

1091
00:36:03,040 --> 00:36:06,160
about that function lambda and so even

1092
00:36:06,160 --> 00:36:07,520
though neural networks are often

1093
00:36:07,520 --> 00:36:09,119
understood as providing additional

1094
00:36:09,119 --> 00:36:10,560
degrees of flexibility

1095
00:36:10,560 --> 00:36:12,079
like being able to learn conditional

1096
00:36:12,079 --> 00:36:14,160
relationships between data

1097
00:36:14,160 --> 00:36:16,160
um this took me a little bit to think

1098
00:36:16,160 --> 00:36:18,160
about but the neural network

1099
00:36:18,160 --> 00:36:20,400
is actually just facilitating us in this

1100
00:36:20,400 --> 00:36:21,680
model it's not saying that it would have

1101
00:36:21,680 --> 00:36:23,359
to be this way for all future active

1102
00:36:23,359 --> 00:36:24,000
learning

1103
00:36:24,000 --> 00:36:25,920
but it's actually still just fitting a

1104
00:36:25,920 --> 00:36:27,280
neural network model

1105
00:36:27,280 --> 00:36:29,440
of a normal distribution so we're

1106
00:36:29,440 --> 00:36:32,160
finding the parameters mu and sigma

1107
00:36:32,160 --> 00:36:33,760
use it which are very difficult to

1108
00:36:33,760 --> 00:36:35,200
estimate as you can imagine for a

1109
00:36:35,200 --> 00:36:36,800
non-linear control task

1110
00:36:36,800 --> 00:36:38,960
but we're still fitting it with a

1111
00:36:38,960 --> 00:36:40,240
function around

1112
00:36:40,240 --> 00:36:41,599
a normal so it's kind of this

1113
00:36:41,599 --> 00:36:43,280
interesting juxtaposition

1114
00:36:43,280 --> 00:36:45,440
of using advanced techniques like a

1115
00:36:45,440 --> 00:36:46,560
neural network

1116
00:36:46,560 --> 00:36:48,800
um high parametric techniques to

1117
00:36:48,800 --> 00:36:50,880
actually drill back down to a mean and a

1118
00:36:50,880 --> 00:36:51,839
variance

1119
00:36:51,839 --> 00:36:53,680
and then so this is this p-o-s-t is this

1120
00:36:53,680 --> 00:36:54,880
first part of this

1121
00:36:54,880 --> 00:36:58,160
um series and then s of t given the

1122
00:36:58,160 --> 00:36:59,839
previous state in the previous policy

1123
00:36:59,839 --> 00:37:01,680
is the second part here so this part

1124
00:37:01,680 --> 00:37:03,119
here gets

1125
00:37:03,119 --> 00:37:06,480
estimated with f of lambda and then the

1126
00:37:06,480 --> 00:37:08,880
uh second half of that series through

1127
00:37:08,880 --> 00:37:11,119
time has another normal distribution

1128
00:37:11,119 --> 00:37:13,680
with uh mu of theta and sigma squared of

1129
00:37:13,680 --> 00:37:14,400
theta

1130
00:37:14,400 --> 00:37:17,200
and then those two get looped up into a

1131
00:37:17,200 --> 00:37:18,160
functional

1132
00:37:18,160 --> 00:37:21,359
over those two similarly like s of t

1133
00:37:21,359 --> 00:37:22,800
is the right hand side what's being

1134
00:37:22,800 --> 00:37:23,920
conditioned on and we're going to be

1135
00:37:23,920 --> 00:37:24,880
estimating the

1136
00:37:24,880 --> 00:37:26,400
mean and variance of what is conditioned

1137
00:37:26,400 --> 00:37:28,720
on and then here it's similar

1138
00:37:28,720 --> 00:37:30,880
we're making a function that is

1139
00:37:30,880 --> 00:37:33,200
estimating what is being conditioned on

1140
00:37:33,200 --> 00:37:36,320
okay then we have this uh

1141
00:37:36,320 --> 00:37:37,680
early parts of the equation which is the

1142
00:37:37,680 --> 00:37:39,359
probability of the policy

1143
00:37:39,359 --> 00:37:41,440
is basically um it's going to be pretty

1144
00:37:41,440 --> 00:37:43,200
simple in this case but this is where

1145
00:37:43,200 --> 00:37:44,320
you could have a lot more degrees of

1146
00:37:44,320 --> 00:37:45,280
flexibility

1147
00:37:45,280 --> 00:37:47,440
this is sort of like an initial skeleton

1148
00:37:47,440 --> 00:37:49,200
paper as far as

1149
00:37:49,200 --> 00:37:51,119
what could be done with this framework

1150
00:37:51,119 --> 00:37:52,400
and that's kind of cool that's actually

1151
00:37:52,400 --> 00:37:54,720
what defines it in some ways as being

1152
00:37:54,720 --> 00:37:56,960
research and as being cutting edges this

1153
00:37:56,960 --> 00:37:57,760
isn't the

1154
00:37:57,760 --> 00:37:59,839
fine tuning of the parameters this is

1155
00:37:59,839 --> 00:38:01,119
laying out the framework that's going to

1156
00:38:01,119 --> 00:38:02,880
help us in a lot of other contexts

1157
00:38:02,880 --> 00:38:04,800
and then the probability of the policy

1158
00:38:04,800 --> 00:38:06,480
this is the part where we actually get

1159
00:38:06,480 --> 00:38:07,599
to free energy

1160
00:38:07,599 --> 00:38:10,640
okay so if we remember from the

1161
00:38:10,640 --> 00:38:14,400
notation slide f is like the free energy

1162
00:38:14,400 --> 00:38:16,240
where we strictly couldn't be making any

1163
00:38:16,240 --> 00:38:17,119
better decisions

1164
00:38:17,119 --> 00:38:20,160
if we knew that but g is the expected

1165
00:38:20,160 --> 00:38:21,520
free energy so just like

1166
00:38:21,520 --> 00:38:23,280
s is the hat s with the hat is real

1167
00:38:23,280 --> 00:38:24,320
state of the environment that's like

1168
00:38:24,320 --> 00:38:25,680
what we'd really want to track

1169
00:38:25,680 --> 00:38:28,720
and free energy would be what our policy

1170
00:38:28,720 --> 00:38:30,160
decisions would strictly want to be

1171
00:38:30,160 --> 00:38:32,000
converging upon but we don't get s

1172
00:38:32,000 --> 00:38:35,119
hat we get s and we don't get f we get g

1173
00:38:35,119 --> 00:38:37,839
what is g where does it come into play

1174
00:38:37,839 --> 00:38:40,960
well the probability of a policy

1175
00:38:40,960 --> 00:38:43,839
is now here sigma is actually not this

1176
00:38:43,839 --> 00:38:46,160
is sigma squared a statistical parameter

1177
00:38:46,160 --> 00:38:48,160
and it's kind of annoying but it is this

1178
00:38:48,160 --> 00:38:50,480
way that this sigma is a soft max

1179
00:38:50,480 --> 00:38:52,720
function which basically is like the

1180
00:38:52,720 --> 00:38:53,680
make a choice

1181
00:38:53,680 --> 00:38:56,560
function in math it just is s for

1182
00:38:56,560 --> 00:38:57,760
softmax here

1183
00:38:57,760 --> 00:39:00,320
sigma for variance here and what this is

1184
00:39:00,320 --> 00:39:01,280
going to be

1185
00:39:01,280 --> 00:39:04,560
is the negative expected free energy and

1186
00:39:04,560 --> 00:39:06,079
sometimes there's some negatives and

1187
00:39:06,079 --> 00:39:07,839
some logs getting thrown around and

1188
00:39:07,839 --> 00:39:09,200
these are all just ways to really just

1189
00:39:09,200 --> 00:39:09,839
say

1190
00:39:09,839 --> 00:39:12,800
pick the best given the expected free

1191
00:39:12,800 --> 00:39:13,680
energy

1192
00:39:13,680 --> 00:39:16,720
of policy and so this is how we get to

1193
00:39:16,720 --> 00:39:18,320
certain statements which have definitely

1194
00:39:18,320 --> 00:39:19,040
been

1195
00:39:19,040 --> 00:39:21,839
discussed on this uh live stream before

1196
00:39:21,839 --> 00:39:23,680
where it's like the agent picks the most

1197
00:39:23,680 --> 00:39:24,960
likely policy

1198
00:39:24,960 --> 00:39:27,280
and it's like wait but is it likely for

1199
00:39:27,280 --> 00:39:28,720
me to win or lose

1200
00:39:28,720 --> 00:39:30,960
what if it's a i know that it's unlikely

1201
00:39:30,960 --> 00:39:32,640
for me to win or lose

1202
00:39:32,640 --> 00:39:35,200
um if it's 100 that i'm going to win how

1203
00:39:35,200 --> 00:39:36,640
is that me picking the most likely

1204
00:39:36,640 --> 00:39:37,440
policy

1205
00:39:37,440 --> 00:39:40,000
but that's actually what um is happening

1206
00:39:40,000 --> 00:39:41,680
but it's not just simply the likeliest

1207
00:39:41,680 --> 00:39:43,200
policy um there's a little bit more

1208
00:39:43,200 --> 00:39:44,880
nuance which we'll look into with g

1209
00:39:44,880 --> 00:39:47,520
okay so that was sort of the p side

1210
00:39:47,520 --> 00:39:48,400
let's

1211
00:39:48,400 --> 00:39:50,400
maybe a little bit more quickly because

1212
00:39:50,400 --> 00:39:52,320
we will recognize a lot of the variables

1213
00:39:52,320 --> 00:39:53,119
and also

1214
00:39:53,119 --> 00:39:55,520
a lot of the structural relationships

1215
00:39:55,520 --> 00:39:56,640
between equations

1216
00:39:56,640 --> 00:39:59,440
here's the cube so we have p and q

1217
00:39:59,440 --> 00:40:01,440
between the agent and the environment

1218
00:40:01,440 --> 00:40:03,119
in a sense these are the two

1219
00:40:03,119 --> 00:40:04,640
distributions that are linking it not

1220
00:40:04,640 --> 00:40:06,480
that one is being computed by one or one

1221
00:40:06,480 --> 00:40:07,599
is computed by the other

1222
00:40:07,599 --> 00:40:09,280
but thinking about in that bayesian

1223
00:40:09,280 --> 00:40:10,960
computationalist framework where we have

1224
00:40:10,960 --> 00:40:12,000
like the data

1225
00:40:12,000 --> 00:40:14,240
going in one model goes to the hyper

1226
00:40:14,240 --> 00:40:16,000
parameters and then the hyper parameters

1227
00:40:16,000 --> 00:40:16,640
generate

1228
00:40:16,640 --> 00:40:19,599
leading to um the uh hey shannon and

1229
00:40:19,599 --> 00:40:20,240
welcome back

1230
00:40:20,240 --> 00:40:22,880
if we if yeah um going back to the

1231
00:40:22,880 --> 00:40:24,560
observed states of the world

1232
00:40:24,560 --> 00:40:28,720
so q is going to be distinguished from p

1233
00:40:28,720 --> 00:40:30,720
p is this implementation of the

1234
00:40:30,720 --> 00:40:32,720
generative model of the world

1235
00:40:32,720 --> 00:40:36,079
where is q is going to very distinctly

1236
00:40:36,079 --> 00:40:37,440
have different parameters

1237
00:40:37,440 --> 00:40:41,440
instead of p o s pi theta here we have q

1238
00:40:41,440 --> 00:40:43,839
of s through time policies and theta so

1239
00:40:43,839 --> 00:40:45,760
this is a slightly simpler

1240
00:40:45,760 --> 00:40:49,599
uh mathematical formulation and

1241
00:40:49,599 --> 00:40:53,280
it is going to be unpacked as

1242
00:40:53,280 --> 00:40:55,040
q of the states through time and the

1243
00:40:55,040 --> 00:40:57,040
policy and the model parameters

1244
00:40:57,040 --> 00:41:00,480
is again uh we see the likelihood of the

1245
00:41:00,480 --> 00:41:01,520
model parameters

1246
00:41:01,520 --> 00:41:03,760
and the likelihood of the policy coming

1247
00:41:03,760 --> 00:41:05,040
out in front

1248
00:41:05,040 --> 00:41:07,280
um and these are similar to the p but p

1249
00:41:07,280 --> 00:41:08,960
doesn't have to equal q

1250
00:41:08,960 --> 00:41:12,000
and then a slightly simpler

1251
00:41:12,000 --> 00:41:14,640
uh piece here which is just about the

1252
00:41:14,640 --> 00:41:16,880
states given the observations

1253
00:41:16,880 --> 00:41:19,200
uh and so this is like literally given

1254
00:41:19,200 --> 00:41:20,240
the retina

1255
00:41:20,240 --> 00:41:23,200
shadows what is the state estimate of

1256
00:41:23,200 --> 00:41:24,240
the world

1257
00:41:24,240 --> 00:41:27,280
so this is um it's like here in

1258
00:41:27,280 --> 00:41:30,560
in p if we look at just

1259
00:41:30,560 --> 00:41:32,480
this uh second line this is the

1260
00:41:32,480 --> 00:41:34,800
probability of observations given states

1261
00:41:34,800 --> 00:41:38,160
so this is given that it's daytime

1262
00:41:38,160 --> 00:41:40,640
there should be a lot of photons if the

1263
00:41:40,640 --> 00:41:42,079
estimated state of the world is night

1264
00:41:42,079 --> 00:41:44,400
time there shouldn't be any photons pos

1265
00:41:44,400 --> 00:41:46,480
okay but it's o given s

1266
00:41:46,480 --> 00:41:49,520
now in q we actually have

1267
00:41:49,520 --> 00:41:52,000
s given o so the p is different than the

1268
00:41:52,000 --> 00:41:54,880
q but also the orders have switched

1269
00:41:54,880 --> 00:41:57,119
this is called a recognition

1270
00:41:57,119 --> 00:41:58,160
distribution

1271
00:41:58,160 --> 00:41:59,920
because we're basically doing an

1272
00:41:59,920 --> 00:42:02,160
estimation of the states

1273
00:42:02,160 --> 00:42:04,880
given the observations so q is kind of

1274
00:42:04,880 --> 00:42:06,480
like the incoming

1275
00:42:06,480 --> 00:42:09,119
way that the observations are going to

1276
00:42:09,119 --> 00:42:11,280
be connected to the state estimators of

1277
00:42:11,280 --> 00:42:12,079
the world

1278
00:42:12,079 --> 00:42:13,920
that's the recognition but then the

1279
00:42:13,920 --> 00:42:16,319
generative model which is the p

1280
00:42:16,319 --> 00:42:19,200
that entails understanding what the

1281
00:42:19,200 --> 00:42:20,800
hidden states of the world are

1282
00:42:20,800 --> 00:42:23,760
s and your estimates of them that is and

1283
00:42:23,760 --> 00:42:24,240
then

1284
00:42:24,240 --> 00:42:27,280
generating out observations that are

1285
00:42:27,280 --> 00:42:29,119
linked up to policy

1286
00:42:29,119 --> 00:42:32,000
and so here there's a slightly different

1287
00:42:32,000 --> 00:42:32,960
way that the

1288
00:42:32,960 --> 00:42:35,760
parameters of this model and that the um

1289
00:42:35,760 --> 00:42:36,960
policy

1290
00:42:36,960 --> 00:42:39,440
mapping is done with these a few more

1291
00:42:39,440 --> 00:42:41,200
statistical parameters

1292
00:42:41,200 --> 00:42:43,040
but similarly which we don't need to go

1293
00:42:43,040 --> 00:42:44,720
into too much detail in here is

1294
00:42:44,720 --> 00:42:46,960
these are also going to be distributed

1295
00:42:46,960 --> 00:42:48,640
using some statistical distribution

1296
00:42:48,640 --> 00:42:49,520
that's going to help us

1297
00:42:49,520 --> 00:42:52,400
estimate them and similarly we can take

1298
00:42:52,400 --> 00:42:54,240
all the statistical parameters

1299
00:42:54,240 --> 00:42:56,319
so for a normal distribution it's a two

1300
00:42:56,319 --> 00:42:57,280
parameter model

1301
00:42:57,280 --> 00:43:00,000
mean and variance but you could have

1302
00:43:00,000 --> 00:43:02,079
distributions with one or with more than

1303
00:43:02,079 --> 00:43:02,720
two

1304
00:43:02,720 --> 00:43:04,960
variables but whatever number of

1305
00:43:04,960 --> 00:43:06,240
statistical variables you want to

1306
00:43:06,240 --> 00:43:06,880
estimate

1307
00:43:06,880 --> 00:43:08,640
we're just going to wrap them into a

1308
00:43:08,640 --> 00:43:10,240
function and figure out some way to

1309
00:43:10,240 --> 00:43:11,200
estimate them

1310
00:43:11,200 --> 00:43:14,640
and so that's a degree of freedom

1311
00:43:14,640 --> 00:43:18,319
you can think of in the model is that

1312
00:43:18,319 --> 00:43:19,839
there's different you could flip out

1313
00:43:19,839 --> 00:43:21,920
this normal for some other type of

1314
00:43:21,920 --> 00:43:23,040
distribution

1315
00:43:23,040 --> 00:43:25,280
or you could have another way to

1316
00:43:25,280 --> 00:43:26,319
estimate the

1317
00:43:26,319 --> 00:43:29,440
distribution's normality okay

1318
00:43:29,440 --> 00:43:31,359
that's p and q but it is really

1319
00:43:31,359 --> 00:43:34,240
important and interesting what they are

1320
00:43:34,240 --> 00:43:36,240
any thoughts or questions or we can just

1321
00:43:36,240 --> 00:43:39,040
keep cruising

1322
00:43:39,520 --> 00:43:43,680
okay yeah um alec

1323
00:43:45,440 --> 00:43:48,480
uh yeah i want to

1324
00:43:48,480 --> 00:43:52,160
ask uh maybe in terms of so p

1325
00:43:52,160 --> 00:43:55,200
is for generative model q

1326
00:43:55,200 --> 00:43:57,920
is for recognition distribution and

1327
00:43:57,920 --> 00:43:59,760
recognition model

1328
00:43:59,760 --> 00:44:03,760
and as we discussed in previous session

1329
00:44:03,760 --> 00:44:07,200
a generative model exists or

1330
00:44:07,200 --> 00:44:10,880
acts uh in uh dynamics

1331
00:44:10,880 --> 00:44:14,000
so you have uh generative model in some

1332
00:44:14,000 --> 00:44:14,800
way of

1333
00:44:14,800 --> 00:44:18,079
it's like was example with dominos so

1334
00:44:18,079 --> 00:44:19,200
when you act

1335
00:44:19,200 --> 00:44:22,319
and act in accordance to this generative

1336
00:44:22,319 --> 00:44:23,200
model

1337
00:44:23,200 --> 00:44:26,240
and in example of road and

1338
00:44:26,240 --> 00:44:29,920
a bike this generative model

1339
00:44:29,920 --> 00:44:31,839
and defines the way you are looking on

1340
00:44:31,839 --> 00:44:34,000
both ways and when go if you don't see a

1341
00:44:34,000 --> 00:44:35,359
bike

1342
00:44:35,359 --> 00:44:38,560
and uh in this terms so

1343
00:44:38,560 --> 00:44:41,040
what will be a recognition distribution

1344
00:44:41,040 --> 00:44:42,160
recognition model

1345
00:44:42,160 --> 00:44:44,720
it's will be understanding how bike is

1346
00:44:44,720 --> 00:44:45,599
looks like

1347
00:44:45,599 --> 00:44:48,720
or what is rule how road

1348
00:44:48,720 --> 00:44:51,839
is looks like and so on or it's the

1349
00:44:51,839 --> 00:44:53,520
wrong direction for my

1350
00:44:53,520 --> 00:44:55,599
understanding a good question and it was

1351
00:44:55,599 --> 00:44:56,640
it was actually

1352
00:44:56,640 --> 00:44:59,599
i had to email alec to clarify a few

1353
00:44:59,599 --> 00:45:00,319
things

1354
00:45:00,319 --> 00:45:02,079
because i looked at this q distribution

1355
00:45:02,079 --> 00:45:03,359
i thought wait it's a recognition

1356
00:45:03,359 --> 00:45:04,400
distribution

1357
00:45:04,400 --> 00:45:07,040
but where are the observations how can q

1358
00:45:07,040 --> 00:45:08,240
be recognition when there's no

1359
00:45:08,240 --> 00:45:09,359
observations

1360
00:45:09,359 --> 00:45:10,960
and then it turns out there are

1361
00:45:10,960 --> 00:45:12,400
observations that are

1362
00:45:12,400 --> 00:45:14,560
uh related to q but it's he just said

1363
00:45:14,560 --> 00:45:16,319
basically it's the norm

1364
00:45:16,319 --> 00:45:18,800
in the recognition distribution

1365
00:45:18,800 --> 00:45:20,079
literature like this part of the

1366
00:45:20,079 --> 00:45:20,800
bayesian

1367
00:45:20,800 --> 00:45:24,480
computational fields this is what they

1368
00:45:24,480 --> 00:45:25,440
call those two

1369
00:45:25,440 --> 00:45:27,200
models the recognition distribution

1370
00:45:27,200 --> 00:45:29,040
which is from the observations

1371
00:45:29,040 --> 00:45:31,119
to the generative model parameters which

1372
00:45:31,119 --> 00:45:32,640
ironically as a norm

1373
00:45:32,640 --> 00:45:35,760
doesn't include the uh observation

1374
00:45:35,760 --> 00:45:37,599
and then the generative model again is

1375
00:45:37,599 --> 00:45:39,280
the one that's going from the

1376
00:45:39,280 --> 00:45:41,200
organisms parameter estimates the world

1377
00:45:41,200 --> 00:45:43,040
to predicted observations and that's how

1378
00:45:43,040 --> 00:45:44,960
expectation maximization works

1379
00:45:44,960 --> 00:45:46,720
now we had all these interesting

1380
00:45:46,720 --> 00:45:48,560
discussions alex which you're alluding

1381
00:45:48,560 --> 00:45:49,119
to

1382
00:45:49,119 --> 00:45:52,079
of for example does the organism have

1383
00:45:52,079 --> 00:45:53,440
the internal model

1384
00:45:53,440 --> 00:45:55,200
that's generative or is the generative

1385
00:45:55,200 --> 00:45:56,720
model enacted

1386
00:45:56,720 --> 00:45:58,560
in terms of the relationship is it

1387
00:45:58,560 --> 00:46:00,079
that's the internalism versus

1388
00:46:00,079 --> 00:46:02,640
externalism discussion that we had and

1389
00:46:02,640 --> 00:46:03,760
so i'm going to try to

1390
00:46:03,760 --> 00:46:06,079
combine what alec informed me about as

1391
00:46:06,079 --> 00:46:08,560
well as channel a little maxwell here

1392
00:46:08,560 --> 00:46:10,480
and i think the answer is going to be

1393
00:46:10,480 --> 00:46:13,200
there's multiple philosophical lenses

1394
00:46:13,200 --> 00:46:16,480
that you could apply um to real-world

1395
00:46:16,480 --> 00:46:17,839
situations

1396
00:46:17,839 --> 00:46:21,760
and this is only what is specified in

1397
00:46:21,760 --> 00:46:23,839
the math and in the programming

1398
00:46:23,839 --> 00:46:26,400
and so if you include it if you include

1399
00:46:26,400 --> 00:46:26,960
in your

1400
00:46:26,960 --> 00:46:29,119
recognition distribution is the uh

1401
00:46:29,119 --> 00:46:30,079
luminosity

1402
00:46:30,079 --> 00:46:31,920
and the edge and the color and those are

1403
00:46:31,920 --> 00:46:33,359
the observations

1404
00:46:33,359 --> 00:46:34,560
and you're recognizing you're doing

1405
00:46:34,560 --> 00:46:36,800
image classification on recognizing a

1406
00:46:36,800 --> 00:46:37,119
bike

1407
00:46:37,119 --> 00:46:39,680
just simplifying it but there it is then

1408
00:46:39,680 --> 00:46:40,240
that is

1409
00:46:40,240 --> 00:46:42,240
strictly only what is in the recognition

1410
00:46:42,240 --> 00:46:43,839
distribution it's going to be about the

1411
00:46:43,839 --> 00:46:45,520
mapping of the observations

1412
00:46:45,520 --> 00:46:48,560
um of the state's given observations and

1413
00:46:48,560 --> 00:46:50,000
your observations could include

1414
00:46:50,000 --> 00:46:51,200
those variables that we just talked

1415
00:46:51,200 --> 00:46:52,880
about so if it's being conditioned on

1416
00:46:52,880 --> 00:46:54,480
that then that's what's happening

1417
00:46:54,480 --> 00:46:56,560
and then even given a single

1418
00:46:56,560 --> 00:46:58,160
formalization of like okay the

1419
00:46:58,160 --> 00:46:59,280
observations are

1420
00:46:59,280 --> 00:47:01,440
the um overall brightness and the amount

1421
00:47:01,440 --> 00:47:02,960
of movement or something like whatever

1422
00:47:02,960 --> 00:47:04,480
it happens to be

1423
00:47:04,480 --> 00:47:06,880
it could still be a a pluralistic

1424
00:47:06,880 --> 00:47:08,560
philosophical scenario

1425
00:47:08,560 --> 00:47:10,240
where somebody could say okay that's a

1426
00:47:10,240 --> 00:47:12,079
modeling convenience but

1427
00:47:12,079 --> 00:47:14,640
really those observations are in the

1428
00:47:14,640 --> 00:47:15,920
space between the organism and the

1429
00:47:15,920 --> 00:47:16,560
environment

1430
00:47:16,560 --> 00:47:17,599
and someone else says yep it's a

1431
00:47:17,599 --> 00:47:19,040
modeling convenience but i think those

1432
00:47:19,040 --> 00:47:19,760
parameters

1433
00:47:19,760 --> 00:47:22,559
are something about the neural firing

1434
00:47:22,559 --> 00:47:24,000
and someone else says it's both of them

1435
00:47:24,000 --> 00:47:26,559
and someone else said so i would be open

1436
00:47:26,559 --> 00:47:27,119
to

1437
00:47:27,119 --> 00:47:29,599
uh correction and also would love to

1438
00:47:29,599 --> 00:47:30,960
hear alex

1439
00:47:30,960 --> 00:47:33,520
perspective on this but i think the

1440
00:47:33,520 --> 00:47:34,960
answer would be these papers that we

1441
00:47:34,960 --> 00:47:36,559
read tale of two densities

1442
00:47:36,559 --> 00:47:38,079
and integrating externalism and

1443
00:47:38,079 --> 00:47:39,920
internalism are actually

1444
00:47:39,920 --> 00:47:42,960
about how by framing it within active

1445
00:47:42,960 --> 00:47:44,160
inference

1446
00:47:44,160 --> 00:47:46,400
we move beyond those philosophical

1447
00:47:46,400 --> 00:47:47,920
debates or another way to say that is

1448
00:47:47,920 --> 00:47:49,680
build a bigger tent that includes both

1449
00:47:49,680 --> 00:47:50,800
of those perspectives

1450
00:47:50,800 --> 00:47:53,359
um in a way that's compatibilist because

1451
00:47:53,359 --> 00:47:55,599
those are the debates that people had

1452
00:47:55,599 --> 00:47:57,839
about these models so like in the

1453
00:47:57,839 --> 00:47:59,359
reinforcement learning literature it's

1454
00:47:59,359 --> 00:47:59,680
like

1455
00:47:59,680 --> 00:48:02,800
okay is the reward the signal

1456
00:48:02,800 --> 00:48:04,640
you know is it a pleasing you know

1457
00:48:04,640 --> 00:48:06,640
aesthetic body form

1458
00:48:06,640 --> 00:48:10,079
is that the reward or is that the signal

1459
00:48:10,079 --> 00:48:11,440
of the reward

1460
00:48:11,440 --> 00:48:13,359
and if it is the reward then isn't that

1461
00:48:13,359 --> 00:48:15,200
a circular definition like organisms

1462
00:48:15,200 --> 00:48:16,640
seek out what's rewarding

1463
00:48:16,640 --> 00:48:18,079
but it's not like you just want to see

1464
00:48:18,079 --> 00:48:19,520
the aesthetics there might be some

1465
00:48:19,520 --> 00:48:20,160
second

1466
00:48:20,160 --> 00:48:22,480
intention for example and so how do you

1467
00:48:22,480 --> 00:48:23,359
actually draw

1468
00:48:23,359 --> 00:48:26,079
out these questions is it happening in

1469
00:48:26,079 --> 00:48:27,920
the organism's head with a reward or is

1470
00:48:27,920 --> 00:48:28,800
it enacted

1471
00:48:28,800 --> 00:48:30,880
and that was sort of the philosophical

1472
00:48:30,880 --> 00:48:31,920
groundwork

1473
00:48:31,920 --> 00:48:34,640
and now we're for a minute putting those

1474
00:48:34,640 --> 00:48:35,440
bags

1475
00:48:35,440 --> 00:48:37,760
of all different stripes down and

1476
00:48:37,760 --> 00:48:39,520
looking at just the way that we're gonna

1477
00:48:39,520 --> 00:48:41,440
specify it and how it plays out in

1478
00:48:41,440 --> 00:48:42,720
simulations

1479
00:48:42,720 --> 00:48:44,960
knowing that potentially one person

1480
00:48:44,960 --> 00:48:46,319
might have a bayesian structural

1481
00:48:46,319 --> 00:48:47,839
computationalist perspective of these

1482
00:48:47,839 --> 00:48:48,960
examples we're going to look at in a

1483
00:48:48,960 --> 00:48:49,440
second

1484
00:48:49,440 --> 00:48:51,599
and somebody else might take a heavily

1485
00:48:51,599 --> 00:48:52,480
inactive

1486
00:48:52,480 --> 00:48:54,559
example they might say oh well the the

1487
00:48:54,559 --> 00:48:56,000
cart that's on the hill

1488
00:48:56,000 --> 00:48:59,520
it's like the cart hill combo organism

1489
00:48:59,520 --> 00:49:02,319
that's being or something like that but

1490
00:49:02,319 --> 00:49:03,119
at the end

1491
00:49:03,119 --> 00:49:04,559
whether the person thinks that it's

1492
00:49:04,559 --> 00:49:06,559
enacted or it's just a bayesian

1493
00:49:06,559 --> 00:49:08,079
computationalist approach

1494
00:49:08,079 --> 00:49:10,000
they're still going to at least be able

1495
00:49:10,000 --> 00:49:11,680
to point to the same equations and

1496
00:49:11,680 --> 00:49:13,920
ultimately the same code as well so

1497
00:49:13,920 --> 00:49:16,800
that's like uh hopefully explanation of

1498
00:49:16,800 --> 00:49:18,480
how the active inference framework and

1499
00:49:18,480 --> 00:49:19,839
the specifics

1500
00:49:19,839 --> 00:49:22,480
end up unifying these general debates

1501
00:49:22,480 --> 00:49:24,240
which potentially without such a

1502
00:49:24,240 --> 00:49:26,000
unifying framework it'd be intractable

1503
00:49:26,000 --> 00:49:27,200
because somebody would say okay well i

1504
00:49:27,200 --> 00:49:28,640
think that q is happening in the brain

1505
00:49:28,640 --> 00:49:29,520
the organism

1506
00:49:29,520 --> 00:49:30,800
somebody else says i think that q

1507
00:49:30,800 --> 00:49:32,559
happens in between the niche and the

1508
00:49:32,559 --> 00:49:34,559
organism someone else says i think q's a

1509
00:49:34,559 --> 00:49:36,079
modeling shorthand someone says i agree

1510
00:49:36,079 --> 00:49:37,200
with person one and three

1511
00:49:37,200 --> 00:49:39,599
or one and two and now we're saying okay

1512
00:49:39,599 --> 00:49:40,400
they're kind of

1513
00:49:40,400 --> 00:49:42,480
all correct and just all ways that we

1514
00:49:42,480 --> 00:49:43,440
can phrase

1515
00:49:43,440 --> 00:49:44,800
the specifics of what we're talking

1516
00:49:44,800 --> 00:49:46,319
about here so not that everyone's

1517
00:49:46,319 --> 00:49:47,920
correct because everyone's correct and

1518
00:49:47,920 --> 00:49:49,359
there is no wrong answer

1519
00:49:49,359 --> 00:49:52,720
but under this reconceptualization

1520
00:49:52,720 --> 00:49:54,800
of action and inference we find that

1521
00:49:54,800 --> 00:49:56,400
some of these previous questions or

1522
00:49:56,400 --> 00:49:57,280
phrasings

1523
00:49:57,280 --> 00:50:00,559
become like yes and instead of either

1524
00:50:00,559 --> 00:50:03,040
slash or

1525
00:50:03,040 --> 00:50:05,680
okay to move a little bit more quickly

1526
00:50:05,680 --> 00:50:06,480
just through these

1527
00:50:06,480 --> 00:50:09,200
uh a few equations before we can i think

1528
00:50:09,200 --> 00:50:10,480
just highlight a little bit

1529
00:50:10,480 --> 00:50:12,400
on the experiments and then probably

1530
00:50:12,400 --> 00:50:13,920
return to the multi-scale

1531
00:50:13,920 --> 00:50:15,920
question that we talked about earlier

1532
00:50:15,920 --> 00:50:18,480
and also about what other areas could

1533
00:50:18,480 --> 00:50:20,960
control be interesting in and also what

1534
00:50:20,960 --> 00:50:22,160
questions would we want to

1535
00:50:22,160 --> 00:50:25,599
ask alec and other attendees next week

1536
00:50:25,599 --> 00:50:29,040
here is equation one and this

1537
00:50:29,040 --> 00:50:30,720
i put after because i think it helps to

1538
00:50:30,720 --> 00:50:32,160
understand that p and q and

1539
00:50:32,160 --> 00:50:34,079
the mappings but this is what is

1540
00:50:34,079 --> 00:50:36,160
ultimately being minimized so again

1541
00:50:36,160 --> 00:50:38,400
we don't get f that's the real free

1542
00:50:38,400 --> 00:50:40,000
energy and that's

1543
00:50:40,000 --> 00:50:42,480
the one that we would really want to be

1544
00:50:42,480 --> 00:50:43,599
converging towards

1545
00:50:43,599 --> 00:50:45,920
which as they put it um converging

1546
00:50:45,920 --> 00:50:47,599
towards an approximation of the

1547
00:50:47,599 --> 00:50:49,680
posterior distribution of

1548
00:50:49,680 --> 00:50:52,880
prop the p model of states policies and

1549
00:50:52,880 --> 00:50:54,880
parameters given observations so that

1550
00:50:54,880 --> 00:50:57,119
would be like the best possible

1551
00:50:57,119 --> 00:50:59,359
state trajectory through time and the

1552
00:50:59,359 --> 00:51:00,960
best possible policy

1553
00:51:00,960 --> 00:51:02,640
given the observations of the world you

1554
00:51:02,640 --> 00:51:05,040
know given that bitcoin is at this value

1555
00:51:05,040 --> 00:51:06,559
and ethereum's at this value

1556
00:51:06,559 --> 00:51:08,319
the state trajectory that's the best for

1557
00:51:08,319 --> 00:51:10,000
me entails this policy

1558
00:51:10,000 --> 00:51:12,160
so that's clearly what we want to know

1559
00:51:12,160 --> 00:51:14,160
but that is intractable

1560
00:51:14,160 --> 00:51:15,599
so we needed to use some type of a

1561
00:51:15,599 --> 00:51:17,760
convergence towards this intractability

1562
00:51:17,760 --> 00:51:19,599
and this is where a lot of the more

1563
00:51:19,599 --> 00:51:22,240
specific and technical details related

1564
00:51:22,240 --> 00:51:23,280
to for example

1565
00:51:23,280 --> 00:51:25,280
the kobeck liblar informational

1566
00:51:25,280 --> 00:51:26,319
divergence

1567
00:51:26,319 --> 00:51:28,240
the informational distance between two

1568
00:51:28,240 --> 00:51:30,240
distributions is related

1569
00:51:30,240 --> 00:51:33,520
because um there's those distance

1570
00:51:33,520 --> 00:51:35,520
metrics are bounded at zero

1571
00:51:35,520 --> 00:51:36,880
like you if two distributions are

1572
00:51:36,880 --> 00:51:38,640
identical their distance is zero

1573
00:51:38,640 --> 00:51:40,559
and as they get more and more distant

1574
00:51:40,559 --> 00:51:42,960
that number strictly increases

1575
00:51:42,960 --> 00:51:44,720
and so it turns out that there's some

1576
00:51:44,720 --> 00:51:46,960
ways to have like this hypothetical

1577
00:51:46,960 --> 00:51:48,480
perfect distribution

1578
00:51:48,480 --> 00:51:50,720
and then have a distance between where

1579
00:51:50,720 --> 00:51:51,599
you're really at

1580
00:51:51,599 --> 00:51:52,800
and this hypothetical perfect

1581
00:51:52,800 --> 00:51:54,480
distribution which is always a positive

1582
00:51:54,480 --> 00:51:55,520
distance

1583
00:51:55,520 --> 00:51:58,319
and then try to converge towards that

1584
00:51:58,319 --> 00:52:00,079
hypothetical perfect position

1585
00:52:00,079 --> 00:52:02,720
by minimizing the distance function and

1586
00:52:02,720 --> 00:52:04,640
that distance function is informational

1587
00:52:04,640 --> 00:52:06,559
but it still is a distance metric

1588
00:52:06,559 --> 00:52:10,960
in a certain way and wrote out a few

1589
00:52:10,960 --> 00:52:14,000
details um the e is the expectation so

1590
00:52:14,000 --> 00:52:15,440
it's expectation

1591
00:52:15,440 --> 00:52:17,440
of states through time policies and

1592
00:52:17,440 --> 00:52:18,480
model parameters

1593
00:52:18,480 --> 00:52:20,400
and it's going to be something that

1594
00:52:20,400 --> 00:52:21,760
combines the q

1595
00:52:21,760 --> 00:52:24,319
and the p the natural log which makes it

1596
00:52:24,319 --> 00:52:25,680
a little bit easier to do the machine

1597
00:52:25,680 --> 00:52:26,079
learning

1598
00:52:26,079 --> 00:52:28,400
techniques and a few other benefits

1599
00:52:28,400 --> 00:52:29,119
scaling it

1600
00:52:29,119 --> 00:52:32,000
and bringing certain values below the

1601
00:52:32,000 --> 00:52:33,119
number line

1602
00:52:33,119 --> 00:52:36,079
and then that is going to be always

1603
00:52:36,079 --> 00:52:37,599
greater than or equal to

1604
00:52:37,599 --> 00:52:40,720
that's this part right here than just

1605
00:52:40,720 --> 00:52:41,440
the observe

1606
00:52:41,440 --> 00:52:43,920
the observations so it turns out that by

1607
00:52:43,920 --> 00:52:45,200
doing this estimator

1608
00:52:45,200 --> 00:52:48,160
we can bound um some but there's a few

1609
00:52:48,160 --> 00:52:49,520
things that get bounded but they're not

1610
00:52:49,520 --> 00:52:52,480
even all phrased here

1611
00:52:52,480 --> 00:52:55,599
um yep

1612
00:52:55,599 --> 00:52:57,040
so the last thing i wrote there was

1613
00:52:57,040 --> 00:52:59,040
given that the q is um

1614
00:52:59,040 --> 00:53:01,520
focusing on basically between p and q

1615
00:53:01,520 --> 00:53:03,040
you get all the parameters

1616
00:53:03,040 --> 00:53:06,240
so what you can do by optimizing the

1617
00:53:06,240 --> 00:53:07,839
recognition density and the generative

1618
00:53:07,839 --> 00:53:08,960
model

1619
00:53:08,960 --> 00:53:10,960
back and forth whether actually like a

1620
00:53:10,960 --> 00:53:12,720
two-cycle engine like expectation

1621
00:53:12,720 --> 00:53:14,240
maximization which is how it gets

1622
00:53:14,240 --> 00:53:15,599
implemented in code

1623
00:53:15,599 --> 00:53:18,319
or dynamically and continuously as in

1624
00:53:18,319 --> 00:53:18,960
the case of

1625
00:53:18,960 --> 00:53:22,079
an active organismal behavior

1626
00:53:22,079 --> 00:53:24,720
what has to get learnt upon but here

1627
00:53:24,720 --> 00:53:26,960
what tractably can be learnt upon and

1628
00:53:26,960 --> 00:53:28,240
conditioned upon

1629
00:53:28,240 --> 00:53:30,559
is that mapping of how observations

1630
00:53:30,559 --> 00:53:32,640
states and policies are linked

1631
00:53:32,640 --> 00:53:35,280
in a nuanced nexus where they're all

1632
00:53:35,280 --> 00:53:36,720
taken into account

1633
00:53:36,720 --> 00:53:38,720
rather than running a classifier that

1634
00:53:38,720 --> 00:53:40,960
goes from just observations to states

1635
00:53:40,960 --> 00:53:42,880
and then a second layer model from

1636
00:53:42,880 --> 00:53:44,400
states to policies

1637
00:53:44,400 --> 00:53:45,760
that would be a little bit more along

1638
00:53:45,760 --> 00:53:46,960
the lines of traditional machine

1639
00:53:46,960 --> 00:53:47,599
learning

1640
00:53:47,599 --> 00:53:48,960
but this is why it's a different

1641
00:53:48,960 --> 00:53:51,520
approach okay

1642
00:53:51,520 --> 00:53:54,559
then um again we don't get g

1643
00:53:54,559 --> 00:53:57,599
uh we or we don't get f we only get g so

1644
00:53:57,599 --> 00:53:58,480
here is another

1645
00:53:58,480 --> 00:54:01,680
phrasing of f that's being played out

1646
00:54:01,680 --> 00:54:04,160
through time

1647
00:54:04,160 --> 00:54:07,440
so here is um building on three and four

1648
00:54:07,440 --> 00:54:09,520
we're looking at the variational free

1649
00:54:09,520 --> 00:54:11,680
energy not just for an instant

1650
00:54:11,680 --> 00:54:14,319
here this is like a kind of timeless

1651
00:54:14,319 --> 00:54:15,760
understanding of free energy you don't

1652
00:54:15,760 --> 00:54:16,319
see t

1653
00:54:16,319 --> 00:54:18,079
in here it's through time with the s

1654
00:54:18,079 --> 00:54:20,240
tilde and the o tilde but it's like

1655
00:54:20,240 --> 00:54:23,520
not a specific times and then this one

1656
00:54:23,520 --> 00:54:24,400
is actually

1657
00:54:24,400 --> 00:54:25,680
a function through time this is

1658
00:54:25,680 --> 00:54:27,760
observation t so this is like

1659
00:54:27,760 --> 00:54:30,000
that specific observation and then

1660
00:54:30,000 --> 00:54:31,040
here's where we see

1661
00:54:31,040 --> 00:54:34,559
the divergence the d distance divergence

1662
00:54:34,559 --> 00:54:37,359
the kl distance between the q and the p

1663
00:54:37,359 --> 00:54:38,160
and those are

1664
00:54:38,160 --> 00:54:40,640
not usually exchangeable so like this

1665
00:54:40,640 --> 00:54:42,880
it's not like driving between two cities

1666
00:54:42,880 --> 00:54:46,160
so this um section again you can

1667
00:54:46,160 --> 00:54:48,079
unpack some of what the equations

1668
00:54:48,079 --> 00:54:49,200
actually say

1669
00:54:49,200 --> 00:54:51,839
but this learning and inference section

1670
00:54:51,839 --> 00:54:52,960
talks about

1671
00:54:52,960 --> 00:54:56,640
how to update or do inference

1672
00:54:56,640 --> 00:54:59,119
do learning based upon the data of these

1673
00:54:59,119 --> 00:55:01,680
parameters

1674
00:55:01,920 --> 00:55:05,040
here is where we get to g so we don't

1675
00:55:05,040 --> 00:55:07,520
get f we only get to estimate g

1676
00:55:07,520 --> 00:55:10,079
so the way i kind of broke this down was

1677
00:55:10,079 --> 00:55:11,440
we want to do more than just

1678
00:55:11,440 --> 00:55:13,200
update our internal model to balance the

1679
00:55:13,200 --> 00:55:14,559
price on observations

1680
00:55:14,559 --> 00:55:16,240
so if all you wanted to do was test

1681
00:55:16,240 --> 00:55:18,640
retest accuracy on an image classifier

1682
00:55:18,640 --> 00:55:19,440
data set

1683
00:55:19,440 --> 00:55:21,040
all you'd have to do would be bound

1684
00:55:21,040 --> 00:55:23,359
surprise on the cross-validated

1685
00:55:23,359 --> 00:55:26,720
versions of that data um or on

1686
00:55:26,720 --> 00:55:30,079
subsample or testing and training splits

1687
00:55:30,079 --> 00:55:31,839
but we want to actually do a few

1688
00:55:31,839 --> 00:55:33,359
different things we want to reduce our

1689
00:55:33,359 --> 00:55:34,799
uncertainty in the future

1690
00:55:34,799 --> 00:55:37,119
so that's tau or the cursive t don't

1691
00:55:37,119 --> 00:55:39,520
know which way you'd say it

1692
00:55:39,520 --> 00:55:41,680
in terms of the policies that we take

1693
00:55:41,680 --> 00:55:43,520
now so it's quite different than just

1694
00:55:43,520 --> 00:55:45,599
minimizing our surprise about a linear

1695
00:55:45,599 --> 00:55:47,599
aggressor given a static data set

1696
00:55:47,599 --> 00:55:49,440
we want to reduce our uncertainty about

1697
00:55:49,440 --> 00:55:51,359
observations in the future

1698
00:55:51,359 --> 00:55:52,799
as a function of the policies we're

1699
00:55:52,799 --> 00:55:56,079
taking now and this minimizable

1700
00:55:56,079 --> 00:55:58,079
this tractable expected free energy

1701
00:55:58,079 --> 00:55:59,680
function g

1702
00:55:59,680 --> 00:56:02,319
takes as arguments policy and the future

1703
00:56:02,319 --> 00:56:03,200
time point

1704
00:56:03,200 --> 00:56:04,880
so as a function of the policies that

1705
00:56:04,880 --> 00:56:07,040
are um available and you know two years

1706
00:56:07,040 --> 00:56:08,160
in the future

1707
00:56:08,160 --> 00:56:11,599
how am i gonna manage certain

1708
00:56:11,599 --> 00:56:13,839
aspects of life and it's gonna be an

1709
00:56:13,839 --> 00:56:14,880
expectation

1710
00:56:14,880 --> 00:56:18,160
that's conditional on um uh

1711
00:56:18,160 --> 00:56:20,319
several things conditional mainly we can

1712
00:56:20,319 --> 00:56:22,319
highlight is conditional on policy

1713
00:56:22,319 --> 00:56:24,400
we're doing an expectation that's

1714
00:56:24,400 --> 00:56:26,240
conditioned on policy because we want to

1715
00:56:26,240 --> 00:56:26,960
know something

1716
00:56:26,960 --> 00:56:28,799
about the states of the world and the

1717
00:56:28,799 --> 00:56:30,640
observations and the estimated states of

1718
00:56:30,640 --> 00:56:32,000
the world as well

1719
00:56:32,000 --> 00:56:35,599
given a policy and then that

1720
00:56:35,599 --> 00:56:38,640
is going to be strictly bigger um and so

1721
00:56:38,640 --> 00:56:39,520
natural log

1722
00:56:39,520 --> 00:56:41,280
that means that it's like basically

1723
00:56:41,280 --> 00:56:43,440
worse in some ways but it depends a lot

1724
00:56:43,440 --> 00:56:44,400
on whether it's like positive or

1725
00:56:44,400 --> 00:56:44,960
negative

1726
00:56:44,960 --> 00:56:47,440
that's kind of confusing stuff sometimes

1727
00:56:47,440 --> 00:56:49,440
um like whether it's a negative log or

1728
00:56:49,440 --> 00:56:51,599
like the subtracting or the positive log

1729
00:56:51,599 --> 00:56:54,240
and what it's always bigger than is the

1730
00:56:54,240 --> 00:56:55,599
negative

1731
00:56:55,599 --> 00:56:58,240
expectations of the observed states in

1732
00:56:58,240 --> 00:56:59,760
the future given a policy me

1733
00:56:59,760 --> 00:57:01,119
here's me observing that i have 50

1734
00:57:01,119 --> 00:57:03,359
bitcoin um

1735
00:57:03,359 --> 00:57:05,839
and that's this part too the p of

1736
00:57:05,839 --> 00:57:07,280
observations given policy

1737
00:57:07,280 --> 00:57:10,000
so what i'd really like to know would be

1738
00:57:10,000 --> 00:57:10,480
uh

1739
00:57:10,480 --> 00:57:12,720
some type of model that just tells me

1740
00:57:12,720 --> 00:57:14,559
what states i can expect

1741
00:57:14,559 --> 00:57:16,720
in the future what observations i can

1742
00:57:16,720 --> 00:57:18,079
expect in the future

1743
00:57:18,079 --> 00:57:20,319
um which relate to the states because of

1744
00:57:20,319 --> 00:57:22,400
the uh estimating the states

1745
00:57:22,400 --> 00:57:24,319
given the observations but here we're

1746
00:57:24,319 --> 00:57:25,359
going for the observations given the

1747
00:57:25,359 --> 00:57:27,440
policy

1748
00:57:27,440 --> 00:57:31,280
and it's the uh log and then

1749
00:57:31,280 --> 00:57:32,799
this last part is kind of the important

1750
00:57:32,799 --> 00:57:34,720
part which is the log of the generative

1751
00:57:34,720 --> 00:57:36,480
model which is the observations given

1752
00:57:36,480 --> 00:57:37,920
the policy that's how things will go

1753
00:57:37,920 --> 00:57:38,400
that's

1754
00:57:38,400 --> 00:57:40,400
well if we take this policy on miles per

1755
00:57:40,400 --> 00:57:42,240
gallon then we will go

1756
00:57:42,240 --> 00:57:44,960
between uh you know 1.5 and 2 degrees

1757
00:57:44,960 --> 00:57:45,760
celsius

1758
00:57:45,760 --> 00:57:47,359
now there's so many degrees of freedom

1759
00:57:47,359 --> 00:57:49,280
that go into that but that's like

1760
00:57:49,280 --> 00:57:51,520
what we'd want to estimate would be

1761
00:57:51,520 --> 00:57:52,480
relating

1762
00:57:52,480 --> 00:57:54,960
how policies literally are going to play

1763
00:57:54,960 --> 00:57:56,079
into observations

1764
00:57:56,079 --> 00:57:57,440
which then tell us about states the

1765
00:57:57,440 --> 00:57:59,599
world estimated like s without a hat

1766
00:57:59,599 --> 00:58:01,440
which should be hopefully related to s

1767
00:58:01,440 --> 00:58:03,200
with a hat the real states of the world

1768
00:58:03,200 --> 00:58:05,200
but still the focus here is on the

1769
00:58:05,200 --> 00:58:06,240
observations

1770
00:58:06,240 --> 00:58:08,720
that are conditioned on policy that kind

1771
00:58:08,720 --> 00:58:10,160
of takes us to

1772
00:58:10,160 --> 00:58:13,520
policy selection and they

1773
00:58:13,520 --> 00:58:15,200
write that policy selection is achieved

1774
00:58:15,200 --> 00:58:16,720
by updating q

1775
00:58:16,720 --> 00:58:20,000
in order to write to minimize f via

1776
00:58:20,000 --> 00:58:23,040
g and the

1777
00:58:23,040 --> 00:58:26,480
uh need for this paper was that

1778
00:58:26,480 --> 00:58:28,319
when you have a short temporal horizon

1779
00:58:28,319 --> 00:58:29,520
you can just run out

1780
00:58:29,520 --> 00:58:31,200
every possible policy like every

1781
00:58:31,200 --> 00:58:33,119
possible set of five chess moves or

1782
00:58:33,119 --> 00:58:34,400
every possible set of all the

1783
00:58:34,400 --> 00:58:35,760
tic-tac-toe moves there can't be more

1784
00:58:35,760 --> 00:58:37,440
than nine moves in a game

1785
00:58:37,440 --> 00:58:39,520
every single step if the branching is

1786
00:58:39,520 --> 00:58:41,520
small and the time horizon is short

1787
00:58:41,520 --> 00:58:44,319
you can evaluate g in full so it becomes

1788
00:58:44,319 --> 00:58:46,559
rather than sampling over a distribution

1789
00:58:46,559 --> 00:58:49,040
literally just calculating a table and

1790
00:58:49,040 --> 00:58:50,559
then sorting

1791
00:58:50,559 --> 00:58:52,559
however when you have deep temporal

1792
00:58:52,559 --> 00:58:54,640
horizons you can't really evaluate the

1793
00:58:54,640 --> 00:58:56,160
full branching tree because there's too

1794
00:58:56,160 --> 00:58:57,040
many options

1795
00:58:57,040 --> 00:58:58,480
so you have to sample from that

1796
00:58:58,480 --> 00:59:00,000
distribution so that's the sampling

1797
00:59:00,000 --> 00:59:00,640
problem

1798
00:59:00,640 --> 00:59:02,400
the second prop and that's the deep

1799
00:59:02,400 --> 00:59:04,240
counterfactual sampling problem which is

1800
00:59:04,240 --> 00:59:05,599
even difficult or

1801
00:59:05,599 --> 00:59:08,160
under uncertainty the second part is the

1802
00:59:08,160 --> 00:59:09,599
mario kart paradigm

1803
00:59:09,599 --> 00:59:11,119
which is that in continuous action

1804
00:59:11,119 --> 00:59:13,680
spaces there are infinite policies

1805
00:59:13,680 --> 00:59:15,359
meaning that some other way is going to

1806
00:59:15,359 --> 00:59:16,720
have to come into play because

1807
00:59:16,720 --> 00:59:19,680
not just are we sampling uh deep through

1808
00:59:19,680 --> 00:59:20,400
time

1809
00:59:20,400 --> 00:59:22,400
we're sampling potentially related to

1810
00:59:22,400 --> 00:59:24,160
counterfactuals which there's infinite

1811
00:59:24,160 --> 00:59:25,359
counter factuals

1812
00:59:25,359 --> 00:59:26,880
and we're talking about continuous

1813
00:59:26,880 --> 00:59:28,480
action spaces where there's infinite

1814
00:59:28,480 --> 00:59:29,359
policies

1815
00:59:29,359 --> 00:59:31,760
so if my only trading affordances are

1816
00:59:31,760 --> 00:59:32,720
should i have

1817
00:59:32,720 --> 00:59:35,920
zero or one or two bitcoin then

1818
00:59:35,920 --> 00:59:37,440
i could ask which one of those three

1819
00:59:37,440 --> 00:59:39,359
options discreetly is better

1820
00:59:39,359 --> 00:59:40,960
but if there's infinite and i can do

1821
00:59:40,960 --> 00:59:43,040
continuous variables

1822
00:59:43,040 --> 00:59:45,520
uh even smaller than one you know

1823
00:59:45,520 --> 00:59:47,640
breakdowns like then should i do

1824
00:59:47,640 --> 00:59:49,920
1.0001 what if that's very different

1825
00:59:49,920 --> 00:59:51,680
than 1.0002

1826
00:59:51,680 --> 00:59:52,880
now you might say well those two should

1827
00:59:52,880 --> 00:59:54,400
be super similar and you should be able

1828
00:59:54,400 --> 00:59:55,680
just to sample every

1829
00:59:55,680 --> 00:59:57,040
little interval and estimate the

1830
00:59:57,040 --> 00:59:58,960
distribution right

1831
00:59:58,960 --> 01:00:01,440
if it's a smooth distribution then it's

1832
01:00:01,440 --> 01:00:03,040
going to be easy to optimize maybe you

1833
01:00:03,040 --> 01:00:04,240
could discretize it

1834
01:00:04,240 --> 01:00:05,760
maybe you could do some other way to do

1835
01:00:05,760 --> 01:00:08,559
smooth optimization but the problem is

1836
01:00:08,559 --> 01:00:11,599
actions and policies are not smooth so

1837
01:00:11,599 --> 01:00:13,119
maybe if you're going into that turn in

1838
01:00:13,119 --> 01:00:14,240
mario kart

1839
01:00:14,240 --> 01:00:17,040
you could aim at the corner and just try

1840
01:00:17,040 --> 01:00:18,480
to take it as fast as you can

1841
01:00:18,480 --> 01:00:20,400
or you could slow down and do a slightly

1842
01:00:20,400 --> 01:00:22,079
different angle or you could do some

1843
01:00:22,079 --> 01:00:23,599
other skidding maneuver

1844
01:00:23,599 --> 01:00:25,920
so there's multiple separate ways that

1845
01:00:25,920 --> 01:00:27,119
you're going to be able to take this

1846
01:00:27,119 --> 01:00:27,599
turn

1847
01:00:27,599 --> 01:00:29,040
potentially with different risks and

1848
01:00:29,040 --> 01:00:31,119
reward and they're all very nuanced

1849
01:00:31,119 --> 01:00:34,240
so that is why the deep through time and

1850
01:00:34,240 --> 01:00:35,920
counter factual aspects

1851
01:00:35,920 --> 01:00:37,920
respectively uh which aren't as much

1852
01:00:37,920 --> 01:00:39,359
dealt with here at counterfactuals but

1853
01:00:39,359 --> 01:00:41,280
through time absolutely is

1854
01:00:41,280 --> 01:00:43,280
and then the continuous actions which is

1855
01:00:43,280 --> 01:00:44,640
really the key

1856
01:00:44,640 --> 01:00:47,599
introduction of this model that takes it

1857
01:00:47,599 --> 01:00:49,119
out of the paradigm of

1858
01:00:49,119 --> 01:00:51,680
classifying images and puts it into the

1859
01:00:51,680 --> 01:00:52,559
paradigm of

1860
01:00:52,559 --> 01:00:55,200
continuous control theory and then it

1861
01:00:55,200 --> 01:00:56,480
turns out that

1862
01:00:56,480 --> 01:00:58,319
there's a lot of trajectories through

1863
01:00:58,319 --> 01:01:00,480
time given how things can go

1864
01:01:00,480 --> 01:01:04,160
and so there's some uh implementation of

1865
01:01:04,160 --> 01:01:05,200
a way to sample

1866
01:01:05,200 --> 01:01:08,640
trajectories that is utilizing what's

1867
01:01:08,640 --> 01:01:11,200
called a monte carlo sampling approach

1868
01:01:11,200 --> 01:01:15,280
or mc and uh there's the markov chain

1869
01:01:15,280 --> 01:01:19,200
monte carlo sampling m c m c m c squared

1870
01:01:19,200 --> 01:01:22,480
um and monte carlo just means that it's

1871
01:01:22,480 --> 01:01:24,720
uh related to monte carlo being a card

1872
01:01:24,720 --> 01:01:25,520
playing

1873
01:01:25,520 --> 01:01:28,559
reference in english and it's like the

1874
01:01:28,559 --> 01:01:30,079
way that you can shuffle a deck is so

1875
01:01:30,079 --> 01:01:30,799
big

1876
01:01:30,799 --> 01:01:32,319
how are you gonna estimate the number of

1877
01:01:32,319 --> 01:01:34,319
ways that you can get a royal flush or a

1878
01:01:34,319 --> 01:01:36,240
pair of fours or something like that

1879
01:01:36,240 --> 01:01:37,920
instead of just actually doing well it's

1880
01:01:37,920 --> 01:01:41,280
1 in 24 times 1 and 52 times 3 over 52.

1881
01:01:41,280 --> 01:01:43,280
the way you do it is you just sample

1882
01:01:43,280 --> 01:01:44,880
randomly and then you say okay i took a

1883
01:01:44,880 --> 01:01:46,240
billion samples and

1884
01:01:46,240 --> 01:01:48,559
1 million of them had this feature and

1885
01:01:48,559 --> 01:01:50,000
then you just take the ratio as your

1886
01:01:50,000 --> 01:01:51,680
estimate so it's a sampling and that

1887
01:01:51,680 --> 01:01:52,160
kind of

1888
01:01:52,160 --> 01:01:54,160
harkens back to earlier where we wanted

1889
01:01:54,160 --> 01:01:55,760
to talk about getting the efficient

1890
01:01:55,760 --> 01:01:56,880
sampling because that's kind of what

1891
01:01:56,880 --> 01:01:57,599
it's about

1892
01:01:57,599 --> 01:02:00,559
is in the markov or sorry in the monte

1893
01:02:00,559 --> 01:02:01,119
carlo

1894
01:02:01,119 --> 01:02:02,400
sampler which could be markov chain

1895
01:02:02,400 --> 01:02:04,640
based we want to get

1896
01:02:04,640 --> 01:02:06,160
good sampling we don't want to sample

1897
01:02:06,160 --> 01:02:08,400
only the hands with a royal flush

1898
01:02:08,400 --> 01:02:10,960
like if we had a poor randomizer because

1899
01:02:10,960 --> 01:02:12,240
then we're going to get an estimate

1900
01:02:12,240 --> 01:02:13,359
that's wrong

1901
01:02:13,359 --> 01:02:15,839
all right then they go into a little bit

1902
01:02:15,839 --> 01:02:17,039
more detail

1903
01:02:17,039 --> 01:02:20,240
about the g the estimated or the

1904
01:02:20,240 --> 01:02:21,440
expected free energy

1905
01:02:21,440 --> 01:02:23,839
which is still as it was before about

1906
01:02:23,839 --> 01:02:25,359
policy in the future

1907
01:02:25,359 --> 01:02:28,799
and now it's going to be uh this

1908
01:02:28,799 --> 01:02:31,119
broken down and this is also where they

1909
01:02:31,119 --> 01:02:32,319
draw some of the homologies to

1910
01:02:32,319 --> 01:02:33,520
reinforcement learning

1911
01:02:33,520 --> 01:02:37,119
and info gain into the uh

1912
01:02:37,119 --> 01:02:39,039
the informational gain kind of like the

1913
01:02:39,039 --> 01:02:40,640
reward and the info

1914
01:02:40,640 --> 01:02:43,200
so this is where the explore exploit

1915
01:02:43,200 --> 01:02:44,720
also comes into play

1916
01:02:44,720 --> 01:02:48,240
which is that if one is only optimizing

1917
01:02:48,240 --> 01:02:50,240
locally

1918
01:02:50,240 --> 01:02:51,680
they may be exploiting they may be

1919
01:02:51,680 --> 01:02:53,039
getting reward for a short period of

1920
01:02:53,039 --> 01:02:54,319
time but then it doesn't lead

1921
01:02:54,319 --> 01:02:57,359
to a um like

1922
01:02:57,359 --> 01:02:59,200
we'll see in the hill climber example

1923
01:02:59,200 --> 01:03:00,720
but if you just reward

1924
01:03:00,720 --> 01:03:02,799
only and only exploit sometimes you

1925
01:03:02,799 --> 01:03:04,079
don't do very well but if you just

1926
01:03:04,079 --> 01:03:04,640
explore

1927
01:03:04,640 --> 01:03:06,400
you might not ever get to exploit

1928
01:03:06,400 --> 01:03:08,880
anywhere good and so the whole trade-off

1929
01:03:08,880 --> 01:03:10,720
and the whole challenge of modeling is

1930
01:03:10,720 --> 01:03:13,039
this balance between explore and exploit

1931
01:03:13,039 --> 01:03:15,760
between searching deeply and searching

1932
01:03:15,760 --> 01:03:16,559
broadly

1933
01:03:16,559 --> 01:03:19,280
and so the holy grail would be the right

1934
01:03:19,280 --> 01:03:19,839
way

1935
01:03:19,839 --> 01:03:21,839
to search deeply down the routes that

1936
01:03:21,839 --> 01:03:23,760
are interesting and informative

1937
01:03:23,760 --> 01:03:25,599
but not down the ones that don't tell

1938
01:03:25,599 --> 01:03:27,520
you that much but we don't know which

1939
01:03:27,520 --> 01:03:29,520
paths are going to be informative or not

1940
01:03:29,520 --> 01:03:32,079
until we go down them however if we have

1941
01:03:32,079 --> 01:03:33,599
a deep generative model

1942
01:03:33,599 --> 01:03:36,079
we can say in terms of me winning this

1943
01:03:36,079 --> 01:03:37,200
chess game

1944
01:03:37,200 --> 01:03:39,599
this branch is not informative for me to

1945
01:03:39,599 --> 01:03:40,400
search down

1946
01:03:40,400 --> 01:03:41,920
not because there aren't trillions of

1947
01:03:41,920 --> 01:03:44,559
options but because i have two castles

1948
01:03:44,559 --> 01:03:45,760
and they have no pieces

1949
01:03:45,760 --> 01:03:47,440
other than their king so i'm gonna win

1950
01:03:47,440 --> 01:03:48,960
so in terms of me winning

1951
01:03:48,960 --> 01:03:50,880
it doesn't give me any information to

1952
01:03:50,880 --> 01:03:52,480
keep on searching down that route i

1953
01:03:52,480 --> 01:03:54,079
already know i'm gonna win

1954
01:03:54,079 --> 01:03:55,920
and then there might be another avenue

1955
01:03:55,920 --> 01:03:57,920
where there's fewer options per se like

1956
01:03:57,920 --> 01:03:58,880
less branching

1957
01:03:58,880 --> 01:04:00,880
but there's more uncertainty that's

1958
01:04:00,880 --> 01:04:03,599
resolvable more infogaine is possible

1959
01:04:03,599 --> 01:04:06,960
with respect to the policies and winning

1960
01:04:06,960 --> 01:04:08,400
all right let's just do a little bit on

1961
01:04:08,400 --> 01:04:10,000
the experiments before we close out so

1962
01:04:10,000 --> 01:04:11,359
the two experiments that they

1963
01:04:11,359 --> 01:04:13,440
go into so hopefully all of you

1964
01:04:13,440 --> 01:04:14,559
experimentalists

1965
01:04:14,559 --> 01:04:16,799
um buy sasha um hopefully all you

1966
01:04:16,799 --> 01:04:18,640
experimentalists will like this part

1967
01:04:18,640 --> 01:04:20,240
and the two examples are the mountain

1968
01:04:20,240 --> 01:04:21,920
car and the uh

1969
01:04:21,920 --> 01:04:23,680
inverted pendulum task and the hopper

1970
01:04:23,680 --> 01:04:26,000
task so the mountain car

1971
01:04:26,000 --> 01:04:28,079
is an example of exploration so what's

1972
01:04:28,079 --> 01:04:29,119
being learnt

1973
01:04:29,119 --> 01:04:32,240
is the policy between position and

1974
01:04:32,240 --> 01:04:33,359
velocity

1975
01:04:33,359 --> 01:04:35,599
and then getting higher up the reward

1976
01:04:35,599 --> 01:04:37,039
function is like getting higher up and

1977
01:04:37,039 --> 01:04:37,359
so

1978
01:04:37,359 --> 01:04:38,559
the car doesn't have a strong enough

1979
01:04:38,559 --> 01:04:40,480
engine just to drive up to the flag so

1980
01:04:40,480 --> 01:04:41,359
it's going to drive up

1981
01:04:41,359 --> 01:04:43,200
and then the perfect policy would be

1982
01:04:43,200 --> 01:04:44,559
right when you're stopped

1983
01:04:44,559 --> 01:04:46,559
flip the engine into reverse and keep in

1984
01:04:46,559 --> 01:04:48,319
reverse until you stop on this side

1985
01:04:48,319 --> 01:04:49,760
and then get a little bit higher up this

1986
01:04:49,760 --> 01:04:51,520
way but this shows you why you can't

1987
01:04:51,520 --> 01:04:53,599
locally optimize why you need to explore

1988
01:04:53,599 --> 01:04:54,640
because let's just say you're driving

1989
01:04:54,640 --> 01:04:55,760
uphill you're slowing down you're

1990
01:04:55,760 --> 01:04:56,799
slowing down

1991
01:04:56,799 --> 01:04:58,319
you start slipping back slipping back

1992
01:04:58,319 --> 01:04:59,839
and you're like no stay on the gas

1993
01:04:59,839 --> 01:05:02,160
continue accelerating forward now you're

1994
01:05:02,160 --> 01:05:03,599
slowing your descent

1995
01:05:03,599 --> 01:05:05,200
so when you get to here you're not

1996
01:05:05,200 --> 01:05:07,039
moving that fast

1997
01:05:07,039 --> 01:05:08,960
so then when you're on this side you'd

1998
01:05:08,960 --> 01:05:10,079
say no no i still want to get to the

1999
01:05:10,079 --> 01:05:10,960
flag

2000
01:05:10,960 --> 01:05:12,720
and so you end up just sort of like

2001
01:05:12,720 --> 01:05:14,720
being very shallow down and focusing a

2002
01:05:14,720 --> 01:05:16,240
lot of your time here

2003
01:05:16,240 --> 01:05:18,480
on the um middle and on the right side

2004
01:05:18,480 --> 01:05:19,520
so if you just

2005
01:05:19,520 --> 01:05:21,520
simply move towards the flag you're

2006
01:05:21,520 --> 01:05:22,960
probably not going to get there

2007
01:05:22,960 --> 01:05:25,119
if the engine is too weak however if you

2008
01:05:25,119 --> 01:05:27,119
actually say i want to explore i want a

2009
01:05:27,119 --> 01:05:29,119
policy that helps me increase my

2010
01:05:29,119 --> 01:05:31,280
range so i want to go as far as i can

2011
01:05:31,280 --> 01:05:33,039
here and then wow if i enact a policy

2012
01:05:33,039 --> 01:05:34,799
where as soon as i hit my maxima i just

2013
01:05:34,799 --> 01:05:35,599
try to explore

2014
01:05:35,599 --> 01:05:37,599
further this way and then i enact a

2015
01:05:37,599 --> 01:05:39,359
policy switch and go back to going this

2016
01:05:39,359 --> 01:05:40,240
way wow

2017
01:05:40,240 --> 01:05:42,480
i might actually reach the goal purely

2018
01:05:42,480 --> 01:05:44,079
as a function of exploring

2019
01:05:44,079 --> 01:05:46,400
now again this is like a little model

2020
01:05:46,400 --> 01:05:47,440
situation

2021
01:05:47,440 --> 01:05:49,680
where it turns out that exploring does

2022
01:05:49,680 --> 01:05:51,280
help one realize

2023
01:05:51,280 --> 01:05:53,039
the goal that's not always the case but

2024
01:05:53,039 --> 01:05:55,599
it isolates that feature of the model

2025
01:05:55,599 --> 01:05:58,400
needing to be able to explore the second

2026
01:05:58,400 --> 01:05:58,880
case

2027
01:05:58,880 --> 01:06:01,039
in the exploit paradigms it's usually a

2028
01:06:01,039 --> 01:06:02,079
little bit more obvious

2029
01:06:02,079 --> 01:06:05,119
what needs to be exploited and about

2030
01:06:05,119 --> 01:06:07,200
whether you're doing it well or not so

2031
01:06:07,200 --> 01:06:08,880
in the inverted pendulum task it's like

2032
01:06:08,880 --> 01:06:10,160
a railroad car

2033
01:06:10,160 --> 01:06:13,200
on a rail and there's a heavy ball m

2034
01:06:13,200 --> 01:06:15,359
that's on top of this pendulum that's

2035
01:06:15,359 --> 01:06:16,319
inverted

2036
01:06:16,319 --> 01:06:18,880
and then the car can like move backwards

2037
01:06:18,880 --> 01:06:19,680
and that kind of

2038
01:06:19,680 --> 01:06:21,440
moves this joint to the left and that

2039
01:06:21,440 --> 01:06:23,359
pushes the um pendulum

2040
01:06:23,359 --> 01:06:25,039
in this case would straighten it out

2041
01:06:25,039 --> 01:06:26,720
whereas if this car starts taking off to

2042
01:06:26,720 --> 01:06:27,359
the right

2043
01:06:27,359 --> 01:06:29,119
then this pendulum is just going to fall

2044
01:06:29,119 --> 01:06:30,640
and so the reward is the height of the

2045
01:06:30,640 --> 01:06:32,400
pendulum so it's trying to maximize its

2046
01:06:32,400 --> 01:06:33,119
reward

2047
01:06:33,119 --> 01:06:35,440
by enacting a policy and so the policy

2048
01:06:35,440 --> 01:06:36,559
that's best

2049
01:06:36,559 --> 01:06:38,240
would be to keep on exploiting that

2050
01:06:38,240 --> 01:06:40,000
perfectly straight up line where you

2051
01:06:40,000 --> 01:06:41,520
actually are in the zone of optimal

2052
01:06:41,520 --> 01:06:42,559
control

2053
01:06:42,559 --> 01:06:44,640
and then the exploit task on the right

2054
01:06:44,640 --> 01:06:45,680
is about

2055
01:06:45,680 --> 01:06:47,520
increasing the distance that's traveled

2056
01:06:47,520 --> 01:06:49,119
by a little jumping

2057
01:06:49,119 --> 01:06:50,880
thing does anyone else have any like

2058
01:06:50,880 --> 01:06:52,720
thoughts on explore exploit

2059
01:06:52,720 --> 01:06:55,440
or um what what else does that yeah go

2060
01:06:55,440 --> 01:06:57,839
ahead blue

2061
01:06:58,559 --> 01:07:00,880
so this i thought was super interesting

2062
01:07:00,880 --> 01:07:02,640
um as i was unpacking

2063
01:07:02,640 --> 01:07:05,920
this paper so and

2064
01:07:05,920 --> 01:07:07,440
maybe i should just kind of like lay a

2065
01:07:07,440 --> 01:07:08,880
little bit of this out there so the

2066
01:07:08,880 --> 01:07:09,680
reward

2067
01:07:09,680 --> 01:07:13,359
is only given in this extrinsic

2068
01:07:13,359 --> 01:07:15,520
value which is like the exploit portion

2069
01:07:15,520 --> 01:07:17,280
of the free energy equation

2070
01:07:17,280 --> 01:07:20,559
like given in number six and so you know

2071
01:07:20,559 --> 01:07:21,599
i don't know you didn't say it

2072
01:07:21,599 --> 01:07:23,359
explicitly but like here in the

2073
01:07:23,359 --> 01:07:24,240
exploration

2074
01:07:24,240 --> 01:07:28,079
experiments the reward just uses that

2075
01:07:28,079 --> 01:07:30,799
um exploit parameter and doesn't do any

2076
01:07:30,799 --> 01:07:32,079
exploration based

2077
01:07:32,079 --> 01:07:34,880
on state or parameter information gain

2078
01:07:34,880 --> 01:07:35,359
and then

2079
01:07:35,359 --> 01:07:37,920
in the exploit task it only uses that

2080
01:07:37,920 --> 01:07:39,839
exploitation parameter

2081
01:07:39,839 --> 01:07:43,680
so like there's no need for exploration

2082
01:07:43,680 --> 01:07:44,799
i just thought that that was super

2083
01:07:44,799 --> 01:07:46,079
interesting and like what would happen

2084
01:07:46,079 --> 01:07:47,839
if they included exploration

2085
01:07:47,839 --> 01:07:51,280
in this explore in the exploitation um

2086
01:07:51,280 --> 01:07:53,119
paradigm so like why did they leave that

2087
01:07:53,119 --> 01:07:55,440
out like it was just kind of weird to me

2088
01:07:55,440 --> 01:07:57,119
well good question like that makes me

2089
01:07:57,119 --> 01:07:58,880
think about let's say there's some parts

2090
01:07:58,880 --> 01:07:59,920
of the railroad track

2091
01:07:59,920 --> 01:08:03,039
where it's different angles and so

2092
01:08:03,039 --> 01:08:05,039
yes you want to maintain the pendulum

2093
01:08:05,039 --> 01:08:07,119
being upright but also you might want to

2094
01:08:07,119 --> 01:08:08,640
explore around a little bit

2095
01:08:08,640 --> 01:08:10,720
to find a region where you can control

2096
01:08:10,720 --> 01:08:11,839
it better so that actually makes me

2097
01:08:11,839 --> 01:08:13,200
think of like doing a track stand on my

2098
01:08:13,200 --> 01:08:14,240
bicycle

2099
01:08:14,240 --> 01:08:16,238
there's some times where there's some

2100
01:08:16,238 --> 01:08:18,000
slopes of pavement that are easy to do a

2101
01:08:18,000 --> 01:08:19,520
track stand on and some are really hard

2102
01:08:19,520 --> 01:08:20,319
to do it

2103
01:08:20,319 --> 01:08:22,158
but the way you get from a hard position

2104
01:08:22,158 --> 01:08:23,679
into an easier part of payment you have

2105
01:08:23,679 --> 01:08:25,120
to explore and that means breaking the

2106
01:08:25,120 --> 01:08:25,920
track stand

2107
01:08:25,920 --> 01:08:29,198
so definitely real control tasks

2108
01:08:29,198 --> 01:08:30,640
are related to the combination of

2109
01:08:30,640 --> 01:08:32,560
explore and exploit why did they use

2110
01:08:32,560 --> 01:08:33,439
these two

2111
01:08:33,439 --> 01:08:35,679
i think that the reason why and let's

2112
01:08:35,679 --> 01:08:38,238
hear from alec as to the real answer

2113
01:08:38,238 --> 01:08:40,719
is that these are part of the open ai

2114
01:08:40,719 --> 01:08:41,839
benchmarking

2115
01:08:41,839 --> 01:08:45,520
set of like little micro computable

2116
01:08:45,520 --> 01:08:47,920
benchmarks for learning algorithms

2117
01:08:47,920 --> 01:08:49,198
here's the open eye

2118
01:08:49,198 --> 01:08:51,759
ai um let's see if we can even open it

2119
01:08:51,759 --> 01:08:52,560
here yeah

2120
01:08:52,560 --> 01:08:55,439
so like here's their website and uh

2121
01:08:55,439 --> 01:08:56,000
there's

2122
01:08:56,000 --> 01:09:00,238
a bunch of uh documentable cases

2123
01:09:00,238 --> 01:09:03,279
that allow comparison between different

2124
01:09:03,279 --> 01:09:05,279
machine learning algorithms and so i

2125
01:09:05,279 --> 01:09:06,640
think they're just outlining

2126
01:09:06,640 --> 01:09:09,198
the minimal single dimensional like sort

2127
01:09:09,198 --> 01:09:10,238
of extreme

2128
01:09:10,238 --> 01:09:12,719
classic test cases there's a ton of

2129
01:09:12,719 --> 01:09:13,920
cases where we can already see it

2130
01:09:13,920 --> 01:09:15,359
wouldn't work like a double pendulum

2131
01:09:15,359 --> 01:09:16,560
that's chaotic or

2132
01:09:16,560 --> 01:09:17,759
there's other kinds of things that this

2133
01:09:17,759 --> 01:09:20,158
model just doesn't even try to do

2134
01:09:20,158 --> 01:09:22,799
but this allows us to directly compare

2135
01:09:22,799 --> 01:09:23,198
two

2136
01:09:23,198 --> 01:09:26,238
other algorithms on the exact same task

2137
01:09:26,238 --> 01:09:27,759
instead of inventing something that

2138
01:09:27,759 --> 01:09:29,359
would like either

2139
01:09:29,359 --> 01:09:31,359
not take advantage of active inferences

2140
01:09:31,359 --> 01:09:33,040
strength or

2141
01:09:33,040 --> 01:09:35,600
be like kind of an unfair example by

2142
01:09:35,600 --> 01:09:36,640
making it

2143
01:09:36,640 --> 01:09:39,839
too nuanced like if we added in a reward

2144
01:09:39,839 --> 01:09:42,080
another type of something that a

2145
01:09:42,080 --> 01:09:44,000
generative model could take advantage of

2146
01:09:44,000 --> 01:09:46,158
then we couldn't compare it to some of

2147
01:09:46,158 --> 01:09:47,359
these other agents that don't use that

2148
01:09:47,359 --> 01:09:49,198
kind of information

2149
01:09:49,198 --> 01:09:51,040
is that i just think they were using the

2150
01:09:51,040 --> 01:09:52,319
minimal case to ex

2151
01:09:52,319 --> 01:09:53,759
to demonstrate what explore and exploit

2152
01:09:53,759 --> 01:09:55,600
could look like and then future work

2153
01:09:55,600 --> 01:09:56,719
hopefully would be about

2154
01:09:56,719 --> 01:09:59,120
things that involve both right and so i

2155
01:09:59,120 --> 01:10:01,040
get that and but it just was

2156
01:10:01,040 --> 01:10:03,440
like interesting to me then i guess

2157
01:10:03,440 --> 01:10:04,320
because

2158
01:10:04,320 --> 01:10:07,679
the there's no reward in the exploit

2159
01:10:07,679 --> 01:10:08,640
parameter

2160
01:10:08,640 --> 01:10:10,320
that that's why they had to keep the

2161
01:10:10,320 --> 01:10:12,800
exploit parameter in the explore task

2162
01:10:12,800 --> 01:10:14,480
do you know what i mean like what i just

2163
01:10:14,480 --> 01:10:15,760
wonder what would be the results if you

2164
01:10:15,760 --> 01:10:16,080
took

2165
01:10:16,080 --> 01:10:18,320
out the exploit parameter from the

2166
01:10:18,320 --> 01:10:20,080
explore task would it then not succeed

2167
01:10:20,080 --> 01:10:21,280
because it just would wander around

2168
01:10:21,280 --> 01:10:22,000
aimlessly

2169
01:10:22,000 --> 01:10:23,920
or would wandering around aimlessly or

2170
01:10:23,920 --> 01:10:25,920
like without a reward to get higher

2171
01:10:25,920 --> 01:10:27,600
would that just produce like a random

2172
01:10:27,600 --> 01:10:29,679
result do you see what i mean i see what

2173
01:10:29,679 --> 01:10:30,239
you mean

2174
01:10:30,239 --> 01:10:33,040
so there's there's one there's one

2175
01:10:33,040 --> 01:10:34,480
driving strategy

2176
01:10:34,480 --> 01:10:37,440
where it's truly just making policy

2177
01:10:37,440 --> 01:10:39,600
that's unrelated to its elevation

2178
01:10:39,600 --> 01:10:43,280
and um that depending on how that plays

2179
01:10:43,280 --> 01:10:44,000
out it might get

2180
01:10:44,000 --> 01:10:46,480
somewhere it might not most likely not

2181
01:10:46,480 --> 01:10:48,080
because the space of the strategies with

2182
01:10:48,080 --> 01:10:49,520
relationship to getting the flag is

2183
01:10:49,520 --> 01:10:52,719
low but yes i i i agree that's an

2184
01:10:52,719 --> 01:10:54,000
interesting question like

2185
01:10:54,000 --> 01:10:57,440
when is it enough to just explore

2186
01:10:57,440 --> 01:11:00,080
like when is novelty search simply

2187
01:11:00,080 --> 01:11:00,960
enough

2188
01:11:00,960 --> 01:11:03,040
when my novelty search be strictly the

2189
01:11:03,040 --> 01:11:04,080
best

2190
01:11:04,080 --> 01:11:06,800
when my novelty search eighty percent

2191
01:11:06,800 --> 01:11:07,120
plus

2192
01:11:07,120 --> 01:11:08,480
twenty percent let's keep a little

2193
01:11:08,480 --> 01:11:10,400
reminder of our elevation when might

2194
01:11:10,400 --> 01:11:11,040
that be

2195
01:11:11,040 --> 01:11:13,840
relevant and tractable strategy which

2196
01:11:13,840 --> 01:11:14,800
parts of these

2197
01:11:14,800 --> 01:11:17,920
explore and exploit are calculatable for

2198
01:11:17,920 --> 01:11:18,480
example

2199
01:11:18,480 --> 01:11:21,040
it might make sense to evaluate or

2200
01:11:21,040 --> 01:11:21,679
exploit

2201
01:11:21,679 --> 01:11:24,800
a current distributional value but

2202
01:11:24,800 --> 01:11:27,120
how do we explore the space of economic

2203
01:11:27,120 --> 01:11:28,480
strategies like

2204
01:11:28,480 --> 01:11:30,719
i can't explore every single possible

2205
01:11:30,719 --> 01:11:32,480
economic strategy but i might be able to

2206
01:11:32,480 --> 01:11:33,120
exploit

2207
01:11:33,120 --> 01:11:35,679
some ratio by doing arbitrage so there's

2208
01:11:35,679 --> 01:11:37,360
some control tasks where

2209
01:11:37,360 --> 01:11:38,800
the exploitation is really

2210
01:11:38,800 --> 01:11:40,400
straightforward and visible and the

2211
01:11:40,400 --> 01:11:41,600
exploration's hard and then there's

2212
01:11:41,600 --> 01:11:42,880
other ones where

2213
01:11:42,880 --> 01:11:44,880
maybe this car can't see the flag so

2214
01:11:44,880 --> 01:11:46,480
maybe exploring is the only thing it can

2215
01:11:46,480 --> 01:11:47,199
do

2216
01:11:47,199 --> 01:11:49,760
and so the really great question those

2217
01:11:49,760 --> 01:11:50,560
are kind of

2218
01:11:50,560 --> 01:11:52,159
interesting about these things being

2219
01:11:52,159 --> 01:11:53,760
traded off so there's the explore

2220
01:11:53,760 --> 01:11:55,120
exploit trade-off

2221
01:11:55,120 --> 01:11:56,880
and how that gets implemented there's

2222
01:11:56,880 --> 01:11:58,239
also the model

2223
01:11:58,239 --> 01:12:00,880
adequacy minus complexity which is we

2224
01:12:00,880 --> 01:12:02,960
want a good model but not too complex or

2225
01:12:02,960 --> 01:12:04,000
over fit one

2226
01:12:04,000 --> 01:12:05,840
so there's no a priori best way to trade

2227
01:12:05,840 --> 01:12:07,120
off those two

2228
01:12:07,120 --> 01:12:10,560
and then um there there's just all these

2229
01:12:10,560 --> 01:12:11,520
interesting

2230
01:12:11,520 --> 01:12:13,440
trade-offs that we can explore the space

2231
01:12:13,440 --> 01:12:15,120
of let's just look at what the results

2232
01:12:15,120 --> 01:12:15,600
were

2233
01:12:15,600 --> 01:12:17,440
so here the x axis is like where

2234
01:12:17,440 --> 01:12:18,880
positions is from

2235
01:12:18,880 --> 01:12:22,159
the other side farther to um 0.5 which i

2236
01:12:22,159 --> 01:12:23,840
guess could be the flag

2237
01:12:23,840 --> 01:12:26,239
or at least close to it i try to line it

2238
01:12:26,239 --> 01:12:26,880
up maybe it's

2239
01:12:26,880 --> 01:12:28,640
the other way or something like that but

2240
01:12:28,640 --> 01:12:30,239
we can see that the position of the

2241
01:12:30,239 --> 01:12:31,199
greedy

2242
01:12:31,199 --> 01:12:33,040
agent who just drives up up up up and

2243
01:12:33,040 --> 01:12:35,280
says no and then just goes up

2244
01:12:35,280 --> 01:12:38,800
no this one stays tightly bounded

2245
01:12:38,800 --> 01:12:42,000
in a medium velocity uh regime

2246
01:12:42,000 --> 01:12:44,800
and within a sort of sampling a ton from

2247
01:12:44,800 --> 01:12:46,080
this part of the distribution

2248
01:12:46,080 --> 01:12:47,199
think about that like an upside down

2249
01:12:47,199 --> 01:12:49,199
bell curve and it's like sampling a ton

2250
01:12:49,199 --> 01:12:50,800
from right here but it's not sampling

2251
01:12:50,800 --> 01:12:52,719
from up here so that's how there's a

2252
01:12:52,719 --> 01:12:53,920
relationship between sampling and

2253
01:12:53,920 --> 01:12:54,640
control

2254
01:12:54,640 --> 01:12:56,080
because to get to certain states it's

2255
01:12:56,080 --> 01:12:57,920
like sampling those states

2256
01:12:57,920 --> 01:13:01,280
the epsilon uh greedy agent which has a

2257
01:13:01,280 --> 01:13:02,880
slightly different implementation

2258
01:13:02,880 --> 01:13:05,920
it does sometimes appear to get outside

2259
01:13:05,920 --> 01:13:06,400
maybe

2260
01:13:06,400 --> 01:13:08,080
by the end if it's 100 epochs it was

2261
01:13:08,080 --> 01:13:09,760
starting to take some

2262
01:13:09,760 --> 01:13:12,239
trips out further but and at slightly

2263
01:13:12,239 --> 01:13:12,880
higher

2264
01:13:12,880 --> 01:13:15,360
uh speeds and slightly further out but

2265
01:13:15,360 --> 01:13:16,719
it doesn't spend most of its time doing

2266
01:13:16,719 --> 01:13:17,360
so

2267
01:13:17,360 --> 01:13:19,520
the active inference learner of course

2268
01:13:19,520 --> 01:13:20,480
they wrote the paper

2269
01:13:20,480 --> 01:13:21,679
so it's going to be the one that

2270
01:13:21,679 --> 01:13:23,520
succeeds but it does

2271
01:13:23,520 --> 01:13:25,600
in 100 epochs learn very fast and it

2272
01:13:25,600 --> 01:13:27,280
does get to some pretty high speeds and

2273
01:13:27,280 --> 01:13:27,840
some pretty

2274
01:13:27,840 --> 01:13:30,800
distant positions and then just briefly

2275
01:13:30,800 --> 01:13:32,880
to like compare it with the other

2276
01:13:32,880 --> 01:13:36,480
task the two exploit tasks

2277
01:13:36,480 --> 01:13:38,640
are laid out here and they are comparing

2278
01:13:38,640 --> 01:13:40,239
it to this ddpg

2279
01:13:40,239 --> 01:13:43,280
agent which is a model free learner and

2280
01:13:43,280 --> 01:13:45,360
so people can look into details or one

2281
01:13:45,360 --> 01:13:46,719
could imagine that maybe there's other

2282
01:13:46,719 --> 01:13:48,159
algorithms they could test it against

2283
01:13:48,159 --> 01:13:49,520
these are all the kinds of things we can

2284
01:13:49,520 --> 01:13:50,719
ask alec about

2285
01:13:50,719 --> 01:13:53,520
but we can see that um a which is the

2286
01:13:53,520 --> 01:13:54,320
same as c

2287
01:13:54,320 --> 01:13:57,600
c is just the first part of a i just

2288
01:13:57,600 --> 01:13:59,280
zoomed in on really close

2289
01:13:59,280 --> 01:14:01,840
but it's like right away in both of

2290
01:14:01,840 --> 01:14:03,360
these after either like

2291
01:14:03,360 --> 01:14:05,920
five epochs like five trials five

2292
01:14:05,920 --> 01:14:06,800
seconds

2293
01:14:06,800 --> 01:14:10,800
or um after maybe 30 or 40 or 50

2294
01:14:10,800 --> 01:14:12,480
the active inference learner just starts

2295
01:14:12,480 --> 01:14:14,400
to take off in terms of

2296
01:14:14,400 --> 01:14:17,040
once it's hit on a solution sometimes it

2297
01:14:17,040 --> 01:14:17,600
just

2298
01:14:17,600 --> 01:14:20,159
it strictly improves it with some noise

2299
01:14:20,159 --> 01:14:21,120
whereas

2300
01:14:21,120 --> 01:14:24,480
the ddpg the two things that you see are

2301
01:14:24,480 --> 01:14:26,320
first off it spends a ton of time near

2302
01:14:26,320 --> 01:14:27,199
the baseline

2303
01:14:27,199 --> 01:14:29,199
so it takes a while before it locks on

2304
01:14:29,199 --> 01:14:32,400
to any useful combination of parameters

2305
01:14:32,400 --> 01:14:35,440
and then when it gets off baseline

2306
01:14:35,440 --> 01:14:38,719
it ends up um sometimes succeeding

2307
01:14:38,719 --> 01:14:42,080
but still um it's like

2308
01:14:42,080 --> 01:14:43,760
perhaps because it's locally optimizing

2309
01:14:43,760 --> 01:14:45,360
or we can ask why it is

2310
01:14:45,360 --> 01:14:47,920
but they're just not sampling highly

2311
01:14:47,920 --> 01:14:49,360
rewarding states

2312
01:14:49,360 --> 01:14:50,880
even after it gets off the baseline it

2313
01:14:50,880 --> 01:14:52,480
does stay off baseline but it doesn't

2314
01:14:52,480 --> 01:14:54,000
ever get as high as the active inference

2315
01:14:54,000 --> 01:14:54,719
learner does

2316
01:14:54,719 --> 01:14:57,120
extremely rapidly so this is kind of

2317
01:14:57,120 --> 01:14:57,840
where they're

2318
01:14:57,840 --> 01:15:00,400
drawing their evidence for the claims

2319
01:15:00,400 --> 01:15:01,120
about

2320
01:15:01,120 --> 01:15:04,159
the potential superiority or preference

2321
01:15:04,159 --> 01:15:05,440
for active inference

2322
01:15:05,440 --> 01:15:08,239
now yes you could probably train a ddpg

2323
01:15:08,239 --> 01:15:10,400
on some massive data set and get better

2324
01:15:10,400 --> 01:15:12,000
performance than they got they probably

2325
01:15:12,000 --> 01:15:13,120
just used a

2326
01:15:13,120 --> 01:15:15,760
straightforward implementation so that's

2327
01:15:15,760 --> 01:15:17,199
where research happens

2328
01:15:17,199 --> 01:15:19,360
that's what people study is okay well

2329
01:15:19,360 --> 01:15:21,840
can we do a dd pg whatever that is

2330
01:15:21,840 --> 01:15:23,920
plus this other feature that is being

2331
01:15:23,920 --> 01:15:26,480
used by this other group or

2332
01:15:26,480 --> 01:15:28,480
what is it that's actually causing the

2333
01:15:28,480 --> 01:15:29,840
active inference learner to get off the

2334
01:15:29,840 --> 01:15:31,280
ground so fast and

2335
01:15:31,280 --> 01:15:32,880
could we even get it off the ground

2336
01:15:32,880 --> 01:15:35,040
faster in the case of this hopper task

2337
01:15:35,040 --> 01:15:35,600
or

2338
01:15:35,600 --> 01:15:38,239
could we make a more reliable reward

2339
01:15:38,239 --> 01:15:40,400
function for the inverted pendulum task

2340
01:15:40,400 --> 01:15:42,800
but this is control theory at its finest

2341
01:15:42,800 --> 01:15:44,480
really and so this is what it's all

2342
01:15:44,480 --> 01:15:44,960
about

2343
01:15:44,960 --> 01:15:47,760
is learning policies that map states

2344
01:15:47,760 --> 01:15:48,719
onto reward

2345
01:15:48,719 --> 01:15:50,400
so those are the key pieces that's why

2346
01:15:50,400 --> 01:15:52,080
we spent so much time talking about the

2347
01:15:52,080 --> 01:15:54,239
equations that are relating between

2348
01:15:54,239 --> 01:15:56,960
observations state estimates and

2349
01:15:56,960 --> 01:15:58,080
policies

2350
01:15:58,080 --> 01:16:00,800
because that's what it's all about is

2351
01:16:00,800 --> 01:16:02,480
the observations coming in

2352
01:16:02,480 --> 01:16:04,960
and then the policies being selected

2353
01:16:04,960 --> 01:16:06,480
based upon the estimated states of the

2354
01:16:06,480 --> 01:16:07,040
world

2355
01:16:07,040 --> 01:16:09,120
and then actions coming out that's the

2356
01:16:09,120 --> 01:16:10,159
markov blanket

2357
01:16:10,159 --> 01:16:12,320
of the organism's perspective at least

2358
01:16:12,320 --> 01:16:13,840
and then outside

2359
01:16:13,840 --> 01:16:16,000
uh world in these examples is simple and

2360
01:16:16,000 --> 01:16:17,920
unchanging like gravity is gravity for

2361
01:16:17,920 --> 01:16:19,280
the pendulum and for the hopper

2362
01:16:19,280 --> 01:16:21,360
and it's not changing but we can start

2363
01:16:21,360 --> 01:16:23,040
to think about well what if there was

2364
01:16:23,040 --> 01:16:26,159
a diurnal gravity rhythm

2365
01:16:26,159 --> 01:16:27,920
how would the control theory change well

2366
01:16:27,920 --> 01:16:29,679
there could be a generative model

2367
01:16:29,679 --> 01:16:32,719
in the agent's control uh mapping of

2368
01:16:32,719 --> 01:16:33,199
those

2369
01:16:33,199 --> 01:16:35,679
p and q that involve some sort of is it

2370
01:16:35,679 --> 01:16:36,719
day or night and then i have a

2371
01:16:36,719 --> 01:16:38,239
conditional policy whether i think it's

2372
01:16:38,239 --> 01:16:39,920
day or night so we can kind of

2373
01:16:39,920 --> 01:16:42,640
see how it starts adding layers there

2374
01:16:42,640 --> 01:16:43,840
and

2375
01:16:43,840 --> 01:16:47,120
yeah that's basically it

2376
01:16:47,120 --> 01:16:49,440
but let's have any last thoughts does

2377
01:16:49,440 --> 01:16:50,480
anyone like

2378
01:16:50,480 --> 01:16:52,880
what was something cool or unexpected

2379
01:16:52,880 --> 01:16:54,640
what's something they'd like to ask alec

2380
01:16:54,640 --> 01:16:55,280
about

2381
01:16:55,280 --> 01:16:57,440
or that they're curious to learn more

2382
01:16:57,440 --> 01:17:03,839
about now

2383
01:17:06,960 --> 01:17:10,159
chill oh shannon go ahead

2384
01:17:10,159 --> 01:17:12,719
hey um yeah so i was thinking about um

2385
01:17:12,719 --> 01:17:13,760
blue's question

2386
01:17:13,760 --> 01:17:17,120
and why not use the um exploration

2387
01:17:17,120 --> 01:17:18,239
component in these

2388
01:17:18,239 --> 01:17:21,040
inverted pendulum and hopper tasks and

2389
01:17:21,040 --> 01:17:22,800
wouldn't it be

2390
01:17:22,800 --> 01:17:24,960
because there's kind of only one state

2391
01:17:24,960 --> 01:17:27,040
that is maximum reward so for completely

2392
01:17:27,040 --> 01:17:27,600
vertical

2393
01:17:27,600 --> 01:17:30,400
or if we hop as far as possible but if

2394
01:17:30,400 --> 01:17:31,120
there were

2395
01:17:31,120 --> 01:17:33,280
potential states that would have

2396
01:17:33,280 --> 01:17:36,560
differing values of reward then we might

2397
01:17:36,560 --> 01:17:39,040
expect to see something different if we

2398
01:17:39,040 --> 01:17:39,760
use the

2399
01:17:39,760 --> 01:17:42,400
the exploration component of the active

2400
01:17:42,400 --> 01:17:43,679
reference model

2401
01:17:43,679 --> 01:17:46,400
great point like if it were a bimodal

2402
01:17:46,400 --> 01:17:47,520
distribution

2403
01:17:47,520 --> 01:17:49,840
then you can't just try to keep it as

2404
01:17:49,840 --> 01:17:52,159
close to the maximum height as possible

2405
01:17:52,159 --> 01:17:53,440
because you wouldn't know if you were

2406
01:17:53,440 --> 01:17:55,199
locally optimizing or

2407
01:17:55,199 --> 01:17:57,520
globally optimizing and you might want

2408
01:17:57,520 --> 01:17:58,880
to be sampling across the whole

2409
01:17:58,880 --> 01:18:00,159
distribution just so

2410
01:18:00,159 --> 01:18:02,159
you know or you might want to spend a

2411
01:18:02,159 --> 01:18:04,239
lot of time at rewarding states but

2412
01:18:04,239 --> 01:18:04,719
still

2413
01:18:04,719 --> 01:18:06,000
have some understanding of the total

2414
01:18:06,000 --> 01:18:07,520
distribution to understand if there

2415
01:18:07,520 --> 01:18:08,159
might be

2416
01:18:08,159 --> 01:18:09,440
more rewarding states that you're just

2417
01:18:09,440 --> 01:18:12,480
not visiting at all that is the whole

2418
01:18:12,480 --> 01:18:13,920
challenge of local and global

2419
01:18:13,920 --> 01:18:14,960
optimization

2420
01:18:14,960 --> 01:18:16,560
and so you're right that in this

2421
01:18:16,560 --> 01:18:18,239
mountain car example

2422
01:18:18,239 --> 01:18:20,320
local optimization is global you're

2423
01:18:20,320 --> 01:18:21,600
going to get to the best flag

2424
01:18:21,600 --> 01:18:24,239
just by ex by you know so to speak i

2425
01:18:24,239 --> 01:18:25,679
know this was in the explore

2426
01:18:25,679 --> 01:18:27,679
strategy but in this one it's clear as

2427
01:18:27,679 --> 01:18:29,199
you brought up if you're

2428
01:18:29,199 --> 01:18:30,560
having the pendulum at the maximum

2429
01:18:30,560 --> 01:18:32,239
height you're simply doing as well as

2430
01:18:32,239 --> 01:18:32,640
you can

2431
01:18:32,640 --> 01:18:34,239
period you don't need to explore other

2432
01:18:34,239 --> 01:18:36,320
ways you could do a loop-de-loop and

2433
01:18:36,320 --> 01:18:38,080
that's the challenge though is you gotta

2434
01:18:38,080 --> 01:18:39,600
you gotta walk through the valley of

2435
01:18:39,600 --> 01:18:40,320
death

2436
01:18:40,320 --> 01:18:42,080
to get from the local optima to the

2437
01:18:42,080 --> 01:18:45,120
global and that's where these algorithms

2438
01:18:45,120 --> 01:18:48,239
uh dare not tread because they have to

2439
01:18:48,239 --> 01:18:48,640
walk

2440
01:18:48,640 --> 01:18:51,760
through improbable or non-preferable

2441
01:18:51,760 --> 01:18:54,400
like moving away from your target states

2442
01:18:54,400 --> 01:18:56,560
in order to get to the next peak which

2443
01:18:56,560 --> 01:18:58,719
might be absolutely higher

2444
01:18:58,719 --> 01:19:01,679
in the exploit paradigm or might reveal

2445
01:19:01,679 --> 01:19:04,320
new territory in the explore paradigm

2446
01:19:04,320 --> 01:19:05,920
so there's reasons why you want to get

2447
01:19:05,920 --> 01:19:08,239
through the valley of low likelihood

2448
01:19:08,239 --> 01:19:10,239
whether you're exploring or exploiting

2449
01:19:10,239 --> 01:19:12,000
or a combination

2450
01:19:12,000 --> 01:19:13,840
and that is where there's so many

2451
01:19:13,840 --> 01:19:15,360
options there's so many weeds and

2452
01:19:15,360 --> 01:19:17,040
tangles in the valley

2453
01:19:17,040 --> 01:19:18,480
that the way that we're going to cut

2454
01:19:18,480 --> 01:19:21,120
through it with a machete is infogain

2455
01:19:21,120 --> 01:19:22,800
and we're going to explore paths through

2456
01:19:22,800 --> 01:19:25,199
the valley that are the most informative

2457
01:19:25,199 --> 01:19:26,159
for us

2458
01:19:26,159 --> 01:19:28,640
given our understanding of our own

2459
01:19:28,640 --> 01:19:29,920
policies

2460
01:19:29,920 --> 01:19:32,239
and so that's like if you have a 4x4

2461
01:19:32,239 --> 01:19:33,199
versus

2462
01:19:33,199 --> 01:19:35,600
a small team versus you're a drone

2463
01:19:35,600 --> 01:19:38,080
different policies different affordances

2464
01:19:38,080 --> 01:19:39,679
mean that you're going to be exploring

2465
01:19:39,679 --> 01:19:41,280
this valley differently

2466
01:19:41,280 --> 01:19:42,880
and then there's whether you're

2467
01:19:42,880 --> 01:19:44,880
exploring for the sake of exploring and

2468
01:19:44,880 --> 01:19:46,239
learning new turf or whether you're

2469
01:19:46,239 --> 01:19:47,760
exploiting because you just want to have

2470
01:19:47,760 --> 01:19:49,840
a high elevation or whether it's a

2471
01:19:49,840 --> 01:19:50,960
little of both

2472
01:19:50,960 --> 01:19:53,600
those are all some nuance you can add in

2473
01:19:53,600 --> 01:19:55,760
but the insight of active inference is

2474
01:19:55,760 --> 01:19:56,239
like

2475
01:19:56,239 --> 01:19:58,239
let's actually think about what would be

2476
01:19:58,239 --> 01:20:00,080
informative trajectories to take through

2477
01:20:00,080 --> 01:20:01,360
that valley

2478
01:20:01,360 --> 01:20:03,199
based upon a generative model of the

2479
01:20:03,199 --> 01:20:04,719
landscape and

2480
01:20:04,719 --> 01:20:06,880
taking our own policy affordances into

2481
01:20:06,880 --> 01:20:08,320
account if you don't have a generative

2482
01:20:08,320 --> 01:20:09,440
model landscape

2483
01:20:09,440 --> 01:20:10,639
you're going to be doing something like

2484
01:20:10,639 --> 01:20:12,639
locally just going downhill or locally

2485
01:20:12,639 --> 01:20:13,440
going uphill

2486
01:20:13,440 --> 01:20:15,040
so you need a deeper generative model

2487
01:20:15,040 --> 01:20:16,719
landscape and if you don't take your

2488
01:20:16,719 --> 01:20:18,639
affordances into account

2489
01:20:18,639 --> 01:20:20,639
then you're lost because you might be

2490
01:20:20,639 --> 01:20:22,639
unknowingly optimizing something that's

2491
01:20:22,639 --> 01:20:23,199
going to be

2492
01:20:23,199 --> 01:20:25,920
appropriate for you know the drone to

2493
01:20:25,920 --> 01:20:27,360
fly over but then you're on the ground

2494
01:20:27,360 --> 01:20:28,960
so you actually can't make it up that

2495
01:20:28,960 --> 01:20:29,520
hill

2496
01:20:29,520 --> 01:20:30,960
but it's a policy that might work for a

2497
01:20:30,960 --> 01:20:33,040
different organism and it's just not the

2498
01:20:33,040 --> 01:20:34,320
one that works for you i know we're kind

2499
01:20:34,320 --> 01:20:35,760
of like mixing metaphors but i think

2500
01:20:35,760 --> 01:20:36,400
it's a fun

2501
01:20:36,400 --> 01:20:38,639
way to think about these optimizations

2502
01:20:38,639 --> 01:20:41,440
because we are implementing a control

2503
01:20:41,440 --> 01:20:42,960
process something that we modeled with

2504
01:20:42,960 --> 01:20:44,880
control theory and then also we're

2505
01:20:44,880 --> 01:20:46,480
seeing it play out in like a very

2506
01:20:46,480 --> 01:20:47,920
abstract computational

2507
01:20:47,920 --> 01:20:52,719
framework here cool

2508
01:20:52,719 --> 01:20:55,520
yep so then they talk about the

2509
01:20:55,520 --> 01:20:57,040
relationship with previous work i think

2510
01:20:57,040 --> 01:20:58,320
i'll just put it on the screen people

2511
01:20:58,320 --> 01:20:58,880
can

2512
01:20:58,880 --> 01:21:01,360
um pause it if they want to look but

2513
01:21:01,360 --> 01:21:03,520
with that i'll just say thanks to

2514
01:21:03,520 --> 01:21:07,280
our cohort here for participating super

2515
01:21:07,280 --> 01:21:09,920
interesting stuff and next week we hope

2516
01:21:09,920 --> 01:21:10,800
to have alec

2517
01:21:10,800 --> 01:21:14,480
on to discuss some of these questions so

2518
01:21:14,480 --> 01:21:16,239
you can check the calendar event to

2519
01:21:16,239 --> 01:21:17,760
provide a follow-up

2520
01:21:17,760 --> 01:21:19,679
survey where you can add some details

2521
01:21:19,679 --> 01:21:20,880
how could we improve or

2522
01:21:20,880 --> 01:21:22,639
what questions would you like to hear

2523
01:21:22,639 --> 01:21:24,480
conveyed in 8.2

2524
01:21:24,480 --> 01:21:26,480
and for those who are not participating

2525
01:21:26,480 --> 01:21:28,560
live please provide us with feedback or

2526
01:21:28,560 --> 01:21:29,440
suggestions or

2527
01:21:29,440 --> 01:21:32,800
questions that we can cover and just

2528
01:21:32,800 --> 01:21:35,440
stay in touch but that was really great

2529
01:21:35,440 --> 01:21:36,159
so thanks

2530
01:21:36,159 --> 01:21:41,839
a lot everyone for the discussion

