SPEAKER_01:
Hello everyone.

This is ACT-INF Lab live stream number 40.2 on March 24th, 2022.

Welcome to the ACT-INF Lab.

We're a participatory online lab that is communicating, learning, and practicing applied active inference.

This is a recorded and an archived live stream, so please provide us with feedback so we can improve our work, hear about your QRF,

All backgrounds and perspectives are welcome.

We may actually have to change this to all QRF are welcome.

And we'll follow video etiquette for live streams.

Check out activeinference.org to learn more about the activities in the lab.

Today in 40.2, we are continuing to learn and discuss this awesome paper, A Free Energy Principle for Generic Quantum Systems by Fields, Friston, Glazebrook and Levin.

And we're really appreciative to have several of the authors joining us today.

In this dot two, we're just going to have introductions and then jump right in to several of the notes that we left for ourself from last time and see where else it goes.

And anyone can write a comment in the live chat and we'll just say hello again.

pick up with some threads that were left unspooled in the dot one and see where we get in the dot two and how we continue going forward.

So I'm Daniel, I'm a researcher in California and I will pass it to Dean.


SPEAKER_02:
Good morning.

My name's Dean.

I'm in Calgary in Canada.

My emphasis, I think, is on the practice part of active inference and seeing how it gets applied in different contexts and situations.

I'll pass it to Blue.


SPEAKER_05:
I'm Blue Knight.

I'm an independent researcher in New Mexico.

And I will be facilitating the discussion today.

But let me pass it off to Steven.

He's still here.

Steven, are you here?

Oh, you're muted, Steven.

We still don't hear you.


SPEAKER_01:
Okay.

Thanks, Steven.

We'll continue on to Dave.


SPEAKER_05:
Dave, I don't see.


SPEAKER_01:
Also left.

Okay.


SPEAKER_05:
Okay.

Let's continue.

Let's pass it on to the authors we go.

So let's pass it to Mike first, since you have audio this time.


SPEAKER_00:
Yes, hi, yep, this is Mike Levin.

I do biology at Tufts, trying to understand what living systems are doing at all scales and how intelligence manifests in various unconventional embodiments across, and they compete and cooperate across scales to give us the amazing phenomena we see in biology.


SPEAKER_05:
Awesome, thank you.

Dave, would you like to say hello, introduce yourself?

Maybe no audio also.

OK.

How about Carl?

Would you like to say hello?


SPEAKER_04:
Yes, I would.

Hello.

I'm Carl.

I'm one of the co-authors on the paper.

I'm a neuroscientist from London.

I have to confess I'm a bit of a passenger and admirer of this paper.

So I'm here to learn as much as to answer questions.

So I'll pass it on to Chris, who's


SPEAKER_03:
Hi, I'm Chris Fields.

I'm also an independent researcher working sort of on the boundaries between physics and biology and information science and sort of convinced that those are all three the same actual discipline.

So this is a paper that expands on that theme a little bit.


SPEAKER_05:
Great.

Thank you.

So I think where we left off last time was talking about how the FEP is asymptotically the principle of unitarity.

And maybe, Chris, would you mind leading us off here?

And if you want to point out a specific maybe formalism or place where we should start?

I think it was the very last formalism in the paper, actually.

But maybe if you would talk us through that, that would be super appreciated.


SPEAKER_03:
Okay.

Well, let's talk first informally just about the motivation for this idea and how it might make sense intuitively.

And again, I'll go back to...

Carl's paper from 2019, Free Energy Principle for a Particular Physics, which the current paper is obviously modeled after in a certain way.

And as we discussed last time, I think, what Carl was able to show in Particular Physics was that the idea, the very intuitive idea of a thing,

of something that exists and importantly maintains its identity as a single system over time.

And what that means is that it can be measured by some other system.

And it can be measured repeatedly and reliably

over time by some other system.

So thingness is associated with repeated measurability.

And what Carl was able to show in particular physics was that if we assume that something is a thing, then we're effectively assuming that it has a stable non-equilibrium steady state density, and therefore we're assuming that it has a Markov blanket.

And therefore we can treat it as implementing active inference, as constantly predicting its own future existence and behaving so as to make that prediction come true to the extent that it can.

And such behavior may be prevented or overcome by its environment

So the environment of something may cause it to cease to exist.

The thing could be a marble sitting on a table and its environment could include a sledgehammer that's about to come down on top of it and destroy its thingness.

But as long as the environment doesn't do that,

the object can continue to execute active inference and maintain its Markov blanket by so doing.

And of course its Markov blanket is what defines it as a separate entity, as a thing that's distinct from its environment.

So let's translate all of that into quantum theory.

In quantum theory, we have this notion of interaction as measurement already.

And we have a notion of interaction as information exchange already.

So it's very natural to take this whole picture and make the notion of measurement over time precise in this, using this quantum theoretic formalism

And quantum theory also gives us a very natural implementation of a Markov blanket, which in physics is called a holographic screen.

And holographic screens were introduced back in the 70s to talk about black holes.

But a holographic screen is just a reformulation of the concept of a Markov blanket.

It's a boundary that encodes information.

And specifically, it's a boundary between two systems that encodes all of the information that one system can have about the other.

It does just what a Markov blanket does.

It provides an information encoding boundary that gives the systems on the two sides of it identities for each other by distinguishing them.

And this notion of identity in quantum theory corresponds to separability.

Separability just means lack of entanglement.

So if the joint, if you have two things,

or a thing in its environment, then if they're not entangled, you can talk about their states independently.

If they are entangled, then you can't talk about their states independently.

And so the idea of thingness goes away since thingness implies having some sort of conditionally independent state, right?

A nest density that can actually be written down.

So all of this fits together rather nicely.

And so if we go back to particular physics, the idea of active inference emerges from that paper as a fundamental underlying principle of physics that

that tells us what we mean by thing or system that's identifiable over time.

So this becomes a very deep principle, deeper than Newton's laws, because Newton's laws actually talk about objects that are identifiable over time.

The free energy principle and the idea of active inference tells us what we mean when we talk about something being identifiable over time.

So if this is a fundamental principle of physics, then one would expect that it would have some relationship to the principle of unitarity.

which is the most fundamental principle of quantum theory.

And it's typically axiom one, when one writes down the axioms of quantum theory, was axiom one in von Neumann's formulation back in the 30s.

Or 40s, I can't remember which.

So what's the principle of unitarity?

The principle of unitarity is just the principle that in a closed system, information is conserved.

So information is neither created nor destroyed in a closed system.

So it's a fundamental conservation law, and it's exactly analogous to the principle of conservation of energy.

The conservation of energy says, in a closed system, energy is neither created nor destroyed.

It's conserved.

So the principle of unitarity just says this for information as well as energy.

And we know that information and energy are very closely linked by Landauer's principle or by Boltzmann's definition of entropy or all of these other connections that make physics informational.

So...

How does the principle of active inference relate to the principle of unitarity?

What does it say about the conservation of information?

Or what does the conservation of information tell us about the principle of active inference or the free energy principle?

Well, the first thing to note is that unitarity applies to closed systems.

So thing-environment pairs.

And active inference characterizes what the thing is doing in response to its environment.

And of course, it also characterizes what the environment is doing in response to the thing.

And another benefit of quantum theory is that it makes this symmetry between any system and its environment manifest, makes it very explicit.

But it's already explicit in the free energy principle.

I mean, the Markov blanket has two sides.

And the system acting on its environment is the same as the environment sensing the system.

And in the same way that the environment acting on the system is the same as the system sensing its environment.

So physical interaction is information exchange in both frameworks.

And it's perfectly symmetrical.

If the system remains identifiable over time, so does its environment.

To exist, its environment ceases to exist because its environment is defined with respect to it.

That's why we call it its environment.

So all of these symmetries are built into both frameworks.

So the free energy principle is fundamentally about prediction, right?

VFE, variational free energy, can be thought of as prediction error or potential prediction error.

So the free energy principle is about the system being able to predict

next state of its own Markov blanket.

And if it predicts the next state of its own Markov blanket perfectly, then VFE is minimized to zero.

And that's the asymptotic case.

Perfect prediction.

There was a question last time about what's asymptotic in the claim that

The free energy principle is asymptotically the principle of unitarity.

And the asymptotic state, as I think Blue pointed out last time, is perfect prediction.

So now let's translate all this to quantum theory.

And this is where the figure in the paper that shows the disk with the various triangles comes into play.

I think that's figure six, but I've actually forgotten.

Yeah, it's that one.

So let's now introduce this idea of a QRF, which is just a little package of predictive capability.

QRF means quantum reference frame.

As we discussed last time, a reference frame is implemented computation that makes a measurement comparable across time.

So a meter stick, for example, implements a computation of length, and it allows us to compare measurements of length across time because we assume that it's fixed.

And of course, we can use a meter stick because each of us has embedded in our brains a representation of length.

In fact, we have a representation of a 3D coordinate system.

without which meter sticks would be useless.

So we can use external reference frames like meter sticks because we have internal reference frames like our representation of 3D space and our intuitive understanding of length that we assume stays fixed over time and that allows our measurements of length to be comparable across time for us.

So now let's think about a QRF as a way of something that implements active inference or that enables a system to implement active inference by allowing it to compare its measurements over time.

Prediction is meaningless if you can't compare your measurements over time.

So let's ask, what would it be like for a system to be able to perfectly predict the next state of its Markov blanket?

The next state of its Markov blanket is a state that its environment has written by acting on it.

So

Our question of perfect prediction is, what would it be like for a system to be able to perfectly predict the next actions of its environment?

And notice that the system isn't predicting the next state of its environment.

It doesn't know the state of its environment.

State of its environment's on the other side of the Markov blanket.

What it's trying to predict is the next action of its environment on it, which is the only action of its environment that's relevant.

And the only action of the environment that's detectable.

So its environment, like it, is characterized by QRFs, right?

The situation is perfectly symmetrical between the system and its environment.

So the question of predicting its environment, and the system can predict its environment's actions perfectly

only if it and the environment exactly share their qrfs because the qrf not only interprets sensation it gives meaning to action so it says what your action is going to be so if i use my meter stick to cut a 2x4

My QRF, the meter stick, is guiding my action.

It's giving it meaning.

It's making it repeatable in the same way that it makes my perceptions repeatable.

And again, that's why we use these things.

We want to be able to act in repeatable ways as well as proceed in repeatable ways.

And if we can't act in repeatable ways, then again, the notion of prediction becomes meaningless.

Perfect prediction corresponds to perfect QRF alignment.

So the question becomes now, what does perfect QRF alignment correspond to?

And Jim Glazebrook and another colleague, Antonino Marciano, who's a physicist in Shanghai, showed in a previous paper that perfect QRF

Perfect QRF alignment between a system and its environment is only possible if the system and environment are entangled.

So perfect QRF alignment corresponds actually to the collapse of the Markov blanket because it corresponds to the collapse of separability, which means that the Ness is no longer well-defined.

because it's no longer a conditionally independent state.

And you can see that if you think of what perfect QRF alignment means.

It means that your actions correspond exactly to my predictions.

A conditional statement, it's an exact statement.

So if I predict that you're going to do X, then you're going to do X, period.

Which means that your state is no longer independent of my state.

Your state actually depends on my state.

And my state correspondingly actually depends on your state.

If you predict that I'm going to do X, then I will do X. That's what perfect prediction means.

when we translate it into this QRF-based concept.

So perfect prediction and the collapse of separability are the same thing.

So the asymptotic limit of the FEP, which is perfect prediction, corresponds to the collapse of separability.

Well, the collapse of separability is just entanglement.

And the principle of unitarity is the claim that any isolated system, left to its own devices, will evolve its state, which is the joint state of any two of its components, will evolve toward complete entanglement.

It will evolve toward a pure state

in quantum theoretic jargon.

So it's in this sense that the FEP is asymptotically the principle of unitarity.

It's that its asymptotic condition is the same as the condition that the principle of unitarity imposes on closed systems, i.e.

on system-environment combinations, where

Whenever I say environment, I just mean everything that exists that's not the system of interest.

So a system environment combination is always a closed system by definition.

So that's my introduction and we can start on discussion.


SPEAKER_05:
That's great.

Thank you.

Stephen, did you have a question?


SPEAKER_07:
Yes, you can hear me okay.

Excellent.

I was just going to ask, that's really helpful.

There's a lot in there, obviously.

I was going to ask, in terms of the pure unitarity, would that be what happens, say, at the electron or the kind of these normal quantum particle scales?

And as you go to scales above that, it becomes more and more approximate.

You have less of this...

isotropic, you know, this quality of knowing and entanglement?


SPEAKER_03:
Well, that's a very deep question.

And it's a very good question.

Let's think about the canonical entanglement experiment, the sort of Bell EPR experiment.

So I'll draw it with my hands here.

So in the canonical experiment, you've got a source, and it's located here in the middle of my face.

And it produces an entangled pair of something, photons or electrons or buckyballs or whatever you want.

And they travel apart at the speed of light or something very close to it.

And at some point,

they encounter two symmetrically placed detectors and the detectors are operated by observers who are always called Alice and Bob.

And these detectors measure something and in the canonical experiment they measure spin.

And what Alice and Bob each observe independently is a random distribution of spins.

And if we think of this as a two-dimensional experiment, then they either measure spin up or spin down in some coordinate systems.

So Alice and Bob each pick a z-axis that defines up, and with respect to their local z-axis, they see a random distribution of up and down.

Now, things get interesting.

when Alice and Bob later get together and compare their results.

And what they find is that whenever Alice observes up, Bob observes down and vice versa.

And so they conclude that their results are classically correlated.

But then it gets more interesting because what we allow Alice and Bob to do

is constantly alter the direction that they detect the spin in with respect to their own local z-axis.

So you can think of the spin detector as like a polarization filter, so like a pair of sunglasses.

And what Alice and Bob can do is randomly and independently change the tilt of their sunglasses

while they do this experiment.

And in real implementations of this experiment, first implemented by Alan Aspect in his lab in Paris in the early 1970s.

And it's since been repeated probably hundreds of times by different groups all over the world, including the Chinese using a satellite to generate the entangled pairs and measuring them thousands of, a thousand or so kilometers apart.

So if you remember the speed of lights, a foot per nanosecond.

So you've got a lot of nanoseconds in there if you're a thousand kilometers apart to play with.

And the

So the trick in this experiment is that Alice and Bob can change the direction of their detector within the time it takes for the entangled pair to get from the source to the detectors.

So if it takes 10 nanoseconds to get from the source to the detectors, they have to be able to change their detectors within 10 nanoseconds.

So that's why you want detectors that are far apart.

So Alice and Bob redo the experiment, randomly changing the directions that they're measuring with respect to their local z-axis.

And then they get together again to compare their results.

And what they find is that if Alice observes up, Bob will observe down.

even when they've been randomly and independently changing the directions of their detectors.

So one way to put that is if Alice decides to rotate her detector 45 degrees, then Bob's result will automatically be rotated 45 degrees.

And it's symmetrical, and vice versa.

So that's not classical correlation.

That's classical correlation that's robust against manipulation.

So I was discussing this with Carl a while back, and I used this example.

If you and I are classically correlated, then we may have the same beliefs about something.

So we might both believe that the earth is round.

That's classical correlation.

Now suppose someone convinces me that the earth is flat.

If that happens and you then believe that the earth is flat, that's entanglement.

That's classical correlation that's robust against manipulation.

So it's correlation, no kidding.

Correlation that survives the environment doing something to you.

And... So...

Now let's go back to this question.

Is this an effect that only occurs in some microscopic domain?

And the answer is it's an effect that was first described by a theory that was intended to only describe a microscopic domain.

Like quantum theory was developed to deal with nuclear and atomic and nuclear physics.

And so there's this idea of the quantum world, which is very small.

But the math, of course, applies across the board.

And trying to think of quantum, trying to think of classical physics as a limit, a mathematical limit of quantum theory always runs into problems.

And the problems are always that numbers go to infinity that shouldn't be infinity.

So it's not really accurate to think of classical physics as some sort of mathematical limit like h-bar goes to zero of quantum theory, because if h-bar goes to zero, lots of relevant energies go to infinity.

And this has been known for a long time.

Nonetheless, it's constantly taught in this classical limit kind of

framework that isn't really correct.

So one point of doing Bell EPR experiments at larger and larger distances is to demonstrate that quantum theory is not really a microscopic theory.

So if you think of an entangled state, an entangled state is one object.

It's not two electrons that happen to have some mysterious relationship.

It's one object that has one state.

Remember what entanglement means is non-separability, non-independence across any decompositional boundary.

So an entangled pair is one thing.

And what the Chinese were able to demonstrate

was you can have one quantum object that's over 1,000 kilometers long.

Now, that's not microscopic.

That's big.

A nice way to think about entanglement was introduced by Leonard Susskind quite a few years ago and Rafael Busa with their idea that an entangled pair is the same thing as an Einstein-Rosen bridge in spacetime.

And an Einstein-Rosen bridge is a black hole and a white hole connected end to end.

Or you can think of it that way.

It's a topological connection in spacetime that simply identifies two points in spacetime that would otherwise be considered distinct.

So this emphasizes that if you have an entangled pair, there's no distance inside it.

if you have two entangled electrons, for example, that are a thousand kilometers apart, as far as they're concerned, they're right next to each other.

And in fact, as far as they're concerned, they're located at exactly the same point in space time.

And that's what this ER bridge notion emphasizes to us.

There's really no separation here, that the separation is an artifact of our observational capabilities.

It's not a characteristic of the entangled state.

So entanglement actually calls into question what the idea of distance even means.

It makes it, it forces it to be relative to us.

And that's why there's all this discussion of emergent space time in quantum gravity, quantum cosmology.

Because if you think about things from a straight quantum theory point of view,

space-time is an observable.

It's just something that's relative to how an observation is made.

It's not an intrinsic property of anything.

It's not ontic, as they say.

So let's go back to this question again.

If we think about entanglement and we think about observations,

And we think about entanglement as something that's observed by comparing observations made by different observers.

Neither Alice nor Bob in that experiment can detect entanglement.

They only realize that there's an entangled state when they talk to each other after they've done the experiment.

Then this question of scale

becomes a question about how observers interact and what observers can know about each other and about each other's experimental apparatus.

So when I described the entanglement experiment, I said Alice and Bob each have their own local z-axis.

And when they get together and they discuss their results,

and they compare their results, then they make a very important assumption, which is the assumption that their z-axes are comparable.

So if during the experiment Bob's z-axis was varying at random with respect to Alice's z-axis, then comparing their results would be meaningless because they'd be measured with respect to completely different reference frames.

So we have to make this assumption that they have the same z-axis.

Now, interestingly enough, that assumption by itself tells you that Alice and Bob have to be entangled, or their z-axes have to be entangled.

So the idea of entanglement kind of

expands to take in all aspects of the experimental situation as soon as one starts unearthing these assumptions that we make to talk about comparability between experiments.

So let's reel the tape back about half an hour

And we see that quantum reference frames are what make experiments comparable for an observer.

It's similarity or comparability of quantum reference frames that make comparing experiments possible for two observers.

But if the two observers exactly share their QRFs,

in a way that's robust against environmental manipulation, then they're entangled.

So we've kind of come full circle here.

One can make this notion of entanglement as macroscopic as one likes.

And again, this is, in a sense, why quantum gravity and quantum cosmology are interesting.

It's what drives things like the black hole information paradox, which you may have read about.

So we're now getting into, in a sense, very fundamental physics.

What's the relationship between entanglement and the concept of space-time?

What's the relationship between quantum theory and general relativity?

which is the big question in physics from one point of view.

But the short answer is you can make entanglement as big as you want.


SPEAKER_05:
That's great, thank you.

That actually leads into a question that I had way back when we were talking about entanglement and quantum reference frames.

So I was just thinking like, if I cannot perfectly predict my own behavior,

Is my quantum reference frame, like, incompletely aligned with my own quantum reference frame?

Like, I mean, maybe we've all had the experience of, you know, predicting if I kick a ball in this way, I predict it'll go over there.

But, like, it doesn't actually go over there.

So, like, I mean, we predict and we're off.

Our prediction is not accurate.

So is it, like, actually a temporal separation that, like, makes that happen?

Or what do you think...

happens in those circumstances where my QRF appears unaligned with my own QRF.


SPEAKER_03:
Now, that's also a beautiful, deep question.

And it points to something that I think can and should be stated as a general theorem, which is,

No system can perfectly predict its own state.

No system can observe its own state, its own total state.

So that situation is ubiquitous.

and unavoidable.

And one could phrase it by saying a system can have a QRF or a metaprocessor, as one often uses that vocabulary, that represents itself.

So we all have a self representation.

That's, in a sense, metacognitive.

We claim to know what we believe and things like that.

But, of course, those beliefs are all, one, very coarse-grained, two, extremely incomplete, three, useful for making predictions, but they're often wrong.

And, you know, this is...

This point has had huge technological consequences.

Think back to the history of artificial intelligence.

Right?

In the 70s, there was the huge new wave was expert systems.

And AI people redefined themselves as knowledge engineers who were going to go out and

interview experts and find out how experts did things and code it up in computers and soon we'd have artificial expert systems that did anything interesting.

And that whole business failed utterly.

It was a complete disaster.

It didn't work at all.

Why?

The simple explanation for why is that experts can't tell you what they're doing.

Expertise isn't verbalizable.

And it's not just expert piano playing isn't verbalizable.

Expert systems engineering isn't verbalizable.

Expert computer programming isn't verbalizable.

And that's just an illustration of the fact that our metaprocessors don't actually have a complete model of the rest of us, much less a model of the rest of us plus the metaprocessor.

So it all comes back to this general principle that a system can't represent itself.

And so it can't predict its own behavior.


SPEAKER_05:
Awesome.


SPEAKER_03:
So between this work... Actually, I should ask Carl to comment on that tirade because he's also thought about this an extraordinary amount.


SPEAKER_04:
Well, I'll certainly make the comment that that was marvellous.

I'm glad this has been recorded because this should certainly be transcribed.

And I know it's probably implicit in the paper, but it was so beautifully articulated and clear, taking us through the issues.

I really enjoyed that.

So I have loads of comments, but I won't waste people's time going through all of them.

That last issue is really interesting about the metaprocessor or the metacognitive aspects of a system being able to measure itself.

I mean, there's a fundamental observation there, of course,

you know, you can't measure yourself.

The whole point of the particular physics paper was to say that, you know, yes, there can be two kinds of information geometries, if you like.

And the big move is that one system can measure, i.e.

infer,

by possessing or having a movement in some sort of information geometry infer a belief update about something else.

So at no point is there any room for it to also start to infer about its own inference.

That is a mathematical impossibility from the random dynamical system perspective.

I'm not sure about the quantum perspective, but it sounds as though that's also true.

So that begs the question, how on earth do we have the illusion that we know ourselves?

And of course, you know, it's a little bit of a colloquial question because 99.9% of things don't actually think that they know themselves.

So unless there's a particular phenotype particle or species,

that boasts philosophers, I'm pretty sure that most of the things that exist don't have any pretense to thinking that they know themselves.

It's a really interesting point to get across.

Anecdotally, I spend a lot of time taking people through examples

they probably go right back to things like ideomotor theory.

The way that we develop a sense of agency and think that we have a sense of agency is a gift, an illusion that is probably unique to only a small number of us and may not even be available to people with, say, severe autism.

And the example that I've literally in the past day just written down in a didactic way

was that if you just take vanilla active inference under a Markov blanket and then you look at particular kinds of sparsity structures where the active states of the Markov blanket or the holographic screen are hidden from the internal state.

So these are special kinds of systems that have a particular sparsity

where now the active states of the Markov blanket are now become hidden from the internal states

then you can certainly license some entanglement.

And I would, I'm going to later ask about the relationship between entanglement and synchronization.

So I'll say entanglement or synchronization of the internal states, such that the internal states have beliefs about their action, but those beliefs become beliefs about action as a hidden cause.

So there's absolutely no notion

from the inside that you cause that you're just representing the cause so the example i have in mind is you're watching a little fish swimming around looking for food gobbling up little bits and particles of food and you think oh that's a very sort of artful fish with purpose and pragmatics and knows how to navigate its world um but from the point of view of the fish

All that is happening is that the water and the particles are moving around it.

in a benevolent, nurturing, and fortuitous way, such that the water is delivering food particles to the fish's mouth.

So from the fish's point of view, it has absolutely no awareness that it is the author or the agent that's causing this synchronization with the environment.

So the deeper question is, how on earth do we have the illusion that we think we know our own agency?

And when do we develop agency?

And furthermore, it's not just agency about me, it's agency about other things.

At what point in our early neonatal neurodevelopment do we have these models of the world that enable us to distinguish between mother and self?

And at what point do we align our QRS, if you like,

with not mother, but with the world, that enables us to now see mother as an independent object, that is something else, that is an agent.

And the argument would then be, well, perhaps if mother is an agent, perhaps I am an agent.

I am now the author of my agency and my actions.

But that is such a high level thing.

I imagine it only pertains to humans.

That's what I'd say.

I'd love to talk about the homologues of entanglement from the point of view of classical thinking, but perhaps I've spoken enough at this point.


SPEAKER_00:
Just a couple of things came to my mind listening to this.

One is that Josh Bongard had this amazing paper in, I think it was around 2006 or so, where he had these robots and they started out like six-legged starfish.

But the cool thing about it was that they didn't have an internal model of what they were or what their shape is or how to move.

And they basically had to flop around and make models of

their own structure based on what happened to them given various outputs that they generated.

And eventually they would build a model of what happens and they would walk around and so on.

And two interesting things followed.

One is that you could, unlike traditional robotics, you could rip off one of the legs and they would very soon revise the model and keep going in different ways.

So they weren't tied to that particular self model, right?

They would have to discover it from scratch, but it was still sort of plastic throughout their whole lifetime and they could get along.

So they had that plasticity.

And the other thing is that, and Christophe Adami wrote a nice kind of interpretation piece of this.

He described, they spent lots of time being completely inactive and basically running through, quote unquote, mentally running through all the different things that they could do and what they think was going to happen before they actually moved.

And so Chris called that dreaming, you know, that they would basically...

sort of play out before you know in between their actual motions where they would go around testing and they would actually sort of play this out internally and try to refine the model such that then when they do move they would actually make movements that uh maximally sort of distinguish the different different possible models and so on and he said you know he said that you can watch them dreaming about about their shape

And then the other thing I just wanted to briefly mention, this idea of when and how do you recognize that you're an agent and that actually you need to act for things to happen versus just having the environment do things to you.

I suspect that one of the things that drives it very early on is this notion of stress.

And I don't have a particular,

uh i don't have a theory of why stress feels stressful but but just on a purely functional level i think that what happens in in cells you know so very early long before you get to humans or anything like that i think that what you get is this um

a set of mechanisms that evolved from things like stress about protein folding and so on, but then basically scaled up to be stress about metabolics and stress about morphology and stress about behavioral issues and so on, that basically is a system-wide metric of

the delta between what's going on and what you'd like to have going on, right?

The delta between your set point and what's happening now.

And what then I think that drives a strengthening of the agency model, because what will happen is as you slowly learn that you can do things that reduce the stress level, it kind of solidifies this idea that it's actually at least some amount of it is up to you to make life better.

And so you then act.

And then of course we know that breaks down and sort of learn helplessness assays and so on.

That's, that's, that, that, that really is, is very traumatic for, for all kinds of creatures that well below human.


SPEAKER_04:
Can I speak to that?

Because there's some great points there.

Please.

Yeah.

So three really important things being brought to the table there.

So I'm bound to forget the third one if I start with the first one.

So I'm coming back to Lou's question about sort of a QRS and alignment and that and

One obvious answer that one could bring to the table is that learning is the alignment of the QRFs.

So learning at all scales, and we're talking here about developmental skills, for example, we're talking about robots that learn to repair themselves or learn their new QRFs, if you remove a limb or a child.

learning to make sense of its world, then you could look at the slow process of alignment of the QRS, the things that are invariant over the faster timescales at which there is

classic information exchange on or in a holographic screen as simply a movement from a state of disentanglement to a state of entanglement as you become better and better at predicting.

But to become better at predicting, you have to align your QRS and you have to align that.

I think the robot example is a nice illustration of that.

in the sense that these robots were equipped with the ability to learn about themselves.

And of course, the analog in developmental psychology, and indeed, I would imagine, developmental robotics, is motor babbling.

It's basically, you know,

soliciting sensory outcomes in order to start to disambiguate between what did I cause that or did you cause that?

What parts are apparently under my control?

But of course, that's a very anthropomorphic interpretation.

There's no minus or minus implicit, but certainly the learning of the world models and the body models

um is probably the first thing that any artifact has to contend with because you see that in children you're shaking their rattle to to um solicit and um actively solicit

the conjunction of visual motion, proprioceptive feedback from the muscles causing the movement of the mobile or the rattle, and the auditory.

So soliciting conjunctions or correlations that are explainable and predictable in multiple modalities.

So you may then ask, why on earth?

What is the imperative for that kind of behavior?

What drives action?

to solicit this opportunity to learn the correlations and the coincidences and the conjunctions.

And that brings us to the second point that these robots dreaming

tell you immediately that at some level they have an internal model of the consequences of action.

And that tells you immediately that you've got, if you wanted to write that down from the point of view of classical active inference, you've got a belief structure on the inside that covers both the external world

and these hidden actions, and the actions upon the world, and the consequences of those actions on the external states.

That's a very sophisticated generative model to have, and you're getting now into the world of planning as inference.

So a thermostat doesn't have that, and yet these robots do have that.

So it tells you that there are two natural kinds of particles or Markov blankets or separable systems, at least two kinds, one of which is more like a thermostat and one of which is more like a sort of, I was thinking of sort of like an Ashby homeostat or allostat, but certainly more like these sort of robots that can learn about themselves.

And the crucial distinction

I think is that the agent has now started to represent the consequences of its actions, but without realising it's its own actions.

We still haven't got to the level of the metacognitive I am aware kind of artefact.

And it instantly comes back to what I was saying before about natural kinds, where one's active states are hidden from the internal state.

So they have to become inferred.

You have to infer them.

They are opaque to the internal states.

And as soon as you say it like that, then you're naturally talking about systems that can effectively

engage in planning as inference.

So they have to have plans in their heads in order to act, which corresponds to the streaming.

From the point of view of the active inference,

Then you ask, well, what are the objective functions or what are the principles of least action that would apply to these kinds of plans?

And when you work it through, then one important component of the pathogen or the actions in question is a drive to resolve uncertainty.

So we come back to this notion of the child soliciting proprioceptive, extra receptive sensations that enable it to resolve uncertainty.

And this is exactly the same principle behind optimal Bayesian design, that we design experiments

that are going to resolve the uncertainty to the greatest extent possible under our current internal models or hypotheses about how the world works.

And that brings me to the third great point about stress and the really important

place of stress and uncertainty and angst and not knowing what to do next or not knowing what's going to work in driving behaviour.

Because if a large chunk of the imperatives or planned action is to maximise information gain or minimise expected surprise or reduce uncertainty,

then you can see easily now why it is situations of uncertainty and stress that will necessarily cause the most epistemic responses in order to drive the system or the, in this instance, the agent to resolve that uncertainty.

The final point now, and this is basically paraphrasing what Mike just said, if the system sees itself behaving more

in times of greater uncertainty, it may now learn that.

and now have the idea, oh, I am the kind of system, or I am behaving as if I am the kind of system that responds more when under stress.

And then you'll become aware of that, and then you can get into the psychiatric or psychological aspects of stress.

You may not, if you're just a protein, you may just show a sort of selection for selectability-like response.

But I think the two fundamental mechanisms, the imperatives that are being

fulfilled here, in accord with basic conservation laws or principles of least action from the classical perspective, account for exactly the same kind of behaviour.

I think the interesting thing about stressful uncertainty, though, is that we're not talking about the content of implicit belief structures, but the second order statistics, the uncertainty.

And that, I think, brings a whole level of analysis to the table, because once you talk about uncertainty and representations of uncertainty in, say, internal states, then from a psychological perspective, you can start to talk about tension and consciousness.

From the point of view of an engineer, we're talking about things like Kalman gain and getting the estimates of noise levels, if you like.

correct.

And I'm not sure where the, if you like, the, well, let me ask, from a quantum theoretic point of view, is uncertainty baked into that?

Can you have a stressed quantum formulation?

I'll put that out there.

I'll stop talking now.


SPEAKER_03:
Yeah, just to answer that question, if one thinks about quantum theory with a Bayesian view of probability, with a kind of subjectivist notion of probability, which, I mean, that

point of view was really pioneered by Chris Fuchs and now David Merman, for example, has taken it up and written some very good things about it.

Then this notion of uncertainty reduction becomes the explanation for why you do experiments and build theories and it all becomes very well aligned, I think, with

the idea of active inference.

In fact, we wrote into that paper at the very end some remark about this cubist perspective about quantum theory becoming a result, not an interpretation, when we think of quantum theory as in a sense a way of reformulating the idea of active inference.

So I think they're very consistent.

A stressed quantum system is just a system that gets observational outcomes that it doesn't expect.

So we have to think of such systems as having generative models and thinking about

the generative model of an electron is a bit of a stretch, right?

Because the electron is only characterized by mass, charge, and angular momentum.

So it can't really have expectations about much, right?

An electron can have no expectations about the external electric field, for example.

It can detect that, it can respond to it, but it can't predict it.

And if we think about something like an electron, then we can focus in on this idea that having a generative model requires having enough memory

to keep a record of the most recent observation, at least the most recent one.

And if you want to have a good generative model, then you better have enough memory to keep a record of quite a number of observations.

And it's this memory resource that really simple things like electrons don't have.

So they're not great tools

predictors because they don't have the memory to allow being a great predictor.

And as both Carl and Mike were saying, in a sense, you have to have memory to be able to feel stress.

You have to know that your predictions were wrong.

So you have to remember what your predictions were.

So memory becomes a really key component of the theory once you put it into this language, because the language in a sense forces you to lay out assumptions about what the computational resources that are being required are.


SPEAKER_04:
wasn't very coherent but anyway i i just wanted to stress the role of memory here perfect thank you carl yeah just to um reinforce and endorse that last point um and uh just tell exactly the same story in a much more pragmatic way from the point of view a statistician so i heard chris say that basically

that if I want to go beyond being a little electron or a thermostat, and I want to now infer the quality of how noisy are my sensors, for example, my thermal sensors, if I'm a thermostat, that will require me becoming a little statistician.

And what does that mean?

Well, basically, I'm going to be estimating the standard error or the experimental variance.

There's something quite important about that, which comes back exactly to the computational resources and memory.

If you do a simple t-test as a statistician on some experimental data, you necessarily have to acquire lots of data points and store them.

And of course, that is just the degrees of freedom associated with your t-test or your f-test.

So the degrees of freedom

score the number of data points that you'll be able to remember and you need a sufficient number in order to get a precise estimate of the uncertainty so literally the degrees of freedom in classical statistics is literally

a statistic that scores your confidence in the estimation of the standard error which is pooled over multiple observations which is an attempt to estimate on average if I observe with this kind of

or I asked my questions, or I wrote to my holographic screen, or I solicited these sensory states, what would, on average, what would the uncertainty be associated with it?

So I think it's a really important point about the computational resources, the degrees of freedom, literally in the sense of the degrees of freedom associated with your F test, or the degrees of freedom you have available for the computing power.

to actually get up to these second order inference machines or takes on on second order inference so and i think that is particularly important when it comes back to mike's observation about stress and uncertainty and these higher order ways of making sense of the world but in this instance making a sense of sensations that are accrued over time not about the content but about the reliability of the or the precision of that content so this is a really important point


SPEAKER_05:
Awesome.

So that kind of... Oh, Chris, go ahead.


SPEAKER_03:
If I could just pick up on this and take it in yet another highly related direction, it's just to point out that all of these resources are energetically expensive.

So if I'm going to devote space...

in my state space to recording memories then that's only useful if I can defend those memories against entropy if I can keep them from decaying so I've got to consume energy to write the memories I've got to consume energy to maintain the memories and then I have to consume energy to read the memories and consume energy to compare

what I've read with what I see with my current event sensors.

So as we start adding these computational resources to systems, the energy budget goes way up.

And it's another kind of thing to keep in mind as we think about these in terms of embodied forms, whether they're robots or organisms, that

these these entities are extracting this free energy that they have to have to run their computations and maintain their memories and all that from the environment so here's this is another input that in a sense is not sensory but it's still having to flow through the markov blanket it's still having to flow through the boundary between the system and its environment and

A lot of the system's actions on its environment, its expenditures of its own internal energy, are to acquire this free energy.

So, you know, we go out and shop for groceries, make breakfast or whatever.

That's stuff that we have to do to keep all these processes running.

So it ties metabolism and cognition together in a way that they aren't often tied, but that they have to be to make sense of what's going on.


SPEAKER_05:
Great.

So just on that point, something that we had written down as a question from last time, and in terms of

an electron having a generative model and discussing agency.

We had talked about free choice and it was brought up in the paper several times, both in terms of like any physical system having free choice.

If one physical system has free choice, they all have free choice.

They generate like their noise generating

things like free choice generates noise in both classical and quantum systems.

And so I just was wondering if you could maybe say a few words about the difference in free choice in an electron and the difference in between an electron and like a human or an animal or even a cell.

What is that difference?

And is that also related to memory?


SPEAKER_03:
Is that a question for me?


SPEAKER_05:
A general question for anyone.


SPEAKER_03:
Well, I'll make a couple of comments.

One is, remember in talking about the canonical entanglement experiment, part of the description is that Alice and Bob can alter

the directions of their detectors, however they want to, at random, independently, whatever you want to call it, during the experiment.

So that's the free choice assumption, or that's called in physics the free choice assumption.

And what that assumption means, it's effectively an assumption of independence.

it means that there's not some common cause in the past that determines what they're going to do as they operate their detectors.

And one can reformulate quantum theory in terms of what's called superdeterminism,

And super determinism is the idea that there is some common cause in the past that determines how experimenters are going to do their experiments.

And in particular, determines how Alice and Bob are going to rotate their detectors in this EPR experiment.

And superdeterminism is kind of the ultimate non-local hidden variable.

So it allows you to predict exactly what entangled pairs are going to do.

And in fact, it renders entanglement a classical effect, right?

It just says,

these kind of super classical correlations are present because there was no independence to begin with.

Everything was determined from the very beginning.

And if you think about, as mentioned last time, Newtonian physics is formulated by Laplace.

It's a super deterministic system.

So anything that happens anywhere in the universe instantly affects what's going on everywhere else in the universe.

And the most current formulation of that is Bohmian quantum mechanics, where the motion of any particle depends instantaneously on the motion of every other particle in the universe.

And that's how Newtonian gravity worked, right, before Einstein imposed locality by making the speed of light finite.

So all of these things are interconnected.

Assumptions about space-time, assumptions about the speed of communication, assumptions about superdeterminism, and assumptions about free choice.

It's that cluster of assumptions that the so-called free will theorem in physics is about, or theorems, there are now a couple of them due to Conway and Koken.

And what those theorems show is that from a formal perspective,

In physics, if you assume that some system has free choice, so if you assume that some system is not subject to superdeterminism, then you have to assume that all systems have free choice in the sense that all systems are not subject to superdeterminism.

So you can't limit superdeterminism to some little piece of the universe and say it only applies here.

It doesn't apply anywhere else.

And in particular, it doesn't apply to me.

I have free choice, even though nothing else does.

That's mathematically inconsistent.

So that's what the free choice assumption means in a strict physical context.


SPEAKER_05:
Thank you.

Very cool.

Nathan, did you have a question?


SPEAKER_07:
I was just going to ask a little bit more about the degrees of entanglement and whether that's different in terms of the observer's degrees versus the mechanical nature of quantum mechanics degrees.

I think you've answered that to some extent, but just the way that that varying degrees of entanglement can be thought about and whether that maybe ties into how the Hilbert space is thought about at the same time.


SPEAKER_03:
Yeah, this assumption...

This question touches on why we do everything in the paper from the point of view of bipartite decomposition.

So we always decompose into a system in its environment in the paper.

And there are two reasons for that.

One is to keep it simple.

And the other one is to enforce the Markov blanket condition.

So

it's entirely commonplace to do physics in an open systems framework where we talk about two systems, we can call them Alice and Bob again, that are embedded in a common environment.

And in that case, whenever you have

a tripartite or greater, some sort of multiparticle kind of decomposition of the state space, you can talk about degrees of entanglement between different systems.

And you can, you know, cut up the state space any way you want to and ask about the entanglement entropy of some component of it.

And you get these ideas of partial

or they call it non-monogamous entanglement.

And that's all well and good.

It's mathematically complicated.

It's conceptually complicated.

But in a sense, it deeply violates the Markov blanket condition.

Because in point of fact, each of us is an observer.

And our goal is to

to say, what does the world look like to an observer?

And from Alice's point of view, Bob is a decomposition of her Markov blanket.

Right?

Alice has to actively disambiguate her incoming signals

into signals that she attributes to Bob as an entity and signals that she attributes to the rest of the environment as an entity.

So that's an active cognitive process on Alice's part.

That's what the Markov blanket condition, that's how the Markov blanket condition in a sense forces us to think.

So

The Markov blanket condition itself makes us take this idea of bipartite decomposition seriously.

And again, you can think of this in terms of implicit assumptions about resources.

If you think in open systems terms, and so you think of Alice and Bob as ontic entities that are separate from each other by a priori assumption and separate from their environments by a priori assumption, then you systematically underestimate the amount of cognition that Alice and Bob have to be doing.

And so you systematically underestimate their energy consumption

And so you systematically underestimate their uncontrolled effect on the environment, i.e.

generation of waste heat, acquisition of free energy resources, and all of that.

So it's not just a philosophical difference.

It's a difference that leads you to make genuinely alternate predictions about things like metabolic load.

so that's why we do things in this bipartite framework to respect the markov blanket condition and to keep our assumptions about energy flow explicit can we take that to the latter sections in the paper about biological cognition


SPEAKER_01:
what are the implications for this for biological systems yeah carl well um


SPEAKER_04:
Just to pursue that sort of thought experiment where you're trying to now say you wanted to use active inference to simulate Alice and Bob observing a pair of electrons and remembering that the pair of electrons are one thing.

So you now got a tripartite with three Markov blankets in play and many of the issues, for example, the super determinism that allows some assumptions about the

QRF alignments between Bob and Alice to be in play and also the discussion of how Alice has to contextualize

sensations from Bob under a belief or an internal model that Bob is indeed another Markov blanket and possibly a Markov blanket very much like Alice.

What you are saying is that two of these particles, Bob and Alice, have aligned QRS that could have been aligned historically under the super, which I never heard of before, but I like the word, at the super determinism.

And that may be a prerequisite to understand the experiments that we were taken through previously when looking at the third Markov blanket, which would be the electron or the two electrons, but for simplicity.

So that from a biological perspective tells you something quite interesting in the sense that it starts to get to

If it's the case that you can basically carve up a bunch of states, not in a bipartite way, but in a multipartite way, and that carving is by inserting Markov blankets to define the partition,

and that every subset of that space now becomes internal to its own Markov blanket, so there are now no external states.

All we have in play now are a set of internal states, each equipped with a holographic screen or Markov blanket states that are exchanging with other internal states.

Then there's some really interesting questions about how that system will evolve.

From the point of view of the discussion we've been having,

it's going to evolve under the principle of unitarity to entanglement.

So it's going to, from a classical perspective, if you allow me, it's going to tend to a state of generalized synchronization, where everything collapses onto the same synchronization manifold and everything is indistinguishable, there's perfect mutual predictability, there's a communication of an elemental and fundamental saw, so everything has basically

everything is singing from exactly the same hymn sheet.

That's the natural way of things.

The free energy principle is just one way of describing that natural tendency.

What would that look like cognitively?

Well, it would look as if the Markov blankets were trying to learn about each other, and to the extent that they can act on each other, they're going to

try and solicit the kinds of outcomes that would enable them to learn about each other.

So we're now going to get a situation that is driven by the imperative towards mutual predictability and entanglement.

That's an illusion.

All that is actually happening is that the system is becoming entangled, but it will look as if all of these separate Markov blankets or sets of internal states are aligning

in a mutually compatible way, their QRS, so that they can exchange and predict each other.

And if there's, if you like, an odd man out, namely the pair of electrons, then there will be an asymmetry and there will be greater degrees of entanglement

at multiple levels.

For example, if they're both observing a thermostat, then the thermostat's not going to be very good at learning how to align its QRS with Bob and Alice, but they're all going to make the best job of it.

Ultimately, of course, with good cultural eco-niche construction, they'll build better thermostats and become little robots, and then they can all live happily and communicate.

So I think that sort of the cognitive thing here comes again back to learning to live in your world,

as an apparent expression of the inevitable progression to entanglement whereby we try to learn about each other under the plausible hypothesis that you are like me.

It's not necessarily true, but it's one hypothesis you can bring to the table.

You never know whether it's true or not.

But that's certainly one hypothesis that would work very nicely for Alice and Bob if they can develop a common language.

So this notion of aligning QRFs between two blanketed systems, particles that are sufficiently similar

then just simply translates into learning to share the same narrative, to share the same language in order to render everything mutually predictable.

So I know exactly what you're going to say next and you know exactly what I'm going to say next.

And we come now to this asymptotic limit of zero prediction error, zero free energy and complete entanglement.

And that would be the objective.

We'd have no Ukrainians or Brexits or anything, if we could get there.

But that would be the direction of travel from a biological perspective.

There are simulations of this from a purely classical perspective.

And what you normally do is start off with two systems that think they have strange attractors, usually a Lorentz attractor.

So they think that their dynamics are generated by their autonomous or their active states create stuff out there that has a chaotic aspect.

And I say that explicitly just because this sort of the notion of free will and choice in the classical domain usually reduces to sensitivity to initial conditions, which strikes me as a homologue of the super determinism game

Can you go right back to the beginning and explain everything?

And in sort of classical dynamical systems, there are certain situations where you can't because you get a sensitivity to initial conditions.

So that would leave space or free will and choice certainly at one level.

But sorry, I digress.

So what you do is you basically put sort of two chaotic systems with sensitivity to initial conditions

together but they're not identical in the first instance but if they can exchange sensory and active states or they can exchange across a shared holographic screen so we're now back to the bipartite situation then they will naturally in fact if you think about they can't do anything else

they will naturally come to a state of entanglement, i.e.

generalized synchrony.

And if you allow the parameters of the equations of motion that underwrite these chaotic dynamics to also maximize mutual predictability or minimize free energy, then they will actually come to show an identical synchronization because they will learn to become like each other, just like Mike's robots.

But in this instance, they're learning about the other person simply to make things predictable.

So then you will have a shared narrative.

And in principle, you should be able to evince a kind of language.

I mentioned that because I know Chris wanted to talk about language.

We wanted to talk about, you know, quantum physics is just basically a description of communication and language.

I don't think we're going to have time to do that, but I thought I'd slip that in anyway.


SPEAKER_05:
Chris, did you want to say a few words, quantum and language?


SPEAKER_03:
Well, that was lovely, Carl, and I like the idea of this kind of simulation leading to generalized synchrony.

I think it's interesting from this perspective that we always divide

our environment into entities like us and then at least one entity that's radically unlike us, which we call the shared environment or the open environment or the general environment or something like that.

And so we have this sense of a social grouping of similar entities

that are commonly exposed to this vastly dissimilar entity with which we don't share a common language.

And we're not very good at predicting and so on.

And so we always have this kind of open systems point of view.

And

One of the functions of this vastly different system with which we don't share a common language is it's our free energy source and sink.

So it's where we put our waste heat and it's where we get our free energy for doing computation.

So I think it's interesting to think of this situation of

kind of local synchrony or local entanglement or a local language community local shared predictability embedded in this unpredictable chaotic and in a sense in principle chaotic because it's the waste heat dump right

We've assumed a priori that we can't understand it because it's where we're putting all of the thermodynamic entropy that we're creating.

We've put ourselves in a conceptual bind almost automatically by being systems that have to generate this entropy and put it somewhere.

So I like this classical to quantum correspondence very much, and I think it works very nicely.


SPEAKER_05:
Awesome.

Mike?


SPEAKER_00:
Yeah, I want to float an idea which is literally just a few days old, so it may be complete nonsense, but I'll float it anyway because I think it's relevant, and I've been thinking about it this way.

It occurs to me that

You know, this binary distinction between there are agents, some of them like me, some of them different, maybe competitors, whatever, but there are some agents that I can communicate with or can I receive influencer signals from.

And then there's this environment, which is, you know, something that we assume, or I mean, some cultures, of course, don't assume that, but we can assume that it has very low or zero agency, meaning that it just is this sort of

dumb, purposeless universe, and it's on us to sort of figure out what it's doing, right?

So it occurs to me that that distinction maybe shouldn't be binary.

And maybe what we want to be thinking about is as an agent, when you are

receiving something from what you think is the outside, you might want to estimate what is the agency on the other end.

And you might wanna do this for the following reason, right?

And I started thinking about this by imagining what it would be like to be in an internal,

partition or a chunk of a giant neural net being trained, you know, you, you live, if, if that's you, you live in a very mindful universe, you know, you could catch on to the fact that, you know what, I'm being, I'm being trained for something, you know, the world, like there are bigger patterns here.

And of course it moves in inscrutable ways and everything, because I can't, you know, I can't sort of, I can't understand the whole pattern of what's going on, but I can definitely tell that it's rewarding me and punishing me for specific behaviors.

Right.

And of course, some people do feel that way about the universe and let large that there are patterns that, um,

that are not just, you know, not quote-unquote just physics.

And so the reason I think, and this extends to, you know, we have supervised learning and unsupervised learning, and again, we think of those as kind of binary things, right?

Is there some sort of intelligence on the other end telling you what's right and wrong, or is it just on you to abstract patterns from the environment?

And the reason I think this matters is that if you are trying to learn from the environment, meaning there's only one agent involved, that's you, there's one agent, and then there's this sort of unthinking universe around you, then you are pretty much guaranteed that whatever you can manage to infer, it will be to your utility.

It's on you to figure out, to learn whatever you can.

If there's another agent on the other side and you are being trained, then what are the odds that that agent has your best interests at heart?

I mean, maybe, but maybe not.

And so if this is some sort of supervised learning, you have to ask yourself, what is it that I'm being trained and is it really what I want?

It's kind of a whole thing.

that you can imagine evolutionarily that maybe to avoid, uh, being hijacked by, um, by, by, by, by parasites, by, by, you know, uh, competitors, by whoever you don't really want to be trainable too much.

You, you want to learn, but you don't really want to be trained.

And so maybe the idea then is that, uh, what if, what if, and this is okay, this is where, you know, I really haven't, haven't, uh, talked to anybody about this yet.

So this is, this again could be a,

very amateurish stuff but but what if uh something like back propagation or whatever what if that literally hurts what if as a as a right as an early creature having some sort of error function forced back through your channels as opposed to whatever you were trying to generate yourself what if that's evolutionarily designed to be unpleasant and what if uh what you're trying to do is avoid that happening you don't want to be trained you want to learn on your own terms

And you could sort of imagine the different layers of a feed forward artificial neural network where the like the initial input layer

That sort of creature gets to see the world, quote unquote, as it is.

It gets the raw inputs.

The next layer, and certainly the layers past that, the ones on the right that are abstracting, they're getting all kinds of propaganda filtered to them by the early layers.

They don't get to see the real inputs.

They get to see whatever the prior layers think they should be seeing.

And so maybe if you don't have a flat network like this, but maybe what you have is a, you know, more biologically, you have a kind of a nested multi-scale kind of system.

Maybe there's some sort of incentive for the middle layers to try to sort of crawl leftward so that they have more raw access to the real world.

and not be trapped uh being being fed by these other agents right so again you know this is all very qualitative stuff but you get the idea that's that's kind of what uh what what i was thinking about nice dean and then daniel mike if you want to chat about this this is what i was doing for about 10 years unleashing and getting out of the lab and


SPEAKER_02:
getting past the toy model.

So perhaps we should chat about this for a bit.

Can I just, a couple of things.

Chris, first of all, thank you for, I feel like I've come away with a Munich Stein volume worth of coolness for the last two weeks just listening to you explain these really, well, complicated things to me in ways that I can actually understand.

One of the things that I'm still kind of curious about is once we let things out of the lab and we keep them in that variability retained space, and we don't want to be in conflict with sort of the basic rules of what quantum information tells us, I want to kind of go back for one second to what Stephen was kind of closing the 40.1 with, and that is what do we do when we look at things in that sort of relational realm that a lot of

indigenous cultures sort of take up and try to find themselves within.

And I'm kind of leading to this idea that there's a sort of a subject matter generalist that leads to a prediction matter expert down the road.

And I talked to Carl, it was my question to Carl back in June when he was

talking to us in the Active Inference Lab.

And so without getting into any kind of conflict with the quantum aspects of this, what do we take out with us when we go on a bike ride with Chris Fields that's quantum related, that isn't in conflict with everything we've talked about today, but gives us a better confidence around the things that we might encounter and predict?


SPEAKER_01:
What do you take on your bike, Chris?


SPEAKER_02:
Yeah, what's in your quiver?


SPEAKER_03:
Yeah, good question.

Once again, these theoretical frameworks are languages and they

their role is to shape our concepts, or they are ways of shaping our concepts.

And I think the fundamental kind of lesson of quantum theory for us is to

not take the boundaries we see as literally as we're encouraged to do in the classical worldview.

I'll try to distinguish the classical worldview from classical physics because classical physics by itself

again, going back to someone like Laplace, is a physics of atoms, which are sort of elemental.

It's not a physics of bounded macroscopic objects.

The boundaries, even in classical physics, are sort of arbitrary.

And I think that's what quantum theory is trying to tell us to do.

is trying to tell us that these are boundaries that we draw on our blankets.

And I think this is, in a sense, what our thinking about the FEP is trying to tell us, that we have to take this notion that we're blanketed entities seriously when we think about what we're interacting with, which is everything but us.


SPEAKER_01:
daniel in our closing minutes um if we could just each give a thought this is really just a special and very powerful uh conversation uh mike with a back propaganda

Amazing thought experiment there.

And no boundary and quantum questions touching on the work of like Ken Wilber.

And I think it's just so powerful about does someone have the whole world in their hands?

Is that a good person?

Is it a bad person or thing?

What kind of thing is that?

Who's on the other side of this video call?

Who's on the other side of that other side?

What's the bigger picture.

And it really brings it home that no, it's not just about electrons.

This is something that is across scales and systems.

So really just wanted to appreciate the paper and hope that we continue on this line of development and I'll pass it to Steven.


SPEAKER_07:
thanks daniel yeah i was going to tie this a little bit some of the threads with um this challenge of having this false sense of certainty in our culture and how it does feel uncomfortable to be trained um but we do it in the west because we're confident that we've got this expert knowledge but then we suddenly find out we don't know as much as we do know or we think we know

So that may be why bottom-up sort of organic indigenous kind of ways of being or ways of sensing can feel more holistic.

So I think there might be something quite powerful in that.

So I like that thread, and I think that ties together with the challenges in practice when we try to train up communities, especially if we're working, say, if I've worked in rural Africa,

And communities there, if they don't feel connected to the colonizing narrative, it feels very oppressive.

So there's a lot of good points there around where is there coherence, where is there decoherence, and also where is there certainty and where there's uncertainty.

So thanks.

This is really helpful.

And I'll pass it over to Blue.


SPEAKER_05:
Well, I've said enough.

I think I'd like to hear from Mike or Carl or Chris about where you're going or what you're taking away or what are your final thoughts about the discussion we've had over the last couple of weeks?


SPEAKER_00:
I mean, I guess the only thing I'll say is that to me, I really like this idea that it turns on its head, this notion that you have this massive amount of mindless stuff and then somehow a little bit of mind shows up at the end that kind of turns that upside down.

And if that's the case, then the scaling problem is really, really interesting, right?

It's how you scale, how biology manages to scale these things so that they become,

synergistic and bigger and bigger, as opposed to, you know, just merely a bigger pile of rocks than the previous pile of rocks.

And so that, right, so those mechanisms, and in particular in biology, and so, you know, I look at it from cells getting together to be organisms and solving problems in the

anatomical space.

But but I think there, we actually have some pretty good alternative, although very, very, very similar in many ways, isomorphic, but alternative stories to what happens in neuroscience to try to understand how that scaling actually works.

So I'm super, I'm just super, super excited about that.

And also the role of the observer and all of this, and the idea that all of this is based on various observers observing each other.

And I think that makes it makes for a lot of progress and fewer pseudo problems when you when you look at it that way.


SPEAKER_05:
Carl or Chris, any final thoughts?


SPEAKER_03:
Well, I'll just thank you guys again for putting this together.

I thought this was a fascinating conversation.

And if I could throw one more thing into it, I think conversations like this are evidence for

the kind of disciplinary siloization that's been forced onto us by academic tradition being an artifact and not necessarily being all that useful.


SPEAKER_05:
Thanks so much.

Carl, we're going to leave you with the final word.


SPEAKER_04:
Good.

Well, it has to be a thank you, doesn't it?

For you lot for putting this together and for the brilliant didactic and also challenging didactic unpacking of some really challenging but I think revealing issues and also the brilliant questions.

My final word will be future pointing.

Just taking up this lead of Chris's, you know, having unsiloed conversations is useful.

Just thinking about Mike having the balls to come up with his brand new hypothesis that's two years old.

Sorry, two days old, my apologies.

So I thought it was really interesting.

Just a nice example of putting things into this kind of discussion, which we're all going to go in and think about.

So my immediate thought was, how on earth does the second layer in a variational autoencoder or something doing bat prop act?

And of course, it can act if it's a recurrent neural network and it can select which of the lowest level neurons or hidden layer, sorry, a non-hidden layer,

units to listen to.

And of course, we come back again exactly to attention and selecting those sources of precise information where you've got a kind of internal action.

So an interesting and silly thought, but just a nice example of how talking together can excite interesting and potentially useful or possibly silly thoughts.

But again, thank you.


SPEAKER_05:
Wonderful.

I had a great time observing all of you and hope to get to do more of it in the future.


SPEAKER_01:
Yep.

We can have a dot three anytime.

Consider 40 in the intermeasurement interval while our igus is digesting.

And talk to you all soon.

Thanks again.

Thanks very much, everyone.

Thank you.

Bye.

Bye-bye.

It was great.