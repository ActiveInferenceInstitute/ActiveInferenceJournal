SPEAKER_01:
All right, hello and welcome.

This is ACT-INF Lab live stream number 40.0.

It's March 10th, 2022.

Welcome to the ACT-INF Lab.

We're a participatory online lab that is communicating, learning, and practicing applied active inference.

You can find us at the links here on the slide.

This is recorded in an archived live stream, so please provide us with feedback so that we can improve our work.

All backgrounds and perspectives are welcome, and we'll be following video etiquette for live streams.

Check out ActiveInference.org to learn more about the lab.

All right, in today's number 40.0, the goal is to learn and discuss this very cool paper that was published on Archive on December 30th, 2021, A Free Energy Principle for Generic Quantum Systems by Chris Fields, Carl Friston, James F. Glazebrook, and Michael Levin.

And just like every video, it's going to be just a conversation going over some parts of the paper.

It's not a review or a final word.

And if anything, it's a cry for help or at least a cry for participation because there's so many areas where somebody with different experience or more knowledge about any of these domains could connect some dots or...

give some useful comments or critique.

So especially with this video, though, Blue and I had help from our colleague Jason Larkin with many of the details.

There's just so much to unpack.

So we'll try to make this a useful dot zero.

And then we're really looking forward to the dot one and dot two and so on when we'll be able to really go into some of these directions.

So

I hope if you're watching live or between now and the .1, check out the paper and listen to this discussion that we'll have now and ask some questions because this is just the beginning of a few new threads, probably more than the answering of questions, especially to any desired level of completeness or applicability.

So it's just the beginning.

That's what the .0 is about.

It's a new decade, 40.0.

So...

We'll just introduce ourselves and then go through a bunch of the paper.

And yeah, thanks again to Jason for a lot of help and Blue for awesome work on the slides too.

Okay, so I'm Daniel.

I'm a researcher in California and I'll pass to Blue as facilitator.


SPEAKER_04:
I'm Blue Knight.

I'm a researcher in New Mexico.

And I have to shout out to Daniel, too, because you're always saying thank you to me.

But, you know, we all have to say thank you to you for providing the affordances to be here and, you know, discuss these awesome questions.

Big paper.

I am excited to delve into this.

I think it will, you know, start a lot of new trails.

So I think and also to bring back Mike Levin and to bring back Chris Fields and to bring back Carl Friston back to the active lab to discuss the dot one.

with us hopefully um okay so is there anything particular that you are excited about daniel or do you want to just power through it let's get let's jump in

So this paper really was trying to unite the quantum principles and the free energy principles.

So quantum mechanics and kind of delving into that.

And we will see some threads carry over from the last time that we had Chris Fields on here, maybe the last time we had Mike Levin on here also.

So how is the free energy principle related to quantum mechanics?

What does the FEP gain from quantum?

What does quantum gain from the FEP?

Are we using the FEP now to model quantum systems?

And why are we pursuing this intersection?

So this was kind of like the big questions kind of maybe we can start to answer with this paper.

So we are here.

Daniel, what's this map about?


SPEAKER_01:
Um, it's a question we're going to probably ask ourselves multiple times so we can insert it like a little emoji, but we can think of among the axes of variation or variability that we're going to explore or where we're going to tune our regime of attention or what perspectives we're going to take.

It's going to be like along two axes ranging from on the right side, FEP act-inf-like and

to the left side, which is like pre- or non-ac-dymph-slash-FEP.

It's the x-axis.

And then the y-axis is the continuum between quantum, which we'll probably nuance and hear many perspectives of what is and isn't quantum, but just to summarize it by saying quantum, and not quantum, like pre- or non-quantum approaches.

and so quantum FEP is in the upper right corner and we can think of it as being like connected in different ways to quantum non-FEP in the top left the blue and then FEP but from a non-quantum perspective like all pre now FEP active in green

And then what are all the other connections?

And so who's right?

Who's wrong?

Who's useful?

Where's their pragmatic value?

Where's their epistemic value?

What are we really talking about?

Do we agree on the phenomena?

Where is there agreement or disagreement?

Where are we in this complex landscape?


SPEAKER_04:
So I think in mechanics, we refer to it as classical mechanics and quantum mechanics.

So now we will be, this is like the dividing point maybe between classical FEP and quantum FEP.

Perhaps.

Let's see where it goes.

So the aims and claims of the paper, there are pretty much three, and we'll revisit these at the summary, because we're gonna just give you a broad overview of the summary of results right now.

Given the standard free choice assumption, the intuitive ideas of an agent or information gathering and using system, IGUS, can be fully formulated within background independent scale-free quantum information theory.

The second claim is that FEP can be a quantum theoretic formulation that renders it applicable to generic quantum systems.

And do you want to read the last one, Daniel?


SPEAKER_01:
Three, when formulated as a generic principle of quantum information theory, the FEP is asymptotically equivalent to the principle of unitarity.


SPEAKER_04:
Cool.

Do you want to read the first section of the abstract?


SPEAKER_01:
All right.

free energy principle or fdp states that under suitable conditions of weak coupling random dynamical systems with sufficient degrees of freedom will behave so as to minimize an upper bound formalized as a variational free energy on surprisal also known as self-information this upper bound can be read as a bayesian prediction error

Equivalently, its negative is a lower bound on Bayesian model evidence, also known as marginal likelihood.

In short, certain random dynamical systems evince a certain kind of self-evidencing.


SPEAKER_04:
So here we reformulate the FEP in the formal setting of space-time background-free, scale-free quantum information theory.

We show how generic quantum systems can be regarded as observers, which with the standard freedom of choice assumption become agents capable of assigning semantics to observational outcomes.

We show how such agents minimize Bayesian prediction error in environments characterized by uncertainty, insufficient learning, and quantum contextuality.

We show that in its quantum theoretic formulation, the FEP is asymptotically equivalent to the principle of unitarity.

Based on these results, we suggest that biological systems employ quantum coherence as a computational resource and implicitly as a communication resource.

We summarize a number of problems for future research, particularly involving the resources required for classical communication and for detecting and responding to quantum context switches.


SPEAKER_00:
It's like, okay, cool.

What does it mean?

How will it be useful?


SPEAKER_04:
Yeah, so we're gonna unpack a lot of this and hopefully give everyone a good framework with which to kind of go forward into the dot one and dot two, maybe a little bit of background understanding.

The paper is very beefy, so we'll do our best to kind of lay the framework down.

They give us a good roadmap.

So there's five sections, the introduction, physical interaction as information exchange, and several subsections within that.

repeated measurements and system identification and subsections, the FEP for generic quantum systems, and the discussion.

And I think that they actually outline what's in each section, so we'll give you that outline overview as we go through the paper as well.

So just we're gonna use, we're gonna actually reuse some slides from active stream number 17.

That was when we had Chris Fields presenting information flow in context dependent hierarchical Bayesian inference.

I think contextuality is like an underlying thread that's pretty important here today.

So Chris kind of lays that out in that paper.

And so if you want to get into

and dive deeper into two spaces and channel theory, which we'll talk about a little bit, but yeah, that's there.

So use that for a resource.


SPEAKER_01:
Just one foreshadowing here.

The two pieces that they claimed in this paper as their goals was to connect contextuality to category theory and two spaces, and then connect that yellow formulation

to hierarchical Bayesian inference, more looking like the statistical models.

And so this paper is kind of building a category theory bridge with Bayesian graphs and statistics and category theory.

And then that's probably going to hinge over to a few other areas.


SPEAKER_04:
Cool.

So we can jump right into the introduction.

And we're just going to highlight some keywords as we go through.

The authors didn't really give keywords for the paper, which I'm kind of grateful for because there's so many other things to unpack here.

So they highlight some things about the FEP in the words of the authors.

Since its introduction as a theory of brain function, the variational free energy principle has been extended into an explanatory framework for systems at all scales.

The FEP is a statement that any measurable bounded and macroscopically persistent system will behave to satisfy these requirements.

What else Daniel?


SPEAKER_01:
It was just cool how they brought in the FEP as being the overarching level as

describing how these particles do two things, which is possess internal dynamics that are conditionally independent

from the environment and performing this self-evidencing feature by returning to some non-equilibrium steady state.

And so just which parts of the FEP they entered in at or emphasized, which we can assume are setting the stage up in their mind best for the interfacing or the on-ramping into quantum, whereas somebody interested in like a system or integration other than quantum might take a different approach.


SPEAKER_04:
Cool.

I think that they borrow also from our particular physics.

We're going to talk about particles.

And they talk more about particles in the discussion.

Maybe we can have a deeper conversation about those in the dot one and dot two.

But they say the Markov boundary of any particle that's an open exchange with external states via its Markov boundary underwrites conditional independence between its internal states and the external states of its environment by localizing and thereby restricting information exchange.

So the Markov boundary separates internal and external states by mediating their exchange.

We've seen that before.

Cool.

So what is active inference, Daniel?

Can you break it down for us?

Two-sentence overview.


SPEAKER_01:
That blanket that Blue just described with the insulation, incoming statistical dependencies can be interpreted as perception and outgoing statistical dependencies can be interpreted as control.

And depending on the situation and what's zero and what's not zero,

that can have a lot of dynamics that are similar to some other classic settings in decision making, gambling, experimentation, quantum measurement in this paper.

Very cool.


SPEAKER_04:
So what is quantum theory?

This is cool.

Just some pictures and it's connected in many, many different fields.

So there's a cool kind of concept map of where quantum theory intersects.

But, you know, the quantum theory here is the idea that that.

All physical systems, including the environment, can be considered observers that act on their surroundings to prepare them for subsequent observations.

That's become common in quantum theory, replacing the wave function collapse postulate of traditional quantum mechanics with interaction-induced decoherence, which is like the dissipation of quantum coherence.

This is like the thing that generates classical information.

And they say, indeed, while quantum theory was originally developed and is still widely regarded as a theory specifically applicable at the atomic scale and below, since the work of Wheeler, Feynman, and Dutch, it has over the past few decades been reformulated as a scale-free information theory and is increasingly viewed as a theory of the process of observation itself.

Yeah, I think when we think about quantum, we think about the observer.

At least I do.

I think about the observer phenomenon.

Just the act of observing a system changes the system.

So that's kind of a fundamental thing that comes to my mind.

What comes to your mind, Daniel, when you think about quantum theory?


SPEAKER_01:
Reading that leaves me uncertain whether we're talking about organic chemistry and the pi orbitals and covalent bonding and emission and all of those things that particles do, which is what it sounds like they're talking about in this orange part, a theory specifically applicable to the atomic scale and below.

And then this blue part makes it sound like they're opening it up into a much larger space.

So I think we'll probably learn a lot about that.

What does quantum mean here?

Are we talking about electrons and protons?

Or is this something that is like Bayesian inference in that it's scale free or scale a priori or scale friendly or something like that?


SPEAKER_04:
Nice.

Scale independence.

So we're going to jump right in.

So section two, they talk a lot about physical interaction as information exchange.

And that's something I wonder also, like, is, you know, we have the classical mechanics and do the laws of quantum always apply or at some scale are they, you know, not applicable or can we extend them into something like quantum?

theory of everything, like are we getting there maybe?

But here in this section they say that they use the category theoretic formalism of channel theory to formalize the operational semantics of natural languages.

So they develop a generic formal representation of quantum reference frames and show how the non-commutativity of quantum reference frames

induces quantum contextuality and i had fun really digging into this um at a level that i felt comfortable explaining it at so i'm excited to see if i if i bungle it or how it goes let's see okay what is quantum wow when physical interaction is used information exchange why is it quantum becomes obvious the fundamental quantum quantum of information is one bit

one unit of entropy that one system exchanges for another.

So one bit, one quantum of information is the answer to one yes or no question.

That is quantum.

Do you want to add anything here, Daniel?


SPEAKER_01:
this is the block text is from the paper and just one piece that will be interesting to explore is just how does time and temperature come together like i had just heard or thought more about the space required for storage and

not really seen it as much connected to the speed of obtaining that yes or no answer at different temperatures and what that might mean for biological or for digital systems but i'm sure that's a very um foregone conclusion maybe working with a quantum device but

new to me.

And Jason was like, Oh, yeah, of course, that's the case.


SPEAKER_04:
And they talk a lot.

So foreshadowing, they're gonna, you know, really present this within like a space time independent context, which is kind of cool, and then like, link it back to time, which that kind of gets a little interesting.

All right.

So moving on, Hilbert spaces.

So

Daniel, do you want to say a bunch about this?

Or what do you want to say about this?

And then I'm going to highlight some stuff.


SPEAKER_01:
I'll just read what they wrote.

The red part was our comments on what they wrote.

People can pause it to read what they wrote.

The Hilbert spaces contain all states described as a vector.

And this is one way that qubits are constructed.

by relating two levels of a system, like electrons in a ground or excited superposition, and then the collapse into one or those other bands.

And so that's more of like a uncertainty to discrete transition.

But then in the limit of high temperature, there's a lot of blur or experimental factors that can be modeled as blur that results in a smoother distribution of outcomes.

and um here this hilbert space is describing how the experiment is set up and the information that's being modeled at a given time so the state of that this space consists of the options for is like the just the experiments space including the total target system and the observer

Maybe.


SPEAKER_04:
So I like this quote at the end that, as Fuchs put it, infinite dimensional Hilbert spaces are, from an information perspective, merely a useful artifice permitting computation with differential equations.

And they contain all the possible states in an experiment as vectors.

There's more to read about that and also the mathematical notation if you're curious about kets and bras and some of these brackets that we had to dig through to find solid ground.

Yeah.

Okay.

So the principle of unitarity is the principle that observable information like energy is neither created nor destroyed by physical processes.

And I thought that this was interesting.

So time reversal symmetry is essential for the conservation of information.

So a system is time reversal symmetric if its equations of motion allow perfect prediction of the starting point based on knowing the state of the system at any given time.

Thank you.

So like if you know a time, whatever, X time steps, you can still say something about the starting system because you can run it forward and backward in time.

And there were some cool things like about if you pulled up a mirror, that's like enables the time reversal.

So some things go forward, but like the spin of an electron is spun backwards in time, right?

So it's like those kinds of things, like some things are parallel and some things are opposite in time reversal symmetry, but anyway.

I thought that was interesting and fundamental to kind of the principle of unitarity and also because we're going to talk about time in a cool way, I think.

OK, so.

Yeah, unitarity.

What do you want to say about unitarity, Daniel?

I said a little bit, so let me pick out some things here that you want to talk about.


SPEAKER_01:
Okay.

This was all with just Jason helping us.

And again, it's like an opportunity for anyone who's familiar with these two formalisms to help us a little bit more through, but just to pick up on one point, just one,

as we mentioned, like we're doing experiments where it doesn't matter what time we started at in a sense, like it may matter in the sense that the different times lead to different results, but a statistical framework for observation that can

cut through some of the parts of the experimental context that are not relevant to compare different events that happen at different time in a unified statistical framework.

And so that was what led to this principle of unitarity that the total probability distribution is preserved with like a mass of one.


SPEAKER_04:
so that there can be information evolution but it's happening in a certain space where there's a certain invariance that allows useful computation to happen cool oh yeah conservation of probability so that's something that maybe came up um like the probability that a particle is somewhere like it's somewhere there's 100 probability that the particle is somewhere so it didn't disappear so that was another kind of interesting point we were talking um

before this.

I mean, that's kind of how you get the conservation of observable information as well.

Okay.

Separability and holographic encoding.


SPEAKER_01:
okay this one just to uh briefly look at a previous slide I think this was from 32. we were looking at sparsely coupled systems from a Matrix perspective and so the dense coupling of like subunits one through six with each other was mainly like within the click of the red or the blue but then there's these off diagonals that reflect the sparse coupling of denser clicks and so

In section 2.3 of this paper, they're also talking about coupling patterns in systems, specifically ones that have a separability

So, like, one of those blocks could be the experimental system, the quantum computer, and the other one of the blocks could be the experimenter, and then there could be sparse connectivity reflecting the experimental apparatus.

But that was being approached from a quantum holographic angle, also setting up for a Markov blanket take.


SPEAKER_04:
Cool.

So one sentence on this page that I think is important is underlined here.

The entanglement entropy is a mutual information measure that detects quantum correlation or coherence between A and B.

And so that defines separability and either a system is separable or it's entangled.

So separable states are also called decoherent and entangled states are also called coherent.

So just point out as we go forward and kind of dive a little bit deeper into the math.


SPEAKER_01:
It's kind of like if it was parametric classical statistics, we would say uncorrelated or correlated.

If it was information theory, we'd say no information or yes, it gives information.

Bayesian graph, yes, it has causal influence or no, it doesn't.

And then this is the quantum take.

Yes, it's entangled or no, it's not entangled.


SPEAKER_04:
Also, don't forget conditional dependence or conditional independent.

So where is it conditionally dependent?

And we know that like the Markov blanket

can help to define conditional dependence when we've looked at active inference in the past.

Okay, cool.

So do you want to talk about the Hamiltonian?

Or not at all?

What do you want to say?

Not at all.

Okay.


SPEAKER_00:
Not sure what you're saying.


SPEAKER_04:
So there's one cool thing that I want to point out here.

You know, we talked about like weak interactions, strong interaction, different timeframes and how these are going to vary as we go forward.

But here, I really just wanted to point out that this H of AB is like the Hamiltonian.

So we're talking about matrices.

separability, interacting matrices, conditional dependence, just on the last slide.

And so the interaction between the Hamiltonian of the matrix can be decomposed into this HAB, where this is like the interaction between A and B. So HAB can be looked at as we go forward as the energetic interaction between

matrix a and matrix b state a state b position a position b or um they gave it to us in a very generic form so i didn't really know how to apply that going forward but maybe if the authors are listening they'll come in and rescue us um that's the only thing i really wanted to point out from from that side

And then this is kind of cool.

So this equation six, which we just looked at, which is the energetic interaction between A and B, this is physical interaction, which I guess could be physical interaction between A and B. That could also be energy, right?

Matter.

equals MC squared.

Physical interaction equals thermodynamics times yes or no questions.

So it's cool the authors say, this formulation emphasizes what quantum theory is about.

The process of obtaining information.

Obtaining information from B requires in particular that A acts on B by asking questions.

As Wheeler puts it, no question, no answer.

All inference in this framework is active inference.

Equation 6 does not allow passive perception to be a physical process.


SPEAKER_01:
Super interesting.

Agreed from a lot of angles.

It almost takes it to a level we haven't seen from just saying, well, perceptual inference, even the generative type, so not just the signal processing, but even a predictive processing generative type,

framework for perception that doesn't take action into account is incomplete, hence the motivation for active inference.

And this is somehow escalating that

into saying that all inference in this framework is active inference and i wonder if that's because like a frame is always needed some kind of generative model is always needed as a recognition model dual for any observation so if you're in the business of making observations you're in the business of generative model modification one way or another or you're not the kind of thing that does either of those but they might come into play

in the minimal active entity or the thing that can be modeled as a minimal active entity and so there's a lot of interesting areas and i think it's also quite interesting with the natural language equation so how should we read that dot thermodynamics what yes no questions and then times or what does it mean


SPEAKER_04:
Yeah, there's the category theory, like that dot operator.

I forget how to read it.

So hopefully it's being rescued.

But yeah, I read it at times because I'm old school.

So going back to that same equation six, I thought that this was important.

It involves no assumptions about space time, objects, or motions.

It is strictly topological.

Given separability, it identifies a boundary, fancy B, between A and B,

at which the energy interaction, physical interaction between A and B is defined.

So I guess that would be like a space.

Well, I guess it's not space.

It's not space.

It's not time.

It's a physical, it's an energy interaction, H-A-B.

Anyway, yeah.


SPEAKER_01:
And this is the Markov blanket fancy B holography connection, which is that all the information that is making the sparse connectivity of A and B, we're talking about systems that have like this screen slash blanket slash experimental apparatus fancy B and the properties of it.

For a system that might be making classical-like measurements,

Or maybe it's making quantum measurements.

So implicitly the prior work had been thinking about what was on the other side of that experimental apparatus from a classical or from a non-quantum perspective.

We'll see.

And this is taking it more into asking what kind of mathematics would be needed to look at it if it were a quantum system that were being investigated.


SPEAKER_04:
Cool.

And I think that takes us into figure one.

So here, Daniel was foreshadowing, doing a great job of the holographic screen.

So this is a holographic screen, fancy B, separating systems A and B with an interaction, HAB, given by equation six.

And so this says that this screen can be realized by an ancillary array of non-interacting qubits that are alternately prepared by A and then measured by B.

Qubits are depicted as spheres here, and there's no requirement that A and B share preparation and measurement bases.

So these are quantum reading or quantum reference frames.

So this is like they share the ability to prepare or measure.

That would be like quantum reference frame.

And we're going to get into the quantum reference frames just here in a couple of slides, I think with a pretty good example.

Anything to add or do you wanna like unpack it with the next couple of slides?


SPEAKER_01:
Um, just thinking about this as like a quantum holograph is sort of the generalization, maybe, of thinking about this in the classical information.

What if this were the chat between Blue and I?

So we could have different perspectives, different reference frames, different semantics.

But if we're not in the same chat room, then we're not in the same chat room.

That's like the holographic screen or the observable that's getting passed between these two systems A and B.

and they don't have to be two people it could be like a person and some other system on the other side of the holograph information channel and the whole question is what kind of math describes that classical information channel case and how is that similar or different or compatible or whatever with thinking about it not as a information bit from a standard probability distribution but like a quantum information bit with a complex statistical distribution


SPEAKER_04:
Nice.

So they describe the holographic screen, actually, as they say the holographic screen, fancy B, has an obvious interpretation in the language of the free energy principle and active inference.

It implements the Markov blanket that separates from B. So we've seen the Markov blanket before and mentioned it here, but I think that they are going to implement this holographic screen of this Markov

like it.

Yeah, perfect, cool.

Oh, and then the quantum reference frame, fun.

So here they say, we show in particular that the FEP emerges naturally in any setting in which an agent or particle deploys quantum reference frames, namely physical systems that give observational outcomes and operational semantics to identify and characterize the states of other systems in this environment.

And so this was kind of a cool figure that I pulled down.

So it's like a man on the train.

To the man, the train is moving.

And to the person on the train, the man is moving, right?

And so it depends on your perspective.

And this is kind of what a quantum reference train is.

is getting at here.

So this says, quantum features such as quantum superposition are only defined relative to an observer.

When we look at the train from the point of view of an observer standing on the platform, the train looks in a quantum superposition of different positions.

However, an observer sitting on the train sees the observer on the platform and the ball in a quantum superposition.

So it's a cool illustration of just kind of how things look differently depending where you're standing.


SPEAKER_01:
Okay, this is awesome.

I like how you brought in the art and the images are a little subtly different, but then in a way that really makes one think.

And the classical case would be what if both of them were moving or still, and then they only got to get a frame update once every two seconds or once every five seconds.

So then there'd be like still an uncertainty distribution, but it'd be a classical parametric statistics or information theory, uncertainty about location.

And that's going to be the big question.

How is that variance estimation that we've already been exploring and that type of inference related to quantum information where there's something a little bit bigger and more complex or different than just simply low sampling rate leading to positional uncertainty of a massive train that's not subject to so-called quantum effects?


SPEAKER_04:
Well,

Did you wanna, so this is kind of cool.

Do you wanna unpack this slide here, Daniel?


SPEAKER_01:
I'm just looking forward to what the free choice assumption means in quantum setting.

But we just highlighted what is this all gonna say about free choice, this specific slide, but also the broader discussion.


SPEAKER_04:
So I agree, too.

I think the free choice aspect is cool.

Here, the authors say, provided A and B are separable, assuming that there are no super determinist a priori correlations, ZA and ZB, what is the Z?

I'm not sure what the Z is.

Oh.

choices of Z. So Z is the choice.

The choice of A and the choice of B are uncorrelated.

This is the free choice assumption.

Free choice is often claimed to be essential to science as a practice.

If it characterizes any bounded system, consistency with quantum theory and special relativity together requires that it must characterize all systems.

So free choice of a basis introduces quantum noise.

that is indistinguishable observationally from classical noise.

And noise is gonna become important here as we move toward the end of the A and ZB.

So yeah, anyway, that's cool.

Nice.

So here they talk about the Z axis in figure one.

I should have pasted figure one in here.

They say that the Z axis is a reference frame.

Free choice of the axis generalizes the free choice of the reference frame, encoding each qubit on the holographic screen fancy B, right?

So, yeah.


SPEAKER_01:
And the part in red, looking forward to unpacking.

A QRF cannot therefore be fully specified by any finite bit string.

It is non-fungible in the terminology of Citation 40.

It's the quantum act-inf NFT crossover that we all needed.

We have it, but we need to explore it and find out what it means.


SPEAKER_04:
Super cool.

And they say that they consider A and B to be isolated during the time interval between preparation and measurement steps.

And I think that we'll get into that in a little bit more like preparation and measurements as we talk about time and memory encoding.


SPEAKER_01:
And that's what this nine formalism is roughly describing.

Something like that.


SPEAKER_04:
Yes, I think, yeah.


SPEAKER_01:
What is happening with it?


SPEAKER_04:
So it says the idea of a computation is this.

So you have bits at one time step going to bits at another time step.

And then you have the Markov blanket at one time step going to another Markov blanket at T plus one.

And then this, is it ZA?

Is that free choice that's in there?

No, it's IF.

So I'm not sure what that one is, but.

Yeah, we can unpack that more.

I will unpack some of the later math, but this, I think it's just important to establish the quantum reference frame.

Anyway, yeah.


SPEAKER_00:
That's good.


SPEAKER_04:
Cool.

Okay.

Next.

Where are we?

Ah, here we go.

See, I'm going to start to unpack some math now.

When I start to roll out the variables, here we go.


SPEAKER_02:
Okay.


SPEAKER_04:
So...

We will be interested in what follows in quantum systems considered to be observers that deploy one or more distinct quantum reference frames to measure particular subsets of the bits encoded on their boundaries slash markup blankets.

And yes, these will effectively decompose the holographic green fancy B into disjoint sectors that we will label E for the observed environment, F for the unobserved environment, and Y for the memory sector, respectively.

Yeah, we're gonna break that out, I think.

Yeah, attention also, so they really talk about the sectors as a sense, right?

Like, so I have like my vision sector, my hearing sector, my taste sector, right?

And so like I'm making observations of my environment with all of these, like my temperature sensing sector.

So there's all of these different ways to observe the environment with different sectors.


SPEAKER_01:
So yeah, it's kind of like saying you win some, you lose some, you don't play every game.

It's kind of like whatever space we're talking about here, which happens to be this boundary that has all these interesting properties.

There's some that are being observed, some that are being unobserved and a special sector that gives continuity of information in some way through time.


SPEAKER_04:
Yeah.

So this is cool here.

Free choice of a decomposition of a holographic screen, fancy B, into sectors with different quantum reference frame induced semantics is indicative of agency.

So I like that.

And I'm curious to unpack that maybe a little bit more, something to ask the authors about in the dot one.


SPEAKER_01:
Yeah.

Or also all non-trivial agents are cognitive systems that engage in active inference.

What is non-trivial?

To who?

Like how do we escape or how do we escape this infinite multi-perspective multi-scenario universe or do we just have a way of working with that


SPEAKER_04:
I do think that they get into non-trivial here in a little while, but yeah, they say a non-trivial agent is a system with internal dynamics that breaks the swap symmetry of its boundary Markov blanket holographic screen.

However, they're going to start to use these things interchangeably.

So I'm just going to keep saying holographic screen, fancy B. But, but I guess if your internal dynamics don't break the swap symmetry or right, like if your internal dynamics are, are,

um, trivial or like not relevant.

Um, or if you don't, if they don't have an effect on the boundary, maybe that's, that becomes trivial.


SPEAKER_01:
Yeah.

Wondering if that's the mirror versus adaptive active inference boundary that we've discussed or what, what this maps to, where does this kick in or not?

So we'll explore it though.


SPEAKER_04:
It totally seems like it's definitely the mirror versus active inference.

That's how I interpreted it as I was reading it.

So yeah.

Sounds like that to me.


SPEAKER_01:
Oh, and okay.

Now we're going to head into some 17 related information because they're going to turn this discussion from QRFs as reference frames to channel theory, which is going to enable this context switching discussion that's important later.

So this is brought up in number 17.

and 17.1 is where we had Chris Fields and a great discussion there.

So continue, Blue.


SPEAKER_04:
Cool.

Yeah, so...

Channel theory of quantum reference frames.

So I think we've said channel theory is an application of category theory to two spaces.

And I'm not gonna read the paper here, but I'm gonna go back to some of the slides that we used from 17, because I think that we kind of unraveled it there in a way that was maybe digestible more so than reading equations off of a paper.

So this is the choose space.

Daniel, what's a choose space?

So K is a set, A are objects, X are attributes.

A choose space fancy A over the set K is the relationship between the objects, A, and their attributes, X. I thought of it just like a computer function, like in Python or any language that's just taking in three kinds of data


SPEAKER_01:
the set, the objects and the attributes.

So describing a large variety of things, but it's just kind of integrating those three types of data in a principled way.

and enabling transformations between different representations that might look very different or allow for different implementations, but also commonly use like all of this information or even just a subset of the information because that just throws out information, which you can always do.


SPEAKER_04:
I really like the Python example.

So like if K is the Python dictionary, A are the keys and X are the values, like you can describe the relationship between the keys and the values with a choose space.

Like that is what the choose space does.

So like you could say, you know, your keys are apple, orange, banana, and your values are red, orange, yellow.

And so then the choose space is how you describe that relationship.

Color of fruit, something like that.

Okay, so going into channel theory and how channel theory works.

So it says, in channel theory, two transforms become isomorphisms, which are natural maps between classifiers.

So classifiers link tokens to types that encompass them.

Like for a stoplight, a set of tokens would be red, green, and yellow.

So that is the set of tokens.


SPEAKER_01:
I think this just builds one level on what you described, which is instead of just the data structure of just saying this is what the function is requesting or this is what is being stored in memory, this is like saying we're going to interpret some of these edges and relationships as classifier mappings or infomorphisms like information sharing or statistical dependencies or some other type of informational edge.

but on that space that we've been discussing.


SPEAKER_04:
Yes.

So they take it to a diagrammatic level where at the center, it's almost looks like a pyramid.

So there's a C and this core C is the information channel.

This is the infomorphism that allows semantic information.

And this, I thought it was very cool that it's very different from Shannon information.

It's not just bits.

It's like the meaning behind the bits.

Like you can say, you know, you can see the word bank.

And are they talking about a river bank, the bank that holds your money or like a bank shot in pool?

Like there's some underlying.

I would dare to say context that is important for not just the letters B, A, and K in that order.

So it's not just the tokens in the particular order, but it's like the semantic context that allows transmission between classifiers.

So I look at this like a shared memory.

So if we look at the classifier A1 here, which would be stoplight, the tokens are red, green, and yellow.

Classifier A2 would be motorist actions.

The tokens would be stop, go forward,

Or I say proceed slowly, but it's really get out of the intersection, right?

Like that's what yellow means.

And then there's other classifier types.

It could be like pedestrian actions, child's game actions.

Like when you're playing red light, green light, do you run?

Do you stop?

Like freeze?

Or do you walk, right?

So there's all these different classifiers that can then map via a core information channel C, shared memory, semantic information between those classifiers.

Cool.

Okay.

So going on, they build from this pyramid.

They invert the pyramid to form this cone-cacone diagram.

So they say that...

A commuting finite cone-cocoon diagram is made of a cone, which is the upright pyramid, and a cocone, which is the inverted pyramid, on a finite set of classifiers.

It illustrates commutativity.

So specifically, these operators, G12, G23, like you can go all the way out to the set.

Like there's a commutativity or like a...

superimposability, commutativity, with a shared infomorphism, if that makes sense.

It also captures a more subtle duality between processes.

It enables object files, tokens, and histories to be viewed not as tokens, but as types that organize respectively trajectory components, features, and feature-based singular categories, and make them mutually consistent collections.

So like where you have all of those classifiers, they're consistent across the board.

So you can use them to map and unmap, right?


SPEAKER_01:
If I can just give a take on this.

So G12 is saying that there's a relationship between A1 and A2.

It could be like appending by one row or maybe changing one little bit through time or having some ability to translate like a state machine or something like that.

let's just say that there's some relationship and then there's also these f functions that allow the a's to be part of a shared context like the pedestrian scene that makes sense and then that is shaped like a cone

and then that is kind of like sense making that semantics is making sense and then this cocoon or the diamond shape is where there's c and d who are both like cognitive sense making frames and then now they're having a shared holograph


SPEAKER_04:
a or a shared access and then it's that is a different object with a different geometry yeah that would be like i'm looking at the same set of classifiers that you're looking at and we both see we both know what they mean we both know that red means stop and um green means go semantically exactly yeah

Right, right.

Or red could mean apple, depending on where you're going with that, right?


SPEAKER_00:
It could be an inside joke.


SPEAKER_04:
Yeah.

Okay, cool.

So there's the cone cocoon.

Hopefully that was unpacked with some level of intelligibility.

So now we can move into figure two.

Okay.

where they attach this cone to cone diagram to measurement operators, any set of measurement operators that are used to measure the states on the


SPEAKER_01:
boundary that defines the relationship between A and B, this HAB, between system A and system B. We're the scientists, we cared about our context C, we're system A, we're making measurements from our perspective of a screen, and we're setting the context of interpreting those observations in this situation.


SPEAKER_04:
Totally.

I could definitely be standing on the other side of that holographic screen, making my measurements from D, from the inverted, from the upside down pyramid, but they would be left and right pointing, measuring onto the same screen.

If I was system B and you were system A, in that kind of context.

Cool.

Anything else to add?


SPEAKER_00:
No.


SPEAKER_04:
Awesome.

Okay, so this is just some more, I think, this slide talking about the cone-cocoon diagram, but something that's to point out that there's the dual construction, that is when it commutes.

I think I did say that already.

So when the infomorphisms on the same classifiers where all the arrows are reversed, when it's reversible, then that's a commuting cone-cocoon diagram.

So non-commutativity is the opposite of that, right?

So we're going to talk about non-commutativity as we go forward.


SPEAKER_01:
And here, what's one thing that I think is happening, hopefully, is like we have been discussing this in the context of two different observers having the same semantics from the same screen, C and D. And then they say if C equals D or C prime equals D prime,

Then you can sort of draw another consistent world.

And this is sort of like a recognition semantics.

And then the out cone is like an operational or generative semantics in a different way.

Cause it's like generating the observations or something like that.

But there's going to be like a dual between the diamond and the hourglass.


SPEAKER_03:
Nice.

Cool.


SPEAKER_04:
Okay.

All right, here we go.

More of this commutativity.

So here they talk about commutativity as Bayesian coherence.

And we talked a little bit about quantum coherence earlier, but they're bringing this notion of Bayesian coherence up.

So viewing commutativity and Bayesian coherence as fundamental to the definition of measurement, like if I measure the length of the salamander and Daniel measures the length of the salamander,

there there we could get the same answer or not um so and hence also to the definition of preparation or action on the environment um so this suggests this foreign rule which is that's what you blew up daniel don't know what it is let's learn about it yeah okay yeah that was that one's um right let's learn about it let's let's let the authors unpack that one for us

Oh, yeah, that's the rule.

So here, blow it up again for me.

Oh, I'll blow it up, actually, myself.

So... Ah!

Too far.

So they say the probability of obtaining X with a state X is the sum of observations over states.

Is that observations over states?

I should have defined these.

And the probability of obtaining...

measurement?

Is it a measurement?

As an observational outcome?

Is the description for coherently assigning amplitudes to components?

Okay.

So, anyway, we can let the authors unpack that one for us.

I can't do it.

Okay.

All right, repeated measurements and system identification.

So this is section three, moving on.

We develop in section three, a generic formal description of how one quantum system identifies another quantum system as a persistent entity, a thing.

So here they're gonna talk about thingness and measures, records and compares its states by deploying specific sequences of quantum reference frames.

And so like, how do I know that Daniel is a different thing than me, right?

Yeah, that's cool.

Sometimes I think we're the same thing because we're doing the same thing at the same time.


SPEAKER_00:
Is there a group thing?


SPEAKER_01:
That's a group thing.

We're having a thing at my house.


SPEAKER_04:
That's it.

All right.

So they break this section.

So these sections get really awesome.

So memory, time, and course grading.

The idea that a system must possess a quasi non-equilibrium steady state solution to its density dynamics and hence be restricted to trajectories in its classical configuration space that do not diverge exponentially over time in order to be observable as a thing immediately raises the issues of time as a measurable duration and of memory

as persistent over measurable time.

And so that they show in this figure that the agent A can only detect changes in

the nest density and employ them as basis for inference.

If actions and actions, if a can write time ordered records to subsequently read from the memory sector, why?

So here the memory sector is why the environment is E and this G I J here, I think it's better done than the next one.

Oh yeah.

Perfect.

We have the next screen right here.

So E I J is this a time clock, a time step from,

One memory, that's the dynamics of internal time.

Internal clock, that's what it is, of the agent.


SPEAKER_01:
We talked already about the different parts of the screen and how some are being observed, some are unobserved, and then there's the memory sector.

And here, the unobserved environment is the biggest set, I think.

It's like...

mostly at least in this image and so one question is just what does this represent in terms of our computers or our sensory apparatus and how is it related to some of the work that they like cited and some related work about attention and bayesian graphs this is a cool representation also like notice that your observations are


SPEAKER_04:
different and not overlapping from your memory.


SPEAKER_01:
Like if your old memory, the new information isn't coming in, if you're not paying attention to anything, it can't have an effect, like that type of thing.


SPEAKER_04:
Right.

And so this is an illustration of quantum reference frames required to write a readable memory of an observed environmental state, E.

So E and Y read the state from E and write it to Y respectively.

And the clock is a time quantum reference frame that defines the time coordinate A. So at the time step, you read the environment and then you write it to memory Y. It's cool.


SPEAKER_01:
And there's papers.

A little perception action loop with memory.


SPEAKER_04:
Yeah.


SPEAKER_00:
Okay.


SPEAKER_04:
Yep.

In a loop.

Sorry.

Cool.

Awesome.

So figure four is,

It's a memory read-write cycle defining one tick from I to J of the environment.

So here it's like you read from the environment, measure or read-measure, and then write-prepare.

So like you prepare for the next time step.

All quantum reference frames and the comparison functions are implemented by the quantum dynamics PA, which is the big block arrow.


SPEAKER_01:
So if this were like a EEG headset that was measuring at 100 hertz, 100 times per second, that would be like 100 classical information reads per second.

And then you could do signal processing.

I think this is kind of like the time step is the sampling frequency of the experimental apparatus that's defined by this partitioning mechanism.

of the blanket fancy b holograph and then subsectors with these different interpretations of being like observed unobserved or memory components and and the authors say here they say formally we think of this pa um as the weighted sum of all possible paths from the boundaries boundary


SPEAKER_04:
From the boundary the fancy B at one state to the boundary the fancy B at the next state so that is the internal dynamics are how the holographic screen is shifted from T to T plus one and Also, this is where there's the cone So the the B are like those that line of A's that are all lined up and then now it's bottlenecking This is the hourglass and then going back out Yes

Yes.

Superpose those figures for next time.

Yeah.

Yeah.

All right.

Then memory, time, and core screening.

So the internal dynamics that operate on those states to maintain a non-equilibrium steady state density are spatially localized inside of the boundaries.

And the boundary represents a Hilbert space where we talked earlier, and it's not a physical space-time decomposition.

So the boundary B is all those little spheres.


UNKNOWN:
Yeah.


SPEAKER_04:
Still.


SPEAKER_01:
What is memory?

We'll discuss it later.


SPEAKER_04:
Yeah, and importantly, they say figure four illustrates an important distinction between classical and quantum representations of dynamics.

Classical physics assumes a space-time embedding, and the quantum does not.


SPEAKER_01:
Interesting.


SPEAKER_04:
Yeah, I'm curious about the self-evidencing that they mention here also.

I'll have to ask them about


SPEAKER_00:
Okay.


SPEAKER_04:
Okay, cool.

Learning and generative models.

I'll let you take this one away.


SPEAKER_01:
This kind of took us almost briefly out of the quantum, but just to give an example of a simpler thing that this is like an elaboration or a generalization of a Bayesian approach like Kalman filtering, which is just taking, it's like a dragging an estimate through time as new information comes in.

And so that's what's happening in a sense here with formalism 27.

There's a prior and a posterior, and that's moving forward.

So it's kind of like using this dragging filter through time, if that were classical information, and then there's something different happening with quantum.

And that's that piece that we're going to keep on returning to.

But this is like a Bayesian analog filter.

And now the math is being used to describe these quantum systems.


SPEAKER_04:
Yes.

Okay, moving on.

Section 3.3, identifying and measuring systems embedded in E. So we've so far considered only observers A that measure the states of their observed environments E without decomposing E into systems that have their own specific states.

And the question of how an observer distinguishes a system from the environment in which S is embedded is central to classical cybernetics.

So I think that that's...

important like are the other agents do they matter are they just part of the environment like there's always that um question of of you know is is it its own thing that other person over there or it's just my perception of my environment and the second part there is like it's um that sort of entity niche differentiation or delineation and then under the rubric of object persistence


SPEAKER_01:
conceptuality of thingness to cognitive and developmental psychology so that's like children with peekaboo and so it's like what connects the child playing peekaboo to the cybernetic entity differentiating causes and how does quantum with its observer based relationality connect those areas


SPEAKER_04:
So here they use a special delineation for an environment that indicates the remainder of E when other systems in the environment are removed.

And the question of how an observer distinguishes an external system from its surrounding environment prior to and as a precondition for measuring some state of interest.

is not something that people traditionally address because it is thermodynamically and computationally difficult, demanding special requirements on the observers.

Cool.

All right.

So figure five shows us a system.

I think it just shows us like pretty much where we are.

Systems S, you know, here you have A and B identifying a system.

requires identifying some proper component R that maintains a constant state or a density of time average samples as the pointer state of PI, right?

So you need a pointer to point to the system or density of time average samples of interest varies.

Oh, so like as this goes to attention, right?

So what is your, what are you pointing to?


SPEAKER_01:
Oh, another way I was kind of seeing this one was it's like a clock hand.

So this could be like a time scenario or it could be quantum with like the spin or with the angle in a complex field or something like that.

But you can decompose the total system S

into the time invariant part, which is like your Python data structure.

And that's like saying, here's the structure of the variables.

And then just like the variables themselves that are time variant, which is like the clock hands.

So there'd be like the body of the clock that's time invariant.

And then there's the parts that are time varying.

I don't know how that R and P and S partitioning connects back, but that's what this kind of looks like.


SPEAKER_04:
Yeah.

I'm also kind of unsure about the pointer states and, but I think it's the interest varies, right?

So, um, yeah, which I think, I think that points to attention, like as your interest, as your point of focus shifts, like what are you pointing to?

Because like, as you look here in one direction, there's a set of variables that are there in that direction, like this wall, that corner, this refrigerator or whatever.

And then as you shift here,

your interest or attention is shifting to a new set of variables, but you still know that that other set of variables is there.

That goes to the object permanence that we were just talking about before.

So like, I know that the refrigerator was in my first point of view, but it's not in my second point of view, but I know that it's still there.

That to me kind of is how I think about this, the pointer.

It'll be cool for the authors to maybe unpack this one a little bit more for us.

Oh, okay, we did talk about the Markov kernel versus the Markov blanket.

Daniel, you so eloquently explained it to me.


SPEAKER_01:
Just one possibility is the blanket is the set of states that insulate the internal and the external, making them conditionally independent.

And then the Markov kernel could be like that applied through time.

And it's kind of like a Rima model.

You could have like a temporal depth of an auto regression.

And then the temporal depth of the Markov kernel through time would be like what time steps are able to


SPEAKER_04:
carry forward but let's discuss that with people who know better yes cool okay good um all right so non-commutativity uh context switching so we talked about non-commutativity we talked about what commutativity means and so non-commutativity would be the opposite of that um so here they say as emphasized by bohr

100 years ago, a finite quantum of action partitions the set of all possible quantum measurement operators into a set of complementary non-commuting pairs, the most well-known being position and momentum.

So if you're trying to measure the position of a particle, you can't simultaneously measure the momentum of the particle at the same time.

So that's non-commutativity.

Yes.

And so why does context switching matter?

They say an observer A capable of switching between non-commuting quantum reference frames must, to maintain an operable memory, implement a clock that is invariant under basis rotations on the energy between A and B, or the physical interaction between A and B. If measurements made at clock ticks I and J do not commute, however, the corresponding clock operations will not commute.

So non-commutativity forces TA, which is time, or the time step that it takes to record a memory, to be unidirectional, and hence memory records to be encoded irreversibly with an accompanying expenditure of free energy.

So the internal clock thus defines TA as entropic time.

I thought that was super interesting.

So it's not like...

actual time but it's like time that you paid entropy for like time that entropy was expended for i'm on the clock that time requiring work right or over time over time okay something to that end all right uh

Cool.

So context switching between non-commuting quantum reference frames, like position and momentum, while holding the other quantum reference frame constant.

So that's the one that's constant is here, the one that's rough in this figure 34 or equation.

What is this thing?

It's a diagram.

That's what it is.

So in this diagram number 34, these different pointer sectors, U and V, could be like the different non-commuting points.

and then you have overlapping but mutually communicating operators in a canonical canonical context switch so that's like someone could be standing not at the

train platform or on the train and be observing both of those people, I suppose.

Different frame.


SPEAKER_01:
A bigger context.

They each have their own local coherence, but it's interoperable.

So it's part of a bigger umbrella, which is like the big C at the top.


SPEAKER_04:
Cool.


SPEAKER_01:
Okay.


SPEAKER_04:
Okay.

Good.

So that's diagram 34.

If it fails to commute...

then the observables are non-code deployable.

So that's like position and momentum.

Those are non-code deployable observables.

So non-commutativity in the

in diagram 34, has been specified in terms of non-existence of a consistently definable joint probability distribution of conditionals.

So that's like the conditional independence, right?

This non-codeployability of observables amounts to the occurrence of intrinsic quantum contextuality in relationship to that diagram.

So this goes really back, it speaks a lot to

what Chris talked to us about when we did number 17.


SPEAKER_01:
So let's get notes on this stuff.


SPEAKER_04:
Yeah, for sure.

So they say in 4.2 below that context switching increases variational free energy by generating prediction errors.

And if you're in one context and you have a prediction, and then you move to another context with the same prediction, your outcome's going to be different.

So it increases variational free energy, which makes minimizing variational free energy and complying with the FEP more difficult.

So going from my same generative model from one context to another context to another context makes it hard.

but can lead to radically better generative models.

So you're always updating, your model becomes more generalizable under different contexts.

So yes, context switching poses a fundamental challenge to any classical formulation of the FEP and a fundamental explanatum, I've not heard that before, for quantum formulations.

I wonder if this provides like some evidence for us having a shared reality.

And I've brought that up a couple of different times too.


SPEAKER_01:
Cool.

It's the fact thing or expression, which is to be explained or explicated.


SPEAKER_03:
Nice.


SPEAKER_00:
Okay.

Now let's get to the paper.

What do you think?


SPEAKER_04:
We're finally here.

We made it.

This is the best part.

Yeah, the FEP for generic quantum systems.

So all that background was to lead you here to this place where we are now.

So how the FEP emerges in this setting, and we're going to look at its asymptotic behavior, considering how it addresses the fundamental problem that's posed by quantum context switches.

All right, we're getting there.

All right, you want to take this one?


SPEAKER_01:
going to go into more detail so that we can get a lot more into this dot zero but we've seen the variational free energy in the context of perceptual inference where there's a surprisal and a divergence term that gets bounded so this is kind of like the snapshot question given the incoming sensory observations how should i update my generative model it's learning it's like a perceptual common filter


SPEAKER_04:
Yes.


SPEAKER_01:
It doesn't have action involved.


SPEAKER_04:
Nice.

They have this formulation of prediction error.

And this is actually from section 3.2.

It's a representation of the prediction error of system A or agent A. So this E-R-E-K.

So K, let's go through these black ones first.

So K is the internal time clock.

So agent A's internal time clock, T-A.

It counts it.

It ticks it up.

So fancy B is the holographic screen.

PB is the dynamics of the interaction partner B. And then this M sub E with respect to K is the observable behavior of the holographic screen fancy B localized to the sector E up to time TA equals K. So like up to leading up into this point.


SPEAKER_01:
And E is the observed environment just to connect it to the previous formalism.

E is the observed environment.


SPEAKER_04:
That is it.

So here, this M-A-E, this is the agent A's generative model of the action of the unknown dynamics, P-B, with respect to time, I think.

Oh, yeah.

On the Markov boundary holographic screen, fancy B, in sector E, the environment that we looked at.


SPEAKER_01:
Which is kind of like saying you only need to have a generative model on where you're expecting to find observations.

If you're going to measure just the thermometer, you make a generative model with just a thermometer.

And that's how you get the cone, co-cone, diamond, hourglass that isn't like with extraneous or redundant or incompatible elements.


SPEAKER_04:
So here, this equation prediction error, it's like ER sub E parentheses K. This is the agent A's total reducible uncertainty about agent or system B at time TA equals K.

So this is like the uncertainty about another system within the environment.

That's why the system separation that we saw in figure five was important.

So if we're gonna define a system, we're gonna look at how other systems interact on the holographic screen, and then we're gonna think about what, can we predict what that system is doing or not?

Like the environment's not doing anything, because it's just sitting there, it's the environment, but that's at any given time step snapshot.

So it is therefore an upper bound on surprise, and now we get to f of pi that we just looked at earlier that Daniel mentioned, the upper bound on surprise.

Cool.

Okay, here we go.

Getting into how the quantum does the FEP.

All right.

So a generic quantum system A will act so as to minimize er sub x for each deployable quantum reference frame

So a system A has different deployable quantum reference frames that's analogous to a sense.

I have hearing, vision, taste, smell, temperature sensing, et cetera, many different deployable quantum reference frames.

And I will minimize my total reducible uncertainty at each time step for each quantum reference frame.

Yes.

Still there?

Okay, so a trivial agent can be viewed as executing a trivial quantum reference frame as only exercising choice of basis for writing to and reading from the holographic screen fancy V as a whole, and so satisfies the FVP trivially.


SPEAKER_01:
Okay.

Let's have a round table on what that means.

We should do it.


SPEAKER_04:
Yeah.


UNKNOWN:
4.2.


SPEAKER_04:
That's it.

Or 40.1.

And here's equation 40.


SPEAKER_00:
Nice.


SPEAKER_04:
There it is.

All right.

So the authors say uncertainty and prediction error and hence variational free energy is generated in the current formalism by system A's in principle ignorance of both the state of B and the dynamics P of B of its interaction partner B.

As the bits A reads from the boundary fancy B are written by PB, this is like the agent or system B is writing to the boundary.

So A's ability to predict the future states of its observable sectors and hence to minimize that ER sub X for each quantum reference frame X

through equation 40, which we just looked at and we're going to look at it again, depends on its ability to predict the behavior of PB locally on each observable sector.

So I have to be able to predict how Daniel's going to smell, how he's going to look.

So my ability, if I'm looking at my other agents in the environment, over each, what temperature he's going to be, is he going to have cold hands or cold feet or something like that?

My ability to minimize my variational free energy over another system in the environment depends on my ability to predict their behavior right into the environment on all of those quantum reference sectors.

Good?

Enough?

Good enough?

Okay.

An animal, for example, must employ its available senses, hence its observable sectors, to predict the nutritional value of food.

Okay.

Here we go.

So this is where I get, it gets a little fuzzy for me.

uh i was good up until this point um they say the weak interaction limit that allows separability between a and b is significant so hab which is the physical interaction between a and b and hence the boundary the holographic screen between a and b must have significantly lower dimension than

the physical location of B, and hence the observable dynamics of B, if the weak interaction limit is to hold.

My brain is melting now, all the way down.

So, yeah.

Anyway, what do you think?

Do you have any thoughts on that, Daniel?


SPEAKER_01:
Not sure if it means that the sparse coupling has to be sufficiently sparse.

It has to be a lot lower dimension than the system.

Otherwise, it's not appropriately

bottlenecked so there's a lower dimensional interface that's like sparse coupling it's physical interaction in the h um frame and it's the holograph slash markov blanket with the fancy b but if the interaction is with the h and that's kind of what we'll

discuss like are we talking about physical interactions of quantum systems are we talking about any mechanistic interaction between any mechanistic system or are we talking about statistical edges statistical interactions like an interaction term between two different systems


SPEAKER_04:
And so just what I've written down here kind of paraphrases what they said up there.

So the ability for a system A to predict the dynamics of system B depends on the dynamic complexity of the interaction between system B, which is PB on the holographic screen.

So what is B writing to the holographic screen?

Like what is my refrigerator writing to the holographic screen?

I would say that's a trivial system, right?

It's like outputting a little bit of heat.

It keeps my food a little bit cold most of the time.

So I can with,

pretty good reliability predict the dynamics of my refrigerator.

I have less ability to predict the dynamics of Daniel or my children who are like total agents of chaos.

Right.

So, but, but like, I want to minimize my uncertainty.

I'm pretty certain about what my refrigerator is doing.

I don't know what my kids are doing when I leave the room.

Yeah.

So that, that kind of made sense to me, but.


SPEAKER_01:
The Schrodinger's cat to blues children pipeline.


SPEAKER_04:
We just got there.

Anything else to add here, Dan?


SPEAKER_00:
No, let's...


SPEAKER_04:
Moving forward.

Okay, so here is a little diagram of what it looks like for me to predict the dynamics of my refrigerator.

So this is figure six A. It says the trivial agent in figure six panel A looks like a noise source to A. So yes, my refrigerator is a source of noise.

It actually literally makes noise and puts out a little bit of heat.

So it says emission of Hawking radiation from a black hole provides perhaps the most pure example of such a noise source.

While the intervention inside the black hole can be arbitrarily large, the internal dynamics are uncoupled from the classical information encoded on the horizon and hence have no classical computational power.

Yes.

Okay.

Maybe my refrigerator has more computational power than a black hole.

I don't know.


SPEAKER_00:
Okay.

Okay.


SPEAKER_04:
Okay, we move on.

Here we go forward.

So the more interesting parts of A's option space for prediction are shown in panel B, C, and D, where B is non-trivial.

If B is non-trivial, it deploys at least one quantum reference frame, X of B, so that's sector X of B, acting on sector FB.

As discussed in section 2.5, B sectors must be mutually decoherent.

So the action of the dynamics on the sector of B is independent of action elsewhere.

It is this independence that makes prediction possible.

If X of B does not overlap any sector for A, B will appear trivial.

So if the green cone is totally removed from where the red cone is, it's a trivial thing.

If my kids aren't here right now, they're not immediately acting on my environment.

So they're trivial, I guess.


SPEAKER_01:
This made me think about if someone was speaking a language that you didn't understand semantically,

not even in the cues and in the metadata, like there's kind of speaking past each other, even though you're sharing a screen, but that's like an attentional informational interpretation.

And this is in a quantum interpretation about the shared semantic frame ranging from identical to overlapping to disjoint.


SPEAKER_04:
So in a disjoint,

Wait, I'm trying to think of what else would be there.

So like a different language is good, but like, what about something like radiation emission, right?

Like, so something's emitting radiation, but I can't perceive that radiation.

So like the thing emitting radiation doesn't appear like it's impacting my environment at all.

So maybe something like that.


SPEAKER_01:
And that'd be like maybe unobserved, the part of B, the holograph that's not in the observed or memory sector.


SPEAKER_04:
Yeah, like that.

Okay, cool.

So...

The interesting cases are the ones in which A and B's observable sectors overlap.

In this case, intuitively, in which A and B can see each other and hence interact in the ordinary non-technical sense of that term.

In panel B, sector XB fully contains XA.

We out.

Okay, so let's look at the whole figure now.

So we saw all the ones trivial and non-trivial.

Okay, so A is a trivial agent, so they're not putting out any code.

B encodes a sector that contains XA, but is bigger.

So I like to think about this as like a teacher.

So we're going to get into like teaching and learning.

So this is like a teacher that knows more than the student can pick up, maybe.

Okay.

in that kind of way.

So the bits on XB but outside XA encode non-local hidden variables for A.

And then in diagram C, the sectors of A and XB overlap, the areas of non-overlap become noise sources.

So here it's like, you know, I can understand you when you speak English, but not when you speak Chinese.

So like when you're speaking Chinese, we have this non-overlapping frame.

Anyway, how do you think of that, Daniela?


SPEAKER_01:
This is just speculative, but in the case of B, so we're the observer investigator A. So in the case of frame B, there's so much information like in the linear regression data set by quantum that there's basically anywhere we look, we can totally get all the information.

So it looks like there's non-local hidden variables because it's like super determined.

In the case of C, the regression has like an R squared of 0.5 or something or 0.6.

And so some of it lines up semantically.

But if we, of course, had the perfect attention or the perfect observation, we would be able to make a better regression.

But then I'm just trying to take the linear regression, normal information framework, and then...

that's where having people familiar with quantum will be really helpful and i hope they find this discussion and the upcoming dot one and dot two as like just the introduction of hopefully some bi-directional exchange because this may be something where active inference is complementary isomorphic incompatible

like let's not lose touch with the active inference thread.

And then also how is this relating to quantum?

And that's how we're going to get up in that quadrant where they're both are.


SPEAKER_04:
Yeah.

So in D, where the sector of X is equal to the sector of, sorry, the sector X of A is equal to the sector X of B. So that means that the quantum reference frame is identical.

It's an identical frame.

Like we are sharing a quantum reference.

We're both standing on the platform or we're both on the train.

And so that sector A is equal to sector B. Any variational free energy there between A and B is generated by insufficient learning.

It's not like we both can't see the train or we both can't see the platform because we're in the same place.

But so there's somebody there is doing some insufficient learning.


SPEAKER_01:
If this is the case, then you just simply need to sample more.

But you already have the right scope and you're not at risk of oversampling.

but it's a little bit more quantum.


SPEAKER_04:
Cool.

And that brings us to this beautiful formulation in equation 41.

Variational free energy equals noise plus insufficient learning.


SPEAKER_01:
So noise is capturing that bottom left part that we just discussed, and insufficient is capturing the D case.

And so if it was...

more and more overlapping, then you want more and more sampling.

But less and less overlapping is gonna require less and less learning, or learning will be less and less helpful.

So how is this compatible, incompatible with the Act-Imp framings that we've seen for VFE?

and EFE?

And then how is this compatible or similar to some of the formalisms and the framings that are really familiar to statisticians and to quantum information scientists?


SPEAKER_04:
And I would also like to like, know what teachers think that you're a teacher and you're watching this.

Like, like, what is your take on that?

Do you minimize free energy by minimizing loin noise?

And, you know,

Maximizing learning or, yeah, like that.

Okay.

Cool.

So asymptotic behavior of the FEP.

So we have these two formulations, surprise alone divergence, which we've seen before in a similar way many times, and then noise plus insufficient learning.

So now we want to say, how is it minimized?

How does an agent act in accordance with the FEP?

What do you want to add here?


SPEAKER_01:
Yeah, just they wrote, comparing equations 35 and 41, it becomes clear what this amounts to.

A system self-evidence is by behaving in a way that minimizes noise while improving learning.

And so here they're juxtaposing the F of pi on surprisal and divergence decomposition of variational free energy with this noise plus insufficient learning

framing so we'll have time to unpack that and hopefully connect it to some systems but it's just a very interesting way that they've reached this trade-off learning requires seeking it's like how do we get there


SPEAKER_04:
Well, that goes back to the context switching.

If you're always in the same context, if you're always listening to the same music, you're never going to learn any new music that someone else might know.

So you have to kind of change your context, maybe.

Take someone else's perspective.


SPEAKER_00:
But, you know, seeking what?

But we'll get there.


SPEAKER_04:
Yes.

Okay.

So...


SPEAKER_01:
Let's also save this for dot one, but the asymptotic behavior of the FEP, let's just say, why does it matter?

Why are we studying asymptotic systems?

What is happening with the FEP asymptotically?

Asymptotically meaning what?

But I think that that's a large discussion about entanglement and where everything is going and how it relates to the principle of unitarity.


SPEAKER_04:
Yes.

Okay, cool.


SPEAKER_01:
Just we'll get there in dot one.

Unitary asymptotic behavior.


SPEAKER_04:
Yeah, that's a good answer.

Yeah, there's only one more slide is the how, yeah, the FEP drives, it becomes the principle of unitarity.

So we can discuss that in dot ones better.


SPEAKER_01:
How does it, does it, why does it matter?

Why would it matter?

Cool.

Okay, discussion.


SPEAKER_04:
Drive us home, please.


SPEAKER_01:
Okay.

We're not going to discuss any of the discussion here.

We're going to look at the summary of the results as they give it.

And then we're going to have a bunch of slides that will just be like a topic.

And then with the dot one and the dot two, we're just going to go to that topic and probably start with just reading a quote from that paragraph.

or hearing the author's or the participant's perspective on each of those topics.


SPEAKER_03:
Cool.


SPEAKER_01:
Okay.

You can go for the summary.


SPEAKER_04:
Come on, help me out.


SPEAKER_01:
Okay.

You read the three, just the three big texts at the very beginning.

But the first summary of the results that the authors say is that they can formulate this agent or information gathering and using system

not just within the classical information theory context that we've been talking about informational and strategic agents, but in the context of quantum information theory.

Point two is not just using a generic agent or information gathering using system, but specifically connecting the FEP to its quantum theoretic formulation

for generic quantum systems, insert all the asterisks and other symbols about what that really means and about how active inference plays in, et cetera.

And then three, the part that we didn't really go into in this discussion, when formulated as a generic principle of quantum information theory, the FEP is asymptotically equivalent to the principle of unitarity

And Ander asked in the chat asymptotically in what parameter, just exactly.

To what end, in what parameter.

So that's the summary of the results.

But the authors then embark on an awesome series of kind of like standalone paragraph vignettes related to a wide set of other ideas.

So for each of these ideas,

I'll ask the question on the top, and then if you want to give a thought on that topic or not.


SPEAKER_04:
Okay, so the first topic is... Let me answer the question.

So it says actually asymptotically perfect learning.

So that's the asymptotically perfect learning that drives to unitarity.

On what axis?

So anyway.


SPEAKER_01:
Okay.


SPEAKER_04:
Go ahead.


SPEAKER_01:
What is observation?


SPEAKER_04:
That's deep.


SPEAKER_01:
several paragraphs they wrote about that and this quote the idea of a metaphysically solipsistic or solipsist theory of observation is self-contradictory what but we'll discuss okay

what is an agent and again we'll keep in mind classical physics classical FEP non-classical FEP that where are we bigger from earlier I'll copy that one back in because this is definitely like a where are we like what are the similarities and differences in the agent model

for FEP and not, and for quantum and not.

Any thoughts or things that you'll want to ask about this?


SPEAKER_04:
What is free choice?

I think that was cool.


SPEAKER_01:
Yeah.

And like, do you get degrees of freedom or free choice over cognitive parameters, action parameters?

Which one do you want choice over or all them preferences?

Okay.

what is self-evidencing so we've talked in several other discussions about classical or bayesian inference as self-evidencing like finding oneself in likely states expected and preferred states how is that different in active than other physics that's like going from the bottom left to the bottom right

then how is this different within active inference with this quantum integration and boost yes okay what of asymptotic behavior

yeah um so i think here it's the asymptotically perfect learning like what is a gauge theoretic perspective i don't even want to open that can of worms at all yeah also this is like the quantum formulation the quantum formalism is background free space is simply an observable represented by a qrf that a system may or may not deploy

It can therefore play no ontic role in maintaining distinctions between systems.

This reflects the general role of physical 3D space in quantum field theories.

Space is there to enforce separability.

C68 for general discussion from a gauge theoretic perspective.

So like the space between is what?

I'm going to also copy in a comment that Andre wrote in the live chat.

Anyone who asks questions, just put it in live chat or put it as a comment under the video or email us.

It helps us and it's awesome questions that people ask.

Okay.


SPEAKER_04:
We will definitely look at this before we do the one.

And so you're welcome to join us, get in touch if you want to participate live, but also like we will ask these questions and we leave them in the chat.


SPEAKER_01:
yeah okay let's go to close out almost kind of getting there applications to biological cognition um and then they wrote in this paper in addition to the results listed above the current framework

the paper we've been discussing has a variety of more specifically biological consequences some of which have been discussed already in citation 13. and here's citation 13 fields glazebrook 11 minimal physicalism as a scale-free substrate for cognition and consciousness and here's the sections of that paper

And so it's just kind of cool to connect back to the basal cognition, computational boundaries of a self discussion that we've been having.

Livestream number 39 just today.


SPEAKER_04:
And we also have neurons as hierarchies of quantum reference frames, which I haven't read yet, that this was just published in January of 22.

I think that was co-released with this paper.

So I'm excited to read that work also.


SPEAKER_01:
Awesome.

So yeah, what are the biological implications?

Okay.

Quantum frames for foraging.

Okay.

So unique explanations and predictions.

It predicts, for example, that moving an ordinary 3D space does not require a QRF for Euclidean space and hence does not require an experience of space.

So like the fish could swim without knowing 3D.

And then from a classical perspective, okay, so I guess that means non-FEP and or non-quantum.

This is certainly true, evidenced by place and grid cells in mammalian brains, etc.,

And then what happens when we integrate FEP in the classical?

Well, the coarse graining would then be mandated by et cetera, et cetera, et cetera.

We'll explore.

Okay, then what happens if we go from classical to classical FEP and then now go from FEP to quantum FEP, still thinking about like foraging or information seeking and processing?

Okay.

contextuality we talked about that a lot in 17.1 but just what is context environment surrounding is this what people mean when they say set the context for the dinner party or give context for a video that they sent what is that everyday sense of context and what is this sense of context

Okay, next steps.

So these are the last two lines of the paper.

And they wrote, in closing, we hope that we have shown to readers familiar with the FEP and active inference framework that quantum effects are worth considering both theoretically and in experimental design.

For readers not familiar with the classical FEP, but literate in quantum theory,

or vice versa, we hope this paper has gone some way to contextualizing your QRFs in sensemaking via Markov blankets and their underlying holographic screens.

So this is like saying, if you were familiar with either quantum, not FEP, upper left, or classical FEP, bottom right, or maybe bottom left, neither, then this paper

hopefully brought you towards that upper right corner of quantum FEP.

And just like the classical, classical way to end an FEP paper was like, we expect and prefer that this reduces your uncertainty.

This is like the classical quantum way to end the paper by saying, we hope it's contextualized your QRF.

the clever ending to a very complex paper and it was really fun to work on this for a couple weeks leading up to these discussions and what else would you say as we now head into the dot one and two


SPEAKER_04:
So thanks for putting up with our rough interpretation of this paper and we hope we didn't butcher it too badly.

We tried.


SPEAKER_01:
Yeah, if you know more or would like to contribute to helping others know more about these topics, that's what we're working on all the time in Act and Flap.

So if you've made it this far and you're riled up or curious about something, then get in touch and let's try to make all of this more...

handleable and able to be translated and learned and applied let's try to align our quantum reference frames with respect to active what else can we say all right so see you all um soon thanks a lot blue thanks also jason and thanks everybody who will participate in the upcoming ones too so see you later bye