1
00:00:07,120 --> 00:00:28,640
[Music]

2
00:00:28,640 --> 00:00:31,599
hello everyone welcome to actinflab

3
00:00:31,599 --> 00:00:35,120
livestream number 43.2

4
00:00:35,120 --> 00:00:39,718
it is may 11 2022.

5
00:00:39,840 --> 00:00:42,000
welcome to the actin flap we're a

6
00:00:42,000 --> 00:00:44,559
participatory online lab that is

7
00:00:44,559 --> 00:00:46,640
communicating learning and practicing

8
00:00:46,640 --> 00:00:48,559
apply active inference

9
00:00:48,559 --> 00:00:50,399
you can find us at the links on this

10
00:00:50,399 --> 00:00:51,520
slide

11
00:00:51,520 --> 00:00:53,760
this is a recorded and archived live

12
00:00:53,760 --> 00:00:55,760
stream so please provide us with

13
00:00:55,760 --> 00:00:58,800
feedback so we can improve our work

14
00:00:58,800 --> 00:01:00,879
all backgrounds and perspectives are

15
00:01:00,879 --> 00:01:03,280
welcome and we'll follow good video

16
00:01:03,280 --> 00:01:05,840
etiquette for live streams

17
00:01:05,840 --> 00:01:07,360
if you want to learn more about what's

18
00:01:07,360 --> 00:01:09,520
happening at actinflab

19
00:01:09,520 --> 00:01:10,640
greetings

20
00:01:10,640 --> 00:01:13,520
head over to activeinference.org

21
00:01:13,520 --> 00:01:15,439
and you can find out more about

22
00:01:15,439 --> 00:01:17,600
participating on live streams or

23
00:01:17,600 --> 00:01:20,080
other modes of participation

24
00:01:20,080 --> 00:01:23,520
and today we're in 43.2

25
00:01:23,520 --> 00:01:26,640
where as always it's uh up to the last

26
00:01:26,640 --> 00:01:30,159
minute with what we actually do

27
00:01:30,159 --> 00:01:33,360
and welcome also to stephen

28
00:01:33,360 --> 00:01:35,040
uh we're going to continue this

29
00:01:35,040 --> 00:01:37,280
discussion in our third part

30
00:01:37,280 --> 00:01:38,479
of the

31
00:01:38,479 --> 00:01:40,159
conversations we've been having on this

32
00:01:40,159 --> 00:01:41,280
paper

33
00:01:41,280 --> 00:01:43,520
predictive coding a theoretical and

34
00:01:43,520 --> 00:01:45,360
experimental review

35
00:01:45,360 --> 00:01:46,799
and

36
00:01:46,799 --> 00:01:48,720
we'll begin with the introductions

37
00:01:48,720 --> 00:01:50,880
and then we can

38
00:01:50,880 --> 00:01:52,720
move around the paper we brought up some

39
00:01:52,720 --> 00:01:54,799
things that we'd like to cover

40
00:01:54,799 --> 00:01:55,920
last week

41
00:01:55,920 --> 00:01:59,520
for today but also we can take it any

42
00:01:59,520 --> 00:02:02,159
questions or areas or sections that any

43
00:02:02,159 --> 00:02:04,960
of them want to talk more about we can

44
00:02:04,960 --> 00:02:07,280
absolutely go there so we'll just start

45
00:02:07,280 --> 00:02:09,440
with introductions and say hi and feel

46
00:02:09,440 --> 00:02:10,560
free to

47
00:02:10,560 --> 00:02:12,720
add anything you'd like um

48
00:02:12,720 --> 00:02:13,520
what

49
00:02:13,520 --> 00:02:15,360
brought you to the paper or what's just

50
00:02:15,360 --> 00:02:17,599
one thing that you took away from it and

51
00:02:17,599 --> 00:02:19,760
then i'm sure we'll have some fun today

52
00:02:19,760 --> 00:02:22,400
so i'm daniel and i'm a researcher

53
00:02:22,400 --> 00:02:27,200
in california and i'll pass it to dean

54
00:02:31,360 --> 00:02:33,519
how goes it dean

55
00:02:33,519 --> 00:02:36,400
oh sorry i was muted in jitsi so

56
00:02:36,400 --> 00:02:39,360
it was on the live stream but welcome to

57
00:02:39,360 --> 00:02:41,120
dean and steven

58
00:02:41,120 --> 00:02:42,239
and uh

59
00:02:42,239 --> 00:02:45,200
i'll also share the slides with you here

60
00:02:45,200 --> 00:02:47,920
in the chat but we're

61
00:02:47,920 --> 00:02:50,480
live and in the game so feel free to say

62
00:02:50,480 --> 00:02:51,599
hello

63
00:02:51,599 --> 00:02:54,319
and anything um uh just to

64
00:02:54,319 --> 00:02:56,239
get us going with this discussion

65
00:02:56,239 --> 00:02:58,560
getting a bunch of feedback on

66
00:02:58,560 --> 00:03:00,720
from somewhere daniel

67
00:03:00,720 --> 00:03:04,680
let's go it's going good

68
00:03:07,920 --> 00:03:10,159
i'll i'll open up another window so that

69
00:03:10,159 --> 00:03:12,959
you can see what slides i'm working on

70
00:03:12,959 --> 00:03:13,760
um

71
00:03:13,760 --> 00:03:16,239
but yeah how goes it or what what was

72
00:03:16,239 --> 00:03:19,840
interesting to you about this paper

73
00:03:24,560 --> 00:03:28,440
do you hear me dean

74
00:03:34,640 --> 00:03:37,359
that's me

75
00:03:40,799 --> 00:03:41,840
okay

76
00:03:41,840 --> 00:03:44,080
all right all right

77
00:03:44,080 --> 00:03:46,400
okay

78
00:03:46,560 --> 00:03:48,400
i can hear you now yeah i could hear you

79
00:03:48,400 --> 00:03:49,760
i couldn't hear you before sonic was

80
00:03:49,760 --> 00:03:53,280
weird sound fine dean

81
00:03:54,319 --> 00:03:56,159
i can hear you daniel but there's a long

82
00:03:56,159 --> 00:03:59,360
delay and uh there was a i can hear i

83
00:03:59,360 --> 00:04:01,360
could hear feedback like a second audio

84
00:04:01,360 --> 00:04:03,760
loop going off while you were talking

85
00:04:03,760 --> 00:04:05,439
okay did you have the stream open or

86
00:04:05,439 --> 00:04:07,280
anything

87
00:04:07,280 --> 00:04:08,319
i just

88
00:04:08,319 --> 00:04:11,120
no i just have the picture of the of the

89
00:04:11,120 --> 00:04:13,040
three of us okay i'll just reload just

90
00:04:13,040 --> 00:04:15,599
to be sure

91
00:04:15,599 --> 00:04:19,040
so it goes with live streams

92
00:04:19,040 --> 00:04:19,918
all right

93
00:04:19,918 --> 00:04:23,840
okay so is that better

94
00:04:26,960 --> 00:04:29,198
we'll

95
00:04:29,919 --> 00:04:31,680
roll with it then

96
00:04:31,680 --> 00:04:32,880
so

97
00:04:32,880 --> 00:04:34,320
okay or

98
00:04:34,320 --> 00:04:36,160
we'll see what happens so yeah steven

99
00:04:36,160 --> 00:04:38,639
how goes it and what do you like about

100
00:04:38,639 --> 00:04:42,320
the paper as we start

101
00:04:42,320 --> 00:04:44,000
well i'm just interested in the general

102
00:04:44,000 --> 00:04:44,880
scope

103
00:04:44,880 --> 00:04:45,759
um

104
00:04:45,759 --> 00:04:48,240
as per normal so i'm sort of going to go

105
00:04:48,240 --> 00:04:49,680
with the go with the

106
00:04:49,680 --> 00:04:51,520
the overall vibe of

107
00:04:51,520 --> 00:04:52,639
um

108
00:04:52,639 --> 00:04:54,000
pushing the boundaries of active

109
00:04:54,000 --> 00:04:55,759
imprints

110
00:04:55,759 --> 00:04:58,160
um i'm fairly i'm fairly relaxed with

111
00:04:58,160 --> 00:05:00,160
this one

112
00:05:00,160 --> 00:05:02,720
okay hey dean work better

113
00:05:02,720 --> 00:05:04,800
yeah my my bad

114
00:05:04,800 --> 00:05:06,800
all good all good thank you for telling

115
00:05:06,800 --> 00:05:09,280
me not to have both jitsi and the

116
00:05:09,280 --> 00:05:11,919
youtube open at the same time so

117
00:05:11,919 --> 00:05:13,199
yeah

118
00:05:13,199 --> 00:05:14,720
that uh

119
00:05:14,720 --> 00:05:16,240
these little technical things that i

120
00:05:16,240 --> 00:05:19,120
should have been uh more on top of

121
00:05:19,120 --> 00:05:21,520
there's like some reflex where if your

122
00:05:21,520 --> 00:05:23,360
own audio is played back to you at a

123
00:05:23,360 --> 00:05:25,840
certain delay it makes it like basically

124
00:05:25,840 --> 00:05:27,919
implausible to speak it's pretty

125
00:05:27,919 --> 00:05:29,120
interesting

126
00:05:29,120 --> 00:05:31,440
yeah well apologies guys that's not the

127
00:05:31,440 --> 00:05:34,160
start i wanted

128
00:05:34,160 --> 00:05:36,720
all good so how goes it or what like

129
00:05:36,720 --> 00:05:38,320
brought to you to this paper or what did

130
00:05:38,320 --> 00:05:41,759
you find interesting and what they wrote

131
00:05:41,759 --> 00:05:42,560
well

132
00:05:42,560 --> 00:05:45,840
i'm i'm not really totally up on on what

133
00:05:45,840 --> 00:05:47,039
predictive

134
00:05:47,039 --> 00:05:48,080
coding

135
00:05:48,080 --> 00:05:49,520
is i think i know what predictive

136
00:05:49,520 --> 00:05:52,720
processing is and when when you

137
00:05:52,720 --> 00:05:54,560
and maria were talking in the dot zero

138
00:05:54,560 --> 00:05:56,400
or you were blue or talking in the dot

139
00:05:56,400 --> 00:05:57,440
one

140
00:05:57,440 --> 00:05:58,720
um

141
00:05:58,720 --> 00:06:01,440
just the sort of the translation of that

142
00:06:01,440 --> 00:06:02,800
into

143
00:06:02,800 --> 00:06:04,960
operations that you can

144
00:06:04,960 --> 00:06:07,280
you can

145
00:06:07,280 --> 00:06:09,280
identify with a certain amount of

146
00:06:09,280 --> 00:06:10,560
confidence

147
00:06:10,560 --> 00:06:12,080
is the part that i'm really interested

148
00:06:12,080 --> 00:06:13,440
in i'm not really sure what the

149
00:06:13,440 --> 00:06:15,840
applications are

150
00:06:15,840 --> 00:06:17,759
beyond the psychology realm i'm sure

151
00:06:17,759 --> 00:06:19,680
there are quite a few and that's kind of

152
00:06:19,680 --> 00:06:22,720
why i showed up today was to sort of

153
00:06:22,720 --> 00:06:25,199
piggyback on what what people who

154
00:06:25,199 --> 00:06:26,720
obviously know a lot more about this

155
00:06:26,720 --> 00:06:27,840
than i do

156
00:06:27,840 --> 00:06:29,520
are saying about it and where it's going

157
00:06:29,520 --> 00:06:32,960
and what the potentials of it are

158
00:06:33,199 --> 00:06:35,440
all right well let's

159
00:06:35,440 --> 00:06:37,199
start with a few

160
00:06:37,199 --> 00:06:39,919
reminders and recalls

161
00:06:39,919 --> 00:06:42,800
is there any area or figure or formalism

162
00:06:42,800 --> 00:06:44,400
that either of you would like to suggest

163
00:06:44,400 --> 00:06:46,800
that we jump to to remind ourselves of

164
00:06:46,800 --> 00:06:48,319
anything critical about the paper

165
00:06:48,319 --> 00:06:50,000
otherwise i can

166
00:06:50,000 --> 00:06:51,599
bring this to some

167
00:06:51,599 --> 00:06:53,039
is it okay to start with the back

168
00:06:53,039 --> 00:06:56,240
propagation of error

169
00:07:00,800 --> 00:07:02,479
all right

170
00:07:02,479 --> 00:07:05,599
so i'll bring in this was in um section

171
00:07:05,599 --> 00:07:07,599
four so i'll be bringing in some but

172
00:07:07,599 --> 00:07:10,639
let's um we're gonna ramp into it

173
00:07:10,639 --> 00:07:13,199
just as a reminder about the roadmap

174
00:07:13,199 --> 00:07:15,360
so the first section of the paper is an

175
00:07:15,360 --> 00:07:16,479
introduction

176
00:07:16,479 --> 00:07:18,560
the second section of the paper

177
00:07:18,560 --> 00:07:21,199
describes with quite a lot of detail

178
00:07:21,199 --> 00:07:22,400
the core

179
00:07:22,400 --> 00:07:24,639
kernel of the predictive coding

180
00:07:24,639 --> 00:07:27,360
architecture this is a computational

181
00:07:27,360 --> 00:07:30,319
architecture and it involves information

182
00:07:30,319 --> 00:07:32,000
transmission

183
00:07:32,000 --> 00:07:35,360
that is in this predictive coding way so

184
00:07:35,360 --> 00:07:38,080
check out the paper the zero the dot one

185
00:07:38,080 --> 00:07:39,520
that's where we're going into a lot of

186
00:07:39,520 --> 00:07:42,240
detail on predictive coding as an

187
00:07:42,240 --> 00:07:44,160
information architecture and then as

188
00:07:44,160 --> 00:07:46,160
maria was

189
00:07:46,160 --> 00:07:47,680
bringing out for us predictive

190
00:07:47,680 --> 00:07:49,759
processing might be used to refer

191
00:07:49,759 --> 00:07:51,919
perhaps more holistically to systems

192
00:07:51,919 --> 00:07:54,000
engaging in predictive coding and

193
00:07:54,000 --> 00:07:55,919
there's a bi-directionality there to

194
00:07:55,919 --> 00:07:58,160
predictive processing whereas predictive

195
00:07:58,160 --> 00:08:00,160
coding might be something that could be

196
00:08:00,160 --> 00:08:01,879
done in a bit more of a

197
00:08:01,879 --> 00:08:04,160
uni-directional way

198
00:08:04,160 --> 00:08:05,840
that was section two on predictive

199
00:08:05,840 --> 00:08:07,039
coding

200
00:08:07,039 --> 00:08:09,280
introducing the kernel and then going

201
00:08:09,280 --> 00:08:11,919
into a few specific generalizations of

202
00:08:11,919 --> 00:08:14,560
that kernel and modifications that help

203
00:08:14,560 --> 00:08:17,520
make it more computationally powerful as

204
00:08:17,520 --> 00:08:19,199
well as linking it closer to certain

205
00:08:19,199 --> 00:08:22,400
biological architectures of tissues like

206
00:08:22,400 --> 00:08:24,639
in the retina and in the cortex of the

207
00:08:24,639 --> 00:08:26,800
mammal brain in predictive coding in the

208
00:08:26,800 --> 00:08:28,000
brain three

209
00:08:28,000 --> 00:08:29,360
there's some

210
00:08:29,360 --> 00:08:31,840
exploration on different paradigms of

211
00:08:31,840 --> 00:08:33,679
predictive coding and these are

212
00:08:33,679 --> 00:08:36,719
referring to kind of like settings

213
00:08:36,719 --> 00:08:39,760
where the core and elaborations can be

214
00:08:39,760 --> 00:08:40,719
applied

215
00:08:40,719 --> 00:08:42,399
and that's in the supervised and

216
00:08:42,399 --> 00:08:45,120
unsupervised cases as well as thinking

217
00:08:45,120 --> 00:08:47,200
about spatial and temporal predictive

218
00:08:47,200 --> 00:08:49,200
coding algorithms

219
00:08:49,200 --> 00:08:50,160
and

220
00:08:50,160 --> 00:08:52,560
connections with modern machine learning

221
00:08:52,560 --> 00:08:55,200
like with deep predictive coding

222
00:08:55,200 --> 00:08:56,080
then

223
00:08:56,080 --> 00:08:58,560
after that sort of kernel and

224
00:08:58,560 --> 00:09:00,720
generalization of the predictive coding

225
00:09:00,720 --> 00:09:02,399
kernel

226
00:09:02,399 --> 00:09:03,360
and

227
00:09:03,360 --> 00:09:04,880
exploring some of the paradigms for

228
00:09:04,880 --> 00:09:06,640
where that kernel and its elaborations

229
00:09:06,640 --> 00:09:08,080
have been applied in section four

230
00:09:08,080 --> 00:09:09,920
there's the relationships

231
00:09:09,920 --> 00:09:12,480
between and among their algorithms and

232
00:09:12,480 --> 00:09:14,560
so that's where we get into this section

233
00:09:14,560 --> 00:09:16,160
on predictive coding and the back

234
00:09:16,160 --> 00:09:18,000
propagation of error

235
00:09:18,000 --> 00:09:20,399
so that's where we'll go

236
00:09:20,399 --> 00:09:22,160
and um

237
00:09:22,160 --> 00:09:24,959
i'll copy in some formalisms or find out

238
00:09:24,959 --> 00:09:27,200
um which ones would be the best to bring

239
00:09:27,200 --> 00:09:28,160
in

240
00:09:28,160 --> 00:09:29,440
but um

241
00:09:29,440 --> 00:09:32,480
here we are on slide 56 which i'll share

242
00:09:32,480 --> 00:09:34,480
in the chat here

243
00:09:34,480 --> 00:09:35,839
what is interesting to you about back

244
00:09:35,839 --> 00:09:37,519
propagation of error then we'll start

245
00:09:37,519 --> 00:09:39,600
there

246
00:09:39,600 --> 00:09:42,160
well what i'm curious about is is the

247
00:09:42,160 --> 00:09:44,240
that bottom line of that slide this

248
00:09:44,240 --> 00:09:46,240
recursion is identical to that of the

249
00:09:46,240 --> 00:09:48,480
propaga

250
00:09:48,480 --> 00:09:51,279
to the propagation of air algorithm

251
00:09:51,279 --> 00:09:55,120
which i'm not which i'd never actually

252
00:09:55,279 --> 00:09:57,279
encountered before this

253
00:09:57,279 --> 00:10:00,080
so i was wondering i i know a bit about

254
00:10:00,080 --> 00:10:02,480
recursion i think we all have a sort of

255
00:10:02,480 --> 00:10:04,720
a basic understanding of what's involved

256
00:10:04,720 --> 00:10:06,959
in recursive

257
00:10:06,959 --> 00:10:10,640
um loops but i was wondering

258
00:10:10,640 --> 00:10:11,839
how

259
00:10:11,839 --> 00:10:13,760
sort of the predictive

260
00:10:13,760 --> 00:10:16,560
where's the where is this relationship

261
00:10:16,560 --> 00:10:19,040
between predictive coding and this other

262
00:10:19,040 --> 00:10:21,120
algorithm which i've heard that i've

263
00:10:21,120 --> 00:10:23,279
heard that that i don't know if it's an

264
00:10:23,279 --> 00:10:25,120
expression or label back propagation of

265
00:10:25,120 --> 00:10:26,800
error but i've never really

266
00:10:26,800 --> 00:10:27,680
looked at

267
00:10:27,680 --> 00:10:30,000
at it from a from a operational

268
00:10:30,000 --> 00:10:32,720
standpoint or you know how it's

269
00:10:32,720 --> 00:10:35,440
how it's laid out mathematically and i'm

270
00:10:35,440 --> 00:10:37,839
not sure if either of you have that

271
00:10:37,839 --> 00:10:39,680
familiarity but i was hoping maybe you

272
00:10:39,680 --> 00:10:41,920
did

273
00:10:44,839 --> 00:10:48,000
great so how does predictive coding

274
00:10:48,000 --> 00:10:51,839
relate to the back propagation of error

275
00:10:51,839 --> 00:10:53,440
let's um

276
00:10:53,440 --> 00:10:55,040
look at these sections which we didn't

277
00:10:55,040 --> 00:10:57,519
annotate too heavily leading up to

278
00:10:57,519 --> 00:10:59,360
because you know there's like

279
00:10:59,360 --> 00:11:02,240
many equations in the paper many areas

280
00:11:02,240 --> 00:11:04,480
um

281
00:11:04,640 --> 00:11:07,360
even before we introduce the formalism

282
00:11:07,360 --> 00:11:11,120
and to give me 15 seconds to read it

283
00:11:11,120 --> 00:11:13,040
qualitatively what would back

284
00:11:13,040 --> 00:11:15,040
propagation of error mean to you or

285
00:11:15,040 --> 00:11:16,399
where is an applied setting where you

286
00:11:16,399 --> 00:11:19,200
think this could matter

287
00:11:19,200 --> 00:11:19,920
well

288
00:11:19,920 --> 00:11:22,079
and again this is this is me

289
00:11:22,079 --> 00:11:23,920
talking out loud hanging my butt out

290
00:11:23,920 --> 00:11:25,040
there because i don't really know what

291
00:11:25,040 --> 00:11:27,600
i'm talking about but in my am i correct

292
00:11:27,600 --> 00:11:29,360
in assuming that it's

293
00:11:29,360 --> 00:11:30,240
um

294
00:11:30,240 --> 00:11:32,959
any time you find yourself in feedback

295
00:11:32,959 --> 00:11:35,040
and feed forward loops

296
00:11:35,040 --> 00:11:37,200
i know that they're acyclical

297
00:11:37,200 --> 00:11:38,480
and i know

298
00:11:38,480 --> 00:11:40,959
that usually implies a directional

299
00:11:40,959 --> 00:11:43,440
but isn't anytime you're getting sort of

300
00:11:43,440 --> 00:11:45,120
a a

301
00:11:45,120 --> 00:11:47,200
looping condition where you get an

302
00:11:47,200 --> 00:11:49,920
opportunity to sort of reset

303
00:11:49,920 --> 00:11:52,000
isn't that what we're isn't that the

304
00:11:52,000 --> 00:11:55,880
situation that we're examining

305
00:11:59,200 --> 00:12:00,000
okay

306
00:12:00,000 --> 00:12:01,200
we're in

307
00:12:01,200 --> 00:12:03,519
the arena of

308
00:12:03,519 --> 00:12:06,000
statistical bayesian graphs so we're

309
00:12:06,000 --> 00:12:07,680
talking about models here we're not

310
00:12:07,680 --> 00:12:10,079
necessarily talking about what an actual

311
00:12:10,079 --> 00:12:12,320
system is doing a computer system nor

312
00:12:12,320 --> 00:12:14,079
some sort of biological system we're

313
00:12:14,079 --> 00:12:16,399
talking about a modeling statistical

314
00:12:16,399 --> 00:12:18,959
architecture and it would be a secondary

315
00:12:18,959 --> 00:12:21,120
conversation about what systems are

316
00:12:21,120 --> 00:12:23,279
actually doing with back propagation so

317
00:12:23,279 --> 00:12:25,120
this isn't just like salt water flowing

318
00:12:25,120 --> 00:12:27,600
from the ocean into the river okay just

319
00:12:27,600 --> 00:12:30,639
to sort of force all any preliminary

320
00:12:30,639 --> 00:12:32,880
connections we might want to draw but we

321
00:12:32,880 --> 00:12:34,720
can see when

322
00:12:34,720 --> 00:12:36,560
we have a bit more sense of what back

323
00:12:36,560 --> 00:12:37,920
propagation of error is on this

324
00:12:37,920 --> 00:12:39,279
graphical setting

325
00:12:39,279 --> 00:12:40,560
how it could apply

326
00:12:40,560 --> 00:12:43,440
so they're introducing this concept of a

327
00:12:43,440 --> 00:12:46,240
computational graph fancy g

328
00:12:46,240 --> 00:12:49,279
not free energy related just g for graph

329
00:12:49,279 --> 00:12:52,000
and it consists of two kinds of elements

330
00:12:52,000 --> 00:12:54,639
just like all graphs or networks do

331
00:12:54,639 --> 00:12:57,519
which is vertices and edges

332
00:12:57,519 --> 00:12:59,040
the vertices are representing

333
00:12:59,040 --> 00:13:02,000
intermediate computation products for

334
00:13:02,000 --> 00:13:02,959
example

335
00:13:02,959 --> 00:13:05,360
the activations at each level this

336
00:13:05,360 --> 00:13:07,120
multi-level predictive processing

337
00:13:07,120 --> 00:13:09,680
architecture so we have like nodes

338
00:13:09,680 --> 00:13:11,839
within the level and then there's edges

339
00:13:11,839 --> 00:13:14,000
that represent influence

340
00:13:14,000 --> 00:13:14,800
um

341
00:13:14,800 --> 00:13:15,760
here

342
00:13:15,760 --> 00:13:17,760
as differentiable functions

343
00:13:17,760 --> 00:13:18,839
so this

344
00:13:18,839 --> 00:13:22,000
is related to some of the graphical

345
00:13:22,000 --> 00:13:23,360
bayesian approaches we've looked at

346
00:13:23,360 --> 00:13:26,399
previously but also it shares a lot with

347
00:13:26,399 --> 00:13:28,720
some neural network representations

348
00:13:28,720 --> 00:13:30,000
where the edges are not just like a

349
00:13:30,000 --> 00:13:32,000
correlation or mutual information but

350
00:13:32,000 --> 00:13:34,160
the edges are more like a differentiable

351
00:13:34,160 --> 00:13:36,560
function

352
00:13:36,800 --> 00:13:38,639
we're going to restrict to looking at

353
00:13:38,639 --> 00:13:40,800
specific kind of graphs here

354
00:13:40,800 --> 00:13:42,480
which are computation graphs they're

355
00:13:42,480 --> 00:13:46,079
saying are directed acyclic graphs so

356
00:13:46,079 --> 00:13:47,839
that means that it's directed there's an

357
00:13:47,839 --> 00:13:48,880
arrow

358
00:13:48,880 --> 00:13:50,800
such that the differentiability of the

359
00:13:50,800 --> 00:13:52,880
function is going from one way to the

360
00:13:52,880 --> 00:13:54,560
other like we can think of that as the

361
00:13:54,560 --> 00:13:56,480
forward direction

362
00:13:56,480 --> 00:13:57,760
and then

363
00:13:57,760 --> 00:13:58,800
the

364
00:13:58,800 --> 00:14:00,240
acyclic-ness

365
00:14:00,240 --> 00:14:01,600
is just ensuring that there's like sort

366
00:14:01,600 --> 00:14:03,600
of one place where we could start and we

367
00:14:03,600 --> 00:14:06,399
could just forward propagate everything

368
00:14:06,399 --> 00:14:07,920
out to the edges

369
00:14:07,920 --> 00:14:09,920
and that wouldn't trap us into an

370
00:14:09,920 --> 00:14:12,160
infinite recursion by going forward

371
00:14:12,160 --> 00:14:13,760
and we've talked about some of the

372
00:14:13,760 --> 00:14:15,120
differences between like cyclic and

373
00:14:15,120 --> 00:14:17,040
acyclic graphs with

374
00:14:17,040 --> 00:14:19,760
majeed when we were talking about the

375
00:14:19,760 --> 00:14:21,760
the dcm the

376
00:14:21,760 --> 00:14:24,079
and all the ambiguities of that acronym

377
00:14:24,079 --> 00:14:26,240
um okay

378
00:14:26,240 --> 00:14:30,680
steven anything and then we'll continue

379
00:14:30,959 --> 00:14:34,800
just one quick question um

380
00:14:34,959 --> 00:14:37,279
ontologically how how

381
00:14:37,279 --> 00:14:39,440
useful or problematic

382
00:14:39,440 --> 00:14:41,920
is the word coding now we've moved a bit

383
00:14:41,920 --> 00:14:44,800
further down with active inference

384
00:14:44,800 --> 00:14:45,519
and

385
00:14:45,519 --> 00:14:48,000
in a way is back propagation of error

386
00:14:48,000 --> 00:14:49,440
needed to be that

387
00:14:49,440 --> 00:14:51,199
needs to be distinguished out even in a

388
00:14:51,199 --> 00:14:53,360
descriptive term just so that

389
00:14:53,360 --> 00:14:56,800
the the connotations of coding don't

390
00:14:56,800 --> 00:15:00,160
sort of confuse all the discourse

391
00:15:00,160 --> 00:15:03,440
um what are your innovations

392
00:15:03,440 --> 00:15:05,519
well that it's basically kind of almost

393
00:15:05,519 --> 00:15:08,959
like a representational kind of um

394
00:15:08,959 --> 00:15:10,639
script almost that's been written

395
00:15:10,639 --> 00:15:12,560
somewhere

396
00:15:12,560 --> 00:15:13,920
it's kind of how you know like the

397
00:15:13,920 --> 00:15:15,279
coding that you get in a computer

398
00:15:15,279 --> 00:15:16,880
program or something

399
00:15:16,880 --> 00:15:19,199
um

400
00:15:19,279 --> 00:15:21,360
and i kind of think that

401
00:15:21,360 --> 00:15:22,959
that

402
00:15:22,959 --> 00:15:25,199
does sort of speak to the nature in a

403
00:15:25,199 --> 00:15:27,120
way because it's this is the the nature

404
00:15:27,120 --> 00:15:28,639
of how

405
00:15:28,639 --> 00:15:30,800
um for the future

406
00:15:30,800 --> 00:15:32,560
but um

407
00:15:32,560 --> 00:15:34,880
back propagation of error

408
00:15:34,880 --> 00:15:36,560
um

409
00:15:36,560 --> 00:15:38,880
kind of

410
00:15:38,880 --> 00:15:41,120
speaks in some ways to the nature of how

411
00:15:41,120 --> 00:15:43,440
the code

412
00:15:43,440 --> 00:15:46,000
is processed

413
00:15:46,000 --> 00:15:47,759
um

414
00:15:47,759 --> 00:15:49,759
and i may be off off topic here but i

415
00:15:49,759 --> 00:15:51,680
just i just kind of wonder as we're

416
00:15:51,680 --> 00:15:53,600
going through this and trying to

417
00:15:53,600 --> 00:15:56,560
link it all together

418
00:15:56,880 --> 00:15:58,079
how much

419
00:15:58,079 --> 00:16:00,480
that ontological term

420
00:16:00,480 --> 00:16:01,440
um

421
00:16:01,440 --> 00:16:03,600
is is

422
00:16:03,600 --> 00:16:06,079
also possibly something that could be

423
00:16:06,079 --> 00:16:09,040
thought of in another way make it easier

424
00:16:09,040 --> 00:16:11,600
to to

425
00:16:11,600 --> 00:16:15,440
to to understand what's going on

426
00:16:16,720 --> 00:16:17,920
okay

427
00:16:17,920 --> 00:16:19,120
um

428
00:16:19,120 --> 00:16:22,959
we are dealing here with

429
00:16:22,959 --> 00:16:24,880
computational architectures so i don't

430
00:16:24,880 --> 00:16:27,040
think we need to run away from

431
00:16:27,040 --> 00:16:28,240
these

432
00:16:28,240 --> 00:16:30,880
questions that were brought up more in

433
00:16:30,880 --> 00:16:33,920
a philosophical non-computational

434
00:16:33,920 --> 00:16:35,920
version into the anti-computationalist

435
00:16:35,920 --> 00:16:37,440
perspective like we're not fighting for

436
00:16:37,440 --> 00:16:39,199
what is happening in the brain here

437
00:16:39,199 --> 00:16:40,720
we're using predictive coding to talk

438
00:16:40,720 --> 00:16:42,079
about information coding and

439
00:16:42,079 --> 00:16:45,120
transmission approaches

440
00:16:45,120 --> 00:16:47,600
so that's one thing and um

441
00:16:47,600 --> 00:16:50,240
yeah i mean we don't we can't just go

442
00:16:50,240 --> 00:16:51,600
around flipping different words

443
00:16:51,600 --> 00:16:53,519
predictive coding is what for decades

444
00:16:53,519 --> 00:16:55,519
has been referenced by a certain

445
00:16:55,519 --> 00:16:58,240
architecture here

446
00:16:58,240 --> 00:16:59,360
and then

447
00:16:59,360 --> 00:17:01,199
there's a lot of openness with how that

448
00:17:01,199 --> 00:17:03,040
architecture is applied

449
00:17:03,040 --> 00:17:04,799
but i

450
00:17:04,799 --> 00:17:07,919
i i'm not 100 sure like

451
00:17:07,919 --> 00:17:10,480
this is about predictive coding

452
00:17:10,480 --> 00:17:12,160
architectures

453
00:17:12,160 --> 00:17:14,799
yeah no that's cool i'm i'm just putting

454
00:17:14,799 --> 00:17:15,919
that out there just seeing how that

455
00:17:15,919 --> 00:17:17,599
floats a little bit i think that's a

456
00:17:17,599 --> 00:17:20,160
good good response like what else would

457
00:17:20,160 --> 00:17:22,400
what else could be in this position of

458
00:17:22,400 --> 00:17:24,799
coding

459
00:17:24,959 --> 00:17:27,599
it's about how signals are encoded what

460
00:17:27,599 --> 00:17:29,840
is being transferred between different

461
00:17:29,840 --> 00:17:31,440
nodes

462
00:17:31,440 --> 00:17:33,280
is what is being transferred the raw

463
00:17:33,280 --> 00:17:34,720
value

464
00:17:34,720 --> 00:17:35,840
or

465
00:17:35,840 --> 00:17:38,080
in the predictive coding architecture

466
00:17:38,080 --> 00:17:39,039
we have

467
00:17:39,039 --> 00:17:39,919
um

468
00:17:39,919 --> 00:17:41,360
two directions

469
00:17:41,360 --> 00:17:44,080
that signals are being passed

470
00:17:44,080 --> 00:17:47,280
in this compute graph not in the brain

471
00:17:47,280 --> 00:17:48,320
and that

472
00:17:48,320 --> 00:17:49,520
would be

473
00:17:49,520 --> 00:17:50,880
coming from

474
00:17:50,880 --> 00:17:51,840
um

475
00:17:51,840 --> 00:17:53,360
one direction

476
00:17:53,360 --> 00:17:55,600
the expectation that's the predictive

477
00:17:55,600 --> 00:17:58,799
part and then the error residual

478
00:17:58,799 --> 00:18:00,480
that's the deviation from the

479
00:18:00,480 --> 00:18:01,760
expectation

480
00:18:01,760 --> 00:18:03,520
and so that is what the predictive

481
00:18:03,520 --> 00:18:05,360
coding architecture is

482
00:18:05,360 --> 00:18:08,240
it's just about

483
00:18:08,400 --> 00:18:10,640
having graphical systems

484
00:18:10,640 --> 00:18:12,000
that are passing

485
00:18:12,000 --> 00:18:16,640
expectations and differences or errors

486
00:18:16,640 --> 00:18:19,039
rather than passing like just the plain

487
00:18:19,039 --> 00:18:20,960
values themselves

488
00:18:20,960 --> 00:18:22,480
yeah

489
00:18:22,480 --> 00:18:24,320
i suppose there's also that question of

490
00:18:24,320 --> 00:18:26,400
um

491
00:18:26,400 --> 00:18:28,960
how much is in

492
00:18:28,960 --> 00:18:31,280
the dynamics of what's going on and the

493
00:18:31,280 --> 00:18:34,160
hyper parameters when looked out

494
00:18:34,160 --> 00:18:37,600
and um how much difference that makes

495
00:18:37,600 --> 00:18:40,000
to to the story

496
00:18:40,000 --> 00:18:42,960
okay so you've got you've got the the

497
00:18:42,960 --> 00:18:45,280
the the predictions uh the prediction

498
00:18:45,280 --> 00:18:47,120
error has been passed down

499
00:18:47,120 --> 00:18:50,160
um but coding tends to be like the

500
00:18:50,160 --> 00:18:51,760
numbers are there

501
00:18:51,760 --> 00:18:55,200
but in some ways the numbers can kind of

502
00:18:55,200 --> 00:18:57,360
evolve once the

503
00:18:57,360 --> 00:19:00,080
the system the dynamics of the systems

504
00:19:00,080 --> 00:19:02,320
or the dynamical

505
00:19:02,320 --> 00:19:03,520
sort of

506
00:19:03,520 --> 00:19:06,160
patterns of the system start to

507
00:19:06,160 --> 00:19:08,320
sort of fire up so to speak you know it

508
00:19:08,320 --> 00:19:10,320
takes a little bit of time for the

509
00:19:10,320 --> 00:19:12,720
active influence model to start

510
00:19:12,720 --> 00:19:14,400
really purring along

511
00:19:14,400 --> 00:19:15,600
sometimes

512
00:19:15,600 --> 00:19:17,600
so that kind of coding

513
00:19:17,600 --> 00:19:21,039
is in a way sort of almost more live

514
00:19:21,039 --> 00:19:21,840
than

515
00:19:21,840 --> 00:19:23,679
traditional coding which is kind of sort

516
00:19:23,679 --> 00:19:26,240
of baked in

517
00:19:26,240 --> 00:19:28,400
okay i got you we're not even in active

518
00:19:28,400 --> 00:19:31,760
inference yet so i see some back later

519
00:19:31,760 --> 00:19:34,559
but we're discussing predictive coding

520
00:19:34,559 --> 00:19:36,400
back propagation of error

521
00:19:36,400 --> 00:19:38,799
and then action does get brought into

522
00:19:38,799 --> 00:19:42,080
the picture in section four five

523
00:19:42,080 --> 00:19:44,720
but up until section four or five

524
00:19:44,720 --> 00:19:46,320
there's no action

525
00:19:46,320 --> 00:19:48,720
even in the model so we're just looking

526
00:19:48,720 --> 00:19:50,160
at the architecture that does

527
00:19:50,160 --> 00:19:51,600
computation

528
00:19:51,600 --> 00:19:53,200
and then understanding

529
00:19:53,200 --> 00:19:54,559
how action could be brought in and

530
00:19:54,559 --> 00:19:56,960
that's kind of the fun surprise that we

531
00:19:56,960 --> 00:19:59,120
uncovered in the dot zero and dot one

532
00:19:59,120 --> 00:20:01,200
and in the layout of the paper was when

533
00:20:01,200 --> 00:20:03,280
the architecture is sufficiently general

534
00:20:03,280 --> 00:20:04,559
and powerful

535
00:20:04,559 --> 00:20:07,200
incorporating another variable that is

536
00:20:07,200 --> 00:20:08,799
about action

537
00:20:08,799 --> 00:20:12,320
like policy selection becomes fluent and

538
00:20:12,320 --> 00:20:13,679
that's

539
00:20:13,679 --> 00:20:16,559
why these architectures are composable

540
00:20:16,559 --> 00:20:18,559
with different sensory modalities with

541
00:20:18,559 --> 00:20:20,080
different scopes of action with

542
00:20:20,080 --> 00:20:21,919
different affordances all these things

543
00:20:21,919 --> 00:20:22,960
because there's a level of

544
00:20:22,960 --> 00:20:24,480
generalizability that we can pull back

545
00:20:24,480 --> 00:20:25,440
to

546
00:20:25,440 --> 00:20:26,720
okay so

547
00:20:26,720 --> 00:20:28,720
let's return to predictive coding and

548
00:20:28,720 --> 00:20:30,640
back propagation of error

549
00:20:30,640 --> 00:20:32,240
we have this graph

550
00:20:32,240 --> 00:20:34,159
the vertices are representing

551
00:20:34,159 --> 00:20:35,840
intermediate computational project

552
00:20:35,840 --> 00:20:37,840
products so like a number or like a

553
00:20:37,840 --> 00:20:39,360
variable

554
00:20:39,360 --> 00:20:40,400
because it's kind of like where you're

555
00:20:40,400 --> 00:20:42,799
storing the intermediate computation

556
00:20:42,799 --> 00:20:44,799
product and then the edges

557
00:20:44,799 --> 00:20:48,080
differentiable functions

558
00:20:48,080 --> 00:20:50,320
could be you know like y equals 2x is a

559
00:20:50,320 --> 00:20:51,760
differentiable function anything that

560
00:20:51,760 --> 00:20:53,440
has smoothness in the graph is

561
00:20:53,440 --> 00:20:56,000
differentiable

562
00:20:56,080 --> 00:20:57,840
and as the orange part says we're

563
00:20:57,840 --> 00:20:59,600
restricting this to

564
00:20:59,600 --> 00:21:01,200
directed acyclic graphs where we're not

565
00:21:01,200 --> 00:21:02,960
going to get into an infinite regress

566
00:21:02,960 --> 00:21:04,559
just by going forward

567
00:21:04,559 --> 00:21:06,400
now what happens

568
00:21:06,400 --> 00:21:08,000
when we're trying to

569
00:21:08,000 --> 00:21:09,039
tune

570
00:21:09,039 --> 00:21:11,280
this architecture

571
00:21:11,280 --> 00:21:15,200
so that it has a minimized loss function

572
00:21:15,200 --> 00:21:17,520
loss function whether we're dealing with

573
00:21:17,520 --> 00:21:20,080
least squares error like a regular

574
00:21:20,080 --> 00:21:21,600
linear regression

575
00:21:21,600 --> 00:21:23,120
or whether we're dealing with some other

576
00:21:23,120 --> 00:21:25,200
loss function the loss function is like

577
00:21:25,200 --> 00:21:27,840
what is trying to be minimized

578
00:21:27,840 --> 00:21:29,919
so when the ball is rolling downhill

579
00:21:29,919 --> 00:21:31,919
we're minimizing like the loss or the

580
00:21:31,919 --> 00:21:35,760
energy function but the energy function

581
00:21:35,760 --> 00:21:37,760
approach and wording is coming more from

582
00:21:37,760 --> 00:21:39,760
like a physics

583
00:21:39,760 --> 00:21:42,000
side whereas the loss function is just a

584
00:21:42,000 --> 00:21:44,000
purely statistical claim like what is

585
00:21:44,000 --> 00:21:46,880
the function that we're minimizing

586
00:21:46,880 --> 00:21:47,919
okay

587
00:21:47,919 --> 00:21:50,720
given the output vertex v out

588
00:21:50,720 --> 00:21:53,120
so this is like the one that we actually

589
00:21:53,120 --> 00:21:55,760
want um to be

590
00:21:55,760 --> 00:21:59,360
reducing the loss around

591
00:21:59,360 --> 00:22:01,360
the loss function is going to be l

592
00:22:01,360 --> 00:22:04,320
l is a function of v out

593
00:22:04,320 --> 00:22:06,320
back propagation can be performed upon a

594
00:22:06,320 --> 00:22:08,480
computation graph so we're going to be

595
00:22:08,480 --> 00:22:10,320
minimizing loss

596
00:22:10,320 --> 00:22:12,640
at a certain vertex

597
00:22:12,640 --> 00:22:15,520
by back propagating upstream

598
00:22:15,520 --> 00:22:17,840
a lot of what led to it being the way it

599
00:22:17,840 --> 00:22:18,960
is

600
00:22:18,960 --> 00:22:20,559
and so that could be done on just the

601
00:22:20,559 --> 00:22:21,679
last

602
00:22:21,679 --> 00:22:24,960
tip of the spear or it could be done

603
00:22:24,960 --> 00:22:27,120
throughout the whole system

604
00:22:27,120 --> 00:22:29,039
back propagation is an extremely

605
00:22:29,039 --> 00:22:31,520
straightforward algorithm

606
00:22:31,520 --> 00:22:33,360
which simply uses the chain rule of

607
00:22:33,360 --> 00:22:35,440
multivariable calculus

608
00:22:35,440 --> 00:22:37,760
to recursively compute the derivatives

609
00:22:37,760 --> 00:22:39,600
of children nodes from the derivatives

610
00:22:39,600 --> 00:22:40,960
of their parents

611
00:22:40,960 --> 00:22:42,559
okay so

612
00:22:42,559 --> 00:22:44,400
formalism 28

613
00:22:44,400 --> 00:22:48,159
this fancy d is partial differential

614
00:22:48,159 --> 00:22:51,600
so the change of the loss function

615
00:22:51,600 --> 00:22:53,919
with respect to the change in an

616
00:22:53,919 --> 00:22:56,159
intermediate variable i

617
00:22:56,159 --> 00:22:57,679
is what we're looking at we're looking

618
00:22:57,679 --> 00:22:59,600
at how

619
00:22:59,600 --> 00:23:01,679
we're going on that bowl are we dropping

620
00:23:01,679 --> 00:23:03,039
on the loss function

621
00:23:03,039 --> 00:23:05,200
are we is the model getting better or

622
00:23:05,200 --> 00:23:06,960
worse

623
00:23:06,960 --> 00:23:09,600
with respect to changes of intermediate

624
00:23:09,600 --> 00:23:12,960
computational products vertices

625
00:23:12,960 --> 00:23:14,480
and that

626
00:23:14,480 --> 00:23:17,039
overall loss function

627
00:23:17,039 --> 00:23:19,039
is the sum

628
00:23:19,039 --> 00:23:20,240
of

629
00:23:20,240 --> 00:23:21,520
v

630
00:23:21,520 --> 00:23:24,240
the subset of p which is the parents

631
00:23:24,240 --> 00:23:26,720
so we're looking at v i

632
00:23:26,720 --> 00:23:29,200
like the um node that we're focused on

633
00:23:29,200 --> 00:23:30,880
node of interest or something

634
00:23:30,880 --> 00:23:32,960
and we're going to sum over all of its

635
00:23:32,960 --> 00:23:34,240
parents

636
00:23:34,240 --> 00:23:36,159
and then for all of its parents we're

637
00:23:36,159 --> 00:23:37,360
going to compute something that's

638
00:23:37,360 --> 00:23:39,200
basically like the change in loss

639
00:23:39,200 --> 00:23:40,640
function over the change in that

640
00:23:40,640 --> 00:23:44,720
parent's value v sub j

641
00:23:45,120 --> 00:23:48,000
and how it changes with respect to

642
00:23:48,000 --> 00:23:50,400
change in the child

643
00:23:50,400 --> 00:23:52,559
so we're taking something that's like

644
00:23:52,559 --> 00:23:54,559
this graphical network

645
00:23:54,559 --> 00:23:56,480
with nodes and edges

646
00:23:56,480 --> 00:23:58,480
and differentiability

647
00:23:58,480 --> 00:24:00,400
and then figuring out which way is the

648
00:24:00,400 --> 00:24:02,640
overall downhill

649
00:24:02,640 --> 00:24:05,760
based upon all of the back propagation

650
00:24:05,760 --> 00:24:07,600
of the gradients

651
00:24:07,600 --> 00:24:09,760
okay by starting with this output output

652
00:24:09,760 --> 00:24:11,120
gradient

653
00:24:11,120 --> 00:24:12,960
that's v out

654
00:24:12,960 --> 00:24:14,320
um

655
00:24:14,320 --> 00:24:16,000
and if all the gradients

656
00:24:16,000 --> 00:24:17,200
are known

657
00:24:17,200 --> 00:24:19,120
so like we're dealing with a model that

658
00:24:19,120 --> 00:24:21,600
we specified

659
00:24:21,600 --> 00:24:24,080
then the derivatives of every vertex

660
00:24:24,080 --> 00:24:25,440
with respect to the loss can be

661
00:24:25,440 --> 00:24:27,840
recursively computed so

662
00:24:27,840 --> 00:24:30,640
because all the edges are differentiable

663
00:24:30,640 --> 00:24:32,880
the big function is also differentiable

664
00:24:32,880 --> 00:24:35,760
so like 2x is differentiable x squared

665
00:24:35,760 --> 00:24:37,919
is differentiable x cubed and x to the

666
00:24:37,919 --> 00:24:39,520
11th power are all differentiable

667
00:24:39,520 --> 00:24:40,480
functions

668
00:24:40,480 --> 00:24:43,120
so you could also differentiate

669
00:24:43,120 --> 00:24:46,320
their concatenation through addition

670
00:24:46,320 --> 00:24:48,320
that'd be like the derivative of 2x plus

671
00:24:48,320 --> 00:24:50,000
the derivative of this

672
00:24:50,000 --> 00:24:52,480
and also the chain rule in calculus

673
00:24:52,480 --> 00:24:55,120
allows us to like nest those so if we

674
00:24:55,120 --> 00:24:57,039
can differentiate 2x and if we can

675
00:24:57,039 --> 00:24:59,120
differentiate x squared we could

676
00:24:59,120 --> 00:25:01,039
differentiate

677
00:25:01,039 --> 00:25:02,559
2x

678
00:25:02,559 --> 00:25:04,880
inside of parentheses squared

679
00:25:04,880 --> 00:25:06,400
that's basically the chain rule in

680
00:25:06,400 --> 00:25:07,919
calculus

681
00:25:07,919 --> 00:25:10,159
um and then

682
00:25:10,159 --> 00:25:13,520
that is what allows this sort of

683
00:25:13,520 --> 00:25:16,640
big downhill computation

684
00:25:16,640 --> 00:25:18,640
based upon the specification of the

685
00:25:18,640 --> 00:25:19,520
graph

686
00:25:19,520 --> 00:25:21,440
and then the back propagation of all the

687
00:25:21,440 --> 00:25:23,840
relevant nodes and finding out how those

688
00:25:23,840 --> 00:25:26,400
need to be tuned so that the final

689
00:25:26,400 --> 00:25:28,559
output node that's being

690
00:25:28,559 --> 00:25:30,559
optimized

691
00:25:30,559 --> 00:25:34,640
can be going downhill defined as going

692
00:25:34,640 --> 00:25:37,760
down on the loss function less loss is

693
00:25:37,760 --> 00:25:39,200
better here

694
00:25:39,200 --> 00:25:40,799
okay yes

695
00:25:40,799 --> 00:25:43,440
excellent thank you because this was one

696
00:25:43,440 --> 00:25:45,600
big opaque markov blanket to me when i

697
00:25:45,600 --> 00:25:47,840
read it i just couldn't make any sense

698
00:25:47,840 --> 00:25:48,799
of it but

699
00:25:48,799 --> 00:25:51,279
is the ability to differentiate or what

700
00:25:51,279 --> 00:25:52,960
they is what they're saying here is the

701
00:25:52,960 --> 00:25:56,559
ability to differentiate an ability to

702
00:25:56,559 --> 00:25:58,080
build

703
00:25:58,080 --> 00:26:01,600
relationship that parent-child thing is

704
00:26:01,600 --> 00:26:03,520
is it that is it the capacity to

705
00:26:03,520 --> 00:26:05,679
differentiate that allows

706
00:26:05,679 --> 00:26:08,000
for the relationship to be identified or

707
00:26:08,000 --> 00:26:10,880
is it the other way around because

708
00:26:10,880 --> 00:26:12,880
when when they're talking here

709
00:26:12,880 --> 00:26:14,400
and saying

710
00:26:14,400 --> 00:26:16,240
back propagation performed on the

711
00:26:16,240 --> 00:26:17,919
computation graph

712
00:26:17,919 --> 00:26:19,760
back propagation is extremely

713
00:26:19,760 --> 00:26:21,120
straightforward

714
00:26:21,120 --> 00:26:23,279
and uses the chain rule of multivariate

715
00:26:23,279 --> 00:26:25,679
stuff when it's talking about that it's

716
00:26:25,679 --> 00:26:26,720
it's

717
00:26:26,720 --> 00:26:28,720
it's pointing back to something that you

718
00:26:28,720 --> 00:26:31,120
don't necessarily have to see but you

719
00:26:31,120 --> 00:26:32,799
know that there is some relationship

720
00:26:32,799 --> 00:26:34,480
just like there is between

721
00:26:34,480 --> 00:26:38,320
2x and x squared am i getting

722
00:26:38,320 --> 00:26:40,960
is that is your explanation helping me

723
00:26:40,960 --> 00:26:42,559
move closer to a better understanding of

724
00:26:42,559 --> 00:26:43,760
that

725
00:26:43,760 --> 00:26:45,919
because i understand derivatives but i'm

726
00:26:45,919 --> 00:26:48,159
not sure how the derivatives

727
00:26:48,159 --> 00:26:51,279
fit into this explanation

728
00:26:51,279 --> 00:26:53,120
great

729
00:26:53,120 --> 00:26:55,600
yeah i think we're um

730
00:26:55,600 --> 00:26:56,559
we're

731
00:26:56,559 --> 00:27:00,080
so solenoidally exploring now

732
00:27:00,080 --> 00:27:03,919
we haven't even brought in predictive

733
00:27:03,919 --> 00:27:05,840
these equations here

734
00:27:05,840 --> 00:27:08,480
are for 28 and 29

735
00:27:08,480 --> 00:27:10,799
are about back propagation on

736
00:27:10,799 --> 00:27:12,720
computation graphs

737
00:27:12,720 --> 00:27:13,679
so

738
00:27:13,679 --> 00:27:15,200
with these papers it's really important

739
00:27:15,200 --> 00:27:17,600
to know like what has not been brought

740
00:27:17,600 --> 00:27:19,679
onto this diction

741
00:27:19,679 --> 00:27:21,679
and there isn't error

742
00:27:21,679 --> 00:27:23,840
this is just about the nodes and edges

743
00:27:23,840 --> 00:27:25,840
like the intermediate computation values

744
00:27:25,840 --> 00:27:27,840
of the abstractest kind

745
00:27:27,840 --> 00:27:29,840
and their differentiable relationships

746
00:27:29,840 --> 00:27:31,840
so now they're going to

747
00:27:31,840 --> 00:27:33,919
show how predictive coding relates to

748
00:27:33,919 --> 00:27:36,080
back propagation of error

749
00:27:36,080 --> 00:27:37,840
so they write predictive coding can also

750
00:27:37,840 --> 00:27:39,360
be straightforwardly extended to

751
00:27:39,360 --> 00:27:42,080
arbitrary computation graphs

752
00:27:42,080 --> 00:27:44,080
to do this we simply augment the

753
00:27:44,080 --> 00:27:46,240
standard computation graphs with

754
00:27:46,240 --> 00:27:48,640
additional error units for each vertex

755
00:27:48,640 --> 00:27:50,799
so let's recall what some of these

756
00:27:50,799 --> 00:27:52,960
graphs that we previously looked at here

757
00:27:52,960 --> 00:27:54,960
in figure 1 of the paper

758
00:27:54,960 --> 00:27:57,360
we have a graph

759
00:27:57,360 --> 00:27:59,279
where the nodes are intermediate

760
00:27:59,279 --> 00:28:01,600
computational products

761
00:28:01,600 --> 00:28:05,279
represent differentiable relationships

762
00:28:05,279 --> 00:28:06,880
and importantly some of these

763
00:28:06,880 --> 00:28:08,960
intermediate products

764
00:28:08,960 --> 00:28:11,520
have the semantics or the interpretation

765
00:28:11,520 --> 00:28:14,640
of being estimates about mean mu

766
00:28:14,640 --> 00:28:17,279
at that level or estimates about

767
00:28:17,279 --> 00:28:20,880
variance and error at that level epsilon

768
00:28:20,880 --> 00:28:23,360
so this is kind of like

769
00:28:23,360 --> 00:28:26,399
a subtype of graph like the abstract is

770
00:28:26,399 --> 00:28:27,760
kind it's just intermediate

771
00:28:27,760 --> 00:28:29,440
computational products

772
00:28:29,440 --> 00:28:31,760
and then predictive coding

773
00:28:31,760 --> 00:28:34,000
are specific kinds of computational

774
00:28:34,000 --> 00:28:35,039
graphs

775
00:28:35,039 --> 00:28:37,600
where some of the nodes represent mean

776
00:28:37,600 --> 00:28:40,320
estimates and some of them are error

777
00:28:40,320 --> 00:28:41,840
estimates

778
00:28:41,840 --> 00:28:44,559
in contrast and hopefully not to confuse

779
00:28:44,559 --> 00:28:46,559
here's from 26.2

780
00:28:46,559 --> 00:28:48,159
where we talked about like integrator

781
00:28:48,159 --> 00:28:49,120
chains

782
00:28:49,120 --> 00:28:51,200
so notice that all of these nodes can be

783
00:28:51,200 --> 00:28:52,399
interpreted as intermediate

784
00:28:52,399 --> 00:28:54,080
computational products but there's no

785
00:28:54,080 --> 00:28:56,640
error term here so this is an example of

786
00:28:56,640 --> 00:28:58,480
a computational graph that doesn't have

787
00:28:58,480 --> 00:29:00,720
error terms this is not a predictive

788
00:29:00,720 --> 00:29:02,480
coding architecture not that it's

789
00:29:02,480 --> 00:29:04,960
inconsistent with or somehow disjoint

790
00:29:04,960 --> 00:29:07,840
from but this is not having epsilons so

791
00:29:07,840 --> 00:29:08,960
it's not a predictive coding

792
00:29:08,960 --> 00:29:11,440
architecture whereas this is sort of a

793
00:29:11,440 --> 00:29:14,000
canonical multi-level predictive coding

794
00:29:14,000 --> 00:29:15,760
architecture

795
00:29:15,760 --> 00:29:17,120
okay great

796
00:29:17,120 --> 00:29:18,799
hey jax good to see you

797
00:29:18,799 --> 00:29:20,799
in the chat okay now we're gonna return

798
00:29:20,799 --> 00:29:23,840
back to the back prop

799
00:29:23,840 --> 00:29:24,840
okay

800
00:29:24,840 --> 00:29:27,440
so we're adding in these additional

801
00:29:27,440 --> 00:29:30,159
error units epsilon sub i for each level

802
00:29:30,159 --> 00:29:32,960
of the um graph formally the augmented

803
00:29:32,960 --> 00:29:35,840
graph becomes now g tilde so previously

804
00:29:35,840 --> 00:29:38,080
fancy g was just edges and vertices

805
00:29:38,080 --> 00:29:41,360
nodes and edges and now the vertices is

806
00:29:41,360 --> 00:29:44,960
is being unpacked so that v can remain

807
00:29:44,960 --> 00:29:47,039
for the mean estimators

808
00:29:47,039 --> 00:29:48,720
which are ultimately the ones that like

809
00:29:48,720 --> 00:29:50,799
we would like to have

810
00:29:50,799 --> 00:29:53,840
the most accuracy on

811
00:29:53,840 --> 00:29:56,559
accounting also for variance estimators

812
00:29:56,559 --> 00:29:58,799
and so epsilon this big e has been

813
00:29:58,799 --> 00:30:00,320
pulled out it's the set of all error

814
00:30:00,320 --> 00:30:01,360
neurons

815
00:30:01,360 --> 00:30:03,360
we then adapt the core predictive coding

816
00:30:03,360 --> 00:30:06,080
dynamics equations from a hierarchy of

817
00:30:06,080 --> 00:30:09,840
layers to arbitrary graphs

818
00:30:10,159 --> 00:30:11,440
change

819
00:30:11,440 --> 00:30:13,440
in v

820
00:30:13,440 --> 00:30:14,720
the nodes

821
00:30:14,720 --> 00:30:17,279
with respect to time

822
00:30:17,279 --> 00:30:18,799
prediction is happening through a

823
00:30:18,799 --> 00:30:20,240
sequence of observations in the

824
00:30:20,240 --> 00:30:22,159
predictive coding architecture that's

825
00:30:22,159 --> 00:30:25,279
that now casting column filter frame

826
00:30:25,279 --> 00:30:27,360
differencing a lot of these other sort

827
00:30:27,360 --> 00:30:29,360
of real-time

828
00:30:29,360 --> 00:30:30,960
algorithms for mean and variance

829
00:30:30,960 --> 00:30:32,880
estimation that we talked about

830
00:30:32,880 --> 00:30:34,080
equals

831
00:30:34,080 --> 00:30:36,480
the change in f

832
00:30:36,480 --> 00:30:38,000
free energy

833
00:30:38,000 --> 00:30:40,240
with respect to change in the note

834
00:30:40,240 --> 00:30:43,840
so now the loss function through time

835
00:30:43,840 --> 00:30:45,600
is going to be

836
00:30:45,600 --> 00:30:47,840
related to the f

837
00:30:47,840 --> 00:30:51,120
that had been previously

838
00:30:52,080 --> 00:30:53,840
previously defined in in earlier

839
00:30:53,840 --> 00:30:55,840
equations and then that is going to be

840
00:30:55,840 --> 00:30:58,240
defined as basically the error

841
00:30:58,240 --> 00:31:01,200
this is in formalism 30 the epsilon sub

842
00:31:01,200 --> 00:31:02,240
i

843
00:31:02,240 --> 00:31:05,360
so the the error variance at that

844
00:31:05,360 --> 00:31:07,279
last level

845
00:31:07,279 --> 00:31:08,799
minus

846
00:31:08,799 --> 00:31:10,399
a sum

847
00:31:10,399 --> 00:31:12,960
of c

848
00:31:12,960 --> 00:31:15,279
so c are the children

849
00:31:15,279 --> 00:31:18,240
and then there's just some more terms

850
00:31:18,240 --> 00:31:22,000
involving basically tuning the nodes

851
00:31:22,000 --> 00:31:23,679
accounting for the fact that we want to

852
00:31:23,679 --> 00:31:26,799
like tune the variance estimators

853
00:31:26,799 --> 00:31:28,559
and the compute

854
00:31:28,559 --> 00:31:30,720
computation nodes that represent the

855
00:31:30,720 --> 00:31:32,640
mean estimates

856
00:31:32,640 --> 00:31:35,039
and so

857
00:31:38,159 --> 00:31:39,840
then the dynamics of the parameters on

858
00:31:39,840 --> 00:31:41,840
the vertices v

859
00:31:41,840 --> 00:31:43,919
and the edge functions theta so they

860
00:31:43,919 --> 00:31:46,399
kind of slightly evolve the edge

861
00:31:46,399 --> 00:31:47,519
notation

862
00:31:47,519 --> 00:31:48,559
towards

863
00:31:48,559 --> 00:31:50,879
theta

864
00:31:51,200 --> 00:31:52,640
can then be derived as a gradient

865
00:31:52,640 --> 00:31:54,640
descent on f where f is the sum of

866
00:31:54,640 --> 00:31:56,559
prediction errors of every node in the

867
00:31:56,559 --> 00:31:57,760
graph

868
00:31:57,760 --> 00:31:59,679
so

869
00:31:59,679 --> 00:32:02,640
um they had specified how the the

870
00:32:02,640 --> 00:32:04,559
composability of the multi-level

871
00:32:04,559 --> 00:32:06,640
predictive coding architecture

872
00:32:06,640 --> 00:32:08,240
is such that

873
00:32:08,240 --> 00:32:09,600
the levels

874
00:32:09,600 --> 00:32:11,120
are

875
00:32:11,120 --> 00:32:13,519
can be factorized from each other

876
00:32:13,519 --> 00:32:16,320
which allows us to sum their free energy

877
00:32:16,320 --> 00:32:18,480
contributions into like a free energy

878
00:32:18,480 --> 00:32:19,519
total

879
00:32:19,519 --> 00:32:21,360
and so that is how a multi-level model

880
00:32:21,360 --> 00:32:22,720
can be fit

881
00:32:22,720 --> 00:32:24,480
because it's finding like the free

882
00:32:24,480 --> 00:32:25,600
energy

883
00:32:25,600 --> 00:32:27,440
minimum for that whole multi-level

884
00:32:27,440 --> 00:32:28,559
system

885
00:32:28,559 --> 00:32:31,360
which might entail one of the levels not

886
00:32:31,360 --> 00:32:34,080
being at its like perfect perfect lowest

887
00:32:34,080 --> 00:32:36,880
free energy state

888
00:32:36,880 --> 00:32:39,039
and in this section

889
00:32:39,039 --> 00:32:40,720
they've connected

890
00:32:40,720 --> 00:32:43,039
the way that back propagation

891
00:32:43,039 --> 00:32:46,080
in 28 and 29 without any action without

892
00:32:46,080 --> 00:32:47,760
any prediction

893
00:32:47,760 --> 00:32:50,240
is able to make a big loss function

894
00:32:50,240 --> 00:32:51,760
that's composed because of the

895
00:32:51,760 --> 00:32:53,200
tractability

896
00:32:53,200 --> 00:32:55,519
of the compute graph

897
00:32:55,519 --> 00:32:57,919
and all of these little loss functions

898
00:32:57,919 --> 00:33:00,559
can be summed into a big loss function

899
00:33:00,559 --> 00:33:02,000
that you use to like train a neural

900
00:33:02,000 --> 00:33:04,720
network for example

901
00:33:04,720 --> 00:33:05,760
um

902
00:33:05,760 --> 00:33:07,360
and then

903
00:33:07,360 --> 00:33:09,200
moving that into

904
00:33:09,200 --> 00:33:12,320
the predictive coding and free energy

905
00:33:12,320 --> 00:33:13,919
minimizing space

906
00:33:13,919 --> 00:33:15,600
by saying well this is a special kind of

907
00:33:15,600 --> 00:33:17,679
compute graph that has the mean

908
00:33:17,679 --> 00:33:19,360
estimators mu and the variance

909
00:33:19,360 --> 00:33:22,320
estimators the error terms

910
00:33:22,320 --> 00:33:24,880
and then we're going to do

911
00:33:24,880 --> 00:33:26,559
something similar

912
00:33:26,559 --> 00:33:29,600
where we're going to compute like

913
00:33:29,600 --> 00:33:32,240
what amounts to a loss function

914
00:33:32,240 --> 00:33:34,000
f the sum of prediction errors of every

915
00:33:34,000 --> 00:33:36,320
node in the graph

916
00:33:36,320 --> 00:33:39,039
based upon the internal

917
00:33:39,039 --> 00:33:41,600
prediction errors being minimized

918
00:33:41,600 --> 00:33:45,200
so in the non-predictive coding

919
00:33:45,200 --> 00:33:46,799
um frame

920
00:33:46,799 --> 00:33:49,200
we're minimizing a big loss function

921
00:33:49,200 --> 00:33:50,480
that's composed of smaller loss

922
00:33:50,480 --> 00:33:52,960
functions in the predictive coding frame

923
00:33:52,960 --> 00:33:54,880
we're minimizing our divergence from

924
00:33:54,880 --> 00:33:56,559
expectations

925
00:33:56,559 --> 00:33:58,480
composed of the divergences from many

926
00:33:58,480 --> 00:34:00,559
smaller expectations

927
00:34:00,559 --> 00:34:03,678
okay yeah go for it

928
00:34:05,039 --> 00:34:07,840
of extrapolating hopefully again from

929
00:34:07,840 --> 00:34:09,119
this

930
00:34:09,119 --> 00:34:11,599
that the predictive coding then

931
00:34:11,599 --> 00:34:12,719
like by

932
00:34:12,719 --> 00:34:14,800
working with the errors

933
00:34:14,800 --> 00:34:16,719
which are kind of almost

934
00:34:16,719 --> 00:34:18,399
uh i know i'm making a little bit of a

935
00:34:18,399 --> 00:34:21,760
jump here but um i kind of implicit to

936
00:34:21,760 --> 00:34:22,719
the

937
00:34:22,719 --> 00:34:24,960
to whatever the system of

938
00:34:24,960 --> 00:34:28,719
uh interpretation is on the data

939
00:34:28,719 --> 00:34:31,040
it is quite um it's kind of that's why

940
00:34:31,040 --> 00:34:32,639
you're going into this biological world

941
00:34:32,639 --> 00:34:35,760
because it's so bottom up in a way

942
00:34:35,760 --> 00:34:38,399
um because it can start just with

943
00:34:38,399 --> 00:34:39,679
um

944
00:34:39,679 --> 00:34:41,599
whatever the errors are

945
00:34:41,599 --> 00:34:44,320
in the nature of the um

946
00:34:44,320 --> 00:34:45,918
the system that's been set up for doing

947
00:34:45,918 --> 00:34:48,320
the sensing

948
00:34:48,320 --> 00:34:50,000
even forgetting action just the nature

949
00:34:50,000 --> 00:34:52,159
of how the sensing set up

950
00:34:52,159 --> 00:34:55,119
will start to generate the errors

951
00:34:55,119 --> 00:34:58,000
at some implicit level

952
00:34:58,000 --> 00:35:02,040
would that be a fair assumption

953
00:35:02,480 --> 00:35:03,920
so anytime there's going to be a

954
00:35:03,920 --> 00:35:06,240
prediction of observations so yeah we

955
00:35:06,240 --> 00:35:08,560
don't need action here yet

956
00:35:08,560 --> 00:35:10,000
there's two options

957
00:35:10,000 --> 00:35:13,760
either you have a 100 predictive power

958
00:35:13,760 --> 00:35:16,400
and your error is zero or there was some

959
00:35:16,400 --> 00:35:17,440
error

960
00:35:17,440 --> 00:35:19,200
so you're always in one of those two

961
00:35:19,200 --> 00:35:22,640
cases and which one are we usually in

962
00:35:22,640 --> 00:35:25,440
not having the total perfect 100

963
00:35:25,440 --> 00:35:27,440
accuracy down to the you know 100th

964
00:35:27,440 --> 00:35:29,280
decimal point

965
00:35:29,280 --> 00:35:32,160
if for no reason other than that's

966
00:35:32,160 --> 00:35:33,920
beyond the point of of diminishing

967
00:35:33,920 --> 00:35:37,200
returns or we're also trying to balance

968
00:35:37,200 --> 00:35:38,400
accuracy

969
00:35:38,400 --> 00:35:40,320
with model complexity

970
00:35:40,320 --> 00:35:42,560
so because we have these metrics like

971
00:35:42,560 --> 00:35:44,640
the aic the bic

972
00:35:44,640 --> 00:35:47,920
all these metrics that find us a model

973
00:35:47,920 --> 00:35:49,440
that's a balance between accuracy and

974
00:35:49,440 --> 00:35:50,640
complexity

975
00:35:50,640 --> 00:35:53,200
so it's not overfitting

976
00:35:53,200 --> 00:35:55,839
the cost of not overfitting

977
00:35:55,839 --> 00:35:56,640
of

978
00:35:56,640 --> 00:35:59,200
cost of having a simpler model is

979
00:35:59,200 --> 00:36:01,440
literally increased error because every

980
00:36:01,440 --> 00:36:03,440
new parameter that you add into a model

981
00:36:03,440 --> 00:36:05,680
you always explain more variance the

982
00:36:05,680 --> 00:36:07,599
first principal component takes the most

983
00:36:07,599 --> 00:36:09,119
variance of the data the second

984
00:36:09,119 --> 00:36:10,960
principal component takes the next most

985
00:36:10,960 --> 00:36:12,800
variance of the data every principal

986
00:36:12,800 --> 00:36:14,640
component on a data set is going to

987
00:36:14,640 --> 00:36:16,720
continue to eat more and more variants

988
00:36:16,720 --> 00:36:18,880
out of the data leaving less and less in

989
00:36:18,880 --> 00:36:20,640
the error term

990
00:36:20,640 --> 00:36:21,520
but

991
00:36:21,520 --> 00:36:24,000
it's a situational thing whether you

992
00:36:24,000 --> 00:36:26,640
need to explain 80 of the data or 90 of

993
00:36:26,640 --> 00:36:28,960
the data or 95 of the data but there's

994
00:36:28,960 --> 00:36:30,960
always going to be some difference

995
00:36:30,960 --> 00:36:32,480
between the

996
00:36:32,480 --> 00:36:34,400
prediction and the observation again

997
00:36:34,400 --> 00:36:36,400
unless one is in this super edge case

998
00:36:36,400 --> 00:36:38,240
where it's perfectly known

999
00:36:38,240 --> 00:36:41,760
so yeah go for it

1000
00:36:41,760 --> 00:36:44,480
yeah that's that's helpful and

1001
00:36:44,480 --> 00:36:47,680
it's also implicit there

1002
00:36:47,680 --> 00:36:50,400
that if even if you in whatever you set

1003
00:36:50,400 --> 00:36:52,880
that complexity and accuracy to at this

1004
00:36:52,880 --> 00:36:55,040
very deflated level

1005
00:36:55,040 --> 00:36:58,640
is is is really helpful so the nature of

1006
00:36:58,640 --> 00:36:59,839
the model

1007
00:36:59,839 --> 00:37:02,400
will change the nature of the errors

1008
00:37:02,400 --> 00:37:05,839
and basically the best it gets to

1009
00:37:05,839 --> 00:37:08,560
by the most it can reduce will vary a

1010
00:37:08,560 --> 00:37:10,800
little bit as you change that model

1011
00:37:10,800 --> 00:37:12,480
um and

1012
00:37:12,480 --> 00:37:14,079
not making too much of an extrapolation

1013
00:37:14,079 --> 00:37:15,680
but that that

1014
00:37:15,680 --> 00:37:19,200
is a nice way to be able to

1015
00:37:19,200 --> 00:37:21,839
unify a lot more complex and verified

1016
00:37:21,839 --> 00:37:23,200
ideas

1017
00:37:23,200 --> 00:37:24,960
about models and

1018
00:37:24,960 --> 00:37:28,079
you know what is really happening

1019
00:37:28,079 --> 00:37:29,040
um

1020
00:37:29,040 --> 00:37:30,480
you can sort of drop back to that

1021
00:37:30,480 --> 00:37:33,359
complexity accuracy

1022
00:37:33,359 --> 00:37:36,359
principle

1023
00:37:37,200 --> 00:37:39,599
so here's some more sections from 4.1

1024
00:37:39,599 --> 00:37:42,000
towards the end of 4.1 on page 30 in the

1025
00:37:42,000 --> 00:37:44,160
paper so yeah hopefully we've been

1026
00:37:44,160 --> 00:37:45,920
representing this at least mostly

1027
00:37:45,920 --> 00:37:47,680
accurately and then for those who want

1028
00:37:47,680 --> 00:37:49,839
to go deeper that's why there's a paper

1029
00:37:49,839 --> 00:37:51,920
and that's why there's like

1030
00:37:51,920 --> 00:37:53,760
a continued discussion and development

1031
00:37:53,760 --> 00:37:56,160
on these ideas because they they drop

1032
00:37:56,160 --> 00:37:58,160
many little crumbs

1033
00:37:58,160 --> 00:38:00,320
of well we've held this to be zero for

1034
00:38:00,320 --> 00:38:01,760
simplicity and

1035
00:38:01,760 --> 00:38:02,880
but they write

1036
00:38:02,880 --> 00:38:04,480
we can think of this as a predictive

1037
00:38:04,480 --> 00:38:06,720
coding network in which all the error is

1038
00:38:06,720 --> 00:38:08,800
initially focused at the output of the

1039
00:38:08,800 --> 00:38:11,040
network where the loss is and then

1040
00:38:11,040 --> 00:38:12,640
through dynamical minimization of

1041
00:38:12,640 --> 00:38:14,480
prediction errors at multiple levels

1042
00:38:14,480 --> 00:38:17,200
layers this error is slowly spread out

1043
00:38:17,200 --> 00:38:19,040
through the network in parallel until

1044
00:38:19,040 --> 00:38:20,880
the optimum distribution

1045
00:38:20,880 --> 00:38:23,520
the error at each vertex

1046
00:38:23,520 --> 00:38:25,520
is precisely the credit that should be

1047
00:38:25,520 --> 00:38:27,680
assigned to causing the error in the

1048
00:38:27,680 --> 00:38:29,760
first place

1049
00:38:29,760 --> 00:38:31,839
that's pretty interesting it's kind of

1050
00:38:31,839 --> 00:38:34,880
like let the chips fall where they may

1051
00:38:34,880 --> 00:38:38,240
with respect to error and variance

1052
00:38:38,240 --> 00:38:39,680
attribution

1053
00:38:39,680 --> 00:38:42,000
dean

1054
00:38:42,079 --> 00:38:44,480
this is this is awesome so

1055
00:38:44,480 --> 00:38:47,359
are they also are they also is the

1056
00:38:47,359 --> 00:38:50,160
way the architecture is and the way the

1057
00:38:50,160 --> 00:38:51,760
graph

1058
00:38:51,760 --> 00:38:55,119
the graph is set up as kind of a mirror

1059
00:38:55,119 --> 00:38:55,839
of

1060
00:38:55,839 --> 00:38:57,520
what the architecture is of this

1061
00:38:57,520 --> 00:38:58,960
layering thing

1062
00:38:58,960 --> 00:39:01,040
are they also there to kind of contain

1063
00:39:01,040 --> 00:39:02,640
little fires of

1064
00:39:02,640 --> 00:39:04,000
of mistakes

1065
00:39:04,000 --> 00:39:06,640
and errors is that why it's effective

1066
00:39:06,640 --> 00:39:09,680
because it sort of contains something

1067
00:39:09,680 --> 00:39:11,599
you know suddenly

1068
00:39:11,599 --> 00:39:12,839
causing a chain

1069
00:39:12,839 --> 00:39:15,200
reaction and having and having

1070
00:39:15,200 --> 00:39:16,079
everything

1071
00:39:16,079 --> 00:39:18,720
and when we read majeed's paper about i

1072
00:39:18,720 --> 00:39:20,400
think it was major maybe was axel's

1073
00:39:20,400 --> 00:39:22,800
paper about you can

1074
00:39:22,800 --> 00:39:24,480
you you could make

1075
00:39:24,480 --> 00:39:27,280
predictions going right off of a cliff

1076
00:39:27,280 --> 00:39:29,440
and and the result is you no longer

1077
00:39:29,440 --> 00:39:31,520
exist is this kind of an architecture

1078
00:39:31,520 --> 00:39:32,880
that

1079
00:39:32,880 --> 00:39:34,880
helps us avoid

1080
00:39:34,880 --> 00:39:36,400
some of those really

1081
00:39:36,400 --> 00:39:39,280
consequential prediction

1082
00:39:39,280 --> 00:39:42,240
consequences

1083
00:39:42,240 --> 00:39:44,720
that's an interesting idea

1084
00:39:44,720 --> 00:39:47,200
i think we should engage in some slide

1085
00:39:47,200 --> 00:39:48,079
play

1086
00:39:48,079 --> 00:39:50,800
and try to

1087
00:39:51,200 --> 00:39:53,200
try to get a little bit of clarity on

1088
00:39:53,200 --> 00:39:55,680
that and like also hopefully we'll hit

1089
00:39:55,680 --> 00:39:56,880
on

1090
00:39:56,880 --> 00:39:57,190
um

1091
00:39:57,190 --> 00:39:58,560
[Music]

1092
00:39:58,560 --> 00:39:59,920
a lot of the ideas that we've been

1093
00:39:59,920 --> 00:40:01,599
bringing up in a more abstract way

1094
00:40:01,599 --> 00:40:03,119
because i know it

1095
00:40:03,119 --> 00:40:05,359
it's helpful for like everyone to see

1096
00:40:05,359 --> 00:40:06,560
multiple

1097
00:40:06,560 --> 00:40:09,280
coats of paint on this and like it it's

1098
00:40:09,280 --> 00:40:12,480
the the epitome of abstraction

1099
00:40:12,480 --> 00:40:14,720
is the austerity of those

1100
00:40:14,720 --> 00:40:18,400
formalisms about compute graphs so let's

1101
00:40:18,400 --> 00:40:20,560
think about a um we won't take it to the

1102
00:40:20,560 --> 00:40:22,400
um the cafe

1103
00:40:22,400 --> 00:40:23,280
level

1104
00:40:23,280 --> 00:40:24,800
um that was even though that was i

1105
00:40:24,800 --> 00:40:28,400
remember that being quite fun um

1106
00:40:28,400 --> 00:40:30,400
we're gonna be we're gonna be between

1107
00:40:30,400 --> 00:40:31,760
the cafe

1108
00:40:31,760 --> 00:40:32,640
um

1109
00:40:32,640 --> 00:40:34,640
and uh you know

1110
00:40:34,640 --> 00:40:36,400
something else so we'll we'll be

1111
00:40:36,400 --> 00:40:37,760
intermediate because we're going to be

1112
00:40:37,760 --> 00:40:40,240
talking about a specific graph but we're

1113
00:40:40,240 --> 00:40:43,119
not going to like necessarily for the

1114
00:40:43,119 --> 00:40:46,160
first pass on it go all the way in okay

1115
00:40:46,160 --> 00:40:47,599
so

1116
00:40:47,599 --> 00:40:48,640
the

1117
00:40:48,640 --> 00:40:51,119
node that we care about being most

1118
00:40:51,119 --> 00:40:53,920
accurate on is seven

1119
00:40:53,920 --> 00:40:56,880
so like this is going to be like our our

1120
00:40:56,880 --> 00:40:58,560
focal note

1121
00:40:58,560 --> 00:41:00,720
this is like

1122
00:41:00,720 --> 00:41:02,640
the one that we want we want to have an

1123
00:41:02,640 --> 00:41:05,280
image classifier algorithm

1124
00:41:05,280 --> 00:41:07,520
this is the classifier node we want to

1125
00:41:07,520 --> 00:41:09,839
have um prediction on what the

1126
00:41:09,839 --> 00:41:11,520
thermometer is going to say that's what

1127
00:41:11,520 --> 00:41:13,280
this is we want to have prediction on

1128
00:41:13,280 --> 00:41:14,880
the temperature in the room that's what

1129
00:41:14,880 --> 00:41:17,200
this is we want to have

1130
00:41:17,200 --> 00:41:19,280
inference on action

1131
00:41:19,280 --> 00:41:22,000
and think about the upstream

1132
00:41:22,000 --> 00:41:23,359
parents

1133
00:41:23,359 --> 00:41:25,040
of action

1134
00:41:25,040 --> 00:41:26,960
then that's what this note is so seven

1135
00:41:26,960 --> 00:41:29,359
is going to be like the node that we're

1136
00:41:29,359 --> 00:41:30,480
interesting

1137
00:41:30,480 --> 00:41:33,599
uh interested in minimizing

1138
00:41:33,599 --> 00:41:36,000
our loss function on

1139
00:41:36,000 --> 00:41:38,240
okay

1140
00:41:40,079 --> 00:41:41,599
this can be carried out on multiple

1141
00:41:41,599 --> 00:41:43,040
variables but we're going to just look

1142
00:41:43,040 --> 00:41:46,560
at minimizing on this okay

1143
00:41:46,560 --> 00:41:49,839
what is the back propagation chain here

1144
00:41:49,839 --> 00:41:51,440
well let's think about what the forward

1145
00:41:51,440 --> 00:41:53,599
and the reverse arrows are so first just

1146
00:41:53,599 --> 00:41:55,280
to clarify like this is a directed

1147
00:41:55,280 --> 00:41:57,359
acyclic graph there's no loops in the

1148
00:41:57,359 --> 00:42:00,400
graph and the arrows are all directed

1149
00:42:00,400 --> 00:42:01,599
um

1150
00:42:01,599 --> 00:42:03,280
they reflect

1151
00:42:03,280 --> 00:42:05,119
differentiable functions causal

1152
00:42:05,119 --> 00:42:07,280
influences amongst these

1153
00:42:07,280 --> 00:42:09,440
uh variables these intermediate

1154
00:42:09,440 --> 00:42:10,720
computational

1155
00:42:10,720 --> 00:42:14,160
products so like variable one

1156
00:42:14,160 --> 00:42:16,000
is then there's some function

1157
00:42:16,000 --> 00:42:17,839
differentiable function

1158
00:42:17,839 --> 00:42:20,160
that translates it into two

1159
00:42:20,160 --> 00:42:22,800
two influences four and three

1160
00:42:22,800 --> 00:42:25,040
three influences five and six six

1161
00:42:25,040 --> 00:42:26,480
influences seven

1162
00:42:26,480 --> 00:42:27,599
okay

1163
00:42:27,599 --> 00:42:29,280
we've seen this in the bayesian context

1164
00:42:29,280 --> 00:42:32,079
where the sparsity of the connections

1165
00:42:32,079 --> 00:42:34,400
allow for the factorization

1166
00:42:34,400 --> 00:42:36,319
of this graph

1167
00:42:36,319 --> 00:42:39,680
like it allows us to sort of

1168
00:42:40,160 --> 00:42:42,960
hold one part

1169
00:42:42,960 --> 00:42:45,520
um unchanging and change other parts

1170
00:42:45,520 --> 00:42:47,119
through factorization that's a lot of

1171
00:42:47,119 --> 00:42:48,560
the variational inference stuff that

1172
00:42:48,560 --> 00:42:50,640
we've talked about okay so what are the

1173
00:42:50,640 --> 00:42:52,560
parents of seven

1174
00:42:52,560 --> 00:42:53,920
which nodes do you think that we should

1175
00:42:53,920 --> 00:42:55,599
consider if we're going to back

1176
00:42:55,599 --> 00:42:58,720
propagate so the forward model

1177
00:42:58,720 --> 00:43:00,800
the actual like causal chain in the

1178
00:43:00,800 --> 00:43:02,480
model not in the world

1179
00:43:02,480 --> 00:43:04,880
is like one you could imagine some

1180
00:43:04,880 --> 00:43:06,960
perturbation happens to one

1181
00:43:06,960 --> 00:43:09,680
every node is going to be influenced

1182
00:43:09,680 --> 00:43:12,079
that's the forward perturbation in the

1183
00:43:12,079 --> 00:43:15,200
forward generative model

1184
00:43:15,200 --> 00:43:16,240
what

1185
00:43:16,240 --> 00:43:19,440
is going to be invoked if we start at 7

1186
00:43:19,440 --> 00:43:22,720
and do a back propagation

1187
00:43:24,319 --> 00:43:27,839
which nodes are not important

1188
00:43:27,920 --> 00:43:29,200
five and four

1189
00:43:29,200 --> 00:43:31,200
right yeah five and four will not be

1190
00:43:31,200 --> 00:43:32,400
invoked

1191
00:43:32,400 --> 00:43:33,520
in this

1192
00:43:33,520 --> 00:43:36,079
optimization scheme

1193
00:43:36,079 --> 00:43:38,319
so if we were

1194
00:43:38,319 --> 00:43:40,079
so we'll make these ones gray that we're

1195
00:43:40,079 --> 00:43:42,160
going to be backpropagating on

1196
00:43:42,160 --> 00:43:44,800
but um and i i also hope i'm

1197
00:43:44,800 --> 00:43:46,720
representing this accurately

1198
00:43:46,720 --> 00:43:48,960
but um

1199
00:43:48,960 --> 00:43:50,560
you could imagine that like

1200
00:43:50,560 --> 00:43:53,280
changing the dials on 5 or the function

1201
00:43:53,280 --> 00:43:55,440
between 3 and 5

1202
00:43:55,440 --> 00:43:57,119
will not reduce

1203
00:43:57,119 --> 00:44:00,000
the loss on 7.

1204
00:44:00,000 --> 00:44:02,240
so it still might be an important thing

1205
00:44:02,240 --> 00:44:03,839
in the forward model

1206
00:44:03,839 --> 00:44:06,800
but it's not in the back propagation

1207
00:44:06,800 --> 00:44:08,480
from seven it's in the forward

1208
00:44:08,480 --> 00:44:10,480
propagation from one

1209
00:44:10,480 --> 00:44:12,560
um okay

1210
00:44:12,560 --> 00:44:14,160
so then

1211
00:44:14,160 --> 00:44:16,640
um this is not a predictive coding

1212
00:44:16,640 --> 00:44:18,560
architecture because in the predictive

1213
00:44:18,560 --> 00:44:21,280
coding architecture some of these

1214
00:44:21,280 --> 00:44:22,079
um

1215
00:44:22,079 --> 00:44:24,640
that's what we saw in like for example

1216
00:44:24,640 --> 00:44:26,000
in figure two

1217
00:44:26,000 --> 00:44:28,160
is what we saw in figure one

1218
00:44:28,160 --> 00:44:29,680
so

1219
00:44:29,680 --> 00:44:31,760
there's the means and

1220
00:44:31,760 --> 00:44:32,960
the

1221
00:44:32,960 --> 00:44:34,960
variance estimators so let's bring in

1222
00:44:34,960 --> 00:44:36,480
figure 1

1223
00:44:36,480 --> 00:44:38,560
and try to adapt it to our graph

1224
00:44:38,560 --> 00:44:42,000
so our graph is sort of

1225
00:44:42,000 --> 00:44:45,599
up to formalism 29.

1226
00:44:45,920 --> 00:44:46,720
now

1227
00:44:46,720 --> 00:44:48,319
we want to think about a graph that's

1228
00:44:48,319 --> 00:44:50,319
not just nodes and edges of the abstract

1229
00:44:50,319 --> 00:44:51,280
type

1230
00:44:51,280 --> 00:44:53,520
but it's going to be nodes and edges

1231
00:44:53,520 --> 00:44:56,880
that include these error neurons as

1232
00:44:56,880 --> 00:44:58,319
they're calling them here

1233
00:44:58,319 --> 00:44:59,839
okay so here's a reminder on what that

1234
00:44:59,839 --> 00:45:01,040
architecture

1235
00:45:01,040 --> 00:45:04,279
looked like

1236
00:45:04,880 --> 00:45:06,880
jax wrote how is the back propagation of

1237
00:45:06,880 --> 00:45:08,400
error related to

1238
00:45:08,400 --> 00:45:09,520
um

1239
00:45:09,520 --> 00:45:12,880
uh holland's john holland bucket brigade

1240
00:45:12,880 --> 00:45:14,880
the bucket brigade in signals and

1241
00:45:14,880 --> 00:45:16,480
boundaries it sounds explain a little

1242
00:45:16,480 --> 00:45:18,640
bit what is the bucket brigade or we'll

1243
00:45:18,640 --> 00:45:20,079
look but it sounds like a bunch of

1244
00:45:20,079 --> 00:45:22,319
people helping and

1245
00:45:22,319 --> 00:45:24,240
sharing buckets or something like that

1246
00:45:24,240 --> 00:45:25,119
um

1247
00:45:25,119 --> 00:45:26,400
okay

1248
00:45:26,400 --> 00:45:27,359
so

1249
00:45:27,359 --> 00:45:28,640
let's just say that the one that we

1250
00:45:28,640 --> 00:45:30,319
actually want to minimize is going to be

1251
00:45:30,319 --> 00:45:33,720
like a mew

1252
00:45:33,760 --> 00:45:37,280
it's going to be a mean estimator

1253
00:45:37,280 --> 00:45:40,240
now let's just modify this graph so that

1254
00:45:40,240 --> 00:45:41,839
this one's going to be error

1255
00:45:41,839 --> 00:45:43,599
i'll just use the um

1256
00:45:43,599 --> 00:45:44,400
won't

1257
00:45:44,400 --> 00:45:46,480
type the variables so this is a mean

1258
00:45:46,480 --> 00:45:48,960
estimator

1259
00:45:50,880 --> 00:45:53,440
and then we're going to alternate

1260
00:45:53,440 --> 00:45:56,079
so that this one

1261
00:45:56,079 --> 00:45:58,240
is an error

1262
00:45:58,240 --> 00:46:01,839
and this one is a mean

1263
00:46:03,119 --> 00:46:06,079
this one's a mean again

1264
00:46:10,240 --> 00:46:12,079
this is not the exact same architecture

1265
00:46:12,079 --> 00:46:13,920
that they laid out and this might not be

1266
00:46:13,920 --> 00:46:17,119
um traditional or um

1267
00:46:17,119 --> 00:46:19,599
classical standards but like this is

1268
00:46:19,599 --> 00:46:21,440
getting us towards this idea

1269
00:46:21,440 --> 00:46:23,839
that within a cortical column

1270
00:46:23,839 --> 00:46:25,359
so to speak

1271
00:46:25,359 --> 00:46:27,280
we have

1272
00:46:27,280 --> 00:46:28,560
um

1273
00:46:28,560 --> 00:46:31,520
the forward propagation of alternating

1274
00:46:31,520 --> 00:46:35,520
layers of means and errors

1275
00:46:36,480 --> 00:46:38,480
we want this

1276
00:46:38,480 --> 00:46:41,359
loss function to be minimized

1277
00:46:41,359 --> 00:46:43,680
by diffusing

1278
00:46:43,680 --> 00:46:46,720
the uncertainty across

1279
00:46:46,720 --> 00:46:49,919
these error nodes

1280
00:46:51,440 --> 00:46:54,079
that is like letting the chips lie

1281
00:46:54,079 --> 00:46:58,960
in terms of the variance attribution

1282
00:46:59,520 --> 00:47:01,200
and as they write precisely the credit

1283
00:47:01,200 --> 00:47:03,200
it should be assigned to cause the error

1284
00:47:03,200 --> 00:47:04,880
in the first place

1285
00:47:04,880 --> 00:47:05,680
so

1286
00:47:05,680 --> 00:47:07,119
if like

1287
00:47:07,119 --> 00:47:10,400
node two in the forward causal

1288
00:47:10,400 --> 00:47:11,839
model

1289
00:47:11,839 --> 00:47:14,480
was causing 90 of the variance

1290
00:47:14,480 --> 00:47:16,880
and so this was like like one

1291
00:47:16,880 --> 00:47:18,640
was you know is a very tight

1292
00:47:18,640 --> 00:47:19,839
distribution

1293
00:47:19,839 --> 00:47:22,160
and it gets blurred a ton on the way to

1294
00:47:22,160 --> 00:47:23,359
three

1295
00:47:23,359 --> 00:47:25,440
and then from three it only gets blurred

1296
00:47:25,440 --> 00:47:28,000
a little bit on the way to seven

1297
00:47:28,000 --> 00:47:31,040
so like two is going to be big

1298
00:47:31,040 --> 00:47:34,880
this is like a big error estimator

1299
00:47:34,880 --> 00:47:38,559
and six is small

1300
00:47:38,559 --> 00:47:40,720
tiny variance estimator

1301
00:47:40,720 --> 00:47:42,880
so it'd be like if we were in

1302
00:47:42,880 --> 00:47:44,319
classical statistics and we were going

1303
00:47:44,319 --> 00:47:45,119
to do

1304
00:47:45,119 --> 00:47:46,800
um you know we were doing

1305
00:47:46,800 --> 00:47:48,240
brain imaging

1306
00:47:48,240 --> 00:47:49,280
on

1307
00:47:49,280 --> 00:47:51,440
a bunch of people from two different

1308
00:47:51,440 --> 00:47:52,400
categories

1309
00:47:52,400 --> 00:47:54,960
like with and without this diagnosis

1310
00:47:54,960 --> 00:47:56,559
you could imagine that in that two-level

1311
00:47:56,559 --> 00:47:59,200
model one world there would be like

1312
00:47:59,200 --> 00:48:01,520
massive variance amongst people

1313
00:48:01,520 --> 00:48:03,440
and very little differences between

1314
00:48:03,440 --> 00:48:05,520
those two higher groups

1315
00:48:05,520 --> 00:48:07,119
in another world it could be the

1316
00:48:07,119 --> 00:48:09,280
opposite there could be big difference

1317
00:48:09,280 --> 00:48:11,680
between the two groups but very small

1318
00:48:11,680 --> 00:48:13,599
differences but amongst the people

1319
00:48:13,599 --> 00:48:15,280
within a group

1320
00:48:15,280 --> 00:48:16,400
and so

1321
00:48:16,400 --> 00:48:18,720
this is the parameterization and finding

1322
00:48:18,720 --> 00:48:20,400
the parameters that are going to

1323
00:48:20,400 --> 00:48:23,359
minimize the loss function

1324
00:48:23,359 --> 00:48:26,880
means that we want the variance

1325
00:48:26,880 --> 00:48:28,720
to be partitioned

1326
00:48:28,720 --> 00:48:30,720
appropriately

1327
00:48:30,720 --> 00:48:33,040
across error terms just like we would

1328
00:48:33,040 --> 00:48:36,160
like the average the mean estimators to

1329
00:48:36,160 --> 00:48:38,400
be accurate

1330
00:48:38,400 --> 00:48:40,960
the equivalent in the error world

1331
00:48:40,960 --> 00:48:44,800
is we want the errors to be appropriate

1332
00:48:44,800 --> 00:48:47,520
in how they're distributed

1333
00:48:47,520 --> 00:48:49,680
so it's like it's like if you're doing a

1334
00:48:49,680 --> 00:48:51,520
mean estimator

1335
00:48:51,520 --> 00:48:52,800
on something you don't just want like

1336
00:48:52,800 --> 00:48:55,040
the highest mean possible you want like

1337
00:48:55,040 --> 00:48:57,839
the most accurate mean possible

1338
00:48:57,839 --> 00:49:00,160
and the most accurate error possible

1339
00:49:00,160 --> 00:49:02,880
doesn't mean the lowest error possible

1340
00:49:02,880 --> 00:49:04,319
that would be the fallacy of well we're

1341
00:49:04,319 --> 00:49:06,000
estimating means well then let's just

1342
00:49:06,000 --> 00:49:07,920
make it bigger

1343
00:49:07,920 --> 00:49:10,559
so we're estimating errors not because

1344
00:49:10,559 --> 00:49:12,640
we want bigger errors or want smaller

1345
00:49:12,640 --> 00:49:15,200
errors that's the thumb on the scale

1346
00:49:15,200 --> 00:49:17,440
estimating errors accurately

1347
00:49:17,440 --> 00:49:18,800
entails

1348
00:49:18,800 --> 00:49:20,960
appropriately distributing the error

1349
00:49:20,960 --> 00:49:22,079
terms

1350
00:49:22,079 --> 00:49:25,520
on this graphical architecture

1351
00:49:25,520 --> 00:49:27,359
and then they're adding in one extra

1352
00:49:27,359 --> 00:49:28,640
point which is basically that the

1353
00:49:28,640 --> 00:49:31,280
dynamics of predictive coding are purely

1354
00:49:31,280 --> 00:49:32,400
local

1355
00:49:32,400 --> 00:49:34,480
requiring prediction errors from the

1356
00:49:34,480 --> 00:49:36,880
current vertex and the child that is

1357
00:49:36,880 --> 00:49:38,400
um

1358
00:49:38,400 --> 00:49:40,400
on the computational front

1359
00:49:40,400 --> 00:49:42,640
a win for tractability

1360
00:49:42,640 --> 00:49:44,800
and for the actual algorithm

1361
00:49:44,800 --> 00:49:46,319
because you don't need to have the whole

1362
00:49:46,319 --> 00:49:48,880
model loaded into ram for example

1363
00:49:48,880 --> 00:49:50,880
because you might only you know which

1364
00:49:50,880 --> 00:49:52,079
neighborhood of variables you're going

1365
00:49:52,079 --> 00:49:53,200
to engage

1366
00:49:53,200 --> 00:49:55,119
when you're doing a certain parameter

1367
00:49:55,119 --> 00:49:58,000
update and then on the biological side

1368
00:49:58,000 --> 00:49:59,680
it starts also leaning towards

1369
00:49:59,680 --> 00:50:00,960
plausibility

1370
00:50:00,960 --> 00:50:02,079
because

1371
00:50:02,079 --> 00:50:03,040
like

1372
00:50:03,040 --> 00:50:05,280
they even call it an error neuron well

1373
00:50:05,280 --> 00:50:07,359
neurons are signaling forward let's just

1374
00:50:07,359 --> 00:50:09,119
call that the direction that the action

1375
00:50:09,119 --> 00:50:11,040
potential travels

1376
00:50:11,040 --> 00:50:12,480
down the axon

1377
00:50:12,480 --> 00:50:13,839
but there's also

1378
00:50:13,839 --> 00:50:16,240
retrograde signaling at the synaptic

1379
00:50:16,240 --> 00:50:17,200
junction

1380
00:50:17,200 --> 00:50:19,680
so it's plausible at the multiple neuron

1381
00:50:19,680 --> 00:50:21,680
architecture level

1382
00:50:21,680 --> 00:50:24,000
or even at the two neuron

1383
00:50:24,000 --> 00:50:26,960
biological system level that there is

1384
00:50:26,960 --> 00:50:28,800
like even if there's a direction at

1385
00:50:28,800 --> 00:50:30,559
which signaling is

1386
00:50:30,559 --> 00:50:32,720
assumed or perceived to be

1387
00:50:32,720 --> 00:50:34,640
normatively happening

1388
00:50:34,640 --> 00:50:38,000
there's also a retrograde signaling

1389
00:50:38,000 --> 00:50:39,680
of multiple kinds we won't go into that

1390
00:50:39,680 --> 00:50:42,160
like complexity of retrograde synaptic

1391
00:50:42,160 --> 00:50:43,440
regulation

1392
00:50:43,440 --> 00:50:44,160
but

1393
00:50:44,160 --> 00:50:46,559
that at the circuit level and at even

1394
00:50:46,559 --> 00:50:48,480
the synapse level the idea that

1395
00:50:48,480 --> 00:50:51,680
signaling is happening both ways

1396
00:50:51,680 --> 00:50:53,839
is something that is

1397
00:50:53,839 --> 00:50:55,040
seen as the strength of the predictive

1398
00:50:55,040 --> 00:50:57,200
coding architecture again the locality

1399
00:50:57,200 --> 00:50:58,880
allows it to be more computationally

1400
00:50:58,880 --> 00:51:00,240
implementable

1401
00:51:00,240 --> 00:51:02,720
and this sort of bi-directionality and

1402
00:51:02,720 --> 00:51:05,200
signaling is more reminiscent of

1403
00:51:05,200 --> 00:51:08,079
biological signaling processes synapses

1404
00:51:08,079 --> 00:51:12,559
conversations brain regions so on

1405
00:51:18,800 --> 00:51:20,400
okay let's

1406
00:51:20,400 --> 00:51:23,839
okay yeah any thoughts on this

1407
00:51:26,559 --> 00:51:28,480
i think that that's a pretty good

1408
00:51:28,480 --> 00:51:31,440
explanation go for it stephen

1409
00:51:31,440 --> 00:51:33,280
just just checking so

1410
00:51:33,280 --> 00:51:35,680
if you added all the errors up

1411
00:51:35,680 --> 00:51:37,280
like are the errors kind of independent

1412
00:51:37,280 --> 00:51:38,800
of each other or would they

1413
00:51:38,800 --> 00:51:40,800
is there like a total error

1414
00:51:40,800 --> 00:51:42,559
across the

1415
00:51:42,559 --> 00:51:45,680
chain so to speak of like

1416
00:51:45,680 --> 00:51:47,839
uh how much error there can be

1417
00:51:47,839 --> 00:51:49,599
or is it like

1418
00:51:49,599 --> 00:51:50,960
kind of

1419
00:51:50,960 --> 00:51:52,640
contained within

1420
00:51:52,640 --> 00:51:54,640
the switch like is six relatively

1421
00:51:54,640 --> 00:51:56,160
contained

1422
00:51:56,160 --> 00:52:00,598
and two relatively contained

1423
00:52:06,720 --> 00:52:07,839
okay dean

1424
00:52:07,839 --> 00:52:10,000
can i take a guess stephen yeah sure i'm

1425
00:52:10,000 --> 00:52:12,400
get i'm guessing so just

1426
00:52:12,400 --> 00:52:15,119
keep the wild a money money part of this

1427
00:52:15,119 --> 00:52:17,040
front of mind um

1428
00:52:17,040 --> 00:52:18,400
i think what the

1429
00:52:18,400 --> 00:52:20,240
i think what the graph is telling us or

1430
00:52:20,240 --> 00:52:21,920
at least when we

1431
00:52:21,920 --> 00:52:24,000
formalize it in this way

1432
00:52:24,000 --> 00:52:24,960
is that

1433
00:52:24,960 --> 00:52:27,200
you could always

1434
00:52:27,200 --> 00:52:30,079
find the cumulative error but the point

1435
00:52:30,079 --> 00:52:33,200
of the system is to

1436
00:52:33,200 --> 00:52:35,520
try and keep the error

1437
00:52:35,520 --> 00:52:39,040
where it actually exists within each

1438
00:52:39,040 --> 00:52:41,920
layer so sort of sort of partnering the

1439
00:52:41,920 --> 00:52:44,319
error

1440
00:52:44,480 --> 00:52:47,119
at each level with with whatever the

1441
00:52:47,119 --> 00:52:50,319
prior or the hierarchical l plus one or

1442
00:52:50,319 --> 00:52:51,920
l minus one

1443
00:52:51,920 --> 00:52:54,480
layer is but me again

1444
00:52:54,480 --> 00:52:56,880
i'm just guessing but i'm kind of making

1445
00:52:56,880 --> 00:52:59,599
sure that i understand completely what

1446
00:52:59,599 --> 00:53:01,280
what daniel laid out here and that would

1447
00:53:01,280 --> 00:53:03,119
be my guess

1448
00:53:03,119 --> 00:53:06,000
i mean you could you can add it all up

1449
00:53:06,000 --> 00:53:08,480
but i think i think the point of it is

1450
00:53:08,480 --> 00:53:11,839
is that before it it runs away from you

1451
00:53:11,839 --> 00:53:14,559
this architecture is set up

1452
00:53:14,559 --> 00:53:16,800
so that

1453
00:53:16,800 --> 00:53:19,440
there will be some cumulative effect but

1454
00:53:19,440 --> 00:53:21,839
it probably wouldn't be

1455
00:53:21,839 --> 00:53:22,800
it

1456
00:53:22,800 --> 00:53:24,480
shouldn't be there's the word i'm

1457
00:53:24,480 --> 00:53:26,480
looking for it shouldn't be as

1458
00:53:26,480 --> 00:53:29,520
abrupt as if you didn't have the layers

1459
00:53:29,520 --> 00:53:31,200
and you didn't have the ability to

1460
00:53:31,200 --> 00:53:34,160
differentiate and you didn't have a kind

1461
00:53:34,160 --> 00:53:36,240
of understanding of what what is

1462
00:53:36,240 --> 00:53:38,400
happening i.e

1463
00:53:38,400 --> 00:53:40,880
back propagationally

1464
00:53:40,880 --> 00:53:42,640
now again i'm just throwing that out

1465
00:53:42,640 --> 00:53:44,240
there but because i don't have a

1466
00:53:44,240 --> 00:53:46,160
reputation around this i could be

1467
00:53:46,160 --> 00:53:48,879
completely wrong

1468
00:53:50,880 --> 00:53:52,800
there's a lot to say and the authors

1469
00:53:52,800 --> 00:53:53,839
like do

1470
00:53:53,839 --> 00:53:56,240
provide many citations but i i believe

1471
00:53:56,240 --> 00:53:58,000
that's right like

1472
00:53:58,000 --> 00:53:59,359
just as

1473
00:53:59,359 --> 00:54:02,160
appropriate mean determination we're

1474
00:54:02,160 --> 00:54:05,760
thinking in a gaussian world like

1475
00:54:05,760 --> 00:54:07,200
um

1476
00:54:07,200 --> 00:54:08,720
there's a lot to say on gaussian

1477
00:54:08,720 --> 00:54:10,400
processes but a gaussian

1478
00:54:10,400 --> 00:54:11,839
is a mean

1479
00:54:11,839 --> 00:54:13,760
and an uncertainty

1480
00:54:13,760 --> 00:54:15,520
so it's there's going to be somewhere

1481
00:54:15,520 --> 00:54:19,040
where the hump of that distribution is

1482
00:54:19,040 --> 00:54:20,559
and then there's going to be some width

1483
00:54:20,559 --> 00:54:21,680
to it

1484
00:54:21,680 --> 00:54:22,960
now

1485
00:54:22,960 --> 00:54:25,119
sometimes

1486
00:54:25,119 --> 00:54:28,160
the process is actually gaussian

1487
00:54:28,160 --> 00:54:30,559
other times we can use nested gaussian

1488
00:54:30,559 --> 00:54:32,000
processes

1489
00:54:32,000 --> 00:54:34,000
so that it's like well there's some

1490
00:54:34,000 --> 00:54:36,319
process that's moving it

1491
00:54:36,319 --> 00:54:38,160
and then there's wiggle around it so

1492
00:54:38,160 --> 00:54:39,680
we're gonna see that

1493
00:54:39,680 --> 00:54:41,599
moving as one galaxy and then the other

1494
00:54:41,599 --> 00:54:42,799
one is like a ripple that's like a

1495
00:54:42,799 --> 00:54:46,160
smaller gaussian on that

1496
00:54:46,720 --> 00:54:49,160
and then even in cases where there's a

1497
00:54:49,160 --> 00:54:51,920
non-gaussian distribution that's where

1498
00:54:51,920 --> 00:54:53,839
the laplace approximation comes into

1499
00:54:53,839 --> 00:54:56,559
play which is the second

1500
00:54:56,559 --> 00:54:58,000
derivative

1501
00:54:58,000 --> 00:54:59,440
we have the jacobian and then the

1502
00:54:59,440 --> 00:55:02,240
hessian matrix in 26

1503
00:55:02,240 --> 00:55:03,520
and then we talked about how when you

1504
00:55:03,520 --> 00:55:05,760
take the second derivative

1505
00:55:05,760 --> 00:55:08,880
you're basically making that bowl

1506
00:55:08,880 --> 00:55:10,960
and then lying in it

1507
00:55:10,960 --> 00:55:12,160
so you're going to the bottom of the

1508
00:55:12,160 --> 00:55:14,559
bowl that you created

1509
00:55:14,559 --> 00:55:16,319
and you know that it's going to be the

1510
00:55:16,319 --> 00:55:17,440
sort of

1511
00:55:17,440 --> 00:55:19,280
hump structure

1512
00:55:19,280 --> 00:55:21,040
that's amenable

1513
00:55:21,040 --> 00:55:21,839
to

1514
00:55:21,839 --> 00:55:23,359
going downhill

1515
00:55:23,359 --> 00:55:26,240
because once you go beyond quadratic

1516
00:55:26,240 --> 00:55:28,720
beyond the hump anything that's like a

1517
00:55:28,720 --> 00:55:31,280
multi-hump distribution or even just x

1518
00:55:31,280 --> 00:55:32,640
cubed

1519
00:55:32,640 --> 00:55:35,680
you're going to have challenges

1520
00:55:35,680 --> 00:55:38,240
getting globally optimal from local

1521
00:55:38,240 --> 00:55:40,720
optimization processes because you won't

1522
00:55:40,720 --> 00:55:42,880
know if you're in a local energy well or

1523
00:55:42,880 --> 00:55:43,680
not

1524
00:55:43,680 --> 00:55:44,960
and so

1525
00:55:44,960 --> 00:55:47,680
many of these computational tools and

1526
00:55:47,680 --> 00:55:49,839
approaches that we're discussing like

1527
00:55:49,839 --> 00:55:52,720
across these live streams and papers

1528
00:55:52,720 --> 00:55:54,160
can be understood

1529
00:55:54,160 --> 00:55:56,480
as taking something that isn't like a

1530
00:55:56,480 --> 00:55:57,839
bowl

1531
00:55:57,839 --> 00:56:01,200
and making it so that it can go downhill

1532
00:56:01,200 --> 00:56:02,960
and finding well what is the appropriate

1533
00:56:02,960 --> 00:56:04,160
level

1534
00:56:04,160 --> 00:56:06,400
of how many layers have to be added to

1535
00:56:06,400 --> 00:56:08,640
this onion or how many oven gloves do i

1536
00:56:08,640 --> 00:56:10,160
have to put on

1537
00:56:10,160 --> 00:56:12,319
how many approximations

1538
00:56:12,319 --> 00:56:14,480
should we carry out in our approximation

1539
00:56:14,480 --> 00:56:15,599
science

1540
00:56:15,599 --> 00:56:18,160
so that there can be something like

1541
00:56:18,160 --> 00:56:19,920
a parabola

1542
00:56:19,920 --> 00:56:20,720
where

1543
00:56:20,720 --> 00:56:24,160
we know that we're on parabola territory

1544
00:56:24,160 --> 00:56:27,200
and that's what allows us to then

1545
00:56:27,200 --> 00:56:29,119
minimize a loss function

1546
00:56:29,119 --> 00:56:30,400
because if one believed that they were

1547
00:56:30,400 --> 00:56:32,240
on a rugged landscape

1548
00:56:32,240 --> 00:56:33,040
then

1549
00:56:33,040 --> 00:56:36,400
minimizing something locally

1550
00:56:36,400 --> 00:56:38,480
would be you'd have no way to know if

1551
00:56:38,480 --> 00:56:40,960
that was on the right track or not

1552
00:56:40,960 --> 00:56:43,200
um yes stephen

1553
00:56:43,200 --> 00:56:45,200
and could i say then would i be okay to

1554
00:56:45,200 --> 00:56:47,440
say that it's almost like each of these

1555
00:56:47,440 --> 00:56:49,760
errors say number six number two

1556
00:56:49,760 --> 00:56:51,200
in here and you could have be like

1557
00:56:51,200 --> 00:56:53,599
little mini bowls or mini

1558
00:56:53,599 --> 00:56:56,839
um at different and the further up the

1559
00:56:56,839 --> 00:57:00,160
chain the bigger the potential

1560
00:57:00,160 --> 00:57:01,119
um

1561
00:57:01,119 --> 00:57:03,440
impact of the positioning in that bowl

1562
00:57:03,440 --> 00:57:06,240
or whatever the landscape is

1563
00:57:06,240 --> 00:57:07,440
out

1564
00:57:07,440 --> 00:57:09,440
towards whatever's being

1565
00:57:09,440 --> 00:57:12,640
you know the mean that's been understood

1566
00:57:12,640 --> 00:57:15,359
okay let's look at figure one

1567
00:57:15,359 --> 00:57:18,720
so this is a cortically inspired so

1568
00:57:18,720 --> 00:57:21,359
inspired by the cortex

1569
00:57:21,359 --> 00:57:23,119
and blue ro dean i understand the

1570
00:57:23,119 --> 00:57:24,720
architecture the same way error

1571
00:57:24,720 --> 00:57:27,520
correction is retained locally

1572
00:57:27,520 --> 00:57:30,119
so let's look at this

1573
00:57:30,119 --> 00:57:33,040
semi-cortically inspired

1574
00:57:33,040 --> 00:57:34,480
predictive coding

1575
00:57:34,480 --> 00:57:36,160
hierarchical

1576
00:57:36,160 --> 00:57:37,359
system

1577
00:57:37,359 --> 00:57:39,440
just like in the example with the two

1578
00:57:39,440 --> 00:57:41,920
clinical populations doing brain imaging

1579
00:57:41,920 --> 00:57:44,000
there's one world where the patients

1580
00:57:44,000 --> 00:57:45,200
within the group vary a lot and the

1581
00:57:45,200 --> 00:57:46,880
groups don't differ there's another

1582
00:57:46,880 --> 00:57:49,280
world where the groups differ a ton

1583
00:57:49,280 --> 00:57:50,960
and then the people within each group do

1584
00:57:50,960 --> 00:57:53,200
not have any variance amongst them so

1585
00:57:53,200 --> 00:57:55,920
depending on how it's parameterized

1586
00:57:55,920 --> 00:57:58,640
one could have a model where

1587
00:57:58,640 --> 00:57:59,839
the

1588
00:57:59,839 --> 00:58:03,200
um highest level

1589
00:58:03,200 --> 00:58:06,879
has a major influence or not

1590
00:58:07,520 --> 00:58:09,920
and that's the whole question it's like

1591
00:58:09,920 --> 00:58:11,760
in a linear model is it more important

1592
00:58:11,760 --> 00:58:13,520
like the um

1593
00:58:13,520 --> 00:58:16,480
mx part the slope or the b how much it

1594
00:58:16,480 --> 00:58:18,240
shifted

1595
00:58:18,240 --> 00:58:19,440
well

1596
00:58:19,440 --> 00:58:21,680
if the regime of attention is on linear

1597
00:58:21,680 --> 00:58:24,160
modeling as an architecture

1598
00:58:24,160 --> 00:58:25,839
it doesn't make sense

1599
00:58:25,839 --> 00:58:28,079
because they're both just parameters in

1600
00:58:28,079 --> 00:58:29,119
a model

1601
00:58:29,119 --> 00:58:30,640
now for any given data set it's an

1602
00:58:30,640 --> 00:58:33,280
empirical question to what extent

1603
00:58:33,280 --> 00:58:37,359
changes in the slope or the intercept

1604
00:58:37,359 --> 00:58:39,040
are associated with changes in the loss

1605
00:58:39,040 --> 00:58:40,240
function

1606
00:58:40,240 --> 00:58:42,559
and that's linear regression

1607
00:58:42,559 --> 00:58:44,720
here's an architecture

1608
00:58:44,720 --> 00:58:46,720
that gives us

1609
00:58:46,720 --> 00:58:50,640
an approach to finding loss functions

1610
00:58:50,640 --> 00:58:53,760
but how do we know how many layers

1611
00:58:53,760 --> 00:58:57,040
how do we know how many of these side

1612
00:58:57,040 --> 00:59:00,000
connections to make

1613
00:59:00,559 --> 00:59:02,400
but there's a few ways to go about that

1614
00:59:02,400 --> 00:59:04,480
one could just a priori

1615
00:59:04,480 --> 00:59:06,400
model the structure

1616
00:59:06,400 --> 00:59:08,720
of the model of the graph around

1617
00:59:08,720 --> 00:59:10,960
something else like previous work or

1618
00:59:10,960 --> 00:59:12,960
some inspiration from a biological

1619
00:59:12,960 --> 00:59:14,960
system

1620
00:59:14,960 --> 00:59:17,280
they might also be interested in this

1621
00:59:17,280 --> 00:59:18,799
structure

1622
00:59:18,799 --> 00:59:21,760
being a parameter of a model

1623
00:59:21,760 --> 00:59:23,839
like

1624
00:59:23,839 --> 00:59:25,359
and that's the whole

1625
00:59:25,359 --> 00:59:26,960
structure learning

1626
00:59:26,960 --> 00:59:27,680
and

1627
00:59:27,680 --> 00:59:30,960
meta-bayesian approaches and all of that

1628
00:59:30,960 --> 00:59:32,960
but that's pulling back another level

1629
00:59:32,960 --> 00:59:34,480
and so that's the

1630
00:59:34,480 --> 00:59:36,400
the challenge of structure learning

1631
00:59:36,400 --> 00:59:39,520
because we can get that loss function

1632
00:59:39,520 --> 00:59:40,640
within

1633
00:59:40,640 --> 00:59:43,760
a given static graph

1634
00:59:43,760 --> 00:59:45,200
but that doesn't mean that we have the

1635
00:59:45,200 --> 00:59:49,119
best possible graph architecture

1636
00:59:49,119 --> 00:59:52,079
it's like if you have 100 pieces of

1637
00:59:52,079 --> 00:59:54,480
data biometric data on people and you're

1638
00:59:54,480 --> 00:59:56,400
making a multiple linear regression to

1639
00:59:56,400 --> 01:00:00,400
find out their risk for some condition

1640
01:00:00,400 --> 01:00:02,960
do you just use 100

1641
01:00:02,960 --> 01:00:05,520
that might be overfitting it might be

1642
01:00:05,520 --> 01:00:07,760
too costly computationally so how many

1643
01:00:07,760 --> 01:00:10,559
of those variables do you use

1644
01:00:10,559 --> 01:00:12,559
there's a process for determining that

1645
01:00:12,559 --> 01:00:14,559
what's at the trade-off between

1646
01:00:14,559 --> 01:00:16,480
accuracy and complexity where it's

1647
01:00:16,480 --> 01:00:17,599
fitting

1648
01:00:17,599 --> 01:00:19,520
the outcome well

1649
01:00:19,520 --> 01:00:21,520
the loss function on the condition that

1650
01:00:21,520 --> 01:00:23,920
you're trying to actually predict

1651
01:00:23,920 --> 01:00:25,359
but it's not past the point of

1652
01:00:25,359 --> 01:00:27,520
diminishing return or using variables

1653
01:00:27,520 --> 01:00:29,680
that are uninformative or for example if

1654
01:00:29,680 --> 01:00:31,040
there's two variables that are perfectly

1655
01:00:31,040 --> 01:00:33,119
correlated with each other

1656
01:00:33,119 --> 01:00:35,040
um that's called multi-linearity and

1657
01:00:35,040 --> 01:00:36,640
like you wouldn't want to use those

1658
01:00:36,640 --> 01:00:38,880
variables

1659
01:00:38,880 --> 01:00:40,000
so

1660
01:00:40,000 --> 01:00:41,760
that's the challenge in the linear

1661
01:00:41,760 --> 01:00:44,240
regression world and this is like taking

1662
01:00:44,240 --> 01:00:47,520
it into another space but it has more

1663
01:00:47,520 --> 01:00:50,079
analogies than not which is why spm

1664
01:00:50,079 --> 01:00:52,559
statistical parametric mapping that

1665
01:00:52,559 --> 01:00:54,559
textbook is

1666
01:00:54,559 --> 01:00:57,040
um for those who want to engage

1667
01:00:57,040 --> 01:00:58,319
vital

1668
01:00:58,319 --> 01:00:59,599
prerequisite

1669
01:00:59,599 --> 01:01:01,520
because it addresses a lot of these

1670
01:01:01,520 --> 01:01:03,280
questions on model fitting

1671
01:01:03,280 --> 01:01:05,440
including on dynamical systems and it

1672
01:01:05,440 --> 01:01:07,119
puts it with

1673
01:01:07,119 --> 01:01:08,799
six feet on the ground

1674
01:01:08,799 --> 01:01:10,480
in classical parametric and

1675
01:01:10,480 --> 01:01:14,400
non-parametric statistics dean

1676
01:01:14,480 --> 01:01:15,920
this just

1677
01:01:15,920 --> 01:01:18,000
raises the question in my mind i haven't

1678
01:01:18,000 --> 01:01:21,440
answered it as to whether or not a mean

1679
01:01:21,440 --> 01:01:23,280
is constructed

1680
01:01:23,280 --> 01:01:24,640
or if a mean

1681
01:01:24,640 --> 01:01:26,559
is actually sculpted

1682
01:01:26,559 --> 01:01:29,280
or some combination of the two i mean

1683
01:01:29,280 --> 01:01:31,359
being a min 2 guy i'm going to assume

1684
01:01:31,359 --> 01:01:32,960
that it's probably

1685
01:01:32,960 --> 01:01:34,000
both

1686
01:01:34,000 --> 01:01:36,240
like you can have the figure

1687
01:01:36,240 --> 01:01:39,760
but it's your understanding of of

1688
01:01:39,760 --> 01:01:42,319
what the difference is between an edge

1689
01:01:42,319 --> 01:01:43,839
and a and a

1690
01:01:43,839 --> 01:01:46,000
and a directional link which you have to

1691
01:01:46,000 --> 01:01:50,240
kind of carve out from the overall image

1692
01:01:50,240 --> 01:01:52,000
but that's again that's one of these

1693
01:01:52,000 --> 01:01:53,520
things now where if you get into this

1694
01:01:53,520 --> 01:01:55,920
predictive coding piece

1695
01:01:55,920 --> 01:01:57,520
i think the product looks like a

1696
01:01:57,520 --> 01:01:59,200
construct

1697
01:01:59,200 --> 01:02:01,839
but an actual but in actuality there's

1698
01:02:01,839 --> 01:02:04,240
there's got to be a huge element of this

1699
01:02:04,240 --> 01:02:05,280
of

1700
01:02:05,280 --> 01:02:07,520
being able to isolate

1701
01:02:07,520 --> 01:02:08,960
the mistakes so that they don't

1702
01:02:08,960 --> 01:02:10,640
overwhelm and if you're isolating

1703
01:02:10,640 --> 01:02:12,480
something if you're removing

1704
01:02:12,480 --> 01:02:15,119
some factor you're actually sculpting as

1705
01:02:15,119 --> 01:02:16,559
well

1706
01:02:16,559 --> 01:02:18,960
so maybe that's a bit of a philosophical

1707
01:02:18,960 --> 01:02:21,839
overlay on the sort of mathematical

1708
01:02:21,839 --> 01:02:23,520
operational side

1709
01:02:23,520 --> 01:02:25,039
but you know me i'm always trying to

1710
01:02:25,039 --> 01:02:26,480
turn it into what's the what's the

1711
01:02:26,480 --> 01:02:27,920
practical

1712
01:02:27,920 --> 01:02:30,000
function of this

1713
01:02:30,000 --> 01:02:32,160
yeah it's like statistics

1714
01:02:32,160 --> 01:02:34,480
as world building because

1715
01:02:34,480 --> 01:02:37,280
if you just want the mean

1716
01:02:37,280 --> 01:02:38,799
then just

1717
01:02:38,799 --> 01:02:41,119
take the grand average if you want the

1718
01:02:41,119 --> 01:02:42,960
mean and the variance there's a method

1719
01:02:42,960 --> 01:02:45,599
do you want a variance on the variance

1720
01:02:45,599 --> 01:02:47,839
how confident are you that it's 10 plus

1721
01:02:47,839 --> 01:02:49,119
or minus 1

1722
01:02:49,119 --> 01:02:51,440
is it 10 plus or minus 1

1723
01:02:51,440 --> 01:02:53,760
plus or minus 0.5

1724
01:02:53,760 --> 01:02:55,839
or is it 10 plus or minus 1 plus or

1725
01:02:55,839 --> 01:02:59,920
minus 0.01 so a tight estimator

1726
01:02:59,920 --> 01:03:02,720
on the error as a parameter

1727
01:03:02,720 --> 01:03:04,480
and so we're like playing with which

1728
01:03:04,480 --> 01:03:06,000
parameters

1729
01:03:06,000 --> 01:03:08,079
are seen as like the things in and of

1730
01:03:08,079 --> 01:03:09,440
themself

1731
01:03:09,440 --> 01:03:10,799
the means

1732
01:03:10,799 --> 01:03:12,640
and which ones with respect to means

1733
01:03:12,640 --> 01:03:15,200
have this interpretation as being error

1734
01:03:15,200 --> 01:03:17,599
neurons or being variance descriptors

1735
01:03:17,599 --> 01:03:18,799
now

1736
01:03:18,799 --> 01:03:19,599
one

1737
01:03:19,599 --> 01:03:22,000
properly fit model which you could take

1738
01:03:22,000 --> 01:03:24,160
into the you know 50

1739
01:03:24,160 --> 01:03:26,880
stacked levels 10 plus or minus 1

1740
01:03:26,880 --> 01:03:29,520
and then on that one variance estimator

1741
01:03:29,520 --> 01:03:31,839
we have plus or minus 0.1 and then how

1742
01:03:31,839 --> 01:03:33,359
how sure are we about the plus or minus

1743
01:03:33,359 --> 01:03:34,480
0.1

1744
01:03:34,480 --> 01:03:36,960
0.01 okay now how sure are we about that

1745
01:03:36,960 --> 01:03:40,160
0.01 0.001 that would be like a well-fit

1746
01:03:40,160 --> 01:03:42,000
model where as we kept on adding

1747
01:03:42,000 --> 01:03:44,400
uncertainty parameters we would be

1748
01:03:44,400 --> 01:03:46,319
making appropriate

1749
01:03:46,319 --> 01:03:47,599
estimators

1750
01:03:47,599 --> 01:03:50,319
now what would be like a male fit model

1751
01:03:50,319 --> 01:03:52,559
and i hope this is accurate

1752
01:03:52,559 --> 01:03:55,359
10 plus or minus 1 and you go how sure

1753
01:03:55,359 --> 01:03:57,680
are you on that one

1754
01:03:57,680 --> 01:03:59,839
plus or minus 50.

1755
01:03:59,839 --> 01:04:00,720
it's like

1756
01:04:00,720 --> 01:04:02,640
the variance just exploded it's like

1757
01:04:02,640 --> 01:04:04,960
well but you're saying that the variance

1758
01:04:04,960 --> 01:04:06,079
could be like

1759
01:04:06,079 --> 01:04:07,520
zero

1760
01:04:07,520 --> 01:04:09,760
or the variance could be 50

1761
01:04:09,760 --> 01:04:11,440
how much confidence should we then have

1762
01:04:11,440 --> 01:04:14,640
in the mean estimator

1763
01:04:14,640 --> 01:04:18,720
and so that's what this appropriate

1764
01:04:18,720 --> 01:04:20,559
distribution

1765
01:04:20,559 --> 01:04:23,839
of uncertainty is now let's think about

1766
01:04:23,839 --> 01:04:24,839
node

1767
01:04:24,839 --> 01:04:28,960
seven an uninformative node seven

1768
01:04:28,960 --> 01:04:30,480
we're predicting temperature but it's

1769
01:04:30,480 --> 01:04:33,520
just it's unchanging

1770
01:04:34,160 --> 01:04:36,480
we don't have a lot of information there

1771
01:04:36,480 --> 01:04:39,200
to fit a world model

1772
01:04:39,200 --> 01:04:40,799
because it could just be a single level

1773
01:04:40,799 --> 01:04:44,640
estimate it's 10 and it's not changing

1774
01:04:44,640 --> 01:04:47,119
but as we deal with progressively more

1775
01:04:47,119 --> 01:04:48,880
and more

1776
01:04:48,880 --> 01:04:51,440
nuanced and informative things that we

1777
01:04:51,440 --> 01:04:55,280
want to minimize loss functions on like

1778
01:04:55,280 --> 01:04:57,200
natural language

1779
01:04:57,200 --> 01:04:59,920
images from natural scenes

1780
01:04:59,920 --> 01:05:01,680
action including the unknown

1781
01:05:01,680 --> 01:05:03,920
consequences of real-time unfolding

1782
01:05:03,920 --> 01:05:05,280
action

1783
01:05:05,280 --> 01:05:07,359
those

1784
01:05:07,359 --> 01:05:10,559
because the uncertainty

1785
01:05:10,559 --> 01:05:12,400
becomes higher

1786
01:05:12,400 --> 01:05:14,400
and the information content of what

1787
01:05:14,400 --> 01:05:16,000
you're trying to minimize your loss

1788
01:05:16,000 --> 01:05:18,000
function on is higher

1789
01:05:18,000 --> 01:05:19,440
it

1790
01:05:19,440 --> 01:05:22,400
um

1791
01:05:22,400 --> 01:05:26,559
not authorizes or licenses but kind of

1792
01:05:26,559 --> 01:05:29,200
moves us into potentially having higher

1793
01:05:29,200 --> 01:05:31,520
levels of model complexity

1794
01:05:31,520 --> 01:05:34,079
as simple as possible and not simpler

1795
01:05:34,079 --> 01:05:35,599
with that principle being carried

1796
01:05:35,599 --> 01:05:36,640
through

1797
01:05:36,640 --> 01:05:37,839
again if you're just trying to predict a

1798
01:05:37,839 --> 01:05:40,000
constant number you don't need a six

1799
01:05:40,000 --> 01:05:43,119
level predictive coding architecture

1800
01:05:43,119 --> 01:05:45,440
whereas if there was something that did

1801
01:05:45,440 --> 01:05:47,039
actually have

1802
01:05:47,039 --> 01:05:49,119
that many levels

1803
01:05:49,119 --> 01:05:51,440
of depth

1804
01:05:51,440 --> 01:05:53,280
that's the kind of architecture that

1805
01:05:53,280 --> 01:05:54,799
would do well to predict it and we

1806
01:05:54,799 --> 01:05:56,960
talked about this with the um par and

1807
01:05:56,960 --> 01:05:58,000
pazulo

1808
01:05:58,000 --> 01:06:00,799
on the architectures for homeostasis and

1809
01:06:00,799 --> 01:06:02,160
allostasis

1810
01:06:02,160 --> 01:06:04,400
and it was like yeah to just recognize

1811
01:06:04,400 --> 01:06:05,920
if you're out of bounds and then come

1812
01:06:05,920 --> 01:06:07,680
back in

1813
01:06:07,680 --> 01:06:09,200
that's a given model

1814
01:06:09,200 --> 01:06:10,400
but then there's a different graph

1815
01:06:10,400 --> 01:06:11,680
that's going to do something like

1816
01:06:11,680 --> 01:06:14,720
intermodal or anticipatory or have

1817
01:06:14,720 --> 01:06:18,000
memory so all of those cognitive or

1818
01:06:18,000 --> 01:06:21,119
computational features

1819
01:06:21,119 --> 01:06:23,039
license or engender

1820
01:06:23,039 --> 01:06:25,440
more complex causal models but these are

1821
01:06:25,440 --> 01:06:27,280
being sculpted

1822
01:06:27,280 --> 01:06:29,520
ab initio from nothing by the

1823
01:06:29,520 --> 01:06:32,520
statistician

1824
01:06:33,440 --> 01:06:36,319
and then we're in sort of brackish or

1825
01:06:36,319 --> 01:06:38,640
gray waters

1826
01:06:38,640 --> 01:06:40,400
when

1827
01:06:40,400 --> 01:06:41,110
we um

1828
01:06:41,110 --> 01:06:43,039
[Music]

1829
01:06:43,039 --> 01:06:44,640
juxtapose

1830
01:06:44,640 --> 01:06:46,960
the architecture of the graph

1831
01:06:46,960 --> 01:06:48,720
with the architecture of

1832
01:06:48,720 --> 01:06:51,759
some natural system

1833
01:06:54,000 --> 01:06:55,520
okay yes

1834
01:06:55,520 --> 01:06:56,480
stephen

1835
01:06:56,480 --> 01:06:58,400
yeah and you've got this and you've got

1836
01:06:58,400 --> 01:07:01,440
this excitary and inhibitory

1837
01:07:01,440 --> 01:07:04,079
dynamic going on

1838
01:07:04,079 --> 01:07:06,480
um and even though the arrows going from

1839
01:07:06,480 --> 01:07:08,960
the error down to the

1840
01:07:08,960 --> 01:07:10,480
the u

1841
01:07:10,480 --> 01:07:14,000
the there is a the the u is exciting the

1842
01:07:14,000 --> 01:07:16,400
layer above isn't it it's exciting so

1843
01:07:16,400 --> 01:07:18,079
it's almost like

1844
01:07:18,079 --> 01:07:20,319
it's like one bottom up is kind of

1845
01:07:20,319 --> 01:07:21,680
exciting

1846
01:07:21,680 --> 01:07:23,760
higher up areas and then

1847
01:07:23,760 --> 01:07:25,599
things that are further up also sort of

1848
01:07:25,599 --> 01:07:27,359
saying hey calm down calm down i can

1849
01:07:27,359 --> 01:07:28,880
reduce some of this

1850
01:07:28,880 --> 01:07:30,319
you're getting a bit out of hand here

1851
01:07:30,319 --> 01:07:32,079
you know they've only scored two goals

1852
01:07:32,079 --> 01:07:35,039
let's relax you know

1853
01:07:35,359 --> 01:07:36,960
that that

1854
01:07:36,960 --> 01:07:38,799
again i also hope this is not uh

1855
01:07:38,799 --> 01:07:39,920
inaccurate

1856
01:07:39,920 --> 01:07:43,359
it's almost like um there's a

1857
01:07:43,359 --> 01:07:46,720
suppression of error like a dampening

1858
01:07:46,720 --> 01:07:49,039
being carried forward

1859
01:07:49,039 --> 01:07:52,079
with the ultimate dampening being

1860
01:07:52,079 --> 01:07:54,160
you predict it perfectly

1861
01:07:54,160 --> 01:07:57,359
you have totally quelled all error

1862
01:07:57,359 --> 01:07:59,680
yet in real settings

1863
01:07:59,680 --> 01:08:02,400
because of just simply model

1864
01:08:02,400 --> 01:08:04,400
simplification or uncertainty in the

1865
01:08:04,400 --> 01:08:05,760
world

1866
01:08:05,760 --> 01:08:07,440
error is coming in

1867
01:08:07,440 --> 01:08:10,000
from the observables which is often what

1868
01:08:10,000 --> 01:08:12,160
we're trying to reduce our loss function

1869
01:08:12,160 --> 01:08:14,000
on and that's this whole difference

1870
01:08:14,000 --> 01:08:15,039
between

1871
01:08:15,039 --> 01:08:17,439
reinforcement learning finding oneself

1872
01:08:17,439 --> 01:08:20,238
in reinforcing or rewarding states and

1873
01:08:20,238 --> 01:08:22,640
active inference with reducing surprise

1874
01:08:22,640 --> 01:08:25,040
about outcomes

1875
01:08:25,040 --> 01:08:27,759
we're dampening error and carrying that

1876
01:08:27,759 --> 01:08:30,399
forward in the full regenerative model

1877
01:08:30,399 --> 01:08:33,520
and then also able to run it back in a

1878
01:08:33,520 --> 01:08:35,120
tractable way

1879
01:08:35,120 --> 01:08:37,040
because it's like

1880
01:08:37,040 --> 01:08:38,479
you're you're you're dampening the

1881
01:08:38,479 --> 01:08:40,158
vibration but then the vibration is

1882
01:08:40,158 --> 01:08:42,158
still entering in and you'd want that

1883
01:08:42,158 --> 01:08:44,080
vibration to be appropriately

1884
01:08:44,080 --> 01:08:47,439
distributed according to where it should

1885
01:08:47,439 --> 01:08:50,560
be okay dean and then stephen

1886
01:08:50,560 --> 01:08:51,679
yeah

1887
01:08:51,679 --> 01:08:53,839
it seems to me that the way

1888
01:08:53,839 --> 01:08:56,560
what this is what this is saying to me

1889
01:08:56,560 --> 01:08:57,679
is that

1890
01:08:57,679 --> 01:09:00,319
because of the way things are organized

1891
01:09:00,319 --> 01:09:02,319
um

1892
01:09:02,319 --> 01:09:04,600
two two things can live

1893
01:09:04,600 --> 01:09:06,880
simultaneously at once one is sort of

1894
01:09:06,880 --> 01:09:07,679
that

1895
01:09:07,679 --> 01:09:10,080
local

1896
01:09:10,080 --> 01:09:11,439
mean

1897
01:09:11,439 --> 01:09:13,439
correction and the others the more

1898
01:09:13,439 --> 01:09:15,759
generalized global

1899
01:09:15,759 --> 01:09:17,600
or

1900
01:09:17,600 --> 01:09:19,719
the other direction in the

1901
01:09:19,719 --> 01:09:21,920
bi-directionality parallel

1902
01:09:21,920 --> 01:09:22,960
of

1903
01:09:22,960 --> 01:09:25,120
of mean correction one is kind of

1904
01:09:25,120 --> 01:09:26,960
reinforced through

1905
01:09:26,960 --> 01:09:29,600
external evidence while the other one is

1906
01:09:29,600 --> 01:09:31,679
reinforced through

1907
01:09:31,679 --> 01:09:33,198
localized

1908
01:09:33,198 --> 01:09:34,399
almost almost

1909
01:09:34,399 --> 01:09:36,560
it is distributed but it's almost like

1910
01:09:36,560 --> 01:09:39,920
the ability to localize and isolate

1911
01:09:39,920 --> 01:09:42,399
if necessary so i know we've talked a

1912
01:09:42,399 --> 01:09:44,640
lot about top down and bottom up but

1913
01:09:44,640 --> 01:09:46,399
this brings a lot more

1914
01:09:46,399 --> 01:09:48,399
color in my mind

1915
01:09:48,399 --> 01:09:50,960
to some of those conversations we've had

1916
01:09:50,960 --> 01:09:52,719
before in terms of

1917
01:09:52,719 --> 01:09:54,880
you know arrows going in opposite

1918
01:09:54,880 --> 01:09:56,800
directions and it's not so much that

1919
01:09:56,800 --> 01:09:58,960
they're going in opposite directions but

1920
01:09:58,960 --> 01:10:01,040
that you can be going

1921
01:10:01,040 --> 01:10:02,719
two different directions quite literally

1922
01:10:02,719 --> 01:10:04,640
we want literally at once because of the

1923
01:10:04,640 --> 01:10:07,920
way things are set up

1924
01:10:07,920 --> 01:10:10,000
so yeah i think this this has been

1925
01:10:10,000 --> 01:10:12,239
really really helpful for me in terms of

1926
01:10:12,239 --> 01:10:13,840
not only understanding what back

1927
01:10:13,840 --> 01:10:16,960
propagand propagation is but actually in

1928
01:10:16,960 --> 01:10:20,239
sort of giving me a little bit more

1929
01:10:20,239 --> 01:10:21,840
foundational

1930
01:10:21,840 --> 01:10:23,840
ideas around again how do we turn this

1931
01:10:23,840 --> 01:10:26,800
to these sort of statistical

1932
01:10:26,800 --> 01:10:29,679
ways of representing it into

1933
01:10:29,679 --> 01:10:32,239
so i'm confused should i

1934
01:10:32,239 --> 01:10:34,719
should i go into the cafe or not i mean

1935
01:10:34,719 --> 01:10:36,800
we do not not all of us have to go to

1936
01:10:36,800 --> 01:10:38,800
that level of detail to really

1937
01:10:38,800 --> 01:10:40,640
understand what the final thing was that

1938
01:10:40,640 --> 01:10:41,679
pushed us

1939
01:10:41,679 --> 01:10:44,719
over the door threshold or not but it

1940
01:10:44,719 --> 01:10:45,920
appears that

1941
01:10:45,920 --> 01:10:47,760
it's this has been around for a while

1942
01:10:47,760 --> 01:10:48,800
and

1943
01:10:48,800 --> 01:10:50,560
being able to take that

1944
01:10:50,560 --> 01:10:53,040
if you really are kind of

1945
01:10:53,040 --> 01:10:54,480
stuck

1946
01:10:54,480 --> 01:10:56,400
because you really don't know

1947
01:10:56,400 --> 01:10:59,280
what the the parents are of your

1948
01:10:59,280 --> 01:11:00,480
current

1949
01:11:00,480 --> 01:11:02,159
action because we haven't got as you say

1950
01:11:02,159 --> 01:11:04,400
we haven't got to action yet but that's

1951
01:11:04,400 --> 01:11:06,640
the whole point there is an architecture

1952
01:11:06,640 --> 01:11:08,560
there that's going to

1953
01:11:08,560 --> 01:11:12,679
allow us to have choice

1954
01:11:14,080 --> 01:11:16,960
thanks um this minimum of two

1955
01:11:16,960 --> 01:11:18,960
um

1956
01:11:18,960 --> 01:11:20,320
comes up so

1957
01:11:20,320 --> 01:11:22,800
much so it's awesome to hear about that

1958
01:11:22,800 --> 01:11:25,440
and then to connect like expectation

1959
01:11:25,440 --> 01:11:27,040
maximization

1960
01:11:27,040 --> 01:11:29,760
and the tale of two densities

1961
01:11:29,760 --> 01:11:32,080
epistemic and pragmatic it's like

1962
01:11:32,080 --> 01:11:34,719
wherever we look there's partitions into

1963
01:11:34,719 --> 01:11:35,600
two

1964
01:11:35,600 --> 01:11:37,760
into multiplicity and unity through

1965
01:11:37,760 --> 01:11:39,040
plurality

1966
01:11:39,040 --> 01:11:41,600
and then other times even within the one

1967
01:11:41,600 --> 01:11:42,480
road

1968
01:11:42,480 --> 01:11:44,320
there's the movement in both directions

1969
01:11:44,320 --> 01:11:46,239
forward and backwards in time

1970
01:11:46,239 --> 01:11:48,560
or the forward propagation of a

1971
01:11:48,560 --> 01:11:50,000
generative model

1972
01:11:50,000 --> 01:11:52,159
which could from just one if all you

1973
01:11:52,159 --> 01:11:53,360
knew was one

1974
01:11:53,360 --> 01:11:55,840
you could simulate sevens

1975
01:11:55,840 --> 01:11:57,840
if all you knew was seven and the

1976
01:11:57,840 --> 01:12:00,000
structure of the network of course

1977
01:12:00,000 --> 01:12:02,159
you could back propagate

1978
01:12:02,159 --> 01:12:05,280
the best possible mean and error

1979
01:12:05,280 --> 01:12:07,600
estimates using

1980
01:12:07,600 --> 01:12:11,760
back propagation of error okay stephen

1981
01:12:11,760 --> 01:12:13,520
this is helpful for thinking about how

1982
01:12:13,520 --> 01:12:16,640
we perceive things as well for

1983
01:12:16,640 --> 01:12:18,320
that was dean was saying about making

1984
01:12:18,320 --> 01:12:21,040
choices it can be when we get zero error

1985
01:12:21,040 --> 01:12:24,000
or whatever seen as negligible error you

1986
01:12:24,000 --> 01:12:25,760
want to just allow that to carry on and

1987
01:12:25,760 --> 01:12:27,520
stay with your imagination so i go to

1988
01:12:27,520 --> 01:12:28,719
the bar

1989
01:12:28,719 --> 01:12:29,840
and i

1990
01:12:29,840 --> 01:12:31,600
a lot of things are the same right maybe

1991
01:12:31,600 --> 01:12:33,600
there's a happy hour sign and if that's

1992
01:12:33,600 --> 01:12:36,080
unusual maybe i'm happy about that i

1993
01:12:36,080 --> 01:12:37,199
note it

1994
01:12:37,199 --> 01:12:38,159
um

1995
01:12:38,159 --> 01:12:39,920
but if a lot of things are exactly or

1996
01:12:39,920 --> 01:12:42,719
very similar to how i expected

1997
01:12:42,719 --> 01:12:44,880
then in a way my perception is probably

1998
01:12:44,880 --> 01:12:46,800
mostly

1999
01:12:46,800 --> 01:12:48,719
my predictions

2000
01:12:48,719 --> 01:12:50,560
just not being

2001
01:12:50,560 --> 01:12:52,480
contradicted it's all they all actually

2002
01:12:52,480 --> 01:12:54,320
i just don't see it i just i think i've

2003
01:12:54,320 --> 01:12:56,880
seen it but i just don't need to see it

2004
01:12:56,880 --> 01:12:58,560
and where there's something which is

2005
01:12:58,560 --> 01:13:00,320
like ambiguous like you were saying you

2006
01:13:00,320 --> 01:13:01,840
need that number seven we're going to

2007
01:13:01,840 --> 01:13:03,920
use this diagram starts to have to be

2008
01:13:03,920 --> 01:13:05,679
looked at you know you start peering at

2009
01:13:05,679 --> 01:13:07,840
things straining their eyes

2010
01:13:07,840 --> 01:13:10,000
trying to sort of see well what's that

2011
01:13:10,000 --> 01:13:12,000
is it is it a dog is it a man running

2012
01:13:12,000 --> 01:13:13,520
into the woods is it a dog is it a man

2013
01:13:13,520 --> 01:13:14,880
running into the woods

2014
01:13:14,880 --> 01:13:16,400
um

2015
01:13:16,400 --> 01:13:19,280
you you know you start to notice

2016
01:13:19,280 --> 01:13:20,719
things so i think this is also quite

2017
01:13:20,719 --> 01:13:23,040
useful for that perspective of

2018
01:13:23,040 --> 01:13:24,880
you know when when you just you don't

2019
01:13:24,880 --> 01:13:26,719
actually need to see a lot of stuff it's

2020
01:13:26,719 --> 01:13:29,040
quite an efficient model right if it's

2021
01:13:29,040 --> 01:13:31,040
if if the area goes below a certain

2022
01:13:31,040 --> 01:13:33,600
level you just move on and carry on of

2023
01:13:33,600 --> 01:13:34,800
course that's where the challenge with

2024
01:13:34,800 --> 01:13:37,760
autism is they think because

2025
01:13:37,760 --> 01:13:39,679
too many things have been looked at that

2026
01:13:39,679 --> 01:13:42,560
are possibly negligibly

2027
01:13:42,560 --> 01:13:46,239
relevant at the time

2028
01:13:46,239 --> 01:13:48,880
okay thank you okay so just one last one

2029
01:13:48,880 --> 01:13:50,800
last thing before because i know you

2030
01:13:50,800 --> 01:13:51,679
want to

2031
01:13:51,679 --> 01:13:53,199
kind of clean this up

2032
01:13:53,199 --> 01:13:55,679
i think then one of the analogies that i

2033
01:13:55,679 --> 01:13:56,640
draw is

2034
01:13:56,640 --> 01:13:59,440
with the emphasis on the word minimum

2035
01:13:59,440 --> 01:14:02,320
two min two doesn't mean

2036
01:14:02,320 --> 01:14:04,239
it's always a you know a hard

2037
01:14:04,239 --> 01:14:06,880
bifurcation and a or a binary

2038
01:14:06,880 --> 01:14:08,719
it means that

2039
01:14:08,719 --> 01:14:10,400
the minimum amount of things like even

2040
01:14:10,400 --> 01:14:11,440
when you

2041
01:14:11,440 --> 01:14:13,280
take your shoelace and wind it through

2042
01:14:13,280 --> 01:14:15,600
all the eyes of your shoe you've got two

2043
01:14:15,600 --> 01:14:16,560
ends

2044
01:14:16,560 --> 01:14:18,320
that you eventually will loop back

2045
01:14:18,320 --> 01:14:20,880
together and and entangle in some way to

2046
01:14:20,880 --> 01:14:22,719
hold your shoe on so even though it's

2047
01:14:22,719 --> 01:14:24,400
one lace

2048
01:14:24,400 --> 01:14:26,480
i think what a lot i think what active

2049
01:14:26,480 --> 01:14:27,679
inference

2050
01:14:27,679 --> 01:14:30,080
reinforces because it's got active and

2051
01:14:30,080 --> 01:14:34,239
inference is that ability to be able to

2052
01:14:34,239 --> 01:14:35,920
see two things

2053
01:14:35,920 --> 01:14:39,280
both seemingly contradictory and both

2054
01:14:39,280 --> 01:14:41,920
actually true now it can be multiple

2055
01:14:41,920 --> 01:14:43,120
things you can have

2056
01:14:43,120 --> 01:14:44,320
multiple

2057
01:14:44,320 --> 01:14:46,800
as as you can have multiple surprises

2058
01:14:46,800 --> 01:14:49,120
some of which are make you quite happy

2059
01:14:49,120 --> 01:14:52,000
and others where

2060
01:14:52,000 --> 01:14:53,679
you walked in and said well why hasn't

2061
01:14:53,679 --> 01:14:55,360
it been happy hour at this hour when

2062
01:14:55,360 --> 01:14:57,679
i've been at the if this far on multiple

2063
01:14:57,679 --> 01:14:59,440
other days like you could be

2064
01:14:59,440 --> 01:15:01,120
disappointed in that

2065
01:15:01,120 --> 01:15:02,800
as well as being

2066
01:15:02,800 --> 01:15:05,199
pleasantly surprised so i think

2067
01:15:05,199 --> 01:15:07,520
what this again i just reinforced is the

2068
01:15:07,520 --> 01:15:09,760
the minimum

2069
01:15:09,760 --> 01:15:11,840
of two allows for the integration the

2070
01:15:11,840 --> 01:15:14,239
minimum of two recognizes the

2071
01:15:14,239 --> 01:15:16,000
differentiation and when we're talking

2072
01:15:16,000 --> 01:15:16,960
about

2073
01:15:16,960 --> 01:15:18,480
statistical issues and when we're

2074
01:15:18,480 --> 01:15:20,320
talking about errors

2075
01:15:20,320 --> 01:15:22,800
and when we're talking about

2076
01:15:22,800 --> 01:15:26,159
energy um i think

2077
01:15:26,159 --> 01:15:28,159
i think the way that they that these

2078
01:15:28,159 --> 01:15:30,560
folks have been able to discover what so

2079
01:15:30,560 --> 01:15:33,679
what architecture would allow for that

2080
01:15:33,679 --> 01:15:36,640
is what's really interesting to me now

2081
01:15:36,640 --> 01:15:38,560
because i i wasn't even thinking in

2082
01:15:38,560 --> 01:15:40,159
these sort of

2083
01:15:40,159 --> 01:15:42,080
so what's what is the

2084
01:15:42,080 --> 01:15:44,400
what does the scaffold look like

2085
01:15:44,400 --> 01:15:46,159
but it looks like there's been a lot of

2086
01:15:46,159 --> 01:15:48,719
work done in this area so

2087
01:15:48,719 --> 01:15:49,520
so

2088
01:15:49,520 --> 01:15:52,640
let's take it to action as we head into

2089
01:15:52,640 --> 01:15:54,320
our last little bit on this and of

2090
01:15:54,320 --> 01:15:56,960
course if anyone is more author or not

2091
01:15:56,960 --> 01:15:59,679
familiar with the formalisms just

2092
01:15:59,679 --> 01:16:01,440
contribute to acting flab help us

2093
01:16:01,440 --> 01:16:02,960
annotate the papers

2094
01:16:02,960 --> 01:16:04,880
and read these deeply because there's so

2095
01:16:04,880 --> 01:16:06,400
much to learn and somebody getting

2096
01:16:06,400 --> 01:16:08,800
involved like a few days or weeks

2097
01:16:08,800 --> 01:16:10,719
before these streams

2098
01:16:10,719 --> 01:16:12,560
is a leverage point if you want to help

2099
01:16:12,560 --> 01:16:15,600
other people understand this area

2100
01:16:15,600 --> 01:16:16,480
so

2101
01:16:16,480 --> 01:16:18,719
i've changed the colors just all to gray

2102
01:16:18,719 --> 01:16:20,080
because they're all just random

2103
01:16:20,080 --> 01:16:21,760
variables now

2104
01:16:21,760 --> 01:16:23,360
we had the seven so we were back

2105
01:16:23,360 --> 01:16:25,760
propagating error on temperature

2106
01:16:25,760 --> 01:16:26,960
prediction

2107
01:16:26,960 --> 01:16:29,920
but also maybe this system is predicting

2108
01:16:29,920 --> 01:16:31,600
um pressure

2109
01:16:31,600 --> 01:16:33,520
and so then three might be like

2110
01:16:33,520 --> 01:16:35,360
estimating

2111
01:16:35,360 --> 01:16:36,800
you know

2112
01:16:36,800 --> 01:16:39,920
is the water boiling

2113
01:16:41,360 --> 01:16:43,600
again just we're getting one one step

2114
01:16:43,600 --> 01:16:45,600
closer to the cafe

2115
01:16:45,600 --> 01:16:48,080
so if if we were only trying to predict

2116
01:16:48,080 --> 01:16:50,000
temperature we would back propagate

2117
01:16:50,000 --> 01:16:54,080
along the seven six three two one route

2118
01:16:54,080 --> 01:16:56,239
if we were only predicting pressure we

2119
01:16:56,239 --> 01:16:58,080
could back propagate along eight five

2120
01:16:58,080 --> 01:17:01,199
three two one

2121
01:17:01,679 --> 01:17:04,960
the fact that there's a parent

2122
01:17:04,960 --> 01:17:07,040
that is upstream

2123
01:17:07,040 --> 01:17:08,960
it's like the last common ancestor of

2124
01:17:08,960 --> 01:17:10,960
pressure and temperature

2125
01:17:10,960 --> 01:17:14,000
like we might be able to reduce um

2126
01:17:14,000 --> 01:17:18,080
these errors a lot on the temperatures

2127
01:17:18,080 --> 01:17:20,480
by having this higher order variable is

2128
01:17:20,480 --> 01:17:22,560
the water boiling and so we can imagine

2129
01:17:22,560 --> 01:17:24,000
like if the answer is yes then it's like

2130
01:17:24,000 --> 01:17:26,000
it's expecting that this is like higher

2131
01:17:26,000 --> 01:17:28,480
on both and if it's low it's lower on

2132
01:17:28,480 --> 01:17:29,360
both

2133
01:17:29,360 --> 01:17:32,080
so the generative model can go from the

2134
01:17:32,080 --> 01:17:33,920
water's boiling what pressure and

2135
01:17:33,920 --> 01:17:35,760
temperatures do i expect and you can add

2136
01:17:35,760 --> 01:17:37,520
a third node

2137
01:17:37,520 --> 01:17:39,360
it allows you to

2138
01:17:39,360 --> 01:17:42,159
condition on a cognitive structure

2139
01:17:42,159 --> 01:17:45,520
go from observations of just temperature

2140
01:17:45,520 --> 01:17:47,120
around the horn

2141
01:17:47,120 --> 01:17:48,400
to pressure

2142
01:17:48,400 --> 01:17:50,960
or from pressure and temperature

2143
01:17:50,960 --> 01:17:52,960
up to the water boiling but the

2144
01:17:52,960 --> 01:17:55,280
influence of these observations

2145
01:17:55,280 --> 01:17:56,960
is like limited

2146
01:17:56,960 --> 01:17:59,440
through this choke point

2147
01:17:59,440 --> 01:18:01,040
it's actually a markov blanket with

2148
01:18:01,040 --> 01:18:02,880
respect to what's on the either side of

2149
01:18:02,880 --> 01:18:05,040
it

2150
01:18:05,040 --> 01:18:07,679
let's bring action into the picture

2151
01:18:07,679 --> 01:18:11,360
action can also be understood as

2152
01:18:11,360 --> 01:18:13,280
parametric

2153
01:18:13,280 --> 01:18:16,640
what angle should my elbow be at

2154
01:18:16,640 --> 01:18:19,040
what angle should the eyes

2155
01:18:19,040 --> 01:18:20,159
be

2156
01:18:20,159 --> 01:18:22,239
oriented

2157
01:18:22,239 --> 01:18:24,880
those types of things again not whether

2158
01:18:24,880 --> 01:18:26,960
that's what the actual neural signaling

2159
01:18:26,960 --> 01:18:29,120
in the brain is doing but this is how we

2160
01:18:29,120 --> 01:18:32,159
model action it's like the the car how

2161
01:18:32,159 --> 01:18:35,360
many miles per hour should i be going

2162
01:18:35,360 --> 01:18:37,360
those kinds of questions

2163
01:18:37,360 --> 01:18:40,400
is parametric modeling of action

2164
01:18:40,400 --> 01:18:42,080
and that's what was so fun and exciting

2165
01:18:42,080 --> 01:18:45,920
was the first 50 equations in this paper

2166
01:18:45,920 --> 01:18:49,280
have scaffolded this tremendous general

2167
01:18:49,280 --> 01:18:52,159
node computation architecture

2168
01:18:52,159 --> 01:18:53,600
multi-level

2169
01:18:53,600 --> 01:18:56,960
means and variances forward and backward

2170
01:18:56,960 --> 01:18:58,880
up down left right

2171
01:18:58,880 --> 01:19:00,960
all of these interesting ways and

2172
01:19:00,960 --> 01:19:02,159
connections

2173
01:19:02,159 --> 01:19:04,960
but not yet action not because we hadn't

2174
01:19:04,960 --> 01:19:07,600
brought action in as a dancing partner

2175
01:19:07,600 --> 01:19:10,000
but actually this was above

2176
01:19:10,000 --> 01:19:12,719
any interpretation of the nodes as

2177
01:19:12,719 --> 01:19:14,880
inference or action

2178
01:19:14,880 --> 01:19:16,000
and then

2179
01:19:16,000 --> 01:19:19,520
it's as easy to condition on action

2180
01:19:19,520 --> 01:19:21,840
as it is to condition on any other

2181
01:19:21,840 --> 01:19:23,120
inference

2182
01:19:23,120 --> 01:19:26,000
because action is just a parameter

2183
01:19:26,000 --> 01:19:28,400
for parametric active entities that are

2184
01:19:28,400 --> 01:19:29,920
engaging in

2185
01:19:29,920 --> 01:19:32,400
action as inference planning as

2186
01:19:32,400 --> 01:19:34,159
inference and so on

2187
01:19:34,159 --> 01:19:36,400
and so then one can think about what is

2188
01:19:36,400 --> 01:19:39,199
the compute graph

2189
01:19:39,199 --> 01:19:40,880
whether it's composed of just nodes and

2190
01:19:40,880 --> 01:19:42,239
edges

2191
01:19:42,239 --> 01:19:43,679
or whether we think of some of those

2192
01:19:43,679 --> 01:19:47,600
nodes as being like variance estimators

2193
01:19:47,600 --> 01:19:51,199
and then um you know this

2194
01:19:51,199 --> 01:19:53,920
uh maybe again the connections i'm not

2195
01:19:53,920 --> 01:19:55,760
gonna rewire this whole graph

2196
01:19:55,760 --> 01:19:57,440
but just like

2197
01:19:57,440 --> 01:19:59,599
is

2198
01:19:59,840 --> 01:20:02,320
is this a water boiling

2199
01:20:02,320 --> 01:20:05,320
situation

2200
01:20:05,440 --> 01:20:06,239
okay

2201
01:20:06,239 --> 01:20:08,320
so we have a thermometer it says that

2202
01:20:08,320 --> 01:20:10,400
it's 100c

2203
01:20:10,400 --> 01:20:12,880
it's boiling temp we did the the

2204
01:20:12,880 --> 01:20:15,199
pressure sensor is broken

2205
01:20:15,199 --> 01:20:17,520
but we back propagate it

2206
01:20:17,520 --> 01:20:20,400
we're in a water we're high confidence

2207
01:20:20,400 --> 01:20:23,440
on the water boiling

2208
01:20:23,440 --> 01:20:24,639
then

2209
01:20:24,639 --> 01:20:26,159
this is like another variable that's

2210
01:20:26,159 --> 01:20:27,280
going to require like a different sort

2211
01:20:27,280 --> 01:20:29,199
of question that it's answering

2212
01:20:29,199 --> 01:20:30,880
but one can imagine

2213
01:20:30,880 --> 01:20:32,480
that if this is a water boiling

2214
01:20:32,480 --> 01:20:34,080
situation

2215
01:20:34,080 --> 01:20:36,880
and the water is not boiling

2216
01:20:36,880 --> 01:20:39,360
there might be an error

2217
01:20:39,360 --> 01:20:40,560
and so

2218
01:20:40,560 --> 01:20:43,679
how can we reduce loss function

2219
01:20:43,679 --> 01:20:46,000
on the total compute graph including

2220
01:20:46,000 --> 01:20:48,320
observation and action

2221
01:20:48,320 --> 01:20:50,639
how can we reduce uncertainty

2222
01:20:50,639 --> 01:20:52,880
about a cognitive model including

2223
01:20:52,880 --> 01:20:55,040
observation and action

2224
01:20:55,040 --> 01:20:56,880
there's two ways to do it

2225
01:20:56,880 --> 01:20:58,800
and it's how they introduce it in the

2226
01:20:58,800 --> 01:21:01,679
very um beginning of the

2227
01:21:01,679 --> 01:21:03,040
of the paper

2228
01:21:03,040 --> 01:21:04,239
which is that

2229
01:21:04,239 --> 01:21:07,040
um the minimization

2230
01:21:07,040 --> 01:21:09,120
of the loss function

2231
01:21:09,120 --> 01:21:10,560
of the free energy

2232
01:21:10,560 --> 01:21:12,320
expected free energy variational free

2233
01:21:12,320 --> 01:21:15,040
energy can be achieved in multiple ways

2234
01:21:15,040 --> 01:21:17,280
through immediate inference about the

2235
01:21:17,280 --> 01:21:18,880
hidden states the world

2236
01:21:18,880 --> 01:21:21,199
explaining perception

2237
01:21:21,199 --> 01:21:23,520
updating a global world model to make

2238
01:21:23,520 --> 01:21:24,960
better predictions

2239
01:21:24,960 --> 01:21:27,120
slower parametric inference updates that

2240
01:21:27,120 --> 01:21:30,480
have the interpretation of learning

2241
01:21:30,480 --> 01:21:31,360
and

2242
01:21:31,360 --> 01:21:33,840
when action is a variable that we have

2243
01:21:33,840 --> 01:21:35,840
agency over

2244
01:21:35,840 --> 01:21:37,760
it introduces some complexities like the

2245
01:21:37,760 --> 01:21:39,840
need to have preference and the need to

2246
01:21:39,840 --> 01:21:42,080
specify a time horizon and to have

2247
01:21:42,080 --> 01:21:44,080
uncertainty about the consequences of

2248
01:21:44,080 --> 01:21:45,679
action right wouldn't it be easy if we

2249
01:21:45,679 --> 01:21:47,760
were just watching the movie and our

2250
01:21:47,760 --> 01:21:49,920
actions didn't have any influence upon

2251
01:21:49,920 --> 01:21:51,520
the story that we saw it'd be a

2252
01:21:51,520 --> 01:21:53,520
different inference

2253
01:21:53,520 --> 01:21:55,360
and finally through action

2254
01:21:55,360 --> 01:21:57,120
to sample sensory data from the world

2255
01:21:57,120 --> 01:21:59,360
that conforms to the predictions

2256
01:21:59,360 --> 01:22:01,440
potentially providing this integrated

2257
01:22:01,440 --> 01:22:04,639
account of adaptive behavior and control

2258
01:22:04,639 --> 01:22:07,520
so it took us 50 equations

2259
01:22:07,520 --> 01:22:10,320
at the general before we could jump into

2260
01:22:10,320 --> 01:22:11,840
action

2261
01:22:11,840 --> 01:22:13,520
but it's a deflationary approach to

2262
01:22:13,520 --> 01:22:14,880
action

2263
01:22:14,880 --> 01:22:17,120
because action is a parameter

2264
01:22:17,120 --> 01:22:19,840
in a broader cognitive and computational

2265
01:22:19,840 --> 01:22:22,639
framework okay stephen

2266
01:22:22,639 --> 01:22:24,159
thanks daniel yeah that's really helpful

2267
01:22:24,159 --> 01:22:26,080
actually going back to that the example

2268
01:22:26,080 --> 01:22:27,760
with water as well

2269
01:22:27,760 --> 01:22:29,520
you can even bring in the higher level

2270
01:22:29,520 --> 01:22:31,199
of um

2271
01:22:31,199 --> 01:22:33,199
affect in the sense that one thing

2272
01:22:33,199 --> 01:22:34,800
that's really hard with water compared

2273
01:22:34,800 --> 01:22:37,120
with a lot of other things when you heat

2274
01:22:37,120 --> 01:22:39,120
up oil on stuff is you can have the

2275
01:22:39,120 --> 01:22:41,440
water boiling you probably had it and

2276
01:22:41,440 --> 01:22:42,480
and you could have a thermometer

2277
01:22:42,480 --> 01:22:45,120
theoretically saying 100 but the steam

2278
01:22:45,120 --> 01:22:47,840
can go above 100 but it's very hard to

2279
01:22:47,840 --> 01:22:48,800
really

2280
01:22:48,800 --> 01:22:50,400
it can trick you right it's like it's

2281
01:22:50,400 --> 01:22:51,920
hard to it's actually quite hard to get

2282
01:22:51,920 --> 01:22:53,360
i find it hard to get my head around

2283
01:22:53,360 --> 01:22:54,880
steam being hotter than water because

2284
01:22:54,880 --> 01:22:56,159
it's kind of

2285
01:22:56,159 --> 01:22:58,000
just kind of how i know

2286
01:22:58,000 --> 01:22:59,280
you just think of it as being 100

2287
01:22:59,280 --> 01:23:01,679
degrees water right and it's almost like

2288
01:23:01,679 --> 01:23:03,040
if you were to get into that situation

2289
01:23:03,040 --> 01:23:05,120
or after i burnt myself one time or

2290
01:23:05,120 --> 01:23:07,280
there's almost maybe i i just start to

2291
01:23:07,280 --> 01:23:09,199
have a feeling of fear

2292
01:23:09,199 --> 01:23:10,800
if i have a sense that i'm somewhere

2293
01:23:10,800 --> 01:23:11,760
where

2294
01:23:11,760 --> 01:23:13,600
what might be coming out is high

2295
01:23:13,600 --> 01:23:15,840
temperature steam right

2296
01:23:15,840 --> 01:23:18,239
um even though and that will override

2297
01:23:18,239 --> 01:23:20,400
the fact that perceptually

2298
01:23:20,400 --> 01:23:23,040
i haven't got a lot of ways to

2299
01:23:23,040 --> 01:23:24,400
easily

2300
01:23:24,400 --> 01:23:25,360
sort of

2301
01:23:25,360 --> 01:23:28,480
gauge that visually unlike say a ring

2302
01:23:28,480 --> 01:23:30,159
getting red

2303
01:23:30,159 --> 01:23:31,840
and you know

2304
01:23:31,840 --> 01:23:32,840
other

2305
01:23:32,840 --> 01:23:36,000
things okay

2306
01:23:36,000 --> 01:23:37,760
here's here's what that makes you think

2307
01:23:37,760 --> 01:23:38,480
of

2308
01:23:38,480 --> 01:23:40,000
sometimes

2309
01:23:40,000 --> 01:23:41,920
we

2310
01:23:41,920 --> 01:23:43,040
have

2311
01:23:43,040 --> 01:23:45,280
indirect cues

2312
01:23:45,280 --> 01:23:47,360
that reduce our uncertainty about

2313
01:23:47,360 --> 01:23:49,920
something that's not directly observed

2314
01:23:49,920 --> 01:23:51,920
like the mood ring if everybody was

2315
01:23:51,920 --> 01:23:53,440
wearing a mood ring

2316
01:23:53,440 --> 01:23:55,600
and that was an accurate

2317
01:23:55,600 --> 01:23:56,800
predictor

2318
01:23:56,800 --> 01:23:58,239
you know that would be this other

2319
01:23:58,239 --> 01:23:59,679
alternate world

2320
01:23:59,679 --> 01:24:01,520
and so there are certain kinds of

2321
01:24:01,520 --> 01:24:02,719
variables

2322
01:24:02,719 --> 01:24:05,840
that are more like the magical mood ring

2323
01:24:05,840 --> 01:24:07,920
or like the temperature of metal within

2324
01:24:07,920 --> 01:24:09,520
a range because i mean

2325
01:24:09,520 --> 01:24:11,360
it's only going to start to get glowing

2326
01:24:11,360 --> 01:24:13,360
when it's super super hot

2327
01:24:13,360 --> 01:24:14,960
so it doesn't help you differentiate

2328
01:24:14,960 --> 01:24:18,239
whether it's free like at 0 c or 50 c or

2329
01:24:18,239 --> 01:24:20,800
200 c probably even but there's some

2330
01:24:20,800 --> 01:24:22,080
range

2331
01:24:22,080 --> 01:24:24,560
for certain things in the world

2332
01:24:24,560 --> 01:24:26,480
where we can use

2333
01:24:26,480 --> 01:24:29,120
indirect sensory cues

2334
01:24:29,120 --> 01:24:31,360
um

2335
01:24:31,360 --> 01:24:32,800
affect is not

2336
01:24:32,800 --> 01:24:34,480
quite here

2337
01:24:34,480 --> 01:24:36,960
in this model in this graph

2338
01:24:36,960 --> 01:24:38,880
but we've talked a lot about how

2339
01:24:38,880 --> 01:24:40,320
uncertainty

2340
01:24:40,320 --> 01:24:44,159
can be understood as like anxiety and or

2341
01:24:44,159 --> 01:24:46,239
negative valence

2342
01:24:46,239 --> 01:24:49,280
in the world of reward maximization

2343
01:24:49,280 --> 01:24:52,880
less reward is bad in the reward

2344
01:24:52,880 --> 01:24:55,600
um in the world of precision

2345
01:24:55,600 --> 01:24:57,679
optimization

2346
01:24:57,679 --> 01:24:58,800
excess

2347
01:24:58,800 --> 01:25:01,520
variance is bad not any variance

2348
01:25:01,520 --> 01:25:02,880
it's not a simple

2349
01:25:02,880 --> 01:25:05,520
you know destroy the variance estimators

2350
01:25:05,520 --> 01:25:07,840
it's about the appropriate applications

2351
01:25:07,840 --> 01:25:09,280
of variance

2352
01:25:09,280 --> 01:25:11,679
but excess variance more variability

2353
01:25:11,679 --> 01:25:14,000
than expected you told me it was 10 plus

2354
01:25:14,000 --> 01:25:15,280
or minus 1.

2355
01:25:15,280 --> 01:25:17,360
but i just pulled 3

2356
01:25:17,360 --> 01:25:18,400
50

2357
01:25:18,400 --> 01:25:20,320
negative 80.

2358
01:25:20,320 --> 01:25:22,000
that's confusing it's more confusing

2359
01:25:22,000 --> 01:25:24,080
than i thought

2360
01:25:24,080 --> 01:25:26,880
so then some of these mean

2361
01:25:26,880 --> 01:25:30,080
and error estimators

2362
01:25:30,080 --> 01:25:30,960
in

2363
01:25:30,960 --> 01:25:34,880
a computational model might have

2364
01:25:34,880 --> 01:25:36,480
this could be a mean estimator on

2365
01:25:36,480 --> 01:25:37,600
valence

2366
01:25:37,600 --> 01:25:39,440
or one could choose to

2367
01:25:39,440 --> 01:25:40,480
write a paper

2368
01:25:40,480 --> 01:25:42,800
where an error estimator

2369
01:25:42,800 --> 01:25:46,000
is framed as being an anxiety parameter

2370
01:25:46,000 --> 01:25:49,280
and that's always that that that um jump

2371
01:25:49,280 --> 01:25:51,360
between what any parameter is in a

2372
01:25:51,360 --> 01:25:53,360
graphical model

2373
01:25:53,360 --> 01:25:55,120
and anything

2374
01:25:55,120 --> 01:25:58,320
about the world or attaching it to some

2375
01:25:58,320 --> 01:25:59,360
word

2376
01:25:59,360 --> 01:26:00,719
because oh it's anxiety well then that

2377
01:26:00,719 --> 01:26:02,400
makes me think of this other situation

2378
01:26:02,400 --> 01:26:04,880
but so you can send someone really

2379
01:26:04,880 --> 01:26:06,639
too easily down

2380
01:26:06,639 --> 01:26:09,440
a road of associations

2381
01:26:09,440 --> 01:26:11,199
when the deflationary perspective is

2382
01:26:11,199 --> 01:26:14,320
just stating what it is

2383
01:26:16,719 --> 01:26:18,480
um

2384
01:26:18,480 --> 01:26:20,480
okay fun didn't didn't expect that we

2385
01:26:20,480 --> 01:26:24,000
would go this way with the back prop but

2386
01:26:24,000 --> 01:26:26,239
blue mentioned it last time and and it

2387
01:26:26,239 --> 01:26:28,480
is important to uh

2388
01:26:28,480 --> 01:26:30,000
bring up and also

2389
01:26:30,000 --> 01:26:31,840
it connects

2390
01:26:31,840 --> 01:26:33,360
to modern

2391
01:26:33,360 --> 01:26:35,040
methods for training

2392
01:26:35,040 --> 01:26:37,199
neural network architectures and that's

2393
01:26:37,199 --> 01:26:39,679
what a lot of the authors research has

2394
01:26:39,679 --> 01:26:42,080
focused on so let's just continue to

2395
01:26:42,080 --> 01:26:45,440
explore action a little bit

2396
01:26:45,440 --> 01:26:47,120
they reiterate

2397
01:26:47,120 --> 01:26:47,920
that

2398
01:26:47,920 --> 01:26:50,560
when we're thinking about

2399
01:26:50,560 --> 01:26:52,800
active inference about inference

2400
01:26:52,800 --> 01:26:55,199
involving action so cybernetics control

2401
01:26:55,199 --> 01:26:56,080
theory

2402
01:26:56,080 --> 01:26:59,679
any area where some parameters represent

2403
01:26:59,679 --> 01:27:03,040
observations or latent states

2404
01:27:03,040 --> 01:27:06,480
and other parameters represent active

2405
01:27:06,480 --> 01:27:08,800
things

2406
01:27:08,800 --> 01:27:10,480
the first way that you can minimize

2407
01:27:10,480 --> 01:27:12,239
prediction error

2408
01:27:12,239 --> 01:27:13,840
is to update predictions to match

2409
01:27:13,840 --> 01:27:16,400
sensory data corresponding to perception

2410
01:27:16,400 --> 01:27:18,320
and the second is to take action and

2411
01:27:18,320 --> 01:27:19,679
earlier from the introduction of the

2412
01:27:19,679 --> 01:27:21,840
paper they kind of

2413
01:27:21,840 --> 01:27:24,400
did a little minimum of two even on this

2414
01:27:24,400 --> 01:27:27,280
which is to split out perception

2415
01:27:27,280 --> 01:27:29,760
as rapid inference

2416
01:27:29,760 --> 01:27:32,080
and learning as a slower updating but

2417
01:27:32,080 --> 01:27:33,920
we've talked about the continuity

2418
01:27:33,920 --> 01:27:36,560
between perception and learning like if

2419
01:27:36,560 --> 01:27:38,639
you're seeing the ball move across the

2420
01:27:38,639 --> 01:27:40,320
screen

2421
01:27:40,320 --> 01:27:43,040
is that perceiving the movement of the

2422
01:27:43,040 --> 01:27:44,080
ball

2423
01:27:44,080 --> 01:27:44,960
or

2424
01:27:44,960 --> 01:27:48,000
is it learning a parameter representing

2425
01:27:48,000 --> 01:27:50,080
the location of the ball

2426
01:27:50,080 --> 01:27:50,960
so

2427
01:27:50,960 --> 01:27:52,880
the whether we call something more

2428
01:27:52,880 --> 01:27:54,239
perceptual

2429
01:27:54,239 --> 01:27:57,840
or more learning oriented and and even

2430
01:27:57,840 --> 01:27:59,280
abstract learning can be seen as like

2431
01:27:59,280 --> 01:28:01,920
perception in interior spaces which has

2432
01:28:01,920 --> 01:28:04,159
been the focus of a lot of work by

2433
01:28:04,159 --> 01:28:05,520
fields 11

2434
01:28:05,520 --> 01:28:06,480
with

2435
01:28:06,480 --> 01:28:09,040
competency in navigating these abstract

2436
01:28:09,040 --> 01:28:11,120
spaces but perception sometimes brings

2437
01:28:11,120 --> 01:28:15,040
us a little bit um

2438
01:28:15,040 --> 01:28:17,920
not too close but a little bit um

2439
01:28:17,920 --> 01:28:19,760
just linguistically to like our

2440
01:28:19,760 --> 01:28:22,080
experience of perception

2441
01:28:22,080 --> 01:28:24,560
when the phenomenology and the qualia is

2442
01:28:24,560 --> 01:28:26,560
not what is in play here it's about

2443
01:28:26,560 --> 01:28:28,159
parameter updating in the model yeah

2444
01:28:28,159 --> 01:28:29,440
dean

2445
01:28:29,440 --> 01:28:31,440
do you think daniel it's about sample

2446
01:28:31,440 --> 01:28:34,320
size but sample size is related to

2447
01:28:34,320 --> 01:28:35,360
maybe the

2448
01:28:35,360 --> 01:28:37,440
the time commitment

2449
01:28:37,440 --> 01:28:39,520
like if i'm inferring something that's a

2450
01:28:39,520 --> 01:28:40,719
very very

2451
01:28:40,719 --> 01:28:41,679
short

2452
01:28:41,679 --> 01:28:42,800
volume

2453
01:28:42,800 --> 01:28:44,080
of sample

2454
01:28:44,080 --> 01:28:46,719
versus prediction which is

2455
01:28:46,719 --> 01:28:49,360
slightly or relatively

2456
01:28:49,360 --> 01:28:50,800
larger volume

2457
01:28:50,800 --> 01:28:54,320
of time commitment to move to that

2458
01:28:54,320 --> 01:28:57,600
volume and then modeling for example

2459
01:28:57,600 --> 01:28:59,520
which which

2460
01:28:59,520 --> 01:29:03,120
takes the the perception and tries to

2461
01:29:03,120 --> 01:29:05,840
um build some something material from

2462
01:29:05,840 --> 01:29:07,120
that

2463
01:29:07,120 --> 01:29:08,080
is that

2464
01:29:08,080 --> 01:29:09,600
do you think that that

2465
01:29:09,600 --> 01:29:11,360
counts here because at least that's what

2466
01:29:11,360 --> 01:29:13,280
i was

2467
01:29:13,280 --> 01:29:15,520
that's what i was telling participants

2468
01:29:15,520 --> 01:29:18,000
we had to take under consideration was

2469
01:29:18,000 --> 01:29:21,520
sort of the time factor of the sample

2470
01:29:21,520 --> 01:29:22,560
sample

2471
01:29:22,560 --> 01:29:25,840
sampling process

2472
01:29:28,400 --> 01:29:29,280
sure

2473
01:29:29,280 --> 01:29:30,639
i think um

2474
01:29:30,639 --> 01:29:32,800
if we allow inference

2475
01:29:32,800 --> 01:29:35,280
to um be just broad and including

2476
01:29:35,280 --> 01:29:37,600
everything then that's what it is but

2477
01:29:37,600 --> 01:29:40,000
yeah just in its connotation inference

2478
01:29:40,000 --> 01:29:41,679
using a model

2479
01:29:41,679 --> 01:29:43,840
often has the um

2480
01:29:43,840 --> 01:29:45,840
it's sort of like the machine is ready

2481
01:29:45,840 --> 01:29:47,760
the model is ready and we're gonna do

2482
01:29:47,760 --> 01:29:49,679
inference the new patient comes in with

2483
01:29:49,679 --> 01:29:51,760
a biometric data we're to do inference

2484
01:29:51,760 --> 01:29:52,960
using this model and we're going to

2485
01:29:52,960 --> 01:29:56,159
predict their risk of the diagnosis

2486
01:29:56,159 --> 01:29:59,360
that's the fast perceptual time frame

2487
01:29:59,360 --> 01:30:00,480
learning

2488
01:30:00,480 --> 01:30:03,760
is unless it's one-shot learning

2489
01:30:03,760 --> 01:30:06,320
is taking in multiple patients and

2490
01:30:06,320 --> 01:30:09,600
updating the parameters of those models

2491
01:30:09,600 --> 01:30:12,400
now those two stages can be alternated

2492
01:30:12,400 --> 01:30:14,960
like an expectation maximization

2493
01:30:14,960 --> 01:30:17,040
or in the tail of two densities

2494
01:30:17,040 --> 01:30:18,560
but that doesn't get away from the fact

2495
01:30:18,560 --> 01:30:20,800
that there's sort of this like one data

2496
01:30:20,800 --> 01:30:22,080
point mode

2497
01:30:22,080 --> 01:30:24,239
like plug and chug inference perception

2498
01:30:24,239 --> 01:30:25,440
mode

2499
01:30:25,440 --> 01:30:27,440
variational free energy

2500
01:30:27,440 --> 01:30:28,639
and then there's a little bit more of

2501
01:30:28,639 --> 01:30:32,000
like the updating the model parameters

2502
01:30:32,000 --> 01:30:33,760
it's like are you tuning the engine or

2503
01:30:33,760 --> 01:30:36,320
are you using the engine

2504
01:30:36,320 --> 01:30:38,320
loosely

2505
01:30:38,320 --> 01:30:40,239
in the um

2506
01:30:40,239 --> 01:30:44,080
non-action space

2507
01:30:44,080 --> 01:30:45,600
in this first

2508
01:30:45,600 --> 01:30:48,159
way to minimize prediction error those

2509
01:30:48,159 --> 01:30:50,239
given the ongoing stream of patients

2510
01:30:50,239 --> 01:30:51,760
coming to your office

2511
01:30:51,760 --> 01:30:56,080
there's two ways to reduce your surprise

2512
01:30:56,080 --> 01:30:57,920
those are the um

2513
01:30:57,920 --> 01:31:00,320
perceptual and learning

2514
01:31:00,320 --> 01:31:01,760
continuum

2515
01:31:01,760 --> 01:31:03,600
which does come down to the specifics

2516
01:31:03,600 --> 01:31:05,440
about like the sample size like you're

2517
01:31:05,440 --> 01:31:06,960
in the architecture of learning and

2518
01:31:06,960 --> 01:31:08,320
perception

2519
01:31:08,320 --> 01:31:11,120
um you could also reduce surprise

2520
01:31:11,120 --> 01:31:12,000
by

2521
01:31:12,000 --> 01:31:14,320
choosing what to sample

2522
01:31:14,320 --> 01:31:16,960
and or modifying the world

2523
01:31:16,960 --> 01:31:20,400
so that's how they bring action in

2524
01:31:20,400 --> 01:31:22,638
and

2525
01:31:23,199 --> 01:31:24,400
it's very

2526
01:31:24,400 --> 01:31:26,239
interesting to think how many

2527
01:31:26,239 --> 01:31:28,960
um pages of pros

2528
01:31:28,960 --> 01:31:31,120
i've gone into

2529
01:31:31,120 --> 01:31:33,280
wondering where action fits in and

2530
01:31:33,280 --> 01:31:35,840
there's still many more pages to go

2531
01:31:35,840 --> 01:31:37,199
in terms of

2532
01:31:37,199 --> 01:31:38,239
where does

2533
01:31:38,239 --> 01:31:41,120
formalism 51 take us

2534
01:31:41,120 --> 01:31:42,480
have we

2535
01:31:42,480 --> 01:31:44,880
um cached the check

2536
01:31:44,880 --> 01:31:47,760
of pragmatism and activism

2537
01:31:47,760 --> 01:31:49,679
extended cognition

2538
01:31:49,679 --> 01:31:52,400
and so on like what is 51

2539
01:31:52,400 --> 01:31:54,480
with respect to all the qualitative

2540
01:31:54,480 --> 01:31:55,920
insights

2541
01:31:55,920 --> 01:31:57,679
of action

2542
01:31:57,679 --> 01:32:00,000
with all of its depth

2543
01:32:00,000 --> 01:32:02,960
where what is 51

2544
01:32:02,960 --> 01:32:04,719
a short answer might be that it's like

2545
01:32:04,719 --> 01:32:07,679
the y equals mx plus b

2546
01:32:07,679 --> 01:32:09,600
with respect to all the ways that linear

2547
01:32:09,600 --> 01:32:12,560
models are used in the world this is

2548
01:32:12,560 --> 01:32:15,520
just like a sort of skeleton

2549
01:32:15,520 --> 01:32:17,520
archetype

2550
01:32:17,520 --> 01:32:20,320
that is just the trace

2551
01:32:20,320 --> 01:32:22,080
or a hint

2552
01:32:22,080 --> 01:32:24,560
for someone who then wants to analyze

2553
01:32:24,560 --> 01:32:27,120
specific actions over specific time

2554
01:32:27,120 --> 01:32:28,960
frames for specific cognitive

2555
01:32:28,960 --> 01:32:31,760
computational models but

2556
01:32:31,760 --> 01:32:35,840
that's where 51 takes us steven

2557
01:32:36,159 --> 01:32:38,000
yeah one other

2558
01:32:38,000 --> 01:32:39,520
piece that could be kind of interesting

2559
01:32:39,520 --> 01:32:42,639
to throw in there as well as

2560
01:32:42,639 --> 01:32:46,800
matching my uh the sensory data with my

2561
01:32:46,800 --> 01:32:48,159
predictions

2562
01:32:48,159 --> 01:32:51,839
i could re-imagine

2563
01:32:52,000 --> 01:32:53,760
my

2564
01:32:53,760 --> 01:32:56,480
reality

2565
01:32:56,800 --> 01:32:59,040
to explain

2566
01:32:59,040 --> 01:33:01,760
my beliefs

2567
01:33:02,239 --> 01:33:04,320
which in a way would mean i create my

2568
01:33:04,320 --> 01:33:06,800
own sensory data

2569
01:33:06,800 --> 01:33:09,840
by proxy if that makes sense which is a

2570
01:33:09,840 --> 01:33:12,159
kind of an interesting

2571
01:33:12,159 --> 01:33:13,120
slight

2572
01:33:13,120 --> 01:33:15,360
add-on to that but um

2573
01:33:15,360 --> 01:33:16,800
it's the same idea because you're not

2574
01:33:16,800 --> 01:33:18,239
strictly

2575
01:33:18,239 --> 01:33:21,199
taking action you're taking actions

2576
01:33:21,199 --> 01:33:22,719
to match sensory data but not

2577
01:33:22,719 --> 01:33:24,480
necessarily the real world sensory data

2578
01:33:24,480 --> 01:33:25,920
it could be the

2579
01:33:25,920 --> 01:33:27,679
the kind of

2580
01:33:27,679 --> 01:33:31,280
uh you know the imagined world data

2581
01:33:31,280 --> 01:33:34,159
i i am seeing an angel coming over the

2582
01:33:34,159 --> 01:33:35,600
top of

2583
01:33:35,600 --> 01:33:38,560
that hill now you know

2584
01:33:38,560 --> 01:33:41,520
yeah one could engage in um mental

2585
01:33:41,520 --> 01:33:43,440
revery

2586
01:33:43,440 --> 01:33:45,440
and it would either be reducing their

2587
01:33:45,440 --> 01:33:46,880
surprise

2588
01:33:46,880 --> 01:33:48,639
in the long run

2589
01:33:48,639 --> 01:33:49,440
or

2590
01:33:49,440 --> 01:33:51,600
that system would fail to persist in an

2591
01:33:51,600 --> 01:33:54,000
entropic world

2592
01:33:54,000 --> 01:33:56,719
and people have made

2593
01:33:56,719 --> 01:33:58,480
all kinds of arguments like in

2594
01:33:58,480 --> 01:34:00,320
evolutionary psychology

2595
01:34:00,320 --> 01:34:02,480
about the basis of why we perceive or

2596
01:34:02,480 --> 01:34:05,360
believe different things along similar

2597
01:34:05,360 --> 01:34:07,839
arguments

2598
01:34:08,080 --> 01:34:10,239
so definitely makes sense let's just

2599
01:34:10,239 --> 01:34:11,679
look a little bit

2600
01:34:11,679 --> 01:34:14,480
in 452 which we didn't um previously get

2601
01:34:14,480 --> 01:34:16,320
to but of course anyone with any other

2602
01:34:16,320 --> 01:34:18,000
like questions in the live chat welcome

2603
01:34:18,000 --> 01:34:19,840
do so

2604
01:34:19,840 --> 01:34:22,080
so

2605
01:34:22,159 --> 01:34:23,120
here

2606
01:34:23,120 --> 01:34:26,639
um in 26 live stream 26 we talked about

2607
01:34:26,639 --> 01:34:28,880
pid control we talked about integrator

2608
01:34:28,880 --> 01:34:29,920
chains

2609
01:34:29,920 --> 01:34:32,080
and about generalized coordinates of

2610
01:34:32,080 --> 01:34:33,280
motion

2611
01:34:33,280 --> 01:34:34,320
so just

2612
01:34:34,320 --> 01:34:35,360
um

2613
01:34:35,360 --> 01:34:40,000
a reminder on what 26 looked like

2614
01:34:40,000 --> 01:34:41,199
we had

2615
01:34:41,199 --> 01:34:43,280
from left to right is time these are

2616
01:34:43,280 --> 01:34:44,800
different time points

2617
01:34:44,800 --> 01:34:47,760
and then at each time point there's this

2618
01:34:47,760 --> 01:34:49,920
vector is like a stack

2619
01:34:49,920 --> 01:34:52,639
reflecting the observables

2620
01:34:52,639 --> 01:34:54,080
and then also

2621
01:34:54,080 --> 01:34:55,280
things

2622
01:34:55,280 --> 01:34:57,920
that are um latent states they're not

2623
01:34:57,920 --> 01:34:59,679
observables of the world

2624
01:34:59,679 --> 01:35:01,760
real or imagined

2625
01:35:01,760 --> 01:35:02,560
they're

2626
01:35:02,560 --> 01:35:05,600
the derivatives of how the observables

2627
01:35:05,600 --> 01:35:06,800
are changing

2628
01:35:06,800 --> 01:35:10,000
and those can be the position

2629
01:35:10,000 --> 01:35:11,520
it's like the zeroth derivative but then

2630
01:35:11,520 --> 01:35:14,320
also velocity jerk so on acceleration so

2631
01:35:14,320 --> 01:35:15,360
on

2632
01:35:15,360 --> 01:35:16,080
so

2633
01:35:16,080 --> 01:35:18,239
we looked at that in 26 but it wasn't

2634
01:35:18,239 --> 01:35:19,840
connected

2635
01:35:19,840 --> 01:35:22,400
formally to predictive processing

2636
01:35:22,400 --> 01:35:25,799
predictive coding

2637
01:35:28,960 --> 01:35:30,639
um

2638
01:35:30,639 --> 01:35:32,480
pid control

2639
01:35:32,480 --> 01:35:35,280
is restated in 53

2640
01:35:35,280 --> 01:35:37,520
using the formalisms

2641
01:35:37,520 --> 01:35:38,480
um

2642
01:35:38,480 --> 01:35:40,080
using the notation

2643
01:35:40,080 --> 01:35:42,320
that is going to prepare for the merge

2644
01:35:42,320 --> 01:35:46,080
with predictive coding like a for action

2645
01:35:46,080 --> 01:35:48,560
epsilon for errors

2646
01:35:48,560 --> 01:35:48,860
um

2647
01:35:48,860 --> 01:35:51,040
[Music]

2648
01:35:51,040 --> 01:35:53,600
and so the the

2649
01:35:53,600 --> 01:35:55,440
error term

2650
01:35:55,440 --> 01:36:01,040
is included in all of the three levels

2651
01:36:01,119 --> 01:36:02,800
to obtain the equivalence to predictive

2652
01:36:02,800 --> 01:36:04,080
coding

2653
01:36:04,080 --> 01:36:06,400
we utilize a linear identity generative

2654
01:36:06,400 --> 01:36:08,239
model with three levels of dynamical

2655
01:36:08,239 --> 01:36:10,880
orders so the joint distribution of all

2656
01:36:10,880 --> 01:36:12,880
the o's all the observables and all the

2657
01:36:12,880 --> 01:36:14,239
x's

2658
01:36:14,239 --> 01:36:15,760
through time

2659
01:36:15,760 --> 01:36:17,679
is going to be this factorized

2660
01:36:17,679 --> 01:36:19,920
expression

2661
01:36:19,920 --> 01:36:22,960
so the distribution of the observation

2662
01:36:22,960 --> 01:36:25,679
conditioned on the latent state

2663
01:36:25,679 --> 01:36:27,040
and then that

2664
01:36:27,040 --> 01:36:28,960
is

2665
01:36:28,960 --> 01:36:30,880
conditionally independent of so it

2666
01:36:30,880 --> 01:36:32,719
allows it to be factorized and

2667
01:36:32,719 --> 01:36:35,280
calculated out separately here's like

2668
01:36:35,280 --> 01:36:37,119
the first derivatives

2669
01:36:37,119 --> 01:36:39,199
second derivatives

2670
01:36:39,199 --> 01:36:41,679
with o double prime and x double prime

2671
01:36:41,679 --> 01:36:43,040
here is

2672
01:36:43,040 --> 01:36:43,840
x

2673
01:36:43,840 --> 01:36:46,480
conditioned upon its own derivative

2674
01:36:46,480 --> 01:36:48,800
the derivative of x conditioned on its

2675
01:36:48,800 --> 01:36:50,080
derivative

2676
01:36:50,080 --> 01:36:51,199
and

2677
01:36:51,199 --> 01:36:52,800
the um

2678
01:36:52,800 --> 01:36:55,520
sort of root node is the double

2679
01:36:55,520 --> 01:36:57,119
derivative of

2680
01:36:57,119 --> 01:36:58,000
x

2681
01:36:58,000 --> 01:36:59,280
because this one like stands alone

2682
01:36:59,280 --> 01:37:00,960
that's like where our model kind of taps

2683
01:37:00,960 --> 01:37:02,880
out that's equivalent to

2684
01:37:02,880 --> 01:37:04,719
node one here

2685
01:37:04,719 --> 01:37:05,520
like

2686
01:37:05,520 --> 01:37:08,320
there's no variance term leading to one

2687
01:37:08,320 --> 01:37:10,320
there could be but then that would be

2688
01:37:10,320 --> 01:37:12,880
a different model

2689
01:37:12,880 --> 01:37:17,280
so these equations in 54

2690
01:37:19,119 --> 01:37:20,719
restate

2691
01:37:20,719 --> 01:37:23,920
this dynamical model

2692
01:37:23,920 --> 01:37:26,480
and introduce

2693
01:37:26,480 --> 01:37:27,760
omega

2694
01:37:27,760 --> 01:37:30,239
which i believe would be an error term

2695
01:37:30,239 --> 01:37:31,760
this w

2696
01:37:31,760 --> 01:37:34,480
and also the muse which is the desired

2697
01:37:34,480 --> 01:37:37,440
set point for x at that order so at the

2698
01:37:37,440 --> 01:37:39,280
first second or third

2699
01:37:39,280 --> 01:37:44,880
um derivative what what is desired there

2700
01:37:45,280 --> 01:37:47,040
um

2701
01:37:47,040 --> 01:37:49,040
then that allows

2702
01:37:49,040 --> 01:37:51,679
so so this this is like a graph where

2703
01:37:51,679 --> 01:37:55,119
instead of these being different things

2704
01:37:55,119 --> 01:37:57,920
like what if what if

2705
01:37:57,920 --> 01:38:00,159
kind of mixing architectures a little

2706
01:38:00,159 --> 01:38:00,880
bit

2707
01:38:00,880 --> 01:38:02,239
because the generalized coordinates

2708
01:38:02,239 --> 01:38:04,560
doesn't have errors interleaving

2709
01:38:04,560 --> 01:38:06,000
it just has

2710
01:38:06,000 --> 01:38:07,760
the

2711
01:38:07,760 --> 01:38:09,600
state the first derivative the second

2712
01:38:09,600 --> 01:38:11,520
derivative and so on

2713
01:38:11,520 --> 01:38:13,199
rather than interleaving error terms but

2714
01:38:13,199 --> 01:38:15,520
we can imagine another similar graph

2715
01:38:15,520 --> 01:38:17,600
where as you back propagate

2716
01:38:17,600 --> 01:38:20,000
it's like higher and higher derivatives

2717
01:38:20,000 --> 01:38:23,119
that's the integrator chain

2718
01:38:23,119 --> 01:38:24,480
but

2719
01:38:24,480 --> 01:38:26,880
i guess in 55

2720
01:38:26,880 --> 01:38:31,040
56 and 57 and 58 they do something

2721
01:38:31,040 --> 01:38:33,280
similar

2722
01:38:33,280 --> 01:38:36,320
to what we had done with the generic

2723
01:38:36,320 --> 01:38:38,480
computation graph

2724
01:38:38,480 --> 01:38:40,880
or to the predictive coding architecture

2725
01:38:40,880 --> 01:38:43,440
with the interleaving of the means and

2726
01:38:43,440 --> 01:38:45,119
the errors

2727
01:38:45,119 --> 01:38:47,199
this is just that

2728
01:38:47,199 --> 01:38:49,520
on the graph architecture

2729
01:38:49,520 --> 01:38:52,000
where the nodes have this interpretation

2730
01:38:52,000 --> 01:38:53,920
of being derivatives

2731
01:38:53,920 --> 01:38:57,239
of one another

2732
01:38:59,440 --> 01:39:00,880
what is there to say that's an

2733
01:39:00,880 --> 01:39:03,119
interesting production

2734
01:39:03,119 --> 01:39:05,280
this is bringing back flashbacks to try

2735
01:39:05,280 --> 01:39:06,159
to

2736
01:39:06,159 --> 01:39:07,840
try to get my head around

2737
01:39:07,840 --> 01:39:10,719
500 level economics courses and when

2738
01:39:10,719 --> 01:39:12,800
you'd have somebody walk in and start

2739
01:39:12,800 --> 01:39:14,480
pounding stuff up on a

2740
01:39:14,480 --> 01:39:17,119
whiteboard on and you know second third

2741
01:39:17,119 --> 01:39:19,520
and fourth derivatives and just

2742
01:39:19,520 --> 01:39:21,679
just feeling like you'd been tossed into

2743
01:39:21,679 --> 01:39:23,760
a blender and you had no way of avoiding

2744
01:39:23,760 --> 01:39:25,199
the blades

2745
01:39:25,199 --> 01:39:27,760
so i'm glad i'm glad that there's people

2746
01:39:27,760 --> 01:39:29,760
that can do this stuff

2747
01:39:29,760 --> 01:39:31,679
but i would have to dedicate way more

2748
01:39:31,679 --> 01:39:34,000
time to trying to parse what the heck

2749
01:39:34,000 --> 01:39:36,480
they're talking about because

2750
01:39:36,480 --> 01:39:38,960
it i it's a wall to me

2751
01:39:38,960 --> 01:39:41,679
it's really hard

2752
01:39:41,679 --> 01:39:44,719
so yeah i i i feel you maybe for the

2753
01:39:44,719 --> 01:39:46,400
last few minutes we can kind of pull

2754
01:39:46,400 --> 01:39:48,480
back to

2755
01:39:48,480 --> 01:39:49,440
okay

2756
01:39:49,440 --> 01:39:50,800
as we

2757
01:39:50,800 --> 01:39:53,360
swoop out of this bathtub out of the dot

2758
01:39:53,360 --> 01:39:55,119
too

2759
01:39:55,119 --> 01:39:58,639
into the great beyond like

2760
01:39:58,639 --> 01:40:02,080
what have we taken with us why was this

2761
01:40:02,080 --> 01:40:03,760
lengthy journey through predictive

2762
01:40:03,760 --> 01:40:06,960
coding and the 60 formalisms and

2763
01:40:06,960 --> 01:40:09,199
what maria brought with the thousands of

2764
01:40:09,199 --> 01:40:11,920
years of philosophy and history on

2765
01:40:11,920 --> 01:40:14,080
perception so

2766
01:40:14,080 --> 01:40:15,440
where are we

2767
01:40:15,440 --> 01:40:17,440
and how are we different

2768
01:40:17,440 --> 01:40:19,679
now and going forward

2769
01:40:19,679 --> 01:40:24,080
than we were before we started 43.

2770
01:40:24,159 --> 01:40:26,639
well i'll i'll say what it what it's

2771
01:40:26,639 --> 01:40:27,840
done for me

2772
01:40:27,840 --> 01:40:29,520
first of all bringing up the historical

2773
01:40:29,520 --> 01:40:31,119
piece of it was really really helpful

2774
01:40:31,119 --> 01:40:32,000
because

2775
01:40:32,000 --> 01:40:34,000
this didn't just sort of come up

2776
01:40:34,000 --> 01:40:36,159
yesterday or in the last couple of years

2777
01:40:36,159 --> 01:40:38,159
it's been around for a while

2778
01:40:38,159 --> 01:40:40,000
i think

2779
01:40:40,000 --> 01:40:42,000
for me predictive i wouldn't have seen

2780
01:40:42,000 --> 01:40:44,239
predictive coding as a as a

2781
01:40:44,239 --> 01:40:47,280
sort of formalized way of retracing a

2782
01:40:47,280 --> 01:40:50,400
navigational route but that's what it

2783
01:40:50,400 --> 01:40:52,639
screamed to me in it and after the point

2784
01:40:52,639 --> 01:40:55,760
one i um

2785
01:40:55,760 --> 01:40:57,440
listen to you having hearing you and

2786
01:40:57,440 --> 01:40:59,440
blue talk about it

2787
01:40:59,440 --> 01:41:01,440
when the when the idea that when the

2788
01:41:01,440 --> 01:41:03,760
question around back propagation came up

2789
01:41:03,760 --> 01:41:06,239
that's when i sort of did a deeper dive

2790
01:41:06,239 --> 01:41:07,199
on that

2791
01:41:07,199 --> 01:41:10,400
and again it wasn't

2792
01:41:10,480 --> 01:41:13,920
i wasn't picking up on how to do that

2793
01:41:13,920 --> 01:41:16,840
path retracement the formalisms weren't

2794
01:41:16,840 --> 01:41:20,239
really addressing what i thought was

2795
01:41:20,239 --> 01:41:22,880
being said i think what today helped me

2796
01:41:22,880 --> 01:41:25,600
with is

2797
01:41:26,320 --> 01:41:28,480
sort of examining if you if you don't

2798
01:41:28,480 --> 01:41:31,280
have traces laid down

2799
01:41:31,280 --> 01:41:33,600
that are material that you can see if

2800
01:41:33,600 --> 01:41:36,000
you weren't actively part of the

2801
01:41:36,000 --> 01:41:37,840
building of the path

2802
01:41:37,840 --> 01:41:40,000
that there is still

2803
01:41:40,000 --> 01:41:40,880
some

2804
01:41:40,880 --> 01:41:42,560
graphical

2805
01:41:42,560 --> 01:41:44,840
statistical ways

2806
01:41:44,840 --> 01:41:46,480
of

2807
01:41:46,480 --> 01:41:48,960
organizing information to give you a

2808
01:41:48,960 --> 01:41:50,880
better sense of

2809
01:41:50,880 --> 01:41:53,119
okay so you didn't lay the breadcrumbs

2810
01:41:53,119 --> 01:41:54,000
down

2811
01:41:54,000 --> 01:41:56,000
but we can still give you a better sense

2812
01:41:56,000 --> 01:41:58,719
of where you came from

2813
01:41:58,719 --> 01:42:00,800
as a result of being able to use this

2814
01:42:00,800 --> 01:42:01,920
kind of

2815
01:42:01,920 --> 01:42:03,520
formalism

2816
01:42:03,520 --> 01:42:07,840
i mean i honestly daniel 53

2817
01:42:07,840 --> 01:42:09,840
53 come on

2818
01:42:09,840 --> 01:42:11,040
i mean if you

2819
01:42:11,040 --> 01:42:12,400
if you're one of the people that was

2820
01:42:12,400 --> 01:42:15,280
able to write those 53 out and actually

2821
01:42:15,280 --> 01:42:17,920
present it in in paper form i mean props

2822
01:42:17,920 --> 01:42:20,800
to you you get you get many

2823
01:42:20,800 --> 01:42:23,199
thank yous but

2824
01:42:23,199 --> 01:42:25,360
holy mackerel other than the fact that

2825
01:42:25,360 --> 01:42:28,000
that there is some evidence now that you

2826
01:42:28,000 --> 01:42:30,239
can retrace even though you don't have

2827
01:42:30,239 --> 01:42:32,080
necessarily those

2828
01:42:32,080 --> 01:42:34,400
markers or

2829
01:42:34,400 --> 01:42:36,639
you didn't self-correct you didn't you

2830
01:42:36,639 --> 01:42:38,880
weren't aware of how you self-corrected

2831
01:42:38,880 --> 01:42:41,520
whereas the predictive coding at least

2832
01:42:41,520 --> 01:42:43,840
gives you an opportunity to maybe trace

2833
01:42:43,840 --> 01:42:46,239
that retrace that back

2834
01:42:46,239 --> 01:42:47,840
even though you didn't spend a lot of

2835
01:42:47,840 --> 01:42:50,480
time trying to

2836
01:42:50,480 --> 01:42:52,080
organize the evidence the other thing

2837
01:42:52,080 --> 01:42:53,920
that it does is i think it reinforces

2838
01:42:53,920 --> 01:42:55,600
the idea that the way

2839
01:42:55,600 --> 01:42:57,280
that these live streams are structured

2840
01:42:57,280 --> 01:43:00,159
which is just introduce the paper just

2841
01:43:00,159 --> 01:43:03,280
give the paper its

2842
01:43:03,280 --> 01:43:06,560
its opening like open up the box

2843
01:43:06,560 --> 01:43:08,480
in the point two

2844
01:43:08,480 --> 01:43:11,360
you can actually go into one particular

2845
01:43:11,360 --> 01:43:13,840
area of the unknown which for me was the

2846
01:43:13,840 --> 01:43:15,600
back propagation which

2847
01:43:15,600 --> 01:43:16,880
you and

2848
01:43:16,880 --> 01:43:18,639
steven help me with

2849
01:43:18,639 --> 01:43:20,080
in the point two

2850
01:43:20,080 --> 01:43:24,239
we are still doing the part where

2851
01:43:24,239 --> 01:43:25,840
the point 2

2852
01:43:25,840 --> 01:43:27,600
could always even if you didn't have a

2853
01:43:27,600 --> 01:43:30,320
record of the point 1 and the dot 0

2854
01:43:30,320 --> 01:43:32,400
this paper told me that you would still

2855
01:43:32,400 --> 01:43:35,600
have some way of knowing

2856
01:43:35,600 --> 01:43:36,800
where that

2857
01:43:36,800 --> 01:43:38,800
elusive.

2858
01:43:38,800 --> 01:43:41,199
exists relative to this

2859
01:43:41,199 --> 01:43:43,840
this live stream today and again i could

2860
01:43:43,840 --> 01:43:46,560
be over i could be overfitting but i

2861
01:43:46,560 --> 01:43:48,239
don't think i am

2862
01:43:48,239 --> 01:43:50,880
otherwise why would you why would you

2863
01:43:50,880 --> 01:43:54,880
string out 53 operations

2864
01:43:57,280 --> 01:44:00,000
a lot of interesting stuff there so so

2865
01:44:00,000 --> 01:44:02,239
um

2866
01:44:02,639 --> 01:44:04,560
because this is level this is the exact

2867
01:44:04,560 --> 01:44:06,480
same i mean what we're doing in the live

2868
01:44:06,480 --> 01:44:07,840
stream and the levels that they're

2869
01:44:07,840 --> 01:44:09,679
talking about

2870
01:44:09,679 --> 01:44:12,320
they they affect each other in exactly

2871
01:44:12,320 --> 01:44:14,960
the same way it's diagrammed out here as

2872
01:44:14,960 --> 01:44:17,440
a stack and we tend to think of ours

2873
01:44:17,440 --> 01:44:18,800
because it's over

2874
01:44:18,800 --> 01:44:20,480
multiple

2875
01:44:20,480 --> 01:44:24,400
multiple days as sort of a horizontal

2876
01:44:24,400 --> 01:44:25,840
continuation

2877
01:44:25,840 --> 01:44:29,440
but they're essentially one and the same

2878
01:44:29,440 --> 01:44:33,119
oh that's that's very interesting um

2879
01:44:33,119 --> 01:44:36,560
so it's almost like

2880
01:44:36,560 --> 01:44:39,440
well there's

2881
01:44:39,440 --> 01:44:41,280
the dot zero and the one of the two they

2882
01:44:41,280 --> 01:44:44,239
can go both ways so in in the temporal

2883
01:44:44,239 --> 01:44:45,679
sense

2884
01:44:45,679 --> 01:44:48,960
the dot zero is a precursor temporally

2885
01:44:48,960 --> 01:44:50,800
it's the dot one the dot two so for the

2886
01:44:50,800 --> 01:44:52,320
for the um

2887
01:44:52,320 --> 01:44:56,000
for the uh youtube channel subscriber

2888
01:44:56,000 --> 01:44:58,719
this is their observation oh

2889
01:44:58,719 --> 01:45:03,040
43.0 oh 43.1 has been live streamed 43.2

2890
01:45:03,040 --> 01:45:04,800
has been live streamed

2891
01:45:04,800 --> 01:45:05,840
but

2892
01:45:05,840 --> 01:45:08,560
um what is like the derivative that sort

2893
01:45:08,560 --> 01:45:10,719
of sets the initial conditions for dot

2894
01:45:10,719 --> 01:45:11,920
two

2895
01:45:11,920 --> 01:45:13,520
it's the dot one

2896
01:45:13,520 --> 01:45:14,719
yeah

2897
01:45:14,719 --> 01:45:17,040
and then what of course sets for the dot

2898
01:45:17,040 --> 01:45:20,159
one dot zero

2899
01:45:20,800 --> 01:45:22,800
and so there's almost this sense in

2900
01:45:22,800 --> 01:45:24,480
which as we

2901
01:45:24,480 --> 01:45:24,790
um

2902
01:45:24,790 --> 01:45:27,040
[Music]

2903
01:45:27,040 --> 01:45:29,920
dampen our uncertainty through action

2904
01:45:29,920 --> 01:45:32,159
and inference moving forward

2905
01:45:32,159 --> 01:45:34,159
in a world that's always continually

2906
01:45:34,159 --> 01:45:38,559
vibrating and transcending our model

2907
01:45:38,880 --> 01:45:40,159
like

2908
01:45:40,159 --> 01:45:42,960
it pushes the earlier actions that we

2909
01:45:42,960 --> 01:45:46,400
take that high school teacher

2910
01:45:46,400 --> 01:45:48,719
that book that you read

2911
01:45:48,719 --> 01:45:50,960
all the way back even beyond one's own

2912
01:45:50,960 --> 01:45:52,639
corporal birth

2913
01:45:52,639 --> 01:45:54,639
as like

2914
01:45:54,639 --> 01:45:56,880
parameters that

2915
01:45:56,880 --> 01:46:00,000
dampen or specify if one doesn't want to

2916
01:46:00,000 --> 01:46:01,679
think about dampening

2917
01:46:01,679 --> 01:46:04,560
the position acceleration and velocity

2918
01:46:04,560 --> 01:46:06,000
and so on

2919
01:46:06,000 --> 01:46:09,040
um they're like higher and higher chains

2920
01:46:09,040 --> 01:46:10,639
and that means that they have like

2921
01:46:10,639 --> 01:46:12,239
they're further and further away from

2922
01:46:12,239 --> 01:46:14,159
where the rubber hits the road for the

2923
01:46:14,159 --> 01:46:16,560
youtube subscriber on the outside

2924
01:46:16,560 --> 01:46:17,920
but they're absolutely like part of the

2925
01:46:17,920 --> 01:46:22,000
process by which something comes to be

2926
01:46:23,040 --> 01:46:25,040
and then the dot two you said can exist

2927
01:46:25,040 --> 01:46:27,280
without the dot one and then then

2928
01:46:27,280 --> 01:46:28,560
the first time it made me think of like

2929
01:46:28,560 --> 01:46:30,320
the negative numbers

2930
01:46:30,320 --> 01:46:34,159
like even before the zero what is what

2931
01:46:34,159 --> 01:46:36,320
is there before zero what

2932
01:46:36,320 --> 01:46:38,840
happens before

2933
01:46:38,840 --> 01:46:42,400
zero is there a negative number

2934
01:46:42,400 --> 01:46:44,800
there's no number that's positive that's

2935
01:46:44,800 --> 01:46:45,840
smaller

2936
01:46:45,840 --> 01:46:46,560
but

2937
01:46:46,560 --> 01:46:48,800
what is is it is it a letter

2938
01:46:48,800 --> 01:46:50,080
is it a shape

2939
01:46:50,080 --> 01:46:51,520
like

2940
01:46:51,520 --> 01:46:54,000
is it its own big bang it's like and

2941
01:46:54,000 --> 01:46:55,360
there's a sense in it that it is and

2942
01:46:55,360 --> 01:46:58,000
there's a sense that it isn't

2943
01:46:58,000 --> 01:46:58,960
um

2944
01:46:58,960 --> 01:47:00,080
that's it

2945
01:47:00,080 --> 01:47:02,320
part of it's the pre-reading the other

2946
01:47:02,320 --> 01:47:04,000
thing that i think

2947
01:47:04,000 --> 01:47:06,960
maybe doesn't sort of register

2948
01:47:06,960 --> 01:47:09,520
explicitly is that

2949
01:47:09,520 --> 01:47:12,159
the error propagation in the way that we

2950
01:47:12,159 --> 01:47:15,119
do the live streams remains

2951
01:47:15,119 --> 01:47:17,040
there are some corrections and there are

2952
01:47:17,040 --> 01:47:18,560
some

2953
01:47:18,560 --> 01:47:20,639
there is a sort of a gradual movement

2954
01:47:20,639 --> 01:47:23,360
towards a bit of minimization

2955
01:47:23,360 --> 01:47:24,880
but every time we

2956
01:47:24,880 --> 01:47:25,760
we

2957
01:47:25,760 --> 01:47:28,800
come together and try to figure out

2958
01:47:28,800 --> 01:47:31,280
we don't come from a position of we

2959
01:47:31,280 --> 01:47:32,800
figured it out

2960
01:47:32,800 --> 01:47:34,800
we come from a position of well what

2961
01:47:34,800 --> 01:47:38,000
will we what will we do with this today

2962
01:47:38,000 --> 01:47:38,800
so

2963
01:47:38,800 --> 01:47:41,600
we retain that error propagation

2964
01:47:41,600 --> 01:47:44,000
and i think that that's a

2965
01:47:44,000 --> 01:47:46,000
i mean

2966
01:47:46,000 --> 01:47:48,480
that's not convention convention is why

2967
01:47:48,480 --> 01:47:50,560
would we spend time on something where

2968
01:47:50,560 --> 01:47:51,679
we leave

2969
01:47:51,679 --> 01:47:54,719
a bunch of error

2970
01:47:55,040 --> 01:47:56,400
baked in

2971
01:47:56,400 --> 01:47:58,480
but i think when when again if we're if

2972
01:47:58,480 --> 01:48:00,560
we're going to differentiate if we're

2973
01:48:00,560 --> 01:48:02,719
going to truly integrate if we're going

2974
01:48:02,719 --> 01:48:04,719
to be able to say that you can have a

2975
01:48:04,719 --> 01:48:05,920
0.2

2976
01:48:05,920 --> 01:48:08,800
existing with a without a 0.1 and a

2977
01:48:08,800 --> 01:48:10,719
point zero of course you can but how

2978
01:48:10,719 --> 01:48:13,520
superficial is that relative to

2979
01:48:13,520 --> 01:48:15,119
the method

2980
01:48:15,119 --> 01:48:17,199
because of the architecture because of

2981
01:48:17,199 --> 01:48:19,679
the way it's structured how much deeper

2982
01:48:19,679 --> 01:48:21,280
you can actually go

2983
01:48:21,280 --> 01:48:23,119
and how many times you can

2984
01:48:23,119 --> 01:48:25,600
bump into a dead end immediately find

2985
01:48:25,600 --> 01:48:28,080
out how quickly you're going or you know

2986
01:48:28,080 --> 01:48:30,159
going off the rails so to speak because

2987
01:48:30,159 --> 01:48:31,679
i can't remember which one of the live

2988
01:48:31,679 --> 01:48:33,600
streams was that you had the

2989
01:48:33,600 --> 01:48:36,639
the train moving down the track but you

2990
01:48:36,639 --> 01:48:38,960
can find out whether or not something is

2991
01:48:38,960 --> 01:48:41,280
a dead end quickly

2992
01:48:41,280 --> 01:48:43,040
and re-correct that's what that

2993
01:48:43,040 --> 01:48:44,960
retracing part today

2994
01:48:44,960 --> 01:48:46,560
i think is one of the

2995
01:48:46,560 --> 01:48:49,760
well it's it's the takeaway from this

2996
01:48:49,760 --> 01:48:52,480
this set of live streams that and i

2997
01:48:52,480 --> 01:48:54,960
wouldn't have anticipated based on the

2998
01:48:54,960 --> 01:48:56,639
title of the paper

2999
01:48:56,639 --> 01:48:58,960
that that retracement piece

3000
01:48:58,960 --> 01:49:00,480
was going to be the thing that was going

3001
01:49:00,480 --> 01:49:01,520
to sort of

3002
01:49:01,520 --> 01:49:02,719
percolate

3003
01:49:02,719 --> 01:49:05,040
and and make the most sense in terms of

3004
01:49:05,040 --> 01:49:05,840
why

3005
01:49:05,840 --> 01:49:08,000
the structure is is

3006
01:49:08,000 --> 01:49:09,760
yes there's an optimizing piece to it

3007
01:49:09,760 --> 01:49:12,159
but there's also a piece that

3008
01:49:12,159 --> 01:49:14,560
that allows for mistakes

3009
01:49:14,560 --> 01:49:16,639
without without

3010
01:49:16,639 --> 01:49:17,920
you know

3011
01:49:17,920 --> 01:49:19,920
i mean sometimes it's very consequential

3012
01:49:19,920 --> 01:49:21,440
but lots of times

3013
01:49:21,440 --> 01:49:23,760
it's the consequence is what's minimized

3014
01:49:23,760 --> 01:49:25,119
not the error

3015
01:49:25,119 --> 01:49:27,360
and i think that's what the architecture

3016
01:49:27,360 --> 01:49:29,040
affords you want to talk about

3017
01:49:29,040 --> 01:49:31,840
affordances

3018
01:49:33,920 --> 01:49:35,360
so when you said the consequence is

3019
01:49:35,360 --> 01:49:37,760
minimized and not the error that makes

3020
01:49:37,760 --> 01:49:39,599
me think about like high reliability

3021
01:49:39,599 --> 01:49:42,480
organizations

3022
01:49:42,480 --> 01:49:43,679
of course

3023
01:49:43,679 --> 01:49:45,679
one way to minimize the consequences of

3024
01:49:45,679 --> 01:49:47,920
error would be to never have errors

3025
01:49:47,920 --> 01:49:49,679
zero tolerance

3026
01:49:49,679 --> 01:49:51,440
for anything

3027
01:49:51,440 --> 01:49:53,599
but that is challenged in a world again

3028
01:49:53,599 --> 01:49:57,119
that's always throwing us um

3029
01:49:57,119 --> 01:49:58,800
challenges

3030
01:49:58,800 --> 01:50:00,000
so

3031
01:50:00,000 --> 01:50:01,840
in in um

3032
01:50:01,840 --> 01:50:03,360
in that setting it's almost like the

3033
01:50:03,360 --> 01:50:05,280
observation

3034
01:50:05,280 --> 01:50:07,119
here the one that we actually want to

3035
01:50:07,119 --> 01:50:09,440
reduce our loss function on

3036
01:50:09,440 --> 01:50:12,639
is not the um so-called proxy of error

3037
01:50:12,639 --> 01:50:13,679
occurring

3038
01:50:13,679 --> 01:50:16,880
but we could reduce our loss function on

3039
01:50:16,880 --> 01:50:18,239
function

3040
01:50:18,239 --> 01:50:20,560
on the thing working and just say we're

3041
01:50:20,560 --> 01:50:23,280
minimizing the consequences of all this

3042
01:50:23,280 --> 01:50:25,440
upstream stuff some stuff that might

3043
01:50:25,440 --> 01:50:27,440
have the interpretation of error and

3044
01:50:27,440 --> 01:50:29,440
things that might not

3045
01:50:29,440 --> 01:50:32,320
they're just nodes in this graph

3046
01:50:32,320 --> 01:50:37,080
and then what is going to dampen

3047
01:50:38,080 --> 01:50:40,960
surprise about the consequences

3048
01:50:40,960 --> 01:50:43,520
and so like if you say you know anything

3049
01:50:43,520 --> 01:50:45,679
that you say to me right now

3050
01:50:45,679 --> 01:50:46,880
uh

3051
01:50:46,880 --> 01:50:49,199
i'm going to accept it

3052
01:50:49,199 --> 01:50:51,040
and believe it

3053
01:50:51,040 --> 01:50:55,280
and then it's like in a in a trust space

3054
01:50:55,520 --> 01:50:57,520
that opens up

3055
01:50:57,520 --> 01:50:59,280
there to be

3056
01:50:59,280 --> 01:51:01,040
like

3057
01:51:01,040 --> 01:51:03,280
a communication

3058
01:51:03,280 --> 01:51:04,960
that goes deep

3059
01:51:04,960 --> 01:51:08,239
if it's being honestly said

3060
01:51:08,239 --> 01:51:09,920
and that's because like what's being

3061
01:51:09,920 --> 01:51:11,679
minimized like it don't tell me

3062
01:51:11,679 --> 01:51:13,679
something surprising

3063
01:51:13,679 --> 01:51:16,080
it's like

3064
01:51:16,560 --> 01:51:18,639
my consequence

3065
01:51:18,639 --> 01:51:20,880
you can have precision on my consequence

3066
01:51:20,880 --> 01:51:24,159
that's one direction of the conversation

3067
01:51:24,159 --> 01:51:26,400
and that is what allows that second

3068
01:51:26,400 --> 01:51:29,920
direction to really come into play

3069
01:51:29,920 --> 01:51:32,400
with the transmission of

3070
01:51:32,400 --> 01:51:34,000
variability

3071
01:51:34,000 --> 01:51:35,599
and rather than

3072
01:51:35,599 --> 01:51:37,280
well how am i going to reduce my

3073
01:51:37,280 --> 01:51:39,119
uncertainty about action relative to

3074
01:51:39,119 --> 01:51:41,280
what the person is going to tell me

3075
01:51:41,280 --> 01:51:43,040
i won't talk to them

3076
01:51:43,040 --> 01:51:46,000
or i'll tell them what to tell me

3077
01:51:46,000 --> 01:51:47,440
or um

3078
01:51:47,440 --> 01:51:49,119
i'll leave them in the dark about how

3079
01:51:49,119 --> 01:51:50,639
i'm going to act

3080
01:51:50,639 --> 01:51:52,159
and then they'll have uncertainty about

3081
01:51:52,159 --> 01:51:54,159
how i'll act if they say something even

3082
01:51:54,159 --> 01:51:55,280
trivial

3083
01:51:55,280 --> 01:51:57,280
and so i think this like really

3084
01:51:57,280 --> 01:51:58,400
it

3085
01:51:58,400 --> 01:51:59,360
it

3086
01:51:59,360 --> 01:52:03,360
spans many levels and ways here because

3087
01:52:03,360 --> 01:52:07,520
there's nested levels and deep chains

3088
01:52:07,520 --> 01:52:10,000
but i i agree i think on the more

3089
01:52:10,000 --> 01:52:11,040
topical

3090
01:52:11,040 --> 01:52:12,159
um

3091
01:52:12,159 --> 01:52:14,400
if such a thing could exist some of the

3092
01:52:14,400 --> 01:52:17,920
the takeaways that that i had also um

3093
01:52:17,920 --> 01:52:20,800
really um appreciated maria providing a

3094
01:52:20,800 --> 01:52:22,560
lot of the philosophical context and

3095
01:52:22,560 --> 01:52:25,360
then that one part where we're like

3096
01:52:25,360 --> 01:52:26,960
wasn't this a meme like thousands of

3097
01:52:26,960 --> 01:52:28,639
years ago and in many cultures in the

3098
01:52:28,639 --> 01:52:30,719
world what is it

3099
01:52:30,719 --> 01:52:32,239
that still makes

3100
01:52:32,239 --> 01:52:34,560
the predictive mind

3101
01:52:34,560 --> 01:52:36,880
and surfing uncertainty and being you

3102
01:52:36,880 --> 01:52:39,280
what makes these

3103
01:52:39,280 --> 01:52:41,920
novel and surprising

3104
01:52:41,920 --> 01:52:44,639
and even somehow counter-cultural

3105
01:52:44,639 --> 01:52:46,639
what what is happening there what chain

3106
01:52:46,639 --> 01:52:48,239
is leading to that

3107
01:52:48,239 --> 01:52:50,719
where the idea that we're generators

3108
01:52:50,719 --> 01:52:52,239
with agency

3109
01:52:52,239 --> 01:52:54,239
rather than passive receivers why is

3110
01:52:54,239 --> 01:52:55,760
that

3111
01:52:55,760 --> 01:52:58,480
such a hill to climb and die on that's

3112
01:52:58,480 --> 01:52:59,840
one piece i

3113
01:52:59,840 --> 01:53:02,560
absolutely take away

3114
01:53:02,960 --> 01:53:04,000
then

3115
01:53:04,000 --> 01:53:06,560
it was awesome with blue um

3116
01:53:06,560 --> 01:53:09,599
to work on this in the dot one

3117
01:53:09,599 --> 01:53:12,000
where we had like on the bottom left the

3118
01:53:12,000 --> 01:53:15,360
qualitative philosophical insights

3119
01:53:15,360 --> 01:53:16,560
and and

3120
01:53:16,560 --> 01:53:18,239
connecting to

3121
01:53:18,239 --> 01:53:20,719
technical and formal insights on the

3122
01:53:20,719 --> 01:53:22,320
bottom right

3123
01:53:22,320 --> 01:53:24,480
and biological systems and it's sort of

3124
01:53:24,480 --> 01:53:25,520
like

3125
01:53:25,520 --> 01:53:28,639
where are we engaging deeply with one of

3126
01:53:28,639 --> 01:53:30,480
these vertices

3127
01:53:30,480 --> 01:53:32,560
where are we engaging deeply with an

3128
01:53:32,560 --> 01:53:34,000
edge

3129
01:53:34,000 --> 01:53:36,480
where are we trying to grab two vertices

3130
01:53:36,480 --> 01:53:38,560
and the edge or

3131
01:53:38,560 --> 01:53:40,639
go around the horn or where are we

3132
01:53:40,639 --> 01:53:43,199
trying to really go for the triple play

3133
01:53:43,199 --> 01:53:44,560
um

3134
01:53:44,560 --> 01:53:46,080
every baseball

3135
01:53:46,080 --> 01:53:47,440
at home base

3136
01:53:47,440 --> 01:53:50,000
inference in action

3137
01:53:50,000 --> 01:53:50,310
um

3138
01:53:50,310 --> 01:53:51,520
[Music]

3139
01:53:51,520 --> 01:53:53,360
in the bottom of the ninth of the dot

3140
01:53:53,360 --> 01:53:54,560
two

3141
01:53:54,560 --> 01:53:56,719
it's it's a full count and it's a power

3142
01:53:56,719 --> 01:53:59,040
play

3143
01:54:00,159 --> 01:54:02,000
that and then also i think the last

3144
01:54:02,000 --> 01:54:05,360
piece that i kind of take away is just

3145
01:54:05,360 --> 01:54:06,480
when the

3146
01:54:06,480 --> 01:54:09,360
computational and cognitive framework

3147
01:54:09,360 --> 01:54:12,800
are defined generally enough

3148
01:54:12,800 --> 01:54:15,119
like at the level of a graphical network

3149
01:54:15,119 --> 01:54:16,960
which opens up message passing

3150
01:54:16,960 --> 01:54:19,280
variational inference

3151
01:54:19,280 --> 01:54:21,280
back propagation of error predictive

3152
01:54:21,280 --> 01:54:24,159
processing architectures

3153
01:54:24,159 --> 01:54:26,880
hybrids of all of these approaches

3154
01:54:26,880 --> 01:54:28,239
then

3155
01:54:28,239 --> 01:54:30,320
action

3156
01:54:30,320 --> 01:54:32,159
is deflated

3157
01:54:32,159 --> 01:54:35,440
or it's inflated maybe or whatever it is

3158
01:54:35,440 --> 01:54:37,840
that we even say it becomes composable

3159
01:54:37,840 --> 01:54:39,119
and tractable

3160
01:54:39,119 --> 01:54:40,560
to discuss

3161
01:54:40,560 --> 01:54:43,840
open-ended combinations of

3162
01:54:43,840 --> 01:54:46,320
perception cognition and action and

3163
01:54:46,320 --> 01:54:48,560
impact which is the home base in the

3164
01:54:48,560 --> 01:54:51,199
niche and so

3165
01:54:51,199 --> 01:54:53,599
if even that model has to be

3166
01:54:53,599 --> 01:54:55,520
structurally revised

3167
01:54:55,520 --> 01:54:58,159
like we end up having another

3168
01:54:58,159 --> 01:55:00,960
way of framing entity and the niche

3169
01:55:00,960 --> 01:55:03,440
interaction

3170
01:55:03,440 --> 01:55:05,119
it may fit within this framework or it

3171
01:55:05,119 --> 01:55:06,719
may necessitate revision of the

3172
01:55:06,719 --> 01:55:09,440
framework but within the entity niche

3173
01:55:09,440 --> 01:55:11,760
interaction space and the nested systems

3174
01:55:11,760 --> 01:55:13,199
and the counter factual cognitive

3175
01:55:13,199 --> 01:55:15,119
systems

3176
01:55:15,119 --> 01:55:16,840
there's almost

3177
01:55:16,840 --> 01:55:20,719
like less and less to action

3178
01:55:20,719 --> 01:55:22,639
than it seems

3179
01:55:22,639 --> 01:55:24,239
it doesn't remove the challenge of

3180
01:55:24,239 --> 01:55:25,520
action

3181
01:55:25,520 --> 01:55:26,400
it

3182
01:55:26,400 --> 01:55:28,719
it reduces something else that i'm not

3183
01:55:28,719 --> 01:55:30,800
quite sure about what it is

3184
01:55:30,800 --> 01:55:34,719
like it doesn't make it easy

3185
01:55:35,520 --> 01:55:37,360
but

3186
01:55:37,360 --> 01:55:41,119
something is being removed as we're

3187
01:55:41,119 --> 01:55:44,719
learning and working through this

3188
01:55:44,719 --> 01:55:47,920
but it doesn't make the climb

3189
01:55:47,920 --> 01:55:49,599
well it makes the climb different to

3190
01:55:49,599 --> 01:55:50,800
think differently

3191
01:55:50,800 --> 01:55:53,119
but it doesn't move doesn't mean that

3192
01:55:53,119 --> 01:55:55,119
fewer foot-pounds of force have to be

3193
01:55:55,119 --> 01:55:57,280
applied

3194
01:55:57,280 --> 01:55:58,719
but there is something different about

3195
01:55:58,719 --> 01:56:01,199
the navigation

3196
01:56:01,199 --> 01:56:04,080
around action and inference

3197
01:56:04,080 --> 01:56:07,040
via active inference

3198
01:56:07,040 --> 01:56:10,080
that i think is will continue to develop

3199
01:56:10,080 --> 01:56:12,800
for a long time

3200
01:56:13,280 --> 01:56:16,159
yeah okay dean and also stephen

3201
01:56:16,159 --> 01:56:18,800
thanks a lot

3202
01:56:18,800 --> 01:56:20,400
wasn't sure there for a second at the

3203
01:56:20,400 --> 01:56:22,639
beginning what would you gotta think but

3204
01:56:22,639 --> 01:56:25,280
i gotta thank you again daniel because

3205
01:56:25,280 --> 01:56:27,360
obviously you did understand have it

3206
01:56:27,360 --> 01:56:30,320
we'll have a reasonable understanding

3207
01:56:30,320 --> 01:56:32,400
far more than mine in terms of what that

3208
01:56:32,400 --> 01:56:34,560
back propagation implication was in

3209
01:56:34,560 --> 01:56:36,800
terms of marrying it to the predictive

3210
01:56:36,800 --> 01:56:37,920
coding so

3211
01:56:37,920 --> 01:56:39,520
didn't mean to put you into the tudor's

3212
01:56:39,520 --> 01:56:41,280
seat today but appreciate the fact that

3213
01:56:41,280 --> 01:56:42,719
you're able to

3214
01:56:42,719 --> 01:56:44,719
sort of pull it apart and then

3215
01:56:44,719 --> 01:56:46,800
put it back together in a way that made

3216
01:56:46,800 --> 01:56:48,320
a lot more sense than just reading it

3217
01:56:48,320 --> 01:56:50,320
off the page so

3218
01:56:50,320 --> 01:56:52,560
thank you sir thank you dean

3219
01:56:52,560 --> 01:56:54,800
see you later all right take care

3220
01:56:54,800 --> 01:56:57,800
bye

3221
01:57:22,880 --> 01:57:24,960
you

