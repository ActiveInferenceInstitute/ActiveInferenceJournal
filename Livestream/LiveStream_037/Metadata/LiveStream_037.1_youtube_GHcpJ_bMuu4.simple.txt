SPEAKER_03:
All right, hello, and welcome to ActInflab live stream number 37.1, Free Energy, A User's Guide.

It's February 2nd, 2022.

Two, two, 22.

20 days till the big one, of course.

Welcome to Active Inference Lab.

We are a participatory online lab that is communicating, learning, and practicing applied active inference.

You can find us at links here on this slide.

This is recorded in an archived live stream, so please provide us with feedback so we can improve our work.

All backgrounds and perspectives are welcome, and we'll be following good video etiquette for live stream.

Maybe people can raise their hand visually so there's not a little jitzy blip until we figure it out, or either way.

Go to activeinference.org if you want to learn more about participating or check the Coda link here.

okay today in 37.1 the goal is to learn and discuss and also appreciate having stephen mann the first author here with us this paper free energy a user's guide

And for this 37.1, we'll start with an introduction and then we'll just fire up some slides and hear perhaps an opening and a contextualizing statement from Stephen to be introduced last and then go into whatever questions that everyone else has brought and anyone watching live.

So I'm Daniel.

I'm a researcher in California and I will pass it to Stephen.


SPEAKER_00:
Hello, Stephen.

I'm a practice-based PhD researcher based in Toronto, and I'll pass it over to Dean.


SPEAKER_02:
Good morning, everybody.

I'm Dean.

I'm up here in Calgary.

I'm somebody who did some programming, went from being an educator to a wayfinder, and I find guides really an interesting topic to have conversations around.

I'll pass it down to Blue.


SPEAKER_05:
Hi, I'm Blue.

I'm a research consultant based out of New Mexico, and I will pass it to the first author, Stephen.


SPEAKER_01:
Hi, everyone.

I'm Stephen.

I am a philosophy PhD, currently a postdoc in the linguistics department at the University of Surrey, and a guest at the Max Planck Institute for Evolutionary Anthropology in Leipzig, where I live.


SPEAKER_03:
Alright, maybe Stephen, would you, or Stephen M, would you like to just give a little context on the paper?

Like, how did this fit into your PhD or research interests?

How did this specific collaboration come to be in the format of the paper and the way it is?


SPEAKER_01:
Sure.

Well, first, thanks for having me and thanks very much for last week's session with Dot Zero.

I think you did a really excellent job at overviewing and I'm really looking forward to talking about it today.

This paper came about because we, myself and Ross and Michael, the other authors, had been in discussions with a few other authors

around a symposium discussing active inference in the free energy principle and also predictive processing at the australian society for philosophy and psychology conference in 2018 we put together a small symposium um it went relatively well and um

After a few more months of sort of passing ideas back and forth, we approached Michael Weisberg, the editor of Biology and Philosophy, about putting together a topical collection, sort of like a special issue, but sort of collected digitally.

And eventually, sort of after sort of pitching it to him and managing to get to talk to him in person, he said that he and the other editors were quite excited.

But what they wanted was an introduction from us that would explain the mathematics and the philosophical dialectics behind sort of at the core of active inference and the free energy principle in a way that was accessible for philosophers.

And so we said, sure, we can do that.

And that was a little while ago.

We started soliciting out for papers.

We've now published most of the papers in that topical collection.

And since then, at the same time, sort of finalizing, finishing off my PhD and then moving to Europe from Australia where my PhD was, we were getting to grips with the real mathematical core of active inference and trying to figure out

what was the necessary mathematics to explain the basics of the framework, and then how to present that mathematics to a philosophical audience who has sort of some mathematical competence.

And the result is the current preprint.

So we think we're probably about one more set of revisions away from submitting for publication, and it will eventually come out as the introduction to that topical collection.

So what I'm really interested in hearing from everyone else today

uh this the same thing we're interested from hearing from the wider community which is the reason we release the preprint which is just comments and suggestions and any kind of corrections that can help improve the paper um so that its final form is sort of even better as good as we can make it okay thanks for the awesome context stephen s


SPEAKER_00:
Thank you.

Yeah, we're really enjoying this paper.

And one thing that'll be interesting to think about, even though you sort of aimed it at maybe a philosophy audience, is some of the aspects of it at this nascent kind of foundational level

could help in an applied context that may be beyond the modeling.

So we're kind of interested in some of that.

So that might be something we might tip into, even if it's not in the remit of this paper's direct publication, I think it would be really helpful in the broader sort of journey of using active inference in the world.

Awesome.


SPEAKER_03:
okay um blue or dean would you like to start with a question or we can return to one of the points that were already kind of brought up i'm good for now um okay so maybe just one starting point was just what backgrounds like

How did you go from thinking about who you wanted to make the paper accessible to, to writing it a certain way?

And then you mentioned it was for philosophers.

So what is the impact in this community that you'd like to, how would you like to update their generative models?


SPEAKER_01:
Nicely put.

First and foremost, we would like to fix in their mind the relationship between variational inference and Bayesian inference.

So I know that's something you've talked about before.

It's something that predates the free energy principle and active inference as an explanatory framework for cognitive science and biology.

And it's something which, as far as I can tell, is sort of the first step in understanding what's going on with that mathematics.

So that's the sort of the key thing we want philosophers to sort of have in their minds.

Also because almost all philosophers, especially philosophers of cognitive science, but also philosophers of biology, will be familiar with Bayesian inference, at least to some extent.

So by pointing out that what active inference is, is something sort of a step to the right of Bayesian inference, something that they can start to understand by analogy with that, we hope it will stop them from sort of getting scared of all the complicated mathematics that you can read in a lot of the papers.

So that's on the math side.

On the philosophy side, a lot of the stuff in section four of the paper was our attempt to really strip back a lot of the claims that were being made, but also sort of categorize the claims that were being made.

One thing that I noticed in reading the literature and attempting to understand it was that different kinds of claims were being conflated and

there was jumping around from claims in different domains, mathematical claims that suddenly leveraged to justify an empirical claim and then suddenly moved to an extremely general claim about all of cognitive science or all of biology in general.

So that's the second thing we want the philosophers to get, that it is possible to disentangle these claims despite the fact that they are habitually sort of conflated or not made distinct enough in the rest of the literature.


SPEAKER_03:
All right, one follow-up, and then I see Steven and Dean.

You mentioned that Bayesian inference may be more familiar, especially because it's used in all kinds of modern statistical descriptive approaches as well as generative.

Just to hear it in your own words, where do you think variational inference is more familiar?

So who does it represent who's more familiar with variational methods or who would be familiar?

And then what are the key differences


SPEAKER_01:
Sure, so my understanding is that physicists, statisticians, and machine learning practitioners

may well have come across variational inference certainly will have had a much better chance of having come across variational inference than philosophers, at least as of 2022.

What I understand variational inference to be is a certain kind of technique for choosing a probability distribution over unobserved states.

that started in physics, as I understand it, with Feynman, although I put a little footnote in the...

preprint pointing out that I haven't been able to translate the stuff in that Feynman book to the latest stuff, especially stuff that David McKay talks about in his textbook on information theory, which includes some issues in variational inference.

But as I understand it, it started in physics, then was adopted into sort of statistics more broadly as a means of approximating Bayesian inference in cases where exact Bayesian inference is too difficult to carry out, too computationally difficult.

and then moved from statistics into machine learning, where it's possible to actually build machine learning algorithms or systems that can perform variational inference.

And then from there, it ended up in the active inference framework.


SPEAKER_03:
All right, thank you.

So Dean first.


SPEAKER_02:
Stephen, thanks for joining us.

I really appreciate it.

Here's a question for you.

Now that...

an examination of the situation and the situation, as you stated, was kind of math and philosophy

have now got a relationship and we're going to out pops a guidebook or a primer.

When the pump is primed, what do you see as being the effect of that relationship between the sort of philosophical audience and the math that was used to get us to this place?


SPEAKER_01:
relationship between the philosophical audience and the math that was used to get us to this place.

I mean, first and foremost, I want the philosophical audience to gain a certain kind of facility with the maths.

I think one of you, I'm not sure who of you it was, but in the point zero, put it extremely well by saying it's like learning how the horse moves in chess.

I think it might have been Daniel, but I don't want to misattribute it to you.

Giving the philosophical audience the basic understanding of the most basic maths.

will give them that first kind of tool, which they can then go on, if they so wish, to build up and learn more of the moves, learn more of the complex maths, if they want to then go on and interrogate the rest of that literature, which is more complex.

We've tried to sort of forego too much critical analysis in the paper.

There is some in there.

We've tried to forego that a little bit just in order to get the understanding of that maths across.


SPEAKER_03:
I can follow up there.

What does it matter for the philosophers?

So what are they in your sense or their sense?

What will knowing the difference between Bayesian and variational help them evaluate?

Or what will seeing it structured this way help them evaluate?

think there's a few so i hope other people also can think of philosophical questions that knowing the difference between the two would help you change your mind on yeah i mean the simple answer is just it will help them understand what friston is claiming


SPEAKER_01:
And by Friston, of course, I'm using him as just an umbrella for anybody who's writing positively in the active inference tradition, attempting to demonstrate that the active inference framework can provide or inform certain process theories that explain cognitive or biological systems.

Philosophers need to know the difference between Bayesian inference and variational inference because they need to know what it is that Friston is claiming can be attributed to systems like this.


SPEAKER_03:
Okay.

Blue on that.


SPEAKER_06:
So I have a question and, um, like maybe I missed it and I was looking, I just did like a quick control up on the paper just to make sure that I didn't miss it.

And I'm not like misinterpreting, but, um, in your explanation of, um, the generative model, like, I just wonder why you didn't choose to.

go into the recognition model.

And I think that while you discussed at length P's and Q's, why did you leave that out?

Or do you think it's not significant?

Or did I miss it?

And did you talk about it at length?


SPEAKER_01:
So by the recognition model, I understand that to be a sort of alternative way of doing inference that an agent could employ.

So I'm saying what I understand by it so you can correct me before I try and answer the question.

I understand it to be, yeah, an alternative to generative inference is just to employ a kind of recognition model which simply takes in data and immediately produces some kind of statistical result from that data.

It doesn't need to simulate or generate its own data and then compare that to what it sees.

That would be the generative way.

Instead, it just applies some kind of, say, mathematical statistical function to the data and then gets a kind of result.

which describes what it hasn't observed.

Is that what you meant by recognition model?


SPEAKER_06:
No.

So I'm referring to the paper, The Tale of Two Densities, the 2019 paper by Bramsted et al.

And in that paper, they refer to the recognition model as the Q, right?

The inverse of the likelihood model.

It's the mapping from the consequences to

the hidden causes.

And so you got really into the maths and discussed the generative model, but just didn't acknowledge this recognition model.

And I just was curious as to why.


SPEAKER_01:
OK, so you just mean the distribution queue by the recognition model.

Am I using a different cue?

I haven't read A Tale of Two Densities, I should say.


SPEAKER_03:
The recognition model is in the kind of namespace of expectation maximization modeling.

The recognition model is like the sensory update

and then the generative part was like emphasized i hope that's not too simplified or what two densities were and then the outbound was more like associated with the generativity and that's also um that's why it's important to go from the frequentist to the bayesian at all because with bayesian generative modeling like the model can be run both ways

though it's used with different adjectives that's like variational autoencoder that's um

all these methods where it's not just descriptive modeling on a data set like principal component analysis or multiple regression it doesn't just describe then it can be used although those can be used or be thought of as bayesian like and be used in a generative way as well but that's the part that people will have less empirical experience seeing but let's think about this and then return to it next week um yeah okay so stephen s


SPEAKER_00:
Just following on from the Bayesian, which is often used in the embodied context.

People think about embodying and multisensory integration and that type of work.

And that field is a bit challenged by moving over to this variational machine learning paradigm because it's highly mathematical.

But what's interesting with active inference, it sort of comes back into...

that being grounded in embodied action, because that gives the preferences somewhere to be anchored.

So how do you see this going back into embodied cognition as a way for those preferences to be grounded?


SPEAKER_01:
That's a difficult one for me to answer in part because I'm not really part of the tradition that emphasizes embodied and inactive approaches to cognition.

The way I was taught it, they were sort of,

alternatives to the representationalist tradition and i was much more in the representationalist tradition so there has been some talk of whether and how free energy approaches support one or the other of those two traditions uh and to some extent because i'm already sympathetic to the representationalist tradition

I'm already leaning towards the idea that a free energy approach will support that, you know, as opposed to an embodied or an inactive kind of approach, which is sort of a shame because like all of those kinds of binaries, it's probably somewhat a false dichotomy.

And it just means that, you know, my direct, my attention has been directed elsewhere than your attention in looking at these issues.

And so, yeah, I don't have enough of value to add, unfortunately.


SPEAKER_03:
Yes, Stephen, one second, but our previous paper, 36, was like a taxonomy of perspectives on the representation question in FEP.

So I think we're all very primed to just take a totally open stance and

is is every possible stance for every person to focus on it's just kind of not within our time and attention capacity so i think it just speaks to um like a diverse field where of course people are focusing on chemistry of this element of that element it won't be exactly that split but

in the broadening field of active inference and FEP, there's going to be people who are focused more on one question or other.

So that's kind of cool to know where we have similar regimes of attention or not.


SPEAKER_00:
Stephen?

Yeah, I'm agreeing with Daniel.

And also, actually, we found this really, really helpful from an embodied perspective, because the way that you separated or you gave the probabilities and preferences of working together was...

it was kind of like a deflated or a more nascent form of representation.

And that jives quite nicely

with potential ways that inactive approaches are also potentially there because of the nature of preferences.

So you start to have a way where they can both live together.

Because I don't know, we were talking about this the other day, weren't we, Daniel, that it wasn't so clear how these two can live together.

And often when people who are from philosopher quote the free energy principle, they talk about early papers like 2008,

maybe 10 years ago even, and that is often then a false argument that gets painted.

So now we've almost got a new paper

which can kind of help ground those philosophers.

So I'm wondering what your thought is in terms of whether you're trying to help people use the most latest form of free energy principle when they were talking about philosophy and to stop some of the conflation of just people criticizing models which are now out of date, if that was part of your rationale for the way this paper was created.


SPEAKER_01:
Yeah, we absolutely wanted to direct people's attention to what we thought of as the real issues, in a way.

The appropriate issues.

I mean, we reckon that...

A critical assessment that is not well informed by the actual workings of the theory is not going to be helpful because you might accidentally hit on a critique that works, but only accidentally.

If you're going to criticize a framework, you better at least understand what's going on.

My worry is that it will become out of date as things change, but there's not a lot you can do about that.

I mean, it took us quite a long time to get this first draft together, to get this preprint together, and I'm sort of hoping that things haven't changed so much that it's out of date by the time it comes out.

I mean, one way to forestall that is to just be as basic as possible so that you're really capturing the core that can't possibly change.

But otherwise, your best chance is just to publish what you've got at a particular time and keep your eye on how things change and update as you go.


SPEAKER_03:
Thanks.

Yes, Dean.


SPEAKER_02:
Stephen, I use a lot of metaphors.

So if you walked into a singles bar and one of the singles was a philosopher and the other single was a mathematician.

And you had to guess now going through the process of building that guy, right?

Like you're not match.com, but right.

You have to make a guess as to whether that long-term relationship, they walk out hand in hand or they're completely repulsed by one another.

I know it always depends, but you're talking about updating the guide.

I'm kind of want to go back one previous step.

What keeps them together?

What pulls them apart?


SPEAKER_01:
Yeah, so how do you write what is essentially a philosophy paper but include mathematics in a way that does justice to both is roughly how I'm hearing that question.


SPEAKER_02:
Well, a long-term relationship, right?

Like, they've still got to have some compatibility.

Compatibility, right.

And Steven Sillard's point was...

Up to now, it's been, I don't know if I even want to go to the bar.

So that's what I'm asking you now, based on what you've journeyed into, right?

Because not everybody... I appreciate the idea of the guidebook because not everybody goes into situations...

Freely, right?

Sometimes you get dropped into situations and it's a little bit more intense.

But what causes people to go freely into that kind of relationship and sustain it over a long enough period that it does make sense?

It doesn't remain kind of a superficial thing or just a concept, but it actually becomes realized.

I was curious what your thoughts on that are.


SPEAKER_01:
Yeah.

I think that, you know, trying hard not to repeat myself too much.

The way I try to think about that question is to try and think about what has prevented philosophers from really accessing the mathematical parts of active inference so far.

And that's just from sort of communicating with philosophers and talking to them and hearing their dissatisfaction with it.

And it was always just that there was too much of it too fast.

And so the, the sort of the only approach we could see that could remedy that was to go as slow as possible in a way.

Uh, and so spend sort of have a much heavier, racier ratio of words to equations in a way, and go into much, much more depth in explaining each equation as it comes along.

rather than throwing all in at once and then decomposing it.

I mean, one of the earlier versions of the draft, we started with the main equations and then decomposed them.

In the current draft that you've read, we start with the components and then build up to the main equation.

That was a little bit risky, I thought, because I was worried that people would feel we were holding the main event back for too long.

But...

So far, it seems to be working, I'll say.

I'd be interested to hear your thoughts on that approach, whether you think that meshes together well enough.


SPEAKER_02:
Yeah, no, that's one of the things.

And again, I don't think mathematicians are trying to be pushy.

But if you don't have that context, it can feel pushy.

And so how long you're willing to leave something open before you drop the big question is sometimes easier for somebody then to size the situation up and contextualize it.

So in this delivery, I don't know previous versions, right?

But in this delivery, in that respect, I actually think it makes it easier


SPEAKER_00:
less intimidating but that's just my that's my personal opinion sorry steven i know you wanted to say something steven yeah just carrying on from what dean was saying as well is um you you looked at the inference model

almost prior to having a Markov blanket.

And I thought that was quite useful.

And one thing that made me think as I was reading it, and I'd be interested in your thoughts, is it helps with this idea of really thinking about how are we going to create the blanket?

When does the blanket come into play?

And what assumptions are there about the blanket?

And in some ways,

it's easy to pick up a pre-built idea of what blankets are and then model off that, whereas it's like, okay, well, let's question that.

And that actually could be useful at a more heuristic level, you know, for other fields of practice.

So I'd be interested in your thoughts about what you think your motivation for that and also maybe the sort of surprising or unsurprising outcomes of not going straight for the blanket.


SPEAKER_01:
Well, one of the big revelations for me in researching this paper was that you can talk about variational inference and you can talk about minimizing expected free energy without talking about Markov blankets.

I had sort of come into this with just sort of a huge deluge of literature from the active inference tradition, lots and lots of like keywords,

Well, what could more uncharitably be called buzzwords like Markov blanket and non-equilibrium steady states and things like this?

And it was a concern that I would first have to understand statistical physics and fluid dynamics before I could understand the claims that were being made about inference.

But looking back into the history and you realize that, first of all, variational inference.

is a precursor to active inference.

So you can think about variational inference in its own little bubble as we have it in its own little section.

And then the sort of next step, which is novel and is quite excitingly novel, which is minimizing expected free energy, can also be construed just in terms of decision theory.

You don't, as far as I can see, you don't have to think or talk about Markov blankets at all to talk about decision theory as

minimizing expected free energy.

So the reason why we separated them was because they're separable.

The reason why we put those two first variational inference and expected minimizing expected free energy is because I think they are simpler and easy to grasp.

And we were trying to start from the simple and build up to the more complex.

It's, I think it's definitely true that the most sort of intriguing and possibly the most sort of difficult part of understanding this whole idea

system which friston is building is understanding the things to do with markup blankets in real like physical situations um but

what I'm sort of interested in now to give you a preview of what I'm like thinking about next.

The thing which I'm more optimistic about being able to make headway on is investigating minimizing expected free energy as a decision theory.

That sort of gets the middle ground between, it's not just something that prefigured active inference as variational inference did.

It's not something that seems to require a very large amount of mathematical understanding as the Markov blanket stuff does seem to, to me.

It's something which is claimed to be a certain way of approaching decision theory.

Decision theory is sort of a philosophical sort of technical term or statistical term.

So it's that nice middle ground between novel but understandable, which is why the thing that I'm sort of most interested in investigating next is the expected free energy approach.

And again, I don't think you need to talk about Markov blankets to talk about that.


SPEAKER_03:
okay thanks for sharing that one thought on where the Markov blanket comes in so you said that variational inference and the minimization of expected free energy in the context of a paper that was structurally laid out with first perception and then introducing action into the loop so it kind of

fits this perception of case as like action affordances are not possible and so that's the special case the more general case is when action can come into play that whole realm of action theory decision theory game theory cybernetics signal processing none of that it was said requires the markov blanket formalism

I'd like to maybe add that there may be a weak sense requirement, like in the sense that on a Bayesian graph or using Bayesian methods, using Perl 1988 version of the Markov blanket, there are Markov blankets in the machinery of these Bayesian methods, because there are variables that are isolated or conditioned on each other.

so that's like the trivial markov blanket the non-contentious one that people are not spending a lot of time and attention on that um and then part of the unknown or at least less clear is the action and perception

interpretation or concordance that fristen has introduced kind of taking the unitypal markov blanket concept and splitting it into like an incoming sense state dependency and an outgoing action state and then none of that gives a clear action perception topology which is why we've seen like around the clock and then with the ones like action and sense are connected and backwards arrows so

There's the part about the partitioning of the Markov blanket and then taking something that's kind of a trivial consequence of statistical models and then tying it to potentially realism in the strong cases, like people saying Markov blankets as defining things.

And then even just within the formalism, how do you go from, how do you ramp up the meaning of this Markov or does it need to even be that way?

which is kind of related to this question which I'll ask and then anyone can give a thought like you talked about necessary and sufficient so is this some of the necessary and sufficient pieces of FEP what is what is necessary like what's the kernel that everything else can continue to elaborate around

What section and page number, please?


SPEAKER_01:
Well, you'll notice that we were cheeky in defining three distinct free energy principles, probably none of which would be assented to by the actual proponents of the free energy principle.

Yeah, exactly.


SPEAKER_03:
Could you go through and just describe in a few sentences or just what is each one of these, the three free energy principles, inference, action, selection, what did they mean to you?


SPEAKER_01:
First one, free energy principle for inference, as we've defined it, is when updating your... Sorry, my cat is biting me.

Ow.


UNKNOWN:
Sorry.


SPEAKER_01:
I'll hold him up here so he doesn't bite me.

Well, the short version is choose Q by minimizing F. So choose your beliefs about hidden states by minimizing variational free energy.

So that's a principle in the sense that philosophers would call a normative principle.

It's a command for how to act.

In this case, the specific kind of action that is how to choose your beliefs.


SPEAKER_03:
Okay.


SPEAKER_01:
And free energy principle for action, also a normative principle telling you how to act.

And this one is, again, in our terminology, choose Z by minimizing G. So choose your action by minimizing its expected free energy.

this is all for anybody who's watching this who hasn't looked at the paper we've tried to sort of describe um in very slow but understandable way what what these different sort of letters are standing for uh let me give the definitions for a discrete case okay so we have perceptual inference


SPEAKER_03:
Bayesian expectation maximization like.

Choose Q, the member of the variational family distribution, by minimizing this snapshot F based upon your priors, basically, and new information coming in.

And then that takes on a normative interpretation.

It's kind of like saying, if you were doing linear regression, you would do the L2 norm least squares.

If you're doing this type of regression,

then do this kind of inference the second one is also normative but it's action theoretic because you introduced action and then that introduced the elaboration on f to the g function um maybe stephen s how would you say that this movement into the future first matters for maybe not necessarily how a philosopher but how um

any other relevant area might see this in an applied context.

Like what does the F to G movement have to do?


SPEAKER_00:
Well, I think it's, I think what's useful is that it's like, it's almost taking what's evolved out with a Markov blanket with the expected free energy and bringing it back down into a more

a form which isn't only a form which is involved in the modelling out of particular systems at low dimensionality.

It's coming in and saying, okay, this is a broader principle that can be talked about.

And I think that then ties into some of the stuff the Active Inference Lab is trying to look at.

So how can active inference itself be used as a way to think of organising and structuring our lives, like George Parekh might have thought about it, and how

Can it be used as a heuristic in areas like coaching psychology, in areas where you're looking at action-orientated decision support in complex, evolving ways?

So you can't model it.

the in the traditional sense of a market because there's nowhere near the dimensionality can be approached so what's useful is they say okay look we've got these general ideas we've got a route to it but that this the general deflated forms of that actually then because they're not so high order and they're not so

nailed down to one idea of a Markov blanket maybe has a more universal application when someone's trying to look at complex contexts and how to act in the world.

So I don't know what your thoughts on that, but that's what I'm very interested in is this idea between sort of

diagnostic kind of syndrome-based psychology and how do we look at actually what's going on in a context look at the the symptoms look at the context unfolding and work on modeling using our own apparatus as dialogical sort of collaborative human beings


SPEAKER_03:
steven uh uh dean first and then steven m if you want to give a thought on that and we're just going to talk about this inference and action piece because i think there's a few more pieces to draw out and then we'll get to the third selection but dean go for it


SPEAKER_02:
Yeah, so back to my strange twisted metaphor.

So now all of a sudden the philosopher walks into the bar, and instead of one math showing up, we'll call it the geometry, which is much more amenable to the model in terms of how a philosopher might walk into a space and see the geometry first.

All of a sudden there's two maths.

There's a statistical math that's showed up at the same time.

Are they twins?

What's going on here?

And I think that's where the guide is kind of handy because if you first walk into the space, I'm not arguing that a Markov blanket exists.

I think relationship matters.

But I think what most people that walk into that bar

don't realize is that you're walking in on two different maths and they're both showing up at the same time when you were expecting one.

You were expecting to be able to work with a model.

which is, as I said, it's far more proximal to the geometry math than to the statistical one.

And so I think that again, when we're talking about guides, I don't have to, I can put my hand in the ocean and figure out what the current is, and I can look up at the stars and figure out where I am in that invariant space.

I don't necessarily have to have a laptop

with the statistical distribution.

I mean, that might help, but that's not a tool that I need at first hand.

Whereas I think the modeling part, which is what you were trying to bring up with this guide, is at hand.

And so it's the availability piece that I think philosophers are trying to

What did I walk into here?

That's essentially what am I walking into and what is the betweenness of those two types of math that they're probably, if they're like me, but I'm not a philosopher, they're asking when they're being introduced to this.

So I'm just curious, again, if I'm going way off on a tangent or if we're introducing something, we actually know what we're being introduced to.

And that's the part where Stephen Hughes talked about slowing down.

Because I really agree.

It's not a breaking down.

It's an actual slow down.

Nothing wrong with that.

Whoa.


SPEAKER_01:
I mean, I could try and approach an answer by sort of extending your metaphor if you'll give me license to do so.

Imagine you're going to the bar and there's dozens or even hundreds of people

Maths or different components of maths or different approaches to maths.

And what you'd really like is some way of pairing that down to something that is approachable.

You know that only a few of these will be approachable, but you don't know which ahead of time.

I'd like to think that you could use what we've written as at least the first step to pairing some of that away.

So what we've left out essentially is the stuff that you could pair away and say, I can't approach that yet.

What I know I can approach is these first few things.

And what I like to think is that we've...

done okay at getting at least some of those first few things in there.

You know, not too much, not too little.

It's really trying to find that Goldilocks zone.

And those will be the ones that are approachable, even, you know, approachable for a philosopher.

who's met very little maths before.

I know I owe Stephen S a response to your earlier question as well, but if you want to go ahead first, Stephen, or Daniel, you'd say what?


SPEAKER_00:
Yeah, Stephen S, go for it.

Yeah, I was just saying, maybe bring up slide 13 if you're able to, Daniel, because that might be a useful one.

Yep.

Just as it has.

I have it.

Yeah.

Because that's got a little bit there about the penalty for overfitting, penalty for failing to explain the data.

And that has...

Oh, is it?

Oh, wait a sec.

Maybe I'm looking at the numbers at the bottom.

Okay.

But on page 23 or slide 35 here.


SPEAKER_03:
Yeah.

Yeah.


SPEAKER_00:
Okay.

Yeah.

Slide 21.

Yes.

Yeah.


SPEAKER_03:
This definitely juxtaposes the F and the G.

it's like a Pokemon evolution, but it includes those different pieces about bringing in action with the uncertainty on the consequences of action and the fundamental and the ability to impact it.

But that was actually what I had kind of written down.

So Steven made the point about how action is a lower dimensional space.

And that's like,

making an algorithm tractable like conditioning inference on action which is something that's very different structurally than a lot of other control theory where the target of inference is a policy selection here the affordances play a little bit of an upstream role and they make the downstream calculation conditioned on action so that speaks to a different embeddedness of action in active inference and then

a few other things but first stephen m what would you what was the answer that you owed the other stephen


SPEAKER_01:
Yeah, I mean, I was really just picking up on the point that Stephen made about the difficulty of accurately modeling.

And we talk about this a lot in the philosophy of science.

I mean, in the philosophy of any of the special sciences, but in the sort of philosophy of science more broadly, one of the biggest topics is modeling.

And one of the biggest questions is how...

how do you trade off between getting a model which is a perfectly accurate representation of the thing that you are modeling versus something that is tractable and that you can handle.

And the analogy is always made with maps.

That's sort of the first analogy.

You can't have a map that is an exact replica of its territory because you wouldn't be able to use it to navigate.

It could not provide you

with anything that was more helpful than the territory itself.

So we have some kind of practical knowledge of how to make maps.

We know what to leave out.

We know how to condense it.

We should at least shrink it, usually, if we're creating a map from a territory.

What we don't really have

in a very general sense across all of science, is a set of principles for how, given a specific situation that is too complex to produce a perfect representation of, what ought you leave out and what ought you keep in, and how should you transform that space into a representation of that space in order to produce a representation that is a useful approximation of it.

So the question coming, you know, back to the formalism would be, how do you choose a kind of a Q distribution, your approximate distribution, the thing that you're going to harbor in your brain and believe that throws out enough of the useless stuff of the real world, but keeps in enough of the stuff that you really need to keep in, in the world.

This is sort of the, one of the big questions in philosophy of science and I guess science proper at like the early 21st century.

Hmm.


SPEAKER_03:
Awesome answer.

Thank you, Dean.

And then Blue.


SPEAKER_02:
Yeah, just real quick.

So, Daniel, when Daniel talked in the point one about the third P, but he called it the P-H-I-T-N-E-S-S, the fitness.

That's what basically you're describing.

How do we take that fitness?

variance field and collapse it down to something more tractable as you said.

And so at some point later on, either later on today or in our next live stream, I think that's what the active inference model, which is not a map,

And it has probably two parts.

It has a frame, but it also has a filtering effect.

Maybe we can talk a little bit about that because that's what the fitness is really about.

So I'm looking forward to sort of diving a little bit deeper on that because it's not just a back and forth across and reaching edges.

It's actually going deeper into it and then returning from.

So, yeah, I'm kind of looking forward to that from a mathematical standpoint as well.


SPEAKER_03:
Thanks, Dean.

Blue?


SPEAKER_06:
So that's a perfect segue, fitness, into what I was going to bring up.

And so, Stephen, something that you mentioned earlier is your attempt to capture the essence of the FEP and the things that will not change and kind of build slowly, incrementally.

And so...

if we have a theory that does not change, essentially like does not evolve, it will die.

Like it will become extinct because we're constantly learning new things.

And so, I mean, I think I like from a counterpoint think that it's kind of critical to capture the evolution of the FEP over time because

it really changes the potential applications and ways that people interpret the principle and the theory of active inference also.

And so if it doesn't change, I mean, will it not ever change?

Or is it subject to change?

Or just what are your thoughts on that?

Like, is it totally inflexible, these points that you've attempted to lay out?


SPEAKER_01:
No, I mean, yeah, that general point is very well taken indeed.

I guess I think that by trying to capture something that we thought wouldn't change, I think we meant or I should have said we're trying to capture the parts of it that the rest of the framework will continue to depend on

for sort of as long as possible.

We've tried to keep the most stable parts of it without necessarily implying that active inference could survive without these mathematical components, but just that

The change to the theory or the change to the approach would have to be so radical once you'd got rid of these core mathematical components that someone could legitimately ask, is it still the same theory?

So that's roughly what I would mean by essential such that.

If, for example, tomorrow, Friston were to say, we don't need to talk about variational inference anymore, or we don't need to talk about minimizing expected free energy anymore.

Someone could legitimately ask, okay, is he now talking about a new theory that's no longer active inference?

Is it so different because he's thrown out that sort of fundamental part that he's now actually proposing something completely different?

I think that someone could legitimately ask that question.

I think that a reasonable person could say that he's now talking about a different theory because I think that those mathematical parts are so crucial to it, as opposed to some of the other parts, which seem, some of the more complex parts seem more dispensable.

You could throw out some of the more complex things, keep these more basic things, and you would still more likely be having the same theory.


SPEAKER_03:
Yablou?


SPEAKER_06:
So just to respond quickly, so for me, that's kind of an arbitrary line in the sand.

And one thing that we've talked about back and forth a lot is this concept of ergodicity and an ergodic system versus a non-equilibrium steady state density, locally ergodic.

What does it mean?

And if we throw out ergodicity and eliminate this requirement, is the theory still the same theory?

And so that's one point, but I mean, there are many points in the minimization of free energy and so on and so forth.

And so as we add on to the theory,

we are changing the theory all the time.

Like as new papers come out, like the recognition model versus the generative model and, you know, Bayesian mechanics for stationary processes was kind of really highlighting a couple of key points, but as the theory goes and changes,

It's like at any point we could say, well, that's not the same theory.

And so if the theory is not allowed to evolve over time, like it's just this arbitrary point in the sand that we don't want to cross, like the minimization of free energy.

What if we decided that the minimization of free energy means something totally different?

Like even in this paper, I mean, you had in a footnote about the complexity versus accuracy, but to refer to free energy as inaccuracy is like,

I've not heard of it described that way before.

And so for me, I mean, it is this complexity and accuracy and I understand like the, um, the way that you framed it, but it's a completely like novel way to talk about free energy.

Like I always hear about as here, here it's been framed in terms of like uncertainty or surprise, but not in accuracy.

Like that was completely.

like caught, took me off guard actually.

So, I mean, as the theory evolves, like, I don't know, it's just, what are the, what's the irreducible component of the FPP?

Like does such a thing exist or is it just turtles the whole way down?


SPEAKER_01:
Yeah, you're asking me the really hard questions.

I like this because it's tough.

It's really tough to think.

It's honestly, yeah, it's tough to think and answer that and to ensure that I'm answering sort of honestly as to what I really believe as opposed to just trying to sort of dismiss what you say.

You know, I'm not trying to dismiss what you say.

I do think...

that the line is blurry, so it's not clear and distinct.

I don't think that it's arbitrary.

I might be wrong in that, but I don't believe that it's arbitrary.

Let me just leave to the side for a moment the description of free energy as inaccuracy.

I'll come back to that, because I'm interested in picking up what you think about the different interpretations of the function f. But I'll try and go back to the idea of herbicity.

Yeah, there's a sense in which things are still being worked out.

And one of the things we put in the paper is something that we were urged to make clear, which is that active inference is a work in progress.

Even the sort of mathematical underpinnings are still being worked

fleshed out in a sense or still being put together in a way that helps connect the different parts of the theory okay that's okay that that in fact was a little bit difficult for me to swallow at first because i felt that if that's true then it doesn't legitimate all of the strong claims that are being sort of made but all of our complaints about that are in that fourth section of the paper um so we tried to make clear what we think is sort of justified and not justified on that basis but it's still true to say that it's fair to have a framework and to you know to expend time trying to

put together the mathematical underpinnings of this framework, even though they don't yet exist.

You know, we don't have to, we shouldn't just throw out the theory or disparage it just because the full maths hasn't been worked out yet.

I agree.

We should allow it to change.

We should allow it to evolve.

We should allow it to be applied to different things and see what works and what doesn't.

With all that being said, I don't think, in this particular case, maybe it's true of other theories, but for active inference, I don't think that it's true that there are things that you could remove and still reasonably say, yeah, this is still active inference.

I think...

a theory could not be that amorphous and still be treated seriously as a way of pursuing science.

I think that you would have to say, if you threw out minimizing variational free energy, or you threw out minimizing the expected free energy, or some other of the core components,

I think you would have to say, if you're being reasonable, again, the word reasonable is doing a lot of work in this paragraph that I'm building up to.

I think you would have to say, okay, it's a different theory.

I think you'd have to say, okay, we were wrong to pursue the minimization of variational free energy as a principle for understanding the behavior of biology and cognition.

We were wrong to pursue that.

We're going to pursue something else instead.

And so you couldn't just say, oh, it's still the same theory, but we've changed this core component of it.

I don't think that line is arbitrary.

I think there are some things that if you change, you have to sort of admit that you're wrong about that approach and go on to something else.

That's sort of my piece.

I've talked for a real long time.

I do want to pick up the idea of free energy as a function that measures inaccuracy, but I don't want to talk for like a huge amount of time.

So maybe I should put a pin in that and we could potentially return to it later.


SPEAKER_03:
How about first free energy selection, Stephen M, finish that three, then as the inaccuracy, then I have a point.


SPEAKER_01:
Right, great.

Yeah, I forgot we were only two thirds of the way through our descriptions of the different free energy principles.

I'm sorry.

So free energy principle for selection.

Let me try and pull it up here so I can just read it directly off the page.

What we have it as is any system that survives long enough will act so as to appear to be minimizing F. One of the issues here is that we've left out G, but for the sake of sort of focusing our attention, we can just talk about F. Okay.


SPEAKER_03:
And then how about the FEP or free energy as inaccuracy interpretation?


SPEAKER_01:
Great, yeah.

So this is something that I was hoping would be, again, a way to present it to philosophers so that it would be easier for them to grasp what was going on.

I wanted them to understand, why do we care about this function f?

Why do we care about variational free energy?

Well, suppose that I tell you that in order to do inference, what you ought to do is minimize variational free energy.

And then you could very well say, why?

Why should I care about minimizing this thing?

And then if I tell you, oh, it's the measure of the cost of inaccuracy in belief, then you immediately say, OK, I understand why I would want to minimize that, because I want to maximize my accuracy.

So very simply put, it's a way of explaining why we should care about f. It's a measure of inaccuracy.

I think that that interpretation holds up just to the extent that if you look at the two components, which can be sort of thought of as a cost penalty for overfitting, a cost penalty for being inaccurate, there's a part of that which is inaccuracy.

It's not the whole story, of course, because the other part is to do with complexity, not just to do with accuracy.

So what I think we've done by describing free energy as a measure of inaccuracy or the measure of the cost of inaccuracy is...

trading off that sort of ability to enter into understanding the maths for a perfectly clear, mathematically very precise way of describing it.

But I definitely think that it should be thought of as containing a term which is a cost of inaccuracy.


SPEAKER_03:
So we talked in the dot zero about it's kind of like finding the shape from the data and the fineness of the mesh and inaccuracy in the real world kind of has elements of both, or at least we're used to thinking about complex decision trade-offs.

Like you could make a bad decision because it took too long, but then you came to the right outcome in the scheme of thinking bigger than just one p-value.

And so it's kind of,

opening up even this very kernel piece of the puzzle to the whole question of how specific and how many subgroups and always leaving space for not overfitting given this whole map territory borges discussion um stephen s


SPEAKER_00:
And would you say that the overfitting inaccuracy is more around when you talk about adaptive active inference, where there's a way to adaptively look and have an idea of beliefs in some way, and that underneath that, there could be a kind of a,

more abductive swarming kind of entropic kind of process which is sits in the background but in terms of how we normally explicitly think about meaning we would think about it more in terms of what can be understood as beliefs so just be interested how that how you see that from a philosophical point of view


SPEAKER_01:
Well, one of the things that's still unclear to me about the overfitting part of F is that it seems that it can only be interpreted as sort of a cost of complexity if what you already believe is simple.

because what it's really measuring is how far you are straying from what you already believe.

So that there's kind of an implication there that everybody always has simple beliefs in the first place and that therefore they ought not stray from those simple beliefs.

One of the things that I'm trying to think about now is what happens if you are starting with sort of more complex beliefs?

Maybe that's not a sort of appropriate question to ask given the framework or the way we're supposed to interpret the maths, but I can't help wondering it, given that it strikes me that in order to interpret it, there's a penalty for complexity.

You have to say, you have to assume that what you're starting with is simplicity.

And I guess there would be real life situations in which you don't start with simple beliefs.

And then presumably this would tell you, well, if your beliefs are complex, then they ought to stay complex because that penalty is a penalty for straying from that kind of complexity, which seems, you know, different from how it's usually described.


SPEAKER_00:
Yeah, Stephen S. And would you say that that falls into our more recent move from science as creating models and fitting things to those models in the most simple way to be modelers, like with post-normal science and even Friston's work with the COVID.

So there's a belief in engaging with a complex, non-resolvable world

system question which is different to science's traditional role which is to have an answer and to fit things to it.


SPEAKER_01:
Well, one of the most exciting and sort of scary aspects of active inference is the idea that it's applied not just as a way of understanding what our target systems are doing, so not just as a way of understanding what a biological system or a brain that I'm studying is doing, but also as a way of understanding what I myself am doing when I represent that target system in order to try and understand it.

You get a kind of...

loop in a way, in a sort of sense in which you feel as though you could model your own activity by using these technical tools which Active Inference is giving you.

but then you feel like how could that be done in a way that doesn't invite any kind of infinite regress?

That's why it's scary as well as exciting.

It's exciting because it seems to potentially provide some kind of extra power or insight into our own activities as scientists or as modelers of any kind, but it's scary because it seems to then drop you into a kind of spiraling hole of the modeler who is modeling themself, modeling themself, et cetera.

That's something which I can't think around even informally, let alone try and get to the formalism of it.


SPEAKER_03:
That was the very structure of paper number 36.

So even in its qualitative application, just at the terms and concept level, it does turn the mirror back.

And that is speaking to the pre and post or pre-post trans distributional aspects of ACT-INF.

The...

all the funny things that dean says as well and the strange loop there so what that made me think of is like the statistics and then the famous quote like the statistician can come in for the post-mortem or something like that but a lot happens before the statistics happen like the design of the experiment and so the optimal experimentation and then the knowledge that it will be passed through a distributional filter

in the big macro of the scientific method, like planning months in advance for how many minutes and hours one is going to count insects or how many microliters of a fluid they're going to move.

That is sort of the implementation phase.

And then there's a design time.

And so that's also what ties science to engineering in a way that it hasn't been in design thinking in a lot of other areas too.

Dean?


SPEAKER_02:
Yeah, this is awesome.

So, I mean, one of the things that we talk about is some of those density questions around what's the linear aspect of it and what's the solenoidal aspect of it.

And we also talk about walking into a room of mirrors with a mirror suit on.

I mean, it all comes together in the sense that there, I think one of the things that Steven Mann pointed out is that there are, I think there are, one of the things I think we can say about active inference that's consistent is that it has at least a minimum of two in that back and forth up and down the density bump and around the density bump, you can go either direction and

So that has me asking whether every time we say that this is a framework, whether we're only giving it half its due, whether it's a framework and also a filtering exercise, like does there have to be a minimum of two, not just the boundary, but then what is actually going on dynamically within that border

so that we know when we're crossing, when we know when we're within the boundary that we've maybe are looking at empirically, right?

Because we selected our unit of analysis, but then when we know when we've crossed outside that, when we've gotten to a place where the mesh is holding certain things back while other things that are of a smaller circumference are still able to sort of pass through.

And so I think as a guide,

that question of as we model, as we model, the model is the minimum.

I think if we just say the model, we don't do it justice.

And if we just look at that as we model, the act of doing that, I think, again, we're looking at sort of a side of beef and expecting to be able to milk it.

And I don't think that that works.

I think you have to have the whole thing or else you don't really have active inference.

So...

I think that's kind of where we're at when we're coming to the place where we're trying to decide what goes in and what doesn't go into a guide.

And it's a struggle, right?

There's no question it's probably one of the hardest things that you can do because the majority of people that are guides are there because they've been there before versus the one who hasn't.

And that would require upending that basic premise, which is, no, everybody has to get into the boat and we're sailing off onto the event horizon.

That would be the only way that we would change that.

So the actual nature of guides would only change if everybody had to get their skin in the game and start at that basic place of not knowing.

But we'll leave that for another discussion.

another live stream.

But at this point, that's what's really interesting here.

One of the assumptions that we made is somebody has taken the time to go and search and explore and come back with information and the other people don't have it.

And the only way that changes is if everybody gets in the boat and sails off and hopes that they don't come to the edge of the cliff and fall off, so.


SPEAKER_03:
okay a lot there thank you dean just a few other points people have different perspectives on what is core or not some of the uncertainty let's get at it with the ontology development and making some definitions and translations and the formalisms clear in the history of science and all of that but even then it might be pretty fundamental like if it includes action and inference these variational methods necessary

So who knows?

People will have different interpretations just about a lot of things.

And so that's, again, all part of the fun.

So Stephen?


SPEAKER_00:
So one question I'd be interested in is talking about guides in terms of that book, Life, a User's Guide.

That's a very deep...

read it for a long time and then i lost it but it's sort of like it takes you into all these aspects of people's lives in that parisian neighborhood and um it never gives you an answer it doesn't but it in some ways it's leaving it to your intuition it's leaving to um your

integration and i'm wondering where you see that that integration that's happening at a non-perspectival level the integration the intuition the the affective consciousness that is part of our knowing and how that relates to this and maybe if it's even something that's not part of science but is part of this kind of work


SPEAKER_01:
Well, I mean, firstly, you sort of cracked the code in a way because the title of the paper was directly and explicitly stolen from the correct book.

It wasn't necessarily a sort of...

the best like joke because it's not it's in a in the sense in which the book is about an incredibly hyper specific and detailed description of a system you know an apartment block at a specific time point on a specific day of the year gave me the idea about okay it's like it

It's not true that we ever really represent things that way.

It's not true that science intends to represent things that way in the way that Perrette does and is sort of making fun of.

But also he's incredibly constrained in the way that he wrote the book, as I understand.

There's some...

there's some really crazy games that he plays with language in writing it.

And that caused, for example, translators a huge amount of difficulty in translating it because how do you know, how do you translate the game that he's played in French into a game that you can play in English while writing the English version of the novel?

So definitely the idea of representation

and sort of naturalism was on my mind.

But the short reason we called it that is because we wanted a punchy title.

We wanted something that people would think was accessible.

But definitely when it came to casting about for punchy and accessible titles, that was the one that primarily came to mind.

Where it comes to sort of

affective consciousness and sort of experience, again, it's a little outside my wheelhouse.

I was very, very impressed upon by the novel, even just in the English translation because I can't read French.

I was really, really sort of moved by it in various different ways, you know, intellectually, emotionally, things like that.

There's a lot about sort of representation in there, just the concept of representation.

And that's something that I'm interested in.

But again, that pulls sort of in the opposite direction from an activism or affective consciousness and things.

And I'm very much situated in that kind of formal dry approach to philosophy, the kind of analytic tradition where we try and chop things down.

We think we're scientists inspecting the human condition under a microscope.

Um, and so, but you know, I can't deny that in reading a novel, it flows over me in the same way, you know, I'll experience it in a similar way that you experience it.

I hope.


SPEAKER_03:
Yes, blue.


SPEAKER_06:
So totally funny.

Um, I was also had a question about a guide, but like on the opposite of like life, a user's guide, I was reminded of the movie Beetlejuice.

and they, like, the couple dies, and they have this, like, handbook for the recently deceased, right?

And, like, the core of, like, the theme that they can put, well, did you read the guide?

Well, did you read the guide?

And it's apparently, like, a very thick, dense book, like, that, no, like, you can't, I mean, we're dead, and we don't know what to do, and we're freaking out, and we don't have time to sit down and read this book.

And so I was reminded of that, which is kind of totally juxtaposition, but it's, like, when you are creating a guide, it's very difficult to, like,

make it usable, right?

Like the map versus the territory, like what,

what will people read and be able to take away and walk away with some kind of general understanding versus like, if you really want to know what to do when you're dead in this situation, you've got to read the book, you know, how to like haunt the house and all these things.

And so like, do we really need to like pull grip of the FPP to really sit down with the guide, you know, whatever, like 3000 page manual

Or, like, how do you distill the essence of something that's so complicated?

Like, what is it to be dead?

Or what is the FEP, right?

It's hard.


SPEAKER_01:
That's such a good example.

It's a handbook for the long-lived, I guess, the free energy principle, as opposed to a handbook for the recently deceased.

Yeah, what is the line that they have in that?

It's something like some incredibly dry statement, which is absolutely no help at all.

Like operational parameters vary from manifestation to manifestation or something.

And yet, I mean, the idea behind it was that the philosophers that we talked to that urged us to try and research and write this were pointing out that when they attempted to read those papers in the active inference tradition, even those that were billed as tutorials,

It was like trying to read the handbook for the recently deceased.

It was, if not too long, then at least too dense.

And they couldn't pick apart those statements because they were too condensed.

And so, yeah, the difficulty was big.

un-condensing it, pulling it apart, selecting what was necessary, and then presenting it in an accessible way.

I mean, all I'll say is that it took sort of on the order of years to do it.

We sort of got commissioned, as it were, in 2019.

I started researching it in earnest at the beginning of 2020.

And it went through a few drafts, and people gave us a lot of comments behind the scenes.

But the first preprint came out in December 2021.

yeah it's for me at least and for us the authors it was that difficult to trawl through the literature find what was necessary and then present it in a presentable way but that's such a great example thanks so much that hadn't crossed my mind but i love that film and the concept of the handbook as well


SPEAKER_03:
just a few comments on that it's not called free energy principle a user's guide it's actually very specific it's about the variational free energy and the expected free energy f and g respectively what's the fep so that's sort of where it takes you and it's very subtle then um that was pretty interesting a handbook for the long lived and

it reminded me about metacognition in learning and about what we expect and prefer and think we can know and how like just being a um learner and like a teacher's assistant seeing how there'd be lecturers that would give um maybe it could be thought of in sort of an effigy framework another day but they would simplify and learners would have high precision on a very simple model

And then other times they would convey too much of the complexity.

And so at the end of the quarter, even if the students learned a ton and they would still feel like lost in a bigger space and there's like good and bad aspects of all of that.

So I think this is kind of like a snapshot.

It's kind of cool that it is so recent.

That was only a few months ago, right?

Now that it's February 22.

But this is very recent and still kind of ongoing that you're looking to update it to.

So it's sort of like a kind of window where there's interactions with the community and hopefully people really think about it.

And the people for whom a section isn't clear have an opportunity through this affordance we have now as scientific publishing with preprints like to ask or correct or you missed a citation here.

That is awesome.

And it's a world apart from sort of three people with it on their desk who are delaying it in review.

And then maybe they have good comments, maybe they don't.

But here there can be something that's so much beyond that as this is just like one thing that you're working on and you're developing.

And then one last comment on that is like SPM, the textbooks are still kind of classics, cult classics, we might even say.

And it's not that the notation hasn't changed a lot because it has in some cases, it's a snapshot and there's some amount of linking back to the past that's clarifying.

And then there can be an understanding that there's drift and focus and evolution of techniques.

And the SPM textbook, it's going to have sentences that you wouldn't include if you're writing it today.

Great.

That's why it's different.

But also there's something about it that helps inform.

So every snapshot that's well intended always is good.

Dean?


SPEAKER_02:
Yeah, I think one of the other things that's really interesting about this is Stephen M. has kind of pointed to the length of time when the question was posed, can you summarize this for us?

Can you synopsize this for us?

Basically what the philosopher, it sounds to me is what the philosophers were asking was, can you go and do

the figuring out and then present that to us in a finding out way.

Will you save us time?

And so I think that's one of the things we have to keep front of mind when we look at this, because those philosophers now didn't do the two years of heavy lifting and searching and foraging.

That's a whole different aspect.

That figuring out is a whole different processing method and mechanism than the finding out, right?

And so again, if you want people

If you want people to come away from guide use with more than the finding out, they're still going to have to get in the field and do the figuring out themselves.

And it's that interaction part which

Thank goodness for Blue and Beetlejuice because that was, again, that was just a wicked example, right?

Because the timing of this, the when-ness of this really, really matters.

And I know that in a lot of educational settings, time is at the essence, right?

13 weeks, X number of hours, blah, blah, blah.

We tend to get that.

That's the only part of the when-ness that we focus on.

Not...

Should the guide or the plan be the thing that initiates all the action, or is that the thing that falls out afterwards?

If we're doing figuring out, it has to fall out afterwards, not before.

And we have a really hard time

with that because traditionally it's always been the legitimizing of guides because they've been there before and they'll help you find out, but they don't necessarily help you figure out just because of the amount of time.


SPEAKER_03:
Yes, please, Stephen M.


SPEAKER_01:
I mean, yeah, so both of the things that you both just said, Daniel and then Dean, like they both open up huge topics which have so many interesting questions and so many interesting ways of approaching them.

Dean, I think I agree 100% with what you just said.

They've done the...

they're going to have to use our guide as a kind of shortcut in a way to doing the initial stuff, the finding out, but it behooves them in a way to do some extra work of figuring out afterwards.

The thing that that most sort of resonates with me regarding is just the idea that our mandate, what we had to do in producing this,

was give them the ability to work through the examples themselves.

Because that's a part of, I mean, I'm not sure how you're distinguishing these two things, but to me, that's a part of figuring out as well as just finding out.

To me, we're not just saying, this is a measure of inaccuracy.

And this is the algorithm by which you minimize it.

We're saying, look at this example with these numbers in the imaginary situation.

And if you work through it, and if you print out the graph yourself, you will find that this is where the minimum lies, for example.

And you will compare that with this other thing.

So we're doing the sort of the first tiny step in helping them figure out how they would figure it out in a way, if you see what I mean, giving them the means to go ahead and do it again themselves in a different kind of situation.

But the sort of the other thing that it brings up, I mean, I shouldn't say that, you know, they they like Michael Weisberg didn't say, you know, go and do this for me.

Go and be my research assistant for two and a half years to print this thing.

He, along with Peter Godfrey Smith, who is another person not connected with the journal in that capacity, but very interested in having this framework explained for a wider audience, pointed out that first and foremost,

we ourselves would get some kind of like plaudits for having done the work, having helped people to understand it.

So, you know, there was the personal selfish incentive to do it, but also that it would be something that would benefit the community in a sort of, in a positive way, not something that we would be giving them for free as it were, but something that we would be

creating for everybody to draw on and use and just improving how the community approaches this question.

So in the same sense in which, you know, in the best case, academia is a wonderful collection of people who are all helping each other to, you know, find those shortcuts, do the finding out without going through however long it takes to sift out

the stuff that is not necessary.

We're all helping each other to do that.

You know, I can read somebody else's paper who is working for two years on something completely different.

And having split up that labor, divided that labor up, we can both sort of benefit from it.

Sorry, I'm going on far too long now.


SPEAKER_02:
No, no, no.


SPEAKER_01:
I'm only answering one question.


SPEAKER_02:
One last thing about the minimum of two thing, though.

If we could get you and Connor Hines into a live stream, I think my mind would be blown.

Just because that math and this philosophy in one proximal location, because that to triangulate off that would be...

amazing because that's essentially what you have to do.

You have to put the finding out and the figuring out together.

I don't think, again, I don't think it's one or the other.

I think it's our ability to sort of be able to hold up both at once and appreciate how each of those things fills in the picture.


SPEAKER_01:
Yeah, and I do want to, Daniel, you should tell me when I should stop or, you know, please just jump in and interrupt me anytime.

But, you know, I just wanted to sort of respond to your points as well.

The other good thing, since I'm in an optimistic mood about academia, like you say, the kind of pre-publication, pre-print, sending it out and enabling people to give us comments back on it.

If you think about it like is that metaphor with going to a classroom and teaching before you go in and teach, you have to pare away all of the nonsense, the stuff that's too complex, get it down to the level that's simple enough so they can understand, but has enough information so they can actually learn something.

In the really good case of getting a kind of course evaluation, you do a whole course.

You get a bunch of students tell you what was right, what was wrong, what went too fast, what went too slow.

And hopefully there's a kind of average where it averages out.

And you improve it sort of next time.

You make it easier for the learners because the learners have told you what was right and what was wrong about it.

It's always that kind of feedback process.

Obviously, in real life situations, it doesn't always work that well getting that kind of feedback.

But if you're sort of lucky enough to start off from a decent point, as I think we have at this paper, you can...

you can get to a kind of point which, once it is snapshotted, because that's the other important thing, I think that this kind of pre-publication peer review is really useful, but there shouldn't be constantly evolving documents all the time.

There should be some kind of snapshots.

Once it's snapshotted, it's as good as it can be at that time, even if it becomes redundant eventually, even if it uses language which won't be used in 10, 20 years.

Once it becomes something that people can refer to valuably for a certain amount of time afterwards, that's really the best that you can hope for.

Certainly, just a paper.

This is just a paper.

It's nothing more than that, really.


SPEAKER_03:
Just one thought on that, on the finding out and figuring out, connecting that to the peer review.

It's almost like

We're all co-learners in participatory engaging education.

So we want to make it easier for the learners, which is us.

And we're all co-learners.

So sometimes we find out that would be somebody with more domain expertise

giving us the feedback on the paper and then in the side channel maybe there's another time and place where it's a different roles not relationship but like and then there's the figuring out and then maybe there's other things here too that's actually um not like feedback from the bottom up but beginners questions abductive logic applications adversarial or contrarian even questions that is always like what is active inference why does f matter um what

the fvp have to do with active inference what does evolution have to do with natural selection what does natural selection have to do with drift if those were not resolved then they're going to be some open ones in this area as well and i think there is also another analogy with sort of like

in a concordance with evolutionary theory and like Darwin's Dangerous Idea, Dennett in 95, that type of book perhaps has already or soon will be written for something like FEP because it has that same ability to like spawn an adjective

and then reintegrate the adjective back into the corpus.

So it was like, there was like evolution of this type.

And then people add like a modality or a subdomain or a new word.

And then it rejoins the main thread.

So we had like deep, affective, sophisticated, contrastive, dot, dot, dot.

But it's going to reintegrate because it will be versioning.

And that returns to like Blue's point about what is core, what isn't, and how will that change?

And so...

and then you just kind of close the loop with the snapshotting but the recognition of the process but we have to make the static modification in the niche but of course it's a process so it's really um interesting where we've gone today yes stephen m and then s


SPEAKER_01:
Oh, yeah, just very quickly.

I think the point about contrarian questions is a very good one.

It's often philosophers' main method of figuring something out, beginning with the contrarian question that is uppermost in their mind, going out and trying to find the answer to it.

And certainly in this case, on my side, when I was doing my part of writing the paper,

I was starting with what on earth is this maths and what is the interpretation of these different components of it?

um and that was just for the for the maths when you get onto the sort of philosophy side the interpretation the dialectic i mean one thing i haven't said is that there are some quite skeptical portions of this paper you probably you know noticed when you read it and we tried to you know pull back a little bit but what we wanted to do was provide you all for figuring out

And you always want to try and do that in good faith.

You know, you always want to do it in a way that's not combative or dismissive.

You want to do it in a way that is designed to help you and the person that you're asking come to a consensus about the answer.


SPEAKER_03:
Thanks, Stephen.


SPEAKER_00:
Okay, Stephen S. Yeah, I really find this helpful, this gratuitous use of the term guide, because you chose that title, which may be

If you weren't doing a preprint, maybe people, I noticed people a bit more creative with the titles, which then that's maybe also a nice benefit.

But by going there, this discussion has been really helpful.

I often hear people when they talk about the findings from research that, oh, we're going to roll out a toolkit, we'll do a toolkit.

And then when they talk about a guide, it's really a sort of a guide to teach the toolkit.

But here, what in a way you're looking at, especially if you're getting into the more,

deeper tacit knowledge is what's the guiding principles to being a modeler what's it about being a modeler and that's where well these kind of conversations are useful but i think that the the type of stuff that's been brought up here are things where you know

they're not resolved down to a toolkit level, but it opens a question for someone to have a conversation about.

So I just thought I'd mention that and what your thoughts are about that challenge of someone becoming a practitioner rather than necessarily an academic disseminator.


SPEAKER_01:
Yeah, it's tough because I'm really not sure.

In part because all that I'm sort of trying to be right now is an academic disseminator.

So I would have to shift into a sort of different gear to think about what it would mean to be a practitioner.

I mean, I would start by asking you what you take being a practitioner to be and then see if I can resonate with something in that.


SPEAKER_00:
Well for me it's more contextual and it's more about being able to adapt and evolve based on a situation and often you find the practitioner work is when you're in a face-to-face performative context in a way where you have to perform

either the dialogue, I suppose, in science, when you're in the field of practice.

In other areas, it could be the performance of giving a performance, be it a performance as a teacher, it could be a performer, being an actor, being a workshop facilitator, being a therapist, being whatever that might be.

And I suppose that question about how something being a guide

toolkit or some way to access the sort of heuristics and ways of knowing which aren't even representational in the kind of the way that we can easily externalize so I suppose there's some of that there's the stuff that we can't take a perspective on directly because we can't necessarily encode it into artifacts and place them in our environment in words however

that knowing is a skillful practice that has been sort of cultivated.

So I kind of feel there's a need for that.

And there's a big move towards that now with the world trying to embrace transdisciplinarity, participation, complexity, where you have no way to make any sort of movement forward without the ability to find other ways to hold the meaning.


SPEAKER_02:
Dean?

Just to sort of piggyback on Stephen, I think if you want to try to draw a comparison, if you're a disseminator, the result can often be something like a desire line, a wearing in, a following.

And if you're looking at the generative model, you're looking at a densifying.

Out of foraging and then an accumulation.

And in that respect, it's quite clear what, from a practical sense, one's not better than the other, but one results in quite a different result than the other.

It's something to think about.


SPEAKER_03:
And then one other thought on this practitioner and scientist, though I hope we see a hundred times more and more different ways to learn and apply active inference, just total first thought, would be like when Stephen was describing a practitioner contextual and adapting on situations with really lower levels of control.

It's on a continuum, but like a crisis or a transition moment or an adversarial scenario,

has a lot of an implicit factor and it's not always as focused on like the coolest calmest most collected stigmergic artifact modification it's more like the firefighting was done appropriately in that scenario given what it was

And then the scientist generates niches like epistemic niche, laboratory niche, computer niche that allows them to generate scenarios where they can apply distributions.

And then when they apply the distributional methods where there shouldn't be a distributional method, it's going to be unfortunately a silent error most of the time because of how little paid attention to all these differences are.


SPEAKER_01:
So Stephen M. Yeah, this is really tricky to think about.

I mean, I think I agree that knowing...

ought to be considered a kind of skillful practice.

That was one thing that you said, Stephen, that I really sort of jumped out at me, in part as being not sufficiently emphasized elsewhere, certainly not sufficiently emphasized in the tradition of philosophy that I come from.

There tends to be a fairly clear distinction between knowing in terms of representational knowledge and

knowing how in terms of skill and there's not that often the consideration of the kinds of things we would usually consider representational knowledge as underpinning a kind of skillful practice but when i think about the way that

I'm thinking about philosophy conferences and the kinds of conversations that go on.

It's pretty clear to me that having a conversation with somebody else about a topic that is so sort of steeped in law and intellectual...

recognition and texts as having a philosophy conversation is, what it requires is a kind of skill, a kind of a smooth, a kind of automatically picking out the topics as you go along, not sort of sitting back and thinking very hard on your own before coming back 30 minutes later and responding to the things that your interlocutor has just said.

It has all the hallmarks of a skill as far as I can see.

And what happens is, well, the way that I have been brought up to view it is you do all your thinking at home or you do all your thinking in the armchair.

And then when you come out to have the conversation, you're ready with that skill.

Because you've done all of that slow, solitary work first, the kind of propositional or representational kind of work.

Then when you're ready, you come out and you practice everything.

discussing it.


SPEAKER_03:
thanks great point it's a lot like the uh representational dimension is kind of the non-linear knowledge model which is it cannot be conveyed in a linear sequence linear presentation in video and in writing is rhetoric and that was one of the most interesting areas um in the paper was like the claims justification the whole second part and i'm happy that we spent

almost all the dot zero in our conversation leading up to it because there's a whole paper and it sounds like it there's so much more to explore um but like the part about the rhetoric and the way that people not just have an edge in their knowledge graph their armchair knowledge graph or their

relational database, not just an edge between concepts, but actually when a question is raised to move to that answer first or the first topic that's mentioned.

Like if somebody asks, what is a Markov blanket?

The first noun, what is it going to be?

well for a cell or is it because of bayesian or what is the actual first rhetorical node that somebody gives and those kinds of knowledge like representations are really interesting too it's not even just that it's the most important thing because that's not how people always structure their speech so like

there's both sides we need the non-linear part so that we can actually build a bigger structure than just an oral script but then it has to be in that like run time that you kind of described at the philosophy conference it has to be presented in a linear way and if there weren't disagreements or um like contrasts in people's perspective then they would just be reading off the same book

so maybe we'd love to hear your thoughts on any of these ladder sections in four like which one of these areas of claims we won't stay long but just what of the areas of claims or the relationships between areas was interesting to you or like you learned while reading about it

because you had the justificatory links between dialectical categories with mathematical, empirical, and general.

So maybe just one edge or one section of those.

What did you find interesting?


SPEAKER_01:
Oh, was that an open question or were you asking me?

I wasn't sure.


SPEAKER_03:
I guess to you.


SPEAKER_01:
I mean, I can definitely start with the first section, which was the mathematical to empirical direction.

And as you said, for each edge of the triangle, we were only sort of considering one direction, mainly for considerations of space.

What's most interesting to me about this is just that it is an established research field called computational cognitive science, when the specific maths that is being looked at is certain kinds of neural networks or other kinds of computational systems, and the specific empirical system that is being looked at is the brain, especially the human brain.

and what we really wanted to emphasize in this section was that the kinds of tools that have already been developed by computational cognitive science so that includes the models and the explanatory tools and the justificatory or inferential tools could be applied to active inference models as well so this was our attempt to say to the philosophers we already have some equipment

we can use when what we're trying to do is evaluate active inference.


SPEAKER_03:
So whether we call it deflationary or not, there's a lot of relevance in emphasizing which parts are specific to active inference and which ones aren't, like bringing action into the loop.

is not a novelty in the last 15 years doing bayesian statistics doing variational inference and so that work helps us really highlight the parts that do have unique and different interpretations like this is definitely one of um my favorite paragraphs i think that we've come across and gotten the highlight on the discussions like and then you even brought it up that it's actually in the distillation

not just implicit knowledge or notational connection, but a rhetorical element that arises.

And then also one with like educational and didactic implications.

So that's really interesting.

Dean?


SPEAKER_02:
Yeah, and I think when I was reading your paper, Steven, I noticed the number of times you had the word evaluate, evaluate, evaluate, which again is another one of those, does this pass, pass muster, pass a standard, pass what goes on?

and what gets held back, what gets continued attention, and what do we now ignore?

And that's why I like when you were talking earlier about, well, when we put a guide together, we just want to basically walk into the bar and make sure that the 98 things that we really can't pay attention to first, that doesn't pass.

What does pass are maybe these two first nascent ideas.

And so again,

You don't need to even hear this, but if you want a just a factory link, that is one right there in real time in terms of what carries on, what can we build off of and what falls away because it doesn't seem to pass whatever evaluative methods we've implied.

But then again, that goes to when do we start evaluating?


SPEAKER_03:
from the from the moment we started we want it to be something a little bit more creative and hold that thing open a little long before we jump to assessment okay so in the last just few minutes yeah stephen you want to give a response there or would you like to have a little bit of a closing statement


SPEAKER_01:
uh let me give a quick response which is just that i agree exactly with what you said dean and um yeah we wanted to show that some things could be evaluated very directly just by working through the numbers and that gives some directions for how other things could be evaluated and you're right it's like passing it's sort of how a philosopher evaluates a scientific theory as being sort of in a sense

first level plausibility or first level acceptability, how it passes that.

It's kind of a philosopher's technical term.

But I can sort of give a kind of closing statement that calls back to what you just mentioned, Daniel, that paragraph, which is just that the thing that I'm thinking about

most often when I think about active inference right now is the interpretation of P in the expected free energy function and the sense in which it can have

probabilistic interpretation as well as an interpretation of a kind of preference.

That is the thing which I really want to try and get to the bottom of, again, just by working with very, very simple models, try and throw some numbers around, try and intuitively grasp what that model can represent.

We have one in there with the example of the cat, but I want to try and expand it a little bit.

Yeah, I'm glad that you like that paragraph.

because it's the thing that is causing me the most, it's the thing that's itching the most that I'm attempting to scratch right now.


SPEAKER_03:
All right, so we'll each give a closing thought.

So just what did people enjoy?

What would they look forward to talking about next week?

So Stephen, select first.


SPEAKER_00:
Well, just thank you a lot for a really great, engaging conversation.

lots of insights um i i'm really interested in that idea of the the peas um so i think that's very interesting and i'd be interested in how that maybe applies both on the um on the sensory side and the action side so how much is the probabilities

and preferences for sensing as much as, or is it that one is more for sensing one's more for action, but, uh, very interested in all of that.

So thank you very much and, uh, look forward to more conversations.

Okay.

Dean or blue.


SPEAKER_06:
I'll go ahead.

Um, so thanks for entertaining all my interrogations.

I appreciate it.

Um, if you're going to come back next week, I would encourage you to check out, um, a tale of two densities because like on the tale of Steven with the P's and the Q's, I'd be curious to, to think about or to hear what your interpretation of that is.

And if you would, um,

maybe change or maybe you will, I mean, it's just a preprint, so maybe you have a burgeoning affordance to kind of consider that in your explanation in the beginning.

I'm curious, or if you think it's one of these superfluous extra components that is for the handbook for the recently deceased, not necessarily, you know, like the 13 steps of dying or whatever.

So I'd be curious to hear what you have to say about that.


SPEAKER_03:
Dean, anything?


SPEAKER_02:
Yeah, it's just that I don't want this to drop down to the sort of quantum level, but I think that when you're doing a guide, it's hard not to sort of try and juggle both the dynamic aspects of what you're trying to share and the stable aspects of what you're trying to share.

You want the screwdriver to remain robust and constant, and then you want it to also be able to

be manipulated in such a way that it drives the screw.

And there's a dynamic and a stability piece to this guiding that's really, really hard to, as you say, square.

I don't know that it can be squared.

I think they both have to be maintained.

And so my sense is that I...

I didn't know what you were going to do in terms of the guiding, but I think the way that you laid it out did slow things down, did allow the teeth of the screwdriver to get set.

And then you could actually do something dynamic with it.

So really appreciate that.

And maybe, maybe next week we can talk about when the screwdriver is used for creative purposes, other than driving screws.

Cause I think what the math says,

if we use the geometry and the statistics and the philosophy all in one concoction, I think that's the basis or the minimum that we have then to be able to do creative things and not just recombinatorial things.

So maybe we can touch on that.

I would be really curious to hear how you see this going off in creative ways without going, because the big fear people have is that just means destabilization.

where I'm saying it has to start from both stable and the potential to move.


SPEAKER_03:
Thanks, Dean.

Stephen, any last thoughts?


SPEAKER_01:
Just to thank you all very much for engaging with our paper, for inviting me on the stream, for asking me really great questions and raising great points that just had never crossed my mind.

This is exactly the reason why I was hoping to do this.

I am going to try and come back next week.

I can't make any promises right now, though, because next week is a bit of a heavy week for us.

But just, yeah, the...

The prospect of going and reading that paper and then being able to respond in a more intelligent way to Blue's question is making me really want to do it.

Not to mention all of the other topics, which, you know, we haven't talked about yet for the rest of you as well.

So I will let you know during the week, but fingers crossed we'll be back again next week.

But thank you all.


SPEAKER_03:
Thank you.

Yeah, really appreciated everybody sharing their perspective and you're welcome back anytime.

So see you everybody.

Peace.