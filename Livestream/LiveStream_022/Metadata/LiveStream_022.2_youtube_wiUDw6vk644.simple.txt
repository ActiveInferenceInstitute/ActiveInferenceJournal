SPEAKER_03:
okay hello everyone we are live welcome to act in flab live stream number 22.2 nice repeating digits there we're here with alex keifer and others we're going to be having our second follow-up discussion on the paper we've been discussing for the little last bit psychophysical identity and free energy

It's May 25th, 2021, and this will be a great discussion.

So thanks again for everybody who's joining live as well as watching in replay.

If you're watching live, especially feel welcome to add a comment in the live chat that we can address.

Welcome to Act-Inf Lab, everyone.

We're a participatory online lab that is communicating, learning, and practicing applied active inference.

You can find us at the links that are listed here.

This is recorded in an archived livestream, so please provide us feedback so that we all can improve our work.

All backgrounds and perspectives are welcome here, and we'll be following good video etiquette for livestreams.

We are here in the second of the two discussions in late May 21, and happy to have Alex joining us for both of these discussions, which has been great.

Today in 22.2, quick correction, we will be just trying to learn and discuss.

Enjoying these conversations, seeing where they go, enjoying what questions bring up, and also carrying on with a few of the topics that we knew that we wanted to cover from last week.

and with that being said we can jump right in so we can go to the introductions and we'll just um maybe go around introduce ourselves say hello and then end with alex and alex would be happy to hear your thoughts or reflections in this past week so i'm daniel i'm a postdoctoral researcher in california and i'll pass to dean hi folks i'm dean i'm from calgary and uh


SPEAKER_04:
Yeah, I'll pass it to Adam.


SPEAKER_06:
I'm Adam.


SPEAKER_07:
I'm a postdoctoral researcher at the Johns Hopkins Center for Psychedelic and Consciousness Science.


SPEAKER_03:
And Stephen?


SPEAKER_00:
Oh, hello.

I'm in Stephen.

I'm in Toronto.

I'm a community development practitioner and applied theatre artist, and I'm doing a practice-based PhD at the moment.

And I will pass it over to Alex.


SPEAKER_05:
Me, Alex, or other Alex?


SPEAKER_03:
I think you're the only Alex right now.


SPEAKER_05:
Okay, okay.

I wasn't sure there's a fellow jitster.

Oh, so I'm Alex Kiefer.

Thanks for having me back again to talk about this paper.

I'm a philosopher.

I'm currently affiliated with Monash University, and I'm also doing more applied work for Nested Minds Solutions.

It's a kind of active inference AI startup.


SPEAKER_03:
Cool.

There's a few ways we can start, but why don't you feel free to give any opening comments and then we can ask questions.

We have some other slides.


SPEAKER_05:
Right.

So you asked about my reflections over the past week.

I haven't reflected a whole lot on deep themes.

I did go through.

So in the point zero discussion, there was a

sort of a question about how we get from equation 2.1 to 2.2 with the flipping of the p's and q's.

So that strikes me as not the most central theme we could spend time on.

But I did just spend some time writing out the derivation, if that's something we can get to at some point.

But in general, I guess my feeling is I think last week was really fun, and it was very far-ranging.

I think it would be fun to drill down a bit more on some of the specifics this week, but it's also whatever people want to say.

That's what I'd be interested in doing.


SPEAKER_03:
Thank you, Alex.

Welcome, Lou.

If you'd like to just say hi, we're having intros, and then we'll walk through some jokes and questions.


SPEAKER_01:
Good morning, I'm Blue Knight.

I'm an independent research consultant based out of New Mexico.


SPEAKER_03:
Cool.

So there's a bunch of places that we wrote down to jump in.

Maybe actually we could go to Dean's three functions walk into a bar.

So it's slide 11 and I'll have it up large on the stream.

So Dean, why don't you unpack what you were thinking here and let's get some initial reads to get the contrastive ball rolling.


SPEAKER_04:
Well, essentially what the point two aspect of this process does is it takes basically what we've introduced as the topic, tried to gain some interpretation around it.

And then, so what does that mean?

What does that turn into?

And so one of the products of that for me was

I kind of went back and reviewed the 22.1.

And one of the things about what you mentioned, Alex, was the explication of a simple idea.

And I thought that was really important.

And so what can that turn into, that simple idea?

That was the three functions walk into a bar piece and essentially spoke to what Scott was talking about last time in terms of paradoxes and what do those mean and

when do we model and when do we follow?

But I thought the bottom part was an important piece in terms of you mentioning that you sought continuities, and I wondered if you were referring to cynicism and that idea of how we take discontinuities and turn them into continuities.


SPEAKER_05:
Man, that's really interesting.

So I had never heard of cynicism.

I keep coming to Paris through strange avenues that were not planned.

I never consciously thought of it this way, but this kind of nicely summarizes how I see things and the way I've just been sort of forced by experience to approach philosophy.

I found it difficult or impossible to draw

to draw boundaries that would create discontinuities between categories quite generally.

So that gets into things like the Serites Paradox.

There's plenty of examples of this.

But I think for me, it's much harder to find a discontinuity than the opposite.


SPEAKER_03:
Can you maybe just walk us through these three functions walking into a bar?

What is the narrative here, and where does it sit in relation to the paper?


SPEAKER_04:
You're asking me?

Yeah.

Okay.

So essentially, if we're going to talk about contrastive divergence, which I think is a critical path to understanding how we move down a gradient and arrive at some sort of...

generative model, I think that there are three functions that essentially exist in that.

It's an inversion process, which, again, I'm not going to go into the reads on that.

There's an identity piece, which is spoken to explicitly in Alex's paper.

And then there's the contrastive divergence piece, which enables a person to remain balanced despite the fact that they don't have

particular answer that there are hidden states.

And I think a lot of what was being spoken to last time, Scott mentioned some things, Blue, Steven, was things like scale, which don't necessarily, we don't come at it with the same perception as to what we're looking at.

Some of us look at things a little bit

on a grander model and some of us look at it on a granular model.

And I think that the part of being able to fit that into a form like the joke, the three guys walk into a bar or whatever, kind of speaks to the fact that

If you think that this is gonna be about stability, you're gonna get interrupted by the change aspect of it.

If you think it's gonna be all about the change piece, you're not gonna be able to realize any sort of conceptualizations because conceptualizations require stability.

So you have to kind of be able to play in both fields at the same time, and that's hard.

And I think that's why

Alex's paper probably knocked me down about five times when I first read it because he actually did, Alex, try to somehow pull together the idea of stabilizing something even though things were pretty choppy and

and rather dynamic.

So I don't know if this is an example of where the part two of us discussing your paper goes, but I think it's interesting, especially in the context of cynicism and your idea that we're constantly trying to move from the unknown to the known as opposed to the traditional.

This is what I know, and I'm moving into these unknown spaces.


SPEAKER_03:
That reminds me of then anyone, Alex or anyone else, reminds me of sort of two complementary ways of thinking about education with the tabula rasa, the blank slate that inscription is put into.

It's like filling the cup with knowledge or inscribing into something that's templateless.

And then the alternative is to burn away ignorance.

And so it's almost like whether we're moving from the known into the unknown or the unknown towards the known, there are left in our right hands of education.


SPEAKER_05:
Right.

Yeah, yeah, this is really cool.

I mean, it, it seems like, Dean, like you have, you have an act for like reading, reading things in a sort of very deeper, almost allegorical way.


SPEAKER_04:
We're like, I'm talking about a very... A Peirce-ian way, yeah.

I read Charles Saunders Peirce two decades ago before it became popular.


SPEAKER_05:
Right.

So, yeah, so I think it's interesting and it's all, these connections are really there.

But I just, just to comment on this for a second.

So I do think that there's something about just the, how ubiquitous sort of

dynamism is and all this and how, in a sense, there's no stable process that we can latch onto here.

But when I was talking about contrastive divergence, my main point was just, well, look, I'm thinking of that very narrowly as a machine learning, like an unsupervised learning algorithm, which I know you have that in mind too, but you're also taking a broader picture.

So my point in contrasting contrastive divergence to simulated annealing was we can suppose that the brain is running something like contrastive divergence, where it's trying to reach a lower energy state.

But the way that algorithm works, of course, you don't need to actually run the basic idea.

is that you don't need to... So, okay, sorry, let me take a step back for a second.

Right, so like one way of doing this sort of unsupervised learning would be to take the distribution over hidden states in a neural net that's induced by an input and try to...

lower the energy of those states while raising the energy of the fantasies that the network would produce top-down, right?

And so the ideal way to do that would be to run the network until it reaches its equilibrium distribution and sample from that when you're doing the negative phase of this, of increasing the energy of the, or therefore lowering the probability of the fantasies.

Contrast and Divergence just takes a shortcut and just runs this for like one step or two steps or whatever.

So I just want to make that clear.

I don't know if it's clear for everyone in the audience who hasn't looked at this deeply.

The specific contrast that I wanted to draw there was just

was just between that and a process like simulated annealing where if you run it to the end of the process, you end up reaching the lowest possible energy state.

So the brain, I guess my point is the brain doesn't necessarily need to be settling to, and this does, I think, connect directly to your point, doesn't need to be settling to a completely stable state or even any particular metastable state.

It just has to be

there has to be this gradient, right, that is available.

But I do think that there's a deeper point here, right?

So the NESS or the non-equilibrium steady state that organisms are approaching as they do this variational inference thing is not any kind of final

You know, it's not a static state, like some kind of ultimate equilibrium.


SPEAKER_04:
Right.

Well, going down a set of stairs, the one steady thing is that I remain balanced and not go tumbling to my demise, right?

That's the one steady thing, the one balanced thing.

And then there's the gradient itself.

That's why there's a next slide that kind of speaks to that piece of it.

And that's all I basically wanted to bring up because I think, and I think the cynicism piece embraces,


SPEAKER_00:
entails all of that there's a there's a dynamic piece and there's a balancing piece and you and you want to be able to sort of address both that's that's cool yep thank you dean stephen and then adam there's interesting questions here for pragmatism and social constructivism you know in terms of how these ideas roll out into how we might talk to other people in the world around

projects and stuff because of this implication so i i wonder how you you would bring in this kind of embodiment of that so um if the brain is an organ that is doing expected more than expected free energy with the nervous system to help

to manage the movement of the organism.

And the organism overall has got that variational free energy to maintain homeostasis.

You've got this energy balance piece, but you've also got that need for entropy.

So I wonder how this can inform us, just like people when we do, I don't know if you know about the Alexander technique, but it's when someone's, when you think about the body and the skeleton,

We think about it as just the bones, but actually it's really everything's held together in a muscular sort of watery soup and with the tendons and everything.

So there needs to be some noise in there.

That entropy piece needs to be there when you're going down the stairs and that.

You can't be frozen.

you're you're full yet you need to have some of that energy equilibrium because again you're full so there's i wonder how if we were to talk to someone out there about their life and their world um walking down the stairs what what would we translate this in their language alex if you want to give a thought on that


SPEAKER_05:
I'm thinking about it.

I'm not sure beyond saying that I do think that there's a balance of two sort of forces or quantities here always.

But this reminds me actually, I'm not going to try to put words in your mouth, but this reminds me of Adam of your remarks about free will in relation to degrees of freedom and entropy and stuff.

So

That's a segue, but it doesn't have to be taken up.


SPEAKER_03:
cool um yeah it reminds me of stream of consciousness or walking downstairs you can't just stop there statically you can't stop anywhere along the staircase and you can't halt the stream of thought so what is happening that's allowing time t plus one to be generated from time t the state only has to move by one moment at a time it doesn't have to do the ultimate um steady state to the lowest possible energy so adam and then anyone else raising their hand


SPEAKER_07:
um i re-read your uh paper last night and it's even better the second time um i'd like to actually talk to you later about like getting into the weeds about different um like mappings on the neural level of like between the thermodynamic and the informational um but uh before we move on i was wondering how you'd feel about um like

a multi-phase or a multi-part description of neural architecture where there's some aspects which might be more annealing-like and some aspects that might be more contrastive-like.

So you could, for instance, tell a story of some sort of predictive workspace where you can think of it as the model selection as iterative annealing, potentially, in terms of some of its aspects.

But then, like, it's just, like, around.

Like, you could think of, like, DeHane-style ignition event as you're generating this big high-temperature complex that then settles down and selects the model.

But this would just be, like, one of the things that's happening.

Like, something contrastive could be, like,

the thalamus, maybe orchestrating different cycles and comparing them, or the hippocampal system.

And that could be doing your contrasts.

Would that be copacetic, or would that... Right.


SPEAKER_05:
Yeah, no, that sounds awesome.

I mean, in general, it seems consistent with the way I've just... I've learned to see these things, you know, just paying attention to all these different sources of evidence.

It seems like... Yeah, this kind of...

It sounds right to me.

I guess my only uncertainty is the reason I focused on this contrast was in part because I wanted to argue for an identity between the

the free energy in the thermodynamic sense and in the variational sense relevant to variational inference.

And so I needed to make explicit the argument that whatever is going on, even if there's sort of a multiple timescales in which this is happening, or if there are different parts of the system that are in effect being annealed to different degrees,

that the whole thing... it's not plausible to think that the whole thing settles to, like, you know, the lowest possible energy state while it's alive.

So anyway, I don't mean to, like, deflect... I think what you just brought up is really interesting and you probably know more about the relevant, you know, neuronal mechanisms than I do, so I can't, like, critique that idea but it sounds, as you said, copacetic.


SPEAKER_03:
Yeah, Adam, you want to add something there?


SPEAKER_07:
Oh, I mean, yeah.

And I wouldn't want to like distract from like the point of like, if we, you actually, you have to not be at equilibrium.

You have to have this like open-endedness and dynamics to keep the process going.

But I, and I don't know like how productive, like sometimes like I'll squint at like different machine learning algorithms and like, you know, push them a little bit further.

It's like, you could think of this iterative Bayesian model selection.

It's like a kind of annealing, but that could like,

not be productive potentially, even though aspects of it could be described that way.


SPEAKER_05:
Yeah, well, that's a good, I mean, it's kind of a good way of framing it.

Like, I think this goes back to this cynicism thing.

Like, I think you can probably always re-describe something in terms of something else, but it's a question of how useful it is.

And I never exactly know where the boundary is, right?

What becomes just kind of a fanciful, like, philosopher's trick versus what's useful.

But the thing that you're suggesting sounds like it would be a useful way of thinking about things.


SPEAKER_03:
And when I contrast of divergence and annealing, when I think of annealing, I think of DNA in the test tube as you turn the temperature down.

So you come to a final frozen state that's like a fixed crystal, essentially.

Whereas the idea of contrast of divergence, it's more like cybernetics.

It's like a guiding and a navigation on a flow already.

And so even if you didn't have any divergence at all between your North Star and your header,

where you're going and where you want to go, you still would be moving.

And so in that sense, even if you're trying to minimize the divergence, there still is a sense of movement.

Whereas in simulated annealing, the idea that there's no difference is more associated with a crystalline or a static state.

So they have very different sort of teleos almost.

And for dynamic systems, that person going down the stairs, stream of consciousness, action selection in an uncertain world, that feels more like the cybernetic navigation rather than the DNA in a test tube, though those are just some aspects.

So Steven, and then Adam.


SPEAKER_00:
That idea of how things keep going and the dynamics, I'd be interested in your thoughts about how that might play out in...

in behavior or in the world.

So I could imagine annealing being a little bit like if things are trying to hibernate, there may be a state where they can go closer to like glass.

Glass gets annealed, basically.

That's how you plunge it into water and it holds that liquid state even though it's colder than liquid.

But the question I have is how do you...

reconcile some of these questions around where we can get caught in loops.

For instance, Caspar Hesp talks about depression, where you're seeing a lack of affordance in the environment, and that could be confirming your predictions.

You can get kind of caught in a loop.

And some of those challenges in computational psychiatry are

they're sort of low energy.

I actually haven't got an answer.

It's made me think, but they're sort of low energy states, but they're also like looping confirmationary states, you know, where you get a reduction in free energy relative to some, some sort of stick in the sand, um,

that has been established for the priors and the dynamics and then it kind of gets stuck in that you know be it you know hyperactivity something that's outside of where the organism would want to be but it's still going there and i don't know if that's quite the same as um going into the sort of a low energy equilibrium you're not going to it's not necessarily going down in energy it's sort of getting caught in a loop though of variational free energy


SPEAKER_05:
Yeah, that's really interesting, actually.

Sorry, someone else wanted to... Oh, no, Alex, go for it, and then after your thoughts, we'll go to Adam.

Yeah, so, I mean, my intuitive reaction is that, yeah, something like that happens in depression.

There's a sense in which it's a low-energy state.

In my paper, which is kind of like a sophisticated argument for a really simple-minded idea, I want to identify those two things and say, yeah, it's physically a low energy state as well.

But it's a local one.

So again, this is my intuition at the moment.

I don't know if it'll be borne out or if it'll work.

But it seems like sometimes in depression, maybe we reach like a local energy minimum in a certain part of the network or something.

But it's not part of an overall optimal state for the organism when it comes to behavior and things like that.

It's really interesting to think about how that happens.


SPEAKER_03:
Yep.

Thanks.

Adam?


SPEAKER_07:
Actually, to speak to what Stephen just mentioned, there's a, within like the psychedelic research communities, there's interesting models based on therapeutic change through annealing, where

Mike Johnson at the quality research Institute has something called like the neural theory or theory of annealing where it's the psychedelic state increases the temperature helps you to break out and then you can crystallize the new regime.

And Robin card Harris has described in very similar terms.

One thing about like generalizations of annealing that came to mind when Dan was talking was

Doug Hofstadter and Melanie Mitchell with their copycat architecture, they said it's different from annealing, but they had something that was kind of like ant colony optimization annealing, where there would be a temperature parameter for when your analogies weren't fitting.

And so you can think of like some sort of contrast of bits saying like, how good is your like matches?

How good is like these analogical matching, like discrete comparisons.

And then this parameterizes the temperature of a continuously adjusted annealing process that doesn't settle.

And more recently, really interestingly, from the beginning, the language was completely workspaced up.

And more recently, Melanie Mitchell has explicitly drawn a connection to the global neural workspace theory.

And so there could be a generalized annealing that has a contrastive bit and an annealing generalized annealing bit that does give you two kinds of psychophysical identity mappings, maybe.


SPEAKER_03:
And a total a total speculatory note would be sometimes we have, you know, accuracy minus complexity or pragmatic versus epistemic gain.

Maybe some decision making approaches are able to hold both together and maybe even rebalance between those different modes.

Dean, I'd like to actually go to 12 and hear a little bit more on what you thought about contrastive divergence before we head to the next topic.

So what did you see or find interesting on slide 12?

What brought you to that slide?


SPEAKER_04:
Well, I'd actually looked at stuff from Oliver Woodford before.

And so that was kind of why, again, I was connecting dots in my own head.

And it's interesting because the parts that Adam and Stephen just brought up, in part of our conversations offline, one of the questions I asked

Daniel and Blue was around the idea.

So you have the physical math and you have the statistical math and somehow they come together and make babies.

And that's what we kind of have here.

And so what is this project?

And all I liked about the, not to,

not to discount or put aside the simulated annealing piece, but to give what I think happens as a, for example, when the person goes down the stairs under control, as opposed to falling to their death, lowest energy state.

I thought that this essentially spoke to it by just giving a nice metaphor in terms of shining the torch beam in our chosen direction of travel.

which allows us to see the lowest point in the field in that direction, which I think Alex was again addressing.

I don't think, Alex, you meant to make this such a central point of your paper, but I thought in terms of trying to explicate the simple idea, the fact that you didn't

just focus on the fact that there's a gradient, but how does a person move down that gradient and not lose control was kind of what I wanted to bring forward here.

And in the notes at the bottom, which I can't see on my screen, there's a really nice explanation for what contrastive divergence does in terms of being an assistant.

That's why I want to bring that one forward.


SPEAKER_03:
Cool.

Alex, if you want to give a thought on that, and then Stephen.


SPEAKER_05:
I don't have much of a thought.

I mean, I think it's a really cool angle that you have on this.

And I think, again, it's something that's there, even if it wasn't my intended focus.

And it reinforces, I think, some of the themes that I was focusing on.


SPEAKER_00:
Thanks.

Stephen?

So what I think is quite useful

And I'm kind of bringing this idea of if I was trying to explain this to an arts practitioner or someone who does psychotherapy or something, how to explain the implications.

And one thing that I think is important here, when you talk about that energy minima, if I jump to the bottom of a hill,

I metaphysically I might know that I'm at a lower energy potential energy overall but actually I'll probably be at a higher energy when I hit the floor for a while right as I start to uh get stressed and perspire and assuming I'm not just completely squished to oblivion so you're in this interesting you know I suppose we do that on roller coasters a little bit but we we there is

there's what we are inferring about our states isn't what it is because we don't directly experience being at the lower energy state we experience what our sensorial states enable us to infer about the results of our actions so and then from that we compare that to our expectations

based on the stick in the sand or the big sticks in the sand, which is our phenotype, which is what we can then use as something to anchor against.

So I'm wondering, that has an implication about how people think about the world because of these types of ideas.

You know, there's a sense that they are...

connected and interconnected at the same time they're always separate in terms of being able to touch something because they're not touching something they're getting sensory data which makes them get that allows their model to predict what they've just done but they didn't actually touch in the way that people might think they've touched so i'm just putting that out there as some question


SPEAKER_05:
yep Alex go for it yeah that so there's there's this piece of what you keep doing Stephen you keep trying to make this like put like put all this in touch with like the body and the world and stuff and I'm like no let me just stay in my internal model and not worry about that but so I don't know actually I don't know if I if I understood the thrust of just like the last couple sentences but I think the point that there's the the fact is we don't we're not yeah we don't just want to like

leap to the lowest energy state possible come what may.

It's much more about the process.

And I think what you said about this thing being anchored in the phenotype and the priors in general is really important.

One, another paper that I wanted to write, or I don't know if it's a paper, maybe it's just a blog post or a tweet or something, but it's just on the fact that, yeah, so like you always have to bear in mind when you're talking about this energy minimization process that this is all relative to a phenotype, which itself embodies some amount of energy, right?

And so, in fact, you might even say that the stable phenotypes are some kind of like optimal

trade-off between accuracy and complexity right just in themselves um so there's this force that's sort of pushing up from below which is just the having a phenotype complex enough to predict anything and you have to work within that like those boundaries so i don't know if that really addresses your point because again i totally missed the embodiment part just like flew by me but


SPEAKER_03:
It's nice, just one point and then Adam.

So I really liked that example of a person or a body in motion going down the stairs and the difference between the controlled walking down the stairs or maybe even using an assisted mobility device and then falling down the stairs.

And both of them can't stop at one moment, whether you're tumbling or whether you're walking, you still can't stop there.

So it's always dynamical and you are going downhill and you are converting your potential energy into going to a lower energy state.

So those two are good ways to think about where does bodily control and motor coordination, which we'll talk about in 23 soon with embodied skillful performance.

But let's think about a mountain climber.

that's somebody who's actually contrastively diverging uphill.

And so that shows us that it's not just like the die is cast and then whether you fall or control on the way down, but there's a way in which going to the top of the mountain is like going downhill or annealing or reducing the contrast and divergence relative to your expectations of where you want to be.

And now you can imagine if the water level's rising, going uphill is the survival strategy.

So we want to have a way of describing where does control and bodily control come into the picture, going downhill, and then even generalizing beyond just bodies with mass falling in a controlled or uncontrolled fashion towards the kind of cybernetic planning that could actually result in a mountain climber, for example, going a little downhill and a little to the side and then making their way up the mountain.


SPEAKER_05:
so alex then adam then stephen yeah yeah that's really it's a really good point to bring up especially in this context of you know of the thrust of trying to simplify things by identifying physical and you know psychological things like no sometimes you want to climb the mountain so i mean my my my

immediate way of trying to summarize how that would work is just, well, you've got a strong prediction that you want to be at the top of the mountain, right?

That's your sort of desired distribution.

It defines your desired distribution over observations.

And so that's going to drive you to climb the mountain.

But I think that the way it does that is, proximally, is that there's going to be an actual

I would say an actual physical disequilibrium in the brain, right, that's caused by the discrepancy between your predicted state and the state that you're inferring from your observations.

And lowering that, you know, that potential is what drives the action of actually climbing the mountain.

So, yeah.


SPEAKER_03:
Cool.

Awesome.

Adam, and then Stephen.


SPEAKER_07:
Head's spinning a little bit, but hopefully this works.

Because like up, down.

But I'm wondering in terms of something like depression, could we think of it as like a very high...

local minima.

And if we thought of what we'd expect, so I guess, OK, what is it that's being predicted at which level of the generative model?

What's being predicted inactively between the organism and niche, and what's being predicted

over the whole skin-encapsulated organism, the brain, and then subsystems.

Ultimately, they have to come to some kind of harmony, but they could diverge.

But the idea would be thinking of

a landscape that when the energy is high, it might be more jagged and you might be more likely to get stuck at local, you're stuck at this local minima and you want to get to the really low one.

And so you could think of something like niche construction as looking for a catalyst to try to smooth out, make a more navigable landscape.

Or you could think of

the psychedelic would be like interning the heat.

So I'm thinking of the difference between like a thermodynamic versus a kinetically favorable chemical reaction.

So like you might like, yeah, it's theory if you can get from there to there, you come up ahead with the enthalpy, but you can't get there.

It's not kinetically favorable.

And so like the different things we're doing is trying to like find ways of getting kinetic favorability for this thermodynamic favorability and bring those into alignment.


SPEAKER_03:
Very nice.

Adam, you can build that bridge.

You don't have to afford the river or swim across, or you can just pray for the quantum tunnel to appear.

So I do Steven and then Dean.


SPEAKER_00:
Wow.

Okay.

There's something very quite important here, I think, because

Okay, we're minimizing this energy gradient.

Okay, that's fair enough, particularly for robots, which are using reinforcement approaches, and they're basically working on energy gradients.

And then you've got the idea of, okay, you can work with variational approaches, i.e.

more like this

Gibbs free energy where the reaction can slightly have entropy.

But the big key thing as well, if you're going to take your agent, is that we're at the level of the chemistry is the chemistry is all non-equilibrium chemistry.

So the whole of the Gibbs free energy is built on equilibrium chemistry.

Here we've got non-equilibrium chemistry when you get to the level of the organisms and cells and everything.

I think what's an interesting point here is, so you're going down the stairs, you're trying to fall over, you're being a rock climber.

So overall, there's this energy piece around how the agent moves.

But for the agent to move, unlike a robot where you might have little...

pistons the actual cells in that are operating at this non-equilibrium state and quite how different actually this gap between these attractor basins versus energy basins which we normally think of i actually don't know i don't know i'm interested to ask carl friston that like what is how how much does it shift things to have any basins to do with the tractors as opposed to just basins to do with energy like equilibrium energy gradients

And that's the thing that's different in terms of what's really going on when I'm climbing a mountain or that, is all my muscles and that at the actual level of making things happen are swarming and trying to enable this kind of biological process to happen.

And okay, from a system perspective, I can see the energy being less for me falling on the ground, but for my muscles to move and everything,

they're operating at this non-equilibrium process, which will have energy impacts, but also has some other types of dynamics which you don't have.

You have this non-equilibrium steady state dynamic, which you don't get in traditional chemistry.

So there's something there.

I'm not saying I expect an answer on that, but I think it's an important point that seems to be a gap, and it really shone out for me there.


SPEAKER_03:
Nice.

Thanks, Steven.

It's kind of like if it's a ball at the bottom of a bowl, then that's the annealing.

It's the crystal state with the ball and the bowl.

But then if you have a neuron that's holding a resting voltage, that is being actively maintained with an enormous expenditure of energy.

But it's its own kind of bowl

that it's converging to, whether it's above or below its set point, it still is doing a type of convergence, but it's a dynamically held state.

And you're absolutely right that sometimes the lower level entity or the entity which the larger one is composed of, they have their own active dynamics, even when the top level system is at rest or appears to be unmoving.

So Dean, and then we have a few other fun topics that we'll get to.


SPEAKER_04:
Well, I'm going to see if it's okay to ask Alex to jump to a third rail at this point, because I'm really, really curious about the modified Ramsey sentence aspect of his paper.

And what I was hoping he might be able to speak to a little bit about is not just what the Ramsey sentence is talking about, but the implications in terms of different time intervals and what role that plays in us being able to understand how

the modified Ramsey sentence works in your paper.


SPEAKER_03:
Perfect.

I switched to that slide 44.

So yeah, I was definitely curious about that as well.

Alex, what does the Ramsey sentence or this entire area of formal logic, how did that come into play?


SPEAKER_05:
Yeah, so, right, I kind of trumped up the Ramsey sentence thing in the last episode, but it's kind of silly of me because there's not a whole lot to it in a way.

But then maybe that's just how it seems to me from the perspective of where I'm coming from.

But the reason this is in here is that the whole identity, the philosophical mind-brain identity piece of this was based on

I was mostly inspired by David Lewis's approach to that topic.

And so there are a couple of influential approaches.

There's Lewis's and there's Smart, I guess, are the two big papers.

But basically, what this piece of formal logic is doing is just trying to capture what a theory says about the entities that it sort of implicitly defines or how you could get from

this isn't all explicitly spelled out graphically, but how you could get from just a collection of statements that you might have sent to about whatever the topic happens to be, in this case we're talking about mental states, from that to a theory that's expressed in general terms and that, again, implicitly defines the entities that figure as the values of these variables here.

Um, so the re so, I mean, we could briefly talk about this, I guess.

Is it useful to go over this?

Yeah, you guys.

Yeah.


SPEAKER_03:
So, um, read out the sentence, um, or translate it or provide an example.


SPEAKER_05:
Sure.

So I guess I'll start with just the Ramsey sentence, so we can talk about modified versions in a second.

So the first symbol here, as you guys discussed in point 0, is just an existential quantifier.

It says there's some x such that whatever follows.

The second symbol is a universal quantifier over the variable y. So it says there's some x such that for all y, blah, blah, blah.

And here, T, the predicate, is just literally, like, so say that you had a collection of platitudes or, I don't want to complicate things, just a collection of statements.

Like, when I see

When I see a cat, I'm happy.

When I think about happiness, I tend to think about sunshine.

Things like that, right?

Just some examples.

And so you just conjoin all those.

Just put an and between all of the sentences of that type that you could think of in this domain.

In this case, it's folk psychology.

So then you'd have a long sentence, right?

It's a giant conjunction now that has some terms that refer to mental states like believe, arguably see, although maybe some people would interpret that as a physical state.

There's definitely blurriness here at the edges.

But in any case, things like believe, desire, think, these are clearly mental state terms, right?

So you'd have this long sentence that has those terms and also other terms.

And so essentially you just, you replace each of the...

terms in question the mental state terms with a variable and what's left over is the predicate that defines what the sentence is saying about those the values of those variables right and then you just append these quantifiers to the beginning um just to to sort of spell out um what your what kind of claim you're making um about the states in question namely there is such a there is something such that it relates to all other things in this way

And so that's the basic Ramsey sentence.

It's just a, it's an abstraction that allows you to spell out in formal logic and first order predicate logic, like what a collection of sentences says about something.

And the last piece here is the, so there's the if and only if, the three bars.

That's the Russellian uniqueness condition.

So this goes back to Russell's theory of definite descriptions.

So like I got, I mean, my start, by the way, was in sort of philosophy of language and stuff.

So that's why this is in here.

I came to all this sort of statistics and physics-based stuff much later.

So Russell had this theory of definite descriptions that he was trying to explain how you could have a meaningful expression like the present king of France, even though there is no such thing.

So how do we philosophically handle failures of reference and things like that?

And so his suggestion was that you can think of definite descriptions like the present king of France

just saying, well, there is something such that it is a present king of France, and there's only one of those things, right?

So it's like a uniquely satisfied description.

And so that's what this end part does here.

It says, this predicate T, which encompasses all of the implicit folk knowledge about mental states in this case, holds of something only if that thing is equal to X. And so one last piece that's important here is that

I took the bold letters here, x and y, to be vectors, essentially.

So we're talking about many different mental states in parallel when we do this.

But if you want, you can just think of it simply as being about one mental state, but then you generalize to all of them.

So I don't know where.

How clear is that?


SPEAKER_03:
it's it's let me try a uh little bit of a physical example it's like there's the stream of consciousness the stream of statements what you said with an ant i saw a cat or photons hit my eye and i perceived a cat so one of those is more of a physicalist claim and one of those is more on a mental side and it's almost like we're going to draw a line around the mental claims

just so that they can be definitely interfaced into a form of logic, even if the contents of that mental experience might not even have a reference in the real world, or it might not be something that exists in the same way that those photons hitting the eyes exist, but it allows us to interface with those kinds of statements by agents in a formal logical framework.


SPEAKER_05:
Well, I mean, I guess one part I'd push back on a bit is, I mean, this sentence here clearly states that this X exists, whatever you take that to mean, right?

So it could be that there's different criteria for existence, right, in different domains or something.

But it definitely says that there exists something such that it's related to all the other things of this kind in the ways that are specified in the predicate.

So, like, yeah, I think...

I think the main, I guess the main point here, so I focused on the Ramsey sentence because people were interested in it, but like the main point is just that you can take all the things that people say about mental states as implicitly defining them in a sort of theory, right, and that that's

that's um and so lewis used this explicitly in the context of trying to identify mental states with brain states right so just to i'll just say a little bit more about this piece and then i'll shut up for a bit but like um if you have this network of relations that's described by a sentence like this uh you can take that as implicitly defining the mental states while being neutral about their sort of ontological character right so um so it could be then that if you do some you know neuroscientific investigation and you find hey there are these

you know states in the brain that are they seem to bear the same relations to one another that these mental states that we were talking about bear to one another uh you know lewis says well then because this the sentence says that the mental states really are just the things that uniquely realize this structure of relations well you've just empirically discovered the mental states um so it's a really cool way of

theoretically bridging something like psychology, intuitive folk psychology, and neuroscience.

And Lewis's point was, once you have this structure, if you could extract this structure from folk psychology that's implicit in it, and if you made the empirical discovery, there'd be no further bells or whistles needed to say that there's an identity between them.

Because that's just what the sentence says, is that the mental states are whatever things satisfy this description.


SPEAKER_02:
Very interesting.

So Dean, then Steven, then Adam.


SPEAKER_04:
Yeah, so Alex, I mean, as it's written out here, it's really stable.

And I'm really curious, because I really don't know this.

Do different time intervals, like really, really short time intervals or longer time intervals, if I've got a day to go down the stairs versus I've got one second to decide whether the 96-inch drop is less harmful to me than the lion that's chasing me, do time intervals affect


SPEAKER_05:
the stability of this right yeah so sorry i neglected that part of your comment earlier um i think no is my short answer i think that this is meant to be a static a static sort of description of a of a implicit theory right which which will include statements about short time scales and long time scales so i would say that that anything about time scales

in theory, should be captured by the folk psychology that you embody or that you have in mind at the moment.

And that might change from one time moment to the next also.

This doesn't need to be a temporarily static structure.

So maybe that speaks more to your point.

But I think the possibility of spelling this structure out, even for one instant, is the lever that Lewis uses to draw his philosophical conclusions.


SPEAKER_04:
OK, thanks.


SPEAKER_02:
Thanks, Stephen.

And then Adam.


SPEAKER_00:
This question about prediction and time, I think like you were just saying, there may be a sort of time scale at which things are just flowing.

Like what sort of speed is it that...

Things are just doing their thing, i.e.

cells are doing their processes.

But what Dean was talking about is longer timescales than that.

And I think, like you say, there's something different there.

Everything beyond a certain point has to be imagined, I suppose.

Anything that's not possible to do variational free energy on, you've got to do expected free energy.

And to do expected free energy, you basically have to imagine things.

imagine in a different way to just our limited sense of imagination, like our body has to imagine at some level the expected free energy, basically what expected free energy is.

So I think that then does bring in some interesting ideas around folk psychology.

Would you say that those mental states can ultimately be

action and sensory states that are being predicted so the mental states are basically the recapitulation or expectation on sensory states and resulting beliefs on action states so they they could be seen as mental states but actually there is a more distributed realization of that i'd be interested if that that sort of is something that could hold


SPEAKER_05:
Yeah, I mean, I think the spirit of Lewis's proposal is also functionalist, right?

So the basic idea of functionalism, of course, is that mental states, in the philosophy of mind, is that mental states can be defined in terms of their relations to inputs and outputs and also to each other.

And I guess it's the to each other bit that distinguishes it from behaviorism.

But yeah, I think that these implicit definitions that Lewis talks about would rely heavily, it would depend heavily on

Things like when I believe that there's a cat present, I expect certain visual appearances to occur and I'm disposed to act in certain ways.

And maybe you want to cache the... I tend to want to cache the actions in the sensory step out in terms of proximal stimuli and like motor effector states rather than distal things and extended things, that's just...

I don't know.

I don't know if it's a bias or what.

It's just the way I tend to think of these things.

But definitely, I guess I would say that the relations between the mental states, though, are just as important as the relation to the active states and the sensory states when it comes to this kind of formalism.

I feel like I missed an opportunity to... It was a really interesting comment, actually.

I don't know if I did it justice, but I'm still thinking about it.


SPEAKER_00:
Can I just add one little thing to that just before... Yeah.

Okay, very quickly.

But one thing that sort of comes to mind that I think might connect what you're saying, you were talking about this and, and, and.

So there seems to be something there about...

the combination of ands and what's, you know, so for instance, and there was a dog and there was a woman with the dog and we're in the park and the dog was wagging its tail and then there was blood on its teeth when it smiled and I'm like, suddenly that's changed it, right?

So the triangulation of the ands

flips once you suddenly the dog bares its teeth and you see blood on them right so that links into what they do in qualitative research where they often triangulate to get something which has got trustworthiness rather than accuracy and I think there's something interesting there about

what you're saying in terms of that.

My knowledge of that field of linguistics is that if I can bring it back into embodied work, I find it easier, which is what I'm trying to do.

But this and, and, and, that has got some practical applications, I think, in a number of areas.


SPEAKER_05:
Cool.

Definitely.


SPEAKER_03:
Yep, thanks.

Adam, if you can return.

Yep, okay, go for it, Adam.


SPEAKER_07:
Hey, making coffee.

So...

Eventually I'd like to get to free will and actually loop around a little bit to actually depression as a case with respect to that.

But before we move on from Ramsey's sentences,

Not to belabor it, but is the idea that you strip away the specific entities being signified, you look at the syntax, and then you're saying, can the same syntax apply in another system?

And then you have the mapping that this would be the map.

So is that the basic idea?


SPEAKER_05:
Essentially, yeah.

If you take syntax in a slightly broad sense, then totally, yeah.


SPEAKER_07:
Okay, so I guess I'd be wondering, like, in terms of, like, active inferential modeling, would it be something like with, like, the graphical brain?

Like, you have, like, this Forney factor graph where you have, like, the continuous regime down below, but then you have this, like, discrete regime up top.

And, like, maybe something in, like, the factor graph portion, you could look for, like, some sort of, like...

of homomorphism or isomorphism there.

Or if it's the brain, you would look at ensembles and describe them as attractors moving along some sort of manifold.

And then when you coarse-grain those or throw a blanket around them or reify them in some ways, if the syntax of their interrelations matches people's subjective reports of their experience,

then you would be able to actually potentially identify physical and computational substrates of consciousness.

I mean, yeah.


SPEAKER_06:
Is that a bridge too far, or is that where we're going?


SPEAKER_05:
I think that's where we're going, except I never made the bridge all the way to consciousness, because that's one thing that I reserve the right to not decide about.

I think your work on this is really cool, actually.

I kind of suspect that most of the main theories of consciousness kind of overlap a bit, and there's a core that's, you know...

that's sort of like uh getting at the way things are which i think you've written about but um so so i want to just bracket the consciousness thing for a second although maybe that totally ruins it for you i don't know but like yeah but that's that's exactly the idea like i think you just expressed it very well that um if you look

with, yeah, you have to squint, you have to do some coarse graining, but if you look at the dynamics of the physical system, you'll be able to discover, in the ideal case, some of the same sort of syntactic relations that you would get from the psychological perspective.

And I think that's also very consonant with the way

know connectionist modelers describe their work sometimes so like you know you think a connection is a simple you know neural network made of these simple processing units uh you can derive that architecture just by looking at the brain and sort of very much simplifying things or you could derive the same graphs in some case just by looking at cognitive processes and so you know it's the idea that you have two perspectives on one thing exactly


SPEAKER_03:
you have a graph isomorphism then that is what was being hinted at with it being sufficient to find that there's relationships amongst mental states like i always feel like i feel this way before this other feeling and then if you found that there was some brain state that always preceded

Is that the end point or is there still more to explain in that context?

Let's actually get to another topic that we highlighted last week, which was the sleep wake example.

So I'm here on slide 40 and we're considering a system whose analysis is tractable, at least according to Alex.

And we have an agent whose behavior as far as sleep wake is concerned is defined by equation 3.1.

So could we walk through what is happening in this simulation?

What is the agent doing?

What does the agent consist of?

And then what does the equation show?

And then how does that relate to what we're showing in this paper?


SPEAKER_05:
Sure.

So I think this is another aspect of the paper that was

maybe seemed to be making a deeper point than it was.

But I'll just talk about this briefly.

So this was actually just meant to be sort of a slight modification of just like a Helmholtz machine running the wake-sleep algorithm.

So I don't know if I need to set that up.

Blue talked about that a little bit in the point zero.

But the idea was if we just have a generic, we have a neural network that has a generative model that's sort of encoded in its top-down connections and an approximate recognition model in the bottom-up connections.

So one way of doing this is to run the wake-sleep algorithm, where you basically generate states of the network top-down, like fantasies, right, functionally speaking.

And then you adjust the bottom-up weights so that they're likely to produce those fantasies.

And then you alternate this with a... So that's the sleep cycle.

You alternate this with a wake cycle where you use an input of the kind of sensory data that you want the model to learn to...

generate, and you do a bottom-up pass and then adjust the top-down generative connections so that they're more likely to produce those states that are induced by input.

So all I was doing here was saying

look, if we suppose, just make the assumption that this is a real system we're talking about.

It's ridiculously unrealistic, right?

So that's why I said it's something that's tractable to analyze, but it's also quite a far cry from anything biologically plausible.

But it's also not completely off the mark, right?

So I think there's a reason that the Helmholtz machine was kind of like,

a seminal moment in the evolution towards what we have now.

Because it got a lot of the coarse-grained sort of conceptual structure really down that I don't know if it had been pulled together before in this form.

Anyway, so let's suppose that the wake and sleep cycles of that machine occur with equal probability.

then we can talk about probabilities of certain states occurring in the network, just period, right?

Whether it's during a sleep or a wake cycle.

And so if you just grant, if you ignore the fact that this is a really only, it ends up being an approximation to an approximation, right?

So it's wake, sleep, wake, sleep, wake, sleep, wake, sleep,

ends up being a sort of an approximation to the EM algorithm, which is itself not quite full variational Bayes.

So anyway, lots of approximations, but if you ignore that for the moment, I just wanted to make the point that you could talk about the,

you can thoroughly, completely characterize the probabilities of various states of the system.

And so you could use that to define this.

This R here is just the probability of a certain state, of the system being in a certain state.

I hear the SI is referred to like the states of the individual neurons, but that's related in a simple way to the overall state of the network.

So you can talk about the probability of the system being in one of these states, regardless of whether it's running a wake or a sleep cycle.

And then that gives you a, if you have a probabilistic description of the states of the whole system, then you could use that as, to define the relevant terms in thermodynamic free energy.

So the entropy and the energy and such.

So that's the basic idea.

But the part that you were wondering about, what is this system simulating?

What does it perceive and such?

This example is completely agnostic as to any of those details.

So once again, this is highly, highly abstract.

And I apologize.


SPEAKER_03:
No, it's cool.

And what do you think this model would allow us to continue developing towards?

Or what does it show for the argument that you put forth as far as the psychophysical identity thesis?


SPEAKER_05:
Right.

Well, I don't know that it shows anything in itself.

I think what it was trying to do was write down a system in which the target would be clear.

So you want it to be the case that this R distribution

so so let me put this way so the r distribution because it's it's essentially made up of or it's it's factored into these wake and sleep cycles right those have direct um interpretations in terms of variational free energy and inference um and yet we have a well-defined distribution over the states of the system that we could use to describe its physics so i just wanted to show that there's one simple case where

where we can write down a distribution that bridges these two descriptions.

And then in the subsequent paragraphs, I try to argue that we can generalize this beyond equilibrium.

And that's the very tricky bit.

And I don't claim to have shown it by any means.

I'm just, again, I was trying to remove obvious obstacles to this being true.


SPEAKER_03:
Awesome.

So Adam with a raised hand, and then Blue, or if anybody else wants to go for it.


SPEAKER_07:
In terms of wake-sleep, there could be some potentially biologically realistic implementations of something like that.

O'Reilly has a paper, Deep Predictive Learning, where he describes a model of the thalamocortical system doing predictive processing that's very wake-sleep-esque.

I'll send that to you.

I'm curious to know if you thought that was a good psychophysical identity mapping there.

The other thing would be if we think of experience as being the ramification of experience, the mapping would happen at the level of predictions.

And if the predictions are the sleep part,

Is there a sense that experience is always, kind of paradoxically, it's always the dream?

Like the awake part is the stuff that's just updating it, but the actual thing generating the experience is the dreaming part.

Is that correct?


SPEAKER_05:
Yeah.

So I have an unpublished paper on this, too, on the representational division of labor.

So people in predictive processing literature say things like, yeah, we experience our expectations of the world or whatever.

But I'm not so clear that it's that way.

I don't know.

I guess if you think that the predictions are the carriers of the experience or the neural correlates of the experience or something, then that would be the case and the wake cycle would do nothing.

But I think it's, I don't see the reason to embrace that interpretation of what's going on here.

Because it's awesome.

No, I mean, I'm all about the idea that we experience sort of virtual models in a way, right?

That's cool.

I don't interpret that in terms of, like, it's just the top-down driving signal that leads to experience.

Although, maybe, I'm not really against that either, and I can see why you'd want to say that.

Anyway, I just don't think that there's any inference from, like, the Helmholtz machine to that.

Like, because...

And I would love to look at this paper you mentioned, by the way, on biologically plausible versions of this, because I think there's a lot that's right about it.

The reason I say it's so impossible is just that it doesn't have any role for top-down modulation of bottom-up signals during perception, which was by design so that it would work quickly.

But that's the main limitation that concerns me.


SPEAKER_03:
Cool, thank you, Alex.

Stephen with a raised hand, and then anyone else, and also anybody watching live, you're more than welcome to write a question in the live chat.

So Stephen, go for it.


SPEAKER_00:
Just to help me clarify, so this being a tractable analysis, so the key point is that by going to stochastic, it shows in principle how...

recognition and generative densities can be used together.

Is that the kind of the point that this shows?

And just because I'm struggling, I think I'm just I'm not so good with the formulas and exactly get it.

But I think the general point you're making is that you're going to stochastic algorithms.

And therefore, you've got this potential for the recognition and generative density, which is basically sensory and

potentially, to be reconciled and shown even a very simple case.

Would that be a correct reading of it?


SPEAKER_05:
I think so.

I think definitely it's in large part, right, so the idea that we're dealing with a stochastic system is kind of important because, yes, I want to claim that, or I want to advance the suggestion, the possibility that probabilities are encoded by probabilities, so then you could have an actual identity.

Whereas if you're just encoding, like, if you're using, like, I don't know, the

a scheme that's more like what Carl Fristen talks about often, where you have sort of neuronal states that are encoding the sufficient statistics of the distribution, then I don't think you could get an actual identity because you'd have a clear representation that has a certain

almost convention built in of how things are represented.

Whereas I'm arguing for the possibility of a much more direct encoding.

And that does depend on this being stochastic.

But the other part of this that I forgot to mention that sort of I think maybe crystallizes the point this is trying to make is that if we're at equilibrium with respect to the network, if we're at the Helmholtz machine's equilibrium distribution, then

In that case, if you do take R as describing the physical probabilities of the system that you would use to specify the thermodynamic properties, then you could show that in that case, at least, the variational free energy and the thermodynamic free energy would be the same.

And then generalizing to non-equilibrium, of course, is the hard part.

But that's more concretely what I was trying to show there.

Yep.


SPEAKER_03:
thanks so i'm gonna go to a question from the chat and then we'll go to adam so cambridge breaths asks can this model describe or map the transition between focused attention and mind wandering grateful for any elaboration thanks everybody um anyone want to take that i i


SPEAKER_05:
I don't know.

I don't know.


SPEAKER_03:
Yeah, I don't know.

Just maybe the dream versus the sleeping versus the waking.

But then even within the waking state, we have a wandering phase versus a very tightly focused phase.

So there's sort of what is happening, if that reminds you of anything.


SPEAKER_05:
I mean, I'd say if we're talking about this model, talking about the Helmholtz machine or this slight elaboration on the Helmholtz machine, then I don't think it would do anything that sophisticated just because... So as Adam says, there are biologically possible ways of implementing this kind of thing, but anything as fine-grained as a shift from attention to mind-wandering, I think...

It's probably going to be left out of a model that's at this level of sort of abstraction and approximation.

That's my thought.


SPEAKER_03:
Thanks.

So Adam, then Blue, and then anyone else with a raised hand or a question in the chat.

Adam?


SPEAKER_07:
Not sure I can address the mind-wandering exactly with psychophysical identity, but in terms of the mountain climbing analogy, I'm wondering if it's like...

mind wandering is kind of like exploratory hill climbing with a little bit of quantum tunneling, something like that.

But that's a, I mean, what you would think, actually, it might loop around to the brain in an interesting sense.

And that there's, like, if we think of, like,

lower levels of like a cortical hierarchy as doing something more like, um, uh, variational inference, uh, via like continuous message passing, maybe with like some discreet updating there too.

Um, so.

That seems to be one kind of implicit representational regime.

There might be a sense in which you're getting probabilities in terms of the attractor dynamics along this hierarchy corresponding to probabilities of a hierarchy of nested events in the world and a deep temporal hierarchy and the deep temporal hierarchy of the latent causes of the world.

But there seems to be potentially, as we move inwards, another level where these get re-represented into more like, when you go into deep association cortex, it might be a different game.

And then when you're getting coupling with the hippocampal system,

Now it seems like you're getting something almost like explicit syntax with discrete semantics.

Because you can map, there's these pointers going from the relationship among these, you call them bump attractors, the hippocampal system, or these place cells.

But they can be used to contextualize the whole overall system within some sort of structured syntax.

Um, I'm, I don't, I don't know, like, would, do you need something like that to have the probabilities where, for, um, is that what you're looking for?

Or could there be more like this, like an active hierarchy of, uh, like a hierarchical Boltzmann machine that has a nested type of cause there.

And that those are probabilistic, like both do it or would only like the re representation.


SPEAKER_05:
Yeah, I don't know.

I think a lot about this issue of re-representation and how much, you know, if it happens and what it's doing and stuff.

But I think... I guess I need to understand more, and this is totally just my ignorance, about the kind of models you're describing with hippocampus and such.

Like, I tend to think of...

I tend to think of semantics in the brain just in terms of vector space models.

And so I'm just curious.

I don't know if we could talk about it now for a bit, maybe.

I don't know.

It's up to Daniel and others.

But what is the explicit syntax in this case?

It sounds like something that would be friendly to what I'm trying to do.


SPEAKER_07:
Um, so I guess like, uh, so this explicit syntax, it's like still heavily researched.

There seems to be kind of like a gold rush, uh, among different.

Like AI companies and like cognitive labs are trying to figure out the hippocampal system, like deep mind.

This is kind of like what started them.

It was like, it's like.

making discoveries about this.

But the idea would be that you have this graph structure that would be, that originally would have evolved for just locations in like meat space or physical space, but then got repurposed for any kind of space.

And so this gives you like structured state spaces, whether you're navigating through the world or you're navigating through like a spatial topology.

And this would basically, the content would be these,

And so it would be at the top of the cortical heterarchy.

And it would have pointers that could be unpacked in terms of these more modes of inactive engagement.

There might be another intermediate level that could be associated with consciousness where you're getting more concentrated attractor dynamics with potentially a quasi-topographic relationship

to events in the world.

And so the principles there, graph neural networks might be relevant there, where basically you get this orders of magnitude greater representational efficiency by actually making the geometry of the system over which you're doing the deep learning

resemble the thing that's being uh modeled so like um there's like graph uh grid neural networks that could be used for like spatial modeling or there's like graph mesh neural networks that could be used for like uh modeling of like someone's po like a pose of a thing or an object and so in theory some things like this might form at the intermediate level and these might be the ones they're most heavily coupling with this hippocampal system which is giving you this syntax of state transitions

with structured composition.


SPEAKER_05:
That's really cool.

Can I comment on that for a minute?


SPEAKER_03:
Yeah.

Alex, go for it, and then Blue.


SPEAKER_05:
okay um yeah so there's a lot there that's that's exactly along the lines of what i've been thinking about this i've written a bit about these like conceptual sort of grid cell type things uh that it seems like there's a lot of evidence for that it's really awesome i know like numento is doing some research that's related to this stuff um so that's okay if that's what you mean then i'm totally on board like i wasn't sure if you meant that or something more language like with like discrete tokens with

other parts.

But that might be encompassed by this as well.


SPEAKER_07:
It seems like people are finding also encodings of the hierarchical structure of the grammar of language is also encoded.

It's found to have a correspondence with the structure of the relationships of these bump attractors.


SPEAKER_05:
That's amazing.

Yeah, I was going to mention also, so you gave all these examples of neural networks that are sort of isomorphic with the domain that they represent.

I was going to mention recursive neural networks used for language processing as well.

The network topology matches a syntax tree or something like that.

So that's very much along the lines of where this is going.


SPEAKER_03:
Thanks, Alex.

So blue, and then Dean afterwards.


SPEAKER_01:
So I want to kind of loop back around to what Adam said about dreaming, because he totally took the words out of my mouth.

But maybe also touch on the question that was asked by the person in chat about mental wandering.

So is it possible?

So Alex, your objection to the dreaming and the physicality was that there's no evidence for top-down control during the wake cycle.

Is that correct?

Is that what I heard you say?


SPEAKER_05:
Sorry, no, I actually meant to say kind of the opposite.

I meant to say that the problem with the Helmholtz machine as a model is that it doesn't model top-down effects during waking perception.


SPEAKER_01:
Right, and that's what I interpreted.

Okay, so if it doesn't model top-down effects during the wake cycle, is it possible that maybe there are overlapping Helmholtz

functions happening right like so you know your mind wanders off or you're not paying attention and like maybe you're consolidating like you're you've got like one set sleeping one set waking and there's maybe like an overlapping construct of this like wake sleep learning cycle happening like while you're out mental wandering i'm consolidating you know the information from you know what i learned at breakfast or or something like that


SPEAKER_05:
Yeah, yeah, I mean, I think there's I think there there are like like this model is adjacent to like many really interesting, plausible variations, right?

And slight elaborations.

So like what you're talking about sounds to me like in that vein, like I saw amazing git repository of just like.

Helmholtz machine variations, where they just tweak certain parameters, like let's see what happens if we propagate a few steps down during the wake cycle as well, things like that.

So I think, I don't know.

I don't know if I fully grasped exactly what you had in mind, but it sounds pretty good.

And thanks for, I mean, go ahead.


SPEAKER_03:
Oh, no, Alex, go.


SPEAKER_05:
Oh, no, I was just going to say thanks for also trying to address the comment, because I felt like I wasn't able to answer it very well.


SPEAKER_03:
nice and there's definitely um wandering in dreams and how is that different than the wake wandering and could that get at what the difference is between sleep and wake and could this model maybe give us a bit of a wedge to enter into that discussion so dean and then anyone else with a raised hand so alex


SPEAKER_04:
Back to analogizing.

So I'm reading your paper and I read something and I go, well, my goodness, look, there's the world's biggest nickel.

And then I continue reading and then, oh, look, there's the world's largest corn cob.

And then I have a chance to have a conversation with you.

And you're like saying to me, well, let's bring this back into some sort of proportionality.

So explain to me what is the

two-carat deep diamond that you were trying to allow readers of your paper to get to?

Because I know I blew it out of proportion because when I first read it, it was a big deal.

But maybe you can help me bring it back into some sort of scale as to what was your deep hope here?


SPEAKER_05:
Yeah, it's interesting.

No, I mean, I didn't, I don't, I also don't mean to suggest that you got it wrong or anything with, I think the proportion, you're finding interpretations that are consistent with what I said, you know, it's not like it's not there, but it's funny that if I'm trying to, if it seems like I'm trying to put that, you know, to put things in proportion or ground it in any way, it's kind of funny because I feel like other others are trying to, are trying to do that.

Like,

you know, relate this to embodiment and activism and things much more concrete.

And I keep trying to keep it abstract.

But anyway, the main... I don't know what the hope was here.

I think...

Yeah, I'm not sure.

I think I just really wanted to point to the possibility.

It was really about this identity thesis, which I'm not even sure that a priori I agree with, by the way.

I'm not sure that identity theory is the way to go in understanding the mind's relation to the brain.

I'm not really a reductionist.

But it seemed like there was a possibility of articulating a quantitative version of that

right, using the tools that we've developed over the past several, you know, couple decades that Lewis didn't have access to.

And I just really, I just love David Lewis as a philosopher.

I think he had some amazing ideas and I wanted to, and it just seemed to me, it's not so much that I wanted to show anything in particular, it just seemed to me that there was a natural convergence here that could be spelled out.

So that's kind of what I was trying to do.


SPEAKER_03:
Thank you.

So Stephen with a raised hand, and then anyone else who raises their hand, and also in the last half hour or so, anyone who wants to ask a question in the live chat.

So Stephen, then Adam.


SPEAKER_00:
I was just tying in a bit with what was also said by Adam around the hippocampus.

So you've got the place cells in the hippocampus, which gives some way to bring the environment in, potentially, in this semantics.

I'd not heard it thought about as semantics, but a semantics of place, if that makes sense.

So now we've got our environment external states potentially being brought in in an attractable way.

You've got action states, could be the grid cells with the what-ness of what's out there.

And the sensory states is this lower level flux that's coming into the bottom of the brain.

And then the generative model would be the higher level

kind of, well, I'd be interested in what the generative model is in all of that, if that makes sense.

If we were to play in that sandpit, it would give that way to bridge, I'm a big fan of the hippocampus, but I'd love to see how it all fits in with some of these pieces.

But I'm just curious around if that kind of

role for these grid and place cells could be quite useful to do this tractability between higher and lower level states.


SPEAKER_03:
Sure.

Alex, if you have any thoughts there.

Otherwise, I'll go to a question from the chat and then Adam.


SPEAKER_05:
Yeah, I mean, I guess just really briefly, it seems to me that if we are using these place cells in this sort of, we've leveraged this thing that was originally meant for physical spatial navigation, and we've transposed it to like conceptual spatial navigation, essentially, that's really cool.

I could see it being the sort of the thing that conditions expectations for the sensory motor stuff.

And it would just define the generative model, I guess.

The dynamics at that highest level would be the thing that sets the set points for things.

But I think Adam might have more to say.


SPEAKER_03:
So just to the question, which is also for Adam, says, thanks.

Adam did mention that the transition process probably involves quantum tunneling.

May I ask if he thinks the same for the transition from mind meandering back to focused attention?

So Adam, feel free to take up that question as well as anything else you'd like to add, and then anyone can raise their hand.


SPEAKER_07:
Oh, boy.

I guess there's a sense in which one of the quantum tunneling events, I guess I would have in mind,

there'll be like these regimes of sense making where the hippocampal system will lay down a given tiling of the hippocampal system in collaboration with the entorhinal cortex with the grid cells will lay down this tiling of some domain within which you're doing this modeling with where you can get basically the relationship among these bump attractors.

You can get this like structure, the syntax and through the pointers, the kind of semantics.

And also with themselves having a semantics of space maybe just in the relation.

But the, so I guess the quantum tunnel, like, so, but then if you get enough prediction error from the overall system, this seems to trigger these resetting events where you'll break up the frame and then you'll do a new tiling.

And it's kind of like a re grip on the active inference.

It's like a new kind of engagement, a new set of policies that could fit within this different,

conceptualization of the safe space you're working with.

And so these events of remapping, I guess you can maybe think of them as like the quantum tunneling.

It's like, you're just, you're not doing, I don't know if this works, but it's like, they're called like, some people call them like levee flights, like an animal's like foraging in a patch.

And then it's like, eh, and it'll just like jump to a greater patch once it's like not getting enough.

And so it'd be like, you're kind of like imagining in this place and you're simulating this place.

And then you're like,

okay, a little bit bored, not quite the thing.

And then now you're imagining something else.

Then you're imagining something else.

I guess you can think of those as like quantum tumbling.

Like you're not just like working within one regime of simulation, just fixing that thing.

You're moving from here to here to here.

But the question I had when I raised my hand was,

So there's a sense in which you might think of predictive coding style models of cortex.

I know it's more complicated than predictive coding.

But there's a sense in which something like that is probably true.

Because if you do a primarily suppressive regime, you end up inducing sparsity.

And if the events that are in the world are clocking slower than your internal updates, you come out ahead in terms of like,

I mean, that's why they did it for video coding.

It's just more efficient.

And so I'm wondering, is that enough to give, like, a psychophysical identity mapping in terms of, like, there's a sense in which you will minimize predictive coding mechanisms to the extent we go with just those.

They should minimize activity.


SPEAKER_05:
Yeah.

Yeah, that's actually kind of where I'm coming from with this paper.

To a large extent, I was thinking about predictive coding as a way of understanding neural networks.

So I think although this perspective can encompass active inference and such, I think that's sort of the core of it, is that the brain is literally trying to, yeah,

right sparsity as you said right and do sparsity minimize activity only pass forward signals that need to be passed forward and that means that you're sort of quelling activity that doesn't get passed forward so i think i don't know if that's strong enough to get you an identity but i think it's uh it's consistent with the identity idea and it's um i think it's a large part of the inspiration for me awesome steven with a raised hand and then anyone else


SPEAKER_00:
Yeah.

If you could just speak to how you see that predictive coding, predictive processing be more or less useful at certain times, um, as the sort of the, the, the, the discourse, um, and when maybe active inference is not as needed at certain times, you know, maybe thinking in applied context, but, um, I'll just be curious.


SPEAKER_05:
Yeah.

It seems to me that if you want a... The main advantage of active inference, practically speaking, to me, seems to be modeling explicitly how policies, actions are chosen, like decision-making, based on how you expect...

your actions to change the way states evolve.

So I think that happens implicitly in a well-trained predictive coding architecture.

And I don't see any fundamental theoretical advantage to active inference there in terms of explaining how things work on an in-principle level.

But that said, it's really hard to just train a recurrent neural network or whatever to do what you want it to do and then interpret its states and so on.

So if you have an idea of a generative model,

of what the agent's generative model should look like, then it makes much more sense to write it down a priori and try to build an active inference model than to just learn it from data.

So that's as close to maybe an applied setting as I could get, but I hope that sort of speaks to it.


SPEAKER_03:
yeah let me let me try to get another view on that from you alex where would you put active inference in relationship to supervised and unsupervised learning for those who might be less familiar with those topics when you're talking about learning from the data versus a generative model where does active inference fit into that yeah that's a great question um


SPEAKER_05:
it's a bit tricky because there's this issue of preference learning that's kind of not settled in the, you know, like as far as how much of the feature of real biological agents learning do we think that is.

But like, so to me, the most natural way of thinking of unsupervised learning happening in active inference is that you've got sort of a,

you've got a phenotype, some aspects of which are going to be immutable over relevant timescales, but some aspects of which will change.

So we're talking about synaptic weights.

You could think of that as an extended part of your phenotype, and that will change over timescales of perceptual learning and during the organism's lifetime and such.

That, I think, is neatly... You can categorize that as a form of unsupervised learning, but that's also not really... Again, it's not... There are people who are active inference sort of practitioners who don't really think that preference learning is a thing that happens or... Yeah, it's not clear what role it plays.

But overall, I mean...

Well, there's also got to be a role for something like supervised learning seems to me the closest thing that we have to that in real systems is reinforcement in a way.

And that's certainly got to play a role that's complementary to unsupervised learning.

I don't know.

This answer is kind of shit.

I'm sorry.

I'm happy to take it up more.

I'm just not sure what... I don't know how to tease apart the parts of active inference that should be understood in terms of unsupervised learning versus just like...

learning in general and how much of it, I suspect a lot of learning in general has got to be unsupervised.

And I think active inference is sort of naturally interpreted, predictive coding certainly is an unsupervised learning paradigm.

And to the extent that active inference reduces to that, it is too.


SPEAKER_03:
great thank you and these are definitely all topics we're always trying to think clearer about and communicate clearer about so stephen and then adam i think this is a useful conversation i know it's a bit off it's put you on the spot a little bit but i think as a group it's quite useful this question of um


SPEAKER_00:
when a generative model comes into play.

So with reinforcement learning, I suppose there's a generative model in relation to like an induction, an inductive reasoning in terms of the goal.

Like you're trying to narrow the gap between the target that you're reinforcing the reward and reducing the gap.

Whereas there's this abductive potential in active inference too.

And I wonder whether,

in the population or the populating of the brain's attention, I'm sort of wondering if place cells and the sort of more granular parts of the lower levels of the neocortex, or I'm not sure if that's the right term,

basically that kind of more unsupervised, very unsupervised, very abductive kind of potentially ways of engaging.

And then these grid cells, as they get more populated with what things are, become kind of more top down, maybe more

let us go back into, say, a more reinforcement learning or supervised learning.

And then you don't farrage as much, so to speak.

You just go straight to the point, which probably I should do now and let someone else take over.


SPEAKER_03:
Thanks, Steven.

Alex, if you want to add something, otherwise we'll go to Adam.


SPEAKER_05:
Yeah, no, just to say, I mean, that kind of makes sense to me.

I think you need unsupervised learning for representation learning of whatever isn't innate, right?

And then once you have that framework, then you can start to think about, like, meaningful interpretations of sensory stimuli that you could associate with rewards.

So that's all I'll say for now.


SPEAKER_02:
Cool.


SPEAKER_07:
Adam?

A quick question, but a quick comment on what Stephen said.

I mean, interestingly about the hippocampal system is there does seem to be this very contrastive thing to it in terms of comparing between current states and then imagined states.

And at different duty cycles of theta, you'll be seeing there seems to be this comparison operation going on.

So it could be very much like this highest level supervisor

in this like Matryoshka dolls of like quasi homuncular things that we're thinking of.

But the question I was wondering, there are people who don't believe preference learning is a thing.


SPEAKER_05:
Oh, I shouldn't put anyone on the spot.

It's not necessarily that they don't believe it's a thing.

It's that it's not clear that we need to invoke it to explain behavioral things, at least in many cases.

So I feel like I'm going to be speaking for people who are colleagues of mine who I don't want to misrepresent their views, so I'll shut up about it.

But there's definitely controversy about the extent to which it happens, I suppose.


SPEAKER_07:
I mean, I'm wondering, I guess, to what extent, so there's things like meta-learning principles where you have

you're figuring out new ways of approaching policies.

So you're realizing goals and you're building up these policies in an exploratory fashion as part of your phenotypic plasticity.

But I guess there is a sense in which if we're subscribing to the free energy principle,

you can only prefer one thing, and that thing never changes, and everything else is just instrumental.

You could just only prefer to be basically Agent Smith for the entire world.

You could, like, my pattern, me, me, me.

Right.

But, you know, ultimately, this should be, like, we, we, we, in terms of, like, evolutionary favorable equilibria.

But it seems like, I guess there is a sense in which that never changes.

Yeah.


SPEAKER_05:
Yeah.

I mean, just to say one thing to try to defend the people that I have been talking about.

When I say preference, there's controversy about preference learning.

I mean, there's clearly something that

that looks like preference learning, right?

It's just a question of whether you're really learning preferences or you're just learning new associations with the things that you prefer.

And those two processes are conceptually distinct.

They might lead to similar results.

But yeah, the point you're raising is interesting, is that really your preference is like you, right, literally, your phenotype, so.


SPEAKER_03:
Well, I have a question for Adam.

Yeah, that's exactly where I was going to go.

Could there not be a cultural scaffolding that's developed over ecological and evolutionary time that values diversity of perspective?

And so, yes, it is true that at different scales, some type of active inference could be happening, but I don't think that Agent Smith would be the only attractor at the bottom of that bowl.

It'd be more like maybe a plate with a lot of different wells, a lot of different kinds of food that could be converged upon.

why would it have to be converging on one specific um especially hollywood represented version of what efficiency is just a thought but yeah i don't think agent smith would win like villains usually lose you know steven uh


SPEAKER_00:
Well, this this could be though, when you get into that non equilibrium, equilibrium dynamic is like, once you get a dictator who establishes an equilibrium, that's an energy equilibrium, which is, that's going to be more powerful than the more subtle, organic, non equilibrium states, it just dominates times.


SPEAKER_03:
And if there is made an equivalence in some near or distant future between actual energy usage and governance, for example, some sort of crypto system with energy and voting and information and finances all being mixed together, it'll be an enormous nexus of power.

And maybe we'll be able to use these kinds of frameworks to describe them.

Stephen?


SPEAKER_00:
And also going the other way then, this is my belief, I strongly believe that to create community engagement in meaningful ways, you have to create the container

for those more subtle non-equilibrium states to have a chance to breathe.

This woman, Ariane Munchkin, she's a theatre director in France.

She talks about don't crush the butterfly.

She would tell the actors, don't crush the butterfly.

The butterfly is like the idea.

So don't grab hold of it because you'll crush it.

So it's quite a nice metaphor.

You have to hold it lightly and allow it to... And there's a certain...

Because equilibrium dynamics or somebody who comes in and basically starts shouting at people will always overdominate someone who's trying to do some let's all come together and find each other's plurality.

So anyway, that sort of dynamic sort of ties in with what you're saying.


SPEAKER_03:
Cool.

So I flipped to 49, where we have our usual set of just closing discussions.

So in these last 10 minutes, we'll just be remarking on what we thought was interesting or important from the conversation.

What would we like to pursue next in terms of our own work or Alex, in terms of your research?

I'm sure we're also all curious as well about how you apply these ideas.

in terms of your, you know, whatever non-proprietary applications you think that this bears on, if none, then that's its own interesting claim.

Or maybe there is something that this helps us do in terms of practice.

What are the next steps here?

Maybe Alex first, and then anyone else can give a thought.


SPEAKER_05:
Sure.


SPEAKER_03:
So, I mean, I could address these questions on the slide or... Yeah, let's hear your answers to these questions on the slide.


SPEAKER_05:
So I mean, this also speaks to what you just asked, but really, I think that this is just a way of thinking about things.

The main thing I think it enables is just allowing you to infer from what you know about cognition or the cognitive states of some system, including yourself, to physical states.

If it's true, then, for example, yeah, you can say, well, I'm depressed.

There's not a lot going on.

you know, I'm ruminating a lot, you can infer that there's something physically happening that mirrors that process.

And you can take either a physical or a psychological approach to solving any problem in your body, right, in theory.

Now, there's a lot of working out to be done of

how that would work in specific cases.

But that's the kind of, like basically just sort of smoothing the path for inference from physical to psychological states, I think is the main thing that I think is practically important about this.

And I'm still curious about how to spell that out for specific types of states, like depression, desires, things like that.

And I'm also curious about whether any of it is true at all or whether it's just complete nonsense.


SPEAKER_03:
big questions adam and then anyone else who wants to give any thought or address one of the questions on the slide


SPEAKER_07:
If it's complete nonsense, I'm not sure what would make sense.

I'm not even sure what sense would mean.

Later, I would really want to talk to you about the degrees of freedom and volition issue and the different ways that could play out.

And also, I want to drag you into consciousness because you are precise, my friend, and you're helping me think better.


SPEAKER_05:
Cool.

Thanks, Adam.

Happy to.


SPEAKER_03:
Cool.

If anyone else has a thought, otherwise we can sort of look back.

Oh, yeah, Stephen, go for it.


SPEAKER_00:
Yeah, I just want to say thank you for bringing this foundational build-up into the thermodynamics.

And I'd be interested to maybe sort of see if there's any... I did physical chemistry, so I've got some background, but I'm curious to see if there's any ways to bring in some elements of...

sort of Gibbs free energy and into some of this.

So I'd be glad to chat about that sometime.


SPEAKER_01:
Yeah, Blue.

So when you guys are done talking about degrees of freedom and agency, you have to come back to the chat because I want to hear all about this.

I have some thoughts that have been cooking about agency related to active inference and other ideas also.


SPEAKER_03:
Cool.

And maybe Dean, I'd like to ask, where does the .2 get us?

What do we do at the end of the .2?

We took that step to the .0 with yourself and Blue and I, and then we take the .1 and .2 steps, ideally with an author, especially when it's an awesome author like Alex, who's engaged with the material before the .1 and between the two.

What's our next step on that staircase?

What do we do after the .2?

How do we make the best of this?


SPEAKER_04:
Well, this is a sample of one.

But for me, it's... So how do you remain stable and dynamic at the same time?

How do you move through these gradients, whether it's ascending or descending, and also keep in the front of your mind how you're going to keep your grip if you're ascending or maintain your balance when you're descending?

and for me that's what alex's paper essentially pointed out there is a there's a physical piece to that and there's a statistical piece to that and i don't want to become a statistic of another old person who falls down the stairs so how do i pull all of that together and have it make sense especially if i don't want

to give somebody a training exercise if I want them to be able to model how to get down that descent or up that ascent, and I can't give them a map.

So what do I give them?

What do I replace that with?

That's what Alex's paper gave to me.

Gave me a little bit of confidence around it.


SPEAKER_03:
Awesome.

One more staircase thought and coming back as well to the up and downhill.

So when you're going up the staircase,

you'd grab onto a certain spot on the rail, and then that helps you ratchet up.

And then when you're going down the staircase, you're unlikely to grab on tight to a rail.

You kind of want to loosely have your hand sliding down the rail so that you can ratchet if you needed to and stabilize.

But if you ratchet while you're going down, then it's going to prevent you from continuing this sort of natural descent.

So it just makes me think about different modes in understanding, especially because as we talked about with the mountain climber, it's like going up and downhill in their own way.

If the top is your goal, they're like both going downhill.

So when in our process do we want to...

grip the rail lightly just like steven said not crush the butterfly just slide along and just go with the flow knowing that we can stabilize when we need to and when do we really want to grip and ratchet because we're working against one energy gradient but we're working towards our goals when we do that so

I hope all of these mixed metaphors come together for the listeners in an enjoyable way.

And Alex, we really appreciate your engagement with Act-Inf Lab here and everybody else.

Awesome conversations.


SPEAKER_05:
Yeah, thanks.

Thanks, Blue, Dean, Daniel, Stephen, Adam, people who were here last week.

Also, I'm happy to be put on the spot.

I'm glad this was of service to people.

I think it's been a really interesting discussion.

And thanks for having me.

Thanks for all that you do.


SPEAKER_03:
Great.

Well, everyone's always welcome and we'll see you all in another stream.

Bye.