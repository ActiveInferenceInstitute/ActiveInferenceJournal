1
00:00:00,000 --> 00:00:09,014
Daniel Friedman: Hello and welcome.

2
00:00:07,953 --> 00:00:19,029
It is March 2023 and we're here in

3
00:00:19,029 --> 00:00:19,029
ActInf Livestream 52.1.

4
00:00:09,051 --> 00:00:22,341
Welcome to the Active Inference Institute.

5
00:00:20,106 --> 00:00:29,076
We're a participatory online institute

6
00:00:29,076 --> 00:00:29,076
that is communicating, learning and

7
00:00:29,076 --> 00:00:29,076
practicing applied active coherence.

8
00:00:22,357 --> 00:00:35,679
This is a recorded and an archived

9
00:00:35,679 --> 00:00:35,679
Livestream, so please provide us feedback

10
00:00:35,679 --> 00:00:35,679
so we can improve our work.

11
00:00:29,090 --> 00:00:49,091
All backgrounds and perspectives are

12
00:00:49,091 --> 00:00:49,091
welcome and we'll be following video

13
00:00:49,091 --> 00:00:49,091
etiquette for livestreams head over

14
00:00:49,091 --> 00:00:49,091
active coherence.org to learn more about

15
00:00:49,091 --> 00:00:49,091
getting involved in learning groups and

16
00:00:49,091 --> 00:00:49,091
projects such as live streams.

17
00:00:36,716 --> 00:01:09,470
All right, we are in 52.1 and our goal

18
00:01:09,470 --> 00:01:09,470
today is to learn and discuss this

19
00:01:09,470 --> 00:01:09,470
awesome paper geometric Methods for

20
00:01:09,470 --> 00:01:09,470
Sampling Optimization, Inference and

21
00:01:09,470 --> 00:01:09,470
Adoptive Agents of Barp and Acosta at

22
00:01:09,470 --> 00:01:09,470
all.

23
00:00:50,189 --> 00:01:13,855
And we're going to just jump right in.

24
00:01:10,509 --> 00:01:23,840
Thanks a lot Lance for joining and those

25
00:01:23,840 --> 00:01:23,840
who have listened to 52.0 will know me.

26
00:01:13,872 --> 00:01:28,324
I'm a researcher and learner with respect

27
00:01:28,324 --> 00:01:28,324
to this topic.

28
00:01:23,877 --> 00:01:39,425
So thanks again for joining and it'll be

29
00:01:39,425 --> 00:01:39,425
great to have you introduce yourself and

30
00:01:39,425 --> 00:01:39,425
also tell a little bit of the story of

31
00:01:39,425 --> 00:01:39,425
how this paper came to be.

32
00:01:28,338 --> 00:01:41,599
Lancelot Da Costa: Sure.

33
00:01:40,534 --> 00:01:43,825
Thanks Daniel for organizing.

34
00:01:41,612 --> 00:01:46,014
This is really great and I'm very happy

35
00:01:46,014 --> 00:01:46,014
to be here.

36
00:01:43,841 --> 00:02:00,095
So my name is Lance de Costa, some of you

37
00:02:00,095 --> 00:02:00,095
may know me, I'm a PhD student both at

38
00:02:00,095 --> 00:02:00,095
Imperial College of London and UCL,

39
00:02:00,095 --> 00:02:00,095
mostly working on active inference and

40
00:02:00,095 --> 00:02:00,095
the free energy principle.

41
00:01:47,022 --> 00:02:03,121
Also some probabilistic machine

42
00:02:03,121 --> 00:02:03,121
learning.

43
00:02:00,099 --> 00:02:10,195
And today we're going to be discussing

44
00:02:10,195 --> 00:02:10,195
geometric methods for sampling

45
00:02:10,195 --> 00:02:10,195
optimization, inference and adaptive

46
00:02:10,195 --> 00:02:10,195
agents.

47
00:02:03,126 --> 00:02:21,300
So how this paper came to be where I

48
00:02:21,300 --> 00:02:21,300
happen to know people in who do more like

49
00:02:21,300 --> 00:02:21,300
statistics, machine learning and so on.

50
00:02:12,211 --> 00:02:36,456
And we've always been talking about the

51
00:02:36,456 --> 00:02:36,456
similarities and differences between what

52
00:02:36,456 --> 00:02:36,456
we do in two inference and what they do

53
00:02:36,456 --> 00:02:36,456
in sampling optimization, which are kind

54
00:02:36,456 --> 00:02:36,456
of the workhorses of statistics and

55
00:02:36,456 --> 00:02:36,456
machine learning.

56
00:02:21,300 --> 00:02:57,663
And at some point we had a paper

57
00:02:57,663 --> 00:02:57,663
invitation for the hamburger of

58
00:02:57,663 --> 00:02:57,663
statistics and we decided to team up and

59
00:02:57,663 --> 00:02:57,663
make a review article to see how all

60
00:02:57,663 --> 00:02:57,663
these Fields that come from very

61
00:02:57,663 --> 00:02:57,663
different places scientifically, that

62
00:02:57,663 --> 00:02:57,663
have very different contributors as

63
00:02:57,663 --> 00:02:57,663
well.

64
00:02:36,457 --> 00:03:15,781
And we wanted to know how they're

65
00:03:15,781 --> 00:03:15,781
interconnected and also how they can help

66
00:03:15,781 --> 00:03:15,781
each other because we realized for all

67
00:03:15,781 --> 00:03:15,781
this time that we're actually doing

68
00:03:15,781 --> 00:03:15,781
similar things, but the communities are

69
00:03:15,781 --> 00:03:15,781
very different, they're dot zero much

70
00:03:15,781 --> 00:03:15,781
talking to each other.

71
00:02:57,663 --> 00:03:20,837
And I think the main barrier is

72
00:03:20,837 --> 00:03:20,837
difference in Lagrange, difference in

73
00:03:20,837 --> 00:03:20,837
jargon.

74
00:03:15,782 --> 00:03:41,047
So that was kind of an issue when we

75
00:03:41,047 --> 00:03:41,047
started and so I wanted to put that all

76
00:03:41,047 --> 00:03:41,047
as much as possible in a paper and see

77
00:03:41,047 --> 00:03:41,047
how these different approaches to

78
00:03:41,047 --> 00:03:41,047
statistics, whether it is sampling,

79
00:03:41,047 --> 00:03:41,047
optimization, inference or decision

80
00:03:41,047 --> 00:03:41,047
making, how they can benefit from each

81
00:03:41,047 --> 00:03:41,047
other and how they relate to each other.

82
00:03:20,837 --> 00:03:56,195
Long story short, we're going to delve

83
00:03:56,195 --> 00:03:56,195
into this into more detail, but long

84
00:03:56,195 --> 00:03:56,195
story short, if you want to ensemble from

85
00:03:56,195 --> 00:03:56,195
a distribution, you can also view that as

86
00:03:56,195 --> 00:03:56,195
an optimization problem.

87
00:03:43,064 --> 00:04:01,183
So optimization is kind of you can see it

88
00:04:01,183 --> 00:04:01,183
under the roots of sampling.

89
00:03:57,202 --> 00:04:06,231
And you want to optimize sampling, make

90
00:04:06,231 --> 00:04:06,231
sampling as efficient as possible

91
00:04:06,231 --> 00:04:06,231
inference.

92
00:04:01,184 --> 00:04:11,284
You can also see it as an optimization of

93
00:04:11,284 --> 00:04:11,284
beliefs, optimization of probability

94
00:04:11,284 --> 00:04:11,284
distinctions.

95
00:04:06,232 --> 00:04:13,306
That's also an optimization procedure.

96
00:04:11,284 --> 00:04:28,450
And if you want to do decision making,

97
00:04:28,450 --> 00:04:28,450
which is what we do in active inference

98
00:04:28,450 --> 00:04:28,450
and reinforcement learning and many

99
00:04:28,450 --> 00:04:28,450
different places, well, through decision

100
00:04:28,450 --> 00:04:28,450
making, you actually need optimization

101
00:04:28,450 --> 00:04:28,450
and inference.

102
00:04:15,321 --> 00:04:33,505
And if you want to do decision making

103
00:04:33,505 --> 00:04:33,505
efficiently, you often are going to need

104
00:04:33,505 --> 00:04:33,505
something as well.

105
00:04:28,452 --> 00:04:45,625
So decision making, an active inference

106
00:04:45,625 --> 00:04:45,625
is kind of like what comes at the very

107
00:04:45,625 --> 00:04:45,625
end and requires all of the sophisticated

108
00:04:45,625 --> 00:04:45,625
machinery of sampling coherence of

109
00:04:45,625 --> 00:04:45,625
optimization in order to work.

110
00:04:33,507 --> 00:04:53,706
So this was really the idea of the paper,

111
00:04:53,706 --> 00:04:53,706
how does optimization come about, how do

112
00:04:53,706 --> 00:04:53,706
you do efficient optimization?

113
00:04:46,631 --> 00:04:56,736
And of course there's many different ways

114
00:04:56,736 --> 00:04:56,736
to do that.

115
00:04:53,707 --> 00:05:01,728
So we decided to focus on natural ways

116
00:05:01,728 --> 00:05:01,728
and we'll get to that.

117
00:04:56,738 --> 00:05:09,803
But one way to do optimization that is

118
00:05:09,803 --> 00:05:09,803
very natural is through techniques from

119
00:05:09,803 --> 00:05:09,803
geometry.

120
00:05:01,729 --> 00:05:13,841
And so same with sampling.

121
00:05:11,825 --> 00:05:19,904
In sampling and inference, you have

122
00:05:19,904 --> 00:05:19,904
geometry that just comes up very

123
00:05:19,904 --> 00:05:19,904
naturally when you want to solve these

124
00:05:19,904 --> 00:05:19,904
problems.

125
00:05:13,842 --> 00:05:22,937
And so decision making puts it all

126
00:05:22,937 --> 00:05:22,937
together.

127
00:05:19,908 --> 00:05:25,965
So that was really the idea of the

128
00:05:25,965 --> 00:05:25,965
paper.

129
00:05:23,941 --> 00:05:31,024
Can we put all these Fields together and

130
00:05:31,024 --> 00:05:31,024
have a connecting line which is based on

131
00:05:31,024 --> 00:05:31,024
geometry?

132
00:05:25,966 --> 00:05:33,040
And so that's where we did.

133
00:05:31,025 --> 00:05:38,094
Daniel: Awesome, great overview.

134
00:05:35,068 --> 00:05:43,143
So, so many places to jump in.

135
00:05:38,096 --> 00:05:49,202
I barely even know where to sample from

136
00:05:49,202 --> 00:05:49,202
this distinctions.

137
00:05:45,166 --> 00:05:52,231
Let's just start with sampling, though.

138
00:05:49,204 --> 00:05:56,278
So what is sampling and how is it being

139
00:05:56,278 --> 00:05:56,278
used?

140
00:05:52,232 --> 00:05:58,294
How has it been used?

141
00:05:56,278 --> 00:06:07,327
And let's characterize sampling and then

142
00:06:07,327 --> 00:06:07,327
move on to these other Fields, right?

143
00:05:59,299 --> 00:06:15,407
Lance: Well, sampling, I mean, the

144
00:06:15,407 --> 00:06:15,407
idea of sampling is very simple and it's

145
00:06:15,407 --> 00:06:15,407
also a very difficult thing to do.

146
00:06:07,328 --> 00:06:17,427
So first explain the idea.

147
00:06:15,408 --> 00:06:23,489
The idea is, let's say you have a

148
00:06:23,489 --> 00:06:23,489
Bayesian in one dimension, so that's very

149
00:06:23,489 --> 00:06:23,489
easy to picture.

150
00:06:18,431 --> 00:06:32,576
Sampling would be so, for example, the

151
00:06:32,576 --> 00:06:32,576
Gaussian I just mentioned describes the

152
00:06:32,576 --> 00:06:32,576
temperature in the room.

153
00:06:24,494 --> 00:06:41,661
So in my room, it's maybe currently 18

154
00:06:41,661 --> 00:06:41,661
degrees Celsius, plus or minus some

155
00:06:41,661 --> 00:06:41,661
variants representing my uncertainty.

156
00:06:32,578 --> 00:06:53,782
Now, sampling from the distribution would

157
00:06:53,782 --> 00:06:53,782
be saying it is maybe 19 degrees or maybe

158
00:06:53,782 --> 00:06:53,782
17 degrees, drawing a lot of different

159
00:06:53,782 --> 00:06:53,782
temperatures.

160
00:06:41,666 --> 00:07:07,867
So that if you put them all together as a

161
00:07:07,867 --> 00:07:07,867
histogram with their frequency, for

162
00:07:07,867 --> 00:07:07,867
example, if you ask me what temperature

163
00:07:07,867 --> 00:07:07,867
it is in my room, I would say there's a

164
00:07:07,867 --> 00:07:07,867
higher chance that I say 18 degrees.

165
00:06:53,782 --> 00:07:25,042
So I would say more often if you ask me

166
00:07:25,042 --> 00:07:25,042
this question many times, and if you put

167
00:07:25,042 --> 00:07:25,042
my answers, if you collect all my answers

168
00:07:25,042 --> 00:07:25,042
in a histogram, for example, I'd say 18

169
00:07:25,042 --> 00:07:25,042
degrees more often, so that barp around

170
00:07:25,042 --> 00:07:25,042
18 degrees would be higher and the other

171
00:07:25,042 --> 00:07:25,042
temperatures would be slightly lower.

172
00:07:07,869 --> 00:07:29,087
And if you aggregate that, you would get

173
00:07:29,087 --> 00:07:29,087
a Gaussian.

174
00:07:25,042 --> 00:07:31,108
Get the Gaussian we started with.

175
00:07:30,091 --> 00:07:34,133
So sampling, in other words.

176
00:07:31,109 --> 00:07:40,195
And very simply, it's like drawing a data

177
00:07:40,195 --> 00:07:40,195
point or an observation from an

178
00:07:40,195 --> 00:07:40,195
underlying probability distribution.

179
00:07:34,133 --> 00:07:50,293
You have a distribution, let's say a

180
00:07:50,293 --> 00:07:50,293
Bayesian that represents your most likely

181
00:07:50,293 --> 00:07:50,293
value of what the temperature in the room

182
00:07:50,293 --> 00:07:50,293
is and some uncertainty.

183
00:07:40,199 --> 00:07:56,356
And you just want to draw one or several

184
00:07:56,356 --> 00:07:56,356
observations from that distribution.

185
00:07:50,295 --> 00:08:03,366
And you want to draw these observations

186
00:08:03,366 --> 00:08:03,366
so as to preserve the overall statistics

187
00:08:03,366 --> 00:08:03,366
of the distribution that you started

188
00:08:03,366 --> 00:08:03,366
with.

189
00:07:57,360 --> 00:08:14,472
So that if you draw infinitely many data

190
00:08:14,472 --> 00:08:14,472
points or infinitely many observations

191
00:08:14,472 --> 00:08:14,472
from a distribution, then you can recover

192
00:08:14,472 --> 00:08:14,472
the original distribution.

193
00:08:04,371 --> 00:08:15,489
So that's what we want to do.

194
00:08:14,473 --> 00:08:20,534
And so why is this useful in the first

195
00:08:20,534 --> 00:08:20,534
place?

196
00:08:16,492 --> 00:08:26,598
Well, it just happens all the time in the

197
00:08:26,598 --> 00:08:26,598
things that you want to computer

198
00:08:26,598 --> 00:08:26,598
integrals.

199
00:08:20,534 --> 00:08:29,624
It just happens all the time.

200
00:08:28,610 --> 00:08:46,794
So, for example, if you have a Bayesian

201
00:08:46,794 --> 00:08:46,794
inference problem, you observe some data

202
00:08:46,794 --> 00:08:46,794
in the world, it could be medical data,

203
00:08:46,794 --> 00:08:46,794
it could really be anything, and you have

204
00:08:46,794 --> 00:08:46,794
a prior and a likelihood of observing

205
00:08:46,794 --> 00:08:46,794
that data.

206
00:08:29,624 --> 00:08:49,823
So these are two terms in, like, Bayes

207
00:08:49,823 --> 00:08:49,823
rule.

208
00:08:46,795 --> 00:08:51,839
Then you want to know.

209
00:08:49,825 --> 00:08:59,922
Then if you apply Bayes rule, you get a

210
00:08:59,922 --> 00:08:59,922
posterior belief about what caused that

211
00:08:59,922 --> 00:08:59,922
data that you observed.

212
00:08:52,850 --> 00:09:07,947
So, for example, a practical use case

213
00:09:07,947 --> 00:09:07,947
would be some medical data of a patient

214
00:09:07,947 --> 00:09:07,947
that's sick, and you want to know.

215
00:08:59,923 --> 00:09:13,009
So you get, for example, it's blood

216
00:09:13,009 --> 00:09:13,009
pressure, collection of symptoms and so

217
00:09:13,009 --> 00:09:13,009
on.

218
00:09:07,949 --> 00:09:22,094
So that's your data, and you want to know

219
00:09:22,094 --> 00:09:22,094
what kind of disease or what kind of

220
00:09:22,094 --> 00:09:22,094
function caused that data.

221
00:09:13,009 --> 00:09:33,203
So let's say typically you would have a

222
00:09:33,203 --> 00:09:33,203
model of, if I have this malfunction of

223
00:09:33,203 --> 00:09:33,203
this disease, I would have these

224
00:09:33,203 --> 00:09:33,203
symptoms.

225
00:09:22,096 --> 00:09:36,237
If I have this other disease, I would get

226
00:09:36,237 --> 00:09:36,237
these other symptoms.

227
00:09:33,208 --> 00:09:48,359
And so Bazrul enables you to infer in the

228
00:09:48,359 --> 00:09:48,359
best way possible, the disease that

229
00:09:48,359 --> 00:09:48,359
caused the symptoms that you just saw.

230
00:09:36,237 --> 00:10:16,572
So this is like a common thing, something

231
00:10:16,572 --> 00:10:16,572
that people use every day in statistics

232
00:10:16,572 --> 00:10:16,572
all the time, and arguably everybody uses

233
00:10:16,572 --> 00:10:16,572
it every day because the thesis of the

234
00:10:16,572 --> 00:10:16,572
Franca principle, or the result that it

235
00:10:16,572 --> 00:10:16,572
provides, is that you can describe

236
00:10:16,572 --> 00:10:16,572
exteroception of humans as doing basic

237
00:10:16,572 --> 00:10:16,572
inference.

238
00:09:49,363 --> 00:10:20,615
So basic inference is a very ubiquitous

239
00:10:20,615 --> 00:10:20,615
thing.

240
00:10:16,573 --> 00:10:30,710
You can use it to describe perception in

241
00:10:30,710 --> 00:10:30,710
humans, and you can also use it to do

242
00:10:30,710 --> 00:10:30,710
statistics and solve all kinds of

243
00:10:30,710 --> 00:10:30,710
problems.

244
00:10:21,629 --> 00:10:42,830
So, coming back to sampling, actually

245
00:10:42,830 --> 00:10:42,830
doing Bayesian inference, you have this

246
00:10:42,830 --> 00:10:42,830
problem of how do you compute the

247
00:10:42,830 --> 00:10:42,830
posterior distribution in the first

248
00:10:42,830 --> 00:10:42,830
place?

249
00:10:30,714 --> 00:10:54,954
And it turns out that this distinctions

250
00:10:54,954 --> 00:10:54,954
is generally intractable because you have

251
00:10:54,954 --> 00:10:54,954
kind of a term in the denominator that's

252
00:10:54,954 --> 00:10:54,954
very hard to compute.

253
00:10:42,834 --> 00:11:01,960
And so one ways to compute it is to use

254
00:11:01,960 --> 00:11:01,960
what's called Monte Carlo methods.

255
00:10:55,965 --> 00:11:03,988
And Monte Carlo methods are based on

256
00:11:03,988 --> 00:11:03,988
sampling.

257
00:11:01,961 --> 00:11:18,138
So, long story short, in order to do

258
00:11:18,138 --> 00:11:18,138
Bayesian inference, you need to compute

259
00:11:18,138 --> 00:11:18,138
this, like, log likelihood term, which is

260
00:11:18,138 --> 00:11:18,138
a high dimension integral and one way to

261
00:11:18,138 --> 00:11:18,138
do it is by using Monte Carlo methods.

262
00:11:04,990 --> 00:11:21,168
And Monte Carlo methods are based on

263
00:11:21,168 --> 00:11:21,168
sampling.

264
00:11:18,139 --> 00:11:28,237
So the sampling enables you to

265
00:11:28,237 --> 00:11:28,237
approximate the high dimensional integral

266
00:11:28,237 --> 00:11:28,237
they started with.

267
00:11:22,170 --> 00:11:49,441
So now many listeners, or also the

268
00:11:49,441 --> 00:11:49,441
readers of this work will wonder, well,

269
00:11:49,441 --> 00:11:49,441
one thing that people do in the free

270
00:11:49,441 --> 00:11:49,441
hundred principle and also kind of like

271
00:11:49,441 --> 00:11:49,441
the red on that of the 300 principle, is

272
00:11:49,441 --> 00:11:49,441
you're actually not going to compute this

273
00:11:49,441 --> 00:11:49,441
denominator.

274
00:11:29,244 --> 00:12:00,493
That's very expensive to the Bayesian

275
00:12:00,493 --> 00:12:00,493
inference, but you're going to

276
00:12:00,493 --> 00:12:00,493
approximate the posterior by minimizing

277
00:12:00,493 --> 00:12:00,493
free energy, which is called variational

278
00:12:00,493 --> 00:12:00,493
inference.

279
00:11:49,442 --> 00:12:07,562
That's another method of doing Brett and

280
00:12:07,562 --> 00:12:07,562
coherence and it has many advantages over

281
00:12:07,562 --> 00:12:07,562
sampling.

282
00:12:00,496 --> 00:12:11,606
Sampling also has advantages with respect

283
00:12:11,606 --> 00:12:11,606
to variational inference.

284
00:12:07,562 --> 00:12:13,623
We can get into that.

285
00:12:11,607 --> 00:12:23,722
So if that's what you're thinking, well,

286
00:12:23,722 --> 00:12:23,722
this is not necessarily interesting

287
00:12:23,722 --> 00:12:23,722
because we can do variational coherence.

288
00:12:15,649 --> 00:12:29,782
There's so many other places where we

289
00:12:29,782 --> 00:12:29,782
need sampling in statistics.

290
00:12:23,728 --> 00:12:37,862
I would say basically anytime you need to

291
00:12:37,862 --> 00:12:37,862
compute an integral and integral are all

292
00:12:37,862 --> 00:12:37,862
over the place.

293
00:12:30,795 --> 00:12:45,946
But I think the Bayesian inference

294
00:12:45,946 --> 00:12:45,946
implication is a nice one because it just

295
00:12:45,946 --> 00:12:45,946
speaks to all of us.

296
00:12:38,872 --> 00:12:54,035
So how does actually sampling getting to

297
00:12:54,035 --> 00:12:54,035
the picture of integration?

298
00:12:50,989 --> 00:12:57,065
Let's say we have an integral that we

299
00:12:57,065 --> 00:12:57,065
need to compute.

300
00:12:54,035 --> 00:13:03,064
An integral is basically, let's say you

301
00:13:03,064 --> 00:13:03,064
have a state space.

302
00:12:58,072 --> 00:13:07,100
So to be very simple, let's say the state

303
00:13:07,100 --> 00:13:07,100
space is my desk.

304
00:13:03,065 --> 00:13:12,155
It would be like a planner surface and we

305
00:13:12,155 --> 00:13:12,155
have a function that's defined on the

306
00:13:12,155 --> 00:13:12,155
desk.

307
00:13:07,101 --> 00:13:16,197
So this would be like a landscape over

308
00:13:16,197 --> 00:13:16,197
the desk, right?

309
00:13:12,156 --> 00:13:21,246
Like a 2D surface landscape that could be

310
00:13:21,246 --> 00:13:21,246
rocked or whatever.

311
00:13:17,201 --> 00:13:28,312
The integral of this function is going to

312
00:13:28,312 --> 00:13:28,312
be the volume between the landscape and

313
00:13:28,312 --> 00:13:28,312
the desk.

314
00:13:22,252 --> 00:13:36,391
This is kind of like the geometric

315
00:13:36,391 --> 00:13:36,391
picture of what an integral is.

316
00:13:31,341 --> 00:13:52,552
This turns out to be very hard to compute

317
00:13:52,552 --> 00:13:52,552
in practice because let's say you have a

318
00:13:52,552 --> 00:13:52,552
very rough surface and it's not clear how

319
00:13:52,552 --> 00:13:52,552
to compute all this volume, which is very

320
00:13:52,552 --> 00:13:52,552
irregular.

321
00:13:38,414 --> 00:14:01,588
What sampling does is it's going to pick

322
00:14:01,588 --> 00:14:01,588
a few locations on the desk, as many as

323
00:14:01,588 --> 00:14:01,588
you wish.

324
00:13:53,565 --> 00:14:04,610
So let's start by one.

325
00:14:02,594 --> 00:14:20,777
And it's going to compute the height

326
00:14:20,777 --> 00:14:20,777
under the function and then pick another

327
00:14:20,777 --> 00:14:20,777
location and compute that height as well,

328
00:14:20,777 --> 00:14:20,777
since sampling is going to pick locations

329
00:14:20,777 --> 00:14:20,777
on the desk at random.

330
00:14:04,611 --> 00:14:30,873
And from there it's going to build a

331
00:14:30,873 --> 00:14:30,873
histogram that's going to approximate the

332
00:14:30,873 --> 00:14:30,873
surface that you started with.

333
00:14:21,785 --> 00:14:38,954
And so histogram is very simple because

334
00:14:38,954 --> 00:14:38,954
you get a whole bunch of skyscrapers if

335
00:14:38,954 --> 00:14:38,954
you wish to approximate the surface that

336
00:14:38,954 --> 00:14:38,954
we started with.

337
00:14:30,874 --> 00:14:46,034
And computing the volume of skyscrapers

338
00:14:46,034 --> 00:14:46,034
is very simple because they're like

339
00:14:46,034 --> 00:14:46,034
squares.

340
00:14:38,958 --> 00:14:51,081
It's like depth times height times

341
00:14:51,081 --> 00:14:51,081
width.

342
00:14:47,046 --> 00:14:54,111
It's very simple to compute the volume of

343
00:14:54,111 --> 00:14:54,111
those things.

344
00:14:51,082 --> 00:15:00,115
So this is kind of the idea we want to

345
00:15:00,115 --> 00:15:00,115
computer the volume under a rock

346
00:15:00,115 --> 00:15:00,115
surface.

347
00:14:55,126 --> 00:15:10,210
And to do that, we're going to pick

348
00:15:10,210 --> 00:15:10,210
arbitrary locations on the desk, on the

349
00:15:10,210 --> 00:15:10,210
page space and build it.

350
00:15:00,117 --> 00:15:16,273
And at those locations build like

351
00:15:16,273 --> 00:15:16,273
skyscrapers at the height of the

352
00:15:16,273 --> 00:15:16,273
surface.

353
00:15:10,210 --> 00:15:23,342
So you get like a skyline, a histogram

354
00:15:23,342 --> 00:15:23,342
that approximates your original

355
00:15:23,342 --> 00:15:23,342
function.

356
00:15:16,275 --> 00:15:29,408
And it's very simple to know the volume

357
00:15:29,408 --> 00:15:29,408
of the histogram, the volume of the

358
00:15:29,408 --> 00:15:29,408
skyline.

359
00:15:23,346 --> 00:15:35,463
So from then you get an estimate of the

360
00:15:35,463 --> 00:15:35,463
integral that you started with.

361
00:15:30,409 --> 00:15:39,501
So that's kind of like the geometric

362
00:15:39,501 --> 00:15:39,501
picture.

363
00:15:36,473 --> 00:15:47,586
The beauty of this is that it works in

364
00:15:47,586 --> 00:15:47,586
the arbitrary dimensions and it doesn't

365
00:15:47,586 --> 00:15:47,586
suffer from the curse of dimension.

366
00:15:39,502 --> 00:15:52,631
So this is why it's so powerful, if you

367
00:15:52,631 --> 00:15:52,631
want to know.

368
00:15:47,587 --> 00:16:05,701
So there's a formula that tells you how

369
00:16:05,701 --> 00:16:05,701
well the volume of your skyline will

370
00:16:05,701 --> 00:16:05,701
approximate the volume of the volume that

371
00:16:05,701 --> 00:16:05,701
you initially wanted to compute the

372
00:16:05,701 --> 00:16:05,701
integral.

373
00:15:52,632 --> 00:16:21,864
So this difference between the integral

374
00:16:21,864 --> 00:16:21,864
and your estimate basically decreases as

375
00:16:21,864 --> 00:16:21,864
a function of the number of skyscrapers

376
00:16:21,864 --> 00:16:21,864
that you put in.

377
00:16:05,709 --> 00:16:24,895
The more skyscrapers, the more precise

378
00:16:24,895 --> 00:16:24,895
you get.

379
00:16:21,865 --> 00:16:38,035
And this bound on the error that you have

380
00:16:38,035 --> 00:16:38,035
on your integral that you started with,

381
00:16:38,035 --> 00:16:38,035
it doesn't depend on the dimension.

382
00:16:27,921 --> 00:16:44,095
So as the higher dimension on your state

383
00:16:44,095 --> 00:16:44,095
space.

384
00:16:38,039 --> 00:16:54,197
So let's say let's imagine I had a high

385
00:16:54,197 --> 00:16:54,197
dimension desk, which is very hard to

386
00:16:54,197 --> 00:16:54,197
imagine, and I had a function on top of

387
00:16:54,197 --> 00:16:54,197
it, and I wanted to compute the area

388
00:16:54,197 --> 00:16:54,197
under the function.

389
00:16:44,095 --> 00:17:07,262
If my desk was very high dimensional, the

390
00:17:07,262 --> 00:17:07,262
higher the dimension, the harder it would

391
00:17:07,262 --> 00:17:07,262
be to solve this problem numerically.

392
00:16:56,214 --> 00:17:16,354
But with sampling, actually, the degree

393
00:17:16,354 --> 00:17:16,354
of accuracy that you get through sampling

394
00:17:16,354 --> 00:17:16,354
would be agnostic to the dimension.

395
00:17:07,263 --> 00:17:25,442
This is why it's so powerful and just

396
00:17:25,442 --> 00:17:25,442
used all the time in physics and machine

397
00:17:25,442 --> 00:17:25,442
learning.

398
00:17:17,363 --> 00:17:46,653
When you imagine practical problems that

399
00:17:46,653 --> 00:17:46,653
you have in machine learning, going back

400
00:17:46,653 --> 00:17:46,653
to medical data, you could get a whole

401
00:17:46,653 --> 00:17:46,653
bunch of data about a patient, which

402
00:17:46,653 --> 00:17:46,653
could be heart rate over time, blood

403
00:17:46,653 --> 00:17:46,653
oxygen levels, blood glucose levels, body

404
00:17:46,653 --> 00:17:46,653
temperature and whatnot.

405
00:17:25,444 --> 00:17:50,690
There's so many data modalities that you

406
00:17:50,690 --> 00:17:50,690
would have.

407
00:17:46,654 --> 00:17:53,727
So your state space would have many, many

408
00:17:53,727 --> 00:17:53,727
dimensions.

409
00:17:50,691 --> 00:18:08,814
And also the state space of the different

410
00:18:08,814 --> 00:18:08,814
diseases that could have given rise to

411
00:18:08,814 --> 00:18:08,814
all these symptoms would be also very

412
00:18:08,814 --> 00:18:08,814
high.

413
00:17:55,744 --> 00:18:16,894
So it could be that the patient has

414
00:18:16,894 --> 00:18:16,894
fever, or it could be that it has flu.

415
00:18:08,815 --> 00:18:17,908
Fever is a symptom.

416
00:18:16,897 --> 00:18:19,927
It could be that the disease is flu.

417
00:18:17,908 --> 00:18:22,951
It could be that the disease is

418
00:18:22,951 --> 00:18:22,951
tuberculosis.

419
00:18:19,927 --> 00:18:33,005
It could be that the disease there's so

420
00:18:33,005 --> 00:18:33,005
many different conditions or problems

421
00:18:33,005 --> 00:18:33,005
that one might want to examine.

422
00:18:22,952 --> 00:18:45,018
So in this particular case of medical

423
00:18:45,018 --> 00:18:45,018
data, and this is just like a very simple

424
00:18:45,018 --> 00:18:45,018
use case, I would say you have a very

425
00:18:45,018 --> 00:18:45,018
high dimensional state space.

426
00:18:34,007 --> 00:18:51,024
And to debate an inference, you have a

427
00:18:51,024 --> 00:18:51,024
very high dimensional integral to

428
00:18:51,024 --> 00:18:51,024
estimate.

429
00:18:46,019 --> 00:19:00,027
And so one way to do that efficiently, or

430
00:19:00,027 --> 00:19:00,027
maybe efficiently, is disingenuous

431
00:19:00,027 --> 00:19:00,027
because it's just very hard.

432
00:18:51,024 --> 00:19:05,032
I mean, it's just very computationally

433
00:19:05,032 --> 00:19:05,032
intensive to do these things.

434
00:19:01,028 --> 00:19:23,050
But one way to do this, that state of the

435
00:19:23,050 --> 00:19:23,050
art, is through sampling just by drawing

436
00:19:23,050 --> 00:19:23,050
different points at random on this safe

437
00:19:23,050 --> 00:19:23,050
space and approximating the functional

438
00:19:23,050 --> 00:19:23,050
landscape and approximating the integral

439
00:19:23,050 --> 00:19:23,050
like that.

440
00:19:05,032 --> 00:19:29,056
So, yeah, this is really why this is so

441
00:19:29,056 --> 00:19:29,056
important.

442
00:19:24,051 --> 00:19:33,060
Daniel: Awesome.

443
00:19:32,059 --> 00:19:48,075
So we've made a sample where does these

444
00:19:48,075 --> 00:19:48,075
topics of accepting or rejecting a move

445
00:19:48,075 --> 00:19:48,075
amongst examples or discretizing, how do

446
00:19:48,075 --> 00:19:48,075
we pick that next sample?

447
00:19:33,060 --> 00:19:52,079
And then what does it mean to accept or

448
00:19:52,079 --> 00:19:52,079
reject that sample?

449
00:19:48,075 --> 00:19:54,081
Lance: That's a great question.

450
00:19:53,080 --> 00:19:57,084
This is basically like the heart of

451
00:19:57,084 --> 00:19:57,084
sampling.

452
00:19:54,081 --> 00:20:05,086
If you knew how to do that in full

453
00:20:05,086 --> 00:20:05,086
generality, sampling would be sold, which

454
00:20:05,086 --> 00:20:05,086
it isn't.

455
00:19:58,085 --> 00:20:10,091
So I'm going to tell you a bit like where

456
00:20:10,091 --> 00:20:10,091
things stand.

457
00:20:05,086 --> 00:20:20,101
To do sampling, you need to pick places

458
00:20:20,101 --> 00:20:20,101
at random and you need to pick places at

459
00:20:20,101 --> 00:20:20,101
random.

460
00:20:14,095 --> 00:20:23,104
So that's to preserve probability

461
00:20:23,104 --> 00:20:23,104
distribution.

462
00:20:20,101 --> 00:20:34,115
So going back to the example of the desk,

463
00:20:34,115 --> 00:20:34,115
you want to pick in that case, you want

464
00:20:34,115 --> 00:20:34,115
to pick examples uniformly on the desk.

465
00:20:23,104 --> 00:20:46,127
If we come back to the previous example

466
00:20:46,127 --> 00:20:46,127
of like a Gaussian distribution, you want

467
00:20:46,127 --> 00:20:46,127
to pick samples that preserve the

468
00:20:46,127 --> 00:20:46,127
Gaussian distribution.

469
00:20:35,116 --> 00:20:52,133
So you ant to preserve to take a lot of

470
00:20:52,133 --> 00:20:52,133
samples around the mean very few samples

471
00:20:52,133 --> 00:20:52,133
on the tails.

472
00:20:46,127 --> 00:21:11,146
So it turns out that for those very

473
00:21:11,146 --> 00:21:11,146
simple distributions like uniform

474
00:21:11,146 --> 00:21:11,146
distribution, Galveston distribution,

475
00:21:11,146 --> 00:21:11,146
there are ways to sample that do not

476
00:21:11,146 --> 00:21:11,146
require what this paper is talking

477
00:21:11,146 --> 00:21:11,146
about.

478
00:20:53,134 --> 00:21:20,155
So there are ways to sample exactly that

479
00:21:20,155 --> 00:21:20,155
do not lead to any kind of error and that

480
00:21:20,155 --> 00:21:20,155
are very fast.

481
00:21:12,147 --> 00:21:31,166
So for Gaussians and uniform and a bunch

482
00:21:31,166 --> 00:21:31,166
of other distributions from the

483
00:21:31,166 --> 00:21:31,166
exponential family, you have ways to

484
00:21:31,166 --> 00:21:31,166
sample.

485
00:21:21,156 --> 00:21:32,167
Exactly.

486
00:21:31,166 --> 00:21:40,175
So the problem is these distinctions,

487
00:21:40,175 --> 00:21:40,175
they're not there all the time.

488
00:21:33,167 --> 00:21:49,184
And it turns out that very often you

489
00:21:49,184 --> 00:21:49,184
don't have these kind of very simple

490
00:21:49,184 --> 00:21:49,184
distributions, otherwise we would be

491
00:21:49,184 --> 00:21:49,184
done.

492
00:21:41,175 --> 00:21:57,192
So one simple example coming back to

493
00:21:57,192 --> 00:21:57,192
Bayesian inference is the idea of

494
00:21:57,192 --> 00:21:57,192
Jeffrey's Prior.

495
00:21:49,184 --> 00:22:11,200
So Jeffrey's Prior is the idea that you

496
00:22:11,200 --> 00:22:11,200
should take the highest entropy prior

497
00:22:11,200 --> 00:22:11,200
that's consistent with what you know

498
00:22:11,200 --> 00:22:11,200
about the system.

499
00:21:58,193 --> 00:22:17,206
Why entropy maximizing?

500
00:22:15,204 --> 00:22:23,212
So we know that entropy is a measure of

501
00:22:23,212 --> 00:22:23,212
the uncertainty present in the

502
00:22:23,212 --> 00:22:23,212
distribution.

503
00:22:17,206 --> 00:22:42,231
And so what Jeffrey's Prior says is that

504
00:22:42,231 --> 00:22:42,231
you should take a prior belief about a

505
00:22:42,231 --> 00:22:42,231
system, the belief that is maximally

506
00:22:42,231 --> 00:22:42,231
uncertain, uncertain, but that is also

507
00:22:42,231 --> 00:22:42,231
compatible with your knowledge.

508
00:22:24,213 --> 00:22:49,238
So out of all priors that are compatible

509
00:22:49,238 --> 00:22:49,238
with what you know about the system, you

510
00:22:49,238 --> 00:22:49,238
would take the one that's most

511
00:22:49,238 --> 00:22:49,238
uncertain.

512
00:22:42,231 --> 00:22:51,240
And this seems pretty intuitive, right?

513
00:22:49,238 --> 00:23:04,247
So when you take Jeffrey's Friar, what

514
00:23:04,247 --> 00:23:04,247
you get is often a distribution that's in

515
00:23:04,247 --> 00:23:04,247
the form of what people call a Gibbs

516
00:23:04,247 --> 00:23:04,247
measure.

517
00:22:52,241 --> 00:23:14,257
So Gibbs measures or Gibbs distributions

518
00:23:14,257 --> 00:23:14,257
there of the form exponential minus V.

519
00:23:05,248 --> 00:23:21,264
So they're like proportional to

520
00:23:21,264 --> 00:23:21,264
exponential minus V, and V could be an

521
00:23:21,264 --> 00:23:21,264
arbitrary function.

522
00:23:15,258 --> 00:23:34,276
So just as an example, if V were like a

523
00:23:34,276 --> 00:23:34,276
parabola, a quadratic function, then the

524
00:23:34,276 --> 00:23:34,276
associated Gibbs distribution is a

525
00:23:34,276 --> 00:23:34,276
Gaussian.

526
00:23:22,265 --> 00:23:36,279
So we all know what Gaussians are,

527
00:23:36,279 --> 00:23:36,279
right?

528
00:23:34,277 --> 00:23:39,282
But v could be pretty much anything.

529
00:23:36,279 --> 00:23:51,294
If you take V to be like X to the power

530
00:23:51,294 --> 00:23:51,294
of four minus X to the power of two, then

531
00:23:51,294 --> 00:23:51,294
V is kind of like a camel upside down.

532
00:23:39,282 --> 00:23:53,296
So, you know, it has like two humps.

533
00:23:51,294 --> 00:24:02,299
And therefore the exponential minus V

534
00:24:02,299 --> 00:24:02,299
distribution, the Gibbs measure, would be

535
00:24:02,299 --> 00:24:02,299
like a gaussian, but with two humps.

536
00:23:53,296 --> 00:24:12,309
So these gibs measures, they're just

537
00:24:12,309 --> 00:24:12,309
there like everywhere and they come up

538
00:24:12,309 --> 00:24:12,309
all the time.

539
00:24:03,300 --> 00:24:18,315
So one other example is in statistical

540
00:24:18,315 --> 00:24:18,315
mechanics.

541
00:24:13,310 --> 00:24:31,328
So let's say you have a system of

542
00:24:31,328 --> 00:24:31,328
molecules that just interact with each

543
00:24:31,328 --> 00:24:31,328
other, and this system of molecules, they

544
00:24:31,328 --> 00:24:31,328
could also be subject to thermal

545
00:24:31,328 --> 00:24:31,328
fluctuations.

546
00:24:18,315 --> 00:24:39,336
And whatnot this system is going to relax

547
00:24:39,336 --> 00:24:39,336
to what people call a steady state, often

548
00:24:39,336 --> 00:24:39,336
a non equilibrium steady state.

549
00:24:31,328 --> 00:24:51,348
These steady states, which is kind of

550
00:24:51,348 --> 00:24:51,348
like the end configuration of the system,

551
00:24:51,348 --> 00:24:51,348
is in general a gives measure.

552
00:24:40,337 --> 00:25:04,355
Now, you can see that in statistical

553
00:25:04,355 --> 00:25:04,355
mechanics and also in statistics, gives

554
00:25:04,355 --> 00:25:04,355
measures come up also in basic

555
00:25:04,355 --> 00:25:04,355
inference.

556
00:24:55,352 --> 00:25:09,360
And it's very hard in general to sample

557
00:25:09,360 --> 00:25:09,360
from a gives measure.

558
00:25:05,356 --> 00:25:15,366
There's ways to do it and we're going to

559
00:25:15,366 --> 00:25:15,366
come back to it, but we need to solve

560
00:25:15,366 --> 00:25:15,366
this problem.

561
00:25:10,361 --> 00:25:17,368
It's a very important problem.

562
00:25:15,366 --> 00:25:28,379
And so the most common way to solve from

563
00:25:28,379 --> 00:25:28,379
this distribution is what's called Markov

564
00:25:28,379 --> 00:25:28,379
Chain Monte Carlo.

565
00:25:18,369 --> 00:25:32,383
The idea is to run a Markov chain.

566
00:25:29,380 --> 00:25:33,384
So to run like a stochastic process.

567
00:25:32,383 --> 00:25:52,403
And you could think of it as stimulating

568
00:25:52,403 --> 00:25:52,403
molecules that interact with each other

569
00:25:52,403 --> 00:25:52,403
with some thermal fluctuations and that

570
00:25:52,403 --> 00:25:52,403
are going to relax to this gift

571
00:25:52,403 --> 00:25:52,403
distribution, this steady state that you

572
00:25:52,403 --> 00:25:52,403
originally specified.

573
00:25:34,385 --> 00:26:00,405
So coming back to the original examples,

574
00:26:00,405 --> 00:26:00,405
the steady state could be like a gaussian

575
00:26:00,405 --> 00:26:00,405
they want to sample from.

576
00:25:54,405 --> 00:26:03,407
Coming back to the example of the desk.

577
00:26:00,405 --> 00:26:07,412
It could be the uniform distribution on

578
00:26:07,412 --> 00:26:07,412
the desk that we want to sample from.

579
00:26:03,408 --> 00:26:09,414
It could also be a gift measure.

580
00:26:07,412 --> 00:26:29,434
So once we know the distribution that we

581
00:26:29,434 --> 00:26:29,434
want to examples from, we're going to

582
00:26:29,434 --> 00:26:29,434
design a stochastic process, some kind of

583
00:26:29,434 --> 00:26:29,434
random motion whose distribution is going

584
00:26:29,434 --> 00:26:29,434
to converge to the target distribution.

585
00:26:11,416 --> 00:26:40,445
So as you run the process, think of it as

586
00:26:40,445 --> 00:26:40,445
simulating those molecules that interact

587
00:26:40,445 --> 00:26:40,445
and that converge to your target.

588
00:26:30,435 --> 00:26:45,450
You're just going to simulate that.

589
00:26:42,447 --> 00:26:57,462
And once your system has converged to its

590
00:26:57,462 --> 00:26:57,462
steady state, which is the target

591
00:26:57,462 --> 00:26:57,462
distribution, then each movement on the

592
00:26:57,462 --> 00:26:57,462
steady state density is going to give you

593
00:26:57,462 --> 00:26:57,462
a new sample.

594
00:26:45,450 --> 00:27:09,468
Just for intuition, let's come back to

595
00:27:09,468 --> 00:27:09,468
the desk and say that we have this

596
00:27:09,468 --> 00:27:09,468
uniform measure, uniform distribution on

597
00:27:09,468 --> 00:27:09,468
the desk that we want to sample from.

598
00:27:00,459 --> 00:27:26,485
So we're going to design like a dynamic

599
00:27:26,485 --> 00:27:26,485
that moves randomly around and that's

600
00:27:26,485 --> 00:27:26,485
going to concept to the uniform

601
00:27:26,485 --> 00:27:26,485
distribution, which means that if you run

602
00:27:26,485 --> 00:27:26,485
it long enough, you're just going to

603
00:27:26,485 --> 00:27:26,485
sample everywhere on the desk and it's

604
00:27:26,485 --> 00:27:26,485
going to examples each point equally

605
00:27:26,485 --> 00:27:26,485
often.

606
00:27:09,468 --> 00:27:41,500
And so you're just going to run this

607
00:27:41,500 --> 00:27:41,500
dynamic for a very long time and then

608
00:27:41,500 --> 00:27:41,500
you're going to collect the samples,

609
00:27:41,500 --> 00:27:41,500
collect the examples and use them to

610
00:27:41,500 --> 00:27:41,500
approximate the integral that you started

611
00:27:41,500 --> 00:27:41,500
with.

612
00:27:27,486 --> 00:27:45,504
So this is how sampling is done.

613
00:27:42,501 --> 00:27:54,513
Now, there's two basically one big

614
00:27:54,513 --> 00:27:54,513
question, one big outstanding question is

615
00:27:54,513 --> 00:27:54,513
how do you choose this dynamics?

616
00:27:45,504 --> 00:28:03,516
How do you choose this random motion to

617
00:28:03,516 --> 00:28:03,516
converge to your target distinctions to

618
00:28:03,516 --> 00:28:03,516
sample from the distribution?

619
00:27:55,514 --> 00:28:16,529
So given a target distribution there's

620
00:28:16,529 --> 00:28:16,529
like a closed form formulas for all the

621
00:28:16,529 --> 00:28:16,529
possible choices of processes that you

622
00:28:16,529 --> 00:28:16,529
can use to sample from them.

623
00:28:04,517 --> 00:28:22,535
That's a closed problem and that's also

624
00:28:22,535 --> 00:28:22,535
explained in the paper.

625
00:28:17,530 --> 00:28:34,547
But then out of all of these processes

626
00:28:34,547 --> 00:28:34,547
you would like to know which one is going

627
00:28:34,547 --> 00:28:34,547
to sample the most efficiently and you

628
00:28:34,547 --> 00:28:34,547
also want to know.

629
00:28:23,536 --> 00:28:42,555
And second of all, a lot of the analysis

630
00:28:42,555 --> 00:28:42,555
of stochastic processes is done in

631
00:28:42,555 --> 00:28:42,555
continuous time.

632
00:28:35,548 --> 00:28:50,562
So you know that if you implement this

633
00:28:50,562 --> 00:28:50,562
process it's going to converge at this

634
00:28:50,562 --> 00:28:50,562
rate to the target distinctions.

635
00:28:42,555 --> 00:28:53,565
And so the faster it converges, the

636
00:28:53,565 --> 00:28:53,565
better.

637
00:28:50,563 --> 00:29:04,571
But it could be that when you simulate

638
00:29:04,571 --> 00:29:04,571
this on a computer, in a computer you can

639
00:29:04,571 --> 00:29:04,571
only have like discrete time steps or

640
00:29:04,571 --> 00:29:04,571
like discrete operations in discrete

641
00:29:04,571 --> 00:29:04,571
time.

642
00:28:53,566 --> 00:29:08,575
So you cannot really simulate this

643
00:29:08,575 --> 00:29:08,575
dynamic in continuous time.

644
00:29:04,571 --> 00:29:12,579
So every time you simulate it, it's going

645
00:29:12,579 --> 00:29:12,579
to introduce some error.

646
00:29:09,576 --> 00:29:22,589
Now it could be that the thing that you

647
00:29:22,589 --> 00:29:22,589
simulate on your computer actually goes a

648
00:29:22,589 --> 00:29:22,589
lot slower than the original process that

649
00:29:22,589 --> 00:29:22,589
you wanted to simulate.

650
00:29:13,580 --> 00:29:25,592
So there's these two questions.

651
00:29:22,589 --> 00:29:32,598
How do you take a process that samples

652
00:29:32,598 --> 00:29:32,598
very efficiently, converges very fast to

653
00:29:32,598 --> 00:29:32,598
your target?

654
00:29:25,592 --> 00:29:47,614
But in addition to that, how do you

655
00:29:47,614 --> 00:29:47,614
stimulate the process accurately on your

656
00:29:47,614 --> 00:29:47,614
computer so that's to retain all the

657
00:29:47,614 --> 00:29:47,614
important characteristics of that

658
00:29:47,614 --> 00:29:47,614
process?

659
00:29:32,599 --> 00:30:03,623
So there's many different criteria and

660
00:30:03,623 --> 00:30:03,623
this is what we discussed essentially one

661
00:30:03,623 --> 00:30:03,623
method that state of the art or among the

662
00:30:03,623 --> 00:30:03,623
state of the art is called Hamiltonian

663
00:30:03,623 --> 00:30:03,623
Monte Carlo.

664
00:29:49,616 --> 00:30:15,636
Now, Hamiltonian Monte Carlo, without

665
00:30:15,636 --> 00:30:15,636
getting Hinton too much detail, it has

666
00:30:15,636 --> 00:30:15,636
two advantages.

667
00:30:03,624 --> 00:30:22,643
The first advantage is that it can be

668
00:30:22,643 --> 00:30:22,643
analyzed using mathematical methods.

669
00:30:15,636 --> 00:30:26,647
So you can get guarantees based on your

670
00:30:26,647 --> 00:30:26,647
target distribution.

671
00:30:22,643 --> 00:30:33,654
You can get guarantees of how fast you're

672
00:30:33,654 --> 00:30:33,654
going to converge, how accurate your

673
00:30:33,654 --> 00:30:33,654
samples are, gain to be and so on.

674
00:30:26,647 --> 00:30:39,660
It has also many other desirable

675
00:30:39,660 --> 00:30:39,660
properties.

676
00:30:35,656 --> 00:30:46,667
So one of them which we discuss a lot in

677
00:30:46,667 --> 00:30:46,667
the paper is the importance of being

678
00:30:46,667 --> 00:30:46,667
irreversible.

679
00:30:39,660 --> 00:31:03,678
So irreversible means being irreversible

680
00:31:03,678 --> 00:31:03,678
means that if you run the process forward

681
00:31:03,678 --> 00:31:03,678
in time let's say you run the process

682
00:31:03,678 --> 00:31:03,678
forward in time for like 10 seconds.

683
00:30:47,668 --> 00:31:06,681
Let's say you run the process backward in

684
00:31:06,681 --> 00:31:06,681
time.

685
00:31:03,678 --> 00:31:10,685
So you kind of run the process backward.

686
00:31:06,681 --> 00:31:17,692
You just take a movie and play it

687
00:31:17,692 --> 00:31:17,692
backward and look at how the process

688
00:31:17,692 --> 00:31:17,692
behaves.

689
00:31:10,685 --> 00:31:37,712
Now, a process is reversible if the

690
00:31:37,712 --> 00:31:37,712
forward and the Ballard movies are

691
00:31:37,712 --> 00:31:37,712
statistically indistinguishable and a

692
00:31:37,712 --> 00:31:37,712
process is irreversible if you run time

693
00:31:37,712 --> 00:31:37,712
as time goes forward.

694
00:31:17,692 --> 00:31:44,719
If you run time forward, it would look

695
00:31:44,719 --> 00:31:44,719
statistically different from if you run

696
00:31:44,719 --> 00:31:44,719
the process backward.

697
00:31:37,712 --> 00:31:54,729
I think you can kind of picture what

698
00:31:54,729 --> 00:31:54,729
irreversibility is.

699
00:31:50,725 --> 00:32:05,734
Now, irreversibility is crucial to do

700
00:32:05,734 --> 00:32:05,734
efficient sampling because if you're

701
00:32:05,734 --> 00:32:05,734
reversible, it means that you're going to

702
00:32:05,734 --> 00:32:05,734
backtrack.

703
00:31:54,729 --> 00:32:21,750
Very often when you're sampling positions

704
00:32:21,750 --> 00:32:21,750
on the decks, on the desk, say you're

705
00:32:21,750 --> 00:32:21,750
going to start somewhere, go somewhere

706
00:32:21,750 --> 00:32:21,750
else, and then there's a nontrivial

707
00:32:21,750 --> 00:32:21,750
chance, significant chance that you're

708
00:32:21,750 --> 00:32:21,750
going to come back to where you started.

709
00:32:05,734 --> 00:32:26,755
So it's going to be very slow to explore

710
00:32:26,755 --> 00:32:26,755
all the desk and build skyscrapers

711
00:32:26,755 --> 00:32:26,755
everywhere.

712
00:32:21,750 --> 00:32:31,760
So then sampling turns out to be very

713
00:32:31,760 --> 00:32:31,760
slow.

714
00:32:28,757 --> 00:32:38,767
Now, when you're irreversible, there's

715
00:32:38,767 --> 00:32:38,767
way less chances that you just come back

716
00:32:38,767 --> 00:32:38,767
to where you started.

717
00:32:31,760 --> 00:32:46,775
So you're going to explore the desk a lot

718
00:32:46,775 --> 00:32:46,775
faster because you're not allowed to come

719
00:32:46,775 --> 00:32:46,775
back to the same place so much.

720
00:32:38,767 --> 00:32:52,781
And so you're going to assemble faster

721
00:32:52,781 --> 00:32:52,781
and it's going to be much more

722
00:32:52,781 --> 00:32:52,781
efficient.

723
00:32:47,776 --> 00:33:06,789
So it's actually, by going from a

724
00:33:06,789 --> 00:33:06,789
reversible process for sampling to an

725
00:33:06,789 --> 00:33:06,789
irreversible process, you can gain orders

726
00:33:06,789 --> 00:33:06,789
and orders of magnitude, efficiency.

727
00:32:53,782 --> 00:33:08,791
It's actually pretty crazy.

728
00:33:06,789 --> 00:33:15,797
The Hamiltonian monte Carlo has

729
00:33:15,797 --> 00:33:15,797
guarantees.

730
00:33:10,793 --> 00:33:17,800
Is irreversible.

731
00:33:15,798 --> 00:33:20,803
It has other desirable properties.

732
00:33:18,801 --> 00:33:42,825
And the main one is that you can actually

733
00:33:42,825 --> 00:33:42,825
stimulate it on a computer in a way that

734
00:33:42,825 --> 00:33:42,825
the discretized version, which you

735
00:33:42,825 --> 00:33:42,825
actually simulate on the computer is

736
00:33:42,825 --> 00:33:42,825
going to be very close to the true

737
00:33:42,825 --> 00:33:42,825
Hamilton in Monte Carlo that you get by

738
00:33:42,825 --> 00:33:42,825
writing the equation down.

739
00:33:21,804 --> 00:33:52,835
So this is like why it's so big and why

740
00:33:52,835 --> 00:33:52,835
people use it.

741
00:33:44,827 --> 00:33:59,841
Yeah, I think this is pretty much it.

742
00:33:56,839 --> 00:34:13,850
Hamiltonia Monte Carlo has an accept

743
00:34:13,850 --> 00:34:13,850
rejects step, which is coming back to

744
00:34:13,850 --> 00:34:13,850
when you simulate a process on your

745
00:34:13,850 --> 00:34:13,850
computer.

746
00:33:59,842 --> 00:34:18,855
Every time you discreditize a process,

747
00:34:18,855 --> 00:34:18,855
you introduce some error.

748
00:34:14,851 --> 00:34:32,869
Now you want to make that discretization

749
00:34:32,869 --> 00:34:32,869
error as small as possible so that the

750
00:34:32,869 --> 00:34:32,869
process that you actually simulate on

751
00:34:32,869 --> 00:34:32,869
your computer is very close to what you

752
00:34:32,869 --> 00:34:32,869
want to simulate.

753
00:34:18,855 --> 00:34:52,889
So Hamiltonia Monte Carlo has a very

754
00:34:52,889 --> 00:34:52,889
important step called Metropolis

755
00:34:52,889 --> 00:34:52,889
Hastings, which is going to say, should I

756
00:34:52,889 --> 00:34:52,889
keep the sample or should I drop the

757
00:34:52,889 --> 00:34:52,889
sample and go to the next examples?

758
00:34:33,870 --> 00:35:01,892
And by using Metropolis Hastings, it's a

759
00:35:01,892 --> 00:35:01,892
very clever but also simple procedure.

760
00:34:53,889 --> 00:35:12,903
By using Metropolis Hastings, you

761
00:35:12,903 --> 00:35:12,903
guarantee that the distribution that

762
00:35:12,903 --> 00:35:12,903
you're going to sample is exactly the

763
00:35:12,903 --> 00:35:12,903
same as the distribution that you want to

764
00:35:12,903 --> 00:35:12,903
sample.

765
00:35:02,893 --> 00:35:22,913
So just to put in other, maybe simpler

766
00:35:22,913 --> 00:35:22,913
terms, so you have this process that you

767
00:35:22,913 --> 00:35:22,913
want to simulate.

768
00:35:12,903 --> 00:35:28,919
This process is going to sample your

769
00:35:28,919 --> 00:35:28,919
target distribution.

770
00:35:23,914 --> 00:35:38,929
Now, it could be that when you discrete

771
00:35:38,929 --> 00:35:38,929
the process, because the discrete process

772
00:35:38,929 --> 00:35:38,929
is different, you're going to sample from

773
00:35:38,929 --> 00:35:38,929
a slightly different distinctions.

774
00:35:29,920 --> 00:35:50,941
Now, by using Metropolis Hastings, you're

775
00:35:50,941 --> 00:35:50,941
going to guarantee that the distribution

776
00:35:50,941 --> 00:35:50,941
that you sample from in practice is

777
00:35:50,941 --> 00:35:50,941
exactly the same as what you really want

778
00:35:50,941 --> 00:35:50,941
to sample from.

779
00:35:39,930 --> 00:36:00,945
And so that's very important because it

780
00:36:00,945 --> 00:36:00,945
just tells you that asymptotically as the

781
00:36:00,945 --> 00:36:00,945
number of examples just growth to

782
00:36:00,945 --> 00:36:00,945
infinity.

783
00:35:50,941 --> 00:36:06,951
You're going to recover exactly what you

784
00:36:06,951 --> 00:36:06,951
wanted to recover, which is the adamant

785
00:36:06,951 --> 00:36:06,951
shrine to grow.

786
00:36:00,945 --> 00:36:13,958
Daniel: Awesome.

787
00:36:12,957 --> 00:36:32,977
I remember the Metropolis Hastings and

788
00:36:32,977 --> 00:36:32,977
the Monte Carlo Markov chains in

789
00:36:32,977 --> 00:36:32,977
phylogenetics where you might have many,

790
00:36:32,977 --> 00:36:32,977
many species and many, many locations in

791
00:36:32,977 --> 00:36:32,977
the genome that you're doing phylogenetic

792
00:36:32,977 --> 00:36:32,977
inference over and you just sample,

793
00:36:32,977 --> 00:36:32,977
sample, sample.

794
00:36:13,958 --> 00:36:39,984
And so all these techniques help

795
00:36:39,984 --> 00:36:39,984
accelerate what's possible with any given

796
00:36:39,984 --> 00:36:39,984
computational hardware.

797
00:36:32,977 --> 00:36:46,991
So how would you bring this towards

798
00:36:46,991 --> 00:36:46,991
adaptive agents?

799
00:36:41,986 --> 00:37:00,999
Are we thinking about this sampling

800
00:37:00,999 --> 00:37:00,999
process as being guided by an adaptive

801
00:37:00,999 --> 00:37:00,999
agent and or are we sampling

802
00:37:00,999 --> 00:37:00,999
distributions about an adaptive agent?

803
00:36:46,991 --> 00:37:02,001
Lance: That's a great question.

804
00:37:01,000 --> 00:37:08,007
And I think it sort of brings us to the

805
00:37:08,007 --> 00:37:08,007
conclusion of this work.

806
00:37:03,002 --> 00:37:27,026
In order to have adaptive agents and to

807
00:37:27,026 --> 00:37:27,026
scale adaptive agents so that they're

808
00:37:27,026 --> 00:37:27,026
able to solve complex problems and you're

809
00:37:27,026 --> 00:37:27,026
able to implement them with finite

810
00:37:27,026 --> 00:37:27,026
computational resources, one useful tool

811
00:37:27,026 --> 00:37:27,026
is sampling.

812
00:37:11,010 --> 00:37:33,032
And we'll see many different places where

813
00:37:33,032 --> 00:37:33,032
sampling can be used and has been used in

814
00:37:33,032 --> 00:37:33,032
active inference.

815
00:37:27,026 --> 00:37:58,057
And that's basically what you said

816
00:37:58,057 --> 00:37:58,057
sampling is at the heart of sampling is

817
00:37:58,057 --> 00:37:58,057
choosing data points intelligently so as

818
00:37:58,057 --> 00:37:58,057
to approximate your integral or whatever

819
00:37:58,057 --> 00:37:58,057
it is that you want to do with those

820
00:37:58,057 --> 00:37:58,057
samples.

821
00:37:37,036 --> 00:38:06,059
So you could think of active agents as

822
00:38:06,059 --> 00:38:06,059
solving the sampling problem.

823
00:37:58,057 --> 00:38:10,063
You could think of an active inference

824
00:38:10,063 --> 00:38:10,063
agent.

825
00:38:06,059 --> 00:38:13,066
Let's say that you have a problem of

826
00:38:13,066 --> 00:38:13,066
sampling.

827
00:38:10,063 --> 00:38:22,075
You could think of an agent, an active

828
00:38:22,075 --> 00:38:22,075
inference agent that's going to choose,

829
00:38:22,075 --> 00:38:22,075
oh, I'm going to sample here, and I'm

830
00:38:22,075 --> 00:38:22,075
going to sample here, and I'm going to

831
00:38:22,075 --> 00:38:22,075
sample here.

832
00:38:13,066 --> 00:38:28,081
So active inference agent in the proper

833
00:38:28,081 --> 00:38:28,081
sense of the word.

834
00:38:22,075 --> 00:38:30,083
They do sampling all the time.

835
00:38:28,081 --> 00:38:49,102
The only I would say, slight difference

836
00:38:49,102 --> 00:38:49,102
with what we've just discussed is that

837
00:38:49,102 --> 00:38:49,102
active inference agents, they sample

838
00:38:49,102 --> 00:38:49,102
observations so that they comply with

839
00:38:49,102 --> 00:38:49,102
their preferences and they observations

840
00:38:49,102 --> 00:38:49,102
that also bring them new information

841
00:38:49,102 --> 00:38:49,102
about the world.

842
00:38:31,084 --> 00:38:59,112
So the objective that active inference

843
00:38:59,112 --> 00:38:59,112
agents use to select new sample is the

844
00:38:59,112 --> 00:38:59,112
expected free energy.

845
00:38:50,103 --> 00:39:16,123
Typically we select actions or policies

846
00:39:16,123 --> 00:39:16,123
that have the lowest expected free

847
00:39:16,123 --> 00:39:16,123
energy, which means that the resulting

848
00:39:16,123 --> 00:39:16,123
observations will be close to your

849
00:39:16,123 --> 00:39:16,123
preferences or goal and also bring you

850
00:39:16,123 --> 00:39:16,123
new information about the world.

851
00:39:00,107 --> 00:39:31,138
But you could also conceivably think of

852
00:39:31,138 --> 00:39:31,138
an agent as selecting actions so that the

853
00:39:31,138 --> 00:39:31,138
resulting samples or observations

854
00:39:31,138 --> 00:39:31,138
accurately sample a distribution.

855
00:39:18,125 --> 00:39:42,149
So how could sampling be used in the

856
00:39:42,149 --> 00:39:42,149
context active coherence lab and adaptive

857
00:39:42,149 --> 00:39:42,149
agents?

858
00:39:33,140 --> 00:39:55,162
And so this is actually a great slide, if

859
00:39:55,162 --> 00:39:55,162
you look at the upper panel is what I

860
00:39:55,162 --> 00:39:55,162
just discussed.

861
00:39:42,149 --> 00:40:10,171
So in the first equation that's up there,

862
00:40:10,171 --> 00:40:10,171
you see that the sequence of actions that

863
00:40:10,171 --> 00:40:10,171
you chaos in active inference is the one

864
00:40:10,171 --> 00:40:10,171
that minimizes this minus lot T, this

865
00:40:10,171 --> 00:40:10,171
probes distribution over action

866
00:40:10,171 --> 00:40:10,171
sequences.

867
00:39:55,162 --> 00:40:13,174
So this minus lot T is actually the

868
00:40:13,174 --> 00:40:13,174
expected free energy.

869
00:40:10,171 --> 00:40:21,182
So we choose action sequences that mean

870
00:40:21,182 --> 00:40:21,182
by the expected free energy, as you see

871
00:40:21,182 --> 00:40:21,182
on the equation just below the expected.

872
00:40:14,175 --> 00:40:25,186
Free energy is a sum of risk and

873
00:40:25,186 --> 00:40:25,186
ambiguity.

874
00:40:21,182 --> 00:40:32,193
So you're going to choose action

875
00:40:32,193 --> 00:40:32,193
sequences that minimize risk, but that

876
00:40:32,193 --> 00:40:32,193
also minimize ambiguity about the world.

877
00:40:25,186 --> 00:40:38,199
And in other words, as shown below,

878
00:40:38,199 --> 00:40:38,199
you're going to choose action sequences

879
00:40:38,199 --> 00:40:38,199
that maximize extrinsic value.

880
00:40:32,193 --> 00:40:43,204
So you could think of that as an expected

881
00:40:43,204 --> 00:40:43,204
reward and intrinsic value.

882
00:40:39,199 --> 00:40:49,210
So that would be expected information

883
00:40:49,210 --> 00:40:49,210
gain value that's intrinsic because

884
00:40:49,210 --> 00:40:49,210
you're getting information.

885
00:40:43,204 --> 00:41:03,218
So really the key here is that this

886
00:41:03,218 --> 00:41:03,218
expected free energy, as its name

887
00:41:03,218 --> 00:41:03,218
suggests, it's given by an expectation.

888
00:40:52,213 --> 00:41:08,223
So you see this minus lock p on the left

889
00:41:08,223 --> 00:41:08,223
equals expectation of something.

890
00:41:03,218 --> 00:41:33,248
Now, when you have a very big generative

891
00:41:33,248 --> 00:41:33,248
model, a very big world model, which is

892
00:41:33,248 --> 00:41:33,248
going to be the case all the time, when

893
00:41:33,248 --> 00:41:33,248
you have, like, a real world application

894
00:41:33,248 --> 00:41:33,248
or a complex application, because the

895
00:41:33,248 --> 00:41:33,248
world around us is so high dimensional,

896
00:41:33,248 --> 00:41:33,248
so complex, well, the expected energy

897
00:41:33,248 --> 00:41:33,248
then is going to be a high dimensional

898
00:41:33,248 --> 00:41:33,248
expectation.

899
00:41:08,223 --> 00:41:35,250
What is an expectation?

900
00:41:34,249 --> 00:41:39,254
It's an integral with respect to

901
00:41:39,254 --> 00:41:39,254
probability distribution.

902
00:41:35,250 --> 00:41:53,268
So the point I want to get to is that to

903
00:41:53,268 --> 00:41:53,268
do decision making, you need to evaluate

904
00:41:53,268 --> 00:41:53,268
the expected free energy on different

905
00:41:53,268 --> 00:41:53,268
action sequences.

906
00:41:40,255 --> 00:41:59,274
And this expected free energy is an

907
00:41:59,274 --> 00:41:59,274
expectation with respect to probability

908
00:41:59,274 --> 00:41:59,274
distribution.

909
00:41:53,268 --> 00:42:07,276
It's a very high dimensional integration

910
00:42:07,276 --> 00:42:07,276
problem, very high dimension integration

911
00:42:07,276 --> 00:42:07,276
expectation.

912
00:42:00,269 --> 00:42:11,280
And so how do you approximate that while

913
00:42:11,280 --> 00:42:11,280
you use template?

914
00:42:08,277 --> 00:42:21,290
And I think the first work that actually

915
00:42:21,290 --> 00:42:21,290
used that in the context of active

916
00:42:21,290 --> 00:42:21,290
inference is the work by Fuentes et al.

917
00:42:11,280 --> 00:42:24,293
2020.

918
00:42:22,291 --> 00:42:43,312
I think it's called scaling active

919
00:42:43,312 --> 00:42:43,312
inference with Monte Carlo methods.

920
00:42:26,295 --> 00:42:45,314
So this is what they did.

921
00:42:43,312 --> 00:42:48,317
I think it was published in New Ritz.

922
00:42:46,315 --> 00:42:51,320
It's a very big machine learning

923
00:42:51,320 --> 00:42:51,320
conference.

924
00:42:49,318 --> 00:43:10,333
And their observation was, okay, well, we

925
00:43:10,333 --> 00:43:10,333
have this active inference method which

926
00:43:10,333 --> 00:43:10,333
theoretically is very powerful, I mean,

927
00:43:10,333 --> 00:43:10,333
in the sense that you have this expected

928
00:43:10,333 --> 00:43:10,333
free energy objectives, that puts a lot

929
00:43:10,333 --> 00:43:10,333
of known constructs together.

930
00:42:51,320 --> 00:43:17,340
So the expected free energy, as shown in

931
00:43:17,340 --> 00:43:17,340
figure three here, puts together this

932
00:43:17,340 --> 00:43:17,340
risk.

933
00:43:11,334 --> 00:43:28,351
So this is the divergence between your

934
00:43:28,351 --> 00:43:28,351
predicted distribution of where you're

935
00:43:28,351 --> 00:43:28,351
going to be in the world and your target

936
00:43:28,351 --> 00:43:28,351
distribution of where you want to be in

937
00:43:28,351 --> 00:43:28,351
the world.

938
00:43:17,340 --> 00:43:38,361
And it has this ambiguity term as well,

939
00:43:38,361 --> 00:43:38,361
which has some nice links with phenomena

940
00:43:38,361 --> 00:43:38,361
in psychology, like the streetlight

941
00:43:38,361 --> 00:43:38,361
affect.

942
00:43:28,351 --> 00:43:43,366
So when you minimize we introduce actions

943
00:43:43,366 --> 00:43:43,366
that minimize ambiguity.

944
00:43:39,362 --> 00:43:50,373
You can recover phenomenology that's

945
00:43:50,373 --> 00:43:50,373
known in psychology, like the streetlight

946
00:43:50,373 --> 00:43:50,373
affect or the drunkard search.

947
00:43:43,366 --> 00:43:59,381
Risk is also an objective that's used in

948
00:43:59,381 --> 00:43:59,381
engineering, in controller inference.

949
00:43:51,374 --> 00:44:01,378
So you can see it on the left panel.

950
00:43:59,381 --> 00:44:07,384
So there are a few methods for doing

951
00:44:07,384 --> 00:44:07,384
adaptive agents that use this KL term.

952
00:44:01,378 --> 00:44:14,391
One would be controlled coherence, which

953
00:44:14,391 --> 00:44:14,391
is also known as maximum entropy

954
00:44:14,391 --> 00:44:14,391
reinforcement learning and KL control.

955
00:44:07,384 --> 00:44:38,415
And also, I think, although it needs to

956
00:44:38,415 --> 00:44:38,415
be investigated further, it hasn't been

957
00:44:38,415 --> 00:44:38,415
formally, I think, so far, but with the

958
00:44:38,415 --> 00:44:38,415
KL turn there, you can recover

959
00:44:38,415 --> 00:44:38,415
predictions that are made by prospect

960
00:44:38,415 --> 00:44:38,415
theory which is a big theory from the end

961
00:44:38,415 --> 00:44:38,415
of the 20th century about decision making

962
00:44:38,415 --> 00:44:38,415
in human agents.

963
00:44:15,392 --> 00:44:51,428
So this is, I think, worthwhile to look

964
00:44:51,428 --> 00:44:51,428
into further but I think there's some

965
00:44:51,428 --> 00:44:51,428
very clear links between that theory and

966
00:44:51,428 --> 00:44:51,428
the scale term in the expected franca.

967
00:44:39,416 --> 00:44:57,434
Anyway, so you have this expected free

968
00:44:57,434 --> 00:44:57,434
energy objective that's very powerful.

969
00:44:51,428 --> 00:45:00,431
Chaos puts a lot of things together.

970
00:44:57,434 --> 00:45:03,434
So I think theoretically it's very nice.

971
00:45:00,431 --> 00:45:18,449
In the last line of the upper panel you

972
00:45:18,449 --> 00:45:18,449
can also see that you can view expected

973
00:45:18,449 --> 00:45:18,449
PNG as weighing expected reward and

974
00:45:18,449 --> 00:45:18,449
expected information gain, extrinsic

975
00:45:18,449 --> 00:45:18,449
value, intrinsic value and extrinsic

976
00:45:18,449 --> 00:45:18,449
value.

977
00:45:04,435 --> 00:45:26,457
It's used in expected utility theory,

978
00:45:26,457 --> 00:45:26,457
basic decision theory, RL, optimal

979
00:45:26,457 --> 00:45:26,457
control.

980
00:45:18,449 --> 00:45:36,467
So these are all like equivalent names

981
00:45:36,467 --> 00:45:36,467
for maximizing this extrinsic value and

982
00:45:36,467 --> 00:45:36,467
intrinsic value, expected information

983
00:45:36,467 --> 00:45:36,467
gain.

984
00:45:26,457 --> 00:45:46,477
It's also used in different places and

985
00:45:46,477 --> 00:45:46,477
for example in Bayesian experimental

986
00:45:46,477 --> 00:45:46,477
design which is in statistics.

987
00:45:36,467 --> 00:46:00,485
It was a seminal paper by Lindley in 1956

988
00:46:00,485 --> 00:46:00,485
and Lindley basically said, okay, well,

989
00:46:00,485 --> 00:46:00,485
suppose that you you can do two

990
00:46:00,485 --> 00:46:00,485
experiments or many different

991
00:46:00,485 --> 00:46:00,485
experiments.

992
00:45:46,477 --> 00:46:02,487
How should you choose between them?

993
00:46:00,485 --> 00:46:05,490
What's the best experiment that you

994
00:46:05,490 --> 00:46:05,490
should do?

995
00:46:02,487 --> 00:46:13,498
And the answer that he came up with is

996
00:46:13,498 --> 00:46:13,498
you should do the experiment that gives

997
00:46:13,498 --> 00:46:13,498
you the most information about the

998
00:46:13,498 --> 00:46:13,498
world.

999
00:46:05,490 --> 00:46:20,505
So you have to keep in mind that in that

1000
00:46:20,505 --> 00:46:20,505
paper there was no extrinsic goal.

1001
00:46:15,500 --> 00:46:27,512
It was not like we're going to do an

1002
00:46:27,512 --> 00:46:27,512
experiment to solve this problem or

1003
00:46:27,512 --> 00:46:27,512
achieve these results.

1004
00:46:20,505 --> 00:46:31,516
It was only doing an experiment for the

1005
00:46:31,516 --> 00:46:31,516
sake of it.

1006
00:46:27,512 --> 00:46:38,523
And so he came to the conclusion that the

1007
00:46:38,523 --> 00:46:38,523
best experiment was the one that

1008
00:46:38,523 --> 00:46:38,523
maximized the expected information gain.

1009
00:46:31,516 --> 00:46:58,543
Now suppose that you have a goal in mind

1010
00:46:58,543 --> 00:46:58,543
target, target result or whatnot then you

1011
00:46:58,543 --> 00:46:58,543
would weigh reasonably and one thing you

1012
00:46:58,543 --> 00:46:58,543
could do is weigh the expected

1013
00:46:58,543 --> 00:46:58,543
information gain with your expected

1014
00:46:58,543 --> 00:46:58,543
reward or expected utility or expected

1015
00:46:58,543 --> 00:46:58,543
how close you're going to get to your

1016
00:46:58,543 --> 00:46:58,543
goal.

1017
00:46:38,523 --> 00:47:01,540
And so this is exactly what the expected

1018
00:47:01,540 --> 00:47:01,540
free energy does.

1019
00:46:58,543 --> 00:47:05,544
It puts these two things on the same

1020
00:47:05,544 --> 00:47:05,544
footing.

1021
00:47:01,540 --> 00:47:28,567
So you have this expected free energy

1022
00:47:28,567 --> 00:47:28,567
which is very nice and which is what

1023
00:47:28,567 --> 00:47:28,567
active inference brings to the table and

1024
00:47:28,567 --> 00:47:28,567
what Fuentes et al did in their paper is,

1025
00:47:28,567 --> 00:47:28,567
okay, well, we have this cool method,

1026
00:47:28,567 --> 00:47:28,567
active inference, let's use it to solve

1027
00:47:28,567 --> 00:47:28,567
nontrivial machine learning, slash

1028
00:47:28,567 --> 00:47:28,567
reinforcement learning problems.

1029
00:47:08,547 --> 00:47:47,586
And so when you actually want to solve

1030
00:47:47,586 --> 00:47:47,586
those problems you have some high

1031
00:47:47,586 --> 00:47:47,586
dimensional generative models, high

1032
00:47:47,586 --> 00:47:47,586
dimensional state spaces that just come

1033
00:47:47,586 --> 00:47:47,586
up and you need time plane to evaluate to

1034
00:47:47,586 --> 00:47:47,586
approximate the expected principle.

1035
00:47:30,569 --> 00:47:55,594
So this is what they did and they also

1036
00:47:55,594 --> 00:47:55,594
put together a lot of other cool tricks

1037
00:47:55,594 --> 00:47:55,594
based on neural networks and so on.

1038
00:47:47,586 --> 00:47:59,597
So a very cool paper, totally recommend.

1039
00:47:56,595 --> 00:48:14,607
But I think the point it suggests, and

1040
00:48:14,607 --> 00:48:14,607
this is also the point that we make,

1041
00:48:14,607 --> 00:48:14,607
although in a very different way in this

1042
00:48:14,607 --> 00:48:14,607
paper is that to actually do decision

1043
00:48:14,607 --> 00:48:14,607
making efficiently in practice

1044
00:48:14,607 --> 00:48:14,607
efficiently.

1045
00:47:59,598 --> 00:48:17,610
But also you want to do take good

1046
00:48:17,610 --> 00:48:17,610
decisions.

1047
00:48:14,607 --> 00:48:19,612
You actually need sampling.

1048
00:48:18,611 --> 00:48:28,621
And this is not a new point, by the way.

1049
00:48:25,618 --> 00:48:32,625
I think many people would agree with

1050
00:48:32,625 --> 00:48:32,625
this.

1051
00:48:28,621 --> 00:48:44,637
But I think the active inference approach

1052
00:48:44,637 --> 00:48:44,637
is nice because you have this explicit

1053
00:48:44,637 --> 00:48:44,637
characterization of expected PNG as an

1054
00:48:44,637 --> 00:48:44,637
expectation of something.

1055
00:48:33,626 --> 00:48:51,644
So it becomes pretty clear that you want

1056
00:48:51,644 --> 00:48:51,644
to do sampling because this is what

1057
00:48:51,644 --> 00:48:51,644
sampling is made for.

1058
00:48:44,637 --> 00:49:01,648
So I initially introduction sampling as

1059
00:49:01,648 --> 00:49:01,648
you know, wanting to approximate

1060
00:49:01,648 --> 00:49:01,648
integral, but expectations are integral.

1061
00:48:53,646 --> 00:49:04,651
So yes, sampling is really what you

1062
00:49:04,651 --> 00:49:04,651
want.

1063
00:49:02,649 --> 00:49:10,657
It just comes up like extremely directly

1064
00:49:10,657 --> 00:49:10,657
when you want to do these kind of

1065
00:49:10,657 --> 00:49:10,657
things.

1066
00:49:04,651 --> 00:49:12,659
Awesome.

1067
00:49:11,658 --> 00:49:13,660
Daniel: Thanks.

1068
00:49:12,659 --> 00:49:28,675
And one sensory example of information

1069
00:49:28,675 --> 00:49:28,675
driven sampling is the eye circade the

1070
00:49:28,675 --> 00:49:28,675
movement of the eyes, which also has been

1071
00:49:28,675 --> 00:49:28,675
modeled in many works from the active

1072
00:49:28,675 --> 00:49:28,675
inference perspective.

1073
00:49:13,660 --> 00:49:56,703
And it's even below our level of

1074
00:49:56,703 --> 00:49:56,703
conscious awareness with the eyes darting

1075
00:49:56,703 --> 00:49:56,703
around to reduce their uncertainty such

1076
00:49:56,703 --> 00:49:56,703
that our visual generative model can have

1077
00:49:56,703 --> 00:49:56,703
high resolution and color throughout the

1078
00:49:56,703 --> 00:49:56,703
visual field, even though that doesn't

1079
00:49:56,703 --> 00:49:56,703
reflect the anatomy of the retina, which

1080
00:49:56,703 --> 00:49:56,703
has a blind spot and differential

1081
00:49:56,703 --> 00:49:56,703
resolution and color attention in the

1082
00:49:56,703 --> 00:49:56,703
periphery.

1083
00:49:28,675 --> 00:50:08,709
So I kind of see that as slam dunk

1084
00:50:08,709 --> 00:50:08,709
evidence that our visual experience and

1085
00:50:08,709 --> 00:50:08,709
by extension other sensory modalities are

1086
00:50:08,709 --> 00:50:08,709
coming from the generative model.

1087
00:49:56,703 --> 00:50:22,723
They're not just received and processed

1088
00:50:22,723 --> 00:50:22,723
in an inward bound fashion and that

1089
00:50:22,723 --> 00:50:22,723
adaptive sampling is vital to maintain

1090
00:50:22,723 --> 00:50:22,723
the coherence of that generative model.

1091
00:50:08,709 --> 00:50:25,726
Lance: Absolutely.

1092
00:50:24,725 --> 00:50:31,732
You want to do adaptive sampling in order

1093
00:50:31,732 --> 00:50:31,732
to preserve the structure.

1094
00:50:26,727 --> 00:50:39,740
I mean, you have this beautiful structure

1095
00:50:39,740 --> 00:50:39,740
in the expected free energy of expected

1096
00:50:39,740 --> 00:50:39,740
information gain.

1097
00:50:31,732 --> 00:50:46,747
So let's say we're just like wanting

1098
00:50:46,747 --> 00:50:46,747
we're just like looking at stuff, so we

1099
00:50:46,747 --> 00:50:46,747
don't have any direct goal.

1100
00:50:39,740 --> 00:51:04,759
The expected energy reduces to expect

1101
00:51:04,759 --> 00:51:04,759
information gain or approximates that and

1102
00:51:04,759 --> 00:51:04,759
you just want to sample sampling is the

1103
00:51:04,759 --> 00:51:04,759
key to approximate this expected

1104
00:51:04,759 --> 00:51:04,759
information gain term while preserving

1105
00:51:04,759 --> 00:51:04,759
the statistics of the generative model.

1106
00:50:46,747 --> 00:51:10,765
So it's very central to scaling active

1107
00:51:10,765 --> 00:51:10,765
coherence.

1108
00:51:05,760 --> 00:51:22,777
I wouldn't say it's central, active

1109
00:51:22,777 --> 00:51:22,777
inference lab proper just the theory

1110
00:51:22,777 --> 00:51:22,777
because in the theory you get these

1111
00:51:22,777 --> 00:51:22,777
expectations and you know how to select

1112
00:51:22,777 --> 00:51:22,777
actions.

1113
00:51:11,766 --> 00:51:33,788
But anytime you want to scale active

1114
00:51:33,788 --> 00:51:33,788
coherence, deploy active inference to

1115
00:51:33,788 --> 00:51:33,788
solve a problem you want to, sampling is

1116
00:51:33,788 --> 00:51:33,788
going to come into play inevitably.

1117
00:51:22,777 --> 00:51:43,798
There's other ways to scale active

1118
00:51:43,798 --> 00:51:43,798
inference.

1119
00:51:39,794 --> 00:51:48,803
One other way could be what's called

1120
00:51:48,803 --> 00:51:48,803
amortizing.

1121
00:51:44,799 --> 00:51:49,804
Amortization.

1122
00:51:48,803 --> 00:51:50,805
So with deep neural networks.

1123
00:51:49,804 --> 00:51:59,814
So one thing you could do is train a

1124
00:51:59,814 --> 00:51:59,814
neural network to predict the expected

1125
00:51:59,814 --> 00:51:59,814
free energy based on your genital model

1126
00:51:59,814 --> 00:51:59,814
and near sensory data.

1127
00:51:50,805 --> 00:52:07,816
But this amortization procedure, as does

1128
00:52:07,816 --> 00:52:07,816
any training of neural networks, it's

1129
00:52:07,816 --> 00:52:07,816
going to require a lot of data.

1130
00:52:00,809 --> 00:52:08,817
So it's going to be slow.

1131
00:52:07,816 --> 00:52:11,820
It's not something that you can deploy

1132
00:52:11,820 --> 00:52:11,820
right away.

1133
00:52:09,818 --> 00:52:26,835
So this is very nice way of I mean,

1134
00:52:26,835 --> 00:52:26,835
amortization is a very nice way of doing

1135
00:52:26,835 --> 00:52:26,835
things, but it's not something that you

1136
00:52:26,835 --> 00:52:26,835
can use like the first time you active

1137
00:52:26,835 --> 00:52:26,835
inference lab to solve a new task.

1138
00:52:12,821 --> 00:52:51,860
So a nice way of scaling active coherence

1139
00:52:51,860 --> 00:52:51,860
and it's not the only way, or it's not

1140
00:52:51,860 --> 00:52:51,860
going to solve all the problems, but it

1141
00:52:51,860 --> 00:52:51,860
would be to use sampling to approximate

1142
00:52:51,860 --> 00:52:51,860
the expected free energy to make

1143
00:52:51,860 --> 00:52:51,860
decisions in real time as you accumulate

1144
00:52:51,860 --> 00:52:51,860
data, then you can train a neural network

1145
00:52:51,860 --> 00:52:51,860
to predict the expected free energy.

1146
00:52:26,835 --> 00:52:54,863
I think this is exactly what Fuentes et

1147
00:52:54,863 --> 00:52:54,863
al.

1148
00:52:51,860 --> 00:52:56,865
Did in their paper, by the way.

1149
00:52:54,863 --> 00:52:58,867
So if you're interested, make sure to

1150
00:52:58,867 --> 00:52:58,867
check it out.

1151
00:52:56,865 --> 00:53:03,866
Daniel: Figure three.

1152
00:53:02,865 --> 00:53:24,887
It's something that Vaughn can just look

1153
00:53:24,887 --> 00:53:24,887
ant for so long, because the imperative,

1154
00:53:24,887 --> 00:53:24,887
what is being utilized in action

1155
00:53:24,887 --> 00:53:24,887
selection by an active inference agent is

1156
00:53:24,887 --> 00:53:24,887
something like a generalization of all

1157
00:53:24,887 --> 00:53:24,887
the words that we see written lower.

1158
00:53:03,866 --> 00:53:34,897
And unless we knew about that

1159
00:53:34,897 --> 00:53:34,897
generalization or that unified

1160
00:53:34,897 --> 00:53:34,897
imperative, it seems like these are quite

1161
00:53:34,897 --> 00:53:34,897
literally orthogonal or disparate from

1162
00:53:34,897 --> 00:53:34,897
each other.

1163
00:53:24,887 --> 00:53:46,909
I mean, what could be more different than

1164
00:53:46,909 --> 00:53:46,909
maximum information, gain oriented

1165
00:53:46,909 --> 00:53:46,909
strategies and maximum reward driven

1166
00:53:46,909 --> 00:53:46,909
strategies?

1167
00:53:35,898 --> 00:53:55,918
And sometimes to get both those flavors

1168
00:53:55,918 --> 00:53:55,918
in the same model, people might try to

1169
00:53:55,918 --> 00:53:55,918
coerce one into the other.

1170
00:53:46,909 --> 00:54:07,924
Usually we see that in terms of a novelty

1171
00:54:07,924 --> 00:54:07,924
bonus or an exploratory impulse bolted on

1172
00:54:07,924 --> 00:54:07,924
to a reward or a pragmatic value driven

1173
00:54:07,924 --> 00:54:07,924
agent.

1174
00:53:55,918 --> 00:54:17,934
And so once you start modifying the

1175
00:54:17,934 --> 00:54:17,934
models and just adding in these

1176
00:54:17,934 --> 00:54:17,934
arbitrarily constructed components, you

1177
00:54:17,934 --> 00:54:17,934
may get adaptive behavior.

1178
00:54:07,924 --> 00:54:23,939
It's never been a claim in the active

1179
00:54:23,939 --> 00:54:23,939
space that other models don't have

1180
00:54:23,939 --> 00:54:23,939
efficacy.

1181
00:54:18,935 --> 00:54:42,959
Rather that by thinking about all of

1182
00:54:42,959 --> 00:54:42,959
these special cases as being

1183
00:54:42,959 --> 00:54:42,959
situationally arising from a more general

1184
00:54:42,959 --> 00:54:42,959
imperative with expected free energy for

1185
00:54:42,959 --> 00:54:42,959
future oriented policy selection, we

1186
00:54:42,959 --> 00:54:42,959
might gain the ability to do what?

1187
00:54:23,940 --> 00:55:06,977
What will we gain conceptually or in

1188
00:55:06,977 --> 00:55:06,977
practice by taking situations where today

1189
00:55:06,977 --> 00:55:06,977
people are using maybe just one of these

1190
00:55:06,977 --> 00:55:06,977
terms as an imperative for what their

1191
00:55:06,977 --> 00:55:06,977
models are doing and what do we gain or

1192
00:55:06,977 --> 00:55:06,977
what might we expect from potentially

1193
00:55:06,977 --> 00:55:06,977
generalizing those imperatives?

1194
00:54:44,961 --> 00:55:12,983
Lance: That's a brilliant and very

1195
00:55:12,983 --> 00:55:12,983
difficult question.

1196
00:55:08,979 --> 00:55:44,015
It's also a question that I would say

1197
00:55:44,015 --> 00:55:44,015
everybody active coherence lab gets asked

1198
00:55:44,015 --> 00:55:44,015
at some point because, let's say people

1199
00:55:44,015 --> 00:55:44,015
doing reinforcement learning, they use

1200
00:55:44,015 --> 00:55:44,015
many different objectives that would be

1201
00:55:44,015 --> 00:55:44,015
tailored to solving one particular task

1202
00:55:44,015 --> 00:55:44,015
or a different task, and they would have

1203
00:55:44,015 --> 00:55:44,015
these ad hoc novelty bonuses that would

1204
00:55:44,015 --> 00:55:44,015
work very well in certain tasks.

1205
00:55:13,984 --> 00:55:47,018
It's a different approach.

1206
00:55:46,017 --> 00:55:57,028
This approach that I was just mentioning

1207
00:55:57,028 --> 00:55:57,028
with reinforcement learning tests to be

1208
00:55:57,028 --> 00:55:57,028
it's much more bottom up.

1209
00:55:50,021 --> 00:56:03,028
It's like we want to have an agent that

1210
00:56:03,028 --> 00:56:03,028
solves this problem, makes this work, and

1211
00:56:03,028 --> 00:56:03,028
so on.

1212
00:55:57,028 --> 00:56:10,035
So we're going to start building and test

1213
00:56:10,035 --> 00:56:10,035
it until it works.

1214
00:56:04,029 --> 00:56:14,039
Active inference lab approach is top

1215
00:56:14,039 --> 00:56:14,039
down.

1216
00:56:11,036 --> 00:56:21,046
So it starts from the furniture principle

1217
00:56:21,046 --> 00:56:21,046
and it's very theoretical.

1218
00:56:15,040 --> 00:56:35,060
And the approach is like, okay, well,

1219
00:56:35,060 --> 00:56:35,060
let's model how an agent interacts with

1220
00:56:35,060 --> 00:56:35,060
its environment, the force generic kind

1221
00:56:35,060 --> 00:56:35,060
of agent, and let's impose constraints

1222
00:56:35,060 --> 00:56:35,060
that an agent has to satisfy.

1223
00:56:21,046 --> 00:56:46,071
So the basic constraint that we have in

1224
00:56:46,071 --> 00:56:46,071
this paper is that you have three sets of

1225
00:56:46,071 --> 00:56:46,071
variables.

1226
00:56:35,060 --> 00:56:52,077
You have variables in the external world

1227
00:56:52,077 --> 00:56:52,077
that you cannot directly have access to.

1228
00:56:46,071 --> 00:56:56,081
So this would be maybe the temperature in

1229
00:56:56,081 --> 00:56:56,081
the room.

1230
00:56:52,077 --> 00:57:02,081
Then you have sensory variables or

1231
00:57:02,081 --> 00:57:02,081
observations.

1232
00:56:58,083 --> 00:57:13,092
So by the way, the environmental

1233
00:57:13,092 --> 00:57:13,092
variables that are denoted as S, the

1234
00:57:13,092 --> 00:57:13,092
sensory observations, are the observatory

1235
00:57:13,092 --> 00:57:13,092
or the observations that are denoted as

1236
00:57:13,092 --> 00:57:13,092
O.

1237
00:57:03,082 --> 00:57:25,104
So this is what belongs to the world and

1238
00:57:25,104 --> 00:57:25,104
you have direct access to this would be

1239
00:57:25,104 --> 00:57:25,104
like your sensations, what you see and so

1240
00:57:25,104 --> 00:57:25,104
on.

1241
00:57:13,092 --> 00:57:38,117
And then you have the action denoted in

1242
00:57:38,117 --> 00:57:38,117
the paper by A, which is basically what

1243
00:57:38,117 --> 00:57:38,117
you can do, and the different things, the

1244
00:57:38,117 --> 00:57:38,117
different options that you can choose

1245
00:57:38,117 --> 00:57:38,117
from at any point in time.

1246
00:57:25,104 --> 00:57:44,123
And this is what will enable you to

1247
00:57:44,123 --> 00:57:44,123
influence the world S and influence your

1248
00:57:44,123 --> 00:57:44,123
observations.

1249
00:57:38,117 --> 00:57:45,123
O.

1250
00:57:44,123 --> 00:58:19,152
So we start from a very generic model of

1251
00:58:19,152 --> 00:58:19,152
an agent and how it interacts with the

1252
00:58:19,152 --> 00:58:19,152
world, these three sets of variables that

1253
00:58:19,152 --> 00:58:19,152
evolve in time and just by adding a few

1254
00:58:19,152 --> 00:58:19,152
other, I would say, constraints that

1255
00:58:19,152 --> 00:58:19,152
agents satisfy, or intelligent agents

1256
00:58:19,152 --> 00:58:19,152
hopefully satisfy, that these agents can

1257
00:58:19,152 --> 00:58:19,152
be described as taking decisions that

1258
00:58:19,152 --> 00:58:19,152
minimize expected free energy.

1259
00:57:45,124 --> 00:58:25,158
So the expected free energy just comes up

1260
00:58:25,158 --> 00:58:25,158
from this general theory of how agents

1261
00:58:25,158 --> 00:58:25,158
behave.

1262
00:58:19,152 --> 00:58:34,167
So to answer your question, what does

1263
00:58:34,167 --> 00:58:34,167
this actually bring in practice?

1264
00:58:27,160 --> 00:58:42,175
Well, first of all, there's many methods

1265
00:58:42,175 --> 00:58:42,175
out there that are similar to active

1266
00:58:42,175 --> 00:58:42,175
inference.

1267
00:58:35,168 --> 00:58:46,179
In some cases, they're almost the same.

1268
00:58:43,176 --> 00:58:55,188
The first difference, which is not

1269
00:58:55,188 --> 00:58:55,188
necessarily an advantage or a

1270
00:58:55,188 --> 00:58:55,188
disadvantage, but it's the approach.

1271
00:58:48,181 --> 00:58:59,192
These are the methods that you see out

1272
00:58:59,192 --> 00:58:59,192
there that come very close to active

1273
00:58:59,192 --> 00:58:59,192
inference.

1274
00:58:55,188 --> 00:59:13,200
They have been designed from a bottom up

1275
00:59:13,200 --> 00:59:13,200
approach of like, we want to model this

1276
00:59:13,200 --> 00:59:13,200
system or we want to solve this task, so

1277
00:59:13,200 --> 00:59:13,200
we're going to add all the components

1278
00:59:13,200 --> 00:59:13,200
that are needed until our agent does what

1279
00:59:13,200 --> 00:59:13,200
we want it to do.

1280
00:59:00,187 --> 00:59:20,207
And it turns out that sometimes all these

1281
00:59:20,207 --> 00:59:20,207
ingredients turn out to be exactly what

1282
00:59:20,207 --> 00:59:20,207
we get.

1283
00:59:14,201 --> 00:59:23,210
Active Inference lab or very similar.

1284
00:59:20,207 --> 00:59:30,217
Other times, maybe the task would be

1285
00:59:30,217 --> 00:59:30,217
simpler and you would get less

1286
00:59:30,217 --> 00:59:30,217
ingredients.

1287
00:59:25,212 --> 00:59:37,224
The disadvantage of that, I would say, is

1288
00:59:37,224 --> 00:59:37,224
that it can turn out to be very messy.

1289
00:59:31,218 --> 00:59:52,239
So you get a new task or a new thing to

1290
00:59:52,239 --> 00:59:52,239
model, maybe a new paradigm that some

1291
00:59:52,239 --> 00:59:52,239
subject would do, and you end up using a

1292
00:59:52,239 --> 00:59:52,239
very different model, a very different

1293
00:59:52,239 --> 00:59:52,239
objective to describe the behavior at

1294
00:59:52,239 --> 00:59:52,239
hand.

1295
00:59:37,224 --> 01:00:01,049
So it's harder to have like a unified

1296
01:00:01,049 --> 01:00:01,049
perspective of what's going on.

1297
00:59:52,239 --> 01:00:09,023
Active Inference I would say the key

1298
01:00:09,023 --> 01:00:09,023
contribution is that you get this unified

1299
01:00:09,023 --> 01:00:09,023
perspective from it.

1300
01:00:01,659 --> 01:00:18,944
You get this objective that puts together

1301
01:00:18,944 --> 01:00:18,944
a lot of other constructs that we know

1302
01:00:18,944 --> 01:00:18,944
and love and puts them together.

1303
01:00:09,027 --> 01:00:30,153
And you know that with this objective you

1304
01:00:30,153 --> 01:00:30,153
can do a lot of things, which is, for

1305
01:00:30,153 --> 01:00:30,153
example, decision making that weighs

1306
01:00:30,153 --> 01:00:30,153
exploration and exploration.

1307
01:00:18,956 --> 01:00:39,093
Now, there are some challenges with

1308
01:00:39,093 --> 01:00:39,093
active inference and anybody using active

1309
01:00:39,093 --> 01:00:39,093
inference would be familiar with them.

1310
01:00:31,196 --> 01:00:48,977
The first one is the scaling up because

1311
01:00:48,977 --> 01:00:48,977
you have this approach, active inference,

1312
01:00:48,977 --> 01:00:48,977
which is so complex in a way.

1313
01:00:40,106 --> 01:00:52,319
I mean, you need to have a generative

1314
01:00:52,319 --> 01:00:52,319
model of the world.

1315
01:00:48,989 --> 01:00:57,804
You need to have to be able to compute

1316
01:00:57,804 --> 01:00:57,804
all these expectations.

1317
01:00:52,364 --> 01:01:03,889
First of all, you need to be able to

1318
01:01:03,889 --> 01:01:03,889
compute all these posterior distributions

1319
01:01:03,889 --> 01:01:03,889
using bayes rule or variational

1320
01:01:03,889 --> 01:01:03,889
inference.

1321
01:00:57,838 --> 01:01:22,702
Then once you have those posterior or

1322
01:01:22,702 --> 01:01:22,702
approximate posterior distributions based

1323
01:01:22,702 --> 01:01:22,702
on your high dimensional model of the

1324
01:01:22,702 --> 01:01:22,702
world, then you need to compute some

1325
01:01:22,702 --> 01:01:22,702
expectations, very high dimensional

1326
01:01:22,702 --> 01:01:22,702
expectation using sampling or whatnot, to

1327
01:01:22,702 --> 01:01:22,702
then get the expected free energy.

1328
01:01:04,979 --> 01:01:24,970
So the expected free energy doesn't come

1329
01:01:24,970 --> 01:01:24,970
up for free.

1330
01:01:22,739 --> 01:01:30,503
It's actually a very I would say it's a

1331
01:01:30,503 --> 01:01:30,503
quite sophisticated thing.

1332
01:01:24,973 --> 01:01:33,841
It puts all these things together, but it

1333
01:01:33,841 --> 01:01:33,841
doesn't come for free.

1334
01:01:30,520 --> 01:01:45,000
It's hard to implement on a practical

1335
01:01:45,000 --> 01:01:45,000
problem that's nontrivial beyond toys and

1336
01:01:45,000 --> 01:01:45,000
nations and people have done it, but it's

1337
01:01:45,000 --> 01:01:45,000
a challenge.

1338
01:01:34,942 --> 01:02:08,172
So the problem that active coherence has

1339
01:02:08,172 --> 01:02:08,172
is, okay, well, we have this night

1340
01:02:08,172 --> 01:02:08,172
theory, we have this very nice objective

1341
01:02:08,172 --> 01:02:08,172
that theoretically works very well, and

1342
01:02:08,172 --> 01:02:08,172
theoretically it's like or it's similar

1343
01:02:08,172 --> 01:02:08,172
to what you would like to have for any

1344
01:02:08,172 --> 01:02:08,172
kind of agenda.

1345
01:01:46,018 --> 01:02:13,224
But we need to find ways of scaling this

1346
01:02:13,224 --> 01:02:13,224
up.

1347
01:02:09,186 --> 01:02:37,463
Here comes the beauty of this, is that in

1348
01:02:37,463 --> 01:02:37,463
scaling up active inference, you're going

1349
01:02:37,463 --> 01:02:37,463
to use sampling, you're going to use

1350
01:02:37,463 --> 01:02:37,463
techniques from optimization, from

1351
01:02:37,463 --> 01:02:37,463
coherence, and so you're going to get

1352
01:02:37,463 --> 01:02:37,463
something that's slightly different from

1353
01:02:37,463 --> 01:02:37,463
the active inference scheme that you

1354
01:02:37,463 --> 01:02:37,463
started with.

1355
01:02:16,254 --> 01:02:46,552
So you had the active inference scheme

1356
01:02:46,552 --> 01:02:46,552
proper, which was in the picture in the

1357
01:02:46,552 --> 01:02:46,552
previous slide.

1358
01:02:37,464 --> 01:02:53,625
This is active inference as you would

1359
01:02:53,625 --> 01:02:53,625
like to implement it if you could.

1360
01:02:49,584 --> 01:03:08,717
But because the problem is complicated

1361
01:03:08,717 --> 01:03:08,717
and you have a high dimension state,

1362
01:03:08,717 --> 01:03:08,717
space and so on, you have many things

1363
01:03:08,717 --> 01:03:08,717
that are computationally intensive,

1364
01:03:08,717 --> 01:03:08,717
you're going to use something, you're

1365
01:03:08,717 --> 01:03:08,717
going to use optimization, you're gain to

1366
01:03:08,717 --> 01:03:08,717
use inference, and so you're going to get

1367
01:03:08,717 --> 01:03:08,717
something.

1368
01:02:54,635 --> 01:03:18,814
Active inference lab algorithm that

1369
01:03:18,814 --> 01:03:18,814
scales, but that's slightly different

1370
01:03:18,814 --> 01:03:18,814
from what you started because it has all

1371
01:03:18,814 --> 01:03:18,814
these other steps.

1372
01:03:09,725 --> 01:03:25,886
Now, in doing so, the active coherence

1373
01:03:25,886 --> 01:03:25,886
agent becomes engineered.

1374
01:03:19,820 --> 01:03:39,022
So it becomes closer to these

1375
01:03:39,022 --> 01:03:39,022
reinforcement learning and bottom up

1376
01:03:39,022 --> 01:03:39,022
agents that are built in a bottom up way

1377
01:03:39,022 --> 01:03:39,022
to solve certain tasks.

1378
01:03:25,888 --> 01:03:47,104
Because you want to engineer the active

1379
01:03:47,104 --> 01:03:47,104
impress algorithm to be able to work to

1380
01:03:47,104 --> 01:03:47,104
solve a certain problem, to scale it in a

1381
01:03:47,104 --> 01:03:47,104
certain way.

1382
01:03:39,024 --> 01:03:52,155
So in doing so, active imprint becomes

1383
01:03:52,155 --> 01:03:52,155
closer to reinforcement learning.

1384
01:03:48,109 --> 01:04:03,203
Now, conversely, in reinforcement

1385
01:04:03,203 --> 01:04:03,203
learning, the amount of compute is

1386
01:04:03,203 --> 01:04:03,203
increasing.

1387
01:03:52,157 --> 01:04:15,329
People want to build reinforcement

1388
01:04:15,329 --> 01:04:15,329
learning agents that are increasingly

1389
01:04:15,329 --> 01:04:15,329
learn in an unsupervised manner just

1390
01:04:15,329 --> 01:04:15,329
because this scale is better.

1391
01:04:04,217 --> 01:04:27,440
You can't always design all the

1392
01:04:27,440 --> 01:04:27,440
components of your reinforcement learning

1393
01:04:27,440 --> 01:04:27,440
agent to solve any single tax.

1394
01:04:18,354 --> 01:04:33,508
It's just too impractical, especially

1395
01:04:33,508 --> 01:04:33,508
when tasks become more and more

1396
01:04:33,508 --> 01:04:33,508
complicated.

1397
01:04:27,440 --> 01:04:45,625
You just would like general solutions

1398
01:04:45,625 --> 01:04:45,625
that are going to work and are going to

1399
01:04:45,625 --> 01:04:45,625
handle a lot of different types of

1400
01:04:45,625 --> 01:04:45,625
situations.

1401
01:04:34,514 --> 01:04:52,694
So reinforcement learning is adding or

1402
01:04:52,694 --> 01:04:52,694
subtracting ingredients to their

1403
01:04:52,694 --> 01:04:52,694
algorithms.

1404
01:04:45,627 --> 01:04:54,718
All these algorithms are evolving.

1405
01:04:52,698 --> 01:05:26,971
But in some sense you can see this is

1406
01:05:26,971 --> 01:05:26,971
debatable, I suppose, but you can see a

1407
01:05:26,971 --> 01:05:26,971
general tendency towards moving to world

1408
01:05:26,971 --> 01:05:26,971
models and generative models, moving to

1409
01:05:26,971 --> 01:05:26,971
intrinsic motivation, which is another

1410
01:05:26,971 --> 01:05:26,971
word for expected information gain or

1411
01:05:26,971 --> 01:05:26,971
variants thereof, and an intrinsic

1412
01:05:26,971 --> 01:05:26,971
motivation or intrinsic value that's

1413
01:05:26,971 --> 01:05:26,971
added onto extrinsic value which is your

1414
01:05:26,971 --> 01:05:26,971
expected reward.

1415
01:04:55,722 --> 01:05:54,253
So you see many I mean, I think we're

1416
01:05:54,253 --> 01:05:54,253
seeing reinforcement learning evolve in a

1417
01:05:54,253 --> 01:05:54,253
direction also that is closer active

1418
01:05:54,253 --> 01:05:54,253
inference lab because everybody wants

1419
01:05:54,253 --> 01:05:54,253
algorithms that stole different tasks and

1420
01:05:54,253 --> 01:05:54,253
not to have to change the algorithms for

1421
01:05:54,253 --> 01:05:54,253
changing environments and so on.

1422
01:05:26,973 --> 01:06:04,296
So in my view, even though we started

1423
01:06:04,296 --> 01:06:04,296
with two different approaches, a bottom

1424
01:06:04,296 --> 01:06:04,296
up approach and a top down approach,

1425
01:06:04,296 --> 01:06:04,296
these are converging.

1426
01:05:55,259 --> 01:06:22,472
Now to come back to the contribution of

1427
01:06:22,472 --> 01:06:22,472
active inference, if one reads through

1428
01:06:22,472 --> 01:06:22,472
the paper and one looks at the derivation

1429
01:06:22,472 --> 01:06:22,472
active inference lab, the point is that

1430
01:06:22,472 --> 01:06:22,472
it's very agnostic.

1431
01:06:05,302 --> 01:06:25,502
It's agnostic to the environment that

1432
01:06:25,502 --> 01:06:25,502
we're in.

1433
01:06:22,473 --> 01:06:27,528
It's an agnostic to many things.

1434
01:06:25,504 --> 01:06:29,544
So it's very general.

1435
01:06:27,529 --> 01:06:46,717
And so if you take many practical

1436
01:06:46,717 --> 01:06:46,717
reinforcement learning agent, you will

1437
01:06:46,717 --> 01:06:46,717
see that they interact with their

1438
01:06:46,717 --> 01:06:46,717
environment in a way that's compatible

1439
01:06:46,717 --> 01:06:46,717
with the assumptions of the free hundred

1440
01:06:46,717 --> 01:06:46,717
principle.

1441
01:06:30,551 --> 01:07:00,790
In other words, the reinforcement

1442
01:07:00,790 --> 01:07:00,790
learning agents can be recast as specific

1443
01:07:00,790 --> 01:07:00,790
active inference agents with specific

1444
01:07:00,790 --> 01:07:00,790
giant models.

1445
01:06:47,723 --> 01:07:02,812
So this is really the key thing.

1446
01:07:00,792 --> 01:07:05,849
It's this unifying perspective.

1447
01:07:02,812 --> 01:07:17,960
I'm not saying it unifies everything, but

1448
01:07:17,960 --> 01:07:17,960
I'm saying that many different

1449
01:07:17,960 --> 01:07:17,960
reinforcement learning algorithms can be

1450
01:07:17,960 --> 01:07:17,960
recast as active inference agents.

1451
01:07:06,850 --> 01:07:39,185
And so this is not to say that active

1452
01:07:39,185 --> 01:07:39,185
inference lab implementation of those

1453
01:07:39,185 --> 01:07:39,185
reinforcement algorithms is going to be

1454
01:07:39,185 --> 01:07:39,185
better, but it's more like a theoretical

1455
01:07:39,185 --> 01:07:39,185
contribution of like this set of

1456
01:07:39,185 --> 01:07:39,185
equations given by the expected primary

1457
01:07:39,185 --> 01:07:39,185
is a complete recipe or almost complete

1458
01:07:39,185 --> 01:07:39,185
recipe to generate adaptive agents.

1459
01:07:17,969 --> 01:07:43,226
So in some sense you don't have to go any

1460
01:07:43,226 --> 01:07:43,226
further than that.

1461
01:07:39,187 --> 01:07:59,382
And so you can view all these

1462
01:07:59,382 --> 01:07:59,382
reinforcement learning algorithms that

1463
01:07:59,382 --> 01:07:59,382
comply with the assumptions so that can

1464
01:07:59,382 --> 01:07:59,382
be recast as active inference algorithms

1465
01:07:59,382 --> 01:07:59,382
as ways of scaling active inference and

1466
01:07:59,382 --> 01:07:59,382
making active inference work.

1467
01:07:43,228 --> 01:08:17,504
So it's not like I don't see any kind of

1468
01:08:17,504 --> 01:08:17,504
conflict between active inference and

1469
01:08:17,504 --> 01:08:17,504
reinforcement learning, but it's more

1470
01:08:17,504 --> 01:08:17,504
like the reinforcement learning

1471
01:08:17,504 --> 01:08:17,504
algorithms that work well and that can be

1472
01:08:17,504 --> 01:08:17,504
recast as active inference algorithms.

1473
01:07:59,387 --> 01:08:30,634
And there are many, I would say more

1474
01:08:30,634 --> 01:08:30,634
algorithms that can be recast and

1475
01:08:30,634 --> 01:08:30,634
algorithm that can help when you look at

1476
01:08:30,634 --> 01:08:30,634
the assumptions of the free energy

1477
01:08:30,634 --> 01:08:30,634
principle that are super generic.

1478
01:08:17,505 --> 01:08:41,740
So you can view all these algorithms as

1479
01:08:41,740 --> 01:08:41,740
specific implementations of active

1480
01:08:41,740 --> 01:08:41,740
inference in a way that active inference

1481
01:08:41,740 --> 01:08:41,740
is meant to scale well.

1482
01:08:30,636 --> 01:08:44,776
So this is kind of like the thing.

1483
01:08:41,744 --> 01:08:54,879
And so I think ultimately, again, these

1484
01:08:54,879 --> 01:08:54,879
two Fields are going to converge, but I

1485
01:08:54,879 --> 01:08:54,879
do not see any tension between them.

1486
01:08:44,777 --> 01:08:58,918
It's more like the tools from one can be

1487
01:08:58,918 --> 01:08:58,918
used in the other.

1488
01:08:55,879 --> 01:09:04,913
I see great work going forward.

1489
01:09:02,893 --> 01:09:08,952
And this is kind of like what we want to

1490
01:09:08,952 --> 01:09:08,952
do with this paper.

1491
01:09:04,914 --> 01:09:22,095
Put this active coherence where it comes

1492
01:09:22,095 --> 01:09:22,095
from very succinctly, and also make it

1493
01:09:22,095 --> 01:09:22,095
accessible for people who don't know the

1494
01:09:22,095 --> 01:09:22,095
jargon from the fringe principal and

1495
01:09:22,095 --> 01:09:22,095
active coherence community.

1496
01:09:08,953 --> 01:09:28,159
And yes, see the exciting developments

1497
01:09:28,159 --> 01:09:28,159
that will follow.

1498
01:09:23,100 --> 01:09:31,181
Daniel: Wow.

1499
01:09:30,177 --> 01:09:32,194
Great comments.

1500
01:09:31,182 --> 01:09:52,392
Two things that reflects to me the

1501
01:09:52,392 --> 01:09:52,392
constraints that you mentioned, which we

1502
01:09:52,392 --> 01:09:52,392
sometimes call the particular partition

1503
01:09:52,392 --> 01:09:52,392
essentially cleaving the particle, which

1504
01:09:52,392 --> 01:09:52,392
you show in figure two, cleaving the

1505
01:09:52,392 --> 01:09:52,392
particle off from the environment.

1506
01:09:32,195 --> 01:09:56,437
This is something that's widely applied

1507
01:09:56,437 --> 01:09:56,437
in agent based modeling.

1508
01:09:52,396 --> 01:10:18,593
Just anytime you're talking about some

1509
01:10:18,593 --> 01:10:18,593
field of action and a player, we're

1510
01:10:18,593 --> 01:10:18,593
basically at least qualitatively within

1511
01:10:18,593 --> 01:10:18,593
the space of partitioning agents from

1512
01:10:18,593 --> 01:10:18,593
environments and then further saying,

1513
01:10:18,593 --> 01:10:18,593
well, there's no edge between the

1514
01:10:18,593 --> 01:10:18,593
internal and the external states, so

1515
01:10:18,593 --> 01:10:18,593
there's no telepathy and there's no

1516
01:10:18,593 --> 01:10:18,593
telekinesis and incoming information.

1517
01:09:56,438 --> 01:10:20,612
We're going to call sense outgoing.

1518
01:10:18,594 --> 01:10:30,715
We're going to call action that

1519
01:10:30,715 --> 01:10:30,715
qualitatively and formally is basically

1520
01:10:30,715 --> 01:10:30,715
consistent with almost any cybernetics

1521
01:10:30,715 --> 01:10:30,715
formulation of adaptive action.

1522
01:10:20,613 --> 01:10:40,815
So Axel constant are really quite minimal

1523
01:10:40,815 --> 01:10:40,815
and seemingly being generalized year

1524
01:10:40,815 --> 01:10:40,815
after year with the work so many

1525
01:10:40,815 --> 01:10:40,815
colleagues are involved in.

1526
01:10:30,716 --> 01:10:45,861
So Axel Costa are not onerous.

1527
01:10:40,817 --> 01:10:51,926
And I think it's a really interesting

1528
01:10:51,926 --> 01:10:51,926
question which reinforcement learnings

1529
01:10:51,926 --> 01:10:51,926
are compatible?

1530
01:10:45,866 --> 01:11:02,978
And then coming from the other side, in a

1531
01:11:02,978 --> 01:11:02,978
lot of active modeling contexts, we find

1532
01:11:02,978 --> 01:11:02,978
ourselves sometimes proposing like

1533
01:11:02,978 --> 01:11:02,978
auxiliary variables.

1534
01:10:51,927 --> 01:11:05,007
Like, let's just do a parameter sweep

1535
01:11:05,007 --> 01:11:05,007
over this.

1536
01:11:03,979 --> 01:11:09,040
And then we'll look back to the textbook

1537
01:11:09,040 --> 01:11:09,040
or to the paper.

1538
01:11:05,009 --> 01:11:11,065
We think, well, where was that in

1539
01:11:11,065 --> 01:11:11,065
expected free energy?

1540
01:11:09,040 --> 01:11:14,092
We just proposed this random thing.

1541
01:11:11,066 --> 01:11:15,109
Where was that in the equation?

1542
01:11:14,094 --> 01:11:21,166
Or we'll look at step by step guide to

1543
01:11:21,166 --> 01:11:21,166
active inference where it's all written

1544
01:11:21,166 --> 01:11:21,166
in terms of matrices.

1545
01:11:16,110 --> 01:11:23,188
It's all very read.

1546
01:11:21,166 --> 01:11:25,200
It like a sentence.

1547
01:11:23,188 --> 01:11:29,243
And all of a sudden it's like, wait a

1548
01:11:29,243 --> 01:11:29,243
could be a neural network.

1549
01:11:25,202 --> 01:11:31,260
It doesn't just have to be a matrix.

1550
01:11:29,244 --> 01:11:40,352
So it's kind of like we bring in these

1551
01:11:40,352 --> 01:11:40,352
methods and ingredients that are being

1552
01:11:40,352 --> 01:11:40,352
used widely, empirically.

1553
01:11:31,261 --> 01:11:43,385
And these are the two approaches.

1554
01:11:41,359 --> 01:11:50,449
Do we build the bottom up mosaic of

1555
01:11:50,449 --> 01:11:50,449
approaches stopping when it works?

1556
01:11:43,386 --> 01:12:06,555
And or do we start with this most general

1557
01:12:06,555 --> 01:12:06,555
agent based cybernetic formulation and

1558
01:12:06,555 --> 01:12:06,555
then kind of build the castle in the sky

1559
01:12:06,555 --> 01:12:06,555
and meet in the middle again with

1560
01:12:06,555 --> 01:12:06,555
something that works?

1561
01:11:51,459 --> 01:12:10,592
It's just incredibly laid out.

1562
01:12:06,556 --> 01:12:27,767
And this paper is at that saddle point

1563
01:12:27,767 --> 01:12:27,767
because it has one hand or antenna or

1564
01:12:27,767 --> 01:12:27,767
whatever in this smooth information

1565
01:12:27,767 --> 01:12:27,767
geometry conceptual area.

1566
01:12:10,594 --> 01:12:36,857
But the motivator of all of the

1567
01:12:36,857 --> 01:12:36,857
conceptual moves that are made, which

1568
01:12:36,857 --> 01:12:36,857
honestly are extensive, like page after

1569
01:12:36,857 --> 01:12:36,857
page, it was just like, where's it

1570
01:12:36,857 --> 01:12:36,857
going?

1571
01:12:28,771 --> 01:12:42,918
It's going somewhere that can be

1572
01:12:42,918 --> 01:12:42,918
simulated on everyday hardware.

1573
01:12:37,866 --> 01:12:53,023
So many of the moves were about reshaping

1574
01:12:53,023 --> 01:12:53,023
or reframing what was to be done in a way

1575
01:12:53,023 --> 01:12:53,023
that could be simulated.

1576
01:12:43,922 --> 01:13:16,191
And so those two paths are connecting and

1577
01:13:16,191 --> 01:13:16,191
like you said, there's not necessarily

1578
01:13:16,191 --> 01:13:16,191
attention, but it'll be quite interesting

1579
01:13:16,191 --> 01:13:16,191
to see how this develops on the theory,

1580
01:13:16,191 --> 01:13:16,191
practice and social frontiers as more and

1581
01:13:16,191 --> 01:13:16,191
more of these threads start to combine.

1582
01:12:53,027 --> 01:13:18,215
Lance: Yeah, I agree.

1583
01:13:17,204 --> 01:13:24,274
I think it's particularly beautiful when

1584
01:13:24,274 --> 01:13:24,274
theory meets practice.

1585
01:13:18,219 --> 01:13:35,389
You oftentimes have practice that works,

1586
01:13:35,389 --> 01:13:35,389
but you have no theory or you have a

1587
01:13:35,389 --> 01:13:35,389
theory that's beautiful but that doesn't

1588
01:13:35,389 --> 01:13:35,389
work in practice.

1589
01:13:25,284 --> 01:13:39,426
And this just happens all the time.

1590
01:13:36,390 --> 01:13:53,564
Typically you would have active that

1591
01:13:53,564 --> 01:13:53,564
works and then you would try to build a

1592
01:13:53,564 --> 01:13:53,564
theory out of it, but then often the

1593
01:13:53,564 --> 01:13:53,564
theory turns out to be too hard, so you

1594
01:13:53,564 --> 01:13:53,564
make some extra assumptions and so on.

1595
01:13:41,442 --> 01:13:57,603
You end up with a theory, but the theory

1596
01:13:57,603 --> 01:13:57,603
turns out to be quite removed from the

1597
01:13:57,603 --> 01:13:57,603
practice.

1598
01:13:53,565 --> 01:13:59,620
So you kind of get that gap.

1599
01:13:57,604 --> 01:14:06,634
It's very beautiful and quite unique and

1600
01:14:06,634 --> 01:14:06,634
also quite rare when the theory meets the

1601
01:14:06,634 --> 01:14:06,634
practice.

1602
01:14:00,570 --> 01:14:14,716
And I would say when the theory meets the

1603
01:14:14,716 --> 01:14:14,716
practice and in particular meets the

1604
01:14:14,716 --> 01:14:14,716
state of the art, then you kind of have a

1605
01:14:14,716 --> 01:14:14,716
complete theory.

1606
01:14:07,645 --> 01:14:34,915
So what we wanted to do in this paper is

1607
01:14:34,915 --> 01:14:34,915
review these different Fields in a way

1608
01:14:34,915 --> 01:14:34,915
that we could show how far the community

1609
01:14:34,915 --> 01:14:34,915
has gone between making a theory that

1610
01:14:34,915 --> 01:14:34,915
meets the state of the art.

1611
01:14:16,736 --> 01:14:51,088
And every section was started with

1612
01:14:51,088 --> 01:14:51,088
theoretical considerations about what

1613
01:14:51,088 --> 01:14:51,088
should be when you need to solve a

1614
01:14:51,088 --> 01:14:51,088
particular problem, let's say adaptive

1615
01:14:51,088 --> 01:14:51,088
agents or sampling or optimization.

1616
01:14:35,923 --> 01:15:06,172
And then from there, and from logical

1617
01:15:06,172 --> 01:15:06,172
steps about, okay, well, it should be

1618
01:15:06,172 --> 01:15:06,172
like this and not like that, because

1619
01:15:06,172 --> 01:15:06,172
there is whatever kind of geometric

1620
01:15:06,172 --> 01:15:06,172
argument or other arguments.

1621
01:14:52,089 --> 01:15:14,253
And so from there, logically arriving at

1622
01:15:14,253 --> 01:15:14,253
state of the art methods that are used in

1623
01:15:14,253 --> 01:15:14,253
practice.

1624
01:15:06,177 --> 01:15:25,369
The other kind of like sequence of

1625
01:15:25,369 --> 01:15:25,369
logical steps was, okay, well, we're

1626
01:15:25,369 --> 01:15:25,369
going to start with optimization which is

1627
01:15:25,369 --> 01:15:25,369
in my view, at the root of everything.

1628
01:15:16,273 --> 01:15:36,476
So sampling could be about optimizing

1629
01:15:36,476 --> 01:15:36,476
samples to obtain the best approximation

1630
01:15:36,476 --> 01:15:36,476
to your integral inferences about

1631
01:15:36,476 --> 01:15:36,476
optimizing beliefs and decision making.

1632
01:15:26,379 --> 01:15:40,517
It's about optimizing decisions based on

1633
01:15:40,517 --> 01:15:40,517
their counterfactuals consequences.

1634
01:15:36,477 --> 01:15:51,620
So we started up with optimization

1635
01:15:51,620 --> 01:15:51,620
because it's the simplest thing both

1636
01:15:51,620 --> 01:15:51,620
conceptually and also in terms of use

1637
01:15:51,620 --> 01:15:51,620
case you need optimization to do

1638
01:15:51,620 --> 01:15:51,620
everything else.

1639
01:15:40,518 --> 01:16:00,659
We then went to sampling and to inference

1640
01:16:00,659 --> 01:16:00,659
and finally to decision making because it

1641
01:16:00,659 --> 01:16:00,659
just brings all these three ingredients

1642
01:16:00,659 --> 01:16:00,659
together.

1643
01:15:52,632 --> 01:16:13,788
We didn't go as far as showing, okay,

1644
01:16:13,788 --> 01:16:13,788
well, this is how you should scale active

1645
01:16:13,788 --> 01:16:13,788
inference in order to solve all the

1646
01:16:13,788 --> 01:16:13,788
problems in the world because this just

1647
01:16:13,788 --> 01:16:13,788
hasn't been done right.

1648
01:16:01,665 --> 01:16:28,930
But we listed a few ingredients that have

1649
01:16:28,930 --> 01:16:28,930
gone into the literature and also a few

1650
01:16:28,930 --> 01:16:28,930
ingredients that this perspective offers

1651
01:16:28,930 --> 01:16:28,930
to how to scale active inference and make

1652
01:16:28,930 --> 01:16:28,930
it more effective.

1653
01:16:14,794 --> 01:16:44,091
So it's actually future work and open

1654
01:16:44,091 --> 01:16:44,091
problem to use the techniques that have

1655
01:16:44,091 --> 01:16:44,091
been developed in the sampling section

1656
01:16:44,091 --> 01:16:44,091
and the sampling literature to make

1657
01:16:44,091 --> 01:16:44,091
active inference even more scalable and

1658
01:16:44,091 --> 01:16:44,091
same with optimization and same with

1659
01:16:44,091 --> 01:16:44,091
coherence.

1660
01:16:28,931 --> 01:16:55,204
So there's many things that have been put

1661
01:16:55,204 --> 01:16:55,204
forward in this article and also

1662
01:16:55,204 --> 01:16:55,204
elsewhere that can be used to scale

1663
01:16:55,204 --> 01:16:55,204
active imprints but ant least.

1664
01:16:44,091 --> 01:17:10,298
Yeah, the goal was to be as comprehensive

1665
01:17:10,298 --> 01:17:10,298
as possible without sacrificing too much

1666
01:17:10,298 --> 01:17:10,298
of actually understanding what's really

1667
01:17:10,298 --> 01:17:10,298
going on and show how the theory means to

1668
01:17:10,298 --> 01:17:10,298
practice throughout and really where the

1669
01:17:10,298 --> 01:17:10,298
field stands.

1670
01:16:55,205 --> 01:17:22,414
Daniel: So one kind of reflection on

1671
01:17:22,414 --> 01:17:22,414
this, again, is if we start with reward

1672
01:17:22,414 --> 01:17:22,414
as our basal imperative pragmatism.

1673
01:17:12,313 --> 01:17:28,476
I mean, after all, don't we want to get

1674
01:17:28,476 --> 01:17:28,476
things done, achieve results in the

1675
01:17:28,476 --> 01:17:28,476
world, realize our preferences?

1676
01:17:22,416 --> 01:17:41,602
We start with pragmatism and then it is

1677
01:17:41,602 --> 01:17:41,602
empirically ad hoc how people introduce

1678
01:17:41,602 --> 01:17:41,602
these novelty bonus or intrinsic

1679
01:17:41,602 --> 01:17:41,602
motivations.

1680
01:17:28,477 --> 01:17:58,778
In contrast, we can start with this

1681
01:17:58,778 --> 01:17:58,778
information gain approach and then the

1682
01:17:58,778 --> 01:17:58,778
thumb is put on the scale to bring more

1683
01:17:58,778 --> 01:17:58,778
and more emphasis onto the alignment with

1684
01:17:58,778 --> 01:17:58,778
preference.

1685
01:17:42,615 --> 01:18:05,786
So it's like two roads, two paths.

1686
01:17:59,782 --> 01:18:37,010
And maybe this is our bias or corner of

1687
01:18:37,010 --> 01:18:37,010
the information space that starting with

1688
01:18:37,010 --> 01:18:37,010
a broader epistemic imperative allows the

1689
01:18:37,010 --> 01:18:37,010
careful introduction of pragmatic value

1690
01:18:37,010 --> 01:18:37,010
whereas a pragmatic foundation that it's

1691
01:18:37,010 --> 01:18:37,010
hard to then recast epistemic value in

1692
01:18:37,010 --> 01:18:37,010
terms of pragmatic value.

1693
01:18:06,791 --> 01:18:40,013
That's kind of like the question of

1694
01:18:40,013 --> 01:18:40,013
valuing basic research.

1695
01:18:37,010 --> 01:18:51,024
And the approach taken here is develop an

1696
01:18:51,024 --> 01:18:51,024
imperative that can look entirely like

1697
01:18:51,024 --> 01:18:51,024
one or the other or mixtures.

1698
01:18:40,013 --> 01:19:08,035
But what's always so perplexing is that

1699
01:19:08,035 --> 01:19:08,035
it has this extrinsic and intrinsic value

1700
01:19:08,035 --> 01:19:08,035
phrasing but there are other ways to

1701
01:19:08,035 --> 01:19:08,035
decompose the function.

1702
01:18:52,025 --> 01:19:18,045
So even intrinsic and extrinsic value are

1703
01:19:18,045 --> 01:19:18,045
not necessarily the ingredients that were

1704
01:19:18,045 --> 01:19:18,045
put in.

1705
01:19:09,036 --> 01:19:28,055
It's more like they were two ingredients

1706
01:19:28,055 --> 01:19:28,055
that were split out of something else

1707
01:19:28,055 --> 01:19:28,055
that is much more integrated.

1708
01:19:18,045 --> 01:19:43,070
It wasn't like the free energy was

1709
01:19:43,070 --> 01:19:43,070
constructed by composition of any given

1710
01:19:43,070 --> 01:19:43,070
decomposition of which there are multiple

1711
01:19:43,070 --> 01:19:43,070
for variational free energy and expected

1712
01:19:43,070 --> 01:19:43,070
free energy.

1713
01:19:28,055 --> 01:20:00,081
So then a question that I've often

1714
01:20:00,081 --> 01:20:00,081
wondered is there might be two policies

1715
01:20:00,081 --> 01:20:00,081
that are very close or have essentially

1716
01:20:00,081 --> 01:20:00,081
identical expected free energy but they

1717
01:20:00,081 --> 01:20:00,081
could be radically different.

1718
01:19:44,071 --> 01:20:08,089
For example, one could be having a good

1719
01:20:08,089 --> 01:20:08,089
expected free energy because it realizes

1720
01:20:08,089 --> 01:20:08,089
a lot of preferences.

1721
01:20:00,081 --> 01:20:13,094
Another might because it provides a lot

1722
01:20:13,094 --> 01:20:13,094
of information gain.

1723
01:20:09,090 --> 01:20:46,127
So is it really as simple asterisk

1724
01:20:46,127 --> 01:20:46,127
asterisk as a unified imperative or how

1725
01:20:46,127 --> 01:20:46,127
do we make sense of the fact that one

1726
01:20:46,127 --> 01:20:46,127
value could rank policies that might

1727
01:20:46,127 --> 01:20:46,127
have, for example, extremely different

1728
01:20:46,127 --> 01:20:46,127
danger profiles or envelopes of

1729
01:20:46,127 --> 01:20:46,127
outcomes?

1730
01:20:14,095 --> 01:20:57,138
How can that seemingly multidimensional

1731
01:20:57,138 --> 01:20:57,138
space be projected into essentially a

1732
01:20:57,138 --> 01:20:57,138
ranking?

1733
01:20:46,127 --> 01:21:02,137
Lance: Yeah, it's a complicated

1734
01:21:02,137 --> 01:21:02,137
question.

1735
01:20:59,139 --> 01:21:08,143
As we can see, the expected free energy

1736
01:21:08,143 --> 01:21:08,143
does this in some way.

1737
01:21:04,139 --> 01:21:17,152
It provides an answer to this question

1738
01:21:17,152 --> 01:21:17,152
based on your preferences and how much

1739
01:21:17,152 --> 01:21:17,152
you would gain by observing this new

1740
01:21:17,152 --> 01:21:17,152
data, how much information you would

1741
01:21:17,152 --> 01:21:17,152
gain.

1742
01:21:08,143 --> 01:21:21,156
You can put these two things on the

1743
01:21:21,156 --> 01:21:21,156
same.

1744
01:21:18,153 --> 01:21:21,156
Footing.

1745
01:21:21,156 --> 01:21:25,160
This is what expected PNG does, and it

1746
01:21:25,160 --> 01:21:25,160
gives you a ranking.

1747
01:21:21,156 --> 01:21:34,169
You're right to say that two very

1748
01:21:34,169 --> 01:21:34,169
different courses of action could have

1749
01:21:34,169 --> 01:21:34,169
the same expected free energy.

1750
01:21:29,164 --> 01:21:37,172
And so how do you choose between them?

1751
01:21:35,170 --> 01:21:49,184
Well, the standard formulation that you

1752
01:21:49,184 --> 01:21:49,184
would see in textbooks or papers has,

1753
01:21:49,184 --> 01:21:49,184
okay, well, G of Action Sequence equals

1754
01:21:49,184 --> 01:21:49,184
this and G of Sequence equals that.

1755
01:21:38,173 --> 01:21:53,188
So these two Action sequences have the

1756
01:21:53,188 --> 01:21:53,188
same G and you don't know what to do.

1757
01:21:49,184 --> 01:22:03,192
But here, this theoretical development in

1758
01:22:03,192 --> 01:22:03,192
this paper makes it very clear that the

1759
01:22:03,192 --> 01:22:03,192
expected PNG is a minus lock

1760
01:22:03,192 --> 01:22:03,192
probability.

1761
01:21:53,188 --> 01:22:04,193
And this is why.

1762
01:22:03,192 --> 01:22:14,203
So to make it more transparent, instead

1763
01:22:14,203 --> 01:22:14,203
of using the letter G that's commonly

1764
01:22:14,203 --> 01:22:14,203
used in the literature, we kept the minus

1765
01:22:14,203 --> 01:22:14,203
log P throughout.

1766
01:22:05,194 --> 01:22:16,205
So we never used the letter G.

1767
01:22:14,203 --> 01:22:21,210
And so the expected free energy is this

1768
01:22:21,210 --> 01:22:21,210
minus log P of Action Sequence.

1769
01:22:16,205 --> 01:22:34,223
And so it says, okay, well, if two Action

1770
01:22:34,223 --> 01:22:34,223
Sequences have the same expected free

1771
01:22:34,223 --> 01:22:34,223
energy, well, then you have, let's say

1772
01:22:34,223 --> 01:22:34,223
you just have two of them with the same

1773
01:22:34,223 --> 01:22:34,223
expected force energy, the lowest one,

1774
01:22:34,223 --> 01:22:34,223
well, then you choose probabilistically.

1775
01:22:21,210 --> 01:22:39,228
Like half of the time you choose one, and

1776
01:22:39,228 --> 01:22:39,228
half of the time you use the other.

1777
01:22:34,223 --> 01:22:53,242
Actually, it's even a bit more

1778
01:22:53,242 --> 01:22:53,242
complicated because since it's a minus

1779
01:22:53,242 --> 01:22:53,242
lot P, you could have an Action Sequence

1780
01:22:53,242 --> 01:22:53,242
with a very high expected free energy.

1781
01:22:40,229 --> 01:22:56,245
And so this means that you can still take

1782
01:22:56,245 --> 01:22:56,245
it.

1783
01:22:53,242 --> 01:22:59,248
But if you would take it, like, not very

1784
01:22:59,248 --> 01:22:59,248
often.

1785
01:22:56,245 --> 01:23:05,248
So you have an exponentially low chance

1786
01:23:05,248 --> 01:23:05,248
of taking that Action Sequence.

1787
01:22:59,248 --> 01:23:08,251
So it's a probabilistic description.

1788
01:23:05,248 --> 01:23:17,260
It says that the most likely Action

1789
01:23:17,260 --> 01:23:17,260
Sequence would be the argument, the

1790
01:23:17,260 --> 01:23:17,260
minimum of the expected free energy.

1791
01:23:10,253 --> 01:23:19,262
So this is like the top line in the

1792
01:23:19,262 --> 01:23:19,262
figure.

1793
01:23:17,260 --> 01:23:28,271
And so if you have two most likely Action

1794
01:23:28,271 --> 01:23:28,271
Sequences, well, then you choose like

1795
01:23:28,271 --> 01:23:28,271
half of the time you choose one, half of

1796
01:23:28,271 --> 01:23:28,271
the time you choose the other.

1797
01:23:20,262 --> 01:23:37,280
But then in general, if you didn't want

1798
01:23:37,280 --> 01:23:37,280
to simulate the most likely Action

1799
01:23:37,280 --> 01:23:37,280
Sequence, then you choose

1800
01:23:37,280 --> 01:23:37,280
probabilistically between all of them.

1801
01:23:28,271 --> 01:23:50,293
And the Action Sequences that have the

1802
01:23:50,293 --> 01:23:50,293
lowest expected reality has an

1803
01:23:50,293 --> 01:23:50,293
exponentially higher chance of being

1804
01:23:50,293 --> 01:23:50,293
selected and the others don't.

1805
01:23:38,281 --> 01:23:55,298
One last thing.

1806
01:23:54,297 --> 01:24:13,310
Another very nice perspective is that the

1807
01:24:13,310 --> 01:24:13,310
probability over Action sequences, so

1808
01:24:13,310 --> 01:24:13,310
these P of a greater than equal to T is

1809
01:24:13,310 --> 01:24:13,310
then the exponential of minus the

1810
01:24:13,310 --> 01:24:13,310
expected free energy.

1811
01:23:55,298 --> 01:24:24,321
Because if you take exponential minus of

1812
01:24:24,321 --> 01:24:24,321
what you get in the equality on the left,

1813
01:24:24,321 --> 01:24:24,321
then you recover this probability

1814
01:24:24,321 --> 01:24:24,321
distribution of our Action Sequences.

1815
01:24:13,310 --> 01:24:33,330
So this distribution of our Action

1816
01:24:33,330 --> 01:24:33,330
Sequences is exponential minus expected

1817
01:24:33,330 --> 01:24:33,330
free energy, exponential minus what's in

1818
01:24:33,330 --> 01:24:33,330
there.

1819
01:24:24,321 --> 01:24:39,336
And we saw before, that gives measures,

1820
01:24:39,336 --> 01:24:39,336
they arise everywhere.

1821
01:24:33,330 --> 01:24:41,338
And so this is an example of a gives

1822
01:24:41,338 --> 01:24:41,338
measure.

1823
01:24:39,336 --> 01:24:55,352
You have exponential minus something

1824
01:24:55,352 --> 01:24:55,352
basically, based on the formalism of the

1825
01:24:55,352 --> 01:24:55,352
free free energy principle comes up that

1826
01:24:55,352 --> 01:24:55,352
the probability distribution over Actions

1827
01:24:55,352 --> 01:24:55,352
is a gives measure.

1828
01:24:41,338 --> 01:25:02,353
It is the gives measure where what's

1829
01:25:02,353 --> 01:25:02,353
inside is the expected free energy.

1830
01:24:56,353 --> 01:25:13,364
So, yeah, it's kind of like a full circle

1831
01:25:13,364 --> 01:25:13,364
thing and this is basically this sort of

1832
01:25:13,364 --> 01:25:13,364
like connectivity.

1833
01:25:03,354 --> 01:25:25,376
They just happen all the time when we

1834
01:25:25,376 --> 01:25:25,376
were writing this paper and discussing

1835
01:25:25,376 --> 01:25:25,376
because there's so many things that just

1836
01:25:25,376 --> 01:25:25,376
there's so many crossovers at so many

1837
01:25:25,376 --> 01:25:25,376
different levels.

1838
01:25:13,364 --> 01:25:39,389
Like on the sort of object level that

1839
01:25:39,389 --> 01:25:39,389
you're studying, but also on the

1840
01:25:39,389 --> 01:25:39,389
ecological level, like methodologies that

1841
01:25:39,389 --> 01:25:39,389
are used in some field, they're used in a

1842
01:25:39,389 --> 01:25:39,389
different field to do something else.

1843
01:25:25,376 --> 01:25:41,392
So there's so many crossovers.

1844
01:25:39,390 --> 01:25:51,402
And so this is, I would say, an

1845
01:25:51,402 --> 01:25:51,402
interesting example of why gives

1846
01:25:51,402 --> 01:25:51,402
measures, gives distinctions, they just

1847
01:25:51,402 --> 01:25:51,402
arise everywhere.

1848
01:25:41,392 --> 01:25:57,408
They arise active inference Lab and as we

1849
01:25:57,408 --> 01:25:57,408
saw before, they're hard to sample from.

1850
01:25:51,402 --> 01:26:08,413
So if you wanted to so let's say you have

1851
01:26:08,413 --> 01:26:08,413
your gives distribution that says, okay,

1852
01:26:08,413 --> 01:26:08,413
well, this is my distribution of our

1853
01:26:08,413 --> 01:26:08,413
action sequences that I get from the

1854
01:26:08,413 --> 01:26:08,413
expected free energy.

1855
01:25:57,408 --> 01:26:10,415
Then you have two choices.

1856
01:26:09,414 --> 01:26:29,434
Either you sample from it to sample like

1857
01:26:29,434 --> 01:26:29,434
an average, I would say not a typical

1858
01:26:29,434 --> 01:26:29,434
action sequence, or you could optimize

1859
01:26:29,434 --> 01:26:29,434
the distribution or optimize the expected

1860
01:26:29,434 --> 01:26:29,434
free energy to sample the most likely

1861
01:26:29,434 --> 01:26:29,434
action sequence.

1862
01:26:10,415 --> 01:26:37,442
In the two cases after you've done your

1863
01:26:37,442 --> 01:26:37,442
planning with the expected free energy,

1864
01:26:37,442 --> 01:26:37,442
you have a choice between sampling and

1865
01:26:37,442 --> 01:26:37,442
optimization.

1866
01:26:30,435 --> 01:27:00,459
So you kind of go back full circle of

1867
01:27:00,459 --> 01:27:00,459
like if I want to select my action gain,

1868
01:27:00,459 --> 01:27:00,459
I either select the most likely action by

1869
01:27:00,459 --> 01:27:00,459
optimizing the expected free energy or

1870
01:27:00,459 --> 01:27:00,459
the gives measure by optimizing this

1871
01:27:00,459 --> 01:27:00,459
minus lot P by taking the action sequence

1872
01:27:00,459 --> 01:27:00,459
with the minimal expected free energy.

1873
01:26:38,443 --> 01:27:07,466
Or I have my gives measure and it will

1874
01:27:07,466 --> 01:27:07,466
sample from it to like get a typical

1875
01:27:07,466 --> 01:27:07,466
action sequence.

1876
01:27:00,459 --> 01:27:09,468
So it's all like super interrelated.

1877
01:27:07,466 --> 01:27:20,479
Daniel: Very interesting in the Par et

1878
01:27:20,479 --> 01:27:20,479
al.

1879
01:27:13,472 --> 01:27:45,504
Textbook from 2022, that dialectic is

1880
01:27:45,504 --> 01:27:45,504
mapped onto the mammalian nervous system

1881
01:27:45,504 --> 01:27:45,504
where policies can be selected by

1882
01:27:45,504 --> 01:27:45,504
essentially passing through habit

1883
01:27:45,504 --> 01:27:45,504
proportionally or expected free energy

1884
01:27:45,504 --> 01:27:45,504
can be applied to sharpen or optimize the

1885
01:27:45,504 --> 01:27:45,504
posterior on action.

1886
01:27:20,479 --> 01:27:54,513
Does this influence how you select micro

1887
01:27:54,513 --> 01:27:54,513
meso or macro actions?

1888
01:27:49,508 --> 01:28:06,519
Lance: Do you mean for human being

1889
01:28:06,519 --> 01:28:06,519
like actions at the cellular level,

1890
01:28:06,519 --> 01:28:06,519
actions at the Global level?

1891
01:27:59,518 --> 01:28:08,521
Or is it something different like at.

1892
01:28:06,519 --> 01:28:21,534
Daniel: The personal, grasping a coffee

1893
01:28:21,534 --> 01:28:21,534
cup at the micro, larger scale decisions,

1894
01:28:21,534 --> 01:28:21,534
attention allocation, communication

1895
01:28:21,534 --> 01:28:21,534
emissions.

1896
01:28:08,521 --> 01:28:31,544
Lance: Yeah, I think all of these

1897
01:28:31,544 --> 01:28:31,544
things can be formulated in this

1898
01:28:31,544 --> 01:28:31,544
treatment.

1899
01:28:23,536 --> 01:28:39,552
So, for example, attention would be where

1900
01:28:39,552 --> 01:28:39,552
you choose to place your focus or your

1901
01:28:39,552 --> 01:28:39,552
mental eye, so to speak.

1902
01:28:31,544 --> 01:28:46,559
So that's and internal action, it could

1903
01:28:46,559 --> 01:28:46,559
be unconscious, it could be undirected,

1904
01:28:46,559 --> 01:28:46,559
but still happening.

1905
01:28:40,553 --> 01:28:56,569
I'm not an expert, but there's a lot of

1906
01:28:56,569 --> 01:28:56,569
talking consciousness research of like,

1907
01:28:56,569 --> 01:28:56,569
you being conscious.

1908
01:28:48,561 --> 01:29:09,576
There's a very low amount of processes

1909
01:29:09,576 --> 01:29:09,576
that are conscious and these change

1910
01:29:09,576 --> 01:29:09,576
according to where you're inner eye or

1911
01:29:09,576 --> 01:29:09,576
your conscious eye, whatever you want to

1912
01:29:09,576 --> 01:29:09,576
call it, like moves.

1913
01:28:57,570 --> 01:29:20,587
This could be thought of a mental action

1914
01:29:20,587 --> 01:29:20,587
or an inner action that you may or may

1915
01:29:20,587 --> 01:29:20,587
not control, but still and action.

1916
01:29:11,578 --> 01:29:41,608
So all these, all other action, whether

1917
01:29:41,608 --> 01:29:41,608
it is planning at the short time scale,

1918
01:29:41,608 --> 01:29:41,608
taking a coffee cup standing, or planning

1919
01:29:41,608 --> 01:29:41,608
at the longer time scale, like what am I

1920
01:29:41,608 --> 01:29:41,608
going to do after my PhD and so on, all

1921
01:29:41,608 --> 01:29:41,608
of these things are action.

1922
01:29:21,588 --> 01:29:54,621
So typically, as you know, of course, we

1923
01:29:54,621 --> 01:29:54,621
we model that by using hierarchical

1924
01:29:54,621 --> 01:29:54,621
models where you have different levels in

1925
01:29:54,621 --> 01:29:54,621
your giant model.

1926
01:29:42,609 --> 01:30:06,627
So in your model of the world and the

1927
01:30:06,627 --> 01:30:06,627
higher levels are represent more abstract

1928
01:30:06,627 --> 01:30:06,627
representations and also longer time

1929
01:30:06,627 --> 01:30:06,627
scales.

1930
01:29:55,621 --> 01:30:21,642
So it could be, let's say at some higher

1931
01:30:21,642 --> 01:30:21,642
level I'm going to take the plane to go

1932
01:30:21,642 --> 01:30:21,642
to Amsterdam, for example, and at the

1933
01:30:21,642 --> 01:30:21,642
lower level, okay, well, once in

1934
01:30:21,642 --> 01:30:21,642
Amsterdam, I'm going to do this, this and

1935
01:30:21,642 --> 01:30:21,642
this.

1936
01:30:07,628 --> 01:30:29,650
It's like this action at the higher level

1937
01:30:29,650 --> 01:30:29,650
of taking the plane predates everything

1938
01:30:29,650 --> 01:30:29,650
that you're going to do at the lower

1939
01:30:29,650 --> 01:30:29,650
level.

1940
01:30:22,642 --> 01:30:46,667
And so factorizing these different

1941
01:30:46,667 --> 01:30:46,667
decisions into different levels of a

1942
01:30:46,667 --> 01:30:46,667
model allow you to be completionally,

1943
01:30:46,667 --> 01:30:46,667
practical, practically implementable when

1944
01:30:46,667 --> 01:30:46,667
you make those decisions.

1945
01:30:30,651 --> 01:30:57,678
And presumably this is why we do in our

1946
01:30:57,678 --> 01:30:57,678
everyday life factorize decisions and

1947
01:30:57,678 --> 01:30:57,678
representations into low level and high

1948
01:30:57,678 --> 01:30:57,678
level things.

1949
01:30:46,667 --> 01:31:04,679
The beauty of the free energy principle

1950
01:31:04,679 --> 01:31:04,679
and of the treatment here.

1951
01:30:59,680 --> 01:31:20,695
But the treatment here is again, just the

1952
01:31:20,695 --> 01:31:20,695
free energy principle in its most bare

1953
01:31:20,695 --> 01:31:20,695
bones and general form is that the

1954
01:31:20,695 --> 01:31:20,695
expected free energy is formulated for

1955
01:31:20,695 --> 01:31:20,695
any kind of gentle model.

1956
01:31:06,680 --> 01:31:28,703
The gentle models that you have in the

1957
01:31:28,703 --> 01:31:28,703
figure on the bottom right there, they

1958
01:31:28,703 --> 01:31:28,703
could be arbitrary.

1959
01:31:21,696 --> 01:31:43,718
So you could use this form of expected

1960
01:31:43,718 --> 01:31:43,718
Lagrange for hierarchical generative

1961
01:31:43,718 --> 01:31:43,718
models that have all these like high

1962
01:31:43,718 --> 01:31:43,718
level, low level decisions and

1963
01:31:43,718 --> 01:31:43,718
representations, but you could also use

1964
01:31:43,718 --> 01:31:43,718
it for any other kind of generative

1965
01:31:43,718 --> 01:31:43,718
model.

1966
01:31:28,703 --> 01:32:03,732
The only difference is that with some

1967
01:32:03,732 --> 01:32:03,732
world models, it would be very hard to

1968
01:32:03,732 --> 01:32:03,732
implement this in practice and with other

1969
01:32:03,732 --> 01:32:03,732
world models, and in particular those

1970
01:32:03,732 --> 01:32:03,732
that are highly factorised and

1971
01:32:03,732 --> 01:32:03,732
distributed like hierarchical models,

1972
01:32:03,732 --> 01:32:03,732
like the wounds we just talked about.

1973
01:31:44,719 --> 01:32:25,754
With these it would typically Dean much

1974
01:32:25,754 --> 01:32:25,754
simpler to take decisions that minimize

1975
01:32:25,754 --> 01:32:25,754
expected frequency when it comes to

1976
01:32:25,754 --> 01:32:25,754
practical computation, just because when

1977
01:32:25,754 --> 01:32:25,754
you action oriented representation

1978
01:32:25,754 --> 01:32:25,754
things, just computations just factor out

1979
01:32:25,754 --> 01:32:25,754
a lot and it's just like way simpler to

1980
01:32:25,754 --> 01:32:25,754
do.

1981
01:32:03,732 --> 01:32:34,763
But the formulation here is like entirely

1982
01:32:34,763 --> 01:32:34,763
generic and it could apply to all kinds

1983
01:32:34,763 --> 01:32:34,763
of models and all kinds of situations.

1984
01:32:25,754 --> 01:32:40,769
Daniel: Very interesting.

1985
01:32:39,768 --> 01:32:54,783
Well, in our last little segment on the

1986
01:32:54,783 --> 01:32:54,783
dot one, let's hear your perspective or

1987
01:32:54,783 --> 01:32:54,783
overview on the roadmap.

1988
01:32:40,769 --> 01:33:04,787
Just walk through what the sections are

1989
01:33:04,787 --> 01:33:04,787
and you mentioned some related topics,

1990
01:33:04,787 --> 01:33:04,787
but what do the subjects broadly cover?

1991
01:32:54,783 --> 01:33:06,789
Why are they structured in that order?

1992
01:33:04,787 --> 01:33:26,809
Lance: Right, well, first of all, the

1993
01:33:26,809 --> 01:33:26,809
introduction just puts like everything in

1994
01:33:26,809 --> 01:33:26,809
context, the conducting line or one of

1995
01:33:26,809 --> 01:33:26,809
the common points between all of these

1996
01:33:26,809 --> 01:33:26,809
sections is that there's a lot of

1997
01:33:26,809 --> 01:33:26,809
geometry.

1998
01:33:08,791 --> 01:33:35,818
So this was not purely because the

1999
01:33:35,818 --> 01:33:35,818
journal is like the handbook of

2000
01:33:35,818 --> 01:33:35,818
statistics, it was called Geometry and

2001
01:33:35,818 --> 01:33:35,818
Statistics.

2002
01:33:27,810 --> 01:33:43,826
So this is not just for that, but it's

2003
01:33:43,826 --> 01:33:43,826
because geometry just comes up naturally

2004
01:33:43,826 --> 01:33:43,826
in all these places.

2005
01:33:35,818 --> 01:33:57,840
So this is what we explained in the

2006
01:33:57,840 --> 01:33:57,840
introduction, like how geometry comes up,

2007
01:33:57,840 --> 01:33:57,840
the different branches of geometry that

2008
01:33:57,840 --> 01:33:57,840
come up in this different field and how

2009
01:33:57,840 --> 01:33:57,840
they're interrelated.

2010
01:33:44,827 --> 01:34:11,848
And so just from there you kind of get a

2011
01:34:11,848 --> 01:34:11,848
picture of, okay, well, this branch,

2012
01:34:11,848 --> 01:34:11,848
let's say symplectic geometry, for

2013
01:34:11,848 --> 01:34:11,848
example, it comes up in accelerated

2014
01:34:11,848 --> 01:34:11,848
optimization and it also comes up in

2015
01:34:11,848 --> 01:34:11,848
sampling.

2016
01:33:57,840 --> 01:34:28,865
And so you can already see from there

2017
01:34:28,865 --> 01:34:28,865
what is going to be discussed, of course,

2018
01:34:28,865 --> 01:34:28,865
but also which branches of geometry occur

2019
01:34:28,865 --> 01:34:28,865
where and what kind of parallels there

2020
01:34:28,865 --> 01:34:28,865
are already.

2021
01:34:12,849 --> 01:34:35,872
So going from the introduction to

2022
01:34:35,872 --> 01:34:35,872
accelerated optimization.

2023
01:34:30,867 --> 01:34:39,876
So optimization is conceptually, it's a

2024
01:34:39,876 --> 01:34:39,876
very simple thing.

2025
01:34:35,872 --> 01:34:41,878
It's like, okay, we have a function.

2026
01:34:39,876 --> 01:34:52,889
So coming back to, let's say that my Dean

2027
01:34:52,889 --> 01:34:52,889
state space come back to where we started

2028
01:34:52,889 --> 01:34:52,889
with and you have a function and a

2029
01:34:52,889 --> 01:34:52,889
landscape over it, let's say like a

2030
01:34:52,889 --> 01:34:52,889
mountain.

2031
01:34:41,878 --> 01:34:58,895
And so the goal is to find the minimum of

2032
01:34:58,895 --> 01:34:58,895
the mountain.

2033
01:34:54,891 --> 01:35:01,892
I go from where you start to the

2034
01:35:01,892 --> 01:35:01,892
minimum.

2035
01:34:58,895 --> 01:35:08,899
There's so many different ways of solving

2036
01:35:08,899 --> 01:35:08,899
this problem, practically speaking.

2037
01:35:02,893 --> 01:35:17,908
The main challenge, of course, is that

2038
01:35:17,908 --> 01:35:17,908
you don't know, you cannot speak anywhere

2039
01:35:17,908 --> 01:35:17,908
else except where you have been.

2040
01:35:09,900 --> 01:35:23,914
So you start somewhere and you're

2041
01:35:23,914 --> 01:35:23,914
completely blind and you need to find a

2042
01:35:23,914 --> 01:35:23,914
minimum.

2043
01:35:17,908 --> 01:35:24,915
So how do you do that?

2044
01:35:23,914 --> 01:35:29,920
There's so many ways, so many approaches

2045
01:35:29,920 --> 01:35:29,920
to optimization.

2046
01:35:25,916 --> 01:35:34,925
I mean, it's a whole field and it's in my

2047
01:35:34,925 --> 01:35:34,925
opinion, a very messy one.

2048
01:35:29,920 --> 01:35:57,948
And this is understandable because

2049
01:35:57,948 --> 01:35:57,948
there's no free lunch theorems that are

2050
01:35:57,948 --> 01:35:57,948
very well known that say that under some

2051
01:35:57,948 --> 01:35:57,948
hypotheses, two ways of doing

2052
01:35:57,948 --> 01:35:57,948
optimization will behave the same on

2053
01:35:57,948 --> 01:35:57,948
average if you test them again, all

2054
01:35:57,948 --> 01:35:57,948
possible sorts of problems.

2055
01:35:34,925 --> 01:36:13,958
So this is to say that if you have a

2056
01:36:13,958 --> 01:36:13,958
given problem, then you need to give then

2057
01:36:13,958 --> 01:36:13,958
the optimization methods that will work

2058
01:36:13,958 --> 01:36:13,958
well are those that implicitly use the

2059
01:36:13,958 --> 01:36:13,958
prior information that you have about the

2060
01:36:13,958 --> 01:36:13,958
problem.

2061
01:35:59,950 --> 01:36:26,971
In other words, according to the

2062
01:36:26,971 --> 01:36:26,971
theorems, there's no optimization methods

2063
01:36:26,971 --> 01:36:26,971
that will beat everything, it just

2064
01:36:26,971 --> 01:36:26,971
doesn't exist because they're all on

2065
01:36:26,971 --> 01:36:26,971
average the same.

2066
01:36:14,959 --> 01:36:43,988
But this is not to say that you cannot

2067
01:36:43,988 --> 01:36:43,988
make any practical, meaningful steps by

2068
01:36:43,988 --> 01:36:43,988
doing optimization because not all

2069
01:36:43,988 --> 01:36:43,988
optimization problems are the

2070
01:36:43,988 --> 01:36:43,988
optimization problems that we have in

2071
01:36:43,988 --> 01:36:43,988
life.

2072
01:36:27,972 --> 01:36:50,995
They're not completely random, they're

2073
01:36:50,995 --> 01:36:50,995
not completely random landscapes that we

2074
01:36:50,995 --> 01:36:50,995
need to optimize, but they actually have

2075
01:36:50,995 --> 01:36:50,995
some structure.

2076
01:36:43,988 --> 01:37:01,000
So we can actually explore that in

2077
01:37:01,000 --> 01:37:01,000
algorithms and have things that just

2078
01:37:01,000 --> 01:37:01,000
behave, that just work a lot better for

2079
01:37:01,000 --> 01:37:01,000
the type of problems that we're

2080
01:37:01,000 --> 01:37:01,000
interested in than others.

2081
01:36:50,995 --> 01:37:08,007
So this is what kind of like the starting

2082
01:37:08,007 --> 01:37:08,007
point for all optimization.

2083
01:37:01,000 --> 01:37:16,015
The type of optimization that we

2084
01:37:16,015 --> 01:37:16,015
considered here is optimization of smooth

2085
01:37:16,015 --> 01:37:16,015
functions.

2086
01:37:10,009 --> 01:37:21,020
This is already like a big restriction

2087
01:37:21,020 --> 01:37:21,020
there's.

2088
01:37:17,016 --> 01:37:32,031
So many methods that are designed to

2089
01:37:32,031 --> 01:37:32,031
optimize functions that are rugged or non

2090
01:37:32,031 --> 01:37:32,031
smooth or have discontinuities and so

2091
01:37:32,031 --> 01:37:32,031
on.

2092
01:37:21,020 --> 01:37:39,037
When you actually get rugged or

2093
01:37:39,037 --> 01:37:39,037
discontinuous landscapes, it's a whole

2094
01:37:39,037 --> 01:37:39,037
different problem.

2095
01:37:33,032 --> 01:37:43,042
Here we chose to focus on smooth

2096
01:37:43,042 --> 01:37:43,042
functions.

2097
01:37:39,038 --> 01:37:53,052
The idea is that you have a smooth

2098
01:37:53,052 --> 01:37:53,052
landscape, you want to find the minimum.

2099
01:37:46,045 --> 01:38:04,057
And one way to do so, and to do so well,

2100
01:38:04,057 --> 01:38:04,057
is through the use of a tool called

2101
01:38:04,057 --> 01:38:04,057
geometric inclination.

2102
01:37:54,053 --> 01:38:10,063
So I'll walk through the main ideas of

2103
01:38:10,063 --> 01:38:10,063
this section.

2104
01:38:05,058 --> 01:38:40,093
The idea, first of all, is that you may

2105
01:38:40,093 --> 01:38:40,093
design a method that theoretically works

2106
01:38:40,093 --> 01:38:40,093
very well, but when you implement it in

2107
01:38:40,093 --> 01:38:40,093
practice on your computer, your

2108
01:38:40,093 --> 01:38:40,093
discretion errors, because you can only

2109
01:38:40,093 --> 01:38:40,093
implement it in discrete time, what you

2110
01:38:40,093 --> 01:38:40,093
actually end up implementing ends up

2111
01:38:40,093 --> 01:38:40,093
deferring significantly from what you

2112
01:38:40,093 --> 01:38:40,093
initially wanted to implement.

2113
01:38:12,065 --> 01:38:51,104
This is a problem that we discussed

2114
01:38:51,104 --> 01:38:51,104
previously in sampling and it just comes

2115
01:38:51,104 --> 01:38:51,104
up everywhere in applied mathematics and

2116
01:38:51,104 --> 01:38:51,104
numerical mathematics.

2117
01:38:41,094 --> 01:39:02,109
The fact that you can only do discrete

2118
01:39:02,109 --> 01:39:02,109
computations on your computer is a big

2119
01:39:02,109 --> 01:39:02,109
implication and it's something that needs

2120
01:39:02,109 --> 01:39:02,109
to be looked into.

2121
01:38:51,104 --> 01:39:06,113
It's maybe even the most important thing

2122
01:39:06,113 --> 01:39:06,113
that needs to be looked into.

2123
01:39:02,109 --> 01:39:21,128
When building a numerical method, you

2124
01:39:21,128 --> 01:39:21,128
want to be able to implement numerical

2125
01:39:21,128 --> 01:39:21,128
methods that are very close from what you

2126
01:39:21,128 --> 01:39:21,128
theoretically would like to implement.

2127
01:39:06,113 --> 01:39:29,136
So typically you would have some

2128
01:39:29,136 --> 01:39:29,136
theoretical algorithm that would have

2129
01:39:29,136 --> 01:39:29,136
some convergence guarantees or

2130
01:39:29,136 --> 01:39:29,136
performance guarantees.

2131
01:39:22,129 --> 01:39:35,142
And so you would like to wait a way to

2132
01:39:35,142 --> 01:39:35,142
implement it on your computer so as to

2133
01:39:35,142 --> 01:39:35,142
preserve those guarantees.

2134
01:39:29,136 --> 01:39:39,146
And this turns out to be very hard in

2135
01:39:39,146 --> 01:39:39,146
general.

2136
01:39:36,143 --> 01:39:54,161
One way to do it, I would say maybe the

2137
01:39:54,161 --> 01:39:54,161
most powerful way out there to do this is

2138
01:39:54,161 --> 01:39:54,161
through procedures from the field of

2139
01:39:54,161 --> 01:39:54,161
geometric inclination.

2140
01:39:40,147 --> 01:40:19,180
And so geometric integration is a set of

2141
01:40:19,180 --> 01:40:19,180
techniques that allow you under certain

2142
01:40:19,180 --> 01:40:19,180
cognition to discretize your theoretical,

2143
01:40:19,180 --> 01:40:19,180
dynamic or theoretical optimization

2144
01:40:19,180 --> 01:40:19,180
procedure like dynamical system, and make

2145
01:40:19,180 --> 01:40:19,180
it into an algorithm that you can

2146
01:40:19,180 --> 01:40:19,180
practically implement on a computer.

2147
01:39:55,162 --> 01:40:25,186
And that's going to respect the

2148
01:40:25,186 --> 01:40:25,186
performance guarantees that you already

2149
01:40:25,186 --> 01:40:25,186
have.

2150
01:40:19,180 --> 01:40:32,193
So now the tricky part, geometric

2151
01:40:32,193 --> 01:40:32,193
inclination is based on geometry.

2152
01:40:26,187 --> 01:40:45,206
So you need to find it's not as simple as

2153
01:40:45,206 --> 01:40:45,206
like, okay, well, I have my landscape, my

2154
01:40:45,206 --> 01:40:45,206
function landscape, and I'd like to just

2155
01:40:45,206 --> 01:40:45,206
go down and find the minimum.

2156
01:40:32,193 --> 01:40:50,211
One way to do that is just by doing grain

2157
01:40:50,211 --> 01:40:50,211
in descent in continuous time.

2158
01:40:45,206 --> 01:40:55,216
And you know that that's going to go down

2159
01:40:55,216 --> 01:40:55,216
until it reaches a local minimum at the

2160
01:40:55,216 --> 01:40:55,216
very least.

2161
01:40:50,211 --> 01:40:56,217
So it's not too bad.

2162
01:40:55,216 --> 01:41:07,222
If you were to implement gradient descent

2163
01:41:07,222 --> 01:41:07,222
numerically, it wouldn't be exactly the

2164
01:41:07,222 --> 01:41:07,222
same as like the continuous time

2165
01:41:07,222 --> 01:41:07,222
dynamic.

2166
01:40:57,218 --> 01:41:20,235
It could be that actually by implementing

2167
01:41:20,235 --> 01:41:20,235
gradient descent numerically, you get all

2168
01:41:20,235 --> 01:41:20,235
sorts of numerical problems or whatnot

2169
01:41:20,235 --> 01:41:20,235
maybe grade and send.

2170
01:41:07,222 --> 01:41:24,239
It's so simple it's not actually a good

2171
01:41:24,239 --> 01:41:24,239
example.

2172
01:41:20,235 --> 01:41:33,248
But the point I want to make is that it's

2173
01:41:33,248 --> 01:41:33,248
not as simple as like, okay, well, I have

2174
01:41:33,248 --> 01:41:33,248
this dynamic that works really well, and

2175
01:41:33,248 --> 01:41:33,248
that gets to the minimum.

2176
01:41:24,239 --> 01:41:37,252
And I know that it's going to get to the

2177
01:41:37,252 --> 01:41:37,252
minimum this fast.

2178
01:41:34,248 --> 01:41:48,263
And so geometric integration will give me

2179
01:41:48,263 --> 01:41:48,263
an algorithm that I can implement on my

2180
01:41:48,263 --> 01:41:48,263
computer, and that's going to get to the

2181
01:41:48,263 --> 01:41:48,263
minimum this fast as well.

2182
01:41:39,254 --> 01:41:50,265
It's not as simple as this.

2183
01:41:48,263 --> 01:41:59,274
Geometric integration works by preserving

2184
01:41:59,274 --> 01:41:59,274
geometric structures in the dynamic that

2185
01:41:59,274 --> 01:41:59,274
you started with.

2186
01:41:51,266 --> 01:42:18,287
So in order to be able to apply geometric

2187
01:42:18,287 --> 01:42:18,287
integration, to have algorithms that work

2188
01:42:18,287 --> 01:42:18,287
for optimization, you need to design a

2189
01:42:18,287 --> 01:42:18,287
dynamical system that converges to the

2190
01:42:18,287 --> 01:42:18,287
minimum and that has some important

2191
01:42:18,287 --> 01:42:18,287
geometric features that can be preserved

2192
01:42:18,287 --> 01:42:18,287
in this way.

2193
01:41:59,274 --> 01:42:25,294
And so this is basically the goal of the

2194
01:42:25,294 --> 01:42:25,294
whole section, and it goes into the

2195
01:42:25,294 --> 01:42:25,294
following steps.

2196
01:42:18,287 --> 01:42:44,313
So one thing that can be discretized or

2197
01:42:44,313 --> 01:42:44,313
implemented on a computer in a way that

2198
01:42:44,313 --> 01:42:44,313
is close to the true dynamical system is

2199
01:42:44,313 --> 01:42:44,313
what's called Hamiltonian flows.

2200
01:42:26,295 --> 01:43:01,324
So if you specify a Hamiltonian, which is

2201
01:43:01,324 --> 01:43:01,324
a kinetic energy and potential energy,

2202
01:43:01,324 --> 01:43:01,324
then you get the Hamilton Jacobi

2203
01:43:01,324 --> 01:43:01,324
equations of motion that gives you the

2204
01:43:01,324 --> 01:43:01,324
behavior of the system that has the

2205
01:43:01,324 --> 01:43:01,324
prescribed Hamiltonian.

2206
01:42:45,314 --> 01:43:15,338
So for those who've taken a course in

2207
01:43:15,338 --> 01:43:15,338
physics, you probably know or may have

2208
01:43:15,338 --> 01:43:15,338
seen that all of Newtonian mechanics can

2209
01:43:15,338 --> 01:43:15,338
be reformulated as Hamiltonian

2210
01:43:15,338 --> 01:43:15,338
mechanics.

2211
01:43:01,324 --> 01:43:24,347
So all of that can be described as with

2212
01:43:24,347 --> 01:43:24,347
Newton, lows of motion can be described

2213
01:43:24,347 --> 01:43:24,347
through Hamiltonian mechanics.

2214
01:43:15,338 --> 01:43:45,368
It's a very general framework or a very

2215
01:43:45,368 --> 01:43:45,368
general way to look at physics, because

2216
01:43:45,368 --> 01:43:45,368
it's such a general point of view on

2217
01:43:45,368 --> 01:43:45,368
physics and such a, and just

2218
01:43:45,368 --> 01:43:45,368
Hamiltonians, they come up everywhere,

2219
01:43:45,368 --> 01:43:45,368
this mixture of kinetic and potential

2220
01:43:45,368 --> 01:43:45,368
energy, to concisely summarize the

2221
01:43:45,368 --> 01:43:45,368
behavior of a system.

2222
01:43:24,347 --> 01:43:55,378
Because they occur so much, they have

2223
01:43:55,378 --> 01:43:55,378
been studied extensively, and it turns

2224
01:43:55,378 --> 01:43:55,378
out that Hamiltonians and specifically

2225
01:43:55,378 --> 01:43:55,378
the motion they entail.

2226
01:43:46,369 --> 01:44:10,387
So the Hamilton Jacobi equations of

2227
01:44:10,387 --> 01:44:10,387
motion, they can be discretized or

2228
01:44:10,387 --> 01:44:10,387
implemented accurately on a computer

2229
01:44:10,387 --> 01:44:10,387
using Symplectic integration, which is a

2230
01:44:10,387 --> 01:44:10,387
part of geometric integration.

2231
01:43:55,378 --> 01:44:19,396
So in short, you can use Symplectic

2232
01:44:19,396 --> 01:44:19,396
integration to accurately simulate a

2233
01:44:19,396 --> 01:44:19,396
Hamiltonian dynamical system.

2234
01:44:10,387 --> 01:44:29,406
Now, the problem is, these dynamics are

2235
01:44:29,406 --> 01:44:29,406
conservative, so they preserve the

2236
01:44:29,406 --> 01:44:29,406
Hamiltonian.

2237
01:44:20,397 --> 01:44:42,419
So if you're at some point hidden states,

2238
01:44:42,419 --> 01:44:42,419
space with a certain kinetic energy,

2239
01:44:42,419 --> 01:44:42,419
potential energy, and you run the

2240
01:44:42,419 --> 01:44:42,419
dynamics forward, your overall energy is

2241
01:44:42,419 --> 01:44:42,419
not going to change.

2242
01:44:29,406 --> 01:44:43,420
So that standard physics.

2243
01:44:42,419 --> 01:44:56,433
Energy is always conserved when there's

2244
01:44:56,433 --> 01:44:56,433
no friction, all kind of like ideal

2245
01:44:56,433 --> 01:44:56,433
physical systems with no friction, the

2246
01:44:56,433 --> 01:44:56,433
energy is conserved.

2247
01:44:43,420 --> 01:45:06,437
So when you're going to run this

2248
01:45:06,437 --> 01:45:06,437
Symplectic optimization scheme to

2249
01:45:06,437 --> 01:45:06,437
simulate these Hamilton and Jacobi

2250
01:45:06,437 --> 01:45:06,437
equations of motion, the energy is going

2251
01:45:06,437 --> 01:45:06,437
to be conserved.

2252
01:44:56,433 --> 01:45:17,448
Now, we're in trouble if we want to do

2253
01:45:17,448 --> 01:45:17,448
optimization, because in optimization, if

2254
01:45:17,448 --> 01:45:17,448
you think of the function as the energy,

2255
01:45:17,448 --> 01:45:17,448
you want to dissipate energy as much as

2256
01:45:17,448 --> 01:45:17,448
possible to reach the minimum.

2257
01:45:06,437 --> 01:45:19,450
So you want to lose energy.

2258
01:45:17,448 --> 01:45:35,466
So what the section does so this section,

2259
01:45:35,466 --> 01:45:35,466
by the Way, is a review of more technical

2260
01:45:35,466 --> 01:45:35,466
papers what these papers do, it's a very

2261
01:45:35,466 --> 01:45:35,466
clever trick is they say, okay, well, we

2262
01:45:35,466 --> 01:45:35,466
want to minimize a function.

2263
01:45:20,451 --> 01:45:43,474
We're going to say the function is

2264
01:45:43,474 --> 01:45:43,474
potential energy and also we're going to

2265
01:45:43,474 --> 01:45:43,474
add a kinetic energy on top of that to

2266
01:45:43,474 --> 01:45:43,474
get a Hamiltonian.

2267
01:45:36,467 --> 01:45:57,487
Now this Hamiltonian, we could simulate

2268
01:45:57,487 --> 01:45:57,487
it through symplectic integration, but

2269
01:45:57,487 --> 01:45:57,487
actually, if we did, we wouldn't

2270
01:45:57,487 --> 01:45:57,487
dissipate the function.

2271
01:45:46,477 --> 01:46:16,501
So now what the section does is it

2272
01:46:16,501 --> 01:46:16,501
introduces a higher dimensional state

2273
01:46:16,501 --> 01:46:16,501
space with the Hamiltonian that if you

2274
01:46:16,501 --> 01:46:16,501
simulate those dynamics, it actually

2275
01:46:16,501 --> 01:46:16,501
optimizes the function.

2276
01:45:57,488 --> 01:46:28,513
So this is what was a convoluted way to

2277
01:46:28,513 --> 01:46:28,513
say it reformulates optimization as a

2278
01:46:28,513 --> 01:46:28,513
conservative system with a different

2279
01:46:28,513 --> 01:46:28,513
Hamiltonian.

2280
01:46:19,504 --> 01:46:45,530
And so by and because we know how to

2281
01:46:45,530 --> 01:46:45,530
simulate dynamics with Hamiltonian so

2282
01:46:45,530 --> 01:46:45,530
well, a good way of doing optimization is

2283
01:46:45,530 --> 01:46:45,530
by finding a Hamiltonian so that when you

2284
01:46:45,530 --> 01:46:45,530
discretize it, you get the optimization

2285
01:46:45,530 --> 01:46:45,530
process that you wanted.

2286
01:46:28,513 --> 01:46:51,536
If you do that, you get a numerical

2287
01:46:51,536 --> 01:46:51,536
method that's stable, that works well,

2288
01:46:51,536 --> 01:46:51,536
that has good coherence guarantees.

2289
01:46:46,531 --> 01:47:02,541
And it turns out the numerical methods

2290
01:47:02,541 --> 01:47:02,541
that are developed, they work for

2291
01:47:02,541 --> 01:47:02,541
optimization on any kind of smooth

2292
01:47:02,541 --> 01:47:02,541
manifold, for function, on any smooth

2293
01:47:02,541 --> 01:47:02,541
functions, on any smooth manifold.

2294
01:46:51,536 --> 01:47:03,542
They work well.

2295
01:47:02,541 --> 01:47:09,548
They are generalized gradient descent in

2296
01:47:09,548 --> 01:47:09,548
the sense that you recover gradient

2297
01:47:09,548 --> 01:47:09,548
descent in a certain limit.

2298
01:47:03,542 --> 01:47:23,562
And they can be seen as accelerated

2299
01:47:23,562 --> 01:47:23,562
because they have this notion of

2300
01:47:23,562 --> 01:47:23,562
acceleration in the sense that, let's say

2301
01:47:23,562 --> 01:47:23,562
the function that you want to optimize,

2302
01:47:23,562 --> 01:47:23,562
it like a hill and you want to go down.

2303
01:47:09,548 --> 01:47:36,575
If you just did great, in the sense

2304
01:47:36,575 --> 01:47:36,575
you're like blindingly going down at the

2305
01:47:36,575 --> 01:47:36,575
same speed, or your speed is like

2306
01:47:36,575 --> 01:47:36,575
proportional to the slope of the

2307
01:47:36,575 --> 01:47:36,575
landscape.

2308
01:47:23,562 --> 01:47:42,580
But when you actually let a Bull rolling

2309
01:47:42,580 --> 01:47:42,580
down, this is not really what happens.

2310
01:47:36,575 --> 01:47:51,590
The Bull is going to roll faster and

2311
01:47:51,590 --> 01:47:51,590
faster and it's going to accelerate, it's

2312
01:47:51,590 --> 01:47:51,590
going to go down, it's going to overshoot

2313
01:47:51,590 --> 01:47:51,590
the minimum and then it's going to like

2314
01:47:51,590 --> 01:47:51,590
oscillate until it converges to a

2315
01:47:51,590 --> 01:47:51,590
minimum.

2316
01:47:42,581 --> 01:47:55,594
So these are the kind of optimization

2317
01:47:55,594 --> 01:47:55,594
methods that are developed here.

2318
01:47:52,591 --> 01:48:10,603
They're optimization methods that are

2319
01:48:10,603 --> 01:48:10,603
accelerated in a physical sense, that has

2320
01:48:10,603 --> 01:48:10,603
physical sense acceleration and physical

2321
01:48:10,603 --> 01:48:10,603
meaning because they're going to

2322
01:48:10,603 --> 01:48:10,603
accelerate as they go down, overshoot and

2323
01:48:10,603 --> 01:48:10,603
then stabilize.

2324
01:47:55,594 --> 01:48:15,608
So this is the whole point of this

2325
01:48:15,608 --> 01:48:15,608
section.

2326
01:48:11,604 --> 01:48:22,615
Now briefly, because I think we're

2327
01:48:22,615 --> 01:48:22,615
running out of time, but we can of

2328
01:48:22,615 --> 01:48:22,615
course, revisit these sections later.

2329
01:48:15,608 --> 01:48:26,619
In the third action.

2330
01:48:25,618 --> 01:48:27,620
We have sampling.

2331
01:48:26,619 --> 01:48:30,623
So we talked extensively about sampling.

2332
01:48:27,620 --> 01:48:38,631
The sampling, as we discussed, can be

2333
01:48:38,631 --> 01:48:38,631
seen as an optimization of probability

2334
01:48:38,631 --> 01:48:38,631
distributions.

2335
01:48:30,623 --> 01:48:53,646
So we have the distribution that we want

2336
01:48:53,646 --> 01:48:53,646
to sample from, and we just run a process

2337
01:48:53,646 --> 01:48:53,646
that is random so it can be described by

2338
01:48:53,646 --> 01:48:53,646
its own distribution and want the process

2339
01:48:53,646 --> 01:48:53,646
to concept as fast as possible to the

2340
01:48:53,646 --> 01:48:53,646
target.

2341
01:48:38,631 --> 01:49:01,648
So we want that distribution of the

2342
01:49:01,648 --> 01:49:01,648
process to concept as fast as possible to

2343
01:49:01,648 --> 01:49:01,648
the target distinctions.

2344
01:48:53,646 --> 01:49:09,656
So in a way that can be seen as I guess

2345
01:49:09,656 --> 01:49:09,656
complicated for many people.

2346
01:49:02,649 --> 01:49:11,658
I think it's pretty abstract.

2347
01:49:09,656 --> 01:49:20,667
But it's been known for a long time that

2348
01:49:20,667 --> 01:49:20,667
you can reformulate sampling as just

2349
01:49:20,667 --> 01:49:20,667
optimization of distributions.

2350
01:49:12,659 --> 01:49:49,696
Now it turns out that when you use the

2351
01:49:49,696 --> 01:49:49,696
accelerated optimization method of the

2352
01:49:49,696 --> 01:49:49,696
second section to sampling so when you

2353
01:49:49,696 --> 01:49:49,696
use, when you do accelerated optimization

2354
01:49:49,696 --> 01:49:49,696
on the space of probability distributions

2355
01:49:49,696 --> 01:49:49,696
in order to solve the sampling problem,

2356
01:49:49,696 --> 01:49:49,696
you get a process that's called under

2357
01:49:49,696 --> 01:49:49,696
damp launch one dynamics.

2358
01:49:21,668 --> 01:50:05,706
So if you solve that process, you're

2359
01:50:05,706 --> 01:50:05,706
basically going to get good samples, very

2360
01:50:05,706 --> 01:50:05,706
good samples of your target distribution

2361
01:50:05,706 --> 01:50:05,706
because that process can be seen as doing

2362
01:50:05,706 --> 01:50:05,706
an accelerated optimization on the space

2363
01:50:05,706 --> 01:50:05,706
of probability distributions.

2364
01:49:49,696 --> 01:50:10,711
In other words, the distribution

2365
01:50:10,711 --> 01:50:10,711
describing the process is going to

2366
01:50:10,711 --> 01:50:10,711
accelerate towards the target.

2367
01:50:06,707 --> 01:50:15,716
So you're going to get there very fast

2368
01:50:15,716 --> 01:50:15,716
and your symbols are going to be very

2369
01:50:15,716 --> 01:50:15,716
good.

2370
01:50:10,711 --> 01:50:24,725
So this is 2.6 where this is kind of

2371
01:50:24,725 --> 01:50:24,725
derived.

2372
01:50:17,718 --> 01:50:33,734
In 3.1, we basically talk about the the

2373
01:50:33,734 --> 01:50:33,734
good properties of samplers in general.

2374
01:50:24,725 --> 01:50:47,748
So sampling is not like a complete field,

2375
01:50:47,748 --> 01:50:47,748
but there's a lot of work showing that

2376
01:50:47,748 --> 01:50:47,748
certain processes have certain

2377
01:50:47,748 --> 01:50:47,748
characteristics of processes make them

2378
01:50:47,748 --> 01:50:47,748
better samplers and others make them

2379
01:50:47,748 --> 01:50:47,748
worse.

2380
01:50:33,734 --> 01:50:49,750
So this is what we discuss.

2381
01:50:48,749 --> 01:50:58,759
And then in free .2, we put this all

2382
01:50:58,759 --> 01:50:58,759
together in Hamiltonian Monte Carlo,

2383
01:50:58,759 --> 01:50:58,759
which is a state of the art method for

2384
01:50:58,759 --> 01:50:58,759
sampling.

2385
01:50:49,750 --> 01:51:18,773
Hamiltonian Monte Carlo is a way of

2386
01:51:18,773 --> 01:51:18,773
using, if you use symplectic integration

2387
01:51:18,773 --> 01:51:18,773
under Downplantromodynamics, which is

2388
01:51:18,773 --> 01:51:18,773
your accelerated sampling method, that

2389
01:51:18,773 --> 01:51:18,773
you cannot stimulate directly, again, you

2390
01:51:18,773 --> 01:51:18,773
get the same problem.

2391
01:51:03,758 --> 01:51:24,779
If you use symplectic integration to

2392
01:51:24,779 --> 01:51:24,779
simulate that, then you get HamiltonI

2393
01:51:24,779 --> 01:51:24,779
Monte Carlo.

2394
01:51:18,773 --> 01:51:33,788
So Hamiltonian Monte Carlo is attributes

2395
01:51:33,788 --> 01:51:33,788
Google way of doing accelerated sampling

2396
01:51:33,788 --> 01:51:33,788
that's based on ideas of symplectic

2397
01:51:33,788 --> 01:51:33,788
integration.

2398
01:51:24,779 --> 01:51:40,795
Now, very briefly, the section four is on

2399
01:51:40,795 --> 01:51:40,795
inference.

2400
01:51:35,790 --> 01:51:47,802
The inference in its most general form is

2401
01:51:47,802 --> 01:51:47,802
variational inference.

2402
01:51:42,797 --> 01:51:53,808
So what we typically do know and love

2403
01:51:53,808 --> 01:51:53,808
from active inference.

2404
01:51:47,802 --> 01:52:00,809
And I have a target probability

2405
01:52:00,809 --> 01:52:00,809
distribution that I'm not able to compute

2406
01:52:00,809 --> 01:52:00,809
directly.

2407
01:51:53,808 --> 01:52:03,812
So I'm going to approximate it as best as

2408
01:52:03,812 --> 01:52:03,812
I can.

2409
01:52:00,809 --> 01:52:23,832
Now, these distributions, they're often

2410
01:52:23,832 --> 01:52:23,832
used to compute expectations, or in other

2411
01:52:23,832 --> 01:52:23,832
words, in statistics and machine

2412
01:52:23,832 --> 01:52:23,832
learning, we often need to compute

2413
01:52:23,832 --> 01:52:23,832
expectations with respect to some

2414
01:52:23,832 --> 01:52:23,832
probability distribution.

2415
01:52:04,813 --> 01:52:32,841
What this section does is it derives a

2416
01:52:32,841 --> 01:52:32,841
whole bunch of divergences.

2417
01:52:24,833 --> 01:52:34,843
Like the Kel divergence.

2418
01:52:32,841 --> 01:52:38,847
I mean, the Kale divergence is not

2419
01:52:38,847 --> 01:52:38,847
discussed so much in this action.

2420
01:52:34,843 --> 01:52:53,862
I'll explain why, but it derives a whole

2421
01:52:53,862 --> 01:52:53,862
bunch of divergences that can be used to

2422
01:52:53,862 --> 01:52:53,862
approximate this unknown distribution

2423
01:52:53,862 --> 01:52:53,862
with some other distributions that are

2424
01:52:53,862 --> 01:52:53,862
tractable.

2425
01:52:38,847 --> 01:53:17,880
So to put in a different way, you have

2426
01:53:17,880 --> 01:53:17,880
this abstract variational inference

2427
01:53:17,880 --> 01:53:17,880
problem where you have this target

2428
01:53:17,880 --> 01:53:17,880
distribution and then you have this

2429
01:53:17,880 --> 01:53:17,880
family of distribution that you know, and

2430
01:53:17,880 --> 01:53:17,880
you want to select the distribution in

2431
01:53:17,880 --> 01:53:17,880
your family that best approximates your

2432
01:53:17,880 --> 01:53:17,880
target distribution.

2433
01:52:55,864 --> 01:53:31,893
Now, in order to do this, you first need

2434
01:53:31,893 --> 01:53:31,893
to derive a measure of similarity between

2435
01:53:31,893 --> 01:53:31,893
distributions to know, okay, well, what

2436
01:53:31,893 --> 01:53:31,893
is the best distribution.

2437
01:53:18,881 --> 01:53:37,900
Like, how can you quantify being the best

2438
01:53:37,900 --> 01:53:37,900
distribution, being the best

2439
01:53:37,900 --> 01:53:37,900
approximation to your target

2440
01:53:37,900 --> 01:53:37,900
distribution?

2441
01:53:31,894 --> 01:53:42,905
And to do that, you need to specify a

2442
01:53:42,905 --> 01:53:42,905
emergence, like the KL divergence.

2443
01:53:37,900 --> 01:53:51,914
But the problem is, the KL divergence is

2444
01:53:51,914 --> 01:53:51,914
not always practically applicable.

2445
01:53:43,906 --> 01:53:56,919
One example is when the target

2446
01:53:56,919 --> 01:53:56,919
distribution is just given by samples.

2447
01:53:52,915 --> 01:54:00,917
So maybe you don't even know the target

2448
01:54:00,917 --> 01:54:00,917
distribution.

2449
01:53:57,920 --> 01:54:04,921
Maybe it's a gaussian, but you don't know

2450
01:54:04,921 --> 01:54:04,921
it.

2451
01:54:01,918 --> 01:54:06,923
You just have samples from the gaussian.

2452
01:54:04,921 --> 01:54:13,930
So you cannot just have, like, a

2453
01:54:13,930 --> 01:54:13,930
histogram, and you need to best

2454
01:54:13,930 --> 01:54:13,930
approximate the histogram with the

2455
01:54:13,930 --> 01:54:13,930
distribution in some family.

2456
01:54:06,923 --> 01:54:20,937
So when you have a problem like this,

2457
01:54:20,937 --> 01:54:20,937
which just happens all the time, you

2458
01:54:20,937 --> 01:54:20,937
cannot use the KL divergence.

2459
01:54:13,930 --> 01:54:22,939
So you need to think about other

2460
01:54:22,939 --> 01:54:22,939
divergences.

2461
01:54:20,937 --> 01:54:43,960
And so what this section does is deriving

2462
01:54:43,960 --> 01:54:43,960
other classes of divergences that are

2463
01:54:43,960 --> 01:54:43,960
more generally applicable than the KL

2464
01:54:43,960 --> 01:54:43,960
divergence, and they have also some very

2465
01:54:43,960 --> 01:54:43,960
nice properties and then showing, okay,

2466
01:54:43,960 --> 01:54:43,960
well, how is it that I can minimize these

2467
01:54:43,960 --> 01:54:43,960
divergences to solve a variation of

2468
01:54:43,960 --> 01:54:43,960
inference problem?

2469
01:54:23,940 --> 01:54:59,976
So I think there's a lot of things to be

2470
01:54:59,976 --> 01:54:59,976
done there in the sense that in active

2471
01:54:59,976 --> 01:54:59,976
inference, we always use the Kale

2472
01:54:59,976 --> 01:54:59,976
divergence to do variational inference

2473
01:54:59,976 --> 01:54:59,976
and minimize free energy.

2474
01:54:44,961 --> 01:55:11,982
And this Kale divergence is available

2475
01:55:11,982 --> 01:55:11,982
because we typically have adjuncted

2476
01:55:11,982 --> 01:55:11,982
models that are nice and they're

2477
01:55:11,982 --> 01:55:11,982
expressed graphical models.

2478
01:55:00,971 --> 01:55:21,992
But there's this whole other plethora of

2479
01:55:21,992 --> 01:55:21,992
divergences and algorithms to minimize

2480
01:55:21,992 --> 01:55:21,992
the divergences that's out there.

2481
01:55:13,983 --> 01:55:34,005
And it could be the case that there's

2482
01:55:34,005 --> 01:55:34,005
very interesting recipes and methods that

2483
01:55:34,005 --> 01:55:34,005
can be either brought back to the KL case

2484
01:55:34,005 --> 01:55:34,005
that we use or just used altogether in

2485
01:55:34,005 --> 01:55:34,005
our setting.

2486
01:55:22,993 --> 01:55:50,021
In particular, when, for example, let's

2487
01:55:50,021 --> 01:55:50,021
say they wanted to approximate the

2488
01:55:50,021 --> 01:55:50,021
expected free energy in active coherence,

2489
01:55:50,021 --> 01:55:50,021
the expected free energy is an

2490
01:55:50,021 --> 01:55:50,021
expectation and want to approximate that

2491
01:55:50,021 --> 01:55:50,021
expectation.

2492
01:55:35,006 --> 01:55:52,023
It could be the case.

2493
01:55:50,021 --> 01:56:10,035
Well, I think these methods that are

2494
01:56:10,035 --> 01:56:10,035
summarizing section four could be very

2495
01:56:10,035 --> 01:56:10,035
useful because they basically develop

2496
01:56:10,035 --> 01:56:10,035
divergences that quantify how far the

2497
01:56:10,035 --> 01:56:10,035
expectations are going to be if you

2498
01:56:10,035 --> 01:56:10,035
choose a different distribution.

2499
01:55:53,024 --> 01:56:15,040
So it's all like, very natural in that

2500
01:56:15,040 --> 01:56:15,040
computational sense.

2501
01:56:10,035 --> 01:56:19,044
And then finally ant activation through

2502
01:56:19,044 --> 01:56:19,044
active coherence.

2503
01:56:15,040 --> 01:56:30,055
Well, I think we've discussed that

2504
01:56:30,055 --> 01:56:30,055
already extensively, but I won't spoil it

2505
01:56:30,055 --> 01:56:30,055
more today and we can come back to it

2506
01:56:30,055 --> 01:56:30,055
next time.

2507
01:56:19,044 --> 01:56:37,062
Daniel: Thanks a lot for that overview.

2508
01:56:35,060 --> 01:56:39,064
That was very powerful.

2509
01:56:37,062 --> 01:56:45,070
Incredible dot one very informative.

2510
01:56:41,066 --> 01:56:54,079
Looking forward to starting with some

2511
01:56:54,079 --> 01:56:54,079
questions from the live chaos and

2512
01:56:54,079 --> 01:56:54,079
people's comments on the video between

2513
01:56:54,079 --> 01:56:54,079
now and next week.

2514
01:56:46,071 --> 01:57:04,083
If anybody else of your colleagues or

2515
01:57:04,083 --> 01:57:04,083
anyone in the institute wants to join,

2516
01:57:04,083 --> 01:57:04,083
we'll be here next week for 52.2.

2517
01:56:54,079 --> 01:57:06,085
So thank you, Lance, for the time.

2518
01:57:04,083 --> 01:57:08,087
Really appreciate it.

2519
01:57:06,085 --> 01:57:09,088
Lance: Thanks, Daniel.

2520
01:57:08,087 --> 01:57:11,090
Daniel: Farewell.

2521
01:57:10,089 --> 01:57:13,092
Lance: See you next week.

2522
01:57:12,091 --> 01:57:14,092
Bye.

