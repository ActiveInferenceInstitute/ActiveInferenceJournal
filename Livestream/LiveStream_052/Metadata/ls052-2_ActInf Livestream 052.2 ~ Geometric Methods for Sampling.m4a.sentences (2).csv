start	end	sentNum	speaker	confidence	text
7590	8618	1	A	0.86814	Hello and welcome.
8784	14940	2	A	0.80864	It's ActInf Lab Livestream 52.2 on March 9, 2023.
15870	17990	4	A	0.99995	Welcome to the Active Inference Institute.
18150	24330	5	A	0.53999	We're a participatory online institute that is communicating, learning, and practicing applied active inference.
25230	28038	6	A	0.99966	You can find more information on these links.
28214	33940	7	A	0.99958	This is a recorded and archive live stream, so please provide feedback so we can improve our work.
34310	47670	8	A	0.99885	All backgrounds and perspectives are welcome, and we'll be following video etiquette for Livestreams head over Active Inference.org to learn more about getting involved with projects and learning groups.
48890	48100	9	A	0.99424	All right!
48115	63340	10	A	0.99424	We are back in Livestream 52.2, in our third discussion on the paper geometric methods for sampling, optimization, inference and adaptive agents.
64350	76480	11	A	0.9999	We had a Dot-Zero background and context video and last week Lance joined for 52.1, where we had a great overview discussion on the paper.
76930	87026	12	A	0.99855	So today we're going to see where it goes, see where our last week has taken us and how we're thinking about it or curious about it.
87128	92130	13	A	0.99998	If you're watching live, of course, feel free to write questions in a live chat.
92650	98550	14	A	0.9996	Otherwise, let us pick up on a mostly blank slide.
98890	103346	15	A	1	And just thanks again, Lance, for joining.
103378	112300	16	A	0.99965	If you want to give any sort of introduction or recap opening here, go for it.
112990	116762	17	B	0.94145	Well, yeah, I mean, thanks a lot, Daniel, for organizing this.
116816	120462	18	B	0.63363	I'm super happy to be here, I think.
120516	126122	19	B	0.78037	Well, last time we went through most of the paper, we discussed a lot about sampling.
126266	127914	20	B	0.77	I guess the idea of sampling.
127962	137620	21	B	0.99994	We discussed a bit less about Hamiltonia Monte Carlo, which is one of the, I guess, state of the art methods for sampling in continuous space.
138870	141250	22	B	0.99999	We discussed a lot about optimization.
141990	151000	23	B	0.99876	There's a nice figure actually that we can discuss today which gives some nice intuition about the kind of optimization methods that we reviewed in the paper.
152410	155750	24	B	0.92	And then there's another section on statistical inference.
155910	164780	25	B	0.96566	So this is a bit of a different section than people in the free energy principle literature and active inference are used to.
165230	176510	26	B	0.99993	Because here the goal of inference is about approximating expectations as opposed to just approximating distributions in of themselves.
176660	181518	27	B	0.77	It turns out to be these two perspectives turn out to be dual.
181694	195030	28	B	0.60059	But I guess here we want to develop notions of divergences and discrepancies that are a bit more general than the KL divergence and that can use to solve problems that the KL divergence cannot.
196090	207078	29	B	0.99	And I guess the overall picture for why we want to do that is the Kale divergence turns out to have a lot of really nice properties that we can discuss.
207244	218798	30	B	0.67	One of them is that if the Kale divergence is reduced, it means that the two distributions in play are more similar in terms of information.
218964	232210	31	B	0.99878	So there is this idea of information monotonicity where the KL divergence sort of gives an ordering as to what extent two distributions quantify.
232710	242706	32	B	0.96572	So if you had three distributions and you compute the KL divergence between them and now KL of AB is lower than KL of AC.
242808	248678	33	B	1	It means that B is more closer in terms of information to A than C is to A.
248764	255734	34	B	0.92389	So you have this really nice thing that is captured by the Kel divergence, which makes sense when we're dealing with information.
255932	259530	35	B	0.89	The Kel divergence also has so many other nice properties.
261230	265798	36	B	0.99964	It's not a distance, but it turns out to behave a bit like a square distance.
265974	270030	37	B	0.99753	So you have this kind of like, really nice pitagorian theorem.
271730	283038	38	B	1	And I won't get into the exact statement, but it's like if you have a B and C distributions, then KLAB plus klac equals KLBC.
283134	294020	39	B	0.99996	If you have like a rectangle triangle, if ABC defines a rectangle triangle in information space, you have other properties like the KL divergence gives and so on.
294950	301266	40	B	0.80777	So the KL divergence is in general, I would say, the distribution, the divergence of choice.
301378	304134	41	B	0.83743	But it turns out that in many cases you just can't use it.
304172	312538	42	B	1	For example, when you have samples and you want to approximate some samples with a distribution, then the Kale divergence just is not going to work there.
312624	314986	43	B	0.90446	So you need to derive some other things.
315168	324480	44	B	0.98068	So this is to say that we're considering statistical inference a bit more generally than what we do in active inference in general.
325010	335040	45	B	0.85	And so this speaks to why the section here is a bit different from the standard inference literature that we usually consider.
335490	353766	46	B	0.81	And then I think that the well, then this section five, which is about active inference, and I think we should discuss that a little bit more because the formation active inference lab that's presented there is to my mind the most general and also the simplest conceptually that's been out there.
353868	365578	47	B	0.55	I mean, we sort of recap the derivation active inference lab and also like the properties of the expected community properties of active inference and also how to scale active inference and so on.
365664	369226	48	B	1	And we do that in just seven pages or five pages.
369258	370640	49	B	0.59	I mean, it's just very short.
371650	375978	50	B	0.91138	So it stands, sure, but it's like a really concise summary.
376074	381386	51	B	1	And actually from there you can really derive a lot of technical papers.
381418	395640	52	B	0.21873	Active inference lab, to me, it's the most general, and if you as a reader can understand that section, then you can sort of really understand what active inference is about.
397370	399800	53	B	0.99737	This is kind of the overview for today.
401210	407210	54	B	0.99	I would really like to be discussing questions because last time we read discussed about most of the papers.
407550	409740	55	B	0.82297	But yeah, whatever comes up.
411070	411820	56	A	0.9999	Awesome.
412190	413850	57	A	0.99101	All right, great.
414000	437170	58	A	0.99991	Well, let us talk about some of the more foundational pieces hamiltonian Monte Carlo and then on through section four with the points that you raised about the KL, which generalized inference beyond how it may have been brought up in other octave.
437510	450760	59	A	1	And then we can spend most of the time in section five and looking at some of those figures connecting some of the intuitions about the ball rolling down the bowl to the person running.
451690	452246	60	A	0.99307	So.
452348	455074	61	B	0.53158	Sounds good on Hamiltonian?
455122	455842	62	A	0.87582	Monte Carlo.
455906	457640	63	A	0.9994	Where do you want to pick up?
458410	458918	64	B	0.99399	Sure.
459004	465980	65	B	0.98	I meantonian so last time we discussed a lot about the problem of sampling and why that's the difficult problem.
467650	473134	66	B	0.96	And we arrived at the conclusion, or I presented like Monte Carlo methods, how they work.
473172	494280	67	B	0.99622	So you're basically running a stochastic process, like a random motion and sort of the distribution defining the process is going to convert your target distribution, which means that when you run the process long enough, then every point that it's going to be in is going to be like a sample of the distribution that you want to sample from.
495290	497480	68	B	1	Now, there's a lot of issues with that.
498490	516438	69	B	0.99007	Conceptually, it's not so difficult, but actually, when you want to implement this in practice, it turns out to be really hard because if you just implement the simplest stochastic process to sample your target distribution, it's going to be extremely slow.
516534	521674	70	B	1	And I think that's the main bottleneck when developing Monte Carlo methods.
521722	524590	71	B	0.99745	Monte Carlo sampling in general is slow.
525090	533390	72	B	0.72	And that's also one of the reasons why one might want to do variational inference instead of sampling.
534770	537758	73	B	0.99475	So something is slower, but it's also more accurate.
537854	541806	74	B	0.96	It can approximate distributions that are completely arbitrary.
541918	548034	75	B	0.99065	So if you care about accuracy and you have time and computational resources, then for sure go for sampling.
548162	555898	76	B	0.99997	If you care about speed, about doing things online, and you don't care about accuracy so much, then the variational inference is the way to go.
555984	558780	77	B	1	At least that's my understanding right now.
559230	564698	78	B	0.54828	So let's say you wanted to sample a distribution in a continuous space.
564784	567514	79	B	0.82817	So it could be just as last time.
567552	578400	80	B	0.98823	Let's imagine the state space is the desk where I'm at, and you sort of have the distribution, which could be like multimodal, very weird, and you just want to take samples from there.
579410	585842	81	B	0.34796	HamiltonI Monte Carlo is probably the state of the art methods method to do that.
585976	594930	82	B	0.9888	There's a lot of other methods out there, but Hamilton Monte Carlo typically just works very well and in a wide variety of situations.
595350	608406	83	B	0.6658	Instead, the idea of HamiltonI Monte Carlo is you're going to augment the state space with so let's say that the original state space you start with are the positions.
608598	613100	84	B	0.65	And so you're going to a mend that with a velocity state space.
613790	621710	85	B	0.93577	If your original state space was Euclidean space of N dimensions, you just end up with a nuclear space of two N dimensions.
622130	624480	86	B	0.98061	So you double the size of the state space.
625090	634050	87	B	0.98	And now you say, okay, well, the distribution that I want to stumble from actually defines an energy landscape.
634950	645406	88	B	0.49613	So technically it's like if you have distribution which is P, then minus lock, p is an energy landscape.
645518	652150	89	B	0.93159	So points where minus lock P is low are points where P is high.
652220	655320	90	B	1	And so these are points that you want to sample a lot from.
655850	662522	91	B	0.71	And contrary wise, if minus Lock t is very high, then P is low.
662576	667370	92	B	1	And you don't really want to go there so much because these are points of low probability.
668110	676282	93	B	0.94884	So I think this minus log P, actually there's many reasons why minus Lock P is meaningful in physics.
676346	695560	94	B	0.99932	But just note for now that minus Lock P is just like a function and the minimum of the functions of that function are the high probability points and these are high energy points where you basically don't want to go there so much.
696330	700502	95	B	0.99566	So let's call this minus Lock P potential energy.
700636	704310	96	B	0.99	And so this is what this really is in physics.
705630	712170	97	B	0.98336	Technically in physics, P would be a gives measure, what people call an equilibrium distribution.
713950	717838	98	B	0.99997	Last time we saw like soft max, minus something.
718004	723086	99	B	0.54	The something is the potential energy anyway.
723188	727200	100	B	0.82	And so minus Lock P would be the potential energy.
728050	739230	101	B	1	And then if you add kinetic energy on your velocities, then you get what's called a Hamiltonium, which is the sum of the potential and kinetic energies.
739390	743062	102	B	0.7547	So what is exactly kinetic energy?
743116	746280	103	B	0.99	The kinetic energy is like velocity squared pretty much.
746730	752786	104	B	0.97319	So if you add remember that your state space is position and velocity.
752978	766806	105	B	0.81211	If you add and you take a point in state space, so you would have kinetic energy, which is velocity squared, and a potential energy which would be minus lock peak.
766998	774062	106	B	1	Now, if you add the two together, what you get is a Hamiltonian, which is the sum of the kinetic energy and potential energy.
774196	775930	107	B	0.87	And this is just standard physics.
776010	781780	108	B	0.64193	Hamiltonian is the sum of kinetic and potential energy and it gives us the total energy of the system.
782870	786750	109	B	0.98092	So why we start with the problem of sampling.
786830	794630	110	B	1	And here I just told you something very complicated where we get a Hamiltonian, there's actually a good reason why I want to do that.
794780	817642	111	B	0.94	And it comes back to the idea of geometric integration that we talked about last time, which is that typically maybe I have a process that I know will give very efficient sampling, but actually when I implement it on the computer in discrete time, I just lose all the properties that make that sampling efficient.
817786	830338	112	B	0.98663	So actually it turns out that most people working in Monte Carlo sampling, they're working on efficient discretizations of continuous processes as opposed to on the continuous process themselves.
830504	831694	113	B	0.95239	Really the bottleneck.
831742	844630	114	B	1	And the difficulty here is the implementation part, implementing process on a computer like you and I had in such a way that we retain all the good sampling properties.
845370	853400	115	B	0.66484	So one very powerful idea is that of geometric integration, which is of preserving geometric properties of a system.
854090	868320	116	B	0.99385	Geometric integration is the field that develops computational methods of numerical integration and numerical discretion in such a way that they preserve important geometric properties of the system.
869250	873626	117	B	0.99797	Here, the geometry in play is a Hamiltonian.
873818	876554	118	B	0.99	And so you might think, well, that's pretty weird.
876602	884014	119	B	0.98	I mean, a Hamiltonian is an energy here we're talking about preserving the geometry and preserving the Hamiltonian.
884062	886706	120	B	0.99651	How do these two things fit together?
886888	903410	121	B	0.97	And so it turns out that the presence of a Hamiltonian and the fact that we have a state space that has positions and velocity, technically, in mathematics, what we then get is what people call symptom geometry.
903570	913850	122	B	0.9767	So symptom geometry just arises when we have those states that comprise positions and velocity and where you have Hamiltonians.
914350	925550	123	B	0.99	So this is just like a way of explaining why the Hamiltonian is closely and intimately related to geometry.
926130	936798	124	B	0.97132	So geometry integration enables you to discrete processes in such a way that the Hamiltonian is preserved.
936974	944360	125	B	0.97	Now, when you think about the Hamiltonian, the Hamiltonian gives you the energy of a particular point in space.
945290	959770	126	B	0.99	And so if you simulate trajectories that preserve the Hamiltonian, what you're effectively doing is sampling from the contours of the probability distribution, contours that have the same probability.
960670	975994	127	B	0.93513	So basically going around, let's say, for example, in circles in a region that has the same probability, when we want to sample, we want to go everywhere.
976042	982340	128	B	0.92	I mean, we want to sample regions of high probability, low probability, and want to be able to go from one to the other.
982870	995480	129	B	0.97931	So what geometric integration allows us to do is to simulate dynamics that are going to preserve the contours of the probability distribution, and they're going to do so very well.
996810	1013962	130	B	1	The advantage here is that when we use geometric integration to simulate Hamiltonian dynamics, which are conservative and again, staying the contours, what geometric integration allows us to do is to take time steps that are very long.
1014096	1020346	131	B	0.99955	So it enables us to travel very far in the landscape while still preserving the Hamiltonian.
1020458	1026986	132	B	0.99974	So you don't need to take very small time steps to remain accurate and preserve the Hamiltonian.
1027018	1033330	133	B	0.97122	But actually, dramatic integration allows you to take very long time steps and still preserve the Hamiltonian.
1033670	1045670	134	B	0.81906	So now we have a dynamic that's Hamiltonian preserving that's just very good because you can take very long time steps, and that enables you to go around the contours of the probability distribution.
1046570	1050786	135	B	0.99556	So what you want to do next is to change contours.
1050818	1057530	136	B	0.99949	You want to go to contours that are of high probability, contours of lower probability.
1058110	1068830	137	B	1	And you want to do so in a way that the contours of high probability are sampled much more and much more often than the contours of lower probability.
1070610	1081010	138	B	0.97888	So what you do is that you augment your Hamiltonian dynamic with what people call a velocity refreshment or a momentum refreshment.
1081430	1084660	139	B	0.99	And so this is how it works.
1085990	1103910	140	B	0.84788	So you're going to simulate your Hamiltonian dynamics for some time, and then after a while, you're going to be like, okay, well, now I'm going to change the velocity at random by just drawing a new velocity from a Gaussian distribution.
1104430	1111020	141	B	0.63	And so by drawing a new velocity from a Gaussian distribution, you're just going to change contour completely.
1112110	1129910	142	B	0.84	And then there's what's called the constraint that I just talked about, which is you want to change contours of the probability distribution in such a way that contours of high probability are visited much more often than contours of low probability.
1130010	1131394	143	B	0.95406	So you want to preserve that.
1131432	1135474	144	B	0.99966	You want to do that in a way.
1135672	1142546	145	B	0.83117	So the third ingredient of Hamiltonian Monte Carlo comes in, which is metropolis.
1142578	1143490	146	B	0.92094	Hastings.
1143650	1150486	147	B	0.92	And so Metropolis Hastings is this accept reject that we discussed briefly last time.
1150668	1168970	148	B	0.31	And so Metropolis Hastings is just super clever and it enables you to say it just tells you whether this momentum refreshing step is actually a good one or a bad one and should be rejected.
1170670	1182222	149	B	0.87	A momentum refreshment is good if overall your sampling is going to remain faithful to the target distribution, but it is bad if it remains unfaithful.
1182366	1197826	150	B	0.99674	So actually running this metropolitate things except rejects, that allows you to change contours of the property distribution in a way that remains faithful to the target distribution.
1198018	1199926	151	B	0.6	And so there you go.
1200108	1202402	152	B	0.72313	That's basically Hamiltonian Monte Carlo.
1202466	1207750	153	B	0.99883	So to recap, you a mental state space by adding velocities.
1208650	1225230	154	B	0.99987	This allows you to build the Hamiltonian by declaring that the original probability distribution gives you potential energy and you add a kinetic energy on the velocities, which is just velocity squared.
1225730	1235662	155	B	0.99999	Because you have a Hamiltonian, you can use geometric integration to simulate Hamiltonian dynamics very accurately and with very long time steps.
1235806	1242226	156	B	0.96	The very long time steps is a crucial thing because it means that with very low computational costs, you can sample very far.
1242328	1251190	157	B	0.80478	So it means that you don't get stuck in a region of the probability distribution, but you can actually visit it much more fast and efficiently.
1251850	1253400	158	B	0.72402	So that's the first part.
1254570	1260182	159	B	1	The problem with those dynamics again, is that they remain on the contour of the probability distribution.
1260246	1263174	160	B	0.99	And so you want to sample the whole probability distribution.
1263302	1283342	161	B	0.98955	So what you do is every once in a while, and I think that's a hyper parameter in your, in your sampling algorithm, let's say every ten iterations of the Hamiltonian dynamic, every ten time steps of the Hamiltonian dynamic, you're going to sample you're, you're just going to randomly take a new velocity.
1283486	1288050	162	B	0.99332	So you're going to change contour in the probability distribution.
1288630	1298840	163	B	0.99	And the crucial point there is you want to change contour in a way that's faithful of the probability distribution and that's faithful of the sampling problem that you want to do.
1299530	1314810	164	B	0.99886	There comes the last thing, which is Metropolis Hastings, which ensures that the momentum reflect freshman will be good for sampling, I mean, will preserve your target probability distribution.
1315550	1322170	165	B	0.98406	So with that, you just get a very efficient sampling algorithm.
1322250	1324560	166	B	0.94	And so it seems a bit convoluted, right?
1325650	1330500	167	B	0.71	And one bottleneck, of course, is that you need to double the dimension of the state space.
1331430	1336062	168	B	1	And if your state space is already extremely large, that could be a bottleneck.
1336206	1343762	169	B	0.74	It could be the case that actually doubling the dimension to add velocities, it could be a computational bottleneck.
1343826	1350200	170	B	0.99988	So that's a problem, but still, in most cases, that's not a problem.
1352730	1355702	171	B	0.99736	Again, Hamilton in Monte Carlo is convoluted.
1355766	1369138	172	B	0.99679	But the overall take home message I would want you to take from this is that it is a method that remains faithful to the probability distribution they want to sample.
1369174	1370270	173	B	1	And this is crucial.
1370930	1380030	174	B	0.85	And it is also a method that through geometric integration, it enables you to take time steps that are very long and still get accurate sampling.
1380690	1383760	175	B	0.79298	So this is the really cool thing.
1384530	1411850	176	B	0.72995	If you could come up with a whole bunch of other methods that did not require to double the dimension of the state space or that didn't use geometric integration, the problem that you would probably run into is that the thing that you came up with when you implemented in the computer, it doesn't exactly preserve the probability distribution that you want to sample.
1412350	1417590	177	B	0.9	And so the problem with that is that this would lead to biased sampling.
1417750	1431250	178	B	0.98	And biased sampling is like you're going to sample a different probability distribution, which might be just a bit different, but still a different probability distribution than what you really want to sample.
1431750	1435166	179	B	0.85	And this would bias your predictions.
1435358	1445480	180	B	0.99454	So the really cool thing of Hamiltonia Monte Carlo is that you're actually able to have unbiased sampling through the Metropolis Hastings step.
1448010	1449414	181	B	1	And this is a crucial thing.
1449452	1460966	182	B	0.99942	So it's computationally implementable in general, there's no computational bottlenecks apart from this doubling of state space, and it leads to unbiased sampling.
1461158	1462698	183	B	0.83849	It's also relatively simple.
1462784	1465660	184	B	0.99933	So this is why this is really used all over the place.
1467970	1473280	185	B	0.86355	There's another few perspectives that might explain why it works so well.
1474130	1494390	186	B	0.5764	So in the paper in the last subsection of section two, which is about optimization, so the action on optimization is about how to accelerate optimization, how to derive an optimization algorithm.
1495610	1496614	187	B	0.97	2.6.
1496732	1497558	188	B	0.49805	That's the one.
1497644	1506794	189	B	0.92766	So the whole thing about section two is about deriving an optimization algorithm that accelerated in a physical way.
1506912	1527134	190	B	0.81	And by accelerated, what I mean by accelerated, it's not about just going faster, but it's about having acceleration, which means that if you go slightly up in the paper on the figure, I think this figure is great.
1527172	1532498	191	B	0.99	And by the way, I wasn't the one who came up with this figure, but I think this figure is great.
1532584	1537186	192	B	0.66	It really gives a lot of intuition for what acceleration really is.
1537368	1551960	193	B	0.95763	So if you look at the green cup, or I know how you call this, the green well on the left, this would be like a bowl rolling down the well.
1552810	1556746	194	B	0.88	And the well is still that honey to like a certain level.
1556928	1559302	195	B	0.73	And so there you get a lot of friction.
1559446	1568860	196	B	0.99809	So your ball would just roll down very slowly, and the speed of the ball would be proportionate to the slope of the well.
1570530	1573978	197	B	0.90264	So this is not accelerated because there's a lot of friction.
1574074	1578174	198	B	0.5	And so the speed is just proportional to the slope of the well.
1578292	1581120	199	B	0.50732	So this is actually what gradient descend does.
1581830	1592350	200	B	0.89283	But now if you go on the right, you get what people coin physics on under the hand system, which is also an accelerated system, a system that's meaningfully accelerated.
1592510	1607126	201	B	0.90115	So if you replace the honey in the well by some water, then there's going to be way less friction and your bowl is actually going to accelerate and overshoot the minimum of the well and then sort of stabilize.
1607238	1614570	202	B	0.66507	But the point here is that this bulb is just going to get so much faster to the minimum.
1622370	1626430	203	B	0.99963	This idea for optimization is just extremely powerful.
1627330	1635646	204	B	0.99	And by the way, on the right hand side in the graph, you can see the improvements that you get when you implement these sort of ideas.
1635758	1639886	205	B	0.72584	So this was on a I'll come back to sampling in a bit, I promise.
1639918	1642690	206	B	0.51494	But this is actually very well, very related.
1644010	1662860	207	B	0.9999	You can see on the graph on the right what kind of improvements you get when you go from under damp, first order system grade in the sense system, when you go from an over damped first order grade in the sense system to an underdamp second order accelerated system.
1663470	1665420	208	B	0.84	And so you can see the curve, right?
1666110	1670370	209	B	0.97955	So the black orange curve is over damp.
1670470	1671738	210	B	0.8499	There's no acceleration.
1671834	1673150	211	B	0.95635	It's very slow.
1674050	1680314	212	B	0.74	The last curve, the blue one, it's accelerated and it's just super fast.
1680452	1692260	213	B	0.84258	So you can see it sort of gives you like quantitative data as to how many improvements you can get by implementing this acceleration in a physically meaningful way.
1693690	1699320	214	A	0.63189	Could you just describe the axes of the graph and also what the league group is here?
1701130	1705014	215	B	0.81	The lead group is in the figure legend.
1705062	1708410	216	B	0.99982	In the fourth line, you see the leg group is so n.
1708560	1716060	217	B	0.64838	So that's technically that's the special orthogonal group of dimensions n.
1716830	1726782	218	B	0.70783	If I remember correctly, these are all the matrices, all the square matrices of size n by n that have a determinant equal to one.
1726916	1734020	219	B	0.99844	So the determinant is just like a function where you give it a matrix and it gives you a number.
1734630	1754200	220	B	0.65	The fact that the fact that the determinant is equal to one means that here we're just taking matrices which are, which produce not translations, but changes of coordinates that preserve the geometry in a system.
1756910	1765450	221	B	0.99933	Just to elaborate on this a little bit, because for people who are not intimately familiar with matrices, it might seem a little opaque.
1765870	1771610	222	B	0.97673	So when you have a matrix, a matrix can multiply vectors.
1771770	1781250	223	B	0.99859	So a square matrix takes in vectors of side of dimension n and it outputs vectors of dimension n by multiplication.
1782150	1797590	224	B	0.98405	So if you have a square matrix, it just induces a transformation of your state space because each vector, each point which is a vector, gets converted into another point which is another vector.
1798170	1804594	225	B	0.48	Now there's a lot of, I guess, properties there, right?
1804652	1813866	226	B	0.99839	You could have all sorts of translations of state space or rotations in state space or transformations of state space.
1814048	1825786	227	B	0.99969	If the determinant of the matrix is equal to one, it means that the transformation of state space that the matrix induces will preserve the geometry of the sixes.
1825818	1833058	228	B	0.87	It will preserve distances and it will preserve crucially orientation as well.
1833224	1847282	229	B	0.99947	Because if you only asked the determinant to be equal to one or minus one, then the matrix transformation would preserve the geometry, but it would not preserve the orientation.
1847346	1849240	230	B	1	It could mirror things.
1850810	1862346	231	B	0.99658	So if you only asked the determinant to be equal to one or minus one, you would get a lead group that's called the orthogonal group, which is usually denoted O of N.
1862528	1867982	232	B	0.92	And here we require the determinant to be just equal to one.
1868036	1870974	233	B	1	And so you get the special orthogonal group.
1871092	1874560	234	B	0.96	And so it's this group of matrices that have this property.
1875090	1890370	235	B	0.96	Now this is not really important for the example here because you could have taken any other lead group and got something similar and got a similar difference in performance.
1893750	1896630	236	B	0.92	I guess it's just interesting for its own sake.
1897210	1900930	237	B	0.97	And so the graph though, the K is the number of iterations.
1901010	1910010	238	B	0.9259	So the number of time steps, so that's the x axis and the y axis is how close you are from the minimum.
1910670	1912646	239	B	0.97	And, and it's in lock scale.
1912758	1925162	240	B	0.9925	So as you can see, the, the blue curve is going to get like in 100 iterations, it's going to get basically at ten to the minus 410 to the minus five distance from the minimum.
1925306	1926942	241	B	0.93198	So it's like super, super close.
1926996	1936660	242	B	0.97	It basically gets there in 100 iterations when you take the other normal gradient descent methods where you see that it's going to take so much longer.
1939030	1943474	243	B	0.98024	So yeah, this is really the advantage of using second order methods.
1943522	1953874	244	B	1	And what I mean by second order methods is that by second order means that you actually double the state space to introduce velocities.
1954002	1960870	245	B	0.99988	So that you not only have a dynamical system over positions, but you have a dynamical system of velocities.
1961030	1971390	246	B	0.5	And so it means that you have a physical notion of acceleration because acceleration is a movement of velocities.
1972290	1986690	247	B	0.59	And so if you double the state space by saying this is position, this is velocities, and you see I have a motion in this like a state space that's twice as big, then you have a meaningfully, a meaningful notion of acceleration.
1987510	1989054	248	B	1	And this is really powerful.
1989182	2006250	249	B	0.95	And so you can see already a parallel here, which is that Hamiltonia Monte Carlo also has this notion of acceleration in some way, at least just intuitively, because we also doubled the size of the state space to introduce velocities.
2006590	2012970	250	B	0.85	And so it turns out that this intuition is actually you can make it into a formal correspondence.
2014190	2019120	251	B	1	And I think this is something that quite interests me, to be honest.
2020210	2025914	252	B	0.96043	So if you remember, if we come back to the intuition for sampling.
2026042	2031502	253	B	1	The intuition for sampling through Monte Carlo methods is we have a target distribution that we want to sample from.
2031636	2037438	254	B	0.99183	So we're going to run a dynamic, random dynamic towards that distribution.
2037614	2051458	255	B	0.77	Now, what makes sampling efficient is that the distribution that characterizes the process because again the process is random so that each time it is at a random location that is characterized by distribution.
2051634	2060220	256	B	0.99995	What makes sampling efficient is that the distribution characterizing the process just converted as fast as possible to the thing that you want to sample from.
2063630	2070554	257	B	0.90082	This is to say that you can think of sampling as an optimization on the space of probability distributions.
2070682	2076830	258	B	0.99995	You want to move your probability distribution of the process as fast as possible to your target.
2077570	2084610	259	B	1	And so you can see from there that sampling is actually not so different from variational inference.
2086310	2090334	260	B	0.89296	It's just the same idea, only variational inference.
2090382	2105690	261	B	0.70174	You're typically going to take a parameterized family of distributions and approximate the targets, while here you have a non parameterized family that's given by your dynamic that's going to perfectly match the target.
2108670	2125280	262	B	0.91113	Again, with that, I want you to have the take home message that sampling, you can think about it as an optimization on the space of probability distributions in the sense that you have a target distribution and you want to get there as fast as you can with the process.
2125890	2137220	263	B	0.99	Now let's suppose, and so here is the crucial connection between sampling and optimization in the way that we've described it here.
2137990	2149478	264	B	0.73448	Let's suppose that you run this accelerated optimization scheme on the space of probability distributions then the process.
2149644	2162300	265	B	0.78929	So you would get the dynamic on the space of probability distributions that has a meaningful notion of acceleration through the accelerated method that was shown here.
2162910	2177230	266	B	0.96655	So if you look at what kind of dynamic this really gives you, it gives you a process which is given by a stochastic differential equation that is known as under damp launch of a dynamic.
2178130	2182898	267	B	0.9843	So there's an equation for it and I think action subsection 2.8.
2183064	2197670	268	B	0.69941	But the point is under dynamics is a stochastic differential equation whose density or probability distribution stole this accelerated optimulation problem on the space of probability distributions.
2198250	2210940	269	B	0.99552	So just from there, you know that under that logo on dynamics, it's going to be a very efficient sampler because it meaningfully accelerates and gets the target, I mean, quite fast.
2211790	2218886	270	B	1	The problem is under label logo on dynamics, you cannot simulate it accurately.
2219078	2224362	271	B	0.76788	Well, you can simulate it accurately, but you cannot simulate it exactly on your computer in practice.
2224506	2230160	272	B	0.7784	So this comes back to the numerical integration problem that we discussed just before.
2232390	2250390	273	B	0.95	And so you have to find a way to discretize or in other words implement under dumpling bound dynamics on your computer in such a way that you retain that the thing that you implemented on the computer retains this meaningful notion of acceleration.
2251290	2251906	274	B	1	It turns.
2251938	2273470	275	B	0.95	Out that you can see Hamiltonian Monte Carlo as a faithful numerical discretion or numerical implementation of under damp launcher and dynamics that's going to preserve these acceleration properties and therefore this efficient sampling.
2274050	2279146	276	B	0.94863	So this is all like, yeah, a lot of interesting connections.
2279338	2288158	277	B	0.9873	But basically what I want to get at is you really have this notion of acceleration that permeates well, I guess physics.
2288254	2292446	278	B	0.99987	But here it permeates sampling and it permeates optimization.
2292638	2301302	279	B	1	And so the method that was shown here about optimization and Hamiltonian Monte Carlo, they're just the same in a way.
2301356	2310330	280	B	0.94976	Only one is applied to optimization, the other is applied to optimization on probability distributions of Aka sampling.
2312590	2313050	281	B	0.9967	Great.
2313120	2315162	282	A	1	I guess last question on this part.
2315216	2319040	283	A	0.99994	What is the shadow Hamiltonian and why does it sound so cool?
2320370	2321310	284	B	0.79	I know, right?
2321380	2323360	285	B	0.96992	Yeah, it's really cool.
2324130	2325358	286	B	0.80278	It's a recall name.
2325444	2333150	287	B	0.94711	So the shadow of Hamiltonian is okay, so let's go back to the Hamiltonian.
2333970	2338894	288	B	0.91615	So we have a Hamiltonian, and we want to simulate the dynamic that preserve the Hamiltonian.
2338942	2340900	289	B	0.99987	We want to implement that on the computer.
2341270	2344070	290	B	0.9963	We're going to do that through geometric integration.
2344650	2350258	291	B	0.98633	Geometric integration gives you a bunch of algorithms to preserve the Hamiltonian.
2350354	2356570	292	B	0.88	I mean, a bunch of algorithms they can implement on the computer, and they're going to preserve the Hamiltonian.
2357470	2360550	293	B	0.99	Do they actually really preserve the Hamiltonian?
2360710	2362378	294	B	1	It turns out that no.
2362464	2394200	295	B	0.96736	So what I said before is a bit of a shortcut, because the numerical integration that you get through any numerical method, including geometric integration, is not going to exactly preserve the Hamiltonian, but it's going to preserve what people call a shadow hamiltonian, which is almost the same as the Hamiltonian, but with extra terms that sort of vanish if the time step is very short.
2396170	2412170	296	B	0.97107	So this is to say that your numerical dynamic implemented through geometric integration is going to exactly preserve the shadow Hamiltonian and approximately preserve the true Hamiltonian.
2413790	2430410	297	B	0.98854	In the papers, we show I don't know if it's well, it's probably algorithm dependent, but basically, depending on the algorithm that you choose, you want to show to what extent the shadow Hamiltonian truly approximates the true Hamiltonian.
2430570	2447070	298	B	0.61	The virtue of geometric integration methods is that actually the shadow Hamiltonian turns out to be extremely close to true Hamiltonian, which dean that you can take a very long time steps and still be very good at preserving the true Hamiltonian.
2447230	2457434	299	B	0.96435	So here, when you implement these methods, you don't exactly preserve the true Hamiltonian, but you still do it pretty well.
2457552	2477786	300	B	1	And so in Hamiltonian Monte Carlo, the momentum refreshment, and Metropolis, usually the Metropolis Hastings accept rejects that is going to correct for those failures of truly preserving the Hamiltonian.
2477898	2493410	301	B	0.9915	So even though you don't exactly preserve the Hamiltonian in your numerical integration, in Hamiltonian Monte Carlo, the Metropolis hating accept reject step is going to correct for this inaccuracy.
2493570	2507420	302	B	0.99	And so this is like, really the true beauty of Hamiltonian Monte Carlo is that even though you get a lot of things that are not exactly preserved when you implement things on a computer.
2508190	2520090	303	B	0.99997	Thanks to Metropolitan Hastings, overall your sampling is going to be perfect in the sense that you're going to truly preserve your target distribution.
2520250	2521920	304	B	0.99763	So this is really the key.
2523170	2539186	305	B	1	Now, a follow up question to that is, okay, well, if Metropolis Hastings is just so crucial and it just gives your dynamic the property that it's going to preserve, whatever it does, even if it samples really badly if?
2539208	2545282	306	B	0.99839	You add Metropolis Hastings, it's still going to preserve your Target distribution.
2545426	2550598	307	B	0.65458	Then why can't You Just Come up with an average process, like whatever Kind Of process?
2550764	2553480	308	B	1	And that Metropolis Hastings at the end?
2553850	2555770	309	B	0.58	And so you can do that.
2555840	2558220	310	B	0.99989	You can take any kind of process.
2563790	2566922	311	B	0.89657	Let's say you take a random process, it could be the worst in the world.
2566976	2572474	312	B	0.93791	Let's say you wanted to sample from a gaussian and you actually take a Brown in motion.
2572602	2577054	313	B	0.77	Now this is clearly not going to work because Brown Emotion just goes all over the place.
2577092	2578414	314	B	0.65	It could go infinitely far.
2578452	2581922	315	B	0.76237	Brown in motion, it's just like random action, right?
2582056	2583570	316	B	0.99677	Completely random motion.
2584950	2596582	317	B	0.84885	There is structure to it, but the structure in Brown in Motion means that it's such that brown in motion is just going to just spread really far.
2596716	2603414	318	B	0.9804	So Brown in motion is not going to preserve your target distribution and it's also going to be very slow, by the way.
2603452	2614374	319	B	0.99223	So it's not going to be a good sampler if you add Metropolis Hastings on Brown emotion, which is you integrate brand action.
2614422	2624318	320	B	0.99515	So you simulate a step of brand emotion on the computer and then you do Metropolis Hastings to know whether you should accept or reject that step.
2624484	2627630	321	B	0.57526	Metropolis Hastings will tell you whether you should do it or not.
2627780	2639230	322	B	0.99809	You either accept and you keep going from that new position, or you reject and you start from where you started from and take a new sample.
2639310	2640302	323	B	0.54183	Accept, reject.
2640446	2641970	324	B	0.89681	If you accept, you keep going.
2642040	2645442	325	B	0.72049	If you reject, you go back and you sort of go like that.
2645576	2650198	326	B	0.99239	So if you do materially facing there, your standard is going to be exact.
2650284	2655900	327	B	0.99987	So it is going to preserve the target and so you're going to have accurate sound plan.
2657550	2658822	328	B	0.96	And so this is crucial.
2658886	2662966	329	B	0.94182	This really highlights the importance of Metropolis Hastings.
2663158	2671250	330	B	0.95788	But there is a big but your sampler here is going to be extremely slow.
2671430	2679514	331	B	0.72487	It's going to be extremely slow, first of all, because brand in action in and of itself, it doesn't at all preserve the target distribution.
2679562	2681102	332	B	0.82	I mean, it just goes all over the place.
2681156	2686260	333	B	1	And you just want to sample a lot around the mode of the gaussian, for example.
2686630	2699910	334	B	0.98951	So it means that Metropolis hasting will reject a lot of your steps because a lot of your steps will try to go further away while you want to stay around the mode typically of the gapsin.
2700810	2712650	335	B	0.99757	So you're going to do a lot of steps for nothing and also Brown in Motion just does not have the qualities that make a sampler efficient.
2713310	2731390	336	B	0.74	And so the reason why Hamiltonian Monte Carlo is so good is because it's able to integrate Metropolis Hastings and still preserve a lot of other properties that make the sampler efficient.
2731730	2747346	337	B	0.99625	So if we remember, HamiltonI Monte Carlo has this geometric integration that does not exactly preserve the Hamiltonian, but it does still does it pretty well approximately by preserving a shadow Hamiltonian.
2747458	2751334	338	B	0.8818	So this means already that integration step is going to be really good.
2751372	2767718	339	B	0.95859	So there's going to be a lot of acceptance in the Metropolis Hastings and also the way the scheme is set up, there's going to be a lot of acceptance set in the Metropolis Hastings.
2767734	2775630	340	B	0.98728	So it means that most of the samples that you would draw will actually be used instead of being rejected and you have to start over again.
2775780	2777310	341	B	0.87783	That's one advantage.
2778370	2792610	342	B	1	The other advantage of Hamiltonium and T Carlo, and this is a crucial one and we kind of discussed this last week, is that one crucial thing to be a good sampler is this idea of time irreversibility.
2793350	2801320	343	B	0.70837	So I'll emphasize it again because it's really crucial and there's a lot of literature on this and it's something that we reviewed also in the paper.
2801850	2816262	344	B	0.97843	So a sampler that is time reversible that is time irreversible is always going to be better or it's at least not going to be worse than a sampler that is time reversible.
2816406	2818254	345	B	0.99922	So what do we mean by this?
2818452	2820750	346	B	0.62	A sample is time irreversible?
2822050	2834754	347	B	0.66377	If and on the if were you to play the dynamics forward or backward, there will be going on your bullet point here.
2834872	2849430	348	B	0.62	A sample is time reversible if and on the if you were to play the dynamics forward or backward in time, so forward in time and then maybe you would play them by reversing the movie by playing the movie backwards.
2850250	2862794	349	B	0.99998	If you were to do that, then the two movies that you would see would be qualitatively the same and statistically the same.
2862992	2870974	350	B	0.89376	So the process is time reversible if and only if the process, if you're running forward or backward, it's basically statistically the same.
2871172	2873290	351	B	1	Now, what does this mean in practice?
2873370	2879440	352	B	0.99948	Well, if your process is time reversible, then it's going to backtrack very often, actually.
2881110	2897094	353	B	0.98342	So it means that you would be somewhere in the probability distribution, just something there and you will go forward and then you probably go backward and so on and you kind of get stuck in a region until you go somewhere else.
2897132	2910310	354	B	0.99385	But it's just going to be very slow to move around and so it's going to be very slow to get good sampling because it's going to take you a long time to visit all the regions of the probate distribution.
2910470	2913660	355	B	0.99999	In other words, the distribution characterizing the process.
2914270	2919840	356	B	0.83883	It's going to move very slowly to the target distribution that's another way to look at it.
2921410	2929982	357	B	0.99927	If the process is time irreversible, on the other hand, then it's a lot less likely to go backward during the sampling process.
2930116	2934754	358	B	0.85785	So it means that it's going to visit the target distribution a lot more.
2934792	2936450	359	B	0.95	I mean, it's just going to go around.
2936600	2947190	360	B	0.9997	Imagine if you're not allowed to go backward just as a human being and you're walking around, you're just going to end up in many more places than if you were allowed to go backward.
2948570	2956950	361	B	0.82	And if you were just going backward all the time to where you started, then you wouldn't be able to do a lot of visiting.
2957030	2958790	362	B	0.96769	So it would be a bad sampler.
2958950	2963980	363	B	0.51692	So again, there's some, like straightforward intuition there.
2964510	2974474	364	B	0.96175	So one idea is in sampling is we want to optimize the extent to which a sampler is timely reversible.
2974522	2982334	365	B	0.99993	We want to increase time irreversibility as much as we can force a sampler to just move around as much as possible.
2982532	2983920	366	B	0.9685	So that's an idea.
2984850	2986578	367	B	0.61	It is explored currently.
2986664	2996710	368	B	1	I guess it's a bit of an open problem of how do you really do that and how do you implement that on the computer in a way that works and preserves all the properties.
2997690	3006886	369	B	0.99778	But the point I wanted to get to is that Metropolis Hastings is a blessing and it's also a curse.
3007078	3014310	370	B	1	It is a blessing because when you add it to any kind of process, you will make your sampling unbiased.
3014390	3021182	371	B	0.92941	So it means that you will sample the Ride distribution even though you're implementing this on a computer.
3021316	3030160	372	B	1	And there can be a lot, so many issues with the numerical integration, numerical approximation and so on.
3030790	3041650	373	B	0.69749	But it's also a curse because whenever you add Metropolis Hastings on the process, it's going to make it time reversible.
3045110	3056170	374	B	0.55574	Actually, yeah, if you just took a random process and added metropolisA, you would get something that's inevitably going to be quite slow.
3057150	3061370	375	B	0.9	And so now you get to the problem or the conundrum.
3061710	3062940	376	B	0.99149	What do I do?
3063390	3065126	377	B	0.98	Do I go for unbiased sampling?
3065158	3066730	378	B	1	Do I care about accuracy?
3068370	3071130	379	B	0.94	And then I should add Metropolis Hastings.
3071290	3081730	380	B	0.71	Or do I not care about accuracy so much and then I should not have Metropolis Hastings and it's going to go faster generally.
3083750	3089790	381	B	0.53	And so Hamiltonia Monte Carlo actually has the blessing and does not have the curse.
3089950	3093560	382	B	0.99	And this is why Hamiltonian Monte Carlo is just so good.
3094730	3101362	383	B	1	And again, it's also complementary to all of the things that we've been discussing.
3101506	3111882	384	B	0.98	And the reason why Hamiltonian Monte Carlo is blessed and not cursed is because the momentum, how do you call this?
3112016	3121210	385	B	0.74	The Metropolis Hastings is just done on the momentum refreshment step as opposed to being done on the overall dynamic.
3121550	3140530	386	B	0.55568	So because if you remember, you do geometric integration to simulate Hamiltonian dynamics, every once in a while you will take a momentum refreshment and then do Metropolis Hastings on that momentum refreshment, as opposed to doing Metropolis Hastings on both the Hamiltonian dynamic and the momentum refreshment.
3142010	3169446	387	B	0.9983	So it's not something that I can really explain how that works, but it turns out that by just doing the Metropolis method, montacarlo is a way of having Metropolis Hastings in a way that you preserve the unbiasedness so that your sampling is accurate, but you don't sacrifice the time irreversibility.
3169638	3171020	388	B	0.95	And so you get both.
3173950	3179280	389	B	0.92	And this is because the Metropolis hasting is just on one of the components and not on both.
3181030	3183634	390	A	0.95	To kind of connect that to an example.
3183752	3201522	391	A	0.99991	As we move into active inference here, we have some probability isocontours, some, we have the high probability carpool lane, and then we have some lower probability lanes, and we can go different speeds in these lanes.
3201666	3206140	392	A	0.89	And we want to have a full accelerated model here.
3206750	3213926	393	A	0.90424	It's almost like the MH is refreshing our velocity just asking when we want to change the lanes.
3214038	3219818	394	A	0.99967	But it's not our full self driving car Metropolis Hastings algorithm.
3219994	3232258	395	A	0.88483	But we're able to use our position and acceleration when we're in our lane to take full advantage of the acceleration following the shadow road.
3232424	3240340	396	A	0.99999	Not necessarily the true road, but the shadow road is close enough, or the shadows on the road, and then lane changes.
3240870	3250710	397	A	0.9995	Are these computationally costly and reversible, but still super useful propositions?
3252250	3253000	398	B	0.99995	Exactly.
3253610	3257366	399	B	0.91	And they're actually not computationally costly.
3257478	3261130	400	B	0.99962	They would be if you were to reject many samples.
3261630	3267186	401	B	0.99995	But here in Hamiltonian Monte Carto, typically you don't get to reject many samples.
3267318	3271994	402	B	0.77345	So yeah, that's such a great picture.
3272042	3278586	403	B	0.84317	So the car follows the Shadow Road by just doing geometric integration and following the shadow.
3278618	3282394	404	B	0.84548	Hamiltonian every once in a while, you get a momentum refreshment.
3282522	3288770	405	B	0.30691	Velocity refreshment, which is, oh, now I move to the first lane, or the second lane, third lane, and so on.
3288920	3299334	406	B	1	And you get a Metropolis Hastings Corrections step that says, do I accept this proposal of lane change or do I reject it?
3299372	3300790	407	B	0.95	And still on the coast.
3301610	3305430	408	A	0.95901	So how does this connect active inference lab?
3306810	3308998	409	B	0.99403	Well, I mean, great question.
3309164	3317270	410	B	0.66738	So active imprints in active inference proper, you don't have any sampling in active imprints.
3317430	3331406	411	B	0.9897	Whenever you want to scale active inference to implement it, to solve any kind of problem in the world, you want to do sampling because there's a lot of computations that are not going to be trackable otherwise.
3331598	3339010	412	B	0.68	And so one cool example is in the figure after this, actually.
3339080	3350600	413	B	0.96232	So for any kind of decision making active inference lab, you need to approximate the expected free energy.
3353130	3357020	414	B	0.99	The one just before yeah, perfect.
3358830	3368954	415	B	0.98956	So if you look at the second equation there, you get this minus lock p of an action sequence equals expectation of something.
3369152	3376080	416	B	0.99931	This minus lock p of the action sequence is our notation in this paper for the expected free energy.
3380530	3386820	417	B	0.9991	You probably all know this, the expected free energy is given by the expectation of something.
3387590	3399910	418	B	1	Now typically, and when you have a very high dimensional model, which happens in most applications, I would say you get a very high dimensional expectation.
3400410	3401650	419	B	0.99966	What is an expectation?
3401730	3406330	420	B	0.98309	An expectation is an integral with respect to probability distribution.
3406670	3410202	421	B	0.65908	How do you compute expectations while you do that?
3410256	3418202	422	B	0.99997	Through sampling, or at least sampling is the way to compute high dimensional expectations.
3418266	3420458	423	B	0.90831	That's the most efficient in statistics.
3420634	3428078	424	B	0.98	And this is the reason why sampling is studied in statistics, is because that's how you solve these problems.
3428164	3440846	425	B	0.77	I mean, expectations just come up everywhere, just like so many things about machine learning bowl down to computing expectations.
3441038	3453942	426	B	0.99	And so here in particular, the expectation that is very dear to us, very close to our hearts, is the one that gives you the expected free energy.
3453996	3456730	427	B	0.98	The expected is the expectation of something.
3456880	3462780	428	B	0.99063	So how do you compute that in a high dimensional model where you have to use something?
3465150	3470010	429	B	0.99969	There comes the usefulness of Hamiltonian Monte Carlo.
3470350	3479870	430	B	0.99997	If you have a discrete state space based model, you're not going to be able to use Hamiltonian Monte Carlo because Hamiltonian Monte Carlo is on continuous states based models.
3480870	3482674	431	B	0.85012	It's on continuous state space, right?
3482712	3485534	432	B	0.99996	We talked about continuous positions, continuous velocity.
3485662	3492002	433	B	1	I talked about something a probability distribution on my desk, which is a continuous state space.
3492136	3501542	434	B	0.98028	So you're not going to be able to use Hamiltonian Monte Carlo if you have partially observed mark of decision process and you're doing active inference there.
3501676	3527418	435	B	0.79027	But if you have for example, I've been talking recently to Ryan Smith, who does a lot of active inference, and he's really leading a lot of the modeling work with active inference and real data of patients of all sorts, many medical data, and also using active inference to model psychological experiments.
3527594	3538180	436	B	1	And one of the things he told me about well is, okay, well, I have a bunch of data, and partially observed markup decision process is just not going to do it.
3538790	3540274	437	B	0.99375	Why is he not going to do it?
3540312	3544710	438	B	0.99999	Because the data that he has lives on a continuous space.
3544860	3562650	439	B	0.97	I don't remember exactly what it was, but let's just say, for the sake of example, that that data was the temperature in the room, and the subjects had to infer the temperature in the room based on their sensations.
3563310	3565660	440	B	0.9971	So that's a continuous state space problem.
3566110	3572942	441	B	0.99	Now, imagine that you ask someone to infer the temperature in the room.
3573076	3577598	442	B	0.60447	Then maybe you would change the temperature in the room or not, and you would ask them again.
3577684	3580640	443	B	0.91316	Change the temperature or not and ask them again, and so on.
3581330	3594680	444	B	0.99829	When you have this sort of set up, you have a discrete you have a phenomenon that unfolds in discrete time because you just repeatedly ask some questions and sometimes elapses between the questions.
3597050	3600226	445	B	0.99765	But you also have a state space that's continuous.
3600418	3612694	446	B	0.69071	When you have this sort of data, then the kind of model that you want to use is a partially observed mark of decision process that we know and love but the state space is going to be continuous instead of discrete.
3612742	3615050	447	B	1	The planet is still going to be discreet.
3616030	3638158	448	B	1	Now, when you have this sort of model, I just want to say it or as an aside, that for the moment, a lot of the modeling work and simulation work in Active inference uses the sweet state space pound DPS, partially observed mark of the same process just because it's been sufficient.
3638254	3649570	449	B	1	And when you simulate agent is often like in grid worlds and when you maybe have a state spaces in experiments they often by design discrete because it's just easier to handle.
3649730	3659882	450	B	0.99892	But that's not something, that's not an assumption, a simplifying assumption that we're going to be able to keep for that much longer.
3660016	3663846	451	B	0.40815	There's just so many things that you cannot account with these sort of models.
3663958	3673040	452	B	0.94529	So one other model that is interesting to have is partially observed Markov decision process, but with a continuous state space.
3673650	3688722	453	B	0.92197	So with those you get the problem of estimating the expected free energy which would be then an expectation or in other words, an integration, an integral in a continuous takes place.
3688856	3694178	454	B	1	And so how do you do that efficiently if you are in a high dimensional state space?
3694264	3695266	455	B	0.86069	Where do you use?
3695288	3696526	456	B	0.49829	Hamilton, monte Carlo.
3696558	3699060	457	B	1	I think this wouldn't be really the best.
3699690	3704390	458	B	0.99045	So this is how you join the dots in this paper.
3704460	3712618	459	B	0.99999	We didn't talk about sampling in discrete space because the methods are quite different.
3712704	3715802	460	B	0.99889	So we really had to choose what to focus on.
3715936	3720750	461	B	0.99414	There's of course a lot more methods in the literature than there are in this paper.
3720820	3726590	462	B	0.99975	We just wanted to sort of review what were the main ones and what people really used in practice.
3728210	3748870	463	B	0.99979	But when you have the expected principal in a discrete state space, computing the expectation that defines the expected priority can often be a little bit easier because it comes down computationally to a bunch of matrix multiplications.
3749850	3757866	464	B	0.96902	Matrix vector multiplications, which generally is doable, unless the state space is enormously high.
3757968	3761580	465	B	1	And then we'd have to think of sampling methods in this sweet space.
3762910	3783262	466	B	0.99989	But as soon as you move to a partially observed markup decision process with a continuous space, which are argu and Ryan Smith argues and I'm sure a lot of people have run into this as soon as you have this kind of model, well, yeah, you just have an integration problem in continuous space.
3783316	3786260	467	B	1	And so Hamiltonium Altekaro is the way to go there.
3788470	3789218	468	A	0.99794	Awesome.
3789384	3798330	469	A	0.82	And your 2020 paper was a synthesis on some of the discrete statespace formalisms of active.
3798350	3818598	470	A	0.98035	So it's very interesting to see how you're now talking about where continuous time, continuous state spaces can come into play and how interesting the Active inference has the capacity to deal with discrete and continuous date spaces.
3818774	3831540	471	A	1	And sometimes we lean on one leg or the other leg more, but it spans the gap in a way that's actually like a value adding, not like there's some sort of missing piece from one side or the other.
3832950	3834242	472	B	0.96219	Yeah, definitely.
3834376	3839380	473	B	0.68	I think active inference is great because it's so flexible in the sort of models that you can consider.
3841270	3848280	474	B	0.93134	But yeah, historically the first models to be developed were continuous space and continuous time.
3848650	3857180	475	B	1	And then it works quite well because you can take gradients of the free energy and just minimize them over time.
3858110	3864140	476	B	0.90429	So you could get around basically everything by doing a grain and assemble free energy.
3864510	3867646	477	B	0.74	And then after that around like so that was like 2010.
3867668	3896130	478	B	0.97	And then around 2015, people started thinking, okay, well, how do I model discrete time decision making with active inference and typically decision making tasks, at least the simple ones that are studied in neuroscience and behavior neuroscience, just to make things simple, the number of actions that you have is discrete.
3896290	3899974	479	B	0.9637	So you have a finite number of actions, which is pretty small.
3900092	3903800	480	B	0.99983	You would also have a finite number of states, which would be pretty small.
3904410	3909340	481	B	0.89	And then people started to think, okay, well, how do we active inference lab to actually account for that?
3910190	3919520	482	B	0.82	And so, yes, and so that's how the whole expectation free energy and partially observed mark of decision processes came into play.
3920770	3927102	483	B	0.67	And now the community has grown a lot and there's more and more data that we want to account for.
3927156	3935550	484	B	0.98287	There's more and more projects that are going on and, you know, people are realizing it's an obvious realization.
3938390	3945922	485	B	0.8978	It's not surprising at all that these two models developed in 2010, 2015.
3946056	3948290	486	B	0.69919	They they're just not going to account for everything.
3948440	3950786	487	B	0.17627	You need to think about other kinds of models.
3950978	3953974	488	B	0.93	It really depends on what kind of data you have at hand.
3954172	3962794	489	B	1	And then one important and obvious type of model would be partially observed Markov decision process with continuous space.
3962992	3965562	490	B	0.96	And actually, this is not a new thing.
3965616	3972078	491	B	0.6	I mean, people have been using these kind of models in reinforcement learning and control for a long time.
3972244	3981454	492	B	0.81	I don't know to what extent they've arrived at practically I mean, they arrived at practically instrumental algorithms.
3981582	3985940	493	B	1	I don't know to what extent they're used, to what extent their state of the art.
3986710	3993640	494	B	0.74828	But the point is, it's something that it's a kind of model that has existed for a long time.
3994170	4004958	495	B	0.94	And so this sampling would be a way to actually practically implement this and scale it when you want to put that within active inference.
4005074	4009100	496	B	0.42673	So I think it's an important thing to think about.
4011390	4012042	497	A	0.99983	Awesome.
4012176	4012522	498	B	0.65863	Yeah.
4012576	4018346	499	A	0.93254	Thomas Parr, also recently in a discussion on the textbook was sharing some timelines.
4018378	4033714	500	A	1	And it's just so interesting how these things have been developing and from continuous through characterization of the discrete, in a sense not culminating, but being synthesized in your 2020 paper.
4033912	4049682	501	A	1	And now there's with an increased emphasis on empirical data, the desire to bring in a lot of these methods that actually help us implement it rather than just think about it, really parsimoniously.
4049826	4060300	502	A	0.96823	So what is your active inference representation in the figure of the running person?
4060910	4069420	503	A	1	And then how do the variables and the processes described in this figure relate to all of this?
4070450	4074538	504	A	1	5 hours of talking about Shadow Hamiltonians.
4074554	4076974	505	B	0.77	And all of this, right?
4077172	4079422	506	B	0.9485	Yeah, that's a broad question.
4079476	4085860	507	B	0.99719	We might need another Daniel to answer that in detail, but just very short.
4087430	4095574	508	B	0.66773	Well, the active inference section was meant to be as complete as possible, even though it was very short.
4095772	4105510	509	B	1	And by completeness I mean that we started by deriving active inference and deriving active inference free energy principle.
4106170	4116214	510	B	0.99961	So this is really what the free energy principle does, even though we weren't able of course, to review the whole free energy principle in like one or two pages.
4116262	4126922	511	B	0.99782	But what we focused on was deriving the expected free energy free energy principle and then from there you get the full active inference algorithm.
4126986	4140786	512	B	0.98948	So full active inference algorithm, I think you just went past it's just below if you go slightly below, I think maybe page 29 or page 30 still, I think next realizing an active agents.
4140968	4149960	513	B	0.72433	So this is the active infrastructure algorithm, like 0.12.3 or something, just from a duration of the expected pre energy.
4151050	4156390	514	B	0.99977	You actually get as a corollary from there, the active imprint algorithm that we know and love.
4156460	4164860	515	B	0.99978	This is actually a more general version than what people use and I'm be excited and I'm actually talking to people to actually implement that.
4165630	4182030	516	B	0.99983	But this is actually the most general version that has been established in the literature and it is more general in a meaningful way in the sense that all the beliefs, all the probability distribution, they are over trajectories or sequences of events.
4184290	4198114	517	B	0.70878	So it means that all the computations, they not only consider events at a particular time in the future, for example, but they consider trajectories of sequences of events.
4198242	4207980	518	B	1	And so this is considering different events at different points in time and their independencies and dependencies between them.
4209950	4236910	519	B	0.94324	So this is just to say that if you would take then this algorithm and you would perform a mini field approximation over time, which is saying that all the things that you see in the future are sort of independent of each other at different points in time, then you would recover what people typically use in the literature, which is easily implementable.
4237070	4255126	520	B	0.63	The point I want to make here is that you can actually not have that limitation and have things that are a bit more complex, that are able to capture more complex relationships in the time series and input that.
4255228	4262220	521	B	0.99696	They may be receiving, like, the kind of sensory data that they may be receiving and the kind of generative models that they would have.
4262990	4266730	522	B	0.97168	So anyway, this is the active inference algorithm, the most general one.
4266880	4272522	523	B	0.97752	We derive that from first principles by deriving the expected community from first principles.
4272666	4277946	524	B	0.93	And so this relates us to that figure that you just showed.
4278058	4288100	525	B	0.98198	So that figure that you showed with S on A is the starting point of the free energy principle described in this paper.
4288470	4308938	526	B	0.98	And so the point is that we want to describe decision making, want to describe actions as a function of sensations, and we want to come up with the most general description of actions as a function of sensations to be able to account for everything.
4309024	4311290	527	B	0.82088	That's kind of the idea of the pre engineer principle.
4312190	4319690	528	B	0.97998	So what do we do is we consider a world, a world in which there is an environment and an agent.
4319840	4325166	529	B	0.64	And so the environment here is denoted by S, and S is a stochastic process.
4325348	4327040	530	B	0.70221	Why a stochastic process?
4328290	4334500	531	B	0.99985	Because a stochastic process is the most general type of dynamic that exists, at least as far as I know.
4335830	4337326	532	B	0.77282	It's really a random dynamic.
4337358	4339394	533	B	1	And it could be random in all sorts of ways.
4339432	4341038	534	B	0.93	It could also be non random.
4341134	4351814	535	B	0.78816	We sort of take the stochastic, the random aspect, as an extra ingredient, just to include a lot more types of scenarios and things you can be confronted with.
4351932	4360378	536	B	0.99276	So you partition the world into the agent, which is O and A, and the environment, which is S, and the agent.
4360464	4365530	537	B	0.99558	Then you subdivide it into two more components, which are O and A.
4365680	4369774	538	B	0.65	O are what we call the observable states.
4369892	4376080	539	B	0.98445	These are like the sensations of the observations that you get at any point in time, also a stochastic process.
4376690	4379838	540	B	0.58	And finally, you have the autonomous states.
4379924	4383058	541	B	0.88	Or you could think about it loosely as the active states.
4383144	4385970	542	B	0.74796	They turn out to be the active states in the implementation.
4386310	4397640	543	B	0.74797	But so the active states, they're really like the muscles, the things you can actually activate and make and then activate to influence the world.
4399290	4408122	544	B	0.91981	So we just partitioned the world into these three sets of states that interact and evolve in some way.
4408176	4411830	545	B	0.49781	They're both stochastic processes that interact.
4411990	4428350	546	B	0.93	And the goal of the community principle, at least when applied to decision making, is that you want to describe A as a function of O, because what happens as an organism, you have control over A, you have access.
4428420	4432062	547	B	1	To O, but you don't have direct control of O over your sensations.
4432206	4437694	548	B	1	And you don't have access to S because that's the environment and beyond the markup.
4437742	4441038	549	B	0.40558	Like it beyond you, beyond your envelope.
4441214	4442642	550	B	0.97117	So you don't have access to S.
4442696	4447750	551	B	0.98814	You know, O and you can control A is what you can choose from.
4447900	4462234	552	B	0.67	And so the free energy principle just answers the question, okay, well, if I take this very general description of the world, what is the equation of A as a function of O?
4462272	4464954	553	B	0.99956	How can I describe A as a function of o?
4465152	4471662	554	B	0.5	And so it turns out there's some mild assumptions in this.
4471716	4483170	555	B	0.59	And these assumptions, they're guided by physical considerations about how humans are and how humans interact with the world, but they're very mild.
4483670	4485154	556	B	0.99911	But whenever you take.
4485192	4493800	557	B	0.99959	These assumptions, you get that the active states or the autonomous states minimize expected free energy.
4495770	4501542	558	B	0.72225	So this is like a very 16th derivation of the expected free energy.
4501596	4504706	559	B	0.99927	From first principles, we start with the partition of the world.
4504828	4508390	560	B	0.53274	We describe active states as a function of observations.
4508550	4514810	561	B	0.69306	As it turns out, that the expected free energy is what describes the active states as a function of observations.
4519330	4535346	562	B	1	The basic active inference algorithm, which everybody uses and which we have also in paper, is about computing the expected free energy and then selecting actions that minimizes expected free energy.
4535528	4540500	563	B	0.46178	So the expected free energy, as we saw, I think it's in the next figure.
4540870	4546120	564	B	0.98412	So the one with all the panels, we've seen it a couple of times already.
4546890	4550920	565	B	0.9335	It's an expectation with posterior distributions in it.
4552410	4564940	566	B	0.52421	What I mean by posterior distributions here is that these are distributions conditioned on the history of the agent, so on the observations that he has already seen and on the action that he has already taken.
4568350	4575230	567	B	0.97083	In any case, the expected free energy is an expectation with posterior distributions within.
4575380	4579038	568	B	0.7919	So it means that to compute the expected free energy, you have two problems.
4579204	4584702	569	B	0.99769	You have computing posterior distribution through Bayes and inference, Bayesian rule.
4584846	4589230	570	B	0.99	And once you have them, you can plug them in into this equation.
4589310	4594674	571	B	0.99	And then you need to complete the the expectation, and then you get the expected free energy.
4594792	4599202	572	B	0.9995	So the first thing is about computing the posterior distributions.
4599346	4606454	573	B	1	Now, what has been proposed in the literature so far is, well, how do you do approximate inference?
4606502	4608646	574	B	0.99996	How do you actually approximate distributions?
4608678	4613740	575	B	0.78032	You do that through variational inference or approximate inference by minimizing free energy.
4615790	4625680	576	B	1	The treatment here, the derivation, and our aim was to do that, provide a derivation that was as conceptually simple as possible.
4626050	4631860	577	B	0.99967	Actually, it highlights that the free energy is not the most important thing here.
4632710	4635234	578	B	1	The important thing is really the expected free energy.
4635352	4641794	579	B	1	The free energy is just a tool to approximate the posterior distributions, to then get the expected free energy.
4641992	4645890	580	B	0.95843	But you could actually use any other type of divergence.
4646330	4650914	581	B	1	The free energy is just like a KL divergence plus some term that makes the whole thing tractable.
4650962	4655750	582	B	1	And so you can minimize the KL divergence to approximate the target distribution.
4656090	4662938	583	B	0.88364	But actually, what this view highlights, and by the way, I'm not at all against the free energy.
4663024	4664540	584	B	1	I think it's really cool.
4665150	4667740	585	B	0.78	And there's so many methods to minimize free energy.
4668510	4671486	586	B	0.99981	If you can do that, then fine and sure, go for it.
4671508	4672622	587	B	0.99393	Like, way to go.
4672756	4674830	588	B	0.5671	But imagine you could not do that.
4674900	4682900	589	B	1	It would not at all be a problem because you could use any other kind of divergence to solve those inference problems.
4684950	4686274	590	B	0.89137	So that would be the first step.
4686312	4695080	591	B	0.9987	You can approximate those particular distributions by doing some kind of approximate inference, which would be through minimization of reenergy or through minimization of something else.
4695690	4699590	592	B	0.53	And then you have the second step, which is computing the expectation.
4699930	4711610	593	B	1	Now, either you're in a low number of states, discrete states from the P like thing and it's all a matter of vector matrix multiplications that are attractable.
4712030	4724960	594	B	0.97528	Either you have a very high number of discrete states and then you need to think about sampling in discrete states, which we didn't discuss in this paper.
4725330	4735300	595	B	0.99929	Either you are in a continuous state space and then you have an expectation in continuous state space and then you want to think about an alternative Monte Carlo, for example.
4736790	4748150	596	B	0.99172	So now with these two steps you have now an estimate of the expected free energy which gives you the quality of any action sequence.
4748730	4758102	597	B	1	And so it's not only the quality, but it's actually the negative Lock probability of any action sequence regarding in this formalism.
4758246	4771950	598	B	0.99998	Because if you remember, the premise of all this was to describe actions as functional sensations in a physical system, not even a physical system, but in interacting stochastic processes.
4774050	4786130	599	B	1	And so the answer to that was well, the expected free energy gives us how actions relate to sensations, the expected free energy.
4786200	4806890	600	B	0.99	And this is why we used the letter, we used minus Lock p as opposed to G to emphasize that the expected free energy is not just like a function of action sequences, but it is really the negative log probability of an action sequence given some sensations.
4807950	4816650	601	B	0.99	And so once you have computed the expected free energy, you had this minus log probability of an action sequence.
4817010	4829870	602	B	0.99957	If you take the exponential negative of that, the exponential negative of the expected free energy, you get the probability distribution over action sequences.
4832210	4838674	603	B	0.9	And so by the way, this exponential negative of expected free energy is what we use all the time.
4838712	4843222	604	B	0.99851	You might recognize this as the soft max of negative expected free energy.
4843276	4848870	605	B	0.99975	This is just all the time kind of fundamental thing, active inference lab models.
4849210	4851640	606	B	0.83315	So I'm really talking about the same thing here.
4853370	4863318	607	B	0.66223	So once you take the soft max of negative expected free energy, you get P of A, which is the distribution over action sequences.
4863414	4865770	608	B	1	And now you have two possibilities.
4866270	4879070	609	B	0.9844	Either you want to stimulate the most likely action sequence, in which case you want to simulate the action sequence that maximizes the probability distribution.
4880370	4885220	610	B	0.99946	So in effect, you have an optimization problem out of all.
4885830	4899534	611	B	0.86053	Yeah, you need to find the action sequence that is going to maximize this probability distribution that's given by the expected free energy or you want to simulate a typical action.
4899582	4901742	612	B	0.98503	So when do I mean a typical action?
4901886	4909210	613	B	0.83	A typical action or a typical action sequence is just a sample from the distribution.
4909710	4924560	614	B	0.96	And so if you want to sample from I mean, if you want to do that, then you have a sampling problem where again you need to sample from a distribution over action sequences given by the expected free energy.
4925250	4929360	615	B	0.85025	So this is really how all these methodologies connect.
4933430	4934850	616	B	0.85	I think that's kind of it, yeah.
4934920	4942726	617	B	1	One last thing is, typically when we stimulate active inference, we never do the sampling at the end.
4942828	4946760	618	B	1	We always take the action sequence that minimizes expected free energy.
4949450	4955110	619	B	0.56956	In other words, the action sequence that maximizes that probability distribution.
4955950	4963958	620	B	0.98	And this is because when we simulate things, it turns out this is how people have done it in the literature.
4964054	4972538	621	B	0.99998	People are more interested in the most likely action sequence that an organism or an agent would produce.
4972714	4988340	622	B	0.9998	But if you want to model data, if you want to use active inference to model data, then you actually want to not just simulate the most likely action sequence, but simulate any kind of action sequence that would fall out of this.
4988870	4996310	623	B	0.97	And so this is really the case where you need to sample from that final distribution as opposed to do your optimization.
4997050	5007402	624	B	0.78326	So depending on the use case, you either have a sampling or an optimization problem after you've computed the expected free energy.
5007536	5010940	625	B	0.95877	So this is how these whole things fall together.
5011790	5015542	626	B	0.56	And so you might be asking, okay, well, you talked about sampling and optimization.
5015686	5017914	627	B	0.83324	There's also a section about inference.
5018042	5019598	628	B	0.99962	Where does that fit in?
5019764	5029822	629	B	0.98	And so it fits in on the remark I gave that we have these postered distributions within the expected free energy.
5029876	5031234	630	B	0.99997	How do we compute them?
5031272	5032754	631	B	0.51153	How do we approximate them?
5032872	5035234	632	B	1	One way is by minimizing free energy.
5035432	5039410	633	B	0.99821	Another way is by minimizing any other kind of divergence.
5040070	5054470	634	B	0.97	And in that section over there, we just reviewed some kind of divergences that are very popular in the statistical inference literature, mainly because they have desirable properties.
5055690	5072160	635	B	0.9	And so if you weren't able to use the variation of free energy for some reason, or maybe something to be explored, and something to be explored is just to use other types of divergences and just see what happens.
5074210	5083520	636	B	0.93183	So the open problem to be explored is whether we can get better performance by using different kinds of divergences and see what we get.
5084210	5095190	637	B	0.99863	Maybe there's part of algorithms that are out there with these other types of divergences that we can make use of to do better performance, to get better performance.
5095770	5102834	638	B	1	Can we actually describe and quantify the improvements in performance that we get by using these other types of algorithms?
5102962	5106090	639	B	0.99929	When would these be appropriate and useful?
5106430	5108060	640	B	0.99364	These are all open questions.
5109630	5122240	641	B	0.99995	Another open question that I think is interesting is can we model maladaptive behavior by using different kinds of divergences that would not work as well as the free energy?
5122770	5129494	642	B	0.99	And there's an interesting paper on that by newer sajid and colleagues.
5129642	5135742	643	B	0.99	I think it's called Bayesian Brains and the Rennie Divergence.
5135806	5141620	644	B	0.97943	It's been published on neurocomputation, I think, last year or the year before.
5142170	5165574	645	B	0.73	And so in that paper, instead of using the variation of free energy to approximate all these posterior distributions, she used the rainy divergence, which is which generalizes the KL divergence in some way, and show that for different rainy divergences, you get different types of approximate posteriors.
5165622	5175626	646	B	1	And she basically looked into what kind of differences you get from there in terms of perception, in terms of decisionmaking.
5175818	5189902	647	B	0.85	And she showed that for that particular divergence, divergence, I think the conclusion was that you basically get different phenomenology, you get different behavior, suggest something to be explored.
5190046	5207660	648	B	0.97	I think the upshot was that maybe I don't remember how far the paper went in this, but I think kind of the goal was to model maladaptive behavior using some kinds of rainy divergences that did not work as well as the free energy.
5208030	5212620	649	B	0.87988	So this is to say, so this is an interesting work.
5214110	5222160	650	B	1	One could examine other kinds of divergences and see whether you actually get better or worse performance than with the free energy.
5223250	5234130	651	B	0.53	One thing, one word of caution, though, is the free energy is just so good in the sense that it uses the KL divergence.
5234550	5241810	652	B	0.98	And as I mentioned at the beginning, the KL divergence has so many properties and it's just so fundamental.
5242730	5247974	653	B	0.91102	It's not straightforward to see that when you first come up with it.
5248012	5262186	654	B	0.99726	But I guess the more I read in different disciplines and the more the Chao divergence comes up and the more the more I see properties of Kale divergence in different disciplines that just make it so interesting.
5262368	5266962	655	B	0.85077	Like, for example, the Kale divergence, Bayesian Statistics Physics is the relative entropy.
5267126	5273182	656	B	0.98851	So it quantifies the amount of entropy that a distribution has with respect to another.
5273316	5279130	657	B	0.98673	Entropy, as we know, is just a very fundamental thing in information theory.
5279210	5304262	658	B	0.99	The KL divergence quantifies the difference in information between two distributions, the amount of bits that you would need to if you take two distributions, A and B, the KL between the two quantifies the amount of information that it takes to go from one to the other.
5304396	5310826	659	B	0.97778	So now you might object and say, okay, but KL A and B is different from KL, B and A.
5310928	5321070	660	B	0.58	And so how can it be that it quantifies the amount of information they need to go from A to B or B to A because it's not symmetric.
5321490	5330426	661	B	0.99968	So the answer is it's either KL of A and B that has this meaning, or KL of B and A that has this meaning.
5330458	5340500	662	B	1	And I just can never remember which direction, but it's one of them that has this interpretation in terms of the difference in information anyway.
5341110	5354870	663	B	0.95755	So Kia is just like something, it just comes up everywhere and it's just so useful, and it has all of these nice properties which makes these free energy really a construct of choice.
5356030	5368330	664	B	0.95382	But that said, there's other divergences, one of them which we describe a bit in the paper called the maximum mean discrepancy, which I think also has properties.
5368670	5377178	665	B	0.66752	It's not necessarily well, it's very different in terms of how you construct it from the KL divergence.
5377354	5381538	666	B	0.99914	But I think my current understanding right now.
5381704	5389460	667	B	0.73	And my current understanding right now is that if you cannot use KL, then maximum mean discrepancy is just like, be nice.
5391590	5392114	668	B	0.86553	But yeah.
5392152	5403160	669	B	0.97304	So the word of caution was that probably most divergences out there are not going to do as good of a job as a free energy, but some clever ones might.
5403530	5413462	670	B	1	And it's an open problem of determining which is how we get the link between all these different sections.
5413606	5417898	671	B	0.97357	So to do perception, we need the inference.
5418074	5425226	672	B	1	To do decision making, that is, computing the expected free energy, we need sampling typically.
5425418	5430398	673	B	1	And then to do action selection, we either need sampling or optimization.
5430574	5435998	674	B	1	And also inference is an optimization of belief.
5436174	5441230	675	B	0.3439	Updating also, as we've discussed, is also an optimization of probability distributions.
5441310	5444102	676	B	0.95416	You can see that as an optimization of beliefs as well.
5444236	5446870	677	B	0.99328	So it's all very tightly interconnected.
5450170	5451014	678	B	0.99558	Wow.
5451212	5452194	679	A	0.99996	Thank you, Lance.
5452242	5455110	680	A	0.95212	That's very informative.
5456990	5471146	681	A	0.99945	Brings up a lot of ways to go and it really shines a different light on even what, learning active inference or learning free energy principle.
5471338	5473870	682	A	1	It was a roller coaster just listening.
5474210	5491730	683	A	0.99996	When you describe the figure of the running person and the new generalized representation here, which is so sparse it looks like it's pseudocode, but it's actually basically necessary and sufficient to describe action.
5493350	5499846	684	B	0.46571	Yeah, it is pseudocode and it is also exact like this is really what active inference boils down to.
5499948	5502310	685	B	0.8	And that was kind of like where we got at.
5502380	5506274	686	B	0.58929	We're like, okay, well, we had this mess of papers of active inference.
5506322	5526282	687	B	0.91935	Not that they're actually immense, but, you know, there's so much information and we're really thinking, reading all the latest free energy principle literature that I've also worked on a lot and also active inference lab literature and really thinking, okay, well, how do we strip all that of the neuroscience?
5526346	5528826	688	B	0.99981	How do we strip all that of the cognitive science?
5528938	5533074	689	B	0.99998	How do we just retain the math and present it in the simplest way possible?
5533272	5538930	690	B	0.9997	That would be appealing for mathematician and also hopefully for a computer scientist.
5539430	5545240	691	B	0.6	It turns out that we got a way simpler perspective than anything that's out there, I think.
5546490	5547142	692	B	0.65	And really?
5547196	5547414	693	B	0.50298	Yeah.
5547452	5555080	694	B	0.83154	So this is the active inference algorithm in pseudocode and in detail also in a way.
5557150	5558698	695	A	0.60954	So totally agree.
5558784	5568490	696	A	0.99963	Again, thanks for the work and for sharing it this way because it is the fewest pixels for the highest resolution picture.
5570370	5590046	697	A	0.99915	Then to describe the fundamental cybernetic challenge as a partition, an axiomatic partition, which one can then say also has grounding in the spatial temporal boundaries of the world or in geometric boundaries in informational spaces.
5590078	5609690	698	A	0.9999	But the particular partition is used to separate in the map, not necessarily making claims about the territory and the actual nature of the objects and their articulations or anatomy, but on the map, which we get to construct.
5610110	5619450	699	A	0.58983	We make it in a way that's amenable to the particular partition, which is not too much more than the separation of figure from ground or agent based modeling.
5619530	5625520	700	A	0.9546	It's just a separation of some autonomous entity from some external process.
5627410	5652146	701	A	0.9999	Then the task of the free energy principle applied to decision making, as you said, was to describe action as a function of observation and everything in between is broadly considered cognitive but for any given system it's going to play out in this immensely nuanced way with a lot of bespoke mechanisms.
5652338	5656040	702	A	1	And why do we take that particular partition step?
5656350	5671374	703	A	0.99989	Well, it's kind of like read, write access in the computer system there's things we don't have access to hidden states and also the reverse of that which is we can't access hidden states nor them influence or affect us.
5671412	5674874	704	A	0.9996	So I think of that as like no telekinesis, no telepathy.
5675002	5677386	705	A	0.99999	You can't go directly across the blanket.
5677498	5681902	706	A	0.92747	You have to intermediate through the blanket of observation and action.
5682046	5694758	707	A	1	And then with respect to our particular states, our blanket and internal states, we have access to observations, but not direct control, nor necessarily would we want to.
5694844	5709366	708	A	0.57385	Because if we had the lever to change what we directly received, then algorithms might learn strategies that basically self deceive so that the observations look good, look good, look good, until the whole system crashes.
5709478	5713386	709	A	0.98863	So we want access to observations but not direct control.
5713568	5724254	710	A	0.66	And then the autonomous states are what we in the optimal ideal situation have total control of which is like our mind and our body, what we think and what we do.
5724452	5740702	711	A	1	It turns out through the pragmatic turn and the inactivist insights in cognitive science that a lot of action sequences have to do with changing what observations are sought after like epistemic affordance.
5740846	5748258	712	A	0.99918	So there is an enmeshment of action but it's also really important that we have access but not control of observations.
5748434	5765130	713	A	0.99998	We don't want to have our control on the thermometer but we want the best possible thermometer and then we want to control the best possible interpretation that's like signal processing and the best possible action sequence which is like decision making and control theory.
5765470	5775870	714	A	0.99	And then free energy principle is addressing that question what is the equation of action as a function of observation?
5777650	5784978	715	A	0.99995	But then it was quite a rollercoaster when you said that the free energy wasn't even necessarily the only way to do it.
5785064	5786820	716	A	0.99997	But it's absolutely true.
5787670	5801202	717	A	1	The properties of the free energy are inherited from one of the terms being KL divergence and the other having the ability to basically ignore in certain relative expected free energy calculation contexts.
5801346	5808342	718	A	0.99921	So then in that situation differences in free energy do come down to differences in the KL which does have all these properties.
5808486	5826800	719	A	0.99998	But that doesn't mean that the free energy is itself axiomatically posited it's actually downstream of the particular partition to use free energy or anything like that at all and other discrepancies may have other properties in different ways.
5828130	5828880	720	B	0.99998	Exactly.
5830050	5842660	721	B	0.90693	There's a bit of a nuance in the sense that here we presented version of the free energy principle, just describing decision making as you summarize though describing A as a function of O.
5845510	5851000	722	B	0.79	And by the way, about that, we didn't even talk about Markov blanket in this paper.
5852090	5860570	723	B	1	I would say that the markup blanket is under the hood because we're saying, okay, well, these are the states that you have access to and these are the states that you do not.
5860720	5863114	724	B	0.99	The states that you have access to are A and O.
5863152	5864490	725	B	1	The states are the agent.
5864640	5867222	726	B	0.99	The states that you do not have access to are the environment.
5867366	5874590	727	B	0.99995	So in some sense there is a markup blanket, but we didn't even have to mention that in the paper.
5874660	5883440	728	B	0.94839	It's just you partition the world into three sets of states, S, O and A, that are by definition A.
5884050	5891860	729	B	0.6	And you just yeah, just from this trip partition, you want to describe one as a function of another, ignoring the third.
5893430	5897654	730	B	0.89	And so that's how you derive expected green energy.
5897692	5903158	731	B	0.6881	You see that action sequences are described by the expected free energy.
5903244	5914294	732	B	0.99	And this is a functional sensations if we want further in the and so this is just what you need crucially, this is just what you need to derive.
5914342	5925950	733	B	0.99982	Active Inference Lab Algorithm if we went further in reviewing the free energy principle, then we would see the fundamental role that the free energy plays.
5928530	5939940	734	B	0.99	And so actually, when reading the latest papers on the mathematical theory of the free energy principle, the role of the variation of free energy is pretty clear.
5941990	5953222	735	B	0.99982	But here the point is that if we just care about decision making, if we just care about the normal active inference algorithm, then we don't even need the variation of free energy.
5953356	5956402	736	B	0.81026	So sure, the free energy should be preferred.
5956466	5959114	737	B	0.96143	Why not, if it is available?
5959232	5964970	738	B	0.95014	But if it is not for some reason, then there's no reason why not to use another kind of divergence.
5972610	5973840	739	A	0.99624	Very interesting.
5974210	5992398	740	A	0.99971	It's making me think about linear regression and the sum of squares, the L two norm is one approach that's often used to fit a regression line because it has good optimization properties, there's good software packages, there's good education, there's good communication around it and so on.
5992504	6000854	741	A	0.92704	But one can select other norms and choose to fit a linear regression with an L one norm or with an L three norm.
6001052	6010422	742	A	0.96	And so that entire question of fitting the linear aggression is a degree of freedom.
6010566	6021070	743	A	0.99998	How the regression is fit, that's downstream of a commitment to, for example, model a system in a generalized linear modeling framework.
6021490	6036366	744	A	1	And so analogously, the upstream commitment or the first principles which yes, can be understood as axiomatic and also have some empirical status in terms of this partitioning.
6036398	6043410	745	A	0.88	A figure from ground the particular partition can simply be accepted axiomatically, which is to say without appeal to evidence.
6043570	6051750	746	A	1	Or somebody might have another upstream axiom and choose to model things according to a particular partition.
6052410	6078160	747	A	0.99998	From there, just like we could have chosen the L one, two, three norm there are different discrepancy criteria or measures that we might want to use, and some of them apply better or worse or not at all, depending on what software, hardware, data set, and generative model we have.
6079490	6080960	748	A	0.97	And so it makes sense.
6082230	6093990	749	A	0.99969	Pull back into the upstream understanding active inference lab as a process theory for particular partitioned systems.
6094730	6112406	750	A	1	And then for those who want to engage in the modeling to have that discussion about the garden of the branching paths, well, you could use a discrete time or you could use a continuous time, and then from here, you could do this sampling.
6112438	6113418	751	A	1	Or you could do that one.
6113504	6116266	752	A	0.91	And if we have this computer access, we can do that.
6116288	6118574	753	A	0.99997	But if we have to do it this way, we'll do it like that.
6118772	6135294	754	A	1	And that's all operational and logistical, but it's actually all under the umbrella or under the auspice of the theoretical or conceptual commitments that are actually not being questioned once one is in that modeling discussion.
6135422	6142806	755	A	0.99946	Just like you could have the L one two three norm conversation, and maybe a reviewer asks you why you chose the two norm versus the three.
6142988	6150598	756	A	0.99998	But it's a broader level of questioning why one took on the linear modeling framework at all.
6150764	6160810	757	A	1	And our analogous upstream bottleneck, not in terms of rate limiting, but just in terms of like, eye of the needle is the particular partition.
6164350	6165242	758	B	0.97	Yes, definitely.
6165376	6175886	759	B	0.42	And I just want to add something actually about the choice of divergences or the choice of discrepancy that you might want to use to solve the inference problem.
6176068	6179614	760	B	1	I think the analogy with linear regression is a really good one.
6179812	6189342	761	B	0.9999	When you do linear regression, yeah, you can use all types of norms, and it's really a design choice here in the algorithm, you also have that design choice that you're going to use KL.
6189406	6192710	762	B	0.9881	So free energy to do active inference.
6194570	6204626	763	B	0.99997	By the way, the inferences are really equation 43 and 44, which are approximate actually, you had them in the slide.
6204658	6209080	764	A	0.9992	Already, 43 and 44 here, got it.
6210090	6216502	765	B	0.99949	Which are approximate some posterior distribution with an approximate posterior distribution.
6216646	6223498	766	B	0.99717	So you can do that with the pre energy, which is the same as the KL divergence, or you could do that with a whole bunch of other divergences.
6223594	6229150	767	B	1	One that I mentioned and that I think is particularly interesting is the maximum mean discrepancy.
6229670	6240450	768	B	0.85	And so here's the difference between KL and maximum dean discrepancy, at least, I guess, an important conceptual difference.
6240600	6257820	769	B	0.99553	So the KL, when you look at distributions that are very close to each other, it's basically going to become symmetric when the distributions are very close, and it's going to measure the amount of information that differs between them.
6258190	6274250	770	B	1	The maximum mean discrepancy, when you take two distributions that are very close, it reduces to what people call the Earth movers distance, also called like the vanishing distance so here's an intuition.
6274410	6285810	771	B	0.99937	If you take two distributions that are very close, just imagine distribution A as a pack of dirt and distribution B as a pack of dirt or a sand with some shape.
6286150	6301766	772	B	1	The maximum mean discrepancy is going to tell you the amount of work that you need to put all that dirt from distribution A and pile it in the shape of distribution B.
6301948	6317406	773	B	0.94545	So of course, there's so many different ways in which you could take all that dirt from distribution A and remodel it in distribution B, but you're interested in the minimal energetic cost that would take.
6317428	6322670	774	B	0.71042	So like the optimal way of doing that movement, people call that optimal transport.
6323730	6345846	775	B	0.93	Now, if you're familiar with optimal transport, you know that the Vaster Stein distance is a distance between probability distribution that regardless of how far they are, is going to measure, is going to give you this cost of optimal transfer.
6345948	6355240	776	B	0.99917	So the energetic cost of moving all that pack of dirt from place A to place B in the optimal way.
6356750	6360380	777	B	0.99692	So the vaster shine distance is something that we could use here.
6362110	6369814	778	B	0.99866	But maximum mean discrepancy, it has a lot of very nice properties and basically reduced it to the Vaster Stein distance.
6369862	6394050	779	B	0.99997	When we consider very close distributions, this is not something that just a mathematical curiosity, but it's done that when one builds a distance out of a divergence, what one does is one takes very close distributions, measures the divergence between them, at which point the divergence is pretty much symmetrical.
6394470	6399606	780	B	1	And then you basically keep adding divergences along the trajectory until you get to the final one.
6399708	6413340	781	B	0.65	And this way, by aggregating divergences between very close distributions and doing that and adding that along a trajectory, you get a distance, a meaningful distance between distributions that could be very far.
6414110	6434020	782	B	0.96932	If you do that with the Kale divergence, you get what's called the fisher information distance, which measures really the amount of information that took you from to go from one distribution to another distribution, regardless of how far they are.
6435190	6440626	783	B	0.9993	If you do that with the vast search time distance, you will get the optimal transport cost.
6440728	6447718	784	B	0.98587	So the amount of energy that you need to put all that dirt, place A to place B in the optimal way.
6447884	6454040	785	B	0.99997	If you do that with the maximum discrepancy, you would also get that you will also get the optimal transport thing.
6458330	6471600	786	B	0.57	I just want to say that the maximum discrepancy discrepancy between two distributions that are far away will not coincide with the Vaster Stein distance, which gives you this optimal transport cost.
6472130	6490574	787	B	0.51319	But when you actually derive a distance from these divergences, the distance derived from the maximum discrepancy and the Vaster Stein distance will end up being the same and the distance that you actually get or the topology that is derived from the distance.
6490622	6495430	788	B	0.99238	So by topology, a topology is really a notion of closeness.
6496890	6502310	789	B	0.99	And so to understand closeness, you need to understand infinitesimal distances.
6503050	6508380	790	B	0.99581	So the infinitesimal distances derived from Vaster Stein or Mmd, they're the same.
6508830	6518650	791	B	1	The topology that results is the topology of what people call weak convergence, which is a standard topology that's considered in probability theory.
6520990	6540610	792	B	0.97041	So Mmd and Vaster Stein, they are very natural in that sense, in the sense that people say that they met rise, weak conversions, like they give rise to the standard topology between probability distributions.
6542330	6555602	793	B	0.96694	So coming back to the choice of divergences, if you're interested in approximating distributions in the sense of approximating their information content, then KL is very natural.
6555746	6574190	794	B	0.86584	But if you were for some reason and maybe would not be in this kind of application, but another kind of application, if for some reason you're interested in approximating distributions for the sake of how close they are when you look at them, then you wouldn't use Mmd or Vassagetein.
6576930	6581220	795	A	0.99927	Wow, great information.
6581910	6588980	796	A	1	And I'm just thinking about we're switching lanes on the highway we're trying to get from here to there.
6589430	6603234	797	A	1	Yes, we want to know about the informational closeness of this tale of two densities, but we also want to know about the transport closeness because we have a schedule and a budget and decisions to make, and there are trade offs.
6603362	6615530	798	A	0.99786	So being able to move the Earth optimally while we're switching lanes and accelerating and slowing down, I know this is mixing many angles informally.
6616930	6631520	799	A	0.53047	We want to have a lot of options for how to think about that challenge of moving dirt between the tail of two densities and make sure everybody is driving in the right lane at the right time.
6633170	6641490	800	B	0.99952	Definitely, yeah, it's a design choice and it's an important one because it depends on what kind of properties we want to preserve.
6643930	6654520	801	B	0.94195	All these divergences, some are not so useful, I guess, but some of them, they're just very natural and vasterstein and Mmd, they're very natural in that sense.
6656350	6658220	802	B	0.99956	Very important to keep in mind.
6658910	6666460	803	B	0.81	And not only active inference lab, but just in general for any kind of inference problem.
6669330	6681940	804	A	0.96527	Well, let us each have a closing round or reflections, any thoughts or any next steps or any suggestions or other information you'd like to provide.
6684070	6685122	805	B	0.37497	It's hard to say.
6685176	6689140	806	B	0.92	I feel we've covered so much already.
6691270	6707114	807	B	0.99	I think to me, what's most exciting about is scaling active inference right now, because you get this active inference algorithm in the paper that's the right compares principles and just from the derivation, you see.
6707152	6715930	808	B	0.99853	Okay, well, there's actually so many things I dean, the assumptions are so small that there are so many things that you can model with this active inference algorithm.
6719470	6722634	809	B	0.55	And all the heavy lifting is done by the generative model.
6722832	6726474	810	B	0.99387	So if you use one generative model, you will get one behavior.
6726522	6731760	811	B	0.99526	If you use another generative model, you will get another behavior, but all the equations will remain the same.
6734310	6736366	812	B	1	It speaks to the generality.
6736558	6740066	813	B	1	Now in having something that's very general, you.
6740088	6742680	814	B	1	Get something that's also very non specific.
6743050	6756700	815	B	1	And I guess for neuroscientists and people who are interested in intelligence, generality comes at a cost of being non specific and non specific about the brain in general.
6757550	6766470	816	B	0.99606	So really the big question to me long term is what kind of generative models do we need to simulate brain like behavior?
6766550	6770990	817	B	0.9998	Because this is really the interesting behavior or the most interesting behavior.
6771810	6778750	818	B	0.99922	So it speaks to a big research program that a lot of people are carrying and have been carrying for a long time.
6778900	6785250	819	B	0.92963	But it's about what kind of representations do we have of the world?
6785320	6787780	820	B	0.99992	What kind of priors do we have?
6788950	6793142	821	B	0.69	Can we identify the priors that we are born with?
6793276	6807926	822	B	0.99075	There's a lot of research on computational or just playing cognitive science, like normal cognitive science, just studying babies and seeing what kind of priors, what kind of basic information they have when they come out of the womb.
6808038	6810460	823	B	0.9002	There's a lot of things that they can already do there.
6810910	6821518	824	B	0.99849	Our genetic code is preconditioning us to operate efficiently in this world and be able to flexibly adapt to any kind of situations that might arise in the natural world.
6821684	6827950	825	B	0.79	And so it's a huge research program to understand and model these priors.
6831090	6836050	826	B	0.72	And not only the priors, but also the likelihood, all the representation, all the state spaces.
6836790	6839330	827	B	0.99258	So I think that's the way forward.
6839480	6848774	828	B	0.99	The creation principle is very elegant because it gives you a very succinct description in terms of a giant model that enables you to simulate pretty much everything.
6848972	6851974	829	B	0.99993	But we're not interested in simulating anything.
6852092	6855046	830	B	0.72705	We're interested in simulating brain like behavior.
6855078	6862860	831	B	0.98	And now we need to drill down even more onto the kind of Janitor models that would be amenable to that.
6867030	6867780	832	A	0.94586	Great.
6869110	6878360	833	A	0.9996	My closing reflection I feel like I know less about fep, but more about something else.
6878730	6881030	834	A	0.99922	For what we've discussed.
6882830	6893814	835	A	0.58075	Earth was moved, Bayesian mechanics were called in, decisions were made, and it's been a really great series.
6893862	6902400	836	A	0.99951	So I'm appreciative and thankful that you suggested this paper in our correspondence as one to discuss.
6903250	6911300	837	A	0.99992	You were absolutely right that it is relevant to bring to the attention of the active community.
6911910	6924100	838	A	0.99	And I hope that everybody who reads or listens thus far has shifted lanes so they can be where they want to be too.
6925190	6926660	839	B	0.63809	Well, yeah.
6927670	6929010	840	B	0.99446	Thank you so much.
6929160	6934010	841	B	0.7	I also really enjoyed the session and think we had a really cool discussion.
6934430	6935482	842	B	0.99849	So thanks again.
6935536	6938140	843	B	0.58	I hope to do this again soon.
6938510	6939094	844	A	0.99908	Excellent.
6939142	6940460	845	A	0.88191	Anytime you'd like.
6940910	6941900	846	A	0.93407	Very well.
6942750	6943350	847	A	0.90148	See you, Lance.
