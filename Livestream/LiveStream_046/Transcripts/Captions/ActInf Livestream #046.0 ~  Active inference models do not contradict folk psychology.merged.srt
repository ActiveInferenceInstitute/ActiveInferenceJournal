3
00:00:12,900 --> 00:00:41,400
FRIEDMAN: All right. Hello and welcome, everyone. It's active live live stream number 46.0. And it's June 10th. 20, 22. Welcome to the active lap, everyone. We're a participatory online lab that is communicating, learning and practicing applied active inference. You can find us at links here on the slide. This is a recorded in an archived live stream, so please provide us with feedback so we can improve our work.

5
00:00:42,467 --> 00:01:16,700
All backgrounds and perspectives are welcome, and we'll be following video etiquette for livestreams. Head over to active inference dot org if you want to learn more about live streams at the lab or other projects that are ongoing. All right. We are here in the first discussion the dot zero for background and context in stream number 46.0. We are learning and discussing the paper active inference models Do Not Contradict Folk Psychology by Ryan Smith, Maxwell Ramstad and Alex Kieffer.

7
00:01:17,333 --> 00:01:43,133
And the video, just like all the videos are, is an introduction an end to contextualize and an appetizer for some of these ideas. It's not a review or a final word. We're going to say hi and give introductions. Then we'll be covering the roadmap and abstract claims and aims. And then we'll head through some of the core sections of the paper and just get some of the key arguments down.

9
00:01:43,500 --> 00:02:12,700
And during the dot, one in the dark two in the coming two weeks, we'll have an open space for asking a lot of questions for those who want to participate, live and ask questions as well. So on we go. We'll start just by introducing ourself as much or as little as we'd like, and if we want to, mentioning something that we're excited about in the paper, like what brought us to want to contribute to this start zero and all start.

11
00:02:12,900 --> 00:02:37,233
I'm Daniel. I'm a researcher in California, and I think the title says it all, though there's still more to add, and it speaks to many of the hottest and brightest debates in active inference, which is the rubber hitting the road with mind, brain and body and psychology and previous and different conceptions. I'll pass it to Dean I certainly Ondina up here in Calgary I think.

13
00:02:39,33 --> 00:03:19,867
DEAN: I certainly Ondina up here in Calgary I think. Well, a couple of things. First of all, one of the first act of interest that I was on was a paper that Ryan had written. And so I was kind of impressed with that paper and I knew that if I sort of vested some time in this one stuff that I would pick up previous and the primary problems was looking at active inference from the decisioning and and the movement standpoint of seeing that looked at from a higher order and the lower order type of processes.

15
00:03:20,400 --> 00:03:45,0
And that when I by the time I got into the paper and started looking at the mind world and world mind piece and and seeing where the potential connectors were between sort of coming into it not necessarily knowing that there would be different things of active inference, much like I didn't realize there was an extended active inference till I read actually Constance Paper that was kind of helpful.

17
00:03:45,200 --> 00:03:48,867
And I'll pass it to Jake everyone. I'm Jakob. I'm a student from the Czech Republic and I'm excited to reduce my uncertainty about the new formulation that that was introduced in this paper. Or at least it was the first time I came across it in the active inference literature, as you mentioned, about the different higher order and lower order descriptions and how they conceptually map to the different mathematical mathematical formulation and also to the psychological ontology and overall, just discuss what that what that means and what it might mean for other applications as well.

19
00:03:48,867 --> 00:04:44,367
JAKOB: I'm Jakob. I'm a student from the Czech Republic and I'm excited to reduce my uncertainty about the new formulation that that was introduced in this paper. Or at least it was the first time I came across it in the active inference literature, as you mentioned, about the different higher order and lower order descriptions and how they conceptually map to the different mathematical mathematical formulation and also to the psychological ontology and overall, just discuss what that what that means and what it might mean for other applications as well.

21
00:04:45,233 --> 00:04:47,667
And accustomed to refine. I mean, I think so. I'm Ryan Smith. Some research associate professor at the Laureate Institute for Brain Research. And so I'm not the first author of this this paper so obviously I was especially excited about the ideas to write about it or sufficiently motivated at least to try to clarify some things that I am you know, from my perspective a sort of common misconceptions one yeah.

23
00:04:49,200 --> 00:05:15,767
SMITH: I mean, I think so. I'm Ryan Smith. Some research associate professor at the Laureate Institute for Brain Research. And so I'm not the first author of this this paper so obviously I was especially excited about the ideas to write about it or sufficiently motivated at least to try to clarify some things that I am you know, from my perspective a sort of common misconceptions one yeah.

25
00:05:15,767 --> 00:05:33,167
I mean, I'm I'm probably more going to sit in the background here. I'll just be here to answer questions or clarify anything. You know, if something comes up where something in the paper wasn't wasn't especially clear because I didn't I didn't do my job well enough. So I'm. Yeah, so I appreciate you guys being willing to talk about it.

27
00:05:34,167 --> 00:05:59,67
FRIEDMAN: Thanks. Well, an overall comment was we really appreciated the clarity of the argument and the writing and the weaving together of the math and the formalisms with the argument, the rhetoric and the ontology. That's that's prime time. So we'll just jump right in. And of course, anyone is welcome to share their comments so Dean, would you like to help us contextualize with a big question?

29
00:05:59,933 --> 00:06:44,67
DEAN: Yeah. So I think that there's some questions surrounding and I'm just going to take some of the important quotes that I lifted from the paper, the concern that active in book psychology, because they do not explicitly include terms for desires or other cognitive constructs at the mathematical level of description. So given that distinction, that there are active inference, not motor control, which need not have desires that are folk psychology and active inference models, who have desires within folk psychology, that free is that most can focus on struggling.

31
00:06:44,67 --> 00:06:54,133
FRIEDMAN: Because you I think when you're talking, you like turn away a little bit and move back. It kind of cuts the audio. So yeah, we'll try that and continue from the given. Thank you. OK, so given the there's a distinction and active inference models of motor control which do not have desires under folk psychology and active interest models of decision processes which do have desires with psychology are so it's argued here then the worry is that if active interest models can explain cognition without appealing to constructs can be mapped out to the common sense notion of desires.

33
00:06:54,867 --> 00:07:21,800
DEAN: OK, so given the there's a distinction and active inference models of motor control which do not have desires under folk psychology and active interest models of decision processes which do have desires with psychology are so it's argued here then the worry is that if active interest models can explain cognition without appealing to constructs can be mapped out to the common sense notion of desires.

35
00:07:22,300 --> 00:07:51,500
Now, to explain what that is, then this could be seen as threat our intuitive folk psychology. Okay. I'll ourselves as agents. Such a situation would also pressure the traditional belief, desire, intent model of folk psychology that is prominent in philosophy. The BD model is a model of human agency that explains what it means to act intentionally. So for me, I was introduced to the BD model as yes, great.

37
00:07:54,233 --> 00:08:29,967
FRIEDMAN: Yes, great. And one way that I kind of saw this big question even pulling back a layer is like is active inference recontextualizing reframing, augmenting, building on what is already familiar. In a sense, though, there are many folk psychologies, and I think that could be something we go into or is this the displacement of some cherished framework for some other construct and the way that people speak like I want the cup of coffee or something like that, are we going to need like a different word for an active compatible folk psychology and linguistics?

39
00:08:30,467 --> 00:08:33,233
So Yaacov, any thoughts on that? Well, I guess one question I had was like this even this formulation of the of the initial of the initial statement, given this distinction of motor control, act of inference and decision processes, act of inference, then we have this, then we have this issue. Well, one thing that I was a bit uncertain about was whether this distinction was made to fit the distinction that within folk psychology there is some kind of ontology for motor control and an ontology for decision processing so that therefore we try to split active inference into these two parts, or whether there is actually whether this distinction follows directly from the mathematical formulation of active

41
00:08:35,67 --> 00:09:36,733
JAKOB: Well, I guess one question I had was like this even this formulation of the of the initial of the initial statement, given this distinction of motor control, act of inference and decision processes, act of inference, then we have this, then we have this issue. Well, one thing that I was a bit uncertain about was whether this distinction was made to fit the distinction that within folk psychology there is some kind of ontology for motor control and an ontology for decision processing so that therefore we try to split active inference into these two parts, or whether there is actually whether this distinction follows directly from the mathematical formulation of active great.

43
00:09:37,133 --> 00:09:59,0
SMITH: So I think there I think one thing one thing to you to clarify is I think I think the way that this kind of given the distinction followed by then here, I think could be leading to a little bit of a misunderstanding in OCD. The idea that there's a concern about about a threat to folk psychology comes not from that distinction.

45
00:09:59,0 --> 00:10:36,533
It comes from the fact that there's at the mathematical level of description, it doesn't look like there's anything in there that that's that's desire ish. Right? I mean, that's where the worry comes from. It doesn't really the worry doesn't come from the distinction between motor control and decision processes. Right. The distinction between motor control and decision processes is actually one thing that by making that more explicit it actually helps to resolve the concern or it shows why it's not really a concern or that part of the concern stems from a failure to make that distinction explicitly.

47
00:10:37,633 --> 00:10:46,433
So. So just to kind of clarify that, I think the order of the thought process here is a little bit different than than the way the way it is in the paper. Thanks. Helpful times and we'll clarify and go through the argument in order to so briefly just the aims of the paper as they presented are to provide a brief review of the historical progression from predictive coding to current active inference models and show that despite a superficial tension when viewed at the mathematical level, the active inference formalism contains terms that are readily identifiable as desires and related cognitive constructs at the psychological level, which is downstream of that clarification of the distinction that Ryan

49
00:10:48,233 --> 00:11:26,300
FRIEDMAN: Thanks. Helpful times and we'll clarify and go through the argument in order to so briefly just the aims of the paper as they presented are to provide a brief review of the historical progression from predictive coding to current active inference models and show that despite a superficial tension when viewed at the mathematical level, the active inference formalism contains terms that are readily identifiable as desires and related cognitive constructs at the psychological level, which is downstream of that clarification of the distinction that Ryan just mentioned.

51
00:11:27,67 --> 00:11:38,433
And then they discuss the additional insights offered by active inference and the implications it has for current debates. About active inference any other aims you'd want to add?

53
00:11:38,433 --> 00:11:44,800
SMITH: Run I think this is fine at the moment. I mean, I'm sure things will come up.

55
00:11:45,800 --> 00:11:51,133
FRIEDMAN: Great and then claims, Jakob, could you read the claims?

57
00:11:52,333 --> 00:12:34,633
JAKOB: Yeah. So firstly, that the apparent problem posed by purely the classic looking construct simply is not a problem. There do not appear to be cases where the phenotype consistent prior expectation in the often called prior preferences will ever conflict with or make distinct predictions, then it's additional. So take a psychological account in which beliefs and desires are integrated to intentions the second claim is that what we have referred to as the partially observable Markov decision process formulation of actin is a corollary of the SEP and it can be implemented using prediction error minimization.

59
00:12:34,833 --> 00:12:46,900
But there are many other aspects of the step and many other theories that fall under the umbrella of predictive processing. And in some there are beliefs and desires in the act of inference. Thanks. And those are just a few claims that we pulled out, but many other declarative sentences will also be claims I wouldn't necessarily call those the primary claims of the paper.

61
00:12:48,400 --> 00:12:55,133
FRIEDMAN: Thanks. And those are just a few claims that we pulled out, but many other declarative sentences will also be claims.

63
00:12:58,67 --> 00:13:20,100
SMITH: I wouldn't necessarily call those the primary claims of the paper. I mean, they're certainly statements that we make, but I think I think the idea that there isn't I think the idea that the apparent problem isn't a problem, I think that's a claim and that it doesn't that there won't be a conflict with with an account where you're combining beliefs and desires to form intentions.

65
00:13:20,100 --> 00:13:20,800
That's true.

67
00:13:22,967 --> 00:13:51,333
This idea about about what falls under the predictive processing umbrella with them may well, I would necessarily say that's something we're arguing for in the paper. It's just it's just something that that matters when you're trying to correctly frame this kind of this kind of debate, because predictive processing is just a very generic term, right? Like it doesn't refer to any particular mathematical formalism.

69
00:13:51,333 --> 00:14:15,700
It just refers to a really broad idea that in some way the brain's doing some sort of predicting either with respect to resolving problems in perception or problems and decision making and motor control so so there really isn't there's not enough there's really just not enough mathematical specificity associated with predictive processing as a term to really even test any predictions that it would make.

71
00:14:16,167 --> 00:14:46,367
Right. So I mean, I mean, what you what you need to do is pick whatever specific mathematical formalism, what actual hypothesis you're talking about and evaluate and test claims respect to that. Right? So there's that. There just aren't there's aren't clear like what even it's just pretty depressing. It's just too general and vague is the point. So we can only really say, look, under under the current models used that are called active inference, right?

73
00:14:46,367 --> 00:15:18,200
So these, you know, partially observable Markov decision process models that minimize expected free energy as a way of making decisions. Right? Those those arguably count as one particular right theory or class of models under the predictive processing umbrella. And we can evaluate claims with respect to that model. But what's true of that doesn't need to be true of the other 20 things out there that might might also fall under a predictive processing umbrella.

75
00:15:18,200 --> 00:15:32,300
So I mean, the main point is just we need to evaluate claims and predictions and things like that with respect to a specific model, not with respect to a kind of vague general category of models thank you.

77
00:15:35,700 --> 00:16:03,967
FRIEDMAN: OK, so just rapidly through the abstract, active inference offers a unified theory of perceptions. Learning and decision making are computational and neural levels of description. In this article, we address the worry that active inference may be in tension with the belief desire intention by model within folk psychology, because it does not include terms for desires or other cognitive constructs at the mathematical level of description.

79
00:16:04,567 --> 00:16:50,233
To resolve this concern, we first provide a brief review of the historical progression from predictive coding to active inference, enabling us to distinguish between active inference formulations of motor control and AI, which need not have desires under folk psychology and active inference formulations. Of decision processes, AI which do have desires under or which are within folk psychology. We then show that despite a superficial tension when viewed at the mathematical level of description, the active inference formalism contains terms that are readily identifiable as encoding both the objects of desire and the strength of desire at the psychological level of description, we demonstrate this with simple simulations of an active inference agent motivated to leave a dark

81
00:16:50,233 --> 00:17:26,767
room for different reasons. Despite their consistency, we further show how active inference may increase the granularity of folk psychological descriptions by highlighting distinctions between drives to seek information versus reward, and how it may also offer more precise quantitative folk psychological predictions. Finally, we consider how the implicitly cognitive components of active inference may have partial analogs, i.e. as if desires in other systems describable by the broader free energy principle to which it conforms here's the road map.

83
00:17:27,400 --> 00:17:54,833
So the dot zeros all of them in the world wouldn't be enough to hit every stop. So we will go through roughly in order of these sections, and the section titles are listed here. But Ryan, what was the thought going into the ordering or the structuring and why there was such a comprehensive historical and preliminary consideration section I mean, I mean, a lot of it, I mean, the vast majority of these sections are just kind of building up background, right?

85
00:17:57,0 --> 00:18:27,400
SMITH: I mean, I mean, a lot of it, I mean, the vast majority of these sections are just kind of building up background, right? I mean, especially in background, I kind of see right where where the both, both I think historically where potential misunderstandings might come from, you know, and also and also just enough of the you know, providing enough of a formalism, you know, one part of the formalism that's kind of built on another writer to see why they, you know, to see whether the apparent problem just isn't there.

87
00:18:27,833 --> 00:18:58,433
Right. So I mean, the vast majority of these sections are just are just preliminary, just kind of building up so that the reader has the information necessary to understand the argument I mean, only, only the last couple of sections that really, really are the meat of the argument itself. I mean, so so you know, for example, just Section two you know, are what we just said from Predictive Coding Act of inference is just kind of highlighting how, you know, these initial phases in brain as implemented through predictive coding was, you know, purely a model of perception.

89
00:18:59,0 --> 00:19:37,367
Right? So then, you know, so those people but a lot of times you'll see, especially in the older literature, and in some philosophy literature, you know, predictive processing somehow both refers to predictive coding, but then also is talked about as though it's as though it's the same thing as active inference. Or they'll be these kinds of ideas where if you just extend predictive coding as kind of a are the words talked about as a kind of way of thinking about what the whole brain does, you know, then all of a sudden, you know, controlling the body ends up also just being something about predicting what the body will do.

91
00:19:37,933 --> 00:20:14,233
Um, but, but, and especially one described that way, right? It sounds like something like desire and motivation and goals and things like that are just kind of completely out the window. It's very hard to make sense of what, how a system like that would even work right and so it's and part of that, I think, is because there's, you know, some, you know, some the way that certain things are written and some of the literature can be a little bit confusing or it's not too it's not too hard to understand why, you know, these sorts of, you know, these sorts of misunderstandings could you know, could happen.

93
00:20:15,433 --> 00:20:36,267
But but but, you know, Section two, though, it really, really is to show how, you know, initially, right. When you're trying to move from predictive coding again, which is purely a model of perception. It's not about decision making. It's not about action selection. You know, it's not even about motor control, right? It's just that it's just a Bayesian it's just a theory of how the brain can do approximate Bayesian inference and perception.

95
00:20:37,33 --> 00:21:04,867
You know, how that was initially just extended to say, hey, like if the brain works this way, then, you know, how do you how do you get a system that actually controls the body using the same generic architecture? Right. And so then, you know, the story of the oppressed and you know, and, you know, some other people try to put together was this story about how you can use predictions you know, dissenting predictions if weighted appropriately.

97
00:21:05,100 --> 00:21:24,367
Right. As a way of essentially setting the target states of the body. Right. Like like it's this kind of the way I see it talked about is, you know, I predict that my arm will be here, but really it's down here. But if I wait there correctly, that it'll kind of like, you know, you'll kind of control the point and reflect startup, you know, so they are arm kind of moves up with their frustration.

99
00:21:24,833 --> 00:21:50,700
Right. But but that's just a theory about how you can use a descending prediction signal to essentially act as a motor command signal. Right. There's nothing in that at all that that's deciding what that prediction ought to be. Right? There's nothing deciding what that what which motor command should should be the one. Right. That's getting sent down in and in and what the form of a prediction right.

101
00:21:50,700 --> 00:22:11,833
So so again, so even there, it's just a theory about how you can use predictions as motor commands, right? Like there's now a very big distinction between that and whatever the system is on top of that. Right. That's is setting. OK, what motor command, but what motor prediction. Right, do I send? And so just making you know, making making that clear, right?

103
00:22:11,867 --> 00:22:49,533
Because around 20, 15, there was this big shift right from this from this act, from active inference being talked about as a just kind of a motor control process, right? Like a like a story about how you can extend predictive coding to also do motor commands right? Like from that to, you know, these larger, more comprehensive decision making models which are the current right on based and those, you know, which was all aimed to show very explicitly you have something that, you know, in the mathematics just does, right?

105
00:22:49,600 --> 00:23:28,500
It specifies the goals of the system. It's pretty hard to get around the fact that you need something. A system needs something like goals, right? Because it has to evaluate somehow why one decision has got to be better than another. Right? The only way it can really do that is with respect to how likely it is to get whatever the system wants so so it's just I mean, in my in my view, it's it's very difficult to see how you can ever get a system to be able to evaluate one action that's better than another without having some sort of target state and and so you can call right.

107
00:23:28,500 --> 00:23:56,200
Like the target states and act of inference, a type of prior belief but at the end of the day, its functional role is to specify what what observations are better than what. Right? So, I mean, you can really think of active inferences as using this kind of trick in a certain sense. Right, of specifying desired outcomes in the form of a probability distribution, because that helps keep everything fully, fully, faithfully Bayesian.

109
00:23:56,367 --> 00:24:29,67
Right. But it's not it's not it's not playing functional belief, right? It's encoding in a higher probability, just means. Right? Like the better, more rewarding outcome. So so a lot of it is just kind of working step by step through all kind of the historical progression. So you can see where the misunderstanding could come from and then also through the current formalism so that you can see exactly where those where the, you know, the goals are encoded in terms of something with the form of a probability distribution.

111
00:24:30,867 --> 00:25:00,800
FRIEDMAN: Thank you. The key words are active inference, folk psychology, predictive processing, Bayesian beliefs and desires so now we're going to jump in and some of the slides have a lot of text topically arranged, so we won't need to read all the text on many of the slides, but especially if somebody wants to pull out like one of the highlighted sections and like bring it to our attention.

113
00:25:00,800 --> 00:25:15,700
That would be awesome. So and also, Ryan, thanks a lot for that great historical overview. And I think there's there's so much more to be going into about what happened before 20, 15 and what happened in the last seven years.

115
00:25:17,933 --> 00:26:01,300
In fact, I think you've covered many of the key points in what you just described here, which had to do with the development of predictive coding framework into understanding brain and body is there anything that anyone else wants to add about these points great. Then all discussions and zeros are like a two way street where some people with active inference familiarity are learning about new ideas and frameworks, and also people who might have familiarity with a broadly used area outside of active are learning about active.

117
00:26:01,300 --> 00:26:36,33
So for both directions on that freeway, it's important to understand what is the target non active framework that's being juxtaposed and found concordance is with active inference. So the article is addressing the worry that active models may be in tension with the belief desire intention model, and there are some consequences to that work. In other words, given some priors, it's a founded worry would anyone like to summarize what the belief desire intention model is?

119
00:26:37,800 --> 00:26:41,233
DEAN: Thank you. Sure, Daniel, because you I think you put this slide together Ryan, what led you to select the BD model? And I wondered about almost this tension or paradox with like it's folk psychology. It's about what the people think. But we're going to do a citation and one specific academic acronym for what people think. So is this like the main game in town for folk psychology from an academic perspective?

121
00:26:44,67 --> 00:27:07,700
FRIEDMAN: Ryan, what led you to select the BD model? And I wondered about almost this tension or paradox with like it's folk psychology. It's about what the people think. But we're going to do a citation and one specific academic acronym for what people think. So is this like the main game in town for folk psychology from an academic perspective?

123
00:27:07,700 --> 00:27:17,467
Or what is the PTI and what led you to select that rather than like a small portfolio of alternate folk psychologies I, I think that is our intention model is just a very kind of generic button, but also widely known like account of trying to capture folk psychology. And it's kind of a, it's a, it's a major sort of target of a lot of discussion within like philosophy of mind.

125
00:27:17,867 --> 00:27:52,200
SMITH: I think that is our intention model is just a very kind of generic button, but also widely known like account of trying to capture folk psychology. And it's kind of a, it's a, it's a major sort of target of a lot of discussion within like philosophy of mind. But I mean, it's just very generic, right? I mean, just this idea of, you know, what, what are the what are the necessary ingredients to make a decision?

127
00:27:52,733 --> 00:28:12,100
Well, you know, I have to have some beliefs about how the world is and about some desires about how the world I would like it to be. And my intention involves integrating those two things. Right. And then and then if all goes if all goes well in terms of translating intention into controlling the body, then I'll act out, you know, something according to my intention, right?

129
00:28:12,167 --> 00:28:35,167
I mean, simple. You know, like the dumb example that you'll often hear is this, you know, something like, you know, I desire some ice cream. You know, I believe that there's an ice cream truck, you know, down the road, you know, given those two things and and necessarily those two things. Right, I can inform intention and form an intention to go walk over to the ice cream truck and buy some ice cream, you know?

131
00:28:35,267 --> 00:28:52,200
So how many questions, how else are you going to explain? Why I went over to the truck to buy the ice cream. I literally just is you know, that is the general sort of thing that when we're reasoning about other people's decisions, other people's behavior, and we're trying to figure out, OK, why did this person do what they did?

133
00:28:52,733 --> 00:29:10,967
You know, we're assuming it's a voluntary action, right? Or assuming it's not because there arm spasmed or, you know, because they have some really highly ingrained habit or compulsion or something like that. Right? I mean, we're talking about voluntary behavior, and that is just the way, right, that we tend to reason about how people do what they do.

135
00:29:11,0 --> 00:29:30,167
You know, either once that when somebody does something that's we think is weird, right? Then usually we have to explain that in terms of, OK, well, they just believe something that was incorrect, right? Or they had some really funny desire, right? That I don't really you know, it's it's tends to be one of those sorts of things. Right?

137
00:29:30,167 --> 00:29:56,800
I mean I mean, I don't know a lot of other, you know, separate folks psychological models that would entail anything different than this, you know, at a very generic level. And it's also exactly the sort of thing right. That that people try to contrast active inference with where where instead of, you know, belief, desire and desires coming together to form intentions.

139
00:29:56,800 --> 00:30:10,333
Instead, it'd be something like one kind of belief and another kind of belief coming together to form an intention, which again, for a lot of reasons, is, you know, confusing and rightfully so when it's presented that way.

141
00:30:12,367 --> 00:30:13,600
FRIEDMAN: Thanks. Yes. These groups so right when we've had some conversations with other authors and other papers where we've talked about the scale, three formalism, and we've also talked a little bit about the sort of scale friendly times when you have to find that history and that context, which you just mentioned, was sort of the generic generalized sense that the VDI umbrella provides.

143
00:30:13,600 --> 00:30:37,967
DEAN: These groups so right when we've had some conversations with other authors and other papers where we've talked about the scale, three formalism, and we've also talked a little bit about the sort of scale friendly times when you have to find that history and that context, which you just mentioned, was sort of the generic generalized sense that the VDI umbrella provides.

145
00:30:38,167 --> 00:31:17,233
You're not saying that scale three quantification and a generic way of modeling something are the same thing. But what I think I mean, without putting words in your mouth, are you saying that the scale freeness as it moves to something more scale friendly sweeps up some of that generic big tent idea or model and now moves it along, allows you to sort of pass and be specific and precise, precise, but also be able to generalize as you move through those, you know, qualifications of the distribution and density and such because that's kind of what I was reading into it.

147
00:31:17,500 --> 00:31:22,200
I just want to make sure that I got it. I was kind of maybe you can help me clean that up a bit. I mean, I really don't know that that weird thing really depends on or even gets into a lot of those sorts of specifics. I mean, really and really all we're saying is, is that, you know, if you want to take a model like that, the current act inference formulas in the current kind of like vanilla formalism, right?

149
00:31:24,167 --> 00:31:50,200
SMITH: I mean, I really don't know that that weird thing really depends on or even gets into a lot of those sorts of specifics. I mean, really and really all we're saying is, is that, you know, if you want to take a model like that, the current act inference formulas in the current kind of like vanilla formalism, right? So in terms of just the standard one or the comedy of hey or if you want to scale up hierarchically, it doesn't really matter.

151
00:31:50,500 --> 00:32:15,300
It is if you want to use the vanilla active inference framework to actually model some sort of voluntary decision process in a human right. So I'm in a lot of my work has to do with people modeling behavior on decision making tasks right. Often have to do with, you know, the person. The person has the goal of maximizing, you know, how much money they want or maximizing some sort of social reward or something like that.

153
00:32:15,767 --> 00:32:55,967
The idea is just that when you're trying to if you're going to take an active inference model and you're going to use it to model successfully model actual human behavior when they're making decisions, then there's always going to be a mapping between the different elements in the active inference model of voluntary behavior that or the whatever the prior, you know, prior preference distribution is you just set that so that it just adds the level of reward you know, so so there's really nothing about any super scale or anything like that.

155
00:32:55,967 --> 00:33:27,100
This is much more generic. It's just if you're going to use active inference to model voluntary choice, then it will always be something analogous to a belief and a desire because that's just what you need right? Like to model, to model voluntary behavior. It's true that, you know, that's probably if you're if you actually we're going to try to capture something kind of like more of the actual architecture around the brain as opposed to just this kind of like voluntary decision process aspect.

157
00:33:27,100 --> 00:33:54,133
I mean, I'm sure there's a lot of kind of hierarchy below that under the hood, right? That's translating more abstract policy selection processes into whatever the dynamic signals are that end up controlling, you know, moment by moment, muscle movements and things like that. But the point is, is that below below this kind of top level where you're doing policy selection at that point, you don't really need the desires anymore, right?

159
00:33:54,133 --> 00:34:21,567
You just need the policy to specify whatever the motor commands are going down that can take the form of predictions. So I don't I don't know if that helps, but it's just it's just that in a certain level, in any kind of hierarchy, of a model that's going to actually be applicable successfully to human behavior and at the level of policy selection prior preferences will just inform the desired outcomes.

161
00:34:21,800 --> 00:34:40,367
They'll just encode the goals that the agent's trying to reach. And the policy that's chosen will be evaluated as being the most likely policy, because it's the thing that's predicted to have the highest probability of getting the desired you know, generating the desired observation if I may also comment on that, and I'm not sure if this is answering your question, Dean, but the way I thought about it when I was reading the paper, was that part of the reason why the believe, desire, intention model kind of works or works well for for mapping the active inference ontology to the folk psychology ontology is because it's the discrete model in that it separates these these different

163
00:34:44,200 --> 00:35:13,433
JAKOB: If I may also comment on that, and I'm not sure if this is answering your question, Dean, but the way I thought about it when I was reading the paper, was that part of the reason why the believe, desire, intention model kind of works or works well for for mapping the active inference ontology to the folk psychology ontology is because it's the discrete model in that it separates these these different these different paths.

165
00:35:13,433 --> 00:35:42,300
And, and, and I think that also might have motivated the choice to consider mainly this preplanned piece and describe the decision, this decision act of inference in that in that way as well because then this discrete model can be more easily mapped to, say, the discrete model of the view MVP that that's described like a like a factory graph.

167
00:35:43,867 --> 00:35:52,133
I'm I'm not sure, but I, I was wondering how this would map to continuous tasks as well and. Well, I mean, I mean, I think the I mean part of the I mean part of the part of the reason why you need something discrete. Right. Is is because actions Mr. Sprague. Right. I mean, there's either one or this policy or this policy, right?

169
00:35:52,833 --> 00:36:33,500
SMITH: Well, I mean, I mean, I think the I mean part of the I mean part of the part of the reason why you need something discrete. Right. Is is because actions Mr. Sprague. Right. I mean, there's either one or this policy or this policy, right? So those those just are sort of necessarily the right I mean, you get the continuous databases work well or are appropriate at lower levels in a hierarchy, you know, and you're talking about kind of dynamics and motor movement that mimics in a set point of some reflects our core or when you're trying to estimate something in perception that, you know, just just as a continuous quantitate, right?

171
00:36:33,533 --> 00:37:07,33
Like brightness or, you know, orientation or things like that. But but the level of at the level of decision making and models are necessarily discrete. I mean, I mean, there is you know, there are there are kind of hybrid models, right. That are out there in the literature Thomas Park, for example, has published several papers visiting these sorts of models where the that kind of policy at the higher level, which is which is an industry model, generates some observation that at some point.

173
00:37:07,500 --> 00:37:42,67
Right. For some continuous or some continuous low level model that then you can end up in a in a way that's kind of like this kind of dark story, you know, like move the eyes around the car to different locations and things like that. So, so I, I kind of think that, that the discrete ness is the, or the, the, the reason why things move to a discrete space architecture is just because of the necessary what's necessary with respect to a model false reflection because it's kind of all or none just to keep the .00 ish.

175
00:37:45,567 --> 00:38:16,633
FRIEDMAN: Just to keep the .00 ish. We're going to move a lot faster through the following slides. And there's many important questions in the chat and, and also arising. So we'll just kind of carry on more rapidly so people can pick up on these key points in the zero. And we'll have a lot of time to explore in section two from predictive coding to active inference traces the history and the developments from various fields.

177
00:38:17,133 --> 00:38:40,767
And just one sentence here that the Dean and I both highlight it on and then Dean, I'll let you describe the button was that crucially, for the purposes of this paper, the first generation active inference was not a theory of decision making. It did not explain how we decide or plan where to move our body. It only explained how body movements can be executed using the predictive coding apparatus.

179
00:38:40,933 --> 00:38:45,367
Once a decision has been made. So how did you connect that to the bottom? Right. Yeah. So if you're on a if you're on a some sort of a website and you have to pass through to something, my question was based on that statement, when the expectation is to know that you've actually crossed the threshold you've moved beyond one page and there's an expectation that there's something that you validated or confirmed or whatever, is the feedback that you receive, does that have how how does the person who's actually expecting that they're on the other side, what kind of feedback mechanism do they need to for that confirmation is tactile feedback enough?

181
00:38:46,333 --> 00:39:23,167
DEAN: Yeah. So if you're on a if you're on a some sort of a website and you have to pass through to something, my question was based on that statement, when the expectation is to know that you've actually crossed the threshold you've moved beyond one page and there's an expectation that there's something that you validated or confirmed or whatever, is the feedback that you receive, does that have how how does the person who's actually expecting that they're on the other side, what kind of feedback mechanism do they need to for that confirmation is tactile feedback enough?

183
00:39:23,167 --> 00:39:50,800
Do they need some sort of a visual confirmation as well? Like what is the what's the it is there because we're talking about thresholds. Is that different for every single person? Or is that sort of expectations built in depending upon the kind of situation that you're dealing with? I do know that with that, the idea that like changes are saved or links are copied, sometimes the click isn't enough to give people confidence that in fact that process is carried through.

185
00:39:52,167 --> 00:40:12,867
SMITH: I mean, I would I would say that I mean, a lot of those questions are really empirical. Empirical questions is the best modeling questions. You know, I mean I mean, in terms of in terms of how you would model that sort of thing, right. You to specify what observations kind of tactile. You specify what observations concept at all and what ends up being thresholds, perception, evidence and things like that.

187
00:40:12,867 --> 00:40:53,33
Just that's not the way that and processes just have the dynamics naturally unroll in the model under whatever the model parameters version is, you know, so so you'll hit a threshold feature if the mapping between observed whatever observations and states is more precise, for example, I mean, there's, you know, in relation to in relation to that when we're doing policy selection right we also have to check and see whether things are actually going as we expected them to go under a choice of policy, it's possible that you choose policy one and you start to get the subsequent observations and they don't actually match what you expected.

189
00:40:53,400 --> 00:41:16,433
You know, given that you've chosen policy, one in which case you'll update your beliefs through perceptual inference and that might influence how you act going forward. So so but are the specifics about, you know, what's enough and whether it's visual or tactile or anything like that? I mean, those are those are really just empirical questions that would have to be answered in studies as opposed to something about model choices.

191
00:41:17,233 --> 00:41:41,0
DEAN: OK, so there was really not a good enough thing when you did the darkroom aspect of it, like at the risk that you were prepared to take on. Right. Like somebody was prepared to take on the risk because they really urgently wanted the ice cream versus the person who was like, yeah, I'm agnostic. Right? So that's maybe that's kind of what I was because this was on the second reading of your paper, right?

193
00:41:41,0 --> 00:41:45,133
So I was kind of now back feeling from further down in the paper. So. Well, I'm into that yeah. We'll go in the audience because we're mentioning things that we haven't brought up yet, but let's continue on and we'll return to that. And Ryan, I also agree that in any specific case, it's going to be a model parameter decision.

195
00:41:45,800 --> 00:41:47,633
SMITH: Well, I'm into that yeah.

197
00:41:47,633 --> 00:42:19,667
FRIEDMAN: We'll go in the audience because we're mentioning things that we haven't brought up yet, but let's continue on and we'll return to that. And Ryan, I also agree that in any specific case, it's going to be a model parameter decision. Some of these are very difficult to answer in the abstract model selection setting here. The distinction between motor active inference and decision active inference is introduced and all allow you to just convey one pass.

199
00:42:20,133 --> 00:42:24,200
What is the difference between motor active inference and decision active inference.

201
00:42:26,933 --> 00:43:10,67
JAKOB: So I'm not sure whether I can say much. That hasn't been said yet. But you know, briefly the Motor Act of inference is does well. As already mentioned, it does not consider desire desires and the in the active inference and for psychological sense as was then connected in the bit in the paper. But also it is my understanding that the motor control version of active inference is modeled continuously like the models of of the movement of individual muscles, which does not entail decision making.

203
00:43:10,67 --> 00:43:56,800
So it's modeled with continuous time rather than in discrete time. And that's decision making act. And as Ryan already said as well, is all about decision making. So it describes the discrete process of decision making with prior beliefs and preferences. And it can I and it can be model at different different levels of cognition as well. Which is one thing that I'm still a bit uncertain about how we can move through these different layers while still keeping the same mathematical formulation but I think we'll probably get to that in the other slides.

205
00:43:58,533 --> 00:45:05,767
FRIEDMAN: Yep. We're going to continue with this distinction of am I for motor active inference and DTI for the decision active inference here we're showing some key sections from the paper and some citations I think we will continue on without going into this in depth, but it describes some of the specific model quantities that are being described in active inference formalism, and we're going to come to them when we look at some equations in the coming slides in section three, preliminary considerations, two broad points are introduced and we might show a second one on a later slide how can we think, Ryan, about what is said here, that decision making models are largely taken to describe

207
00:45:05,800 --> 00:45:29,0
some personal non conscious processes? And also it was asked in the chat not that we have to address it now by doing it. Has active inference produced a single reasonable model of equality? So when we're thinking about this first broad point that was made here, where is experience and what is the distinction between the personal and the sub personal?

209
00:45:29,0 --> 00:45:29,733
And I um, well, I mean, so there's a couple of different questions you asked there and I don't necessarily think they're synonymous. So when you said I think the first question you ask was something about has active inference provided some sort of explanation or model of, of qualia that would be satisfactory in the strong sense on the Sentinel in the sense of quality as an explanation for the hard problem of consciousness, then I think active inferences in the same place as anyone else and no one has a good explanation for or how to deal with the hard problem of consciousness.

211
00:45:32,67 --> 00:46:07,33
SMITH: Um, well, I mean, so there's a couple of different questions you asked there and I don't necessarily think they're synonymous. So when you said I think the first question you ask was something about has active inference provided some sort of explanation or model of, of qualia that would be satisfactory in the strong sense on the Sentinel in the sense of quality as an explanation for the hard problem of consciousness, then I think active inferences in the same place as anyone else and no one has a good explanation for or how to deal with the hard problem of consciousness.

213
00:46:07,33 --> 00:46:38,867
Right? I mean, like it's massive literature out there, but I think everyone thinks it's just as mysterious as ever. So so no. Right. I mean, on the other hand, I mean, you know, myself and others have published multiple papers showing how you can successfully use active inference models to to model conscious access processes. Right? So the distinction between when the brain is representing something unconsciously versus when it's representing something consciously, you know, in that it can, you know, self-report, right?

215
00:46:38,900 --> 00:47:05,200
What it's representing can use the information to make voluntary choices. And we've shown that those sorts of models are able to reproduce like empirical results and like EEG studies and MRI studies and things like that that are now and that also can make novel neurophysiological predictions, some of which seem like they, you know, in some subsequent work have empirical support for those predictions.

217
00:47:06,133 --> 00:47:28,100
So so in terms of providing a, you know, a what seems like a useful account of the processes associated with what people self-report that they consciously experience and and the brand basis for that, I think act of inference has at least the starting, you know, the starting starting point for for being useful and explaining those sorts of things.

219
00:47:28,100 --> 00:48:00,133
But, you know, why one little posterior inside a model versus another posterior in a model actually corresponds to like the experience of red versus blue or something. I mean, no, I don't I think act of inferences is not any better than anyone else of, you know, any other model for that question. The I guess the second thing that you asked had to do with this kind of like related question of why it's the case that one level has to do with a conscious process for his unconscious process and the best ever really got there.

221
00:48:00,133 --> 00:48:20,333
And you know what, what falls out of the models that we have shown really just have to do with temporal scale, you know, so there's no there will be a certain level of temporal representations in a hierarchical model that that integrates enough and represents regularities over a long enough timescale that it can contribute to a sort of perspective.

223
00:48:20,433 --> 00:48:46,400
And it'll be sufficiently compact to generate things like soul works. Right? So I mean, think about how complicated and temporally extended we're performing and choosing to report something like, you know, I see something green in front of me, right? I mean, that's a very complicated and really deep and type of policy to select. And it requires integrating a bunch of information from stuff at lower levels that's happening over faster time scales.

225
00:48:47,500 --> 00:49:18,267
So at a minimum, right? You just need to be at a level of representation where the regularities are sufficiently sufficiently long and especially temporally deep, and then have access to all the relevant information you need to integrate to be able to generate reports like that. Whereas whereas much of the other kind of little pieces in the model, right, like, you know, that generated say like expecting error for like Variational for energy gradients and things like that, that people like all like surprise, right?

227
00:49:18,267 --> 00:49:36,967
I mean, no one's claiming that and often they will not relate in any way to people's conscious reports about the surprise because conscious reports about feelings surprise will have to do with representations of surprises in states. Right? As opposed to, you know, some sort of prediction error or like gradient minimization process. So thanks also in section three, there are several clarifications and some seeds that are planted, namely if computational and folk psychological predictions converge and no other available theory can account for behavior equally well.

229
00:49:37,367 --> 00:50:17,967
FRIEDMAN: So thanks also in section three, there are several clarifications and some seeds that are planted, namely if computational and folk psychological predictions converge and no other available theory can account for behavior equally well. This could entail the mathematical structure of DI as more than a convenient tool. Instead, that it corresponds to the true information processing structure underlying in enabling folk psychology and related abilities.

231
00:50:18,433 --> 00:50:47,0
And this is really nicely put here that the crucial point remains that one should not conflate mathematical and psychological levels of description. However, DI models might nonetheless offer more detailed information about the true form of folk psychological categories and processes. And then they add that their aims are to demonstrate that there's a clear isomorphism between the elements of models and those of the BDI model.

233
00:50:47,433 --> 00:51:17,133
And then show how provided one does not assume probability distributions in computational models must be identified with beliefs at the psychological level, there will be no tension between DJI and PDI, and that comparison or juxtaposition is clarified by separating AI from day I like has been mentioned. Anything else before we start to jump into some of the Formalisms and keeping all of this in mind.

235
00:51:20,967 --> 00:51:56,333
JAKOB: I guess I had one question on on the on which ontology we're working with when we say there's a isomorphism between the elements of die models and those are the Beauty II model because I think there are multiple ways to interpret this one. One thing that I'm wondering about is whether this means that we can basically construct a mathematical formulation of the of the body on a model that is like a subset of active inference.

237
00:51:56,333 --> 00:52:22,33
Or maybe, maybe there are certain certain elements of the body model that aren't necessarily encapsulated by the Nocturnes that weren't discussed in this paper. And what the that would mean in terms of formulating this mathematical mathematical formulation of, of the body model.

239
00:52:23,867 --> 00:52:45,833
SMITH: So, I mean, what the isomorphism just means is tell me the description at one level and I'll be able to translate it for you very quickly and directly into whatever the description is at the other level in both directions. Right? I mean, so just means tell me, tell me what, tell me what it is that you want. You know, if I say, do you want ice cream or do you want a pizza, right?

241
00:52:46,133 --> 00:53:07,567
Tell me, tell me that you like if you tell me that you like you want pizza twice as much as you like ice cream, then it's very easy to just put that out for, you know, in the you know, in the in the distribution and in the preference distribution over the observation of pizza and the two for ice cream and then sock max it and log it right.

243
00:53:07,567 --> 00:53:27,167
And then like, you know, there's that's the description, right? So just in a very direct way, it just encodes relative desires for one thing versus another. To my your beliefs are right. I mean, if you believe the pizza is to the left or to the right, I can put that in as the different categories of hidden states. So you're going in for a distribution over right.

245
00:53:27,167 --> 00:53:49,900
So like it's just the point is, is that in either direction? Right. Give me the full psychological description. I can translate it very straightforwardly. Using the same elements every time as being desires or beliefs. Give it to me at the at the mathematical level. I can translate that into the description terms of beliefs and desires. I mean, it's just it's just one to one.

247
00:53:50,867 --> 00:54:08,600
I can't think of an example offhand where there would be any kind of like mismatch or an ability for one to account for the other. But, you know, it's kind of hard to prove a negative. Right? So I mean, maybe you can give me an example, but I can't think of one awesome. Yeah. Yeah. I was just going to say that I can't really think of an example right now.

249
00:54:09,400 --> 00:54:09,600
FRIEDMAN: Yeah.

251
00:54:10,833 --> 00:54:33,533
JAKOB: Yeah. I was just going to say that I can't really think of an example right now. I, I I just found it really interesting with the usage of, of just the word isomorphism because that like, as you, as you said, it's just a by bidirectional and subjective map. So it's basically equivalent, it's just set in a different way.

253
00:54:34,100 --> 00:54:53,433
So I can imagine that meaning that we can basically instead of the Wikipedia page where the BDA model using all of these terms and like leave desire intention, it could just be a set of active inference equations. And that's the beauty I model because it's an isomorphism.

255
00:54:54,0 --> 00:55:18,233
SMITH: Right? I mean, literally your your beliefs or just your cues, right? And your and your desires are just your prose, right? I mean, in I mean, and, you know, the way that we've, you know, we and others have tended to write it now, right? Is to literally, just explicitly to say like the desires are or the preferences aspiration is given.

257
00:55:18,233 --> 00:55:35,333
See, right? Or see is just a matrix that defines your preferences. Right? So I mean, it's a lot clearer to do that than to just just just leave it just though, right? I think that's part of the confusion is this is that it's not clear where the preferences come from, but they're just it's just because they're conditional on this other thing.

259
00:55:35,333 --> 00:55:35,667
See, and see can be fixed or learned. But that's the basis of the calculation there. Yeah. Here we get into section for variational and expected free energy considerations. And in large script we see the variational free energy equation Dean, what is the skydiver doing? And during the one in the two, we'll unpack more about the exact terms and and what is coming into and coming out of this equation.

261
00:55:37,533 --> 00:55:41,833
FRIEDMAN: And see can be fixed or learned. But that's the basis of the calculation there.

263
00:55:42,733 --> 00:55:43,33
SMITH: Yeah.

265
00:55:44,67 --> 00:56:13,100
FRIEDMAN: Here we get into section for variational and expected free energy considerations. And in large script we see the variational free energy equation Dean, what is the skydiver doing? And during the one in the two, we'll unpack more about the exact terms and and what is coming into and coming out of this equation. But just as an appetizer here, what's the skydiver doing?

267
00:56:14,267 --> 00:56:31,167
DEAN: Well, now I've got the answer here. I just threw that in there because I like to I don't think it's a metaphor, but the analogy of a so how do you respond when you jump out of the airplane and, you know, your parachute is not going to work? Do you do you go ahead first and really attack it or like, what now?

269
00:56:31,167 --> 00:56:44,133
What are you doing in terms of what your expectations are so maybe maybe that that was a good analogy, right? Maybe like so what we are where we are going with that because. Yeah, well, I mean, I think the point the point of those sorts of examples are just to just to try to put this to to show why it's not it's not really correct to think about them like prior, you know, the prior preference distribution, even though it's, you know, it's again, it's cast as a prior belief.

271
00:56:44,967 --> 00:57:15,767
SMITH: Well, I mean, I think the point the point of those sorts of examples are just to just to try to put this to to show why it's not it's not really correct to think about them like prior, you know, the prior preference distribution, even though it's, you know, it's again, it's cast as a prior belief. Right. And not really appropriate to think about that as a as a belief per se.

273
00:57:16,100 --> 00:57:44,133
Right. I mean, or an expectation at any at a psychological level description. So you can and the way to contrast that, right, is you can say like like the person in a model where they don't want to fall to the ground and die. Right. That would be in the. Yeah, that would be the right it's your preference not to have the observation of hitting the ground and dying, but where you are at.

275
00:57:44,433 --> 00:58:04,633
Right. Is, is your cue about given high, right? It's what do I expect to observe given that I choose this policy versus that policy. Right. So that's the that's the belief part is what I expect given that I do this or that. And, you know, how close is that to how much does that diverge from what I what I want?

277
00:58:04,633 --> 00:58:22,867
Right. Which your vow so it's just a it's just a clear example of how your belief, the expectations and your desire, the expectations come apart and it just doesn't work conceptually. I think one is that I think of one as like the same kind of kind of thing as the other.

279
00:58:23,967 --> 00:58:31,700
DEAN: Yeah. I just saw it as if I'm not going to get a soft landing. How big of a creator can I can I create that? Well, but that's that then is going to be packed into your preference distribution. Right? Right. I would have some desire for to make a big conditional on you're going to die, right? You know, you'd prefer right.

281
00:58:31,700 --> 00:58:49,867
SMITH: That then is going to be packed into your preference distribution. Right? Right. I would have some desire for to make a big conditional on you're going to die, right? You know, you'd prefer right. To make a big crater that small crater, and that would still just go in your favor. All right. So yeah. Yeah.

283
00:58:52,233 --> 00:59:22,400
JAKOB: Yuka I was just wondering, and this might be me thinking thinking to the OR not too deeply about the equation, rather, but in this, in this formulation where it's a variation of three energy for each policy and what pi does that does that imply when in the last sentence on this slide that free energy is a function of beliefs and a function of observations?

285
00:59:22,400 --> 00:59:48,733
That doesn't mean that the three energy is essentially a function of three variables, but in this case, we are only writing it off of PI because it's always it's it's clear that it's a function of beliefs and observations or should we think of it more as just a function of each policy? I mean, the way it's written here, I'm going to think that most preferred way to think about it is I mean, it literally just means that using this equation, you will calculate a different best value for each policy.

287
00:59:50,500 --> 01:00:12,433
SMITH: I mean, the way it's written here, I'm going to think that most preferred way to think about it is I mean, it literally just means that using this equation, you will calculate a different best value for each policy. Right? I mean, that's really like you just there will be you're going to be computing some, some variation for energy value for each policy, and that's going to make up a distribution over policies.

289
01:00:14,233 --> 01:00:40,933
And and I mean, the tricky thing, I guess here is, is, is that, you know, this isn't about this is an F of F apply here isn't about making decisions, right? This is just about something like evaluating evidence for you. For various policies. One, because you you can't you calculate f when you already have the observation, right? So so you can't really do this prospective decision making thing with F.

291
01:00:41,867 --> 01:01:03,200
So this is just basically a way of describing how how underage policy your beliefs will change or wouldn't change right under you know, when you get conditional an observation that you got and and so it's not a yeah. So all it denotes really is this just you have a value of F for each policy and that makes a the distribution.

293
01:01:04,867 --> 01:01:41,600
FRIEDMAN: And that takes us to G expected free energy the letter after F and as shown here not sure if there's another reason for why it's G. This is equation 2.6 from the active inference textbook. Just for reference with some other versions of how G is framed G is a prospective value and they write decision making does not only require beliefs about past and present states it also requires making predictions about future states and future observations.

295
01:01:42,33 --> 01:02:04,133
This requires taking the average i.e. expected free energy g of pi given anticipated outcomes under each policy that one might choose. And there's a lot to say on expected free energy. What is just one short note that somebody could add? Or Ryan, why was it placed here?

297
01:02:06,267 --> 01:02:10,700
SMITH: Um, I'm not sure I understand the question. Like, why was why is why is expected free energy required? Why is variation of free energy not enough expected for energy is just as just what the system is trying to minimize when it's selecting a policy. Right? So I mean, it's just trying to I mean, in this I mean, this composition right here is often called like the risk risk plus ambiguity, decomposition.

299
01:02:11,267 --> 01:02:15,833
FRIEDMAN: Why is why is expected free energy required? Why is variation of free energy not enough.

301
01:02:17,967 --> 01:02:58,267
SMITH: Expected for energy is just as just what the system is trying to minimize when it's selecting a policy. Right? So I mean, it's just trying to I mean, in this I mean, this composition right here is often called like the risk risk plus ambiguity, decomposition. But I guess I like I think that I think that showing the the risk term the risk term here provides a nice intuition for for again, the separation between beliefs and desires and act of inference because you're you're set up the the term underlined and and red then right so the divergence between zero given pi and five.

303
01:02:58,267 --> 01:03:31,633
All right. I mean, that's just saying that you know how different are the observations I expect given that I choose given policy and how different how how different is that? How do I expect that to be from my my preferences or my desires? Right. Well, so the the closer those are together, the more the more similar I expect the observations to be under a policy to my preferred observations, the smaller that's going to be.

305
01:03:32,33 --> 01:03:55,0
And so if I'm trying to select the policy that minimizes G right, then that means I'm going to select the policy that's going to get me as close as that's going to get me as close to my preferred observations as possible. Right. So literally just is that tail divergence literally just as trying to choose the policy that brings beliefs closest to desires very nice.

307
01:03:55,0 --> 01:03:56,733
FRIEDMAN: And then what does the blue term mean?

309
01:03:59,167 --> 01:04:25,167
SMITH: And that's just entropy term, right? So I mean, it's just basically saying that the is what drives information seeking or part of what drives information. So again, it's just it's just yeah, basically the agents choose driven to choose policies that also are going to generate more precise expected observations, observations that are going to disambiguate states are more easily great here.

311
01:04:25,167 --> 01:04:46,600
FRIEDMAN: We'll explore it more in the dark one. But there's a description of the posterior probability distribution over policies. P of pi and an expression involving the soft max symbol with the sigma. We'll return to that later. But this is just so that we can cover like the key experiments in the simulation results today.

313
01:04:48,967 --> 01:05:30,800
This is also one other area of formalism we can explore in the coming discussions. About precision and the relationship of beta and gamma and what the convergence towards means. But we won't go there. There is precision parameter in this model let's go to the dark room problem and many lines of PDF screen and ink has been written on the dark room in the active world since perhaps first in at all 2012 and also outside of active and they write.

315
01:05:31,233 --> 01:06:02,600
In a nutshell, the concern is that if agents only act to minimize prediction error as opposed to acting under the impetus of a cognitive desire like state, then they ought to simply seek out very stable, predictable environments such as a dark room and stay there would anybody like to add anything about this dark room problem or what is the relationship between docs, artistic and cognitive ontology and active I mean, are you just asking what like what those words mean or what like I mean, how do you how do you use these words?

317
01:06:08,833 --> 01:06:13,367
SMITH: I mean, are you just asking what like what those words mean or what like I mean.

319
01:06:13,400 --> 01:06:15,67
FRIEDMAN: How do you how do you use these words?

321
01:06:16,767 --> 01:06:44,867
SMITH: I mean, I mean, forecasting is just a term that refers to belief, you know, like epistemic sorts of things, right? So so a diagnostic ontology would be an ontology that includes belief things, right? Whereas whereas, you know, cognitive just refers to being like targeted toward something, right? Like something about desires or something things you want versus don't want things you like versus don't like.

323
01:06:44,967 --> 01:07:05,500
Right? So it's just, you know, when we say it's apparently purely a tastic ontology, as you're saying, it might look as though superficially like the the ontology proposed an act of inference, like the things that exist and act of inference are purely beliefs. That's all that means. Great. And it's applied in the setting of this dark room for the following two slides.

325
01:07:06,733 --> 01:07:22,400
FRIEDMAN: Great. And it's applied in the setting of this dark room for the following two slides. Dean, help us understand what concerns are addressed and what the child on the top of the slide is doing.

327
01:07:23,967 --> 01:07:49,100
DEAN: Yeah, OK. So I'm not going to go through all, all of the text, but essentially this was my introduction to the dark room problem because it was kind of the opposite of my experience, which is that I tend to find people that are curious and we're trying to move away from information leveling, leveling off or or being static to information gain.

329
01:07:49,100 --> 01:08:16,400
So first of all, I had to learn what but the what the argument was about why people would actually, you know, who are normally social, why they would move away from that social realm and into this sort of dark space under the under the idea that active inference is actually implies that that's what people would do and then secondly, it was I was kind of trying to tie it into the idea of the refrigerator and where it is.

331
01:08:16,600 --> 01:08:46,33
And until you actually understand it, can you and I talked about this a bit, the pragmatic piece of till you actually open the refrigerator door, which is on that kind of the next slide, you don't really I mean, you can have a belief that there's something of value in there, but it can turn out that when you open the door or Monti raises the curtain, the thing that you were expecting turns out to be a value, but not necessarily of that thing that you were you are setting yourself up to believe.

333
01:08:46,567 --> 01:09:14,833
And so that that young individual spitting the coin out. And maybe I guess I was just trying to be a little bit facetious there that it holds value, but it doesn't hold the same kind of tasty value as, say, having a lick of an ice cream cone. So, again, it was it was trying to move away from the idea that the belief is that alone is status satisfactory or necessary.

335
01:09:14,833 --> 01:09:35,800
I always get those two mixed up, but I think I was just trying to reinforce the idea that you kind of need to have both so that you can compare and contrast, so that you get a sense of what a person or what an agent is doing as they're getting past some of those shrouds or some of those non observables into the observable state.

337
01:09:38,933 --> 01:10:09,233
FRIEDMAN: Thanks will keep going this is unpacking some of the concerns about the apparent pure docs artistic, belief oriented ontology of acting. So Ryan described earlier like is it about beliefs colliding? And if so, if it's purely docs artistic, then where is this desire? And is there anything else that anybody wants to add here?

339
01:10:11,400 --> 01:11:14,167
JAKOB: I would maybe comment that I think this also relates to your to the earlier thing that was discussed how this confusion might stem from people misinterpreting or confusing the terms predictive processing and act of inference. And I feel like this addresses it as well where if we just if it's only beliefs then there is obviously a concern that once we're in a dark room, we can because if we're only in the regime of predictive processing, there's no way for us to move to a different state or there isn't the formalism that that describes planning an action but as I guess we'll get to the other slides when we do include this planning, we suddenly have

341
01:11:14,567 --> 01:11:18,300
designer like terms appearing within the mathematical formulation as well.

343
01:11:21,0 --> 01:11:21,267
Right?

345
01:11:23,567 --> 01:11:45,833
SMITH: Yeah. And I want to be clear, it's not like they're thrown in ad hoc, right? They emerge naturally as like necessary components of America, you know, using this sort of framework or building it out to involve planning. So it's not like that. They emerge naturally and necessarily it's not it's not because someone's just kind of talking them on great.

347
01:11:46,333 --> 01:12:13,300
FRIEDMAN: And this is referring to that minimization of the minimization of G drives the agent to seek out observations that will reduce uncertainty about the best way to subsequently bring about phenotype congruent or preferred outcomes. So that's the information seeking another way to put this is that under AI, an agent doesn't simply seek to minimize prediction error with respect to its current sensory input.

349
01:12:13,733 --> 01:12:42,267
It seeks instead to minimize prediction error with respect to its global beliefs about the environment, which entails seeking out observations that are expected to generate prediction errors such that uncertainty is minimized for the generative model as a whole. And another aspect of this type of global prediction error minimization process is that it pertains not only to beliefs about states in the present, but also to beliefs about the past and in the future.

351
01:12:42,967 --> 01:13:10,200
And so this is leading to one of the claims, which is that in addition to desires, Die captures folk psychological experiences associated with the drive to both know about one's current status and learn what will happen when choosing to move to other states, among other parameters. In a generative model let's go into this generative model and come to the darkroom simulation itself.

353
01:13:12,400 --> 01:13:41,800
And we'll unpack it more in future times. But the prior over policies E of Pi, they write that when the agent repeatedly chooses a policy, this term increases the probability that the agent will continue to select that policy in the future. At the level of the formalism. This corresponds to an agent coming to expect that it will choose a policy simply because it has chosen that policy many times in the past.

355
01:13:42,433 --> 01:14:02,200
This can be thought of as a type of hybridization process, but it doesn't have any direct connection to preferred outcomes because E of PI is not informed by other beliefs. In the agent's model. So here's the partially observable Markov decision process, just one representation of it, and E is sort of floating there, influencing, but not being influenced by.

357
01:14:03,33 --> 01:14:41,567
And we had some interesting discussions which we can return to another time about how we might be able to assess whether somebody is engaging in a behavior because they simply have habitually engaged in that behavior, but they understand the actual mapping of how policies relate to outcomes, or in another case where somebody might be engaging in a behavior not because of habitual action, but rather because they have some sort of deviation from the appropriate mapping between policies and outcomes and maybe there's other ways.

359
01:14:41,867 --> 01:15:11,867
So I thought that was very interesting how even within the same sort of sparse and first principles model similar behavioral outcomes might be observed on like a behavioral manifolds, and then different kinds of perturbations or evaluations might reduce uncertainty about what is giving rise to those conversion behaviors. In that case, OK, Dean, with the ice cream truck and the I now I'm going to I'm going to wait because I think that's I think this one in the and the next one are better to take up in a 12 part because pick up because if Ryan can come back, there's some good questions I want to ask him about those two sections because this slide and

361
01:15:12,733 --> 01:15:35,233
DEAN: Now I'm going to I'm going to wait because I think that's I think this one in the and the next one are better to take up in a 12 part because pick up because if Ryan can come back, there's some good questions I want to ask him about those two sections because this slide and the next one are kind of anti dark room.

363
01:15:35,733 --> 01:16:10,700
And so I want to kind of pick his brain about what, you know, how we can sort of convince people that that that dark room problem is for such a small subset of the population. That majority of the stuff that we're talking about here is done in in sort of social settings and social context and there's a third party sometimes you can observe an observer and what role that plays in trying to figure out what's what's going on here as we move from that from the idea of decisioning and and so forth.

365
01:16:10,700 --> 01:16:11,500
So I'll wait. Great. So here's part one of that and here's part two looking at social learning theory a little bit. But let's go to the figure and to the simulation this is figure one simulation of an active inference agent deciding whether to eat some ice cream and there's various ways to go about describing it. But one of the key pieces that anyone can give remark about what is occurring here is that there's three cases that are being compared.

367
01:16:12,100 --> 01:16:48,400
FRIEDMAN: Great. So here's part one of that and here's part two looking at social learning theory a little bit. But let's go to the figure and to the simulation this is figure one simulation of an active inference agent deciding whether to eat some ice cream and there's various ways to go about describing it. But one of the key pieces that anyone can give remark about what is occurring here is that there's three cases that are being compared.

369
01:16:49,100 --> 01:17:16,900
There's a no desire case, a weak desire reflected by this pillow and a strong desire case where the ratio between the two alternatives, between wanting the ice cream and or between the ice cream state and the no ice cream state is a sharper distinction in this second row. So there's a case in which ice cream is in the fridge, but where the kitchen is currently dark.

371
01:17:16,900 --> 01:17:46,900
And so the agent doesn't know whether the fridge is to the left or right. So it's like a TVs set up with three possible cases, one where there's no preference for observing ice cream or not a weak or a strong preference for that. And then under these situations, we can ask about what happens in terms of the action as well as the beliefs and valence updates.

373
01:17:47,800 --> 01:17:49,167
What else would you add about that? Right well, I good point. You know, the point of this is just to show why I guess mix of events have been mentioned. Know the issue with the dark room, right? I mean, as I said, I mean, as you said, I mean, this is essentially just that a particular very similar to to like a tmas, right?

375
01:17:49,167 --> 01:18:22,833
SMITH: Right well, I good point. You know, the point of this is just to show why I guess mix of events have been mentioned. Know the issue with the dark room, right? I mean, as I said, I mean, as you said, I mean, this is essentially just that a particular very similar to to like a tmas, right? I mean, just putting it putting a different sort of semantics on top of it, you know, but the idea is just that it's just set up to show that, you know, even without any kind of desire.

377
01:18:23,200 --> 01:18:51,433
Right? Just, just resolving uncertainty the agent will be driven to leave a dark room or do something to get rid of the dark room. And so you don't need a desire. Right. But but in fact, any realistic agent is also going to have desires. So so in the case where there are desires, then there's two different reasons why no active inference agent will ever stay in a dark room or be motivated to stay in a dark room.

379
01:18:51,433 --> 01:19:24,200
Like in all cases, it will have a motivation to to leave so I mean, the point is just to show. Right. And some explicit simulations that generically. Right, like this kind of dark room problem this will it will just never apply. To talk of inference again, this dark room thing only applies if you assume the thing is just doing something like predictive coding, but then somehow also assume that it's making decisions but that's not active inference.

381
01:19:26,600 --> 01:19:28,0
Because it's not a theory of decision making.

383
01:19:31,67 --> 01:19:31,800
FRIEDMAN: Awesome.

385
01:19:35,300 --> 01:20:17,233
Here is some description about the strength of the desire could have been shown before the figure. But we wanted to introduce the the simulation setting and as described, there is a desire as well as an information seeking. And I believe that's the two reasons why the agent will escape the dark room. And there's there's other escape hatches depending on how one constructs their model, potentially like a hierarchical model might have a slightly different explanation for why an agent does or doesn't stay in the room.

387
01:20:17,467 --> 01:20:29,167
But even just within this single level model, there's an information seeking as well as a preference realizing reason any other comments here?

389
01:20:33,633 --> 01:20:34,933
OK, Dean, just a quick think of maybe right in the island. I'll put you in the island. Go for it. Yeah, so maybe Brian, just just a just a quick this last, last couple of senses, however, preference distributions are set to zero. Oh, I'm sorry. I saw the previous slide. No, sorry. Can you go back one? Yeah, go for it.

391
01:20:35,767 --> 01:20:37,467
DEAN: Just a quick think of maybe.

393
01:20:37,467 --> 01:20:40,533
FRIEDMAN: Right in the island. I'll put you in the island. Go for it. Yeah.

395
01:20:41,567 --> 01:20:53,333
DEAN: So maybe Brian, just just a just a quick this last, last couple of senses, however, preference distributions are set to zero. Oh, I'm sorry. I saw the previous slide. No, sorry. Can you go back one?

397
01:20:53,367 --> 01:20:54,100
FRIEDMAN: Yeah, go for it.

399
01:20:54,667 --> 01:21:20,533
DEAN: OK, so however, your preference distributions are set to zero, as in our no desert simulation, such the no outcome is desired over any other, and active interpretations will nonetheless be driven to choose behaviors that will maximize information gain. OK, that all makes sense. That's just the background. This is the part I was curious about. While this might reasonably be considered a motivational influence, it is prima facie less plausible that it should be considered cognitive.

401
01:21:21,133 --> 01:21:45,967
I mean, therefore be better seen as a type of dark, sarcastic drive here the formulas and may therefore help us to recover and potentially nuance this folk psychological distinction between desire and curiosity. These types of drug drives seem to differ fundamentally. I agree with you, but I was wondering if you could maybe explain why that should be something that we should keep separate.

403
01:21:46,200 --> 01:21:55,967
The idea of desire and curiosity I know you go into explaining it a little more into the paper, but why did you want to point that out to readers? Well, I mean, I think there's a couple of things I mean I mean, one, I think that these things are both driving, you know, decisions about what to do, right?

405
01:21:57,133 --> 01:22:40,533
SMITH: Well, I mean, I think there's a couple of things I mean I mean, one, I think that these things are both driving, you know, decisions about what to do, right? So in some way, they motivate they both motivate behavior right? But at the same time, you know, and I think this is something that Alex Cooper pointed out when we were writing this, as opposed to just you know, so it's not just me pointed out that, you know, there is this kind of fairly clear difference between the this, you know, curiosity or epistemic driven sort of behavior from the kind of desire driven behavior and the the kind of clear differences is that this epistemic driven

407
01:22:40,533 --> 01:23:12,167
motivation isn't it isn't driven toward anything. Right? It doesn't have a target. It's not trying to get one thing versus another all it's trying to do is just just become clearer about what's out there, essentially. Right. So the fact that it lacks a target is really, I think, what makes the what makes the distinction clear. But I mean, beyond that, I think the motivation was just to was just to show that you know, like just generically, right?

409
01:23:12,167 --> 01:23:50,633
Like the belief desire, intention, principle doesn't really doesn't really say anything about know types of types of desires. There's nothing really explicitly just in that very, very simple way of describing the framework that that separates out information seeking from from reward seeking. Right. So, you know, so you could write if all you're doing is trying to compare active inference to do the VDI model very simply stated, then then this is able to kind of nuance a little more.

411
01:23:51,67 --> 01:24:25,433
Right? Like different, different things that that might look like, you know, monitor motivation and all kinds of things but but then are separated those on why decisions are made for one thing versus another that are more kind of tied to beliefs in a different way. That being said, I mean, at the same time, I think that you know, black folks psychology more more broadly, I think I think very intuitively and naturally does recognize the difference between things like curiosity.

413
01:24:25,833 --> 01:25:01,133
Right. And things like and things like reward driven behavior. Right. Those are concepts that we have just in our natural kind of folk psychology setting. And so active inference captures those, right? I mean, I yeah, I talked about this just as an example of how intuitive I think and like natural this sort of aspect, as you know. And I just think of like most of the behaviors that say like my little dog does, you know, if I look at if I look at what my dog does, 90% of the time, it's way more information seeking than it is reward seeking, you know, searches out for some food a couple of times a day.

415
01:25:01,533 --> 01:25:22,433
But I take her in the car and she's bottom left and right to see what's out the window and how that changed all the time. You know, any little sound perks up looks right nonetheless as a reward driven. They're all just information seeking. So I mean, very, very clearly that's a big part of what drives us and other animals to do so.

417
01:25:22,433 --> 01:25:37,267
So the point is just that just to kind of show that actual inference captures that in a certain sense. It adds some granularity to them to at least what the model says. But but in that case, the model is kind of to a two horse grand. And I think normal psychology doesn't include those things already. Great all sorts of to be returned to Dean.

419
01:25:39,267 --> 01:25:44,100
FRIEDMAN: Great all sorts of to be returned to Dean.

421
01:25:45,900 --> 01:26:09,467
DEAN: Yeah, because Brian just basically asserted all these two images are basically doing is separating out the sort of goal directed from the curiosity which is, you know, the image on the right is basically a documentary about the Franklin expedition where they were going out to the event horizon, but they never returned. So did they have a goal? Probably.

423
01:26:10,0 --> 01:26:20,100
Was that their curiosity being carried out? I think we I think we got to be able to make sure that we appreciate both. So that's all I wanted the this makes me think like are you driven to watch the sunset over the horizon or are you driven to find out what's at the end of the rainbow and what's over the horizon?

425
01:26:20,567 --> 01:26:49,733
FRIEDMAN: This makes me think like are you driven to watch the sunset over the horizon or are you driven to find out what's at the end of the rainbow and what's over the horizon? And that's this sort of like infinite open ended curiosity drive beyond the horizon versus the preferred specific state that one can desire in terms of their observations and reduce the divergence there.

427
01:26:50,433 --> 01:27:28,167
But cool wishful thinking. We'll come back soon. We're just leaving notes so that we can have more to discuss later because these are all like they're such vital threads. Ryan and Maxwell and Alex because they touch to our day to day experience in a way that few other frameworks and and even papers within active do so affect and the role of affect and precision curiosity.

429
01:27:28,167 --> 01:27:35,967
These are all just like terms that touch humans and we we.

431
01:27:36,200 --> 01:27:56,267
SMITH: One thing that I, you know, that I think is probably worth just touching on a minute ago, something maybe you guys would want to talk about in the future, you know, maybe when I'm not around it and the other and the other stuff, not sure. But, you know, so there is a probably a distinction that's worth keeping in mind between curiosity and and goal directed information seeking.

433
01:27:56,633 --> 01:28:12,733
I think some of the examples you guys have mentioned have been more kind of along the lines of one versus the other. So think it might be good to just just keep that distinction clear that you know, and and vanilla active inference. I mean, this is really something more just kind of like curiosity is kind of like independently driven.

435
01:28:13,33 --> 01:28:46,133
Just kind of look where you're going to get the most information whereas you know, the construct of directed exploration, you know, and reinforcement learning and yeah. What also you know, often something that can emerge I think a little more clearly in like sophisticated active inference is, you know, is information seeking specifically or in the service of knowing how to get your goal, you know, the the the curiosity version that we're showing here, it has the effect of helping the agency get to what it wants.

437
01:28:47,33 --> 01:29:16,667
But but the drive to seek out information isn't actually itself due to the fact that the agent thinks it will help get his goal. It's just driven to seek the information independently. Whereas whereas in in other yeah. Like investigated inference they the agent is actually doing something more like I'm going to look over here because I think looking over here is actually going to help me get to what I want better.

439
01:29:17,167 --> 01:29:24,600
Right? So this is kind of strategic information seeking. And that's that's a little different than just like intrinsic curiosity. So it's just something to keep clear that's quite interesting. It kind of ties a breed back, but let's explore that later here we have a nice clean representation of the summary of the main arguments. Their proposed solution is somewhat deflationary in the sense that it simply argues that the functional role of desire, not the experience of desire, is straightforward, straightforwardly present in the formalism, and then in more detail they argue that and they provide four points, which it'll be great to go over with with the authors.

441
01:29:25,300 --> 01:30:03,933
FRIEDMAN: That's quite interesting. It kind of ties a breed back, but let's explore that later here we have a nice clean representation of the summary of the main arguments. Their proposed solution is somewhat deflationary in the sense that it simply argues that the functional role of desire, not the experience of desire, is straightforward, straightforwardly present in the formalism, and then in more detail they argue that and they provide four points, which it'll be great to go over with with the authors.

443
01:30:05,67 --> 01:30:39,67
Based on those considerations, the apparent problem posed by purely talk, sarcastic looking constructs is simply not a problem. There are beliefs and desires in the active inference framework perhaps we could have explored this more with the formalism, so we'll bring it up to talking more about F, but I won't go into it now. We'll return to the letters later and then the appendix is very informative.

445
01:30:39,867 --> 01:31:15,167
There's a description of all the states and the factors that are used in the simulation and in the Model Stream one, which is, by the way, Ryan, it's our most popular series was Model Stream one. It was it was a it's a fan favorite, but it's some similar concepts and MATLAB script. So the appendix describes how the figure one results were generated and maybe we'll see if anybody can run that and execute it.

447
01:31:15,167 --> 01:31:41,267
We can play with a few different things and take some of these qualitative linguistics and even mutate the simulation a little bit, see where that takes us we'll close out with our usual closing slide. So who would like to take the first last word Justine then. Yeah, Ryan, first of all, thanks for shepherding us these three cats through this paper because there's an awful lot of stuff to try to cover in a pretty short period of time.

449
01:31:41,533 --> 01:32:11,767
DEAN: Ryan, first of all, thanks for shepherding us these three cats through this paper because there's an awful lot of stuff to try to cover in a pretty short period of time. And it was and it's easy, I think, to sort of go I don't want to say tangentially, but go deeper into some of the parts of the paper, because for me it was one of those ones where I would go back and have to reflect on something after I read a section and then try to fit it into the larger picture.

451
01:32:11,767 --> 01:32:47,100
There was Ryan. I think the paper did a very good job of sort of ordering through what you were trying to say in terms of the reassurance of how the quantitative and the and the modeling of the psychosocial could be seen as working with each other as opposed to though this doesn't answer what this other thing questions but it does cause this is this was a paper that for me, I won't speak for the others, but I had to read the section and then try to plug it back into the overall narrative that was being told.

453
01:32:47,300 --> 01:33:19,600
And again, I think part of that is because that the translation from the stuff that's typically seen as the quantitative part is hard to move into the qualitative part, I think that's that's a challenge for anybody that tries to move back and forth between those two things. But yeah, I mean, in terms of in terms of making a case and, and providing what I think people need to sort of see the two in the same light.

455
01:33:20,400 --> 01:33:21,667
Thank you. Appreciate it. Sure. I mean, happy, happy if it's helpful I could. Yeah. I think in I guess there are two points that I like to touch on. Firstly, I think I thought it was very helpful to map these folks, these concepts that everyone even though everyone I guess that's the nature of psychology that everyone will have a slightly, slightly different probably distribution of what they these terms actually mean.

457
01:33:23,100 --> 01:33:26,800
SMITH: Sure. I mean, happy, happy if it's helpful I could.

459
01:33:28,133 --> 01:34:20,733
JAKOB: Yeah. I think in I guess there are two points that I like to touch on. Firstly, I think I thought it was very helpful to map these folks, these concepts that everyone even though everyone I guess that's the nature of psychology that everyone will have a slightly, slightly different probably distribution of what they these terms actually mean. But I think it's in just learning about active inference, it's helpful to link the mathematical formulation and even just the active inference ontology, which itself can be very cumbersome at times to these very intuitive concepts.

461
01:34:21,267 --> 01:35:07,100
And I think as we get we're starting to explore modeling within the axon flap as well. I think it's and will be really helpful to use this isomorphism between active inference and folk psychology to explain the behavior of agents within these models and not beyond our group problem. And there is some unexpected behavior of an agent we can directly look at, OK, how how did this tensor change its values and describe it with this looks like a psychological ontology.

463
01:35:07,400 --> 01:35:16,600
So I think personally that's the most exciting thing about this paper for me yeah.

465
01:35:17,200 --> 01:35:17,367
DEAN: OK.

467
01:35:17,900 --> 01:35:39,400
SMITH: I mean, if I mean if that's the kind of thing that you're interested in, then I mean, that's kind of the whole it's kind of all motivation of being a for instance, like computational psychiatry, right? Which is like the area that I probably work in prior to you. You take, for instance, clinical populations where people may behave in unexpected or ways or ways that don't necessarily seem like they're all that adaptive.

469
01:35:39,867 --> 01:36:00,400
Right? And you can just put these models to their behavior and you can figure out, OK, well, what is making their behavior abnormal? Right. Is it is it something about an overly precise preference distribution, or is it something about, you know, the belief that states states transition to too and too volatile or uncertain away or things like that?

471
01:36:00,400 --> 01:36:22,800
So, I mean, it is yeah. I mean, the kind of that know, the major point is you can use these models in empirical studies to figure out what the mechanisms are that are leading to healthy and unhealthy behavior. And that can give you kind of guiding information toward designing better treatments or, you know, trying to measure these things in a more quantitative way, things like that.

473
01:36:22,800 --> 01:36:53,33
And and the you know, I just as I've said, I mean, the sample using using tasks that are, you know, that involve some kind of goal, right? Like seeking some kind of reward or social approval or whatever it is that humans seek out, you can do that, right? Unless you have a straightforward way to map the formalism, each element of formalism to the reason that we think people behave in the way that they do.

475
01:36:53,167 --> 01:37:16,433
Right. So, so on. So I guess I'm just saying, if this if that's an interest of yours, then I would think that you would be probably a fan of a lot of a lot of the computational psychiatry literature more broadly, both of the act of inference part, which is a lot of what my lab does, but also just the broader computational psychiatry community that uses reinforcement learning and repetition models and all the other from know all the other classics that are out there.

477
01:37:18,67 --> 01:37:57,567
FRIEDMAN: Cool. And it opens it up to what organizations want and what the cells want and all these other Transpositions. Well, Ryan, really appreciate that last minute belief or desire combination thereof to join us. It certainly help resolve our uncertainty. A lot and it's a great conversation. In the coming two weeks, we're going to be with hopefully some more authors and more lab participants and just I'm looking forward to taking some notes.

479
01:37:59,600 --> 01:38:02,933
Thank you. See you all soon. And by.
