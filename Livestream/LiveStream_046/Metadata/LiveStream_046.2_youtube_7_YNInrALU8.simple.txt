SPEAKER_00:
hello everyone welcome to active lab live stream number 46.2 it's june 22nd 2022.

Welcome to the ACT-INF Lab.

We're a participatory online lab that is communicating, learning, and practicing applied active inference.

You can find us at the links on the slide.

This is a recorded and an archived live stream, so please provide us with feedback so we can improve our work.

All backgrounds and perspectives are welcome, and we'll follow video etiquette for live streams.

Head over to ActiveInference.org to learn about participating in livestreams or in the many other Active Lab projects.

We're here in our third discussion on the paper, Active Inference Models Do Not Contradict Folk Psychology by Smith, Ramstad, and Kiefer.

had a dot zero with ryan joining and jacob and dean where we talked through some of the background of this paper and last week in the dot one we had a great discussion went a lot of ways as dot ones do and opened up some threads to continue discussing in this dot two

I know each of you have some things to bring up.

There's also a few key sections of the paper that we haven't gone into in much detail.

So there'll be a lot to do in the dot-to.

And of course, everybody watching live is also welcome to make comments.

We'll start with just an introduction and warm-up.

we can say hi and add anything else that we're looking forward to talking about or to reducing our uncertainty about through today's discussion or maybe even if it's not too early where we'd like to be heading as we take off on this dot 2 and leave the 46 series how does it

result in us being different thinking differently acting differently in the rest of our post 46 lives so I'm Daniel I'm a researcher in California and

Just a conversation with Dean before we began about some other core concepts other than beliefs, desires, and intentions.

So what other acronym models could we use?

What other kinds of models are consistent or where else can Active Inference be providing us extra information or utility?

And a few other things.

And I'll pass it to Dean.


SPEAKER_03:
Thanks Daniel.

I'm Dean here in Calgary.

I think what I'm curious about is a couple of things.

As I said, I'm curious about things or behaviors that appear to be targeted versus behaviors that appear to be non-targeted.

And there's some reference to that in this paper.

The other thing, as I said, I'm kind of curious about is this moving to the place of saying that

Active inference has these different types, be it extended or decision making or motor active inference.

what the implications of that are.

The bottom line for me is I think if we can operationalize that word through active inference, it shouldn't be difficult to figure out that that applies to behaviors, that there's operations grounding a lot of behaviors.

So yeah, that's what I'm kind of curious about today.

I'll pass it to David.


SPEAKER_02:
great to be back uh it's my second time on here really uh appreciate this i'm i'm on uh 33 so i've listened through lecture 33 so i'm almost uh caught up to uh the current i look forward to having daniel on my channel friday 4 p.m eastern time um you know there's so much to active inference because it's a useful framework for

countless different fields and specifically related to this I had your definitely thoughts and then how do we look at the mechanics of the equation versus

We call folk psychology, but I would put that generally into what I would call introspection.

I have a background in theology, and I've thought a lot about introspection and trying to match what we see through various methods of introspection and maybe where the science and mathematics is leading us.

And also, I guess, the field of psychometrics that isn't necessarily introspection, but it may or may not match the equations.

And then how do we describe the phenomenon?

You understand them, or maybe they're not descriptible, saying that we describe them with the mathematical equations.

And there's not really any good way to translate that into words that would be understandable to folk, common people in that way.


SPEAKER_00:
Awesome.

Ali?


SPEAKER_01:
Hi, I'm Ali.

I'm an independent researcher from Iran.

I'm very glad to be here and I'm looking forward to learn more about this fascinating paper.

Especially, I'm interested in exploring phenomenological aspects of BDI

believe, desire and intention, and also to explore somewhat more deeply the philosophical underpinnings of representation versus simulation aspect of modeling VDI in active inference.

And yeah, that's it for me.


SPEAKER_00:
Great.

Let's begin with this more taxonomic question about the types of active inference.

So we can think about different types that we've heard about in this paper and elsewhere, and then

whether or not we have something to contribute about adding a specific type to this list that will continue to grow.

What does it mean or entail that we do have these different types?

So just to review in this paper, 46,

They make a very clear upfront distinction between what they characterize as motor actinth, MAI, and decision actinth.

And there's a few differences between motor and decision.

Who can list one category of difference?


SPEAKER_03:
Well, the motor active inference doesn't typically require that you have to make a decision.

It's more a reaction or a reflective form as compared to the decision active inference, which does, as the papers say, likely map over to the desire question.


SPEAKER_00:
Yes.

So the motor AI was connected to motor reflex.

Are there decision-making reflex?

Even if that's not a classical usage, like in the reflex arc of the spine or something, moving the hand away from a hot surface, are there cognitive reflexes?


SPEAKER_03:
Not really sure.

I just basically was asking in the context of people who are writing these papers now who are bringing the question down to a motor operational behavior standpoint, how breaking active inference up into different classifications is that in response to a bigger problem, which is the behavior doesn't necessarily

behavior isn't something that's necessarily, we're able to conveniently dissolve down to or concentrate down into motor operations or extensions or any of those other different things that the writers tend to want to focus on now, as opposed to sort of the complexity and the variety and the randomness of behavior as a whole, so.


SPEAKER_00:
Yes, great.

So this is from page 81.

Oh, yes, Ali, go for it.


SPEAKER_01:
Well, I think the distinction between MAI and DAI is not globally accepted among, well, various researchers.

For instance, if we look at the work of Alan Berthouds,

French neuroscientist, especially his book, I think it was called The Brain's Sense of Movement.

In that book, he actually has a famous quote, namely, perception is simulated action.

And by this, he means that he implies that perception and motion and motion and perception or

thinking for that matter, are irreducibly interconnected.

And so the former defines the latter because of the intrinsic motricity

uh, uh, of the creatures endowed with, uh, nervous systems.

Uh, so I'm not sure if we can, uh, distinguish between MAI and DAI in such a, uh, clear cut manner, uh, because as we know that most motor, uh, most, uh, um, motricity and, uh, motor or actions, uh, are also, uh,

predefined in that perception or many other thought processes.

Thanks.

David?


SPEAKER_02:
Yes, I didn't know enough about the BDI model or the, you know, I'm still new to the language, especially of the authors of this paper, to the general philosophy.

But, you know, I was talking a lot about last week about the unified I,

and higher order rules so if you want to look like decision as higher order rules and they would have some sort of power like usually when we think of consciousness in a unified eye that makes decisions and

We talked about eliminativism and the implications of the equations.

Are they eliminativistic or not?

And what direction does the evidence take us?

And so in terms of motor control, like I mentioned, Fodor's modular mind, that it could be that it's a threshold, it's a free energy principle.

And it could just be action, reaction, sense perception, and then a module of our mind sends some perception of however we understand consciousness that makes it appear to us like we made a decision.

I mean, but that may not be accurate that you're the equations might hint that that's not actually what's going on it's simply free energy threshold being reached the threshold could conceivably have.

Nothing or very little to do with the decision making process and it could be post facto like the lead that experiments that the perception, like we made a decision actually comes post facto from the threshold.


SPEAKER_00:
Cool.

Thank you.

Also, I think Adam Safran, who had discussed those Libet experiments, does find a space for agency, if that's not too coarse of a simplification.

But there is some interesting ways to think about what that experiment does or doesn't show.

Maybe we can return to that when we kind of have some figures and details.

Dean?


SPEAKER_03:
yeah i didn't know what you guys were talking about with this illimitativist thing until i went back to the paper and then i found this and i'll just quote it we also this is from the paper we also motivate a squarely non-illimitivist position with respect to such constructs and suggest that the set of theoretical primitives out of which the active inference models are built is sufficient not only to recover the categories

a folk psychology, but also to potentially nuance them with more fine-grained distinctions.

So I'm not sure exactly, David, what you've been saying either corresponds with that or not, but I'm kind of curious.


SPEAKER_00:
Yeah, go for it.


SPEAKER_02:
Yeah, I mean, to me, it's a fallacy that, you know, like a best of both worlds fallacy that materialistic research into consciousness make is that in reality, my understanding of the conclusions of what they're saying is that it is a limit of this.

And they'll put a little statement in like it's not a limit of this.

But what is the evidence of their models actually say?

And can they actually program like a unified eye?

And did they eliminate the unified eye?

And it's just a bunch of perceptions and various factors that reach a threshold.

And what does it mean to make a decision?

And that's why I said, do we just throw away thousands of years of dualistic theology?

How people, our whole lexicon of consciousness, psychology comes from a dualistic tradition.

So if they're trying to grandfather in these dualistic concepts, but even the evidence of what they're saying doesn't necessarily seem to warrant it.

And then, you know, do they have the courage?

to be like, no, unfortunately, the evidence points to illimitivism and go with that.

So, I mean, in my impression, they kind of just throw in the statement, but it's unclear how they're, you know, how they're doing it.

Because, you know, I guess, you know, it's going to be unpopular to be an illimitivist.

It's kind of like the free will question that, I mean, illimitivism also relates to free will.

But, you know, to stand up and be like, no, I'm sorry, free will doesn't exist.

That's where the evidence is pointed.

sort of put in there that they're not trying to say that.

But my impression, I think they actually are trying to say that.

Or that's where the evidence of their conclusions are saying, and they just have a human weakness that doesn't want to go so far as to follow the evidence of their research.


SPEAKER_00:
interesting so just to continue on this motor and decision ai so page five mai does not make decisions once a decision has been made about what to do mai uses proprioceptive prediction signals to move the body to carry out the decided action sequence and elsewhere we've talked about that sort of set point and then a transient suppression of precision which allows the body to reach this new spatial position

and also these models have tended to be formulated in continuous time.

Whereas decision AI plugs in very nicely to the motor AI because it is explicitly considering decision making and these higher order rules that

have to do with either if you take a more realist perspective what organisms or cognitive systems are doing or the more instrumental perspective which is just this is how the the process of decision making can be modeled and it's about what which decisions are made about what to do in order to generate some observations and not others and it's that uh

focus on the observations that are generated under different courses of action and their evaluation in terms of expected free energy that also ties it closely to like perceptual control theory.

So that's the distinction they bring up.

And again, whether in the real world, this carves cognitive systems at the joint is one question.

In the world of the theories as constructed, this is a clean separation.

Although as Ali brought up, that doesn't mean that it's widely accepted or even if everybody heard about it that they would necessarily agree with it.

And there may be phenomena that are mixtures.

And that's also why they talk about the hybrid models where it's like decision-making at a higher level and then motor at a lower level.

So that could allow decisions about what section of a face to look at or what section of a page to read.

And then that decision becomes implemented in a continuous motor active inference context through ocular motor action.

Dean?


SPEAKER_03:
Yeah.

I don't think I'm leading with this question about are we moving to a place that says that active inference will have different types because I think that there's math that's used in financial situations, those operations.

There's math that's used in mechanical situations, those operations.

So I think it's a natural byproduct of, so how do you make the math work?

given the circumstance.

I don't think that there's anything about this that's saying active inference doesn't work just because you want to make sure that you're applying the proper formula to the thing that you're trying to describe.

But I do think it's interesting that in order to be able to describe it more precisely, you just can't say active inference.

You have to kind of figure out what the math is for the specific condition that you're trying to analyze.


SPEAKER_00:
Yeah, definitely makes sense.

Let's now move to this lower part of the page on the different adjectives that we've seen.

So people can probably add or think of more or even imagine.

There's so many adjectives in the textbook called the dictionary.

We've talked about extended active inference, which was addressing extended cognitive features and phenomena, where there could be sort of a offloading, which was when the adaptive active entity is going to utilize something that is more like a notepad, like it's offloading memory onto the notepad, and then the entity is holding on to information about how to seek that information.

Or on both sides of the interface, there could be adaptive act-inf.

And so that was like the sort of true emergent extended cognitive processes.

Deep active inference and citations could be added, didn't get them for all.

was utilized to describe temporal depth in terms of longer and longer time horizons of considerations.

This was really an important development because it moved beyond the sort of one-shot next step model of active and help manage this trade-off between considering time horizons as well as taking action in the time step that the entity is actually in.

sophisticated active inference and various other cousins of it utilized hierarchical modeling which could have temporal depth at one or multiple levels but doesn't need to it does and it could but this is referring to like the thickness or the hierarchical modeling component

uh affective active inference which was used by hesped all to refer to uncertainty parameters and some of the cognitive interpretations of uncertainty parameters as being related to valence um and then there's others like branching time act infants um it comes to what dean said which is just saying like we use active inference

may not reduce uncertainty enough any more than we used a linear model.

whether just talking about it casually or writing the paper, more information has to be provided.

And so this is starting to build the taxonomy and the classifications and the ways of communicating, reducing uncertainty.

Okay, you went to that hemisphere, but was it this continent or that continent?

Was it this coast or was it that coast?

Like zooming in, ultimately resulting in just describing the particulars of the model that was constructed.

Ali?


SPEAKER_01:
Well, adding to what Dean has just said, well, I don't think that these different flavors and versions of active inference that have recently been branched up, they don't necessarily concern themselves with different situations or different niches.

For example, that last one, branching time active inference,

Well, that was a very recent version of active inference, which was, yes, this is the paper they introduced that.

And it's basically a more efficient computational approach to active inference.

And it's just the traditional active inference, but in a more


SPEAKER_00:
efficient with a more efficient algorithm to compute the all the parameters needed yes sometimes it's these adjectives are describing heuristics or implementations or algorithms other times they're describing the model structure other times they're referring to the context that the model is being applied to like an extended cognitive system dean


SPEAKER_03:
Yeah, that's what I was going to ask Ali about.

So if I'm saying something more efficient, what am I saying is more efficient relative to?


SPEAKER_01:
Well, relative to the traditional approach to active inference that has been proposed for the past decade or two, and also relative to the other approaches that are similar to active inferences approach, but not exactly equivalent to it.

For instance, reinforcement learning approaches and so on.


SPEAKER_00:
And one other kind of analogy or mapping there would be like, when a new variant of a neural network architecture is introduced, there's a pomp and circumstance to announce the novelty and the relevance of this for somebody who's in that field.

Similarly, when there's a new variant or a new focus, whether model structure, model target, or something else related to evolutionary biology,

sometimes a new word will come in, but then that new target or model structure, if it becomes used and it's sufficiently close that it's not rejected from the rest of the body of theory, if it's an incoherent usage of the adjective, someone says, well, I made simple active inference and it has this totally different structure.

that might not become incorporated into the network of active inference models.

Whereas if it does become incorporated through its theoretical compatibility or utility in modeling that phenomena, or it's presented in terms of a model architecture that does apply elsewhere, the adjective kind of gets dropped

And then it just goes back to being neural networks, back to being active inference, back to being evolutionary biology.

And then the field moves on.

And so the adjectives are just kind of like another brick in the wall.

Doof it.


SPEAKER_02:
Yeah, I also mentioned last week, I'm not sure if it would go here in this section, is the purpose-driven behavior, action, or even perception related to a unified I and I.

even if it's on the pure level of sense perception is it just that we have uh you know these perceivers and they perceive and then how are the signals read and uh i mean it's easier to describe this in a liministic way whether we're limited or not uh in the for the predictive mind

is the main struggle, so to say, between short-term goals and long-term goals.

And then you have to put in what axioms are we making?

Is there some sort of, for the higher order rules, if we assume that there's some sort of rule that like an organism acts in its own self-interest, in its own, you know, sort of say desire to survive,

or to uh replicate and then you the only struggle would be between short-term and long-term actions like you know God forbid here we have a mosquito pandemic I was gardening and got you know eaten up by mosquitoes and it was just a sense you're replying to the environment like I have an itch should I itch it or should I have some longer term that'll go away quicker if uh if I don't itch it

And is that something that's even in the subconscious where just naturally I would have an itch and I would itch it, but then I would somehow enter a longer term decision-making process that would tell me to act in a different way.

And even in terms for how I'm going to interact with the environment in the future, let alone something that might have a moral or ethical implication.

So if you have a simplified model of just a,

where do we need purpose for sense perception to work and for motor control to work even in terms of reflexes because i think uh you're just even on the motor control let alone the decision making uh you know where does the decision making uh go and what's the purpose behind it and then how is that purpose derived yes so we can go to uh targeted non-targeted


SPEAKER_00:
Another branch point is I think this important question of mapping from real-world phenomena and even direct felt experiences like aesthetic or just more generally phenomenological and anything about a formalism.

And I'm not sure if I've quoted too narrowly,

But they are writing that intentions, so just to review the BDI, the beliefs and the desires come together, and that is what generates the intention.

There's the desire for the ice cream, and there's the belief that there's the ice cream truck, and that is what generates the intentional behavior of pursuing the ice cream truck.

Intentions map straightforwardly to policies with the lowest value for expected free energy, which is calculated across different policies.

Policies are affordances that can be taken over a given time horizon.

So over a time horizon of three, it's the combination of affordances of length three.

Almost all the variables in the DAI model are candidates for traditional psychological beliefs if being used to model the right kinds of high level cognitive processes.

So what are the right kinds?

But then later in footnote five,

This is distinguishing in what they characterize as a different reading of desire.

This reading is not the thing that is desired, but instead about the transient presence of the motivational force to approach the thing we desire.

So it's like, why did you go there?

It was my desire to go there.

What moved you to go there?

Desire.

So it's almost like desire in the specifics, and then also seeing it as a motivating force

But then they note that habit might not have a direction of fit, and it illustrates another reason consistent with our broader argument concerning desires not to assume that probability distributions in the formalism must be mapped onto beliefs at the psychological level.

So they're candidates if we do it right, but it isn't an assumption that they must be mapped onto beliefs.


SPEAKER_01:
Well, I wanted to mention the broader sense of the term intentionality, which I think here is referred to because you see, for all the entities defined by markup blankets and defined by the existence of their markup blankets and their ergodic behavior,

Well, we need an entity who can treat an effect as being about its cause.

An entity who can follow the direction from effect to cause.

And we also need an entity who can treat an isomorphic map.

as being about what it maps, or let's say as oriented toward what it maps.

Well, in both of these cases, the directionality or orientation can be referred to as intentionality in its broad sense.


SPEAKER_00:
So just to clarify there, so the second piece you mentioned was the entity needs to be able to treat some sort of isomorphic or structure-preserving mapping as having an aboutness of the target, like the map of the city

translating that into the physical movement.

And then there was a causal inference question.

Entity can trace causes such that they're doing some kind of causal mapping where agency is the belief that one can be the cause of future aspects.

So is this agency or is this causal modeling that could happen in the absence of entity level agency?


SPEAKER_01:
I think it's broader than necessarily being a cognitive agent.

You see, it's any abstract entity that can

that can sketch out these kinds of causal relationships between the signs and their either icons or their indices.

So it's much broader and more abstract than necessarily cognitive agents.


SPEAKER_00:
What kind of entities are you thinking of?

And isn't it manipulation and that kind of logical juxtaposition?


SPEAKER_01:
No, the one obvious example would be neural networks.

neural nets.

We don't necessarily bestow upon neural networks a cognitive agency, right?

But they can well match at least their input patterns onto their output indices.


SPEAKER_00:
and it's um these continuums of agency continuums of cognitive systems it's like easy to forget we're we're talking about a cognitive modeling framework albeit one that has a motor cousin mai and motor motor modeling history because the mai distinction is um

Also historical, like in terms of which models were developed when.

And is this pan-cognitivism?

Are we modeling everything as if it is on the continuum of cognitive entities?

Like, I don't know if it's as controversial to say that a neural network is a cognitive artifact.

it might not be self-perpetuating or embodied or have open-ended agency or all these other features that some cognitive systems have, but what makes it not cognitive, if you meant that?


SPEAKER_01:
Well, probably the cognitive here was not a proper adjective.

Perhaps what I meant was to be, I don't know, a kind of conscious agent or

But again, on the subject of using the adjective cognitive for neural networks, well, there are quite a few opponents to this characterization for neural networks because they believe that neural networks as agents don't necessarily...

decide on their cognitive basis how to map between the inputs and outputs, because that's the difference between representation and simulation if we

well, can differentiate between those two.

So probably, yeah, the more suitable adjective here should be a conscious agent as opposed to cognitive agent.


SPEAKER_00:
Does that not take us extremely far afield out of where we lose touch with empirical measurements, for example, and enter into important

philosophical questions, but ones that take us away from our cognitive leg.

And psychology, perhaps even especially folk psychology, is sitting at the intersection of cognitive systems, philosophical, self-reflexive systems.

So it's almost like a question of this teetering stack of folk psychology.

Which way will it end up falling?

Elimitivism perhaps is saying we'll be able to dispense with classical philosophical debates or some aspects of them by just moving everything that was folk psychological into a mathematical cognitivist framework.


SPEAKER_01:
Well, what I mean here is that, well, the term intentionality here can also be used

in abstract models of active inference and not necessarily well in the cases where we unambiguously deal with conscious entities.

That's what I mean.


SPEAKER_00:
I think one of the takeaways of this paper or one of the implications of this paper would be that if

intentions in folk psychology are beliefs plus desires and beliefs and desires are identifiable quantities in the academic formalism

Then, by constructing entities consistent with the act of formalism, it can be said that they have intentionality, because it could be said that they have beliefs and desires, and so then it would only make sense to call the behaviors arising from beliefs and desires to be intentional.


SPEAKER_01:
So doesn't this conceptualization of intentionality also subsume the more strict or narrow sense of that term?

Because, well, in this sense, if we infer from the use of intentionality here as referring to only conscious agents,

Well, in that case, the whole purpose of simulating active inference agents could potentially, well, raise some questions.

I'm not sure if I could express myself clearly on this matter or not.


SPEAKER_00:
Very interesting.

Dean, and then do it.


SPEAKER_03:
So maybe amongst the three of you, you can help me with this because I don't really keep up with the latest news on neural nets.

But if I were to look at a neural net, I would assume that most of those nets are given some kind of a target.

Even if they go out and forage for it, there is something about that.

But what I've always been curious about is, especially in the context of this paper, is that

If there is a target, that's been sort of linked to desire in this paper.

And if there's a curiosity aspect to the agent or the net, that's been sort of linked to non-targeting.

So if that's one continuum, the orthogonal aspect of that also in the paper is that there's a reward seeking component

say on the left of that, there's an information seeking or an information and ambiguity component to the right of that.

So here's my question.

Unless we say that curiosity actually is a target, which this paper says it's actually a non-target and the operation and the formalism actually points that out, then how do we set something up like a neural net to actually be curious?

Because we can be curious, we can be non-targeting and find reward in that if we go one direction and find information gained in that in another direction.

And they are completely different things.

They're not seen in the formalism as the same thing.

So I'm just curious whether...

Because as I said, I don't know enough about neural nets to know, but aren't neural nets constantly constrained by having a target?


SPEAKER_00:
I think there's many ways to answer that.

I am not sure if it would totally map onto the difference of supervised and unsupervised learning.

like supervised learning being where labels are provided.

These x-rays belong to this patient category.

These ones belong to the alternate category.

I want you to get really good, but don't over-specify, don't over-fit that distinction, supervised learning.

Unsupervised learning is more along the lines of like, here's input.

According to how you're set up,

embody the statistical regularities and the structure of the information that has been input.

And then that representation allows like clustering and subsequent analyses or the addition of labels later, but it isn't predicated in the training phase upon the data or the cases being labels.

Does that?


SPEAKER_03:
Yeah, but the predication is not curiosity, is it?

That's my point, is that there is no curiosity in what you just described.


SPEAKER_00:
Right.

It's like a pipeline that is receiving whatever information is being provided.

And curiosity seems to kind of break out of that.

And it's like, give me more examples.

And then the directed curiosity would be like, I'm looking for more examples of the label A.

The undirected curiosity would be more like, I just would like more examples.


SPEAKER_03:
So to ask Ali maybe, Ali, is it consciousness if it doesn't have curiosity?


SPEAKER_01:
Well, I don't think so, because you see, even in...

unsupervised learnings.

We don't necessarily, well, the neural networks don't necessarily extract the essence of their training examples.

What they do is to extract

statistical prototype of their tokens the statistical prototype of their training examples so actually they can't recognize a dog as a dog they just see patterns they just see statistical patterns which they've learned through their training process so they're not uh

they're not necessarily conscious of the object of dog or cat or whatever.

What they try to do is, and in fact, in some cases, well, sometimes we see that they have, in fact, inferred wrong statistical prototypes because of, well, insufficient training examples or

well, not appropriate training examples or so on.

But in any case, I don't think we can...

say that, well, neural networks, because of their ability to recognize these patterns, they necessarily, well, have consciousness because, well, probably in order to achieve consciousness, well, other layers of cognitive and even perceptual mechanisms need to be deployed.

David.


SPEAKER_02:
Yeah, I had some other points, but if you wanted to.

You'll stay in the curiosity topic and it's related to what the point I was going to make about belief and desire.

Clearly defining the words so they're specifically you know you're going to take the BDI model and use words like belief and desire to.

you know, some relatively obscure scientific model versus, you know, like a whole historical review of the etymology and, you know, I mean, and how do we, how are we defining beliefs and desire?

You know, does curiosity have a desire to learn something?

For its own purpose, that means it's not goal-driven.

And then how I would understand belief and desire in terms of, so desires are biological urges, like reproduction or survival, and if the emotions are maybe all derivative.

How you're going to put that out where if you're going to try to source all of them from one pure desire and all the other desires are derivative or if you're going to have multiple desires, and then you'd have to have some sort of waiting function to wait the different desires and then beliefs are self made.

rules that come from our own cognition and that's where decision making comes comes in and even you know i think a rabbinic statement in terms of free will that free will is implying that you have the choice to make the less desirous opinion the the less desires choice like as a chess player if you're thinking like uh uh candidate moves and analysis trees that in reality our candidate moves are just how we control our body

And do we move our arm up or down or the various controls of our physical function?

But what are the candidate moves?

And then how would the analysis tree and

decision making is it you know how would it come that you would make the less desirous uh decision is it purely you know let's say short term uh versus long term and then the organization of uh you know let's take a system like okay i'm a jew i'm a muslim i'm an atheist or i'm a capitalist i'm a communist that we have these self-directed uh

beliefs that control our behavior and if it's learning to do things like i can't steal god forbid i can't rape i can't kill and that like my desire if the body tells me okay i see attractive woman i want to have sexual relations but then i have these beliefs like that there's a system of rules and governance

that is it purely because I can't get away with it that I don't do it?

We don't rape, steal, and kill because we can't get away with it?

Or is there this self-imposed moralistic behavior and that's coming down to what belief means?

And then also, so curiosity, you'd have to clearly define

curiosity if you're talking about neural nets that you know can computer just learn for its own sake uh and even can a human just learn for its own sake that uh you know we're participating in these discussions purely because i enjoy figuring things out even if it has no practical implication to uh you know some primal directive of survival

or reproduction or however you're going to understand these primal directives.

And then the equation be similar to a chess algorithm for a computer where it would appear that you could add in weighting factors, that you could program this into the equations and you have some constants that would be weighting factors.

So if you did have just one primal directive of survival or two primal directives of reproduction and survival, and then you could give those weighting factors, or you could have a feedback mechanism with the environment.

And then, as I said, where do the belief comes in, the self-made rules, and then how are those weighting factors calculated?

in decision-making and what does it mean to make a decision?

Is it possible that we make the least desirous decision?

And if we can't make the less desirous decision, do we not have free will?


SPEAKER_00:
Thanks.

So Jonathan Schock made a great point, which is that deep neural networks applied to reinforcement learning can include curiosity as an explicit factor.

It guides the agent to states about which it has the most uncertainty.

So it's a term which makes it rewarding to explore currently unexplored states.

And then just to provide a recent example, here's a way in which a neural network architecture was used.

certainly worthy of more exploration and at a first pass or at least just qualitatively one way to think about that and then we'll come to how curiosity was described in the text is in active inference we have a imperative for action selection that includes a pragmatic and an epistemic component

Whereas a pragmatic absolutist perspective like reinforcement learning needs to generate these modules and alternate architectures

such that information seeking, curiosity, can be coerced into a reward framework.

I mean, what is the next question gonna be?

Well, it's rewarding to gain information.

Oh, what kind of information?

How much information?

How are we going to learn the parameters on our curiosity model?

And so on.

And so active inference as a first principles approach for this kind of artificially intelligent system

allows us to include at the base level both an objective achieving and a pure curiosity reducing element.

Dean, and then we'll look at how they talk about curiosity.


SPEAKER_03:
Thanks, Daniel.

So, as has historically been the case for point twos, David just left and I was going to ask him this question.

Okay, I guess he's still here.

So, David, after thought one, and now just what you were just sharing with us here, I wondered, without putting words in one mouth, can I get a clarification?

I think one of the things that you're trying to make clear or

or at least bring into the conversation is that prioritization, which is the sort of the value weighting aspect of how we see the world is not ordering the kind of placing of a formalism down on paper that includes rules like equals and plus and minus in the FEP or the sort of extended and variation of free energy piece.

Is that,

And that oversimplifying what you want us to make clear that that having evaluating is not the same.

That kind of prioritization is not the same as being able to formally set down an order.


SPEAKER_02:
Well, I'm a dualist, so like I'm trying to I think I could use these equations for dualistic purposes, and you could just factor in a weighting factor for these higher order rules.

And then, you know, so my system would have some sort of struggle between two separate realms of material and spiritual realm.

So that's personally how I'm I'm looking at it.

But, you know, I could attempt to understand it from just the materialistic realm and how the

equations uh you would apply and then if there's competing factors what's the origin of those competing factors so so if you just put your desires are biological uh animalistic urges and beliefs are self-created uh rules of uh

cognition, and then you want to have a separate function like curiosity, where curiosity maybe benefits the purpose of making beliefs, which would later come to become higher order rules.

Or if you want to have the ability to have behavior that has no purpose, that I just enjoy understanding things, maybe that understanding will help me make better higher order rules.

And then saying, oh, like you're saying for the equation, here we have these equations and it's free energy.

And so the purpose is to minimize the least action principle or limit energy usage.

And so if you're looking like, well, why did I do that?

Well, it's like, dummy, didn't you look at the equation?

It was the free energy principle.

You did it to minimize energy usage.

And so we're just saying that that's the origin of all human behavior from an eliminativistic sense.

And from the folk psychology, that's why I'm taking a dualistic perspective where these higher order rules are coming from a non-material plane.

but I think they could be modeled into the equations.


SPEAKER_00:
Thanks.

Also, free energy minimization doesn't entail the actual minimal possible energy usage.

Though some people have made that, accidentally or intentionally, a claim, it isn't what those equations, as they're being used here, necessarily represent, but it could.

There could be a system that thrives optimally based upon reducing energy usage, but also there's situations where free energy minimization and the path of least action are not the lowest energy consumption.


SPEAKER_02:
Was that short term versus long term?

They're saying long term it is, but it's just short term versus long term decision making in the, as opposed to a dualistic, the predictive mind that's saying it's not dualistic, spiritual versus material.

It's a single materialistic in its short term versus long term.


SPEAKER_00:
okay let's think about that in the context of of curiosity um how they're describing so g expected free energy of policies it's like the policies are enumerated and then g is calculated for them reflects the inferred value of each policy based upon beliefs beliefs are p of o sub t

conditioned on pi.

So the distribution of outcomes conditioned upon policies.

If I go left, what do I expect to see?

If I go right, what do I expect to see?

That's a belief.

And the belief distribution about observations conditioned upon hidden states of the world.

If there is food there, then what observations will I expect to see?

And desired outcomes, which is, as we've explored in 37 in user's guide, there's this dual implication of the P of O distribution and active inference as what is expected as well as preferred.

because we reduce our surprise about the expected

slash preferred outcome distribution, and that is how the desired outcomes are realized, not by providing a higher reward or value to increasingly preferred states, but rather treating the preference distribution as expectations, which allows us to use surprisal and surprisal-bounding approaches towards achieving

preferences so how do they talk about desire and curiosity they're suggesting that these drives so this is in earlier we talked about there's the two ways to talk about desire the specific target of desire as a desire like i desire a cube of tungsten or something and then there's the drive that is associated with desire what made the person do it desire in the abstract

um curiosity drives discovery of what is not yet known and thus has no preconceived target however one could also say that it has a semi-formed concept of target because one could be like curious about something and then their curiosity would be satiated by something else something but not something else so in that case there was some of something of a prior on what they were looking for um

The claim that curiosity is not cognitive, so desire-related, might seem suspect on the grounds it could also be characterized as simply the desire to learn, qualitatively, and this in turn could be conceived as the desire that one's beliefs are as precise as possible.

Even though, especially in the short term, learning sometimes feels like it reduces our precision.

However, the mathematics allow us to motivate a genuine distinction here.

Specifically, changing outcomes to minimize the KL divergence in the risk term in EFE is a fundamentally different sort of process from minimizing the ambiguity term.

So the KL divergence is on the left side here.

And the ambiguity term is on the right side here.

Here's equation 2.6 from the textbook.

and it's it's in a different order but just to see here's risk with the kl divergence and then here's expected ambiguity with the h for the entropy calculation um the latter which is the ambiguity term does not care how uncertainty is resolved so long it is resolved there's no preference for becoming more confident in one possible belief over another

Whereas the reduction of uncertainty by reducing the KL divergence is what is bringing us into alignment with our preferences slash expectations.

Hence, that is a much more targeted form of curiosity in that it allows for goal-directed information seeking.

And then they write, Dean?


SPEAKER_03:
Yeah, that's perfect.

Because what I wanted to say was that I think that curiosity really points to that risk.

And the reason I say that is because you may find that when the ambiguity is removed, the prize is a happy one or a not so happy one.

And I think that's kind of important here to see sort of the... It's hard to say, as it says here,

However, the claim that curiosity is non-cognitive might seem suspect on the grounds it could also be characterized as simply the desire to learn.

Before the learning, you're sort of in an ambiguous state.

Will it be a happy surprise or will it be an unhappy surprise?

And so I think this kind of pulls that out.

The ambiguity applies a certain amount of risk, but then you have to act in the active inference aspect of it to determine whether or not the surprise all at the other side of it is actually good or not so good.

So I think that's where the curiosity arm of this comes to the fore.

It is non-targeted until it actually has been realized or somehow materialized.

Whereas the targeted stuff, the desire stuff, can be part of your plan.

I'm not sure whether the curiosity fits as conveniently as the desire does.


SPEAKER_00:
And just one short note on that is we see a conditioning on policy.


SPEAKER_03:
Right.


SPEAKER_00:
in a few different places.

So it'd be interesting to think about where does planning to learn come into play?

And in what ways is planning to learn directed?

Or what if you plan to have undirected learning?

Or all these other combinations.

Doovit?


SPEAKER_02:
Yeah, I'm not sure if it would exactly fit in with the equation, but I'm thinking here like Maslow's hierarchy of needs defined in terms of the free energy principle where, so to say, curiosity requires excess energy.

So if you're on the first rung of the hierarchy,

that you have limited energy to apply towards curiosity.

And if you do have energy to apply towards curiosity, you're going to be best off to be curious about things that will directly apply to your security,

your food or the primal directives as opposed to if you move up the hierarchy, at least put this into Maslow's hierarchy, where there's less risk associated with curiosity that maybe you've achieved more leisure activity and therefore have more energy to expand towards curiosity that you could reach the highest levels of Maslow's hierarchy and focus on

you know ideals and uh what is the meaning of truth or understanding uh science uh but it would still be uh you however you're defining the free energy principle that you have some sort of uh uh conservation of energy and curiosity is an expansion

of energy that is limited, but more resources could be allocated, so to say, energy resources to curiosity if it makes the whole unified person more efficient and they become more secure, more safe, more social, accepted, so on and so on.

And therefore, they have more energy to expand towards curiosity.


SPEAKER_00:
Thanks, Ali.


SPEAKER_01:
I also think it might be helpful to mention the neural basis for these surprise appraisals, because you see, as we know, we have two systems of thinking, system one and system two famously sketched out by Kahneman and Tversky, or fast track and slow track reacting to stimuli.

So in the fast track,

Well, the stimuli bypass the sensory cortex and go directly from thalamus to amygdala.

So our first reaction, our immediate reaction to every surprise would be something quite similar to fear.

But then after appraising that stimulus, after going through the sensory cortex and then amygdala and then hippocampus, then we can appraise, we can evaluate that surprise as being positive or negative.

And as a result of that, we get a positive or negative valence effect.

So in summary, well, every surprise, I mean, either positive or negative, it could be at first, at the very first moment, can induce a negative valence emotion in us.


SPEAKER_00:
Yes, I brought in some of the quotes from this paper, Habitual and Reflective Control in Hierarchical Predictive Coding.

It's from 2021 and it's by Kinghorn, Milledge and Buckley.

So they directly connect hierarchical predictive coding architectures, which when they consider action have a lot to do with active inference.

in terms of thinking fast and slow, like you had just brought up.

So they wrote, on this view, fast actions may be triggered using only the lower levels of the hierarchical predictive coding schema, whereas more deliberative actions need higher layers.

We demonstrate that HPC can distribute learning throughout its hierarchy with higher layers called into use only as required.

So that is very interesting when we think about

going back to the MAI-DAI distinction from this paper, it's a hybrid model, albeit one where the motor spatial control is continuous or modeled as continuous, and then there's a more discrete, more mental or cognitive model that's like thinking slow.

So it's almost like there's thinking fast and slow even within the mind, and then there's thinking with the body.

that's like even a lower level i don't think even by thinking fast they weren't talking about the reflex arc but there can be hierarchical modeling even there um so it uh what are these nested models that are slower

How do those develop?

Are they related to the physical architecture of our onboard machinery?

To what extent do they involve so many of our off-sourced or extended cognitive phenomena, like our colleagues, like our social networks, our books and learnings, the social structures that scaffold our beliefs and so on?

There's a lot of interesting pieces there.

What would be a good direction to go in this second half of the dot, too?

We had targeted, non-targeted.

Is there anything there that's not covered by the curiosity discussion?

Is there... Oh, unmute, Dina, then yes, go for it.


SPEAKER_03:
Sorry about that.

Yeah, I think we pretty much wrestled that one to the ground.


SPEAKER_00:
Okay, David?


SPEAKER_02:
Yeah, my conception for targeted, I'm calling the unified I in terms of...

maybe like the ant colony where you could look at it like the ants are all functioning personally with their own directive behavior and it just works out that they're directed or as a unit.

But even in like a human, whether there's a unified of the human cells, like even sense perception that it's easier to look at it like our...

Like I mentioned, we have almost 100 million cones and rods in our eyes that are receiving photons at every given instant.

And we just look at it like they're acting in a unified manner.

But even that requires some sort of targeted behavior for even direct motor control that our cells in our given body are acting in a unified manner.

And could you take the free energy principle to a cellular level and say, well, cells will act in a unified way if it's in accordance with the free energy principle.

But if it wasn't in accordance with the free energy principle, then cells don't act in a unified targeted way.

and act according to their own levels.

I'm not sure if you could take that to the cellular level for even things like sense perception, motor control, like one arm wants to go this way and one arm wants to go that way.

And how do we have this unified control?


SPEAKER_00:
It's an interesting thing about what would make something concord or not with FEP because it's a description framework.

here is where in from livestream 25 with uh professor levin here's even in the ant colony example where different subsystems and and cancer and and um like other situations like biofilms were modeled this way that there can be coherence within each cone so to speak uh

I don't know if this moves us closer to understanding the experience of the eye or whether there is in fundament a unified eye, but the cells in the nestmate's body can be understood as undergoing coherent behavior.

The nestmates can, the colony can.

And then different people have taken different perspectives on what makes one level of analysis more relevant than others.

Like an evolutionary perspective is that the unit of selection is granted some special power.

A information processing perspective or integrated information theory might highlight what happens informationally within and across levels.

Let's look at their dark room experiment.

We kind of came to it a little bit last time, but what did anyone think their figure and simulation spoke to?

How was it adding details or information that weren't present in the

more formalism and qualitative driven other sections of the paper?


SPEAKER_03:
I have a question.

I don't know if I have an interpretation of it.

When others looked at this as it's now graphed out, did they see ambiguity removal or did they see an entropy question being resolved?

Because what I saw was the latter.

I kind of saw that something...

something appeared with more information gain or something disappeared if there was no sense that the change of an ambiguity state was going to make any difference.

So I'm kind of curious how others interpreted the actual data as it laid out post hoc, because this is all post hoc.

This is just comparing .7.3 to .99.01.

In terms of the desire strength, and I think they use the term urgency in the paper, going up, right?

Yes.


SPEAKER_00:
Yes.

Well, on the left side, okay, so time is moving from left to right.

There's an entity that doesn't desire, they don't have a preference for achieving ice cream.

And in this simulation run, they observed that they were in a dark room and they picked the decision to flip a switch.

They then went to the right

and they ended up not finding that they got ice cream the weak desire agent first flips a switch and then with higher confidence goes to the left and they end up realizing ice cream in this case of the strong desire agent

even though they have uncertainty about going left or right initially they're in a hurry or it's urgent and they go left immediately and that turns out that it does achieve getting the ice cream one note is like

these are only showing one run of each of those simulations so it's like does the no desire entity always go to the right or is that a 50 50. how have people used the bdi to do quantitative modeling of behavior

Are they moving their verbal and formal arguments from above in the paper into a form factor that will be more amenable or palatable to people who are already using these models to do behavioral analysis?


SPEAKER_03:
Well, I think the BDI, I mean, strictly from the standpoint of here's what we watched this agent do.

It kind of had a 50-50 choice.

It was playing more in the geometry space.

How this is represented is more sort of the Bayesian distribution piece, right?

So you've got a

percentage of an area as you're moving from left to right that's either darkened or remains agnostic.

It doesn't sort of change what the outcome or what the matching of an outcome and the expected free energy are.

So I think that it just brings more information to the

to the observation of what's actually going on when the lights either do go on or don't go on.

Because that first one, the lights don't go on, I think, and the agent either stumbles to the right place or doesn't, but they don't care.

But I do think that what happens is you can have geometry only, or you can have geometry and

a proportion or a distribution, and I think that's what this is kind of laying out for us, that now you've got more information.

And with more information, hopefully you've got less invariance.

You've got more variance being described here than you would if you left it at the geometric level alone.

Does that make sense?


SPEAKER_00:
Yes, and they follow up after the figure that this magnitude mapping, it's giving not just some theoretical detail to this mapping, and they provide several citations, many recently with Smith and others,

where it's used in many different contexts.

And then I kind of found it also interesting in the following sentences after the paragraph that I had just quoted there.

This motivating force could be corresponding to the magnitude of the KL divergence.

KL divergence between the Q variational distribution of observations conditioned upon policy divergence with the preference distribution P of up within the expected free energy so that's one of the terms that we've looked at in the G of Pi i.e the risk term not the ambiguity term with entropy

This is because stronger preference values over rewarding outcomes in P of O of T increase the KL divergence and lead the agent to seek reward over information gain.

So there's still a knob, maybe multiple that are slightly interacting.

There's a knob by which more

Pure curiosity.

That would be just the ambiguity resolving, but undirected.

Mixtures of pure curiosity and directed curiosity.

Weak preferences with a lot of openness.

And increasingly sharp preference distributions induce increasingly urgent pragmatic value-seeking outcomes.

And...

There's a lot of funny things that come to mind, like a question for one person might be a survival question, for another it might be a research question, for another it might be like a pure curiosity.

Where's the oxygen in this room?

Is that a survival question?

Is that just, you know, again, are you researching oxygen distributions in rooms?

So you have a target to understand that?

Or are you just curious about that thought?

Dean, then David.


SPEAKER_03:
I think, Daniel, that clearly speaks to what David and Allie were both mentioning in terms of, so what's your timeframe here, right?

So you take off and you have a bird strike and now you don't have enough time to land anywhere other than on the river.

Is that curiosity?

Is that desire?

What is that in terms of how much time do you have now to manage the risk aspect of this situation that you now find yourself under?

Certainly survival.

But yeah, what percentages or what proportions of each one of these different parts of the equation are being calculated at any given moment relative to the overall time frame that you're now constrained under?


SPEAKER_00:
Yes, do it.


SPEAKER_02:
let me just look at the refrigerator you know example that well okay had i been curious you know earlier during the day about the layout of the room i might have remembered how to get to the refrigerator but i i didn't expend that mental energy so here i am hungry

And I don't know my surroundings.

And so you have the level of curiosity could have provided benefit.

But now at this point, you know, you have the risk factor.

Will I injure myself or eat?

And I was thinking, you know, like chess or something like, OK, like the AlphaZero is programmed with the most powerful computers for hours and hours.

to just understand the game.

And then later, it's able to take that and win.

So as a person, it's like, OK, I really just like thinking about chess and understanding the patterns.

But then, OK, well, I have to reproduce.

I have to see to the success of my children and the offspring.

I have to make money and survive.

and so you know maybe i could become a professional chess player or something like that but then you would come and come in and well um if my goal is to uh you know reproduce and see the success of my offspring and you know make money and survive there's better methods to do that than becoming a professional chess player even like active inference

that, okay, I'm curious about how this stuff works, but it's probably not going to help me reproduce or make a living.

And if I tried to take my curiosity about consciousness and use that to benefit the reproduction or making a living, it's unlikely to see that much fruition.

But at the same time, the power of curiosity is you don't know how it's going to benefit you.

So the ice cream example, if we had a meeting in the kitchen during the day and then we all go back to our rooms to go to sleep and then we're hungry at night, the person who was just curious about how the room was laid out is going to be able to likely retrieve the ice cream without any injury as where the person who didn't

expand the energy to be curious about the layout of the room may not achieve the ice cream.

And that's why in my own head, it may not be directly applicable to this paper, but it could be in folk psychology.

It would be to map this to something like Maslow's hierarchy of rules, which would be in line with neural nets, that there would be some sort of higher order rules.

and some sort of ability to uh put the expansion of more energy like okay like i thought about chess and now i'm winning and i've achieved a little bit of social standing or you know won a little prize money or you know even school i was curious about consciousness now i got a bachelor's degree and i have enough proficiency to you know get a job and support a family


SPEAKER_00:
and now i could exhort even more energy to it but at the time of the pure curiosity you don't know how it may you actually benefit you in terms of reward great points that it's almost like jumping through different hoops what it might be best accomplished through pure curiosity at a future time point

So in, again, that survival, research, and pure curiosity trilemma, there's times where being driven by one or the other helps us move through complex real-world situations.

If we knew the whole story from the beginning, then we could just follow along.

But in a highly partial information world, where we don't want our priors to...

lead to ruin basically then pure curiosity and research help bring things within our survivable limit into information gathering spaces that we wouldn't necessarily have traveled to limited resources i don't know if they could program that also into the computer also like the limit of resources and if that if you interpret free energy principle in general to you'll be a definition of limited energy resources

Ali?


SPEAKER_01:
Well, adding to my own previous comments about the subject of consciousness and curiosity, I personally believe that the nature of consciousness is ultimately computational.

So it's amenable to modeling and simulation.

But we're just not there yet.

But well,

One possible approach to achieve such model could be potentially the active inference approach or other related approaches.

But you see, curiosity is just one aspect of consciousness.

I think it could probably be helpful to distinguish between the artificial curiosity and the experience of curiosity or the phenomenology of the curiosity because what we see here is the agent that simulates the artificial curiosity and it's not exactly

isomorphic with the experience we get from our derived to our information seeking drives.

And in fact, in this paper, I think it was in page 28.

Yes.

It's in page 28 that they state that we have not addressed questions about the structure a generative model would need in order to account for experiences of beliefs and desires.

Well, at least in this paper, we're not dealing with the actual experience of curiosity.

We're just trying to somehow model and simulate the artificial curiosity.

In fact, this term artificial curiosity is one favored by Carl Friston himself in his various other lectures.


SPEAKER_00:
yes very good point and it relates to kind of the experienced view from the inside versus the behavioral modeling view from the outside a curious particle or a curious forager might be engaging in some kind of behavior but that isn't the same thing as experience of

but they do provide references to other work, like including work that has been discussed previously on live streams with Christopher White and Ryan Smith on report paradigms of consciousness.

As we kind of head towards the end here, I thought this was very interesting in the section before the conclusion 11, free energy principle and direction of fit.

And this is kind of a good,

section to carry out and bring forward into our other discussions on Act-Inf.

For any organism described by the FEP, the description will contain an implicitly normative state element about the states the organism should be in and can be described as having cognitive desire-like direction of fit.

So there's a preference distribution.

And as this paper is building up, it can have an interpretation as desire, being a targeted desire.

Even beyond the case of forward-looking decision-making agents,

Not all Bayesian beliefs in the FEP formalism are best characterized as doxastic, being about belief, doxology.

This perspective may expand upon current discussion in the FEP literature, where it is fairly prominent to discuss as-if beliefs in simple systems, whether a mere active entity like a pendulum or adaptive active entities, and just say, well, I'm not saying that it really believes that.

It's acting as if it believes that.

that conform to the FEP.

Here, our point is they can also equally be described as having as-if desires.

Belief entered the active lexicon slash ontology

Perhaps because belief is used also in Bayesian statistics, where distributions more generally are called beliefs.

Also disjoint from the phenomenology of experiencing a belief, but rather that's just called belief updating, is like a process in Bayesian statistics.

This paper...

kind of closes the loop with belief, not towards phenomenology, but stapling together some of the Bayesian distributional usage of the term belief with the doxastic being about belief.

The aboutness of those Bayesian beliefs is the folk psychological concept of belief.

By making that mapping and connecting the formalism as a whole, or at least in the core equations like the F and the G, to the BDI model, it also allows them to identify which Bayesian belief distributions map to belief in the BDI, and which Bayesian belief distributions map to D, to the desires in the BDI.

and so to the extent that somebody can say a system has an as if belief implicitly in a folk psychological way we can also talk about as if desires and that helps um partition

but not disregard the discussion around what different systems experience, the classic, you know, what is it like to be X?

But it, at least according to this argument and perspective, authorizes usage of intentions and desires, intentions arising from basically the combination of the beliefs and the desires in the BDI, right?

and talking about active systems as if they have desires.

What is that simulation desirous of?

And then using its beliefs and desires to explain its intentional behavior, not the experience of intentionality, experience of belief, experience of desire, but using them in this view from the outside, more deflationary perspective.

So that's quite interesting.

And I think something that

We'll see how it catches on.

Are there other sections that people want to talk about?

Or what will they carry forward into their post-46 life?


SPEAKER_03:
think daniel a couple of things i think the desire to think part that you're just talking about there i'm not sure that it's specific in nature i think it's more generalizable and sort of that scale free um to there's some of the stuff that david brought up um i think that when you when you um

you start getting getting to know active infants a little bit more and i'll speak from personal experience with a focus on a little bit of sort of personal grooming you become one heck of an attractive state and so i think you might not make money off of that but at this point but i think as you get more comfortable with the kind of being able to take the information and uh use it across a variety of different situations it's um

It actually is quite helpful.

I don't think I'll ever get rich off of it at this point, but it is kind of interesting how it's, I think it is growing in terms of the amount of attention that it's getting.

So that's kind of my two takes on this so far.


SPEAKER_00:
So you're saying it might influence fitness?


SPEAKER_03:
I think it might down the road, as long as we have enough timescale.


UNKNOWN:
Do the talk.


SPEAKER_02:
Yeah.

And I've been coaching chess for a while and mostly to youth and I'm used to explaining, uh,

somewhat you know these concepts like you know i i want you to say that uh people who are just curious about chess and how the patterns work and how the pieces work often improve much faster than people who desire to win and that a lot of times people will reach a certain strength and then their curiosity diminishes and it's just their desire to win which isn't enough that you know it's just like i want to spend my night thinking about these uh patterns

versus like I really want to win and have some sort of practical benefit from my efforts.

So I have my own personal goals that brought me to active inference because I was looking for my own tools to advance my own research.

and came on to active inference as a method or tool that even though it appears that the majority of people are using it for a different purpose, that I would be able to rework it for my own purpose.

But because it's an interdisciplinary study and I'm an engineer and engineering usually works that way, where someone has professional certification, they sign off,

and you could expect that they did their part right and it's going to work and you could you know attach that module to your module and both modules are going to do what they said they're going to do and then you know the curiosity will do i really want to understand how your module works

you know, do I really care about Dean and Ali's research or, you know, do I just, you know, want to trust that their module works and I'm going to be able to attach that to my module to, you know, make something more powerful.

And both are probably true to, you know, to your limited energy, limited resources that, you know, that I would like to understand Dean and Ali's module to the best of my

ability but energy time allocation resources are limited but then you know certainly if you had a module that would help my module and we could plug them in together and you create a more powerful interface so that I'm bullish about active inference and as a framework that will benefit you know the more and more people who get involved and I'm seeing my own direction into my own research how

I think this will be useful and I even think I got Jennifer, I think, joined the Discord and I mentioned to a few other people that might be able to advance their research and then try to understand the current existing modules that are out there within the active inference.

As I mentioned, the importance of interdisciplinary studies for big issues.

None of us are going to figure this out.

It's going to take interdisciplinary studies, and none of us are going to be able to understand all the disciplines necessary to piece together the bigger puzzle.


SPEAKER_00:
Nice.

Thank you.

Yes.

Interesting point about the curiosity-driven learning.

and how that can be like a not even paradoxically more successful approach or mentality to set off on a learning journey with.

I just think about somebody trying to learn organic chemistry, which I tutored for many years, and people who set themselves up for the pragmatic value and said, I want this outcome.

Sometimes they achieve the outcome, other times they didn't, but it set up a lot of psychology around not achieving the outcome when it didn't happen on the expected timeline and a lot of like secondary cascading failures.

However, there's also the clear counterpoint, which is, but if we don't want the higher grade, then like if we're just going to be curious about learning organic chemistry, like

my finals in six weeks.

So how are we going to balance the timelines and the curiosity?

And I think maybe even this paper helped us look at one way, which is keep the preference direction, but understand how the urgency of your preference

influences the way that you take action.

And just think about what if your final was tomorrow?

How would you go about it?

Okay, now what if the final was in 100 years?

How would you go about it?

Where are we in that continuum?

Do we have time for curiosity and for openness?

Or is this an actual emergency situation?

and then we can triage where there is an emergency organic chemistry situation but also hold space for curiosity and openness and even in the emergency there has to be information seeking it's just more directed information seeking okay we're going to work through the practice tests and that's what we're going to have time for there still is going to be information seeking but not of the same kind if we had more time to kind of space out

even though in an alternate slash preferable world, perhaps that's the better way to learn or the more fun way to learn or so on.

Any other thoughts?


SPEAKER_01:
Well, one of the things I really like about active inference research is

the willingness of the researchers in this area to seriously address the criticisms instead of just dodging them and their willingness to constantly improve and update the theory in order to fill the gaps and also address the

well, the weakness or any weakness or loophole in the theory.

And that's very, you see, liberating to see such active area of research going forward in a very determined and also very open-minded way.

And well, that's one of the things I think sets it apart from

some other research areas today.


SPEAKER_00:
It's what we prefer.

It's what we expect.

We're curious about it.

Okay, Dean, Ali, Duvid, thanks a lot for this fun discussion, and Ryan, Maxwell, and Alex for this paper.

It really capped off a long run of livestreams.

We've had quite a nice sequence going back to the beginning of this year, getting through many, many discussions.

Next week, we're going to have the second quarterly round table meeting, and then we'll have July off of paper discussions.

And we'll be coming back in August with paper discussions.

We don't know exactly what they're going to be, but we know some of them and we have a few guest streams and other streams coming up, but, um,

Yeah, it's been a nice run.

The lab meeting next week will be a great cap to this season slash semester.

And then we'll come back for the end of 2022 with some new changes that I think people will be really excited about.

So thanks, everybody.

And see you later.


SPEAKER_03:
Thanks, Daniel.


SPEAKER_04:
Thanks, everyone.

Okay, thanks a lot.