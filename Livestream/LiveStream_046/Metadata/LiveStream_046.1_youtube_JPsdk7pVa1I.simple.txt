SPEAKER_00:
hello and welcome everyone it's june 15th 2022 and we're here in actinflab live stream number 46.1 welcome oh and mute the stream if you have in the background thank you welcome to the active inference lab we are a participatory online lab that is communicating learning and practicing applied active inference you can find us at some of the links on the slide

This is a recorded and an archived and transcribed and edited and published live stream.

So please provide feedback so we can improve our work.

All backgrounds and perspectives are welcome and we'll be following good video etiquette for live streams.

Head over to ActiveInference.org to learn more about live streams and a lot of the other projects that are happening in the lab.

So we're here in ACT-IMP Stream 46.1, and we're in our second discussion of the paper, Active Inference Models Do Not Contradict Folks' Psychology by Ryan Smith, Maxwell Ramstad, and Alex Kiefer.

and we're going to go i expect in many fun and interesting directions today so thanks everybody who's joined the panel live and also for those who are watching live thanks for adding your comments in the live chat

we'll begin with some introductions and then i believe that will introduce many interesting areas we can continue from there so we can start by just introducing ourselves and then passing it to someone else who has not yet spoken and we'll close with the authors who are here so i'm daniel i'm a researcher in california and

The dot zero was very interesting with Jakob and Dean and Ryan, and it raised many questions that I was excited to discuss today.

Just to provide one would be perhaps the relationship between formalisms of any kinds and natural language and just regular concepts that people have.

How do we draw the connection or evaluate connections that are drawn there?

And I'll pass to Ali.

Questions I'd like to ask if they're not... Sorry, Ali, wait, sorry, just the audio is set up a little bit differently.

So if you could just start, you can just reintroduce, but go for it.

Thank you.


SPEAKER_01:
Okay.

Is it okay now?


SPEAKER_00:
Yes.

Thank you.


SPEAKER_01:
All right.

Yeah.

I'm an independent researcher from Iraq.

And as I said, I also have a couple of questions I'd like to ask.

They're not addressed during the discussion, especially when we get to section nine of the paper.

And yeah, I'm very glad to be here and that's it from me and I'll pass it to Dean.


SPEAKER_04:
Morning.

My name is Dean.

I'm here in Calgary.

I really like this

which I kind of indicated in the last livestream.

My curiosity, because I really don't know, is because of my background in education, when I'm looking at that sort of qualification, quantification piece, and I'm thinking about the desires as something that we can see as 0.1 and 0.9 as a distribution, I often thought of some of my

previous conversations around things like Likert scales.

And so I know this paper doesn't address those things specifically, but the idea of being able to translate into sort of a numeric form has always been interesting to me.

And that's something that maybe today or maybe in the point two, we can think about the implications of that.

And I'll pass it to David.


SPEAKER_03:
Hey, David Kelton here.

Thanks for having me on my first time here on Active Inference.

I go by Duvid as a streamer.

I'm a civil engineer by education and practice by background linguistics and physics and psychology.

I spent many years in yeshiva rabbinic study and have been a practicing Hindu.

I'm more on the mystical side of consciousness, been studying it actively streaming for a few years, but also the mathematical materialistic side.

So this paper was very interesting, especially dealing with the sense perception related to motor control, which my perception of dualism is something that

the material does actually control.

So I like the model, I like the paper.

I was interested in looking at some of the more philosophical and even mystical precursors.

What could actually be explained?

What are the assumptions being made?

And this paper is definitely a good start.


SPEAKER_00:
Thank you, David, and to Alex.

So feel free to give any introduction and then provide any context on what brought about the paper from your perspective.


SPEAKER_02:
Yeah, thanks.

So I'm Alex Kiefer.

I'm one of the authors on the paper.

I'm affiliated with Monash University and Jakob Hovy's Cognition and Philosophy Lab there, and I currently

Also, my main sort of gig is at Versus Research Labs in LA.

So we've been doing some really interesting research there that plugs into active inference, among other things.

So as far as context for the paper, so this is this issue of how and whether active inference and

and theories in the vicinity, like predictive processing and all that.

How those things map onto folk psychology is something I've been interested in for a long time, before I spoke to Ryan and then Maxwell about this paper.

And I won't try to give Ryan's side of the back story.

But basically, he was, I think, planning on drafting something along these lines independently.

We got in touch.

through Carl Fristen, I think.

And it was pointed out that I was drafting something on the same thing.

And then I ended up just hopping on board to work on certain sections and to sort of help carry through the argument.

So that's a little bit of background.


SPEAKER_00:
Awesome.

What sections we can look at the roadmap?

did you work on or also if you have any thoughts on this overall structure of like what sections did you include and why did you order them in that way?


SPEAKER_02:
Yeah.

I mean, I guess, I mean, really we, we share credit for it, for all of it.

Like it's, there isn't anything, you know, I, I, we, we contributed to the, to the whole paper.

But the, the sections that I was more that I leaned more on maybe, and that I contributed more to were the thing about,

Quantifying the Motivational Force of Desires, Section 7.

And then we also had a bunch of back and forth about the last few sections, Free Energy Principle and Direction of Fit.

So, I mean, Ryan, being the first author, definitely did a lot of the writing.

But those are the sections that I had more to do with directly.


SPEAKER_00:
Awesome.

And then just one more question, Alex, and then we can go back to our open list of topics.

What would you characterize the big question of the paper as?

What do you think would bring somebody to this paper because they were wondering X?


SPEAKER_02:
Yeah.

I mean, so it's pretty, I think it's pretty clear in this case, right?

Fortunately, it's pretty easy.

It's just, the question is whether, uh,

The active inference formalism, particularly a certain strain of that sort of discrete decision model flavor of active inference is consistent with or compatible with folk psychology and the VDI model in particular.


SPEAKER_00:
Great.

Okay, and then also, what would you characterize the BDI model as?

And then we'll open up for more questions.

But just to get some of the prerequisites, and you're right that it is great that it is clear.

Many papers have much more esoteric big questions, and this one is very down the middle.


SPEAKER_02:
Yeah, one thing I liked about working with Ryan is that he sort of wanted to just make the title of the paper a declarative sentence that says,

This is what we're claiming.

And I really like that.

I'm going to try to follow that in some of my work.

But the VDI model, I don't think I have a whole lot to add here either.

It's just the idea fundamentally that beliefs and desires interact to form intentions.

And that's, I guess, maybe also that that's a legitimate way to explain behavior for some class of systems, intelligent systems, people, agents.


SPEAKER_00:
All right, awesome.

So Ali, Dean, or Duvid, if you have any questions you'd like to raise at this time, otherwise we'll go into one of these pieces we've raised.

Yes, Duvid.


SPEAKER_03:
It just, I'd never heard of Hilton or the folk psychology BDM model.

Is that a prominent model you purposely chose or could this be, you know, fill in for basically any non-scientific or introspective or even dualist model for

for consciousness, or is it a bit specific, this Hilton model?

And are you claiming that it fails as a materialistic model?


SPEAKER_02:
Yeah.

So I think part of the reason we referred to the BDI model was to sort of bracket for the purposes of the paper, although I'm happy to discuss it here.

a lot of questions that minorize about folk psychology and what exactly is meant by that.

So if we just say we're talking about the idea that beliefs and desires interact to form intentions, then that's a clear target.

And then, of course, there are many different conceptions of, maybe there are many different folk psychologies and views on

uh in that vicinity but like uh i guess yeah the bdi uh models is sort of maybe supposed to be like a an essence that you can distill from many of those different um perspectives now maybe that's not true we can talk about whether the bdi model is really common to different conceptions of folk psychology uh because i i you know

I have to think about that.

I kind of assume that it is.

I'm curious about the materialism dualism issue.

I don't see, I guess, directly how it plays into things at this level of description, because I guess we're not claiming necessarily that beliefs and desires are material or not at this stage.

But anyway, happy to get into that.


SPEAKER_00:
Yeah, feel free to unpack that, David.


SPEAKER_03:
Yeah, I mean, just classically, obviously people have had minds for as long as human existence.

Maybe if you believe in Julian Jaynes and evolution, that there was an origin to consciousness in the mind at some point.

But historically, most of the Western tradition up till a few hundred years ago believed that these things originated from a non-material source, whether it's soul, however you want to explain it.

uh but uh you know as the controller from the greek model of the soul ethos logos pathos or any model that you know so beliefs and desires that the that would be the controller that would uh be decisive in these uh cognitive functions don't arise from the material so if you have a materialistic model where you're saying that these things do in fact arise from the brain

um you could say that uh you know the ancients were just incorrect either either in ascribing non-material origins to things that have material origins or you could say they were completely incorrect and like in a limited perspective that there is no such thing as belief or desire or there is no such thing as a as like a unified

um, I, so as a way of human Hilton has some sort of material division, even Freud, like even, even going back to Freud just a hundred years ago, uh, the question of the psyche and the subconscious, uh, you know, whether that has material origins or not is unclear.


SPEAKER_02:
Right.

Yeah.

So, so I guess, I guess my perspective on this, I'm sort of a methodological materialist about these things.

Like I think that you can,

Insofar as, so in terms of like the scope of this kind of explanation that we discussed in this paper and active inference in general works with, I think anything that you can explain about the causes of intelligent behavior, I think you can probably put a material gloss on that, but I'm not,

Personally, I'm not really committed to the claim that you can explain everything about people in terms of input-output mappings.

But insofar as you can conceive of some function, whether cognition, perception, whatever, as a sort of input-output mapping in space of behavior, then I think you can explain it using these frameworks interpreted as descriptions of brain processes.

So it's interesting that you kind of contrast

Or you suggest that maybe there's an argument for eliminativism.

If you were thinking of mental states as having a root or a source in something non-material, maybe then if you reject that idea, then you'd be prone to eliminativism.

So coming back to the idea, I'm starting from a sort of methodological materialist standpoint, but I'm definitely not an eliminativist.

Actually, the one thing I wanted to get into today is I really don't understand

I don't understand how illuminativism is a tenable position with respect to folk psychology, if you're a materialist, because I think that there's just, well, I'll hold off on getting into that, but I think, I guess I'll just, just one last comment on this.

I think the question of whether beliefs and desires and intentions and other mental states have any non-material aspect and the question of whether they exist and whether they should be eliminated from our ontology are distinct.


SPEAKER_00:
thank you I think this is a fine place we'll have a lot of time to explore other avenues but it would be awesome if you could describe the limitivism and also um there was a quote in your paper where it says if the worry is founded that there's a tension between active inference and folk psychology specifically the BDI model it could be taken either to imply that active inference models are implausible because reasons or

if and to the extent that the models are successful, to imply that desire should be eliminated from scientific theories of psychology.

So what is eliminativism, and how did you interact with that topic?


SPEAKER_02:
Right, so eliminativism is, as we're using it here, and I think this is the mainstream sense, is just a view, well, I guess, okay, the most general version of the view with respect to anything is just that

that thing should be sort of eliminated from serious discourse or serious theory, maybe scientific theory.

And I mean, the idea that the Churchlands have in defending eliminativism about folk psychology is that it's like a failed theory.

So the basic idea is if theories, I suppose, survive on the basis of their predictive and explanatory power and

some other criteria, you know, theoretical virtues, the ability to evolve and explain new anomalies, apparent anomalies that crop up.

So the Churchlands basically think that folk psychology has failed this test.

So the theory of folk psychology has been falsified, and we should just move on.

And that's, I would say, you know, to be sort of a...

precise, that's a version of illimitativism applied to mental states.

But that's the view that we're really talking about here.


SPEAKER_00:
Okay.

Yes, David, please.


SPEAKER_03:
Yeah, I guess there's different schools in illimitativism, but if you want to take that to consciousness studies in totality, or questions of free will, or like I mentioned, the ancient dualistic understanding of

uh consciousness is you could take a limit of some to consciousness in totality that the the man is a mechanistic computer and even uh you know as as a mystic i would argue possibly against the strong interpretation of active inference that's a atheistic eliminavistic model and you might

not you know for philosophical reasons not want to be a limitivists and therefore try to defend it uh but uh then you know what are the mathematics what are your claims actually say uh but yeah i mean the strong levels say that uh there is no uh there is no belief there is no desire there is no

unified I, and we're just an automaton that has some sort of threshold interaction with the environment and whatever perception in our head that, you know, we have voices in our head that might make us think that we're conscious beings, might make us think that we have self-control or, you know, beliefs or even free will are essentially illusions of the mind that have nothing to do with our actions.


SPEAKER_02:
I could just, how do I do follow up?

This is the author's privilege.

Well, great.

Yeah, I would just, it's a good question, how consciousness fits into this picture.

And I'm not sure whether the version of illuminativism that I took myself to be targeting here

includes consciousness or not, it's mostly been a view that's focused on the idea of discrete mental states that play these functional roles, beliefs and desires and so forth.

So, yeah, I definitely think there's further questions about that.

And I can see, yeah, I can see how you might interpret active inference, not just active inference, but almost any mainstream sort of, you know, theory in like neuropsychology and that

vein as as implying a form of illuminate of ISM if you think that these mental states are by definition not material or not entirely material but again I'm happy to get into that further hmm yes the the idea that any kind of modeling by making it specific


SPEAKER_00:
is approaching or on the road or slippery slope or already reached the point of eliminating the need for appeals outside of that description it's also possible to consider that an entire category error and say we're describing brain processes which is i believe what you said earlier and no description of a sunset

is the territory of the sunset math is not the territory as we hear often and so how can one be a limitivist about a process with any kind of description whether it's predictive processing or active inference or any other kind of model um


SPEAKER_02:
Yeah, I raised my raise my hand here.

I'll just raise my actual hand.

Yeah, I mean, another thing I just don't know what you just said that I should bring up here is that I mean, strictly speaking, I suppose active inference isn't committed to these being directly descriptions of brain processes.

They're right, they're sort of computational models of decision making processes with beliefs and all that.

And of course, if you take the

There's this whole background of the free energy principle and all that that links this to physics and the physical nature of systems.

And I tend to read these models as pretty transparently mapping onto brain processes, but it's not necessarily the case that you need to be committed to that interpretation of these processes as material processes when you use active inference to describe some system at the psychological level.

And there's of course still a lot of question about how the psychological description maps onto the physical description, which I have views about, but it's an open question.

Awesome.


SPEAKER_00:
Uh, Dean and then Ali.


SPEAKER_04:
So in the paper itself on page seven, I think there's a paragraph that kind of refers to all of this that we've been talking about.

I'll just quote at the relationship between conscious and unconscious computation, therefore remains an open question.

That said, some specific DAI models have been used to describe higher-level cognitive processes that can generate conscious beliefs and verbal reports, and then it says who the authors are.

In these cases, the inferential prediction error minimization process can still be seen as subpersonal or unconscious, but the resulting beliefs and decisions themselves are assumed to enter awareness.

As a general rule, however, subpersonal processes in DAI should not be expected to map one-to-one

with consciously accessible or personal level processes.


SPEAKER_00:
Great.

So I've copied that up on the slides.

And Dean, what do you think that spoke to or what made you want to share that?


SPEAKER_04:
I think the first author and the other authors were essentially saying, let's make sure that we don't try to conflate things here, that we focus in on what we're trying to do here, which is point to the potential of these formalisms

explaining something if a person can self-report.

If they can't, there's still aspects of this that might apply.

But I think they were just trying to clarify exactly what they were pointing to and not pointing to.


SPEAKER_00:
And Ryan Smith has made clearly a line of research as well as multiple live streams and exhortations on social media about this distinction that one can take a cognitive modeling approach of report behavior.

Did you see that or not?

And that can be very clearly, although subtly, distinguished from the actual awareness of seeing something.

It's not the same thing to have report behavior as it is to have the experiential underpinning

they're potentially adjacent questions or there's a space that they're linked in a meaningful way but it's quite possible to blanket literally one's uncertainty about the question of experience even in a visual or a multimodal way from the question of let's just say we had

the animal or the computer program in the chair and now we're making a cognitive model of its report behavior different question than can the report behavior model be one of the same as what is actually happening because there could be an inter leaving stage where they just choose to lie or other all these other kinds of interesting things happening ali


SPEAKER_01:
Yeah, and just as a brief side note, I think the term folk psychology here can also be related to the distinction made by Wilfred Sellers between manifest image and the scientific image of human beings.

And the manifest image being our understanding of ourselves as personal and social beings.

And obviously the scientific image speaks for itself.

So I think the term folk psychology can possibly be

uh, equivalent to this manifest image of ourselves.

And, um, yeah, that's just a side note I wanted to share.


SPEAKER_00:
How do you see that Alex?


SPEAKER_02:
Yeah, I think, I mean, I, I'd almost agree.

I would just say maybe, I don't, I don't think I would say full psychology is equivalent to the manifest image, but I think it might be a part of it, which is probably nitpicking, but there just might be more to the manifest.


SPEAKER_00:
image of ourselves than just folk psychology but anyway i basically agree um yeah yes the the question dean anything you want to bring here no this reminds me of with

the conversations we've had on linguistics how there's one view on language as a entity like out there body of knowledge and then there's also the person's self-constructed sense of language and they only have a partial subset of the words or they use them in a certain way and there's an analogous distinction where

there's folk psychology the academic field of versus people's inner sense and how do people generate their inner sense of manifest image if if that's appropriate and how can that be connected and mapped to again any descriptive model or disciplinary or transdisciplinary model on alex and then do it


SPEAKER_02:
Yeah, so I really should take the opportunity to say that my conception of how folk psychology works is like thoroughly Sellarsian.

It's like, I think he got it exactly right.

So basically, and it's been a long time since I've tried to recite this, but basically just the idea that there's sort of verbal behavior, right, that people enact and engage in that we end up sort of associating with

other things that are going on internally, and that through this sort of process, we end up sort of inadvertently in the course of evolutionary history at some point.

There's this whole Solarsian myth about this stuff, but basically the idea is that folk psychology sort of arises, and introspection and things like that, and I may be putting a bit more into Sellers than he actually says right now.

Again, it's been a while, but basically the idea that introspection and our sense of self-awareness and stuff like that sort of

could have developed out of, first, outward behavior.

And then we sort of become sensitive to correlations among these outward signals, and that develops sort of an inner sense in that way.

But the fundamental idea that's relevant to this discussion, this paper, I think, is that folk psychology is just the name for this sort of thing that naturally developed in the course of human history.

I got to say, of course, there isn't just one folk psychology right there.

For one thing, people speak different languages.

But I do think that the piece of it that I think is, is pretty, pretty safe to say is true, or I think, and that we meant to capture, this was my take on why we were using the BDI model is that, I mean, pretty much anyone, this isn't entirely true, there are different, you know, dialects and things.

But basically,

if you want to understand why somebody did something, you can say, oh, they believed X and they wanted Y, right?

And they intended Z. And that's the level at which I mean to sort of endorse folk psychology is just, I don't see how that sort of psychological, and I got to say, it's not for me, my motivation for sort of wanting to defend folk psychology isn't really anything to do with introspection or consciousness.

It's just

We obviously use these terms to explain behavior, and we do it very successfully.

And so I don't think it could be the case that these terms fail to carry information about the states that people are in.

So this is why I don't quite get the illimited to best argument.

Anyway, that's gone a bit far field from where we started.


SPEAKER_00:
David, and then anyone else?


SPEAKER_03:
Yeah, well, I think, I mean, as a, say, a spiritualist, the limit of this argument is saying that's the natural conclusion of what you're saying and you're drawing from the dualistic tradition when you use these terminologies.

So, you know, say that all of the thousands of years of Western tradition that believed in the soul, and then you want to borrow the terminology.

from a materialistic point of view, it may not be accurate and follow the evidence and think, you know, Jerry Fodor and the modular mind or Benjamin Lieblitz experiments that, you know, what is active inference actually saying?

It's a threshold that is reached

that causes activity in, you know, like leave its famous experiments where the threshold is reached and it could be measured in the brain before the, you'll call the active conscious part of the person recognizes it.

And if it was like a modular mind that you have multiple conflicting parts of the person that could have beliefs and motivation, but what we would call

the you know the module of the mind that creates the narrative for us is only one of those and that's just what active to the person so when i interact with myself or you interact with another person through language you only have access to that one part of the brain that creates a narrative but you know said the liebits experiments uh and you know a few you know more recent experience has demonstrated that that's not likely the part that controls action

And your active inference didn't exist then.

I mean, Bayesian mechanics did, but you're saying it's a threshold and there's all sorts of things that cause a person's threshold to be reached.

And active inference could potentially model that.

And then if even you put in your paper that you could include things like

if you want to call beliefs or desires as higher order rules.

So even at the point, there may not be a mechanistic understanding of what's the origin or how these higher order rules operate, but it would be some sort of free energy principles, some sort of mathematical reduction of a threshold being reached

where the sum totality of conscious and subconscious factors cause the action and even the person ourself through introspection isn't going to have full access to that.


SPEAKER_02:
If I can just respond here.

I think first of all, just to be respectful to my co-authors, I should say, because I might get into my own views here, which they don't necessarily share that that's all.

I should say, I think this paper is really targeted at explaining the connections potentially or clarifying the connections between folk psychology, whatever its implications, right?

Whether folk psychology carries implications of soul type things because of its roots, maybe it does.

But anyway, it's trying to clarify the connections between active inference as just as sort of a formal theory of decision making and folk psychology.

So anyway, it's neutral technically on the issue of whether active inference is true or is an exhaustive or true description of what we are and what we do.

Maybe there's still an issue there.

If you really think that folk psychology, that the terms, the very terms of folk psychology carry dualistic implications, and if you think that active inference

carries materialistic implications, then there's still a problem, I guess.

I guess I don't really know if I agree with either of those, but... Yeah, I mean, I don't... I guess I don't see how the...

I don't see how active inference as such implies anything one way or the other about whether there are non-material origins to behavior.

Let me try this.

I'm just trying to see if I get your argument, David.

We're saying that active inference, or let's say active inference as a framework, says that this is how decisions happen.

You do a search over policies, which are these discrete things, and you figure out the expected free energy, which has to do with comparing sensory data to expected sensory data.

And I guess if you think all of those components are pieces of a material thing, right?

They're all beliefs or desires or something like that, which you take to be.

I mean, actually, I think I can answer this, sorry.

I realize I'm not doing the best job of this right now, but at least I'm getting, this is difficult.

I'm glad you're bringing this stuff up because this is actually, this gets quite challenging.

But I think, so active inference is this theory of, well, DAI is this theory of discrete decision-making that appeals to this, you know, to these,

distributions or things that are like belief distributions, right?

A belief distribution and a desire or a preference distribution.

I don't think it says anything about where the preference distribution comes from.

And in particular, I don't think it says that it doesn't come from the soul or, you know, or some deeper thing.

So that switched from me trying to rationally reconstruct your argument to me trying to

Rebut it.

Sorry about that.

But I'm just trying to make some progress.


SPEAKER_00:
Let me try to walk through some of these steps because I agree it's an important distinction.

So the focus of the paper, the regime of attention of the paper, very clearly written to remain on a line because there's many open threads related to, for example, different cultural folk psychologies, various folk psychology models, various metaphysical claims.

The paper was focused on identifying one possible area of incompatibility, which would be the relationship between the BDI model entities, the nodes in the BDI graph, and assignment of terms for specific parts of the active formalism.

And identifying that we'll come back to.

Now, then...

As has been pointed out today, one could ask if folk psychology carries a dualist implication in the sense of there being material and non-material types of things, whether implicitly or axiomatically or historically, but if folk psychology has a dualist implication,

and active inference carries a purely materialist implication, implicitly or explicitly, then there could be another battlefront of tension, which would not be based around mapping the nodes in the BDI model to the nodes or the formalisms in the active formalism, which is like a theory-theory ontology map question, but this would actually be

a metaphysical incompatibility.

And then Alex, you walk through some steps that said, if active inference is a framework that says, this is going to be a model of how decisions happen.

There's a search over discrete policies.

There's the calculation of variational free energy and or expected free energy.

And then you added as part of a material thing.

then it is going to be incompatible with anything in material.

However, one could also simply say, Act-Inf is a descriptive framework saying, here's how I will model how decisions happen.

As a search over discrete policies and as the calculation of FE,

then there might be one two three four kinds of things in the universe or it could be anything but this is where the materialism enters is actually as a clause in the assumptions of that string rather than materialism arising as a consequence of the neutral descriptive formal basis of the framework what do you think about that alex


SPEAKER_02:
Yeah, thanks, Daniel, for articulating that so well.

I think that's basically right.

And just as a specific example, even if you go so far as to think that you can map this formalism onto brain states, you don't have to think that brain states get their status as desires or beliefs just from their material constitution, right?

Do you believe that free will arises in microtubules, for example, or something?

I don't know how that works, that theory, by the way.

I don't mean to disparage it either.

I just, I don't know how it works, but I'm using it as an example.

Maybe you think that free will kind of somehow bubbles up through this free will at smaller scales or something, right?

So I just don't think that even if we take this as a description of the brain, that we're committed to anything so heavy as materialism.


SPEAKER_00:
Thanks, Alex.

David?


SPEAKER_03:
Yeah, I appreciate your research.

I'm not here to debate dualism here.

I'm just saying that if we could recognize what are the assumptions or axioms.

So you have questions, and that's why I like your focus on motor control connected to sense perception.

So if there's your perception of a unified I,

And even like Daniel and his research on ants or something like that, that, okay, there's David, Alex, Daniel, all the panelists, Ali and Dean that are talking to each other.

We might refer to ourselves as a name, but is there a unified I?

And so, okay, that's an axiom that is based on a dualistic tradition that may or may not be accurate.

And if you said, well, there's a sum total

of forces that are limited through the free energy principle that we refer to as unified eye that makes decisions but that's more a lexical misnomer and even if you think daniel's uh research and answer something like that that a question like is there a unified ant that avoids death that tries to survive why does the ant have some sort of will to live if i argue that that's also non-materialistic the ants

will to live or that there's a unified force.

So, I mean, you could have a materialistic explanation like higher order rules and just leave it that I believe that these higher order rules stem from genetics or some sort of

uh you know parallel like all ant uh reverse anthropomorphization of machine learning where an ant has some sort of will to survive and therefore you know if you try to step on an ant it's going to move the other direction or something like that but is there actually a unified force in the ant that is uh telling it to survive that causes it to act in a unified way

Or is it just, you know, the free energy principle and a reduction of all of the various sense perceptions?

And, you know, so we are using these axioms from a dualistic perspective, you know, like specifically what we call the unified eye that makes more sense as a non-material force that chooses the eye that's not my body.

chooses to make this action.

And so if active inference is saying, no, it's a sum total of sense perception, some sort of higher order rules that are acquired through a combination of genetics and other machine-like processes that we use the language description as I, but the mathematics is really saying that's not really accurate.


SPEAKER_00:
And Alex, to you, and I'll also just recall way back when, in 2-2-2-2-2-2-2, when we discussed your paper, Psychophysical Identity and Free Energy, which very directly tackles this question of identity, materialism, physicalism, various other processes.

Just want to drop that note and feel free to reply to it.


SPEAKER_02:
Yeah, that's great.

Um, yeah, yeah.

The reason I get so excited about this stuff is that I care about it and I definitely don't take like a sort of default materialist position on this stuff.

Um, so I guess, I mean, overall, David, like my, my view here is sort of about the self and, uh, you know, the self and the self with a capital S maybe in some like Buddhist type traditions, I'm, I'm actually a fairly, um,

far on the on the mystical end of the spectrum myself.

And, and for that reason, I don't expect now I'm sorry, this is maybe not addressing what you said in all its nuance.

But basically, the gist of how I see this is, you shouldn't expect that thing, the really special thing that we don't want to eliminate, you shouldn't expect it to show up in our descriptions of things, because you can't describe it anyway, it's transcendent.

So, you know, even if the brain is identical with the mind, insofar as we can describe the mind,

The mind isn't identical with the mind insofar as we can describe the mind, right?

It's the thing.

It's the big self that we can't ever pin down with words.

And actually, out of respect for that thing, I am happy for it not to show up in the descriptions that we give of how this material stuff works or even how anything works, right?

Because insofar as you can reduce it to a description, it's not that thing.


SPEAKER_00:
thanks alex and and to kind of add some thoughts there um the paper clearly delineates two variants or applications of the active inference formalism which is mai motor active inference and dai decision active inference and the the two theories differ in at least two important ways

or these two applications of the frameworks differ in at least two important ways.

The first is the phenomena that they are targeting to describe, whether discrete decision-making and planning behavior or whether motor behavior.

And then there's the question of discrete and continuous modeling.

And so for reasons of biology and historical precedent, the motor models have come from the continuous category

while many of the decision-making models which often map onto things that are legitimately categorical in the world like a team maze or a planning or sentence generation task has a discreteness or categoricalness to its basis and that made me think about linear regression as i really like to think about because

in the history of linear regressions no one said you used a linear regression to model the stimuli intensity and the behavioral response so you think people are a linear regression and this is another mathematical formalism that in some ways although i'm happy to also update my model on this is

able to be interpreted, but not the only interpretation, as having an equal epistemic claim to the territory as a linear model, because they're formalisms.

And the least squares error in a linear regression, that which fits, which is not the only norm one could choose, but whatever function is used as the imperative to fit that linear regression, could be playing an analogous role to like the calculation of variational free energy.

It could be purely understood as a modeling heuristic

that's used to make statistical comparisons within a model.

And then also the linear regression framework can be used to make discrete decisions like breakpoint regression, where you can contrast two different alternative models.

And you can say,

is it more consistent with one regression or is it possible that there's some break point, a two parameter model that we're going to identify?

And so I try to always be thinking like we're on the freeway and here's the action framework and here's the linear regression framework.

And if there's going to be some claim about active inference or free energy principle at all,

about what the formalism means, I always like jumping from car to car and thinking, would people or do they or have they said that about linear regression?

And if they can't, there better be a good reason why they can't.

For example, people who are committed to taking an interpretation of the territory based upon anything of the ACT-INF map, do they think that that is something that's true of all different statistical modeling frameworks and they'd apply that to a linear regression?

or is there something different in the active inference formalisms that legitimize or warrant that kind of a interpretation beyond the linear regression that was the first point and then the second point was about alex very beautifully said with like not expecting the transcendent

and that which cannot be named or however we want to think about that space to appear in the immanent and in the specific realizations, I think it's very important that the axioms are stated in self-contained scientific argumentation and rhetoric.

Although, unstated axioms come in at least two types.

One are the secret axioms that you made and snuck in.

Like, we didn't mention this issue, but we're going to use it as if it was an axiom in our deployment of a broader argument later in Section 9.

Alternatively, an issue might not be addressed because the argument is agnostic or orthogonal or blanketed with respect to that axiom.

Like, you didn't mention what color shirt you're wearing because

not you're going to use it and slip it into the argument later, but rather that the argument being made is uncorrelated or is not related to the shirt color.

So I think that the potentially even aware avoidance of the metaphysical baggage precursor exploration in this paper

is not to say that the issues are unimportant as various other work by all the authors actually speaks to but rather that this can be understood as a specific sequence of thoughts and rhetoric and symbols

that update belief on the relatively narrow, although still quite broad, question of whether the concepts, categories of B, D, and I can map to aspects of the actant framework, just like the linear regression slope could be mapped on to the concept influence of X on Y.

Not that that still wouldn't have some ability to be critiqued in the future or nuanced by future modeling, but you could say the linear regression model is not inconsistent, does not contradict, not that it proves, but it does not contradict folk regressionology.

So active inference models do not contradict folk psychology.

Linear regression models do not contradict or negate folk causal inference.

anything that's going to break beyond that epistemic map is going to need to make a special case beyond people have interpreted this way or somebody who wasn't paying attention might make the mistake of believing X. So sorry for the extended piece there, but I think there's so many important aspects that this paper either guides us on and also takes us to a vista of.

Do you...


SPEAKER_04:
I'm not going to be able to articulate it as clearly as you just did, but here's my thing.

So coming at the paper with my background, my question ended up being, so if we're going to compare something that adds two things up, a belief and a desire, and out pops an intention.

And then last week with Alex on, sorry, Alex, with Brian on here, we started moving to the idea that with expected free energy,

The ability to see the discrete, the difference between the ambiguous and the risk was a difference.

So it's not an adding up to come to some conclusion.

It was an actual knowing that we want to try to move things that are apart closer together.

And so from the standpoint of writing the paper, now the question is, can those things work in concert?

can one approach which says these things add up and then we behave accordingly work at the same time as this other way of quantifying which says there's a variational part that we're trying to minimize and there's an expected part that we're trying to juggle as well.

And so I think when you get closer to the end of the paper and you talk about the world to mind and the mind to world,

That isn't necessarily always additive.

That's still a differential.

But I don't think you, as writers of this paper, disqualified what's going on with the, well, we can add these two things together and this is what pops up.

All I think, and it's said through the paper many times is, under these particular types of sins, the difference seems to also

determine what degree of desire or belief or, I can't say doxacity, might pertain to that expected free energy difference.

So again, that's not as eloquent as Daniel or you can describe it, but from somebody who's way down here and just trying to make sure that in my own head,

That image right there that's up there where suddenly the circumstances have changed and I've gone to a desire that says, well, I can't change gravity.

So I'm going to make the biggest crater I possibly can instead of the outcome, which I'd like, which is to continue to exist.

Maybe my identity now is how big a hole in the earth I can make.

So that's a difference as opposed to an adding up.


SPEAKER_00:
Thanks, Alex.

Feel free to respond, and also we'll look at expected free energy and the simulation.

It'll be great to explore those.


SPEAKER_02:
Yeah, cool.

Yeah, so I think I got the point about halfway through.

I'm seeing where you're getting at.

It's interesting.

So I think, I mean, my first answer was, well...

Okay, we shouldn't think of belief plus desire equals intention as literally involving a sum.

You know, since I've been doing a lot of writing code lately for work, and I would think of it as like, well, we define the sum operator for belief and desire as just the thing that active inference does, right?

Essentially, right?

Basically, belief plus desire means take the KL divergence.

But a more informative answer is, I mean, if you want to think of it as a mathematical...

type operation, like a sum or a difference, I think you're right, being that it's much more like a difference.

It's much more like intention equals desire minus belief, right?

So it's like you have your model of the world, you see what the difference is between the belief and the, sorry, between your model currently, sorry, you have your model of what you want the world to be like, rather.

see that what the difference is between that and your model of what the world is like and uh and that gives you the expected free energy but um i know you said we get to this in a second daniel but um i think you could pretty much literally see this in the expected free energy um in the kl term there right so yeah so you could expand that so q of the divergence between q and p you can you can write this out in a way that's you know where you're subtracting one

entropy from another, basically.

And so you can see it as literally a difference.

So if you want to map it onto the difference concept, then it's pretty straightforward.


SPEAKER_00:
And that's one feature of the logarithm function as a modeling heuristic, not metaphysical truth, that

division is a division of different terms like the ratio is related to the subtraction of the log of the ratio so there's various reasons why like log likelihoods are used and it's also a core function that's deployed in the KL divergence as well as entropy terms and then just

Yes, duvid, but just to get through the variables here, it's written out in the paper, but a KL divergence is describing a divergence, not a distance, between what are on the two sides of the double line.

And this is the Q variational distribution of observations over a time horizon conditioned upon policy, which serves also a very important function heuristically, especially in the discrete case, and the divergence between that observations conditioned on policy and the posterior distribution on observations through time.

just that's what's in the kl term and we explore this also more in the dot zero and we can return to it as well but just wanted to clarify like and contextualize this to some of our early discussions like this is the y equals mx plus b of this framework and the least squares is like fitting the minimum of something and so again to go beyond the interpretation of linear modeling here not that this is a linear model

requires sometimes describing either the specifics of this model and how it differs, or taking a vaster, potentially extremely untenable position about the naive interpretation of variables in arbitrary equations, which I think is fair to say is an untenable position, which puts the onus of people making metaphysical interpretations or claims about this line into a place where the specifics of this line must be addressed.

Dean and then David.


SPEAKER_04:
Just real quick.

I think for me, it's hard to determine whether or not a relationship or a diversion or the difference is material or not.

And so for me, sometimes that just depends.

Sometimes I can actually

see the edges of the relationship.

And sometimes it's very, very fluid and it's hard to determine whether or not there's something material about that.

And that's actually baked into this formula too.

So I don't know what others think about that, but I mean, there is an aspect of this that is written in, but I don't know if we can actually lock it down and say that that thing, that relationship there is actually material or not.


SPEAKER_00:
Thanks, Dean.

David?


SPEAKER_03:
Yeah, I think just looking at it as a statistical model could be used to model any higher order rules with a feedback mechanism, whether the origins of them are material or not.

So we don't have to go into America around talking about what's the origin of these higher order rules.

And I was just thinking the phenomenon of folk psychology applying to humans

and the belief desire intention model if we were looking at a simpler model you know i think like obviously you know daniel studied ants uh but at what level is there uh sense perception and motor control and does that need um

a controller.

It was just a pure feedback mechanism, like action, reaction, and their decision is made based on higher order rules that, you know, I don't know if you'd consider an ant, if you just simplify it, like eat, survive.

And even, you know, if an ant doesn't have reproduce, if even you eliminate like an ant colony where only the queen

reproduces and possibly in humans, you could say the only difference between a human and the ant is you add the reproduce, but you have these higher order rules of basically survive.

And you maybe that's maybe there's only one higher order rule, or maybe you want to give a whole bunch of higher order rules.

And then you define that in your free energy principle, like, okay, so you have the sense perception, and then you have

the movement and so how you define the variables in the feedback mechanism, the active inference mathematical framework could model it no matter how you define it.

And this thing also, I mean, you obviously were focusing on humans, but it might be more simplified to

focus on, you know, the most simplified species, even plants, maybe that they don't have a survive instinct that they, I mean, they have some sort of survive instinct, but like, you know, insect that could try to survive.

If I try to squash an insect, it's going to move in order to try to survive.

And that's a clear example of sense perception.

The insect senses me, you know, trying to kill it, God forbid.

and then moves out of the way of what exactly caused it.

And so you're just going to hypothesize, well, of course it has some sort of survival instinct and the sensory perception feeds in to its motor control movement versus if it's just seeking food or like a Maslow hierarchy of needs.

and uh you know i like the terminology you know anthrop if we're anthropomorphizing you know the ant or are we reverse anthropomorphizing the machine that the fact is in terms of sense perception motor control we understand how the robot computer works much better than the mind and so are the active inference equations really more suited to machine learning robotic automation

And then where you reverse anthropomorphizing that to the human mind.

But certainly the equations are valuable because largely they could be interchanged and defined how you want them to.


SPEAKER_00:
thanks i'll connect some um ant thoughts to the skydiver so dean has returned to this example of the skydiver as being like well if i can't change gravity my policies whether mental attention policies pray or no pray um

you know, do this motor behavior or do this speech behavior, which is a motor behavior as well, conditioned on policy, not going to be able to influence gravity.

And then once updates there prior that also conditioned upon various action policies, they're not going to be able to open a functional parachute, then there's this discrete shift as you've described to like making the biggest crater.

And hearing about the ants, over the years,

it makes me think about folk biology, like the notion that people have in terms of their received understanding that there is like a drive to survive or a drive to reproduce or a drive to do various numbers of things.

It's almost like the BDI of evolutionary biology or of ecology.

And I'm thinking about the case where a nestmate is out foraging for the colony

then they're being like messed with by somebody with like a magnifying glass or being touching them and at first it's like evading now that behavior looks a lot like a solitary insect that might be trying to evade and survive ostensibly to reproduce and increase like its um individual offspring if one is still within the folk biological realm and then it's like there's a switch where the nest mate is actually like no

the evolutionary unit is the colony and so it goes for the biggest crater possible and that's even embodied in the anatomy of some insects for example with a hooked stinger where they can't they're committing six-legged death

to compose a broader high fitness entity at the colony scale and so that's like a behavioral shift from trying to open the individual nestmate parachute to make the biggest crater on the attacker possible for the good of the colony and that no matter how hard you try to map that to the behavior of a solitary insect will be

along a potentially didactic or interesting, but ultimately facetious route because the colony is the evolutionary unit for these obligately used social species.

And so one will be scratching their head at various of the behaviors.

And that's why the value of a descriptive framework is so important because we're able to describe various computational qualities and not be inconsistent or contradicting

folk ant psychology, while also remaining absolutely impartial to questions of what ants think, for example.

And so we can have computational representations of ant decision-making and cognition, perception, cognition, action, impact, and we can link it to natural language descriptions through the active inference ontology, as well as through potentially other ontologies like ant folk psychology,

And we can take that yes and, and other people can add other yes ands if they want, but they're gonna have to take a different tack to uncouple the relationship between these computational quantities and try to interject a wedge and say, no, it does contradict folk psychology.

That's a different argument than that relationship is in violating some other third belief system that I'm bringing to the table.

So hope that addresses some of it.

And thanks, Blue, for your questions in the chat there.

Ali, would you like to raise anything or take us to a question or area that you want to focus on?


SPEAKER_01:
Yeah, one more thing about this discussion is bringing personal semiotics into table, I think.

Well, active inference actually, I believe, is a kind of,

iconic symbol as opposed to index.

Because you see in personal semiotics for index, we need to necessarily allow some kind of causal relationship between the symbol and the index.

But for icons, we only need to have some isomorphic

isomorphic similarities, not to say similarity because similarity is a very vague term, but some isomorphism between the symbol and the icon.

So ideally, active inference is a kind of, let's say, structure-preserving mapping between the behavior and the model.

So I guess if we could differentiate between icons and indices,

some of these, at least, confusions could potentially be resolved.


SPEAKER_00:
So icons and indices of process semiotics.

Thanks for sharing that, and it connects to some of the discussions we've had on process ontologies as well.

Alex?


SPEAKER_02:
Yeah, just really quickly, I mean, I gotta say, I don't know that much about process semiotics, but that way of thinking of active inference and of theories in general as like iconic representations is pretty much how I think of theories and how, I mean, then the most recent thing I published with Jakob Hovey, we basically said,

that you can think of scientific theories as relating to the world by a process, not process, a relation of sort of structural similarity, isomorphism being the sort of case.

So I just, I agree with that.

And I think it kind of comes right back to a lot of what we discussed.

As I get older, I start to think that maybe there's something to the essential indexical idea that like I as a special role to play

You know, the letter capital I in English.

But other than that, I think things pretty much function descriptively.

And I think description functions via isomorphism or similarity.

So I totally agree.


SPEAKER_00:
Awesome.

That reminds me of the book Anthem by Rand, where the word I is not included in the linguistics.

And then the end of the book...

not you know spoiler alert um that word i is rediscovered and so it's kind of an allegory that traces some of these questions about the potentially special role of the bodily identity but it's very interesting that these frameworks actually are engaging

or with this augmented perspective for example that ali has raised that these theories can be seen as already having been engaged in

a discourse that people might not expect like predictive processing is what the brain is doing do you agree or deny what's the evidence for predictive processing being active in the brain versus not active in the brain is this neural signal recording that we made more consistent with a predictive or non-predictive model

It takes that meso range of what the system is doing and it partitions it, as we heard also from Ryan previously, into like, well, predictive processing can't be invalidated, nor can linear regression framework, nor can active inference framework.

Any specific model is now engaged in a specific model evidence comparison.

And then one can choose what kind of model comparisons they want to make

knowing that they're not going to be able to exhaustively consider all possible cognitive architectures but also any invalidation or relative model fit or adequacy amongst different models at this specific level are speaking only rhetorically to the truth or the validity or the adequacy of the higher level inviolable framework

There's a lot there to explore, do it.


SPEAKER_03:
Yeah, maybe we could tie this back to the illimitivism and the anthropomorphism.

So if you ascribe an eye to the computer, you say that's a logical fallacy of anthropomorphism because there is no eye, it's just following code.

Or even to the ant, if mammals may be, but insects communicate, if an ant sends pheromones and you want to anthropomorphize,

An eye to the ant that like the ant is saying, I want to communicate with my fellow ants for a purpose.

And it's like, no, no, that's not that's anthropomorphism, logical fallacy.

The ant is just following genetic code.

And then you say, well, really, for humans also, that we're morphizing the mind and that there is no I related to unified I related to the me.

that even right now that I am communicating with you fine gentlemen, but that's a misnomer in terms that it's just me following my predictive coding and that just for the purpose of language,

I'm referring it to as I talking to you, but that's just like a computer sending code to another computer or an ant sending pheromones or whatever method of communication it uses.

And that's just the language and lexicon that we use.


SPEAKER_00:
Yeah, it's...

It's a dialogue that has played out in not only Gdel Escher Bach, but many college dorm rooms, many late night sessions.

One participant or perspective believes that they have, for example, the ability to choose and have agency, and the other disregards that position.

Or one believes that there's something and there's a divergence in their perspective.

I think this is just the heart of the map territory debate in the distributed cognitive setting, as all cognitive systems ultimately are, even what is called individual behavior is just referring to collective behavior at another scale.

For example, one person can say this conversation can be modeled using active inference, or this conversation can be modeled using predictive processing, just like it could be constructed with a linear regression or family of linear regressions.

And somebody else could say this conversation is nothing but linear regressions, nothing but predictive processing, nothing but active inference.

someone might believe that and if they believe that it would be true that that is their perspective i don't know if that would make it true but they would be taking they would be stepping into a territory that the person who remains with both feet in instrumentalism i'm choosing to model it this way or i'm testing a portfolio of different models around how we could model our difference in perspective

Maybe one can say that they have been too timid and they haven't actually engaged in the real question, which is what's really happening, not with how you're modeling it, but that's a whole another debate.

Alex, and then do it.


SPEAKER_02:
Yeah, I just think this might tie into the stuff in section nine that maybe we'll get to.

We don't have to jump to it.

I'm just saying.

basically, I agree, you could raise these questions for any of these systems, people, machines, ants, protons, whatever.

And I think there's an argument to be made that there's not a clear place to draw the line there.

But it could go either way with respect to all of those, right?

I think that, you know, you could be anthropomorphizing in all of those cases, or none of them.

It's not easy to, I don't think it's easy to draw a line somewhere along the sort of

evolutionary continuum or anything like that to say, although there's an argument about temporal depth of generative models that's interesting that touched on a couple of papers here and there.

But, you know, I think the cool thing about active inference and the free energy principle stuff is that it applies across scales.

So I think that to me, that means that you're faced with a similar problem at whatever scale you consider it.

I just got to throw out there, I'm probably going to have to leave around

1230 Eastern.

So I'll say that now so that I can just abruptly close my window.


SPEAKER_00:
So we're in the summary of main argument section nine.

So, Alex, what is the main argument?

And also, in the contexts and audiences that you've presented it in?

How do you feel like it lands?

Or what cognitive updates are you aiming to achieve with this argument as constructed and communicated?

Is this section nine?


SPEAKER_02:
I think I actually may have meant section eight, but I'm sorry.


SPEAKER_00:
Okay.

Section eight, desires and affective states.

Oh, no, no, no.


SPEAKER_02:
Let me see.

I meant 10.

Okay.

I don't want to totally bypass your question.

I just think nine is kind of a summary of the argument thus far.

All right.


SPEAKER_00:
How about 10?

Let's talk about direction of fit.


SPEAKER_02:
Yeah.

So, I mean, so the... Sorry.

Sort of the point here was just that there's a...

certainly is relevant to a lot of what we're discussing there's a straightforward way to generalize this beyond systems that you would necessarily intuitively describe as having beliefs and desires and we can just talk about any system that's described by active inference by this framework or that's describable accurately by this framework

you can talk about the difference between q and p um and this i think also ties into some of the work that maxwell remsted has done on um just the idea that you know uh the generative model is sort of representation uh or it's it's sort of a representation embodied by the system

if it's a representation.

We still disagree about that.

Anyway, the generative model and the approximate recognition model are sort of always there, even if you apply these frameworks to describe very simple systems.

And you can see something desire-like or belief-like in those.

And we just remain very neutral in this paper on the question whether there really are beliefs and desires in these sort of

extended cases, by extended, I mean, not necessarily paradigmatic, right?

So if, if beliefs and desires paradigmatically applied to like people, and then maybe to ants, and I would say definitely dogs, you know, then this, this stuff in Section 10 is, is about what you can say without necessarily committing to beliefs and desires and those in the in the edge cases.

But you can still say that there's at least an ingredient of beliefs and desires, which is a direction of fit.

That sums it up.


SPEAKER_00:
So how could this be used in one case for a human entity in the folk psychological way, and in another case for some entity that people would maybe say that type of folk psychology would be inadmissible for?


SPEAKER_02:
I mean, as far as how it could be used in the case of people that have beliefs and desires or that we think do, I think it's pretty straightforward, right?

It's just saying, well, any kind of full psychological explanation you can give of a person's behavior, it's consistent with the description of that person in terms of active inference.

I guess then the only question is, in the case of a system that might be not clearly

that you wouldn't necessarily think of as having a psychology in the same sense.

What kinds of things would you want to say about it?

I think there's an example that made it into the paper about like a plant reaching towards the light or something, or it's sort of these simpler sort of feedback systems, right?

Where something, there's like a set point and the thing is approaching the set point.

You could still think of the prior distribution as having a,

world-to-mind direction of fit, right?

Because it's the piece of the system that brings it about that things change so that distribution describes reality.

Yeah, so you still have those.

So that's one example.

I don't know, maybe like a bacterium following some kind of nutrient gradient or something.

I don't really know about that stuff, but

That's another example that might... You could describe directions of fit to that creature, and I don't... Okay, my last thought on this.

I don't know why it would be useful to do that necessarily.

I don't know.

There might be reasons in studying these systems that you'd want to.

But if you did want to do it, you could understand it from the framework.


SPEAKER_00:
just some brief thoughts and then ali so first there's a paper of calvo and friston 2017 which is specifically applying predictive processing and active to the vegetative case and i think from the perspective of behavioral analysis there's also precedent in the 1989 paper framework for plant behavior by silvertown and gordon

So suffice to say that plants are included within this cognitivist modeling perspective.

And then it made me think about how the surprise, the self-information is an energy function.

It's what dampens the spring.

And so maybe could you say like the heavier ball with folk?

ball psychology.

The heavier ball wants to drop faster or it wants to make a bigger crater or all these other things.

Again, it doesn't have the agency to want otherwise, given the initial conditions and the rules of physics in that situation, but

it's exactly like a person wanting to make a small hole in the paper or wanting to make a big hole and then realizing that intention would be analogous to an energy functional being reduced by some kind of purely physical system which does again hint towards some of the potentially non-materialist implications legacy that do slip in to different encultured conversations around mind um

Yes, Alex, any last thoughts on that?


SPEAKER_02:
Just real quick, yeah, on the ball example.

I mean, I think there is a sense, of course, in which this framework applies.

But I think, if anything, the ball wouldn't have a desire or the system involving the ball might though, right?

So because the term that would pull the ball towards the ground or whatever wouldn't really be in the makeup of the ball.

And so whether that larger system has a proto-belief or desire, I don't know.


SPEAKER_00:
Ali, and again, Alex, feel free to part whenever, but Ali, go for it.


SPEAKER_01:
Well, yeah, I'm not sure if we have enough time to get into this question.

I mean, if not, we can discuss it in the doc too, but I had a question about the aesthetic experience and the pleasure or positive valence we get from engaging with works of art.

In particular, I'm talking about unexpected plot twists in movies or novels or different kinds of intentional ambiguities in some artworks.

For instance, the works of M.C.

Escher and his impossible geometries will immediately come to mind.

And the sense of excitement and joy they tend to induce in the audience.

In fact, playing around with these kinds of defamiliarizations, as literary critics like to call them,

seems to be more of a rule than an exception in any creative endeavor.

On the other hand, outside the safety of the world of arts, we generally don't like to be encountered with too much unexpectedness, as we've seen.

So I wonder whether or how these kinds of aesthetic reactions can be integrated within the formalism of active inference.

Are they special cases of information-seeking drives or

There's a whole other story going on here.


SPEAKER_00:
Alex, go for this, and then thanks again for your time here.


SPEAKER_02:
Yeah.

Yeah, I'll check out after this.

Thank you so much.

I love these discussions.

I knew it would be an interesting crowd, interesting topics.

I got to say, I don't know much about what you just asked about, Ali, but I love this topic.

I actually come from a background in aesthetics as well, I should say.

But anyway, I know there's a lot of work on this.

So I know that under the banner of predictive processing, there's a whole lot of work in aesthetics these days on, I think, suggesting something very similar to what you're saying, that there's clearly a relationship here between surprisal and unexpectedness and predictions and the joy that we get out of and other emotions that we get out of artworks.

And I would love to know more about this.

I haven't had time to look into it, but I think Daniel's put a...


SPEAKER_00:
This was also a predictive processing type paper with an incredible title, Move Me, Astonish Me, Delight My Eyes and Brain, and then enter the subtitle.

sequel title um perhaps in the dot two let's sketch this out let's act let's look at the formalisms and let's do some mappings so someone said i believe that mondrian is an amazing painter and i want to go to a space where i do see beautiful art and i want to have this kind of experience or something like that but let's explore that in the dot too with some of the bdis and the aesthetics of encultured experiences

Thank you, Alex.


SPEAKER_02:
Sure.

If I could just really quickly, I think that the challenge there is going to be that sometimes prediction error is fine and sometimes it's not.

We need to figure out, right, there's probably some complicated way of saying what the difference is between those cases.

But that's as far as my intuition goes.

Yeah, I'd love to discuss it.

Awesome.

Thanks again.

See you later.


SPEAKER_00:
Thank you all.

Bye-bye.

Great.

Dean?

Dean?


SPEAKER_04:
Yeah, I just wanted to kind of jump on that point that Ali was making.

I think that in the, I just want to make sure I've got the right section of the paper here.

Sorry, the free energy principle and the direction of fit, yeah.

Sort of to tag on what Ali and Alex were saying, there's a statement here that says, holding the value of the observation constant in this equation

F decreases as the approximate posterior distribution Q of the state approaches the Q posterior.

The QS term, therefore, is a straightforwardly belief-like mind-to-world direction of fit in that its value changes to accommodate new observations.

I think that the Escher and the Mondrian and every time I go to a sporting event, my openness, my accommodation to

what is perceived as an uncertain outcome is the thing that draws my attention.

And I think Daniel's point of let's map that out.

Let's see how long some people are able to hold that ambiguity space and not necessarily see it as a risk is both immaterial until it materializes and is a process that I think a lot of people want to go through

Because there's something to that that isn't just attention.

It isn't just information seeking, but it may also satiate certain desires.

So I think that is a point to mapping that we should maybe spend a little bit of time on.

Because I don't know that when you open a space up for something to eventually happen, you're...

imposing what the final material form should take, you're simply leaving something open in the hopes that something interesting, i.e.

an Escher painting, might end up being in the next room.

I mean, this is what happens when I go to museums in Spain.

I'm not looking to find the particular Dali.

I'm looking to go into that space and be surprised.


SPEAKER_00:
i wonder how that actually does map out using these formalisms yes it reminds me of when in the dot zero ryan described like the different reasons and the different nuancing the types of information seeking that's very relevant i'm navigating through this museum to reduce my uncertainty about where that one piece that i came to see is

the target driven epistemic foraging from a more general, like, I don't know what is in that other room that is going to influence my probability of moving room to room.

And certainly with the eye circuiting, that is how we maintain a visual field that appears to have roughly equal resolution via our generative model of vision and ocular motor circuiting to regions of maximal information.

distinctly uncoupled from only what regions are most rewarding though people's gaze does tend to linger in certain regions that might be perceived as rewarding that isn't the only imperative and that's why it's so special and relevant

to have a cross system and multi-scale behavioral modeling framework like active inference that helps us understand the pure static field, eyes trying to latch on to anything mode from the gaze on a candle flame during meditation or one region of particular beauty in another visual scene.

Dean?


SPEAKER_04:
Yeah, just real quick.

And I think that also...

Ali, thank you.

You raised semiotics and I'm a Pierce fan.

So there's a, there's a huge piece of that involved in this as well as to what is the signal that, that very much there's a, there's a slide in here that we didn't get to, but when the ice cream cone is looking off into the distance at that, at that ice cream truck, where, where do we, where do we place that in the foreground or in the background?

And that is a huge, I think that plays a huge part in, in,

the role of the third person now looking at the observer, looking at the observer and getting that sort of recursive aspect involved in this as well.

So again, I don't know how that, we'll borrow Daniel's how to be able to map that as a 9-1 or as a 3-7 and then maybe put it on the Likert scale because I think all of that kind of is a potential way for this

to sort of make a sense.

I wasn't bringing up with Alex the idea that like literally beliefs and desires add up to intentions.

I was sort of saying that tongue in cheek just to be able to show the difference when something is discreet and how we try to bring them together.

And this observer of an observer thing, although it's not, I don't think it's Alex's and the other two authors,

primary goal here, but I do think they lower the bar in terms of bringing some of the more folk aspects of this into the formalism aspects.


SPEAKER_00:
yes and it was a very clever and interesting response which is it depends on what is meant by addition what does it mean for um dean plus ali does that mean they're both going to stand on a scale and we're measuring their mass does it mean that we're going to stack them head to toe and then consider the length does it mean that they're going to interact in a certain context

Doesn't mean we're going to blend them up.

I mean, there isn't an intrinsic definition to what the addition operator or any operator means in a formal system.

And so it opens up the idea that we could have whether specific symbols or just here's how we're using this symbol here.

and use that to refer to relatively potentially complex and multi-step operations or operations that can be phrased in multi-step.

For example, a multiplication on the processor might happen in a different way than somebody is cognitively thinking about it, but that

is, as the title hints, not contradictory.

Not that one validates or encompasses or proves the other, but there's so many things that are not contradictory.

And active inference may be contradictory of certain things.

Let's make a list.

What is active inference contradictory of?

What is folk psychology contradicting of?

And we can make all of that mapping in the right knowledge management system.

And the claim of the article, as I guess Ryan's imperative was, was to make this claim that as they've operationalized both, active inference models do not contradict folk psychology.

And that's quite an interesting claim.

Dean?


SPEAKER_04:
Yeah, just real quick.

I think Daniel, your point is, I'm rephrasing it from my own view, which is,

you raise a lot of different joint probabilities that by their nature are arbitrary.

And I think that's important to keep in mind.

This leaves open the possibility of looking at things a variety of different ways.


SPEAKER_00:
Yeah, and just to speak to the joint probability density.

So the joint probability density in the Bayesian modeling approach is like where there's a comma.

So instead of A conditioned on B, it's like the joint distribution of A and B.

why a and b why not b and y why not these three and so there's always something like a periphery that the model comes from and we can be blanketed off from it and that actually serves as a scientific and really meta-scientific way

to have rigor and accessibility potentially of the models, to respect when we're in the regime of attention of a model, what kinds of claims can or cannot be supported, what kinds of contradictions are or are not tenable to make, and then also have the yes and with respecting that that joint distribution was not

handed down from on high.

It is not the only possible joint distribution that could have been selected.

And so we can separate off.

How did these real researchers in this real situation come to focus on that phenomena and pick this joint distribution from conditioned on the joint distribution?

What was the actual conversation and consequences and modeling they performed?

David?


SPEAKER_03:
Yeah, it's all fascinating.

I guess I had two separate points I wanted to express, and they might be more general if this is my first time on this stream than, I mean, it's related to this paper, but specific to active inference in general and the interdisciplinary studies.

um what my streaming partner uh jennifer scharf calls herself church of entropy we've been three years now uh talking about consciousness and i showed her the free energy principle and she immediately said that uh isn't that just the least action principle

And I mean, it's not directly related to this paper, but I could see that in terms of my second point, what I'll call goal directed behavior in general.

And if you want to say that there's only one motivating force in

active inference, and that's the free energy principle, which is basically a restating of the least action principle.

And then at a second point,

I went, you know, last week in Metro Detroit, they had the International Automation Conference, and they had the latest in robotic arms and technology for manufacturer, and they had on display a lot of what we'll call sense perception and motor control, specifically robotic arms that

um don't just repeat the same action or even have like a sensor embedded when but have an embedded sensor of a camera that will recognize the object and then create a set of rules in order to tell the robotic arm the best trajectory in order to pick up the object and then in terms of uh

like old school manufacturer where it would just been taking an object and setting it in one place where it actually has some level of machine learning intelligence, where it could intelligently design where to put the object in terms of like stacking boxes, where it could, you know, the algorithm of the computer could determine what's the best way to stack the objects and then control the robotic arm to do that.

And if it's like, so for humans,

just on the peer level of sense perception has goal directed behavior.

How do I, you know, if we have a hundred million cones and rods in our eye, how do we direct the,

our physical capabilities of sense perception to perceive the environment in this thing that could be modeled by these equations.

And we'll call it the free energy principle, least action principle.

And then the decision making that the goal directed behavior like the automation computer, it has to have a goal code in order to act.

And so it could action, reaction, sense perception,

feedback mechanism in order to action and then the equation are describing goal-directed behavior.

That's why I'm a fan of the active inference model because as a dualist, I mean, as a scientist, let's describe these in purely materialistic things and we don't have to get too much into the theology or what's the origin of these higher order rules, even if you want to assume

that all higher order rules are material in origin.

But I think the equations in general could model it no matter what their origin is.

And it's just a good framework to understand all these theories, the goal directed behavior at all aspects.

And then to put on the last spin on it, like the Maslow's hierarchy of needs,

in uh in like you know what is belief desire and uh you know that i would have introspection or education that would give me um you know morals ethics that okay like my body uh like i put the pithy in the the expression i see the heart desires the mind plots and the limb carry out that uh that uh

I have the capability that my eyes see, my heart desires, but my mind stops me and says, that's wrong.

And even though my sense perception saw it and my desires told me that I should do it, somehow there's this higher order principle of the mind that tells me that's wrong and I'm not going to do it.

And there's that control factor before the limbs carry out.


SPEAKER_00:
thank you i'll just make some short points and then we can just close off with what we're excited to explore in the dot too i really just appreciate what a lot of people shared and i think over these discussions and the years we're finding some clarities around where are different implications and consequences

what is entering into Active Inference as a field and a filter and what is coming out of it, what's happening on the playground.

And so there's just a lot to explore.

Then Livestream 45, just in the last few weeks,

and not to rehearse outside of this paper regime of attention, but the free energy principle, as it's rehearsed in that paper, is establishing the particular partition that's Markov blanketing off the figure from the ground, the thing which is able to undergo repeated measurements in the quantum sense from the thing that is not that thing.

That's the particular partition with the sensory, active,

internal external partition the autonomous states the blanket states from sparse coupling unpacking the implications in terms of Bayesian inference in other words seeing the flow of those states as doing something that is slash can be modeled as Bayesian inference and then finally understanding paths in terms of a principle of least action

which has been starting to be explored from at least the early path formalizations of active inference years ago.

And I think in the last,

two weeks to two years, taking a new view on that through a lot of the work on geometry and analysis by Dalton, Maxwell and other collaborators.

So indeed this path formalization is very relevant and the principle of least action, which isn't the principle of least motion.

It's not the laziest thing.

It's not the one that always works.

It's none of those things, but it's a framework for analyzing behavior.

And with that,

what would people be excited to explore next week or what would be something that they didn't have uncertainty or a motivational drive to explore before today but it has come onto their Horizon through this discussion yes Ali then Dean dude uh well it was uh it was a really fascinating discussion and uh


SPEAKER_01:
I thank you all for bringing such interesting topics onto the table, but I'm very much looking forward to that too.

And I also had a couple of questions.

I'm interested in exploring the phenomenological aspects of folk psychology, especially belief and desire, and also the relation of DAI to

abnormal psychology, which is just briefly touched on in the paper, but not in detail.

And yeah, I hope the next session will be at least as fascinating as this one.

Thank you, Ali.

Dean?


SPEAKER_04:
I already said what I'm hoping we can look at in this point too, but I'll just add this.

I think it's really interesting that the term active inference

And I'll just say in this calendar year alone, we've had a couple of papers that have started typing active inference.

We've had outside the skull or extended active inference.

And now we've got this DAI and MAI.

And I think there's probably going to be more.

And so depending on how many authors are available next week, I might be asking them a little bit about that too.

Like, does that seem like a natural rollout when you have these scale-free ideas that you

need these scale-friendly qualifiers just so that it continues to make sense.


SPEAKER_00:
Thank you, David, and then I'll make a point on that, Dean.


SPEAKER_03:
Yep, and because this is my first time, so I had a lot of general stuff on active inference in general, and I tried to stick straight to this paper.

I think it'd be interesting to cover more.

I asked the question, has active inference even explained one qualia?

And that there's actually a model here in the equations

Could we describe a single process, a single sense perception to decision making?

And so like the human model to a simpler life form, or even say that is in essence the automation, like the machine learning algorithms for robotic arms, is that in essence using the same active inference

computers i spoke to you know brock online who i guess is an entrepreneur thinking like real estate uh but uh is is it you know what would the application of this be uh to uh you know autonomous cars are more complicated but like something the most simplified version which is probably uh robotic sensors and controlled movement based on machine learning that uh and uh and then

you know said could we try to explain a single qualia in terms of what happens when i sense something and make some sort of movement and then like i was talking what would all of the axioms uh necessary to in terms of the higher order rules or goal-oriented behavior they're not beliefs desires intentions

What are they and how are they modeled into the equation?

What happens when I perceive something and that's translated into action?

What axioms do we have to put into the model to make it work as opposed to or in comparison to the robotic arm that's coded for that does that?


SPEAKER_00:
Thank you to all those returning in first time.

And our second Applied Active Inference Symposium, which is going to be in July 2022, is on robotics.

So we can absolutely address a lot of the applications and also adjacencies.

And the sense that I got maybe just thinking of that robotic case is like a little wind-up toy on a table.

We want to build it.

and this discussion because of how it is constituted and enacted is helping us understand not just all of the implications that go into that wind-up toy but exploring a lot of the consequences of the wind-up toy

And then there's people saying, but wasn't the table constructed?

And wouldn't a different table have resulted in a different wind-up toy behavior?

And who placed it on the table?

And why are tables designed that way?

And isn't table just like a functional consequence of anything being put on it?

And what are we doing here?

How did we decide on that?

How should we decide the next wind-up toy?

And it just takes it in so many amazing places.

So thanks to everybody in the chat and joining live and of course to the authors for the paper.

See you in 46.2.

Thank you, Jens.

Bye.