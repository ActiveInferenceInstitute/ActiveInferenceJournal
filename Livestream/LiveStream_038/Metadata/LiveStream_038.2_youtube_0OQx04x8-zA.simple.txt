SPEAKER_01:
Hello and welcome everyone to ACT-INF Lab live stream number 38.2.

It's February 23rd, 2022.

Welcome to ACT-INF Lab.

We are a participatory online lab that is communicating, learning, and practicing applied active inference.

You can find us at the links here on this page.

This is a recorded and an archived live stream, so please provide us with feedback so that we can improve our work.

All backgrounds and perspectives are welcome and will follow good video etiquette for live streams.

Go to ActiveInference.org to learn more about how to participate in any of these live streams, which are part of the comms communications organizational unit, or just any other part of the lab.

All right, today in ACT-INF stream number 38.2, we're going to be having our third discussion.

There is the dot zero, the dot one, and now the dot two on this paper, the evolution of brain architectures for predictive coding and active inference.

And, uh,

Maybe each of us have a few ideas in mind, and I'm sure we'll come up with a few other things.

Plus, if anyone's watching live, they can write a comment in the chat.

So we'll start with just introduction, saying anything if we want about the paper before just jumping in somewhere or somewhere else.

I'm Daniel.

I'm a researcher in California, and I will pass it to Dean.


SPEAKER_03:
Hi, I'm Dean.

I'm up here in Calgary, and I'm not doing very much except trying to keep up with all the papers that we're looking at in active inference, and I'll pass it down to Blue.


SPEAKER_00:
I'm Blue.

I'm a research consultant in New Mexico, and I really enjoyed this paper for many reasons.

My background in neuroscience, not particularly

being a priority, but yeah, it is.

So I'm excited to get into it and to discuss some of the points that I picked up with you guys.


SPEAKER_01:
Okay.

Well, blue joining us today, what figure can we start with or start with a blank sheet and just any of the points that you'd like to raise or we can do something else.


SPEAKER_00:
Uh, man,

like figure four for me was like awesome um so maybe that was my favorite figure maybe that's the one we should start with okay all right so what was your just perspective on what figure four was and then what did it mean or why was it interesting for you so i was interested in this figure and maybe like even in how this figure could be expanded in terms of

hierarchical depth and temporal depth.

And temporal depth like has more than one potential scale, which isn't really like mentioned here.

Like temporal depth can be thought of as like

small time steps, like what am I going to do next?

What's my next action?

But also like in bigger time steps, like what is the next iteration of me and how like these hierarchical depths, like, cause that's obviously like a larger level hierarchy, like the next iteration of me as a species or the human species, right?

Like what is the next iteration of the species versus what is the next action I'm going to perform as part of the species?

So that was kind of an interesting, like,

perspectival dance that they took and just really like the, yeah, multidimensionality of this and how to kind of think about it in like a

maybe like a, is this like a multidimensional space, right?

Like, is it like in terms of like my cells, what are my cells going to do next?

My tissues, my organs, me, my active inference lab, like what are all these things going to do next?

And also like on that level, is that like a short timeframe or is it like a large timeframe?

And do the timeframes differ or can like the same hierarchical level have more than one timeframe or not?


SPEAKER_01:
Okay, nice questions.

Dean, what do you think about any of that as we start to look at figure four as a starting point for talking more about what Blue just mentioned?


SPEAKER_03:
Well, I think

One of the things we touched on in the point one was the idea that within a frame, there's also an orthogonal mesh.

So as we push through this representation from the bottom up, are we going from what might be described as an architectural existence to at the top, what we might describe as architectural learning?

Now, of course,

If we take that position, we have to be careful that we're not reinforcing the idea that it's all about constructivism all the time versus being creative.

I think you need to be a little bit of both.

And I'm not being creationist, like not one story that carries forward all the way through time, as Blue kind of reffed there.

But the idea that the updating

matters throughout the time scale that you choose to look at.

And so now the question is, is architecture the lens that we should be using to talk about how we advance from mere existence to a place that we would describe as learning?

I mean, that's what was chosen here, but is that the one way now, right?

It's a way.

It's a good way.

It certainly makes something super, super complex into something that's just complicated.

But is it the only way?

I don't know.


SPEAKER_01:
Just one question of clarification.

When you said this is the only way, what were you referring to?

This figure four or what?


SPEAKER_03:
Through architecture, the idea of an architecture.

the architectural lens, as opposed to other ways that we might build out this idea of going from homeostatic existence to going from unknowing to knowing, and whatever that means.


SPEAKER_01:
Okay.

Thanks for sharing it.

Just to kind of maybe connect this, you mentioned architectural distance, which is within the metered space.

Whatever the metric is or the measure or the grids that you draw, there's a distance within a map.

And that's like the ecological transect, that's the blueprint, that's the forensic analysis, and then that's like parametric learning, because it's a distortion of parameters in a given space, and then fully defined.

not just like space for openness whereas the architectural learning is at the structural level architectural and then that was kind of like what you related to not just the homeostatic or even the allostatic perhaps but something that's like the sort of unknown unknown open-endedness biological open evolutionary trajectories


SPEAKER_03:
Yeah, so not just sustaining it, but actually realizing it.


SPEAKER_01:
So we'll just get a few notes on each of these transformations, then see what other ones or what are some situations that might model, then also return to the questions that were asked.

raised early by blue like with a multi-level self and like where are the where's mental action or thought in this model the examples were provided of like um for example the allostat that took the temperature homeostat and then added in in their example like the sunrise visual detector and modeler column and so that gave the anticipatory change in body temperature when the sun was viewed

then is there a um similar structure for cognition is it just like linking together senses in more and more combinatoric way it's a very sense oriented perspective which from an evolutionary perspective which is what this paper is exploring that's the one to ground further elaborations and changes on

rather than trying to reverse from something like engaging counterfactuals.

So just using an active inference model, sometimes for a counterfactual agent, if the model says that, that's okay, or doing the bacteria without implying that it's doing the counterfactual explicitly, that might be possible too.


SPEAKER_03:
So we have thermal regulation in the paper, but then the question is, does that equate to feelings in a human being, right?

Like, does all that feelings cover necessarily collapse down to the example of thermal regulation?

And at what point are we aware of the fact that there might be a difference between the example and the concept?

Like, where in this figure four is that blurry line that we cross?

It's a good question.

I don't know where it is.


SPEAKER_00:
So Dean, are you talking about feelings like emotions or feelings like sensations or both?


SPEAKER_03:
Yeah, all of that, right?

So feelings tends to take on a big sort of, it's more detached from the example of thermal regulation.

And yet that's just the fact that you can ask that question proves out that maybe the one example doesn't cover all of the different aspects of the higher concept, right?

Yeah.

And that's where the scaling part comes in.

So it's not just temporal depth that allows for that.

You have to have the temporal depth and the hierarchical depth.

What kind of feelings are you talking about?

Implies that there's more than one way that has to exist for you to come at that, to ask that question.

Where do we draw the partition?

Right?

So in here, they show duplication.

But it kind of, I'm not going to say it misleads, but it could potentially mislead if you think that there's a linearity to this.

But in fact,

A couple of times Daniel talked in the point one about the fact that there is a step function moment.

There is a jump.

It's not a jump.

I forget the example of one example where we can't say you just go from one eye to two just because.

I think that was one of the examples you gave, Daniel.

But at some over evolutionary time, there is these little progressions where if you look back on it,

it seems like a rather large jump took place, right?


SPEAKER_01:
Let me give a few.

So when you said like the big jumps, and so in one sense, that's related to the kind of discussion around complex patterns of evolution and some phenotypes or genotype regions that are very stable through long periods of time over many generations, like the ultra conserved elements in the genome.

that have very low mutation rates versus regions that have high mutation rates etc and then same as phenotypes like phenotypes that are very constant like the coelacanth fish or phenotypes that are very plastic or dynamic or ones that we just don't have the records of um

then how to connect what is happening or the models that we want to make in humans especially with computer enabled and language enabled humans technology enabled humans with the continuum of cognitive processes and then you said like it's not linear and then that kind of

made me think like there's like feelings which um was still it's still a rich qualitative area like you brought out like sensations but also experiences and emotions and then how

quickly slash securely or unambiguously can we map just that cloud of concepts just to be like, it's a policy selection on attention.

It's an uncertainty on valence.

It's valence.

Like we're doing the parametric cognitive model with this, but it's still even a little bit open what this represents.

Is this the evolutionary biologists

doing model testing on a phylogenetic tree?

Or is this talking about the genomic or the neurophysiological components that have to be connected just anatomically for a certain function to arise?

And that is the rich area that there's so much to explore in too.


SPEAKER_03:
Well, I think the one thing we can agree on is, because we're talking about evolution, we're talking about history.

So it is backwards looking, and backwards looking is easier than looking into the future, right?

So I think that's one thing we can agree on.

What this is trying to do is explain, perhaps, how the history came about.


SPEAKER_00:
So one thing that the authors mentioned as well, and that's kind of linked to the idea of feelings, this was a discussion about the evolution of brain architecture, but there's also the fact that brains are in bodies.

They don't just exist in jars.

And for me, at least, I feel like

feel like emotions not necessarily sensations but i feel like emotions are driven in a large part by the body like we've we've made a huge kind of connection between like the gut and the brain um and like there's probably more connections to be

because I feel feelings like emotions deeply in my body.

Like I feel them in my heart or I feel them in my stomach or I feel them in my pinky toe.

So I really think that the idea of like emotions can't be separated from embodiment.

But prediction, I think it's a mental activity or at least like I feel it in my brain.

So I don't know if that's the same kind of...

sensation that everyone has, but like prediction is in my mind, a brain thing, but I know that it's also that's overridable.

Like if someone throws a ball at me, like I put my hand up, like that's a reflex.

So, but that's, is that like my brain driving my body?

I'm not sure really, but I know that there's, um, you know, some, some prediction that's maybe not mental, that's more like physical or that's more embodied is probably the right word.


SPEAKER_03:
Okay.

And you kind of move into that intuitive space as well, right?

Like if you think about going to the beach, I can't tell whether you're going to think about the wetness aspect of that, the warmness part of that, the smell of the sunscreen part of that.

But that prediction is going to also generate embodied emotions, even though you may not articulate them, right?

You're still intuiting them.

you're still anticipating them.

And so I'm not sure how the architecture pulls that out, especially to Daniel's point where our form has adapted evolutionarily to the phenotypical situation that we find ourselves in.

And going forward, let's say that sea levels rise and suddenly you have beachfront property where

For millions of years, you did not.

How does that affect now your emotions?

Right?

So I like the architectural idea of being able to take something and look at the historicity of it and be able to try to explain it out with a little bit more confidence.

I'm not sure, though.

I'm still struggling with being able to figure out how, if we want to look ahead, we can necessarily set it up the layered way it was set up here.

And I really like figure four.

But I just have to categorize it and keep it where it's most useful, which is in the backwards-facing part of this.

That's all.


SPEAKER_01:
OK.

Let's return to how to use this.

That sounds like a good question, but we'll get there.

Lou brought up the brain and complement with the body, and this was just the quote from the very final lines of the paper, or near the end, where they acknowledge that

partial perspective that they present in the paper partial meaning just a portion of but also partial like partial to a certain view because they're with a neuroscience regime of attention and that's the contribution that was made that helps apply to other systems and then there's another synthesis to be made and this is kind of like the opening where they just

uh acknowledge that cognition can be extended and embodied and it suggests that not all aspects of control need to be solved by or represented a central generative model so it's this point that we've come to from many different angles from like the ecological and the cognitive and then here from more of a structure learning perspective that like the representation

whether just in the model of a system or in the system's own self-representation, it doesn't have to be the exact same thing as some latent variable in the outside world.

So it's possible to have an effective model of climate action without a perfectly accurate model.

But that has to be understood within, like was brought up, a space of counterfactuals of what could happen from the outside world where we really never can eradicate the total distribution and also the introduction of like unknown unknowns.

And so that's the fundamental openness of the external states and the modeler's view.

And then there's...

still a lot to explore with the counterfactuals of the models that the system that like the agent is can implement but i think that gets a little bit to how to start to use it in a certain area but um yeah any thoughts or what


SPEAKER_03:
I've got a question for you, Dan.

So when you studied ants, for example, and their foraging, and I think it's section eight or I forget what section that they say foraging really, really matters.

I think if we're point two-ing this now, I think that the sort of the go forward piece of this is now when you started looking at ants, did you start from a position, I don't know what your background is, but did you start from a position of sort of pulling apart the historicity

of why that thing is now sort of laid out the way it is.

I know there's a piece of that that's there, but is that the place where most people that begin a study start?

Which is kind of interesting about this paper, because to me,

going from existence to learning implies a certain history.

And so I'm wondering how you sort of come at things when you see them foraging, where history fits in terms of that, you gaining some understanding of what's happening here, as opposed to then what happens.


SPEAKER_01:
Great question.

The topic is historiosity and foraging for 400 from Dean.

Lou, what would you say on the topic first?

How would you bring that together?

What would be some important points?


SPEAKER_00:
So I really liked this idea also, and I have like a completely unrelated point and then an unrelated question.

So it says mechanisms of memory and planning have evolved from mechanisms of navigation in the physical world.

And some super interesting that I thought side point was, if you've ever read the book, Deep Work by Cal Newport,

he talks about memorizing a deck of cards.

And if you haven't read the book, read the book.

But it's interesting because he goes through a very elaborate way to memorize the deck of cards, and it's through building a memory palace.

And so in this memory palace,

you have a place that you know very well, like your own house.

You can imagine walking through your door.

You imagine the porch, the doorstep, how it looks.

You imagine the doorway, all the rooms, all the closets.

Imagine going through your house, taking a tour, and exploring each room in a very systematic way.

So it's very easy to memorize a route you would take through your house.

Say you're looking for a ghost in your closet or something hiding in your house.

How would you look?

So you go through your house and you, so you have this palace, right?

That you have in your mind.

And then he talks about making every card a character, right?

Like, like, so, you know, the queen of hearts is, you know, queen Elizabeth or, or something like who is each character in the card deck.

So each character,

character in the card deck becomes a character that you memorize.

So you've memorized these 52 cards as people that you know.

And then, and so this is an interesting play also on the socio dynamics as well as the spatial

dynamics.

So each character in the deck is the person that you know well.

You memorize that 52 people correspond to these 52 cards and you know the layout of your house.

So then when you can go through the order of the deck, anybody can do it.

You can repeat back the order right away.

So like you go through the cards and you say, okay, you know, you can go through it three or four times and then you know the entire order of the deck of cards.

So this is how to repeat back the order of a deck of cards in like just you memorize the order.

Like, oh, there's the queen of hearts.

She's in my closet and

you know, like all these, or who's standing in the doorway is like the first part.

Right.

And so, you know, the tour through the house and you place these people in this spatial orientation in your house.

And so, and this is like a proven solid way, like the people that do these kinds of memory trips use by constructing this memory house.

And I thought that that was super interesting in relation to this paper, that memory and planning have evolved from mechanisms of navigation.

in the physical world.

And I also wonder if there is like a social role that also contributes to memory and could that social role be this kind of higher level allostat, right?

Like we talked about the homeostat and that's like, there's no other, like you've got one time step, right?

And then in the allostat, there's other ways to kind of modify, but how many, like in a social component,

you know, to succeed and function and to actively have memory and prediction.

Like, does a tissue have memory because there's other cells in the tissue?

Does an ant have memory because it can spatially navigate for food?

And also, it knows its friends.

You know, like, I'm sure, like, ants have ways to distinguish one ant from another ant.

Like, they're very social creatures.

Like, I don't think that they all think they're all the same.

Like, my cats don't, definitely don't.

Like my cats know each other, but like if you showed them like a stray cat, like they'd be really upset at the stray cat, I'm sure.

So, you know, animals know each other.

I'm sure ants know each other also.

And so what component of memory is also social?

And that just, yeah, Cal Newport spoke reminded me of that or brought that to light.

Sorry, sorry if I remember.


SPEAKER_01:
Awesome.

it brings up a lot of the aspects that i could add to now just from a specifically anti perspective so you mentioned the evolutionary aspect it's one of the themes of the paper that perhaps from forging but other processes too as key cognitive demands those early challenges or like

ancestral challenges giving rise to current life were faced in and met in this way so that was the evolutionary aspect you mentioned and then um thinking about the history at multiple nested scales so like there's the history of the ant colony as

a genuine modelable entity where the colony year after year kind of develops in its foraging territory as its colony personality or basically phenotype at the colony level um evolve and then asterisk one

Then at the nestmate level, it's the recent interactions of a nestmate that induce it to forage, locally meaning retrieving a seed.

So like there might be an ant whose current neural or hormonal state is such that a lot of interactions with incoming foragers

don't stimulate more foraging.

But then there might be another ant whose status is such that a certain reduced rate of interactions with other foragers, maybe even no interactions with other foragers in the entry chamber, cause it to go on a foraging trip.

That foraging biology is specific to this ant shown here, the harvester ant, but maybe other ants too.

Okay, that's asterisk two.

Then there's the ant tissue.

And like each of the ant tissues, the brain, the different glands, the gut, they're all undergoing kind of stereotyped transitions that are called temporal polyethism, or they're going through like recent changes, like a leg was lost and then the rest of the body like adapts.

So that's like the history of each nestmate tissue.

The asterisks kind of combine for me personally, but also just more conceptually with thinking about the relational view on modeling the ants, like not taking too strong a view on where phenomena should be located in terms of nestmate versus collective cognitive behavior.

And then also the place-based and the field and the long-term experiments.

So my advisor, Professor Deborah Gordon has done like a 30 year plus field study in Arizona.

And so I was doing five years of field work there

But it was like year, I don't know, 20 something or 30 something to some other number five years later in this space where there was a lot known about this ant with a long lived colony, but with turnover of the foragers.

And so the sort of.

ecological and the place-based nature, and then also the specific biology of this ant, where the forager was just so clearly an expendable part of the process of the colony, like sloughed off, and some other features of the foraging biology of these ants.

pretty interesting system and it reveals a lot on like different cognitive demands and different foraging environments so that's not even getting into the whole mental foraging or affective component but just at the ant foraging level i think you brought up an important point though daniel and i'm not sure if people associate architecture with abduction but


SPEAKER_03:
your advisor, supervisor, whatever her title was, her 30-year window, and then where you stepped in for your five-year window as nested, right?

You were the one now nested within a larger timeframe.

So back to Blue's earlier point, but you weren't historically looking back

from the perspective, oh, okay, here's the evolutionary nature, you are now seeing yourself as relative to something that had a greater timestamp, right?

So you walked into the party, and you had to ask yourself, did these ants come from this colony?

So back to Peirce's

big question of, right?

So it's when I come into the situation that matters as much as if I can induce a skyscraper or deduce how much structural rigidity that requires, right?

So I think this is kind of interesting now because

I'm not sure if we should assume, like when you were talking about the phylogenetic trees, sometimes we just assume where we're stepping in on the branching, but I'm not sure we should make that assumption.

I think we have to be careful to be, as you said, very explicit, not just assumptive of where we come in in this history.

Because if we don't, we can end up thinking that this is sort of a linear layering


SPEAKER_01:
that figure four when when maybe it's more like identity it's it's both stable and dynamic so it's definitely related to almost the very first comments of blue of like where's multi-scale identity and multi-scale systems in this hierarchical depth

It may be related in some way to multi-scale systems.

We could draw that out.

But where is that nesting that we're describing, the real physical enclosure sense, and this way that mental systems can almost be modeled as nested?

Just like we saw mental action as a nesting of a cognitive model with an action model inside of it.

It's like the mental is enclosing and even modeling through inclusion of the peripersonal space.

But then with like a drop off going further out, then what is that modeling space and

Is there another operation here?

Again, what are these graphs?

What are we seeing here?

Dean?


SPEAKER_03:
Well, my question is, to answer Blue's question, do we get closer to a satisfactory answer by looking at the mechanics of this, or do we get a better sense of it by seeing the relationship?

Like when you were explaining the ant part, you spent a lot of time talking about relationship.

And I think maybe...

one of the things we try to do is we try to apply the operation to it when in fact what we should be doing is seeing the relationship in its entirety.

I don't want to say zoom out because you can still zoom out and still get bogged down in the sequencing because that's kind of what this does.

It says this layer of sequencing can now build out, fractal out into these other layers of sequencing.

And I'm suggesting rather than seeing the layers,

Maybe it's the totality of the relationships.

I don't know.

Because Blue also pointed to the social piece, which is all relationship all the time, right?

So I'm just wondering if we help ourselves, if we collapse to, oh, well, this is now explainable because we have some way of showing the sequence, right?

Sometimes that helps, but maybe in this case, from an evolutionary standpoint, it doesn't matter whether we're talking about 100,000 years ago and today as much as the relationship of what 100,000 years ago and today represents.

I don't know.

Just throwing it out there.


SPEAKER_01:
Thanks for sharing it.

Just one thought on that, and then we'll continue here.

phylogenetic trees with genomic data are usually based upon sequence alignment followed by the fitting of a tree on the aligned sections of the sequences.

And so there's a lot of ways and approaches of modeling from the sequence alignment itself, from unaligned to aligned sequences, a lot of ways you could do it.

And then from the aligned sequence matrix to the tree model, there's a lot of ways to do that.

It could be a bifurcating tree.

It could be like a different kind of tree, different algorithms, Bayesian, et cetera.

One interesting point that...

many have raised, but it's very challenging to deal with is that depending on how stringently you align the sequences,

different sites with different histories or different information content, partially or in totality, are being filtered out in a different way.

So if you have a mode of evolution where short chunks get interchanged so that locally the sequences are not changed, like domains of a protein aren't changed, but then they're swapped in order,

those might become non-alignable sequences.

And so the hope is that those kinds of genomic changes are silent with respect to the long-term evolutionary history of a species.

But in the short term, other methods might be needed.

But in the long term, it's the hope that by pulling back to like the alignable sections, you can get a good signal.

And so that's a pretty satisfactory approach when multiple converging threads do exist.

overwhelmingly agree but it really shows that when there's like a signal processing filtering and then a model fitting this the information in the data can be extremely powerfully misleading

because you're getting exactly the same post-normalized data, whether it was total noise in, total bias out, or whether your correction process over-normalized for one thing or another, those are kind of in that gray zone, unknown, unknown space, coming into the searchlight.

And so there's the whole looking out of the searchlight story.

So maybe...

Where do we situate active inference with respect to that?

Looking where the light is, searching for one's keys, et cetera, et cetera.


SPEAKER_03:
So can I just say real quick, I'm not advocating for don't show your work.

I believe that showing your work really matters.

And then when you're trying to explain what's happening at a certain point, don't get stuck in, well, this was the order of the steps that I took when I showed my work.

Try and zoom out and try and understand what the relationship was well.

That's all I'm, what I'm asking is that, does that help being able to toggle back and forth?


SPEAKER_00:
So can I just jump in here for a second and point out that we have phylogenetic trees or we had, yeah, I guess,

They weren't called phylogenetic trees at the time, but we've had speciation trees long before we had genetics, right?

And so we can construct them based on morphometric analysis.

And something that I liked in this paper is that it really drew out the importance of the niche environment with respect to duplication, because we saw many instances of

species because we did these trees when we didn't have genetic information.

And so we had all of these morphometric characteristics that we thought were similar.

And so we lumped these species together because they must be related because they share this morphometric feature.

But in many circumstances, that was not the case.

And so because of the similarity of the niche environment or even existing in the same niche,

You know, we had evolution converge on this feature that was successful in that environment.

And so I think here, like the idea of duplication and the authors got into that, which I thought was really cool.

So, so the same mechanism can evolve more than one time in parallel, just because of the fitting to the niche.


SPEAKER_01:
Totally agree, Blue.

So when I said multiple conversion lines of evidence, like what I was totally thinking of was how genomics, the patterns that we get from those aligned sequences, do recapitulate and even discover unexpected but later verified relationships.

And so that's sort of like a measure of the unique explanations and predictions.

But this tree

could have been fit with phenotypic characters, as you mentioned, as it was for a long time.

And then it was just a few sites in proteins.

And that was sort of like the 1960s and 70s was fitting with very reduced data sets.

And now the amount of genomic data is rapidly increasing.

But out of the genomics analysis, the action state of phylogenetics is really just this tree.

Topology fit from a family of trees

hopefully with an uncertainty associated whether they show it like with a bootstrap uncertainty or some other way but then that is an artifact now there's a few cases where like this is in and itself interesting like when people have resolved some deep relationships within insects or other groups and then it helps structure thinking that can later be brought out about different traits and ecologies but it's like

this is just a starting point for thinking about evolutionary histories.

And like you said, similar ecological or generative processes dynamics might beget increased likelihood for a certain generative model to arise.

And that's like kind of what ecosystem is, like a desert seed harvesting ant, whether it's in the Mediterranean or the Southwest U.S.,

like Pogonomyrmex in the US and then Cataglyphus in the Mediterranean regions, there's some similarities there.

But then there's other species that are more closely related that have a different foraging ecology.

So then how does the foraging strategy sometimes have extreme fidelity with the group?

Like leafcutter ants, where once they're committed to being a full leafcutter ant,

so to speak, evolutionarily, they don't, or they haven't been observed to revert back to some other mode versus other like foraging strategies at the group level, at the colony level, but it's the individual in the other sense.

That's like very interesting.

Like thinking about foraging phenotypes on this tree and why not?

just like any other trait that you could study, like the evolution of first spatial foraging, and then the evolution of cognitive foraging, and then applying that to different search spaces, which was also explored a little in the citations here, the foraging in mind and foraging in semantic fields papers.

What would you say, Blue?


SPEAKER_00:
Well, so it's cool that you brought that up, Daniel.

And just because in our past conversations, you've brought up that the same species of ant can have different foraging patterns based upon the colony that they live in.

I think that that's super interesting.

And I wonder how could you map

foraging patterns like can you put foraging patterns into a phylogenetic tree right like is there a tree structure that we could use to describe foraging patterns and would that relate to or map on to this brain structure tree in some way like is there I mean even I mean there's a lot of diversity within the same brain structure also like the ants have the same brain structure but you know even humans have like some of us go to the grocery store some some humans out there are still like

hunting and gathering, you know, to make their food, so.


SPEAKER_01:
Awesome.

Oh yeah, Dean, go for it first.


SPEAKER_03:
So you guys can learn me, school me on something here.

So is there any evidence that ants all gather in the morning and the queen ant or whatever, the organizing ant, the principal ant pulls the map out and says, now I want you to take this thing that you've mapped and carry it out today.

And I'm not being a smart aleck.

I'm asking, is there some sort of analogous evidence that they do that?


SPEAKER_01:
okay so to the um uh team huddle uh monday morning stand up no i hope that's not over generalizing because ants are also of course very diverse in their foraging strategies and a lot is unknown but just speaking to the first approximation the queen is not a central decision maker in information router hormonally and at a slower time scale for sure but at the behavioral regulation level

Now, in the morning for the Pogonomyrmex, they would like chill and some would slowly come out and like their walking speed is temperature dependent, like all insects and it just assessing maybe the humidity or...

damage around the nest entrance so there's no reason why those archetypes like convergence before planning or rupture repair which of course cannot have a planning component directly different algorithms are going to have different levels there but because the ant

symbolic behavioral communication is pretty low bandwidth, probably.

So unlike the waggle dance, which is conveying like quite a lot from an information theory perspective, using symbolic means like the direction and the distance and also chemical information like about the flowers, there's ants that like physically pull another of their nest mate to a foraging location.

So using memory or pheromone or like tandem run.

And there's probably some limited examples of being able to do some like a little bit higher order signaling.

And also, of course, the smell of the food and the pheromone.

And so a lot of the extended features.

But they don't do a powwow with the queen.


SPEAKER_03:
Okay, so let me take what you just said and sort of feed it back and maybe build on it a bit.

So you described a situation, it's morning.

If morning, then ant behaves differently.

like so and in the last slide of this deck and the phylogenetic tree you had then to now or then if so what i'm wondering is

Can we exist in a sequential world of if-then?

As a homeostatic representation, is if-then all we need?

But if we want to include temporal depth and hierarchical depth, we actually incorporate the inversion of that.

We incorporate the then-if, right?

So that's my question.

So to Blue's point earlier, where is

Where is this shift or this sense of what's going on?

The relationship might be the discrepancy, the first representation, figure one, the discrepancy might be those people that are looking at things from an if-then perspective.

If this, then we should expect that from a predictive standpoint versus the then if perspective.

Then the critical call had to be made as the base runner was foraging for second base.

And a call was made now if.

Now a whole bunch of people chime in about what their interpretation of what just happened is.

Right?

So again, I'm not sure if only looking at it frontwards and backwards as a sequence is enough.

I think we also have to be able to see the relationship of if-then and then-if from the historical view.

And I think when we do that, we go from architectural existence to architectural learning.


SPEAKER_01:
okay let me try to restate that but i've not lost the forging trail so yeah if the um outcome is like um the end point then that's the uh if then uh that's the if that if the person committed the crime you do the time and then um

the sort of then-if takes, it precludes if-then in multiple sequences of if-then and uncertainties on if-thens.

And then it says, okay, then, or it's like if-then-if.

So we're kind of downplaying if.

And then that's where the outcome is a starting point.

And so that is, in one sense, it's teleological because it's end-directed.

Like, where is this project going to go?

Do we really expect and prefer to publish this paper on February 28th?

And then also it includes the next steps.

So it creates a world model where there is a possible, which is say selectable set of policies that the team will achieve like that expected and preferred outcome.

And then it sets it up for what would be the obvious next loop of policy selection.

And so if it's like, if things are this good or bad with the environment in 2030, then this is how much damage will go to this or this way.

even if you were right, it wouldn't involve the policy selection element.

And so that's probably a complex situation with the partitioning of estimation and world policy selection, which is clearly a separate discussion that's not only being invoked here as an example, but it just points to how those are different components of inference.

And then foraging, an example of if-then and then the as-if or then-if was like,

Sometimes the colonies would pack their nest entrance with pebbles and then there'd be a thunderstorm in the afternoon.

I don't think a study has ever... I mean, it's a totally widely observed behavior with many animals and there's no exception with harvester ants.

Now, maybe there's thunderstorms where they fail to make pebbles or it's not enough.

And there's probably some false positives too.

So we don't really know the exact success ratio.

Maybe it's better than the previous day's forecast.

Maybe it's worse, but...

it's very clear to see that the nestmate doesn't need to have been inheriting from its evolutionary history and its niche

rain cloud modeling software it's just picking up pebbles with a proclivity to interactions and humidity etc that help colonies that have that proclivity succeed in that niche which doesn't even mean that it was a popular phenotype like 20 years ago as things change in a region so that's like super interesting um

Let's return to foraging and the foraging variation question.

But first let's see if we've completed the figure four discussion.

And just like, is there anything else we want to add about like the main, because this is kind of what the paper works towards.

And then there's like a little downhill roll is like, we could do this algebra on the tree, but this is sort of where things get led up to.

through demonstration of the motifs and the connection between cognition and structures and structure learning and then like parameter learning at a behavioral or developmental time scale and then structure changes over evolutionary time scales so we have hierarchical depth temporal depth which we're also just kind of adding in a spatial component allostat which was used in the paper with the intermodality but

Maybe it could be other modalities or same.

There's duplication, which is kind of like parallelization.

That's like adding another nestmate or another unit to the compound I of an insect developmentally.

And then I is homeostasis, which is being used here as sort of the base or root or ancestral case, which is referring at the behavioral timescale to return to a stable point.

And then also at the more evolutionary timescale, the I operator on the homeostat, it's like the homeostasis on homeostasis.

It's keeping the structure of that model fixed.

And then when the homeostasis at the evolutionary timescale is open, then the structural transformations here are like the affordances from that base case, which is what's being shown like with the main one on the left being broken into these.

And then each of these become the prior for each of these next ones.

Anything to add or we go to foraging?


SPEAKER_03:
Okay.

Yeah.


SPEAKER_01:
so great relevant question blue measuring foraging so one paper though there's a bunch that are really relevant but um michelle lenon 2014 did a lot of literature review and visualizations of foraging strategies in different ant species so um these are like some of the foraging approaches like foraging archetypes um and then

uh categorized those into different traits on a tree and um so that's an awesome work and something that could and should be extended and integrated with like modern databases so that somebody could submit we just saw this one going in a trail and then that kind of reduces our uncertainty about a broader model of

ant foraging because it's like oh that's a surprising observation about this given what we already knew about that species for example but how do you actually measure foraging variation within or across a species so in this case these um in figure one these are like kind of like the structure

at one level.

They're like archetypes of structure.

Now, sometimes they probably blur within each other.

Like if it's two and it's tandem running, but if it's three, is it a group or is it still like pseudo tandem running?

So it could be a little blurriness and also there could be different modes.

even within the same species or like a continuum between a foraging column with like a trunk and a spread versus like just a spread.

So this is sort of like, yeah.


SPEAKER_00:
I've got to like just jump in and say like how these look like neurons, like just with like differing axons and like dendritic arbors.

Like I'm like, these are like different brain structures.

So I just had to like point that out.


SPEAKER_01:
Yeah.

The bottom one definitely does.


SPEAKER_00:
Even both of these and even this top one too, the trunk trails.


SPEAKER_01:
Yeah.

And let's just say that these are sort of archetypes within a broader space.

And then within a given mode...

then the behavioral ecologist will tend to make like a more specific measure so let's just say it's a 100 a trail forager then having the counts to and from on the trail is a good measure so like in the harvester ants they most basically do this trunk trail on the top

So there would be like one or two or three main avenues that they were leaving the colony in for that day.

And then sometimes it'd be the same day to day.

Other times it would be slightly different.

But then what happens when one wanders off, not on a trail?

Is it still a forager?

And a lot of that space is really interesting.

But suffice to say that once a foraging definition has been selected, like not just the class that it's going to be, but also how it's going to be measured in that study, then there can be like quantitative parameter comparisons like this colony foraged at this rate.

in terms of number of outgoing foragers per minute.

And then its neighboring colony of the same species was doing at this rate.

So you can do like parameter comparisons within the species kind of at the population level.

And then there might be another ant species whose activity it doesn't really make to compare.

because it's like a different number of nest mates, it has a different foraging ecology.

So that's kind of where like the structure learning would come into play with comparing the ants that are tending the scale insects versus foraging for seeds versus doing whatever else they do.

And then within a species, or perhaps across a few species that have a similar foraging ecology, it's possible to do parametric comparisons.


SPEAKER_03:
So I have a question for you, Daniel.

How does forging fit architecture?


SPEAKER_01:
What do you think?


SPEAKER_03:
No, I mean, I'm not trying to be a smart aleck here.

I'm really curious because most architectural analogies result in some sort of an outcome that's static.

Like there's a lot of processing that went into the outcome.

but the outcome is static.

And I don't think that any of the representations in the frame that you're moving right now, although the differences appear as static, they're supposed to be representing something that's quite dynamic.

So that's where the question of the architecture piece, blended with evolution, might be helpful or it might be oxymoronic, depending upon

how you interpret it, right?


SPEAKER_00:
So having architecture implies there's an architect.

I don't know.

In an evolutionary sense, I'm not sure architecture is the right word.

It's weird.


SPEAKER_03:
Yeah.

And I'm not saying it's wrong.

I'm just saying you have to be really, really careful.

And then what assumptions you come in with based on what you think architecture is.

Yeah, maybe you're thinking it the way I am.

I'm not saying it's wrong.

I'm just saying, what baggage does that carry when we're talking about something that's actually quite dynamic?

Those ants, I mean, you can see the ants and the anthill as an architecture, yes?

You can take a snapshot of it.

But is that what we're really talking about when we're talking about foraging?


SPEAKER_00:
So what's the difference between a structure and an architecture?

I wonder that.


SPEAKER_03:
Yeah.


SPEAKER_00:
Is it just words?

It's just semantics?


SPEAKER_03:
Yeah, I think it's more than that.

But we just have to be careful that we don't insert one for the other, thinking that they're the same thing.

That's what the whole ontology exercise is about.

I mean, I got my mind changed, OK?

Normally, I'm the one that argues, don't give somebody an owner's manual.

Get them behind the wheel.

right?

They'll see their owner's manual later.

But in this particular case, I'm kind of going, wait a second, we better all agree what we're talking about.


SPEAKER_00:
So here it is.

What's the difference between structure and architecture?

Structure tends to be the pieces and the parts of the design and how it goes together and the finished object.

Architecture defines how the final object looks, behaves, and costs by designating how design choices


SPEAKER_01:
are made so architecture implies that there's some kind of agency behind the design and that's kind of that was kind of my interpretation of it also okay okay bunch of stuff there that last point would like the definition of architecture involves the choices rather than structure involving just the uh description of parts so that's kind of like the perception variational free energy that's like structure


SPEAKER_00:
It also means the entire thing.

So it's not just the parts.

It also means the entire object.


SPEAKER_01:
Yes.

But it still doesn't involve preferences or choices.

It's about description like perceptual processing is.

And then the architectural definition has like choices in it.

And then that is what you brought to agency.

And also architecture, it's like a profession and an operational approach to modeling the process of building a building, though there's probably theoretical and basic architecture and all this other stuff.

Okay, just a few thoughts here on the...

engineering and designing.

So I guess one ontology that can be helpful here is with Bucky Fuller talking about structural integrity, which is something that has static holding strength, like a metal cube.

has static holding strength um then there's process or the pattern integrity which is sort of like describing the life cycle of the butterfly and the caterpillar like a recapitulation of process and that is a lot more like this sort of dynamic systems approach to

rather than the build it and block it approach because these multi-scale systems always have things that are turning over at different timescales.

And then there's just so many mechanisms that that can be modeled by or actually occurs by.

Like just in the harvester ants, it's the historiosity of that colony over the years, then the nestmate and that day and its visual memory and just...

how many factors come into play, then every foraging trip at the estimate level could be seen as unique and the exact combinations will just never be recapitulated.

Some of the major ones can be explored and then controlled for or tested for in a lab, but that's part of the open-endedness of dynamical systems because by changing the setting, you can study certain features,

But then it's another step that's impossible in practice to understand how those features that were in a different environment translate to the first environment.

So you can take the essential behavior of the traffic jam and then recapitulate it with the simulation and the lab experiment and all this, but it's a different thing to actually put it into the design time, which is happening at a different timescale than just building the skyscraper and leaving it there.

But that's more like the dynamic organism.

So where's foraging on this?


SPEAKER_03:
And I would ask, is there a different kind of foraging if we're talking about sort of the machine learning type of foraging on this versus the wet foraging of an ant?

Like can we actually see those two things being quite different in terms of how those two foraging types plays out?

Or do we focus on the things that are different about those two things?

Or do we focus on the things that are the same about those two types of foraging?


SPEAKER_01:
Blue, also with your foraging from a more cultural and human perspective, what would you say about machine learning and foraging?


SPEAKER_00:
So machine learning and foraging, I mean, so yeah, so I've done some modeling of foraging with like agent-based modeling, but in machine learning, I wonder like,

I mean, I know that there's information forging, but that's usually explored from the human context, right?

Like humans going out and looking for information and how long we stay on a website and whatever.

So, but, um, I wonder about machine learning and like, you know, neural networks doing object classification.

Like, is there a forging that they do there?

Like, you know, they pick up things like, um,

Uh, Chris Ola wrote a really awesome publication about, um, you know, how we understand how neural networks work and they kind of deconstructed deep dream.

Uh, that's on, on distill pub, which is really cool.

It was like a 2018 paper, but you know, they look at how, how does a neural network recognize a dog?

you know, and a dog and a tennis ball.

So they look for like round object and like, you know, floppy ear.

Like, so there's like different neurons in the neural network that'll like learn what is a floppy ear or learn what is like a round object.

And so like, it's this combination of different things that the neural network learns that's pieced together to form like this is a dog with a tennis ball, which is a super interesting way to think about it.

And I wonder like in training neural network,

can that be looked at as a type of information forging, right?

Like the network is setting out to learn distinct pieces of a pattern that it'll later like piece together to make its complete image recognition.

So, interesting.


SPEAKER_01:
I'll give a thought on the machine learning and the bio forging.

so you mentioned like what's well there's the question of should we approach it from a similarities or a different perspective and there's different reasons why you might approach different angles right like what is the most pedagogical to someone learning about the difference versus what is the best way to approach this to a certain stakeholder who is actually applying this question in a certain context but to get to the question outside of that um

The idea of contrast came to mind because we recently had the model stream on contrastive active inference, which used machine learning.

So check out that stream, but it involved a contrasting step of processing inputs before doing policy selection, et cetera.

So that helped.

scenes that are broadly similar, but have a key difference that's small, like where the ping pong ball is, can be learned better because there's a contrasting.

And that reminds me of language learning when it's like, here's and here's.

And then that's a contrast that isn't going to come up in the language, but then it helps learn on that.

And that's not just a machine learning thing, because even in the parametric modeling of SPM, statistical parametric modeling,

mapping, but the model making of it.

the contrast matrix is the experimental design.

And so if it's just condition A and condition B and you have 10 measurements, it's just five of A, you know, five zeros and five ones.

And that's like the true or false matrix that basically gets multiplied to do statistics on.

So whether it's a very classical parametric sparse modeling approach, which was initially all that was had by statisticians or whether it is now things that are

highly parametric, or just all this other stuff with modern machine learning, the contrast is like this key piece, because it's always about what signal is being detected within a dataset, and then also how the difference between that sample and the population is being modeled.

And so like in parametric statistics, that's about the sample standard deviation.

And then there's a slightly different equation for like the population standard deviation if you would have kept on sampling.

And then it's also sometimes hard to incorporate that kind of a reasoning into these more modern statistical systems where it's like very easy to overfit because there's a lot of data, but it's hard to model how that large chunk of data is related to even other segments of data.

So it's similar to the phylogenetic challenge, but that is one that is like searching for contrast takes on a very different meaning.

But how is it related to foraging?

There's the info foraging like Blue mentioned.

There's the path element of foraging, which might be related to like inferring the best info foraging path for somebody on their feed, because it has to balance the epistemic and the pragmatic, or at least it acts as if it balances the epistemic and the pragmatic.

So foraging could be maybe looked at in that way.

Yeah, Dean.


SPEAKER_03:
I think what this slide represents is,

broadly speaking, not just or broadly identity.

I think what we do is in that diagram, we tend to differentiate.

We see the levels because we've created the partitions.

We see the dependencies because over on the far left, we have actual blue arrows that show what those dependencies are.

And then we reintegrate.

I remember when I was doing, I always come back to the programming that I was doing, but I used to say to the kids, I mean, there's a migration piece to this that we have to develop, which I would consider to be the tactics, which would include foraging.

And then there's a tools use or a strategy piece, which is sort of the information covered as change, as measured, which is kind of the instrument piece.

And what I kept saying to them was,

you kind of need to have both all the time.

You don't need to know the difference between something that's a migration or an inaction or a fulfillment in sort of the physical space and the tools, sort of the thinking instrumental parts where you can turn what you're seeing into these models and these representations.

And you have to kind of be able to marry the two of them all the time.

You have to be able to integrate them

across these boundaries when you're trying to get into these professional settings.

Now, that isn't a construction exercise.

That's being creative because you really don't know at the end of the day how it's going to turn out.

But the big point that we were trying to make was don't leave one of those two things behind.

Don't get stuck because you can't go out and forage.

Don't get stuck because you don't think you can draw the perfect representation

of the world.

It's just an instrument, right?

It's, I mean, even a spoon can eventually drain an ocean if you're prepared to spend enough time on it.

So I think that's what this representation, I think that's one of the greatest gifts of this representation is it kind of lays out very clearly that there's two parts to this, how we differentiate on different, eventually on different duplication, parallelization,

dependency, predictability, preferential, time-based and spatial-based, and then scale-based, and then reintegrate it all back together into some sort of a coherency.

For some people, though, I think it's kind of dense.

I mean, if you walked in today and

Gee, I don't know what kind of prerequisites you would need, what kind of priors you would need to understand what the heck we're talking about.

But as I said, for me, the entry point, the lowest level was, do you migrate?

Do you tool use?

Most people already admit they can find examples of when they do both.

So my question then would be, so will you know that you're doing both?

Going forward and then and if you can do that, maybe it's not quite so quite so dance or quite so mystifying A few things there so great point that going foraging


SPEAKER_01:
on your merry way without having all hidden states learned at the structural level or the parametric level, even conditioned on a structure.

So you don't even know what's out there.

No cognitive agent does.

And at the structural and the parametric level, the inference challenge is about action selection under uncertainty of multiple types.

The inference challenge is of action

having sub-problems involving inference on perception and causal modeling.

But those are like little sub-problems within a broader frame that active inference provides of like action orientation, action on policy selection, and then foraging is a great setting to study policy selection.

And then you brought up like that there's prerequisites that we hope to learn what different backgrounds can come to active inference from.

But like, I think one takeaway from the paper would be that perhaps

our cognitive foraging structure, whatever that means.

But the way that we forage through linguistic and idea space and solution space, strategy space can be modeled by some graph motifs and classes and transformations, which is what the contribution of this paper is.

And they also describe some of the more basal or homeostatic ancestral structures.

So it's like you have a linear model that works for height data and it works for weight data and it works for height and weight together.

It's just any numbers you pass to the linear model, the GLM, it's going to be,

Basically, okay, this is like another model class that can take or apply to cognitive modeling, homeostatic modeling, cognitive and homeostatic modeling, all these variations that are being described here.

So that's just one way to put it with perhaps fewer prerequisites.

And then these were interesting questions.

Is this what it was?

Do you migrate and do you use tools?


SPEAKER_03:
Yeah.

So if you're doing, and when you're talking about tools, are you talking about provisions?

And especially if you come to breakfast with a plan on how to build a spoon,

How is that going to help you eat your cereal when your foraging exercise was to be able to move the cereal from the bowl into your mouth?

So lots of times, especially in some of the more conventional ways we look at things, we tend to take the plan to the cereal bowl instead of the actual spoon.

So the provisioning part is more than a plan.

It's more than the words, and it's more than the representations.

It's the actual implements that we carry with us when we do that migration that I think really counts.

Because if you carry a, I guess you can origami a sheet of paper into a spoon, but then that's another process that you have to go through.

And really what you wanted was just to have the implement, so.


SPEAKER_00:
So when you talk about migration, like how far is the migration?

Like if you're a single celled organism, like, you know, migrating through the ocean, like what?


SPEAKER_03:
Maybe the migration in that case is moving around you, right?

Like you don't have to be, you don't have to think migration in terms of me from A to B if I'm stationary and A to B are passing by me.

Like when the car beside me is pulling out of the parking lot, I feel like I'm moving forward.

Right?

That's also a migration.


SPEAKER_01:
So that is related to...

we talked about with some of the geometry like the projective geometry and how there's the flipping between the egocentric geometric projection where it's like your peripersonal space and it's kind of like a distribution around you like there's me in the center or located somewhere and then there's like things closer to the eyes are generated to be

bigger because they don't have to be because we know we're making the generative model anyway so why does it happen why can't i see it from grand theft auto perspective it is a certain way for a certain reason so then that is flipping that's flipping with the um

more like objective or depersonalized stance like the prior on the architecture structurally of my room with the right angle and even if it looks different than a 90 degree angle in the generative model that's perceived as normal or unsurprising because it's compatible with the underlying structural hypothesis that's unobserved and then the observed structural observation that has to do with the actual way that the angles look

So here's just one other kind of Professor Gordon shout out slash angle to look into.

Evolution of algorithms for collective behavior.

So let's connect this to the cognitive foraging and then Dean's questions.

Do you migrate?

Do you use tools and do you provision?

So that's like related questions to that one might be like, how do you adapt when things change and you can't,

adjust certain things or um also the difference between like let's just say i'm using a software i'm not very familiar with like photoshop between doing one move photoshop searching on a search engine how do i paste okay paste okay i do one move so it's like a one step model of function versus someone who just rolls out of bed

opens up Photoshop, and then they just open their mind to being creative and being in feedback with what they actually do.

And maybe that does involve still using a search engine, but they're in a functional flow with respect to that tool.

And they've just set aside the time so that their regime of attention can be like productive or aligned with a project.

But they're not going step by step.

They're engaged in broader organization.


SPEAKER_03:
So we're talking about figuring out part rather than the finding out.

That's what you just described.

The difference between those two things.


SPEAKER_01:
Yeah.

Opening space for figuring out.


SPEAKER_03:
For figuring out.


SPEAKER_01:
And that's sort of like, it's a little bit like local and more meso or global foraging, which is like you can dig in a given patch of dirt.

So it's super labor intensive and,

but it's a local finding of what is there versus trying to find a better patch of dirt and dig there for a seed, maybe even find an exposed seed.

But whether one of those policies is like, has a higher risk reward or energy expenditure, that's gonna depend a lot on what one believes about the frequency of like,

half emerged seeds and seeds in this location and the time cost of moving from location to location.

There's just a ton of features.

And it's not just like as simple as making a heat map of where the seeds are.


SPEAKER_03:
We would describe it as mimic foraging and mimic foraging.

And what was the other one?

Modify foraging.


SPEAKER_01:
Something like, oh, blue, go for it.


SPEAKER_00:
So it's interesting at the conference I was at last week that, you know, they talked about like how far can you get mimicking an expert?

And there were several like talks like so, you know, whether it's navigating a maze or, you know, figuring out whatever.

So like, you know, they'll train a model on a whole bunch of expert.

What would an expert do?

And then they set them loose in like a novel circumstance.

And if the novel circumstance is similar enough, it kind of works.

But really like the better thing to do is to put some exploratory component in there.

So, you know, you have like the expert training, but if there's an explorer component about that doesn't have to do with an expert or like, you know, if we train it to navigate its own maze, also sometimes like alternating with its own maze or, you know, a maze with experts in it,

So like following the experts only gets you so far.

And I wonder, and something that's come to really mean a lot to me in the field of intelligence is like when, it's when there's innovation, like when you can do something new, when you can generalize and solve any maze because you learned from a few experts, like that's innovative or, you know, like the ability to generalize, but also the ability to innovate and produce some new output rather than just do what the experts do.


SPEAKER_01:
so one thought that's awesome comments blue like learning from examples and from experts usually learning by example when used not in a malicious way is referring to seeing somebody who's better or at least adequate if not far far better and then there's this question of like should it be shown only at the expert level

because the expert speaker would do tongue twisters and Russian sentences with five conjugations.

But the expert in interaction is able to approach a zone of agreement and of like proximal development so that the example and the expertise as applied

is in a very specific space.

And that's like the order of examples and then knowledge, like this person is able to conjugate this thing, but they're having a challenge in conjugating this case.

So then depending on their personality, maybe you lean more on the one that they are more familiar with, or maybe they...

come to you to be wrong.

So there's a lot of advanced cognitive modeling and parameters that could be in a full-fledged model because that's a super complex scenario, especially in a group and all of these relationships on relationships.

And we don't need to have that whole

generative process model to have a generative model of policy that can be effective at forging in that space.

So it is a project and making that map is helpful for it.

But to make policy decisions in the cognitive space isn't the same as describing and mastering all the variables of the cognitive process.

And so this mental forging and physical forging, and also what we talked about with a sensory motor detachment helps make that really clear.

So like, how does Active Inference model relevant expertise?

Whether domain expertise or discipline?

like a set of affordances A versus a whole different set of affordances B or expertise like in that language learning example or some other example where it's not simply about like providing some advanced example and then having people asymptote to that.

It's about opening the space for figuring out in that setting.


SPEAKER_03:
I think you can find a structural adaptation in mimicking an expert.

And that typically sort of plays itself out as instructionalism.

I think you can find yourself also modifying your niche and adapting in that way.

and then being able to go back and have an expert look at what you've done.

And the reason why they're an expert in that particular case isn't because you're going to mimic them, but because you're going to ask them what they, how the process that they use to arrive at where they have a certain subject confidence, they are able to now diagnose

where your confidences might exist and where you might want to re-examine what the probabilities and preferences were that got you to the conclusions that you drew.

So again, you're going to adapt either way.

But I think that the path that you choose matters.

And knowing which path that you chose also matters.

So I adapted, right?

I adapted because I'm now trained up to be able to find the blue dot, the blue ball in the sea of plastic balls, right?

That's one form of adapting because I've never been in a ball pit before.

And now I found the one that I was looking for.

But another person could go in there and be able to maybe do something else with that blue ball because they modified the frame and the mesh.

And that, again, we just want to make sure that we know that there's a difference so that when we are reintegrating them at some point in the future, we know how we got there.

That's all.


SPEAKER_01:
Okay.

I like the throwback to instructionalism and interactionism.

It's an example that was like latently there when talking about that niche dependence and the co-creation.

So all these kinds of terms, digital stigmergy when working online, for example, become implicit when we're using a given

sequence to be talking about like a certain thing that we want to call our attention to.

We call our attention to some example or to some relationship and then that modifies our cognitive model so that we're thinking about things and doing things differently after.

And so it's kind of like quality of engagement rather than quantity because some people by reading a little change a lot and vice versa.


SPEAKER_03:
Ty set up the relationship, I think.


SPEAKER_00:
It's funny that you bring up reading.

So for a very long time, my PhD advisor never read anything.

She would never read anything.

Did you read it?

Oh, yeah, I read it.

She does, like, speed reads.

She speed reads, right?

Which means, like, she looked at every third word, right?

And then, like, when she really sits down to read it, she's got all these things to say about it and wants to, like, you know, wordsmith every sentence.

And it's great.

Like, we've had a lot of fun working together.

I don't mean to, like, make that sound evil in any way.

But, I mean, I don't speed read.

I read fast, but I'm totally incapable of speed reading because I feel like

I have to duplicate my efforts.

Like if I skim it, like I can, you know, pick up some key, you know, headings or whatever, but, but I never really got to read it.

Like, like I want to read something.

I want to really read it, like go through it line by line by line and look up things.

I don't know what they mean and this kind of thing.

So, so it's, it's a different, um, an interesting approach, how different people approach things in different ways.

Yeah.


SPEAKER_01:
Yeah.

You know, talking about in this paper,

we've been going between the sort of physiological and biological substrate of cognition and the nervous system and the brain all of that and then this more cognitive modeling approach which can be sort of cut and dry or overly computational or so-called unrealistic with respect to biological foundations it's kind of like what dean pointed to with like the bifurcation and so now things are kind of coming together

not in the way that everyone might've expected, but at least in a way.

And so that's a very interesting space.

And then like blue with a fast and slow reading, it's almost like there are multi-scale dynamics associated with attention.

That can be measured with the EEG, but it's a hidden state, what is actually happening in the mind and brain.

But those are the kinds of experiments that people use.

And there's some rhythms like the fast cycles, like gamma that are playing out at like kind of like the speed of perception and awareness of like words.

And then there's also slower, like symbolic or semantic changes and all these different timescales.

And it's just like,

making the space to let the connections and the terms and the implications resonate and connect with the learner and the creator is like a lot more valuable than any amount of coefficient of low reading and so how to balance the information amount

and type and sequence and all of these things with holding the space for just the slower transformative process.

And that's very related to, yeah.


SPEAKER_03:
That's huge, Daniel, because I think a lot of people that they get into the instructionalism, you'll hear the expression, and I'm not overgeneralizing here.

You'll hear, well, we're going to break this down.

as opposed to the interactionism, which is we're going to slow this down.


SPEAKER_01:
There's quite a difference between those two things.

Open up and slow down, or we're going to drill down, finish it out, get it done in the time.

And as we discuss, this is the archetypes or the dialectic.

It's not like we're only taking one approach or another, but it's very easy to see how the range in at least education space, not even thinking of other areas, is like...

it's the amount of content and then it projects down into how it's delivered.

And then content gets slotted in or out or things get expanded or not, or the, you know, Monday's class gets canceled and it moves to Tuesday.

So that's like the sort of instruction projection approach, which is so different in multiple ways, especially in how it's applied to thinking more about the opening up a space and slowing down and the learner's journey and all that.


SPEAKER_03:
And when you're in the huddle and you're calling out the shorthand before you actually line up at the scrimmage line and snap the football, it's interesting what you point out, Luke.

I, in my history, I was always prepared to slow down when it was math and the symbology.

Like I have no problem slowing down for that, but trying to read out long sentences, it just about kills me.

I mean,

My ADD, I have to interleave like every 20 to 30 minutes because if I don't, my skin starts to crawl.

So I mean, those sort of contextual factors that are literally weighing on you, you don't know those sorts of things.

And if you're an expert who's just trying to push out all this information in a 13-week window,

I'm not really sure whether or not you can sort of get down to that level of personalization.

But if you're able to, it makes all the difference in the world in terms of what people take away from the exposure, right?

I find it way easier to do the shorthand thing.

You know, if a picture's worth a thousand words, I'm in full agreement with that.

You just can't do the thousand word thing.

So, yeah.


SPEAKER_01:
Yeah, really interesting.

And Steven wrote in the chat, good to see these questions about active modeling expertise being thought of in different ways, like the direction of travel, the distance to travel, the rate of travel, mode of transport.

Yeah, thanks for sharing it, Steven.

Landscapes and sort of the sense making and the way finding.

and being on this cognitive landscape versus or and being on this spatial foraging landscape.

So going out for the mushroom forage with someone who's familiar with mushrooms and somebody else who's familiar with the biochemistry but hasn't seen the mushroom in the ground, and then someone else who's on a different perspective because of their background or people with different physical abilities and knowledge in the spatial setting, and then there's

the cognitive foraging, and then just like, is it that the colony forges as a unit?

And then that's the sort of flip side of the nest mates forage collectively.

And so the team forges as a unit collectively, and the individual is sort of engaged at this level that we have experience at in the policy selection relevant to our participation in some either niche or team or project.

Let's go back to the paper, see if there's any other pieces that we could kind of look at.

Let's look at the roadmap.


SPEAKER_03:
Can we talk a bit about the endowment part of this?

Because we haven't really touched on that.

Well, just the endowment.

What's the endowment?

So in the point twos, essentially, now that we've built this base, this stable platform, what can we do with it?

What leverage have we now potentially achieved?

So what's the endowment here in terms of

what the paper really, what's the new affordances that we didn't have before, that we didn't maybe necessarily have explicated quite so clearly prior to reading the paper.

Maybe that's one, I don't want to put pressure on Blue, but what do you think, Blue?


SPEAKER_00:
so i'm trying to remember maybe you guys can remind me in this figure oh wait wait wait so endowing with temporal depth um it's got to be an allostat right is that correct yeah yeah yeah um because in having a homeostat with temporal depth like isn't possible right or or like isn't like they just can they can only do um

And I wonder if that's like, you know, a single celled organism can only like do at that moment, like they're not planning for it to get cold later or something like that.

Um, and really the, so I wonder if it's not only temporal depths, but any kind of relationship.

Like, I wonder if it's not necessarily temporal depth, if time is flat.

I mean, I guess in order to modify your own behavior or thought, you would have to have some temporal depth.

But this allostatic idea is interesting with respect to my relationship to my future self or my relationship to my previous self or my relationship to other people in my community or whatever.

So I just wonder about...

If that's why this is the allostat and not the homeostat.

Or can you endow a homeostat with temporal depth and get that same kind of ability for perspective and retrospective inference?

You can't.

But why not?

Maybe let's put some words to that.

Let me see if I can find some in the paper.


SPEAKER_01:
Nice point.

I would say homeostatic function could be in a model with memory or anticipation.

Like the thermometer could record the last 100 time points, or it could have a prediction for the next 100, but the function would be that it only turns on the heating once it gets too cold.

So it still is the, on the action selection side, it still is making a one Markov chain decision based upon an instantaneous

measurement.

And so it can be implemented whether just for a computational parsimony or in a simple biological system with just one time step.

If it's this hot, then turn on the cooling.

And so it's the ultimate if then, because it's like a threshold model.

And so it gets pared down over evolutionary time, but then you're bringing up like to even engage with a counterfactual or some influence or something on future policy, there has to be like a depth.

And then this gets back to whether it's modeling the thing itself.

what do these represent are they the scientists testing a model of one two three or four five hour temporal depth for the ant forager or is this the foragers quote cognitive model as if that were somehow not model-based science or is it the neural architecture or the functional anatomy of the forager there's a lot of ways it could lean or be framed um

I think in a complimentary way, but one will have to be really careful where support for one domain super valid and where is one not.

Like if it were a circuit board with that topology, then it seems like pretty good to go to use that as a pretty broad descriptor of a system.

Whereas if this was a simplification of memory and there was an uncertainty parameter labeled uncertainty or

anxiety, like we discussed a little earlier, someone slaps a parameter on one of these edges and starts addressing complex real-world settings, how does that exactly work?


SPEAKER_03:
So one of the things that I think that it endows us with is that the homeostat is the sort of the basic pattern of

there's a partition between the epsilon and the mu.

So the first thing that they did is they created a sort of horizontal partition.

And then when they went to the parallelism, now there's two epsilons and two mus.

And so now they added the vertical partition as well.

And I think that's really, really helpful in terms of at the basic level of the statistical.

We talked last time that you have to kind of be a polymath.

But I think from a modeling perspective, it's getting that orthogonal mesh established that moves us up the chain of complexity.

Because then all of a sudden, you can have diagonal dependencies.

And then you can actually add the Z plane going through this in terms of how the scale is built out on both distance and time.

So I think that's one of the endowments that it provides.


SPEAKER_01:
I could just restate that.

It's like when we say that one of the advantages potentially in application of active inference could be that models are composable.

So they can be composed within a given scale, like spatially or temporally, and that has a visual representation.

It can also be composed in this nested way, which, as we've explored several times, can represent physical enclosure or temporal enclosure, as well as this cognitive architecture, like mental action, depending on how different variables are interpreted in nested modeling.

And so it's composable in several dimensions of transformation, which they represented in figure four, in a way where each transformative step, even though the function might change a lot from the beginning to the end, each organizational or structural, architectural, cognitive step or morphological, if one is looking at that layer,

can be mapped into a certain space and direction of movement within that space.


SPEAKER_03:
Do you think it can also be sculpted out?

I mean, because we're looking at this historically, we're looking at all the things that happened in the history.

Was this the stuff that was kind of carved out and a lot of the stuff that doesn't matter removed in order for it to be more comprehensible?

because I agree with you, it can be composed, but I also think it's not decomposed, but I do think, or even deconstructed, I think it can be sculpted out of a greater history, a greater whole.


SPEAKER_01:
This, oh, yes, please.


SPEAKER_00:
So, sorry, like what, you know, when you talk about a greater history, and we talked about historicity in today, like during, in the last two hours,

And we've also talked about memory, and there's a difference, right?

So historicity is like historically accurate, and memory is like what I remember, or like what any individual remembers.


SPEAKER_03:
Yeah, we've talked about that before, actually.

A few live streams ago.

All I'm thinking is that what this does is compare all the things that... Is it Axel Constant that said...

How did he frame it so that we can understand why we're here now versus all the things that didn't make it, right?

That's essentially what I'm talking about in terms of explaining, right?

They're explaining why something got to the place that it did as opposed to the necessity of all the things you had to do, all the things you had to compose in order to realize the outcome.

I'm trying to bring that back to a sculpting metaphor now.


SPEAKER_01:
awesome so that's um the axel constant 2021 paper the title was the free energy principle it's not about what it takes it's about what took you there and so that's definitely an evolutionary perspective and it's partially because of axel's background in evolution and ecology because that's what we can say about evolution this is what got birds here right

And so the counterfactuals in evolution are a really interesting topic, and that's sort of explored in a variety of more popular as well as more mathematical treatments.

Like, how do we go from the observed, which must have existed, so it's very easy to fall to them being the best of all possible worlds, optimal form, etc.,

But then we also recognize the changing environments and interactions and all that.

And then blue, like with the historicity, facts and the impacts, which are like facts that aren't known.

And then there's the memory, which requires a perspective

People could use system memory or something to refer to a factor and impact on a system, but these are just being used loosely.

Like some parts of how the past influences the present and the future have to do with systems that take a perspective.

Other impacts are not through those adaptive active inference agents.

And so that's very different.

And so historicity is kind of like the stigmergy pheromone layer.

And then there's like memory with the forager.

So you could talk about the memory of the ground for the pheromone, but it makes sense to just remember that it's a different thing with the pheromone on the ground than the cognitive in for ants.

And no Nesme is going to have all the knowledge or the onboard modeling to make decisions, say for the ones that,

not to complicate it too much but it's stuck in the dialectic between doing exactly what worked in the past which is to say recently succeeded but might not work in the future and changing things but once you move into changing things the space of the adjacency of changing is sometimes like daunting and you still haven't really addressed the problem of changing world so origins very deep entry point like into a lot of these

questions in active inference and in other areas because it really connects to the egocentric hopefully not in the um solipsistic or narcissistic sense but just in the way finding sense making paradigm that actually accommodates for others through modeling them explicitly and prioritizing the environment and things like that so pretty

Cool.

And this paper, just to kind of restate what they brought to the picture, they looked at evolutionary timescales and they framed cognition as structural change, which in a Bayesian modeling framework is sometimes called structural learning, as opposed to like parameter learning, fine tuning, given the model structure.

And they connected that to the Bayesian graph model of the active inference partitioning.

then connected that to the factor graphs and then using the homeostat example talked about how there could be like elaborations into other structures so from structures to each other that might be enabling the rise of phenotypes or enabling the modeling of phenotypes that are interesting okay any final thoughts or like where does this pape take us

What is different now?

What are we going to be talking about soon?


SPEAKER_00:
So I'm excited to really delve into the math that is going to get behind the models that were elucidated out in figure four.

How do we go through time and through relationality and hierarchical dimensions and so forth?


SPEAKER_01:
Okay.

Thank you, Blue.

Dean, you won't have the last word, but what do you think?


SPEAKER_03:
Well, I'm still trying to figure out how this sort of ties in with the whole identity piece.

I left that because I thought that was just a rabbit hole that went way too far and too deep.

But I know that when you do get that parallelism and when you can sort of

create a dimensional grid that has negative space as well so like you can be as units going positively or negatively and passing through zero and how that fits with identity that's that's sort of a neck that's a kind of a personal thing that i got to do and then the other thing that i really but the thing that i really liked about this paper is that i think it took something that's really as you said over over huge time scales and sort of

took it back down to something that might be digestible for a lot of people that otherwise they kind of go, okay, so here's 100,000 years ago or a million years ago or whatever, from the bacteria to now, what are the sort of basic building blocks that we say might have played a part in

getting to the kind of sophistication where we are now.

And again, I think it's about learning.

I always think that evolution is about learning.

And so, as I said in the point one, this affirmed a lot of the stuff that I think we need to be bringing into some of the more formal ways that we structure learning, because I think it's learning sort of unleashed as opposed to all tied up.


SPEAKER_01:
Awesome.

Thanks both and everybody who was helping in all the ways for the previous videos.

Just some last thoughts would be from both of you.

And hopefully all together, there's really some interesting insights into learning and education for active inference learning, which is kind of like our meta regime of attention in Active Inference Lab when we're in that regime of attention.

many people have other regimes of attention where it would certainly apply to bring some of these methods and ideas in and also bring pieces from outside into our cognitive modeling of attention and collaboration and communication like those topics and how those are the pillars of education and research

during a time when education and research and participation are evolving is some of the most interesting things.

And so to be able to read evolutionary papers that take a cool scope and approach and then connect it to how we're hopefully organizing together and including the affordance to participate with anyone who's listening now,

It's an interesting mixture, so I hope that we all can just keep on learning and applying together.

All right.

Peace.

Thanks, guys.

Thanks again.

Bye.