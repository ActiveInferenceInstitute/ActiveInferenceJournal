1
00:00:12,559 --> 00:00:13,040
hello

2
00:00:13,040 --> 00:00:15,440
and welcome everyone this is the active

3
00:00:15,440 --> 00:00:17,760
inference lab it is active inference lab

4
00:00:17,760 --> 00:00:19,400
live stream number

5
00:00:19,400 --> 00:00:23,680
26.0 on august 6 2021

6
00:00:23,680 --> 00:00:25,519
we're going to be discussing the paper

7
00:00:25,519 --> 00:00:27,039
bayesian mechanics for stationary

8
00:00:27,039 --> 00:00:29,519
processes

9
00:00:29,519 --> 00:00:32,000
welcome to active inference lab everyone

10
00:00:32,000 --> 00:00:33,360
we are a participatory

11
00:00:33,360 --> 00:00:35,440
online lab that is communicating

12
00:00:35,440 --> 00:00:36,880
learning and practicing

13
00:00:36,880 --> 00:00:39,600
applied active inference you can find us

14
00:00:39,600 --> 00:00:40,960
at the links

15
00:00:40,960 --> 00:00:43,600
on this slide this is recorded in an

16
00:00:43,600 --> 00:00:45,520
archived live stream so please provide

17
00:00:45,520 --> 00:00:47,280
us with feedback so that we can improve

18
00:00:47,280 --> 00:00:49,920
on our work

19
00:00:50,000 --> 00:00:51,360
all backgrounds and perspectives are

20
00:00:51,360 --> 00:00:53,760
welcome here as well

21
00:00:53,760 --> 00:00:56,399
today as you can find out at this short

22
00:00:56,399 --> 00:00:57,199
link

23
00:00:57,199 --> 00:00:59,120
we're going to be having the context

24
00:00:59,120 --> 00:01:01,440
video for the discussions on august 10th

25
00:01:01,440 --> 00:01:04,559
and 17th in number 26.1 and 26.2

26
00:01:04,559 --> 00:01:06,640
which are going to be group discussions

27
00:01:06,640 --> 00:01:08,320
with some of the authors joining

28
00:01:08,320 --> 00:01:10,080
so if you want to join for any of these

29
00:01:10,080 --> 00:01:11,600
talks

30
00:01:11,600 --> 00:01:14,159
or discussions then please just let us

31
00:01:14,159 --> 00:01:14,880
know

32
00:01:14,880 --> 00:01:17,759
and also we have a few weeks where we

33
00:01:17,759 --> 00:01:19,040
don't have a paper decided so if you

34
00:01:19,040 --> 00:01:19,840
have a suggestion

35
00:01:19,840 --> 00:01:21,360
and want to be in those discussions let

36
00:01:21,360 --> 00:01:23,200
us know

37
00:01:23,200 --> 00:01:25,600
all right today in acting stream number

38
00:01:25,600 --> 00:01:28,080
26.0 the goal is going to be to

39
00:01:28,080 --> 00:01:30,320
learn and discuss this paper bayesian

40
00:01:30,320 --> 00:01:32,400
mechanics for stationary processes

41
00:01:32,400 --> 00:01:36,159
by decosta fristen heinz and pavliotis

42
00:01:36,159 --> 00:01:40,320
which was posted in june 2021

43
00:01:40,320 --> 00:01:42,640
this video just like all the dot zeros

44
00:01:42,640 --> 00:01:44,479
is just an introduction to some of the

45
00:01:44,479 --> 00:01:46,479
ideas in a walk through the paper one

46
00:01:46,479 --> 00:01:49,600
way it's not a review or a final word

47
00:01:49,600 --> 00:01:51,759
we're gonna give some overview to the

48
00:01:51,759 --> 00:01:53,840
paper then

49
00:01:53,840 --> 00:01:56,640
address a few of the key words from a

50
00:01:56,640 --> 00:01:58,079
big picture perspective

51
00:01:58,079 --> 00:01:59,360
then go through the figures in the

52
00:01:59,360 --> 00:02:02,000
formalism

53
00:02:03,759 --> 00:02:06,960
i'm daniel and i'm a postdoc researcher

54
00:02:06,960 --> 00:02:10,399
in davis california

55
00:02:10,878 --> 00:02:13,760
so in this paper the aims and the claims

56
00:02:13,760 --> 00:02:14,160
are

57
00:02:14,160 --> 00:02:17,440
laid out as followed they wrote in this

58
00:02:17,440 --> 00:02:18,000
paper

59
00:02:18,000 --> 00:02:19,520
we considered the consequences of a

60
00:02:19,520 --> 00:02:21,440
boundary mediating interactions between

61
00:02:21,440 --> 00:02:23,840
states internal and external to a system

62
00:02:23,840 --> 00:02:25,440
so it's about interfaces and

63
00:02:25,440 --> 00:02:28,560
interactions that's the first point

64
00:02:28,560 --> 00:02:30,959
on unpacking this notion we found that

65
00:02:30,959 --> 00:02:33,120
the states internal to a markov blanket

66
00:02:33,120 --> 00:02:35,200
look as if they perform variational

67
00:02:35,200 --> 00:02:36,640
bayesian inference

68
00:02:36,640 --> 00:02:38,640
optimizing beliefs about their external

69
00:02:38,640 --> 00:02:39,760
counterparts

70
00:02:39,760 --> 00:02:43,519
so uh when the boundary is set up in a

71
00:02:43,519 --> 00:02:44,400
certain way

72
00:02:44,400 --> 00:02:46,080
for which kinds of systems that's what

73
00:02:46,080 --> 00:02:47,440
we'll be

74
00:02:47,440 --> 00:02:51,040
asking uh how do those systems look from

75
00:02:51,040 --> 00:02:52,560
the outside or what does it look as if

76
00:02:52,560 --> 00:02:53,680
they're doing

77
00:02:53,680 --> 00:02:56,800
and then three when subdividing the

78
00:02:56,800 --> 00:02:58,720
blanket into sensory and active states

79
00:02:58,720 --> 00:03:00,640
we found that autonomous states perform

80
00:03:00,640 --> 00:03:02,400
active inference in various forms of

81
00:03:02,400 --> 00:03:03,599
stochastic control

82
00:03:03,599 --> 00:03:06,239
i.e generalizations of pid control so a

83
00:03:06,239 --> 00:03:07,760
lot of these terms like variational

84
00:03:07,760 --> 00:03:08,400
bayesian

85
00:03:08,400 --> 00:03:11,440
markov blanket pid control we're going

86
00:03:11,440 --> 00:03:12,319
to be

87
00:03:12,319 --> 00:03:14,400
talking about more but at the overview

88
00:03:14,400 --> 00:03:16,159
level that's the aims and claims as the

89
00:03:16,159 --> 00:03:19,280
authors write them

90
00:03:19,280 --> 00:03:21,040
the abstract states that the paper

91
00:03:21,040 --> 00:03:22,959
develops a bayesian mechanics for

92
00:03:22,959 --> 00:03:26,400
adaptive systems and then there's only

93
00:03:26,400 --> 00:03:29,599
these three claims again

94
00:03:29,599 --> 00:03:31,680
which are again related to the blanket

95
00:03:31,680 --> 00:03:32,720
and adaptiveness

96
00:03:32,720 --> 00:03:36,720
of systems and then this partitioning of

97
00:03:36,720 --> 00:03:39,040
that interface into sense and action so

98
00:03:39,040 --> 00:03:40,720
first we model the interface between a

99
00:03:40,720 --> 00:03:42,400
system and its environment with a markov

100
00:03:42,400 --> 00:03:43,280
blanket

101
00:03:43,280 --> 00:03:44,879
this affords conditions under which

102
00:03:44,879 --> 00:03:46,720
states internals of the blanket encode

103
00:03:46,720 --> 00:03:47,840
information about

104
00:03:47,840 --> 00:03:50,480
external states second we introduce

105
00:03:50,480 --> 00:03:51,200
dynamics

106
00:03:51,200 --> 00:03:53,200
and represent adaptive systems as markov

107
00:03:53,200 --> 00:03:54,799
blankets at steady state

108
00:03:54,799 --> 00:03:56,959
this allows us to identify a wide class

109
00:03:56,959 --> 00:03:58,640
of systems whose internal states appear

110
00:03:58,640 --> 00:04:00,159
to infer external states

111
00:04:00,159 --> 00:04:02,159
consistent with variational inference in

112
00:04:02,159 --> 00:04:03,760
bayesian statistics and theoretical

113
00:04:03,760 --> 00:04:05,439
neuroscience

114
00:04:05,439 --> 00:04:09,439
finally whoops we partition the blanket

115
00:04:09,439 --> 00:04:11,840
into sensory and active states

116
00:04:11,840 --> 00:04:13,519
it follows that active states can be

117
00:04:13,519 --> 00:04:15,680
seen as performing active inference

118
00:04:15,680 --> 00:04:17,519
and well-known forms of stochastic

119
00:04:17,519 --> 00:04:20,000
control such as pid control

120
00:04:20,000 --> 00:04:21,519
which are prominent formulations of

121
00:04:21,519 --> 00:04:24,479
adaptive behavior in theoretical biology

122
00:04:24,479 --> 00:04:27,120
and engineering so this is going to be

123
00:04:27,120 --> 00:04:28,160
relating to

124
00:04:28,160 --> 00:04:29,919
math and physics with the markov

125
00:04:29,919 --> 00:04:31,680
blankets and the far from equilibrium

126
00:04:31,680 --> 00:04:32,800
thermodynamics

127
00:04:32,800 --> 00:04:35,759
component and information theory and

128
00:04:35,759 --> 00:04:36,240
then

129
00:04:36,240 --> 00:04:39,040
it's also going to be developed into

130
00:04:39,040 --> 00:04:40,320
some domain specific

131
00:04:40,320 --> 00:04:42,479
cases or shown to be a generalization of

132
00:04:42,479 --> 00:04:43,520
domain specific

133
00:04:43,520 --> 00:04:46,880
cases like theoretical biology

134
00:04:46,880 --> 00:04:50,560
and engineering these are the sections

135
00:04:50,560 --> 00:04:52,479
of the paper so first there's an

136
00:04:52,479 --> 00:04:54,160
introduction which has some of the

137
00:04:54,160 --> 00:04:57,680
general concepts then there's a section

138
00:04:57,680 --> 00:04:59,600
on markov blankets which is going to be

139
00:04:59,600 --> 00:05:01,759
a key

140
00:05:01,759 --> 00:05:04,320
framework and a key uh formalism to

141
00:05:04,320 --> 00:05:05,440
track because it's kind of what the

142
00:05:05,440 --> 00:05:06,320
paper is about

143
00:05:06,320 --> 00:05:08,639
so first technical sections about the

144
00:05:08,639 --> 00:05:10,400
markov blankets

145
00:05:10,400 --> 00:05:12,560
followed by a discussion of how that

146
00:05:12,560 --> 00:05:14,240
relates to bayesian

147
00:05:14,240 --> 00:05:16,160
systems or certain types of bayesian

148
00:05:16,160 --> 00:05:17,440
systems

149
00:05:17,440 --> 00:05:21,280
and then this general bayesian framework

150
00:05:21,280 --> 00:05:24,479
is then sort of uh

151
00:05:24,479 --> 00:05:26,720
specified towards an active inference

152
00:05:26,720 --> 00:05:29,039
model specifically with an eye towards

153
00:05:29,039 --> 00:05:31,199
stochastic control

154
00:05:31,199 --> 00:05:32,800
and then there's a discussion and

155
00:05:32,800 --> 00:05:35,360
conclusion and then there's three

156
00:05:35,360 --> 00:05:37,520
supplemental sections related to the

157
00:05:37,520 --> 00:05:39,120
synchronization map

158
00:05:39,120 --> 00:05:41,199
which is about the synchronization of

159
00:05:41,199 --> 00:05:43,039
internal and external states

160
00:05:43,039 --> 00:05:45,440
and how that's related to some math

161
00:05:45,440 --> 00:05:46,320
results

162
00:05:46,320 --> 00:05:48,720
there's the helmholtz decomposition

163
00:05:48,720 --> 00:05:49,440
which

164
00:05:49,440 --> 00:05:51,840
is related to vector fields and

165
00:05:51,840 --> 00:05:53,680
splitting them into different components

166
00:05:53,680 --> 00:05:54,800
and then there's the free energy

167
00:05:54,800 --> 00:05:57,280
computation and

168
00:05:57,280 --> 00:06:00,080
some more details related to what

169
00:06:00,080 --> 00:06:00,960
exactly

170
00:06:00,960 --> 00:06:06,319
that formalism is used as here

171
00:06:06,319 --> 00:06:09,039
the keywords of the paper were

172
00:06:09,039 --> 00:06:10,720
variational bayesian inference

173
00:06:10,720 --> 00:06:13,280
non-equilibrium steady state markov

174
00:06:13,280 --> 00:06:14,240
blanket

175
00:06:14,240 --> 00:06:16,000
free energy principle predictive

176
00:06:16,000 --> 00:06:18,960
processing and active inference

177
00:06:18,960 --> 00:06:22,240
so first non-equilibrium non-equilibrium

178
00:06:22,240 --> 00:06:25,440
steady state here's a figure

179
00:06:25,440 --> 00:06:28,880
from this paper stable unstable and

180
00:06:28,880 --> 00:06:30,800
meta-stable states of equilibrium

181
00:06:30,800 --> 00:06:32,880
definitions and applications to human

182
00:06:32,880 --> 00:06:34,240
movement so

183
00:06:34,240 --> 00:06:35,759
there's going to be some mathematical

184
00:06:35,759 --> 00:06:38,960
definitions and uses of non-equilibrium

185
00:06:38,960 --> 00:06:40,479
steady state but this is a domain

186
00:06:40,479 --> 00:06:42,800
specific usage that gets at some of the

187
00:06:42,800 --> 00:06:43,759
nuances

188
00:06:43,759 --> 00:06:45,919
there's not just one single way to frame

189
00:06:45,919 --> 00:06:46,800
equilibrium

190
00:06:46,800 --> 00:06:49,039
especially for dynamical systems and

191
00:06:49,039 --> 00:06:49,840
this is shown as

192
00:06:49,840 --> 00:06:53,039
with an example of a person in movement

193
00:06:53,039 --> 00:06:55,680
so there might be a total thermodynamic

194
00:06:55,680 --> 00:06:56,479
equilibrium

195
00:06:56,479 --> 00:06:59,680
like death but even within the non-death

196
00:06:59,680 --> 00:07:02,960
regime there are still many types of

197
00:07:02,960 --> 00:07:03,840
equilibrium

198
00:07:03,840 --> 00:07:06,160
there's lying down they're sitting in a

199
00:07:06,160 --> 00:07:07,039
chair

200
00:07:07,039 --> 00:07:08,960
there's a walking steady state there's

201
00:07:08,960 --> 00:07:10,720
this meta-stable state

202
00:07:10,720 --> 00:07:12,319
and then there's unstable states of

203
00:07:12,319 --> 00:07:14,240
equilibrium so a few

204
00:07:14,240 --> 00:07:17,360
just questions would be like what does

205
00:07:17,360 --> 00:07:19,120
it mean to have equilibrium

206
00:07:19,120 --> 00:07:21,759
of a measurement or a system at a given

207
00:07:21,759 --> 00:07:23,280
level and what's the difference between

208
00:07:23,280 --> 00:07:23,759
that

209
00:07:23,759 --> 00:07:26,479
static just something on the ground

210
00:07:26,479 --> 00:07:28,800
versus a dynamic equilibrium

211
00:07:28,800 --> 00:07:30,160
like something that maintains its

212
00:07:30,160 --> 00:07:33,039
position and uses energy to do that

213
00:07:33,039 --> 00:07:35,759
so in those cases where does the energy

214
00:07:35,759 --> 00:07:37,199
come from

215
00:07:37,199 --> 00:07:39,280
how does this relate to dissipative

216
00:07:39,280 --> 00:07:40,479
systems

217
00:07:40,479 --> 00:07:42,720
so something where there's energy to be

218
00:07:42,720 --> 00:07:44,160
expended like a battery

219
00:07:44,160 --> 00:07:46,720
or a tornado and how does that relate to

220
00:07:46,720 --> 00:07:47,520
adaptive

221
00:07:47,520 --> 00:07:50,720
systems and predictive systems

222
00:07:50,720 --> 00:07:52,720
which ones are related to active

223
00:07:52,720 --> 00:07:55,360
inference one or both

224
00:07:55,360 --> 00:07:58,080
and what about when there are

225
00:07:58,080 --> 00:07:59,199
multi-level

226
00:07:59,199 --> 00:08:02,560
systems of equilibria so some that are

227
00:08:02,560 --> 00:08:05,039
higher frequency or shorter timescale or

228
00:08:05,039 --> 00:08:06,639
smaller spatial scale

229
00:08:06,639 --> 00:08:09,280
and others that are broader and also

230
00:08:09,280 --> 00:08:10,639
what if we want to have

231
00:08:10,639 --> 00:08:13,280
action-oriented models of those systems

232
00:08:13,280 --> 00:08:15,199
so we want to have the description

233
00:08:15,199 --> 00:08:16,319
that's optimal

234
00:08:16,319 --> 00:08:18,479
for some other set of requirements other

235
00:08:18,479 --> 00:08:20,720
than just accurate measurement

236
00:08:20,720 --> 00:08:23,440
and that's where this paper is going to

237
00:08:23,440 --> 00:08:24,639
be kind of headed

238
00:08:24,639 --> 00:08:26,560
is thinking about dynamical systems in

239
00:08:26,560 --> 00:08:28,000
general and looking

240
00:08:28,000 --> 00:08:31,759
at equations that relate to solving them

241
00:08:31,759 --> 00:08:34,320
another keyword was variational bayesian

242
00:08:34,320 --> 00:08:35,519
inference

243
00:08:35,519 --> 00:08:38,320
and there's a lot of good literature on

244
00:08:38,320 --> 00:08:38,880
this

245
00:08:38,880 --> 00:08:40,240
topic from a lot of different

246
00:08:40,240 --> 00:08:42,320
perspectives but this article

247
00:08:42,320 --> 00:08:44,560
had a good way of phrasing it which is

248
00:08:44,560 --> 00:08:45,600
that

249
00:08:45,600 --> 00:08:48,399
variational inference methods consist in

250
00:08:48,399 --> 00:08:50,080
finding the best approximation of a

251
00:08:50,080 --> 00:08:52,160
distribution among a parameterized

252
00:08:52,160 --> 00:08:55,040
family and in contrary to sampling

253
00:08:55,040 --> 00:08:55,760
approaches

254
00:08:55,760 --> 00:08:57,680
a model is assumed which is the

255
00:08:57,680 --> 00:08:59,760
parameterized family

256
00:08:59,760 --> 00:09:01,519
implying a bias but also a lower

257
00:09:01,519 --> 00:09:03,040
variance in general

258
00:09:03,040 --> 00:09:04,880
variational inference methods are less

259
00:09:04,880 --> 00:09:08,000
accurate than sampling based like mcmc

260
00:09:08,000 --> 00:09:11,040
ones but produce results much faster

261
00:09:11,040 --> 00:09:12,880
these methods are better adapted to big

262
00:09:12,880 --> 00:09:15,120
scale very statistical problems

263
00:09:15,120 --> 00:09:16,399
so again to just kind of give a

264
00:09:16,399 --> 00:09:18,560
qualitative example it's like the real

265
00:09:18,560 --> 00:09:20,160
world is giving you this data which is

266
00:09:20,160 --> 00:09:22,480
the blurry image of a cat

267
00:09:22,480 --> 00:09:25,839
one way to get at what was the

268
00:09:25,839 --> 00:09:26,560
generative

269
00:09:26,560 --> 00:09:29,279
uh underlying cat that generated this

270
00:09:29,279 --> 00:09:30,480
blurry image

271
00:09:30,480 --> 00:09:32,720
would be to sample and find the most

272
00:09:32,720 --> 00:09:34,720
likely cat generating this image

273
00:09:34,720 --> 00:09:37,839
or do various other sampling schemes and

274
00:09:37,839 --> 00:09:40,480
if it's set up properly it can fit

275
00:09:40,480 --> 00:09:41,519
arbitrary

276
00:09:41,519 --> 00:09:43,120
distributions however it can be

277
00:09:43,120 --> 00:09:44,720
computationally expensive and really

278
00:09:44,720 --> 00:09:46,000
hard to know if you're

279
00:09:46,000 --> 00:09:49,120
solving the problem at

280
00:09:49,120 --> 00:09:52,480
a functional enough rate in contrast the

281
00:09:52,480 --> 00:09:54,399
variational inference approach is

282
00:09:54,399 --> 00:09:56,160
related to fitting the data

283
00:09:56,160 --> 00:09:58,480
based upon a pre-specified family of

284
00:09:58,480 --> 00:09:59,680
distributions

285
00:09:59,680 --> 00:10:01,600
which can still be really general and it

286
00:10:01,600 --> 00:10:03,440
can be fast but it can sometimes

287
00:10:03,440 --> 00:10:06,399
lead to fitting the optimal support for

288
00:10:06,399 --> 00:10:08,320
a given distribution

289
00:10:08,320 --> 00:10:10,640
but having it just be categorically

290
00:10:10,640 --> 00:10:12,480
wrong on some other dimension like

291
00:10:12,480 --> 00:10:14,160
estimated through deep time or something

292
00:10:14,160 --> 00:10:15,680
like that

293
00:10:15,680 --> 00:10:17,519
so variational bayesian inference is

294
00:10:17,519 --> 00:10:18,959
this lower

295
00:10:18,959 --> 00:10:20,800
cat where there's a known cat and then

296
00:10:20,800 --> 00:10:22,880
you stretch and distort the cat for

297
00:10:22,880 --> 00:10:23,360
example

298
00:10:23,360 --> 00:10:25,920
reparameterize the cat to find an

299
00:10:25,920 --> 00:10:29,120
underlying likely cat

300
00:10:30,839 --> 00:10:33,920
another was markov blanket

301
00:10:33,920 --> 00:10:36,079
and there was good discussion of this

302
00:10:36,079 --> 00:10:37,040
with mel

303
00:10:37,040 --> 00:10:40,160
andrews in active stream 14

304
00:10:40,160 --> 00:10:43,680
and we kind of had this continuum from

305
00:10:43,680 --> 00:10:47,200
markov on the left here which was

306
00:10:47,200 --> 00:10:49,120
studying systems from a mathematical

307
00:10:49,120 --> 00:10:50,399
perspective didn't have

308
00:10:50,399 --> 00:10:53,040
computer so it was looking at matrices

309
00:10:53,040 --> 00:10:54,240
and which elements

310
00:10:54,240 --> 00:10:56,240
of matrices were connected to each other

311
00:10:56,240 --> 00:10:57,600
or not

312
00:10:57,600 --> 00:11:00,240
and then that was developed later by

313
00:11:00,240 --> 00:11:00,720
pearl

314
00:11:00,720 --> 00:11:03,440
and others in this broader bayesian

315
00:11:03,440 --> 00:11:04,800
statistical framework

316
00:11:04,800 --> 00:11:06,800
that's where the markov blanket

317
00:11:06,800 --> 00:11:07,920
terminology

318
00:11:07,920 --> 00:11:11,040
starts to come from and

319
00:11:11,040 --> 00:11:14,720
it's also oriented towards empirical

320
00:11:14,720 --> 00:11:16,800
data and discovering dependencies in

321
00:11:16,800 --> 00:11:19,200
data and it's very computational

322
00:11:19,200 --> 00:11:22,399
and then part of the

323
00:11:22,399 --> 00:11:24,959
literature that we're discussing is

324
00:11:24,959 --> 00:11:25,519
where

325
00:11:25,519 --> 00:11:29,040
fristen and others have built on or

326
00:11:29,040 --> 00:11:31,920
used this pearl blanket slash markov

327
00:11:31,920 --> 00:11:32,880
blanket

328
00:11:32,880 --> 00:11:35,760
theme and done a few things like

329
00:11:35,760 --> 00:11:37,920
separating the blanket states into

330
00:11:37,920 --> 00:11:39,360
sensory in action

331
00:11:39,360 --> 00:11:43,200
incoming and outgoing nodes

332
00:11:43,200 --> 00:11:46,560
uh introducing the cybernetic

333
00:11:46,560 --> 00:11:49,360
imperative to be a goal seeking or a

334
00:11:49,360 --> 00:11:51,120
multi-scale good regulator

335
00:11:51,120 --> 00:11:53,120
to maintain that non-equilibrium steady

336
00:11:53,120 --> 00:11:54,959
state which we'll talk about

337
00:11:54,959 --> 00:11:58,720
or and we did um and then also

338
00:11:58,720 --> 00:12:01,600
what's being explored from a formalism

339
00:12:01,600 --> 00:12:02,800
perspective in the paper we're

340
00:12:02,800 --> 00:12:03,920
discussing

341
00:12:03,920 --> 00:12:06,959
is how is it or under what conditions do

342
00:12:06,959 --> 00:12:09,440
internal states act as if they're a

343
00:12:09,440 --> 00:12:11,920
model of their non-local dependencies

344
00:12:11,920 --> 00:12:14,320
so causal dependencies in the world

345
00:12:14,320 --> 00:12:15,120
would be

346
00:12:15,120 --> 00:12:17,600
reflected by how the brain or some other

347
00:12:17,600 --> 00:12:19,200
computer system

348
00:12:19,200 --> 00:12:22,639
works so that entails this generative

349
00:12:22,639 --> 00:12:23,760
model of

350
00:12:23,760 --> 00:12:27,680
the action in the niche and also

351
00:12:27,680 --> 00:12:31,440
brings in the element of including the

352
00:12:31,440 --> 00:12:33,760
uh blanket in internal external states

353
00:12:33,760 --> 00:12:34,880
as part of this broader

354
00:12:34,880 --> 00:12:37,600
inactive embodied and cultured slash

355
00:12:37,600 --> 00:12:40,560
pragmatic term

356
00:12:41,040 --> 00:12:45,440
also in active stream 14 we

357
00:12:45,440 --> 00:12:47,920
had this sort of progression emerging

358
00:12:47,920 --> 00:12:48,480
from the

359
00:12:48,480 --> 00:12:51,760
structuring of the paper where there's a

360
00:12:51,760 --> 00:12:52,240
uh

361
00:12:52,240 --> 00:12:55,560
sort of vector field meets diffusion

362
00:12:55,560 --> 00:12:59,040
thermodynamics uh branch on the bottom

363
00:12:59,040 --> 00:13:00,160
with the

364
00:13:00,160 --> 00:13:03,519
uh focker plank and helmholtz

365
00:13:03,519 --> 00:13:06,320
and that's related to non-equilibrium

366
00:13:06,320 --> 00:13:07,600
steady state

367
00:13:07,600 --> 00:13:11,279
densities and then the free energy

368
00:13:11,279 --> 00:13:12,079
principle

369
00:13:12,079 --> 00:13:15,440
uh subsuming all these sort of pieces

370
00:13:15,440 --> 00:13:17,440
like the markov blanket being maintained

371
00:13:17,440 --> 00:13:18,399
through time

372
00:13:18,399 --> 00:13:20,639
necessitates the degenerative model of

373
00:13:20,639 --> 00:13:21,839
action

374
00:13:21,839 --> 00:13:24,079
is what the internal states have to be

375
00:13:24,079 --> 00:13:26,480
inferring so the useful components

376
00:13:26,480 --> 00:13:30,160
of the external world

377
00:13:30,160 --> 00:13:33,360
and then uh under free energy principle

378
00:13:33,360 --> 00:13:37,120
there's all these sort of related areas

379
00:13:37,120 --> 00:13:37,600
like

380
00:13:37,600 --> 00:13:39,279
active inference is that an

381
00:13:39,279 --> 00:13:41,040
implementation of systems under the free

382
00:13:41,040 --> 00:13:42,240
energy principle

383
00:13:42,240 --> 00:13:43,920
how is this related to predictive

384
00:13:43,920 --> 00:13:45,440
processing

385
00:13:45,440 --> 00:13:48,800
bayesian brain so we talked more about

386
00:13:48,800 --> 00:13:52,240
that but today we're going to look at

387
00:13:52,240 --> 00:13:54,959
how it's used more by the authors in

388
00:13:54,959 --> 00:13:57,440
this paper

389
00:13:57,440 --> 00:14:00,639
so the first thing is that the

390
00:14:00,639 --> 00:14:03,760
code is available on connors

391
00:14:03,760 --> 00:14:07,839
github and we'll also be

392
00:14:07,839 --> 00:14:11,199
talking with connor hopefully so

393
00:14:11,199 --> 00:14:13,440
let's um maybe work through it or if

394
00:14:13,440 --> 00:14:14,399
anyone has

395
00:14:14,399 --> 00:14:16,880
the chance to run it tell us about how

396
00:14:16,880 --> 00:14:18,639
it went or what they learned from it but

397
00:14:18,639 --> 00:14:19,279
i didn't

398
00:14:19,279 --> 00:14:24,480
get to run it so

399
00:14:26,480 --> 00:14:29,040
we can start with figure one which is

400
00:14:29,040 --> 00:14:30,639
laying out the big

401
00:14:30,639 --> 00:14:33,360
graphical intuition of the whole paper

402
00:14:33,360 --> 00:14:34,800
and everything is going to be

403
00:14:34,800 --> 00:14:38,240
specifying uh constraints

404
00:14:38,240 --> 00:14:41,360
or some details or implications of

405
00:14:41,360 --> 00:14:44,800
a way of interpreting this intervention

406
00:14:44,800 --> 00:14:46,160
of the blanket states between

407
00:14:46,160 --> 00:14:49,519
internal and external states so we have

408
00:14:49,519 --> 00:14:52,800
mu the internal states b the blanket

409
00:14:52,800 --> 00:14:53,600
states

410
00:14:53,600 --> 00:14:57,519
and eta which are looks like a curly n

411
00:14:57,519 --> 00:15:01,040
and um this is going to allow us to

412
00:15:01,040 --> 00:15:05,120
separate any set of nodes

413
00:15:05,120 --> 00:15:08,240
mu that we're specifying and

414
00:15:08,240 --> 00:15:11,760
ask what are the blanket states that

415
00:15:11,760 --> 00:15:15,199
insulate from a some

416
00:15:15,199 --> 00:15:17,680
statistical codependency sense which

417
00:15:17,680 --> 00:15:19,120
we'll be exploring

418
00:15:19,120 --> 00:15:22,639
insulates these two partitions

419
00:15:22,639 --> 00:15:26,240
and the caption says the mark called

420
00:15:26,240 --> 00:15:28,079
blanket is depicted graphically as an

421
00:15:28,079 --> 00:15:30,000
undirected graphical model also known as

422
00:15:30,000 --> 00:15:32,560
a markov random field

423
00:15:32,560 --> 00:15:35,120
the circles represent random variables

424
00:15:35,120 --> 00:15:36,560
the lines represent conditional

425
00:15:36,560 --> 00:15:38,880
dependencies between random variables

426
00:15:38,880 --> 00:15:40,800
the markov blanket condition means that

427
00:15:40,800 --> 00:15:42,880
there is no line between mu

428
00:15:42,880 --> 00:15:45,680
internal states and eta the external

429
00:15:45,680 --> 00:15:46,480
states

430
00:15:46,480 --> 00:15:48,320
this means that mu and eta are

431
00:15:48,320 --> 00:15:51,279
conditionally independent given b

432
00:15:51,279 --> 00:15:54,160
so conditioned on the blanket these

433
00:15:54,160 --> 00:15:54,639
internal

434
00:15:54,639 --> 00:15:56,639
external states are separated in other

435
00:15:56,639 --> 00:15:58,800
words knowing the internal state mu

436
00:15:58,800 --> 00:16:00,560
does not afford additional information

437
00:16:00,560 --> 00:16:02,320
about the external state eta when the

438
00:16:02,320 --> 00:16:03,120
blanket state b

439
00:16:03,120 --> 00:16:05,519
is known thus blanket states act as an

440
00:16:05,519 --> 00:16:07,279
informational boundary between

441
00:16:07,279 --> 00:16:10,160
internal and external states so that's

442
00:16:10,160 --> 00:16:11,279
what the

443
00:16:11,279 --> 00:16:14,800
blanket states do and this paper is

444
00:16:14,800 --> 00:16:16,160
going to explore some of the

445
00:16:16,160 --> 00:16:17,600
consequences of

446
00:16:17,600 --> 00:16:21,120
that and again anyone who

447
00:16:21,120 --> 00:16:24,160
has more expertise in this area or

448
00:16:24,160 --> 00:16:27,759
some piece of knowledge that i totally

449
00:16:27,759 --> 00:16:30,800
missed or got wrong my apologies but

450
00:16:30,800 --> 00:16:33,360
um just want to try to represent it as i

451
00:16:33,360 --> 00:16:34,160
saw it

452
00:16:34,160 --> 00:16:36,399
because a lot of the details i was just

453
00:16:36,399 --> 00:16:37,440
wanting to

454
00:16:37,440 --> 00:16:40,160
learn more about and go over with the

455
00:16:40,160 --> 00:16:41,120
authors

456
00:16:41,120 --> 00:16:43,440
uh so if anyone has comments in the chat

457
00:16:43,440 --> 00:16:44,160
they can also

458
00:16:44,160 --> 00:16:47,199
just like mention it okay

459
00:16:47,199 --> 00:16:49,920
so let's jump into how they present some

460
00:16:49,920 --> 00:16:51,120
of the key pieces

461
00:16:51,120 --> 00:16:54,079
of the formalism because that's the

462
00:16:54,079 --> 00:16:55,839
details of free energy

463
00:16:55,839 --> 00:16:57,600
principle slash some of the grounding of

464
00:16:57,600 --> 00:16:58,959
active inference so

465
00:16:58,959 --> 00:17:02,720
even if this is new uh formalism for you

466
00:17:02,720 --> 00:17:05,439
then also hopefully it's also

467
00:17:05,439 --> 00:17:07,760
interesting

468
00:17:07,760 --> 00:17:10,160
so keeping that picture in mind of

469
00:17:10,160 --> 00:17:11,599
figure one

470
00:17:11,599 --> 00:17:13,760
another way of writing out that

471
00:17:13,760 --> 00:17:15,359
graphical model

472
00:17:15,359 --> 00:17:18,079
with a formalism is this eta and then

473
00:17:18,079 --> 00:17:20,160
upside down t

474
00:17:20,160 --> 00:17:23,760
so that's the external states

475
00:17:23,760 --> 00:17:27,280
and then mu conditioned on b so that is

476
00:17:27,280 --> 00:17:29,360
blanket states are markov blanket

477
00:17:29,360 --> 00:17:31,520
separating internal external states so

478
00:17:31,520 --> 00:17:33,120
the top third of the slide

479
00:17:33,120 --> 00:17:35,440
these are like writing out in pros the

480
00:17:35,440 --> 00:17:36,880
same thing as this graphical

481
00:17:36,880 --> 00:17:40,400
model and then

482
00:17:40,400 --> 00:17:43,760
we can take that tuple that

483
00:17:43,760 --> 00:17:47,280
set of those three kinds of nodes

484
00:17:47,280 --> 00:17:49,200
so we have measurements from all these

485
00:17:49,200 --> 00:17:51,039
different things or generative models of

486
00:17:51,039 --> 00:17:52,640
each of these different categories of

487
00:17:52,640 --> 00:17:54,000
nodes

488
00:17:54,000 --> 00:17:57,039
and then that set

489
00:17:57,039 --> 00:17:59,360
so all the measurements slash generative

490
00:17:59,360 --> 00:18:00,720
processes

491
00:18:00,720 --> 00:18:04,000
that x is existing in a bigger

492
00:18:04,000 --> 00:18:06,240
state space so the little x which

493
00:18:06,240 --> 00:18:08,000
consists of like the real

494
00:18:08,000 --> 00:18:11,360
measurements are part of the bigger

495
00:18:11,360 --> 00:18:14,080
x which is kind of like the capital

496
00:18:14,080 --> 00:18:17,120
versions of each of these

497
00:18:17,120 --> 00:18:20,480
and those spaces the the uh e b

498
00:18:20,480 --> 00:18:22,799
and i are taking to be euclidean spaces

499
00:18:22,799 --> 00:18:24,640
for simplicity so i don't know

500
00:18:24,640 --> 00:18:28,000
if it holds for other kinds of spaces so

501
00:18:28,000 --> 00:18:31,440
that's just defining the total space the

502
00:18:31,440 --> 00:18:32,480
possible

503
00:18:32,480 --> 00:18:35,280
states of each of these nodes and then

504
00:18:35,280 --> 00:18:38,720
also the ones that you actually observe

505
00:18:41,039 --> 00:18:44,080
they start with

506
00:18:44,080 --> 00:18:47,039
this case of a gaussian distribution p

507
00:18:47,039 --> 00:18:49,039
encoding the distribution of states of

508
00:18:49,039 --> 00:18:49,600
the world

509
00:18:49,600 --> 00:18:53,440
so p is a random variable

510
00:18:53,440 --> 00:18:56,400
that has drawn from n that's like a

511
00:18:56,400 --> 00:18:58,160
normal distribution symbol

512
00:18:58,160 --> 00:19:00,080
with a mean and a variance and the mean

513
00:19:00,080 --> 00:19:03,120
is zero and the variance is this

514
00:19:03,120 --> 00:19:06,640
um pi to the negative one

515
00:19:06,640 --> 00:19:10,160
and um this has an associated precision

516
00:19:10,160 --> 00:19:12,559
covariance matrix so mean zero that's

517
00:19:12,559 --> 00:19:14,240
the convention n means the normal

518
00:19:14,240 --> 00:19:15,360
distribution

519
00:19:15,360 --> 00:19:17,360
and so it's zero mean that's the

520
00:19:17,360 --> 00:19:19,120
variance pi

521
00:19:19,120 --> 00:19:22,559
and the precision matrix is pi

522
00:19:22,559 --> 00:19:26,559
so then the variance is this pi inverse

523
00:19:26,559 --> 00:19:29,360
and sometimes the equations are

524
00:19:29,360 --> 00:19:31,440
formulated in terms of precision

525
00:19:31,440 --> 00:19:34,559
other times they're they're discussed in

526
00:19:34,559 --> 00:19:35,760
terms of variance

527
00:19:35,760 --> 00:19:37,440
but those are kind of like two sides of

528
00:19:37,440 --> 00:19:39,919
the same coin because the same

529
00:19:39,919 --> 00:19:42,240
it's just like describing it whether

530
00:19:42,240 --> 00:19:43,840
it's how uncertain you are is like

531
00:19:43,840 --> 00:19:45,440
looking from the mean out

532
00:19:45,440 --> 00:19:46,880
and then your precision might be kind of

533
00:19:46,880 --> 00:19:50,320
like is like focusing down

534
00:19:50,840 --> 00:19:53,760
uh unpacking

535
00:19:53,760 --> 00:19:56,640
in terms of gaussian densities so we

536
00:19:56,640 --> 00:19:58,480
would find that a markov blanket is

537
00:19:58,480 --> 00:20:00,960
equivalent to sparsity in the precision

538
00:20:00,960 --> 00:20:03,919
matrix so the mark called blanket

539
00:20:03,919 --> 00:20:05,200
condition is entailing

540
00:20:05,200 --> 00:20:08,240
that the covariance the pi between

541
00:20:08,240 --> 00:20:10,080
external states and internal states

542
00:20:10,080 --> 00:20:12,799
that's the first

543
00:20:13,200 --> 00:20:17,120
one here is equivalent to between

544
00:20:17,120 --> 00:20:20,159
external states and internal states

545
00:20:20,159 --> 00:20:21,919
the mu and the eta and that both of

546
00:20:21,919 --> 00:20:23,679
those equal zero

547
00:20:23,679 --> 00:20:26,880
so there's no covariance and they're the

548
00:20:26,880 --> 00:20:28,880
same as zero

549
00:20:28,880 --> 00:20:31,679
so they're conditionally independent

550
00:20:31,679 --> 00:20:34,080
that's the

551
00:20:34,080 --> 00:20:38,080
bayesian covariance matrix

552
00:20:38,080 --> 00:20:42,559
framing of the marcal blanket sparsity

553
00:20:43,840 --> 00:20:45,679
blanket states act as an information

554
00:20:45,679 --> 00:20:47,520
boundary between external

555
00:20:47,520 --> 00:20:51,360
and internal states and this allows

556
00:20:51,360 --> 00:20:54,159
the breakdown of instead of the all by

557
00:20:54,159 --> 00:20:54,640
all

558
00:20:54,640 --> 00:20:57,440
consideration of correlations for data

559
00:20:57,440 --> 00:20:59,520
fitting or generative modeling

560
00:20:59,520 --> 00:21:02,640
you can reduce

561
00:21:02,640 --> 00:21:06,559
the model space to a much better

562
00:21:06,559 --> 00:21:10,799
uh formulated subset of equations

563
00:21:10,799 --> 00:21:13,120
which are related to inferring

564
00:21:13,120 --> 00:21:14,400
distributions

565
00:21:14,400 --> 00:21:16,080
relating to like external states

566
00:21:16,080 --> 00:21:17,679
conditioning on the blanket states and

567
00:21:17,679 --> 00:21:18,720
internal states

568
00:21:18,720 --> 00:21:21,520
conditioning on the blanket states this

569
00:21:21,520 --> 00:21:23,679
enables us to associate to any blanket

570
00:21:23,679 --> 00:21:25,760
state its corresponding expected

571
00:21:25,760 --> 00:21:30,480
external and expected internal states

572
00:21:30,480 --> 00:21:33,840
so then this equation

573
00:21:33,840 --> 00:21:38,320
said uh drew us a set of equivalencies

574
00:21:38,320 --> 00:21:40,880
which were that the internal states as a

575
00:21:40,880 --> 00:21:44,159
function of blanket states so mu of b

576
00:21:44,159 --> 00:21:47,919
were equal to the expectation

577
00:21:47,919 --> 00:21:51,120
fancy e of mu conditioned on b

578
00:21:51,120 --> 00:21:53,200
so that's the expectation of external

579
00:21:53,200 --> 00:21:55,120
states conditioned

580
00:21:55,120 --> 00:22:00,239
up on of internal states

581
00:22:02,640 --> 00:22:06,400
um internal states conditioned on

582
00:22:06,400 --> 00:22:07,280
blanket i

583
00:22:07,280 --> 00:22:10,240
think that's corrected is right then

584
00:22:10,240 --> 00:22:11,600
three

585
00:22:11,600 --> 00:22:15,120
that that expectation is the same

586
00:22:15,120 --> 00:22:19,120
as the distribution that's

587
00:22:19,120 --> 00:22:22,240
being calculated involving uh the

588
00:22:22,240 --> 00:22:23,520
objective distribution

589
00:22:23,520 --> 00:22:27,919
p and that also that that's related to

590
00:22:27,919 --> 00:22:31,280
uh the variance in covariance like this

591
00:22:31,280 --> 00:22:34,880
sigma variable of internal

592
00:22:34,880 --> 00:22:38,559
and blanket states mu and b

593
00:22:38,559 --> 00:22:41,440
mapping to the space of all the possible

594
00:22:41,440 --> 00:22:42,720
internal states

595
00:22:42,720 --> 00:22:47,840
which was i from here

596
00:22:48,960 --> 00:22:51,679
and then they wrote pursuing the example

597
00:22:51,679 --> 00:22:53,440
of the nervous system each sensory

598
00:22:53,440 --> 00:22:55,120
impression on the retina and ocular

599
00:22:55,120 --> 00:22:56,480
motor orientation

600
00:22:56,480 --> 00:22:59,280
blanket state is associated with an

601
00:22:59,280 --> 00:23:00,080
expected

602
00:23:00,080 --> 00:23:02,559
scene that caused sensory input which is

603
00:23:02,559 --> 00:23:04,559
the expected external state

604
00:23:04,559 --> 00:23:07,280
and does an expected pattern and an

605
00:23:07,280 --> 00:23:08,000
expected pattern

606
00:23:08,000 --> 00:23:10,480
of neural activity in the visual cortex

607
00:23:10,480 --> 00:23:13,039
expected internal state

608
00:23:13,039 --> 00:23:16,640
so it's a way that that objective

609
00:23:16,640 --> 00:23:18,320
distribution

610
00:23:18,320 --> 00:23:21,440
of uh p gets

611
00:23:21,440 --> 00:23:25,200
integrated into the internal model's

612
00:23:25,200 --> 00:23:30,480
output given blanket states

613
00:23:30,640 --> 00:23:33,039
or maybe there's another interpretation

614
00:23:33,039 --> 00:23:34,799
too so i was just i don't know

615
00:23:34,799 --> 00:23:37,840
one way to look at it

616
00:23:39,679 --> 00:23:43,200
this question about the relationship

617
00:23:43,200 --> 00:23:46,240
between the internal and the external

618
00:23:46,240 --> 00:23:50,240
states after you've not

619
00:23:50,240 --> 00:23:53,360
denoised them but decorated them in a

620
00:23:53,360 --> 00:23:56,158
specific way

621
00:23:56,720 --> 00:24:01,919
is this topic of the synchronization map

622
00:24:01,919 --> 00:24:04,080
so they go from just pointing out that

623
00:24:04,080 --> 00:24:05,679
okay we've decorated internal and

624
00:24:05,679 --> 00:24:07,039
external states with these blanket

625
00:24:07,039 --> 00:24:07,919
states

626
00:24:07,919 --> 00:24:10,000
now we're going to ask how these

627
00:24:10,000 --> 00:24:11,600
internal states might encode

628
00:24:11,600 --> 00:24:14,240
information about expected external

629
00:24:14,240 --> 00:24:15,600
states

630
00:24:15,600 --> 00:24:18,559
so after we've decorated systems how do

631
00:24:18,559 --> 00:24:20,400
they have a memory or a model of one

632
00:24:20,400 --> 00:24:22,240
another

633
00:24:22,240 --> 00:24:24,559
for this we would need to characterize a

634
00:24:24,559 --> 00:24:25,760
synchronization function

635
00:24:25,760 --> 00:24:28,159
sigma mapping the expected internal

636
00:24:28,159 --> 00:24:29,520
state to the expected

637
00:24:29,520 --> 00:24:32,159
external state given the blanket state

638
00:24:32,159 --> 00:24:32,720
so

639
00:24:32,720 --> 00:24:35,279
sigma mapping function of internal

640
00:24:35,279 --> 00:24:36,480
states of

641
00:24:36,480 --> 00:24:39,840
blanket states is going to

642
00:24:39,840 --> 00:24:42,880
relate to the

643
00:24:42,880 --> 00:24:45,120
external states at a conditioned on

644
00:24:45,120 --> 00:24:46,799
blanket states

645
00:24:46,799 --> 00:24:49,360
so there's still the dependence of both

646
00:24:49,360 --> 00:24:50,159
internal and

647
00:24:50,159 --> 00:24:54,240
external states on the blanket states b

648
00:24:54,240 --> 00:24:57,279
and now there's a sigma mapping that

649
00:24:57,279 --> 00:24:59,279
is gonna connect internal and external

650
00:24:59,279 --> 00:25:01,840
states

651
00:25:07,679 --> 00:25:12,000
and lemma 2.1 goes

652
00:25:12,000 --> 00:25:13,360
through some details of that

653
00:25:13,360 --> 00:25:15,200
specification

654
00:25:15,200 --> 00:25:17,200
so the first is proposing that there is

655
00:25:17,200 --> 00:25:18,799
a function that maps

656
00:25:18,799 --> 00:25:22,000
internal and external states

657
00:25:22,000 --> 00:25:25,120
for any blanket state

658
00:25:25,120 --> 00:25:27,600
i don't know how generally it holds but

659
00:25:27,600 --> 00:25:28,400
or

660
00:25:28,400 --> 00:25:29,919
this would be cool to talk to the

661
00:25:29,919 --> 00:25:32,640
authors about but it's sort of proposing

662
00:25:32,640 --> 00:25:35,840
this sigma function and

663
00:25:35,840 --> 00:25:38,799
maybe in certain cases it's a zero line

664
00:25:38,799 --> 00:25:40,080
maybe in other cases there's some

665
00:25:40,080 --> 00:25:40,640
meaningful

666
00:25:40,640 --> 00:25:42,559
relationship but for biological systems

667
00:25:42,559 --> 00:25:43,760
it does seem like there's a meaningful

668
00:25:43,760 --> 00:25:44,559
relationship

669
00:25:44,559 --> 00:25:46,480
so those are the systems that we want to

670
00:25:46,480 --> 00:25:49,840
explore modeling

671
00:25:50,159 --> 00:25:53,279
they then write in how to construct this

672
00:25:53,279 --> 00:25:56,320
synchronization map the key idea is to

673
00:25:56,320 --> 00:25:58,559
map an expected internal state mu of b

674
00:25:58,559 --> 00:26:00,320
to an expected external state

675
00:26:00,320 --> 00:26:04,000
eta of b and to do this the

676
00:26:04,000 --> 00:26:07,039
two points they provide are

677
00:26:07,039 --> 00:26:10,240
one to find a blanket state that maps to

678
00:26:10,240 --> 00:26:10,559
this

679
00:26:10,559 --> 00:26:13,679
expected internal state i.e by

680
00:26:13,679 --> 00:26:16,000
inverting mu and 2 from this blanket

681
00:26:16,000 --> 00:26:18,400
state find the corresponding expected

682
00:26:18,400 --> 00:26:19,840
external state

683
00:26:19,840 --> 00:26:23,200
i.e by applying eta we now proceed to

684
00:26:23,200 --> 00:26:24,400
solving this problem

685
00:26:24,400 --> 00:26:27,279
given an internal state mu we study the

686
00:26:27,279 --> 00:26:29,120
blanket states b

687
00:26:29,120 --> 00:26:32,480
such that the

688
00:26:32,480 --> 00:26:36,080
internal states of b

689
00:26:36,080 --> 00:26:39,760
equals mu

690
00:26:39,760 --> 00:26:43,919
they provide some details

691
00:26:44,080 --> 00:26:46,000
maybe that is meant to be external

692
00:26:46,000 --> 00:26:48,720
states i'm not sure

693
00:26:48,720 --> 00:26:52,640
um here um

694
00:26:52,640 --> 00:26:56,799
they're framing that inference

695
00:26:56,799 --> 00:27:01,200
that mu is doing the internal states

696
00:27:01,200 --> 00:27:04,840
in terms of covariance matrices

697
00:27:04,840 --> 00:27:07,600
which is in

698
00:27:07,600 --> 00:27:11,120
this equation 2.4

699
00:27:11,200 --> 00:27:14,559
and then frames that

700
00:27:14,559 --> 00:27:18,080
matrix of unknowns as a system of linear

701
00:27:18,080 --> 00:27:19,200
equations

702
00:27:19,200 --> 00:27:20,399
or those are kind of similar

703
00:27:20,399 --> 00:27:22,880
representations and then

704
00:27:22,880 --> 00:27:25,919
solves for it in the vector space using

705
00:27:25,919 --> 00:27:27,279
this

706
00:27:27,279 --> 00:27:31,120
equation 2.5 they use this

707
00:27:31,120 --> 00:27:34,399
matrix negative

708
00:27:34,399 --> 00:27:36,640
function which is the more penrose

709
00:27:36,640 --> 00:27:39,440
pseudo inverse

710
00:27:39,919 --> 00:27:41,919
it would be helpful to have someone

711
00:27:41,919 --> 00:27:43,600
explain in a little more detail

712
00:27:43,600 --> 00:27:46,559
what the matrix inverse is or what

713
00:27:46,559 --> 00:27:48,399
degrees of freedom there are in choosing

714
00:27:48,399 --> 00:27:48,880
different

715
00:27:48,880 --> 00:27:52,000
kinds of matrix inverses but i just

716
00:27:52,000 --> 00:27:54,480
found it interesting from wikipedia that

717
00:27:54,480 --> 00:27:56,320
a common use of the pseudo inverse

718
00:27:56,320 --> 00:27:59,520
is to compute a best fit or least square

719
00:27:59,520 --> 00:28:01,279
solution to a system of linear equation

720
00:28:01,279 --> 00:28:03,760
that locks a solution

721
00:28:03,760 --> 00:28:06,640
another use is to find the minimum norm

722
00:28:06,640 --> 00:28:08,480
solution to a system of linear equations

723
00:28:08,480 --> 00:28:09,919
with multiple solutions

724
00:28:09,919 --> 00:28:12,399
so this means that there might be

725
00:28:12,399 --> 00:28:12,960
multiple

726
00:28:12,960 --> 00:28:15,840
solutions that are equally well fit and

727
00:28:15,840 --> 00:28:17,440
this just allows you to pick one

728
00:28:17,440 --> 00:28:20,159
fast maybe

729
00:28:20,880 --> 00:28:23,919
and then they write that the key for the

730
00:28:23,919 --> 00:28:26,080
existence of a function sigma mapping

731
00:28:26,080 --> 00:28:27,760
expected internal states to expected

732
00:28:27,760 --> 00:28:29,679
external states given blanket states

733
00:28:29,679 --> 00:28:31,200
is that for any two blanket states

734
00:28:31,200 --> 00:28:33,279
associated with the same expected

735
00:28:33,279 --> 00:28:34,080
internal state

736
00:28:34,080 --> 00:28:35,760
these be associated with the same

737
00:28:35,760 --> 00:28:38,320
expected external state

738
00:28:38,320 --> 00:28:41,279
this non-degeneracy means that the

739
00:28:41,279 --> 00:28:43,520
internal states eg patterns of activity

740
00:28:43,520 --> 00:28:44,880
in the visual cortex

741
00:28:44,880 --> 00:28:46,880
have enough capacity to represent all

742
00:28:46,880 --> 00:28:48,720
possible expected external states

743
00:28:48,720 --> 00:28:51,440
eg 3d scenes of the environment that's

744
00:28:51,440 --> 00:28:52,399
formalized

745
00:28:52,399 --> 00:28:55,840
in this lemma so first

746
00:28:55,840 --> 00:28:58,720
was the point discussed before that

747
00:28:58,720 --> 00:28:59,760
we're interested

748
00:28:59,760 --> 00:29:02,159
in positing the existence of this sigma

749
00:29:02,159 --> 00:29:04,240
function

750
00:29:04,240 --> 00:29:07,600
and then 0.2 so these are all

751
00:29:07,600 --> 00:29:09,039
points that are going to be equivalent

752
00:29:09,039 --> 00:29:10,640
to each other

753
00:29:10,640 --> 00:29:14,000
0.2 is that for any

754
00:29:14,000 --> 00:29:17,279
two blanket states one and two that the

755
00:29:17,279 --> 00:29:21,600
if the two external states

756
00:29:21,600 --> 00:29:24,240
are equal i'm sorry if the two internal

757
00:29:24,240 --> 00:29:25,760
states are equal the muse

758
00:29:25,760 --> 00:29:28,720
of those two b's then it's going to map

759
00:29:28,720 --> 00:29:29,440
onto

760
00:29:29,440 --> 00:29:32,480
equal points in

761
00:29:32,480 --> 00:29:36,320
external world so

762
00:29:36,320 --> 00:29:39,360
the blanket is a is a

763
00:29:39,360 --> 00:29:42,640
map that conserves certain properties of

764
00:29:42,640 --> 00:29:44,320
the relationship between

765
00:29:44,320 --> 00:29:47,678
internal and external states

766
00:29:50,640 --> 00:29:53,120
then points three and four of the lemma

767
00:29:53,120 --> 00:29:54,720
2.1

768
00:29:54,720 --> 00:29:57,760
use this kernel

769
00:29:57,760 --> 00:30:00,960
in image notation

770
00:30:00,960 --> 00:30:03,039
so here was a image that was kind of

771
00:30:03,039 --> 00:30:05,360
interesting

772
00:30:05,360 --> 00:30:08,559
about how spaces were mapped to each

773
00:30:08,559 --> 00:30:10,000
other

774
00:30:10,000 --> 00:30:13,760
so someone could definitely

775
00:30:13,760 --> 00:30:16,159
help explain what some of these mappings

776
00:30:16,159 --> 00:30:17,520
mean or what the emblem

777
00:30:17,520 --> 00:30:22,080
implications are and then this sideways

778
00:30:22,080 --> 00:30:25,679
u shape is the proper subset

779
00:30:25,679 --> 00:30:28,559
symbol so that's meaning that every

780
00:30:28,559 --> 00:30:29,200
element

781
00:30:29,200 --> 00:30:31,679
of the first one is in the second one

782
00:30:31,679 --> 00:30:32,320
but b

783
00:30:32,320 --> 00:30:35,840
is a bigger subset so

784
00:30:35,840 --> 00:30:39,279
certain mappings between the internal

785
00:30:39,279 --> 00:30:42,240
and blanket covariance and the external

786
00:30:42,240 --> 00:30:44,240
and blanket covariance

787
00:30:44,240 --> 00:30:48,840
and then uh similar for the

788
00:30:48,840 --> 00:30:51,840
pi

789
00:30:55,919 --> 00:30:59,200
figure 2 provides a visualization of

790
00:30:59,200 --> 00:31:02,840
some simulations drawn

791
00:31:02,840 --> 00:31:06,559
that uh support just from a simulation

792
00:31:06,559 --> 00:31:07,840
perspective

793
00:31:07,840 --> 00:31:10,320
the existence of a useful

794
00:31:10,320 --> 00:31:11,600
synchronization

795
00:31:11,600 --> 00:31:15,200
map function so

796
00:31:15,200 --> 00:31:19,919
figure two on the left side shows

797
00:31:21,600 --> 00:31:24,640
the external states given blanket states

798
00:31:24,640 --> 00:31:33,440
so those are the orange

799
00:31:33,440 --> 00:31:36,640
yeah external states up these are

800
00:31:36,640 --> 00:31:39,200
the flipped

801
00:31:45,600 --> 00:31:49,440
sorry about that so

802
00:31:49,440 --> 00:31:52,559
the blue are the

803
00:31:52,559 --> 00:31:55,760
internal states the sigma

804
00:31:55,760 --> 00:31:57,919
mapping corresponding to the internal

805
00:31:57,919 --> 00:31:59,440
states conditioned on the external

806
00:31:59,440 --> 00:32:00,240
states

807
00:32:00,240 --> 00:32:03,440
and they're doing a very accurate job

808
00:32:03,440 --> 00:32:06,399
of mapping onto the external states in

809
00:32:06,399 --> 00:32:08,159
orange

810
00:32:08,159 --> 00:32:13,120
and then in b is a so-called non-example

811
00:32:13,120 --> 00:32:16,320
and i'd be curious what

812
00:32:16,320 --> 00:32:20,000
changed or what was different about this

813
00:32:20,000 --> 00:32:22,240
second example or is there more than one

814
00:32:22,240 --> 00:32:23,840
way to break the model

815
00:32:23,840 --> 00:32:25,279
what are the cases where it does or

816
00:32:25,279 --> 00:32:29,840
doesn't have a mapping

817
00:32:30,480 --> 00:32:33,519
then in section 3 they

818
00:32:33,519 --> 00:32:36,720
go from that sort of static estimate

819
00:32:36,720 --> 00:32:39,760
of variables that are just

820
00:32:39,760 --> 00:32:42,159
having a specific relationship to one

821
00:32:42,159 --> 00:32:43,519
another

822
00:32:43,519 --> 00:32:46,399
to beijing mechanics operating through

823
00:32:46,399 --> 00:32:46,880
time

824
00:32:46,880 --> 00:32:49,279
so they write in order to study the time

825
00:32:49,279 --> 00:32:51,120
evolution of systems with a markov

826
00:32:51,120 --> 00:32:51,760
blanket

827
00:32:51,760 --> 00:32:53,760
we introduce dynamics into the external

828
00:32:53,760 --> 00:32:55,600
blanket and internal states

829
00:32:55,600 --> 00:32:57,519
henceforth we assume a synchronization

830
00:32:57,519 --> 00:32:59,360
map under the conditions of the

831
00:32:59,360 --> 00:33:02,320
lemma 2.1 so that was what was discussed

832
00:33:02,320 --> 00:33:04,480
up here

833
00:33:04,480 --> 00:33:07,679
and now in contrast with

834
00:33:07,679 --> 00:33:11,200
figure 1 which was just the variables

835
00:33:11,200 --> 00:33:14,640
by themself now we're

836
00:33:14,640 --> 00:33:17,519
putting the t subscript and looking at

837
00:33:17,519 --> 00:33:19,039
how those variables are changing through

838
00:33:19,039 --> 00:33:21,279
time

839
00:33:21,840 --> 00:33:24,159
we use bacillus to depict an intuitive

840
00:33:24,159 --> 00:33:25,679
example of a markov blanket that

841
00:33:25,679 --> 00:33:27,679
persists over time

842
00:33:27,679 --> 00:33:29,120
here the blanket state between the

843
00:33:29,120 --> 00:33:30,799
membrane and actin filaments of the

844
00:33:30,799 --> 00:33:33,600
cytoskeleton

845
00:33:34,480 --> 00:33:36,240
which mediate all interactions between

846
00:33:36,240 --> 00:33:37,840
the internal states and the external

847
00:33:37,840 --> 00:33:41,039
media external states

848
00:33:41,440 --> 00:33:44,480
in example 3-1 they write there are many

849
00:33:44,480 --> 00:33:46,799
examples of stochastic processes at a

850
00:33:46,799 --> 00:33:48,720
gaussian steady state p

851
00:33:48,720 --> 00:33:52,399
to name a few uh stationary diffusion

852
00:33:52,399 --> 00:33:54,559
processes with initial conditions

853
00:33:54,559 --> 00:33:58,559
x0 tilde p the time evolution is given

854
00:33:58,559 --> 00:34:00,640
by an ito stochastic differential

855
00:34:00,640 --> 00:34:01,600
equation

856
00:34:01,600 --> 00:34:04,240
appendix b next slide that will be on

857
00:34:04,240 --> 00:34:05,360
the next slide

858
00:34:05,360 --> 00:34:07,760
and then also example three one more

859
00:34:07,760 --> 00:34:08,719
generally

860
00:34:08,719 --> 00:34:10,719
any markov process at steady state p

861
00:34:10,719 --> 00:34:11,839
such as the zigzag

862
00:34:11,839 --> 00:34:14,879
process any mean zero gaussian process

863
00:34:14,879 --> 00:34:17,918
at steady state and any random dynamical

864
00:34:17,918 --> 00:34:21,280
system at steady state p

865
00:34:21,280 --> 00:34:24,480
so questions for people who know more or

866
00:34:24,480 --> 00:34:25,520
the authors would be

867
00:34:25,520 --> 00:34:27,440
what kinds of systems fall under this

868
00:34:27,440 --> 00:34:30,079
category of stochastic processes

869
00:34:30,079 --> 00:34:31,679
and what kind of real world systems

870
00:34:31,679 --> 00:34:33,839
would be modeled well or not by this

871
00:34:33,839 --> 00:34:36,079
formalism

872
00:34:36,079 --> 00:34:39,679
and then going a little deeper into

873
00:34:39,679 --> 00:34:43,359
that first point in the examples

874
00:34:43,359 --> 00:34:45,280
appendix b points to this helmholtz

875
00:34:45,280 --> 00:34:47,119
decomposition

876
00:34:47,119 --> 00:34:50,399
and that is conditioned on this

877
00:34:50,399 --> 00:34:53,599
ido stochastic differential equation

878
00:34:53,599 --> 00:34:56,079
and again just questions for someone who

879
00:34:56,079 --> 00:34:58,240
knows more or for the authors

880
00:34:58,240 --> 00:35:02,720
what does this edo calculation entail

881
00:35:02,720 --> 00:35:06,480
and what does or doesn't fit under this

882
00:35:06,480 --> 00:35:07,920
edo

883
00:35:07,920 --> 00:35:11,119
framework that would work using some

884
00:35:11,119 --> 00:35:13,040
other definition

885
00:35:13,040 --> 00:35:16,480
uh just

886
00:35:16,480 --> 00:35:19,119
not sure about that but in this

887
00:35:19,119 --> 00:35:20,160
helmholtz

888
00:35:20,160 --> 00:35:23,280
supplement there is

889
00:35:23,280 --> 00:35:26,560
a very nice figure 10 that is

890
00:35:26,560 --> 00:35:29,680
looking at in this kind of hill climbing

891
00:35:29,680 --> 00:35:30,880
perspective

892
00:35:30,880 --> 00:35:33,839
so in an algorithm that's looking in its

893
00:35:33,839 --> 00:35:34,480
local

894
00:35:34,480 --> 00:35:36,800
neighborhood and doing a calculation to

895
00:35:36,800 --> 00:35:39,280
sort of make local decision making and

896
00:35:39,280 --> 00:35:42,960
hill climb that action

897
00:35:42,960 --> 00:35:44,880
of a stochastic but hill-climbing

898
00:35:44,880 --> 00:35:46,240
algorithm

899
00:35:46,240 --> 00:35:49,839
up this gradient

900
00:35:49,839 --> 00:35:51,760
or down depending on which way you set

901
00:35:51,760 --> 00:35:53,040
it up

902
00:35:53,040 --> 00:35:55,920
is going to have two components to its

903
00:35:55,920 --> 00:35:56,839
motion

904
00:35:56,839 --> 00:35:59,839
this straight up the mountain component

905
00:35:59,839 --> 00:36:01,599
like putting a ruler on the mountain and

906
00:36:01,599 --> 00:36:03,040
the maximum slope

907
00:36:03,040 --> 00:36:05,200
and then another component that's at the

908
00:36:05,200 --> 00:36:07,520
same likelihood like the same altitude

909
00:36:07,520 --> 00:36:10,880
same energy that's going

910
00:36:10,880 --> 00:36:12,960
at an iso contour just like you can

911
00:36:12,960 --> 00:36:14,880
always do for a mountain

912
00:36:14,880 --> 00:36:18,320
so with that idea in mind

913
00:36:18,320 --> 00:36:21,040
it's possible to take the full dynamic

914
00:36:21,040 --> 00:36:22,880
of a stochastic trace

915
00:36:22,880 --> 00:36:24,160
on the top left this is like this

916
00:36:24,160 --> 00:36:26,000
particle that is going

917
00:36:26,000 --> 00:36:27,680
different colors through time that just

918
00:36:27,680 --> 00:36:29,520
like converging to the top of this

919
00:36:29,520 --> 00:36:30,000
mountain

920
00:36:30,000 --> 00:36:33,599
diffusing like to the bottom of the bowl

921
00:36:33,599 --> 00:36:35,119
like a marble going to the bottom of a

922
00:36:35,119 --> 00:36:36,720
bowl

923
00:36:36,720 --> 00:36:39,200
and then that trajectory can be

924
00:36:39,200 --> 00:36:40,000
separated

925
00:36:40,000 --> 00:36:44,320
into this spiral or i mean this um

926
00:36:44,320 --> 00:36:47,839
oval the time irreversible component and

927
00:36:47,839 --> 00:36:49,680
then a time reversible component

928
00:36:49,680 --> 00:36:54,320
that has a much more direct trajectory

929
00:36:54,320 --> 00:36:57,760
and that was in the section with remark

930
00:36:57,760 --> 00:36:58,720
three one

931
00:36:58,720 --> 00:37:00,720
which is again related to the ido

932
00:37:00,720 --> 00:37:02,480
stochastic differential equation which i

933
00:37:02,480 --> 00:37:02,800
just

934
00:37:02,800 --> 00:37:05,839
i'm not too sure about um

935
00:37:05,839 --> 00:37:07,280
but they write when the dynamics are

936
00:37:07,280 --> 00:37:09,040
given by this edo stochastic

937
00:37:09,040 --> 00:37:10,560
differential equation

938
00:37:10,560 --> 00:37:12,640
a markov blanket of the steady state

939
00:37:12,640 --> 00:37:14,320
density does not

940
00:37:14,320 --> 00:37:16,400
necessarily imply that internal and

941
00:37:16,400 --> 00:37:17,680
external states cannot

942
00:37:17,680 --> 00:37:20,560
influence each other so that's i think

943
00:37:20,560 --> 00:37:22,000
kind of the interesting

944
00:37:22,000 --> 00:37:25,520
tension in question is how do certain

945
00:37:25,520 --> 00:37:27,680
mathematical definitions of conditional

946
00:37:27,680 --> 00:37:30,240
independence of blanket states

947
00:37:30,240 --> 00:37:33,440
separating internal external states how

948
00:37:33,440 --> 00:37:34,560
does that partition

949
00:37:34,560 --> 00:37:37,440
sometimes result in subsets or systems

950
00:37:37,440 --> 00:37:39,280
that don't influence each other

951
00:37:39,280 --> 00:37:42,320
versus systems that do so in the case of

952
00:37:42,320 --> 00:37:44,000
systems that don't influence

953
00:37:44,000 --> 00:37:46,320
each other i was thinking of like an

954
00:37:46,320 --> 00:37:48,160
empty bottle

955
00:37:48,160 --> 00:37:50,880
of air in a room of air like they're

956
00:37:50,880 --> 00:37:52,640
separated systems

957
00:37:52,640 --> 00:37:55,760
but they interact through the bottle

958
00:37:55,760 --> 00:37:57,760
so they could transfer heat for example

959
00:37:57,760 --> 00:37:59,520
through a hot

960
00:37:59,520 --> 00:38:01,839
bottle could transfer heat to the room

961
00:38:01,839 --> 00:38:04,079
but the systems would only interact

962
00:38:04,079 --> 00:38:05,520
conditioned on the temperature of the

963
00:38:05,520 --> 00:38:06,800
interface

964
00:38:06,800 --> 00:38:09,920
versus a person in a room

965
00:38:09,920 --> 00:38:11,680
could be planning or thinking about the

966
00:38:11,680 --> 00:38:13,520
external states

967
00:38:13,520 --> 00:38:16,800
so just how do we think about what kinds

968
00:38:16,800 --> 00:38:20,240
of systems are still having

969
00:38:20,240 --> 00:38:23,440
influence or a long-term implication

970
00:38:23,440 --> 00:38:26,400
for each other even after conditioned on

971
00:38:26,400 --> 00:38:28,480
the interfacing a certain way

972
00:38:28,480 --> 00:38:32,079
and then also just how does this example

973
00:38:32,079 --> 00:38:35,280
provided kind of

974
00:38:35,280 --> 00:38:39,760
show that that'd be good to walk through

975
00:38:39,760 --> 00:38:42,720
and the absence of reciprocal influences

976
00:38:42,720 --> 00:38:44,160
between two states

977
00:38:44,160 --> 00:38:47,280
in the drift sometimes but not always

978
00:38:47,280 --> 00:38:50,640
implies conditional independence

979
00:38:50,640 --> 00:38:53,920
okay going back to the main uh

980
00:38:53,920 --> 00:38:57,440
facts and figures in figure four there's

981
00:38:57,440 --> 00:39:01,359
now looking at this synchronization map

982
00:39:01,359 --> 00:39:02,960
and transition probabilities for

983
00:39:02,960 --> 00:39:05,839
processes at the gaussian steady state

984
00:39:05,839 --> 00:39:08,320
so on the left is we plot the

985
00:39:08,320 --> 00:39:10,880
synchronization map as in figure 2.

986
00:39:10,880 --> 00:39:12,720
only here the samples are drawn from

987
00:39:12,720 --> 00:39:14,960
trajectories of a diffusion process

988
00:39:14,960 --> 00:39:18,320
with a markov blanket so now it's

989
00:39:18,320 --> 00:39:21,920
a temporal process

990
00:39:22,960 --> 00:39:25,200
on the right panel there are the

991
00:39:25,200 --> 00:39:27,680
transition probabilities of that same

992
00:39:27,680 --> 00:39:31,359
diffusion process for the blanket state

993
00:39:31,359 --> 00:39:33,520
at two different times

994
00:39:33,520 --> 00:39:35,839
and this is called a joint distribution

995
00:39:35,839 --> 00:39:37,359
because there's two

996
00:39:37,359 --> 00:39:39,040
distributions that are being looked at

997
00:39:39,040 --> 00:39:41,200
jointly and

998
00:39:41,200 --> 00:39:43,760
if you kind of went to one side and

999
00:39:43,760 --> 00:39:45,359
looked through the cornfield one way

1000
00:39:45,359 --> 00:39:47,839
you'd see this gaussian

1001
00:39:47,839 --> 00:39:50,720
p of b sub s and if you looked at it the

1002
00:39:50,720 --> 00:39:52,400
other way you'd see

1003
00:39:52,400 --> 00:39:55,760
p of b through t

1004
00:39:55,760 --> 00:39:57,839
and uh then they write which is kind of

1005
00:39:57,839 --> 00:39:59,200
interesting

1006
00:39:59,200 --> 00:40:01,680
um this shows that in general processes

1007
00:40:01,680 --> 00:40:03,200
at a gaussian steady state are not

1008
00:40:03,200 --> 00:40:05,920
gaussian processes

1009
00:40:05,920 --> 00:40:08,160
so that was just like very i'm curious

1010
00:40:08,160 --> 00:40:10,160
about what that meant

1011
00:40:10,160 --> 00:40:12,960
in fact the ornstein olbeck process is

1012
00:40:12,960 --> 00:40:15,200
the only stationary diffusion process

1013
00:40:15,200 --> 00:40:17,359
that is a gaussian process so the

1014
00:40:17,359 --> 00:40:19,520
transition probabilities of nonlinear

1015
00:40:19,520 --> 00:40:21,520
diffusion processes are never

1016
00:40:21,520 --> 00:40:25,359
multivariate gaussians

1017
00:40:25,359 --> 00:40:26,720
not sure what that means but sounded

1018
00:40:26,720 --> 00:40:29,760
kind of interesting all right so then

1019
00:40:29,760 --> 00:40:33,200
uh from this sort of mapping between

1020
00:40:33,200 --> 00:40:35,839
internal and external states through

1021
00:40:35,839 --> 00:40:37,839
time the synchronization mapping

1022
00:40:37,839 --> 00:40:40,800
sigma they write in the section on

1023
00:40:40,800 --> 00:40:42,319
predictive processing

1024
00:40:42,319 --> 00:40:44,560
we can go further and associate to each

1025
00:40:44,560 --> 00:40:45,680
internal state

1026
00:40:45,680 --> 00:40:48,160
mu a probability distribution over

1027
00:40:48,160 --> 00:40:49,920
external states

1028
00:40:49,920 --> 00:40:52,640
such that each internal state encodes

1029
00:40:52,640 --> 00:40:53,680
beliefs about

1030
00:40:53,680 --> 00:40:56,960
external states so

1031
00:40:56,960 --> 00:40:59,359
now rather than just framing these as

1032
00:40:59,359 --> 00:41:01,280
two dynamical processes that

1033
00:41:01,280 --> 00:41:04,480
track one another like oh there's this

1034
00:41:04,480 --> 00:41:07,200
synchronization map between this random

1035
00:41:07,200 --> 00:41:07,839
variable

1036
00:41:07,839 --> 00:41:09,599
internally and this random variable

1037
00:41:09,599 --> 00:41:11,839
externally

1038
00:41:11,839 --> 00:41:14,319
they're going to frame this q

1039
00:41:14,319 --> 00:41:15,680
distribution

1040
00:41:15,680 --> 00:41:19,280
so q is going to be

1041
00:41:19,280 --> 00:41:22,640
a probability distribution inside of mu

1042
00:41:22,640 --> 00:41:25,200
that's over external states such that

1043
00:41:25,200 --> 00:41:26,800
each of those states encode beliefs

1044
00:41:26,800 --> 00:41:28,240
about external states so q

1045
00:41:28,240 --> 00:41:32,240
of internal states is about eta

1046
00:41:32,240 --> 00:41:34,960
and that's going to be a normal

1047
00:41:34,960 --> 00:41:36,960
distribution

1048
00:41:36,960 --> 00:41:40,800
with a mean of the actual external state

1049
00:41:40,800 --> 00:41:44,079
it's like mean and variance

1050
00:41:44,079 --> 00:41:48,079
um so it's eta and then sigma of mu

1051
00:41:48,079 --> 00:41:50,640
the mapping function comma variant so

1052
00:41:50,640 --> 00:41:51,599
here these two

1053
00:41:51,599 --> 00:41:54,960
are both what it's being uh

1054
00:41:54,960 --> 00:41:58,079
is being inferred is the the external

1055
00:41:58,079 --> 00:42:00,160
state and the mapping

1056
00:42:00,160 --> 00:42:01,920
and then there's the variance of the

1057
00:42:01,920 --> 00:42:04,960
precision on external states

1058
00:42:04,960 --> 00:42:09,119
and then um 3.4

1059
00:42:09,119 --> 00:42:11,359
is just giving a little bit more details

1060
00:42:11,359 --> 00:42:12,400
about how that

1061
00:42:12,400 --> 00:42:15,040
q is like this internal function where

1062
00:42:15,040 --> 00:42:16,160
the states of it

1063
00:42:16,160 --> 00:42:18,880
are reflecting beliefs about external

1064
00:42:18,880 --> 00:42:21,200
states

1065
00:42:21,200 --> 00:42:24,720
um and then there's a relationship to

1066
00:42:24,720 --> 00:42:26,720
how the internal states are conditioned

1067
00:42:26,720 --> 00:42:29,760
on blanket states

1068
00:42:29,760 --> 00:42:32,880
this was a um interesting remark that'd

1069
00:42:32,880 --> 00:42:33,680
be cool to

1070
00:42:33,680 --> 00:42:36,240
have people discuss would be uh when

1071
00:42:36,240 --> 00:42:37,119
they wrote

1072
00:42:37,119 --> 00:42:38,800
note a potential connection with

1073
00:42:38,800 --> 00:42:41,040
epistemic accounts of quantum mechanics

1074
00:42:41,040 --> 00:42:42,800
namely a world governed by classical

1075
00:42:42,800 --> 00:42:44,400
mechanics sigma

1076
00:42:44,400 --> 00:42:46,079
conditioned at zero or i don't know if

1077
00:42:46,079 --> 00:42:47,359
there's another way to read that symbol

1078
00:42:47,359 --> 00:42:49,440
with three lines

1079
00:42:49,440 --> 00:42:53,680
in 3.2 um not sure because in 3.2

1080
00:42:53,680 --> 00:42:56,160
i'm not sure if there was a sigma in

1081
00:42:56,160 --> 00:42:58,240
which each agent encodes gaussian

1082
00:42:58,240 --> 00:42:59,040
beliefs about

1083
00:42:59,040 --> 00:43:01,920
external states the could appear to the

1084
00:43:01,920 --> 00:43:03,680
agents as reproducing many features of

1085
00:43:03,680 --> 00:43:05,520
quantum mechanics

1086
00:43:05,520 --> 00:43:07,760
so this was just cool like what is the

1087
00:43:07,760 --> 00:43:09,359
relationship between the sigma

1088
00:43:09,359 --> 00:43:11,839
internal external mapping function and

1089
00:43:11,839 --> 00:43:12,960
then classical

1090
00:43:12,960 --> 00:43:16,240
versus quantum mechanics so maybe

1091
00:43:16,240 --> 00:43:17,599
classical systems are like

1092
00:43:17,599 --> 00:43:18,640
the ones where there's a clean

1093
00:43:18,640 --> 00:43:21,599
separation between the internal and the

1094
00:43:21,599 --> 00:43:22,960
external states

1095
00:43:22,960 --> 00:43:26,240
quantum states being ones that are more

1096
00:43:26,240 --> 00:43:29,359
uh with residual influence between

1097
00:43:29,359 --> 00:43:32,720
internal and external states

1098
00:43:32,880 --> 00:43:35,920
so returning to the um

1099
00:43:35,920 --> 00:43:38,960
predictive processing they

1100
00:43:38,960 --> 00:43:42,720
write that under that 3 4 so under this

1101
00:43:42,720 --> 00:43:45,280
implication of the q internal

1102
00:43:45,280 --> 00:43:47,119
distribution

1103
00:43:47,119 --> 00:43:49,760
expected internal states are the unique

1104
00:43:49,760 --> 00:43:52,839
minimizer of a callback liblar

1105
00:43:52,839 --> 00:43:55,839
divergence so that mu through time

1106
00:43:55,839 --> 00:43:57,760
internal states through time are the

1107
00:43:57,760 --> 00:43:59,599
minimization the argument

1108
00:43:59,599 --> 00:44:03,280
over the mu states internal states

1109
00:44:03,280 --> 00:44:06,839
of the d kl the kl divergence

1110
00:44:06,839 --> 00:44:09,839
of

1111
00:44:10,160 --> 00:44:12,960
the internal belief distribution q about

1112
00:44:12,960 --> 00:44:14,240
external states

1113
00:44:14,240 --> 00:44:17,440
q of eta double line

1114
00:44:17,440 --> 00:44:20,000
divergence between the objective

1115
00:44:20,000 --> 00:44:21,760
distribution

1116
00:44:21,760 --> 00:44:24,319
of external states conditioned on

1117
00:44:24,319 --> 00:44:25,920
blanket states

1118
00:44:25,920 --> 00:44:28,880
so if that q distribution can converge

1119
00:44:28,880 --> 00:44:30,160
to the p

1120
00:44:30,160 --> 00:44:34,400
then that is being minimized effectively

1121
00:44:34,400 --> 00:44:36,480
this measures the discrepancy between

1122
00:44:36,480 --> 00:44:39,119
beliefs about the external world

1123
00:44:39,119 --> 00:44:42,000
q mu sub mu of eta and the posterior

1124
00:44:42,000 --> 00:44:42,960
distribution over

1125
00:44:42,960 --> 00:44:46,160
external variables computing the kl

1126
00:44:46,160 --> 00:44:47,440
divergence

1127
00:44:47,440 --> 00:44:51,760
they're going to obtain this 3.5

1128
00:44:51,760 --> 00:44:54,880
and um that's

1129
00:44:54,880 --> 00:44:59,119
argument so it's minimizing

1130
00:44:59,119 --> 00:45:02,839
the differential uh between sigma's

1131
00:45:02,839 --> 00:45:04,240
prediction

1132
00:45:04,240 --> 00:45:07,520
so that's sigma of mu minus

1133
00:45:07,520 --> 00:45:10,400
the actual external states through time

1134
00:45:10,400 --> 00:45:11,200
sigma

1135
00:45:11,200 --> 00:45:12,640
mapping function of internal states

1136
00:45:12,640 --> 00:45:15,040
minus the actual state

1137
00:45:15,040 --> 00:45:18,880
multiplied by so pi

1138
00:45:18,880 --> 00:45:23,599
of the precision matrix of eta

1139
00:45:23,599 --> 00:45:27,040
relating to how wrong

1140
00:45:27,040 --> 00:45:30,560
that differential is so that's kind of

1141
00:45:30,560 --> 00:45:31,280
an interesting

1142
00:45:31,280 --> 00:45:34,960
framing um and then they write that

1143
00:45:34,960 --> 00:45:38,480
the right hand side of 3.5 that equation

1144
00:45:38,480 --> 00:45:40,160
is commonly known as the squared

1145
00:45:40,160 --> 00:45:42,160
precision weighted prediction error

1146
00:45:42,160 --> 00:45:43,760
which is the discrepancy between the

1147
00:45:43,760 --> 00:45:45,440
prediction and the expected state of the

1148
00:45:45,440 --> 00:45:46,880
environment

1149
00:45:46,880 --> 00:45:48,240
and it's weighted with a precision

1150
00:45:48,240 --> 00:45:50,400
matrix that derives from the steady

1151
00:45:50,400 --> 00:45:51,680
state density

1152
00:45:51,680 --> 00:45:53,440
this equation is formally similar to

1153
00:45:53,440 --> 00:45:54,880
that found in predictive coding

1154
00:45:54,880 --> 00:45:57,040
formulations of biological function

1155
00:45:57,040 --> 00:45:59,119
which stipulate that organisms minimize

1156
00:45:59,119 --> 00:46:00,319
prediction errors

1157
00:46:00,319 --> 00:46:02,960
and in doing so optimize their beliefs

1158
00:46:02,960 --> 00:46:04,880
to match the distribution of external

1159
00:46:04,880 --> 00:46:06,880
states

1160
00:46:06,880 --> 00:46:10,319
so that's pretty cool and we can talk

1161
00:46:10,319 --> 00:46:11,440
more about it but

1162
00:46:11,440 --> 00:46:14,640
it kind of reminds me of this

1163
00:46:14,640 --> 00:46:17,280
uncertainty reduction imperative rather

1164
00:46:17,280 --> 00:46:18,240
than reward

1165
00:46:18,240 --> 00:46:20,640
maximization imperative it's kind of

1166
00:46:20,640 --> 00:46:22,000
like saying

1167
00:46:22,000 --> 00:46:24,240
if the organisms are minimizing their

1168
00:46:24,240 --> 00:46:25,920
prediction errors

1169
00:46:25,920 --> 00:46:28,720
not maximizing the reward they will

1170
00:46:28,720 --> 00:46:30,480
optimize their beliefs to match the

1171
00:46:30,480 --> 00:46:33,040
distribution of external states

1172
00:46:33,040 --> 00:46:36,720
so maybe that's related to that

1173
00:46:36,720 --> 00:46:40,560
variance reduction imperative

1174
00:46:41,599 --> 00:46:45,359
um so we had the uh

1175
00:46:45,359 --> 00:46:49,040
predictive processing section and then

1176
00:46:49,040 --> 00:46:52,560
there's one more layer that gets added

1177
00:46:52,560 --> 00:46:53,200
on

1178
00:46:53,200 --> 00:46:56,160
so from the markov blanket to making it

1179
00:46:56,160 --> 00:46:57,040
a bayesian

1180
00:46:57,040 --> 00:47:01,760
markov blanket happening through time

1181
00:47:01,760 --> 00:47:05,200
to introducing this q distribution

1182
00:47:05,200 --> 00:47:11,839
that's a special type of internal state

1183
00:47:12,079 --> 00:47:15,359
they write in the next section we can go

1184
00:47:15,359 --> 00:47:16,880
further and associate

1185
00:47:16,880 --> 00:47:18,960
expected internal states to the solution

1186
00:47:18,960 --> 00:47:21,119
to the classical variational inference

1187
00:47:21,119 --> 00:47:22,800
problem from statistical machine

1188
00:47:22,800 --> 00:47:23,520
learning

1189
00:47:23,520 --> 00:47:26,640
and theoretical neurobiology so

1190
00:47:26,640 --> 00:47:28,880
it's going to be that q function is

1191
00:47:28,880 --> 00:47:30,640
going to be a very specific kind of q

1192
00:47:30,640 --> 00:47:31,359
function

1193
00:47:31,359 --> 00:47:34,720
so not all systems are going to be

1194
00:47:34,720 --> 00:47:37,760
doing this subtype of variational

1195
00:47:37,760 --> 00:47:38,400
inference or

1196
00:47:38,400 --> 00:47:41,760
maybe they are um that is something we

1197
00:47:41,760 --> 00:47:42,880
could discuss

1198
00:47:42,880 --> 00:47:46,000
but we can finesse

1199
00:47:46,000 --> 00:47:49,119
that mapping function between

1200
00:47:49,119 --> 00:47:52,319
the internal and external states and

1201
00:47:52,319 --> 00:47:54,880
what exactly the internal states are

1202
00:47:54,880 --> 00:47:55,520
because if

1203
00:47:55,520 --> 00:47:57,359
you can co-design both the internal

1204
00:47:57,359 --> 00:47:58,960
states and the mapping

1205
00:47:58,960 --> 00:48:01,599
then you have a lot of degrees of

1206
00:48:01,599 --> 00:48:02,160
freedom

1207
00:48:02,160 --> 00:48:05,599
in mapping on to external states

1208
00:48:05,599 --> 00:48:08,559
even as they change so now we're going

1209
00:48:08,559 --> 00:48:08,960
to

1210
00:48:08,960 --> 00:48:12,079
do a really sub-special

1211
00:48:12,079 --> 00:48:13,920
phrasing maybe it's a more general one

1212
00:48:13,920 --> 00:48:15,599
but just one specific phrasing

1213
00:48:15,599 --> 00:48:17,520
of how the internal states could map

1214
00:48:17,520 --> 00:48:19,040
onto the external states

1215
00:48:19,040 --> 00:48:21,119
and that's going to be as expected

1216
00:48:21,119 --> 00:48:22,160
internal states

1217
00:48:22,160 --> 00:48:24,160
as the unique minimizers of a free

1218
00:48:24,160 --> 00:48:25,359
energy functional

1219
00:48:25,359 --> 00:48:28,880
i.e in evidence bound so now there's a

1220
00:48:28,880 --> 00:48:31,599
f function over blanket and internal

1221
00:48:31,599 --> 00:48:33,359
states through time

1222
00:48:33,359 --> 00:48:36,960
and that f

1223
00:48:36,960 --> 00:48:40,000
function is going to consist of two

1224
00:48:40,000 --> 00:48:43,760
elements which is like a divergence term

1225
00:48:43,760 --> 00:48:47,280
that we saw before with a divergence

1226
00:48:47,280 --> 00:48:48,880
between

1227
00:48:48,880 --> 00:48:52,960
q's internal estimate of external states

1228
00:48:52,960 --> 00:48:55,359
divergence and actual external states

1229
00:48:55,359 --> 00:48:57,359
conditional blanket states

1230
00:48:57,359 --> 00:49:01,280
minus the uh the evidence

1231
00:49:01,280 --> 00:49:05,520
term and then that can be

1232
00:49:05,520 --> 00:49:07,839
equivalent to this energy minus entropy

1233
00:49:07,839 --> 00:49:09,440
term

1234
00:49:09,440 --> 00:49:11,440
so that last line expresses the free

1235
00:49:11,440 --> 00:49:13,680
energy as a difference between energy

1236
00:49:13,680 --> 00:49:17,280
and entropy pretty cool energy or

1237
00:49:17,280 --> 00:49:19,119
accuracy measures to what extent

1238
00:49:19,119 --> 00:49:21,119
predicted external states are close to

1239
00:49:21,119 --> 00:49:21,599
the true

1240
00:49:21,599 --> 00:49:24,160
external states while entropy penalizes

1241
00:49:24,160 --> 00:49:26,800
beliefs that are overly precise

1242
00:49:26,800 --> 00:49:30,079
so that's cool like energy is locking in

1243
00:49:30,079 --> 00:49:33,680
on the good solution that's like

1244
00:49:33,680 --> 00:49:36,640
maybe the component that is going up the

1245
00:49:36,640 --> 00:49:37,760
hill

1246
00:49:37,760 --> 00:49:40,800
and then entropy is keeping things

1247
00:49:40,800 --> 00:49:43,520
away from just going up the hill and

1248
00:49:43,520 --> 00:49:45,760
keeping this other component in

1249
00:49:45,760 --> 00:49:49,280
but if um

1250
00:49:49,280 --> 00:49:51,520
entropy overwhelms the entropy uh the

1251
00:49:51,520 --> 00:49:53,359
energy then the solution

1252
00:49:53,359 --> 00:49:57,119
will not kind of fit the situation

1253
00:49:57,119 --> 00:50:00,160
so at first sight

1254
00:50:00,160 --> 00:50:01,680
variational inference and predictive

1255
00:50:01,680 --> 00:50:02,960
processing are solely useful to

1256
00:50:02,960 --> 00:50:04,720
characterize the average internal state

1257
00:50:04,720 --> 00:50:07,599
given blanket states at steady state

1258
00:50:07,599 --> 00:50:09,680
it is then surprising to see that the

1259
00:50:09,680 --> 00:50:11,599
free energy says a great deal about a

1260
00:50:11,599 --> 00:50:12,960
system's expected

1261
00:50:12,960 --> 00:50:15,040
trajectories as it relaxes the steady

1262
00:50:15,040 --> 00:50:16,319
state

1263
00:50:16,319 --> 00:50:18,480
pretty interesting so here's how they

1264
00:50:18,480 --> 00:50:21,520
kind of show that

1265
00:50:21,680 --> 00:50:24,240
figure five is using that free energy

1266
00:50:24,240 --> 00:50:25,280
minimizing

1267
00:50:25,280 --> 00:50:28,720
framework to look at variational

1268
00:50:28,720 --> 00:50:32,160
inference and predictive processing

1269
00:50:32,160 --> 00:50:34,800
so the highlighted part says the figure

1270
00:50:34,800 --> 00:50:36,400
illustrates the system's behavior

1271
00:50:36,400 --> 00:50:38,640
after experiencing a surprising blanket

1272
00:50:38,640 --> 00:50:39,520
state

1273
00:50:39,520 --> 00:50:42,200
so kind of like a perturbation this is a

1274
00:50:42,200 --> 00:50:44,720
multi-dimensional ornstein olbeck ou

1275
00:50:44,720 --> 00:50:47,599
process with two external blanket and

1276
00:50:47,599 --> 00:50:49,359
internal variables

1277
00:50:49,359 --> 00:50:51,359
initialized at the steady state density

1278
00:50:51,359 --> 00:50:53,280
conditioned on an improbable blanket

1279
00:50:53,280 --> 00:50:54,079
state

1280
00:50:54,079 --> 00:50:56,319
which was given at the initial time

1281
00:50:56,319 --> 00:50:58,319
actual distribution of x and b

1282
00:50:58,319 --> 00:51:01,359
at time 0. and

1283
00:51:01,359 --> 00:51:04,559
on the left top left quadrant

1284
00:51:04,559 --> 00:51:08,000
is sort of this red to blue gradient

1285
00:51:08,000 --> 00:51:09,599
of free energy so it's kind of high

1286
00:51:09,599 --> 00:51:11,200
elevation to low elevation

1287
00:51:11,200 --> 00:51:13,040
and through time the blanket stage just

1288
00:51:13,040 --> 00:51:15,839
converged down to the bottom of the bowl

1289
00:51:15,839 --> 00:51:19,280
so that's the free energy minimization

1290
00:51:19,280 --> 00:51:22,559
in action the upper right is the is the

1291
00:51:22,559 --> 00:51:23,440
free energy

1292
00:51:23,440 --> 00:51:25,040
over time averaged over multiple

1293
00:51:25,040 --> 00:51:26,960
trajectories so it starts out

1294
00:51:26,960 --> 00:51:29,760
really high and then it kind of rolls

1295
00:51:29,760 --> 00:51:31,359
down and it converges to

1296
00:51:31,359 --> 00:51:37,040
this low level at 40 time points

1297
00:51:37,040 --> 00:51:40,559
the lower left is showing

1298
00:51:40,559 --> 00:51:44,880
this uh predictive processing

1299
00:51:44,880 --> 00:51:48,720
framing of the q distribution

1300
00:51:48,720 --> 00:51:52,480
versus the actual distribution and said

1301
00:51:52,480 --> 00:51:55,440
at steady state from time step about 100

1302
00:51:55,440 --> 00:51:58,720
the predictions become accurate

1303
00:51:58,720 --> 00:52:01,920
so that's showing how for the estimate

1304
00:52:01,920 --> 00:52:05,040
of the parameter converges to the

1305
00:52:05,040 --> 00:52:05,920
accurate

1306
00:52:05,920 --> 00:52:07,599
external states under their simulation

1307
00:52:07,599 --> 00:52:09,359
be cool to do a walkthrough

1308
00:52:09,359 --> 00:52:12,880
and then on the bottom right is looking

1309
00:52:12,880 --> 00:52:16,400
at the error prediction errors

1310
00:52:16,400 --> 00:52:20,880
the covariance of so the two co errors

1311
00:52:20,880 --> 00:52:23,040
um the evolution of precision weighted

1312
00:52:23,040 --> 00:52:24,480
prediction errors

1313
00:52:24,480 --> 00:52:26,559
over time these are normally distributed

1314
00:52:26,559 --> 00:52:30,160
with zero mean at steady state

1315
00:52:30,720 --> 00:52:33,760
uh figure six

1316
00:52:33,760 --> 00:52:36,960
is uh

1317
00:52:36,960 --> 00:52:40,160
maybe i didn't change not sure exactly

1318
00:52:40,160 --> 00:52:41,280
it's a similar

1319
00:52:41,280 --> 00:52:42,800
figure it has a little bit of

1320
00:52:42,800 --> 00:52:44,839
differences

1321
00:52:44,839 --> 00:52:47,599
uh again showing the predictive

1322
00:52:47,599 --> 00:52:48,400
processing

1323
00:52:48,400 --> 00:52:51,760
lock in on a free energy minimizing

1324
00:52:51,760 --> 00:52:53,200
process

1325
00:52:53,200 --> 00:52:55,760
showing the average free energy

1326
00:52:55,760 --> 00:52:56,960
initially having a

1327
00:52:56,960 --> 00:52:58,400
slight increase maybe and then just

1328
00:52:58,400 --> 00:53:00,079
decreasing through time

1329
00:53:00,079 --> 00:53:03,280
and then also just showing that the um

1330
00:53:03,280 --> 00:53:06,480
the relationship

1331
00:53:06,480 --> 00:53:09,220
of the covariance um

1332
00:53:09,220 --> 00:53:10,480
[Music]

1333
00:53:10,480 --> 00:53:13,359
was raised up from zero and then started

1334
00:53:13,359 --> 00:53:15,040
converging back to zero

1335
00:53:15,040 --> 00:53:18,240
so just cool figures but cool to see

1336
00:53:18,240 --> 00:53:21,520
what other people would think about them

1337
00:53:22,319 --> 00:53:24,720
in figure four or i'm sorry section four

1338
00:53:24,720 --> 00:53:25,599
we get to

1339
00:53:25,599 --> 00:53:28,000
active inference and stochastic control

1340
00:53:28,000 --> 00:53:29,760
so they write in order to model agents

1341
00:53:29,760 --> 00:53:31,359
that interact with their environment we

1342
00:53:31,359 --> 00:53:33,119
now partition blanket states into

1343
00:53:33,119 --> 00:53:35,440
sensory and active states

1344
00:53:35,440 --> 00:53:37,520
so for active everything that we've

1345
00:53:37,520 --> 00:53:38,960
talked about before is like an

1346
00:53:38,960 --> 00:53:40,480
undirected

1347
00:53:40,480 --> 00:53:43,839
bayesian graph um

1348
00:53:43,839 --> 00:53:47,760
it's not using that frist and blanket

1349
00:53:47,760 --> 00:53:50,319
separation so that's where we're gonna

1350
00:53:50,319 --> 00:53:52,240
be bringing in a lot of other

1351
00:53:52,240 --> 00:53:56,000
uh cool formalisms and

1352
00:53:56,000 --> 00:53:59,839
ideas so let's go from that sort of

1353
00:53:59,839 --> 00:54:02,800
blanket one type of fiber in the blanket

1354
00:54:02,800 --> 00:54:03,200
to

1355
00:54:03,200 --> 00:54:06,480
two now uh in order to model agents to

1356
00:54:06,480 --> 00:54:08,000
interact with their environment we now

1357
00:54:08,000 --> 00:54:09,920
partition blanket states into sensory

1358
00:54:09,920 --> 00:54:11,680
and active states

1359
00:54:11,680 --> 00:54:14,079
so the blanket state b of t blanket

1360
00:54:14,079 --> 00:54:15,200
through c

1361
00:54:15,200 --> 00:54:18,640
is now two subsets of sensory

1362
00:54:18,640 --> 00:54:21,760
and action states through time so now

1363
00:54:21,760 --> 00:54:23,040
that whole

1364
00:54:23,040 --> 00:54:24,640
tuple the whole set that you need to

1365
00:54:24,640 --> 00:54:27,200
infer the four kinds of states are

1366
00:54:27,200 --> 00:54:30,559
external sense action and internal

1367
00:54:30,559 --> 00:54:34,000
eta s-a-u yeah

1368
00:54:34,000 --> 00:54:36,160
and now that previous example of the

1369
00:54:36,160 --> 00:54:38,559
bacillus so here we had

1370
00:54:38,559 --> 00:54:40,880
just one we had external and internal

1371
00:54:40,880 --> 00:54:43,680
states mediated by one kind of node

1372
00:54:43,680 --> 00:54:46,880
and now the external states are coupled

1373
00:54:46,880 --> 00:54:48,640
to the sensory states

1374
00:54:48,640 --> 00:54:51,440
that's s of t and sensory states are

1375
00:54:51,440 --> 00:54:53,280
coupled to internal states

1376
00:54:53,280 --> 00:54:54,880
internal states are coupled to action

1377
00:54:54,880 --> 00:54:57,280
states and actions connect back to

1378
00:54:57,280 --> 00:54:59,040
external states also sense and action

1379
00:54:59,040 --> 00:55:00,559
are connected to each other

1380
00:55:00,559 --> 00:55:03,599
but i wonder if that part is needed or

1381
00:55:03,599 --> 00:55:07,119
i'm always wondering what topologies

1382
00:55:07,119 --> 00:55:08,400
of connectedness different

1383
00:55:08,400 --> 00:55:10,160
functionalities arise from

1384
00:55:10,160 --> 00:55:14,240
and uh miguel aguilera's

1385
00:55:14,240 --> 00:55:18,799
paper and recent uh guest stream

1386
00:55:18,799 --> 00:55:23,520
speak to that so

1387
00:55:23,520 --> 00:55:26,000
we take that dynamic markov blanket

1388
00:55:26,000 --> 00:55:28,559
model from the previous sections and now

1389
00:55:28,559 --> 00:55:32,400
split the blanket states into sense in

1390
00:55:32,839 --> 00:55:35,119
action

1391
00:55:35,119 --> 00:55:38,160
that was this piece here

1392
00:55:38,160 --> 00:55:40,319
now then they write intuitively in

1393
00:55:40,319 --> 00:55:42,160
agents actions and internal states

1394
00:55:42,160 --> 00:55:42,799
depend

1395
00:55:42,799 --> 00:55:44,960
upon its sensations therefore we are

1396
00:55:44,960 --> 00:55:45,920
interested

1397
00:55:45,920 --> 00:55:48,480
in characterizing autonomous i.e active

1398
00:55:48,480 --> 00:55:49,920
and internal

1399
00:55:49,920 --> 00:55:53,280
so we can't control our senses directly

1400
00:55:53,280 --> 00:55:55,839
but we can control internal states and

1401
00:55:55,839 --> 00:55:56,880
active states

1402
00:55:56,880 --> 00:55:59,040
so those two states we're going to think

1403
00:55:59,040 --> 00:56:00,720
about that pair of notes

1404
00:56:00,720 --> 00:56:04,240
given sensory states so

1405
00:56:04,240 --> 00:56:06,400
that is the following free energy

1406
00:56:06,400 --> 00:56:07,520
equation

1407
00:56:07,520 --> 00:56:09,839
that was brought up earlier so taking

1408
00:56:09,839 --> 00:56:11,040
that free energy

1409
00:56:11,040 --> 00:56:13,920
minimizing perspective on the

1410
00:56:13,920 --> 00:56:15,359
distribution of mu

1411
00:56:15,359 --> 00:56:17,280
internal states and blanket states as a

1412
00:56:17,280 --> 00:56:18,559
whole b

1413
00:56:18,559 --> 00:56:22,799
before we introduce the split here then

1414
00:56:22,799 --> 00:56:26,799
do a similar free energy equation

1415
00:56:26,799 --> 00:56:30,000
with three variables on

1416
00:56:30,000 --> 00:56:34,480
the sensory action and internal states

1417
00:56:34,480 --> 00:56:37,680
which is just another way of saying the

1418
00:56:37,680 --> 00:56:38,880
blanket states

1419
00:56:38,880 --> 00:56:42,079
and the internal states mu

1420
00:56:42,079 --> 00:56:45,359
and then etc etc more details that

1421
00:56:45,359 --> 00:56:46,079
people can

1422
00:56:46,079 --> 00:56:48,960
explain if they know better but the

1423
00:56:48,960 --> 00:56:50,079
result

1424
00:56:50,079 --> 00:56:53,440
that um comes out

1425
00:56:53,440 --> 00:56:55,920
relates to action so it'd be cool to

1426
00:56:55,920 --> 00:56:57,920
learn more about what this equation

1427
00:56:57,920 --> 00:56:58,960
means

1428
00:56:58,960 --> 00:57:00,799
but then they write this is known as

1429
00:57:00,799 --> 00:57:02,559
active inference because expected

1430
00:57:02,559 --> 00:57:05,760
autonomous states minimize free energy

1431
00:57:05,760 --> 00:57:07,200
crucially active inference is a

1432
00:57:07,200 --> 00:57:09,040
well-known framework to describe and

1433
00:57:09,040 --> 00:57:10,559
generate adaptive behavior in

1434
00:57:10,559 --> 00:57:12,160
neuroscience machine learning and

1435
00:57:12,160 --> 00:57:13,280
robotics

1436
00:57:13,280 --> 00:57:17,760
see figure eight so

1437
00:57:17,839 --> 00:57:20,960
figure eight is a similar

1438
00:57:20,960 --> 00:57:24,839
diagram to we had before

1439
00:57:24,839 --> 00:57:27,920
but now it's an active inference

1440
00:57:27,920 --> 00:57:29,920
agent rather than just the free energy

1441
00:57:29,920 --> 00:57:31,040
minimizer

1442
00:57:31,040 --> 00:57:33,440
of the previous framing and then they

1443
00:57:33,440 --> 00:57:35,119
write

1444
00:57:35,119 --> 00:57:37,200
the figure illustrates a system's

1445
00:57:37,200 --> 00:57:39,200
behavior after experiencing a surprising

1446
00:57:39,200 --> 00:57:40,400
sensory state

1447
00:57:40,400 --> 00:57:42,240
averaging internal variables for any

1448
00:57:42,240 --> 00:57:44,400
blanket state this is an ornstein olbeck

1449
00:57:44,400 --> 00:57:45,040
process

1450
00:57:45,040 --> 00:57:48,000
with two external one sensory one active

1451
00:57:48,000 --> 00:57:49,599
and two internal variables

1452
00:57:49,599 --> 00:57:51,599
initialized at steady state density

1453
00:57:51,599 --> 00:57:53,440
conditioned upon an improbable sensory

1454
00:57:53,440 --> 00:57:55,760
state

1455
00:57:55,760 --> 00:57:59,760
and also one pattern that they found was

1456
00:57:59,760 --> 00:58:00,480
that

1457
00:58:00,480 --> 00:58:02,960
the free energy minimization here it's

1458
00:58:02,960 --> 00:58:04,799
relatively monotonic

1459
00:58:04,799 --> 00:58:08,000
it kind of doesn't ever bump back

1460
00:58:08,000 --> 00:58:12,160
up it just goes down or stays the same

1461
00:58:12,160 --> 00:58:14,720
but then it was kind of interesting they

1462
00:58:14,720 --> 00:58:15,599
said

1463
00:58:15,599 --> 00:58:17,440
we plot the free energy of the expected

1464
00:58:17,440 --> 00:58:19,359
internal state averaged over multiple

1465
00:58:19,359 --> 00:58:20,480
trajectories

1466
00:58:20,480 --> 00:58:23,680
so this is not just one aberrant run

1467
00:58:23,680 --> 00:58:27,040
in this example or maybe this is just

1468
00:58:27,040 --> 00:58:27,760
one example

1469
00:58:27,760 --> 00:58:30,160
but they wrote the average free energy

1470
00:58:30,160 --> 00:58:32,079
does not decrease monotonically

1471
00:58:32,079 --> 00:58:35,200
see figure five for an explanation and

1472
00:58:35,200 --> 00:58:37,520
then um

1473
00:58:37,520 --> 00:58:39,359
maybe we can learn more about that but

1474
00:58:39,359 --> 00:58:41,599
that was kind of cool

1475
00:58:41,599 --> 00:58:44,960
okay they

1476
00:58:44,960 --> 00:58:48,160
continue on and write that any mean

1477
00:58:48,160 --> 00:58:50,400
stationary mean zero stationary gaussian

1478
00:58:50,400 --> 00:58:52,400
process with exponentially decaying auto

1479
00:58:52,400 --> 00:58:54,079
covariance function

1480
00:58:54,079 --> 00:58:56,079
so it resembles itself less and less

1481
00:58:56,079 --> 00:58:57,839
through time

1482
00:58:57,839 --> 00:59:01,040
is an ornstein obec process which is

1483
00:59:01,040 --> 00:59:03,119
kind of cool because in phylogenetics we

1484
00:59:03,119 --> 00:59:04,880
sometimes would use this

1485
00:59:04,880 --> 00:59:07,119
for let's just say the average femur

1486
00:59:07,119 --> 00:59:08,160
length of

1487
00:59:08,160 --> 00:59:11,680
some mammal and then you would be

1488
00:59:11,680 --> 00:59:12,720
inferring a model

1489
00:59:12,720 --> 00:59:15,119
that had an average value so it's kind

1490
00:59:15,119 --> 00:59:15,760
of like a

1491
00:59:15,760 --> 00:59:18,160
peg and then like a tether so it's like

1492
00:59:18,160 --> 00:59:19,920
a diffusion term

1493
00:59:19,920 --> 00:59:23,440
and then a mean so just a mean

1494
00:59:23,440 --> 00:59:25,440
and a variance that drift through time

1495
00:59:25,440 --> 00:59:27,440
is like the orangeteen olbeck or the oh

1496
00:59:27,440 --> 00:59:28,079
you

1497
00:59:28,079 --> 00:59:32,319
process sometimes known as dub's theorem

1498
00:59:32,319 --> 00:59:37,440
so those kinds of processes which

1499
00:59:37,440 --> 00:59:39,520
are apparently general enough to be

1500
00:59:39,520 --> 00:59:40,559
really good

1501
00:59:40,559 --> 00:59:43,200
model systems for studying math i guess

1502
00:59:43,200 --> 00:59:44,839
thus if

1503
00:59:44,839 --> 00:59:48,079
c equals a finite sum of exponentially

1504
00:59:48,079 --> 00:59:49,520
decaying functions

1505
00:59:49,520 --> 00:59:51,920
we can express s of t the state's

1506
00:59:51,920 --> 00:59:53,119
sensory states

1507
00:59:53,119 --> 00:59:55,760
as a linear function of several nested

1508
00:59:55,760 --> 00:59:57,200
ou processes

1509
00:59:57,200 --> 00:59:59,119
i.e an integrator chain from control

1510
00:59:59,119 --> 01:00:00,799
theory

1511
01:00:00,799 --> 01:00:02,880
so the integrator chain was kind of a

1512
01:00:02,880 --> 01:00:05,680
cool idea and

1513
01:00:05,680 --> 01:00:07,440
we'll talk about maybe applications of

1514
01:00:07,440 --> 01:00:09,520
integrator chain in a few slides

1515
01:00:09,520 --> 01:00:12,240
but just to continue with the math that

1516
01:00:12,240 --> 01:00:12,640
they

1517
01:00:12,640 --> 01:00:16,400
have so there's this um

1518
01:00:16,400 --> 01:00:18,400
s of t states through time sensory

1519
01:00:18,400 --> 01:00:19,839
states is going to be this f

1520
01:00:19,839 --> 01:00:23,680
function and then there's these um

1521
01:00:23,680 --> 01:00:28,160
d these these kind of similar

1522
01:00:28,160 --> 01:00:32,319
d equations so it says in this example

1523
01:00:32,319 --> 01:00:35,119
f and f sub i are suitably chosen linear

1524
01:00:35,119 --> 01:00:35,920
functions

1525
01:00:35,920 --> 01:00:37,599
not sure what the pronunciation is but

1526
01:00:37,599 --> 01:00:39,839
the squiggle are matrices

1527
01:00:39,839 --> 01:00:43,040
and w are standard brownian motion

1528
01:00:43,040 --> 01:00:45,040
thus we can see sensory states through

1529
01:00:45,040 --> 01:00:47,440
time s t as the output of a continuous

1530
01:00:47,440 --> 01:00:49,119
time hidden markov model

1531
01:00:49,119 --> 01:00:53,920
whose hidden states s of t superscript i

1532
01:00:53,920 --> 01:00:56,640
encode various orders of motion position

1533
01:00:56,640 --> 01:00:57,359
velocity

1534
01:00:57,359 --> 01:01:00,000
jerk etc these are known as generalized

1535
01:01:00,000 --> 01:01:01,839
coordinates of motion in the bayesian

1536
01:01:01,839 --> 01:01:05,119
filtering literature which we'll look at

1537
01:01:05,119 --> 01:01:07,440
graphically in figure 9

1538
01:01:07,440 --> 01:01:09,680
and more generally the state process s

1539
01:01:09,680 --> 01:01:10,720
of t and a function

1540
01:01:10,720 --> 01:01:12,640
f need not be linear which enables to

1541
01:01:12,640 --> 01:01:13,920
realize

1542
01:01:13,920 --> 01:01:16,799
non-linear non-gaussian processes sst

1543
01:01:16,799 --> 01:01:18,640
technically this follows as ornstein

1544
01:01:18,640 --> 01:01:20,960
obec processes are the only stationary

1545
01:01:20,960 --> 01:01:22,880
gaussian markov processes yet we

1546
01:01:22,880 --> 01:01:24,160
emphasize that stochastic

1547
01:01:24,160 --> 01:01:26,000
realization is not as well developed in

1548
01:01:26,000 --> 01:01:28,799
the general case

1549
01:01:28,960 --> 01:01:32,559
so this is um in a way saying

1550
01:01:32,559 --> 01:01:34,079
that we're going to have like the

1551
01:01:34,079 --> 01:01:35,839
position of the ball

1552
01:01:35,839 --> 01:01:38,400
is the sensory data that's like the

1553
01:01:38,400 --> 01:01:39,599
first pass

1554
01:01:39,599 --> 01:01:41,440
um of where the ball is that's the

1555
01:01:41,440 --> 01:01:43,520
measurement that's the sensory data

1556
01:01:43,520 --> 01:01:46,079
then there's the variance and then

1557
01:01:46,079 --> 01:01:47,040
there's the second

1558
01:01:47,040 --> 01:01:50,880
derivative of that statistical moment

1559
01:01:50,880 --> 01:01:52,400
and so if the variance is equal through

1560
01:01:52,400 --> 01:01:54,000
time then you can just integrate away

1561
01:01:54,000 --> 01:01:55,440
and the higher levels are zero and

1562
01:01:55,440 --> 01:01:57,200
you've kind of locked on to the pattern

1563
01:01:57,200 --> 01:01:59,200
after just one or two levels

1564
01:01:59,200 --> 01:02:02,240
but there's other distributions where as

1565
01:02:02,240 --> 01:02:03,839
you go to higher and higher

1566
01:02:03,839 --> 01:02:07,520
distribution uh higher moments

1567
01:02:07,520 --> 01:02:09,359
there's just more or different

1568
01:02:09,359 --> 01:02:10,799
information

1569
01:02:10,799 --> 01:02:13,280
so there's this concept of the

1570
01:02:13,280 --> 01:02:14,640
integrator chain

1571
01:02:14,640 --> 01:02:18,160
where these relationships of equations

1572
01:02:18,160 --> 01:02:18,960
are all

1573
01:02:18,960 --> 01:02:20,960
integrals or derivatives of each other

1574
01:02:20,960 --> 01:02:22,799
which are kind of like going up or down

1575
01:02:22,799 --> 01:02:25,599
in this rows of equations and then this

1576
01:02:25,599 --> 01:02:26,480
helps

1577
01:02:26,480 --> 01:02:29,520
use gaussian type mathematics like the

1578
01:02:29,520 --> 01:02:30,160
ou

1579
01:02:30,160 --> 01:02:32,880
stochastic process where a lot of the

1580
01:02:32,880 --> 01:02:34,720
math is clean

1581
01:02:34,720 --> 01:02:38,240
it allows you to apply these

1582
01:02:38,240 --> 01:02:41,760
systems of equations of well-behaved

1583
01:02:41,760 --> 01:02:45,760
types oh you to model highly non-linear

1584
01:02:45,760 --> 01:02:47,440
systems so

1585
01:02:47,440 --> 01:02:49,839
this was related to some interesting

1586
01:02:49,839 --> 01:02:50,559
discussions

1587
01:02:50,559 --> 01:02:54,160
um uh i i will look forward to hearing

1588
01:02:54,160 --> 01:02:54,960
what you

1589
01:02:54,960 --> 01:02:57,839
have to say about these so-called

1590
01:02:57,839 --> 01:03:00,960
generalized coordinates of motion

1591
01:03:00,960 --> 01:03:03,760
and that relationship between control

1592
01:03:03,760 --> 01:03:04,559
theory

1593
01:03:04,559 --> 01:03:07,359
and then looking at nonlinear functions

1594
01:03:07,359 --> 01:03:08,960
as relationships of integrals and

1595
01:03:08,960 --> 01:03:10,000
derivatives

1596
01:03:10,000 --> 01:03:12,160
leads to this discussion of the pid

1597
01:03:12,160 --> 01:03:13,119
control

1598
01:03:13,119 --> 01:03:15,119
so proportional integral derivative

1599
01:03:15,119 --> 01:03:16,559
control pid

1600
01:03:16,559 --> 01:03:18,400
is a well-known control method in

1601
01:03:18,400 --> 01:03:20,400
engineering more than 90

1602
01:03:20,400 --> 01:03:22,079
of controllers in engineered systems

1603
01:03:22,079 --> 01:03:24,160
implement either pid or pi

1604
01:03:24,160 --> 01:03:25,839
no derivative like just proportional

1605
01:03:25,839 --> 01:03:29,039
integral control

1606
01:03:29,039 --> 01:03:31,920
the goal of pid control is to control a

1607
01:03:31,920 --> 01:03:32,559
signal

1608
01:03:32,559 --> 01:03:35,680
s sub t its integral s sub t

1609
01:03:35,680 --> 01:03:37,520
with a 0 instead of a 1 and its

1610
01:03:37,520 --> 01:03:39,280
derivative

1611
01:03:39,280 --> 01:03:41,200
s sub 2 of the 2 close to a

1612
01:03:41,200 --> 01:03:42,559
pre-specified target

1613
01:03:42,559 --> 01:03:45,760
value so it's like i want 95

1614
01:03:45,760 --> 01:03:48,640
battery and i want to be a rectangle at

1615
01:03:48,640 --> 01:03:50,960
95 percent and it's derivative to be

1616
01:03:50,960 --> 01:03:53,760
such and such during use this turns out

1617
01:03:53,760 --> 01:03:55,440
to be exactly what happens

1618
01:03:55,440 --> 01:03:57,359
when we take stochastic control of an

1619
01:03:57,359 --> 01:03:59,359
integrator chain

1620
01:03:59,359 --> 01:04:01,839
with two with three orders of motion so

1621
01:04:01,839 --> 01:04:02,480
that's just

1622
01:04:02,480 --> 01:04:04,559
a three level model in this sort of

1623
01:04:04,559 --> 01:04:06,480
infinite rows of the moments of the

1624
01:04:06,480 --> 01:04:07,520
distribution

1625
01:04:07,520 --> 01:04:09,839
the three levels are just what are

1626
01:04:09,839 --> 01:04:11,599
described here the signal the integral

1627
01:04:11,599 --> 01:04:14,240
and the derivative

1628
01:04:15,599 --> 01:04:18,480
when f is linear expected autonomous

1629
01:04:18,480 --> 01:04:20,480
states control to what extent

1630
01:04:20,480 --> 01:04:21,920
integral proportional and derivative

1631
01:04:21,920 --> 01:04:24,319
processes s t at zero one and two

1632
01:04:24,319 --> 01:04:27,599
levels of derivative are from their

1633
01:04:27,599 --> 01:04:28,880
target value of 0.

1634
01:04:28,880 --> 01:04:31,039
so it's like if it's a linear response

1635
01:04:31,039 --> 01:04:32,960
function then the first derivative

1636
01:04:32,960 --> 01:04:34,799
is going to be a constant value as in

1637
01:04:34,799 --> 01:04:37,280
the second derivative you get rid of it

1638
01:04:37,280 --> 01:04:40,319
furthermore from f and k alone one can

1639
01:04:40,319 --> 01:04:41,839
derive integral proportional

1640
01:04:41,839 --> 01:04:43,839
derivative gains which penalize

1641
01:04:43,839 --> 01:04:45,440
deviations of these three moments

1642
01:04:45,440 --> 01:04:47,680
respectively from a target value of zero

1643
01:04:47,680 --> 01:04:50,640
so these are highly optimizable problems

1644
01:04:50,640 --> 01:04:51,119
and

1645
01:04:51,119 --> 01:04:54,960
computable crucially these control gains

1646
01:04:54,960 --> 01:04:56,640
are simple byproducts of the steady

1647
01:04:56,640 --> 01:04:58,240
state density and the stochastic

1648
01:04:58,240 --> 01:05:00,240
realization problems

1649
01:05:00,240 --> 01:05:02,640
this is a cool question why restrict

1650
01:05:02,640 --> 01:05:05,039
ourselves to pid control when stochastic

1651
01:05:05,039 --> 01:05:06,880
control of integrator chains is

1652
01:05:06,880 --> 01:05:09,520
available it turns out that when sensory

1653
01:05:09,520 --> 01:05:10,480
states s of t

1654
01:05:10,480 --> 01:05:12,000
are expressed as a function of an

1655
01:05:12,000 --> 01:05:13,920
integrator chain one to get away with

1656
01:05:13,920 --> 01:05:15,760
controlling an approximation of the true

1657
01:05:15,760 --> 01:05:18,160
sensory process obtained by truncating

1658
01:05:18,160 --> 01:05:20,000
high orders of motion as these have less

1659
01:05:20,000 --> 01:05:20,559
effect

1660
01:05:20,559 --> 01:05:23,520
on the dynamics though knowing when this

1661
01:05:23,520 --> 01:05:25,200
is warranted is a problem in

1662
01:05:25,200 --> 01:05:28,640
approximation theory so how

1663
01:05:28,640 --> 01:05:30,319
let's just say we open the door to doing

1664
01:05:30,319 --> 01:05:32,799
infinite derivatives of statistical

1665
01:05:32,799 --> 01:05:33,680
distributions

1666
01:05:33,680 --> 01:05:36,079
infinite variances upon variances how

1667
01:05:36,079 --> 01:05:38,079
would we know when to stop

1668
01:05:38,079 --> 01:05:40,240
that's the problem in approximation

1669
01:05:40,240 --> 01:05:42,640
theory or approximation science

1670
01:05:42,640 --> 01:05:44,960
this may explain why integral feedback

1671
01:05:44,960 --> 01:05:46,000
control

1672
01:05:46,000 --> 01:05:49,599
which is just like battery good

1673
01:05:49,599 --> 01:05:52,160
pi control n equals one and then the pid

1674
01:05:52,160 --> 01:05:53,280
control with

1675
01:05:53,280 --> 01:05:55,760
two extra layers of the derivatives are

1676
01:05:55,760 --> 01:05:57,760
the most ubiquitous control methods in

1677
01:05:57,760 --> 01:05:58,400
engineering

1678
01:05:58,400 --> 01:06:00,720
applications however when simulating

1679
01:06:00,720 --> 01:06:01,760
biological

1680
01:06:01,760 --> 01:06:03,839
biological control usually with highly

1681
01:06:03,839 --> 01:06:05,200
non-linear systems

1682
01:06:05,200 --> 01:06:06,880
it is not uncommon to consider

1683
01:06:06,880 --> 01:06:08,400
generalized motion to fourth

1684
01:06:08,400 --> 01:06:11,680
or sixth order so that's pretty cool um

1685
01:06:11,680 --> 01:06:14,480
like how many levels of recursion and um

1686
01:06:14,480 --> 01:06:15,680
depth in modeling

1687
01:06:15,680 --> 01:06:19,359
are needed to have a people

1688
01:06:19,359 --> 01:06:22,880
so calling back to

1689
01:06:22,880 --> 01:06:26,480
here when we defined that initial sense

1690
01:06:26,480 --> 01:06:27,359
function

1691
01:06:27,359 --> 01:06:30,240
as part of this integrator chain setting

1692
01:06:30,240 --> 01:06:32,240
off the integrator chain

1693
01:06:32,240 --> 01:06:35,359
here's that initial sense function

1694
01:06:35,359 --> 01:06:39,119
as part of a broader set of dependencies

1695
01:06:39,119 --> 01:06:42,480
so here is that sense function

1696
01:06:42,480 --> 01:06:46,640
at time 3 6 and 9.

1697
01:06:46,640 --> 01:06:49,119
the figure is depicting in a graphical

1698
01:06:49,119 --> 01:06:50,160
format

1699
01:06:50,160 --> 01:06:53,680
the bayesian network of those

1700
01:06:53,680 --> 01:06:57,200
equations flipped

1701
01:06:57,200 --> 01:06:58,799
the encircled variables are random

1702
01:06:58,799 --> 01:07:01,039
variables and the processes are indexed

1703
01:07:01,039 --> 01:07:02,559
an arbitrary

1704
01:07:02,559 --> 01:07:05,359
sub an arbitrary arbitrary sequence of

1705
01:07:05,359 --> 01:07:06,960
subsequent times

1706
01:07:06,960 --> 01:07:08,720
the arrows represent relationships of

1707
01:07:08,720 --> 01:07:10,559
causality so

1708
01:07:10,559 --> 01:07:13,520
the sensory states are not causing each

1709
01:07:13,520 --> 01:07:14,000
other through

1710
01:07:14,000 --> 01:07:16,079
time they're getting measured through

1711
01:07:16,079 --> 01:07:17,359
time but

1712
01:07:17,359 --> 01:07:20,559
they are being emitted through time

1713
01:07:20,559 --> 01:07:23,440
by this s at the zeroth level like the

1714
01:07:23,440 --> 01:07:25,680
just the base generative model

1715
01:07:25,680 --> 01:07:29,280
of this s of zero

1716
01:07:29,280 --> 01:07:31,920
level function so this is the generative

1717
01:07:31,920 --> 01:07:33,200
process

1718
01:07:33,200 --> 01:07:36,799
then that can have higher derivatives

1719
01:07:36,799 --> 01:07:40,240
of change and each of those are

1720
01:07:40,240 --> 01:07:42,400
being framed as well behaved

1721
01:07:42,400 --> 01:07:44,000
statistically

1722
01:07:44,000 --> 01:07:46,160
so in the hidden markov model and these

1723
01:07:46,160 --> 01:07:47,520
um white nodes are

1724
01:07:47,520 --> 01:07:50,160
hidden states but they're inferred by

1725
01:07:50,160 --> 01:07:51,920
statistics

1726
01:07:51,920 --> 01:07:54,319
the hidden integrator state hidden state

1727
01:07:54,319 --> 01:07:56,319
processes sat

1728
01:07:56,319 --> 01:07:58,640
is given by an integrator chain i.e

1729
01:07:58,640 --> 01:08:01,359
nested stochastic differential equations

1730
01:08:01,359 --> 01:08:04,160
these processes can be seen as encoding

1731
01:08:04,160 --> 01:08:04,960
the position

1732
01:08:04,960 --> 01:08:07,359
velocity jerich etc so higher

1733
01:08:07,359 --> 01:08:11,839
derivatives of the distribution

1734
01:08:12,079 --> 01:08:15,520
so this integrator chain is kind of a

1735
01:08:15,520 --> 01:08:16,000
cool

1736
01:08:16,000 --> 01:08:19,520
idea so here was one paper stabilization

1737
01:08:19,520 --> 01:08:20,719
of integrator chains

1738
01:08:20,719 --> 01:08:22,880
in the presence of magnitude and rate

1739
01:08:22,880 --> 01:08:25,839
saturations a gain scheduling approach

1740
01:08:25,839 --> 01:08:29,120
so this paper wrote and the conclusions

1741
01:08:29,120 --> 01:08:30,560
in this paper we have given a time

1742
01:08:30,560 --> 01:08:32,880
varying controller

1743
01:08:32,880 --> 01:08:34,238
so kind of like a heuristic or an

1744
01:08:34,238 --> 01:08:36,000
algorithm for control

1745
01:08:36,000 --> 01:08:37,920
for stabilizing a chain of integrators

1746
01:08:37,920 --> 01:08:39,679
in the presence of magnitude and rate

1747
01:08:39,679 --> 01:08:41,120
saturations

1748
01:08:41,120 --> 01:08:42,960
it is proved that the controller gives a

1749
01:08:42,960 --> 01:08:44,960
convergent closed-loop system

1750
01:08:44,960 --> 01:08:48,399
i.e for any bounded state initial or

1751
01:08:48,399 --> 01:08:50,000
initial condition the state will

1752
01:08:50,000 --> 01:08:51,679
converge to the origin

1753
01:08:51,679 --> 01:08:53,359
the main strength of the controller is

1754
01:08:53,359 --> 01:08:55,120
that it gives provable convergence

1755
01:08:55,120 --> 01:08:56,960
without being overly conservative

1756
01:08:56,960 --> 01:08:59,839
this is verified in a simulation study

1757
01:08:59,839 --> 01:09:00,560
so

1758
01:09:00,560 --> 01:09:02,960
it's kind of like we have the frame of

1759
01:09:02,960 --> 01:09:04,399
the airplane

1760
01:09:04,399 --> 01:09:07,520
at steady state and then

1761
01:09:07,520 --> 01:09:09,120
which is flying through the air so how

1762
01:09:09,120 --> 01:09:10,880
are we going to re-equilibrate all the

1763
01:09:10,880 --> 01:09:11,679
sensors

1764
01:09:11,679 --> 01:09:13,920
so that if we get knocked off to the

1765
01:09:13,920 --> 01:09:14,719
side

1766
01:09:14,719 --> 01:09:17,359
what's the path by which we're going to

1767
01:09:17,359 --> 01:09:19,839
get those sensors back to their desired

1768
01:09:19,839 --> 01:09:22,000
level

1769
01:09:22,000 --> 01:09:24,960
and it's just a question i oh and this

1770
01:09:24,960 --> 01:09:26,399
is kind of what it looked like one of

1771
01:09:26,399 --> 01:09:28,719
the figures from the paper

1772
01:09:28,719 --> 01:09:31,839
so these are these derivative functions

1773
01:09:31,839 --> 01:09:33,759
they get get like bumped and then they

1774
01:09:33,759 --> 01:09:35,120
can come back to

1775
01:09:35,120 --> 01:09:38,399
the level that they're desired

1776
01:09:38,399 --> 01:09:40,799
almost in this signal processing like

1777
01:09:40,799 --> 01:09:43,040
way

1778
01:09:43,600 --> 01:09:45,359
so what are integrator chains how are

1779
01:09:45,359 --> 01:09:46,880
they used maybe someone has

1780
01:09:46,880 --> 01:09:50,399
used them before that'd be cool and then

1781
01:09:50,399 --> 01:09:52,880
one kind of random thought was there's a

1782
01:09:52,880 --> 01:09:53,759
lot of cases

1783
01:09:53,759 --> 01:09:56,800
where we frame a process as mean

1784
01:09:56,800 --> 01:09:59,840
zero because it

1785
01:09:59,840 --> 01:10:02,320
allows thinking about something in

1786
01:10:02,320 --> 01:10:03,040
relationship

1787
01:10:03,040 --> 01:10:06,560
to uh a defined axis whether it's the

1788
01:10:06,560 --> 01:10:08,400
number line or whether it's some other

1789
01:10:08,400 --> 01:10:09,840
variable

1790
01:10:09,840 --> 01:10:11,760
it kind of splits half the things

1791
01:10:11,760 --> 01:10:13,600
negative and positive or there's various

1792
01:10:13,600 --> 01:10:14,400
other times

1793
01:10:14,400 --> 01:10:16,400
but there's actually a bunch of places

1794
01:10:16,400 --> 01:10:18,080
and maybe more or maybe these are not

1795
01:10:18,080 --> 01:10:18,960
all the same so

1796
01:10:18,960 --> 01:10:20,960
it's okay if somebody knows more and

1797
01:10:20,960 --> 01:10:22,800
helps us all out

1798
01:10:22,800 --> 01:10:25,840
but there's actually a few cases where

1799
01:10:25,840 --> 01:10:27,840
a distribution that's hard to estimate

1800
01:10:27,840 --> 01:10:30,080
is replaced with a zero mean like

1801
01:10:30,080 --> 01:10:33,360
sometimes there's replacing elements of

1802
01:10:33,360 --> 01:10:34,000
a list

1803
01:10:34,000 --> 01:10:36,239
with a z score like their standard

1804
01:10:36,239 --> 01:10:37,120
deviation

1805
01:10:37,120 --> 01:10:40,800
from the mean or the mode um

1806
01:10:40,800 --> 01:10:43,120
but then it's like half or above and

1807
01:10:43,120 --> 01:10:44,480
half are below

1808
01:10:44,480 --> 01:10:46,560
so that's like replacing something with

1809
01:10:46,560 --> 01:10:47,679
a zero center

1810
01:10:47,679 --> 01:10:51,199
z score or t distribution sometimes

1811
01:10:51,199 --> 01:10:53,440
there are error distributions which are

1812
01:10:53,440 --> 01:10:55,199
extracted from a signal it's like the

1813
01:10:55,199 --> 01:10:55,679
signal

1814
01:10:55,679 --> 01:10:58,080
is the underlying line and the goal of

1815
01:10:58,080 --> 01:10:58,719
the signal

1816
01:10:58,719 --> 01:11:00,480
extraction is to leave your error

1817
01:11:00,480 --> 01:11:01,920
distribution

1818
01:11:01,920 --> 01:11:04,960
mean zero and then equally

1819
01:11:04,960 --> 01:11:06,400
distributed in both directions so

1820
01:11:06,400 --> 01:11:08,080
sometimes we're

1821
01:11:08,080 --> 01:11:11,840
pulling out an error distribution

1822
01:11:11,840 --> 01:11:16,000
we're trying to find uh

1823
01:11:16,000 --> 01:11:18,880
that mean zero get to a level of

1824
01:11:18,880 --> 01:11:20,640
derivative of a signal

1825
01:11:20,640 --> 01:11:22,880
where the mean is zero like where the

1826
01:11:22,880 --> 01:11:24,400
rate of change of some

1827
01:11:24,400 --> 01:11:26,640
high derivative is zero which implies

1828
01:11:26,640 --> 01:11:29,520
that it's not changing at that level

1829
01:11:29,520 --> 01:11:33,199
and then sometimes we're trying to get

1830
01:11:33,199 --> 01:11:36,239
um like in predictive processing

1831
01:11:36,239 --> 01:11:38,880
study the differentiable or predictive

1832
01:11:38,880 --> 01:11:40,000
processing with

1833
01:11:40,000 --> 01:11:43,280
trying to get a zero centered variance

1834
01:11:43,280 --> 01:11:47,520
on the sensory input but more

1835
01:11:47,520 --> 01:11:49,920
about how we can study the differential

1836
01:11:49,920 --> 01:11:52,800
between some controllable distribution

1837
01:11:52,800 --> 01:11:55,040
and then some other distribution that we

1838
01:11:55,040 --> 01:11:56,320
can't control

1839
01:11:56,320 --> 01:11:58,800
and then how to make how does zero

1840
01:11:58,800 --> 01:11:59,920
center that

1841
01:11:59,920 --> 01:12:01,920
to determine which solutions are better

1842
01:12:01,920 --> 01:12:03,199
or worse than each other and there's a

1843
01:12:03,199 --> 01:12:05,679
lot of different methods there

1844
01:12:05,679 --> 01:12:08,400
and then there was this other paper time

1845
01:12:08,400 --> 01:12:10,159
optimal regulation of a chain of

1846
01:12:10,159 --> 01:12:12,239
integrators with saturated input and

1847
01:12:12,239 --> 01:12:14,880
internal planet variables in application

1848
01:12:14,880 --> 01:12:18,000
to trajectory planning

1849
01:12:18,000 --> 01:12:21,600
so again just kind of a open question

1850
01:12:21,600 --> 01:12:23,040
what is the relationship between

1851
01:12:23,040 --> 01:12:25,040
integrator chains and then this idea

1852
01:12:25,040 --> 01:12:26,560
that we talk about a lot with

1853
01:12:26,560 --> 01:12:30,080
action planning as inference

1854
01:12:30,719 --> 01:12:33,600
then the conclusion this paper outlines

1855
01:12:33,600 --> 01:12:35,199
some of the key relationships between

1856
01:12:35,199 --> 01:12:36,400
stationary processes

1857
01:12:36,400 --> 01:12:38,159
inference and control these

1858
01:12:38,159 --> 01:12:40,000
relationships rest upon partitioning the

1859
01:12:40,000 --> 01:12:41,120
world into those

1860
01:12:41,120 --> 01:12:42,960
things that are internal or external to

1861
01:12:42,960 --> 01:12:44,159
a statistical boundary

1862
01:12:44,159 --> 01:12:46,960
known as a markov blanket when equipped

1863
01:12:46,960 --> 01:12:48,960
with dynamics the expected internal

1864
01:12:48,960 --> 01:12:50,080
states appear to engage

1865
01:12:50,080 --> 01:12:51,920
in variational inference while the

1866
01:12:51,920 --> 01:12:53,520
expected active states

1867
01:12:53,520 --> 01:12:55,520
appear to be performing active inference

1868
01:12:55,520 --> 01:12:56,719
in various forms of

1869
01:12:56,719 --> 01:12:59,520
stochastic control the rationale behind

1870
01:12:59,520 --> 01:13:01,199
these findings is rather simple

1871
01:13:01,199 --> 01:13:02,880
if a markow blanket derives from a

1872
01:13:02,880 --> 01:13:04,480
steady state density the states the

1873
01:13:04,480 --> 01:13:05,840
system will look as if they are

1874
01:13:05,840 --> 01:13:07,679
responding adaptively to external

1875
01:13:07,679 --> 01:13:08,960
perturbations

1876
01:13:08,960 --> 01:13:11,280
in order to recover the steady state

1877
01:13:11,280 --> 01:13:12,239
conversely

1878
01:13:12,239 --> 01:13:13,840
well-known methods used to build

1879
01:13:13,840 --> 01:13:16,239
adaptive systems implement the same kind

1880
01:13:16,239 --> 01:13:18,000
of dynamics implicitly

1881
01:13:18,000 --> 01:13:20,080
so the system maintains a steady state

1882
01:13:20,080 --> 01:13:22,239
with its environment

1883
01:13:22,239 --> 01:13:25,199
so maybe there's i mean this isn't a

1884
01:13:25,199 --> 01:13:26,320
totally accurate

1885
01:13:26,320 --> 01:13:29,840
uh classification but there's some

1886
01:13:29,840 --> 01:13:31,120
algorithms

1887
01:13:31,120 --> 01:13:33,679
that are being connected on one side to

1888
01:13:33,679 --> 01:13:34,239
each other

1889
01:13:34,239 --> 01:13:36,800
so we have learning and optimization

1890
01:13:36,800 --> 01:13:38,640
learning as inference

1891
01:13:38,640 --> 01:13:41,520
all of machine learning etc learning and

1892
01:13:41,520 --> 01:13:42,080
optim

1893
01:13:42,080 --> 01:13:45,120
optimization and then variational

1894
01:13:45,120 --> 01:13:47,520
inference being used as an optimization

1895
01:13:47,520 --> 01:13:50,239
technique with the gradient descent by

1896
01:13:50,239 --> 01:13:51,520
free energy

1897
01:13:51,520 --> 01:13:54,640
in machine learning and maybe in

1898
01:13:54,640 --> 01:13:57,920
evolutionary systems then there's this

1899
01:13:57,920 --> 01:13:58,640
question about

1900
01:13:58,640 --> 01:14:01,199
estimating latent causes in the world

1901
01:14:01,199 --> 01:14:02,719
and connecting that to

1902
01:14:02,719 --> 01:14:05,360
higher derivatives in the integrator

1903
01:14:05,360 --> 01:14:06,239
chains

1904
01:14:06,239 --> 01:14:09,199
or as just variables under consideration

1905
01:14:09,199 --> 01:14:10,480
that's that mapping

1906
01:14:10,480 --> 01:14:13,280
of external states which aren't directly

1907
01:14:13,280 --> 01:14:15,120
seen

1908
01:14:15,120 --> 01:14:19,280
and then maybe

1909
01:14:19,280 --> 01:14:22,800
this one goes on this side but

1910
01:14:22,880 --> 01:14:24,800
uh there's this whole other set of

1911
01:14:24,800 --> 01:14:26,080
algorithms related to

1912
01:14:26,080 --> 01:14:29,199
adaptive systems and these are framed

1913
01:14:29,199 --> 01:14:31,199
variously but we have adaptive systems

1914
01:14:31,199 --> 01:14:32,960
cybernetic systems

1915
01:14:32,960 --> 01:14:36,560
anticipatory systems holism homeostatic

1916
01:14:36,560 --> 01:14:37,760
slash

1917
01:14:37,760 --> 01:14:41,040
active learning allostatic agents

1918
01:14:41,040 --> 01:14:44,880
all these sort of biologically inspired

1919
01:14:44,880 --> 01:14:47,120
yes drawing on far from equilibrium

1920
01:14:47,120 --> 01:14:48,400
thermodynamics

1921
01:14:48,400 --> 01:14:51,679
but here was like the flame dissipating

1922
01:14:51,679 --> 01:14:53,199
like it's about something that just sort

1923
01:14:53,199 --> 01:14:55,040
of gets to its free energy minimization

1924
01:14:55,040 --> 01:14:56,480
just like gets there

1925
01:14:56,480 --> 01:14:59,760
but with these active systems

1926
01:14:59,760 --> 01:15:02,480
the question becomes how do we take this

1927
01:15:02,480 --> 01:15:03,920
ongoing

1928
01:15:03,920 --> 01:15:07,360
multi-scale inference

1929
01:15:07,360 --> 01:15:11,600
side and connect it to this multi-scale

1930
01:15:11,600 --> 01:15:15,199
action in the loop niche modifying

1931
01:15:15,199 --> 01:15:20,159
also action planning biology section

1932
01:15:21,840 --> 01:15:25,840
um one friend uh looked at these slides

1933
01:15:25,840 --> 01:15:27,280
and then made a comment

1934
01:15:27,280 --> 01:15:29,679
and they wrote i think it would be good

1935
01:15:29,679 --> 01:15:31,760
to expand on the differences

1936
01:15:31,760 --> 01:15:34,239
of the paradigms in section three which

1937
01:15:34,239 --> 01:15:35,040
were lettered

1938
01:15:35,040 --> 01:15:38,320
as they were in the paper a priori

1939
01:15:38,320 --> 01:15:40,880
a posteriori estimate estimation

1940
01:15:40,880 --> 01:15:42,719
afterwards estimation

1941
01:15:42,719 --> 01:15:44,960
predictive processing and variational

1942
01:15:44,960 --> 01:15:45,920
base

1943
01:15:45,920 --> 01:15:48,320
i get the differences formally but still

1944
01:15:48,320 --> 01:15:50,320
not at a super intuitive level so this

1945
01:15:50,320 --> 01:15:52,000
might be good as a pedagogical

1946
01:15:52,000 --> 01:15:54,800
exercise for ourselves so that'd be cool

1947
01:15:54,800 --> 01:15:56,719
maybe everyone can think about that

1948
01:15:56,719 --> 01:15:59,760
and come to their own explanation for

1949
01:15:59,760 --> 01:16:01,760
what the difference is between these

1950
01:16:01,760 --> 01:16:05,120
three and we'll talk about it in the dot

1951
01:16:05,120 --> 01:16:07,840
one and dot two

1952
01:16:08,480 --> 01:16:10,960
then just a few of the implications and

1953
01:16:10,960 --> 01:16:12,480
bigger questions that are raised by the

1954
01:16:12,480 --> 01:16:13,600
paper

1955
01:16:13,600 --> 01:16:15,760
so in the section on interacting markov

1956
01:16:15,760 --> 01:16:16,880
blankets they write

1957
01:16:16,880 --> 01:16:19,440
the sort of inference we have described

1958
01:16:19,440 --> 01:16:21,120
could be nuanced by partitioning the

1959
01:16:21,120 --> 01:16:22,800
external state space into several

1960
01:16:22,800 --> 01:16:24,560
systems that are themselves markov

1961
01:16:24,560 --> 01:16:25,280
blankets

1962
01:16:25,280 --> 01:16:27,199
such as markov blankets nested at

1963
01:16:27,199 --> 01:16:29,040
several different scales

1964
01:16:29,040 --> 01:16:31,360
from the perspective of internal states

1965
01:16:31,360 --> 01:16:32,239
this leads to

1966
01:16:32,239 --> 01:16:34,560
a more interesting inference problem

1967
01:16:34,560 --> 01:16:36,960
with a more complex generative model

1968
01:16:36,960 --> 01:16:38,960
it may be that the distinction between

1969
01:16:38,960 --> 01:16:40,719
the sources systems we generally think

1970
01:16:40,719 --> 01:16:42,480
of as engaging in cognitive

1971
01:16:42,480 --> 01:16:45,360
inferential dynamics and simpler systems

1972
01:16:45,360 --> 01:16:47,280
rest upon the level of structure

1973
01:16:47,280 --> 01:16:49,199
in their generative models i.e the

1974
01:16:49,199 --> 01:16:50,480
steady state densities

1975
01:16:50,480 --> 01:16:53,840
that describe their inferential dynamics

1976
01:16:53,840 --> 01:16:56,880
so that's pretty cool about maybe this

1977
01:16:56,880 --> 01:16:59,679
framework or at least work in this level

1978
01:16:59,679 --> 01:17:01,120
of analysis

1979
01:17:01,120 --> 01:17:04,320
mapping just directly to nested markov

1980
01:17:04,320 --> 01:17:05,760
blankets

1981
01:17:05,760 --> 01:17:09,120
and it brings up this whole discussion

1982
01:17:09,120 --> 01:17:12,560
about what kinds of systems can we model

1983
01:17:12,560 --> 01:17:15,440
with active inference so no one's saying

1984
01:17:15,440 --> 01:17:16,000
that

1985
01:17:16,000 --> 01:17:18,880
the stock market is an auto-regressive

1986
01:17:18,880 --> 01:17:19,360
model

1987
01:17:19,360 --> 01:17:22,239
but people use auto-regressive models so

1988
01:17:22,239 --> 01:17:23,199
what kinds of

1989
01:17:23,199 --> 01:17:25,280
systems will we usefully be able to

1990
01:17:25,280 --> 01:17:27,120
model with active inference

1991
01:17:27,120 --> 01:17:28,880
without really just getting into a

1992
01:17:28,880 --> 01:17:30,560
debate about whether it quote

1993
01:17:30,560 --> 01:17:33,199
is active inference in the system just

1994
01:17:33,199 --> 01:17:34,880
how are we going to use variational

1995
01:17:34,880 --> 01:17:36,320
based methods

1996
01:17:36,320 --> 01:17:39,199
with modern twists and developments

1997
01:17:39,199 --> 01:17:40,080
related to

1998
01:17:40,080 --> 01:17:43,040
cybernetics and multi-scale systems so

1999
01:17:43,040 --> 01:17:45,280
that's like the instrumentalism side

2000
01:17:45,280 --> 01:17:48,320
and then the realism side

2001
01:17:48,320 --> 01:17:50,560
is what kind of systems are doing active

2002
01:17:50,560 --> 01:17:51,760
inference

2003
01:17:51,760 --> 01:17:55,120
so there's maybe even a realism of

2004
01:17:55,120 --> 01:17:58,800
philosophy branch and then even maybe on

2005
01:17:58,800 --> 01:17:59,760
the applied side

2006
01:17:59,760 --> 01:18:02,159
like it's a philosophical debate is the

2007
01:18:02,159 --> 01:18:03,040
cell doing

2008
01:18:03,040 --> 01:18:04,880
active inference doing free energy

2009
01:18:04,880 --> 01:18:06,719
principle is it realizing

2010
01:18:06,719 --> 01:18:08,880
certain constraints of nature or how

2011
01:18:08,880 --> 01:18:10,080
would we know what

2012
01:18:10,080 --> 01:18:12,719
um uh you know an ant is quote doing

2013
01:18:12,719 --> 01:18:15,840
free energy minimization in its brain

2014
01:18:15,840 --> 01:18:19,360
and then on the engineering side

2015
01:18:19,360 --> 01:18:21,280
it could be argued that if a robot is

2016
01:18:21,280 --> 01:18:23,520
implementing active inference code that

2017
01:18:23,520 --> 01:18:25,040
it is actually doing

2018
01:18:25,040 --> 01:18:27,600
active inference so this question about

2019
01:18:27,600 --> 01:18:29,520
designing systems within the active

2020
01:18:29,520 --> 01:18:30,960
inference framework

2021
01:18:30,960 --> 01:18:33,360
so instead of saying i think all

2022
01:18:33,360 --> 01:18:34,560
internet networks

2023
01:18:34,560 --> 01:18:36,320
are active in front systems it's

2024
01:18:36,320 --> 01:18:38,000
definitely a claim somebody could make

2025
01:18:38,000 --> 01:18:40,640
interesting claim but it's quite another

2026
01:18:40,640 --> 01:18:41,840
thing to design

2027
01:18:41,840 --> 01:18:44,480
a computer network that is within an

2028
01:18:44,480 --> 01:18:45,440
ontology of

2029
01:18:45,440 --> 01:18:47,679
active inference then it would be fair

2030
01:18:47,679 --> 01:18:49,760
to say that that network is quote doing

2031
01:18:49,760 --> 01:18:50,960
active inference

2032
01:18:50,960 --> 01:18:53,280
so that's like realism and maybe for

2033
01:18:53,280 --> 01:18:55,679
some it's more of an engineering realism

2034
01:18:55,679 --> 01:19:00,000
others it's a philosophical realism

2035
01:19:00,000 --> 01:19:01,920
another implication and bigger question

2036
01:19:01,920 --> 01:19:03,520
that arises in the paper

2037
01:19:03,520 --> 01:19:05,840
is about temporally deep inference so

2038
01:19:05,840 --> 01:19:07,600
they write

2039
01:19:07,600 --> 01:19:09,120
this distinction may speak to a

2040
01:19:09,120 --> 01:19:10,640
straightforward extension of the

2041
01:19:10,640 --> 01:19:11,679
treatment on offer

2042
01:19:11,679 --> 01:19:13,679
from simply inferring an external state

2043
01:19:13,679 --> 01:19:15,360
to inferring the trajectories of

2044
01:19:15,360 --> 01:19:18,800
external states so again moving from

2045
01:19:18,800 --> 01:19:20,560
not just the point estimate current

2046
01:19:20,560 --> 01:19:22,480
estimate of external state

2047
01:19:22,480 --> 01:19:24,560
that was what was presented earlier to

2048
01:19:24,560 --> 01:19:26,719
inferring the trajectories of external

2049
01:19:26,719 --> 01:19:27,600
states

2050
01:19:27,600 --> 01:19:30,800
which is to say decomposing their

2051
01:19:30,800 --> 01:19:33,840
higher orders of movement this may be

2052
01:19:33,840 --> 01:19:35,679
achieved by representing the external

2053
01:19:35,679 --> 01:19:36,239
process

2054
01:19:36,239 --> 01:19:38,320
in terms of its higher orders of motion

2055
01:19:38,320 --> 01:19:40,640
by solving the stochastic realization

2056
01:19:40,640 --> 01:19:43,360
problem by repeating the analysis above

2057
01:19:43,360 --> 01:19:45,199
internal states may be seen as inferring

2058
01:19:45,199 --> 01:19:46,159
the position

2059
01:19:46,159 --> 01:19:48,480
velocity juror etc of the external

2060
01:19:48,480 --> 01:19:49,440
process

2061
01:19:49,440 --> 01:19:51,840
consistently with temporally deep

2062
01:19:51,840 --> 01:19:52,480
inference

2063
01:19:52,480 --> 01:19:55,040
in the sense of a bayesian filter a

2064
01:19:55,040 --> 01:19:56,800
special case of which is the extended

2065
01:19:56,800 --> 01:19:58,800
kalman boosie filter

2066
01:19:58,800 --> 01:20:00,560
so these are cool things to talk about

2067
01:20:00,560 --> 01:20:01,920
we could talk about

2068
01:20:01,920 --> 01:20:05,120
what is temporally deep active inference

2069
01:20:05,120 --> 01:20:08,239
what are the ways that the model deals

2070
01:20:08,239 --> 01:20:10,320
with internal and external categories

2071
01:20:10,320 --> 01:20:12,480
and discrete variables

2072
01:20:12,480 --> 01:20:15,520
how do we deal with the inference on

2073
01:20:15,520 --> 01:20:17,440
external states and how does that relate

2074
01:20:17,440 --> 01:20:19,280
to our action selection

2075
01:20:19,280 --> 01:20:20,560
and then what happens when there's a

2076
01:20:20,560 --> 01:20:23,199
feedback or um some other type of

2077
01:20:23,199 --> 01:20:24,800
interaction with the niche

2078
01:20:24,800 --> 01:20:26,719
the informational niche the social needs

2079
01:20:26,719 --> 01:20:28,560
the stigma niche

2080
01:20:28,560 --> 01:20:33,360
so or other questions people can write

2081
01:20:33,360 --> 01:20:37,920
um well that was

2082
01:20:38,080 --> 01:20:41,199
a sort of quick run through

2083
01:20:41,199 --> 01:20:44,800
paper and i'm not

2084
01:20:44,800 --> 01:20:47,520
sure if i got each section 100 correct

2085
01:20:47,520 --> 01:20:49,120
so it will be good to have

2086
01:20:49,120 --> 01:20:50,719
the author's perspective on a lot of

2087
01:20:50,719 --> 01:20:52,480
pieces as well as a lot of other

2088
01:20:52,480 --> 01:20:55,040
experts who i'm sure could have said a

2089
01:20:55,040 --> 01:20:56,000
ton

2090
01:20:56,000 --> 01:20:58,840
more and better about some of the math

2091
01:20:58,840 --> 01:21:00,239
but

2092
01:21:00,239 --> 01:21:02,000
we can offer up the same questions that

2093
01:21:02,000 --> 01:21:03,600
we have for any paper

2094
01:21:03,600 --> 01:21:05,840
like what might a good understanding

2095
01:21:05,840 --> 01:21:07,040
enable

2096
01:21:07,040 --> 01:21:08,880
what are the unique predictions and

2097
01:21:08,880 --> 01:21:10,960
implications and the unique developments

2098
01:21:10,960 --> 01:21:11,440
of this

2099
01:21:11,440 --> 01:21:14,400
paper what are some of the next steps

2100
01:21:14,400 --> 01:21:15,040
for

2101
01:21:15,040 --> 01:21:16,480
free energy principle and active

2102
01:21:16,480 --> 01:21:18,320
inference research

2103
01:21:18,320 --> 01:21:21,199
what are the goals of this research and

2104
01:21:21,199 --> 01:21:21,600
then

2105
01:21:21,600 --> 01:21:24,159
also to the participants and the authors

2106
01:21:24,159 --> 01:21:25,440
what are they still

2107
01:21:25,440 --> 01:21:29,839
curious about learning so

2108
01:21:30,320 --> 01:21:33,840
thanks for participating it was a fun

2109
01:21:33,840 --> 01:21:37,760
26 and uh we hope that you'll

2110
01:21:37,760 --> 01:21:40,800
join for 26.1 and 0.2

2111
01:21:40,800 --> 01:21:43,120
if you can or comment on the videos or

2112
01:21:43,120 --> 01:21:44,480
whatever

2113
01:21:44,480 --> 01:21:52,239
and thanks talk to you later bye

