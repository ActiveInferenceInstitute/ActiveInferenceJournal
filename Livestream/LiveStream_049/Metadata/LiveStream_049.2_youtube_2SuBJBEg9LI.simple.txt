SPEAKER_03:
Hello everyone.

Welcome.

It's ACT-INF live stream number 49.2 on October 12th, 2022.

welcome to the active inference institute we're a participatory online institute that is communicating learning and practicing applied active inference you can find us at some of the links on the page this is a recorded and an archived live stream so please provide feedback so we can improve our work all backgrounds and perspectives are welcome and we'll be following video etiquette for live streams

Head over to ActiveInference.org to learn more about the kinds of projects and learning groups you can get involved in.

And we're here in stream number 49.2 in the third video of our explorations of the paper, A Worked Example of the Bayesian Mechanics of Classical Objects.

In the dot zero, Jakob and Ali and I provided some background and context, then

last week in 49.1 with dalton we all convened and we had a great discussion and went through a lot of that context again and that set us up very well today for 49.2 to be primarily going through the paper which is very exciting so we'll begin with just

saying hello and anything else we'd like to add on this wednesday and then we will head right in so i'm daniel i'm a researcher in california and i guess i'm excited to get to the paper and understand what points are touched upon and why and i'll pass to jakob


SPEAKER_02:
Hello, I'm Jakob.

I'm a student in the UK and I'm excited to talk about the different faces of Bayesian mechanics, how they are related, how they are different.

I'll pass it to Ali.


SPEAKER_00:
Hello, I'm Ali.

I'm an independent researcher from Iran.

Again, I'm very excited to be here as well.

Last week, we had a truly amazing discussion with Dalton.

I'm very much looking forward to continue our journey through this fascinating paper today.

I also have a bunch of questions I'd like to ask, especially when we come to section four on quantum ontology, and I'll pass it to Dalton.


SPEAKER_01:
Okay, well, I'm Dalton.

I'm a mathematician and a physicist currently based at Stony Brook University.

I'm also at the Versys Lab where a large part of my research program right now is to do with the maths and physics of the free energy principle.

So I'm pleased to be here and thank you for having me.

I'm happy to get the conversation underway.


SPEAKER_03:
Well, we've looked previously at the roadmap, so let's just take one last glimpse at our map before we go white knuckle on the steering wheel.

Maybe just one overview, Dalton, if you could provide what sections are addressed and what is the general anatomy and physiology of the paper.


SPEAKER_01:
Yeah, of course.

So as we were talking about last time, the structure of the paper partially reflects the environment that it was written in, in a way that is or has come to characterize the free energy principle.

So it's kind of funny in that sense.

One of the things that was a kind of unmet need was a nice paper relatively contained that drew together some of the recent ideas that have been written in the past six months or so about what we've called Bayesian mechanics and there are a few key papers that are then kind of

summarized and put on stage in the first maybe four sections.

And then sections five through seven are actually taking all of that summary and putting it into a worked example of what Bayesian mechanics looks like.

So we have a lot of rigorous development

To begin with, and then we actually use some of that in the wild and show okay so if you're actually to treat this algorithmically and go and compute something using this framework, what would it look like.

So in a way, it's kind of split roughly along mathematical and physical lines, if you'd like to think of it that way.

Mathematicians really like foundational, rigorous stuff, and then physicists really like to be able to compute things and say something about models of the physical world.

So in a way, it's trying to meet both of those kind of metological needs, and that's the reason why it's structured this way.

So as we go through, you'll see at some point there's a bit of a phase transition where we go from here are all the basic ingredients, here are what they mean, and how they ought to be used, to here is how we actually use them.


SPEAKER_03:
We'll keep an eye out for that time post.

and we'll be paying attention to the equations as part of our preparatory work here it just um those on the live stream will see a subset of our coda page where we have all of the equations and some awesome annotations by ali so we'll be able to look at the paper and also bring in some pre-screenshotted formalisms and we'll uh journey forth so

beginning with the introduction what did you aim to set up in the introductions what did you enter what did you want people to have

prepared or their state when they entered the introduction and leave it.

And also I'm a little curious about the acknowledgements at the end of the first section.

Of course.


SPEAKER_01:
Yeah.

So if you go and it might benefit me to have a copy of this in front of me as well.

So give me one moment to bring that up.

But one of the things that I wanted to do with the introduction was really roadmap exactly what I had just described, which is that in the last couple of years, and especially the last six months, there's been a lot written about this thing called Bayesian mechanics.

And it is a bit of a different take on what has traditionally been written as the free energy principle.

So if you're in the active inference literature or if you're in the predictive processing literature, this is probably new to you.

And likewise, if you are if you're coming from conventional stochastic process theory,

then you're probably not familiar with the specific technique or philosophy underlying Bayesian mechanics.

So that's probably new to you as well.

So the idea of the introduction is just to set out, okay, here is Bayesian mechanics.

We've talked a lot about it in these previous papers, and it was probably time to...

set out in detail what is it and why are we interested in it and how do we use it which is of course later on in the papers the work example.

So in the beginning of the introduction I just lay out okay here is what we have called Bayesian mechanics and here is under what circumstances is it useful which introduces the idea of synchronization in the first and second paragraphs.

And then in the third paragraph on the third page, well, the third paragraph, the first one on the third page, I describe this idea that there hasn't really been a kind of worked example of this yet.

So some of the theory has been worked out in previous papers, some of them mine, some of them...

are uh co-authored with other people some of them are from uh carl's group at the welcome center at ucl but but in all of those um papers they're primarily theoretical uh except for certain uh kind of algorithmic papers mostly out of the control theory literature so it is worth complementing this unified view that i try and describe uh taking in the introduction with

an application of that unified view, if for no other reason than to give it some concrete particulars.

So that's actually a phrase from category theory, which is probably appropriate, given that category theory is very interested in the general and the abstract

and not so much in the concrete particular.

In fact, I think that was a phrase from Lovaire, who's one of the most famous, well-known category theorists.

So it is kind of appropriate, and that part of the motivation for at least the second half of the paper is to say, okay, we've done all this theory work, and we've laid out, here's precisely what this thing, Bayesian mechanics, is.

And then to give it some

kind of meat to grab onto if you're someone that likes to actually write models or understand how to shuffle symbols around in an equation and really work with things, then here is something for you that will actually kind of make things make sense to you.


SPEAKER_03:
Awesome.

And yes, this is quite, not an indictment, but just reflecting the very rapid pace of development that much has been discussed around the role of Bayesian mechanics as a conceptual integrator or unifier, yet

the concrete particulars remained to be demonstrated.

Of course, yeah.


SPEAKER_01:
And as you say, it's not an indictment because there is a place for both.

And of course, I'm biased coming from a very strong mathematical background.

But I think it is better to go with the more general, more abstract.

And it's better to build theory rather than just deploy it.

But it's I mean, there's room for both and they serve different needs.

So doing exclusively one or the other is, in my opinion and in my research, not the best way to approach a problem because you need to be able to build the techniques that solve the problems.

Then you also need to use them to solve problems.

So, yes, not an indictment, but.

maybe a striking observation that there's been a lot of the abstract stuff and maybe something more concrete has been missing historically in the literature.


SPEAKER_03:
Awesome.

And then any thoughts on the last paragraph or the unusual positioning of the acknowledgements paragraph?


SPEAKER_01:
No thoughts on the last one.

I think the last one just draws all of those ideas together and also says one of the reasons why this approach is interesting is it recovers some

things of independent mathematical interest, which is what I gesture at in the last sentence.

I put all of my acknowledgements at the end of the introduction.

I think that's just something that I developed, a quirk maybe, although I think it's common, well, it's relatively common in mathematical papers to put the acknowledgements right after the introduction.

So, well, unusual maybe with respect to other fields that I think put it after the conclusion or after the last section and before the references.

I like it there.

I like it right after the introduction because I think it gives credit more visibly.

Mathematical writing is kind of unique in that often you are writing alone, but thinking together.

And so the end product, the paper itself is not always reflected and in fact is rarely reflective of the mathematical thinking that went into it.

So it's good to front load that information.

It's good to say straight away, here are the people that I thought about this problem with.

And that's what went into this paper, contributions, intellectual contributions from all of these people that I had conversations with or bounced ideas off of.

And so the acknowledgments is right there in the beginning.

Awesome.

Makes a lot of sense.


SPEAKER_03:
Okay, so...

into section two on mechanics so for each section i'll just kind of start up a new page and we can bring in equations and quotations as seen fit so let's just begin with section 2a classical physics in one dimensions why start here and what does this section say


SPEAKER_01:
Yeah, so section 2A is just a very brief summarization of what is classical mechanics.

So this is important for two reasons, really.

One is it allows me to talk a little about the basic building blocks that I'm going to use in the second section.

excuse me, second half of the paper.

So we start off on a point of familiarity.

And if not, then

You know, all of that is built up so that later on the rest of the paper is at least referencing something that has already been discussed.

So just in terms of layout, it makes sense to get these preliminaries done first.

The other thing is, of course, one of the points of the paper, or at least one of the motivations, is that

Bayesian mechanics is a mechanical theory just like any other mechanical theory.

And so to really make that analogy come across, it was good to investigate, OK, well, what are mechanical theories?

What does that really mean?

So in the context of classical mechanics, what do we mean by the interaction of

stationary action principles and laws of motion and dynamics and all these things that we talked about in the previous episode.

What do all those look like in classical mechanics?

And then the kind of the metallurgical point of the paper in some sense is

Well, I don't know.

You could argue that this is the point of the paper, is to make the analogy precise, to point out that, OK, all these things that live in Bayesian mechanics are things that live in mechanical theories that map onto something like classical mechanics, and that you can prove this.

So really, in some sense, the paper is an extended exercise in proving that that map between something that we know very well and something that we maybe don't exists.

But I would argue at least that that's only window dressing, the real point of the paper being proving stuff about Bayesian mechanics and classical mechanics is just a useful analogy.

But I think the way it's shaped up, it kind of does both.

And you could argue that, yeah, it does one or the other.

with one in service of the other.

But how that relationship goes, I think, is maybe open to interpretation, just the way that the paper evolved.

Regardless, the reason why we start with classical physics is to put all those pieces on the board so that later on we can go and use them.


SPEAKER_03:
Awesome.

So equation 1 and 1.1, just using a decimal point to reflect unnumbered formalisms that follow a numbered formalism.

Where do we get on the first page with these equations 1 through 2?


SPEAKER_01:
Yeah.

Equation one is starting really from the very basics.

So this is the action functional.

And in particular, it's the action functional for classical mechanics in the Lagrangian setting.

Equation 1.1

is the result of finding the path of least action or the stationary action.

So mathematically, the way that is done is by finding what's called the Euler-Lagrange equation.

And that's what this is.

So if you apply the Euler-Lagrange equation to the action, then 1.1 is the result.

And what is interesting about that is that gives you back Newton's second law, F equals MA.

And the reason why is because the derivative of V with respect to Q

So the gradient of a scalar potential is a force acting on something.

And the Euler-Lagrange equation tells us that that force is equal to the mass times the time derivative of velocity, which is the acceleration.

So the chain of reasoning goes that beginning from an optimization principle, you get a law of motion, and that that kind of embodies classical mechanics in the case when you begin from the classical action and you get Newton's second law.

So the idea is, and the reason why this is mentioned, is it calls back the reasoning in the paper on Bayesian mechanics, Physics of and by Beliefs, I think is the full title, which tells us that in the same way that this exists in classical physics,

Bayesian mechanics has its own analogy to this.

So if we want to regard this as a kind of informational physics, then we can begin with some kind of action functional, in this case the surprisal, or the free energy functional, depending on the situation.

And then somehow...

the thing that optimizes that is a law of motion that describes some kind of dynamical system.

And in the informational or Bayesian case, that is approximate Bayesian inference.

And then once you have that law of motion, you can start plugging things in and get dynamical theories based on certain boundary conditions, like the initial conditions

or data about what these symbols actually mean.

So in the classical case, you're wondering, okay, what is precisely the potential that I'm interested in?

What is the mass?

What is the initial velocity and position?

And in Bayesian mechanics, you might be interested in, okay, where is the boundary for the Markov blanket?

What do my internal states mean?

So what kinds of systems am I actually interested in?

What are they doing inference over?

So what is the environmental states they're trying to infer?

Or at least what do they look like to the system?

And so once you do that, you can start getting from this general law of motion, this general approximate Bayesian inference idea.

you can get actual dynamical things and models of real situations.

And so the reason why that's kind of nice is because then the whole last half of the paper is exactly, well, what does it mean to produce a dynamical system out of this law of motion?

I have this very general idea of approximate Bayesian inference.

What does it mean to actually start writing down models of things?

And it is precisely the worked example

in the latter half of the paper that gives you that back.


SPEAKER_03:
Awesome.

Jakob, Orly, anything?

Or we'll continue 2B?


SPEAKER_00:
Well, not for now, but I'll definitely have some questions later.


SPEAKER_03:
Okay.

Classic.

Section 2B or not 2B question.

But let's go 2B.


SPEAKER_01:
Yes, that's always good, I think.

In this section, it is basically running through the same reasoning at a very high level.

And so this subsection 2b is all about, okay, what is Bayesian mechanics?

What do we mean by Bayesian mechanics?

And in a way, it is kind of...

it plays on this theme of the paper I just mentioned, this On Bayesian Mechanics paper very nicely, because this gives us, okay, here are the basics of what we're talking about.

Here are all the important ingredients.

And then the subsections that follow are trying to build out, okay, what do we mean by it's a physics of beliefs?

And then what do we mean by it's a physics by beliefs?

Because both of these are kind of imprecise terms.

And so defining these phrases in a way that is a little more enlightening is a nice way of fleshing out this section and the contributions of the paper.

So 2B is about the basics of Bayesian mechanics.

And it just...

kind of introduces the idea.

What do we want from Bayesian mechanics?

What is it trying to do?

How does it fit into the free energy principle?

How does it fit into stochastic process theory?

And so you'll see in this section, a lot of it is just building up the idea that systems that minimize surprisal

as the kind of law or the optimization principle that they follow exhibit a kind of law of motion like Newton's law and its approximate Bayesian inference and that that follows from this reasoning about things that synchronize and minimize surprisal do approximate Bayesian inference about the parameters of the probability density of the system to which they're coupled.

So a lot of this section is just the very fundamentals.

And we can go through, I think, equation by equation and maybe clarify what those things mean.

That might be a good way of extracting some insight from this.

So this is exactly what I was describing.

What are the kind of...

important ingredients, what's the basic setting of Bayesian mechanics.

And you'll see on...

Equation on, what is it, page five in equation three, we begin just from a stochastic differential equation.

So this is some kind of random variable that evolves through time according to not only a drift, so some kind of average path or vector field on time,

the value of the random variable at a given time, but also this noise term at the other end of it.

So these are modeled on what we call controlled rough paths in stochastic process theory.

And so you can think of this as just an ordinary differential equation.

with an incoming signal.

And the signal is the noise.

It's this DW thing is what's called a Wiener process.

It's just white noise.

So you have your differential equation, and then you have some kind of random signal coming into it.

The idea of stochastic process theory is, okay, how do we make sense of the kind of equation that we're looking at here?

And in particular, you know, there are a couple of ways of making sense of it.

One of the interesting ones is looking at as this thing produces trajectories, so random sample paths.

how do we understand the statistics of those sample paths and thereby understand something about what the system is doing at an ensemble level?

One of the ways of doing that, and this gets into the next page and the following equations, is by understanding, okay, so what is the probability of a path?

And that's equation five, but that needs some machinery.

We can't just fabricate kind of arbitrary probability over paths.

So where do we get that from?

And that comes from a least action principle, just the same as it did in classical physics.

So that's really the, I think, primary point of this section is just to begin with, or at least one of the primary points of this section is just to begin with, already some of the analogies is taking shape.

because we begin from a least action principle.

So S is, again, an action functional, just like it was in the previous subsection.

And omega is a realization of noise.

You can imagine it as just being one of these incoming signals.

So what is the noise that I'm putting into the system?

And of course, that's where your randomness is coming from.

So that's what we're interested in when we're interested in probabilities over paths, is really how does a realization of noise or a configuration of noise affect the underlying sample path?

And that comes from...

this action.

So the probability is just kind of the exponentiation of this thing, which comes from stochastic process theory.

The same thing arises in the path integral formulation of quantum physics.

So in that context, we're often interested in what is the transition probability of a particle through spacetime.

So that's nothing but asking, what is the probability that a particle moves from point A to point B, given a particular fixed initial point?

What is the probability that it takes a particular path from A to B?

So path integrals are like path probability densities, or at least they produce these things.

So it's interesting and it's not a coincidence that the same thing shows up there, that if you take the action on paths and you just put e to the minus s, then you get a path integral.

Although I've kind of left some details out because that's a path integral for a statistical field theory in kind of

uh, what we call after wick rotation.

And so the, in quantum field theory, we add an eye, it's an imaginary variable, but these things are mathematically transferable.

So it doesn't really matter for our purposes, uh, in what context we talk about them.

Uh, so, so that's, that's where equation five comes from is if we have this action and we just do E to the minus S then, uh,

what we get is a path probability density.

And as you've written there, this, again, it doesn't come out of nowhere.

It's consistent with stochastic process theory.

So all of the sample paths of a stochastic process

If they're continuous, they live in what's called an abstract Wiener space.

And the probability density over an abstract Wiener space is exactly this e to the minus s thing.

So that's where that comes from.

And it's nice that that kind of falls out of Bayesian mechanics very naturally.

So if you begin from the reasoning that we want an action, an at least action principle, and that tells us something about the trajectories of the system, then there is a very canonical way to get back the Wiener measure.

It's not surprising in some sense, but it's nice that it's consistent with that.

So

I talk a little about, okay, what is this?

What does this mean?

And how is this equivalent to a surprisal?

Because I think that's important too.

Um, and, uh, so the action that I talked about previously, I guess we'll call it 4.1, um, does come from the, uh,

Yes, so 4.1, that S is equivalent to the surprisal.

And that comes from, if you just put a logarithm on both sides of equation five, you get log P equals minus S. And so if you put a minus on both sides, then you get minus log P equals S. So the surprisal of a trajectory is equivalent to this integral over time of,

the noise squared.

So by the way, I don't know that I defined those brackets, but the brackets just means you take the two things inside the bracket and you multiply them by each other.

So really, this is just the integral through time of the noise squared.

And that that is equivalent to the surprisal is more interesting for our purposes because it means the converse also holds.

If you start from the point of the abstract Venus space and you write down the correct action, then you get Bayesian mechanics back as the idea that something that minimizes its action in the Bayesian mechanical setting minimizes its surprisal.

So I'll let you write that down.

And then we can carry on, I think, from page seven, because the rest of page six is just saying all of that.


SPEAKER_03:
Sure.

I think surprisal may be more conventionally understood in a statistics framework, but what is action?

And is this related to me moving my arm action, or what do we mean by action here?


SPEAKER_01:
Yeah, so in the context of physics and mechanics, an action is a function, so it takes a function and it gives you back a number.

And as a functional, what it does is it gives you a kind of a weight or a cost associated with a trajectory.

So if you write down a path through space or through spacetime as a specific function,

then the action takes that function and gives you back the cost of taking that path.

And so the idea in classical mechanics is, okay, the cost associated to a path is based on how much extra energy does it take if you take that path from A to B.

Um, and extra energy is kind of circular in the sense of kind of presupposes the, uh, least action path exists, but then, uh,

If you'll allow that for a moment, then the idea is, okay, so there should be a path that uses the least extra energy to get from A to B. And in doing so, it produces the least cost.

So finding the least action path, the path of minimum action.

is the optimal way to get from A to D. And in classical physics, paths of least or stationary action, more generally, are the only acceptable paths.

When you start to introduce noise, it becomes a probabilistic judgment.

So paths of least surprise are the most likely paths.

You have other ways to get from A to D as well, if there are very large fluctuations, for instance.

So in that sense, you can think of action as kind of a loss functional, or something analogous to it in the machine learning world, because it is a judgment about how good a path from A to B is.


SPEAKER_03:
Before we go to the next section, Ali or Jakob, do you want to add anything?

Okay, that was page six.

Now we're going to page seven.


SPEAKER_01:
Yeah, so then I go on with this story about synchronization, which is introduced here in some greater detail than has previously been done, I think, which is one of the points of the paper.

So I begin by saying, okay, let's take two random dynamical systems, which I call eta and mu,

This is kind of, well, it's not kind of, it is an abuse of types.

So just be aware when you're reading this, eta and mu are states of the random dynamical system.

But a random dynamical system is a bit more complicated than that.

There's more machinery going on in the background.

However, just like we would write a big capital X as a random variable, so we name the SDE after the values of its states, we can do the same with the random dynamical system if we wink and nod and remember that that's not quite correct.

But it's also worth pointing out that a random dynamical system can be identified with an SDE under the right circumstances and that you do so very easily.

So this is totally consistent with the previous discussion.

And I have a paper forthcoming that does that in a bit more detail.

So it's continuing along these lines and saying, OK,

If we begin from this Bayesian mechanical story of systems that are coupled to each other do inference, and if they are random dynamical systems, then that inference is meaningful and comes with a path probability density and all this.

That's in greater detail in this forthcoming paper.

So anyway, that's kind of technical remarks, but just keep in mind in that first sentence, there's a bit more going on there, but I'm allowed to do that because it all works out anyway.

And then we begin with this thing about synchronization.

So when you consider coupled systems, then those systems synchronize.

So there's some relationship between the statistics of those two systems.

And that is this sigma function that is given in earlier literature by people like Carl and people in his group.

So the sigma is relating the average internal state to the average external states.

It's even called the synchronization function in that literature.

And in this case, we actually also want to be able to say not only a state at a given time, but also that the paths of the system synchronize.

So taking it a little bit more generally than has been written before,

you know, we now want to be able to say that, okay, so now, uh, the, the trajectories of the random dynamical systems, um, synchronize.

So how one evolves depends on how the other evolves, which is, um, conceptually is, is fine.

Um, and relates all to things that have already kind of been worked out like active inference, you know, how an active inference agent evolves through time depends on how its environment evolves through time and vice versa, because, um,

Active inference agents can act on their environment and change it.

So, and, you know, control systems more generally are things that fit into this trajectory based formalism.

So then I talk a little about surprisal.

So what does it mean that systems that synchronize minimize their surprisal?

And there's a lot to detail in this section.

There's a lot of stuff that goes along with that statement.

But ultimately, it's just saying that systems that synchronize with each other

um almost by definition are minimizing the magnitude of fluctuations away from whatever is being synchronized to so this relationship means that you are minimizing your surprisal if surprise was defined as deviations away from the thing that is being synchronized to so that i think um again that's that's almost um a tautology but uh

That's, I think, kind of the power of the framework is you begin from the statement that makes almost trivial conceptual sense.

And then it gives you some kind of actual useful model of what the internal dynamics of some system are doing.

And that's at the end of page seven.


SPEAKER_03:
Great.

i'll ask a specific and a general question from the chat so first the specific question and just let me know which equation to look at martin biel asks what is the relationship between x of t and gamma


SPEAKER_01:
Gamma is a path, so it's a realization of xt, the random variable.

X of t is just another way of writing gamma.

I do it in a couple of different ways, just to drill down the point that lots of different

literature, lots of different ways of seeing this thing are all the same.

So for instance, gamma is used in the literature around maximum caliber, which is maximum path entropy.

X of t is kind of consistent with this functional idea, so regarding a path as a function, and then plugging it into the functional and seeing, OK, what is the surprise?

What's the cost associated with this path?

And you'll also see, I think, Q of t later in the paper, and that's interesting because Q is the variable and Q of t is conventionally used in classical physics literature, just again as a mathematical convention.

So anyway, yes, to answer your question, gamma is just this X of t, they're different labels for the same object.


SPEAKER_03:
Okay.

And Martin follows up.

Is this synchronization an additional assumption to Bayesian mechanics, or is it part of the assumptions for it?

And then is X of T gamma of T?


SPEAKER_01:
Um,

Okay, so the idea of synchronization is critical to Bayesian mechanics actually telling you anything useful because the whole story about coupled things do inference on each other is something that follows from this synchronization.

So the whole story about approximate Bayesian inference follows from the coupling.

So synchronization is an important assumption.

One thing that you can do, however, is to prove that things that synchronize are coupled and vice versa, things that couple are synchronized.

And this is at least shown in...

paper I have from earlier this year called Towards a Geometry and Analysis for Bayesian Mechanics.

I believe that's in Lemma's 4.2 and 4.3, and maybe theorem 4.2.

So it's shown that if you write down two coupled systems, then you can get the statistics to synchronize.

That's not really, it wasn't difficult to show, and it's not really surprising.

but that is something that you can show.

Gamma of t, I don't think I use gamma of t in the paper.

Maybe I use gamma sub T, so gamma T, like sort of offset from the main line.

Gamma sub T is, again, the same notation that's used elsewhere.

So it just means a path at a particular time point.

So it's just a state, a realization of the random variable at that time.


SPEAKER_03:
Okay.

And then the more general question before we head on was from Dave, who wrote, what does using energy mean?

For example, is that extracting potential energy and transferring that withdrawal to kinetic energy or the relevant analogs?


SPEAKER_01:
Yeah, in the context of an action functional, that's exactly what it means.

So this transfer of potential energy to energy of motion, which is kinetic energy.

Yeah, I think there is a discussion of this, a kind of conceptual discussion of this in the On Bayesian Mechanics paper.

somewhere in section two, I think.

And it's the idea that, okay, when we talk about minimizing action, it's about you have some energy budget, your potential energy, and you want to know, okay, what is the most efficient way of using that budget?

What is the most, what is the way that transfers potential energy to kinetic energy with the least accumulated loss over time?

And

Physically, that is just following a force gradient.

So if you try to do extra, if you try to wiggle your way through the force gradient, you now need to invest more potential energy, but you're getting to the same spot.

So that's not necessarily what you want to do.

So this is why the Euler-Lagrange equation is kind of interesting because it tells us what we intuitively expect is the most efficient way of transferring energy

an energy budget to actual motion is just following along a force gradient.

And that's why we see things like Newton's law that the acceleration of the system is always the force acting on it or is in proportion to it anyway, because you also have this mass constant.


SPEAKER_03:
Awesome.

On to page eight, equations six, seven, and eight.


SPEAKER_01:
Yeah.

So this is setting up the equation,

the variational free energy.

So we have in six and seven, we have the kind of traditional factorization that we've seen in a lot of this literature, which is here is the free energy functional with the joint density, the kind of generative model.

And then if we take out this extra surprisal term, then we get the variation of free energy in a kind of reduced form, which bounds the actual surprisal of the internal states of the system, or the particular states of the system, the blanket and the internal states.

So then this...

kind of sets us up to say, okay, then if the system is synchronizing well, so if it's minimizing its surprisal and it matches the mode in the first log term, then that bound vanishes and we are putting a bound on the surprisal of internal states.

And then equation eight just states it again in the setting of paths and not states.

So you have these functions, eta of t, mu of t, is about the evolution of the system through time.


SPEAKER_03:
All right, Jakob, Orly, anything you want to add there?

okay now we get to the physics of and by beliefs we could have completed the constitutional trifecta with the four beliefs also some very interesting connections that jacob and i and others have explored with grammatical case for example the physics of belief being the genitive

case whereas the physics by belief might be like the instrumental case and that might point towards natural and semi-natural languages to describe beliefs but just broadly what is happening in these sections and how do we get towards equation nine yeah so in this uh section it's just two the the you know at the end of the previous section um synchronization gives you surprise minimization


SPEAKER_01:
And in section C, I'm using the building blocks to actually make that statement.

So approximate Bayesian inference is about how a system's beliefs behave, given that they need to match some kind of density over the environment, and where match means not necessarily equal, but synchronized to.

So this is what we mean really by physics of beliefs is the context for Bayesian mechanics is certain kinds of systems that are coupled to their environment or that are coupled to another system synchronized to that other system.

And as a result, we can understand the statistics of one system as synchronizing to the statistics of the other system.

So any kind of belief updating or any kind of large deviations principles or anything that we can use to understand the statistics of one are done implicitly in the context of the statistics of the other.

And again, this is what we mean by physics of beliefs, is suddenly we have now formulated a kind of law of motion for the beliefs of the system, which is to do with synchronization and approximate Bayesian inference.

So the idea that we can understand

sometimes literally motion in the sense of motion on a statistical manifold, movement in a space of beliefs.

We can understand it as being a response to the pressure to minimize surprisal given whatever you are or the system is synchronizing to.

That's really the main thrust of this section.

and I talk a little about exactly what does that mean and what is the point of synchronization.

I don't think there are a lot of equations in this section, but it's about that.

It's about

Okay, synchronization is a thing that we've talked about a lot, and we've talked about it in the context of minimizing surprisal, but it's important to set up the idea that when we talk about basic mechanics,

It is partially about the system itself, but what makes it kind of special is it's about the beliefs of the system.

And it's saying, okay, here is a way of understanding coupled systems by forgetting about the systems themselves and going into synchronized beliefs and understanding how does synchronization affect the probabilities that we assign to system states.


SPEAKER_03:
Hmm.

Great.

So that's of beliefs.

And now we go to by beliefs.

Oh, first, Jakob.


SPEAKER_02:
Mm-hmm.

Yeah, I'm just wondering, how would you say that active states are formalized within Bayesian mechanics?

Because I feel like sometimes there's this kind of duality where we can say that systems can be described by Bayesian mechanics, and we say that they act as if they're performing Bayesian inference.

Then there are also systems which, in this kind of conventional sense, do perform Bayesian inference through some active states.

So I'm just wondering, how do active or even sensory states fit within Bayesian mechanics?


SPEAKER_01:
Yeah, that's a good question.

Because as you said, sometimes, especially for very simple systems, this is a kind of mathematical technique.

It's even a trick in some sense.

That's not to say that it doesn't work, but it doesn't have the kind of...

epistemological sense of belief, or if it does, you've got to do a lot of work to make that make sense.

And I am kind of... There's a lot of philosophical debate about this in the literature, and I know there's a corner of literature that is specifically about do things actually minimize their free energy, or is it just a useful model?

I'm kind of agnostic.

I think the whole question is...

basically irrelevant.

Um, because the, the reality is whether or not it is true in a literalist sense, or is just a model or, or whatever at the end of the day, the maths works.

So yes, you have to be careful about acknowledging the limitations of the maths to describe the actual physics and the biology, but you should be being careful about that anyway.

Um,

And I acknowledge that maybe I'm being a bit unfair because I'm saying the question is irrelevant and then going on to say, you do have to be careful about the question.

But at the end of the day, it is just maths.

And so whether the maths is a true model of a system or is a model of what we think the system is doing,

is kind of a silly question being phrased that way.

And the reason why is because the maths is always just a model.

I think something like that point was advanced in a paper by Mel Andrews, where it's said that the FEP is just a model of a system.

And whether the model is any good or not is strictly separate from whether the model is true or not.

And in general, models are not true in the sense that

No system is actually sitting down and calculating, okay, here is the root of my free energy functional.

Here is what nature says I should be doing.

I'm going to go do it.

So anyway, that was kind of a digression.

That wasn't directly your question.

The reality is, yes, it is a kind of a mathematical trick and the maths works, but it doesn't always tell the satisfying conceptual story that we want to hear.

So I think...

You're right, the big difference is to do with how active the system is, because systems that can actually do actions do have a use for storing representations.

And, you know, we think about things like controlled systems in this sense, which are systems that aren't just minimizing their surprisal as a mathematical truism that unsurprising systems do unsurprising things, but they are systems that exist in an environment that is trying to dissipate them actively because they are very far from an equilibrium point and they need to know that

know what the environment is doing in order to know how to respond to it.

So active states do draw a pretty clear line between, and I should say as well, sophisticated active states, because you can think of things like

the active states of a stone.

They're not very sophisticated, but a stone does kind of, for instance, irradiate heat back into the environment.

So that is an action.

It's just not a very interesting one.

But sophisticated active states draw a pretty clear line between genuine Bayesian inference and just kind of like applied statistics, so to speak.

And it's something that I haven't really thought deeply about, except to note that this is a place where there is a distinction to be made.

I talk a little about this in the geometry and analysis paper that I just mentioned, and it shows up quite a lot in the forthcoming paper that I mentioned in the last session, which is by

Lance and myself and Carl and a few other people, and it's called Path Integrals and Particular Kinds.

In that paper, I think I mentioned in the context of an interesting calculation to do with moving frames of reference, but additionally,

there's quite a lot of work in that paper.

And one of the key deliverables of that paper is here are a number of different kinds of free energy functionals, which are defined by different kinds of partitions.

So a partition that has active states and a partition that doesn't.

And what are the qualitatively different kinds of behaviors that we're able to describe?

And one thing, one case that that paper tries to make is that there are

interesting systems and non-interesting systems and there are lifelike systems and not lifelike systems and that they exhibit very different behaviors when they minimize their free energy including you know lifelike systems are able to minimize their expected free energy so they're not just

you know, it's not just a case of applied statistics.

They're actually, one presumes, holding a model of the world and making predictions about the world and taking actions now that minimize free energy in the future.

So that's a bit more sophisticated than just a tree branch shaking in the wind, because it would be kind of surprising if it didn't, you know, that's

That's a law of physics.

It would be surprising if the tree branch didn't shake in the wind.

But to say that the tree branch is doing Bayesian inference over its environment is only true in this, I guess, instrumentalist sense.

I don't know if that's actually the right word for it.

I think that's a word from the philosophy literature that I'm not qualified to use properly.

But it is true in the instrumental sense that

That is an instrument that we can use to describe the dynamics of the system.

It's not true in the kind of literal cognitive sense that the tree is now forming a model and making predictions about its current state and state of the environment.

And there may be panpsychist types that would disagree with that.

But that's the view I take anyway.

So this is a very interesting question.

I hope that answered at least part of it.

Jakob?


SPEAKER_02:
Yeah, it definitely did.

I'm just also wondering whether on your point where we have sophisticated actions and not sophisticated actions, whether that could also be a consequence of the complexity of the environment.

Because in the case of just a tree branch being shaken by the wind, we just have one type of mechanical force that the tree branch is synchronizing to.

but in a more complex environment with living systems, there are many more of not explicit forces, but maybe cognitive forces or biological forces that the systems might need to couple to.

So I'm wondering whether the formalism could also

not be adjusted to the complexity of just the individual entity that we're interested in, but also to the complexity of the influences of the environment that the system couples to.


SPEAKER_01:
Yeah, I think there's definitely remit to say that simpler systems can only infer simple things, and so they do best in very simple environments.

More complex things

In a way, and there are arguments that this is why structures like the brain evolved.

Actually, I believe, I suppose he's listening.

Martin Beale has an interesting paper about this.

And I forget the title, but the point of the paper is there's a very neat hypothesis that the brain evolved because it's very good as a biological structure at handling what's called counterfactual information.

So the brain evolved as a prediction generation mechanism.

So there's remit to say that complexity of an individual scales with the complexity of the environment because something like a human that wants to self-organize very far from equilibrium, suddenly there's a lot more to keep track of because there's a lot more acting on you to keep you down, so to speak.

And so you not only need complex sensory motor loops to respond to all that complexity, but you need a complex processing hub to actually deal with all of those variables and categorize all that information and decide, OK, what are my sensory motor loops doing in this situation?

How am I actually responding to the things that I'm observing?

So yeah, definitely, there is an interesting story to be told with how the complexity of the outside determines the complexity of the inside.

And it is kind of, again, a very nice meta application of the FEP.

Because if we think that, you know, if we want to say that things that self-organize are things that mirror their environment,

then it is precisely the claim that if you want to be a complex thing and you are subject to very complex environmental forces, then you need to be a complex thing to self-organize.

And this is the kind of good regulator-type theorem that has come to characterize discussions about the FEP.

So yes, another interesting question.


SPEAKER_03:
Great.

Well, just to carry forth and get a first pass and everything, although of course the door is always open for .3s and beyond, in Section 2D, the Physics of Beliefs, we have Equation 9, 10, 11, and several more.

So where do we get to by the end of Section 2D?

What's the key piece here?


SPEAKER_01:
Yeah, so in the previous subsection, I spent a lot of time building up the idea that Bayesian mechanics is a kind of a special way of thinking about laws of motion in the space of beliefs.

So motion on a statistical manifold, which is one really interesting thing about it.

And that's of mathematical interest, maybe, because it's now saying, okay, here are some kind of new dynamical systems theories on statistical manifolds, which is quite cool, and it does...

I think that's interesting on its own.

But if you are into physics or biology, that's not quite enough.

The nice thing is that there is this idea that, okay, it's not only about laws of motion in information geometry, but it's about mapping

a system which has some kind of physics in the real world into a ideally simpler physics in statistical manifold.

in virtue of talking about synchronization as a law of motion for beliefs, we are now saying, okay, we don't need to talk about the material physics underlying the synchronization.

We can go into this space of beliefs and we can say, okay, synchronization tells me that the system's beliefs are changing this way and that reflects a physical change of this nature.

So it's an equivalent way of talking about real physics.

So we have a physics of beliefs and that this maps back and forth between a real physics.

So we should then be able to make inferences about real systems using Bayesian mechanical laws.

And this is what is meant by a physics by beliefs is if we invert the story and say, okay, now I want to know what is this, what is approximate Bayesian inference saying about the mode of the system, about the parameters that are doing

approximate Bayesian inference.

And you can do that.

You can make inferences about the system itself.

And if your inferences are good, then you learn something about the system.

So that's very general.

And that's also subject to surprise minimization.

So if you are unsurprised, then you have a good model of the system.

So now the whole story applies to itself in some sense.

If you minimize surprisal about your beliefs about a system, minimizing surprisal, then you can get a model of how that system is self-organizing.

And you hope that the loop kind of closes.

So this is, I think, quite an important point.

It's the subject of a duality relationship that I gesture at and think

write a lot about in the Geometry and Analysis paper.

It also shows up in a paper called the Map Territory Fallacy.

It has fallacy twice in the title.

And that's by myself, Maxwell Ramstad, and Carl Friston.

And it investigates the idea that you can actually turn the story on its head and make a model of a system making a model of its environment.

and that that's insightful for various reasons.

The, the interesting thing about that is, um, it now gives you a physics by beliefs in the sense that now my, um, my description of what the system is doing.

Uh, so my description of the material physics is inferential.

It's based on my beliefs about what the system, um,

is synchronizing to and how well is it minimizing surprisal.

And it's also based on how good my model is.

So it's based on whether I can minimize my own surprisal and make good inferences about the system.

And this calls back to the principle of constrained maximum entropy, because what that's saying is my model of the system is an inference of the system subject to the constraint that

the model of the system reproduces surprisal minimization.

So any model that I have of the system must say that the model is itself or that the system is itself holding a model of its environment and is minimizing surprisal.

So that's where the constraint comes from.

It's that this is something that we know a priori, so it's something that we should incorporate into our model of the system, this surprisal minimization.

And just working out the maths of that is all of these equations.

So it's showing that if you put a constraint that your model of the system includes surprisal minimization,

then you get back exactly approximate Bayesian inference.

So there is this other route to Bayesian mechanics that just says, OK, if we begin from, and in reality, and the point I try and make is that it's not actually a different route to Bayesian mechanics.

Because all this is saying is, if my model of the system begins from the point of view that systems that synchronize minimize their surprisal,

then I get back the minimization of free energy and surprisal in the context of the system.

So kind of nuanced, I think.

There's a lot of moving pieces.

But ultimately, that's all that means when we say physics by beliefs is it's the application of the constrained maximum entropy principle

to create a model of a system which is minimizing its surprisal.

And what's interesting is that that model itself is subject to the laws of Bayesian mechanics because it is a probabilistic belief.

So it's like saying I'm sitting in the environment

And I'm synchronizing to the system, which is synchronizing to me.

And if I make a good model of that system, I incorporate the knowledge that it is doing approximate Bayesian inference.

That shapes my own approximate Bayesian inference about the system.

There's this symmetry to the problem that falls out of very first principles considerations.


SPEAKER_03:
Excellent.

On to section three, a general equation for Bayesian classical mechanics.

So it'll be helpful for you to situate where it begins and then how we approach equation 15.


SPEAKER_01:
Yeah, so this section is kind of taking those building blocks.

OK, so we have a way of modeling systems that model their environment, and it's this kind of dual suprisal minimization problem.

So how do we actually write that as a problem that we can solve?

How do we do computations with this thing in the context of classical physics, especially?

And also this analogy that we talked about previously, does that go through to this case?

You can build up this idea.

You can build up the idea of a classical physical system that couples to its environment.

And it is, in this case, a force that acts to separate the thing from its environment.

So again, there's a bit of an abuse of types in the sense that we would usually consider a sensory state experiencing or measuring that force.

But instead, I just plug in the force itself under the assumption that it's not a noisy sensor, maybe.

And that proves to be, again, not a taxing assumption because it tells us the same story at the end.

You can deduce everything that you'd need to.

So you can set up a synchronization function in that case and it just tells the system what the environment is probably like given the force acting on the system and already you have the ingredients for

approximate Bayesian inference, because you have a conditional independence.

So the system doesn't need to know what the environment is like if it knows the force acting on it.

So you can argue that there is a conditional independence there, or at least a sparse coupling.

And you have an inference problem because the system does need to know what to do given the force acting on it.

So it does need to know what is the environment like given that force.

And it can only do what it needs to do if it is minimizing surprisal.

So all the ingredients are there.

And you can also talk about the fact that

The classical action is the Bayesian mechanical action in the limit of no uncertainty.

So you do get surprisal minimization as equivalent to classical action minimization.

And that's ultimately the chain of reasoning that gets us down to equation 15, is that the...

the path that minimizes the classical action is the mode, so it is the most likely path, so the path of least surprisal.

So you can structure classical mechanics as a least surprisal problem.

And that gets us down to equation 15.


SPEAKER_03:
Excellent.

While I bring 15 in, Ali or Jakob, any thoughts?

So maybe could you read equation 15 with the variables and or the natural language semantics?


SPEAKER_01:
Yeah, I'm a big fan of that.

I think that's a useful way of breaking things down is explaining the objects being involved.

And there are people that really take that philosophy to the extreme, to the extent that I've seen talks where you're not allowed, the chair of the session says, okay, you're not allowed to just tell me the name of the thing.

You need to explain to me what the thing is and what it's doing.


SPEAKER_03:
I believe, isn't that a case of the chair doing inference on you?


SPEAKER_01:
Yeah, well, maybe.

In fact, probably it is, yeah.

How do I best fit this into my world model?

Well, tell me in terms that I understand.

Yeah, explain it to me.

That's really what it is.

Yeah, so here we have the path probability density.

So it's the probability of a classical position Q at a time T, which is a joint density in this case.

It equals the exponential of the minus of the action that we saw in the basics of Bayesian mechanics section.

So it is the normal path probability density.

And the only question is, okay, what is S?

Excuse me.

So we've plugged in something interesting for S. It's the integral over time of the...

deviation of the classical path Q from the path of least action, where the path of least action is defined as the double integral of the force divided by the mass.

So the double integral of an acceleration, which is just a position.

So given that we know the initial conditions,

what is in the vertical bars, so what is being squared, is just the deviation of Q, the classical path, from the expected path, or the path of least action.

Excuse me.

So this is precisely the classical action.

in the sense that it gives you back the path of least classical action, gives you back the path that follows Newton's laws.


SPEAKER_03:
Excellent.

So to bring it closer one level, what variable might we be talking about?

Like what kind of data set or variable might Q be?


SPEAKER_01:
In classical physics, we're mostly interested in spatial positions.

or at least generalized coordinates describing those spatial positions.

But more generally, we could talk about a lot of things.

Q could be really anything.

One of the nice things about

random dynamical systems and random variables is there is a great generality in what that state could represent.

So in general, it's just a label for something.

Here in classical physics, yeah, we are interested in positions, spatial positions.


SPEAKER_03:
Okay, so it could be how excited I am about a song or my belief about the temperature or what this person's next sentiment is going to be.


SPEAKER_01:
Yeah, yeah.


SPEAKER_03:
All right.

Anything else on three or it'll be great to move to four?


SPEAKER_01:
No, I think that's really the story about three.


SPEAKER_03:
Awesome.

Well, four.

Ali, would you like to set up or introduce how you see section four and what you wanted to ask?


SPEAKER_00:
Well, yeah, actually, if you permit, I wanted to make a somewhat lengthy comment here.

If I may, not too long, I promise.

We're going to need 0.3, I think.

I'm following that with a question.

You see, as we know, there are numerous approaches proposed for driving classical properties from

quantum matter, so to speak.

But I wanted to mention two, among which, to my mind, are particularly congruous with Bayesian mechanics view on quantum physics.

I'm not sure if you're familiar with causal fermion systems.

approach developed by Felix Finster and others, because it's not a particularly well-known theory.

But in any case, it's basically another variational approach for explaining the emergence of a structured spacetime with all of its associated phenomenological properties, such as the flow of time, the chain of causal events, and so on.

from an optimal configuration of self-organizing quantum wave functions.

But instead of defining the action functional as the surprisal to be minimized in order to achieve the optimal inference, as we saw in Bayesian mechanics, they define the causal action as the action functional minimizing

which leads to the optimal configuration of wave functions, which in turn results in the structured spacetime properties.

And the other approach I wanted to mention is

quantum Darwinism proposed by Wojciech Zurek, inspired by the principle of natural selection, which attempts to explain how the most stable pointer states are favored among the many possible quantum states and

thereby resulting in the classicality of our everyday observations.

Actually, this approach is also alluded to Fields et al.

's paper Free Energy Principle for

generic quantum systems, I guess.

So do you see Bayesian mechanics as ultimately unifying all these different approaches somehow into an M-theory-like integrated theory?

Because in your recent paper on the map territory fallacy-fallacy, which you mentioned, FEP is already shown to be the ideal

modeling tool for generic systems in statistical physics.

So can this statement be potentially extended to encompass all the other physical systems as well?


SPEAKER_01:
Yeah, that's a good question.

I'm not familiar with this causal fermion systems work, although it sounds like it fits into a kind of spirit of question that exists in condensed matter theory, asking about, OK, how do things emerge that have a given structure?

from things that don't have structure.

And especially the word causal seems interesting because a lot of condensed matter people are very interested in information theory very recently.

But anyway, yeah, so there is similar work in condensed matter by people like Michael Levin, who's not the Mike Levin that does developmental biology at Tufts, which is kind of interesting.

It's a different Michael Levin.

And Levin and someone called Wen have developed things like string net condensation, which is all about how do... Well, I guess at a high level, it's about how does structure arise from the application of constraints to...

I guess you might call them self-organization in... You might call them self-organizing field theories, although that's not the language that Levin and Wen use, and I think that's kind of...

Telling the wrong story, maybe.

But there's something there, definitely something to be generalized.

And likewise for quantum Darwinism, there is this idea that the things that we measure as the most certain or the classical states arise from a...

spatial interaction component.

So things that couple to other things have well-defined measurements.

So, you know, pointer states because of this localized interaction.

I apologize.

So, you know, this is as a resolution of, I think, the decoherence problem.

This is one interpretation, and it just remains to kind of make that more mathematically rigorous.

And, you know, people like Sean Carroll have written about this at length.

So in both cases, there is kind of a

Yeah, an intersection of ideas.

And they both seem very Bayesian mechanical.

I think one of the nice things about Bayesian mechanics is it's very general.

It's just a story about how constraints and superficial minimization and statistics interact to get you a model of a physical system.

So...

In principle, that is very general.

And you start to add extra constraints and things like the Markov blanket and whatnot.

But

there is probably remit to generalize this even further to something that is purely about how do paths that synchronize behave probabilistically.

And that is very general.

And that probably applies to more than just conventional classical statistical physics, but maybe other aspects of quantum mechanics and condensed matter theory


SPEAKER_03:
and and so forth great thank you well in our last 30 minutes of the dot 2 with of course the dot 3 on demand let's get to those worked examples and we will look forward to a thousand notebooks blooming

with people simulating and making interactable visualizations and extending some of these examples.

It'll be great though to hear what are the real world situations that you are applying Bayesian mechanics to.

And then what do each of these equations do on the path towards application in each of these settings?

Previously, we discussed the three faces of Bayesian mechanics.

Could you just review the three faces of Bayesian mechanics in light of where we're going to go in the coming applications?


SPEAKER_01:
Yeah, of course.

The pyramid that you see here at the bottom layer is all of these

I guess, boundary conditions specific applications of the FEP where the boundary condition that we're interested in is whether the mode being matched, whether the thing that we're synchronizing to is a state

Uh, and then you have states and paths.

That's the first split.

And within states, you're also interested in, okay, is that state in motion or is that state fixed?

Uh, and this corresponds really nicely to a story in classical mechanics about, um, forces in equilibrium, uh, forces being applied and, kind of continuous forces, uh,

which the examples I used are an object at rest, an object that is moving to a point at which it would rest, and an object in constant motion, like something in orbit.

And specifically for the middle one, I think I use a ball thrown in the air.

And so eventually, it comes back down to Earth and rests on the ground.

And then the celestial body, a planet in orbit, is your path tracking.


SPEAKER_03:
Yeah.

Okay, so we have the analogy very clear, and we can say rigorously supported.

The left side, we're talking about synchronization to states, like parameter values that are instantaneous, whereas the right branch is the density over path, so the synchronization is to a path.

On the left side, we have fixed and dynamic mode,

the mode mode fallacy fallacy and that is matching to uh a ball at rest and a ball thrown in the air on a parabola that will come to rest and the satellite motion is the infinite chasing now

We're talking about cognitive systems.

So what are the cognitive analogs or the real world cognitive settings where we're talking about some cognitive entity like a computer or a person or an ant colony rather than perhaps a ball on a hill?


SPEAKER_01:
Yeah, so this is a good question.

I think in the path tracking case, at least, it's pretty obvious that this is active inference.

This is a very general blueprint for what it means to be in a dynamic environment and to constantly be synchronizing to an environment that's changing and that maybe you yourself are changing.

And that's maybe something that's worth commenting on.

It's only this last case that is the kind of stuff that we're interested in, in terms of worked examples when it comes to genuinely cognitive systems.

And it's this last case that we know the most about in terms of worked examples.

So it's the case that hasn't been really worked out in terms of rigorous maths, although that's in the last six months or so, that's what's been being done.

not only with this paper, but also with the path integrals paper that's about to come out and the free energy principle made simpler, but not too simple.

And also Lance and Carl and Greg have a paper called geometric sampling methods in optimization and adaptive agents, where this is also talked about.

So in a way, this is the case that we know the most about.

And it's the case that

works the best.

It's the case that actually explains the kinds of stuff that we want to explain.

But the rigorous maths hasn't been done in that case.

The simpler density dynamics formalism is much less useful.

and to some extent suffers from its own problems in terms of edge cases and maybe mathematical confusions.

So there is some cleaning still to do with the density over states formalism.

But again, ironically, that's the formalism that we care the least about.

And what we're most interested in is making the path tracking make more sense and making it more complicated and generalizing even past it to explain things that synchronize two paths in a more complex way.

Um, so, so the path tracking is about, uh, these kinds of things.

And one way to think about them is in terms of expected free energy.

So, you know, not only, um, minimizing my free energy right now, but minimizing my expected free energy along the path.

Um, that's, that's one way of thinking about it.

And another way of thinking about it is minimizing the surprise of the path.

Um,

So mathematically, that works nicely, but it gives you a bit of a different story, and the expected free energy is nicer in the context of cognitive agents because it gives you this idea of prediction and action back.

The density over states formalism is much simpler, and it doesn't apply...

much, doesn't apply very strongly to very complex agents.

You can think of it as an instantaneous approximation to the path tracking.

And so in that sense, there are things that are cognitive and do fixed mode tracking.

or what we call mode matching.

But if you think about it, that is, again, an instantaneous approximation to the path tracking setup.

So if you think about something like URI, we're usually not matching a mode because that means we are staying completely still and our environment is staying completely still.

And that happens mostly at depth.

which is, it is something that we can talk about.

We can talk about a system at total rest, but even then the analogy breaks because the environment still isn't at rest only on very brief timescales.

Can we approximate it as being at rest?

And it's also not the story that we're looking for about cognitive agents.

So the fixed mode and the dynamic mode are mathematically interesting, but I think when it comes to the biology and to some extent even the physics, they're not very interesting.


SPEAKER_03:
Very interesting.

So maybe as we scan through these equations, just what are each equation doing within the example?

So we're in terminal mode matching section 6A, and we see equation primarily 17.


SPEAKER_01:
Yeah, so equation 17 is just giving you...

I think we skipped section five, which is the mode matching.

So maybe I do want to just quickly mention that when you have forces at equilibrium and you have an initial condition of zero, this is in equation 16.

then the path of least action is not a path at all.

It's a stationary object.

It's an object at rest.

And so you can do this very easily.

You'll see I write Q minus zero squared equals zero.

So the surprisal, that is the surprise, right?

You're not integrating through time because you're only at one time point.

So the integral goes away.

And the double integral of the force over time is just zero because the forces are at equilibrium.

the surprisal is minimized when Q equals zero, when there is no motion and the system is at the mode.

In this case, you can imagine Q as a generalized position corresponding to the height above the ground.

So when Q is on the ground, not moving at that time point, you are minimizing your surprisal.

And that's what we call mode matching.

And again, you see this is a very simple setting because literally nothing is happening.

And that's not really fit for describing cognitive agents, but it is a good simple case just to make sure that all the maths works in the simple case.


SPEAKER_03:
yep i'm imagining this to be our belief about the room is that it's 37c and the thermometer is giving us 37 37 37 so the mode instantaneously is not being updated and that's kind of like a balloon is being inflated and it's pressure matching or the ball is on the ground so the forces are canceling out

on the statistical distributions the bayesian surprise is zero the prior and the posterior are the same we're in the most static possible situation


SPEAKER_01:
Yeah, exactly.

There are no, if you want to imagine again, this physics of belief setting, there are no forces acting on me between observations.

There are no probabilistic forces changing my beliefs about the system.

So the mode is stationary.

I'm always matching the same mode.

So nothing's happening, no movement on the statistical manifold.

And therefore, we get mode matching.

It's a very trivial case.


SPEAKER_03:
Now we introduce some forces into the picture with mode tracking.


SPEAKER_01:
Yeah, so mode tracking is a little bit more complicated because you have an actual inference.

You're interested in where something is and also how to get to it.

And there's kind of an open question somewhere in this section.

which is about, or maybe in the following section, which asks, um, is a least surprising path to a, uh, target mode, also a, um, instance of mode tracking.

Right.

Uh, and I actually, I don't know that, um, that's something that is open for me.

I think we'll encounter it somewhere.

Um,

Yeah, I don't know.

Well, we will stumble into it anyway.

But anyway, it's the idea of, okay, so we want to do inference about where is a mode that I'm not at and how do I get there?

In this case, the example is of a ball being thrown through the air.

So again, thinking of Q as a generalized position corresponding to the height above the ground, I start at some initial condition above the ground.

And gravity is the force acting on me, telling me the mode that you want to be at is at rest on the ground.

So in some sense, you can read this, you can read a ball being thrown through the air and then falling to the ground as doing inference about what gravity tells it to do.

And if you write this out, there is an equation of motion, which is a path of least action.

And it's just this parabolic path to the ground.

And if you plug that in and you minimize the surprisal, then you get a system kind of goes like that.

And what's more, you can write this as a gradient ascent on surprisal.

So it's, well, a gradient ascent on the probability density, a gradient descent on the surprisal.

So it is literally a minimization problem because you can get back the equation of motion from a gradient descent on the surprisal.

And that is interesting.

I think we will call it 17.2.

So it's the third equation in this section.

Yes, that's the one.

Right after the first labeled one, which is 17.

So this gradient descent, this minimization problem, gets you exactly the equation of motion that you want.

So you can prove that

surprise minimization tells you something interesting about this case of mode tracking.


SPEAKER_03:
Cool.

I'm imagining a cognitive entity, a physicist, a Bayesian mechanic, modeling in their perception implicitly or in their notebook explicitly the path of a ball.

Mm-hmm.

And the cleanest situation would be if their factorization and understanding of the sparsity of the territory, if their map resembles it.

But no matter, even if it does, it still is a different thing and will be treated under the Bayesian mechanics as being by and about beliefs rather than by and about mass.


SPEAKER_01:
Yeah, that's definitely one way of thinking about it.

We talked a little last time about what it looks like to collaborate and to converge on a belief.

And it's a little bit like that.

If we assume there's no uncertainty about where everyone is headed, and you just want to figure out how to get there.

So if you're like a bunch of people collaborating on an idea and you know where at A and I know what B is, then this says that the best way to get to B from A is just to minimize your surprisal.

That's the path of least action from A to B. And in this case, that means that it is precisely the most likely path that is the path of the classical object from A to B.


SPEAKER_03:
Wow, very interesting since sometimes it seems like we're discussing in a value and preference aligned setting how to do something, policies as inference, whereas there's also a discussion of where to go in all of these other pieces.

We'll just touch on each piece as lightly as possible in a few minutes so we can have a closing round.

In B,

6b, we have tracking of mode, infinite mode tracking.


SPEAKER_01:
Yeah, this is the kind of precursor to the idea of path tracking, which is saying, okay, if that mode is constantly in motion, what does that look like?

And you can do the same thing.

If you write out the equation of surprisal minimization, you can get the idea of continuous motion as well.

Um, but it's slightly more complicated and it is slightly less conceptually satisfying, uh, because it's not surprising minimization.

It's, um, sort of surfing along level sets of the probability.

So it's the probability isn't minimized and, uh, and the, or the, the surprise isn't minimized.

The probability isn't maximized.

So you're not choosing the most likely, um, path, uh,

Which is one of the reasons why I then go on to talk about path tracking in the next section is to say, you know, okay, so we tried to do this thing with a continuously moving mode.

And it kind of worked, but not really.

So what if we said something about minimizing the surprisal of paths?

You know, so that instead of continuous mode tracking, what if we just talked about continuous motion, tracking a path?

do these things coincide?

Do they tell the same story?

And this is where the initial stuff in the basics of Bayesian mechanics section comes into play because now we're talking about path probabilities and minimizing action functionals.

And at the end of the story, you say, okay, so the whole thing does go through.

You can talk about selecting the path of minimum surprisal.

And in this case, it is following along in a satellite orbit based on the continuous forces that are being applied to you.

So at every turn, you have a kind of...

circular force, you have not only a tangential force outwards, but also centripetal force inwards.

And if you write this down appropriately, you can get the equation for a circular orbit.

And so that's what this is doing is saying, okay, if you have this continuous force acting on you, then can you match a path of least surprisal?

And you can.


SPEAKER_03:
Excellent.

And just one last note on the first idea of g-theory before we take a breath in our closing round.


SPEAKER_01:
Yeah, so this is kind of a complicated section.

The point of this section is ultimately to say two things, really.

One is that the case for classical physics is a nice playground, but it's kind of a simple one.

And the aspirations of Bayesian mechanics are to talk about non-equilibrium, complex, self-organizing systems.

So can we pull something more interesting out of the maths?

And it's also to make the case that the path-based formalism is the right thing to look at when we want to pull something interesting out of the maths.

And so the answer to the first question is yes.

And implicitly, that supports the second name, because it says, okay, not only, you know, can we actually get a description of, in this case, chaos versus integrability or...

ergodicity versus non-ergodicity, but also that it comes out of the path-based formalism very naturally.

And in a way, Bayesian mechanics is a little bit special in this sense, because the idea of a path integral approach to classical physics comes out of Bayesian mechanics very naturally.

And the results in this setting come from that path integral approach.

So it implicitly has this kind of third aim that because of this path based formalism in Bayesian mechanics is what did the job, that Bayesian mechanics is the thing that we maybe want to look at in more complex systems.

So that's the aim of this section.

What this section does is it just writes down the path integral for a system in classical physics, given that it does Bayesian inference as per Bayesian mechanics.

So approximate Bayesian inference, if you'd like.

So if you write down a system in classical physics doing some kind of synchronization, you get a path integral with a particular kind of form.

And then you can transform this a couple of different ways.

I do detail the derivation there, but they're all very standard transformations.

And you get out of this something called a supersymmetry.

Now, the idea of supersymmetry goes back to, I think, the 70s.

It is an observation that in certain quantum field theories, you get asymmetry that relates different kinds of particles.

So what that means is if I write down a quantum field theory with two different kinds of particles, and in general, they are fermions or bosons, but it doesn't actually quite matter what.

At least you can get specific kinds of fermions and bosons, so the story doesn't have to be totally general.

then sometimes you can exchange the different kinds of particles and you get the same theory.

So you can freely swap them and nothing about the physics changes.

This is called a supersymmetry.

It's not a usual symmetry in the sense that, you know, when we think about symmetries, we think of geometric things that relate, say, two different sides of a shape.

So it is a symmetry in that it relates to different things in such a way that nothing changes, but it's a supersymmetry because it's about particles, not shapes, say.

The interesting thing is supersymmetry breaking always leads to mathematically interesting observations and physically interesting observations.

So if we have access to a supersymmetry,

then the thought is immediately, okay, what can I say with this?

I should keep an eye out for something interesting happening when the supersymmetry breaks.

And in this context,

the supersymmetry breaking is about having two or more different constants of motion.

And what that means is the system is non-ergotic.

So ergodic systems have one constant of motion.

It's just the energy or the Hamiltonian that you'd put into the probability measure.

But in non-ergotic systems, in integrable systems, you have multiple constants of motion.

So it's not just the energy, but it's some other thing.

You don't know what necessarily, but you have additional variables.

And what's interesting about that is then we can make the observation that supersymmetry is about or is analogous to chaos because ergodic motion is chaotic.

It's about things that mix and things that fill their state space in sometimes unpredictable ways.

Whereas integrability, non-ergodicity,

is about systems that are very predictable.

You just integrate them and you say where it will be in a future time.

So after all this derivation and conceptual work, what we end up with is a way of saying Bayesian mechanics has an accounting mechanism for chaos and not chaos.

And that's where I leave off.

I say, so this is something interesting that we can do with Bayesian mechanics.

And it comes out of the path integral formulation very naturally.

And this is a very trivial case of just classical physical systems.

What can we get when we just start to describe the complex cases of more interesting systems like biological physics or self-organizing field theories or things of this nature?

And that's the end of the paper.


SPEAKER_03:
Well, like paper, like stream, as they say.

So let us spend our last several minutes with Ali and Jakob.

Any just closing thoughts or questions or directions that you want to continue on?


SPEAKER_00:
Well, it was an amazingly...

illuminating learning journey.

So I wanted to thank again, Daniel, Jakub and Ender for organizing the discussion sessions leading to these live streams and especially Dalton for his time and for sharing his brilliant insights and expertise with us.

And on a more personal note, Dalton, your work has rekindled my

long forgotten deep passion for theoretical physics.

And I know I'll certainly continue to explore this fascinating area of Bayesian mechanics a lot more.

So I'm truly grateful for that.

Yes, that's it for me.

And I'll pass it to Jakob.


SPEAKER_02:
yeah um also thanks to everyone uh daniel ali under uh who participated in the discussions i think uh

your input, Ali, on the different equations was really invaluable.

And of course, thank you, Dalton, for firstly writing the paper and then spending the time with us going through it.

I'm really looking forward to future work.

I would have...

many other questions about how Bayesian mechanics is related to other areas of physics, such as relativistic mechanics or the non-classical results within quantum mechanics, which we touched on last time, and then the actual applications to computational models as well.

I'm looking forward to exploring these more.

Awesome.


SPEAKER_03:
Dalton, what do you think are some of the best ways for someone to catch up to the frontier of Bayesian mechanics learning and application?


SPEAKER_01:
Yeah, well, first let me say it's been a pleasure.

I've really enjoyed the discussions and you guys came in very well prepared.

So that made it even richer.

So thank you for all your hard work and thank you for having me.

I think basic mechanics is becoming a very technical side of the free energy principle.

And I think that speaks to how ecumenical the FEP has been and how interdisciplinary it has been, because people come to it from many different backgrounds, including mathematics and physics like me, but also computer science and machine learning and also neurobiology and also philosophy.

So there's something in it for everyone.

And if you are interested in this kind of more technical side,

One thing you can do and to some extent just have to do is read.

There is a lot of literature being published at a very fast pace in the last few months.

So it can seem like a lot to wrap one's head around.

But I think one thing that I have started to be better about, and certainly my co-authors have been good about,

is road mapping things.

So it's easier and easier, I think, to get a handle on what all is being said and how it relates to other things being said.

Papers like this are a good example of things that draw everything together really nicely, I think anyway.

I don't know if I can say that, but I will anyway.

And there are other papers and things that kind of

break things down and explain things in a more accessible way than the highly mathematical, highly technical work that's also being published.

I write blog posts summarizing some of my papers sometimes.

So if you're interested in those, you can find them on my website.

Also on my website, I have a kind of Bayesian mechanical bibliography where I organize all of the recent papers in this area and what their contributions are.

That's not on my blog.

That's under a...

page on my website called research but nonetheless you know that's that's something that you can look at as well and I think everyone involved is also fairly accessible via email I think in my experience that's been the case anyway I'm always available at my email Carl is a very generous person with his time

And people like Maxwell and Lance and Thomas, Connor, you know, all the people that have been involved are, in my experience, people who are willing to take and answer questions.

So that's also something to do, you know, if you're reading something and it just doesn't make sense.

you know, do get in touch with someone.

And in my experience, people will be very charitable in terms of taking and answering those questions.

But yeah, and there's, of course, the

The one thing that is tough is kind of building up the background for these.

But I think, like anything, it is something that you can develop on the fly, so to speak.

So as long as something makes sense to you at some level, and maybe you're not an expert on the topic, maybe it only makes sense in isolation and you don't have the whole...

picture in your head.

I think in general, that's all right.

So yeah, maybe it's not a very satisfying answer.

But But at least part of the answer to your question is, we'll just start reading.

And if you do get stuck, then people in this area are pretty nice people.

So don't hesitate to contact one of them.

If you do get stuck, or if you want to bounce ideas around.


SPEAKER_03:
Well, as stated, it's been an amazing series, and I know it's not the end of 49.

There are decimals to come.

So Dalton, thanks again.

Jakob, Ali, Ander, thanks for all the amazing work.

Till the next gradient.

Okay, thank you.


SPEAKER_04:
Yeah, I'm looking forward to whatever comes next.