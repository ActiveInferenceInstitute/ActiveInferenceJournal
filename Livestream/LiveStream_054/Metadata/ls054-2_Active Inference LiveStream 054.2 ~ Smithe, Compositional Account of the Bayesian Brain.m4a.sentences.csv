start	end	sentNum	speaker	confidence	text
6820	8144	2	B	1	Hello and welcome.
8342	11152	3	B	0.72419	It's June 15, 2023.
11286	12860	4	B	0.9995	We're in active Livestream.
12940	14290	5	B	0.95	54.2.
14660	17052	6	B	0.99998	So welcome to the active institute.
17196	23708	7	B	0.71767	We're a participatory online institute that is communicating, learning, and practicing applied active inference.
23804	25744	8	B	0.99997	You can find us at the links here.
25942	31576	9	B	0.99999	This is a recorded and an arch Live Livestream, so please provide feedback so we can improve our work.
31758	37640	10	B	0.99996	All backgrounds and perspectives are welcome and we'll follow video etiquette for Live Streams.
38540	45820	11	B	0.99998	Head over to activeinference.org to learn more about participating in Live Streams and other projects.
46480	50540	12	B	0.99843	All right, we're in Live stream 54.2.
50690	62348	13	B	0.99411	Continuing with our third discussion on the work, mathematical foundations for a compositional account of the Bayesian brain, we're back with Dean Ali and Toby.
62524	77904	14	B	0.95788	So if each want to say hello and anything to begin with otherwise, Ali has some questions ready and we have some questions that people have submitted in the meantime as well.
78042	84088	15	B	0.99952	So shall we just proceed to the questions as we have the same people as dot one?
84254	85064	16	B	0.99998	Great.
85262	90010	17	B	0.51783	Okay, I'm going to jump into some of the presubmitted questions.
90320	102700	18	B	0.99468	So would it be correct to call equation 4.2 compositional Bayes theorem, which is or are Bayes's theorem categorically?
103440	112348	19	B	1	And we have the document ready or anything that you want to share, but what does it mean for Bayes theorem to be categorified?
112524	114800	20	B	1	And where is that in the dissertation?
115140	117664	21	A	0.99955	Yeah, okay, so that's a nice question.
117862	134440	22	A	1	I would say that equation 4.2 is like a sort of basic is like a sort of it's like a basic representation of the product law of probability theory.
135100	139300	23	A	1	And so I wouldn't say it's particularly inherently compositional.
139380	146472	24	A	0.99952	It's just something that is just like an axiom that is just like a consequence of the sort of standard axioms of probability theory.
146616	160336	25	A	1	The thing that makes it a little bit different from the way that it's normally written in probability theory is that I've kind of annotated those P symbols which represent the probability of a certain event.
160518	172416	26	A	0.99918	I've annotated them each with a subscript, and that subscript represents where the probability is coming from or the probability according to whom.
172608	174550	27	A	0.99955	That's kind of how you can think of it.
175400	194540	28	A	0.99	And so normally I find this kind of like P notation to be a little bit confusing because people often write P of B given A, and they also write like P of X given Y or like P of W comma a comma z.
194690	201020	29	A	1	And so in each of those cases, the sort of content of the P is kind of different.
201090	218932	30	A	0.96818	Like the A and the B might be events of a different kind to X and Y, and yet they're all put into this P symbol, whereas in this case, with the annotations, it says, like, as I say, it says according to what?
219066	233716	31	A	1	And so here the little subscript C represents what's typically called in compositional probability theory like a channel or a kernel.
233908	239668	32	A	0.99988	But that is like a kind of abstract way of just saying conditional probability distribution.
239844	249852	33	A	1	And so the little C means it's a conditional probability distribution from space X to Y, a space Y.
249906	260144	34	A	1	And here I'm thinking of the B as being an event of type Y and A as being an event of type A, sorry, of type x.
260262	272564	35	A	1	And so the PC says it's the probability of the event B of type Y given the event A of type x.
272762	280504	36	A	1	And so that means that when you plug these kind of flows of information together, you make sure the types match.
280622	284120	37	A	0.99953	It's kind of like working with a strongly typed programming language.
284780	299150	38	A	0.99879	So that type information is like the main thing that's different between this and the standard product rule of probability and it's from that product rule of probability theory that you can just write down Bayes theorem, which is the equation 4.3.
299520	321120	39	A	1	I would say that the reason why I slightly hesitate to call equation 4.3 like a sort of abstract or categorical version of Bayes theorem, even though it's annotated by these channels, is because you have this division.
321280	332820	40	A	1	And that division isn't something that's well defined in all categories, in all situations that you might want to consider probability theory.
332900	354270	41	A	0.99982	For instance, you might have this P of C dot pi thing and that means the kind of Y marginal of the joint distribution or it's otherwise known as the push forward of the distribution pi through the channel C.
355120	360432	42	A	0.7	That thing might have what's known as measure zero, which means the probability might be zero.
360486	365410	43	A	1	And so the division isn't very well defined and so that expression doesn't always make sense.
366600	379796	44	A	1	Now the thing that does always make sense on the other hand is that just product law equation which tells you how the two ways you can write down this joint distribution.
379988	395580	45	A	0.99988	So if you have a joint distribution like on the space x times y, I've written it there, then you can decompose it into a prior on x and a channel from x to y.
395730	407170	46	A	0.9996	So that then if you put the information from the prior through the channel you get the marginal on y and that's that push forward thing.
407540	418420	47	A	0.99977	Or you could write the joint distribution as a prior on Y and a conditional distribution from Y to x.
418570	422864	48	A	1	And the thing is, obviously we're talking about the same joint distribution in both cases.
422912	433530	49	A	0.99882	So those two decompositions, they're sometimes called disintegrations, those two disintegrations need to be equal and that's what that equation is saying.
434460	446140	50	A	0.9705	So that's kind of because it doesn't have this division in it and because Bayes'law follows from it and because it's something you can write down in all settings, it's kind of more fundamental.
447200	454720	51	A	0.99904	But I quite like the kind of string diagrammatic form of it which is something that is drawn.
455060	456572	52	A	0.99989	It's not my invention.
456716	464588	53	A	1	I think I originally saw it in a paper by Bart Jakobs and I think his student at the time, Kenta Cho.
464764	479160	54	A	0.97743	So in, let's see equation 4.5 so that's section 4.1.2 on abstract Bayesian inversion.
479980	492540	55	A	0.99933	So yeah, if you scroll down a little, it's on like page 130 or 130 in my version, which might be hopefully around the same place in your version.
496480	498460	56	A	0.99232	Yeah, a little further.
501560	503396	57	A	1	Oh man, no, maybe not.
503578	507960	58	A	0.95577	Let me get up the version on because I've realized I've opened the wrong version.
510220	526480	59	A	0.99975	Meanwhile, see it so so the the thing I'm going for here is the sort of, as I say, the string diagrammatic depiction.
527140	527552	60	A	0.88	Yes.
527606	529968	61	A	0.89	4.1.2, it's page 120.
530054	531170	62	A	0.99995	Sorry about that.
535160	539220	63	A	0.74556	Yeah, so it kind of shows you how the information flows.
541000	547940	64	A	1	And so this makes the two processes quite explicit.
548020	552600	65	A	0.9959	So here on the left, the prior of the joint distribution is pi.
553180	562392	66	A	1	And then you take the sort of probability, the information from pi and you copy it and you keep one of the copies and that gives you your X marginal.
562536	569960	67	A	1	And then you feed the other one through the likelihood or the conditional channel C, and that gives you the other marginal.
570120	576044	68	A	1	And so if you throw away this X information, you get the Y marginal.
576092	578050	69	A	1	And that's what marginalization is.
578420	587456	70	A	1	And that's why the Y marginal, if you look on the right hand side, the prior is C after pi, that's the Y marginal.
587488	591910	71	A	0.62491	So this is like depicting that Product Law.
592600	609528	72	A	1	And then you say you can call something a Bayesian inversion of C with respect to the prior pi if it is something that can go in the box on the right hand side where I've written C dagger pi.
609624	623390	73	A	1	And the reason I've used this dagger symbol is because under certain technical conditions, this Bayesian inversion thing gives you what's known in category theory as a dagger function.
624740	628960	74	A	1	And that's something that swaps the direction of a morphism.
629620	636496	75	A	1	And so here you've taken the thing that goes from X to Y and you've swapped it and it goes from Y to X, but it depends on the prior.
636528	640420	76	A	0.68	And so I've written this little subscript and so for me, this picture.
642840	643168	77	A	0.88001	It's 
643184	646950	78	A	0.99979	kind of equivalent to that Product Law equation 4.2.
647420	658844	79	A	0.92442	But I think although it's a kind of new kind of language, I think it's a kind of more intuitive one because you can sort of see how the information flows through the system.
659042	665564	80	A	0.82922	Sorry, that was a bit of a long answer, but I think that's how I think of it.
665682	666350	81	B	0.99967	Great.
667120	670508	82	B	0.99852	Okay, next question.
670594	672208	83	B	0.99559	Could be a short one.
672374	676348	84	B	0.99749	I'm mostly wondering about how chapter six will be rewritten.
676524	677520	85	B	0.99998	Will it be major?
677590	685856	86	B	0.98	And when we promise we didn't write this question primarily to select the best policy as to where to direct my regime of attention?
685968	692112	87	B	0.99981	Like, should I wait to dig deeper into chapter six until the updated observations arrive?
692256	697064	88	B	0.99995	Is reflecting deeply up until chapter five where I should focus for now?
697102	699304	89	B	0.9657	Or is chapter six something that won't change too much?
699342	702344	90	B	1	And I can still explore that next week.
702542	704810	91	A	0.67483	So this is a great question.
706140	714140	92	A	1	And I'm sorry that the rewritten version isn't online yet, but it is really close, I promise.
714800	721356	93	A	0.98	And I am kind of aiming for it to be done like next week or maybe let's not hold myself hostage to fortune.
721388	723490	94	A	0.99984	So let's call it the next couple of weeks.
724340	735140	95	A	0.99934	But it's quite a change in the sense that it's kind of annoying because it's simpler but also kind of more structured.
735960	758990	96	A	0.84	And so that means that there were a lot of finicky details that I didn't anticipate needing to deal with, that I had to deal with, even though fundamentally the basic idea is kind of the same but also neater and simpler at the same time.
762080	769630	97	A	0.89	I can go into some details about the differences if you'd like, or I can just leave it at that.
770000	771052	98	A	0.52031	What would you rather?
771186	773410	99	B	0.99974	Let's return to this in the three.
773860	775360	100	A	0.99452	Okay, yeah, let's do that.
775430	776560	101	A	0.97021	That's a nice idea.
776710	788612	102	A	0.99986	So, yeah, I would say don't dig too deeply into it, because basically the thing that I've managed to do away with and sorry for all the people who've kind of tried to bang their heads on it already, is.
788666	791440	103	A	1	The kind of pro functor, like optics.
791520	807370	104	A	0.99404	Kind of like the sort of pro functor stuff with those weird coen things, the kind of integral symbols that I was using to define context for statistical games, that whole thing.
808320	812056	105	A	1	It turns out you don't actually need the complexity of that structure.
812248	818780	106	A	1	And the notion of context is really given just by two things.
818850	825680	107	A	0.86666	It's really just the prior, which we've already talked about, and also the observation you take from the environment.
826340	841780	108	A	1	And so before I thought you needed to consider not just the observation, but also the stuff that might go on in the environment around the observation that gives you correlations.
842280	846360	109	A	0.99992	But it turns out actually you don't need that, at least not for the free energy principle.
847500	852200	110	A	1	And so that makes things a bit simpler because you don't need that kind of weird structure.
853980	869084	111	A	0.99996	But there's, as I say, some technical stuff which is very annoying, which made it also a little bit slightly annoying to write down and involved by categories and sorry about that.
869202	893430	112	A	0.99983	But it's actually the fundamental idea of a statistical game being like a Bayesian lens which describes the inference process, maybe like a parameterized Bayesian lens that allows you to learn, but a Bayesian lens that comes with a loss function that's still the same idea.
894440	904436	113	A	1	And it turns out that loss functions like the relative entropy and the free energy, they actually have a really neat categorical structure.
904468	914748	114	A	0.99994	So the things I was calling like free energy games before or Bayesian inference games, those are actually now a lot even neater still.
914834	916510	115	A	0.9999	So that's really nice.
918960	928396	116	A	1	And the way you get predictive coding is still as like a functor from these statistical games to dynamical systems.
928508	930736	117	A	0.84781	So that idea is still the same.
930918	935430	118	A	0.56409	It's just actually it turned out that the statistical games themselves.
935880	940790	119	A	0.99882	There was actually a lot more nice stuff going on there than I had realized before.
942200	942950	120	B	0.99955	Awesome.
944920	945830	121	A	0.98084	All right.
947800	953876	122	B	0.44647	You cite Erisman and Van Bermesh work on memory evolution systems.
953988	956532	123	B	1	To what extent have you used their work in the thesis?
956596	969310	124	B	0.99996	Would it be correct to say that there might exist a functor from that book to your dissertation or indeed to any of your citations, is there work someone could do to explore the connection between the two?
969680	979868	125	B	1	To me, this is a question of one instance if a learner or researcher performs active inference on the interface between a work and a citation more generally?
979964	980640	126	B	0.99967	Great question.
980710	1000132	127	A	0.80664	Yeah, I think it's a really nice so I I read this work by Erisman of Rambamish on memory reevoltative systems a few years ago, and I found it very abstract and confusing.
1000196	1008350	128	A	1	And I was like, yeah, this is all really nice, but how does it actually connect to the brain and how things like brains work?
1011040	1030800	129	A	0.99997	But I've kind of softened my stance on it recently, and I think actually there's some really cool stuff in that work, some really great ideas about hierarchical complex systems and emergence and even things like neural coding.
1032180	1047290	130	A	0.43694	It's kind of, I think, slightly in danger, I think, of being forgotten because people see it and think, okay, well, how does it actually make contact with things I know about now, things that actually scientists use?
1048620	1056410	131	A	0.99	And so I think it would be great to explore the connections in a kind of more detailed way.
1056780	1060430	132	A	1	I don't know precisely what that would look like.
1062000	1070320	133	A	1	I heard a talk, actually, by don't know.
1070470	1073424	134	A	0.68874	There may be some on YouTube, I don't know.
1073542	1101160	135	A	0.99943	This was in Consciousness Maths of Consciousness like workshop at the end of April, and she explained some of the more recent stuff they'd been doing, and it sounded like actually there is a proof, I think, that Hebian learning does actually give you sort of what she calls cat neurons.
1102940	1112540	136	A	0.99	And so before I've been like, okay, well, it's a nice story, but does it actually relate to things like heavy learning, or is it just like an analogy?
1113920	1117180	137	A	0.96231	But it sounds like it's actually a bit more precise than I had thought.
1117330	1132140	138	A	1	And obviously, because of the connection between things like heavy and learning and predictive coding, it sounds like there should be a way to relate something like predictive coding to memory evolutive systems.
1132220	1144192	139	A	1	And that would be really nice because I sometimes think about this is kind of a direction that I'm trying to go in slightly, but try to think about nested active inference systems.
1144256	1158860	140	A	0.98885	Like, you might have a little region of the brain and all the cells are doing active inference, and the circuits do predictive coding, and they make up a brain and the brains make up society and an organization.
1159280	1171216	141	A	1	And that story of hierarchical complex systems is really the story that this work is trying to tell as well.
1171318	1172704	142	A	0.99998	Just in a different kind of way.
1172742	1190116	143	A	1	And so I think it's a really fruitful area, and I really hope somebody does dig into it, because I think it's great work, and I think it's just work that was kind of maybe ahead of its time, so it kind of got left by the wayside maybe a little bit.
1190138	1194230	144	A	0.5407	But I'm really glad to see somebody ask about it now.
1195260	1196056	145	A	0.98022	Cool.
1196238	1199224	146	B	0.99993	Just one short remark on this, and then alir Dean, please.
1199262	1204964	147	B	0.60598	It's almost like when people draw associations, like a line of sight.
1205092	1207204	148	B	1	Oh, well, emergence is like this.
1207262	1212648	149	B	0.93513	It's like they're surveying and can have quite far vision.
1212824	1218476	150	B	0.99998	But category theory is like building the high speed rail where it's, like, locked in.
1218658	1226172	151	B	1	And then we can say there really is a relationship of this exact formal type between Hebian learning and predictive coding.
1226236	1234992	152	B	0.99443	Let's just say some type so then that can be really relied on as a foundational building block.
1235136	1256052	153	B	1	And it kind of brings those literatures and merges those streams or at least adjoins the streams or naturally transforms the streams, or whatever the appropriate terminology would be, but in a really solid way that's not just like, well, one person on a mountaintop saw that these two things could be connected.
1256116	1259710	154	B	0.81917	It's more like an engineering project that really locks it in for everybody.
1260160	1261484	155	A	0.99996	Yeah, I think so.
1261522	1266568	156	A	1	And I hope people are incentivized to do that engineering.
1266664	1268030	157	A	0.76	I think that'd be great.
1268720	1272130	158	B	0.6642	All right, last of the presubmitted questions.
1273700	1288196	159	B	0.99969	So, in the par, pazulo and Friston 2022 active inference textbook, the first question in the recipe for designing an active inference model this is chapter six is which system?
1288378	1298250	160	B	0.99999	This entails three pieces of data one, the agent generative model, two, the interface sensory data and actions, and three, the external environment, the generative process.
1298860	1314620	161	B	0.99767	So how do these relevant big chunks of notions from the recipe for making an active inference model in the par at all textbook map to the sections of what you've done in your dissertation?
1314960	1316060	162	A	0.99992	That's a nice question.
1316130	1328800	163	A	1	And it takes me on to a question of action and active inference beyond the sort of approximate inference that I was talking about in my thesis, predominantly.
1329300	1335220	164	A	0.99976	Maybe here I could draw some stuff, and so I don't know how easy that is for you, but I can share my screen.
1335370	1336164	165	A	0.61	Yes.
1336362	1338470	166	A	0.98757	Let's see how this will work.
1341880	1342388	167	A	0.81513	Yeah.
1342474	1343110	168	A	0.9983	Okay.
1343480	1344230	169	A	0.99969	Share.
1345900	1346808	170	B	0.9982	All right.
1346974	1349508	171	A	0.99999	Can you see my cursor thingy?
1349604	1350250	172	B	0.99884	Yeah.
1350780	1351850	173	A	0.99882	Okay, cool.
1354060	1365660	174	A	0.65735	So I like to draw this picture, and this is like, the little channel c, which does prediction, and it goes from here, and it goes outwards.
1366560	1378780	175	A	1	And this is the inversion, the approximate inversion, and it takes in, like, a prior, which comes from here, and it takes in an observation.
1378940	1392230	176	A	0.75301	So we could think of this as, like this is, like, high level belief and, like, lower level.
1396110	1411360	177	A	1	And this is like somehow you get something which gives you an observation, and then this gives you like new belief, high level.
1415220	1417612	178	A	1	And this thing is a Bayesian lens.
1417756	1421970	179	A	0.99866	So that's what the Bayesian lenses are all about.
1423160	1433510	180	A	1	And the thing that I was talking about in my thesis is turning this into like a predictive coding dynamical system.
1434200	1443544	181	A	0.58727	Because you've got neurons which do this sort of prediction part and then neurons which do this passing back of error signals to do this updating part.
1443582	1446676	182	A	1	And they have this kind of like bi directional form and that's really neat.
1446708	1456652	183	A	0.7	And so you can put in another one here, another one here, or you can just start with your prior which is like something that I often write as pi up here.
1456786	1460190	184	A	1	And then this gives you like a new pi at this point.
1460820	1465788	185	A	0.61	And so this is going always from higher level beliefs to lower level beliefs.
1465804	1490120	186	A	0.52	And down here you might eventually get to the lowest level, which is like if you're thinking about visual systems, then this would be like the V one visual cortex stuff or like the stuff you get in the retina and you get prediction about let's say visual signals.
1491420	1495364	187	A	0.99997	But then the world, you get this predicted.
1495412	1512360	188	A	0.99997	But then the world comes back and it actually gives you actual this is predicted, gives you actual signals and then the brain uses that to update its beliefs up here.
1512510	1521036	189	A	1	And so really the interface is somehow like this, okay?
1521218	1529330	190	A	1	And so this is like lens world and this is like external world.
1531060	1535516	191	A	0.99986	So that's where the external environment comes into the picture.
1535708	1539590	192	A	1	And you could think of everything in here as like agent.
1541160	1548260	193	A	0.99996	But this doesn't really tell us much about action and it doesn't tell us much about interaction.
1548680	1562920	194	A	1	And so there's another kind of story for that which is kind of similar in many respects, which is the story that is told at least in category theory by what's known as categorical systems theory.
1563440	1565980	195	A	1	And there you get pictures like this.
1566130	1568524	196	A	0.91571	So this is like your world.
1568642	1577730	197	A	1	And there you've got some system inside the world and here you've got another system inside the world.
1578820	1585200	198	A	1	And so people then draw like things that are called wiring diagrams to kind of represent how these things interact.
1586100	1590676	199	A	0.98966	So let's call this a for a.
1590858	1594292	200	A	0.99999	Maybe there's another system over here and this is B.
1594346	1596132	201	A	0.81	And maybe that's C for A.
1596266	1602890	202	A	0.99782	Its environment is like everything that isn't A, it's B and C.
1605260	1619756	203	A	0.95088	So maybe it's connected like this, I don't know, some weird wiring thing actually, maybe that should go round to here and then this goes like to that.
1619858	1621390	204	A	1	I don't know, something like this.
1622640	1624712	205	A	0.99781	This is just what's known as a wiring diagram.
1624776	1627810	206	A	1	It just tells you how the systems are coupled together.
1628660	1635292	207	A	1	And that would be like specifying how the information flows across the Markov blankets of your systems.
1635436	1641060	208	A	0.51	And so this box is like the Markov blanket of A.
1641130	1645940	209	A	1	And then this wiring is like the data of the coupling of the blankets.
1647720	1660040	210	A	1	And so there's a whole theory, a whole sort of story in category theory about how to sort of compose if you've got like, you know, if you you know, it has to compose dynamical systems of this kind.
1660110	1661576	211	A	1	And so, you know, what?
1661598	1681280	212	A	0.76999	What we do is we say, okay, well, we we write down like the type of if we say if we call if we write IA to represent the interface like the data of this is like X and this is like Y or something like that the kind of shape of the Markov blanket.
1682180	1694790	213	A	0.43	Then what system theory tells us is that for each interface we get a whole category of systems that you could put in that box to animate it to make it like a living system.
1696360	1701128	214	A	1	And then this is like a closed box at the moment.
1701294	1706920	215	A	1	And so maybe it just represents the whole universe which doesn't have any external environment.
1707260	1724380	216	A	0.7798	But you might also have something like a company, so you call it like company X, and that has some agent which decides what the company does, or some agent here which takes in information from the environment.
1724880	1736370	217	A	1	And so this wiring is then something that gives you a morphism from like A and B and C to X.
1737300	1767310	218	A	1	And what this dynamical systems theory tells you is that let's call that W for wiring is that you get this functor from din A and din B and din C to din X, which tells you then how to wire all these dynamical systems together to give you one that fits into this outer box.
1767920	1772776	219	A	1	And so this tells you how to do all this for just dynamical systems.
1772808	1777004	220	A	0.99996	But of course, we're kind of interested in active inference systems.
1777052	1785330	221	A	0.75	And so here you don't just have some DX by DT thing to go in here.
1786180	1799670	222	A	0.99933	You've got the data of prediction and plans and goals and maybe then something about how to actually do the inference, like the statistical game stuff.
1800620	1802488	223	A	0.99952	But really the story is the same.
1802574	1822572	224	A	0.98	And so if you have these boxes, again, what we can do is if we have a box like this x to Y is we can think of an agent as having as a part of it a way of predicting, say, X.
1822626	1829452	225	A	0.99999	We think of let's call these something else, sorry, let's call these S.
1829586	1832448	226	A	0.99989	So this is like the sense data that goes into the system.
1832534	1836370	227	A	1	And then let's call this A, and then this is maybe like the actions that it takes.
1836740	1839430	228	A	0.99996	Let's now call this box, I don't know B.
1840440	1841732	229	A	1	Oh, no, I don't like B.
1841786	1843190	230	A	0.99996	Let's call it y.
1846280	1847540	231	A	0.99991	So now let's think.
1847610	1872332	232	A	0.99099	Okay, well, part of what an active inference agent is doing is that they're predicting they've got some high level belief of type Y, and then they make a prediction about not just the sort of sense data, but also about their actions and then their body samples from this belief about how they should act.
1872466	1881500	233	A	0.65506	Or you've got these little cells, these little mechanisms which try to correct the prediction errors to make those actions into reality.
1881580	1886960	234	A	1	And then maybe that gets coupled to some other system which receives those actions as inputs.
1887540	1908280	235	A	1	And you might have another part here which goes in the other direction which says, okay, given my actual sense data and my actual actions, maybe my body is still learning how to play tennis or something, what are my new high level beliefs?
1908860	1913080	236	A	1	And so you can do this whole story again of Bayesian lenses.
1916620	1921028	237	A	1	And this goes like that, and this is now just why?
1921214	1923052	238	A	1	And then this is like S times A.
1923106	1948356	239	A	0.97	And this is s times a So you can tell this story and you can build like, hierarchical systems, but now you have a way of filling in each box and in principle, a way of coupling them together to give composite active inference systems, like companies or like colonies of cells or things like that.
1948538	1953610	240	A	0.89563	This isn't a story yet that I've written down, but I know it works.
1954220	1957210	241	A	0.8	And I'm in the process of slowly writing it down.
1958300	1964090	242	A	0.99944	So the kind of fundamental structures that are in the thesis are like part of the story.
1965280	1980240	243	A	0.81	The main thing that's missing is kind of like reorienting it's, just like reorienting this picture so that it's not like going from here from left to right.
1980310	1988096	244	A	0.99168	It's like sort of poking down into the box, if you see what I mean.
1988198	1991990	245	A	1	And this is like the stuff you put in.
1992440	2000260	246	A	0.99982	So this is like your lens thing here, and you sort of fill in the box with your lens.
2002220	2012250	247	A	0.99652	So I think that tells I mean, that tells you how the chunks of the thesis kind of fit into the standard act of inference story.
2013100	2025980	248	A	1	The main job, at least as far as I'm concerned now, is to spell out the details and then start to talk about things like what happens if we've got Y and you've got Z's here?
2026050	2031730	249	A	0.69077	What if they're trying to form part of an organization, but they disagree about what to do?
2032180	2035120	250	A	0.96023	How does an organization resolve disagreements?
2035860	2041852	251	A	0.99999	What if you've got two signals from your brain to your muscles that tell you to do different things?
2041926	2043140	252	A	0.99965	How do you resolve?
2045880	2049830	253	A	0.99964	How do you get harmonious active inference systems in some sense?
2050680	2056772	254	A	0.9982	So I'll stop sharing my screen now, and then we could sort of return to the discussion.
2056836	2059690	255	A	0.99102	But that's, again, my kind of long winded answer.
2060940	2061690	256	B	0.99827	Awesome.
2063100	2065390	257	A	1	I can share the pictures I see.
2065920	2070430	258	A	0.6889	Dean you said you shared something, but I can share some more things.
2072080	2077656	259	B	0.34373	Dina unmute and then go for it and then Ali no, I just shared.
2077688	2088192	260	D	0.99999	Something from about nine years ago that I was doing in my programming that everything you just wrote out was I just wanted to share one part of it.
2088246	2096944	261	D	1	That confirms that you could come from completely different places and arrive at the same destination.
2096992	2102756	262	D	0.99	The whole bi directionality, the whole predictive parabolic.
2102868	2103624	263	D	0.83939	Yeah.
2103822	2108360	264	D	0.99998	You can bring this into classrooms and have it make sense.
2108430	2115500	265	D	1	It doesn't have to be esoteric or too remote, I guess.
2115570	2117884	266	A	0.91946	Yeah, that's great to hear.
2117922	2119596	267	A	0.99996	I'm really glad to hear that.
2119778	2122110	268	D	0.89093	Yeah, it's really awesome.
2122800	2123548	269	A	0.99998	Thanks.
2123714	2132192	270	A	0.8229	Yeah, as I say, there's lots left to do, but I think an important part of that is like spreading the word.
2132326	2137490	271	A	0.99424	It's really great that process is beginning, thanks to you guys.
2137860	2148644	272	B	0.96066	So, yeah, the rehearse play reflect cycle actually begins when you reverse the direction of thought reading from Dean's email.
2148762	2149430	273	B	0.99997	Interesting.
2151480	2152432	274	D	0.99825	Self organized.
2152496	2153110	275	D	0.99767	Yeah.
2153960	2155620	276	D	0.97794	It's all part of this whole cat.
2155770	2176120	277	D	0.99994	This is the like, I love the questions that we've had so far and I want to hear Ali's questions and then I want to be able to take it and have people not be intimidated by it because you can really find yourself doing these things on a daily basis.
2176200	2181312	278	D	0.99999	You just don't necessarily identify them the way that we are.
2181446	2188960	279	D	0.99998	But that doesn't mean that we have somehow lost access to the things that we're discussing today.
2189030	2191350	280	D	0.99992	So I'll just leave it at that for now.
2192280	2196484	281	A	0.9695	Yeah, cool.
2196602	2204920	282	B	0.99328	All right, in the rest of the time that we have with you for the two Toby.
2205820	2206840	283	B	0.64187	Ali.
2214140	2215530	284	C	0.76678	Okay, thank you.
2218140	2219720	285	B	0.51435	Your video is frozen.
2220640	2221608	286	B	0.99822	Your video is frozen.
2221624	2223150	287	B	0.97839	Maybe you can just turn it off.
2226260	2227632	288	B	0.99916	Yeah, go for it.
2227766	2228610	289	C	0.99756	Thank you.
2229060	2229970	290	A	0.99736	All right.
2233860	2240236	291	C	0.55874	In basically three to ridiculously.
2240268	2240850	292	C	0.63196	Next.
2244100	2247940	293	C	0.86973	Sorry, the notion of Marko, I noticed in your thesis.
2250800	2253544	294	B	0.9995	Sorry, Ali there's just a lot of lag.
2253672	2254350	295	B	0.90581	Yeah.
2274450	2277870	296	B	0.99995	What would you say is the chapter six equivalent?
2278370	2290420	297	B	0.96519	Is there yet a recipe for designing the kind of categorical, kind of compositional organization that you alluded to?
2294470	2296674	298	A	1	I can answer that quickly.
2296872	2299174	299	B	0.99056	Yeah, go for a quick answer and then I think now it's better.
2299212	2303254	300	A	0.98173	Ali yeah, so the quick answer?
2303452	2306840	301	A	0.98245	Well, it's a quick answer, but it's not a quick thing to do.
2307450	2328880	302	A	0.99953	But there's a great book on categorical systems theory in its kind of great generality, which doesn't explicitly talk about active inference like I've been, but it does talk about this kind of composing dynamical systems in this hierarchical way idea.
2329890	2334910	303	A	1	And that's the book that's currently being drafted by David Jazz Myers.
2335910	2338580	304	A	1	I can circulate a link to it.
2340550	2375520	305	A	0.86	Myers that sort of spells out the kind of general structure and I believe he and Mateo Capucci have got a paper upcoming at the upcoming Act Conference on Applied Category Theory this year, talking about using that framework to do kind of cybernetic like things.
2376930	2396306	306	A	0.99	And so what I've been thinking about lately is trying to fit active inference and the stuff I've been doing into that framework, which has been sort of developing in parallel and kind of fortunately and maybe slightly unsurprisingly, they fit very nicely together.
2396488	2402450	307	A	0.99	And so the pictures I was sketching are kind of a fragment of that other framework.
2402530	2405000	308	A	1	And as I say, I think they go quite well together.
2406250	2407000	309	B	0.99976	Awesome.
2407610	2410700	310	B	0.69266	Okay, Ali, go for it.
2411230	2411738	311	C	0.99622	Okay.
2411824	2412922	312	C	0.99977	Sorry about that.
2413056	2431630	313	C	0.99894	All right, so I noticed in your thesis that you don't rely too much on the notion of markup blankets, but instead you use this notion of polynomial functions as its more formal or perhaps more rigorous replacement.
2432930	2442420	314	C	0.99998	With regard to that in your paper Polynomial life, you say in the literature on active inference sorry.
2444470	2453190	315	C	0.9	And the free energy principle, there is much debate about the concept and role of markup blankets, which are sometimes conceived to represent the boundary of an adaptive system.
2453340	2462150	316	C	0.99999	We believe that the algebraic polynomials will help to make such thinking precise where it departs from the established usage of markup blankets and Bayesian networks.
2462230	2464682	317	C	0.99924	So would you care to elaborate a bit on that?
2464736	2473698	318	C	1	And how do you see polynomial functions as overcoming some of the limitations of the notion of markup blankets?
2473894	2475134	319	A	0.99867	Yeah, okay.
2475332	2497170	320	A	0.97197	So I will preface this by saying I think some people might disagree with me, but there is a notion of Markov blanket that for me is nicely defined, that exists in the sort of Bayesian statistics literature.
2497990	2508242	321	A	1	And it says if you've got a Bayesian network, you can consider the nodes in that network and you can ask what are their Markov blankets?
2508306	2517030	322	A	1	And in particular, you can just define the Markov blanket of a particular node to be its parents.
2517110	2535860	323	A	0.97326	So those nodes that it's conditionally sort of dependent on its children, sort of those nodes which are conditionally dependent on it and what are known as its coparent, so the other parents of its children.
2537750	2548686	324	A	0.76	And that's a very nicely well defined notion, but it's only nicely and well defined in this context of Bayesian networks.
2548878	2561734	325	A	0.76	And so it's like generalizing that to kind of situations where you've got interacting dynamical systems is something that informally makes total sense.
2561772	2572166	326	A	0.99988	You want to say, okay, well, I have this thing in the world and it behaves so it changes in time, and it's sort of a coherent unity in some sense.
2572208	2574270	327	A	0.85	And so it has a kind of boundary.
2575090	2587220	328	A	1	And because it has a boundary, information and energy from the environment always has to flow through this boundary in order to interact with it.
2587990	2595650	329	A	0.99	And that sort of boundary notion, it seems, is like what is in other contexts also called a Markov blanket.
2595990	2609886	330	A	0.99	And I think if you set up your dynamics in a particular way or your definition of Bayesian network in a particular way, that the two ideas that might coincide.
2610018	2612300	331	A	0.99998	But I don't think that's true in general.
2612670	2626030	332	A	1	And I think what people mean in the literature when they're talking about Markov blankets, but in this dynamical context, I think all they really mean is like boundary or interface.
2626450	2657318	333	A	0.99964	So the data of the system, like capacity for interaction or something like that, the stuff that is on the edge of the system through which interactions with its environment are mediated, that sort of general idea is something, again, that appears nicely in categorical systems theory, but in a very general way.
2657404	2676154	334	A	1	And it doesn't require any of the notions of Bayesian statistics, and it doesn't require conditional dependence or parents or children of a graph because you might have something more complicated than a graph.
2676202	2681706	335	A	0.86129	Like you might have edges which are allowed to connect more than one node, and that gives you a hypergraph.
2681738	2691682	336	A	1	And there, of course the notion of Bayesian of marker blanket in the standard sense that doesn't make sense at all, but of course the notion of interface does.
2691736	2695678	337	A	1	And there are certain categories of interfaces.
2695854	2704210	338	A	1	And those wiring diagrams I was drawing before are an example of a category of interfaces.
2704290	2707400	339	A	0.99859	Like they don't have any data of the systems themselves.
2707770	2711980	340	A	1	The category just tells you how to sort of plug interfaces together.
2713150	2730160	341	A	0.74	And so I think it's kind of neater to think about this connectivity in the interfaces sort of separately from the stuff that fills the interfaces, like the data of the dynamical systems or of the active inference, like games that I've been talking about.
2732450	2749030	342	A	1	And so a really nice kind of category that you can use to talk about interfaces and indeed to talk about lots of other things, but in particular to talk about interfaces is this category of polynomial functions.
2750090	2756178	343	A	1	And it kind of generalizes these wiring diagrams that I was drawing earlier.
2756354	2778350	344	A	1	And it does so in a particularly useful way, I think, which is that if you sort of formalize the interface of a system using this polynomial language, you can start to talk about interfaces that themselves might change depending on the context.
2779330	2801334	345	A	0.99735	So when you get into the car to drive somewhere effectively, you've sort of changed your interface because now you've got this car around you and it behaves in a different way than if you're just on your own or if you're just normally going about your life.
2801532	2810730	346	A	0.99992	You might blink right, or you might close your eyes, and that means that you're no longer receiving visual signals from the world.
2810880	2826880	347	A	0.57	And so if you just say you're writing down your active inference model and part of the model is that it receives visual signals, then talking about situations where those visual signals go away.
2829810	2830126	348	A	0.99999	You.
2830148	2832634	349	A	0.99997	Can do it right, but it's not very neat.
2832682	2845540	350	A	1	And so to sort of account for interfaces that might change like this, it's nicer to be able to say, okay, well, my interface actually is allowed to depend on what I'm doing right now.
2846870	2862540	351	A	0.99911	So I'm currently on a video call and it means I can do certain things, but I'm currently wired into the computer so I can't so easily go and walk around like the set of signals I receive or actions I might take might change.
2862990	2878960	352	A	1	And so I think it's easy to start by saying, okay, when we're talking about Markov blankets in dynamical systems, we just mean like, there is some set that is like the action set and some set which is the sort of sensory set.
2879970	2897986	353	A	0.55364	For me it's just not enough because of the fact that the world is dynamical context change coupling might be dependent on like you might be in an organization and there's some executive who's in charge of defining the team structure.
2898178	2909894	354	A	1	And that means the team structure is like the wiring of the agents in that organization, but how they behave depends on the decisions that that executive makes.
2910092	2915526	355	A	1	And so their markup blankets are conditional on those decisions.
2915638	2924794	356	A	1	And that's something you can talk about nicely in this polynomial language because you're allowed to have systems which affect the wiring of other systems.
2924922	2937246	357	A	0.99997	But it's really not something that's easy to talk about in this standard framework of interfaces and boundaries that is dominant in the active inference literature.
2937438	2949010	358	A	1	And I think that's because really in the active inference literature, there isn't a framework for interfaces and wiring and that framework is supplied by these categories of interfaces.
2949590	2965850	359	A	1	And so you can just choose one and you can hope it does choose one that's appropriate for your situation that you're trying to model, but it helps to actually have one that allows you to do this wiring and that's something that using category theory allows you to do because it's all about composition.
2968670	2969420	360	B	0.99943	Awesome.
2970990	2972986	361	B	1	The textbooks will be rewritten. Dean.
2973098	2981680	362	D	0.61245	Quick thing, Toby, does the timing of the choice in your experience really matter?
2984050	2988482	363	A	1	The timing in what whenever, whenever you.
2988616	3003874	364	D	0.64164	Do decide to make a choice, doesn't the effect of the timing, the whenness of activating that choice play a huge part in what follows in terms of the category?
3004002	3004390	365	A	0.99895	Yeah.
3004460	3017050	366	A	0.50959	So do you mean like if you're choosing to use a particular kind of interface language, say or describe a thing with a particular interface or like particular kind of boundary?
3017630	3018378	367	A	0.99983	Yeah.
3018544	3020010	368	A	0.99805	So I agree.
3020160	3023514	369	A	1	And that's why I kind of tend to work quite abstractly.
3023642	3035620	370	A	0.99995	So rather than saying I'm working with a particular kind of interface language, I'm just saying I will assume my interface language allows me to do these certain things.
3036310	3041380	371	A	0.85	And so that's not so useful for actually implementing a particular model.
3042550	3051000	372	A	0.99997	But if you're trying to think about systems in general, it's helpful to work agnostically in that way.
3051530	3064170	373	A	1	And so the reason I sort of advocate like this for polynomial functions is I think that they sort of fit at a nice sort of intermediate level of abstraction.
3064750	3072880	374	A	0.99941	It's not to say, okay, well, there is a collection of interfaces and some collection wiring them together because that doesn't tell you actually how that works.
3073730	3076458	375	A	0.99856	So it is slightly opinionated.
3076634	3082560	376	A	0.98386	It's different from certain choices that people in other bits of applied category theory make.
3083810	3096750	377	A	0.99998	But it does generalize this simple case where you have just a single set of outputs and a single set of inputs or single set of actions and a single set of observations.
3096910	3105830	378	A	1	And so I think because of that it's a nice sort of intermediate level and I think it's one I've tried to work with, because I think it's quite natural.
3106170	3109062	379	A	0.99741	But yeah, you can sort of totally work at a very abstract level.
3109116	3117260	380	A	0.99	And that's what David Jazz does with his systems, just he just talks about interfaces in general.
3119790	3121980	381	A	0.99664	You might not have actions at all.
3123950	3125610	382	A	0.9997	It's completely agnostic.
3130700	3131208	383	B	0.99825	Awesome.
3131294	3132040	384	B	0.33319	Ollie.
3134860	3136412	385	C	0.41413	OK, thank you so much.
3136466	3165290	386	C	0.99026	So my second question is about the relation between your compositional account of active inference and the recent line of research done in Bayesian mechanics, namely the discovery of the duality between FEP and constraint maximum entropy principle as discovered primarily through the work of Dalton Saktive Adebel in the last couple of years.
3166060	3178824	387	C	0.99892	There's this nice duality between the observer dependent the viewpoint from the inside observer of the agent and the outside observer.
3178872	3187560	388	C	0.92448	So, respectively, the perspective of FEP as opposed to constrained maximum entropy principle.
3187720	3200984	389	C	0.95381	But Dalton has demonstrated that actually, those two perspectives can be unified through showing the equivalency between the Bayesian optimality and James optimality.
3201052	3211780	390	C	0.47526	So from Bayesian optimality, we can obtain FEP, and from Jane's optimality, we can acquire CMAP.
3212120	3241520	391	C	0.93535	So, given that the notion of Bayesian lens also comprise both Bayesian inference and its inverse process, do you think the Bayesian lens as providing a kind of, I don't know, a tool to account for showing this kind of duality between FEP and constraint maximum entropy principle?
3242180	3244800	392	A	1	I think the answer is probably yes.
3244870	3260292	393	A	0.99953	But I think this is a really great question, because genuinely, I don't know the story mean, I know a bit about Dalton's work, and I think it's wonderful, but I really don't know yet how it connects to the stuff I've been doing.
3260346	3263110	394	A	0.96	And it's really like an open question for me.
3263480	3268712	395	A	0.99895	But there are some tantalizing signs that, as I say, I think the answer to your question is yes.
3268766	3280044	396	A	1	There is a kind of unification of the two kinds of story, and some of the ingredients of that story are kind of floating around out there.
3280162	3297356	397	A	0.99988	So I know that there seems to be a connection, or like I know that there is a connection between quantities like the relative entropy and energetic concepts you get in physics.
3297548	3304000	398	A	0.97	And through that, you can make a link to the kinds of things that Dalton has been doing with gauge theory.
3304160	3318884	399	A	0.98	And I feel like there is a kind of geometrical structure that you can put on top of these statistical games that I've been working with, because, remember, they are these lenses with these loss functions.
3318932	3325610	400	A	1	And these loss functions seem to have this kind of, as I say, this kind of geometric thing going on with them.
3326480	3346770	401	A	0.99946	But really explaining or putting constrained maximum entropy into statistical games language is not something that I've done and it's something that I've been thinking about doing, and I'd be delighted to talk to people about more.
3347380	3350640	402	A	1	And so I don't know precisely the details.
3351560	3356870	403	A	0.99632	There is a kind of other duality, which I think is quite nice which is related to this.
3359640	3380670	404	A	0.89	And I think again, at the nexus of these is this systems theoretic idea, because of course, all of this work of Dalton's lives in this kind of dynamical systems world where you have dynamical systems that are interacting and information flowing between them.
3383280	3390076	405	A	1	And there are some really tantalizing connections, again, of course, between physics and information processing.
3390108	3407540	406	A	1	And I learned the other day, for instance, that there are certain classes of generative adversarial networks sorry, this is just a slight tangent, but I think you might be interested to know certain classes of generative adversarial networks that you can set them up.
3407690	3424436	407	A	1	And the two parts of the network tend to instead of settling into an equilibrium, they seem to exhibit some orbits around each other so they don't achieve some equilibrium state in the game they're playing.
3424468	3426430	408	A	0.99998	They kind of just got around.
3428960	3441796	409	A	0.99999	But somebody was telling me about if you have an orbit and you're a physicist, you think, okay, well, what is that orbit conserving?
3441848	3444268	410	A	0.99997	Is there like a quantity that it's conserving?
3444444	3454576	411	A	1	And in this case, and I don't know the details, but in this case, this person found that the quantity that was conserved in this orbit was the relative entropy.
3454688	3456756	412	A	1	And so there's this weird thing going on.
3456858	3463540	413	A	0.98873	These things are playing a game, but they're still at this kind of somehow steady state of relative entropy.
3464780	3475610	414	A	1	And so there seems to be this deep connection between these kinds of game like systems and sort of information physics in some sense.
3476460	3479924	415	A	0.96	And I'm aware I need to head off for the moment, but I just want to draw one more picture.
3479972	3488030	416	A	0.99	And I'm sorry, Elliot, you probably had loads of questions, but we kind of ran out of managed to answer many of them, but hopefully we'll get to the rest of them soon.
3488740	3503780	417	A	0.99998	But if I just draw, as I say, one more picture, which is a kind of slightly different kind of duality, but a similar kind of similar kind of flavor.
3504360	3509408	418	A	0.99996	So what we have in systems theory is this category.
3509504	3521800	419	A	0.98993	You have this category of interfaces of systems and the morphisms tell you how to wire these systems together to give like hierarchical or like composite systems.
3523020	3544640	420	A	0.98	And if you have something like this thing which I wrote before Din, which I said for each interface I was like a category, then you can sort of think of this as a functor from int to like cat the category of categories.
3545140	3556176	421	A	1	And one thing you can do with index categories of this kind is you can sort of turn them into what are called like vibrations using what's known as the Groton deconstruction.
3556208	3566490	422	A	0.85	And if you know about physics, you've probably heard of a concept called a fiber bundle, which is just like a collection of spaces indexed by points of another space.
3567580	3585660	423	A	1	And so what you can do is you can write this vibration which says, okay, well, for each interface I've got a category of systems on that interface and they're all like glued together correspondingly with the wirings of your interface category.
3586320	3593088	424	A	1	And so you write this as like another function which kind of forgets about the dynamical systems and just returns the interface again.
3593254	3599090	425	A	1	And so you have this vibration thing here and this is like where kind of like physics lives.
3601800	3620020	426	A	1	And so what I've been trying to tell this story about, in this story about active inference is that you have a similar one where you have for each type of interface, the category of agents that might have that interface.
3620180	3637080	427	A	0.5978	Like we're all humans and so we are all like the type that might fit in like a human shaped box and so we're all in that particular category and we come together to form organizations and that's another object of this category of interfaces and another kind of agent category on those interfaces.
3637240	3639416	428	A	1	And so that gives you another one of these vibrations.
3639448	3652324	429	A	1	And the thing that something like predictive coding tells you is it says, okay, well, given a certain story about a type of agent, can I turn that into a dynamical system which actually animates it?
3652442	3655830	430	A	1	And so that's like a functor like this.
3656680	3669770	431	A	0.87564	So maybe what we could do is we could think of this as maybe like some version of biology or we could think of this as like we could think of this as like body and we could sort of think of this as like mind.
3670700	3676730	432	A	0.99	And so this is telling us how to go from a description of a mental system to a sort of embodied system.
3677100	3688430	433	A	1	And I think some of what the free energy principle is trying to say is that for certain kinds of systems there's a way to turn your description of a dynamical system into something that looks like an agent.
3688820	3697570	434	A	1	And so the thing I'm wondering is that whether there's some adjunction or maybe this is like I don't know.
3698100	3716410	435	A	1	I don't know which way we might write labels on these, but maybe there's, like, some adjunction here that allows us to compare these two processes of turning a sort of mental system into a physical one and then going in the other direction from a physical system into a mental one.
3717100	3721530	436	A	1	And so maybe this is also where information comes in.
3723340	3740224	437	A	1	And it's a kind of similar story in category theory where there's a sort of duality between geometry and logic that that's sort of sometimes written like this.
3740262	3761764	438	A	0.99999	You have truth values down here and you have logic over here and you have space over here and there's a way to sort of draw a picture like this that says, okay, well, logic is somehow like dual to space in some sort of mumbo Jumboy way.
3761802	3773930	439	A	0.99	I mean, again, I've run out of time, but I think there's a story that people try to tell about science in this kind of abstract world and I think it's a similar story to maybe something that's being told over here.
3775180	3782540	440	A	0.9998	Again, lots of details, and I don't know precisely the connection with Dalton's work, but I think it's kind of pointing in this kind of direction.
3784480	3785832	441	B	0.99997	Thank you, topy.
3785976	3797180	442	B	1	After you have revised and proceeded, let's have 54.3 and talk more about action, active inference.
3797260	3798368	443	B	0.99982	So thank you.
3798534	3799232	444	A	0.99978	Yeah, great.
3799286	3800288	445	A	0.99987	Thank you so much for having me.
3800294	3802980	446	A	0.75	And I look forward to speaking again and answering your questions.
3803050	3805700	447	C	0.8111	Ali, thank you so much.
3805850	3806804	448	C	0.98	That was great.
3806922	3807700	449	A	0.58351	Okay, great.
3807770	3808630	450	A	0.99507	Bye, guys.
3809560	3810420	451	C	0.89972	Bye.
3811960	3824276	452	B	0.67713	Well, I'd like to ask Dean a oh, Ali, please make a remark.
3824308	3840908	453	C	0.91	And then I have a yeah, you know, I really think of Toby's work as really provocative as it really opens up Pandora's box of many, many different fertile questions.
3841074	3854004	454	C	0.78992	So I'm a firm believer of this old saying that a sign of a great book is not how many answers it provides, but actually how many questions it gives rise to.
3854042	3886236	455	C	0.96816	So I really wanted to congratulate Toby on writing such a I mean, it looks as if he began from the perspective of trying to address some of the I don't know, some long held questions, but then it turned out to be much more deeper than that in terms of actually giving rise to many fertile questions.
3886338	3889010	456	C	0.9164	So, yeah, that's really great.
3892050	3902660	457	B	0.99182	Dean, I'd like to ask, what is the difference or how can we think about being on time in time and out of time?
3904950	3908580	458	B	0.99955	Because Toby said he was out of time with the answer.
3909270	3918866	459	B	0.99	And I know that we've spoken about this when we consider some of the time consciousness and category theory work previously.
3919058	3921240	460	B	0.99997	So what is it to be out of time?
3922010	3924470	461	D	0.99994	Yeah, that's a great question.
3924540	3946510	462	D	0.99999	All I can say at this point is that it's easier to discretize when you're in time and out of time as a comparator than it is to say when you're on time versus those first two positions.
3949010	3973200	463	D	0.80193	That's all I can say about that for now, because I'm sure Toby, from a diagrammatic perspective, could probably tell us what is happening when he's actually using his stylus versus not right.
3973270	3977890	464	D	0.66818	Like the result of that leaves something in and out.
3978580	3986470	465	D	0.61132	But while he's actually on point, he's literally in a different place.
3989160	3993956	466	D	0.99692	Here's an interesting thing, back to the provocative Ali in the Dot.
3993988	4004250	467	D	1	One was talking about virtual and actual models and was probably saying it in a way that's completely different than how I use.
4005280	4009710	468	D	1	I believe those same two models are in effect.
4010560	4043210	469	D	0.96	And so if you, for example, draw up a play, say, in sports, because we're talking a lot of strategy while Toby was on today and a lot of gaming theory and stuff, you draw up a play, then you confirm that you have all of the elements or resources that you need in order to be able to carry that out.
4044220	4052344	470	D	1	And then you're as a group communicating with one another like we are doing on this live stream, right?
4052382	4057384	471	D	0.99728	Like you're literally calling out the play in North American football.
4057432	4074880	472	D	0.52737	You'd huddle up and literally call out a sequence of code and then you'd have to literally reverse that and turn the inference as the shortest time window into a prediction.
4075300	4084470	473	D	0.99974	Like you would literally line up and then you would carry out the simulation in actual terms.
4086440	4107288	474	D	0.99563	All of that together means that I believe that the virtual version of the model is, as Toby was saying, in the bi directional sense, going in one direction, and the actual model is going in 180 degrees the opposite direction.
4107464	4119650	475	D	1	And then when he mentioned the dagger symbol today, I was just like, okay, where does that fit in to this bi directionality and the difference between.
4121380	4121792	476	A	1	The.
4121846	4125970	477	D	0.99938	SIM, the digital, the virtual, and the actual?
4126340	4142560	478	D	0.99985	So these are the things that literally pop up at any given moment, aren't necessarily part of what you consider to be the space that is inhabited by virtuality and actuality.
4142640	4144840	479	D	1	And yet there it is.
4144990	4146804	480	D	1	It just appears.
4146932	4151450	481	D	1	And then you have to sit down and figure out, well, where does that categorically fit?
4151980	4170156	482	D	0.99961	So again, don't want to go off on a deep rabbit hole philosophical take on this, but I just find that at any given moment, there is again, so much math in this philosophy that it's kind of staggering.
4170268	4178640	483	D	1	And just to be able to have somebody who can explain that and draw it out is pretty impressive.
4180200	4183284	484	D	1	I don't know if it's provocative what I just said.
4183402	4194360	485	D	0.73	I hope it isn't because, man, I did this work for almost a decade and it seemed like young people weren't scared by it.
4194510	4196890	486	D	0.99991	Maybe older folks are, but I don't know.
4200910	4213470	487	C	0.99704	So if I may add a brief comment on just what you said, I was recently watching this talk by John Bayes about the history of applied category theory.
4214290	4227182	488	C	0.8642	So he had this nice diagram showing the relationship between different areas of knowledge, I mean, going from business to pure mathematics.
4227326	4252470	489	C	1	And he claimed that most people in category theory, or in most other areas, consider category theory as being on the top of the pyramid, as being the purest of the pure, so as being even kind of being on a meta level than even the pure mathematics.
4252630	4262826	490	C	0.99996	But then he said that I believe category theory can actually be seen as kind of permeating all of these levels.
4262938	4269150	491	C	0.99998	So it's not something that sits on top of the hierarchy.
4269230	4274382	492	C	0.84518	It's something that actually can be seen as influencing and permeating all the levels.
4274526	4294330	493	C	0.80429	So at least from the perspective of applied category theory, it seems to be, if not self evident, but something that gathers much, I mean, more evidence as the research goes by.
4294400	4300714	494	C	0.97951	So I'm really optimistic in the research direction that applied category theory is going.
4300832	4310030	495	C	1	And hopefully in near future we can see it applied to many, many different areas, many different unforeseen areas.
4312770	4314654	496	D	0.88	I think I'll just tag on to that.
4314692	4332630	497	D	0.69419	Ali, if you use an abductive logic lens, then it's simply a question of when did you enter, at what point did you enter the abstracted timeline?
4332970	4340454	498	D	0.99987	Because if you see it that way, it's not just top down and it's not just bottom up.
4340492	4355802	499	D	0.95125	It's back to my question to Toby was, does the whenness of this really matter if you want to be able to take it off the shelf and use it?
4355936	4373554	500	D	0.98	And of course, his answer was, yeah, if you want to deal with idiosyncrasies, you're left with no choice but actually to acknowledge the point in the continuum where you take this up.
4373752	4380114	501	D	0.99926	But I think that actually makes it quite easy to see it permeating every level.
4380312	4390262	502	D	0.99998	But again, it's the abduction, the abductive piece of this back to last year in August, right?
4390316	4403722	503	D	0.95547	We're coming up on one year since we talked about how important that is, and yet here we are, what, ten and a half months later, and we're circling back.
4403776	4406394	504	D	0.67395	We have another predictive parabolic on our.
4406432	4407210	505	C	0.87577	Heads.
4411900	4414010	506	B	0.99744	Few comments on that.
4414700	4426316	507	B	0.96074	It's reminding me of Professor Mike Levin's work on basal cognition and the idea that intelligence isn't on the top of the pyramid either.
4426498	4434684	508	B	0.93554	Rather, it's something that's distributed compositionally across levels and something that exists at all levels.
4434732	4454980	509	B	1	And so we can then still talk about higher order properties of systems or properties of composites or aggregate systems while also grounding in the foundations.
4456440	4457220	510	B	0.76541	Um.
4462230	4472002	511	D	0.84899	Yeah, and that, and that grounding and anchoring and stabilizing, that's by itself is nothing but a feature.
4472066	4488640	512	D	1	I think you also want to be able to, though, because there was a lot of talk today about being able to see this in the way that things dynamically play out.
4489010	4499870	513	D	0.9999	So, again, we're back to the what's the minimum two ways that we want to incorporate this observation, both as stabilized and as searching.
4499950	4500580	514	D	1	Right.
4501110	4508770	515	D	0.98823	If we can have one eye on each at all times, it does take a bit of rethinking.
4512890	4517480	516	D	0.78175	There is a there is a there is an interoceptive piece to this.
4517930	4522460	517	D	0.99999	What we feel from that is different.
4526030	4538106	518	B	0.57	That brings us to the sensor fusion aspects of the dissertation 7.1.1 Bayesian sensor fusion.
4538298	4539040	519	D	0.93335	Yeah.
4540930	4547810	520	B	0.74	A situation that is common in natural embodied systems, but which is not yet well treated by current statistical machine learning methods.
4548390	4553380	521	B	0.9991	Also, Ali, thanks so much for asking the Markov blanket question.
4553910	4567718	522	B	1	I think his response is worthy, honestly, to review and unpack in the time we have, we can just sort of review a little bit and think about what other questions we want to prepare for.
4567884	4591360	523	B	0.61	Two, how would you, Ali, restate the limitations of the Markov blanket concept for all the positive things that we've said in the previous 300 live streams and where category theory can help address and move past some of that?
4593810	4614070	524	C	0.98625	Yeah, you see, this notion obviously is one of the most or, I don't know, probably one of the most controversial concepts in whole FEP literature because it has received a fair amount of criticism from many various perspectives.
4614810	4626822	525	C	0.99599	But some criticisms, at least as far as I know, they're basically directed toward the universality of Markov blanket.
4626886	4637760	526	C	0.99954	How universal is this notion as it's claimed to be ranging from, I don't know, inert rocks to the brains, right.
4638130	4650850	527	C	0.99934	So does it apply equally for modeling inert rocks as well as the most complex system we know of in the whole universe, namely the brain?
4651270	4678630	528	C	0.99713	So the response this line of criticism got from the researchers in the active inference area, again, to the best of my understanding, is to the effect that although theoretically, it can be applied to many different systems with many different levels of complexity.
4678790	4693518	529	C	0.99998	But then again, for simple linear systems such as I don't know, many non complex systems, it doesn't have anything interesting to say.
4693684	4700834	530	C	0.99981	So rather than being applicable to all of these systems, the relevant question should.
4700872	4701460	531	A	0.64925	Be.
4705190	4716418	532	C	0.95831	There are enough insights we can gain from applying this notion to many different situations and systems.
4716514	4736694	533	C	0.95095	So I believe Toby's alternative for this problem by proposing the polynomial function as a replacement for Markup blanket can cover this line of criticism pretty nicely.
4736742	4753074	534	C	0.49	It can address this criticism pretty nicely due to its abstractness and a kind of more rigorous way of talking about both the universality and the individuality of each system.
4753192	4768018	535	C	0.9997	So I think that's a nice way to at least a viable answer to this question that needs a lot more consideration.
4768114	4772380	536	C	0.98042	So that's my take on it as far as.
4774350	4793854	537	B	0.99618	Okay, I'll give my take two, which is the Markov blanket concept, since the work of Pearl in the 1990s is actually not doing that much philosophical work in and of itself.
4793972	4800334	538	B	0.69	It just describes the parents, the children and the coparents of any given node within a graph.
4800382	4803006	539	B	0.99755	So first, we're talking about maps, not territories.
4803118	4808798	540	B	0.99851	We're not talking about features of the world, carving nature of the joints, necessarily hashtag malandrus.
4808894	4810802	541	B	0.99978	We're talking about the Bayesian graph.
4810946	4821894	542	B	0.99	And secondly, even on the graph, it's not that a node is like by its essence an internal state or a blanket state or an action state if you use the Friston blanket.
4821942	4824202	543	B	0.99996	Rather it's always in relationship to others.
4824336	4827434	544	B	0.99012	So the concept by itself does very little work.
4827552	4842702	545	B	0.99922	However, people have deployed the concept implicitly and explicitly to describe interfaces of cybernetic entities, the kinds of entities that it makes sense to describe as an active inference agent.
4842836	4861750	546	B	0.99803	So we know from the particular physics and the strange kinds work the path integrals paper that we can describe using the formalism, the rocks, the simple active systems and the sophisticated active systems.
4863610	4863926	547	A	0.99997	In.
4863948	4880250	548	B	1	Order to have an interface concept that does justice to on one hand the relatively inert interfaces, on the other hand, potentially extremely conditional or contextual interfaces.
4882830	4893882	549	B	0.99993	Just having some tagging system of nodes on a Bayes graph is going to get extremely messy.
4894026	4900398	550	B	0.99412	It's not that it couldn't be done, but just in terms of actually doing the programming, it's going to be extremely messy.
4900574	4911350	551	B	0.99782	You're going to need to have a lot of accessory or auxiliary variables that indicate what the current interface is at this time or what it would be if this happened.
4911500	4926038	552	B	1	And all these kinds of conditionalities would be like a less elegant way of describing what our category theory colleagues have been developing explicitly with the wiring diagrams and interfaces.
4926214	4935470	553	B	0.99707	So just to kind of conclude there people draw the Bayesian graphs and the particular physics is using a Bayesian graph.
4935970	4950130	554	B	0.99949	However, Bayesian graphs don't naturally have a lot of these properties that were really being conflated with interfaces more generally.
4951030	4971606	555	B	0.99	And by using an interface concept, as Toby said, at an intermediate level of abstraction, that's slightly opinionated but also really flexible, that is kind of the right coarse graining, the right optimal grasp on the interfaces that we actually want to talk about for active inference agents.
4971788	4978854	556	B	0.99	And again, just trying to get down to the firmware with the Bayesian graph, we're going to get lost in the details.
4978902	4987530	557	B	1	And any accounting system that we develop is going to be ad hoc and certainly less principled or powerful than what the category theorists are developing.
4988990	4989354	558	A	0.99	Yes.
4989392	4993840	559	D	0.68369	Dean, I'm really curious what you think of this.
4994610	5004242	560	D	0.99985	If we're talking about the relationship with the interface, could we see and I'm really asking this question.
5004296	5023242	561	D	0.75	I don't know, I'm spitballing could we see the Markov blanket as the more stabilized version or form of the relationship and see the polynomial version of that as the search version of that relationship?
5023376	5024940	562	D	0.99998	What do you guys think of that?
5031070	5044400	563	D	1	And I'm really asking, just listening to both of you talk here, I'm just wondering if I'm having one of those unitary moments myself or if I'm way out to.
5047010	5050820	564	B	0.32224	Ali, give a first thought, then I'll also give a speculative answer.
5052870	5053282	565	C	1	Yes.
5053336	5071730	566	C	0.99728	So one thing that comes to mind is, you see, sometimes people consider markup blanket as being a kind of static boundary or interface that just separates the agent from its environment.
5071810	5084650	567	C	0.99974	But actually what it really is is kind of providing really a dynamic interface between those two internal and external states.
5084720	5089150	568	C	0.99964	So it's not a static or stabilized in any way.
5089300	5100038	569	C	0.99884	But of course, in some situations we treat it as if it's stable or, I don't know, static coding.
5100154	5113400	570	C	0.98267	Maxwell Ramstead every theory of markup blanket is inherently per se, so there isn't any static conception of markup blanket at all.
5114410	5140938	571	C	0.99998	But on the other hand, well, obviously for the polynomial function, not just polynomial function, but the whole area, category theory deals with objects not in their static sense, but rather in the meaning they acquire through their relations, through their morphisms.
5141034	5170390	572	C	0.97	And it's not about so one of the main differences between category theory and the set theory is exactly hinges on that distinction between the static viewpoint of mathematical or, I don't know even non mathematical objects and the inherently dynamical or relational identity of the objects as defined in categories.
5170890	5198720	573	C	0.9999	So I believe polynomial functions again, by themselves are inherently and intrinsically dynamical, perceptual, and in the terms of some continental philosophers, such as Alan Badu, they acquire existence through their imminent relations.
5201810	5212690	574	C	0.9972	They don't need any notion of pre existence as some of the Platonic notions of mathematical objects and ideas.
5213210	5239520	575	C	0.98226	So yes, in this sense, I think polynomial functions, I'm not sure which one can be seen as, I don't know, more dynamic or processual than the other, but at least to a degree, both of those concepts can be seen as sufficiently processual, in my view.
5241170	5241774	576	B	0.99998	Awesome.
5241892	5245962	577	B	0.81611	Okay, I'll just add with a few other associative comments.
5246106	5256238	578	B	1	One is to blanket something is to dampen and stabilize it, whereas polynomial seems to invoke, like many names, polynomos, polytopos.
5256414	5263018	579	B	0.99907	So potentially there's a multiplicity in the polynomial that is not acknowledged.
5263214	5277050	580	B	0.69892	So lexically in the Markov blanket and then a more formal way to say that would be a Markov blanket might be like a specific realization of some little neighborhood within the polynomial.
5277470	5281558	581	B	0.52758	So polynomial functor is a generalization of the Markov blanket.
5281734	5288766	582	B	0.99	And so in that sense, it requires more searching and it is more abstract and it is more general.
5288948	5297200	583	B	0.99949	But when you do stabilize it down, then the Markov blanket formalism may absolutely apply.
5298930	5309540	584	B	0.99631	But wherever the Markov blanket formalism does apply, like, let's just say that we stabilize down to a computer system and we have an API and we consider that that's one of our blanket states.
5310310	5316726	585	B	0.99	That would also be seen as an interface, of course, which is happy we'll talk about it.
5316748	5319080	586	B	1	And so it would be a polynomial function.
5320250	5344270	587	B	0.98	And so this helps us look back at the literature and see, as has been done many, many times in FEP and other literatures, recent developments enable previous developments not to be invalidated, but understood as special cases or constrained or stabilized cases.
5345010	5347520	588	B	1	And it only makes sense that we would start.
5349990	5357758	589	B	0.99761	Well, putting aside what makes sense in active inference, it seems that we are taking both paths.
5357934	5373720	590	B	1	In some cases leading with the stabilized and generalizing, but in other situations making unstable generalizations that then precipitate stability inside of them.
5376010	5377930	591	D	0.89282	So more bi directionality.
5383530	5384182	592	B	0.99996	Great.
5384316	5393574	593	B	0.99996	Well, we will have a 54.3 with a focus more on action.
5393702	5398694	594	B	0.9999	Are there any other topics that you fellas would like to raise?
5398742	5402880	595	B	0.99998	Or if anyone in the chat wants to ask a question, please go for it.
5403570	5410000	596	B	0.98571	In our last bit here, let's look back to the table of contents or Ali, please go for it.
5410930	5447370	597	C	0.94	No, just I wanted to ask Toby about the relationship between his theory or compositional account of statistical inference as opposed to the category theoretical account developed about, I don't know, more than probably ten years ago by people like Bob Kirky and others specifically related to the distinction between classical and non classical Bayesian inference.
5448270	5457034	598	C	0.89206	That's been clearly distinguished in one of the papers from 2011.
5457082	5458894	599	C	1	I guess so, yeah.
5458932	5473182	600	C	0.96883	That's one question I wanted to ask Toby, and of course a subsequent question about the relation of this distinction nondistinction to the accounts of quantum FEP.
5473246	5485640	601	C	0.99993	Because in quantum FEP markup blanket is kind of replaced, or rather blended with the notion of holographic inner screen.
5486170	5511230	602	C	0.99677	So how can we see quantum FEP as arising from quantum Bayesianism rather than from, I don't know, predictive quantum theory and the relation between those two frameworks of Bayesian inference to that topic?
5513750	5514500	603	B	0.99386	Awesome.
5514870	5522690	604	B	1	Yes, the quantum category theory active FEP triangle.
5526220	5542396	605	B	1	And also, I think the question about reading the literature in terms of the interfaces between a work and the citations, I think is extremely rich.
5542588	5553860	606	B	0.99905	It's a really novel way to perform bibliographic metaanalysis, but also just in our own learning journeys.
5555960	5579228	607	B	0.75457	This following this category theory dictum of knowing a thing by its relations understanding the paper within the web of the past papers which it cites, all of which are past and actual and then its future time cone of possible relationships to things that haven't happened yet.
5579394	5582488	608	B	1	The co parents haven't even happened yet, necessarily.
5582664	5586910	609	B	0.9382	But that becomes part of the evaluation of the significance in the moment.
5587600	5602728	610	B	1	And if we could have the right generative model and understand how much attention to weight onto different things in the moment, that would be like being able to see the whole time cone at the right core screening.
5602764	5605572	611	B	0.99996	But of course, as limited nest mates we can't do that.
5605706	5612020	612	B	0.99945	But we have our rules, our heuristics and our approaches that address that nonetheless.
5614940	5620090	613	B	0.99974	Anyone in the Chat or Dean, what would you like to explore in 54.3?
5623180	5627108	614	D	0.99673	I'm just going to follow the two of you.
5627294	5630524	615	D	1	I got two big workhorses here.
5630722	5633340	616	D	0.99	I just got to get out of the way so I don't get trampled.
5637520	5643744	617	B	0.99996	Let's look at the table of contents here.
5643862	5655270	618	B	0.94401	We're just shifting to the code of document, the back end that we use to coordinate a lot of our work just so that it can all be seen in the video.
5659160	5660790	619	B	0.99987	Chapter one is short.
5663480	5671370	620	B	0.82075	Chapter two, if someone is looking for another account of like, why does category theory matter?
5672300	5693760	621	B	0.94377	Toby begins chapter two with three examples of situations neural circuits, Bayesian networks and computations where people often just use a kind of schematic diagram but it's not necessary or sufficient to really convey all of the richness that we can add on with category theory.
5698900	5713750	622	B	0.99995	Chapter three starts getting into more detail with string diagrams and developing towards circuit diagrams in this rate coding neural setting, a lot more new vocabulary arising along the way.
5715340	5725640	623	B	0.74995	Chapter four, which the question the beginning of this Livestream brought a focus to, is on the compositional aspects of probability.
5726780	5733468	624	B	1	The copy discard structure is introduced, which we saw in the diagram today.
5733554	5748130	625	B	0.99989	That's when the piece of information is duplicated and then one of them can be thrown away Bayesian inversion, the dagger, Lady Macbeth's dagger always just dangling there.
5748580	5765690	626	B	0.98	Then the growth and deek construction, bringing back strong recall of Shauna Dobson, Chris Field's, math, art and the complexity of the self.
5768940	5773400	627	B	0.44803	Chapter five went into dynamical systems.
5774780	5786700	628	B	0.7717	Markov chains open and closed dynamical systems with this polynomial interface concept.
5787040	5793650	629	B	0.99772	It's really built up in an extremely methodical way.
5794500	5803292	630	B	1	First the dynamical system is kept, within a nutshell, extremely bounded, but then it's progressively opened up.
5803366	5812470	631	B	1	And so even though it's going to be a lot of new information reading the dissertation, it's done in a way that does also clearly build upon itself.
5813240	5840928	632	B	0.6621	Chapter six goes into the Bayesian lenses, connects to several more prevalent concepts in statistics maximum likelihood estimation, approximate Bayesian inference, auto encoders, and connects this to the emerging concepts of Bayesian lenses and statistical games in terms of the approximate inference doctrines in chapter seven.
5841094	5842450	633	B	0.99101	Yeah, Ali, please.
5843140	5851520	634	C	0.93	No, I just wanted to mention this particular chapter is being rewritten at the moment, so yeah, that's thank you.
5851670	5852236	635	B	0.97862	Absolutely.
5852358	5852692	636	B	1	Yes.
5852746	5859488	637	B	0.99995	As we discussed a little earlier, chapter six is going to get simpler but better, but it was tricky.
5859584	5860640	638	B	0.52143	But it's simpler.
5860720	5861556	639	B	0.99989	But it's better.
5861658	5862980	640	B	0.99997	But it was tricky.
5865260	5888380	641	B	0.56	And then chapter seven closes it out, but really opens it up with the compositional, cognitive cartography sailing the Three Seas society of systems more alliteration, many, many connections to areas of interest for all system scientists and complexity enthusiasts.
5891940	5896780	642	B	0.98261	What a tour de force and a journey.
5896860	5904790	643	B	0.99	And it's going to be awesome that we'll get to see some of the next increments in the work.
5905720	5907380	644	B	0.9977	Talk more with Toby.
5907800	5908900	645	B	0.96	Yes, Dean?
5910200	5911924	646	D	0.99652	Can I just throw this in?
5911962	5914896	647	D	0.99	And it's going to indicate how old I am.
5914938	5930040	648	D	0.85098	But a long time ago, the first time a needle dropped on the first Van Halen album, something changed about everything that we thought about guitar playing.
5930200	5936312	649	D	1	And if you weren't there in that moment, you wouldn't know how everything changed.
5936376	5963876	650	D	0.5911	I'm not sure what category theory taken up on a mass scale will do if it will be the equivalent moment for all people who use math in all the different ways that they use it, but I think that we are at the beginning of something that it is going to change things.
5963978	5982344	651	D	0.51	And I don't know exactly how it's going to change things, but I think this will always now be included as how we try to both figure things out and out the figures in that three dimensional space.
5982382	5992770	652	D	0.54	I mean, one of the things that I thought was interesting in the dot one was when Toby said, well, I work in 2D space and now I'm curious about I wonder what that would look like.
5994020	6001010	653	D	0.99216	Well, we exist in a 3D space and so I think the applicability of it is going off at any given moment.
6001540	6004470	654	D	0.99998	But I do really think this is the start of something.
6006600	6012500	655	D	0.99906	I'm not sure exactly what, but I don't think we'll be able to unlearn this.
6012650	6015690	656	D	0.52	I think it's going to remain influential for a long time.
6017580	6021370	657	B	0.75326	For those about to categorify, we salute you.
6022700	6023352	658	A	0.58982	Yeah.
6023486	6024120	659	D	0.97	Right.
6024270	6025320	660	D	0.62437	There we go.
6025470	6026410	661	D	0.99997	Thank you.
6027760	6029470	662	D	0.84498	You can always make it better.
6033360	6035708	663	B	0.99978	Any other thoughts on this?
6035794	6036620	664	B	0.76394	Otherwise.
6041750	6042500	665	C	0.96075	Great.
6042950	6043314	666	A	0.96268	Yeah.
6043352	6045970	667	B	0.93946	Ali, please with any last thoughts?
6046950	6051166	668	C	1	No, I just wanted to say I'm really looking forward for the next installment.
6051278	6057880	669	C	1	I hope it happens soon because again, I have so many burning questions.
6058250	6066966	670	C	0.71	I try mean whittle it down to some I don't know, not too much time consuming questions.
6067068	6074582	671	C	0.99132	But yeah, I'm really interested in I'm curious to know Toby's answers to them.
6074636	6079790	672	C	0.95639	So thank you so much for everything, for organizing this and inviting Toby.
6080210	6081600	673	B	0.59	Oh, absolutely.
6082850	6085200	674	B	0.99209	All right, thank you, everybody.
6085570	6087760	675	B	0.99996	See you in 54.3.
6092370	6092650	676	A	0.77842	Bye.
