SPEAKER_01:
Hello and welcome.

It's June 7th, 2023.

We're in ACT-INF Livestream 54.1 discussing mathematical foundations for a compositional account of the Bayesian brain.

So, welcome to the ACT-INF Institute.

We're a participatory online institute that is communicating, learning, and practicing applied active inference.

This is a recorded and an archived livestream, so please provide feedback so we can improve our work.

All backgrounds and perspectives are welcome, and we'll be following video etiquette for live streams.

To learn more about live streams and other projects, head over to ActiveInference.org.

And we're here today in ActiveStream 54.1.

We are in our first discussion with the author of the work, Mathematical Foundations for a Compositional Account of the Bayesian Brain.

Today in 54.1, we're going to say hello, then be on with it and see where it all goes together.

So we'll begin with introductions.

I'm Daniel.

I'm a researcher in California.

six months ago was quite unfamiliar with category theory and have had quite a fun journey with ali and dean and i guess toby via stigmatic proxy so really looking forward to this discussion and i'll pass to dean and then ali next time i'm dean i'm here at calgary um


SPEAKER_00:
My goal in joining this group was to take the idea, as we got in one of the previous slides, the idea of practicing applied active inference.

I see the potential through category theory of making that even more accessible, more possible.

And so I'm really excited to have the author with us today and maybe have a look at what that means.

And I'll pass it over to Ali.


SPEAKER_02:
Hello, I'm Ali.

I'm an independent researcher of Premier One.

And as I said in that zero, I'm quite excited to be here to discuss this magnificent dissertation with its author and

Well, I mean, in the past several months, we did our best to understand and dissect it as best as we could.

But obviously, we have many, many questions that I'm looking forward to discussing with.


SPEAKER_03:
so toby thanks again for joining please lead us off with just any introduction and background that's gonna set the stage maybe how the the work came to be and that would be great so thanks again for yes great no well thanks dan and and all of you guys for hosting me and and for having the courage to read my thesis which uh as you noticed it's a kind of strange mix of things it's kind of

both the research work and as i noticed um what are you saying in the in the previous stream it's at this kind of frontier of knowledge and of course it needs to be but i also because this language is so kind of unfamiliar to people and because i think it you know will prove to be very useful across the sciences um i really wanted to make

it kind of legible to people so you know for people to read the the thesis but also like my research and kind of understand what i was saying effectively how it came about was

i was supposed to be studying um interactions between frontal cortex and hippocampal circuits in the brain and at the sort of time of trying to get started with that um obviously i was kind of interested in the free energy principle and active inference and all of that um but i found that there was a lot of kind of

As I've said in the thesis and as you talked about in the previous stream and probably in discussions before as well, there's a lot of kind of, each research group has its own language and these different groups, they don't necessarily talk to each other in a way that is kind of

an efficient kind of communication each you know group of people is interested in their own thing and one of the things I like about the free energy principle and about active inference is that it this nice sort of general framework for adaptive systems and so it is in itself a good place to kind of situate an understanding of systems like the brain and other adaptive systems

But of course, it doesn't immediately resolve this problem of, well, the problem that was for me a kind of confusion about what's going on in these circuits and how should I understand what one person says in relationship to what another person says about this bit of the brain or this interaction.

And so in the process of kind of trying to understand what was going on there and to resolve in part the confusion I had about predictive coding itself and the complexities of all of these models I was encountering, I kind of resolved to replace that confusion with another kind of confusion, which is what is all this crazy category theory stuff?

and you know so you might think okay well that's mad what's the point of that you've just made everybody's life a lot harder it's kind of like that xkcd comic where you've got all of these different standards and you know we decide to like come together and and make a new standard and in fact this is happening i think and like i don't know what it was in in cellular biology maybe i heard john byers talking about this yesterday that you know they

have lots of different standards for writing down diagrams, but describing like interacting like biological processes and the kind of scientific community in that area has set up a kind of mediating body to kind of try to, you know, form like bring together all of these diagram languages.

um but they weren't really able to do so so they still they instead of just coming up with one new standard they came up with three new standards to try to unify these things and the trouble you know i had or have with these different languages or different sort of syntaxes for talking about scientific things is that

not only are they all different but they're kind of all ad hoc and so the reason why i feel that there's promise in replacing this confusion of this of of so many different ideas i mean of course it's great to have this kind of ecosystem of ideas about how these complicated systems work but it's still very ad hoc and confusing and so instead of just coming up with a new ad hoc and confusing way of understanding

these things, I was kind of hoping to use a language which is maybe kind of universal in some sense, like it's really about or it's really capturing like how we think and maybe also like how the world is actually built up.

um but in particular it seems to capture something of how we think and so you know the fundamental theorem of category theory says that you shall know a concept by the company it keeps to adapt the kind of that that sort of motto of i think um

birth from linguistics that you should know a word by the company it keeps.

That's really like at the heart of how we come to understand things in the world.

And I think the maths that is category theory captures that very nicely and very precisely and at the same time enforces a kind of discipline.

And so I know it is quite like hard going reading this kind of research work, this kind of introduction to all this new stuff.

But in part, that's because when you're being disciplined is hard and doing things very formally, precisely does require a bit of

well, you know, a lot of dedication.

But that isn't to say that it's not worth it or that these ideas even used a bit informally somewhere down the line might not be useful, at least to sort of frame the way we think about things.

So I hope to be, you know, some use in helping not only sort of change the confusions that we have, but also like modulate them in a kind of way that will be sort of useful for people.


SPEAKER_01:
awesome, great starting place.

Ali or Dean, where can we begin?

How can we replace some of our prior confusions with a new and different confusion?

Ali, want to go first?


SPEAKER_00:
Or Dean?

Yeah, can I ask a quick question to Toby?

Toby, when you were talking about when you actually saw all of these standards, so you know, you were the sort of

what you were the you were the hub of all of these standards you saw sort of all around you can you maybe speak to the idea of what you perceived or what you sensed was the stabilizing function of those standards but also the searching

Because, of course, you had gone out and realized there were all of these different standards at play.

I remember in a previous professional life of mine having to have chief financial officers and their math.

sit at the table with engineers and their math and them talking right past one another and making no sense to each other.

And I had to be kind of the medium between them so that their math would actually get a little bit sticky and they'd be actually be able to understand and interpret one another.

In your experience with this, how did that play out, both the stabilization through the standards and the search?


SPEAKER_03:
Well, I guess I should begin by saying that this is still ongoing, and nor am I an expert in all of these different standards.

But the thing that I kind of at least noticed was that

People use languages like Bayesian inference or reinforcement learning or dynamical systems to talk about certain bits of the brain that I was interested in.

And they kind of just plug all these ideas together, and it's fine.

So you want to write a paper, and it's about a particular phenomenon, and it's great.

You maybe come up with some nice model, and you put people in MRI scanners, and the quantities in the

in the sort of bold signal correspond to quantities in your model.

And that's great.

It says that maybe this bit of the brain is doing that.

I mean, we can argue about MRI at some other time, but it doesn't really tell you about how that little model you've got interacts with the rest of the brain or the rest of the world.

And so if you care about like this whole complicated thing, you want to know how do these parts actually talk to each other.

And so I was just fortunate at the beginning of this, in some sense, to be in the right place at the right time.

So I knew there were these different ingredients all being put into these different models.

only you know i'm only sort of familiar with some of them but i could still see that they had some similar structure and that was in part because i've been going to you know some applied category theory meetings or talks and seen that say um

economic games which are very closely related to reinforcement learning have this kind of bi-directional structure where an agent tries to sort of effectively in some sense choose they make an observation and they sort of do this kind of

forwards projecting kind of thing of choosing an action at the same time as saying, okay, well, if supposing I take this action, like what would the payoff be?

And that's this kind of backwards facing thing.

And then you can sort of chain that process and think, well, if I do this in multiple stages, like how does the utility I get at the end of this, you know, multi-stage process, like feed back to the utility I'm going to get having taken just one step right now.

And that's a similar sort of bi-directional thing to what happens in predictive coding specifically, where a little circuit is saying, OK, well, given my high-level beliefs about what's causing this sensory data, I need to sort of retrofit the actual sensory data to kind of come up with a new belief about what those causes are.

And so that seemed to me to have the same kind of structure.

A similar thing also happens in backprop in machine learning, where you have, say, some neural network and it kind of, you know, you feed forward some information through the network and it, say, does a classification.

And then you have some training system which says, okay, well, actually you have this error and then you need to sort of backpropagate that to update, you know, say, some part of the model on the basis of that.

And so that also has this kind of bidirectional structure.

And it just was fortunate that at this time people were talking a lot about these kind of bi-directional processes.

And so I was thinking about these things at the same time I was kind of thinking about the application of Bayesian inference.

And I kind of noticed that they had the same structure and I kind of wanted to figure out what was going on there.

Like really sort of pinned down

what it was that made like this kind of predictive coding circuit have this kind of shape in some sense.

Because as I think you've also talked about, and as I kind of mentioned a few minutes ago, that individual predictive coding circuit isn't an isolated system, right?

It's part of like this hierarchical thing.

And so you have one little circuit connected to another circuit, and that whole conglomeration of circuitry is supposed to do something quite grand, but at the same time, it's made of smaller parts.

And one of the major confusions I had at the beginning was, okay, so you have this big generative model with lots and lots of factors and you go through it and you try to derive the differential equations that give you the sort of predictive coding dynamics by saying, okay, well, we're going to minimize the free energy and you have this complicated thing with lots of sums in it.

it seems like very intimidating to try to like come up with that differential equation, even though actually when you sort of look at this, the kind of look at the process that you're doing is quite kind of mechanical because effectively you're doing the same transformation to each factor of this model.

And so that also hinted that there was this kind of compositionality thing going on in these systems.

Not only do you see that this bit of the brain has this kind of modularity, but you also get a sense of that modularity in that derivation you're doing.

And so what I wanted to do was to capture both of these things.

One is the kind of shape of the circuitry, and the other is how to somehow save the effort of having to kind of re-derive everything for each different case.

And that kind of formalization of this process corresponds to a kind of functoriality you get when effectively the functoriality means you preserve compositional structure.

And so what you want to do is you want to say, okay, well, what's the compositional structure of the thing that the functor starts with, like the process starts with, and that's the compositional structure of Bayesian inference itself.

And then you want to say, OK, well, what's the compositional structure of the kind of dynamical systems, which is the thing you're trying to get to?

And how do you map from one to the other in a way that preserves that structure?

And so that's kind of what I was doing in this thesis is just saying, OK, well, what are the structures I need and how do I relate them?

And it turned out that there were a lot of details.

I had to write them all down.

But the kind of basic idea, I hope, is quite simple.

It's just trying to say, what are the kind of individual components, like the kind of LEGO blocks, and how do they connect together?

And how can I sort of relate the kind of LEGO blocks of one thing with the LEGO blocks of another in a way that kind of preserves the shapes?

And so, yeah, it's kind of this kind of mammoth thing, but the kind of fundamental idea is quite simple.

And I think it's kind of like how when, if you're like programming a computer, you can write in a high level language or you can write in like low level language.

And if you wanted to, you could write in assembly language.

And category theory is like a language where you start with the kind of assembly language and you build up a high level language within the language itself in some sense.

And so if you really want to start with that at the very beginning, like I did with the definition of category and then build up to this big thing, you have to make a lot of steps because like assembly language is really simple and it's, you know, it's just like single instructions that your processor does.

And so getting all the way to something like zoom that can do a video call is quite complicated.

And so people don't, they start with the high level language.

but the thing that people strive for in designing high level languages is to set them up in such a way that they're sort of that the abstractions are quite nice or sort of modular and so that's what i'm trying to do with using category theory is to kind of find abstractions that are modular in a similar kind of way and i know um

the previous call um dan you mentioned um the the kind of analogy between like typing in this category theoretic sense and in the programming sense and they're quite similar the category theory sense is kind of a much sort of more general bigger idea it has a lot it sort of encompasses all kinds of things um but you could imagine somewhere down the line having a programming language and that you know people are trying to build these things

but having a programming language where you could express anything you could in category theory.

And I, to be honest, find it quite intense.

And quite sometimes mechanical and tedious.

I had to prove that certain categorical structure satisfies the coherence conditions that it has to satisfy, like, you know, lax associativity or monoidality or something like this.

There are a lot of like diagrams that you have to check commute or something.

And much of the time that checking is quite tedious.

And someday I hope that we'll have tools that we can say, OK, well, I'm going to spell out what my structure is and the tool will just check that it satisfies all the axioms.

And so, you know, I know you guys have to wade through a lot of that stuff in the thesis, but it's kind of manually necessary right now.

But in the future, it might not be.

And then we can use this high level language in a much more kind of liberal way.

I hope that'll be great.

Sorry, I've been waffling on for ages, so I'll stop there.


SPEAKER_01:
Awesome, great.

I'll go to a question in the chat.

Mark wrote, applied category theory and active inference have tremendous promise.

I confess I have not yet read this dissertation.

It would be helpful to describe a specific engineering application for the work.

So what do you see as proximate and or distal engineering applications here?


SPEAKER_03:
So one of the things that I hope could be produced soon as an engineering application is a sort of general modeling framework for building kind of complicated active inference systems that might include lots of parts, lots of, you know, agents, um, kind of like, um,

Something that my colleague Jules Hedges wants in cybernetics more generally, something like a kind of programming language maybe that incorporates

All of these kind of strange cybernetic structures I mentioned earlier, like reinforcement learning and like back prop in machine learning and Bayesian inference, they all have this kind of bidirectionality.

And so you should be able to have this kind of modeling environment which allows you to incorporate all of these things in a kind of nice way.

But I think before we get something quite as grand as a whole new sort of modeling environment, I think just having tools to help us build approximate and active inference systems that are really nicely compositional is one thing that I hope to come out of this.

To be honest, I don't know very well what the general tooling is like for this kind of thing right now.

I know that there's SPM, I know that there's like PyMDP for certain kinds of problem, but I don't know how some general they are.

Another thing

that you would get if you have this kind of toolkit because of the kind of modularity of category theory is you should be able to plug it into other things that exist already so one of the things that's particularly of interest to me at the moment is kind of multi-agent systems and sort of building trying to understand how we could build something like or simulate things like

something like a corporation or some kind of society structure where you've got lots of active inference agents coming together to pursue a sort of common shared goal, how can you kind of

effectively distribute that goal sharing across systems they could be like little robotic systems say or something like that or agent or like I don't know if it's precisely I'm kind of like an abstract thinker but I think like being able to kind of control or like modulate the performance of these kind of

distributed multi-agent like active imprint systems might be quite a cool thing to be able to build.

So that's kind of like a kind of maybe sort of flavor of the kind of thing that this tooling gives you.

I suppose for me, this particular work was really about

trying to encourage people to use this language to understand things more clearly.

So, yeah, there's a lot of stuff that I hope we can understand.

Well, at least I can understand more clearly.

Sure.


SPEAKER_01:
Awesome.

Thank you.

Ali?


SPEAKER_02:
Thank you.

Yes.

So in this paper by Christoph

Wojtowicz, Are There Category Theoretical Explanations of Physical Phenomena?

He argues that category theory by itself does not and cannot provide any mathematical explanations for physical phenomena.

So the idea here is that category theory is merely a meta theory to kind of do a kind of bookkeeping or house holding of the physical theories.

And it's not a tool to construct the mathematical theory of physical phenomena itself.

I'm not sure I agree with this argument entirely because in one sense, some of the most profound aha moments in the history of science obviously results from looking at a pre-existing theory or a model

from a novel angle and I believe category theory can provide such novel perspectives even when looking at some established and pre-existing models of theories so

I'm curious to know your opinion about this.

So do you think category theory can actually provide mathematical explanations for, I mean, either in cognitive science, neuroscience, or even other areas, other scientific disciplines as well?


SPEAKER_03:
I think it's a it's a subtle question.

Right now, it's probably largely the case that the role of category theory is kind of this.

I'm not I think it's like like bookkeeping, but like clarification to bookkeeping, if you think of it as a very general way of like trying to account for the

the things you're thinking about very precisely and not sort of miss details.

Like if your books don't balance, you kind of miss some payment or some debt.

I think that's quite a nice analogy.

But I think one of the goals of

quite a lot of people, or not maybe, I mean, a fair chunk of the community, particularly that which comes from a sort of more abstract mathematical side of category theory, one of their goals is to try to recast

a lot of how we think in kind of purely categorical language.

So one of the things that category theory allows us to do is to kind of formalize, in some sense, patterns that crop up all over the place using the notion of universal construction.

And the thing about universal constructions is that you have like

some little pattern.

And if you know that you can instantiate that pattern in your category, that you have like some object which kind of captures the essence of that pattern.

And you don't need to say, be able to kind of write down all of the specifics of that object

sort of a priori because the kind of universality gives you a recipe for constructing it.

It gives you it in some sort of unique way.

And so you know that if you have this universality, you can always like access this object.

And yeah, so I'm talking very generally

But because of that, one thing that people try to do is to try to say, OK, well, we've got these things that we're interested in, in, say, physics, like the principle of least action or the nature of space-time or something like that.

can we express those things as kind of universal constructions um or for instance in a completely different realm like we might have some process which is something we're interested in on the computer like um the migration of data and databases can we write that down in a way that

doesn't have any kind of ad hoc ingredients.

It only is built from universal constructions.

These are things that we can just write down kind of abstract sort of axioms in the language of category theory, and that kind of gives us the process or the structure that we want.

This kind of line of work is often called like synthetic something, like synthetic, you know,

probability theory or synthetic physics or synthetic topology or something like that.

And it means you sort of start from these kinds of very high level categorical ideas

And then you sort of end up with a characterization of the essence of the thing you're interested in.

In physics, a kind of a simple example of this, which I supply in a kind of relatively feeble efforts to say that it's not true that category theory doesn't give you a characterization of things in physics.

So there is a category of, say, topological spaces, and the morphisms between them are continuous functions.

And there's a category of sets, and the morphisms between the sets are functions.

And of course, underlying every continuous function is a plane function.

And so there is a functor from the category of topological spaces to the category of sets, which just forgets the topological structure of the spaces because every topological space has an underlying set of points.

So you have this forgetful functor.

And this forgetful functor has two adjoints.

And one of the things the category theory teaches you is that adjunctions give you this universality.

So adjoint functors are characterized uniquely by the satisfaction of this adjunction property.

So these two adjoints to this forgetful functor, one gives you what are called

discrete spaces.

So if you take a set, you can turn it into a topological space by thinking of all the points as little islands in this space.

So there's no like connectivity between them.

And that's called a kind of discrete space on that set.

And the other adjoint functor gives you what's called the indiscrete or sometimes co-discrete space, where all of the points are sort of collected into one big island.

So they're all sort of connected together.

So it's like a sort of fully connected graph.

And of course, that's very different from the discrete space.

And it's different from like the space time or the space that you live in, which has a particular kind of connectivity, like you can't walk through walls.

um and so you know people try to use these things particularly use adjunctions to characterize things like properties of spaces another thing that comes out of a jointness um and this is something that i um can let you read about uh later because it'll take me the rest of the talk to try to explain um but the you you might be familiar from logic that you have these quantifiers you have existential and universal quantifiers

And you can do things with these quantifiers.

Like you can say, you can sort of compose them together.

So you get things like for all X there exists a Y such that this.

And you can think sometimes of these composites or these compositions of quantifiers as like maybe like modal operators.

Like you can sort of decompose necessity and possibility in terms of the compositions of logical quantifiers.

But the kind of weird thing about quantifiers is that they too arise out of an adjunction.

It's kind of like they are left and right adjoints to substitution.

So if you have a proposition, you can substitute a term into it.

And the adjoint functors to substitution give you the quantifiers.

And you can sort of take this another step.

And then you can think about composing these adjoint functors.

And those give you the modal operators.

And so that's something that comes just out of category theory, but is really sort of fundamental in sort of logic.

And we might think that there's a kind of close relationship between physics and computation or physics and logic or physics and information and information and computation and logic.

So I think it's not quite true that there's nothing to be gained from thinking about

of traditional mathematical things uh or traditional physical things using category theory in some sense they you know doing that really clarifies the essence of them um because it tells you what their kind of universal properties are and you can then like instantiate those things in different contexts so one of the things that you could do is start to think about

these kind of logical structures in different contexts and that's kind of like what type theory is all about and you could use it to think about the logic of like dynamical systems or you could use it to try to characterize um say like the universal property even of the free energy principle and that's something i like to think about sometimes like how can we think about active inference systems as like trying to achieve their goals

Is that related to these adjunctions that come up in the foundations of logic when you look at them categorically?

And if it is, then that's quite profound because it tells you that maybe the FEP does have this kind of universality that people want to claim it does.

So I think it is true that right now, because it's quite early days,

category theory is kind of mostly used for bookkeeping, but I guess that might be because quite a lot of bookkeeping to do before we can make the most of this kind of move.

of make the most of using these kind of universal structures.

And maybe one day further in the future where people are more familiar with this kind of language and we have this big library of categorical tools and our computer modeling environments and programming languages know how to import stuff from this category just really easily.

And so you don't have to do all this kind of tedious manual stuff.

Maybe like in the future, in that future, it'll be much more common just to say, okay, well, we're going to start to model things using these universal properties, you know, off the bat, rather than trying to sort of retrofit them.


SPEAKER_01:
Awesome.

Thank you, Toby.

Ali?


SPEAKER_02:
Yes.

Thank you so much for your detailed answer.

And, um,

Again, I have a follow-up question to that.

So there's this view in philosophy of science that views scientific theories as not as a kind of monolithic, I mean, phenomena or model, but rather any given scientific theory can be viewed as a population of models.

So some of those models are more fundamental than the others.

or in terms of Manuel de Landa, there are virtual and actual parts of any given scientific model.

So the idea here is that the actual parts of scientific models try to capture

the context-dependent behavior of phenomena or any physical system but on the other hand the virtual or more fundamental part of scientific models or theories try to somehow capture its more abstract and

abstract model of the phenomena in terms of its topological invariance.

So do you think category theory can provide a rigorous language to somehow unify this view of science?

I mean, and to see how exactly those context-dependent part of scientific theories fit or at least

can be compatible with the context-independent part of scientific theories or the virtual part.

Because, you see, in the context-dependent or actual models, scientists usually try to refine their models to fit the data as close as possible or at least approximately close enough to be useful.

But for the more fundamental parts comprising of principles, axioms and so on, they only try to capture the topological terrain or the topological invariance of the models and how models can be compared in terms of their singularities and

topological shapes.


SPEAKER_03:
Yeah, that does sound very familiar.

I don't know this kind of work or idea in any... I haven't come across this before, but it does sound something that would be quite amenable.

And in fact, there seems to be, at least in my mind, some alignment between this kind of sense of virtual that you're talking about and this kind of universality that I was talking about.

So you could think of a category of models of particular kinds as being inhabited by all of those things which satisfy these invariants.

And then you have different individual instances of these things, which would be like the objects of the category and then the differences between them.

other you know the morphisms and the thing about morphisms in the category is that often they are the things which preserve the structure uh in other bits of mathematics they're called homomorphisms and that's where the word morphism comes from and so you could think of those as you know

ways of comparing the models or translating the models from one to the other um but preserving those invariants yeah and so that that seems to me to capture some of the idea that you were sketching

I guess one thing which may or may not be useful, depending on how you look at it, the category theory gives you is it's obviously kind of a lot more general.

And so it allows you to talk about invariance of kinds that are more than just

excuse me um more than just topological um in some sense like functoriality is a kind of um in like it kind of captures the kind of invariance as well and say okay well we preserve this structure um each I mean just one way of like looking at a topological space is to take its um

it's what's called its nerve.

And so that, that takes a topological space, and turns it into a category.

And you can sort of think of the morphisms in that category as like the sort of like the paths in that space, or ways to sort of get from one sort of part of the space to another.

And then, you know, morphisms

uh functors between topological spaces considered in categories like that they really are just things that preserve those topological structures um and so so you like this this language kind of seems to encompass the kinds of things you're saying um yeah yeah it would be nice yeah I I would love somebody to make that connection


SPEAKER_01:
I'll just follow up on this and then Dean, it's a related comment from Roman in the chat.

Roman wrote, quoted you in this fractal quote streaming, thinking about the FEP through category theory and relation to goals maybe allows to prove that FEP has the universality that people claim it has.

roman asks didn't maxwell ramsted and dalton's activity already kind of proved this in the bayesian mechanics physics of and by belief work so you're talking about the role of generalization

What do we gain with the category theorification of FEP beyond, for example, the generalizations that we've seen in Bayesian mechanics and G-theory over the last year?


SPEAKER_03:
Yeah, that's a great question.

I think...

maxwell and dalton are doing a great job um formalizing the ideas of bayesian mechanics but as far as i'm aware the job isn't done yet um and so i haven't yet seen you know i mean i have a particular aesthetic right and i would like

I would like to see a really clear recipe of a way to take of like on the one hand, some like or like some machine that takes in that has like a particular shape.

It's like input shape and it takes in like a dynamical system of a particular kind.

And it gives me back.

like the specification of an inference problem that that dynamical system is solving.

I think that's what Bayesian mechanics is saying.

It's saying, okay, well, if we have a dynamical system that is somehow kind of, you could sort of look at it and say it has a boundary, it's a Markov blanket,

that you can write down its dynamics as if it were doing free energy minimization, that is solving some inference problem.

but there's a lot of and i so i think that statement is true for certain classes of dynamical systems but it's not i don't think the story has been made like like the questions for me are like what are the classes um and what are their what's the essence of those dynamical systems so

it the result might depend on like specific technical criteria which maybe you think okay well like that that's kind of like a distraction from this kind of abstract principle which we're trying to get at and so it would be nice to sort of know what the actual like essence is of the problem that allows us to do this translation and then you know there seem to be to be like questions of

I mean, other fairly technical questions, but questions about things like, well, what is this boundary thing?

Like, how long does it persist?

And what does it mean to separate a thing off and consider it as having a boundary?

Most of the treatments I've seen of this idea have not been done, have not been explained or expressed in this compositional way.

And so they just assume you're given a system and a boundary, and then that's kind of it.

um but you know boundaries come in all kinds of shapes um like the boundaries of the cells in my body are kind of all like glued together in a particular way and they form me and i also have a boundary um and so how do the kind of local inference problems that are being solved by those individual cells

given their gluing, amount to the kind of inference problem that my whole body is solving.

And I don't think an answer to that is anywhere near given right now.

And yet, obviously, we look at systems out in the world, and they all seem to display this property of re-energy minimization, or at least something that looks a lot like it.

And so it would be nice to be able to relate those kind of inference problems to one another.

So I think there's still a lot to be done.

Just because we've kind of made some first steps doesn't mean that we're all of the way there.

Obviously, given my aesthetics, what I would love to see is this kind of abstract characterization of this universality.

um and i think i yeah i think there's a way of stating or at least the structure of that universal property um using this compositional active inference language of which the thesis is apart but effectively it seems to be something like this adjoint thing that i was talking about earlier so you on the one hand you have a like a something like a functor that takes

um statistical problems and gives you dynamical systems that kind of solve those inference problems and so that's a function from like you know statistical yeah what I call statistical games into dynamical systems of some kind but of course you have lots of dynamical systems and so you know what this um Bayesian mechanics idea seems to be saying is that you can go the other way as well

And maybe this mapping in the other direction is also functorial.

And that would be a way of characterizing this kind of gluing together of dynamical systems like I was talking about cells and ending up with maybe dynamical statistical games that also have this kind of gluing property.

But there's still a fair amount of work to be done

even to get the basic framework to spell out that story precisely.

It's work that I'm trying to slowly get on with at the moment.

But I think the ingredients to doing this in the kind of generality that I would like is starting to become clear.

And so hopefully we get there.

But I don't think it's sold yet.


SPEAKER_00:
awesome yes just so cool to see all these paths weaving together dean i i think it's awesome toby that you in this conversation have kind of anti-captured a jointness and common jointness because i think that's a huge part of of your work here and and reading it so here's my here's my question i

I think, and I would like you to maybe comment on this as though you were explaining it to a very curious 15 year old.

So on the sort of most basic level, when I hear under sort of a common adjointness principle, the word bookkeeping, I immediately wonder, okay, so what is the partner?

What's the thing that's being glued to?

To use your metaphor.

And so

I would glue it to taking receipts, essentially, where you have a stabilization of a record under bookkeeping.

So I get that part.

And then the taking receipts is the stabilization of the change function, right, the exchange, something that we receive, those two things seem to kind of work together, which then allows for compositionality, and all that other stuff.

But maybe

I wonder if maybe you could kind of speak to this idea that something is presented to us, and then what the category theory does is allow us to now start working with, so where does this fit?

Does this fit under this superordinate of being a tool, or does it fit under this column directly adjacent as a rule?

Like, that's the part where...

I think the adjointness could be really, really helpful in terms of maybe helping people see the applicability and not just the abstraction.

What's your thoughts on that?


SPEAKER_03:
So I think David Spivak talks about category theory as being like a kind of accounting system

or accounting systems plural for mathematics.

And I think he's kind of quite right there.

So the way I see it is like when you're keeping books, particularly if you're sort of using like this double entry system,

trying to keep track of the stuff that kind of flows into and out of your account uh your company or whatever it is um without sort of missing some bits you see where everything goes and so that's how i think of this kind of mathematical language you have this stuff

um and it's kind of like some like abstract collection of things some like maybe mathematical ideas and well a functor takes that stuff and does something with it and turns it into some stuff of another kind um but

it's like this kind of double entry idea that you know when you take something out of here you have to put it in here and so you have to sort of keep track of all the details at least all of the details that are relevant to those two to that float i suppose and so when you have an injunction you have a way of going from one place to another and back again without losing track of some stuff

It's like a little bit kind of like you're allowed to lose track of some stuff, but you know the stuff you've lost track of because you don't care about it.

Like, you know, you might allow for some, you know, have some like buffer there, but you know how big your buffer is or something like that.

So more precisely, an adjunction is a way to map from one category to another and back again in such a way that the two mappings are kind of like ideal approximations of the inverse of each other and that you can sort of measure the difference between them.

um they sort of like give you it gives you like an isomorphism of between the two sets of morphisms of some kind and that that kind of gives you this nice kind of structure preservation property this kind of bookkeeping property um i don't i mean so i know that there are people out there um who have used um

category theory to model stock flow diagrams and so these are used in economics to measure you know flows of stocks and things like that but they also use an epidemiology to model you know the transmission of disease because that's also like um a flow of some stock you have people moving around um

And so it would be nice to sort of bring this idea full circle and have this mathematical language of bookkeeping actually applied to bookkeeping.

But I don't know how that would go just yet.

But if we think of economies and corporations as adaptive systems,

or if we somehow kind of translate from flows of money to like flows of information that there does seem to be like an analogy between that kind of flow and the kind of flows that we think of in active inference explicitly um and you know another thing yeah one of the things I like about category theory is it allows us to make these analogies in a precise way and so maybe we can

relate these two things quite clearly.

I mean, it's yet to be done, but I would love to see it.


SPEAKER_01:
Awesome.

Dean smiles when his keywords are buzzed during a response.

We'll go to another great question in the chat from Matt N. Matt wrote, can you provide some ideas about the next necessary steps or milestones for categorical theory to be effectively utilized across research and in subsequent engineering applications?

And I'll just kind of append to that.

What do you think at the individual team and organizational scale

What can we do?

What milestones exist to realize some of these engineering applications and implications that you brought up?


SPEAKER_03:
Right.

So I think the main thing, possibly, unfortunately, for you guys who spent a lot of time reading the details I wrote, is to kind of have this community involved.

develop to a stage where the tools that I mentioned that allow us to kind of use these category theoretic concepts fluently without having to know all of those like boring and complicated details, to develop those to a stage where people are actually able to use them without being kind of like mathematicians or category theory domain experts.

um so this is I think starting to happen I guess you know as a result of the kind of needs of the pandemic people have developed these tools for epidemiology I mentioned this stock flows stuff and I think you know you can probably there's like some I can't remember what it's called unfortunately now um

So in the Julia programming language, there's this great framework to use for kind of building system using category theory concepts.

But of course, this doesn't satisfy the property of not having to be a category theory domain expert.

Yet on top of that, people have built using compositional ideas about dynamics.

frameworks for building compositional dynamical systems and compositional models for things like epidemiology and stuff like that.

you know hopefully we'll get there also with um you know statistical modeling and active inference and all that stuff but what you know once once you've got that kind of lower level library people can start to build like user interfaces on top of it and that's the thing that's starting to happen now with the stock flow stuff um and i think the people involved in that project are

I mean, they know that there's one major proprietary tool for doing this kind of modeling, which is used by lots of different organizations.

For instance, it was used by governments for modeling during the pandemic.

But it's not very collaborative.

It's not compositional.

So if you have this huge model, it's very hard to deal with, to modulate just some small part of it.

And so these people, as I say, it's very unfortunate I can't remember all their names or the name of the software, but they're building this tool which allows you to build out these models just using this interface, but it's built out of this compositional stuff.

And so it has a lot of the nice properties that come out of it.

And of course, if you want, you can sort of delve under the hood and understand actually how it works and connect it to all this other stuff.

And maybe down the line, when we've got really advanced tools, that will kind of be able to be done for free in some nice user interface.

But I think, you know, so if people want to make the most of this, you know, they can sort of get involved with that kind of effort, or at least they can sort of get familiar with the basic ideas of categorical modeling or compositional thinking, as I like to say these days.

But I don't, I also don't want to like prescribe to people where they have to know what like a monad is and all that stuff, because you know, there are, it, it, it is technical.

It, it has to be technical because it's about technical stuff, but I mean, it's also trying to be ergonomic and yeah, if, if that's your thing, you can try to help make it more so.


SPEAKER_01:
Awesome.

Dean.


SPEAKER_00:
No, I'm waiting because there's a part of the paper that the belief updating and the fuzzy of distributions and stuff.

I'm going to want to talk about that later, but I'm done for now.


SPEAKER_01:
right i'll go to a question submitted by jr also who created the syllabus so thanks again jr for that amazing work so jr wrote um in compositional active inference from may 17 2021 toby said i'm with valeria on this i think we need to seek ai alignment for the artificial intelligences that we already have things like corporations and social systems and we should be concentrating on those right now

Could you speak more about how you envision this kind of application?

This is especially interesting in light of what we spoke about in the 54.0 regarding sensor fusion and consensus.

What might this mean for corporations and social systems?

Toby, do you mean that this between humans and things kind of like artificial intelligences or machines and artificial intelligences in the context of companies and societies?


SPEAKER_03:
yeah that's a great question and i think you know jr's done a great job with the syllabus which i also had a look at um yeah yeah i think uh

it's a good it's a good it's a good like list of um material and concepts to sort of get get to grips with um but as for yeah AI alignment it's a very vexed issue of course um I know I mean I've put this to people who are involved in the AI safety community and some of them say oh well

we concentrate on machine intelligence rather than corporations because there's no hope for making corporations safe.

It's too late.

They're already out there, so we can't fix that, which is obviously a very defeatist attitude, but maybe it's right to concentrate on a matter where they think that they can actually have an influence.

But I do nonetheless still think that

Corporations are like super intelligences.

They've been made out of code, but the code isn't a traditional computer programming language.

It's the legal programming language that makes up their contracts.

those contracts sort of determine how they operate and are executed on a thing which is a bit like a computer like the legal system um you know you go in a court it processes the contract and it explains what the outcome is going to be it's a it's like a computer but it's it's like made up of people um and you know they have you know goals and

desires and they take actions and they receive information from the world.

And so, yeah, they're a lot like, well, AI systems.

But it's nice because we can pun on AI and have it mean both artificial intelligence and active inference.

So yeah, so that's like a long preamble.

One of the things that, at least as far as I know right now, the active inference literature doesn't talk an awful lot about, at least not very precisely, is this notion of sense of fusion.

So you can have like

So if you think about the brain again, you've got two little neural circuits next to each other, and they're making predictions about two visual receptive fields.

But those visual receptive fields, they kind of often overlap.

what we might want a system like the brain to do is to be able to kind of glue the two inferences that those circuits made together over this overlap so that you get like this

unitary perception.

We don't just see a bunch of independent patches of the world.

We see this kind of glued together thing, even though the way it's been inferred is through lots of individual systems next to one another.

And so it's

quite you know it's quite clear how to put two things next to each other mathematically you just take their sort of product that you do then you just do them side by side but when you need to when you want them to sort of glue together in this way you might encounter some problems like you might have one make one inference and one make another inference and so you get like a disagreement

then you need to start to say okay well what's what's going on there like what is the nature of this disagreement is it something that can be resolved by like say you know passing some messages between the two systems or do we need to just like ignore some of the data or is there fundamentally some like paradox which means that we can't resolve this disagreement

Excuse me.

And so in mathematics, there's a lot of theory that's been done about precisely this question in topology in an abstract way related to the field of what's called cohomology, which is all about measuring obstructions to doing this kind of gluing thing.

And in this world of applied topology, people talk about

algorithms for resolving disagreements and and things like that and they often have the flavor of like diffusion you can sort of think of diffusion as like smoothing out disagreements like because you're just sort of like letting stuff propagate um something there maybe could be said about like how these diffusion models work in generative ai but i haven't really thought about that

And so maybe there's something to be done for political systems or corporations, like maybe we can look at how the mathematics says we can resolve these disagreements and implement better processes in our organizations that are inspired by those algorithms or universal properties.

And, you know, maybe that'll make the world a kind of more harmonious place, or maybe it will just help us build, you know, systems in the future, which resolve disagreements better.

And this is one of the reasons why I was talking about, you know, multi-agent systems before.

I know

This is a thing that sometimes people think about in the context of blockchain systems and things like that, which are actually actively composed of lots of different participants.

But I don't know yet how it might all pan out.

I mean, ultimately, the question of alignment is really about do the goals of this other system

disagree with my goals and you know if the other system has more power than you then ultimately there's probably not much you can do about it regardless of whether there's whether there exists some algorithm that might help you smooth it out so I think I hope at least that by looking at how like

mathematics says we can optimally resolve disagreements or smooth them out or patch things together or build kind of multi-agent systems that will help us build things in the future in such a way that we don't get to a situation where the systems we're working with are actually aligned against us say um but obviously we can't really guarantee it we actually have to sort of do some work but it's nice that at least

the framework of active inference allows us to talk about that at least, right?

So, you know, we can say like, oh, I have these beliefs about the world and this other agent has these beliefs about the world.

And then, you know,

we can express these beliefs in a mathematical framework which is amenable to using these tools from cohomology and applied topology to be able to start to make use of that work that's already being done.

It's, to me, not so clear how you would do that if you're not working in this active inference world and you're working, say, with just reinforcement learning.

I know

there are similar questions about how to kind of glue together preference functions in economics.

And I think for me, the simplest way to kind of understand those questions is to kind of turn those preference functions into distributions over states and then use this kind of sort of more active inferency language to think about it.

So yeah, again, we're just at the start of this process, but it sounds like we should be able to make use of this wealth of tooling, which has been developed in other fields.

Because we're putting this into this kind of modular categorical language, we should be able to kind of put these two modules together and make the most of them.


SPEAKER_01:
thanks i'm gonna go to a different sort of question here i'm gonna uh play dissertation roulette but i kind of know where i'm gonna go and uh i'm gonna skip to a diagram it's a diagram at the end of chapter six and it looks like this so what do we see here what happens

in this graphical arrangement it doesn't have to be ultra specific about defining every variable but

Is what matters here the topology or the geometry?

Is it an arbitrary visual layout, but you're conveying something about the connectivity?

Or is it read from left to right?

Or is there a certain way to understand or just approach these diagrams, which in slightly smaller forms or larger forms, we see peppered throughout category theory and your dissertation?


SPEAKER_03:
So, okay, yeah.

So here, what I'm trying to do

is say that if you have a hierarchical predictive coding system, if you take the formative two parts that are sort of plugged into one another, and this is the G and the H, if you do predictive coding on G,

And you sort of plug that into H and then you do predictive coding on H with that input.

It's the same thing as doing predictive coding directly on the two parts as if they were one thing at the start.

So what I mean is if you have, so like here, we've got like a hierarchical system.

again, the parts of the hierarchy are G and H. And we could do two things.

We could either apply predictive coding to the two parts and then glue those predictive coding systems together.

Or we could glue the G and H together and then apply predictive coding to GH, the glued system.

And what this bit of this result is saying is if you do those two processes, you get the same dynamical system.

And that's saying that this predictive coding thing, at least with this sort of Laplacian scheme, is functorial.

So in this diagram,

It is read from left to right.

I mean, in some sense, you can orient these diagrams however you want, as long as you're clear about how the information flows.

And if I remember rightly, what we've got is we've got some like, yes, we've got X and Y. So I think

So we've got one system which is predicting X and one system which is predicting Y. And I'm not totally sure what P and Q are, but I guess they relate to X and Y. And you've got some stuff that's coming into the predictive coding system H of G. And some other stuff which is coming in and going to H of H.

And these give you updated states.

So in predictive coding with this Laplace algorithm, what happens is that you get this new observation that comes in, and you look at the error between that observation and your prediction, and you update your prediction according to the direction that error points you in.

And so that's what these HG and HH systems are doing.

But because it's a hierarchical system, this like second layer, which, yeah, this second layer requires you to take in the prediction of the first layer.

So if you sort of follow in the flow of information, HH takes in inputs from gamma.

Gamma is the kind of,

the predictive channel, the predictive part of G. And so that feeds into H. And the update of G, which is a sort of layer above H, requires this sort of newly updated belief from H, right?

So that's going sort of up in the causal hierarchy.

And so if you sort of follow the flow in as well into this g update function at the top, h of g, you see that it gets an input from this sigma function.

And that's the new belief emitted by the h system in this part of the proof, at least.

That was the notation I used.

And so this is a saying, if you do predictive coding on these two bits, it has this structure, which is you do the forwards pass down through the system G and then H. And that gives you a prediction at the lowest level.

And then you take your observation, which is, I think, the thing you get in

here in Z, yeah, that's what Z is, it goes into H, you get an updated belief that comes out in the form of the sigma and then gets passed to the first level of the hierarchy, which is used to give you the highest level of belief.


SPEAKER_01:
Great.

Well, it's awesome because in so many papers,

we see what I guess people expect and prefer, which is you should be able to make a nested model here and have communicating agents here and do sophisticated affective inference in this way.

And it's like we're already playing with the Legos in a sense and talking about it like it's a total play shop.

So to understand in a way that is worthy of dissertation research,

some of that substrate, it's basic Lego research.

And how do you know when you're working, you describe this as a result

How do we know?

I mean, can I just draw a line from here to here?

Or can I just make a D and just have D connect to gamma?

What rules, do you keep a guidebook or a recipe on the table?

What rules help us know what edges and shapes you can even draw?

And when you describe the manual checking, are you looking for what?


SPEAKER_03:
Right, so yeah, this is a good question.

So yeah, this is like, it is like a language, so it has a syntax.

And that syntax is like, I mean, it's like the grammar, right?

And it tells you what things make sense to say.

And so you only say those things.

don't we all don't we all no but that but it's it's that's what i am laughing because often you want to like play with the grammar right and so sometimes you're like oh well you know i'm it feels like i'm not allowed to like draw this thing like i'm not allowed to connect this box to this other box in this way but like i really want to do that

And it's actually, that's not a bad thing.

You shouldn't do it in that diagram where it doesn't make sense.

But you should take that feeling and reflect on it and say, oh, but that's saying that maybe this diagram syntax is missing something important.

And then you should trust your intuitions there and say, okay, well, actually, what do I need to do to this diagram language to make it like,

allow me to do that move that I wanted to do, to draw that thing I wanted to draw.

And so that suggests that you're walking through a valley, and you can see there's a hill over here, and there's something peeking out over it.

And you're like, actually, there's something over there I need to be able to see.

And so you have to move over towards a different place to be able to get to that place.

And so you should do that, right?

Then that's fine.

But the reason why I said at the beginning, don't just draw it in your diagram is because then that means your diagram doesn't mean anything.

And that's worse.

So this is part of the reason that it's actually requires using this kind of mathematical formalism, really using mathematics generally requires this discipline.

Because you don't want to say things that don't make sense.

If you have an intuition, you should do it justice and treat it seriously.

And you probably get more out of it by figuring out what's missing.

So like, you know, with this particular kind of string diagram language, you can't just get used to reading them, right?

So you know that these little black dots mean copy some information.

So if you see the first one or like the second one on Y, you know, you go from Y, you go to this copier and you just send the information to both of those outputs.

If you read like Bob Cooker's work or say his book on...

his book picturing quantum processes which is all about uh quantum theory using this string diagram language um there's a lot of like there are lots of lots of different rules for like stuff you can do with these languages languages like you have colored like spiders he calls them which are like colored versions of these black dots

And, you know, there are things you're allowed to do, like if you have two spiders next to each other that are the same color, you can sort of merge them to be a spider with like, as many legs as the two of them.

And if they don't have the same color, then you can sort of split them apart.

And like that's that those kinds of those kinds of moves are like,

part of the syntax of this language, but it's a human language.

And so people developed it and they realized that they could do some things and they realized that they couldn't do others.

And they tried to make the rules of the game match the things they wanted to do.

And they ended up with this language, which is now used a lot in quantum computing because it's a very sort of like natural language for that problem.

so as to like how do you know what kinds of things to draw well here like I was trying to prove functoriality which is the sort of general property and it says the thing you know it says in an abstract way the thing that I started by saying which is like there I was I wanted like h of gh to be the same as

Yes, see here.

If you see this line, the update map of the composite system, you see I've got HH after HG.

Well, I want that to be the same as H just applied to H after G. And so that says, okay, well, I want these two things to be equal.

And so what I do is I draw the two diagrams for the two parts.

And they, okay, you draw them out and they, first of all, they don't look equally like, oh, that's annoying.

But then you stare at it for a bit and you reflect on the kind of moves that you're allowed to make.

You think, well, OK, maybe I can apply this move, and it makes the diagrams look a bit more similar.

And eventually, you make the diagrams look the same.

You've only used rules that you're allowed to use.

I can see you skimming through to see if it looks like that directly in the thesis.

But effectively, that's what's going on.

It's just that the rules are a little bit abstract.

Though, that being said,

I know that Pavel Sobochinsky, who's a researcher in category theory at Tallinn, he's got a project with a colleague of his to build a mobile game, which is all about making string diagrams equal in this way.

And so the idea is that in this game, you have like, pictures like this, and you've got certain moves you can do to manipulate the pictures.

and that you know and the sort of aim of the game is to like transform one the sort of starting picture into like the sort of gold picture just by applying these moves and as you go through the game the kind of moves you can do become more complicated um but it's i mean it's the same kind of process i'm not sure the game is at the stage now where you're allowed to like

do this human creative thing and think, actually, I want to make that be a new kind of move or change the diagrams or add in a color here or something.

That's a really human thing.

And there's nothing to say you shouldn't do that.

But I'm just trying to advocate for doing that in a way which is also rigorous.


SPEAKER_01:
Awesome.

Awesome.

Yes.

to speak fluently the syntax and the grammar whether we're talking about natural human language or we're talking about the active inference ontology we want the syntax to be unobtrusive if not compressient so that we can actually convey the semantics because that's the real information flow

the syntax is within the Shannon signal entropy space.

And then in Livestream 17 and 4D and the Physics as Information Processing with Chris Fields, where we've been exploring these semantic Bayesian information flows that must out of necessity to be enriched beyond the syntax have to include an individual or shared context

that flow necessitates the proper syntax.

And so it's just part of the learning.

And so it's exciting to see that there's games and work like yours and others to help.

Because if we could play with those Legos and get the instantaneous feedback, just like learning with a language tutor of like, no, these two pieces, they don't fit together.

And then it just, we kind of would actively infer patterns, make our own rules and understandings, but there would be certain compositionality of the system itself

And so it's interesting to think of, like, you described it as a natural language.

It is technical and naturally arising.

And our natural language, without going too much into the Sapir-Whorf and everything like that, it reflects the kind of subject-object-verb structure that we often want to convey.

This is a natural language for science.

it conveys what we want to convey.

And so being able to do that in a way that is both disciplined and rigorous,

also enabling low cognitive overhead fluency for some individuals today but for more tomorrow that's just extremely powerful and the fact that it has like such a beautiful and intuitive way to graphically represent it

is very promising because that may tap us into a more holistic understanding and a visual field or a felt sense understanding that just looking at this and someone says wait this is what we learn in active inference it's like well no that's not even the tip of the iceberg there's so much more to it and it's not only this and all of that but it's one of the pieces that at this moment in time

in our sort of early calculator phase, or abacus phase almost, it's one of those things that we're tackling, but it's the wave that we're riding.

And I just can't wait until there's more accessibility and the learning pathways and the playgrounds to use all this.


SPEAKER_03:
yeah i mean i i totally agree with with all of that and i i think um it was it was nice to see the gr in this syllabus that included um references to eugenia cheng's work because she's done a lot of great work to kind of make mathematics more accessible in this way um she had an article in the guardian like

in the last week or so even talking about mathematics education and how it's often it often like scares people because they're taught to like you just apply algorithms in this kind of blind way to do like multiplication or calculus or whatever and not really like play with the concepts

the way that i was trying to say okay well you know you're drawing these diagrams and you know you want to like play with them and it's it would be nice to see mathematics education take this kind of more playful route to start with one of the things that um eugenia says in this article is that unfortunately that would make things kind of slower because like

you just want people to muck around.

You don't want people just to be able to churn out this kind of computation.

But in this future where computational tools are so powerful,

maybe we don't all need to be perfect integrators or derivators and be able to multiply numbers quickly.

Some people like doing long division, but I don't even remember how to do long division.

Why would I?

It's silly to kind of drill that into children.

So there have been projects

um to teach like kindergarten children um like like a couple of projects not many some of the kind of rules of this string diagrammatic stuff um in in this quantum um information processing world this um of book bob cooker and his colleagues

think there was one um project by dan geeka in birmingham and maybe one by bob himself or at least he was trying to get it off the ground i don't remember um but at least where it has been tried i think they found that children very easily learn to use these

these kinds of languages because it's just playing with pictures.

They're kind of much more approachable than this kind of scary symbolic language, which is, you know, I mean, it's a kind of fine language if you're used to, like, typing on a typewriter or like writing by hand where you write in this linear way.

But if you go to a mathematics department and look at the whiteboards or the chalkboards there, most of the time you see lots of pictures, diagrams and things.

And that's how people reason typically.

And so a lot of what's been happening with applied category theory is trying to take using diagrams seriously as mathematics.

and trying to say, OK, well, here's what we can do if we do take it seriously.

We can recapitulate some of these things which people have found abstract or abstruse or difficult in mathematics before and make them seem a bit more

easy to reason with now and so I mean that applies to like abstract things like stuff I've mentioned already like adjunctions like the laws of adjunctions you can draw them with string diagrams I mean you know I haven't shown it in my thesis but like you can if you sort of Google around you can see you know adjunctions in a two category and they end up being some kind of snaky picture

And so you get a sense of what's going on there from these pictures, like the flow of information in some sense.

And there's a similar thing with monads.

The joke for functional programmers about monads is like, oh, you don't know what a monad is?

Well, it's just a monoid in the category of endofunctors.

And I mean, that's true.

It's not just a joke.

It's true.

But the thing is, if you draw

what a monoid is it's like a thing which like like one of these like you see on that picture you've got this Gauss thing and then it's got a black dot and you got you got one wire and then it it has a black dot and then two wires come out of it and I said this is like copying

Well, like a monoid is like that in the other direction.

Like you've got two things that go into a dot and that come out with one thing.

So like when people say monoid, they mean something like they often mean something like addition.

You've got two numbers that come together and they produce one number.

We've got like multiplication.

You've got two numbers.

Again, they come together and produce one number.

So it's like the opposite of copying in some abstract sense, which takes one thing and gives you two things.

This is something that takes two things and gives you one thing.

And so you can just draw the diagrams that define a monoid and say, OK, well, what does this mean for endofunctors?

And you can sort of start to reason about it a bit more approachably.

I mean, it's still quite abstract because it is quite abstract, but it makes it kind of less scary to use this kind of language, I think.


SPEAKER_01:
awesome yeah there's so much psychology and sociology and mathematics and just hearing about yeah on real chalkboards people branch and they flow and they circle things and they put an x through something it's like there's all these operations that can't be copied with a typewriter

And as our cyber-physical and social niches develop, and we have different affordances, different metaphors, different quantum reference frames for working and being, it starts to make more sense for having a natural language that can express that.

Yeah.


SPEAKER_00:
Yeah.


SPEAKER_01:
No, no, go on.

I've said loads of stuff.

It just makes me think of a Turing tape.

where even if there is a linear representation, it can still in some other way, characterize like a Lisp program with nesting or hierarchical model, even though yes, there's like a linearity, but also there's a model.

So it's not that we can't represent certain things with a bit streams or anything like that.

It's just that that may be more like the assembly language.

And that when we actually wanna do certain kinds of work,

we may want to just move lightly and semantically with a high-level way to think about math.


SPEAKER_03:
Yeah, totally.

It's notable to me that recently, I've been giving talks for a while using a computer, whether or not over Zoom, but it could be in person.

I have my PowerPoint slides or whatever.

these days if i give a talk i just use my like tab like digital tablet and i do everything like all the slides by hand and i draw pictures and it's nice now that we've got like technology that is starting to you know be a bit more human in that sense and i think this is like a kind of mathematical technology which is like that although i think it's also notable that

um it's still in substance quite niche and i think i mean i don't i don't know but the impression i've got from talking to people is that it's still the case that some mathematicians sort of think of this kind of like mathematics of diagrams are somehow like not quite like real mathematics because it's like it's too much like play in some sense um but i think that i think that perspective is changing and people are taking it seriously i mean it is real work and there's a lot of hard problems um

and you know stuff actually gets done but i think it's it doesn't to me it doesn't really matter what like a handful of mathematicians think it's just what's useful to people that matters um and so i mean i i hope that you know these tools continue to develop and like you know we can use them in all sorts of different domains um i don't know you know i've never really

It's like notable to me as well that like human vision is kind of like two and a bit dimensional, really.

It's not really like three-dimensional, but you've got a bit of three-dimensionality.

And I've never really played much with like three-dimensional diagrams, but maybe I will one day have some tools with my like, you know, vision pro or less not pro thing or whatever.

It'll allow me to do things even more like naturally, like actually like plug together some stuff in some abstract space.

Who knows?

Who knows?


SPEAKER_01:
yeah the diagram being two-dimensional or planar gives us this kind of classical screen holographic screen that information can be written on that then quantum cognitive agents can unfold into the imaginary plane with the wick rotation

But also the boundary, just like you said earlier, can come in many shapes, many dimensionalities.

So we could have a four-dimensional boundary artifact that still becomes rotated into a higher dimension.

And that's not the framing or the mathematics that most of us have learned up to this point.

There's a really...

Crystallized would be a complimentary way to say it, but codified or fossilized sedimentary understanding of math education, its role in broader thinking and what we learn along the way and the progressions get reified with who makes it through the pipeline.

So I think that's like...

that's like the the unknown unknowns here the known unknowns like we all know that we struggle to understand this but then what but but then that's the real jumping off when it when it's not just us adapting into a new regime um of learning and doing but when there's um

composition and construction within that regime in our last um sections here um dean or ali another question or um what what are you looking to bridge or gap into the dot too dean okay ali please


SPEAKER_02:
Well, yeah, I actually, I've written down a number of questions, but they may be quite specific.

And I think they're perhaps best suited for the .2 discussion.

But I wanted to thank Toby for, I mean, I literally had goosebumps the entire time.

So it was really fascinating and quite enjoyable.

And I learned a lot.

And I hope to, I also have some additional questions in my mind.

I hope to get to some of them in the second discussion.

So yes, thank you again.

It was really, really great.


SPEAKER_01:
Thanks.

Dean, with the penultimate thoughts, what do you see us heading into?


SPEAKER_00:
Yeah, well, if it's OK, I'd like just to read a really brief piece of the paper because I don't want to launch on Toby in the dot too without giving him a chance to think about this a bit.

Under 7.4, you've got fundamental theory and you say future work connected to this thesis need not only be in applications

A number of purely theoretical questions raised themselves too.

And I love 741.

This one paragraph, it's not, it's for me, I call it a really have to slow down and enjoy the moment.

Today, Toby, I don't know if you're a distance runner, an endurance athlete of some kind, but your stamina has been phenomenal.

But this one paragraph to me would be like a refreshment station where they offer you a milkshake

and a piece of battered fish.

Like it's yummy, but you need to wait.

You have to pause and kind of go, I don't know if I want to do that.

But it really ties in nicely with the syntax stuff that Danny was talking about.

And I have a question at the end of it.

So I just want to read it though.

The mathematics of belief.

So you basically said belief is theoretical.

That's fantastic.

Is in large part about replacing definite points with fuzzier distributions over them.

Independent type theory, we've replaced points with terms.

Non-dependent terms are exactly points, so a type of theory with belief should somehow encompass fuzzy terms.

Just as we can replace points with distributions, we can replace dependent points with dependent distributions.

However, the standard replacement, moving from a category of functions to a category of stochastic channels, obscures some of the universal categorical structure.

and underpins the rules of type theory, this standard replacement also misses something else.

While it does allow for fuzzy terms, it omits a model of fuzzy types.

We might well want to express beliefs about things whose identity we are not quite sure."

And then you say in the next sentence, there seems to be a couple of related resolutions to this puzzle.

My question for you is this, and it's not for today, it's maybe for next time.

It seems to me we have to grapple with this idea of making fuzzy clear and making fuzzy precise.

And you started speaking to that.

And my wonder coming now with a much stronger active inference set of priors is there has to be something more to this than just a gradient descent.

And I think you started to speak to that in this section.

And so I'm kind of curious, do you think that this is a feature?

The fact that we can do this, we can do fuzzy clear and fuzzy precise and not necessarily see that as a contradiction, but actually the way category theory kind of gives us permission to examine that.

So again, it doesn't have to be answered today.

And maybe I'm misinterpreting what you were trying to say there, so I'm open to being redirected.

But I just think that this opens up a world of possibilities.

And when I first read it, I don't know what Ali's goosebumps looked like, but I was just like, oh, man, I really want to ask you about this.


SPEAKER_03:
Yeah.

I mean, yeah, I, yeah.

So the thing about fuzzy type, yeah.

So I do, I got to start by saying, I agree that the kind of, that what some of this is seeking is something like thinking clearly about thinking fuzzily in some way is kind of weird.

Um, it's like,

having some certainty about uncertainty.

But it's definitely the case that still now I think a notion of fuzzy type theory is not well developed, though I am aware of various people having thought about this and people thinking about it at the moment.

And of course, I've got my own ideas about it.

it seems natural right like we often you know think we know what i think like we can recognize a thing but like um maybe you're not quite sure and so like you know you're not sure if it's this or that or you see somebody coming down the street towards you and you kind of recognize them as somebody you know or you used to know and then like as they approach that their identity becomes a bit clearer but you're not you know you weren't sure for a while um and i think you know

there's nothing to say that, you know, we shouldn't be able to, you know, in some sense, like types are a kind of element of some bigger space.

And so we should be able to play all this maths to it.

And it's kind of really about figuring out what the rules are that makes the kind of language of type theory kind of align nicely with the language of probability.

And it's a research effort, but I'm happy to talk about it more next time.

I'm also happy to talk in any detail about any of the actual specifics of the stuff in the material in the thesis or whatever else in category theory you might be interested in.

I can't promise to be expert in everything, of course, but I'm happy to try my best.

Particularly, Ali, it sounded like your questions

Well, maybe of a more technical nature, maybe not.

I don't know if I got the right sense of what you're saying, but if they are, I'm happy to talk about the details of that.

Thank you, Simon.

And also to review any of the stuff, to try to say, because you're right that there's a lot of detail in the thesis, because you make a claim, and you're supposed to substantiate it, and that means you have to give a proof, and sometimes the proof is quite complicated.

But structurally, I want this to be simple or at least to have a simple framework.

And so I would like to be able to clarify some of that if there's time for that or if it comes to it.


SPEAKER_01:
yeah that sounds amazing in dot two we will uh return perhaps any questions that people submit as a comment on the video or as a message in the category theory channel on our discord we'll curate those questions we'll

rewatch and digest.

And then we can begin with Ali asking some, taking us on a little bit of a technical journey.

And Toby, thanks again for the incredible work.

It's defined our 2023 in many ways.

So it's been a joy and we look forward to next week.


SPEAKER_03:
Thanks for plowing through.

I think

yeah there's also the stuff i i think we talked about before that that we haven't really touched on this time and obviously i didn't really touch on much in the pieces about like how do you actually fit in like action into this framework and like how do you like start to talk about this like multi-agent stuff we can you know if there's time we can talk about all of that two of the pieces just to share that that gave us some of the most laughs were um first


SPEAKER_01:
We didn't get action.

And we're like... It's... I mean... Just... The... It wasn't an anti-climax.

It was a climax of its own.

and uh and then also we had had so many discussions over the months of time and the treatment of time backwards and forwards ringing the bell unringing the bell um all of these different concepts and then in your limitations you said we we really have to work on getting a dynamical treatment oh yeah but i actually think that

depending on like what you care about it may not be too hard so that's fine but even that you would say it that way just having dealt with time oh yeah yeah and then to be like well i mean it's like i thought that's what dynamical modeling was involving time no no no so that that you're right you're totally right that so all i meant at that point was


SPEAKER_03:
so the the kind of like statistical framework that i've been working with until then it just seems you have like a prior and like a way of make generating predictions but like the pretty there's no like nothing to say that the prior has any like

data about how stuff actually evolves in time or the predictions have any data about how like the sense data evolves in time it's just like I believe that there's this on the screen and that makes there be this like stuff coming to my eye and that's it it's just like a snapshot and so like when you want to include time evolution in those beliefs it things become a bit more complicated


SPEAKER_01:
Awesome.

Well, thank you again, Toby.

We'll see you in a week and a day.

It's been a pleasure.

Thank you for having me.

Thank you so much.