SPEAKER_04:
all right hello and welcome everyone it's november 21st 2023 we're here in actin live stream number 56.2 discussing a quartet of papers with alex arurbia this is the third discussion we've had we had a dot zero giving some background and context right hello everyone it's november 21st 2022. alexander you're in active live stream

empirical demonstration of the feedback delay of live streaming so let's just jump in perhaps blue if you have any initial kind of remarks or questions then to Alex and also if anyone's watching live they can of course write a question and I'll check it out so go for it blue and we'll just jump in


SPEAKER_02:
So for me today, I think I'm really excited to get into the cognitive model.

So like the last paper was my favorite and it was, I think maybe like the most zoomed out.

So I'm really kind of looking forward to getting into that and then maybe exploring what that would look like in the non-human system.

So that's, I mean, I kind of always want to go there, but I'm still, I still want to go there.


SPEAKER_04:
What figure should we jump to or what part of the paper should we jump to, Alex?


SPEAKER_01:
I mean, whichever one caught, I think, yours and Blue's interest.

I guess we could go to the architecture one.

Oh, I do want to, if you don't mind, a tiny shameless plug that I just want to take the moment right now.

I'm going to post this link in the chat because it relates to our conversation we had in point one.

So this is a paper that just came out the end of last week.

um i just want to add that as contextualization especially blue you might find it interesting because uh this was work i worked on i think i even alluded to it over like the last seven months um this is why i was talking about inactive and embodied cognition uh and uh there's a lot more so now now it's out there i don't have to pretend like oh it's a secret project

That was it.

So that's my only shameless plug.

Let's go back.

I should start with this.


SPEAKER_04:
So the the the as not to steal the thunders of 56.1 were this paper that came out in the time between.


SPEAKER_01:
Yeah, it literally came out last end of last week.

Yeah.


SPEAKER_04:
Wow.

So, I mean, maybe just while we're here, like, could you just review it?


SPEAKER_01:
I've already had some you already have so many papers, but it might be worth it.


SPEAKER_02:
Could you just give us the elevator pitch about this paper and maybe your favorite figure?

We were really excited for your comments last week.


SPEAKER_01:
Scroll up, Daniel.

It's actually early.

There's cool stuff.

It's a very long paper.

Yeah, that picture.

It also has an appendix or supplement.

It was a longer original paper, too.

Just that way, again, I don't steal a thunder of this particular podcast because our focus was different.

Now, the general idea is my my thesis or Carl and my thesis is about moral computation, which is a phrase that Jeffrey Hinton.

uh introduced uh very briefly like in about like two sentences or a small paragraph in his paper in december uh and i have written at length about it in a couple of my own papers end of december of last year in january and february um so this is sort of like uh the big uh deep dive into what does it mean to make a computer that is not immortal which is what we have in computer science today

The computer is inextricably bound or rather the software is inextricably bound to the hardware.

Sorry, not bound to the hardware.

I'm just making a mistake there.

So, for example, we can copy our software machine intelligence program across any amount of computers and it doesn't really matter.

And it's also extremely energy inefficient.

and then the opposite side of that is mortal computation which is essentially drawing inspiration from life itself uh for example uh when any one of us dies a human dies your computations your memories your quirks the things that define who you are

are essentially gone right because it's unique to you and that is because you're an embodied inactive agent um and so what's kind of nice about this diagram is it's it's a really colorful pretty diagram but it's in it sort of synthesizes two out of the three perspectives in this paper so uh carl and i investigated biophysics

uh which is sort of like the intersection of physics physiology biology chemistry and the ideas that have echoed over i mean essentially the last century and that's the top half the bottom half is a classical and very interesting domain called cybernetics which is like the intersection of computer science control theory also physics and a bunch of other domains and information theory

and it also has similar ideas and everything centers around this idea of homeostasis and all the millions of uh variations in higher order uh you know uh concepts that build on that and the ideas that uh our intelligence and uh essentially is driven by our our desire to persist and to survive in an environment

And so this actually takes my comments from the last point one podcast with you guys to its natural conclusion, which is I don't just believe you need a body, you need an environment, you need essentially a drive to persist and to fight thermodynamic dissolution or dissipation into the environment or disintegration is a better word.

um so we are essentially applying the biological second law of thermodynamics which is why it's also about free energy uh and so then uh we and then there's another person but it's also that it's a later diagram cognitive science and uh carl and i uh propose

5e cognitive theory which is just taking the classical 4e theory um i don't remember if i said this to you last time but embedded uh extended uh inactive and uh you know the ends uh yeah embedded oh embodied

The traditional four E's, we added something called elementary cognition, which I did say to you guys, basal cognition last time.

So this kind of like ties these three areas together, as well as the philosophy of life and death and existentialism and kind of combines them together into a unified framework.

And then we dive into Markov blankets.

I think they're a beautiful and elegant formalism for tying these ideas together and getting us a step towards the mortal computation, mortal computer design.

And then we talk about the free energy principle underpinnings that essentially the mortal computer embodies.

And we review a couple of existing ideas

mortal computers which do exist so organoids or micro physiological intelligence is a beautiful example of this uh even uh we talk about fungal computers also michael levin's work on xenobots so we have like a nice little table and then there's an appendix with a little bit of expansion on that also we have to give credit to uh ashby uh who's a really well known and or uh

very important cybernetical scientist cyber cybernetic cybernetician um and his homeostat which is also an example of an in silico model computer so long story short uh we if we want one path to artificial general intelligence is not going to be the way we have it now

It's not through just bigger and bigger transformers, which are extremely energy efficient.

They're labeled in the domain of AI itself, red AI.

We want green AI.

We want edge computing.

We want neuro robots that are also able to do human-like actions and enact in human-like behavior.

Because we think, for example, the human model or even animal models, right, are a good template for how we can interact and engage in our environment.

Then the idea is that we need to transition to this idea of mortal computation.

and leave behind, my last point here, the tool-oriented view of artificial general intelligence.

Because the way we treat AGI today, and we say this towards the end of the paper, that while it's very important and very helpful for humanity to build artificial intelligence systems that are very, very narrow,

and very tool centric.

They are more to support something for a particular task.

If we want to build general intelligence, then Carl and I put forth the mortal computation thesis as one possible pathway to go into the future.

So this is sort of also a call for researchers across all these different domains to come together.

ranging from biophysics to biology to computer science and machine learning to computational neuroscience, cognitive science.

It's pretty much in cybernetics, of course.

all of them kind of converging to perhaps build a different pathway to what we call the mortal computer.

And so I think that wasn't quite a good elevator pitch.

That was a little bit longer, but I'm going to stop there because I think then you can just read the paper.

It's fun.


SPEAKER_04:
Well, it's a tall elevator.

There's a lot of floors in the bunker.

I think there's a perfect...

articulation there 56.2 let's focus on living functioning cognitive frameworks but it's really cool that you're going into the life and death elements that way so


SPEAKER_01:
I do think that the paper that Blue wants to talk about, there's a complement to it, because we do mention very briefly in this paper cognitive architectures like the common and also the common model of cognition blueprint that we also talked about in point one, which is the center basis for the paper that Blue was going to ask some questions about.

I think it's mentioned here briefly, and we also talked about as that being a potential

Maybe we don't say it this way.

I said it in conversation to someone, but an inductive bias, which you did write, you wrote basis.

I also talk about it as like the idea of cognitive architecture and modules of mind serve sort of like as a prior, and that is produced by evolution.

And we also talk in the paper to the moral computing paper, evolution is important.

Natural selection is an important ingredient.

And if we don't use that, then we have to design the results of evolution.

So I think the common model of cognition, which can help segue into the paper now, is a beautiful bias.

It is one of our best bets.

for how do we emulate the modules of mind and how things interact.

And this would get at the neural computation component of a mortal computer.

Obviously, it does not say anything about the body, about the niche, about other agents, but you can imagine it is a little block that would go into this framework, and that would be one step towards a mortal computer.


SPEAKER_02:
So can I just temporarily derail us?

I just have to ask a follow-up question I have to ask.


SPEAKER_01:
It's my fault for derailing at the beginning.


SPEAKER_02:
So just in terms, when you're talking about mortal computing, I mean, I just couldn't help but go to quantum computing, where the computation itself is so heavily dependent on the substrate and the modality of the hardware.

The hardware and the computation are really inextricably linked there.

And in the same way that I can write a paper, you can write a paper, all of these things will outlast us.

So some of our computations will survive beyond the point where we're biologically dead, right?

So in a quantum computer, similarly, all of those computations can then be taken and translated and put into Python and all of the things, right?

But I just wonder to what extent and like I know I kind of know where quantum computers and artificial intelligence like meet, you know, like everything has got to go into the cubo and then the answer comes out.

And so then we take the answer and put it back into Python and do regular AI things with it or in some language.

Right.

Not always Python, but sometimes.

Right.

so where do you think can a quantum computer or can we ever get quantum computation or what is the role of quantum computation how can that intermingle with artificial intelligence and then become a mortal computer or is that just like too far-fetched we're not going to think about that well so the paper doesn't go into that specifically however we touch on a little bit because uh


SPEAKER_01:
A little bit of the paper, and we cited plenty, Carl's work with Chris Fields, which I know you guys have been doing a series with him on quantum computing and quantum information theory.

He had a paper, Neuromorphic Computing Induces the Free Energy Principle, or some version of that title.

I read that many times as well.

And in there, I think, is the way that quantum computing or quantum information theory would interact.

with the mortal computer and so I don't see I see it as another perspective there could have been a fourth perspective in this already long paper and I did originally have some ambition to write something about that and we distilled it to just the concept that Chris Fields introduces which was the interface so I think the quantum information theoretic interpretation of the brain

and the body especially like as presented in that paper and related work could be a better way to deal with the markov blanket formalism that uh carl and i uh constructed in this paper this paper uh which is largely grounded by also my educational background too because i only have uh you know some moderate knowledge in you know

quantum mechanics and it was a while since I studied that.

But in there we are treating the paper is like a classical interpretation or you could say almost the Newtonian interpretation of the free energy principle.

And in Carl and I discuss as many times as we were working on this paper that that has a limitation.

It's not necessarily that you can't build a more I think this paper

It gives you all the foundation you need to literally build a mortal computer or get started.

It's like a theoretical, mathematical conceptualization.

However, there are some weird things about the thermodynamic energy exchange between the internal states of your...

agent, your entity in the environment.

And originally I had a different diagram of the Markov blanket so that there is later in the paper, you'll see it.

And I really liked that diagram because it really made, yeah, you probably saw it.

It was there towards the end.

It looked like a spider almost.

Yeah, that.

so this originally had a different version where i had these uh extra states uh because i like to take old concepts and extend them myself and i had these thermodynamic states in there and i had them tried and i had probabilistic arcs that wired them all these arcs are designed carefully to make sure that it adheres to the markov blanket principles of like you know the dependency relationships between children and parents and the children of children

or the children of parents, and how they relate to Go.

So I had embedded

extra states and carl said that i should remove those because it's uh it violates the classical interpretation of the free energy principle and long story short is that you have this energy exchange in the diagram and you can represent that is dissipation but it's not a state that the agent would have like access to in the markov blanket so now back to the chris fields interpretation

If you go to the interface, I think he calls it a quantum interface.

He had a name for it.

It has this really fancy symbol in the paper.

If you use that, you get access.

It's not like you have access to manipulate it, but you can sort of perceive it from the perspective of the agent.

You see the sensory and the action states or the partitions of that field.

And I'm probably butchering his language, Chris's language.

And then you also have the thermodynamic exchange portion or partition of that field.

And it's like the non-manipulatable and manipulable portions of it.

And so I think that interpretation could be a more powerful way

like you said, Blue, earlier, that quantum information theory and quantum, sorry, quantum information theoretic and quantum computing interpretations lend themselves to that natural entanglement that this paper takes from.

So, again, we surveyed work all the way back to Descartes and Immanuel Kant, but, you know, and tying all their ideas together, because, by the way, even though we're

putting forth the phrase mortal computation, the mortal computation thesis, and trying to essentially establish that as our foundation for

all of science to build on, it's kind of been echoed.

Brilliant minds, thinkers, theoreticians, engineers have existed forever.

So it's kind of like a synthesis and unification of already wonderful ideas across vast parts of all the domains.

But I think the quantum information theoretic way could be the next step, the fourth perspective to quantum computing.

and it could lend itself to maybe easier implementation, especially if you have access to a quantum computer.

Obviously, this is the joke we had last time when we talked about evolution and why I specifically might not directly work in that, although I have some work in genetic algorithms and neuroevolutionary with Travis Dazzle, who was on here for the ant colony optimization work that was presented.

it's compute right i don't have access to the quantum computers of our time or maybe the simulator and of course the knowledge to perhaps use that effectively however i think that someone who does could perhaps take the principles that are put forth here take the chris fields

interface interpretation, and he goes into a lot more detail.

He had something called a TDNN or something.

It was like the quantum neural network, and they were trying to come up with the morphology.

But the principles there are echoed in some sense here, too.

And we cite that word, obviously.

But Carl's on there, too.

But the the the principles of morphology, which are like essentially and we originally had another word in the title called morphic, because the idea is that intelligence should ultimately you can't divorce it from any form of instantiation.

You've got to choose something.

You're going to be brittle, but you're going to be thermodynamically efficient.

And I think if you could interpret it from that perspective, the quantum information theoretic, that might lend itself to a more powerful implementation.

The last comment I'll make, and I'm already long-winded on this, so the final point is we do also briefly mention in the conclusion of this paper, and we haven't even talked about the papers that we wanted to about today, but in the conclusion,

I also mentioned quantum computing, but in a weird way, so I hope it doesn't feel too contradictory to that I just said that if you take the quantum information theoretic interpretation of mortal computing or build your own interpretation, because we don't

really do it much for you here, except mention the interface.

While that could be a powerful and perhaps the best way, who knows, to implement it, we also mentioned quantum computation as sort of like, okay, others have been looking at this in AI,

And for example, saying like we can do if we have a properly developed quantum computer, we can do big brute force search.

Right.

We can do simulated kneeling faster than our minds ever could have conceived with classical computing.

And that's kind of just been in what's we can do machine learning better.

And we we sort of argue a little tiny bit against it, not against the.

interpretation, but rather the fact that quantum computing plus machine learning is just another way to do what we currently do, which is narrow AI brute force search better and faster.

And so that's essentially it keeps alive immortal computation, right?

Because what are we going to probably do?

I'm not pretending to be a seer.

I'm not pretending to predict the future.

There's no way I can know of all people.

But

The way we're going about it is that, oh, we're going to try to put chat GPT or some transformer-like model in a quantum computer.

And yeah, it's going to work a lot faster.

It might be more efficient.

But at the end of the day, we're going to be programming that quantum computer at a separation level, right?

We're going to try to deal with it like we do in a normal operating system.

Maybe we all have to learn a little quantum mechanics to do it, and we write our code, and we write our software, and then we just hope that the quantum computer can execute it really fast.

That's not the premise that I would want a quantum computer to be used.

That's still immortal computation, just done in an accelerated, faster way.

So we do warn, or rather even just more like slightly comment,

that while quantum computing will be important, and there is promise there to even speed up the computations we do today, it's not necessarily, its current use or the way we sort of project to use it is not the right path to AGI either.

Or biomimetic intelligence, which is really what the paper's trying to say.

If we want to build biomimetic AGI, maybe there's other types of AGI,

and i don't mean like animal because animals are definitely a part of this paper uh organisms anything that maintains homeostasis to some level that's what this paper says is the the pathway to that style of agi there might be something else again i don't want to comment on whether or not uh large language models and transformers and these new architectures

There might be something alien that I can't foresee, and maybe quantum computing will make that more energy efficient in some way or faster.

It's still going to carry forward, though, the premise of tool-based AI and AI in the way that we do narrow AI.

I don't think it's going to lend itself to...

the path that we would really want general intelligence and general intelligence really is tied uh at least if we use organisms as our exemplars tied to the fact that we we don't have forever right uh that we we know to some degree whether we're conscious or unconsciously aware of the fact that i am at odds with my environment

I'm going to behave in this way in service of that.

And of course, evolution encodes some of that knowledge going into it.

So I just want to comment that I think that it depends on how you use the quantum perspective.

Like if you use it from the Chris Fields quantum information, theoretic interpretation of the Markov blanket, that might be a really excellent way for someone to even follow up on this.

And add the fourth perspective that Carl and I kind of just dance around a little bit or an implementation.

I think there could be some really fascinating things here.

But if you're just using quantum computing to accelerate your normal run of current day machine learning, the current approaches that we have, then you're just still carrying forward the banner of immortal computation.

Again, too, I want to make one last comment just because we talked about it.

This paper says we need mortal computation.

And it was weird.

There isn't much more than Jeff's one mention of it in his 2022 Ford Ford learning paper.

Then my paper had a little bit longer section, the predictive Ford Ford algorithm.

And then I had the spiking version of the Ford Ford, the pioneer, that idea.

And we had like an introduction, like about a page about mortal computation.

And then there's this one with Carl, which is, you know,

really really long uh doozy of a paper um so aside from that I've only seen Mortal Computation sort of discussed oh I see a little bit of Mortal Kombat appearing um I see discussions like brief mentions of Mortal Computation but there was something that Jeff mentioned somewhere along the line or maybe it was an interpretation of it I don't also think Mortal Computation

to completely replace immortal computation.

I think both have a place in society.

We just need to understand that they both do different things and they both have different purposes.

If we want, you know, intelligent agents and narrow robots,

i'm on the camp you need mortal computation to do it right but if we want that type of general behavior but immortal computation is not going to go away it's just more like we understand it has a very high thermodynamic cost because we have to deal with the von neumann bottleneck the memory bottleneck we're not using in memory processing

Maybe quantum computing will speed that up, too.

And then immortal computation can live side by side, and we'll have those as tools.

So I also want to make that clear for anyone that ever watches this recording later, that the mortal computation thesis isn't to say it's the only way.

to do computation it's just we should shake up the roots of computer science at its foundation and say maybe there's another way to do it and we should have both live side by side and hey this one might lend itself to agi um which by the way some people might disagree with that as well i don't again i we do offer it very humbly in the paper as one possible pathway not the

Because, again, I could be completely wrong.

There could be a better way to do this.

But yeah.


SPEAKER_02:
So, well, that was a really good answer, and you really articulated what I was trying to ask about.

And I think it's actually really easy to get access to a quantum computer, but it's not.

It's really easy to get access to the interface.

to a quantum computer.

And I think that what you, what you keyed in on is like, you need the morphology, you need the structure.

Like, so in order to play with a quantum computer and program the quantum computer to do mortal computation, you actually have to play with the substrate itself and not just have access to the computer through some interface network, right?

Yep.

Bingo.


SPEAKER_00:
Bingo.


SPEAKER_04:
to kind of bring us towards the non-human cognitive modeling slash fourth paper.

Something coming up in that was all the different ways that we talk about interface and also the different ways we represent it.

Like this is really creative and I've never seen the blanket represented this way with a zone and which connects nicely to the blanket index.

But whether we're talking about the kind of strict

analytical base graph markov blanket or the quantum interface or just an engineering interface input output or flow diagram systems dynamics or the kind of perhaps most general or accounting system of them all like applied category theory we're describing these different facets of the interface

So that's one place to begin when modeling a non-human or a human cognitive architecture is its interfaces.

It's like if those aren't accounted for, we're either speculating information that we're measuring or observing or interacting with this cognitive thing.

We're either speculating about what we could do or about what we could measure, or we're missing things that we actually can intervene with and measure.

So maybe how do we go about...

before even wondering about which formalism it's gonna be described as, how do we think about the interface of a cognitive system?


SPEAKER_01:
Well, you just brought up a really good point.

I just want to point out that you said if we don't design the interface between, let's say, the internal states of the agent, which just to connect it to the cognitive modeling paper, you could think of the common model of cognition as the design of the internal states, right?

It's the brain, right?

And let's just keep it like the organization itself.

all principles of the brain.

Because again, I think of CMC, common model of cognition, as a blueprint.

And, you know, cog engine, which is what that paper is about, is a physical, well, it is a computational instantiation of some pieces of CMC.

And even that is still only a part of the puzzle.

So, but you can think of that, that's going to be what's inside the Markov blanket, all right?

And then, of course, inside of it could be more Markov blankets, because we also talk about

markup blankets of markup blankets of markup blankets and there's a recursive assembly kind of but uh you brought up daniel if you don't design

It could also be an engineered, you know, permeable boundary with pumps and things that, you know, for example, remove toxins from the internals of the agent and brings in nutrients and energy, which we do talk about as well in the in the mortal computation paper.

Regardless of the formalism, you're all if you don't account for it and you don't.

So while cog engine does not account for it, it's still one of those like, well, we're going to just say we're looking at some very, very specific internal states and we're going to probe it in a very specific way.

Although we kind of have an agent because we do use the Jim mini grid.

So there is a body, but it's like.

a really really really simplified body uh you're missing out on a lot of intelligence and cognition that the boundary itself will give you so even in cells right so this is to take what you said daniel and you know jack uh boost it even higher the boost the signal uh is that i also believe a lot of the intelligent computations that we do

are offloaded, right?

This is the embodiment thesis of cognitive science.

Even the permeable cell boundary, right, of just single-celled organisms or multicellular organisms, it does a lot of beautiful things that the internal states are not doing like

consciously or directly with effort.

May I should be careful of consciousness at different levels.

But that boundary, the Markov blanket offloads some of that compute that the brain or the internal states need to worry about.

And they can sort of rely on what the boundary does.

Now, of course, there's more to that story that even the Markov blanket

doesn't necessarily need to address it but there's the fact that there's also autopesis so the idea is that the system reproduces it's self-reproducing that's where why there's a lot more it's a paper that very much is like an iceberg you can read the beginning and be like that's a beautiful phrase and then what's underneath it is this extremely deep and i don't even think i carl and i have properly even captured all the facets that you could add to this there's more like we just talked about the

quantum interpretations as well.

So assuming that we have everything taken care of, that things self heal, self repair, the boundary itself is in constant reconstruction, you have this nice power or nice advantage that you not only account for how energy flows in and out of the system,

and things that you would normally not account for in our traditional agents that we design today.

But you would also have the ability to offload cognition.

There's even a domain, we mentioned it in the paper too, but you might have heard of morphological robotics.

And there's even classical ideas going back to even, I believe even Rodney Brooks mentioned aspects of this as well in some of his early work.

If you study

the way that we move our joints and our arms uh you know there's a lot of uh

cognition offloaded into that act and you can also get that in terms of robotics too and just saying by understanding the you know kinematics that drive an arm now the robotic brain if you will the neuro robot only needs to say i need to move my hand to this point and then it can sort of trust its digital nervous system or rather the actual constructs and the robotic hardware

to move the rest of the arm like it doesn't have to think consciously about moving the elbow just needs to move the point you know from computer graphics inverse kinematics right you only need to move the point of the hand to where you want to go and then the rest takes care of the motion and it looks you know it doesn't break the constraints of how like the bones are structured and the skeletal structure of the

armature of the character.

So I think there's even more to just model.

So we do talk about modeling, too, because some of us, or a lot of us, might not have access to the hardware as well, right?

I think it's in the

I think it had to be moved to the supplement of the paper because it was already very long.

Yeah, it is in the supplement, but we have this problem called the body niche problem.

And besides the fact it's a nice sounding philosophical problem, there's this issue that robotic hardware or even organoid, you know,

constructs or biological substrates or chimeric won't be available to everyone so if we want to democratize things we're going to probably need to model these digitally and so we have this concept called a digital morphology so maybe we can take whatever principles of physics and other aspects of thermodynamics maybe we can construct bodies that we can simulate for cheap so that way people can work on mortal computers

simulated right uh although the ultimate would be you just like blue brought up earlier about the best way to use a quantum computer would be to literally have access to the quantum computer and then design your internal states your software that would run it run it uh literally on chip right or on on quantum computer whatever the right word for that would be

But they're entangled.

So you're only paying the cost, the thermodynamic cost of reading and writing to the memory right on the chips or right on the actual platform itself, rather than having these separations, even including operating systems and the transfer of memory in a hierarchy.

And so having the actual hardware would be the best.

And I think that's where, you know, even the work kind of says this is where the future really lies.

But probably along the way, we could probably work with digital morphologies as well.

So long answer, but just to say that your point is great and we could boost it even further by offloading cognition to the body.

And I also think, as you said, what formalism would you choose?

And I don't think...

any one formalism is you know like superior per se they give you different things i think the marco blanket is nice because it connects to uh bayesian probability and then you can kind of at least characterize the relationships between states um but from an engineering point of view i don't think you like directly have to design the exact marco blanket because now you're dealing with a graphical model and what would you what do we usually do we usually choose discrete states and

world's continuous i've thought about this like i thought okay now that this paper has come out how do i build my own mortal computer right just to show how we could do this uh but you know i think michael levin has a great example uh with the xenobots like that's one way to do it although it's very biological artificial um but i think just designing boundaries

And sort of clearly explaining or accounting for the thermodynamic exchange and understanding, like, what are the resources that we have at hand, even in a very controlled environment, might be the way to design the Markov blanket.

Because then you get for free if you have, like, and I think we talked last time about, like, a quadruped neuro robot.

like spot or something and you know have it outside right if you already choose your body and you put it in an environment you've already now dealt with the boundary in the niche you just need to understand the properties of that which is where we can leverage the the wonderful knowledge across domains like physics and biology and chemistry understand the properties of that body right understand the properties of that niche and then all we have to work on is the internal state design

and how does that interact with maintaining persistence right for example battery level power level that's a homeostatic variable or a metabolic variable there you go now you can build your agent about keeping that variable uh in within a certain range right because homeostasis is about a set point so may have a target or actually the we changed the word to something more powerful hormy or he says

which is homeostasis over time, right?

Because set points might change like in flux to the environment.

So that's a kind of a cool concept as well.

There's like a word for everything I learned when writing this paper.

So many concepts already exist.

All we have to do is just stitch them together.

And this is one way to stitch them together into a nice little framework.

So did that make sense?


SPEAKER_04:
yeah i'll i'll make a note and then blue i'll be curious to see what you think about this i think with what you've just described you've almost given some of the most specific ways to think about what is offloadable we've talked about extended cognition and about having passive artifacts in the niche like paper and pen and then having active artifacts in the niche like autonomous agents or whether they're material or or just digitalized

So it's interesting that by putting certain computation on the boundary or on the interface, broadly conceived with both a material thermodynamic and a informational semantic component, then it's like, yeah, the nucleus doesn't decide about the cell morphology.

And so it's like, how many layers can you put in between

between so that the computation goes out to the interfaces everywhere's an interface from somewhere and that's where the work is really done and then there's just so many other great points but what do you think about this kind of conclusion to 2023 live streams after long arcs with thinking about embodied cognition and cognitive architectures


SPEAKER_02:
um so wow what is offloadable uh i have a lot to say about that um so like in terms of what the body does um and let me know if my internet cuts out and i'll shut my video off um but in terms of what the body does

Like it's like you think about things that are automatic, right?

Like the heartbeat and the breath and stuff that like we just ignore.

And like, I mean, if you really you could do biofeedback and slow your heart rate and like breathing, you can definitely control.

I mean, it's very obvious that you can control it.

But, like, I wonder about these things, like, what is offloaded to the body that we're ignoring, right?

Like, if you offload too much, you know, like, we have, like, gut reactions to things, like, you know, these, like, sensations, and there's, like, a lot of computation happening within our own morphological structure that maybe we're not conscious of.

Like, so a lot is unconscious, but then, like, are we overlooking stuff that we should then be paying attention to?

Like, I wonder, what is the price of offloading?


SPEAKER_01:
I think that's a great question.

I mean, I don't know.

To be fair, I can't say I know the exact sweet spot because that would also mean that I have the exact instantiation of the mortal computer that I wish to build, right?

You know, the answer is we need to study that.

That's the short answer.

The slightly longer answer.

How do I say this without letting myself ramble?

Well, so maybe there is a point where we cross where we had, let's say humans, animals, even any, any entity has failed to find the sweet spot.

Like you just said, blue, even we humans.

When we do something, we have a gut reaction and we might tend to listen to that gut reaction rather than doing some other type of processing like thinking critically or logically and counteracting it.

We also have emotions, which I think is very important, which we don't really quite have that in today's AI, but we do kind of have a little bit of some good work has been done in cognitive science and cognitive architectures.

I think that we might have already crossed the sweet spot because some of us listen more to our guts and our emotions than logical logic or reasoning or, you know, planning things out more carefully or listing pros and cons.

Some of us might not listen enough to our gut feelings and we listen too much.

So I think the diversity in even within society

any entity such as a human is vast and so maybe someone has the optimal sweet spot i don't know who does it varies but it doesn't matter so it's kind of interesting we it's it's an interesting question to quantify and worth looking at but at the same time in designing a mortal computer let's say i failed to design the one that has the right balance let's say i designed a computer that mortal computer that

leaned more heavily towards gut reactions than not.

Well, I would still be thrilled that we built such a computer because while it would be great to find and characterize these set points, or sorry, these boundaries and regions,

we would still have the premise that, look, life is built on these hierarchical or rather layers of complexity.

So homeostasis, sorry, homeohesis and homeostasis, which sit at sort of the bottom of what we talk about in the paper, and then underneath that are like

Got to be careful a little bit, but they're like metabolic pathways or what we or Carl and I call essential primitives or variables, which are kind of like the materials and the very base constructs that maybe we manipulate to survive with.

But above that are things like allostasis and complex processing.

And of course, we put at the top of our hierarchy.

auto pieces but technically the idea is that everything would be self-repairing and healing but if we put the growth and dynamic change aside for just a minute our allostasis can be argued and it has been argued to be all kinds of things it can be oh we have little neural circuits that try to predict

when homeostatic processes are going to need resources.

And so this is where you can see it in animals and insects and other types of creatures that, oh, I know that the seasons are going to change, like birds, they fly to another, and so they have these kind of instincts built in, or they have some sensors in circuit processing to say, I should probably go somewhere else where I'm not going to die for the winter.

And so then they flock away, right?

Or they fly away.

So there's already some higher level behavior built on there.

The reason I bring up that, just to tie it back to that balance point that you bring, Blue, is that we would have the opportunity to design those neural processes that could override, for example, your gut reaction or your

more primitive instincts.

And so this is what's kind of nice about the mortal computer is we would want that ability to do planning, to do higher level thinking.

And this is, again, what connects nicely to the cognitive architecture, right?

If we have a more developed, let's say, brain region area, right, we have different types of

memory, like procedural declarative memory, now we're able to start to think at a higher level that's not just purely driven by our instincts.

And so the 5E cognitive theory in the paper, elementary cognition, I don't think is the only thing you need.

That would be like, I only rely on my gut instincts.

I am primitive in the sense, primal.

I only want to live and I will do whatever it takes to live.

But for example, if you live in

a society of mortal computers which is one way you could think of humans i'm not gonna start calling my friends mortal computers but we live in a in a relationship we have a we are a complex system in ourselves well now we're not just only thinking about uh exactly like i i don't want to die right now right because if that's how we live then you know we go back to uh kill or be killed law of the jungle right we are just sort of fighting amongst each other so i think

while it's hard to answer what's the sweet spot or the balance point i would still think having a mortal computer that even has the ability to engender those primal gut instincts would be very powerful and then we could work on thinking well what are the right neural processes to counteract that right to add the critical logical thinking what constructs would have evolution evolved to allow us to counteract that um

Does that make sense?

Because I think it's almost like it's a good question to ask, but I don't think it's more like it would be profound if we had something that leaned a little too heavily on its gut instinct and we say, okay, but now we have these allostatic processes.

We're just missing more of that higher level behavior to counteract that because we humans are able to, for example, ignore even sometimes our primal needs, our desire, not maybe completely desire to persist because some of that's very deep, low level.

But like we even have the act of like heroism.

Right.

You know, like I'm going to go save someone that I care about and that will end your persistence.

You will thermodynamically disintegrate when, you know, I go into the fire.

Right.

So we have these higher level cognitive processes.

We're going to need to design those two or let some evolutionary process let those emerge.

So I would still we just don't have the low level either.

And we might not have the full picture of the higher level, but right now, a lot of artificial intelligence doesn't even have that that primal persistence.

Right.

So I think I would be thrilled to have that problem and say, oh, blue, it's a little too survival oriented.

Maybe we could try to introduce the right mechanisms to counterbalance that.

That's another thought.


SPEAKER_02:
so i just i'm rereading a book by um the theoretical physicist fred allen wolf and he talks about um like literally in terms of quantum entanglement he talks about the entanglement of thought and emotion which i think like thinking about quantum computing and quantum entanglement like the entanglement between thought and emotion is just like a really

interesting concept to me or just an interesting way to think about like who wins or like can you have one without the other or one always knows what the other one is doing or yeah


SPEAKER_01:
And the problem we have in, I agree, we have that entanglement, and it's fascinating, the problem in artificial systems or technological artifacts, which, by the way, another theme of this paper, and we sort of wrap it up, is it's like a path to, it's going to sound a little odd, artificial sentience, and then that also opens up the whole moral

issues and ethical dilemmas, but, um, but even get there, I would argue we're missing the half of your entanglement, right?

We're missing more the emotional side, which I think also stems from, you know, even the lower level processes that kind of give rise to the emotional states.

And cause you know, there's, there's a lot of physiology and a lot of physiological connections between like the chemicals and things in our body.

that also help drive those emotions.

And I think we need them.

And I think technological artifacts are missing at least.

I'm not going to say if we've tackled sufficiently the higher level cognitive behavior, because there's still the work being done in cognitive architectures and cognitive modeling.

Although I also think that because we're missing half, which is the emotional side of things and the biophysical drives and manipulations, we're missing that entanglement.

So the design of our intelligent system is sort of like detached.

We're still in many ways in AI, and we also mentioned this in that paper, you might have heard of brain in a vat.

which is the idea of what you can think of intuitively.

It's an old cognitive.

No one really ever said it.

It's more of like a criticism of old cognitive science, which is to say that neural processing, our mental representations, our decisions that we make and our plans that we make and our complex logical order processing are completely divorced of the body.

It's the extreme.

uh it's essentially mortal immortal computation which is kind of another fun thing we pointed out um but in the cognitive sciences and philosophy of mind realm and because we've been designing things from that perspective for so long uh we're missing that entanglement and i think there's

some of the roadblocks we will face in the future some of the things we can't necessarily build maybe the holy grails that still remain like you know higher order logical reasoning and uh complex planning that you know transformers and the big neural models can't really quite do today

despite claims that are being made from the public relations of different companies um i think that we're missing that other piece of the equation that could have helped inform and make those processes that we design better but we're also missing that relationship so that entanglement blue is inherently not there uh which is there in for example

human entities and animals or living beings.

We have that interplay, and then we have the ability to decide if we want to override it.

But technological artifacts don't have that.

There's nothing to override.

So at least I'm going to make that claim.

I'm sure that there is this world called effective computing, but I'm not 100% clear if whether or not that has

all the ingredients that I would say need to be in place to build that 50% of the entanglement of emotion to higher level cognition and reasoning and non-emotional reasoning.

so and we need that so i would love to have that and then we could then quantify that entanglement right and talk about the relationship or proportion of emotional processing or even low-level biological processing to higher level or cognitive processing and planning and decision making i don't know if blue heard that but i see her think green so


SPEAKER_04:
yeah wow i i brought up an image this is a figure 1.2 from the textbook with the high road and the low road so the low road how it's constructed and that's bayesian but we could consider other ways that things are actually built like jf cloutier working on the symbolic active inference so programs from the bottom up or there could be different heterogeneous elements we talked about quantum and neuromorphic so

as many material substrates as there are material substrates to be inclusive of what ecosystems actually consist of and then first principles thinking first principles approaches including the free energy principle

or unified through consideration with the free energy principle all of these terms that include complex systems phenomena self-organization autopoiesis like you mentioned and how

the current narrow or whatever it is computer science that we continue to ride inertia and acceleration on from the kind of von neumann architecture um and scaling in in materials with a lot of costs like that

is almost missing these two complements one of them is the top-down organizing principle though there are organizational principles within computer science of course it's a formal field but unified principle and then almost like you know in a very interesting relation that that i hope people can explore later is this other complementary relationship

between i mean to put it coarsely like the heart and the brain and the integration with the hands and about pragmatic value and the affective value and blue you ask like what if we're what if we're like least aware of what we offloaded it's like that's we're only aware of what we're not offloaded so every every if we just take a a mental survey of what we know that's the remainder

of what we don't know and that's a very different very integrated compressible perspective that then can unroll a lot of different ways that isn't just like we have to do what we're doing now but just more


SPEAKER_01:
Well, and just a quick point, there's also this beautiful concept called, and it's being embraced in cognitive science more recently because it was even the theme of COGS, I believe, last year, cognitive diversity.

And that's the beautiful part of embodiment, the embodiment thesis in cognitive science, which is it can give you an explanation

of all the different ways in which we might have something more offloaded than not into the different varying degrees.

And so even maybe the question sometimes isn't what's optimal, but rather, can we capture the wide array of different amounts of cognitive offloading?

Because if you change the body, you change the cognition.

And that's like the embodiment thesis in its natural form.

And this paper echoes that extreme kind of view a bit that if you change the body, you're going to change the thinking and fundamentally.

And we know this even internally within the same body if you are feeling sick, if you are feeling hungry, or even if you can fight these things with a top-down approach to some degree, but it will affect, for example, your focus.

If you're sick, it's harder sometimes to write a paper.

You have something called brain fog, right?

And so that's where the body is so intimately involved

uh in our biophysics and our physiology so intimately involved in our everyday processing that uh and different people are affected to different degrees i mean i'm sure there's someone out there's like no i'm uh maybe they had for example uh a really bad cold and they're like no i was able to get the same amount of work done as always right i mean and that would also show you that it's going to be vastly different even within the same type of entity and so um

that that's something cognitive diversity I think gets captured by this type of thinking and it could be really interesting you know from using the premise of a mortal computer to sort of construct systems that are like that and by the way the mortal computer rests on that nice diagram that you have there you know with the active inference and the free energy it sort of tries to hit most of those main points and sort of like

agglomerate them into, well, we even propose a definition, right?

I mean, is it a complete definition?

I'm sure there's extensions.

There's probably corollaries to add to the mortal computation thesis.

But I just wanted to throw that point in there because I think that that's where it's that that how much we offload will also change, even if it's like maybe not optimal.

But, you know, that would be more dictated by an evolutionary process.

But you have different entities and different organisms that offload to different degrees and depending on your body and what affordances it gives you, what what abilities it offers you to interact with affordances in the environment and tools and things like that.

If I had eight legs, I'm going to be able to do drastically different things than, you know, with my bipedal body right now.

And morphological robotics usually explores some of that.

What can different bodies beyond the humanoid style do?

uh provide and for example quadruped robots which they take you know another thing in nature like oh let's say animals like dogs and cats but they're wonderful for like search and rescue right whereas a bipedal system might struggle to get into certain spots but if we had a quad in there we've changed the body and hence we've changed the cognition and the mental neural processing


SPEAKER_04:
yeah a lot lot just even from the outside of robotics i hear about cognitive robotics so the adjective is saying well we're pulling back to consider cognitive architectures and then there's another layer which is like well how does it get there what's the developmental trajectory and then what is the ecology of similar or different minds and and bodies and then what's the evolutionary process you can

keep the um like you you you again in in um kind of distinction describe the immortal it's designed as if immortal but of course in reality the linux operating system or any given language model is mortal you just unplug it because its energy resources aren't accounted for so it's kept in this suspended bare life state where it's at the behest of something else and so then that like unsustainability

propagates through a system causing externalities so ensuring that the externalities can be understood where they are leads so we expect to scalable interpretable systems that don't just hide the semantic ambiguity and the material components they're so abstractly considered

And it's so unintegratable with emotive components that it feels like a dead end.


SPEAKER_02:
So I hate to keep talking about mortal computation, but we're doing it.


SPEAKER_01:
Well, it's your guy's podcast.

I'm happy to blab about anything.

I just want to make sure that...

If you wanted to talk about those papers... By the way, we did talk about those papers last time, too, and they're integrated, right?

Maybe we can relate some of them.

Like, I keep bringing the cog engine paper, not because it in and of itself is mortal, but I argue that it is a piece of that puzzle.

Like, if I were to go, yeah, that architecture there, that's not a mortal computer.

However, it is a cognitive architecture, and I think it plays a role in the design of systems, right?

For example, maybe blue, it helps...

It would help us, for example, to design higher-level processing to counteract some of the lower-level emotive decisions that an agent would want to make.

So I just want to make a mention.

I'm fine with talking about whatever.

I'm the one that shamelessly plugged it.

I just actually wanted to plug it, and then we could go from there.

But they're intertwined.

It's not like my thinking is, oh, when I work on CogEngine, I turn off the mortal computer.

It's like, no, they're all swirling around.

It's all part of the same thought.

So if you want to keep talking about it, be my guest.

I'm your guest.


SPEAKER_02:
So I just have a question about when we talk about scalability and interpretability, I wonder how much interpretability is due to the fact that we're missing that emotive

setup, right?

So if we have some kind of interplay between persistence, emotion, thought, if there's some kind of struggle, like who's winning the war when we make a decision, when we choose to act, are we going to lose interpretability when we start to design mortal computation?

Or is there a way that we can keep interpretability?

I mean, I guess we do all the programming.

So

Is it going to end up being more black box?

I mean, a human is way like, I don't know.

I just compute.

I don't know what's going on.

I mean, I can try to check in and like, where is this coming from?

Is this my logical brain or is this from my heart?

Or is it just like a motor kinesthetic memory or that's driving me to act?

in a certain way, like I can try to dissect it, but even it's hard to know my own like computational process.

So when we're looking at like designing an artificial system, are we gonna lose that interpretability in the design?

Is that like built in?


SPEAKER_01:
Well, fascinating point or fascinating premise

I think it depends, not to bust out the famous it depends answer, and any of my students listening will be like, well, there he goes under the shield of it depends.

But it really does, and I think it depends on what interpretability you're looking for.

And I'm also going to mix, and it is different to some degree, explainability.

And I'm going to bring in that word here because there's those that work in, like, interpretable AI versus explainable AI, and they can get pretty mad if you, like, say, oh, it's the same thing, and it's not quite.

So in designing, let's say, a mortal computer, let's even say, like, a con...

The beginnings, because by the way, we are encouraging everyone to contribute.

We have sort of like a low level or what we call a homeohedic or homeostatic mortal computer.

And then things that have other processes are allostatic and things that are at the top level, the complex computer would be autopedic.

And that would be like the ideal.

That would be like, oh, well, there we have a human, right?

We have an animal.

We have at least a sentient organ organ.

Um, yeah, if you're looking for Daniel, it's like after it's in section five, uh, under the definition.

But if you wanted to see that little, it's like, it's sort of a taxonomy.

Uh, and then we use it to evaluate modern day mortal computers.

No scroll.

It's not a picture.

No, no, no.

It's a, under the definition, it's, it's a bullet point.

Scroll down.

You were close.

It's weird.


SPEAKER_04:
All right.


SPEAKER_01:
Yeah.

Go down.

That's the definition.

And then you scroll down right there.

So there, yeah, we, you had it.

You had it right there.

Uh, scroll up a little more.

No, a little more.

Scroll a little more.

Homeostatic, allostatic, autopedic.

So we sort of give a little bit of a characterization of like mortal computers of varying complexity.

So I'm referring to this just in answering Blue's question.

If I designed the ideal MC, Mortal Computer, Autopedic, right?

So it has all the ingredients we want.

And you're saying, is it interpretable?

Do we lose some interpreting?

I would argue not completely.

The parts of interpretability you preserve, and I think it's even better in some ways than your run-of-the-mill transformers and large neural models that are in operation today.

is when, for example, ChatGPT or GPT-5 or Stable Diffusion does something really interesting, like, oh, it can do this downstream task that I never expected to do, like zero-shot learning, which arguably is very interesting and promising that these models can do some elements of this type of adaptation.

We can't answer why that happens.

The best answer we have is, well, it's because we keep throwing more and more parameters at these models, more neurons, more synapses that connect them.

And so if I toss more Legos at this, it'll just, through emergence, create complex behavior, and we get these nice little properties.

And it's interesting because that does relate to complex system, complex adaptive systems theory, like John Holland's work in the 90s and the Santa Fe Institute and other other people that have worked on dynamical systems and complexity theory and how you get complex structures that emerge from these very simple structures.

And self-organization was actually on Daniel's work.

Hierarchy was like a one piece of an organizing principle.

So that part is like the part where it might be hard to completely interpret.

Why does this behavior emerge?

Because it is this complex, multi-level interaction of parts.

and you could at least say it comes from like and we do talk about it too in the paper uh because we do talk about self-organization you can't without if you're gonna talk about any living system you have to go into self-organization uh upward causation and downward causation so upward causation is like

The little parts give rise to complex emergent parts and then their relationships to each other.

And then the top-down causation is you have these higher-level parts that have now laws and physical relationships and implicit relationships with each other that exert a modulatory effect on the lower-level parts.

And so that's why you have top-down, bottom-up arrows of causation and interaction and constraint.

Sort of give rise to a complex system.

And so you can point to those pieces and say, well, that's the reason why certain behaviors probably emerged.

But then you get into nonlinear systems and it's very, very hard to even mathematically analyze them, let alone come up with intuitive, qualitative pictures of what's going on.

But the part that you also get in designing a mortal computer and like the cog engine architecture that Daniel has here on the slide is you get interpretability in terms, at least the structure and some roles, especially if we're talking about like the internal states, like the reason I like the common model of cognition and there's other, you know,

theories and blueprints out there.

It's not to say it's the only one.

But the reason I really like it is it sort of cuts up or cleaves the mind up into these general blobs of responsibilities and has some relationships.

It doesn't commit you to any implementation as we talked about at the podcast point one.

But it sort of tells you like, oh, procedural memory, it's going to be doing this very specific thing, right?

It's going to learn how to memorize sequences of actions, kind of like a reactive, physiological, physical reactive components.

And, you know, the way I interpret it was

the transition dynamics model of active inference, or let me build a predictive coding little structure that tries to guess latent states.

But then you have like declarative memory and it stores the facts of the world, things that, you know, I bind the name of a person to their face.

And, you know, I'm storing these little bits of knowledge into my representations and declarative memory.

So you get the interpretability, at least at the level of, I know what these modules are doing.

I probably could investigate

and probe in even a computational fashion the contents of memory cognitive architectures in general so that's the part that i like they bring at least a level of interpretability because you have this organizational principles you have responsibilities for different modules and even classical cognitive architectures have things like production systems and

You can encode knowledge into them.

There's good work on if-then statements, and you can break up knowledge into at least bits and pieces of logic, and we can very easily inspect that.

While that might not be computational in the most efficient way, we could probably do mappings between the neural representations since they're essentially mimicking

what like act are and soar and very classic prominent cognitive architectures are trying to do to these production systems there's been good work even from Yashua's group uh he had a paper uh neural production systems which I kind of like that idea

about how do we emulate that piece of cognitive architectures with just neural networks.

And so we can take advantage of that mapping and we could probably get some decoding going on and interpret some pieces of our architecture

agent system mortal computer and also by the way the very design of the moral computer you actually would have a clear picture of like well these are the essential variables or the metabolic pathways here are the homeostatic processes these are the things I defined that define the life of this system

Or otherwise it will die, right?

And then the allostatic processes live above that.

And so that's what that, like, cool picture that I really like in the middle of the paper, the biophysics, shows you, like, the hierarchy of different types of processing that would happen from biology.

And then the cybernetics tells you what is it going to do from, like, an analysis point of view.

It's, you know, trying to, you know, find stable states.

It wants to be ultra stable.

to use Ashby's and the cyberneticist's old terms, right?

And that's, you know, I'm able to very quickly satisfy my constraints so I can keep living and not, you know, die and essentially preserve or have enough internal variety to counterbalance my external variety.

And that's the cybernetician's kind of framing of what's going on in society.

and organizing systems and so you get that interpretability in terms of the design you know the parts the mechanisms behind it but you will lose the piece of like why did that behavior specifically come about it's going to be a non-linear process so you will lose it and i don't think you can get all of that back here's the last point i said at the very beginning explainability

Now, this is different than interpretability, and it's going to be my digested version of explainability.

So, Blue, you were saying to me earlier, I might be able to inspect the contents of my mind and come up with a reasoning for why I did something.

And then you mentioned that, well, it could be wrong or, you know, I might not completely capture it.

And I agree because we do this in all the fields, right?

Like especially anything about the mind.

I try to think about the contents of why I did something or what was going on in my brain or break down my process and then try to turn that in a computational model that then explains like the actual entity.

And it might be wrong.

It might be biased.

However, there's something cool about doing that.

That's the explainable part.

you blue might not know the true reason, the real reason of the universe, or the biological reasoning, or the thermodynamic cognitive reasoning of why you did something specifically.

However, you can provide an explanation or a rationalization of why you did it.

And while it might not be perfect, and we shouldn't take the account as wholesale the exact truth, you are able to communicate

basis of your decision so you are able to use your construct your biology your neural processing to formulate and then of course we also have this thing called communication you use the other parts of your body to transmit those sound waves to me and daniel

across a tool zoom um and we hear what you're saying and you say oh i when i wanted to solve this problem i did x y and z and what we would find is then if we did x y and z maybe that's not exactly the true explanation why you did it but i would be able to solve the problem now and we teach right we pass on this knowledge and so the explainable part might arise

I think that might counterbalance the lack of interpretability.

So while we might not be able to say exactly 100%, I still argue we have more interpretability than monolith structures like transformers today, where we just say, eh, it emerged.

And that's cool, right?

I mean, there is probably analysis.

I don't want to completely dismiss Transformers.

There probably is interesting work on maybe identifying what parts of the network.

But from the design principles or the inductive bias that evolution gave us, I think a cognitive architecture gives you some interpretability in a structural way.

But then you're going to get a mortal computer that would probably be able to explain to you

Why did it do this?

Because why?

The 5e cognition theory that Carl and I have

doesn't it absorbs or expands for e-cognitive theory which includes embedded and the embedded cognition is really important because that's part of that like other diagram i had where i had the slices of a pie of cognition in a mortal computer and among there it's saying i have to interact with other well i had other neural robots but i'm talking to you blue and that means that i have to be able to communicate some approximation of why i did something

There is an explainable, you know, there's explainability and I communicate this reasoning to you.

You give me feedback and, you know, we kind of come up with a solution to the problem or a better understanding of something.

And I think that's where the mortal computer in its full glory.

Would give you.

Because it would be able to tell you why.

It would interact with you.

Because it also needs to.

Because you're part of its niche.

You affect its survival.

So it can't sort of like.

Oh okay.

I'm just going to ignore you.

Because actually it might be really important.

It might be important for it to achieve its goals.

Which could be to allow it to get more power.

If we go back to the primal connection.

There's a lot of jumping around going on here.

But you are an essential part.

We humans.

All of us are an essential part of what a true mortal computer would be.

This is what makes it artificially sentient, too, right?

It has to live in its niche, and the niche, you know, can get very complex.

It's not going to be a laboratory that I put it in a little white-walled room and, you know, oh, okay, I've emulated life.

No, ultimately...

You would want this to integrate with human society and to interact with us because there's things that you get with a group, with a collective, with social norms that you don't get living in pure isolation.

And so you're going to get that.

It's not interpretability, but it's explainability.

And I think that that communication and that part might counterbalance the fact that we're dealing with, as you rightly point out, Blue,

an extremely non-linear complex system that it's gonna be very hard to say exactly why did it do what it did based on inspection of its contents even if we designed it so the explainable part i think will counterbalance that to some degree wow sounds like psychotherapy psychotherapy for the mortal computer there you go yes we need it


SPEAKER_04:
There's so many pieces to add in.

I barely know where to go.

yeah it's a it's a lot you brought out i think the connection to complexity science is very good because that's where we can ask and have a laboratory for like well what's the account you can give of this double pendulum what's the account you can give of wolfram's rule 30. what's in and by that we can contextualize yeah how many experiments of what type would we expect to

before we could understand a fruit flies decision in a tea maze what about a human in this or that and then this tension but fundamental so we can quickly come to adapt to it that there's things we do and don't know about it's one of the quotes beginning a chapter in the 2022 textbook i think it's like a minsky quote we're aware of least what our brains do best

and so that whole like searching under the street light with the light of attention that every agent is only engaged in as a fundamental constraint that's one constraint is the attentional informational another constraint is the material physical niche which is always actual

and that's that's um connected to the environment totally fundamentally like there can't be a discussion of what ant colony foraging strategy works best even for one field location there's going to be different ant species with different total strategies and different nest mates with sub strategies as modeled by so

embarked on a wildly fundamental task that combines a lot of the discussions happening in active inference with the broader cognitive sciences broader complex systems and it's definitely interesting and relevant so i really appreciate that you share it this way i'm happy you guys uh


SPEAKER_01:
took to it so well.

And I certainly want that idea out there.

So now, now that there's a, what do you call it?

A proper treatment, an initial treatment of moral computations,

please spread the word.

You know, I want, I want to hear other people come back to me like, Oh yeah, I heard about mortal computer and I'd love to see you guys and everyone else try to take a whack at designing even the most primitive versions of it.

Cause I think this is like, I don't know if it's quite that, but it almost feels like, uh, like a little baby step.

Cause if this paper is, uh, is, uh,

intensive as it has been uh and informative and so fun working with carl on it um it is just a step in a big direction as you just said daniel and it's a wild wild place and it also goes at odds with a lot of like maybe this group here you know we're a lot more what do you say receptive

and excited by these prospects.

But it does go even to challenge a lot of what we hold dear and near and dear to ourselves, which is that we really do like our immortal computers.

And, you know, there's going to be trade-offs to that.

And the paper does talk about that.

It even starts by trying to address the reader by saying, the reader might ask...

you know themselves you know why do I really want this because it's also very brittle I'm gonna just be clear too but then again humans and animals and organisms are also brittle as well um but why do I want this right and you know and then we had and we motivate this with like uh three kind of stabs which is

thermodynamic, which is the most important.

By the way, the free energy principle in physicists in the room might say, well, wait a minute, free energy, that's thermodynamic.

This is not quite the same thing.

There's the mixture of information theory in here as well.

But, you know, the thermodynamic free energy is a really important piece to this puzzle.

And the way that computers are organized is sort of what this challenge is.

And, you know, it also, we have tools to attack this, like neuromorphic chips.

wonderful wonderful platform uh for uh you know a mortal computer uh and we do talk about it in the supplement it got moved to the supplement because again i was already a little bit too long um so i talk about uh neuromorphic architectures and the also neuromimetic algorithms which kind of connect to the papers too like predictive coding it isn't like front and center i don't we don't try to like throw it in your face uh even though it is a uh

one way of thinking, a consequence of free energy minimization.

And so we talk about these things, but

I think it also challenges and gets us to think about existentialism and philosophy of life and death because there was even citations to Heidegger and Soren and all kinds of wonderful thinkers too that have just thought about philosophy of mind and how our identities and our thought processes are just naturally influenced by the fact that we know that

you know things are going to possibly end um and wonderful thinkers and there's also been this concept of like and again and this is a little heideggerian but uh you know your your being there's this famous book being in time and you think about well you know at the end of time you you have to understand when you live you're projecting your being to there and then going backwards and so there's a quote that kind of starts the paper from

sarin kikegaard about uh you know we we look at life backwards but we must live it forwards and there's that interaction with knowing that this this rodeo is this play is not going to last forever um which is a motivator for why we do a lot of things including teaching and passing on

to the next generation.

And the other part was, again, cognitive science.

I think cognitive science got a little bit of a spotlight because it needed to.

I think the embodiment thesis, inactive cognition, and then Kirchhoff's and his collaborators' life-mind continuity thesis needed to sort of be foregrounded a little bit because I think that's another piece of this puzzle.

And it kind of ties everything together about how to think about minds and brains.

But it all challenges what things we're very used to.

We're very used to when we design, especially artificial intelligence.

Okay, I trust this hardware is good.

I'm going to try to build some software and I believe that I can design all my processes properly.

uh from you know from scratch without even accounting for maybe what you know evolution might have given us uh we are seeing some of that especially bayesian uh framings have some of that in there right the idea of a prior uh i think is important but a lot of modern day neural systems don't

100% I think foreground that and play how important these priors are to sort of like driving your behavior and so that's what's going to be interesting is that this is truly a weird place to be and it also really says you gotta have a body you gotta have an environment so you're not done if you say I have this wonderful algorithm that I think

emulate some piece of intelligence, that's wonderful, but that's not going to be the end of the story.

In fact, you're far from the end of the story.

You need to be integrating that into a brittle body where that process that you've designed is also going to be shaped now.

by the substrate right and its interactions its thermodynamic exchange with the environment the environment itself is going to change how it works and so you sort of get this malleable flexible kind of framing of ai as well that intelligence is you just no longer can divorce it from the mechanics of interaction with interacting with the world you cannot divorce it from the thermodynamic exchange that's how we're going to get energy efficient ai

I think that's like the other main message, but it's challenging, right?

And others will say, well, I have quantum computing and it is very promising.

It's not any dismissal of it.

I'm just going to do the same AI I've always done, but faster.

And do I really need to look at, you know, how life emerges?

Do I really need to look at how neurons really do things?

You know, it'll be interesting.

If nothing else, it might be a little bit of a race going forward.

Maybe it'll be

the mortal computing still you know on its pedestal being the dominant paradigm in mortal computing being rather niche for a while i mean it's kind of same thing with the free energy principle and active inference i like to think of the mortal computation as you know another con a big expansion of free energy and active injury because you know active inference is a corollary of the free energy principle

and at its mortal computer's heart is the free energy principle right it talks about the non-equilibrium steady state the mass and that's kind of like at the core and we cast there's the other part of the paper there's a lot of parts of the paper about inference learning and structure and you cannot ignore any of those pieces if you're going to build a proper and that's actually part of our definition there's an entanglement there

That's a whole other conversation, but it's like an expansion of the free energy principle.

It says, where does this go next?

And it's really like how free energy often is used in the literature.

to explain other phenomenon in like, for example, Carl and many others try to use that to do things in neuroscience and neurophysiology and computational psychiatry.

This is what would happen if you take the free energy principle and you merge it with hardware considerations and morphology and place it in the world of AI.

If our goal is for in silico artificial sentience, not sentience, artificial sentience in our artifacts, well, this is where it's natural consequence.

I like to think of it as an extension in placing a pathway if you come from that line of thinking.

All of you guys, the Active Inference Institute, it's like,

perfect candidates right because you're you're studying deeply the free energy principle um dying mortal computation is just like the next step right it's like okay well that's another piece to this puzzle it's where you go if you want to build technological artifacts with what we would consider sentience if that makes sense blue wanna add anything


SPEAKER_02:
sure um i mean i i have millions of questions but um nothing pressing but this one i think maybe goes back to um you talking about cognitive diversity and then daniel mentioning like shining the light of attention um and just as we're as we're thinking about um

like attention as as maybe like the foundation for cognitive diversity because like while we are all fundamentally have the same programming the same like voluntary and involuntary consciousness right i guess we'll say it like that like my heartbeat and kind of the my self-sustaining system um

we can kind of make that conscious like i've mentioned the breathing but also like just through like motor control like you can activate motor circuits like we all have different like some people can spread their toes out and some people cannot like if you've never tried to do that like it's hard and you have to like practice practice practice but then like through constantly paying attention to those like neural connections neuromuscular connections you you gain like a different perspective

um than others and so just um in terms of cognitive diversity for humans it's gonna look really different like within like intra-species and inter-species diversity um is gonna be crazy right like you know a tardigrade doesn't even have a toe to spread maybe they do i don't know um i don't think they have toes but but um

Just across the different species, maybe we, this is the time to kind of look a little closer at like procedural memory, long-term memory, like at what, like what is long-term memory, right?

Like if...

you know when you're looking at something like an insect that doesn't really have a brain definitely doesn't have like a hippocampus to store the long-term memory do you get um long-term memory does it go into the generative model like or where does it go like i mean you think about they just have like the working buffer memory or if you were to try to design one of these cognitive kernels for a non-human

um like maybe you don't have to go to a plant but like where would you start to kind of add or subtract things like long-term memory because we know that that's really different just even in the animal kingdom well i


SPEAKER_01:
First of all, I agreed with most of what you were saying at the beginning.

That just resonated with cognitive diversity.

Talking about how would I design or begin to think about something like a fruit fly as opposed to a human,

again, the mortal computation definition and, like, the general framing.

And let's just, again, for the audience members that might join in and say, wait, what are they talking about that's not in any of the four papers we're mentioning?

Let's just think of the mortal computation thesis as subsuming all of these, because I think of all those...

Just as a quick point to all of that work, I think, is in service of this, even though this was written far more recently.

And I know, Blue, you were going to ask at one time, what was the history of the ordering of these papers?

But obviously, they're not in a strict sequence.

so it's like mortal computation is like one way to do a synthesis of all these ideas um now to build like something like a fruit fly mortal computation just says you need at least at its heart a generative mod right everything's a generative model but the form of that generative model is not con you know it's not specified um because

there's the the principles like for example in that paper brings up the cybernetic ideas of like the good regulator theorem i'm sure you guys have encountered this too because you kind of are all especially in any discussion with those with free energy

They always borrow from cybernetics.

It's impossible.

So law of requisite variety and the good regulator theorem are kind of like the most well-known.

That paper talks about a lot of other ones that I don't think get enough attention.

So all the axioms of cybernetics are kind of in that paper.

But the good regulator theorem and the principle of model internal control, which is not as popular as good regulator, but...

you sort of need those at the formation of any of these entities and so as long as you're able to design the body of that fly and you are i'm assuming you're going to study the object in reality right so you're going to study the actual fruit fly and hopefully extract principles because again this is biomimetic so the title of the paper says we are mimicking or performing mimicry of biology

or the things that we perceive in our real world, the physiological organisms.

And so if you're able to study the fruit fly, I would imagine you're constructing a body that's very similar to it, tries to adhere to as many of its physics and physical principles that govern how it moves and interacts and its exchange with materials.

If you have all that part,

I think you're almost there, believe it or not.

That's the kind of the fun part of the mortal computer is designing that Markov blanket and implicitly explicitly, however you want to go about it and placing in a niche gets you really close.

Cause again, embodiment offloads a lot of that cognition because that fruit fly does a lot of what he does based on reactions.

And, uh, it's, uh,

interactions with its niche and that is where in like the 5e cognitive theory of the paper uh the bottom the most let's say you need this because you it influences everything else is called what carl and i did introduce is the it's a rewrapping of basal cognition you need elementary cognition

Which you could just, if you want to call it basal cognition, that's also fine.

We cite the heck out of that in Michael Evans' group and many other biologists.

So you would be implementing that level.

So you'd say, if I'm going to build the fruit fly, I'm not going to be building, you know, embodied.

Well, you're going to get embodied cognition from that, but you're not going to be building these complex processes.

You're going to focus on that slice, right?

And that's what's kind of nice about five ethers.

You can slice it up and say, I'm going to design at this level.

Obviously, the bottom level affects the upper level.

So you sort of do have to account for that.

And so you would be saying, well, what are the basal cognitive functions that define something like a fruit fly?

what does it do what would evolution have given it because if you're not going to simulate evolution which would give you those things if you know properly done and with enough compute uh you're going to design those inductive biases you're going to hopefully study the fruit fly and then its internal cognitive model will not be the common model of cognition because the common model of cognition is sort of like okay that was the product of the human evolutionary track

right and that's what evolution gave us is like our organizing principle of the brain um but other animals don't necessarily have that to the same degree and creatures as you get smaller and smaller and simple let's say different on the spectrum especially as you move towards things that are a little bit simpler like single-celled organisms they're going to have a lot less of that functionality but still under the hood is that generative model

It just might not be a generative models and like, oh, I have a neural circuit that's trying to predict the next state of the environment, like a fantasy or a dream sequence that I unroll out.

Like we humans can sort of like, oh, let me think about what's going to happen if I close my eyes and I knock over the computer.

We can use our internal physics simulation.

to figure out what it's going to do and say, nah, I'm not going to do that.

Whereas a flute fly might have some sense of physics, but it might not be like, oh, I'm rolling out over a long-term trajectory.

So I'm not going to be building, for example, a procedural memory or an episodic memory quite like what I do in the common model of cognition.

And I might only need very simple little neural circuits because, again, the number of neurons and, for example, like insects is really, really, really small.

And that's why we can study them.

too that's also why people study that or even like it's not necessarily the same as a fruit flights is a lot simpler but still fascinating is c elegans right has been studied a lot because we can map out every single bit of its neural circuits and that in of itself is rather complex so i would argue that the fruit fly cognitive model will be simpler will and it will be dictated by what we decide are the elementary cognitive functions

that make its mortal computer, it a mortal computer.

And we won't need these complex modules interacting in the way we do in, for example, a human model or let's say an animal model.

I think that's, but again, that's grounded in something like

You understand you're mimicking.

So you go with the route of biomimicry.

You should probably be studying the fruit fly or at least understand what we understand about it and dissect that and bring back what are its base functions.

And then how am I emulating that?

And then, you know, you build your little cognitive internal states right inside the Markov blanket that maintain, for example, what are the essential variables that the fruit fly needs to maintain?

It's not going to be the same biochemical processes that dictate a human, right?

Like, for example, when we have blood, we're looking at like pH level and temperature.

The fruit fly might be looking at a little bit different.

essential variables, right?

Certain chemical concentrations matter to it more.

You'd want to model that.

And I think that that, by the way, when you talk about the basal cognition, in designing it, my thought on this is that you are approaching it from what are those life-sustaining variables that characterize that.

Start from there.

And then you say, okay, well, does that explain...

some of the things that i observe you know let's say again we're modeling at this point but you know what the fruit fly does like for example flying around why does it fly around well maybe it's because it needs to you know reach this particular nutrient and so it knows if i go to this region i am more likely to achieve it that might be an allostatic process right and you'd say oh okay there's something that i need uh and this could also be like a bottom-up design

If you don't think that you need the inductive bias that's provided by the common model, you sort of build your little functions as needed, and now you build your little internal generative model, your good regulator, into the fruit fly based on the key functions it needs to satisfy so that it does not die.

right and ultimately the best way to probably do this is then you simulate evolution right and maybe you let some natural selection happen because if you don't want to design those processes then you'd want to simulate you know the origins of it and by the way mortal computation doesn't ignore evolution here it doesn't talk about designing it because you know that's a whole realm in of itself but

Even the life-mind continuity thesis from Kirchhoff's group, they talk about you need a selection history.

And I think the only way to get around the selection history is when you say, well, okay, if I'm not going to simulate the selection history and let these primitives emerge into the structures that make, for example, fruit fly work,

you need to figure out well what was those what was the product of our current non-selection history right what did evolution do to give the fruit fly as is so you got like two choices study the real thing and try to emulate some of those very basic principles like identifying its essential variables identifying allostatic processes that might service those essential variables and the homeostasis of them or the hormonohesis of them um or

talk about some very basic primitives and then say, I'm going to simulate a population of these.

And that might be more difficult because if you're dealing with the actual, like, let's say you have a little fruit fly robot, since we're talking about substrates, that might be not very cheap to do where it might be easier to do it in simulation and doing it with a digital morphology.

And that's another can of worms.

So I don't know if that kind of gives you something blue.


SPEAKER_02:
No, it definitely does.

And like, yeah, so sorry, my brain works faster than my tongue.

Sometimes insects definitely have brains, just nothing like our brains.

They just definitely don't have brains like ours, right?

Like, so nothing that we can map analogously over.

Although some of the neurotransmitters and things still work, but just in a different form.

functional way to my to my knowledge um also andrew barron is building like a tremendous model of the honeybee brain that is just so super cool i think if you don't know his work it's really really neat send me a link to that i'd love to see that that sounds awesome yeah it's way cool um has him running around in mazes and doing all kinds of learning like how to tell van gogh apart from a monet i mean they're they're really doing some pretty pretty complex uh stuff and and that's why like it um

you know, it always makes me wonder, like, where does this stuff go?

Like, where is the memory there?

And it just is such a fascinating process to me, how memories are created and stored and, like, how they map into the brain and

like sometimes i can pull something up right away and like sometimes it'll take me four days to remember someone's name like what was the name of and like i'll remember it i'll be just driving down the road it was whatever and like it's just like how many layers of circuitry did i have to like transgress to get from a to b you know um and like yeah how do different kinds of animals do that is always really fascinating to me


SPEAKER_01:
i think a piece of that too is evolution also has a memory right and i think that selection history is what goes into things like for example the fruit fly right so there's its predecessors you know you know maybe they did certain other behaviors that were not conducive to their survival i think there's that too that implicit kind of memory and then that gets encoded uh in the morphology right and this is where it goes back to where i just said if you want it or like your your

collaborator your friend that you mentioned about designing like the honeybees uh it's kind of the same principles you say well okay what did evolution give it let me design that you're just skipping the evolutionary phase i think there's some memory in the structure too so this is where the body now of course with your example about you retrieving it there's layers of intricacy there like

I'm not complaining about that.

But even like the fruit fly, why does it remember to do certain things or why does it seem to have certain patterns?

And that's also what the moral computation thesis does account for, or at least tries to, by saying that it is because that body changes and it's subject to a selection history because it's constantly in this eternal change of repair.

In maintenance, in the face of disintegration, because it's always the threat of disintegration, your identity will cease when you die.

And so because of that, things get encoded in that memory, and that's also this beautiful piece of the interplay of physics and cybernetics.

This is without ever getting into the probably wonderful quantum interpretations I'm sure Chris Fields could enlighten us all about.

But

you know the idea that information or variety gets encoded into these interact through its interactions gets encoded into the morphology the very organization and structural manifestation of that organization because organization is not structure it is the relationships of the parts and it can exist independent of the manifestation and the manifestation is like oh okay here's the body that embodies those principles that also encodes that is a memory

Because, for example, an organism that understands a particular chemical interaction might say, well, look, I need to filter out this toxin or I'm going to die.

And I need to pump in these nutrients.

That's a memory.

It's just not a retrievable memory.

It's just like an implicit memory.

But that's why, for example, it's able to conduct the actions that it does.

And this is why moral computation really tries to, and this is where I think it's very forward thinking or very far ahead of

of what we can probably even do easily, which is it really says you do need to understand the body.

The substrate is so important.

And understanding how that will then affect the internal states and how you do this processing, that has to be at the front and center of your story, of whatever you build.

And then the niche, you can't escape the niche.

By having a body, you're like, well, okay, but the body only existed because it was in response to the environment and it has evolved or it has adapted because of the perturbations the environment has subjected it to.

That's why I like the thesis so much.

We need to flip our thinking a bit.

Not, okay, we're going to design the brain and someday in the future we'll have good bodies for it.

I think that was valuable and it has produced some interesting things, but it can only get you so far.

Then you miss

at least 50% of the puzzle that could also inform that design where we talked earlier about like emotions.

And, you know, I don't, I wouldn't argue that the systems that we have today, despite the media claims, and you know, there's the stuff with open AI.

And I saw some comments about Oh, well, you know, Alton and others, they have some secret AGI program, but

I've heard conspiracies about that stuff all the time.

So I don't, I put too much credence to it.

I don't think that they've cracked the, the emotional nut, the biophysical nut.

I think it's more like we've had lots of people either argue, study very specific slices of it.

But those voices need to be echoed.

Right.

And so that's what I think the moral computation is an echo as well of the

At least like a century of thought.

And it's saying.

This is how we can approach.

Artificial general intelligence.

And then it can account for things.

Like the fruit fly.

Actually you said Andrew was his name.

On the work on like honeys.

That to me is an example of.

He's got a learning component.

And an inferential component.

And there is some organizing.

He has a body.

He has a niche.

That's very close to an in silico.

version of a mortal computer, right?

You know, the only other components that it might be more like an allostatic MC.

So and again, in the paper, we have a table and Carl did want that to stay.

I was going to move it to the appendix again length.

So we made a compressed table of different types of mortal computers and we kind of characterize them.

There's a few that are auto-pedic.

We actually do have very like organoids

really, really close to what you would want, right?

But they're all biophysical.

So there's not like, oh, I designed something on a neuromorphic chip with predictive coding, like what I would do.

This is, you know, oh, we're using stem cells to construct this microphysiological architectures.

I do think that has a place, a super important role going forward.

And I would only hope that there's some democratization of an exchange of ideas between this wonderful, really new world,

and machine intelligence to learn and study organoids, but also fungal and mold-based computing, really interesting place to be as well.

And to think about how does that biophysical organization give rise to, and those are examples of mortal computers,

Ashby's homeostat deserves a lot of love and attention because it's the oldest and really the most prominent example of what I would argue is a true in silico mortal computer, but it's homeostatic.

A little bit allostatic, depending on what you've done.

There's variations to it.

But like the xenobots, really interesting.

I think the xenobots are an example of something that they use frog cells for.

lake cells and pieces of frogs to actually instantiate these little tiny robots that can self-heal and repair and i think that's going to be the part where we have autopedic computers already in front of us like organoids and xenobots are some of the most interesting i think profound examples of how you get this computer and then for example andrew's work would have

you know maybe the missing component so his would be more allostatic so mid-level kind of Mortal computers and I'd have to read more about them but just from your explanation um but the structural selection the evolution of the morphology the self-replication part of the story which we also talk about as well

is more in like the xenobots.

And so I think it's interesting how do those two worlds interact and how do you get those properties of self-repair, self-replication, which by the way, if you add a mutation to self-replication, you get reproduction because now that creates a new system that's now subject to natural selection.

And now you've essentially done reproduction.

And now we have an account in your your your computer has all the pieces that, you know, complex organisms do to also ensure their persistence, which is we have offspring.

Right.

You know, that's another way we project ourselves into the future in an indirect way.

So it'd be kind of cool to take like the honeybee model.

And think about what are the ways in which we can have its morphology be damaged and conduct self-repair.

And that gets into the real nitty gritty.

And even it might be difficult to do.

Right.

And that's where I think the this is where the grand challenge.

Right.

It's got an open an open pathway.

I don't think like any one of us has an exact candidate, you know, for, okay, there's already exists.

Cause there'd be really no point in writing the paper.

Um, I do think the Xenobots and organoids can teach us a tremendous amount about structural selection, um,

morphogenesis uh and self-repair and then maybe may build like a you know a synthetic uh you know honeybee mortal computer that also is autopedic right it's able to constantly uh repair itself to some degree i mean that that would be very interesting so

The fact that you brought that up was kind of like, oh, that's probably another example of an in silico mortal computer versus a biophysical.

We have some good examples of biophysical.

Not as many in silico to my knowledge.

Even like robots today, they're not mortal.

There might be some interesting things I'm not aware of, but largely they have all the parts, they have the ingredients, I think, for mortal computers, but they're not completely there yet.

And so I think that making a robot inherently, whatever the robot system, it could be the honeybee, it could be a creature that we come up with, it could be humanoid, making it inherently driven by just this fundamental process of persistence is the starting point.

And then thinking about what are those essential variables.

And like we talked about the fruit fly, designing all of those principles from the ground up.

And then at one point you've got to say,

Is this supposed to be human-like?

Am I going to be able to evolve a population of these, or am I going to need to employ inductive biases like a common model of cognition?

And I like to think of cognitive architectures as a possible bias and say, well, okay, I'm going to design a brain based on these principles.

It could be the wrong bias, but you know what?

It's probably capturing a lot in, you know, cognitive architectures are fit to a lot of human data, so...

they do explain a lot of different effects so I I would say it's a pretty good bet um and you bring in those biases and now you design the internal states and now you have a a very complicated Mortal computer but you know the future will be a very interesting place and hopefully uh more interesting Mortal computers will emerge in the future


SPEAKER_04:
Thank you, Alex.

These are really great points.

In closing, Blue, first, as much as you'd like to add, and then Alex, any closing thoughts that you want to kind of leave it with?


SPEAKER_02:
I don't know that Andrew Barron is building a robot bee.

That would be super cool.

He's just modeling the real actual biological honeybee brain, which does some level of mortal computing.

I guess it is a mortal computer, right?

But it's in vivo, not in silico.

But Alex, thank you so much for entertaining all of my fun questions and for, you know, trancing us down this like super fun path toward mortal computing.

I'm super excited to read your new paper and appreciate your time on the stream.


SPEAKER_01:
Yeah, thank you.

Thank you, Blue, and thank you, Daniel, for inviting me.

This was a really thrilling discussion.

I really like your guys' podcast series, and I think it's great that you guys are pushing for the narrative of free energy and active inference and trying to educate the greater public on it.

So my students, as I already told you, are fans of your channel, so it was great.

my pleasure to be on here.

I hope you guys enjoy the paper.

And I guess as a one final comment, I guess it's now sort of our own private running joke.

Again, for those that tuned in hoping to like have a deep dive into I think you guys did a good job on point zero.

going through all four of those papers, to be fair, I think that captured their essence.

And then last time at the end of point one, I gave like a crash course on the NGC predictive coding.

So just to make a final comment to sort of like tie everything together to today's, I didn't actually expect I,

It's my fault for introducing the paper, but it may use a welcome derailment going down mortal computer.

But I think those four papers you could argue are like building blocks as well.

There are other pieces to the puzzle of mortal computation.

For example, my preference or my thoughts are predictive coding, which is a manifestation of free energy or variational free energy minimization.

that's going to be an important piece your neural circuitry should probably adhere to that because i think it's very friendly to a lot of hardware like neuromorphic chips so that's kind of like where all the predictive coding stuff just to think about my papers they're like oh okay that's how that relates it's probably going to be the allostatic processes if i were to guess uh and building circuits there and building little modules like we do in cog engine uh the cog engine paper

is we have talked about it even if it's not about it specifically the common model of cognition is a wonderful bias if you want to try to skip ahead rather than evolve from the ground up to human cognition um and if we want to build a mortal computer that has aspects of human behavior we should maybe appeal to that type of bias um there's a lot more in the world and i encourage you know viewers to go into the world of cognitive science and computational neuroscience and

dig into the eternal well that is of the knowledge there.

So I recommend that.

And that's how that paper relates.

The spiking predictive coding and the convolutional, which we didn't, we only like sort of like touched on them briefly.

I'll just comment that the convolutional predictive coding paper, which was like the second one that you guys talked about, is like an extension of the nature paper in NGC.

And it just says, how do we do vision processing?

I consider that as...

Another version of the same building block that would go into a mortal computer and the spiking predictive coding, I think, is really interesting.

It says, well, if I'm going to try to get as close as I can to biophysical, right, and get as close as I can to neuromorphics.

we should be able to think about what do real neurons do.

So it's kind of like we're building the neuron as a little biome, a little mortal computer in of itself.

And we know that they communicate with spikes.

And so the spiking predictive coding is like one way.

There's other ways to emulate predictive coding at a very fine course, fine grained dynamics level.

And I would imagine that that would probably be a great way to build a neuromorphic

chip-based mortal computer.

So the idea is if you get into neuromorphics, and the mortal computing paper does talk about it, not in great detail.

It talks about even my other work that's beyond predictive coding, like forward-forward, predictive forward-forward only learning and other variants.

um and also spike timing dependent plasticity and how do all those relate to the mortal computer and i think that's in the supplement so if you're like really a glutton for punishment and you can't get enough there's you know an appendix with a couple sections um and it's talked about there and so i think that

You can just, for the viewers of this podcast, this closing podcast, you could be like, well, that's how it all relates.

Really, it was all parts of a mortal computer.

And we can all pretend that from the beginning I had envisioned a mortal computer, even though that only came out the framework in the last seven months.

I see all those parts as giving rise to that.

And there are tools that you can use, just like Daniel brought up the whole framework of active inference and the free energy principle and Bayesianism.

they're all tools that might help you build, you know, very powerful and interesting mortal computers, whether they are simulated or whether they're real world.

And then as we brought up in this one, you guys have, and I think it's a compliment to like some of Chris Fields teachings and some of his work.

There's the, also the whole quantum interpretation, right?

not quantum computing as a solution but rather a mortal computer and a neuromorphic system which that's what you know carl and chris did and carl and i did in mortal computation the interpretation from the quantum information theoretic could be a very promising uh way of formulating it and right and that might open up the doors to an extremely powerful form like being quantum computing so

I think there's a lot of wonderful wild out there places to go, but they're not too out there.

That's my last point that I want to make.

They're out there.

They go against a lot of our, like I said earlier, held beliefs, especially those tied to immortal computation.

But I also think that there's the kind of build on intuitions and ideas that have existed in other places, like if we take biology and biochemistry and biophysics seriously and we know that these things work.

So it's not like, oh, I'm going to do something drastically strange and controversial.

It's just saying, let's take a little bit deeper inspiration from the world around us.

and living entities to build what could arguably be one way to do artificial general intelligence and ultimately artificial sentience which i think is kind of like the the final end goal right and then yeah and we end up there so thank you guys again it was so much fun talking letting thank you for letting me at some points ramble i hope my rambling was useful but you know


SPEAKER_04:
thank you i'll give a short closing remark so first thank you blue for working on the dot zero diligently and thank you alex for like suggesting to take on this challenge and reading between and among the citations is like always what it's about and the engagement and the developments in the real world so it's just epic it's fun and it's live the research program is lived forward but experienced backwards or however it was

um definitely very excited for everything you've described and on on all these topics i hope we can continue to discuss and that people will be excited to step up and do like a 56.3 um and we can just like continue working together and i'll close actually just by reading a short selection from an abstract

because I think it really contextualizes a big element of Bayesian mechanics.

So this is the paper, Is There a Newton of the Blade of Grass by Peter Schuster 2011.

So just the first sentences.

In 1790, Immanuel Kant makes the famous statement in his Critique of Judgment.

There will never be a Newton of the blade of grass because human science will never be able to explain how a living being can originate from inanimate matter.

The German naturalist Ernst Haeckel, about 70 years later, celebrates Charles Darwin to be such a Newton of the grass blade.

Haeckel's enthusiasm about Darwin was not shared among his contemporaries and is not too widespread today, although the path-breaking role of Darwin's scholarly work is not...

least doubted or questioned the american philosopher physicist and molecular biologist evelyn fox keller says that considering darwin as the newton of biology is simply wrong darwin himself has systematically avoided dwelling upon the question of how life has originated from inanimate materials natural selection begins with a living cell

And I think it's actually this nexus that you're addressing with the 1900s and early 2000s in mind that is a big one.

So thank you again for undertaking the project and for joining these streams and talk to you next time.


SPEAKER_01:
Yeah, thank you for having me again.

Looking forward to the next time.


SPEAKER_03:
Bye.