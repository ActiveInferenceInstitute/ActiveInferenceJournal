SPEAKER_00:
Hello, everyone.

Welcome to the Active Inference live stream.

And this is the Active Inference Lab.

I'm Daniel Friedman, and I'm really excited to be having this conversation with my friend, Blue.

Hi, Blue.

Welcome to the Active Inference Lab, everyone.

We are an experiment in online team communication, learning, and practice related to active inference.

You can find us on our website, Twitter, email, Discord, YouTube, whatever it may be in the future.

This is a recorded and an archived livestream, so please provide us with feedback so that we can improve on our work.

All backgrounds and perspectives are welcome here, and we will look forward to using good dialogue video etiquette.

Today in 16.0, we're going to be setting the stage for February 16th and February 23rd, 2021's events, which are both going to be discussions on this same paper we're talking about today.

And for the 16th, we're going to have the author, Wanda Weiss, join us for the discussion.

today in 16.0 the goal is really to set the context for 16.1 and 16.2 which are participatory group discussions the paper we're discussing is the neural correlates of consciousness under the free energy principle from computational correlates to computational explanation by weiss and carl friston november 18 2020 and there's a link given

The video is an introduction to the context.

It's not a review or a final word.

Blue and I just gave it a read.

We're still working through these issues.

We hope to kind of surface what we're thinking about on those topics.

And one of the punchlines is that FEP, it's not a singular theory or a definition of consciousness itself, but it lends itself to some pretty powerful thinking and theory development in this area.

And in the video of 16, we're gonna go with an introduction section and thanks Blue for the structural tip.

We're gonna talk about the author's perspective on their introduction, really like aims and claims, abstract and roadmap.

Then we'll consider the keywords kind of just where we were at with those topics and where we think there might be a nice bi-directional road kind of on and off ramp from active inference.

And then we'll actually go through a fair amount of the details of the paper, including some of the formalisms.

close with a couple questions and thoughts and in 16.1 and 16.2 we'll be discussing this paper so that is all for the introduction let's go to the aims and claims of the paper um the paper was as stated blue do you want to um be the aims and claims so


SPEAKER_01:
The first theme is how can research on neural correlates of consciousness lead to an explanation of consciousness and what role could the free energy principle, the FEP, play in this endeavor?

We have suggested that research on neural correlates should be complemented by research on computational correlates of consciousness, CCCs, in order to yield a computational explanation of consciousness.

Moreover, according to the free energy principle, neural correlates of consciousness must be defined in terms of neural dynamics, not neural states, and compilational correlates of consciousness should be defined in terms of probabilities encoded by neural states.

All we hope to have shown is that a computational explanation of consciousness is possible and that the free energy principle can make a significant contribution to this project.


SPEAKER_00:
big aims and claims and a lot of interesting things that are already being mentioned a lot of these words we're going to dive into so if it's your first time hearing some of these terms and acronyms or whether these are things where you're already bringing a lot of priors to the table hopefully you'll be able to look at it in a new light and these are big topics so there's just going to be a lot underlying these aims and claims anything else you'd add on those

cool let's talk about the abstract which is how the authors have distilled and summarized their work for broad uh reading so this is the section that most people read it's kind of like a power law where a few people see the title then the smaller subset see the abstract and it goes down so we always look at how the authors reflect their um work in the abstract so i'll read the first half the abstract and then you can give a thought on something in there

How can the free energy principle contribute to research on neural correlates of consciousness and to the scientific study of consciousness more generally?

Under the free energy principle, neural correlates should be defined in terms of neural dynamics, not neural states, and should be complemented by the research on computational correlates of consciousness, defined in terms of probabilities encoded by neural states.

We argue that these restrictions brighten the prospects of a computational explanation by addressing two central problems.


SPEAKER_01:
So just a thought there.

I think that the FEP is really well suited to providing a computational explanation of consciousness or a computational correlate of consciousness.

If we can kind of

Maybe talk about the easy problem of consciousness, right, which which will get into the hard, easy and medium problems of consciousness.

But but really, the easy problem of consciousness is well described by the FEP.

And I don't know that we can really even in like nail down what exactly consciousness is, except from that computational standpoint.


SPEAKER_00:
Cool.

And this question of defining consciousness, it's going to rear its head a million different ways, not the least of which when deciding what to measure or which analogy to use, having a computational versus some other type of adjective that you could put there.

So how about you go for recapitulating that last point, which is there's two central problems that are going to be addressed and then continue.


SPEAKER_01:
So we argue that these restrictions brighten the prospect of a computational explanation of consciousness by addressing two central problems.

The first is to account for consciousness in the absence of sensory stimulation and behavior.

The second is to allow for the possibility of systems that implement computations associated with consciousness without being conscious, which requires differentiating between computational systems that merely simulate conscious beings and computational systems that are conscious in and of themselves.

Given the notion of computation entailed by the free energy principle, we will derive constraints on the inscription of consciousness in controversial cases, for example, in the absence of sensory stimulation and behavior.

We show that this also has implications for what it means to be as opposed to merely simulate a conscious system.


SPEAKER_00:
So the two key problems, the central problems, one is what happens in the absence of stimuli.

And then the second big block of text is the difference between actually being conscious versus simulating it.

And then by thinking about these two central problems and using the FEP as our guide, remember we're under, according to the title, under the FEP, not because of the FEP or some other way of talking about it.

under the fep we're going to think about how this notion of computation is actually going to lead to some unique predictions and explanations and hypotheses that then we can talk about in a really scientific way that will take it out of the land of abstraction and well what about this thought experiment and what about this uncertainty here and towards the realm of well this model predicts that this kind of a brain or this kind of an agent will have this type of a measurement or response in this context

We want to have that consciousness-o-meter, the measuring device.

But without the definition, it's hard to have the measuring device and vice versa.

And so FEP looks like a promising way to sort of navigate that paradox.

Let's go to the roadmap.

so this is a paper structure with six sections an introduction and a conclusion and with four internal sections the first internal section and we're going to go through a lot of these keywords in just a second starts from neural correlates of consciousness and moves the discussion from thinking neurally to thinking computationally so that's the movement from neural correlates to computational correlates of consciousness

Then the third section moves from the computational correlates of consciousness into the free energy principle.

Surprise, surprise.

The fourth section goes back to computational correlates and moves the focus, the regime of attention from computational correlates alone, which have already been linked to the FEP to computational explanations of consciousness.

And then the fifth section brings together the computational explanations of consciousness with some of the first author's previous research on minimal unifying models of consciousness.

And all of this is implicitly interwoven with FEP, which is kind of what is being tied together with this paper.

So any thoughts on the structure or the roadmap, Lou?


SPEAKER_01:
No, it's good.

It was a good flow, I thought.


SPEAKER_00:
Yep, a dense paper.

So...

Definitely okay to take it in many sections and skip around and skim it through it first.

There's a lot of ways that each person will read different genres of paper.

Okay, the keywords, the part we've been excited to talk about, I guess, all of it though.

And we just took the keywords from the paper and laid them out in an order and tried to present each keyword in a way that was standalone on just one or two slides.

Again, thinking about the on and the off ramp for active inference.

So if you read this because Fristin's one of the authors or because it came up in a keyword search for free energy principle, but maybe you haven't thought about some of these other topics, that's one mode of listening.

And then the other mode of listening is like maybe with more experience or having thought more about these topics, where's free energy principle and active inference playing into all that.

And then beginner's mind and learning by doing plays on both directions of the road.

So our first

keyword uh well let's just actually read through the keywords free energy principle and active inference consciousness minimal unifying model neural correlates of consciousness computational correlates of consciousness computational explanation and islands of awareness okay so first free energy principle so how about you read it and i'll give a comment on the first half and then we'll flip


SPEAKER_01:
Awesome.

So the free energy principle provides an information theoretic analysis of the concept of existence of self-organizing systems.

It entails that self-organizing systems at non-equilibrium steady state bound the entropy of their sensory signals by minimizing, on average, a quantity known as variational free energy.

As such, FEP is not a theory of consciousness.

Do you want me to read the second part or do you want to switch now?


SPEAKER_00:
I'll give a thought and then we can switch if there's two, I guess.

But just that in the first paragraph, if you only dipped a toe in, you'd already find that FEP is not itself a theory of consciousness.

So the debate's not done.

We're looking at what the FEP is.

That's the first part of the paragraph.

It's a certain information theoretic analysis for thinking about self-organizing systems for complex adaptive systems.

And it's not itself a theory of consciousness.

So I think that that's just a really nice way to open the tone of the paper and the discussion.

So the second part here, referring to what is the free energy principle and how is this going to relate to the paper?

A fundamental constraint provided by FEP is that it only applies to active systems that engage with their environment.

Hence, a computer simulation of a system that minimizes variational free energy may perform computations that are also instantiated by a conscious agent that interacts with its environment.

But if these computations are realized by a piece of hardware that cannot be regarded as an agent, e.g., they cannot move or change external states, then they can at most lead to a simulation of consciousness.


SPEAKER_01:
I think that this is interesting because it's like, it doesn't really...

just like delineate what exactly is an active system and what what is engaging with the environment like for example if you have like an unborn baby inside of the mother is that like an active system engaging with its environment like can it doesn't have any control over like the environment of the environment is delivered to it like all non-stationary like self-organizing systems that are maybe more passive like i think about like ocean you know

creatures that just sit there like... I know that the FEP does apply, but it just doesn't really delineate exactly what those systems are.


SPEAKER_00:
Yep.

Agreed.

And so if this is your first time hearing about it, it's obviously a big topic.

There's a lot of ways to go about it.

Also, I had a question like whether other physical systems like a proton, are we going to include that as an active system?

But there's a lot of... Is that an active... It's engaging with the environment, yes, but is it active?

So...

that's where we're going what is simulation versus actual consciousness where's the fep let's in this keyword section think about just what is the fep before we go that far out with the paper because we wanted to draw on the quotes from the paper to see where they were going with the fep and now let's pull back to just thinking about what is the free energy principle and this is a slide that had been used actually a couple uh

active streams ago, but it actually, a lot of the terms got reused.

Fokker-Planck, Helmholtz, non-equilibrium steady state, Markov blankets, active inference, everything here, except for some of these more specific like sub process theories on the neural side, almost everything here was discussed in this paper.

So this is why it's so interesting to think about convergences between the papers, because there's a lot of overlap.

We're on the right track and we can hopefully start to reduce our uncertainty.

Just to run through these, the Fokker-Planck, and this is from Mel Andrews' paper and the history of thermodynamics of the FEP.

So active 14, if you want to listen more, but the Fokker-Planck is bringing in a...

uh vector way and the helm holds as well of dealing with vectors and mathematics for certain kinds of systems namely these non-equilibrium steady state densities which we're going to go into in more detail so we're not going to go into it here and the free energy principle is a

just as was said on the previous slide, it's an information theoretic analysis approach for these kinds of systems.

Doing interesting stuff, non-equilibrium, steady state, cybernetic systems, and using that type of vector maths on it, and then it leads to all of these consequence, falsifiable, testable hypotheses, the process theories up at the top, and there could be other things as well.

Anything else to add on that, Blue?


SPEAKER_01:
Not at all.


SPEAKER_00:
To go into one of the process theories that we like, active inference, and this is from another paper we've discussed a while ago, Vassal et al., A World Unto Itself, and this was thinking about communication.

On 11, we said, okay, it's about active systems engaging with their world.

Slide 12, we're going to think about that in this kind of thermo, info, statistical way.

And then 13, okay, let's bring in almost the real processes and almost a systems engineering or just a systems modeling perspective to what kinds of systems are engaging with the world, active with a generative model of their niche, and how are we gonna think about that under the free energy principle?

That's where active inference comes into play.

And this is a diagram we see in many guises where you have internal states and external states, which are separated by

an interface that can be modeled as a Markov blanket, but we'll also go into more detail on that later, where what goes inside or from one side of the interface to the other is sensation coming in.

That changes internal states.

Internal states such as

different policy estimates for the world or different policy estimates for what one's self will engage in result in different action patterns, which influence external states, which also have their endogenous dynamics.

So that's active inference.

That's what active inference lab is like thinking about and coming at from many angles.

So that's one little just snapshot of active inference.

What is active inference for you today, Blue?

Or what does this make you think about?


SPEAKER_01:
so i'm always interested in reflecting on the internal states like hunger right how that results in an external action like a behavior like i'm gonna go find some food so i'm always interested in reflecting on on this and whether it's um it can be reduced to computation right like we know if we have a good estimate of what our predictive model is

or our generative model is, if we have that estimate, then we know what's coming at us, what is the input.

Can we always predict output?

Are we just the sum of... Are we just a computation?

I always think about that, so it brings that up for me.


SPEAKER_00:
Yep, this is a skeleton, but then if it's skeletons all the way down, where's the...

meet where is the actual self or is it something other than that maybe it's that that is the self or some other thing like that so active inference active inference eight we talked about it from a reinforcement learning and a control theory perspective we've talked about it from a historical angle with mel and from a philosophical angle um in 15

We're reintroducing consciousness, which we also talked about in nine with a projective consciousness model.

So that consciousness free energy principle active inference discussion was about geometry and the projections and then the way that agents did active inference on this projective geometry.

We're actually not going to talk about that projective, almost peripersonal space.

relationship with the fep and this paper is going to take the same topics go in a little different way with more of a focus on the information theory and on the generative model and on the divergence of a few different kinds of surprise and measurements of the world so it's another facet

let's talk about the main piece of the paper which is consciousness so how many ways to start or cover it um just when we were planning this as a lab and talking about it people were just bringing up good stuff in live discussion so someone said a felt sense of isness people were asking like where do we look for consciousness what do we measure and where what spatial temporal scales what kinds of systems and many people just pointed out there's so many

understandings here and uh areas to study i mean if one is curious there's a great wealth of resources um before we dive into each facet of this hexaflower blue what does consciousness what like what interested you in this paper what makes you curious to study these things so i don't know consciousness is one of those things it's like love like we don't really have a good like definition for it we all kind of like


SPEAKER_01:
I think we know what it is, right?

Like we think we know what it is and what it isn't, but it's like a very, you know, ethereal concept.

So I don't know, it's always interesting to try to tackle these like things that can't really be pinpointed or like nailed to a certain like

bored right like you can't really exactly define consciousness it's always fun to kind of take a scientific approach to evaluate these things right like reduce love to you know oxytocin or whatever but it's more than that like it's it's I mean clearly consciousness is more than what any one thing that where it's more than the FEP it's more than what we're able to you know

attached to it project onto it but it's it's always interesting to try to tackle these hard problems and i love the hexaflower so i've got to say like daniel put this together it's like a um a super cool design that takes consciousness as the center point and then integrates all of these keywords that we're going to be discussing the minimum unifying model islands of awareness neural correlates of consciousness computational correlates of consciousness

computational explanation, and then the easy, medium, and hard problems of consciousness, right?

So all these are surrounding the consciousness as the center point.

I love it.


SPEAKER_00:
What was kind of fun about that and almost meta is like, I was trying to arrange the list.

It's like, okay, we got active inference, free energy principle, keywords.

Get them out of the way.

Then we have consciousness-related keywords and consciousness itself.

And so how can they be arranged linearly?

And it was like there's no single linear arrangement.

Everyone could have a different way of seeing that.

So then it's just something that from studying the bees, we see the hexagon and then I see it more like when we want to reflect tiling, but a coherent tiling like Settlers of Catan, you can play on a bigger board, smaller board, but instead of just something that's blocky, it's like a it's yeah.

okay so let's go to the first little sub pedal because thinking about the problems that steer us or that motivate us in consciousness research so this is like not you know moral proclamations on consciousness this is about scientific study of consciousness and about investigations um about people who are coming together from different perspectives not just living from within um

one specific definition.

So people are going to be kind of playing fast and loose and having different takes.

That's kind of the wildness of the field.

So there was famous framing of the hard problem of consciousness by Chalmers in the 90s and subsequent research.

That's a pretty famous singular moment, but

just thought of you know easy medium and hard problems but different people are going to perceive different difficulties for some people they're really hung up on mind and body other people it's like a speed bump they just say yeah i mean it's this other way so that's just something that studying the field of consciousness studies is so interesting to me is some people a word they just they spend their whole life investigating it other people they just blow right by it or it seems like a question that totally it

even if they're aware of it isn't something super relevant so which problems are easy medium and hard it fits in that category there are hard problems like how could a physical thing or can a physical things generate conscious awareness and how would we know there's a lot of hard problems um but it's an interesting topic what did this make you think about


SPEAKER_01:
I think I already divulged what I was thinking about in the easy, medium, and hard problems of consciousness and how the FEP really lends itself to the easy problem.

Really, are we so reducible to the easy problem of consciousness?

We all know that there's something more than that, and when we get into that more than that

thing do we become then like less scientific and more like spiritual right like like do we take some leap of faith going into the hard problem of consciousness or are we just like ascribing some

property like if we're going to really be scientific about it like consciousness is one of those things that if you're going to buy into it like it has to kind of be everywhere like i mean we make this like hard cut off like if you look at research like only higher vertebrates that have a central nervous system those are the only like things that are conscious in the world right like and some people have like lines within that like only humans right so

Really, can we draw these like hard boundaries?

Like, I don't know.

I kind of feel like if consciousness exists, it's pervasive, but maybe pervasive only among living systems, but then as a tree conscious.

So it's one of these, it's hard.

It's a hard problem.


SPEAKER_00:
yes um agreed and the easy one is almost the part that explains it's like when people make fun of daniel dennett's book consciousness explained consciousness explained away it's like yeah we know how a robot would respond to a sensory um you know cue to engage in action but that's not the hard part that's not really the heart of the matter


SPEAKER_01:
next topic so minimum unifying model of consciousness what what did you find interesting about this or what did you like about what you read um i liked this quote that um i pulled out from from the end of the uh paper like i think it was right before the conclusion maybe the end of section four

that says, you know, minimizing variational free energy could count as a minimum unifying model.

Variational free energy must be minimized by every self-organizing system that persists and hence also by any conscious system.

I liked that and I thought that it was applicable and kind of really right on target.


SPEAKER_00:
The challenge is decompiling.

So every self-organizing system that persists

Are those the conscious systems?

Are those two sets the same?

So self-organizing storm cloud, what is it like to be a storm cloud?

What is it like to be a volcano?

That's the question of what is it like to be a bat?

And then another thread is like the cultural.

Like maybe if there's a prior or something that's implicit or sub-personal that leads us to certain kinds of explanations being just absurd versus real.

intuitive like panpsychism versus only vertebrates or only subclasses or or nothing it's like what do you mean nothing it's like well just nothing it's not something i wonder about why not but not not an issue if not so that's the minimum unifying model it's going to come up in the terms of this paper just because that's kind of um both of the authors are interested in that i would say

And just to go into one of the prior papers, a solo author paper by the first author, Wanja.

So this is the science of consciousness does not need another theory.

It needs a minimum unifying model, unifying words on 7-11-2020, great date for a paper.

And here are on the right side are referring to two kind of hypotheses for how we could think about different

fields of meaning one way of uh arranging different fields would be like information generation is all these tan things in a so this is like computers and random number generators and die or something like that and then consciousness is a subset where maybe there's some conscious systems that don't generate information maybe there's some that do

Maybe you have a different feeling about how these are overlapped, like in B, where there's information generating systems, that's a big super class.

And then within that, there are systems like the blue, the non-reflexive behavior that are cybernetic to some extent.

Like it's predictive, it's acting in a way that might have some game theory like, or some sort of adaptive seeming dynamics, but consciousness is a subset of that.

And so I just really appreciated the research direction of the author, because the difference between A and B is night and day.

And there's many other options.

It wasn't an attempt to be exhaustive.

It's like, if we could talk about this, we could have a better way of framing, oh, our computer's conscious, our human and the computer, what's conscious?

Let's take a step back.

What are we overlapping with what and what's on the table here and what kinds of words do we care about and where's the territory?

It's okay if territories are nested within each other or overlapping or they're intercalated or they're complementary or something, but we have to pull back to kind of a level where we can at least sort through all these theories of the science of consciousness.

because otherwise it's just a total mess and the information overload aside, it doesn't even make sense.

Just if everyone's working in their own wavelength, it doesn't even make sense.

So really nice direction.

Any thoughts on that, Blue?


SPEAKER_01:
so i wonder if like information generation and consciousness like aren't a full overlap like if those can just like be all lumped into one of one another and then non-reflexive behavior is like some subset of that um just just even going to like the spin of a of an electron like a coupled electron like if you're looking at at qubits right like so it it's always got to be there's a paired system and is that conscious like just getting down to the very basic like atomic particles


SPEAKER_00:
Especially what we talked about earlier, like if the free energy principle is for so-called passive and active systems that are engaging with their niche, like systems that aren't usually thought of as very reactive, like a proton or like a rock at a larger scale.

are they on this consciousness continuum or are they disjoint from it or so those are the kinds of things where reading the paper helps bring us to the edge of the ideas and of research and also to the edges socially thinking about it and talking about it hearing people who have different perspectives so on the perspectives issue also computational explanations so just in the word

What is computation?

You're going to have a lot of takes.

Some people will say, I mean, of course, you know, my Linux computer right here is a computer, but then they'll say that the hydrogen is also a computer and the football, when it gets kicked, it's also computing a parabola.

So it's computing everything.

And then what is explanation?

philosophy of science rabbit hole to go down, but is it about being emotionally satisfied with what we know?

Or is it about being able to usefully act?

Like, do we have an explanation for traffic?

I don't know.

Maybe some people would say yes, no, in this situation, yes, but do we have best practices?

Do we have approaches?

So explanation versus approaches,

And then the last point here is just thinking, especially in the biological case, about unconventional computation.

So let's just call the Turing von Neumann genre, the binary state machine idea conventional computation.

There's a whole world, quite literally, of unconventional computation.

So reservoir computing, things that we're going to talk about right at the very end.

Within the binary computers and then outside of the binary computers, physical computing, wetware by Bray is kind of about moving beyond software hardware distinctions, which don't exist in cells.

DNA is DNA.

It's not hardware.

It's not software.

It's not source code.

It's DNA.

And then Leviathan cover of that famous work with a larger source.

the group made up of the individuals so that kind of multi-level systems perspective on computation multi-level cognition all of these things come into play when we're talking about computational explanation so can i just like yeah maybe add a little bit oh yeah i know i know that this is one of your chillest areas so i just think about explanation like what is the um


SPEAKER_01:
Like explanation is like the death of curiosity.

It's like the ultimate like pacification.

Like I just explained it to you, therefore shut up.

Like that's why, that's your answer.

So I think like explanation, like we should never be satisfied with any explanation.

Like we should not...

presume that we understand fully like anything because it just ceases investigation at that point.

And so I think like, you know, computational approximation might be more fun and lend itself more to deeper scientific explanation.


SPEAKER_00:
yeah one thing that we were talking about just like um an hour ago with some other people in the lab was like if the heart of the issue is how things are realism once you get the lossless you know mp3 file the quest for what is is done but then if the song is not just the mp3 file but it's actually the relationship how could you say that that ever ends so it's kind of like yeah are we looking to engage

and to do things in the world and act?

Or are we looking to come to a satisfying emotional explanation in some

uh topic all right so 19. so here we are getting to some of the details like the computational versus the neural correlates of consciousness so there's two double c's this is the ccc and then the next one's going to be the ncc so what are the computational correlates of consciousness what would be your definition for a ccc


SPEAKER_01:
So, like I said, I think that the computational correlates of consciousness, you know, it goes back to, like, is a football conscious, right?

Like, it's input-output.

So, like, you know, you have – what goes into the system and what comes out of the system and, you know, is – like, can we call that consciousness?

I don't really know.

But for me, like, my interpretation is it's a decision, right?

Like, so you have the input.

You know what you're supposed to do or what you think you're supposed to do.

You have some approximation about what you're supposed to do, how you're supposed to engage with your environment based on the input that comes in.

And then you act in accordance with what you think you're supposed to do or what you predict will lead to the best outcome.


SPEAKER_00:
I don't know.

Something like that.

Yep.

Well, the correlate word is suggesting that this is not an explanation that's causal.

Correlation is not causation, as they say.

So it's like, we're talking about correlations.

We're talking about observables, kind of like a correlation, like a regression coefficient, but a little bit probably deeper than that.

And then I guess my question for the authors would be, how is this related to the cybernetic correlates of consciousness or the cybernetic correlates

attributes um in the paper nine with rudroff and um and other authors it was like there was the five functional invariance or something like that like the perceptual invariance so what are these computational correlates um and how are they related to algorithmic or cybernetic

Because maybe the word computer has a lot of baggage.

We're live streaming on a computer.

It's just used in a really specific way.

It's a specific word.

And then maybe there's another way to think about like processual correlates or like the informational correlates of consciousness that might be a little bit...

different aspect of what they're showing but the details of what they're showing we'll get to all right ncc so the neural correlates of consciousness it's another correlate um question so we're looking for neural things that correlate with consciousness so first off correlation causation again and the correlation can be like evolutionary like we think that this brain region over the breadth of species diversity is correlated with consciousness or it's correlated with this behavior

or the correlation can be like a molecular thing, or it can be a dynamical pattern.

It could be this fMRI pattern or this EEG pattern is a correlative consciousness.

We set them up so that it was an experiment where in this task, they did have consciousness and this one they didn't.

So it gets into defining consciousness, but they say the difference between these two conditions is the neural correlative consciousness, or the difference between patients in this category versus patients in this category is this.

And for two takes on the issue, in 2016,

Christoph Koch at all, talked about like from their pro neural correlate of consciousness agenda direction, what were the problems and progress in their fields?

And then here's a paper from 2019 with me and a colleague where we kind of took a step back from just thinking about the neural correlates and thought, okay, what about for the ant colony or for other systems that aren't just like set up like the mammalian brain?

how would we think about consciousness because if you study only the neural correlates consciousness you're studying how would you know that that's actually the subset of systems it's like you're shining a spotlight maybe a good one maybe a distorted one on the neural system but what if it's not just neural it's glial oh well of course i meant that okay well what if it's neural and the body oh yeah i meant that too so all of a sudden okay now you're talking about neural in the niche and that's why we're talking about multi-scale systems

so that's what there's a lot of interesting stuff happening here and about how the fep and multi-scale approaches fit together with the more neural focus and the more certain time scales and certain neural signatures that avenue of research in neuroscience humans sensu strictu now connecting it to a clearly very vast area what do you think about that blue um


SPEAKER_01:
So I think that the neural correlates of consciousness is cool.

I think that like they do the fMRI study, like when you're asleep versus when you're awake and then they take like the difference.

That's like a common way that they like estimate the neural correlates of consciousness.

There's also like the hyper consciousness, like I can't remember the author.

um but he did like the information theory like aspects of like psychedelics so like expanded consciousness like what does expanded consciousness look like and how like there's more connections between uh neurons i'll have to remember the name of that paper for next time um but but it's it's just uh the neural correlation of of consciousness was really done by differentials um that's a common thing i think


SPEAKER_00:
Yes, exactly.

It's an experimental way to get at using measurements, real data, real experimental setups, the kinds of things that exist in neuroscience labs, getting at questions of consciousness.

And the question is, are we on the right track or might we be misled by the tools that we have available and the approaches we have?

So 21, islands of awareness.

Okay, so this is kind of a topic that I'd never heard about.

It's from a recent paper by Bain et al, 2020.

And so we're thinking about kind of the fringe cases or the areas where we might be able to have a unique prediction or an explanation that is going to be a value add for the FEP in thinking about neuroscience and consciousness or which systems are going to be useful to think about, even if other systems also agree.

And there's going to be this case proposed, like a thought experiment called the Island of Awareness, which is a conscious stream.

So I don't know, is the rabbit already in the hat?

It's a conscious stream or system whose contents are not shaped by sensory input from either the external world or the body and which cannot be expressed via motor output.

Now, one could just say, well, but what if the body's part of the whole conscious system?

So it's a kind of non sequitur to say, well, it's happening in the brain.

Ergo, you can cut that out.

maybe you can, maybe you can't.

But by looking at the paper and by believing that the authors have thought through what they wrote, it's always a useful starting point for discussion.

So the fringe and the edge cases can be where we start to see theory differentiation.

So if this thought experiment isn't very interesting to you, you'll probably find another one that might be.

But these are like we're looking for the exceptions to prove the rule or the sort of higher level game that is revealed by us oversampling just one area of state space.

The issue with thought experiments, though, is, well, kind of like science fiction, they can provide inspiration if they're...

at the right place at the right time, you're never going to reach these ideal situations.

And they often have a huge amount of assumptions built in.

And then even for, there's this dream of empirical application.

Oh, we'll study the island of awareness then because it's such a great thought system.

And there's a hundred papers on published on it.

But then it, even for a close case,

like, oh, maybe in this medical condition, they're locked in syndrome.

It ends up that it's not exactly what people want.

And so then it goes into a really protracted multi-year thing with just is the system the right one to test this thought experiment?

Short answer, no.

And it's hard to know what to do with real systems to really make a dent in the consciousness problem.

Any thoughts on that?


SPEAKER_01:
Just that the islands of awareness, I think,

are always, there's always going to be those exceptions to the rule or those hard cases.

Like we don't even really know how to get at consciousness in a system like that.

Like a brain in a dish model, is there consciousness in that?

Like I remember working in the lab and growing cells in my like petri dish or whatever they were growing in.

And like, you know,

I was like, I wonder what my culture is thinking or if they're thinking, like I would be like doing neuronal differentiation and be like, you know, I just wonder like what they're thinking about today.

So, so, I mean, it's just, it's always like a, this mystery.

So we don't really know if there's, if we can approximate consciousness in a system like that.

Also the author of the information theory and psychedelic paper is Andrew Gallimore is his name.

Sorry, I forgot.


SPEAKER_00:
Cool.

Yeah.

And again, like how does philosophical uncertainty or debate propagate through basic research and application?

What about with organoid research on neural cultures?

And so is there a certain size of brain or what about there's a brain and a body or you recapitulated something from a stem cell, from a neuron and from a skin cell or you made some new cell type.

It's like, is it different or worse or better to throw a gallon of skin cells versus a gallon of this type of cell?

those are big questions and that's why the consciousness discussion is really important to not just resolve but to sort of like clarify and to engage with so the big picture of this paper now to get into um the

quotes and some of the key topics.

We're not going to go through every quote.

We're not going to read every quote because there's a bunch of quotes, but this section is going to just describe the main three observations that link three of the big TLAs, three letter acronyms together.

So FEP is the big one, but then we have the neural and the computational correlates of consciousness.

So they're all kind of going to be joined together.

And just to read the first point of each one,

If we're going to go FEP, neural correlates should be in terms of neural dynamics, not neural states.

So in other words, patterns of neural systems through space and time, not just like, oh, the Jennifer Aniston neuron fired.

So they were conscious of Jennifer Aniston.

It's going to have to move a little bit beyond that into something that's about dynamics through state spaces.

This second point is that there are relevant distinctions to be made between the probabilities of movements through this neural state space and the probabilities encoded by neural states.

That's going into a whole encoding representation question and a lot of statistical details.

If that sounds interesting, read it.

And then the third point is that some of the computational correlates literature

able to be recast within the FEP.

And so the FEP is going to be like a bridge or like a nexus between people have identified 10 computational correlates and 10 neural correlates.

Well, you got this blood signal in this brain region when they see this thing and this auditory region when they hear this thing and this when they remember themselves.

And then on the computational side, you have this feature ABCD, all this stuff, information theory.

How are we going to bring them together?

FEP.

Any thoughts, Blue?

nope so let's go through kind of with a little i don't think we kept the exact order of the paper but early in the paper we start from the neural correlates of consciousness which is something that people have at least probably thought of like there's something different when there's blood loss to the brain than the hand so people have kind of thought that there's a neural correlate of consciousness

We're going to move the discussion from just thinking about neural correlates to computational correlates.

So this is the narrative trajectory from being like neuro reductionist or centric to more computational perspective.

They say CCC computational correlates are more general and promised to be more explanatory than neural correlates.

correlates but there's also challenges so big benefits that you get you can consider ant colonies and ecosystems all kinds of cool stuff and perhaps have access to a whole new set of computational tools downside are um what computational correlates are not defined in terms of neural structures but are neutral with respect to the question of whether the conscious experience correlate with global neural activity or not so the issue is that the brain is changing state all at once

And so you don't know whether that one feature you isolated is really the difference that makes a difference, so to speak.

It's like you could run two different computers and you wouldn't really know what about their outcomes from a correlated perspective was the actual explanation.

So one part is it's hard to get an explanation, even though they say it's more explanatory.

And then basically the second challenge for the computational correlates is the mapping from any correlate to consciousness, especially in controversial cases.

And the third challenge for any correlate of consciousness is basically fringe cases and cases we don't know or don't, but even those who knows what we do and don't know.

So-

there's these are three of the major dimensions of the challenge for any correlate of consciousness global versus local structure mapping between um consciousness and any correlate arbitrarily or not and then cases we don't know or understand so there's big territory that's pretty open and there's a lot there what do you think about that


SPEAKER_01:
There's a lot, there's a lot remains to be, you know, elucidated in all of those areas.

So.

Yep.


SPEAKER_00:
Yep.


SPEAKER_01:
So 24.


SPEAKER_00:
So yeah, we'll kind of,

Taking computational, just at the author's word, that's the thread they tie.

So it's a broader understanding than just, I think, a computer processor.

I hope that we'll find that out, especially when we talk to the authors.

So there's a generality of these computational principles, but they also have a disadvantage.

The properties described by them may not be necessary for many types of conscious experience, but probably not sufficient.

So probably, it's a probabilistic statement, but do we know what is sufficient?

And so in other words, what is required for consciousness?

That's sort of the issue with this computational approach is you get this general toolkit that can cross scales really easily.

You say, oh wait, if I can make a measurement of a millimeter and a measurement of kilometers, and then I can use my tools on numbers, then it's a multi-scale model, right?

And so the challenge is, have you underspecified aspects of the system leading to a really potentially

like bad false positive or false negative rate of course the question is what is the ground truth whose ground truth and how are we going to get to these edge cases and resolve them in a real finite world and then the authors say in order to address this question of what is necessary and sufficient we show that um we show to what extent and from what assumptions some computational principles can be derived from first principles

so they're going to say all right this even the computational correlates of consciousness people yes there's some issues with going computationalist but we have studied those this is good phrasing then we're going to ask how even the computational correlates could be themselves generated from an underlying something first first principles which are going to be information and physical principles as we are seeing what do you think about that


SPEAKER_01:
So, I mean, I think in order to delineate what's required for consciousness, you need to kind of get at the point of what is consciousness.

Like, and I think that, you know, they artfully skate past that in the paper.

And I mean, I don't blame them, right?

Like it's a, it's a touchy and difficult and many gray areas, you know, exist within trying to define consciousness.

But if you can't define what is consciousness, how can you define the requirements for consciousness?


SPEAKER_00:
Yep.

agreed and so let's uh see what any of the authors have to say on that but this is the question how is computational principles or physical principles going to come into play all right here we go into the formalism section there's a bunch of formalisms in the paper

And here is just one from the paper starting on the top left that sites out to a Friston paper, this Friston 2019 long monograph that is having many active improvements and revisions and discussions on it.

And then here's two sections from this Friston 2019 paper from 12 and 13, I think, but really you could take it even back further, just like any other literature.

You kind of take it back as far as you want to learn.

But for the purposes of the top left, the paper that we're reading today, the key formalism is here, or one of the key formalisms, just the one on this slide.

We're going to express the flow of F in terms of surprisal, and hence in terms of a non-equilibrium steady state density.

Expressing the flow F in terms of surprisal is almost like thinking about surprisal like it were a flow.

So just like you could have a flow of water, we're thinking about kind of surprisal flows, which is to say using flow like dynamics to study surprisal, because that's all sort of a few different facets of the same thing.

And so there's going to be some flow that's going to reflect

some terms that can be rewritten a few different ways we're not going to go down all the details i think of every letter anything that we should add on this slide blue but this is just about the idea of expressing information as a flow which is going to set us up for some of these later discussions and formalisms yeah no i'm good

yep and we just throw these slides uh in the order just that we snap them so there's other orders and other ways of going through it we had to look up a ton of stuff we learned that the uh i'm going to bring this on the dell or the nabla it's the operator used in mathematics particularly vector calculus uh that is a vector differential

so it's like div grad curl but it's it's an upside down triangle but it does have to do with change just like a regular delta but it's a whole area of math and so this is just to say some people maybe they didn't expect an equation in a consciousness paper other people maybe they're very familiar with this math and applying it to consciousness seems like an outrageous overstep so that's the conversation yeah


SPEAKER_01:
If you're somewhere in the middle, I'm somewhere in the middle of that.

But if you're somewhere in the middle, just knowing that it's like about information geometries, like how Daniel was mentioning, it's about a flow.

And so when you have like, it's a geometry, like the probabilities are thought about in these shaped spaces and kind of knowing that helps to contextualize the way that it moves, I think.


SPEAKER_00:
You know, thinking of float, it all makes me think of like a program, it's all set up and loaded, which files to read in, what to analyze.

You hit enter, it's like a bunch of grain in a silo and you pull out,

the stopper, and then it flows because there are forces.

So the computer's having energy course through it, and there's certain irreversible processes that increment a flow of information.

And so that's kind of, I wonder what kinds of metaphors, like this could be something for the author, like how do we think about this flow

And where, how do we, how can we describe it and learn about it?

So this is another, this is, so yeah, maybe this one could have gone before the other one, but this is a pretty general framing of random dynamical systems that are using this Langvane formalism that was developed in the direction of Free Energy Principle by Ao, AO, 2008, and other authors.

And

Basically, we can read this bottom part and go back to the equation.

So the state of the system x of t at time t, tau, is constituted by slowly changing macroscopic variables, which are grounded in microscopic variables with faster dynamics.

So it's almost like saying little things are composed of littler things.

Little things compose bigger things.

So it's kind of allowing us to go multi-scale by saying that there's gonna be a sort of big wave and a ripple.

And a bunch of the ripples summating makes the big wave informationally just kind of like a bunch of physical things spatially compose a bigger thing, but this is happening

through time as a random dynamical system not with a spatial metaphor so think about little things assembling into bigger things and then port it out of the physical into the dynamical systems and it's what kind of a dynamical system it could be related to information this is why the result is a stochastic differential equation comprising not only the state dependent flow f

but also a stochastic term omega with a mean equal to zero.

So another way of thinking about this is like signal and noise.

And so it's all like the vibration, but you can partition it with a model into change through time of a signal and a noise that's like much higher frequency.

So that noise, it's not like you're saying it's like bad.

It's just that with the signal that you're pulling out, it's the residual.

And the signals that are hard to find are the ones that are shorter, like they're hiding in the noise, but those can be pulled out.

If you have a really long time series, you can totally pull it out.

And there's other signals where the signal is so strong and then the noise is so tiny, like the vibration an inch off of the orbit of a planet.

It's like really easy to pull out the signal because the noise term is so small.

So any thoughts on that, Blue, or we can continue?

All right.

So now we want to talk about what exists, which is related to Fristian's theory of every quote thing or of particular physics, which is a specific way of doing physics, and it's a physics of particles.

Anything that exists will have characteristic features that do not change over time.

This is like measure theory.

It's like, if it's not there through time, it doesn't exist.

Like the reason why there isn't, it's kind of like material costs.

Like if there isn't a cow in my room, it's just not there.

If something doesn't persist, it's not there.

Formally, we express this by assuming that the system is a random dynamical system in non-equilibrium steady state.

So the equilibrium, the total heat death equilibrium steady state of air molecules in the room would be dispersed

to homogeneity with some summary statistic, like the well-mixedness.

But if it's not at equilibrium to the well-mixedness, physically or kind of informationally, then it's in a non-equilibrium steady state.

The steady state part is because it's existing through time, like the length of your arm, but then the non-equilibrium part is reflecting that the arm is an organization beyond just dissipating air molecules.

So when you have a non-equilibrium steady state like an arm that's persisting despite being disordered surrounding, this means that the system is exchanging with its environment and its dynamics can be described in terms of its Ness probability density, i.e.

a probability density that does not change during the time over which the system is said to exist.

So over the second to the second timescale, there's a constant measurement on the length of the arm and through time, it could be modeled as something changing.

But in all those cases, it's like definitely not just something that's, there's something different about what that system is doing informationally relative to other systems.

Okay, and then the third kind of quote section here is,

Such a system has a random attractor, which can be thought of in two ways, or another way to say that would be you can think about systems as having a random attractor, which then has multiple downstream consequences.

First, it can be considered as a trajectory of systemic states that evolve through time.

So then, in this sense, the system will, after sufficient time, revisit particular regions of a state space, the attracting set.

So we've talked on the Actim stream before about returning to a desired body temperature.

So it's not that your body returns to the state that it was as a body a week ago, a year ago, 10 years ago.

It's that on that one dimension, with respect to the modeling of the signal and noise of body temperature through time, because you're staying warmer than the background for a persistent amount of time in a way that defies the otherwise dissolving forces of thermodynamics, you can model that like it's doing some sort of strange attractor.

That's what that part is saying.

And then the second part is that you can think about that as not just, you can take a trajectory view, like a single path through that state space, temperature going up in the morning or down in the morning.

But the other way is like when you have a million paths, an infinite number of paths, it's like a density.

And in fact, it's a flow density.

So it's like one traffic you're driving, that's like one car, but then there's the traffic flow.

And so when you switch from a particle modeling to a flow modeling, there's a lot of, it's kind of like discrete versus continuous time, but it's a spatial analog, whether you go particular, like an electron is a particle, electron is a wave.

How do you make that distinction?

And so these are all kind of related topics, but that's what is under the scope of the pulling back to thinking this way.

Anything else?

All right, 27.

The fact that internal states are conditionally independent of external states, given blanket states, allows us to disentangle systems dynamics.

So now we're going to talk about the interfaces between those active interesting systems and their otherwise disordering environments, relatively speaking, or whatever the other side of the interface is.

other words we can write down separate equations of motions for the internal states and active states that only depend on the blanket states so there's a couple things happening here we're going from this active agent model through pearl's work building on bayesian statistics and markov blankets talked about other places other people can have a lot more to say on that

adding as per Mel Andrews's paper, the innovation of Friston, which is the partitioning of blanket states into sensory and action.

So sensory as being defined as inbound and active as being defined as outbound.

And then we're gonna take this sort of like equations of motion, trajectory flow remix,

and think about that kind of a physical depiction of a system with the partitioning between now two flows, like a highway with two directions.

So here was just like landscape flow.

Like the elevation is a flow in one way.

It's kind of just its own flow, the water flow.

But then here we're gonna have two directions in a way.

It's not just up and downhill, but it's like there's a sense flow and an action flow.

So there's information coming in that might have an asymmetry.

And then there might be like a totally disjoint kind of asymmetry with respect to action going out.

So if a robot has a photon sensor,

And then it has a physical actuator.

This is going to allow a total obvious, really simple partitioning.

Yeah, photon come in, actuator go out, generative model, internal.

Maybe I know that fully like a state machine.

Maybe I'm modeling it like the intentional stance.

But by partitioning into sensory input and then the motor, the behavioral, the experimental output,

we're going to be able to kind of like tidy our thought around interfacing with active systems and even inactive systems and then formally that's defined as um being a flow so that's this f is going to be a function of policy which is like the agents you know it is the policy of your arm to be the length it is just like it's the policy of someone to wear the clothes that they wear and then it's going to be over um

there's going to be this is not from the same paper but formally there are ways to define these different states and partition them and it's an area of active research and discussion which formalisms apply over which scope and how well all of these innovations of first ones line up with all the other thoughts in the area anything on markov blankets or this kind of partitioning


SPEAKER_01:
So something I've been thinking about like while you've been talking and just a metaphor that keeps popping up for me is like a ski resort, right?

Like we have the input information coming in and like, depending on your policy, you might select like a black diamond or a blue diamond or a bunny hill, like slope and the flow of people going out.

And then there's like the people that like a high level of surprisal that like want to ski back country and like possibly hit a tree or like there's all of this, like, you know, all of these options.

That's kind of how it's been coming together in my brain.


SPEAKER_00:
Yep.

The ski slope, people have different affordances, different preferences, different risk tolerances, different inclination for nostalgia of a simple one versus the thrill of a new one.

It's like, these are all, it's kind of like what Ryan Smith has been talked about.

Like these are above level of just one repeated task that two people could perform and up.

There's a difference in how they performed.

We're looking at something that's actually internal about those higher order properties.

All right.

Here is where we go from the flow state across an interface.

So we have this bi-directional freeway with the flow that's partitioned.

So we got like signal processing dynamics on the inbound and all the Bayesian statistics that kind of interfaces with all the cybernetics and the policy selection, and then output is behavior.

So that's the bi-directional flow across an interface.

We can...

Okay, let's read this quote and then unpack these equations and read them.

If the probability distribution Q of mu, Q sub mu, is sufficiently similar to the actual conditional distribution P of, I think it might be eta, but I don't know.

It looks like an N. We call it N. Curly N given pi policy.

So P of the actual, we'll just call it actual.

Yeah, actual distribution.

fancy one so if the probability distribution you know q of fancy n is sufficiently similar to the actual conditional distribution p of n given policy so states given policy how things will turn out given how i act over external states how will the external states be given my investing strategy what will stimuli will i see on my website in

under different policy assumptions um then we can approximate that flow so if you're treading water some motor pattern is being enacted that's resulting in treading water it's not accidental so that is self-organization in a dissipating environment and so it's as if a system that's treading water is able to approximate the flow of the actual states

informationally it can stay above water informationally so it has to be doing something like swimming equivalently we can say that the gradient flow of autonomous states can be considered as a gradient flow on variational free energy so now we move from the sort of general computational phrasing or physical computational phrasing of gradient flows into

gradient flows being related to this variational free energy estimate which it turns out is going to allow um very easy like tractable optimization based upon minimizing variational free energy so the phrasing of a gradient flow

was sort of neutral with respect to what you did with it now by porting the gradient flow into gradients of variational free energy it opens up a domain of optimization which is based upon variational base and variational free energy and just to skip to this bottom line um the variational free energy so this thing that it looks as if it's optimizing with respect to policy big f of pi um

uh is just equal and it throws out approximations coefficients it's just like you got to work through it and there's probably a lot of ways to do it but um this free energy value like on policy is related to this expectation of this fancy j which are we do we have that in a later slide

um of basically yeah it's the it is um the self-surprise i think we have in a later slide so um it's the expectation of how surprised you are given about your policies given the states so that's like how surprised are you about where you are that's why it's about yourself surprise about policy given state estimates that value plus

the divergence, which is like a KL divergence, between the state estimate versus the actual flow.

And there's probably a lot to say about these kinds of information theoretic divergences, but it turns out that that is gonna be greater than or equal to

how surprised you are on policy itself.

So almost reading it backwards, it's like how surprised you are to find yourself doing a policy, which is not just an instantaneous action.

A policy is the trajectory.

Like, I can't believe I'm the kind of person who's on the top of Mount Everest.

That is tied up.


SPEAKER_01:
If you've been like, you know, a 700 pound person down to your couch at one point in your life, like, I can't believe I'm on top of Mount Everest would be kind of like, I've taken a policy that I've ran every day and hiked all this stuff.

And now I'm on Mount Everest.


SPEAKER_00:
Yeah.

So, yeah.

So what we really want to know is given a optimistic self.

identity a persisting self-identity now some people get hung up on that they're like what if my self-identity is negative well it'd be equivalent to um the heart or lungs stopping existing it'd be then you wouldn't see that system treading water and that's why it's tragic when it does happen so we want to think about how surprised are individuals with respect to policy this doesn't tell you how to know what to expect or what policies are possible but this is how surprised one is about their own policy

is going to be approximated with an expectation so it's tractable of surprisal of policy given states which is much easier to calculate much easier to say how surprised am i about um how much i've been investing given how much i have rather than computing the total space of everything that could happen which is infinite plus just the details of how far off you are so if you're on the ball then this divergence term is low

and then your the variational free energy is like kind of closer to the idealized minimal surprise and this is something that one does want minimal surprise on because in a dissipating world you get the disorder for free and so this is something that's actually being like asymptotically converged towards


SPEAKER_01:
So something we should maybe clarify.

In the paper, I think that the authors use self-information or surprisal.

They don't really talk about self-surprisal.

And this is kind of like we're conflating now with last week's paper about who is creating the model of the self?

When you have a self-model, who is exactly constructing that self-model?

And I think in terms of this, it's like surprisal over policy

okay but like in relation to your model of yourself or i think your model of yourself is part of like your generative model overall yeah maybe yeah interesting


SPEAKER_00:
Cool, let's go to 29.

All right, so this was... So after thinking about this landscape of flows being operationalized as a variational free energy landscape that we're going to be able to do some kinds of operations on, now there can be sort of dimension play

with mapping states from this is something I would like to ask the authors about is like which connecting which manifolds to which manifolds matter what's the hookup we need which ones are the FEP providing us with because in this quote they connect it to the information geometry and geometry is just the shape of things so it's kind of like the shape of that information landscape

You can think about the physical landscape, or you can say the flow on that landscape of the water if the water fell on it.

And so it's kind of like, okay, information geometry is one thing.

And then this is partitioning with an information geometry angle

according to this Markov blanket active inference partitioning.

So the quote says at the end blue, you can give any thought on it.

Conversely, on this extrinsic manifold, so viewed from the outside,

The internal states minimize variational free energy when conditioned on the blanket states.

In other words, whenever the blanket states change, that could be sense or action, the expected internal state changes and there is movement on the extrinsic manifold that by construction, so is this how things are or how we're constructing them, can be cast as Bayesian belief updating.

This is because the expected internal state encodes probabilistic, i.e.

Bayesian beliefs about external states.

They act as if,

There's an internal state that's encoding and representing, or at least acting as if it encoded or represented actions about external states.

The blanket states here can be construed as the sensory impressions of the external states on the market blanket that contain the internal states.

In short, it may be more useful to consider the system from the point of view of the extrinsic information geometry, the probabilities encoded by internal states like neural firing patterns going out, rather than from the point of view of the intrinsic information geometry.

In other words, the statistical complexity of the neural dynamics considered alone might be misleading.

We might want to actually highlight the neural dynamics

projected onto a manifold of action or with respect to external states because we don't just want that raw time series like doing bitcoin analysis we want to know how that is associated with other patterns in a way that would suggest that it's acting purely responsibly or proactively or in some way that we're going to talk about how you could describe the complexity of it


SPEAKER_01:
I don't really have anything to add.

I thought, but I just was looking back through the paper.

I had thought that it was, you know, mapping from one, the manifold of the internal geometry or like there was a geometry created that was over the whole internal states versus the external states.

And it was that mapping that mattered, but

But yeah, I'm curious to revisit that now.


SPEAKER_00:
So we have a question in the chat, and someone asks, can you say a few words about the islands of awareness?

So that's like with the sensory input is disconnected.

Can you say a few words about islands of awareness and their relationship to the equations you're explaining?

So on this Markov blanket model on 27, if the sensory input were damped,

that would be the islands of awareness model so if nothing else active inference as a process theory that is consistent with the free energy principle is helping us functionally operationally however you want to think about it get at this island of awareness problem so instead of just saying imagine that there was very low or minimal input or no input of sensory state or imagine that somebody could get sensory state but couldn't act or imagine the only sense they could get was hearing and then the only action they could have is this

this is a way that we can think about totally separating the sort of north and southbound traffic with the active and the sensory states being partitioned.

That's the Friston innovation.

And so the island of awareness was from the non-FEP people.

It's probably from a different area.

And so to kind of latch onto that key topic that's being more broadly discussed,

this paper is saying, actually, like, here's the immediate value add of FEP and active inference.

We can actually subsume the debate around islands of awareness, which is something you all already agreed was an important question.

And then we actually have our own way of thinking about islands of awareness.

So maybe if that's a question you care about, maybe this is a good way that you would want to study it because it led us to these interesting conclusions about islands of awareness.

Okay, so...

Okay, so this is unpacking a little bit more about that big F of pi with expectation of the surprise of policy given states plus the divergence of the actual and the estimated states.

So we can look at the quotation.

Here, the divergence between the estimated and actual states describes the statistical complexity of the internal model.

How much do I have to change my mind to accommodate current changes in sensory signals?

So with respect to state estimates about how bright it is, it's like about whether you estimate it to be bright and it is or it isn't.

Whereas this other term, the negative expectation of how surprised one is on the policy given the states, describes the accuracy.

And then this is a parenthetical describing why it's negative.

So minimizing this entails minimizing the difference between these two.

So it's accuracy and accuracy.

model complexity and then it's just you depending on how you have the negatives and the positives you get good points for being accurate but it's a monotonic penalty to be more complex so always better to fit better always better to be simpler and those two lines always intersect

because you can always have a simpler model that does worse, and you can always have a more complex model that does better, if only because it explains some little random feature of the error signal.

So this is not about how the world is, this is about statistical partitionings.

Like a principal component analysis, the principal components are guaranteed to be orthogonal.

Well, there's certain assumptions that get built into here that we don't have to over-interpret with respect to how reality actually is.

note that the accuracy depends on the particular states so the states of the particle the pi the total states now actually confusingly i wonder if this is referring to blanket and internal states instead of policy as usually we use pi to mean


SPEAKER_01:
I had that same question.


SPEAKER_00:
Oh, yeah, yeah.


SPEAKER_01:
Written on my paper.


SPEAKER_00:
Yeah, because, yeah, that's our little icon with the policy pie.

But this one's cool too.

I like the blanket and internal states, but yeah, maybe it could be clarified.

And which one is in here?

Because...

Are we thinking about the minimization on policy alone or on the entire thing?

So let's make sure we're clear on that one.

During a period of partial disconnection from blanket states, such as dreaming, that's the islands of awareness, the variational free energy gradient in the following equation will mainly be driven by the complexity part, which does not depend on the blanket states.

So we have the bidirectional traffic and the flow, and then we're disconnecting sense.

so now it's like the system is just emitting so to speak flow but that is being driven by the um uh divergence term rather than this

including the internal state policy.

We'll figure it out, but this part drops away.

So then, because it's not conditioned on these blanket states, it's only conditioned on the internal model and the actual model.

So this D term is only conditioned on internal and actual states, and this one also includes blanket states.

So you can then do some...

good factorization or mathematics and then the conclusion of that at least um or the form of this equation entails that neural processes can perform the computations required to minimize free energy even when the coupling with the environment is suspended it's like you unplug the computer or something and then it's like it stops but then could you seize sensory input for the brain in a way that actually um

let the brain reveal a different stream of output that would reflect in complex internal dynamics now how will we measure it we'll get to in a second but the idea would be that we could use sleep and dreaming as a model i don't know and think about how the fep could be applied to these islands of awareness and we come to this same result isolated systems will minimize free energy by reducing the complexity of the generative model blue i knew i knew you thought that was interesting what did you like about that


SPEAKER_01:
So I specifically liked the fact that they said, like, when you're sleeping, there's no accuracy, right?

Or like in some island of awareness type of state, you don't have any accuracy because you don't have any sensory input.

And so when in these situations that then you minimize free energy by reducing the complexity of the generative model, I think that that's cool because sleep, just from a neuroscience perspective, background, is really thought to integrate and solidify your experiences.

shuffle things from short-term memory into long-term memory if like they're you know necessary like if it was like a peak emotional experience it'll be like cemented forever but all these things happen like during the sleep phase so it's literally like reducing complexity of the neural correlates of consciousness also which i think is interesting


SPEAKER_00:
Yep, very nicely said.

Like when you're getting sensory data in, there's an imperative to make it match, like to predict what the next word is so that your world doesn't seem like this like blur of just things that are uncertain.

But then when you disconnect the sense, the only imperative, the only reason that was getting complexity pushed up was the need to fit data.

when you don't need to fit the data there can be this radical scaling back in the complexity of the bottle so it's kind of like play or learning or higher dimensional existence or lower dimensional pretty interesting okay so 31. um this is going to be a connection now from that variational free energy landscape to computational research and optimization and machine learning

they're gonna reveal.

Variational free energy minimization in machine learning was predicated on minimizing algorithmic or computational complexity, which is the basis of universal computation.

People can read the citation and have their own thoughts on what it means to be universal or be a computer, but there's the citation.

Here's pretty interesting part.

Consciousness researchers assume

Maybe, unsighted, who does, maybe.

But one could assume complexity has to be large, computational complexity has to be large, yet the imperatives for universal computation in general and the free energy principle in particular say exactly the opposite.

So are we looking for at the simple rules end or at the complex outcomes end?

This apparent paradox can be resolved easily

by noting that free energy is a bound on marginal likelihood, AKA model evidence in the same way that the LZ, which we're gonna get to in a second, complexity is an upper bound on algorithmic complexity.

So they're like, it's not enough to just look at how surprised you are by individual neural states because the brain is never going to repeat an exact state.

So you're going to be infinitely surprised if you use parametric statistics.

You need to actually have a type of statistical inference based upon the dynamics of the trajectories and interpreting them on a flow landscape of information geometry rather than just being infinitely surprised by the specific measurements you get.

And then they basically write that to kind of speak to the islands of awareness idea, it's no surprise then to see that a good model of a complex world will show a high degree of algorithmic or statistical complexity even when observed in temporary isolation.

So this is saying, okay, you unplug the computer, it's gonna radically simplify.

If it was a Bitcoin node, it's disconnected from the internet, it's gonna simplify its processing.

but there might be another kind of system that has a high degree.

Take your empirical question, what high degree or shouldn't they be simpler or wouldn't it simplify it once it's isolated?

But that's the kind of interesting behavior we would expect or be predicting to see from an isolated system.

And just my question for the author was, what does it mean that the free energy is bounding the model evidence in the same way that this information measure, which we're going to get to, of complexity is an upper bound on algorithmic complexity?

I was just very curious.

It's a lot of things I've only heard a little bit about.

So it's just very interesting to think about.

What did this make you think about?


SPEAKER_01:
Well, so I think I put what I thought about this in a few slides away from now.

We'll loop back into that, I think.


SPEAKER_00:
Cool.

So then we're like, okay, what is this LZ complexity?

Because Blue and I both love complexity and met while we were studying complexity a few years ago.

So we were both excited with that.

And this Lempel-Ziv complexity measure was our statistic, however you want to think about it.

was first presented in the article on the complexity of finite sequences in 1976 by two Israeli computer scientists, Lemple and Zipf.

This complexity measure is related to the Kolmogorov complexity, but the only, and that's, so then another one would be the Shannon.

So Shannon is like the surprise with the coin flip.

Kolmogorov is like the algorithmic complexity, usually described as that way.

But the only function that the LZ is going to use is the recursive copy, i.e.

the shallow copy.

The LZ complexity can be used to measure the repetitiveness of binary sequences in text like song, lyrics, or prose.

Fractal dimension estimates of real-world data have also been shown to correlate with LZ complexity.

So it's interesting because learning about it on the wiki page, this is apparently the whole algorithm.

It's kind of just like looking for repeating blocks, blocks with prefixes.

and pointers it's a compression technique so if it was something where if your file was one two three four five you'd imagine that it would take a i i don't even want to say too much because i don't even know what would have a higher low lz complexity i'd like to ask but just like something could be easily zipped or not some things are going to be amenable amenable to lz complexity measures being high or low so that was just my main question is how do we go from this algorithm to like

conscious systems or to measuring real comparing real systems just pretty interesting not sure what to think about that but also really looking forward to the um everyone's perspective in like 16.1 and 2 because it was out of i didn't expect this to come into play as it cool to learn about what do you think about it


SPEAKER_01:
So I looked up like the LZ complexity versus like the Kolmogorov complexity where the Kolmogorov complexity is like total randomness, right?

Like 3.14159, like that's like a totally like Kolmogorov complexity to the max.

But this LZ complexity I think is related to like repetitiveness and sequences and how much they're repeated.

So it's different than the just totally randomness.

I guess that was like my guess.

glint of what I read from that.


SPEAKER_00:
So yeah, if something was just 10 of the same version, you know, transpose on or something concatenated 10 times, you could define it by defining the unit and then 10 pointers, you wouldn't need 100 data points, you need 10 plus 10 pointers.

So like, for example, that would be something compressible related to LZ.

But let's take a step back and ask, okay, even beyond the measure of the

complexity or the entropy measure.

I mean, let's learn and find out what all those are, but what is dynamical complexity?

And this is really related to complex adaptive systems and a lot of the more like non-free energy principle complexity research that we've been learning about blue.

So what is it rather than how it can be measured?

Now, we're not going to fall into a realist trap.

We're not going to say systems are this way, but we're thinking about the kinds of complexity that could be dynamically instantiated and measured.

And this is a paper from...

first in 2019, A, not B, which was the particular physics one.

And in dynamical systems theory, so this is drawing from even before complexity in some ways, like systems theory, three types of complex behavior can be distinguished.

So this is not feedback loops and stuff like that.

Those are the mechanisms by which we're gonna be tracking one particle in the space.

So we've got the particle, the one ping pong ball in the airflow,

That's the particle trajectory model.

And then we have the flow, which is the air that the ping pong ball is being spun around in.

In that sort of vector flow trajectory world, sometimes we see chaotic itinerancy.

So that's like when you have two pieces of wood in the stream, and if it's a lowly operative exponent, they go together for a long time.

If there's a lot of chaoticness, then high chaotic divergence, they diverge rapidly.

hetero clinic cycling.

So this is like cycling with, so repeating to come back to some places, but often with a twist and then switching under multi-stability.

So like you can be like, your brain can be like in a sleep mode and then it can go into the waking mode.

And so, yes, there is a gray zone, but you tend to see like phasic or categorical transitions.

So complex systems do that kind of stuff.

Sometimes they're wild and chaotic itinerancy and wacky, and then they can also cycle and also they can switch.

And sometimes we can even uncouple those ideas.

Like something could switch and the switching could reflect it turning on or off chaotic itinerancy or something like that.

So, and then I just copied out the definitions from the chapter in the Friston book.

What do you think about that?

Or what did that make you think about with respect to complexity?


SPEAKER_01:
Just like the dynamical complexity versus like, you know, what's happening in a computer is like just how things change really over time, right?

So in a dynamical system is a system that's changing, not like how complex is this number that is pi or, you know, 1.0000, right?

So it's just that basic difference.


SPEAKER_00:
Cool.

Okay, let's return to the kind of free energy perspective.

Again, thinking about the dynamical complexity, but we want to be thinking about the complexity of these dynamical systems.

So this is because the computations performed by a system that minimizes variational free energy and inferences, which correspond to movements on the system's extrinsic statistical manifold.

Existing measures of dynamical complexity, however, do not measure complexity in terms of probabilities encoded by neural activity, but in terms of statistical properties of neural activity, that is, properties of the intrinsic statistical manifold.

Hence, dynamical complexity, at least measured by existing approaches, should be associated with NCCs, at least from the point of view of the FEP.

So this is to their point that we want to move from thinking about neural states to neural trajectories and flows

is otherwise we don't get access to this kind of a dynamical complexity measure.

Because if we just think in terms of snapshot states, we're going to think Shannon entropy.

How surprised am I by this neuron being lit instead of unlit at this time slice?

Whereas in the flow model, we can think about the dynamics of trajectories through really high dimensional state spaces.

And that's where FEP suggests an alternative.

An FEP-inspired measure of dynamical complexity would be based on the information length of neurally encoded probability distributions, i.e.

Bayesian beliefs, instead of considering the statistical properties of a neural time series as such.

So that's kind of what I just mentioned.

All right, conscious activity and complexity.

Lou, what would you say about this?


SPEAKER_01:
So this goes back to the LV complexity, really, and also the Kolmogorov complexity.

But I'll just read this quote from the paper.

So it says, to the extent that proposed measures of dynamical complexity have empirical validity as measure of consciousness, which is like...

What is consciousness?

What are we measuring?

How do we just know if it's valid?

I don't know.

All those things are packed into that sentence for me.

They may be regarded as empirically adequate, but it would still be desirable to provide a fundamental justification because this could further support their application to controversial cases like islands of awareness.

In addition, it could help resolve an uncertainty about whether existing measures of dynamic complexity also track algorithmic complexity.

So we know that LZ complexity is not the same as Kolmogorov complexity because it just takes in the repeats, but it doesn't take in all of the different ways that Kolmogorov complexity works.

does.

So here it says it's well known that LZ complexity, for instance, constitutes an upper bound on algorithmic complexity.

However, this entertains the possibility that conscious activity maximizes LZ complexity and related measures of dynamic complexity, but it minimizes algorithmic complexity.

This hypothesis is stated, and there's a citation, Ruffini, 2017.

Finally, developing a measure of dynamical complexity within the FEP could help by providing a computational explanation of consciousness.

So I think that that's a really cool idea.

thing that the authors have brought back around.

Like, can we put dynamic complexity in the FEP framework and thereby, you know, put a computational explanation of consciousness forward?

I think that's really awesome.


SPEAKER_00:
Great points.

okay let's talk a little bit more about a formalism that people love and also just an interesting um i think question about realism and instrumentalism and also just how we think about the definitions of which things are contingent on which so here they're going to write a further assumption we shall make is that the system possesses a markov blanket so

the language of whether it possesses or is um or there just is one and then the system is a secondary description and it describes a little bit more about the blanket and so this was kind of related to earlier but we didn't need this level of depth and it talks about where it's drawn on in terms of developing on pearl and the directed acyclic graphs and generalizations from there

But then here what matters is that the existence of a Markov blanket has subtle profound implications.

So is that the Markov blanket exists in the world?

Or is it that the implications of us modeling with a Markov blanket have profound implications?

So how do we think about whether we're describing how the systems are versus being clear when we think that it's actually not how things are or where they might be congruent?

And so is it, how do we know, and this is related to a general question that people has, how do we pull out these Markov blankets from the empirical data and relate it to the analytical concept?

So again, another slide just from Mel Andrews' paper

uh discussion where we talked about the development of the markov blanket topic from markov's initial framing in analytical mathematics and matrix mathematics to pearl's extension into bayesian statistics and graph theory computational approaches

and then where fristen has developed it over the decades and collaborators and then what is now being um done and learned about with respect to this the post markov blanket whatever it's wanting to be called any markov thoughts yep no cool

um this is related to one of the global challenges that were addressed which is that mapping where does consciousness come into play it's like whoa okay all of this flow and the information theory and the geometry but how are we going to connect this back to the consciousness question and relating anything about the system to the actual um question of what is conscious or not

and so this is the one quote that i want to highlight on 39 is being conscious versus just simulating it and so they um write a system with an unequal room steady state and a markov blanket comprises internal external and blanket states as shown in section 3 such a system can also be described as performing certain computations inferences by virtue of causal relations between internal external and blanket states that is what we were measuring those relation dynamical contingencies

in the equations we talked about by virtue of the causal relations.

This is different for a mirror simulation.

To be sure, a simulating system can perform the same computations, and it will perform them because of causal relations between its parts.

So it is true that the A matrix and the B matrix get multiplied together.

in the program.

However, it will not perform them because of causal relations between its internal external blanket states.

The simulation may instantiate a virtual machine, which may have internal external blanket states such that its internal states encode a probability distribution over external states given blanket states.

But the internal states of the virtual machine will not be the internal states of the physical machine on which the virtual machine is running.

So this is getting into the total virtualization, simulation, everything.

And we're not going to read this dialogue, but on 40, it's a section from a conversation about this topic in the book, The Mind's Eye, which is compiled by Hofstetter and Dennett.

And just, it's about, you're simulating a hurricane.

And, oh, well, programmers aren't claiming the simulation is a hurricane.

It's just simulating parts of a hurricane.

Buildings don't get wet.

And then you have to look at it the right way.

Well, what do you mean look at it the right way?

You know, what is getting wet?

It's your perception.

It just, it's a big area.

So it's fun because it's something that, you know, we're all just...

learning about and again no one has a great measuring device so it's not like we can resolve these debates there's not like an open and shut answer so that's what's so interesting it's like there might be a hot take or a quote you like or something that's inspiring to you about whether computers are conscious or not but in the end it's almost like it's a bottomless pit

So that's why it's good that the authors are actually starting to build bridges across it, I think.

All right, and then a last one slide on reservoir computing.

This was suggested by Sarah.

She was bringing up reservoir computing and researching maybe things that we'll hear about in the coming months, like about how it might relate to active inference.

Reservoir computing is a framework for computation that is sort of generalizing or building upon a neural network model.

and it's mapping the inputs not just to a fixed array of nodes or even multiple layers like a deep neural network or something but the way that these nodes internal to the system the reservoir they can actually be any system

So that could be various types of things.

Could be a slowly changing or a fast changing system or a system with a lot of other structures.

And so just, we don't have answers to this, but bringing up just reservoir computing, Sarah had some thoughts on it.

So we'll look forward to hearing about this and about the niche as a reservoir and computation as happening and where's that put computationalism.

Any thoughts on that before we go to our last bit?

nice yeah chill and these were just some things we brought up but you know people will bring up their own in 16.1 uh and anyone else can bring up uh anything they want us to put on the screen for the author and others but there's so much to think about with this paper they concluded just by writing that

um how can research on neural correlates of consciousness lead to an explanation of consciousness and what role could free energy principle play in this endeavor we have suggested that research on neural correlates should be complemented by research on computational correlates of consciousness in order to yield a computational explanation of consciousness

Moreover, according to free energy principle, neural correlates of consciousness must be defined in terms of neural dynamics, not states, and CCCs should be defined in terms of probabilities encoded by the neural states.

specific claims for those to engage with a lot of um footholds and challenging walls to climb by interesting topics a lot of um things that understanding could enable and we're talking about consciousness and neuroscience so everything is kind of adjacent to it any closing thoughts blue on this very nice discussion


SPEAKER_01:
No, thank you so much for having me.

It's been fun participating.


SPEAKER_00:
Yep, that was great times.

Thanks so much for joining because it makes it a lot more interesting to make and to do.

So we hope to see people in 16.1 and beyond.

Other than that,