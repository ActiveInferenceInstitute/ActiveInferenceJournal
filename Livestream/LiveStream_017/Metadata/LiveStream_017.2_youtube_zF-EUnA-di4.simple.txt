SPEAKER_01:
Hello, welcome to Active Inference Lab and Active Inference Livestream 17.2.

It's March 16th, 2021.

Welcome to the Active Inference Lab, everyone.

We're a participatory online lab that is communicating, learning, and practicing applied active inference.

You can find us at our links on this slide.

This is a recorded and an archived livestream, so please provide us with feedback so that we can be improving on our work.

All backgrounds and perspectives are welcome here, and we'll be following video etiquette for live streams.

At this shortened link, you'll find our calendar for Active Inference live streams for 2021.

And here we are in the follow-up to 17.1 in the same paper, and definitely recommended to check out 17.0 and 17.1 if you haven't, but this will hopefully be a cool discussion either way.

And you can also see the future

live streams cool well today in 17.2 we are going to be just continuing to discuss and learn this really interesting paper and it will be fun to

speak with whoever joins or doesn't for this stream, and also hopefully to get some questions from the live chat.

But we're just going to introduce ourself, go over some general questions, and I think seeing as it's a .2, and we had a lot of the background in .0, and then we had Chris Fields, the author, come on for .1, let's just think about where we can take this fun discussion.

okay so here um especially for our first time participants we can introduce ourselves and just warm up so first we can just introduce ourselves i'm daniel i'm in northern california and i'll pass it to stephen


SPEAKER_04:
Hello there.

I'm Stephen.

I'm in Toronto, Canada.

And, yeah, I'm interested in a number of areas that relate to active inference, particularly those that can inform community-based development and the way that we make meaning in complex contexts.

And I'll pass it over to... Is that Alex there?


SPEAKER_01:
Dean.


SPEAKER_04:
Dean, sorry.


SPEAKER_03:
Hi, I'm Dean.

I don't know how to pass things yet.

I'm pretty new to this.

I'm in Calgary.

So hi, Stephen, in Toronto.

And I decided to step into this because of a reach out that Daniel did on ResearchGate and a follow-up and then the opportunity to look at last week's 17.1

presentation and for about two hours I was completely absorbed in the conversation and thought this is really interesting.

So I took the next step and decided that I would try and integrate myself more with what's going on here.


SPEAKER_01:
Cool.

Well, let's maybe learn more about your perspective as we walk through some of these warm-up questions and just go through at whatever pace we want, just sort of the topics in the paper as well.

So the warm-up questions are, what is something you're excited about today?

What's something you liked or remembered about the paper or also the discussion, 17.01?

And what's something you're wondering about or would like to have resolved?

So maybe since we all listened to it, and hopefully those listening will have too, what was something about 17.1 that sort of stood out in people's mind or something that changed how they thought about active inference or how they thought about something that wasn't active inference?

Yep, Steven.


SPEAKER_04:
Yeah, well, one of the things that was quite interesting was that there are other people

ways of people looking at the math side of it which some of you know the math itself is normally quite a challenging area to get your head around but to realize there's also some other thoughts happening at some foundational level so that um was interesting i didn't know about that particularly um or the extent that was happening so that that was particularly one area and that tied into this idea of

quantum contextuality, which I hadn't heard of actually, and really was very interesting.

Dean, what do you think?


SPEAKER_03:
I guess the biggest thing for me was, and I use terms that may not, you might have to unpack them, but one of the things that I was really interested in listening to was the fact that

The perspective piece and how you, every time you're observing something, the perspective that you hold, you may not be aware of how important that is, but the fact that Chris sort of brought that out again and again, well, that really resonated with me because it's something that I've been working with people for a long time.


SPEAKER_01:
Cool.

So a few thoughts that I had from 17.1 and also what you just said.

So this quantum contextuality, and then the part that was really novel and exciting to me was thinking about quantum, not as just simply about electrons and protons and okay, you got strong force, weak force, electrons, protons, Maxwell's, you know, just throw the regular physics, particle physics or something.

And then it's just equations that have different,

efficacy over different spatial scales that's one presentation of quantum and so then it's like well if you were that size or there's something about uh the system about that specific system or that size of system that makes it quote quantum and this just

expanded the definition of quantum to me to this kind of measurement communication encryption encoding and ultimately also bi-directional meaning and semantic information all the way down so that was a very different way to think about the relationship of like the molecule to the electron orbital it's like it's quantum it's not the way that the electrons would be behaving by themselves but maybe that's not just because they're electrons maybe that's something about structure in general

So that was pretty cool.

And then also you mentioned and Chris did, observation is always coming from a perspective.

And that was something that we talked a lot about with the projective consciousness model from an earlier discussion.

And so that was saying, yes,

you get all these cybernetic functions and all these functional attributes of consciousness from a projective geometry where the observer is at the center at this actual special point and then things are projecting out in a certain way so that's like kind of physical analog it's geometric and then

um stephen you said there was a different sort of math that they were presenting they didn't use projection of geometry this was from like a different branch of the game with the category theory and with these other theories that we just were barely scratching the surface on so that you know what does that mean that those different branches can re uh integrate in a certain way and then potentially not just through an equation but through a process theory

So that was some interesting stuff.

Any other thoughts?

Or I mean, really?


SPEAKER_04:
Yeah, we're just, yeah, go ahead.

No, that's some really, that's really interesting.

I'm just letting it sit because it takes a couple of seconds to land.

But I hear what you're saying.

I like that.

This idea of perspective and this idea, you know, the idea that this quantum idea can be much more across scale.

And he did talk about, I think he called it quantum noise.

There was the use of noise

which then gives a rationale, I think, for how this quantum processes could permeate through everything, even if you don't see quantum transitions in the simple sense, like you said, with electrons and stuff.

This is permeating, and that then comes to that idea of the contextuality, as well as perspective, when we think we take a different perspective in a very...

okay i can see i've moved from here to here and i've taken a perspective but perspective at this kind of phenomenological deep level is kind of happening happening at um

um all scales like the the context is changing um beyond what we can take a perspective on if that makes sense except we use the word perspective because that's what we can get a handle on but it's it's changing in so many ways of which some of which we just can't know so i thought that was really interesting

And maybe that's something that our biology is knowing, but at a deeper level, you know, at maybe these nested levels, there's ways of which that sort of knowing is being harvested, for want of a better term.

So, yeah, thanks.


SPEAKER_01:
The body knowing, which is something we hear about and something you just said, it's almost like, well, if the body knows through action, like the tendon knows to do this because of its biomechanical properties, but that's its...

how the knowledge it's not a turing computer it's not doing some trigonometry but it involves angles but it's because of how it's embodied so that's a it's an it's not the knowledge on a hard drive so that's sort of why some of these information science approaches

are probably on the cutting edge of what information means because we're having to think about how there is information like in the body of the insect that helps it walk, or in the nervous system of the insect, there's some pattern generators, for example, that that's where the knowledge of walking is.

So it can't do every walking pattern,

but it is like this attractor for walking and then that's where the knowledge is but it's not all knowledge and it's not a text file or script that is implemented on how to walk or not even really an algorithm so it's kind of like good and also yeah knowing is on the inference side and then what is the other side of that with action

Interesting stuff, yeah.

Can I ask a question?


SPEAKER_03:
So I sometimes use the frame of prisms and prismatics, and you got energy in, and then you got a rainbow on the other side.

Daniel, are you kind of talking about seeing both at once?

Like knowing what both are doing?

I mean, it's going to go through this triangle, right?

But I mean, just being aware that...

What we see on one side is not necessarily what we see on the other side.

And that doesn't make one more important than the other.

What's important is knowing how things are looking to the person who's got this perspective now.


SPEAKER_01:
Okay, I'll try to address it.

I seem to remember Shauna saying the word prismatic or chromatic or something about... Yeah, I use that all the time.


SPEAKER_03:
Yeah.


SPEAKER_01:
Okay.

It probably has an interesting technical definition.

So it's interesting just that it's like a vivid sensory representation of all the opportunities, all the possibilities, all the colors of the rainbow, and even beyond with the electromagnetic spectrum.

Greetings, blue.

Welcome.

Um, and then there's like, um, yes, the prism focusing different rays of light or just optics, like the rays of light are focusing at the center point.

And then, um, that's where the focus is.

That's where the regime of photons is.

And then that's what enables the function.

Um, greetings blue.

Do you want to say hi and give any, um, thoughts while I just resize some stuff?


SPEAKER_00:
Sure.

Good morning, everyone.

My name is Blue Knight.

I am an independent research consultant based out of New Mexico.

And yeah, this paper was, I don't know, it was like really difficult to work through, I thought, and also really well written for, like, I'm not like one to sit and read like math, lemma this and theorem that, and like, that's always like not my thing.

I mean, I always find it just difficult to digest.

I like to do math as problems, but not read it as like reading material.

But I thought that for like the amount of information that was contained in this paper, it was like really well written and easy to relate to.

I did think that it could have used some additional like practical examples of stuff.

But then like considering the length of the paper, I was like, man, if they like put practical examples for all of these different things, it would have been like a 70 page paper.

So those are my thoughts on the paper.

And it was great having Chris here with us last week to answer all of our questions and definitely something I really enjoyed.

Cool.


SPEAKER_01:
um yeah i wonder if we can keep that question about examples of this in mind as we maybe look through the keywords or look through the roadmap let's just re acquaint with the paper so this is the information flow in context dependent hierarchical bayesian inference by fields and glazebrook one of their papers and collaborations together

And they basically lay out that there's two goals.

They're kind of a twin purpose with this paper.

So one piece is related to what Steven was bringing up earlier with taking this quantum contextuality approach and then generalizing it in a scale-free, AKA multi-scale way, using techniques that are scale-free

apparently, such as two spaces and channel theory.

Although also say like a linear regression is scale free.

There's no a priori scale for a linear regression.

It could be over little things.

It could be over big things.

So in a way, just saying scale free is almost like saying we made it about how the modeler approaches the system so that we didn't get tied down in attributes of the system that we don't want to be

um making scale free and then the second side of this scale free approach to contextuality is they're going to demonstrate a connection between that and a lot

of recent work in bayesian statistics and hierarchical bayesian models which is also where the most direct connection to active inference comes into play because we've also seen hierarchical bayesian models as implementing active inference and then that's being tied to something that's

at a different or a higher level of mathematical generality, which potentially could allow like an active inference model that you'd make for this specific task.

If you make it within that framework, you might be able to lift it out and put it somewhere totally different.

Like you might be able to use it to describe systems and fit parameters or generate data.

That's something that not all models can do, but there's probably other modeling maneuvers that will be possible.

And so it's kind of like if you have Gaussian assumptions, certain things in statistics work really well together.

Like, you know, certain relationships between multiplying things and adding variances.

So this is kind of like a higher level statistical relationship.

And I think that has to do with the commutative...

commuting of the cones or the co cones but who knows um okay on the road map were there any sections that like sprung to mind or anything somebody wants to say on this

All right, let's go to why it matters and think about the examples.

So yeah, Stephen.


SPEAKER_04:
Yeah, okay.

Good point you just made.

I think that the...

that example that was just given actually about the prism, I think it was a good one.

I think that might even itself be something, it could even be a topic of discussion.

I think that opens up things, but it also, it gets some other stuff because one thing that's going on here is,

the Bayesian inference, you're kind of inside the situation that's at play.

And what I think that if we're going to say why this matters, I think it might relate interestingly to a paper that's going to be actually coming up in the next week, which talks about

way that we understand global workspace or theory of the brain and the idea that we have this phenomenological consciousness which is somehow attuned to the flux of sensory data and then we have what we're actually often modeling which is what we're able to consciously be aware of so this flux that's at the you know which sort of starts to get into the markovian monism theories of

of Friston, this seems to sort of give another way to go from the flux up.

Maybe in the way that David Bowden talks about the implicit order of nature.

And I got a message from Tim as well just through saying about to think that we've got this idea of quantum noise and classical noise.

know and you know this non-linear dynamical systems are kind of working with what could be seen as noise or changes in noise so um so i think that that part of the that part of the the story is um

is sort of important across all of active inference in a way, because at some level, there has to be a way to extract meaning from uncertainty.

And so it seems that this gives some other way into that.


SPEAKER_01:
Lou or Dean?

Here's a thought.

OK, go ahead, Dean.


SPEAKER_03:
I was just going to say that.

So back to the perspective thing.

So one of the hardest things that when I was working with people trying to find themselves in new situations was you're either inside of the box or you're outside of it.

And I like the word that Stephen used there, extraction.

Because I think that that, I think what this work does is it maybe enables that extraction piece a little easier.

If people know what you're talking about in terms of stepping back, we have a tendency to step into things and analyze things from an inside out perspective.

And I think how this could potentially work is as a way of gaining

a sense of removal, which is actually advantageous at times.

I mean, if you're looking at something that's complex, it's very difficult sometimes not to get caught up in the moment.

I was speaking just before the live stream started about

Whitewater rafting.

When you're going down the river and you're in a class three rapid, you're thinking about that.

You're not thinking about the perspective of being up on the cliff watching the raft go down the river.

I think this allows people to get outside of that moment.

I think that's one of my hopefully why this matters contributions.


SPEAKER_04:
Stephen?

Well, just sort of with that, I think in some ways I agree with what you're saying, but I would also say what's interesting is maybe it allows you to remove yourself more than we normally can, but also show that actually when you think you're immersed in it, you aren't as immersed as you think you are, right?

Because there's these other levels of immersion which are you're beyond –

your conscious awareness, and there's probably even other levels which are even beyond your phenomenological and biological system's ability to tap into.

So maybe it's both ends, if that makes sense.

You can go further in if the word in is meant that way and further out if the word out is meant that way.


SPEAKER_01:
So on this, why it matters, here's one thought and then anyone else or I could go for a second.

So Steven, when you said extraction, and I know you have a background in chemistry, so that's sort of like it's separating into the different fractions.

So it's not just extracting like, you know, the lithium from the ore.

It's actually like we can have a discussion.

What are the affordances?

What is on the table?

What are we just going to just say is our option space for policy?

And then what are our preferences and what kind of uncertainties are we each bringing to the table from our perspective?

So it is not like we're extracting the essence of the conflict and then we're going to fix the essence or the reduction of the conflict or one dimension of the conflict perceived.

And then that will propagate through the other aspects of the situation.

It's kind of like we're going to come with uncertainty to a minimal model.

And then if one person has one narrative for the policy and somebody else has a different narrative, that's off the table.

So that is a way where people can bring their different

ways of seeing a common model differently like in the quantum measurement case if both people are measuring the quantum particle and they're both fine with it that's one type of experiment steven


SPEAKER_04:
Yeah, I like the point you picked up there on extraction.

It was interesting because that sort of came up so strongly.

And I think the other thing that's interesting is the idea, even in chemistry, there's the idea that still you extract something, right?

It's quite thing-like.

But the idea that you're extracting something from noise, because in chemistry it's normally like basically you calculate everything down and then say what is...

negligible what can you say is beyond concern so you just say it's beyond worries you know it's it's within tolerance so to speak and then you just work within that whereas in this case it's like well all that noise

so to speak, is what we're extracting the information from.

It feels to us like the stuff's out there and we're getting thingness, so to speak, but we're actually getting signals and I suppose extracting enough variational free energy changes in the noise to then perceive it as

you know knowledge but it actually it has to start out as fluctuations in i don't know if the word noise is maybe the wrong word but certainly fluctuations in non-linear dynamics so that's that's that changes a lot of things about how we understand knowing the world


SPEAKER_01:
Interesting.

Here's kind of another point on the signal to noise.

So we're thinking in the Shannon information, AKA Shannon disinfo theory, nothing against it framework.

It's about the telegraph and the wire and getting the exact recapitulation of the signal on one end of the wire as the other end of the wire.

That was the second paragraph of the 1948 paper by Shannon.

We talked about it in the dot zero video.

he said the question of communication is about perfectly reconstituting a signal.

And so in that framework, if you're doing a chemical synthesis and there's one product you want, then you can calculate like the yield of that product.

And then similarly, if there's one thing that you know that you want, you can calculate really exact statistics like information.

And then once you open it up to the semantics, then

The noise has a different perspective, just like you are highlighting here.

I think there's a lot of richness in what you already said.

But yes, noise is richer than just decay in the copper wire because we're not trying to recapitulate anything in the person's mind.

It's not a bitwise transfer through speech.

It's actually like the differences in the way that we speak are conveying meaning.

So it's not just error from some perceived...

um pattern of speech it's like just the meaning that the person is conveying through their action so that i think is also something that really matters when we think about differences in how people are going to be learning or communicating or something like that stephen yeah and that the interesting thing is that


SPEAKER_04:
While to some extent you heat up a liquid or something, it expands and you sort of the energy put in shows itself as the work.

You particularly see, say, when water freezes, that there's this whole question of entropy and how it's somehow tied to some rearrangement, which is not.

shown as work in the system you know that you you try and heat up ice and it hits a point there's something going on there and we can't quite know what it is and it's energy hungry in some instances or energy yielding but um that that process is is beyond our direct

perception.

So you just have to build it in with Gibbs free energy and the entropy and enthalpy terms to see what will happen with reaction.

So that actually then actually ties into Friston's work.

And actually, it's the sort of foundation of his work, in a way.

So I'm not sure how entropy was named in this paper.

I don't think that's directly part of this math.

This is another way to come in without maybe coming in with the word entropy.

But I think it's interesting.

Thanks.

Dean?


SPEAKER_03:
I just, again, just try to draw from examples of when I would talk about this with people.

There's a privilege always given over to gap closing.

Like we want to close the gap.

We want to understand.

We want to find the signal within the noise.

And I think what this does is it sort of gives over a certain amount of credibility, just a gap respecting, just leaving the thingness out of it for a bit so that you can actually take in more information back to what Stephen was and what you're both alluding to.

How do we...

How do we give ourselves, cut ourselves a little bit of slack by saying gap respecting is just as important as gap closing.

And if we give ourselves that, it's a kind of a privilege to do that because it's twice as much effort as just gap closing.

I think the benefits can be really quite profound.


SPEAKER_01:
Nice point.

Thank you.

So Sarah, oh, Stephen, do you have anything to add here?


SPEAKER_04:
Well, just one last point on that is that could then where you start to get into abductive growth based knowing where is maybe we're used to because humans have got this capacity for deductive and rapid exclusion of what's out there and inductive trying to narrow the gap between us and a goal.

But when we're growing, when we think about sometimes I need to just sit back and heal, you know, there's certain situations in the world which I can never process psychologically from a – I can't close the gap on certain things, right?

I just have to sit back and heal, right, because they're hard.

And so that same piece you're talking about there then starts to tap into, well, that's the main game in town for organisms.

Yeah, the game in town of closing gaps is –

is a nice add-on that we have, but it isn't the main game.

Hello?


SPEAKER_00:
So that just brings up to mind like time as a gap closer, right?

Like when you just sit back and heal and ultimately like time as a gap closer, like if you think about like the time value of money and I mean, like time is ultimately the thing that will, you know, close the gap on all prediction.

And like, we don't really see that in the models or in the math at all.

It'd be interesting to see like the temporal dimension and how that plays in or if people have thought about that or, I mean, time, like, can it flow forward and backward?

And I think that was something that was brought up maybe in the last live stream.

That's just interesting.


SPEAKER_03:
Yeah, nice.

Dean?

Just one last thing.

I completely agree with you because, again, the privilege goes on to time on task instead of task or task on time instead of just seeing time in and of itself.

I have this crazy theory that time is learning, not just a way of measuring learning.

And you can't get there unless you can get off that treadmill.

So thank you.

That's a great point.


SPEAKER_01:
And Dean, what you said about learning as time, it's like the difference between Kairos and Kronos.

So Kronos, the chronometer, the decimal time, it's about the wall time, the clock time.

And then action is happening in a space of meaning.

It's time for dinner and that's an action affordance.

And so that is something that's

we can bring in the encultured component, whereas the other approaches, no, the wall time is just simply how it is.

And we're going to, like Procrustes, shrink, expand, use heuristics, use coarse graining to get around this sort of fundamental linearizing from our perspective.

just at the scale we're at, which makes it not scale-free, which is why perhaps quantum only applies to certain so-called spatial levels of what we measure.

Stephen?


SPEAKER_04:
Yeah, sorry, give me a sec.

I had it and then I just went for a sec there, sorry.


SPEAKER_01:
Let me ask Sarah's question, because it's really a nice point in chat.

So Sarah wrote, could we look at ChooseSpace slide and get a broader perspectival view to maximize signal to noise, sort of?

speak.

So maybe I didn't perfectly read it, but I think it was two spaces.

Can we enter into here a little bit and connect that to some of the bigger discussion points and maybe even the other useful points.

So Steven, you want to give a thought or is there anyone who wants to give a thought on the two space piece here?


SPEAKER_04:
Yeah, go ahead.

I'm not sure exactly how, but this gives a way that things can transform from one space to another.

So it gives you that capacity.

I mean, sort of tying this to the idea of time.

And I know this paper is not specific active inference.

With active inference, you know, without time, you're not able to make inferences from time.

noise so to speak or changes in information content in random fluctuations you only get that because you've got time because then you can tell if there's been a fluctuation so one snapshot can't do that now this seems to maybe give a way to okay you've now got a shape of the information space what happens once it has a shape um now but beyond that it's uh i'm not entirely sure


SPEAKER_01:
yeah um blue anything you'd say on this um topic otherwise i think walking through kind of just the way they laid it out and the definitions could be helpful in some of the examples they gave because like steven you you mentioned this morphism right and it seemed like there's the chew space

And that's like a matrix, but one that can be various kinds of things.

It's a matrix, but just like we can represent a network with a matrix.

So we can think about like the space of all the networks, all the social networks of five people.

It's like a five by five matrix and ones and zeros or weighted numbers.

So that's the matrix representation of the network.

and then that is one type of meaning of the matrix but also this can describe probability and it can describe programming languages bayesian networks like if each cell had information about a conditional dependence or not so that's like a chew space is the space of the possible of these things and then this is the part where maybe we'll just

say it's beyond the experience on this conversation but the wikipedia has like understood statically it's a relation and then understood dynamically and then it has another definition so it's like it's interesting it has a static or a dynamic interpretation so i think it's yeah unless anyone in the chat wants to jump in and help or somebody with expertise wants to come on later um

How can we connect that to some of these use cases?

Blue or that on anything else?

Go ahead.


SPEAKER_00:
So I think like the dynamic aspect of the two space and the two morphisms is that like, you know, any...

if you have like a set, a matrix, right?

So if you have a matrix and it's like any series of transformations that can be done to form a new matrix.

So that in my mind is like the dynamism of it all.

Like if I take, you know, set A and I do this, that, this, that, this, that in this specific order.

So again, like here's like the temporal, like we're alluding to like time as a variable or time as a gap closer, but like the temporal sequence is important because, you know, if you do,

you know, if you multiply before you subtract, or if you get your order of operations wrong, it's going to be different, right?

So the temporal order of things is the, the morphism to, to make the next set.

Hmm.


SPEAKER_01:
Thanks for that.

Another interesting sentence is that it's like the true transform or the morphism is a pair.

It kind of comes into existence as two spaces and a mapping between them or a map between them.

And so that is what ties it really broadly to functions and computation and these sort of transformation, transmutation or input output seeming, communication seeming processes, measurement-like processes, because it's about some space and some other space.

And so when we think about the active inference model, and then we have hidden states that inference is being done on, and then we have observations.

and it's almost like there's a matrix that connects the two of them i'm not saying that that's going to be all at this level of chew space but it's kind of like there's a mapping where you can run the model from the sense data to the state and do inference or you can generate from the state likely sensory data so that is a bi-directional it's like a two-way bayesian

machine because it can take in observations and update expectations of hidden state variables or it can generate.

So that generative and receptive element of Bayesian computation is I think just it's like whatever is the topic that includes that and that network matrix and a few other things

that's kind of where this topic can go which is why i think it's a really rich area and that's why the papers are written in 2020 and that's uh yeah stephen and then dean


SPEAKER_04:
I think this idea of moving between spaces is also really valuable because, as you know, I'm very interested in understanding how we can look at awareness and sort of indigeneity is very much about awareness.

And a lot of the active infant work tends to be about whatness.

What's this?

What's that?

How could we understand what this is understood to do and think about?

But when you start to get to this broader idea

understanding of how we can make meaning and taking that idea at a very broad level is the ability to transform between spaces and engage with spaces and that might extend up to our conscious awareness space but some of these spaces are well below the level of consciousness you know down to the level of cells you know but it's it seems to have and play out the importance of

spatial transformation over whatness.

Thank you, Stephen.

Dean?


SPEAKER_03:
Yeah, what I took away from this was that when we discriminate, when we separate, this sort of gives you a sense of why we might do that.

I think of some of the stuff

that we looked at in some of the work that I did, we would ask people to watch something, maybe a YouTube clip, and instead of trying to take all the information in as classically recorded through notes, we'd ask them to

columnize and row in under three headings tools and rules and pools now that was the mnemonic but pools is basically where the gradient is what's aggregating and so we'd ask people to classify

something.

And what people found was something could fit into two categories.

Something could be a tool and a rule.

Sometimes it could go across all three.

It could be a tool and a rule and a pool.

Like there was a way of being able to see relationship.

And I think that's what this two spaces does.

It says,

We can discriminate, we can separate, but sometimes things fit into multiple categories.

And that's something we need to be aware of.

Our minds are able to sort of pull apart and then reorganize.

That's what I took away from that.


SPEAKER_01:
Nice, very nice, Dean.

And I think that's sort of reflected by this cone and potentially even your prism topic, because it's like, yes, there's a unity of C in this case, but it is going to be manifest in these different spaces.

And this is a really informative slide.

So it's talking again about these pair of two spaces that are related through a transform.

The transform A to B can, and this is from section, or example two seven in the paper, the transform A to B in this case can be viewed as transporting the information encoded in valid flow formulas from A to B and can thus be thought of informally as a channel from A to B

implicitly providing a sense of spatial and or temporal separation between A and B. So I thought like, there's the maps of meaning.

And so there's my internal map, just so to speak, just using it instrumentally.

And then there's person B. And then if we're playing 20 questions, it's like, okay, is the house bigger or smaller than a bread box?

There's some semantic mapping internal to me, and then there's a channel with the sense data.

And then there's a semantic flow related to whether they're going to give me a yes, no, which is like Chris said, that's quanta, because we're quantizing the response.

Is it bigger or not?

We're making a measurement of the response.

They could be lying or they could be wrong or they could, you know, we couldn't hear them or something, but it's a binary question.

and then there's a semantic flow and then there's a back and forth potentially otherwise you're talking about different things and so if somebody is thinking maybe i was thinking of a little toy house smaller than a bread box so if you have a different frame of reference then even the communication is not going to work because the holograph is going to be read too differently by the people even with the same information

So that's like the separation of cognition across participants in a conversation.

And then that's happening implicitly through time.

But then it seems like also things can be just more abstractly described as being separated through time.

And so something that's separated in time but not in space is like memory.

which is where this whole discussion of memory comes into play.

Because it's a communication through time at that spot, like a time capsule.

It's like 50-year message.

Now, you can debate whether the absolute position of the time capsule is the same, but it's like relative to it, it's a message through time.


SPEAKER_00:
So it's funny that you bring up a time capsule.

Like I've been really thinking about, you know, at scale carrying information forward and backward, like from, you know, cells to person to like a group of people.

And, and it's like, you know, when we, what do we,

carry forward and when we like used to make time capsules like every 10 years I don't know if we still do but then we would dig them up and like you know dig them up every 20 or 30 years or whatever and like what do we put into a time capsule and does that like effectively capture like the culture of the society at that time like a cd or like you know these different things that go into the time capsules like this is actually like what we're carrying forward and sometimes it's like dumb stuff like

I don't know, it's just funny to think about what goes forward in time and why that and how the selection process works and if it's a systemic or generalized thing or I don't know, it's just something that I've been thinking about how that is transmitted across time.


SPEAKER_01:
Great question and very prescient, of course, with so much digital information and a potentially fluctuating cost of storage, wildly cheap, but then wildly expensive.

And that could lead to some very unfortunate information flows.

Evolution has sort of an answer to that, which is like what's passed forward is what is fit to its niche.

Not biggest bench press, strongest fittest, but fit to the niche, adapt, skilled to the niche.

So we don't need to go too semantic on that, but I think the term actually does fit.

And where evolution by natural selection

as well as active inference come into play is by formalizing a process theory

you kind of step away, or at least you can maybe get some distance or some modelability of these complex processes.

So in evolution, the process theory is basically you have heritable variation in phenotype that's found in a population where there's heritable variation in fitness.

And if those are all linked up in the right way, at least locally, that's the way that the phenotype and the population moves.

And so active inference, it's similar, but kind of like with information, just saying, okay, sense data comes in, action goes out from the generative model into the niche, back into the sense, something happens with the generative model, it integrates the information, engages in policy.

So it's like if somebody listens to a lecture and they only write the notes of five sentences, and then they pass that off,

The process theory explained why there was an information bottleneck there, because we just modeled the situation and we don't need to go into, oh, it's tragic, there was only five sentences, or there was more than, you know, it was five deep sentences though, or something like that.

We just say what it was that was the actual transmission.

And then that is a starting point for the kinds of value-oriented analyses that you might want to do afterwards.

Dean?


SPEAKER_03:
Yeah, I'm just curious what other people's thinking is on this, because

Typically, between the inference and the model, not necessarily the people here, but oftentimes what's parked in between those two things is a plan.

And what you just described is not a plan.

So I'm curious what other people think is between the inference and the model.

I have my ideas, but because I'm trying to get to know you folks, I'd like to know what you guys think is between the inference and the model.

Stephen?


SPEAKER_04:
Yeah, well, that's a $6 million question.

I think that the introduction of the quantum approach at certain scales does yield something very plausible.

And Chris's work with Mike Levin would tie into that because he does a lot of work with bioelectrics on cells, membranes.

So I could see...

that this question where it's more directly attributed to quantum fluctuations and what that means, you know, at the level of the cell and then the bioelectrical or the chemical electrics or the bioelectrics of the membrane.

And then the next level that I can kind of see it more plausible is brainwaves, you know, and you've got this overlap.

Now, maybe there's some quantum effect.

but then in between that i i'm it's probably more action is more classical in terms of how you pick things up it's literally like i just keep doing it and in a very rough and ready way i extract some sense of how it is to pick up an apple or something you know and i'm inferring things in a more classical way so there's i think there's a mixture of a classical and not only past partially knowable

set of information transfer, and maybe some more quantifiable stuff, which maybe is, I don't know if it gives you more accuracy at that level, but might be more quantum like, but I'm not, that's, that's my thoughts.


SPEAKER_01:
um okay uh so just to dean the question was what's in between the model and the inference okay is that what you asked yeah so let's just kind of go into that so what by model you mean the actual code as you wrote it on the computer or the actual systems diagram like the model you mean what's on the computer or what's on the paper is that what you mean that's probably

That's the product of the model.

And then the inference is the computation that the model does, or is the inference how we then look at that model and then decide how we should do policy?


SPEAKER_03:
Because- Yeah, it's literally in, it's moment by moment.

It's the smallest of timeframes relative to the,

the end game or the end product.

How do people, typically they put a plan in between those two bookends.

That's how they parameterize.

And so what I'm curious is what other people think actually is in there, because I know we see a plan, or we're given a plan, but I'm not sure that that's exactly what's going on.

So I was just curious what other people thought is going on.


SPEAKER_01:
Lou?


SPEAKER_00:
I'm not sure that I'm also understanding the question.

So there's the generative model and the predictive model.

So there's these two models.

And so the generative model is the model that you have.

Daniel would probably have a better way to say that.

And then the predictive model is, in my mind, that's the plan.

I predict that...

If I invest in crypto, I will have 10% more money at the end of the year or whatever, right?

Like, so that's my prediction.

That's my predictive model.

That's my plan.

So in my mind, those two things are synonymous, but maybe Daniel can clarify or speak to that.

in a better way.


SPEAKER_01:
Thank you, Blue.

I think I tried to just take what you wrote, annotate it a little bit.

The internal states is a generative model of the niche, and that includes the agent's action in the niche.

Like, I can see myself going on a walk every morning.

That's like a combination of a trajectory of action

and affordances and a niche and other regularities and other availabilities shoes or something like that and then there's the actual generative process and the generative process is like the part that is the play and also where cybernetics theories like the quote good regulator theorem

come into play because the cybernetics is like well you have to be effective you have to have all the variables in your um environment but then we can look at for example um alternate understandings of astronomy and there might be evolutionarily adequate different understandings of astronomy that allow individuals to deal with the regularities in their environments

for the niche that they're in, given their affordances.

But the sort of realism take would be that it's the same moon and sun.

Look at the chart, the Fibonacci spiral, all these things you can do, but it's about the narrative of policy

under that generative model, the niche, but it's the same market.


SPEAKER_04:
It gives me an ability to act in a surprised way as opposed to using surprise all, which is this kind of metric which I can kind of use both in my retina and my nerves and everything is this kind of general awareness of how much of a variation is applied.

But surprise and something can happen to me once.

and I make big decisions on that.

And that is sort of basically sitting on top of all this activity.

Sort of need to know as an animal because, and there's a great presentation on this and I can't, where at one point in history, basically we have to add in who into our environment.

So up to then, it was just like how.


SPEAKER_03:
Sometimes things fit multiple categories.

So how do we explain that with a plan?

No, because that's fluid.

That's just dependent upon how you're looking at it.

And sometimes you'll talk to the person beside you and say, do you see what I see?

Which, Dan, you've already pointed that out a couple of times in this conversation.

So I'm just trying to figure out what's in there.

I think it's more than a plan.

And I'd hate to default just to that or over-reduce just to that because I think that's part of the problem when we're trying to figure this stuff out.


SPEAKER_01:
Thanks, Dean and Luke.


SPEAKER_00:
So definitely there is a who, and I think that that really loops us back around to the point of this Fields and Glazebrook paper, that there's this intrinsic contextuality.

And so you can't really effectively model contextuality

unless it's you can remove the intrinsic component right like so when you can you when you can remove the the subjective aspects like i mean we had a conversation i don't remember if it was last week or two weeks ago about like at a dinner party like how was the food did you have a good time like or not did you have like how was the food was it fun and so all of this is like you know there's no objective

answer to these questions it's going to be different for all the 15 people that were at the dinner party right like some person liked the food some person had fun one person didn't one person you know thought the food was cold or didn't like the dessert or whatever right there's the subjective experience so it's really difficult to separate the who from contextuality nice questions and uh answer steven


SPEAKER_04:
yeah this is very this is very important actually what you're saying i mean i think this also ties into this idea of what it means when we do planning and also how we think of planning and start to extrapolate that so generally speaking in the

in the everyday sense of planning, we have like some sort of shared something in the niche.

Like we have a plan.

We often make plans.

If not, it's somehow there in some verbal semantic thing, which isn't just in our head.

It is in the niche.

It's sort of in this semantic niche.

But the idea, for instance, of how does my body know the plan for getting on a streetcar, right, when the doors open?

I know how to do that.

And it's not.

But that kind of plan has to come from somewhere and it's much more there.

You know, I mean, so they get all merged together.

But the and that maybe is partly in our niche in the way that we have the right sort of shoes on.

We we set up the design, you know, because we have some control.

but then even when you get into other areas of the niche okay i come across a particular cliff in a mountain and i i'm you know i'm not from the modern world so i haven't got all the technology right but you can reinterpret the past right you can do it yeah that's a not within our affordances


SPEAKER_01:
We can only infer on certain things, but we have causal agency.

And actually in the SPM textbook, there are some integrals that are like from all of the time series together, just like sort of mashes all of time together.

And there's other ones that are calculated like up to that moment in a sliding window.

And then it says, that's what makes it causal is we've restricted the analysis to only the previous states.

that's kind of how mathematically causality is defined as is like, well, if it's lagged in time or if you slide a window as the arrow of time changes, but then that's not the same thing as the arrow of time or the experience of time or anything like that.

Yep, but then this local logic slide was just to say that, and to also continue this discussion on contextuality, it's the local settings.

So where does this matter and how does this expand the discussion and hopefully lead to more powerful models is if you're not playing with the local rules,

then you're not playing the game.

And so you're going to semantically lose against nature if there's organization in a way that attempts to violate local logic.

Like if there's some equivalence between heat and computation in our current understanding,

and you design a machine that just violates those rules, like you don't plan to dissipate a certain amount of heat given how much computation, it's like you're not designing within the rules of the system.

You're just making a poor computer.

And so we're talking about communication though and information transfer that's meaningful.

So what are the local logics for communication?

What are the local logics that are shared by people who speak the same language versus all languages versus all ages and things like that?

What's the shared context that lets us communicate what we need or how we should act together?

else what would be a fun slide to go to or just topic to go to it mentions ergodicity there that might just be interesting to see his take on that yeah you know blue do you remember but um i feel like ergodicity wasn't

We can look actually in the paper itself.

Let's just see if it's used.

There we go.

Not used in the paper itself, but we put it in there for some reason.

Partially related to these, kind of what we're talking about now in a way.

Like as you're bringing up, it's relevant of a term, but yeah.


SPEAKER_04:
It might be, there's a question about, it raises that question because it's such a big part of active inference.

How those...

two things relate because it seems to be able to get at some of the questions without the need necessarily for ergodicity in the same way, but maybe I'm not reading into it.

But I've got a feeling that it may not require it because you have these spaces that maybe have inherent ways of obtaining knowledge or information.

between these different types of morphological transformations?


SPEAKER_01:
Okay, I think here is where we asked it.

So this is the quote in the paper.

They're talking about contextuality by default.

And they say, the criterion effectively generalizes the intrinsic contextuality of quantum theory, so the one that we know of with the wave and the particle and the entanglement, spooky action stuff, to the case in which other properties of a context, e.g.

the order in which questions are asked, also affect the distribution of a variable of interest.

So it's like 20 questions.

if you go down one branch first, it's going to be like a bifurcation with a question and communication is like a bifurcation.

Whereas in the telegraph, in the Shannon info theory, it's like if a signal is garbled,

and it doesn't come through, it's a lost transmission.

But semantically, it might ruin the file.

But at the level of the message, it just wasn't transmitted accurately.

So it bifurcates the meaning of the file, but from a signal to noise, it didn't have a categorical bifurcation.

Maybe only one bit in a million was actually flipped, and that was just a stochastic thing.

But when we think about semantic information flow, the order in which the information flows, especially in a dialectical or in an ecological context, is like the whole topic.

Information flow is improvised or at the very least it's engaging.

So it's not just letters on the page recapitulated, but it's something informational.

Stephen?


SPEAKER_04:
Yeah, that that that's important.

And that ties into the idea of how much there's like with Shannon entropy or there's the idea of a signal, there's something in the signal and you're losing some of it.

Now, with Kristen's work, it's the idea that it's all nonlinear and you need the action.

so that you can compare the way that the signal changes are happening to infer something from the noise, let's speak.

You need the action, but in this case, it's like there's another way to sort of say there's an inherent

something out there so to speak there's sort of something in the signal um it's not just only the action needed which is probably why then this can be applied to bayesian inference and not only active inference because they're saying there's something inherent you don't only need the action and you're getting it because of the order in which the questions are asked um and that order

actually that's interesting then that that isn't often how i've thought of contextuality i just think about contextuality is where am i you know what i mean and what's happening but what order did what happened happen give me something is new yep when are we and when were we there all those questions blue


SPEAKER_00:
So I have a comment on ergodicity, but can you back up to the cone-cocoon diagram?

Because I think that this is why we brought it up.

Yes.

So here in this cone-cocoon diagram, the one on the top, right?

So you see this information channel C, right?

That relates all of these classifiers, A1, A2.

All the classifiers are linked to this diagram.

core information channel.

And that kind of doesn't really imply like a distributed system.

It applies like a centralized control.

But we brought up ergodicity because if you look down in the second picture here from C to D, there's this commutative property that is, or I guess it's even in the top picture.

So it's the Gs, right?

The commutative aspect of the cone-cocoon diagram.

And so I think that that's where the ergodicity comes.

came into this paper, right?

Like the fact that all properties are available to all points in the cone cocoon.


SPEAKER_01:
cool and also you know these topics can go expand beyond the narrow and the technical but let's think about a technical definition of sampling ergodicity so not taking on all the um experiential elements per se but a remember is a classifier so it's a chew space scarlet letter a that's what's being represented with the

And it itself is a classifier because when we were talking about the choose spaces, there was like, it could be the types of a computer language and then what their descriptions are.

So this is like cats are small, you know, horses are big.

This is my classifier, you know, big and small and then horse and cat.

And then just which one's big, which one is small.

So it's a choose space informally.

And then here is a different classifier.

choose space A2 at a different time.

Maybe it's time point two.

Maybe it's person two.

Maybe it's all the people.

So here's me, A sub K, all the K people or all the K moments.

And whether it's one person through time, if you ask the question, you get the same quantized response.

Yes, the cat is smaller than the horse because cat's small, horse big.

If you always get that response back semantically, then you're sampling from ergodicity with respect to that question.

So it's a big topic with like what it means in physics and everything like that.

But just from a sampling perspective, if there's K people in the room and you sample an all 100 of them, or every time you sample 70 out of 100 give you an answer, that's the sampling ergodicity.

And then here are C and D, which are like two observers and they're kind of co-sampling, but they can only see the raw data.

So they're able to see all, just what we were getting at with the top part, just like this is like sampling across informally population or through time.

And then it's ergodic if there is a stationarity there.

Here, that is the same scenario, but now there's two observers.

And then if they are related in this very specific way,

then it opens up a lot of connections semantically between c and d also sarah added in the chat that salience is a time dependent phenomena

And that's extremely true.

So everything that we talk about with attention and salience and surprise, those are like almost explicitly time bound processes.

And even in machine learning, when people talk about, oh, it's a neural network with attention or with recurrence, they're kind of talking about a time element.

but anything where it's not just a snapshot that moves state to state, but there's something that's captured across time steps and that's called attention sometimes.

So it's kind of like, it's actually a similar way to how it's used in a modeling framework here.

This was one question that we had in .zero and beyond, and hopefully got to ask Chris a little bit, but like,

what are examples or how can we, what's the next question to ask or what's the next system to explore this way?

That was one set of questions.

Also, if anyone in live chat has any questions, we can definitely look at those.

What else would be interesting?

I mean, there's a few more slides that we haven't looked at that we could kind of


SPEAKER_04:
explore so maybe one element here is oh yeah go ahead steven sorry well just just once he talked about and maybe this is something he brought up as a as a slightly new advancement he talked about separability

separability as a sort of, he positioned that sort of center stage during his slides when he did his introduction as maybe a way to, I don't know, think about contextuality in a more tractable way.

Yeah, I wondered if that was, you know, was that, how did that come up?

Was that something, oh, that's interesting.

Was that a little bit surprising that he, when he did that,


SPEAKER_01:
Yeah, great question and point.

So I just searched in the document.

There's two spots where it's mentioned.

They write, we have previously shown how inference can be represented using the formulism of this paper, employing only the quantum theory of separable systems and the thermodynamics of measurement interactions.

So there's the citation to Fields and Glazebrook to explore that more.

But I think

what we're talking about here is an interesting part that is related to two spaces it is often the case that two spaces may be separable or other types but let's just focus on the separable element

um i.e both separable so it could be separable it's almost like you could have another choose space you know which two spaces a through z are separable or not so there's separables equality and then it says separable means all rows are distinct extensional means all columns are distinct so actually the transform that goes between them is probably the transpose the t in r

then if it's separable on columns and you transpose it it's separable on rows so that's like a relationship that's kind of a high level but it's maintained when you transform it back and forth like blue is saying add subtract add subtract you can transpose the matrix back and forth um

So separable meaning the rows are distinct.

So let's just think about the case of the chew space as a descriptor, just which was one of the ways that they used it.

So like the types of processes kind of.

So if it's separable, it's like they're distinguishable types.

Sometimes that's also called a full rank matrix where it's like every row and column matters uniquely and informationally.

there's no doubled rows where you could condense the matrix by saying, actually, there's five of this row, or this row is a linear combination of this other row.

Stephen?


SPEAKER_04:
Yeah, this is good to bring it back here because this is sort of the applications of it.

And the separability, I think there's more that can be looked at with this over time.

I think this is obviously something that's going to be

quite applicable and it also relates to you know this idea of self-organization and planned organization so you you know how much are things um uh able to to to to infer things because of the um the separability um that in itself um maybe changes what's possible um


SPEAKER_01:
yeah actually here's a quote we haven't looked at this is really interesting though in working set theoretically so with this sort of set approach to choose spaces there's considerable scope for the choice of arguments in the choose space as well as the choice of the corresponding relation r because we get to choose the spaces and the map so we can you know map from various things to various things different ways

And so what kinds of things can we do?

Probabilistic, in particular, conditional relationships.

So that's like all of computation and stats, Bayesian.

Fuzzy type relationships.

Fuzzy logic, fuzzy math.

Spatial observations.

Object identification and merological reasoning.

This isn't a paper to look into.

That means parts and wholes, how they're related to each other.

And dual process theories of cognition.

So that's bringing it to the cognitive neuro and to even the neuroscientific.

Numerous examples are discussed in the paper, and they are.

It's a double paper, but it's very informative.

And so all these kinds of things are kind of what is adjacencies for the Chu space.

Dean, and then anyone else.

Dave, if you have any thoughts after Dean.

Otherwise, no worries.


SPEAKER_03:
Could you go back to that cocon thing again?

That diagram?

Yeah, that one there, the bottom one, it's interesting because when I read, looked at that in the paper, it took me back to some stuff I did about that diamond shape and how that symbolically relates to opening up, which you mentioned, Daniel, and self-organization, which Stephen mentioned.

We see that when we see a diamond shape.

designating a high occupancy vehicle lane and the sort of way that that frees you up as long as you meet a minima in terms of the number of people in your in your vehicle and we used to talk about that idea of how these spaces are there even though you may not be necessarily noticing that um

Yeah, even if we don't formally look at it that way, there's all sorts of examples around us of when that's actually occurring.

So I just thought I'd point that out.

You may not necessarily do those kind of associations, but again, if you're trying to bring this kind of information to people and go, well, here's an example of where we're actually doing this stuff.

We may not be aware of it, but it's going on.


SPEAKER_02:
this that's as soon as i saw that that's what kind of made me smile cool thanks for that association there dave this is not addressing any specific point but uh gregory bates and a number of times observed the cyberneticians getting stuck by talking about random inputs random inputs he says look stop thinking about random i want you to think about noise

We're now going to talk about organization from noise.

And I think part of the point is noise is more clearly relative to your values and your plans.


SPEAKER_01:
Yes, very nice.

And also affordances, which are semantic.

Like even years ago when I was learning about Shannon information theory, I thought I can be symbolically surprised by the characters on a page, but if I don't speak the language, who's to say whether the information is really there.

So there has to be something else here that's helping address the situations that are meaningful or not, because it's not just about how rare the character is.

in a world where just one word can mean a lot at the right time, in the right context.

Stephen?


SPEAKER_04:
Yeah, the idea that you're

you need to constrain at certain times or separate.

I mean, I suppose in a funny way, the car lane example is quite interesting.

You've got the movement of traffic, and at some point, the high-occupancy vehicle lane becomes different in terms of what's on it.

As long as you can enforce a rule...

and communicate it and enforce it.

And that kind of idea that you can create separability.

Otherwise, and maybe that sort of principle of there's some constraints implicitly out there, I suppose, on what things are going to do with each other, I suppose.

just like the way water behaves in certain contexts at certain scales within our gravitational field.

But there's also, and I'm not sure how, if I'm over extrapolating, but how

Biologically, in different ways, there has to be some point where you have to impose a separability.

You might need to form an organ from cells to be able to do the next thing, to create insulin or something.

It's not just enough to have some insulin cells dotted all around the body.

You need to have a pancreas.

So there needs to be that constraint


SPEAKER_01:
know so that you're in the high occupancy lane and that's what's happening so it's um you're in the high insulin producing cell type and then at a bigger level you're in the high insulin producing organ sub component in the organ and so it's this nesting and there's um uh maybe even extraction of function using what you were talking about earlier so then sarah wrote in the chat also about the uh

definition of the chew space is here saying that this is another way in which the ergodicity is going to come into play because uh sarah writes separable is saying that the event space for a given time frame cannot be compressed i'm not sure if that implies the aggregate matrix itself cannot be compressed reduced in some way and then here this this bi-extensional collapse

So if you can't collapse the rows and you can't collapse the columns and you can transform it, and that still is gonna be like true, it's just like, it's informationally rich, then any repetitions in the rows of objects and columns of attributes are factored out.

And also the reason why attributes are at, time is an attribute.

If you think about the object as existing through time, just like you could measure the color every inch of the ruler,

you could measure the length of the ruler at every measurement in 10 time points.

In practice, this removes unnecessary repetitions in the content of information, hence minimizes the amount of processing required by a given algorithm.

So if you do a hundred measurements,

of exactly one meter, because the time was unique, that's still 100 measurements.

So the classical approach would be like, well, sounds like we got an answer.

I mean, look at the p-value, it's one meter.

But then here, when we retain this rich contextuality, we actually don't pool, even though we were sampling from ergodicity of length, we don't need to pool all of those measurements together in the same way, perhaps.

And so that is definitely related to Sarah's point that this matrix, the rows or the columns can be thought of as being temporal.

So when we think about the matrix having structure on like a top to bottom or left to right way, that can represent structure in time.

Like, just like you have an eigenvector, you could have an eigenvalue through time.

Stephen?


SPEAKER_04:
So if I'm understanding you, you could have...

a relatively small number of observation types, but build out a space because over time, the time variable gives you the ability to make that into some sort of space, some sort of topological space.

It's not just a space of different measurements of different things.

It's sort of certain things over time.

Is that right?


SPEAKER_01:
Yep.

Here's an example that kind of came to mind.

It relates to insect vision.

So a lot of times people think about insect vision like, oh, they must see like a bunch of versions of the world.

But then we think, okay, well, we have two eyes and we see one version of the world.

So it's probably a little more integrated than buggy.

Okay.

Putting that aside, what's the resolution of the bug's sight?

And it turns out that there's some insects that only have like one ommatidia cone.

So it's like kind of like a one pixel camera.

It's like almost light dark.

So you would think.

And if it were on the wall, all it could do is inference light dark in the room.

But because the insect has a body, is a body, it can move.

So even if it's just light dark or gradients of...

it's getting like a bit string.

We can think about continuous variables or just a zero one.

And so can a bit string encode information that's rich?

Like, yes, like sports casting of a sports ball game and say, now they're running from the 30 and they're at the 20.

There's a person and they're at the 10.

And so that's a bit string, but it conveys action and context.

So they don't need to take the 4K video in order to know whether to run or walk.

And that's actually really related to Carl Friston's wood lice example, which he claims is the origins of some of the free energy principle kind of.

any other slides we want to go to, or we can just look at the last ones.

Otherwise, I think it's been a great conversation.

And it was definitely a educational paper and several weeks like for the lab, we're always happy to have new participants, such as yourself, Dean.

So thanks a lot for joining.

And

Yeah, this was an interesting set of discussions.

Also, thanks a lot, Sarah, for helping on and Blue for .0 for 17 because that was kind of like how we started the conversation in a way that helped us structure it because there's a lot to get lost in here.

Blue, what do you think?

And then Dean.


SPEAKER_00:
So you're on the Markov blanket side.

Can you go back to it?

Yep.

so i was really thinking about like i have this note in the paper so hold on let me find it so in like you know when we have this markov blanket it's like the things that we're not privy to the information that we like don't necessarily know about right and so

We make a decision.

We have all of the information that we need to make a decision.

But I was thinking, in a system where the Markov blanket is too big, if there's too many things under the Markov blanket that we don't have access to, how does that impact our...

um, like ability to act within the constraints of the system.

So like here it's where they talk about the frame problem, right?

Like, so we're, we're, um, you know, you, you kind of can't solve a problem until it's been solved already until you know how to solve the problem.

Like you can't determine the answer.

And I think that that's like the, the gist of the frame problem.

Feel free to like elaborate or, or correct me on that.

But, um,

You know, I think that that's like one of the things that is so difficult about a problem like climate change.

Right.

Like so we can't solve the problem like climate change because we don't know how many factors are potentially influencing.

Like we don't necessarily have the entire context for climate.

the climate change situation.

So I know what I'm doing.

I know what my carbon output is.

And I can research the companies that I buy products from, et cetera.

But I don't know what all of the other 9 billion agents in the world are doing.

And so we can't make predictions based on our actions.

So is the Markov blanket too big in that situation to be able to solve the problem?

Because we're not able to see directly the outcome of our actions or even the actions of our group of people that are in our network.

I was thinking about that.


SPEAKER_01:
Very interesting.

Dean, and then Dave.


SPEAKER_03:
Just a couple of things.

First of all, thank you for being so welcoming.

I really appreciate that.

And the second thing is that

When I watched last week's broadcast, because I watched it on YouTube, I felt like I was a spectator.

And now that I've been a participant, but I've been a participant of a debriefing exercise.

So I've actually been a participant of something that's been separated out from what originally happened.

And I think that this paper...

This is real time, what this paper was discussing.

So if you want to, I don't know if you could find a better example of where that idea of what perspective is and what potentially prismatics are, even if we're not talking about them, we're still playing by their rules.

Again, thank you for allowing me to be one of the people in the tile today.

I just really, really appreciate that.


SPEAKER_01:
Cool.

And it's like the paper is the tent pole in some ways because it's actually North star or the reference point, but we're giving our perspective on it, but we shouldn't be disagreeing about what the paper is or says.

We're looking at the same slides, but then the richness is actually everyone's understanding and contribution, just wherever it is coming from, whenever it's coming from there, because what else could that context provide Dave?


SPEAKER_02:
Yeah, I don't,

want to go too far off track, but I noticed the paper references Donald Hoffman.

And I don't want to do an injustice to the good doctor.

It may be that I see him stepping into it when he didn't really with his one video about

The interface is anywhere you want it to be.

It doesn't make any difference.

The interface is totally arbitrary.

Maybe that's just his billions and billions moment.

But did Donald Hoffman go down the rabbit hole a couple of years ago, or is he still doing good, solid work that I can read and not get my inexpert self thrown down a rabbit hole?


SPEAKER_01:
can't speak to uh the body of work don't know it that much but just i pulled up the citation from the fields and glazebrook paper it's a 2015 paper the interface theory of perception and so the way that they that fields and glazebrook use it in the paper is basically to um actually in a way that's related uh to the interfaces it says equivalently an interface and that's the citation so the markov blanket here is being

connected to their approach.

So it's kind of probably a yes and it probably is great insights about the interface and then it probably does matter where it is or what it is or how it's modeled.

So yeah, nice point though, Stephen.


SPEAKER_04:
Yeah, good observation there.

I mean, there's probably a, you know, there's a reason why Chris Fields has got involved in Active Influence because

let's be honest, from my understanding or my observations over the last 30, 40 years, consciousness and physicists have kind of run the show around consciousness.

And there's been more and more

sort of big claims about, you know, consciousness, which is great.

And this is seen as, you know, and there's a thing called the Mindels that do the process-orientated psychology.

And some good work, but I always used to, like, have a bit of a sigh when quantum got mentioned because I knew that it was going to be, like,

Even though I knew physics, I just felt, and maybe I was wrong, but I just felt it was being used in a very transpersonal, slightly hand-wavy way.

But maybe that, and now we actually bring it into like, it's not all about the physics, it's about the biology.

which is kind of like taking the physics area down a peg or two.

Although now, Kristen could say it takes it up a peg or two because it's all based on physics.

It depends which way you want to look at it.

But interesting world.

Let's put it like that.

Thanks.


SPEAKER_01:
Yep.

And this quote, this is the authors.

They're saying that this Markov blanket concept, which is map the interface and all these other ideas like communication channels,

it's doing a double role in these models which is that it's where free energy is minimized so it's sort of what is going into the function that's getting minimized if you're you might be reducing your water usage but what's going into your actual function that's deciding your policy that's what's getting minimized and then something else might also be affected but what's getting minimized are the blanket states

and it is that epistemic barrier that's keeping context what isn't directly measured that information is hidden from the observer so

There's probably a bunch of questions about this and a lot to say about it, but one big question that I have is, we know from previous papers that one of Fristian's innovations was to separate, separability perhaps, separate the blanket states into outgoing action states and incoming sense states.

Now it's possible that there are certain kinds of models that play nice in the sort of undirected Bayesian conditional relationship, neutral,

way because it's sort of like a built-in bi-directional road it's sort of like cars going both ways in the same lane but when we really make that separation clear and we really have some states that have an asymmetrical relationship and other states that have an asymmetrical relationship

It could be simpler.

It could be more difficult.

So there might be new relationships that are enabled by the separation.

There might be relationships that are put off for now because it complicates it in a different way.

So I don't know what those would be, but those are just like what could happen when you split the states.

Or maybe nothing happens and it's already been dealt with.

But yeah.

And then Sarah's perpetual slide on the reservoir computing.

We had a little, oh, the next steps were just from their words.

They had three areas of next steps.

Kind of, we'll go through this, then we'll kind of give anyone else give a last thought.

But here's the areas where they're taking it next or where they want to signal for everyone to take it next.

So one is exploring intrinsic contextuality in humans.

It's like short and sweet, apply it to humans.

So we're asking about applied active inference, about what is the applications of this paper?

They are asking that too.

They don't need to go into any more detail.

The second question is about how context switching is implemented neurocognitively.

So like you're talking to two people and you're bilingual and they say something in one language and the other person says something in a different language, but semantically you might not even be aware of that.

difference it might just be associated with that person's voice or with the situation so how is that happening in the brain or in the body or different animals and then the third question their broader question so this is the real you know that's the speculative no the third question is whether that intrinsic contextuality can be detected and characterized

at multiple scales in complex systems so this is where it's kind of getting to the collective intelligence or distributed computational systems like what if there were a signal that we thought were uninformative but it were actually reflective of this just immense

wisdom or processing power cognitive uh dimension so we might think that we're communicating with all intelligent life when we send out the golden you know phonograph with the etching of the fibonacci sequence or a tetrahedra or our body or something like that but there could be a whole dimension of information that's just at a resolution we're not even perceiving so that would be big of course how would we detect that a priori with minimal

scale and system dependent assumptions, which are equivalent to throwing out the noise and the signal together in this way of thinking.

Well, it would be great to learn more about these topics.

I hope that we can continue to just have experts on, have

all learners and participants on because it's kind of fun, especially when we're talking about stuff like this.

So any last?

Yep, Steven.

You're muted, Steven.


SPEAKER_04:
Just mention you've got a couple of other, you know, the next couple of events that are coming up, just so that people know if they're interested that you're going to be talking with, we're going to be doing the other live stream.


SPEAKER_01:
Ah, yes.

Let's look at the calendar.

Yep.

So we will.

Yep.

We'll have 18 in the coming two weeks.

on the Predictive Global Neuronal Workspace with Ryan Smith and Christopher White, hopefully joining for March 23rd and 30th, but then also March 18th.

In two days, we'll have Demetrius Bolas.

So yeah, that will be pretty cool.

Thanks, everyone, for participating.

Great discussion.

So fun times.

Bye.