"Speaker Name","Start Time","End Time","Transcript"
"Speaker 1","00;00;01;26","00;00;02;04","No."
"Speaker 2","00;00;07;01","00;00;41;08","All right. Hello, everyone, and welcome to Active Flab Live stream number 24.2. Today is June 29th 2021. And we're looking forward to this follow up or jump off discussion with some of the authors as well as other lab participants. On this awesome paper. An Empirical Evaluation of Active Inference in Multi Arm Bandits. Welcome to the Active Inference Lab. We are a participatory online lab that is communicating, learning and practicing applied active inference."
"Speaker 2","00;00;41;23","00;01;10;25","You can find out more about us at the links on this slide. This is a recorded in an archived live stream, so please provide us with feedback so that we can be improving on our work all backgrounds and perspectives are welcome here and we'll be following good video etiquette for live streams. It's great that there's so many on the call and I'm sure we'll have many questions and opportunities to raise our hand as well as for those in the live chat to ask questions whenever they feel like it."
"Speaker 2","00;01;12;07","00;01;38;10","We're closing out June with this dot to discussion on paper number 24. So last week we also spoke with Sara and Dmitri and others. That was very informative and now we're in the dot to we're able to take it to a few different places and raise up a few questions that were asked over the last week. And the goal is really just to learn and discuss this paper and related topics."
"Speaker 2","00;01;38;10","00;02;01;09","We have a few cool related areas that we're going to be going into. So we can just begin with a introduction round. Each person can say hello or check in, say anything that they're thinking about today, and then pass it to somebody who hasn't spoken yet. So I'm Daniel. I'm a postdoc in California and all pass it first to Blue."
"Speaker 3","00;02;05;00","00;02;08;04","Hi, I'm Blue. I am an independent research."
"Speaker 4","00;02;08;04","00;02;19;22","Consultant based out of New Mexico, and I will pass it to Ryan Hi. I'm Ryan Smith. I'm an investigator at the Lauren Institute for Brain Research."
"Speaker 3","00;02;21;06","00;02;35;14","And so hi, I'm Sarah, and I'm a person at the Technical University in Arizona. And I'm looking forward to the discussions today. And I want to do IRA."
"Speaker 1","00;02;35;17","00;02;58;29","I'm Dimitri Markowitz, postdoc at Technical University and also chair of neuroimaging. And I best to they've can be topic selection no Douglas my background's basic psych and cybernetic learning and I'll pass this to Steven please."
"Speaker 4","00;03;00;12","00;03;15;04","Hello, I'm Steven. I'm based in Toronto. I'm doing a practice based around social topographies and immersive experiences, and I think I'll pass it back to Daniel, if I'm not mistaken."
"Speaker 2","00;03;15;25","00;03;33;11","Yep. Great. Thanks for the cool intro round. So Sarah prepared this slide which we just want to start off with, so go for it. Sarah, how does this set the intention in the mood for what we're going to be going into today?"
"Speaker 3","00;03;34;18","00;04;16;02","With How can I make it so that I see it again? OK, so after the discussion last week and also the questions we've got, we thought it would be a good idea to just make a short overview slide about what we understand as active inference and as cognitive neuroscientists you said in the discussion feel. So we are open on mainly interested in this action perceptual loop that an agent where we as living agents are in with our environment and that's what you see on the right in this loop."
"Speaker 3","00;04;16;02","00;04;44;14","And on the left side, on the right you see the environment and they have hidden states that on the states that you may know from Markov decision processes, processes and reinforcement learning. But that may also be more abstract things that aren't observable to an agent like context, volatility parameters, anything that describes the environment in these hidden states may also evolve with time."
"Speaker 3","00;04;45;07","00;05;24;03","And then such an environment generates an observation that the agent then integrates together with its prior beliefs in order to infer the hidden states of the environment, which is what we call perception. Then you can use this information to plan ahead and select an action accordingly. And in turn, the action may change in the environment. The interesting and concretely how the agent side of this works in inference is so that you specify a probabilistic generative model that contains the hidden states."
"Speaker 3","00;05;25;01","00;05;59;03","You are a priori knowledge on your assumptions about how these hidden states relate to each other, which states may follow up on which states and so on. It contains observation generation rules, it content actions or policies which and act of inference are also treated as hidden variables that need to be inferred. And additionally, the generative model may contain its own parameters and a random variable so that they can be inferred and therewith learned."
"Speaker 3","00;06;00;15","00;06;46;10","Then you specify time and probability distribution of approximate beliefs. In theory, you could also serve the beliefs of the generative model analytically, but that becomes very computationally expensive really quickly or even analytically intractable. So what you do instead is formulate these approximate beliefs which are supposed to be of a simpler form. And for example, in your approximate beliefs you could assume that all hidden variables are independent random variables, which makes the beliefs very easy to calculate but may not properly capture the temporal dynamics, for example, of your environment."
"Speaker 3","00;06;47;23","00;07;15;14","And this this independent assumption is also called the Milford Approximation. But you could also say no with some hidden variables. It's very important that they are allowed to call vary and be dependent on each other. And then you would have pairwise dependencies in these approximately. So just think about the better approximation you may have different approximations for different variables."
"Speaker 3","00;07;15;14","00;07;18;17","Some may vary together, others are independent."
"Speaker 3","00;07;20;19","00;08;03;10","Then you plug in the generative model and through approximate beliefs into the free energy, and then you find your approximate beliefs at the minimum of this free energy. And this way you can form about beliefs about hidden state of the environment. It's really can be anything your location and volatility of the environment, the context in you infer beliefs about policies, which is the probability distribution or the actions from which you can then choose, and you can even form beliefs about parameters of the model and then with obtained your knowledge of the model and its timestamp."
"Speaker 3","00;08;05;01","00;08;42;20","And then in the end you can use all this and for knowledge to make it. And you know, it's cognitive neuroscientists are often interested in this whole group but were demolished last week is also that in principle this can be really modular, right? So in our paper, for example, perception versus same for all different agents, we're estimating then in different action selection algorithms, one corresponding to the expected for energy and active inference."
"Speaker 3","00;08;42;20","00;09;08;18","But other than on action selection algorithm two. So yeah, you can really also play around with this framework and use its modular nature. You could, on the other hand, use the same action selection algorithm and compare different learning algorithms, which is something we're also often interested about in our work. And with that, that's it for me for now."
"Speaker 2","00;09;11;04","00;09;34;24","Ooh, very interesting. And anyone can raise their hands, but I think the part that spoke to me there was just that it's a framework and so it's kind of like the framework of a desktop computer. You can take out the memory or change out the hard drive. And so we can talk about changing the environment or dynamics with respect to the hidden states and how they evolve through time."
"Speaker 2","00;09;35;01","00;10;02;17","We can talk about changing perception, but we can also like walk in multiple of the components and then explore how different learning rules influence system behavior. That's what we explored in this multi our bandit paper, but it could be the same learning and policy selection rule, but then a different perception rule. And then those might map on to very subtle differences in decision making of agents that we care about."
"Speaker 2","00;10;02;17","00;10;21;28","Like what's the difference between somebody who has blurry vision but they know the language versus clear vision? But then there semantically unsure about what the symbols are representing setting. Yeah. Steven and then anyone else who raises their hand yeah."
"Speaker 4","00;10;21;28","00;10;54;22","This is really interesting. It's helpful to see your thinking here. I would just be curious how actions states or you know, the idea of different types of states alongside these hidden states and just how you treat those in your thinking because they could be kind of the action states that are imagined and the action states which are part of the kind of external environment that you're somehow immersed in."
"Speaker 3","00;10;57;03","00;11;27;23","So in the end, yeah. And actions are also treated as hidden there, but I think they're very separate from the from the hidden states for example, because the space of actions determines what an agent can choose. You cannot choose a state in terms of other hidden variables. I think. So, for example, if I think location versus context, then in my head the generative model becomes a hierarchical model instantly."
"Speaker 3","00;11;28;21","00;11;48;21","And in the end, yeah, that's also what I meant when I said, you plug in your a priori knowledge or your assumptions about the environment because different types of hidden states have different relationships to each other. Then you really end up with a completely different generative little."
"Speaker 2","00;11;50;20","00;12;01;14","Just to follow up there. So you said that when location and context are differentiated that it's a hierarchical model. So what does that look like on this layout?"
"Speaker 3","00;12;04;05","00;12;06;06","You mean in this figure here."
"Speaker 2","00;12;06;19","00;12;16;14","Like what's the setting where location and context are identical? And so it's a non hierarchical model versus a case where they are differentiated and then it is a hierarchical model."
"Speaker 3","00;12;17;11","00;12;48;02","So for example, if I want to model myself working through my flat, that wouldn't be a hierarchical model where just its location, maybe the different drawing rooms, counties and states that I infer based upon the curtains I see, for example. But then if I want to introduce another person's flat then the transition dynamics may be different for their flat."
"Speaker 3","00;12;48;02","00;13;13;21","So for example, in my flat I can go from the living room into the kitchen, but in my friend's friend, I cannot make this transition. And that's actually something I'm working with currently where an agent the underlying decision process is very similar, that an agent needs to infer which context he's in in order to then know the correct transition dynamics."
"Speaker 2","00;13;16;06","00;13;43;07","That reminds me of the SPM textbook, how it talks about hidden states being just the state that a process is in that generates outcomes. So we have a clear distinction between the hidden stage, which aren't directly observed, but there is this hidden state like which flat am I in? And then that is going to change the transition dynamics between the rooms."
"Speaker 2","00;13;43;13","00;14;02;07","But the observations are what are coming to the agent. And then also there's like learning which we don't have here, but that would reflect the prior beliefs being updated through time what about this planning stage? Like what is happening in this planning module?"
"Speaker 3","00;14;04;27","00;14;32;01","And that's a good question actually nowadays. And so this figures from my previous paper nowadays I learned in perception and planning together because it's really not that is inseparable. The so in this case what I meant is perception is really inferring past up into the current hidden state and to which I had the observations that belong to each sense."
"Speaker 3","00;14;32;15","00;14;54;09","Whereas planning is inferring future hidden states and future observations and potentially future reports. But in the end, it's all one model and it's a chain to go through the state. So that differentiation on the next medium since I think it's rather one inference problem."
"Speaker 2","00;14;55;18","00;14;58;19","Interesting. Thanks. Blue then anyone else."
"Speaker 3","00;15;00;29","00;15;06;18","So just thinking about metacognition and where that might fit into this."
"Speaker 4","00;15;07;10","00;15;07;22","Model."
"Speaker 3","00;15;11;28","00;15;19;01","Actually has some has produced a paper on metacognition recently also."
"Speaker 1","00;15;19;01","00;15;51;02","So I'm not a control actually. Right, but, but yeah, I mean one can just see one can stack multiple agents on top of each other and imagine this a kind of higher level agent controlling what the bottom level agent is doing. And so this would be like, well, the active inference models and in one of the recent papers, we're also exploring this in the kind of some meta control approach for describing like cognitive control."
"Speaker 3","00;15;52;16","00;15;57;22","So if there's some kind of downward causation, does that then inhibit what's going on at the."
"Speaker 4","00;15;58;02","00;15;59;17","Lower agent level?"
"Speaker 1","00;16;01;00","00;16;34;25","Yeah. So basically the consistent actions on the higher level are defining for us on the lower level and selecting the policy space, right? So what kind of your lower level, lower level agent can actually do what it's like? This is now just kind of illustration of kind of separating maybe higher level cognition from the executive power to just kind of moving arms or muscles."
"Speaker 2","00;16;34;25","00;17;25;24","Something about it's it's interesting about that, like kind of like a virtual machine or a hypervisor that there's this like emulated agents you know, what would my better self do? That's a classic metacognition question. And then also it was just interesting that, you know, blue, you asked about metacognition and then Dmitry, you are right to matter control. And so that really speaks to the way in which we're thinking about cognition as control and that's part of a control theoretic perspective, which is that like the cognition planning as inference, the cognition is about action selection but then one piece that differs potentially is in active inference relative to just sort of the way that control theory"
"Speaker 2","00;17;25;24","00;17;52;10","is often discussed is the insight of perceptual control theory, which is that the planning as inference is being done in service of the expected observations. And so we're planning and acting in order to control our perceptions. And that's happening as part of this integrated loop. So it's kind of cool that there's like this like good regulator theorem in terms of cybernetics."
"Speaker 2","00;17;52;18","00;18;15;00","And then it is like there actually is an emulated regulator agents and then, yeah, pretty cool where does that play in with like art thought does that I don't know, what does that relate to our actual experience of thought or does this happen all at the sub personal scale."
"Speaker 1","00;18;19;27","00;18;45;02","Well, I mean that's just how I view it. It's really like a problem of separating different timescales and certain uncertainty associated with different time scale. I mean, what you can do now and for example in the next couple of seconds is very different from what you can do in the next couple of months and potentially or long term goals and plans have an impact on what you're doing currently."
"Speaker 1","00;18;46;09","00;19;20;03","And there needs to be a way how to resolve this uncertainty on different levels. Of representation and right from active inference. One solution for that is just like use fact agents on top of each other, which just representing increasingly longer timescales interesting. So and I mean, as each agent I mean we can see it though, right? That's a little it's something which is separated from an environment with the macro blanket."
"Speaker 1","00;19;20;03","00;19;48;06","So basically through the actions and the observations it's making, I mean, you can also separate the brain in multiple nested blankets, right, where one part of the brain just deforms and sends information to other part and that's signals, it's actions. So and I mean, we know just from experimental research, welcome, this is hierarchical structure. So in both temporal and spatial hierarchies."
"Speaker 2","00;19;50;01","00;19;55;15","Thanks symmetry Steven. And then anyone else yeah."
"Speaker 4","00;19;55;15","00;20;40;03","Would I be correct in between perception and planning, you've kind of got this more conscious belief awareness being sort of available and the prior beliefs, once you get from around the observations to perceptions, might be below consciousness in the sense that might be part of the visual system or whatever. And I was just wondering how you see that transition from, you know, below awareness to phenomenological consciousness at play now with the types of models I know sometimes like Wayne Smith uses some semi Markov room processes which start with some, you know, self-reports about beliefs."
"Speaker 4","00;20;40;03","00;20;57;08","So it's working at a level which is kind of building on top of the dynamics that might be going on in the kind of biology. So I was just wondering how you see those different dynamics playing out and where you fit your models with some other models. If they were sort of like play with each other."
"Speaker 3","00;21;01;16","00;21;45;09","If I may say so. I think this relates back to Dimitri's statement about the hierarchy of timescales because if it's like my conscience, find us on a slower time scale, for example, then my visual perception is and I think the, you know, make conscious son is maybe rather responsible for the slower timescales where it helps me to narrate through the slow Markov decision process where as it would be not useful if I have to critically think about any inference and make on merit in an image, for example."
"Speaker 2","00;21;47;27","00;22;20;09","It's interesting you said there that the conscious thought it narrates because first off, we've talked about narrative and active inference, but also just like you described how there was this hidden state of which flat I'm in. And then that sets the transition probability of the rooms. Maybe you have a narrative that sets up like which policies you're transitioning between like in baseball, you know, there's a story to the alternation of the innings and then it's like OK, we're going to be enacting this policy because we're in this phase."
"Speaker 2","00;22;20;24","00;22;53;08","And so there's like a higher level narrative that helps connect when policy transitions might be plausible to be adaptive. And then that is almost by definition at a slower timescale than the play by play, because the play by play is going to be a lot more like motor control, the ice skating. And then as you slow down, you get slower transition dynamics that are more and more narrative in nature because they narrate like different phases of action."
"Speaker 2","00;22;53;08","00;22;55;08","But then the sub actions are very rapid."
"Speaker 3","00;22;57;27","00;23;26;23","And really in a sense it doesn't so do with a level of abstraction, right? Especially if it's just a leaf. It has a very concrete meaning in terms of, you know, physical environment where as my study program, for example, it's something a lot more abstract that is a lot harder to grasp with odd abstract states that you maybe need a narrative for more."
"Speaker 4","00;23;29;13","00;23;29;21","To."
"Speaker 2","00;23;32;00","00;23;33;22","Write than anyone else."
"Speaker 4","00;23;36;09","00;24;01;22","Oh, I mean, I was just going to say, I mean, you know, like when we went through my own Christmas paper on consciousness a couple of months ago or whatever, I mean, this question about how conscious of conscious processes relate to active inference, really any related navigational model is is a complicated one in part because what consciousness, what the word consciousness is used to mean can be different in different contexts."
"Speaker 4","00;24;02;25","00;24;33;25","You know, I don't personally think that yeah. I mean, the question of what processes are conscious or unconscious in and of themselves doesn't really fall directly for massive inference, right? All we're doing is modeling things at different timescales and their relationships to one another, you know, I mean, in, in the model of, you know, visual consciousness, you know, in the paper that we published a few months ago, you know, the idea was very similar to what other people were saying, you know, which is this idea about different time scales."
"Speaker 4","00;24;34;26","00;25;02;03","But but here, I mean, the idea the idea was something more like you have a particular level and a hierarchy that operates over a sufficiently long timescale that you can do the kind of goal directed things that consciousness allows, including generating remote reports, which themselves are very kind of extended, you know, integrated policies, but that, you know, but that also requires that it integrates information from enough different local sources."
"Speaker 4","00;25;02;21","00;25;27;05","Right. To do that. But beyond that, you know, talking about consciousness as itself this floor timescale process and also I think, you know, we're all sort of subtle because what a lot of people in consciousness you know, has to do with the kind of subjective character of the kind of like moment to moment, you know, phenomenological aspects of experience."
"Speaker 4","00;25;27;18","00;25;54;09","And that's clearly not happening on a slow timescale, right? So those moment to moment changes in conscious perceptual experience are fast, you know, so what what we're doing in this kind of higher narrative level, but I think you're talking about is something about, you know, integrating evidence for those over time and, you know, using them to come up with you know, certain sorts of longer timescale policies for a certain sort of longer term social policies."
"Speaker 4","00;25;55;17","00;26;24;27","And, you know, so the way that, you know, we've talked about it previously is just that, you know, you have you can have this sort of depending on the precision of the interactions between the first and the second level. In a model. If that precision is lower than the lower level, then to a certain extent this kind of operate semi-autonomous way in which case the higher level doesn't really need to have all that much influence or know that much about what's going on at the lower level."
"Speaker 4","00;26;25;22","00;27;10;14","So you probably have as a kind of selection process where the precision gets turned up or down at different times in four different states. So the second level kind of selectively become aware of and start integrating evidence with respect to certain lower level processes, which simultaneously allows this kind of top down control over those first level processes. You know, so so perceptual phenomenology stuff, it's probably more about the moment to moment updates between lower level perceptual processes and these higher levels or grand scale processes when the perceiving is sufficient for those updates to the second level to matter but anyway, I mean that's more long winded that I'm on it to be, but mainly just"
"Speaker 4","00;27;10;14","00;27;19;01","trying to point out that it's, it's subtle and it means a lot and it depends a lot on what you mean by consciousness and it's not specific to active inference necessarily."
"Speaker 2","00;27;21;04","00;27;21;20","Nice."
"Speaker 1","00;27;22;04","00;27;30;23","Great. I think the difficulty in talking about consciousness is I don't, I mean we don't know what the, what it is doing right?"
"Speaker 1","00;27;33;01","00;27;42;06","What kind of problem is consciousness solving and what would be like a hyper intelligent organism without the conscious."
"Speaker 4","00;27;43;06","00;28;18;26","Yeah, I mean, I think there are definitely there are definitely number of ideas in the literature. It's not, you know, it's not like it's completely pinned down, right? I mean, like there are things, for instance, like requiring memory maintenance, right? Like, like extended working memory maintenance beyond a specific timescale. Looks like it can't happen unconsciously. Listen for experiments, any kind of like multi-step mental processes, like, for instance, like you can go unconscious priming effects or people can do something like two plus two, but you can't them but they can't unconsciously do two plus two -4, right?"
"Speaker 4","00;28;18;26","00;28;34;23","So anything that requires holding this kind of intermediate result in mind to do a further operation on it is something that at least thus far, nobody's able to do an experiment to, you know, that people can do that unconsciously. Whereas, you know."
"Speaker 1","00;28;34;23","00;28;51;27","Put into Ryan would think that consciousness is like 01 state. I mean, from that perspective, I mean, right. For example, Julia at the Ngoni, right. Kind of sees this as a continuum. Like consciousness is really a continuum of states where you can just have higher levels and lower levels of consciousness."
"Speaker 4","00;28;52;07","00;29;27;14","Well, so again, I mean, this this gets back to what what you're using consciousness to mean, right? So in consciousness refers as a distinction between levels of consciousness and content of consciousness. Now, like content of consciousness is I think most people agree is fairly binary. I'm actually not totally sure what what the Iot crowd would say. And look back at look back at some of the more recent stuff there but but in terms of neuroscience, you know, it's it's it's very well characterized."
"Speaker 4","00;29;27;14","00;29;53;18","We're like ignition events that are that are nonlinear all or you know, sorts of processes where if something becomes conscious, you get this global non-linear, this kind of broad activation widely across lines, field networks, whereas in the event you don't pass this like ignition threshold, then you still get a local perceptual like local activation in, let's say, visual effects for vision or whatever sensory cortex."
"Speaker 4","00;29;54;27","00;30;17;13","But you don't get but it's just kind of linear and it doesn't kind of percolate up or process threshold to process large scale more hour long kind of thing where the where the information becomes kind of broadly accessible throughout the rest of the system. So that that aspect, I think has a fairly binary character to it that's different than this kind of levels of consciousness."
"Speaker 4","00;30;17;26","00;30;45;13","And if you look at something kind of like the being in a predisposition to represent conscious contents, which would kind of be like a continuum from say like coma to like a world awareness and that that probably just has to do with kind of like the state of cortical processing that allows for the kind of dynamics that support this kind of all or none the stuff that allows for selective contents."
"Speaker 4","00;30;46;10","00;30;54;28","But anyway, I mean, all of this is going pretty far afield from Chroma active inference in as this paper now. So I don't want to detracted."
"Speaker 2","00;30;55;27","00;31;30;21","It's fun stuff and it's important. So we'll go to a more applied question then following this kind of round on an applied question, we're going to go into a few code walk slash talk thrus as well as learn a little bit about a few approximations and some of other work by zero. So Lars asked us a question on Twitter, which anyone is always welcome to do and wrote, I would love to hear any thoughts on how this work on the multi armband."
"Speaker 2","00;31;30;21","00;31;57;22","It might be related to real world problem spaces for applications. How might active improvements in multi arm bandit tasks translate to improving how some problems or decisions are currently solved? We talked a little bit about this in zero and one, but all go to any of the authors for a first take and then everyone else is welcome to give any thoughts or like ask a follow up question."
"Speaker 2","00;31;59;05","00;32;06;12","So when you present the work and somebody just goes to this kind of obvious applied active inference question, what is your thought."
"Speaker 1","00;32;08;22","00;33;05;01","Well, I mean, as I said, would multi and benefits are applied to a super wide range of real world applications? So I opened a survey like a survey on practical applications of multi armed bandits and contextual bandits on the bonus block. And I wish you'd in addition Jalal Bonhoeffer of. Right. So this is like one of the recent surveys so found 2019 on our hope and they here their list for example couple of domains where they are applied health care finance dynamic pricing recommender system Maxim Maximization, dialog system, telecommunications anomaly detection and I mean just by looking from that, I would first try things out with active inference based bandits in kind of non stationary"
"Speaker 1","00;33;05;08","00;34;03;01","problems and this is from what they see dynamic pricing and recommender system they're kind of in this domain but obviously about one cannot imagine that right telecommunication systems would also be a non stationary problem and it's kind of searching for the fastest routing path and similar where different routes can change over time and then you have constantly right to explore different channels for passing along the information more optimally and right this is a kind of practical domains where one could first try to move the active inference based methods and as I said, in on stationary kind of problems, which is most of the other things I listed, this is a bit more difficult for us"
"Speaker 1","00;34;03;01","00;34;20;27","to see if there is a way to deal with this kind of simple asymptotic badness in talking big data. And basically all our optimistic information such Awesome."
"Speaker 2","00;34;20;27","00;34;27;24","Sara, any thoughts on that or anyone else Stephen."
"Speaker 4","00;34;29;29","00;34;37;15","Could you just repeat that last bit? You said something about some topic behavior or some type of behavior. I didn't quite."
"Speaker 1","00;34;38;00","00;35;14;19","Asymptotic, right? So this is like in, in stationary bandwidth. People are interested in the asymptotic behavior after like in infinite many actions, so to say. And how to how a different algorithm scaled there, whether they converge to a good solution or not. And I mean, this is what we find in the right in the stationary problem. Active inference is too optimistic in the way it converges both solution to fast as the way we defined it at this and that's why it doesn't have a good asymptotic behavior."
"Speaker 1","00;35;14;19","00;35;41;25","So if you would apply to non stationary problem when you would like with hi probability to find a good solution. I mean active inference algorithm is not one to go for the applet. Again, we have some ideas how to change this, but I mean, just based on expected free energy, this is not something which behaves nicely."
"Speaker 4","00;35;42;26","00;35;48;17","So you almost have to do like a hack on it to keep bringing it back away from any two."
"Speaker 1","00;35;48;18","00;36;19;28","Or yeah, exactly. Kind of just gets stuck prematurely into a, into a solution which the, the agent believes it's a good one. And the reason for this one can see immediately just from this from the term which drives the exploration, which is this let's just expect that information gain in reinforcement learning. This is called quote, exploration bonus or something like this and that this doesn't increase with time."
"Speaker 1","00;36;20;27","00;36;51;24","So in a way, all these previous algorithms like upper confidence bonus to be in reinforcement learning based algorithms, they have a bond which increases with time. So if you are not sampling from one arm, this band becomes bigger. So your algorithm is kind of forced to switch at some point. And this is not happening here. So right at either one will need a different generative model or a different way to introduce more randomness into the behavior."
"Speaker 2","00;36;52;25","00;37;24;20","One aspect of it was figure one or know figure. Figure two in the paper was that that on the top left there that the variance across active inference agents was increasing. So it wasn't that like every instance was slightly degrading in performance. It was actually that a small subset where you wrote there, a small percentage of the ensemble did not find the accurate solution and were overconfident in their estimate."
"Speaker 2","00;37;25;03","00;37;56;10","So it it does suggest a few ways in which maybe, you know, when the variance of a few parallel instances of active inference starts diverging, that could be like a warning sign that some of them are getting too confident, too early. And then also is interesting how you explored that the learning rate or lambda through time and just kind of said that, OK, there's no simple answer here, but it's an area of future work for sure."
"Speaker 1","00;37;56;21","00;38;28;27","Yeah. I mean, the problem with like parallel grants and in practical applications, you don't have that so they say and that advantages to like simulations. I can just run I mean any number of simulations, just see how it behaves rather than practice. When you're solving the problem, you just get one trajectory and then you have to kind of provide an insurance that this sample or this sequence of actions will behave better than random or better than that."
"Speaker 1","00;38;29;08","00;39;00;24","There is some probability to converge over over a long or long run. And this is something which you don't get right with redacted inference and stationary problems, at least in our stationary. We don't see this issue anymore because of the basically the generic the model itself because the more you on the less we're exploring, the more your uncertainty arises on the arms, which you haven't observed, because the agent believes that things will change over time."
"Speaker 1","00;39;01;20","00;39;22;00","Simply, this is also what helps it. The shift between arms and it's also very efficient to kind of extract information from them because it just picks up really fast. What kind of arms we're not simple and is aligned with its beliefs and."
"Speaker 4","00;39;23;14","00;39;54;25","I wonder if this also might reflect the difference between optimizing the model, the practical application in, I don't know, computers simulation program and the way that organisms behave. You know, it may be that, you know, we, we we prematurely shut off and let things become a habit. But that may have downsides. You know, it may be that, you know, organisms just to minimize use of energy, premature really converge on something inaccurate."
"Speaker 4","00;39;54;25","00;40;04;18","And so maybe that's like gambling in that it could show a fragility at times. So this maybe two ways that it's being applied, you know?"
"Speaker 1","00;40;06;07","00;40;29;26","Yeah. I mean, I would say that organisms are never exposed to a stationary environment, so. Right. I mean, in a way, if you are not doing that, you are suboptimal because you are living in an environment that changes constantly. Right? So in a way, you can exploit this by now creating situations where people behave who appear to have a gambling issue and stuff."
"Speaker 1","00;40;30;15","00;40;41;09","But that. Right. I don't think that's kind of a disadvantage for well for what we evolve to do actually for that, we are very good in doing."
"Speaker 4","00;40;42;02","00;40;42;29","That and."
"Speaker 1","00;40;43;00","00;40;45;12","Finding good solid solutions reasonably fast."
"Speaker 4","00;40;46;18","00;41;25;15","Yeah. Sorry. I was just I was just curious. I mean, because, you know, I mean, this is something that, you know, like with some of our empirical work we've run into, you know, so like when trying to model change point detection tasks, for example, not using active inference where yeah, like same thing, like the thing becomes too confident too quickly but I wonder, I mean, because I mean and in a lot of other empirical work, like in neuroscience especially like it's, it's pretty clear that people don't just kind of learn and then unlearn the so like, like reward probabilities or just whatever the kind of environmental statistics are like when there's like abrupt changes right?"
"Speaker 4","00;41;25;15","00;41;47;18","I mean, like what people do is instead they infer that there's something new or hidden because. Right. There's some new light in context. And then under that new context, you basically just have really flat low, you know, really, really small, you know, like magnitude 5% parameters. And then you just go, well, right, like your beliefs are new under that new context."
"Speaker 4","00;41;49;04","00;42;30;29","And so there's like something so there's like that kind of approach which either would require or adding some something hierarchical or having some kind of like additional hidden state factor that would correspond to context, right? I mean, you could do it either of those ways. The then the other thing to do would be to have some kind of like need to be like in the calcium filter where you have some kind of a like dynamically adjusted learning rate or really something more like, you know, so and like recently when we were updating some work with our editorial paper and you know, like after talking with Carl, you know, it seemed like it would be a"
"Speaker 4","00;42;30;29","00;42;56;01","good idea to also include this kind of like forgetting rate parameter as opposed to just like the standard learning rate parameter, which is just kind of like a scaler parameter on the actual and the actual configuration parameters. Right prior to adding on new accounts, you know. And so you could that's not dynamic, but but at least it does prevent, you know, it can act as kind of like a something like an implicit barrier."
"Speaker 4","00;42;56;01","00;43;20;25","And ultimately that can prevent the thing from becoming too confident too quickly. But but yeah, I guess I just I wondered if you guys had thought about or, you know, like later on at all with what's something like that? Something like inferring, inferring new kind of like latent contacts as opposed to just having the kind of like, you know, like the thing becoming too confident and having to spend a bunch of time over writing."
"Speaker 4","00;43;21;06","00;43;25;06","Right. It's you know, it's all, it's all beliefs, which happens way too slow."
"Speaker 3","00;43;26;25","00;43;59;07","I mean, in in the end, I mean, current model is actually based on such a hierarchical model, as you described, where my agent instead of unlearning all the action outcome contingencies, it opens up new context OK, have you inferred that the context change? I think when we were looking for proper learning algorithms for the people, we most definitely looked in the contextual learning."
"Speaker 3","00;43;59;19","00;44;33;00","And I think, yeah, in the stationary case, there are no contexts that's why we didn't introduce it there. And I think the smarter algorithm we used for the Nazis, no and it also has the forgetting rate and just like you say, getting rid on the concentration parameters, which I think is another reason why this algorithm worked well in the non stationary came out better than the stationary course."
"Speaker 3","00;44;33;13","00;44;57;21","And in theory I think we also tried some version of this where we have both contents and primitives. But yeah, in the end then for them randomly moving, then we had our some about then having another layer to this hierarchical model that in person volatility to adjust the learn."
"Speaker 4","00;44;58;06","00;44;58;15","Yeah."
"Speaker 3","00;44;59;05","00;45;02;27","Like you said that your learning model becomes."
"Speaker 4","00;45;03;03","00;45;03;29","Very abstract very."
"Speaker 3","00;45;03;29","00;45;06;18","Quickly, you know all the time."
"Speaker 4","00;45;07;04","00;45;27;02","It's I guess, I guess what I don't completely understand still is so even in this if if you're forgetting rate especially high, I mean that all this is going to happen if your actual like magnitude, your concentration parameters are never going to build up to too high value. Right. So like does that not still help with the overconfidence issue?"
"Speaker 4","00;45;27;09","00;45;28;06","I just sort of thought it would."
"Speaker 1","00;45;30;12","00;45;41;20","Well, we don't set up for kind of forgetting parameter in then stationary case. I place this shut off because well, the agent believes it's in a stationary environment."
"Speaker 4","00;45;42;10","00;45;53;01","Yeah, I guess it is not right whether you could still put an agent in a stationary environment, but it seems like it could be plausible that it has that kind of yeah, forget it. All right."
"Speaker 1","00;45;53;01","00;46;10;21","So yeah, I agree. I mean, that's one way one could try outright to resolve the it's exploration from mean stationary case, just simply giving the agent the wrong release so that I think we sort of look and say, just go that."
"Speaker 3","00;46;11;08","00;46;35;29","We use the same learning, the same Bayesian relief updating algorithm for all the different X and selection methods that we comprehend. And then it's a weird interplay between the learning model that we chose for the stationary case and the X and selection rule. And I mean, times and sampling which uses the same learning does not have this issue."
"Speaker 4","00;46;36;25","00;46;37;06","Yeah."
"Speaker 3","00;46;37;29","00;46;40;23","And that I think is also interesting."
"Speaker 2","00;46;42;18","00;47;04;27","So to the second part of the question where how would that translate to improving how some problems are decisions are currently solved? I'm hearing a few things we talked about speeding up computation relative to other approaches, but that's not a solved problem. For example, if there's a ten times speed up, but then you have to run ten agents in parallel to get a good ensemble estimate, then it's a wash."
"Speaker 2","00;47;05;02","00;47;35;09","So potentially for speeding up just the computational requirements for certain challenges. A second would be that it might be possible to more rapidly lock in to dynamically changing regimes and to avoid some of the pathologies of model fitting in multi arm bandit contexts. And then a third way that it could translate to improvements would be it might reveal some hidden similarities between these different problems and settings."
"Speaker 2","00;47;35;16","00;48;09;15","Like we already know that they're somewhat similar because we can apply a multi armband it to, you know, health finance recommendations systems, et cetera. So we know that there's a lot of problems involving data that have similar enough structures such that a similar kind of general algorithm can be applied but then it could be interesting once we have them on the common grounding of active inference to say, actually, you know, the structure of the decision making is similar across these two settings or, you know, the telecommunications routing and the logistics routing are similar in this unexpected way."
"Speaker 2","00;48;09;21","00;48;39;04","So maybe insights relating to what kinds of tweaks an agent could improve on their performance with like what we're talking about here with the category of categorical hidden states or learning and forgetting tweaks, maybe some of those insights could be implemented in active inference and then more easily transferred across different domains. So hope that conveyed some of our thoughts on this question, too."
"Speaker 2","00;48;39;04","00;48;40;05","Lars, anyone else?"
"Speaker 1","00;48;40;25","00;49;09;11","Yes, I mean, the one issue there is that in different domains, you will in principle have different generative models, right? I mean, although the problem is the same midterm, but I mean, you would need different representation of the environment. And this is then where the challenge comes potentially. It's if you can represent that there's a multiple embedded problem, you can choose different whatever action selection algorithm you find works best."
"Speaker 1","00;49;09;11","00;49;31;09","And in non stationary situation, so at least for what's being investigated, this seems to work well. This doesn't mean necessarily that this generalize this one, we'll still have to try out different things just to make sure but in the end, the bigger challenge is like, OK, what is a good generative model for this dynamic problem, which I have and one thing go there, right?"
"Speaker 1","00;49;31;09","00;49;56;01","It's many different things. I mean, for example, what the Rand also mentioned, this kind of open ended contextual learning that one can represent simply in the environments where you don't know anything about what's going on. You can just do a nonparametric majority model like the regular process of process. You just try to learn even what the model itself should be."
"Speaker 2","00;49;57;10","00;50;30;27","Awesome. So let's go to this little sub discussion on Sarah, one of your previous papers, and then we're going to turn notebooks and walkthroughs of the Bandit project. But hopefully this will be informative because first off, belief propagation and message passing and these types of approximations are of interest to the lab and the community. And also we're seeing a few faces that we can ascend Active Inference Mountain on."
"Speaker 2","00;50;31;09","00;50;54;15","We have Ryan with a Matrix based MATLAB approach. We will walk through in just a few minutes with a Python based approach of the bandit. And then this is a slightly different approach based upon the best approximation. So Sarah anything you'd like to describe? I'm sure this will be new to many people, so it will be helpful to convey what you are working on here."
"Speaker 3","00;50;56;16","00;51;31;28","Sure. So in regard to the upper one, what you see is the generative model of the normal observable make of decision process where the in the upper row with the unfold circuits are the hidden states where they were called in the previous slide and below the observations. And then the whole mimics of which states follow upon each other is determined by the policy of pi on the left side."
"Speaker 3","00;51;33;08","00;52;11;13","And then point people often do is assume in this cue that we saw it was that before the measured approximation which means basically which means said for example here we have a bunch of hidden states each t h, t plus one and so on. And then if you assume the mean approximation and the approximate distribution would be just u of h t times, q of h, t plus one times and so on and so forth."
"Speaker 3","00;52;12;01","00;52;48;08","And there with you create an implicitly you essentially treat all the hidden states as independent in your approximate release and then the dependencies will be averaged out and in FIG. three you actually see the inverted model and in with M, you see the messages that are being passed in between notes. So if you it doesn't matter what approximation you use in the end you can calculate your beliefs with some sort of message passing algorithm."
"Speaker 3","00;52;49;14","00;53;29;10","Um, except that now if you just admitted approximation and you estimate on hidden said separately what you found is that actually they may not fit very well to each other. So for example, when my agent predicted how it went all through the grid and this and policy, it actually often predicted it would trump and go places that don't adhere to the transitions and that is of course leading to decreased goal reaching success."
"Speaker 3","00;53;30;24","00;54;14;06","And then instead of doing this measured approximation, we assumed the better approximation which instead of having Q h t times Q it's D plus one and so on, you have small pairs of point distribution. So you have each T and its T plus one times Q of its T plus one and its T plus two. And then doing the math, you can show that if you assume this type of approximation and you plug it into the fit, and if you want to minimize the free energy, the belief propagation method, the passing algorithm comes out."
"Speaker 3","00;54;15;25","00;54;52;15","And so you can use the belief propagation passing algorithm and the better approximation to calculate pennies and this is actually exact on graphs with all and then you get a more appropriate joint representation in this case of temporarily dependent hidden variables but I mean, in the end, what I do nowadays that I also have the hierarchical model where know, for example, the parameters of the Markov decision process are context dependent."
"Speaker 3","00;54;53;09","00;55;14;22","I look into my model and think which variables belong together? And then I apply them the better approximation on these parts, but then some slower varying variables like the context, I just use them in fit approximation because it varies differently anyways."
"Speaker 2","00;55;17;12","00;55;41;17","Thanks for that breakdown. What is message passing like? Who are the messages being passed between and does that reflect a variant on active inference or is it the same exact active inference model can be approximated or can be calculated through message passing or through other mechanisms?"
"Speaker 3","00;55;44;27","00;56;13;12","Correct me if I'm wrong, but I think in the end all active inference agents to message person depends on the approximation, which type of message parsing algorithm. So I the better approximation it's belief propagates propagation message parsing. I think they're equivalent to the same product algorithm. Also, you just get different messages that maybe that are worse, but OK, what other messages?"
"Speaker 3","00;56;13;12","00;56;45;20","Essentially it's not in the graph, so it's hidden variable since other than variable that it's connected to a message about which stand it's repeat. And so it's t would say, hey, we're currently here then I think in the next state we should be there and then vise versa. And suppose one can send a message back that says, Hey, we want to be there next time said where should we be now?"
"Speaker 3","00;56;47;02","00;57;09;25","And so on. These variables essentially send each of the messages on what they should be so that they are in agreement with each other and that's how you get essentially a probability distribution of what you think you know, which state you're in and will be in yet."
"Speaker 2","00;57;09;25","00;57;19;09","Dmitri, any thoughts on message passing or where do you see message passing fitting in to Bayesians autistics and a few other topics."
"Speaker 1","00;57;20;17","00;57;42;00","I mean, as Sarah said, I mean table to say, all the algorithms are message first. So when you talk about mindful approximation, this would be traditionally a variation on message parsing. It's called the algorithm right here. This is like belief propagation. It's message parsing algorithm based on marginal probabilities."
"Speaker 1","00;57;44;03","00;58;10;14","Instead of in the variation on message. Best thing, if you have like expectations on the log of conditional probabilities, I mean, this is kind of the differences what you what you are getting and losing. I mean, we shared another paper with Thomas Power and Karl, and you're wrong on message passing using meaningful data and marginal approximations where we kind of contrast the different ways."
"Speaker 1","00;58;10;14","00;58;37;09","So who is interested in this topic? Can look into that bit and back to discussion of similarities and differences in practice, the difficulty with meaningful approximation, it's I mean, for dynamical problems, for example, decision making, it's not really a good approximation. This is not something which one would use and implementation bias in active inference means field approximation is not used under dynamical at all."
"Speaker 1","00;58;38;10","00;58;51;28","What what they are using in MATLAB, for example, is this marginal approximation it's still kind of gradient based method, but it's computed slightly differently. So yeah, sorry."
"Speaker 2","00;58;52;15","00;58;53;08","Continue, continue."
"Speaker 1","00;58;54;22","00;59;19;09","Now I just wanted to can wrap up is basically the more complex problem. The it is, the more uncertainties you have on the stage transitions, the more difficult it would be difficult t0 have it mean field and marginal approximation. Basically the meta approximation is the only thing which kind of corresponds to actually the exact inference in the in graph."
"Speaker 1","00;59;19;15","00;59;29;04","So basically this is this is the radical solution you know that you can be exact on the specific conditions on the marginal."
"Speaker 3","00;59;31;08","00;59;56;17","But I can only warmly recommend by idea and advice I think in 2001 called understanding belief propagation and its generalization and I find that very handy tactic. It taught me a lot and they explained in detail how variation for instance I so connected to such passing algorithms interesting."
"Speaker 2","00;59;56;17","01;00;17;07","So just to capture that one interesting thing you said there about the gradients, the gradient, it's sort of like your models in a given spot on the landscape and then it checks the temperature and it goes in the direction of the gradient. So we've talked a lot about gradient based methods with the straight line versus the ISO contour message."
"Speaker 2","01;00;17;07","01;00;49;24","Passing kind of breaks that down into a process. So each click of the model messages are being passed back and forth to one another, which is both computationally tractable. It's also shown through some work of the Bias Lab, Berta and others that for specific categories of Bayesian graphs, that message passing algorithms are basically equivalent in the form factor graphs, the EFG, which we're going to be learning about in the future."
"Speaker 2","01;00;50;04","01;01;17;29","And also this topic logically puts you more into touch with the predictive processing, for example, the messages that neurons are passing to each other. So it's one thing to say well, it's as if the neurons are messaging to each other, and that's doing a gradient descent. But it's another thing to actually saying we have a message passing scheme for modeling how these message passing agents do inference."
"Speaker 2","01;01;18;22","01;01;31;20","So there's a few points of contact there that I think are pretty important. And it's pretty it's also interesting that you brought up that early paper, so we'll check that one out. Steven, did do you have a question."
"Speaker 4","01;01;33;08","01;01;35;01","I think it's been sort of covered."
"Speaker 2","01;01;35;01","01;02;04;03","Really cool area, though. So thanks, Sarah, for sharing that. Just one last question on this before we go to the bandit codes and walk through like where do these approaches are they converging and they're going to weave together more closely or is one of them like an umbrella over the other such that work will continue mainly under the generalized form."
"Speaker 2","01;02;05;13","01;02;24;25","Where do these different approaches that we're talking about to implementing active inference, where are they heading like is it is more development happening on the message passing approximation or on other modes of breaking down active inference."
"Speaker 1","01;02;30;06","01;03;33;15","I'm not sure I found the overview of of hundreds of papers published every month and active inference. Let's say something about as far as I mean our motivation is here we just want to have in different situation good enough inference approximations. So in a way for me more important question is like what is a good representation of different tasks and environments to have rather than what is the best kind of inference algorithm to use because specially I mean depending again on the environment you're working on but in dynamic context it's difficult to get like lots of advantage with just improving slightly on the inference performance brain does because there's lots of uncertainty in X and"
"Speaker 1","01;03;33;15","01;04;01;23","in any way change all the time. So yeah, I mean with this, we also kind of ripe for this multi paper. We tested for lots of different algorithms. There is one of the notebooks in repository just kind of lists and different things that try it out, but in the end one doesn't see you. I mean, any reason why when I work not with me specifically a way is better than another."
"Speaker 1","01;04;01;23","01;04;05;18","It just they're very similar sub subtle, subtle differences."
"Speaker 2","01;04;06;25","01;04;44;08","Great point that there's a lot of work on the comparability of different approximations of different algorithms, but actually it might be more beneficial for a given application to focus more on how they're specifying the generative model and making sure that that really captures essential features of the environments because it's like, OK, let's just roll with active inference and spend our attention on the generative process and the generative model rather than try to finesse potentially a grossly inferior generative model with some better approximation, there might be limited returns there."
"Speaker 2","01;04;44;16","01;04;48;02","So Steven, and then we'll go to looking at some of the bandit code."
"Speaker 4","01;04;49;03","01;04;59;18","Yeah, yeah. This is a kind of a general question related to that is I often think about so didactic beyond the Q type."
"Speaker 1","01;05;01;24","01;05;02;04","Of."
"Speaker 4","01;05;03;15","01;05;33;08","Ways of making inference is sort of deductive thinking and such like and I'm wondering whether the message passing is, is, is more present in those types of models because it's something that's been detected in the environment and decisions based on that are being made. And you've got then you've got you kind of inductive where you're trying to narrow the gap between a goal and then you've got your objective where you're trying to build something up."
"Speaker 1","01;05;33;19","01;05;34;11","And infer."
"Speaker 4","01;05;34;11","01;05;59;13","From like a landscape that you're trying to work out what, what is out there, so to speak, and I'm wondering if this is correct in my thinking that the message policy is more used when you have like a particular deductive reasoning approach and inductive or abducted ones would be."
"Speaker 1","01;05;59;21","01;06;00;06","Different."
"Speaker 2","01;06;02;24","01;06;36;07","Interesting question about how those different modes and types of logic are connected to message passing one thought which might be on or off base, is that we're thinking a lot about how variables in a model are like nodes, and then there's edges. Connecting the nodes that reflect the relationship between those variables and message passing is just one way to describe as a model updates through time, which information is being passed between the variables."
"Speaker 2","01;06;36;26","01;07;11;09","So it doesn't say anything about the mode of operation of an agents, which might be engaging in different kinds of logics. And I think that's a really excellent question. Like how how do we break out of the known with respect to how our algorithms update and it does actually touch upon this mean field approximation. For example, if you think that all through all time, past, present, future, that there are some station parity of the hidden state, then the bead field approximation will work."
"Speaker 2","01;07;11;25","01;07;59;12","But then if there's going to be a change in the state, then the mean field approximation is potentially going to give a misleading outcome. But in any case, message passing is just describing sort of the mechanics of how the model updates and which information between variables is connected, but importantly which variables are not connected like the observation at a time point doesn't influence the observation at a different time points directly, but it could via a specified path of message passing let's look a little bit at the bandit code."
"Speaker 2","01;08;00;11","01;08;08;17","So the the links to the GitHub di Markov, you have the right name to work in the area."
"Speaker 1","01;08;09;29","01;08;10;21","I know you."
"Speaker 2","01;08;13;03","01;08;38;06","So we have a few of these notebooks up and is there we can look at the overall notebooks folder or do you have a sense of which of the notebooks might be interesting to walk the record? Go to a few or if you want to jump to a first one, I think just this first one."
"Speaker 1","01;08;38;06","01;08;39;10","But think about this."
"Speaker 2","01;08;39;10","01;08;43;25","Maybe I'll go ahead yeah."
"Speaker 1","01;08;44;00","01;09;04;05","There are a couple of things. I mean, there are couple of notebooks which are not immediately relevant for the paper so we can focus just on the things which are part of the paper. Or I can just generally kind of talk also about this other things which are just process of thinking about the problem."
"Speaker 2","01;09;05;11","01;09;31;04","OK, how about before we even how do you as a researcher working on this area keep that separate like the paper specific developments, but then your overall developments, do you find that you're on an overall development mood and then you dip into specifying a paper? Or do you pursue the paper and find that you have more general insights while you're working through the problems?"
"Speaker 1","01;09;32;22","01;09;54;25","Well, I mean, I pursued the paper, but I mean, then I mean, there are lots of branching facts in that way and way I have to figure out what's potential interesting, what's relevant. And so part of this is just exploration of things topics. It's very interesting for me, but which turned out not to be so important in the end."
"Speaker 1","01;09;54;27","01;10;21;04","Just maybe for some other paper and things which are just focusing exactly on the comparison of multi and algorithms, but discussing this part so in a way, it's difficult to combine lots of potentially unrelated things into one paper so one always has to make some favorites."
"Speaker 2","01;10;21;04","01;10;41;06","And then I knew it would be a, a both type of question because it's something that researchers are often, you know, interested general questions. But we need to deliver on specific research projects with a defined scope and conclusions as well. So it's just cool to see that this repository holds a little bit of both."
"Speaker 1","01;10;41;26","01;11;14;06","So for example, this notebook which opened first, like expected free energy comparison this was just my contemplation of just different ways you can define expected free energy. So typically people think about expected free energy in this term, so expectations of outcomes. But for example, other questions, OK, but why not why not computing? And in terms of expectations? So we're states and there is a relation between this two, right?"
"Speaker 1","01;11;14;16","01;12;03;28","One is an upper bound and another. So basically you'll see this last relation there is as the fiber is g of pi and there is I five and basically g of by would be expected free energy in terms of expectations. So I think states so this first and this is upper bound and what this would be like expected surprisingly for me in equivalence to the free energy being the bound, the marginal like block of likelihood, the surprising and then there is the I of PI which is just called divergence between posterior prior which gives you then something else and in one can also think well we can select policies or make decision making algorithm based"
"Speaker 1","01;12;03;28","01;12;24;18","Nathaniel on this quantities and what happens when you use one or another so this is something which I was just testing out for myself and I'm still not clear what to think about this. So that's why I don't have a paper on it."
"Speaker 2","01;12;25;00","01;12;50;11","This is very interesting. It's like that. It's all conditioned on policy with PI and then we're approaching it from the top and from the bottom and so the free energy is like being sandwiched in between these other approximations. And then you wrote here that the minima of I and g of Pi match, but s is giving a different minima."
"Speaker 2","01;12;50;11","01;12;53;01","So what was curious about that too, you."
"Speaker 1","01;12;53;02","01;13;15;20","Know, at least in this example, right? So I just kind of build up simple example and one can see that optimal policy or like minima of these different quantities is different. And one can also think probably of different examples. Well, this will I mean, this relation will not hold what they just wrote this recommended. But I mean, this is more like than practical question."
"Speaker 1","01;13;15;26","01;13;51;01","So if you would then build an agent, which one of these quantities should you use? They are all kind of effectively can be seen as a right excitation expectation of a future surprise. Then and having different bouncing that expectation is an approximate quantity. So just the question is and I also found in different problems, depending how I formulate problem, one of this algorithms works up well, not algorithms but objective functions let's call them works better."
"Speaker 1","01;13;51;16","01;14;26;13","So right so in this particular multi I'm glad that states could try it explore the GOP is not so what I mean what should correspond to expected for energy. This is not behaving that well in the way you don't get such a good performance. But I've been slowly with change the past and I can get better performance with GFI or specify so as I said I'm not sure what to think about this still so for."
"Speaker 2","01;14;26;22","01;14;27;04","Well."
"Speaker 1","01;14;27;19","01;14;30;01","It's really like exploration of different things."
"Speaker 2","01;14;30;23","01;14;40;07","Well we'll have you back on this topic when you're in a phase. You want to look at inference, algorithms, comparison or is."
"Speaker 1","01;14;40;17","01;15;18;13","Well, yeah. So inference algorithms. As I said, this notebook and just live some of the things which we consider right in the literature. When you think about this about approximate inference problems in changing environments, one can think of different ways how to solve this what we use here is the right, this representation, which comes from change point models as an approximation for the task, which is a good approximation for this kind of switching bandwidth, which is what we just showed just showing here."
"Speaker 1","01;15;18;13","01;15;56;16","Right. For example, this is the question you had for last week. Awesome. So this would be how probability changes in a in sitting bandwidth on one arm over time right now probability of generating one. Let's call this a reward. This is what this flight is showing and right. And this is is such an concept that after each whenever a switch occurs, we are just sampling the new probability for each arm so this is this kind of setting with non stationary, a difficult thing, right?"
"Speaker 1","01;15;56;16","01;16;21;01","So basically this difference between the best arm and second best is it very sort. Fine. And then you have like a drifting dynamics or which so slightly different generative model would also be better but then I can also say, well, we can use any generative model for any of these problems and let's just see which does inference better or are there any differences there?"
"Speaker 1","01;16;21;13","01;16;55;11","So can you just use different representations in for different underlying environmental dynamics? In a way, it may specify the model, but still doing reasonably well in the inference part. And right when you kind of look at the results kind of posterior expectations, you get over time different approaches similarly to very similar results in the act. So there is no kind of strong advantage or disadvantage of one another."
"Speaker 1","01;16;55;25","01;17;06;28","And that's the reason why we just pick the simplest thing which can the most efficient basically algorithm because then it's much easier to scale to more arms the more times that something."
"Speaker 2","01;17;09;16","01;17;16;27","OK, very interesting. This is a pretty thorough walk through the hierarchy. Yeah."
"Speaker 1","01;17;17;04","01;17;52;07","Variational smile yeah, exactly. Just describe the generative model. Some of the steps one needs to take to get to the posteriors there are also then just implementation of the algorithms and back there. But besides this, right? So what we used in the paper, we also implemented some other approaches which are non variational kind of vision inference which is tends to be quite good."
"Speaker 1","01;17;52;08","01;18;08;03","I mean like on average it performs better. It's like more optimal representation. Now this comes from I think also recent paper and multi amended the remembers are a little faster. I thought maybe or."
"Speaker 3","01;18;09;00","01;18;10;23","Unfortunately not, I would know."
"Speaker 1","01;18;11;09","01;18;17;29","Well we are citing the paper anyway. So but right now."
"Speaker 3","01;18;19;26","01;18;21;09","But you have pretty recent paper."
"Speaker 1","01;18;21;10","01;18;30;10","In particular is paper and one can see that it the slightly better job. So that would be I guess this algorithm you're showing now. Yeah."
"Speaker 2","01;18;31;18","01;18;36;25","What are the lines representing the red, blue, green and then the sort of."
"Speaker 1","01;18;37;12","01;19;13;03","The green it does to the posterior expectation or like reward probability. So right. The perfect algorithm should just match green with blue and the red is basically change point inference. So there's a posterior probability that the change occur at the specific moment of time. And as we can see, this process is quite noisy in the way that you have lots of small errors in a way or slight jumps in the in places where change doesn't necessarily occur."
"Speaker 2","01;19;13;11","01;19;39;25","You know what what this reminds me of is the blue is some hidden true price of an asset and then the green is like the market's tracking that price or value. And then the red are like orders like buy and sell orders on the market that represents the underlying situation changing. And it's like."
"Speaker 1","01;19;40;02","01;19;53;25","Again, it just may be well, I mean markets, it's not like this. If markets is doing some kind of inference on the true value of the price. Right. This will be kind of distributed insurance from."
"Speaker 2","01;19;54;12","01;20;02;25","Yep. I mean, it's the whole no one knows the price of a pencil, but maybe the person making the eraser knows when the price of rubber changes a little bit."
"Speaker 1","01;20;04;13","01;20;06;28","But both their colors are just the incidents."
"Speaker 2","01;20;08;04","01;20;17;21","But yeah, OK. And then here we see something yes."
"Speaker 1","01;20;17;21","01;20;50;06","Here is this. This is if I remember correctly, this would be the hierarchical deletion filter applied to the same problem. So this is work from a piece of the Christmas this. So so he actually in his first paper he did apply to inferring the price for Mesothelin. So when he introduced that but but it's found lots of applications in cognitive neuroscience and just understanding how people adjust to volatile environments."
"Speaker 1","01;20;50;06","01;21;04;08","So there so what we have here is that this kind of change probability is constant over time. But you can also think of the environment change probability itself changes over time so that you need to kind of adjust to this change. It's awesome."
"Speaker 1","01;21;07;16","01;21;22;10","So that would be also point one straightforward extension of this multi and bending problem, different types of dynamics, and that's been golden, more complex generative models of approximations to deal with this problem."
"Speaker 1","01;21;25;13","01;21;32;11","And so right, we are just comparing now how this algorithm tracks the underlying price value in different environments."
"Speaker 2","01;21;32;13","01;22;07;17","So that's I have a question about what action does. So here the underlying generative process is stochastic, but the actions don't change the process, like choosing a different slot machine isn't changing the probability of slot machines. So it's almost like a little bit more of a niche modification setting, or can it just be directly put into the model that certain actions actually change aspects of the underlying generative process?"
"Speaker 2","01;22;08;02","01;22;17;26","Or is that kind of a feedback between action and then future hidden states? Is that like another module that has to be constructed in."
"Speaker 1","01;22;21;23","01;23;02;24","Well, for what we have implemented here, that would definitely need an extension, right? So we kind of this is more than this general representation, which of also implementation of active inference, which for example, is implemented in ESPN, which then helps to deal with this more extended problems. So here we really are working with the simplest algorithm just for having it's like very efficient and compact so that it can still easily what the more general you are trying to capture many different problems, the more difficult to have the."
"Speaker 2","01;23;06;02","01;23;25;13","It's it's like inference all the way up or all the way down. And it's a theme that will return to many times, which is that it's all good to track the absolute value of what you're interested in. But then the uncertainty on that and then the uncertainty on your uncertainty about that can get you into this infinite recursion."
"Speaker 2","01;23;25;25","01;23;48;19","So you just do you go quick and dirty and just have a simple idea of how variance in higher order uncertainties propagate or does one fully specify all the possible ways that uncertainty can exist across multiple levels, which can get to an explosion of the computational requirements really fast well."
"Speaker 1","01;23;49;16","01;23;52;14","I don't think that's necessarily hierarchy of the issue."
"Speaker 1","01;23;55;18","01;24;26;02","But it's more right if you then start assuming that your actions change, the status step changes or transition matrices in this, right? So basically our effective actions are modifying the state transition matrices then this requires that. I mean, you also think about the planning problem and it's not any more simple action selection problem, but that's then becomes a planning problem."
"Speaker 1","01;24;27;25","01;24;37;00","And this makes things more complicated if you introduce such an environment because then it depends where you are at different moments of time in different states."
"Speaker 2","01;24;37;11","01;25;06;01","So yes, because we've seen in the Markov decision processes that policy PI plugs into B, which is the transition matrix between hidden states. And so that's like actions changing the way in which hidden states are inferred to change through time, whereas the one step decision making is doesn't have to be done in that same way."
"Speaker 1","01;25;06;15","01;25;37;20","But yeah, I think also, I mean, it lists the original implementation in that and what is use, this doesn't scale so very well for this type of problem. And since different groups of people have started exploring local Monte Carlo research and other methods which actually allow you to then figure out potentially best policy in a very complex, high dimensional problems all right."
"Speaker 1","01;25;37;25","01;25;50;21","But but I mean, as long as you are kind of in domain of cognitive behavioral neuroscience, you can get away with this by just making your task presumably simple oh, OK. I have this control."
"Speaker 2","01;25;50;21","01;26;10;17","So yes, but even as as Ryan I pointed out earlier, that real humans, even when you control the experiment or you think that you're introducing like a gradual change in a parameter, they might actually be cognitively doing a different type of inference."
"Speaker 1","01;26;11;17","01;26;15;02","Yeah. Humans are problematic. I don't like."
"Speaker 2","01;26;15;02","01;26;16;10","Them. Oh, humans."
"Speaker 1","01;26;17;29","01;26;19;13","It's a big experiments with robots."
"Speaker 2","01;26;20;15","01;26;46;06","Well, maybe that will be I mean, we brought that conversation of course, logistics planning, motor behavior, exploration, exploitation, spatially. Those are things where maybe having a defined digital twin for some robotics and then we go from in silicone to robotics to starting to introduce the elements of the human and the unknown Steven."
"Speaker 1","01;26;46;09","01;27;23;17","I mean, what? So I think, I mean, like in behavioral experiments, you always have this problem of uh oh. Just like convincing yourself that the model you are using is something which reasonably well represents humans. And doing. And you can be quite certain that this is not what they're doing. Exactly right. This is just an approximation of all the complexity which we kind of have in, well, our nonparametric representation of the role by hand and I mean kind of there this is so right."
"Speaker 1","01;27;23;18","01;27;48;23","You can kind of get people to perform very well on the task through lots of training, but then is like OK, is this really what they want to kind of experimentally where they're like, oh, how can you just learn to do this task well? Or I'm actually interested what people are doing when they are solving any task, how they represent their moment, data, time representation, how is this incorporated in their decision?"
"Speaker 1","01;27;49;28","01;28;12;05","Model? So and I think it's I don't know how other people feel maybe want to comment on this, but for me it's always like a difficult to to, to deal with. It's like all this uncertainty of whether you're doing the right thing by simply enforcing something. Sometimes can people."
"Speaker 2","01;28;14;06","01;28;16;05","Yes. Thank you, Steven."
"Speaker 4","01;28;18;09","01;28;30;19","Yeah. So talking about this, the problem with humans, but is I'm interested in how the precision parameter you try the precision parameter it helps to determine whether someone's going."
"Speaker 1","01;28;30;19","01;28;32;10","To explore, exploit."
"Speaker 4","01;28;32;10","01;29;06;10","The contents. And I'm interested in how exploration can become the pragmatic this precision about the usefulness of something that's exploratory. I want art or an experience of some sort and how that meaningful ness in the future could offset a pragmatic gain in the near term. So I'm interested in this the way that precision fits in with that and sort of the evolution of that."
"Speaker 4","01;29;06;10","01;29;39;21","And they even talk about that bit with the affective charge with Casper Hesse I aspects of is how your precision about an expectation has been violated or not. It's not necessarily whether it's good or bad it's whether your your prediction of how well you could expect something to happen suddenly got violated and that amplifies everything. So I'm interested in that because I'm trying to create immersive experiences for theater and places like that."
"Speaker 4","01;29;40;03","01;29;59;14","But I was just wondering what your thoughts about the precision, how that precision parameter fits in with that dynamic and how that could be extended or if there's other than other parameters that kind of fits in there as well mm."
"Speaker 1","01;30;03;12","01;30;20;25","I'm not quite sure that I understand the question, but let's say the are you asking like is precision always relevant?"
"Speaker 4","01;30;21;06","01;30;45;10","Yeah. Can you stack the precision with the pragmatic that makes sense to say you've got no precision but you have a high precision over the fact that exploring the low precision would be useful. So the two things kind of stack on top of each other as being a sort of a pragmatic epistemic game. I can see that being used."
"Speaker 1","01;30;45;10","01;31;15;08","Yes. So I mean, we in this other paper on Matter Control, we are playing with this a bit differently. So we are saying that you can kind of control your exploration tendencies if you learn over time that exploration is better and this is kind of where this kind of stacking of different levels of the hierarchy are like a higher level kind of agent controlling the lower level comes into play."
"Speaker 1","01;31;16;15","01;31;43;03","All right. Because simply of this kind of level observes that over time you're like the agent is not performing well in a way. It's not reaching the goals efficiently, then it's kind of punish this exploration and learns just to be more exploitative in specific settings. And the other way around, right, we can make kind of a setting where the exploration is beneficial always and."
"Speaker 1","01;31;43;11","01;32;07;18","Right. And this is when the agent learns to kind of behaving this way better. So one can then actually assume in the real situation this is something which people learn right? So just if they observe that depending on what they do, they gain more or less, they will also adjust their tendencies and associate this with different contexts, right?"
"Speaker 1","01;32;09;05","01;32;10;23","So you could have."
"Speaker 4","01;32;10;23","01;32;16;13","Almost like it's not just precision, you could have like another generative model managing those."
"Speaker 1","01;32;17;21","01;32;32;25","Yeah, exactly. I mean, you can just seven and a kind of higher level representation which controls a prior decisions on the lower level. So. Right. And basically you're seeing different behavior after that."
"Speaker 2","01;32;34;13","01;33;06;29","To connect that to the incentive cuz it's almost like if you had a, a sound or a cue that said, OK, now we're in a brainstorming period, OK, now we're going to drill down. And by alternating between a brainstorming period and by drilling down we're going to have the right kind of outcomes, but giving a cue for when one should be in a more exploratory mode versus potentially like more working with what is already known."
"Speaker 2","01;33;07;20","01;33;38;08","But this looks like an interesting paper, this better control of exploration, exploitation dilemma and also framing it in terms of the hierarchy of timescales, whereas often it's framed in terms of I guess just instantaneous ously what maneuver would be best, whether one is instantly preferring exploration or exploitation, rather than through deep time."
"Speaker 1","01;33;42;19","01;34;00;12","Is the interactive attribute where doing that paper is what motivated this person. So this public becomes like, OK, I really need something to just explain. Unpack some of the similarities and differences between active inference and everything else around."
"Speaker 2","01;34;02;03","01;34;30;23","Nice. Well, if there's any other sort of closing thoughts, this has been an awesome set of discussions. I think we'll have a lot to think about and hopefully people will work through these notebooks. Keep an eye out for when the final paper is published. We're So You got this one fully published. While the multi armbands is still not ready."
"Speaker 1","01;34;31;15","01;34;39;06","It's still under review. Yeah we are fine. Yeah, hopefully so cool. It's a first revision around currently."
"Speaker 2","01;34;40;22","01;34;48;02","Well to anyone who's on here, any other thoughts or questions or what do we take moving forward?"
"Speaker 2","01;34;50;12","01;35;10;08","I'm just thinking about different tabs. I could be having a regime of attention on as the multi arm bandit, you know. Do I check something I haven't checked in a while because I'm uncertain? Or should I pull back to my higher level and be like, you know, it doesn't even matter if I'm uncertain about that tab. I should just stick on this one."
"Speaker 2","01;35;15;13","01;35;18;28","I'm sure there'll be some fun. Yeah. Imagery."
"Speaker 1","01;35;19;29","01;35;27;25","Well, I mean, it's very general problem. As I said. So most of the problems are mostly on vendors. It's not surprisingly."
"Speaker 2","01;35;29;09","01;35;43;26","Awesome. Well, Sarah and Dmitri thanks so much. It's great to have your engagement from a dot zero on through. It really made it awesome for the lab. So thanks everyone for watching and until next."
"Speaker 1","01;35;43;26","01;35;45;05","Thank you for having us here."
"Speaker 3","01;35;45;12","01;35;45;28","Thank you."
"Speaker 1","01;35;47;10","01;35;48;00","So much."
"Speaker 2","01;35;48;00","01;35;48;18","Till next time."
"Speaker 1","01;35;48;18","01;35;50;27","Bye bye. Bye bye."
