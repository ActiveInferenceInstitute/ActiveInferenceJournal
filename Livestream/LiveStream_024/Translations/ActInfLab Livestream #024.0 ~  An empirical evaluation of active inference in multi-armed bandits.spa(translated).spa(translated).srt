1
00:00:08,480 --> 00:00:09,040
hola a

2
00:00:09,040 --> 00:00:12,000
todos, bienvenidos a la

3
00:00:12,000 --> 00:00:14,400
transmisión en vivo número 24.0 de actin flab,

4
00:00:14,400 --> 00:00:18,000
hoy es el 16 de junio de 2021

5
00:00:18,000 --> 00:00:19,920
y vamos a hablar sobre este

6
00:00:19,920 --> 00:00:22,560
artículo en la evaluación empírica

7
00:00:22,560 --> 00:00:25,039
de la inferencia activa en bandidos con múltiples brazos,

8
00:00:25,039 --> 00:00:26,000


9
00:00:26,000 --> 00:00:30,320
soy daniel y estoy aquí con blue hola

10
00:00:30,320 --> 00:00:32,880
increíble  bienvenidos al

11
00:00:32,880 --> 00:00:34,239
laboratorio de inferencia activa todos

12
00:00:34,239 --> 00:00:37,120
somos un laboratorio en línea participativo que

13
00:00:37,120 --> 00:00:38,239
está comunicando el

14
00:00:38,239 --> 00:00:40,320
aprendizaje y practicando la inferencia activa aplicada

15
00:00:40,320 --> 00:00:41,920
puede encontrarnos

16
00:00:41,920 --> 00:00:44,800
en los enlaces aquí en esta página esto está

17
00:00:44,800 --> 00:00:45,760
grabado en una

18
00:00:45,760 --> 00:00:48,000
transmisión en vivo archivada, así que envíenos sus

19
00:00:48,000 --> 00:00:50,000
comentarios para que podamos  puede mejorar

20
00:00:50,000 --> 00:00:52,239
nuestro trabajo todos los antecedentes y

21
00:00:52,239 --> 00:00:54,000
perspectivas son bienvenidos aquí

22
00:00:54,000 --> 00:00:55,280
y seguiremos una buena

23
00:00:55,280 --> 00:00:57,760
etiqueta de video para transmisiones en vivo

24
00:00:57,760 --> 00:01:00,640
aquí en el enlace corto encontrará

25
00:01:00,640 --> 00:01:02,000
todas las transmisiones en vivo

26
00:01:02,000 --> 00:01:04,400
y diferentes series que hacemos en la

27
00:01:04,400 --> 00:01:06,880
unidad de comunicaciones de actin flab

28
00:01:06,880 --> 00:01:08,720
y hoy vamos a estar

29
00:01:08,720 --> 00:01:11,200
contextualizando en el video punto cero

30
00:01:11,200 --> 00:01:13,520
para dos próximas discusiones en la

31
00:01:13,520 --> 00:01:14,400
segunda quincena

32
00:01:14,400 --> 00:01:17,600
de junio de 2021 el 22

33
00:01:17,600 --> 00:01:19,920
y el 29 cuando tengamos discusiones  en

34
00:01:19,920 --> 00:01:21,040
24.1

35
00:01:21,040 --> 00:01:24,479
y 24.2 en este documento y, con suerte,

36
00:01:24,479 --> 00:01:27,280
con los autores que se unen

37
00:01:27,280 --> 00:01:31,520
hoy en actin livestream número

38
00:01:31,520 --> 00:01:33,680
24.0, intentaremos establecer un

39
00:01:33,680 --> 00:01:35,840
contexto y dar una introducción

40
00:01:35,840 --> 00:01:38,400
al siguiente documento, una

41
00:01:38,400 --> 00:01:40,479
evaluación empírica de la inferencia activa en

42
00:01:40,479 --> 00:01:41,600


43
00:01:41,600 --> 00:01:45,040
bandidos con múltiples brazos por  los autores enumerados aquí

44
00:01:45,040 --> 00:01:47,200
y el video son solo una introducción a

45
00:01:47,200 --> 00:01:48,799
algunas de las

46
00:01:48,799 --> 00:01:51,360
ideas, no es una revisión o una palabra final,

47
00:01:51,360 --> 00:01:53,200
es como una

48
00:01:53,200 --> 00:01:55,280
intersección de tres vías, tenemos personas que

49
00:01:55,280 --> 00:01:56,960
tal vez están dentro de la

50
00:01:56,960 --> 00:01:58,320
comunidad de inferencia activa y buscan ser

51
00:01:58,320 --> 00:02:00,079
expuestos  algunas áreas diferentes, como

52
00:02:00,079 --> 00:02:02,479
estadísticas bayesianas o aprendizaje automático,

53
00:02:02,479 --> 00:02:04,799
el segundo camino es para aquellos que provienen

54
00:02:04,799 --> 00:02:06,640
de estadísticas bayesianas o

55
00:02:06,640 --> 00:02:07,600
enfoques de aprendizaje automático

56
00:02:07,600 --> 00:02:09,840
y sienten curiosidad por la inferencia activa y

57
00:02:09,840 --> 00:02:11,440
luego, por supuesto, esperamos que esto sea

58
00:02:11,440 --> 00:02:12,720
emocionante e interesante,

59
00:02:12,720 --> 00:02:14,560
incluso si no está familiarizado con la inferencia activa.

60
00:02:14,560 --> 00:02:16,239
inferencia o aprendizaje automático

61
00:02:16,239 --> 00:02:17,920
, con suerte intentaremos conectarlo con

62
00:02:17,920 --> 00:02:19,360
algunas preguntas más amplias sobre el

63
00:02:19,360 --> 00:02:21,840
comportamiento y la toma de decisiones de

64
00:02:21,840 --> 00:02:22,959
manera más amplia.

65
00:02:22,959 --> 00:02:24,480
Vamos a repasar los objetivos y

66
00:02:24,480 --> 00:02:26,720
afirmaciones del artículo, el resumen en la

67
00:02:26,720 --> 00:02:28,080
hoja de ruta que

68
00:02:28,080 --> 00:02:29,920
cubre algunas preguntas importantes y luego

69
00:02:29,920 --> 00:02:31,519
vamos a repasar todas las

70
00:02:31,519 --> 00:02:32,239
cifras

71
00:02:32,239 --> 00:02:34,080
y algunos de los formalismos clave del

72
00:02:34,080 --> 00:02:36,879
artículo para que, ya sea que lea  el documento

73
00:02:36,879 --> 00:02:37,519
o

74
00:02:37,519 --> 00:02:39,920
no, con suerte estará en un buen lugar para

75
00:02:39,920 --> 00:02:41,760
hacer preguntas y aprender más

76
00:02:41,760 --> 00:02:44,400
y, por supuesto, en el punto uno y el punto dos

77
00:02:44,400 --> 00:02:46,000
en las próximas semanas discutiremos

78
00:02:46,000 --> 00:02:47,200
este mismo documento,

79
00:02:47,200 --> 00:02:49,360
así que guarde y envíe sus preguntas y

80
00:02:49,360 --> 00:02:50,720
permítanos  sepa si le gustaría

81
00:02:50,720 --> 00:02:54,800
participar o contribuir de alguna manera

82
00:02:55,120 --> 00:02:58,480
aquí estamos en el documento en sí que

83
00:02:58,480 --> 00:03:01,680
tiene una captura de pantalla de la portada en esta

84
00:03:01,680 --> 00:03:05,360
diapositiva leeré los objetivos y reclamos

85
00:03:05,360 --> 00:03:06,400
y luego azul puede

86
00:03:06,400 --> 00:03:08,000
dar una primera idea sobre qué  usted pensó que

87
00:03:08,000 --> 00:03:09,840
eran piezas geniales sobre

88
00:03:09,840 --> 00:03:13,120
lo que pretendían o afirmaban en este

89
00:03:13,120 --> 00:03:13,840


90
00:03:13,840 --> 00:03:15,920
documento, proporcionamos una comparación empírica

91
00:03:15,920 --> 00:03:17,760
entre la inferencia activa,

92
00:03:17,760 --> 00:03:19,440
un marco teórico de información bayesiano

93
00:03:19,440 --> 00:03:21,599
y dos

94
00:03:21,599 --> 00:03:23,440
algoritmos de aprendizaje automático de última generación

95
00:03:23,440 --> 00:03:26,720
límite de confianza superior bayesiano ucb a  y el

96
00:03:26,720 --> 00:03:28,799
muestreo optimista de Thompson en

97
00:03:28,799 --> 00:03:30,799


98
00:03:30,799 --> 00:03:33,840
bandidos estocásticos de múltiples brazos estacionarios y no estacionarios,

99
00:03:33,840 --> 00:03:35,519
introdujimos un

100
00:03:35,519 --> 00:03:36,720
algoritmo de inferencia activo aproximado

101
00:03:36,720 --> 00:03:38,799
para el cual nuestras comprobaciones en el

102
00:03:38,799 --> 00:03:40,080
problema del bandido estacionario

103
00:03:40,080 --> 00:03:41,760
mostraron que su rendimiento

104
00:03:41,760 --> 00:03:43,280
sigue de cerca al de la

105
00:03:43,280 --> 00:03:46,720
versión exacta y, por lo tanto, derivamos un

106
00:03:46,720 --> 00:03:48,319
algoritmo de inferencia activo  que es

107
00:03:48,319 --> 00:03:50,319
eficiente y fácilmente escalable

108
00:03:50,319 --> 00:03:53,200
a problemas de alta dimensión, entonces, ¿qué fue lo

109
00:03:53,200 --> 00:03:55,439
bueno de eso o qué te entusiasmó

110
00:03:55,439 --> 00:03:55,920
para

111
00:03:55,920 --> 00:03:59,680
hacer este punto cero?

112
00:03:59,680 --> 00:04:00,239


113
00:04:00,239 --> 00:04:03,680


114
00:04:03,680 --> 00:04:04,319


115
00:04:04,319 --> 00:04:06,560


116
00:04:06,560 --> 00:04:07,760


117
00:04:07,760 --> 00:04:10,640
realmente bastante difícil,

118
00:04:10,640 --> 00:04:12,159
así que creo que los autores hicieron un gran

119
00:04:12,159 --> 00:04:13,280
trabajo al

120
00:04:13,280 --> 00:04:15,519
derivar este algoritmo de inferencia activa

121
00:04:15,519 --> 00:04:17,199
y demostrar que es

122
00:04:17,199 --> 00:04:21,120
útil de acuerdo e hicieron un trabajo increíble al

123
00:04:21,120 --> 00:04:24,160
incorporarlo analíticamente como con

124
00:04:24,160 --> 00:04:25,919
ecuaciones

125
00:04:25,919 --> 00:04:28,320
en línea o al menos yuxtaponerlo a

126
00:04:28,320 --> 00:04:29,919
otros enfoques en el aprendizaje automático.

127
00:04:29,919 --> 00:04:32,240
en lugar de apelar a un

128
00:04:32,240 --> 00:04:33,440
cuerpo cualitativo de teoría

129
00:04:33,440 --> 00:04:35,520
lo cual también es genial, este es definitivamente

130
00:04:35,520 --> 00:04:36,880
uno en el que las

131
00:04:36,880 --> 00:04:40,000
afirmaciones son específicas y exactas y eso es

132
00:04:40,000 --> 00:04:40,720
lo que haremos un

133
00:04:40,720 --> 00:04:43,840
seguimiento, por

134
00:04:44,479 --> 00:04:46,400
lo que el resumen leeré la primera mitad

135
00:04:46,400 --> 00:04:48,960
y luego puede optar por la segunda mitad,

136
00:04:48,960 --> 00:04:51,280
una característica clave de la decisión secuencial.

137
00:04:51,280 --> 00:04:53,120
hacer bajo incertidumbre

138
00:04:53,120 --> 00:04:56,400
es una necesidad de equilibrar entre explotar

139
00:04:56,400 --> 00:04:58,000
elegir la mejor acción de acuerdo con

140
00:04:58,000 --> 00:05:00,080
el conocimiento actual y explorar

141
00:05:00,080 --> 00:05:02,320
obtener información sobre los valores de

142
00:05:02,320 --> 00:05:03,680
otras acciones

143
00:05:03,680 --> 00:05:05,759
el problema del bandido de múltiples brazos una

144
00:05:05,759 --> 00:05:07,600
tarea clásica que captura esta

145
00:05:07,600 --> 00:05:08,560
compensación

146
00:05:08,560 --> 00:05:10,560
sirvió como vehículo en el aprendizaje automático

147
00:05:10,560 --> 00:05:12,800
para el desarrollo de algoritmos de bandido que

148
00:05:12,800 --> 00:05:14,560
demostraron ser útiles en numerosas

149
00:05:14,560 --> 00:05:17,440
aplicaciones industriales el

150
00:05:17,440 --> 00:05:18,800
marco de inferencia activa

151
00:05:18,800 --> 00:05:20,320
en el enfoque de la toma de decisiones secuencial

152
00:05:20,320 --> 00:05:22,320
desarrollado recientemente en

153
00:05:22,320 --> 00:05:24,000
neurociencia para comprender

154
00:05:24,000 --> 00:05:26,080
el comportamiento humano y animal se

155
00:05:26,080 --> 00:05:27,840
distingue por su sofisticada

156
00:05:27,840 --> 00:05:28,720
estrategia

157
00:05:28,720 --> 00:05:30,479
para resolver el

158
00:05:30,479 --> 00:05:32,479
intercambio de explotación de exploración que

159
00:05:32,479 --> 00:05:34,400
esto hace activo  inferencia una interesante

160
00:05:34,400 --> 00:05:36,720
alternativa a las ya establecidas  Hed

161
00:05:36,720 --> 00:05:39,360
algoritmos de bandidos, por lo que es

162
00:05:39,360 --> 00:05:39,919
increíble, las

163
00:05:39,919 --> 00:05:42,160
primeras palabras se trata de la

164
00:05:42,160 --> 00:05:43,039
toma de decisiones secuenciales

165
00:05:43,039 --> 00:05:46,160
bajo incertidumbre y la tarea de bandidos

166
00:05:46,160 --> 00:05:46,560
se

167
00:05:46,560 --> 00:05:49,199
hizo para explorar que el aprendizaje automático

168
00:05:49,199 --> 00:05:50,000
ya ha

169
00:05:50,000 --> 00:05:52,160
obtenido mucho valor de la búsqueda de

170
00:05:52,160 --> 00:05:54,000
algoritmos para abordar

171
00:05:54,000 --> 00:05:56,960
este problema de bandidos de múltiples brazos y luego

172
00:05:56,960 --> 00:05:57,440
ingresar.

173
00:05:57,440 --> 00:06:00,240
inferencia activa que se desarrolló

174
00:06:00,240 --> 00:06:01,199
inicialmente para

175
00:06:01,199 --> 00:06:03,600
cubrir casos de comportamiento humano y animal,

176
00:06:03,600 --> 00:06:05,680
pero como lo estamos viendo, también va

177
00:06:05,680 --> 00:06:06,080
más allá

178
00:06:06,080 --> 00:06:08,960
y eso motiva a estudiar

179
00:06:08,960 --> 00:06:10,319
la inferencia activa

180
00:06:10,319 --> 00:06:12,080
en el contexto de los problemas de bandidos de múltiples brazos

181
00:06:12,080 --> 00:06:13,840
, así que ve a la segunda

182
00:06:13,840 --> 00:06:17,440
parte aquí  Derivamos un algoritmo de

183
00:06:17,440 --> 00:06:19,520
inferencia activo aproximado eficiente y escalable

184
00:06:19,520 --> 00:06:20,080


185
00:06:20,080 --> 00:06:22,080
y lo comparamos con dos algoritmos en bandas de última generación.

186
00:06:22,080 --> 00:06:23,600


187
00:06:23,600 --> 00:06:25,600
Límite de confianza superior bayesiano y

188
00:06:25,600 --> 00:06:27,680
muestreo de Thompson optimista.

189
00:06:27,680 --> 00:06:29,759
Esta comparación se realiza en dos tipos de

190
00:06:29,759 --> 00:06:30,880
problemas de bandidos,

191
00:06:30,880 --> 00:06:32,880
un bandido de conmutación estacionario y dinámico.

192
00:06:32,880 --> 00:06:35,440
La evaluación empírica

193
00:06:35,440 --> 00:06:36,800
muestra que el

194
00:06:36,800 --> 00:06:38,639
algoritmo de inferencia activa no produce resultados eficientes a

195
00:06:38,639 --> 00:06:39,759
largo plazo.  El comportamiento de m

196
00:06:39,759 --> 00:06:42,160
en bandidos estacionarios, sin embargo, en el

197
00:06:42,160 --> 00:06:43,759


198
00:06:43,759 --> 00:06:44,400
algoritmo de bandido de conmutación más desafiante

199
00:06:44,400 --> 00:06:46,160
o la inferencia activa de bandido de conmutación

200
00:06:46,160 --> 00:06:47,759
funciona sustancialmente mejor

201
00:06:47,759 --> 00:06:49,599
que los dos algoritmos en bandas de última generación

202
00:06:49,599 --> 00:06:50,880
,

203
00:06:50,880 --> 00:06:52,880
los resultados abren lugares emocionantes para

204
00:06:52,880 --> 00:06:54,720
futuras investigaciones en

205
00:06:54,720 --> 00:06:55,919
aprendizaje automático teórico y aplicado

206
00:06:55,919 --> 00:06:58,240
, así como  dan credibilidad adicional

207
00:06:58,240 --> 00:06:59,919
a la inferencia activa como un

208
00:06:59,919 --> 00:07:01,199
marco general para estudiar

209
00:07:01,199 --> 00:07:03,759
el comportamiento humano y animal, por lo que esto es

210
00:07:03,759 --> 00:07:05,120
realmente bueno

211
00:07:05,120 --> 00:07:07,840
porque toma como inferencia activa como una

212
00:07:07,840 --> 00:07:09,360
forma aproximada en que los

213
00:07:09,360 --> 00:07:11,599
humanos deducen la razón equilibran este

214
00:07:11,599 --> 00:07:13,520


215
00:07:13,520 --> 00:07:16,960
paradigma de explotación de exploración y lo programan en el

216
00:07:16,960 --> 00:07:17,840
marco

217
00:07:17,840 --> 00:07:19,759
para  solo muestra que sabes que se está

218
00:07:19,759 --> 00:07:21,840
acercando más al pensamiento humano

219
00:07:21,840 --> 00:07:22,560


220
00:07:22,560 --> 00:07:25,919
en una máquina, cada vez más, creo que

221
00:07:25,919 --> 00:07:28,479
sí, y hay una especie de par de pares a los

222
00:07:28,479 --> 00:07:29,759


223
00:07:29,759 --> 00:07:31,759
que volveremos varias veces en esta discusión, el

224
00:07:31,759 --> 00:07:33,840
primero es el  dos tipos de problemas

225
00:07:33,840 --> 00:07:36,240
el estacionario y el dinámico bandido

226
00:07:36,240 --> 00:07:36,960


227
00:07:36,960 --> 00:07:38,400
cual de ellos es estático  de ellos está

228
00:07:38,400 --> 00:07:39,919
cambiando, vamos a hablar más sobre

229
00:07:39,919 --> 00:07:40,560
eso

230
00:07:40,560 --> 00:07:42,639
y el otro par que aparece a

231
00:07:42,639 --> 00:07:45,039
menudo es el límite de confianza superior

232
00:07:45,039 --> 00:07:47,680
bayesiano y el muestreo optimista de Thompson

233
00:07:47,680 --> 00:07:49,440
, también vamos a volver a eso, por lo

234
00:07:49,440 --> 00:07:51,520
que están haciendo una especie de  enfoque de par de

235
00:07:51,520 --> 00:07:54,319
pares y luego los resultados son

236
00:07:54,319 --> 00:07:55,680
realmente fascinantes y vamos a

237
00:07:55,680 --> 00:07:56,720
desglosar

238
00:07:56,720 --> 00:07:59,599
que en realidad en el caso más simple vemos

239
00:07:59,599 --> 00:08:01,440
que el algoritmo de inferencia activa

240
00:08:01,440 --> 00:08:04,160
no funciona a la perfección, pero en este caso

241
00:08:04,160 --> 00:08:05,360
dinámico más desafiante

242
00:08:05,360 --> 00:08:07,039
lo hace mejor que el estado  del

243
00:08:07,039 --> 00:08:08,560
arte, entonces, ¿cómo se llama algo que

244
00:08:08,560 --> 00:08:11,520
va más allá del estado del arte?

245
00:08:11,520 --> 00:08:14,720
aquí está la hoja de ruta para el artículo y, por

246
00:08:14,720 --> 00:08:15,360
supuesto,

247
00:08:15,360 --> 00:08:18,160
como con estos videos 0, si tiene curiosidad

248
00:08:18,160 --> 00:08:18,800
acerca de

249
00:08:18,800 --> 00:08:20,400
cómo se indicó específicamente en el

250
00:08:20,400 --> 00:08:22,319
artículo o si desea sumergirse

251
00:08:22,319 --> 00:08:24,400
desea obtener más información y desea ver cómo

252
00:08:24,400 --> 00:08:26,400
citaron o cómo desarrollaron un reclamo,

253
00:08:26,400 --> 00:08:27,919
debe ir al documento en sí,

254
00:08:27,919 --> 00:08:30,400
esta es solo la hoja de ruta para ello,

255
00:08:30,400 --> 00:08:31,919
comienzan con una introducción

256
00:08:31,919 --> 00:08:34,719
del bandido de múltiples brazos y cubren los

257
00:08:34,719 --> 00:08:36,559
dos tipos de  banda  es que exploran

258
00:08:36,559 --> 00:08:38,240
cuál es la versión estacionaria y la de conmutación

259
00:08:38,240 --> 00:08:40,320
y hablan sobre cómo evalúa el

260
00:08:40,320 --> 00:08:40,958
rendimiento

261
00:08:40,958 --> 00:08:43,839
en diferentes versiones, luego

262
00:08:43,839 --> 00:08:45,600
presentan los algoritmos que

263
00:08:45,600 --> 00:08:46,320
van a

264
00:08:46,320 --> 00:08:49,600
utilizar y hablan sobre este

265
00:08:49,600 --> 00:08:51,600
enfoque de sonrisa variacional del que cubriremos solo un

266
00:08:51,600 --> 00:08:53,120
poco  pero

267
00:08:53,120 --> 00:08:54,640
espero escuchar a los autores

268
00:08:54,640 --> 00:08:57,200
sobre lo que hace,

269
00:08:57,200 --> 00:09:00,320
luego hay resultados para el par de

270
00:09:00,320 --> 00:09:02,000
problemas que exploran

271
00:09:02,000 --> 00:09:03,440
bandidos estacionarios y de conmutación

272
00:09:03,440 --> 00:09:05,279
y luego tienen cinco cifras que

273
00:09:05,279 --> 00:09:08,000
revisaremos para mostrar algunos resultados y, con

274
00:09:08,000 --> 00:09:08,720
suerte,

275
00:09:08,720 --> 00:09:11,839
incluso si los algoritmos o los formalismos

276
00:09:11,839 --> 00:09:13,680
fueron un poco difíciles de seguir las

277
00:09:13,680 --> 00:09:15,040
cifras son realmente claras

278
00:09:15,040 --> 00:09:17,279
y muestran cómo funcionan los algoritmos a lo

279
00:09:17,279 --> 00:09:19,360
largo del tiempo y cierran con una discusión

280
00:09:19,360 --> 00:09:21,440
que toca algunos puntos generales asombrosos

281
00:09:21,440 --> 00:09:22,959
para las comunidades de inferencia activa y aprendizaje automático

282
00:09:22,959 --> 00:09:25,360


283
00:09:25,360 --> 00:09:26,880
aquí están las palabras clave que se proporcionaron

284
00:09:26,880 --> 00:09:29,120
con el  papel, por lo que, como de costumbre, vamos

285
00:09:29,120 --> 00:09:29,440
a

286
00:09:29,440 --> 00:09:31,920
utilizar estas palabras clave como punto de partida, pero

287
00:09:31,920 --> 00:09:32,560
también

288
00:09:32,560 --> 00:09:35,279
como punto de partida para aquellos  que podría estar

289
00:09:35,279 --> 00:09:37,519
familiarizado con la toma de decisiones secuenciales,

290
00:09:37,519 --> 00:09:40,720
también conocida como vida, pero que no está familiarizado con las

291
00:09:40,720 --> 00:09:42,720
estadísticas bayesianas y vamos a

292
00:09:42,720 --> 00:09:44,800
comenzar con la toma de decisiones secuenciales

293
00:09:44,800 --> 00:09:45,360
y

294
00:09:45,360 --> 00:09:47,360
luego hablar más ampliamente sobre

295
00:09:47,360 --> 00:09:48,640


296
00:09:48,640 --> 00:09:51,120
los bandidos con múltiples brazos de inferencia bayesiana, por lo que está totalmente bien

297
00:09:51,120 --> 00:09:52,800
si usted  ni siquiera he oído hablar del problema de los bandidos

298
00:09:52,800 --> 00:09:53,680
,

299
00:09:53,680 --> 00:09:55,200
entonces vamos a hablar sobre esos dos

300
00:09:55,200 --> 00:09:56,800
algoritmos diferentes que van

301
00:09:56,800 --> 00:09:57,760
a explorar el

302
00:09:57,760 --> 00:09:59,440
límite de confianza superior y el

303
00:09:59,440 --> 00:10:01,440
muestreo de Thompson y luego

304
00:10:01,440 --> 00:10:02,959
ver cómo hablaron sobre la

305
00:10:02,959 --> 00:10:04,240
inferencia activa que va a ser realmente

306
00:10:04,240 --> 00:10:05,200
forma distinta en

307
00:10:05,200 --> 00:10:07,600
relación con muchos enfoques que hemos

308
00:10:07,600 --> 00:10:10,160
visto anteriormente,

309
00:10:10,160 --> 00:10:12,320
así que pasemos a la toma de decisiones secuencial

310
00:10:12,320 --> 00:10:13,200


311
00:10:13,200 --> 00:10:16,399
azul, ¿qué diría sobre esto?

312
00:10:16,399 --> 00:10:18,240
Entonces, la toma de decisiones secuenciales depende

313
00:10:18,240 --> 00:10:18,560
del

314
00:10:18,560 --> 00:10:21,360
tiempo t correcto, así que un paso de tiempo tiene un

315
00:10:21,360 --> 00:10:22,640
estado del sistema

316
00:10:22,640 --> 00:10:25,360
que realiza.  una acción y eso altera

317
00:10:25,360 --> 00:10:26,160
el sistema

318
00:10:26,160 --> 00:10:28,000
correctamente, de modo que en el segundo paso de tiempo

319
00:10:28,000 --> 00:10:29,839
el sistema ahora está en un nuevo estado y

320
00:10:29,839 --> 00:10:31,440
luego tiene que tomar otra decisión

321
00:10:31,440 --> 00:10:32,560
sobre qué  lo que vas a hacer

322
00:10:32,560 --> 00:10:34,480
con el sistema, así que esto es como conducir

323
00:10:34,480 --> 00:10:35,680
un vehículo,

324
00:10:35,680 --> 00:10:37,440
administrar una cartera de acciones, jugar un

325
00:10:37,440 --> 00:10:39,519
juego de ajedrez, decisiones políticas secuenciales

326
00:10:39,519 --> 00:10:40,480


327
00:10:40,480 --> 00:10:43,040
y, por lo tanto, te gusta yuxtaponer lo que no es

328
00:10:43,040 --> 00:10:44,320
un

329
00:10:44,320 --> 00:10:46,320
problema secuencial para que sea algo así como la

330
00:10:46,320 --> 00:10:48,079
clasificación de imágenes no lo es.  secuencial como si

331
00:10:48,079 --> 00:10:49,680
pudieras clasificar todas las imágenes en

332
00:10:49,680 --> 00:10:51,040
paralelo o a la vez

333
00:10:51,040 --> 00:10:52,480
en el estado del sistema no

334
00:10:52,480 --> 00:10:54,480
depende de cómo hayas clasificado la

335
00:10:54,480 --> 00:10:56,320
imagen anterior

336
00:10:56,320 --> 00:10:58,560
increíble así que definitivamente todo tipo de

337
00:10:58,560 --> 00:11:00,959
comportamiento del organismo en la toma de

338
00:11:00,959 --> 00:11:03,839
decisiones sucede en el tiempo así que piensa en las

339
00:11:03,839 --> 00:11:04,480
decisiones  estamos pensando

340
00:11:04,480 --> 00:11:07,040
generalmente en la toma de decisiones secuenciales,

341
00:11:07,040 --> 00:11:08,720
especialmente cuando la decisión

342
00:11:08,720 --> 00:11:11,200
influye en el futuro, esos son todos los

343
00:11:11,200 --> 00:11:12,640
tipos de problemas de los

344
00:11:12,640 --> 00:11:14,560
que vamos a hablar, pero

345
00:11:14,560 --> 00:11:17,040
también para hacerlo más amplio que eso,

346
00:11:17,040 --> 00:11:19,120
algunos problemas no secuenciales se pueden

347
00:11:19,120 --> 00:11:20,480
enmarcar secuencialmente,

348
00:11:20,480 --> 00:11:21,760
así que solo  digamos que teníamos ese

349
00:11:21,760 --> 00:11:24,000
problema de clasificación en el que se trata de un

350
00:11:24,000 --> 00:11:26,720
blob, un gran conjunto de datos y, por lo tanto, no hay

351
00:11:26,720 --> 00:11:28,079
una secuencia temporal,

352
00:11:28,079 --> 00:11:30,240
es posible que queramos un algoritmo  m que lo

353
00:11:30,240 --> 00:11:32,240
trata como si fuera secuencial

354
00:11:32,240 --> 00:11:33,760
para que pudiéramos comenzar a leer

355
00:11:33,760 --> 00:11:35,440
ejemplos y luego, después de 10, lo

356
00:11:35,440 --> 00:11:38,720
entendí bien, así que al mirarlo como

357
00:11:38,720 --> 00:11:40,399
si fuera un problema secuencial

358
00:11:40,399 --> 00:11:42,959
y estuviéramos resolviendo cosas a través del tiempo, a

359
00:11:42,959 --> 00:11:44,880
veces podemos abordar no  -problemas secuenciales de

360
00:11:44,880 --> 00:11:46,399
esa manera porque en la

361
00:11:46,399 --> 00:11:48,640
computadora va a ser secuencial en

362
00:11:48,640 --> 00:11:49,600
el procesador

363
00:11:49,600 --> 00:11:51,680
por lo que es para cosas que en realidad son

364
00:11:51,680 --> 00:11:52,959
secuenciales en el mundo

365
00:11:52,959 --> 00:11:54,880
o son para cosas que queremos

366
00:11:54,880 --> 00:11:57,600
actuar como si fueran secuenciales

367
00:11:57,600 --> 00:12:00,240
una gran tensión que  surge con todo

368
00:12:00,240 --> 00:12:01,760
tipo de modelos

369
00:12:01,760 --> 00:12:05,040
es el dilema de exploración, explotación, reducción

370
00:12:05,040 --> 00:12:08,160
de la compensación y este es un artículo asombroso de

371
00:12:08,160 --> 00:12:08,880
2015 sobre

372
00:12:08,880 --> 00:12:11,440
colinas en toda la exploración versus

373
00:12:11,440 --> 00:12:12,639
explotación

374
00:12:12,639 --> 00:12:15,760
en la mente espacial y la sociedad,

375
00:12:15,760 --> 00:12:17,360
por lo que es genial porque habla

376
00:12:17,360 --> 00:12:19,519
de múltiples dominios diferentes

377
00:12:19,519 --> 00:12:21,760
aquí en la tabla  1 hay

378
00:12:21,760 --> 00:12:22,639
forja de animales

379
00:12:22,639 --> 00:12:25,519
búsqueda visual búsqueda de información búsqueda de memoria

380
00:12:25,519 --> 00:12:26,399


381
00:12:26,399 --> 00:12:28,320
búsqueda y resolución de problemas y

382
00:12:28,320 --> 00:12:29,839
aprendizaje de grupos sociales esos son como

383
00:12:29,839 --> 00:12:33,120
todos nuestros temas favoritos azul y

384
00:12:33,120 --> 00:12:34,880
da jus  t un pequeño ejemplo visual de

385
00:12:34,880 --> 00:12:36,160
cómo

386
00:12:36,160 --> 00:12:38,639
en diferentes dominios, cómo se ve el

387
00:12:38,639 --> 00:12:40,240
arquetipo de

388
00:12:40,240 --> 00:12:42,560
exploración y cómo se ve el arquetipo de

389
00:12:42,560 --> 00:12:43,760
explotación,

390
00:12:43,760 --> 00:12:46,800
algunos de estos están

391
00:12:46,800 --> 00:12:49,600
muy relacionados con una especie de movimiento físico

392
00:12:49,600 --> 00:12:50,160


393
00:12:50,160 --> 00:12:52,560
como la exploración de forja de parches que se mueve a

394
00:12:52,560 --> 00:12:53,600
un diferente

395
00:12:53,600 --> 00:12:56,000
explotación de árboles permanecer en el mismo árbol

396
00:12:56,000 --> 00:12:57,440
pero también

397
00:12:57,440 --> 00:13:00,720
exploración de enfoque visual escanear alrededor exploración

398
00:13:00,720 --> 00:13:03,200
explotación tener una mirada fija y

399
00:13:03,200 --> 00:13:04,160
mirar fijamente

400
00:13:04,160 --> 00:13:06,720
algo y luego también podemos pensar

401
00:13:06,720 --> 00:13:07,519


402
00:13:07,519 --> 00:13:09,680
incluso en asociación de palabras como la

403
00:13:09,680 --> 00:13:10,560
exploración de memoria

404
00:13:10,560 --> 00:13:12,720
está dando grandes saltos desde diferentes

405
00:13:12,720 --> 00:13:13,920
vecindarios semánticos

406
00:13:13,920 --> 00:13:16,800
mientras que la explotación podría ser  Al igual que todos

407
00:13:16,800 --> 00:13:18,720
los animales de ganado o animales con

408
00:13:18,720 --> 00:13:20,000
la misma letra, hay diferentes

409
00:13:20,000 --> 00:13:21,920
formas de explotar porque

410
00:13:21,920 --> 00:13:23,519
hay diferentes dimensiones en el

411
00:13:23,519 --> 00:13:25,040
paisaje semántico,

412
00:13:25,040 --> 00:13:27,279
pero aún existe esta compensación entre

413
00:13:27,279 --> 00:13:28,320
saltar lejos

414
00:13:28,320 --> 00:13:30,480
o permanecer relativamente cerca en el

415
00:13:30,480 --> 00:13:31,360
vecindario,

416
00:13:31,360 --> 00:13:34,000
por lo que es una gran compensación.  se estudia en

417
00:13:34,000 --> 00:13:35,279
el comportamiento animal

418
00:13:35,279 --> 00:13:36,800
se estudia en todos los parentescos  ds de

419
00:13:36,800 --> 00:13:39,120
tareas de toma de decisiones

420
00:13:39,120 --> 00:13:42,240
cualquier cosa para agregar, solo que

421
00:13:42,240 --> 00:13:44,160
pude interactuar mucho con peter todd

422
00:13:44,160 --> 00:13:45,760
el verano pasado, que es el segundo autor de

423
00:13:45,760 --> 00:13:46,639
este artículo

424
00:13:46,639 --> 00:13:50,079
y fue muy divertido, genial y también

425
00:13:50,079 --> 00:13:52,240
ian cuisine ha hecho

426
00:13:52,240 --> 00:13:53,600
un trabajo de comportamiento colectivo increíble,

427
00:13:53,600 --> 00:13:55,440
así que es emocionante  pensar en cómo

428
00:13:55,440 --> 00:13:56,880
estos

429
00:13:56,880 --> 00:13:59,920
algoritmos pueden aplicarse a agentes individuales,

430
00:13:59,920 --> 00:14:00,959
pero también a

431
00:14:00,959 --> 00:14:02,720
grupos, y eso se insinúa varias

432
00:14:02,720 --> 00:14:05,040
veces aquí, como la asignación de roles y

433
00:14:05,040 --> 00:14:08,160
la conectividad social,

434
00:14:08,560 --> 00:14:11,040
como escuchamos en el resumen del

435
00:14:11,040 --> 00:14:13,120
documento que estamos discutiendo

436
00:14:13,120 --> 00:14:15,600
hoy, pasaron directamente de  la toma de decisiones secuenciales

437
00:14:15,600 --> 00:14:17,519
bajo incertidumbre

438
00:14:17,519 --> 00:14:20,639
para bandidos con múltiples brazos es

439
00:14:20,639 --> 00:14:22,800
una forma en que podemos estudiar eso y

440
00:14:22,800 --> 00:14:23,680
del artículo

441
00:14:23,680 --> 00:14:25,839
aquí es donde estamos introduciendo

442
00:14:25,839 --> 00:14:27,760
ese problema doble que los dos problemas

443
00:14:27,760 --> 00:14:28,720
están

444
00:14:28,720 --> 00:14:30,800
resolviendo consideramos dos tipos de problemas de bandidos

445
00:14:30,800 --> 00:14:33,279
en nuestra evaluación empírica

446
00:14:33,279 --> 00:14:35,360
un bandido estacionario como un

447
00:14:35,360 --> 00:14:36,880
problema de aprendizaje automático clásico y un

448
00:14:36,880 --> 00:14:37,519
bandido de conmutación

449
00:14:37,519 --> 00:14:39,600
comúnmente utilizado en neurociencia, por lo que vamos

450
00:14:39,600 --> 00:14:41,760
a entrar en más detalles sobre

451
00:14:41,760 --> 00:14:43,199
cómo  estos están definidos técnicamente,

452
00:14:43,199 --> 00:14:45,440
pero comencemos con lo que la gente

453
00:14:45,440 --> 00:14:47,519
está buscando con el bandido de múltiples brazos,

454
00:14:47,519 --> 00:14:50,000
¿por qué es algo que tanta gente

455
00:14:50,000 --> 00:14:51,839
ha abordado?

456
00:14:51,839 --> 00:14:53,519
Esto hará que los resultados presentados

457
00:14:53,519 --> 00:14:54,880
que están haciendo aquí sean

458
00:14:54,880 --> 00:14:56,399
directamente relevantes no solo para la

459
00:14:56,399 --> 00:14:58,000
comunidad de aprendizaje automático.

460
00:14:58,000 --> 00:14:59,600
pero también para estudios de aprendizaje y toma de

461
00:14:59,600 --> 00:15:01,600
decisiones en neurociencia que a

462
00:15:01,600 --> 00:15:02,880
menudo utilizan

463
00:15:02,880 --> 00:15:04,480
el marco de inferencia activa para una

464
00:15:04,480 --> 00:15:06,720
amplia gama de preguntas de investigación,

465
00:15:06,720 --> 00:15:08,560
por lo que hay todas estas áreas diferentes

466
00:15:08,560 --> 00:15:10,399
aquí hay un bandido de múltiples brazos que decide qué

467
00:15:10,399 --> 00:15:11,600
área estudiar

468
00:15:11,600 --> 00:15:14,160
ciencias de la computación aprendizaje automático

469
00:15:14,160 --> 00:15:15,120
economía

470
00:15:15,120 --> 00:15:18,160
neurociencia estas son  todas las áreas en las

471
00:15:18,160 --> 00:15:20,079
que el bandido de múltiples brazos es como un

472
00:15:20,079 --> 00:15:21,760
puente entre ellas,

473
00:15:21,760 --> 00:15:24,160
así que ahora estamos sentados en la inferencia activa

474
00:15:24,160 --> 00:15:26,320
justo en ese

475
00:15:26,320 --> 00:15:27,760
nexo. Hemos hablado mucho sobre conectar la

476
00:15:27,760 --> 00:15:30,160
informática con el comportamiento

477
00:15:30,160 --> 00:15:32,639
o conectar la neurociencia con la economía.

478
00:15:32,639 --> 00:15:33,759


479
00:15:33,759 --> 00:15:36,639
nexo común ¿y si eso fuera

480
00:15:36,639 --> 00:15:37,839
una inferencia activa?

481
00:15:37,839 --> 00:15:39,519
Estas son cosas divertidas de las que hablar,

482
00:15:39,519 --> 00:15:40,880


483
00:15:40,880 --> 00:15:43,920
pero no lo son.  Es solo un nexo de

484
00:15:43,920 --> 00:15:46,160
conexión conceptual, el bandido de hierro múltiple y

485
00:15:46,160 --> 00:15:47,279
la inferencia activa,

486
00:15:47,279 --> 00:15:48,959
hay muchos casos de uso realmente específicos

487
00:15:48,959 --> 00:15:51,040
y muchos de los algoritmos que

488
00:15:51,040 --> 00:15:54,639
impulsan nuestra experiencia en línea están realmente

489
00:15:54,639 --> 00:15:55,440
entrenados

490
00:15:55,440 --> 00:15:58,959
y se ajustan a los problemas de bandido de múltiples brazos,

491
00:15:58,959 --> 00:16:01,279
así que aquí hay algunos divertidos.  Los ejemplos que encontramos

492
00:16:01,279 --> 00:16:02,000


493
00:16:02,000 --> 00:16:05,680
mientras investigamos aquí en la parte superior

494
00:16:05,680 --> 00:16:09,120
izquierda muestran cómo tienes un

495
00:16:09,120 --> 00:16:11,360
bandido de múltiples brazos que desempeña un papel en las

496
00:16:11,360 --> 00:16:12,720
recomendaciones musicales,

497
00:16:12,720 --> 00:16:15,519
por lo que es como el brazo que

498
00:16:15,519 --> 00:16:16,560
se elige,

499
00:16:16,560 --> 00:16:18,399
esa es la canción, por lo que está pensando en

500
00:16:18,399 --> 00:16:20,320
ello desde el  desde el punto de vista de la

501
00:16:20,320 --> 00:16:21,120
plataforma de música

502
00:16:21,120 --> 00:16:23,920
, está enviando una canción y luego el usuario objetivo,

503
00:16:23,920 --> 00:16:24,560


504
00:16:24,560 --> 00:16:26,959
que es la máquina bandida aquí, le devuelve un

505
00:16:26,959 --> 00:16:28,880
pago al algoritmo con los

506
00:16:28,880 --> 00:16:31,839
pulgares hacia arriba o hacia abajo y luego el

507
00:16:31,839 --> 00:16:34,079
algoritmo le envía otra canción

508
00:16:34,079 --> 00:16:35,839
y luego se le da un pago, por lo que es

509
00:16:35,839 --> 00:16:37,759
Toma de decisiones secuencial

510
00:16:37,759 --> 00:16:40,320
y es esa misma relación la que se

511
00:16:40,320 --> 00:16:40,880
muestra

512
00:16:40,880 --> 00:16:43,040
gráficamente. El objetivo es maximizar la

513
00:16:43,040 --> 00:16:44,800
suma de las calificaciones frente a maximizar la

514
00:16:44,800 --> 00:16:46,560
suma de los pagos en un resumen.  t

515
00:16:46,560 --> 00:16:47,680
problema

516
00:16:47,680 --> 00:16:50,560
aquí hay un ejemplo de sitio web a b

517
00:16:50,560 --> 00:16:52,560
probando versiones de prueba de un sitio web,

518
00:16:52,560 --> 00:16:54,880
por lo que en la parte superior hay cuatro versiones del

519
00:16:54,880 --> 00:16:56,000
sitio web

520
00:16:56,000 --> 00:16:58,320
y luego cada una se asigna a

521
00:16:58,320 --> 00:16:59,839
una cuarta parte de los usuarios

522
00:16:59,839 --> 00:17:01,920
y luego cada uno de los usuarios permanece

523
00:17:01,920 --> 00:17:03,440
en el sitio para  una cierta cantidad de tiempo

524
00:17:03,440 --> 00:17:05,679
o permaneciendo por diferentes cantidades de veces

525
00:17:05,679 --> 00:17:07,439
en la prueba estándar a b durante

526
00:17:07,439 --> 00:17:09,520
toda la duración de su

527
00:17:09,520 --> 00:17:13,119
prueba, mantiene esa cuarta parte para cada sitio,

528
00:17:13,119 --> 00:17:15,280
pero en el bandido de múltiples brazos comienza

529
00:17:15,280 --> 00:17:16,319
con una cuarta parte,

530
00:17:16,319 --> 00:17:18,000
pero luego muy rápidamente  vemos que este

531
00:17:18,000 --> 00:17:20,720
azul comienza a funcionar mejor

532
00:17:20,720 --> 00:17:22,720
y luego seguimos explorando y

533
00:17:22,720 --> 00:17:25,199
dedicando algo de tiempo a estos otros

534
00:17:25,199 --> 00:17:27,839
colores, pero vemos que el azul

535
00:17:27,839 --> 00:17:28,559


536
00:17:28,559 --> 00:17:31,440
domina de manera bastante constante y luego esa línea negra

537
00:17:31,440 --> 00:17:32,000
termina siendo

538
00:17:32,000 --> 00:17:34,960
más alta, por lo que en general un número más alto al

539
00:17:34,960 --> 00:17:36,960
final del  época, por lo que está

540
00:17:36,960 --> 00:17:39,280
ganando mientras aprende porque

541
00:17:39,280 --> 00:17:40,240


542
00:17:40,240 --> 00:17:43,840
puede explorar mientras también está

543
00:17:43,840 --> 00:17:45,039
explotando

544
00:17:45,039 --> 00:17:47,840
y hay documentos específicamente sobre eso

545
00:17:47,840 --> 00:17:49,200
como bandidos bayesianos

546
00:17:49,200 --> 00:17:51,280
en el contexto  t de recomendaciones personalizadas en línea

547
00:17:51,280 --> 00:17:52,960


548
00:17:52,960 --> 00:17:56,480
alguna idea sobre ese azul

549
00:17:56,480 --> 00:17:57,919
genial, así que estos son sí, estos son

550
00:17:57,919 --> 00:18:00,000
algoritmos que se usan

551
00:18:00,000 --> 00:18:02,640
todos los días y potencian gran parte de

552
00:18:02,640 --> 00:18:03,520
nuestra experiencia

553
00:18:03,520 --> 00:18:07,120
y mucho apoyo para la toma de decisiones

554
00:18:07,120 --> 00:18:09,200
aquí es donde traemos algunos de los

555
00:18:09,200 --> 00:18:11,440
algoritmos bayesianos

556
00:18:11,440 --> 00:18:12,880
van a usar estos dos

557
00:18:12,880 --> 00:18:15,039
tipos de problemas de bandidos estacionarios y de

558
00:18:15,039 --> 00:18:15,840
conmutación

559
00:18:15,840 --> 00:18:18,880
y aquí está el segundo par de términos

560
00:18:18,880 --> 00:18:20,480
que van a comparar empíricamente por

561
00:18:20,480 --> 00:18:22,000
inferencia activa

562
00:18:22,000 --> 00:18:24,320
con otros dos algoritmos de bandas de última generación

563
00:18:24,320 --> 00:18:26,080
del aprendizaje automático,

564
00:18:26,080 --> 00:18:27,679
por lo que esos  quienes están familiarizados con el

565
00:18:27,679 --> 00:18:29,760
aprendizaje automático habrán visto mucho estos dos

566
00:18:29,760 --> 00:18:31,280
algoritmos,

567
00:18:31,280 --> 00:18:33,679
el primero es un algoritmo de límite de confianza superior

568
00:18:33,679 --> 00:18:34,480


569
00:18:34,480 --> 00:18:37,760
ucb y el segundo es una variante del

570
00:18:37,760 --> 00:18:39,200
muestreo de thomson llamado

571
00:18:39,200 --> 00:18:42,080
muestreo optimista de thompson y

572
00:18:42,080 --> 00:18:43,039
luego notan aquí

573
00:18:43,039 --> 00:18:45,760
los dos algoritmos que alcanzan el ucb y el

574
00:18:45,760 --> 00:18:47,360
muestreo de thomson

575
00:18:47,360 --> 00:18:48,880
rendimiento de última generación en

576
00:18:48,880 --> 00:18:51,360
varios problemas de bandidos estacionarios

577
00:18:51,360 --> 00:18:53,200
logrando arrepentimiento, que es la diferencia

578
00:18:53,200 --> 00:18:55,200
entre lo real y lo óptimo  el rendimiento

579
00:18:55,200 --> 00:18:56,480
volverá pronto, lo

580
00:18:56,480 --> 00:18:58,240
que está cerca del mejor

581
00:18:58,240 --> 00:18:59,919
arrepentimiento logarítmico posible

582
00:18:59,919 --> 00:19:01,440
y en el cambio de bandidos, el aprendizaje es

583
00:19:01,440 --> 00:19:03,280
más complejo, pero una vez que esto se tiene en cuenta,

584
00:19:03,280 --> 00:19:03,760


585
00:19:03,760 --> 00:19:05,200
ambos algoritmos exhiben un

586
00:19:05,200 --> 00:19:07,039
rendimiento de última generación,

587
00:19:07,039 --> 00:19:10,080
por lo que nunca puedes jugar perfectamente, pero

588
00:19:10,080 --> 00:19:12,000
tú  Me estoy aproximando a lo bien

589
00:19:12,000 --> 00:19:12,720
que podrías jugar

590
00:19:12,720 --> 00:19:15,280
con estos algoritmos. ¿Cómo se

591
00:19:15,280 --> 00:19:16,559
ve eso antes de entrar

592
00:19:16,559 --> 00:19:18,880
en los detalles técnicos de qué son estos

593
00:19:18,880 --> 00:19:20,880
algoritmos?

594
00:19:20,880 --> 00:19:22,960
En la parte superior izquierda, vamos a

595
00:19:22,960 --> 00:19:24,559
pensar de nuevo si se trata de

596
00:19:24,559 --> 00:19:26,559
decidir qué versión de un  sitio web

597
00:19:26,559 --> 00:19:28,480
que queremos presentar o qué canciones

598
00:19:28,480 --> 00:19:29,919
queremos presentar

599
00:19:29,919 --> 00:19:32,559
o simplemente manteniéndolo un poco abstracto en

600
00:19:32,559 --> 00:19:34,160
la parte superior izquierda, comenzamos

601
00:19:34,160 --> 00:19:36,559
con cero pruebas, así que esto es antes de que

602
00:19:36,559 --> 00:19:38,000
tengamos

603
00:19:38,000 --> 00:19:41,120
información y luego, a medida que

604
00:19:41,120 --> 00:19:44,160
ocurren las pruebas y se observan los pagos y  el

605
00:19:44,160 --> 00:19:44,720


606
00:19:44,720 --> 00:19:48,640
conteo de intentos cuenta después de 28 intentos

607
00:19:48,640 --> 00:19:50,799
, hemos alcanzado un conjunto de distribuciones muy marcadamente diferente

608
00:19:50,799 --> 00:19:52,799


609
00:19:52,799 --> 00:19:55,679
y, por lo tanto, esto en general parece

610
00:19:55,679 --> 00:19:57,360
que apareces en el casino y no

611
00:19:57,360 --> 00:19:58,559
sabes  ahora el pago de

612
00:19:58,559 --> 00:20:01,039
cualquiera de las máquinas tragamonedas y luego

613
00:20:01,039 --> 00:20:02,080


614
00:20:02,080 --> 00:20:04,880
elegirá alguna política, alguna forma de

615
00:20:04,880 --> 00:20:05,520
acercarse a

616
00:20:05,520 --> 00:20:07,840
esas máquinas tragamonedas y cambiar

617
00:20:07,840 --> 00:20:10,080
entre ellas según sea necesario,

618
00:20:10,080 --> 00:20:12,720
algún enfoque que, con suerte,

619
00:20:12,720 --> 00:20:13,600
resulte en que

620
00:20:13,600 --> 00:20:15,760
obtenga la mayor cantidad de dinero y así en este

621
00:20:15,760 --> 00:20:17,600
caso, es como si a medida que

622
00:20:17,600 --> 00:20:19,200
obtiene más y más información, está

623
00:20:19,200 --> 00:20:21,120
ajustando su estimación

624
00:20:21,120 --> 00:20:23,360
de cómo se ven las distribuciones

625
00:20:23,360 --> 00:20:25,440
, podemos ver cómo se ajusta la distribución roja a

626
00:20:25,440 --> 00:20:27,760
medida que se prueba más y más

627
00:20:27,760 --> 00:20:29,200
y de manera similar para las otras

628
00:20:29,200 --> 00:20:31,360
distribuciones, entonces  Eso

629
00:20:31,360 --> 00:20:34,320
es lo que hace este algoritmo: comienza

630
00:20:34,320 --> 00:20:35,200


631
00:20:35,200 --> 00:20:37,760
sin un sesgo específico hacia una máquina tragamonedas determinada

632
00:20:37,760 --> 00:20:38,799


633
00:20:38,799 --> 00:20:41,840
y luego trata de desarrollar una estrategia

634
00:20:41,840 --> 00:20:43,840
para quedarse con las máquinas

635
00:20:43,840 --> 00:20:46,080
tragamonedas conocidas en lugar de probar otras nuevas

636
00:20:46,080 --> 00:20:48,240
o las que no ha probado en mucho tiempo.

637
00:20:48,240 --> 00:20:49,679
para obtener el mejor

638
00:20:49,679 --> 00:20:51,520
resultado posible y, como puede imaginar,

639
00:20:51,520 --> 00:20:53,840
si hay uno estático, entonces es un

640
00:20:53,840 --> 00:20:55,039
problema más fácil

641
00:20:55,039 --> 00:20:57,360
si es dinámico, debe tener en cuenta la

642
00:20:57,360 --> 00:21:00,479
tasa de cambio en

643
00:21:00,640 --> 00:21:03,440
cualquier pensamiento  s en esa buena buena

644
00:21:03,440 --> 00:21:04,240
explicación,

645
00:21:04,240 --> 00:21:07,520
está bien, los bandidos de bernoulli son

646
00:21:07,520 --> 00:21:11,120
la clase de bandidos a los que se

647
00:21:11,120 --> 00:21:12,799
van a limitar, por

648
00:21:12,799 --> 00:21:15,280
lo que dicen que nos estamos limitando

649
00:21:15,280 --> 00:21:17,440
a una versión bien estudiada de bandidos,

650
00:21:17,440 --> 00:21:20,159
los llamados bandidos de bernoulli para bandidos de

651
00:21:20,159 --> 00:21:21,520
bernoulli

652
00:21:21,520 --> 00:21:23,600
Los resultados de elección se extraen de una

653
00:21:23,600 --> 00:21:26,240
distribución de bernoulli específica para cada

654
00:21:26,240 --> 00:21:28,080
brazo. Los bandidos de bernoulli, junto con los bandidos gaussianos,

655
00:21:28,080 --> 00:21:30,640
son la variante más comúnmente estudiada

656
00:21:30,640 --> 00:21:32,960
de bandidos multibrazo, tanto en el

657
00:21:32,960 --> 00:21:35,120
aprendizaje automático teórico y aplicado

658
00:21:35,120 --> 00:21:38,480
como en la ciencia cognitiva experimental, por lo

659
00:21:38,480 --> 00:21:41,760
que puede adaptarse a cualquier tipo de distribución

660
00:21:41,760 --> 00:21:44,720
para las recompensas subyacentes a cada uno.  de estas

661
00:21:44,720 --> 00:21:46,000
máquinas tragamonedas,

662
00:21:46,000 --> 00:21:47,840
pero resulta que si usa la

663
00:21:47,840 --> 00:21:49,679
distribución de bernoulli,

664
00:21:49,679 --> 00:21:52,960
las matemáticas funcionan muy bien, lo que hace que sea

665
00:21:52,960 --> 00:21:55,200
fácil de estudiar.

666
00:21:55,200 --> 00:21:56,799


667
00:21:56,799 --> 00:21:57,679


668
00:21:57,679 --> 00:22:00,400


669
00:22:00,400 --> 00:22:01,200


670
00:22:01,200 --> 00:22:04,000
obtenga cinco con una cierta

671
00:22:04,000 --> 00:22:05,360
curva

672
00:22:05,360 --> 00:22:07,280
de campana de cuánto podría ganar bernoulli

673
00:22:07,280 --> 00:22:08,400
va a ser diferente  distribución en forma,

674
00:22:08,400 --> 00:22:09,520


675
00:22:09,520 --> 00:22:10,960
pero la idea es

676
00:22:10,960 --> 00:22:12,640
que aprenderá los parámetros

677
00:22:12,640 --> 00:22:16,159
que describen la recompensa devuelta por

678
00:22:16,159 --> 00:22:18,480
ese brazo,

679
00:22:18,480 --> 00:22:20,960
por lo que es solo la subcategoría o la

680
00:22:20,960 --> 00:22:23,039
función que subyace al

681
00:22:23,039 --> 00:22:24,320
pago de la recompensa

682
00:22:24,320 --> 00:22:27,840
en estas máquinas

683
00:22:29,600 --> 00:22:32,640
, hablemos de los dos algoritmos que

684
00:22:32,640 --> 00:22:34,960
ellos  vamos a discutir mucho

685
00:22:34,960 --> 00:22:37,280
y luego también dónde

686
00:22:37,280 --> 00:22:39,520
entran en juego estos algoritmos en términos de estrategia,

687
00:22:39,520 --> 00:22:41,200
así que nuevamente estás sentado en la

688
00:22:41,200 --> 00:22:43,280
máquina tragamonedas en el casino

689
00:22:43,280 --> 00:22:46,640
y cómo vas a decidir

690
00:22:46,640 --> 00:22:49,679
cómo quedarte o dejar una máquina determinada

691
00:22:49,679 --> 00:22:51,360
quédese en el casino, aunque ahí es

692
00:22:51,360 --> 00:22:53,200
donde quiere estar

693
00:22:53,200 --> 00:22:57,280
esto es de una buena publicación de blog de 2019 Los

694
00:22:57,280 --> 00:22:58,960
científicos de datos han desarrollado varias

695
00:22:58,960 --> 00:23:00,880
soluciones para abordar este problema

696
00:23:00,880 --> 00:23:02,799
y los tres algoritmos más comunes son

697
00:23:02,799 --> 00:23:04,240
épsilon codicioso,

698
00:23:04,240 --> 00:23:06,000
luego límite de confianza superior y

699
00:23:06,000 --> 00:23:08,000
muestreo de thompson tan épsilon codicioso

700
00:23:08,000 --> 00:23:11,600
no se proporciona en este documento porque no es

701
00:23:11,600 --> 00:23:13,360
el algoritmo de mejor rendimiento, pero es

702
00:23:13,360 --> 00:23:14,000
realmente

703
00:23:14,000 --> 00:23:17,039
un buen tipo de algoritmo de inicio, es

704
00:23:17,039 --> 00:23:18,799
el algoritmo más simple para un  aborde la compensación de

705
00:23:18,799 --> 00:23:21,600
explotación de exploración

706
00:23:21,600 --> 00:23:23,840
básicamente durante la exploración o la

707
00:23:23,840 --> 00:23:25,120
explotación, lo siento,

708
00:23:25,120 --> 00:23:26,880
la palanca con el pago más alto conocido

709
00:23:26,880 --> 00:23:28,320
siempre se tira, así que

710
00:23:28,320 --> 00:23:30,640
cualquiera que sea la mejor estimación actual de

711
00:23:30,640 --> 00:23:32,960
la máquina tragamonedas de mayor rendimiento es la

712
00:23:32,960 --> 00:23:36,400
predeterminada allí, sin embargo, de vez en cuando

713
00:23:36,400 --> 00:23:38,880
alguna fracción aleatoria épsilon con alguna

714
00:23:38,880 --> 00:23:39,440
fracción

715
00:23:39,440 --> 00:23:40,880
el cinco por ciento o el uno por ciento

716
00:23:40,880 --> 00:23:42,480
de las veces selecciona

717
00:23:42,480 --> 00:23:45,039
otro brazo al azar para explorar los otros

718
00:23:45,039 --> 00:23:45,600
brazos

719
00:23:45,600 --> 00:23:48,159
con un resultado desconocido, de modo que te

720
00:23:48,159 --> 00:23:49,440
quedes con el que tiene la

721
00:23:49,440 --> 00:23:50,960
estimación puntual más alta

722
00:23:50,960 --> 00:23:53,279
y luego solo una fracción del tiempo

723
00:23:53,279 --> 00:23:54,880
cambias a un  uno diferente solo para

724
00:23:54,880 --> 00:23:55,919
verificar

725
00:23:55,919 --> 00:23:58,000
y luego actualiza su estimación de cómo

726
00:23:58,000 --> 00:23:59,039
les está yendo a cada uno de ellos,

727
00:23:59,039 --> 00:24:01,600
así que esa es una estrategia ahora aquí hay dos

728
00:24:01,600 --> 00:24:02,559
estrategias que funcionan

729
00:24:02,559 --> 00:24:04,320
mejor que esas son las

730
00:24:04,320 --> 00:24:06,080
que vamos a contrastar con

731
00:24:06,080 --> 00:24:08,000
la inferencia activa

732
00:24:08,000 --> 00:24:09,840
una de ellas es  el límite de confianza superior

733
00:24:09,840 --> 00:24:12,080
que a veces se denomina

734
00:24:12,080 --> 00:24:14,320
optimismo frente a la incertidumbre que

735
00:24:14,320 --> 00:24:16,080
suena como inferencia activa

736
00:24:16,080 --> 00:24:18,640
asume t  que los pagos medios desconocidos

737
00:24:18,640 --> 00:24:21,279
de cada brazo serán lo más altos posible

738
00:24:21,279 --> 00:24:24,240
según los datos históricos, por lo que no

739
00:24:24,240 --> 00:24:25,279
sabemos el pago

740
00:24:25,279 --> 00:24:28,000
de cada brazo, pero queremos asumir dado

741
00:24:28,000 --> 00:24:30,240
lo que ya hemos obtenido de los datos,

742
00:24:30,240 --> 00:24:32,240
que es lo más lejos que podemos  Podemos especular que

743
00:24:32,240 --> 00:24:33,600
queremos asumir que es tan bueno como

744
00:24:33,600 --> 00:24:34,400
podría haber sido,

745
00:24:34,400 --> 00:24:36,240
por lo que vemos el límite de confianza superior

746
00:24:36,240 --> 00:24:39,200
en la parte superior de esta distribución

747
00:24:39,200 --> 00:24:41,840
y luego el muestreo de Thompson es

748
00:24:41,840 --> 00:24:43,600
fundamentalmente una

749
00:24:43,600 --> 00:24:44,320
técnica de optimización bayesiana

750
00:24:44,320 --> 00:24:45,679
con un principio central conocido como

751
00:24:45,679 --> 00:24:47,679
coincidencia de probabilidad que puede  se puede

752
00:24:47,679 --> 00:24:48,240
resumir como

753
00:24:48,240 --> 00:24:50,720
tocar un brazo de acuerdo con su probabilidad

754
00:24:50,720 --> 00:24:51,440
de ser

755
00:24:51,440 --> 00:24:54,480
el mejor brazo, por lo que, en contraste con epsilon,

756
00:24:54,480 --> 00:24:56,159
que dice simplemente elija el que

757
00:24:56,159 --> 00:24:57,520
crea que es mejor

758
00:24:57,520 --> 00:24:59,440
y luego el diez por ciento del tiempo haga

759
00:24:59,440 --> 00:25:00,559
otra cosa, el

760
00:25:00,559 --> 00:25:02,080
muestreo de Thompson es como usted.

761
00:25:02,080 --> 00:25:03,919
tiene un gráfico circular con un rendimiento relativo

762
00:25:03,919 --> 00:25:05,120


763
00:25:05,120 --> 00:25:08,000
de diferentes brazos y luego los elige en

764
00:25:08,000 --> 00:25:09,200
función de

765
00:25:09,200 --> 00:25:12,640
qué tan grande es el pastel, por lo que rara vez

766
00:25:12,640 --> 00:25:14,880
elige los que no tienen pagos altos

767
00:25:14,880 --> 00:25:16,400
solo para verificar  en ellos,

768
00:25:16,400 --> 00:25:17,919
pero luego, si revisa uno y lo

769
00:25:17,919 --> 00:25:19,919
hizo muy bien, entonces esa porción

770
00:25:19,919 --> 00:25:21,679
del pastel comienza a crecer

771
00:25:21,679 --> 00:25:23,360
y luego el objetivo principal de entrenar

772
00:25:23,360 --> 00:25:25,760
estos algoritmos es qué tan rápido debe

773
00:25:25,760 --> 00:25:26,080


774
00:25:26,080 --> 00:25:28,720
volver a ponderar en el caso dinámico,

775
00:25:28,720 --> 00:25:29,279


776
00:25:29,279 --> 00:25:30,640
etc.  decirlo así no es la

777
00:25:30,640 --> 00:25:32,960
solución, pero esto está llegando a algunas

778
00:25:32,960 --> 00:25:33,679
formas,

779
00:25:33,679 --> 00:25:35,279
ya sea el optimismo frente a la

780
00:25:35,279 --> 00:25:37,919
incertidumbre o este tipo de combinación conservadora de

781
00:25:37,919 --> 00:25:39,600
probabilidades,

782
00:25:39,600 --> 00:25:41,600
estas son dos formas que, como hemos visto,

783
00:25:41,600 --> 00:25:43,039
son lo último en tecnología porque

784
00:25:43,039 --> 00:25:45,200
básicamente funciona lo mejor posible, por

785
00:25:45,200 --> 00:25:47,520
lo que lo estamos bloqueando con una

786
00:25:47,520 --> 00:25:50,320
confianza superior y un límite de confianza inferior.

787
00:25:50,320 --> 00:25:53,520
Es una muy buena elección de algoritmos

788
00:25:53,520 --> 00:25:55,279
que se presentan como un par instructivo en

789
00:25:55,279 --> 00:25:57,360
todo el espacio educativo de aprendizaje automático, una

790
00:25:57,360 --> 00:26:00,240
buena elección por parte del

791
00:26:00,240 --> 00:26:02,159
los autores lo yuxtaponen tan

792
00:26:02,159 --> 00:26:05,679
claramente a la inferencia activa,

793
00:26:05,679 --> 00:26:08,320
así es el muestreo de Thompson, entonces el pesimismo

794
00:26:08,320 --> 00:26:11,360
frente a la incertidumbre, las

795
00:26:11,360 --> 00:26:13,520
cosas buenas no podrían ser mejores de lo que

796
00:26:13,520 --> 00:26:16,080
han sido en el

797
00:26:16,080 --> 00:26:18,240
pasado, profundicemos un poco más en

798
00:26:18,240 --> 00:26:19,679
detalle los dos

799
00:26:19,679 --> 00:26:22,559
algoritmos diferentes y luego hable

800
00:26:22,559 --> 00:26:24,400
sobre el arrepentimiento,

801
00:26:24,400 --> 00:26:27,600
así que aquí hay otra publicación

802
00:26:27,600 --> 00:26:29,520
de blog del blog de lillian wang que

803
00:26:29,520 --> 00:26:32,559
habla sobre estrategias de bandido, por lo que

804
00:26:32,559 --> 00:26:35,360
nuevamente se trata de explorar y explotar

805
00:26:35,360 --> 00:26:35,919
a pesar de que

806
00:26:35,919 --> 00:26:38,000
la inferencia activa nos ayudará a

807
00:26:38,000 --> 00:26:39,120
reconceptualizar la

808
00:26:39,120 --> 00:26:40,799
explotación de exploración que tal vez podamos

809
00:26:40,799 --> 00:26:42,320
obtener  al final,

810
00:26:42,320 --> 00:26:44,000
pero no queremos estar explorando de manera

811
00:26:44,000 --> 00:26:45,919
ineficiente porque

812
00:26:45,919 --> 00:26:48,240
estamos gastando nuestro tiempo jugando

813
00:26:48,240 --> 00:26:49,440
en máquinas perdedoras

814
00:26:49,440 --> 00:26:51,039
mientras sabemos que hay una mejor manera

815
00:26:51,039 --> 00:26:53,520
de jugar, así que para evitar una exploración tan ineficiente

816
00:26:53,520 --> 00:26:54,240
,

817
00:26:54,240 --> 00:26:57,600
un enfoque es hacer un muestreo épsilon

818
00:26:57,600 --> 00:27:00,159
y luego, en el caso de un conjunto estático de

819
00:27:00,159 --> 00:27:00,880


820
00:27:00,880 --> 00:27:03,039
pagos, disminuye ese parámetro épsilon en el

821
00:27:03,039 --> 00:27:04,960
tiempo, así que, de nuevo, ¿qué tan rápido debe

822
00:27:04,960 --> 00:27:06,240
disminuirlo?

823
00:27:06,240 --> 00:27:07,919
Aún tiene que ajustarse a los parámetros, pero ese es

824
00:27:07,919 --> 00:27:09,919
solo un enfoque,

825
00:27:09,919 --> 00:27:13,840
el otro enfoque para evitar

826
00:27:13,840 --> 00:27:17,200
esta exploración ineficiente, así que evite el

827
00:27:17,200 --> 00:27:18,159
dolor.

828
00:27:18,159 --> 00:27:20,720
es ser optimista sobre los valores que

829
00:27:20,720 --> 00:27:21,200
son

830
00:27:21,200 --> 00:27:22,720
optimistas sobre las opciones con alta

831
00:27:22,720 --> 00:27:24,480
incertidumbre y, por lo tanto,

832
00:27:24,480 --> 00:27:26,960
prefieren acciones implícitamente para las cuales  ich

833
00:27:26,960 --> 00:27:28,799
todavía no hemos tenido una estimación del valor de confianza,

834
00:27:28,799 --> 00:27:30,559
es por eso que esto es optimismo

835
00:27:30,559 --> 00:27:32,320
frente a la incertidumbre,

836
00:27:32,320 --> 00:27:34,480
en otras palabras, favorecemos la exploración de

837
00:27:34,480 --> 00:27:36,559
acciones con un gran potencial para tener

838
00:27:36,559 --> 00:27:38,799
un valor óptimo, así que eso es exactamente lo que hace el

839
00:27:38,799 --> 00:27:39,600
algoritmo de

840
00:27:39,600 --> 00:27:42,720
límite de confianza superior ucb.

841
00:27:42,720 --> 00:27:44,799
lo mide con un límite de confianza superior

842
00:27:44,799 --> 00:27:47,520
para que el valor verdadero siempre esté

843
00:27:47,520 --> 00:27:48,320
por debajo de

844
00:27:48,320 --> 00:27:52,559
ese límite y luego estamos tratando de

845
00:27:52,559 --> 00:27:55,279
subir el límite superior sabiendo que en

846
00:27:55,279 --> 00:27:56,559
algún lugar debajo de él, con

847
00:27:56,559 --> 00:28:00,799
suerte, no muy lejos está el valor verdadero

848
00:28:00,799 --> 00:28:03,440
y luego el algoritmo ucv

849
00:28:03,440 --> 00:28:06,559
optimiza con esto  arg max

850
00:28:06,559 --> 00:28:08,159
seleccionando la acción más codiciosa para

851
00:28:08,159 --> 00:28:10,559
maximizar ese límite de confianza superior, de

852
00:28:10,559 --> 00:28:12,960
modo que, como se establece en el blog,

853
00:28:12,960 --> 00:28:14,000
básicamente no puede hacer

854
00:28:14,000 --> 00:28:17,440
ninguna exploración, es solo

855
00:28:17,440 --> 00:28:19,279
elegir la primera en la que se sienta y permanecer

856
00:28:19,279 --> 00:28:21,600
allí, puede explorar al azar

857
00:28:21,600 --> 00:28:24,960
eso es épsilon codicioso o usted  puede explorar de manera

858
00:28:24,960 --> 00:28:25,600
inteligente

859
00:28:25,600 --> 00:28:27,840
con una preferencia por la incertidumbre, por

860
00:28:27,840 --> 00:28:29,279
lo que solo estamos construyendo sobre esa

861
00:28:29,279 --> 00:28:29,840


862
00:28:29,840 --> 00:28:31,760
idea épsilon de apegarnos a la que

863
00:28:31,760 --> 00:28:33,279
generalmente nos gusta,

864
00:28:33,279 --> 00:28:35,600
pero  luego pasar a veces en otro lugar

865
00:28:35,600 --> 00:28:37,279
cuánto tiempo pasar en otro lugar y

866
00:28:37,279 --> 00:28:38,720
cuáles deberíamos elegir bien no

867
00:28:38,720 --> 00:28:40,240
solo vaya a cualquier máquina vieja si

868
00:28:40,240 --> 00:28:41,919
va a seleccionar otro lugar

869
00:28:41,919 --> 00:28:44,080
donde elijamos aquellos que todavía tienen una buena

870
00:28:44,080 --> 00:28:46,159
probabilidad de tener un alto rendimiento esperado

871
00:28:46,159 --> 00:28:47,200


872
00:28:47,200 --> 00:28:50,320
así que eso es ucb cualquier comentario sobre

873
00:28:50,320 --> 00:28:53,279
eso no, por el contrario, tenemos

874
00:28:53,279 --> 00:28:54,880
muestreo

875
00:28:54,880 --> 00:28:58,799
de thompson de una buena plataforma de diapositivas de agrowall

876
00:28:58,799 --> 00:29:01,760
columbia y el muestreo de thompson se remonta

877
00:29:01,760 --> 00:29:03,840
a 1933,

878
00:29:03,840 --> 00:29:05,679
así que, como muchos otros algoritmos, las

879
00:29:05,679 --> 00:29:07,760
variantes clásicas

880
00:29:07,760 --> 00:29:10,480
son precomputacionales, a veces

881
00:29:10,480 --> 00:29:12,640
incluso son solo experimentos mentales.

882
00:29:12,640 --> 00:29:14,720
y en las diapositivas se habla sobre cómo el

883
00:29:14,720 --> 00:29:16,159
muestreo de Thompson es una

884
00:29:16,159 --> 00:29:18,399
heurística natural y eficiente que

885
00:29:18,399 --> 00:29:19,520
mantiene la creencia

886
00:29:19,520 --> 00:29:21,760
sobre la efectividad, que es la

887
00:29:21,760 --> 00:29:23,760
principal recompensa de cada

888
00:29:23,760 --> 00:29:25,440
brazo. Vamos a hacer un seguimiento de lo

889
00:29:25,440 --> 00:29:27,440
bien que creemos que le está yendo a cada brazo a través del

890
00:29:27,440 --> 00:29:28,399
tiempo

891
00:29:28,399 --> 00:29:30,000
y  Básicamente, la forma en que funciona es que

892
00:29:30,000 --> 00:29:32,000
vamos a observar los comentarios,

893
00:29:32,000 --> 00:29:34,159
luego actualizar nuestras creencias sobre los diferentes

894
00:29:34,159 --> 00:29:36,240
brazos de una manera bayesiana

895
00:29:36,240 --> 00:29:38,159
y luego sacar un  rms con una

896
00:29:38,159 --> 00:29:40,399
probabilidad posterior de ser el mejor brazo,

897
00:29:40,399 --> 00:29:42,240
por lo que no es lo mismo que elegir el brazo

898
00:29:42,240 --> 00:29:44,399
que tiene más probabilidades de ser el mejor. De

899
00:29:44,399 --> 00:29:47,039
nuevo, es como un gráfico circular que muestra

900
00:29:47,039 --> 00:29:48,240
las proporciones

901
00:29:48,240 --> 00:29:49,760
de qué tan bien se están desempeñando y luego

902
00:29:49,760 --> 00:29:52,480
elegimos en función de esa proporción.

903
00:29:52,480 --> 00:29:56,399
y el pseudocódigo se ve así

904
00:29:56,399 --> 00:29:59,679
, comenzamos, inicializamos el modelo

905
00:29:59,679 --> 00:30:03,919
con una distribución anterior, así como la familia de

906
00:30:03,919 --> 00:30:06,240
distribuciones de las que se

907
00:30:06,240 --> 00:30:08,559
espera que se extraigan nuestras recompensas, por lo que este es un

908
00:30:08,559 --> 00:30:09,279


909
00:30:09,279 --> 00:30:10,960
caso gaussiano, pero aquí es donde podría ver

910
00:30:10,960 --> 00:30:12,960
entrar a un bandido de bernoulli  jugar

911
00:30:12,960 --> 00:30:16,720
y luego el algoritmo es el siguiente

912
00:30:16,720 --> 00:30:20,159
primero hay una muestra de una

913
00:30:20,159 --> 00:30:23,440
media con una estimación de la parte posterior

914
00:30:23,440 --> 00:30:26,799
para un brazo dado i luego los

915
00:30:26,799 --> 00:30:28,799
brazos se juegan de acuerdo con la

916
00:30:28,799 --> 00:30:29,919
probabilidad

917
00:30:29,919 --> 00:30:33,279
de que sean el mejor brazo

918
00:30:33,279 --> 00:30:36,799
se observa la recompensa y luego

919
00:30:36,799 --> 00:30:39,520
todo se actualiza  así que es como una

920
00:30:39,520 --> 00:30:41,679
muestra

921
00:30:41,679 --> 00:30:44,559
de tu posterior de tu predicción,

922
00:30:44,559 --> 00:30:44,960
luego

923
00:30:44,960 --> 00:30:48,399
actúa, luego observa y actualiza, es algo así

924
00:30:48,399 --> 00:30:49,600
como esa

925
00:30:49,600 --> 00:30:51,440
canción de la hora de cierre que sabes que cada

926
00:30:51,440 --> 00:30:52,640
comienzo proviene de algún otro

927
00:30:52,640 --> 00:30:54,159
los comienzos terminan

928
00:30:54,159 --> 00:30:56,559
y se llama posterior en las

929
00:30:56,559 --> 00:30:57,600
estadísticas bayesianas, sabes que el

930
00:30:57,600 --> 00:31:00,159
anterior se actualiza en el posterior, pero

931
00:31:00,159 --> 00:31:01,679
luego ese posterior

932
00:31:01,679 --> 00:31:04,399
es el anterior para la siguiente ronda, por lo que

933
00:31:04,399 --> 00:31:05,840
no es como si fuera solo una

934
00:31:05,840 --> 00:31:08,960
ronda de aprendizaje, el posterior se retroalimenta

935
00:31:08,960 --> 00:31:10,480
en el modelo, razón por la cual simplemente  hable

936
00:31:10,480 --> 00:31:12,559
sobre la actualización bayesiana continua,

937
00:31:12,559 --> 00:31:15,600
por lo que es como ooda como

938
00:31:15,600 --> 00:31:18,240
observar orientar decidir actuar este tipo de

939
00:31:18,240 --> 00:31:19,679
bucles de acción que,

940
00:31:19,679 --> 00:31:22,240
por supuesto, incluyen la inferencia activa es

941
00:31:22,240 --> 00:31:22,880
lo que

942
00:31:22,880 --> 00:31:26,080
hace que estos modelos sean realmente similares o al

943
00:31:26,080 --> 00:31:27,679
menos en el mismo vecindario

944
00:31:27,679 --> 00:31:28,960
y luego este artículo que estamos

945
00:31:28,960 --> 00:31:32,240
discutiendo  los alinea

946
00:31:32,240 --> 00:31:34,320
analíticamente con las ecuaciones y a

947
00:31:34,320 --> 00:31:37,440
través de la simulación y la yuxtaposición,

948
00:31:37,440 --> 00:31:39,360
eso es lo que es el muestreo de thompson, aunque

949
00:31:39,360 --> 00:31:42,240
cualquier comentario sobre thompson

950
00:31:42,240 --> 00:31:44,399
qué tan bien juega en el

951
00:31:44,399 --> 00:31:46,320
proceso de toma de decisiones secuencial del que

952
00:31:46,320 --> 00:31:47,679
hablábamos antes,

953
00:31:47,679 --> 00:31:49,200
así que tiene un próximo paso de tiempo y

954
00:31:49,200 --> 00:31:51,120
actualizas y actualizas y actualizas,

955
00:31:51,120 --> 00:31:52,960
sí, así que de nuevo, incluso para esas

956
00:31:52,960 --> 00:31:54,960
tareas no secuenciales como  la

957
00:31:54,960 --> 00:31:56,640
clasificación de imágenes que mencionaste

958
00:31:56,640 --> 00:31:59,679
, podrías muestrear de tu gran base de datos,

959
00:31:59,679 --> 00:32:01,600
luego actualizar tu modelo y luego, una vez

960
00:32:01,600 --> 00:32:02,880
que estés muestreando y estés como si realmente no estuviera

961
00:32:02,880 --> 00:32:05,120
actualizando mi modelo tanto,

962
00:32:05,120 --> 00:32:06,960
es posible que no necesites revisar todo el

963
00:32:06,960 --> 00:32:08,640
conjunto de datos

964
00:32:08,640 --> 00:32:10,960
y entonces, al enmarcar secuencialmente ese

965
00:32:10,960 --> 00:32:12,480
problema no secuencial

966
00:32:12,480 --> 00:32:15,679
, obtienes una gran velocidad computacional

967
00:32:15,679 --> 00:32:16,960
y luego, por supuesto, para la

968
00:32:16,960 --> 00:32:18,799
toma de decisiones secuenciales, entonces necesitas un

969
00:32:18,799 --> 00:32:21,519
enfoque como este,

970
00:32:22,240 --> 00:32:25,360
¿qué tal si te arrepientes?

971
00:32:25,360 --> 00:32:27,279


972
00:32:27,279 --> 00:32:30,240
Creo que

973
00:32:30,240 --> 00:32:31,840
pusiste esto aquí, la introducción al

974
00:32:31,840 --> 00:32:33,600
arrepentimiento y el aprendizaje por refuerzo, que

975
00:32:33,600 --> 00:32:33,919
es

976
00:32:33,919 --> 00:32:37,039
una publicación mediana correcta,

977
00:32:37,039 --> 00:32:38,320
así que si quieres aprender más sobre el

978
00:32:38,320 --> 00:32:40,080
arrepentimiento, puedes consultarlo allí, pero el

979
00:32:40,080 --> 00:32:40,960
arrepentimiento es

980
00:32:40,960 --> 00:32:43,679
solo la diferencia entre el

981
00:32:43,679 --> 00:32:45,519
rendimiento óptimo y cómo.  lo bueno que podría

982
00:32:45,519 --> 00:32:46,320
hacer

983
00:32:46,320 --> 00:32:48,159
y el rendimiento real, como puede

984
00:32:48,159 --> 00:32:50,320
ver en esta pequeña imagen aquí

985
00:32:50,320 --> 00:32:52,880
, puede ver que la mejor política es

986
00:32:52,880 --> 00:32:54,559
la línea de puntos roja y luego las elecciones

987
00:32:54,559 --> 00:32:55,600
que hace el agente

988
00:32:55,600 --> 00:32:58,799
son l  como el rendimiento

989
00:32:58,799 --> 00:33:01,039
logarítmico arrepentimiento logarítmico

990
00:33:01,039 --> 00:33:02,799
y están convergiendo la idea

991
00:33:02,799 --> 00:33:04,080
es converger con la mejor

992
00:33:04,080 --> 00:33:06,720
política posible basada en sus decisiones previas

993
00:33:06,720 --> 00:33:07,600


994
00:33:07,600 --> 00:33:10,320
explorando la explotación um y luego los

995
00:33:10,320 --> 00:33:11,519
autores aquí usan

996
00:33:11,519 --> 00:33:13,360
arrepentimiento cuando están mirando a los

997
00:33:13,360 --> 00:33:14,880
bandidos estacionarios

998
00:33:14,880 --> 00:33:16,240
usan el arrepentimiento como una medida de

999
00:33:16,240 --> 00:33:18,559
rendimiento, pero luego usan la

1000
00:33:18,559 --> 00:33:20,159
tasa de arrepentimiento cuando miran a los

1001
00:33:20,159 --> 00:33:22,320
bandidos que cambian, por lo que la tasa de arrepentimiento es

1002
00:33:22,320 --> 00:33:23,039
solo

1003
00:33:23,039 --> 00:33:25,039
el arrepentimiento a lo largo del tiempo y usan la

1004
00:33:25,039 --> 00:33:26,399
tasa que dijeron que

1005
00:33:26,399 --> 00:33:28,000
había sido ilustrada para ser un mejor

1006
00:33:28,000 --> 00:33:29,440
estimador  de este

1007
00:33:29,440 --> 00:33:33,279
arrepentimiento logarítmico en el caso dinámico

1008
00:33:33,279 --> 00:33:37,360
impresionante y la gran idea del arrepentimiento

1009
00:33:37,360 --> 00:33:40,399
es mirar hacia atrás en su historial,

1010
00:33:40,399 --> 00:33:42,240
así que para toda la historia es

1011
00:33:42,240 --> 00:33:44,240
un arrepentimiento acumulativo que se aplica muy

1012
00:33:44,240 --> 00:33:46,000
bien al problema estacionario

1013
00:33:46,000 --> 00:33:49,279
o historia reciente que se aplica bien

1014
00:33:49,279 --> 00:33:50,720
al caso dinámico

1015
00:33:50,720 --> 00:33:52,080
porque si  las cosas siempre están cambiando

1016
00:33:52,080 --> 00:33:53,840
estás más interesado en lo

1017
00:33:53,840 --> 00:33:54,159
bien que

1018
00:33:54,159 --> 00:33:57,600
te está yendo recientemente en lugar

1019
00:33:57,600 --> 00:33:59,279
de todo el tiempo no quieres algo

1020
00:33:59,279 --> 00:34:00,960
Las fluctuaciones desde el principio

1021
00:34:00,960 --> 00:34:03,279
juegan un papel en su valor acumulado

1022
00:34:03,279 --> 00:34:04,159
porque no desea adaptar su

1023
00:34:04,159 --> 00:34:05,440
estrategia ahora

1024
00:34:05,440 --> 00:34:07,120
para reducir el arrepentimiento de una

1025
00:34:07,120 --> 00:34:09,119
época diferente, lo que puede suceder si no lo

1026
00:34:09,119 --> 00:34:09,918
hace de esta manera.

1027
00:34:09,918 --> 00:34:11,839


1028
00:34:11,839 --> 00:34:13,359
del historial de

1029
00:34:13,359 --> 00:34:16,000
arrepentimiento acumulativo para el caso fijo o

1030
00:34:16,000 --> 00:34:18,639
historial reciente para el caso dinámico

1031
00:34:18,639 --> 00:34:21,199
actualice su estrategia para que

1032
00:34:21,199 --> 00:34:23,359
haya minimizado el arrepentimiento de

1033
00:34:23,359 --> 00:34:26,079
xero jugando esa estrategia todo el tiempo para

1034
00:34:26,079 --> 00:34:26,800
que sepa

1035
00:34:26,800 --> 00:34:30,000
mirando hacia atrás en el precio de bitcoin qué

1036
00:34:30,000 --> 00:34:31,199
estrategia

1037
00:34:31,199 --> 00:34:34,480
habría sido sin arrepentimientos

1038
00:34:34,480 --> 00:34:36,800
esos  son las grandes preguntas o solo en

1039
00:34:36,800 --> 00:34:39,119
la última pequeña ventana de tiempo

1040
00:34:39,119 --> 00:34:42,159
dado lo que recientemente descubrí ¿cómo

1041
00:34:42,159 --> 00:34:44,399
podría hacer que mi tasa de arrepentimiento

1042
00:34:44,399 --> 00:34:48,000
sea lo más baja posible para

1043
00:34:48,000 --> 00:34:50,320
que sea una forma de mirar hacia atrás y luego

1044
00:34:50,320 --> 00:34:51,359


1045
00:34:51,359 --> 00:34:54,719
pensar con optimismo en cómo podría haber actuado?

1046
00:34:54,719 --> 00:34:57,359
al reducir el arrepentimiento a cero y vemos

1047
00:34:57,359 --> 00:34:57,760
esto

1048
00:34:57,760 --> 00:34:59,920
todo el tiempo en la informática, como

1049
00:34:59,920 --> 00:35:01,200
maximizar algo,

1050
00:35:01,200 --> 00:35:03,200
lo haces al minimizar si hay

1051
00:35:03,200 --> 00:35:04,880
un negativo arrojado allí

1052
00:35:04,880 --> 00:35:07,359
o si t  aquí hay un logaritmo natural

1053
00:35:07,359 --> 00:35:08,560
arrojado allí o si es

1054
00:35:08,560 --> 00:35:10,640
uno sobre algo o simplemente está enmarcado

1055
00:35:10,640 --> 00:35:12,240
de manera opuesta

1056
00:35:12,240 --> 00:35:13,760
muchas veces si sabes que estás

1057
00:35:13,760 --> 00:35:15,760
limitado a cero, algo no puede ir por debajo de

1058
00:35:15,760 --> 00:35:16,560
cero,

1059
00:35:16,560 --> 00:35:19,280
entonces quieres ir tan bajo como  posible

1060
00:35:19,280 --> 00:35:19,920
o

1061
00:35:19,920 --> 00:35:21,760
si desea maximizar algo, a

1062
00:35:21,760 --> 00:35:23,839
veces es más fácil hacer uno sobre el

1063
00:35:23,839 --> 00:35:25,359
máximo y luego tratar de llevar ese número

1064
00:35:25,359 --> 00:35:26,400
a cero en

1065
00:35:26,400 --> 00:35:28,560
lugar de esta maximización ilimitada

1066
00:35:28,560 --> 00:35:30,960
como está bien, estoy en 5 millones,

1067
00:35:30,960 --> 00:35:32,560
¿debería parar?  incluso

1068
00:35:32,560 --> 00:35:35,520
cerca porque no hay un número más alto,

1069
00:35:35,520 --> 00:35:37,200
así que se arrepienten de haber aprendido y así es

1070
00:35:37,200 --> 00:35:38,960
como van a calcular su

1071
00:35:38,960 --> 00:35:41,119
rendimiento,

1072
00:35:41,119 --> 00:35:44,400
pasemos a la inferencia activa, así que una

1073
00:35:44,400 --> 00:35:45,200
cosa

1074
00:35:45,200 --> 00:35:46,960
que verán en esta diapositiva de inmediato

1075
00:35:46,960 --> 00:35:48,400
es que no estamos viendo

1076
00:35:48,400 --> 00:35:51,920
un motor sensorial  bucle, no estamos viendo un

1077
00:35:51,920 --> 00:35:54,720
agente en un entorno con flechas y

1078
00:35:54,720 --> 00:35:56,160
nodos

1079
00:35:56,160 --> 00:35:57,839
, estamos llegando a una inferencia activa desde

1080
00:35:57,839 --> 00:35:59,520
este punto de vista de la

1081
00:35:59,520 --> 00:36:00,400
toma de decisiones secuenciales

1082
00:36:00,400 --> 00:36:03,920
bajo incertidumbre y, por lo tanto, en esta sección,

1083
00:36:03,920 --> 00:36:05,200
que es un gran título

1084
00:36:05,200 --> 00:36:09,680
tres dos en  La inferencia activa

1085
00:36:09,680 --> 00:36:12,320
escriben que la

1086
00:36:12,320 --> 00:36:14,320
compensación de la explotación de la exploración se puede formular

1087
00:36:14,320 --> 00:36:16,160
como un problema de reducción de la incertidumbre

1088
00:36:16,160 --> 00:36:19,280
donde las opciones apuntan a resolver la

1089
00:36:19,280 --> 00:36:20,800


1090
00:36:20,800 --> 00:36:22,640
incertidumbre esperada e inesperada sobre las propiedades ocultas del

1091
00:36:22,640 --> 00:36:24,640
medio ambiente, por lo que ya estamos viendo

1092
00:36:24,640 --> 00:36:26,640
que la formulación de la inferencia

1093
00:36:26,640 --> 00:36:28,160
activa tiene estados ocultos en el  entorno al

1094
00:36:28,160 --> 00:36:30,079
que no tenemos acceso directo,

1095
00:36:30,079 --> 00:36:32,640
pero obtenemos resultados admitidos de las

1096
00:36:32,640 --> 00:36:34,320
decisiones,

1097
00:36:34,320 --> 00:36:36,320
esto lleva a emitir un comportamiento de elección

1098
00:36:36,320 --> 00:36:37,440
y planificar,

1099
00:36:37,440 --> 00:36:39,839
también conocido como planificación como inferencia, como un

1100
00:36:39,839 --> 00:36:42,079
problema de inferencia probabilística

1101
00:36:42,079 --> 00:36:44,800
expresado por la inferencia activa, por lo que la

1102
00:36:44,800 --> 00:36:45,359
acción

1103
00:36:45,359 --> 00:36:47,920
y la inferencia nuestra inferencia es sobre

1104
00:36:47,920 --> 00:36:49,839
qué acciones tomamos.  estamos planeando y sobre

1105
00:36:49,839 --> 00:36:51,440
los estados ocultos del mundo dados los

1106
00:36:51,440 --> 00:36:52,640
resultados que estamos recibiendo

1107
00:36:52,640 --> 00:36:55,839
datos sensoriales usando este enfoque

1108
00:36:55,839 --> 00:36:58,240
diferentes tipos de comportamiento explotador y

1109
00:36:58,240 --> 00:37:00,079
exploratorio

1110
00:37:00,079 --> 00:37:03,119
emergen naturalmente en

1111
00:37:03,119 --> 00:37:04,800
estrategias de decisión de inferencia activa las

1112
00:37:04,800 --> 00:37:08,079
políticas de comportamiento se eligen en base a

1113
00:37:08,079 --> 00:37:09,680
un solo

1114
00:37:09,680 --> 00:37:12,480
principio de optimización o ayer  yo pienso que fue  a

1115
00:37:12,480 --> 00:37:14,320
qué era funcional

1116
00:37:14,320 --> 00:37:15,920
una base funcional común o algo

1117
00:37:15,920 --> 00:37:18,160
así el principio de optimización única

1118
00:37:18,160 --> 00:37:19,119


1119
00:37:19,119 --> 00:37:21,680
es minimizar la sorpresa esperada sobre

1120
00:37:21,680 --> 00:37:23,680
los resultados observados y futuros

1121
00:37:23,680 --> 00:37:26,560
esa es la energía libre esperada por lo que

1122
00:37:26,560 --> 00:37:27,920
es genial como

1123
00:37:27,920 --> 00:37:30,960
el enfoque retrospectivo

1124
00:37:30,960 --> 00:37:34,160
es minimizar el arrepentimiento como lo

1125
00:37:34,160 --> 00:37:37,280
haría  Me he desempeñado mejor

1126
00:37:37,280 --> 00:37:39,599
dado lo que sé sobre el pasado. ¿

1127
00:37:39,599 --> 00:37:40,400
Cómo cambia eso

1128
00:37:40,400 --> 00:37:43,520
la forma en que actúo de vez en cuando?

1129
00:37:43,520 --> 00:37:46,480


1130
00:37:46,480 --> 00:37:48,880


1131
00:37:48,880 --> 00:37:49,599


1132
00:37:49,599 --> 00:37:52,880


1133
00:37:52,880 --> 00:37:55,040
¿Puedo minimizar

1134
00:37:55,040 --> 00:37:56,720
la energía libre esperada

1135
00:37:56,720 --> 00:37:59,280
porque el arrepentimiento no es un

1136
00:37:59,280 --> 00:38:01,599
arrepentimiento anticipatorio es solo mirar hacia atrás, por

1137
00:38:01,599 --> 00:38:03,280
lo que es realmente fácil de

1138
00:38:03,280 --> 00:38:05,200
entrenar y luego aquí hay algo

1139
00:38:05,200 --> 00:38:06,480
que está mirando hacia adelante,

1140
00:38:06,480 --> 00:38:07,920
así que es genial cómo el

1141
00:38:07,920 --> 00:38:10,560
momento actual es este traspaso

1142
00:38:10,560 --> 00:38:13,200
entre el arrepentimiento retrospectivo

1143
00:38:13,200 --> 00:38:14,079
aprendizaje

1144
00:38:14,079 --> 00:38:16,839
y luego la posible minimización de energía libre

1145
00:38:16,839 --> 00:38:18,320


1146
00:38:18,320 --> 00:38:20,079
, así es como enmarcan la inferencia activa

1147
00:38:20,079 --> 00:38:22,320
aquí cualquier g  comentarios generales o qué

1148
00:38:22,320 --> 00:38:24,800
crees que fue genial sobre eso,

1149
00:38:24,800 --> 00:38:27,280
así que solo estoy pensando en que me gusta el artículo de alex

1150
00:38:27,280 --> 00:38:29,280
chance que hicimos hace mucho tiempo,

1151
00:38:29,280 --> 00:38:30,720
creo que fue el número ocho, pero

1152
00:38:30,720 --> 00:38:32,800
um, siempre vuelvo a eso cuando

1153
00:38:32,800 --> 00:38:34,480
estoy  mirando estos

1154
00:38:34,480 --> 00:38:36,000
marcos computacionales porque lo dividió muy

1155
00:38:36,000 --> 00:38:36,800
bien

1156
00:38:36,800 --> 00:38:39,440
en como la recompensa, el valor pragmático

1157
00:38:39,440 --> 00:38:41,200
que podría ser, en este caso,

1158
00:38:41,200 --> 00:38:43,599
la minimización del arrepentimiento puede verse

1159
00:38:43,599 --> 00:38:45,119
como el valor pragmático o la

1160
00:38:45,119 --> 00:38:46,000
recompensa

1161
00:38:46,000 --> 00:38:48,880
y luego el valor epistémico, así

1162
00:38:48,880 --> 00:38:50,240
que tienes  ambas cosas que juegan

1163
00:38:50,240 --> 00:38:51,040
en

1164
00:38:51,040 --> 00:38:54,079
um le dan al sistema cómo ayudar a esto,

1165
00:38:54,079 --> 00:38:55,280
la actualización del agente

1166
00:38:55,280 --> 00:38:58,320
relevante para el sistema es genial y

1167
00:38:58,320 --> 00:38:59,440
espero tener

1168
00:38:59,440 --> 00:39:01,599
noticias de los autores si

1169
00:39:01,599 --> 00:39:03,440
estudiaron la inferencia activa y luego se

1170
00:39:03,440 --> 00:39:05,440
acercaron a la toma de decisiones bayesiana

1171
00:39:05,440 --> 00:39:05,839
apro

1172
00:39:05,839 --> 00:39:09,119
uh algoritmos donde vendrían  de una

1173
00:39:09,119 --> 00:39:10,960


1174
00:39:10,960 --> 00:39:12,079
formación en informática de inferencia no activa y luego

1175
00:39:12,079 --> 00:39:13,599
descubrió que la inferencia activa era algo

1176
00:39:13,599 --> 00:39:15,599
emocionante. ¿Cómo

1177
00:39:15,599 --> 00:39:19,440
convergieron en este enfoque

1178
00:39:20,480 --> 00:39:22,320
poco después de la introducción?  En la

1179
00:39:22,320 --> 00:39:23,680
inferencia activa, recurrieron a

1180
00:39:23,680 --> 00:39:26,800
una inferencia activa aproximada y

1181
00:39:26,800 --> 00:39:28,320
describieron que

1182
00:39:28,320 --> 00:39:30,320
la inferencia activa en su forma inicial se

1183
00:39:30,320 --> 00:39:32,800
desarrolló para espacios de estados pequeños y

1184
00:39:32,800 --> 00:39:33,520
problemas de juguetes

1185
00:39:33,520 --> 00:39:35,520
sin tener en cuenta las aplicaciones

1186
00:39:35,520 --> 00:39:36,960
a los problemas típicos de aprendizaje automático

1187
00:39:36,960 --> 00:39:39,119
, por lo que es como cuando hay dos

1188
00:39:39,119 --> 00:39:41,440
decisiones en una especie de  una matriz de dos por dos

1189
00:39:41,440 --> 00:39:42,800
y dos resultados en el mundo

1190
00:39:42,800 --> 00:39:46,000
y dos decisiones que puede tomar esto ha

1191
00:39:46,000 --> 00:39:47,359
cambiado recientemente

1192
00:39:47,359 --> 00:39:49,280
y se han propuesto varias soluciones escalables

1193
00:39:49,280 --> 00:39:50,960
creo que una de estas citas

1194
00:39:50,960 --> 00:39:51,599
sería la

1195
00:39:51,599 --> 00:39:53,920
posibilidad de escalar la

1196
00:39:53,920 --> 00:39:56,079
inferencia activa flujo activo

1197
00:39:56,079 --> 00:39:58,800
ocho además de  optimización de políticas secuenciales complejas

1198
00:39:58,800 --> 00:39:59,920


1199
00:39:59,920 --> 00:40:01,839
que implica búsquedas sofisticadas de árboles profundos,

1200
00:40:01,839 --> 00:40:04,400
por lo que es una inferencia activa sofisticada

1201
00:40:04,400 --> 00:40:06,720
con estos despliegues

1202
00:40:06,720 --> 00:40:10,160
de árboles seguidos de enfoques de poda de árboles, por lo

1203
00:40:10,160 --> 00:40:12,160
tanto, para hacer que el enfoque de inferencia activa sea

1204
00:40:12,160 --> 00:40:13,280
práctico

1205
00:40:13,280 --> 00:40:15,119
y escalable a los

1206
00:40:15,119 --> 00:40:16,880
problemas de bandidos de alta dimensión que se usan típicamente en

1207
00:40:16,880 --> 00:40:17,839
el aprendizaje automático

1208
00:40:17,839 --> 00:40:19,920
, presentamos aquí un aproximado  C.A

1209
00:40:19,920 --> 00:40:21,920


1210
00:40:21,920 --> 00:40:23,839
definitivamente será genial escuchar a los

1211
00:40:23,839 --> 00:40:25,520
autores decir qué

1212
00:40:25,520 --> 00:40:28,640
estamos aproximando exactamente, qué más se

1213
00:40:28,640 --> 00:40:30,400
podría aproximar

1214
00:40:30,400 --> 00:40:32,640
y aún tener la inferencia activa o

1215
00:40:32,640 --> 00:40:35,040
qué no se puede aproximar,

1216
00:40:35,040 --> 00:40:37,520
pero veamos cómo y por qué se

1217
00:40:37,520 --> 00:40:40,720
aproximaron a la inferencia activa,

1218
00:40:40,720 --> 00:40:43,599
así que esto es  así que sí, para

1219
00:40:43,599 --> 00:40:45,200
hablar de por qué tú y yo hemos

1220
00:40:45,200 --> 00:40:45,599
hecho,

1221
00:40:45,599 --> 00:40:47,920
um, ya sabes, la construcción de árboles en

1222
00:40:47,920 --> 00:40:49,839
términos de filogenética justo en el

1223
00:40:49,839 --> 00:40:51,440
cambio de árbol y el cambio de nodos

1224
00:40:51,440 --> 00:40:53,280
y eso puede ser realmente

1225
00:40:53,280 --> 00:40:54,560
abrumador desde el punto de vista computacional,

1226
00:40:54,560 --> 00:40:56,640
como puede durar días.  y días y días,

1227
00:40:56,640 --> 00:40:58,800
así que es realmente

1228
00:40:58,800 --> 00:41:00,720
agradable ver una implementación de aproximación tan dulce y limpia

1229
00:41:00,720 --> 00:41:03,200
aquí

1230
00:41:03,200 --> 00:41:06,240
sí, aquí

1231
00:41:06,240 --> 00:41:09,359
no vamos a profundizar en el

1232
00:41:09,359 --> 00:41:11,680
formalismo 16 y 17, pero

1233
00:41:11,680 --> 00:41:13,680
esperamos que los autores lo describan,

1234
00:41:13,680 --> 00:41:17,200
pero aquí está  la pieza clave las

1235
00:41:17,200 --> 00:41:19,520
creencias posteriores marginales exactas sobre las

1236
00:41:19,520 --> 00:41:21,839
probabilidades de recompensa

1237
00:41:21,839 --> 00:41:25,200
theta se pueden expresar de esta manera, está bien,

1238
00:41:25,200 --> 00:41:27,119
solo mirando eso, está bien, es

1239
00:41:27,119 --> 00:41:29,119
retorcido, ¿

1240
00:41:29,119 --> 00:41:32,319
cómo vamos a wi  n si eso es lo que

1241
00:41:32,319 --> 00:41:33,520
tenemos que resolver,

1242
00:41:33,520 --> 00:41:36,640
entonces las creencias exactas sobre

1243
00:41:36,640 --> 00:41:38,960
las creencias correctas exactas sobre la recompensa se

1244
00:41:38,960 --> 00:41:40,640
verían de esta manera

1245
00:41:40,640 --> 00:41:42,240
y luego escriben que el posterior marginal exacto

1246
00:41:42,240 --> 00:41:44,640
en la ecuación

1247
00:41:44,640 --> 00:41:46,800
17 no pertenecerá a la distribución beta, lo que

1248
00:41:46,800 --> 00:41:48,880
hace que la inferencia exacta sea analíticamente

1249
00:41:48,880 --> 00:41:50,240
intratable,

1250
00:41:50,240 --> 00:41:53,280
por lo que no  podría ser una forma de

1251
00:41:53,280 --> 00:41:56,000
abordarlo numéricamente y simularlo o

1252
00:41:56,000 --> 00:41:56,640
calcularlo, pero

1253
00:41:56,640 --> 00:41:58,000
si queremos mirar a través de grandes

1254
00:41:58,000 --> 00:41:59,760
conjuntos de datos y hacerlo rápido

1255
00:41:59,760 --> 00:42:01,680
sin grandes cantidades de

1256
00:42:01,680 --> 00:42:04,000
esfuerzo computacional, necesitamos una forma diferente,

1257
00:42:04,000 --> 00:42:07,280
sin embargo, restringimos si restringimos la

1258
00:42:07,280 --> 00:42:09,359
unión posterior a esto.  forma aproximada

1259
00:42:09,359 --> 00:42:11,200
completamente factorizada

1260
00:42:11,200 --> 00:42:13,680
y hemos visto la factorización de

1261
00:42:13,680 --> 00:42:16,800
variables antes de que la factorización de

1262
00:42:16,800 --> 00:42:18,000
variables sea un

1263
00:42:18,000 --> 00:42:21,280
gran tema, así que no vamos a

1264
00:42:21,280 --> 00:42:22,560


1265
00:42:22,560 --> 00:42:24,400
entrar en detalles aquí de nuevo, sería

1266
00:42:24,400 --> 00:42:26,000
increíble saber de los autores cómo

1267
00:42:26,000 --> 00:42:27,920
se derivaron  y factorizar,

1268
00:42:27,920 --> 00:42:31,119
pero una forma de pensarlo es que

1269
00:42:31,119 --> 00:42:34,079
restringir una gran ecuación larga abierta

1270
00:42:34,079 --> 00:42:35,119


1271
00:42:35,119 --> 00:42:37,839
a una forma factorizable reduce el

1272
00:42:37,839 --> 00:42:38,800
espacio de solución

1273
00:42:38,800 --> 00:42:42,000
a  mucho y eso permite que ciertos tipos de

1274
00:42:42,000 --> 00:42:44,800
optimización se vuelvan manejables, por

1275
00:42:44,800 --> 00:42:45,359
ejemplo,

1276
00:42:45,359 --> 00:42:47,760
para la regresión lineal tenemos mínimos

1277
00:42:47,760 --> 00:42:48,880
cuadrados,

1278
00:42:48,880 --> 00:42:50,800
que es una forma en la que si limita

1279
00:42:50,800 --> 00:42:52,880
el problema a decir que estoy tratando de

1280
00:42:52,880 --> 00:42:54,640
resolver la suma de cuadrados,

1281
00:42:54,640 --> 00:42:56,720
no la suma de cubos o el  suma de alguna

1282
00:42:56,720 --> 00:42:58,000
otra función, pero solo estoy tratando de

1283
00:42:58,000 --> 00:42:59,359
resolver esta,

1284
00:42:59,359 --> 00:43:02,880
entonces hay cálculos que se escalan

1285
00:43:02,880 --> 00:43:03,920
muy bien

1286
00:43:03,920 --> 00:43:05,520
y eso es lo que está sucediendo, una

1287
00:43:05,520 --> 00:43:07,599
factorización y otra forma de

1288
00:43:07,599 --> 00:43:08,960
pensar en la factorización

1289
00:43:08,960 --> 00:43:11,280
es si tiene un gráfico bayesiano donde

1290
00:43:11,280 --> 00:43:13,040
los nodos son los  variables

1291
00:43:13,040 --> 00:43:14,400
y luego los bordes son como las

1292
00:43:14,400 --> 00:43:16,960
relaciones entre las

1293
00:43:16,960 --> 00:43:19,280
variables, podría volcarlo todo en un

1294
00:43:19,280 --> 00:43:20,800
marco de ajuste de parámetros

1295
00:43:20,800 --> 00:43:23,119
con todos los bordes posibles que

1296
00:43:23,119 --> 00:43:24,960
sería como un modelo no factorizado,

1297
00:43:24,960 --> 00:43:27,200
por lo que la cantidad de bordes que tiene para

1298
00:43:27,200 --> 00:43:28,560
calcular los

1299
00:43:28,560 --> 00:43:31,920
valores exactos para  va a ser mucho

1300
00:43:31,920 --> 00:43:33,520
y va a aumentar exponencialmente

1301
00:43:33,520 --> 00:43:34,800
con la cantidad de parámetros que

1302
00:43:34,800 --> 00:43:35,680
desea ajustar,

1303
00:43:35,680 --> 00:43:38,240
pero si factoriza las cosas, está bien, la

1304
00:43:38,240 --> 00:43:39,119
variable a

1305
00:43:39,119 --> 00:43:41,599
solo es  asociado con b y b solo está

1306
00:43:41,599 --> 00:43:42,880
asociado con c

1307
00:43:42,880 --> 00:43:45,200
y a, de repente está reduciendo

1308
00:43:45,200 --> 00:43:47,599
la cantidad de bordes que tiene que ajustar, lo

1309
00:43:47,599 --> 00:43:50,720
que lo ayuda a llegar a

1310
00:43:50,720 --> 00:43:54,000
una solución que se alcanza de manera atractiva

1311
00:43:54,000 --> 00:43:54,880
pero también

1312
00:43:54,880 --> 00:43:57,280
aproximadamente precisa, por lo que

1313
00:43:57,280 --> 00:43:59,760
probablemente probablemente

1314
00:43:59,760 --> 00:44:02,960
cálculo bayesiano aproximadamente correcto y aproximado, pero

1315
00:44:02,960 --> 00:44:05,359
hemos visto que la factorización algunas

1316
00:44:05,359 --> 00:44:06,560


1317
00:44:06,560 --> 00:44:10,079
veces no entrará en muchos más detalles aquí,

1318
00:44:10,079 --> 00:44:13,040
pero lo que hacen es tomar esta

1319
00:44:13,040 --> 00:44:15,359
forma factorizada

1320
00:44:15,359 --> 00:44:18,319
y usan cálculo variacional para

1321
00:44:18,319 --> 00:44:19,520
recuperar la siguiente

1322
00:44:19,520 --> 00:44:21,680
regla de sonrisa variacional que nosotros  Iré a

1323
00:44:21,680 --> 00:44:23,280
en un segundo

1324
00:44:23,280 --> 00:44:24,960
y para que lleguen a un conjunto diferente de

1325
00:44:24,960 --> 00:44:27,119
formalismos, escucharemos a los autores

1326
00:44:27,119 --> 00:44:27,520
sobre

1327
00:44:27,520 --> 00:44:30,319
qué es diferente en esos formalismos

1328
00:44:30,319 --> 00:44:30,880
y

1329
00:44:30,880 --> 00:44:34,400
luego, lo que es genial es que para el

1330
00:44:34,400 --> 00:44:35,599
bandido estacionario

1331
00:44:35,599 --> 00:44:38,800
donde puede cambiar los parámetros para que me

1332
00:44:38,800 --> 00:44:42,560
gusten.  cero para la tasa de cambio

1333
00:44:42,560 --> 00:44:44,480
que corresponde a la inferencia exacta de Beijing

1334
00:44:44,480 --> 00:44:46,160
sobre el

1335
00:44:46,160 --> 00:44:47,760
problema del bandido de Bernoulli estacionario,

1336
00:44:47,760 --> 00:44:50,000
por lo que fue un poco interesante cómo

1337
00:44:50,000 --> 00:44:50,960
el ex  la

1338
00:44:50,960 --> 00:44:54,640
forma de actuar de un algoritmo la solución podría,

1339
00:44:54,640 --> 00:44:57,359
eh, cómo la inferencia activa podría estar haciendo

1340
00:44:57,359 --> 00:44:57,760
algo

1341
00:44:57,760 --> 00:45:01,040
exacto en la asíntota

1342
00:45:01,040 --> 00:45:04,560
qué es la sonrisa aquí está el papel de la sonrisa

1343
00:45:04,560 --> 00:45:06,480
métodos variacionales como premio para

1344
00:45:06,480 --> 00:45:08,560
sorprender el aprendizaje de minimización,

1345
00:45:08,560 --> 00:45:10,079
por lo que suena como muchas de las cosas que

1346
00:45:10,079 --> 00:45:11,839
hacemos con métodos

1347
00:45:11,839 --> 00:45:13,200
variacionales variacionales

1348
00:45:13,200 --> 00:45:16,079
minimización de base y sorpresa y el pseudocódigo

1349
00:45:16,079 --> 00:45:16,560


1350
00:45:16,560 --> 00:45:18,560
se presenta aquí para la familia exponencial

1351
00:45:18,560 --> 00:45:20,319


1352
00:45:20,319 --> 00:45:22,560
esta es solo una pregunta para los autores

1353
00:45:22,560 --> 00:45:24,160
qué hace la

1354
00:45:24,160 --> 00:45:26,880
sonrisa cómo nos ayuda a aproximar

1355
00:45:26,880 --> 00:45:28,480
la inferencia activa

1356
00:45:28,480 --> 00:45:32,000
¿para qué más podemos usar la sonrisa

1357
00:45:32,000 --> 00:45:33,839
así que esa es esta inferencia activa aproximativa?

1358
00:45:33,839 --> 00:45:35,440


1359
00:45:35,440 --> 00:45:38,880
interludio toman una gran forma desordenada

1360
00:45:38,880 --> 00:45:41,280
y luego, al restringir cómo las variables

1361
00:45:41,280 --> 00:45:43,920
se pueden relacionar entre sí

1362
00:45:43,920 --> 00:45:45,839
y usar métodos variacionales en esa

1363
00:45:45,839 --> 00:45:48,640
representación factorizada

1364
00:45:48,640 --> 00:45:52,560
, es posible obtener una aproximación

1365
00:45:52,560 --> 00:45:55,759
que será efectiva,

1366
00:45:56,480 --> 00:45:58,800
por lo que es interesante que, um, sepa que

1367
00:45:58,800 --> 00:46:00,000
existe esta

1368
00:46:00,000 --> 00:46:02,319
correspondencia directa  para el

1369
00:46:02,319 --> 00:46:03,760
caso de bandido uh estacionario

1370
00:46:03,760 --> 00:46:05,920
porque en el caso estacionario l

1371
00:46:05,920 --> 00:46:07,040
Como si no vimos una

1372
00:46:07,040 --> 00:46:08,720
mejora correcta usando el

1373
00:46:08,720 --> 00:46:10,240
algoritmo de inferencia activa que

1374
00:46:10,240 --> 00:46:12,880
explica totalmente por qué,

1375
00:46:12,880 --> 00:46:14,640
sí, y tienen algunas piezas más sobre

1376
00:46:14,640 --> 00:46:16,319
eso, creo que en la

1377
00:46:16,319 --> 00:46:19,680
figura cuatro más grande o algo así,

1378
00:46:19,680 --> 00:46:20,560


1379
00:46:20,560 --> 00:46:24,560
bien, vayamos a los dos

1380
00:46:24,560 --> 00:46:26,720
problemas que abordan y  luego los

1381
00:46:26,720 --> 00:46:28,000
resultados para esas dos secciones,

1382
00:46:28,000 --> 00:46:29,920
así que cubriremos primero el

1383
00:46:29,920 --> 00:46:32,720
bandido estacionario y luego el bandido dinámico,

1384
00:46:32,720 --> 00:46:34,880
así que aquí está la definición y dónde

1385
00:46:34,880 --> 00:46:36,800
funcionan a través

1386
00:46:36,800 --> 00:46:39,280
del bandido estacionario, por lo que un

1387
00:46:39,280 --> 00:46:42,800
bandido estacionario tiene un número finito de brazos

1388
00:46:42,800 --> 00:46:46,800
uh, tiene uh k brazos

1389
00:46:46,800 --> 00:46:49,599
y  entonces va a estar jugando a

1390
00:46:49,599 --> 00:46:50,000
través de

1391
00:46:50,000 --> 00:46:53,359
t pasos de tiempo y luego son grandes k

1392
00:46:53,359 --> 00:46:56,720
grandes k brazos y luego cada pequeño pequeño k

1393
00:46:56,720 --> 00:46:59,440
k es el conjunto de pequeños brazos pequeño k

1394
00:46:59,440 --> 00:47:02,480
sí k es la acción

1395
00:47:03,520 --> 00:47:05,119
así que así es como definen al

1396
00:47:05,119 --> 00:47:07,119
bandido estacionario y

1397
00:47:07,119 --> 00:47:09,200
nuevamente puedes pensar  sobre t y

1398
00:47:09,200 --> 00:47:10,240
acciones de tiempo

1399
00:47:10,240 --> 00:47:13,359
y uh brazos y luego en

1400
00:47:13,359 --> 00:47:15,920
bandidos estacionarios las probabilidades de recompensa

1401
00:47:15,920 --> 00:47:18,640
theta sub k se fijan para todas las pruebas, por lo que

1402
00:47:18,640 --> 00:47:19,760
theta es como si

1403
00:47:19,760 --> 00:47:21,280
fuera divertido, es como el parámetro que

1404
00:47:21,280 --> 00:47:22,960
significa solo  como variable a

1405
00:47:22,960 --> 00:47:24,800
veces supongo que muchos de ellos lo hacen, pero

1406
00:47:24,800 --> 00:47:26,559
sobre todo los datos,

1407
00:47:26,559 --> 00:47:30,800
así que solo un valor de recompensa fijo,

1408
00:47:30,800 --> 00:47:33,520
la probabilidad de recompensa fija sí, por

1409
00:47:33,520 --> 00:47:35,839
eso no es estacionario

1410
00:47:35,839 --> 00:47:38,079
en el casino, esto sería como si uno de

1411
00:47:38,079 --> 00:47:39,040
ellos

1412
00:47:39,040 --> 00:47:41,359
pagara en promedio uno a uno de  ellos

1413
00:47:41,359 --> 00:47:42,960
paga el cincuenta por ciento uno paga el

1414
00:47:42,960 --> 00:47:46,240
doscientos por ciento pero nunca cambian,

1415
00:47:46,240 --> 00:47:47,440
así que aquí hay una especie de

1416
00:47:47,440 --> 00:47:50,079
representación visual de eso con

1417
00:47:50,079 --> 00:47:52,640
aquí está el brazo múltiple y luego el

1418
00:47:52,640 --> 00:47:54,960
mouse obtiene el queso

1419
00:47:54,960 --> 00:47:57,280
y cada brazo tiene una probabilidad fija diferente

1420
00:47:57,280 --> 00:47:58,240


1421
00:47:58,240 --> 00:47:59,599
pero esos no  no cambia, por lo que la

1422
00:47:59,599 --> 00:48:01,520
probabilidad de que el queso

1423
00:48:01,520 --> 00:48:06,480
no se mueva

1424
00:48:06,480 --> 00:48:10,800
aquí está la figura uno, así que en la figura uno

1425
00:48:10,800 --> 00:48:14,319
vamos a ver un análisis de la tasa de arrepentimiento, por

1426
00:48:14,319 --> 00:48:18,240
lo que la tasa de arrepentimiento que pueden imaginar

1427
00:48:18,240 --> 00:48:20,400
es que llegaremos al segundo, pero el

1428
00:48:20,400 --> 00:48:22,240
análisis de la tasa de arrepentimiento para el  bandido estacionario

1429
00:48:22,240 --> 00:48:23,440


1430
00:48:23,440 --> 00:48:25,200
y luego vamos a comparar

1431
00:48:25,200 --> 00:48:28,000
la inferencia activa aproximada en rojo

1432
00:48:28,000 --> 00:48:31,680
con la inferencia activa exacta en azul,

1433
00:48:31,680 --> 00:48:33,359
por lo que será genial hablar con los

1434
00:48:33,359 --> 00:48:34,880
autores sobre

1435
00:48:34,880 --> 00:48:37,359
cuál fue el cambio relativo en cuánto

1436
00:48:37,359 --> 00:48:40,480
t  iempo que se tardó en calcular,

1437
00:48:41,119 --> 00:48:44,480
lo descubriremos y lo que

1438
00:48:44,480 --> 00:48:48,319
hacen es mostrar que

1439
00:48:48,319 --> 00:48:49,920
el azul y el rojo siempre se

1440
00:48:49,920 --> 00:48:51,599
mueven juntos,

1441
00:48:51,599 --> 00:48:53,520
lo que sugiere que la

1442
00:48:53,520 --> 00:48:54,960
forma aproximada hace

1443
00:48:54,960 --> 00:48:57,520
un muy buen trabajo porque sigue el

1444
00:48:57,520 --> 00:48:58,160
comportamiento

1445
00:48:58,160 --> 00:49:01,520
de la forma exacta.  forma bastante bien

1446
00:49:01,520 --> 00:49:04,240
y luego solo para saber cómo leer

1447
00:49:04,240 --> 00:49:04,800
este

1448
00:49:04,800 --> 00:49:08,240
uh gráfico, por lo que hay cuatro columnas

1449
00:49:08,240 --> 00:49:10,960
correspondientes a k es igual a 10 20 40 y

1450
00:49:10,960 --> 00:49:12,240
80 brazos,

1451
00:49:12,240 --> 00:49:14,000
por lo que cambia solo el número de

1452
00:49:14,000 --> 00:49:15,440
brazos,

1453
00:49:15,440 --> 00:49:18,800
luego están las filas que son

1454
00:49:18,800 --> 00:49:22,319
para uh épsilon

1455
00:49:22,319 --> 00:49:23,760
siendo el entonces  esto es como el

1456
00:49:23,760 --> 00:49:26,079
diferencial entre los brazos,

1457
00:49:26,079 --> 00:49:29,200
así

1458
00:49:29,200 --> 00:49:32,559
que creo que la tarea es fácil, y luego ese es el

1459
00:49:32,559 --> 00:49:35,440
punto uno punto dos cinco y el punto cuatro

1460
00:49:35,440 --> 00:49:35,920
y luego

1461
00:49:35,920 --> 00:49:38,960
dentro de cada celda

1462
00:49:38,960 --> 00:49:42,800
hay lambda uh que es

1463
00:49:42,800 --> 00:49:45,680
una función de precisión sobre las preferencias anteriores

1464
00:49:45,680 --> 00:49:47,280


1465
00:49:47,280 --> 00:49:50,559
y luego r  sub t,

1466
00:49:50,800 --> 00:49:53,200
que es el arrepentimiento en función de las

1467
00:49:53,200 --> 00:49:55,440
pruebas

1468
00:49:55,440 --> 00:49:57,520
y la línea negra discontinua indica el

1469
00:49:57,520 --> 00:49:58,960
límite superior en la tasa de arrepentimiento

1470
00:49:58,960 --> 00:50:00,319
correspondiente al agente aleatorio

1471
00:50:00,319 --> 00:50:04,720
, así que

1472
00:50:04,800 --> 00:50:10,079
supongo que esto es tan malo como podría obtener

1473
00:50:10,640 --> 00:50:13,599
y luego vemos  esa inferencia activa está

1474
00:50:13,599 --> 00:50:14,319
funcionando

1475
00:50:14,319 --> 00:50:16,559
mejor como si converge en una

1476
00:50:16,559 --> 00:50:17,520


1477
00:50:17,520 --> 00:50:20,640
tasa de arrepentimiento más baja que

1478
00:50:20,640 --> 00:50:23,680
0.1 o alrededor de 0.1, que es la cantidad de

1479
00:50:23,680 --> 00:50:25,760
arrepentimiento que se acumula

1480
00:50:25,760 --> 00:50:29,839
para el agente que se comporta aleatoriamente,

1481
00:50:29,839 --> 00:50:33,200
así que solo para anotar eso, um,

1482
00:50:33,200 --> 00:50:35,359
que pensé que era interesante y lo

1483
00:50:35,359 --> 00:50:37,119
hice más  significativo para mí ese

1484
00:50:37,119 --> 00:50:38,880
parámetro lambda la precisión,

1485
00:50:38,880 --> 00:50:40,640
por lo que dice cuando el

1486
00:50:40,640 --> 00:50:42,559
agente de inferencia activo tiene preferencias muy imprecisas,

1487
00:50:42,559 --> 00:50:46,079
por lo que lambda más cerca de cero

1488
00:50:46,079 --> 00:50:49,200
se dedica a la exploración durante más tiempo y

1489
00:50:49,200 --> 00:50:50,880
reduce la incertidumbre de

1490
00:50:50,880 --> 00:50:53,040
esa manera a expensas de acumular

1491
00:50:53,040 --> 00:50:54,240
recompensa, así que solo

1492
00:50:54,240 --> 00:50:56,079
um solo para algo así  nota al pie de página

1493
00:50:56,079 --> 00:50:58,160
que es

1494
00:50:58,160 --> 00:50:59,440
interesante y que

1495
00:50:59,440 --> 00:51:02,240
definitivamente volverá cuando hablemos de

1496
00:51:02,240 --> 00:51:03,920
inferencia activa y cómo reconsideremos

1497
00:51:03,920 --> 00:51:05,760
explorar explotar

1498
00:51:05,760 --> 00:51:07,760
entonces, ¿qué es esto que muestra

1499
00:51:07,760 --> 00:51:08,880


1500
00:51:08,880 --> 00:51:12,319


1501
00:51:12,319 --> 00:51:15,119


1502
00:51:15,119 --> 00:51:15,520


1503
00:51:15,520 --> 00:51:17,839
?  comportamiento en los

1504
00:51:17,839 --> 00:51:18,800
agentes de inferencia activos,

1505
00:51:18,800 --> 00:51:20,640
pero la aproximación básicamente

1506
00:51:20,640 --> 00:51:22,640
siempre funciona bastante bien

1507
00:51:22,640 --> 00:51:25,200
y luego también th  Las líneas punteadas son menos

1508
00:51:25,200 --> 00:51:26,880
intentos y las líneas continuas son más

1509
00:51:26,880 --> 00:51:27,520
intentos,

1510
00:51:27,520 --> 00:51:29,680
por lo que podemos ver que en todos estos casos

1511
00:51:29,680 --> 00:51:31,440
la línea punteada y luego el guión y

1512
00:51:31,440 --> 00:51:32,880
luego el sólido

1513
00:51:32,880 --> 00:51:34,839
siempre lo estás haciendo mejor con más

1514
00:51:34,839 --> 00:51:36,480
intentos, eso es lo

1515
00:51:36,480 --> 00:51:38,640
que vemos como si  solo tienes 100

1516
00:51:38,640 --> 00:51:41,839
pruebas, por lo que solo unas pocas pruebas en 80 brazos,

1517
00:51:41,839 --> 00:51:43,760
tu arrepentimiento es casi como si estuvieras

1518
00:51:43,760 --> 00:51:45,680
jugando al azar porque apenas has

1519
00:51:45,680 --> 00:51:47,680
probado cada brazo una vez, por lo que no puedes

1520
00:51:47,680 --> 00:51:50,960
hacerlo tan bien, pero

1521
00:51:50,960 --> 00:51:53,200
si estás  en el área correcta de precisión,

1522
00:51:53,200 --> 00:51:54,640
no demasiada precisión,

1523
00:51:54,640 --> 00:51:57,359
pero aun así, en esta área aquí abajo

1524
00:51:57,359 --> 00:51:58,000
, tienes

1525
00:51:58,000 --> 00:52:01,280
10 000 intentos, incluso con 80 brazos,

1526
00:52:01,280 --> 00:52:03,440
la tasa de arrepentimiento puede caer a un nivel muy

1527
00:52:03,440 --> 00:52:05,040
bajo, por lo que jugar

1528
00:52:05,040 --> 00:52:08,160
casi de manera óptima incluso con 80 brazos

1529
00:52:08,160 --> 00:52:10,880
dados los intentos y  dada una diferencia lo

1530
00:52:10,880 --> 00:52:13,040
suficientemente significativa entre los

1531
00:52:13,040 --> 00:52:16,079
resultados, eso es lo que muestra la figura uno,

1532
00:52:16,079 --> 00:52:17,040
que es que

1533
00:52:17,040 --> 00:52:19,200
la inferencia activa puede aprender a reducir su

1534
00:52:19,200 --> 00:52:22,240
arrepentimiento dados los parámetros correctos

1535
00:52:22,240 --> 00:52:23,920
las cosas que esperaríamos que hicieran la

1536
00:52:23,920 --> 00:52:26,319
situación más difícil, como más brazos

1537
00:52:26,319 --> 00:52:28,720
o menos diferenciabilidad  entre los

1538
00:52:28,720 --> 00:52:30,079
brazos o

1539
00:52:30,079 --> 00:52:34,079
súper alta um o baja precisión vari uh

1540
00:52:34,079 --> 00:52:36,559
tasas esas son las cosas que

1541
00:52:36,559 --> 00:52:40,160
influyen en los algoritmos de inferencia activa

1542
00:52:40,400 --> 00:52:42,400
um y también dijeron que encontraron que

1543
00:52:42,400 --> 00:52:44,559
la tasa mínima de arrepentimiento

1544
00:52:44,559 --> 00:52:47,599
um alrededor de lambda es 0.1

1545
00:52:47,599 --> 00:52:49,839
por eso fijaron la

1546
00:52:49,839 --> 00:52:52,160
tasa de arrepentimiento para  las próximas pruebas o para las

1547
00:52:52,160 --> 00:52:55,200
próximas pruebas porque hay un

1548
00:52:55,200 --> 00:52:55,920
montón de

1549
00:52:55,920 --> 00:52:59,440
perillas para modificar, por lo que hacen

1550
00:52:59,440 --> 00:53:01,520
todo lo posible para hacer barridos de parámetros y

1551
00:53:01,520 --> 00:53:03,280
mostrar como aquí está para

1552
00:53:03,280 --> 00:53:05,119
que conozcan la distribución completa de

1553
00:53:05,119 --> 00:53:06,400
lambda

1554
00:53:06,400 --> 00:53:09,280
para tres regímenes de muestreo diferentes para

1555
00:53:09,280 --> 00:53:11,040
cuatro estilos de brazo diferentes para  tres

1556
00:53:11,040 --> 00:53:12,400
dificultades diferentes, como que

1557
00:53:12,400 --> 00:53:14,480
la combinatoria ya se vuelve muy alta y

1558
00:53:14,480 --> 00:53:15,760
si fuera a usar esto en una

1559
00:53:15,760 --> 00:53:17,200
situación industrial

1560
00:53:17,200 --> 00:53:20,319
, lo optimizaría con todos estos

1561
00:53:20,319 --> 00:53:22,400
parámetros en juego

1562
00:53:22,400 --> 00:53:25,680
y luego, um, escriben que solo

1563
00:53:25,680 --> 00:53:26,559
van a considerar

1564
00:53:26,559 --> 00:53:28,480
esta inferencia activa aproximada

1565
00:53:28,480 --> 00:53:31,440
variante para la comparación entre agentes

1566
00:53:31,440 --> 00:53:33,200
porque le estaba yendo bastante bien en la

1567
00:53:33,200 --> 00:53:35,040
figura uno, por lo que simplemente

1568
00:53:35,040 --> 00:53:36,880
seguirán con la  aproximado, pero es

1569
00:53:36,880 --> 00:53:38,400
algo que podemos preguntarles, como

1570
00:53:38,400 --> 00:53:40,160
cuál es la diferencia en el

1571
00:53:40,160 --> 00:53:42,160
tiempo de cálculo para la

1572
00:53:42,160 --> 00:53:44,720
figura dos general o exacta, está bien, así que todavía estamos

1573
00:53:44,720 --> 00:53:45,359


1574
00:53:45,359 --> 00:53:47,520
pensando en el bandido de Bernoulli estacionario

1575
00:53:47,520 --> 00:53:49,119


1576
00:53:49,119 --> 00:53:51,119
aquí va a ser una trama ligeramente diferente

1577
00:53:51,119 --> 00:53:52,960


1578
00:53:52,960 --> 00:53:54,960
, es una comparación de la

1579
00:53:54,960 --> 00:53:57,119
trayectorias de arrepentimiento acumuladas para la

1580
00:53:57,119 --> 00:53:59,680
inferencia activa aproximada que es aai

1581
00:53:59,680 --> 00:54:02,000
tops optimistas y muestreo que es

1582
00:54:02,000 --> 00:54:03,200
púrpura

1583
00:54:03,200 --> 00:54:05,440
y bayesiano límite de confianza superior en

1584
00:54:05,440 --> 00:54:06,480
el verde azulado,

1585
00:54:06,480 --> 00:54:08,160
por lo que esas son las tres líneas y esa es

1586
00:54:08,160 --> 00:54:11,200
la leyenda en la parte superior izquierda

1587
00:54:11,200 --> 00:54:13,520
y como azul acaba de decir, la

1588
00:54:13,520 --> 00:54:15,920
precisión previa se fija en  el punto uno,

1589
00:54:15,920 --> 00:54:18,079
que es lo que encontraron en la figura uno,

1590
00:54:18,079 --> 00:54:19,760
como este tipo de caída

1591
00:54:19,760 --> 00:54:22,319
que todos tienen en el punto uno cercano

1592
00:54:22,319 --> 00:54:24,079
que parece ser una buena

1593
00:54:24,079 --> 00:54:26,480
configuración variable de precisión, por lo que

1594
00:54:26,480 --> 00:54:28,079
simplemente van a rodar con eso en lugar de

1595
00:54:28,079 --> 00:54:30,400
también barrer posiciones

1596
00:54:30,400 --> 00:54:33,359
y aquí  vemos columnas y filas similares

1597
00:54:33,359 --> 00:54:33,920


1598
00:54:33,920 --> 00:54:36,480
donde k diferente número de brazos en las

1599
00:54:36,480 --> 00:54:37,440
columnas

1600
00:54:37,440 --> 00:54:40,160
y luego diferentes dificultades de problemas

1601
00:54:40,160 --> 00:54:40,720
en

1602
00:54:40,720 --> 00:54:43,520
las filas

1603
00:54:43,760 --> 00:54:47,200
y luego  el arrepentimiento acumulativo, por

1604
00:54:47,200 --> 00:54:50,240
lo que desea un arrepentimiento más bajo que

1605
00:54:50,240 --> 00:54:51,680
tiene sentido, eso es todo en lo que

1606
00:54:51,680 --> 00:54:54,079
estamos entrenando, um,

1607
00:54:54,079 --> 00:54:56,480
¿qué vemos?

1608
00:54:56,480 --> 00:54:57,599


1609
00:54:57,599 --> 00:55:00,319


1610
00:55:00,319 --> 00:55:00,799


1611
00:55:00,799 --> 00:55:03,920
bueno, ya que la cantidad

1612
00:55:03,920 --> 00:55:04,640
de muestras

1613
00:55:04,640 --> 00:55:08,000
aumenta más allá de, digamos, cien en

1614
00:55:08,000 --> 00:55:10,640
casi todos los casos, la

1615
00:55:10,640 --> 00:55:12,480
inferencia activa aproximada de la línea roja

1616
00:55:12,480 --> 00:55:16,079
está por debajo de las otras,

1617
00:55:16,079 --> 00:55:18,559
por lo que se arrepiente menos con

1618
00:55:18,559 --> 00:55:20,000
la inferencia activa

1619
00:55:20,000 --> 00:55:22,880
en el bandido estacionario para muchas

1620
00:55:22,880 --> 00:55:24,799
combinaciones de parámetros,

1621
00:55:24,799 --> 00:55:27,599
está bien, pero hay algunos

1622
00:55:27,599 --> 00:55:28,720
piezas interesantes, por

1623
00:55:28,720 --> 00:55:31,920
lo que una de ellas es que a veces la inferencia activa al

1624
00:55:31,920 --> 00:55:32,400


1625
00:55:32,400 --> 00:55:34,799
principio tiene un mayor arrepentimiento, por lo que tal vez

1626
00:55:34,799 --> 00:55:37,200
sea un poco más

1627
00:55:37,200 --> 00:55:39,040
exploratorio al principio, eso es algo para ver

1628
00:55:39,040 --> 00:55:40,559
en la esquina inferior izquierda,

1629
00:55:40,559 --> 00:55:41,839
hay algunos otros donde es

1630
00:55:41,839 --> 00:55:43,599
algo así  codo

1631
00:55:43,599 --> 00:55:46,000
desde el principio, pero luego está este

1632
00:55:46,000 --> 00:55:48,240
comportamiento muy interesante que en realidad se

1633
00:55:48,240 --> 00:55:48,799
muestra mucho

1634
00:55:48,799 --> 00:55:51,839
en la parte superior izquierda, por lo que no siempre es

1635
00:55:51,839 --> 00:55:53,040
el caso de que simplemente puede

1636
00:55:53,040 --> 00:55:54,400
configurar su mod  el a alguna

1637
00:55:54,400 --> 00:55:56,079
combinación de parámetros y sacar una

1638
00:55:56,079 --> 00:55:57,520
conclusión realmente generalizada,

1639
00:55:57,520 --> 00:55:59,119
pero este es un punto increíble de los

1640
00:55:59,119 --> 00:56:00,559
autores,

1641
00:56:00,559 --> 00:56:04,559
por lo que están mirando

1642
00:56:04,559 --> 00:56:07,119
a un conjunto de agentes, así que aquí hay

1643
00:56:07,119 --> 00:56:07,599
mil

1644
00:56:07,599 --> 00:56:09,599
agentes como si estuvieran ejecutando

1645
00:56:09,599 --> 00:56:11,040
mil uh

1646
00:56:11,040 --> 00:56:13,599
de cada uno de ellos.  estos y luego tomando el

1647
00:56:13,599 --> 00:56:14,960
promedio, por lo que las líneas son

1648
00:56:14,960 --> 00:56:16,079
suaves

1649
00:56:16,079 --> 00:56:18,400
y lo que vemos en la parte superior izquierda

1650
00:56:18,400 --> 00:56:19,680
es que

1651
00:56:19,680 --> 00:56:21,359
la inferencia activa asiática está funcionando tan

1652
00:56:21,359 --> 00:56:22,960
bien como los otros algoritmos, entonces está funcionando

1653
00:56:22,960 --> 00:56:24,720
mejor a la derecha, arrepentimiento inferior

1654
00:56:24,720 --> 00:56:27,920
debajo de esas líneas, pero luego el error

1655
00:56:27,920 --> 00:56:28,480
El límite

1656
00:56:28,480 --> 00:56:30,880
aumenta ese sombreado rojo y comienza

1657
00:56:30,880 --> 00:56:32,079
a dirigirse muy hacia

1658
00:56:32,079 --> 00:56:34,960
arriba, por lo que es bastante fascinante lo que está

1659
00:56:34,960 --> 00:56:36,240
sucediendo y escriben que

1660
00:56:36,240 --> 00:56:37,920
esta divergencia está impulsada por un pequeño

1661
00:56:37,920 --> 00:56:40,400
porcentaje de los agentes en el conjunto

1662
00:56:40,400 --> 00:56:42,880
que no encontraron la solución precisa

1663
00:56:42,880 --> 00:56:43,680
y tenían demasiada

1664
00:56:43,680 --> 00:56:45,440
confianza en su estimación.  del brazo

1665
00:56:45,440 --> 00:56:47,680
con la mayor probabilidad de recompensa

1666
00:56:47,680 --> 00:56:50,799
por lo que ese tipo de gráfico circular de qué

1667
00:56:50,799 --> 00:56:51,440
brazo debe

1668
00:56:51,440 --> 00:56:54,319
elegir tuvo un mal comienzo y luego su

1669
00:56:54,319 --> 00:56:56,160
precisión fue tal t  que simplemente

1670
00:56:56,160 --> 00:56:56,640


1671
00:56:56,640 --> 00:56:58,799
aceptaron eso y siguieron viendo

1672
00:56:58,799 --> 00:57:00,559
la información que estaban obteniendo de

1673
00:57:00,559 --> 00:57:01,599
esa manera de

1674
00:57:01,599 --> 00:57:03,839
establecer el problema, por lo que

1675
00:57:03,839 --> 00:57:04,880
terminaron para una pequeña

1676
00:57:04,880 --> 00:57:06,960
fracción de los agentes

1677
00:57:06,960 --> 00:57:09,440
descarrilados y continuaron arrepintiéndose de las

1678
00:57:09,440 --> 00:57:11,359
decisiones que tomaron.

1679
00:57:11,359 --> 00:57:13,680
Debido a que estaban bloqueados en la

1680
00:57:13,680 --> 00:57:14,799
divergencia, no es

1681
00:57:14,799 --> 00:57:16,880
visible en la configuración anterior,

1682
00:57:16,880 --> 00:57:18,160


1683
00:57:18,160 --> 00:57:21,359
no estoy seguro de qué variables

1684
00:57:21,359 --> 00:57:22,160
deben verse allí,

1685
00:57:22,160 --> 00:57:24,079
ya que se requieren conjuntos más grandes y una

1686
00:57:24,079 --> 00:57:25,760
mayor cantidad de ensayos para observar

1687
00:57:25,760 --> 00:57:28,240
instancias subóptimas

1688
00:57:28,240 --> 00:57:29,520
. Puede parecer sorprendente que  la

1689
00:57:29,520 --> 00:57:31,200
divergencia es evidente solo para la

1690
00:57:31,200 --> 00:57:32,880
cantidad más pequeña de brazos considerados

1691
00:57:32,880 --> 00:57:34,000
porque se supone que es como el

1692
00:57:34,000 --> 00:57:34,640


1693
00:57:34,640 --> 00:57:36,880
problema más fácil; sin embargo, la razón de esto es que

1694
00:57:36,880 --> 00:57:39,280
cuanto menor es la cantidad de brazos,

1695
00:57:39,280 --> 00:57:41,440
más posibilidades tiene un agente de explorar

1696
00:57:41,440 --> 00:57:43,599
cada brazo individual para un número de prueba limitado

1697
00:57:43,599 --> 00:57:44,559


1698
00:57:44,559 --> 00:57:46,799
por lo que es casi como si fuera más fácil

1699
00:57:46,799 --> 00:57:48,559
encerrar sus creencias

1700
00:57:48,559 --> 00:57:51,040
y tal vez incluso creencias falsas para un pequeño

1701
00:57:51,040 --> 00:57:52,240
grupo social en

1702
00:57:52,240 --> 00:57:54,640
lugar de una fiesta con  k equivale a 80

1703
00:57:54,640 --> 00:57:56,160


1704
00:57:56,160 --> 00:57:58,079
personas, es como si hubiera tanto que aprender

1705
00:57:58,079 --> 00:57:59,680
que es menos probable que te quedes encerrado

1706
00:57:59,680 --> 00:58:02,880
antes, pero luego, en la fiesta más pequeña,

1707
00:58:02,880 --> 00:58:04,400
algunos de estos agentes de inferencia activa se

1708
00:58:04,400 --> 00:58:06,319
están enganchando

1709
00:58:06,319 --> 00:58:09,119
muy pronto a lo que creen que

1710
00:58:09,119 --> 00:58:10,880
son los brazos más gratificantes

1711
00:58:10,880 --> 00:58:13,200
y  luego terminan sin muestrear de

1712
00:58:13,200 --> 00:58:14,480


1713
00:58:14,480 --> 00:58:17,839
manera eficaz, por lo que terminan implementando

1714
00:58:17,839 --> 00:58:20,880
políticas lamentables, por lo que es bastante

1715
00:58:20,880 --> 00:58:23,280
fascinante, así que solo quiero hacer una nota al pie

1716
00:58:23,280 --> 00:58:24,160
aquí también,

1717
00:58:24,160 --> 00:58:26,960
um, entonces están viendo esta parte superior izquierda

1718
00:58:26,960 --> 00:58:27,520
donde k

1719
00:58:27,520 --> 00:58:30,559
es igual a 10 y luego este épsilon es 0.1,

1720
00:58:30,559 --> 00:58:33,680
la parte superior izquierda es  el más fácil y luego

1721
00:58:33,680 --> 00:58:35,359
el de abajo a la derecha es el más difícil

1722
00:58:35,359 --> 00:58:36,319
donde k

1723
00:58:36,319 --> 00:58:38,799
es el número de brazos y luego este

1724
00:58:38,799 --> 00:58:40,000
factor épsilon

1725
00:58:40,000 --> 00:58:42,880
es la diferencia entre los brazos así

1726
00:58:42,880 --> 00:58:43,280


1727
00:58:43,280 --> 00:58:44,960
que es la diferencia de resultado

1728
00:58:44,960 --> 00:58:46,640
si voy a un brazo que tiene una recompensa versus

1729
00:58:46,640 --> 00:58:48,640
un  brazo que no,

1730
00:58:48,640 --> 00:58:52,240
sí, creo que el punto uno es más difícil

1731
00:58:52,240 --> 00:58:54,160
porque hay menos distinción

1732
00:58:54,160 --> 00:58:55,839
entre uno mejor y uno peor,

1733
00:58:55,839 --> 00:58:59,760
así que la menor cantidad de brazos es

1734
00:58:59,760 --> 00:59:02,839
más fácil, pero luego el punto cuatro es un mayor

1735
00:59:02,839 --> 00:59:05,359
control  rast,

1736
00:59:05,359 --> 00:59:08,000
entonces el punto uno es más difícil que el punto cuatro,

1737
00:59:08,000 --> 00:59:08,480
está bien,

1738
00:59:08,480 --> 00:59:10,720
entonces es la parte inferior izquierda que es la

1739
00:59:10,720 --> 00:59:11,680


1740
00:59:11,680 --> 00:59:15,040
que sería la más fácil, bueno, depende

1741
00:59:15,040 --> 00:59:16,960
de lo que quieras decir con más fácil, quiero decir que todas las

1742
00:59:16,960 --> 00:59:18,240
cosas son iguales,

1743
00:59:18,240 --> 00:59:21,040
menos brazos es más fácil y luego todas las cosas

1744
00:59:21,040 --> 00:59:22,000
son iguales,

1745
00:59:22,000 --> 00:59:24,319
más contraste  entre los brazos buenos y los malos es

1746
00:59:24,319 --> 00:59:25,119


1747
00:59:25,119 --> 00:59:27,920
más fácil, así que lo tengo, así que la parte inferior

1748
00:59:27,920 --> 00:59:28,720
izquierda sería

1749
00:59:28,720 --> 00:59:32,160
la más fácil, sí, la menor cantidad de brazos y el

1750
00:59:32,160 --> 00:59:33,440
mayor contraste y,

1751
00:59:33,440 --> 00:59:34,880
curiosamente, ahí es donde vemos el

1752
00:59:34,880 --> 00:59:37,440
codo más grande de inferencia activa

1753
00:59:37,440 --> 00:59:38,640
como el mayor

1754
00:59:38,640 --> 00:59:41,680
arrepentimiento inicial, así que es como cuando  El

1755
00:59:41,680 --> 00:59:43,599
juego es fácil y hay pocos brazos. La

1756
00:59:43,599 --> 00:59:45,280
inferencia activa permanece

1757
00:59:45,280 --> 00:59:48,559
explorando un poco más, pero

1758
00:59:48,559 --> 00:59:51,760
luego termina enfocándose en lo que es correcto

1759
00:59:51,760 --> 00:59:54,079
y luego, especialmente cuando no hay

1760
00:59:54,079 --> 00:59:56,319
una diferencia tan grande entre los brazos,

1761
00:59:56,319 --> 00:59:59,359
todos tienen este ligero repunte y

1762
00:59:59,359 --> 01:00:00,400
luego la variación.

1763
01:00:00,400 --> 01:00:02,079
aumentando con este sombreado que

1764
01:00:02,079 --> 01:00:03,599
nos muestra que no es que

1765
01:00:03,599 --> 01:00:05,520
todo el conjunto se comporte de manera

1766
01:00:05,520 --> 01:00:06,720
diferente, pero

1767
01:00:06,720 --> 01:00:09,520
tal vez nuevamente que un subconjunto se está

1768
01:00:09,520 --> 01:00:11,359
trastornando

1769
01:00:11,359 --> 01:00:13,280
y th  es sí, es por eso que creo que cuanto

1770
01:00:13,280 --> 01:00:15,040
más grande sea el épsilon,

1771
01:00:15,040 --> 01:00:16,880
más difícil será, pero tendremos que reservarlo

1772
01:00:16,880 --> 01:00:18,240
para los autores.

1773
01:00:18,240 --> 01:00:19,760
Pensaría que cuanto menos contraste sería

1774
01:00:19,760 --> 01:00:21,359
más fácil, así que supongo que

1775
01:00:21,359 --> 01:00:23,680
eso no es muy claro, así que  solo

1776
01:00:23,680 --> 01:00:24,480
tendremos que preguntar,

1777
01:00:24,480 --> 01:00:27,599
sí, así que este es un

1778
01:00:27,599 --> 01:00:30,720
resultado genial y es casi como si fuera una

1779
01:00:30,720 --> 01:00:34,079
crítica calificada que hace un punto más importante

1780
01:00:34,079 --> 01:00:36,960
sobre dónde la inferencia activa

1781
01:00:36,960 --> 01:00:38,799
realmente puede tener éxito y dónde aún podría

1782
01:00:38,799 --> 01:00:39,920
necesitar desafíos a los que vamos a

1783
01:00:39,920 --> 01:00:40,880
regresar,

1784
01:00:40,880 --> 01:00:44,000
así que  eso es bandido estacionario

1785
01:00:44,000 --> 01:00:47,119
, vayamos al bandido que cambia, la

1786
01:00:47,119 --> 01:00:50,240
diferencia clave es que en cada paso de tiempo,

1787
01:00:50,240 --> 01:00:53,040
cualquier brazo en particular tiene una

1788
01:00:53,040 --> 01:00:54,559
recompensa máxima esperada

1789
01:00:54,559 --> 01:00:57,839
y esta probabilidad de recompensa va a

1790
01:00:57,839 --> 01:01:00,480
cambiar con una probabilidad, por lo que hay

1791
01:01:00,480 --> 01:01:01,520
una

1792
01:01:01,520 --> 01:01:05,119
fila de probabilidad um que es uh

1793
01:01:05,119 --> 01:01:09,599
es p  o es una fila, sí, con una fila

1794
01:01:09,599 --> 01:01:13,119
que es la probabilidad de que cambie la recompensa,

1795
01:01:13,119 --> 01:01:16,000
así que ahora no puedes aprenderlo

1796
01:01:16,000 --> 01:01:17,760
en el orden anterior porque las cosas están

1797
01:01:17,760 --> 01:01:19,280
cambiando con el tiempo, la probabilidad

1798
01:01:19,280 --> 01:01:22,240
del queso depende del tiempo.

1799
01:01:22,240 --> 01:01:25,119
sección 2.2 oh, sí, adelante azul oh

1800
01:01:25,119 --> 01:01:26,559
, no tengo nada, no, eso es todo, así que lo

1801
01:01:26,559 --> 01:01:28,799
hiciste, está bien, así que 2.2 es donde

1802
01:01:28,799 --> 01:01:29,760


1803
01:01:29,760 --> 01:01:31,359
dan el formalismo para el

1804
01:01:31,359 --> 01:01:33,280
bandido que cambia y,

1805
01:01:33,280 --> 01:01:35,280
en contraste con el

1806
01:01:35,280 --> 01:01:37,599
problema del bandido estacionario, los resultados se extraen de un tiempo

1807
01:01:37,599 --> 01:01:39,440


1808
01:01:39,440 --> 01:01:40,559
distribución de probabilidad de bernoulli dependiente, por

1809
01:01:40,559 --> 01:01:43,920
lo que se proporciona y, um,

1810
01:01:43,920 --> 01:01:46,799
aquellos que quieran ver los detalles

1811
01:01:46,799 --> 01:01:47,200
pueden

1812
01:01:47,200 --> 01:01:49,520
hacerlo, pero la diferencia clave es que

1813
01:01:49,520 --> 01:01:50,960
existe cierta probabilidad de

1814
01:01:50,960 --> 01:01:53,599
que las cosas cambien a medida que

1815
01:01:53,599 --> 01:01:54,480
juegas,

1816
01:01:54,480 --> 01:01:57,520
así que tenía una pregunta aquí para

1817
01:01:57,520 --> 01:01:58,240
el  autores

1818
01:01:58,240 --> 01:02:00,240
y espero poder

1819
01:02:00,240 --> 01:02:01,359
preguntarles si

1820
01:02:01,359 --> 01:02:03,920
la probabilidad es la misma y

1821
01:02:03,920 --> 01:02:06,160
luego cambia repentinamente, así que después de

1822
01:02:06,160 --> 01:02:09,039
20 pasos de tiempo o 50 pasos de tiempo como si fuera

1823
01:02:09,039 --> 01:02:10,160
lo mismo lo mismo

1824
01:02:10,160 --> 01:02:12,720
y luego cambia de repente o es

1825
01:02:12,720 --> 01:02:14,720
el es  cambiando en cada paso de tiempo, siento

1826
01:02:14,720 --> 01:02:15,280
que es

1827
01:02:15,280 --> 01:02:17,359
porque dice que cambia con cierta

1828
01:02:17,359 --> 01:02:19,599
probabilidad, pero por lo demás es constante,

1829
01:02:19,599 --> 01:02:21,920
así que tengo curiosidad como una constante como en

1830
01:02:21,920 --> 01:02:23,760
todos los brazos es que la probabilidad

1831
01:02:23,760 --> 01:02:25,599
eso es constante o siempre está

1832
01:02:25,599 --> 01:02:26,240
cambiando. No sé.

1833
01:02:26,240 --> 01:02:28,799
Buena pregunta.

1834
01:02:30,400 --> 01:02:33,119
Aquí llegamos a las comparaciones entre agentes

1835
01:02:33,119 --> 01:02:35,039
de diferentes algoritmos en

1836
01:02:35,039 --> 01:02:36,799
el bandido de bernoulli de conmutación

1837
01:02:36,799 --> 01:02:38,799
con una diferencia de resultado media fija, por lo que

1838
01:02:38,799 --> 01:02:40,799
épsilon es igual a

1839
01:02:40,799 --> 01:02:44,000
25. Entonces, están configurando épsilon fijo, así que ahora.

1840
01:02:44,000 --> 01:02:45,920
va a ser una situación diferente de fila y

1841
01:02:45,920 --> 01:02:48,160
columna,

1842
01:02:48,160 --> 01:02:51,599
por lo que en esta figura las tres columnas son

1843
01:02:51,599 --> 01:02:55,039
fila igual a 0,01 02 y o4,

1844
01:02:55,039 --> 01:02:56,799
por lo que esa es la probabilidad de cambio, por lo que

1845
01:02:56,799 --> 01:02:58,559
aquí en la columna de la izquierda

1846
01:02:58,559 --> 01:03:00,240
es un entorno dinámico con un uno

1847
01:03:00,240 --> 01:03:02,319
por ciento de pasos de tiempo, aquí hay un cambio

1848
01:03:02,319 --> 01:03:04,000
está en el lado derecho,

1849
01:03:04,000 --> 01:03:05,680
cambia hasta un cuatro por ciento,

1850
01:03:05,680 --> 01:03:08,960
por lo que, en igualdad de condiciones, cuanto más

1851
01:03:08,960 --> 01:03:11,440
cambie, más difícil será

1852
01:03:11,440 --> 01:03:12,480
porque será como

1853
01:03:12,480 --> 01:03:15,520
cambiar, um más rápido y luego, cuanto menos

1854
01:03:15,520 --> 01:03:17,280
cambie, es más como el

1855
01:03:17,280 --> 01:03:20,559
caso estático y luego las filas ahora son las  brazos

1856
01:03:20,559 --> 01:03:21,119
entonces k

1857
01:03:21,119 --> 01:03:24,880
10 20 y 40. para que todo sea

1858
01:03:24,880 --> 01:03:27,039
igual, es más fácil cuando hay menos brazos

1859
01:03:27,039 --> 01:03:30,160
porque hay menos decisiones que tomar

1860
01:03:30,160 --> 01:03:32,079
y luego vamos a buscar

1861
01:03:32,079 --> 01:03:33,760
dentro de cada celda

1862
01:03:33,760 --> 01:03:37,359
como  la tasa de arrepentimiento

1863
01:03:37,359 --> 01:03:40,880
esta r sub t con una tasa de arrepentimiento de tilde a lo

1864
01:03:40,880 --> 01:03:43,039
largo del tiempo donde nuevamente desea

1865
01:03:43,039 --> 01:03:45,440
tener menos arrepentimiento, por lo que cuanto más bajo es mejor

1866
01:03:45,440 --> 01:03:47,920
en función de las muestras, es decir, hasta

1867
01:03:47,920 --> 01:03:48,880
varios miles de

1868
01:03:48,880 --> 01:03:51,520
muestras y luego aquí están los algoritmos

1869
01:03:51,520 --> 01:03:52,640
que se comparan

1870
01:03:52,640 --> 01:03:55,119
inferencia activa  en rojo bayesiano

1871
01:03:55,119 --> 01:03:57,200
confianza superior en azul

1872
01:03:57,200 --> 01:03:59,920
thompson optimista en púrpura y luego

1873
01:03:59,920 --> 01:04:02,480
control aleatorio en la línea discontinua negra,

1874
01:04:02,480 --> 01:04:06,000
por lo que la jugada aleatoria es um, como es

1875
01:04:06,000 --> 01:04:09,200
buena, es um, no es la jugada contradictoria,

1876
01:04:09,200 --> 01:04:10,799
por lo que no es como si estuvieras

1877
01:04:10,799 --> 01:04:13,119
eligiendo  perder, pero esta es la reproducción aleatoria

1878
01:04:13,119 --> 01:04:14,880
y lo que estamos viendo es que

1879
01:04:14,880 --> 01:04:18,000
acumula una cantidad estática de

1880
01:04:18,000 --> 01:04:21,760
tasa de arrepentimiento, comienza con el mismo valor,

1881
01:04:21,760 --> 01:04:25,200
los algoritmos púrpura y verde azulado

1882
01:04:25,200 --> 01:04:27,839
también convergen en una tasa de arrepentimiento

1883
01:04:27,839 --> 01:04:28,240
que es

1884
01:04:28,240 --> 01:04:30,799
más baja que la reproducción aleatoria, por lo que  están

1885
01:04:30,799 --> 01:04:32,960
jugando mejor que al azar,

1886
01:04:32,960 --> 01:04:36,400
pero vemos que, en esencia, en todos los casos,

1887
01:04:36,400 --> 01:04:39,119
la inferencia activa es más baja que estos

1888
01:04:39,119 --> 01:04:39,440
otros

1889
01:04:39,440 --> 01:04:41,920
algoritmos, por lo que cuando decimos "oh, la

1890
01:04:41,920 --> 01:04:43,839
inferencia activa tiene un mejor rendimiento

1891
01:04:43,839 --> 01:04:47,599
en esta tarea".  yo, otro algoritmo,

1892
01:04:47,599 --> 01:04:50,559
esto es algo así como esto

1893
01:04:50,559 --> 01:04:50,960


1894
01:04:50,960 --> 01:04:54,079
dice que a medida que pasa el tiempo, la

1895
01:04:54,079 --> 01:04:54,559
inferencia de octava

1896
01:04:54,559 --> 01:04:57,200
se arrepiente a un ritmo más bajo que

1897
01:04:57,200 --> 01:04:58,640
los otros algoritmos, simplemente se está

1898
01:04:58,640 --> 01:05:00,400
desempeñando mejor, está implementando una

1899
01:05:00,400 --> 01:05:00,799
mejor

1900
01:05:00,799 --> 01:05:04,880
política, entonces podemos ver que

1901
01:05:04,880 --> 01:05:08,240
menos cambia  y menos brazos

1902
01:05:08,240 --> 01:05:11,440
en la parte superior izquierda, así que es más fácil

1903
01:05:11,440 --> 01:05:14,079
, vemos que la diferencia entre

1904
01:05:14,079 --> 01:05:15,599
el juego aleatorio y el algoritmo

1905
01:05:15,599 --> 01:05:19,200
es significativa y la inferencia activa funciona

1906
01:05:19,200 --> 01:05:19,520


1907
01:05:19,520 --> 01:05:22,559
muy bien, mientras que cuando tienes un

1908
01:05:22,559 --> 01:05:23,760
entorno muy dinámico

1909
01:05:23,760 --> 01:05:27,520
y más brazos, no

1910
01:05:27,520 --> 01:05:29,599
obtienes tanto.  de un arrepentimiento, todavía lo está haciendo

1911
01:05:29,599 --> 01:05:31,119
relativamente mejor y la inferencia aún activa

1912
01:05:31,119 --> 01:05:32,480
supera a los otros

1913
01:05:32,480 --> 01:05:33,440
algoritmos,

1914
01:05:33,440 --> 01:05:34,960
pero es como imaginar si cambiara

1915
01:05:34,960 --> 01:05:36,640
cada pocos pasos de tiempo y hubiera 100

1916
01:05:36,640 --> 01:05:37,520
brazos

1917
01:05:37,520 --> 01:05:40,000
que solo usted nunca sería

1918
01:05:40,000 --> 01:05:40,880
capaz de probar lo

1919
01:05:40,880 --> 01:05:43,599
suficiente para hacer una significativa  actualice

1920
01:05:43,599 --> 01:05:44,640
su modelo,

1921
01:05:44,640 --> 01:05:47,440
por eso cuanto más rápido cambien las cosas

1922
01:05:47,440 --> 01:05:49,119
y más brazos haya,

1923
01:05:49,119 --> 01:05:51,359
mayor será el rendimiento general de cualquier

1924
01:05:51,359 --> 01:05:52,720
algoritmo de aprendizaje automático  thm va a

1925
01:05:52,720 --> 01:05:54,880
converger al juego aleatorio,

1926
01:05:54,880 --> 01:05:57,440
mientras que cuanto más estático sea el problema

1927
01:05:57,440 --> 01:05:59,839
y luego haya menos opciones,

1928
01:05:59,839 --> 01:06:03,200
entonces mejores y mejores estrategias

1929
01:06:03,200 --> 01:06:04,720
se desempeñarán cada vez mejor en

1930
01:06:04,720 --> 01:06:06,480
relación con el juego aleatorio,

1931
01:06:06,480 --> 01:06:09,359
por lo que es genial

1932
01:06:09,359 --> 01:06:11,359
que hagan simulaciones que hacen.

1933
01:06:11,359 --> 01:06:14,480
um, supongo que miles de simulaciones

1934
01:06:14,480 --> 01:06:16,000
y luego el programa de cambio se

1935
01:06:16,000 --> 01:06:17,760
genera aleatoriamente para cada

1936
01:06:17,760 --> 01:06:19,599
instancia de agente dentro del conjunto,

1937
01:06:19,599 --> 01:06:23,359
por lo que hacen una simulación completa mil

1938
01:06:23,359 --> 01:06:25,039
veces para cada uno de estos casos y luego

1939
01:06:25,039 --> 01:06:26,400
promedian

1940
01:06:26,400 --> 01:06:29,839
y sí, bien hecho inferencia activa

1941
01:06:29,839 --> 01:06:32,720
bastante bueno para ver  que le está yendo

1942
01:06:32,720 --> 01:06:33,200
mejor

1943
01:06:33,200 --> 01:06:35,440
en el bandido de bernoulli de cambio para una

1944
01:06:35,440 --> 01:06:36,880
amplia gama

1945
01:06:36,880 --> 01:06:40,640
de situaciones y rápidamente

1946
01:06:40,640 --> 01:06:41,599
descubre

1947
01:06:41,599 --> 01:06:44,400
una buena manera de trabajar y luego se mantiene en

1948
01:06:44,400 --> 01:06:48,559
esa baja tasa de acumulación de arrepentimiento

1949
01:06:48,640 --> 01:06:52,160
cualquier pensamiento sobre tres súper genial

1950
01:06:52,160 --> 01:06:55,200
sí ahora um en

1951
01:06:55,200 --> 01:06:59,599
cuatro, vamos a arreglar el número de brazos,

1952
01:06:59,599 --> 01:07:02,000
así que ahora estamos en k es igual a 20 brazos en el

1953
01:07:02,000 --> 01:07:03,680
bandido de bernoulli de conmutación

1954
01:07:03,680 --> 01:07:04,880
y luego vamos a comparar

1955
01:07:04,880 --> 01:07:07,200
estos algoritmos ag  De acuerdo, aquí

1956
01:07:07,200 --> 01:07:09,440
las columnas son tal como eran antes,

1957
01:07:09,440 --> 01:07:12,400
con menos filas cambiantes igual a 0.01 o2

1958
01:07:12,400 --> 01:07:14,000
y o4 a la derecha,

1959
01:07:14,000 --> 01:07:16,480
pero ahora, como vimos en las

1960
01:07:16,480 --> 01:07:18,640
figuras anteriores, tenemos épsilon,

1961
01:07:18,640 --> 01:07:21,359
que es el diferencial entre los

1962
01:07:21,359 --> 01:07:23,680
brazos gratificantes y menos gratificantes

1963
01:07:23,680 --> 01:07:28,960
como las filas.  así que podemos pensar en

1964
01:07:28,960 --> 01:07:30,480
el menor cambio

1965
01:07:30,480 --> 01:07:33,599
y el mayor contraste entre las filas

1966
01:07:33,599 --> 01:07:37,039
es donde ves la mayor

1967
01:07:37,039 --> 01:07:40,319
ganancia en relación con

1968
01:07:40,319 --> 01:07:43,359
el juego aleatorio, mientras que cuando estás en la

1969
01:07:43,359 --> 01:07:46,240
configuración más dinámica y cuando hay

1970
01:07:46,240 --> 01:07:47,920
menos diferencias entre la elección

1971
01:07:47,920 --> 01:07:50,000
que haces en términos  del resultado,

1972
01:07:50,000 --> 01:07:53,280
entonces hay menos diferencia de tasa de arrepentimiento

1973
01:07:53,280 --> 01:07:54,799
con los algoritmos,

1974
01:07:54,799 --> 01:07:57,920
pero nuevamente, en general, la

1975
01:07:57,920 --> 01:08:00,000
inferencia activa está funcionando mejor

1976
01:08:00,000 --> 01:08:01,920
que estos otros algoritmos,

1977
01:08:01,920 --> 01:08:05,359
por lo que a medida que aumenta el muestreo,

1978
01:08:05,359 --> 01:08:07,200
la inferencia activa se bloquea en un lugar bastante

1979
01:08:07,200 --> 01:08:09,039
bueno alrededor de

1980
01:08:09,039 --> 01:08:12,160
200 o 500 muestras

1981
01:08:12,160 --> 01:08:14,720
y esto es  para los 20 brazos, por lo que

1982
01:08:14,720 --> 01:08:15,440
es como si

1983
01:08:15,440 --> 01:08:17,600
hubiera visitado cada brazo, probablemente unas cuantas

1984
01:08:17,600 --> 01:08:18,479
veces,

1985
01:08:18,479 --> 01:08:20,719
quizás algunas más que otras, pero nuevamente

1986
01:08:20,719 --> 01:08:22,479
, siempre están cambiando

1987
01:08:22,479 --> 01:08:26,158
y, por lo tanto, activas.  La inferencia ve es capaz de

1988
01:08:26,158 --> 01:08:28,158
hacer frente a eso y también es interesante

1989
01:08:28,158 --> 01:08:29,759
que, especialmente este verde

1990
01:08:29,759 --> 01:08:33,839
azulado, casi tiene una

1991
01:08:33,839 --> 01:08:36,839
tasa de arrepentimiento más baja y luego

1992
01:08:36,839 --> 01:08:38,319
aumenta sigilosamente,

1993
01:08:38,319 --> 01:08:40,880
mientras que al menos solo visualmente estamos

1994
01:08:40,880 --> 01:08:43,120
viendo una especie de línea plana de inferencia activa

1995
01:08:43,120 --> 01:08:45,439
pero no vuelve a subir y  así que eso es

1996
01:08:45,439 --> 01:08:46,719
algo que puede pasar

1997
01:08:46,719 --> 01:08:48,158
con todo tipo de algoritmos

1998
01:08:48,158 --> 01:08:49,759
que quedarán atrapados en un

1999
01:08:49,759 --> 01:08:50,839


2000
01:08:50,839 --> 01:08:53,520
régimen de precisión aberrante y

2001
01:08:53,520 --> 01:08:57,520
um así que hay otra forma de

2002
01:08:57,520 --> 01:08:59,040
dividirlo en la figura

2003
01:08:59,040 --> 01:09:01,759
tres fijaron el épsilon la diferencia

2004
01:09:01,759 --> 01:09:02,799
entre

2005
01:09:02,799 --> 01:09:05,439
los brazos más y menos gratificantes y

2006
01:09:05,439 --> 01:09:06,880
luego  exploraron cómo el número de

2007
01:09:06,880 --> 01:09:08,719
brazos se asoció con la dinámica de

2008
01:09:08,719 --> 01:09:10,319
un problema que se estaba resolviendo

2009
01:09:10,319 --> 01:09:13,520
en la figura cuatro arreglamos los brazos

2010
01:09:13,520 --> 01:09:15,759
para que pudiéramos explorar cómo rho la

2011
01:09:15,759 --> 01:09:16,880


2012
01:09:16,880 --> 01:09:19,679
probabilidad de cambio dinámico y épsilon el

2013
01:09:19,679 --> 01:09:21,040
diferencial

2014
01:09:21,040 --> 01:09:24,799
cómo cambian el rendimiento

2015
01:09:24,799 --> 01:09:27,920
y luego um

2016
01:09:28,399 --> 01:09:31,120
bien bien

2017
01:09:32,158 --> 01:09:36,238
ahora um  está bien, la figura cinco

2018
01:09:36,238 --> 01:09:39,439
aquí es, uh, otra figura de apariencia similar

2019
01:09:39,439 --> 01:09:40,719


2020
01:09:40,719 --> 01:09:44,319
, vamos a tener una fila similar

2021
01:09:44,319 --> 01:09:46,560
para la columna, así que menos cambios y izquierda

2022
01:09:46,560 --> 01:09:48,640
co  lumn más cambiando en la columna de la derecha

2023
01:09:48,640 --> 01:09:49,759
y tendremos el número de

2024
01:09:49,759 --> 01:09:52,238
brazos como la figura tres con 10

2025
01:09:52,238 --> 01:09:55,159
20 y 40 pero habrá una

2026
01:09:55,159 --> 01:09:58,080
dificultad no estacionaria

2027
01:09:58,080 --> 01:10:02,480
y la dificultad del problema es

2028
01:10:02,480 --> 01:10:04,239
no estacionaria como ventaja  del

2029
01:10:04,239 --> 01:10:05,760
mejor brazo sobre el segundo mejor brazo

2030
01:10:05,760 --> 01:10:07,600
cambia con el tiempo

2031
01:10:07,600 --> 01:10:11,120
ah, sí, entonces épsilon varía,

2032
01:10:11,120 --> 01:10:14,159
sí, exactamente, así que cambia el cambio de

2033
01:10:14,159 --> 01:10:15,360
épsilon a tiempo

2034
01:10:15,360 --> 01:10:17,760
y arreglan la precisión sobre las

2035
01:10:17,760 --> 01:10:18,960
preferencias a lambda

2036
01:10:18,960 --> 01:10:22,159
igual a 0.5, por lo que es una lambda

2037
01:10:22,159 --> 01:10:22,880
diferente a la que usaron en

2038
01:10:22,880 --> 01:10:25,440
otros lugares y esto es solo  En cierto modo,

2039
01:10:25,440 --> 01:10:26,080


2040
01:10:26,080 --> 01:10:28,880
quiero decir que los valores de las variables que

2041
01:10:28,880 --> 01:10:29,280
eligen

2042
01:10:29,280 --> 01:10:30,800
claramente funcionan porque están

2043
01:10:30,800 --> 01:10:32,400
superando el estado del arte, pero

2044
01:10:32,400 --> 01:10:34,159
aquí eligieron una variable diferente,

2045
01:10:34,159 --> 01:10:37,040
sí, azul, la lambda de 0.5 que usaron en

2046
01:10:37,040 --> 01:10:37,440
todos

2047
01:10:37,440 --> 01:10:40,320
los gráficos de conmutación, oh sí, figura 3

2048
01:10:40,320 --> 01:10:41,679
figura 4  y la figura 5.

2049
01:10:41,679 --> 01:10:43,679
y lo cambiaron a 0.5 en el

2050
01:10:43,679 --> 01:10:45,360
cambio porque solo optimizaron

2051
01:10:45,360 --> 01:10:46,400
para eso pero no mostraron

2052
01:10:46,400 --> 01:10:48,800
esa optimización variable, está bien, gracias

2053
01:10:48,800 --> 01:10:50,000


2054
01:10:50,000 --> 01:10:53,199
y aquí podemos ver que

2055
01:10:53,199 --> 01:10:55,440
um, sí, actúe  Tengo la inferencia de que la línea roja está

2056
01:10:55,440 --> 01:10:56,480
en la parte inferior

2057
01:10:56,480 --> 01:10:58,640
y no tiene este tipo de

2058
01:10:58,640 --> 01:10:59,520


2059
01:10:59,520 --> 01:11:02,800
aumento secundario en la tasa de arrepentimiento, por lo que, incluso para la

2060
01:11:02,800 --> 01:11:06,560
dinámica a la derecha y muchos brazos

2061
01:11:06,560 --> 01:11:08,640
en la parte inferior derecha, vemos que la

2062
01:11:08,640 --> 01:11:09,840
inferencia activa funciona

2063
01:11:09,840 --> 01:11:13,120
bien, así que figura tres, cuatro y cinco.

2064
01:11:13,120 --> 01:11:16,080
realmente es un caso súper convincente para

2065
01:11:16,080 --> 01:11:17,600
la inferencia activa que

2066
01:11:17,600 --> 01:11:20,800
supera a los algoritmos de última generación buen

2067
01:11:20,800 --> 01:11:22,640
trabajo y eso es algo que

2068
01:11:22,640 --> 01:11:24,719
nos entusiasma

2069
01:11:24,719 --> 01:11:26,400
mucho vayamos a la discusión y

2070
01:11:26,400 --> 01:11:27,760
dediquemos un par de minutos

2071
01:11:27,760 --> 01:11:30,640
a la discusión y las notas finales

2072
01:11:30,640 --> 01:11:31,440
y luego

2073
01:11:31,440 --> 01:11:34,640
Esperaremos con ansias el punto uno y el punto dos.

2074
01:11:34,640 --> 01:11:37,280
Abren la discusión ensayando

2075
01:11:37,280 --> 01:11:38,000


2076
01:11:38,000 --> 01:11:40,719
lo que mencionaron anteriormente de

2077
01:11:40,719 --> 01:11:42,480
que están comparando la inferencia activa con

2078
01:11:42,480 --> 01:11:43,920
dos algoritmos de aprendizaje automático de última generación,

2079
01:11:43,920 --> 01:11:45,920
el límite de confianza superior bayesiano

2080
01:11:45,920 --> 01:11:46,320


2081
01:11:46,320 --> 01:11:48,400
y el  muestreo de thompson optimista

2082
01:11:48,400 --> 01:11:49,760
ese es el par de algoritmos

2083
01:11:49,760 --> 01:11:52,159
en el par de problemas los

2084
01:11:52,159 --> 01:11:53,679


2085
01:11:53,679 --> 01:11:56,400
bandidos estocásticos multi-armados estacionarios y no estacionarios su

2086
01:11:56,400 --> 01:11:57,440
contribución

2087
01:11:57,440 --> 01:11:59,280
entre otras cosas w  como la introducción

2088
01:11:59,280 --> 01:12:00,960
del algoritmo de inferencia activo aproximado

2089
01:12:00,960 --> 01:12:02,159


2090
01:12:02,159 --> 01:12:04,239
y luego realizan algunas comprobaciones para

2091
01:12:04,239 --> 01:12:05,440
demostrar que está

2092
01:12:05,440 --> 01:12:08,960
funcionando tan bien como usted podría hacerlo exactamente,

2093
01:12:08,960 --> 01:12:10,880
por lo que derivaron un

2094
01:12:10,880 --> 01:12:12,800
algoritmo de inferencia activo que es eficiente y fácilmente

2095
01:12:12,800 --> 01:12:15,280
escalable a problemas de alta dimensión,

2096
01:12:15,280 --> 01:12:17,920
lo que nos lleva a preguntar, por supuesto.  ¿Dónde

2097
01:12:17,920 --> 01:12:18,800
podría ser genial,

2098
01:12:18,800 --> 01:12:21,600
útil o importante aplicar la inferencia activa?

2099
01:12:21,600 --> 01:12:22,800


2100
01:12:22,800 --> 01:12:25,280
Sabemos que hay muchas ideas

2101
01:12:25,280 --> 01:12:26,159
sobre esto

2102
01:12:26,159 --> 01:12:27,920
y, con suerte, habrá muchas más, pero

2103
01:12:27,920 --> 01:12:29,920
solo notaremos para aquellos que están

2104
01:12:29,920 --> 01:12:32,880
escuchando en el momento adecuado

2105
01:12:32,880 --> 01:12:34,719
que recientemente se anunció una red.  Hack

2106
01:12:34,719 --> 01:12:37,600
Challenge y comenzaremos a

2107
01:12:37,600 --> 01:12:38,400
trabajar en esto

2108
01:12:38,400 --> 01:12:40,480
a fines de julio o principios de

2109
01:12:40,480 --> 01:12:42,320
agosto de 2021,

2110
01:12:42,320 --> 01:12:44,719
por lo que si está interesado en aplicar

2111
01:12:44,719 --> 01:12:46,080
la inferencia activa a

2112
01:12:46,080 --> 01:12:49,280
un desafío de rendimiento de videojuegos,

2113
01:12:49,280 --> 01:12:52,239
esperamos que tenga un equipo colaborativo.

2114
01:12:52,239 --> 01:12:54,080
porque este desafío

2115
01:12:54,080 --> 01:12:56,560
será una oportunidad increíble para

2116
01:12:56,560 --> 01:12:58,320
demostrarle al mundo lo que

2117
01:12:58,320 --> 01:12:59,600
puede hacer la inferencia activa,

2118
01:12:59,600 --> 01:13:01,440
pero también esperamos con ansias  Los

2119
01:13:01,440 --> 01:13:02,840
autores y todos los

2120
01:13:02,840 --> 01:13:06,080
invitados comparten qué tipo de

2121
01:13:06,080 --> 01:13:07,760
preguntas creen que podría ser interesante

2122
01:13:07,760 --> 01:13:09,120
explorar usando

2123
01:13:09,120 --> 01:13:10,560


2124
01:13:10,560 --> 01:13:13,520
algoritmos de tipo de inferencia activos aproximados como este.

2125
01:13:16,159 --> 01:13:18,880
Aquí hay un punto realmente bueno que habla

2126
01:13:18,880 --> 01:13:19,600
de

2127
01:13:19,600 --> 01:13:22,719
eso, um nuevamente en la figura dos,

2128
01:13:22,719 --> 01:13:26,159
donde vimos ese tipo de arrepentimiento desbocado

2129
01:13:26,159 --> 01:13:29,679
en un pequeño  fracción de los agentes

2130
01:13:29,679 --> 01:13:31,199
que acababan de quedar atrapados en

2131
01:13:31,199 --> 01:13:33,440
decisiones extremadamente lamentables

2132
01:13:33,440 --> 01:13:36,880
en ese caso k es igual a 10,

2133
01:13:36,880 --> 01:13:40,560
entonces, ¿qué dicen al respecto?

2134
01:13:40,560 --> 01:13:42,560
Para nuestra sorpresa, la

2135
01:13:42,560 --> 01:13:44,239
comparación del algoritmo empírico en el

2136
01:13:44,239 --> 01:13:45,679
problema del bandido estacionario, la figura 2,

2137
01:13:45,679 --> 01:13:47,040
mostró que el

2138
01:13:47,040 --> 01:13:48,880
algoritmo de inferencia activa no es asintóticamente

2139
01:13:48,880 --> 01:13:49,920
eficiente,

2140
01:13:49,920 --> 01:13:51,920
el arrepentimiento acumulativo aumentó más rápido

2141
01:13:51,920 --> 01:13:53,280
que logarítmico

2142
01:13:53,280 --> 01:13:56,480
en el límite de pruebas grandes, por lo que, en otras

2143
01:13:56,480 --> 01:13:58,000
palabras, aunque no

2144
01:13:58,000 --> 01:14:00,320
todos los agentes se trastornan, los

2145
01:14:00,320 --> 01:14:01,040
que lo hacen

2146
01:14:01,040 --> 01:14:03,440
están arrastrando al grupo de una manera

2147
01:14:03,440 --> 01:14:04,400
que está

2148
01:14:04,400 --> 01:14:08,480
dañando esta causa porque el comportamiento

2149
01:14:08,480 --> 01:14:10,320
parece ser el  precisión previa fija

2150
01:14:10,320 --> 01:14:12,080
sobre las preferencias lambda

2151
01:14:12,080 --> 01:14:13,679
que actúa como un parámetro de equilibrio

2152
01:14:13,679 --> 01:14:16,320
entre expl  oración y explotación, por

2153
01:14:16,320 --> 01:14:19,120
lo que esta es una pieza bastante interesante en

2154
01:14:19,120 --> 01:14:19,920
lugar de

2155
01:14:19,920 --> 01:14:22,480
dos modos explorar y explotar y luego

2156
01:14:22,480 --> 01:14:24,080
vamos a tener un parámetro que nos cambia de

2157
01:14:24,080 --> 01:14:25,520
un lado a otro como un

2158
01:14:25,520 --> 01:14:26,320
interruptor de luz

2159
01:14:26,320 --> 01:14:28,560
o tenemos un modo de exploración extrema y

2160
01:14:28,560 --> 01:14:30,800
una explotación extrema  mode en el modelo

2161
01:14:30,800 --> 01:14:32,080
y luego vamos a tener un atenuador

2162
01:14:32,080 --> 01:14:34,239
que va entre los dos en inferencia activa,

2163
01:14:34,239 --> 01:14:35,360


2164
01:14:35,360 --> 01:14:38,480
la perilla que hace eso es en

2165
01:14:38,480 --> 01:14:40,080
realidad la precisión previa

2166
01:14:40,080 --> 01:14:43,760
sobre las preferencias, por lo que

2167
01:14:43,760 --> 01:14:47,600
si no tiene preferencias, es decir, no tiene

2168
01:14:47,600 --> 01:14:50,080
precisión sobre las preferencias,

2169
01:14:50,080 --> 01:14:51,679
vas a actuar de la

2170
01:14:51,679 --> 01:14:53,600
manera más exploratoria

2171
01:14:53,600 --> 01:14:55,600
si tienes un previo increíblemente fuerte e

2172
01:14:55,600 --> 01:14:57,920
increíblemente preciso

2173
01:14:57,920 --> 01:15:01,199
sobre tus preferencias, entonces

2174
01:15:01,199 --> 01:15:03,840
vas a actuar de una manera muy explotadora

2175
01:15:03,840 --> 01:15:05,520
como si hubiera dos restaurantes

2176
01:15:05,520 --> 01:15:08,239
y uno de ellos te gustara  conoce 60 el

2177
01:15:08,239 --> 01:15:10,159
otro que te gusta 40

2178
01:15:10,159 --> 01:15:11,440
si no tienes preferencia vas

2179
01:15:11,440 --> 01:15:13,199
a ir a él 50 50. eso es como

2180
01:15:13,199 --> 01:15:15,360
explorar pero luego si tienes una

2181
01:15:15,360 --> 01:15:17,360
precisión súper alta sobre tus preferencias

2182
01:15:17,360 --> 01:15:18,960
siempre estás  y va a ir al

2183
01:15:18,960 --> 01:15:19,280


2184
01:15:19,280 --> 01:15:21,199
que prefiera, incluso si solo lo prefiere ligeramente.

2185
01:15:21,199 --> 01:15:22,800


2186
01:15:22,800 --> 01:15:24,960
Un análisis de cómo el rendimiento del

2187
01:15:24,960 --> 01:15:27,120
algoritmo depende de

2188
01:15:27,120 --> 01:15:28,800
ese parámetro mostró que los valores de los parámetros que brindan

2189
01:15:28,800 --> 01:15:31,600
el mejor rendimiento disminuyen con el tiempo,

2190
01:15:31,600 --> 01:15:33,199
lo que sugiere que este parámetro debe ser

2191
01:15:33,199 --> 01:15:35,280
adaptativo y decaer.  con el tiempo, a medida que la necesidad

2192
01:15:35,280 --> 01:15:37,520
de exploración disminuye,

2193
01:15:37,520 --> 01:15:40,320
así que comience con poca precisión sobre sus

2194
01:15:40,320 --> 01:15:41,440
preferencias

2195
01:15:41,440 --> 01:15:44,640
y luego aprenda

2196
01:15:44,640 --> 01:15:46,800
y actualice para que eventualmente

2197
01:15:46,800 --> 01:15:49,040
aumente su precisión. Los

2198
01:15:49,040 --> 01:15:50,800
intentos posteriores de remediar la situación con un

2199
01:15:50,800 --> 01:15:52,480
esquema de descomposición simple y ampliamente utilizado

2200
01:15:52,480 --> 01:15:53,760
no

2201
01:15:53,760 --> 01:15:55,679
lo conseguimos.  el logaritmo del tiempo, por lo que simplemente

2202
01:15:55,679 --> 01:15:57,600
hace que la precisión sea

2203
01:15:57,600 --> 01:16:00,080
directamente una función del tiempo como si

2204
01:16:00,080 --> 01:16:00,960
supiera uno

2205
01:16:00,960 --> 01:16:02,880
sobre el número de intentos, ese tipo

2206
01:16:02,880 --> 01:16:04,159
de cosas es como si fuera una

2207
01:16:04,159 --> 01:16:05,600
función que escala con el número de

2208
01:16:05,600 --> 01:16:07,280
intentos, así que aquí

2209
01:16:07,280 --> 01:16:10,400
lo escala con el logaritmo de  tiempo

2210
01:16:10,400 --> 01:16:12,000
esto indica que no es una

2211
01:16:12,000 --> 01:16:13,679
relación simple y

2212
01:16:13,679 --> 01:16:15,360
se necesitará un análisis teórico adecuado para identificar

2213
01:16:15,360 --> 01:16:17,760
si un sch  eme existe,

2214
01:16:17,760 --> 01:16:20,239
así que es bastante interesante, ¿

2215
01:16:20,239 --> 01:16:20,880
cómo vamos a

2216
01:16:20,880 --> 01:16:23,440
retroceder un nivel? De acuerdo, creemos que

2217
01:16:23,440 --> 01:16:25,520
la arquitectura de inferencia activa

2218
01:16:25,520 --> 01:16:28,000
será una forma realmente productiva de

2219
01:16:28,000 --> 01:16:30,239
modelar el aprendizaje bajo incertidumbre,

2220
01:16:30,239 --> 01:16:32,080
pero también estamos empujando el problema

2221
01:16:32,080 --> 01:16:33,440
a un nivel superior, lo cual está

2222
01:16:33,440 --> 01:16:36,960
bien.  inciertos deberíamos ser y luego

2223
01:16:36,960 --> 01:16:39,360
cómo deberíamos cambiar esa incertidumbre

2224
01:16:39,360 --> 01:16:40,800
sobre las preferencias moviéndose a

2225
01:16:40,800 --> 01:16:45,360
través del tiempo tan buen punto allí

2226
01:16:45,360 --> 01:16:48,640
y luego um un

2227
01:16:48,640 --> 01:16:52,239
último pensamiento es en lo no estacionario

2228
01:16:52,239 --> 01:16:54,400
por lo que el bandido de conmutación dinámica el

2229
01:16:54,400 --> 01:16:57,120
algoritmo de inferencia activo generalmente

2230
01:16:57,120 --> 01:16:58,560
superó el límite de confianza superior bayesiano

2231
01:16:58,560 --> 01:17:00,960
y  el

2232
01:17:00,960 --> 01:17:02,400
muestreo de thompson optimista

2233
01:17:02,400 --> 01:17:04,159
proporciona evidencia de que el

2234
01:17:04,159 --> 01:17:06,000
marco de inferencia activa puede proporcionar una buena

2235
01:17:06,000 --> 01:17:08,159
solución para los problemas de optimización que

2236
01:17:08,159 --> 01:17:11,040
requieren una adaptación continua

2237
01:17:11,040 --> 01:17:13,040
la inferencia activa proporciona la forma más

2238
01:17:13,040 --> 01:17:14,159
eficiente

2239
01:17:14,159 --> 01:17:16,880
de obtener información y esta propiedad

2240
01:17:16,880 --> 01:17:17,840
del algoritmo

2241
01:17:17,840 --> 01:17:21,679
vale la pena en la configuración no estacionaria

2242
01:17:21,679 --> 01:17:23,440
puntos interesantes  que será increíble

2243
01:17:23,440 --> 01:17:25,760
escuchar la perspectiva del autor

2244
01:17:25,760 --> 01:17:28,239


2245
01:17:28,239 --> 01:17:29,360


2246
01:17:29,360 --> 01:17:32,560


2247
01:17:32,560 --> 01:17:35,520
Entonces, ¿cómo comparamos los algoritmos del marco de inferencia activa con el aprendizaje automático de manera más amplia y, luego, especialmente para los problemas en los que la

2248
01:17:35,520 --> 01:17:36,960


2249
01:17:36,960 --> 01:17:40,000
búsqueda informada es útil, como

2250
01:17:40,000 --> 01:17:42,960
no es que épsilon codicioso simplemente a veces

2251
01:17:42,960 --> 01:17:44,159
mira hacia otro lado de los mejores y elige

2252
01:17:44,159 --> 01:17:45,679
al azar

2253
01:17:45,679 --> 01:17:49,360
y no solo el muestreo de Thompson?

2254
01:17:49,360 --> 01:17:51,199
Recuerde elegir cada uno  brazo de acuerdo con la

2255
01:17:51,199 --> 01:17:53,600
probabilidad de que sea el mejor brazo

2256
01:17:53,600 --> 01:17:56,480
podríamos tener un esquema aún más informado o con

2257
01:17:56,480 --> 01:17:57,360


2258
01:17:57,360 --> 01:18:00,480
mejor rendimiento empírico para hacer el

2259
01:18:00,480 --> 01:18:01,440
intercambio

2260
01:18:01,440 --> 01:18:03,440
de ganar mientras aprende usted sabe que

2261
01:18:03,440 --> 01:18:04,880
ganar mientras aprende no significa

2262
01:18:04,880 --> 01:18:05,360
que está

2263
01:18:05,360 --> 01:18:08,320
aprendiendo de manera óptima o  ganar de manera óptima

2264
01:18:08,320 --> 01:18:08,880
o

2265
01:18:08,880 --> 01:18:12,000
cómo vamos a equilibrarlo

2266
01:18:12,000 --> 01:18:13,440
y parece que la inferencia de octava va

2267
01:18:13,440 --> 01:18:15,679
a ser un fuerte competidor

2268
01:18:15,679 --> 01:18:18,239
en los próximos años a medida que más y más

2269
01:18:18,239 --> 01:18:19,840
personas en la comunidad de aprendizaje automático

2270
01:18:19,840 --> 01:18:20,719
comiencen

2271
01:18:20,719 --> 01:18:22,560
a interesarse en estos resultados afinar el

2272
01:18:22,560 --> 01:18:23,760
régimen de atención

2273
01:18:23,760 --> 01:18:25,280
a lo que estos autores y otros están

2274
01:18:25,280 --> 01:18:27,280
haciendo y comienza a

2275
01:18:27,280 --> 01:18:30,480
entenderse más ampliamente que, en lugar

2276
01:18:30,480 --> 01:18:31,280
de simplemente

2277
01:18:31,280 --> 01:18:33,040
tener más  Re y más parámetros y

2278
01:18:33,040 --> 01:18:34,800
billones y billones de parámetros en

2279
01:18:34,800 --> 01:18:35,679
nuestro modelo

2280
01:18:35,679 --> 01:18:37,520
y entrenamiento en redes cada vez más grandes

2281
01:18:37,520 --> 01:18:39,440
de ya sabes computadoras

2282
01:18:39,440 --> 01:18:42,320
¿Qué pasaría si tuviéramos un agente curioso que

2283
01:18:42,320 --> 01:18:44,800
aprende a aprender y prefiere ganar?

2284
01:18:44,800 --> 01:18:47,159
Es como una reinterpretación de la planta baja.

2285
01:18:47,159 --> 01:18:48,320


2286
01:18:48,320 --> 01:18:51,360
de estos problemas y creo que escuchar

2287
01:18:51,360 --> 01:18:52,400
las opiniones del autor

2288
01:18:52,400 --> 01:18:55,840
sobre hacia dónde

2289
01:18:55,840 --> 01:18:56,880


2290
01:18:56,880 --> 01:18:58,800
se dirigen las comunidades y los campos de inferencia activa y aprendizaje automático seguramente será

2291
01:18:58,800 --> 01:19:00,080


2292
01:19:00,080 --> 01:19:02,640
informativo para nosotros ¿qué

2293
01:19:02,640 --> 01:19:05,120
piensas sobre ese azul?

2294
01:19:05,120 --> 01:19:07,199
Solo estoy pensando en problemas como

2295
01:19:07,199 --> 01:19:09,199
um como la montaña  El problema del auto

2296
01:19:09,199 --> 01:19:12,159
como lo que en realidad estamos aprendiendo es ganar

2297
01:19:12,159 --> 01:19:13,520
justo como cuando tienes que hacerlo

2298
01:19:13,520 --> 01:19:15,600
si tienes que explorar quieres subir cuanto más

2299
01:19:15,600 --> 01:19:17,520
alto quieras subir la colina

2300
01:19:17,520 --> 01:19:19,440
para que puedas volver al otro

2301
01:19:19,440 --> 01:19:20,960
lado de la colina y  la bandera

2302
01:19:20,960 --> 01:19:23,120
me gusta qué otros problemas hay por

2303
01:19:23,120 --> 01:19:24,320
ahí como ese

2304
01:19:24,320 --> 01:19:27,360
que no necesariamente tiene como

2305
01:19:27,360 --> 01:19:29,199
una recompensa que está desacoplada de

2306
01:19:29,199 --> 01:19:32,560
ex desacoplada de la exploración, así que estoy

2307
01:19:32,560 --> 01:19:34,159
pensando en eso y yo d  no

2308
01:19:34,159 --> 01:19:36,800
sé dónde está dónde está aprendiendo ganar

2309
01:19:36,800 --> 01:19:37,760
gran

2310
01:19:37,760 --> 01:19:39,120
pregunta es casi como en el

2311
01:19:39,120 --> 01:19:41,280
carro de montaña la altitud

2312
01:19:41,280 --> 01:19:43,840
es en algunos sentidos una recompensa heurística

2313
01:19:43,840 --> 01:19:45,600
quieres llegar a la cima de una colina por

2314
01:19:45,600 --> 01:19:46,960
lo que parece que la altitud sería el camino

2315
01:19:46,960 --> 01:19:48,880
a seguir  pero luego, la forma en que se configura el problema

2316
01:19:48,880 --> 01:19:50,239


2317
01:19:50,239 --> 01:19:52,960
también podría optimizar los límites y

2318
01:19:52,960 --> 01:19:53,679
decir que

2319
01:19:53,679 --> 01:19:56,800
busco expandir mis límites lateralmente

2320
01:19:56,800 --> 01:19:57,520
más,

2321
01:19:57,520 --> 01:19:59,280
oh sí, por supuesto que estamos cambiando en

2322
01:19:59,280 --> 01:20:01,280
altura, sabes que estamos en las montañas,

2323
01:20:01,280 --> 01:20:05,440
pero especialmente para casos  donde nos enfocamos

2324
01:20:05,440 --> 01:20:06,800
en la exploración

2325
01:20:06,800 --> 01:20:09,920
como la innovación o tal vez en otras

2326
01:20:09,920 --> 01:20:11,440
áreas, es genial pensar en cómo la

2327
01:20:11,440 --> 01:20:13,520
inferencia activa puede funcionar bien,

2328
01:20:13,520 --> 01:20:15,840
entonces, ¿cuáles son los próximos pasos para los

2329
01:20:15,840 --> 01:20:16,719
autores y

2330
01:20:16,719 --> 01:20:20,639
para nosotros? Un próximo paso importante

2331
01:20:20,639 --> 01:20:22,560
para examinar la inferencia activa en el

2332
01:20:22,560 --> 01:20:24,159
contexto de bandidos con múltiples brazos.  está

2333
01:20:24,159 --> 01:20:26,000
estableciendo límites teóricos

2334
01:20:26,000 --> 01:20:27,520
sobre el arrepentimiento acumulativo por el

2335
01:20:27,520 --> 01:20:29,280
problema del bandido estacionario

2336
01:20:29,280 --> 01:20:31,600
porque, como vimos, divergió de

2337
01:20:31,600 --> 01:20:32,800
una manera inesperada

2338
01:20:32,800 --> 01:20:35,280
que tenía sentido pero aún no era

2339
01:20:35,280 --> 01:20:36,320
el comportamiento que

2340
01:20:36,320 --> 01:20:39,040
era  inicialmente esperado y una parte clave de

2341
01:20:39,040 --> 01:20:40,560
estos estudios teóricos será

2342
01:20:40,560 --> 01:20:42,400
investigar si es

2343
01:20:42,400 --> 01:20:44,639
posible idear un esquema de descomposición de sonido para ese

2344
01:20:44,639 --> 01:20:46,000
parámetro lambda,

2345
01:20:46,000 --> 01:20:49,199
entonces, ¿qué tan rápido debemos cambiar

2346
01:20:49,199 --> 01:20:51,920
nuestra precisión sobre las preferencias que

2347
01:20:51,920 --> 01:20:53,040
probablemente funcione

2348
01:20:53,040 --> 01:20:54,719
para todas las instancias del bandido estacionario canónico?

2349
01:20:54,719 --> 01:20:56,639


2350
01:20:56,639 --> 01:20:58,159
que permiten esa es nuestra

2351
01:20:58,159 --> 01:21:00,159
pregunta favorita esto conduciría al

2352
01:21:00,159 --> 01:21:02,080
desarrollo de nuevos

2353
01:21:02,080 --> 01:21:03,520
algoritmos inspirados en la inferencia activa

2354
01:21:03,520 --> 01:21:06,719
que pueden lograr una eficiencia asintótica

2355
01:21:06,719 --> 01:21:08,320
estos límites teóricos también

2356
01:21:08,320 --> 01:21:10,400
nos permitirían comparar de manera más rigurosa

2357
01:21:10,400 --> 01:21:12,080
los algoritmos de inferencia activa con los algoritmos en

2358
01:21:12,080 --> 01:21:14,000
bandas ya establecidos

2359
01:21:14,000 --> 01:21:16,800
para los cuales se conocen además los límites de arrepentimiento

2360
01:21:16,800 --> 01:21:18,719
potencialmente podríamos

2361
01:21:18,719 --> 01:21:20,400
generalizar más allá de las configuraciones

2362
01:21:20,400 --> 01:21:23,440
que hemos probado empíricamente aquí, el trabajo futuro

2363
01:21:23,440 --> 01:21:23,920


2364
01:21:23,920 --> 01:21:26,000
también puede considerar un

2365
01:21:26,000 --> 01:21:28,800
análisis teórico de la información de inferencia activa

2366
01:21:28,800 --> 01:21:30,800
que podría ser más apropiado que el

2367
01:21:30,800 --> 01:21:33,280
análisis de arrepentimiento,

2368
01:21:33,280 --> 01:21:36,480
también una idea genial, como que el

2369
01:21:36,480 --> 01:21:40,480
análisis de arrepentimiento estaba orientado al rendimiento

2370
01:21:40,480 --> 01:21:43,520
, está diciendo  está calculando su

2371
01:21:43,520 --> 01:21:45,040
arrepentimiento en función de

2372
01:21:45,040 --> 01:21:48,560
la diferencia en el rendimiento entre lo

2373
01:21:48,560 --> 01:21:51,199
óptimo y lo que hizo, pero otra

2374
01:21:51,199 --> 01:21:52,159
forma de verlo

2375
01:21:52,159 --> 01:21:55,120
es usar la teoría de la información y mirar

2376
01:21:55,120 --> 01:21:56,000
como una función de la

2377
01:21:56,000 --> 01:21:58,320
información que se obtiene tal vez a través del

2378
01:21:58,320 --> 01:21:59,360
tiempo, lo

2379
01:21:59,360 --> 01:22:02,159
cual, tal como lo mencionaste, realmente

2380
01:22:02,159 --> 01:22:03,360
ayuda  enfoquémonos en la

2381
01:22:03,360 --> 01:22:06,320
exploración porque si todo el proyecto

2382
01:22:06,320 --> 01:22:08,639
se enmarca en términos de rendimiento,

2383
01:22:08,639 --> 01:22:10,400
recompensa y

2384
01:22:10,400 --> 01:22:12,960
valor, es casi como favorecer la explotación

2385
01:22:12,960 --> 01:22:14,080
desde el principio

2386
01:22:14,080 --> 01:22:16,080
porque la exploración siempre

2387
01:22:16,080 --> 01:22:17,760
tendrá que expresarse en términos de

2388
01:22:17,760 --> 01:22:18,719


2389
01:22:18,719 --> 01:22:21,280
explotación exitosa como esta investigación básica es

2390
01:22:21,280 --> 01:22:22,159
importante

2391
01:22:22,159 --> 01:22:24,320
porque luego  en adelante, podremos aplicarlo,

2392
01:22:24,320 --> 01:22:26,320
lo cual es justo,

2393
01:22:26,320 --> 01:22:27,920
pero cuando tenemos un

2394
01:22:27,920 --> 01:22:30,000
análisis teórico de la información, no solo un

2395
01:22:30,000 --> 01:22:32,480
análisis de rendimiento de arrepentimiento,

2396
01:22:32,480 --> 01:22:35,520
podría haber una manera de tener

2397
01:22:35,520 --> 01:22:37,920
exploración por el bien de la exploración y lo que eso

2398
01:22:37,920 --> 01:22:40,000
podría permitir

2399
01:22:40,000 --> 01:22:43,440
o incluso la explotación se puede incluir.

2400
01:22:43,440 --> 01:22:47,280
en términos de sorpresa, eh,

2401
01:22:47,280 --> 01:22:49,199
minimización de sorpresa, como si

2402
01:22:49,199 --> 01:22:51,040
fuéramos a enmarcar la inferencia activa en el

2403
01:22:51,040 --> 01:22:52,000
término  s de minimización

2404
01:22:52,000 --> 01:22:54,000
de la sorpresa, piense en algo como

2405
01:22:54,000 --> 01:22:55,760
el problema del mercado de valores, así

2406
01:22:55,760 --> 01:22:57,360
es como un problema de cambio de bandido

2407
01:22:57,360 --> 01:22:58,239
, como si

2408
01:22:58,239 --> 01:23:00,080
todo estuviera cambiando todo el tiempo, como si

2409
01:23:00,080 --> 01:23:01,360
fuera lo mismo por un tiempo,

2410
01:23:01,360 --> 01:23:03,520
como si fueras tu acción que

2411
01:23:03,520 --> 01:23:04,560
va a ganar

2412
01:23:04,560 --> 01:23:06,800
Entonces, como si supiera que se sorprende

2413
01:23:06,800 --> 01:23:08,239
cuando se desvía de, por

2414
01:23:08,239 --> 01:23:10,639
ejemplo, el s p 500, entonces desea realizar un seguimiento

2415
01:23:10,639 --> 01:23:12,960
con el s p 500 y la sorpresa ocurre

2416
01:23:12,960 --> 01:23:15,520
cuando se desvía de

2417
01:23:15,520 --> 01:23:17,199
ese pensamiento más allí sobre el

2418
01:23:17,199 --> 01:23:19,199
análisis teórico de la información

2419
01:23:19,199 --> 01:23:21,280
y cómo podría decir algo diferente.

2420
01:23:21,280 --> 01:23:22,719
que arrepentirnos

2421
01:23:22,719 --> 01:23:25,440
, volvamos a elegir un restaurante, por lo

2422
01:23:25,440 --> 01:23:27,360
que a menudo oímos hablar de una novedad controlada

2423
01:23:27,360 --> 01:23:28,159


2424
01:23:28,159 --> 01:23:30,159
que desea sorprender, pero no demasiada,

2425
01:23:30,159 --> 01:23:31,199


2426
01:23:31,199 --> 01:23:33,440
por lo que esto explica por qué a la

2427
01:23:33,440 --> 01:23:35,199
gente le puede gustar su

2428
01:23:35,199 --> 01:23:36,159


2429
01:23:36,159 --> 01:23:38,480
restaurante favorito, ni siquiera es necesario pensarlo en

2430
01:23:38,480 --> 01:23:39,280
el  contexto

2431
01:23:39,280 --> 01:23:43,040
de maximizar la recompensa como el 60

2432
01:23:43,040 --> 01:23:44,960
probablemente sea el restaurante más gratificante

2433
01:23:44,960 --> 01:23:46,960
, podría ser como si estuviera tratando de reducir mi

2434
01:23:46,960 --> 01:23:48,159
incertidumbre,

2435
01:23:48,159 --> 01:23:50,159
por lo que es probable que elija un lugar t  Con lo que estoy

2436
01:23:50,159 --> 01:23:51,199
familiarizado,

2437
01:23:51,199 --> 01:23:54,320
tal vez elegiré una

2438
01:23:54,320 --> 01:23:56,480
comida diferente o tal vez elegiré la comida que

2439
01:23:56,480 --> 01:23:57,520
siempre pido,

2440
01:23:57,520 --> 01:24:00,480
pero es como si la elección fuera impulsada por la

2441
01:24:00,480 --> 01:24:02,960
reducción de la incertidumbre,

2442
01:24:02,960 --> 01:24:06,080
ni siquiera por la maximización de la recompensa,

2443
01:24:06,080 --> 01:24:07,440
que es algo que nosotros  volvamos

2444
01:24:07,440 --> 01:24:10,000
todo el tiempo a la diferencia entre el

2445
01:24:10,000 --> 01:24:11,199


2446
01:24:11,199 --> 01:24:14,000
aprendizaje por refuerzo impulsado por el valor, el aprendizaje por recompensa

2447
01:24:14,000 --> 01:24:16,000
y el arrepentimiento implícito, que es el arrepentimiento

2448
01:24:16,000 --> 01:24:19,440
por la recompensa y la reducción de la

2449
01:24:19,440 --> 01:24:20,880
incertidumbre, lo

2450
01:24:20,880 --> 01:24:23,440
que nos coloca en un espacio completamente diferente.

2451
01:24:23,440 --> 01:24:25,280


2452
01:24:25,280 --> 01:24:27,440


2453
01:24:27,440 --> 01:24:29,120
donde obtenemos los

2454
01:24:29,120 --> 01:24:32,480
componentes rectos um pragmáticos y luego el

2455
01:24:32,480 --> 01:24:34,960
solenoide el flujo el contorno iso sí

2456
01:24:34,960 --> 01:24:36,960
, accedemos a toda esa área

2457
01:24:36,960 --> 01:24:39,360
en el mundo de la reducción de la incertidumbre de la teoría de la información,

2458
01:24:39,360 --> 01:24:40,560


2459
01:24:40,560 --> 01:24:43,600
pero también obtenemos cualitativamente una

2460
01:24:43,600 --> 01:24:44,880
historia diferente en una

2461
01:24:44,880 --> 01:24:46,560
explicación diferente para el comportamiento de

2462
01:24:46,560 --> 01:24:48,719
nuevo.  No necesito entender por qué

2463
01:24:48,719 --> 01:24:50,719
alguien está maximizando la recompensa

2464
01:24:50,719 --> 01:24:52,320
por qué fue a ese restaurante o

2465
01:24:52,320 --> 01:24:54,480
por qué pidió esa cosa

2466
01:24:54,480 --> 01:24:57,600
cuando pasó mucho tiempo.  Es solo que se presenta solo

2467
01:24:57,600 --> 01:24:58,000
como una

2468
01:24:58,000 --> 01:25:00,159
reducción de la incertidumbre y una comprensión previa de las

2469
01:25:00,159 --> 01:25:01,760
preferencias en

2470
01:25:01,760 --> 01:25:04,080
lugar de tener que

2471
01:25:04,080 --> 01:25:06,239
convertirlo en algún tipo de

2472
01:25:06,239 --> 01:25:09,120
maximización, uno, voltearé la última

2473
01:25:09,120 --> 01:25:10,800
diapositiva y luego tenemos una

2474
01:25:10,800 --> 01:25:15,040
pregunta increíble, así que, um, escribió alex v,

2475
01:25:15,040 --> 01:25:18,639
¿hay conexiones entre la

2476
01:25:18,639 --> 01:25:21,360
exploración?  sobre el valor epistémico y la

2477
01:25:21,360 --> 01:25:23,360
explotación por valor pragmático,

2478
01:25:23,360 --> 01:25:25,199
creo que está relacionado con lo que

2479
01:25:25,199 --> 01:25:26,800
estabas hablando,

2480
01:25:26,800 --> 01:25:29,520
um, que es que lo estamos poniendo en una

2481
01:25:29,520 --> 01:25:30,639


2482
01:25:30,639 --> 01:25:32,880
base común con inferencia activa en términos

2483
01:25:32,880 --> 01:25:34,800
de la reducción de la energía libre esperada

2484
01:25:34,800 --> 01:25:35,760


2485
01:25:35,760 --> 01:25:38,400
que tiene este epistémico o

2486
01:25:38,400 --> 01:25:39,600
componente de ganancia de conocimiento

2487
01:25:39,600 --> 01:25:41,920
y este componente pragmático o funcional

2488
01:25:41,920 --> 01:25:42,639
,

2489
01:25:42,639 --> 01:25:44,960
por lo que el epistémico es como aprender y

2490
01:25:44,960 --> 01:25:45,920
el pragmático

2491
01:25:45,920 --> 01:25:49,280
es ganar, así que estamos aprendiendo mientras

2492
01:25:49,280 --> 01:25:50,159
ganamos

2493
01:25:50,159 --> 01:25:53,360
o al revés, estamos

2494
01:25:53,360 --> 01:25:55,679
adquiriendo información epistémicamente valiosa

2495
01:25:55,679 --> 01:25:57,199


2496
01:25:57,199 --> 01:26:00,320
mientras también estamos  adquirir

2497
01:26:00,320 --> 01:26:03,280
información pragmáticamente valiosa porque la

2498
01:26:03,280 --> 01:26:04,880
toma de decisiones

2499
01:26:04,880 --> 01:26:08,400
de minimización de energía libre esperada está

2500
01:26:08,400 --> 01:26:11,120
condicionada por la política que estamos eligiendo

2501
01:26:11,120 --> 01:26:12,639
políticas

2502
01:26:12,639 --> 01:26:15,760
basadas en una función que

2503
01:26:15,760 --> 01:26:18,480
analiza ambas conjuntamente y

2504
01:26:18,480 --> 01:26:18,880
esa

2505
01:26:18,880 --> 01:26:21,199
es una de las formas en que estamos repensando la

2506
01:26:21,199 --> 01:26:23,840
exploración y la explotación

2507
01:26:23,840 --> 01:26:26,480
al pensar bien, esa no es realmente la

2508
01:26:26,480 --> 01:26:27,520
dualidad

2509
01:26:27,520 --> 01:26:29,920
de políticas de la que quiere hablar

2510
01:26:29,920 --> 01:26:31,520
porque explorar explotar lo hace sonar

2511
01:26:31,520 --> 01:26:33,040
como si fueran dos comportamientos que el ave

2512
01:26:33,040 --> 01:26:34,480
puede estar haciendo

2513
01:26:34,480 --> 01:26:36,320
y aquí lo que estamos haciendo es que

2514
01:26:36,320 --> 01:26:38,719
estamos tomando la idea

2515
01:26:38,719 --> 01:26:40,880
de que a veces quieres hacer un

2516
01:26:40,880 --> 01:26:41,920
acto más explotador

2517
01:26:41,920 --> 01:26:44,159
otras veces un acto más exploratorio y

2518
01:26:44,159 --> 01:26:45,600
luego estamos preguntando

2519
01:26:45,600 --> 01:26:48,320
dada la política de la cual

2520
01:26:48,320 --> 01:26:49,679
podría existir todo un espectro

2521
01:26:49,679 --> 01:26:53,199
de diferentes políticas, cómo contribuye cada política

2522
01:26:53,199 --> 01:26:56,719
a la ganancia epistémica y pragmática

2523
01:26:56,719 --> 01:27:00,480
y luego qué

2524
01:27:00,480 --> 01:27:02,639
política tendrá la mejor combinación de

2525
01:27:02,639 --> 01:27:03,760
las dos,

2526
01:27:03,760 --> 01:27:06,639
tal vez haya estrategias en las que esté

2527
01:27:06,639 --> 01:27:07,920
maximizando ambas y tal vez haya

2528
01:27:07,920 --> 01:27:09,280
estrategias  donde no estás maximizando

2529
01:27:09,280 --> 01:27:10,159
ninguno de los dos,

2530
01:27:10,159 --> 01:27:11,760
pero si solo estás mirando uno u

2531
01:27:11,760 --> 01:27:14,000
otro, entonces podrías

2532
01:27:14,000 --> 01:27:15,360
elegir uno que sea como una mala

2533
01:27:15,360 --> 01:27:17,040
combinación,

2534
01:27:17,040 --> 01:27:19,120
bueno, así que es un ejemplo perfecto.  Como usted

2535
01:27:19,120 --> 01:27:20,239
sabe,

2536
01:27:20,239 --> 01:27:23,199
su política se basa en su

2537
01:27:23,199 --> 01:27:24,480
posibilidad anterior de

2538
01:27:24,480 --> 01:27:26,880
recompensa de minimizar la sorpresa, por lo que tengo

2539
01:27:26,880 --> 01:27:29,679
una política de que no voy a

2540
01:27:29,679 --> 01:27:31,840
comer una comida que nunca antes había probado en un

2541
01:27:31,840 --> 01:27:33,360
restaurante en el que nunca había estado antes.

2542
01:27:33,360 --> 01:27:33,920
porque

2543
01:27:33,920 --> 01:27:35,199
me gusta, no sé en lo que me estoy metiendo,

2544
01:27:35,199 --> 01:27:37,040
eso es muy por ahí, así que mi

2545
01:27:37,040 --> 01:27:39,040
política sería pedir una comida nueva en un

2546
01:27:39,040 --> 01:27:40,560
restaurante que me guste

2547
01:27:40,560 --> 01:27:43,760
o pedir una comida a la que estoy acostumbrado

2548
01:27:43,760 --> 01:27:45,840
en un restaurante nuevo  así que sería

2549
01:27:45,840 --> 01:27:46,960
como la política

2550
01:27:46,960 --> 01:27:50,239
en que solo para continuar con ese ejemplo

2551
01:27:50,239 --> 01:27:54,080
genial, bueno, qué discusión tan divertida,

2552
01:27:54,080 --> 01:27:56,800
espero que esto haya sido útil para aquellos que están

2553
01:27:56,800 --> 01:27:57,600
familiarizados

2554
01:27:57,600 --> 01:28:01,040
con la inferencia activa, así como con el

2555
01:28:01,040 --> 01:28:03,679
aprendizaje automático de estadísticas bayesianas o

2556
01:28:03,679 --> 01:28:04,719


2557
01:28:04,719 --> 01:28:07,760
no, todo está tranquilo porque sus preguntas

2558
01:28:07,760 --> 01:28:08,159
serán

2559
01:28:08,159 --> 01:28:10,320
Realmente ayuda a hacer avanzar todo el proyecto

2560
01:28:10,320 --> 01:28:12,560
, las partes que tienen y no tienen

2561
01:28:12,560 --> 01:28:13,199
sentido

2562
01:28:13,199 --> 01:28:15,040
y las partes que desea explorar

2563
01:28:15,040 --> 01:28:16,960
más.

2564
01:28:16,960 --> 01:28:19,199


2565
01:28:19,199 --> 01:28:21,600


2566
01:28:21,600 --> 01:28:24,480


2567
01:28:24,480 --> 01:28:25,679


2568
01:28:25,679 --> 01:28:27,920
ya sea que estés muy familiarizado o no

2569
01:28:27,920 --> 01:28:30,159
, eres totalmente bienvenido a participar

2570
01:28:30,159 --> 01:28:32,560
en nuestras discusiones en vivo o simplemente para hacer

2571
01:28:32,560 --> 01:28:33,840
preguntas o

2572
01:28:33,840 --> 01:28:37,199
participar de alguna otra manera,

2573
01:28:37,199 --> 01:28:39,440
gracias azul por la increíble ayuda con la

2574
01:28:39,440 --> 01:28:41,280
preparación de las diapositivas y por esta

2575
01:28:41,280 --> 01:28:44,080
conversación y nos vemos a todos

2576
01:28:44,080 --> 01:28:45,760
otra vez

2577
01:28:45,760 --> 01:28:52,639
adios

