1
00:00:08,480 --> 00:00:09,040
안녕하세요

2
00:00:09,040 --> 00:00:12,000
여러분 actin flab 라이브 스트림 번호 24.0에 오신 것을 환영합니다.

3
00:00:12,000 --> 00:00:14,400


4
00:00:14,400 --> 00:00:18,000
오늘은 2021년 6월 16일

5
00:00:18,000 --> 00:00:19,920
이며 우리는 다중 무장 도적의 능동 추론에 대한 실증적 평가에서 이 문서에 대해 이야기할 것입니다.

6
00:00:19,920 --> 00:00:22,560


7
00:00:22,560 --> 00:00:25,039


8
00:00:25,039 --> 00:00:26,000


9
00:00:26,000 --> 00:00:30,320
저는 다니엘이고 여기 블루 하이

10
00:00:30,320 --> 00:00:32,880
굉장합니다.  능동 추론 연구실에 오신 것을 환영합니다. 학습과 적용 능동 추론

11
00:00:32,880 --> 00:00:34,239


12
00:00:34,239 --> 00:00:37,120
을 연습하는 참여형 온라인 연구실에 오신 것을 환영합니다.

13
00:00:37,120 --> 00:00:38,239


14
00:00:38,239 --> 00:00:40,320


15
00:00:40,320 --> 00:00:41,920


16
00:00:41,920 --> 00:00:44,800
이 페이지의 링크에서 찾을 수 있습니다. 이것은

17
00:00:44,800 --> 00:00:45,760


18
00:00:45,760 --> 00:00:48,000
보관된 실시간 스트림에 기록

19
00:00:48,000 --> 00:00:50,000
되므로 피드백을 제공해 주십시오.  작업을 개선할 수 있습니다.

20
00:00:50,000 --> 00:00:52,239
모든 배경과

21
00:00:52,239 --> 00:00:54,000
관점을 환영

22
00:00:54,000 --> 00:00:55,280
합니다. 여기 짧은 링크에서

23
00:00:55,280 --> 00:00:57,760
라이브 스트림에 대한 좋은 비디오 에티켓을

24
00:00:57,760 --> 00:01:00,640
따를 것입니다. actin flab

25
00:01:00,640 --> 00:01:02,000


26
00:01:02,000 --> 00:01:04,400
의 커뮤니케이션 부서에서 수행하는 모든 라이브 스트림과 다양한 시리즈를 찾을 수 있습니다.

27
00:01:04,400 --> 00:01:06,880


28
00:01:06,880 --> 00:01:08,720
그리고 오늘 우리는

29
00:01:08,720 --> 00:01:11,200


30
00:01:11,200 --> 00:01:13,520


31
00:01:13,520 --> 00:01:14,400


32
00:01:14,400 --> 00:01:17,600
2021년 6월 22

33
00:01:17,600 --> 00:01:19,920
일과 29일에 있을 두 차례의 예정된 토론을 위해 도트 제로 비디오에서 상황을 설명할 것입니다.

34
00:01:19,920 --> 00:01:21,040


35
00:01:21,040 --> 00:01:24,479
이 백서의 24.1 및 24.2에서, 그리고

36
00:01:24,479 --> 00:01:27,280


37
00:01:27,280 --> 00:01:31,520
오늘 액틴 라이브 스트림 번호 24.0에 참여하는 저자와 함께

38
00:01:31,520 --> 00:01:33,680
우리는 몇 가지 컨텍스트를 설정

39
00:01:33,680 --> 00:01:35,840


40
00:01:35,840 --> 00:01:38,400
하고 다음 백서

41
00:01:38,400 --> 00:01:40,479
에 다중 무장 도적의 능동 추론에 대한 경험적 평가를 소개하려고 합니다.

42
00:01:40,479 --> 00:01:41,600


43
00:01:41,600 --> 00:01:45,040
여기에 나열된 저자

44
00:01:45,040 --> 00:01:47,200
와 비디오는 일부 아이디어에 대한 소개일 뿐입니다

45
00:01:47,200 --> 00:01:48,799


46
00:01:48,799 --> 00:01:51,360
. 리뷰나 최종 단어가 아닙니다.

47
00:01:51,360 --> 00:01:53,200
일종의 3자 교차로와 같은

48
00:01:53,200 --> 00:01:55,280


49
00:01:55,280 --> 00:01:56,960
활동적인 추론

50
00:01:56,960 --> 00:01:58,320
커뮤니티 내에 있고 노출을 원하는 사람들이 있습니다.

51
00:01:58,320 --> 00:02:00,079


52
00:02:00,079 --> 00:02:02,479
베이지안 통계 또는 머신 러닝과 같은 다른 영역

53
00:02:02,479 --> 00:02:04,799
두 번째 길은

54
00:02:04,799 --> 00:02:06,640
베이지안 통계 또는 머신

55
00:02:06,640 --> 00:02:07,600
러닝 접근 방식에서

56
00:02:07,600 --> 00:02:09,840
와서 능동 추론에 대해 호기심이 많은 사람들입니다.

57
00:02:09,840 --> 00:02:11,440
그러면 물론 능동에 익숙하지 않더라도 이것이 흥미롭고 흥미로울 수 있기를 바랍니다.

58
00:02:11,440 --> 00:02:12,720


59
00:02:12,720 --> 00:02:14,560


60
00:02:14,560 --> 00:02:16,239
추론 또는 기계 학습

61
00:02:16,239 --> 00:02:17,920


62
00:02:17,920 --> 00:02:19,360


63
00:02:19,360 --> 00:02:21,840
을 보다 광범위하게 행동 및 의사 결정에 관한 보다 광범위한 질문에 연결하려고

64
00:02:21,840 --> 00:02:22,959


65
00:02:22,959 --> 00:02:24,480
노력할 것입니다.  몇 가지 큰 질문을 다루는 로드맵

66
00:02:24,480 --> 00:02:26,720
에 있는 논문 초록의 목적과 주장을 살펴보고 논문의

67
00:02:26,720 --> 00:02:28,080


68
00:02:28,080 --> 00:02:29,920


69
00:02:29,920 --> 00:02:31,519
모든

70
00:02:31,519 --> 00:02:32,239
그림

71
00:02:32,239 --> 00:02:34,080
과 주요 형식

72
00:02:34,080 --> 00:02:36,879
을 살펴보겠습니다.  논문

73
00:02:36,879 --> 00:02:37,519
이든

74
00:02:37,519 --> 00:02:39,920
아니든 질문을 하고 더 많은 것을 배울 수 있는 좋은 위치에 있기를 바랍니다.

75
00:02:39,920 --> 00:02:41,760


76
00:02:41,760 --> 00:02:44,400
물론

77
00:02:44,400 --> 00:02:46,000
앞으로 몇 주 동안 1점과 2점에서 우리는

78
00:02:46,000 --> 00:02:47,200
이 동일한 논문에 대해 논의할

79
00:02:47,200 --> 00:02:49,360
것이므로 질문을 저장하고 제출

80
00:02:49,360 --> 00:02:50,720
하고 저희에게 보내주십시오.

81
00:02:50,720 --> 00:02:54,800
어떤 식으로든 참여하거나 기여하고 싶다면

82
00:02:55,120 --> 00:02:58,480


83
00:02:58,480 --> 00:03:01,680
이 슬라이드의 표지 스크린샷이 있는 종이 자체에 있습니다

84
00:03:01,680 --> 00:03:05,360
. 목적과 주장을 읽은

85
00:03:05,360 --> 00:03:06,400
다음 파란색

86
00:03:06,400 --> 00:03:08,000
으로 무엇을 먼저 생각해볼 수 있습니다.  당신

87
00:03:08,000 --> 00:03:09,840
은

88
00:03:09,840 --> 00:03:13,120
그들이 이 백서에서 목표로 하거나 주장한 것에 대해 일종의 멋진 조각이라고 생각했습니다.

89
00:03:13,120 --> 00:03:13,840


90
00:03:13,840 --> 00:03:15,920
우리

91
00:03:15,920 --> 00:03:17,760
는 능동적

92
00:03:17,760 --> 00:03:19,440
추론과 베이지안 정보 이론

93
00:03:19,440 --> 00:03:21,599
프레임워크와 두 가지 최첨단

94
00:03:21,599 --> 00:03:23,440
기계 학습 알고리즘 사이의 경험적 비교를 제공했습니다.

95
00:03:23,440 --> 00:03:26,720
베이지안 상위 신뢰 경계 ucb a

96
00:03:26,720 --> 00:03:28,799


97
00:03:28,799 --> 00:03:30,799
고정 및 비정상

98
00:03:30,799 --> 00:03:33,840
확률적 다중 무장 밴디트에서 낙관적 톰슨 샘플링

99
00:03:33,840 --> 00:03:35,519


100
00:03:35,519 --> 00:03:36,720


101
00:03:36,720 --> 00:03:38,799
우리는 고정

102
00:03:38,799 --> 00:03:40,080
적기 문제

103
00:03:40,080 --> 00:03:41,760
에 대한 검사에서 성능이 정확한 버전의 성능을 밀접하게 따른다는 것을 보여주는 근사 능동 추론 알고리즘을 도입

104
00:03:41,760 --> 00:03:43,280


105
00:03:43,280 --> 00:03:46,720
했으며 따라서

106
00:03:46,720 --> 00:03:48,319
능동 추론 알고리즘을 도출했습니다.  그것은

107
00:03:48,319 --> 00:03:50,319
효율적이고

108
00:03:50,319 --> 00:03:53,200
고차원 문제로 쉽게 확장할 수 있습니다. 그래서

109
00:03:53,200 --> 00:03:55,439
그것에 대해 멋진 점이나

110
00:03:55,439 --> 00:03:55,920


111
00:03:55,920 --> 00:03:59,680
이 도트 0을 0으로 만들게 된

112
00:03:59,680 --> 00:04:00,239


113
00:04:00,239 --> 00:04:03,680
이유

114
00:04:03,680 --> 00:04:04,319


115
00:04:04,319 --> 00:04:06,560


116
00:04:06,560 --> 00:04:07,760


117
00:04:07,760 --> 00:04:10,640
정말 꽤 어렵기

118
00:04:10,640 --> 00:04:12,159
때문에 저자는

119
00:04:12,159 --> 00:04:13,280


120
00:04:13,280 --> 00:04:15,519
이 능동 추론 알고리즘

121
00:04:15,519 --> 00:04:17,199
을 유도하고 유용하다는 것을 증명하는 데 큰 역할을 했다고

122
00:04:17,199 --> 00:04:21,120
생각합니다. 그리고 그들은 일렬

123
00:04:21,120 --> 00:04:24,160
로 방정식과 같이 분석적으로 가져오거나 적어도 기계 학습의 다른 접근 방식과 병치되는 것과 같이 분석적으로 가져오는 멋진 일을 했습니다.

124
00:04:24,160 --> 00:04:25,919


125
00:04:25,919 --> 00:04:28,320


126
00:04:28,320 --> 00:04:29,919


127
00:04:29,919 --> 00:04:32,240
질적 이론에 호소하기 보다는

128
00:04:32,240 --> 00:04:33,440


129
00:04:33,440 --> 00:04:35,520
이것은 또한 훌륭합니다. 이것은

130
00:04:35,520 --> 00:04:36,880


131
00:04:36,880 --> 00:04:40,000
주장이 구체적이고 정확

132
00:04:40,000 --> 00:04:40,720
하며 우리가

133
00:04:40,720 --> 00:04:43,840
후속 조치를 취할

134
00:04:44,479 --> 00:04:46,400
것이므로 전반부를 읽고 후반부

135
00:04:46,400 --> 00:04:48,960


136
00:04:48,960 --> 00:04:51,280
를 순차 결정의 핵심 기능으로 갈 수 있습니다.

137
00:04:51,280 --> 00:04:53,120
불확실성

138
00:04:53,120 --> 00:04:56,400
하에서 만드는 것은 현재 지식

139
00:04:56,400 --> 00:04:58,000
에 따라 최선의 행동을 선택하는 것을 이용하는 것과 다른 행동의

140
00:04:58,000 --> 00:05:00,080


141
00:05:00,080 --> 00:05:02,320
가치에 대한 정보를 얻는 것 사이에서 균형을 잡을 필요가 있습니다

142
00:05:02,320 --> 00:05:03,680


143
00:05:03,680 --> 00:05:05,759
. multi-armed bandit problem

144
00:05:05,759 --> 00:05:07,600
이 절충점을 포착하는 고전적인 작업

145
00:05:07,600 --> 00:05:08,560


146
00:05:08,560 --> 00:05:10,560
은 기계 학습의 수단으로 사용되었습니다

147
00:05:10,560 --> 00:05:12,800


148
00:05:12,800 --> 00:05:14,560
수많은

149
00:05:14,560 --> 00:05:17,440
산업 응용 분야에서 유용한 것으로 입증된 적기 알고리즘 개발을 위해 최근 신경 과학에서 개발

150
00:05:17,440 --> 00:05:18,800


151
00:05:18,800 --> 00:05:20,320
된 순차적 의사 결정에 대한 접근 방식의 능동 추론 프레임워크

152
00:05:20,320 --> 00:05:22,320


153
00:05:22,320 --> 00:05:24,000


154
00:05:24,000 --> 00:05:26,080


155
00:05:26,080 --> 00:05:27,840


156
00:05:27,840 --> 00:05:28,720


157
00:05:28,720 --> 00:05:30,479
는 탐색 착취 트레이드오프를 해결하기 위한 정교한 전략으로 구별됩니다.

158
00:05:30,479 --> 00:05:32,479


159
00:05:32,479 --> 00:05:34,400


160
00:05:34,400 --> 00:05:36,720
이미 establis에 대한 흥미로운 대안을 추론  hed

161
00:05:36,720 --> 00:05:39,360
bandit algorithm 그래서 그것은 일종의

162
00:05:39,360 --> 00:05:39,919
멋진

163
00:05:39,919 --> 00:05:42,160
처음 몇 단어입니다.

164
00:05:42,160 --> 00:05:43,039


165
00:05:43,039 --> 00:05:46,160
불확실한 상황에서의 순차적 의사결정에 관한 것이고, bandit 작업

166
00:05:46,160 --> 00:05:46,560


167
00:05:46,560 --> 00:05:49,199
은 머신 러닝

168
00:05:49,199 --> 00:05:50,000
이

169
00:05:50,000 --> 00:05:52,160


170
00:05:52,160 --> 00:05:54,000


171
00:05:54,000 --> 00:05:56,960
이 multi-arm bandit 문제에 접근하기 위한 알고리즘을 추구함으로써 이미 많은 가치를 얻었음을 탐구하기 위해 만들어졌습니다.

172
00:05:56,960 --> 00:05:57,440


173
00:05:57,440 --> 00:06:00,240


174
00:06:00,240 --> 00:06:01,199
어 처음

175
00:06:01,199 --> 00:06:03,600
에는 인간과 동물의 행동 사례를 다루기 위해 개발된 능동 추론

176
00:06:03,600 --> 00:06:05,680
이지만 우리가 보고 있는 것처럼 그것은 또한 그

177
00:06:05,680 --> 00:06:06,080
이상을 넘어서서

178
00:06:06,080 --> 00:06:08,960


179
00:06:08,960 --> 00:06:10,319


180
00:06:10,319 --> 00:06:12,080
다중 팔 도적 문제의 맥락에서 능동 추론을 연구하도록 동기를 부여

181
00:06:12,080 --> 00:06:13,840
하므로 여기에서 두 번째 부분으로 이동합니다.

182
00:06:13,840 --> 00:06:17,440
우리는 효율적이고

183
00:06:17,440 --> 00:06:19,520
확장 가능한 근사 능동 추론

184
00:06:19,520 --> 00:06:20,080
알고리즘을 도출하고

185
00:06:20,080 --> 00:06:22,080
이를 두 가지 최신 밴드 알고리즘과 비교합니다.

186
00:06:22,080 --> 00:06:23,600


187
00:06:23,600 --> 00:06:25,600
베이지안 상한 및

188
00:06:25,600 --> 00:06:27,680
낙관적 톰슨 샘플링

189
00:06:27,680 --> 00:06:29,759
이 비교는 두 가지 유형의

190
00:06:29,759 --> 00:06:30,880
적기 문제에

191
00:06:30,880 --> 00:06:32,880
대해 수행됩니다. 고정 및 동적 스위칭

192
00:06:32,880 --> 00:06:35,440
적기  경험적 평가

193
00:06:35,440 --> 00:06:36,800
에 따르면 능동 추론

194
00:06:36,800 --> 00:06:38,639
알고리즘은 효율적인

195
00:06:38,639 --> 00:06:39,759
장기

196
00:06:39,759 --> 00:06:42,160
고정 적기에서의 m 동작 그러나

197
00:06:42,160 --> 00:06:43,759
더 까다로운 스위칭 적기

198
00:06:43,759 --> 00:06:44,400
알고리즘

199
00:06:44,400 --> 00:06:46,160
또는 스위칭 적기 능동 추론

200
00:06:46,160 --> 00:06:47,759
은

201
00:06:47,759 --> 00:06:49,599
두 가지 최첨단 대역

202
00:06:49,599 --> 00:06:50,880


203
00:06:50,880 --> 00:06:52,880
알고리즘보다 훨씬 더 나은 성능

204
00:06:52,880 --> 00:06:54,720


205
00:06:54,720 --> 00:06:55,919


206
00:06:55,919 --> 00:06:58,240
을 발휘합니다.  인간과 동물의 행동을 연구하기

207
00:06:58,240 --> 00:06:59,919
위한 일반적인 프레임워크로서 능동 추론에 추가적인 신뢰성을 부여합니다.

208
00:06:59,919 --> 00:07:01,199


209
00:07:01,199 --> 00:07:03,759
그래서 이것은

210
00:07:03,759 --> 00:07:05,120


211
00:07:05,120 --> 00:07:07,840


212
00:07:07,840 --> 00:07:09,360


213
00:07:09,360 --> 00:07:11,599
인간이 이

214
00:07:11,599 --> 00:07:13,520
탐색 착취

215
00:07:13,520 --> 00:07:16,960
패러다임의 균형을 맞추고 이를

216
00:07:16,960 --> 00:07:17,840
프레임워크에 프로그래밍하는 대략적인 방법으로 능동 추론처럼 취하기

217
00:07:17,840 --> 00:07:19,759
때문에 정말 좋습니다.  그것은 단지 당신이 그것이 기계에서 인간의 사고에 더 가까워지고 있다는 것을 알고 있다는 것을 보여줍니다. 그것은

218
00:07:19,759 --> 00:07:21,840
점점 더

219
00:07:21,840 --> 00:07:22,560


220
00:07:22,560 --> 00:07:25,919


221
00:07:25,919 --> 00:07:28,479
그렇습니다. 그리고

222
00:07:28,479 --> 00:07:29,759
우리가

223
00:07:29,759 --> 00:07:31,759
이 토론에서 여러 번으로 돌아가게 될 일종의 쌍이 있습니다.

224
00:07:31,759 --> 00:07:33,840
첫 번째는  두 가지 유형의 문제

225
00:07:33,840 --> 00:07:36,240
는 고정식 적기와 동적 적기

226
00:07:36,240 --> 00:07:36,960


227
00:07:36,960 --> 00:07:38,400
중 하나가 정적 적기입니다.  그 중 하나가

228
00:07:38,400 --> 00:07:39,919
변경되고 있어 이에 대해 더 자세히 이야기할 예정

229
00:07:39,919 --> 00:07:40,560


230
00:07:40,560 --> 00:07:42,639
이며 자주 등장하는 다른 쌍

231
00:07:42,639 --> 00:07:45,039
은 베이지안 신뢰

232
00:07:45,039 --> 00:07:47,680
상한과 낙관적 톰슨 샘플링

233
00:07:47,680 --> 00:07:49,440


234
00:07:49,440 --> 00:07:51,520
입니다.  한 쌍의 쌍

235
00:07:51,520 --> 00:07:54,319
접근 방식을 사용하면 결과가

236
00:07:54,319 --> 00:07:55,680
정말 매혹적

237
00:07:55,680 --> 00:07:56,720


238
00:07:56,720 --> 00:07:59,599
입니다. 실제로 더 간단한

239
00:07:59,599 --> 00:08:01,440
경우에는 능동 추론 알고리즘

240
00:08:01,440 --> 00:08:04,160
이 완벽하게 수행되지 않지만 이 더

241
00:08:04,160 --> 00:08:05,360
어려운 동적

242
00:08:05,360 --> 00:08:07,039
경우에는 상태보다 더 잘 수행된다는 사실을 압축 해제할 것입니다.

243
00:08:07,039 --> 00:08:08,560
예술의 상태를 넘어서는 것을 무엇이라고 부를까요?

244
00:08:08,560 --> 00:08:11,520


245
00:08:11,520 --> 00:08:14,720
종이에 대한 로드맵이 있습니다.

246
00:08:14,720 --> 00:08:15,360
물론 이

247
00:08:15,360 --> 00:08:18,160
비디오와 마찬가지로 종이

248
00:08:18,160 --> 00:08:18,800


249
00:08:18,800 --> 00:08:20,400
에 구체적으로 언급된 방법이 궁금

250
00:08:20,400 --> 00:08:22,319
하거나 다이빙을 원할 경우

251
00:08:22,319 --> 00:08:24,400
더 많은 정보를 원하면

252
00:08:24,400 --> 00:08:26,400
그들이 어떻게 인용했는지 또는 주장을 어떻게 구성했는지 보고 싶으실

253
00:08:26,400 --> 00:08:27,919
것입니다. 이 문서 자체로 이동해야 합니다.

254
00:08:27,919 --> 00:08:30,400
이것은 로드맵일 뿐입니다. 그들은

255
00:08:30,400 --> 00:08:31,919


256
00:08:31,919 --> 00:08:34,719
다중 무장 도적의 소개로 시작하여

257
00:08:34,719 --> 00:08:36,559
두 가지 종류를 다룹니다.  밴드

258
00:08:36,559 --> 00:08:38,240
고정 버전과 전환

259
00:08:38,240 --> 00:08:40,320
버전을 탐색하고 다른 버전에서 성능을 평가하는 방법에 대해 이야기

260
00:08:40,320 --> 00:08:40,958


261
00:08:40,958 --> 00:08:43,839
한 다음 사용할

262
00:08:43,839 --> 00:08:45,600
알고리즘을 소개하고

263
00:08:45,600 --> 00:08:46,320


264
00:08:46,320 --> 00:08:49,600
이 변형

265
00:08:49,600 --> 00:08:51,600
미소 접근 방식에 대해 이야기합니다. 여기서 약간만 다룰 것

266
00:08:51,600 --> 00:08:53,120
입니다.  그러나

267
00:08:53,120 --> 00:08:54,640


268
00:08:54,640 --> 00:08:57,200
그것이 하는 일에 대해 저자의 이야기를 듣게 되기를 기대합니다.

269
00:08:57,200 --> 00:09:00,320
그러면 고정 및 스위칭 도적을 탐구하는 한 쌍의 문제에 대한 결과가 있습니다. 그런

270
00:09:00,320 --> 00:09:02,000


271
00:09:02,000 --> 00:09:03,440


272
00:09:03,440 --> 00:09:05,279
다음 우리는

273
00:09:05,279 --> 00:09:08,000
일부 결과를 보여주고

274
00:09:08,000 --> 00:09:08,720


275
00:09:08,720 --> 00:09:11,839
바라건대 알고리즘이나 형식이

276
00:09:11,839 --> 00:09:13,680


277
00:09:13,680 --> 00:09:15,040
숫자를 따라가기가 조금 어려웠습니다. 정말 명확

278
00:09:15,040 --> 00:09:17,279
했으며 활성 추론 및 기계 학습 커뮤니티에 대한 몇 가지 멋진 일반 사항

279
00:09:17,279 --> 00:09:19,360
에 대한 토론을 통해 알고리즘이 시간이 지남에 따라 어떻게 수행되는지 보여줍니다.

280
00:09:19,360 --> 00:09:21,440


281
00:09:21,440 --> 00:09:22,959


282
00:09:22,959 --> 00:09:25,360


283
00:09:25,360 --> 00:09:26,880
여기에 제공된 키워드가

284
00:09:26,880 --> 00:09:29,120
있습니다.  평소와 같이

285
00:09:29,120 --> 00:09:29,440


286
00:09:29,440 --> 00:09:31,920
이러한 키워드를 점프로 사용할 뿐만

287
00:09:31,920 --> 00:09:32,560
아니라

288
00:09:32,560 --> 00:09:35,279


289
00:09:35,279 --> 00:09:37,519
순차적 의사 결정(

290
00:09:37,519 --> 00:09:40,720
일명 삶)에 익숙하지만 베이지안 통계에 익숙하지 않은 사람

291
00:09:40,720 --> 00:09:42,720
과 우리

292
00:09:42,720 --> 00:09:44,800
는 순차적 의사 결정에서

293
00:09:44,800 --> 00:09:45,360
시작한 다음

294
00:09:45,360 --> 00:09:47,360


295
00:09:47,360 --> 00:09:48,640
베이지안 추론

296
00:09:48,640 --> 00:09:51,120
multi-armed bandits에 대해 더 광범위하게 이야기할 것이므로 다음과 같이 하는 것이

297
00:09:51,120 --> 00:09:52,800
좋습니다.  도적 문제에 대해 들어본 적이

298
00:09:52,800 --> 00:09:53,680


299
00:09:53,680 --> 00:09:55,200
없다면 우리는 그들이 상한선과 톰슨 샘플링을 탐구할 두 가지

300
00:09:55,200 --> 00:09:56,800
다른 알고리즘에

301
00:09:56,800 --> 00:09:57,760


302
00:09:57,760 --> 00:09:59,440


303
00:09:59,440 --> 00:10:01,440


304
00:10:01,440 --> 00:10:02,959
대해

305
00:10:02,959 --> 00:10:04,240
이야기할 것이고 그들이 실제로 실제

306
00:10:04,240 --> 00:10:05,200


307
00:10:05,200 --> 00:10:07,600
우리가 이전에 본 많은 접근 방식과 상대적인 방식

308
00:10:07,600 --> 00:10:10,160


309
00:10:10,160 --> 00:10:12,320


310
00:10:12,320 --> 00:10:13,200


311
00:10:13,200 --> 00:10:16,399
이 다르므로 순차 의사 결정으로 이동합니다. 파란색으로 이동합니다. 이에 대해 무엇이라고 말

312
00:10:16,399 --> 00:10:18,240
하겠습니까? 따라서 순차 의사 결정은 시간 t에 따라 달라

313
00:10:18,240 --> 00:10:18,560
집니다.

314
00:10:18,560 --> 00:10:21,360
따라서 한 시간 단계는 수행하는 시스템의 상태를 갖게 됩니다.

315
00:10:21,360 --> 00:10:22,640


316
00:10:22,640 --> 00:10:25,360


317
00:10:25,360 --> 00:10:26,160


318
00:10:26,160 --> 00:10:28,000
두 번째 단계

319
00:10:28,000 --> 00:10:29,839
에서 시스템이 이제 새로운 상태에 있게 된

320
00:10:29,839 --> 00:10:31,440
다음 무엇에 대해 다른 결정을 내릴 수 있도록 시스템을 올바르게 변경합니다.

321
00:10:31,440 --> 00:10:32,560
당신

322
00:10:32,560 --> 00:10:34,480
은 시스템으로 할 것이므로 이것은 마치

323
00:10:34,480 --> 00:10:35,680


324
00:10:35,680 --> 00:10:37,440
체스 게임을 하는 주식 포트폴리오를 관리하는 차량을 운전하는

325
00:10:37,440 --> 00:10:39,519


326
00:10:39,519 --> 00:10:40,480


327
00:10:40,480 --> 00:10:43,040
것과 같

328
00:10:43,040 --> 00:10:44,320
으며 순차적이지 않은

329
00:10:44,320 --> 00:10:46,320
문제를 일종의 병렬 문제로 만들어 이미지 분류와 같은 것이 되지 않도록 하는 것과 같습니다.

330
00:10:46,320 --> 00:10:48,079
순차적으로

331
00:10:48,079 --> 00:10:49,680
모든 이미지를

332
00:10:49,680 --> 00:10:51,040
병렬로 또는 한 번

333
00:10:51,040 --> 00:10:52,480
에 분류할 수 있는 시스템 상태

334
00:10:52,480 --> 00:10:54,480
는 이전 이미지를 어떻게 분류했는지에 따라 달라지지

335
00:10:54,480 --> 00:10:56,320


336
00:10:56,320 --> 00:10:58,560


337
00:10:58,560 --> 00:11:00,959
않습니다.

338
00:11:00,959 --> 00:11:03,839


339
00:11:03,839 --> 00:11:04,480


340
00:11:04,480 --> 00:11:07,040


341
00:11:07,040 --> 00:11:08,720
특히 결정

342
00:11:08,720 --> 00:11:11,200
이 미래에 영향을 미칠 때 일반적으로 순차적인 의사 결정을 내리는 것을 다시 생각합니다. 이러한

343
00:11:11,200 --> 00:11:12,640
문제

344
00:11:12,640 --> 00:11:14,560
는 우리가 이야기할 모든 종류의 문제이지만

345
00:11:14,560 --> 00:11:17,040


346
00:11:17,040 --> 00:11:19,120
일부 비순차적 문제가 순차적으로 구성될 수 있다는 것보다 더 광범위하게 만들기

347
00:11:19,120 --> 00:11:20,480


348
00:11:20,480 --> 00:11:21,760
위해

349
00:11:21,760 --> 00:11:24,000
하나의

350
00:11:24,000 --> 00:11:26,720
블롭 하나의 빅 데이터 세트인 분류 문제가

351
00:11:26,720 --> 00:11:28,079


352
00:11:28,079 --> 00:11:30,240
있어서 알고리즘을 원하는 시간적 시퀀스가 없다고 가정해 보겠습니다.  m

353
00:11:30,240 --> 00:11:32,240


354
00:11:32,240 --> 00:11:33,760
은 그것을 순차적인 것처럼 취급하여 예제에서 읽기 시작

355
00:11:33,760 --> 00:11:35,440
하고 10시 이후에

356
00:11:35,440 --> 00:11:38,720
알았습니다. 그러면

357
00:11:38,720 --> 00:11:40,399
마치 순차적인 문제인 것처럼 보고

358
00:11:40,399 --> 00:11:42,959
시간을 통해 문제를 해결하는 것처럼 우리는

359
00:11:42,959 --> 00:11:44,880
때때로 비에 접근할 수 있습니다.  -순차적인

360
00:11:44,880 --> 00:11:46,399
문제

361
00:11:46,399 --> 00:11:48,640
는 컴퓨터에서는 프로세서에서 순차적

362
00:11:48,640 --> 00:11:49,600


363
00:11:49,600 --> 00:11:51,680
이기 때문에 실제로

364
00:11:51,680 --> 00:11:52,959
세계에서 순차적인

365
00:11:52,959 --> 00:11:54,880
것 또는 우리가 순차적인 것처럼 행동하려는 것들에 대한 것이기 때문에

366
00:11:54,880 --> 00:11:57,600


367
00:11:57,600 --> 00:12:00,240
하나의 큰 긴장이 발생합니다.  모든

368
00:12:00,240 --> 00:12:01,760
종류의 모델링

369
00:12:01,760 --> 00:12:05,040
은 탐색 익스플로잇 딜레마 슬래시

370
00:12:05,040 --> 00:12:08,160
트레이드오프입니다. 이것은 2015년에 우주 정신과 사회의 모든 탐사 대 착취에 관한 멋진

371
00:12:08,160 --> 00:12:08,880
논문입니다.

372
00:12:08,880 --> 00:12:11,440


373
00:12:11,440 --> 00:12:12,639


374
00:12:12,639 --> 00:12:15,760


375
00:12:15,760 --> 00:12:17,360
그래서 여기 표에서 여러 다른 영역에 대해 이야기하기 때문에 꽤 멋집니다.

376
00:12:17,360 --> 00:12:19,519


377
00:12:19,519 --> 00:12:21,760
1 동물

378
00:12:21,760 --> 00:12:22,639
단조

379
00:12:22,639 --> 00:12:25,519
시각적 검색 정보 검색 기억

380
00:12:25,519 --> 00:12:26,399


381
00:12:26,399 --> 00:12:28,320
검색 및 문제 해결 및 사회

382
00:12:28,320 --> 00:12:29,839
집단 학습이 있습니다.

383
00:12:29,839 --> 00:12:33,120
이것들은 우리가 가장 좋아하는 주제와 유사합니다.

384
00:12:33,120 --> 00:12:34,880
t 약간의 시각적

385
00:12:34,880 --> 00:12:36,160
예

386
00:12:36,160 --> 00:12:38,639
입니다. 다른 영역

387
00:12:38,639 --> 00:12:40,240
에서 탐색

388
00:12:40,240 --> 00:12:42,560
의 원형이 어떻게 생겼는지, 착취의 원형이

389
00:12:42,560 --> 00:12:43,760


390
00:12:43,760 --> 00:12:46,800
어떻게 생겼는지, 이들 중 일부는

391
00:12:46,800 --> 00:12:49,600


392
00:12:49,600 --> 00:12:50,160


393
00:12:50,160 --> 00:12:52,560
패치 단조 탐사와 같은 물리적 움직임

394
00:12:52,560 --> 00:12:53,600
의 종류와 매우 관련이 있습니다.  나무

395
00:12:53,600 --> 00:12:56,000
착취 같은 나무에 머무르는 것

396
00:12:56,000 --> 00:12:57,440
뿐만 아니라 시각적 초점

397
00:12:57,440 --> 00:13:00,720
탐색 탐색 탐색

398
00:13:00,720 --> 00:13:03,200
고정된 시선

399
00:13:03,200 --> 00:13:04,160
으로

400
00:13:04,160 --> 00:13:06,720
무언가를 응시하고 우리는

401
00:13:06,720 --> 00:13:07,519


402
00:13:07,519 --> 00:13:09,680
기억 탐색과 같은 단어 연상에서도 생각할

403
00:13:09,680 --> 00:13:10,560


404
00:13:10,560 --> 00:13:12,720


405
00:13:12,720 --> 00:13:13,920


406
00:13:13,920 --> 00:13:16,800
수 있습니다.

407
00:13:16,800 --> 00:13:18,720
모든 가축 동물이나

408
00:13:18,720 --> 00:13:20,000
같은 문자를 가진 동물과 마찬가지로 의미 체계에 다른 차원이

409
00:13:20,000 --> 00:13:21,920
있기 때문에 악용할 수 있는 다른 방법이 있습니다.

410
00:13:21,920 --> 00:13:23,519


411
00:13:23,519 --> 00:13:25,040


412
00:13:25,040 --> 00:13:27,279


413
00:13:27,279 --> 00:13:28,320


414
00:13:28,320 --> 00:13:30,480


415
00:13:30,480 --> 00:13:31,360


416
00:13:31,360 --> 00:13:34,000
그것은

417
00:13:34,000 --> 00:13:35,279
동물의

418
00:13:35,279 --> 00:13:36,800
행동에서 연구되었습니다 모든 친족에서 연구되었습니다  ds의

419
00:13:36,800 --> 00:13:39,120
의사 결정 작업

420
00:13:39,120 --> 00:13:42,240
에 추가할 사항이 있습니다.

421
00:13:42,240 --> 00:13:44,160


422
00:13:44,160 --> 00:13:45,760
작년 여름에 이 논문의 두 번째 저자인 Peter todd와 많은 상호 작용

423
00:13:45,760 --> 00:13:46,639
을

424
00:13:46,639 --> 00:13:50,079
했습니다. 너무 재미있었습니다. 시원하고

425
00:13:50,079 --> 00:13:52,240
이안 요리도 멋진 집단

426
00:13:52,240 --> 00:13:53,600
행동 작업을 수행

427
00:13:53,600 --> 00:13:55,440
하여 흥미진진합니다.

428
00:13:55,440 --> 00:13:56,880
이러한 알고리즘

429
00:13:56,880 --> 00:13:59,920
이 개별 에이전트

430
00:13:59,920 --> 00:14:00,959
뿐만 아니라

431
00:14:00,959 --> 00:14:02,720
그룹에도 적용할 수 있는 방법

432
00:14:02,720 --> 00:14:05,040


433
00:14:05,040 --> 00:14:08,160


434
00:14:08,560 --> 00:14:11,040
에 대해

435
00:14:11,040 --> 00:14:13,120


436
00:14:13,120 --> 00:14:15,600
생각하기  multi-armed bandit

437
00:14:15,600 --> 00:14:17,519
에 대한 불확실성 하에서 순차적인 의사 결정

438
00:14:17,519 --> 00:14:20,639


439
00:14:20,639 --> 00:14:22,800
은 우리가 그것을 연구할 수 있는 방법

440
00:14:22,800 --> 00:14:23,680


441
00:14:23,680 --> 00:14:25,839
이며 여기에서 우리가

442
00:14:25,839 --> 00:14:27,760
두 가지 문제가 해결하고 있는 두 가지 문제를 논문에서 소개하고

443
00:14:27,760 --> 00:14:28,720


444
00:14:28,720 --> 00:14:30,800
있습니다. 우리는 경험적 평가에서 두 가지 유형의 bandit 문제를 고려합니다.

445
00:14:30,800 --> 00:14:33,279


446
00:14:33,279 --> 00:14:35,360
고전적 기계 학습 문제로서의 고정 적기와

447
00:14:35,360 --> 00:14:36,880


448
00:14:36,880 --> 00:14:37,519


449
00:14:37,519 --> 00:14:39,600
신경 과학에서 일반적으로 사용되는 스위칭

450
00:14:39,600 --> 00:14:41,760


451
00:14:41,760 --> 00:14:43,199
적기  그것들은 기술적으로 정의되지만

452
00:14:43,199 --> 00:14:45,440
사람들

453
00:14:45,440 --> 00:14:47,519
이 다중 팔 도적을 사용하여 얻는 것부터 시작하겠습니다.

454
00:14:47,519 --> 00:14:50,000
왜 그렇게 많은 사람들

455
00:14:50,000 --> 00:14:51,839
이 해결

456
00:14:51,839 --> 00:14:53,519
한 것입니까? 이것은

457
00:14:53,519 --> 00:14:54,880
그들이 여기에서 수행하는 결과

458
00:14:54,880 --> 00:14:56,399
를 기계 학습 커뮤니티뿐만 아니라 직접적으로 관련이 있게 만들 것

459
00:14:56,399 --> 00:14:58,000
입니다.

460
00:14:58,000 --> 00:14:59,600
뿐만 아니라 다양한 연구 질문에 대해 능동 추론 프레임워크

461
00:14:59,600 --> 00:15:01,600
를 자주 사용하는 신경과학의 학습 및 의사결정 연구를

462
00:15:01,600 --> 00:15:02,880


463
00:15:02,880 --> 00:15:04,480
위해

464
00:15:04,480 --> 00:15:06,720


465
00:15:06,720 --> 00:15:08,560
이러한 다양한 영역이 있습니다.

466
00:15:08,560 --> 00:15:10,399
여기에

467
00:15:10,399 --> 00:15:11,600


468
00:15:11,600 --> 00:15:14,160
컴퓨터 과학 기계 학습

469
00:15:14,160 --> 00:15:15,120
경제학

470
00:15:15,120 --> 00:15:18,160
신경과학을 공부할 영역을 결정하는 다중 팔 도적이 있습니다.

471
00:15:18,160 --> 00:15:20,079
다중 무장 도적(multi-armed bandit)이 다리와 같은 모든 영역에서

472
00:15:20,079 --> 00:15:21,760


473
00:15:21,760 --> 00:15:24,160
지금 우리는 바로 그 연결점에 능동적 추론

474
00:15:24,160 --> 00:15:26,320
을 하고 있습니다.

475
00:15:26,320 --> 00:15:27,760
우리는

476
00:15:27,760 --> 00:15:30,160
컴퓨터 과학을 행동에

477
00:15:30,160 --> 00:15:32,639
연결하거나 신경 과학을 경제학에 연결하는

478
00:15:32,639 --> 00:15:33,759
것에 대해 많이 이야기했습니다. 우리가 모두 한 자리에서 만날 수 있다면 어떨까요?

479
00:15:33,759 --> 00:15:36,639
공통 넥서스 만약 그것이

480
00:15:36,639 --> 00:15:37,839
능동 추론이었다면

481
00:15:37,839 --> 00:15:39,519
이것들은 이야기할 수 있는 재미있는 종류의 것들

482
00:15:39,519 --> 00:15:40,880


483
00:15:40,880 --> 00:15:43,920
이지만 그렇지 않습니다.  다중 철 도적과 능동 추론의 개념적 연결에 불과합니다.

484
00:15:43,920 --> 00:15:46,160


485
00:15:46,160 --> 00:15:47,279


486
00:15:47,279 --> 00:15:48,959
실제로 특정 사용

487
00:15:48,959 --> 00:15:51,040
사례가 많이 있으며 온라인 경험을 뒷받침하는 많은 알고리즘

488
00:15:51,040 --> 00:15:54,639
이 실제로

489
00:15:54,639 --> 00:15:55,440
훈련

490
00:15:55,440 --> 00:15:58,959
되고 다중 팔 도적 문제에 적합

491
00:15:58,959 --> 00:16:01,279
하므로 여기에 몇 가지 재미가 있습니다.

492
00:16:01,279 --> 00:16:02,000


493
00:16:02,000 --> 00:16:05,680
여기 왼쪽 상단에서 조사하는 동안 우리가 발견한 예

494
00:16:05,680 --> 00:16:09,120
는

495
00:16:09,120 --> 00:16:11,360
다중 팔 도적이 음악 추천에서 역할을 수행하는 방법을 보여줍니다

496
00:16:11,360 --> 00:16:12,720


497
00:16:12,720 --> 00:16:15,519


498
00:16:15,519 --> 00:16:16,560


499
00:16:16,560 --> 00:16:18,399


500
00:16:18,399 --> 00:16:20,320
.  음악 플랫폼의 관점에서 보면

501
00:16:20,320 --> 00:16:21,120


502
00:16:21,120 --> 00:16:23,920
노래를 보내고 있는 대상

503
00:16:23,920 --> 00:16:24,560
사용자

504
00:16:24,560 --> 00:16:26,959
가 여기에 있는 도적기 기계에 대한

505
00:16:26,959 --> 00:16:28,880
보상을 알고리즘

506
00:16:28,880 --> 00:16:31,839


507
00:16:31,839 --> 00:16:34,079


508
00:16:34,079 --> 00:16:35,839
에 제공합니다.

509
00:16:35,839 --> 00:16:37,759
순차적 의사 결정

510
00:16:37,759 --> 00:16:40,320
과 동일한 관계가

511
00:16:40,320 --> 00:16:40,880


512
00:16:40,880 --> 00:16:43,040
그래픽으로 표시됩니다. 목표는

513
00:16:43,040 --> 00:16:44,800
평가의 합을 최대화하는

514
00:16:44,800 --> 00:16:46,560
것과 추상화에서 보수의 합을 최대화하는 것입니다.  t

515
00:16:46,560 --> 00:16:47,680
문제

516
00:16:47,680 --> 00:16:50,560
여기 웹사이트의 예가 있습니다. 웹사이트의

517
00:16:50,560 --> 00:16:52,560
테스트 버전을 테스트하기

518
00:16:52,560 --> 00:16:54,880
때문에 맨 위에는 4가지 버전

519
00:16:54,880 --> 00:16:56,000
의 웹사이트

520
00:16:56,000 --> 00:16:58,320
가 있습니다. 그런 다음 각 버전은

521
00:16:58,320 --> 00:16:59,839
사용자의 4분의 1에게 할당

522
00:16:59,839 --> 00:17:01,920
되고 각 사용자는

523
00:17:01,920 --> 00:17:03,440
해당 사이트에 계속 머물게 됩니다.  표준 b 테스트에서 전체 테스트 기간 동안 특정

524
00:17:03,440 --> 00:17:05,679
시간 또는 다른 시간 동안 머무르는

525
00:17:05,679 --> 00:17:07,439


526
00:17:07,439 --> 00:17:09,520


527
00:17:09,520 --> 00:17:13,119
동안 각 사이트에 대해 1/4을 유지

528
00:17:13,119 --> 00:17:15,280
하지만 다중 무장 밴디트

529
00:17:15,280 --> 00:17:16,319
에서는 1/4로 시작

530
00:17:16,319 --> 00:17:18,000
하지만 매우 빠르게  이

531
00:17:18,000 --> 00:17:20,720
파란색이 더 나은 성능을

532
00:17:20,720 --> 00:17:22,720
발휘하기 시작한 다음 계속 탐색하고

533
00:17:22,720 --> 00:17:25,199
다른 색상에 시간을 할당

534
00:17:25,199 --> 00:17:27,839
하지만 파란색이 꽤

535
00:17:27,839 --> 00:17:28,559
꾸준히

536
00:17:28,559 --> 00:17:31,440
우세하고 검은 선이

537
00:17:31,440 --> 00:17:32,000


538
00:17:32,000 --> 00:17:34,960
더 높게 유지되어 전체적으로 더 높은 숫자가

539
00:17:34,960 --> 00:17:36,960
마지막에  신기원

540
00:17:36,960 --> 00:17:39,280
을 통해 배우는 동안 일종의 수익을 올릴 수

541
00:17:39,280 --> 00:17:40,240


542
00:17:40,240 --> 00:17:43,840
있습니다. 탐색하는 동안 탐색을 할 수도

543
00:17:43,840 --> 00:17:45,039


544
00:17:45,039 --> 00:17:47,840


545
00:17:47,840 --> 00:17:49,200


546
00:17:49,200 --> 00:17:51,280
있고 맥락에서 베이지안 도적과 같은 구체적으로 이에 관한 논문이 있기 때문입니다.  t 온라인 개인화

547
00:17:51,280 --> 00:17:52,960
추천

548
00:17:52,960 --> 00:17:56,480
그 파란색 멋진 것에 대한 어떤 생각도

549
00:17:56,480 --> 00:17:57,919
그렇습니다

550
00:17:57,919 --> 00:18:00,000
이것들은 매일 사용되는 알고리즘

551
00:18:00,000 --> 00:18:02,640
이며

552
00:18:02,640 --> 00:18:03,520
우리

553
00:18:03,520 --> 00:18:07,120
의 많은 경험과 많은 의사 결정 지원에 힘을

554
00:18:07,120 --> 00:18:09,200


555
00:18:09,200 --> 00:18:11,440
실어줍니다. 여기에서 우리가 베이지안 알고리즘 중 일부를 가져옵니다

556
00:18:11,440 --> 00:18:12,880
그들은

557
00:18:12,880 --> 00:18:15,039
고정 및 전환 두 가지 유형의 적적 문제를 사용할

558
00:18:15,039 --> 00:18:15,840


559
00:18:15,840 --> 00:18:18,880
것이며 여기에 두 번째 용어 쌍이

560
00:18:18,880 --> 00:18:20,480
있습니다.

561
00:18:20,480 --> 00:18:22,000
능동 추론

562
00:18:22,000 --> 00:18:24,320
을 기계 학습의 다른 두 가지 최신 밴드

563
00:18:24,320 --> 00:18:26,080
알고리즘과 경험적으로 비교할 것입니다.

564
00:18:26,080 --> 00:18:27,679
기계 학습에 익숙한 사람은

565
00:18:27,679 --> 00:18:29,760
이 두 알고리즘을 많이 보았을 것입니다

566
00:18:29,760 --> 00:18:31,280


567
00:18:31,280 --> 00:18:33,679
. 첫 번째는 신뢰 상한

568
00:18:33,679 --> 00:18:34,480
알고리즘인

569
00:18:34,480 --> 00:18:37,760
ucb이고 두 번째는 낙관적 톰슨 샘플링이라고 하는 톰슨 샘플링의 변형입니다.

570
00:18:37,760 --> 00:18:39,200


571
00:18:39,200 --> 00:18:42,080
그런

572
00:18:42,080 --> 00:18:43,039
다음 여기

573
00:18:43,039 --> 00:18:45,760
에서 ucb 및 톰슨 샘플링이 도달하는 두 가지 알고리즘에 주목합니다.

574
00:18:45,760 --> 00:18:47,360


575
00:18:47,360 --> 00:18:48,880


576
00:18:48,880 --> 00:18:51,360
다양한 고정 적기 문제에 대한 최첨단 성능

577
00:18:51,360 --> 00:18:53,200


578
00:18:53,200 --> 00:18:55,200
실제와 최적의 차이인 후회를 달성  성능

579
00:18:55,200 --> 00:18:56,480
은

580
00:18:56,480 --> 00:18:58,240
가능한 최고의

581
00:18:58,240 --> 00:18:59,919
대수 후회에

582
00:18:59,919 --> 00:19:01,440
가깝고 도적을 전환할 때 학습이

583
00:19:01,440 --> 00:19:03,280
더 복잡하지만 이것이 고려되면

584
00:19:03,280 --> 00:19:03,760


585
00:19:03,760 --> 00:19:05,200
두 알고리즘 모두

586
00:19:05,200 --> 00:19:07,039
최첨단 성능을 나타내

587
00:19:07,039 --> 00:19:10,080
므로 완벽하게 플레이할 수는 없지만 성능은 곧 돌아올 것입니다.

588
00:19:10,080 --> 00:19:12,000


589
00:19:12,000 --> 00:19:12,720


590
00:19:12,720 --> 00:19:15,280
이 알고리즘으로 플레이할 수 있는 가장 좋은 방법에 대해 다시

591
00:19:15,280 --> 00:19:16,559
살펴보겠습니다.

592
00:19:16,559 --> 00:19:18,880
이 알고리즘이 무엇인지에 대한 기술적인 세부 사항으로

593
00:19:18,880 --> 00:19:20,880


594
00:19:20,880 --> 00:19:22,960
들어가기 전에 어떻게 생겼습니까? 왼쪽 상단에 있으므로

595
00:19:22,960 --> 00:19:24,559


596
00:19:24,559 --> 00:19:26,559
어떤 버전의

597
00:19:26,559 --> 00:19:28,480
우리가 발표하고 싶은 웹사이트 또는 어떤 노래

598
00:19:28,480 --> 00:19:29,919
를 발표하고 싶은지

599
00:19:29,919 --> 00:19:32,559
또는 왼쪽 상단에 추상화를 유지하는 것입니다.

600
00:19:32,559 --> 00:19:34,160


601
00:19:34,160 --> 00:19:36,559
우리는 시도 없이 시작하므로 정보가 전혀 없기 전에 시도가

602
00:19:36,559 --> 00:19:38,000


603
00:19:38,000 --> 00:19:41,120


604
00:19:41,120 --> 00:19:44,160
발생하고 결과가 관찰됩니다.

605
00:19:44,160 --> 00:19:44,720


606
00:19:44,720 --> 00:19:48,640
28번의 시도 후에 시도 횟수가 계산됩니다.

607
00:19:48,640 --> 00:19:50,799
우리는 매우 현저하게 다른 분포 세트에 도달했습니다.

608
00:19:50,799 --> 00:19:52,799


609
00:19:52,799 --> 00:19:55,679
따라서 이 전체가 어떻게 보이는지

610
00:19:55,679 --> 00:19:57,360
당신이 카지노에 나타나지만 게임을 하지 않는 것입니다.

611
00:19:57,360 --> 00:19:58,559
이제

612
00:19:58,559 --> 00:20:01,039
슬롯 머신 중 하나의 결과가 나온 다음 해당 슬롯 머신에 접근하고 필요에 따라 슬롯 머신 간에 전환

613
00:20:01,039 --> 00:20:02,080


614
00:20:02,080 --> 00:20:04,880
하는 몇 가지 정책을 선택

615
00:20:04,880 --> 00:20:05,520


616
00:20:05,520 --> 00:20:07,840


617
00:20:07,840 --> 00:20:10,080


618
00:20:10,080 --> 00:20:12,720


619
00:20:12,720 --> 00:20:13,600


620
00:20:13,600 --> 00:20:15,760
하여 가장 많은 돈을 얻을 수 있는 방법을 선택할 것입니다.

621
00:20:15,760 --> 00:20:17,600


622
00:20:17,600 --> 00:20:19,200
더 많은 정보를 얻을

623
00:20:19,200 --> 00:20:21,120


624
00:20:21,120 --> 00:20:23,360
수록 분포가 어떻게 생겼는지에 대한 추정치를 미세 조정하는 것과 같습니다

625
00:20:23,360 --> 00:20:25,440


626
00:20:25,440 --> 00:20:27,760


627
00:20:27,760 --> 00:20:29,200
. 다른 분포에 대해 점점 더 많이 그리고 유사

628
00:20:29,200 --> 00:20:31,360
하게 시도할수록 빨간색 분포가 어떻게 조정되는지 알 수 있습니다.  그것이 이 알고리즘이 하는 일의 일종입니다

629
00:20:31,360 --> 00:20:34,320


630
00:20:34,320 --> 00:20:35,200


631
00:20:35,200 --> 00:20:37,760
. 주어진 슬롯 머신에 대한 특정한 편견 없이

632
00:20:37,760 --> 00:20:38,799


633
00:20:38,799 --> 00:20:41,840
시작한 다음 새로운

634
00:20:41,840 --> 00:20:43,840
슬롯 머신이나 한동안 시도하지 않은 슬롯 머신에 대해 알려진 슬롯 머신을 유지하기 위한 전략을 개발하려고 시도합니다.

635
00:20:43,840 --> 00:20:46,080


636
00:20:46,080 --> 00:20:48,240


637
00:20:48,240 --> 00:20:49,679
가능한 최상의 결과를 얻으려면

638
00:20:49,679 --> 00:20:51,520
상상할 수 있듯이

639
00:20:51,520 --> 00:20:53,840
정적 인 것이

640
00:20:53,840 --> 00:20:55,039


641
00:20:55,039 --> 00:20:57,360
있으면 동적 인 경우

642
00:20:57,360 --> 00:21:00,479
변경 속도를 염두에

643
00:21:00,640 --> 00:21:03,440
두어야하는 더 쉬운 문제입니다.  좋은

644
00:21:03,440 --> 00:21:04,240
설명입니다.

645
00:21:04,240 --> 00:21:07,520
베르누이 도적

646
00:21:07,520 --> 00:21:11,120
은 어 부류의 도적이며 그들이

647
00:21:11,120 --> 00:21:12,799
스스로를 제한하려고

648
00:21:12,799 --> 00:21:15,280


649
00:21:15,280 --> 00:21:17,440


650
00:21:17,440 --> 00:21:20,159
하므로 베르누이 도적을 위한 소위 베르누이 도적이라고 불리는 잘 연구된 버전의 도적에게 우리 자신을 제한하고 있다고 말합니다.

651
00:21:20,159 --> 00:21:21,520


652
00:21:21,520 --> 00:21:23,600
선택 결과는 팔별 베르누이 분포에서 가져옵니다.

653
00:21:23,600 --> 00:21:26,240


654
00:21:26,240 --> 00:21:28,080
가우스 산적과 함께 베르누이 산적

655
00:21:28,080 --> 00:21:30,640


656
00:21:30,640 --> 00:21:32,960
은

657
00:21:32,960 --> 00:21:35,120
이론 및 응용 기계 학습

658
00:21:35,120 --> 00:21:38,480
및 실험적 인지 과학 모두에서 가장 일반적으로 연구되는 다중 팔 산적의 변형이므로

659
00:21:38,480 --> 00:21:41,760


660
00:21:41,760 --> 00:21:44,720
각 기본 보상에 대해 모든 종류의 분포를 맞출 수 있습니다.

661
00:21:44,720 --> 00:21:46,000


662
00:21:46,000 --> 00:21:47,840
하지만 베르누이 분포를 사용

663
00:21:47,840 --> 00:21:49,679


664
00:21:49,679 --> 00:21:52,960
하면 수학이 잘 풀려서

665
00:21:52,960 --> 00:21:55,200
공부하기 쉬우

666
00:21:55,200 --> 00:21:56,799
므로 베르누이와 가우스에 대해 많은 연구가

667
00:21:56,799 --> 00:21:57,679


668
00:21:57,679 --> 00:22:00,400
있었기 때문에 가우스 분포 보상은

669
00:22:00,400 --> 00:22:01,200
괜찮을

670
00:22:01,200 --> 00:22:04,000
것입니다.  당신이 베르누이를 얼마나 얻을 수 있는지에 대한

671
00:22:04,000 --> 00:22:05,360
종 곡선

672
00:22:05,360 --> 00:22:07,280
은

673
00:22:07,280 --> 00:22:08,400
다를 것입니다.  셰이프

674
00:22:08,400 --> 00:22:09,520
분포

675
00:22:09,520 --> 00:22:10,960
지만 아이디어는 해당 팔에서

676
00:22:10,960 --> 00:22:12,640


677
00:22:12,640 --> 00:22:16,159
반환된 보상을 설명하는 매개변수를 학습하게

678
00:22:16,159 --> 00:22:18,480


679
00:22:18,480 --> 00:22:20,960
되므로 이 기계

680
00:22:20,960 --> 00:22:23,039
의 보상 보상의 기초가 되는 하위 범주 또는 함수일 뿐입니다

681
00:22:23,039 --> 00:22:24,320


682
00:22:24,320 --> 00:22:27,840


683
00:22:29,600 --> 00:22:32,640
. 두 알고리즘에 대해 이야기하겠습니다.

684
00:22:32,640 --> 00:22:34,960
많은 논의가 있을

685
00:22:34,960 --> 00:22:37,280
것이며 전략 측면에서 이러한 알고리즘이 작용하는 위치에 대해서도 논의

686
00:22:37,280 --> 00:22:39,520


687
00:22:39,520 --> 00:22:41,200
할 것이므로 다시

688
00:22:41,200 --> 00:22:43,280
카지노의 슬롯 머신에 앉아

689
00:22:43,280 --> 00:22:46,640
있고

690
00:22:46,640 --> 00:22:49,679
주어진 머신에 머물거나 떠날 방법을 결정할 것입니다.

691
00:22:49,679 --> 00:22:51,360
2019년 데이터 과학자들이

692
00:22:51,360 --> 00:22:53,200
이 문제를 해결하기 위해 여러 가지 솔루션을 개발

693
00:22:53,200 --> 00:22:57,280
한 멋진 블로그 게시물에서 가져온

694
00:22:57,280 --> 00:22:58,960
것입니다.

695
00:22:58,960 --> 00:23:00,880


696
00:23:00,880 --> 00:23:02,799
가장 일반적인 세 가지 알고리즘은 엡  

697
00:23:02,799 --> 00:23:04,240
론 욕  

698
00:23:04,240 --> 00:23:06,000
, 신뢰 상한, 톰슨 샘  

699
00:23:06,000 --> 00:23:08,000
링이므로 엡실론 욕심이 있습니다.  최고의 성능을 제공하는 알고리즘

700
00:23:08,000 --> 00:23:11,600
이 아니기 때문에 이 백서에서 제공되지

701
00:23:11,600 --> 00:23:13,360
는 않지만

702
00:23:13,360 --> 00:23:14,000


703
00:23:14,000 --> 00:23:17,039
실제로 가장 좋은 종류의 시작 알고리즘

704
00:23:17,039 --> 00:23:18,799
이며 가장 간단한 알고리즘입니다.  기본적으로 탐사 또는 착취 동안

705
00:23:18,799 --> 00:23:21,600
탐사 착취 트레이드 오프

706
00:23:21,600 --> 00:23:23,840


707
00:23:23,840 --> 00:23:25,120


708
00:23:25,120 --> 00:23:26,880
를 해결하십시오. 가장 높은 지불금을 가진 레버

709
00:23:26,880 --> 00:23:28,320
는 항상 당겨

710
00:23:28,320 --> 00:23:30,640


711
00:23:30,640 --> 00:23:32,960
져서 최고 성능 슬롯 머신의 실행 최고 추정치가

712
00:23:32,960 --> 00:23:36,400
기본값이 되지만 때때로

713
00:23:36,400 --> 00:23:38,880
임의의 분수 일부 분수가 있는 엡실론

714
00:23:38,880 --> 00:23:39,440


715
00:23:39,440 --> 00:23:40,880
시간의 5% 또는 시간의 1%

716
00:23:40,880 --> 00:23:42,480
는 알 수 없는 결과를 가진

717
00:23:42,480 --> 00:23:45,039
다른 무기를 탐색하기 위해 다른 임의의 팔을 선택

718
00:23:45,039 --> 00:23:45,600


719
00:23:45,600 --> 00:23:48,159


720
00:23:48,159 --> 00:23:49,440
하여 가장 높은 점수 추정치를 가진 것을 고수

721
00:23:49,440 --> 00:23:50,960


722
00:23:50,960 --> 00:23:53,279
하고 그 다음에는 시간의 일부만

723
00:23:53,279 --> 00:23:54,880
전환합니다.  다른 하나는

724
00:23:54,880 --> 00:23:55,919
확인

725
00:23:55,919 --> 00:23:58,000
하고 각각이 어떻게 하고 있는지에 대한 추정치를 업데이트

726
00:23:58,000 --> 00:23:59,039


727
00:23:59,039 --> 00:24:01,600
하면 이것이 하나의 전략입니다. 이제 여기

728
00:24:01,600 --> 00:24:02,559


729
00:24:02,559 --> 00:24:04,320
그보다 더 나은 두 가지 전략이 있습니다.

730
00:24:04,320 --> 00:24:06,080
이것이 우리가 능동 추론과 대조할 전략입니다. 그

731
00:24:06,080 --> 00:24:08,000


732
00:24:08,000 --> 00:24:09,840
중 하나는 다음과 같습니다.

733
00:24:09,840 --> 00:24:12,080


734
00:24:12,080 --> 00:24:14,320


735
00:24:14,320 --> 00:24:16,080


736
00:24:16,080 --> 00:24:18,640
t를 가정하는 능동 추론처럼 들리는 불확실성에 직면하여 낙관주의라고도 하는 신뢰 상한  각 부문의 알 수 없는 평균 수익은 과거 데이터를 기반

737
00:24:18,640 --> 00:24:21,279
으로 가능한 한 높기 때문에 각 부문

738
00:24:21,279 --> 00:24:24,240


739
00:24:24,240 --> 00:24:25,279
의 수익

740
00:24:25,279 --> 00:24:28,000
을 알지 못하지만

741
00:24:28,000 --> 00:24:30,240
데이터에서 이미

742
00:24:30,240 --> 00:24:32,240
얻은 것을 감안할 때 최대한 멀리 있다고 가정하고 싶습니다.

743
00:24:32,240 --> 00:24:33,600


744
00:24:33,600 --> 00:24:34,400


745
00:24:34,400 --> 00:24:36,240
이것이 우리가 이 분포의 상단에서 신뢰 상한선을 보는 이유

746
00:24:36,240 --> 00:24:39,200


747
00:24:39,200 --> 00:24:41,840
이며 톰슨 샘플링은

748
00:24:41,840 --> 00:24:43,600
기본적

749
00:24:43,600 --> 00:24:44,320


750
00:24:44,320 --> 00:24:45,679
으로

751
00:24:45,679 --> 00:24:47,679
확률 매칭으로 알려진 핵심 원칙을 가진 베이지안 최적화 기술입니다.  최고의 무기가

752
00:24:47,679 --> 00:24:48,240


753
00:24:48,240 --> 00:24:50,720
될 확률에 따라 무기를 사용하는 것으로 요약됩니다.

754
00:24:50,720 --> 00:24:51,440


755
00:24:51,440 --> 00:24:54,480
따라서 엡실론과 대조적으로 최고

756
00:24:54,480 --> 00:24:56,159
라고 생각하는 것을 선택

757
00:24:56,159 --> 00:24:57,520


758
00:24:57,520 --> 00:24:59,440
하고 10%의 시간

759
00:24:59,440 --> 00:25:00,559
은 다른 일을 하는 것과 대조적으로

760
00:25:00,559 --> 00:25:02,080
톰슨 샘플링은 당신과 같습니다.

761
00:25:02,080 --> 00:25:03,919


762
00:25:03,919 --> 00:25:05,120


763
00:25:05,120 --> 00:25:08,000
서로 다른 부문의 상대적 성과가 있는 원형 차트를 만든 다음

764
00:25:08,000 --> 00:25:09,200


765
00:25:09,200 --> 00:25:12,640
원형의 크기에 따라

766
00:25:12,640 --> 00:25:14,880
선택하므로 일종의 확인을 위해 높은 보수가 없는 차트는 거의 선택하지 않습니다

767
00:25:14,880 --> 00:25:16,400
.  그것들

768
00:25:16,400 --> 00:25:17,919
에 대해 다시 확인

769
00:25:17,919 --> 00:25:19,919


770
00:25:19,919 --> 00:25:21,679
하면 파이 조각이 커지기 시작

771
00:25:21,679 --> 00:25:23,360
하고 이러한 알고리즘을 훈련하는 요점은

772
00:25:23,360 --> 00:25:25,760


773
00:25:25,760 --> 00:25:26,080


774
00:25:26,080 --> 00:25:28,720
동적 사례 등에서 가중치를

775
00:25:28,720 --> 00:25:29,279


776
00:25:29,279 --> 00:25:30,640
재조정해야 하는 속도입니다.  그렇게 하는 것은

777
00:25:30,640 --> 00:25:32,960
해결책이 아니지만 불확실성

778
00:25:32,960 --> 00:25:33,679


779
00:25:33,679 --> 00:25:35,279
에 직면한 낙관주의

780
00:25:35,279 --> 00:25:37,919
든 이러한 보수적

781
00:25:37,919 --> 00:25:39,600
확률 매칭이든 간에

782
00:25:39,600 --> 00:25:41,600
우리가 보았듯이 최첨단인 두 가지 방법이 있습니다.

783
00:25:41,600 --> 00:25:43,039


784
00:25:43,039 --> 00:25:45,200
기본적으로 가능한 한 잘 수행

785
00:25:45,200 --> 00:25:47,520
하므로 신뢰 상한

786
00:25:47,520 --> 00:25:50,320
과 신뢰 하한으로 제한

787
00:25:50,320 --> 00:25:53,520
하고 있습니다. 알고리즘의 꽤 좋은 선택입니다

788
00:25:53,520 --> 00:25:55,279


789
00:25:55,279 --> 00:25:57,360
. 머신 러닝 교육 공간 전체에서 교육용 쌍

790
00:25:57,360 --> 00:26:00,240
으로 표시되므로

791
00:26:00,240 --> 00:26:02,159
저자는 그것을 능동 추론과 매우 명확하게 병치하기

792
00:26:02,159 --> 00:26:05,679


793
00:26:05,679 --> 00:26:08,320
때문에 톰슨 샘플링

794
00:26:08,320 --> 00:26:11,360
과 불확실성에 직면한 비관주의

795
00:26:11,360 --> 00:26:13,520


796
00:26:13,520 --> 00:26:16,080
가 과거보다 더 좋을 수

797
00:26:16,080 --> 00:26:18,240
없었습니다. 조금 더 자세히 살펴보겠습니다.

798
00:26:18,240 --> 00:26:19,679
두 가지

799
00:26:19,679 --> 00:26:22,559
다른 uh 알고리즘에 대해 자세히 설명한 다음 후회에 대해 이야기합니다.

800
00:26:22,559 --> 00:26:24,400


801
00:26:24,400 --> 00:26:27,600
여기 다른 블로그 게시물에서 lillian

802
00:26:27,600 --> 00:26:29,520
wang의 블로그에서

803
00:26:29,520 --> 00:26:32,559
bandit 전략에 대해 이야기하고 있습니다. 따라서

804
00:26:32,559 --> 00:26:35,360


805
00:26:35,360 --> 00:26:35,919


806
00:26:35,919 --> 00:26:38,000
능동적 추론이

807
00:26:38,000 --> 00:26:39,120


808
00:26:39,120 --> 00:26:40,799
우리가 얻을 수 있는 탐색 익스플로잇을 재개념화하는 데 도움이 될지라도 탐색과 익스플로잇에 관한 것입니다

809
00:26:40,799 --> 00:26:42,320
.

810
00:26:42,320 --> 00:26:44,000
하지만 우리는

811
00:26:44,000 --> 00:26:45,919


812
00:26:45,919 --> 00:26:48,240
게임

813
00:26:48,240 --> 00:26:49,440
을

814
00:26:49,440 --> 00:26:51,039
하는 더 좋은 방법이 있다는 것을 알고 있는 동안 잃어버린 기계를 가지고

815
00:26:51,039 --> 00:26:53,520
노는 데 시간을 보내고 있기 때문에 비효율적인 탐색을 원하지 않습니다. 그래서 그러한 비효율적인 탐색을 피하기 위한

816
00:26:53,520 --> 00:26:54,240


817
00:26:54,240 --> 00:26:57,600
한 가지 접근 방식은 엡실론 샘플링을 수행하는 것입니다.

818
00:26:57,600 --> 00:27:00,159
그런 다음 고정된 보수 집합의 경우

819
00:27:00,159 --> 00:27:00,880


820
00:27:00,880 --> 00:27:03,039


821
00:27:03,039 --> 00:27:04,960
시간이 지나면서 해당 매개변수 엡실론을 감소시키므로 다시 얼마나 빨리 줄여야

822
00:27:04,960 --> 00:27:06,240


823
00:27:06,240 --> 00:27:07,919
매개변수에 맞아야 하지만

824
00:27:07,919 --> 00:27:09,919


825
00:27:09,919 --> 00:27:13,840


826
00:27:13,840 --> 00:27:17,200
이는 비효율적인 탐색을 방지하기 위한 다른 접근 방식 중 하나일 뿐이므로 고통을 피하십시오.

827
00:27:17,200 --> 00:27:18,159


828
00:27:18,159 --> 00:27:20,720


829
00:27:20,720 --> 00:27:21,200


830
00:27:21,200 --> 00:27:22,720


831
00:27:22,720 --> 00:27:24,480
불확실성이 높은 옵션에 대해 낙관적인 가치에 대해 낙관적이어서 다음을

832
00:27:24,480 --> 00:27:26,960
위해 암묵적으로 행동을 선호합니다.  ich 우리

833
00:27:26,960 --> 00:27:28,799
는 아직 신뢰도 값을

834
00:27:28,799 --> 00:27:30,559
추정하지 않았기 때문에 이것이

835
00:27:30,559 --> 00:27:32,320
불확실성에 직면한 낙관론입니다.

836
00:27:32,320 --> 00:27:34,480
다시 말해서 우리

837
00:27:34,480 --> 00:27:36,559
는 최적 값을 가질 수 있는 강력한 잠재력을 가진 활동의 탐색을 선호

838
00:27:36,559 --> 00:27:38,799
하므로 이것이 바로

839
00:27:38,799 --> 00:27:39,600
ucb

840
00:27:39,600 --> 00:27:42,720
신뢰 상한 알고리즘이 하는 일입니다

841
00:27:42,720 --> 00:27:44,799
.

842
00:27:44,799 --> 00:27:47,520
진정한 값이 항상 그 경계

843
00:27:47,520 --> 00:27:48,320
아래에

844
00:27:48,320 --> 00:27:52,559
있도록 신뢰 상한으로 측정한 다음

845
00:27:52,559 --> 00:27:55,279


846
00:27:55,279 --> 00:27:56,559
그 아래 어딘가에

847
00:27:56,559 --> 00:28:00,799
실제 값이 너무 멀지

848
00:28:00,799 --> 00:28:03,440
않기를 바라며 ucv 알고리즘이 이것으로

849
00:28:03,440 --> 00:28:06,559
최적화를 수행한다는 것을 알고 상한을 올리려고 합니다.  arg max

850
00:28:06,559 --> 00:28:08,159


851
00:28:08,159 --> 00:28:10,559
그 신뢰 상한을 최대화하기 위해 가장 탐욕스러운 행동을 선택

852
00:28:10,559 --> 00:28:12,960
하여 블로그에 기본적으로 배치되어

853
00:28:12,960 --> 00:28:14,000


854
00:28:14,000 --> 00:28:17,440
있으므로 탐색을 할 수 없습니다. 거기

855
00:28:17,440 --> 00:28:19,279
에 머물면서 처음으로 앉아 있는 것을 선택하는 것뿐입니다

856
00:28:19,279 --> 00:28:21,600
. 무작위로 탐색할 수 있는

857
00:28:21,600 --> 00:28:24,960
엡실론 탐욕 또는 당신

858
00:28:24,960 --> 00:28:25,600


859
00:28:25,600 --> 00:28:27,840
불확실성에 대한

860
00:28:27,840 --> 00:28:29,279


861
00:28:29,279 --> 00:28:29,840


862
00:28:29,840 --> 00:28:31,760
선호로 현명하게 탐색할 수 있으므로

863
00:28:31,760 --> 00:28:33,279
일반적으로 우리가 좋아

864
00:28:33,279 --> 00:28:35,600
하지만  그런 다음 다른 곳에서

865
00:28:35,600 --> 00:28:37,279
때때로 보내는 시간 다른 곳에서 보내는 시간과

866
00:28:37,279 --> 00:28:38,720
우리

867
00:28:38,720 --> 00:28:40,240
가 잘 선택해야 할 기계

868
00:28:40,240 --> 00:28:41,919


869
00:28:41,919 --> 00:28:44,080


870
00:28:44,080 --> 00:28:46,159


871
00:28:46,159 --> 00:28:47,200


872
00:28:47,200 --> 00:28:50,320
그래서 그것은 ucb입니다 그것에 대한 의견이

873
00:28:50,320 --> 00:28:53,279
없습니다. 대조적으로 우리는

874
00:28:53,279 --> 00:28:54,880


875
00:28:54,880 --> 00:28:58,799
agrowall columbia의 멋진 슬라이드 데크에서 톰슨 샘플링을 가지고

876
00:28:58,799 --> 00:29:01,760
있으며 톰슨 샘플링은 1933년으로 거슬러 올라갑니다.

877
00:29:01,760 --> 00:29:03,840


878
00:29:03,840 --> 00:29:05,679
그래서 다른 많은 알고리즘과 마찬가지로

879
00:29:05,679 --> 00:29:07,760
고전적인 변형

880
00:29:07,760 --> 00:29:10,480
은 사전 계산적이기 때문에

881
00:29:10,480 --> 00:29:12,640
때로는 생각 실험일 수도 있습니다.

882
00:29:12,640 --> 00:29:14,720
슬라이드에서는

883
00:29:14,720 --> 00:29:16,159
thompson 샘플링이 각 팔의 주요 보상인 효과에 대한 믿음

884
00:29:16,159 --> 00:29:18,399
을 유지하는 자연스럽고 효율적인 경험적 방법에

885
00:29:18,399 --> 00:29:19,520


886
00:29:19,520 --> 00:29:21,760
대해 이야기

887
00:29:21,760 --> 00:29:23,760


888
00:29:23,760 --> 00:29:25,440


889
00:29:25,440 --> 00:29:27,440


890
00:29:27,440 --> 00:29:28,399


891
00:29:28,399 --> 00:29:30,000
하고 있습니다.  기본적으로 작동 방식

892
00:29:30,000 --> 00:29:32,000
은 피드백을 관찰

893
00:29:32,000 --> 00:29:34,159
한 다음

894
00:29:34,159 --> 00:29:36,240
베이지안 방식으로 다른 팔에 대한 믿음을 업데이트

895
00:29:36,240 --> 00:29:38,159
한 다음

896
00:29:38,159 --> 00:29:40,399
최고의 팔이 될 사후 확률이 있는 rms는 가장 좋은

897
00:29:40,399 --> 00:29:42,240
팔을 선택하는 것과 같지 않습니다.

898
00:29:42,240 --> 00:29:44,399


899
00:29:44,399 --> 00:29:47,039
이것은 다시 원형 차트와 같습니다. 이 차트

900
00:29:47,039 --> 00:29:48,240


901
00:29:48,240 --> 00:29:49,760
는 얼마나 잘 수행하고 있는지에 대한 비율을 표시한 다음

902
00:29:49,760 --> 00:29:52,480
그 비율을 기반으로 선택합니다.

903
00:29:52,480 --> 00:29:56,399
의사 코드는 다음과 같습니다.

904
00:29:56,399 --> 00:29:59,679


905
00:29:59,679 --> 00:30:03,919


906
00:30:03,919 --> 00:30:06,240
우리는 보상을 받을

907
00:30:06,240 --> 00:30:08,559
것으로 예상되는 사전 분포 및 분포 패밀리로 모델을 초기화하기 시작합니다. 그래서 이것은

908
00:30:08,559 --> 00:30:09,279
가우스

909
00:30:09,279 --> 00:30:10,960
사례이지만 여기에서

910
00:30:10,960 --> 00:30:12,960
베르누이 도적이 들어오는 것을 볼 수 있습니다.  플레이

911
00:30:12,960 --> 00:30:16,720
하고 알고리즘은 다음과 같습니다.

912
00:30:16,720 --> 00:30:20,159
먼저 주어진 팔 i에 대한 사후 추정치로 평균 샘플링이 있습니다.

913
00:30:20,159 --> 00:30:23,440


914
00:30:23,440 --> 00:30:26,799
그런 다음

915
00:30:26,799 --> 00:30:28,799
팔이 최고의 팔이 될 확률에 따라 팔이 재생됩니다

916
00:30:28,799 --> 00:30:29,919


917
00:30:29,919 --> 00:30:33,279


918
00:30:33,279 --> 00:30:36,799
. 보상이 관찰되고

919
00:30:36,799 --> 00:30:39,520
모든 것이 업데이트됩니다.  그래서 그것은

920
00:30:39,520 --> 00:30:41,679


921
00:30:41,679 --> 00:30:44,559
당신의 예측에서 나온 후부의 샘플과 같습니다.

922
00:30:44,559 --> 00:30:44,960
그런 다음

923
00:30:44,960 --> 00:30:48,399
행동하고 관찰하고 업데이트하는

924
00:30:48,399 --> 00:30:49,600
것과 같습니다. 마치 모든 시작이 다른 것에서 비롯된다는 것을 알고 있는 마감 시간의 노래와 같습니다.

925
00:30:49,600 --> 00:30:51,440


926
00:30:51,440 --> 00:30:52,640


927
00:30:52,640 --> 00:30:54,159
시작은 끝

928
00:30:54,159 --> 00:30:56,559
이고 베이지안 통계에서는 사후(posterior)라고 하며

929
00:30:56,559 --> 00:30:57,600


930
00:30:57,600 --> 00:31:00,159
이전은 사후 업데이트되지만 해당 사후

931
00:31:00,159 --> 00:31:01,679


932
00:31:01,679 --> 00:31:04,399
는 다음 라운드에 대한 사전이므로 모델에

933
00:31:04,399 --> 00:31:05,840


934
00:31:05,840 --> 00:31:08,960
사후 피드백을 다시 학습하는 한 라운드가 아닙니다.

935
00:31:08,960 --> 00:31:10,480


936
00:31:10,480 --> 00:31:12,559
지속적인 베이지안 업데이트에 대해 이야기하십시오.

937
00:31:12,559 --> 00:31:15,600


938
00:31:15,600 --> 00:31:18,240
관찰 오리엔트 결정 행위와 같은 일종의 ooda와 같습니다.

939
00:31:18,240 --> 00:31:19,679


940
00:31:19,679 --> 00:31:22,240
물론 능동 추론을 포함하는 이러한 종류의 작업 루프

941
00:31:22,240 --> 00:31:22,880


942
00:31:22,880 --> 00:31:26,080
는 이러한 모델을 실제로 유사하거나 적어도 동일한 이웃에서 만드는 것입니다.

943
00:31:26,080 --> 00:31:27,679


944
00:31:27,679 --> 00:31:28,960
그런 다음 우리가 논의하는 이 문서

945
00:31:28,960 --> 00:31:32,240


946
00:31:32,240 --> 00:31:34,320
방정식과 분석적으로 정렬하고

947
00:31:34,320 --> 00:31:37,440
시뮬레이션과 병렬

948
00:31:37,440 --> 00:31:39,360
을 통해 톰슨 샘플링이 무엇인지 알 수 있습니다. 톰슨에

949
00:31:39,360 --> 00:31:42,240
대한 의견

950
00:31:42,240 --> 00:31:44,399
은 앞서 이야기한

951
00:31:44,399 --> 00:31:46,320
순차 의사 결정 프로세스에 얼마나

952
00:31:46,320 --> 00:31:47,679
잘

953
00:31:47,679 --> 00:31:49,200
작용하는지 알려줍니다.

954
00:31:49,200 --> 00:31:51,120
업데이트하고 업데이트하고 업데이트합니다.

955
00:31:51,120 --> 00:31:52,960
예를 들어 다음과 같은

956
00:31:52,960 --> 00:31:54,960
비순차적 작업에 대해서도 마찬가지로  가져온 이미지

957
00:31:54,960 --> 00:31:56,640
분류

958
00:31:56,640 --> 00:31:59,679
는 큰 데이터베이스에서 샘플링

959
00:31:59,679 --> 00:32:01,600
한 다음 모델을 업데이트할 수 있습니다. 그런 다음

960
00:32:01,600 --> 00:32:02,880
샘플링을 하고 나면 전체 데이터 세트

961
00:32:02,880 --> 00:32:05,120


962
00:32:05,120 --> 00:32:06,960
를 살펴볼 필요가 없을 정도로 내 모델을 업데이트하지 않는 것처럼 보입니다.

963
00:32:06,960 --> 00:32:08,640


964
00:32:08,640 --> 00:32:10,960
비순차적

965
00:32:10,960 --> 00:32:12,480
문제를 순차적으로 구성

966
00:32:12,480 --> 00:32:15,679
하면 계산 속도가 크게 향상

967
00:32:15,679 --> 00:32:16,960
되고 물론 순차

968
00:32:16,960 --> 00:32:18,799
의사 결정을 위해서는

969
00:32:18,799 --> 00:32:21,519
이와 같은 접근 방식이 필요합니다.

970
00:32:22,240 --> 00:32:25,360
후회 학습 후회는 어떻

971
00:32:25,360 --> 00:32:27,279


972
00:32:27,279 --> 00:32:30,240
습니까?  나는 당신

973
00:32:30,240 --> 00:32:31,840
이 이것을 후회와 강화 학습에 대한 소개를 여기에 넣은 것

974
00:32:31,840 --> 00:32:33,600


975
00:32:33,600 --> 00:32:33,919


976
00:32:33,919 --> 00:32:37,039


977
00:32:37,039 --> 00:32:38,320


978
00:32:38,320 --> 00:32:40,080


979
00:32:40,080 --> 00:32:40,960


980
00:32:40,960 --> 00:32:43,679


981
00:32:43,679 --> 00:32:45,519
같아요  당신이 할 수 있는 좋은

982
00:32:45,519 --> 00:32:46,320


983
00:32:46,320 --> 00:32:48,159
일과 실제 성능 그리고

984
00:32:48,159 --> 00:32:50,320
여기 이 작은 이미지에서 볼 수 있습니다.

985
00:32:50,320 --> 00:32:52,880
음 당신은 최선의 정책이 빨간 점선이라는 것을 알 수 있습니다.

986
00:32:52,880 --> 00:32:54,559
그리고

987
00:32:54,559 --> 00:32:55,600
나서 에이전트가

988
00:32:55,600 --> 00:32:58,799
이것을 선택하는 것은 l입니다  대수 성능

989
00:32:58,799 --> 00:33:01,039
과 마찬가지로 대수 후회 및 그래서

990
00:33:01,039 --> 00:33:02,799
그들은 아이디어

991
00:33:02,799 --> 00:33:04,080
를 수렴하고

992
00:33:04,080 --> 00:33:06,720
있습니다. 이전 결정을 기반으로 가능한 최상의 정책으로 수렴하는 것입니다.

993
00:33:06,720 --> 00:33:07,600
바로

994
00:33:07,600 --> 00:33:10,320
um을 탐색하는 것입니다. 그런 다음

995
00:33:10,320 --> 00:33:11,519
여기 작성자

996
00:33:11,519 --> 00:33:13,360
는 고정된 도적을 볼 때 후회를 사용합니다.

997
00:33:13,360 --> 00:33:14,880


998
00:33:14,880 --> 00:33:16,240
그들은 성능의 척도로 후회를 사용

999
00:33:16,240 --> 00:33:18,559
하지만 전환하는 도적을 볼 때 후회율을 사용

1000
00:33:18,559 --> 00:33:20,159


1001
00:33:20,159 --> 00:33:22,320
하므로 후회율은

1002
00:33:22,320 --> 00:33:23,039


1003
00:33:23,039 --> 00:33:25,039
시간이 지남에 따라 후회할뿐이며

1004
00:33:25,039 --> 00:33:26,399


1005
00:33:26,399 --> 00:33:28,000
더 나은 추정기로 설명 된 비율을 사용합니다.

1006
00:33:28,000 --> 00:33:29,440


1007
00:33:29,440 --> 00:33:33,279
동적 사례에서 이 대수적 후회의

1008
00:33:33,279 --> 00:33:37,360
굉장하고 후회의 큰 아이디어는

1009
00:33:37,360 --> 00:33:40,399
당신의 역사를 되돌아보는

1010
00:33:40,399 --> 00:33:42,240
것이므로 고정 문제에

1011
00:33:42,240 --> 00:33:44,240
정말 잘 적용되는 누적 후회인 모든 역사

1012
00:33:44,240 --> 00:33:46,000


1013
00:33:46,000 --> 00:33:49,279
또는 동적 사례에 잘 적용되는 최근 역사

1014
00:33:49,279 --> 00:33:50,720


1015
00:33:50,720 --> 00:33:52,080
에 대해  상황은 항상 변화하고

1016
00:33:52,080 --> 00:33:53,840
있습니다 당신은 항상 원하지 않는 것보다 최근에 얼마나 잘하고 있는지에 더 관심

1017
00:33:53,840 --> 00:33:54,159


1018
00:33:54,159 --> 00:33:57,600


1019
00:33:57,600 --> 00:33:59,279
이 있습니다.

1020
00:33:59,279 --> 00:34:00,960


1021
00:34:00,960 --> 00:34:03,279


1022
00:34:03,279 --> 00:34:04,159


1023
00:34:04,159 --> 00:34:05,440


1024
00:34:05,440 --> 00:34:07,120


1025
00:34:07,120 --> 00:34:09,119


1026
00:34:09,119 --> 00:34:09,918
이러한 방식으로 하지 않을 경우 발생할 수 있는 다른 시대의 후회를 줄이기 위해 지금 전략을 적용하고 싶지 않기

1027
00:34:09,918 --> 00:34:11,839
때문에 초기 변동이 누적 가치에 역할을

1028
00:34:11,839 --> 00:34:13,359
합니다.

1029
00:34:13,359 --> 00:34:16,000
고정된 사례에 대한 누적 후회 또는

1030
00:34:16,000 --> 00:34:18,639
동적 사례에 대한 최근 기록

1031
00:34:18,639 --> 00:34:21,199
의 전략을 업데이트하여 해당 전략

1032
00:34:21,199 --> 00:34:23,359
을 계속 플레이함으로써 xero에 대한 후회를 최소화

1033
00:34:23,359 --> 00:34:26,079


1034
00:34:26,079 --> 00:34:26,800


1035
00:34:26,800 --> 00:34:30,000
하여 비트코인 가격을 되돌아보면 어떤 전  

1036
00:34:30,000 --> 00:34:31,199
이 

1037
00:34:31,199 --> 00:34:34,480
회가 없었을 것인지 알 수 있습니다.  큰 

1038
00:34:34,480 --> 00:34:36,800
질문인지

1039
00:34:36,800 --> 00:34:39,119
아니면 마지막 시간

1040
00:34:39,119 --> 00:34:42,159
에 제가 최근에 알게 된 사실을 감안할 때

1041
00:34:42,159 --> 00:34:44,399
후회율

1042
00:34:44,399 --> 00:34:48,000
증가를 가능한

1043
00:34:48,000 --> 00:34:50,320
한 낮추는 방법을 찾아낸 후 되돌아보고

1044
00:34:50,320 --> 00:34:51,359


1045
00:34:51,359 --> 00:34:54,719
당신이 어떻게 수행할 수 있었는지에 대해 낙관적으로 생각하는 방법입니다.

1046
00:34:54,719 --> 00:34:57,359
후회를 0으로 줄임으로써 우리

1047
00:34:57,359 --> 00:34:57,760


1048
00:34:57,760 --> 00:34:59,920
는 컴퓨터 과학에서 항상 이것을 볼

1049
00:34:59,920 --> 00:35:01,200


1050
00:35:01,200 --> 00:35:03,200
수 있습니다. 무언가를 최대화하는 것과 같이 거기

1051
00:35:03,200 --> 00:35:04,880
에 부정적인 요소가 끼어 있는지

1052
00:35:04,880 --> 00:35:07,359
여부를 최소화하여 하는 것입니다.  여기에 던져진 자연 로그

1053
00:35:07,359 --> 00:35:08,560
가 있습니다.

1054
00:35:08,560 --> 00:35:10,640
또는 그것이 1보다 1인지 아니면 여러 번

1055
00:35:10,640 --> 00:35:12,240
반대 방향으로 프레임이 지정

1056
00:35:12,240 --> 00:35:13,760
되었는지 여부를 알 수 있습니다. 만약 당신이 당신이 0에 경계를 두고 있다는 것을 안다면

1057
00:35:13,760 --> 00:35:15,760
무언가가 0 아래로 갈 수 없다는 것을 알고

1058
00:35:15,760 --> 00:35:16,560


1059
00:35:16,560 --> 00:35:19,280
있다면 당신은 최대한 낮게 가고 싶습니다  가능

1060
00:35:19,280 --> 00:35:19,920
하거나

1061
00:35:19,920 --> 00:35:21,760
무언가를 최대화하고 싶다면

1062
00:35:21,760 --> 00:35:23,839
때때로

1063
00:35:23,839 --> 00:35:25,359
최대값보다 하나를 더 한 다음 그 숫자

1064
00:35:25,359 --> 00:35:26,400
를 0으로

1065
00:35:26,400 --> 00:35:28,560
만드는 것이 좋습니다.

1066
00:35:28,560 --> 00:35:30,960


1067
00:35:30,960 --> 00:35:32,560


1068
00:35:32,560 --> 00:35:35,520
가장 가까운 숫자가 없기

1069
00:35:35,520 --> 00:35:37,200
때문에 학습을 후회하고 그것이

1070
00:35:37,200 --> 00:35:38,960
그들이 수행을 계산하는 방법입니다

1071
00:35:38,960 --> 00:35:41,119


1072
00:35:41,119 --> 00:35:44,400
능동적 추론을 시작하겠습니다. 따라서

1073
00:35:44,400 --> 00:35:45,200


1074
00:35:45,200 --> 00:35:46,960
이 슬라이드에서

1075
00:35:46,960 --> 00:35:48,400
바로 볼 수

1076
00:35:48,400 --> 00:35:51,920
있는 한 가지는 감각 운동을 보고 있지 않다는 것입니다.  루프 우리는

1077
00:35:51,920 --> 00:35:54,720
화살표와

1078
00:35:54,720 --> 00:35:56,160
노드

1079
00:35:56,160 --> 00:35:57,839
가 있는 환경

1080
00:35:57,839 --> 00:35:59,520
에서 에이전트를

1081
00:35:59,520 --> 00:36:00,400


1082
00:36:00,400 --> 00:36:03,920


1083
00:36:03,920 --> 00:36:05,200
볼 수

1084
00:36:05,200 --> 00:36:09,680
없습니다  전자적 추론

1085
00:36:09,680 --> 00:36:12,320
그들은 탐사

1086
00:36:12,320 --> 00:36:14,320
이용 트레이드오프가 환경의 숨겨진 속성에 대한 예상 및 예상치 못한 불확실성

1087
00:36:14,320 --> 00:36:16,160


1088
00:36:16,160 --> 00:36:19,280
을 해결하는 것을 목표로 하는 선택이 있는 불확실성 감소 문제로 공식화될 수 있다고 씁니다.

1089
00:36:19,280 --> 00:36:20,800


1090
00:36:20,800 --> 00:36:22,640


1091
00:36:22,640 --> 00:36:24,640
그래서 이미 우리는

1092
00:36:24,640 --> 00:36:26,640
능동적 추론 공식화

1093
00:36:26,640 --> 00:36:28,160
에 숨겨진 상태가 있음을 보고 있습니다

1094
00:36:28,160 --> 00:36:30,079
우리가 직접 접근할 수는

1095
00:36:30,079 --> 00:36:32,640
없지만 결정으로부터 승인된 결과를 얻는 환경

1096
00:36:32,640 --> 00:36:34,320


1097
00:36:34,320 --> 00:36:36,320
이것은 능동 추론으로 표현되는 확률론적 추론 문제인 추론으로 선택 행동

1098
00:36:36,320 --> 00:36:37,440
및 계획

1099
00:36:37,440 --> 00:36:39,839
계획으로 이어집니다.

1100
00:36:39,839 --> 00:36:42,079


1101
00:36:42,079 --> 00:36:44,800
따라서

1102
00:36:44,800 --> 00:36:45,359
행동

1103
00:36:45,359 --> 00:36:47,920
과 추론은 우리가

1104
00:36:47,920 --> 00:36:49,839
어떤 행동에 대해

1105
00:36:49,839 --> 00:36:51,440


1106
00:36:51,440 --> 00:36:52,640
우리가

1107
00:36:52,640 --> 00:36:55,839
이 접근 방식을 사용하여 감각 데이터를 수신하는 결과를 고려할 때 세계의 숨겨진 상태에 대해 계획하고

1108
00:36:55,839 --> 00:36:58,240


1109
00:36:58,240 --> 00:37:00,079


1110
00:37:00,079 --> 00:37:03,119
능동적인 추론에서 자연스럽게 나타나는 다양한 유형의 착취 및 탐색적 행동

1111
00:37:03,119 --> 00:37:04,800
결정 전략

1112
00:37:04,800 --> 00:37:08,079
행동 정책은

1113
00:37:08,079 --> 00:37:09,680
단일 최적화

1114
00:37:09,680 --> 00:37:12,480
원칙을 기반으로 선택되거나 어제  나는 그것이라고 생각한다

1115
00:37:12,480 --> 00:37:14,320


1116
00:37:14,320 --> 00:37:15,920
기능적 공통 기능 기반

1117
00:37:15,920 --> 00:37:18,160
또는 단일 최적화

1118
00:37:18,160 --> 00:37:19,119
원칙

1119
00:37:19,119 --> 00:37:21,680
은 예상되는 자유 에너지인 관찰된 미래 결과에 대해 예상되는 놀라움을 최소화하는 것이므로

1120
00:37:21,680 --> 00:37:23,680


1121
00:37:23,680 --> 00:37:26,560


1122
00:37:26,560 --> 00:37:27,920


1123
00:37:27,920 --> 00:37:30,960
거꾸로 보는 접근 방식과

1124
00:37:30,960 --> 00:37:34,160
같이 멋진 방법은 후회를 최소화하는

1125
00:37:34,160 --> 00:37:37,280
것입니다.  나는

1126
00:37:37,280 --> 00:37:39,599
과거에 대해 내가 아는 바를 감안할 때

1127
00:37:39,599 --> 00:37:40,400


1128
00:37:40,400 --> 00:37:43,520
현재 내가 행동하는 방식을 어떻게 바꾸고 자유

1129
00:37:43,520 --> 00:37:46,480
에너지 최소화

1130
00:37:46,480 --> 00:37:48,880
현재와 미래 순간

1131
00:37:48,880 --> 00:37:49,599


1132
00:37:49,599 --> 00:37:52,880
에 예상되는 자유 에너지는 현재 내 모델의 상태

1133
00:37:52,880 --> 00:37:55,040
와 앞으로 어떻게 나아가는지에 대해 최선을 다했습니다.

1134
00:37:55,040 --> 00:37:56,720


1135
00:37:56,720 --> 00:37:59,280
후회는 기대하는 것이 아니기 때문에 기대되는 자유 에너지를 최소화 할 수 있습니까?

1136
00:37:59,280 --> 00:38:01,599
후회는 돌아

1137
00:38:01,599 --> 00:38:03,280
보기만하기 때문에 훈련하기가 정말

1138
00:38:03,280 --> 00:38:05,200
쉽고 여기

1139
00:38:05,200 --> 00:38:06,480
에 기대

1140
00:38:06,480 --> 00:38:07,920
되는 것이 있습니다.

1141
00:38:07,920 --> 00:38:10,560


1142
00:38:10,560 --> 00:38:13,200


1143
00:38:13,200 --> 00:38:14,079
학습

1144
00:38:14,079 --> 00:38:16,839
및 그 다음 예상 자유 에너지

1145
00:38:16,839 --> 00:38:18,320
최소화

1146
00:38:18,320 --> 00:38:20,079
가 여기에서 능동 추론을 구성하는 방법입니다.

1147
00:38:20,079 --> 00:38:22,320
일반적인 의견이나

1148
00:38:22,320 --> 00:38:24,800
그것에 대해 어떤 점이 멋있었다고 생각하나요?

1149
00:38:24,800 --> 00:38:27,280
그래서 저는 우리가 예전에 했던 Alex Chanse의 논문처럼 생각하고 있어요. 제 생각

1150
00:38:27,280 --> 00:38:29,280


1151
00:38:29,280 --> 00:38:30,720
에는 그게 8번이었던 것 같아요. 하지만

1152
00:38:30,720 --> 00:38:32,800
음, 저는 여전히 항상 그때로 돌아

1153
00:38:32,800 --> 00:38:34,480
가요  이 계산

1154
00:38:34,480 --> 00:38:36,000
프레임워크를 보면 그는

1155
00:38:36,000 --> 00:38:36,800


1156
00:38:36,800 --> 00:38:39,440
보상처럼 실용적인 가치

1157
00:38:39,440 --> 00:38:41,200
를 아주 멋지게 나누었습니다. 이

1158
00:38:41,200 --> 00:38:43,599
경우 후회를 최소화하는

1159
00:38:43,599 --> 00:38:45,119
것은 실용적인 가치나 보상으로 볼 수

1160
00:38:45,119 --> 00:38:46,000


1161
00:38:46,000 --> 00:38:48,880
있고 그 다음에는 인식적 가치로 볼 수 있습니다. 그래서

1162
00:38:48,880 --> 00:38:50,240
당신은  이 두 가지가 모두

1163
00:38:50,240 --> 00:38:51,040


1164
00:38:51,040 --> 00:38:54,079
시스템에 도움이 되는 방법을 시스템에 제공하는 데 도움이

1165
00:38:54,079 --> 00:38:55,280
되는 에이전트

1166
00:38:55,280 --> 00:38:58,320
가 시스템과 관련된 멋진 업데이트를 제공하는 데 도움이

1167
00:38:58,320 --> 00:38:59,440


1168
00:38:59,440 --> 00:39:01,599
됩니다. 저자가

1169
00:39:01,599 --> 00:39:03,440
능동적 추론을 연구하고 알고리즘에

1170
00:39:03,440 --> 00:39:05,440
접근하여 베이지안 의사 결정에 접근했다면 저자의 의견

1171
00:39:05,440 --> 00:39:05,839


1172
00:39:05,839 --> 00:39:09,119
을 기대하겠습니다.

1173
00:39:09,119 --> 00:39:10,960
비활성 추론 컴퓨터 과학

1174
00:39:10,960 --> 00:39:12,079
배경

1175
00:39:12,079 --> 00:39:13,599


1176
00:39:13,599 --> 00:39:15,599
에서 흥미로운 것으로

1177
00:39:15,599 --> 00:39:19,440
능동적

1178
00:39:20,480 --> 00:39:22,320
추론을 발견했습니다.  능동

1179
00:39:22,320 --> 00:39:23,680
추론을 통해

1180
00:39:23,680 --> 00:39:26,800
그들은 근사

1181
00:39:26,800 --> 00:39:28,320


1182
00:39:28,320 --> 00:39:30,320
능동 추론으로 바뀌었고 초기 형태의 능동 추론은 일반적인 기계 학습 문제에 대한 적용을 고려하지 않고

1183
00:39:30,320 --> 00:39:32,800
작은 상태 공간과 장난감

1184
00:39:32,800 --> 00:39:33,520
문제

1185
00:39:33,520 --> 00:39:35,520
를 위해 개발되었다고 설명했습니다.

1186
00:39:35,520 --> 00:39:36,960


1187
00:39:36,960 --> 00:39:39,119


1188
00:39:39,119 --> 00:39:41,440
2 x 2 매트릭스

1189
00:39:41,440 --> 00:39:42,800
와 2개의 결과가 세상에

1190
00:39:42,800 --> 00:39:46,000
있고 이것이 할 수 있는 두 가지 결정이

1191
00:39:46,000 --> 00:39:47,359
최근에 변경

1192
00:39:47,359 --> 00:39:49,280
되었고 다양한 확장 가능한 솔루션이 제안되었습니다.

1193
00:39:49,280 --> 00:39:50,960
저는 이러한 인용 중 하나가

1194
00:39:50,960 --> 00:39:51,599


1195
00:39:51,599 --> 00:39:53,920
기회

1196
00:39:53,920 --> 00:39:56,079


1197
00:39:56,079 --> 00:39:58,800
가 될 것이라고 생각합니다.  복잡한 순차 정책

1198
00:39:58,800 --> 00:39:59,920


1199
00:39:59,920 --> 00:40:01,839
최적화는 정교한 심층 트리

1200
00:40:01,839 --> 00:40:04,400
검색을 포함하므로

1201
00:40:04,400 --> 00:40:06,720
이러한 트리 롤아웃을 사용한 정교한 능동 추론과

1202
00:40:06,720 --> 00:40:10,160
트리 프루닝 접근 방식

1203
00:40:10,160 --> 00:40:12,160
을 통해 능동 추론

1204
00:40:12,160 --> 00:40:13,280
접근 방식을 실용

1205
00:40:13,280 --> 00:40:15,119
적이고 머신 러닝

1206
00:40:15,119 --> 00:40:16,880
에서 일반적으로 사용되는 고차원 산적 문제에 확장할 수 있도록 합니다.

1207
00:40:16,880 --> 00:40:17,839


1208
00:40:17,839 --> 00:40:19,920
교류  tive

1209
00:40:19,920 --> 00:40:21,920
추론 알고리즘

1210
00:40:21,920 --> 00:40:23,839


1211
00:40:23,839 --> 00:40:25,520


1212
00:40:25,520 --> 00:40:28,640
은 우리가 근사할

1213
00:40:28,640 --> 00:40:30,400
수 있는 다른 것을 정확히 근사

1214
00:40:30,400 --> 00:40:32,640
하고 여전히 활성 추론을 갖고

1215
00:40:32,640 --> 00:40:35,040
있거나 근사할 수 없는 것과 같은 저자의 말을 들으면 확실히 멋질 것입니다.

1216
00:40:35,040 --> 00:40:37,520
하지만 활성 추론을 근사화한 방법과 이유를 살펴보겠습니다.

1217
00:40:37,520 --> 00:40:40,720


1218
00:40:40,720 --> 00:40:43,599


1219
00:40:43,599 --> 00:40:45,200
당신과 내가 왜 당신과 내가 둘 다 했는지 이야기

1220
00:40:45,200 --> 00:40:45,599


1221
00:40:45,599 --> 00:40:47,920
하자면, 당신

1222
00:40:47,920 --> 00:40:49,839
은 트리 전환과 노드 전환에서 계통 발생학의 관점에서 트리 구성을 알고

1223
00:40:49,839 --> 00:40:51,440


1224
00:40:51,440 --> 00:40:53,280


1225
00:40:53,280 --> 00:40:54,560


1226
00:40:54,560 --> 00:40:56,640
있으며 며칠 동안 실행할 수 있는 것처럼 계산적으로 압도적일 수 있습니다.  그리고 날과 날

1227
00:40:56,640 --> 00:40:58,800
이 그렇습니다. 여기에서 근사

1228
00:40:58,800 --> 00:41:00,720
의 달콤하고 깔끔한 구현을 보는 것이 정말 좋습니다.

1229
00:41:00,720 --> 00:41:03,200


1230
00:41:03,200 --> 00:41:06,240
예, 여기

1231
00:41:06,240 --> 00:41:09,359
에서는 형식주의 16과 17에 대해 깊이 들어가지 않을

1232
00:41:09,359 --> 00:41:11,680
것이지만

1233
00:41:11,680 --> 00:41:13,680
저자가 설명하기를 기대합니다.

1234
00:41:13,680 --> 00:41:17,200
하지만 여기  핵심 부분

1235
00:41:17,200 --> 00:41:19,520
보상 확률에 대한 정확한 한계 사후 신념

1236
00:41:19,520 --> 00:41:21,839


1237
00:41:21,839 --> 00:41:25,200
ta는 이런 식으로 표현될 수 있습니다.

1238
00:41:25,200 --> 00:41:27,119
괜찮습니다.

1239
00:41:27,119 --> 00:41:29,119


1240
00:41:29,119 --> 00:41:32,319
n 그것이 우리

1241
00:41:32,319 --> 00:41:33,520
가 해결

1242
00:41:33,520 --> 00:41:36,640
해야 하는 것이므로

1243
00:41:36,640 --> 00:41:38,960
보상에 대한 정확한 정확한 믿음

1244
00:41:38,960 --> 00:41:40,640
이 이런 식

1245
00:41:40,640 --> 00:41:42,240
으로 보일 것이고 방정식 17의 정확한 한계 사후값을

1246
00:41:42,240 --> 00:41:44,640


1247
00:41:44,640 --> 00:41:46,800


1248
00:41:46,800 --> 00:41:48,880
작성하면 베타 분포에 속하지 않을 것이므로 정확한 추론을 분석적으로 다루기 어렵게 만듭니다.

1249
00:41:48,880 --> 00:41:50,240


1250
00:41:50,240 --> 00:41:53,280
수치적으로

1251
00:41:53,280 --> 00:41:56,000
접근하여 시뮬레이션하거나 계산하는 방법일

1252
00:41:56,000 --> 00:41:56,640


1253
00:41:56,640 --> 00:41:58,000
수 있지만 빅

1254
00:41:58,000 --> 00:41:59,760
데이터 세트를 살펴보고

1255
00:41:59,760 --> 00:42:01,680
엄청난 양의 계산

1256
00:42:01,680 --> 00:42:04,000
노력 없이 빠르게 수행하려면 다른 방법이 필요

1257
00:42:04,000 --> 00:42:07,280


1258
00:42:07,280 --> 00:42:09,359
합니다.  대략적인

1259
00:42:09,359 --> 00:42:11,200
완전 인수분해 형식

1260
00:42:11,200 --> 00:42:13,680
이고 우리

1261
00:42:13,680 --> 00:42:16,800
는 변수 인수분해

1262
00:42:16,800 --> 00:42:18,000
가 일종의

1263
00:42:18,000 --> 00:42:21,280
큰 주제이기 전에 변수 인수분해를 보았

1264
00:42:21,280 --> 00:42:22,560


1265
00:42:22,560 --> 00:42:24,400
으므로 여기서 다시 자세히

1266
00:42:24,400 --> 00:42:26,000
설명하지

1267
00:42:26,000 --> 00:42:27,920
않을 것입니다.  인수 분해

1268
00:42:27,920 --> 00:42:31,119
하지만 그것에 대해 생각하는 한 가지 방법

1269
00:42:31,119 --> 00:42:34,079
은 큰 개방형 긴

1270
00:42:34,079 --> 00:42:35,119
방정식

1271
00:42:35,119 --> 00:42:37,839
을 인수 분해 가능한 형식으로 제한하면

1272
00:42:37,839 --> 00:42:38,800
솔루션 공간이 감소한다는 것입니다

1273
00:42:38,800 --> 00:42:42,000
.  많은 종류의

1274
00:42:42,000 --> 00:42:44,800
최적화를 다루기 쉽게 만들 수 있으므로 예를

1275
00:42:44,800 --> 00:42:45,359


1276
00:42:45,359 --> 00:42:47,760
들어 선형 회귀의 경우 최소

1277
00:42:47,760 --> 00:42:48,880


1278
00:42:48,880 --> 00:42:50,800
제곱이 있습니다

1279
00:42:50,800 --> 00:42:52,880


1280
00:42:52,880 --> 00:42:54,640


1281
00:42:54,640 --> 00:42:56,720
.

1282
00:42:56,720 --> 00:42:58,000
다른 함수의 합이지만 이 함수를

1283
00:42:58,000 --> 00:42:59,359
해결하려고

1284
00:42:59,359 --> 00:43:02,880
하면 정말 잘 확장되는 계산

1285
00:43:02,880 --> 00:43:03,920


1286
00:43:03,920 --> 00:43:05,520
이 있으므로 인수분해가 발생하고

1287
00:43:05,520 --> 00:43:07,599
인수분해에 대해 생각하는 또 다른 방법

1288
00:43:07,599 --> 00:43:08,960


1289
00:43:08,960 --> 00:43:11,280


1290
00:43:11,280 --> 00:43:13,040
은 노드가 있는 베이지안 그래프가 있는 경우입니다.  변수

1291
00:43:13,040 --> 00:43:14,400
와 모서리는

1292
00:43:14,400 --> 00:43:16,960
변수 간의 관계와 같습니다.

1293
00:43:16,960 --> 00:43:19,280
모든 모서리를

1294
00:43:19,280 --> 00:43:20,800
매개변수 피팅 프레임워크

1295
00:43:20,800 --> 00:43:23,119
에 덤프할 수 있습니다. 가능한 모든 모서리

1296
00:43:23,119 --> 00:43:24,960
는 인수분해되지 않은 모델과 같으

1297
00:43:24,960 --> 00:43:27,200
므로 정확한 값을 파악해야 하는 모서리의 수입니다.

1298
00:43:27,200 --> 00:43:28,560


1299
00:43:28,560 --> 00:43:31,920
많은 것이 될 것이고

1300
00:43:31,920 --> 00:43:33,520


1301
00:43:33,520 --> 00:43:34,800
맞추려는 매개변수의 양에 따라 기하급수적으로 증가

1302
00:43:34,800 --> 00:43:35,680


1303
00:43:35,680 --> 00:43:38,240
할

1304
00:43:38,240 --> 00:43:39,119


1305
00:43:39,119 --> 00:43:41,599
것입니다.  b 및 b

1306
00:43:41,599 --> 00:43:42,880
와 연관된 것은 c와만 연관되어

1307
00:43:42,880 --> 00:43:45,200
있고 갑자기

1308
00:43:45,200 --> 00:43:47,599
맞춰야 하는 모서리의 양을 줄여서

1309
00:43:47,599 --> 00:43:50,720


1310
00:43:50,720 --> 00:43:54,000
매력적으로 도달했지만 대략적으로 정확한 솔루션에 도달하는 데 도움이 됩니다.

1311
00:43:54,000 --> 00:43:54,880


1312
00:43:54,880 --> 00:43:57,280


1313
00:43:57,280 --> 00:43:59,760
대략적으로 정확

1314
00:43:59,760 --> 00:44:02,960
하고 근사한 베이지안 계산이지만

1315
00:44:02,960 --> 00:44:05,359
여기에서 인수분해

1316
00:44:05,359 --> 00:44:06,560


1317
00:44:06,560 --> 00:44:10,079
가 너무 자세히 설명되지 않는다는 것을 몇 번

1318
00:44:10,079 --> 00:44:13,040
보았지만 그들이 하는 일은 이

1319
00:44:13,040 --> 00:44:15,359
인수분해된 형식

1320
00:44:15,359 --> 00:44:18,319
을 취하고 변형 미적분을 사용

1321
00:44:18,319 --> 00:44:19,520
하여 다음

1322
00:44:19,520 --> 00:44:21,680
변형 미소 규칙을 복구하는 것입니다.  잠시 후 로 이동

1323
00:44:21,680 --> 00:44:23,280


1324
00:44:23,280 --> 00:44:24,960
하여 그들은 다른 형식의 집합에 도달하게 됩니다.

1325
00:44:24,960 --> 00:44:27,119
우리는 작성자로부터

1326
00:44:27,119 --> 00:44:27,520


1327
00:44:27,520 --> 00:44:30,319
이러한 형식의 차이점에 대해 듣게 될

1328
00:44:30,319 --> 00:44:30,880


1329
00:44:30,880 --> 00:44:34,400
것입니다. 그런 다음 멋진 점은

1330
00:44:34,400 --> 00:44:35,599
고정 적기

1331
00:44:35,599 --> 00:44:38,800
에 대해 매개변수를 다음과 같이 변경할 수 있다는

1332
00:44:38,800 --> 00:44:42,560
것입니다.  변화율에 대해 0은

1333
00:44:42,560 --> 00:44:44,480


1334
00:44:44,480 --> 00:44:46,160
고정된 베르누이 산적 문제에 대한 정확한 베이징 추론에

1335
00:44:46,160 --> 00:44:47,760


1336
00:44:47,760 --> 00:44:50,000
해당하므로

1337
00:44:50,000 --> 00:44:50,960
ex가 어떻게

1338
00:44:50,960 --> 00:44:54,640
알고리즘 솔루션의 행위 형태는

1339
00:44:54,640 --> 00:44:57,359
어 얼마나 적극적인 추론이 점근선에서 정확한 일을 할 수 있는지 알 수 있습니다

1340
00:44:57,359 --> 00:44:57,760


1341
00:44:57,760 --> 00:45:01,040


1342
00:45:01,040 --> 00:45:04,560
미소란 무엇입니까? 스마일 페이퍼

1343
00:45:04,560 --> 00:45:06,480
변형 방법은

1344
00:45:06,480 --> 00:45:08,560
놀라움으로 최소화 학습

1345
00:45:08,560 --> 00:45:10,079
을 위한 상으로 우리가 변형 방법으로 하는 많은 일처럼 들립니다

1346
00:45:10,079 --> 00:45:11,839


1347
00:45:11,839 --> 00:45:13,200
변형  기본

1348
00:45:13,200 --> 00:45:16,079
및 놀라움 최소화 및 의사

1349
00:45:16,079 --> 00:45:16,560
코드

1350
00:45:16,560 --> 00:45:18,560
는 지수 패밀리에 대해 여기에 표시됩니다.

1351
00:45:18,560 --> 00:45:20,319


1352
00:45:20,319 --> 00:45:22,560
이것은 작성자에 대한 질문일 뿐입니다.

1353
00:45:22,560 --> 00:45:24,160
미소는

1354
00:45:24,160 --> 00:45:26,880
무엇을 하고 있습니까? 이것이 능동 추론을 근사화하는 데 어떻게 도움이 됩니까

1355
00:45:26,880 --> 00:45:28,480


1356
00:45:28,480 --> 00:45:32,000
? 미소를 사용할 수 있는 또 다른

1357
00:45:32,000 --> 00:45:33,839
이유는 이것이 근사 능동

1358
00:45:33,839 --> 00:45:35,440
추론입니다.  중간에

1359
00:45:35,440 --> 00:45:38,880
그들은 큰 지저분한 형태를 취합니다.

1360
00:45:38,880 --> 00:45:41,280
그런 다음 변수

1361
00:45:41,280 --> 00:45:43,920
가 서로 관련될 수 있는 방법을 제한

1362
00:45:43,920 --> 00:45:45,839
하고 인수분해된 표현에 대한 변형 방법을 사용하여

1363
00:45:45,839 --> 00:45:48,640


1364
00:45:48,640 --> 00:45:52,560
효과적인 근사치를 얻을 수

1365
00:45:52,560 --> 00:45:55,759


1366
00:45:56,480 --> 00:45:58,800
있으므로 음, 이 직접적인 대응이 있다는 것을 알고 있다는 것이 흥미롭습니다.

1367
00:45:58,800 --> 00:46:00,000


1368
00:46:00,000 --> 00:46:02,319
고정식 uh

1369
00:46:02,319 --> 00:46:03,760
bandit

1370
00:46:03,760 --> 00:46:05,920
케이스의 경우 고정식 케이스 l에 있기 때문에

1371
00:46:05,920 --> 00:46:07,040
우리는 왜

1372
00:46:07,040 --> 00:46:08,720
옳은지 완전히 설명하는 능동 추론 알고리즘을 사용하여 개선을 보지 못했습니다.

1373
00:46:08,720 --> 00:46:10,240


1374
00:46:10,240 --> 00:46:12,880


1375
00:46:12,880 --> 00:46:14,640
네, 거기에 몇 가지 더 많은 부분이 있습니다.

1376
00:46:14,640 --> 00:46:16,319
어

1377
00:46:16,319 --> 00:46:19,680
더 큰 그림 4 또는 그와 비슷한

1378
00:46:19,680 --> 00:46:20,560
것이

1379
00:46:20,560 --> 00:46:24,560
좋습니다.

1380
00:46:24,560 --> 00:46:26,720
그들이 다루는 두 가지 문제로 이동하고  그런 다음

1381
00:46:26,720 --> 00:46:28,000
이 두 섹션에 대한 결과

1382
00:46:28,000 --> 00:46:29,920
이므로 먼저 고정

1383
00:46:29,920 --> 00:46:32,720
적기를 다루고 그 다음 동적 적기를 다룰

1384
00:46:32,720 --> 00:46:34,880
것이므로 여기에 정의와

1385
00:46:34,880 --> 00:46:36,800


1386
00:46:36,800 --> 00:46:39,280
고정

1387
00:46:39,280 --> 00:46:42,800
적기가 유한한 수의 팔을 가지도록 고정 적기를 통해 작동하는 위치가 있습니다.

1388
00:46:42,800 --> 00:46:46,800


1389
00:46:46,800 --> 00:46:49,599
그런 다음

1390
00:46:49,599 --> 00:46:50,000


1391
00:46:50,000 --> 00:46:53,359
t개의 시간 단계를 거쳐 재생될 것입니다. 그런 다음 큰 k개의

1392
00:46:53,359 --> 00:46:56,720
큰 k 암이고 각 작은 작은 k

1393
00:46:56,720 --> 00:46:59,440
k는 작은 팔의 집합입니다. 작은 k

1394
00:46:59,440 --> 00:47:02,480
예 k는 동작

1395
00:47:03,520 --> 00:47:05,119
이므로 여기에서 고정 적기를 정의하는 방법

1396
00:47:05,119 --> 00:47:07,119


1397
00:47:07,119 --> 00:47:09,200
이 있습니다. 다시 생각할 수 있습니다.  t 및 시간

1398
00:47:09,200 --> 00:47:10,240
동작

1399
00:47:10,240 --> 00:47:13,359
및 uh 팔에 대해 그리고 고정된

1400
00:47:13,359 --> 00:47:15,920
도적에서 보상 확률 ta

1401
00:47:15,920 --> 00:47:18,640
sub k는 모든 시도에 대해 고정되어 있으므로

1402
00:47:18,640 --> 00:47:19,760
ta는 재미

1403
00:47:19,760 --> 00:47:21,280


1404
00:47:21,280 --> 00:47:22,960
있습니다.  변수처럼

1405
00:47:22,960 --> 00:47:24,800
때로는 많은 사람들이 그럴 것이라고 생각하지만

1406
00:47:24,800 --> 00:47:26,559
데이터는

1407
00:47:26,559 --> 00:47:30,800
특히 고정 보상

1408
00:47:30,800 --> 00:47:33,520
값 고정 예 보상 확률이므로

1409
00:47:33,520 --> 00:47:35,839


1410
00:47:35,839 --> 00:47:38,079
카지노에서 고정되지 않은 이유

1411
00:47:38,079 --> 00:47:39,040


1412
00:47:39,040 --> 00:47:41,359
중 하나는 평균 1:1로 um을 지불하는 것과 같을 것입니다.

1413
00:47:41,359 --> 00:47:42,960
하나는 50%를 지불하고 하나는

1414
00:47:42,960 --> 00:47:46,240
200%를 지불하지만 절대 변하지 않습니다.

1415
00:47:46,240 --> 00:47:47,440
그래서 여기에 다중 무기가 있는 것을 시각적으로

1416
00:47:47,440 --> 00:47:50,079
표현한 것입니다. 그런

1417
00:47:50,079 --> 00:47:52,640
다음

1418
00:47:52,640 --> 00:47:54,960
마우스가 치즈를

1419
00:47:54,960 --> 00:47:57,280
얻고 각 팔은 고정

1420
00:47:57,280 --> 00:47:58,240
확률이

1421
00:47:58,240 --> 00:47:59,599
다르지만 그렇지 않습니다.

1422
00:47:59,599 --> 00:48:01,520
치즈의 확률이

1423
00:48:01,520 --> 00:48:06,480
움직이지 않도록 변경하지 마십시오.

1424
00:48:06,480 --> 00:48:10,800
여기 그림 1에서

1425
00:48:10,800 --> 00:48:14,319
우리는 후회율 분석을 볼

1426
00:48:14,319 --> 00:48:18,240
것이므로 상상할 수 있는 후회율

1427
00:48:18,240 --> 00:48:20,400
은 어 우리가 두 번째에 도달할 것이지만 다음 그림에 대한

1428
00:48:20,400 --> 00:48:22,240
후회율 분석  정지된

1429
00:48:22,240 --> 00:48:23,440
적기의 경우

1430
00:48:23,440 --> 00:48:25,200


1431
00:48:25,200 --> 00:48:28,000
빨간색

1432
00:48:28,000 --> 00:48:31,680
으로 표시된 대략적인 활성 추론을 파란색으로 표시된 정확한 활성 추론과 비교하여 t의 상대적인 변화가 무엇

1433
00:48:31,680 --> 00:48:33,359
인지에 대해 저자와 이야기하는 것이 좋습니다.

1434
00:48:33,359 --> 00:48:34,880


1435
00:48:34,880 --> 00:48:37,359


1436
00:48:37,359 --> 00:48:40,480
계산하는 데 시간이 걸렸을

1437
00:48:41,119 --> 00:48:44,480
때 그들이 하는

1438
00:48:44,480 --> 00:48:48,319


1439
00:48:48,319 --> 00:48:49,920
일은 파란색과 빨간색이 항상 일종의

1440
00:48:49,920 --> 00:48:51,599
함께 추적

1441
00:48:51,599 --> 00:48:53,520
된다는 것을 보여주고 있어 대략적인

1442
00:48:53,520 --> 00:48:54,960
형식

1443
00:48:54,960 --> 00:48:57,520
이 정확한 동작을 따르기 때문에 정말 좋은 일을 한다는 것을 암시합니다.

1444
00:48:57,520 --> 00:48:58,160


1445
00:48:58,160 --> 00:49:01,520
꽤 잘 형성된

1446
00:49:01,520 --> 00:49:04,240
다음 이 어 그래프를 읽는 방법에 대해 설명

1447
00:49:04,240 --> 00:49:04,800


1448
00:49:04,800 --> 00:49:08,240
하자면

1449
00:49:08,240 --> 00:49:10,960
k에 해당하는 4개의 열이 10 20 40 및 80 암과 같으

1450
00:49:10,960 --> 00:49:12,240


1451
00:49:12,240 --> 00:49:14,000
므로 암의 수만 변경되면

1452
00:49:14,000 --> 00:49:15,440


1453
00:49:15,440 --> 00:49:18,800


1454
00:49:18,800 --> 00:49:22,319
어 엡실론

1455
00:49:22,319 --> 00:49:23,760
에 대한 행이 있습니다.  이것은

1456
00:49:23,760 --> 00:49:26,079
팔 사이의 차이와

1457
00:49:26,079 --> 00:49:29,200
같아서 um 작업이 얼마나 쉬운지 알 수 있습니다.

1458
00:49:29,200 --> 00:49:32,559
그런 다음

1459
00:49:32,559 --> 00:49:35,440
포인트 1 포인트 2 5 및 포인트 4입니다.

1460
00:49:35,440 --> 00:49:35,920
그런 다음

1461
00:49:35,920 --> 00:49:38,960
각 셀

1462
00:49:38,960 --> 00:49:42,800
내에는

1463
00:49:42,800 --> 00:49:45,680
이전 선호도에 대한 정밀도의 함수인 람다가

1464
00:49:45,680 --> 00:49:47,280


1465
00:49:47,280 --> 00:49:50,559
있고 r  sub

1466
00:49:50,800 --> 00:49:53,200
t는 시행의 함수로서 후회

1467
00:49:53,200 --> 00:49:55,440


1468
00:49:55,440 --> 00:49:57,520
이고 검은색 대시 선은

1469
00:49:57,520 --> 00:49:58,960


1470
00:49:58,960 --> 00:50:00,319
임의

1471
00:50:00,319 --> 00:50:04,720
에이전트에 해당

1472
00:50:04,800 --> 00:50:10,079
하는 후회율의 상한

1473
00:50:10,640 --> 00:50:13,599
을 나타냅니다.  능동적 추론은

1474
00:50:13,599 --> 00:50:14,319


1475
00:50:14,319 --> 00:50:16,559


1476
00:50:16,559 --> 00:50:17,520


1477
00:50:17,520 --> 00:50:20,640


1478
00:50:20,640 --> 00:50:23,680


1479
00:50:23,680 --> 00:50:25,760


1480
00:50:25,760 --> 00:50:29,839
무작위로 행동하는 에이전트에 대해 누적되는 후회의

1481
00:50:29,839 --> 00:50:33,200
양인 0.1 또는 약 0.1보다 낮은 후회율로 수렴하는 것처럼

1482
00:50:33,200 --> 00:50:35,359


1483
00:50:35,359 --> 00:50:37,119
더 잘 수행됩니다.

1484
00:50:37,119 --> 00:50:38,880


1485
00:50:38,880 --> 00:50:40,640
활성 추론

1486
00:50:40,640 --> 00:50:42,559
에이전트가 매우 부정확한

1487
00:50:42,559 --> 00:50:46,079
선호도를 가질 때 람다가 0에 가까울 때 람다 매개변수가 정밀도를 나타내는

1488
00:50:46,079 --> 00:50:49,200
것이 나에게 의미가 있습니다. 람다가 탐색에 더 오래 참여하고

1489
00:50:49,200 --> 00:50:50,880


1490
00:50:50,880 --> 00:50:53,040
그런 식으로 보상을 축적하는 대신

1491
00:50:53,040 --> 00:50:54,240


1492
00:50:54,240 --> 00:50:56,079
불확실성을 줄입니다.  각주

1493
00:50:56,079 --> 00:50:58,160
거기에서

1494
00:50:58,160 --> 00:50:59,440
흥미롭고 그것은

1495
00:50:59,440 --> 00:51:02,240
우리가

1496
00:51:02,240 --> 00:51:03,920
능동적 추론과 익스플로잇 탐색을 재고하는 방법에 대해 이야기할 때 확실히 돌아올

1497
00:51:03,920 --> 00:51:05,760


1498
00:51:05,760 --> 00:51:07,760
것입니다. 그래서 이것이 당신이 보여주는 것이 무엇인지 보여줍니다.

1499
00:51:07,760 --> 00:51:08,880


1500
00:51:08,880 --> 00:51:12,319
비록 그것들이

1501
00:51:12,319 --> 00:51:15,119
정밀도의 함수로서 당신이

1502
00:51:15,119 --> 00:51:15,520


1503
00:51:15,520 --> 00:51:17,839
달라지고 있음을 보여주는 것입니다  활성

1504
00:51:17,839 --> 00:51:18,800
추론 에이전트의 동작

1505
00:51:18,800 --> 00:51:20,640
이지만 근사는 기본적으로

1506
00:51:20,640 --> 00:51:22,640
항상 꽤 잘 작동합니다.

1507
00:51:22,640 --> 00:51:25,200
e 점선은 더 적은

1508
00:51:25,200 --> 00:51:26,880
시도를 하고 실선은 더 많은

1509
00:51:26,880 --> 00:51:27,520
시도를

1510
00:51:27,520 --> 00:51:29,680
하므로 이러한 모든 경우

1511
00:51:29,680 --> 00:51:31,440
에서 점선, 대시

1512
00:51:31,440 --> 00:51:32,880
, 실선을

1513
00:51:32,880 --> 00:51:34,839
볼 수 있습니다. 더 많은 시도를 할수록 항상 더 잘하고 있습니다.

1514
00:51:34,839 --> 00:51:36,480


1515
00:51:36,480 --> 00:51:38,640
당신은 단지 100개의

1516
00:51:38,640 --> 00:51:41,839
시험을 가지고 있으므로 80개의 암에 대한 몇 번의 시험만

1517
00:51:41,839 --> 00:51:43,760
있으면 거의 무작위로 플레이하는 것처럼 후회할 것입니다.

1518
00:51:43,760 --> 00:51:45,680
왜냐하면

1519
00:51:45,680 --> 00:51:47,680
모든 암을 거의 한 번 시도

1520
00:51:47,680 --> 00:51:50,960
하지 않았기 때문에 그렇게 잘 할 수 없었기 때문입니다.

1521
00:51:50,960 --> 00:51:53,200
정확한 정확도의 오른쪽 영역에서

1522
00:51:53,200 --> 00:51:54,640
너무 많은 정확도가

1523
00:51:54,640 --> 00:51:57,359
아니라 여전히 음 여기 아래의 이 영역

1524
00:51:57,359 --> 00:51:58,000
에는

1525
00:51:58,000 --> 00:52:01,280
10,000번의 시도가 있습니다. 80개의 암을

1526
00:52:01,280 --> 00:52:03,440
사용해도 후회율은 매우 낮아질 수 있습니다.

1527
00:52:03,440 --> 00:52:05,040


1528
00:52:05,040 --> 00:52:08,160


1529
00:52:08,160 --> 00:52:10,880
결과

1530
00:52:10,880 --> 00:52:13,040
사이에 상당한 차이가

1531
00:52:13,040 --> 00:52:16,079
있으므로

1532
00:52:16,079 --> 00:52:17,040


1533
00:52:17,040 --> 00:52:19,200
활성 추론

1534
00:52:19,200 --> 00:52:22,240
이 올바른 매개변수가 주어지면 후회를 줄이는 방법을 배울

1535
00:52:22,240 --> 00:52:23,920
수 있다는 것을 그림 1에서 보여줍니다.

1536
00:52:23,920 --> 00:52:26,319


1537
00:52:26,319 --> 00:52:28,720


1538
00:52:28,720 --> 00:52:30,079
무기나

1539
00:52:30,079 --> 00:52:34,079
초고음 또는 저정밀도 가변

1540
00:52:34,079 --> 00:52:36,559
율 중에서

1541
00:52:36,559 --> 00:52:40,160
능동추론 알고리즘

1542
00:52:40,400 --> 00:52:42,400
음에 영향을 미치는 것들이며 또한

1543
00:52:42,400 --> 00:52:44,559


1544
00:52:44,559 --> 00:52:47,599
람다 부근에서 최소 후회율 음이

1545
00:52:47,599 --> 00:52:49,839
0.1임을 발견했다고 해서 에 대한 후회율을 고정한 것

1546
00:52:49,839 --> 00:52:52,160
입니다.  다가오는 시험 또는

1547
00:52:52,160 --> 00:52:55,200
다가오는 테스트

1548
00:52:55,200 --> 00:52:55,920


1549
00:52:55,920 --> 00:52:59,440
를 위해 조정할 수 있는 많은 손잡이가 있기 때문에

1550
00:52:59,440 --> 00:53:01,520
매개변수 스윕을 수행하고

1551
00:53:01,520 --> 00:53:03,280
여기에 있는 것처럼 표시하기

1552
00:53:03,280 --> 00:53:05,119
위해 최선을

1553
00:53:05,119 --> 00:53:06,400
다합니다.

1554
00:53:06,400 --> 00:53:09,280


1555
00:53:09,280 --> 00:53:11,040


1556
00:53:11,040 --> 00:53:12,400
이미 조합론과 같은 세 가지 다른

1557
00:53:12,400 --> 00:53:14,480
어려움이 매우 높아져 산업 상황

1558
00:53:14,480 --> 00:53:15,760
에서 이것을 사용

1559
00:53:15,760 --> 00:53:17,200


1560
00:53:17,200 --> 00:53:20,319
하려는 경우 이러한 모든

1561
00:53:20,319 --> 00:53:22,400
매개변수를 사용하여 최적화

1562
00:53:22,400 --> 00:53:25,680
한 다음 음 그들은

1563
00:53:25,680 --> 00:53:26,559


1564
00:53:26,559 --> 00:53:28,480
이 대략적인 능동 추론만 고려할 것이라고 씁니다.

1565
00:53:28,480 --> 00:53:31,440
에이전트 간 비교에 대한 변형

1566
00:53:31,440 --> 00:53:33,200
은 그림 1에서 꽤 잘 수행하고 있었기

1567
00:53:33,200 --> 00:53:35,040


1568
00:53:35,040 --> 00:53:36,880
때문에  대략적이지만 일반적인 또는 정확한 그림 2에 대한

1569
00:53:36,880 --> 00:53:38,400


1570
00:53:38,400 --> 00:53:40,160
계산 시간의 차이가 무엇인지 물을 수 있는

1571
00:53:40,160 --> 00:53:42,160


1572
00:53:42,160 --> 00:53:44,720
것이므로 여기

1573
00:53:44,720 --> 00:53:45,359


1574
00:53:45,359 --> 00:53:47,520
에서 고정된 베르누이

1575
00:53:47,520 --> 00:53:49,119
산적

1576
00:53:49,119 --> 00:53:51,119
은 약간 다른 플롯이 될 것이라는 점에 대해 여전히 생각하고 있습니다

1577
00:53:51,119 --> 00:53:52,960


1578
00:53:52,960 --> 00:53:54,960
.

1579
00:53:54,960 --> 00:53:57,119
대략적인 활성 추론에 대한 누적 후회 궤적은

1580
00:53:57,119 --> 00:53:59,680


1581
00:53:59,680 --> 00:54:02,000
낙관적 정상이고 샘플링은 청록색

1582
00:54:02,000 --> 00:54:03,200


1583
00:54:03,200 --> 00:54:05,440
에 있는 자주색 및 베이지안 상한

1584
00:54:05,440 --> 00:54:06,480


1585
00:54:06,480 --> 00:54:08,160
이므로 세 줄이며

1586
00:54:08,160 --> 00:54:11,200
왼쪽 상단의 범례

1587
00:54:11,200 --> 00:54:13,520
이고 파란색이 방금 말한 대로 사전

1588
00:54:13,520 --> 00:54:15,920
정밀도는 다음으로 고정됩니다.  1번

1589
00:54:15,920 --> 00:54:18,079
포인트는 좋은 정밀 변수 설정

1590
00:54:18,079 --> 00:54:19,760


1591
00:54:19,760 --> 00:54:22,319
인 것처럼 보이는 1번 포인트 근처에 있는 이러한 종류의 딥과 같은 그림 1에서 찾은

1592
00:54:22,319 --> 00:54:24,079


1593
00:54:24,079 --> 00:54:26,480
것이므로 위치를 가로질러 스위핑

1594
00:54:26,480 --> 00:54:28,079
하는 대신 롤링할 것입니다.

1595
00:54:28,079 --> 00:54:30,400


1596
00:54:30,400 --> 00:54:33,359
우리는 유사한 열과 행을 볼 수 있습니다. 열에

1597
00:54:33,359 --> 00:54:33,920


1598
00:54:33,920 --> 00:54:36,480
는 k개의 서로 다른 수의 팔이 있고

1599
00:54:36,480 --> 00:54:37,440
행

1600
00:54:37,440 --> 00:54:40,160
에는 서로 다른 문제 난이도

1601
00:54:40,160 --> 00:54:40,720
가 있습니다

1602
00:54:40,720 --> 00:54:43,520
.

1603
00:54:43,760 --> 00:54:47,200
누적된 후회

1604
00:54:47,200 --> 00:54:50,240
는 더 낮은 후회를 원하기

1605
00:54:50,240 --> 00:54:51,680
때문에 의미가 있는 것입니다. 그것이

1606
00:54:51,680 --> 00:54:54,079
우리가 훈련하는 모든 것입니다. 음 우리는

1607
00:54:54,079 --> 00:54:56,480
무엇을 볼 수 있습니까? 볼 수 있는 조합

1608
00:54:56,480 --> 00:54:57,599
이 너무 많기 때문에

1609
00:54:57,599 --> 00:55:00,319
볼 수 있는 것이

1610
00:55:00,319 --> 00:55:00,799
많습니다

1611
00:55:00,799 --> 00:55:03,920
.  거의 모든 경우

1612
00:55:03,920 --> 00:55:04,640
에 샘플

1613
00:55:04,640 --> 00:55:08,000
수가 100개 이상으로 증가

1614
00:55:08,000 --> 00:55:10,640
합니다. 빨간색 선

1615
00:55:10,640 --> 00:55:12,480
근사 활성 추론

1616
00:55:12,480 --> 00:55:16,079
은 다른 것

1617
00:55:16,079 --> 00:55:18,559
보다 낮으므로

1618
00:55:18,559 --> 00:55:20,000


1619
00:55:20,000 --> 00:55:22,880
많은 매개변수 조합에 대해 고정 적기에 대한 활성 추론으로 후회를 덜 하게 됩니다.

1620
00:55:22,880 --> 00:55:24,799


1621
00:55:24,799 --> 00:55:27,599
괜찮지만 몇 가지가 있습니다.  흥미로운

1622
00:55:27,599 --> 00:55:28,720


1623
00:55:28,720 --> 00:55:31,920
조각 중 하나는 초기에 능동적인

1624
00:55:31,920 --> 00:55:32,400
추론

1625
00:55:32,400 --> 00:55:34,799
이 더 큰 후회를 하는 경우가 있기 때문에 처음에는

1626
00:55:34,799 --> 00:55:37,200
조금 더 탐색적인 것처럼

1627
00:55:37,200 --> 00:55:39,040


1628
00:55:39,040 --> 00:55:40,559
왼쪽 하단 모서리에서 볼

1629
00:55:40,559 --> 00:55:41,839
수 있는 것 중 하나입니다.

1630
00:55:41,839 --> 00:55:43,599


1631
00:55:43,599 --> 00:55:46,000
초기에는 팔꿈치

1632
00:55:46,000 --> 00:55:48,240


1633
00:55:48,240 --> 00:55:48,799


1634
00:55:48,799 --> 00:55:51,839
왼쪽 상단에 실제로 많이 표시되는 매우 흥미로운 동작이 있으므로 항상 모드

1635
00:55:51,839 --> 00:55:53,040
를 설정할 수 있는 것은 아닙니다.

1636
00:55:53,040 --> 00:55:54,400
el을 일부 매개변수

1637
00:55:54,400 --> 00:55:56,079
조합에 적용하고 정말

1638
00:55:56,079 --> 00:55:57,520
일반화된 결론을 이끌어내지

1639
00:55:57,520 --> 00:55:59,119
만 이것은 저자의 굉장한 요점입니다.

1640
00:55:59,119 --> 00:56:00,559


1641
00:56:00,559 --> 00:56:04,559
그래서 그들은

1642
00:56:04,559 --> 00:56:07,119
에이전트의 앙상블을 보고 있습니다. 그래서 여기에서는

1643
00:56:07,119 --> 00:56:07,599


1644
00:56:07,599 --> 00:56:09,599
마치 그들이 각각의 수천 uh를 실행하는 것과 같은 수천 개의 에이전트

1645
00:56:09,599 --> 00:56:11,040


1646
00:56:11,040 --> 00:56:13,599
가 있습니다.  이것들과

1647
00:56:13,599 --> 00:56:14,960
평균을 취하는 이유는 라인이

1648
00:56:14,960 --> 00:56:16,079


1649
00:56:16,079 --> 00:56:18,400
매끄럽고 그래서 왼쪽 상단에서 볼 수 있는

1650
00:56:18,400 --> 00:56:19,680


1651
00:56:19,680 --> 00:56:21,359
것은 활성 추론 아시아인이 다른 알고리즘과 마찬가지로 수행하고 있다는 것입니다.

1652
00:56:21,359 --> 00:56:22,960
그러면

1653
00:56:22,960 --> 00:56:24,720


1654
00:56:24,720 --> 00:56:27,920
해당 라인 아래에서 더 나은 오른쪽 낮은 후회를 하고 있지만 오류가 발생합니다.

1655
00:56:27,920 --> 00:56:28,480
경계

1656
00:56:28,480 --> 00:56:30,880
는 그 빨간 음영을 증가시키고 그것은

1657
00:56:30,880 --> 00:56:32,079
정말로 멀리

1658
00:56:32,079 --> 00:56:34,960
위로 향하기 시작합니다. 그래서 무슨 일이 일어나고 있는지 매우 흥미롭습니다.

1659
00:56:34,960 --> 00:56:36,240
그들은

1660
00:56:36,240 --> 00:56:37,920
이 발산이

1661
00:56:37,920 --> 00:56:40,400


1662
00:56:40,400 --> 00:56:42,880
정확한 솔루션을 찾지 못하고

1663
00:56:42,880 --> 00:56:43,680


1664
00:56:43,680 --> 00:56:45,440
자신의 추정치를 과도하게 확신했던 앙상블의 소수의 에이전트에 의해 발생한다고 씁니다.  어떤 팔

1665
00:56:45,440 --> 00:56:47,680
을 선택해야

1666
00:56:47,680 --> 00:56:50,799
하는 파이 차트와 같은 종류의 파이 차트가

1667
00:56:50,799 --> 00:56:51,440


1668
00:56:51,440 --> 00:56:54,319
좋지 않은 출발을 했고 그

1669
00:56:54,319 --> 00:56:56,160
정밀도가 이 정도였습니다.  그들은 그냥 그런 식

1670
00:56:56,160 --> 00:56:56,640
으로

1671
00:56:56,640 --> 00:56:58,799
굴러갔고 그들은 문제를 설정하는 방식으로

1672
00:56:58,799 --> 00:57:00,559
그들이 얻고 있는 정보를 계속 보았고

1673
00:57:00,559 --> 00:57:01,599


1674
00:57:01,599 --> 00:57:03,839
, 그래서 그들은 결국

1675
00:57:03,839 --> 00:57:04,880


1676
00:57:04,880 --> 00:57:06,960


1677
00:57:06,960 --> 00:57:09,440


1678
00:57:09,440 --> 00:57:11,359
그들이 내린 결정을 계속 후회하면서 탈선하는 요원의 작은 부분에 이르렀습니다.  발산

1679
00:57:11,359 --> 00:57:13,680
에 잠겨 있기 때문에

1680
00:57:13,680 --> 00:57:14,799


1681
00:57:14,799 --> 00:57:16,880


1682
00:57:16,880 --> 00:57:18,160


1683
00:57:18,160 --> 00:57:21,359
더 큰 설정으로 더 쉬운 설정에서 볼 수 없습니다. 최적이 아닌

1684
00:57:21,359 --> 00:57:22,160
경우

1685
00:57:22,160 --> 00:57:24,079


1686
00:57:24,079 --> 00:57:25,760
를 관찰하기 위해 더 큰 앙상블과 더 많은 시도가 필요하기

1687
00:57:25,760 --> 00:57:28,240


1688
00:57:28,240 --> 00:57:29,520
때문에 어떤 변수가 거기에 표시되어야 하는지 잘 모르겠습니다.

1689
00:57:29,520 --> 00:57:31,200
발산은

1690
00:57:31,200 --> 00:57:32,880
고려되는 가장 적은 수의 암에 대해서만 분명합니다.

1691
00:57:32,880 --> 00:57:34,000
왜냐하면 그것이 더 쉬운 문제와 비슷하다고 생각되기 때문입니다.

1692
00:57:34,000 --> 00:57:34,640


1693
00:57:34,640 --> 00:57:36,880
그러나 그 이유

1694
00:57:36,880 --> 00:57:39,280
는 암의 수가 적을수록 상담원이 제한된 시행 횟수에 대해 각 개별 암

1695
00:57:39,280 --> 00:57:41,440
을 탐색해야 할 기회가 더 많기 때문입니다.

1696
00:57:41,440 --> 00:57:43,599


1697
00:57:43,599 --> 00:57:44,559


1698
00:57:44,559 --> 00:57:46,799
그래서 당신의 믿음을 가두는 것이 더 쉬우며

1699
00:57:46,799 --> 00:57:48,559


1700
00:57:48,559 --> 00:57:51,040
, 작은 사회 집단에 대한 잘못된 믿음까지도 가두는 것이 더 쉽습니다.

1701
00:57:51,040 --> 00:57:52,240


1702
00:57:52,240 --> 00:57:54,640
k는 80

1703
00:57:54,640 --> 00:57:56,160


1704
00:57:56,160 --> 00:57:58,079
명과 같습니다. 배울 것이 너무 많아 조기

1705
00:57:58,079 --> 00:57:59,680
에 갇힐 가능성이

1706
00:57:59,680 --> 00:58:02,880
적지만 소규모

1707
00:58:02,880 --> 00:58:04,400
파티에서는 이러한 능동적 추론 에이전트 중 일부가

1708
00:58:04,400 --> 00:58:06,319


1709
00:58:06,319 --> 00:58:09,119
가장 보람 있는 무기라고 생각하는 것에 매우 일찍 갇히게 됩니다.

1710
00:58:09,119 --> 00:58:10,880


1711
00:58:10,880 --> 00:58:13,200
그런 다음 그들은

1712
00:58:13,200 --> 00:58:14,480
효율적으로 샘플링

1713
00:58:14,480 --> 00:58:17,839
하지 않아 결국 유감스러운 정책을 구현

1714
00:58:17,839 --> 00:58:20,880


1715
00:58:20,880 --> 00:58:23,280
하게 되므로 매우 매력적입니다. 그래서 여기에 각주를 추가하고 싶습니다.

1716
00:58:23,280 --> 00:58:24,160


1717
00:58:24,160 --> 00:58:26,960
그래서 여기 왼쪽 상단

1718
00:58:26,960 --> 00:58:27,520
에서 k가

1719
00:58:27,520 --> 00:58:30,559
10이고 이 엡실론이 0.1인

1720
00:58:30,559 --> 00:58:33,680
왼쪽 상단을 보고 있습니다.  가장 쉽고

1721
00:58:33,680 --> 00:58:35,359
오른쪽 아래가 가장 어렵습니다.

1722
00:58:35,359 --> 00:58:36,319
여기서 k

1723
00:58:36,319 --> 00:58:38,799
는 팔의 수이고 이

1724
00:58:38,799 --> 00:58:40,000
엡실론 계수

1725
00:58:40,000 --> 00:58:42,880
는 팔 간의

1726
00:58:42,880 --> 00:58:43,280


1727
00:58:43,280 --> 00:58:44,960
차이입니다

1728
00:58:44,960 --> 00:58:46,640


1729
00:58:46,640 --> 00:58:48,640
.  그렇지 않은 팔

1730
00:58:48,640 --> 00:58:52,240
예 제 생각에는 1번 포인트가 더 어렵다고 생각합니다.

1731
00:58:52,240 --> 00:58:54,160
왜냐하면 더 나은 것과 더 나쁜 것의 구분이 덜하기 때문입니다.

1732
00:58:54,160 --> 00:58:55,839


1733
00:58:55,839 --> 00:58:59,760
그래서 더 적은 수의 암

1734
00:58:59,760 --> 00:59:02,839
이 더 쉽지만 4번 포인트는 더 큰 연속입니다.

1735
00:59:02,839 --> 00:59:05,359


1736
00:59:05,359 --> 00:59:08,000
우선 포인트 1은 포인트 4보다 어렵습니다.

1737
00:59:08,000 --> 00:59:08,480


1738
00:59:08,480 --> 00:59:10,720
그래서

1739
00:59:10,720 --> 00:59:11,680


1740
00:59:11,680 --> 00:59:15,040
가장 쉬운 것은 왼쪽 하단입니다. 가장

1741
00:59:15,040 --> 00:59:16,960
쉬운 의미는 무엇을 의미하는지에 따라 다릅니다. 모든

1742
00:59:16,960 --> 00:59:18,240
것이 평등하면

1743
00:59:18,240 --> 00:59:21,040
더 적은 수의 팔이 더 쉽고 모든

1744
00:59:21,040 --> 00:59:22,000
것이 동일

1745
00:59:22,000 --> 00:59:24,319
하면 더 대조적입니다.  좋은 팔과 나쁜

1746
00:59:24,319 --> 00:59:25,119


1747
00:59:25,119 --> 00:59:27,920
팔 사이가 더 쉬우므로 왼쪽 하단

1748
00:59:27,920 --> 00:59:28,720


1749
00:59:28,720 --> 00:59:32,160
이 더 쉬울 것입니다. 그렇습니다. 가장 적은 팔과

1750
00:59:32,160 --> 00:59:33,440
가장 큰 대조가 있고

1751
00:59:33,440 --> 00:59:34,880
흥미롭게도 가장 큰 음 초기 후회와 같은

1752
00:59:34,880 --> 00:59:37,440
능동적 추론의 가장 큰 음 팔꿈치를 볼

1753
00:59:37,440 --> 00:59:38,640


1754
00:59:38,640 --> 00:59:41,680
수 있습니다.

1755
00:59:41,680 --> 00:59:43,599
게임이 쉽고 팔이 거의 없기 때문에 능동

1756
00:59:43,599 --> 00:59:45,280
추론이

1757
00:59:45,280 --> 00:59:48,559
탐색을 조금 더 오래 유지

1758
00:59:48,559 --> 00:59:51,760
하지만 결국 옳은 것에 고정

1759
00:59:51,760 --> 00:59:54,079
되고 특히

1760
00:59:54,079 --> 00:59:56,319
팔 사이에 큰 차이가 없을 때

1761
00:59:56,319 --> 00:59:59,359
모든 무기가 약간의 상승을 하고

1762
00:59:59,359 --> 01:00:00,400
그 다음에는 편차가 발생합니다.

1763
01:00:00,400 --> 01:00:02,079
이 음영으로 증가하면

1764
01:00:02,079 --> 01:00:03,599


1765
01:00:03,599 --> 01:00:05,520
모든 앙상블이 다르게 동작하는

1766
01:00:05,520 --> 01:00:06,720
것이 아니라

1767
01:00:06,720 --> 01:00:09,520
하위 집합이 이상해지고 있음을 다시 한 번 알 수 있습니다.

1768
01:00:09,520 --> 01:00:11,359


1769
01:00:11,359 --> 01:00:13,280
ko 그렇기 때문에

1770
01:00:13,280 --> 01:00:15,040
더 큰 엡실론이

1771
01:00:15,040 --> 01:00:16,880
더 어려울 것이라고 생각하지만 우리는

1772
01:00:16,880 --> 01:00:18,240
저자를 위해 엡실론을 저장해야 할

1773
01:00:18,240 --> 01:00:19,760
것입니다. 나는 대비가 적을수록 더 쉬울 것이라고 생각합니다.

1774
01:00:19,760 --> 01:00:21,359


1775
01:00:21,359 --> 01:00:23,680
우리는 단지

1776
01:00:23,680 --> 01:00:24,480


1777
01:00:24,480 --> 01:00:27,599
예를 물어야 할 것이므로 이것은 멋진

1778
01:00:27,599 --> 01:00:30,720
결과이며

1779
01:00:30,720 --> 01:00:34,079


1780
01:00:34,079 --> 01:00:36,960
능동 추론이

1781
01:00:36,960 --> 01:00:38,799
실제로 성공할 수 있는 곳과 여전히

1782
01:00:38,799 --> 01:00:39,920
우리가 다시 돌아가야 할 도전이 필요한 부분에 대해 더 큰 요점을 제시하는 자격을 갖춘 비평과 거의 같습니다.

1783
01:00:39,920 --> 01:00:40,880


1784
01:00:40,880 --> 01:00:44,000
고정 적기

1785
01:00:44,000 --> 01:00:47,119
입니다 전환 적기로 가자 주요

1786
01:00:47,119 --> 01:00:50,240
차이점은 각 시간 단계에서

1787
01:00:50,240 --> 01:00:53,040
특정 팔이 최대

1788
01:00:53,040 --> 01:00:54,559
보상을   

1789
01:00:54,559 --> 01:00:57,839
고 이 보상 확률이 확률로 변  

1790
01:00:57,839 --> 01:01:00,480
될 것이기 때문에 일  

1791
01:01:00,480 --> 01:01:01,520
확률 행 u

1792
01:01:01,520 --> 01:01:05,119
이 있다는 것입니

1793
01:01:05,119 --> 01:01:09,599
다.  아니면 행인지 어

1794
01:01:09,599 --> 01:01:13,119
, 보상이 변할 확률이 있는 행

1795
01:01:13,119 --> 01:01:16,000
이므로 시간이 지남에 따라

1796
01:01:16,000 --> 01:01:17,760
상황이 변하기 때문에 이전 순서로 배울 수 없습니다

1797
01:01:17,760 --> 01:01:19,280


1798
01:01:19,280 --> 01:01:22,240
. 치즈의 확률은 시간에 따라 달라집니다.

1799
01:01:22,240 --> 01:01:25,119
섹션 2.2 오 예 파랑 오 나는

1800
01:01:25,119 --> 01:01:26,559
아무것도 가지고 있지 않습니다 아니요 그게 아니라

1801
01:01:26,559 --> 01:01:28,799
당신이 한 것이 좋습니다 그래서 2.2는

1802
01:01:28,799 --> 01:01:29,760
그들이

1803
01:01:29,760 --> 01:01:31,359
스위칭 적기에 대한 형식주의를 제공하는 곳

1804
01:01:31,359 --> 01:01:33,280
이므로

1805
01:01:33,280 --> 01:01:35,280
고정 적기와 대조적으로

1806
01:01:35,280 --> 01:01:37,599
문제 결과는 시간에서 그려집니다

1807
01:01:37,599 --> 01:01:39,440
종속 베르누이 확률

1808
01:01:39,440 --> 01:01:40,559
분포

1809
01:01:40,559 --> 01:01:43,920
가 제공

1810
01:01:43,920 --> 01:01:46,799
되므로 세부 사항을 살펴보고 싶은 사람

1811
01:01:46,799 --> 01:01:47,200


1812
01:01:47,200 --> 01:01:49,520
은 그렇게 할 수 있지만 주요 차이점

1813
01:01:49,520 --> 01:01:50,960


1814
01:01:50,960 --> 01:01:53,599
은 게임을 하는 동안 상황이 변경될 가능성

1815
01:01:53,599 --> 01:01:54,480


1816
01:01:54,480 --> 01:01:57,520
이 있다는 것이므로 여기에 대해 질문을

1817
01:01:57,520 --> 01:01:58,240
했습니다.  저자

1818
01:01:58,240 --> 01:02:00,240
와 어, 확률이 같을 수 있도록 질문을 하기를 고대

1819
01:02:00,240 --> 01:02:01,359


1820
01:02:01,359 --> 01:02:03,920
하고 있습니다. 그런 다음

1821
01:02:03,920 --> 01:02:06,160


1822
01:02:06,160 --> 01:02:09,039
20단계 또는 50단계 후에

1823
01:02:09,039 --> 01:02:10,160
동일하게 동일한 것처럼 갑자기 변경

1824
01:02:10,160 --> 01:02:12,720
되다가 갑자기 변경

1825
01:02:12,720 --> 01:02:14,720
되거나  각 시간 단계에서

1826
01:02:14,720 --> 01:02:15,280


1827
01:02:15,280 --> 01:02:17,359
변화하는 것은 그것이 어느 정도 확률로 변한다고 말했기 때문인 것처럼 느껴지

1828
01:02:17,359 --> 01:02:19,599
지만 그렇지 않으면 일정

1829
01:02:19,599 --> 01:02:21,920
하므로

1830
01:02:21,920 --> 01:02:23,760
모든 팔에 걸쳐 상수로 궁금합니다. 확률은 다음과 같습니다.

1831
01:02:23,760 --> 01:02:25,599
그것은 일정하거나 항상 변하는

1832
01:02:25,599 --> 01:02:26,240


1833
01:02:26,240 --> 01:02:28,799
것입니까?

1834
01:02:30,400 --> 01:02:33,119
여기서 좋은 질문을 모르겠습니다. 전환 베르누이 산적

1835
01:02:33,119 --> 01:02:35,039
에서 서로 다른 알고리즘의 에이전트 비교 사이

1836
01:02:35,039 --> 01:02:36,799


1837
01:02:36,799 --> 01:02:38,799
에 고정 평균 결과 차이가 있으므로

1838
01:02:38,799 --> 01:02:40,799
엡실론은 25입니다.

1839
01:02:40,799 --> 01:02:44,000
그래서 그들은 엡실론을 고정으로 설정하고 있습니다.

1840
01:02:44,000 --> 01:02:45,920
다른 행 및

1841
01:02:45,920 --> 01:02:48,160
열 상황이

1842
01:02:48,160 --> 01:02:51,599
될 것이므로 이 그림에서 3개의 열은

1843
01:02:51,599 --> 01:02:55,039
행이 0.01 02 및 o4

1844
01:02:55,039 --> 01:02:56,799
이므로 변경 가능성이 있으므로

1845
01:02:56,799 --> 01:02:58,559
여기 왼쪽 열에

1846
01:02:58,559 --> 01:03:00,240
는 1

1847
01:03:00,240 --> 01:03:02,319
%의 시간 단계가 있는 동적 환경입니다. 여기에 변경 사항이

1848
01:03:02,319 --> 01:03:04,000
있습니다.  오른쪽에 있습니다. 최대

1849
01:03:04,000 --> 01:03:05,680
4%까지 변경

1850
01:03:05,680 --> 01:03:08,960
되므로 모든 것이 같을수록

1851
01:03:08,960 --> 01:03:11,440
변경하기가 더 어려워집니다. 왜냐하면

1852
01:03:11,440 --> 01:03:12,480


1853
01:03:12,480 --> 01:03:15,520
um을 더 빠르게 변경하고 덜

1854
01:03:15,520 --> 01:03:17,280
변경하는 것과 같을 것이기 때문에 더 정적

1855
01:03:17,280 --> 01:03:20,559
케이스와 같으며 이제 행은 다음과 같습니다.  arm

1856
01:03:20,559 --> 01:03:21,119
so k

1857
01:03:21,119 --> 01:03:24,880
10 20 및 40. 모든 것이 평등

1858
01:03:24,880 --> 01:03:27,039
하므로 결정해야 할 것이 더 적기 때문에 팔이 적을수록 더 쉽습니다.

1859
01:03:27,039 --> 01:03:30,160


1860
01:03:30,160 --> 01:03:32,079
그러면 각 셀 내에서 다음과 같이 살펴볼 것입니다.

1861
01:03:32,079 --> 01:03:33,760


1862
01:03:33,760 --> 01:03:37,359


1863
01:03:37,359 --> 01:03:40,880
후회율 이 r sub t

1864
01:03:40,880 --> 01:03:43,039
시간이 지남에 따라 후회를 덜 하고 싶을 때

1865
01:03:43,039 --> 01:03:45,440
후회율을 낮추는 것이

1866
01:03:45,440 --> 01:03:47,920
샘플의 함수로 더 좋으므로 최대

1867
01:03:47,920 --> 01:03:48,880
수천 개의

1868
01:03:48,880 --> 01:03:51,520
샘플이 있으며 다음

1869
01:03:51,520 --> 01:03:52,640
은 비교되는 알고리즘입니다.

1870
01:03:52,640 --> 01:03:55,119
능동 추론  빨간색 베이지안 상위

1871
01:03:55,119 --> 01:03:57,200
신뢰 파란색

1872
01:03:57,200 --> 01:03:59,920
파란색 낙관적 톰슨

1873
01:03:59,920 --> 01:04:02,480
, 검은색 점선의 무작위 제어

1874
01:04:02,480 --> 01:04:06,000
그래서 무작위 플레이는 음 좋은

1875
01:04:06,000 --> 01:04:09,200
것입니다 음 그것은 음 적대적인 플레이가

1876
01:04:09,200 --> 01:04:10,799
아니므로 당신이 선택한 것과 같지 않습니다

1877
01:04:10,799 --> 01:04:13,119
하지만 이것은 무작위 플레이

1878
01:04:13,119 --> 01:04:14,880
이고 우리가 보고 있는 것은

1879
01:04:14,880 --> 01:04:18,000


1880
01:04:18,000 --> 01:04:21,760
동일한

1881
01:04:21,760 --> 01:04:25,200
값을 보라색으로 시작하고 청록색

1882
01:04:25,200 --> 01:04:27,839
알고리즘도 무작위 플레이보다 낮은 후회율로 수렴하는 정적 양의 후회율

1883
01:04:27,839 --> 01:04:28,240
을 축적한다는

1884
01:04:28,240 --> 01:04:30,799
것입니다.  그들은

1885
01:04:30,799 --> 01:04:32,960
무작위보다 더 잘 작동

1886
01:04:32,960 --> 01:04:36,400
하지만 본질적으로 모든 경우

1887
01:04:36,400 --> 01:04:39,119
에 활성 추론이 이러한

1888
01:04:39,119 --> 01:04:39,440
다른

1889
01:04:39,440 --> 01:04:41,920
알고리즘

1890
01:04:41,920 --> 01:04:43,839


1891
01:04:43,839 --> 01:04:47,599
보다 낮습니다.  me other

1892
01:04:47,599 --> 01:04:50,559


1893
01:04:50,559 --> 01:04:50,960


1894
01:04:50,960 --> 01:04:54,079
algorithm 시간이 지남에 따라 옥타브

1895
01:04:54,079 --> 01:04:54,559
추론

1896
01:04:54,559 --> 01:04:57,200
은 다른 알고리즘보다 더 낮은 비율로 후회를 획득

1897
01:04:57,200 --> 01:04:58,640


1898
01:04:58,640 --> 01:05:00,400
하고 더 나은 성능을 보일 뿐이며 더 나은 정책을 구현하고 있음

1899
01:05:00,400 --> 01:05:00,799


1900
01:05:00,799 --> 01:05:04,880
을 알 수 있습니다. 그러면 덜 변경되는 것을 볼 수 있습니다.

1901
01:05:04,880 --> 01:05:08,240
그리고

1902
01:05:08,240 --> 01:05:11,440
왼쪽 상단에 있는 팔이 더 적기 때문에

1903
01:05:11,440 --> 01:05:14,079


1904
01:05:14,079 --> 01:05:15,599
무작위 플레이와 알고리즘의 차이

1905
01:05:15,599 --> 01:05:19,200
가 중요하고 능동 추론은

1906
01:05:19,200 --> 01:05:19,520


1907
01:05:19,520 --> 01:05:22,559
매우 잘하는 반면 매우

1908
01:05:22,559 --> 01:05:23,760
역동적인 환경

1909
01:05:23,760 --> 01:05:27,520
과 더 많은 팔이 있을 때는 그렇게 많이 얻지 못한다

1910
01:05:27,520 --> 01:05:29,599
는 것을 쉽게 알 수 있습니다.  유감스럽게도 당신은 여전히

1911
01:05:29,599 --> 01:05:31,119
적으로 더 잘하고 있고 여전히 능동적인 추  

1912
01:05:31,119 --> 01:05:32,480
이 다른 알고리즘을 능가합니다. 그  

1913
01:05:32,480 --> 01:05:33,440


1914
01:05:33,440 --> 01:05:34,960
나 그것이 몇  

1915
01:05:34,960 --> 01:05:36,640
계마다 변경되고 있고 100개의 팔  

1916
01:05:36,640 --> 01:05:37,520
 

1917
01:05:37,520 --> 01:05:40,000
다면 의미를 만들기에 충  

1918
01:05:40,000 --> 01:05:40,880
히 샘플링할 수 없을 것이라고 상상하는

1919
01:05:40,880 --> 01:05:43,599
것과 같  

1920
01:05:43,599 --> 01:05:44,640


1921
01:05:44,640 --> 01:05:47,440
니다.  모델을 업데이트하여 모든 기계 학습 알고리즘의 전반적인 성능

1922
01:05:47,440 --> 01:05:49,119
이 더 빠르게 변경되고 더 많은 팔이 있는 이유

1923
01:05:49,119 --> 01:05:51,359


1924
01:05:51,359 --> 01:05:52,720
입니다.  thm은

1925
01:05:52,720 --> 01:05:54,880
랜덤 플레이로 수렴하는

1926
01:05:54,880 --> 01:05:57,440
반면 문제가 더 정

1927
01:05:57,440 --> 01:05:59,839
적이고 더 적은 옵션이

1928
01:05:59,839 --> 01:06:03,200
있으면 더 좋고 더 나은 전략

1929
01:06:03,200 --> 01:06:04,720
이 무작위에 비해 더 잘 수행

1930
01:06:04,720 --> 01:06:06,480


1931
01:06:06,480 --> 01:06:09,359
될 것이므로

1932
01:06:09,359 --> 01:06:11,359
그들이 수행하는 시뮬레이션을 수행하는 것은 꽤 멋집니다.

1933
01:06:11,359 --> 01:06:14,480
음 저는 천 개의 시뮬레이션

1934
01:06:14,480 --> 01:06:16,000
을 추측하고 앙상블 내의 각 에이전트 인스턴스에 대해 전환 일정이

1935
01:06:16,000 --> 01:06:17,760
무작위로 생성

1936
01:06:17,760 --> 01:06:19,599


1937
01:06:19,599 --> 01:06:23,359
되므로

1938
01:06:23,359 --> 01:06:25,039
이러한 각 경우에 대해 전체 시뮬레이션을 천 번 수행한 다음

1939
01:06:25,039 --> 01:06:26,400
평균

1940
01:06:26,400 --> 01:06:29,839
을 내며 활성

1941
01:06:29,839 --> 01:06:32,720
추론을 잘 수행했습니다.  다양한 상황

1942
01:06:32,720 --> 01:06:33,200


1943
01:06:33,200 --> 01:06:35,440
에서 전환 베르누이 산적에서 더 잘하고

1944
01:06:35,440 --> 01:06:36,880


1945
01:06:36,880 --> 01:06:40,640
있고

1946
01:06:40,640 --> 01:06:41,599


1947
01:06:41,599 --> 01:06:44,400
일종의 좋은 작업 방식을 빠르게 파악한 다음

1948
01:06:44,400 --> 01:06:48,559
낮은 후회 누적률로 유지

1949
01:06:48,640 --> 01:06:52,160


1950
01:06:52,160 --> 01:06:55,200
됩니다.

1951
01:06:55,200 --> 01:06:59,599
4 우리는 암의 수를 고칠

1952
01:06:59,599 --> 01:07:02,000
것이므로 이제 스위칭 베르누이 밴디트에서 k는 20 암과 같습니다.

1953
01:07:02,000 --> 01:07:03,680


1954
01:07:03,680 --> 01:07:04,880
그런 다음 이러한 알고리즘 ag를 비교할 것입니다.

1955
01:07:04,880 --> 01:07:07,200
그래서 여기

1956
01:07:07,200 --> 01:07:09,440
에서 열은 이전

1957
01:07:09,440 --> 01:07:12,400
과 같으며 오른쪽의 행은 0.01 o2

1958
01:07:12,400 --> 01:07:14,000
및 o4와 같습니다.

1959
01:07:14,000 --> 01:07:16,480
그러나 이제 이전 수치에서 보았듯이

1960
01:07:16,480 --> 01:07:18,640


1961
01:07:18,640 --> 01:07:21,359


1962
01:07:21,359 --> 01:07:23,680
보상이 있는 팔과 덜 보상이 있는 팔 사이의 차이인 엡실론이

1963
01:07:23,680 --> 01:07:28,960
있습니다.  그래서 우리

1964
01:07:28,960 --> 01:07:30,480
는 덜 변화

1965
01:07:30,480 --> 01:07:33,599
하고 행 사이의 가장 큰 대비

1966
01:07:33,599 --> 01:07:37,039
가

1967
01:07:37,039 --> 01:07:40,319


1968
01:07:40,319 --> 01:07:43,359
무작위 재생에 비해 가장 큰 이득을

1969
01:07:43,359 --> 01:07:46,240


1970
01:07:46,240 --> 01:07:47,920


1971
01:07:47,920 --> 01:07:50,000
볼 수 있는 곳이라고 생각할 수 있습니다.  결과

1972
01:07:50,000 --> 01:07:53,280
의

1973
01:07:53,280 --> 01:07:54,799
경우 알고리즘과의 후회율 차이가

1974
01:07:54,799 --> 01:07:57,920
적지만 전반적으로

1975
01:07:57,920 --> 01:08:00,000
능동 추론이 이러한 다른 알고리즘보다 더 나은 성능을 발휘

1976
01:08:00,000 --> 01:08:01,920


1977
01:08:01,920 --> 01:08:05,359
하므로 샘플링이 증가함에 따라

1978
01:08:05,359 --> 01:08:07,200
능동 추론

1979
01:08:07,200 --> 01:08:09,039
이 약

1980
01:08:09,039 --> 01:08:12,160
200개 또는 500개

1981
01:08:12,160 --> 01:08:14,720
샘플만큼 꽤 좋은 지점에 고정됩니다.  20개 팔

1982
01:08:14,720 --> 01:08:15,440


1983
01:08:15,440 --> 01:08:17,600
의 경우 각 팔을 방문하는 것과 같습니다. 아마 몇

1984
01:08:17,600 --> 01:08:18,479
번

1985
01:08:18,479 --> 01:08:20,719
이고 다른 팔보다 더 많이 방문하지만

1986
01:08:20,719 --> 01:08:22,479
다시 항상 변화

1987
01:08:22,479 --> 01:08:26,158
하고 매우 활동적입니다.  ve 추론은

1988
01:08:26,158 --> 01:08:28,158
그것에 대처할 수 있고 또한 흥미

1989
01:08:28,158 --> 01:08:29,759
롭습니다. 특히 이

1990
01:08:29,759 --> 01:08:33,839
청록색은 거의

1991
01:08:33,839 --> 01:08:36,839
후회율이 낮고 실제로는 기어

1992
01:08:36,839 --> 01:08:38,319
오르는

1993
01:08:38,319 --> 01:08:40,880
반면, 적어도 시각적으로 우리는

1994
01:08:40,880 --> 01:08:43,120
활성 추론 종류가 평평

1995
01:08:43,120 --> 01:08:45,439
하지만 다시 위로 올라가지 않는 것을 보고 있습니다.  그래서 그것은

1996
01:08:45,439 --> 01:08:46,719


1997
01:08:46,719 --> 01:08:48,158
모든 종류의 알고리즘에서 발생할 수 있는 일이며

1998
01:08:48,158 --> 01:08:49,759
, 비정상적

1999
01:08:49,759 --> 01:08:50,839
정밀도

2000
01:08:50,839 --> 01:08:53,520
체제에 갇히게 되며

2001
01:08:53,520 --> 01:08:57,520
음, 그래서 그것을 그림 3에서 쪼개는 또 다른 방법이 있습니다.

2002
01:08:57,520 --> 01:08:59,040


2003
01:08:59,040 --> 01:09:01,759
그들은

2004
01:09:01,759 --> 01:09:02,799


2005
01:09:02,799 --> 01:09:05,439
더 많은 보상과 덜 보상적인 무기 사이의 엡실론 차이

2006
01:09:05,439 --> 01:09:06,880
를 수정했습니다.  그들은

2007
01:09:06,880 --> 01:09:08,719
암의 수가 그림 4에서 문제의 역학이 어떻게 해결되고 있는지와 어떻게 연관되어 있는지

2008
01:09:08,719 --> 01:09:10,319


2009
01:09:10,319 --> 01:09:13,520


2010
01:09:13,520 --> 01:09:15,759
탐구했습니다. 우리는

2011
01:09:15,759 --> 01:09:16,880
동적

2012
01:09:16,880 --> 01:09:19,679
변화 확률과 엡실론의

2013
01:09:19,679 --> 01:09:21,040
차이가

2014
01:09:21,040 --> 01:09:24,799
성능을 어떻게 변화시키는지 탐색할 수 있도록 암을 고정한

2015
01:09:24,799 --> 01:09:27,920
다음 음

2016
01:09:28,399 --> 01:09:31,120
좋습니다.

2017
01:09:32,158 --> 01:09:36,238
이제 음  좋아요. 다섯 번째 그림입니다.

2018
01:09:36,238 --> 01:09:39,439
어, 또 다른 비슷한 모양의

2019
01:09:39,439 --> 01:09:40,719
그림

2020
01:09:40,719 --> 01:09:44,319


2021
01:09:44,319 --> 01:09:46,560
입니다. 열에 대해 비슷한 행을 갖게 되므로 덜 변경되고 왼쪽으로 이동합니다.

2022
01:09:46,560 --> 01:09:48,640
오른쪽 열에서 lumn이 더 변경

2023
01:09:48,640 --> 01:09:49,759
되고 우리는

2024
01:09:49,759 --> 01:09:52,238
10 20 및 40으로 그림 3과 같은 팔의 수를 갖게 될

2025
01:09:52,238 --> 01:09:55,159
것이지만

2026
01:09:55,159 --> 01:09:58,080
non-stationary

2027
01:09:58,080 --> 01:10:02,480
어려움이 있을 것이고 문제의 어려움은

2028
01:10:02,480 --> 01:10:04,239
non-stationary라는 이점이 있습니다.

2029
01:10:04,239 --> 01:10:05,760
두 번째로 좋은 팔보다 두 번째로 좋은 팔

2030
01:10:05,760 --> 01:10:07,600
이 시간

2031
01:10:07,600 --> 01:10:11,120
에 따라 변합니다. 예, 그래서 엡실론이 다양합니다.

2032
01:10:11,120 --> 01:10:14,159
그렇습니다. 그래서

2033
01:10:14,159 --> 01:10:15,360
엡실론을 시간

2034
01:10:15,360 --> 01:10:17,760
으로 변경하고 기본 설정보다 정밀도를 람다로 고정하면

2035
01:10:17,760 --> 01:10:18,960


2036
01:10:18,960 --> 01:10:22,159
0.5가 되므로

2037
01:10:22,159 --> 01:10:22,880


2038
01:10:22,880 --> 01:10:25,440
다른 곳에서 사용하는 것과 다른 람다입니다.  일종의

2039
01:10:25,440 --> 01:10:26,080


2040
01:10:26,080 --> 01:10:28,880
표시는 그들이 선택한 변수 값

2041
01:10:28,880 --> 01:10:29,280


2042
01:10:29,280 --> 01:10:30,800


2043
01:10:30,800 --> 01:10:32,400
이 최신 기술을 능가하기 때문에 분명히 작동한다는 것을 의미하지만

2044
01:10:32,400 --> 01:10:34,159
여기서는 다른 변수를 선택했습니다.

2045
01:10:34,159 --> 01:10:37,040
예 파란색 0.5의 람다를

2046
01:10:37,040 --> 01:10:37,440


2047
01:10:37,440 --> 01:10:40,320
모든 전환 그래프에 사용했습니다. 오 예 그림 3

2048
01:10:40,320 --> 01:10:41,679
그림 4  그리고 그림 5.

2049
01:10:41,679 --> 01:10:43,679


2050
01:10:43,679 --> 01:10:45,360
전환에서 0.5로 변경했는데, 그 이유는 단지 최적화

2051
01:10:45,360 --> 01:10:46,400
되었지만 변수 최적화가 제대로 표시되지

2052
01:10:46,400 --> 01:10:48,800


2053
01:10:48,800 --> 01:10:50,000


2054
01:10:50,000 --> 01:10:53,199


2055
01:10:53,199 --> 01:10:55,440
않았기 때문입니다.  ive 추론 빨간 선

2056
01:10:55,440 --> 01:10:56,480
은 하단에

2057
01:10:56,480 --> 01:10:58,640
있고 후회율의 이러한 종류의

2058
01:10:58,640 --> 01:10:59,520
2차

2059
01:10:59,520 --> 01:11:02,800
증가가 없으므로

2060
01:11:02,800 --> 01:11:06,560
오른쪽의 동적 및

2061
01:11:06,560 --> 01:11:08,640
오른쪽 하단의 많은 팔에 대해서도 능동

2062
01:11:08,640 --> 01:11:09,840
추론이 잘 수행되는 것을 볼 수

2063
01:11:09,840 --> 01:11:13,120
있으므로 그림 3 4 및 5

2064
01:11:13,120 --> 01:11:16,080


2065
01:11:16,080 --> 01:11:17,600


2066
01:11:17,600 --> 01:11:20,800
최첨단 알고리즘을 능가하는 능동 추론에 대한 매우 매력적인 사례를 만들었

2067
01:11:20,800 --> 01:11:22,640
습니다. 정말 기쁩니다

2068
01:11:22,640 --> 01:11:24,719


2069
01:11:24,719 --> 01:11:26,400
. 토론으로 이동하여 토론과 마무리 메모에 대해

2070
01:11:26,400 --> 01:11:27,760
몇 분만 시간을 할애

2071
01:11:27,760 --> 01:11:30,640


2072
01:11:30,640 --> 01:11:31,440
한 다음  우리는

2073
01:11:31,440 --> 01:11:34,640
점 1과 점 2를 기대합니다.

2074
01:11:34,640 --> 01:11:37,280


2075
01:11:37,280 --> 01:11:38,000


2076
01:11:38,000 --> 01:11:40,719
그들이 이전에 언급한 것을 리허설함으로써 토론을 시작할 것입니다.

2077
01:11:40,719 --> 01:11:42,480
그들은 능동 추론을

2078
01:11:42,480 --> 01:11:43,920
2개의 최첨단 기계 학습

2079
01:11:43,920 --> 01:11:45,920
알고리즘과 베이지안 상한 신뢰

2080
01:11:45,920 --> 01:11:46,320
경계

2081
01:11:46,320 --> 01:11:48,400
및  문제

2082
01:11:48,400 --> 01:11:49,760
쌍의 알고리즘 쌍인 낙관적 톰슨 샘플링

2083
01:11:49,760 --> 01:11:52,159


2084
01:11:52,159 --> 01:11:53,679
고정 및 비정상

2085
01:11:53,679 --> 01:11:56,400
확률적 다중 무장 도적은

2086
01:11:56,400 --> 01:11:57,440


2087
01:11:57,440 --> 01:11:59,280
무엇보다도 그들의 기여도 w

2088
01:11:59,280 --> 01:12:00,960
대략적인 능동 추론

2089
01:12:00,960 --> 01:12:02,159
알고리즘

2090
01:12:02,159 --> 01:12:04,239
을 도입한 다음, 사용자가 정확하게 수행할 수 있는 만큼 다시 수행되고 있음을 보여주기 위해 몇 가지 검사를

2091
01:12:04,239 --> 01:12:05,440
수행하여

2092
01:12:05,440 --> 01:12:08,960


2093
01:12:08,960 --> 01:12:10,880


2094
01:12:10,880 --> 01:12:12,800
효율적이고 쉽게

2095
01:12:12,800 --> 01:12:15,280
고차원 문제로 확장할 수 있는 능동 추론 알고리즘을

2096
01:12:15,280 --> 01:12:17,920
도출하여 다음과 같이 묻습니다.

2097
01:12:17,920 --> 01:12:18,800


2098
01:12:18,800 --> 01:12:21,600
능동 추론을 적용하는 것이 멋지거나 유용하거나 중요할 수 있는 곳은 어디

2099
01:12:21,600 --> 01:12:22,800
입니까?

2100
01:12:22,800 --> 01:12:25,280
이에 대해 많은

2101
01:12:25,280 --> 01:12:26,159
생각이

2102
01:12:26,159 --> 01:12:27,920


2103
01:12:27,920 --> 01:12:29,920
있다는 것을 알고 있으며 더 많이 있을 것입니다.

2104
01:12:29,920 --> 01:12:32,880


2105
01:12:32,880 --> 01:12:34,719
해킹

2106
01:12:34,719 --> 01:12:37,600
챌린지 및 우리는 2021년

2107
01:12:37,600 --> 01:12:38,400


2108
01:12:38,400 --> 01:12:40,480
7월 말 또는 8월 초에 이에 대한 작업을 시작할 예정

2109
01:12:40,480 --> 01:12:42,320


2110
01:12:42,320 --> 01:12:44,719
이므로

2111
01:12:44,719 --> 01:12:46,080


2112
01:12:46,080 --> 01:12:49,280
비디오 게임 성능 챌린지에 능동적 추론을 적용

2113
01:12:49,280 --> 01:12:52,239
하는 데 관심이 있다면 협력 팀이 참가할 수 있기를 바랍니다.

2114
01:12:52,239 --> 01:12:54,080
이 도전

2115
01:12:54,080 --> 01:12:56,560
은

2116
01:12:56,560 --> 01:12:58,320
능동

2117
01:12:58,320 --> 01:12:59,600
추론이 무엇을

2118
01:12:59,600 --> 01:13:01,440
할 수 있는지 세계에 실제로 보여줄 멋진 기회가 될 것이지만 우리는 또한

2119
01:13:01,440 --> 01:13:02,840
저자와 모든

2120
01:13:02,840 --> 01:13:06,080
손님은 이와 같은

2121
01:13:06,080 --> 01:13:07,760


2122
01:13:07,760 --> 01:13:09,120


2123
01:13:09,120 --> 01:13:10,560
대략적인 능동 추론 유형

2124
01:13:10,560 --> 01:13:13,520
알고리즘을 사용하여 탐색하는 것이 흥미로울 수 있다고 생각하는 질문의 종류를 공유합니다.

2125
01:13:16,159 --> 01:13:18,880
여기

2126
01:13:18,880 --> 01:13:19,600


2127
01:13:19,600 --> 01:13:22,719
에 그림 2

2128
01:13:22,719 --> 01:13:26,159
에서 우리가 작은 사람에 대한 그런 종류의 후회를 보았을 때 그 음에 대해 다시 말해주는 정말 좋은 요점이 있습니다.

2129
01:13:26,159 --> 01:13:29,679


2130
01:13:29,679 --> 01:13:31,199


2131
01:13:31,199 --> 01:13:33,440


2132
01:13:33,440 --> 01:13:36,880
k가 10인 경우에 극도로 유감스러운 결정에 갇히게 된 에이전트의 비율이 10인 경우

2133
01:13:36,880 --> 01:13:40,560
에 대해 그들은 무엇이라고 말합니까?

2134
01:13:40,560 --> 01:13:42,560
놀랍게도

2135
01:13:42,560 --> 01:13:44,239
고정 적기

2136
01:13:44,239 --> 01:13:45,679
문제 그림 2의 경험적 알고리즘 비교

2137
01:13:45,679 --> 01:13:47,040
는 능동 추론

2138
01:13:47,040 --> 01:13:48,880
알고리즘이 점근적이지 않다는 것을 보여주었습니다

2139
01:13:48,880 --> 01:13:49,920


2140
01:13:49,920 --> 01:13:51,920
효율적인 누적 후회

2141
01:13:51,920 --> 01:13:53,280


2142
01:13:53,280 --> 01:13:56,480
는 대규모 시행의 한계에서 대수보다 빠르게 증가

2143
01:13:56,480 --> 01:13:58,000
했습니다. 즉,

2144
01:13:58,000 --> 01:14:00,320
모든 에이전트가 정신을 잃은 것은 아니지만 행동에 대한 이러한 원인을 손상

2145
01:14:00,320 --> 01:14:01,040


2146
01:14:01,040 --> 01:14:03,440
시키는 방식으로 그룹을 끌어내리고 있는

2147
01:14:03,440 --> 01:14:04,400


2148
01:14:04,400 --> 01:14:08,480


2149
01:14:08,480 --> 01:14:10,320
것 같습니다.  expl 사이

2150
01:14:10,320 --> 01:14:12,080


2151
01:14:12,080 --> 01:14:13,679
의 균형 매개변수 역할을 하는 기본 설정 람다에 대한 고정 사전 정밀도

2152
01:14:13,679 --> 01:14:16,320


2153
01:14:16,320 --> 01:14:19,120


2154
01:14:19,120 --> 01:14:19,920


2155
01:14:19,920 --> 01:14:22,480
탐색 및 활용 두 가지 모드가 아닌 매우 흥미로운 부분입니다. 그러면

2156
01:14:22,480 --> 01:14:24,080


2157
01:14:24,080 --> 01:14:25,520
전등 스위치처럼 한 방향으로 다른 방향으로 전환하는 매개변수가 생기

2158
01:14:25,520 --> 01:14:26,320


2159
01:14:26,320 --> 01:14:28,560
거나 하나의 극단적인 탐색 모드와

2160
01:14:28,560 --> 01:14:30,800
하나의 극단적인 공격이 있습니다.  모델에서 모드를

2161
01:14:30,800 --> 01:14:32,080
선택한 다음

2162
01:14:32,080 --> 01:14:34,239
활성 추론에서 둘 사이를 이동하는 조광기가 있을 것

2163
01:14:34,239 --> 01:14:35,360


2164
01:14:35,360 --> 01:14:38,480
입니다. 그런 종류의 노브는 실제로

2165
01:14:38,480 --> 01:14:40,080


2166
01:14:40,080 --> 01:14:43,760
기본 설정보다 우선하는 정밀도이므로 기본 설정이 없는

2167
01:14:43,760 --> 01:14:47,600
경우 기본 설정이 없는 경우

2168
01:14:47,600 --> 01:14:50,080
선호도에 대한 정확성 당신은 당신의 선호도에

2169
01:14:50,080 --> 01:14:51,679


2170
01:14:51,679 --> 01:14:53,600


2171
01:14:53,600 --> 01:14:55,600
대해 믿을 수 없을 정도로 정확하고 믿을 수 없을

2172
01:14:55,600 --> 01:14:57,920
정도로 정확한 사전

2173
01:14:57,920 --> 01:15:01,199
이 있다면 최대한 탐색적인 방식

2174
01:15:01,199 --> 01:15:03,840
으로 행동할 것입니다. 그러면 당신은

2175
01:15:03,840 --> 01:15:05,520
레스토랑이 두 개

2176
01:15:05,520 --> 01:15:08,239
있고 그 중 하나가 당신을 좋아하는 것처럼 매우 착취적인 방식으로 행동할 것입니다  60 알고

2177
01:15:08,239 --> 01:15:10,159
다른 하나 당신이 좋아하는 40

2178
01:15:10,159 --> 01:15:11,440
당신이 선호하는 것이 없다면 당신은

2179
01:15:11,440 --> 01:15:13,199
그들에게 갈 것입니다 50 50. 그것은 탐색과 비슷

2180
01:15:13,199 --> 01:15:15,360
하지만

2181
01:15:15,360 --> 01:15:17,360
당신이 선호하는 것보다 초고 정밀도를 가지고 있다면

2182
01:15:17,360 --> 01:15:18,960
당신은 항상  알고리즘의

2183
01:15:18,960 --> 01:15:19,280


2184
01:15:19,280 --> 01:15:21,199


2185
01:15:21,199 --> 01:15:22,800


2186
01:15:22,800 --> 01:15:24,960
성능이 해당 매개변수에 따라 어떻게 달라지는지 분석한

2187
01:15:24,960 --> 01:15:27,120


2188
01:15:27,120 --> 01:15:28,800
결과 시간이 지남에 따라 최상의 성능을 제공하는 매개변수 값이

2189
01:15:28,800 --> 01:15:31,600
감소하여

2190
01:15:31,600 --> 01:15:33,199
이 매개변수가 적응 및 감소해야 함을 시사하는 것으로 나타났습니다.

2191
01:15:33,199 --> 01:15:35,280
시간이 지남에 따라 탐색의 필요성

2192
01:15:35,280 --> 01:15:37,520
이 감소

2193
01:15:37,520 --> 01:15:40,320
하므로 기본 설정보다 낮은 정밀도

2194
01:15:40,320 --> 01:15:41,440


2195
01:15:41,440 --> 01:15:44,640
로 시작한 다음

2196
01:15:44,640 --> 01:15:46,800
배우고 업데이트하여 결국

2197
01:15:46,800 --> 01:15:49,040
정밀도를 높일 수 있습니다. 나중에

2198
01:15:49,040 --> 01:15:50,800


2199
01:15:50,800 --> 01:15:52,480
간단하고 널리 사용되는 붕괴 방식으로 상황을 해결하려고 시도

2200
01:15:52,480 --> 01:15:53,760
하지만 성공하지 못합니다.

2201
01:15:53,760 --> 01:15:55,679
시간의 대수 그래서 당신은 시행 횟수에 대해 하나

2202
01:15:55,679 --> 01:15:57,600


2203
01:15:57,600 --> 01:16:00,080
를 아는 것처럼 정밀도를 시간의 함수로 직접 만듭니다.

2204
01:16:00,080 --> 01:16:00,960


2205
01:16:00,960 --> 01:16:02,880
그런 종류

2206
01:16:02,880 --> 01:16:04,159
의 것은 시행

2207
01:16:04,159 --> 01:16:05,600
횟수에 따라 조정되는 함수

2208
01:16:05,600 --> 01:16:07,280
이므로 여기에서

2209
01:16:07,280 --> 01:16:10,400
다음의 로그로 규모를 조정합니다.

2210
01:16:10,400 --> 01:16:12,000
이것은 단순한

2211
01:16:12,000 --> 01:16:13,679
관계가 아니며 적절한 이론적

2212
01:16:13,679 --> 01:16:15,360


2213
01:16:15,360 --> 01:16:17,760
분석이 sch  eme가 존재

2214
01:16:17,760 --> 01:16:20,239
하기 때문에

2215
01:16:20,239 --> 01:16:20,880
우리가 어떻게

2216
01:16:20,880 --> 01:16:23,440
한 수준을 되돌릴 것인가와 같이 꽤 흥미롭습니다. 우리는

2217
01:16:23,440 --> 01:16:25,520
능동적 추론 아키텍처

2218
01:16:25,520 --> 01:16:28,000
가 불확실성 하에서 학습을 모델링하는 정말 생산적인 방법이 될 것이라고 생각

2219
01:16:28,000 --> 01:16:30,239


2220
01:16:30,239 --> 01:16:32,080
하지만 우리는 또한 문제

2221
01:16:32,080 --> 01:16:33,440
를 수준 높은 수준으로 밀어올리고 있습니다.

2222
01:16:33,440 --> 01:16:36,960
괜찮은 방법  불확실해야 하며 시간이 지남에 따라 이동하는 선호도에

2223
01:16:36,960 --> 01:16:39,360
대한 불확실성을 어떻게 변경해야 합니까?

2224
01:16:39,360 --> 01:16:40,800


2225
01:16:40,800 --> 01:16:45,360


2226
01:16:45,360 --> 01:16:48,640


2227
01:16:48,640 --> 01:16:52,239
마지막으로 한 가지 생각은 비정상 상태

2228
01:16:52,239 --> 01:16:54,400
이므로 동적 전환 적기

2229
01:16:54,400 --> 01:16:57,120
능동 추론 알고리즘은 일반적으로

2230
01:16:57,120 --> 01:16:58,560
베이지안 신뢰 상한을 능가

2231
01:16:58,560 --> 01:17:00,960
하고  낙관적

2232
01:17:00,960 --> 01:17:02,400
톰슨 샘플링

2233
01:17:02,400 --> 01:17:04,159
이것은 능동

2234
01:17:04,159 --> 01:17:06,000
추론 프레임워크가 지속적인 적응

2235
01:17:06,000 --> 01:17:08,159
을 필요로 하는 최적화 문제에 대한 좋은 솔루션을 제공할 수 있다는 증거를

2236
01:17:08,159 --> 01:17:11,040


2237
01:17:11,040 --> 01:17:13,040
제공합니다 능동 추론은

2238
01:17:13,040 --> 01:17:14,159


2239
01:17:14,159 --> 01:17:16,880
정보를 얻는 가장 효율적인 방법을 제공

2240
01:17:16,880 --> 01:17:17,840
하며 알고리즘의 이러한 속성은

2241
01:17:17,840 --> 01:17:21,679
고정되지 않은 설정

2242
01:17:21,679 --> 01:17:23,440
쿨 포인트에서 효과가 있습니다  작가의 관점을 듣는 것은 굉장할 것

2243
01:17:23,440 --> 01:17:25,760
입니다

2244
01:17:25,760 --> 01:17:28,239
그렇다면 어떻게 능동 추론

2245
01:17:28,239 --> 01:17:29,360
프레임워크 알고리즘

2246
01:17:29,360 --> 01:17:32,560
을 머신 러닝과 더 광범위하게 비교할

2247
01:17:32,560 --> 01:17:35,520
수 있습니까? 그리고 특히 엡실론 탐욕이 아닌

2248
01:17:35,520 --> 01:17:36,960
정보에 입각한

2249
01:17:36,960 --> 01:17:40,000
채집이 도움이

2250
01:17:40,000 --> 01:17:42,960
되지 않는 문제의 경우

2251
01:17:42,960 --> 01:17:44,159
때때로 최고를

2252
01:17:44,159 --> 01:17:45,679


2253
01:17:45,679 --> 01:17:49,360
외면하고 톰슨 샘플링뿐만 아니라

2254
01:17:49,360 --> 01:17:51,199
무작위로 선택합니다.  학습하는 동안 수익에

2255
01:17:51,199 --> 01:17:53,600
대한 절충안

2256
01:17:53,600 --> 01:17:56,480
을 수행하기 위해 더 많은 정보에 입각하거나

2257
01:17:56,480 --> 01:17:57,360
경험적으로

2258
01:17:57,360 --> 01:18:00,480
더 나은 성과 계획을 가질 수 있습니다.

2259
01:18:00,480 --> 01:18:01,440


2260
01:18:01,440 --> 01:18:03,440


2261
01:18:03,440 --> 01:18:04,880
학습 중 수익

2262
01:18:04,880 --> 01:18:05,360
이

2263
01:18:05,360 --> 01:18:08,320
최적의 학습을 의미하거나 학습 중이라는 의미는 아닙니다.  최적의 수익

2264
01:18:08,320 --> 01:18:08,880
또는

2265
01:18:08,880 --> 01:18:12,000
균형을 어떻게 맞출 것인가? 머신 러닝 커뮤니티에서 점점 더 많은 사람들이 이러한 결과에 관심을

2266
01:18:12,000 --> 01:18:13,440
갖기 시작함에 따라 향후 몇 년 동안 옥타브 추론이 강력한 경쟁자가 될 것 같습니다.

2267
01:18:13,440 --> 01:18:15,679


2268
01:18:15,679 --> 01:18:18,239


2269
01:18:18,239 --> 01:18:19,840


2270
01:18:19,840 --> 01:18:20,719


2271
01:18:20,719 --> 01:18:22,560


2272
01:18:22,560 --> 01:18:23,760


2273
01:18:23,760 --> 01:18:25,280
이 작가들과 다른 사람들이

2274
01:18:25,280 --> 01:18:27,280
하는 일에 대해 이해하기 시작합니다.

2275
01:18:27,280 --> 01:18:30,480


2276
01:18:30,480 --> 01:18:31,280


2277
01:18:31,280 --> 01:18:33,040
우리 모델에서 더 많은 매개변수

2278
01:18:33,040 --> 01:18:34,800
와 수십억 개의 매개변수

2279
01:18:34,800 --> 01:18:35,679


2280
01:18:35,679 --> 01:18:37,520


2281
01:18:37,520 --> 01:18:39,440
를 알고 컴퓨터의 더 크고 더 큰 네트워크에서 훈련

2282
01:18:39,440 --> 01:18:42,320


2283
01:18:42,320 --> 01:18:44,800
하는 방법을 배우고 이기는

2284
01:18:44,800 --> 01:18:47,159
것을 선호하는 호기심 많은 에이전트가 있다면 1층 재해석과 같습니다.

2285
01:18:47,159 --> 01:18:48,320


2286
01:18:48,320 --> 01:18:51,360
활성 추론 및

2287
01:18:51,360 --> 01:18:52,400


2288
01:18:52,400 --> 01:18:55,840


2289
01:18:55,840 --> 01:18:56,880
기계 학습

2290
01:18:56,880 --> 01:18:58,800
커뮤니티 및 분야가 어디로 향하고

2291
01:18:58,800 --> 01:19:00,080


2292
01:19:00,080 --> 01:19:02,640
있는지에 대한 저자의 견해를 듣는 것은 우리에게 확실히 유익한 정보가 될

2293
01:19:02,640 --> 01:19:05,120
것이라고 생각합니다.

2294
01:19:05,120 --> 01:19:07,199
파란색에 대해 어떻게 생각

2295
01:19:07,199 --> 01:19:09,199
하세요?

2296
01:19:09,199 --> 01:19:12,159
우리가 실제로 배우고 있는 것과 같은 자동차 문제는 바로 이기는

2297
01:19:12,159 --> 01:19:13,520


2298
01:19:13,520 --> 01:19:15,600
것입니다. 탐험해야 하는

2299
01:19:15,600 --> 01:19:17,520
경우 더 높이 올라가고 싶고 언덕

2300
01:19:17,520 --> 01:19:19,440
의 반대편으로 다시 올라갈 수 있도록 언덕을 오르고 싶은

2301
01:19:19,440 --> 01:19:20,960
경우와 같이

2302
01:19:20,960 --> 01:19:23,120
플래그는 다른 문제가

2303
01:19:23,120 --> 01:19:24,320


2304
01:19:24,320 --> 01:19:27,360
있는 것과 마찬가지로 탐험

2305
01:19:27,360 --> 01:19:29,199
에서 분리된 전과 결합되지 않은 보상과 같은 보상을 가지고 있지는 않습니다.

2306
01:19:29,199 --> 01:19:32,560
그래서 저는 그것에

2307
01:19:32,560 --> 01:19:34,159
대해 생각하고 있습니다. 그리고 저는 d  위대한 질문을

2308
01:19:34,159 --> 01:19:36,800
이기는 학습이 어디에 있는지 모릅니다.

2309
01:19:36,800 --> 01:19:37,760


2310
01:19:37,760 --> 01:19:39,120
거의

2311
01:19:39,120 --> 01:19:41,280
산악 자동차와 같습니다. 고도

2312
01:19:41,280 --> 01:19:43,840
는 어떤 의미에서 보상 휴리스틱

2313
01:19:43,840 --> 01:19:45,600
입니다. 언덕 꼭대기에 도달하기를 원하므로

2314
01:19:45,600 --> 01:19:46,960
고도가 갈 길인 것처럼 보입니다.

2315
01:19:46,960 --> 01:19:48,880
하지만 문제가 설정되는 방식으로

2316
01:19:48,880 --> 01:19:50,239


2317
01:19:50,239 --> 01:19:52,960
경계를 최적화할 수도

2318
01:19:52,960 --> 01:19:53,679


2319
01:19:53,679 --> 01:19:56,800
있고 제가 경계를 측면으로 더 확장하려고 한다고 말할 수도 있습니다.

2320
01:19:56,800 --> 01:19:57,520


2321
01:19:57,520 --> 01:19:59,280
오 예, 물론 높이가 변하고

2322
01:19:59,280 --> 01:20:01,280
있습니다. 우리가 산에 있다는 것을

2323
01:20:01,280 --> 01:20:05,440
알지만 특히 경우에 따라  우리가

2324
01:20:05,440 --> 01:20:06,800


2325
01:20:06,800 --> 01:20:09,920
혁신이나 다른 영역과 같은 탐색에 집중하는 곳

2326
01:20:09,920 --> 01:20:11,440
에서는 능동

2327
01:20:11,440 --> 01:20:13,520
추론이 얼마나 잘 수행될 수 있는지 생각해 보는 것이 좋습니다.

2328
01:20:13,520 --> 01:20:15,840
따라서

2329
01:20:15,840 --> 01:20:16,719
저자

2330
01:20:16,719 --> 01:20:20,639
와 우리를 위한 다음 단계는 다중 무장 도적

2331
01:20:20,639 --> 01:20:22,560
의 맥락에서 능동 추론을 조사하는 중요한 다음 단계입니다.

2332
01:20:22,560 --> 01:20:24,159


2333
01:20:24,159 --> 01:20:26,000


2334
01:20:26,000 --> 01:20:27,520


2335
01:20:27,520 --> 01:20:29,280
고정

2336
01:20:29,280 --> 01:20:31,600
적기 문제에 대한 누적 후회에

2337
01:20:31,600 --> 01:20:32,800
대한 이론적 한계를 설정

2338
01:20:32,800 --> 01:20:35,280


2339
01:20:35,280 --> 01:20:36,320
하고 있습니다.

2340
01:20:36,320 --> 01:20:39,040
처음에 예상되었으며 이러한 이론적 연구의 핵심 부분은

2341
01:20:39,040 --> 01:20:40,560


2342
01:20:40,560 --> 01:20:42,400


2343
01:20:42,400 --> 01:20:44,639
해당 람다 매개변수에 대한 사운드 감쇠 방식을 고안할 수 있는지 여부를 조사하는

2344
01:20:44,639 --> 01:20:46,000


2345
01:20:46,000 --> 01:20:49,199
것이므로 표준 고정 적기의 모든 인스턴스에

2346
01:20:49,199 --> 01:20:51,920
대해 증명할 수 있는 기본 설정보다 정밀도를 얼마나 빨리 변경해야

2347
01:20:51,920 --> 01:20:53,040


2348
01:20:53,040 --> 01:20:54,719


2349
01:20:54,719 --> 01:20:56,639


2350
01:20:56,639 --> 01:20:58,159
하는지를 조사하는 것입니다.  그것이 우리가 가장 좋아하는 질문을 가능하게 하는 것은

2351
01:20:58,159 --> 01:21:00,159


2352
01:21:00,159 --> 01:21:02,080


2353
01:21:02,080 --> 01:21:03,520


2354
01:21:03,520 --> 01:21:06,719
점근적 효율성을 달성할 수 있는 새로운 능동 추론 영감 알고리즘의 개발로 이어질 것입니다.

2355
01:21:06,719 --> 01:21:08,320
이러한 이론적 경계는 또한

2356
01:21:08,320 --> 01:21:10,400


2357
01:21:10,400 --> 01:21:12,080
능동 추론 알고리즘을 후회 경계가 알려진

2358
01:21:12,080 --> 01:21:14,000
이미 확립된 밴드 알고리즘과 더 엄격하게 비교할 수 있게 해줍니다.

2359
01:21:14,000 --> 01:21:16,800


2360
01:21:16,800 --> 01:21:18,719
우리는 잠재적으로

2361
01:21:18,719 --> 01:21:20,400


2362
01:21:20,400 --> 01:21:23,440
여기에서 경험적으로 테스트한 설정을 넘어 일반화할 수 있을 것입니다. 미래의

2363
01:21:23,440 --> 01:21:23,920
작업

2364
01:21:23,920 --> 01:21:26,000
은 후회 분석

2365
01:21:26,000 --> 01:21:28,800


2366
01:21:28,800 --> 01:21:30,800
보다 더 적절할 수 있는 능동적 추론의 정보 이론적 분석도 고려할 수 있습니다.

2367
01:21:30,800 --> 01:21:33,280
후회 분석

2368
01:21:33,280 --> 01:21:36,480
과 같은 멋진 아이디어도

2369
01:21:36,480 --> 01:21:40,480
성능 지향적이었습니다.

2370
01:21:40,480 --> 01:21:43,520
당신은

2371
01:21:43,520 --> 01:21:45,040


2372
01:21:45,040 --> 01:21:48,560


2373
01:21:48,560 --> 01:21:51,199
최적과 당신이 한 것 사이의 성능 차이를 기반으로 후회를 계산하고 있지만

2374
01:21:51,199 --> 01:21:52,159
그것을 보는 또 다른 방법

2375
01:21:52,159 --> 01:21:55,120
은 정보 이론을 사용하고

2376
01:21:55,120 --> 01:21:56,000


2377
01:21:56,000 --> 01:21:58,320
아마도

2378
01:21:58,320 --> 01:21:59,360
시간이 지남에 따라 얻은 정보의 함수

2379
01:21:59,360 --> 01:22:02,159
로 보는 것입니다.

2380
01:22:02,159 --> 01:22:03,360


2381
01:22:03,360 --> 01:22:06,320
전체 프로젝트

2382
01:22:06,320 --> 01:22:08,639
가 성능, 보상 및 가치 측면에서 구성되어 있다면

2383
01:22:08,639 --> 01:22:10,400


2384
01:22:10,400 --> 01:22:12,960


2385
01:22:12,960 --> 01:22:14,080


2386
01:22:14,080 --> 01:22:16,080
탐사가 항상 성공적인 착취의

2387
01:22:16,080 --> 01:22:17,760
관점에서 다루어져야 하기 때문에 배트에서 착취를 선호하는 것과 같기 때문에 우리는 탐색에

2388
01:22:17,760 --> 01:22:18,719


2389
01:22:18,719 --> 01:22:21,280


2390
01:22:21,280 --> 01:22:22,159
중점을 둡니다.

2391
01:22:22,159 --> 01:22:24,320
왜냐하면 나중에  우리는 공정하게 적용할 수

2392
01:22:24,320 --> 01:22:26,320


2393
01:22:26,320 --> 01:22:27,920
있지만 후회 성능 분석이 아닌 정보

2394
01:22:27,920 --> 01:22:30,000
이론적인

2395
01:22:30,000 --> 01:22:32,480
분석

2396
01:22:32,480 --> 01:22:35,520
이 있을 때 탐색을 위한 탐색을 할 수 있는 방법이 있을 수 있습니다

2397
01:22:35,520 --> 01:22:37,920


2398
01:22:37,920 --> 01:22:40,000


2399
01:22:40,000 --> 01:22:43,440


2400
01:22:43,440 --> 01:22:47,280
.  놀라움의 측면에서 uh

2401
01:22:47,280 --> 01:22:49,199
놀라움 최소화 맞습니다.

2402
01:22:49,199 --> 01:22:51,040


2403
01:22:51,040 --> 01:22:52,000
놀라움을

2404
01:22:52,000 --> 01:22:54,000
최소화하는 것

2405
01:22:54,000 --> 01:22:55,760
주식 시장 문제와 같은 문제에 대해 생각해 보세요. 바로 이와 같은 문제

2406
01:22:55,760 --> 01:22:57,360
는 스위칭 산적

2407
01:22:57,360 --> 01:22:58,239
문제와 매우 흡사합니다.

2408
01:22:58,239 --> 01:23:00,080
모든 것이 항상 변하는 것처럼

2409
01:23:00,080 --> 01:23:01,360
잠시 동안은 똑같습니다.

2410
01:23:01,360 --> 01:23:03,520
마치 당신이 당신의 주식인 것처럼 승리할 주식입니다.

2411
01:23:03,520 --> 01:23:04,560


2412
01:23:04,560 --> 01:23:06,800
따라서 sp 500에서 벗어날 때 놀랐다는 것을 아는 것처럼

2413
01:23:06,800 --> 01:23:08,239
sp

2414
01:23:08,239 --> 01:23:10,639
500으로 추적하려고

2415
01:23:10,639 --> 01:23:12,960


2416
01:23:12,960 --> 01:23:15,520


2417
01:23:15,520 --> 01:23:17,199
하고 정보 이론 분석에 대해 한 가지 더 생각

2418
01:23:17,199 --> 01:23:19,199


2419
01:23:19,199 --> 01:23:21,280
하고 다른 것을 말할 수 있는 방법에서 벗어날 때 놀라움이 발생합니다.

2420
01:23:21,280 --> 01:23:22,719
후회하는 것보다

2421
01:23:22,719 --> 01:23:25,440
레스토랑 선택으로 돌아가자. 그래서

2422
01:23:25,440 --> 01:23:27,360
우리는 통제된 참신함과 같은 이야기를 자주 듣는다.

2423
01:23:27,360 --> 01:23:28,159


2424
01:23:28,159 --> 01:23:30,159
당신은 놀라움을 원하지만 너무

2425
01:23:30,159 --> 01:23:31,199
놀라지

2426
01:23:31,199 --> 01:23:33,440
않기 때문에 이것은

2427
01:23:33,440 --> 01:23:35,199
사람들이 좋아하는 레스토랑을 좋아할 수 있는 이유

2428
01:23:35,199 --> 01:23:36,159


2429
01:23:36,159 --> 01:23:38,480
에

2430
01:23:38,480 --> 01:23:39,280
대한 설명을 제공합니다.

2431
01:23:39,280 --> 01:23:43,040


2432
01:23:43,040 --> 01:23:44,960
가장 보람 있는 레스토랑

2433
01:23:44,960 --> 01:23:46,960
이 될 가능성이 있는 60과 같은 보상을 최대화하는 맥락은 불확실성을 줄이려고 노력하는 것과 같을 수

2434
01:23:46,960 --> 01:23:48,159


2435
01:23:48,159 --> 01:23:50,159
있으므로 장소를 선택할 가능성이 높습니다.  다른

2436
01:23:50,159 --> 01:23:51,199


2437
01:23:51,199 --> 01:23:54,320


2438
01:23:54,320 --> 01:23:56,480
음식을 선택하거나 항상 주문하는 식사를 선택할 수도

2439
01:23:56,480 --> 01:23:57,520


2440
01:23:57,520 --> 01:24:00,480
있지만 우리가 제공

2441
01:24:00,480 --> 01:24:02,960


2442
01:24:02,960 --> 01:24:06,080
하는 보상을 최대화하여 그 자체가 아니라 불확실성을 줄임으로써 선택을 주도한 것과 같습니다.

2443
01:24:06,080 --> 01:24:07,440


2444
01:24:07,440 --> 01:24:10,000


2445
01:24:10,000 --> 01:24:11,199
가치 주도

2446
01:24:11,199 --> 01:24:14,000
강화 학습 보상 학습

2447
01:24:14,000 --> 01:24:16,000
과 암묵적 후회의 차이로 돌아오십시오.

2448
01:24:16,000 --> 01:24:19,440
보상에 대한 후회와

2449
01:24:19,440 --> 01:24:20,880


2450
01:24:20,880 --> 01:24:23,440
우리를 완전히 다른 공간에 두는 불확실성의 감소

2451
01:24:23,440 --> 01:24:25,280
그렇습니다. 우리는

2452
01:24:25,280 --> 01:24:27,440
정보 흐름 영역의 전체 물리학에 들어갈 수 있습니다.

2453
01:24:27,440 --> 01:24:29,120
여기서 우리는 실용적인

2454
01:24:29,120 --> 01:24:32,480
음 직선 구성 요소를 얻은 다음

2455
01:24:32,480 --> 01:24:34,960
솔레노이드 흐름 iso 등고선을 얻습니다. 예

2456
01:24:34,960 --> 01:24:36,960
우리는 정보 이론의 전체 영역에 액세스합니다.

2457
01:24:36,960 --> 01:24:39,360


2458
01:24:39,360 --> 01:24:40,560
불확실성의 감소 세계

2459
01:24:40,560 --> 01:24:43,600
하지만 또한 우리는 행동

2460
01:24:43,600 --> 01:24:44,880
에 대한 다른 설명에서 질적으로 다른 이야기

2461
01:24:44,880 --> 01:24:46,560


2462
01:24:46,560 --> 01:24:48,719
를 얻습니다.

2463
01:24:48,719 --> 01:24:50,719


2464
01:24:50,719 --> 01:24:52,320
왜 누군가가 그 식당에 갔는지, 또는

2465
01:24:52,320 --> 01:24:54,480


2466
01:24:54,480 --> 01:24:57,600
시간이 많이 들 때 한 가지를 주문했는지에 대한 보상을 극대화하는 이유를 이해할 필요가 없습니다.  일종의 최대화에 대해 설명할 필요 없이

2467
01:24:57,600 --> 01:24:58,000


2468
01:24:58,000 --> 01:25:00,159
불확실성 감소 및 사전

2469
01:25:00,159 --> 01:25:01,760
선호도

2470
01:25:01,760 --> 01:25:04,080
이해로 단독으로 존재

2471
01:25:04,080 --> 01:25:06,239


2472
01:25:06,239 --> 01:25:09,120
합니다. 마지막

2473
01:25:09,120 --> 01:25:10,800
슬라이드를

2474
01:25:10,800 --> 01:25:15,040
뒤집고 알렉스 v가 쓴 멋진 질문

2475
01:25:15,040 --> 01:25:18,639
이 있습니다.

2476
01:25:18,639 --> 01:25:21,360
인식적 가치와

2477
01:25:21,360 --> 01:25:23,360
실용주의적 가치에 대한 착취에 대해

2478
01:25:23,360 --> 01:25:25,199
나는 그것이 당신이 방금 말한 것과 관련이 있다고 생각합니다.

2479
01:25:25,199 --> 01:25:26,800


2480
01:25:26,800 --> 01:25:29,520
음, 그것은 우리

2481
01:25:29,520 --> 01:25:30,639


2482
01:25:30,639 --> 01:25:32,880


2483
01:25:32,880 --> 01:25:34,800


2484
01:25:34,800 --> 01:25:35,760


2485
01:25:35,760 --> 01:25:38,400
가 이 인식론적 또는  지식

2486
01:25:38,400 --> 01:25:39,600
획득 구성 요소

2487
01:25:39,600 --> 01:25:41,920
및 이 화용적 또는 기능적

2488
01:25:41,920 --> 01:25:42,639
구성 요소

2489
01:25:42,639 --> 01:25:44,960
이므로 인식론은 학습과 같

2490
01:25:44,960 --> 01:25:45,920
으며 화용론

2491
01:25:45,920 --> 01:25:49,280
적 수익은 획득하는 동안 학습하는

2492
01:25:49,280 --> 01:25:50,159


2493
01:25:50,159 --> 01:25:53,360


2494
01:25:53,360 --> 01:25:55,679


2495
01:25:55,679 --> 01:25:57,199


2496
01:25:57,199 --> 01:26:00,320
것입니다.  우리가 선택한 정책

2497
01:26:00,320 --> 01:26:03,280


2498
01:26:03,280 --> 01:26:04,880


2499
01:26:04,880 --> 01:26:08,400
에 따라 예상되는 자유 에너지 최소화를 결정하기 때문에 실용적으로 가치 있는 정보를

2500
01:26:08,400 --> 01:26:11,120
얻습니다.

2501
01:26:11,120 --> 01:26:12,639


2502
01:26:12,639 --> 01:26:15,760


2503
01:26:15,760 --> 01:26:18,480
두 가지를 함께 살펴보는 기능을 기반으로 하는 정책

2504
01:26:18,480 --> 01:26:18,880


2505
01:26:18,880 --> 01:26:21,199
은 우리가 괜찮다고 생각하여 탐색과 활용을 재고하는 방법 중 하나입니다.

2506
01:26:21,199 --> 01:26:23,840


2507
01:26:23,840 --> 01:26:26,480


2508
01:26:26,480 --> 01:26:27,520


2509
01:26:27,520 --> 01:26:29,920


2510
01:26:29,920 --> 01:26:31,520


2511
01:26:31,520 --> 01:26:33,040
새가 할 수 있는 두 가지 행동인

2512
01:26:33,040 --> 01:26:34,480


2513
01:26:34,480 --> 01:26:36,320
것처럼 여기에서 우리가 하는

2514
01:26:36,320 --> 01:26:38,719


2515
01:26:38,719 --> 01:26:40,880
것은 때때로 당신이 더 착취적인 행동을 하고 싶고,

2516
01:26:40,880 --> 01:26:41,920


2517
01:26:41,920 --> 01:26:44,159
또 다른 한편으로는 더 탐색적인 행동을

2518
01:26:44,159 --> 01:26:45,600
하고 싶다는 생각을 하고 있다는 것입니다.

2519
01:26:45,600 --> 01:26:48,320
전체 스펙트럼이 서로 다른 정책으로 존재할 수 있는 정책이 주어지면

2520
01:26:48,320 --> 01:26:49,679


2521
01:26:49,679 --> 01:26:53,199
각 정책

2522
01:26:53,199 --> 01:26:56,719
이 인식론적 및 실용적인

2523
01:26:56,719 --> 01:27:00,480
이익에 어떻게 기여하고 어떤 정책

2524
01:27:00,480 --> 01:27:02,639
이

2525
01:27:02,639 --> 01:27:03,760
두 가지를 가장

2526
01:27:03,760 --> 01:27:06,639
잘 조합할 수 있는지

2527
01:27:06,639 --> 01:27:07,920
두 가지를 모두 극대화하는 전략이 있을 수 있습니다.

2528
01:27:07,920 --> 01:27:09,280


2529
01:27:09,280 --> 01:27:10,159
어느 쪽도 최대화하지 않고

2530
01:27:10,159 --> 01:27:11,760
있지만 둘 중 하나만 보고 있다면

2531
01:27:11,760 --> 01:27:14,000
어

2532
01:27:14,000 --> 01:27:15,360
, 빈약한 조합과 같은 것을 선택할 수

2533
01:27:15,360 --> 01:27:17,040


2534
01:27:17,040 --> 01:27:19,120
있으므로 완벽한 예입니다.  아시다시피

2535
01:27:19,120 --> 01:27:20,239


2536
01:27:20,239 --> 01:27:23,199
귀하의 정책은

2537
01:27:23,199 --> 01:27:24,480


2538
01:27:24,480 --> 01:27:26,880
놀라움을 최소화하는 보상의 이전 기회를 기반으로 하므로

2539
01:27:26,880 --> 01:27:29,679


2540
01:27:29,679 --> 01:27:31,840
전에 가본 적이 없는 레스토랑에서 한 번도 먹어본 적이 없는 식사를 하지 않겠다는 정책이

2541
01:27:31,840 --> 01:27:33,360
있습니다.

2542
01:27:33,360 --> 01:27:33,920


2543
01:27:33,920 --> 01:27:35,199
나는 내가 무엇을 하고 있는지 잘 모르기

2544
01:27:35,199 --> 01:27:37,040
때문에 좋아

2545
01:27:37,040 --> 01:27:39,040
하는 식당에서 새로운 식사를 주문하거나 새로운 식당에서 익숙한 식사를 주문하는 것이 내 정책이 될 것입니다.

2546
01:27:39,040 --> 01:27:40,560


2547
01:27:40,560 --> 01:27:43,760


2548
01:27:43,760 --> 01:27:45,840
그래서 그것은

2549
01:27:45,840 --> 01:27:46,960


2550
01:27:46,960 --> 01:27:50,239
그 예시를 계속 잘 이어나가기 위한 정책과 같을

2551
01:27:50,239 --> 01:27:54,080
것입니다. 재미있는

2552
01:27:54,080 --> 01:27:56,800
토론이군요. 능동 추론과 베이지안 통계 기계 학습에 익숙한 사람들에게 이것이 유용하기를 바랍니다.

2553
01:27:56,800 --> 01:27:57,600


2554
01:27:57,600 --> 01:28:01,040


2555
01:28:01,040 --> 01:28:03,679


2556
01:28:03,679 --> 01:28:04,719


2557
01:28:04,719 --> 01:28:07,760


2558
01:28:07,760 --> 01:28:08,159


2559
01:28:08,159 --> 01:28:10,320
전체 프로젝트를 진행하는 데 정말 도움

2560
01:28:10,320 --> 01:28:12,560
이 됩니다.

2561
01:28:12,560 --> 01:28:13,199
이해

2562
01:28:13,199 --> 01:28:15,040
가 되는 부분과 그렇지 않은 부분, 더 탐색하고 싶은

2563
01:28:15,040 --> 01:28:16,960


2564
01:28:16,960 --> 01:28:19,199


2565
01:28:19,199 --> 01:28:21,600
부분

2566
01:28:21,600 --> 01:28:24,480
은 배경이 다른 사람들을 환영함으로써 우리

2567
01:28:24,480 --> 01:28:25,679


2568
01:28:25,679 --> 01:28:27,920
앙상블이 이러한 학제 간 영역에서 진행되는 방식이라고 생각합니다.  당신이 정말로 친숙하든 그렇지 않든

2569
01:28:27,920 --> 01:28:30,159


2570
01:28:30,159 --> 01:28:32,560
라이브 토론에 참여하거나 질문

2571
01:28:32,560 --> 01:28:33,840


2572
01:28:33,840 --> 01:28:37,199
을 하거나 다른 방법으로 참여하는 것을 전적으로 환영

2573
01:28:37,199 --> 01:28:39,440


2574
01:28:39,440 --> 01:28:41,280
합니다. 슬라이드 준비와 이

2575
01:28:41,280 --> 01:28:44,080
대화에 대한 멋진 도움에 대해 blue에게 감사드립니다. 그리고 우리는 모두를 볼 것입니다.

2576
01:28:44,080 --> 01:28:45,760
다른 시간

2577
01:28:45,760 --> 01:28:52,639
안녕

