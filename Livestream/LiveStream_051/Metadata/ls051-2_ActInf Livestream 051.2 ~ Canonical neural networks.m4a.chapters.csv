start	end	startTime	summary	headline	gist
32290	76090	00:32	This is ActInf Livestream, number 51.28, November 9, 2022. We're a participatory online institute that is practicing applied active inference. All backgrounds and perspectives are welcome, and we'll be following video etiquette for live streams. Please provide us feedback so we can improve our work.	ActInf is a participatory online institute that is practicing applied active inference	Livestream
77070	199760	01:17	Canonical neural networks perform active inference from 2022. We're in our third discussion on the paper. Today we're going to cover some empirical details, some implications, connect some more dots. Thanks again to Kuya for joining these discussions.	Canonical neural networks perform active inference from 2022	Canary Network Inactive Inference
203350	358834	03:23	The paper aims to characterize the dynamics and plasticity of canonical neural network in terms of Bayesian inference. Once we translate that dynamics in. terms of Beijing ants, we can align quantities in Beijing parents for any biological quantities. This enables us to lend the experiment ambiguity to the neural network dynamics and architecture.	One representation is in equation one with loss function of a neural network and free energy	Neural Network dynamics and plasticity under Bayesian inference
359032	973670	05:59	There is a clear parallel between the functional structure or those components in variation and free energy and the component in neural network cost function. It speaks to a sort of identity between those two different expressions. But its correlation to neural network expression is not very clear in general.	There is a clear parallel between variational free energy and neural network cost function	Neural network and the variational free energy
974750	2297336	16:14	So what does it mean for an artificial or for a biological neuron to have activity dynamics or activity context? That justifies it being described as playing like a belief role in a Bayesian setting. Higher firing means more belief, higher firing means lower belief. Figure four of the neural network architecture.	What does it really mean to have a connection between activity dynamics and belief states	Bayesian Networks 4, Hebbian Plasticity
2297528	2593638	38:17	The MATLAB scripts are available and archived on Zenoto. Here is the GitHub repo for reverse engineering. If you run the script, then you can see the process of an agent solving the maze task. What advantages or limitations do you see in MATLAB?	The MATLAB scripts are available and also archived on Zenoto	Solving the Maze Problem in MATLAB
2593814	3595520	43:13	Daniel Treisman: Decision is a sequence of four step actions. Each action corresponds to a movement to right or left or up or down. This makes an association between past decision secrets and the current risk which enables to optimize decision to minimize future risk.	Here we characterize decision as a sequence of four step actions	Decision process under the influence of dopamine
3600680	4076850	1:00:00	In terms of script there's no difference, sympathetic difference, right? They works in the same manner. What is it about the canonical neural network architectures that facilitates its translation into the POMDP form?	How can we translate neural network to computational bomb DP model	POMDP vs neural network: Translation
4078980	4189250	1:07:58	Dave: What kind of matrix or vector did you describe? The mass block matrix. Block rock meaning what? Brock matrix or broke vector is vector. Vector or matrix of matrix. All right, thank you.	Dave: What kind of matrix or vector did you describe	Matrices and their general thoughts
4189700	4332500	1:09:49	Why is it important that generative model matrices are sparse? Why the tangential matrix sparse? What do you think about compressed analyses on sparse matrices? Is that a useful technique or direction?	Why is it important that generative model matrices are sparse	In the Elevator With Karl Friston
4334440	5447750	1:12:14	From a canonical neural network to a particular form of a POMDP gives us some semantics and interpretability around the dynamics and plasticity of the neural network. Are you continuing research into more advanced computational agents, robotic animal?	Mapping between canonical neural network and corresponding neural network architectures is straightforward	POMDP and Bayesian networks
5449370	5613900	1:30:49	Well, we learned some corroborating work about the implication of celery using various animals. And so it's only natural to then explore different embodied systems as well. So we hope we can show some interesting results following results using animal data.	This paper builds on previous work about celery using various animals	Celery and its neurophysiology
5619630	5756810	1:33:39	The neuronal substrate of variance is still unclear and we now try to figure out that. Another limitation is that thanks to a simple ODP structure in this paper, we don't care about the hierarchical optimization. But generally it is crucial to update parameters through hierarchical optimization through some back propagation like competition.	Some limitation of these papers which is not directly discussed in the papers	Limits to the paper
5774450	6429054	1:36:14	Where in neural structures is the learning reflected? Sometimes it has to do with not just structural Tweaking, but the presence or absence of synapses. By intermediating through a formal connection, we can extend the chain of explanation, prediction, control, design all the way on through.	Understanding how larger scale structural changes become reflected in artificial neural networks	Where is the learning reflected in artificial neural networks?
6429172	6901360	1:47:09	Is planning a true Deep Horizon consideration or is it just short term heuristic or nested models that are short? And also I'm always curious about the invertebrate brain as an ant researcher. We really appreciate the time that you took for these discussions.	David Tour: I'm curious about the computational complexity of these models	Deep Horizon and the planning process
