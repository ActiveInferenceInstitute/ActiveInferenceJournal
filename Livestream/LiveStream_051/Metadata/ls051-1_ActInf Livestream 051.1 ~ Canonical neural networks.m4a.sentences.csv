start	end	sentNum	speaker	confidence	text
38860	41080	1	A	0.12903	Key all right, hello everyone.
41150	41816	2	A	0.9984	Welcome.
41998	45640	3	A	0.9998	This is activem live stream number 51.1.
45790	52760	4	A	0.99959	We are in the second discussion of our this paper canonical neural networks perform active inference.
53340	55892	5	A	0.99997	Welcome to the active inference institute.
56036	62164	6	A	0.50022	We're a participatory online institute that is communicating, learning and practicing applied active inference.
62292	67692	7	A	0.9995	You can find us on the this slide and this is recorded in an archived Livestream.
67836	70976	8	A	0.99683	So please provide us feedback so we can improve our work.
71158	76560	9	A	0.99603	All backgrounds and perspectives are welcome and we'll follow good video etiquette for livestreams.
77060	85060	10	A	0.99996	Head over to activemfirms.org to learn more about the institute and how to participate in projects and learning groups.
86040	99956	11	A	0.65691	All right, we're in Livestream number 51 one and having our first non solo discussion on this paper, canonical Neural Networks Perform Active Inference.
100148	104988	12	A	0.65	And really appreciative dakuya that you've joined today.
105074	107448	13	A	0.73008	It's going to be a great discussion.
107624	109512	14	A	0.9926	We'll begin with introductions.
109576	118444	15	A	0.88565	I'll say hello and then please just jump in however you'd like and we can start by setting some context.
118572	120092	16	A	0.98974	So I'm Daniel.
120156	137520	17	A	0.99958	I'm a researcher in California, and I was interested in this paper because we've been talking a lot about active inference from a variety of different perspectives, from the more fundamental math and physics to some applications.
137600	142372	18	A	0.99741	Philosophy embodiment all these really interesting threads.
142516	159576	19	A	1.0	And this paper seems to make a really clear, meaningful contribution and connection by connecting active inference entities and this approach of modeling to neural networks which are in daily use globally.
159768	166448	20	A	0.99488	So thought it was a fascinating connection and really appreciate that we can talk about this today.
166534	168690	21	A	0.98723	So to you and welcome.
174570	178280	22	A	0.99854	Go for it Tokuya however you'd like to introduce and say hello.
178730	179574	23	B	0.65564	Yeah.
179772	180278	24	B	0.88423	Hi.
180364	186250	25	B	0.55553	I'm Takai Somar, neuroscientist in Lieken Brain Science Institute in Japan.
186670	196490	26	B	0.95963	I'm particularly interested in universal characterization of neural network and brain using mathematical techniques.
196650	213630	27	B	0.90487	So this work I believe important as a link between active coherence aspect aspect of the brain and the dynamic system aspect of the neural network.
213790	217770	28	B	0.99926	So I'm very happy to join this discussion.
217950	219586	29	B	0.95908	Thank you for invitation.
219778	221000	30	B	0.99962	Nice to meet you.
222090	224440	31	A	0.99981	Nice to meet you as well.
226490	231850	32	A	1.0	The first thing you added, the universal characterization of neural networks.
232430	236374	33	A	0.9994	What is the universal characterization of neural networks?
236422	239820	34	A	0.99978	Why is it being pursued in this area of research?
241310	269202	35	B	0.92448	So, as a narrow sense, my main aim of this paper is that so people use active inference formularization to characterize brain activity, behavior, so on and so on, but which would be different from a conventional neural network.
269266	290026	36	B	0.9994	So there is a crossover program which is associated with conventional neural network and it is not very clear whether all characterization of computational neural network can be explained by active infrastructure and as a principle or not.
290128	320326	37	B	0.99563	So here universal characterization means that parameterisation of every aspect of conventional neural network which is a kind of dynamical system derived as association between biological phenomena and simple mathematical formula, typically using differential equations as the broad sense.
320508	342410	38	B	1.0	I think universal characterization means that well, it is a characterization of brain intelligence, but it's a big picture and what the paper particular address is only one aspect of the full picture.
346290	355490	39	A	0.96033	All right, so it'll be great to pull back to really understand what synthesis is happening.
355640	365778	40	A	0.99511	So I'm going to ask what makes a neural network model a neural network model and what makes an active inference model an active inference model?
365944	371560	41	A	0.99997	Is this synthesis and connection you've made true because of what?
374330	399626	42	B	0.74604	Because basically what we showed is the mathematical equivalence between the correlation of canonical neural networks and the correlation active inference lab in the sense that we show that a stress of neural network can be characterized by a minimization.
399738	402718	43	B	0.82	Of some biological plausible cost function.
402884	422360	44	B	1.0	And we show that that cost function can be lead as variation of Bayesian coherence and particular cross of generative model in terms of well known partially observable process.
426080	433970	45	A	0.99866	All right, shall we perhaps walk through some of the action of the paper?
434420	435376	46	A	0.99323	It would be awesome.
435478	447190	47	A	0.99679	Just for each of these sections, maybe the numbered and the lettered sections, what does the section aim to show and why was it there in the paper?
460820	461724	48	B	0.49068	It's and overview.
461772	486024	49	B	0.99079	Right, first we introduce so the main issue, main program, our interest, which is a relationship, which is that we try to make a formal ring between neural network and active infrastructure.
486072	490056	50	B	0.46429	That's the main problem background.
490168	499676	51	B	1.0	And then we first formulate the equivalent mathematical equivalence in a very broad manner.
499868	521770	52	B	0.99675	So in the least action in result, we formulate the relationship using concrete cross theorem, which is a well known statistical theorem proposed very long time ago.
522380	535704	53	B	0.68	And using that, we link a general form of neural network with a general form of variational data coherence.
535832	553932	54	B	0.99988	But a problem is that this characterization does not address a specific generative model which is crucial to characterize a specific model, specific neural network dynamics.
553996	574040	55	B	0.97649	So in the following sections, we characterize the problem using Pomodb or partially observer Marco digital process and link that model with a particular cross of canonical neural network.
575820	589260	56	B	0.99	And then we simulated we used the simulation to corroborate that property in terms of some maze task.
595150	597500	57	A	0.99837	All right, thank you for this.
598270	602350	58	A	0.77835	Could we talk about the complete class theorem?
602770	614260	59	A	0.96518	So what is the scope of the complete class theorem and why was it the relevant set of the neural networks to pursue or the right way to frame it?
615270	617090	60	B	0.99994	Thank you for asking that.
617160	625106	61	B	0.96976	So I like the slide you showed the last week's video.
625288	636310	62	B	0.86	The computer basically indicates the relationship between some crossover decision rule and Beijing inference.
637210	664746	63	B	0.94367	Here a crucial keyword is admissibility or admissible decision rule, which is rule which is the same as good as other decision rules or at least at one point better than other decision rules.
664778	674266	64	B	0.91204	So simply speaking, administrative indicate in some sense it is the best rule for some aspect.
674398	683366	65	B	0.54	And usually we characterize such a goodness using cost function loss function or risk function.
683548	707962	66	B	1.0	And here what we did is establish some association with this type of loss function or risk function with function of canonical neural network which is we call cost function or biological cost function for neural network.
708106	713586	67	B	0.99784	So our assumptions is that neural network minimize cost function.
713768	730200	68	B	0.99343	So if it achieved the minimization and it is validly achieved some sort of optimality so we can say it is admissible with respect to that cost function.
730650	751910	69	B	0.99222	So the beauty of complete cross serum is that if we find some admissible decision then automatically we can say that it is based on coherence in terms of some Bayesian cost function with generative model or prior beliefs.
752070	767214	70	B	0.99677	So this complexity theorem is crucial as abstract characterization of the relationship between conventional neural network architectures, dynamics and variational.
767262	768450	71	B	0.46284	Beijing inference.
771830	773860	72	A	0.87425	Right, thank you.
775450	780360	73	A	0.99822	What does it mean when you said it was biologically plausible of a loss function?
782090	808190	74	B	0.97	The term is a little bit arbitrary because in this paper we Dean by prosperity in the sense that this neural network model can be derived from heuristic neural model through some approximation.
810850	823620	75	B	0.61536	Here, biological probability suggests or means probability as a neural model or synaptic prostitution model.
824390	836390	76	B	0.54	And if this cost function loss function can derive such a plausible algorithm, then we can say that this cost function is vertically plausible.
839630	847980	77	A	0.90448	So what is the distinction between those neural and synaptic components in the loss function or what equation to look at?
849710	854154	78	B	0.99557	You mean distinction between dynamics and synaptic?
854282	854670	79	A	0.99282	Yeah.
854740	859070	80	A	0.99999	What is the distinctions between them and how is it represented in the equations?
860690	884406	81	B	0.99691	Okay, basically neuroptivity equation means differential equation about variable that represent firing intensity or some sort of variables associated with the neural firing on the other.
884428	900650	82	B	0.64	And synaptic plastic creation means an update rule about the synaptic weight or synaptic strengths which is a connection between two neurons.
901150	926440	83	B	1.0	And beauty of this formulation in this paper is that we characterize both heuristic equation and synaptic process in terms of gradient descent on a same cost function, common Costa function.
927050	950198	84	B	0.99238	So we can say that if we consider the partial derivative of some cost function with respect to neural activity, then it derives gradient descent rule about activity neuroptivity.
950374	959790	85	B	0.85327	While if we consider partial generative of cost function L with respect to synaptic weight, then we derive a synaptic prosthesis rule.
970340	978420	86	A	0.99984	Are those the only two aspects of a neural network or why are those the two key aspects?
984040	990740	87	B	0.99	I think it's a main body of the neural activity.
990820	1017824	88	B	0.82516	If we consider some inference running our action exhibit by neural network in the sense that neural activity correspond to fast dynamics, fast gradient dynamics mix and while synaptic prostitution indicates a slow dynamics that minimize risk function cost function.
1018022	1024168	89	B	0.99993	But in general we can consider and aspect any variables associated with Urinator.
1024204	1045012	90	B	0.98097	For example ant least what we show in the paper is any free parameter which may be associated with firing threshold or although we don't discuss in this paper it would be possible to add other variables related to neural network.
1045076	1060480	91	B	0.99852	For example, here we ignored contribution of griar factor but it would be possible to add the grille factor in this correlation or any other aspect of virus Carnap network.
1064740	1096408	92	A	0.99976	That's very interesting and it speaks also to a general separation of timescales, for example in different multi scale systems or in the renormalization group where it's describing some minimal multi times scale system where the faster time scale can be seen as perception like and the slower timescale can be seen as more learning like.
1096574	1103800	93	A	0.89	And then in some hierarchical model what's learning of one time scale can be perceptual for a slower time scale?
1103880	1107340	94	A	0.99949	So it's a very nice generalization.
1112500	1123476	95	A	0.99477	Are there any examples of decision rules that will help us think about the action components of what the neural network is doing?
1123658	1135716	96	A	0.99997	Because it may be more familiar to think about digit characterization and image classification, some kind of classical tasks for neural networks.
1135908	1141480	97	A	0.99985	But how does the decision rule play out in the context of neural networks?
1144300	1156190	98	B	0.94122	Okay, so in this paper we basically assume a close group comprising a neural network part and environmental part.
1156560	1167520	99	B	0.88049	So Neuron receives sensor input from environment and provides some feedback to the environment.
1171860	1187844	100	B	0.72225	Even with the example of digit classification we can say that output correspond to classifier classification output which is kind of decision rule.
1187972	1200920	101	B	0.99809	More relevant example would be for example controller agent like a robot control or any kind of controlling or decision making tasks.
1201080	1224020	102	B	0.99989	For example, when we encounter some choice task we need to advertise, for example left or right or something, any kind of Dutch a decision can be associated with the adommissibility or atomic decision rule.
1227170	1238270	103	A	0.98591	So what would and example of an inadmissible or admissible strategy be in the decision making task?
1240930	1270650	104	B	0.48686	Admissibility usually characterized by loss function or risk function here in adommissibility indicate that there is another decision rule which is at least one point better than the forecast decision rule.
1272670	1286190	105	B	0.62559	Simply speaking in Adobe Civility indicate that decision rule is not better, not good negatively.
1287170	1290820	106	A	0.93753	Let's just say our decision rule is we always turn right.
1291590	1293934	107	A	0.99994	Is that an example of a decision rule?
1293982	1302530	108	A	0.99998	Because there might be settings where that is strictly effective and the simplest rule whereas there's other settings where that's going to be tragic.
1302690	1311110	109	A	0.99508	So what does it mean to be admissible for an agent in light of different environmental contexts?
1312350	1314234	110	B	0.76939	That's an interesting point.
1314352	1331680	111	B	0.67862	So even with such a too much simplified rule it can be admissible under some particular situation, particular loss function.
1332130	1341218	112	B	0.99669	For example, the ruler that always turns right, maybe the best under some situation right.
1341384	1355750	113	B	0.88442	So the relationship of admissibility or in admissibility depends on both agent characteristic and the environmental characteristic.
1359450	1362410	114	A	0.99278	What aspects of the environment?
1366510	1389410	115	B	0.99716	For example, if that decision rule matches the structure architecture of environment then maybe that decision always turn right, achieves the shortest past right under some situation some environment.
1391830	1397090	116	A	0.99845	How does this admissibility help us think about, like, overfitting?
1398170	1408630	117	A	1.0	And how does it help us think about the way that different practices are used for neural networks to prevent them from being overfit in practice?
1410890	1424190	118	B	0.82516	Well, strictly, adomissibility is characterized with the patient risk.
1424870	1442994	119	B	0.97077	So we cannot observe a hidden states of the environment, only we can observe Hae Park of the entire universe.
1443042	1454102	120	B	0.72091	So the question is, an important question is what is the best choice under such a limited information?
1454236	1459382	121	B	0.58557	Limited information.
1459516	1489922	122	B	0.67557	So this basically complexity tell us that only the well known Beijing framework achieved the admissible decision.
1489986	1500674	123	B	0.99998	Which means that in this aspect, beijing optimization give us a best choice strategy.
1500722	1513150	124	B	0.62617	Otherwise we all buffet or find the suboptima evolution.
1513890	1527550	125	B	0.98089	So it's a nice association, nice linkage between the decision what is a good decision about the decision, and the more established statistical coherence Beijing and influence framework.
1531290	1534210	126	A	0.99996	Thank you, that's very helpful.
1534290	1544010	127	A	0.99625	So we're reducing our uncertainty and risk about hidden states in the environment.
1544350	1563310	128	A	0.99808	So in the special case where the entire environment is observable without error, like a chess game, then there's an equivalence between calculation of risk or loss on observables or on hidden states.
1563380	1567060	129	A	0.99991	But they're not really hidden, but they are environmental states.
1567590	1605898	130	A	0.99726	Whereas any amount of uncertainty in the mapping between observations and hidden states, which is usually shown as a in the partially observable Markov decision process, any amount of uncertainty about unobserved or partially observed environmental states enables you to fit your uncertainty optimally about that hidden states and fit that uncertainty simply with a gradient descent.
1606074	1630390	131	A	0.73	And by doing so, you don't overfit a model of observables, which might be the fallacy or the issue with simply doing descriptive statistics, you might get an infinitely small variance with a frequentist estimate because you have 100,000 data points.
1630540	1636440	132	A	0.9997	So the variance from a descriptive statistics perspective might be very small.
1641150	1655194	133	A	1.0	I think it speaks very much to why neural networks are useful in practice from training with limited data sets, because that's an empirical conversation that they don't entirely overfit.
1655322	1660350	134	A	0.99997	But also, I'm sure there's ways to construct them that are overfit.
1661250	1670814	135	B	0.87899	Yeah, overfit would occur if we select some optimal prior beliefs.
1670862	1671620	136	B	0.97845	For example.
1673830	1696778	137	B	0.98472	Well, I'm not sure if it is overfit in the sense that you mentioned, because if we select some prior base, then the Beijing function itself changes and the neural network that try to fit to that cost function.
1696864	1712030	138	B	0.99331	So cost function minimization will be achieved such a situation, but that evolution is not good for our original purpose.
1712930	1714480	139	B	0.92041	That's a tricky part.
1714790	1715586	140	B	0.9983	Yeah.
1715768	1730360	141	A	0.999	That is reminiscent of some discussions we've had discussing, like driving off a cliff or blowing up is also reducing free energy, like dropping off a building reduces your potential energy.
1730730	1749590	142	A	1.0	And so there are potentially decision making or strategic trajectories that do for some time horizon minimize free energy, perhaps even or maybe even guaranteed better than some longer time horizon.
1749750	1761230	143	A	0.99999	Because if the short term strategies were somehow better than the long term horizon, it would be difficult to imagine because the long term horizon would be at least as good as a short term strategy.
1762530	1768078	144	A	0.99899	So that speaks to the challenges of planning in action.
1768174	1777080	145	A	0.99729	So how is planning addressed in Modern neural networks and how does this work help us think about that?
1780010	1783350	146	B	0.92308	That's another very important aspect.
1785770	1812270	147	B	1.0	I have to say that this framework address planning aspects, but that planning is not necessarily the optimal optimal solution in the sense that what we interested in is optimization or planning under limited structure.
1814230	1821170	148	B	0.95	The structure is characterized by here birdscape prospero to a neural network.
1821670	1834934	149	B	0.99773	So yes, planning occurred by an association between risk in the future and our decision in the past.
1835132	1849290	150	B	0.99524	Here we model that aspects using delayed moderation of symptomatic activity mediated by some neuromodurator or neurotransmitters.
1853470	1876930	151	B	0.54415	This is model as this is model as product of the risk factor and the behavior product on the neural network.
1882090	1889454	152	A	0.96698	All right, I'm going to ask a great question from the chat and then we'll look at the figures a little closer.
1889602	1895690	153	A	0.98335	So ML Don wrote a question stuck in my mind for a long time.
1895840	1897978	154	A	0.99991	Could you please put it to rest?
1898144	1906670	155	A	0.95529	Do we need to have knowledge about all states possible actions and sensory inputs for active inference?
1910920	1928170	156	B	0.96703	Well, you mean if you seek the exact solution, optimized solution, then maybe more information would help you to find that.
1929020	1948240	157	B	0.99749	But under some model, under some idea assumption, then the variables is not necessary to achieve the optimal evolution.
1949780	1953890	158	B	0.51585	I'm not sure if I correctly answer your point.
1955640	1958390	159	A	0.94434	So just to restate it.
1959240	1964980	160	A	1.0	Of course, knowing all the states possible actions and sensory inputs, it's not a bad thing.
1965130	1972036	161	A	0.97014	Worst case, there's some computational complexity, trade offs, but the problem becomes fully stateable.
1972228	1996770	162	A	0.9981	But I think Mldon is asking about cases where you don't know all of the state spaces or potentially even the dimensionality or the semantics of hidden states, active states, sensory inputs, and why not even and cognitive states.
1998500	2012310	163	A	0.99476	So in not just partially observed but partially known state spaces, how are these addressed in neural networks and how does active inference help us think about it.
2017900	2032960	164	B	0.95755	Okay, I think the function is about how can we separate those states like least active coherence external.
2037180	2053804	165	A	0.71248	How can we separate, not just in principle have these states be separated, but deal with the fact that some of these states we might have good knowledge on and some states like the hidden states we might not even know.
2054002	2059024	166	A	0.99942	We don't know the dimension of the cause vector in the world.
2059222	2060210	167	B	0.99	I see.
2062660	2071840	168	B	0.99733	In terms of dimensionality, there is a statistical technique to estimate the dimensionality.
2071920	2080544	169	B	0.99838	For example, various information criteria, information criteria based information criteria.
2080672	2092090	170	B	0.86491	All of them try to inform or estimate plausible dimensionality about the environmental hidden states.
2093760	2115360	171	B	0.96814	There is an analogy with those information criteria and variation free energy minimization with virtual free energy inclination we can identify the plausible model structure which in principle involved the dimension aspect.
2116500	2137050	172	B	0.99992	But in terms of neural network in this paper we don't carefully consider about the dimension optimization because we first define the NABO neuron and don't change during training.
2137660	2157200	173	B	0.99792	But in principle we can consider the change in the number of neuron which is associated with the, for example, neurogenesis adult neurogenesis or development during the development stage.
2157620	2166240	174	B	0.99827	That would be an important extension of this direction.
2173640	2175270	175	A	0.95041	That's very interesting.
2176040	2178580	176	A	0.69979	Here's a remark.
2179160	2187960	177	A	0.99109	Well, one note is equation one summarizes a lot of what you've been describing.
2188460	2201580	178	A	0.99904	There's a parallelism or a concordance being drawn between the loss function of neural networks and the variational free energy of the parameterized model there.
2201730	2225460	179	A	0.9267	So to come back to these processes that influence learning which we could think of as the neural network becoming more fit from a loss function perspective or the variational Bayesian partially observable Markov decision process entity generative model becoming better at doing what it does.
2225610	2245420	180	A	0.99931	So there's the firing rate on the neural network side the synaptic plasticity at a slower time scale which we discussed a little earlier and then now there's a third time scale with the birth and death of new cells and maybe even new layers.
2246480	2264240	181	A	1.0	And that kind of multi scale temporal structuring is not intrinsic to the Bayes graph to represent multiple nested timescales in a Bayesian graph.
2264980	2284516	182	A	0.99989	In the active inference literature it's more common to make a hierarchically nested model and just say that the time handling on one level is happening more rapidly with respect to clock time than deeper nested, slower models.
2284708	2303900	183	A	0.87131	Whereas the neural formulation allows us to deal with multiple ongoing timescales without appealing to hierarchical nesting which is a very important feature.
2311600	2317504	184	B	0.7874	Well, both direction will be possible.
2317702	2325152	185	B	0.61068	So without hierarchical model motoring or with hierarchical model.
2325296	2339588	186	B	0.88316	So even with hierarchical modeling the optimization of dimensionality should be possible, would be possible but in other direction.
2339684	2382950	187	B	0.93344	So we can consider that a population of neural models so one has a single layer, another has two layers, three layers, four layers and consider the probability or plausibility of network architecture associated with the performance or cost function minimization under a particular environment which is in principle have the same computational architectures with the hierarchical page and model.
2386810	2388600	188	A	0.6663	Very interesting.
2389290	2410830	189	A	0.99988	Yes, perhaps I over generalized or speculated because I thought about how one could have a 100 time step POMDP that also performs multiscale behavior potentially extremely wastefully but at least it could in principle.
2411250	2422178	190	A	0.99	And similarly, within a neuron there could be another neural network or some other structure approximated by that.
2422344	2440950	191	A	0.70849	So they almost both enable hierarchical and non hierarchical model as you described but in very different ways that lead to very different implementations.
2444170	2452650	192	A	0.60381	Yeah, I think this brings us to the topic of forward and reverse engineering.
2453070	2457130	193	A	0.99835	So you talked a lot about reverse engineering.
2458770	2468590	194	A	0.99987	What is reverse engineering and what is forward engineering and what has been done in these areas of engineering.
2470450	2503260	195	B	0.99454	Okay, I'm not an expert of divas engineering in the process, but I believe that levers here means a characterization of the blueprint of some device or machine from data observable information like activity or action behavior of some agent.
2504190	2508490	196	B	0.97745	So, goal is identification of blueprint.
2509230	2513854	197	B	1.0	And the crucial here blueprint correspond to generative model.
2513972	2523906	198	B	0.99991	Because once we define generative models, we can derive various energy algorithms running influence algorithm under any behavior of agent.
2524008	2537142	199	B	0.95834	So, here, reverse means that we first observe some activity of agent and its mechanism is still unknown for us.
2537276	2568462	200	B	0.7669	But we can estimate its mechanism using activity by identifying the most plausible gear T model which can minimize some post function or risk function when we feed the data to the model the model.
2568596	2595350	201	B	0.99664	So, on the other hand, for engineering would be more mainstream way fast define model blueprint gently model then Deneve everything including Bayesian parametric functional running Paris algorithms, behavior action algorithm.
2600030	2615280	202	A	0.90042	So, by reverse engineering neural networks, we're observing some already parameterized neural network and then fitting a POMDP to it.
2616690	2628290	203	A	1.0	To what extent is it possible to take a given POMDP and create a neural network that errors that inference?
2632970	2679170	204	B	0.86531	Okay, in this paper or in the following paper what we consider is strategy that we first fit empirical data whether for neural response data to bioscape plaudible canonical neural network model which is similar to a computational model fitting approach where we have differential equation and data and data to the differential equation to explain the behavior with the minimum prediction.
2679590	2701494	205	B	0.99103	So, now, a virtue of this framework we establish is that we can naturally transform such a neural network architecture with the very no partially observable Markov process architecture.
2701622	2708060	206	B	0.99993	Because for any kind of canonical neural network, there is a cost function.
2710050	2721762	207	B	0.90603	So, we derive cost function for neurotivity question which is opposite with the computational way.
2721816	2736530	208	B	0.97792	We first define cost function derived algorithm and then we use the force the formal equivalents between neural network cost function and Virginia query.
2737690	2745598	209	B	0.92899	So, now transform the neural network architecture to Beijing model architectures.
2745794	2762010	210	B	0.63	And once we characterize Virginia free energy, there should be some generative model that define that Virginia free energy function.
2765330	2778210	211	B	0.99957	In particular, in this example, canonical neural network necessary correspond to well known across well known Attial edition process.
2778360	2800140	212	B	0.987	So, by using this procedure, we identify a plausible homedp architecture which is correspond to obsolete data.
2809500	2815310	213	A	0.96487	Well, let's stay on this last point.
2815920	2842480	214	A	0.9807	So, after all those transformations, first the measurements of neurons using that data to fit the neural network and then by virtue of the relationships unpacked in the paper, transforming the neural network in the left side of figure one into a particular form of the POMDP.
2842640	2848560	215	A	0.95881	So first, what are the constraints on that form of the POMDP?
2848720	2855960	216	A	0.99929	Is this a little corner of model space or what are the space of acceptable POMDPs?
2858220	2864140	217	B	0.96717	That totally depends on what kind of neural network model you are considering.
2864480	2879664	218	B	0.88727	So for example in this paper we discuss about a particular cross of Coda that in which each state takes either zero or one.
2879862	2890864	219	B	0.93247	So it's very restricted compared to the general form of OMDP but we consider a factorization.
2890992	2922110	220	B	0.97653	So in the sense that although each static has a Ronen of one but we consider a vector of conversation and vector of hidden state where each element correspond to Ronen single one, whole vector but as and entire state it can represent high dimension discrete state space.
2923200	2943910	221	B	0.55	And this architectures nicely correspond to neural network architectures because usually each neuron takes either zero, one or some continuous variable between zero and one.
2944360	2954548	222	B	0.97074	So we use this association to characterize a particular home DP which correspond to neural networks.
2954724	3006680	223	B	0.99	And this follows a particular Memphis approximation, approximation or approximation in generative model because we associate posterior belief in this particular homo DB with the neuropathy, which means that posterior of action also chaos, a factorization architectures in the sense that we don't fully consider about the second order statistics between neurobans activity and neurons activity, which is outside of this pulmorism.
3007500	3036690	224	B	0.95005	So each neurons activity correspond to posterior expectation about the particular elements of the state and we don't consider the joint posterial property of all state.
3040850	3063430	225	B	0.96462	So although this is a limitation, we see this as a Beijing imprint but otherwise for examples we can consider any recurrent network architecture which correspond to state to transition matrix.
3065870	3089950	226	B	0.98808	It would be possible to extend this architectures to higher card structure in the sense that it is straightforward to consider a tree structure or any kind of higher card structure by assuming that some neuron connect to other neuron but not connect to other neuron.
3090030	3096900	227	B	0.87743	So this is same as considering the higher card structure in general.
3103810	3106960	228	A	0.82337	That's very interesting.
3108290	3124958	229	A	0.89701	It's commonly remarked in the base graphs that they represent the connections amongst random variables and there's a relationship between their computability and their sparsity.
3125134	3149754	230	A	0.99	The sparsity structure as in which variables do or do not influence each other makes the problem tractable through factorization and just kind of conceptually like if every one of 1000 variables or an unknown number of large variables if it was all by all the number of parameters to fit on that connectivity matrix would be very high.
3149872	3154170	231	A	0.99982	So statistical power would be very low for any given edge.
3154330	3168930	232	A	0.99725	Whereas the more and more constrained you make the connectivity of the variables, the more statistical power you have to resolve or kind of spend on fitting those edges, like in a structural equation.
3169430	3182306	233	A	0.9986	But you might be losing sight of the unknown unknowns by constraining yourself to a very limited or fallacious biology of the variables.
3182418	3218450	234	A	0.99985	So there's this kind of structure learning statistical inference question in the Bayes graphs then on the neural side from the biological much of neuroscience is about understanding how the firing rate, connectivity patterns and other factors, how the structure of those neural systems and their function like form and function enable adequate coherence and coherence on action.
3218950	3230530	235	A	0.88201	So it's like in both of those areas or really like in neural network, artificial and neural networks and in variational bays.
3231130	3257290	236	A	1.0	The discussion is about how the structure and the finetuning work together to generate function and about some of the statistical or biological challenges of balancing different needs while also constraining the cost in terms of materials and biometabolism.
3257730	3265680	237	A	0.99635	So it's a very rich intersection that is being explored here.
3269620	3272880	238	A	0.98402	If these models can really be moving back and forth.
3278290	3282750	239	B	0.88376	In the sense that back and forth.
3285570	3300086	240	A	0.99985	Moving back and forth, like there's imprints of the model that is implementation independent or like some interlingual or some semantics or compatibility, I don't really know.
3300108	3315766	241	A	0.89	I mean, that's something we can explore is like what is it that is such that one could forward engineer and then reverse engineer and have kind of an expectation maximization between these two areas.
3315798	3319610	242	A	0.82576	So, what is it that's being sought?
3325230	3329562	243	B	0.79751	Yes, important point.
3329616	3357690	244	B	0.50938	So, for example, a virtue of this relationship is that we can use the knowledge of to explain neuropty neurodynamics, which is crucial because people often say that capitalizing dynamics is not straightforward.
3360270	3371530	245	B	0.99602	We may obtain some solution on neural net dynamics, but the meaning of that dynamics in terms of the functional aspects is very unclear.
3371610	3382082	246	B	0.99994	We don't know the meaning of connectivity strengths, matrices and what is the meaning of the threshold factor, so on and so on.
3382136	3399838	247	B	0.99209	Those are derived from the moderate biological phenomena, but it is not necessary to have clear linkage to function explanation.
3400014	3426480	248	B	0.60116	So, exploration of function of the brain, but once we translate these dynamics into Bayesian infrastructure, then we can explain every functional aspect of the neural net dynamics architectures in terms of well established Bayesian inference under a particular crossover Beijing model, in this case palm DB model.
3428370	3441090	249	B	0.91501	So now it turns out that synaptic strengths correspond to a matrix b matrix, which are very established culture meaning.
3441990	3458010	250	B	0.7325	So yeah, this is useful to explain neuro and synaptic property in terms of well established statistics.
3464400	3481890	251	B	0.99994	Also, for the people in active inference lab site, it would be helpful to understand the neuronounce rate about particular active coherence modeling model.
3483800	3508270	252	B	0.45444	So I think it related to forward modeling, but finally to discuss with discuss about the biotcar substrate of that forward model, we need to address the neural network architectures substrate property.
3508800	3529404	253	B	0.93285	So, in that case, we can transform a particular pond Beijing modeling to a neural network architectures using this relationship and then get prediction about the substrate.
3529452	3546630	254	B	0.99287	So, if we have ant least Beijing model, this particular quantity in this model should be possible.
3555000	3555684	255	A	0.99316	It's all good.
3555722	3558100	256	A	0.98071	Can you just repeat the last like 20 seconds?
3558760	3559510	257	B	0.74565	Yes.
3559820	3578910	258	B	0.50813	So in the last part I mentioned about first we define the Beijing model and then can predict what is the neuronal substrate that correspond to that particular Beijing model.
3579440	3588960	259	B	0.994	So this will be useful to identify the biological quantities.
3590340	3593840	260	B	0.98772	That correspond to a quantity in Beijing.
3598120	3598870	261	A	0.74357	Wow.
3600440	3606230	262	A	0.94565	Well, there's a lot there.
3607000	3627020	263	A	0.98424	It makes me think about the differences of implementation and heuristics in the computational setting, which is often in the extreme disembodied, and the biological setting, which is in the extreme, entirely embodied.
3627360	3662360	264	A	0.99	And for a given generative model, the kinds of computational heuristics that can be applied include a whole host of different strategies, ranging from sampling to tree exploration and branching to paralyzing the data architecture and all these other kinds of disparate strategies and software packages and implementations.
3664540	3686480	265	A	0.99996	But on the biological side, what is needed is something that's very simple but also very inscrutable, which is a given pattern of interactions must embody that correlation.
3688500	3699300	266	A	0.96909	So that might mean that it can add three digit numbers, but it can't add two digit numbers under some constraints.
3700920	3707952	267	A	0.9995	But what isn't accessible to that kind of morphological, biological, or like form and functional computing?
3708096	3736590	268	A	0.95051	What's not accessible are the tree branching, the database decentralization, like they're a different set of heuristics, but they're both very useful when we're thinking about making sentience artifacts or benefiting simply from the explainability across both sides of this figure.
3738720	3739516	269	B	0.80937	Yeah.
3739698	3742860	270	B	0.70773	So now there is an important point.
3742930	3756368	271	B	0.98656	So, Hornetry, it is very known to bear whether there is a corresponding vertical architecture for any given Bayesian architecture.
3756464	3766068	272	B	0.73	I believe it is impossible to design biascar architectures to correspond to arbitrary Bayesian architectures.
3766164	3775576	273	B	0.71467	So only a limited aspect of Bijan model can be implemented in a vertical, plausible manner.
3775688	3785340	274	B	1.0	And that point is crucial as a characterization of biological brain.
3789520	3790076	275	B	0.91035	Yeah.
3790178	3790696	276	B	0.72216	Wow.
3790818	3796240	277	A	0.66659	Well, just to kind of touch again on this forward in reverse engineering.
3798440	3798804	278	B	0.9907	For.
3798842	3812916	279	A	1.0	A given POMDP, if we're willing to compose it within a certain class, which might be quite general still, but some class of POMDP as written.
3812948	3813770	280	A	0.99983	On the paper.
3815020	3830632	281	A	0.9999	We may be able to have a neural network architectures that would be very amenable to deep learning, low energy computing, pretraining various features.
3830776	3848150	282	A	1.0	And then on the other side, for a given artificial neural network that we come across in the wild, or a model of neural dynamics that we fit using a neural network model.
3848840	3862440	283	A	0.99631	So something in a neuroscience laboratory that model can have interpretability corresponding to the variables of a given POMDP.
3862940	3872280	284	A	0.98	And just to kind of give one more point on how that's going deeper than, for example, statistical parametric mapping SPM.
3873040	3883964	285	A	0.94938	So let's just assume that the neural network we're dealing with is fit from brain data from some lucky ant right?
3884002	3908132	286	A	0.99997	Now, what would be possible or prior to this line of work or without this line of work, one could fit a neural dynamics model and then do all kinds of analyses, like power analyses on the different frequency spectra and say, look at the average firing rate or the correlation coefficients of firing rate.
3908186	3914216	287	A	0.99879	So fit the firing rates and the synaptic Plasticities and store all that data.
3914398	3924360	288	A	0.99	And then we could just pick a POMDP that we've seen in the literature without any reference to the neural network and optimize the POMDP.
3924520	3935348	289	A	1.0	And then we could say well, it turns out that when the Pomdpo is high there's increased theta power in this firing pattern.
3935544	3947170	290	A	0.72287	So it's like comparing the descriptive statistics from the neural model to the descriptive summary statistics of the POMDP decision making model.
3947560	3964616	291	A	0.99972	However, with this formal connection there is actually an interpretability to the unobserved neural states which are what are being inferred from the fMRI measurement, from the EEG measurements and so on.
3964798	3974780	292	A	0.99975	Those underlying variables have a specific interpretability in relationship to the structure of the POMDP.
3981440	4006592	293	B	0.53588	Right, that's also very interesting, important aspect what you said is I think more conventional strategy and it is also commonly related to model comparison aspect.
4006736	4018170	294	B	0.98648	So we usually think bias Bayesian modeling and identify or select what is the best model to explain a given data.
4018700	4051300	295	B	0.99	And this robust engineering idea involves such a model comparison aspect in the sense that we try to find the model with the best experiment ambiguity which should be have the identical function right directory addresses the exact same Costa function architectures using the transformation natural transformation.
4051720	4060150	296	B	0.97722	So it should be up to explain the neural data in the Bayesian sense.
4062540	4084990	297	A	0.83159	Yeah, one can imagine how that would transform the way that current neuroimaging studies and technologies describe what it is about the measurement that provides information about the cognitive model.
4085300	4104180	298	A	0.90704	So to give another related example, let's just say a person was wearing an EEG headset and a previous study had shown that increased alphaband activity was associated with this behavior.
4105880	4125500	299	A	0.68038	That's comparing a descriptive statistic of the observations of the sensor and correlating the summarized observable to some other variable like anxiety or performance on a behavior.
4127680	4150020	300	A	0.99999	In contrast, an unobserved variable in this setting the actual underlying neural state is being correlated to some semantic generative model component.
4151480	4178380	301	A	0.99675	So it's no longer necessarily that any single frequency band would be associated more or less with a given outcome but it's actually some hidden states variability which gains the interpretability across this transformation.
4179040	4208740	302	A	0.99997	Which is a subtle point but it speaks to how broadly the equivalence would reinterpret empirical neuroimaging results as well as a variety of artificial neural network experiments and diagnostics where people do lesion studies and double knockouts on artificial neural networks.
4211100	4237772	303	A	0.99319	So anywhere where somebody with awareness sees that a neural network, artificial or biological is having summary features described and correlation to something that's more semantic in a quest for meaning may now have a different approach that involves foraging.
4237836	4255140	304	A	1.0	The model explicitly in terms of unobserved hidden states with a cost function akin to a variational free energy, minimizing risk or bounding surprise on the unobservables.
4256520	4276780	305	A	0.99581	So even though the unobservables were modeled in a sense in the other conventional strategy like neural activity is a variable in fMRI experiments, it's underlying the bold signal.
4277440	4287680	306	A	0.99992	Yet this formalism concordance is a more coherent and powerful connection.
4294660	4296450	307	B	0.97	I believe so.
4300420	4307012	308	B	0.9583	Very important point to address that.
4307066	4312970	309	B	0.90956	So we need to clarify about what is a program.
4313580	4315128	310	B	0.99954	Consider here.
4315214	4335740	311	B	0.97923	So this is a program so called metabasian problem in the sense that researchers try to infer or estimate neuro activity or brain activity which infer the external world dynamics, right.
4335810	4343132	312	B	0.59695	So neuron brain info environment and the researcher info brain activity.
4343276	4348972	313	B	0.97635	So there is a two step coherence processes.
4349116	4370440	314	B	0.82592	So this sort of metabasion program is quite tricky intractable because sometimes probability, sometimes random variable becomes posterior about other aspect.
4371020	4377592	315	B	0.73325	So I think there is some established approach about metabasium.
4377656	4405076	316	B	0.95273	But this paper provides some alternative in the sense that we separate two program by saying that here what we infer is simply neural network model or neural network dynamics which is shown in the left hand side of this figure.
4405258	4414356	317	B	0.99797	So we feed data to conventional neural network model which is a simple differential equation.
4414548	4438640	318	B	0.91868	But thanks to this formal equivalence between neural network dynamics and behavior, we can transform the resulting neural network architecture or dynamics into the page and infrastina in some sense post hook manner.
4440660	4454740	319	B	0.99842	So we nicely avoid the directory addressing the metabasium problem but obtain the same kind of solution in that sense.
4454810	4462468	320	B	0.99182	Yes, with combining with brain activity recording like IEG or imaging.
4462644	4477370	321	B	0.52414	Yeah, we can estimate a plausible neural network model in the left hand side and we can transform that to OMDP in the right hand side.
4480140	4480708	322	B	0.55353	Great.
4480814	4481372	323	A	0.99888	Awesome.
4481506	4487120	324	A	0.87662	I'm going to show an image and ask a question from Dave in the chat.
4487540	4504740	325	A	0.93107	So Dave made this image, it's the right side of figure one that we've just been looking at with the variational Bayesian correlation and he wrote the arc shown as impinging on the S self arc.
4506520	4508288	326	A	0.97402	Is this intentional?
4508384	4514250	327	A	0.99995	If so, it could represent tuning or modulation of the feedback of S into itself.
4517740	4519370	328	A	0.80129	Do you have a thought on this?
4520860	4522052	329	B	0.87137	It's attention?
4522116	4560616	330	B	0.99984	Yes, I think it's related to the usual formulation of Pom DB architecture and active coherence context in the sense that our decision or policy in the usual setting modify active states transition matrix b matrix here delta is alternative of policy of agent.
4560718	4573130	331	B	0.99378	So basically the director indicates stated transition matrix under a particular decision which agent made.
4574080	4582296	332	B	0.99957	In that sense what the agent changes is state transition matrix not state itself directory.
4582488	4587340	333	B	0.76463	That's why we use this exploration.
4589460	4590210	334	A	0.97874	Awesome.
4591460	4600736	335	A	0.99988	Very subtle but important point which is when we look at the classical POMDP formulation.
4600928	4604292	336	A	0.99828	So here we'll look at a version shown in figure two.
4604346	4606710	337	A	0.93736	I'll just bring just figure two in.
4609480	4623496	338	A	0.99981	Could you describe what you just did about the role of the B matrix in influencing how hidden states change and how that is where our policies have impact?
4623688	4629550	339	A	1.0	And also please, how do the top and the bottom of figure two differ?
4633200	4644540	340	B	0.98486	Okay, so in the usual formulation under active infrastructure with a palm DP structure.
4644620	4673660	341	B	0.86759	So for us to consider the prior free for us and depending on the prior free for us, we compute the expected free energy and its minimization provides the policy and the policy modulate active states transition.
4674320	4686530	342	B	0.95018	So now in the upper array we instead use the Pirator which is the option of the agent.
4687300	4695650	343	B	0.52811	So here computational decision was made for each time step.
4696420	4712200	344	B	0.94115	So that unlike the computational formulation, we have a sequence of generative and for each time step derita moderate active states transition matrix B.
4712350	4723470	345	B	0.83455	So B is a matrix that transform hidden state in the previous step to the S in the current time step.
4724000	4751984	346	B	0.99	And it's moderation indicate that under a specific decision rule, for example, if this indicates our position in the battery environment with the goal decision our position moved forward, or if we choose no go decision, then it's unchanged.
4752112	4771050	347	B	0.98996	So such a conversation of state transition was made by choosing EBITDA and the lower part correspond to Beijing influence made by Beijing agent.
4771820	4801590	348	B	0.94886	So basically there is a symmetry between apart part and lower part because we assume that this Beijing agent has a plausible gentle model which nicely correspond to a given environment defined in the above in this figure.
4802200	4844240	349	B	0.99956	But one interesting thing so asymmetry is that to model this particular canonical neural network, we don't consider an arrow or link from Derek posterior to the posterior which is in the environment data moderate S in the next step through B matrix correlation.
4845300	4873160	350	B	0.65349	In this particular Beijing engine which formally correspond to canonical neural network, we don't consider that it is correspond to and absence of the projection from output layer to the middle layer.
4879180	4879930	351	B	0.78797	Okay.
4886000	4896252	352	A	0.98008	This is from the 2020 paper, but it shows the neural network architecture, the two layer architectures.
4896396	4914820	353	A	0.98067	So could you restate the top and the bottom of figure two in the 22 paper and connect it to why it's important that you're studying two layer neural network models?
4915960	4917190	354	B	0.88	I miss you.
4917560	4918904	355	A	0.26	Oh yeah.
4919022	4934540	356	A	0.99921	Can you just connect the asymmetry between the top and the bottom on figure two with the two layer neural network architecture?
4935520	4940430	357	A	0.9998	You said that the asymmetry there's no direct link between.
4945320	4949610	358	B	0.44487	Yes, this is another story.
4949980	4972300	359	B	0.60034	So in the previous paper, in the previous paper there is only output rate perceptual layer because we basically consider a single layer free toward network.
4972380	4983268	360	B	0.7953	So my apologies for some confusion about the network architecture in the 2020 paper.
4983354	5000840	361	B	0.99822	So now upper part of this network architectures correspond to environmental generative process and only a lower part correspond to single feed forward neural network architecture.
5001520	5017760	362	B	0.69478	So now this part is identical to a map from Syria in the 2022 papers.
5023300	5024144	363	A	0.5097	Okay?
5024342	5031270	364	A	0.93107	So on the top of figure two is the actual generative process.
5032120	5048116	365	A	0.97905	It's the true structure of causation in the environment, which is to say that actions delta active coherence how states change through time via b delta.
5048308	5049050	366	B	0.87362	Right.
5049740	5057260	367	A	0.99	The generative process through the A matrix emits observations, sequences of observations.
5058240	5070160	368	A	1.0	And here on the bottom with a mirrored structure is the generative model of the entity.
5070740	5078950	369	A	0.99925	So what's the relevance of the arrows and the more force factor graph structure on the bottom?
5080760	5088340	370	B	0.99	The arrow indicates active inference.
5091580	5111804	371	B	0.84673	It's a flow of the information in the sense that to calculate in the step two, we use the information of step two's observation and step one's posterior expectation of our hidden states.
5111922	5118080	372	B	0.90976	So those two determine the s two's expectation.
5118740	5127760	373	B	0.99613	Usually in the phony graph we consider retrospective arrow.
5127840	5135984	374	B	0.9815	So in the sense that s three also affect the s two influence.
5136032	5151616	375	B	0.99696	But this correspond to a Beijing smooth in the sense that we update every time step simultaneously to better inference.
5151748	5171344	376	B	0.9915	However, what we consider here is a more filtering approach in the sense that for each step we compute the latest hidden states and then we don't change any other states in the past.
5171542	5178790	377	B	0.95065	So that's why we don't consider the arrow from future to the past.
5182440	5183140	378	A	0.98375	Awesome.
5183290	5206700	379	A	0.99095	Yeah, just to highlight that in the Bayesian smoothing approach, it's kind of like fitting a spline because it takes the whole time series and it fits the smoothest possible line, or the line whose smoothness is on the AIC BIC frontier.
5207760	5227520	380	A	0.68152	But here on the bottom with the almost pseudo code implementation provided by the 40 factor graph, which was demonstrated to be equivalent with the Bayesian graph in the 2017 work with Friston, Par and DeVries.
5228440	5253210	381	A	0.99881	This architecture is reflecting a filtering scheme like a Coleman filter or just generalized Bayesian filtering through time, where estimates are being carried forward and changed time point to time point, such that the decision rules, or the updates perhaps more accurately, are defined between time points.
5253760	5261550	382	A	0.99	And the total time series does not have to be loaded into memory or remembered at once.
5261920	5272480	383	A	1.0	And then the Bayesian filtering approach has the asymmetry with a different consideration of action.
5274100	5287910	384	A	0.99464	So why again is it that action is considered differentiate in the Bayesian filtering approach on the bottom of the generative models than the consideration of action in the generative process?
5290040	5312270	385	B	0.81552	This that corresponds to lack of connection from Y to X in the figure one, or probably a figure four is helpful to that relationship.
5319540	5327436	386	B	0.99588	This is an example network architectures comprising input Dayan, middle Brea and output Dayan.
5327548	5341052	387	B	0.99778	What we consider is information flow from sensory to middle Dayan and middle area have self connection, recurrent connection and middle area project to output tray.
5341216	5347960	388	B	0.98904	So there is no connection from old output Dayan to middle Dayan.
5348540	5349290	389	B	0.96247	Right.
5350540	5365500	390	B	0.99859	So that's why we don't consider the link from derita in the bottom layer of the figure to two s posterior.
5367200	5374800	391	B	0.99598	So this is different from true generative process in the environment.
5378170	5393450	392	B	0.99966	This is a kind of simplification because our purpose is identifying the plausible Bayesian model which correspond to this typo to a neural network.
5396350	5417330	393	B	0.85265	So in other words, this neural network is and approximation about that point or use limited form of palm DP scheme.
5423810	5424560	394	A	0.99767	Thanks.
5424870	5445960	395	A	0.96051	So could you describe W VK and comma just what is the biological or functional interpretation of those variables and what brain regions or what processes or pathologies do they map to?
5447130	5493160	396	B	0.99436	Okay, so basically WVK synaptic strengths in the form of Atreides and they represent synaptic connection in a different layer or different architecture in the sense that W means forward connectivity from sensory layer to metal area, k correspond to recurrent network recurrent connectivity and V correspond to projection from metal Brea to output Brea.
5493530	5509770	397	B	0.98168	So in this paper, we don't discuss the correlation to brain anatomy in detail, but one can consider analogy.
5510130	5534370	398	B	0.95559	For example, say x correspond to cerebral cortex activity and yellow brain in the sense that it determined the action.
5534710	5542978	399	B	0.55628	So it is considered that in the cerebral there is signal that represent choice.
5543074	5549430	400	B	0.32864	This is Journey, for example gold, this is Journal or no Gold discogn made in Serbia.
5551710	5557670	401	B	0.82337	It's analogous to this particular architectures.
5557830	5582766	402	B	0.9994	On the other hand, in the several cortex we compute the accessory information to generate some inference, prediction and planning so on, which is computed by this recurrent network.
5582878	5627950	403	B	0.99951	In this particular modeling, although we don't separate brain rhythm in detail, but this recurrent network is sufficient this graph of recurrent network is sufficient to characterize any type brain architectures in the sense that we can design and higher car or mutually connected architectures using generic crossover recurrent network by weight Attial.
5635710	5656450	404	A	0.99663	So the middle layer we can think of as like the cognitive stuff, it's the internal states when we talk about perception, cognition, action in the active scheme or even in the sandwich model of cognition, perception, cognition action.
5657350	5678250	405	A	0.58056	So W is describing how those sensory inputs either in one step or composably in multiple steps become processed to these x representations of hidden external causes inferred external states.
5678320	5688346	406	A	1.0	And so these are the states that have that sigma relationship and a generalized synchrony with external states.
5688528	5706690	407	A	0.98	The sigma and the generalized synchrony are not discussed in your paper, but it connects to other work and the recurrent connections are facilitating attention or weighting of the stimuli.
5708390	5716550	408	A	0.99942	This is the recurrent learning loop and the relationship of the A between observations and hidden state estimates.
5718330	5729750	409	A	1.0	And then a different kind of modulation comes into play between the hidden state estimate of the external states and the action selection.
5729910	5734506	410	A	0.60811	So what is gamma corresponding to?
5734528	5746880	411	A	0.9	And why is the gamma modulation between layers two and three differing functionally from the k synaptic modulation of one and two?
5747970	5758734	412	B	0.95186	Yeah, so K matrix basically formally correspond to B matrix in the Bayesian progression.
5758782	5765000	413	B	0.78935	So which locate the information about the prediction, right?
5765770	5774200	414	B	0.57887	Our generative, our expectation about the next state based on the previous state.
5774890	5782662	415	B	0.51215	On the other hand, Laura gamma is quite different from such a competition.
5782726	5796606	416	B	0.91149	Gamma basically means risk factor risk function, which is in principle we can, we can use arbitrary risk function.
5796788	5833740	417	B	0.71875	This is a part of generative model we designed and the rule of risk function in generative model formulation is alternation form of generative models depending on that value of gamma which examples postdictive or retrospective modulation of and Markov decision given an outcome in the future.
5835310	5841666	418	B	0.98712	In terms of neural network, of course it corresponds to some neuromodulation.
5841798	5854610	419	B	0.99662	For example, Dopaminergic moderation is famous in the literature which modulates the activity and activity of various brain reason.
5854680	5871250	420	B	0.94643	But we particularly focus on Dopaminergic or any kind of neuromoduration of synaptic prosthesis in the output brain, which may correspond to cerebral.
5871670	5902990	421	B	0.92593	So you're in the cerebral neural activity or prosthesis moderated by domain input from it is used as the optimization rule, decision rule or sometimes attention Bijan.
5909360	5909916	422	A	0.96731	Awesome.
5910018	5925936	423	A	0.99994	Very interesting because in some previous papers and models that we've looked at, attention is dealt with as policy selection on mental states.
5926118	5936180	424	A	0.99769	So internal action selection, it's an action like variable describing attention and awareness and even metacognition.
5936840	5968080	425	A	1.0	And so that connects the role of Dopamine in motor decisionmaking seen in many Dyskinesias, but also with the role of Dopamine in seemingly non motor based decision making like gambling or investing, where it doesn't seem to immediately translate to a given motor sequence.
5969060	5991068	426	A	0.83999	Yet it has analogous computational characteristics and the comorbidities and the side effects of different drugs that affect the Dopamine neurophysiology are known to have carryover in terms of the rigidity or excessivity of motor and decision making aspects.
5991104	6019440	427	A	0.99404	So it's like interesting that Dopamine has long been understood to have that parallel role in attention as cognitive action and motor action and that was established empirically through modifications of Dopamine signaling and also had been modeled analogously with computational neuroscience.
6019860	6035990	428	A	1.0	And this is providing again a slightly different interpretation of that very well studied Dopaminergic modulation of attention and policy.
6041000	6041750	429	B	0.99355	Yes.
6042360	6052020	430	B	0.91	And in addition to that, I believe another important aspects is the modulation of scientific ergodicity by Dopamine.
6052520	6053270	431	B	0.55767	Well.
6075930	6077480	432	A	0.46654	Do you want to show something?
6078330	6079080	433	B	0.85997	Yeah.
6081050	6085262	434	B	0.99592	Can you see this paper?
6085356	6096430	435	B	0.98727	It send you PDF.
6097750	6099140	436	A	0.99878	Okay, let me see.
6100390	6102500	437	A	0.72555	I'll get it up now.
6107590	6108082	438	A	0.99605	All right.
6108136	6122606	439	A	1.0	The paper is a critical time window for Dopamine actions on the structural plasticity of Dendrite expines from 2014 by Yagoshita.
6122738	6125180	440	A	0.94822	So what is interesting about this paper.
6126030	6154510	441	B	0.99976	It basically explained conversation of activity by Dopamine, which is common but crucial point of this paper is that it shows that it's proved that Dopaminezic input can modulate Hebbian prostate ebin after Hebbian prosthesis is established.
6154590	6170306	442	B	0.97884	So this paper showed that they had open magic input, for example, two second after or several seconds after the HEPIA ergodicity is established.
6170338	6194618	443	B	0.99849	But such a post hoc moderation, post hoc introduction of Dopamine input is sufficient to change the past plasticity which may be associated with the post hoc evolution of our past decisions.
6194714	6205358	444	B	0.60532	So by decision making, we of course changes the weight matrix through activity.
6205534	6221110	445	B	0.9997	But to evaluate the goodness or badness of our decision, we need to see observe the future outcome which is propagated by, for example, Dopamine.
6221770	6243200	446	B	0.85255	This paper nicely show empirically that Dopamine actually can change the past evaluation even after such a psychic level, very local level.
6252290	6302740	447	A	0.91778	So there's a short term window, the critical time window that they're describing but there's some window, some window by which dopamine potentially unrelated to the initial heavy and plasticity event where secondary domain signaling or not secondary just after the initial fact potentially of a different valence or the same valence can synergize or cancel the plasticity formed in the moment.
6303270	6304020	448	B	0.90343	Exactly.
6305590	6313000	449	B	0.97	And this is not limited to Dopamine, but other neuromoderators can also do this.
6318330	6325130	450	A	0.99786	Well, on one hand, how does this change our understanding of animal neurophysiology?
6325470	6333690	451	A	1.0	And then, I guess on the other hand, how does this influence how we would design sentient artifacts.
6336910	6351220	452	B	0.52291	When for both animals and artificial agent?
6353430	6365270	453	B	0.98	One important message, I believe, is that this tells us possible simple architecture to make.
6365420	6396160	454	B	0.96815	Planning this is and association between past decision and future labor any risk factors which is otherwise computed by computing forward prediction by iterating some computational I believe this is a usual way to predict the future event and then select option.
6396610	6415190	455	B	0.99943	But using this property, biological property which is observed in Attial experiment, we can design, we can imagine other simpler architectures to make a planning.
6417370	6440750	456	B	0.96795	So for both animal and generative Beijing agent, it provides an alternative explanation about the association between our past decision and the future based on the optimization of our decision to maximize the reward or minimize the risk.
6445160	6457476	457	A	0.99977	Well, one interesting note is we spoke earlier about the difference between the Bayesian smoothing all at once approach and the Bayesian filtering step by step approach.
6457668	6466268	458	A	0.997	Now, if one had infinite knowledge and computational resources, the Bayesian smoothing approach is the way to go.
6466434	6469592	459	A	0.67133	Like, you don't want the decision rule for investment.
6469736	6477084	460	A	0.99999	You want to look at the whole time series past, present and future and know the best moments to have made the trades.
6477212	6478604	461	A	0.93	I mean, there's no comparison.
6478652	6481628	462	A	0.73654	You're going to do better with a Bayesian smoothing.
6481804	6489748	463	A	0.99998	However, it's just implausible computationally and because it requires total memory of the past and knowledge of the future.
6489914	6501130	464	A	0.99883	So that's what motivates the development of Bayesian filtering approaches which are tractable and calculable through time.
6501980	6505800	465	A	0.99992	Yet with this time delayed modulation.
6507500	6508008	466	B	0.99997	Part.
6508094	6512830	467	A	1.0	Of the Bayesian smoothing strength comes back into play.
6514000	6523630	468	A	0.99994	It doesn't enable true anticipation of future states, but that's what the expected free energy does.
6524740	6531890	469	A	0.99955	However, the delayed neuromodulation allows for reconsideration of a window of past states.
6532660	6548980	470	A	0.99	And so in that way it corresponds to like a slightly deeper filter, not just a filter of a time step of one, but a filter of like a rolling window of five or with some decay.
6549740	6563050	471	A	0.99	And you don't want that window to be too big because if the window were ten minutes, then too many contrasting stimuli would get piled together.
6563500	6567180	472	A	1.0	The Dopamine level would just converge to a meanfield average.
6567520	6591830	473	A	0.99997	But there's some time decay or time constant on the post hoc modulation where that neuromodulatory signal is actually a parameter of interest and that's not an infinitely long or infinitely short window, but it's some niche dependent amount of time.
6592680	6611028	474	A	1.0	And that's a very interpretable and first principles interpretation of the computational role of neuromodulators in a way that is also consistent with all these other concordances we've been exploring.
6611204	6622460	475	A	0.99928	So it's quite an interesting connection back I guess in our final minutes of this discussion.
6627020	6653900	476	A	0.97372	What are you well, maybe go to the beginning at the and which I meant to ask earlier, but it's a good way that we can sort of close today and look forward, which is how did you come to this line of research specifically studying neural networks in this way with Karl Friston and your colleagues?
6658400	6678036	477	B	0.51561	So yes, my interest was the characterization of biological network.
6678228	6695500	478	B	0.99764	So my first motivation is to make biological plausible artificial intelligence, but to active that we need to know about biological brain or biological neural network.
6700820	6749496	479	B	0.87698	In these February years, I collaborated with the doctor professor Karl Friston to study about his Calgary real as a principal after doing for us and then what my question during that period, was everything about the verdict neural network or is there any other aspects that can characterize the Barriscar neural network?
6749608	6752460	480	B	0.84684	So it is non trivial.
6753360	6755140	481	B	0.943	It was non trivial.
6755320	6767284	482	B	0.87683	So that's why I tried to start from characterizing the neural network first.
6767482	6796990	483	B	0.54277	So our strategy is not considering the way of implementing any Bayesian agreement as the brain architecture, but my interest is rather characterization of a given vertical network in terms of something, some other things.
6797520	6803260	484	B	0.99	One possible way is of course based on inference free energy coherence.
6803700	6809520	485	B	0.80084	So that's why I first start from characterizing bioscon network.
6810740	6833792	486	B	0.9897	But just defining neural network architectures is insufficient, it is not trackable, it is far beyond the computational tractability as the mathematical analysis.
6833856	6843500	487	B	1.0	And we need some assumption, some trick to increase the tractability.
6844000	6865744	488	B	0.84	And one day I came up with an idea that in which we considered that both neuron activity and prosthetic flow the same cost function gradient.
6865872	6877484	489	B	0.99983	This is very much analogy with physical system like Lagrangian correlation or Habilitonian formulation.
6877552	6899528	490	B	0.50083	So usually we consider some energy landscape and design plausible trajectory as the solution of some principle of minimum action or risk action.
6899704	6921460	491	B	0.96563	So we imagine that what if we apply such idea to conventional neural network or voucher neural network to characterize the dynamics in the fast principle.
6923640	6929720	492	B	0.85838	That's a fast motivation fast step to come up with this framework.
6931500	6958448	493	B	0.91	And finally we noticed that it is not easy to connect the Newtonian dynamics with this type of neural activity study because neural activity are not necessary to be a second order differential equation, but rather it is first order and considering many things.
6958534	6989144	494	B	0.998	Then we finally used a cost function proposed in the papers which is not necessary have a formal identity with the Socalled ravalanjian in the Newtonian physics.
6989192	7003760	495	B	0.52962	But it is rather plausible as the rule or underlying mechanism of such type of network.
7011950	7012700	496	A	0.99979	Awesome.
7013630	7019934	497	A	0.99745	Well, it has been quite an interesting one.
7020132	7024640	498	A	1.0	I really appreciate everything you've shared today.
7025250	7027422	499	A	0.99979	Is there anything else you want to add at this point?
7027476	7029040	500	A	0.99994	Otherwise we'll talk again.
7033890	7038654	501	B	0.92	I already speak a Ronen, thank you.
7038772	7040830	502	A	0.99566	All right, talk to you later.
7040900	7041550	503	A	0.9615	Bye.
7042450	7044530	504	B	0.99986	Thank you very much for the nice discussion.
