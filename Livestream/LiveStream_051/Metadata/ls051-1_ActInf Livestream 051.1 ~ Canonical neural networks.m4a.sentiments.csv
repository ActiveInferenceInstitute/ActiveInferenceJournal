start	end	speaker	sentiment	confidence	text
38860	41080	A	0.5948757529258728	Key all right, hello everyone.
41150	41816	A	0.7317204475402832	Welcome.
41998	45640	A	0.8944810628890991	This is activem live stream number 51.1.
45790	52760	A	0.8774380683898926	We are in the second discussion of our this paper canonical neural networks perform active inference.
53340	55892	A	0.6894928216934204	Welcome to the active inference institute.
56036	62164	A	0.5337911248207092	We're a participatory online institute that is communicating, learning and practicing applied active inference.
62292	67692	A	0.8799402117729187	You can find us on the this slide and this is recorded in an archived Livestream.
67836	70976	A	0.5307847857475281	So please provide us feedback so we can improve our work.
71158	76560	A	0.9208272099494934	All backgrounds and perspectives are welcome and we'll follow good video etiquette for livestreams.
77060	85060	A	0.7317577004432678	Head over to activemfirms.org to learn more about the institute and how to participate in projects and learning groups.
86040	99956	A	0.7094440460205078	All right, we're in Livestream number 51 one and having our first non solo discussion on this paper, canonical Neural Networks Perform Active Inference.
100148	104988	A	0.9808313250541687	And really appreciative dakuya that you've joined today.
105074	107448	A	0.9682714343070984	It's going to be a great discussion.
107624	109512	A	0.8881863355636597	We'll begin with introductions.
109576	118444	A	0.6313851475715637	I'll say hello and then please just jump in however you'd like and we can start by setting some context.
118572	120092	A	0.8010696172714233	So I'm Daniel.
120156	137520	A	0.9025965929031372	I'm a researcher in California, and I was interested in this paper because we've been talking a lot about active inference from a variety of different perspectives, from the more fundamental math and physics to some applications.
137600	142372	A	0.8829883933067322	Philosophy embodiment all these really interesting threads.
142516	159576	A	0.8903969526290894	And this paper seems to make a really clear, meaningful contribution and connection by connecting active inference entities and this approach of modeling to neural networks which are in daily use globally.
159768	166448	A	0.9859209656715393	So thought it was a fascinating connection and really appreciate that we can talk about this today.
166534	168690	A	0.9168375730514526	So to you and welcome.
174570	178280	A	0.6384960412979126	Go for it Tokuya however you'd like to introduce and say hello.
178730	179574	B	0.5491447448730469	Yeah.
179772	180278	B	0.5325649380683899	Hi.
180364	186250	B	0.9234662055969238	I'm Takai Somar, neuroscientist in Lieken Brain Science Institute in Japan.
186670	196490	B	0.6824936270713806	I'm particularly interested in universal characterization of neural network and brain using mathematical techniques.
196650	213630	B	0.7509509921073914	So this work I believe important as a link between active coherence aspect aspect of the brain and the dynamic system aspect of the neural network.
213790	217770	B	0.9835786819458008	So I'm very happy to join this discussion.
217950	219586	B	0.9678386449813843	Thank you for invitation.
219778	221000	B	0.9245960712432861	Nice to meet you.
222090	224440	A	0.9636296629905701	Nice to meet you as well.
226490	231850	A	0.8458783626556396	The first thing you added, the universal characterization of neural networks.
232430	236374	A	0.8708625435829163	What is the universal characterization of neural networks?
236422	239820	A	0.6338547468185425	Why is it being pursued in this area of research?
241310	269202	B	0.8082627058029175	So, as a narrow sense, my main aim of this paper is that so people use active inference formularization to characterize brain activity, behavior, so on and so on, but which would be different from a conventional neural network.
269266	290026	B	0.6438648104667664	So there is a crossover program which is associated with conventional neural network and it is not very clear whether all characterization of computational neural network can be explained by active infrastructure and as a principle or not.
290128	320326	B	0.8827454447746277	So here universal characterization means that parameterisation of every aspect of conventional neural network which is a kind of dynamical system derived as association between biological phenomena and simple mathematical formula, typically using differential equations as the broad sense.
320508	342410	B	0.7368191480636597	I think universal characterization means that well, it is a characterization of brain intelligence, but it's a big picture and what the paper particular address is only one aspect of the full picture.
346290	355490	A	0.5919206142425537	All right, so it'll be great to pull back to really understand what synthesis is happening.
355640	365778	A	0.8891201615333557	So I'm going to ask what makes a neural network model a neural network model and what makes an active inference model an active inference model?
365944	371560	A	0.8668212294578552	Is this synthesis and connection you've made true because of what?
374330	399626	B	0.7492888569831848	Because basically what we showed is the mathematical equivalence between the correlation of canonical neural networks and the correlation active inference lab in the sense that we show that a stress of neural network can be characterized by a minimization.
399738	402718	B	0.7703664302825928	Of some biological plausible cost function.
402884	422360	B	0.7509914636611938	And we show that that cost function can be lead as variation of Bayesian coherence and particular cross of generative model in terms of well known partially observable process.
426080	433970	A	0.9089249968528748	All right, shall we perhaps walk through some of the action of the paper?
434420	435376	A	0.9647946953773499	It would be awesome.
435478	447190	A	0.8992488980293274	Just for each of these sections, maybe the numbered and the lettered sections, what does the section aim to show and why was it there in the paper?
460820	461724	B	0.8033221364021301	It's and overview.
461772	486024	B	0.8570767045021057	Right, first we introduce so the main issue, main program, our interest, which is a relationship, which is that we try to make a formal ring between neural network and active infrastructure.
486072	490056	B	0.8299337029457092	That's the main problem background.
490168	499676	B	0.8589521050453186	And then we first formulate the equivalent mathematical equivalence in a very broad manner.
499868	521770	B	0.8204236626625061	So in the least action in result, we formulate the relationship using concrete cross theorem, which is a well known statistical theorem proposed very long time ago.
522380	535704	B	0.776578426361084	And using that, we link a general form of neural network with a general form of variational data coherence.
535832	553932	B	0.6051488518714905	But a problem is that this characterization does not address a specific generative model which is crucial to characterize a specific model, specific neural network dynamics.
553996	574040	B	0.9144590497016907	So in the following sections, we characterize the problem using Pomodb or partially observer Marco digital process and link that model with a particular cross of canonical neural network.
575820	589260	B	0.8985832333564758	And then we simulated we used the simulation to corroborate that property in terms of some maze task.
595150	597500	A	0.949095606803894	All right, thank you for this.
598270	602350	A	0.9226244688034058	Could we talk about the complete class theorem?
602770	614260	A	0.8830890655517578	So what is the scope of the complete class theorem and why was it the relevant set of the neural networks to pursue or the right way to frame it?
615270	617090	B	0.7848424315452576	Thank you for asking that.
617160	625106	B	0.9348587393760681	So I like the slide you showed the last week's video.
625288	636310	B	0.8890935182571411	The computer basically indicates the relationship between some crossover decision rule and Beijing inference.
637210	664746	B	0.6137454509735107	Here a crucial keyword is admissibility or admissible decision rule, which is rule which is the same as good as other decision rules or at least at one point better than other decision rules.
664778	674266	B	0.5103645324707031	So simply speaking, administrative indicate in some sense it is the best rule for some aspect.
674398	683366	B	0.8198201656341553	And usually we characterize such a goodness using cost function loss function or risk function.
683548	707962	B	0.8566752076148987	And here what we did is establish some association with this type of loss function or risk function with function of canonical neural network which is we call cost function or biological cost function for neural network.
708106	713586	B	0.8698274493217468	So our assumptions is that neural network minimize cost function.
713768	730200	B	0.5942939519882202	So if it achieved the minimization and it is validly achieved some sort of optimality so we can say it is admissible with respect to that cost function.
730650	751910	B	0.6853088140487671	So the beauty of complete cross serum is that if we find some admissible decision then automatically we can say that it is based on coherence in terms of some Bayesian cost function with generative model or prior beliefs.
752070	767214	B	0.811799168586731	So this complexity theorem is crucial as abstract characterization of the relationship between conventional neural network architectures, dynamics and variational.
767262	768450	B	0.8718595504760742	Beijing inference.
771830	773860	A	0.7708016633987427	Right, thank you.
775450	780360	A	0.7769990563392639	What does it mean when you said it was biologically plausible of a loss function?
782090	808190	B	0.7797316908836365	The term is a little bit arbitrary because in this paper we Dean by prosperity in the sense that this neural network model can be derived from heuristic neural model through some approximation.
810850	823620	B	0.8778433799743652	Here, biological probability suggests or means probability as a neural model or synaptic prostitution model.
824390	836390	B	0.7425538897514343	And if this cost function loss function can derive such a plausible algorithm, then we can say that this cost function is vertically plausible.
839630	847980	A	0.8488853573799133	So what is the distinction between those neural and synaptic components in the loss function or what equation to look at?
849710	854154	B	0.7853382229804993	You mean distinction between dynamics and synaptic?
854282	854670	A	0.5491447448730469	Yeah.
854740	859070	A	0.8511240482330322	What is the distinctions between them and how is it represented in the equations?
860690	884406	B	0.8534062504768372	Okay, basically neuroptivity equation means differential equation about variable that represent firing intensity or some sort of variables associated with the neural firing on the other.
884428	900650	B	0.8930097222328186	And synaptic plastic creation means an update rule about the synaptic weight or synaptic strengths which is a connection between two neurons.
901150	926440	B	0.8213480710983276	And beauty of this formulation in this paper is that we characterize both heuristic equation and synaptic process in terms of gradient descent on a same cost function, common Costa function.
927050	950198	B	0.9064164757728577	So we can say that if we consider the partial derivative of some cost function with respect to neural activity, then it derives gradient descent rule about activity neuroptivity.
950374	959790	B	0.9156093597412109	While if we consider partial generative of cost function L with respect to synaptic weight, then we derive a synaptic prosthesis rule.
970340	978420	A	0.8534008860588074	Are those the only two aspects of a neural network or why are those the two key aspects?
984040	990740	B	0.8651131987571716	I think it's a main body of the neural activity.
990820	1017824	B	0.8635802865028381	If we consider some inference running our action exhibit by neural network in the sense that neural activity correspond to fast dynamics, fast gradient dynamics mix and while synaptic prostitution indicates a slow dynamics that minimize risk function cost function.
1018022	1024168	B	0.8858672976493835	But in general we can consider and aspect any variables associated with Urinator.
1024204	1045012	B	0.8354518413543701	For example ant least what we show in the paper is any free parameter which may be associated with firing threshold or although we don't discuss in this paper it would be possible to add other variables related to neural network.
1045076	1060480	B	0.7626307010650635	For example, here we ignored contribution of griar factor but it would be possible to add the grille factor in this correlation or any other aspect of virus Carnap network.
1064740	1096408	A	0.8412891030311584	That's very interesting and it speaks also to a general separation of timescales, for example in different multi scale systems or in the renormalization group where it's describing some minimal multi times scale system where the faster time scale can be seen as perception like and the slower timescale can be seen as more learning like.
1096574	1103800	A	0.8216408491134644	And then in some hierarchical model what's learning of one time scale can be perceptual for a slower time scale?
1103880	1107340	A	0.9597514867782593	So it's a very nice generalization.
1112500	1123476	A	0.9159371852874756	Are there any examples of decision rules that will help us think about the action components of what the neural network is doing?
1123658	1135716	A	0.6064329743385315	Because it may be more familiar to think about digit characterization and image classification, some kind of classical tasks for neural networks.
1135908	1141480	A	0.8562892079353333	But how does the decision rule play out in the context of neural networks?
1144300	1156190	B	0.8793553113937378	Okay, so in this paper we basically assume a close group comprising a neural network part and environmental part.
1156560	1167520	B	0.8641238808631897	So Neuron receives sensor input from environment and provides some feedback to the environment.
1171860	1187844	B	0.880206286907196	Even with the example of digit classification we can say that output correspond to classifier classification output which is kind of decision rule.
1187972	1200920	B	0.814005970954895	More relevant example would be for example controller agent like a robot control or any kind of controlling or decision making tasks.
1201080	1224020	B	0.8843303322792053	For example, when we encounter some choice task we need to advertise, for example left or right or something, any kind of Dutch a decision can be associated with the adommissibility or atomic decision rule.
1227170	1238270	A	0.8304945826530457	So what would and example of an inadmissible or admissible strategy be in the decision making task?
1240930	1270650	B	0.52907794713974	Admissibility usually characterized by loss function or risk function here in adommissibility indicate that there is another decision rule which is at least one point better than the forecast decision rule.
1272670	1286190	B	0.8179696798324585	Simply speaking in Adobe Civility indicate that decision rule is not better, not good negatively.
1287170	1290820	A	0.5110301375389099	Let's just say our decision rule is we always turn right.
1291590	1293934	A	0.8060204386711121	Is that an example of a decision rule?
1293982	1302530	A	0.5415184497833252	Because there might be settings where that is strictly effective and the simplest rule whereas there's other settings where that's going to be tragic.
1302690	1311110	A	0.8833467364311218	So what does it mean to be admissible for an agent in light of different environmental contexts?
1312350	1314234	B	0.7870833873748779	That's an interesting point.
1314352	1331680	B	0.7774111032485962	So even with such a too much simplified rule it can be admissible under some particular situation, particular loss function.
1332130	1341218	B	0.7545959949493408	For example, the ruler that always turns right, maybe the best under some situation right.
1341384	1355750	B	0.8119932413101196	So the relationship of admissibility or in admissibility depends on both agent characteristic and the environmental characteristic.
1359450	1362410	A	0.8159128427505493	What aspects of the environment?
1366510	1389410	B	0.6049516797065735	For example, if that decision rule matches the structure architecture of environment then maybe that decision always turn right, achieves the shortest past right under some situation some environment.
1391830	1397090	A	0.6497405767440796	How does this admissibility help us think about, like, overfitting?
1398170	1408630	A	0.7826122045516968	And how does it help us think about the way that different practices are used for neural networks to prevent them from being overfit in practice?
1410890	1424190	B	0.6307580471038818	Well, strictly, adomissibility is characterized with the patient risk.
1424870	1442994	B	0.7497339248657227	So we cannot observe a hidden states of the environment, only we can observe Hae Park of the entire universe.
1443042	1454102	B	0.7749809622764587	So the question is, an important question is what is the best choice under such a limited information?
1454236	1459382	B	0.692545473575592	Limited information.
1459516	1489922	B	0.8313066959381104	So this basically complexity tell us that only the well known Beijing framework achieved the admissible decision.
1489986	1500674	B	0.5440682768821716	Which means that in this aspect, beijing optimization give us a best choice strategy.
1500722	1513150	B	0.6288492679595947	Otherwise we all buffet or find the suboptima evolution.
1513890	1527550	B	0.8716924786567688	So it's a nice association, nice linkage between the decision what is a good decision about the decision, and the more established statistical coherence Beijing and influence framework.
1531290	1534210	A	0.9836751818656921	Thank you, that's very helpful.
1534290	1544010	A	0.7165529131889343	So we're reducing our uncertainty and risk about hidden states in the environment.
1544350	1563310	A	0.8163830637931824	So in the special case where the entire environment is observable without error, like a chess game, then there's an equivalence between calculation of risk or loss on observables or on hidden states.
1563380	1567060	A	0.7673779129981995	But they're not really hidden, but they are environmental states.
1567590	1605898	A	0.770844578742981	Whereas any amount of uncertainty in the mapping between observations and hidden states, which is usually shown as a in the partially observable Markov decision process, any amount of uncertainty about unobserved or partially observed environmental states enables you to fit your uncertainty optimally about that hidden states and fit that uncertainty simply with a gradient descent.
1606074	1630390	A	0.5945001840591431	And by doing so, you don't overfit a model of observables, which might be the fallacy or the issue with simply doing descriptive statistics, you might get an infinitely small variance with a frequentist estimate because you have 100,000 data points.
1630540	1636440	A	0.7772673964500427	So the variance from a descriptive statistics perspective might be very small.
1641150	1655194	A	0.7710575461387634	I think it speaks very much to why neural networks are useful in practice from training with limited data sets, because that's an empirical conversation that they don't entirely overfit.
1655322	1660350	A	0.5395625233650208	But also, I'm sure there's ways to construct them that are overfit.
1661250	1670814	B	0.6454049348831177	Yeah, overfit would occur if we select some optimal prior beliefs.
1670862	1671620	B	0.6899105906486511	For example.
1673830	1696778	B	0.7218766212463379	Well, I'm not sure if it is overfit in the sense that you mentioned, because if we select some prior base, then the Beijing function itself changes and the neural network that try to fit to that cost function.
1696864	1712030	B	0.6849080920219421	So cost function minimization will be achieved such a situation, but that evolution is not good for our original purpose.
1712930	1714480	B	0.5990576148033142	That's a tricky part.
1714790	1715586	B	0.5491447448730469	Yeah.
1715768	1730360	A	0.5090389847755432	That is reminiscent of some discussions we've had discussing, like driving off a cliff or blowing up is also reducing free energy, like dropping off a building reduces your potential energy.
1730730	1749590	A	0.5354290008544922	And so there are potentially decision making or strategic trajectories that do for some time horizon minimize free energy, perhaps even or maybe even guaranteed better than some longer time horizon.
1749750	1761230	A	0.49002692103385925	Because if the short term strategies were somehow better than the long term horizon, it would be difficult to imagine because the long term horizon would be at least as good as a short term strategy.
1762530	1768078	A	0.7763910293579102	So that speaks to the challenges of planning in action.
1768174	1777080	A	0.9064056873321533	So how is planning addressed in Modern neural networks and how does this work help us think about that?
1780010	1783350	B	0.7076609134674072	That's another very important aspect.
1785770	1812270	B	0.5267134308815002	I have to say that this framework address planning aspects, but that planning is not necessarily the optimal optimal solution in the sense that what we interested in is optimization or planning under limited structure.
1814230	1821170	B	0.8257446885108948	The structure is characterized by here birdscape prospero to a neural network.
1821670	1834934	B	0.8222060203552246	So yes, planning occurred by an association between risk in the future and our decision in the past.
1835132	1849290	B	0.9149922728538513	Here we model that aspects using delayed moderation of symptomatic activity mediated by some neuromodurator or neurotransmitters.
1853470	1876930	B	0.8461587429046631	This is model as this is model as product of the risk factor and the behavior product on the neural network.
1882090	1889454	A	0.7946822047233582	All right, I'm going to ask a great question from the chat and then we'll look at the figures a little closer.
1889602	1895690	A	0.798363208770752	So ML Don wrote a question stuck in my mind for a long time.
1895840	1897978	A	0.8244044780731201	Could you please put it to rest?
1898144	1906670	A	0.879948616027832	Do we need to have knowledge about all states possible actions and sensory inputs for active inference?
1910920	1928170	B	0.7411920428276062	Well, you mean if you seek the exact solution, optimized solution, then maybe more information would help you to find that.
1929020	1948240	B	0.7115680575370789	But under some model, under some idea assumption, then the variables is not necessary to achieve the optimal evolution.
1949780	1953890	B	0.574196457862854	I'm not sure if I correctly answer your point.
1955640	1958390	A	0.7975739240646362	So just to restate it.
1959240	1964980	A	0.6102325320243835	Of course, knowing all the states possible actions and sensory inputs, it's not a bad thing.
1965130	1972036	A	0.514402449131012	Worst case, there's some computational complexity, trade offs, but the problem becomes fully stateable.
1972228	1996770	A	0.6594624519348145	But I think Mldon is asking about cases where you don't know all of the state spaces or potentially even the dimensionality or the semantics of hidden states, active states, sensory inputs, and why not even and cognitive states.
1998500	2012310	A	0.9044854640960693	So in not just partially observed but partially known state spaces, how are these addressed in neural networks and how does active inference help us think about it.
2017900	2032960	B	0.8806984424591064	Okay, I think the function is about how can we separate those states like least active coherence external.
2037180	2053804	A	0.7092271447181702	How can we separate, not just in principle have these states be separated, but deal with the fact that some of these states we might have good knowledge on and some states like the hidden states we might not even know.
2054002	2059024	A	0.663913369178772	We don't know the dimension of the cause vector in the world.
2059222	2060210	B	0.5826064348220825	I see.
2062660	2071840	B	0.8840073347091675	In terms of dimensionality, there is a statistical technique to estimate the dimensionality.
2071920	2080544	B	0.8689399361610413	For example, various information criteria, information criteria based information criteria.
2080672	2092090	B	0.8750435709953308	All of them try to inform or estimate plausible dimensionality about the environmental hidden states.
2093760	2115360	B	0.8580702543258667	There is an analogy with those information criteria and variation free energy minimization with virtual free energy inclination we can identify the plausible model structure which in principle involved the dimension aspect.
2116500	2137050	B	0.5733736157417297	But in terms of neural network in this paper we don't carefully consider about the dimension optimization because we first define the NABO neuron and don't change during training.
2137660	2157200	B	0.8979158401489258	But in principle we can consider the change in the number of neuron which is associated with the, for example, neurogenesis adult neurogenesis or development during the development stage.
2157620	2166240	B	0.7171939015388489	That would be an important extension of this direction.
2173640	2175270	A	0.959330141544342	That's very interesting.
2176040	2178580	A	0.7187589406967163	Here's a remark.
2179160	2187960	A	0.8223819732666016	Well, one note is equation one summarizes a lot of what you've been describing.
2188460	2201580	A	0.8565160632133484	There's a parallelism or a concordance being drawn between the loss function of neural networks and the variational free energy of the parameterized model there.
2201730	2225460	A	0.5321059823036194	So to come back to these processes that influence learning which we could think of as the neural network becoming more fit from a loss function perspective or the variational Bayesian partially observable Markov decision process entity generative model becoming better at doing what it does.
2225610	2245420	A	0.7885109782218933	So there's the firing rate on the neural network side the synaptic plasticity at a slower time scale which we discussed a little earlier and then now there's a third time scale with the birth and death of new cells and maybe even new layers.
2246480	2264240	A	0.49526557326316833	And that kind of multi scale temporal structuring is not intrinsic to the Bayes graph to represent multiple nested timescales in a Bayesian graph.
2264980	2284516	A	0.691898763179779	In the active inference literature it's more common to make a hierarchically nested model and just say that the time handling on one level is happening more rapidly with respect to clock time than deeper nested, slower models.
2284708	2303900	A	0.7905029058456421	Whereas the neural formulation allows us to deal with multiple ongoing timescales without appealing to hierarchical nesting which is a very important feature.
2311600	2317504	B	0.4982602596282959	Well, both direction will be possible.
2317702	2325152	B	0.8380234241485596	So without hierarchical model motoring or with hierarchical model.
2325296	2339588	B	0.5642750263214111	So even with hierarchical modeling the optimization of dimensionality should be possible, would be possible but in other direction.
2339684	2382950	B	0.8841052651405334	So we can consider that a population of neural models so one has a single layer, another has two layers, three layers, four layers and consider the probability or plausibility of network architecture associated with the performance or cost function minimization under a particular environment which is in principle have the same computational architectures with the hierarchical page and model.
2386810	2388600	A	0.9324204325675964	Very interesting.
2389290	2410830	A	0.631702184677124	Yes, perhaps I over generalized or speculated because I thought about how one could have a 100 time step POMDP that also performs multiscale behavior potentially extremely wastefully but at least it could in principle.
2411250	2422178	A	0.8706966042518616	And similarly, within a neuron there could be another neural network or some other structure approximated by that.
2422344	2440950	A	0.8526705503463745	So they almost both enable hierarchical and non hierarchical model as you described but in very different ways that lead to very different implementations.
2444170	2452650	A	0.8060539364814758	Yeah, I think this brings us to the topic of forward and reverse engineering.
2453070	2457130	A	0.7681909203529358	So you talked a lot about reverse engineering.
2458770	2468590	A	0.8874754905700684	What is reverse engineering and what is forward engineering and what has been done in these areas of engineering.
2470450	2503260	B	0.8264270424842834	Okay, I'm not an expert of divas engineering in the process, but I believe that levers here means a characterization of the blueprint of some device or machine from data observable information like activity or action behavior of some agent.
2504190	2508490	B	0.8050375580787659	So, goal is identification of blueprint.
2509230	2513854	B	0.8453112840652466	And the crucial here blueprint correspond to generative model.
2513972	2523906	B	0.7728093862533569	Because once we define generative models, we can derive various energy algorithms running influence algorithm under any behavior of agent.
2524008	2537142	B	0.7919015288352966	So, here, reverse means that we first observe some activity of agent and its mechanism is still unknown for us.
2537276	2568462	B	0.8337326645851135	But we can estimate its mechanism using activity by identifying the most plausible gear T model which can minimize some post function or risk function when we feed the data to the model the model.
2568596	2595350	B	0.6908037662506104	So, on the other hand, for engineering would be more mainstream way fast define model blueprint gently model then Deneve everything including Bayesian parametric functional running Paris algorithms, behavior action algorithm.
2600030	2615280	A	0.8876768350601196	So, by reverse engineering neural networks, we're observing some already parameterized neural network and then fitting a POMDP to it.
2616690	2628290	A	0.7935517430305481	To what extent is it possible to take a given POMDP and create a neural network that errors that inference?
2632970	2679170	B	0.8866925239562988	Okay, in this paper or in the following paper what we consider is strategy that we first fit empirical data whether for neural response data to bioscape plaudible canonical neural network model which is similar to a computational model fitting approach where we have differential equation and data and data to the differential equation to explain the behavior with the minimum prediction.
2679590	2701494	B	0.5774270296096802	So, now, a virtue of this framework we establish is that we can naturally transform such a neural network architecture with the very no partially observable Markov process architecture.
2701622	2708060	B	0.6295668482780457	Because for any kind of canonical neural network, there is a cost function.
2710050	2721762	B	0.6274883151054382	So, we derive cost function for neurotivity question which is opposite with the computational way.
2721816	2736530	B	0.907613217830658	We first define cost function derived algorithm and then we use the force the formal equivalents between neural network cost function and Virginia query.
2737690	2745598	B	0.8527904748916626	So, now transform the neural network architecture to Beijing model architectures.
2745794	2762010	B	0.8185154795646667	And once we characterize Virginia free energy, there should be some generative model that define that Virginia free energy function.
2765330	2778210	B	0.7690088748931885	In particular, in this example, canonical neural network necessary correspond to well known across well known Attial edition process.
2778360	2800140	B	0.8353840708732605	So, by using this procedure, we identify a plausible homedp architecture which is correspond to obsolete data.
2809500	2815310	A	0.7932830452919006	Well, let's stay on this last point.
2815920	2842480	A	0.9000838994979858	So, after all those transformations, first the measurements of neurons using that data to fit the neural network and then by virtue of the relationships unpacked in the paper, transforming the neural network in the left side of figure one into a particular form of the POMDP.
2842640	2848560	A	0.8625295758247375	So first, what are the constraints on that form of the POMDP?
2848720	2855960	A	0.8636180758476257	Is this a little corner of model space or what are the space of acceptable POMDPs?
2858220	2864140	B	0.8610717058181763	That totally depends on what kind of neural network model you are considering.
2864480	2879664	B	0.9102020859718323	So for example in this paper we discuss about a particular cross of Coda that in which each state takes either zero or one.
2879862	2890864	B	0.8086264729499817	So it's very restricted compared to the general form of OMDP but we consider a factorization.
2890992	2922110	B	0.8768154382705688	So in the sense that although each static has a Ronen of one but we consider a vector of conversation and vector of hidden state where each element correspond to Ronen single one, whole vector but as and entire state it can represent high dimension discrete state space.
2923200	2943910	B	0.5659852027893066	And this architectures nicely correspond to neural network architectures because usually each neuron takes either zero, one or some continuous variable between zero and one.
2944360	2954548	B	0.8845596313476562	So we use this association to characterize a particular home DP which correspond to neural networks.
2954724	3006680	B	0.6744258999824524	And this follows a particular Memphis approximation, approximation or approximation in generative model because we associate posterior belief in this particular homo DB with the neuropathy, which means that posterior of action also chaos, a factorization architectures in the sense that we don't fully consider about the second order statistics between neurobans activity and neurons activity, which is outside of this pulmorism.
3007500	3036690	B	0.8219443559646606	So each neurons activity correspond to posterior expectation about the particular elements of the state and we don't consider the joint posterial property of all state.
3040850	3063430	B	0.8886764645576477	So although this is a limitation, we see this as a Beijing imprint but otherwise for examples we can consider any recurrent network architecture which correspond to state to transition matrix.
3065870	3089950	B	0.7067540287971497	It would be possible to extend this architectures to higher card structure in the sense that it is straightforward to consider a tree structure or any kind of higher card structure by assuming that some neuron connect to other neuron but not connect to other neuron.
3090030	3096900	B	0.9092342853546143	So this is same as considering the higher card structure in general.
3103810	3106960	A	0.959330141544342	That's very interesting.
3108290	3124958	A	0.8824880123138428	It's commonly remarked in the base graphs that they represent the connections amongst random variables and there's a relationship between their computability and their sparsity.
3125134	3149754	A	0.8047856688499451	The sparsity structure as in which variables do or do not influence each other makes the problem tractable through factorization and just kind of conceptually like if every one of 1000 variables or an unknown number of large variables if it was all by all the number of parameters to fit on that connectivity matrix would be very high.
3149872	3154170	A	0.5851529240608215	So statistical power would be very low for any given edge.
3154330	3168930	A	0.8200860023498535	Whereas the more and more constrained you make the connectivity of the variables, the more statistical power you have to resolve or kind of spend on fitting those edges, like in a structural equation.
3169430	3182306	A	0.512014627456665	But you might be losing sight of the unknown unknowns by constraining yourself to a very limited or fallacious biology of the variables.
3182418	3218450	A	0.8266589045524597	So there's this kind of structure learning statistical inference question in the Bayes graphs then on the neural side from the biological much of neuroscience is about understanding how the firing rate, connectivity patterns and other factors, how the structure of those neural systems and their function like form and function enable adequate coherence and coherence on action.
3218950	3230530	A	0.8770233392715454	So it's like in both of those areas or really like in neural network, artificial and neural networks and in variational bays.
3231130	3257290	A	0.8987509608268738	The discussion is about how the structure and the finetuning work together to generate function and about some of the statistical or biological challenges of balancing different needs while also constraining the cost in terms of materials and biometabolism.
3257730	3265680	A	0.8657114505767822	So it's a very rich intersection that is being explored here.
3269620	3272880	A	0.827610433101654	If these models can really be moving back and forth.
3278290	3282750	B	0.820376992225647	In the sense that back and forth.
3285570	3300086	A	0.852516233921051	Moving back and forth, like there's imprints of the model that is implementation independent or like some interlingual or some semantics or compatibility, I don't really know.
3300108	3315766	A	0.7976817488670349	I mean, that's something we can explore is like what is it that is such that one could forward engineer and then reverse engineer and have kind of an expectation maximization between these two areas.
3315798	3319610	A	0.8125426769256592	So, what is it that's being sought?
3325230	3329562	B	0.4983033537864685	Yes, important point.
3329616	3357690	B	0.5061678886413574	So, for example, a virtue of this relationship is that we can use the knowledge of to explain neuropty neurodynamics, which is crucial because people often say that capitalizing dynamics is not straightforward.
3360270	3371530	B	0.7197173237800598	We may obtain some solution on neural net dynamics, but the meaning of that dynamics in terms of the functional aspects is very unclear.
3371610	3382082	B	0.5705544948577881	We don't know the meaning of connectivity strengths, matrices and what is the meaning of the threshold factor, so on and so on.
3382136	3399838	B	0.7834070920944214	Those are derived from the moderate biological phenomena, but it is not necessary to have clear linkage to function explanation.
3400014	3426480	B	0.769865870475769	So, exploration of function of the brain, but once we translate these dynamics into Bayesian infrastructure, then we can explain every functional aspect of the neural net dynamics architectures in terms of well established Bayesian inference under a particular crossover Beijing model, in this case palm DB model.
3428370	3441090	B	0.8088502883911133	So now it turns out that synaptic strengths correspond to a matrix b matrix, which are very established culture meaning.
3441990	3458010	B	0.6695960760116577	So yeah, this is useful to explain neuro and synaptic property in terms of well established statistics.
3464400	3481890	B	0.6711016893386841	Also, for the people in active inference lab site, it would be helpful to understand the neuronounce rate about particular active coherence modeling model.
3483800	3508270	B	0.8772621750831604	So I think it related to forward modeling, but finally to discuss with discuss about the biotcar substrate of that forward model, we need to address the neural network architectures substrate property.
3508800	3529404	B	0.8601285815238953	So, in that case, we can transform a particular pond Beijing modeling to a neural network architectures using this relationship and then get prediction about the substrate.
3529452	3546630	B	0.733204185962677	So, if we have ant least Beijing model, this particular quantity in this model should be possible.
3555000	3555684	A	0.8811412453651428	It's all good.
3555722	3558100	A	0.7816728353500366	Can you just repeat the last like 20 seconds?
3558760	3559510	B	0.46103888750076294	Yes.
3559820	3578910	B	0.9209538698196411	So in the last part I mentioned about first we define the Beijing model and then can predict what is the neuronal substrate that correspond to that particular Beijing model.
3579440	3588960	B	0.6037036180496216	So this will be useful to identify the biological quantities.
3590340	3593840	B	0.8827909231185913	That correspond to a quantity in Beijing.
3598120	3598870	A	0.7093686461448669	Wow.
3600440	3606230	A	0.7301774024963379	Well, there's a lot there.
3607000	3627020	A	0.8163439631462097	It makes me think about the differences of implementation and heuristics in the computational setting, which is often in the extreme disembodied, and the biological setting, which is in the extreme, entirely embodied.
3627360	3662360	A	0.7803640961647034	And for a given generative model, the kinds of computational heuristics that can be applied include a whole host of different strategies, ranging from sampling to tree exploration and branching to paralyzing the data architecture and all these other kinds of disparate strategies and software packages and implementations.
3664540	3686480	A	0.7568224668502808	But on the biological side, what is needed is something that's very simple but also very inscrutable, which is a given pattern of interactions must embody that correlation.
3688500	3699300	A	0.66755211353302	So that might mean that it can add three digit numbers, but it can't add two digit numbers under some constraints.
3700920	3707952	A	0.5598812103271484	But what isn't accessible to that kind of morphological, biological, or like form and functional computing?
3708096	3736590	A	0.6028848886489868	What's not accessible are the tree branching, the database decentralization, like they're a different set of heuristics, but they're both very useful when we're thinking about making sentience artifacts or benefiting simply from the explainability across both sides of this figure.
3738720	3739516	B	0.5491447448730469	Yeah.
3739698	3742860	B	0.6909366250038147	So now there is an important point.
3742930	3756368	B	0.8767809867858887	So, Hornetry, it is very known to bear whether there is a corresponding vertical architecture for any given Bayesian architecture.
3756464	3766068	B	0.5937913656234741	I believe it is impossible to design biascar architectures to correspond to arbitrary Bayesian architectures.
3766164	3775576	B	0.8166378736495972	So only a limited aspect of Bijan model can be implemented in a vertical, plausible manner.
3775688	3785340	B	0.8309487700462341	And that point is crucial as a characterization of biological brain.
3789520	3790076	B	0.5491447448730469	Yeah.
3790178	3790696	B	0.7093686461448669	Wow.
3790818	3796240	A	0.8780814409255981	Well, just to kind of touch again on this forward in reverse engineering.
3798440	3798804	B	0.5803324580192566	For.
3798842	3812916	A	0.8660825490951538	A given POMDP, if we're willing to compose it within a certain class, which might be quite general still, but some class of POMDP as written.
3812948	3813770	A	0.7717181444168091	On the paper.
3815020	3830632	A	0.8455480933189392	We may be able to have a neural network architectures that would be very amenable to deep learning, low energy computing, pretraining various features.
3830776	3848150	A	0.857943594455719	And then on the other side, for a given artificial neural network that we come across in the wild, or a model of neural dynamics that we fit using a neural network model.
3848840	3862440	A	0.8246371150016785	So something in a neuroscience laboratory that model can have interpretability corresponding to the variables of a given POMDP.
3862940	3872280	A	0.865664005279541	And just to kind of give one more point on how that's going deeper than, for example, statistical parametric mapping SPM.
3873040	3883964	A	0.7922968864440918	So let's just assume that the neural network we're dealing with is fit from brain data from some lucky ant right?
3884002	3908132	A	0.8954700827598572	Now, what would be possible or prior to this line of work or without this line of work, one could fit a neural dynamics model and then do all kinds of analyses, like power analyses on the different frequency spectra and say, look at the average firing rate or the correlation coefficients of firing rate.
3908186	3914216	A	0.8480722308158875	So fit the firing rates and the synaptic Plasticities and store all that data.
3914398	3924360	A	0.8204173445701599	And then we could just pick a POMDP that we've seen in the literature without any reference to the neural network and optimize the POMDP.
3924520	3935348	A	0.797306478023529	And then we could say well, it turns out that when the Pomdpo is high there's increased theta power in this firing pattern.
3935544	3947170	A	0.7979928851127625	So it's like comparing the descriptive statistics from the neural model to the descriptive summary statistics of the POMDP decision making model.
3947560	3964616	A	0.8729249238967896	However, with this formal connection there is actually an interpretability to the unobserved neural states which are what are being inferred from the fMRI measurement, from the EEG measurements and so on.
3964798	3974780	A	0.8538258671760559	Those underlying variables have a specific interpretability in relationship to the structure of the POMDP.
3981440	4006592	B	0.9103569388389587	Right, that's also very interesting, important aspect what you said is I think more conventional strategy and it is also commonly related to model comparison aspect.
4006736	4018170	B	0.8522067666053772	So we usually think bias Bayesian modeling and identify or select what is the best model to explain a given data.
4018700	4051300	B	0.5690317153930664	And this robust engineering idea involves such a model comparison aspect in the sense that we try to find the model with the best experiment ambiguity which should be have the identical function right directory addresses the exact same Costa function architectures using the transformation natural transformation.
4051720	4060150	B	0.8611866235733032	So it should be up to explain the neural data in the Bayesian sense.
4062540	4084990	A	0.709113597869873	Yeah, one can imagine how that would transform the way that current neuroimaging studies and technologies describe what it is about the measurement that provides information about the cognitive model.
4085300	4104180	A	0.6030921936035156	So to give another related example, let's just say a person was wearing an EEG headset and a previous study had shown that increased alphaband activity was associated with this behavior.
4105880	4125500	A	0.871090292930603	That's comparing a descriptive statistic of the observations of the sensor and correlating the summarized observable to some other variable like anxiety or performance on a behavior.
4127680	4150020	A	0.805997908115387	In contrast, an unobserved variable in this setting the actual underlying neural state is being correlated to some semantic generative model component.
4151480	4178380	A	0.8081551194190979	So it's no longer necessarily that any single frequency band would be associated more or less with a given outcome but it's actually some hidden states variability which gains the interpretability across this transformation.
4179040	4208740	A	0.8544607162475586	Which is a subtle point but it speaks to how broadly the equivalence would reinterpret empirical neuroimaging results as well as a variety of artificial neural network experiments and diagnostics where people do lesion studies and double knockouts on artificial neural networks.
4211100	4237772	A	0.8206645250320435	So anywhere where somebody with awareness sees that a neural network, artificial or biological is having summary features described and correlation to something that's more semantic in a quest for meaning may now have a different approach that involves foraging.
4237836	4255140	A	0.8711460828781128	The model explicitly in terms of unobserved hidden states with a cost function akin to a variational free energy, minimizing risk or bounding surprise on the unobservables.
4256520	4276780	A	0.8863771557807922	So even though the unobservables were modeled in a sense in the other conventional strategy like neural activity is a variable in fMRI experiments, it's underlying the bold signal.
4277440	4287680	A	0.6226273775100708	Yet this formalism concordance is a more coherent and powerful connection.
4294660	4296450	B	0.5684971213340759	I believe so.
4300420	4307012	B	0.5046234726905823	Very important point to address that.
4307066	4312970	B	0.7855746150016785	So we need to clarify about what is a program.
4313580	4315128	B	0.6159622669219971	Consider here.
4315214	4335740	B	0.7596433758735657	So this is a program so called metabasian problem in the sense that researchers try to infer or estimate neuro activity or brain activity which infer the external world dynamics, right.
4335810	4343132	B	0.8840763568878174	So neuron brain info environment and the researcher info brain activity.
4343276	4348972	B	0.8721315860748291	So there is a two step coherence processes.
4349116	4370440	B	0.5397128462791443	So this sort of metabasion program is quite tricky intractable because sometimes probability, sometimes random variable becomes posterior about other aspect.
4371020	4377592	B	0.8263838887214661	So I think there is some established approach about metabasium.
4377656	4405076	B	0.8803656101226807	But this paper provides some alternative in the sense that we separate two program by saying that here what we infer is simply neural network model or neural network dynamics which is shown in the left hand side of this figure.
4405258	4414356	B	0.8837806582450867	So we feed data to conventional neural network model which is a simple differential equation.
4414548	4438640	B	0.5550735592842102	But thanks to this formal equivalence between neural network dynamics and behavior, we can transform the resulting neural network architecture or dynamics into the page and infrastina in some sense post hook manner.
4440660	4454740	B	0.6884437799453735	So we nicely avoid the directory addressing the metabasium problem but obtain the same kind of solution in that sense.
4454810	4462468	B	0.8562817573547363	Yes, with combining with brain activity recording like IEG or imaging.
4462644	4477370	B	0.6947690844535828	Yeah, we can estimate a plausible neural network model in the left hand side and we can transform that to OMDP in the right hand side.
4480140	4480708	B	0.7671424746513367	Great.
4480814	4481372	A	0.9184247851371765	Awesome.
4481506	4487120	A	0.9178134202957153	I'm going to show an image and ask a question from Dave in the chat.
4487540	4504740	A	0.9096097946166992	So Dave made this image, it's the right side of figure one that we've just been looking at with the variational Bayesian correlation and he wrote the arc shown as impinging on the S self arc.
4506520	4508288	A	0.7737468481063843	Is this intentional?
4508384	4514250	A	0.8903066515922546	If so, it could represent tuning or modulation of the feedback of S into itself.
4517740	4519370	A	0.8624383807182312	Do you have a thought on this?
4520860	4522052	B	0.7123621106147766	It's attention?
4522116	4560616	B	0.8972780704498291	Yes, I think it's related to the usual formulation of Pom DB architecture and active coherence context in the sense that our decision or policy in the usual setting modify active states transition matrix b matrix here delta is alternative of policy of agent.
4560718	4573130	B	0.9007056951522827	So basically the director indicates stated transition matrix under a particular decision which agent made.
4574080	4582296	B	0.8454815745353699	In that sense what the agent changes is state transition matrix not state itself directory.
4582488	4587340	B	0.7082464098930359	That's why we use this exploration.
4589460	4590210	A	0.9184247851371765	Awesome.
4591460	4600736	A	0.5450440049171448	Very subtle but important point which is when we look at the classical POMDP formulation.
4600928	4604292	A	0.9177669882774353	So here we'll look at a version shown in figure two.
4604346	4606710	A	0.8441991209983826	I'll just bring just figure two in.
4609480	4623496	A	0.9159209132194519	Could you describe what you just did about the role of the B matrix in influencing how hidden states change and how that is where our policies have impact?
4623688	4629550	A	0.8564046025276184	And also please, how do the top and the bottom of figure two differ?
4633200	4644540	B	0.884899914264679	Okay, so in the usual formulation under active infrastructure with a palm DP structure.
4644620	4673660	B	0.8820999264717102	So for us to consider the prior free for us and depending on the prior free for us, we compute the expected free energy and its minimization provides the policy and the policy modulate active states transition.
4674320	4686530	B	0.8811689019203186	So now in the upper array we instead use the Pirator which is the option of the agent.
4687300	4695650	B	0.8602595925331116	So here computational decision was made for each time step.
4696420	4712200	B	0.8737782835960388	So that unlike the computational formulation, we have a sequence of generative and for each time step derita moderate active states transition matrix B.
4712350	4723470	B	0.8932545781135559	So B is a matrix that transform hidden state in the previous step to the S in the current time step.
4724000	4751984	B	0.8853196501731873	And it's moderation indicate that under a specific decision rule, for example, if this indicates our position in the battery environment with the goal decision our position moved forward, or if we choose no go decision, then it's unchanged.
4752112	4771050	B	0.8314992785453796	So such a conversation of state transition was made by choosing EBITDA and the lower part correspond to Beijing influence made by Beijing agent.
4771820	4801590	B	0.5968883633613586	So basically there is a symmetry between apart part and lower part because we assume that this Beijing agent has a plausible gentle model which nicely correspond to a given environment defined in the above in this figure.
4802200	4844240	B	0.6571579575538635	But one interesting thing so asymmetry is that to model this particular canonical neural network, we don't consider an arrow or link from Derek posterior to the posterior which is in the environment data moderate S in the next step through B matrix correlation.
4845300	4873160	B	0.748399555683136	In this particular Beijing engine which formally correspond to canonical neural network, we don't consider that it is correspond to and absence of the projection from output layer to the middle layer.
4879180	4879930	B	0.584351658821106	Okay.
4886000	4896252	A	0.8846415281295776	This is from the 2020 paper, but it shows the neural network architecture, the two layer architectures.
4896396	4914820	A	0.8877468705177307	So could you restate the top and the bottom of figure two in the 22 paper and connect it to why it's important that you're studying two layer neural network models?
4915960	4917190	B	0.4783906638622284	I miss you.
4917560	4918904	A	0.5364589691162109	Oh yeah.
4919022	4934540	A	0.8747391104698181	Can you just connect the asymmetry between the top and the bottom on figure two with the two layer neural network architecture?
4935520	4940430	A	0.6156938076019287	You said that the asymmetry there's no direct link between.
4945320	4949610	B	0.6943955421447754	Yes, this is another story.
4949980	4972300	B	0.8739790320396423	So in the previous paper, in the previous paper there is only output rate perceptual layer because we basically consider a single layer free toward network.
4972380	4983268	B	0.5536621809005737	So my apologies for some confusion about the network architecture in the 2020 paper.
4983354	5000840	B	0.8831067681312561	So now upper part of this network architectures correspond to environmental generative process and only a lower part correspond to single feed forward neural network architecture.
5001520	5017760	B	0.8443659543991089	So now this part is identical to a map from Syria in the 2022 papers.
5023300	5024144	A	0.7123860716819763	Okay?
5024342	5031270	A	0.912604808807373	So on the top of figure two is the actual generative process.
5032120	5048116	A	0.8794533610343933	It's the true structure of causation in the environment, which is to say that actions delta active coherence how states change through time via b delta.
5048308	5049050	B	0.5664746165275574	Right.
5049740	5057260	A	0.8652576208114624	The generative process through the A matrix emits observations, sequences of observations.
5058240	5070160	A	0.8812515735626221	And here on the bottom with a mirrored structure is the generative model of the entity.
5070740	5078950	A	0.9000088572502136	So what's the relevance of the arrows and the more force factor graph structure on the bottom?
5080760	5088340	B	0.858893096446991	The arrow indicates active inference.
5091580	5111804	B	0.8872158527374268	It's a flow of the information in the sense that to calculate in the step two, we use the information of step two's observation and step one's posterior expectation of our hidden states.
5111922	5118080	B	0.8373386263847351	So those two determine the s two's expectation.
5118740	5127760	B	0.6301206946372986	Usually in the phony graph we consider retrospective arrow.
5127840	5135984	B	0.8760808110237122	So in the sense that s three also affect the s two influence.
5136032	5151616	B	0.605074942111969	But this correspond to a Beijing smooth in the sense that we update every time step simultaneously to better inference.
5151748	5171344	B	0.8864597678184509	However, what we consider here is a more filtering approach in the sense that for each step we compute the latest hidden states and then we don't change any other states in the past.
5171542	5178790	B	0.5336402654647827	So that's why we don't consider the arrow from future to the past.
5182440	5183140	A	0.9184247851371765	Awesome.
5183290	5206700	A	0.6769174933433533	Yeah, just to highlight that in the Bayesian smoothing approach, it's kind of like fitting a spline because it takes the whole time series and it fits the smoothest possible line, or the line whose smoothness is on the AIC BIC frontier.
5207760	5227520	A	0.7628996968269348	But here on the bottom with the almost pseudo code implementation provided by the 40 factor graph, which was demonstrated to be equivalent with the Bayesian graph in the 2017 work with Friston, Par and DeVries.
5228440	5253210	A	0.8698540329933167	This architecture is reflecting a filtering scheme like a Coleman filter or just generalized Bayesian filtering through time, where estimates are being carried forward and changed time point to time point, such that the decision rules, or the updates perhaps more accurately, are defined between time points.
5253760	5261550	A	0.797831654548645	And the total time series does not have to be loaded into memory or remembered at once.
5261920	5272480	A	0.8627719283103943	And then the Bayesian filtering approach has the asymmetry with a different consideration of action.
5274100	5287910	A	0.5725248456001282	So why again is it that action is considered differentiate in the Bayesian filtering approach on the bottom of the generative models than the consideration of action in the generative process?
5290040	5312270	B	0.7915764451026917	This that corresponds to lack of connection from Y to X in the figure one, or probably a figure four is helpful to that relationship.
5319540	5327436	B	0.9042952656745911	This is an example network architectures comprising input Dayan, middle Brea and output Dayan.
5327548	5341052	B	0.9226295948028564	What we consider is information flow from sensory to middle Dayan and middle area have self connection, recurrent connection and middle area project to output tray.
5341216	5347960	B	0.5831427574157715	So there is no connection from old output Dayan to middle Dayan.
5348540	5349290	B	0.5664746165275574	Right.
5350540	5365500	B	0.5176675319671631	So that's why we don't consider the link from derita in the bottom layer of the figure to two s posterior.
5367200	5374800	B	0.6728655695915222	So this is different from true generative process in the environment.
5378170	5393450	B	0.7903141975402832	This is a kind of simplification because our purpose is identifying the plausible Bayesian model which correspond to this typo to a neural network.
5396350	5417330	B	0.897553026676178	So in other words, this neural network is and approximation about that point or use limited form of palm DP scheme.
5423810	5424560	A	0.6283750534057617	Thanks.
5424870	5445960	A	0.8996455073356628	So could you describe W VK and comma just what is the biological or functional interpretation of those variables and what brain regions or what processes or pathologies do they map to?
5447130	5493160	B	0.9090484380722046	Okay, so basically WVK synaptic strengths in the form of Atreides and they represent synaptic connection in a different layer or different architecture in the sense that W means forward connectivity from sensory layer to metal area, k correspond to recurrent network recurrent connectivity and V correspond to projection from metal Brea to output Brea.
5493530	5509770	B	0.8403289318084717	So in this paper, we don't discuss the correlation to brain anatomy in detail, but one can consider analogy.
5510130	5534370	B	0.9091706275939941	For example, say x correspond to cerebral cortex activity and yellow brain in the sense that it determined the action.
5534710	5542978	B	0.8959043622016907	So it is considered that in the cerebral there is signal that represent choice.
5543074	5549430	B	0.8596187233924866	This is Journey, for example gold, this is Journal or no Gold discogn made in Serbia.
5551710	5557670	B	0.8320183753967285	It's analogous to this particular architectures.
5557830	5582766	B	0.885389506816864	On the other hand, in the several cortex we compute the accessory information to generate some inference, prediction and planning so on, which is computed by this recurrent network.
5582878	5627950	B	0.6546105742454529	In this particular modeling, although we don't separate brain rhythm in detail, but this recurrent network is sufficient this graph of recurrent network is sufficient to characterize any type brain architectures in the sense that we can design and higher car or mutually connected architectures using generic crossover recurrent network by weight Attial.
5635710	5656450	A	0.8891217708587646	So the middle layer we can think of as like the cognitive stuff, it's the internal states when we talk about perception, cognition, action in the active scheme or even in the sandwich model of cognition, perception, cognition action.
5657350	5678250	A	0.9042090773582458	So W is describing how those sensory inputs either in one step or composably in multiple steps become processed to these x representations of hidden external causes inferred external states.
5678320	5688346	A	0.8767582178115845	And so these are the states that have that sigma relationship and a generalized synchrony with external states.
5688528	5706690	A	0.8484643697738647	The sigma and the generalized synchrony are not discussed in your paper, but it connects to other work and the recurrent connections are facilitating attention or weighting of the stimuli.
5708390	5716550	A	0.881449818611145	This is the recurrent learning loop and the relationship of the A between observations and hidden state estimates.
5718330	5729750	A	0.8720717430114746	And then a different kind of modulation comes into play between the hidden state estimate of the external states and the action selection.
5729910	5734506	A	0.86183762550354	So what is gamma corresponding to?
5734528	5746880	A	0.7961727380752563	And why is the gamma modulation between layers two and three differing functionally from the k synaptic modulation of one and two?
5747970	5758734	B	0.9026852250099182	Yeah, so K matrix basically formally correspond to B matrix in the Bayesian progression.
5758782	5765000	B	0.8663924932479858	So which locate the information about the prediction, right?
5765770	5774200	B	0.8758338689804077	Our generative, our expectation about the next state based on the previous state.
5774890	5782662	B	0.724490761756897	On the other hand, Laura gamma is quite different from such a competition.
5782726	5796606	B	0.8652945756912231	Gamma basically means risk factor risk function, which is in principle we can, we can use arbitrary risk function.
5796788	5833740	B	0.9102638959884644	This is a part of generative model we designed and the rule of risk function in generative model formulation is alternation form of generative models depending on that value of gamma which examples postdictive or retrospective modulation of and Markov decision given an outcome in the future.
5835310	5841666	B	0.8831048011779785	In terms of neural network, of course it corresponds to some neuromodulation.
5841798	5854610	B	0.5807297229766846	For example, Dopaminergic moderation is famous in the literature which modulates the activity and activity of various brain reason.
5854680	5871250	B	0.9036169648170471	But we particularly focus on Dopaminergic or any kind of neuromoduration of synaptic prosthesis in the output brain, which may correspond to cerebral.
5871670	5902990	B	0.9252451062202454	So you're in the cerebral neural activity or prosthesis moderated by domain input from it is used as the optimization rule, decision rule or sometimes attention Bijan.
5909360	5909916	A	0.9184247851371765	Awesome.
5910018	5925936	A	0.7188023328781128	Very interesting because in some previous papers and models that we've looked at, attention is dealt with as policy selection on mental states.
5926118	5936180	A	0.8787127137184143	So internal action selection, it's an action like variable describing attention and awareness and even metacognition.
5936840	5968080	A	0.514260470867157	And so that connects the role of Dopamine in motor decisionmaking seen in many Dyskinesias, but also with the role of Dopamine in seemingly non motor based decision making like gambling or investing, where it doesn't seem to immediately translate to a given motor sequence.
5969060	5991068	A	0.6773979663848877	Yet it has analogous computational characteristics and the comorbidities and the side effects of different drugs that affect the Dopamine neurophysiology are known to have carryover in terms of the rigidity or excessivity of motor and decision making aspects.
5991104	6019440	A	0.5294272303581238	So it's like interesting that Dopamine has long been understood to have that parallel role in attention as cognitive action and motor action and that was established empirically through modifications of Dopamine signaling and also had been modeled analogously with computational neuroscience.
6019860	6035990	A	0.758085310459137	And this is providing again a slightly different interpretation of that very well studied Dopaminergic modulation of attention and policy.
6041000	6041750	B	0.46103888750076294	Yes.
6042360	6052020	B	0.7413944005966187	And in addition to that, I believe another important aspects is the modulation of scientific ergodicity by Dopamine.
6052520	6053270	B	0.6177208423614502	Well.
6075930	6077480	A	0.8668386936187744	Do you want to show something?
6078330	6079080	B	0.5491447448730469	Yeah.
6081050	6085262	B	0.8644910454750061	Can you see this paper?
6085356	6096430	B	0.7914489507675171	It send you PDF.
6097750	6099140	A	0.6621345281600952	Okay, let me see.
6100390	6102500	A	0.6487113237380981	I'll get it up now.
6107590	6108082	A	0.4896698594093323	All right.
6108136	6122606	A	0.8735401034355164	The paper is a critical time window for Dopamine actions on the structural plasticity of Dendrite expines from 2014 by Yagoshita.
6122738	6125180	A	0.9392553567886353	So what is interesting about this paper.
6126030	6154510	B	0.6141010522842407	It basically explained conversation of activity by Dopamine, which is common but crucial point of this paper is that it shows that it's proved that Dopaminezic input can modulate Hebbian prostate ebin after Hebbian prosthesis is established.
6154590	6170306	B	0.8551445603370667	So this paper showed that they had open magic input, for example, two second after or several seconds after the HEPIA ergodicity is established.
6170338	6194618	B	0.8417088985443115	But such a post hoc moderation, post hoc introduction of Dopamine input is sufficient to change the past plasticity which may be associated with the post hoc evolution of our past decisions.
6194714	6205358	B	0.906726062297821	So by decision making, we of course changes the weight matrix through activity.
6205534	6221110	B	0.7251238822937012	But to evaluate the goodness or badness of our decision, we need to see observe the future outcome which is propagated by, for example, Dopamine.
6221770	6243200	B	0.8620112538337708	This paper nicely show empirically that Dopamine actually can change the past evaluation even after such a psychic level, very local level.
6252290	6302740	A	0.8488576412200928	So there's a short term window, the critical time window that they're describing but there's some window, some window by which dopamine potentially unrelated to the initial heavy and plasticity event where secondary domain signaling or not secondary just after the initial fact potentially of a different valence or the same valence can synergize or cancel the plasticity formed in the moment.
6303270	6304020	B	0.5662814974784851	Exactly.
6305590	6313000	B	0.7870861291885376	And this is not limited to Dopamine, but other neuromoderators can also do this.
6318330	6325130	A	0.6647605299949646	Well, on one hand, how does this change our understanding of animal neurophysiology?
6325470	6333690	A	0.8199424147605896	And then, I guess on the other hand, how does this influence how we would design sentient artifacts.
6336910	6351220	B	0.6186841130256653	When for both animals and artificial agent?
6353430	6365270	B	0.6307656764984131	One important message, I believe, is that this tells us possible simple architecture to make.
6365420	6396160	B	0.8564388751983643	Planning this is and association between past decision and future labor any risk factors which is otherwise computed by computing forward prediction by iterating some computational I believe this is a usual way to predict the future event and then select option.
6396610	6415190	B	0.6892935037612915	But using this property, biological property which is observed in Attial experiment, we can design, we can imagine other simpler architectures to make a planning.
6417370	6440750	B	0.8222775459289551	So for both animal and generative Beijing agent, it provides an alternative explanation about the association between our past decision and the future based on the optimization of our decision to maximize the reward or minimize the risk.
6445160	6457476	A	0.7037176489830017	Well, one interesting note is we spoke earlier about the difference between the Bayesian smoothing all at once approach and the Bayesian filtering step by step approach.
6457668	6466268	A	0.5765283703804016	Now, if one had infinite knowledge and computational resources, the Bayesian smoothing approach is the way to go.
6466434	6469592	A	0.6117194294929504	Like, you don't want the decision rule for investment.
6469736	6477084	A	0.5534510016441345	You want to look at the whole time series past, present and future and know the best moments to have made the trades.
6477212	6478604	A	0.6546281576156616	I mean, there's no comparison.
6478652	6481628	A	0.650366485118866	You're going to do better with a Bayesian smoothing.
6481804	6489748	A	0.7955893874168396	However, it's just implausible computationally and because it requires total memory of the past and knowledge of the future.
6489914	6501130	A	0.5545856952667236	So that's what motivates the development of Bayesian filtering approaches which are tractable and calculable through time.
6501980	6505800	A	0.4944218397140503	Yet with this time delayed modulation.
6507500	6508008	B	0.5885525941848755	Part.
6508094	6512830	A	0.874504029750824	Of the Bayesian smoothing strength comes back into play.
6514000	6523630	A	0.5737380385398865	It doesn't enable true anticipation of future states, but that's what the expected free energy does.
6524740	6531890	A	0.8097062110900879	However, the delayed neuromodulation allows for reconsideration of a window of past states.
6532660	6548980	A	0.896230936050415	And so in that way it corresponds to like a slightly deeper filter, not just a filter of a time step of one, but a filter of like a rolling window of five or with some decay.
6549740	6563050	A	0.559235155582428	And you don't want that window to be too big because if the window were ten minutes, then too many contrasting stimuli would get piled together.
6563500	6567180	A	0.7323551177978516	The Dopamine level would just converge to a meanfield average.
6567520	6591830	A	0.790579080581665	But there's some time decay or time constant on the post hoc modulation where that neuromodulatory signal is actually a parameter of interest and that's not an infinitely long or infinitely short window, but it's some niche dependent amount of time.
6592680	6611028	A	0.6136232614517212	And that's a very interpretable and first principles interpretation of the computational role of neuromodulators in a way that is also consistent with all these other concordances we've been exploring.
6611204	6622460	A	0.9756578803062439	So it's quite an interesting connection back I guess in our final minutes of this discussion.
6627020	6653900	A	0.741813600063324	What are you well, maybe go to the beginning at the and which I meant to ask earlier, but it's a good way that we can sort of close today and look forward, which is how did you come to this line of research specifically studying neural networks in this way with Karl Friston and your colleagues?
6658400	6678036	B	0.5065398216247559	So yes, my interest was the characterization of biological network.
6678228	6695500	B	0.7804433703422546	So my first motivation is to make biological plausible artificial intelligence, but to active that we need to know about biological brain or biological neural network.
6700820	6749496	B	0.9069457650184631	In these February years, I collaborated with the doctor professor Karl Friston to study about his Calgary real as a principal after doing for us and then what my question during that period, was everything about the verdict neural network or is there any other aspects that can characterize the Barriscar neural network?
6749608	6752460	B	0.5330686569213867	So it is non trivial.
6753360	6755140	B	0.5706771016120911	It was non trivial.
6755320	6767284	B	0.8439331650733948	So that's why I tried to start from characterizing the neural network first.
6767482	6796990	B	0.8163440823554993	So our strategy is not considering the way of implementing any Bayesian agreement as the brain architecture, but my interest is rather characterization of a given vertical network in terms of something, some other things.
6797520	6803260	B	0.8376538157463074	One possible way is of course based on inference free energy coherence.
6803700	6809520	B	0.8763362765312195	So that's why I first start from characterizing bioscon network.
6810740	6833792	B	0.7796473503112793	But just defining neural network architectures is insufficient, it is not trackable, it is far beyond the computational tractability as the mathematical analysis.
6833856	6843500	B	0.8338170647621155	And we need some assumption, some trick to increase the tractability.
6844000	6865744	B	0.7015043497085571	And one day I came up with an idea that in which we considered that both neuron activity and prosthetic flow the same cost function gradient.
6865872	6877484	B	0.867849588394165	This is very much analogy with physical system like Lagrangian correlation or Habilitonian formulation.
6877552	6899528	B	0.9142694473266602	So usually we consider some energy landscape and design plausible trajectory as the solution of some principle of minimum action or risk action.
6899704	6921460	B	0.9055362343788147	So we imagine that what if we apply such idea to conventional neural network or voucher neural network to characterize the dynamics in the fast principle.
6923640	6929720	B	0.7284615635871887	That's a fast motivation fast step to come up with this framework.
6931500	6958448	B	0.49322110414505005	And finally we noticed that it is not easy to connect the Newtonian dynamics with this type of neural activity study because neural activity are not necessary to be a second order differential equation, but rather it is first order and considering many things.
6958534	6989144	B	0.7849168181419373	Then we finally used a cost function proposed in the papers which is not necessary have a formal identity with the Socalled ravalanjian in the Newtonian physics.
6989192	7003760	B	0.7027198076248169	But it is rather plausible as the rule or underlying mechanism of such type of network.
7011950	7012700	A	0.9184247851371765	Awesome.
7013630	7019934	A	0.9515298008918762	Well, it has been quite an interesting one.
7020132	7024640	A	0.9860720038414001	I really appreciate everything you've shared today.
7025250	7027422	A	0.902848482131958	Is there anything else you want to add at this point?
7027476	7029040	A	0.7310770153999329	Otherwise we'll talk again.
7033890	7038654	B	0.7238249778747559	I already speak a Ronen, thank you.
7038772	7040830	A	0.7073058485984802	All right, talk to you later.
7040900	7041550	A	0.5137447118759155	Bye.
7042450	7044530	B	0.9884634613990784	Thank you very much for the nice discussion.
