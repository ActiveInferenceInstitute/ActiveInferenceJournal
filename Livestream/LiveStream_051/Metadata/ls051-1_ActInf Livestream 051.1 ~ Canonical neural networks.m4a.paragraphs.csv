start	end	paragNum	speaker	confidence	startTime	wordCount	text
38860	55892	1	A	0.12903	00:38	35	Key all right, hello everyone. Welcome. This is activem live stream number 51.1. We are in the second discussion of our this paper canonical neural networks perform active inference. Welcome to the active inference institute.
56036	85060	2	A	0.50022	00:56	74	We're a participatory online institute that is communicating, learning and practicing applied active inference. You can find us on the this slide and this is recorded in an archived Livestream. So please provide us feedback so we can improve our work. All backgrounds and perspectives are welcome and we'll follow good video etiquette for livestreams. Head over to activemfirms.org to learn more about the institute and how to participate in projects and learning groups.
86040	118444	3	A	0.65691	01:26	63	All right, we're in Livestream number 51 one and having our first non solo discussion on this paper, canonical Neural Networks Perform Active Inference. And really appreciative dakuya that you've joined today. It's going to be a great discussion. We'll begin with introductions. I'll say hello and then please just jump in however you'd like and we can start by setting some context.
118572	166448	4	A	0.98974	01:58	96	So I'm Daniel. I'm a researcher in California, and I was interested in this paper because we've been talking a lot about active inference from a variety of different perspectives, from the more fundamental math and physics to some applications. Philosophy embodiment all these really interesting threads. And this paper seems to make a really clear, meaningful contribution and connection by connecting active inference entities and this approach of modeling to neural networks which are in daily use globally. So thought it was a fascinating connection and really appreciate that we can talk about this today.
166534	168690	5	A	0.98723	02:46	5	So to you and welcome.
174570	196490	6	A	0.99854	02:54	39	Go for it Tokuya however you'd like to introduce and say hello. Yeah. Hi. I'm Takai Somar, neuroscientist in Lieken Brain Science Institute in Japan. I'm particularly interested in universal characterization of neural network and brain using mathematical techniques.
196650	224440	7	B	0.90487	03:16	48	So this work I believe important as a link between active coherence aspect aspect of the brain and the dynamic system aspect of the neural network. So I'm very happy to join this discussion. Thank you for invitation. Nice to meet you. Nice to meet you as well.
226490	290026	8	A	1.0	03:46	106	The first thing you added, the universal characterization of neural networks. What is the universal characterization of neural networks? Why is it being pursued in this area of research? So, as a narrow sense, my main aim of this paper is that so people use active inference formularization to characterize brain activity, behavior, so on and so on, but which would be different from a conventional neural network. So there is a crossover program which is associated with conventional neural network and it is not very clear whether all characterization of computational neural network can be explained by active infrastructure and as a principle or not.
290128	342410	9	B	0.99563	04:50	72	So here universal characterization means that parameterisation of every aspect of conventional neural network which is a kind of dynamical system derived as association between biological phenomena and simple mathematical formula, typically using differential equations as the broad sense. I think universal characterization means that well, it is a characterization of brain intelligence, but it's a big picture and what the paper particular address is only one aspect of the full picture.
346290	371560	10	A	0.96033	05:46	53	All right, so it'll be great to pull back to really understand what synthesis is happening. So I'm going to ask what makes a neural network model a neural network model and what makes an active inference model an active inference model? Is this synthesis and connection you've made true because of what?
374330	422360	11	B	0.74604	06:14	75	Because basically what we showed is the mathematical equivalence between the correlation of canonical neural networks and the correlation active inference lab in the sense that we show that a stress of neural network can be characterized by a minimization. Of some biological plausible cost function. And we show that that cost function can be lead as variation of Bayesian coherence and particular cross of generative model in terms of well known partially observable process.
426080	447190	12	A	0.99866	07:06	46	All right, shall we perhaps walk through some of the action of the paper? It would be awesome. Just for each of these sections, maybe the numbered and the lettered sections, what does the section aim to show and why was it there in the paper?
460820	521770	13	B	0.49068	07:40	81	It's and overview. Right, first we introduce so the main issue, main program, our interest, which is a relationship, which is that we try to make a formal ring between neural network and active infrastructure. That's the main problem background. And then we first formulate the equivalent mathematical equivalence in a very broad manner. So in the least action in result, we formulate the relationship using concrete cross theorem, which is a well known statistical theorem proposed very long time ago.
522380	589260	14	B	0.68	08:42	92	And using that, we link a general form of neural network with a general form of variational data coherence. But a problem is that this characterization does not address a specific generative model which is crucial to characterize a specific model, specific neural network dynamics. So in the following sections, we characterize the problem using Pomodb or partially observer Marco digital process and link that model with a particular cross of canonical neural network. And then we simulated we used the simulation to corroborate that property in terms of some maze task.
595150	625106	15	A	0.99837	09:55	60	All right, thank you for this. Could we talk about the complete class theorem? So what is the scope of the complete class theorem and why was it the relevant set of the neural networks to pursue or the right way to frame it? Thank you for asking that. So I like the slide you showed the last week's video.
625288	707962	16	B	0.86	10:25	116	The computer basically indicates the relationship between some crossover decision rule and Beijing inference. Here a crucial keyword is admissibility or admissible decision rule, which is rule which is the same as good as other decision rules or at least at one point better than other decision rules. So simply speaking, administrative indicate in some sense it is the best rule for some aspect. And usually we characterize such a goodness using cost function loss function or risk function. And here what we did is establish some association with this type of loss function or risk function with function of canonical neural network which is we call cost function or biological cost function for neural network.
708106	768450	17	B	0.99784	11:48	99	So our assumptions is that neural network minimize cost function. So if it achieved the minimization and it is validly achieved some sort of optimality so we can say it is admissible with respect to that cost function. So the beauty of complete cross serum is that if we find some admissible decision then automatically we can say that it is based on coherence in terms of some Bayesian cost function with generative model or prior beliefs. So this complexity theorem is crucial as abstract characterization of the relationship between conventional neural network architectures, dynamics and variational. Beijing inference.
771830	808190	18	A	0.87425	12:51	51	Right, thank you. What does it mean when you said it was biologically plausible of a loss function? The term is a little bit arbitrary because in this paper we Dean by prosperity in the sense that this neural network model can be derived from heuristic neural model through some approximation.
810850	836390	19	B	0.61536	13:30	39	Here, biological probability suggests or means probability as a neural model or synaptic prostitution model. And if this cost function loss function can derive such a plausible algorithm, then we can say that this cost function is vertically plausible.
839630	884406	20	A	0.90448	13:59	69	So what is the distinction between those neural and synaptic components in the loss function or what equation to look at? You mean distinction between dynamics and synaptic? Yeah. What is the distinctions between them and how is it represented in the equations? Okay, basically neuroptivity equation means differential equation about variable that represent firing intensity or some sort of variables associated with the neural firing on the other.
884428	959790	21	B	0.64	14:44	104	And synaptic plastic creation means an update rule about the synaptic weight or synaptic strengths which is a connection between two neurons. And beauty of this formulation in this paper is that we characterize both heuristic equation and synaptic process in terms of gradient descent on a same cost function, common Costa function. So we can say that if we consider the partial derivative of some cost function with respect to neural activity, then it derives gradient descent rule about activity neuroptivity. While if we consider partial generative of cost function L with respect to synaptic weight, then we derive a synaptic prosthesis rule.
970340	978420	22	A	0.99984	16:10	18	Are those the only two aspects of a neural network or why are those the two key aspects?
984040	1060480	23	B	0.99	16:24	134	I think it's a main body of the neural activity. If we consider some inference running our action exhibit by neural network in the sense that neural activity correspond to fast dynamics, fast gradient dynamics mix and while synaptic prostitution indicates a slow dynamics that minimize risk function cost function. But in general we can consider and aspect any variables associated with Urinator. For example ant least what we show in the paper is any free parameter which may be associated with firing threshold or although we don't discuss in this paper it would be possible to add other variables related to neural network. For example, here we ignored contribution of griar factor but it would be possible to add the grille factor in this correlation or any other aspect of virus Carnap network.
1064740	1107340	24	A	0.99976	17:44	82	That's very interesting and it speaks also to a general separation of timescales, for example in different multi scale systems or in the renormalization group where it's describing some minimal multi times scale system where the faster time scale can be seen as perception like and the slower timescale can be seen as more learning like. And then in some hierarchical model what's learning of one time scale can be perceptual for a slower time scale? So it's a very nice generalization.
1112500	1141480	25	A	0.99477	18:32	59	Are there any examples of decision rules that will help us think about the action components of what the neural network is doing? Because it may be more familiar to think about digit characterization and image classification, some kind of classical tasks for neural networks. But how does the decision rule play out in the context of neural networks?
1144300	1167520	26	B	0.94122	19:04	33	Okay, so in this paper we basically assume a close group comprising a neural network part and environmental part. So Neuron receives sensor input from environment and provides some feedback to the environment.
1171860	1224020	27	B	0.72225	19:31	80	Even with the example of digit classification we can say that output correspond to classifier classification output which is kind of decision rule. More relevant example would be for example controller agent like a robot control or any kind of controlling or decision making tasks. For example, when we encounter some choice task we need to advertise, for example left or right or something, any kind of Dutch a decision can be associated with the adommissibility or atomic decision rule.
1227170	1238270	28	A	0.98591	20:27	17	So what would and example of an inadmissible or admissible strategy be in the decision making task?
1240930	1270650	29	B	0.48686	20:40	31	Admissibility usually characterized by loss function or risk function here in adommissibility indicate that there is another decision rule which is at least one point better than the forecast decision rule.
1272670	1311110	30	B	0.62559	21:12	75	Simply speaking in Adobe Civility indicate that decision rule is not better, not good negatively. Let's just say our decision rule is we always turn right. Is that an example of a decision rule? Because there might be settings where that is strictly effective and the simplest rule whereas there's other settings where that's going to be tragic. So what does it mean to be admissible for an agent in light of different environmental contexts?
1312350	1355750	31	B	0.76939	21:52	56	That's an interesting point. So even with such a too much simplified rule it can be admissible under some particular situation, particular loss function. For example, the ruler that always turns right, maybe the best under some situation right. So the relationship of admissibility or in admissibility depends on both agent characteristic and the environmental characteristic.
1359450	1362410	32	A	0.99278	22:39	5	What aspects of the environment?
1366510	1389410	33	B	0.99716	22:46	29	For example, if that decision rule matches the structure architecture of environment then maybe that decision always turn right, achieves the shortest past right under some situation some environment.
1391830	1408630	34	A	0.99845	23:11	36	How does this admissibility help us think about, like, overfitting? And how does it help us think about the way that different practices are used for neural networks to prevent them from being overfit in practice?
1410890	1489922	35	B	0.82516	23:30	66	Well, strictly, adomissibility is characterized with the patient risk. So we cannot observe a hidden states of the environment, only we can observe Hae Park of the entire universe. So the question is, an important question is what is the best choice under such a limited information? Limited information. So this basically complexity tell us that only the well known Beijing framework achieved the admissible decision.
1489986	1527550	36	B	0.99998	24:49	51	Which means that in this aspect, beijing optimization give us a best choice strategy. Otherwise we all buffet or find the suboptima evolution. So it's a nice association, nice linkage between the decision what is a good decision about the decision, and the more established statistical coherence Beijing and influence framework.
1531290	1605898	37	A	0.99996	25:31	118	Thank you, that's very helpful. So we're reducing our uncertainty and risk about hidden states in the environment. So in the special case where the entire environment is observable without error, like a chess game, then there's an equivalence between calculation of risk or loss on observables or on hidden states. But they're not really hidden, but they are environmental states. Whereas any amount of uncertainty in the mapping between observations and hidden states, which is usually shown as a in the partially observable Markov decision process, any amount of uncertainty about unobserved or partially observed environmental states enables you to fit your uncertainty optimally about that hidden states and fit that uncertainty simply with a gradient descent.
1606074	1636440	38	A	0.73	26:46	53	And by doing so, you don't overfit a model of observables, which might be the fallacy or the issue with simply doing descriptive statistics, you might get an infinitely small variance with a frequentist estimate because you have 100,000 data points. So the variance from a descriptive statistics perspective might be very small.
1641150	1671620	39	A	1.0	27:21	55	I think it speaks very much to why neural networks are useful in practice from training with limited data sets, because that's an empirical conversation that they don't entirely overfit. But also, I'm sure there's ways to construct them that are overfit. Yeah, overfit would occur if we select some optimal prior beliefs. For example.
1673830	1730360	40	B	0.98472	27:53	95	Well, I'm not sure if it is overfit in the sense that you mentioned, because if we select some prior base, then the Beijing function itself changes and the neural network that try to fit to that cost function. So cost function minimization will be achieved such a situation, but that evolution is not good for our original purpose. That's a tricky part. Yeah. That is reminiscent of some discussions we've had discussing, like driving off a cliff or blowing up is also reducing free energy, like dropping off a building reduces your potential energy.
1730730	1777080	41	A	1.0	28:50	96	And so there are potentially decision making or strategic trajectories that do for some time horizon minimize free energy, perhaps even or maybe even guaranteed better than some longer time horizon. Because if the short term strategies were somehow better than the long term horizon, it would be difficult to imagine because the long term horizon would be at least as good as a short term strategy. So that speaks to the challenges of planning in action. So how is planning addressed in Modern neural networks and how does this work help us think about that?
1780010	1783350	42	B	0.92308	29:40	5	That's another very important aspect.
1785770	1849290	43	B	1.0	29:45	82	I have to say that this framework address planning aspects, but that planning is not necessarily the optimal optimal solution in the sense that what we interested in is optimization or planning under limited structure. The structure is characterized by here birdscape prospero to a neural network. So yes, planning occurred by an association between risk in the future and our decision in the past. Here we model that aspects using delayed moderation of symptomatic activity mediated by some neuromodurator or neurotransmitters.
1853470	1876930	44	B	0.54415	30:53	21	This is model as this is model as product of the risk factor and the behavior product on the neural network.
1882090	1906670	45	A	0.96698	31:22	60	All right, I'm going to ask a great question from the chat and then we'll look at the figures a little closer. So ML Don wrote a question stuck in my mind for a long time. Could you please put it to rest? Do we need to have knowledge about all states possible actions and sensory inputs for active inference?
1910920	1964980	46	B	0.96703	31:50	70	Well, you mean if you seek the exact solution, optimized solution, then maybe more information would help you to find that. But under some model, under some idea assumption, then the variables is not necessary to achieve the optimal evolution. I'm not sure if I correctly answer your point. So just to restate it. Of course, knowing all the states possible actions and sensory inputs, it's not a bad thing.
1965130	2012310	47	A	0.97014	32:45	81	Worst case, there's some computational complexity, trade offs, but the problem becomes fully stateable. But I think Mldon is asking about cases where you don't know all of the state spaces or potentially even the dimensionality or the semantics of hidden states, active states, sensory inputs, and why not even and cognitive states. So in not just partially observed but partially known state spaces, how are these addressed in neural networks and how does active inference help us think about it.
2017900	2032960	48	B	0.95755	33:37	18	Okay, I think the function is about how can we separate those states like least active coherence external.
2037180	2060210	49	A	0.71248	33:57	55	How can we separate, not just in principle have these states be separated, but deal with the fact that some of these states we might have good knowledge on and some states like the hidden states we might not even know. We don't know the dimension of the cause vector in the world. I see.
2062660	2137050	50	B	0.99733	34:22	99	In terms of dimensionality, there is a statistical technique to estimate the dimensionality. For example, various information criteria, information criteria based information criteria. All of them try to inform or estimate plausible dimensionality about the environmental hidden states. There is an analogy with those information criteria and variation free energy minimization with virtual free energy inclination we can identify the plausible model structure which in principle involved the dimension aspect. But in terms of neural network in this paper we don't carefully consider about the dimension optimization because we first define the NABO neuron and don't change during training.
2137660	2166240	51	B	0.99792	35:37	38	But in principle we can consider the change in the number of neuron which is associated with the, for example, neurogenesis adult neurogenesis or development during the development stage. That would be an important extension of this direction.
2173640	2225460	52	A	0.95041	36:13	91	That's very interesting. Here's a remark. Well, one note is equation one summarizes a lot of what you've been describing. There's a parallelism or a concordance being drawn between the loss function of neural networks and the variational free energy of the parameterized model there. So to come back to these processes that influence learning which we could think of as the neural network becoming more fit from a loss function perspective or the variational Bayesian partially observable Markov decision process entity generative model becoming better at doing what it does.
2225610	2303900	53	A	0.99931	37:05	130	So there's the firing rate on the neural network side the synaptic plasticity at a slower time scale which we discussed a little earlier and then now there's a third time scale with the birth and death of new cells and maybe even new layers. And that kind of multi scale temporal structuring is not intrinsic to the Bayes graph to represent multiple nested timescales in a Bayesian graph. In the active inference literature it's more common to make a hierarchically nested model and just say that the time handling on one level is happening more rapidly with respect to clock time than deeper nested, slower models. Whereas the neural formulation allows us to deal with multiple ongoing timescales without appealing to hierarchical nesting which is a very important feature.
2311600	2382950	54	B	0.7874	38:31	94	Well, both direction will be possible. So without hierarchical model motoring or with hierarchical model. So even with hierarchical modeling the optimization of dimensionality should be possible, would be possible but in other direction. So we can consider that a population of neural models so one has a single layer, another has two layers, three layers, four layers and consider the probability or plausibility of network architecture associated with the performance or cost function minimization under a particular environment which is in principle have the same computational architectures with the hierarchical page and model.
2386810	2440950	55	A	0.6663	39:46	79	Very interesting. Yes, perhaps I over generalized or speculated because I thought about how one could have a 100 time step POMDP that also performs multiscale behavior potentially extremely wastefully but at least it could in principle. And similarly, within a neuron there could be another neural network or some other structure approximated by that. So they almost both enable hierarchical and non hierarchical model as you described but in very different ways that lead to very different implementations.
2444170	2508490	56	A	0.60381	40:44	87	Yeah, I think this brings us to the topic of forward and reverse engineering. So you talked a lot about reverse engineering. What is reverse engineering and what is forward engineering and what has been done in these areas of engineering. Okay, I'm not an expert of divas engineering in the process, but I believe that levers here means a characterization of the blueprint of some device or machine from data observable information like activity or action behavior of some agent. So, goal is identification of blueprint.
2509230	2595350	57	B	1.0	41:49	115	And the crucial here blueprint correspond to generative model. Because once we define generative models, we can derive various energy algorithms running influence algorithm under any behavior of agent. So, here, reverse means that we first observe some activity of agent and its mechanism is still unknown for us. But we can estimate its mechanism using activity by identifying the most plausible gear T model which can minimize some post function or risk function when we feed the data to the model the model. So, on the other hand, for engineering would be more mainstream way fast define model blueprint gently model then Deneve everything including Bayesian parametric functional running Paris algorithms, behavior action algorithm.
2600030	2628290	58	A	0.90042	43:20	40	So, by reverse engineering neural networks, we're observing some already parameterized neural network and then fitting a POMDP to it. To what extent is it possible to take a given POMDP and create a neural network that errors that inference?
2632970	2736530	59	B	0.86531	43:52	143	Okay, in this paper or in the following paper what we consider is strategy that we first fit empirical data whether for neural response data to bioscape plaudible canonical neural network model which is similar to a computational model fitting approach where we have differential equation and data and data to the differential equation to explain the behavior with the minimum prediction. So, now, a virtue of this framework we establish is that we can naturally transform such a neural network architecture with the very no partially observable Markov process architecture. Because for any kind of canonical neural network, there is a cost function. So, we derive cost function for neurotivity question which is opposite with the computational way. We first define cost function derived algorithm and then we use the force the formal equivalents between neural network cost function and Virginia query.
2737690	2762010	60	B	0.92899	45:37	31	So, now transform the neural network architecture to Beijing model architectures. And once we characterize Virginia free energy, there should be some generative model that define that Virginia free energy function.
2765330	2800140	61	B	0.99957	46:05	36	In particular, in this example, canonical neural network necessary correspond to well known across well known Attial edition process. So, by using this procedure, we identify a plausible homedp architecture which is correspond to obsolete data.
2809500	2855960	62	A	0.96487	46:49	82	Well, let's stay on this last point. So, after all those transformations, first the measurements of neurons using that data to fit the neural network and then by virtue of the relationships unpacked in the paper, transforming the neural network in the left side of figure one into a particular form of the POMDP. So first, what are the constraints on that form of the POMDP? Is this a little corner of model space or what are the space of acceptable POMDPs?
2858220	2943910	63	B	0.96717	47:38	126	That totally depends on what kind of neural network model you are considering. So for example in this paper we discuss about a particular cross of Coda that in which each state takes either zero or one. So it's very restricted compared to the general form of OMDP but we consider a factorization. So in the sense that although each static has a Ronen of one but we consider a vector of conversation and vector of hidden state where each element correspond to Ronen single one, whole vector but as and entire state it can represent high dimension discrete state space. And this architectures nicely correspond to neural network architectures because usually each neuron takes either zero, one or some continuous variable between zero and one.
2944360	3036690	64	B	0.97074	49:04	104	So we use this association to characterize a particular home DP which correspond to neural networks. And this follows a particular Memphis approximation, approximation or approximation in generative model because we associate posterior belief in this particular homo DB with the neuropathy, which means that posterior of action also chaos, a factorization architectures in the sense that we don't fully consider about the second order statistics between neurobans activity and neurons activity, which is outside of this pulmorism. So each neurons activity correspond to posterior expectation about the particular elements of the state and we don't consider the joint posterial property of all state.
3040850	3063430	65	B	0.96462	50:40	31	So although this is a limitation, we see this as a Beijing imprint but otherwise for examples we can consider any recurrent network architecture which correspond to state to transition matrix.
3065870	3096900	66	B	0.98808	51:05	58	It would be possible to extend this architectures to higher card structure in the sense that it is straightforward to consider a tree structure or any kind of higher card structure by assuming that some neuron connect to other neuron but not connect to other neuron. So this is same as considering the higher card structure in general.
3103810	3168930	67	A	0.82337	51:43	132	That's very interesting. It's commonly remarked in the base graphs that they represent the connections amongst random variables and there's a relationship between their computability and their sparsity. The sparsity structure as in which variables do or do not influence each other makes the problem tractable through factorization and just kind of conceptually like if every one of 1000 variables or an unknown number of large variables if it was all by all the number of parameters to fit on that connectivity matrix would be very high. So statistical power would be very low for any given edge. Whereas the more and more constrained you make the connectivity of the variables, the more statistical power you have to resolve or kind of spend on fitting those edges, like in a structural equation.
3169430	3265680	68	A	0.9986	52:49	153	But you might be losing sight of the unknown unknowns by constraining yourself to a very limited or fallacious biology of the variables. So there's this kind of structure learning statistical inference question in the Bayes graphs then on the neural side from the biological much of neuroscience is about understanding how the firing rate, connectivity patterns and other factors, how the structure of those neural systems and their function like form and function enable adequate coherence and coherence on action. So it's like in both of those areas or really like in neural network, artificial and neural networks and in variational bays. The discussion is about how the structure and the finetuning work together to generate function and about some of the statistical or biological challenges of balancing different needs while also constraining the cost in terms of materials and biometabolism. So it's a very rich intersection that is being explored here.
3269620	3272880	69	A	0.98402	54:29	10	If these models can really be moving back and forth.
3278290	3282750	70	B	0.88376	54:38	7	In the sense that back and forth.
3285570	3319610	71	A	0.99985	54:45	69	Moving back and forth, like there's imprints of the model that is implementation independent or like some interlingual or some semantics or compatibility, I don't really know. I mean, that's something we can explore is like what is it that is such that one could forward engineer and then reverse engineer and have kind of an expectation maximization between these two areas. So, what is it that's being sought?
3325230	3357690	72	B	0.79751	55:25	36	Yes, important point. So, for example, a virtue of this relationship is that we can use the knowledge of to explain neuropty neurodynamics, which is crucial because people often say that capitalizing dynamics is not straightforward.
3360270	3441090	73	B	0.99602	56:00	135	We may obtain some solution on neural net dynamics, but the meaning of that dynamics in terms of the functional aspects is very unclear. We don't know the meaning of connectivity strengths, matrices and what is the meaning of the threshold factor, so on and so on. Those are derived from the moderate biological phenomena, but it is not necessary to have clear linkage to function explanation. So, exploration of function of the brain, but once we translate these dynamics into Bayesian infrastructure, then we can explain every functional aspect of the neural net dynamics architectures in terms of well established Bayesian inference under a particular crossover Beijing model, in this case palm DB model. So now it turns out that synaptic strengths correspond to a matrix b matrix, which are very established culture meaning.
3441990	3458010	74	B	0.7325	57:21	17	So yeah, this is useful to explain neuro and synaptic property in terms of well established statistics.
3464400	3546630	75	B	0.99994	57:44	100	Also, for the people in active inference lab site, it would be helpful to understand the neuronounce rate about particular active coherence modeling model. So I think it related to forward modeling, but finally to discuss with discuss about the biotcar substrate of that forward model, we need to address the neural network architectures substrate property. So, in that case, we can transform a particular pond Beijing modeling to a neural network architectures using this relationship and then get prediction about the substrate. So, if we have ant least Beijing model, this particular quantity in this model should be possible.
3555000	3588960	76	A	0.99316	59:15	53	It's all good. Can you just repeat the last like 20 seconds? Yes. So in the last part I mentioned about first we define the Beijing model and then can predict what is the neuronal substrate that correspond to that particular Beijing model. So this will be useful to identify the biological quantities.
3590340	3593840	77	B	0.98772	59:50	7	That correspond to a quantity in Beijing.
3598120	3662360	78	A	0.74357	59:58	87	Wow. Well, there's a lot there. It makes me think about the differences of implementation and heuristics in the computational setting, which is often in the extreme disembodied, and the biological setting, which is in the extreme, entirely embodied. And for a given generative model, the kinds of computational heuristics that can be applied include a whole host of different strategies, ranging from sampling to tree exploration and branching to paralyzing the data architecture and all these other kinds of disparate strategies and software packages and implementations.
3664540	3686480	79	A	0.99996	1:01:04	28	But on the biological side, what is needed is something that's very simple but also very inscrutable, which is a given pattern of interactions must embody that correlation.
3688500	3736590	80	A	0.96909	1:01:28	78	So that might mean that it can add three digit numbers, but it can't add two digit numbers under some constraints. But what isn't accessible to that kind of morphological, biological, or like form and functional computing? What's not accessible are the tree branching, the database decentralization, like they're a different set of heuristics, but they're both very useful when we're thinking about making sentience artifacts or benefiting simply from the explainability across both sides of this figure.
3738720	3775576	81	B	0.80937	1:02:18	59	Yeah. So now there is an important point. So, Hornetry, it is very known to bear whether there is a corresponding vertical architecture for any given Bayesian architecture. I believe it is impossible to design biascar architectures to correspond to arbitrary Bayesian architectures. So only a limited aspect of Bijan model can be implemented in a vertical, plausible manner.
3775688	3785340	82	B	1.0	1:02:55	11	And that point is crucial as a characterization of biological brain.
3789520	3796240	83	B	0.91035	1:03:09	15	Yeah. Wow. Well, just to kind of touch again on this forward in reverse engineering.
3798440	3848150	84	B	0.9907	1:03:18	87	For. A given POMDP, if we're willing to compose it within a certain class, which might be quite general still, but some class of POMDP as written. On the paper. We may be able to have a neural network architectures that would be very amenable to deep learning, low energy computing, pretraining various features. And then on the other side, for a given artificial neural network that we come across in the wild, or a model of neural dynamics that we fit using a neural network model.
3848840	3914216	85	A	0.99631	1:04:08	130	So something in a neuroscience laboratory that model can have interpretability corresponding to the variables of a given POMDP. And just to kind of give one more point on how that's going deeper than, for example, statistical parametric mapping SPM. So let's just assume that the neural network we're dealing with is fit from brain data from some lucky ant right? Now, what would be possible or prior to this line of work or without this line of work, one could fit a neural dynamics model and then do all kinds of analyses, like power analyses on the different frequency spectra and say, look at the average firing rate or the correlation coefficients of firing rate. So fit the firing rates and the synaptic Plasticities and store all that data.
3914398	3974780	86	A	0.99	1:05:14	117	And then we could just pick a POMDP that we've seen in the literature without any reference to the neural network and optimize the POMDP. And then we could say well, it turns out that when the Pomdpo is high there's increased theta power in this firing pattern. So it's like comparing the descriptive statistics from the neural model to the descriptive summary statistics of the POMDP decision making model. However, with this formal connection there is actually an interpretability to the unobserved neural states which are what are being inferred from the fMRI measurement, from the EEG measurements and so on. Those underlying variables have a specific interpretability in relationship to the structure of the POMDP.
3981440	4060150	87	B	0.53588	1:06:21	108	Right, that's also very interesting, important aspect what you said is I think more conventional strategy and it is also commonly related to model comparison aspect. So we usually think bias Bayesian modeling and identify or select what is the best model to explain a given data. And this robust engineering idea involves such a model comparison aspect in the sense that we try to find the model with the best experiment ambiguity which should be have the identical function right directory addresses the exact same Costa function architectures using the transformation natural transformation. So it should be up to explain the neural data in the Bayesian sense.
4062540	4125500	88	A	0.83159	1:07:42	88	Yeah, one can imagine how that would transform the way that current neuroimaging studies and technologies describe what it is about the measurement that provides information about the cognitive model. So to give another related example, let's just say a person was wearing an EEG headset and a previous study had shown that increased alphaband activity was associated with this behavior. That's comparing a descriptive statistic of the observations of the sensor and correlating the summarized observable to some other variable like anxiety or performance on a behavior.
4127680	4208740	89	A	0.99999	1:08:47	98	In contrast, an unobserved variable in this setting the actual underlying neural state is being correlated to some semantic generative model component. So it's no longer necessarily that any single frequency band would be associated more or less with a given outcome but it's actually some hidden states variability which gains the interpretability across this transformation. Which is a subtle point but it speaks to how broadly the equivalence would reinterpret empirical neuroimaging results as well as a variety of artificial neural network experiments and diagnostics where people do lesion studies and double knockouts on artificial neural networks.
4211100	4287680	90	A	0.99319	1:10:11	107	So anywhere where somebody with awareness sees that a neural network, artificial or biological is having summary features described and correlation to something that's more semantic in a quest for meaning may now have a different approach that involves foraging. The model explicitly in terms of unobserved hidden states with a cost function akin to a variational free energy, minimizing risk or bounding surprise on the unobservables. So even though the unobservables were modeled in a sense in the other conventional strategy like neural activity is a variable in fMRI experiments, it's underlying the bold signal. Yet this formalism concordance is a more coherent and powerful connection.
4294660	4296450	91	B	0.97	1:11:34	3	I believe so.
4300420	4343132	92	B	0.9583	1:11:40	60	Very important point to address that. So we need to clarify about what is a program. Consider here. So this is a program so called metabasian problem in the sense that researchers try to infer or estimate neuro activity or brain activity which infer the external world dynamics, right. So neuron brain info environment and the researcher info brain activity.
4343276	4414356	93	B	0.97635	1:12:23	95	So there is a two step coherence processes. So this sort of metabasion program is quite tricky intractable because sometimes probability, sometimes random variable becomes posterior about other aspect. So I think there is some established approach about metabasium. But this paper provides some alternative in the sense that we separate two program by saying that here what we infer is simply neural network model or neural network dynamics which is shown in the left hand side of this figure. So we feed data to conventional neural network model which is a simple differential equation.
4414548	4438640	94	B	0.91868	1:13:34	33	But thanks to this formal equivalence between neural network dynamics and behavior, we can transform the resulting neural network architecture or dynamics into the page and infrastina in some sense post hook manner.
4440660	4477370	95	B	0.99842	1:14:00	57	So we nicely avoid the directory addressing the metabasium problem but obtain the same kind of solution in that sense. Yes, with combining with brain activity recording like IEG or imaging. Yeah, we can estimate a plausible neural network model in the left hand side and we can transform that to OMDP in the right hand side.
4480140	4508288	96	B	0.55353	1:14:40	56	Great. Awesome. I'm going to show an image and ask a question from Dave in the chat. So Dave made this image, it's the right side of figure one that we've just been looking at with the variational Bayesian correlation and he wrote the arc shown as impinging on the S self arc. Is this intentional?
4508384	4514250	97	A	0.99995	1:15:08	15	If so, it could represent tuning or modulation of the feedback of S into itself.
4517740	4582296	98	A	0.80129	1:15:17	83	Do you have a thought on this? It's attention? Yes, I think it's related to the usual formulation of Pom DB architecture and active coherence context in the sense that our decision or policy in the usual setting modify active states transition matrix b matrix here delta is alternative of policy of agent. So basically the director indicates stated transition matrix under a particular decision which agent made. In that sense what the agent changes is state transition matrix not state itself directory.
4582488	4587340	99	B	0.76463	1:16:22	6	That's why we use this exploration.
4589460	4606710	100	A	0.97874	1:16:29	34	Awesome. Very subtle but important point which is when we look at the classical POMDP formulation. So here we'll look at a version shown in figure two. I'll just bring just figure two in.
4609480	4629550	101	A	0.99981	1:16:49	43	Could you describe what you just did about the role of the B matrix in influencing how hidden states change and how that is where our policies have impact? And also please, how do the top and the bottom of figure two differ?
4633200	4712200	102	B	0.98486	1:17:13	103	Okay, so in the usual formulation under active infrastructure with a palm DP structure. So for us to consider the prior free for us and depending on the prior free for us, we compute the expected free energy and its minimization provides the policy and the policy modulate active states transition. So now in the upper array we instead use the Pirator which is the option of the agent. So here computational decision was made for each time step. So that unlike the computational formulation, we have a sequence of generative and for each time step derita moderate active states transition matrix B.
4712350	4844240	103	B	0.83455	1:18:32	166	So B is a matrix that transform hidden state in the previous step to the S in the current time step. And it's moderation indicate that under a specific decision rule, for example, if this indicates our position in the battery environment with the goal decision our position moved forward, or if we choose no go decision, then it's unchanged. So such a conversation of state transition was made by choosing EBITDA and the lower part correspond to Beijing influence made by Beijing agent. So basically there is a symmetry between apart part and lower part because we assume that this Beijing agent has a plausible gentle model which nicely correspond to a given environment defined in the above in this figure. But one interesting thing so asymmetry is that to model this particular canonical neural network, we don't consider an arrow or link from Derek posterior to the posterior which is in the environment data moderate S in the next step through B matrix correlation.
4845300	4873160	104	B	0.65349	1:20:45	32	In this particular Beijing engine which formally correspond to canonical neural network, we don't consider that it is correspond to and absence of the projection from output layer to the middle layer.
4879180	4879930	105	B	0.78797	1:21:19	1	Okay.
4886000	4934540	106	A	0.98008	1:21:26	75	This is from the 2020 paper, but it shows the neural network architecture, the two layer architectures. So could you restate the top and the bottom of figure two in the 22 paper and connect it to why it's important that you're studying two layer neural network models? I miss you. Oh yeah. Can you just connect the asymmetry between the top and the bottom on figure two with the two layer neural network architecture?
4935520	4940430	107	A	0.9998	1:22:15	10	You said that the asymmetry there's no direct link between.
4945320	5017760	108	B	0.44487	1:22:25	86	Yes, this is another story. So in the previous paper, in the previous paper there is only output rate perceptual layer because we basically consider a single layer free toward network. So my apologies for some confusion about the network architecture in the 2020 paper. So now upper part of this network architectures correspond to environmental generative process and only a lower part correspond to single feed forward neural network architecture. So now this part is identical to a map from Syria in the 2022 papers.
5023300	5057260	109	A	0.5097	1:23:43	52	Okay? So on the top of figure two is the actual generative process. It's the true structure of causation in the environment, which is to say that actions delta active coherence how states change through time via b delta. Right. The generative process through the A matrix emits observations, sequences of observations.
5058240	5088340	110	A	1.0	1:24:18	38	And here on the bottom with a mirrored structure is the generative model of the entity. So what's the relevance of the arrows and the more force factor graph structure on the bottom? The arrow indicates active inference.
5091580	5151616	111	B	0.84673	1:24:51	83	It's a flow of the information in the sense that to calculate in the step two, we use the information of step two's observation and step one's posterior expectation of our hidden states. So those two determine the s two's expectation. Usually in the phony graph we consider retrospective arrow. So in the sense that s three also affect the s two influence. But this correspond to a Beijing smooth in the sense that we update every time step simultaneously to better inference.
5151748	5178790	112	B	0.9915	1:25:51	47	However, what we consider here is a more filtering approach in the sense that for each step we compute the latest hidden states and then we don't change any other states in the past. So that's why we don't consider the arrow from future to the past.
5182440	5261550	113	A	0.98375	1:26:22	143	Awesome. Yeah, just to highlight that in the Bayesian smoothing approach, it's kind of like fitting a spline because it takes the whole time series and it fits the smoothest possible line, or the line whose smoothness is on the AIC BIC frontier. But here on the bottom with the almost pseudo code implementation provided by the 40 factor graph, which was demonstrated to be equivalent with the Bayesian graph in the 2017 work with Friston, Par and DeVries. This architecture is reflecting a filtering scheme like a Coleman filter or just generalized Bayesian filtering through time, where estimates are being carried forward and changed time point to time point, such that the decision rules, or the updates perhaps more accurately, are defined between time points. And the total time series does not have to be loaded into memory or remembered at once.
5261920	5287910	114	A	1.0	1:27:41	46	And then the Bayesian filtering approach has the asymmetry with a different consideration of action. So why again is it that action is considered differentiate in the Bayesian filtering approach on the bottom of the generative models than the consideration of action in the generative process?
5290040	5312270	115	B	0.81552	1:28:10	25	This that corresponds to lack of connection from Y to X in the figure one, or probably a figure four is helpful to that relationship.
5319540	5365500	116	B	0.99588	1:28:39	74	This is an example network architectures comprising input Dayan, middle Brea and output Dayan. What we consider is information flow from sensory to middle Dayan and middle area have self connection, recurrent connection and middle area project to output tray. So there is no connection from old output Dayan to middle Dayan. Right. So that's why we don't consider the link from derita in the bottom layer of the figure to two s posterior.
5367200	5374800	117	B	0.99598	1:29:27	11	So this is different from true generative process in the environment.
5378170	5393450	118	B	0.99966	1:29:38	24	This is a kind of simplification because our purpose is identifying the plausible Bayesian model which correspond to this typo to a neural network.
5396350	5417330	119	B	0.85265	1:29:56	21	So in other words, this neural network is and approximation about that point or use limited form of palm DP scheme.
5423810	5534370	120	A	0.99767	1:30:23	127	Thanks. So could you describe W VK and comma just what is the biological or functional interpretation of those variables and what brain regions or what processes or pathologies do they map to? Okay, so basically WVK synaptic strengths in the form of Atreides and they represent synaptic connection in a different layer or different architecture in the sense that W means forward connectivity from sensory layer to metal area, k correspond to recurrent network recurrent connectivity and V correspond to projection from metal Brea to output Brea. So in this paper, we don't discuss the correlation to brain anatomy in detail, but one can consider analogy. For example, say x correspond to cerebral cortex activity and yellow brain in the sense that it determined the action.
5534710	5549430	121	B	0.55628	1:32:14	30	So it is considered that in the cerebral there is signal that represent choice. This is Journey, for example gold, this is Journal or no Gold discogn made in Serbia.
5551710	5627950	122	B	0.82337	1:32:31	88	It's analogous to this particular architectures. On the other hand, in the several cortex we compute the accessory information to generate some inference, prediction and planning so on, which is computed by this recurrent network. In this particular modeling, although we don't separate brain rhythm in detail, but this recurrent network is sufficient this graph of recurrent network is sufficient to characterize any type brain architectures in the sense that we can design and higher car or mutually connected architectures using generic crossover recurrent network by weight Attial.
5635710	5716550	123	A	0.99663	1:33:55	135	So the middle layer we can think of as like the cognitive stuff, it's the internal states when we talk about perception, cognition, action in the active scheme or even in the sandwich model of cognition, perception, cognition action. So W is describing how those sensory inputs either in one step or composably in multiple steps become processed to these x representations of hidden external causes inferred external states. And so these are the states that have that sigma relationship and a generalized synchrony with external states. The sigma and the generalized synchrony are not discussed in your paper, but it connects to other work and the recurrent connections are facilitating attention or weighting of the stimuli. This is the recurrent learning loop and the relationship of the A between observations and hidden state estimates.
5718330	5765000	124	A	1.0	1:35:18	74	And then a different kind of modulation comes into play between the hidden state estimate of the external states and the action selection. So what is gamma corresponding to? And why is the gamma modulation between layers two and three differing functionally from the k synaptic modulation of one and two? Yeah, so K matrix basically formally correspond to B matrix in the Bayesian progression. So which locate the information about the prediction, right?
5765770	5841666	125	B	0.57887	1:36:05	104	Our generative, our expectation about the next state based on the previous state. On the other hand, Laura gamma is quite different from such a competition. Gamma basically means risk factor risk function, which is in principle we can, we can use arbitrary risk function. This is a part of generative model we designed and the rule of risk function in generative model formulation is alternation form of generative models depending on that value of gamma which examples postdictive or retrospective modulation of and Markov decision given an outcome in the future. In terms of neural network, of course it corresponds to some neuromodulation.
5841798	5902990	126	B	0.99662	1:37:21	69	For example, Dopaminergic moderation is famous in the literature which modulates the activity and activity of various brain reason. But we particularly focus on Dopaminergic or any kind of neuromoduration of synaptic prosthesis in the output brain, which may correspond to cerebral. So you're in the cerebral neural activity or prosthesis moderated by domain input from it is used as the optimization rule, decision rule or sometimes attention Bijan.
5909360	5991068	127	A	0.96731	1:38:29	124	Awesome. Very interesting because in some previous papers and models that we've looked at, attention is dealt with as policy selection on mental states. So internal action selection, it's an action like variable describing attention and awareness and even metacognition. And so that connects the role of Dopamine in motor decisionmaking seen in many Dyskinesias, but also with the role of Dopamine in seemingly non motor based decision making like gambling or investing, where it doesn't seem to immediately translate to a given motor sequence. Yet it has analogous computational characteristics and the comorbidities and the side effects of different drugs that affect the Dopamine neurophysiology are known to have carryover in terms of the rigidity or excessivity of motor and decision making aspects.
5991104	6035990	128	A	0.99404	1:39:51	62	So it's like interesting that Dopamine has long been understood to have that parallel role in attention as cognitive action and motor action and that was established empirically through modifications of Dopamine signaling and also had been modeled analogously with computational neuroscience. And this is providing again a slightly different interpretation of that very well studied Dopaminergic modulation of attention and policy.
6041000	6053270	129	B	0.99355	1:40:41	20	Yes. And in addition to that, I believe another important aspects is the modulation of scientific ergodicity by Dopamine. Well.
6075930	6099140	130	A	0.46654	1:41:15	20	Do you want to show something? Yeah. Can you see this paper? It send you PDF. Okay, let me see.
6100390	6102500	131	A	0.72555	1:41:40	5	I'll get it up now.
6107590	6170306	132	A	0.99605	1:41:47	91	All right. The paper is a critical time window for Dopamine actions on the structural plasticity of Dendrite expines from 2014 by Yagoshita. So what is interesting about this paper. It basically explained conversation of activity by Dopamine, which is common but crucial point of this paper is that it shows that it's proved that Dopaminezic input can modulate Hebbian prostate ebin after Hebbian prosthesis is established. So this paper showed that they had open magic input, for example, two second after or several seconds after the HEPIA ergodicity is established.
6170338	6243200	133	B	0.99849	1:42:50	92	But such a post hoc moderation, post hoc introduction of Dopamine input is sufficient to change the past plasticity which may be associated with the post hoc evolution of our past decisions. So by decision making, we of course changes the weight matrix through activity. But to evaluate the goodness or badness of our decision, we need to see observe the future outcome which is propagated by, for example, Dopamine. This paper nicely show empirically that Dopamine actually can change the past evaluation even after such a psychic level, very local level.
6252290	6313000	134	A	0.91778	1:44:12	77	So there's a short term window, the critical time window that they're describing but there's some window, some window by which dopamine potentially unrelated to the initial heavy and plasticity event where secondary domain signaling or not secondary just after the initial fact potentially of a different valence or the same valence can synergize or cancel the plasticity formed in the moment. Exactly. And this is not limited to Dopamine, but other neuromoderators can also do this.
6318330	6333690	135	A	0.99786	1:45:18	31	Well, on one hand, how does this change our understanding of animal neurophysiology? And then, I guess on the other hand, how does this influence how we would design sentient artifacts.
6336910	6351220	136	B	0.52291	1:45:36	7	When for both animals and artificial agent?
6353430	6415190	137	B	0.98	1:45:53	82	One important message, I believe, is that this tells us possible simple architecture to make. Planning this is and association between past decision and future labor any risk factors which is otherwise computed by computing forward prediction by iterating some computational I believe this is a usual way to predict the future event and then select option. But using this property, biological property which is observed in Attial experiment, we can design, we can imagine other simpler architectures to make a planning.
6417370	6440750	138	B	0.96795	1:46:57	38	So for both animal and generative Beijing agent, it provides an alternative explanation about the association between our past decision and the future based on the optimization of our decision to maximize the reward or minimize the risk.
6445160	6478604	139	A	0.99977	1:47:25	82	Well, one interesting note is we spoke earlier about the difference between the Bayesian smoothing all at once approach and the Bayesian filtering step by step approach. Now, if one had infinite knowledge and computational resources, the Bayesian smoothing approach is the way to go. Like, you don't want the decision rule for investment. You want to look at the whole time series past, present and future and know the best moments to have made the trades. I mean, there's no comparison.
6478652	6508008	140	A	0.73654	1:47:58	52	You're going to do better with a Bayesian smoothing. However, it's just implausible computationally and because it requires total memory of the past and knowledge of the future. So that's what motivates the development of Bayesian filtering approaches which are tractable and calculable through time. Yet with this time delayed modulation. Part.
6508094	6563050	141	A	1.0	1:48:28	101	Of the Bayesian smoothing strength comes back into play. It doesn't enable true anticipation of future states, but that's what the expected free energy does. However, the delayed neuromodulation allows for reconsideration of a window of past states. And so in that way it corresponds to like a slightly deeper filter, not just a filter of a time step of one, but a filter of like a rolling window of five or with some decay. And you don't want that window to be too big because if the window were ten minutes, then too many contrasting stimuli would get piled together.
6563500	6622460	142	A	1.0	1:49:23	97	The Dopamine level would just converge to a meanfield average. But there's some time decay or time constant on the post hoc modulation where that neuromodulatory signal is actually a parameter of interest and that's not an infinitely long or infinitely short window, but it's some niche dependent amount of time. And that's a very interpretable and first principles interpretation of the computational role of neuromodulators in a way that is also consistent with all these other concordances we've been exploring. So it's quite an interesting connection back I guess in our final minutes of this discussion.
6627020	6653900	143	A	0.97372	1:50:27	57	What are you well, maybe go to the beginning at the and which I meant to ask earlier, but it's a good way that we can sort of close today and look forward, which is how did you come to this line of research specifically studying neural networks in this way with Karl Friston and your colleagues?
6658400	6695500	144	B	0.51561	1:50:58	36	So yes, my interest was the characterization of biological network. So my first motivation is to make biological plausible artificial intelligence, but to active that we need to know about biological brain or biological neural network.
6700820	6796990	145	B	0.87698	1:51:40	110	In these February years, I collaborated with the doctor professor Karl Friston to study about his Calgary real as a principal after doing for us and then what my question during that period, was everything about the verdict neural network or is there any other aspects that can characterize the Barriscar neural network? So it is non trivial. It was non trivial. So that's why I tried to start from characterizing the neural network first. So our strategy is not considering the way of implementing any Bayesian agreement as the brain architecture, but my interest is rather characterization of a given vertical network in terms of something, some other things.
6797520	6865744	146	B	0.99	1:53:17	82	One possible way is of course based on inference free energy coherence. So that's why I first start from characterizing bioscon network. But just defining neural network architectures is insufficient, it is not trackable, it is far beyond the computational tractability as the mathematical analysis. And we need some assumption, some trick to increase the tractability. And one day I came up with an idea that in which we considered that both neuron activity and prosthetic flow the same cost function gradient.
6865872	6921460	147	B	0.99983	1:54:25	63	This is very much analogy with physical system like Lagrangian correlation or Habilitonian formulation. So usually we consider some energy landscape and design plausible trajectory as the solution of some principle of minimum action or risk action. So we imagine that what if we apply such idea to conventional neural network or voucher neural network to characterize the dynamics in the fast principle.
6923640	7003760	148	B	0.85838	1:55:23	99	That's a fast motivation fast step to come up with this framework. And finally we noticed that it is not easy to connect the Newtonian dynamics with this type of neural activity study because neural activity are not necessary to be a second order differential equation, but rather it is first order and considering many things. Then we finally used a cost function proposed in the papers which is not necessary have a formal identity with the Socalled ravalanjian in the Newtonian physics. But it is rather plausible as the rule or underlying mechanism of such type of network.
7011950	7029040	149	A	0.99979	1:56:51	31	Awesome. Well, it has been quite an interesting one. I really appreciate everything you've shared today. Is there anything else you want to add at this point? Otherwise we'll talk again.
7033890	7044530	150	B	0.92	1:57:13	22	I already speak a Ronen, thank you. All right, talk to you later. Bye. Thank you very much for the nice discussion.
