start	end	speaker	sentiment	confidence	text
32290	35054	A	0.8654952049255371	Subscribe hello and welcome everyone.
35252	42480	A	0.9419136047363281	This is ActInf Livestream, number 51.28, November 9, 2022.
43250	45978	A	0.6894928812980652	Welcome to the active inference institute.
46154	53498	A	0.5296252369880676	We're a participatory online institute that is communicating, learning, and practicing applied active inference.
53674	60520	A	0.5080267786979675	This is a recorded and an archived live stream, so please provide us feedback so we can improve our work.
60890	67830	A	0.8318765163421631	All backgrounds and perspectives are welcome, and we'll be following video etiquette for live streams.
68970	76090	A	0.6980394124984741	Head over to activemfronts.org to learn more about participating in different institute projects.
77070	83230	A	0.7521710991859436	All right, well, we're in active states number 51.2.
83380	86558	A	0.8846859335899353	We're in our third discussion on the paper.
86644	89930	A	0.8491894006729126	Canonical neural networks perform active inference.
90010	91920	A	0.8515075445175171	From 2022.
92290	98110	A	0.880913496017456	We had a dot zero video with some background and context and overview.
98270	109634	A	0.9836516976356506	And then last week in 51.1, we had a great discussion, went over many interesting details of the paper and related topics.
109762	121820	A	0.8043875694274902	So today we're going to jump in, cover some empirical details, some implications, connect some more dots, maybe look at some code.
122590	126570	A	0.894739031791687	And thanks again to Kuya for joining these discussions.
127710	158206	A	0.834439754486084	I'm Daniel, I'm a researcher in California and thought a lot over the last week about what this kind of neural network POMDP synthesis or translation really means and just want to learn more about what fundamentals or foundational aspects of these different kinds of models enable that synthesis or translation.
158398	166790	A	0.8525769710540771	And then again what that means for areas where one or the other kind of model is already in use.
166940	181290	A	0.9030217528343201	So thanks again for joining and I'll pass it to you if you want to say hi or give any other a second introduction.
182990	188750	B	0.8202636241912842	Oh, yeah, I'm takirisomera in, lieutenant brain science institute, japan.
189330	199760	B	0.9143804907798767	So I look forward to discuss another different aspects of this work.
203350	219240	A	0.8788914084434509	Well, let's just remind ourselves of the fundamental parallel being made in the paper and then we'll get to these two questions about kind of the two directions that things can go.
220090	230614	A	0.8759685158729553	One representation is in equation one with loss function of a neural network and the free energy on a POMDP.
230742	242746	A	0.8912013173103333	And that's also seen visually in figure one, with a neural network being drawn a concordance against the variational bays of the action perception loop.
242858	246830	A	0.7809924483299255	So maybe just let's begin by restating.
247170	256980	A	0.9178688526153564	What is this parallel that is in equation one and figure one and how was it reached in this paper?
259430	298750	B	0.6461271643638611	So basically idea here is that we derived to characterize the dynamics and plasticity of canonical neural network in terms of Bayesian inference, because arbitrary dynamics of neural network is interruptible in the sense that we don't know what is the function underlying such a dynamics and what is the coherence of the self organization or prostitution.
300230	314558	B	0.8386268019676208	So once we translate that dynamics in terms of Beijing ants, we can align quantities in Beijing parents for any biological quantities.
314734	324158	B	0.7486608624458313	So which enables us to lend the experiment ambiguity to the neural network dynamics and architecture.
324354	326730	B	0.7233219742774963	So that's a basic idea.
326880	353680	B	0.8540131449699402	And what we have done in this paper is that we consider a biological plausible cost function for this particular canonical neural network and show the equivalence between that cost function and the variation free energy and the particular partially observable process model.
357990	358834	A	0.9184247851371765	Awesome.
359032	368518	A	0.8751331567764282	So let's look ant the parallel between the cost function for neural networks and the variational free energy.
368684	373218	A	0.8860763311386108	So one representation of that was in figure three.
373404	385660	A	0.8920019865036011	So maybe could you just describe what is the structure of the variational free energy expression and what is the structure of the loss function?
387090	402660	B	0.8497902750968933	Okay, so there is a clear parallel between the functional structure or those components in variation and free energy and the component in neural network cost function.
403110	420162	B	0.8866522312164307	So let's say the first time in F correspond to the correspond to the expectation about hidden state s is the hidden states posterior period.
420226	446670	B	0.9075356721878052	So that part basically indicates the free energy with respect to the hidden states and the second part correspond to the free energy about the decision posterior there indicates the posterior belief about agent decision or action.
448470	481530	B	0.9065080285072327	And now in terms of the correspondence between the free energy and neural network function here the first time in the neural network function correspond to middle rear neuroptivity which has recurrent connection and receive sensory input from sensory layer and then project the output to the output layer.
482350	494750	B	0.9168810248374939	And the second time correspond to output Dayan which receive signals from metal Dayan and send the feedback response to the environment.
505200	523460	A	0.8665491342544556	So both of these expressions have the first term being more like a cognitive perceptual sensory learning term and the second term is more like a control theory action selection.
523880	535450	A	0.6338359117507935	And how did you see this analogy or concordance because it looks like a zipper, like everything is totally lined up.
538330	549590	B	0.6392986178398132	Well, this graph itself showed a clear correspondence.
551070	563566	B	0.8896337151527405	Now we are considering a particular form of pound DP in which each element of hidden state takes either zero or one.
563748	575150	B	0.8581348657608032	But there are many states so it is expressed in the form of parameterisation.
575830	600794	B	0.8518550992012024	So now we consider that in terms of the s is posterior part of borders correspond to the expectation about each element of s taking one and the lower part of the border s correspond to the expectation about s taking zero.
600912	620160	B	0.7194297313690186	So it is Brock vector about the expectation post Brea expectation and this s nicely correspond to the block vector shown in the bottom up this figure.
621010	648810	B	0.8716124296188354	It is a vector of x and it is a vector of x and by x and here by X indicate one minus x in the element y sense which is exactly correspond to broke vector of S expectation.
650510	675874	B	0.9249725937843323	This correspondence also observed in the second term here log S correspond to log x and also log A correspond to the broke matrix of W log W.
676072	689640	B	0.8795411586761475	Here W hat indicates the sigmoidal function of W and its bar means sigmaidal function of W.
690330	705446	B	0.8985906839370728	So actually because we now consider hidden state and boundary conversation it's likelihood mapping.
705638	718720	B	0.8916060924530029	Likelihood mapping from hidden states to observation is expressed as block matrix which is exactly correspond to block matrix shown in the bottom of this figure.
725390	726042	B	0.714073896408081	Like this.
726096	735390	B	0.8663896322250366	For every tab we have the exact correspondence between the upper expression and the lower expression.
737970	747630	B	0.7012892961502075	So that's why we can say that this is a natural mapping from neural network correlation to computational vision formation.
751970	759010	B	0.8630593419075012	It speaks to a sort of identity between those two different expressions.
760150	774870	B	0.8561030626296997	So although 1 may be able to consider another mapping from neural network to Beijing infrastructure, this is a sort of just simplest mapping.
777150	786146	A	0.8572041988372803	So how would it look different if it were three states categorical distribution or a continuous distribution?
786278	788800	A	0.8671097755432129	What aspects would change?
789650	792382	B	0.784842312335968	Thank you for asking that.
792436	813314	B	0.5288587808609009	So that's in some sense outside of this paper because only when we consider a binary hidden states, this analogy is established nicely.
813442	833980	B	0.8736761212348938	Otherwise we need to consider some attention because consider that each neuron encode the probability or expectation of some value taking one.
834430	849770	B	0.8453910946846008	Then the probability or expectation of taking zero can be simply computed by computing one minus neural activity.
849850	860050	B	0.8240389227867126	So actually activity which is a single dimensional variable is sufficient to express the expectation.
860970	871430	B	0.6894958019256592	But once we consider the three state hidden states program so this doesn't work.
871500	876694	B	0.831251859664917	So we need to consider at least two variables.
876822	886300	B	0.5991442799568176	But its correlation to neural network expression is not very clear in general.
892130	909730	A	0.6707429885864258	That's very interesting why it would be so strong of a concordance in a binary case but immediately unclear for other distributions.
910870	940160	B	0.7519715428352356	Yeah, generative for pond DP expression we consider the Ronen photo expression vector expression which means that we normalize the value in the sense that the sum summation of all or variable to be one.
941730	947338	B	0.8302981853485107	Maybe there is some neural neural subscription that achieve that normalization.
947514	961166	B	0.9082030057907104	But for classic type of neural network like canonical neural network consider in this paper what is that neuronal?
961198	964210	B	0.601719081401825	Savage street is not very clear.
964360	973670	B	0.5187280178070068	So that's why we selected the boundary case because it's simple and have a clear analogy.
974750	988670	A	0.8964567184448242	So what does it mean for an artificial or for a biological neuron to have activity dynamics or activity context?
989650	998750	A	0.8436745405197144	That justifies it being described as playing like a belief role in a Bayesian setting.
1001800	1005664	A	0.717744767665863	Higher firing means more belief, higher firing means lower belief.
1005712	1011670	A	0.6809683442115784	Like what does it really mean to have a connection between activity dynamics and belief states?
1012300	1013144	B	0.5826064944267273	I see.
1013262	1022932	B	0.8567758202552795	So if you assign a mapping, a particular mapping, then its meaning is also determined.
1023076	1036670	B	0.9068881273269653	In this case, we assign that neuro activity correspond to the posterior expectation about an element of hidden state taking one.
1037040	1046130	B	0.7466301918029785	So once we define this mapping, then higher neuropetivity indicate the higher probability of taking one.
1052540	1065710	A	0.9135509729385376	So neural activity is the probability neural activity is on the x axis and the y axis of the sigmoid function is the probability of taking one.
1067440	1074800	B	0.7214927673339844	Well, neural activity encodes the expectation.
1075220	1080870	B	0.8526585102081299	So activity is sigmoidal function of something itself.
1088570	1097740	B	0.8874972462654114	This is because once we see a fixed point of neuroptivity equation which is derived from this cost function.
1098110	1100538	B	0.8026641607284546	It has a form of sigmaidal function.
1100624	1104140	B	0.877035915851593	So x equals sigmaidar function of grab drive.
1104590	1121600	B	0.8792527914047241	So this form is exactly correspond to a softmax operation softomax function of something which is seen in the solution of posterior expectation that there is.
1126570	1136390	A	0.8906585574150085	So that's what the neural activity encodes and what is the Bayesian interpretation or the update rules on the plasticity.
1137870	1142346	B	0.5489124059677124	Okay, that's another important point.
1142528	1167570	B	0.9122845530509949	So in terms of posture of parameters so in the case of Beijing Coherence, we consider update about deleted parameterisation of a matrix and B matrix which is usually expressed by the small case variable.
1168630	1215810	B	0.8747946619987488	And its meaning is that if we compute the partial derivative of partial derivative of F with respect to small a, then its solution, its fixed point solution looks like out of product of Sno which is also known as Hebbian product because it has analogy to update through depending on the neuron activity and post synaptic neuron activity.
1216230	1264990	B	0.8952207565307617	And according to this format equivalent, we can see again such and analogy in a formal sense here if we compute the partial derivative of neural networks function with respect to W, then we can formally derive the behavior prosthesis which depends on the activity of pre on post synaptic neuroptivity.
1268500	1277110	A	0.8519821166992188	Okay, so Hebbian plasticity often described as neurons that fired together, wired together.
1277720	1289110	A	0.9132980704307556	Here you're discussing it in terms of a matrix operation on the POMDP side between observables and hidden states.
1290060	1304590	A	0.7000739574432373	So there's a Hebian plasticity happening between the perceptual layer and the cognitive layer, right?
1306000	1325200	A	0.8173696398735046	The first half of the neural network is trained according to Hebbian plasticity rules that optimize the A in terms of the perceptual and learning like relationship between hidden states and observables.
1326600	1333140	A	0.8977196216583252	And then the second half of the neural network has a slightly different structure.
1333960	1350440	A	0.869933545589447	It is optimizing based upon retroactive reanalysis of consequences of action according to the fictive causality construction.
1353440	1365728	B	0.8944329023361206	So actually in this figure b, upper layer correspond to environment and the lower part correspond to agent.
1365814	1369410	B	0.8466106653213501	So this structure corresponds to figure eight.
1371140	1374732	B	0.8881259560585022	This correspond to a simpler version of palm DP.
1374796	1382816	B	0.8466002345085144	So for Bull version of palm DP, its corresponding neural network is showing.
1383008	1392340	B	0.9317132234573364	Figure four of this paper may start.
1392490	1393430	B	0.5760965943336487	There we go.
1393740	1396948	B	0.8248778581619263	This is the neural network architecture.
1397124	1414500	B	0.8892489075660706	All right, so as you said, there is a network connection from sensory layer to coordinating layer which is expressed by W here.
1414570	1426740	B	0.9013414978981018	And the recurrent connection which correspond to state cognition matrix is expressed by K matrix which is recurrent assignment connectivity.
1426820	1449330	B	0.9084756374359131	And as you say, the action generative through retrospective, reward or risk evolution is done by output trailer through the synaptic connectivity expressed as V in this figure.
1451220	1461270	A	0.8945498466491699	So V is the synaptic connectivity between cognitive states in the middle layer and the action selection states in Y.
1461960	1465524	A	0.8236761093139648	And so in that way V is exactly analogous to W.
1465722	1472132	A	0.6523274183273315	But why and how does gamma come into play only in this second layer?
1472196	1476760	A	0.8157417178153992	I mean, why not have gamma one in the first layer, gamma two in the second layer.
1479280	1492148	B	0.7726287245750427	Generally speaking, it is possible to modulate plasticity in first layer using another modulator gamma.
1492264	1498640	B	0.8203955292701721	But for complexity we focus only on neuromodulation in the output layer.
1499380	1543280	B	0.8559248447418213	Analogy is that for example, as you said, the first layer compute more perceptual things so perception of external world and instead on the other hand middle second layer which is mapping from cognitive layer to action layer perform the optimization of its own action.
1543620	1559460	B	0.8189569711685181	So for example, in the story atom in the brain, action selection is optimized by moderation of dopaminersic input.
1559880	1581508	B	0.9188613891601562	So usually that sacred receives signal from canonical neuroscience and sends signal to another neuronal nucleus in meat brain.
1581684	1593068	B	0.8426938652992249	But the point here is that neuron in storiatum encodes some decision, for example goal or no goal.
1593164	1596400	B	0.7761255502700806	So such a decision is encoded.
1596900	1623044	B	0.884229302406311	So now we consider analogy between pond EP expression in the base information and neuroscience in the brain that optimize action group some sort of conversation by another factor.
1623172	1626040	B	0.7935135364532471	Here that factor correspond to gamma.
1626780	1645340	B	0.8367177844047546	Andy Clark gamma gamma has a variety of function, but in this paper we focus only on the moderation of activity.
1646560	1672276	B	0.7295931577682495	So here the heavy and prostitution is not determined by only post relationship but determined by three factors relationship in the sense that the prostitute is updated by the product of gamma and pre and postsynaptic activity.
1672388	1677480	B	0.8305228352546692	So there are three times in one prosthesis.
1678140	1682600	B	0.8643771409988403	This is why this gamma can modulate prosticity.
1686290	1692570	A	0.8630622029304504	So how would a glial factor look different computational?
1692730	1701060	A	0.6892940402030945	And where in the brain have people identified Glial or other factors as relevant for learning?
1702310	1705234	B	0.7758888602256775	Yeah, that's and interesting point.
1705432	1713826	B	0.57961505651474	I'm not really sure about the equation of the free correlation of neural activity or plasticity.
1713938	1734746	B	0.6932953596115112	There are many discussion, I'm sorry, I don't know the exact form, but one possible implementation is similar to this type of neuromodulation.
1734858	1758850	B	0.8270261287689209	So it would be possible to model some griar modulation contribution of Glapter to activity in the form of three factor learning group, which is mathematically speaking in the same as this type of neuromodulation.
1763960	1769300	A	0.910452127456665	Here in table two we have another set of correspondences.
1769960	1773624	A	0.8651807904243469	It's like a sideways figure three, right?
1773742	1776280	A	0.7828643321990967	But a little bit more like a dictionary.
1781080	1782132	A	0.8329665660858154	Anything to add?
1782186	1785030	A	0.6732327342033386	Or any variables that we haven't really mentioned.
1786940	1788724	A	0.8074755072593689	What about the firing thresholds?
1788772	1806936	A	0.7318947315216064	Because these are common parameters in a neural model, however, we don't really hear about the interpretation of these constructs within the variational bays.
1806968	1820240	B	0.9522154927253723	POMDP yeah, there is an interesting story that's a very interesting point.
1820310	1847560	B	0.5543316006660461	So when we first tried to make and arrowy between neural network and OMDP, one problem is the law of threshold factor because as you said, it is not observing pondip structure.
1847900	1864960	B	0.8776214122772217	But there is another factor in pondip which is prior expectation about hidden state which is usually expressed by D matrix.
1866180	1875180	B	0.846088171005249	And what we consider is a relationship between D matrix and firing threshold.
1875340	1906540	B	0.8706211447715759	And finally, what we found is that firing threshold is not equal to D matrix itself but it is a summation of D matrix and some function of synaptic strengths which is equal to a matrix B matrix in the Pom DP formation.
1906880	1942920	B	0.8169676065444946	In other words, what we found is that h which is a firing threshold in NeuroNetwork architectures is actually and adaptive threshold which is not fixed by but h is a function of W synaptic strengths and h changes depending on W's value.
1942990	1951140	B	0.7107717394828796	For example, if W is too large, then neuroptivity can be unstable.
1951220	1961420	B	0.5993633270263672	So h behavior to reduce the activity to make neuro active states more stable.
1962020	2010040	B	0.8762262463569641	So we can see and analogy of homeostatic mechanism here like this if we design h as the function of w and function of some another factor which is called perturbation time in this table, then we could make formal analogy between this h and some variable in Palm DP formulation which is shown in the right hand side of this table.
2010200	2018832	B	0.7683546543121338	Although its value is not simple because it has three times, three different times.
2018886	2025990	B	0.8488298058509827	So all of them contribute to make h or M.
2028760	2041560	B	0.6038339138031006	But anyway, once we establish a mapping between h and this value then everything works.
2041710	2050360	B	0.8531392216682434	So the cost function in different settings have a force correspondence.
2053100	2057740	A	0.8337284326553345	What are the h and M firing thresholds.
2058160	2072908	B	0.8899573683738708	So h correspond to middle rare, m indicate output rare threshold which are different variables.
2073084	2098920	B	0.7672791481018066	And interestingly h correspond to posterior sorry, prior expectation about the hidden states because it correspond to cognitive layer and M correspond to prior belief about its own action because it is a bias in the action layer.
2100640	2122736	A	0.7142297029495239	Yeah, it's very interesting that the perceptual firing threshold h only includes prior beliefs on hidden states, beliefs about how observations map to hidden states A and beliefs about how hidden states change through time B.
2122918	2140184	A	0.822436511516571	So that's like pure passive inference and then the foraging thresholds for M correspond to only beliefs about preferences and beliefs about actions or habits with C and E.
2140382	2157660	A	0.6888619661331177	So there's like a complete division of labor or partitioning functionally between these structurally different parts of the neural network and structurally different and functionally different parts of the POMDP.
2159280	2167760	A	0.8274238109588623	Yet they're integrated in unified loss functions or unified imperatives.
2170180	2198360	A	0.527191698551178	And so it's like there's extreme separability of perception and action on both sides of the figure one divide but also they're integrated, but they're separate and that's what kind of grants it the best of both worlds because if they were any more integrated you couldn't really pull them apart.
2198780	2209740	A	0.6312761306762695	And if they were any less integrated then the imperative, the loss function or the variational free energy would be ad hoc and unprincipled.
2210720	2216640	A	0.798753559589386	But there's kind of a middle ground where they have a principled integration but still a distinguishment.
2218980	2219730	B	0.7360090017318726	Right?
2221860	2248168	B	0.6902983784675598	This is caused by network structure defined or it is because it is because the structure of Bayesian network defined in the OMDB model.
2248334	2256328	B	0.8136840462684631	So both of them define the causal relationship between elements or quantities.
2256504	2264492	B	0.5423904061317444	And so it's, you know, it's substrate is not important.
2264626	2276000	B	0.8643627166748047	So it's relationship, causal relationship is crucial to to determine the Costa function or it's a fixed point in this context.
2276160	2281300	B	0.8083556890487671	So that's why we can see the data analogy.
2284620	2297336	A	0.8068190813064575	Well, there's a few technical points I think we can now go into and then there will be some more general points about applications and intelligence.
2297528	2302588	A	0.7877229452133179	So, first the code availability statement.
2302764	2310060	A	0.976556658744812	Awesome to see that the MATLAB scripts are available and also archived on Zenoto.
2310220	2315700	A	0.8146399855613708	So here is the GitHub repo for reverse engineering.
2316440	2321632	A	0.880757749080658	Do you want to give any overview descriptions of what people can expect to see in this repo?
2321776	2325220	A	0.889341413974762	And also what about using MATLAB?
2330250	2332514	A	0.8233511447906494	Why did you use MATLAB?
2332642	2336230	A	0.8923062086105347	What advantages or limitations do you see in MATLAB?
2338490	2351690	B	0.7307569980621338	So because this is a very simple simulation, so it is so MATLAB is sufficient to encode the wall script.
2354930	2362080	B	0.8762878179550171	We also try some visualization in the Attial here.
2363570	2375010	B	0.8894570469856262	If you run the script, then you can see the process of an agent solving the maze task.
2379590	2383974	A	0.8944527506828308	What did they do in the May's task here?
2384092	2394970	B	0.8135383725166321	The aim of this agent is to reach the right hand side of this maze.
2396430	2405310	B	0.8162937760353088	Because this is a typical example of a derived moderation task, that's why we select the maze task.
2406770	2419918	B	0.8598966002464294	So to achieve this main task, is it required to make some plan to be able to select a good decision?
2420094	2433698	B	0.820527970790863	Because without planning, you may encounter the wall and cannot go further and you may fail the mace.
2433874	2443820	B	0.5296288728713989	But with planning, it is possible to see the path to reach the right hand side of this space.
2446190	2449290	A	0.7631624341011047	So does it know its exposition?
2453230	2464478	B	0.9068043828010559	Yeah, it received a state from neighboring eleven times eleven cells, so which is shown in the bottom part.
2464564	2466494	B	0.7154908776283264	Yeah, this all correct.
2466612	2473390	B	0.8530139327049255	All most yeah, left figure see indicate the observation.
2473470	2481300	B	0.8830913305282593	So, eleven times eleven state around the agent position.
2481910	2482322	B	0.584351658821106	Okay.
2482376	2493020	B	0.8961024880409241	Now agent is on the right hand side of mace, ant the gold position and it observed our neighboring state.
2497150	2500330	A	0.9220653772354126	Well, a few interesting things here.
2500400	2503340	A	0.6533541083335876	It's looking off the right end.
2503950	2504566	B	0.5491447448730469	Yeah.
2504688	2511230	A	0.871297299861908	And it has this kind of periodic belief in the distribution.
2511650	2512400	A	0.6120102405548096	Why?
2515250	2533506	B	0.7848122119903564	I think it is because when the agent is in the middle point of maze, then all neighboring state is in the maze.
2533538	2539160	B	0.6192306280136108	So there is a path and there is war.
2539930	2562800	B	0.8997224569320679	So this makes some periodicity because mazes may have some structure and actually have a periodic structure and only at the gold position, then righthand side becomes war.
2563810	2570580	B	0.6611526012420654	But it is not common in the for this agent.
2571030	2583170	B	0.8598155379295349	So because this is because this agent belief shows such a periodic patterns.
2584310	2590440	A	0.7671618461608887	Yes, the streets are one wide and they tend to be separated by one.
2591470	2593638	A	0.8385664820671082	So we see this periodicity.
2593814	2601130	A	0.8933894634246826	What is the numbers in this middle bottom plot and what does the checker board represent?
2601630	2611658	B	0.8877723217010498	Yeah, here, QS and QD correspond to posterior expectation about active states and decision.
2611754	2618770	B	0.8770384788513184	So middle Canada indicate decision posterior and decision.
2619270	2627678	B	0.9166061282157898	Here we characterize decision as a sequence of four step actions.
2627774	2638840	B	0.8922027349472046	So each action corresponds to a movement to right or left or up or down.
2639450	2648138	B	0.9076985716819763	And we consider four step sequence of that option which is expressed as D.
2648304	2659790	B	0.5572448372840881	So it has four powerful possibility.
2661490	2663040	A	0.6583408713340759	256.
2663970	2666190	B	0.7290316820144653	Yeah, 256.
2666340	2681862	B	0.9220510125160217	So this is a protein on XY coordinate because in the middle panel, middle point correspond to the current cognition of agent.
2681996	2704830	B	0.9001429080963135	And with four step movement, agent can go one of any current position and the current brightness correspond to the expectation about the agent decision.
2705810	2707726	A	0.9748290777206421	Well, this is very interesting.
2707908	2715070	A	0.8456048369407654	If we just were to think about you're in a point and you can go up, down, left, right, you have four moves.
2716630	2721490	A	0.49603331089019775	Naively it sounds like, well, it should look like a gaussian blur.
2721990	2728538	A	0.8276425004005432	Most of those should cancel out and then it should become rare and rare monotonically.
2728734	2743660	A	0.5912837982177734	But actually if you start in the middle you can't end up on these white squares because it's like one, two, three and then you have to leave.
2744910	2745754	B	0.7360090017318726	Right?
2745952	2765950	A	0.592657208442688	So it's kind of like horses in chess or other pieces where actually their embodiment, it's very unexpected that you can't in four moves, end up next to where you began when you can be so much further.
2766470	2781250	A	0.8664779663085938	And then we see this kind of like embodied differentiate prior with QS that embodies regularity beliefs about the width of the road and the separation of the roads.
2781590	2793450	A	0.8377139568328857	And then there's these embodied action priors and real consequences that have to do with the structure of movement.
2794910	2796426	A	0.8062378168106079	So what it's doing?
2796528	2801386	A	0.887397050857544	It's thinking about policies of length four.
2801488	2804480	A	0.9039992690086365	There's 256 policies of length four.
2805010	2810718	A	0.8733012080192566	There's some degeneracy because there's obviously not 256 squares here.
2810884	2829220	A	0.6948932409286499	So while only one policy is going to take you up, down, down, other squares are reachable, like the center square is probably the mode because it can be reached at least a handful of ways.
2831690	2839240	A	0.8486295342445374	And then at each time point it's basically saying, okay, I know where my X position is.
2839690	2848700	A	0.6470240950584412	And given my local eleven by eleven view, I'm trying to plan to go right.
2854780	2860750	A	0.8393236994743347	And then here through time, in the simulation here it starts at 30 something.
2861520	2868210	A	0.8531252145767212	It quickly figures out how to get to about 40 and then it's kind of going up and down on 40.
2869140	2876720	A	0.6047150492668152	But it can't really break out because all of these bottom four routes are closed.
2877380	2883430	A	0.8587574362754822	It has a breakout and then very quickly it hits another plateau around 60.
2884360	2885110	B	0.5664745569229126	Right.
2885720	2893130	A	0.9704697132110596	Then it kind of has a very nice breakout and in just a few steps goes very far.
2895260	2897352	A	0.8293192982673645	So what is dopamine doing?
2897406	2903160	A	0.8705484867095947	Or how is Dopamine helping it in the plateau and then to break out of the plateau?
2903660	2904410	B	0.46103888750076294	Yes.
2904880	2918988	B	0.8455056548118591	So this agent learned this particular mate structure through many trials.
2919164	2931620	B	0.4601328372955322	So before training it failed to reach the goal, but after training it achieved such a nice behavior.
2932040	2954504	B	0.7674472332000732	So to achieve this, the rule of domain is that we design gamma function such that if the agent can move rightward with some distance during some time limit, then risk becomes small.
2954622	2961148	B	0.7594183683395386	So like say comma equals zero, so no risk situation in that sense.
2961234	2969660	B	0.9033150672912598	In that case, this agent updates synaptic weights through hebium prosthesis.
2970260	2993240	B	0.6748113036155701	But if the agent failed to go lightward with some distance during a limited time frame, then gamma become rush like 0.6, which is larger than the average 0.5.
2993390	3007764	B	0.5810282230377197	Then we design that during such action, anti Hebbian ergodicity occurred instead of heavy prostitution.
3007812	3020280	B	0.6128129363059998	So antihibian prostitute indicates the works as the disassociation between the current state and current decisions.
3020440	3026988	B	0.9384879469871521	Because the current decision doesn't work, it's not good decisions.
3027084	3042284	B	0.9038512110710144	So we try to make the agent who get that particular decision rules through the moderation of heavy and prosticity done by dharma factor.
3042432	3050680	B	0.8096808791160583	So this can be a narrow to the dopam natural conversation and heavier prosthesity.
3052060	3064488	A	0.6472128033638	So if the policy is resulting in the expected outcome, gamma stays at 0.5, the policy is as risky or consequential as expected.
3064664	3086500	A	0.4738142788410187	And then the policy can either go better than expected, which facilitates learning to support that decision to be made more, or the outcome of the policy can be worse than expected, which disassociates previous conceptions to discourage that kind of behavior.
3087000	3087750	B	0.5662814974784851	Exactly.
3089480	3111964	B	0.8198979496955872	Crucial point is that this association with a exafferent time forage in the sense that we consider multiplication of current risk and past decisions to average over past to present Hebbian product.
3112162	3126188	B	0.7720813155174255	This makes an association between past decision secrets and the current risk, which enables to optimize decision to minimize the future risk.
3126284	3126736	B	0.5664745569229126	Right.
3126838	3129200	B	0.7735549211502075	It is just a sift or time frame.
3131720	3146890	A	0.6277199387550354	So here risk is being used in a formal sense similar to how it's used in economics, which is the associated uncertainty of outcomes with respect to a policy.
3148220	3150970	A	0.8800758719444275	Where does Daniel come into play?
3151900	3159340	A	0.6608339548110962	Like what if there was an adversary in the maze or something that was dangerous?
3160400	3168004	A	0.6170164942741394	How does this kind of model accommodate or hunger or different kinds of competition?
3168072	3172720	A	0.6700945496559143	Because right now it's basically just trying to diffuse right word with a bias.
3173380	3174130	B	0.7360090017318726	Right?
3174660	3183910	A	0.8901039958000183	But how do different kind of situational elements become integrated into the generative model and generative process?
3185000	3197524	B	0.6834341287612915	Okay, any of those factors can be involved in risk factor, a single risk factor.
3197572	3209676	B	0.8224479556083679	So you can actually design risk factor because risk factor modulate moderate generative model.
3209858	3220360	B	0.8166481852531433	So that's why agent try to minimize risk through Beijing brain updating.
3220440	3227440	B	0.7454909086227417	But the risk itself is in some sense outside of such a Bayesian framework.
3227780	3233552	B	0.792258620262146	So we can design arbitrary risk.
3233616	3241620	B	0.5511265397071838	So it may involve some danger after any other factor.
3243900	3254292	A	0.7678076028823853	And this simulation is a POMDP or it is a neural network.
3254356	3261070	A	0.9038314819335938	And what scripts might we look at to understand the structure of the maze agent?
3262320	3274232	B	0.8619124889373779	Okay, it is basically expressed using the quantity in OMDP for tractability.
3274376	3310720	B	0.806723415851593	But for examples, if you see the MDP MTP learning, probably okay, there is a variable in the definition of same type correspond to the type of simulation.
3310800	3320900	B	0.8925469517707825	So if it's one or two it becomes fomodp or neural network to my understanding.
3321340	3357120	B	0.8459732532501221	Well, in this particular examples we use, let's say maybe it's not good example that DeForest is creating the well said no exafferent in this script as well.
3357190	3366090	B	0.7350209355354309	So maybe another, let's see.
3370460	3375624	A	0.9119607210159302	MDP and it is initiating the Markov decision process.
3375822	3376376	B	0.5662814974784851	Exactly.
3376478	3396530	B	0.8762161731719971	It's just determining the initial state of the home TD simulation and Fe computer variation of free energy or risk MDP risk computer risk function.
3398040	3409620	B	0.9048892259597778	So basically we use the neural network structure computation in this particular setup.
3410360	3433660	B	0.8821181058883667	So when you free maze m, then in the line gain one line gain one we determined that cinematypo is two this correspond to neural network architecture.
3434000	3492720	B	0.8030800223350525	So there is a very slight difference between home DP architecture and neural network architectures because assuming neural network architectures correspond to considering well, if you choose the palm DP architecture then we sometimes use d gamma function to compute the posterior expectation about parameters.
3493460	3520424	B	0.7692983150482178	But in the neural network modeling the gamma function does appear but it is replaced with the logarithm of some function and asymmetry speaking active coherence between the gamma function of something and logarithm function of something is asymmetry saying.
3520622	3528584	B	0.5424618124961853	So that's why we can transform on TP two neural network architectures.
3528632	3532990	B	0.7951944470405579	When the number of samples is sufficiently large.
3537360	3545490	A	0.8225662708282471	Which form do you expect performs better under small or large amounts of data?
3547620	3560260	B	0.8496939539909363	Well, for large amount of data they books in the same manner, same cycle, same manner or small amount of examples?
3561020	3573444	B	0.8253459930419922	I'm not truly sure, but it's correspond to assumption about the posterability distribution.
3573572	3595520	B	0.7845383286476135	So if you assume the Richard distribution, then your resulting function form is something that use the function in terms of basic robbery which is optimal.
3600680	3606710	A	0.8658781051635742	All right, let's return to the earliest questions from today.
3608120	3629020	A	0.8980184197425842	So in your script, which people can reference, there's basically a toggle between having it in simtype one or simtype two corresponding to the POMDP and the neural network.
3630400	3635980	A	0.9125033020973206	What about if there's a published neural network or POMDP?
3637300	3644560	A	0.8876837491989136	How can we use this architecture to create a translation?
3648170	3650114	A	0.8245750665664673	Is there any difference in this?
3650172	3665950	A	0.7490792870521545	Kind of like translating models in the wild different than the full construction of a special script that can speak both languages?
3670610	3680480	B	0.5435906648635864	Well, in terms of script there's no difference, sympathetic difference, right?
3681970	3684842	B	0.7846683859825134	They works in the same manner.
3684906	3706234	B	0.8145385980606079	So only a translation or variable you can see the same source code in the two exafferent ways.
3706352	3719790	B	0.8391332626342773	So if you see that this is a neural network implication, then it is translated as a neural network or if you see that this is a Pomodp, then it's Pomodp.
3723160	3735956	A	0.9078718423843384	So for some neural network being used in an industrial setting, how would we get from the neural network to a POMDP?
3736148	3740040	A	0.8214966654777527	And where or how would that representation be valuable?
3741100	3741850	B	0.7360090017318726	Right?
3744940	3755052	B	0.8443793058395386	Neural network in the different architecture important point is that we consider a particular.
3755186	3761500	B	0.8911148905754089	Form of neural network which is called canonical neural network architectures.
3761660	3775140	B	0.8768529295921326	So only when we assume this class of neural network, then you can find the exact correspondence to a particular homo DB.
3775480	3790410	B	0.8640497326850891	Otherwise you need to establish another equivalence between another form of neural network architecture and some sort of model.
3792940	3808000	B	0.6620072722434998	This may be expressed by Pomodp, but maybe not so straightforward to be expressed as the computational bomb DP architecture.
3809300	3818710	A	0.907831072807312	So what is it about the canonical neural network architectures that facilitates its translation into the POMDP form?
3819320	3824630	B	0.6711300015449524	Yeah, first of all, it assumes sigmoid inclination function.
3825080	3833080	B	0.5021905303001404	It is nicely correspond to enthalpy time in the force DP equations POMDP formulations.
3833580	3840440	B	0.832249641418457	So that's why we can create a marking.
3841840	3848264	B	0.650787889957428	In other words, simply speaking, they have the same nonlinearity.
3848392	3863068	B	0.8178567886352539	That's why this translation is very easy with another nonlinearity or neural network equation.
3863164	3873664	B	0.8551737666130066	Then we need to find another type of entropy equation or another type of prior distribution.
3873792	3876340	B	0.6455100178718567	It is very nontrivial.
3878280	3882970	A	0.5908942222595215	How does one even go about doing that research?
3890620	3899820	B	0.8709590435028076	If you want to go that direction, then I think the first step is to find the prior brief.
3907360	3919270	B	0.9101884365081787	Find the prior brief and find the equivalent between a particular neural network texture and particular Beijing model.
3925460	3929810	A	0.8888033032417297	This sigmoidal activation is interesting.
3930420	3942500	A	0.8988597989082336	It corresponds to general patterns seen in psychophysics to objects that are the same weight.
3943320	3946600	A	0.7083930373191833	You're going to have a 50% chance of saying that one is heavier.
3947020	3958140	A	0.7434505224227905	And then initially the difference has the most returns on that decision being made accurately.
3959360	3974480	A	0.8257609009742737	And then as it crosses some threshold where it just is beyond a noticeable difference, the decision becomes essentially probabilistic, like the firing curve becomes saturated.
3975620	3983410	A	0.7302641868591309	The neuron has a very low belief about zero or very high belief about zero or one flipped at.
3986520	4010460	A	0.900342583656311	So there is a nice grounding of that kind of a sigmoidal response curve with respect to stimuli differences and it has of course tractable analytical properties, but it also just happens to be a good response summarizer.
4011440	4013020	B	0.4803207516670227	Yeah, you're right.
4013090	4017500	B	0.8972522616386414	So sigmoidal function is also known as a psychometric function.
4017570	4026444	B	0.8764906525611877	As you said, we observe that characteristic in many ecological experiments.
4026572	4039472	B	0.8805728554725647	And the previous work also said that even at the single neuron level, neuronal level the same behavior were observed.
4039616	4060830	B	0.9000831842422485	Which means that for each neural activity we can leo absorbed similar property, which is sometimes called as neurometric function, which have the form of sigmoidal inclination function.
4063440	4076850	B	0.8453089594841003	So it is nice reason to design neural network architecture using a sigmoidal function.
4078980	4090100	A	0.8361883163452148	All right, let's cover a few questions in the chat from Dave and then in the end turn to some general thoughts.
4090600	4094710	A	0.9020334482192993	Okay, this was when we were looking at figure three.
4095420	4103572	A	0.8224489688873291	So you described these vectors or matrices.
4103636	4106724	A	0.879011332988739	What kind of matrix or vector did you describe?
4106772	4112980	A	0.8547933101654053	The mass block matrix.
4114840	4116100	B	0.5744388699531555	Block, matrix.
4119080	4123870	A	0.7251562476158142	Block rock meaning what?
4124240	4129016	B	0.7992422580718994	Okay, brock matrix or broke vector is vector.
4129128	4131900	B	0.7890089750289917	Vector or matrix of matrix.
4133520	4134770	B	0.5736258625984192	Imagine that.
4143060	4145724	A	0.6883525848388672	Sorry, just zoom glitch.
4145772	4148370	A	0.7623004913330078	Just repeat the last piece okay.
4150100	4157540	B	0.5502333641052246	Well, broke matrix means that the element of matrix is a matrix.
4158280	4166040	B	0.9094597101211548	So let's say two by two matrix like matrix in pointing.
4166460	4176460	B	0.5482663512229919	So this here W one hat is a matrix, and W zero hat is another matrix.
4177360	4184700	B	0.8416000604629517	And combining four matrices, we define a single block matrix.
4186820	4189250	A	0.8092430830001831	All right, thank you.
4189700	4199372	A	0.9271426796913147	So Dave then asks the hosts of machine learning Street Talk number 67 with Karl Friston.
4199436	4203120	A	0.8029384016990662	Another podcast where Friston has spoken.
4204180	4206516	A	0.870673656463623	Pressed Karl Friston on.
4206618	4214170	A	0.624127984046936	Why is it so important that most of the values in a generative model matrix assume values of exactly zero?
4217220	4221360	A	0.7546517252922058	Why is it important that generative model matrices are sparse?
4223140	4229760	B	0.6478644609451294	Why the tangential matrix sparse?
4230820	4232364	B	0.6897123456001282	I'm not really sure.
4232502	4237530	B	0.8888453841209412	I think there is some context before that point.
4238220	4253550	B	0.7355945706367493	I think on that particular situation, then, as you say, many elements in the matrix of gentle model should be zero, but I'm not sure if it's a general statement or not.
4254560	4264720	A	0.8943555355072021	What do you think about compressed analyses on sparse matrices?
4268980	4272160	A	0.8812423944473267	Is that a useful technique or direction?
4275640	4288148	B	0.5905314683914185	You can use that knowledge to construct model, so you can use that knowledge to make more accuracy inference.
4288244	4294120	B	0.5573521256446838	So in that sense, generally speaking, such assumption should be useful.
4295660	4309112	B	0.844270646572113	For example, as you said, it would be possible to use some sparse prior to restrict the value parameter.
4309176	4332500	B	0.8401771187782288	Like it is in principle same as assuming some ruby norm to design the distribution, to design the prior distinctions, which is, massmarket speaking, exactly same as considering Lasso regression.
4334440	4335190	A	0.46103888750076294	Yes.
4337080	4357340	A	0.7226017117500305	So we've explored a little bit how from a canonical neural network to a particular form of a POMDP, gives us some semantics and interpretability around the dynamics and plasticity of the neural network.
4358080	4369760	A	0.8835737109184265	What do we gain by taking a stated POMDP generative model and deriving an analogous neural network?
4372420	4380340	A	0.7122113704681396	Do we gain access to efficient computation, new software packages, different applications?
4384200	4401928	B	0.6214848160743713	Well, if one use palmdp under one's goal is to design an efficient Bay Zion model, then I think palm DP expression is sufficient.
4402024	4431524	B	0.7491416335105896	So you don't need to consider neural network architectures, probably because designed to achieve give some sort of mathematically optimal inference and decision making, right?
4431562	4437620	B	0.5177116990089417	So it itself is optimal scheme.
4437780	4453340	B	0.8385071158409119	But if one need to consider link between Bayesian coherence and biological substrate, then this mapping is crucial.
4457680	4467548	B	0.7184008359909058	Simply speaking, we consider that we assume that a brain perform Beijing inference, but its substrate is still unclear.
4467644	4475436	B	0.847070038318634	So we need to link the Beijing quantity to biological quantities.
4475628	4481760	B	0.5028632283210754	So this mapping, this equivalence, helps us to its transformation.
4483160	4497620	B	0.7395519614219666	So when you start from OMDB model, then this translation facilitates the process of finding its neuronal substrate.
4497780	4516688	B	0.584065318107605	So once you translate that to neural network quantities, then it help us facilitate the experimental implication application to real data.
4516774	4543450	B	0.9084237217903137	So if its modeling is up for a particular neural network neural circuit architecture, then it should provide some prediction about the architecture or dynamics of the empirical data.
4543900	4544648	B	0.7360090017318726	Right?
4544814	4552988	B	0.651780903339386	So first we start from Pasium model, which is not necessary to be equal to empirical data.
4553074	4559288	B	0.6227235794067383	So there is some mapping, but it's mapping is not straightforward.
4559464	4580100	B	0.79401695728302	We may have multiple mappings, but once you translate Asia model to a particular neural network architectures then mapping or relationship between empirical data to such a particular neural network model is straightforward.
4580920	4589412	B	0.5026377439498901	So it helps us to apply phase to an explanation of Mpcard data.
4589546	4593780	B	0.5758001804351807	That's my soul.
4596860	4632500	A	0.6334607005119324	Is it fair to say that neural networks have found wide recent application because they facilitate statistical learning in cases where the inference problem has not been a priori well specified, one can just have a folder of images and a list of labels and just say here's the data, run it through this architecture or this Architecture Explorer.
4633880	4646490	A	0.7129651308059692	And so with this concordance we gain new interpretability into those settings that kind of arose from ill specified inference problems.
4647180	4673440	A	0.6795849800109863	And then on the other hand, for problems that we already have well specified in terms of a POMDP generative model of a particular form, we gain the connection to actually implement it with empirical data and bring it into relevant ancestral settings.
4676690	4700670	A	0.78087317943573	What systems or phenomena are promising to continue research on the maze example obviously is a simple case, but are you continuing research into more advanced computational agents, robotic animal?
4705700	4735850	B	0.5268381834030151	Well, one can design a more sophisticated agent which performs some difficult task based on canonical network neural network but there is some clear limitation on that direction, right?
4736380	4751740	B	0.762406587600708	Yeah, I should emphasize that across canonical neural network which correspond to a particular Pom DP is much smaller than general OMDP framework.
4752400	4756428	B	0.7069578170776367	So there are some limitations, a list of limitations.
4756524	4778004	B	0.7708545327186584	So if one's goal is designed and sophisticated Beijing to perform some task or control robot, then what direction is just forget such limitation and seek the mathematical optimality right?
4778122	4781660	B	0.8061575889587402	And another direction is biascalic possibility.
4781840	4808160	B	0.843718945980072	So if one want to make some agent which is biological possible then this correspondence is crucial because it it tells us some limitation, vertical limitation through the existence or no existence of such a mapping between Pom DPN particular neural network architectures.
4808500	4811330	B	0.5108225345611572	So yeah.
4811700	4822720	B	0.7111879587173462	So it would be useful to consider substrate to achieve difficult task.
4830870	4840110	B	0.8455368876457214	And that task would be related to large dimensional image processing.
4840270	4851590	B	0.7832944989204407	Image recognition or sound recognition, such as multimodality can be involved or decision can be higher dimension.
4853450	4868390	B	0.8060435652732849	In the main task, we just considered the four direction of movement, but it can be extended to higher dimensionality like arm movement, body movement, so on and so on.
4868560	4876190	B	0.5832980871200562	So in Prince Boom it can be extended in that direction.
4879090	4894870	A	0.5335204601287842	Which directions or questions are you excited about or what areas of studying the basis of biological and computational intelligence are relevant?
4895850	4896646	B	0.46103888750076294	Yes.
4896828	4911206	B	0.8676407933235168	So in terms of the importance of canonical network, as you said, virtue is a vertical probability.
4911318	4939858	B	0.5813954472541809	So it would be nice that if we model some task which is conducted by lear animal and one already recorded some neuroptive activity then we design a task which is exactly the same as the task which is done.
4940024	4958782	B	0.9235291481018066	By the animal and then compare the simulated agent and MP card data to discuss about the similarity or difference between the simulated agent and riyadh animal.
4958946	4962620	B	0.9170178771018982	That would be very interesting dimension of research.
4965630	4977360	A	0.6966642737388611	Yeah and if there could be some unexpected prediction or explanation in the computational agent that would bolster the relationship.
4978210	4998130	A	0.5806150436401367	And then one other aspect is it would help with the reproducibility and the documentation around behavioral studies if the computational agent were preregistered.
4999050	5018782	A	0.8604087233543396	And someone said, we've already done the statistical power analyses and we've already explored with parameter sweeps how many observations we need to make of the two armed bandit how many observations of the three armed bandit should we do?
5018916	5022720	A	0.8256983160972595	Three mice 100 times or 100 mice three times?
5023650	5030670	A	0.7140669226646423	Those are the total substance of designing research programs.
5031590	5044470	A	0.7386255860328674	And so having a formal representation of behavioral tasks that are being studied will help us design behavior observations and experiments that aren't simply ad hoc.
5048810	5052520	B	0.9014883637428284	All right, that's an interesting application.
5055310	5086980	B	0.5668237209320068	This framework helps to design the experimental setup itself and what we often consider is the prediction ability of these modeling canonical neural networks to predict the steroidization or dynamics of the VR neural network in the animal during the learning process.
5087350	5110086	B	0.6825664639472961	So impressed for it possible to predict the behavior after learning based only on data in the initial stage because once we obtain some empirical data, then we can fit that data to design a particular canonical network.
5110278	5126522	B	0.8306361436843872	And canonical neural network makes some serialization through a minimization of cost function which is exactly the same as the Bayesian belief updating under a particular generative models.
5126666	5148706	B	0.8422853350639343	So which means that its dynamics goes through the shortest path on the free energy landscape which means that we can make some quantitative prediction about the synaptic trajectory or neural activity or any kind of parameters.
5148898	5159974	B	0.6855171918869019	So we demonstrated that using in virtual neural network and uploaded some blueprint recently.
5160102	5183870	B	0.49533456563949585	So at least at the stage, at least at the level of individual network which is much simpler than VR brain, we could predict the self urbanization of individual network using this canonical network architecture.
5185110	5208780	B	0.7288296818733215	This support the probability of free energy principle because this canonical network predict the self organization through the variation of free energy minimization and its solution, its result chaos type correlation between.
5216750	5219498	A	0.9350240230560303	That'S a very interesting experiment.
5219594	5228110	A	0.9064449667930603	So what animal were the neurons from and what was measured about these neurons?
5228450	5255538	B	0.8925139904022217	Yes, so that in vitro network is obtained from blood embryo, we use cortical cells to make that individual network and task is a sort of causal coherence task which can be designed in the form of OMDB.
5255714	5268678	B	0.9139241576194763	So imagine that we usually simulate agent that receive signals generated by OMD generative process and process some Bayesian task.
5268854	5276554	B	0.837538480758667	So we just replace that Beijing agent to a real in virtual neural network.
5276682	5286450	B	0.8351385593414307	So we stimulate neuron with some signal which is made by some hidden sources through likelihood mapping.
5286870	5295186	B	0.8697565793991089	And question is whether in vitro network can in for the hidden states through some expectation.
5295298	5300230	B	0.7888094186782837	And they can, they could infer the hidden causes.
5303850	5312570	A	0.8315626978874207	What does it look like functionally when the neural network has succeeded at inferring the hidden causes?
5312910	5324074	B	0.897318422794342	Yeah, the director conversation is done by their response number of response spikes to a particular pattern of sensory input.
5324202	5334258	B	0.7922425270080566	So again, we can see a clear correspondence between neuro activity level and posterior about hidden states.
5334344	5341550	B	0.9064109921455383	So here we see Brea book response to electrocastimary.
5341630	5370160	B	0.8529695868492126	We see the response from ten to 13 millisecond after each estimation and we computer the number of spikes and that spikes changes their preference in the sense that some neuron learn to preferentially respond to source one but not source two.
5370930	5381630	B	0.78733891248703	So which is not a response to input itself, but it looks like a response to particular source.
5382050	5399138	B	0.7239065766334534	So it is inference and which is evidence that neural network actually perform some sort of causal coherence in a manner consistent with variation and Beijing inference.
5399314	5416858	B	0.8597512245178223	And then we compute another quantity in Bayesian coherence in the real bird card data, we show that firing stressful factor is consistent with the prior belief about hidden states.
5416944	5447750	B	0.8500332236289978	And we also compute the cyanpic weight statistically through some connection strength estimation method and show that estimated synaptic strengths is consistent with something encoding posterior belief about parameters as expected by the Salary.
5449370	5476910	A	0.8497087955474854	Well, we looked at table two earlier and this is almost like the next step after the theoretical concordance is all right, well, let's measure the release of a neurotransmitter or the empirical synaptic strength or the firing threshold or all these different features in different empirical systems.
5477650	5484980	A	0.8913325667381287	So what experimental systems does your group work in?
5490710	5498502	B	0.8789123892784119	That invitral system was made when I was a PhD student.
5498636	5506198	B	0.8922929167747498	So that is the experiment we done in my previous route.
5506374	5517318	B	0.8743018507957458	And now I COVID to the Rican Institute and I'm a principal investigator of Salary unit.
5517414	5523550	B	0.7049106359481812	So now actually, we don't use any experimental setup.
5524210	5529550	B	0.7871565222740173	Any experimental variation is down with some correlation.
5529890	5535386	B	0.7643299102783203	So although I cannot say a detail about that corroboration.
5535498	5545910	B	0.7204526662826538	But yeah, we learned some corroborating work about the implication of celery using various animals.
5546250	5546806	B	0.46103888750076294	Yes.
5546908	5554360	B	0.949600100517273	So we hope we can show some interesting results following results using animal data.
5558350	5560460	A	0.9324204325675964	Very interesting.
5561630	5580270	A	0.6150262951850891	Yes, well, it speaks a lot to the stage that our field is in in certain ways where we've seen a lot of graphics that are suggestive.
5581170	5604694	A	0.635130763053894	This paper and the building on the previous 2020 paper made a suggestive possibility much closer to an analytically demonstrated translation and then took the next step incrementally into the in silica agent.
5604892	5613900	A	0.5626489520072937	And so it's only natural to then explore different embodied systems as well.
5619630	5636020	A	0.6534134745597839	Are there any other sections that you wanted to look at or highlight or any other topics about the paper or adjacencies or active inference that you think are interesting to go into?
5641510	5652114	B	0.837076723575592	Okay, we would like to mention about some limitation of these papers which is not directly discussed in the papers.
5652242	5660380	B	0.8944952487945557	So for example, well, we focus on a discrete state space model.
5660750	5672378	B	0.8252471685409546	So we avoid to assume some sabo street that encoding the covariance of the distribution.
5672474	5677370	B	0.8681632876396179	So once you assume pole DP, then it is categorical distribution.
5677450	5685534	B	0.8667479753494263	So it is different from assuming Gaussian distribution characterized by me and variance.
5685662	5696310	B	0.6901545524597168	So the neuronal substrate of variance is still unclear and we now try to figure out that.
5696460	5699750	B	0.7178725600242615	So this is one dimension of limitation.
5700490	5719466	B	0.5639209747314453	And another limitation is that thanks to a simple ODP structure in this paper, we don't care about the hierarchical optimization.
5719578	5733150	B	0.8486313223838806	But generally it is crucial to update parameters through hierarchical optimization through some back propagation like competition.
5733490	5756810	B	0.8003832697868347	Although it is unclear whether back propagation itself occurs in the real brain, but we still have some alternative that active such optimization and its neuronal substrate still unclear and this paper does address that direction.
5774450	5785230	A	0.8390612602233887	Another area I'm wondering about is like where in neural structures is the learning reflected?
5786370	5789518	A	0.7574309706687927	Where is the function and learning reflected?
5789694	5798654	A	0.7799192070960999	Well, sometimes it has to do with not just structural Tweaking, but the presence or absence of synapses.
5798702	5812422	A	0.5505101680755615	So obviously this model does not expand into synaptogenesis synaptic pruning, let alone neurogenesis and neuro allostasis which we mentioned in the previous dimension.
5812566	5844126	A	0.8131918907165527	But understanding how these larger scale structural changes which are certainly important in biological systems become reflected in artificial neural networks and then how that translates all the way back to POMDP and then whether we could go the other way what kinds of POMDP structures in their neural network realization would have structural modification.
5844238	5853254	A	0.6248763203620911	Like you could imagine a POMDP that does structure learning but the neural network doesn't have structural change.
5853452	5862970	A	0.8253517746925354	Or there's a POMDP that doesn't do structural learning but it's manifested by a neural network that does have a structural change element.
5863870	5869418	A	0.8725358843803406	So structure is doing something very different in these two different categories of model.
5869584	5890862	A	0.8312678337097168	And then also even within neural firing, which is different amongst different species and so on, there's different aspects of what that firing is that would have different implications for the actual biological substrate of cognition.
5891006	5903258	A	0.8651307821273804	Like the simple connection is firing rate to posterior belief, average firing rate, no change in posterior.
5903374	5906534	A	0.6684385538101196	Reduce the firing rate if the posterior should be going down.
5906652	5908758	A	0.7862834334373474	Increase it if it should be going up.
5908924	5913434	A	0.759480357170105	Or maybe there are neurons that have a flipped valence but the same type of relationship.
5913632	5926350	A	0.8726853132247925	But there's other firing patterns like spike time dependent plasticity synchronization amongst different brain regions.
5927570	5932670	A	0.5255221128463745	There's a lot of things that don't change the rate overall.
5933970	5942980	A	0.8674717545509338	That, again, from the biological systems, we know that those phenomena and mechanism are important for different cognitive processes, right?
5946150	5952040	A	0.8403275012969971	So there will be many years of a fruitful relationship.
5954650	5962650	A	0.9059394598007202	I'm going to bring in this picture that Alexandra had taken.
5962720	5984880	A	0.8294833302497864	Maybe we need a third panel in figure one because these three systems moving between them is going to be the substance of the field for a long time and there's maybe other edges to build.
5985890	6019670	A	0.5985096096992493	But understanding how artificial neural networks intermediate between the empirical measurements and manipulations that we can make of real neural systems and the interpretability and factorizability of POMDPs, it might be a bridge too far to go from the POMDP to the neuron.
6019830	6028830	A	0.755166232585907	You could always use this technique, but it would be a purely descriptive statistic type approach.
6031570	6059880	A	0.8743348121643066	But it's so interesting that by intermediating through a formal connection established in figure one, I mean in equation one, but also shown here, then we can kind of extend the chain of explanation, prediction, control, design all the way on through.
6061050	6084750	A	0.7050178647041321	And that just unlocks an incredible amount of neuroscience that hasn't been formalised mathematically and an incredible amount of generative models that have been specified for different learning settings, sometimes even by analogy to biological settings.
6085890	6096930	A	0.7609379887580872	But the metaphor remains just a metaphor until it's possible to intermediate with this type of neural network development.
6097830	6101400	B	0.7075645327568054	Yeah, that's a crucial point.
6105210	6120700	B	0.58481365442276	It is easy to imagine that Liar data or lear phenomena can be modeled using very realistic neuro model or Glia model, synaptic model, right.
6123150	6138466	B	0.4664045572280884	We believe that it is possible and then model is not necessary tractable, not necessarily useful because it is too much complicated to analyze something.
6138568	6148770	B	0.8079572916030884	So we use some reduction, usually mathematically speaking, which correspond to topological transformation to make the model simpler.
6149530	6170778	B	0.6326135396957397	And then we need to consider the translation of that simplified neural network model because neural network model itself is not explainable, which just represents some dynamics and its functional meaning is not clear.
6170944	6199650	B	0.9332475066184998	But thanks to the Bayesian framework, we have a very nice framework to lens the experiment ability and this translation, this correspondence helped us to link such phenomena base equation modeling and functional based equations.
6200970	6212310	A	0.8165292143821716	Yeah, one paper from 2017 that was much discussed by some could a neuroscientist understand a microprocessor?
6213070	6228160	A	0.8754530549049377	And this group with Jonas and Cording, they had a simulation of a microprocessor from earlier video game console, I believe.
6228850	6251814	A	0.8625926375389099	And then using the analogy of the transistors and their connections as neural firing and structural connectivity, they were able to simulate experimental settings, input and action and then make measurements from every neuron including doing lesions and loss of functions and so on.
6251932	6275706	A	0.5115163922309875	And it turns out that a lot of the techniques that are used to derive scientific explanation from analogous data collected from a biological system, those techniques which ostensibly should be isolating functional explanations in fact did not isolate effective explanations.
6275898	6292370	A	0.7119109034538269	You could have a deletion over here that induces some statistical change all the way over here and that may or may not be a useful cue towards the function of even sub circuits.
6293270	6314810	A	0.7290244102478027	And so I think that was a wake up call with respect to the interpretability of simply this connection between the biological and the neural network.
6316190	6337310	A	0.5578956604003906	This connection alone is of limited applicability, even when the neural network model becomes so complex as to recapitulate the biological phenomena, you're never under any guarantee that you're going to recover interpretability.
6337830	6349578	A	0.6722893118858337	You may have just created an atomic level simulation of the phenomena, but of course, a map that is the same scale as the phenomena isn't a map.
6349774	6353190	A	0.7390573620796204	It's just a copy that has no more interpretability.
6355370	6386830	A	0.7427293658256531	And it's almost like what is now extended again, as we kind of just summarize this and think about how we move forward, is that connection can now be extended into the space of interpretable causal models and the generalized Bayesian graphical computational frameworks and all the heuristics that we can then use like variational, Bayesian and all these other methods.
6387270	6408914	A	0.5328476428985596	So it'd be interesting to look back at different data sets of in vitro and in vivo and in silico neural activation, especially if the task was of this constrained set of POMDPs and it was already amenable.
6408962	6422570	A	0.68411785364151	Because, as you brought up, other settings would require a little bit more theory development before we understand what POMDP family would be applicable.
6428450	6429054	B	0.84200119972229	Cool.
6429172	6433520	A	0.8733499050140381	Well, do you have any final thoughts or questions?
6436050	6439300	B	0.7182431817054749	Well, do you have.
6443670	6455810	A	0.7956041693687439	I want to download the MATLAB scripts and generate the figures, play around with a few of these parameters.
6456630	6460920	A	0.7846764326095581	Like, I see that you can change how far the entity can see.
6462590	6469770	A	0.6641401648521423	And then with these models, I'm also always curious about the computational complexity.
6470190	6482910	A	0.7881978154182434	Like if you extended the planning horizon from four to five or you dropped it down to three, what is the runtime consequences and what is the performance consequences?
6483890	6500230	A	0.6227498054504395	And where might we be able to use single or swarms of really simple agents, maybe even making binary decisions and achieve high performance?
6501210	6538990	A	0.6506531238555908	And where do we really need to move into these large combinatoric spaces in order to solve problems and the kinds of complex planning problems that we solve, whether it's planning our day or planning our week, are those more like true Deep Horizon planning problems with extensive consideration of counterfactuals and calculation of alternatives?
6539150	6558150	A	0.8296710848808289	Or are those actually composite decisions that are made up of smaller, simpler, sub decisions that we may or may not have flexibility to restructure?
6560330	6569260	A	0.8476078510284424	So that a decision, a complex chess maneuver, a sacrifice in chess or another game.
6570990	6586990	A	0.651881992816925	It may be possible to model that as a Deep Horizon scan or a kind of intuitive heuristic for an appropriate skilled entity.
6590210	6608402	B	0.5359406471252441	For this particular Tour structure, there is a clear limitation about the horizon of the forward search because it doesn't use forward prediction.
6608466	6611394	B	0.8807994723320007	It used post action approach.
6611442	6625370	B	0.8101054430007935	So it's a career limitation, but still, it may have some performance ability to achieve some revenue performance.
6627330	6632350	A	0.6430182456970215	That provides even another way to look at planning.
6632850	6655590	A	0.6748218536376953	So the the two ways I was describing planning, as it's often described in the PMDP literature, is again, is it a true Deep Horizon consideration or is it just short term heuristic or nested models that are short and I think that this paper says maybe neither.
6656250	6679178	A	0.7504680752754211	Maybe it's purely the fictive causality on the past that leads to the emergence of sentient and maybe even teleological planning like behavior through the ongoing reconsideration of the consequences of past action.
6679354	6683674	A	0.5913478136062622	But it's neither a short nor a long term planning challenge.
6683722	6687046	A	0.6686211228370667	It's actually like a memory and learning challenge.
6687178	6689022	A	0.5820712447166443	And no planning occurs.
6689166	6689860	B	0.7360090017318726	Right?
6690470	6697970	B	0.9025056958198547	But indirect to planning planning element is involving C matricing.
6698950	6704630	A	0.7480044364929199	Planning as a phenomena occurs and derisking through time occurs.
6706810	6731920	A	0.618270993232727	But it says something quite interesting and deep that that phenotype or function could be enacted by a system that explicitly looks a long way ahead, explicitly looks a short way ahead or moves forward and looks backwards only, which is what they sometimes say about the past and the future.
6733650	6753720	A	0.5877543091773987	So that may be a very biological plausible form of learning and it's already intimately connected with the dynamics and the plasticity in terms of an integrated loss function.
6755290	6762280	A	0.9453537464141846	So these are all excellent directions to keep learning on, right?
6763050	6772582	B	0.7532832026481628	And I'm also interested in the barsky implication of such a short term or long term force, the prediction and planning.
6772646	6788290	B	0.8981022238731384	And I hope to find some nice connectivity to such implementation of Bayesian mode and implementation VR brain network.
6789590	6790386	B	0.84200119972229	Cool.
6790568	6799650	A	0.7221531867980957	And also I'm always curious about the invertebrate brain as an ant researcher.
6800090	6812374	A	0.6385741829872131	And so many of the brain architectures as well as the regional architectures that people discuss are mammalian centric, which makes sense.
6812572	6825680	A	0.6551224589347839	The mammalian cortical column and the relationship with Dopaminergic brain and the cortical regions and the spinal reflux arc, those are all important systems of interest.
6826290	6835390	A	0.8465535044670105	Yet the micro and meso anatomy of the invertebrate nervous system is pretty distinct.
6836130	6847890	A	0.7943437695503235	So our model should be able to describe neural and cognitive systems, of course across invertebrates and vertebrates.
6848230	6867450	A	0.5289180874824524	So I look forward to also seeing like what those models of the invertebrate nervous system and cognitive behavior where you could have some type of backwards looking risk coherence of the swarm.
6868750	6869850	A	0.706895649433136	Who knows?
6872190	6872940	B	0.6177208423614502	Well.
6875310	6879734	A	0.9478827714920044	We really appreciate the time that you took for these discussions.
6879782	6888210	A	0.9568459391593933	I think they are immensely important and we wish you the best of luck in these cognition continuum directions.
6895380	6896688	A	0.5725107192993164	Okay, that's it.
6896774	6897570	A	0.8529649376869202	Thank you.
6898420	6899680	B	0.9599630236625671	Thank you very much.
6899830	6900672	A	0.6020334959030151	See you next time.
6900726	6901360	A	0.5137446522712708	Bye.
