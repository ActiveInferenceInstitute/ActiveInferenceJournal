start	end	startTime	summary	headline	gist
38860	85060	00:38	This is activem live stream number 51.1. Welcome to the active inference institute. We're a participatory online institute that is communicating, learning and practicing applied active inference. All backgrounds and perspectives are welcome.	Active inference institute is communicating, learning and practicing applied active inference	Livestream
86040	178280	01:26	We're having our first non solo discussion on this paper, canonical Neural Networks Perform Active Inference. It's going to be a great discussion. Go for it Tokuya however you'd like to introduce and say hello.	Daniel: We're having a discussion on canonical Neural Networks Perform Active Inference	How Can Neural Networks Perform Active Inference?
178730	224440	02:58	Takai Somar is a neuroscientist in Lieken Brain Science Institute in Japan. He is particularly interested in universal characterization of neural network and brain using mathematical techniques. He believes this work is important as a link between active coherence aspect aspect of the brain and the dynamic system aspect.	Takai Somar is interested in universal characterization of neural network and brain	Neuroscience discussion of the neural network
226490	422360	03:46	What is the universal characterization of neural networks? Why is it being pursued in this area of research? People use active inference formularization to characterize brain activity, behavior, so on. What makes a neural network model a neuralnetwork model and what makes an active inference model anactive inference model?	The first thing you added, the universal characterization of neural networks	The universal characterization of neural networks
426080	597500	07:06	The paper tries to make a formal ring between neural network and active infrastructure. In the following sections, we characterize the problem using Pomodb or partially observer Marco digital process. And then we simulated we used the simulation to corroborate that property in terms of some maze task.	This paper tries to make a formal ring between neural network and active infrastructure	Applying the concrete cross to neural network
598270	1107340	09:58	Could we talk about the complete class theorem? The computer indicates the relationship between some crossover decision rule and Beijing inference. This complexity theorem is crucial as abstract characterization of relationship between conventional neural network architectures and dynamics.	Complete class theorem is crucial as abstract characterization of relationship between conventional neural network architectures	The Complete Class Theorem
1112500	1876930	18:32	How does the decision rule play out in the context of neural networks? The relationship of admissibility depends on both agent characteristic and the environmental characteristic. How does this admissible help us think about, like, overfitting?	Are there any examples of decision rules that will help us think about neural network action	Decision Rules in neural networks
1882090	2440950	31:22	Do we need to have knowledge about all states possible actions and sensory inputs for active inference? How are these addressed in neural networks and how does active inference help us think about it?	Do we need knowledge about all states possible actions and sensory inputs for active inference	Do we need to know all the states of a neural network for
2444170	3481890	40:44	Reverse engineering is a characterization of the blueprint of some device or machine from data observable information like activity or action behavior of some agent. By reverse engineering neural networks, we're observing some already parameterized neural network and then fitting a POMDP to it. To what extent is it possible to create a neural network that errors that inference?	Reverse engineering is a characterization of the blueprint from data observable	Neuroscience: Forward and Reverse Engineering
3483800	4480708	58:03	So we can transform a particular pond Beijing modeling to a neural network architectures using this relationship and then get prediction about the substrate. It makes me think about the differences of implementation and heuristics in the computational setting and the biological setting.	We need to address the neural network architectures substrate property	Neural Network Architectural substrate
4480814	5424560	1:14:40	Awesome. Could you describe what you just did about the role of the B matrix in influencing how hidden states change and how that is where our policies have impact? Can you connect the asymmetry between the top and the bottom on figure two with the two layer neural network architecture?	Dave: Could you describe the role of B matrix in influencing how hidden states change	POMDP and the two-layer neural network
5424870	5716550	1:30:24	W VK and comma represent synaptic connection in a different layer or different architecture. The middle layer we can think of as like the cognitive stuff. The recurrent connections are facilitating attention or weighting of the stimuli. This graph of recurrent network is sufficient to characterize any type brain architectures.	WVK synaptic strengths represent synaptic connection in a different layer or architecture	WVK and its neural correlates
5718330	6052020	1:35:18	 Gamma basically means risk factor risk function. This is a part of generative model we designed. Connects the role of Dopamine in motor decisionmaking seen in many Dyskinesias. Also in seemingly non motor based decision making like gambling or investing.	Laura Bijan: Gamma modulation between layers two and three is interesting	Bayesian decision-making with Dopamine
6052520	6622460	1:40:52	The paper is a critical time window for Dopamine actions on the structural plasticity of Dendrite expines. How does this change our understanding of animal neurophysiology? And how does this influence how we would design sentient artifacts?	A recent paper shows that Dopamine can modulate past plasticity	Can Dopamine Modulate the Future?
6627020	7003760	1:50:27	My first motivation is to make biological plausible artificial intelligence. To active that we need to know about biological brain or biological neural network. Just defining neural network architectures is insufficient. And we need some assumption, some trick to increase the tractability.	How did you come to study neural networks specifically with Karl Friston	Quantum neural networks in the biological brain
7011950	7044530	1:56:51	Awesome. Well, it has been quite an interesting one. Is there anything else you want to add? Otherwise we'll talk again. All right, talk to you later.	Ronen: Well, it has been quite an interesting one	A discussion on the Right to Know
