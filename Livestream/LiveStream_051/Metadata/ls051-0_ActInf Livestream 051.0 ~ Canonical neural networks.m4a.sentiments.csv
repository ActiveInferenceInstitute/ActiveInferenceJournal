start	end	speaker	sentiment	confidence	text
28470	28946	A	0.6228107213973999	Intro.
29088	31682	A	0.7946102023124695	All right, welcome.
31816	32418	A	0.6054748892784119	It is.
32504	35380	A	0.9022907614707947	ActInf lab Livestream number 51.0.
35830	41054	A	0.8972258567810059	This is the background and context first discussion for canonical neural networks.
41102	44402	A	0.8870869278907776	Perform active inference by isomerate et al.
44536	47620	A	0.9027393460273743	It's October 26 2,022.
48790	51070	A	0.6894928216934204	Welcome to the active inference institute.
51230	57590	A	0.6512011885643005	We're a participatory online institute that is communicating, learning and practicing applied active coherence.
57750	60458	A	0.8592308163642883	You can find us at some of the links on the page.
60624	66060	A	0.5365678668022156	This is a recorded and an archived Livestream, so please provide us with feedback so we can improve our work.
66430	83698	A	0.785330057144165	All backgrounds and perspectives are welcome and we'll be following video etiquette for Solo live Streams head active coherence Jorge to learn how to get involved active Coherence Institute projects today.
83784	88290	A	0.848616898059845	It's the first of several discussions that we'll have on the paper.
88360	98042	A	0.9356772899627686	Canonical neural networks perform active inference 2,022 by Takuya IsomerA, Hideaki Shimazaki and Karl Friston.
98206	101538	A	0.8698369860649109	The video is just an introduction to some of the ideas.
101554	103734	A	0.6272425055503845	It's not a review or a final word.
103932	109690	A	0.8804083466529846	There will be an overview of the structure of the paper and then we'll go through many of the key points.
109840	118346	A	0.7128997445106506	Also just to disclaim, there's many, many other and better resources to learn about neural networks.
118458	133190	A	0.9206277132034302	So I would very much welcome those with a technical understanding of neural networks and or some of the more applied computational or otherwise aspects of neural networks.
133210	145880	A	0.9694744944572449	It would be awesome to have them on for the dot one and the dot two, because it was not an area I was familiar with and so hope that I can hear more from the authors in our coming weeks and others.
146250	158394	A	0.6400253176689148	I'm Daniel, I'm a researcher in California, and this will just be a solo dot zero, which I guess hasn't happened in a while in the making of this.
158512	175790	A	0.8093351125717163	Here are some of the generative art prompts area 51 active Inference area 51 neural Network area 50 active coherence Lab ant area 51 active inference neural network just some interesting images coming out of stable diffusion.
176450	183362	A	0.524611234664917	So as to some big questions that the paper is addressing and that one might be interested in to come to the paper.
183496	194230	A	0.8652341961860657	How can artificial neural networks be understood as generic optimization processes and what is the correspondence between neural dynamics and Modern statistical inference methods?
195370	214086	A	0.7968927025794983	Other big questions are about the history and next steps of the enmeshment of natural intelligence, Egyptian neuroscience and artificial intelligence, as well as of course, whether to even play into this kind of distinction at all and have different integrated intelligence frameworks.
214278	229402	A	0.6945922374725342	And one paper where any of the authors or anyone who has kind of resonated with this work is recent by Zador at all 2,022 towards the next generative artificial Intelligence catalyzing the neuro AI revolution.
229546	231658	A	0.6156874299049377	And so this is a bunch of authors.
231754	242634	A	0.7672467827796936	And so it's interesting just to quote in terms of what some areas of discourse are saying right now, which is neuroscience has long been an important driver of progress in artificial intelligence AI.
242702	245586	A	0.5084959268569946	We propose that to accelerate progress in AI.
245698	249474	A	0.5301201343536377	We must invest in fundamental research in neuro AI.
249602	254902	A	0.8301710486412048	So that's one way to read some of the developments that are happening in the paper.
254956	259878	A	0.800157904624939	We'll discuss what does it mean to be particular but generic?
259974	263530	A	0.8024658560752869	That's a phrase used in the paper, so maybe that's kind of a jumping off point.
263680	274190	A	0.8747310638427734	And then how can active inference help us understand the past, present and future here of the interface with neural networks, statistics and neural AI?
279030	280450	A	0.768013596534729	Here's the abstract.
282310	295570	A	0.8508409857749939	This work considers a class of canonical neural networks comprising rate coding models wherein neural activity and plasticity minimize a common cost function and plasticity is modulated with a certain delay.
295730	302722	A	0.6719009280204773	We show that such neural networks implicitly perform active coherence and learning to minimize the risk associated with culture outcomes.
302866	319360	A	0.6923595666885376	Mathematical analyses demonstrate that this biological optimization can be cast as maximization of model evidence or equivalently minimization of variational free energy under the well known form of a partially observed Markov decision process model.
319970	331666	A	0.702271044254303	This equivalence indicates that the delayed modulation of heavy and plasticity accompanied with adaptation of firing thresholds is the sufficient neuronal substrate to attain Bayesian optimal inference and control.
331848	337170	A	0.5965622067451477	We corroborated this proposition using numerical analyses of May's tasks.
337670	350680	A	0.7153168320655823	This theory offers a universal characterization of canonical neural networks in terms of Bayesian belief updating and provides insight into the neuronal mechanisms underlying planning and adaptive behavior control.
353290	356214	A	0.9029691815376282	Here is the roadmap I'll be driving.
356262	364140	A	0.8836246132850647	On the right side of the road, there's an introduction and a table with a glossary of different expressions used.
364830	377866	A	0.8786885738372803	Then there's the Results sections, which has first an overview of equivalence between neural networks and variational Bayesian active inference formulated using a postdiction of past decisions.
377978	381950	A	0.8610113263130188	Canonical neural networks perform active inference and numerical simulations.
382110	400978	A	0.8637199401855469	So they work on the interface between neural networks and variational Bayesian methods and start with a more theoretical and mathematical background and then eventually present some maize simulations that are in MATLAB.
401154	414726	A	0.872518002986908	Then there's a discussion, and then the methods section is following the discussion, and it has the subsections generative model variational free energy inference and learning, neural networks, simulations and data analysis.
414918	423230	A	0.7552385330200195	And I think that I have kept to the right color codes consistently from here on forward.
423380	437150	A	0.8604010343551636	The black quotes are the direct quotes from the paper, Bleu quotes are related to perception, orange for action, complete class theorems, and neural networks together in purple.
437310	450598	A	0.5581361651420593	And then red is commentary and then the highlighting for red is related to the variational methods, but it's kind of red ish okay.
450684	456678	A	0.9117870926856995	The papers canonical neural networks perform active inference by the authors listed previously.
456774	461100	A	0.9091154336929321	It's in Communications biology from 2,022.
461550	465542	A	0.7030980587005615	And the key aims of the paper are laid out well in the first paragraph.
465606	468074	A	0.7955107092857361	So that's in black and other colors.
468122	482820	A	0.8720242977142334	And here the red is just kind of getting into initial conversation with the paper and connecting a little bit more to some previous streams before we go more into the specifics of the paper.
483190	487090	A	0.8432808518409729	The sentient behavior of biological organisms is characterized by optimization.
487670	496370	A	0.8172364830970764	Biological organisms recognize the state of their environment by optimizing internal representations of the external environmental dynamics generating sensory inputs.
496450	499160	A	0.8319578766822815	So that's the sensory recognition model.
500010	507878	A	0.6015116572380066	In addition, they optimize their behavior for adaptation to the environment, thereby increasing their probability of survival and reproduction.
508054	519610	A	0.8699153065681458	So that is bringing the entire active and inactive control theory, formal theories of action, action selections, planning and planning, its inference.
519770	536690	A	0.8653427362442017	All of these action oriented pragmatic turn type ideas come into play when this action orange aspect is brought in and it is, must be, should be, et cetera, oriented towards survival and persistence.
537510	544790	A	0.5858762860298157	Otherwise we don't see that kind of thing for log over appropriate definitions for thing and log, et cetera.
545370	558726	A	0.8192217350006104	And this few sentences that the paper begins with summarizes a common theme in ActInf, which is that there's basically two pathways towards proficiency in the niche.
558918	565014	A	0.6752342581748962	There's changing the mind, which is the perceptual and learning and then there's changing the world through action.
565142	578830	A	0.8662593960762024	And that kind of integration of inference, cognitive inference, whether it's perceptual or learning or other and action as enacted is part of the active formulasm and shared with other areas.
579410	589330	A	0.8859146237373352	This biological self organization is typically formulated as the minimization of cost functions wherein a gradient descent on a cost function furnishes neurodynamics and synaptic plasticity.
589910	610410	A	0.7412950992584229	So they are working with a framework where the way that this perception action flow is trackable computationally either just for our current computers so that we can implement simulations and data fitting or whether more fundamentally like this is the computational context of action.
611390	619210	A	0.8319185376167297	They're suggesting there's a way to think of it in terms of a cost function minimization and also note like inclination maximization.
619370	624958	A	0.6320489645004272	In a way they're interchangeable because there's just sometimes negative signs that can flip them.
625124	639054	A	0.8542145490646362	So it's the same energy and fitness landscape that is being navigated whether you're minimizing to the bottom of the bowl and thinking of action prediction that way and inference or whether you're climbing to the top of the hill.
639102	643350	A	0.8106145858764648	Gradient descent, gradient ascent they're both kind of two sides of the same coin.
645850	647986	A	0.7574620842933655	Two fundamental issues remain to be established.
648018	665226	A	0.8584336042404175	Namely so this is what the papers saying they're filling the gap in literature the characterization of the dynamics of an arbitrary neural network as a generic optimization process and the correspondence between such neural dynamics and statistical inference found in applied mathematics and machine learning.
665408	682720	A	0.5949335694313049	The present work addresses these issues by demonstrating that a class of canonical neural networks of rate coding models is functioning as and thus universally characterized in terms of variational Bayesian inference under a particular but generic form of generative model.
685110	692398	A	0.6797472834587097	This is maybe the only slide that has resources from too far afield from paper.
692584	694760	A	0.8098936080932617	Well, almost a few more.
696010	697750	A	0.8166755437850952	It's just on neural networks.
698330	707462	A	0.5606604218482971	The search on a very common search tool resulted in five plus million results for what are neural networks?
707606	718350	A	0.9676679372787476	And the first one was 3 Bleu, one brown from 2,017, which is just a nice YouTube video as they very often make with these beautiful renditions.
718850	721390	A	0.9817573428153992	And it's a very great video and there's many, many others.
721540	734820	A	0.8905968070030212	A neural network is a network or circuit of biological neurons and that is variously purely computational and or biological map territory stuff.
735590	747590	A	0.9015821814537048	And they can be thought of as nodes and edges, which are the firing rates and the connections between the biological neurons being modeled as weights between nodes.
748970	754486	A	0.7127636671066284	A positive weight reflects an excitatory connection, while negative values mean inhibitory connections.
754598	760694	A	0.8526259064674377	And here is data coming in and ending up activating different neurons in this final layer.
760822	768298	A	0.897769570350647	So this is kind of doing inference in a neural network and then there's an action part.
768464	781566	A	0.5705379247665405	Okay, the paper says variational Bayesian inference offers a unified explanation for inference learning, prediction, decision making and the evolution of biological form, which can be considered over multiple timescales.
781598	789250	A	0.9018082618713379	So this returns to the earlier theme of like perception, action and persistence within it among generations.
789590	805126	A	0.5246310234069824	And the citations that are provided here for this are Friston Kilner Harrison 2,006 and Friston 2,010, both very classic active FEP papers.
805238	825870	A	0.6391748785972595	Just to show one figure from each here's from the first citation with the winged snowflake, where if the snowflake ends up being somewhere that's too warm, that's not able for it to maintain the structure, then it melts, melts into a dew, et cetera.
826210	833134	A	0.86890709400177	And it must be ActInf lab if in one way or another it's staying above that phased boundary.
833262	840850	A	0.8227144479751587	That's how it's statistically identified, it's how it's autogenetically identified, functionally identified.
842330	869840	A	0.7620953321456909	And then here is one of the kind of pathetic figures in the Friston 2,010 paper with a tree of many different areas to connect to, informalisms to represent as, including probabilistic, neural coding, Bayesian brain, optimal control and value learning.
870770	878240	A	0.5748725533485413	These three and others can be really seen ant play in this 2,022 paper.
881190	889970	A	0.8942505121231079	The kind of inference variational basic methods use rests upon a generative model that expresses a hypothesis about the generation of sensory input.
890310	897378	A	0.7816714644432068	Perception and behavior can then be read as optimizing the evidence for a generative model inherent in sensory exchanges for the environment.
897554	904650	A	0.8063252568244934	And that's the integration of perception and action within a single imperative in terms of if only computation.
905150	914060	A	0.8631386756896973	And that is described more on this slide, which one can pause and read, but the rest of the quotes are from the paper.
920650	937078	A	0.6143143773078918	One key formalism that I had no familiarity with before this paper and associated readings and conversations with align was the Complete Class Theorem.
937254	944334	A	0.9056965112686157	So it would be great for anyone who is familiar with Complete Class Theorem to help a little bit here.
944372	954794	A	0.9396626353263855	But here's some interesting things that I came across crucially from the picture as a corollary of the Complete Class Theorem citations 19 through 21.
954932	961890	A	0.8941370844841003	Any neural network minimizing a cost function can be viewed as performing variational Bayesian inference under some prior beliefs.
962630	975634	A	0.8911623358726501	Here are the citations 19 through 21, from 19 47 19 81 2,013, and also found some interesting resources.
975682	988106	A	0.7367103099822998	So quoting from this less wrong post linked here, Dutch book defines belief as willingness to bet and Money Pump defines preference as willingness to pay.
988288	996586	A	0.8983368873596191	This is in terms of the foundational arguments for a Bayesian Epistemological worldview.
996778	997662	A	0.49010729789733887	Hope that's correct.
997716	1013586	A	0.6750584244728088	Again, it'd be good to hear from anyone who knows more here, but in terms of different ways that one can consider the Bayesian proposition, which perhaps these are even better to use than referencing any person's last name.
1013688	1027830	A	0.5662041902542114	Because the interesting thing will be the different lenses that these different framings on Bayesian Probabilities are interpreted as.
1027980	1031370	A	0.7150134444236755	Just like what a Pvalue is interpreted as in the frequentist world.
1031440	1034730	A	0.8265073895454407	Kind of analogously like a Bayesian factor interpretation.
1035310	1041450	A	0.8575193285942078	So Dutch book defines belief as willingness to bet and Money Pump defines preference as willingness to pay.
1041600	1050960	A	0.5521813035011292	In doing so, both arguments put the justification of decision theory into hypothetical exploitation scenarios which are not quite the same as the actual decisions we face.
1051730	1060030	A	0.4936545789241791	If these were the best justifications for consequentialism we could muster, I would be somewhat dissatisfied, but would likely leave it alone.
1060190	1062382	A	0.6545965671539307	Fortunately, a better alternative exists.
1062446	1064210	A	0.8168529868125916	The complete Class theorem.
1066230	1090118	A	0.9135164618492126	So here's an image from that post possible world states conversation likelihood maps to the possible observations hashtag a matrix then decision making rule may be probabilistic action selection as inference a possible actions affordances.
1090294	1098270	A	0.8230137228965759	And here we commonly see the loop being closed from actions to world states like through the B matrix changing how the world changes through time.
1098420	1107826	A	0.8365001082420349	And here these are both going to be mapped to a loss function l a real valued score from taking an Anthony G.
1108008	1112290	A	0.8183008432388306	Chen the world turned out to be theta realized theta.
1113270	1115890	A	0.9208652377128601	So that's quite an interesting framing.
1117030	1119302	A	0.843587338924408	And there were some other useful posts online.
1119436	1130210	A	0.8432047963142395	And from this Zhat blog the argument boils down to if you agree with expected utility as your objective, then you have to be Bayesian.
1130370	1139226	A	0.5902326107025146	In a nutshell, a strategy is inadmissible if there exists another strategy that is as good in all situations and strictly better in at least one.
1139408	1148750	A	0.8666700124740601	If you want your strategy to be admissible, it should be equivalent to a Bayes estimator Complete Class Theorems.
1149650	1152122	A	0.8175968527793884	Only Bay's strategies are Admissible.
1152266	1154830	A	0.8043997287750244	And Admissible strategies are Bayes.
1156070	1167950	A	0.795825183391571	So there's probably a lot of interpretations of this, but it seems kind of related to optimal control or Bay's optimal inference, perhaps a little bit more keenly.
1168110	1173058	A	0.9427919387817383	So these are some next two slides were contributed by Ali.
1173154	1181942	A	0.8973879814147949	So if you or if anyone familiar in this area wants to come on and the discussion would be great, but Ali pointed me to this book.
1181996	1197280	A	0.8608332276344299	Fundamentals of Bayesian Epistemology by title bomb 2,022 table of contents shown here and some challenges and objections to Bayesian Epistemology are listed which can be read.
1198050	1223030	A	0.86487877368927	And then also there's some quite interesting logical structures which can be read here in terms of their premise, theorem and conclusion in the areas of arguments for Bayesianism being representation theorem argument for probabilism, the Dutch book argument for probabilism, and the gradational accuracy argument for probabilism.
1223850	1225720	A	0.9751617908477783	So pretty interesting.
1227690	1237270	A	0.7484925985336304	Back to the paper they wrote we have previously introduced a reverse engineering approach that identifies a class of biologically plausible cost functions for neural networks.
1237430	1251934	A	0.9200457334518433	Citation 22 Previous paper of Isomerra and Friston 20 20 the paper was reverse engineering neural networks to characterize their cost functions, the abstracts shown here.
1251972	1263902	A	0.8724172115325928	But this letter considers a class of biologically plausible cost functions for neural networks using generative models based on partially observable Markov decision processes.
1263966	1272834	A	0.7842491865158081	POMDP we show that neural activity and plasticity perform Bayesian inference and learning respectively by maximizing model evidence.
1272962	1281720	A	0.8299483060836792	So this is a precursor paper from 2,020 that is cited and foundational for the 2,022 paper.
1282970	1284860	A	0.920612096786499	Here are some figures from that paper.
1285310	1292570	A	0.8852053880691528	They have a comparisons among a Markov decision process scheme and a neural network.
1293090	1301550	A	0.9174285531044006	For example, a Markov decision process scheme expressed as a fourney factor graph based on the formulation in Friston.
1302210	1322230	A	0.914208173751831	So here is the Markov decision process as a fourni factor graph and on the right side is the neural network with the hidden states, sensory inputs and neural activity, and some figures and concordances.
1326300	1334872	A	0.8514506816864014	And they wrote in this context, the neural network can in principle be used as a dynamic causal model to estimate threshold, constants and implicit priors.
1335016	1344940	A	0.8310918211936951	This reverse engineering speaks to estimating the priors used by real neuronal systems under ideal Bayesian assumptions, sometimes referred to as metabasian inference.
1345100	1357844	A	0.8872225284576416	So they're laying out their research agenda and much of the work is going to reference this earlier paper and other work.
1358042	1369510	A	0.764369010925293	And then there's also some new integrations and especially the maze simulation in this paper and probably more so let's find out.
1371500	1383770	A	0.8961660265922546	Referring to the earlier paper, this foundational work identified a class of cost functions for single layer feedforward neural networks of rate coding models with a sigmoid or logistic activation function.
1384380	1397584	A	0.8502984046936035	We subsequently demonstrated that mathematical equivalents between the class of cost functions for such neural networks and variational free energy under a particular form of degenerative model, which is similar broadly to what the 22 paper dot.
1397622	1408100	A	0.8634265065193176	Two, this equivalence licenses variational Bayesian inference as a fundamental optimization process that underlies both the dynamics and function of such neural networks.
1410440	1420196	A	0.8836155533790588	However, it remains to be established whether the active inference is an apt explanation for any given neural network that actively exchanges with its environment.
1420388	1428840	A	0.8408437371253967	In this paper, we address this active or control aspect to complete the formal equivalents of neural network optimization and the free energy principle.
1429420	1436460	A	0.659123957157135	So this earlier work was not including action.
1436960	1460500	A	0.4978294372558594	And so this paper's key addition, as I understand it hopefully, is that they bring action more formally into the model and it'd be interesting to know what else is that change associated with, or what else happens or doesn't.
1463240	1480440	A	0.9068127274513245	Here's some more text about the approach that they're going to take, and many of these details are going to be addressed later on here's table One glossary of expressions.
1481280	1487870	A	0.8847972750663757	So these will also be broadly addressed later on.
1491070	1510660	A	0.7501222491264343	Maybe it's useful though just to read the first one a canonical neural network in this work, the canonical neural network is defined by differential equations of neural activity derived as a reduction of realistic neuron models through some approximations which give a network of rate encoding neurons with a sigmoid activation function.
1511350	1521910	A	0.8508860468864441	In particular, we consider networks comprising a middle layer that involves recurrent connections and the output layer that provides feedback responses to the environment.
1522730	1538460	A	0.899113655090332	So some category of neural network architectures or anatomies physiologies whatever with sensory, cognitive and action like features in an environment or a generative process.
1540190	1551582	A	0.8883463144302368	So the results section, they write an overview of equivalence between neural networks and variational base.
1551716	1556062	A	0.8845136165618896	First, we summarize the formal correspondence between neural networks and variational base.
1556196	1562750	A	0.9133626222610474	A biological agent is formulated here as an autonomous system comprising a network of rate coding neurons.
1562830	1573846	A	0.9029895067214966	Figure One a so here's a small figure one A we'll see it larger based upon the assumptions which will be brought up later on in a different fuller form.
1574028	1584698	A	0.9002545475959778	The update rule for the ith component of Phi, which is the internal states so the cognitive studies and the output layer y.
1584784	1607434	A	0.8640251755714417	So middle layer x and output layer y, these can be seen as the cognitive and the action generative aspects which are the autonomous states in contrast to the particular states of the active coherence entity which is the whole blanket, and the cognitive states so including the sensory states.
1607572	1613218	A	0.756096601486206	But the sensory states can't be directly controlled, however action can influence them.
1613304	1623640	A	0.8828500509262085	And so that's what closes the causal loop and that set of the particular states comprising the autonomous states.
1624410	1631080	A	0.8818950653076172	The update rule for the ith component of Phi is derived as the gradient descent on the cost function.
1631530	1639660	A	0.8908450603485107	So the change in that Phi sub I is proportional to a generative on the loss function.
1640030	1644214	A	0.8862465620040894	This determines the dynamics of neural networks including their activity and plasticity.
1644262	1654362	A	0.6444969177246094	So l common loss function o observations sensory states by internal states comprising the middle and output layer neural activity.
1654426	1662900	A	0.8591864705085754	That's the rate coding part and synaptic strengths w the parameterisation and other free parameters, including that that characterize L.
1663510	1666126	A	0.7919327616691589	Then there's the output layer activity.
1666238	1670210	A	0.7877088189125061	Y is determining the network's actions or decisions.
1670570	1674758	A	0.7431363463401794	Delta O x and Y.
1674844	1676802	A	0.8141238689422607	Y is the outputting action environment.
1676866	1685126	A	0.8675054907798767	Generative process hidden state, passing observations to the sensory, cognitive active layers of the neural network.
1685318	1693834	A	0.885983407497406	And that is analogous topologically to the variational Bayesian formulation in Figure One.
1693872	1694460	A	0.5460720658302307	B.
1694990	1701594	A	0.8617684841156006	So left side gradient descent on a neural network cost function L determines the dynamics of neural activity and plasticity.
1701722	1721058	A	0.806853711605072	Thus L is sufficient to characterize the neural network and then being shown next to on the right side variational free energy minimization allows an agent to self organize to encode the hidden states of the external milieu and to make decisions minimizing future risk.
1721234	1727814	A	0.8874627947807312	Here, variational free energy F is sufficient to characterize the inferences and behavior of the agent.
1728012	1742380	A	0.8717506527900696	So sentence structure parallelism, and these two schemes or approaches being linked and applied is a focus of this area.
1745410	1748606	A	0.7596801519393921	So neural networks are minimizing the cost function L.
1748708	1761970	A	0.9003320336341858	In contrast, variational Bayesian inference depicts a process of updating the prior distribution of external states P of theta to the corresponding posterior distribution q of theta based upon a sequence of observations.
1762630	1769810	A	0.8505015969276428	And we see other familiar terms from discussions on variational bays like minimization of surprise.
1770810	1775240	A	0.876166582107544	And there's some more model details shown here.
1775610	1794010	A	0.6523532867431641	A few points are about choosing the family of distributions that one is doing variational inference with, and that allows for the gradient update rules in that family of distinctions to be made simpler.
1794510	1798334	A	0.8341087102890015	For example, choosing a linear regression with an L two norm.
1798532	1804014	A	0.7763962149620056	At the very least, you can say that it has a simple decision rule for being fit.
1804132	1821490	A	0.5591850876808167	I'm sure there's like also counterarguments and other algorithms that are better and so on, but just to say that a simple decision rule in a known family of distributions can often be good enough as an approximation, if not more crucially.
1821570	1834102	A	0.8430930376052856	According to the Complete Class theorem from earlier, a dynamical system that minimizes its cost function can be viewed as performing Bayesian inference under some generative model and prior beliefs.
1834246	1846314	A	0.7940443754196167	The Complete Class theorem goes on to describe it ensures the presence of a generative model that formally corresponds to the above defined neural network characterized by L.
1846432	1853166	A	0.7487929463386536	Hence, this speaks to the equivalence between the class of neural network cost functions and variational free energy under such a generative model.
1853348	1871670	A	0.8165482878684998	Equation one loss function on the time series of observations comma parameters three lines is defined as f the free energy function on the same o through time comma parameterisation.
1872330	1887210	A	0.8895571827888489	So there's a parallel being shown slashdefined wherein the internal states of a network by encode or parameterize the post tier expectation theta.
1888670	1901050	A	0.8144688606262207	This mathematical equivalence means that an arbitrary neural network in the class under consideration is implicitly performing active inference through variational free energy minimization and more is written.
1901130	1920530	A	0.8806616067886353	But this is one of many statements that will be made corresponding to correspondences between neural network loss function, generative models, active free energy minimization, and associated formalisms.
1922810	1936970	A	0.7839052081108093	Note that being able to characterize the neural network in terms of maximizing model evidence lends it in explainability in the sense that internal neural network states and parameters encode Bayesian beliefs or expectations about the causes of observations.
1937390	1941370	A	0.7956428527832031	In other words, the generative models explains how outcomes were generated.
1941870	1948510	A	0.7792826294898987	However, the Complete Class theorem does not specify the form of a generative model for any given neural network.
1949970	1963262	A	0.9139094948768616	To address this issue in the remainder of the paper, we formulate active inference using a particular form of partially observable Markov decision processes POMDP models whose states take binary values.
1963326	1970290	A	0.8560797572135925	So this is one of several simplifications is one way to see it or areas for later generalization.
1972310	1982754	A	0.910870373249054	Figure Two in this section we define a generative model and ensuing variational free energy that corresponds to a class of canonical neural networks that will be considered in the subsequent section.
1982882	1989580	A	0.8722853660583496	The external milw is expressed as a discrete state space in the form of a POMDP figure two.
1990030	2005160	A	0.8486809134483337	So to make figure two larger, there's a lot to probably say about this figure.
2006250	2015930	A	0.8572303056716919	I'll just note that the caption is informative and some of the highlighted lines.
2016750	2036482	A	0.7802441716194153	It'll be awesome to have the author and other people who is familiar with some of the differences and symmetries between the, for example, bottom and top, above and below the observations, and also about the role of time and what these two risks are.
2036616	2038450	A	0.7636818289756775	What is fictive causality?
2040710	2047720	A	0.9262642860412598	Here's more details on that POMDP then equation two.
2048170	2053778	A	0.9086565971374512	This is in this section active inference formulated using a postdiction of past decisions.
2053874	2060650	A	0.49844831228256226	So if it was a prediction of future decisions, it's the opposite, a postdiction of past decisions.
2061070	2076990	A	0.900484561920166	Hence we define the generative model as follows PO delta s gamma theta, which is the model of observations decisions, observations decisions, hidden states risk and theta.
2079330	2087570	A	0.9272321462631226	Theta equals A, b and C constitutes the set of parameters and more details are provided.
2087990	2096666	A	0.9016766548156738	This is the familiar notation with some slight differences that will be described.
2096798	2110086	A	0.8821452856063843	And equation two reflects the factorizability and the dimensions and the kind of computational tractability expression.
2110278	2113580	A	0.8285759091377258	So that would be interesting to also learn about.
2114910	2121130	A	0.8285308480262756	Under what conditions can this joint distribution be factorized?
2121810	2146366	A	0.8685872554779053	Under what simplifications or constructions the agent is making decisions to minimize a risk function capital gamma that's on the bottom of figure two, active causality leading to this gamma coming from that gamma, equation three is shown.
2146558	2165146	A	0.7374266982078552	And to characterize the optimal decisions as minimizing expected risk in our POMDP model, we use effective mapping from the current risk gamma to past decisions that's that retrodictive active causality, although this is not the true causality in the real generative process that generates sensory data.
2165328	2172566	A	0.9078148603439331	Here we intend to model the manner that an agent subjectively evaluates its previous decisions after experiencing their consequences.
2172758	2181550	A	0.7900659441947937	This victim causality is expressed in the form of a categorical distribution, so it could be other families hypothetically.
2182050	2194334	A	0.7235158681869507	But this equation three is describing victim causality and this interesting sign indicates the elementwise division operator.
2194462	2203186	A	0.8709429502487183	Also note throughout the manuscript, the overly variable indicates one minus that variable, so gamma bar equals one minus gamma.
2203298	2213500	A	0.8321235179901123	Or it can be understood as the complement of a statistical probability probability of a happening and the probability of not a happening in that one way.
2216670	2221750	A	0.652907133102417	Importantly, the agent needs to keep selecting good decisions while avoiding bad decisions.
2221830	2242530	A	0.6682806611061096	To this end, equation three supposes that the agent learns from the failure of decisions by assuming that the bad decisions were sampled from the opposite of the optimal policy, mapping some more details and then by convention, active inference uses C to denote the prior preference.
2242950	2249650	A	0.8951682448387146	That's how we've seen the C variable in many models as preferences.
2249810	2257560	A	0.9143137335777283	Prior Preference this work uses C to denote a mapping to determine a decision depending on the previous state.
2257930	2261820	A	0.8143085837364197	Herein the prior preference is implicit in the risk function.
2262270	2268758	A	0.5750278234481812	Due to construction, C does not explicitly appear in the inference.
2268854	2279150	A	0.5507956147193909	Thus it is omitted in the following formulations so that's a key point about the notation of the variable C and something kind of maybe interesting to explore.
2280450	2290510	A	0.7524989247322083	Equation Four variational Bayesian inference refers to the process that optimizes the posterior belief q of theta based on the gain field approximation.
2290590	2304754	A	0.891894519329071	Q of theta is expressed as and here is the factorization representation of the q of theta variational and another notation.
2304802	2320858	A	0.9266350269317627	Note throughout the manuscript, bold case variables such as bold s subtau denote the posterior expectations of the corresponding italic case random variables and some more details about the model.
2320944	2334122	A	0.7561213970184326	For example, for simplicity, here we suppose that state indecision priors d and e are fixed, so one could imagine they don't have to be, but for simplicity they will be.
2334196	2357250	A	0.9069978594779968	Here, under the above defined generative model and posterior beliefs, the ensuing variational free energy is analytically expressed as follows equation Five this is a variational free energy F and recall equation one that it is being connected to juxtaposed with, et cetera.
2357410	2359240	A	0.5823739171028137	The loss function.
2360670	2369900	A	0.8914914131164551	The gradient descent on variational free energy updates the post tier beliefs about hidden states s decisions, delta and parameters data.
2370350	2385360	A	0.8224635124206543	The optimal post tier beliefs that minimize variational free energy are obtained as the fixed point of the implicit gradient descent, which ensures that change in F with respect to the change in hidden states through time equals zero.
2386050	2388158	A	0.8109680414199829	And some more definitions.
2388254	2389810	A	0.765465497970581	All of them are zero.
2389960	2392660	A	0.502510666847229	That 1 might be an O, but they're all zero.
2393430	2420330	A	0.7669424414634705	And this is saying the ball rolls to the bottom of the hill in this gradient descent, and when the rate of change is zero, then that is a fixed point, a tractorlike dynamic, and that can be used as a way to incrementally fit statistical models like the loss function is used to incrementally fit neural networks.
2422110	2438080	A	0.8946765661239624	To explicitly demonstrate the formal correspondence with the cost function for neural networks, consider in the next section we further transform the variational free energy as follows some Details Using these relationships, equation five is transformed into the form shown in Figure three.
2438450	2441970	A	0.9381192326545715	See the Methods section variational Free Energy for further details.
2442950	2448706	A	0.9014767408370972	In what follows, we demonstrate that the internal states of canonical neural networks encode posterior beliefs.
2448818	2462214	A	0.9131882786750793	Here's figure three on the top from the caption figure three is the mathematical equivalence between variational free energy and neural network cost functions depicted by one to 1 correspondence of their components.
2462342	2473406	A	0.9045334458351135	Top variational free energy transformed from equation five using the Bayes theorem and foreshadowing equation seven.
2473588	2480238	A	0.9070437550544739	Using this relationship, equation seven is transformed into the form presented at the bottom of the figure.
2480404	2501670	A	0.7607770562171936	So here's f variational free energy and L the neural network cost function and different elements as they're represented here with some resonances and concordance and beyond which we can explore, they're being shown to be equivalent.
2502090	2512970	A	0.8975925445556641	And it was in the conversation preparing for this dot zero with Dean, where we saw this as some chromosomes.
2518030	2527162	A	0.9179458022117615	In this section, canonical neural networks perform active Coherence in this section, we identified the neuronal substrates that correspond to components of the active imprint scheme defined above.
2527306	2531674	A	0.8888794779777527	We consider a class of two layer neural networks with recurrent connections in the middle layer.
2531722	2538770	A	0.8880192637443542	Figure one a those are those connections with loops recurrent in the middle layer.
2539590	2547350	A	0.9167072176933289	The modeling of the networks in this section, referred to as canonical neural networks, is based on the following three assumptions that reflect physiological knowledge.
2547770	2554322	A	0.8705312609672546	One gradient descent on a Costa function l determines the updates of neural activity and synaptic weights.
2554386	2565290	A	0.9124404788017273	Method Section neural Networks Neural Two Assumption 2 neural activity is updated by the weighted sum of inputs and its fixed point is expressed in a form of the sigmoid or logistic function.
2565360	2571210	A	0.8666408061981201	And assumption three a modulatory factor mediates synaptic plasticity in a post hoc manner.
2575890	2587780	A	0.8959198594093323	They write based upon assumption two, which is neural activity is updated by the weighted sum of inputs and its fixed point is expressed in the form of a sigmoid or logistic function.
2588710	2597350	A	0.9237398505210876	Based on assumption two, we formulate neural activity in the middle layer and output layer the autonomous states as follows.
2598810	2603750	A	0.8138167262077332	Equation six without loss of generality.
2605770	2611514	A	0.8757445216178894	Equation six can be cast as the gradient descent on cost function l such.
2611552	2616842	A	0.9065561294555664	A cost function can be identified by simply integrating the right hand side of equation six with respect to x and y.
2616896	2618566	A	0.8712018132209778	Consistent with previous treatments.
2618678	2648310	A	0.7562973499298096	Citations because neural activity and synaptic plasticity minimize the same cost function l, the derivatives of L must generate the modulated synaptic plasticity under these constraints, reflecting assumptions one through 3, a class of cost functions is identified as follows equation Seven loss function awesome to hear somebody read this directly.
2650730	2662940	A	0.9094744920730591	So there's a firing rate aspect that's related to neural firing in the short term more perceptual aspect of function.
2663310	2675770	A	0.765223503112793	And there's a slower neurotransmitter neuroglial factor mediated learning over perhaps a different time scale and with some different features.
2675930	2679258	A	0.8662579655647278	And they're being included as a joint model of inference.
2679434	2682990	A	0.8753693103790283	And here that is being connected to doing inference on action.
2684370	2695826	A	0.88530433177948	Synaptic Plasticity and Neural Networks so, synaptic plasticity rules conjugate to the above rate coding model can now be expressed as a gradient descent on the same cost function l according to assumption one.
2696008	2710860	A	0.5538212060928345	Equations 8 and nine showing that neural networks can integrate those modes of firing rate like and synaptomdulatory like.
2712830	2713686	A	0.737934410572052	Neural networks.
2713718	2724880	A	0.9086399674415588	Cost Functions and Variational Free Energy Based on the above considerations, we now establish the formal correspondence between the neural network cost function and variational free energy.
2726130	2728314	A	0.8657934665679932	Under the aforementioned three minimal assumptions.
2728362	2731502	A	0.8948028087615967	We identify the neural network cost function as equation seven.
2731636	2739090	A	0.911237359046936	Equation 7 can be transformed into the form shown in figure three bottomed, using sigmoid functions of synaptic strengths.
2739430	2749960	A	0.8934873938560486	So equation seven loss function transformed into the form shown in figure three bottom.
2763280	2774800	A	0.9148283004760742	Hence, this class of Costa functions for canonical neural networks is formally homologous to variational free energy under the particular form of the POMDP generative model defined in the previous section.
2775860	2789110	A	0.7360286712646484	We obtain this result based on analytic derivations without reference to the complete class theorem, thereby confirming the proposition of equation one loss function and free energy.
2789980	2796680	A	0.8817431330680847	This in turn suggests that any canonical neural network in this class is implicitly performing active inference.
2797900	2805416	A	0.8511730432510376	Table two summarizes the correspondence between the quantities of the neural network and their homologs in variational bays.
2805608	2811100	A	0.8805131912231445	So two, a great concordance table.
2811840	2814940	A	0.890670657157898	On the left side, neural network formation.
2815300	2818880	A	0.8226901888847351	On the right side, variational bays formulation.
2819460	2829220	A	0.8474634289741516	So just like in figure three, we had the two long lines.
2829880	2845770	A	0.9066431522369385	Then table two, we have rotated 90 degrees and the variables for different parts of these models are laid next to each other.
2848140	2856990	A	0.9103662371635437	So what papers of neural networks can we make active models for?
2857600	2863550	A	0.8473315834999084	Is it already done or is there just one script that needs to be done?
2864340	2896120	A	0.7708377838134766	And then conversely, what interesting, variational Bayesian models have interesting applications or some other value or information gain from being cast as neural networks or integrating neural networks into what had previously been only analytical variational Bayesian models as well as the empirical data fitting aspect which is related that's highlighted by the authors.
2897820	2908476	A	0.8335402011871338	So in summary, when a neural network minimizes the cost function with respect to its activity and plasticity, the network self organizes to furnish responses that minimize the risk implicit in the cost function.
2908658	2916624	A	0.8600267171859741	This biological optimization is identical to variational free energy minimization under a particular form of the POMDP model.
2916822	2928160	A	0.8054884672164917	Hence, this equivalence indicates that minimizing the expected risk through variational free energy minimization is an inherent property of canonical neural networks featuring delayed modulation of Hebbian plasticity.
2929160	2938500	A	0.8212283849716187	Okay, brief seconds to view some image memes and take a breath in a stretch.
2949140	2955748	A	0.78528892993927	On the left side, the top panel says every neural network is implicitly performing active inference question mark.
2955914	2957030	A	0.9799191951751709	That's awesome.
2958120	2965780	A	0.8057071566581726	In the middle image meme, one simply makes a neural network and it is implicitly performing active coherence.
2966200	2967750	A	0.748027503490448	Also question mark.
2968620	2976420	A	0.8629744648933411	And then in the right image meme, there are two pieces of paper neural network and implicit performance of active inference.
2976580	2980140	A	0.6756582856178284	Corporate needs you to find the differences between this picture and this picture.
2980960	2982764	A	0.7229545712471008	And here is the paper.
2982962	2984460	A	0.6874263286590576	They're the same picture.
2985840	3010950	A	0.6050469875335693	So the previous sections have successfully extended the variational bays meets inference neural network result from the 2,020 paper with an action loop and a loss function only on the autonomous states.
3011880	3021210	A	0.9008383750915527	So that was the conceptual and technical feature that this paper brought in.
3022300	3026680	A	0.9668511152267456	Again, it'll be awesome to hear the author describe it more and differently.
3027020	3040380	A	0.9027618765830994	And then in this part of the paper, they turn from that kind of analytical theoretical towards some numerical simulations in MATLAB.
3041380	3046540	A	0.855523943901062	Here we demonstrate the performance of canonical neural networks using may's tasks.
3046700	3061812	A	0.9013949632644653	As an example of a delayed reward task, the agent comprised the aforementioned canonical neural networks figure four a thus it implication performs active inference by minimizing variational free energy.
3061946	3080648	A	0.8714026212692261	So now some entity or agent is going to be constructed and numerically simulated to support some of the aspects of their model and point towards utility in other settings.
3080664	3115270	A	0.9141035676002502	So here's figure four simulation of neural networks solving maize tasks in part A there is the architecture of the agent sensory input layer O of T synaptic weights into the middle layer x internal states and the output layer y decision action with risk gamma of T.
3117580	3123240	A	0.8819132447242737	The sensation comes in a neural network then outputs a decision.
3124940	3143360	A	0.8792547583580017	There's some task that the entity must perform which is to move towards the goal from the start across this lateral maze.
3143940	3158500	A	0.5819875001907349	So one could imagine that if it were just a hallway with no maze features, simple strategies would be very overfit but effective like always move simply towards the goal.
3158840	3170148	A	0.6518373489379883	Whereas in more complex settings, which this is an example of where there's uncertainty as well as many local optima.
3170324	3198736	A	0.7359432578086853	So one has to sometimes take one or 2 or three or 4 or more steps or however many to get closer to the goal and sometimes may not know for example how long those backtracking situations are going to be and all these other complexities for which this may's example is symbolic of.
3198918	3213648	A	0.6946237683296204	So maybe there's some interesting mythos maze connections and computational and here's some performance measures on the maze task with the neural network entity.
3213744	3225268	A	0.4967135787010193	This way before training, the agent moved to a random direction in each step resulting in a failure to reach the goal position right end within the time limit.
3225364	3231984	A	0.7134814262390137	During training, the neural network updated synaptic strengths depending on its neural activity and ensuring outcomes, ie.
3232052	3232780	A	0.6600064635276794	Risk.
3233600	3238060	A	0.9107252955436707	This training comprised a cycle of action and learning phases.
3239040	3251212	A	0.67381751537323	This treatment renders neural activity and adaptive behaviors of the agent highly explainable and manipulable in terms of the appropriate prior beliefs implicit in firing thresholds for a given task or environment.
3251356	3258976	A	0.8474387526512146	In other words, these results suggest that firing thresholds are the neuronal substrates that encode state and decision priors as predicted.
3259008	3261990	A	0.7026659250259399	Mathematically big if true.
3264360	3294268	A	0.8068132996559143	Furthermore, when the updating of parameters is slow across these two now linked domain parameters of the variational Bayesian autonomous state inference and the neural network loss function parameters, when the updating of these parameters are slow in relation to the experimental observations, the parameters can be estimated through Bayesian inference based on empirically observed neuronal responses.
3294364	3311270	A	0.9279626607894897	C Method section Data Analysis for details using this approach, we estimated implicit prior E, which is encoded by PSI from sequences of neural activity generated from the synthetic neural networks used in the simulations reported in figure four.
3311640	3316968	A	0.8039944767951965	We confirmed that this estimator was a good approximation to the true e.
3317134	3319290	A	0.9747713208198547	So that's also pretty interesting.
3319820	3336590	A	0.5944847464561462	This is showing they don't just lay out this architecture and show that it's possible to fulfill this maze task with the best whatever.
3337120	3341660	A	0.6878021359443665	It's not a classification accuracy generative alone.
3342740	3362980	A	0.8846688866615295	They're describing that from empirically observed neuronal responses, which is to say the experimenter's observation the sequences of neural activity generated from the synthetic neural networks used in that figure numerically.
3363400	3368248	A	0.6251310110092163	So statistically, that estimator was a good approximation to the true e.
3368334	3372570	A	0.8829851746559143	Figure five a so here's figure five.
3374220	3380170	A	0.8459315896034241	Estimation of implicit priors enables the prediction of subsequent learning.
3381260	3392190	A	0.9473115801811218	So that's pretty interesting and will be great to hear what each of the axes are and what all the variables mean.
3394720	3408070	A	0.8124024271965027	With this setup in place, they did some numerical validation and talked a little bit more about fitting data from this simulation model.
3411160	3421892	A	0.8969393968582153	Here's the discussion action so the first paragraph of the discussion biological organisms formulate plans to minimize future risks.
3422036	3425832	A	0.6538805365562439	In this work, we captured this characteristic in biologically plausible terms.
3425886	3437356	A	0.6999239325523376	Under minimal assumptions, we derive simple differential equations that can be plausibly interpreted in terms of a neural network architecture that entails degrees of freedom with respect to certain free parameters, e.
3437378	3438780	A	0.7037909030914307	G firing threshold.
3439200	3444640	A	0.8679754137992859	These free parameters play the role of prior beliefs in variational Bayesian formulation.
3445060	3453212	A	0.8620089888572693	Thus, the accuracies of inferences and decisions depend upon prior beliefs implicit in neural networks.
3453356	3470840	A	0.6645917892456055	And here's some more stable diffusion ant neural network ant brain neural network so some more summarization of what they did based on the view of the brain as an agent that performs Bayesian coherence.
3471260	3494690	A	0.8360276818275452	Neuronal implementations of Bayesian belief updating have been proposed which enables neural networks to store and recall spiking sequences eight learn temporal dynamics and causal hierarchy nine extract hidden causes 10 solve maize tasks 11 and make plans to control robots 12 so citations eight through 12 listed here.
3496260	3501696	A	0.8953343033790588	In these approaches, the update rules are generally derived from Bayesian cost functions e.
3501718	3503330	A	0.7364435791969299	G variational free energy.
3503720	3514340	A	0.8544678092002869	However, the precise relationship between these update rules and the neural activity and plasticity of canonical neural networks has yet to be fully established.
3517400	3525560	A	0.8959416747093201	We identified a one to 1 correspondence between neural network architecture and a specific POMDP implicit in that network.
3526860	3539420	A	0.81976717710495	Equation two speaks to a unique POMDP model consistent with the neural network architecture defined in equation six, where their correspondences are summarized in table two and the figures.
3540400	3548800	A	0.7373680472373962	This means that our scheme can be used to identify the form of the POMDP given an observable circuit structure.
3549300	3555490	A	0.8932247161865234	Moreover, the free parameters that parameterize equation six can be estimated using equation 24.
3556340	3563590	A	0.5306278467178345	This means that the generative model and ensuring variational free energy can in principle be reconstructed from empirical data.
3564360	3573304	A	0.6436148285865784	This offers a formal characterization of implicit Bayesian models entailed by neural circuits, thereby enabling a prediction of subsequent learning.
3573502	3576810	A	0.7538933157920837	So what can be done with this?
3577660	3580730	A	0.8492955565452576	What is this new?
3581760	3583070	A	0.8728460073471069	What is new here?
3584160	3598560	A	0.9156678318977356	Does this second selection fully establish the precise relationship between these update rules and the neural activity and plasticity of canonical neural networks.
3603300	3611380	A	0.8418419361114502	Here is a discussion action on Hebbian plasticity, neurotransmitters and glia with a lot of citations listed.
3611720	3619104	A	0.8376809358596802	And here was just one interesting follow on discussion from the computational aspects.
3619152	3638060	A	0.8783154487609863	Neurocognitive and computational aspects of Hebbian plasticity is these modulations have been observed empirically with various neuromodulators and neurotransmitters such as Dopamine, Noradrenaline, muscarine, and GABA, as well as glial factors.
3638480	3656948	A	0.7369952201843262	So here's a picture by Alexandra Mikhailova Cultured Astrostites release signaling and growth factors that regulate proper neuronal development so Cool, Glial, Pick, Dopamine, and reinforcement learning.
3657114	3666630	A	0.8895633220672607	In particular, a delayed modulation of synaptic plasticity is well known with Dopamine neurons citations 35 through 37.
3667340	3670490	A	0.8992111682891846	Those citations are listed here.
3671740	3684140	A	0.8577004671096802	This speaks to a learning scheme that is conceptually distinct from standard reinforcement learning algorithms, such as the temporal difference learning with actorcritic models based on state action advantage function.
3684720	3705190	A	0.8927857875823975	Please see the previous work citation 50 for a detailed competition between active inference and reinforcement learning that is, Sajid, Ball, Par and Friston active inference demystified and compared from 2,021 and that's also active model stream number 2.1.
3706360	3718890	A	0.6433752179145813	We mathematically demonstrated that such plasticity enhances the association between the prepost mapping and the future value of the modulatory factor, where the latter is cast as a risk function.
3719420	3726388	A	0.7329216599464417	This means that postsynaptic neurons self organized to react in a manner that minimizes future risk.
3726564	3746530	A	0.8700220584869385	So the neural network had three layers it's the second and the third layer, not the initial sensory layer, but the second and the third layer, the cognitive and the active states, which are the autonomous states of the particular states.
3747140	3761460	A	0.820263683795929	So that's quite interesting the self organization of postsynaptic neurons to react in a manner that minimizes future risk.
3762760	3791020	A	0.7723307013511658	Crucially, this computation corresponds formally to variational Bayesian inference under a particular form of pom DP generative models, suggesting that the delayed modulation of Hebbian plasticity is a realization of active inference and regionally specific projections of neuromodulators may allow each brain region to optimize activity to minimize risk and leverage a hierarchical generative models implication in cortical and subcortical hierarchies.
3791760	3796860	A	0.893120288848877	This is reminiscent of theories of neuromodulation and metallarning developed previously.
3796940	3804290	A	0.6319335103034973	Citation 52 Doya 2,002 metallarning and Neuromodulation cool.
3805160	3814420	A	0.8806700706481934	Our work may be potentially useful when casting these theories in terms of generative models and variational free energy minimization.
3817340	3823044	A	0.8939552903175354	They then return the discussion to the complete Class theorem and neural networks.
3823092	3836940	A	0.8033404350280762	So the Complete Class Theorem same citations from before ensures that any neural network whose activity and plasticity minimize the same cost function can be cast as performing Bayesian inference.
3837440	3850880	A	0.5158688426017761	However, identifying the implicit generative model that underwrites any canonical neural network is a more delicate problem, because the theorem does not specify a form of the generative model for a given canonical neural network.
3852580	3853970	A	0.9425793886184692	Which is pretty interesting.
3854660	3862004	A	0.8459188938140869	Is that to say that the form of the generative model as modeled is different in what ways?
3862122	3875908	A	0.6853898167610168	From the given canonical neural network, the posterior beliefs are largely shaped by prior beliefs, making it challenging to identify the generative model by simply observing systemic dynamics.
3876084	3886510	A	0.9096411466598511	To this end, it is necessary to commit to a particular form of the generative model and elucidate how posterior beliefs are encoded or parameterisation by the neural network states.
3887120	3903196	A	0.510988712310791	This work addresses these issues by establishing a reverse engineering approach to identify a generative model implicit in a canonical neural network, thereby establishing one to 1 correspondences between their components.
3903388	3916980	A	0.8178579807281494	Remarkably, a network of rate coding models with sigmoid activation function formally corresponds to a class of POMDP models, which provide an analytically tractable example of the present equivalence.
3917340	3921480	A	0.9357373118400574	Please refer to the previous paper citation 22 for further discussion.
3921900	3937550	A	0.9006729125976562	So some of the analytical details, especially on the inferential side cognitive side, were captured in the earlier paper.
3938800	3965030	A	0.6956942677497864	This paper goes further into mapping the potentially necessary and sufficient aspects of the particular entity, which is to say the risk minimizing features of the autonomous states with respect to the entire particular states, including sensory states.
3966140	3981160	A	0.8382281064987183	Connecting that back of the envelope verbally expressible formulation to some complete class of neural networks.
3981320	3984732	A	0.8392965793609619	So what's outside of the complete class, and why?
3984866	3991580	A	0.8820847868919373	And then what groups within the class have special or different features?
3993280	4000988	A	0.7845884561538696	It is remarkable that the proposed equivalence can be leveraged to identify a generative model that an arbitrary neural network implicitly employs.
4001164	4007620	A	0.5819190740585327	This contrast with naive neural network models that address only the dynamics of neural activity and plasticity.
4009400	4018276	A	0.5392884016036987	If the generative model differs from the true generative process that generates the sensory input, inferences and decisions are biased I e.
4018298	4023956	A	0.8324276208877563	Suboptimal relative to Bay's optimal inferences and decisions based upon the right sort of beliefs.
4024068	4031016	A	0.7228316068649292	Prior Beliefs in general, the implicit priors may or may not be equal to the true priors.
4031128	4034780	A	0.5637460947036743	Thus, a generic neural network is typically suboptimal.
4035200	4040876	A	0.717869758605957	Nevertheless, these implicit priors can be optimized by updating free parameters e.
4040898	4049008	A	0.8338220715522766	G threshold factors, phi PSI based on the gradient descent on cost function l.
4049174	4058100	A	0.5663959383964539	By updating the free parameters, the network will eventually, in principle become Bayes optimal for any given task.
4058600	4076440	A	0.8101006746292114	In essence, when the cost function is minimized with respect to neural activity, synaptic strengths, and any other constants that characterize the cost function, the cost function becomes equivalent to variational free energy with the optimal prior beliefs.
4080900	4111220	A	0.8346185088157654	So the cost function for the neural network activity and synaptic strengths underlying the loss function are equivalent to the kind of gradient descent enabled variational free energy minimization under the Bay's optimality scenario from a risk perspective.
4112200	4124540	A	0.7340313792228699	Simultaneously, the expected risk is minimized because variational free energy is minimized only when the precision of the risk gamma is maximized.
4125520	4129020	A	0.9170533418655396	See method section Generative Models for further details.
4130320	4131310	A	0.9324204325675964	Very interesting.
4133780	4141788	A	0.8652215003967285	They then say the class of neural networks we consider can be viewed as a class of reservoir networks.
4141964	4166920	A	0.5627239942550659	Citation 54 citation 55 here, the proposed equivalents could render such reservoir networks explainable and may provide the optimal plasticity rules for these networks to minimize future risk by using the formal analogy to variational free energy minimization under the particular form of POMDP models.
4167340	4176030	A	0.6038410663604736	A clear interpretation of reservoir networks remains an important open issue in computational neuroscience and machine learning.
4178160	4193200	A	0.8816992044448853	So from Wikipedia reservoir computing is a framework for computation derived from recurrent neural network theory that maps input signals into higher dimension computational spaces through the dynamics of a fixed nonlinear system called a reservoir.
4194180	4204500	A	0.8889807462692261	After the input signal is fed into the reservoir, which is treated as a black box, a simple readout mechanism is trained to read the state of the reservoir and map it to the desired output.
4205400	4207960	A	0.8064985871315002	Then there are two key benefits of this approach.
4208380	4215640	A	0.7804654836654663	The first key benefit of this framework is that training is performed only at the readout stage as the reservoir dynamics are fixed.
4216700	4227230	A	0.5485790371894836	The second is that the computational power of naturally available systems, both classical and quantum mechanical, can be used to reduce the effective computational cost.
4229920	4242740	A	0.8074657320976257	Here's some stable diffusion reservoir computing, active inference, neural network so this would be interesting to discuss.
4242810	4253640	A	0.585658073425293	And I remember some active institute participants who are specifically interested empirical analyses and hypotheses.
4254620	4266300	A	0.8550271391868591	They write the equivalence between neural network dynamics and gradient flows on variational free energy is empirically testable using electrophysiological recordings or functional imaging of brain activity.
4267200	4286960	A	0.7696399688720703	So then another summarization crucially the proposed equivalence guarantees that an arbitrary neural network that minimizes its cost function, possibly implemented in biological organisms or neuromorphic hardware, can be cast as performing variational Bayesian inference.
4287120	4303850	A	0.8444582223892212	So to state it a few more times in the final paragraph, in summary, a class of biologically plausible cost functions for canonical neural networks can be cast as variational free energy.
4305820	4310840	A	0.8823339343070984	Formal correspondences exist between priors posteriors and cost functions.
4311000	4317500	A	0.6838123202323914	This means that canonical neural networks that optimize their cost functions implicitly perform active inference.
4318000	4325890	A	0.5097856521606445	This approach enables identification of the implicit generative model and reconstruction of variational free energy that neural networks employ.
4326740	4336740	A	0.7296141386032104	This means that in principle, neural activity, behavior and learning through plasticity can be predicted under Bayes optimality assumptions.
4341400	4343392	A	0.8468515276908875	There's a code availability statement.
4343456	4350680	A	0.523932933807373	The MATLAB scripts are available at GitHub in the repo of the first author.
4351020	4371100	A	0.9503592252731323	And it would be awesome for the author or anyone to bring this working MATLAB script up and see if we could do some realtime active inference.
4372260	4377840	A	0.9091408252716064	Then, as mentioned earlier, from the roadmap the methods are following the discussion.
4379380	4388320	A	0.6868270635604858	I'll just show the equations but not go into any details because there is not time nor familiarity.
4388480	4398472	A	0.9777517914772034	So those who have more of one or the other would be welcome to fill in some dots because this is a really awesome and important paper.
4398606	4414030	A	0.6649376749992371	So I hope that it can be interpreted and critiqued and elaborated on and so on by those with familiarity in both sides of that free energy loss function.
4416240	4423036	A	0.8456259965896606	Equation one generative model section many details are provided.
4423148	4424716	A	0.8422915935516357	Equation 10 is shown.
4424828	4428000	A	0.8593125343322754	It's a larger unpacking of the generative models.
4429540	4443296	A	0.8736547231674194	Section variational free energy many details are provided equation 11, 12, 13, 14 and 15 section inference and learning details are provided.
4443408	4446340	A	0.8575150370597839	Equations 16, 17, 18.
4448760	4455576	A	0.9263204336166382	Then section on neural networks so there's just some interesting writing here, so I wanted to highlight that.
4455758	4465964	A	0.8910611867904663	In this section we elaborate the one to 1 correspondences between components of the canonical neural networks and variational bays via an analytically tractable model.
4466082	4471790	A	0.8934670090675354	So that's the figure three that we've been returning to.
4473680	4482000	A	0.5460869669914246	Neurons respond quickly to a continuum stimulus stream with a timescale faster than typical changes in sensory input.
4482420	4503092	A	0.6703118085861206	For instance, a peak of spiking neurons in the visual cortex of V one appears within 50 and 80 milliseconds after a visual stimulation citation 62, 63, which is substantially faster than the temporal correlation timescale of natural image sequences about 500 milliseconds.
4503156	4505130	A	0.8121695518493652	Citation 64 65.
4505500	4507530	A	0.9759477972984314	So that's pretty interesting.
4509120	4514220	A	0.878200888633728	What is the temporal auto correlation timescale of natural sequences?
4516880	4527410	A	0.8930280208587646	What time scale do neural firing and neuroplasticity et cetera processes actually occur at?
4528500	4539110	A	0.8390315175056458	And when might some type of function at a given time scale be understood to be function or not?
4541480	4559320	A	0.7216174602508545	Thus, in other words, downstream of the fact that neurons respond quickly at a time scale faster than typical changes in sensory input, we consider the case where the neural activity converges to a fixed point given a sensory stimulus.
4560060	4566910	A	0.883933424949646	We note that the present equivalence is derived from the differential equations equation six, but not from its fixed point.
4567280	4588660	A	0.737267017364502	Thus, the equivalence holds true irrespective of the time constant of neurons to rephrase neural networks with a large time constant formally correspond to Bayesian belief updating with a large time constant, which implies an insufficient coverage of the posterior beliefs.
4590440	4614940	A	0.8199469447135925	Pretty interesting related to learning rates and Bayesian updating rates, and all of the nooks and crannies of Bayesian coherence and the challenges associated with dynamics, uncertain, rugged fitness and free energy landscapes.
4616560	4624892	A	0.8175780177116394	These optimization challenges, which are addressed differently methodologically, culturally, et cetera.
4625036	4634790	A	0.8155000805854797	In the variational Bayesian and in the neural cases, they have to deal with time.
4635320	4662380	A	0.5880199670791626	And so all of those different nooks and crannies mentioned, like catastrophic learning, catastrophic forgetting, simply memory, anticipation, attention, local maxima, choosing when to play all these higher order questions are connected here.
4663950	4670060	A	0.6752846837043762	Does that make it what kind of a problem space now or just what kind of space?
4670590	4682510	A	0.9174864292144775	Pretty interesting and equation 19, 20, 21, 22, 23 they have some more details on the simulation.
4683890	4691070	A	0.887486457824707	Maybe we could see the simulation go and in the last section data analysis.
4691230	4707510	A	0.8078944683074951	So this is kind of returning to that point about the time constants in Bayesian and neural network systems when the belief updating of implicit priors D and E is slow in correlation to experimental observations.
4708170	4721542	A	0.8698952794075012	D and E, which are encoded by Phi and PSI, can be viewed as being fixed over a short period of time as an analogy to homeostatic plasticity over longer time scales.
4721606	4750050	A	0.6571395397186279	66 Homeostatic plasticity in the developing nervous system 2,004 very interesting in light of our recent discussions on allostasis and other topics, Thus, fi and PSI can be statistically estimated by a conventional Bayesian inference or maximum likelihood estimation given a flat prior based on empirically observed neuronal responses.
4750210	4765020	A	0.6466325521469116	In this case, the estimators of phi and PSI are obtained as follows nice equation number 24 mentioned earlier, so that will be definitely one to look into more.
4767950	4775200	A	0.945451557636261	Well, I hope you found this a useful and interesting dot zero.
4776690	4781338	A	0.9602587223052979	I'm looking forward to the discussion with the author.
4781434	4807910	A	0.8613206148147583	And again, any other institute participants or those with knowledge or strong feelings to express about neural networks, active inference, applied active inference, computational modeling of perception, cognition and action, neural networks in the wild, AI, ethics, all these different areas.
4808250	4816200	A	0.9155787229537964	Can hopefully have a nice discussion in 51.1 and 0 2.
4816810	4819210	A	0.8338732123374939	That'll be the last paper.
4819280	4822780	A	0.858599841594696	Streams for 2,022.
4823250	4836580	A	0.7480846643447876	There will still be a few guest streams upcoming, so those discussions will close the paper focused, prepared Livestream number 2,022.
4837030	4850520	A	0.681097686290741	And yeah, if you want to be more involved with live streams whenever you're listening to this, join or recommend someone to join or help in any number of other ways.
4851770	4855734	A	0.9727694392204285	Just listening and learning is awesome.
4855932	4884800	A	0.962790310382843	And we also really look forward to those who want to help make some of these connections that are agent and sometimes exposed in these papers and conversations, and with a few motivated people who want to connect, for example, to the neural network communities and those who can facilitate discussions on these topics, that would be awesome.
4885810	4896126	A	0.834583044052124	Just using my final thoughts on this zero, because it's always great to have others also join in the preparation for the dot zero.
4896308	4901986	A	0.762317419052124	So just want to add that note on this rare solo stream.
4902098	4907926	A	0.9749186038970947	So thanks again, looking forward to talking or seeing you later.
4908028	4908290	A	0.5137447118759155	Bye.
