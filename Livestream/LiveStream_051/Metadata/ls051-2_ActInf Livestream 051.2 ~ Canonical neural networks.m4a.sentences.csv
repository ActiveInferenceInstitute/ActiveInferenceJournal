start	end	sentNum	speaker	confidence	text
32290	35054	1	A	0.11085	Subscribe hello and welcome everyone.
35252	42480	2	A	0.99992	This is ActInf Livestream, number 51.28, November 9, 2022.
43250	45978	3	A	0.98553	Welcome to the active inference institute.
46154	53498	4	A	0.85978	We're a participatory online institute that is communicating, learning, and practicing applied active inference.
53674	60520	5	A	0.73626	This is a recorded and an archived live stream, so please provide us feedback so we can improve our work.
60890	67830	6	A	0.99987	All backgrounds and perspectives are welcome, and we'll be following video etiquette for live streams.
68970	76090	7	A	0.99988	Head over to activemfronts.org to learn more about participating in different institute projects.
77070	83230	8	A	0.99641	All right, well, we're in active states number 51.2.
83380	86558	9	A	0.55572	We're in our third discussion on the paper.
86644	89930	10	A	0.99564	Canonical neural networks perform active inference.
90010	91920	11	A	0.99997	From 2022.
92290	98110	12	A	0.99999	We had a dot zero video with some background and context and overview.
98270	109634	13	A	1.0	And then last week in 51.1, we had a great discussion, went over many interesting details of the paper and related topics.
109762	121820	14	A	0.77437	So today we're going to jump in, cover some empirical details, some implications, connect some more dots, maybe look at some code.
122590	126570	15	A	1.0	And thanks again to Kuya for joining these discussions.
127710	158206	16	A	0.99947	I'm Daniel, I'm a researcher in California and thought a lot over the last week about what this kind of neural network POMDP synthesis or translation really means and just want to learn more about what fundamentals or foundational aspects of these different kinds of models enable that synthesis or translation.
158398	166790	17	A	1.0	And then again what that means for areas where one or the other kind of model is already in use.
166940	181290	18	A	0.83719	So thanks again for joining and I'll pass it to you if you want to say hi or give any other a second introduction.
182990	188750	19	B	0.61	Oh, yeah, I'm takirisomera in, lieutenant brain science institute, japan.
189330	199760	20	B	0.86274	So I look forward to discuss another different aspects of this work.
203350	219240	21	A	0.99985	Well, let's just remind ourselves of the fundamental parallel being made in the paper and then we'll get to these two questions about kind of the two directions that things can go.
220090	230614	22	A	1.0	One representation is in equation one with loss function of a neural network and the free energy on a POMDP.
230742	242746	23	A	1.0	And that's also seen visually in figure one, with a neural network being drawn a concordance against the variational bays of the action perception loop.
242858	246830	24	A	0.99233	So maybe just let's begin by restating.
247170	256980	25	A	1.0	What is this parallel that is in equation one and figure one and how was it reached in this paper?
259430	298750	26	B	0.88598	So basically idea here is that we derived to characterize the dynamics and plasticity of canonical neural network in terms of Bayesian inference, because arbitrary dynamics of neural network is interruptible in the sense that we don't know what is the function underlying such a dynamics and what is the coherence of the self organization or prostitution.
300230	314558	27	B	0.70928	So once we translate that dynamics in terms of Beijing ants, we can align quantities in Beijing parents for any biological quantities.
314734	324158	28	B	0.47736	So which enables us to lend the experiment ambiguity to the neural network dynamics and architecture.
324354	326730	29	B	0.95334	So that's a basic idea.
326880	353680	30	B	1.0	And what we have done in this paper is that we consider a biological plausible cost function for this particular canonical neural network and show the equivalence between that cost function and the variation free energy and the particular partially observable process model.
357990	358834	31	A	0.99972	Awesome.
359032	368518	32	A	0.9977	So let's look ant the parallel between the cost function for neural networks and the variational free energy.
368684	373218	33	A	0.99503	So one representation of that was in figure three.
373404	385660	34	A	0.99712	So maybe could you just describe what is the structure of the variational free energy expression and what is the structure of the loss function?
387090	402660	35	B	0.62691	Okay, so there is a clear parallel between the functional structure or those components in variation and free energy and the component in neural network cost function.
403110	420162	36	B	0.98827	So let's say the first time in F correspond to the correspond to the expectation about hidden state s is the hidden states posterior period.
420226	446670	37	B	0.92828	So that part basically indicates the free energy with respect to the hidden states and the second part correspond to the free energy about the decision posterior there indicates the posterior belief about agent decision or action.
448470	481530	38	B	0.9	And now in terms of the correspondence between the free energy and neural network function here the first time in the neural network function correspond to middle rear neuroptivity which has recurrent connection and receive sensory input from sensory layer and then project the output to the output layer.
482350	494750	39	B	0.99	And the second time correspond to output Dayan which receive signals from metal Dayan and send the feedback response to the environment.
505200	523460	40	A	0.99692	So both of these expressions have the first term being more like a cognitive perceptual sensory learning term and the second term is more like a control theory action selection.
523880	535450	41	A	0.94	And how did you see this analogy or concordance because it looks like a zipper, like everything is totally lined up.
538330	549590	42	B	0.66313	Well, this graph itself showed a clear correspondence.
551070	563566	43	B	0.99995	Now we are considering a particular form of pound DP in which each element of hidden state takes either zero or one.
563748	575150	44	B	0.99966	But there are many states so it is expressed in the form of parameterisation.
575830	600794	45	B	0.94847	So now we consider that in terms of the s is posterior part of borders correspond to the expectation about each element of s taking one and the lower part of the border s correspond to the expectation about s taking zero.
600912	620160	46	B	0.99922	So it is Brock vector about the expectation post Brea expectation and this s nicely correspond to the block vector shown in the bottom up this figure.
621010	648810	47	B	0.99571	It is a vector of x and it is a vector of x and by x and here by X indicate one minus x in the element y sense which is exactly correspond to broke vector of S expectation.
650510	675874	48	B	0.5047	This correspondence also observed in the second term here log S correspond to log x and also log A correspond to the broke matrix of W log W.
676072	689640	49	B	0.50216	Here W hat indicates the sigmoidal function of W and its bar means sigmaidal function of W.
690330	705446	50	B	0.89789	So actually because we now consider hidden state and boundary conversation it's likelihood mapping.
705638	718720	51	B	0.49818	Likelihood mapping from hidden states to observation is expressed as block matrix which is exactly correspond to block matrix shown in the bottom of this figure.
725390	726042	52	B	0.89521	Like this.
726096	735390	53	B	0.99776	For every tab we have the exact correspondence between the upper expression and the lower expression.
737970	747630	54	B	0.60377	So that's why we can say that this is a natural mapping from neural network correlation to computational vision formation.
751970	759010	55	B	0.69833	It speaks to a sort of identity between those two different expressions.
760150	774870	56	B	0.71725	So although 1 may be able to consider another mapping from neural network to Beijing infrastructure, this is a sort of just simplest mapping.
777150	786146	57	A	0.96953	So how would it look different if it were three states categorical distribution or a continuous distribution?
786278	788800	58	A	0.99557	What aspects would change?
789650	792382	59	B	0.99994	Thank you for asking that.
792436	813314	60	B	0.58001	So that's in some sense outside of this paper because only when we consider a binary hidden states, this analogy is established nicely.
813442	833980	61	B	0.99736	Otherwise we need to consider some attention because consider that each neuron encode the probability or expectation of some value taking one.
834430	849770	62	B	0.99853	Then the probability or expectation of taking zero can be simply computed by computing one minus neural activity.
849850	860050	63	B	0.98397	So actually activity which is a single dimensional variable is sufficient to express the expectation.
860970	871430	64	B	0.61386	But once we consider the three state hidden states program so this doesn't work.
871500	876694	65	B	0.99008	So we need to consider at least two variables.
876822	886300	66	B	0.70868	But its correlation to neural network expression is not very clear in general.
892130	909730	67	A	0.95562	That's very interesting why it would be so strong of a concordance in a binary case but immediately unclear for other distributions.
910870	940160	68	B	0.62423	Yeah, generative for pond DP expression we consider the Ronen photo expression vector expression which means that we normalize the value in the sense that the sum summation of all or variable to be one.
941730	947338	69	B	0.99888	Maybe there is some neural neural subscription that achieve that normalization.
947514	961166	70	B	0.9989	But for classic type of neural network like canonical neural network consider in this paper what is that neuronal?
961198	964210	71	B	0.25886	Savage street is not very clear.
964360	973670	72	B	0.62827	So that's why we selected the boundary case because it's simple and have a clear analogy.
974750	988670	73	A	0.82123	So what does it mean for an artificial or for a biological neuron to have activity dynamics or activity context?
989650	998750	74	A	0.99998	That justifies it being described as playing like a belief role in a Bayesian setting.
1001800	1005664	75	A	0.9974	Higher firing means more belief, higher firing means lower belief.
1005712	1011670	76	A	0.9963	Like what does it really mean to have a connection between activity dynamics and belief states?
1012300	1013144	77	B	0.94	I see.
1013262	1022932	78	B	0.9996	So if you assign a mapping, a particular mapping, then its meaning is also determined.
1023076	1036670	79	B	0.99997	In this case, we assign that neuro activity correspond to the posterior expectation about an element of hidden state taking one.
1037040	1046130	80	B	0.99935	So once we define this mapping, then higher neuropetivity indicate the higher probability of taking one.
1052540	1065710	81	A	0.98295	So neural activity is the probability neural activity is on the x axis and the y axis of the sigmoid function is the probability of taking one.
1067440	1074800	82	B	0.61364	Well, neural activity encodes the expectation.
1075220	1080870	83	B	0.99862	So activity is sigmoidal function of something itself.
1088570	1097740	84	B	0.60026	This is because once we see a fixed point of neuroptivity equation which is derived from this cost function.
1098110	1100538	85	B	0.99813	It has a form of sigmaidal function.
1100624	1104140	86	B	0.98928	So x equals sigmaidar function of grab drive.
1104590	1121600	87	B	0.97514	So this form is exactly correspond to a softmax operation softomax function of something which is seen in the solution of posterior expectation that there is.
1126570	1136390	88	A	0.65085	So that's what the neural activity encodes and what is the Bayesian interpretation or the update rules on the plasticity.
1137870	1142346	89	B	0.57343	Okay, that's another important point.
1142528	1167570	90	B	0.97362	So in terms of posture of parameters so in the case of Beijing Coherence, we consider update about deleted parameterisation of a matrix and B matrix which is usually expressed by the small case variable.
1168630	1215810	91	B	0.73	And its meaning is that if we compute the partial derivative of partial derivative of F with respect to small a, then its solution, its fixed point solution looks like out of product of Sno which is also known as Hebbian product because it has analogy to update through depending on the neuron activity and post synaptic neuron activity.
1216230	1264990	92	B	0.99	And according to this format equivalent, we can see again such and analogy in a formal sense here if we compute the partial derivative of neural networks function with respect to W, then we can formally derive the behavior prosthesis which depends on the activity of pre on post synaptic neuroptivity.
1268500	1277110	93	A	0.99661	Okay, so Hebbian plasticity often described as neurons that fired together, wired together.
1277720	1289110	94	A	0.99954	Here you're discussing it in terms of a matrix operation on the POMDP side between observables and hidden states.
1290060	1304590	95	A	0.93436	So there's a Hebian plasticity happening between the perceptual layer and the cognitive layer, right?
1306000	1325200	96	A	1.0	The first half of the neural network is trained according to Hebbian plasticity rules that optimize the A in terms of the perceptual and learning like relationship between hidden states and observables.
1326600	1333140	97	A	0.97	And then the second half of the neural network has a slightly different structure.
1333960	1350440	98	A	0.99659	It is optimizing based upon retroactive reanalysis of consequences of action according to the fictive causality construction.
1353440	1365728	99	B	0.98975	So actually in this figure b, upper layer correspond to environment and the lower part correspond to agent.
1365814	1369410	100	B	0.99804	So this structure corresponds to figure eight.
1371140	1374732	101	B	0.63782	This correspond to a simpler version of palm DP.
1374796	1382816	102	B	0.99724	So for Bull version of palm DP, its corresponding neural network is showing.
1383008	1392340	103	B	0.99431	Figure four of this paper may start.
1392490	1393430	104	B	0.49375	There we go.
1393740	1396948	105	B	0.98839	This is the neural network architecture.
1397124	1414500	106	B	0.79919	All right, so as you said, there is a network connection from sensory layer to coordinating layer which is expressed by W here.
1414570	1426740	107	B	0.98	And the recurrent connection which correspond to state cognition matrix is expressed by K matrix which is recurrent assignment connectivity.
1426820	1449330	108	B	0.52	And as you say, the action generative through retrospective, reward or risk evolution is done by output trailer through the synaptic connectivity expressed as V in this figure.
1451220	1461270	109	A	0.97358	So V is the synaptic connectivity between cognitive states in the middle layer and the action selection states in Y.
1461960	1465524	110	A	0.9	And so in that way V is exactly analogous to W.
1465722	1472132	111	A	0.53393	But why and how does gamma come into play only in this second layer?
1472196	1476760	112	A	0.97	I mean, why not have gamma one in the first layer, gamma two in the second layer.
1479280	1492148	113	B	0.97224	Generally speaking, it is possible to modulate plasticity in first layer using another modulator gamma.
1492264	1498640	114	B	0.94774	But for complexity we focus only on neuromodulation in the output layer.
1499380	1543280	115	B	0.52267	Analogy is that for example, as you said, the first layer compute more perceptual things so perception of external world and instead on the other hand middle second layer which is mapping from cognitive layer to action layer perform the optimization of its own action.
1543620	1559460	116	B	0.9388	So for example, in the story atom in the brain, action selection is optimized by moderation of dopaminersic input.
1559880	1581508	117	B	0.99787	So usually that sacred receives signal from canonical neuroscience and sends signal to another neuronal nucleus in meat brain.
1581684	1593068	118	B	0.99987	But the point here is that neuron in storiatum encodes some decision, for example goal or no goal.
1593164	1596400	119	B	0.99467	So such a decision is encoded.
1596900	1623044	120	B	0.99363	So now we consider analogy between pond EP expression in the base information and neuroscience in the brain that optimize action group some sort of conversation by another factor.
1623172	1626040	121	B	0.99581	Here that factor correspond to gamma.
1626780	1645340	122	B	0.9942	Andy Clark gamma gamma has a variety of function, but in this paper we focus only on the moderation of activity.
1646560	1672276	123	B	0.9486	So here the heavy and prostitution is not determined by only post relationship but determined by three factors relationship in the sense that the prostitute is updated by the product of gamma and pre and postsynaptic activity.
1672388	1677480	124	B	0.80211	So there are three times in one prosthesis.
1678140	1682600	125	B	0.79967	This is why this gamma can modulate prosticity.
1686290	1692570	126	A	0.99916	So how would a glial factor look different computational?
1692730	1701060	127	A	1.0	And where in the brain have people identified Glial or other factors as relevant for learning?
1702310	1705234	128	B	0.99114	Yeah, that's and interesting point.
1705432	1713826	129	B	0.98183	I'm not really sure about the equation of the free correlation of neural activity or plasticity.
1713938	1734746	130	B	0.99912	There are many discussion, I'm sorry, I don't know the exact form, but one possible implementation is similar to this type of neuromodulation.
1734858	1758850	131	B	0.98353	So it would be possible to model some griar modulation contribution of Glapter to activity in the form of three factor learning group, which is mathematically speaking in the same as this type of neuromodulation.
1763960	1769300	132	A	0.99913	Here in table two we have another set of correspondences.
1769960	1773624	133	A	0.63166	It's like a sideways figure three, right?
1773742	1776280	134	A	0.98529	But a little bit more like a dictionary.
1781080	1782132	135	A	0.99962	Anything to add?
1782186	1785030	136	A	0.99988	Or any variables that we haven't really mentioned.
1786940	1788724	137	A	0.96536	What about the firing thresholds?
1788772	1806936	138	A	0.99974	Because these are common parameters in a neural model, however, we don't really hear about the interpretation of these constructs within the variational bays.
1806968	1820240	139	B	0.77447	POMDP yeah, there is an interesting story that's a very interesting point.
1820310	1847560	140	B	0.88215	So when we first tried to make and arrowy between neural network and OMDP, one problem is the law of threshold factor because as you said, it is not observing pondip structure.
1847900	1864960	141	B	0.99998	But there is another factor in pondip which is prior expectation about hidden state which is usually expressed by D matrix.
1866180	1875180	142	B	0.83	And what we consider is a relationship between D matrix and firing threshold.
1875340	1906540	143	B	0.92	And finally, what we found is that firing threshold is not equal to D matrix itself but it is a summation of D matrix and some function of synaptic strengths which is equal to a matrix B matrix in the Pom DP formation.
1906880	1942920	144	B	0.9482	In other words, what we found is that h which is a firing threshold in NeuroNetwork architectures is actually and adaptive threshold which is not fixed by but h is a function of W synaptic strengths and h changes depending on W's value.
1942990	1951140	145	B	0.99986	For example, if W is too large, then neuroptivity can be unstable.
1951220	1961420	146	B	0.94183	So h behavior to reduce the activity to make neuro active states more stable.
1962020	2010040	147	B	0.46282	So we can see and analogy of homeostatic mechanism here like this if we design h as the function of w and function of some another factor which is called perturbation time in this table, then we could make formal analogy between this h and some variable in Palm DP formulation which is shown in the right hand side of this table.
2010200	2018832	148	B	0.99664	Although its value is not simple because it has three times, three different times.
2018886	2025990	149	B	0.96457	So all of them contribute to make h or M.
2028760	2041560	150	B	0.9333	But anyway, once we establish a mapping between h and this value then everything works.
2041710	2050360	151	B	0.9973	So the cost function in different settings have a force correspondence.
2053100	2057740	152	A	0.99921	What are the h and M firing thresholds.
2058160	2072908	153	B	0.98173	So h correspond to middle rare, m indicate output rare threshold which are different variables.
2073084	2098920	154	B	0.66	And interestingly h correspond to posterior sorry, prior expectation about the hidden states because it correspond to cognitive layer and M correspond to prior belief about its own action because it is a bias in the action layer.
2100640	2122736	155	A	0.75944	Yeah, it's very interesting that the perceptual firing threshold h only includes prior beliefs on hidden states, beliefs about how observations map to hidden states A and beliefs about how hidden states change through time B.
2122918	2140184	156	A	0.99839	So that's like pure passive inference and then the foraging thresholds for M correspond to only beliefs about preferences and beliefs about actions or habits with C and E.
2140382	2157660	157	A	0.99217	So there's like a complete division of labor or partitioning functionally between these structurally different parts of the neural network and structurally different and functionally different parts of the POMDP.
2159280	2167760	158	A	0.99955	Yet they're integrated in unified loss functions or unified imperatives.
2170180	2198360	159	A	0.99	And so it's like there's extreme separability of perception and action on both sides of the figure one divide but also they're integrated, but they're separate and that's what kind of grants it the best of both worlds because if they were any more integrated you couldn't really pull them apart.
2198780	2209740	160	A	1.0	And if they were any less integrated then the imperative, the loss function or the variational free energy would be ad hoc and unprincipled.
2210720	2216640	161	A	0.99995	But there's kind of a middle ground where they have a principled integration but still a distinguishment.
2218980	2219730	162	B	0.98463	Right?
2221860	2248168	163	B	0.999	This is caused by network structure defined or it is because it is because the structure of Bayesian network defined in the OMDB model.
2248334	2256328	164	B	0.93648	So both of them define the causal relationship between elements or quantities.
2256504	2264492	165	B	0.89	And so it's, you know, it's substrate is not important.
2264626	2276000	166	B	0.98646	So it's relationship, causal relationship is crucial to to determine the Costa function or it's a fixed point in this context.
2276160	2281300	167	B	0.98143	So that's why we can see the data analogy.
2284620	2297336	168	A	0.99917	Well, there's a few technical points I think we can now go into and then there will be some more general points about applications and intelligence.
2297528	2302588	169	A	0.97143	So, first the code availability statement.
2302764	2310060	170	A	0.99969	Awesome to see that the MATLAB scripts are available and also archived on Zenoto.
2310220	2315700	171	A	0.96036	So here is the GitHub repo for reverse engineering.
2316440	2321632	172	A	0.99938	Do you want to give any overview descriptions of what people can expect to see in this repo?
2321776	2325220	173	A	1.0	And also what about using MATLAB?
2330250	2332514	174	A	0.99801	Why did you use MATLAB?
2332642	2336230	175	A	0.99993	What advantages or limitations do you see in MATLAB?
2338490	2351690	176	B	0.59524	So because this is a very simple simulation, so it is so MATLAB is sufficient to encode the wall script.
2354930	2362080	177	B	0.99862	We also try some visualization in the Attial here.
2363570	2375010	178	B	0.99946	If you run the script, then you can see the process of an agent solving the maze task.
2379590	2383974	179	A	0.99872	What did they do in the May's task here?
2384092	2394970	180	B	0.77	The aim of this agent is to reach the right hand side of this maze.
2396430	2405310	181	B	0.99297	Because this is a typical example of a derived moderation task, that's why we select the maze task.
2406770	2419918	182	B	0.98143	So to achieve this main task, is it required to make some plan to be able to select a good decision?
2420094	2433698	183	B	0.99995	Because without planning, you may encounter the wall and cannot go further and you may fail the mace.
2433874	2443820	184	B	0.52313	But with planning, it is possible to see the path to reach the right hand side of this space.
2446190	2449290	185	A	0.98646	So does it know its exposition?
2453230	2464478	186	B	0.74141	Yeah, it received a state from neighboring eleven times eleven cells, so which is shown in the bottom part.
2464564	2466494	187	B	0.90406	Yeah, this all correct.
2466612	2473390	188	B	0.64389	All most yeah, left figure see indicate the observation.
2473470	2481300	189	B	0.9866	So, eleven times eleven state around the agent position.
2481910	2482322	190	B	0.78717	Okay.
2482376	2493020	191	B	0.9996	Now agent is on the right hand side of mace, ant the gold position and it observed our neighboring state.
2497150	2500330	192	A	0.98696	Well, a few interesting things here.
2500400	2503340	193	A	0.7483	It's looking off the right end.
2503950	2504566	194	B	0.6251	Yeah.
2504688	2511230	195	A	0.99	And it has this kind of periodic belief in the distribution.
2511650	2512400	196	A	0.95545	Why?
2515250	2533506	197	B	0.99	I think it is because when the agent is in the middle point of maze, then all neighboring state is in the maze.
2533538	2539160	198	B	0.94551	So there is a path and there is war.
2539930	2562800	199	B	0.95471	So this makes some periodicity because mazes may have some structure and actually have a periodic structure and only at the gold position, then righthand side becomes war.
2563810	2570580	200	B	0.99986	But it is not common in the for this agent.
2571030	2583170	201	B	0.89368	So because this is because this agent belief shows such a periodic patterns.
2584310	2590440	202	A	0.88289	Yes, the streets are one wide and they tend to be separated by one.
2591470	2593638	203	A	0.96815	So we see this periodicity.
2593814	2601130	204	A	0.99992	What is the numbers in this middle bottom plot and what does the checker board represent?
2601630	2611658	205	B	0.78905	Yeah, here, QS and QD correspond to posterior expectation about active states and decision.
2611754	2618770	206	B	0.99776	So middle Canada indicate decision posterior and decision.
2619270	2627678	207	B	0.98797	Here we characterize decision as a sequence of four step actions.
2627774	2638840	208	B	0.99802	So each action corresponds to a movement to right or left or up or down.
2639450	2648138	209	B	0.87	And we consider four step sequence of that option which is expressed as D.
2648304	2659790	210	B	0.64456	So it has four powerful possibility.
2661490	2663040	211	A	0.95	256.
2663970	2666190	212	B	0.97955	Yeah, 256.
2666340	2681862	213	B	0.94619	So this is a protein on XY coordinate because in the middle panel, middle point correspond to the current cognition of agent.
2681996	2704830	214	B	0.99	And with four step movement, agent can go one of any current position and the current brightness correspond to the expectation about the agent decision.
2705810	2707726	215	A	0.99291	Well, this is very interesting.
2707908	2715070	216	A	0.99999	If we just were to think about you're in a point and you can go up, down, left, right, you have four moves.
2716630	2721490	217	A	0.25773	Naively it sounds like, well, it should look like a gaussian blur.
2721990	2728538	218	A	0.76779	Most of those should cancel out and then it should become rare and rare monotonically.
2728734	2743660	219	A	0.91805	But actually if you start in the middle you can't end up on these white squares because it's like one, two, three and then you have to leave.
2744910	2745754	220	B	0.70299	Right?
2745952	2765950	221	A	0.98727	So it's kind of like horses in chess or other pieces where actually their embodiment, it's very unexpected that you can't in four moves, end up next to where you began when you can be so much further.
2766470	2781250	222	A	0.96	And then we see this kind of like embodied differentiate prior with QS that embodies regularity beliefs about the width of the road and the separation of the roads.
2781590	2793450	223	A	0.99	And then there's these embodied action priors and real consequences that have to do with the structure of movement.
2794910	2796426	224	A	0.93568	So what it's doing?
2796528	2801386	225	A	0.98764	It's thinking about policies of length four.
2801488	2804480	226	A	0.69813	There's 256 policies of length four.
2805010	2810718	227	A	0.93211	There's some degeneracy because there's obviously not 256 squares here.
2810884	2829220	228	A	0.9185	So while only one policy is going to take you up, down, down, other squares are reachable, like the center square is probably the mode because it can be reached at least a handful of ways.
2831690	2839240	229	A	0.95	And then at each time point it's basically saying, okay, I know where my X position is.
2839690	2848700	230	A	1.0	And given my local eleven by eleven view, I'm trying to plan to go right.
2854780	2860750	231	A	1.0	And then here through time, in the simulation here it starts at 30 something.
2861520	2868210	232	A	0.81183	It quickly figures out how to get to about 40 and then it's kind of going up and down on 40.
2869140	2876720	233	A	0.95951	But it can't really break out because all of these bottom four routes are closed.
2877380	2883430	234	A	0.99056	It has a breakout and then very quickly it hits another plateau around 60.
2884360	2885110	235	B	0.93961	Right.
2885720	2893130	236	A	0.99896	Then it kind of has a very nice breakout and in just a few steps goes very far.
2895260	2897352	237	A	0.99052	So what is dopamine doing?
2897406	2903160	238	A	0.99997	Or how is Dopamine helping it in the plateau and then to break out of the plateau?
2903660	2904410	239	B	0.46752	Yes.
2904880	2918988	240	B	0.84929	So this agent learned this particular mate structure through many trials.
2919164	2931620	241	B	0.99963	So before training it failed to reach the goal, but after training it achieved such a nice behavior.
2932040	2954504	242	B	0.99364	So to achieve this, the rule of domain is that we design gamma function such that if the agent can move rightward with some distance during some time limit, then risk becomes small.
2954622	2961148	243	B	0.54979	So like say comma equals zero, so no risk situation in that sense.
2961234	2969660	244	B	0.99988	In that case, this agent updates synaptic weights through hebium prosthesis.
2970260	2993240	245	B	0.9959	But if the agent failed to go lightward with some distance during a limited time frame, then gamma become rush like 0.6, which is larger than the average 0.5.
2993390	3007764	246	B	0.97431	Then we design that during such action, anti Hebbian ergodicity occurred instead of heavy prostitution.
3007812	3020280	247	B	0.73373	So antihibian prostitute indicates the works as the disassociation between the current state and current decisions.
3020440	3026988	248	B	0.99993	Because the current decision doesn't work, it's not good decisions.
3027084	3042284	249	B	0.99904	So we try to make the agent who get that particular decision rules through the moderation of heavy and prosticity done by dharma factor.
3042432	3050680	250	B	0.79449	So this can be a narrow to the dopam natural conversation and heavier prosthesity.
3052060	3064488	251	A	0.9994	So if the policy is resulting in the expected outcome, gamma stays at 0.5, the policy is as risky or consequential as expected.
3064664	3086500	252	A	1.0	And then the policy can either go better than expected, which facilitates learning to support that decision to be made more, or the outcome of the policy can be worse than expected, which disassociates previous conceptions to discourage that kind of behavior.
3087000	3087750	253	B	0.82499	Exactly.
3089480	3111964	254	B	0.98386	Crucial point is that this association with a exafferent time forage in the sense that we consider multiplication of current risk and past decisions to average over past to present Hebbian product.
3112162	3126188	255	B	0.90428	This makes an association between past decision secrets and the current risk, which enables to optimize decision to minimize the future risk.
3126284	3126736	256	B	0.68673	Right.
3126838	3129200	257	B	0.99259	It is just a sift or time frame.
3131720	3146890	258	A	0.87606	So here risk is being used in a formal sense similar to how it's used in economics, which is the associated uncertainty of outcomes with respect to a policy.
3148220	3150970	259	A	0.99999	Where does Daniel come into play?
3151900	3159340	260	A	0.98793	Like what if there was an adversary in the maze or something that was dangerous?
3160400	3168004	261	A	1.0	How does this kind of model accommodate or hunger or different kinds of competition?
3168072	3172720	262	A	0.99998	Because right now it's basically just trying to diffuse right word with a bias.
3173380	3174130	263	B	0.93971	Right?
3174660	3183910	264	A	0.99994	But how do different kind of situational elements become integrated into the generative model and generative process?
3185000	3197524	265	B	0.99758	Okay, any of those factors can be involved in risk factor, a single risk factor.
3197572	3209676	266	B	0.99932	So you can actually design risk factor because risk factor modulate moderate generative model.
3209858	3220360	267	B	0.99967	So that's why agent try to minimize risk through Beijing brain updating.
3220440	3227440	268	B	0.99971	But the risk itself is in some sense outside of such a Bayesian framework.
3227780	3233552	269	B	0.92863	So we can design arbitrary risk.
3233616	3241620	270	B	0.99976	So it may involve some danger after any other factor.
3243900	3254292	271	A	0.92	And this simulation is a POMDP or it is a neural network.
3254356	3261070	272	A	0.97	And what scripts might we look at to understand the structure of the maze agent?
3262320	3274232	273	B	0.79338	Okay, it is basically expressed using the quantity in OMDP for tractability.
3274376	3310720	274	B	0.99844	But for examples, if you see the MDP MTP learning, probably okay, there is a variable in the definition of same type correspond to the type of simulation.
3310800	3320900	275	B	0.97715	So if it's one or two it becomes fomodp or neural network to my understanding.
3321340	3357120	276	B	0.57549	Well, in this particular examples we use, let's say maybe it's not good example that DeForest is creating the well said no exafferent in this script as well.
3357190	3366090	277	B	0.99253	So maybe another, let's see.
3370460	3375624	278	A	0.78004	MDP and it is initiating the Markov decision process.
3375822	3376376	279	B	0.9738	Exactly.
3376478	3396530	280	B	0.50725	It's just determining the initial state of the home TD simulation and Fe computer variation of free energy or risk MDP risk computer risk function.
3398040	3409620	281	B	0.89882	So basically we use the neural network structure computation in this particular setup.
3410360	3433660	282	B	0.97192	So when you free maze m, then in the line gain one line gain one we determined that cinematypo is two this correspond to neural network architecture.
3434000	3492720	283	B	0.77404	So there is a very slight difference between home DP architecture and neural network architectures because assuming neural network architectures correspond to considering well, if you choose the palm DP architecture then we sometimes use d gamma function to compute the posterior expectation about parameters.
3493460	3520424	284	B	0.99944	But in the neural network modeling the gamma function does appear but it is replaced with the logarithm of some function and asymmetry speaking active coherence between the gamma function of something and logarithm function of something is asymmetry saying.
3520622	3528584	285	B	0.99828	So that's why we can transform on TP two neural network architectures.
3528632	3532990	286	B	0.97359	When the number of samples is sufficiently large.
3537360	3545490	287	A	0.57099	Which form do you expect performs better under small or large amounts of data?
3547620	3560260	288	B	0.98006	Well, for large amount of data they books in the same manner, same cycle, same manner or small amount of examples?
3561020	3573444	289	B	0.35168	I'm not truly sure, but it's correspond to assumption about the posterability distribution.
3573572	3595520	290	B	0.98616	So if you assume the Richard distribution, then your resulting function form is something that use the function in terms of basic robbery which is optimal.
3600680	3606710	291	A	0.85185	All right, let's return to the earliest questions from today.
3608120	3629020	292	A	0.61085	So in your script, which people can reference, there's basically a toggle between having it in simtype one or simtype two corresponding to the POMDP and the neural network.
3630400	3635980	293	A	0.99994	What about if there's a published neural network or POMDP?
3637300	3644560	294	A	0.99483	How can we use this architecture to create a translation?
3648170	3650114	295	A	0.99948	Is there any difference in this?
3650172	3665950	296	A	0.99467	Kind of like translating models in the wild different than the full construction of a special script that can speak both languages?
3670610	3680480	297	B	0.99636	Well, in terms of script there's no difference, sympathetic difference, right?
3681970	3684842	298	B	0.86401	They works in the same manner.
3684906	3706234	299	B	0.98936	So only a translation or variable you can see the same source code in the two exafferent ways.
3706352	3719790	300	B	0.97191	So if you see that this is a neural network implication, then it is translated as a neural network or if you see that this is a Pomodp, then it's Pomodp.
3723160	3735956	301	A	0.86803	So for some neural network being used in an industrial setting, how would we get from the neural network to a POMDP?
3736148	3740040	302	A	0.68	And where or how would that representation be valuable?
3741100	3741850	303	B	0.9943	Right?
3744940	3755052	304	B	0.6138	Neural network in the different architecture important point is that we consider a particular.
3755186	3761500	305	B	0.99998	Form of neural network which is called canonical neural network architectures.
3761660	3775140	306	B	0.99815	So only when we assume this class of neural network, then you can find the exact correspondence to a particular homo DB.
3775480	3790410	307	B	0.57297	Otherwise you need to establish another equivalence between another form of neural network architecture and some sort of model.
3792940	3808000	308	B	0.96632	This may be expressed by Pomodp, but maybe not so straightforward to be expressed as the computational bomb DP architecture.
3809300	3818710	309	A	0.99575	So what is it about the canonical neural network architectures that facilitates its translation into the POMDP form?
3819320	3824630	310	B	0.56128	Yeah, first of all, it assumes sigmoid inclination function.
3825080	3833080	311	B	0.99914	It is nicely correspond to enthalpy time in the force DP equations POMDP formulations.
3833580	3840440	312	B	0.98586	So that's why we can create a marking.
3841840	3848264	313	B	0.89517	In other words, simply speaking, they have the same nonlinearity.
3848392	3863068	314	B	0.98538	That's why this translation is very easy with another nonlinearity or neural network equation.
3863164	3873664	315	B	0.95519	Then we need to find another type of entropy equation or another type of prior distribution.
3873792	3876340	316	B	0.74397	It is very nontrivial.
3878280	3882970	317	A	0.97871	How does one even go about doing that research?
3890620	3899820	318	B	0.70071	If you want to go that direction, then I think the first step is to find the prior brief.
3907360	3919270	319	B	0.95096	Find the prior brief and find the equivalent between a particular neural network texture and particular Beijing model.
3925460	3929810	320	A	0.99993	This sigmoidal activation is interesting.
3930420	3942500	321	A	0.75025	It corresponds to general patterns seen in psychophysics to objects that are the same weight.
3943320	3946600	322	A	0.90525	You're going to have a 50% chance of saying that one is heavier.
3947020	3958140	323	A	0.61	And then initially the difference has the most returns on that decision being made accurately.
3959360	3974480	324	A	0.77	And then as it crosses some threshold where it just is beyond a noticeable difference, the decision becomes essentially probabilistic, like the firing curve becomes saturated.
3975620	3983410	325	A	0.98	The neuron has a very low belief about zero or very high belief about zero or one flipped at.
3986520	4010460	326	A	0.66248	So there is a nice grounding of that kind of a sigmoidal response curve with respect to stimuli differences and it has of course tractable analytical properties, but it also just happens to be a good response summarizer.
4011440	4013020	327	B	0.97108	Yeah, you're right.
4013090	4017500	328	B	0.98962	So sigmoidal function is also known as a psychometric function.
4017570	4026444	329	B	0.99997	As you said, we observe that characteristic in many ecological experiments.
4026572	4039472	330	B	0.96	And the previous work also said that even at the single neuron level, neuronal level the same behavior were observed.
4039616	4060830	331	B	0.99998	Which means that for each neural activity we can leo absorbed similar property, which is sometimes called as neurometric function, which have the form of sigmoidal inclination function.
4063440	4076850	332	B	0.97387	So it is nice reason to design neural network architecture using a sigmoidal function.
4078980	4090100	333	A	0.98444	All right, let's cover a few questions in the chat from Dave and then in the end turn to some general thoughts.
4090600	4094710	334	A	0.98448	Okay, this was when we were looking at figure three.
4095420	4103572	335	A	0.91003	So you described these vectors or matrices.
4103636	4106724	336	A	0.99994	What kind of matrix or vector did you describe?
4106772	4112980	337	A	1.0	The mass block matrix.
4114840	4116100	338	B	0.90998	Block, matrix.
4119080	4123870	339	A	0.99231	Block rock meaning what?
4124240	4129016	340	B	0.98533	Okay, brock matrix or broke vector is vector.
4129128	4131900	341	B	0.51771	Vector or matrix of matrix.
4133520	4134770	342	B	0.95249	Imagine that.
4143060	4145724	343	A	0.98854	Sorry, just zoom glitch.
4145772	4148370	344	A	0.99091	Just repeat the last piece okay.
4150100	4157540	345	B	0.86711	Well, broke matrix means that the element of matrix is a matrix.
4158280	4166040	346	B	0.92751	So let's say two by two matrix like matrix in pointing.
4166460	4176460	347	B	0.92497	So this here W one hat is a matrix, and W zero hat is another matrix.
4177360	4184700	348	B	0.99	And combining four matrices, we define a single block matrix.
4186820	4189250	349	A	0.99839	All right, thank you.
4189700	4199372	350	A	0.68666	So Dave then asks the hosts of machine learning Street Talk number 67 with Karl Friston.
4199436	4203120	351	A	0.99992	Another podcast where Friston has spoken.
4204180	4206516	352	A	0.69886	Pressed Karl Friston on.
4206618	4214170	353	A	0.99999	Why is it so important that most of the values in a generative model matrix assume values of exactly zero?
4217220	4221360	354	A	0.99998	Why is it important that generative model matrices are sparse?
4223140	4229760	355	B	0.99322	Why the tangential matrix sparse?
4230820	4232364	356	B	0.60324	I'm not really sure.
4232502	4237530	357	B	0.98	I think there is some context before that point.
4238220	4253550	358	B	1.0	I think on that particular situation, then, as you say, many elements in the matrix of gentle model should be zero, but I'm not sure if it's a general statement or not.
4254560	4264720	359	A	0.99995	What do you think about compressed analyses on sparse matrices?
4268980	4272160	360	A	0.99964	Is that a useful technique or direction?
4275640	4288148	361	B	0.93306	You can use that knowledge to construct model, so you can use that knowledge to make more accuracy inference.
4288244	4294120	362	B	0.98149	So in that sense, generally speaking, such assumption should be useful.
4295660	4309112	363	B	0.99852	For example, as you said, it would be possible to use some sparse prior to restrict the value parameter.
4309176	4332500	364	B	0.37246	Like it is in principle same as assuming some ruby norm to design the distribution, to design the prior distinctions, which is, massmarket speaking, exactly same as considering Lasso regression.
4334440	4335190	365	A	0.99846	Yes.
4337080	4357340	366	A	0.99368	So we've explored a little bit how from a canonical neural network to a particular form of a POMDP, gives us some semantics and interpretability around the dynamics and plasticity of the neural network.
4358080	4369760	367	A	0.9997	What do we gain by taking a stated POMDP generative model and deriving an analogous neural network?
4372420	4380340	368	A	0.99556	Do we gain access to efficient computation, new software packages, different applications?
4384200	4401928	369	B	0.9638	Well, if one use palmdp under one's goal is to design an efficient Bay Zion model, then I think palm DP expression is sufficient.
4402024	4431524	370	B	0.93592	So you don't need to consider neural network architectures, probably because designed to achieve give some sort of mathematically optimal inference and decision making, right?
4431562	4437620	371	B	0.97447	So it itself is optimal scheme.
4437780	4453340	372	B	0.89581	But if one need to consider link between Bayesian coherence and biological substrate, then this mapping is crucial.
4457680	4467548	373	B	0.98219	Simply speaking, we consider that we assume that a brain perform Beijing inference, but its substrate is still unclear.
4467644	4475436	374	B	0.99972	So we need to link the Beijing quantity to biological quantities.
4475628	4481760	375	B	0.95262	So this mapping, this equivalence, helps us to its transformation.
4483160	4497620	376	B	0.91193	So when you start from OMDB model, then this translation facilitates the process of finding its neuronal substrate.
4497780	4516688	377	B	0.99077	So once you translate that to neural network quantities, then it help us facilitate the experimental implication application to real data.
4516774	4543450	378	B	0.95132	So if its modeling is up for a particular neural network neural circuit architecture, then it should provide some prediction about the architecture or dynamics of the empirical data.
4543900	4544648	379	B	0.76581	Right?
4544814	4552988	380	B	0.94562	So first we start from Pasium model, which is not necessary to be equal to empirical data.
4553074	4559288	381	B	0.98717	So there is some mapping, but it's mapping is not straightforward.
4559464	4580100	382	B	0.94906	We may have multiple mappings, but once you translate Asia model to a particular neural network architectures then mapping or relationship between empirical data to such a particular neural network model is straightforward.
4580920	4589412	383	B	0.99724	So it helps us to apply phase to an explanation of Mpcard data.
4589546	4593780	384	B	0.70828	That's my soul.
4596860	4632500	385	A	0.99982	Is it fair to say that neural networks have found wide recent application because they facilitate statistical learning in cases where the inference problem has not been a priori well specified, one can just have a folder of images and a list of labels and just say here's the data, run it through this architecture or this Architecture Explorer.
4633880	4646490	386	A	1.0	And so with this concordance we gain new interpretability into those settings that kind of arose from ill specified inference problems.
4647180	4673440	387	A	0.99	And then on the other hand, for problems that we already have well specified in terms of a POMDP generative model of a particular form, we gain the connection to actually implement it with empirical data and bring it into relevant ancestral settings.
4676690	4700670	388	A	0.99505	What systems or phenomena are promising to continue research on the maze example obviously is a simple case, but are you continuing research into more advanced computational agents, robotic animal?
4705700	4735850	389	B	0.6233	Well, one can design a more sophisticated agent which performs some difficult task based on canonical network neural network but there is some clear limitation on that direction, right?
4736380	4751740	390	B	0.5952	Yeah, I should emphasize that across canonical neural network which correspond to a particular Pom DP is much smaller than general OMDP framework.
4752400	4756428	391	B	0.99691	So there are some limitations, a list of limitations.
4756524	4778004	392	B	0.98699	So if one's goal is designed and sophisticated Beijing to perform some task or control robot, then what direction is just forget such limitation and seek the mathematical optimality right?
4778122	4781660	393	B	0.88	And another direction is biascalic possibility.
4781840	4808160	394	B	0.99202	So if one want to make some agent which is biological possible then this correspondence is crucial because it it tells us some limitation, vertical limitation through the existence or no existence of such a mapping between Pom DPN particular neural network architectures.
4808500	4811330	395	B	0.60892	So yeah.
4811700	4822720	396	B	0.80086	So it would be useful to consider substrate to achieve difficult task.
4830870	4840110	397	B	0.44	And that task would be related to large dimensional image processing.
4840270	4851590	398	B	0.91502	Image recognition or sound recognition, such as multimodality can be involved or decision can be higher dimension.
4853450	4868390	399	B	0.83985	In the main task, we just considered the four direction of movement, but it can be extended to higher dimensionality like arm movement, body movement, so on and so on.
4868560	4876190	400	B	0.59881	So in Prince Boom it can be extended in that direction.
4879090	4894870	401	A	0.9999	Which directions or questions are you excited about or what areas of studying the basis of biological and computational intelligence are relevant?
4895850	4896646	402	B	0.99489	Yes.
4896828	4911206	403	B	0.68535	So in terms of the importance of canonical network, as you said, virtue is a vertical probability.
4911318	4939858	404	B	0.99918	So it would be nice that if we model some task which is conducted by lear animal and one already recorded some neuroptive activity then we design a task which is exactly the same as the task which is done.
4940024	4958782	405	B	0.61619	By the animal and then compare the simulated agent and MP card data to discuss about the similarity or difference between the simulated agent and riyadh animal.
4958946	4962620	406	B	0.99787	That would be very interesting dimension of research.
4965630	4977360	407	A	0.99809	Yeah and if there could be some unexpected prediction or explanation in the computational agent that would bolster the relationship.
4978210	4998130	408	A	0.98	And then one other aspect is it would help with the reproducibility and the documentation around behavioral studies if the computational agent were preregistered.
4999050	5018782	409	A	1.0	And someone said, we've already done the statistical power analyses and we've already explored with parameter sweeps how many observations we need to make of the two armed bandit how many observations of the three armed bandit should we do?
5018916	5022720	410	A	0.98	Three mice 100 times or 100 mice three times?
5023650	5030670	411	A	0.54816	Those are the total substance of designing research programs.
5031590	5044470	412	A	0.97	And so having a formal representation of behavioral tasks that are being studied will help us design behavior observations and experiments that aren't simply ad hoc.
5048810	5052520	413	B	0.78107	All right, that's an interesting application.
5055310	5086980	414	B	0.82881	This framework helps to design the experimental setup itself and what we often consider is the prediction ability of these modeling canonical neural networks to predict the steroidization or dynamics of the VR neural network in the animal during the learning process.
5087350	5110086	415	B	0.99053	So impressed for it possible to predict the behavior after learning based only on data in the initial stage because once we obtain some empirical data, then we can fit that data to design a particular canonical network.
5110278	5126522	416	B	1.0	And canonical neural network makes some serialization through a minimization of cost function which is exactly the same as the Bayesian belief updating under a particular generative models.
5126666	5148706	417	B	0.39857	So which means that its dynamics goes through the shortest path on the free energy landscape which means that we can make some quantitative prediction about the synaptic trajectory or neural activity or any kind of parameters.
5148898	5159974	418	B	0.99582	So we demonstrated that using in virtual neural network and uploaded some blueprint recently.
5160102	5183870	419	B	0.99705	So at least at the stage, at least at the level of individual network which is much simpler than VR brain, we could predict the self urbanization of individual network using this canonical network architecture.
5185110	5208780	420	B	0.66134	This support the probability of free energy principle because this canonical network predict the self organization through the variation of free energy minimization and its solution, its result chaos type correlation between.
5216750	5219498	421	A	0.99715	That'S a very interesting experiment.
5219594	5228110	422	A	0.96782	So what animal were the neurons from and what was measured about these neurons?
5228450	5255538	423	B	0.99516	Yes, so that in vitro network is obtained from blood embryo, we use cortical cells to make that individual network and task is a sort of causal coherence task which can be designed in the form of OMDB.
5255714	5268678	424	B	0.99232	So imagine that we usually simulate agent that receive signals generated by OMD generative process and process some Bayesian task.
5268854	5276554	425	B	0.99358	So we just replace that Beijing agent to a real in virtual neural network.
5276682	5286450	426	B	0.99977	So we stimulate neuron with some signal which is made by some hidden sources through likelihood mapping.
5286870	5295186	427	B	0.98	And question is whether in vitro network can in for the hidden states through some expectation.
5295298	5300230	428	B	1.0	And they can, they could infer the hidden causes.
5303850	5312570	429	A	0.99999	What does it look like functionally when the neural network has succeeded at inferring the hidden causes?
5312910	5324074	430	B	0.98968	Yeah, the director conversation is done by their response number of response spikes to a particular pattern of sensory input.
5324202	5334258	431	B	0.99895	So again, we can see a clear correspondence between neuro activity level and posterior about hidden states.
5334344	5341550	432	B	0.98925	So here we see Brea book response to electrocastimary.
5341630	5370160	433	B	0.99993	We see the response from ten to 13 millisecond after each estimation and we computer the number of spikes and that spikes changes their preference in the sense that some neuron learn to preferentially respond to source one but not source two.
5370930	5381630	434	B	0.86158	So which is not a response to input itself, but it looks like a response to particular source.
5382050	5399138	435	B	0.91295	So it is inference and which is evidence that neural network actually perform some sort of causal coherence in a manner consistent with variation and Beijing inference.
5399314	5416858	436	B	1.0	And then we compute another quantity in Bayesian coherence in the real bird card data, we show that firing stressful factor is consistent with the prior belief about hidden states.
5416944	5447750	437	B	1.0	And we also compute the cyanpic weight statistically through some connection strength estimation method and show that estimated synaptic strengths is consistent with something encoding posterior belief about parameters as expected by the Salary.
5449370	5476910	438	A	0.99977	Well, we looked at table two earlier and this is almost like the next step after the theoretical concordance is all right, well, let's measure the release of a neurotransmitter or the empirical synaptic strength or the firing threshold or all these different features in different empirical systems.
5477650	5484980	439	A	0.92292	So what experimental systems does your group work in?
5490710	5498502	440	B	0.99676	That invitral system was made when I was a PhD student.
5498636	5506198	441	B	0.95007	So that is the experiment we done in my previous route.
5506374	5517318	442	B	0.87	And now I COVID to the Rican Institute and I'm a principal investigator of Salary unit.
5517414	5523550	443	B	0.62863	So now actually, we don't use any experimental setup.
5524210	5529550	444	B	0.99533	Any experimental variation is down with some correlation.
5529890	5535386	445	B	0.75715	So although I cannot say a detail about that corroboration.
5535498	5545910	446	B	0.99946	But yeah, we learned some corroborating work about the implication of celery using various animals.
5546250	5546806	447	B	0.36423	Yes.
5546908	5554360	448	B	0.98378	So we hope we can show some interesting results following results using animal data.
5558350	5560460	449	A	0.99475	Very interesting.
5561630	5580270	450	A	0.56204	Yes, well, it speaks a lot to the stage that our field is in in certain ways where we've seen a lot of graphics that are suggestive.
5581170	5604694	451	A	0.99982	This paper and the building on the previous 2020 paper made a suggestive possibility much closer to an analytically demonstrated translation and then took the next step incrementally into the in silica agent.
5604892	5613900	452	A	1.0	And so it's only natural to then explore different embodied systems as well.
5619630	5636020	453	A	0.99982	Are there any other sections that you wanted to look at or highlight or any other topics about the paper or adjacencies or active inference that you think are interesting to go into?
5641510	5652114	454	B	0.47037	Okay, we would like to mention about some limitation of these papers which is not directly discussed in the papers.
5652242	5660380	455	B	0.96649	So for example, well, we focus on a discrete state space model.
5660750	5672378	456	B	0.99109	So we avoid to assume some sabo street that encoding the covariance of the distribution.
5672474	5677370	457	B	0.63423	So once you assume pole DP, then it is categorical distribution.
5677450	5685534	458	B	0.99728	So it is different from assuming Gaussian distribution characterized by me and variance.
5685662	5696310	459	B	0.98223	So the neuronal substrate of variance is still unclear and we now try to figure out that.
5696460	5699750	460	B	0.91077	So this is one dimension of limitation.
5700490	5719466	461	B	0.94	And another limitation is that thanks to a simple ODP structure in this paper, we don't care about the hierarchical optimization.
5719578	5733150	462	B	0.90763	But generally it is crucial to update parameters through hierarchical optimization through some back propagation like competition.
5733490	5756810	463	B	0.71434	Although it is unclear whether back propagation itself occurs in the real brain, but we still have some alternative that active such optimization and its neuronal substrate still unclear and this paper does address that direction.
5774450	5785230	464	A	0.99836	Another area I'm wondering about is like where in neural structures is the learning reflected?
5786370	5789518	465	A	0.99991	Where is the function and learning reflected?
5789694	5798654	466	A	0.99924	Well, sometimes it has to do with not just structural Tweaking, but the presence or absence of synapses.
5798702	5812422	467	A	0.99838	So obviously this model does not expand into synaptogenesis synaptic pruning, let alone neurogenesis and neuro allostasis which we mentioned in the previous dimension.
5812566	5844126	468	A	0.99969	But understanding how these larger scale structural changes which are certainly important in biological systems become reflected in artificial neural networks and then how that translates all the way back to POMDP and then whether we could go the other way what kinds of POMDP structures in their neural network realization would have structural modification.
5844238	5853254	469	A	0.78601	Like you could imagine a POMDP that does structure learning but the neural network doesn't have structural change.
5853452	5862970	470	A	0.99998	Or there's a POMDP that doesn't do structural learning but it's manifested by a neural network that does have a structural change element.
5863870	5869418	471	A	0.99889	So structure is doing something very different in these two different categories of model.
5869584	5890862	472	A	0.87	And then also even within neural firing, which is different amongst different species and so on, there's different aspects of what that firing is that would have different implications for the actual biological substrate of cognition.
5891006	5903258	473	A	0.85688	Like the simple connection is firing rate to posterior belief, average firing rate, no change in posterior.
5903374	5906534	474	A	0.99493	Reduce the firing rate if the posterior should be going down.
5906652	5908758	475	A	0.95237	Increase it if it should be going up.
5908924	5913434	476	A	0.99999	Or maybe there are neurons that have a flipped valence but the same type of relationship.
5913632	5926350	477	A	0.68915	But there's other firing patterns like spike time dependent plasticity synchronization amongst different brain regions.
5927570	5932670	478	A	0.99604	There's a lot of things that don't change the rate overall.
5933970	5942980	479	A	0.91616	That, again, from the biological systems, we know that those phenomena and mechanism are important for different cognitive processes, right?
5946150	5952040	480	A	0.98801	So there will be many years of a fruitful relationship.
5954650	5962650	481	A	0.99192	I'm going to bring in this picture that Alexandra had taken.
5962720	5984880	482	A	0.94588	Maybe we need a third panel in figure one because these three systems moving between them is going to be the substance of the field for a long time and there's maybe other edges to build.
5985890	6019670	483	A	0.9997	But understanding how artificial neural networks intermediate between the empirical measurements and manipulations that we can make of real neural systems and the interpretability and factorizability of POMDPs, it might be a bridge too far to go from the POMDP to the neuron.
6019830	6028830	484	A	0.99256	You could always use this technique, but it would be a purely descriptive statistic type approach.
6031570	6059880	485	A	0.99998	But it's so interesting that by intermediating through a formal connection established in figure one, I mean in equation one, but also shown here, then we can kind of extend the chain of explanation, prediction, control, design all the way on through.
6061050	6084750	486	A	1.0	And that just unlocks an incredible amount of neuroscience that hasn't been formalised mathematically and an incredible amount of generative models that have been specified for different learning settings, sometimes even by analogy to biological settings.
6085890	6096930	487	A	0.99997	But the metaphor remains just a metaphor until it's possible to intermediate with this type of neural network development.
6097830	6101400	488	B	0.98025	Yeah, that's a crucial point.
6105210	6120700	489	B	0.9998	It is easy to imagine that Liar data or lear phenomena can be modeled using very realistic neuro model or Glia model, synaptic model, right.
6123150	6138466	490	B	0.99934	We believe that it is possible and then model is not necessary tractable, not necessarily useful because it is too much complicated to analyze something.
6138568	6148770	491	B	0.99909	So we use some reduction, usually mathematically speaking, which correspond to topological transformation to make the model simpler.
6149530	6170778	492	B	0.92	And then we need to consider the translation of that simplified neural network model because neural network model itself is not explainable, which just represents some dynamics and its functional meaning is not clear.
6170944	6199650	493	B	0.99944	But thanks to the Bayesian framework, we have a very nice framework to lens the experiment ability and this translation, this correspondence helped us to link such phenomena base equation modeling and functional based equations.
6200970	6212310	494	A	0.91142	Yeah, one paper from 2017 that was much discussed by some could a neuroscientist understand a microprocessor?
6213070	6228160	495	A	1.0	And this group with Jonas and Cording, they had a simulation of a microprocessor from earlier video game console, I believe.
6228850	6251814	496	A	1.0	And then using the analogy of the transistors and their connections as neural firing and structural connectivity, they were able to simulate experimental settings, input and action and then make measurements from every neuron including doing lesions and loss of functions and so on.
6251932	6275706	497	A	1.0	And it turns out that a lot of the techniques that are used to derive scientific explanation from analogous data collected from a biological system, those techniques which ostensibly should be isolating functional explanations in fact did not isolate effective explanations.
6275898	6292370	498	A	0.99959	You could have a deletion over here that induces some statistical change all the way over here and that may or may not be a useful cue towards the function of even sub circuits.
6293270	6314810	499	A	1.0	And so I think that was a wake up call with respect to the interpretability of simply this connection between the biological and the neural network.
6316190	6337310	500	A	0.98701	This connection alone is of limited applicability, even when the neural network model becomes so complex as to recapitulate the biological phenomena, you're never under any guarantee that you're going to recover interpretability.
6337830	6349578	501	A	0.99996	You may have just created an atomic level simulation of the phenomena, but of course, a map that is the same scale as the phenomena isn't a map.
6349774	6353190	502	A	0.95533	It's just a copy that has no more interpretability.
6355370	6386830	503	A	1.0	And it's almost like what is now extended again, as we kind of just summarize this and think about how we move forward, is that connection can now be extended into the space of interpretable causal models and the generalized Bayesian graphical computational frameworks and all the heuristics that we can then use like variational, Bayesian and all these other methods.
6387270	6408914	504	A	0.93615	So it'd be interesting to look back at different data sets of in vitro and in vivo and in silico neural activation, especially if the task was of this constrained set of POMDPs and it was already amenable.
6408962	6422570	505	A	0.99999	Because, as you brought up, other settings would require a little bit more theory development before we understand what POMDP family would be applicable.
6428450	6429054	506	B	0.96411	Cool.
6429172	6433520	507	A	0.99385	Well, do you have any final thoughts or questions?
6436050	6439300	508	B	0.91392	Well, do you have.
6443670	6455810	509	A	1.0	I want to download the MATLAB scripts and generate the figures, play around with a few of these parameters.
6456630	6460920	510	A	0.9447	Like, I see that you can change how far the entity can see.
6462590	6469770	511	A	0.87	And then with these models, I'm also always curious about the computational complexity.
6470190	6482910	512	A	0.79562	Like if you extended the planning horizon from four to five or you dropped it down to three, what is the runtime consequences and what is the performance consequences?
6483890	6500230	513	A	1.0	And where might we be able to use single or swarms of really simple agents, maybe even making binary decisions and achieve high performance?
6501210	6538990	514	A	1.0	And where do we really need to move into these large combinatoric spaces in order to solve problems and the kinds of complex planning problems that we solve, whether it's planning our day or planning our week, are those more like true Deep Horizon planning problems with extensive consideration of counterfactuals and calculation of alternatives?
6539150	6558150	515	A	0.99991	Or are those actually composite decisions that are made up of smaller, simpler, sub decisions that we may or may not have flexibility to restructure?
6560330	6569260	516	A	0.9989	So that a decision, a complex chess maneuver, a sacrifice in chess or another game.
6570990	6586990	517	A	0.99999	It may be possible to model that as a Deep Horizon scan or a kind of intuitive heuristic for an appropriate skilled entity.
6590210	6608402	518	B	0.81861	For this particular Tour structure, there is a clear limitation about the horizon of the forward search because it doesn't use forward prediction.
6608466	6611394	519	B	0.99558	It used post action approach.
6611442	6625370	520	B	0.98473	So it's a career limitation, but still, it may have some performance ability to achieve some revenue performance.
6627330	6632350	521	A	0.85191	That provides even another way to look at planning.
6632850	6655590	522	A	0.68034	So the the two ways I was describing planning, as it's often described in the PMDP literature, is again, is it a true Deep Horizon consideration or is it just short term heuristic or nested models that are short and I think that this paper says maybe neither.
6656250	6679178	523	A	0.99738	Maybe it's purely the fictive causality on the past that leads to the emergence of sentient and maybe even teleological planning like behavior through the ongoing reconsideration of the consequences of past action.
6679354	6683674	524	A	0.99998	But it's neither a short nor a long term planning challenge.
6683722	6687046	525	A	0.99995	It's actually like a memory and learning challenge.
6687178	6689022	526	A	0.99	And no planning occurs.
6689166	6689860	527	B	0.52894	Right?
6690470	6697970	528	B	0.73341	But indirect to planning planning element is involving C matricing.
6698950	6704630	529	A	0.99965	Planning as a phenomena occurs and derisking through time occurs.
6706810	6731920	530	A	0.5626	But it says something quite interesting and deep that that phenotype or function could be enacted by a system that explicitly looks a long way ahead, explicitly looks a short way ahead or moves forward and looks backwards only, which is what they sometimes say about the past and the future.
6733650	6753720	531	A	0.99801	So that may be a very biological plausible form of learning and it's already intimately connected with the dynamics and the plasticity in terms of an integrated loss function.
6755290	6762280	532	A	0.99845	So these are all excellent directions to keep learning on, right?
6763050	6772582	533	B	0.87	And I'm also interested in the barsky implication of such a short term or long term force, the prediction and planning.
6772646	6788290	534	B	0.95	And I hope to find some nice connectivity to such implementation of Bayesian mode and implementation VR brain network.
6789590	6790386	535	B	0.98684	Cool.
6790568	6799650	536	A	1.0	And also I'm always curious about the invertebrate brain as an ant researcher.
6800090	6812374	537	A	0.96	And so many of the brain architectures as well as the regional architectures that people discuss are mammalian centric, which makes sense.
6812572	6825680	538	A	1.0	The mammalian cortical column and the relationship with Dopaminergic brain and the cortical regions and the spinal reflux arc, those are all important systems of interest.
6826290	6835390	539	A	0.99995	Yet the micro and meso anatomy of the invertebrate nervous system is pretty distinct.
6836130	6847890	540	A	0.86975	So our model should be able to describe neural and cognitive systems, of course across invertebrates and vertebrates.
6848230	6867450	541	A	0.98423	So I look forward to also seeing like what those models of the invertebrate nervous system and cognitive behavior where you could have some type of backwards looking risk coherence of the swarm.
6868750	6869850	542	A	0.96477	Who knows?
6872190	6872940	543	B	0.99429	Well.
6875310	6879734	544	A	0.99997	We really appreciate the time that you took for these discussions.
6879782	6888210	545	A	1.0	I think they are immensely important and we wish you the best of luck in these cognition continuum directions.
6895380	6896688	546	A	0.98807	Okay, that's it.
6896774	6897570	547	A	0.99958	Thank you.
6898420	6899680	548	B	0.99858	Thank you very much.
6899830	6900672	549	A	0.99807	See you next time.
6900726	6901360	550	A	0.74509	Bye.
