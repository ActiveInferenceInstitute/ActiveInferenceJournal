39287	41007	A	0.62	All right, hello everyone.
41085	41727	A	1.0	Welcome.
41895	45507	A	1.0	This is ActInf livestream number 51 one.
45660	52612	A	0.99855	We are in the second discussion of this paper, canonical Neural Networks perform Active Inference.
53187	55757	A	1.0	Welcome to the active inference institute.
55922	62072	A	0.90665	We're a participatory online institute that is communication, learning and practicing applied active inference.
62192	67517	A	1.0	You can find us on this slide and this is recorded in an archived livestream.
67652	70872	A	0.90933	So please provide us feedback so we can improve our work.
71055	84937	A	1.0	All backgrounds and perspectives are welcome and we'll follow good video etiquette for live streams, head over active inference.org to learn more about the institute and how to participate in projects and learning groups.
85887	104877	A	0.47	All right, we're in ActInf livestream number 51 one, and having our first nonsolo discussion on this paper, canonical Neural Networks perform active inference and really appreciative that you've joined today.
104970	107282	A	0.59279	It's going to be a great discussion.
107447	109412	A	0.80146	We'll begin with introductions.
109487	114657	A	0.80791	I'll say hello and then please just jump in however you'd like.
114810	118337	A	0.9	And we can start by setting some context.
118487	142262	A	0.75828	So I'm Daniel, I'm a researcher in California, and I was interested in this paper because we've been talking a lot about active inference from a variety of different perspectives, from the more fundamental math and physics to some applications, philosophy, embodiment, all these really interesting threads.
142412	159422	A	0.92	And this paper seems to make a really clear meaningful contribution and connection by connecting active inference entities and this approach of modeling to neural networks which are in daily use globally.
159617	166302	A	0.87203	So thought it was a fascinating connection and really appreciate that we can talk about this today.
166395	168550	A	0.7129	So to you and welcome.
174375	178212	A	0.97963	Go forward, Takuya, however you'd like to introduce and say hello.
178575	179337	B	0.54	Yeah.
179700	180195	B	0.97762	Hi.
180272	186175	B	0.58672	I'm Tafia Isomura, neuroscientist in Lique Brain Science Institute in Japan.
186525	196370	B	0.81195	I'm particularly interested in universal characterization of neural network and brain using mathematical techniques.
196535	213500	B	0.65677	So this work I believe important as a link between active brain forest aspect, Bayesian aspect of the brain, and the dynamics system aspect of the neural network.
213650	217790	B	0.78223	So I'm very happy to join this discussion session.
217895	219440	B	0.98938	Thank you for invitation.
219620	220962	B	0.99344	Nice to meet you.
222000	224337	A	0.99877	Nice to meet you as well.
226350	231700	A	0.99	The first thing you added, the universal characterization of neural networks.
232275	236210	A	0.99562	What is the universal characterization of neural networks?
236255	239712	A	0.99281	Why is it being pursued in this area of research?
241200	269075	B	0.79329	So, as a narrow sense, my gain aim of this paper is that so, you know, people active inference lab communication to characterize brain activity, behavior, so on, so on, but which would be different from conventional neural network.
269150	289935	B	0.71505	So there is a crossover program which is associated with conventional neural network and it is not very clear whether all characterization of computational neural network can be explained by activity infrastructure principle or not.
290042	312170	B	0.86937	So here universal characterization means that characterization of every aspect of conventional neural network which is a kind of dynamics system derived as association between biological phenomena and simple mathematics.
312185	320190	B	0.54987	Car formula using gift card, using differential equations as the broad sense.
320357	342250	B	0.66	I think universal characterization means that well, it is a characterization of brain intelligence, but it's a big picture and the paper particular address is only one aspect of the Bull picture.
346200	347205	A	0.95	All right?
347402	355365	A	0.91457	So it'll be great to pull back to really understand what synthesis is happening.
355532	365640	A	0.87706	So I'm going to ask what makes a neural network model a neural network model and what makes active inference lab model an active inference model?
365807	370170	A	1.0	Is this synthesis and connection you've made true?
370247	371487	A	0.99832	Because of what?
374175	402570	B	0.93901	Because basically what we show is the mathematical equivalence between the formulation of canonical neural networks and the formulation active inference lab in the sense that we show that as possible neural networks can be characterized by minimization of some biological plausible cost function.
402722	422187	B	0.86	And we show that that cost function can be least as variational based on inference and a particular cross of gentlemen model in terms of well known partially observable position process.
426000	433812	A	0.64195	Alright, shall we perhaps walk through some of the sections of the paper?
434250	435285	A	0.94	It would be awesome.
435392	442160	A	0.88638	Just for each of these sections, maybe the numbered and the lettered sections.
442355	447087	A	0.99962	What does the section aim to show and why was it there in the paper?
457125	462312	B	0.52315	Briefly it's over, right?
463275	464825	B	0.52123	So briefly.
464900	476787	B	0.59295	So first we introduce so the gain issue main program, our interest, which is relationship.
480975	489935	B	0.61074	We try to make a formal ring between neural network and active reinforcements that gain program background.
490055	499535	B	0.93	And then we first formulate the equivalence, mathematical equivalence, in a very Brea manner.
499730	521712	B	0.74626	So in the first section in results, we formulate the relationship using complete craft serum, which is well known statistical theorem proposed very long time ago.
522300	535505	B	0.82	And using that we link a general form of neural network with a general form of variational data impress.
535640	553895	B	0.79795	But a problem is that this characterization does not address a specific generative model which is crucial to characterize a specific model, specific neural network dynamics.
553985	573925	B	0.50049	So in the following sections, we characterize the problem using Pomodb or partially observable Markosition process and link that model with a particular class force canonical neural network.
575625	589150	B	0.94	And then we simulated we use the simulation to propagate that property in terms of some major tasks.
595000	597412	A	0.94	All right, thank you for this.
598150	602225	A	0.99682	Could we talk about the complete class theorem?
602650	614137	A	0.7762	So what is the scope of the complete class theorem and why was it the relevant set of the neural networks to pursue or the right way to frame it?
615100	616975	B	0.99181	Thank you for asking that.
617037	625015	B	0.70867	So I like the slide you showed last week's video.
625182	636125	B	0.47195	So computer cross theorem basically indicates the relationship between some crossover decision rule and vision in France.
637150	664620	B	0.94818	Here a crucial keyword is admissible decision rule, which is a rule which is as good as other decision rules or at least at one point better than other decision rules.
664635	674175	B	0.51835	So simply speaking, adomissibility indicates in some sense it is the best rule for some aspect.
674325	683290	B	0.67	And usually we characterize such a goodness using cost function, loss function or risk function.
683457	707940	B	0.78	And here what we did is we established some association with this type of loss function or risk function with canonical neural network which is we call cost function or biotic roles Costa function or neural network.
708120	713485	B	0.56917	So our assumption is that neural network minimize cost function.
713667	730162	B	0.82904	So if it active the inclination and it is virusly active some sort of optimality so we can say it is adommissible with respect to that cost function.
730525	751815	B	0.73533	So the beauty of complete cross theorem is that if we find some admissible decision rule then automatically we can say that it is based on inference in terms of some Bayesian Costa function with gentlemen model a priori beliefs.
751995	767085	B	0.68203	So this computer chaos theorem is crucial as abstract characterization of the relationship between conventional neural network architecture, dynamics and variational.
767130	768350	B	0.22101	Beijing influence.
771650	773762	A	0.49	All right, thank you.
775325	780287	A	0.99798	What does it mean when you said it was biologically plausible of a loss function?
781925	808050	B	0.77	The term is a little bit arbitrary because in this paper we mean by probability in the sense that this neural network model can be derived from realistic neural model through some approximation.
808625	823562	B	0.58	And so here barricade probability, suggest means probability as a neural model or synaptic processing model.
824300	836175	B	0.87	And if this cost function loss function can derive such a plausible algorithm, then we can say that this cost function is barely plausible.
839525	847862	A	0.71853	So what is the distinction between those neural and synaptic components in the loss function or what equation to look at?
849500	854035	B	0.55	You mean distinction between dynamics and synaptic?
854155	854525	A	0.87	Yeah.
854587	858975	A	0.99947	What is the distinction between them and how is it represented in the equations?
860525	883050	B	0.95	Okay, basically neuropathivity equation means differentiate equation about a variable that represents firing intensity or some sort of variables associated with the firing.
883625	900450	B	0.9989	On the other hand, dusty equation means an update rule about the synaptic weight or synaptic strengths which is a connection between two neurons.
901025	926387	B	0.86	And beauty of this formulation proposed in this paper is that we characterize both heuristic equations synaptic procedure equations in terms of gradient descent on a same cost function, common cost function.
926975	959625	B	0.70275	So we can say that if we consider the partial derivative of some cost function with respect to new activity, then it's derived by gradient descent rule about if we consider a partial derivative of chaos function errors with respect to synaptic weights, then we derive a prosthesis rule.
970187	978312	A	1.0	Are those the only two aspects of a neural network or why are those the two key aspects?
980837	990637	B	0.51	It is a main, I think it's the main body of the neural activity.
990712	1017692	B	0.76424	If we consider some inference running or action exhibit by neural networks in the sense that neural activity correspond to fast dynamics, fast gradient dynamics mix and scientific processes indicate through dynamics that minimize least function and cost function.
1017890	1023997	B	0.93685	But in general, we can consider any aspects, any variables associated with your method.
1024042	1044892	B	0.99263	For example, at least what we show in the paper is any free parameter which may be associated with firing threshold or although we don't discuss in this paper it would be possible to add other variables related to neural network.
1044952	1060362	B	0.99058	For example, here we ignored contribution of Griad factor but it would be possible to add the Griar factor in this correlation or any other aspect of virus corporate neural network.
1064612	1073422	A	0.93201	That's very interesting and it speaks also to a general separation of time scales.
1073617	1096277	A	0.99825	For example in different multi scale systems or in the renormalization group where it's describing some minimal multi time scale system where the faster time scale can be seen as perception like a slower time scale can be seen as more learning like.
1096445	1103632	A	0.78	And then in some hierarchical model what's learning of one time scale can be perceptual for a slower time scale?
1103722	1107237	A	0.79569	So it's a very nice generalization.
1112387	1123322	A	1.0	Are there any examples of decision rules that will help us think about the action components of what the neural network is doing?
1123505	1135582	A	0.98897	Because it may be more familiar to think about digit characterization and image classification, some kind of classical tasks for neural networks.
1135747	1141362	A	0.87781	But how does the decision rule play out in the context of neural networks?
1144187	1156050	B	0.86	Okay, so in this paper we basically assume a closed loop so comprising a neural network part and environmental part.
1156487	1167387	B	0.83151	So Neuron receives sensor input from environment and provide some feedback to the environment.
1171787	1189062	B	0.80081	Even with the example of classification, we can say that output correspond to classification output, which is kind of generative model relevant.
1189412	1198772	B	0.99444	Example would be, for example, controlling agent like a robot control or any kind of control errors.
1198805	1200787	B	0.99903	Decision making tasks.
1200937	1212375	B	0.98971	For example, when we encounter some choice tasks, we need to advertise, for example, left or right or something.
1212887	1222362	B	0.99734	Any kind of such a decision can be associated with the admissibility or admissible decision.
1227050	1238175	A	0.69648	So what would an example of an inadmissible or admissible strategy be in the decision making task?
1240850	1248962	B	0.33222	Admissibility usually characterized by loss function or risk function.
1252925	1270500	B	0.67062	Here admissivity indicates that there is another decision rule which is at least one point better than the forecast decision rule.
1272575	1286025	B	0.54836	Simply speaking in Adobe CBD indicates that decision rule is not good relatively.
1287050	1290737	A	0.67056	Let's just say our decision rule is we always turn right.
1291475	1293790	A	1.0	Is that an example of a decision rule?
1293820	1302370	A	0.99612	Because there might be settings where that is strictly effective and the simplest rule whereas there's other settings where that's going to be tragic.
1302535	1311000	A	0.72753	So what does it mean to be admissible for an agent in light of different environmental contexts?
1312250	1314155	B	0.58704	That's an interesting point.
1314277	1331612	B	0.63528	So even with such a too much simplified rule it can be admissible under some particular situation, particular loss function.
1331975	1341110	B	0.75999	For example, the rulers that always turn right maybe the best under some situation, right?
1341292	1355625	B	0.67831	So the relationship of admissibility or enough adommissibility depends on both agent characteristics and environmental characteristics.
1359350	1362300	A	0.99131	What aspects of the environment.
1364975	1365962	B	0.59821	For example?
1366400	1389225	B	0.71231	For example, if that decision group matches the structure architecture of environment then maybe that decision always downright active the shortest past under some situation, some environment.
1391675	1408500	A	0.95488	How does this admissibility help us think about like overfitting and how does it help us think about the way that different practices are used for neural networks to prevent them from being over fit in practice?
1410725	1424100	B	0.72985	Well, strictly admissivity is characterized with the Bayesian risk.
1430225	1442860	B	0.99197	We cannot observe a hidden states of the environment, only we can observe is a part of the entire universe.
1442905	1453955	B	0.57143	So the question is an important question is what is the best choice under such a limited information?
1454077	1459250	B	0.93629	Limited information?
1459387	1489780	B	0.70892	So this Bayesian list adoissibility or computer credit theorem tell us that well known, only the well known Bayesian framework achieved the adommissible decision.
1489840	1512900	B	0.54745	Which means that in this aspects Bayesian optimization give us a least choice strategy, otherwise we overfit or find the suboptima evolution.
1513700	1526470	B	0.84003	So it's a nice association, nice linkage between the decision, but is a good decision about the decision and more established statistical inference.
1526560	1527662	B	0.13996	Freedom work.
1531137	1534082	A	0.93512	Thank you, that's very helpful.
1534172	1543912	A	0.75414	So we're reducing our uncertainty and risk about hidden states in the environment.
1544262	1563162	A	0.92056	So in the special case where the entire environment is observable without errors like a chess game, then there's an equivalence between correlation of risk or loss on observables or on hidden states.
1563225	1566925	A	0.99532	But they're not really hidden, but they are environmental states.
1567512	1605752	A	0.94661	Whereas any amount of uncertainty in the mapping between observations and hidden states, which is usually shown as a in the partially observable Markov decision process, any amount of uncertainty about unobserved or partially observed environmental states enables you to fit your uncertainty optimally about that hidden state and fit that uncertainty simply with the gradient descent.
1605932	1630287	A	0.89	And by doing so, you don't overfit a model of observables, which might be the fallacy or the issue with simply doing descriptive statistics you might get an infinitely small variance with a frequentist estimate because you have 1000 data points.
1630425	1636375	A	0.84905	So the variance from a descriptive statistics perspective might be very small.
1641012	1654992	A	0.99	I think it speaks very much to why neural networks are useful in practice from training with limited data sets because that's an empirical observation that they don't entirely over fit.
1655115	1660237	A	0.94502	But also I'm sure there's ways to construct them that are overfit.
1661112	1670597	B	0.66	Yeah, overfit will occur if we select some optimal priorities.
1670717	1671550	B	0.9867	For example.
1673712	1696707	B	0.71018	Well, I'm not sure if it is overfit in the sense what you mentioned because if we select some priorities then the Bayesian function itself changes and the neural networks that try to fit to that Costa function.
1696785	1703697	B	0.88017	So cost function minimization will be achieved agent such a situation.
1703880	1712125	B	0.97065	But that solution is not good for our original help us.
1712787	1714422	B	0.89249	That's the tricky part.
1714605	1726857	A	0.75	Yeah, that is reminiscent of some discussions we've had discussing like driving off a cliff or blowing up is also reducing free energy.
1726935	1730200	A	0.90308	Like dropping up a building reduces your potential energy.
1730637	1749437	A	0.84	And so there are potentially decisionmaking or strategic trajectories that do for some time horizon minimize free energy, perhaps even or maybe even guaranteed better than some longer time horizon.
1749587	1754362	A	0.99156	Because if the shortterm strategies were somehow better than the longterm horizon.
1755087	1761112	A	1.0	It would be difficult to imagine because the long term horizon would be at least as good as a shortterm strategy.
1762437	1767902	A	0.75439	So that speaks to the challenges of planning in action.
1768007	1777000	A	0.7137	So how is planning addressed in modern neural networks and how does this work help us think about that?
1779837	1783162	B	0.61552	That's another very important aspect.
1785612	1812187	B	1.0	I have to say that this framework addresses planning aspect, but that planning is not necessarily the optimal solution in the sense that what we interested in is optimization or learning under limited structure.
1814112	1821422	B	0.9	The structure is characterized by here Prosperia neural networks.
1821617	1834797	B	0.56967	So yeah, planning occurred by association between risk in the future and our decision in the past.
1834980	1849162	B	0.98176	Here we model that aspects using delayed moderation of scientific activity mediated by some neuromodurator or neurotransmitters.
1850712	1852075	B	0.7	This is the model.
1858812	1876837	B	0.81	This is model as the risk factor and the heavy product holding the neural network.
1881987	1889342	A	0.94	All right, I'm going to ask a great question from the chat and then we'll look at the figures a little closer.
1889477	1895637	A	0.63808	So ML Don wrote a question stuck in my mind for a long time.
1895775	1897872	A	0.9985	Could you please put it to rest?
1898055	1906537	A	0.99931	Do we need to have knowledge about all states possible actions and sensory inputs for active inference?
1910812	1928000	B	0.76562	Well, you mean if you seek the exact solution, exact optimal solution, then maybe more information would help you to find that.
1928887	1948187	B	0.91696	But under some ideal assumptions then the is not necessary to achieve the optimal solution.
1949662	1953800	B	0.58367	I'm not sure if I correctly answer your point.
1955512	1958300	A	0.47779	So just to restate it.
1959037	1964812	A	0.91	Of course, knowing all the state's possible actions and sensory inputs, it's not a bad thing.
1964950	1971897	A	0.87043	Worst case, there's some computational complexity, trade offs, but the problem becomes fully stateable.
1972092	1996625	A	0.91944	But I think ML Dawn is asking about cases where you don't know all of the state spaces or potentially even the dimension or the semantics of hidden states, active states, sensory inputs and why not even add cognitive states?
1998412	2012225	A	0.88226	So in not just partially observed but partially known state spaces, how are these address in neural networks and how does active inference help us think about it?
2017762	2028067	B	0.82	Okay, I think the question is about how can we separate those states?
2028190	2037565	B	0.73804	Like sensory function interface entorhinal, how can.
2037582	2058880	A	0.99688	We separate not just in principle have these states be separated, but deal with the fact that some of these states we might have good knowledge on and some states like the hidden states we might not even know, like we don't know the dimension of the cause vector in the world.
2059077	2060062	B	0.55	I see.
2062525	2091937	B	0.99	In terms of dimension, there is a statistical technique to estimate the dimensionality, for example via information criteria like I agent information criteria, based information criteria, all them try to info estimate plausible dimension about the environmental hidden states.
2093650	2099790	B	0.994	There is an analogy with those information criteria and version of free energy minimization.
2099895	2115200	B	0.65892	So with version of free energy inclination we can identify the plausible model structure which in principle involves the dimension aspect.
2116375	2136937	B	0.84863	But in terms of Neural network in this paper we don't carefully consider about the dimensionality optimization because we first define the number of neurons and don't change during the training.
2137600	2156975	B	0.95479	But in principle we can consider the change in the number of neurons which is associated with the neurogenesis adult neurogenesis or development during the developmental stage.
2157475	2166125	B	0.99	That would be an important expansion of this direction.
2173450	2175187	A	0.59968	That's very interesting.
2175925	2178500	A	0.86307	Here's a remark.
2179000	2187875	A	0.74346	Well, one note is equation one summarizes a lot of what you've been describing.
2188300	2201470	A	0.89847	There's a parallelism or a concordance being drawn between the loss function of Neural networks and the variational free energy of the parameterized model there.
2201622	2225350	A	0.55261	So to come back to these processes that influence learning which we could think of as the Neural network becoming more fit from a loss function perspective or the variational Bayesian partially Observable Markov decision process entity generative model encoding better at doing what it does.
2225487	2235090	A	0.87628	So there's the firing rate on the Neural network side, the synaptic plasticity at a slower time scale which we discussed a little earlier.
2235120	2245250	A	0.86	And then now there's a third time scale with the birth and death of new cells and maybe even new layers.
2246350	2271010	A	0.7	And that kind of multiscale temporal structuring is not intrinsic to the Bayes graph to represent multiple nested timescales in a Bayesian graph in the act of inference literature it's more common to make a hierarchically nested model, right?
2271192	2284365	A	0.95	And just say that the time handling on one level is happening more rapidly with respect to clock time than deeper nested, slower models.
2284545	2303750	A	0.78117	Whereas the Neural formulation allows us to deal with multiple ongoing active states without appealing to hierarchical nesting, which is a very important feature.
2311450	2317237	B	0.65814	Well, both distinctions will be possible.
2317600	2333725	B	0.63126	So without hierarchical or with higher car modeling so even with hierarchical modeling, the optimization of dimensionality should be possible.
2333787	2335162	B	0.49	It would be possible.
2335525	2353470	B	0.69948	But in other distinctions we can consider that a population of Neural models so one has a single layer, another has two layers, three layers, four layers.
2353635	2382787	B	0.96	And consider the probability of network architectures associated with Costa minimization and a particular environment which is in principle have the same computational architectures with the hierarchy model.
2386800	2388462	A	0.94273	Very interesting.
2389200	2410675	A	0.97772	Yes, perhaps I over generalized or speculated because I thought about how one could have a 100 timestep POMDP that also performs multiscale behavior potentially extremely wastefully, but at least it could in principle.
2411100	2422110	A	0.94	And similarly, within a neuron there could be another Neural network or some other structure approximated by that.
2422292	2440900	A	0.78689	So they almost both enable hierarchical and non hierarchical model modeling as you described, but in very different ways that lead to very different implementations.
2444025	2444787	B	0.79544	Yes.
2445900	2452525	A	0.98	I think this brings us to the topic of forward and reverse engineering.
2452950	2457025	A	0.81298	So you talked a lot about reverse engineering.
2458650	2468500	A	0.99562	What is reverse engineering and what is forward engineering and what has been done in these areas of engineering?
2470350	2503212	B	0.91	Okay, I'm not an expert in this process, but I believe that liver here means your characterization of the blueprint of some device or machine from data observable information like activity or action behavior of some agent.
2504400	2523810	B	0.93846	Goal is identification of blueprint and the crucially here blueprint correspond to generative models because once we define generative model, we can Deneve evolution, anthropology algorithm, running inference algorithm and any behavior of the agent.
2523917	2568330	B	0.64021	So here reverse means that we first observe some activity of agent and its mechanism is still unknown for us, but we can estimate its mechanism using that activity by identifying the most plausible guarantee model which can minimize some Costa function or risk function when we feed the data to the model.
2568452	2595250	B	0.76303	So, on the other hand, for the engineering would be more mainstream, way fast defined model blueprint gently model then drive everything including parasite functional running algorithms and behavior action prediction algorithm.
2599875	2615187	A	0.85908	So, by reverse engineering neural networks, we're observing some already parameterized neural network and then fitting a POMDP to it.
2616525	2628250	A	0.95	To what extent is it possible to take a given POMDP and create a neural network that performs that inference?
2632875	2679025	B	0.77	Okay, in this paper or in the following paper, what we consider is a strategy that we first feed empirical data whether force neural response data to BioScale prosper neural network model which is similar to a conventional model fitting approach where we have differential equation data and differential equation to explain the behavior with the minimum prediction.
2679450	2701310	B	0.65388	So now, a virtue of this framework we established is that we can naturally transform such neural network architecture with the very known partially observable markup action process architecture.
2701430	2707962	B	0.98907	Because for any kind of canonical neural network there is a cost function.
2709900	2736612	B	0.50418	So we Deneve cost function through neuroactive decision which is opposite with the conventional way we define cost function derived algorithm and then we use the formal equivalence between neural network Costa function and variant queen energy.
2737575	2761790	B	0.57242	So now transform the journal architecture to Beijing model architectures and once we characterize vital energy, there should be some general that define that informational energy functional.
2761970	2778075	B	0.49666	So in particular, in this example, canon network nicely correspond to well known across macquarlin process.
2778212	2800062	B	0.74964	So, by using this procedure, we identify a plausible home DP architecture which correspond to observed activity data.
2809337	2815200	A	0.62355	Well, let's stay on this last point.
2815862	2842387	A	0.62056	So, after all those transformations, first the measurements of neurons using that data to fit the neural network and then by virtue of the relationships unpacked in the paper, transforming the neural network in the left side of figure one into a particular form of the P-O-M DP.
2842537	2848462	A	0.71567	So first, what are the constraints on that form of the P-O-M DP?
2848612	2855862	A	0.98	Is this a little corner of model space or what are the space of acceptable P-O-M DPS?
2858012	2864037	B	0.58	That totally depends on what kind of neural network model you are considering.
2864387	2879597	B	0.53454	So for example, in this paper we discussed about a particular crossover from DP in which each state takes either zero or one.
2879780	2886862	B	0.70856	So it's very restricted compared to the general form of homedp.
2886937	2922000	B	0.89893	But we consider a factorization so in the sense that although each but we consider a vector of observation, a vector of hidden states where each element correspond to one single one hot vector but as an entire state it can represent high dimension discrete state space.
2923112	2943750	B	0.74	And this architectures nicely correspond to neural network architectures because usually each neuron takes either zero one or some value continuous variable between zero and one.
2944262	3005722	B	0.69869	So we use this association to characterize a particular OMDP which correspond to neural networks, and this follows a particular mini field approximation, approximation or approximation in generative model because we associate posterior belief in this particular homo DP with the neural activity, which means that posterior of action also has a factorization architecture in the sense that we don't fully consider about the second order statistics between neurons activity and activity, which is outside of this poem.
3005767	3006612	B	0.07832	RASM.
3007337	3036600	B	0.61649	So each neuron activity correspond to posterior expectation about a particular element of the state and we don't consider the joint posterior property of all state.
3040700	3076045	B	0.57342	So although this is a implication, we see this Asia impress, but otherwise, for example, we can consider any recurrent network architectures which correspond to state to transition metrics and it would be possible to extend this architecture to higher call structure in the sense that it is straightforward.
3076135	3089830	B	0.99962	Consider a tree structure or any kind of higher car structure by assumptions that some neurons connect to other neuron but not connect to other neurons.
3089890	3096812	B	0.73678	So this is Lamme as considering the higher car structure in general.
3103675	3106837	A	0.5473	That's very interesting.
3108175	3124815	A	0.61908	It's commonly remarked in the base graphs that they represent the connections amongst random variables and there's a relationship between their computability and their sparsity.
3124995	3149635	A	0.98	The sparsity structure as in which variables do or do not influence each other makes the problem tractable through factorization and just kind of conceptually like if every one of a thousand variables or an unknown number of large variables if it was all by all the number of parameters to fit on that connectivity matrix would be very high.
3149742	3154020	A	0.85851	So statistical power would be very low for any given edge.
3154185	3168800	A	0.95045	Whereas the more and more constrained you make the connectivity of the variables, the more statistical power you have to resolve or kind of spend on fitting those edges like in a structural equation.
3169300	3182160	A	0.97329	But you might be losing sight of the unknown unknowns by constraining yourself to a very limited or fallacious topology of the variables.
3182280	3218300	A	0.77873	So there's this kind of structure learning statistical inference question in the Bayes graphs then on the neural side from the biological much of neuroscience is about understanding how the firing rate, connectivity patterns and other factors Hohwy the structure of those neural systems and their function like form and function enable adequate inference and inference on action.
3218875	3229590	A	0.70451	So it's like in both of those areas or really like in neural network artificial and neural networks and in variational.
3229620	3257150	A	0.33951	DAGs the discussion is about how the structure and the fine tuning work together to generate function and about some of the statistical or biological challenges of balancing different needs while also constraining the cost in terms of materials and biometabolism.
3257650	3265537	A	0.61241	So it's a very rich interoception that is being explored here.
3269462	3272787	A	0.94379	If these models can really be moving back and forth.
3278137	3282587	B	0.77	In the sense that back and forth.
3285487	3299947	A	0.99858	Moving back and forth, like there's some imprints of the model that is implementation independent or like some interlingua or some semantics or compatibility, I don't really know.
3299980	3315627	A	0.73	I mean, that's something we can explore is like what is it that is such that one could forward engineer and then reverse engineer and have like kind of an expectation maximization between these two areas.
3315657	3319412	A	0.70348	So what is it that's being solved?
3325087	3371412	B	0.73947	Yes, important point, for example, about you is that we can use the knowledge of Bayesian inference to explain your activity dynamics, which is crucial because people often say that characterizing neurodynamics is no straightforward, we may obtain some solution on your net dynamics, but the meaning of that dynamics in terms of the functional aspect is very unclear.
3371487	3391017	B	0.99903	We don't know the meaning of connectivity strength matrices and what is the learning of the threshold factor, so on and so on those de Vries from the modern physiological phenomena.
3391077	3399702	B	0.91023	But it is not necessary to have clear linkage to functional exploration.
3399882	3403452	B	0.42626	So explanation of function of the brain.
3403557	3426425	B	0.95069	But once we transform translate this dynamics into Bayesian inference, then we can explain every functional aspect of the neural network diagrams architecture in terms of where established Bayesian inference under a particular crossover Bayesian model, in this case palm DP model.
3428287	3440912	B	0.79756	So now it turns out that synaptic strength correspond to a matrix B matrix, which are very established culture meaning.
3441862	3457937	B	0.71228	So yeah, this is useful to explain neuronsynatic property in terms of established statistics.
3464287	3481775	B	0.96118	Also, for the people in active inference lab site, it would be helpful to understand the neuronounce master straight about particular active interface model model.
3483712	3488592	B	0.74279	So I think it related to forward modeling.
3488727	3508100	B	0.92749	But finally to discuss with discuss about the border service rate of that forward model, we need to address the neural network architecture service property.
3508687	3529272	B	0.83296	So in that case, we can transform a particular force DP invasion modeling to a neural network architecture using this relationship and then get prediction about the substrate.
3529317	3547175	B	0.82297	So if we have this based on model, this particular quantity in this model should be it would be possible using.
3554737	3555502	A	0.68	Oh, it's all good.
3555520	3557987	A	0.77744	Can you just repeat the last 20 seconds?
3558637	3559402	B	0.98159	Yes.
3559570	3578825	B	0.62974	So in the last part I mentioned about first we define the Bayesian model and then can predict what is the neural net substrates that correspond to that particular Beijing model.
3579337	3593412	B	0.71696	So this will be useful to identify the biological quantities that correspond to a quantity in Beijing.
3593487	3594125	B	0.36832	Chaos.
3603562	3606050	A	0.54383	There's a lot there.
3606787	3612367	A	0.77	It makes me think about the inference of implementation and.
3612415	3626997	A	0.99184	Heuristics in the computational setting, which is often in the extreme disembodied, and the biological setting, which is in the extreme entirely embodied.
3627192	3662237	A	0.82	And for a given generative model, the kinds of computational heuristics that can be applied include a whole host of different strategies ranging from sampling to tree exploration and branching to paralyzing the data architectures and all these other kinds of disparate strategies and software packages and implementations.
3664387	3686387	A	0.96435	But on the biological side, what is needed is something that's very simple but also very inscrutable, which is a given pattern of interactions must embody that calculation.
3688387	3699137	A	0.6212	So that might mean that it can add three digit numbers, but it can't add two digit numbers under some constraints.
3700837	3720287	A	0.9462	But what isn't accessible to that kind of morphological, biological or like form and functional computing, what's not accessible are the tree branching, the database decentralization, like they're a different set of heuristics.
3721012	3721372	B	0.57	Right.
3721405	3736550	A	0.97779	But they're both very useful when we're thinking about making sentience artifacts or benefiting simply from the explainability across both sides of this figure.
3738562	3739372	B	0.64	Yeah.
3739555	3742762	B	0.82632	So you now address an important point.
3742825	3756252	B	0.71812	So Homistry, it is very nontrivial whether there is a corresponding valve car architecture force any given Bayesian architectures.
3756357	3765927	B	0.98	I believe it is impossible to design biography architectures to respond to arbitrary Bayesian architectures.
3766032	3775422	B	0.58635	So only a limited aspect of region model can be implemented in a vertical plausible manner.
3775542	3782787	B	0.85	And that point is crucial as capitalization of biological network.
3782862	3785237	B	0.16647	Biological brain.
3789412	3789952	B	0.61	Yeah.
3790045	3790567	A	0.78876	Wow.
3790690	3796112	A	0.77317	Well, just to kind of touch again on this forward in reverse engineering.
3798412	3798727	B	0.55183	For.
3798745	3812802	A	0.99	A given POMDP if we're willing to compose it within a certain class, which might be quite general still, but some class of PMDP, as written.
3812832	3813725	A	0.99914	On the paper.
3814912	3830517	A	0.99925	We may be able to have a neural network architecture that would be very amenable to deep learning, low energy computing, pretraining various features.
3830652	3848000	A	0.92	And then on the other side, for a given artificial neural network that we come across in the wild or a model of neural dynamics that we fit using a neural network model.
3848737	3862337	A	0.8918	So something in a neuroscience laboratory that model can have interpretability corresponding to the variables of a given POMDP.
3862762	3872162	A	0.64	And just to kind of give one more point on how that's going deeper than, for example, statistical parametric mapping SPM.
3872962	3883897	A	0.87407	So let's just assume that the neural network we're dealing with is fit from brain data from some lucky Kant, right?
3883930	3908017	A	1.0	Now, what would be possible or prior to this line of work or without this line of work, one could fit a neural dynamics model and then do all kinds of analyses, like power analyses on the different frequency spectra and say, look at the average firing rate or the correlation coefficients of firing rate.
3908065	3914122	A	0.95627	So fit the firing rates and the synaptic Plasticities and store all that data.
3914305	3924237	A	0.74	And then we could just pick a POMDP that we've seen in the literature without any reference to the neural network and optimize the POMDP.
3924387	3935202	A	0.66	And then we could say well, it turns out that when the POMDP o is high there's increased theta power in this firing pattern.
3935382	3947075	A	0.83177	So it's like comparing the descriptive statistics from the neural model to the descriptive summary statistics of the POMDP decision making model.
3947437	3964492	A	0.99914	However, with this formal connection there is actually an interpretability to the unobserved neural states which are what are being inferred from the fMRI measurement, from the EEG measurements and so on.
3964690	3974687	A	0.9992	Those underlying variables have a specific interpretability in relationship to the structure of the P-O-M DP.
3981337	3981832	B	0.67	Right?
3981910	3988937	B	0.49102	So yeah, that's also very interesting important aspect.
3989587	4006467	B	0.50466	So what you said is I think more conventional strategy and it is also formally related to model comparison aspect.
4006602	4018100	B	0.60124	So we usually think various modeling and identify or select what is the best model to explain a given data.
4018612	4051262	B	0.7	And this reverse engineering idea involves such a model comparison aspect in the sense that we try to find the model with the best expandability which should we have the identical functionality, right directory address, the exact same Costa function architectures using the information natural transformation.
4051687	4060025	B	0.97269	So it should be up to explain the neural data in the Bayesian sense.
4062412	4085017	A	0.64	Yeah, one can imagine how that would transform the way that current neuroimaging studies and technologies describe what it is about the measurement that provides information about the cognition model.
4085215	4104062	A	0.6816	So, to give another related example, let's just say a person was wearing an EEG headset and a previous study had shown that increased alphaband activity was associated with this behavior.
4105762	4125362	A	0.91716	That's comparing a descriptive statistic of the observations of the sensor and correlating the summarized observable to some other variable like anxiety or performance on a behavior.
4127512	4149887	A	0.93	In contrast, an unobserved variable in this setting the actual underlying neural state is being correlated to some semantic generative models component.
4151437	4178312	A	0.88112	So it's no longer necessarily that any single frequency band would be associated more or less with a given outcome, but it's actually some hidden state variability which gains the interpretability across this transformation.
4178887	4208687	A	0.99862	Which is a subtle point, but it speaks to how broadly the equivalents would reinterpret empirical neuroimaging results as well as a variety of artificial neural network experiments and diagnostics where people do lesion studies and double knockouts on artificial neural networks.
4211062	4237617	A	0.96202	So anywhere where somebody with awareness sees that a neural network, artificial or biological, is having summary features described and correlated to something that's more semantic in a quest for meaning may now have a different approach that involves formalizing.
4237677	4255037	A	1.0	The model explicitly in terms of unobserved hidden states with a cost function akin to a variational free energy minimizing risk bounding surprise on the Unobservables.
4256362	4276637	A	0.72704	So even though the unobservables were modeled in a sense in the other conventional strategy like neural activity is a variable in fMRI experiments, it's underlying the bold signal.
4277287	4287512	A	0.96361	Yet this formalism concordance is a more coherent and powerful connection.
4295362	4296702	B	0.19353	Lib sold.
4296882	4302787	B	0.65618	So you now address this very important point.
4302850	4314982	B	0.57507	So first to address that so we need to clarify about what is a program, consider here.
4315060	4335042	B	0.61066	So this is a program Socalled metabasian problem in the sense that researchers try to infer or estimate neuro activity or brain activity which infer the external world dynamics.
4335177	4335607	B	0.68	Right.
4335685	4342992	B	0.68179	So neuron or brain environment and we research brain activity.
4343127	4348812	B	0.61989	So there are two step processes.
4348962	4370612	B	0.55057	So this sort of meta Bay is quite tricky intractable because sometimes London variable becomes posterior about other aspects.
4370962	4377432	B	0.57451	So I think there is some established approach about metabolism.
4377522	4404967	B	0.94378	But this paper provides some alternative in the sense that we separate two programs by saying that here what we import is simply neural network dynamics which is shown in the left hand side of this figure.
4405165	4414302	B	0.81765	So we feed data to conventional neural network model which is a simple differential creation.
4414482	4438562	B	0.96229	But thanks to this formal recovery between neural network dynamics and home VP behavior, then we can transform the resulting neural network architectures or dynamics into the page and in force in some sense post Hog mana.
4440487	4454587	B	0.74078	So we nicely avoid the directory addressing the meta agent program but obtain the same kind of solution in that sense.
4454650	4462332	B	0.79019	Yes, with combining with brain activity recording Lieke de Boer imaging.
4462497	4477250	B	0.39	Yeah, we can estimate a plausible neural network model in the right hand side and we can transform that to home DB in the right hand side.
4480537	4481212	A	0.99164	Awesome.
4481350	4487012	A	0.95493	I'm going to show an image and ask a question from Dave in the chat.
4487437	4504562	A	0.83204	So, Dave made this image, it's the right side of figure one that we've just been looking at with the variational Bayesian information and he wrote the arc shown as impinging on the S self arc.
4506412	4508157	A	1.0	Is this intentional?
4508247	4514150	A	0.98431	If so, it could represent tuning or modulation of the feedback of S into itself.
4517587	4519325	A	0.77268	Do you have a thought on this?
4520737	4521942	B	0.34071	It's attention?
4522002	4522672	B	0.91346	Yes.
4522855	4551137	B	0.99	I think it's related to the usual formulation of home DP architecture and active inference concept in the sense that our decision or policy in the usual setting modify the state transition matrix b matrix.
4553662	4560472	B	0.68515	Here, delta is an alternative of policy of agent.
4560580	4573025	B	0.7084	So basically the director indicates stated transition metrics under a particular decision which agent made.
4573987	4582152	B	0.99	In that sense, what the agent changes is state transition metrics, not state itself directly.
4582332	4587062	B	0.9647	That's why we use this illustration.
4589362	4590125	A	0.99309	Awesome.
4591387	4600487	A	0.9992	Very subtle but important point, which is when we look at the classical POMDP formulation.
4600837	4604167	A	0.7477	So here we'll look at a version shown in figure two.
4604215	4606550	A	0.58459	I'll just bring just figure two in.
4609312	4623287	A	0.99839	Could you describe what you just did about the role of the B matrix in influencing how hidden states change and how that is where our policies have impact?
4623637	4629500	A	0.62	And also please, how do the top and the bottom of figure two differ?
4633087	4644432	B	0.66	Okay, so in the usual correlation under active inference with palm DB structure.
4644522	4673537	B	0.58664	So we for us to consider the prior inference and depending on the prior preference, we compute the expect free energy and its minimization provide the policy and the policy moderate state transition.
4674187	4686425	B	0.62611	So now in the upper Brea, we instead use the builder which is the option of the agent.
4687162	4712032	B	0.63757	So here option or decision was made for each timestep so that unlike the conventional formation, we have a sequence of delta and for each time step delta moderates active states cognition matrix B.
4712185	4730462	B	0.81778	So B is a matrix that transformed hidden state in the previous step to the current time step and its moderation indicate that under a specific decision rule.
4731637	4744250	B	0.84723	For example, if this F indicates our cognition in the virtual environment with the Gold decision move forward.
4745287	4751877	B	0.5474	But if we choose the no go decision, then it unchanged.
4751982	4770950	B	0.58424	So such a moderation of state transition was made by choosing debuta and the lower part correspond to Beijing inference made by Bayesian agent.
4771687	4801475	B	0.58118	So basically there is a symmetry between a third part and roar part because we assume that this Beijing agent has a plausible guarantee model which nicely correspond to given environment defined in the above upper part in this figure.
4802062	4844087	B	0.90889	But one interesting thing asymmetry is that to model this particular canonical neural network, we don't consider an arrow or link from delta posteria to S posteria which is in the environment data moderate S in the next step through P matrix moderation.
4845187	4873037	B	0.92	In this particular Bay jets which formally correspond to a canonical neural network, we don't consider that it is correspond to an absence of the projection from output layer to the middle layer.
4879087	4879850	B	0.69	Okay.
4885837	4896162	A	0.99	This is from the 2020 paper, but it shows the neural network architectures, the two layer architectures.
4896312	4914737	A	0.73646	So could you restate the top and the bottom of figure two in the 22 paper and connect it to why it's important that you're studying two layer neural network models?
4915837	4917050	B	0.54	I miss you.
4918162	4934387	A	0.48	Yeah, can you just connect the asymmetry between the top and the bottom on figure two with the two layer neural network architectures?
4935337	4940375	A	0.99	You said that the asymmetry, there's no direct link between.
4947475	4949437	B	0.5	This is another story.
4949800	4972125	B	0.65017	So in the previous paper there is only output or concept layer because we basically consider a single layer feedforward network.
4972200	4983145	B	0.519	So my apologies for some confusion about the network architectures in the 2020 paper.
4983222	5000675	B	0.68685	So now upper part of this network architectures correspond to environmental generative process and only a lower part correspond to single foot feed for neural network architectures.
5001400	5012965	B	0.71096	So now this part is identical to a map from O to S.
5013057	5017625	B	0.18507	OSS area in the 2022 papers.
5023225	5031187	A	0.85	Okay, so on the top of figure two is the actual generative process.
5032000	5047925	A	0.74129	It's the true structure of causation in the environment, which is to say that actions delta actually influence how states change through time via B delta.
5049625	5057150	A	0.97	The generative process through the A matrix emits observations, sequences of observations.
5058100	5070125	A	0.92	And here on the bottom with a mirrored structure is the generative model of the entity.
5070625	5078887	A	0.82668	So what's the relevance of the arrows and the more force factor graph structure on the bottom?
5080675	5088275	B	0.89	The arrow indicates active inference.
5090425	5111680	B	0.59978	So it's a flow of the information in the sense that to calculate in the step two, we use the information of step two conversation and step one's posterior expectation about hidden states.
5111802	5117900	B	0.70968	So those two determine the s two's expectation.
5118625	5135880	B	0.99039	Usually in the following graph, we consider retrospective arrow so in the sense that s three also affect the s two inference.
5135940	5151555	B	0.95356	But this corresponds to Bayesian smoother in the sense that we update every time step simultaneously to better inference.
5151690	5171230	B	0.99786	However, what we consider here is more filtering approach in the sense that for each step we compute the latest hidden states and then we don't change any other states in the past.
5171427	5178712	B	0.94488	So that's why we don't consider the arrow from future to the past.
5182337	5183012	A	0.99774	Awesome.
5183150	5183492	A	0.6	Yeah.
5183540	5206587	A	0.98844	Just to highlight that in the Bayesian smoothing approach, it's kind of like fitting a spline because it takes the whole time series and it fits the smoothest possible line or the line whose smoothness is on the AIC BIC frontier.
5207612	5227362	A	0.91235	But here on the bottom with the almost pseudocode implementation provided by the Force Factor graph, which was demonstrated to be equivalent with the Bayesian graph in the 2017 work with Friston, Par and de Vries.
5228237	5253150	A	1.0	This architectures is reflecting a filtering scheme like a common filter or just generalized Bayesian filtering through time, where estimates are being carried forward and changed time point to time point, such that the decision rules, or the updates perhaps more accurately, are defined between time points.
5253662	5261567	A	0.98	And the total time series does not have to be loaded into memory or remembered at once.
5261765	5272362	A	0.86	And then the Bayesian filtering approach has the asymmetry with a different consideration of action.
5273987	5287875	A	0.91019	So why again is it that action is considered differently in the Bayesian filtering approach on the bottom of the generative models than the consideration of action in the generative process.
5291162	5302125	B	0.76	That correspond to lack of cognition from Y to X in the figure one?
5303387	5312100	B	0.87	Or probably a figure four is helpful to that relationship.
5317487	5318250	A	0.8	Four?
5318762	5319392	B	0.62	Yeah.
5319515	5327237	B	0.88	This is an example network architecture comprising input Brea, output Brea.
5327375	5340907	B	0.98267	What we consider is information flow from sensory to middle Brea and middle area have a self connection, recurrent connection and middle area project to output layer.
5341072	5347812	B	0.698	So there is no connection from all output layer to middle layer.
5348387	5349150	B	0.56	Right.
5350412	5365362	B	0.65968	So that's why we don't consider the link from data in the bottom layer of the figure to posterior.
5367062	5374662	B	0.70969	So this is different from true generative process in the environment.
5377975	5380500	B	0.99	This is a kind of simplification.
5380650	5394650	B	0.59161	So because our purpose is identifying the plausible Bayesian model which correspond to this type of neural network canonical network.
5396200	5417300	B	0.66701	So in other words, this neural network uses approximation about that point or use limited form of palm DP scheme.
5423700	5424555	A	0.98217	Thanks.
5424752	5433170	A	0.79612	So could you describe W-V-K and Gamma?
5433335	5439925	A	0.85821	Just what is the biological or functional interpretation of those variables?
5440800	5445837	A	0.98924	What brain regions or what processes or pathologies do they map to?
5447025	5459862	B	0.91	Okay, so basically, WVK, synaptic strength is in the form of matrix and active inference.
5464875	5493215	B	0.96217	They represent connection in the different layer or different architectures in the sense that W means forward connectivity from sensory Laje to middle Laje, k correspond to recurrent network recurrent connectivity and V correspond to projection from middle Brea to output layer.
5493395	5534200	B	0.83598	So in this paper, we don't discuss the relation to brain anatomy in detail, but what one can consider analogy, for example, say x corresponds to several cortex activity and Y, for example correspond to cerebral wrong in the sense that it determines the action.
5534625	5542820	B	0.69167	So it is considered that in the cerebrum there is a signal that represents choice.
5542910	5549200	B	0.5	This is joined for examples goal no go decision made in cergram.
5551575	5557550	B	0.629	It's analogous to this particular architectures.
5557700	5582615	B	0.98627	On the other hand, in the several cortex we compute the sensory information to generate some inference, prediction and planning the way it is computer by this recurrent network.
5582720	5626750	B	0.98	In this particular modeling, although we don't separate brain region in detail, but this recurrent network is sufficient this graph of recurrent network is sufficient to characterize any type brain architecture in the sense that we can design any higher car or mutually connected architecture using a generic crossover recurrent network by changing weight.
5634750	5635470	A	0.99127	Awesome.
5635622	5642187	A	0.87266	So the middle layer we can think of as like the cognition stuff.
5642625	5656300	A	0.71402	It's the internal states when we talk about perception, cognition, action in the active scheme or even in the sandwich model of cognition, perception, cognition action.
5657250	5678100	A	0.72832	So W is describing how those sensory inputs either in one step or composably in multiple steps become processed to these internal representation of hidden external causes inferred external states.
5678162	5688240	A	0.63	And so these are the states that have that sigma relationship and a generalized synchrony with external states.
5688407	5706550	A	0.98	The sigma and the generalized synchrony are not discussed in your paper, but it connects to other work and the recurrent connections are facilitating attention or waiting of the stimuli.
5708250	5716450	A	1.0	This is the recurrent learning loop and the relationship of the A between observations and hidden state estimates.
5718225	5729645	A	0.91	And then a different kind of modulation comes Hinton play between the hidden state estimate of the internal states state and the action selection.
5729810	5734410	A	0.89224	So what is gamma corresponding to?
5734442	5746812	A	0.93	And why is the gamma modulation between layers two and three differing functionally from the k synaptic modulation of one and two?
5747850	5758490	B	0.67	Yeah, so K matrix basically formally correspond to B matrix in the Bayesian information.
5758595	5774037	B	0.74325	So we rotate the information about the prediction, right, our narrator or our expectation about the next state based on the previous state.
5774775	5782550	B	0.94555	On the other hand, Laurel gamma is quite different from such a computation.
5782625	5796330	B	0.86366	Gamma basically means risk function, which is in principle can we use arbitrary risk function.
5796452	5833587	B	0.58071	So this is a part of generative models we designed and the rule of risk function in generative model formulation is attention form of generative models depending on that value of gamma which examples retrospective moderation of evaluation of task decisions given an outcome in the future.
5835225	5841485	B	1.0	In terms of neural network, of course it corresponds to some neural modulation.
5841605	5854580	B	0.77036	For example, Dopaminergic moderation is famous in the literature which moderates the activity and fluxicity of various brain vision.
5854640	5870950	B	0.86998	But we particularly focus on Dopaminergic or any kind of neuromoduration of cyanogic prosthesis in the output trigger which may correspond to Cergram.
5871525	5905362	B	0.67126	So in the Serbram neural activity or processes moderated by Dopaminergic, input from is used as the optimization action rule, decision rule or sometimes attention help us.
5909212	5909797	A	0.97696	Awesome.
5909905	5925817	A	0.99936	Very interesting because in some previous papers and models that we've looked at, attention is dealt with as policy selection on mental states.
5926015	5936012	A	0.87948	So internal action selection, it's an action like variable describing attention and awareness and even metacognition.
5936737	5967962	A	0.69	And so that connects the role of Dopamine in motor decision making seen in many Dyskinesias but also with the role of Dopamine in seemingly nonmotor based decisionmaking like gambling or investing where it doesn't seem to immediately translate to a given motor sequence.
5968912	5990877	A	0.83835	Yet it has analogous computational characteristics and the comorbidities and the side effects of different drugs that affect the Dopamine neurophysiology are known to have carryover in terms of like the rigidity or excessivity of motor and decision making aspects.
5990907	6019337	A	0.86092	So it's like interesting that Dopamine has long been understood to have that parallel role in attention as cognitive action and motor action and that was established empirically through modifications of Dopamine signaling and also had been modeled analogously with computational neuroscience.
6019687	6035900	A	0.84	And this is providing again a slightly different interpretation of that very well studied Dofaminergic modulation of attention and policy.
6040837	6041600	B	0.8773	Yes.
6043462	6051887	B	0.78	In addition to that, I believe another important aspects is correlation of scientific processing by document.
6075850	6078937	A	0.61029	Do you want to show something or yeah.
6080875	6085387	B	0.99683	Can you see this paper?
6087475	6091325	B	0.55	I sent you a chat.
6092275	6096275	B	0.96724	If you can't, I'll send you a PDF.
6097450	6099037	A	0.91	Okay, let me see.
6100300	6102412	A	0.63115	I'll look at it up now.
6107425	6107980	A	0.91	All right.
6108027	6122460	A	1.0	The paper is a critical time window for Dopamine actions on the structural plasticity of dendritic spines from 2014 byagasha.
6122580	6125155	A	0.66269	So what is interesting about this paper.
6125352	6154395	B	0.65	Yeah, it basically explained conversation of plasticity by Dopamine, which is common but crucial point of this paper is that it shows that it proved that Dopaminezic input can moderate after hebion prosthesis is established.
6154485	6170190	B	0.65474	So this paper showed that they add domain logic input for about 2 seconds after or several seconds after the Hebbian process is established.
6170220	6194520	B	0.82213	But such a post hoc moderation, post hoc introduction of heterotopamagic Impetu is sufficient to change the past capacity which may be associated with the Costa hoc evolution of our past decisions.
6194610	6205180	B	0.52774	So by decision making we of course changes the changes the weight matrix by through trust 50.
6205377	6221000	B	0.87003	But to evaluate the goodness or badness of our decision, we need to see observe the future outcome which is propagated by for example, Dopamine.
6221425	6245437	B	0.56	And this paper nicely show empirically that Dopamine actually can change the past evaluation, maybe after such a psychic level, very local level, ecoscopic level.
6252250	6263520	A	0.85886	So there's a short term window, the critical time window that they're describing.
6263610	6265935	A	0.95887	But there's some window.
6266130	6278605	A	0.36	Yeah, some window by which dopamine potentially unrelated to the initial heavy and plasticity events, right.
6278727	6302662	A	0.69533	Where secondary dopamine signaling or not secondary just after the initial fact, potentially of a different valence or the same valence can synergize or cancel the plasticity formed in the moment.
6303100	6303862	B	0.9436	Exactly.
6305425	6312862	B	0.7	And this is not limited to Dopamine, but other neuro moderator can also do this.
6318250	6325110	A	0.88741	Well, on one hand, how does this change our understanding of animal neurophysiology?
6325305	6333575	A	0.94	And then I guess, on the other hand, how does this influence how we would design sentient artifacts.
6342625	6351112	B	0.92198	For both animals and artificial agent?
6353350	6357820	B	0.7	One important message I free with us.
6357972	6366275	B	0.77062	So this tells us possible simple architectures to make learning.
6367900	6396037	B	0.99	This is association between past decision and future reward or any risk factors, which is otherwise computed by computing forward prediction by iterating some computational, this is a usual way to predict the future event and then select the option.
6396475	6415100	B	0.91799	But using this property, biological property, which is observed in experiment, we can design, we can imagine other simpler architecture to make a planning.
6417250	6440600	B	0.7134	So for both animals and synthetic Bayesian agent, it provides an alternative explanation about the association between our past decision and the future risk and the optimization of our decision to maximize, reward or minimize risk.
6445075	6457335	A	0.91343	Well, one interesting note is we spoke earlier about the difference between the Bayesian smoothing all at once approach and the Bayesian filtering step by step approach.
6457530	6466120	A	0.85	Now, if one had infinite knowledge and computational resources, the Bayesian smoothing approach is the way to go.
6466272	6469455	A	0.78991	Like, you don't want the decision rule for investment.
6469590	6476940	A	0.92	You want to look at the whole time series past, present and future, and know the best moments to have made the trades.
6477045	6478500	A	0.8	I mean, there's no comparison.
6478575	6481515	A	0.96121	You're going to do better with the Bayesian smoothing.
6481695	6489640	A	0.99979	However, it's just implausible computationally and because it requires total memory of the past and knowledge of the future.
6489807	6501037	A	0.87672	So that's what motivates the development of Bayesian filtering approaches, which are tractable and calculable through time.
6501775	6505625	A	0.99969	Yet with this time delayed modulation.
6507400	6507895	B	0.99664	Part.
6507972	6512662	A	1.0	Of the Bayesian smoothing strength comma back into play.
6513850	6523537	A	1.0	It doesn't enable true anticipation of future states, but that's what the expected free energy does.
6524650	6531712	A	0.99981	However, the delayed neuromodulation allows for reconsideration of a window of past states.
6532525	6548900	A	0.74	And so in that way it corresponds to like a slightly deeper filter, not just a filter of a time step of one, but a filter of like a rolling window of five or with some decay.
6549550	6562837	A	0.87	And you don't want that window to be too big because if the window were ten minutes, then too many contrasting stimuli would get piled together.
6563350	6567050	A	0.95	The Dopamine level would just converge to a mean field average.
6567400	6582412	A	0.97802	But there's some time decay or time constant on the post hoc modulation where that neuromodulatory signal is actually a parameter of interest.
6583000	6591787	A	0.91	And that's not an infinitely long or infinitely short window, but it's some niche dependent amount of time.
6592450	6610920	A	0.66	And that's a very interpretable and first principles interpretation of the computational role of neuromodulators in a way that is also consistent with all these other concordances we've been exploring.
6611085	6622400	A	0.619	So it's quite an interesting connection back, I guess, in our final minutes of this discussion.
6626850	6627987	A	0.67372	What are you?
6628725	6653800	A	0.77818	Well, maybe go to the beginning at the end, which I meant to ask earlier, but it's a good way that we can sort of close today and look forward, which is how did you come to this line of research specifically studying neural networks in this way with Karl Friston and your colleagues?
6658275	6677915	B	0.42795	So, yes, so my interest was the characterization of Barricade network.
6678095	6687155	B	0.78059	So my first motivation is to make biologically plausible artificial intelligence.
6687215	6695725	B	0.81674	But to achieve that, we need to know about biological brain or biological neural networking.
6701100	6716725	B	0.54	In these several years, I collaborated with the doctor professor Californiston to study about his salary principal after doing forest.
6721125	6749390	B	0.73057	My question during that period was the priority principle, is everything about the biological possible neural network or is there another aspect that can characterize the virus car neural network?
6749495	6752350	B	0.68284	So it is non trivial.
6753150	6755015	B	0.61	It was non trivial.
6755195	6767130	B	0.70782	So that's why I tried to start from characterizing the neural network first.
6767327	6796887	B	0.62316	So our strategy is not considering the way of implementing any Bayesian algorithm as the brain architectures, but my interest is rather characterization of a given vertical network in terms of some other things.
6797400	6803200	B	0.99	One possible way is of course based on inference free energy transplant reinforce.
6803550	6809425	B	0.66567	So that's why I start from characterizing power's network.
6810675	6818575	B	0.65633	But just defining neural network architecture is insufficient.
6821625	6833675	B	0.58	It is not tractable, it is far beyond the computational tractability as the mathematical analysis.
6833750	6843400	B	0.88	And we need some assumptions or some trick to increase the tractability.
6844500	6865580	B	0.64	One day I came up with an idea that in which we consider that both new activity and fastest follow the same cost function gradient.
6865715	6877295	B	0.99	This is very much an allergy with physical system like Lagrangian information geometry, Hamiltonian formation.
6877385	6899435	B	0.76372	So usually we consider some energy landscape and design plausible trajectory as the evolution of some principle of minimum action or restruction.
6899630	6929575	B	0.83048	So we imagine that what if we applied such idea to computational neural network or biological neural networks to characterize their dynamics in the first principle, that's the first computational step to come up with this framework.
6931425	6958335	B	0.75	And finally we noticed that it is not easy to connect the Newtonian dynamics with this type of neural activity study because neural activification not necessary to be a second order differential equation, but rather it is fast order and considering many things.
6958442	7003675	B	0.59758	Then we finally use a Costa function proposal in the papers, which is not necessary to have a former identity with the so called lavalier in the Newtonian physics, but it is rather plausible as the rule or underlying mechanism of such type of network.
7011800	7012562	A	0.99249	Awesome.
7013525	7019810	A	0.95628	Well, it has been quite an interesting dot one.
7019992	7024487	A	0.98	I really appreciate everything you've shared today.
7025075	7027280	A	0.97	Is there anything else you want to add at this point?
7027327	7028912	A	0.55513	Otherwise we'll talk again.
7030325	7036050	B	0.68	Yeah, I already speak a role.
7037675	7038485	A	0.99959	Thank you.
7038592	7040675	A	0.8978	Alright, talk to you later.
7040737	7041450	A	0.56393	Bye.
7042325	7044400	B	0.99798	Thank you very much for a nice discussion.
