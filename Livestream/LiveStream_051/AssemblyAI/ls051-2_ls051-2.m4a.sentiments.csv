33087	34897	A	0.915437638759613	Hello and welcome everyone.
35080	38497	A	0.9143355488777161	This is ActInf livestream number 51.
38605	39322	A	0.569148600101471	Two.
39505	42350	A	0.9062787890434265	It's November 9, 2022.
43162	45807	A	0.6419978737831116	Welcome to the the active inference institute.
45972	53427	A	0.506173849105835	We're a participatory online institute that is communication, learning and practicing applied active inference.
53607	60350	A	0.4953252673149109	This is a recorded and an archived livestream, so please provide us feedback so we can improve our work.
60712	75962	A	0.846643328666687	All backgrounds and perspectives are welcome and we'll be following video etiquette for live streams, head over active inference.org to learn more about participating in different institute projects.
76912	83137	A	0.8834777474403381	Alright, well, we're in act imp stream number 51.2.
83275	86407	A	0.8846859335899353	We're in our third discussion on the paper.
86485	91942	A	0.9181711077690125	Canonical neural networks perform active inference from 2022.
92140	97962	A	0.880913496017456	We had a dot zero video with some background and context and overview.
98112	109557	A	0.9833967089653015	And then last week in 51.1 we had a great discussion, went over many interesting details of the paper and related topics.
109722	121700	A	0.8043875694274902	So today we're going to jump in, cover some empirical details, some implications, connect some more dots, maybe look at some code.
122362	126437	A	0.894739031791687	And thanks again to Kuya for joining these discussions.
127537	157937	A	0.8209903836250305	I'm Daniel, I'm a researcher in California and thought a lot over the last week about what this kind of neural network synthesis or translation really means, and just want to learn more about what fundamentals or foundational aspects of these different kinds of models enable that synthesis or translation.
158287	166657	A	0.8525769710540771	And then again what that means for areas where one or the other kind of model is already in use.
166810	181175	A	0.8951334357261658	So thanks again for joining and I'll pass it to you if you want to say hi or give any a second interoception.
182875	188600	B	0.7808510661125183	Oh yeah, I'm appearing Brain Science Institute, Japan.
189175	199687	B	0.9167478680610657	So I look forward to discuss another different aspect of this work.
203200	219112	A	0.8788914084434509	Well, let's just remind ourselves of the fundamental parallel being made in the paper and then we'll get to these two questions about kind of the two directions that things can go.
219925	230505	A	0.8759685158729553	One representation is in equation one with loss function of a neural network and the free energy on a POMDP.
230640	242640	A	0.8913002014160156	And that's also seen visually in figure one, with a neural network being drawn a concordance against the variational base of the action perception loop.
242745	246650	A	0.7809924483299255	So maybe just let's begin by restating.
247000	256912	A	0.9178688526153564	What is this parallel that is in equation one and figure one and how was it reached in this paper?
259375	298550	B	0.682417631149292	So basically idea here is that we derived to characterize the dynamics and activity of canonical neural network in terms of Bayesian inference, because arbitrary dynamics of neural network is interoceptive in the sense that we don't know what is the function underlying such a dynamics and what is the coherence of the self organization or activity.
300100	323900	B	0.5945028066635132	So once we translate that dynamics in terms of Bayesian, we can assign quantities in Bayesian for any biological quantities, which enables us to lend the explainability to the neural network dynamics and architectures.
324250	326620	B	0.7233219742774963	So that's a basic idea.
326772	341325	B	0.8595117926597595	And what we have done in this paper is that we consider a biological plausible cost function for this particular canonical neural network.
341400	353587	B	0.8936582207679749	And show the equivalence between that Costa function and the variation navy energy and the particular partially observable cognition process model.
357850	358660	A	0.9184247851371765	Awesome.
358842	368410	A	0.8910495042800903	So let's look at the parallel between the cost function for neural networks and the informational free energy.
368592	373060	A	0.8860763311386108	So one representation of that was in figure three.
373242	385537	A	0.8862543106079102	So maybe could you just describe what is the structure of the informational free energy expression and what is the structure of the loss function?
386950	402562	B	0.8432716727256775	Okay, so there is a clear parallel between the functional structure or those component in informational free energy and component in neural network Costa function.
403000	418850	B	0.8434630632400513	So let's say the first time in F correspond to the it correspond to the expectation about hidden states is a hidden states Australia.
419950	429550	B	0.8839160203933716	So that part basically indicates the free energy with respect to the hidden state.
429612	439155	B	0.8516812324523926	Yeah, and the second part correspond to the free energy about the decision posterior.
439290	446525	B	0.9009406566619873	So the indicates the posterior belief about agent decision or action.
448300	494525	B	0.9099044799804688	And now in terms of the correspondence between the free energy and neural network function here the first time in the neural network function correspond to middle layer neural activity which has a recurrent connection and receive sensory input from sensory layer and then project the output to the output layer and the second term correspond to output layer which receive signals from middle layer and send the feedback response to the environment.
505037	523287	A	0.8846842646598816	So both of us expressions have the first term being more like a cognition perceptual sensory learning term and the second term is more like a control theoretic action selection.
523787	535275	A	0.6338359117507935	And how did you see this analogy or concordance because it looks like a zipper, like everything is totally lined up.
538137	563427	B	0.8406330943107605	Well, this graph itself showed a clear correspondence because now we are considering a particular form of on DP in which each element of hidden states takes either zero or one.
563595	574987	B	0.8623151779174805	But there are many states so it is expressed in a form of factorization.
575712	584597	B	0.9076880812644958	So now we consider that in terms of the s fosteria Bordeaux.
584792	600672	B	0.8477795124053955	Upper part of Bordeaux correspond to the expectation about each element of s taking one and lower part of the bordese correspond to the expectation about s taking zero.
600780	648637	B	0.8194005489349365	So it is broke vector about the posterior expectation and this nicely correspond to the Brea vector shown in the bottom up this figure it is a vector of x and Bijan sorry it is a vector of x and by x and here by x indicate one minus x in the element y sense which is exactly correspond to block vector or expectation.
650412	658987	B	0.9243286848068237	This correspondence also observed in the second tab.
659562	675792	B	0.8959628343582153	Here, log S correspond to log X and also log A correspond to the broke matrix of W log W.
675990	689500	B	0.8773208856582642	Here W hat indicates the sigmoidal function of W and its bar means sigmoidal function of W.
690237	705262	B	0.862446129322052	So actually, because we now consider binary hidden state and binary observation it's like reviewed mapping.
706137	718600	B	0.8686086535453796	Mapping from hidden states to conversation is expressed as block matrix, which is exactly correspond to broke matrix shown in the bottom of this figure.
724775	735225	B	0.872306764125824	So like this, for every tab we have the exact correspondence between the upper expression and the lower expression.
737825	747525	B	0.7342366576194763	So that's why we can say that this is a natural mapping from neural network formation to parishional vision formation.
751137	758812	B	0.867958664894104	So it speaks a sort of identity between those two different expressions.
760062	774712	B	0.8329108357429504	So although 1 may be able to consider another mapping from neural network to Bayesian inference, this is a sort of simplest mapping.
777012	785972	A	0.8572041988372803	So how would it look different if it were three states categorical distribution or a continuous distribution?
786092	788650	A	0.8671097755432129	What aspects would change?
789462	792267	B	0.784842312335968	Thank you for asking that.
792315	813167	B	0.4997362792491913	So that's in some sense outside of this paper because only when we consider a binary hidden state, this analogy is established nicely.
813302	818212	B	0.7056076526641846	Otherwise we need to consider some attention.
818862	849632	B	0.8509541153907776	So because consider that each neuron code the probability or expectation of some value taking one, then the probability or expectation of taking zero can be simply computed by computing one Ines neural activity.
849722	859997	B	0.8189077973365784	So actually neural activity which is a single dimensional variable is sufficient to express the expectation.
860192	860817	B	0.7360090017318726	Right?
860940	871287	B	0.780863881111145	But once we consider the three state hidden states program, this doesn't work.
871350	886150	B	0.5985119342803955	So we need to consider at least two variables but it's relation to neural network expression is not very clear in general.
891987	909562	A	0.6707429885864258	That's very interesting why it would be so strong of a concordance in a binary case but immediately unclear for other distributions.
910737	940000	B	0.7614699602127075	Yeah, generally for poem DB expression we consider the one hot expression, one hot vector expression which means that we normalize the value in the sense that the summation of all variable to be one.
941562	947177	B	0.8679811954498291	Maybe there is some neural substrate that achieve that communication.
947357	964062	B	0.6821204423904419	But for classic type of neural network like canonical neural network, consider in this paper what is that neural substrate is not very clear.
964200	973537	B	0.5315683484077454	So that's why we selected the binary case because it's simple and have a clear analogy.
974637	988537	A	0.8816662430763245	So what does it mean for an artificial or for a biological neuron to have activity dynamics or plasticity context?
989487	998662	A	0.8436745405197144	That justifies it being described as playing like a belief role in a Bayesian setting.
1001625	1005620	A	0.717744767665863	Higher firing means more belief, higher firing means lower belief.
1005710	1011537	A	0.7893902063369751	What does it really mean to have a connection between in this episode of street talk belief states.
1012200	1022780	B	0.8491862416267395	I see, so if you assign a mapping, a particular mapping, then its meaning is also determined.
1022915	1036680	B	0.8992375135421753	In this case, we assign that neural activity correspond to the posterior expectation about an element of hidden states taking one.
1036877	1046037	B	0.6959911584854126	So once we define this mapping, then higher neural activity indicates the higher probability of taking one.
1052362	1065575	A	0.9135509729385376	So neural activity is the probability neural activity is on the x axis and the y axis of the sigmoid function is the probability of taking one.
1067362	1068125	A	0.6177208423614502	Well.
1069837	1074662	B	0.6659923791885376	Neural activity encodes the expectation.
1075012	1080725	B	0.8599506616592407	So neural activity is sigmoidal function of something itself.
1088487	1104287	B	0.8989236354827881	This is because once we see a fixed point of neural activity equation which is derived from this cos function, it has a form of sigma WADA function so x equals sigmawilder function of graph, graph, graph.
1104437	1120687	B	0.8800820708274841	So this form is exactly correspond to softwaremax function of something which is seen in the solution of possibly expectation.
1126600	1136300	A	0.8664458990097046	That'S what the neural activity encodes and what is the Bayesian interpretation or the update rules on the plasticity.
1137775	1142215	B	0.5489124059677124	Okay, that's another important point.
1142382	1167425	B	0.9180231094360352	So in terms of posture of parameters so in the case of Bayesian force us we consider update about deleted parameters of a matrix and B matrix which is usually expressed by the small case variable.
1168525	1215650	B	0.810090184211731	And its meaning is that if we compute the partial derivative of a partial derivative of F with respect to small A then its solution it's fixed point solution looks like an computer product of which is also known as Hebbian product because it has an errors drink to update depending on the precinaptic neuron activity and postsynaptic neuron activity.
1216075	1264775	B	0.901137113571167	And according to this formal equivalent we revisit we can see again such analogy in a formal sense here if we computer the partial derivative of neural network function with respect to W then we can formally derive the Hebbian prosthesis which depends on the activity of prey and postsynaptic neuro activity.
1268337	1276975	A	0.8582319617271423	Okay, so hebion plasticity often described as neurons that fired together, wired together.
1277562	1288975	A	0.9132980704307556	Here you're discussing it in terms of a matrix operation on the POMDP side between observables and hidden states.
1289937	1304425	A	0.7299358248710632	So there's a hebion plasticity happening between the perceptual layer and the cognitive layer, right?
1304787	1325062	A	0.8283446431159973	So the first half of the neural network is trained according to heavy and plasticity rules that optimize the A in terms of the perceptual and learning like relationship between hidden states and observables.
1326387	1333012	A	0.8977196216583252	And then the second half of the neural network has a slightly different structure.
1333812	1350337	A	0.8480843901634216	It is optimizing based upon retroactive re analysis of consequences of action according to the fictive causality construction.
1353387	1365582	B	0.8888694643974304	So actually in this figure b up layer correspond to environment and lower part correspond to agent.
1365660	1374587	B	0.8999436497688293	So this structure corresponds to figure eight, this correspond to a simpler version of foam DP.
1374662	1392475	B	0.917808473110199	So for version of POMDP, its corresponding neural network is showing figure four or this paper image task.
1393575	1396750	B	0.8366572856903076	This is the neural network architectures.
1402712	1426657	B	0.9136355519294739	So as you say, there is a network connection from sensory layer to cognition layer which is expressed by W here and recurrent connection which corresponds to state transient matrix is expressed by K matrix which is recurrent Sinematic connectivity.
1426747	1449225	B	0.9205695390701294	And as you say the action generation through retrospective reward or risk evolution is done by output trigger through the synaptic connectivity expressed as V in this figure.
1451087	1461150	A	0.8945498466491699	So V is the synaptic connectivity between cognitive states in the middle layer and the action selection states in Y.
1461587	1461947	B	0.5662814974784851	Exactly.
1461980	1465275	A	0.8236761093139648	And so in that way V is exactly analogous to W.
1465637	1472017	A	0.6523274183273315	But why and how does gamma come into play only in this second layer?
1472077	1474747	A	0.759899377822876	I mean why not have gamma one in the first layer?
1474792	1476612	A	0.8486695289611816	Gamma two in the second layer.
1478987	1491997	B	0.6776148080825806	Generally speaking, it is possible to moderate plasticity in first layer using another moderator gamma.
1492117	1498512	B	0.8457545638084412	But for complexity we focus only on neural modulation in the output layer.
1499237	1543137	B	0.868217945098877	Analogy is that for example, as you said, the first rigor computer more perceptual things so perception of external world and instead on the other hand middle secondary which is mapping from cognition layer to action layer perform the optimization of its own action.
1543487	1559412	B	0.8091752529144287	So for example, in the story item in the brain action prediction is optimized by conversation of dopamine as a input.
1559837	1581382	B	0.9266730546951294	So usually that socket receives signal from ecological neural socket and send signal to another neuronal nucleus in meat grain.
1581547	1592932	B	0.8569225668907166	But the point here is that neuron in storatum encodes some decision for examples goal or no goal.
1593022	1596237	B	0.7761255502700806	So such a decision is encoded.
1596812	1622917	B	0.8867533802986145	So now we consider analogy between pond DP expression in the Bayesian formation and neural socket in the brain that optimize action through some sort of moderation by another factor.
1623052	1638452	B	0.8720753788948059	Here that factor corresponds to gamma and gamma has variety of function.
1638545	1645287	B	0.7249982357025146	But in this paper we focus only on the moderation of activity.
1646387	1672117	B	0.9051691293716431	So here the behavior activity is not determined by only a preposter relationship but determined by three factors relationship in the sense that the activity is updated by the product of gamma and prayer and postsynaptic activity.
1672252	1675950	B	0.8088091015815735	So there are three times in one.
1678037	1682487	B	0.661044180393219	This is why this comma can moderate prosthesity.
1686150	1692515	A	0.8469046354293823	So how would a glial factor look different computationally?
1692695	1700937	A	0.7355949878692627	And where in the brain have people identified levels or other factors as relevant for learning?
1702200	1704975	B	0.7928861379623413	Yeah, that's an interesting point.
1705112	1713665	B	0.5757677555084229	I'm not really sure about the equation of the real moderation of neural activity or plasticity.
1713770	1734590	B	0.6739489436149597	There are many discussions and I'm sorry, I don't know the exact form, but one possible implementation is similar to this type of neuromodulation.
1734695	1758700	B	0.7635027766227722	So it would be possible to model some real contribution or free factor to plasticity in the form of three factor learning room which is mathematically speaking Lamme as this type of neural moderation.
1763750	1769175	A	0.910452127456665	Here in table two we have another set of correspondences.
1769825	1773500	A	0.8651807904243469	It's like a sideways figure three, right?
1773637	1776225	A	0.7828643321990967	But a little bit more like a dictionary.
1780862	1782017	A	0.8329665660858154	Anything to add?
1782065	1784925	A	0.6732327342033386	Or any variables that we haven't really mentioned.
1786712	1788622	A	0.8074755072593689	What about the firing thresholds?
1788667	1808112	A	0.7083699703216553	Because these are common parameters in a neural model, however, we don't really hear about the interpretation of these constructs within the variational base POMDP.
1809587	1815075	B	0.8415846824645996	Yeah, there is an interesting story.
1817462	1820087	B	0.9275079369544983	That's a very interesting point.
1820150	1847412	B	0.7373918890953064	So when we first tried to make analogy between neurons network and one program is the law of threshold factor because as you said, it is not absorbing POMDP structure.
1847762	1864812	B	0.8911253213882446	But there is another factor in Pompey which is prior expectation about hidden state which is usually expressed by D matrix.
1866062	1875007	B	0.8363075256347656	And what we consider is the relationship between d matrix and firing threshold.
1875172	1906437	B	0.8793839812278748	And finally, what we found is that firing threshold is not equal to the matrix itself, but it is a summation of B matrix under some function of synaptic strength or which is equal to a matrix b matrix in the POMDP formation.
1906787	1942787	B	0.8111426830291748	In other words, what we found is that each which is a firing solution in neural network architecture, it is actually an adaptive threshold which is not a fixed value, but h is a function of W sinatic strengths and h changes depending on W's value.
1942850	1950982	B	0.6941880583763123	For example, if W is too Laje, then your activity can be unstable.
1951072	1961262	B	0.7506232857704163	So h behavior to reduce the activity to make neural activity more stable.
1961837	1968450	B	0.8968492746353149	So we can see an analogy of omeostatic mechanism here.
1975562	2009887	B	0.8673720359802246	If we design A as the function of w and function of another factor which is all part of the term in this table, then we could make common analogy between this h and some variable in palm DP correlation which is shown in the right hand side of this table.
2010037	2018677	B	0.732941210269928	Although its value is not simple because it chaos three different tasks.
2018707	2025900	B	0.8488298058509827	So all of them contribute to make h or M.
2028662	2041412	B	0.6271663308143616	But anyway, once we map, so once we establish a mapping between h and this value, then everything works.
2041550	2050212	B	0.827213704586029	So the cost function in different settings have Omar correspondence.
2054462	2057562	A	0.7778598070144653	H and the M firing thresholds.
2057987	2072752	B	0.903508186340332	So H correspond to middle rare M indicator output raider threshold which are different variables.
2072932	2098737	B	0.7764171957969666	And interestingly h correspond to prior expectation about hidden states because it corresponds to community rare and M correspond a priori belief about its own action because it is a bias in the action layer.
2100437	2122622	A	0.6944032907485962	Yeah, it's very interesting that the perceptual firing threshold h only includes prior beliefs on hidden states, beliefs about how observations map to hidden states A and beliefs about how hidden states change their time B.
2122805	2126562	A	0.667015016078949	So that's like pure passive inference.
2127212	2140097	A	0.8820340037345886	And then the firing thresholds for M correspond to only beliefs about preferences and beliefs about actions or habits with C and E.
2140280	2157462	A	0.6888619661331177	So there's like a complete division of labor or partitioning functionally between these structurally different parts of the neural network and structurally different and functionally different parts of the POMDP.
2159162	2167662	A	0.8274238109588623	Yet they're integrated in unified loss functions or unified imperatives.
2170037	2188662	A	0.7322137951850891	And so it's like there's extreme separability of perception and action on both sides of the figure one divide, but also they're integrated, but they're separate.
2189462	2198187	A	0.6236479878425598	And that's what kind of grants it the best of both worlds because if they were any more integrated you couldn't really pull them apart.
2198612	2209662	A	0.6312761306762695	And if they were any less integrated then the imperative, the loss function or the variational free energy would be ad hoc and unprincipled.
2210537	2216562	A	0.798753559589386	But there's kind of a middle ground where they have a principled integration but still a distinguishment.
2218862	2219625	B	0.7360090017318726	Right?
2221712	2248022	B	0.6729408502578735	This is caused by network structure defined or it is because the structure of Bayesian network defined in the MDV model.
2248205	2256162	B	0.8136840462684631	So both of them define the causal relationship between elements or quantities.
2260187	2275882	B	0.6502890586853027	Its substrate is not important, so it's relationship is crucial to determine the cost function or it's a fixed point in this context.
2276047	2281212	B	0.8083556890487671	So that's why we can see the data analogy.
2284525	2297190	A	0.8068190813064575	Well, there's a few technical points I think we can now go into and then there will be some more general points about applications and intelligence.
2297370	2302440	A	0.8001598715782166	So first the code availability statement.
2302620	2309970	A	0.9792994856834412	Awesome to see that the MATLAB scripts are available and also active on Zinodo.
2310135	2315525	A	0.8146399855613708	So here is the GitHub repo for reverse engineering.
2316250	2321505	A	0.880757749080658	Do you want to give any overview descriptions of what people can expect to see in this repo?
2321640	2325050	A	0.889341413974762	And also what about using MATLAB?
2330062	2332347	A	0.8233511447906494	Why did you use MATLAB?
2332467	2336087	A	0.8923062086105347	What advantages or limitations do you see in MATLAB?
2338387	2351537	B	0.7570980191230774	So, because this is a very simple simulation, so Macrab is sufficient to encode the whole script.
2354812	2360952	B	0.8701706528663635	We also try some implication in the material.
2361057	2374937	B	0.8982541561126709	See here, if you run the script, then you can see the process of an agent solving the maze task.
2379412	2381837	A	0.8898963332176208	What did they do in the maze task?
2382787	2394887	B	0.8458490967750549	So here the aim of this agent is to reach the right hand side of this maze.
2396287	2401572	B	0.6815221309661865	Because this is a typical example of the rate moderation task.
2401692	2405237	B	0.8527430891990662	That's why we select the main task.
2406637	2419752	B	0.8570981621742249	So to achieve this next task, is it required to make some plan to be able to select a good decision?
2419932	2433612	B	0.8590037226676941	Because without planning, you may encounter the war and cannot go further and you may fail the image.
2433762	2443700	B	0.6523585915565491	But with learning, it is possible to see the path to reach the right hand side of this space.
2446012	2449112	A	0.8333707451820374	So does it know its exploration?
2453137	2460642	B	0.9010297656059265	Yeah, it received a state from neighboring eleven times eleven Jelle.
2460702	2464312	B	0.8141301870346069	So which is shown in the bottom part.
2464375	2473287	B	0.8802148103713989	Yeah, this left figure C indicates the observation.
2473362	2481125	B	0.8973024487495422	So eleven times eleven state around the agent position.
2481787	2482192	B	0.584351658821106	Okay.
2482240	2492900	B	0.8991955518722534	Now agent is on the right hand side of image at the goal position and it observes our neighboring state.
2496937	2500237	A	0.9220653772354126	Well, a few interesting things here.
2500300	2503250	A	0.6533541083335876	It's looking off the right end.
2503762	2504392	B	0.5491447448730469	Yeah.
2504515	2511137	A	0.8944197297096252	And it has this kind of periodic belief in the key distribution.
2511562	2512325	A	0.6120102405548096	Why?
2515087	2533377	B	0.7848122119903564	I think it is because when the agent is in the middle point of maze, then all neighboring state is in the maze.
2533407	2539025	B	0.8220528364181519	So there is a path and there is a wall.
2539762	2562650	B	0.7629571557044983	So this makes some ergodicity because mazes have some structures and actually have a periodic structure and only at the goal position, then right hand side becomes war.
2563687	2570450	B	0.6108686923980713	But it is not common for this agent.
2572312	2582762	B	0.752752423286438	This is because this agent show such a priori pattern.
2584237	2590325	A	0.6780003905296326	Yeah, the streets are one wide and they tend to be separated by one.
2591362	2593527	A	0.8385664820671082	So we see this periodicity.
2593707	2601062	A	0.8933894634246826	What is the numbers in this middle bottom plot and what does the checker board represent?
2601487	2611527	B	0.8554884791374207	Yeah, hered correspond to possibility, expectation about active states and decision.
2611632	2618687	B	0.8593513369560242	So middle indicate decision posterior and decision.
2619037	2627547	B	0.9118349552154541	Here we characterize decision as a secret of four step actions.
2627667	2638700	B	0.8902621269226074	So each action correspond to a movement to right or left or up or down.
2639362	2648047	B	0.9090214371681213	And we consider a four step sequence of that option which is expressed as D.
2648230	2659637	B	0.7719938158988953	So it has four power, four possibility.
2661337	2662925	A	0.6583408713340759	256.
2663812	2666077	B	0.7290316820144653	Yeah, 256.
2666245	2681707	B	0.9244915246963501	So this is a protein on XY coordinate because in the middle panel, middle point correspond to the current position of agent.
2681860	2704637	B	0.8997148871421814	And with four step movement, agent can go one of any current position and the current brightness corresponds to the expectation about the agent decision.
2705662	2707597	A	0.9709072709083557	Well this is very interesting.
2707780	2714912	A	0.8385390639305115	If we just were to think about you're at a point and you can go up, down, left, right, you have four moves.
2716462	2721362	A	0.5028258562088013	Naively it sounds like, well it should look like a gaussian blur.
2721862	2728302	A	0.8304163217544556	Most of those should cancel out and then it should become rarer and rarer monotonically.
2728482	2743550	A	0.5965538620948792	But actually you start in the middle, you can't end up on these white squares because it's like one, two, three and then you have to leave.
2744737	2745500	B	0.7360090017318726	Right?
2745862	2765837	A	0.5888354778289795	So it's kind of like horses in chess or other pieces where actually their embodiment, it's very unexpected that you can't in four moves end up next to where you began when you can be so much further.
2766262	2781062	A	0.8888953924179077	And then we see this kind of like embodied inferential prior with QS that embodies regularity beliefs about the width of the road and the separation of the roads.
2781412	2793362	A	0.8358162641525269	And then there's these like embodied action priors and real consequences that have to do with the structure of movement.
2794837	2796277	A	0.8062378168106079	So what it's doing?
2796370	2801272	A	0.887397050857544	It's thinking about policies of length four.
2801380	2804300	A	0.9039992690086365	There's 256 policies of length four.
2804887	2810602	A	0.8733012080192566	There's some degeneracy because there's obviously not 256 squares here.
2810770	2819142	A	0.7357472777366638	So while only one policy is going to take you up, up, down, down, other squares are reachable.
2819202	2829050	A	0.7201104760169983	Like the center square is probably the mode because it can be reached at least a handful of ways.
2831587	2848550	A	0.7396541237831116	And then at each time point it's basically saying okay, I know where my X position is and given my local eleven by eleven view, I'm trying to plan to go right.
2854662	2868025	A	0.8603317737579346	And then here through time in the simulation here it starts at 30 something, it quickly figures out how to get to about 40 and then it's kind of going up and down on 40.
2868987	2876662	A	0.6047150492668152	But it can't really break out because all of these bottom four routes are closed.
2877162	2883325	A	0.8587574362754822	It has a breakout and then very quickly it hits another plateau around 60.
2884212	2884975	B	0.5664745569229126	Right.
2885562	2893075	A	0.9704697132110596	Then it kind of has a very nice breakout and in just a few steps goes very far.
2895162	2897217	A	0.8293192982673645	So what is dopamine doing?
2897265	2902987	A	0.8705484867095947	Or how is Dopamine helping it in the plateau and then to break out of the plateau?
2903562	2904325	B	0.46103888750076294	Yes.
2904762	2918852	B	0.8538284301757812	So this agent learned this particular structure through many trials.
2919032	2931487	B	0.4601328372955322	So before training it failed to reach the goal, but after training it achieved such a nice behavior.
2932062	2961057	B	0.8296574354171753	So to active this, the role of domain is that we design gamma function such that if the agent can move rightward with some distance during some time limit, then risk becomes small like say comma equals zero nor risk situation in that sense.
2961135	2969437	B	0.9094979763031006	In that case, this agent updates synaptic weights through hebion frostbust.
2970087	2993112	B	0.6746302843093872	But if the agent failed to go rightward with some distance during a limited time frame, then gamma becomes large like zero six which is larger than the average zero five.
2993250	3007012	B	0.7341016530990601	Then we design that drawing in attention antihebian prosthesis occurred instead of Hebbian.
3007512	3020117	B	0.7193760871887207	So antihabion indicates the works as the disassociation between the current state and current decisions.
3020252	3026732	B	0.6904186606407166	Because the current decision does work, it's not good decision.
3026897	3042182	B	0.8846177458763123	So we try to make the agent who will get that particular decision rules through conversation of heavy and plasticity done by Dharma factory.
3042347	3050512	B	0.8946903944015503	So this can be an arrow to the Dopamine moderation heavy and activity.
3051912	3073037	A	0.6176329255104065	So if the policy is resulting in the expected outcome, gamma stays at .5, the policy is as risky or consequential as expected, and then the policy can either go better than expected, which facilitates learning to support that decision.
3073187	3086287	A	0.8174940943717957	To be made more or the outcome of the policy can be worse than expected, which disassociates previous conceptions to discourage that kind of behavior.
3086937	3087700	B	0.5662814974784851	Exactly.
3089337	3111700	B	0.8295382857322693	Crucial point is that this association with different time frame in the sense that we consider multiplication of current risk and least decisions to average over past two present Hebbian product.
3112062	3126377	B	0.7716543078422546	This makes an association between past decision secrets and the current risk which enables to optimize decision to minimize the future risk.
3126557	3129112	B	0.5502896904945374	It is just a safe time frame.
3131562	3146800	A	0.6362353563308716	So here risk is being used in a formal sense similar to how it's used in economics which is the associated uncertainty of outcomes with respect to a policy.
3148062	3150850	A	0.6435666680335999	Where does danger come into play?
3151737	3159262	A	0.6608339548110962	Like what if there was an adversary in the maze or something that was dangerous?
3160212	3167867	A	0.6693267822265625	How does this kind of model accommodate or hunger or different kinds of competitions?
3167927	3172612	A	0.6700945496559143	Because right now it's basically just trying to diffuse right word with a bias.
3173187	3173950	B	0.7360090017318726	Right?
3174537	3183850	A	0.8840740323066711	But how do different kind of situational elements become interface into the generative model and generative process?
3184812	3197372	B	0.6834341287612915	Okay, any of those factors can be involved in risk factor, a single risk factor.
3197417	3209547	B	0.8518036007881165	So you can arbitrary design and risk factor because risk factor moderate generative model.
3209730	3220217	B	0.8405376076698303	So that's why agent try to minimize the risk through basic embryo updating.
3220277	3227287	B	0.7454909086227417	But the risk itself is in some sense outside of such a Bayesian framework.
3227712	3233417	B	0.792258620262146	So we can design arbitrary risk.
3233477	3241537	B	0.6108556985855103	So it may involve some danger factor, any other factor.
3243762	3254117	A	0.7988919019699097	And this simulation, it is a POMDP or it is a neural network.
3254177	3260950	A	0.9020312428474426	And what scripts might we look at to understand the structure of the maze agents?
3262212	3274037	B	0.8752814531326294	Okay, it is basically expressed using the quantity in home depp for tractability.
3274187	3310600	B	0.8159819841384888	But for example, if you see the MDP learning probably okay, there is a variable Lamme type in the definition of SIM type correspond to the type of simulation.
3310675	3320775	B	0.8970077037811279	So if it's one or two it becomes homo DP or neural network to my understanding.
3321200	3356987	B	0.8456557393074036	Well, in this particular example, Jelle, we use the let's say maybe it's not good example that DeForest is learning the deforesting this script as well.
3357050	3366000	B	0.8226404786109924	So maybe another as an example, let's see.
3369287	3375467	A	0.8779596090316772	What is MDP init is initiating the markup decision process.
3375665	3376202	B	0.5662814974784851	Exactly.
3376295	3396450	B	0.8782453536987305	It's just determining the initial state of the computer generative model fe compute variational free energy or risk MDP computer risk function.
3397937	3409512	B	0.9048892259597778	So basically we use the neural network structure computation in this particular setup.
3410237	3428762	B	0.8937612175941467	So when you click maze m then in the line 31 line we determine that Lamme type is two.
3428825	3433512	B	0.8424434661865234	This correspond to neural network architecture.
3434012	3492612	B	0.7975402474403381	So there is a very slight difference between home depicture and neural network architecture because assuming neural network architecture correspond to, you know, considering considering okay, well, if you choose the palm DP architectures, then we sometimes use the gamma function to computer the posterior expectation about parameters.
3493337	3507900	B	0.7710508108139038	But in the neural network modeling the gamma function doesn't appear but it is replaced with the logarithm of some function.
3508562	3520292	B	0.7564647793769836	And simply speaking, the difference between the gamma function of something and the logarithm function of something is asymmetry Lamme.
3520490	3528472	B	0.5007637143135071	So that's why we can transform home DP two neural network architectures.
3528517	3532800	B	0.7951944470405579	When the number of samples is sufficiently large.
3537287	3545325	A	0.8225662708282471	Which form do you expect performs better under small or large amounts of data?
3547487	3553137	B	0.7669517993927002	Well, for large amount of data they work in the same manner.
3553937	3554812	B	0.6975769400596619	Same manner.
3554887	3573292	B	0.8105741739273071	For small amount of examples, I'm not truly sure but it corresponds to assumptions about the posterior belief distribution.
3573427	3595362	B	0.7254318594932556	So if you assume delicious distribution then your resulting function form is something that used the gamma function in terms of basic inference probably which is optimal.
3600512	3606600	A	0.8658781051635742	All right, let's return to the earliest questions from today.
3608012	3628887	A	0.9057131409645081	So in your script, which people can reference, there's basically a toggle between having it in SIM type one or SIM type two corresponding to the POMDP in the neural network.
3630212	3635787	A	0.9125033020973206	What about if there's a published neural network or POMDP?
3637112	3644412	A	0.8876837491989136	How can we use this architecture to create a translation?
3648000	3649905	A	0.8245750665664673	Is there any difference in this?
3649952	3665800	A	0.7490792870521545	Kind of like translating models in the wild different than the full construction of a special script that can speak both languages?
3670500	3678987	B	0.5395569801330566	Well, in terms of script there's no difference, sympathetic difference.
3679575	3680430	B	0.5664745569229126	Right.
3680627	3684680	B	0.7300592064857483	So they work in the same manner.
3684740	3706155	B	0.8241154551506042	So only a translation of variable the same source code in two different ways.
3706277	3714995	B	0.8756933212280273	So if you see that this is a neural network generation, then it is translated as a neural network.
3715085	3719650	B	0.699974000453949	Or if you see that this is a POMDP, then it's POMDP.
3723075	3735700	A	0.9078718423843384	So for some neural network being used in an industrial setting, how would we get from the neural network to a POMDP?
3736050	3739900	A	0.8214966654777527	And where or how would that representation be valuable?
3740925	3741687	B	0.7360090017318726	Right?
3742275	3761345	B	0.8947518467903137	So when neural network in the different architectures the important point is that we consider a particular form of neural network which is called canonical neural network architecture.
3761510	3775000	B	0.8824775815010071	So only when we assume this crossover neural network then you can find the exact correspondence to a particular form of POMDP.
3775350	3790287	B	0.879991352558136	Otherwise you need to establish another equivalent between another form of neural network architectures and some sort of Bayesian model.
3792825	3807850	B	0.6686073541641235	This may be expressed by POMDP, but maybe not so straightforward to be expressed as the computational AP architectures.
3809175	3818637	A	0.9082266092300415	So what is it about the canonical neural network architecture that facilitates its translation into the POMDP form?
3819225	3824487	B	0.7313084006309509	Yeah, first of all, it assumes sigmoid or activation function.
3824850	3832975	B	0.6070340871810913	It is nicely correspond to enthralpy time in the force DP equations from DP formulations.
3833400	3840275	B	0.6817307472229004	So that's why we can clear marketing.
3840425	3848105	B	0.6359010338783264	So yeah, in other words, simply speaking, they have the same nonlinearity.
3848240	3873530	B	0.7209484577178955	That's why this translation is very easy with another nonlinearity or neural network equation, then we need to find another type of entropy equation or another type of prior distribution.
3873665	3876175	B	0.6455100178718567	It is very nontrivial.
3878175	3882912	A	0.5908942222595215	How does one even go about doing that research?
3889575	3919137	B	0.8558247685432434	If you want to go that direction, then I think the first step is to find the prior brief, which makes the prior brief and find the equivalence between a particular neural network architectures and particular Bayesian model.
3925312	3929675	A	0.8888033032417297	This sigmoidal activation is interesting.
3930412	3942362	A	0.8743933439254761	It corresponds to general patterns seen in psychophysics, like two objects that are the same weight.
3943162	3957962	A	0.7464214563369751	You're going to have a chance of saying that one is heavier and then initially the difference has the most returns on that decision being made accurately.
3959287	3983150	A	0.6888033747673035	And then as it crosses some threshold where it just is beyond a noticeable difference, the decision becomes essentially probabilistic, like the firing curve becomes saturated, the neuron chaos, a very low belief about zero or very high belief about zero or one flip that.
3986587	4010387	A	0.8932554125785828	So there is a nice grounding of that kind of a sigmoidal response curve with respect to stimuli differences and it has of course, tractable analytical properties, but it also just happens to be a good response summarizer.
4011262	4012882	B	0.4803207516670227	Yeah, you're right.
4012960	4018567	B	0.8912712931632996	So sigmoidar function is also known as a psychometric function, as you say.
4018765	4026342	B	0.8765237927436829	We observe that characteristic in many psychical experiments.
4026477	4060700	B	0.8325572609901428	And the previous work also said that even at the single neuron level, neuronal level, the same behavior were absorbed, which means that each heuristic we can reobserve the similar property, which is sometimes called as neurometric function, which is which have the form of sigmoida activation function.
4063312	4076675	B	0.8161500096321106	So it is nice reason to design neural network architecture using a sigmoid or function.
4078837	4089962	A	0.8361883163452148	All right, let's cover a few questions in the chat from Dave and then in the end turn to some general thoughts.
4090462	4094600	A	0.9020334482192993	Okay, this was when we were looking at figure three.
4095337	4103442	A	0.8224489688873291	So you described these vectors or matrices.
4103502	4106547	A	0.879011332988739	What kind of matrix or vector did you describe?
4106592	4112925	A	0.8547933101654053	The mass block matrix.
4114625	4116000	B	0.6319137215614319	Block matrix.
4118900	4123712	A	0.7105626463890076	Block rock learning what?
4124075	4126510	B	0.8530686497688293	Okay, rock matrix of rock.
4126555	4131430	B	0.8248935341835022	Vector is a vector vector or matrix of matrix.
4131490	4134587	B	0.6553595066070557	So imagine that.
4142900	4147112	A	0.5144848227500916	Sorry, just zoom, just glitch just repeat the last piece.
4147550	4157400	B	0.5015366077423096	Okay, well, broke matrix Dean that the element of matrix is a matrix.
4158125	4165875	B	0.9026859402656555	So let's say two by two matrix like matrix in the ear pointing.
4166375	4176375	B	0.5770570635795593	So this here W one hat is a matrix and W zero hat is another matrix.
4177250	4184550	B	0.8416000604629517	And combining four matrices, we define a single block matrix.
4186625	4189112	A	0.8092430830001831	All right, thank you.
4189625	4199260	A	0.935556948184967	So Dave then asks the hosts of Machine Learning Street Talk Number 67 with Karl Friston.
4199305	4202925	A	0.7772468328475952	Another podcast, Karl Friston has spoken.
4204100	4214087	A	0.7017779350280762	Pressed Karl Friston on why is it so important that most of the values in a generative model matrix assume values of exactly zero?
4217037	4221262	A	0.7546517252922058	Why is it important that generative model matrices are sparse?
4222962	4223725	B	0.6120102405548096	Why?
4230687	4232232	B	0.6693134903907776	I'm not Bull sure.
4232385	4237450	B	0.8888453841209412	I think there is some context before that point.
4238037	4253200	B	0.734178364276886	I think on that particular situation, then, yeah, as you say, the many elements in the matrix or gentle model should be zero, but I'm not sure if it's a general statement at all.
4254312	4264575	A	0.8943555355072021	What do you think about compressed analyses on sparse matrices?
4268825	4282350	A	0.8812423944473267	Is that a useful technique or direction?
4285850	4299295	B	0.5127846002578735	You can use that knowledge to construct model, so you can use that knowledge to make more accurate inference.
4299385	4305225	B	0.5084879994392395	So in that sense, generally speaking, such assumptions should be useful.
4306775	4320250	B	0.8411979675292969	For example, yeah, as you said, it would be possible to use some sparse prior to restrict the value of parameter.
4320325	4332340	B	0.8354552984237671	Like, it is in principle same as assuming some L one norm to design the distribution.
4332445	4338665	B	0.8757643103599548	To design the prior distribution, which is mass Dutch speaking.
4338757	4343625	B	0.8005033731460571	Exactly same as considering Lasso regression.
4345550	4346312	A	0.46103888750076294	Yes.
4348250	4368525	A	0.7226017117500305	So we've explored a little bit how from a canonical neural network to a particular form of a POMDP, gives us some semantics and interpretability around the dynamics and plasticity of the neural network.
4369175	4381050	A	0.8835737109184265	What do we gain by taking a stated POMDP generative model and deriving an analogous neural network?
4383725	4391625	A	0.7122113704681396	Do we gain access to efficient computation, new software packages, different applications?
4395462	4413182	B	0.5706666111946106	Well, if one use Home DP and one's goal is so design an efficient basic model, then I think your Home DP expression is sufficient.
4413272	4442457	B	0.7079002857208252	So you don't need to consider neural network architecture, probably because Homedippy architecture and Bayesian correlation is designed to achieve some sort of mathematically optimal inference and decision making.
4442535	4442817	A	0.7360090017318726	Right?
4442865	4448837	B	0.5177116990089417	So it itself is optimal scheme.
4448987	4464637	B	0.8348466157913208	But if one need to consider a link between Bayesian inference and biological substrates, then this mapping is crucial.
4468962	4478807	B	0.7184008359909058	Simply speaking, we consider that we assume that a brain perform Beijing inference, but its substrate is still unclear.
4478897	4486697	B	0.8608431220054626	So we need to link the Bayesian quantity to biological quantities.
4486892	4492987	B	0.5768797397613525	So this mapping, this equivalent, helps us to its translation.
4493862	4494447	B	0.7360090017318726	Right?
4494555	4508912	B	0.7652783393859863	So when you start from on the model, then this translation facilitates the process of finding its neuronal substrate.
4509062	4527917	B	0.6485339403152466	So once you translate that to a basic to neural network quantities, then it facilitates the experimental validation application to reality.
4528052	4554700	B	0.8855706453323364	So if its modeling is apt for a particular neural network neural circuit architecture, then it should provide some prediction about the architecture or dynamics of the empirical data.
4555212	4555932	B	0.7360090017318726	Right?
4556085	4564302	B	0.6551326513290405	So first we start from Bayesian model, which is not necessary to be equal to empirical data.
4564395	4570547	B	0.6227235794067383	So there is some mapping, but it's mapping is not straightforward.
4570742	4591537	B	0.7647902369499207	We may have multiple mappings, but once you translate Bayesian model to a particular neural network architectures then mapping or relationship between applicable data to such a particular neural network model is straightforward.
4592187	4600750	B	0.5160863995552063	So it helps us to apply base to an explanation of MP card data.
4606737	4626037	A	0.6835460662841797	So is it fair to say that neural networks have found wide recent application because they facilitate statistical learning in cases where the inference problem has not been a priori well specified?
4627137	4636375	A	0.8126876950263977	One can just have a folder of images and a list of labels and just say, here's the data.
4637412	4643737	A	0.8884192109107971	Run it through this architecture or this architecture Explorer.
4645137	4657825	A	0.7929444313049316	And so with this concordance we gain new interpretation into those settings that kind of arose from ill specified inference problems.
4658412	4684687	A	0.6524167656898499	And then on the other hand, for problems that we already have well specified in terms of a POMDP generative model of a particular form, we gain the connection to actually implement it with empirical data and bring it into relevant industrial settings.
4687987	4709167	A	0.7629078030586243	What systems or phenomena are promising to continue research on the image example obviously is a simple case, but are you continuing research into more advanced computational agents?
4709365	4711937	A	0.49513307213783264	Robotic animal.
4716200	4746505	B	0.5141364336013794	Oh, hello can design a more sophisticated agent which performs some difficult tasks based on canonical network neural network but there is some limitation, clear limitation on that direction.
4746565	4746965	B	0.7360090017318726	Right?
4747057	4763025	B	0.7061716318130493	So yeah, I should emphasize that across the canonical neural network which correspond to a particular home DP is much smaller than general home DP framework.
4763600	4767670	B	0.7442866563796997	So there are some limitations, a least of limitations.
4767760	4792725	B	0.7226830124855042	So if one's goal is designed and sophisticated DAGs to perform some task or control robot, then one direction is just forget such limitations and take the mathematical optimality right and another direction is barrelscale probability.
4793075	4819425	B	0.6848194599151611	So if one wants to image some agent which is barely possible, then this correspondence is crucial because it tells us biological limitations through the existence, no existence of such a mapping between POMDP and particular neural network architectures.
4819775	4822562	B	0.6129430532455444	So, yeah.
4823000	4833975	B	0.7681305408477783	So it would be useful to consider a vertical substrate to achieve exafferent task.
4842162	4851362	B	0.8612588047981262	And that task would be related to high dimension image processing.
4851512	4859882	B	0.7855556011199951	Image recognition or sound recognition, such as multimodality, can be inbox or decision.
4859972	4879677	B	0.7780376076698303	Can be higher dimensional like in the mainstays, we just consider the four directional movement, but it can be extended to higher dimensionality, like arm movement, body movement, so on, so on.
4879845	4887412	B	0.6803385019302368	So in principle it can be extended in that direction.
4890312	4896387	A	0.6200768351554871	Which directions or questions are you excited about?
4896525	4906162	A	0.8872111439704895	Or what areas of studying the basis of biological and computational intelligence are relevant?
4907112	4907967	B	0.46103888750076294	Yes.
4908165	4922447	B	0.8770596385002136	So in terms of the importance of canonical network, as you said, virtue is a biological probability.
4922567	4970012	B	0.5683746337890625	So it would be nice that if we model some task which is conducted by learning and one already recorded some neural activity, then we design a task which is exactly same as the task which is done by the animal and then compare the simulated agent and Mpcar data to discuss about the similarity or difference between the simulated agent and the animals.
4970162	4973950	B	0.9272391200065613	That would be very interesting direction of research.
4976862	4988650	A	0.6851698756217957	Yeah, and if there could be some unexpected prediction or explanation in the computational agent, that would bolster the relationship.
4989462	5025452	A	0.7916011810302734	And then one other aspect is it would help with the reproducibility and the documentation around behavior studies if the computational agent were preregistered and someone said we've already done the statistical power analysis and we've already explored with parameter sweeps how many observations we need to make of the two armed bandit.
5025557	5030067	A	0.8478490114212036	How many observations of the three armed bandit should we do?
5030190	5034100	A	0.8256983160972595	Three mice 100 times or 100 mice three times?
5034912	5041987	A	0.7140669226646423	Those are the total substance of designing research programs.
5042862	5055787	A	0.7386255860328674	And so having a formal representation of behavioral tasks that are being studied will help us design behavior observations and experiments that aren't simply ad hoc.
5060037	5063875	B	0.9014883637428284	All right, that's an interesting application.
5066862	5072800	B	0.6090289950370789	This framework helps to design the experimental setup itself.
5073762	5098300	B	0.8778238892555237	And what we often consider is the prediction ability of these modern canonical neural networks to predict the Jelle phoneization or dynamics of the VR neural network in the animal during the learning process.
5098662	5121347	B	0.5926860570907593	So in place for it is possible to predict the behavior after learning based only on data in the initial stage because once we obtain some empirical data, then we can fit that data to design a particular canonical network.
5121542	5137617	B	0.847804605960846	And canonical neural network makes some correlation through a minimization cost function which is exactly same as the Bayesian belief updating under a particular guarantee model.
5137815	5159972	B	0.8412252068519592	So which means that its dynamics goes through the shortest path on the free energy landscape which means that we can make some quantitative prediction about the sinatic trajectory or neural activity or any kind of parameters.
5160167	5171267	B	0.6783416867256165	So we demonstrated that using in virtual neural network and uploaded some footprint recently.
5171402	5214407	B	0.5184800624847412	So at the stage, at least at the level in vitro network, which is much simpler than VR brain, we could predict the self organization of in virtual network using this canonical network architecture and this support the probability of free energy principle because this canonical network predict the communication through the variational free energy minimization and its solution.
5214497	5224537	B	0.6501262187957764	Its results have a very tight correlation between correlation to Archer synchronization.
5227962	5230787	A	0.947458803653717	That's a very interesting experiment.
5230862	5239387	A	0.9064449667930603	So what animal were the neurons from and what was measured about these neurons?
5239737	5266802	B	0.8940626382827759	Yes, so that in vitro network is obtained from blood embryo, we use cortical cells to make that individual network and task is sort of causal inference task which can be designed in the form of OMDP.
5266982	5279957	B	0.8966491222381592	So imagine that we usually simulate agents that receive signals generated by OMDP generative process and process and Beijing task.
5280122	5287847	B	0.8447185754776001	So we just replaced that Bayesian agent to neural network.
5287967	5311537	B	0.858124315738678	So we stimulate neuron with some signal which is made by some hidden sources through like a human mapping and question is whether in viral network can info the hidden states through some communication and they can they could Ines the hidden culture.
5315112	5323922	A	0.8315626978874207	What does it look like functionally when the neural network has succeeded at inferring the hidden causes?
5324117	5335397	B	0.8917657732963562	Yeah, the direct conversation is done by the response number response spikes to a particular pattern sensory input.
5335517	5345502	B	0.843519926071167	So again, we can see a clear correspondence between activity level and posterior belief about hidden state.
5345595	5352782	B	0.8821337819099426	So here we see re a book response to an electropaste memory.
5352872	5381500	B	0.8777483105659485	We see the response from ten to 13 milliseconds after each stimulation and we compute the number of spikes and that spikes changes their preference in the sense that some neurons learn to preferentially respond to force one but not source two.
5382237	5392912	B	0.78733891248703	So which is not a response to input itself, but it looks like a response to particular source.
5393337	5410382	B	0.7110843658447266	So it is inference which is empirical evidence that neural network actually perform some sort of causal inference in a manner consistent with traditional Bayesian inference.
5410547	5418162	B	0.8528993725776672	And then we compute another quantity in Bayesian inference in the real vertical data.
5418300	5458987	B	0.8370637893676758	We show that firing special factor is consistent with the prior belief about hidden states and we also compute the synaptic rate statistically through some connection strength estimation method and show that the estimated synaptic strength is consistent with something encoding posterior belief about parameters, as expected by the theory.
5460612	5488237	A	0.8497087955474854	Well, we looked at table two earlier and this is almost like the next step after the theoretical concordance is all right, well, let's measure the release of a neurotransmitter or the empirical synaptic strength or the firing threshold or all these different features in different empirical systems.
5488962	5496250	A	0.8913325667381287	So what experimental systems does your group work in?
5502012	5509767	B	0.8996928334236145	That in virtual system was made when I was a PhD student.
5509890	5528582	B	0.9163722395896912	So that is experiment we done in my previous route and now I COVID to the Bijan Institute and I'm a Princepal investigator of Celery unit.
5528672	5540887	B	0.6627157330513	So now actually we don't use any experimental setup, so any experimental bidding is down with some collaboration.
5541237	5546732	B	0.7599158883094788	So although I cannot say detail about that exploration.
5546822	5557322	B	0.7191546559333801	But yeah, we learn some collaborating work about the implication of salary using various animals.
5557517	5565700	B	0.937881588935852	Yeah, so we hope we can show some interesting results following results using animal data.
5569662	5571775	A	0.9324204325675964	Very interesting.
5572887	5591587	A	0.7310962677001953	Yeah, well, it speaks a lot to the stage that our field is in in certain ways where we've seen a lot of graphics that are suggestive.
5592387	5615967	A	0.6488123536109924	This paper and the building on the previous 2020 paper made a suggestive possibility much closer to an analytically demonstrated translation and then took the next step incrementally into the in silico agent.
5616165	5625175	A	0.5626489520072937	And so it's only natural to then explore different embodied systems as well.
5630862	5647300	A	0.6239761710166931	Are there any other sections that you wanted to like, look at or highlight or any other topics about the paper or adjacencies or active inference that you think are interesting to go into?
5650212	5663417	B	0.7856513261795044	Yeah, okay, I would like to mention about some implication of these papers, which is not the director discussing the papers.
5663552	5671675	B	0.8944952487945557	So for example, well, we focus on a discrete state space model.
5672037	5683652	B	0.7824991941452026	So we avoid to assume some subscript that encodes the coherence of the distribution.
5683757	5688617	B	0.8297559022903442	So once you assume homedp then it is categorical distinctions.
5688677	5696792	B	0.8680087924003601	So it is different from assuming Gaussian distribution characterized by me and variants.
5696927	5707632	B	0.6792939901351929	So the neural substrate of variance is still unclear and we now try to figure out that.
5707785	5730767	B	0.5709208250045776	So this is one direction of limitation and another implication is that thanks to a simple ODP structure in this paper, we don't care about the hierarchical optimization.
5730902	5744437	B	0.8468706011772156	But generally it is crucial to update parameters through hierarchical optimization through some backpropagation like computation.
5744787	5751617	B	0.7546353936195374	Although it is unclear whether back propagation itself occurred in the real brain.
5751677	5768062	B	0.5701487064361572	But we still have some alternative that achieve such optimization and it's neural substrate still unclear and this paper doesn't address that direction.
5785650	5796475	A	0.8390612602233887	Another area I'm wondering about is like where in neural structures is the learning reflected?
5797575	5800790	A	0.7574309706687927	Where is the function and learning reflected?
5800970	5809955	A	0.7799192070960999	Well, sometimes it has to do with not just structural Tweaking, but the presence or absence of synapses.
5810015	5823695	A	0.5555479526519775	So obviously this model does not expand into synaptogenesis synaptic pruning, let alone neurogenesis and neuro allostasis which we mentioned in the previous discussion.
5823860	5841015	A	0.6749361753463745	But understanding how these larger scale structural changes which are certainly important in biological systems become reflected in artificial neural networks and then how that translates all the way back to P-O-M.
5841032	5844300	A	0.8174566626548767	DP and then whether we could go the other way.
5844437	5855360	A	0.8666383028030396	What kinds of POMDP structures in their neural network realization would have structural modification.
5855480	5864535	A	0.690980076789856	Like you COVID imagine a POMDP that does structure learning but the neural network doesn't have structural change.
5864717	5874250	A	0.841214120388031	Or there's A-P-O-M DP that doesn't do structural learning but it's manifested by a neural network that does have a structural change element.
5875125	5880690	A	0.8725358843803406	So structure is doing something very different in these two different categories of model.
5880857	5903085	A	0.8422107696533203	And then also even within neural firing, which is different amongst different species and so on, there's different aspects of what that firing is that would have different implications for the actual biological substrate of cognition niche.
5903267	5911160	A	0.8457621335983276	The simple connection is firing rate to posterior belief.
5911355	5914535	A	0.7838589549064636	Average firing rate, no change in posterior.
5914655	5917830	A	0.6684385538101196	Reduce the firing rate if the posterior should be going down.
5917952	5920020	A	0.7862834334373474	Increase it if it should be going up.
5920172	5937625	A	0.8599861860275269	Or maybe there are neurons that have a flipped valence but the same type of relationship, but there's other firing patterns like spike time dependent plasticity synchronization amongst different brain regions.
5938800	5944000	A	0.5255221128463745	There's a lot of things that don't change the rate overall.
5945250	5953150	A	0.8525274991989136	That again from the biological systems we know that those phenomena and mechanism are important for different cognitive processes.
5957400	5963337	A	0.8657150864601135	So there will be many many years of a fruitful relationship.
5965875	5973945	A	0.9059394598007202	I'm going to bring in this picture that Alexandra had taken.
5974022	5996187	A	0.8444175720214844	Maybe we need a third panel in figure one because these three systems moving between them is going to be the substance of the field for a long time and there may be other edges to build.
5997150	6030965	A	0.5953333973884583	But understanding how artificial neural networks intermediate between the empirical measurements and manipulations that we can make of real neural systems and the interpretability and factorizability of POMDPs it might be a bridge too far to go from the POMDP to the neuron.
6031145	6040075	A	0.7799180150032043	You could always use this technique but it would be a purely descriptive statistic type approach.
6042825	6071187	A	0.8839786052703857	But it's so interesting that by intermediating through a formal connection established in figure one I Dean in equation one but also shown here, then we can kind of extend the chain of exploration, prediction, control, design all the way on through.
6072300	6096025	A	0.4821925759315491	And that just unlocks like an incredible amount of neuroscience that hasn't been formalized mathematically and an incredible amount of generative models that have been specified for different learning settings sometimes even by analogy to biological settings.
6097200	6108175	A	0.7609379887580872	But the metaphor remains just a metaphor until it's possible to intermediate with this type of neural network development.
6109125	6112737	B	0.7075645327568054	Yeah, that's a crucial point.
6116400	6131130	B	0.6708946824073792	It is easy to imagine that phenomena can be modeled using very realistic neural model or free model synaptic model.
6131252	6131937	B	0.5664745569229126	Right.
6134400	6149715	B	0.453252375125885	We believe that it is possible and then Laje model is not necessarily tractable, not necessarily useful because it's too much complicated to analyze something.
6149807	6160150	B	0.8079572916030884	So we use some reduction, usually mathematically speaking, which correspond to topological transformation to make the model simpler.
6160800	6182040	B	0.6322662830352783	And then we need to consider the translation of that simplified neural network model because neural network model itself is not explainable which just represents some dynamics and its functional meaning is not clear.
6182207	6193975	B	0.9514247179031372	But thanks to the Bayesian framework we have a very nice event framework to least the experiment ability.
6194400	6210850	B	0.5148566365242004	And this translation, this correspondence helped us to link such a phenomena base equation modeling and functional base equations.
6212250	6223600	A	0.8165292143821716	Yeah, one paper from 2017 that was much discussed by some could a neuroscientist understand a microprocessor?
6224325	6239487	A	0.8724193572998047	And this group with Jonas and Courting, they had a simulation of a microprocessor from an earlier video game console, I believe.
6240075	6263085	A	0.8737934231758118	And then using the analogy of like the transistors and their connections as neural firing and structural connectivity they were able to simulate experimental settings, input and action and then make measurements from every neuron including doing lesions and loss of functions and so on.
6263192	6286825	A	0.5790053606033325	And it turns out that a lot of the techniques that are used to derive scientific explanation from analogous data collected from a biological system, those techniques which ostensibly should be isolating functional explanations in fact did not isolate effective exploration.
6287175	6303700	A	0.6301164627075195	You could have a deletion over here that induces some statistical change all the way over here and that may or may not be a useful clue towards the function of even subcircuits.
6304575	6326125	A	0.7290244102478027	And so I think that was a wake up call with respect to the interpretability of simply this connection between the biological and the neural network.
6327450	6348625	A	0.582772433757782	This connection alone is of limited applicability even when the neural network model becomes so complex as to recapitulate the biological phenomena, you're never under any guarantee that you're going to recover interpretability.
6349050	6360815	A	0.6722893118858337	You may have just created an atomic level simulation of the phenomena, but of course, a map that is the same scale as the phenomena isn't a map.
6360995	6364450	A	0.7390573620796204	It's just a copy that has no more interpretability.
6366600	6398125	A	0.7535446286201477	And it's almost like what is now extended again, as we kind of just summarize this and think about how we move forward, is that connection can now be extended into the space of interpretable causal models and the generalized Bayesian graphical computational frameworks and all the heuristic that we can then use like variational, Bayes and all these other methods.
6398550	6420155	A	0.5328476428985596	So it'd be interesting to look back at different data sets of in vitro and in vivo and in silico neural activation, especially if the task was of this constrained set of POMDPs and it was already amenable.
6420215	6433750	A	0.68411785364151	Because, as you brought up, other settings would require a little bit more theory development before we understand what POMDP family would be applicable.
6439650	6440280	B	0.84200119972229	Cool.
6440402	6444837	A	0.8733499050140381	Well, do you have any final thoughts or questions?
6447300	6450625	B	0.7862346768379211	Well, do you hop.
6454912	6467087	A	0.9109904766082764	I kant to download the MATLAB scripts and generate the figures, play around with a few of these parameters?
6467887	6472175	A	0.7846764326095581	Like, I see that you can change how far the entity can see.
6473887	6481037	A	0.6641401648521423	And then with these models, I'm also always curious about the computational complexity.
6481462	6494162	A	0.7881978154182434	Like if you extended the planning horizon from four to five or you dropped it down to three, what is the runtime consequences and what is the performance consequences?
6495187	6511487	A	0.6213653087615967	And where might we be able to use single or swarms of really simple agent, maybe even making binary decisions and achieve high performance?
6512437	6550257	A	0.6619532704353333	And where do we really need to move into these large combinatoric spaces in order to solve problems and the kinds of complex planning problems that we solve, whether it's planning our day or planning our week, are those force like true Deep Harrison planning problems with extensive consideration of counterfactuals and calculation of alternatives?
6550422	6569387	A	0.8296710848808289	Or are those actually composite decisions that are made up of smaller, simpler, sub decisions that we may or may not have flexibility to restructure?
6571612	6580550	A	0.8476078510284424	So that a decision, a complex chess maneuver, a sacrifice in chess or another game.
6582262	6598262	A	0.651881992816925	It may be possible to model that as a Deep Horizon scan or a kind of intuitive heuristic for an appropriate skilled entity.
6601537	6622647	B	0.5800433158874512	For this particular two Brea structure, there is a clear limitation about the horizon forward because it doesn't use forward prediction, it used post action approach.
6622692	6636587	B	0.8136842846870422	So it's a clear limitation, but still, it may have some performance ability, active, some levels of affordance.
6638587	6643637	A	0.6430182456970215	That provides even another way to look at planning.
6644887	6660172	A	0.8117814660072327	The two ways I was describing planning, as it's often described in the PMDP literature is again, is it a true Deep Horizon consideration or is it just short term heuristics or nested models that are short?
6660355	6666812	A	0.6476669907569885	And I think that this paper says maybe neither.
6667537	6690477	A	0.8329698443412781	Maybe it's purely the active causality on the past that leads to the emergence of sentient and maybe even teleological planninglike behavior through the ongoing reconsideration of the consequences of least action.
6690657	6694947	A	0.5913478136062622	But it's neither a short nor a long term planning challenge.
6694992	6698352	A	0.6686211228370667	It's actually like a memory and learning challenge.
6698457	6700287	A	0.5820712447166443	And no planning occurs.
6700437	6701150	B	0.5664745569229126	Right.
6702637	6708587	B	0.8905624747276306	Indirect planning planning element is involving C matrix.
6710212	6715937	A	0.7576532363891602	Planning as a phenomenon occurs and derisking through time occurs.
6716437	6743225	A	0.6355149745941162	But it says something quite interesting and deep that that phenotype or function could be enacted by a system that explicitly looks a long way ahead, explicitly looks a short way ahead or moves forward and looks backwards only, right, which is what they sometimes say about the past and the future.
6745012	6754550	A	0.6337820291519165	So that may be a very biologically plausible form of learning.
6755887	6765050	A	0.842439591884613	And it's already intimately connected with the dynamics and the activity in terms of an integrated loss function.
6766537	6771725	A	0.9591498970985413	So these are all excellent directions to keep learning on.
6772837	6773600	B	0.7360090017318726	Right?
6774262	6783802	B	0.5848535895347595	And I'm also interested in the barrel implementation of such a short term or long term for the prediction and running.
6783895	6799562	B	0.9041956067085266	And I hope to find some nice connectivity to such implementation of Bayesian motor and implementation in VR brain network.
6800887	6801697	B	0.84200119972229	Cool.
6801880	6810962	A	0.7221531867980957	And also I'm always curious about the invertebrate brain as an ant researcher.
6811387	6823672	A	0.6685259938240051	And so many of the brain architectures as well as the brain architecture that people discuss are mammalian centric, which makes sense.
6823855	6836975	A	0.7262479066848755	The mammalian cortical column and the relationship with Dopaminergic midbrain and the cortical regions and the spinal reflex arc those are all important systems of interest.
6837562	6846662	A	0.8465535044670105	Yet the micro and meso anatomy of the invertebrate nervous system is pretty distinct.
6847687	6859112	A	0.808375895023346	So our model should be able to describe neural and cognitive systems, of course, across invertebrates and vertebrates.
6859537	6878762	A	0.5263932347297668	So I look forward to also seeing what those models of the invertebrate nervous system and collective behavior where you could have some type of backwards looking risk inference of the swarm.
6880012	6881162	A	0.706895649433136	Who knows?
6883537	6884300	B	0.6177208423614502	Well.
6886537	6890997	A	0.9478827714920044	We really appreciate the time that you took for these discussions.
6891042	6895250	A	0.9013051390647888	I think they are immensely important.
6895687	6899462	A	0.939091145992279	And we wish you the best of luck in these continued directions.
6903387	6904150	B	0.46103888750076294	Yes.
6906612	6907962	A	0.5725107192993164	Okay, that's it.
6908025	6908875	A	0.8529649376869202	Thank you.
6909687	6910962	B	0.9599630236625671	Thank you very much.
6911100	6911967	A	0.6020334959030151	See you next time.
6912015	6912712	A	0.5137446522712708	Bye.
