start	end	speaker	confidence	start time	text from AssemblyAI	corrected text	speaker name	bad phrase	bad phrase	bad phrase
33087	45807	DANIEL FRIEDMAN	0.59	00:33	Hello and welcome everyone. This is ActInf livestream number 51. Two. It's November 9, 2022. Welcome to the the active inference institute.	Hello and welcome everyone. This is ActInf livestream number 51. Two. It's November 9, 2022. Welcome to the the active inference institute.				
45972	86407	Daniel	0.45771	00:45	We're a participatory online institute that is communication, learning and practicing applied active inference. This is a recorded and an archived livestream, so please provide us feedback so we can improve our work. All backgrounds and perspectives are welcome and we'll be following video etiquette for live streams, head over active inference.org to learn more about participating in different institute projects. Alright, well, we're in act imp stream number 51.2. We're in our third discussion on the paper.	We're a participatory online institute that is communication, learning and practicing applied active inference. This is a recorded and an archived livestream, so please provide us feedback so we can improve our work. All backgrounds and perspectives are welcome and we'll be following video etiquette for live streams, head over active inference.org to learn more about participating in different institute projects. Alright, well, we're in ActInf Stream number 51.2. We're in our third discussion on the paper				
86485	126437	Daniel	0.98074	01:26	Canonical neural networks perform active inference from 2022. We had a dot zero video with some background and context and overview. And then last week in 51.1 we had a great discussion, went over many interesting details of the paper and related topics. So today we're going to jump in, cover some empirical details, some implications, connect some more dots, maybe look at some code. And thanks again to Kuya for joining these discussions.	“Canonical neural networks perform active inference,” from 2022. We had a Dot Zero video with some background and context and overview. And then last week in 51.1 we had a great discussion, went over many interesting details of the paper and related topics. So today we're going to jump in, cover some empirical details, some implications, connect some more dots, maybe look at some code. And thanks again to Takuya for joining these discussions.				
127537	199687	Daniel	0.91426	02:07	I'm Daniel, I'm a researcher in California and thought a lot over the last week about what this kind of neural network synthesis or translation really means, and just want to learn more about what fundamentals or foundational aspects of these different kinds of models enable that synthesis or translation. And then again what that means for areas where one or the other kind of model is already in use. So thanks again for joining and I'll pass it to you if you want to say hi or give any a second interoception. Oh yeah, I'm appearing Brain Science Institute, Japan. So I look forward to discuss another different aspect of this work.	I'm Daniel, I'm a researcher in California and thought a lot over the last week about what this kind of neural network synthesis or translation really means, and just want to learn more about what fundamentals or foundational aspects of these different kinds of models enable that synthesis or translation. And then again what that means for areas where one or the other kind of model is already in use. So thanks again for joining and I'll pass it to you if you want to say hi or give any a second interpretation. 				
		TAKUYA ISOMURA		03:01		Oh yeah, I'm at RIKEN Brain Science Institute, Japan. So I look forward to discuss another different aspect of this work.				
203200	256912	Daniel	0.72989	03:23	Well, let's just remind ourselves of the fundamental parallel being made in the paper and then we'll get to these two questions about kind of the two directions that things can go. One representation is in equation one with loss function of a neural network and the free energy on a POMDP. And that's also seen visually in figure one, with a neural network being drawn a concordance against the variational base of the action perception loop. So maybe just let's begin by restating. What is this parallel that is in equation one and figure one and how was it reached in this paper?	Well, let's just remind ourselves of the fundamental parallel being made in the paper and then we'll get to these two questions about kind of the two directions that things can go. One representation is in equation one with loss function of a neural network and the free energy on a POMDP. And that's also seen visually in figure one, with a neural network being drawn a concordance against the variational base of the action perception loop. So maybe just let's begin by restating. What is this parallel that is in equation one and figure one and how was it reached in this paper?				
259375	353587	Takuya	0.52086	04:19	So basically idea here is that we derived to characterize the dynamics and activity of canonical neural network in terms of Bayesian inference, because arbitrary dynamics of neural network is interoceptive in the sense that we don't know what is the function underlying such a dynamics and what is the coherence of the self organization or activity. So once we translate that dynamics in terms of Bayesian, we can assign quantities in Bayesian for any biological quantities, which enables us to lend the explainability to the neural network dynamics and architectures. So that's a basic idea. And what we have done in this paper is that we consider a biological plausible cost function for this particular canonical neural network. And show the equivalence between that Costa function and the variation navy energy and the particular partially observable cognition process model.	So basically idea here is that we derived to characterize the dynamics and activity of canonical neural network in terms of Bayesian inference, because arbitrary dynamics of neural network is interoceptive in the sense that we don't know what is the function underlying such a dynamics and what is the coherence of the self organization or activity. So once we translate that dynamics in terms of Bayesian, we can assign quantities in Bayesian for any biological quantities, which enables us to lend the explainability to the neural network dynamics and architectures. So that's a basic idea. And what we have done in this paper is that we consider a biological plausible cost function for this particular canonical neural network. And show the equivalence between that Costa function and the variation navy energy and the particular partially observable cognition process model.				
357850	402562	Daniel	0.99513	05:57	Awesome. So let's look at the parallel between the cost function for neural networks and the informational free energy. So one representation of that was in figure three. So maybe could you just describe what is the structure of the informational free energy expression and what is the structure of the loss function? Okay, so there is a clear parallel between the functional structure or those component in informational free energy and component in neural network Costa function.	Awesome. So let's look at the parallel between the cost function for neural networks and the informational free energy. So one representation of that was in figure three. So maybe could you just describe what is the structure of the informational free energy expression and what is the structure of the loss function? Okay, so there is a clear parallel between the functional structure or those component in informational free energy and component in neural network Costa function.				
403000	494525	Takuya	0.78027	06:43	So let's say the first time in F correspond to the it correspond to the expectation about hidden states is a hidden states Australia. So that part basically indicates the free energy with respect to the hidden state. Yeah, and the second part correspond to the free energy about the decision posterior. So the indicates the posterior belief about agent decision or action. And now in terms of the correspondence between the free energy and neural network function here the first time in the neural network function correspond to middle layer neural activity which has a recurrent connection and receive sensory input from sensory layer and then project the output to the output layer and the second term correspond to output layer which receive signals from middle layer and send the feedback response to the environment.	So let's say the first time in F correspond to the it correspond to the expectation about hidden states is a hidden states Australia. So that part basically indicates the free energy with respect to the hidden state. Yeah, and the second part correspond to the free energy about the decision posterior. So the indicates the posterior belief about agent decision or action. And now in terms of the correspondence between the free energy and neural network function here the first time in the neural network function correspond to middle layer neural activity which has a recurrent connection and receive sensory input from sensory layer and then project the output to the output layer and the second term correspond to output layer which receive signals from middle layer and send the feedback response to the environment.				
505037	535275	Daniel	0.57621	08:25	So both of us expressions have the first term being more like a cognition perceptual sensory learning term and the second term is more like a control theoretic action selection. And how did you see this analogy or concordance because it looks like a zipper, like everything is totally lined up.	So both of us expressions have the first term being more like a cognition perceptual sensory learning term and the second term is more like a control theoretic action selection. And how did you see this analogy or concordance because it looks like a zipper, like everything is totally lined up.				
538137	648637	Takuya	0.62176	08:58	Well, this graph itself showed a clear correspondence because now we are considering a particular form of on DP in which each element of hidden states takes either zero or one. But there are many states so it is expressed in a form of factorization. So now we consider that in terms of the s fosteria Bordeaux. Upper part of Bordeaux correspond to the expectation about each element of s taking one and lower part of the bordese correspond to the expectation about s taking zero. So it is broke vector about the posterior expectation and this nicely correspond to the Brea vector shown in the bottom up this figure it is a vector of x and Bijan sorry it is a vector of x and by x and here by x indicate one minus x in the element y sense which is exactly correspond to block vector or expectation.	Well, this graph itself showed a clear correspondence because now we are considering a particular form of on DP in which each element of hidden states takes either zero or one. But there are many states so it is expressed in a form of factorization. So now we consider that in terms of the s fosteria Bordeaux. Upper part of Bordeaux correspond to the expectation about each element of s taking one and lower part of the bordese correspond to the expectation about s taking zero. So it is broke vector about the posterior expectation and this nicely correspond to the Brea vector shown in the bottom up this figure it is a vector of x and Bijan sorry it is a vector of x and by x and here by x indicate one minus x in the element y sense which is exactly correspond to block vector or expectation.				
650412	718600	Takuya	0.78737	10:50	This correspondence also observed in the second tab. Here, log S correspond to log X and also log A correspond to the broke matrix of W log W. Here W hat indicates the sigmoidal function of W and its bar means sigmoidal function of W. So actually, because we now consider binary hidden state and binary observation it's like reviewed mapping. Mapping from hidden states to conversation is expressed as block matrix, which is exactly correspond to broke matrix shown in the bottom of this figure.	This correspondence also observed in the second tab. Here, log S correspond to log X and also log A correspond to the broke matrix of W log W. Here W hat indicates the sigmoidal function of W and its bar means sigmoidal function of W. So actually, because we now consider binary hidden state and binary observation it's like reviewed mapping. Mapping from hidden states to conversation is expressed as block matrix, which is exactly correspond to broke matrix shown in the bottom of this figure.				
724775	735225	Takuya	0.6376	12:04	So like this, for every tab we have the exact correspondence between the upper expression and the lower expression.	So like this, for every tab we have the exact correspondence between the upper expression and the lower expression.				
737825	747525	Takuya	0.56482	12:17	So that's why we can say that this is a natural mapping from neural network formation to parishional vision formation.	So that's why we can say that this is a natural mapping from neural network formation to parishional vision formation.				
751137	774712	Takuya	0.54554	12:31	So it speaks a sort of identity between those two different expressions. So although 1 may be able to consider another mapping from neural network to Bayesian inference, this is a sort of simplest mapping.	So it speaks a sort of identity between those two different expressions. So although 1 may be able to consider another mapping from neural network to Bayesian inference, this is a sort of simplest mapping.				
777012	818212	Daniel	0.75003	12:57	So how would it look different if it were three states categorical distribution or a continuous distribution? What aspects would change? Thank you for asking that. So that's in some sense outside of this paper because only when we consider a binary hidden state, this analogy is established nicely. Otherwise we need to consider some attention.	So how would it look different if it were three states categorical distribution or a continuous distribution? What aspects would change? Thank you for asking that. So that's in some sense outside of this paper because only when we consider a binary hidden state, this analogy is established nicely. Otherwise we need to consider some attention.				
818862	886150	Takuya	0.51667	13:38	So because consider that each neuron code the probability or expectation of some value taking one, then the probability or expectation of taking zero can be simply computed by computing one Ines neural activity. So actually neural activity which is a single dimensional variable is sufficient to express the expectation. Right? But once we consider the three state hidden states program, this doesn't work. So we need to consider at least two variables but it's relation to neural network expression is not very clear in general.	So because consider that each neuron code the probability or expectation of some value taking one, then the probability or expectation of taking zero can be simply computed by computing one Ines neural activity. So actually neural activity which is a single dimensional variable is sufficient to express the expectation. Right? But once we consider the three state hidden states program, this doesn't work. So we need to consider at least two variables but it's relation to neural network expression is not very clear in general.				
891987	973537	Daniel	0.85864	14:51	That's very interesting why it would be so strong of a concordance in a binary case but immediately unclear for other distributions. Yeah, generally for poem DB expression we consider the one hot expression, one hot vector expression which means that we normalize the value in the sense that the summation of all variable to be one. Maybe there is some neural substrate that achieve that communication. But for classic type of neural network like canonical neural network, consider in this paper what is that neural substrate is not very clear. So that's why we selected the binary case because it's simple and have a clear analogy.	That's very interesting why it would be so strong of a concordance in a binary case but immediately unclear for other distributions. Yeah, generally for poem DB expression we consider the one hot expression, one hot vector expression which means that we normalize the value in the sense that the summation of all variable to be one. Maybe there is some neural substrate that achieve that communication. But for classic type of neural network like canonical neural network, consider in this paper what is that neural substrate is not very clear. So that's why we selected the binary case because it's simple and have a clear analogy.				
974637	998662	Daniel	0.88138	16:14	So what does it mean for an artificial or for a biological neuron to have activity dynamics or plasticity context? That justifies it being described as playing like a belief role in a Bayesian setting.	So what does it mean for an artificial or for a biological neuron to have activity dynamics or plasticity context? That justifies it being described as playing like a belief role in a Bayesian setting.				
1001625	1046037	Daniel	0.9992	16:41	Higher firing means more belief, higher firing means lower belief. What does it really mean to have a connection between in this episode of street talk belief states. I see, so if you assign a mapping, a particular mapping, then its meaning is also determined. In this case, we assign that neural activity correspond to the posterior expectation about an element of hidden states taking one. So once we define this mapping, then higher neural activity indicates the higher probability of taking one.	Higher firing means more belief, higher firing means lower belief. What does it really mean to have a connection between in this episode of street talk belief states. I see, so if you assign a mapping, a particular mapping, then its meaning is also determined. In this case, we assign that neural activity correspond to the posterior expectation about an element of hidden states taking one. So once we define this mapping, then higher neural activity indicates the higher probability of taking one.				
1052362	1080725	Daniel	0.71441	17:32	So neural activity is the probability neural activity is on the x axis and the y axis of the sigmoid function is the probability of taking one. Well. Neural activity encodes the expectation. So neural activity is sigmoidal function of something itself.	So neural activity is the probability neural activity is on the x axis and the y axis of the sigmoid function is the probability of taking one. Well. Neural activity encodes the expectation. So neural activity is sigmoidal function of something itself.				
1088487	1120687	Takuya	0.99422	18:08	This is because once we see a fixed point of neural activity equation which is derived from this cos function, it has a form of sigma WADA function so x equals sigmawilder function of graph, graph, graph. So this form is exactly correspond to softwaremax function of something which is seen in the solution of possibly expectation.	This is because once we see a fixed point of neural activity equation which is derived from this cos function, it has a form of sigma WADA function so x equals sigmawilder function of graph, graph, graph. So this form is exactly correspond to softwaremax function of something which is seen in the solution of possibly expectation.				
1126600	1264775	Daniel	0.53186	18:46	That'S what the neural activity encodes and what is the Bayesian interpretation or the update rules on the plasticity. Okay, that's another important point. So in terms of posture of parameters so in the case of Bayesian force us we consider update about deleted parameters of a matrix and B matrix which is usually expressed by the small case variable. And its meaning is that if we compute the partial derivative of a partial derivative of F with respect to small A then its solution it's fixed point solution looks like an computer product of which is also known as Hebbian product because it has an errors drink to update depending on the precinaptic neuron activity and postsynaptic neuron activity. And according to this formal equivalent we revisit we can see again such analogy in a formal sense here if we computer the partial derivative of neural network function with respect to W then we can formally derive the Hebbian prosthesis which depends on the activity of prey and postsynaptic neuro activity.	That'S what the neural activity encodes and what is the Bayesian interpretation or the update rules on the plasticity. Okay, that's another important point. So in terms of posture of parameters so in the case of Bayesian force us we consider update about deleted parameters of a matrix and B matrix which is usually expressed by the small case variable. And its meaning is that if we compute the partial derivative of a partial derivative of F with respect to small A then its solution it's fixed point solution looks like an computer product of which is also known as Hebbian product because it has an errors drink to update depending on the precinaptic neuron activity and postsynaptic neuron activity. And according to this formal equivalent we revisit we can see again such analogy in a formal sense here if we computer the partial derivative of neural network function with respect to W then we can formally derive the Hebbian prosthesis which depends on the activity of prey and postsynaptic neuro activity.				
1268337	1333012	Daniel	0.88	21:08	Okay, so hebion plasticity often described as neurons that fired together, wired together. Here you're discussing it in terms of a matrix operation on the POMDP side between observables and hidden states. So there's a hebion plasticity happening between the perceptual layer and the cognitive layer, right? So the first half of the neural network is trained according to heavy and plasticity rules that optimize the A in terms of the perceptual and learning like relationship between hidden states and observables. And then the second half of the neural network has a slightly different structure.	Okay, so hebion plasticity often described as neurons that fired together, wired together. Here you're discussing it in terms of a matrix operation on the POMDP side between observables and hidden states. So there's a hebion plasticity happening between the perceptual layer and the cognitive layer, right? So the first half of the neural network is trained according to heavy and plasticity rules that optimize the A in terms of the perceptual and learning like relationship between hidden states and observables. And then the second half of the neural network has a slightly different structure.				
1333812	1350337	Daniel	0.97	22:13	It is optimizing based upon retroactive re analysis of consequences of action according to the fictive causality construction.	It is optimizing based upon retroactive re analysis of consequences of action according to the fictive causality construction.				
1353387	1396750	Takuya	0.79601	22:33	So actually in this figure b up layer correspond to environment and lower part correspond to agent. So this structure corresponds to figure eight, this correspond to a simpler version of foam DP. So for version of POMDP, its corresponding neural network is showing figure four or this paper image task. This is the neural network architectures.	So actually in this figure b up layer correspond to environment and lower part correspond to agent. So this structure corresponds to figure eight, this correspond to a simpler version of foam DP. So for version of POMDP, its corresponding neural network is showing figure four or this paper image task. This is the neural network architectures.				
1402712	1465275	Takuya	0.77476	23:22	So as you say, there is a network connection from sensory layer to cognition layer which is expressed by W here and recurrent connection which corresponds to state transient matrix is expressed by K matrix which is recurrent Sinematic connectivity. And as you say the action generation through retrospective reward or risk evolution is done by output trigger through the synaptic connectivity expressed as V in this figure. So V is the synaptic connectivity between cognitive states in the middle layer and the action selection states in Y. Exactly. And so in that way V is exactly analogous to W.	So as you say, there is a network connection from sensory layer to cognition layer which is expressed by W here and recurrent connection which corresponds to state transient matrix is expressed by K matrix which is recurrent Sinematic connectivity. And as you say the action generation through retrospective reward or risk evolution is done by output trigger through the synaptic connectivity expressed as V in this figure. So V is the synaptic connectivity between cognitive states in the middle layer and the action selection states in Y. Exactly. And so in that way V is exactly analogous to W.				
1465637	1476612	Daniel	0.73723	24:25	But why and how does gamma come into play only in this second layer? I mean why not have gamma one in the first layer? Gamma two in the second layer.	But why and how does gamma come into play only in this second layer? I mean why not have gamma one in the first layer? Gamma two in the second layer.				
1478987	1581382	Takuya	0.80447	24:38	Generally speaking, it is possible to moderate plasticity in first layer using another moderator gamma. But for complexity we focus only on neural modulation in the output layer. Analogy is that for example, as you said, the first rigor computer more perceptual things so perception of external world and instead on the other hand middle secondary which is mapping from cognition layer to action layer perform the optimization of its own action. So for example, in the story item in the brain action prediction is optimized by conversation of dopamine as a input. So usually that socket receives signal from ecological neural socket and send signal to another neuronal nucleus in meat grain.	Generally speaking, it is possible to moderate plasticity in first layer using another moderator gamma. But for complexity we focus only on neural modulation in the output layer. Analogy is that for example, as you said, the first rigor computer more perceptual things so perception of external world and instead on the other hand middle secondary which is mapping from cognition layer to action layer perform the optimization of its own action. So for example, in the story item in the brain action prediction is optimized by conversation of dopamine as a input. So usually that socket receives signal from ecological neural socket and send signal to another neuronal nucleus in meat grain.				
1581547	1645287	Takuya	0.93482	26:21	But the point here is that neuron in storatum encodes some decision for examples goal or no goal. So such a decision is encoded. So now we consider analogy between pond DP expression in the Bayesian formation and neural socket in the brain that optimize action through some sort of moderation by another factor. Here that factor corresponds to gamma and gamma has variety of function. But in this paper we focus only on the moderation of activity.	But the point here is that neuron in storatum encodes some decision for examples goal or no goal. So such a decision is encoded. So now we consider analogy between pond DP expression in the Bayesian formation and neural socket in the brain that optimize action through some sort of moderation by another factor. Here that factor corresponds to gamma and gamma has variety of function. But in this paper we focus only on the moderation of activity.				
1646387	1675950	Takuya	0.69458	27:26	So here the behavior activity is not determined by only a preposter relationship but determined by three factors relationship in the sense that the activity is updated by the product of gamma and prayer and postsynaptic activity. So there are three times in one.	So here the behavior activity is not determined by only a preposter relationship but determined by three factors relationship in the sense that the activity is updated by the product of gamma and prayer and postsynaptic activity. So there are three times in one.				
1678037	1682487	Takuya	0.92935	27:58	This is why this comma can moderate prosthesity.	This is why this comma can moderate prosthesity.				
1686150	1734590	Daniel	0.82575	28:06	So how would a glial factor look different computationally? And where in the brain have people identified levels or other factors as relevant for learning? Yeah, that's an interesting point. I'm not really sure about the equation of the real moderation of neural activity or plasticity. There are many discussions and I'm sorry, I don't know the exact form, but one possible implementation is similar to this type of neuromodulation.	So how would a glial factor look different computationally? And where in the brain have people identified levels or other factors as relevant for learning? Yeah, that's an interesting point. I'm not really sure about the equation of the real moderation of neural activity or plasticity. There are many discussions and I'm sorry, I don't know the exact form, but one possible implementation is similar to this type of neuromodulation.				
1734695	1758700	Takuya	0.78796	28:54	So it would be possible to model some real contribution or free factor to plasticity in the form of three factor learning room which is mathematically speaking Lamme as this type of neural moderation.	So it would be possible to model some real contribution or free factor to plasticity in the form of three factor learning room which is mathematically speaking Lamme as this type of neural moderation.				
1763750	1776225	Daniel	0.91288	29:23	Here in table two we have another set of correspondences. It's like a sideways figure three, right? But a little bit more like a dictionary.	Here in table two we have another set of correspondences. It's like a sideways figure three, right? But a little bit more like a dictionary.				
1780862	1815075	Daniel	0.97584	29:40	Anything to add? Or any variables that we haven't really mentioned. What about the firing thresholds? Because these are common parameters in a neural model, however, we don't really hear about the interpretation of these constructs within the variational base POMDP. Yeah, there is an interesting story.	Anything to add? Or any variables that we haven't really mentioned. What about the firing thresholds? Because these are common parameters in a neural model, however, we don't really hear about the interpretation of these constructs within the variational base POMDP. Yeah, there is an interesting story.				
1817462	1906437	Takuya	0.7155	30:17	That's a very interesting point. So when we first tried to make analogy between neurons network and one program is the law of threshold factor because as you said, it is not absorbing POMDP structure. But there is another factor in Pompey which is prior expectation about hidden state which is usually expressed by D matrix. And what we consider is the relationship between d matrix and firing threshold. And finally, what we found is that firing threshold is not equal to the matrix itself, but it is a summation of B matrix under some function of synaptic strength or which is equal to a matrix b matrix in the POMDP formation.	That's a very interesting point. So when we first tried to make analogy between neurons network and one program is the law of threshold factor because as you said, it is not absorbing POMDP structure. But there is another factor in Pompey which is prior expectation about hidden state which is usually expressed by D matrix. And what we consider is the relationship between d matrix and firing threshold. And finally, what we found is that firing threshold is not equal to the matrix itself, but it is a summation of B matrix under some function of synaptic strength or which is equal to a matrix b matrix in the POMDP formation.				
1906787	1968450	Takuya	0.96515	31:46	In other words, what we found is that each which is a firing solution in neural network architecture, it is actually an adaptive threshold which is not a fixed value, but h is a function of W sinatic strengths and h changes depending on W's value. For example, if W is too Laje, then your activity can be unstable. So h behavior to reduce the activity to make neural activity more stable. So we can see an analogy of omeostatic mechanism here.	In other words, what we found is that each which is a firing solution in neural network architecture, it is actually an adaptive threshold which is not a fixed value, but h is a function of W sinatic strengths and h changes depending on W's value. For example, if W is too Laje, then your activity can be unstable. So h behavior to reduce the activity to make neural activity more stable. So we can see an analogy of omeostatic mechanism here.				
1975562	2025900	Takuya	0.74871	32:55	If we design A as the function of w and function of another factor which is all part of the term in this table, then we could make common analogy between this h and some variable in palm DP correlation which is shown in the right hand side of this table. Although its value is not simple because it chaos three different tasks. So all of them contribute to make h or M.	If we design A as the function of w and function of another factor which is all part of the term in this table, then we could make common analogy between this h and some variable in palm DP correlation which is shown in the right hand side of this table. Although its value is not simple because it chaos three different tasks. So all of them contribute to make h or M.				
2028662	2050212	Takuya	0.66895	33:48	But anyway, once we map, so once we establish a mapping between h and this value, then everything works. So the cost function in different settings have Omar correspondence.	But anyway, once we map, so once we establish a mapping between h and this value, then everything works. So the cost function in different settings have Omar correspondence.				
2054462	2126562	Daniel	0.51	34:14	H and the M firing thresholds. So H correspond to middle rare M indicator output raider threshold which are different variables. And interestingly h correspond to prior expectation about hidden states because it corresponds to community rare and M correspond a priori belief about its own action because it is a bias in the action layer. Yeah, it's very interesting that the perceptual firing threshold h only includes prior beliefs on hidden states, beliefs about how observations map to hidden states A and beliefs about how hidden states change their time B. So that's like pure passive inference.	H and the M firing thresholds. So H correspond to middle rare M indicator output raider threshold which are different variables. And interestingly h correspond to prior expectation about hidden states because it corresponds to community rare and M correspond a priori belief about its own action because it is a bias in the action layer. Yeah, it's very interesting that the perceptual firing threshold h only includes prior beliefs on hidden states, beliefs about how observations map to hidden states A and beliefs about how hidden states change their time B. So that's like pure passive inference.				
2127212	2167662	Daniel	0.89	35:27	And then the firing thresholds for M correspond to only beliefs about preferences and beliefs about actions or habits with C and E. So there's like a complete division of labor or partitioning functionally between these structurally different parts of the neural network and structurally different and functionally different parts of the POMDP. Yet they're integrated in unified loss functions or unified imperatives.	And then the firing thresholds for M correspond to only beliefs about preferences and beliefs about actions or habits with C and E. So there's like a complete division of labor or partitioning functionally between these structurally different parts of the neural network and structurally different and functionally different parts of the POMDP. Yet they're integrated in unified loss functions or unified imperatives.				
2170037	2216562	Daniel	0.77	36:10	And so it's like there's extreme separability of perception and action on both sides of the figure one divide, but also they're integrated, but they're separate. And that's what kind of grants it the best of both worlds because if they were any more integrated you couldn't really pull them apart. And if they were any less integrated then the imperative, the loss function or the variational free energy would be ad hoc and unprincipled. But there's kind of a middle ground where they have a principled integration but still a distinguishment.	And so it's like there's extreme separability of perception and action on both sides of the figure one divide, but also they're integrated, but they're separate. And that's what kind of grants it the best of both worlds because if they were any more integrated you couldn't really pull them apart. And if they were any less integrated then the imperative, the loss function or the variational free energy would be ad hoc and unprincipled. But there's kind of a middle ground where they have a principled integration but still a distinguishment.				
2218862	2219625	Takuya	0.76	36:58	Right?	Right?				
2221712	2256162	Takuya	0.98688	37:01	This is caused by network structure defined or it is because the structure of Bayesian network defined in the MDV model. So both of them define the causal relationship between elements or quantities.	This is caused by network structure defined or it is because the structure of Bayesian network defined in the MDV model. So both of them define the causal relationship between elements or quantities.				
2260187	2281212	Takuya	0.69466	37:40	Its substrate is not important, so it's relationship is crucial to determine the cost function or it's a fixed point in this context. So that's why we can see the data analogy.	Its substrate is not important, so it's relationship is crucial to determine the cost function or it's a fixed point in this context. So that's why we can see the data analogy.				
2284525	2321505	Daniel	0.93054	38:04	Well, there's a few technical points I think we can now go into and then there will be some more general points about applications and intelligence. So first the code availability statement. Awesome to see that the MATLAB scripts are available and also active on Zinodo. So here is the GitHub repo for reverse engineering. Do you want to give any overview descriptions of what people can expect to see in this repo?	Well, there's a few technical points I think we can now go into and then there will be some more general points about applications and intelligence. So first the code availability statement. Awesome to see that the MATLAB scripts are available and also active on Zinodo. So here is the GitHub repo for reverse engineering. Do you want to give any overview descriptions of what people can expect to see in this repo?				
2321640	2325050	Daniel	0.95	38:41	And also what about using MATLAB?	And also what about using MATLAB?				
2330062	2336087	Daniel	0.9991	38:50	Why did you use MATLAB? What advantages or limitations do you see in MATLAB?	Why did you use MATLAB? What advantages or limitations do you see in MATLAB?				
2338387	2351537	Takuya	0.56154	38:58	So, because this is a very simple simulation, so Macrab is sufficient to encode the whole script.	So, because this is a very simple simulation, so Macrab is sufficient to encode the whole script.				
2354812	2374937	Takuya	0.99404	39:14	We also try some implication in the material. See here, if you run the script, then you can see the process of an agent solving the maze task.	We also try some implication in the material. See here, if you run the script, then you can see the process of an agent solving the maze task.				
2379412	2419752	Daniel	0.94571	39:39	What did they do in the maze task? So here the aim of this agent is to reach the right hand side of this maze. Because this is a typical example of the rate moderation task. That's why we select the main task. So to achieve this next task, is it required to make some plan to be able to select a good decision?	What did they do in the maze task? So here the aim of this agent is to reach the right hand side of this maze. Because this is a typical example of the rate moderation task. That's why we select the main task. So to achieve this next task, is it required to make some plan to be able to select a good decision?				
2419932	2443700	Takuya	0.98116	40:19	Because without planning, you may encounter the war and cannot go further and you may fail the image. But with learning, it is possible to see the path to reach the right hand side of this space.	Because without planning, you may encounter the war and cannot go further and you may fail the image. But with learning, it is possible to see the path to reach the right hand side of this space.				
2446012	2449112	Daniel	0.85354	40:46	So does it know its exploration?	So does it know its exploration?				
2453137	2482192	Takuya	0.42	40:53	Yeah, it received a state from neighboring eleven times eleven Jelle. So which is shown in the bottom part. Yeah, this left figure C indicates the observation. So eleven times eleven state around the agent position. Okay.	Yeah, it received a state from neighboring eleven times eleven Jelle. So which is shown in the bottom part. Yeah, this left figure C indicates the observation. So eleven times eleven state around the agent position. Okay.				
2482240	2492900	Takuya	0.98	41:22	Now agent is on the right hand side of image at the goal position and it observes our neighboring state.	Now agent is on the right hand side of image at the goal position and it observes our neighboring state.				
2496937	2512325	Daniel	0.91225	41:36	Well, a few interesting things here. It's looking off the right end. Yeah. And it has this kind of periodic belief in the key distribution. Why?	Well, a few interesting things here. It's looking off the right end. Yeah. And it has this kind of periodic belief in the key distribution. Why?				
2515087	2582762	Takuya	0.99	41:55	I think it is because when the agent is in the middle point of maze, then all neighboring state is in the maze. So there is a path and there is a wall. So this makes some ergodicity because mazes have some structures and actually have a periodic structure and only at the goal position, then right hand side becomes war. But it is not common for this agent. This is because this agent show such a priori pattern.	I think it is because when the agent is in the middle point of maze, then all neighboring state is in the maze. So there is a path and there is a wall. So this makes some ergodicity because mazes have some structures and actually have a periodic structure and only at the goal position, then right hand side becomes war. But it is not common for this agent. This is because this agent show such a priori pattern.				
2584237	2618687	Daniel	0.9	43:04	Yeah, the streets are one wide and they tend to be separated by one. So we see this periodicity. What is the numbers in this middle bottom plot and what does the checker board represent? Yeah, hered correspond to possibility, expectation about active states and decision. So middle indicate decision posterior and decision.	Yeah, the streets are one wide and they tend to be separated by one. So we see this periodicity. What is the numbers in this middle bottom plot and what does the checker board represent? Yeah, hered correspond to possibility, expectation about active states and decision. So middle indicate decision posterior and decision.				
2619037	2662925	Takuya	0.64276	43:39	Here we characterize decision as a secret of four step actions. So each action correspond to a movement to right or left or up or down. And we consider a four step sequence of that option which is expressed as D. So it has four power, four possibility. 256.	Here we characterize decision as a secret of four step actions. So each action correspond to a movement to right or left or up or down. And we consider a four step sequence of that option which is expressed as D. So it has four power, four possibility. 256.				
2663812	2714912	Takuya	0.69	44:23	Yeah, 256. So this is a protein on XY coordinate because in the middle panel, middle point correspond to the current position of agent. And with four step movement, agent can go one of any current position and the current brightness corresponds to the expectation about the agent decision. Well this is very interesting. If we just were to think about you're at a point and you can go up, down, left, right, you have four moves.	Yeah, 256. So this is a protein on XY coordinate because in the middle panel, middle point correspond to the current position of agent. And with four step movement, agent can go one of any current position and the current brightness corresponds to the expectation about the agent decision. Well this is very interesting. If we just were to think about you're at a point and you can go up, down, left, right, you have four moves.				
2716462	2765837	Daniel	0.63299	45:16	Naively it sounds like, well it should look like a gaussian blur. Most of those should cancel out and then it should become rarer and rarer monotonically. But actually you start in the middle, you can't end up on these white squares because it's like one, two, three and then you have to leave. Right? So it's kind of like horses in chess or other pieces where actually their embodiment, it's very unexpected that you can't in four moves end up next to where you began when you can be so much further.	Naively it sounds like, well it should look like a gaussian blur. Most of those should cancel out and then it should become rarer and rarer monotonically. But actually you start in the middle, you can't end up on these white squares because it's like one, two, three and then you have to leave. Right? So it's kind of like horses in chess or other pieces where actually their embodiment, it's very unexpected that you can't in four moves end up next to where you began when you can be so much further.				
2766262	2804300	Daniel	0.95	46:06	And then we see this kind of like embodied inferential prior with QS that embodies regularity beliefs about the width of the road and the separation of the roads. And then there's these like embodied action priors and real consequences that have to do with the structure of movement. So what it's doing? It's thinking about policies of length four. There's 256 policies of length four.	And then we see this kind of like embodied inferential prior with QS that embodies regularity beliefs about the width of the road and the separation of the roads. And then there's these like embodied action priors and real consequences that have to do with the structure of movement. So what it's doing? It's thinking about policies of length four. There's 256 policies of length four.				
2804887	2829050	Daniel	0.86611	46:44	There's some degeneracy because there's obviously not 256 squares here. So while only one policy is going to take you up, up, down, down, other squares are reachable. Like the center square is probably the mode because it can be reached at least a handful of ways.	There's some degeneracy because there's obviously not 256 squares here. So while only one policy is going to take you up, up, down, down, other squares are reachable. Like the center square is probably the mode because it can be reached at least a handful of ways.				
2831587	2848550	Daniel	0.8	47:11	And then at each time point it's basically saying okay, I know where my X position is and given my local eleven by eleven view, I'm trying to plan to go right.	And then at each time point it's basically saying okay, I know where my X position is and given my local eleven by eleven view, I'm trying to plan to go right.				
2854662	2893075	Daniel	0.79	47:34	And then here through time in the simulation here it starts at 30 something, it quickly figures out how to get to about 40 and then it's kind of going up and down on 40. But it can't really break out because all of these bottom four routes are closed. It has a breakout and then very quickly it hits another plateau around 60. Right. Then it kind of has a very nice breakout and in just a few steps goes very far.	And then here through time in the simulation here it starts at 30 something, it quickly figures out how to get to about 40 and then it's kind of going up and down on 40. But it can't really break out because all of these bottom four routes are closed. It has a breakout and then very quickly it hits another plateau around 60. Right. Then it kind of has a very nice breakout and in just a few steps goes very far.				
2895162	2931487	Daniel	0.74883	48:15	So what is dopamine doing? Or how is Dopamine helping it in the plateau and then to break out of the plateau? Yes. So this agent learned this particular structure through many trials. So before training it failed to reach the goal, but after training it achieved such a nice behavior.	So what is dopamine doing? Or how is Dopamine helping it in the plateau and then to break out of the plateau? Yes. So this agent learned this particular structure through many trials. So before training it failed to reach the goal, but after training it achieved such a nice behavior.				
2932062	3020117	Takuya	0.55269	48:52	So to active this, the role of domain is that we design gamma function such that if the agent can move rightward with some distance during some time limit, then risk becomes small like say comma equals zero nor risk situation in that sense. In that case, this agent updates synaptic weights through hebion frostbust. But if the agent failed to go rightward with some distance during a limited time frame, then gamma becomes large like zero six which is larger than the average zero five. Then we design that drawing in attention antihebian prosthesis occurred instead of Hebbian. So antihabion indicates the works as the disassociation between the current state and current decisions.	So to active this, the role of domain is that we design gamma function such that if the agent can move rightward with some distance during some time limit, then risk becomes small like say comma equals zero nor risk situation in that sense. In that case, this agent updates synaptic weights through hebion frostbust. But if the agent failed to go rightward with some distance during a limited time frame, then gamma becomes large like zero six which is larger than the average zero five. Then we design that drawing in attention antihebian prosthesis occurred instead of Hebbian. So antihabion indicates the works as the disassociation between the current state and current decisions.				
3020252	3086287	Takuya	0.97194	50:20	Because the current decision does work, it's not good decision. So we try to make the agent who will get that particular decision rules through conversation of heavy and plasticity done by Dharma factory. So this can be an arrow to the Dopamine moderation heavy and activity. So if the policy is resulting in the expected outcome, gamma stays at .5, the policy is as risky or consequential as expected, and then the policy can either go better than expected, which facilitates learning to support that decision. To be made more or the outcome of the policy can be worse than expected, which disassociates previous conceptions to discourage that kind of behavior.	Because the current decision does work, it's not good decision. So we try to make the agent who will get that particular decision rules through conversation of heavy and plasticity done by Dharma factory. So this can be an arrow to the Dopamine moderation heavy and activity. So if the policy is resulting in the expected outcome, gamma stays at .5, the policy is as risky or consequential as expected, and then the policy can either go better than expected, which facilitates learning to support that decision. To be made more or the outcome of the policy can be worse than expected, which disassociates previous conceptions to discourage that kind of behavior.				
3086937	3129112	Takuya	0.95984	51:26	Exactly. Crucial point is that this association with different time frame in the sense that we consider multiplication of current risk and least decisions to average over past two present Hebbian product. This makes an association between past decision secrets and the current risk which enables to optimize decision to minimize the future risk. It is just a safe time frame.	Exactly. Crucial point is that this association with different time frame in the sense that we consider multiplication of current risk and least decisions to average over past two present Hebbian product. This makes an association between past decision secrets and the current risk which enables to optimize decision to minimize the future risk. It is just a safe time frame.				
3131562	3172612	Daniel	0.88848	52:11	So here risk is being used in a formal sense similar to how it's used in economics which is the associated uncertainty of outcomes with respect to a policy. Where does danger come into play? Like what if there was an adversary in the maze or something that was dangerous? How does this kind of model accommodate or hunger or different kinds of competitions? Because right now it's basically just trying to diffuse right word with a bias.	So here risk is being used in a formal sense similar to how it's used in economics which is the associated uncertainty of outcomes with respect to a policy. Where does danger come into play? Like what if there was an adversary in the maze or something that was dangerous? How does this kind of model accommodate or hunger or different kinds of competitions? Because right now it's basically just trying to diffuse right word with a bias.				
3173187	3220217	Takuya	0.63	52:53	Right? But how do different kind of situational elements become interface into the generative model and generative process? Okay, any of those factors can be involved in risk factor, a single risk factor. So you can arbitrary design and risk factor because risk factor moderate generative model. So that's why agent try to minimize the risk through basic embryo updating.	Right? But how do different kind of situational elements become interface into the generative model and generative process? Okay, any of those factors can be involved in risk factor, a single risk factor. So you can arbitrary design and risk factor because risk factor moderate generative model. So that's why agent try to minimize the risk through basic embryo updating.				
3220277	3241537	Takuya	0.98041	53:40	But the risk itself is in some sense outside of such a Bayesian framework. So we can design arbitrary risk. So it may involve some danger factor, any other factor.	But the risk itself is in some sense outside of such a Bayesian framework. So we can design arbitrary risk. So it may involve some danger factor, any other factor.				
3243762	3320775	Daniel	0.88	54:03	And this simulation, it is a POMDP or it is a neural network. And what scripts might we look at to understand the structure of the maze agents? Okay, it is basically expressed using the quantity in home depp for tractability. But for example, if you see the MDP learning probably okay, there is a variable Lamme type in the definition of SIM type correspond to the type of simulation. So if it's one or two it becomes homo DP or neural network to my understanding.	And this simulation, it is a POMDP or it is a neural network. And what scripts might we look at to understand the structure of the maze agents? Okay, it is basically expressed using the quantity in home depp for tractability. But for example, if you see the MDP learning probably okay, there is a variable Lamme type in the definition of SIM type correspond to the type of simulation. So if it's one or two it becomes homo DP or neural network to my understanding.				
3321200	3366000	Takuya	0.74102	55:21	Well, in this particular example, Jelle, we use the let's say maybe it's not good example that DeForest is learning the deforesting this script as well. So maybe another as an example, let's see.	Well, in this particular example, Jelle, we use the let's say maybe it's not good example that DeForest is learning the deforesting this script as well. So maybe another as an example, let's see.				
3369287	3428762	Daniel	0.83218	56:09	What is MDP init is initiating the markup decision process. Exactly. It's just determining the initial state of the computer generative model fe compute variational free energy or risk MDP computer risk function. So basically we use the neural network structure computation in this particular setup. So when you click maze m then in the line 31 line we determine that Lamme type is two.	What is MDP init is initiating the markup decision process. Exactly. It's just determining the initial state of the computer generative model fe compute variational free energy or risk MDP computer risk function. So basically we use the neural network structure computation in this particular setup. So when you click maze m then in the line 31 line we determine that Lamme type is two.				
3428825	3528472	Takuya	0.72494	57:08	This correspond to neural network architecture. So there is a very slight difference between home depicture and neural network architecture because assuming neural network architecture correspond to, you know, considering considering okay, well, if you choose the palm DP architectures, then we sometimes use the gamma function to computer the posterior expectation about parameters. But in the neural network modeling the gamma function doesn't appear but it is replaced with the logarithm of some function. And simply speaking, the difference between the gamma function of something and the logarithm function of something is asymmetry Lamme. So that's why we can transform home DP two neural network architectures.	This correspond to neural network architecture. So there is a very slight difference between home depicture and neural network architecture because assuming neural network architecture correspond to, you know, considering considering okay, well, if you choose the palm DP architectures, then we sometimes use the gamma function to computer the posterior expectation about parameters. But in the neural network modeling the gamma function doesn't appear but it is replaced with the logarithm of some function. And simply speaking, the difference between the gamma function of something and the logarithm function of something is asymmetry Lamme. So that's why we can transform home DP two neural network architectures.				
3528517	3532800	Takuya	0.94729	58:48	When the number of samples is sufficiently large.	When the number of samples is sufficiently large.				
3537287	3545325	Daniel	0.99719	58:57	Which form do you expect performs better under small or large amounts of data?	Which form do you expect performs better under small or large amounts of data?				
3547487	3595362	Takuya	0.70441	59:07	Well, for large amount of data they work in the same manner. Same manner. For small amount of examples, I'm not truly sure but it corresponds to assumptions about the posterior belief distribution. So if you assume delicious distribution then your resulting function form is something that used the gamma function in terms of basic inference probably which is optimal.	Well, for large amount of data they work in the same manner. Same manner. For small amount of examples, I'm not truly sure but it corresponds to assumptions about the posterior belief distribution. So if you assume delicious distribution then your resulting function form is something that used the gamma function in terms of basic inference probably which is optimal.				
3600512	3644412	Daniel	0.91989	1:00:00	All right, let's return to the earliest questions from today. So in your script, which people can reference, there's basically a toggle between having it in SIM type one or SIM type two corresponding to the POMDP in the neural network. What about if there's a published neural network or POMDP? How can we use this architecture to create a translation?	All right, let's return to the earliest questions from today. So in your script, which people can reference, there's basically a toggle between having it in SIM type one or SIM type two corresponding to the POMDP in the neural network. What about if there's a published neural network or POMDP? How can we use this architecture to create a translation?				
3648000	3665800	Daniel	0.99513	1:00:48	Is there any difference in this? Kind of like translating models in the wild different than the full construction of a special script that can speak both languages?	Is there any difference in this? Kind of like translating models in the wild different than the full construction of a special script that can speak both languages?				
3670500	3714995	Takuya	0.83567	1:01:10	Well, in terms of script there's no difference, sympathetic difference. Right. So they work in the same manner. So only a translation of variable the same source code in two different ways. So if you see that this is a neural network generation, then it is translated as a neural network.	Well, in terms of script there's no difference, sympathetic difference. Right. So they work in the same manner. So only a translation of variable the same source code in two different ways. So if you see that this is a neural network generation, then it is translated as a neural network.				
3715085	3719650	Takuya	0.92506	1:01:55	Or if you see that this is a POMDP, then it's POMDP.	Or if you see that this is a POMDP, then it's POMDP.				
3723075	3775000	Daniel	0.6676	1:02:03	So for some neural network being used in an industrial setting, how would we get from the neural network to a POMDP? And where or how would that representation be valuable? Right? So when neural network in the different architectures the important point is that we consider a particular form of neural network which is called canonical neural network architecture. So only when we assume this crossover neural network then you can find the exact correspondence to a particular form of POMDP.	So for some neural network being used in an industrial setting, how would we get from the neural network to a POMDP? And where or how would that representation be valuable? Right? So when neural network in the different architectures the important point is that we consider a particular form of neural network which is called canonical neural network architecture. So only when we assume this crossover neural network then you can find the exact correspondence to a particular form of POMDP.				
3775350	3790287	Takuya	0.6159	1:02:55	Otherwise you need to establish another equivalent between another form of neural network architectures and some sort of Bayesian model.	Otherwise you need to establish another equivalent between another form of neural network architectures and some sort of Bayesian model.				
3792825	3840275	Takuya	0.97673	1:03:12	This may be expressed by POMDP, but maybe not so straightforward to be expressed as the computational AP architectures. So what is it about the canonical neural network architecture that facilitates its translation into the POMDP form? Yeah, first of all, it assumes sigmoid or activation function. It is nicely correspond to enthralpy time in the force DP equations from DP formulations. So that's why we can clear marketing.	This may be expressed by POMDP, but maybe not so straightforward to be expressed as the computational AP architectures. So what is it about the canonical neural network architecture that facilitates its translation into the POMDP form? Yeah, first of all, it assumes sigmoid or activation function. It is nicely correspond to enthralpy time in the force DP equations from DP formulations. So that's why we can clear marketing.				
3840425	3882912	Takuya	0.64007	1:04:00	So yeah, in other words, simply speaking, they have the same nonlinearity. That's why this translation is very easy with another nonlinearity or neural network equation, then we need to find another type of entropy equation or another type of prior distribution. It is very nontrivial. How does one even go about doing that research?	So yeah, in other words, simply speaking, they have the same nonlinearity. That's why this translation is very easy with another nonlinearity or neural network equation, then we need to find another type of entropy equation or another type of prior distribution. It is very nontrivial. How does one even go about doing that research?				
3889575	3919137	Takuya	0.78348	1:04:49	If you want to go that direction, then I think the first step is to find the prior brief, which makes the prior brief and find the equivalence between a particular neural network architectures and particular Bayesian model.	If you want to go that direction, then I think the first step is to find the prior brief, which makes the prior brief and find the equivalence between a particular neural network architectures and particular Bayesian model.				
3925312	3983150	Daniel	0.89355	1:05:25	This sigmoidal activation is interesting. It corresponds to general patterns seen in psychophysics, like two objects that are the same weight. You're going to have a chance of saying that one is heavier and then initially the difference has the most returns on that decision being made accurately. And then as it crosses some threshold where it just is beyond a noticeable difference, the decision becomes essentially probabilistic, like the firing curve becomes saturated, the neuron chaos, a very low belief about zero or very high belief about zero or one flip that.	This sigmoidal activation is interesting. It corresponds to general patterns seen in psychophysics, like two objects that are the same weight. You're going to have a chance of saying that one is heavier and then initially the difference has the most returns on that decision being made accurately. And then as it crosses some threshold where it just is beyond a noticeable difference, the decision becomes essentially probabilistic, like the firing curve becomes saturated, the neuron chaos, a very low belief about zero or very high belief about zero or one flip that.				
3986587	4060700	Daniel	0.7448	1:06:26	So there is a nice grounding of that kind of a sigmoidal response curve with respect to stimuli differences and it has of course, tractable analytical properties, but it also just happens to be a good response summarizer. Yeah, you're right. So sigmoidar function is also known as a psychometric function, as you say. We observe that characteristic in many psychical experiments. And the previous work also said that even at the single neuron level, neuronal level, the same behavior were absorbed, which means that each heuristic we can reobserve the similar property, which is sometimes called as neurometric function, which is which have the form of sigmoida activation function.	So there is a nice grounding of that kind of a sigmoidal response curve with respect to stimuli differences and it has of course, tractable analytical properties, but it also just happens to be a good response summarizer. Yeah, you're right. So sigmoidar function is also known as a psychometric function, as you say. We observe that characteristic in many psychical experiments. And the previous work also said that even at the single neuron level, neuronal level, the same behavior were absorbed, which means that each heuristic we can reobserve the similar property, which is sometimes called as neurometric function, which is which have the form of sigmoida activation function.				
4063312	4076675	Takuya	0.79246	1:07:43	So it is nice reason to design neural network architecture using a sigmoid or function.	So it is nice reason to design neural network architecture using a sigmoid or function.				
4078837	4112925	Daniel	0.59847	1:07:58	All right, let's cover a few questions in the chat from Dave and then in the end turn to some general thoughts. Okay, this was when we were looking at figure three. So you described these vectors or matrices. What kind of matrix or vector did you describe? The mass block matrix.	All right, let's cover a few questions in the chat from Dave and then in the end turn to some general thoughts. Okay, this was when we were looking at figure three. So you described these vectors or matrices. What kind of matrix or vector did you describe? The mass block matrix.				
4114625	4116000	Takuya	0.76149	1:08:34	Block matrix.	Block matrix.				
4118900	4134587	Daniel	0.98356	1:08:38	Block rock learning what? Okay, rock matrix of rock. Vector is a vector vector or matrix of matrix. So imagine that.	Block rock learning what? Okay, rock matrix of rock. Vector is a vector vector or matrix of matrix. So imagine that.				
4142900	4184550	Daniel	0.9398	1:09:02	Sorry, just zoom, just glitch just repeat the last piece. Okay, well, broke matrix Dean that the element of matrix is a matrix. So let's say two by two matrix like matrix in the ear pointing. So this here W one hat is a matrix and W zero hat is another matrix. And combining four matrices, we define a single block matrix.	Sorry, just zoom, just glitch just repeat the last piece. Okay, well, broke matrix Dean that the element of matrix is a matrix. So let's say two by two matrix like matrix in the ear pointing. So this here W one hat is a matrix and W zero hat is another matrix. And combining four matrices, we define a single block matrix.				
4186625	4214087	Daniel	0.95029	1:09:46	All right, thank you. So Dave then asks the hosts of Machine Learning Street Talk Number 67 with Karl Friston. Another podcast, Karl Friston has spoken. Pressed Karl Friston on why is it so important that most of the values in a generative model matrix assume values of exactly zero?	All right, thank you. So Dave then asks the hosts of Machine Learning Street Talk Number 67 with Karl Friston. Another podcast, Karl Friston has spoken. Pressed Karl Friston on why is it so important that most of the values in a generative model matrix assume values of exactly zero?				
4217037	4223725	Daniel	0.99945	1:10:17	Why is it important that generative model matrices are sparse? Why?	Why is it important that generative model matrices are sparse? Why?				
4230687	4264575	Takuya	0.40258	1:10:30	I'm not Bull sure. I think there is some context before that point. I think on that particular situation, then, yeah, as you say, the many elements in the matrix or gentle model should be zero, but I'm not sure if it's a general statement at all. What do you think about compressed analyses on sparse matrices?	I'm not Bull sure. I think there is some context before that point. I think on that particular situation, then, yeah, as you say, the many elements in the matrix or gentle model should be zero, but I'm not sure if it's a general statement at all. What do you think about compressed analyses on sparse matrices?				
4268825	4282350	Daniel	0.99143	1:11:08	Is that a useful technique or direction?	Is that a useful technique or direction?				
4285850	4338665	Takuya	0.55	1:11:25	You can use that knowledge to construct model, so you can use that knowledge to make more accurate inference. So in that sense, generally speaking, such assumptions should be useful. For example, yeah, as you said, it would be possible to use some sparse prior to restrict the value of parameter. Like, it is in principle same as assuming some L one norm to design the distribution. To design the prior distribution, which is mass Dutch speaking.	You can use that knowledge to construct model, so you can use that knowledge to make more accurate inference. So in that sense, generally speaking, such assumptions should be useful. For example, yeah, as you said, it would be possible to use some sparse prior to restrict the value of parameter. Like, it is in principle same as assuming some L one norm to design the distribution. To design the prior distribution, which is mass Dutch speaking.				
4338757	4381050	Takuya	0.98723	1:12:18	Exactly same as considering Lasso regression. Yes. So we've explored a little bit how from a canonical neural network to a particular form of a POMDP, gives us some semantics and interpretability around the dynamics and plasticity of the neural network. What do we gain by taking a stated POMDP generative model and deriving an analogous neural network?	Exactly same as considering Lasso regression. Yes. So we've explored a little bit how from a canonical neural network to a particular form of a POMDP, gives us some semantics and interpretability around the dynamics and plasticity of the neural network. What do we gain by taking a stated POMDP generative model and deriving an analogous neural network?				
4383725	4391625	Daniel	0.96173	1:13:03	Do we gain access to efficient computation, new software packages, different applications?	Do we gain access to efficient computation, new software packages, different applications?				
4395462	4464637	Takuya	0.82167	1:13:15	Well, if one use Home DP and one's goal is so design an efficient basic model, then I think your Home DP expression is sufficient. So you don't need to consider neural network architecture, probably because Homedippy architecture and Bayesian correlation is designed to achieve some sort of mathematically optimal inference and decision making. Right? So it itself is optimal scheme. But if one need to consider a link between Bayesian inference and biological substrates, then this mapping is crucial.	Well, if one use Home DP and one's goal is so design an efficient basic model, then I think your Home DP expression is sufficient. So you don't need to consider neural network architecture, probably because Homedippy architecture and Bayesian correlation is designed to achieve some sort of mathematically optimal inference and decision making. Right? So it itself is optimal scheme. But if one need to consider a link between Bayesian inference and biological substrates, then this mapping is crucial.				
4468962	4508912	Takuya	0.81908	1:14:28	Simply speaking, we consider that we assume that a brain perform Beijing inference, but its substrate is still unclear. So we need to link the Bayesian quantity to biological quantities. So this mapping, this equivalent, helps us to its translation. Right? So when you start from on the model, then this translation facilitates the process of finding its neuronal substrate.	Simply speaking, we consider that we assume that a brain perform Beijing inference, but its substrate is still unclear. So we need to link the Bayesian quantity to biological quantities. So this mapping, this equivalent, helps us to its translation. Right? So when you start from on the model, then this translation facilitates the process of finding its neuronal substrate.				
4509062	4570547	Takuya	0.84098	1:15:09	So once you translate that to a basic to neural network quantities, then it facilitates the experimental validation application to reality. So if its modeling is apt for a particular neural network neural circuit architecture, then it should provide some prediction about the architecture or dynamics of the empirical data. Right? So first we start from Bayesian model, which is not necessary to be equal to empirical data. So there is some mapping, but it's mapping is not straightforward.	So once you translate that to a basic to neural network quantities, then it facilitates the experimental validation application to reality. So if its modeling is apt for a particular neural network neural circuit architecture, then it should provide some prediction about the architecture or dynamics of the empirical data. Right? So first we start from Bayesian model, which is not necessary to be equal to empirical data. So there is some mapping, but it's mapping is not straightforward.				
4570742	4600750	Takuya	0.99871	1:16:10	We may have multiple mappings, but once you translate Bayesian model to a particular neural network architectures then mapping or relationship between applicable data to such a particular neural network model is straightforward. So it helps us to apply base to an explanation of MP card data.	We may have multiple mappings, but once you translate Bayesian model to a particular neural network architectures then mapping or relationship between applicable data to such a particular neural network model is straightforward. So it helps us to apply base to an explanation of MP card data.				
4606737	4684687	Daniel	0.71314	1:16:46	So is it fair to say that neural networks have found wide recent application because they facilitate statistical learning in cases where the inference problem has not been a priori well specified? One can just have a folder of images and a list of labels and just say, here's the data. Run it through this architecture or this architecture Explorer. And so with this concordance we gain new interpretation into those settings that kind of arose from ill specified inference problems. And then on the other hand, for problems that we already have well specified in terms of a POMDP generative model of a particular form, we gain the connection to actually implement it with empirical data and bring it into relevant industrial settings.	So is it fair to say that neural networks have found wide recent application because they facilitate statistical learning in cases where the inference problem has not been a priori well specified? One can just have a folder of images and a list of labels and just say, here's the data. Run it through this architecture or this architecture Explorer. And so with this concordance we gain new interpretation into those settings that kind of arose from ill specified inference problems. And then on the other hand, for problems that we already have well specified in terms of a POMDP generative model of a particular form, we gain the connection to actually implement it with empirical data and bring it into relevant industrial settings.				
4687987	4711937	Daniel	0.99833	1:18:07	What systems or phenomena are promising to continue research on the image example obviously is a simple case, but are you continuing research into more advanced computational agents? Robotic animal.	What systems or phenomena are promising to continue research on the image example obviously is a simple case, but are you continuing research into more advanced computational agents? Robotic animal.				
4716200	4792725	Takuya	0.45	1:18:36	Oh, hello can design a more sophisticated agent which performs some difficult tasks based on canonical network neural network but there is some limitation, clear limitation on that direction. Right? So yeah, I should emphasize that across the canonical neural network which correspond to a particular home DP is much smaller than general home DP framework. So there are some limitations, a least of limitations. So if one's goal is designed and sophisticated DAGs to perform some task or control robot, then one direction is just forget such limitations and take the mathematical optimality right and another direction is barrelscale probability.	Oh, hello can design a more sophisticated agent which performs some difficult tasks based on canonical network neural network but there is some limitation, clear limitation on that direction. Right? So yeah, I should emphasize that across the canonical neural network which correspond to a particular home DP is much smaller than general home DP framework. So there are some limitations, a least of limitations. So if one's goal is designed and sophisticated DAGs to perform some task or control robot, then one direction is just forget such limitations and take the mathematical optimality right and another direction is barrelscale probability.				
4793075	4833975	Takuya	0.69135	1:19:53	So if one wants to image some agent which is barely possible, then this correspondence is crucial because it tells us biological limitations through the existence, no existence of such a mapping between POMDP and particular neural network architectures. So, yeah. So it would be useful to consider a vertical substrate to achieve exafferent task.	So if one wants to image some agent which is barely possible, then this correspondence is crucial because it tells us biological limitations through the existence, no existence of such a mapping between POMDP and particular neural network architectures. So, yeah. So it would be useful to consider a vertical substrate to achieve exafferent task.				
4842162	4887412	Takuya	0.72	1:20:42	And that task would be related to high dimension image processing. Image recognition or sound recognition, such as multimodality, can be inbox or decision. Can be higher dimensional like in the mainstays, we just consider the four directional movement, but it can be extended to higher dimensionality, like arm movement, body movement, so on, so on. So in principle it can be extended in that direction.	And that task would be related to high dimension image processing. Image recognition or sound recognition, such as multimodality, can be inbox or decision. Can be higher dimensional like in the mainstays, we just consider the four directional movement, but it can be extended to higher dimensionality, like arm movement, body movement, so on, so on. So in principle it can be extended in that direction.				
4890312	4970012	Daniel	0.99753	1:21:30	Which directions or questions are you excited about? Or what areas of studying the basis of biological and computational intelligence are relevant? Yes. So in terms of the importance of canonical network, as you said, virtue is a biological probability. So it would be nice that if we model some task which is conducted by learning and one already recorded some neural activity, then we design a task which is exactly same as the task which is done by the animal and then compare the simulated agent and Mpcar data to discuss about the similarity or difference between the simulated agent and the animals.	Which directions or questions are you excited about? Or what areas of studying the basis of biological and computational intelligence are relevant? Yes. So in terms of the importance of canonical network, as you said, virtue is a biological probability. So it would be nice that if we model some task which is conducted by learning and one already recorded some neural activity, then we design a task which is exactly same as the task which is done by the animal and then compare the simulated agent and Mpcar data to discuss about the similarity or difference between the simulated agent and the animals.				
4970162	4973950	Takuya	0.9869	1:22:50	That would be very interesting direction of research.	That would be very interesting direction of research.				
4976862	5041987	Daniel	0.53	1:22:56	Yeah, and if there could be some unexpected prediction or explanation in the computational agent, that would bolster the relationship. And then one other aspect is it would help with the reproducibility and the documentation around behavior studies if the computational agent were preregistered and someone said we've already done the statistical power analysis and we've already explored with parameter sweeps how many observations we need to make of the two armed bandit. How many observations of the three armed bandit should we do? Three mice 100 times or 100 mice three times? Those are the total substance of designing research programs.	Yeah, and if there could be some unexpected prediction or explanation in the computational agent, that would bolster the relationship. And then one other aspect is it would help with the reproducibility and the documentation around behavior studies if the computational agent were preregistered and someone said we've already done the statistical power analysis and we've already explored with parameter sweeps how many observations we need to make of the two armed bandit. How many observations of the three armed bandit should we do? Three mice 100 times or 100 mice three times? Those are the total substance of designing research programs.				
5042862	5055787	Daniel	0.92	1:24:02	And so having a formal representation of behavioral tasks that are being studied will help us design behavior observations and experiments that aren't simply ad hoc.	And so having a formal representation of behavioral tasks that are being studied will help us design behavior observations and experiments that aren't simply ad hoc.				
5060037	5063875	Takuya	0.60984	1:24:20	All right, that's an interesting application.	All right, that's an interesting application.				
5066862	5159972	Takuya	0.52986	1:24:26	This framework helps to design the experimental setup itself. And what we often consider is the prediction ability of these modern canonical neural networks to predict the Jelle phoneization or dynamics of the VR neural network in the animal during the learning process. So in place for it is possible to predict the behavior after learning based only on data in the initial stage because once we obtain some empirical data, then we can fit that data to design a particular canonical network. And canonical neural network makes some correlation through a minimization cost function which is exactly same as the Bayesian belief updating under a particular guarantee model. So which means that its dynamics goes through the shortest path on the free energy landscape which means that we can make some quantitative prediction about the sinatic trajectory or neural activity or any kind of parameters.	This framework helps to design the experimental setup itself. And what we often consider is the prediction ability of these modern canonical neural networks to predict the Jelle phoneization or dynamics of the VR neural network in the animal during the learning process. So in place for it is possible to predict the behavior after learning based only on data in the initial stage because once we obtain some empirical data, then we can fit that data to design a particular canonical network. And canonical neural network makes some correlation through a minimization cost function which is exactly same as the Bayesian belief updating under a particular guarantee model. So which means that its dynamics goes through the shortest path on the free energy landscape which means that we can make some quantitative prediction about the sinatic trajectory or neural activity or any kind of parameters.				
5160167	5224537	Takuya	0.87602	1:26:00	So we demonstrated that using in virtual neural network and uploaded some footprint recently. So at the stage, at least at the level in vitro network, which is much simpler than VR brain, we could predict the self organization of in virtual network using this canonical network architecture and this support the probability of free energy principle because this canonical network predict the communication through the variational free energy minimization and its solution. Its results have a very tight correlation between correlation to Archer synchronization.	So we demonstrated that using in virtual neural network and uploaded some footprint recently. So at the stage, at least at the level in vitro network, which is much simpler than VR brain, we could predict the self organization of in virtual network using this canonical network architecture and this support the probability of free energy principle because this canonical network predict the communication through the variational free energy minimization and its solution. Its results have a very tight correlation between correlation to Archer synchronization.				
5227962	5287847	Daniel	0.93658	1:27:07	That's a very interesting experiment. So what animal were the neurons from and what was measured about these neurons? Yes, so that in vitro network is obtained from blood embryo, we use cortical cells to make that individual network and task is sort of causal inference task which can be designed in the form of OMDP. So imagine that we usually simulate agents that receive signals generated by OMDP generative process and process and Beijing task. So we just replaced that Bayesian agent to neural network.	That's a very interesting experiment. So what animal were the neurons from and what was measured about these neurons? Yes, so that in vitro network is obtained from blood embryo, we use cortical cells to make that individual network and task is sort of causal inference task which can be designed in the form of OMDP. So imagine that we usually simulate agents that receive signals generated by OMDP generative process and process and Beijing task. So we just replaced that Bayesian agent to neural network.				
5287967	5311537	Takuya	0.87125	1:28:07	So we stimulate neuron with some signal which is made by some hidden sources through like a human mapping and question is whether in viral network can info the hidden states through some communication and they can they could Ines the hidden culture.	So we stimulate neuron with some signal which is made by some hidden sources through like a human mapping and question is whether in viral network can info the hidden states through some communication and they can they could Ines the hidden culture.				
5315112	5381500	Daniel	0.97665	1:28:35	What does it look like functionally when the neural network has succeeded at inferring the hidden causes? Yeah, the direct conversation is done by the response number response spikes to a particular pattern sensory input. So again, we can see a clear correspondence between activity level and posterior belief about hidden state. So here we see re a book response to an electropaste memory. We see the response from ten to 13 milliseconds after each stimulation and we compute the number of spikes and that spikes changes their preference in the sense that some neurons learn to preferentially respond to force one but not source two.	What does it look like functionally when the neural network has succeeded at inferring the hidden causes? Yeah, the direct conversation is done by the response number response spikes to a particular pattern sensory input. So again, we can see a clear correspondence between activity level and posterior belief about hidden state. So here we see re a book response to an electropaste memory. We see the response from ten to 13 milliseconds after each stimulation and we compute the number of spikes and that spikes changes their preference in the sense that some neurons learn to preferentially respond to force one but not source two.				
5382237	5488237	Takuya	0.53913	1:29:42	So which is not a response to input itself, but it looks like a response to particular source. So it is inference which is empirical evidence that neural network actually perform some sort of causal inference in a manner consistent with traditional Bayesian inference. And then we compute another quantity in Bayesian inference in the real vertical data. We show that firing special factor is consistent with the prior belief about hidden states and we also compute the synaptic rate statistically through some connection strength estimation method and show that the estimated synaptic strength is consistent with something encoding posterior belief about parameters, as expected by the theory. Well, we looked at table two earlier and this is almost like the next step after the theoretical concordance is all right, well, let's measure the release of a neurotransmitter or the empirical synaptic strength or the firing threshold or all these different features in different empirical systems.	So which is not a response to input itself, but it looks like a response to particular source. So it is inference which is empirical evidence that neural network actually perform some sort of causal inference in a manner consistent with traditional Bayesian inference. And then we compute another quantity in Bayesian inference in the real vertical data. We show that firing special factor is consistent with the prior belief about hidden states and we also compute the synaptic rate statistically through some connection strength estimation method and show that the estimated synaptic strength is consistent with something encoding posterior belief about parameters, as expected by the theory. Well, we looked at table two earlier and this is almost like the next step after the theoretical concordance is all right, well, let's measure the release of a neurotransmitter or the empirical synaptic strength or the firing threshold or all these different features in different empirical systems.				
5488962	5496250	Daniel	0.67467	1:31:28	So what experimental systems does your group work in?	So what experimental systems does your group work in?				
5502012	5557322	Takuya	0.94215	1:31:42	That in virtual system was made when I was a PhD student. So that is experiment we done in my previous route and now I COVID to the Bijan Institute and I'm a Princepal investigator of Celery unit. So now actually we don't use any experimental setup, so any experimental bidding is down with some collaboration. So although I cannot say detail about that exploration. But yeah, we learn some collaborating work about the implication of salary using various animals.	That in virtual system was made when I was a PhD student. So that is experiment we done in my previous route and now I COVID to the Bijan Institute and I'm a Princepal investigator of Celery unit. So now actually we don't use any experimental setup, so any experimental bidding is down with some collaboration. So although I cannot say detail about that exploration. But yeah, we learn some collaborating work about the implication of salary using various animals.				
5557517	5565700	Takuya	0.5	1:32:37	Yeah, so we hope we can show some interesting results following results using animal data.	Yeah, so we hope we can show some interesting results following results using animal data.				
5569662	5625175	Daniel	0.99012	1:32:49	Very interesting. Yeah, well, it speaks a lot to the stage that our field is in in certain ways where we've seen a lot of graphics that are suggestive. This paper and the building on the previous 2020 paper made a suggestive possibility much closer to an analytically demonstrated translation and then took the next step incrementally into the in silico agent. And so it's only natural to then explore different embodied systems as well.	Very interesting. Yeah, well, it speaks a lot to the stage that our field is in in certain ways where we've seen a lot of graphics that are suggestive. This paper and the building on the previous 2020 paper made a suggestive possibility much closer to an analytically demonstrated translation and then took the next step incrementally into the in silico agent. And so it's only natural to then explore different embodied systems as well.				
5630862	5647300	Daniel	0.98285	1:33:50	Are there any other sections that you wanted to like, look at or highlight or any other topics about the paper or adjacencies or active inference that you think are interesting to go into?	Are there any other sections that you wanted to like, look at or highlight or any other topics about the paper or adjacencies or active inference that you think are interesting to go into?				
5650212	5696792	Takuya	0.6	1:34:10	Yeah, okay, I would like to mention about some implication of these papers, which is not the director discussing the papers. So for example, well, we focus on a discrete state space model. So we avoid to assume some subscript that encodes the coherence of the distribution. So once you assume homedp then it is categorical distinctions. So it is different from assuming Gaussian distribution characterized by me and variants.	Yeah, okay, I would like to mention about some implication of these papers, which is not the director discussing the papers. So for example, well, we focus on a discrete state space model. So we avoid to assume some subscript that encodes the coherence of the distribution. So once you assume homedp then it is categorical distinctions. So it is different from assuming Gaussian distribution characterized by me and variants.				
5696927	5768062	Takuya	0.80197	1:34:56	So the neural substrate of variance is still unclear and we now try to figure out that. So this is one direction of limitation and another implication is that thanks to a simple ODP structure in this paper, we don't care about the hierarchical optimization. But generally it is crucial to update parameters through hierarchical optimization through some backpropagation like computation. Although it is unclear whether back propagation itself occurred in the real brain. But we still have some alternative that achieve such optimization and it's neural substrate still unclear and this paper doesn't address that direction.	So the neural substrate of variance is still unclear and we now try to figure out that. So this is one direction of limitation and another implication is that thanks to a simple ODP structure in this paper, we don't care about the hierarchical optimization. But generally it is crucial to update parameters through hierarchical optimization through some backpropagation like computation. Although it is unclear whether back propagation itself occurred in the real brain. But we still have some alternative that achieve such optimization and it's neural substrate still unclear and this paper doesn't address that direction.				
5785650	5841015	Daniel	0.99885	1:36:25	Another area I'm wondering about is like where in neural structures is the learning reflected? Where is the function and learning reflected? Well, sometimes it has to do with not just structural Tweaking, but the presence or absence of synapses. So obviously this model does not expand into synaptogenesis synaptic pruning, let alone neurogenesis and neuro allostasis which we mentioned in the previous discussion. But understanding how these larger scale structural changes which are certainly important in biological systems become reflected in artificial neural networks and then how that translates all the way back to P-O-M.	Another area I'm wondering about is like where in neural structures is the learning reflected? Where is the function and learning reflected? Well, sometimes it has to do with not just structural Tweaking, but the presence or absence of synapses. So obviously this model does not expand into synaptogenesis synaptic pruning, let alone neurogenesis and neuro allostasis which we mentioned in the previous discussion. But understanding how these larger scale structural changes which are certainly important in biological systems become reflected in artificial neural networks and then how that translates all the way back to P-O-M.				
5841032	5880690	Daniel	0.46854	1:37:21	DP and then whether we could go the other way. What kinds of POMDP structures in their neural network realization would have structural modification. Like you COVID imagine a POMDP that does structure learning but the neural network doesn't have structural change. Or there's A-P-O-M DP that doesn't do structural learning but it's manifested by a neural network that does have a structural change element. So structure is doing something very different in these two different categories of model.	DP and then whether we could go the other way. What kinds of POMDP structures in their neural network realization would have structural modification. Like you COVID imagine a POMDP that does structure learning but the neural network doesn't have structural change. Or there's A-P-O-M DP that doesn't do structural learning but it's manifested by a neural network that does have a structural change element. So structure is doing something very different in these two different categories of model.				
5880857	5920020	Daniel	0.53	1:38:00	And then also even within neural firing, which is different amongst different species and so on, there's different aspects of what that firing is that would have different implications for the actual biological substrate of cognition niche. The simple connection is firing rate to posterior belief. Average firing rate, no change in posterior. Reduce the firing rate if the posterior should be going down. Increase it if it should be going up.	And then also even within neural firing, which is different amongst different species and so on, there's different aspects of what that firing is that would have different implications for the actual biological substrate of cognition niche. The simple connection is firing rate to posterior belief. Average firing rate, no change in posterior. Reduce the firing rate if the posterior should be going down. Increase it if it should be going up.				
5920172	5953150	Daniel	0.99332	1:38:40	Or maybe there are neurons that have a flipped valence but the same type of relationship, but there's other firing patterns like spike time dependent plasticity synchronization amongst different brain regions. There's a lot of things that don't change the rate overall. That again from the biological systems we know that those phenomena and mechanism are important for different cognitive processes.	Or maybe there are neurons that have a flipped valence but the same type of relationship, but there's other firing patterns like spike time dependent plasticity synchronization amongst different brain regions. There's a lot of things that don't change the rate overall. That again from the biological systems we know that those phenomena and mechanism are important for different cognitive processes.				
5957400	5963337	Daniel	0.85317	1:39:17	So there will be many many years of a fruitful relationship.	So there will be many many years of a fruitful relationship.				
5965875	6040075	Daniel	0.72879	1:39:25	I'm going to bring in this picture that Alexandra had taken. Maybe we need a third panel in figure one because these three systems moving between them is going to be the substance of the field for a long time and there may be other edges to build. But understanding how artificial neural networks intermediate between the empirical measurements and manipulations that we can make of real neural systems and the interpretability and factorizability of POMDPs it might be a bridge too far to go from the POMDP to the neuron. You could always use this technique but it would be a purely descriptive statistic type approach.	I'm going to bring in this picture that Alexandra had taken. Maybe we need a third panel in figure one because these three systems moving between them is going to be the substance of the field for a long time and there may be other edges to build. But understanding how artificial neural networks intermediate between the empirical measurements and manipulations that we can make of real neural systems and the interpretability and factorizability of POMDPs it might be a bridge too far to go from the POMDP to the neuron. You could always use this technique but it would be a purely descriptive statistic type approach.				
6042825	6112737	Daniel	0.92793	1:40:42	But it's so interesting that by intermediating through a formal connection established in figure one I Dean in equation one but also shown here, then we can kind of extend the chain of exploration, prediction, control, design all the way on through. And that just unlocks like an incredible amount of neuroscience that hasn't been formalized mathematically and an incredible amount of generative models that have been specified for different learning settings sometimes even by analogy to biological settings. But the metaphor remains just a metaphor until it's possible to intermediate with this type of neural network development. Yeah, that's a crucial point.	But it's so interesting that by intermediating through a formal connection established in figure one I Dean in equation one but also shown here, then we can kind of extend the chain of exploration, prediction, control, design all the way on through. And that just unlocks like an incredible amount of neuroscience that hasn't been formalized mathematically and an incredible amount of generative models that have been specified for different learning settings sometimes even by analogy to biological settings. But the metaphor remains just a metaphor until it's possible to intermediate with this type of neural network development. Yeah, that's a crucial point.				
6116400	6131937	Takuya	0.61	1:41:56	It is easy to imagine that phenomena can be modeled using very realistic neural model or free model synaptic model. Right.	It is easy to imagine that phenomena can be modeled using very realistic neural model or free model synaptic model. Right.				
6134400	6210850	Takuya	0.91038	1:42:14	We believe that it is possible and then Laje model is not necessarily tractable, not necessarily useful because it's too much complicated to analyze something. So we use some reduction, usually mathematically speaking, which correspond to topological transformation to make the model simpler. And then we need to consider the translation of that simplified neural network model because neural network model itself is not explainable which just represents some dynamics and its functional meaning is not clear. But thanks to the Bayesian framework we have a very nice event framework to least the experiment ability. And this translation, this correspondence helped us to link such a phenomena base equation modeling and functional base equations.	We believe that it is possible and then Laje model is not necessarily tractable, not necessarily useful because it's too much complicated to analyze something. So we use some reduction, usually mathematically speaking, which correspond to topological transformation to make the model simpler. And then we need to consider the translation of that simplified neural network model because neural network model itself is not explainable which just represents some dynamics and its functional meaning is not clear. But thanks to the Bayesian framework we have a very nice event framework to least the experiment ability. And this translation, this correspondence helped us to link such a phenomena base equation modeling and functional base equations.				
6212250	6303700	Daniel	0.83	1:43:32	Yeah, one paper from 2017 that was much discussed by some could a neuroscientist understand a microprocessor? And this group with Jonas and Courting, they had a simulation of a microprocessor from an earlier video game console, I believe. And then using the analogy of like the transistors and their connections as neural firing and structural connectivity they were able to simulate experimental settings, input and action and then make measurements from every neuron including doing lesions and loss of functions and so on. And it turns out that a lot of the techniques that are used to derive scientific explanation from analogous data collected from a biological system, those techniques which ostensibly should be isolating functional explanations in fact did not isolate effective exploration. You could have a deletion over here that induces some statistical change all the way over here and that may or may not be a useful clue towards the function of even subcircuits.	Yeah, one paper from 2017 that was much discussed by some could a neuroscientist understand a microprocessor? And this group with Jonas and Courting, they had a simulation of a microprocessor from an earlier video game console, I believe. And then using the analogy of like the transistors and their connections as neural firing and structural connectivity they were able to simulate experimental settings, input and action and then make measurements from every neuron including doing lesions and loss of functions and so on. And it turns out that a lot of the techniques that are used to derive scientific explanation from analogous data collected from a biological system, those techniques which ostensibly should be isolating functional explanations in fact did not isolate effective exploration. You could have a deletion over here that induces some statistical change all the way over here and that may or may not be a useful clue towards the function of even subcircuits.				
6304575	6364450	Daniel	0.85	1:45:04	And so I think that was a wake up call with respect to the interpretability of simply this connection between the biological and the neural network. This connection alone is of limited applicability even when the neural network model becomes so complex as to recapitulate the biological phenomena, you're never under any guarantee that you're going to recover interpretability. You may have just created an atomic level simulation of the phenomena, but of course, a map that is the same scale as the phenomena isn't a map. It's just a copy that has no more interpretability.	And so I think that was a wake up call with respect to the interpretability of simply this connection between the biological and the neural network. This connection alone is of limited applicability even when the neural network model becomes so complex as to recapitulate the biological phenomena, you're never under any guarantee that you're going to recover interpretability. You may have just created an atomic level simulation of the phenomena, but of course, a map that is the same scale as the phenomena isn't a map. It's just a copy that has no more interpretability.				
6366600	6433750	Daniel	0.91	1:46:06	And it's almost like what is now extended again, as we kind of just summarize this and think about how we move forward, is that connection can now be extended into the space of interpretable causal models and the generalized Bayesian graphical computational frameworks and all the heuristic that we can then use like variational, Bayes and all these other methods. So it'd be interesting to look back at different data sets of in vitro and in vivo and in silico neural activation, especially if the task was of this constrained set of POMDPs and it was already amenable. Because, as you brought up, other settings would require a little bit more theory development before we understand what POMDP family would be applicable.	And it's almost like what is now extended again, as we kind of just summarize this and think about how we move forward, is that connection can now be extended into the space of interpretable causal models and the generalized Bayesian graphical computational frameworks and all the heuristic that we can then use like variational, Bayes and all these other methods. So it'd be interesting to look back at different data sets of in vitro and in vivo and in silico neural activation, especially if the task was of this constrained set of POMDPs and it was already amenable. Because, as you brought up, other settings would require a little bit more theory development before we understand what POMDP family would be applicable.				
6439650	6444837	Takuya	0.98211	1:47:19	Cool. Well, do you have any final thoughts or questions?	Cool. Well, do you have any final thoughts or questions?				
6447300	6450625	Takuya	0.61238	1:47:27	Well, do you hop.	Well, do you hop.				
6454912	6511487	Daniel	0.64	1:47:34	I kant to download the MATLAB scripts and generate the figures, play around with a few of these parameters? Like, I see that you can change how far the entity can see. And then with these models, I'm also always curious about the computational complexity. Like if you extended the planning horizon from four to five or you dropped it down to three, what is the runtime consequences and what is the performance consequences? And where might we be able to use single or swarms of really simple agent, maybe even making binary decisions and achieve high performance?	I kant to download the MATLAB scripts and generate the figures, play around with a few of these parameters? Like, I see that you can change how far the entity can see. And then with these models, I'm also always curious about the computational complexity. Like if you extended the planning horizon from four to five or you dropped it down to three, what is the runtime consequences and what is the performance consequences? And where might we be able to use single or swarms of really simple agent, maybe even making binary decisions and achieve high performance?				
6512437	6569387	Daniel	0.97	1:48:32	And where do we really need to move into these large combinatoric spaces in order to solve problems and the kinds of complex planning problems that we solve, whether it's planning our day or planning our week, are those force like true Deep Harrison planning problems with extensive consideration of counterfactuals and calculation of alternatives? Or are those actually composite decisions that are made up of smaller, simpler, sub decisions that we may or may not have flexibility to restructure?	And where do we really need to move into these large combinatoric spaces in order to solve problems and the kinds of complex planning problems that we solve, whether it's planning our day or planning our week, are those force like true Deep Harrison planning problems with extensive consideration of counterfactuals and calculation of alternatives? Or are those actually composite decisions that are made up of smaller, simpler, sub decisions that we may or may not have flexibility to restructure?				
6571612	6598262	Daniel	0.96082	1:49:31	So that a decision, a complex chess maneuver, a sacrifice in chess or another game. It may be possible to model that as a Deep Horizon scan or a kind of intuitive heuristic for an appropriate skilled entity.	So that a decision, a complex chess maneuver, a sacrifice in chess or another game. It may be possible to model that as a Deep Horizon scan or a kind of intuitive heuristic for an appropriate skilled entity.				
6601537	6666812	Takuya	0.98303	1:50:01	For this particular two Brea structure, there is a clear limitation about the horizon forward because it doesn't use forward prediction, it used post action approach. So it's a clear limitation, but still, it may have some performance ability, active, some levels of affordance. That provides even another way to look at planning. The two ways I was describing planning, as it's often described in the PMDP literature is again, is it a true Deep Horizon consideration or is it just short term heuristics or nested models that are short? And I think that this paper says maybe neither.	For this particular two Brea structure, there is a clear limitation about the horizon forward because it doesn't use forward prediction, it used post action approach. So it's a clear limitation, but still, it may have some performance ability, active, some levels of affordance. That provides even another way to look at planning. The two ways I was describing planning, as it's often described in the PMDP literature is again, is it a true Deep Horizon consideration or is it just short term heuristics or nested models that are short? And I think that this paper says maybe neither.				
6667537	6701150	Daniel	0.99168	1:51:07	Maybe it's purely the active causality on the past that leads to the emergence of sentient and maybe even teleological planninglike behavior through the ongoing reconsideration of the consequences of least action. But it's neither a short nor a long term planning challenge. It's actually like a memory and learning challenge. And no planning occurs. Right.	Maybe it's purely the active causality on the past that leads to the emergence of sentient and maybe even teleological planninglike behavior through the ongoing reconsideration of the consequences of least action. But it's neither a short nor a long term planning challenge. It's actually like a memory and learning challenge. And no planning occurs. Right.				
6702637	6765050	Takuya	0.39078	1:51:42	Indirect planning planning element is involving C matrix. Planning as a phenomenon occurs and derisking through time occurs. But it says something quite interesting and deep that that phenotype or function could be enacted by a system that explicitly looks a long way ahead, explicitly looks a short way ahead or moves forward and looks backwards only, right, which is what they sometimes say about the past and the future. So that may be a very biologically plausible form of learning. And it's already intimately connected with the dynamics and the activity in terms of an integrated loss function.	Indirect planning planning element is involving C matrix. Planning as a phenomenon occurs and derisking through time occurs. But it says something quite interesting and deep that that phenotype or function could be enacted by a system that explicitly looks a long way ahead, explicitly looks a short way ahead or moves forward and looks backwards only, right, which is what they sometimes say about the past and the future. So that may be a very biologically plausible form of learning. And it's already intimately connected with the dynamics and the activity in terms of an integrated loss function.				
6766537	6801697	Daniel	0.77175	1:52:46	So these are all excellent directions to keep learning on. Right? And I'm also interested in the barrel implementation of such a short term or long term for the prediction and running. And I hope to find some nice connectivity to such implementation of Bayesian motor and implementation in VR brain network. Cool.	So these are all excellent directions to keep learning on. Right? And I'm also interested in the barrel implementation of such a short term or long term for the prediction and running. And I hope to find some nice connectivity to such implementation of Bayesian motor and implementation in VR brain network. Cool.				
6801880	6859112	Daniel	0.89	1:53:21	And also I'm always curious about the invertebrate brain as an ant researcher. And so many of the brain architectures as well as the brain architecture that people discuss are mammalian centric, which makes sense. The mammalian cortical column and the relationship with Dopaminergic midbrain and the cortical regions and the spinal reflex arc those are all important systems of interest. Yet the micro and meso anatomy of the invertebrate nervous system is pretty distinct. So our model should be able to describe neural and cognitive systems, of course, across invertebrates and vertebrates.	And also I'm always curious about the invertebrate brain as an ant researcher. And so many of the brain architectures as well as the brain architecture that people discuss are mammalian centric, which makes sense. The mammalian cortical column and the relationship with Dopaminergic midbrain and the cortical regions and the spinal reflex arc those are all important systems of interest. Yet the micro and meso anatomy of the invertebrate nervous system is pretty distinct. So our model should be able to describe neural and cognitive systems, of course, across invertebrates and vertebrates.				
6859537	6881162	Daniel	0.784	1:54:19	So I look forward to also seeing what those models of the invertebrate nervous system and collective behavior where you could have some type of backwards looking risk inference of the swarm. Who knows?	So I look forward to also seeing what those models of the invertebrate nervous system and collective behavior where you could have some type of backwards looking risk inference of the swarm. Who knows?				
6883537	6884300	Takuya	0.71772	1:54:43	Well.	Well.				
6886537	6899462	Daniel	0.99306	1:54:46	We really appreciate the time that you took for these discussions. I think they are immensely important. And we wish you the best of luck in these continued directions.	We really appreciate the time that you took for these discussions. I think they are immensely important. And we wish you the best of luck in these continued directions.				
6903387	6904150	Takuya	0.08	1:55:03	Yes.	Yes.				
6906612	6912712	Daniel	0.96	1:55:06	Okay, that's it. Thank you. Thank you very much. See you next time. Bye.	Okay, that's it. Thank you. Thank you very much. See you next time. Bye.				
