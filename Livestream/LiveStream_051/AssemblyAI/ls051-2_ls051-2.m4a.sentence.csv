33087	34897	A	0.59	Hello and welcome everyone.
35080	38497	A	0.99746	This is ActInf livestream number 51.
38605	39322	A	0.93	Two.
39505	42350	A	0.72179	It's November 9, 2022.
43162	45807	A	0.96897	Welcome to the the active inference institute.
45972	53427	A	0.45771	We're a participatory online institute that is communication, learning and practicing applied active inference.
53607	60350	A	0.99727	This is a recorded and an archived livestream, so please provide us feedback so we can improve our work.
60712	75962	A	0.99845	All backgrounds and perspectives are welcome and we'll be following video etiquette for live streams, head over active inference.org to learn more about participating in different institute projects.
76912	83137	A	0.65597	Alright, well, we're in act imp stream number 51.2.
83275	86407	A	0.62576	We're in our third discussion on the paper.
86485	91942	A	0.98074	Canonical neural networks perform active inference from 2022.
92140	97962	A	0.98635	We had a dot zero video with some background and context and overview.
98112	109557	A	0.91	And then last week in 51.1 we had a great discussion, went over many interesting details of the paper and related topics.
109722	121700	A	0.94925	So today we're going to jump in, cover some empirical details, some implications, connect some more dots, maybe look at some code.
122362	126437	A	0.9	And thanks again to Kuya for joining these discussions.
127537	157937	A	0.91426	I'm Daniel, I'm a researcher in California and thought a lot over the last week about what this kind of neural network synthesis or translation really means, and just want to learn more about what fundamentals or foundational aspects of these different kinds of models enable that synthesis or translation.
158287	166657	A	0.96	And then again what that means for areas where one or the other kind of model is already in use.
166810	181175	A	0.62533	So thanks again for joining and I'll pass it to you if you want to say hi or give any a second interoception.
182875	188600	B	0.52	Oh yeah, I'm appearing Brain Science Institute, Japan.
189175	199687	B	0.3867	So I look forward to discuss another different aspect of this work.
203200	219112	A	0.72989	Well, let's just remind ourselves of the fundamental parallel being made in the paper and then we'll get to these two questions about kind of the two directions that things can go.
219925	230505	A	1.0	One representation is in equation one with loss function of a neural network and the free energy on a POMDP.
230640	242640	A	0.94	And that's also seen visually in figure one, with a neural network being drawn a concordance against the variational base of the action perception loop.
242745	246650	A	0.87661	So maybe just let's begin by restating.
247000	256912	A	0.99697	What is this parallel that is in equation one and figure one and how was it reached in this paper?
259375	298550	B	0.52086	So basically idea here is that we derived to characterize the dynamics and activity of canonical neural network in terms of Bayesian inference, because arbitrary dynamics of neural network is interoceptive in the sense that we don't know what is the function underlying such a dynamics and what is the coherence of the self organization or activity.
300100	323900	B	0.81982	So once we translate that dynamics in terms of Bayesian, we can assign quantities in Bayesian for any biological quantities, which enables us to lend the explainability to the neural network dynamics and architectures.
324250	326620	B	0.71077	So that's a basic idea.
326772	341325	B	0.79	And what we have done in this paper is that we consider a biological plausible cost function for this particular canonical neural network.
341400	353587	B	0.95	And show the equivalence between that Costa function and the variation navy energy and the particular partially observable cognition process model.
357850	358660	A	0.99513	Awesome.
358842	368410	A	0.84919	So let's look at the parallel between the cost function for neural networks and the informational free energy.
368592	373060	A	0.86367	So one representation of that was in figure three.
373242	385537	A	0.78216	So maybe could you just describe what is the structure of the informational free energy expression and what is the structure of the loss function?
386950	402562	B	0.83	Okay, so there is a clear parallel between the functional structure or those component in informational free energy and component in neural network Costa function.
403000	418850	B	0.78027	So let's say the first time in F correspond to the it correspond to the expectation about hidden states is a hidden states Australia.
419950	429550	B	0.60769	So that part basically indicates the free energy with respect to the hidden state.
429612	439155	B	0.4	Yeah, and the second part correspond to the free energy about the decision posterior.
439290	446525	B	0.56694	So the indicates the posterior belief about agent decision or action.
448300	494525	B	0.62	And now in terms of the correspondence between the free energy and neural network function here the first time in the neural network function correspond to middle layer neural activity which has a recurrent connection and receive sensory input from sensory layer and then project the output to the output layer and the second term correspond to output layer which receive signals from middle layer and send the feedback response to the environment.
505037	523287	A	0.57621	So both of us expressions have the first term being more like a cognition perceptual sensory learning term and the second term is more like a control theoretic action selection.
523787	535275	A	0.73	And how did you see this analogy or concordance because it looks like a zipper, like everything is totally lined up.
538137	563427	B	0.62176	Well, this graph itself showed a clear correspondence because now we are considering a particular form of on DP in which each element of hidden states takes either zero or one.
563595	574987	B	0.88682	But there are many states so it is expressed in a form of factorization.
575712	584597	B	0.86137	So now we consider that in terms of the s fosteria Bordeaux.
584792	600672	B	0.94466	Upper part of Bordeaux correspond to the expectation about each element of s taking one and lower part of the bordese correspond to the expectation about s taking zero.
600780	648637	B	0.87236	So it is broke vector about the posterior expectation and this nicely correspond to the Brea vector shown in the bottom up this figure it is a vector of x and Bijan sorry it is a vector of x and by x and here by x indicate one minus x in the element y sense which is exactly correspond to block vector or expectation.
650412	658987	B	0.78737	This correspondence also observed in the second tab.
659562	675792	B	0.97913	Here, log S correspond to log X and also log A correspond to the broke matrix of W log W.
675990	689500	B	0.96934	Here W hat indicates the sigmoidal function of W and its bar means sigmoidal function of W.
690237	705262	B	0.68523	So actually, because we now consider binary hidden state and binary observation it's like reviewed mapping.
706137	718600	B	0.70532	Mapping from hidden states to conversation is expressed as block matrix, which is exactly correspond to broke matrix shown in the bottom of this figure.
724775	735225	B	0.6376	So like this, for every tab we have the exact correspondence between the upper expression and the lower expression.
737825	747525	B	0.56482	So that's why we can say that this is a natural mapping from neural network formation to parishional vision formation.
751137	758812	B	0.54554	So it speaks a sort of identity between those two different expressions.
760062	774712	B	0.68291	So although 1 may be able to consider another mapping from neural network to Bayesian inference, this is a sort of simplest mapping.
777012	785972	A	0.75003	So how would it look different if it were three states categorical distribution or a continuous distribution?
786092	788650	A	0.99482	What aspects would change?
789462	792267	B	0.99691	Thank you for asking that.
792315	813167	B	0.68898	So that's in some sense outside of this paper because only when we consider a binary hidden state, this analogy is established nicely.
813302	818212	B	0.99393	Otherwise we need to consider some attention.
818862	849632	B	0.51667	So because consider that each neuron code the probability or expectation of some value taking one, then the probability or expectation of taking zero can be simply computed by computing one Ines neural activity.
849722	859997	B	0.70664	So actually neural activity which is a single dimensional variable is sufficient to express the expectation.
860192	860817	B	0.54	Right?
860940	871287	B	0.94105	But once we consider the three state hidden states program, this doesn't work.
871350	886150	B	0.87898	So we need to consider at least two variables but it's relation to neural network expression is not very clear in general.
891987	909562	A	0.85864	That's very interesting why it would be so strong of a concordance in a binary case but immediately unclear for other distributions.
910737	940000	B	0.63	Yeah, generally for poem DB expression we consider the one hot expression, one hot vector expression which means that we normalize the value in the sense that the summation of all variable to be one.
941562	947177	B	0.98868	Maybe there is some neural substrate that achieve that communication.
947357	964062	B	0.94493	But for classic type of neural network like canonical neural network, consider in this paper what is that neural substrate is not very clear.
964200	973537	B	0.53636	So that's why we selected the binary case because it's simple and have a clear analogy.
974637	988537	A	0.88138	So what does it mean for an artificial or for a biological neuron to have activity dynamics or plasticity context?
989487	998662	A	0.99709	That justifies it being described as playing like a belief role in a Bayesian setting.
1001625	1005620	A	0.9992	Higher firing means more belief, higher firing means lower belief.
1005710	1011537	A	0.99945	What does it really mean to have a connection between in this episode of street talk belief states.
1012200	1022780	B	0.97	I see, so if you assign a mapping, a particular mapping, then its meaning is also determined.
1022915	1036680	B	0.99872	In this case, we assign that neural activity correspond to the posterior expectation about an element of hidden states taking one.
1036877	1046037	B	0.88078	So once we define this mapping, then higher neural activity indicates the higher probability of taking one.
1052362	1065575	A	0.71441	So neural activity is the probability neural activity is on the x axis and the y axis of the sigmoid function is the probability of taking one.
1067362	1068125	A	0.84374	Well.
1069837	1074662	B	0.36792	Neural activity encodes the expectation.
1075012	1080725	B	0.66802	So neural activity is sigmoidal function of something itself.
1088487	1104287	B	0.99422	This is because once we see a fixed point of neural activity equation which is derived from this cos function, it has a form of sigma WADA function so x equals sigmawilder function of graph, graph, graph.
1104437	1120687	B	0.71398	So this form is exactly correspond to softwaremax function of something which is seen in the solution of possibly expectation.
1126600	1136300	A	0.53186	That'S what the neural activity encodes and what is the Bayesian interpretation or the update rules on the plasticity.
1137775	1142215	B	0.89	Okay, that's another important point.
1142382	1167425	B	0.66692	So in terms of posture of parameters so in the case of Bayesian force us we consider update about deleted parameters of a matrix and B matrix which is usually expressed by the small case variable.
1168525	1215650	B	0.7	And its meaning is that if we compute the partial derivative of a partial derivative of F with respect to small A then its solution it's fixed point solution looks like an computer product of which is also known as Hebbian product because it has an errors drink to update depending on the precinaptic neuron activity and postsynaptic neuron activity.
1216075	1264775	B	0.57	And according to this formal equivalent we revisit we can see again such analogy in a formal sense here if we computer the partial derivative of neural network function with respect to W then we can formally derive the Hebbian prosthesis which depends on the activity of prey and postsynaptic neuro activity.
1268337	1276975	A	0.88	Okay, so hebion plasticity often described as neurons that fired together, wired together.
1277562	1288975	A	0.99252	Here you're discussing it in terms of a matrix operation on the POMDP side between observables and hidden states.
1289937	1304425	A	0.87718	So there's a hebion plasticity happening between the perceptual layer and the cognitive layer, right?
1304787	1325062	A	0.55324	So the first half of the neural network is trained according to heavy and plasticity rules that optimize the A in terms of the perceptual and learning like relationship between hidden states and observables.
1326387	1333012	A	0.93	And then the second half of the neural network has a slightly different structure.
1333812	1350337	A	0.97	It is optimizing based upon retroactive re analysis of consequences of action according to the fictive causality construction.
1353387	1365582	B	0.79601	So actually in this figure b up layer correspond to environment and lower part correspond to agent.
1365660	1374587	B	0.79607	So this structure corresponds to figure eight, this correspond to a simpler version of foam DP.
1374662	1392475	B	0.81401	So for version of POMDP, its corresponding neural network is showing figure four or this paper image task.
1393575	1396750	B	0.50307	This is the neural network architectures.
1402712	1426657	B	0.77476	So as you say, there is a network connection from sensory layer to cognition layer which is expressed by W here and recurrent connection which corresponds to state transient matrix is expressed by K matrix which is recurrent Sinematic connectivity.
1426747	1449225	B	0.95	And as you say the action generation through retrospective reward or risk evolution is done by output trigger through the synaptic connectivity expressed as V in this figure.
1451087	1461150	A	0.76938	So V is the synaptic connectivity between cognitive states in the middle layer and the action selection states in Y.
1461587	1461947	B	0.66981	Exactly.
1461980	1465275	A	0.4	And so in that way V is exactly analogous to W.
1465637	1472017	A	0.73723	But why and how does gamma come into play only in this second layer?
1472077	1474747	A	0.63	I mean why not have gamma one in the first layer?
1474792	1476612	A	0.98243	Gamma two in the second layer.
1478987	1491997	B	0.80447	Generally speaking, it is possible to moderate plasticity in first layer using another moderator gamma.
1492117	1498512	B	0.9622	But for complexity we focus only on neural modulation in the output layer.
1499237	1543137	B	0.63938	Analogy is that for example, as you said, the first rigor computer more perceptual things so perception of external world and instead on the other hand middle secondary which is mapping from cognition layer to action layer perform the optimization of its own action.
1543487	1559412	B	0.78206	So for example, in the story item in the brain action prediction is optimized by conversation of dopamine as a input.
1559837	1581382	B	0.87918	So usually that socket receives signal from ecological neural socket and send signal to another neuronal nucleus in meat grain.
1581547	1592932	B	0.93482	But the point here is that neuron in storatum encodes some decision for examples goal or no goal.
1593022	1596237	B	0.74657	So such a decision is encoded.
1596812	1622917	B	0.69224	So now we consider analogy between pond DP expression in the Bayesian formation and neural socket in the brain that optimize action through some sort of moderation by another factor.
1623052	1638452	B	0.97904	Here that factor corresponds to gamma and gamma has variety of function.
1638545	1645287	B	0.94935	But in this paper we focus only on the moderation of activity.
1646387	1672117	B	0.69458	So here the behavior activity is not determined by only a preposter relationship but determined by three factors relationship in the sense that the activity is updated by the product of gamma and prayer and postsynaptic activity.
1672252	1675950	B	0.50966	So there are three times in one.
1678037	1682487	B	0.92935	This is why this comma can moderate prosthesity.
1686150	1692515	A	0.82575	So how would a glial factor look different computationally?
1692695	1700937	A	1.0	And where in the brain have people identified levels or other factors as relevant for learning?
1702200	1704975	B	0.85	Yeah, that's an interesting point.
1705112	1713665	B	0.58256	I'm not really sure about the equation of the real moderation of neural activity or plasticity.
1713770	1734590	B	0.98436	There are many discussions and I'm sorry, I don't know the exact form, but one possible implementation is similar to this type of neuromodulation.
1734695	1758700	B	0.78796	So it would be possible to model some real contribution or free factor to plasticity in the form of three factor learning room which is mathematically speaking Lamme as this type of neural moderation.
1763750	1769175	A	0.91288	Here in table two we have another set of correspondences.
1769825	1773500	A	0.96497	It's like a sideways figure three, right?
1773637	1776225	A	0.81108	But a little bit more like a dictionary.
1780862	1782017	A	0.97584	Anything to add?
1782065	1784925	A	0.9954	Or any variables that we haven't really mentioned.
1786712	1788622	A	0.99824	What about the firing thresholds?
1788667	1808112	A	0.98679	Because these are common parameters in a neural model, however, we don't really hear about the interpretation of these constructs within the variational base POMDP.
1809587	1815075	B	0.84	Yeah, there is an interesting story.
1817462	1820087	B	0.7155	That's a very interesting point.
1820150	1847412	B	0.63476	So when we first tried to make analogy between neurons network and one program is the law of threshold factor because as you said, it is not absorbing POMDP structure.
1847762	1864812	B	0.97029	But there is another factor in Pompey which is prior expectation about hidden state which is usually expressed by D matrix.
1866062	1875007	B	0.62	And what we consider is the relationship between d matrix and firing threshold.
1875172	1906437	B	0.57	And finally, what we found is that firing threshold is not equal to the matrix itself, but it is a summation of B matrix under some function of synaptic strength or which is equal to a matrix b matrix in the POMDP formation.
1906787	1942787	B	0.96515	In other words, what we found is that each which is a firing solution in neural network architecture, it is actually an adaptive threshold which is not a fixed value, but h is a function of W sinatic strengths and h changes depending on W's value.
1942850	1950982	B	0.99669	For example, if W is too Laje, then your activity can be unstable.
1951072	1961262	B	0.6935	So h behavior to reduce the activity to make neural activity more stable.
1961837	1968450	B	0.65713	So we can see an analogy of omeostatic mechanism here.
1975562	2009887	B	0.74871	If we design A as the function of w and function of another factor which is all part of the term in this table, then we could make common analogy between this h and some variable in palm DP correlation which is shown in the right hand side of this table.
2010037	2018677	B	0.98297	Although its value is not simple because it chaos three different tasks.
2018707	2025900	B	0.68279	So all of them contribute to make h or M.
2028662	2041412	B	0.66895	But anyway, once we map, so once we establish a mapping between h and this value, then everything works.
2041550	2050212	B	0.66673	So the cost function in different settings have Omar correspondence.
2054462	2057562	A	0.51	H and the M firing thresholds.
2057987	2072752	B	0.73874	So H correspond to middle rare M indicator output raider threshold which are different variables.
2072932	2098737	B	0.62	And interestingly h correspond to prior expectation about hidden states because it corresponds to community rare and M correspond a priori belief about its own action because it is a bias in the action layer.
2100437	2122622	A	0.83	Yeah, it's very interesting that the perceptual firing threshold h only includes prior beliefs on hidden states, beliefs about how observations map to hidden states A and beliefs about how hidden states change their time B.
2122805	2126562	A	0.84124	So that's like pure passive inference.
2127212	2140097	A	0.89	And then the firing thresholds for M correspond to only beliefs about preferences and beliefs about actions or habits with C and E.
2140280	2157462	A	0.94592	So there's like a complete division of labor or partitioning functionally between these structurally different parts of the neural network and structurally different and functionally different parts of the POMDP.
2159162	2167662	A	0.99334	Yet they're integrated in unified loss functions or unified imperatives.
2170037	2188662	A	0.77	And so it's like there's extreme separability of perception and action on both sides of the figure one divide, but also they're integrated, but they're separate.
2189462	2198187	A	0.87	And that's what kind of grants it the best of both worlds because if they were any more integrated you couldn't really pull them apart.
2198612	2209662	A	0.77	And if they were any less integrated then the imperative, the loss function or the variational free energy would be ad hoc and unprincipled.
2210537	2216562	A	0.93471	But there's kind of a middle ground where they have a principled integration but still a distinguishment.
2218862	2219625	B	0.76	Right?
2221712	2248022	B	0.98688	This is caused by network structure defined or it is because the structure of Bayesian network defined in the MDV model.
2248205	2256162	B	0.77204	So both of them define the causal relationship between elements or quantities.
2260187	2275882	B	0.69466	Its substrate is not important, so it's relationship is crucial to determine the cost function or it's a fixed point in this context.
2276047	2281212	B	0.61599	So that's why we can see the data analogy.
2284525	2297190	A	0.93054	Well, there's a few technical points I think we can now go into and then there will be some more general points about applications and intelligence.
2297370	2302440	A	0.68174	So first the code availability statement.
2302620	2309970	A	0.99627	Awesome to see that the MATLAB scripts are available and also active on Zinodo.
2310135	2315525	A	0.7824	So here is the GitHub repo for reverse engineering.
2316250	2321505	A	0.9914	Do you want to give any overview descriptions of what people can expect to see in this repo?
2321640	2325050	A	0.95	And also what about using MATLAB?
2330062	2332347	A	0.9991	Why did you use MATLAB?
2332467	2336087	A	0.99573	What advantages or limitations do you see in MATLAB?
2338387	2351537	B	0.56154	So, because this is a very simple simulation, so Macrab is sufficient to encode the whole script.
2354812	2360952	B	0.99404	We also try some implication in the material.
2361057	2374937	B	0.48282	See here, if you run the script, then you can see the process of an agent solving the maze task.
2379412	2381837	A	0.94571	What did they do in the maze task?
2382787	2394887	B	0.74946	So here the aim of this agent is to reach the right hand side of this maze.
2396287	2401572	B	0.94778	Because this is a typical example of the rate moderation task.
2401692	2405237	B	0.76268	That's why we select the main task.
2406637	2419752	B	0.68969	So to achieve this next task, is it required to make some plan to be able to select a good decision?
2419932	2433612	B	0.98116	Because without planning, you may encounter the war and cannot go further and you may fail the image.
2433762	2443700	B	0.66598	But with learning, it is possible to see the path to reach the right hand side of this space.
2446012	2449112	A	0.85354	So does it know its exploration?
2453137	2460642	B	0.42	Yeah, it received a state from neighboring eleven times eleven Jelle.
2460702	2464312	B	0.4492	So which is shown in the bottom part.
2464375	2473287	B	0.49	Yeah, this left figure C indicates the observation.
2473362	2481125	B	0.8096	So eleven times eleven state around the agent position.
2481787	2482192	B	0.65	Okay.
2482240	2492900	B	0.98	Now agent is on the right hand side of image at the goal position and it observes our neighboring state.
2496937	2500237	A	0.91225	Well, a few interesting things here.
2500300	2503250	A	0.96452	It's looking off the right end.
2503762	2504392	B	0.51	Yeah.
2504515	2511137	A	0.9	And it has this kind of periodic belief in the key distribution.
2511562	2512325	A	0.93001	Why?
2515087	2533377	B	0.99	I think it is because when the agent is in the middle point of maze, then all neighboring state is in the maze.
2533407	2539025	B	0.73393	So there is a path and there is a wall.
2539762	2562650	B	0.73986	So this makes some ergodicity because mazes have some structures and actually have a periodic structure and only at the goal position, then right hand side becomes war.
2563687	2570450	B	0.96869	But it is not common for this agent.
2572312	2582762	B	0.71443	This is because this agent show such a priori pattern.
2584237	2590325	A	0.9	Yeah, the streets are one wide and they tend to be separated by one.
2591362	2593527	A	0.81855	So we see this periodicity.
2593707	2601062	A	0.99286	What is the numbers in this middle bottom plot and what does the checker board represent?
2601487	2611527	B	0.43	Yeah, hered correspond to possibility, expectation about active states and decision.
2611632	2618687	B	0.87547	So middle indicate decision posterior and decision.
2619037	2627547	B	0.64276	Here we characterize decision as a secret of four step actions.
2627667	2638700	B	0.87321	So each action correspond to a movement to right or left or up or down.
2639362	2648047	B	0.66	And we consider a four step sequence of that option which is expressed as D.
2648230	2659637	B	0.80469	So it has four power, four possibility.
2661337	2662925	A	0.75	256.
2663812	2666077	B	0.69	Yeah, 256.
2666245	2681707	B	0.62411	So this is a protein on XY coordinate because in the middle panel, middle point correspond to the current position of agent.
2681860	2704637	B	0.78	And with four step movement, agent can go one of any current position and the current brightness corresponds to the expectation about the agent decision.
2705662	2707597	A	0.69868	Well this is very interesting.
2707780	2714912	A	0.99766	If we just were to think about you're at a point and you can go up, down, left, right, you have four moves.
2716462	2721362	A	0.63299	Naively it sounds like, well it should look like a gaussian blur.
2721862	2728302	A	0.99987	Most of those should cancel out and then it should become rarer and rarer monotonically.
2728482	2743550	A	0.90543	But actually you start in the middle, you can't end up on these white squares because it's like one, two, three and then you have to leave.
2744737	2745500	B	0.57	Right?
2745862	2765837	A	0.8349	So it's kind of like horses in chess or other pieces where actually their embodiment, it's very unexpected that you can't in four moves end up next to where you began when you can be so much further.
2766262	2781062	A	0.95	And then we see this kind of like embodied inferential prior with QS that embodies regularity beliefs about the width of the road and the separation of the roads.
2781412	2793362	A	0.68	And then there's these like embodied action priors and real consequences that have to do with the structure of movement.
2794837	2796277	A	0.80491	So what it's doing?
2796370	2801272	A	0.88178	It's thinking about policies of length four.
2801380	2804300	A	0.79751	There's 256 policies of length four.
2804887	2810602	A	0.86611	There's some degeneracy because there's obviously not 256 squares here.
2810770	2819142	A	0.78411	So while only one policy is going to take you up, up, down, down, other squares are reachable.
2819202	2829050	A	0.88609	Like the center square is probably the mode because it can be reached at least a handful of ways.
2831587	2848550	A	0.8	And then at each time point it's basically saying okay, I know where my X position is and given my local eleven by eleven view, I'm trying to plan to go right.
2854662	2868025	A	0.79	And then here through time in the simulation here it starts at 30 something, it quickly figures out how to get to about 40 and then it's kind of going up and down on 40.
2868987	2876662	A	0.99299	But it can't really break out because all of these bottom four routes are closed.
2877162	2883325	A	0.69	It has a breakout and then very quickly it hits another plateau around 60.
2884212	2884975	B	0.41	Right.
2885562	2893075	A	0.98765	Then it kind of has a very nice breakout and in just a few steps goes very far.
2895162	2897217	A	0.74883	So what is dopamine doing?
2897265	2902987	A	0.99511	Or how is Dopamine helping it in the plateau and then to break out of the plateau?
2903562	2904325	B	0.46	Yes.
2904762	2918852	B	0.63112	So this agent learned this particular structure through many trials.
2919032	2931487	B	0.74828	So before training it failed to reach the goal, but after training it achieved such a nice behavior.
2932062	2961057	B	0.55269	So to active this, the role of domain is that we design gamma function such that if the agent can move rightward with some distance during some time limit, then risk becomes small like say comma equals zero nor risk situation in that sense.
2961135	2969437	B	0.98256	In that case, this agent updates synaptic weights through hebion frostbust.
2970087	2993112	B	0.92191	But if the agent failed to go rightward with some distance during a limited time frame, then gamma becomes large like zero six which is larger than the average zero five.
2993250	3007012	B	0.69215	Then we design that drawing in attention antihebian prosthesis occurred instead of Hebbian.
3007512	3020117	B	0.60554	So antihabion indicates the works as the disassociation between the current state and current decisions.
3020252	3026732	B	0.97194	Because the current decision does work, it's not good decision.
3026897	3042182	B	0.78533	So we try to make the agent who will get that particular decision rules through conversation of heavy and plasticity done by Dharma factory.
3042347	3050512	B	0.65921	So this can be an arrow to the Dopamine moderation heavy and activity.
3051912	3073037	A	0.94651	So if the policy is resulting in the expected outcome, gamma stays at .5, the policy is as risky or consequential as expected, and then the policy can either go better than expected, which facilitates learning to support that decision.
3073187	3086287	A	0.82	To be made more or the outcome of the policy can be worse than expected, which disassociates previous conceptions to discourage that kind of behavior.
3086937	3087700	B	0.95984	Exactly.
3089337	3111700	B	0.98865	Crucial point is that this association with different time frame in the sense that we consider multiplication of current risk and least decisions to average over past two present Hebbian product.
3112062	3126377	B	0.9952	This makes an association between past decision secrets and the current risk which enables to optimize decision to minimize the future risk.
3126557	3129112	B	0.97	It is just a safe time frame.
3131562	3146800	A	0.88848	So here risk is being used in a formal sense similar to how it's used in economics which is the associated uncertainty of outcomes with respect to a policy.
3148062	3150850	A	0.9934	Where does danger come into play?
3151737	3159262	A	0.90262	Like what if there was an adversary in the maze or something that was dangerous?
3160212	3167867	A	1.0	How does this kind of model accommodate or hunger or different kinds of competitions?
3167927	3172612	A	0.98197	Because right now it's basically just trying to diffuse right word with a bias.
3173187	3173950	B	0.63	Right?
3174537	3183850	A	0.93924	But how do different kind of situational elements become interface into the generative model and generative process?
3184812	3197372	B	0.9	Okay, any of those factors can be involved in risk factor, a single risk factor.
3197417	3209547	B	0.68227	So you can arbitrary design and risk factor because risk factor moderate generative model.
3209730	3220217	B	0.90229	So that's why agent try to minimize the risk through basic embryo updating.
3220277	3227287	B	0.98041	But the risk itself is in some sense outside of such a Bayesian framework.
3227712	3233417	B	0.60246	So we can design arbitrary risk.
3233477	3241537	B	0.92738	So it may involve some danger factor, any other factor.
3243762	3254117	A	0.88	And this simulation, it is a POMDP or it is a neural network.
3254177	3260950	A	0.79	And what scripts might we look at to understand the structure of the maze agents?
3262212	3274037	B	0.79	Okay, it is basically expressed using the quantity in home depp for tractability.
3274187	3310600	B	0.90295	But for example, if you see the MDP learning probably okay, there is a variable Lamme type in the definition of SIM type correspond to the type of simulation.
3310675	3320775	B	0.68443	So if it's one or two it becomes homo DP or neural network to my understanding.
3321200	3356987	B	0.74102	Well, in this particular example, Jelle, we use the let's say maybe it's not good example that DeForest is learning the deforesting this script as well.
3357050	3366000	B	0.78093	So maybe another as an example, let's see.
3369287	3375467	A	0.83218	What is MDP init is initiating the markup decision process.
3375665	3376202	B	0.9909	Exactly.
3376295	3396450	B	0.43697	It's just determining the initial state of the computer generative model fe compute variational free energy or risk MDP computer risk function.
3397937	3409512	B	0.46992	So basically we use the neural network structure computation in this particular setup.
3410237	3428762	B	0.65622	So when you click maze m then in the line 31 line we determine that Lamme type is two.
3428825	3433512	B	0.72494	This correspond to neural network architecture.
3434012	3492612	B	0.64361	So there is a very slight difference between home depicture and neural network architecture because assuming neural network architecture correspond to, you know, considering considering okay, well, if you choose the palm DP architectures, then we sometimes use the gamma function to computer the posterior expectation about parameters.
3493337	3507900	B	0.86665	But in the neural network modeling the gamma function doesn't appear but it is replaced with the logarithm of some function.
3508562	3520292	B	0.86	And simply speaking, the difference between the gamma function of something and the logarithm function of something is asymmetry Lamme.
3520490	3528472	B	0.89579	So that's why we can transform home DP two neural network architectures.
3528517	3532800	B	0.94729	When the number of samples is sufficiently large.
3537287	3545325	A	0.99719	Which form do you expect performs better under small or large amounts of data?
3547487	3553137	B	0.70441	Well, for large amount of data they work in the same manner.
3553937	3554812	B	0.58283	Same manner.
3554887	3573292	B	0.94198	For small amount of examples, I'm not truly sure but it corresponds to assumptions about the posterior belief distribution.
3573427	3595362	B	0.73222	So if you assume delicious distribution then your resulting function form is something that used the gamma function in terms of basic inference probably which is optimal.
3600512	3606600	A	0.91989	All right, let's return to the earliest questions from today.
3608012	3628887	A	0.62873	So in your script, which people can reference, there's basically a toggle between having it in SIM type one or SIM type two corresponding to the POMDP in the neural network.
3630212	3635787	A	0.99687	What about if there's a published neural network or POMDP?
3637112	3644412	A	1.0	How can we use this architecture to create a translation?
3648000	3649905	A	0.99513	Is there any difference in this?
3649952	3665800	A	0.96319	Kind of like translating models in the wild different than the full construction of a special script that can speak both languages?
3670500	3678987	B	0.83567	Well, in terms of script there's no difference, sympathetic difference.
3679575	3680430	B	0.72	Right.
3680627	3684680	B	0.60515	So they work in the same manner.
3684740	3706155	B	0.70486	So only a translation of variable the same source code in two different ways.
3706277	3714995	B	0.81228	So if you see that this is a neural network generation, then it is translated as a neural network.
3715085	3719650	B	0.92506	Or if you see that this is a POMDP, then it's POMDP.
3723075	3735700	A	0.6676	So for some neural network being used in an industrial setting, how would we get from the neural network to a POMDP?
3736050	3739900	A	0.79	And where or how would that representation be valuable?
3740925	3741687	B	0.7	Right?
3742275	3761345	B	0.44618	So when neural network in the different architectures the important point is that we consider a particular form of neural network which is called canonical neural network architecture.
3761510	3775000	B	0.7659	So only when we assume this crossover neural network then you can find the exact correspondence to a particular form of POMDP.
3775350	3790287	B	0.6159	Otherwise you need to establish another equivalent between another form of neural network architectures and some sort of Bayesian model.
3792825	3807850	B	0.97673	This may be expressed by POMDP, but maybe not so straightforward to be expressed as the computational AP architectures.
3809175	3818637	A	0.86587	So what is it about the canonical neural network architecture that facilitates its translation into the POMDP form?
3819225	3824487	B	0.66	Yeah, first of all, it assumes sigmoid or activation function.
3824850	3832975	B	0.54	It is nicely correspond to enthralpy time in the force DP equations from DP formulations.
3833400	3840275	B	0.81232	So that's why we can clear marketing.
3840425	3848105	B	0.64007	So yeah, in other words, simply speaking, they have the same nonlinearity.
3848240	3873530	B	0.89762	That's why this translation is very easy with another nonlinearity or neural network equation, then we need to find another type of entropy equation or another type of prior distribution.
3873665	3876175	B	0.88	It is very nontrivial.
3878175	3882912	A	0.83	How does one even go about doing that research?
3889575	3919137	B	0.78348	If you want to go that direction, then I think the first step is to find the prior brief, which makes the prior brief and find the equivalence between a particular neural network architectures and particular Bayesian model.
3925312	3929675	A	0.89355	This sigmoidal activation is interesting.
3930412	3942362	A	0.9	It corresponds to general patterns seen in psychophysics, like two objects that are the same weight.
3943162	3957962	A	0.82096	You're going to have a chance of saying that one is heavier and then initially the difference has the most returns on that decision being made accurately.
3959287	3983150	A	0.86	And then as it crosses some threshold where it just is beyond a noticeable difference, the decision becomes essentially probabilistic, like the firing curve becomes saturated, the neuron chaos, a very low belief about zero or very high belief about zero or one flip that.
3986587	4010387	A	0.7448	So there is a nice grounding of that kind of a sigmoidal response curve with respect to stimuli differences and it has of course, tractable analytical properties, but it also just happens to be a good response summarizer.
4011262	4012882	B	0.64	Yeah, you're right.
4012960	4018567	B	0.81639	So sigmoidar function is also known as a psychometric function, as you say.
4018765	4026342	B	0.99144	We observe that characteristic in many psychical experiments.
4026477	4060700	B	0.73	And the previous work also said that even at the single neuron level, neuronal level, the same behavior were absorbed, which means that each heuristic we can reobserve the similar property, which is sometimes called as neurometric function, which is which have the form of sigmoida activation function.
4063312	4076675	B	0.79246	So it is nice reason to design neural network architecture using a sigmoid or function.
4078837	4089962	A	0.59847	All right, let's cover a few questions in the chat from Dave and then in the end turn to some general thoughts.
4090462	4094600	A	0.85	Okay, this was when we were looking at figure three.
4095337	4103442	A	0.7942	So you described these vectors or matrices.
4103502	4106547	A	0.99761	What kind of matrix or vector did you describe?
4106592	4112925	A	0.93	The mass block matrix.
4114625	4116000	B	0.76149	Block matrix.
4118900	4123712	A	0.98356	Block rock learning what?
4124075	4126510	B	0.94	Okay, rock matrix of rock.
4126555	4131430	B	0.9218	Vector is a vector vector or matrix of matrix.
4131490	4134587	B	0.2778	So imagine that.
4142900	4147112	A	0.9398	Sorry, just zoom, just glitch just repeat the last piece.
4147550	4157400	B	0.91	Okay, well, broke matrix Dean that the element of matrix is a matrix.
4158125	4165875	B	0.52541	So let's say two by two matrix like matrix in the ear pointing.
4166375	4176375	B	0.87486	So this here W one hat is a matrix and W zero hat is another matrix.
4177250	4184550	B	0.61	And combining four matrices, we define a single block matrix.
4186625	4189112	A	0.95029	All right, thank you.
4189625	4199260	A	0.83733	So Dave then asks the hosts of Machine Learning Street Talk Number 67 with Karl Friston.
4199305	4202925	A	0.99872	Another podcast, Karl Friston has spoken.
4204100	4214087	A	0.75868	Pressed Karl Friston on why is it so important that most of the values in a generative model matrix assume values of exactly zero?
4217037	4221262	A	0.99945	Why is it important that generative model matrices are sparse?
4222962	4223725	B	0.9254	Why?
4230687	4232232	B	0.40258	I'm not Bull sure.
4232385	4237450	B	0.99	I think there is some context before that point.
4238037	4253200	B	0.91	I think on that particular situation, then, yeah, as you say, the many elements in the matrix or gentle model should be zero, but I'm not sure if it's a general statement at all.
4254312	4264575	A	0.56772	What do you think about compressed analyses on sparse matrices?
4268825	4282350	A	0.99143	Is that a useful technique or direction?
4285850	4299295	B	0.55	You can use that knowledge to construct model, so you can use that knowledge to make more accurate inference.
4299385	4305225	B	0.81027	So in that sense, generally speaking, such assumptions should be useful.
4306775	4320250	B	0.96577	For example, yeah, as you said, it would be possible to use some sparse prior to restrict the value of parameter.
4320325	4332340	B	0.53366	Like, it is in principle same as assuming some L one norm to design the distribution.
4332445	4338665	B	0.84	To design the prior distribution, which is mass Dutch speaking.
4338757	4343625	B	0.98723	Exactly same as considering Lasso regression.
4345550	4346312	A	0.95	Yes.
4348250	4368525	A	0.82796	So we've explored a little bit how from a canonical neural network to a particular form of a POMDP, gives us some semantics and interpretability around the dynamics and plasticity of the neural network.
4369175	4381050	A	0.99303	What do we gain by taking a stated POMDP generative model and deriving an analogous neural network?
4383725	4391625	A	0.96173	Do we gain access to efficient computation, new software packages, different applications?
4395462	4413182	B	0.82167	Well, if one use Home DP and one's goal is so design an efficient basic model, then I think your Home DP expression is sufficient.
4413272	4442457	B	0.75856	So you don't need to consider neural network architecture, probably because Homedippy architecture and Bayesian correlation is designed to achieve some sort of mathematically optimal inference and decision making.
4442535	4442817	A	0.58	Right?
4442865	4448837	B	0.64152	So it itself is optimal scheme.
4448987	4464637	B	0.57791	But if one need to consider a link between Bayesian inference and biological substrates, then this mapping is crucial.
4468962	4478807	B	0.81908	Simply speaking, we consider that we assume that a brain perform Beijing inference, but its substrate is still unclear.
4478897	4486697	B	0.82306	So we need to link the Bayesian quantity to biological quantities.
4486892	4492987	B	0.7134	So this mapping, this equivalent, helps us to its translation.
4493862	4494447	B	0.51	Right?
4494555	4508912	B	0.90457	So when you start from on the model, then this translation facilitates the process of finding its neuronal substrate.
4509062	4527917	B	0.84098	So once you translate that to a basic to neural network quantities, then it facilitates the experimental validation application to reality.
4528052	4554700	B	0.52029	So if its modeling is apt for a particular neural network neural circuit architecture, then it should provide some prediction about the architecture or dynamics of the empirical data.
4555212	4555932	B	0.6	Right?
4556085	4564302	B	0.7865	So first we start from Bayesian model, which is not necessary to be equal to empirical data.
4564395	4570547	B	0.63039	So there is some mapping, but it's mapping is not straightforward.
4570742	4591537	B	0.99871	We may have multiple mappings, but once you translate Bayesian model to a particular neural network architectures then mapping or relationship between applicable data to such a particular neural network model is straightforward.
4592187	4600750	B	0.87087	So it helps us to apply base to an explanation of MP card data.
4606737	4626037	A	0.71314	So is it fair to say that neural networks have found wide recent application because they facilitate statistical learning in cases where the inference problem has not been a priori well specified?
4627137	4636375	A	1.0	One can just have a folder of images and a list of labels and just say, here's the data.
4637412	4643737	A	0.99941	Run it through this architecture or this architecture Explorer.
4645137	4657825	A	0.83	And so with this concordance we gain new interpretation into those settings that kind of arose from ill specified inference problems.
4658412	4684687	A	0.88	And then on the other hand, for problems that we already have well specified in terms of a POMDP generative model of a particular form, we gain the connection to actually implement it with empirical data and bring it into relevant industrial settings.
4687987	4709167	A	0.99833	What systems or phenomena are promising to continue research on the image example obviously is a simple case, but are you continuing research into more advanced computational agents?
4709365	4711937	A	0.96037	Robotic animal.
4716200	4746505	B	0.45	Oh, hello can design a more sophisticated agent which performs some difficult tasks based on canonical network neural network but there is some limitation, clear limitation on that direction.
4746565	4746965	B	0.84	Right?
4747057	4763025	B	0.60478	So yeah, I should emphasize that across the canonical neural network which correspond to a particular home DP is much smaller than general home DP framework.
4763600	4767670	B	0.66349	So there are some limitations, a least of limitations.
4767760	4792725	B	0.69789	So if one's goal is designed and sophisticated DAGs to perform some task or control robot, then one direction is just forget such limitations and take the mathematical optimality right and another direction is barrelscale probability.
4793075	4819425	B	0.69135	So if one wants to image some agent which is barely possible, then this correspondence is crucial because it tells us biological limitations through the existence, no existence of such a mapping between POMDP and particular neural network architectures.
4819775	4822562	B	0.59824	So, yeah.
4823000	4833975	B	0.71553	So it would be useful to consider a vertical substrate to achieve exafferent task.
4842162	4851362	B	0.72	And that task would be related to high dimension image processing.
4851512	4859882	B	0.98373	Image recognition or sound recognition, such as multimodality, can be inbox or decision.
4859972	4879677	B	0.9946	Can be higher dimensional like in the mainstays, we just consider the four directional movement, but it can be extended to higher dimensionality, like arm movement, body movement, so on, so on.
4879845	4887412	B	0.85288	So in principle it can be extended in that direction.
4890312	4896387	A	0.99753	Which directions or questions are you excited about?
4896525	4906162	A	0.96286	Or what areas of studying the basis of biological and computational intelligence are relevant?
4907112	4907967	B	0.94	Yes.
4908165	4922447	B	0.69432	So in terms of the importance of canonical network, as you said, virtue is a biological probability.
4922567	4970012	B	0.80628	So it would be nice that if we model some task which is conducted by learning and one already recorded some neural activity, then we design a task which is exactly same as the task which is done by the animal and then compare the simulated agent and Mpcar data to discuss about the similarity or difference between the simulated agent and the animals.
4970162	4973950	B	0.9869	That would be very interesting direction of research.
4976862	4988650	A	0.53	Yeah, and if there could be some unexpected prediction or explanation in the computational agent, that would bolster the relationship.
4989462	5025452	A	0.7	And then one other aspect is it would help with the reproducibility and the documentation around behavior studies if the computational agent were preregistered and someone said we've already done the statistical power analysis and we've already explored with parameter sweeps how many observations we need to make of the two armed bandit.
5025557	5030067	A	1.0	How many observations of the three armed bandit should we do?
5030190	5034100	A	1.0	Three mice 100 times or 100 mice three times?
5034912	5041987	A	1.0	Those are the total substance of designing research programs.
5042862	5055787	A	0.92	And so having a formal representation of behavioral tasks that are being studied will help us design behavior observations and experiments that aren't simply ad hoc.
5060037	5063875	B	0.60984	All right, that's an interesting application.
5066862	5072800	B	0.52986	This framework helps to design the experimental setup itself.
5073762	5098300	B	0.69	And what we often consider is the prediction ability of these modern canonical neural networks to predict the Jelle phoneization or dynamics of the VR neural network in the animal during the learning process.
5098662	5121347	B	0.7232	So in place for it is possible to predict the behavior after learning based only on data in the initial stage because once we obtain some empirical data, then we can fit that data to design a particular canonical network.
5121542	5137617	B	0.75	And canonical neural network makes some correlation through a minimization cost function which is exactly same as the Bayesian belief updating under a particular guarantee model.
5137815	5159972	B	0.66102	So which means that its dynamics goes through the shortest path on the free energy landscape which means that we can make some quantitative prediction about the sinatic trajectory or neural activity or any kind of parameters.
5160167	5171267	B	0.87602	So we demonstrated that using in virtual neural network and uploaded some footprint recently.
5171402	5214407	B	0.77705	So at the stage, at least at the level in vitro network, which is much simpler than VR brain, we could predict the self organization of in virtual network using this canonical network architecture and this support the probability of free energy principle because this canonical network predict the communication through the variational free energy minimization and its solution.
5214497	5224537	B	0.80437	Its results have a very tight correlation between correlation to Archer synchronization.
5227962	5230787	A	0.93658	That's a very interesting experiment.
5230862	5239387	A	0.73813	So what animal were the neurons from and what was measured about these neurons?
5239737	5266802	B	0.94	Yes, so that in vitro network is obtained from blood embryo, we use cortical cells to make that individual network and task is sort of causal inference task which can be designed in the form of OMDP.
5266982	5279957	B	0.63193	So imagine that we usually simulate agents that receive signals generated by OMDP generative process and process and Beijing task.
5280122	5287847	B	0.87358	So we just replaced that Bayesian agent to neural network.
5287967	5311537	B	0.87125	So we stimulate neuron with some signal which is made by some hidden sources through like a human mapping and question is whether in viral network can info the hidden states through some communication and they can they could Ines the hidden culture.
5315112	5323922	A	0.97665	What does it look like functionally when the neural network has succeeded at inferring the hidden causes?
5324117	5335397	B	0.48	Yeah, the direct conversation is done by the response number response spikes to a particular pattern sensory input.
5335517	5345502	B	0.72504	So again, we can see a clear correspondence between activity level and posterior belief about hidden state.
5345595	5352782	B	0.8625	So here we see re a book response to an electropaste memory.
5352872	5381500	B	0.99743	We see the response from ten to 13 milliseconds after each stimulation and we compute the number of spikes and that spikes changes their preference in the sense that some neurons learn to preferentially respond to force one but not source two.
5382237	5392912	B	0.53913	So which is not a response to input itself, but it looks like a response to particular source.
5393337	5410382	B	0.80366	So it is inference which is empirical evidence that neural network actually perform some sort of causal inference in a manner consistent with traditional Bayesian inference.
5410547	5418162	B	0.79	And then we compute another quantity in Bayesian inference in the real vertical data.
5418300	5458987	B	0.98956	We show that firing special factor is consistent with the prior belief about hidden states and we also compute the synaptic rate statistically through some connection strength estimation method and show that the estimated synaptic strength is consistent with something encoding posterior belief about parameters, as expected by the theory.
5460612	5488237	A	0.93056	Well, we looked at table two earlier and this is almost like the next step after the theoretical concordance is all right, well, let's measure the release of a neurotransmitter or the empirical synaptic strength or the firing threshold or all these different features in different empirical systems.
5488962	5496250	A	0.67467	So what experimental systems does your group work in?
5502012	5509767	B	0.94215	That in virtual system was made when I was a PhD student.
5509890	5528582	B	0.83132	So that is experiment we done in my previous route and now I COVID to the Bijan Institute and I'm a Princepal investigator of Celery unit.
5528672	5540887	B	0.58569	So now actually we don't use any experimental setup, so any experimental bidding is down with some collaboration.
5541237	5546732	B	0.65183	So although I cannot say detail about that exploration.
5546822	5557322	B	0.88494	But yeah, we learn some collaborating work about the implication of salary using various animals.
5557517	5565700	B	0.5	Yeah, so we hope we can show some interesting results following results using animal data.
5569662	5571775	A	0.99012	Very interesting.
5572887	5591587	A	0.7	Yeah, well, it speaks a lot to the stage that our field is in in certain ways where we've seen a lot of graphics that are suggestive.
5592387	5615967	A	0.99929	This paper and the building on the previous 2020 paper made a suggestive possibility much closer to an analytically demonstrated translation and then took the next step incrementally into the in silico agent.
5616165	5625175	A	0.81	And so it's only natural to then explore different embodied systems as well.
5630862	5647300	A	0.98285	Are there any other sections that you wanted to like, look at or highlight or any other topics about the paper or adjacencies or active inference that you think are interesting to go into?
5650212	5663417	B	0.6	Yeah, okay, I would like to mention about some implication of these papers, which is not the director discussing the papers.
5663552	5671675	B	0.55402	So for example, well, we focus on a discrete state space model.
5672037	5683652	B	0.82215	So we avoid to assume some subscript that encodes the coherence of the distribution.
5683757	5688617	B	0.46901	So once you assume homedp then it is categorical distinctions.
5688677	5696792	B	0.75584	So it is different from assuming Gaussian distribution characterized by me and variants.
5696927	5707632	B	0.80197	So the neural substrate of variance is still unclear and we now try to figure out that.
5707785	5730767	B	0.54727	So this is one direction of limitation and another implication is that thanks to a simple ODP structure in this paper, we don't care about the hierarchical optimization.
5730902	5744437	B	0.92836	But generally it is crucial to update parameters through hierarchical optimization through some backpropagation like computation.
5744787	5751617	B	0.95979	Although it is unclear whether back propagation itself occurred in the real brain.
5751677	5768062	B	0.94984	But we still have some alternative that achieve such optimization and it's neural substrate still unclear and this paper doesn't address that direction.
5785650	5796475	A	0.99885	Another area I'm wondering about is like where in neural structures is the learning reflected?
5797575	5800790	A	0.62817	Where is the function and learning reflected?
5800970	5809955	A	0.88236	Well, sometimes it has to do with not just structural Tweaking, but the presence or absence of synapses.
5810015	5823695	A	0.93095	So obviously this model does not expand into synaptogenesis synaptic pruning, let alone neurogenesis and neuro allostasis which we mentioned in the previous discussion.
5823860	5841015	A	0.98472	But understanding how these larger scale structural changes which are certainly important in biological systems become reflected in artificial neural networks and then how that translates all the way back to P-O-M.
5841032	5844300	A	0.46854	DP and then whether we could go the other way.
5844437	5855360	A	0.99886	What kinds of POMDP structures in their neural network realization would have structural modification.
5855480	5864535	A	0.76557	Like you COVID imagine a POMDP that does structure learning but the neural network doesn't have structural change.
5864717	5874250	A	0.9957	Or there's A-P-O-M DP that doesn't do structural learning but it's manifested by a neural network that does have a structural change element.
5875125	5880690	A	0.84932	So structure is doing something very different in these two different categories of model.
5880857	5903085	A	0.53	And then also even within neural firing, which is different amongst different species and so on, there's different aspects of what that firing is that would have different implications for the actual biological substrate of cognition niche.
5903267	5911160	A	1.0	The simple connection is firing rate to posterior belief.
5911355	5914535	A	0.99924	Average firing rate, no change in posterior.
5914655	5917830	A	0.93679	Reduce the firing rate if the posterior should be going down.
5917952	5920020	A	0.99328	Increase it if it should be going up.
5920172	5937625	A	0.99332	Or maybe there are neurons that have a flipped valence but the same type of relationship, but there's other firing patterns like spike time dependent plasticity synchronization amongst different brain regions.
5938800	5944000	A	0.77419	There's a lot of things that don't change the rate overall.
5945250	5953150	A	0.73998	That again from the biological systems we know that those phenomena and mechanism are important for different cognitive processes.
5957400	5963337	A	0.85317	So there will be many many years of a fruitful relationship.
5965875	5973945	A	0.72879	I'm going to bring in this picture that Alexandra had taken.
5974022	5996187	A	0.99403	Maybe we need a third panel in figure one because these three systems moving between them is going to be the substance of the field for a long time and there may be other edges to build.
5997150	6030965	A	0.99143	But understanding how artificial neural networks intermediate between the empirical measurements and manipulations that we can make of real neural systems and the interpretability and factorizability of POMDPs it might be a bridge too far to go from the POMDP to the neuron.
6031145	6040075	A	0.99	You could always use this technique but it would be a purely descriptive statistic type approach.
6042825	6071187	A	0.92793	But it's so interesting that by intermediating through a formal connection established in figure one I Dean in equation one but also shown here, then we can kind of extend the chain of exploration, prediction, control, design all the way on through.
6072300	6096025	A	0.96	And that just unlocks like an incredible amount of neuroscience that hasn't been formalized mathematically and an incredible amount of generative models that have been specified for different learning settings sometimes even by analogy to biological settings.
6097200	6108175	A	0.96406	But the metaphor remains just a metaphor until it's possible to intermediate with this type of neural network development.
6109125	6112737	B	0.75	Yeah, that's a crucial point.
6116400	6131130	B	0.61	It is easy to imagine that phenomena can be modeled using very realistic neural model or free model synaptic model.
6131252	6131937	B	0.75	Right.
6134400	6149715	B	0.91038	We believe that it is possible and then Laje model is not necessarily tractable, not necessarily useful because it's too much complicated to analyze something.
6149807	6160150	B	0.83758	So we use some reduction, usually mathematically speaking, which correspond to topological transformation to make the model simpler.
6160800	6182040	B	0.9	And then we need to consider the translation of that simplified neural network model because neural network model itself is not explainable which just represents some dynamics and its functional meaning is not clear.
6182207	6193975	B	0.96741	But thanks to the Bayesian framework we have a very nice event framework to least the experiment ability.
6194400	6210850	B	0.76	And this translation, this correspondence helped us to link such a phenomena base equation modeling and functional base equations.
6212250	6223600	A	0.83	Yeah, one paper from 2017 that was much discussed by some could a neuroscientist understand a microprocessor?
6224325	6239487	A	0.89	And this group with Jonas and Courting, they had a simulation of a microprocessor from an earlier video game console, I believe.
6240075	6263085	A	0.87	And then using the analogy of like the transistors and their connections as neural firing and structural connectivity they were able to simulate experimental settings, input and action and then make measurements from every neuron including doing lesions and loss of functions and so on.
6263192	6286825	A	0.9	And it turns out that a lot of the techniques that are used to derive scientific explanation from analogous data collected from a biological system, those techniques which ostensibly should be isolating functional explanations in fact did not isolate effective exploration.
6287175	6303700	A	1.0	You could have a deletion over here that induces some statistical change all the way over here and that may or may not be a useful clue towards the function of even subcircuits.
6304575	6326125	A	0.85	And so I think that was a wake up call with respect to the interpretability of simply this connection between the biological and the neural network.
6327450	6348625	A	0.95237	This connection alone is of limited applicability even when the neural network model becomes so complex as to recapitulate the biological phenomena, you're never under any guarantee that you're going to recover interpretability.
6349050	6360815	A	1.0	You may have just created an atomic level simulation of the phenomena, but of course, a map that is the same scale as the phenomena isn't a map.
6360995	6364450	A	0.39632	It's just a copy that has no more interpretability.
6366600	6398125	A	0.91	And it's almost like what is now extended again, as we kind of just summarize this and think about how we move forward, is that connection can now be extended into the space of interpretable causal models and the generalized Bayesian graphical computational frameworks and all the heuristic that we can then use like variational, Bayes and all these other methods.
6398550	6420155	A	0.78808	So it'd be interesting to look back at different data sets of in vitro and in vivo and in silico neural activation, especially if the task was of this constrained set of POMDPs and it was already amenable.
6420215	6433750	A	0.98945	Because, as you brought up, other settings would require a little bit more theory development before we understand what POMDP family would be applicable.
6439650	6440280	B	0.98211	Cool.
6440402	6444837	A	0.86471	Well, do you have any final thoughts or questions?
6447300	6450625	B	0.61238	Well, do you hop.
6454912	6467087	A	0.64	I kant to download the MATLAB scripts and generate the figures, play around with a few of these parameters?
6467887	6472175	A	0.507	Like, I see that you can change how far the entity can see.
6473887	6481037	A	0.71	And then with these models, I'm also always curious about the computational complexity.
6481462	6494162	A	0.7271	Like if you extended the planning horizon from four to five or you dropped it down to three, what is the runtime consequences and what is the performance consequences?
6495187	6511487	A	0.92	And where might we be able to use single or swarms of really simple agent, maybe even making binary decisions and achieve high performance?
6512437	6550257	A	0.97	And where do we really need to move into these large combinatoric spaces in order to solve problems and the kinds of complex planning problems that we solve, whether it's planning our day or planning our week, are those force like true Deep Harrison planning problems with extensive consideration of counterfactuals and calculation of alternatives?
6550422	6569387	A	0.98698	Or are those actually composite decisions that are made up of smaller, simpler, sub decisions that we may or may not have flexibility to restructure?
6571612	6580550	A	0.96082	So that a decision, a complex chess maneuver, a sacrifice in chess or another game.
6582262	6598262	A	0.99	It may be possible to model that as a Deep Horizon scan or a kind of intuitive heuristic for an appropriate skilled entity.
6601537	6622647	B	0.98303	For this particular two Brea structure, there is a clear limitation about the horizon forward because it doesn't use forward prediction, it used post action approach.
6622692	6636587	B	0.83089	So it's a clear limitation, but still, it may have some performance ability, active, some levels of affordance.
6638587	6643637	A	0.91882	That provides even another way to look at planning.
6644887	6660172	A	0.99	The two ways I was describing planning, as it's often described in the PMDP literature is again, is it a true Deep Horizon consideration or is it just short term heuristics or nested models that are short?
6660355	6666812	A	0.87	And I think that this paper says maybe neither.
6667537	6690477	A	0.99168	Maybe it's purely the active causality on the past that leads to the emergence of sentient and maybe even teleological planninglike behavior through the ongoing reconsideration of the consequences of least action.
6690657	6694947	A	0.96517	But it's neither a short nor a long term planning challenge.
6694992	6698352	A	0.97159	It's actually like a memory and learning challenge.
6698457	6700287	A	0.94	And no planning occurs.
6700437	6701150	B	0.5	Right.
6702637	6708587	B	0.39078	Indirect planning planning element is involving C matrix.
6710212	6715937	A	0.99863	Planning as a phenomenon occurs and derisking through time occurs.
6716437	6743225	A	0.52269	But it says something quite interesting and deep that that phenotype or function could be enacted by a system that explicitly looks a long way ahead, explicitly looks a short way ahead or moves forward and looks backwards only, right, which is what they sometimes say about the past and the future.
6745012	6754550	A	0.85446	So that may be a very biologically plausible form of learning.
6755887	6765050	A	0.95	And it's already intimately connected with the dynamics and the activity in terms of an integrated loss function.
6766537	6771725	A	0.77175	So these are all excellent directions to keep learning on.
6772837	6773600	B	0.8	Right?
6774262	6783802	B	0.57	And I'm also interested in the barrel implementation of such a short term or long term for the prediction and running.
6783895	6799562	B	0.7	And I hope to find some nice connectivity to such implementation of Bayesian motor and implementation in VR brain network.
6800887	6801697	B	0.84484	Cool.
6801880	6810962	A	0.89	And also I'm always curious about the invertebrate brain as an ant researcher.
6811387	6823672	A	0.97	And so many of the brain architectures as well as the brain architecture that people discuss are mammalian centric, which makes sense.
6823855	6836975	A	0.98	The mammalian cortical column and the relationship with Dopaminergic midbrain and the cortical regions and the spinal reflex arc those are all important systems of interest.
6837562	6846662	A	0.99958	Yet the micro and meso anatomy of the invertebrate nervous system is pretty distinct.
6847687	6859112	A	0.47947	So our model should be able to describe neural and cognitive systems, of course, across invertebrates and vertebrates.
6859537	6878762	A	0.784	So I look forward to also seeing what those models of the invertebrate nervous system and collective behavior where you could have some type of backwards looking risk inference of the swarm.
6880012	6881162	A	0.60754	Who knows?
6883537	6884300	B	0.71772	Well.
6886537	6890997	A	0.99306	We really appreciate the time that you took for these discussions.
6891042	6895250	A	0.98	I think they are immensely important.
6895687	6899462	A	0.98	And we wish you the best of luck in these continued directions.
6903387	6904150	B	0.08	Yes.
6906612	6907962	A	0.96	Okay, that's it.
6908025	6908875	A	0.99955	Thank you.
6909687	6910962	B	0.99776	Thank you very much.
6911100	6911967	A	0.99439	See you next time.
6912015	6912712	A	0.85294	Bye.
