SPEAKER_03:
Hello and welcome everyone.

Thanks for joining.

It's November 30th, 2021.

And we're in Act-Inf Lab live stream number 33.2 on thinking like a state embodied intelligence in the deep history of our collective minds.

This is the second discussion we've had on this paper.

And if you're watching along live, definitely ask us questions because it'll help us have a fun feedback and a discussion.

Welcome to Active Inference Lab.

We are a participatory online lab that is communicating, learning, and practicing applied active inference.

You can find us at the links here on this slide.

This is a recorded and an archived livestream, so please provide us with feedback so that we can improve our work.

All backgrounds and perspectives are welcome, and we'll be following good video etiquette for livestreams.

It's a new slide.

The short link is gone.

It's been deprecated.

Thanks to the work of many awesome ActifLab participants and especially Jessica B, we have moved over our live stream past and upcoming database to a Coda site.

So you can go to this Coda site or maybe somebody can post the link.

And this is an interactive way for you to look at

the date, video, the title, the number, the guests that were on the stream, the keywords, all the links.

This is linked up with our knowledge management as well as our people

management, CRM as they call it.

So this is an awesome tool that we're using with Coda and hopefully it improves the findability and the indexability so that if you're looking for some keyword, you can find all the live streams where we discussed that keyword or if you have somebody who you like to listen to, then you can find them in the guests or in the participants section and you can hear what they had to say about a certain topic at a certain time.

Today in ACT-INF stream 33.2, we're going to be having our .2 jump off slash speculate onwards and upwards discussion on the paper by Evel Gwinnon-Kalu, Thinking Like a State, Embodied Intelligence in the Deep History of Our Collective Minds.

So we'll just have fun.

We have some topics from last time that we put on a slide for 33.2 that we can talk a little bit through.

As always, things come up and it'd be great to have anyone's questions in the live chat.

Otherwise, we're just going to be chilling and talking about this cool paper.

So we will start with introductions and then just take it from there.

I'm Daniel.

I'm a researcher in California, and I'll save my specific excitements or what I'd like or remembered about the paper for our kind of intro round, and I'll pass to Dean.


SPEAKER_01:
Hi, I'm Dean.

I'm from Calgary, and I'm kind of interested, like you said, in seeing what happens when, like, our migration from Google to Coda

and we pick up and move off of some of these representations or some of these ideas, what that looks like.

And I'll pass it over to Stephen.


SPEAKER_04:
Hello.

I'm Stephen.

I'm based in Toronto.

And yeah, I'm interested about a lot of the generative binoculars I think this paper starts to create.

And I've had some good conversations with Dean, actually, and we've been chewing over

how much this maybe opens new doors, maybe is a step too far at this stage, and where other doors we might have that we can step into.

So I think it's an interesting set of mirrors and alleyways to go into.


SPEAKER_03:
So I'm curious what those doors are, which ones have ramps, which ones are downhill, which ones are a spiry staircase.

Like what places would one go from this paper?

And I'm sure we can start even writing on our 33.2 slide.

Like what are those doors?

Are they ajar?

Are they locked?


SPEAKER_01:
So Daniel, one of the things, and I don't know if this is sense-making or just messing with something, but if a city was made up oftentimes like what we see in some of MC Escher's work, and then there were Markov blankets all over the place, what might that look like relative to sort of the,

the city that I live in or the city that you live in or the city that Stephen lives in, and are there ways that we can, are there similarities and are there real differences between what that sort of MC Escher world and Markov blankets would represent as versus their actual representations of actual cities?

That's one of my questions.


SPEAKER_03:
so let me kind of unpack that you're talking about the MC Escher art with the stairs going in different apparent directions and asking whether those portals would reflect intelligently designed transporters or what does that physical or cyber physical City look like


SPEAKER_01:
Yeah, in many of these live streams, you've had one image on the slide that has the ants walking around the, I forget what that symbol is.


SPEAKER_03:
Yeah, a Mobius strip with ants.


SPEAKER_01:
Thank, a Mobius strip.

So that would be an example of a real representation that we could generate.

But is that a city?

That's my question.


SPEAKER_03:
Okay, Stephen, and welcome, Dave.


SPEAKER_04:
Yeah, is that a city?

I mean, it also takes me thinking about something called transect walks, which is what you can do in a participatory engagement with a town or something, where literally you transect or you walk through a cross-section of a town and you just see what you end up encountering.

the way of structuring participation.

But it's an interesting question.

So basically, you start to move through it, and we go through a path and start to see what's on that route.

And it's the same, it's then that sort of question that goes back to, you know, when I was talking about the doorways, it's like, everyone's been like, so where do I find my doorways and start squeezing through the doorway?

Or when do I need to, again, step back and find the unifying principles?

When do I need to go back to accuracy and complexity?

And when do I go in to try and force it through the doorway?

And active influence has allowed me to step back and hold more rather than try and not worry about fitting through the doorway.

However, as we realise as we're talking here, at some point you need to put stuff into...

communications uh be it encoder be it in google docs you know so in some ways you're going to categorize for practice practical purposes right but it's not the same as walking on the movis strip so there's an interesting challenge as practitioners that we face okay welcome back dave i hope it's working just


SPEAKER_03:
Everyone remember to mute if you're not talking and turn off all your messaging applications.

The idea of the transect, that reminds me a lot of ecology, where we know that there's spatial and temporal variation, but a common approach is to take a transect, like either going up an elevation gradient

or going within the same elevation gradient.

So those are kind of like the two directions that we always talk about, going on the irrotational component that climbs straight up the hill to see how elevation changes biodiversity, or to go at the same altitude, maybe on a north to south, to ask how does latitude influence biodiversity at a given elevation?

That's like that iso contour.

So then the transect is a sampling approach.

that in the context of a generative model gives us a picture of the map of the territory.

So, yeah, Stephen?


SPEAKER_04:
Yeah, that's good.

I think it's probably been ported over, whoever did that.

It's probably more used in participatory development.

community development than participatory theatre.

Theatre support development might touch on it, but a lot of times theatre work, they don't really go there, they just talk about scenes and situations.

I think the transect is a nice way to sort of walk through and get a cross-section in that kind of semi-scientific way.

But I actually then was much more interested in going for a social topography, just allowing people to get the whole landscape out there, which in some ways, once we get into the kind of agent-based stuff,

work, which I didn't know about back in the day.

But, you know, then, because the argument would be, well, the transect is already adding all this complication.

You've got people walking, taking a cross section of the town as opposed to having something nice and clean.

It's adding some, why go even further?

But the, you know, active influence says, well, it's okay if your regime of attention is being

organized around a certain type of abductive inference, right?

So yeah, you don't want to be doing it if you're deducting, because you'll just get completely swallowed up by it.

So that could be interesting sort of crossover there.


SPEAKER_03:
It's like one way to take the transect and perhaps a null transect would be a quote straight line that would just be unbiased or it's a simple choice.

And then in a city, you might want to take that transect or you might be on rails.

So you might be taking the F Muni in San Francisco and that's like giving you scenes of city life and

And that actually speaks to the difference between Kronos and Kairos.

Kronos is like that straight line that just doesn't care whether you're putting the meter stick over the city or the mountain.

And then Kairos is like that streetcar or the path.

It's like you're walking along the path, but it might have curves, but that's the path that you're on.

So then that's more like Kairos.

Dean?


SPEAKER_01:
Yeah, so I...

don't know whether the author was intending this, but one of the things that I took away from the paper that I thought was really potentially an amazing insight from the paper was the fact that if you go into a city,

you can get a sense of a feeling of the city.

So there is a collective feel.

I'll take my own personal example.

You can go into the city of Barcelona, and it isn't just where it is situated on a coast.

There is a fundamental feeling difference as somebody who is now within that geographic territory than the one that you sense when you're in Madrid or when you're in Lisbon.

They each have a collective feel about them.

And it isn't just that you want it to be different because the architecture is different or where it's situated on a hill is different.

There's actual social aspects of that feeling which make themselves present and which you attune to.

So I don't, I would never argue with the fact that as an example of

a collective act of inference that cities couldn't exhibit those types of not just behavior, but sense of who we are and what we are, what we are.

But I'm not sure, like again, I'm not sure if the scale aspect of this actually works, because as I said, in my mind, I can do the MC Escher thing all the time.

I can twist things and invert things, but it's hard to do that with dead things made of concrete.

I'm not saying it can't happen, but I don't see examples of that out there when things scale up and out.


SPEAKER_03:
Thanks, Dean.

Stephen?


SPEAKER_04:
Yeah, and say as you're walking, if you say walking down these routes in Barcelona, for instance, as Dean mentioned there, you know, there's the route that we pass along and that's kind of what's available and there's a scale that's friendly to being available.

There's a certain size of building, there's a certain, you know, at the end of the day, if you're walking on your, or you're going through some ambulatory route,

There's things available to you.

But there's also then what's adjacent to that and what's hidden and what's hidden right next to you.

Maybe there's a homeless person on the side.

They're on the same route, but are they seeing the same things I'm seeing?

Are they seeing the same affordances?

Are they seeing what's, you know, and often that route is where the vantage point is.

So what's behind that wall on the right?

What's hidden from the time that we see these buildings?

And I think that's an interesting question of, you know, there's the system as seen from a perspective, and then there's what it's really like in many different contexts.


SPEAKER_03:
Thanks, Stephen.

Dean?


SPEAKER_01:
Yeah, which brings me to the Sagrada Familia, which to me, standing beside it, sticks out and up and all over the place and has

allusions to termite mounds and, and, and, and like, it's one of those attempts, I think, to actually mimic the things that we nature.

And it certainly is solenoidal and ramping.

I mean, it's, if you want an example of where architecture is actually doing a symbolic, how do you do, the Sagrada Familia would be a perfect example of that.

terms of what it in terms of what about active inference some of the some of the shapes we see kicking out from some of the math that's happening in the on the in the statistical mechanics so that's kind of fascinating too hmm you know what you mentioned okay a few um you know little references since we're in the fun dot two there we go spiral so the tower of babel


SPEAKER_03:
whether or whatever it was, it's often at least classically represented as a spiral ascent.

So that's very interesting that it's not like the Tower of Pisa with just rings.

That's like iso contours that are separated from each other.

But there's something about the way that it's classically shown that makes it look more like it's a spiral, which is, as we've discussed from a technical perspective,

related to the decomposition of that spiral into an uphill irrotational component and then a purely rotational component and then the other sort of reference was to william blake's poem london where he says i wander through each chartered street near where the chartered tames does flow and mark in every face i meet marks of weakness marks of woe

So here there's so much about how the streets are chartered, the flow of people and the river is chartered because it's also part of the niche that's been engineered.

And there's also flow, which brings us back to number 32.

That was our big lead in was flow.

What is flow and how can different systems

have similar mappings of heat flow, information flow, bulk flow, particle flow, liquid flow.

So how does flow matter in a city?

The sewage going out and the resources coming in.

And then also it's like even niche modification on our countenance.

It's marked on the faces that Blake is meeting.

aspects of the city are kind of imprinted on them.

And then that speaks to what Dean was saying about how there's like a collective feeling that's partially architectural, but it's like a feedback that's complex between the people and the time and the place.

So Dean, then Stephen.


SPEAKER_01:
Yeah, and it's interesting too, because the artifacts part of this, whether it's a cathedral or whatever the artifacts are that get kicked out,

we can look at that from an ingredient standpoint.

Like we can look at beer as having water and yeast and barley and, and whatever.


SPEAKER_00:
Right.


SPEAKER_01:
But, but the fact is there's also time required and there's also energy that has to be applied.

And I think that's the part, the time and the energy piece of city States that are

are the real key to whether or not we can see what, as individuals, we perceive active inference as affording versus what, on a collective level, we see active inference as affording.

I think where it separates is on the specifics of the ingredients, but where the common is is in terms of the energy applied and the time required.


SPEAKER_03:
Thanks.

Stephen?


SPEAKER_04:
Yeah, with the idea of the time and energy, and we're talking about scale, you know, when you're around the Thames, I mean, back in the day, there was that big, there was a boat full of

important people, I don't know if they were royalty or politicians or whatever, but they were on the Thames and the boat kind of sank, and the people in the water.

And because the water was so putrid and rank that a lot of them died, basically.

And that instigated a lot of the clean-up.

So I suppose there's this question of how close is close?

You get closer to water, and at some point you put your head in it, you can't really make anything out apart from water.

Then you've got certain vantage points which allow you to understand that you're in a chart of 10s.

You get so close you could be in any body of water.

And then you move out further.

So there's a scale dependency in terms of how you can structurally relate to the information.

And then just whether you like it, there's a structurally dependent nature of the scale of the Thames, right?

So I can't walk across the Thames because it's too small compared to, say, a small stream.

So these are some of the questions in terms of how the information is going to be processed

And how much of that information is adjacent to someone and how much of it's hidden?

Because those people on that boat, they lived next to a smelly Thames for a long time.

Actually, the people in the House of Commons used to have scented handkerchiefs they'd put up to their nose so that they could overcome the smell of the sewage in the Thames, right?

And so, you know, at some point they got up close and dirty to it and probably changed their perception of what was really going on.


SPEAKER_03:
Interesting.

So another thing I had written down and kind of connecting us to some of the core terms in Act-Inf, affordance, which is the capacity for action.

And those are the opportunities for policy selection.

They're chosen amongst the different affordances.

And in cities, it's very related to ability and access.

So two people who are walking down the street are able to enter different doors and they're able to sit down in different places.

And so I think that's a very tangible and important example of embodied, extended, and cultured, et cetera, cognition, all the E's and other letters, because it's something that we all experience.

They're issues that people really care about.

And

putting them under a descriptive, I hesitate to say neutral banner of affordances, financial affordances or physical or however it may be, it helps us

have a discussion about what the affordances should be.

Should you be able to get into the bus, in the back of the bus?

There's trade-offs with that.

Maybe it's harder to clock the fares, but then it might be easier to access for some people, but then now there's this ability for people to evade the fare, but then how bad is that relative to the buses being late?

If everybody has to go in the front, all of these kinds of trade-offs,

Active inference is giving a way to talk about the agentic level, the individual person on the streets of the city and their perception, cognition, and action, which are selected from their affordances, which are situational, not just like all people can go up a staircase.

And then we have a individual level model and can ask then, okay, collective model, feedback with a niche,

avel's paper takes it is like the city and the state as active inference agents composed of subunit active inference agents just like we can have an active model of a body as well as of the cells steven yeah i'll be curious what your thoughts are on this daniel in terms of


SPEAKER_04:
when when we have the active inference models like we mentioned they're often you know particular low dimensional ways to get into sort of types of regimes of attention you know so maybe it's going to model the nature of people you know looking at this their their attentional states x y and z and because the challenge is once you go and you start walking through different doors and you're in a town

you've got this question about how do you model that when the actual low dimensionality becomes very hard to work with?

And I suppose that question then is at what point do you look at what actual people are doing

which hasn't happened as much in active inference and then try and go back and try and understand okay what is what they've done and how that's inscribed on the niche reflective of the action policies and versus how much is it about looking at the sensorium that might explain the generative model that we anticipate going on and emulating that and say that might relate to i suppose you might have that same question with ants you know when do you try and

do an agent-based model of a few ants as a conceptual, and when do you try and understand what ants are doing in situ?

Because obviously that gets kind of complex, right, because they're all moving around.

So I don't know if that has a correlation to that question in that field as well, but I think that relates here to this situated cityscape scale, because it's very granular once you get into that

and in some ways that it's nice to make it become like a mind it's nice to make all of that because suddenly it it kind of fits in with the modeling that we kind of use right and in some ways it might so there may be some validity but that it may be that that we have to bring in that mind body environment dynamical mess um that opens some questions about well how do we go about that


SPEAKER_03:
Good question.

So here on this slide, we have the dimensionality of ACT-INF models.

So we can even just emphasize maps, not territories.

And then what does the next step in formalizing this model look like?

So let's think of a specific city situation, and then we can talk about like modeling that city situation and what would the dimensionality of the model be?

Where does regime of attention come into play?

So what would be like a city situation

common situation fringe situation important situation like what's a case that we care about in a city maybe one that involves complex interactions between for example bureaucracy which was the main topic of the paper and legacy history and affordances of agents dean


SPEAKER_01:
I think to get there, you'd have to have a lot more of the bottom-up aspect of that being honoured as opposed to more of the top-down control piece.

I don't know what the final product would look like because it's active inference.

I would be inferring and I would think that there would be 13 million architects and one citizen.

which is not how cities are typically designed.

And that's one of the struggles that I have with this in terms of drawing a parallel across scales.

There's only one of me, but I've got however many neurons, and I'm kind of dependent on those, so.


SPEAKER_03:
Okay, yes, I see where you're going and I think we're gonna keep the bottom up and top down.

And I think this modeling approach, it's not the only one, but starting with a scenario and kind of like Bruno Latour's Actor Network Theory or ANT appropriately, we can start by identifying traces and action trajectories in that scenario.

And let's see if in a bottom-up way, on our first pass, we can get to like a skeletal act-inf model.

And then the iteration is infinite slash perpetual.

So I don't think it's about just going for one, getting bottom-up input once, and then...

laying the grid work down, and then Procrustes from there on.

It's an iterated process.

And this is how we start from the bottom.

So we're going to kind of like start from the bottom up of a scenario that's real, that describes subject, verb, object that people will recognize.

Person gets on bus.

And then let's think about what active core terms we would want to

apply to different nodes, recognizing that even the assignment of internal, external blanket states, it's conditional on our model.

It's not like the door is a blanket state outside of us modeling it a certain way.

And certainly we know external and internal are that way as well.

Stephen?


SPEAKER_04:
And this question of modeling, of course, this is where the niche and how much the niche can come in.

I think one of the things, if we're taking more modern societies, I mean, certainly more recently, is there's been an increasing role of this top-down or what I call literally copy and paste.

I mean, in Canada, they've got something called Shopper's Drug Mart.

They've got these kind of stores now.

And having worked in some...

like agencies, graphic agencies, is I can just imagine that there's like a design for a store, it gets tweaked, and it literally, and this couldn't have really happened in the past, it literally gets copied and pasted.

And it looks like it.

It looks like, oh, here's another shop that's another drugstore, but more like a chain, a franchise.

McDonald's is a classic case, I suppose.

There's some adaptation, but it's pretty much like plonk, plonk,

And in some ways, it's kind of devoid from active inference.

And that may be part of the problem is the more that it's done that way and the less that there's kind of an, even in the top down, there's not really even an inference process going on there anymore.

It's like, what are we gonna do?

I'm just gonna copy and paste using a machine, something that was done elsewhere.

It's not even contextualized from the top down anymore.

We're just completely bulldoze whatever we need to make it fit.


SPEAKER_03:
agree that that's the franchise model, which allows for rapid deployment, for example.

And then on the other side, from the user's perspective, maybe walking into a franchise is comforting.

And there is a reduction of uncertainty about aisle seven is where the serials are.

Oh, wow.

I was right.

They're actually there, even though I've never been in this city before.

And so that is definitely a evolutionarily novel context to have that level of precision of like what you'll find somewhere you've never been, but it allows for increasingly globally accessible reduction of surprise.

And maybe we're seeing that the reduction of uncertainty of what is there and the quality and how many grams are gonna be in that box and the profit margins of everybody down the line,

That system in many cases displaces the hand shoveling of granola and every little co-op having its own granola blend.

And these are definitely scenarios that can be modeled with Active Inference.

Dave and then Steve.


SPEAKER_00:
yeah the cut and paste mentality for corporate decision making in particular is really destructive uh the single biggest determinant for where you're going to locate a new business if you're a corporation either putting in your own outlets doing franchising is

Is there lots of competition?

If there's lots of competition, that's the location I want.

So you've got all these outlets competing with each other when, you know, across town, there's this whole underserved area where everybody would be happy, including your employees and your stock owners.

I've seen this in when a Walmart came into my old town.

The one big draw that would send people to the Kmart is Kmart had not changed any of their layouts for decades, so all the little old ladies who had trouble remembering where they lived could still find the granola.

So what happens when Walmart opens up across the street?

Well, they went in, reorganized Kmart and all the little old lady says, well, if there's no reason to go to Kmart anymore, I might as well save a few cents at Walmart.


SPEAKER_03:
And again, on the first pass, it's like.

but where there's less access to that thing.

But you go, well, I already know people are shopping here and now I can draw people who are shopping and people who are new.

It makes dollars, doesn't make sense.

What do they say?

Steven?


SPEAKER_04:
Yeah, this question about how to deal with the niche is a massive, massive challenge, you know, because the...

The bottom-up ability to self-organise, once that's lost, you're now in a different regime.

You've lost something and it becomes...

it becomes augmented by these other, because it's not even like we say that someone, we look, they don't necessarily look like if I was in a town, I might look where people are shopping, but actually what's happened is they're looking at the outputs of some metrics, which tells someone at head office, the, the, the key performance indicators.

from which they can algorithmically make some decisions.

And it all starts to roll out.

And one of the things that does mean, the initial stage is with, say, food, like one reason for, say, oh, why would I go to McDonald's?

Like, well, at least they think they wash, they don't know it, but by washing everything in ammonia or by, basically, by things always not having E. coli.

which is not an incidental thing in some areas.

So you'd go there and it's like, it becomes like this will never fall below a certain standards.

That's what their main thing is.

We've got buckets and buckets of disinfectant around the back.

So you're never gonna have to worry about any of the equipment, blah, blah, blah.

But of course the downside of that is that you get into this vicious cycle of mechanization, which suits that kind of producer.


SPEAKER_03:
That reminds me a lot of our discussions with Stephen Fox, I think in 27, about industrial engineering.

And before Dean could even reload, there was the craft dimension.

And it was about the integration of craft and industry and how just bringing up, here's the tolerable limits.

Like that doesn't mean that you're going to take it to some extreme over-mechanicized level.

way but balancing those two i just want to return to a specific scenario particular scenario in a city that will help us extend and connect to the paper and then we're going to go through some of the terms and actually just stay with one model and look at

What does an active inference model of a city look like?

Some people may read Serval's paper and then think, okay, it was prose.

I didn't see a figure.

I didn't see an equation.

I didn't see an example.

So what are we going to do to actually connect this to my local public transit planner or this grant that we have in this area?

Stephen?


SPEAKER_04:
We could use an example helping to connect people, connect across age and culture, and using public spaces and internet access.

So using actually the project we're just looking at the moment, we're putting in a Wi-Fi mesh in a community, a sort of a newcomer community, relatively low income.

There's questions about, okay, do you bring in resources so that people get more stuff at home?

And then how much of that stuff at home is enough to leverage something outside of just consuming?

How does that then leverage resources?

doing something with it back in the community, making it something that extends the niche.

Things like Meetup, I think that's a familiar platform, which has been quite useful for people to self-organize.

So we see this ability to do that through the internet, but of course,

Well, what's the ability to do that in real life as well?

Like the coffee shops, the cafes, you know?

So, you know, you know, anyways.


SPEAKER_03:
Yeah.

Let's pick a, we can do like a meetup, you know, planned or unplanned meetup at a certain spot, but let's pick like a very specific scenario where somebody can say, I haven't seen that be modeled this way.

There are new ways that we can now, uh,

talk about that scenario.

So brought up many important areas like connecting across ages and cultures, et cetera.

So let's think of some public space like we could do.


SPEAKER_04:
A cafe adjacent to a park.

Let's say that.

And we know that that might be relating to other cafes.

We should say if there's this cafe next to a park and how does that relate to

you know, getting a coffee, but obviously, it's not just about getting a coffee, is it?

But there's an interesting, yeah, what does that relate to the niche?

So we're going to talk about this.

So how does that relate to the niche, the ability to have action policies, the ability to serve service needs?

Yes, also service wants and loves.

So actually, actually, one thing that you might find an interesting in

In the development world, when they're trying to look at more complex contexts, you've got needs, wants, and loves.

What needs to happen?

What would I want to happen?

What would I love to happen?

And often what would I love to happen is actually more generative.

Often everyone wants to talk of the needs, right?

I need to get a cup of coffee.

Okay, here you go.

I need, what's your needs now?

I need a drink.

Okay, here you go.

And it's kind of stuck, right?

Well, what do you want?

What would you love?

And that's kind of what humans have a role in.

We're not a machine that needs filling in from one end.

So I wonder what your thoughts are in terms of how that, what sort of cafe should we think of?

Because we're all gonna have a different cafe in our minds here, right?


SPEAKER_03:
Yeah, I agree.

It shouldn't be like the cafe in my little town on this corner.

So we're going to talk about a cafe adjacent to the park.

Also, Dave, thanks for the cool sumo references in the live chat.

I think that's an example of how you can scaffold and use ontology as a thought pump and explore formal, dance towards the formal, and then back towards the qualitative.

So it's a cafe adjacent to a park.

we're not describing the territory.

That would be like a Borges horror novella where we're trying to describe to the atomic level, you know, the paint coating on the streetlight.

So, dispense.

We're doing a human-centric model.

Maybe there are assistant animals, but

we're going to build up the model.

And that's why we're discussing this on the slide with dimensionality.

So what's the dimensionality of a cafe next to a park?

I mean, the question barely makes sense.

You could have a parameter in your state space for every molecule of air, but we're talking about a communicable simple model that might be on some sort of Pareto optimal front, Bayes optimal front of accuracy and complexity.

So it's like,

can't explain this to the local politician in a third of a second but three minutes is probably too much so we're going to find some communicable level of detail and make a use-oriented active skeleton and then see where that takes us dean so this is a i'm asking this question because i don't really know if we've got a cafe adjacent to a park are we having some kind of a


SPEAKER_01:
Are we assuming some kind of a compounded sense around what is an attractor state here?


SPEAKER_03:
So it's a great question, like dwell times, like maybe there's some transition frequency from the cafe, you know, from non locations that we're not even discussing.

It's not the whole world.

This is our map.

It's just a little map.

into the cafe and then from the park to the cafe.

And then there's like the ingress and egress of the park and then its relationship.

So we could even start to think about like nodes and edges that are connecting the location of a person.

Stephen, and then we'll start working through the list or feel free to say any of those terms.


SPEAKER_04:
Yeah, I think as Dean mentioned, I was thinking about like the non-equilibrium steady state is, so maybe we need to think

Okay, you've got a cafe adjacent to a park.

Okay, so like you say, you could be, what's the non-equilibrium steady state of that grass, if there's grass on the edge of the park, right?

Or what's the non-equilibrium steady state for the behavior setting?

Actually, there's some really interesting work that Harry Heft does with behavior settings.

So maybe that could be another, so that, and of course,

we'd have to see what scale.

So again, what sort of scale is friendly to this kind of question?

If the behavior setting gives us kind of an idea of the niche, almost, as is capitulated by each person.

And of course, this is where the challenge is in terms of, if I'm gonna be taking the sensory state perspective, I kind of have to take an agent


SPEAKER_03:
Yes, there's no sense state outside of a specifically defined agent.

Which agent are we going to be looking at?

Should we take the barista?


SPEAKER_04:
Do you want to take the barista?

That might be easier.


SPEAKER_03:
Look, let's just do human.

Okay, human.

So these are people who we're talking about.

There's other entities.

There could be drones flying around.

For sure, there's ants.

There's all kinds of stuff happening in the territory, allegedly.

But we're going to be making a reduced dimensionality model

Maybe one that has low computational overhead, or maybe one that's easy to communicate, or one that explains a lot of variance but not every single nook and cranny.

So we're going to be talking about humans in the cafe adjacent to the park in a city.

Dean?


SPEAKER_01:
So if we're looking at this through the lens of active inference, there's two things now that have been raised.

One is, do we have an attractor state?

And meaning, will people migrate?

Will they move?

Will they congregate?

Will they gather?

And then Stephen brings up the idea of, okay, so how do people remain in that non-equilibrium steady state?

How does the expectation now get realized once the migration has occurred?

This is what an action and active inference working together allows for.

Something gets kicked out at the end, right?

some material thing with ingredients that we can now account for gets kicked out at the end.

But in the meantime, what we have to do is we have to actually look, will people gather?

Is this actually a place that people will now move towards?

And then, because that's a city, right?

They've all congregated.

And then we have to ask is, will expectations meet intentions?

That's what going through an active inference process actually affords.

It doesn't guarantee, as you said, Daniel, it doesn't guarantee the specifics and the particulars.

What it does is it holds up on a more abstracted level for a longer period of time before energy is actually applied, before something actually materializes.

And I think that's what messes people up because there isn't a critical path

ready to be fulfilled.

It's an active inference process that has to have certain anchors in the ground before you can, before an anchor is meaning abstract that you have to have available that act as affordances that eventually kick out the blueprint, which eventually kicks out the dwelling, the edifice.


SPEAKER_03:
Thanks, Stephen.


SPEAKER_04:
and so you've got this kind of broader dynamic so we've got again so resolving scales again so it comes in because could like there's going to be at the broad level customers and someone serving in the cafe right um starbucks calls them a barista right to tie in with that vibe but

So they've got a different teleological expectation, even in the abstract.

We haven't even worked out who they are, right?

Now, of course, that's not quite so true if one of the customers is an adult with a three-year-old child, right?

The three-year-old child's expectations are slightly different in terms of what it is to go in there.

So you've got this, but essentially speaking, there's a regime of behavior that each of them are teleologically attuned to, to some extent.


SPEAKER_03:
Let's go through these terms in this order, and there's a specific reason why.

So affordances are capacities for action.

They're what actions are selected from.

Yes, they're ecological, et cetera, et cetera, et cetera.

Which affordances will we put in our model?

So taking out a phone of your pocket, it's an affordance, but is that the model that we're making?

So again, not the dimensionality of the territory, but what is our model?

Are we interested in treating the person like a blob and the affordance is literal, just go to the park or leave the scene?

And so we can have a simple matrix.

Are you going to be in the three by three matrix?

Are you going to be in the cafe, in the park, or neither?

With a transition on the off diagonal and the diagonal would be your dwell time.

So that is like, the person is just like a point.

Okay.

Also affordances can be zoomed in and a lot more granular.

The affordances could be the angle of every joint in the person's body.

And that might be relevant if the steps are going up to the cafe and someone doesn't have a joint mobility to raise up their leg a certain level, then that is going to influence their transition movement matrix.

So when we coarse grain to just the blob and the three by three transition matrix, which is simple,

that may abstract above important layers.

So that's why iterated modeling is really important, but iterating means we need to have something there to iterate on.

So for a first pass, do we want to do a model of movements?

of the people amongst the different spaces.

So that would be like one example.

Another example would be like, we're interested in drinking behavior.

So the affordance that we're going to model is the choice of no drink, coffee, tea, smoothie.

So we're making a kind of behavioral economic model and actually we're not as interested in the movements

transitions, we're interested in how the niche, the temperature, influences people's buying habits.

Or we could have both.

We could have where they are as a blob and what drink they buy.

Or we could have where they are and all their joints and what drink they buy and them looking at the phone.

That's the dimensionality of the model.

It's not the dimensionality of the territory because we're still talking about the same place.

So what kind of affordances do we want to focus on?

Like we know that you could go, anything a person could do is going to be an affordance.

But what affordances are we going to be talking about here?


SPEAKER_04:
I quite like the idea of working with the where, the where-ness.

I think there's a lot of tendency for what personal orders, what the thing is,

sort of thing that you can in some ways potentially emulate in a lab i don't think you can emulate the awareness in a lab like so what sort of zones might they occupy like there's this around tables there's around the doorway so it could be

You know, you've got these, yeah, you've got the park.

So even more broadly, yeah, maybe a very broad level, there's the cafe, there's the park.

And then that can then break down by some zones or maybe they fall out from the model, you know?

But yeah.


SPEAKER_03:
So these, this is going to be fun because I'll just do it.

So the diagonals of the matrix, this is like a movement matrix.

So the stay is the number could be like zero to one, the probability in the next hour or the next minute.

It's not an absolute disclaim.

It's time dependent.

And then you could imagine within staying at the cafe that

we could make another little matrix that had the table, the bathroom, the counter, but it would be only and strictly within that top left cell.

That's the sub matrices that we were looking at in number 32.

So we're going to be in a state and that's what coarse graining means.

Someone can't look at our matrix and say, how could you not have modeled the counter in the bathroom when people have different... Great.

We made a three by three matrix.

Now let's make a submatrix and let's make that fine grained.

And that submatrix could be defined in terms of Kronos.

Like what is your coordinates in the cafe?

Three comma four.

Or it could be Kairos.

They're at the counter or they're...

doing something spatially, but we're not putting a number on it.

So staying is the on diagonal, because we're making a coarse grained movement model.

We're not looking at their elbow angle.

We're not looking at where they are inside the park.

This is a first iteration of a model.

And then if there was surprise coming from our model, discrepancies with the observations,

just like Act-Inf, we could update our model.

But again, iteration entails that we need a complete model before there's anything to discuss.

If people are just throwing out random core terms and terms outside of the Act-Inf ontology, it's part of a discussion, but we're not iterating on a model.

So it's fine, but that's not making an active inference model.

Dean, and then we'll continue.


SPEAKER_01:
So I like this because materialization piece now what gets kicked out is on a gradient descent.

But my question again then is, so when you're talking about affordance, are you including availability, as in what Stephen was talking about, because of where I am, now things are at hand, are proximal, or are you talking about threshold lowering, meaning ease,

at which something can be attained because they're not they're not the same thing and i want to know whether or not we're including both in terms of crystallizing this materialization stephen and then we'll come to that yeah this is helpful like i think it's good this idea of drilling down


SPEAKER_04:
And I suppose this is this extra question, maybe it's at the side there, but is how much does the nature of things change by being in the cafe?

By staying in one location,

or move in between locations, there's that question about this kind of, I suppose it's this kind of fluidity, right?

And that's an interesting side question, which- We can put it in our model.


SPEAKER_03:
We'll be able to actually iterate on that question.

And I'd argue this isn't drilling down, this is building up.

There's nothing to drill into until we have this fully described.

Otherwise it's just like two people are, you can't drill into a linear model that hasn't been specified.

So there is no drilling down until we're talking about something particular.

And then we could coarse grain or we could fine grain or we could iterate or elaborate or transpose.

But we're at the zero to one step in act-inf modeling here.

Dave?


SPEAKER_00:
Yeah, and making those transitions actually changes the inventory of potential affordances of other participants.

When you walk into a room, you give every person in that room seconds to either greet you and establish a potential relationship or to say, oh, this guy doesn't want to talk to me or he would have nodded.

Urban Goffman goes into painful detail on how that stuff works.

And that one relationship can persist for years.

The guy you nod to and the guy you never to, do you nod up or do you nod down?


SPEAKER_03:
And it's very personalized and cultural.

And that's definitely like a level that we, we haven't even gotten into the inter agentic, but we can, we'll, we'll get there.

And we can see, is this part of our zero to one model or is that gonna be included in our one to two model?

But repeatedly returning to, not saying it's a bad thing, but just repeatedly returning to aspects of the territory before we have a model to iterate on, the model is gonna remain uncompleted and you'll have done a partial inventory of a territory in a totally ad hoc pseudo linear way

when it could have been all there and iterated using our ontology and framework, which we're here to work on.

Dean, then Steven.


SPEAKER_01:
Yes, so Daniel, maybe you can help me because I say, when I think about this, the availability piece, because it's proximal, doesn't mean that it's not on a high shelf

meaning high threshold and I can't get the coffee bag down that's full of the beans, right?

So again, I like what we're doing here, but I still ask when we're talking about affordances, are we looking at two ways of describing that at a minimum?

Because that's what I'm hoping we're doing, but if we're not, what are we doing?


SPEAKER_03:
Stephen?


SPEAKER_01:
You were going to give me some thoughts around that.


SPEAKER_03:
Yeah, first, Stephen, with a raised hand.


SPEAKER_04:
Yeah, that got me thinking now.

The question I suppose is as well, as well as iterating on, you know, we can run multiple examples of, so it might be one of these cases, like you say, many things can happen, but you could run, you know, you could have two or three types of models that are kind of simple and you run them all many times and see, okay, and maybe change certain parameters to make something more likely that there's a long-term relationship, that there's a potential binding energy that kind of

is exhibited.

And then you can sort of look for clusters of transitions, clusters of behavioural patterns, right?

And so then we're sort of comparing patterns.

And at some level, then it's in a way becomes a sense making process for us.

And the advantages we've got is we can tap back into our embodiment, because we're humans.

So we can say, okay, seeing that, what sense do I bring a higher dimension to all of that?


SPEAKER_03:
Yep.

You could have 500 groups of three separate and make their own active model of a cafe adjacent to a park.

But they all have to get that zero to one.

Otherwise, if they come together, what is there to discuss?

500 times zero.

Zero.


SPEAKER_04:
Well, I wasn't so much thinking about different people.

I'm thinking even us, say the person who does the model, you just literally...


SPEAKER_03:
run it lots of times but with slightly different tweaks and then so you get you you can sort of get something from that i would say that's a different type of maybe you start to see some of these patterns that's iterated modeling with getting the first version and then changing parameters and iterating and then looking for patterns across iterations that are achieved via a certain strategy of changing parameters but incomplete model will never run so

Yes, there's a total space to do stochastic simulation and run one model 5,000 times and 5,000 different models one time and every other combination.

They all are predicated on iterating on something that already is there.

And so that's the zero to one phase, Dave.


SPEAKER_00:
I was puzzled how you translate the stories that you find in so many academic papers, or semi-academic papers.

Sociologists are great at this.

They'll say, this happens, this happens.

How do you turn that into sumo?

Very simple.

Exists.

Exists person, person enters room, and, and, and.

and you throw it in the model, and if it says contradiction, something's wrong.

If you're really confident that, hey, that's the way the real world goes, you negate it, you throw a does not exist, and you got a universal, and run it, and it blows up, and you say, oh, I guess not everybody does.

What I said is wrong.

Let's find out what I did wrong.

Cool stuff.

You don't even need the exotic.

You don't even need to recreate things.


SPEAKER_03:
um mathematically oriented modeling tools you can just do it in pure yes or no true or false logic just realized that this morning and my head lit up nice um yeah take people at their work just use their word and they asserted that this and then i hope they used nouns and verbs

And if so, then you could be able to parse it.

So let's, we're making a coarse grained movement model.

So again, it could be fine step.

You could have the affordance be to take a step and the location to be something else fine grained, but we're taking a coarse grain.

Now we're going to talk about the sense of the agents.

So their actions are their movements, which is just a coarse grain movement state.

That's the actions that they're doing inference on.

what are their perceptions we know about the 5 11 55 senses it's not about the scent of coffee in this model again the future model with which thing they bought you could go to what is their sense of smell but here we're just going to do a sense mapping matrix with light

Okay, so the cafe is gonna have red light.

I love red light.

So the cafe is going to have basically a 80% chance of red light if you're in the dark room, a 0.2 chance of sunlight if you're at the window seat and it's never dark.

If you're in the park, there's a 100% chance of it being sunlight.

There's no red light in the park.

and there's no darkness in the park.

So it's like the daytime.

So again, that's iterating.

So it's good to keep those things in mind and like have a coda or a space where you could have everyone's perspective added even when you're building the first iteration.

But some matrices do need to be specified to continue talking about it as an active inference model.

And then neither, we'll say neither, it's never red.

This is a rare red light that the cafe uses.

and it's half the time sunny and it's half the time dark because that's who knows we just have maximal uncertainty but we know that it's not red okay so this is how the a matrix in active inference if you said you're in a dark room where are you well here given these simple numbers we know that we're in neither the cafe or the park if you said you're in a red light

where are you you must be in the cafe it's the only place with a red light if you said you're in the sun what is the probability that you're in the park it's two-thirds roughly this is 1.7 and so it's 1 divided by 1.7 is literally the probability of being in the park conditioned on seeing sun

So that is Bayesian statistics.

It's like, we have a matrix of sensory mappings, and then it's like, here's a new observation.

It's red.

You go, okay, it's 0.8 over 0.8 that I'm in the cafe.

Okay, so that is the sense mapping matrix.

What is the inference on?

What is the S, the hidden state?

Where am I?

That's not directly observed.

you're observing only the photons in this model.

So this is a mapping between the O, the observations, and then the S, the states that inference is being done on.

But aren't they thinking about their to-do list?

Yes.

in the territory keep it in mind add a note add a comment we want to hear your perspective that's not the coarse grain movement model so these are active memes for simplifying teams okay we have the perception which is the sense here it's three states and we have the locations that inference is being done on now we can talk about preferences what are preferences for

This is like perceptual control theory.

Preferences are over observations.

So it's like the preference is to observe the body being in homeostasis.

That's part of the preference specification in ACT-INF.

So one could imagine that if somebody had no preference for any of the... I don't really care.

Then...

they would move proportionally to the ratio of the transitions of the affordance matrix.

So if all the transition frequencies were even and there was no preference over sensory outcomes, you would be evenly distributed.

If there is a preference for darkness, no matter how slight, and there's any ability to move into the neither, then that will be the attractor.

because individuals will dwell in a more preferred state because they prefer the darkness, which is only accessed here.

If there's a preference strong, then you exaggerate it.

Like a strong preference for sun, we would see like everyone or almost everyone in the park.

A weak preference for sun would only slightly bias towards the park.

Dean?


SPEAKER_01:
Yeah, I think I'm asking, should we assume that the preference is to be verdantly caffeinated or caffeinatedly verdant?

And I'm not being a smart apple.

I'm asking that, is that the assumption that we're building our model around?


SPEAKER_03:
Because you asked.

Here's the interesting thing about this model as we're building it in the first iteration.

The sense is visual.

So there's no coffee in this model.

No, I know, but why isn't there?

Right.

So if we could talk about a different affordance matrix, a different sense mapping, it could be interoception.

It could be, am I excited or not?

And then do I prefer to be excited or relaxed?

So just two interoceptive states.

Then there's an affordance, which is to drink coffee or not, which is to have some probability of moving you from one state to another, okay?

Coffee is increasing your likelihood of getting excited versus not, doesn't.

That is not a spatial model.

So now we could make that preference over caffeination states

And that's like a module that's going to compose very interoperably with the spatial model because the affordance vector, the sense vectors, those can be heterogeneous.

That can be, here's the three by three spatial and the two by two caffeine.

And those are sub matrices.

And it does turn out that the cafe is where that affordance is enabled.

And there isn't the affordance for the coffee in here in the park.

But those are two types of...

observations.

There's the photon observation, which we're using as a proxy for location.

And then there'd be the interoception, which is related to the caffeination state.

And then those could be combined and you could have a joint density over caffeination and location.

And then policies like where to move could be selected based upon the long-term expected free energy, given the preferences and affordances of that agent.

So there are different modules that can be composed in an integrative modeling framework for perception, action, and cognition.

Hashtag active inference.

Dean, and then Steven.


SPEAKER_01:
Yeah, just real quickly, I was going to say, I was going to answer my own question.

I think then in terms of a preference confirmation, the iconography on the side of the cup would seem to fit within the niche as well.

So maybe it's a large acacia tree in green.

So I wasn't saying it in the sense that we were... I don't want to drag this off course.

I want to actually reinforce the idea of how preferences align as opposed to saying, why aren't we including that?

I'm kind of reinforcing the sense mapping matrix.

Thanks.


SPEAKER_03:
Stephen?


SPEAKER_04:
Hello?

Yeah.

I suppose one thing I'd like to check in with, though, as we're just doing this, take a little bit of a breath, is you've kind of got the deontics, you've kind of got the deontic cues, you've kind of got the, okay, I can make a choice between the affordances for action.

So it's sort of coming slightly from a more deductive kind of script approach.

triggering world, which is useful.

I'm also wondering, there could be, say for instance, that sense mapping matrix, as well as it being something that links someone's preferences back to where they go more broadly.

So that's quite useful.

But I'm wondering also, if someone's navigating a space,

And maybe within the cafe, there's some red, there's some sun, there's some dark.

I know you talked about embedding, but there's a question about, is there a tendency to move towards deontic type of structuring because it kind of takes us there?

And if there was to be a kind of a more gradient based transition that's happening in relation to the space, it might be a different, you know, how much does this adapt to that?

Or does it need to be rethought in terms of the type of modeling?


SPEAKER_03:
Okay, so this is a coarse-grained model.

So to say that it's 0.8 red in the cafe and 0.2 in sun in the cafe corresponds to 20% of the locations have sunlight on them.

So one could then make a sub-model where at table one, it's 100% sunny.

So you're still in the sub-matrix that coarse-grains to 80-20.

But there's two tables that are in the sun and then there's eight that are in the red.

So then you would have affordance matrix within the cafe sub matrix of moving of a 10 by 10 tables.

But one can see that as you include more rows in the matrix, you get exponential explosion and that,

proposes computational challenges and just like parameter identification challenges.

Cause maybe you never saw someone go from seven to two, but it's not that it can't happen.

It just, there's only 80 people who went to the shop and there's a hundred transitions.

So it just, you're not gonna see all them.

So then you get a very poor estimate of a hundred parameters.

that's why we're talking about modeling not what is happening in the territory this is going to give you some coarse grain results then the sense mapping matrix is preference free it is not a preference matrix the preference matrix c is where the preferences are specified over sensory outcomes only

So here's Dean who has like a nine to three of red over sun.

Now Dave has 1.1 to one.

So they both prefer red over sun, but we can see, and in the model stream one, Ryan Smith and Christopher White, we talked about like what these numbers mean, their ratio, their absolute amount, et cetera.

So we're not gonna talk about it here, but Dean has a stronger preference for red over sun, whereas Dave has a weak preference for red over sun.

Okay, so we have the preferences over the observations.

Okay, we have the affordances, coarse-grained movement, not the elbow motion, not which table, coarse-grained movement.

We know that we could make a submatrix.

Then there's the action states, which is moving from one to another.

Then there's perceptions.

The observations, the sense states, those are photons, not location.

but there's a matrix.

Now that could be a fixed matrix or it could be learnt, but we're just starting with a fixed matrix.

We have preferences over observations.

Those are only over colors of light.

And so for Dean, it's just a vector of three, but we're just contrasting two different agents that are in this cafe area.

Then we have expectations.

So expectations are the generative model, what would be expected observations.

And so Dean says, I'm the kind of person who expects and prefers red a lot.

That will shape which of these affordances are taken.

And so Dave and Dean can have the same sense mapping matrix

They don't differ in how they infer where they are given the photons, but the affordances can also be the same and they'll have different behavior.

So that's how you get agent specific behavior from a model like this.

You could have agents with the same preference, but they differ in affordances or some other combination that's iterating and enriching a model.

And then just one thing here before we go to the question, Steven.

So what is the niche?

So yes, again, the territory, we think everything, it's just everything in the world, but the niche is the generative process.

So the agent is the generative model.

And the niche is the generative process that's actually like handing those observations to the agent.

In this case, it's just the emission of photons.

It's literally just the light source is the niche because we're making a super simple model where the only observation that's getting handed from the niche is photon.

So the only thing we need to say for the niche is it's the process, the hidden process that emits photons.

Maybe it's a red light bulb, maybe it's red cellophane and it's white light, or that's the hidden generative process.

The niche in this case is just the process that emits observations to the agent so that they can then integrate that into their generative model.

Stephen, did you want to?


SPEAKER_04:
yeah yeah i think i mean rather than necessarily emission of photons you could say it's like the perception of light because it could be the niche is not a perception the agent perceives the observation of light but the niche is the process that gives rise to agents observations right okay if you take it from but the the red red is not photons that's the perception of

state yeah without getting into what is red do we all see the same red we're talking about the mapping between the perception of what is called an english red and the location state and the location state no exactly and so you then got well two questions one question do you know the list you've got nine three zero as opposed to it doesn't so how do you scale that like would you you don't do it so they always number one is the highest and it's a you've actually gone above one there so is that they use a different how would you scale what the maximum is in that


SPEAKER_03:
So this is what we talked about in model stream one with Ryan Smith, but basically these numbers do get normalized to sum to one to be a proper probability.

in a softmax function.

Oh, I see.


SPEAKER_04:
So it just sums them all up and then, yeah, sums them all up.


SPEAKER_03:
That's how you get the probability proper from this, but then the ability to have it go beyond just one.

So that's the difference between five and one versus 50 and 10.

Depending on the generative model, those might behave very, very differently.


SPEAKER_01:
yeah this first of all this is fantastic to build it in real time but i want to just now ask a question so so and then in real terms we built this model and it kind of makes us aware of things that we maybe wouldn't be aware of because we weren't in the active inference realm but now my question is so so now

Is this also projectional?

What kind of inferences do we make off of this in terms of agents go, don't go?

Because to me, then, that's when the real value is realized because we can't predict with certainty who goes and who doesn't, who ends up at the cafe with the coffee and who stays at home and watches TV.

Friends, right?

Like, so how, so we've got this, this is fantastic.

But now we want to get to a place where a person who normally would be somewhat risk averse takes this and goes, oh my goodness, this opened up something that I would normally never have gone.

But now I'm prepared to go.

Does it help?

Do you think this work helps that person?

just off the top of your head?

Because I know it helps me, helps you, but that person who is trying to do this on that decision branch moment, how does making them aware of this alter their thinking?


SPEAKER_03:
I think it does a few things, some of which we've seen in the past few minutes, others which probably remain to be explored.

It separates out

observations from the state that's being inferred.

Because it'd be very easy just to simply say, well, I prefer the cafe.

Oh, I'm observing red in the cafe and I prefer red.

So by having the preferences over outcomes and then separating the observed outcome from the inferred hidden state, you're gonna be like, you like spicy food.

That's why you say you like this kind of food.

So pull it back to these matrices.

Let's just say that they knew all the options.

Maybe people are not aware of all the affordances that they can even take, or maybe they have some to add themselves.

So this is like saying, this is like, these are all your chess moves.

We're playing chess, so we're not even going to worry about knocking the pieces off the table.

We're playing a well-mannered chess game.

But we can modify the rules, but we're playing with the affordances.

So somebody might have their mind expanded by just considering all the affordances that are available.

Like, well, I guess I could go to the art museum in the city.

but I'm not that kind of person.

It just hadn't even seemed to me.

So by bringing their regime of attention to affordances, we're seeing the whole space.

Then people can separate out the outcomes that they have preferences over for the hidden states.

And then remember affordances are the actions that modify the transition probability of the hidden states.

actions that's like where the pi plugs into the b which is intermediate between the s through time the pi policy doesn't plug into changing the state you don't have an affordance for red light you have an affordance to move to a location that you've inferred has higher red light so

There's probably many other approaches, but this sort of like gets the whole map out there in terms of the space of the possible, which is, again, we're saying that is the space of the possible.

It's not like there's some other secret affordance.

And then you can have a conversation about how people map things.

their perceptions which can include internal perceptions like being bored or being sad or happy that's the whole mental action they can map their preferences over observations to inference on states and the affordances that get them there Dean


SPEAKER_01:
OK, I'm sorry, you froze for a minute there, partway through your explanation.

So if I'm saying something back that you already answered, I apologize.

So this kind of, to me now, so now that we're talking about regime of attention, because I still heard that part, that kind of goes back to one of those live streams before where we were, I think I mentioned, is it about time on task?

because we can now measure that because that's now something that we easy to measure, or is it still about what have we made available to ourselves?

And so what we get a sense of in terms of what we might be missing in terms of change blindness as one example, versus what we now,

Again, how we've expanded our awarenesses as opposed to what we've given more attention over to.

Because, again, my sense is it's easy to measure what I'm paying attention to.

It's more difficult but probably more valuable to know what –

what the possibilities are in terms of that 80-20 that I may not have been conscious of before.

Does that make sense to you?

Because that's how I see this eventually moving on a gradient descent.


SPEAKER_03:
Yes.

So these are a single level agents right now.

Like they don't have metacognition.

So they're not like, I'm unsure about something or I'm sad about something.

But I'm seeing two cases where regime of attention applies.

It doesn't apply in this current model.

Two regimes of attention.

One would be like an intra model regime of attention.

Like we could have in this agent, a metacognitive attentional layer that is either paying attention or not to sensory outcomes.

And if they're not paying attention to it, it's going to slip by and it's like the gradient is flat.

And then the more attention they pay, the sharper they're going to realize their preferences.

It's like, wow, it is really sunny out here and I prefer red light.

So I'm going to go because I was...

brought my attention to it.

Then there's sort of this like XO model where you're talking about bringing people's attention to different parts of the model.

Now that itself could be an active recursive model, but that's like,

using this model to drop to both expand people's to the space of the possible and then direct their regime of attention to certain phenomena or attributes of this model.

So there's, I think there's like two little bit separate uses, but they both apply.


SPEAKER_01:
Do you think, do you think the second one,

Because if I go or I don't go, both of them give me a feedback loop that I learn from, right?

So do you think the second one is nuanced different than the first or quite radically different from the first?

Because I know if I don't go, that's quite different.

That's the zero.

And if I do go, that's the one.

They're quite separable and quite discreet.

Is what you're describing more of that blur?

I wasn't in on the 31.

I think it was where there was no line drawn in the sand.

And so I'm wondering...

Now I'm wondering about that because, again, ultimately if we can take this off the page and use it and actually use it in ways that give us more prediction matter expertise, boom.

So what do you think?


SPEAKER_03:
Yeah, let me type something.

Stephen, anything to add there?


SPEAKER_04:
Do what you're doing and I'll say what I was going to say.

It's sort of

It adds, but it's a slightly different point.

So I don't want to just let you finish this point.


SPEAKER_03:
Okay.

So the first case of the regime of attention is going to be, we do a recursive layer in this agent so that they can be paying attention to something or not.

Okay?


SPEAKER_01:
Yep.

Time and energy apply.

Done.


SPEAKER_03:
Yeah.

So the second, the sort of application or communication of the model would be deploying this

I don't even know.

It's like a meta slash XO model.


SPEAKER_01:
Are you coming up with new ways of describing things?


SPEAKER_03:
Not during a live stream.

We don't do that.

We do that before.

And then we rehearse, remember?

So you could use this model to bring the policy planner's attention to something.

So again, you distinguished there was first just stating the space of the possible.

So that's not an active secret.

Like the policy planner might go, oh, I guess I never really thought people would move from the park to the cafe.

Oh, I was thinking how people would get to the park and then how they'd get to the cafe, but I didn't realize that they would move between them.

Maybe that literally happens.

So that's just like a movement matrix.

Any kind of systems thinking or...

design thinking or agent-based model would converge on that, any kind of iterated modeling.

Okay.

But we're talking about what Act-Inf could direct their regime of attention towards.

So let's just say that we had a nice polished dashboard for this cafe movement simulation.

And then we had two kinds of

people, somebody with visual scenario A and visual scenario B. So maybe it could be anything.

It could be their preferences over ramps.

Children love ramps.

Some people cannot move up them.

Some people love bright.

Some people love dark.

Okay, so you can say there are, we're going to just say there's two kinds of agents in this simulation.

And we'd like to bring your attention, policy planner,

Your preference over observations, which is like local businesses being intact, people hanging out in the park during these times of day.

You have these preferences over observations.

We're kind of meeting you and we're seeing those, your observations are our outputs.

Our model is outputting the things that you are observing and caring and preferring over.

We've done a suite of model explorations and it seems a little counterintuitive, but adding a red streetlight in the park changes how people use it.

Nobody would have suggested the red streetlight, but we know that there's people who love red light.

And it turns out that just having one red streetlight, it makes it great for them.

That has totally changed the flow steady state, non-equilibrium steady state, reflecting in a tractor in our model.

That has changed.

And we can see these suite of simulations that

and we're just gonna call your attention to this graph and call your attention to how the points go higher on the y-axis as the x-axis dial changes.

But it turns out we don't want only red light in the park.

So we ran a simulation from zero to one, red and sun, half and half and every combination.

And so there's some curve and we'll draw your attention to the point where that curve is.

That's a great first step and we'll iterate.

because it's an open source model and we're in conversation with you and then we'll be able to test.

So the map and then the allocation of numbers on the map is kind of like the regime of attention.

That's our affordances as modelers.

And then there's that layer of communicating it clearly with strings of natural and computer language and visuals

so that the regime of attention of something not in your model at the core level, like the policy planner, they're like, oh yeah, I guess I do expect and prefer this.

And here's somebody who's giving me that expectation and preference and a toolkit for counterfactuals and elaboration and their outcomes are my incomes.


SPEAKER_01:
Okay, thank you.

No, but I think that's helpful because at the end of the day, there's somebody who's actually observing this and putting it into each one of these cells.

But I'm not sure that the people that are actually doing it are necessarily aware of it.

And so my question is, once they become aware of it, what can they do with it?

What's the value to them?


SPEAKER_03:
Yeah, so it's like the first ring of the model, you know, the person's moving.

We could do mean field approximation, really simple.

We could do the trajectory-based particle simulation.

Okay, then what's outside of our model and the sort of boutique step is communicating to the policy planner.

But now let's just say that I, the modeler, include the policy planner in this model or they have a different model.

Now the outcome of that model is being passed to me.

So you never get around the notion that there's like a boutique level of communication of the model.

But the idea is that like critical infrastructure could be inside the model and the boutique communication could be to the public.

And then we would have functional infrastructure and good communications.

instead of little sub ad hoc modules for critical infrastructure with boutique communication amongst them, so that any tenuous wrapper drawn around all the critical infrastructure is gonna be incoherent.

Then that incoherent blanket cannot be communicated out another level.


SPEAKER_01:
I think you're reinforcing the idea of the difference between instructionalism and interaction.

And what you're describing there is kind of the way finder rule

sort of coinciding with the person who's wayfinding.

So... Cool.


SPEAKER_03:
Maybe we'll have templates, guidebooks, playbooks, workshop, all those things.

Like, what is the right order?

There's probably not only one order.

But again, if we don't have a model to discuss...

it's going to be like getting to 0.1 and then to zero.

And then there's the grass and the grass is alive.

And then the grass has viruses and our virus is alive.

And what is green?

It's like kind of these like false starts.

But I think once it connects, even conceptually, we didn't write this in code.

It's not even pseudo code.

But once it conceptually connects, and then we can say, okay, let's make affordance matrix E1, and then let's make E2.

So just like it's an alternate hypothesis on the affordance matrix.

Then we have, you know, A1 and A2, just two hypotheses on the mapping between hidden states and observations.

And then we're going to run a two by two model simulation.

E1, A1, E1, A2, E2, A1, E2, A2.

Now we're doing decision support

And it's up to us, because that's the unmodeled, is our decisions, our preferences over the outcomes that we're seeing.

Oh, I like the E2A1 because I prefer people to be in the park.

And then it's the cafe owner says, I looked at that one and I liked that one.

Oh, we're modeling ourselves making this decision and you like people to be in the park and I like people to be in the cafe.

we have a different preference.

So we're not going to eliminate tension, but that's actually a conversation to have versus I consulted this group and they made this PDF and you did this and they did a word file.

It's a different file type.

They wrote in a different language.

They're not informationally integrated.

What is the comparison?

Cool, you know a consultant, but then this is a way where

People may call it transparent.

I'm not sure how transparent massive statistical models will ever truly be, but maybe it's kind of like a transparent engine.

It doesn't mean it's made of glass.

It means like there's a window into it.

So here we can see the pieces going in.

There's no side door.

There's no other matrix.

If we specify the partially observable Markov decision process, the POMDP,

those are the pieces that went in and the connectors are also established then we used a message passing algorithm or some other approach to find parameters so which part of that would you like us to interact on i mean that's an actual conversation and then even if somebody doesn't know about one part they could still be included in the dialogue perhaps dean


SPEAKER_01:
Yeah, and again, you touched on it, you kind of circled back to it a couple times, and you actually used the word support, whether it's support or serve or contribute, that's kind of the one constant regardless of how it sketches out.

That's the one thing that seems to run through this as a constant, how Active Inference actually supports


SPEAKER_03:
what what inevitably gets kicked out or what we observe at the end of the day right like we're doing this we're using limited high energy electrons and our attention and our finite life and everything like that all these resources so that we can have decision support in this example and then we undertake a policy that modifies the niche modifies the generative process and

but that's unmodeled.

Again, we are at the first level where we don't even have the construction site.

So then we have the model where I can choose to change a light bulb from the, you know, maybe we can add a natural light into the cafe.

That would be the next, that would be like an Act-Inf model of agents using an Act-Inf model.

And then that model would still have this boutique layer that has to be communicated

informally and that's like kind of the connective tissue where you have something that's like a pomdp interfacing with the world it has to have some sort of an interface like that stephen then dean yeah i think this is really helpful the the affordance thinking of affordances as effectively the setting up for the action policy and the generatives


SPEAKER_04:
generative model.

So it's saying, okay, in this case, it's the affordances to be able to stay or move.

And what I think is really helpful or I'm excited about is, and this sort of comes down to what I was talking about, like sort of the dynamic availability or the, this could be happening at different

rates you can have the same model that's here nested at different speeds let's not use it with temporal rates of recursion i.e there's the general idea that someone come in they go to the cafe they chose to go to a part of the cafe these might be happening over 10 20 seconds

they make a choice of where they are there may be something about people leaving the cafe from certain areas over the period of 10 minutes but there's also like i'm walking towards a cafe and i can be making choices i can be making a an intuition about what affordances to stay or move do i go in the cafes or go to the park and i i can be

thinking about it, I can turn, I can change my position, I could be flipping and flopping, actually, maybe once every half a second over a period of maybe 10 seconds.

And then once I walk through the door and I'm in the queue, I'm pretty much like in, I'm going to be staying for a while, right?

So now I'm in the rate, so the rate at which the same idea of the affordance is being used could be now happening at a slightly different nested

speed right because okay if i'll maybe choose i'm in here now am i going to stay for a minute or not i'll sit down and then it's like i'm getting into a good conversation am i going to stay for 10 minutes and they're different but they're the same in some ways so they're different chronos


SPEAKER_03:
But there's a kairos that links the timeliness together.

And that's why categorical cybernetics and event-oriented cognition like Martin Booth's recent guest stream, the event is I'm ordering.

There's a beginning and an end to that.

Now within that matrix or within that event context, it could be playing out at a second by second.

but then in a different event context, it can be a different model.

And the higher level is which context am I in?

What is the event?

So that I think will go a very long way towards going from like that kind of autoethnographic narrative

of like, I was jangling and I was moving my elbows.

So maybe in that event context, you do have the model.

Like I was getting a taxi.

Maybe that has a different spatial temporal scale, different set of affordances.

And then for our model, not for the real world, which isn't changing, but then in our model, we say, okay, once you're in the taxi, the event is in taxi.

And we're only going to look at block by block.

Or then we slow the model down in the simulation or something like that when the event context changes.

And then we're doing inference at the higher level on which event context we're in.

So we would have a way to talk about that and iterate and include all the richness in the sub matrices and pull back to the coarse grain when we have to do that.

Dean?


SPEAKER_01:
This is fantastic because it's really helping me.

I hope it's helping everybody else that's watching and participating.

So again, what I'm hearing is a very clear line being drawn between something what we might describe as goal-directed behavior and the relationship that we're trying to proscribe in three tables.

And it's the relationship between those three tables as opposed to a specific outcome which we, in our minds, say we want to achieve or realize or recapitulate versus building out a relationship through support, through serving,

through contribution.

But that is not a goal.

That stays on the relational level, never to collapse underneath that.

Out of that pops out these goals that can be directed behaviorally.

But if I'm

If I'm misinterpreting this or am I laying something over this that reconfirms my biases, push back on this.

But I think what we continue to do is reinforce the difference between what we're doing here in terms of a model and what effects that can potentiate versus a model that has a specific and idealized and a particular outcome.

Am I overstepping or overreaching?


SPEAKER_03:
No, thanks for sharing how you see it.

I think the only piece I caught on is goal isn't an act in fontology.

We have preferences and expectations and then we adjust, we trim tab so that we realize those observations.

And so it's like, I want to be under the finish line at the four minute and 52nd mile.

That's the observation I want.

Not my goal is to run a 450 mile.

So then there's actually policy selection, how you get there.

And this is from a paper that I'll release very, very soon.

Here's just a re-visualization of the POMDP that we've seen many times.

It's a little bit adapted from the mental action Sanford Smith paper and a few other sources.

But basically we have this discrete time POMDP.

And then we have C, the preferences.

E, the affordances, the possible policies that can be taken, and G, which is the expected free energy calculation.

That's the minimization component.

Those play into pi.

Pi influences B, which is the state transition mapping of underlying hidden states.

In our model, that was where one is inferred to be, but not what they're observing.

B is only changing how states transfer to each other.

A, which we had as the sense mapping matrix, is mapping from the observations, which were photons, emitted by the generative process, the niche.

A is intermediating between the photon and the inference on where you are.

Sometimes it's really obvious.

If it's dark, you're not in the cafe or the park.

If it's red, you're more likely to be in the cafe.

You used to be totally likely, but now you're pretty sure because we added that red light to the park.

And then there's uncertainty estimates, which can be fixed or learnt on all of those.

And this is not the only model architecture.

This is a model architecture that we're using to integrate perception, cognition, and action and impact service contribution.

Steven?


SPEAKER_04:
Yeah, thanks, Daniel.

This is really helpful.

Talking about these three, the relating, so as the model is at the moment, the top affordance matrix, which gives the policy options, it's giving us sort of the states, the possible choices, so it's fairly set.

But those, the sense mapping and the preference matrix,

you could put temperature into that, or you could put variation of how much.

So for instance, at certain scales, generally speaking, the room was red when I went to the cafe.

When you're in the cafe and the lights, maybe the sun goes behind the cloud, comes out again, maybe...

in difference, there's different rates at which that can be fluctuating a little bit, maybe my preferences, as I'm starting to think about what I like in cafes in general, and then I'm saying, Well, you know what, I actually quite like it in the sun, right?

So but what this does, but even within this model, is you know, you could start to

not only change the values, but you could change how much the values either just by temperature or noise fluctuate, or maybe there's a temporal oscillation.

Maybe you say, okay, this one has the ability to change within its parameters over

five second period or over a five minute period or it's happening below perception you know there's a because we're circadian so you could say okay maybe someone doesn't notice there's a dark part of the room because it's just one table in the corner right so there's something nice about even within this model you've got the ability to to start to get this nested hierarchy


SPEAKER_03:
Yeah.

Like if you have uncertainty and you allow the parameters to be learnable in your model, not debating whether people actually are learning, just we're going to test two models, one where they cannot learn the mapping, one where they can learn the mapping, or we're going to test one where it's just visual versus a scent.

It might smell like coffee more outside in the park than in the cafe because that's where they vent.

Right.

So that could be learnt and understood and somebody at the first pass, oh, of course it's going to smell more like coffee in the cafe.

It might not.

So it doesn't have to be the direction people expect.

It can be included in the prior D. That was the only letter that didn't mention was that's how you get to the first state in the Markov chain.

is with the prior.

And so you could have high uncertainty over a prior.

Just say like, I don't know where I am and I'm very uncertain.

Or I'm certain I don't know where I am.

Or any other number of combinations.

And then,

The Bayesian information criterion, just to add like one more little technical note.

So the BIC, it's related to the AIC, but the BIC, it's basically, it's a value, BIC, is going to be something related to the number of parameters.

That's the K term.

That's the number of parameters times the natural log of the number of data points.

So that's like, are you fitting 50 parameters on one data point?

I mean, you can imagine that those are gonna be very poor estimates versus like one parameter on 50.

So then someone said, well, that one parameter, that's not the world.

Right, it's a model.

We're talking about statistical modeling minus two times the natural log of the likelihood function.

So this is like model complexity minus model accuracy.

So then we can say, okay, I'm testing three different affordance matrices.

one is the three by three one is a nine by nine because i've split each of the zones into three parts and there's like the window where it's very sunny and then a 50 50 and then a very red part and then i have another one where it's 500 by 500 and like the first 10 columns are the same because like they're all sunny and then the second one are all the same and they're very similar to the first 10. one can imagine that depending on what kind of data they have and how much data they have

they might find that the BIC for the 3x3, 9x9, or 9000x9000 model is supported.

And so that wouldn't be saying the territory is three by three, nine or 900.

It wouldn't even be saying that the map is three by three, nine by nine, 9,000.

It'd be like saying, this is a Pareto optimal, Bayes optimal statistical model that's on a frontier manifold between explaining variance while reducing model complexity.

So it's like,

That's the level above the map.

And that's where the BIC and model selection comes into play.

You don't just do the bottom up and then finish your model at the zero to one.

That's the iterating.

We could have a whole network or matrix of models and then have principled ways of selecting amongst them and adding a new data, designing counterfactuals.

What would be the most informative

data point to obtain?

Or what would be a perturbation that would distinguish these two different hypotheses?

Those are the kind of maximum information foraging questions because they amount to which policy as a modeler will reduce my uncertainty about dot, dot, dot.

That might be formalized in this meta XO model or it might not be.

but we can use like act-inf-quant as our kernel and then act-inf-qual as our wrapper, hashtag.coms.

Dave and then Steven.


SPEAKER_00:
Have activities of navigating among models at various scales and topologies as you've been describing, have those been observed adequately to tell


SPEAKER_03:
to what degree free energy is being minimized during that evolution that's a great question potentially for martin boots or for someone else um which is kind of the first principles unifying theory angle which we didn't even mention today in act inf would be like dis

could we have a common currency or could we understand actions selected in different contexts as being in the same game of reducing expected free energy?

So then could we look at, like we have the sub matrices within CAFE, PARC and neither.

And then like, we're looking at the fine scale transitions as a free energy minimizing process and the macro transition, and then looking at how like small and large changes in expected free energy are related to sort of micro and macro transitions in a hierarchical model.

Is that what you're asking?


SPEAKER_00:
Yeah, whether using this modeling framework

exhibits the kind of behavior that allows you to evaluate the free energy principle and its friends in play, in the real world.

And for one thing, are people just plain turning on data collection adequately?

Donald Knuth did that way decades ago when he was developing latex.

He turned on this massive data collection.

Everybody in his organization was feeding in...

Every key press was being captured, and then he ran metrics on that, and he says, well, this is where we're putting our attention.

I'm trying to make things easier, and I'm making them harder.

Well, that's wrong.

Let's start working.

And if he hadn't collected the data, he wouldn't have been able to give all those speeches about how it worked and how you study data.

the ecology of software development.

And this stuff is a lot cooler than anything that he ever did.


SPEAKER_03:
I think that we're moving from a zero to one to a continuous deployment of models landscape, which puts us squarely within the scope of Act-Inf.

Because we're no longer doing descriptive analysis, like how was this car made?

We're doing like continuous deployment on the ship of Theseus and that is gonna give a lot more information.

And then whatever information is collected, we'll respect that as being,

observations so whether we have every key press and every mouse movement and the pupil diameter and the eye gaze and the natural language processing on the live stream and and and all of those things it still would just be observations and let them debate whether it's all them ones that we need but then we'll specify our matrices we'll use bic we'll iterate with the real world

And yeah, I think that between the Git commits and the language use and the absolute accuracy or validity of the model, there would be quite some interesting patterns to see.

Like does, as the accuracy versus Git commits, do you like go really fast up and then dip and then recover accuracy?

Do you have a prolonged period of low accuracy followed by like a phase transition was like, oh, once we added in the sense of smell, it just was like, whoa, then it fit.

Or is it like some other dynamic or how does that relate to the language use?

How does it relate to the saliva, cortisol, metabolite?

Like there's no end to what you could bring into the model because they're just observations.

and then the relationships amongst different kinds of observations is something that's learnt and we'll use the BIC and related techniques like Bayesian model reduction and structure learning, which Friston pointed to as the key open problem in the dot tools section of our June 21 symposium.

Structure learning is how you go from just proposing variance on matrices and exploding your model space

to actually finding models that are on that frontier of being useful.

So very interesting question, Dave.

Thank you, Stephen.

And then closing round of thoughts.

Brilliant.


SPEAKER_04:
So I was just seeing that that was really helpful to have this diagram here.

So you've got preferences and affordances for action straddling, you can see my hands, straddling the free energy, which is coming from all the sensory kind of

interpretation so to speak and one question i've got is you know you've got uncertainties there and i know this is just purely more from an instrumental kind of

practical point is as it importance is at the moment there that's kind of like i suppose you could have a big matrix and the uncertainties could be flipped they flip on and off what's available you know it's like you can move you can't move you have to stay right maybe at some point you've got no choice you've got to stay right um whereas in the other ones they're numbers so it could be you could vary them so you you would try and change you would you would treat those matrices slightly differently right because the other one you're either switching on and off

options for what you could do and down lower down you could do something to change that number between either zero and one or whatever so yeah just wondering what your thoughts are on that yes so this is just one architecture and one representation so i'll be totally open to being wrong on these points but i'll just bring up what i think is interesting about that


SPEAKER_03:
Notice that the uncertainty is on A, not O. So you could say, my thermometer says 22.2, but I don't know how that maps to the real temperature because it's a noisy thermometer.

That's zero ambiguity about the thermometer.

But if you say, I'm not even sure what the thermometer says, it's 20 something,

Then you need another model with what is the visual observation mapping to the thermometer reading, mapping to the temperature.

So uncertainty, that's just one interesting point is it's not connected to O. But of course we have uncertainty about what we're seeing as a blur, right?

But if you don't even know if you saw it or not,

you're even another level removed.

So you could be uncertain about the mapping from whatever the thermometer says to temperature.

The extreme case being you're so uncertain about the mapping of A that even when you visually see it says 22, you're just like, I literally got no information on the real temp.

Or it could be a tight mapping.

But that's one thing that doesn't have an uncertainty associated with it.

And again, not that it couldn't, it's just that maybe it doesn't need to.

And then the other one is,

As you pointed out, there's no uncertainty over pi.

That I find quite interesting.

And I think the reason why is we're not doing inference on pi.

We're conditioning all of our analysis, conditioning our free energy calculation horizontal line on pi.

So we're saying there's three options and I'm conditioning the expected free energy of one, two, or three conditioned on selecting one, two, or three.

So it is a little bit of a different variable and also action is not in this.

It's implicitly in there because the B matrix, which we can have uncertainty on in how the B matrix, how policies map to B and how B maps to states.

So a technical phrasing would have to clarify, like, you know what, I drew the red line here to the middle of the edge.

Is that an uncertainty on the mapping of pi to b, or is that a mapping on... So it's not a technical claim, it's a visual artifact, but I think it might be possible to have no uncertainty on observation and no uncertainty on policy.

And that could just compress the computational complexity

by a huge amount and all the other ambiguity could actually be like very nicely dealt with elsewhere.

But if it's like, I'm just thinking of other examples.

People can probably imagine.

If there's uncertainty on what policy you're conditioning on, I think the analysis starts to lose sense.

Like conditioned on left or right, am I going to get the food?

That makes sense.

Conditioned on, I'm not sure if I'm going left or right, I don't see how there could be anything other than you don't know.

It's not a conditional, so you can't get a marginal likelihood from a Bayesian perspective.

So yeah, Stephen, yeah, last.


SPEAKER_04:
Yeah, the last point, I suppose it's one of those, it's that question saying, just do it type of thing, isn't it?

With the policy, it's like, you've got the option of just doing it, right?

So you say like, okay, I'm just going to do it and run with it.

So I don't, the benefit of actually then going and starting to tweak it all the time and put, like, you've got that all around it.

The point is, let's put it all around it and the conditionality, I think you just said, and then run it.

And then I suppose it is what it is.

And ultimately it's the best you've got.

So, you know, like if you're an organism, basically the policy you've got is the policy you've got

So you can go back and change your preferences because of what it did, but ultimately that's all you got.

So maybe you just have to sort of run with it.


SPEAKER_03:
And you'll either resist dissipation or not.

Dean, and then Dave, if you'd like a closing thought.


SPEAKER_01:
Yeah, so here's my closing thought.

So today we basically pulled out a material relationship on that slide.

We built it in real time.

and we were making a comparison to the materiality of a city state, I think.


SPEAKER_03:
To bring it back to the paper.


SPEAKER_01:
To bring it back to the paper.

No, I think this is really important because I actually support a lot of what Serval wrote.

And I also believe that what we were talking about was material generative models.

Out of that, there's a kind of a parallel to an iterative process.

All right, so even in the diagram that you have up here, this is confirming iteration.

So whether that iteration is in iterating, filling in a table versus it being blank, right?

There's an iteration process or the city grew from 12 buildings to 1200.

That's an iterative process or whatever.

We've got multiple confirmations of the fact that at scale, iteration is a thing.

It's a material thing.

What I'm going to go away from today's conversation, because I don't have the answer to this, but now I've got to think about this, is so when we move away from those things that fall out, those capitulations that fall out in terms of skyscrapers and

Nine by nines from three by threes.

Do we trust the map or the blueprint?

Or do we trust the process, meaning critical path, in the same material way?

Because I think in the point one, as you said, Daniel, we're just talking about zero to one right now.

But at some point we're gonna have to get past one and to get the real bootstrapping going.

And then the question is, do we have to now incorporate something to get outside of scale-free for that to make sense?

And that's gonna be my question to myself is, do we materialize the trust

in these models the same way as we materialize the model themselves.

That's going to be my, I'm going to go think about that for a few hours because that'll burn a few neurons for sure.

It'll go up in smoke.

But thank you for this because this was really helpful to me, like incredibly helpful.


SPEAKER_03:
Thanks.

You know, when I was in model stream one with Ryan and Christopher and they were going through it and so,

there are better people and will be better people to teach it and walk through it.

And there'll be a million ways to do it.

So it's a funny thing that it happened in 33.2, a funny thing happened on the way to 33.3, but yeah.

Dave, any last comments?


SPEAKER_00:
Yeah.

The question of uncertainty over policy is,

require needs a lot of reflection and study and i would suggest one thing to look at is what exactly is repression that's all i have to say for now yeah okay fellows thank you very much


SPEAKER_03:
Congrats to those who have listened to the end and you're always welcome to participate in Active Lab.

So thanks again and peace out.


SPEAKER_01:
Thanks, Daniel.


SPEAKER_03:
Bye.