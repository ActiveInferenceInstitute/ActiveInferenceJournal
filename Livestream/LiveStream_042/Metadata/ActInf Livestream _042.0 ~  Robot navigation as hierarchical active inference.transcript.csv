"Speaker Name","Start Time","End Time","Transcript"
"Speaker 1","00;00;27;02","00;01;01;22","All right. Hello and welcome to Active Livestream number 42.0. It's April 16th, 2022. Welcome to the Active Lab. We're a participatory online lab that is communicating, learning and practicing applied active inference. You can find us at the links on this slide. This is a recorded and an archived livestream, so please provide us feedback so we can improve our work all backgrounds and perspectives are welcome and we'll be following good video etiquette for livestreams and said Thanks a ton for joining us."
"Speaker 1","00;01;02;20","00;01;38;12","Really looking forward to this conversation. If you want to learn more about active live activities, check out Active Inference Board. OK, we're here in Active Livestream number 42.0 and we are starting to learn and discuss this paper robot navigation as hierarchical active inference in the journal Neural Networks October 2021 it's by ozone cattle timber Belgian tune Thunder Mallee Bart Dot and Adam Safran and some of whom we're looking forward to speaking with in the upcoming weeks."
"Speaker 1","00;01;38;28","00;02;14;17","And this video is an introduction for some of the ideas and just some background and context and rapidly assembled fun and memes that we'll go through. So it's just the introduction of a discussion and we hope that if you're watching live or later, that you can still contribute to this. And we're going to go over the main aims and claims of the paper, then the abstract and roadmap, and then walk through some cool keywords and context, which will be great to hear since perspective from working with robotics, which is an area that certainly I've never actually been involved in."
"Speaker 1","00;02;14;17","00;02;36;08","So going through some of the more applied work that we're going to see with robotics and also some of the more formal aspects from active inference. And then this third vector that maybe we both share, which is some of the biological basis of navigation. So we're going to just go into the introductions first I'm Daniel, I'm a researcher in California, and I'll pass to sit."
"Speaker 1","00;02;36;20","00;02;40;03","So Sid, I'll walk through your slides. But yes, let's hear it."
"Speaker 2","00;02;41;26","00;03;13;17","So let's go to Slide nine. And before I even address myself, I would say that we need to address the elephant in the room that this is Livestream number 42, which is one of my favorite numbers on the favorite number for a lot of people because it's the answer to life, universe and everything so this is the first time that I am like coming to an active inference livestream and I'm actively inferring the whole idea of active inference itself."
"Speaker 2","00;03;13;17","00;03;45;06","I'm very new to the field. So, so yeah, very excited to learn a lot of things and yeah, just as we are on this slide right now, 42 has a lot of other references that you can check out on that Wikipedia link. OK, moving to the next slide, I usually document like the many things that I've been up to this particular link, and in the next slide I highlight like the few places where I have had the fortune to be at."
"Speaker 2","00;03;45;06","00;04;32;18","So I formerly have studied computer science and design and I've like meandered by accident and by intention in a lot of different places that you can see here. So I studied computer science at a university in India which practices a lot of hands on experience, and that's where I got my start in robotics and a lot of other things then and then studied further and through various participatory workshops and internships, space organizations, media labs, and then spent two years at financial services to understand how money works and was introduced to robotics mostly through open source software in the bottom most thing that you see here, that's the Google Summer of Code program."
"Speaker 2","00;04;33;07","00;05;13;28","And I would go into more detail about how that robotic journey even started these days. I'm very much interested in how coordination happens and how we can think about security of like countries and communities in general and more importantly, all the emerging aspects of society. That's technology, economics, culture and policy. So I know that active inference is a study of autonomous behavior, and we are moving into this area of very decentralized and autonomous organizations are gaining a lot of popularity as well as like mainstream acceptance, increasingly."
"Speaker 2","00;05;13;28","00;05;40;01","So it's very interesting to see where this new field of study that's active inference that is a field that is invented in our lifetime. Like it's very rare to see that you get to explore a field that that is so recent and has a long history of like true connections to other fields. So it's definitely an evolving area which can help explore other evolving areas."
"Speaker 2","00;05;40;01","00;06;09;16","And that's what I find very fascinating about applying active inference in the way that it's applied in this paper as well. So I'll try to explain, like the history of robotics in a way through the lens of my experience with it. So one of the first things that I did when I started studying, so as you can see, I started studying in 2012 and immediately jumped in to like all the robotics labs that I could get my hands on and university."
"Speaker 2","00;06;09;23","00;06;48;07","And one of the first tasks that was very appealing to me was like multi robot teams, like how do teams operate that? Teams have been like a constant like fascination for me throughout life. Like human teams, teams of biological are organizing like organizations, organisms such as aunts and bees and then themes of like robots. And we derive a lot of like inspiration as well as a lot of like biomimicry kinds of techniques."
"Speaker 2","00;06;48;21","00;07;27;21","In multi robot exploration as well. So the specific topic that we were studying is in the next slide, which is multi robot terrain exploration so if we go to slide 13, these were the different like techniques we were studying like just like and leave pheromone trails on different signals for other members of their colony. We try to model these kinds of similar techniques like recency, like how recent was it that a robot that was covering a particular terrain that has been that hasn't been explored before, how recently was that covered?"
"Speaker 2","00;07;27;21","00;07;49;17","So you can imagine this as like a grid, so a two dimensional grid and you see the green squares. Those are the multi robot teams so the Green Square represents a robot and they are trying to explore and map out this entire area as a team. And the assumption is that they can communicate among themselves and in certain cases they cannot."
"Speaker 2","00;07;49;26","00;08;20;03","So the red squares represent obstacles and you will see a similar obstacle map in this paper which involves the use of their house. But we were using similar similarly configured different obstacle maps, both in a simulated environment as well. As a physical environment. So we explored different approaches back then, which is things like just representing them as an automator, like giving them very simple deterministic rules which they can follow."
"Speaker 2","00;08;20;10","00;08;43;19","And those could be imagined as simply as quandary as game of life, like the glider pattern or similar patterns that you might know. And then we moved on to more animal inspired or bio inspired techniques, which is a technique like recency in which the robot leaves pheromone trails in each square, and each square has like a countdown timer."
"Speaker 2","00;08;43;19","00;09;08;15","How recently was it visited by any other robot so this can be understood as ants, living trails which decay over time. And this gives other ants an idea of how to make a map that surrounding region effectively. And then there were very simple approaches which are more suited for the digital world, such as simply not counting that how many robots have visited this node before?"
"Speaker 2","00;09;08;15","00;09;36;11","So every time you visit any square, you just increase its count, visit count by one. So that helps the robots and understanding. OK, this area has been visited five times and the surrounding squares have only been visited two times. So I should maybe explore the unexplored regions first so these were different techniques that were used and we moved on, published a few papers and were also inspired by military organization and techniques."
"Speaker 2","00;09;36;25","00;10;01;14","The typical OODA loop or the Observe, Orient, Decide and Act, which is kind of applied act of inference in a way so we did we did explore that, like clustering approaches and different ways of conquering the whole map. So this was an exploration and exploitation problem that that I had like the opportunity to study in like second and third year."
"Speaker 2","00;10;01;24","00;10;29;15","So if my undergraduate computer science and then I went on to make fancier things thanks to the Google Summer of Code program. So this was a project with the Italian Mars Society, which reports to the European Space Agency. And here it's it was more about autonomous navigation, working with the human. So this was a robot and a human team working together and the next slide shows like how it actually happened."
"Speaker 2","00;10;29;22","00;10;56;17","So if we go to the next slide and play the video, we will see that that it is meant for an astronaut who is safe in a Martian habitat. And the robot is a rover which is exploring the Martian terrain outside in a more dangerous environment. So every moment of the rover comes from the astronauts movements which are mapped from an Omni directional treadmill that the astronaut is walking on."
"Speaker 2","00;10;56;25","00;11;29;08","And similarly, there is feedback received from the rover's camera which feeds into the astronauts virtual reality headset. So do note that this was back in 2015 when headsets were clunky and things moved very slowly. But Kinect was all very it's like mapping body movements, mapping like robot movements in an unexplored territory using 3D cameras, which is which is a technique that this paper also uses using our jib and kept cameras."
"Speaker 2","00;11;29;15","00;12;01;18","So those were the techniques which still are very popularly used even today. So this was my introduction to understanding how different like robot and human teams can work and how tele robotics and telepresence can work. So my responsibility in this project was to do the entire networking architecture and ensure that there's no latency or there's no feedback in which a robot can enter a dangerous state just because the astronaut did not receive the information on time."
"Speaker 2","00;12;01;26","00;12;27;23","So this is how we began. And the operating system that we used in that particular experiment is on Slide 16. So whenever the video is done, we can move to the next slide. So inside 16, you'll see a husky robot. So these are opensource robots that are very popularly used with the robot operating system, and we'll keep coming back to this particular framework of Rus."
"Speaker 2","00;12;27;27","00;13;01;21","So Rus became extremely popular. It gained its reputation from the earliest DARPA challenges in which very popular car they just crawled through through an entire desert terrain navigating autonomously. So Rus was an open source robotics library, which was built out of that. And you see many different sensors and actuators on this particular rover. So you'll see a lot of symbols which will be repeated in this particular paper, out paper as well."
"Speaker 2","00;13;01;29","00;13;31;18","So the task of a localization technique is to gather all these sensor inputs, fuze all those inputs so the sensors can be understood as AMU or like measurement units, inertial measurement units such as accelerometers and speed and all those measurement metrics. Then you have camera, which is similarly RG GB, that's red, green, blue colors of the visible spectrum."
"Speaker 2","00;13;32;12","00;13;53;23","And then you have 3D sensing in the in the sense of the Kinect sensor that you see on that particular robot and you would see a similar setup in this paper as well. They use a total bot to iRobot, which reveal which you will get into, which is also using graphs and it uses the same concept as we used in that particular paper."
"Speaker 2","00;13;53;29","00;14;36;07","So all these different attributes such as a 3D sensing Audiometry camera and IMU are inputs to the robot localization technique. And all of this together is meant to estimate the three dimensional surroundings of a particular robot. And all of these techniques do not use active inference. They used probabilistic methods, which we will slightly refer in the paper. So it's very promising to see that if we are inspired so much from biological ways of navigation, we should rather use a technique which like organisms have evolved to be so effective at like over so many years."
"Speaker 2","00;14;36;15","00;15;03;17","And as humans we're finding was considered a survival skill for a long, long time before we entered the era of Google Maps. And we just totally lost the technique of finding our way around rural, urban and natural settings. So wayfinding and navigation, localization and mapping was a technique which is very familiar to anyone in their seventies or eighties."
"Speaker 2","00;15;03;17","00;15;28;09","If you ask them, how would you find your way around a city block or the jungle they will have their own ways of navigating that. So they will either use natural cues like wind direction, the way the sun is setting the map that they have already covered, asking people around. So these kinds of techniques are built in our human brain."
"Speaker 2","00;15;28;09","00;15;49;07","And it's very natural for animals to use that as well in urban as well as their own natural environments. So this paper goes into these many big questions, which is in the next slide, slide number 17. So over to Daniel where he illustrates all these wonderful connections."
"Speaker 1","00;15;50;12","00;16;20;27","Said thanks for the innovation on the livestream format. A lot of fascinating background and it sets us up really well to discuss some of the big questions of this paper and some of the big questions in general. So one big question, just the kind of thing that would bring somebody to want to even read this 20, 21 paper or future work is how do biological like evolved and human created mathematical statistical and robotic."
"Speaker 1","00;16;21;05","00;16;47;28","So several different kinds of human created entities. How do biological and human created entities engage in actionable, tractable adaptive navigation in complex conditional and changing landscapes? And that's a question that one could ask about everything from the organismal level to the colony level, arguably also an organism, but in a little different way and all manner of biological systems."
"Speaker 1","00;16;48;10","00;17;22;04","And then here is a really nice slide from this Bill Ant Robotics project where they did a direct side to side of the Harvester Ant's Anatomy and also their robot's anatomy. And that's kind of like a bridge that takes us into a different space first with the walking around the warehouse. And does it does it stay standing when it gets pushed and can it localize when somebody turns off the light in the room in these sort of basic though still relatively advanced, but also relatively basic tasks and settings."
"Speaker 1","00;17;22;16","00;17;52;21","And then off on the right side here are some of the visions and representations that people use for when those low level activities are such that if a robot can resist being pushed over it, then how does that have complex feedback from society? So it was just something that you also impressed upon, like the very holistic nature of this area and also just how to keep a lot on the table talking about it."
"Speaker 1","00;17;52;21","00;17;55;12","So that's what will be fun to talk about. What do you think?"
"Speaker 2","00;17;55;25","00;18;14;16","Yeah, I think before we enter into the paper itself, I would want to understand from you, like what has been your learning from observing and behavior and studying their actions in such an environment like in natural as well as artificial environments?"
"Speaker 1","00;18;16;11","00;18;42;24","I can hopefully accurately relay an anecdote from my advisor, Professor Deborah Gordon, and she would often talk about how there would be at a conference or some type of competition. And this is something I've observed, but to a lesser small extent is there will be a presentation of an algorithm or a robotics implementation of so-called swarm algorithm or ant colony algorithm, ant colony optimization."
"Speaker 1","00;18;43;00","00;19;08;11","We see it on the pure optimization or computer only, but also a lot of bio inspired robotics design. And one common feature of these algorithms is that there's some like underlying map that shared like when you mentioned the grid counting, of course there has to be like a mesh network so that the robots kind of have basically either telepathy or some kind of common signal, even if it's asynchronous or something like that."
"Speaker 1","00;19;08;11","00;19;28;06","But there has to be some sort of like updating of the grid in their mind and being in the field and also drawing upon what we know about what we know about ants, the nest meat, when it's deciding to forage or not, it doesn't know how many seeds the colony has, how many seeds are out there, what the right decision would be."
"Speaker 1","00;19;28;15","00;19;57;21","So it must use stochastic interactions that it receives locally and cognitive constraints to make its decision. And then once it's out there, there's no telepathy among the ants, there's no queen control, there's no forager groups that all like tell each other orders and all of that. So that navigation is also multi-sensory and related to their cognitive constraints, but also their finesse in a certain niche in a harvester, ants is not going to forage well in the Arctic."
"Speaker 1","00;19;57;28","00;20;22;28","And so understanding how it's that interplay between the nest mate and the colony and the variable of the environment, it's a really rich area and it's easy to bring in other modalities that humans can use, like long range communication and understanding how those novel affordances for decentralized systems design do or don't relate to some of the ways that biological systems work."
"Speaker 1","00;20;23;05","00;20;27;07","That's a really fascinating area yeah."
"Speaker 2","00;20;27;20","00;21;02;15","And the reason I think that this paper is relevant, first of all, is because it's based on active inference, which is like the study of how the human brain would react in certain scenarios, but more broadly, how a biological organization like organism or an organized colony would react in those kinds of situations. And just like you said, the map may not be shared in certain cases the map theme might be decentralized, communication might be unavailable."
"Speaker 2","00;21;02;15","00;21;42;08","These are extremely realistic situations. Even for groups of robots today. So you can imagine these as robots who are exploring the fallout of a nuclear situation, like when a nuclear plant needs to undergo maintenance and humans cannot enter that area. So you cannot assume 100% communication when the robot is mapping out that area. So this is one of the important reasons why some amount of cognition and some amount of active inference of the terrain is extremely important."
"Speaker 2","00;21;42;08","00;22;12;18","And our infrastructure in robotics as well as communication is only now getting there. Like with the new standards introduced in 5G and six networks, we will start getting into like scenarios where robots become part of our daily lives and they already have. So I'm based in Singapore and it's very common to see cleaner robots and teams of like helper robots moving around like in university campuses as well as airports and shopping centers."
"Speaker 2","00;22;12;18","00;22;43;18","So these robots have covered their territory already. So they use very basic approaches of obstacle avoidance and trying to clean the entire area and complete their objectives. And there is very little stochastic action going on there because most of those tasks can be completed in a hard coded map that is shared among those robot teams in a very specific, highly connected environment."
"Speaker 2","00;22;43;24","00;22;58;01","But when we start moving into more urban environments where this cannot be guaranteed, we definitely need approaches like the one described in this paper. So yeah, but all that context, we can jump into the aims and claims of this paper."
"Speaker 1","00;22;59;04","00;23;27;21","Awesome. So just to read some of the aims and claims which we're going to revisit a bunch, the paper is robot navigation as hierarchical active inference, and some of their main claims were that they are going to first propose a hierarchical generative model casting navigation as minimizing expected variational free energy. So that is what brings all of these areas of navigation and robotics under the umbrella or drawing an edge to active inference framework."
"Speaker 1","00;23;28;10","00;24;01;02","We show how perception, localization, mapping and navigation naturally emerge from optimizing this hierarchical generative model under active inference. So that's sort of the theory and background and some of the formalisms that go through. Then they implement the system in silicone on a real world robot platform, navigating a warehouse environment, using camera sensor input only, and then they also have this third angle, not just the theoretical and the robotic implementation of that, but the biological."
"Speaker 1","00;24;01;02","00;24;10;26","And they relate their work to various findings and hypotheses in biology about navigation in the rodent and primate brain. OK, yeah."
"Speaker 2","00;24;12;12","00;24;43;11","I mean, these are wonderful claims. Before we jump into the claims, I was very fascinated by like the list of authors of the paper. So I'll just zoom into that a bit if that's visible on this slide. So, so you see that 33 of those authors are located in Belgium and the last author really fascinated me because they come from a center of psychedelic and consciousness research, which happens to be one of my favorite facilities in the entire world, focusing on these kinds of topics."
"Speaker 2","00;24;43;19","00;25;08;00","So I would also like to ask you that, how do these kinds of like multidisciplinary research like showed through in this particular paper? So obviously we have teams of engineers and researchers from Belgium, but we also have an author from a very different field. And how do you think that contributed in this paper."
"Speaker 1","00;25;09;09","00;25;41;27","That that'll be something great to ask them when they visit. But I think at the general level, we see several factors, including like of course shared interest, common framework in active inference. Also, I'm sure some want to point out in this specific case, but it's a great question and it's an important question. OK, so I'll read the abstract first half and then the first three."
"Speaker 1","00;25;42;08","00;26;23;26","Localization and mapping has long been a standing localization, and mapping has been a long standing area of research, both in neuroscience to understand how mammals navigate their environment as well as in robotics to enable autonomous mobile robots. In this paper, we treat navigation as inferring actions that minimize expected variation of free energy. Under a hierarchical generative model, we find that familiar concepts like perception, path integration, localization mapping naturally emerge from this active inference formulation moreover, we show that this model is consistent with models of hippocampal functions and can be implemented in silicone."
"Speaker 1","00;26;23;27","00;26;41;01","A real world robot. Our experiments illustrate that a robot equipped with our hierarchical model is able to generate topological consistent maps and correct navigation behavior is inferred when a goal location is provided, the system yeah."
"Speaker 2","00;26;41;04","00;27;12;19","I mean, that's a lot to get into. So yeah, I mean, so the paper makes a very simple claim. Like if you broadly look at the paper, it makes a very simple claim that active inference works and it's able to consistently reproduce maps which are representative of the physical world map. So this also goes into this literally goes into the map is not deterring kind of discussion that we have been having in active inference streams."
"Speaker 2","00;27;13;01","00;27;59;14","And in this case, they are able to consistently reproduce a particular kind of map that is a warehouse kind of a setting. And they compare it with many different approaches and there's many different tasks that you can see here. So the highlighted task so tell you that there's perception which is understanding the entire environment, then combining all the parts that can be taken from point A to point B and then localization, which is understanding your own position as a robot in that particular environment, and then mapping as you are doing all of these things simultaneously, localizing your position and state, as well as mapping the entire region while you're doing that."
"Speaker 2","00;27;59;14","00;28;29;01","And all of these are naturally emerging from like formulating it as like active inference, which is minimizing expected variation in free energy. So. So yeah, just before we go into more detail, do you want to explain the robotics researchers who might visit this livestream about why they should care about variation in free energy and probably these new words that that might be very important for them."
"Speaker 1","00;28;30;10","00;28;55;21","Nice. Thanks for that very clear summary. And definitely we hope that this kind of a presentation at least in the zero and also in the group discussions, it's like a two way street. So people are going to have different amounts of familiarity with some of the robotics as well as with the active inference so to anyone who's anywhere in that space, I think there's a lot to be said for just taking a first principles approach."
"Speaker 1","00;28;55;29","00;29;20;16","That's sort of a simplicity and elegance route. There's value to be found in transdisciplinary approaches like localization and mapping and cognitive affects and emotion. Some of the psycho logical frameworks that we've been discussing in other live streams or in other papers. And so there's value in not just simplicity, but in finding connections like complexity and patterns across systems."
"Speaker 1","00;29;21;01","00;29;48;13","And I think also for something that is clearly so nascent in its development to be able to, as it is describing, have some functional closure of maps and cast this problem of like where is one and how should one act and what is the bigger space map look like? And all those things which, as discussed in the real world, have all these other challenges like the communication of those maps and everything."
"Speaker 1","00;29;48;21","00;30;14;04","However, just at the individual wayfinding route, drawing on first principles from biology and being a part of that conversation that's clearly already functional, but also a lot of potential is probably a good thing to at least listen to OK, so how do they do that? Here's the roadmap. In the beginning they introduced the problem and some of the backgrounds, just like we've done in these last minutes."
"Speaker 1","00;30;14;19","00;30;43;14","They then discuss some biological perspectives on navigation. They then formulate in sections three and four the hierarchical active inference model for navigation. It's going to be a two layer model and we're going to go into it a lot and there'll be colors that are consistently associated with the levels they then discuss the experiments, which is the implementation, the robot embodiment of the robot, and then they have some discussion."
"Speaker 2","00;30;46;03","00;31;13;01","OK, yeah. Yeah. Before we enter into each of these specific topics, I would share what I had shared with Danielle a week ago when we started approaching this paper. So I mean, this paper is exceptionally well written even if you're not from any of these fields. So just looking at like the language that's used, it's very easy to follow for the most part."
"Speaker 2","00;31;13;01","00;31;36;23","And they make references to like topics which people will be familiar with. So they explain active inference, free energy, and all these different concepts of slam and very technical terms in an extremely simple language, which is why I think it's a great paper to start with. If you are new to either of these fields, robotics are active."
"Speaker 1","00;31;36;23","00;31;59;09","And it's very true because I know I was looking up a lot of robo citations, watching videos and learning a lot because it's just totally not my area. And I can imagine somebody with a different background would have a different experience. So it's I agree, an awesome written paper and it exists for anyone who wants to go into more detail and check out the citation networks."
"Speaker 1","00;31;59;09","00;32;21;19","If you're in the future, they listed several keywords. I could influence robot navigation, deep learning, slam simultaneous localization and mapping, and then Rat Slam, which is a biologic inspired version of Slam. So let's just go to your active inference meme. If you would like to give a real time meme reading, please feel free to."
"Speaker 2","00;32;23;03","00;32;53;24","Yeah. So the meme explains itself and this is essentially the teaching robots like as if you're teaching a child. And I think that is essentially what all kinds of learning techniques come down to. And there was another meme of like a toddler reading neural networks for babies, which is not in this presentation, but that meme essentially meant that a neural network is learning how neural networks work."
"Speaker 2","00;32;53;25","00;33;26;25","And so this meme is inspired by that, that in order to solve a particular purpose, you need to infer actively, which means you need to firstly be active. And that's the first condition. And the second condition is that you need to be constantly inferring like your own assumptions about the environment, about the observations that have transpired in the last few time steps, and then continue to do both these steps in a loop."
"Speaker 2","00;33;26;26","00;33;53;27","And in that combination of those two loops you are able to solve that purpose. So the meme is inspired from Rick and Morty in which the only sole purpose of that robot is to pass butter and in this case, that sole purpose of just implementing active inference in a robot is all that's needed to solve that particular task, and that is intended for the claim of the paper."
"Speaker 2","00;33;54;05","00;34;04;09","So that is why active inference as a whole I think is like all encompassing when it comes to make doing all the steps that we covered in the last seconds."
"Speaker 1","00;34;06;27","00;34;36;21","All only comment on what you said, because it's so true that as a holistic and composable model, it'd be possible to bring in different sensor modalities, different communication, connectivities, different actuator possibilities and active inference could grow in terms of how it's being used. So this is like a relative to some other possible algorithms which would have to be composed in a bit of an ad hoc or in principled way."
"Speaker 1","00;34;37;03","00;34;59;17","This is a way to explore just that that you and for actively could be for the robot in condition a or the robot in condition B depending on the generative model and the mark up like it and the external states in the world itself in the context. So let's just go straight into the meme analysis of this second video."
"Speaker 1","00;34;59;17","00;35;01;01","I mean, you have prepared."
"Speaker 2","00;35;02;12","00;35;27;21","Yeah, meme analysis is something new that might be unique for this livestream, at least in this animated format. And as you can see in this particular meme and in the previous meme that a robot has to forget all their existing slam techniques that robots have popularly used. So we go into many different techniques that are cited in the paper."
"Speaker 2","00;35;28;03","00;36;05;03","So one of those techniques is obviously rat slam, which we will go into next, but probabilistic robotics is like this popular book, this classical book, which was used by the robots of the last decade or two. And it describes many different approaches of how Slam can be implemented and all techniques that we see in conventional robots today, whether it's like a robot that's cleaning your house or a robot that's serving your food in one of those experimental restaurants, all of them use probabilistic robotics techniques."
"Speaker 2","00;36;05;12","00;36;40;09","And this meme in particular goes into firstly the mission of this entire participatory lab, which is act in fur. And so and once you do that, once you do all these three things as a robot, you're able to successfully navigate your way around these very confusing terrains, which might be complex and dynamic. And on the top you have a diagram which describes how deep learning methods typically work and how this paper implements one of those techniques with an active inference flavor on top of it."
"Speaker 2","00;36;40;18","00;36;54;23","So Dan, do you want to describe like how active inference on deep learning, like how this the combination of these two fields has come through in this paper sure."
"Speaker 1","00;36;54;23","00;37;21;03","First of all, I interpret to mean and then describe the deep learning, but then we'll get into more details as we actually walk through the paper so I see the the and first serve of active lab, which is open to anybody who wants to participate. And then it's a little bit like the experiment where people are passing basketballs to each other and then something unexpected crosses the screen and many people will not report seeing that other thing crossing the screen."
"Speaker 1","00;37;21;07","00;37;54;21","But there's a lot of analogies to other cognitive contexts. So it's like we're focused in the lab, but then also we have to be aware of the unknowns and the unexpected and the anomalies within the anomaly space. And then that's how we get to four, which is like the Tetrahedra, which is bigger than just us anyone. So how to be doing that nice, neat thing that we can juggle and three numbers in our head at once, or seven numbers in our head at once or can only grab two things at once or even fewer."
"Speaker 1","00;37;54;25","00;38;33;07","So how do we actually use these limitations that we have and be part of still a bigger navigation? So it's nice mean basically this paper is going to present a method that uses some model structures from active inference, but also uses some more mainstream deep learning and machine learning techniques. And those methods we'll talk about more like the specifics of how they're combined, but it contains both things that are like machine learning, neural network type approaches, as well as that being structured in an active inference way."
"Speaker 1","00;38;33;24","00;39;00;13","And that active inference structure, when it's just with simple matrices, can be looked at like in the model stream. One or in active inference, a step by step guide. That's the very simple matrix multiplication, very austere kernel of the active inference structuring and then here, because some of the data includes like video data and it's being implemented on modern hardware, it does have like a deep learning machine learning aspects and modules to it."
"Speaker 1","00;39;01;29","00;39;32;27","OK, so here's slam finally, finally the keywords. So researching it, I found this paper, are we ready for service robots and presenting a data set for Slam and on the bottom right, it's showing some different scenes as well as how they change. And the paper concludes that with respect to this challenge of simultaneous localization and mapping, that various factors can often confuse a robot."
"Speaker 1","00;39;33;04","00;40;04;20","And so one can imagine this is just like an algorithm that has a blind spot or some sort of area of poor performance for any number of reasons. And that's exactly how these authors begin the paper with being able to robustly explore and navigate an environment has been a longstanding challenge in robotics. So the paper just begins with what we've been talking about, which is that this is like a perennial and across system problem, but also in hashtag 2022, it's far from solved in real world settings."
"Speaker 1","00;40;05;14","00;40;06;11","Well, what else is yet?"
"Speaker 2","00;40;07;13","00;40;35;03","I mean, especially like like the title of the paper which describes why we are doing all of this. The title is Are We Ready for some of Robots? And in the previous meme we saw that the third pillar of the trifecta after Act and infer is so. So all the robots that that we are building and most of the applications that we focus on are meant to so that they have they have service as an objective function."
"Speaker 2","00;40;35;13","00;41;11;06","And that is what makes this task challenging because if you are replacing human actions by a robot, you have to forget all the assumptions we make when dealing with like human themes because human themes are dynamic and they learn on the fly. And obviously they might be as they might not be as effective as a robot who might be better evolved to or better suited to its architecture to consider, adapt and different different kinds of attributes in a changing environment."
"Speaker 2","00;41;11;25","00;41;41;15","But that that group organization poses a lot of challenges to traditional slam techniques, such as changing even one thing in that environment can make greatly modify what map the robot had made and you can imagine this as like there's a map and you had localized your position of with reference to particular objects in the map. And then you move those objects so the robot's world just shifted all around it literally."
"Speaker 2","00;41;41;22","00;42;17;10","And that that simple change might be very obvious for humans to detect but for a robot which is using those reference points to localize itself in the world and construct the map out of it, that is a big challenge in traditional Islam. Approaches. So. So yeah, many people who have tried to train a robot before it cleans their house by like driving the robot around in different rooms is very familiar with this particular problem that when you move a chair in between, the robot just completely forgets its entire sense of its surroundings."
"Speaker 2","00;42;17;19","00;42;22;09","So. So yeah, that's why I really like this reference. Yeah."
"Speaker 1","00;42;22;20","00;42;47;26","Yes. And that's going to come into play with the internally maintained hierarchical generative model that the robot has on board. And that may offer it some resilience against these kinds of changes. So that's why we're going this route at all. And one adjacent work that's discussed in the paper is Rat Slam. So I will play the videos and if you want to maybe describe or contextualize Rat Slam."
"Speaker 2","00;42;49;09","00;43;19;04","Yeah. So Rat Slam was this bio inspired technique which really solved such slam in a very simple manner, which is that you it could perform as effectively as other slam techniques which relied on like expensive equipment and replaced it with like a simple camera, which has imperfect information. So the video goes into it in a lot more detail and we'll cover it in the next slide as well."
"Speaker 2","00;43;19;23","00;43;39;28","But essentially it's a hippocampal model, which means that it models like a rat's brain and is able to like map the world and localize the robot that way. So I think the video is very self-explanatory. On the next video, we'll explain it even more about how the map is constructed."
"Speaker 1","00;43;40;09","00;43;42;29","So let's look at that one. OK, go for it."
"Speaker 1","00;43;45;04","00;43;47;05","So what is happening in this second video?"
"Speaker 2","00;43;48;10","00;44;09;17","Yeah, so the second video is one instance of Rat Slam, which is Open Rat Slam. So this was a code base that was released both for C++ as well as the Ross operating the robot operating system. And here you see this one particular robot called the rat robot mapping out an Australian environment, which is an urban environment that you see on the top."
"Speaker 2","00;44;09;17","00;44;38;15","Right. And you see the robot making specific circles around certain loops and making both exploration decisions along the boundaries as well. So this is very similar to how a rat or a biological organism would explore a particular territory. So all of this is being done with a single camera and that is the main like achievement of this particular piece of work."
"Speaker 2","00;44;38;24","00;45;10;28","So of through this paper you see that the inputs on the top right are mapped into the images that you see on the bottom right. And those simple images are what's being used to map out determinants. So to the human eye that that particular input is extremely blurry and not high fidelity enough to map out a terrain effectively but as this paper explores, it can very effectively do that even when we degrade the image quality by a lot."
"Speaker 2","00;45;11;08","00;45;31;29","So that is that is why rats lamb became very popular as cited reference in this paper because it's one of those bio inspired techniques which comes very close to active inference techniques that this paper goes into. So yeah, that's what this video covers and it explores different kinds of terrains, as you can see."
"Speaker 1","00;45;32;17","00;46;01;11","Awesome. So the paper in the introduction introduces the relevance of this necessity of the deep navigational functions that humans and other organisms have, but also that robots we would want to design having. That's the main theme here. If we learn from biology and bring action into robotic slam, we may be able to have a way to approach these questions."
"Speaker 1","00;46;02;08","00;46;27;04","And then they say, OK, well, how are we going to bring action into Slam? Because this is sort of the an activist insight that having the perfect map in one's head is like the knowing. But then the knowing how to act is not always trivial. Even with the most high resolution map, like one could know exactly every molecule of the car and still not know how it would fail in an environmental situation."
"Speaker 1","00;46;27;22","00;46;47;29","And that's what an activists and an activism gets at, which is like what if somebody doesn't have the digital twin model of where things are in their body? But actually the representation, if there even is one, is more about how the body should move or how one should act. So that's called the pragmatic turn or the in activist term."
"Speaker 1","00;46;48;13","00;47;12;29","And in the terms of cognitive science, that's the for e cognition. So even though that is about the richness of usually human cognition embedded in cultured, extended, et cetera, et cetera, it's interesting to again see that come into play with this discussion of robotics. Like what if there are cultural practices around movement in a space? How could that or be integrated into a robotics model?"
"Speaker 1","00;47;13;03","00;47;42;01","So there's a lot that goes with this taking serious of action selection as a real primary imperative, not just the hypothetical mapping. So they say, well, let's use active inference as a process theory of the brain that cast action as perception as two sides of the same coin. Not sure if it was action and perception, but still maybe it stands both ways and a process theory is just like a way that it gets done."
"Speaker 1","00;47;42;15","00;48;06;20","So how do organisms get it done or taking one step removed in the instrumental direction? How will we model organisms getting it done? And then people can debate about what organisms actually do, but this is like us actionable mapping that territory. In Section two, they introduce some neural correlates of navigation, which we're going to discuss in the next slide."
"Speaker 1","00;48;07;10","00;48;31;23","And in section three, they bring the question of navigation in terms of active inference. And so that's when they go from this hierarchical Bayesian generative model of localization again, and on one hand connected to the active inference framework, and on the other to this prior work on machine learning in robotics and that was also related to their previous paper."
"Speaker 1","00;48;31;23","00;48;43;29","So there are others, of course have previous work and there's related work to OK, so the H, E, G or anything others that I mean."
"Speaker 2","00;48;44;15","00;49;11;24","Yeah, in the introduction they raise two very important points before they start to go into the actual techniques they have implemented. So they say that humans easily explore and map their surroundings without much extra thought or considerations. Like intuitively, we build a logically consistent map without needing accurate distance measurements and we find it natural to think about navigation in terms of sequences of moves towards locations."
"Speaker 2","00;49;12;04","00;49;37;15","And when we are considering moving to that new location, humans typically do not consider lower level tasks such as opening doors or lifting feet. In this paper they go into like lower level tasks as well because those kinds of assumptions cannot be made for robots. And they also mention an interesting point, which is that the working of the human mapping and localization hasn't been thoroughly understood."
"Speaker 2","00;49;38;06","00;49;57;29","But the best models we have so far are present for rodent navigation, which is where rats, lam and other techniques can come from. So this like predicate, the work that goes on into this paper and how they model this as a multi-agent active inference task."
"Speaker 1","00;49;59;03","00;50;41;15","Right? So the H slushy system is the hippocampal slush and to write system and homologous brain regions are here shown for the mouse, the rodent, the macaque, which is a type of primate and the human and these brains are sort of aligned and shown so that one can see how these regions are evolutionarily related to one another. And then on the bottom are some examples of histology or tissue staining showing like kind of a cross section and a little bit more detail at the cellular level because as one might imagine, this has been studied and there's many, many copious numbers of like review papers."
"Speaker 1","00;50;41;15","00;51;32;01","And so it's like a whole thing how people have studied this like many others. But here is the citation that they provided in the paper, I believe, which was a bizarre paper about memory navigation and the theta in rhythm in the hippocampal and trial system. So suffice to say that the function of this coupling of brain regions has been modeled in some very fascinating and rich ways and trying to understand how the same brain regions in different functional ways can be integrating different aspects of softness and memory navigation way finding some of the complexities of how these different functions are related to each other anything to add on that?"
"Speaker 1","00;51;32;01","00;51;35;00","And then we'll look at how that has been addressed in the active inference framework."
"Speaker 2","00;51;36;19","00;52;19;21","Yeah. The only thing I would add is one particular image that will be used in this particular slide, which is look at the similarity between the tasks done by the hippocampus and the interaction system and the similar set of sensors on this particular robot. So we use extremely similar architectures to center ourselves in the world, which is we use sensors in the form of sensory organs and obviously ears and eyes and all these are sensors but all of that is computed in that particular region of the brain, which is considered the robot localization module in this particular robot."
"Speaker 2","00;52;20;01","00;52;24;17","So so yeah, that's what that analogy I find interesting."
"Speaker 1","00;52;25;14","00;53;01;11","Awesome. And that's with the action states in the sense states like just like the sensors in the actuate we could have two of the same kind or 50 of the same kind or 50 different kinds. And that's like the kind of multisensory fusion that's also interesting to think about and they write in the paper, we will ground the following discussion of the hippocampal and trial system in terms of its role in generalized search and navigation and the citation here is to this Kaplan And first in paper, we're not going to go over this model right now, but people could pause, look at the graphical model, go to the citation and we'll hear about it more"
"Speaker 1","00;53;01;11","00;53;28;26","from the authors. How did they build on prior work? All, all add here and I said, if you want to ask them is totally chill, would be they use a Bayesian graphical framework and we're going to see a lot of Bayesian graphical frameworks. The nodes, the circles represent statistical variables of different kinds and then the edges reflect the spar city of influence of connections."
"Speaker 1","00;53;28;26","00;53;54;15","Among those variables so like two variables that influence each other have arrows pointing between each other. And this is a Bayesian graph way that is sometimes used to represent models graphically that's kind of playing on graphical in two senses, like it's visual, it's graphical like a picture, but also it's a graph like a network. So it's something that is a representation of models at the intersection of those two senses of graphical."
"Speaker 1","00;53;54;20","00;54;17;20","And we use them a lot in active inference. And in this paper they made active inference models for navigation in search, and they overlaid it on some of the plausible neuroanatomy of the brain and some of the functions that those regions of the brain have been modeled or seen as performing great. OK, yeah."
"Speaker 1","00;54;19;29","00;55;02;27","The paper also on the biological section explores the grid cells, and we saw the grid cells also in rat slam. The grid cells are in the inter renal cortex, so it's in the H.E. system, and they represent a largely triangular or hexagonal tiling of space organized according to egocentric reference frames. Now it's hexagonal in the flat plane, but what shape is it in higher dimensions and the right that the regularity of these repeating grids provides a basis for path integration via estimating distances and location in terms of the direction and frequency with which this metro grid metro tiling is traversed."
"Speaker 1","00;55;03;24","00;55;22;29","And this was pretty interesting to hear how they framed it in physical domains. It has been observed that the spacing of gradient representations varies as a function of the space being titled, e.g. smaller and more fine grained. If an agent is situated within an enclosure or larger and more coarse grained if it is situated in an open space."
"Speaker 1","00;55;23;25","00;55;49;14","The granularity of tilings appears to be influenced by brainstem locomotor nuclei, potentially reflecting an inductive bias for greater speed being more likely in larger spaces, as well as by an external receptive stimulus such as optic flow. So it makes me think about driving at 70 miles per hour and it's like one still has this extended sense of mobility and well, I could make a left turn over that space and time scale."
"Speaker 1","00;55;49;21","00;56;09;27","And that's as natural feeling to somebody who's familiar with driving in a certain context as like I'm running at this speed and I could make a certain turn at a certain speed and then the optic flow reminds me of a great experiment with honeybees where they had them forage, but they had to go in and out through this long section where there was an alternating stripe pattern."
"Speaker 1","00;56;10;09","00;56;33;20","And so when the stripes were thick, like, let's just say a meter of dark and then a meter of light, then they would forage a certain distance and they would be able to do the waggle dance and communicate it to their nest mates. But then when that was replaced with a very fast alternating stripes, it increased what's known as optic flow, which is just the simple rate of change, like the frame, different seeing across the retina."
"Speaker 1","00;56;34;03","00;57;01;29","And the bees were foraging a shorter distance because it was like their estimates of optic flow were higher. And I think that speaks to also a point that Steven has raised in the chart, which is the information geometry versus information geography, and that could be connected to a lot of different other areas. So that's just something to think about with how is the actual space represented, how is the perceptual space represented?"
"Speaker 1","00;57;02;06","00;57;13;24","And the grid cells are something that people have modeled as being at the intersection there from a cognitive perspective and from a tissue perspective, anything to add?"
"Speaker 2","00;57;15;00","00;57;40;28","Yeah. So yeah, Stephan has raised a great point about the geography, and I think in humans and organisms, like arts and bees, it's more about survival. And that is why they like attach a different kind of a grid sizing for different kinds of terrains. And yeah, your description of driving in an open wide road is extremely accurate and so is the bees one."
"Speaker 2","00;57;41;06","00;58;21;23","And I think it comes down to minimizing error. Are they being more specific in constrained environments? So, so if their actions are as wide and as like broad ranging as an open environment that might be harmful for their objective function, which is not only make reaching from point A to point B in that small environment, but also makes survival like just banging into an obstacle if they are not being very specific about their grid size."
"Speaker 2","00;58;22;00","00;58;33;22","So so I think, yeah, it comes down to optic of optic flow as well as I think these survival functions which are like hidden state and like the models of all these agents."
"Speaker 1","00;58;35;05","00;59;12;19","Awesome. They move from the biological towards the formal by writing speculatively. If hippocampal pattern completion is inherently predictive or generative, in a Bayesian framework, then this could help to scaffold the development of more sophisticated predictive abilities for the rest of the brain. So I think this is a very deep area that'll be fun to explore in the conversations, but it's almost like you can bootstrap more complexity off of something that is already providing a more complex and oscillating signal."
"Speaker 1","00;59;13;03","00;59;42;02","So I think the richness of self and the place based ness and learn ability there is quite interesting to explore and they also note that there's ample evidence that spatial awareness is at the core of the mammal brain with explicit representation for Poe's heading and location so what I wanted to explore here in the discussions was location is the core of the mammal brain or cognitive functions in general or in insects two or something?"
"Speaker 1","00;59;42;08","01;00;06;21","No, it's olfaction. It's emotion. No, it's this. So where do some of these core functions fit and then they close the section by just writing, taking it from the introduction with robotics to the biological in section two. And then they say in the remainder of this paper, we will further build on these insights using a process theory of the brain deeply rooted in predictive processing, active inference."
"Speaker 1","01;00;06;28","01;00;24;02","So you'll note that other than our additional context, like we haven't gotten into active in the paper, but that's when they crossed the Rubicon. And from here on out we're going to be talking about the act of inference formalization anything else to as it yeah."
"Speaker 2","01;00;24;22","01;01;06;14","I mean, I really liked how you framed that particular importance that different kinds of organisms and like robots have to be assigned when, when we are dealing with like their objective functions, which is, is location like the most important state for them or are other senses more important? And if we are thinking about like self-driving cars and like evidently like Tesla is very particular on not using leider and like laser depth sensing technology, it's trying to just use our JGB depth cameras and trying to navigate the world."
"Speaker 2","01;01;06;14","01;01;35;20","And I think the same is true for Gamma, which is another open source self-driving toolkit. So these kinds of toolkits that exist for navigation in the physical world, they just rely on location and vibration as their only source of input and not other senses. So so yeah, it's interesting how you can modify the importance of these different attributes to achieve different tasks."
"Speaker 1","01;01;36;25","01;02;04;06","All right. So Intersection three navigation as hierarchical active inference. OK, so this is where active inference gets applied in the theory level and then it gets applied in another way when it becomes simulated and then it in another way when it becomes enacted, et cetera. So we cast the same problem in terms of hierarchical Bayesian generative model, the agent reasons on to different nested levels."
"Speaker 1","01;02;04;22","01;02;22;04","So there's going to be the use of a higher and lower to describe these two different ones. But one could use different spatial metaphors like inner or outer or whoever else on a higher level. But this is going to be consistent with the coloring and which one is placed above or below on a higher level for long term navigation."
"Speaker 1","01;02;22;11","01;02;45;15","And on a lower level for short term perception. On the higher level, the agents capable of reasoning in terms of sequences of location wants to visit. I want to go to the post office and then to the university and then back home without having to worry about the intricacies of how to control its readers to get there. Like I'm not overthinking the footsteps and how to cross the street on the lower level."
"Speaker 1","01;02;45;15","01;03;08;21","The agent can reason and plan in terms of observation sequences without needing to think too far ahead. Short term action selection plans based upon ongoing input. We will distinguish between the higher level and the lower level actuation by calling them moves M and actions A for the two higher and lower levels and the sensor readings like the visual input."
"Speaker 1","01;03;08;21","01;03;40;02","But other sensors could be added to at the lower level or called observations. And that's modeled with an oh. And that reminded me of the relationship between strategy and tactics in chess. Whereas in strategy there are more Harris sticks like control. The Center or the knight on the rim is grim because it has reduced mobility that doesn't actually suggest how to do it or what kind of a direct or oblique strategy would actually be realized in which way it just sort of like general ideas."
"Speaker 1","01;03;40;12","01;04;01;23","And then there's the tactical and the roll out and all of that in in the specifics of the situation, which cannot be really thought too far in advance because even just two or three in advance, the branching is so complex that it's not really useful all the time, although some brute force approaches have used that to great success."
"Speaker 1","01;04;01;23","01;04;21;11","And it may work in certain cases, but it's not a general strategy just to roll out tactics further and further and then hope that strategy just falls out of rollouts of tactics so I'm sure you'll have some thought on that. But how do you think that frames this as a multi skill statistical problem? And then it's going to be approach from this Bayesian active inference way?"
"Speaker 2","01;04;22;19","01;04;47;09","Yeah, I think it perfectly models it. So you add that strategy and tactics, I would only add objective objectives like as a third element to that. So objectives, strategy and tactics are like these different levels of tasks that people want to achieve. And this is not only true for the tasks that that you refer to like chess or other applications."
"Speaker 2","01;04;47;09","01;05;14;17","But also like when we go about in our own life, like our higher level task can not just be going to the post office but achieving some objective as a result of that which is I, I'm going to the post office because I might have received an admission letter from, from a university that has a higher level task on top of it, which is this has broader implications to my career or life in general."
"Speaker 2","01;05;14;24","01;05;44;07","So one person's or one robot strategy can be another robot's tactics it's the way you define moves and actions is totally arbitrary and dependent on like how reliable your sensors are. So I think the levels are the place where we draw the line between lower, higher or inner and outer levels are dependent on the sensors, which is the ground truth that we can reliably measure in that particular moment."
"Speaker 1","01;05;45;26","01;06;07;17","The only thing out there is that also, just as you said, where one robot strategies and others tactics, this nesting of Bayesian generative models can be three layers, it can be four layers, et cetera. So there's arbitrary design of these graphs. And we've seen like in metacognitive papers like act in five string number 25 on metacognition as mental action."
"Speaker 1","01;06;07;25","01;06;44;14","It actually is like action and perception all the way up, all the way down. So just because a layer isn't modeled, we have an interface for the unknown through the blankets that we do specify. OK, so let's look at it specifically on the left is figure one. It is the prototypical generative model of an active inference agent. As we discussed a little before, the nodes in the graphical model represent random variables where the gray color is indicating the observed variables so the observations are observed in gray and then the actions are also observed."
"Speaker 1","01;06;44;21","01;07;11;20","So one could complicate this assumption, but we're assuming that like if the robot is hitting the gas that it knows that it's actually doing that motion in observation. At the current time, step o sub t is generated by the hidden state s, so it has the white node. So it is not directly observed, but it's like a parameter in a model, the generative model of the robot, which in turn is generated by the previous hidden state and action at time steps T -1."
"Speaker 1","01;07;11;25","01;07;36;13","So it's like here's s in the past and it's marching forward and then it's influenced by its prior states, as well as by how actions influence states if at all. And future states and observations depend on future actions which are determined or not completely determined, but but have a statistical relationship with the policy PI and Policy PI is sequences of actions."
"Speaker 1","01;07;36;20","01;08;15;12","If one has a policy depth of one, then the action at the next time step in the policy are the same inference. But when we have a horizon of planning that's deeper than one, it means that policies are actually sequences of action. And that's part of the complexity of cybernetics and so on. And on the right, I have a little bit cut this generative model into a grid so the now time step is the action that we took in the past, the hidden state inference at that time unobserved and the real time observation and then the left to right is the past time step, the now time step, the next time step, and then just"
"Speaker 1","01;08;15;12","01;08;34;28","deep future time steps whatever the horizon of planning is. And this is a discrete time model. There's also continuous time active and active inference models, and they can be used together, but it's not in this paper. And at the top is policy selection. And there's a lot of cognitive apparatus that might connect to this pie, but that's also not modeled here."
"Speaker 1","01;08;36;04","01;08;59;00","Actions selection is these A's, and those are just your actions through time. I moved E to a four and then an F three, and then the hidden states are whatever the hidden states are that are being tracked as being influenced or related to policy selections via action, and then hidden states in observations. And that's what makes it a partially observed Markov process."
"Speaker 1","01;08;59;10","01;09;18;19","And then because it's a policy variable that's being modeled here, it's a partially observed Markov decision process because it's not just the mark of process inference, it's also having action as a parameter that's planning US inference anything to add on one?"
"Speaker 2","01;09;20;02","01;10;01;02","Yeah. I think adding the grid really helps simplify the different steps that the agent has to take and how it's composable with different policies that might connect from different objectives. So so we had observed and unobserved, I think the more important key pieces here, which is which again, can be have like which can have different probabilities because as you go through through deeper layers, you can consider the previous layers, observation, previous layers, unobserved state to be your current layers observed state."
"Speaker 2","01;10;01;09","01;10;10;18","So it depends on how much probability you assign to make the strength of that particular observation. And yeah."
"Speaker 1","01;10;12;20","01;10;29;16","One last thing, which is the observations in the future are unobserved. So just to note that there's a difference between the past and the future. And one could also imagine that maybe there's a forgetting or something like that, but that's a very key difference. Is that the same type of variable like actions are unobserved in future? We can't say, well, we'll make these three moves."
"Speaker 1","01;10;29;16","01;10;51;25","It's like, but what if another chess piece blocks that specific move? Well, that would be dumb of them to do, but would it? So that's part of the complexity of strategy. So figure two is where they go from this single layer model. This is kind of the kernel of the model, and they're going to introduce a slightly more complicated graphical model."
"Speaker 1","01;10;52;07","01;11;18;24","This is going to specifically cast navigation as a hierarchical generative model for active inference. And so the lower level is this again, more tactical or more local visual perception on the bottom filled in observations. That's the real time camera data coming in is one way to think about it. But another way to think about it is actually by looking at the arrow direction, it's being generated using some underlying states."
"Speaker 1","01;11;19;12","01;11;41;00","And then the actions at that lower level are also being observed in the past. And at the lower level highlight in blue models, entertaining beliefs about hidden states is that agents and the agents pose P, so here's the S and the P like each time step there's a hidden state. And suppose the hidden states are giving rise to the observations."
"Speaker 1","01;11;41;00","01;12;26;18","Oh, and then the hidden state. And those are influenced by the previous state. That's the arrow coming horizontally pose and action or the higher level model in the case of the initial states. And so here is like at each time step. So here we're like in this blue block with a T like at the faster model time step and then at the slower level there's an injection from this like slower click that shoots something in and then that influences the rest of this blue block and then it's carried forward and there's another injection like a slower timescale at that more strategic level and at the higher level highlighted red, the agent reasons about locations."
"Speaker 1","01;12;27;23","01;12;49;27","The next location is determined by executing the move on. M So here's the more slower updating movements like where one is in that map. And then this is the more fine grained action selection. What do you see in this figure yeah."
"Speaker 2","01;12;49;27","01;13;19;21","So yeah, it like it's a continuation of the previous figure and like the speed differences are what's interesting here, like the higher level being just a two step process. Whereas the lower figure has more involved actions involved. So so yeah, you see that observations exist in both these layers, but there's more depth of unobserved states in that particular linear."
"Speaker 1","01;13;22;06","01;13;45;17","I hope it now by filling in some formalisms related to this that we can put a little detail because there's a lot that can be said about this and I hope that we've been at least consistent in our descriptions, but we'll look forward to hearing from the authors on it. So they write in active inference Agent will infer beliefs over these hidden states based upon experience."
"Speaker 1","01;13;46;21","01;14;09;25","Looking back into the past observations those are the observations from the past that the computer has access to, as well as infer future actions through a process of minimizing variation or free energy. This is where they're going to introduce this free energy minimization as kind of like a model metric that helps do parameter selection, parameter optimization on this type of graph."
"Speaker 1","01;14;10;09","01;14;38;26","So we have some graphical structure, believe it or not, and it could look different. That does strategy and tactics. It's like the skeleton, but then the real challenge is to have the video data come in and to have the movement data actually modeled and to make that happen on limited hardware and so on. And so what they do is first describe that in terms of equations, and then they're going to talk a little bit later about like how the equations get adopted into using neural networks and actual cameras and sensors."
"Speaker 1","01;14;39;06","01;15;13;04","But this is just going to be still at the equation, level one from this graphical intuition about how to do strategy and tactics and how to have them modify each other into an analytical way of framing it. So P is the joint model of O as a PI. That's the observation is the video camera data that states hidden states at this layer and the actions and the policy different aspects of the past, present and future are modeled as sparsely connected."
"Speaker 1","01;15;13;04","01;15;38;01","So one could, believe it or not, that those are sparsely connected, so-called in reality, but in this model, there's actually quite sparse connectivity among variables, even though if if it's new to you, it might look like a circuit board or something, but relationship to the all versus all that, it could be connected. This is a quite sparse connectivity like this bottom left one doesn't influence this top right one, for example."
"Speaker 1","01;15;38;15","01;16;04;09","So factorization is a way that that spark city of the variables can be converted into a factor sized equation. So we have this joint distribution, which is like the ultimate panopticon distribution, but because they're so far city of connectivity, different parts of the model can be like partitioned out differently. So it's like this big joint model that gets separated into separate parts."
"Speaker 1","01;16;04;18","01;16;29;10","And each of those one can interpret as being like the distribution of that. So like there's the distribution of policies, the district over two policies or over continuous policies. Then there's the distribution of action states that are taken depending on the policy. So like given that I intended to move A than B, did I actually take A? Then there's the state underlying distribution in green hidden state."
"Speaker 1","01;16;29;10","01;17;00;11","So that's not directly observed. The blue is the distribution of observations conditioned on hidden states. That's like a Bayesian hidden Markov model. And then there's this relatively more complex and combinatorial term that is asking, well, how do states depend on past states and actions? And then how do actions actually depend on policy decisions? And how do the observations in the future depend on the hidden states in the future?"
"Speaker 1","01;17;01;17","01;17;20;24","So it's taking this joint model and breaking it down into a few different pieces that as we'll see, can be simplified. And that makes this problem tractable in a way that just the all by all non-factor ized non-factor Isabel model is much more difficult to fit yeah."
"Speaker 2","01;17;21;02","01;17;52;17","Absolutely. And you have this this goes into like the practical implementation of how such a thing can be done and the interesting factor in this formula for me is like the community breakdown, which takes in the previous states and multiplies it with the current state and like this is one of the ways active inference can be modeled. And I think in previous life streams there might be different implementations of the same framework always."
"Speaker 2","01;17;52;17","01;18;00;09","And they are used in many different like formulation arrangements great point."
"Speaker 1","01;18;00;09","01;18;33;07","Yes, though there are some differences in notation across papers. There is hopefully more coherence than not. So knowing this framework helps one to understand active inference domain different domain models. OK, so how is free energy going to be used to fit this model both on the sort of perception as inference side? So that's the part of the model on the bottom that's more like a what is my pose given the visual input and what actions should I take in the short term?"
"Speaker 1","01;18;33;26","01;19;00;06","And this deeper, more navigational layer in the red, how are those going to be reconciled and parameter ized, which includes action selection and policy selection? How's that going to be parameter ised using a single criterion? So they use the variation of free energy and it's calculated up to the current step t so variation of free energy as contrasted, which we'll get to with expected free energy variation."
"Speaker 1","01;19;00;07","01;19;21;06","Free energy is like the parts that are observable are easier to calculate over. One can imagine so that's the variation of free energy. And the expected free energy is going to have continuity with the variation of free energy, but it's going to introduce this complexity of calculate expected free energy use about unobserved observations and actions. But they're similar."
"Speaker 1","01;19;21;06","01;19;53;05","But it goes like from first variation. Free energy is looking back and that's the more perceptual component. And then there's a deeper expected component once a time horizon is considered. So we can go into this more with the authors. But briefly in the first light f this variation of free energy is being defined as the expectation. That's the fancy of the difference between the Q distribution, which is the variational distribution that's under the control of the experimenter of the robot."
"Speaker 1","01;19;53;05","01;20;28;11","And that's like a simplified distribution in family. So just like fitting a linear model can be done, even if the data are super nonlinear and you're totally misled, fitting a linear model can be quite fast or fitting just a parabolic model can be quite fast. So if you constrain what model family you're willing to use for. Q Though there are still some quite expressive families that are also tractable, then you can try to minimize the expectation of the difference between the distribution that you're controlling and this distribution that you'd like to know that's going to help you go a long way towards doing policy selection."
"Speaker 1","01;20;29;14","01;20;49;22","This expectation can be rewritten using a K.L. divergence and that can also be rephrased as a difference between a tail divergence and another expectation. We can go more into this with the authors, and I think that will be great to hear their explanation. But for now, I just want to leave it at that level of detail."
"Speaker 2","01;20;51;28","01;21;23;24","Yeah, I agree. And I mean, the broader point that I see from this particular framing is like you're presenting it in terms of divergent design and evidence, and this is how not only they use it for their experimental setting, but this is how the actual free energy model will be implemented in real life. Situation as well, in which the first stone which is in their control, may not be in their control when the robot is in a dynamic environment like that."
"Speaker 2","01;21;23;26","01;21;36;28","So in this particular paper, in a warehouse environment, this kind of a framing makes perfect sense. But when the setting might be different, the framing might also need to reflect that bias."
"Speaker 1","01;21;36;29","01;22;03;02","And also there's that complexity minus accuracy interpretation. Yeah, OK, so here's where they move from the very free energy F to the expected free energy G. So they write crucially in active inference, the agent will not only optimize its generative model by minimizing F for past observations. In addition, the agent will also select actions that it believes will minimize its future surprise however, future observations are not available."
"Speaker 1","01;22;03;16","01;22;20;29","The free energy F cannot be computed, and the expected free energy G is used instead to compare the effect of various policies or actions in relation to the goal of reaching the preferred state. So wouldn't it be simple if we could just infer how the map looked in the past and then make decisions based upon how the map looked in the past?"
"Speaker 1","01;22;21;05","01;22;53;29","But that opens up to all these basically failures of function in changing environments. G in formalism three is a sum across over a given time horizon. T So the expected free energy g of PY and t policy and time for a given certain policy py and time step t in the future is defined as and this is going to be another set of formalism, but we can just pull back and remind ourselves of that sentence from the introduction."
"Speaker 1","01;22;54;03","01;23;21;11","Active inference is a process theory of the brain that casts action as perception as two sides of the same coin. So variation or free energy, which is more perceptual like because it's looking in past observed states and then g, which is going to introduce the uncertainty of action in an uncertain future. How an f, how are F and g similar or different how are they being cast as two sides of the same coin?"
"Speaker 1","01;23;22;04","01;23;44;05","How through the presence are those two processes being reconciled because time step five from now is going to be like Now then? So how will we have continuity in dealing with certain moments like now? But then there's things that we're uncertain about in the past and the presence and the future, and they're all very, quite different kinds and they have different relationships to past actions."
"Speaker 1","01;23;44;12","01;24;05;23","And that's like the blockchain angle. You can't change the past you can change your interpretation of the past, but then there's a different kind of variability or openness in inferences about the future. So these are great questions to learn about and think about how are F and G similar and different? What is variation of free energy? What is expected free energy?"
"Speaker 1","01;24;06;04","01;24;41;07","What is free energy of the expected future, which very much at all have introduced? And what other kinds of representations of this nexus are relevant to think about? Because these cited papers and shown equations do not exhaust the richness of that setting, but it's awesome how they pulled back to just this. It's a function g of what you do py and what horizon you're considering it over tao and then implicitly how you think about all of that and how you think about that."
"Speaker 1","01;24;41;21","01;24;54;19","So they both pulled out to a level that I think will provide a lot more discussion. But also we have to get specific in order for that robot to be in the warehouse yeah."
"Speaker 2","01;24;55;11","01;25;25;05","And the only fascinating observation for me, like obviously there's a there's a lot in this slide because this is the entire model. This is the crux of the entire calculation where you have variation in free energy and the expected free energy. And you see the similarity between both these forms, labor divergence and log evidence as mentioned. And then complexity and accuracy are domes of that formula."
"Speaker 2","01;25;25;05","01;25;53;25","And eventually it comes down to risk and ambiguity in the expected free energy formula. When all the probabilities are given a certain policy and on a particular time horizon, so which is represented by THAL. So these films like divergence, complexity, risk are like in one bucket and log evidence, accuracy and ambiguity are make in the same similar category."
"Speaker 2","01;25;53;25","01;25;56;06","And those two aren't really awesome."
"Speaker 1","01;25;56;28","01;26;17;28","I think we will as we expect the unexpected will start to actually accelerate through because the goal of the DART zero is really to set a lot of that context because that is what brings one to the trailhead so to speak, for a lot of the details that are going to present and of course the accuracy of their experiments and the implications and everything like that."
"Speaker 1","01;26;18;14","01;26;51;17","So we're just going to sort of continue on knowing that that getting there is getting quite a far way with this paper and then we're going to go slightly faster through many other aspects of the paper, just like give it a first pass. So here in Formalism five, they are casting P of PI the distribution of policies as a soft mark sigma of the free energy on policy and this temperature parameter of gamma."
"Speaker 1","01;26;52;25","01;27;28;17","This is casting planning as an inference problem which allows one to go from like the relative free energies of different policies to a decision on those policies. And when there's high temperature, it's like the pie chart is made, but one is still just picking from the different policies as if they had relatively more equal PIs. Whereas when the temperature's low like absolute zero, then one is selecting the best policy like more than it should be expected in a way and so that Gamma reflects the confidence that the agent has and current beliefs over policies."
"Speaker 1","01;27;28;17","01;27;49;03","So when there's a lot of confidence, then the most the best expected policy selected always when there's low confidence, then it's not taken into account as much. And that's, of course, the fun to think about in the context of like expecting the unexpected. I think I can, I think I can. And then it says on the bottom, right, no one had the heart to tell him he was going the wrong way."
"Speaker 1","01;27;49;17","01;28;04;26","So one can think they can and be acting consistent with their model and going the wrong way relative to what. So there's a lot again there that connects like the math to some broader questions. That we all have. What do you think."
"Speaker 2","01;28;07;00","01;28;14;18","Yeah, totally agree. And the meme really brings the point home. So yeah, let's, let's go to the next one."
"Speaker 1","01;28;14;29","01;28;51;11","And in 37 livestream number 37 people can read about this dual interpretation of preferences and expectations and about how they co realize each other so section 3.2, they move to the hierarchical generative model for navigation. And here it's the same higher and lower model with blue at the lower time scale read at the higher level. And it's going to be basically as we spent more time on previously but just applied to this multi skill navigation problem where it was being approached a little bit more abstractly before."
"Speaker 1","01;28;51;22","01;29;20;07","So in Formalism six, they're going to have their big joint Model B, all the things that one would want to know in this whole nested model. That's why previously when we saw the P distribution, there was only four variables because it was considered like just a more simple kernel layer and this is writing it out for the whole nested model where there's actions and moves."
"Speaker 1","01;29;20;21","01;30;03;16","So moves across these two layers being jointly considered and then it's going to be like this multiplication between the lower level distribution and the higher level distribution because it can be factor ized across these two levels because they're sparsely connected because of how it was designed. So that simplification takes like sort of an all by all model and just at this level that corresponds graphically to the sparse connectivity allows those two to kind of twist a little bit independently from each other, yet also containing a common basis in this joint distribution anything that."
"Speaker 2","01;30;04;23","01;30;11;11","Not I think this will be clarified further in the next slide, which goes into global policy selection. All right."
"Speaker 1","01;30;11;28","01;30;43;19","So in the higher level read, the global policy is emitted. Every move is treated independent of each other. This hierarchical arrangement allows the systems of reason about its environment further ahead, both temporally and spatially. And so then they take this joint distribution and it gets broken down into these three terms. From Formalism. Seven, we can see the generative model decomposes into terms for both the lower level dynamics blue, i.e. how actions influence the next state and post."
"Speaker 1","01;30;44;05","01;30;57;02","So we broke the blue out from the red. And then there's this other term which we can talk about from the joint distribution what do you think yeah."
"Speaker 2","01;30;57;20","01;31;18;25","Yeah, I think the this is where it comes to expressing it. Thumbs up G, which was the expected free energy. And we see those terms repeat here. And I think this is, I think the most important formula of this paper in which the global policy selection happens in the higher level. Yeah."
"Speaker 1","01;31;20;00","01;31;47;07","OK, so as we saw before with a simpler version, first, there is a decomposing SSION on P, there's a factorization on a P distribution. We saw this for like with a simpler P here. They then got turned into an F energy. Here we have a more full feature. P is also going to be turned into an F, which is the variation of free energy and then a G."
"Speaker 1","01;31;47;23","01;32;23;14","So this is F of the hierarchical model. They write now that we fully specified our generative model that was P, the factories to joint distribution, we again turn to Variational F and then later the expected G free energy that will be minimized in active inference so it's a variational distribution cue that they're fitting and they take the same approaches they took earlier with a single layer model and they reach this hierarchical free energy that can be rewritten by the bottom row as the decomposition of the free energy of the lower model and of the higher model."
"Speaker 1","01;32;23;23","01;32;48;05","So I think it'll be great to hear the authors like How do they reach this and what do they think it means? And so on. But I think the awesome question to think about here is how do we think about free energy minimization in multi agents and multi scale systems? How do free energy decompositions work? And what if nine do really well than one doesn't?"
"Speaker 1","01;32;48;16","01;33;10;16","How does that group outcome get treated off against well everybody is doing a little bit worse, but is not better than one person doing a lot worse. Well, it depends by how much you mean by a lot and a little in the situation and so on. So how is all of that going to be amenable to these kinds of seemingly cut and dry decompositions yeah."
"Speaker 2","01;33;10;25","01;33;28;22","That is an excellent question. And another question that I would add to this is how many terms can you decompose this into as you think about more and more models? So here here we have a lower level and a higher level, but can there be multiple levels for different kinds of scenarios?"
"Speaker 1","01;33;29;22","01;33;52;18","Awesome. OK, so they are now going to pick up on that. Bottom line, there's a low and a high decomposition of the hierarchical variation of free energy. And then right. This falls apart into a term for the lower level and the higher level, the hierarchy, which we can further unpack for the higher level we get. And then they provide expansion of that F high and F low."
"Speaker 1","01;33;53;07","01;34;16;08","And these have the same complexity and accuracy interpretation as we saw with the previous F except that this complexity minus accuracy can be understood as being about only the higher level. And this complexity minus accuracy on lower level can be interpreted as being about only the lower level. So it's like been a separation of consideration between these levels."
"Speaker 1","01;34;16;16","01;34;41;13","But again, they're coming from a common joint distribution so that is just like an example of taking the analogous logic and path that was followed on the single level model. Then using this composable framework making the nested generative model and then being able to apply the same kinds of techniques to reach the same kinds of conclusions. But now in this different context, Anthea."
"Speaker 2","01;34;41;21","01;34;59;26","Totally agree. Yeah. Splitting it into like these very specific terms and differentiating the forest from the trees where high is the forest and the lower level of the trees is very, very helpful. And it also shows how they are related and not related awesome."
"Speaker 1","01;35;01;01","01;35;20;19","So now they're going to make that F to G when considering future time steps tile the variation variational free energy becomes and expected free energy, which again unfolds to a term for each level in the hierarchy. So they're going to do that F high and F low type decomposition, but it's going to be about g the expected free energy."
"Speaker 1","01;35;21;01","01;35;46;12","And so here's the low on the right and the high on the left. And so here there's that same risk plus ambiguity but now it's being applied to the decomposition between the high and the low. And so similar leads to equation for this unpacks in a risk term to reach a prior goal location and an ambiguity term. Intuitively, this means the agent selects a route to its goal location with the lowest ambiguity."
"Speaker 1","01;35;46;21","01;36;25;21","Hence, if the agent operates in a completely static environment without uncertainty, this basically becomes equivalent to shortest path planning. So that's was really interesting to hear. About again, in the context of what you described, like well mapped, well connected, real time updating, highly controlled settings, the future is more like F than it is like G because it's like you can just trust in the future that you'll get a snapshot update and you'll be able to make the perfect move because you'll be able to do shortest path planning and traditional optimization techniques because you'll have no ambiguity about the future."
"Speaker 1","01;36;25;24","01;36;36;06","Basically, in the short term. And then that gets more complex when there actually is different kinds and different patterns of ambiguity in the future, such as like such a cool way to hear about it. Now."
"Speaker 2","01;36;37;10","01;36;43;01","Yeah. Could an upset had better similar thoughts on this particular framing?"
"Speaker 1","01;36;44;01","01;37;11;04","OK, so that was Section three in section four there. Now we still haven't seen Active apply yet. We haven't seen any action perception loops. It's been like very analytical to this point. So now in Section four, they're going to actually bring that generative model into active at first. So they right now we've established our generative model and the Variational three energy optimization objectives."
"Speaker 1","01;37;11;16","01;37;39;24","We present how to instantiate such a model in silica for navigation on a real robot with camera input. So it's kind of interesting because in silicon often means like we only simulated it, but here it means we implemented it on a silicon processor. Yeah, in a, in a real embedded situation. And so the observations are the raw pixels from the camera sensor and the actions consist of the command specifying the linear and angular velocity."
"Speaker 1","01;37;40;06","01;37;57;17","So that is just taking that generative model structure that we described kind of abstractly. Like we just talked about the observed observations. But is that a one pixel camera? Is it a 4K video? Is it lighter? Like this is where they are going to connect it to the specifics of what they actually do in the robot?"
"Speaker 2","01;37;59;14","01;38;24;27","Yeah, yeah. The only thing allowed is again, this picture because it's such a helpful picture in framing the pixels and the sensors that that are being captured in their case as well. So they are taking just this camera inputs, which is our G and B values for this particular paper, as well as like the IMU units and the automated units, which is velocity awesome."
"Speaker 1","01;38;25;22","01;38;50;06","So in Section 41, they highlight the visual perceptive aspects of their model. We're not going to describe it here. We'll hear about it, but for one focuses on that visual perceptive aspect for two, which we're also not going to focus on here. Takes it a little bit out from the visual perception, you know, how is the tree recognized given the retina?"
"Speaker 1","01;38;50;13","01;39;22;22","And this is like the path integration around those trees. So this is a path integration approach. And then they also bring up some points about how this has some similarities on the biological side. And also they introduce this topological map components of the higher generative, higher level generative model, the red model, do anything to add, especially maybe about that topological basis of the higher model yeah."
"Speaker 2","01;39;22;23","01;39;48;28","So I mean, this is where it's attaching it to like the physical world. This is where the lower levels and higher levels get connected to these particular formulations. So yeah, this is a question I will have for the authors as well. Like how is this seen network represented and why did they choose this particular framing of connecting the two letters?"
"Speaker 1","01;39;49;07","01;40;08;28","Yeah, they wrote the poster distribution. That's the one that we control is represented by a continuous attractor network, the can, a 3D cube that wraps around the edges with these different dimensions. So that might enforce some type of closure on the network, which we also saw happening with the Rat Slam. But that would be a good thing to ask."
"Speaker 1","01;40;09;14","01;40;42;16","OK, so then in section 43, they highlight the the localization and mapping. These are being simultaneously inferred. So it's a slam and this is the localization and mapping features, which are another level kind of above or different and just path integration. And they relate that to the higher level model. So they provide some other formalisms and maybe this gets up what we were discussing due to odometer integration drift."
"Speaker 1","01;40;42;16","01;41;15;13","So inaccuracy about how many footsteps you took. Like that's the kind of the reason why people apparently walk in a circle when they're lost in a featureless landscape because they have like a little bit of a different step length and so they have drift in their heading. Matching experiences will not have exactly the same associated posts. These displacement errors are distributed throughout the graph by use of graph relaxation shifting the stored pose according to equation 16 this enforces the map to be top logically consistent even after loop closures, which is often challenging in metric slammed systems."
"Speaker 1","01;41;15;18","01;41;43;10","So that definitely gets out. Steven's information geography or information geometry versus information topology. Because if we enforce a rigid geometry, then tiny differences might drive us wild. But if we enforce topological closure, then even if a road like became 30% longer, we'd still be able to navigate from city one to city two. And it wouldn't be so bothersome yeah."
"Speaker 2","01;41;44;03","01;42;06;21","Yeah. And including Drift is like one of the fundamental things all robotics experiments have to do because everything that we formulate via math never seems to work out well in actual physical sensors and actuators. There's always that drift dome that needs to be added, and I like how they have handled like the drift here."
"Speaker 1","01;42;07;25","01;42;42;19","Awesome. In Section 44, they discuss and highlight the navigation features. And here we'll talk more. I just want to raise these questions because they make up like three of the perspectives that are really getting integrated and re combined here. And you spoke to it right there. How do mathematical entities navigate like Bayesian graph models and generative models how do biological entities navigate and how do robotic entities navigate and what are their similarities and differences and different opportunities and challenges?"
"Speaker 1","01;42;42;28","01;43;03;19","And how will we generalize and make the right kinds of connections across different systems within these domains and across and among these domains. So that's awesome. Complexity question. I hope a lot of people can enter into these questions and like provide their thought and be involved in this yeah."
"Speaker 2","01;43;03;29","01;43;10;28","I mean, this could be a whole section on navigating navigation, which is like an interesting topic for complexity."
"Speaker 1","01;43;12;16","01;43;51;01","Awesome. OK, Section five, and this will be, I think, just fascinating to hear their hands on experience about these experiments. Which we're not going to go into too much detail in. But in Section five, they describe their setup and implementation. So this is a Tesla operation of a mobile robot in a lab with a warehouse style, and they describe some details about like what kind of robot they used, what kind of camera was used, and how many data points existed and then they talk a little bit about their implementation of how that generative model became basically implemented using machine learning."
"Speaker 1","01;43;51;10","01;43;56;22","As a Lstm network yeah."
"Speaker 2","01;43;56;26","01;44;19;10","Yeah. This is where this is. This is the most fun part of the paper for many robotics researchers because this is like the standard robotic toolkit that's used in almost all robotics labs around the world. Total Bot has become like the Raspberry Pi of robots in which every lab has one, and anyone can replicate this kind of an experiment easily."
"Speaker 2","01;44;19;18","01;44;53;02","And it's interesting that they have access to like all these sensors that they talk about such as lighter and millimeter wave radar, but they only use like the minimal set of sensors they need, which is the RGV data and that is what they use to collect data points. And they're sampling it at like an interval, which is very close to human perception, like hundred milliseconds it gets close to like biological level perception, like the frame rate that we have for our sensory organs."
"Speaker 2","01;44;53;14","01;45;05;21","So that is very interesting and the implementation is even more interesting where they very much we have to definitely ask the authors about how they use this setup."
"Speaker 1","01;45;07;06","01;45;30;24","Thank you. Great. In FIG. three, they show on the right side a picture of the bot, turtle bot. So there it is. And then on the left side, we see some still images of the lab warehouse scene at different points. So like here, point one on the map is corresponding to what was seen as like approaching this wall and kind of doing a U-turn."
"Speaker 1","01;45;31;08","01;45;57;23","And so this is the path that was taken as it was kind of circulating these warehouse shelves, basically. Yeah. Well, and also, I really appreciate how you like you described the the commonality of these techniques because those I just didn't know that this was such a common hardware and it'd be awesome to see, like what it will look like when people start to deploy it in different settings."
"Speaker 2","01;45;58;18","01;46;17;23","Yeah, that's and it's important because the user us first of all turtle bot uses the robot operating system and like this is the first time people are looking at a turtle. But by just looking at the image, you can tell that it's a room above it. Like a shelf on top of it with many different sensors. So honestly, that's all there is."
"Speaker 2","01;46;18;00","01;46;40;01","So the movement movement is done by like the vacuum cleaner on the bottom, the cleaning robot module on the bottom of the robot. And then the rest of the rack, the rack is full of sensors where you see the cameras attached. So earlier there used to be Kinect cameras attached and you can attach any sort of additional units on top of it."
"Speaker 2","01;46;40;01","01;46;58;23","And then there's a processing unit there, which like takes in all those inputs and does all the calculations on board. So so yeah, reproducibility in robotics research is extremely rare. And using a technique like this definitely helps. For other labs to reproduce these kinds of results."
"Speaker 1","01;46;59;29","01;47;25;03","Yeah. Thanks for that. And I'd be really curious to learn more also about like the edge computing implications. Like, is that a mini P.C.? What exactly is needed here? What if the model were a hundred times simpler? What if it were a hundred times more complex? So in FIG. five, in Section 53, they discuss their results and they ask three research questions, and those are addressed in the following section."
"Speaker 1","01;47;25;03","01;47;52;02","So they ask, does that lower level model learn accurate representations for inference and prediction by minimizing free energy? So does the lower level work too? Can these representations be used in the hierarchical model for generating biological maps of the environment? Because although we kind of didn't discuss in detail those that topological closure that's impressed upon at the higher level, but not at the lower level."
"Speaker 1","01;47;52;10","01;48;23;21","So can the lower level work and then can it be used as a useful interface with this totally different in type topological closed higher level model? And then the holistic question is, does the system infer sensible moves and actions by minimizing expected free energy to engage in navigation? Like, OK, given that the two components are interfacing, does the whole thing do free energy minimization even in a way that ends up doing so-called sensible moves?"
"Speaker 1","01;48;24;13","01;48;44;16","That is maybe what a person would do if they said, just patrol that warehouse. Just walk around without any too specific of a goal, but just make sure that you walk everywhere. Pretty much that's pretty sensible. Didn't spend any time over here. They didn't just go up and down one shelf. So that's sensible, even though there's not quite a holistic for that."
"Speaker 1","01;48;44;16","01;48;50;18","But I think that's really a fascinating question. What is sensible behavior yeah."
"Speaker 2","01;48;51;03","01;49;01;16","And I think they go into how they quantify sensible behavior by comparing it with other approaches and the results. So it will be interesting to ask the authors about that."
"Speaker 1","01;49;02;12","01;49;27;00","Yeah, OK. Table one just goes into some details about their neural network parameters zation. We'll hear about it from the authors. So how did neural networks come into play? What was the process of fitting that? OK, bigger for? All right. Figure four is the sequences of the ground truth observations first row. So that's the video data coming in on the top."
"Speaker 1","01;49;27;00","01;49;52;28","That's like just looks like regular video data, reconstructed observations, second row. That's the generative model of visual input. And that's kind of like thinking about this in terms like a course training, but this brings the visual input into the robot's terms corresponding to latent space samples, third row. So this is like potentially an internal representation like a layer of a neural network."
"Speaker 1","01;49;53;12","01;50;24;15","And so it's just showing that these perhaps very similar or different scenes can be differentiated via their position in like a higher dimensional latent space or it's lower dimensional in the video, but it's higher dimensional than just like the X in the Y the robot is turning towards the left in the sequence, as can be seen for both the sequence of observation as well as the shift towards higher theta values in the pose cube and that's the post cube activation on the bottom row."
"Speaker 1","01;50;25;11","01;50;56;19","So this is what it looks like at that lower model to go from video data to hidden state estimation, the kind of course screening generative model of the video to this latent state, internal representation to the pose estimation that's going to come into play at the higher level of the model. They're kind of overlaying timestamps as columns during this execution of a turn and showing how different layers about lower model are updating yep."
"Speaker 2","01;50;57;11","01;51;26;17","And I think this is a time series like you described left to writing indicates like look, 10 seconds for example, 10 seconds off or turn off a robot. And that was an interesting comment. On the higher level dimension for a robot is lower level fidelity for us with those pixels. So so yeah, the way we represent things and the way it's represented in a robot can have very different terminologies."
"Speaker 1","01;51;27;28","01;51;46;09","Yeah. And higher, lower inner outer more or less. It's always in relationship and so those can sometimes get swept under the rug. It's a high dimensional representation that we did of this. You know what's what you have to ask in 42.0 how high because."
"Speaker 2","01;51;47;08","01;51;48;15","It's just a few pixels."
"Speaker 1","01;51;50;06","01;52;13;27","In FIG. five, they show the generated experience map left and the comparison map extracted from localization with our tab map. So I'll show the citation here, but I would love to hear your own interpretation of what do they mean by the experience? Map is topological while the art tab map is metric, what are being shown differently here?"
"Speaker 2","01;52;14;02","01;52;46;07","Here yeah. So so yeah, they're comparing the figure that they obtained on the left with the data obtained from a similar technique. So the way these robotic experiments work is they use different localization techniques and they are using a dub map, which is another technique on the right. And yeah, the second point is very interesting and I think that is Steven's question as well, which is how is the information geography represented?"
"Speaker 2","01;52;46;07","01;53;19;20","So the experience map, which is on the left, it briefly describes how like the environment is to biologically Yeah. Closed and the order map is accurate to like physical world metric units, which is measurements. So so topology just means like how everything is oriented. It doesn't need to be physically precise as a real world. It's like wisdom versus knowledge."
"Speaker 2","01;53;19;25","01;53;39;20","So topology is more, more of an idea that that if you follow this kind of a map, you will find your way and you won't get lost. Whereas metric is like precise mapping of the physical environment and mapping it to scale like one is to 20 or one is 200, whatever that scale maybe."
"Speaker 1","01;53;41;02","01;54;12;06","I really like that knowledge and wisdom. And then here's why there's always the minimum of two and why we respect both, because the top of logical maps may be totally non comparable in their geometry or two different entities mapping the same space. And so if we are both trying to get the geometry of the geography, that's where it's possible to have the most objective agreement on the knowledge side allegorically here."
"Speaker 1","01;54;12;25","01;54;40;14","And then the top logical side can be so much simpler and so much more personalized and local and can actually help in those wayfinding and the changing situations. And maybe there's analogy or there's resonance or there's small isomorphism with different wisdoms, but one has gone down that path and has basically given up making the image on the right that other people will just see and recognize as well."
"Speaker 1","01;54;40;14","01;55;11;07","Yeah, that totally lines up with what I see. So it's quite a nice point yeah. OK, figure six is some more outputs of the model. So the right imaginary policies, imaginary policies. So there's several images of different things happening. There's the current state which is the video input at that time step, and then there's imagined short term goals."
"Speaker 1","01;55;11;18","01;55;31;16","I want it to look like this. I want the frame different seeing at that time step to be super small. I want to be really unsurprised about looking like this at that short time step in this turn, you can kind of see that piece on the left that's getting brought more into view. As I turn my head left, I don't want to be surprised."
"Speaker 1","01;55;31;16","01;56;01;01","I want it to feel normal. And then in the long term goal there's a lot more like blurriness because it's not super important whether the handle is here or here because it's just an uncertain future. And so these are imagined policies that can be considered past, present and future time steps. And that's kind of what the partial observability of the hidden Markov model structure or motif brings into this picture."
"Speaker 1","01;56;01;05","01;56;25;27","This is why it's good to have a generative model rather than just a recognition or an input or a signal processing model. That's like where the whole generative Bayesian concept and predictive processing from the biological side come into play. And also in the future, it trails off. These are the same time series and further and further in the future, it gets blurry and blurry until it's like, I just want to be in a horizontal plane in the future."
"Speaker 1","01;56;26;18","01;56;28;25","Basically standing."
"Speaker 2","01;56;29;05","01;57;06;23","Yeah, yeah, yeah. Figure D is like very interesting. In this particular picture where they have three different policies and you see very different results as a result of those policies. So this is like robotics, one on one behavior where you program the robot to always go left, always go right, or always go straight, and you start with these particular policies and then understand that these simple changes in behavior have like such vast differences in the results so yeah, the sentence you just highlighted is."
"Speaker 1","01;57;07;02","01;57;27;17","Yeah, so so here the three policies are basically like the two different turns or going straight. And so they say when calculating G low in evaluating the distribution on policies, this results in a probability close to one to take the policy, go left like look at how on the bottom row that's the go left policy. It stays sharp in the future."
"Speaker 1","01;57;28;08","01;57;50;06","But then this the policies that diverge increasingly from the goals at different time scales with respect to those goals, it becomes really unclear. So it's like I want $100, so I'm saving $1 per day. Then at day 71 I expect $71. Wow, it's exactly $71. That's like this bottom time one. And this is like I'm losing money every day."
"Speaker 1","01;57;50;06","01;58;08;26","I'm getting less and less clear on how it's going to end up at 100 at this future time step. So maybe that's not a good policy, not because my expected values dropping, but because it's just it's unclear how many get to a hundred. And that's something that can be neutrally said without even taking a judgment on the amount at any given time."
"Speaker 2","01;58;08;26","01;58;37;07","Step yeah. Yeah. I think that analogy really drives the point home that you need to choose your policies according to the goals. And I think all those goals were part of their formulation of the expected free energy. So I think it's important to ask this to the author is like how were these goals as well as policies chosen and can this be generalized for different kinds of environments?"
"Speaker 1","01;58;38;03","01;59;10;05","Awesome. So figure seven they write different goals for the long term path of figure five. So just here's figure five again with the top logical closure of the higher model, the lower level dynamics model will take the corresponding states as preferred state goals sequentially. So this is where we see that the connections between the models becoming enacted. So let's just say that one is coming around this edge and there's two options."
"Speaker 1","01;59;10;05","01;59;34;08","They can continue straight or they can go right or they can go in reverse. But we're considering forward motion only so as to alternate policy. It's not the infinite space decision making that humans are sometimes confronted with, but here it's a robotics motion decision about continuing straight, ostensibly to explore this final right most shelf sequence or taking the right turn map."
"Speaker 1","01;59;34;08","01;59;55;19","So go straight or turn right. Now, what would sensible behavior be if one had recently or repeatedly visited the closer shelf? Then to be more exploratory, it would make sense to like go straight so that this last shelf could be explored. So that's the kind of decision that we would want that robot to be able to incorporate when it's able to be making that decision."
"Speaker 1","01;59;56;09","02;00;25;16","And so that could be thought of as having a long term goal, to be expecting oneself to be on the far right shelf here, the bottom one. And then in the moments which one of these actions turn right or go straight is going to be preferred with respect to how one looks now. And so then that's what it means to say the lower level dynamics model will take the corresponding states from the higher long term path as the preferred state goals."
"Speaker 1","02;00;26;09","02;00;45;13","So then one could be like, well, I'd prefer to see myself just right here already one has chosen a branch, but that is helping you reduce your uncertainty about being found here later. So that, although I really look forward to also hearing everyone else, is like unpacking of like what is the robot doing or thinking in that pivot moment."
"Speaker 1","02;00;46;04","02;01;10;24","That's like kind of how I read the way that the long term planning goals become imposed upon the lower level action selections yeah. Agree. OK, what did you see or want to talk about with the contrast with other slam approaches we see?"
"Speaker 2","02;01;11;28","02;01;44;00","So yeah, this paragraph that describes different slam approaches and you see the same vague group of authors mentioned from probabilistic robotics with Sebastian Thrun, none the coauthors I mentioned and those were engineered approaches which also used different kinds of Bayesian like the next two districts. And then there were more bio inspired approaches such as the Rat Slam Group, which is the 2013 paper."
"Speaker 2","02;01;44;00","02;02;14;13","And then, yeah, they rely on both scan and this experience map, which they compare it with and the recently like deep learning has obviously been used on Visual Slam like you see in this, like the bottom, like bottom of this paragraph and yeah, the underlined section is important. Do you want to cover that, the act of inference. Oh, allow for a holistic treatment."
"Speaker 1","02;02;15;23","02;02;50;24","I think that's where they bring it home, which is they say, well yeah, yes, people have used this recognition Variational Auto Encoder model and yes, there's been this topological approach to rat slam navigation, closure and et cetera. But then those are often again composed in an ad hoc way. And so active inference is providing a possible way to approach it in a more principled and more integrative first principles way OK, true conclusion."
"Speaker 1","02;02;51;00","02;03;12;24","Let's hear from the authors. People can draw their own conclusions but I'll just highlight the last sentence that we think this research direction might offer new insights both on how navigation works in the mammal brain, as well as how to scale active inference to real world applications. So it's like those were the three vectors we brought in with biological, mathematical and the robotics."
"Speaker 1","02;03;13;04","02;03;23;20","And then from that nexus it's kind of like it feeds back out because now from the brain, they might be learning about the math and the robotics and then the others in a similar fashion."
"Speaker 2","02;03;24;24","02;03;51;23","Yeah, yeah. And as the authors conclude the paper, they also bring up some open questions, such as Can these techniques be used for lifelong learning, which is a relatively new field of machine learning in which states change all the time, and you do not need to retrain your model, but you do not you need just need to like retrain specific parts of your model to continuously learn throughout the lifetime of that application."
"Speaker 2","02;03;52;00","02;04;20;23","So so the suggest something like a sleep cycle. That means that whenever the robot is charging, that is when it can update its model of the entire environment and share that and do that active inference approach to achieve lifelong learning. So I'll be very interested in knowing this from the others. Like what are the weaknesses in this approach and how can this be solved to scale for real world applications?"
"Speaker 1","02;04;21;21","02;04;25;26","Awesome. And how about just describe what this last video is showing?"
"Speaker 2","02;04;26;26","02;04;51;12","Yeah. So this video is just for people who are coming from the active inference lab, but want to see like a robot actually more. We have been talking about robots moving, so we played the video. It's just an introduction to turtle bot and how people use it in an experimental setting. So so yeah, the first few seconds of the video will describe all there is awesome."
"Speaker 1","02;04;52;18","02;05;29;03","Well, we leave a blank slide for the discussion sections. This was an awesome and memorable discussion and it's just the opening of the 42 when we'll continue on in a participatory group setting in the coming two weeks and hopefully have any of the authors join anyone else who would like to join in. All right. You give a penultimate thought, but just really appreciate the, the care that you brought to these slides and to this stream yeah."
"Speaker 2","02;05;29;04","02;05;33;14","And thanks to Steven and everyone else who asked questions."
"Speaker 1","02;05;34;27","02;05;42;07","Yeah. OK, so if you have anything else you want to add or otherwise, we can just thank the listeners and."
"Speaker 2","02;05;43;21","02;06;14;14","Yeah, I mean, this was my first active conference appearance in in the sequence of hopefully a lot of appearances in the future. And this clarified a lot of concepts for me as well. I'm connected to one of the fields that I was very intimately connected with almost a decade back. So. So yeah, happy to see connections being re forged and yeah, looking forward to meet with the others."
"Speaker 1","02;06;15;17","02;06;20;01","OK, thanks a lot, Sid. Thanks everybody. And see you next week. Bye."
"Speaker 2","02;06;21;15","02;06;22;00","Thank you."
