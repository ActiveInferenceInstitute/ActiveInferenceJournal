SPEAKER_03:
Hello and welcome everyone.

This is Act-Inf Lab live stream number 36.2.

It's January 26th, 2022.

Welcome to Active Inference Lab.

We are a participatory online lab that is communicating, learning, and practicing applied active inference.

You can find us at the links here on this page.

This is a recorded and an archived live stream, so please provide us with feedback so we can improve our work.

All backgrounds and perspectives are welcome, and we'll be following good video etiquette for live streams.

Check out activeinference.org if you want to learn more about what Active Lab is up to, or if you want to participate in any of the activities, which include live streams in the communications organizational unit, but a ton of other stuff is happening.

today in 36.2 our third discussion on 36 we're going to continue to learn and discuss this paper by sims and pizzulo 2021 modeling ourselves what the free energy principle reveals about our implicit notions of representation and

We're going to have a nice jumping off dot two as we do and have some questions written down and prepared.

Other things will spontaneously arise.

And if anyone watching live wants to just write a question in a live chat, we can also address that.

We'll start with an introduction.

So we'll go around and introduce ourselves.

People can say anything they want, and they can also add just what got them excited about the paper in general or for this DOT2 discussion specifically.

So I'm Daniel.

I'm a researcher in California.

Just excited to see how this representation discussion influences our own self representation and that at the individual and the lab scale.

Moving forward, I'll pass it to Blue.


SPEAKER_02:
Hi, I'm Blue.

I'm an independent research consultant in New Mexico.

And I am excited by this paper because in our previous discussions we're, as usual, left with more questions than answers.

And also I kind of am finding myself swayed by the different representational, structural, content-driven, non-representational

like these different arguments.

And I just find them very interesting.

And I just want to know if at the end of this, if I'll be swayed more or less in certain directions, or maybe just be more open to other interpretations of FEP.

And I will pass it to Danielle.


SPEAKER_01:
Hello, I'm Danielle.

I'm a cognitive scientist at Google with a background in language evolution, language development.

I'm really interested in thinking about how humans evolve the ability to model other minds.

So interested in how this discussion can contribute to that and generally interested in how really good frameworks like the FEP can help kind of encompass other frameworks and revise them.


SPEAKER_03:
Awesome.

Dean?


SPEAKER_00:
Hi, I'm Dean.

I'm up here in Calgary in Canada and a little bit of recency effect.

I started watching Ozark the last season and so I'm trying to plug this paper in through what would Marty Byrd do?

So that's kind of my little twist on modeling.

So back to you, Daniel.


SPEAKER_03:
Who is Marty Byrd and what would he do?


SPEAKER_00:
Right.

Exactly.


SPEAKER_03:
Great question.

Well, that's all we prepared for today.

So we'll go into the discussion.

But we have some things written down.

Is there anything just off the bat that anybody wants to just ask or jump into or like a figure or a quotation to begin with?

Or we can look at some of the things that we had written down.

Okay, let's just start with what we've written down and then of course at any point we can branch off.

Okay.

I think a big theme that we'll probably return to again and again is this idea of moving back and forth from non-representational forms to representational forms.

In the paper, they introduce

four different facets of representation, and then how each of those facets can be approached in a representational or non-representational way.

And although the image here shows some solid black lines, that was kind of the discussion was, is there movement across these areas or blurriness?

So maybe Dean?

What is there to say or start to explore with representations emerging, like almost precipitating or crystallizing out of something non-representational, and then the reverse process of something that is more representational submerging back into something that's less?


SPEAKER_00:
Well, one of the things the authors did talk quite a bit about in terms of the functional aspect of this was the vicarious nature, and then they also talked quite a bit about

whether or not somebody who's sort of moving in that radical and activism space still has to be able to differentiate and include some of the temporal aspects of what might pop up and become something that we can stabilize in model representation form.

But then it has to also be able to disappear, right?

It also has to not necessarily consume everything in terms of our attentional fields.

So I'm not really sure exactly how that works itself through.

But I would think that it's difficult to say that

even if we're in a flow state that there isn't some moment when we do reflect in that mirror.

So that's kind of where I'm at.

I don't have any answers per se, but I don't want to get stuck in the idea that it's just a on off switch.

I think that there's a bit of a, a moment of dimming and then re relighting.

So.


SPEAKER_03:
That makes me think about certain paths that our thought takes over these eight cells.

Like when we're in the representational side, when we're dealing with the representation, how do we take that tetrahedra and look at the four different sides?

And then how do we stay within a column looking at just the organizational aspects of a system and then move

north and south on that.

Do these kinds of knowledge or cognitive transitions happen all the time?

Do they have other names that might be more familiar than using some of this philosophical language?

what is it are there any times in our days where we're dealing with something representationally and we shift to a non-representational version within one of these categories or across categories so i was just thinking of that actually like um


SPEAKER_02:
What does an organizational representation look like?

That is like a map, like a structural representation, a content-related representation, and a functional representation.

And what do these representations look like?

And how are they different?

I was just thinking about that.


SPEAKER_03:
Let's go to the definition of the organizational representation just to kind of remember.

The fact that FEP requires internal states, states that encode the recognition model that are statistically separated from the external reality.

So the organizational area

is about how variables inside of systems are separated from variables outside of the system.

The pro representation take is there's an evidentiary boundary, the Markov blanket, and there's something on the inside that is doing something like a representation on what's outside.

So that's the pro-representational take.

Then the non-representational take is where we get into the ecological and the inactivist persuasion.

And that's where the authors say that some have approached this Markov blanket structural formalism, even though we're talking about it in the organizational, not the structural facet, in a manner that suggests a non-representational view.

And they argue that just partitioning two coupled systems like agent and environment with a Markov blanket doesn't imply that the behavior of the agent is explained by anything related to an internal model that's doing anything like capturing the structure of the outside world.


SPEAKER_02:
So you just use like organizational and structural, like in this like big hobnob.

But so my question was really, what does an organizational representation look like?

And so I'm hearing that you answered that there are clearly defined boundaries in organizational representation or partitions between internal and external states.

So like I have a clearly, when I have a representation in my mind that's organizational, it is like,

your boundary is different from like, is it only your own boundary or is it like the boundaries of each individual agent are organizationally represented in your mind?

Or is it just the boundary between you and the outside world?

And how might that differ from structural and content related?

Like what do these different representations look like?

That's what I'm trying to see.

Like would they be maps and how would the maps be different?


SPEAKER_03:
The structural, which does come up several times in the organizational definition.

So we see structure coming up, the structure of the system in how it's organized, but what is the structural specifically?

Okay.

Having representational vehicles that are structurally similar to the state of affairs in the world that they stand for.

The pro-representational structural side is kind of like the good regulator theorem of cybernetics.

So the organizational side is highlighting that there is some sort of informational encapsulation, we might even say, like our previous discussions, but some sort of organization of variables such that there's an inside and an outside that are separated.

The structural side is saying that it's like if there's three things that are connected in the outside world, then not just that there are variables that are organizationally separated in the internal states, but that the structure of those isolated variables is gonna do something like recapitulate or have a structural resemblance to the generative process.

Generative process, that's like the niche, that's what's outside.

Generative model, that's what the agent has on board.

And so if it's to be useful for control purposes, then it may have to have some sort of structural resemblance to the actual connectivity of the generative process.

So generative model and generative process being separated is what's captured in the organizational side.

Them having similar resemblances or similar structures is what the structural side is.

the structural non-representationalists are suggesting, this is, I think, tale of two densities with Ramsted et al, or modeling ourself.

The author suggests that generative models do not meet the requirements of structural representations because the process of exploitable structural representations, so posterior beliefs in the entity,

is enacted and so it doesn't necessarily have to recapitulate the form of the generative process so maybe one could be skilled in the performance of driving without having variables connected in the way that a car pieces are connected.

It comes back to a theme that Active presents to us, perhaps more as a question than an answer, which is how much do we have to know in order to act?

Do we have to have an internal model that is very similar to the process?

Uncorrelated in how similar it is?

Anti-correlated in how similar it is?

And can we have a framework as researchers that helps us compare the structure and organization of generative processes and generative models of those processes?

Yes.


SPEAKER_00:
Go for it, Dean.

So I'll put this out there and then people push back or say it doesn't make any sense.

From what I read in the paper now, because I had to go back over and look at it again.

If I were to try to draw a simple comparison between organization and structure, organization would, you could see it as being something as being either in or out.

So you could be inside

It could be inside a cell or outside of a cell.

And in our mind, we can tell, we will draw those partitions and then we'll decide what's in or out.

Structural, I think, takes on more of the entailing question, something that Sirval brought up in the chat, which is, so once you've decided whether something's in or not, is there something else that now can be seen as being superordinate to that?

from the perspective of sort of what's wrapped around now the thing that's in, or what can sit upon

theoretically the thing that you've now decided is foundational to whatever it is you're looking at and what can be set aside as not being important to what you're looking at.

So again, pull that apart and say that that's wrong, but that's kind of what I try to read into what the readers or what the writers were saying.

So it's just my interpretation.


SPEAKER_03:
Thanks, Blue.


SPEAKER_02:
So I just wonder in this organizational representation, do you draw a distinction between, I mean, clearly there's one between like what's internal and external to yourself, but are you also trying to like

draw distinctions between what's internal and external to your computer or your refrigerator or your best friend or your child?

Are you making a representation of everything that's internal and external to every other thing?

Or is it only with respect to your own self versus environment?


SPEAKER_00:
I would think it's when you do that.

I don't know that it's implied that you do it all the time.

But if you choose to do that, I think that that's something that's pretty easy to tell the difference around.

So again, I'm not sure that they were saying that we do this, we're always constantly doing this.

But I think what they were trying to do is show the difference between knowing when something's in or out versus knowing when something's first or second.

from a structural standpoint.

Again, I don't want to put words in the author's mouth, but I did hear that in the words that they were doing to try to parse those two things and give each their due, as opposed to saying they're just the same thing overlapping.


SPEAKER_03:
Let's try one little thought loop.

So let's start with...

Blue's question of what does an organizational representation look like?

So we'll start in that very top left cell and then shift the focus towards the structural components and then challenge the structural representation, but stay within the structural domain and then see if that can result to us making it back to a non-representational organizational framing.

So what is a good organizational, what's something that is classic vanilla organizational representation?

Well, that's something that is well separated in terms of variables inside and outside the system.

So we're not worried about the structure of the variables inside or outside, just that they are separated.

So,

Computers seem like pretty clear cases where within a program you could have variables that by design are separated through like an intermediate variable or computers and hardware, like two computer systems could be totally separated except for an interface like a USB port or something.

But of course this paper is about that strange loop

when it's a cognizing agent, an adaptive active inference agent doing that representing not necessarily a mere active agent, but should we use a computational example or some sort of enacted human


SPEAKER_00:
example but you got you got a good example right here on the page so how would we how would we shift across the y-axis between organizational representational because i'm assuming we're going clockwise to representational structural that's not that's not a hard example to to make yes um


SPEAKER_03:
yes so um in the human case this would be like um so two humans in a conversation they are in a conversation yes perfect outside of the conversation yes two humans when two humans are in conversation right there is separation in terms of their sensory motor

So we have checked the box for organizational, representational, starting in the top left cell.

All right, now the question would be, is there structural representation?

So that would be like maybe if one person thought of a sentence and then said it, and then the other person thought of that sentence too.

would that qualify as a structural representation because there's a structural resemblance in the model of the two conversions um yeah we could also find out if if both of us were talking at the same time and suddenly stopped turn taking that the structure of of that


SPEAKER_00:
model would would now fundamentally change it's still representational and two people arguing over top of one another to the third party isn't necessarily something comprehensible never mind to the two people that are inside the conversation right hello


SPEAKER_02:
So when I think about conversation, something comes to mind recently.

Like, really, you need to have, like, the order of the language specified.

Like, my son is reading now, and he's five.

And, you know, he's taking the book, like, hop on top, the Dr. Seuss book, and he'll turn it upside down, and he'll say, dod, no, do.

And, like, he'll read it that way.

And then he wants to read, like, every sentence backwards, like, from the end to the beginning, which I'm like, I don't care, as long as you're reading, because it gets him practicing reading.

But it's completely...

but the context is completely um different right when you're reading like each word in the opposite order so like when you're talking about a structural representation of a conversation i think that there needs to be like a literal representation or at least like a coarse-grained representation of in what order things are said in order to glean some kind of meaning but then are we bleeding into the content related but like as we're you know that's why i really feel like

like what are these different maps look like and trying to maybe elucidate what the representations are is valuable because i think when you have organization okay inside outside like this is the sentence or he said this and she said that or whatever and then you try to put structure on it like that gives it then content or context that they can then you know and so on and so forth dean


SPEAKER_00:
No, I don't have much to add to that other than I just don't think that this loop that we've just selected this.

We said there was going to be a certain amount of randomness in the last live stream.

And we've chosen this now.

Let's walk through it.

I don't see it being difficult.

to follow that path and find examples.

So we have a superordinate right now.

Structurally, we want to carry out this directionality from the representational side of things to the non-representational side.

And Blue, if your kid wants to turn the book upside down, that's actually a feature, right?

Because they're not already stuck in this only one way of doing it thing.

So, yeah.


SPEAKER_03:
Let's complete the red loop and then the green and the orange will come into play.

Okay.

So we started with two people in conversation.

That's organizational separation of cognition.

This brings us to the structural facet, which is where there's a structural resemblance in the representations of the conversants.

So there...

Maybe it is the case where they're both thinking about a similar topology of variables.

So there's some structural representation.

But now let's stay within the structural column, go from B to C. Okay, so the two people are in a conversation.

It's kind of like a dance.

So what if those two people's representation

is so different that it's actually not structurally resembling.

So maybe one person is the more experienced in the discipline and the other is less experienced.

Like one person's super good at fixing motors, the other person just has no idea.

So the representationalist take would be like, well, they're both thinking about the motor, but then when we start to see like a cognitive asymmetry, all of a sudden,

we fall out of structural representationalist between these two systems because their cognitive models don't necessarily have similar structure.

Yes, Danielle.

Oh wait, unmute it then, go for it.


SPEAKER_01:
So I might be missing something here, but I thought that we...

can only start to talk about the structural dimension here once, in this example, the two people in the conversation are representing the same thing.

And then the question is, how much information, or how does each of their representations, do each of their representations have to look similar to one another?

But part of it has to be that they are representing the same thing.

Is that a necessary component?

If they're not representing the same thing, then we're having a different conversation.


SPEAKER_03:
Well, that may come to the functional, that might come to the content related, like the novice and the expert, the representations are both about the engine, but they're so structurally different.

in their representation of the engines so that although the content, the aboutness of the representation is similar, so still qualifying as a representation in that sense, there's a structural non-resemblance such that by that criteria in that situation, we've fallen out of the representational cell B into something non-representational potentially.

Blue, what do you think?


SPEAKER_02:
So I think two people in a conversation can be trying to represent the same thing.

Yes, they both need to be trying to have the same representation.

They're trying to converge on a conversation, a meaningful conversation, presumably.

But they don't always converge.

And then that's where you get misunderstandings or we both think that we think the same.

We both agree that we're thinking that we have the same structural representation, but perhaps they're different and then the communication breaks down.


SPEAKER_03:
Okay, so the structures are so different that we're recognizing it as a continuum from total overlap of structural resemblance to total non-overlap, but it would be important to specify that null hypothesis.

So we've kind of scooted into C.

How do we stay in that space of like the novice and the expert who have different cognitive representations and then use that to challenge even organizational representationalism?

Blue, then Dean.

Oh, Dean first and then Blue.


SPEAKER_02:
Go ahead.


SPEAKER_03:
All right.


SPEAKER_00:
I just thought I want to just go back to the to Daniel's point.

So if we're if we're structuring a conversation, normally we turn take.

But if we're playing in a band, we're all playing at once and then we stop playing.

So I think we can start with structure, too.

It's just deciding how we want to signal.

Right?

So I don't think there's necessarily an order that we have to start with organization first.

We can actually start with structure first as well.


SPEAKER_01:
Yeah, and I think a conversation is a particularly challenging example because we're representing two things.

We're representing what the other person is trying to say and then presumably what the conversation is about is something else in the world that we could be representing.


SPEAKER_03:
Exactly, yeah.

Blue?


SPEAKER_02:
So I think we're representing...

a degree of information sharing and I think that this is going to like lump into autopoiesis which I've been really wanting to kind of get into but when we have like I'm my own person and I'm communicating with Danielle from you know 50,000 miles away we both

feel like we're getting on the same page when we actually like do get on the same page like do we form some kind of like separate cognitive unit like at what degree of model overlap is the degree of information sharing so high that then we are

worthy of our own Markov blanket.

We're sure that we understand that we are the same unit.

And I think that this idea of self-assembly and information sharing and model overlap, I think that there's an important path to traverse down this way.

Because if you don't have full overlap of the model, or do you need full overlap to form a self-assembling system to form a higher level?

It's just an interesting thought.


SPEAKER_03:
that's kind of where the c to d transition takes us which would be like so we have um the drummer's waiting for this and has a model resembling this and then the singer has a totally different structure and then when we think about the whole cognitive system it

it doesn't deny what we recognized in A, that there still is like the sensory motor separation, but we've reached that point by those people or roles being part of a larger non-separable extended cognitive system.

So almost by recognizing the interaction, so here we focused on the separation.

in A and that's what granted us the representational cell.

But we've returned to seeing that partial information encapsulation within some type of broader structure where none of the entities have like the band level representation.

So hopefully other people can think of other like ABCD examples.

But when we were at B,

we kind of started branching off into like talking about the content related things, the aboutness.

So here it's like two people do have a structural resemblance in their internal model and it's about the same thing.

But then what if one person sees the aboutness in such a different way that again, we fall out of the content related

representation and then how would we move from there back to C, where all of a sudden the cognitive models in a sense don't have structural representations, resemblance, because they're about different things now.

Danielle?


SPEAKER_01:
So would this be like in the case of two things that are so analogous that they share a lot of structural similarities and things of like Dedrick Entner's work that

you can actually draw lines between the individual aspects of, of the concepts, but they could be about totally different things.

But two people talking about these things can, can form some sort of structural similarity in the representations.

And it's just like an entry point into being able to think about all other things.

But the aboutness really has nothing to do with it.


SPEAKER_03:
Dean, then I might want to ask me on that.


SPEAKER_00:
I don't know if this answers that, Danielle, but from my space, I'm thinking the difference between, say, a distracted driver who's looking down at their phone between the seats and somebody who's got that information in a heads-up display on their windshield.

Right, so content twice, but structurally presented, one as a distracted state and one as a contiguous state.

So I don't know if that answers your point, but I think we could, we know the difference, right?

In terms of where the content is structured and how we're trying to contextualize each matter, so.


SPEAKER_03:
Again, staying with this sort of educational setting, what is it important to see a transference or a new emergence of?

Is it that the structural model of the learner is moving into more resemblance with the teacher?

Is it that the aboutness of the learner is moving towards the same aboutness of the teacher?

Or let's just remind about what the functional is.

Supporting vicarious use before or in the absence of external events.

So does the teaching conversation

Will it be a functional representation when vicariously without the teacher, the student can carry out what the teacher could do, which might be having aboutness or not.

It might be with a structural cognitive resemblance or not.

It might involve total informational isolation.

putting a squarely in A, or it might involve some type of challenging of that in D. The reason why there's not gonna be, I think, a precise answer, because as the paper lays out,

even for the same scenario, people do have different perspectives.

So it's not like we're trying to take a scenario, then classify it into, well, that one's like an A, B, E, G, or an A, C, E, H. Like that is probably not what one of the outcomes could be, but these are all perspectives that we could take on a given scenario.

And they do reveal interesting things about the systems of studies.

Anything else to add on this sort of like looping around the cells or should we push on?

Push.

Push.

Okay, Blue, what were you thinking here?


SPEAKER_02:
I was just taking notes.

And so like if, so maybe we should talk about content related and functional.

So I was just taking notes on, you know, what these are organizational, like how are the representations?

And I was trying to draw a picture.

So if you, I will draw my picture.

If, if you will talk about maybe functional representation, like what does a functional representation look like or content related?

What is it?

What's inside of those?

And then I will draw my picture and then you can show it.

All right, I'll just start while you're talking.


SPEAKER_03:
Sure.

So the content related is whether the generative models need to explicitly model the ways external states produce sensations, environmental models, or the ways actions produce sensations.

Is it really important that internal states resemble external states or is it sufficient that they afford accurate action control?

So let's just say there's a spotlight that's shining photons onto the eye.

the content of the cognitive representation would put us more, we'd be more in the representational camp if the cognitive model were truly explicitly modeling the ways in which the photons hit the retina.

Maybe.

But this or is a bit challenging because

The ways actions produce sensations, that could be a model of like, well, if I blink, it becomes darker, and when I open my eyes, it's lighter.

But that's a totally disjoint question from understanding how a spotlight works.

But those two scenarios of the spotlight's cognitive explicit modeling, the environmental model, or

The sensory motor model of blinking and it becoming darker, those are both content related.

And Dean?


SPEAKER_00:
Well, I don't know if this helps or not, but one of the things that I used to bring up around this idea was the...

was the the puzzle concept i.e so you got a box and it says a thousand piece puzzle and when you open up the box is that representational or is it not representational until you've figured out whether all thousand pieces have now been

duly assembled right so from a from a content perspective do you have what you need in order to be able to tell the difference between something which is representative and that which is not so again i don't know if that's helpful in terms of sort of trying to see a difference between that say and structure like where it's placed relative to the context or not but that was the way i tried to


SPEAKER_03:
One evolution or handshake that hinges on that or of the environmental models and the sensory motor models, they do unpack a little bit.

So one approach consists in starting from the sensory motor models.

So that would be when I blink, it becomes darker.

When my eyes are open, it's lighter, but progressively extends them to incorporate extra variables that describe external causes of sensation.

So like if there's a light on one side, but not on the other side, then it can be the case that that blinking is true, no matter how you're turned.

But then that could be enriched or augmented with a model of parameters that describes external causes of sensation.

Like there's a light over there and not over there.

And so actually that little loop that we just took

was from the sensory motor B, the sensory motor model in B moving to a representational model of the content, like there's a light over there.

And then does that, well, at least that was the BTE move.

But then maybe that could do something else.

So maybe Blue will clarify there.

But let's go back to just review functional.

Like what is the functional?

And it's good to revisit these in the zero, one, two, three, four, five, because it's the contribution of the paper.

And maybe there are other facets, other columns to add.

And there's just a lot of complexity, even as this is.

So the functional one,

is about supporting vicarious use before or in the absence of external events.

So in that story with the lights and the blinking, that model only has to be instantiated while in that room with the photons hitting the eye and the blinking happening.

However, we can imagine a situation that's vicariously detached

or before that setting like what would happen if there were a light over here and a light over here and it was the case that blinking made it darker and this is where they trace back to Piaget that representations should vicariously stand for something external in their absence and afford vicarious operations

So there's a light over on the left side.

You reach over and you unscrew it.

What is in your hands?

Now that is seeming to be in the functional facet because we're talking about the role the representation is playing.

and the fact that it is standing for something external in the absence.

There's no physical light that we're talking about.

It's not like we're unscrewing it and then verifying that it's in our hands.

Who's for and against that?

What?

What functional roles do internal models play during free energy minimization?

And does minimization require the internal manipulation of variables in ways that resemble vicarious operations in the classical Piaget account of representation?

Yes, Blue.


SPEAKER_02:
So this might be like, I don't know, maybe it's the easiest and also like the hardest to get a grip on.

So I think about, um, like, do we, so if we have a representation of internal variables that like are functional, like a functional representation of a functional internal representation, is this like doing, um,

like you manipulate the variables internally and then manipulate them externally.

Like you plan to reach for the cup to take a drink of water, and then you reach for the cup to take a drink of water, but you have to have like the internal execution prior to, or maybe simultaneous with the external execution.

Is that like functional representation?

Like you plan the action and do the action, maybe separate or maybe together,

Is that what functional representation looks like?


SPEAKER_03:
Let's go with a reaching for the cup, because as Danielle noted,

Conversation, improvised, spontaneous conversation of reflexive entities is one of the hardest cases, but it's the one that we have.

So that's awesome.

But we're going to be talking about a adaptive active inference agent reaching for a mere active inference agent.

So in the Sims other paper we discussed, now we're talking about the case of unidirectional

integration rather than the multi-scale reciprocal integration so the person is separated from the cup there's a separation of the cognitive model of the agent from the cup

The structural side, if the internal model is cup-like or it features a cup variable touching a table variable, and then another edge that is engaged of the hand touching the cup, for example, that might be a structural similarity.

But I think that's part of the debate is how could there be a structural similarity when it's not a cup in your brain, which we kind of talked about last time.

Like how could you have something that structurally resembles a car

if it's your brain and body.

The contents related, encoding environmental contingencies or sensory motor contingencies.

So it could be the case that a certain sensory motor action will result in picking up and grasping the cup, whereas another sensory motor action is gonna result in the shattering of the cup.

And that could be analyzed in terms of correctness.

The functional representational question would be like the vicarious detachment of the sensory motor loop from the cognition.

So then it would be like, if you were to pick up that cup, then you dumped it, what would happen?

And then someone says like, well, water would fall out.

So in that case, it is like there's a functional representation, whether or not

it resembles the structure of the cup.

There's a functional representation because that idea of grasping the cup, it's able to be operated on internally vicariously in the absence of direct stimuli related to the cup.

Dean?


SPEAKER_00:
Do you mind if I just read right from the paper for a second?

Because I think it helps in terms of this difference between the automaticity and reflective aspects of this action.

One important implication falling out of this diagnosis is that when considering functional rural aspects, it's often how the details of our chosen process theories are fleshed out

and contextualized by the kinds of cognitive phenomena that we are attempting to account for

for that skew, our interpretation of FEP in one direction or another.

For example, one may consider that there are core aspects of FEP, such as the possession of a Markov blanket and more ancillary aspects, and I think ancillary is the key here, such as the possibility, but not the necessity to engage in counterfactual inference, which is only required for planning.

And it is only the latter more ancillary aspects that call for a representational interpretation under a given process theory.

This would imply that when using functional role as a sole criterion for representational processes, only some FEP agents, mainly those that can engage in counterfactual forms of inference would meet the criteria for representation.

It is only this subset of FEP agents that would be equated to full-fledged predictive processing agents.

So there is an automaticity part to this.

where it's really not a Markov blanket.

You just do it almost subconsciously.

And that's, again, the authors are trying to point this out.

Yes, if we fail, I drop the cup and now I reflect on that.

That's the representational piece.

But prior to that, I was just going through the motions.

I didn't need a set of instructions telling me to reach out for the cup.

So that's just in the author's words.


SPEAKER_03:
Thanks a lot for clarifying that.

It's like, yes, if one is reflexively grasping at it or accidentally, then grasping the cup, like if you're groping around in a dark room and then you happen to grasp the cup, it doesn't have to be representational because there isn't a counterfactual.

So

And that's very interesting how like they say that it is ancillary.

So that's kind of like secondary or not essential to it because we can imagine an active inference entity that's taking in sensory observations, updating its generative model, engaging in policy selection, and then resulting in some action output impacting the niche and the cycle begins again.

that can be just like a single layer model that doesn't engage in counterfactuals.

But they raised that notion that it's only the counterfactuals in cognition that actually like give us the space to have a functional representation.

It's like if the shell just represents the shell, can't be anything else.

but then there's another kind of entity who can see the shell as financial or can see it in a different way.

And then it's those counterfactuals that enable the shell to play a functional representational role in that it stands for something else.

Blue, what is this imagery on the bottom?


SPEAKER_02:
So I just was trying to really look at or try to visualize what would these different representations really look like, right?

So if we take the idea of

to a person and a cup even, right?

Okay.

So on the first one, right, we have organizational.

So like I am a thirsty body.

I'm contained within me.

There is a cup that contains water over there.

Like I know my boundary.

I know the boundary of the cup and the representation looks like this.

And then a structural representation is just me and the cup

And that my relationship between me and the cop, right?

Like, so do I have to also have like, like, so, so my, my real question here is do these perhaps build on one another?

So, so here you have the structural and, and, um, then the next one would be content related.

Do I also have to have this connecting line in the content related?

Uh, is that required?

Like, do I have to have an idea of the structure to understand the content?

And then in the functional, do you need to know the content and the structure and the organizational to have an understanding of the functions?

do i need to know like the content related like i know that there's water in the cup right i assume that there's water in the cup to find out i have to realize that there's an inside of me and outside of me and inside of the cup and outside of the cup i have to realize my relationship between me and the cup and then to find out the content like i have to go sample the cup like to see what's inside of it and i have to know what's inside of me and then the function like like can i only

I wonder if there's water in that cup.

And then if I go to drink it and there's whiskey in it or something, I'm not going to understand the function until I have all of those things layered on top of each other.

And so that's kind of really my question here, and Daniel's drawing on my drawings.

But really, I just wonder if there's levels of increasing complexity between these different kinds of representations, or if it's just merely the structure, the organizational, and I don't need these boundaries between self and cup in these other models.

Maybe it's just the line without the circles in the structural, or...

the no external circles and content related so i just want to know like what you guys maybe think of that if there is a layering here because i was kind of layering them up but i don't know if that's really the right mental representation thanks blue dean um


SPEAKER_00:
I'm not muted.

Good.

I think there's two parts to this.

One is that we are able to differentiate, which is what the table allows for.

And I think that the second part is the curved arrow that Daniel drew, which essentially represents boundary crossing, number one.

So the difference between something that's static and something that is translatable.

And then the second part of it, I think, without going back down the rabbit hole that we almost fell into in the point one of this, when we started talking about free will and can and will and the orthogonal piece of that, I think

What it speaks to, maybe, is that it's not a question of free or encapsulated.

It's a degree of dependency question.

When you throw that curved line on

on this sort of tiled representation and start moving across a boundary.

So I don't want to call it degrees of dependency will up to a point of passing through zero, but I'd like to, because I think there is an aspect of that.

And that's why I think it's kind of crazy if we just focus on the static things instead of the moving around.

The moving through four squares is what I really think gives our minds a good workout.


SPEAKER_03:
Yep, so here's another little workout.

So blue had two circles in relationship.

So here, the circle is going to reflect an adaptive active inference agent.

or the full-fledged predictive processing agent, one that can engage in counterfactuals.

So the top is two adaptive entities in relationship, and the triangle is going to reflect a mere active inference entity like a cup or just something that doesn't engage in counterfactuals.

So organizational is the separation of the systems.

So that's very similar because it's just describing there being a Markov blanket separating the systems.

The structural representation is having vehicles that are structurally similar.

So it's simpler in the lower case.

Triangle out there in the world, is there a structural resemblance?

That would be very representational.

Whereas if they were cognitively imagining something different than a triangle, that would have less resemblance.

But that gets challenging with adaptive-adaptive because...

We're modeling ourself, modeling each other, blah, blah, blah.

So here's them modeling the conversation.

And that's where there's sort of like very complex dynamics, which is how can we have a structural similarity about a conversation with another person?

But it's simpler in the adaptive mirror case.

The content related representations encode environmental contingencies or sensory motor contingencies.

So like in this case, the triangle, it is the case that it can rotate clockwise.

And so this entity does have a good content related representation if it can actually turn the dial to that way.

And again, that's a little bit more complex in the reciprocal case.

But in the unidirectional case, this red arrow is a content-related representation of the actual motion in the world.

And then this last case is the functional representation.

And here it still is, it could be more structural.

So like more about the actual motion

structure of the cognitive model, or it could be more about the encoding of the contingencies.

But the key piece is this isolation, which isn't a Markovian isolation.

This is actually the true vicarious separation of.

So here the person or the entity is able to engage in either structural pondering of the triangle or functional pondering of the triangle in the absence of seeing the triangle or grasping the triangle.

And again, though, that's a little bit complex when you have multiple counterfactual cognizers asking each other questions.


SPEAKER_02:
I just added a counterfactual to your question.


SPEAKER_03:
Yeah, exactly.

The red one is... Then there's the blue one.

It could go a different way.

And then this is how we know that it's a true...

cognizer and a true functional representation yes great call thanks a lot blue because it has to do with the vicarious nature with not directly seeing it but it also has to do with that representation whether more structural triangular or more functional red arrow could be different so there's them having a counterfactual um

action contingency and here they're also imagining a counterfactual structural position okay i'm gonna go to a question from steven in the chat steven asked

how do we resolve the use of the term functional as used in correlational dynamics?

So that's referring to some of our earlier discussions on like functional and effective connectivity in neuroimaging and the term functional in use, and the term functional in terms of having cognitive counterfactuals.

So how is the functional here related to

effective and functional connectivity in neuroimaging and time series statistics.

I'll give a first thought.

It's not that it can't be linked or connected, but they are different namespaces and they're totally different.

The functional connectivity in the time series is...

about how changes in one variable through time influence another variable through time or are associated with changes in the other one through time.

So it's not a mechanistic causal relationship per se, but it's just that changes in one variable have an edge reflecting how changes in some other variable change.

that does not engage either of the pieces that we're highlighting here, which is the vicarious or standing for nature, nor the counterfactual nature.

So it is a different use of the term functional.

Functional is an overloaded word.

And so, yeah, it's not that you couldn't have a paper that was looking at functional representation.

and using neuroimaging and using functional and effective connectivity of brain regions while individuals were engaged in functional representation.

But that would a little bit be like the star was the star of the movie.

It's just using a word in multiple senses in a way that may give some ambiguity to those who don't parse out the different senses extremely clearly.

Is that fair to say, or does anyone have a different thought?

Functional can also mean teleological, like the function of something essentially.

So there's many uses of function, and I think it's interesting that it has come up in these different spaces.


SPEAKER_02:
So I do agree that they're disconnected, but I am able to perhaps see a relationship in functional connectivity and also in counterfactuals.

So when things are functionally connected, one drives the other, right?

And then the counterfactual is when things are not functionally connected, there's no corresponding correlation, right?

so so in the exploration of functional connectivity you have to have all of the data points like over a time series so you have to um like you understand functional connectivity through the exploration of counterfactuals does that make sense okay how about this functional connectivity the term it is a functional representation that cognitive scientists use


SPEAKER_03:
because it could be otherwise.

They're engaging and they're saying region A and B have functional connectivity because I did the time series statistics in SPM and we got this value.

And so that functional connectivity value is able to be used in subsequent internal cognitive representations.

It stands for something and it can be engaged with in a counterfactual way.

Like what if it would have been stronger?

Then what would our conclusion have been?

Or what if it would have been weaker?

What would it have been?

And then Steven wrote, these are definitions and ways to name.

Could be where the ontology working group could have a future role.

Yes, ontology development in active inference and...

How will we even make the decisions of what terms to use and what senses and disambiguate the uses and the different corpuses that we are looking at?

So pretty interesting, this graphic, actually.

I hope any of the authors or anyone who is interested in this topic, what do you think about these doodles?

Do you agree?

Disagree?

Let's go to Blue's question about autopoiesis.

What is interesting or that about?


SPEAKER_02:
Just really where it comes in, and I think we kind of brought it up earlier in the sharing of a model.

So is sharing of a generative model necessary for self-assembly or even the attempt to share?

a generative model.

Is that a necessary component of autopoiesis?

And at what level?

Like, organizationally, structurally, content-related, functionally, like, at all the levels?

I just wonder, like, how these things are related.

And when we were talking earlier about having a conversation and trying to make your models align with one another through information sharing, and like we saw with the computational boundary of a self about

self-assembly and autopoiesis via Mike Levin, just about the informational sharing between subunits leads to the formation of a larger cognitive unit.

And so I was just wondering about model relationships and forming a larger cognitive unit.

Like we were talking about the conversation and then we formed with complete overlap of, yes, we get it.

We grok, we're there.

And then we form a larger cognitive unit.

Um, and is that on all aspects?

Is it just related to content structure, organization or function or all of the above?

Um, just what anybody thinks about that.


SPEAKER_03:
All right.


SPEAKER_02:
So we saw this actually in Matt Sims earlier paper, the biological symbiosis, right?


SPEAKER_03:
Yes.

The autopoetic system is capable of producing and maintaining itself by creating its own parts.

So it's kind of like the ship of Theseus plus crew.

They're able to be modifying and reconstructing the material basis of the system.

On one hand, that maintains an organizational separation of like the cell and the surrounding in terms of the realist interpretation of a Markov blanket.

At the same time, the autopoetic process does not need to have, well, it involves ingressing and outgressing material.

So that does blur the boundary.

And structurally, it doesn't need to be the case that the autopoietic process of the cell has like a blueprint or a structural resemblance of the cell.

It could just be subunits that are non-representational.

They cannot engage.

It doesn't even make sense to ask whether the cognitive model has structural similarity with the target

because it's a non-cognitive entity.

And similarly, on the functional side, the enzymes can't engage in counterfactuals that synthesize the lipids and add them to the membrane.

So is information a representation?


SPEAKER_02:
I don't know.

I mean, we're getting into the quantum now.

So, yeah.


SPEAKER_03:
Where's information in this?

It comes up in the paper 18, 17 times based on local information.

Information comprises the generative model.

Past and present information, future information, information gain, no additional information about internal states, that's the Markov definition.

High mutual information can be in the context of a non-representational generalized synchrony, like the pendulums that synchronize.

Where is information in this eight-fold distinction?


SPEAKER_02:
So the author talks about here, if I can read a quote quickly,

If one only appeals to the organizational aspect of representation, the presence of environmental or sensory motor or complex or frugal model does not matter insofar as the internal variables of the model are understood to be separated from external reality by a Markov blanket and the generative model is leveraged

to infer the causal structure of external reality via self-evidencing.

However, these differences matter if one considers structural aspects and the degree of resemblance between hidden variables and environmental dynamics, as opposed to action or information gathering dynamics.

So, I don't know.

Here the content of representations is used to draw a further distinction within the representational view between an internalist, sometimes called intellectualist or encodist,

versus an action-oriented perspective.

So.


SPEAKER_03:
Probably one of the most thrilling academic debates.

Dean?


SPEAKER_00:
Well, please don't judge what I'm about to say next.

Just bear with me.

Be kind.

So in this representation, for example, where we've got this table,

if we were to look at those lines, each one of those horizontal lines, because there's three IC, and each one of those vertical lines, because there's four IC, and we realized them as a standard XY graph, we know that there's a relationship between X and Y, that every one of those horizontal lines relative to Y has a zero component to it.

And we know that every one of those vertical lines relative to X has a zero component to it.

So most people will look at the blackness of that relative to the white background and they'll just see something material separating.

But if we actually look at it graphically, and we take Daniel's idea of the tetrahedron, every time we round an edge and change direction on that tetrahedron, there is a zero element that allows for that boundary crossing that we, again, don't pay as much attention to.

And so from an autopoetic standpoint, you can actually see where something like a Markov blanket both separates

and leaves the potential open for that transfer or that crossing or that transition.

So when we're modeling ourselves, the last paragraph of the section five of the paper, they wrote, arriving at an FEP as synthesis.

So some non-zero number and zero,

view depends upon which representational criterion we are assuming when either considering FEP central constructs or considering specific cognitive phenomena through the lens of a process theory under FEP.

Do we include the zero piece of this or not?

Tentatively?

Fully?

Or do we willfully ignore it?

Hence, in the end, the debate about FEP may reveal more about us

our criteria whether we want this to be a material thing and not not include the zero aspect of it and our interest in particular facets of cognition than does about the representational status of fep so i just want to kind of bring that again don't judge me because i i could be way wrong here and i may be overfitting but i think that the autopoetic part of it

We can see both the separation and we can see the portal in a line if we choose to include both.

That's kind of what I wanted to bring up.


SPEAKER_03:
Okay.

Very interesting, Dean.

Thanks.

Here's the unfolded tetrahedra.

There's a few shapes of paper that can be folded into a tetrahedra.

One looks more like a parallelogram and one looks more like an equilateral triangle where it just kind of like folds up like the petals of a flower.

So these zero lines.

So there's the zero point of within a facet,

representational and non-representational that's almost like the two sides of the paper like how many triangles are here oh four how about eight how many units how many triangle units of paint do you need to paint this four no eight two sides so the zero is like the thickness of the paper and that's also when you fold it up that's like inside versus outside of the tet

And then these zero Y lines are like the movements from one face to another face, where it's also thin enough as to be imperceptible, especially when it's laid flat, but it makes all the difference to move from one side to another.

How do we use...

Moving through zero in this eightfold or other cognitive models, how do we use that to increase the efficacy or the fluidity or the accessibility of models?


SPEAKER_00:
Does it help us in explaining that we're not locked out of that self-organization loop?

That we can actually participate in it?

Is that the first thing that it tells us?

That we're not locked out of that ability to self-generate?

That was a question.

I wasn't questioning.

It was like an honest, sincere question.


SPEAKER_03:
I think so.

One supportive or complimentary component would be, this is sort of a map.

This is like a cognitive map.

And someone could say, this side of the paper is better than the other side.

And this is my favorite face.

it's presented as part of a larger knowledge structure such that the learner could engage in counterfactuals like what if we were on the other side of the paper or what if we were on a different face so this allows for example individuals to reflect their understanding of the lay of the land but also communicate their preferences

And as the paper shows, different individuals do have different outcomes in terms of their cognitive conclusions.

And that's what reveals the super fascinating thing about us.

And that's why the paper is modeling ourself

what the free energy reveals about our implicit notions of representation, not free energy principle modeling representation, what the free energy principle reveals about representation, which would be a slightly different paper and title.

So just the scholarship and the sense-making phase that only very few have to engage in, like Sims and Pizzulo have, is to make these

maps and then bring the perspectives that were not integrated to be shown as just different locations in a phase space like we put four zeros but so it's not as simple as just like two numbers but you know if there was if it was just two topics being against each other

Every perspective could have a position in that phase space.

And then what do we do with that?

Yes, Danielle.


SPEAKER_01:
I guess I'm thinking about the ourselves part of modeling ourselves.

I'm not really thinking about...

all humans and the way that our minds work.

It's more of the academic conversations that have been happening around the sort of intellectual tradition that's been happening around representation.

And so the contribution of this paper, as I see it, is that, look, we've got this framework that does a lot of work for us in a lot of different disciplines.

And if we apply it to this conversation, this intellectual debate,

that's been happening, we can reveal implicit assumptions of the debate itself.

And what emerges is that perhaps as an artifact of particular examples that have been used to understand representation, we see one side of the coin or another.

We can see these, we pull on these different dimensions that are

laid out in this paper.

So I guess it's just important to think about and disagree if you disagree.

But the ourselves is really just about the way that philosophers and cognitive scientists have been thinking about this.

Nothing is true.

This is not revealing something about cognition per se.

It's more about the implicit assumptions that have been kind of unfolding and how we're thinking about the discipline.


SPEAKER_03:
Thanks for that.

Just like there was a sort of hinge on the functional being used in two different ways, another sense of representation, one that might be more commonly used outside of cognitive science would be like representation in terms of different perspectives or identities in a group.

And then that made me think of nothing about us without us,

which is used in different contexts, but basically has to do with participatory decision-making that decisions are not being made in a way removed from the people who it influences.

And that has to do with representation, no taxation without representation, for example.

And so cognitive science is,

is actually in a nothing about us without us.

Because if there's just an academic discussion, especially an unexamined one with a lot of implicit baggage about

a hyper-intellectualized, hyper-abstracted scenario.

Or like, we like to study representational organizational cases where it's super clean.

These are the ones that we study.

These are the model systems.

These are the kind of careers that have been built in academia, for example.

But it's about us in the broader sense, like humans, and then even us as cognitive entities.

And so...

it is the philosophers and the literature that is in this paper, as Danielle kind of highlighted, that's the modeling ourself.

The selves there are the participants in the discussion around representation, which of course has been textual, abstract, English speaking,

qualitative, other adjectives.

So it's another interesting connection there.

Blue?


SPEAKER_02:
So definitely the subjectivity that Danielle highlighted is a big part of perhaps why we have these organizational, structural, these different viewpoints.

But maybe something that I don't think is really emphasized too much in this paper is

is kind of the realist versus instrumentalist viewpoint of active inference.

And so there's a pretty big argument in the literature.

And I think probably the math is not the territory maybe gets into it the best, maybe, or in the most detail of the papers that we've studied here on this stream.

But there's,

people that say like active inference is a way to model the cognitive process or the action perception process that we all undergo.

And then there are people who say that this is actually happening in a computational way in the brain.

It's not a model of, it is how it works.

And so there's this ongoing like vision fusion feud

happening in the active inference community also.

And I just wanted to highlight that because, yeah, because you may not know.


SPEAKER_03:
Thanks a lot, Blue.

I pulled out a few quotes because I also noticed that when we, it was one of the earlier quotes when we were talking about the, I think, organizational element.

So look at how often reality comes into play in these conversations.

Discussion, so internal variables of a model.

Okay, so we're talking about instrumentalism, right?

Like models are understood to be separated from external reality by a Markov blanket.

Wait, reality?

And the generative model, model, is leveraged to infer the causal structure of external reality.

So it flips four times in that sentence

from reality, from model to reality, back to model, back to reality.

It doesn't make it right or wrong.

It's just a very interesting epistemic artifact.

Because within the reality of the model,

like the reality of the map, it is the case that the internal variables are separated.

And if the model is trying to do determination on that level of reality, like maps trying to infer maps, that is reality.

But then that's not the sort of layer one

external reality in the sense that many people often mean or use it.

Dean?


SPEAKER_00:
Yeah, I think, Danny, if you take the words reality and model and push them out into even more extreme tales, you could see the model.

You could see people who are pushing back against the model idea, and they're arguing you're just too rigid, right?

You're just too stuck.

And you can see people that are taking the non-representational sort of reality view, the variance view,

maintained or retained view as say, you can see the people that are on the model end of the continuum saying, that's just chaos.

There's nothing about that that we can actually make sense of because the cognitive overload right now is just swamping me, right?

And so I think what these authors were trying to do is say, well,

Can we move back and forth instead of getting stuck on those really far out positions in terms of this way of being able to see when we have these densities, right?

And then how do those densities re-reset back to some sort of invariance and then re-reform?

Right?

So I think that's, I hope that kind of speaks to what Daniel was saying too, because sure, we can point out the most extreme example, like at the very end of the continuum, or we can actually talk about how we're going to draw these unidirectional or bidirectional lines and boundary cross.

And I think that's what they were trying to open our thinking up to, but...

Maybe I'm just being Pollyanna here because I really like the paper animal.


SPEAKER_03:
Interesting point.

Realism is also used in another way, which is kind of like it's a school of literature or a thread of literature.

And so then I found this paper, Affect of Realism, Evoke Realism Beyond Representation.

And so this is in the case of literary expression.

So that's an activity that cognitive entities are engaged in.

And we just see a lot of terms that we talk about in ACT-INF, like agency, affect, process.

And here it's not about reality, realism, territory, it's like realization.

And realization is an interesting word.

And I know Verveke and others use it as well because realization, it is about the model.

But when something is realized, it becomes real in the model.

But usually we wouldn't say that something is realized like, oh, I just realized that zebras have nine legs, right?

It's like you engaged in a counterfactual, but is it a realization if the model is updated in a way that isn't concordant with reality?

And I agree that the paper gives us a lot of nuance to talk about these areas because we can talk about how, well, the isolation of the variables doesn't change, or the structure of the legs and the zebra

doesn't change or it can still run, right?

So why not nine legs?

Is it still a zebra?

There's a lot of open threads, but the way that they use model and reality in light of a lot of the other discussions we've had is really illustrative.

Blue?


SPEAKER_02:
So one of my favorite things to think about in terms of the realism versus the instrumentalism is the Markov blanket.

I was looking for the picture of the person sleeping under the Markov blanket.

Really, as a partition for a system, do systems have Markov blankets?

Or can they be modeled with Markov blankets?

And I always just like,

Think of that cute little picture with the little person sleeping under the Markov blanket.

Like, do I have Markov blanket wrapped around me?

Um, because that's really where it, um, tends to break down in my mind.

It's like, yes, there's a boundary.

Um, but I'm not sure that it's a fist and blanket or a Pearl blanket or a Markov blanket.

Like maybe it's just skin.


SPEAKER_03:
Um, yes, Dean.


SPEAKER_00:
I hate answering a question with another question but in the conclusion of the paper the authors speak specifically to the free energy principle can be very heuristic and so I'm wondering in the instrumentalist versus realist debate whether it has to necessarily get up to that abstract level of Markov blanket or whether we can just say that sandwiched between those two are rules that we demarcate, that we

we lay down and that we have act as a parsing mechanism.

I don't know.

What do you think, Blue?

Like our rules are rules, things that we can just get our hands on right today instead of having to go all the way up to figuring out what a Markov blanket is under this set of circumstances.


SPEAKER_02:
No, I think definitely rules, right?

So, I mean, we all agree that there are laws in physics.

Like, if you drop an apple, it will fall to the floor.

Like, we all abide by these rules.

They might not apply at every scale, but I definitely think that a rule-based construction or understanding, like, does that then bridge the realism versus instrumentalism debate, perhaps?


SPEAKER_03:
So...

Building on the point that the ourselves in the title is the people reading the paper.

So not just like people in the psych department, but it's the ourselves, the people who are in that epistemic commons.

So using that, but also the content related representations in terms of correctness or truth.

So if the ourselves are those who are pondering FEP, then the heuristic that they refer to, we conclude by highlighting the heuristic power of the FEP to advance our understanding of the notion of internal representation.

It is pretty meta because we're representing the debate about people representing the debate about representation.

However,

the fact that it has a heuristic utility within the content related aspect at the very least it does have representational impact i'm not sure where that takes us there's probably other ways to take it but i think something about um the diversity of conclusions that people have and how that shines a light back on us or is a mirror

and how the FEP has been applied here in this paper as a heuristic for sense-making in this meta-debate says something, I hope.

Danielle?


SPEAKER_01:
I hope I'm addressing what you're saying and not taking this in another direction.

Stepping back, I'm thinking of FEP as just one of many different tools of thought that we have that allow us to align our representations.

And if it is an effective tool, we all start having a conversation that makes sense to each other, that's mutually intelligible.

In this case, it is kind of meta because it's about how

the academics, the intellectual conversation about representations have failed to converge on something.

There's this debate.

There are many layers of the debate.

And so what it reveals is that we haven't yet converged.

The community hasn't converged.

And so FEP is

is this thing that we can use that reveals those things and allows us to then better, because it's revealing these things, we can all attend to those things that were implicit and are now made explicit.

We're converging our representations.

So I think that kind of addresses what you're saying.

It's about representations, but it's also this tool, like there are many other types of tools that allow us to realize what we've been taking for granted and align our representations.


SPEAKER_03:
Thanks a lot.

Dean?


SPEAKER_00:
Yeah, just to add on to that, if you're like me, you think rules and tools are interchangeable.

And the other thing you think is that if it's a heuristic, it speaks kind of to that vicarious function in terms of content.

So I just want to throw that on top because I think there's some agreement around that.

We use the rules to make that next vicarious play before we make the next move.

So, I mean, anybody that doesn't is kind of kidding themselves, I think, but maybe I'm wrong.


SPEAKER_03:
Okay, here's a little bit of FEP in a heuristic case.

So we've talked about the Helmholtz decomposition of vector fields, like in stream number 32, about how there's this pragmatic or sort of hill climbing or gradient descending component, whether you take the optimistic biology, climbing mountain probable, go straight up the mountain of fitness, or the physicist's

gradient descent into the bottom of the well.

In either case, there's that irrotational component that's associated with pragmatism.

And then there's this epistemic component that's associated with the solenoidal isocontour.

So we've talked about that Helmholtz decomposition.

So here's one way in which the FEP is being heuristically applied.

So Danielle said, the academic conversation on representation has not converged.

And it has not converged.

And it has also not even cohered.

Like there isn't a shared ontology.

There's not a shared narrative.

There's not shared words or regime of attention or what people are even focused on.

And so what the FEP is doing literally like they did here with this distinction, it does a few things.

It holds space for not overfitting.

Like let's just say in 2055, all the people in the world or all the cognitive scientists, they all agreed.

Oh great, we converged.

Let's lock that in.

But FEP even then will remind us like not to overfit

and also not to center one side of the tetrahedra.

We could say, this is the side that has these attributes, or we focus on this side for these reasons, and no one goes there to this other side, or there's a reason why we don't go there, or we take a journey, we travel through there, but we don't live there or something like that.

It brings a level of coherence to the discussion that

doesn't necessarily have the goal of perfect static convergence but still there'll be solenoidal flow and differences in opinion even then um who said the fep wasn't useful


SPEAKER_01:
Well, and maybe this is obvious, but is that not what any good theory does?

Like Blue said, well, gravity is true because if I drop an apple, it will fall.

Yeah, so the theory of gravity does the same thing.

It allows us to kind of converge our representations.

It's just that the theory of gravity is not itself about representation.


SPEAKER_03:
Yes, this is like the hall of mirrors, this paper and conversation, because it is like, it's the group of people in the hall of mirrors and they're all wearing mirror suits in a weird way.

But it is our gem for building the kind of frameworks that then can reduce our uncertainty a ton

potentially in similar cases.

And the strange loop of reflexive cognitive entities is going to be this open-ended bount for a long time to come.

But just like how we started here with a really complex reciprocal case of two adaptive entities, but then it was a lot less ambiguous here.

And I wonder if...

active informed system design will frame an increasing amount of pieces especially in a digital world into this bottom tier offloading some of the repetitive tasks attention consuming tasks anxiety producing stimuli into these type of interactions which opens up new spaces for these kinds of interactions with the two adaptive entities

To return to that having or possessing a Markov blanket, just one quick point was, which we already even read the quote, which was a core aspect of FEP, such as the possession of a Markov blanket.

So is the Markov blanket the system?

Or does it have one?

Those are both realist.

Or is it modeled as having?

Is it modeled as being?

Those are instrumentalist ways of similar framings.

And how do we know what the core aspects are?

What

does that stem from so there's a ton to learn and discuss there and then let's look at any in just our last few minutes any of the other topics and if anybody wants to highlight one of these or also maybe as we jump off from 36.2 to 37 and beyond

when we discuss free energy a user's guide but also we just continue on our paths like why does it matter not all these papers maybe make the argument for why this whole representation debate matters so what is the pragmatics

that make this meaningful, make it important to fund people working on it or the way that it influences the technologies that we're developing rather than just a pure info gain reduction of uncertainty question.

So any topics here or any like thoughts on how this will or could or should influence our action selection going forward?


SPEAKER_00:
I'm comfortable with long silences, but I'm going to throw this out there.

I think people will be able to use this tool to become more creative, not just be able to reduce or minimize their prediction errors, but actually have the confidence to come up with new and different ways of looking at problems that we probably didn't have in our toolkit before in terms of being able to come up with something different.

And so I think

the first thing that it does is it allows for a boundary crossing that maybe we constructed in our minds before, but we're seeing less and less of it as being a hard stop.

And there's now maybe a little bit more

More say in whether to go or don't go.

So that's what I would think that this kind of work is maybe opening up.

Unless somebody comes and shuts it down.

And I can't speak to what outside forces would find terribly threatening, but I'm sure there are some out there.


SPEAKER_03:
Outside.

Luke?


SPEAKER_02:
so I'm not sure if this has any pragmatic value, but I'm, I'm certainly interested in kind of really exploring like sensory motor engagement and structural representation and maybe like synesthesia.

I know Daniel's been to Meow Wolf, but like,

You know, when you're playing these invisible, like the invisible harp, you know, and it's like, could you structure a room, like draw a map in a room?

And your goal is to like, kind of like an escape room, but your goal is to find, navigate your way through based on sound, right?

Like you ting the things and you have to find the right sound.

You're playing Mary Had a Little Lamb and then you get to your prize at the end or you get to get out of the room at the end.

So I wonder creatively, like Dean was saying, like really these maps, these representations, can we get literally out of our own representation and into the feeling of an alternate representation?

And what would that feel like or be like?

And that's also why I brought up like blindness.

Like, you know, if you ever wake up and like a totally, like my power went out the other night and it was like black.

I mean, no moon, nothing.

It's just like, whoa, total darkness.

No little blue light from the plug or nothing.

So in these total darkness situations, you have this representation of what does my house look like?

Where's my flashlight?

You have to be able to navigate yourself in a totally dark situation, which is very foreign.

to go find a flashlight.

And so I like these kind of boundary pushing experiences because they really force us to examine our own model and perhaps allow us to explore the kind of models that other people use.


SPEAKER_03:
Thinking through other minds is this case with adaptive agents in dialogue.

And it's like thinking through other representations and this paper and discussion opens up not to then simply converge, but opens up and holds ways to think and act through other types of representations, not just the same type, but in a different cognitive entity.

it comes up a lot and it'd be awesome to see how just as so many other themes that we've had raised by very prescient papers like 14 math is not the territory 20 emperor's new markov blanket and some of the further nuancing about the markovian assumptions

this representational and non-representational and these words like organization structure content and function they will come up again and maybe they'll be citing this paper maybe they won't but like

It's almost like when we see in a future paper, just one facet of the Tet and they'll say, here's how it is.

It's this one side.

It's like, well, no, there's other sides and we could be inside or we could be outside.

And someone could still say, I prefer this one, but we know there's a bigger system that we can at least come to the table around Dean.


SPEAKER_00:
I'm not marketing, but it's going to come up in 37.

It's going to come up a bunch of times in 37.

So that's just the next paper.

So anyway, hold on to your socks because if you think you have to wait for it to come up again, it's going to come up again next week.


SPEAKER_03:
Don't touch that dial.

Thanks a lot for the awesome sequence.

This was a somewhat complex or intellectual paper.

I mean, they're all written, but this one was like challenging topics, a lot of different perspectives.

And then not only did they

hold it open for all of the different perspectives, but then rather than pick a winner, they flipped the table in the end and posed it not as an answered competition for us to then have like domain specific clarity of action within, but really a challenge on multiple levels.

for researchers who are familiar with FEP and not.

The big question we asked was, can the free energy principle help us advance or even resolve the long lasting debate on internal representation in philosophy of mind?

We certainly asked.

So,

If anybody has any last comments they wanna make on anything, they're welcome to.


SPEAKER_00:
The last word, so I'll get this in real quick.

I think that if we're still arguing about whether or not representation and modeling is heavily dependent, like that there is a dependency, I think that the more philosophical

views that we see come up around FEP and active inference, the harder and harder it is to make the case that we can remove that dependency or somehow just see the scale-free aspects of this tool.

That there's actually a heavy dependency on what we're going to get out of representation or non-representation

based on our awareness or our realization that every time we cross a boundary, that is just an independent act.

That's a highly dependent act.

So that'll be my last word.


SPEAKER_02:
So I just want to give a final comment.

You know, we talk about instrumentalism and realism, and then there's like the third axis of utility.

And I really think that this paper was super useful in prompting new questions and holding up these different views of representation and non-representation and in these different categories and allowing us to really kind of view them through like a partitioned framework that I think will drive

future questions and really be useful in helping researchers formulate their theories.


UNKNOWN:
Great.


SPEAKER_03:
Danielle, if you're still here, thanks for joining for your first stream.

Do you have any last comments?


SPEAKER_01:
Well, this was a wonderful introduction.

I'm curious how representative it is of other conversations.

It was super heady in a really pleasant way.


SPEAKER_03:
It was not representative or representational of other conversations.

No.

Thanks a lot for the awesome convo.

Everyone's always welcome to join these discussions or other lab activities.

So thanks again to the authors and all the participants here.

See