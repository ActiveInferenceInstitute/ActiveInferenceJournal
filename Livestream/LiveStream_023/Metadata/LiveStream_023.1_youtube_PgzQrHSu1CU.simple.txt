SPEAKER_01:
Greetings.

Hello, everyone.

Thank you for joining live or in replay.

Today, it is May 27th.

Is that true?

Not even close.

Not even close.

It's June 8th.

It's June 8th, 2021.

We're here in Act-Inf Lab Livestream 23.1, and we are discussing the paper, Embodied Skillful Performance, where the action is.

So welcome everyone to Active Lab.

We are a participatory online lab that is communicating, learning, and practicing applied active inference.

You can find us at the links that are here on this slide.

This is a recorded and an archived live stream with all of the advantages and constraints that that provides.

Please provide us with feedback so that we can improve on our work.

All backgrounds and perspectives are welcome here.

And we'll be trying to follow good etiquette for live streams.

From this short link, you can access the calendar of events for live streams of multiple different kinds.

And highlighted there with the blue arrows are today's discussion on June 8th and next week's discussion that'll be on the 15th.

And they're both gonna be on this paper, embodied skillful performance.

So we had a good time making the dot zero and learning about this and kind of opening up

what this was adjacent to and now we'll look forward to continuing the discussion and just seeing where it goes for those who are watching live it would be i guess especially appreciated to throw us some questions whether they're related to the paper or not

The goal for today is to discuss and learn.

The paper is Embodied Skillful Performance, where the action is by Hippolyto, Baltieri, Friston, and Ramsted from 2021.

And today in 23.1, we'll be ambling skillfully, we hope, through the paper again and

flagging areas where we wanna be talking with the authors next week.

Greetings, Dave.

Welcome.

And just seeing where we get to, opening up threads and kind of enjoying the middle part of the .012 sandwich.

So we can begin with the introductions and the warmups.

Today, there's a few of us, so we can go around in the introduction and just give a short introduction or a check-in, and we can also then pass it to somebody who hasn't spoken, taking a look at the warmup questions.

So I'm Daniel, I'm a postdoctoral researcher in California, and I'll pass to Dean.


SPEAKER_02:
Yeah, I'm Dean.

I'm up here in Calgary.

And I'm getting more and more involved with this idea of sort of building up the active inference profile.

I'll pass it to David.

Dave is there.

But if he isn't, I'll pass it back to Daniel.


SPEAKER_01:
Dave, you're welcome to join in whenever you would like.

I hear you tapping a little bit, but maybe whenever you want to speak.

Otherwise, what is the Active Inference profile?


SPEAKER_02:
That's what I think we're trying to build out here.

I think we're trying to give that some anchors and some leverage.

So we haven't figured it out completely yet.

It's like everything in Active Inference.

It's a generative model.

It's growing.

And I don't know what its final form will be or if it takes on a final form even.


SPEAKER_01:
Are there other areas that have profiles or are there other profiles of note?


SPEAKER_02:
Yeah, I think there's convention.

That's already an established profile.

And I don't know that this has got to that place yet where we can say it has a convention or something that's predictable about it.

And I think that's what makes it kind of, well, in my mind, it makes it curious.

Where is it going as opposed to where it's been and what it's established so far?


SPEAKER_01:
nice points agreed active inference especially in these nascent times it's like a strange attractor where people come in from so many perspectives and then they get slingshot out in a different direction or with a different um memory or different view so dave no worries about the hardware mystery everyone is welcome to just type in the youtube chat if they have questions so i think for the rest of this stream

we're going to walk through again, maybe thinking again about walking as a skillful action and all the fun similarities and differences between motor actions, which are what are discussed here and that sort of space where motor and knowledge come together like with skilled action.

Yes, Dave, your different embodiments are muted indeed.

So the paper,

uh laid out their aims and claims and the central aim of the paper according to the authors is to discuss critically the limitations of instructionist control theoretic models of skillful performance so the big dichotomy or dilemma that's going to come up again and again is this difference between interactionism and instructionism so maybe dean

Where are you coming at that from or how would you describe the difference between instructionism and interactionism?


SPEAKER_02:
Well,

Well, first of all, even including interactionism as a formality, I think is a huge step.

It's metaphorically speaking, it's opening both of your eyes.

You have a second eye available, but maybe you weren't aware of it.

And now with the idea of turning that into sort of a structured or formalized approach as opposed to just...

the instructionalism piece, which is traditionally what we've formalized is it's not just a doubling of what we might be aware of.

It's actually placing ourselves where we can see the depth of what we're observing or what we're analyzing or what we're addressing.

And I think that that would be a huge step if we could get people comfortable with that.

I'm not saying that people will necessarily get comfortable with it, though.

Because for a lot of people, let's be honest, just following along and being instructed is difficult enough.

And now you're introducing a whole second lens of information.

And very quickly, you'll have a bunch of people screaming, no, you're going to overwhelm them.

You're going, well, I'm not.

Just because I have both my eyes open doesn't mean that I'm going to be... I hope it doesn't mean I'm going to be scared.

I hope it means that I'm going to feel a little bit more grounded and centered.

But we'll have a conversation about that today, especially when we include the whole body.


SPEAKER_01:
Yes, the entire corpus.

One thought there, instructionism being like instructions are passed from A to B, you know, water flowing downhill.

Instructionism has a directional context and also the idea that what's being passed is the sort of packet of meaning.

Like, here's the envelope with your instructions, now carry them out.

and what i think is exciting about interactionism is it's not just a bi-directional instructionism it's not like well you instruct me and then i'll instruct you that's sort of the the low bar for interactionism but where interactionism really blows the lid off is when we open into that third space of interaction and improvisation so i think that's what's kind of

Interesting to draw out, and they are going to highlight in this paper how control theory models of skillful performance or otherwise, implicitly or explicitly, do have instructionist assumptions.

Specifically, this idea that motor representations convey or harness instructions about how to perform a specific task.

So even if the authors of those control theory papers didn't explicitly use the word instructionism, then they're still playing into this idea that instructions are being passed, for example, from the brain to the body in order to be carried out.

And we'll be looking at that from a more formal perspective in a few minutes.

And the big claim that they're going to be reaching is that Active Inference doesn't need to posit that instructionist assumption.

So there's a way to frame control and skillful performance in the Active Inference framework that doesn't take on these instructionist assumptions and the content based directional message passing that it entails.

And that'll be something fun to explore.

Also, Dave has a nice comment in chat.

Dave wrote, as I recall, Piaget and colleagues counted and described something like 400 distinct embodied concepts used by the walking skills of a typical 15 month old.

So that just shows how there's a lot going on, even with, uh,

behaviors like walking.

Cool.


SPEAKER_02:
One other thing too, the assumption that somehow the muscles and the nerve endings sending signals that are in symbolic form is quite a stretch.

I mean, we talked about that last week when we got to that inverse directionality slide.

But I thought about that a little bit after because I went back and watched

after last week, and I was just like, I know for me, I was incredulous a couple of times when we went through the paper with Blue, but even going back and looking at it, you'd have to build a really powerful argument that says that the pressure signals on my fingertips are coming back to me in verbalized form.


SPEAKER_01:
Exactly.

It's this idea that, you know, the files are on the computer, like what's coming up from the fingertips is pain and what's going down is an instruction.

That's sort of the Cartesian dualism mapped onto instructionism is just like body and brain are two disjoint pieces and they pass special symbolic information to each other.


SPEAKER_02:
Right.

And we'll see how that... Then our brain and our body is having a conversation.


SPEAKER_01:
So what is it, if not a conversation, or could it be beyond a conversation?


SPEAKER_02:
Right, right.


SPEAKER_01:
Nice.

Cool.

We covered the abstract last time.

All we'll point out here is just that they start as good philosophers with an examination of the instructionism and what that entails.

The second and third sections of the paper are characterizing the representationalism that's related to these motor commands, kind of what we were just alluding to, and a special focus on the optimal motor control theory.

And then the final sections take it to predictive coding and to active inference, which are formal frameworks for modeling behavior that are related to control theory formalizations, but the goal of the paper is to show that some of the instructionism is left at home, which allows us to go out with interactionism.

Here is the roadmap framing a similar outline.

and also just giving a few more signposts along the way with the figures and the box and whatnot.

The keywords provided here were helping us understand what did the authors want to have their work indexable near.

In the semantic net of literature online, how did the authors want their work to be grounded?

And it was in skillful performance, that's in the title.

Optimal motor control, that's the sort of scapegoat or foil, that's the contrast.

Maybe even bringing us back to contrasting divergences.

Instructionism, again, tied up with the optimal motor control.

Motor representations lending us into action-oriented representations and finally taking us to active inference where we kind of begin and end.

So skillful performance can mean many pieces and the authors defined it as opposed to bear movements, such as breathing and blinking, skillful performances are intelligent bodily activities, which harness knowledge about how to perform certain movements expertly.

It reminds me of the eternal debate who slash what is intelligent if an insect knows how to walk or if it is trained to do something versus if it's something that its body provides the training for inherently.

What is skillful?

So definitely we'll want to ask the authors and anybody in the chat and anybody who joins us next week.

What is skillful performance?

What is unskillful performance?

If somebody tries to do a skillful performance and fails, is that still within this category of behavior?


SPEAKER_02:
I saved up for this week because I wanted to get to the

after the comma, the which harness knowledge.

I kind of hinted that that's, I wanted to ask a question, and I still do want to ask a question.

What does that mean, to harness knowledge?

Consciously?

Or can you get to a place, I mean, Blue talked about this, you talked about this.

Can we get to a place of doing it automatically?

Does that mean it's harnessed, just because we're not thinking about it?

And how much time did they spend looking at that piece?

Because that kind of demarcates out what skill is.

If it's a dependency on harnessing, then how do we define that?

How do we define what's captured and what isn't?


SPEAKER_01:
And the harnessing brings up kind of like harnessing or yoking a buffalo or a horse or something like that.

And that's kind of hinging on that word.

It's like the knowledge is that wild stallion.

And it's actually the bodily activities

which harness that knowledge because when you quote know that your body can move in many different ways but skillful performance is when that is harnessed it's when it's connected to an instrument or whether it's its own instrument and it's channeled in a way maybe that's productive or expressive well at a fundamental level we have to again be careful


SPEAKER_02:
that something going on at our fingertips is being harnessed by something going on three and a half feet away?

Yes, connected, but is that an assumption that's verifiable?

Is there an actual harnessing going on even?

Because lots and lots of times, things happen at my fingertips that I'm not


SPEAKER_01:
sending i'm not even aware of what my hand is doing my wife tells me stop jiggling right just because i got nervous energy or whatever i think that's going to come back also to the predictive processing and predictive coding frameworks which is sort of when the body is getting the sick the signals it expects like if you're not consciously bringing your attention to you know your foot

If it's just your foot in the shoe, it feels like nothing or there's no attention paid to it.

And you can kind of shine that light of attention on it and it will feel normal.

Or maybe you can start to zoom in on other sensations like tingling or other feelings.

But the sort of default state when you're not paying attention, things that are happening the way that you expect is normal.


SPEAKER_02:
And that's why that active inference piece is really interesting.

Because in order for it to be active inferencing, there has to be some kind of attention or awareness being paid.


SPEAKER_01:
And that's like, it's attention as a resource.

Got to pay the cost of attention or suffer the regret of not paying attention.

And Dave wrote, trying and failing, especially if part of the problem is choking, which was brought up by the authors in the paper as well, is likelier to involve more neocortical activation and more access consciousness than smooth performance of the same routine.

So trying and failing, there's a lot more inner dialogue or thought process, like awareness happening.

Whereas when something is performed skillfully and smoothly, it just sort of goes off without a hitch and just, you know, you whip out the instrument

make your shot or your swing or whatever it happens to be.

And then maybe you can narrate in retrospect, but in the moment you're not having as much awareness.

So that's something.


SPEAKER_02:
One last.


SPEAKER_01:
Oh yeah.


SPEAKER_02:
So this is really interesting to me because again, is it skillful to be in the Peloton and be, be pulled along by what we would describe as the intention of those people

front of you is that considered to be a part of this because there's a lot of things that we're aware and conscious of and some things that happen in these skill performances they're just because they're part of the collective they're they're caught up in the inertia of the moment and is how do we how do we factor that in when we're talking about active inference because I think that's what instructionalism doesn't attend to

There's many, many things that are going to get dragged along here just because they're drafting.

And how do we address that when we're talking about skill performance, skillful performance and interactionism?

Because interactionism at least says I can be caught up in an inertia moment.

I don't have to explain it.


SPEAKER_01:
absolutely um instructionism has to pitch and hole everything into that symbolic information theory what is the instruction from the front of the pack of the flock of birds or the peloton of cyclists what is the instruction that's getting passed back

And so we have to go from what we know is just happening, which is like the physical inertia.

There's also a narrative inertia.

There might even be just an air current going over the person that actually stabilizes them in their spot.

We don't need to fall back to referring to those as instructions when they're clearly interacting phenomena, different types of interactions.

You could have somebody breathing heavily next to you and that could give you a signal, but it's about the unpacking of that interaction and then where that takes the collective rather than again, just thinking about everything as connected with wires and passing secrets.


SPEAKER_02:
Right.


SPEAKER_01:
Cool.

um we can look again at the active infer plants so this was just asking where are the limits of skillful performance if the niche and the fitness to the niche is what counts for different organisms our human cultural niche has all these awesome kinds of skillful performance and otherwise but what about

other creatures?

What about other phenomena, the kinds of things that we might want to also model with active inference, but just don't quite have that same level of maybe thinking through other minds as we have with people, whereas we try to put ourselves in the shoes of somebody else?


SPEAKER_02:
Do you think, Daniel, that that plant has got an embodied technical skill?


SPEAKER_01:
Welcome, Blue.


SPEAKER_02:
Hey, Blue.


UNKNOWN:
Hi.


SPEAKER_01:
We're just wondering whether plants have the... This plant.

Oh, this plant.


SPEAKER_02:
This plant has a technical skill now that it has the tools to be able to move from side to side.


SPEAKER_01:
It's a great question.

I wonder if it could be shown that it got better at moving from side to side, that would start to look increasingly skill-like.

And I think it's that idea that the molecular changes could occur that would allow the plant to respond faster.

Or you could imagine selecting on a whole greenhouse of plants, and the ones that are able to switch faster

those are going to grow faster and then you select the ones that grow faster based upon their ability to learn in that generation so it kind of shows how you get this development of skill within a life that's development but then between generations you can also have the um entrenching or the canalizing of learned skill like language

And skillful performance in this paper and in our slides, it's kind of like we're hinting a lot at this full body type performance, high jump and things like that.

But of course, language is maybe one of the examples of skilled performance.

It's a motor behavior.

It involves a huge number of interacting motor subunits, voice box and the mouth.

And...

speech therapists and others that they go deep into that but speech is almost like the case where you say well surely instructions are being passed that's maybe the the high watermark for where interactionism could go would be to have a speech

a framing of speech that moved us beyond instructionism because this seems like clearly the transmutation of semantic or symbolic information into not directly related motor behavior.

So that would be kind of a nice case to investigate.

And Dave wrote in the chat, it seems odd that dogmas that have been known to be false for decades are still premises of so much funded professional activity.

I'm thinking of BF Skinner's insistence that all control activity must be strictly cortical, even though it's been known since at least the 50s, purely on the basis of speed of nerve conduction, that that would prevent graceful walking, let alone faster and more intricate movements.

So that's pretty interesting.

we have almost just anatomical reasons to know that not everything can go through this sort of control and cognition in the loop.

There's just not fast enough transduction along the nerves.

So there has to be this sort of distributed function more consistent with an interactionist framework than an instructionist framework.

Yet it's easy to fall back to,

Instructionism, maybe, especially for professionalized areas.

Let's go to optimal control, blue, if you want to, feel free to add anything that you'd like.

Optimal control theory is a nice bridge point.

because in the paper, and as we'll be going into, we're again, thinking about motor behavior, but control theory is something that applies to the electrical grid, to logistics, to,

robotics which are i guess motorized but optimal control theory is a framework that expands to many non-motor systems as well so that makes me wonder about whether we can also apply that instructionism versus interactionism contrast to control theoretic situations that

are implicitly instructionist.

Like there's an algorithm and then it sends the buy order to the unit that makes the purchase on a market.

Or it sends a certain piece of information to a different computer that then enacts that suggestion.

And then even in systems where we know instructions are being sent, like computer systems, maybe there's an interactionist way to think about that too.

Any other thoughts or?


SPEAKER_02:
Does optimal control essentially place all of our chips on the top down aspect of the relationship between top down and bottom up?

Does it optimal control, say, optimization happens exclusively from a top-down directionality that there is really no place for the bottom-up part?


SPEAKER_01:
I think it's a good question, and I'll skip to this Friston 2011 paper, which is entitled, What is Optimal About Motor Control?

I wonder if um that optimality does arise from the top or um what is optimal once we move beyond instructionism there's a perfect set of instructions there's a perfect way to do it and then that is either carried out faithfully or it's not


SPEAKER_02:
So philosophically, if you said optimal would be some openness to both an ability to recapitulate and an ability to discover, to be able to put those two things into some sort of coherent relationship.

I'm not saying that that's what is being said here, but I'm just not sure why we always assume that optimal is always about being able to create copies.

Even in skillful performance, even compared to a standard, there are things that happen when a gymnast does their routine where some...

some element of the variability that applied to that situation is considered when something is being judged.

I think the only thing that doesn't factor in variability is the clock, right?

Like you either ran 9.8 seconds or you didn't.

But many of the skillful performances that we pay attention to,

aren't always about recapitulation.

So it's interesting.

I don't know.

I guess, again, it's all how you define it.

But we actually want to get on to doing something useful here.


SPEAKER_01:
Yep, and also here's a line in that first in 2011 that reminds me of Dave's comment, which is these estimates, which are coming from a predictive processing or active inference framework can finesse problems incurred by sensory delays in the exchange of signals between the central and peripheral nervous system.

So the generative model can include space for that delay

When we think about just sort of two people who are talking and accounting for each other's delay, for example, in that kind of an interaction versus the send, process, wait, send back model, there's actions that happen faster.

Another example of that maybe would be like baseball, where there's such a small amount of time to decide whether to initiate the behavior of swinging.

um and this paper from 10 years ago laid out just such an interesting difference between value learning and active inference which allows for that pragmatic and the epistemic component the optimal

suggests multiple things.

First off, it kind of suggests that there is an optimum that is being achieved.

So that's one easier point just to say, okay, well, maybe there's an optimal way, maybe there's not an optimal way.

But what is being optimized is the value.

Just like reinforcement learning, what's being implicitly optimized here is a value function.

And just as it says here, the replacement of value and cost functions with prior beliefs about movements removes the optimal control problem completely.

So this idea of the value and cost, it's kind of like an economic analysis of motor behavior.

So then let's just imagine that any number of circumstances, like somebody has a...

belief about how a performance will be viewed socially well you could couch that in reward and you could try to go break down from the narrative and the social all the way down to the movement of the fingers on the piano about the value and well if you mess up it's a lower value action but you're getting really far away from the embodiment of the performance which maybe doesn't have

that same sort of cost all the way down so it's like will we have cost functions and economics all the way down and value and cost or will we have generative models and an instrumental way of thinking about action blue anything overall otherwise also anyone who's watching lives welcome to ask a related or an unrelated question

I'm good.

Anything after last week's discussion that you'd been thinking about?


SPEAKER_00:
I'm trying to remember last week's discussion.

Refresh my memory.


SPEAKER_01:
Yep, that's what this first part is.

Let's go to figure one and two of the paper.

And

take a more formal look at uh and we can go to first in 2011 if we want more details on the similarities and differences because this is kind of the core of the contrast between optimal optimal motor control theory and active inference it's going to come down to the differences in how these models are framed because there's an interpretive layer but

the heart of it it's the differences between these two kinds of models between figure one and figure two here so in figure one uh and we'll go to the juxtaposition in figure one and figure two we have in both cases the plant kinetics which are defined with the exact same equations um and the sensory mapping so this

Red box is the same between both of the models, between optimal motor control on the left and ACT-INF on the right.

And there is still an optimal control module in Active Inference.

So that is...

interesting but if we look a little closer we can see that in figure one that uh motor commands that u with a tilde over it it's the minimization so it's optimization you know minimization maximization sometimes by minimizing the cost you maximize the profit or it's

flippable, throw a negative sign in there and a min becomes a max.

So here what's being minimized is an integral of potentially the cost function, C of X and U for changes in time.

So cost is being minimized through time and that is optimal control in that framework.

When we look at the optimal control,

In the active inference model, we see a really different structure, even of that optimal control module.

We see that u, which is playing a similar role, it's not a command, but it's still being passed, this u function, is still related to a minimization, but what's happening inside of the equation is very different.

And we can...

go to the Fristen figure caption to see what is happening there.

That E, curly E, is the distinction between exteroceptive, which is E with little e, and proprioceptive, E with a P, reporting on hidden states in extrinsic and intrinsic frames of references, respectively.

These prediction errors are the difference between sensory input observed and predicted.

so going back to here what's being minimized isn't the cost function through time even philosophical disagreements with homo economicus aside okay let's put aside cost

And then there's the challenge of assigning costs to different kinds of states.

What's being minimized here is the cost through time.

I mean, don't businesses try to do that?

Everyone wants to figure out how to minimize cost through time.

It's challenging to do.

What's being done here?

The minimization between the proprioceptive sensory differential with a multiplication potentially through time, not sure what that does in the model.

it just so interesting that um the minimization here is just like we've talked about in so many of these discussions it's about your generative model of action and sensory outcomes sensory outcomes are emitted by hidden underlying states that you can't directly observe like you don't know exactly whether it's night or day but you are getting photons or not so there's a hidden state that's being

evaluated that's the sort of hidden markov model component and the hidden state is in the model emitting states that are being observed as sensory outcomes and in active inference the depth of that generative model is actually such that instead of having a really rich generative model of cost functions and then trying to reverse engineer your cost function to find the cheapest behavior

generative model is of expected sensory outcomes like every time i move my shoulder here it starts to hurt and we don't need to introduce a concept of reward or cost into that equation we can suffice to say that there is a generative model of the sensory outcomes under different motor policies and the organism has a preference for let's just say being in non-painful states

It sidesteps that question of cost in a way where we can see that even from the side by side, even where there is an optimal control element, like a minimization element, what's being minimized is something that is very, very different.

And that's one of the key aspects of active inference that what's being minimized is the divergence between expected outcomes and realized outcomes.

That's what of course makes it so related to predictive coding, predictive processing, rather than drawing only on the reinforcement learning type approaches that are doing a minimization, implicitly maximization on reward.


SPEAKER_02:
Daniel, can I color in a little bit too?

Please.

When I saw this, it was interesting because what I saw was not, I guess it was a replacement.

So on the figure one, it's due estimation.

And then in figure two, what I saw was the removal of that and the application of a rule.

minimize prediction errors.

That's the rule as opposed to a step.

And all I thought about was, for example, Hippocratic oath.

I don't know what I should be doing in terms of this patient, but the rule is do no harm.

So I think that's what I thought was really interesting here is that an actual step was replaced with a rule.


SPEAKER_03:
Hmm.


SPEAKER_02:
And that to me was the big differentiator, the introduction of rules.

That's why I asked last week, when you changed the rules of the game for the plant, I know the affordance has changed and I know the tools were introduced and all of that stuff, but I keep coming back to tools, rules and pools.

Tools being obvious, rules being obvious, pools just being an aggregation of resources.

And so I think if you're able to sort of coordinate all three, it gives you a different sense of what might be going on.


SPEAKER_01:
Okay, a fun thought on that just to think about game playing.

The rules are always in effect and the rules can be explicit or implicit.

Like it's a rule in chess that you have to move out of check or figure out how to get out of check.

But then there's sort of what are equivalent to rules.

Like if a piece is pinned, it can't move but you don't need to state that as a rule.

So rules are, they're simultaneous.

They're always in effect unless there's another rule and they can breed emergence.

You just say, okay, here's how the pieces move, and then here's check.

Those are the rules.

And then it's as if there's a rule that is you can't move out of a pinned piece.

So rules always in effect allow for the space of emergence.

Steps have to be sequential.

And so it's almost like we're moving from the within a round of a game.

That's the instructionist.

Okay, you're playing risk.

First, roll the die.

Now, see whether the three is higher than the two die or whatever it happens to be.

And interactionism is pulling us back to like the rules and the pattern that still there can be sequential interaction.

instructions or sequential information can occur.

But it is very different to have rules rather than specified steps.

So let's see.

We're building up.

Yeah, go ahead.


SPEAKER_02:
Just one last thing.

So when I would ask young people to watch a video clip of something, and I would ask them to draw three columns and title them tools, rules and pools, and find examples, find tokens of each.

What do you think was the easiest thing for them to accumulate under?

It was tools.

Those have got the edges.

What was the second highest aggregation?

tools because they could they could literally figure out what was congregating what was the hardest thing the parallel processing which is what you just described it's always going off the sequential is much easier to account for the parallel processing the happening

as co-occurrence is the hardest thing for people when you're walking into a novel situation to take account of.

So you can say it, it's just being aware of it and finding examples of it that's really, really hard for most minds.


SPEAKER_00:
So even from a computational aspect, the parallelizing functions make them speed up so much, right?

But they also are so computationally intensive, right?


SPEAKER_01:
Yeah, exactly.

Dave has another great comment on this slide.

He wrote, I'm looking for where time is applied in the two approaches.

The intrinsic frame of reference for ACT-INF is U tilde of T. So that's, we'll zoom in a little bit on just figure two.

Here's that U tilde of T passing through the intrinsic frame of reference.

but there's no explicit T in the optimal control formula.

We can just see that motor commands U tilde are passed.

So there's kind of like a timelessness to, you know, contract this muscle.

It's not contract this muscle now, it's actually just a timeless statement.

So T he says, whereas T is inside the optimal control formula,

here is t, dt, it's a derivative through time and not in the intrinsic frame of reference.

as seen in Act-Inf.

So he asked whether that tells us where the approaches are taking account of time differently.

I think that's a great question.

How does time play a role differently in these two frameworks?

Let's keep on looking for similarities and differences.

So we have rules, not steps for active inference.

We introduce a time dependence of that downward motor signal.

We have, of course, a deep generative model component.

we have state estimation, that's the Hamlet joke.

There's this whole module that's clearly different in optimal motor control, which is the state estimation.

And that's what doesn't need to be done in active inference is this state estimation of, okay, given the sensory input we're getting, like I'm getting, you know, two thirds of my proprioceptors here and one third here are firing.

So let's estimate that the arm is here.

Okay, now pass that to the next part of the model.

Given that the arm is here, what happens?

we want to get the arm to okay now given which side of where we want the arm to go to we estimate the optimal and the actual r send the command you know turn the steering wheel to the side to bring it into alignment with the optimal or the most rewarding state so state estimation is in optimal motor control theory but in active inference you just don't have it

And that's sort of an interesting piece to drop out of the model because we don't need to have an explicit representation or an explicit variable with the location of the arm.

So that's a rule.

It's like John Cage, everybody has the best seat.

It's almost like it's enough to just say you're on the ocean, you're sailing, and then you're going to be trying to reduce your uncertainty as you pursue policies that in your generative model of the world, which includes latent causes,

So the deep generative model includes like latent causes of the world, which are not anywhere to be seen in this optimal motor control theory.

Like there's a deep latent cause that if too much weight is on, you know, this branch, it's going to break.

But where's that?

the constraints of the niche or something that's deep about the nation not there so anyways it's like you're in the boat you want to be reducing your uncertainty about getting the sensory states that you want like seeing that land look bigger reflecting you being closer but you don't need to have that gps coordinate where am i okay now where do i want to be and how are we going to get there

it's enough to actually have a sensory preference and then reduce your uncertainty on the trajectory of reaching that sensory outcome.

So that's a big difference in active inference.

And I'm seeing even a few more.

Let's look at the green boxes.

So in the green box for figure one, we have a forward model.

So they write that the function of the forward model

is to improve the execution of action.

It's kind of funny, you know, executive office or the executive component of the government, it's about executing.

That's where the instructions are issued from, executive orders.

Improve the execution of action by helping to finesse the inferences of the state estimator.

So again, it's in feedback with the state estimate, and then it's sending an effort copy.

So that's outgoing is efference.

And so there's this feedback between the prediction of basically where the body is in this case, and then that gets sent.

It's kind of interesting that the X comes from a state estimation.

That's the where is the arm.

And then the forward model is the forward model of motor control.

That is what connects with this U tilde.

That's the green box, that forward model in Optimal Motor Control.

Whereas in Active Inference, we have a different forward model.

It's a forward model of X as well as V, which is the prior belief.

So again, there doesn't need to be a forward model of position and motor action as happening here.

it's enough potentially to have a model of action and over beliefs.

We can look at the first in caption to see a little bit more closely.

Yeah, any thoughts on that?


SPEAKER_02:
I think the state estimator to go back, I think one live stream

State estimator says that there have to be ties between the two rails to stabilize those ties so that some processing can take place.

I think what this talks about is the fact that we know that there's a gradient, we know the train is gonna roll downhill as long as there's a gradient.

It's a rule as opposed to trying to stabilize the relationship between the ties of the railroad.

Two very different ways of looking at something.

And I think that this goes kind of back to what I said.

I think there are times when we do give ourselves instructions and then there are times when we simply parallel process because we have a rule.

I don't want to make mistakes because that doesn't serve my goals or my target.

And I think, again, I just suggest

that the inclusion of both is probably to our advantage.

It's just that what we tend to do is give all of our, we've been trained to give all of our attention over to making sure that the thing is stabilized.


SPEAKER_01:
nice also one piece of first in 2011 that's not brought over to this paper figure one was that motor control figure two is predictive coding and motor control so already we see the um reduction of the model in the terms of the state estimate goes away

You don't need to explicitly have a state estimator because the state estimator has now been subsumed into the forward model, which is why crucially the mapping from hidden states to sensations is now part of the forward generative model.

So we have a generative model of what we expect.

And now with predictive coding, instead of keeping a variable of what we think is happening,

which can be tracked through time and all that, we're simplifying that state estimator by including the expectations about the state estimator in our forward model.

That's predictive coding.

How does that differentiate from active inference?

that's a good question here we have plant kinetics sensory mappings forward model and optimal control with a cost function still coming in you still see that integral with the minimization of motor commands u over time whereas in active inference again we're moving from it's more valuable to be getting the signals i like and i like rewarding things

to I'm just bringing the sensory outcomes into alignment with expectations and I'm selecting policies based upon which ones I think are gonna get me there.

And then this section that I had highlighted

In summary, the tenet of optimal control lies in the reduction of optimal motion to flow on a value function like the downhill flow of water.

So that's pragmatic value.

And that's awesome because think about how much work has been done on information flows in the last 10 years.

Conversely, in active inference, the flow is specified directly in terms of the equations of motion that constitute prior beliefs like patterns of wind flow.

The essential difference, so how do we go from water going downhill on the value, gradient descent or up and down again, they kind of get flipped around, but how do we go from just thinking about what direction does gravity take you?

That's value, that's reward.

There's one answer.

Which policy for financial outcomes is gonna have a higher value?

That's that scalar estimate of value.

The essential difference is that prior beliefs in active inference can include solenoidal flow.

So this is where we're opening up the whole discussion of play.

So I hope that we can think about that for a second.

And Friston says, you know, he doesn't want to overstate the shortcomings of optimal control.

So it's not that you can't introduce a solenoidal component to value.

You can have the idea of solenoidal flow circulating on iso contours.

But how many businesses stop and say, you know, let's not pick the most rewarding number.

Let's look for maybe it's not the most rewarding number, but then there's the most solenoidal play around that number.

People say, but we're not going to be doing those.

So why would we stop at, you know, 5000 feet when we know that we can get to 6000 feet?

And solenoidal flow and the ability to have that pragmatic and epistemic, that directed and the solenoidal components opens up the space of play, hopefully.

So what do you think about that?

Or does that...

I'll put up this slide where we had separated out this optimal motor control theory with a value only.

That's the one thing that this robot is tracking, is the slope and the altitude.

Its following is uphill as much as it can, so it can get to the top of mount value.

Whereas in active inference, we're using the Helmholtz decomposition, which is related to the physics of flow on vector fields,

that is going to reduce to these two irreducibly separated components so like they're totally orthogonal they don't have redundant information they have totally separate information there is the value component the straight line but there's also this equal value solenoidal flow any thoughts on that you explained it really well

Here's a comment from Dave, while people are thinking.

Giving oneself instructions can refer to something real and useful if one interprets the execution of the instruction appropriately.

I'm referring to playing a piece of music without touching the instruments, which can be nearly as effective as actually playing.

If the challenge is to simply touch the right stops at the right moments, this can actually be more affecting.

Empowered machine operators may seem less efficient than highly regimented ones, but may over time get to far more effective overall operations.

Dean, what do you think about that?


SPEAKER_02:
Again, I completely agree.

My only question is, so why are more people not picking up on the potential of this and the value of having an awareness of both?


SPEAKER_00:
So I think it's maybe just getting started in a computational way.

I mean, we've explored some computation papers looking at how to optimize a given task computationally.

So I think that it will...

gain traction, right?

It's just so new.

I mean, not active inference as a concept, but the practical applications of active inference, I think, are just starting to be explored.

And I think that the play...

aspect is important.

I mean, because it's like how we learn, right?

Exploring or playing or, you know, these types of things give rise to real learning, even if it's accidental learning, like not necessarily effort directed.


SPEAKER_02:
Yeah.

I think it's also, I think it's something some has to do with a perception that

play doesn't necessarily generate value, which is kind of sad because there's so many examples where it does.

The outcomes of play cause your mind to go off in so many because it's supposed to be about distribution.

This is a kind of a way of encouraging that distribution.

And yet, for some reason, it just doesn't get the same respect.

So.


SPEAKER_01:
I'm just thinking about the pipeline from basic to translational to applied to sort of infused research.

Like once, oh, everybody knows that.

Once basic though becomes applied and then becomes every day.

So let's just imagine that we're going back shooting on that skilled performance slide.

Well, if we have implicitly or explicitly, if we're working under this optimal motor control function,

we're thinking, okay, maybe people's biomechanics differ, but for each person's biomechanics, there is an optimal way to shoot a free throw.

And we want people to have a more accurate modeling of where their hand is on the ball so that they can execute the movement better so that we can get the reward, score the points, put the ball in the hoop.

And so it relates to having people

practice or maybe get input on your hand was a little bit off here relative to the coach's expectations of where the hand should be um

But then there's this whole question about visualization and about what Dave was saying, like playing the music without touching the instrument and the ability that was almost discovered in a bottom-up way of changing beliefs about one's performance, rehearsing mentally, but also changing beliefs about performance, influencing motor behavior.

That is more consistent with what we see in active inference.

And so there's just multiple things that previously would be seen as sort of exceptions or quirks of a pure motor control

system like incorporating these deeper elements of our generative model um all the way up to even like the psychological like maybe your generative model is that your team is fated to lose so then you do choke in that moment because like you know you didn't psychologically want to win or whatever and that's as dina's we're always joking about like the interview with the athletes right after the game it's like i wanted to win or something like that like

they're not going to give you that third person.

My hand, you know, was on the wrong spot on the ball.

It just, we're seeing how

now as we have just like blue said more computational modeling that recognizes interactionism and that recognizes deep generative models it will be possible to start to slide some of these examples from being like quirky outliers to actually sketching out the structure of inference and action

instead of just being seen as this one weird trick that's going to help you learn free throws.

It'll be like, that's always about your generative model, and that includes you as being a team player, for example.

It always is going to include that, and then it's going to come down to maybe being modeled better by active inference rather than a reward-based framework.

Blue?


SPEAKER_00:
So I just was thinking like, you know, in your, you said you, you were exploring like the, the dynamic, you were, you were going through the dynamic that was like exploration and then doing something intentionally, like learning how to do it and then like perfecting a skill.

Right.

And I was thinking like you left off the end of that, like, uh, just like from a societal like standpoint, right?

Like we explore new things, like not thinking as an organism, but thinking as, as a social structure.

We explore new things, we set out the intention to complete those new things, we perfect those new things, and then we forget them.

So does that come into play in this?

I wonder, because I think about scaling active inference a lot, not in the way that we talked about scaling active inference in the paper, scaling active inference, but just as from small components of a system to systems.

And, you know, in that scaling, like, so are we missing something about forgetting, right?

Like handwriting, if you think about like learning cursive, you know, that was something like people start out scribbling on paper, little kids, you know, they're playing and they're drawing and whatever.

And then they intend to learn cursive, they perfect cursive.

But like as a society, we're not teaching that anymore.

So they don't know cursive.

And it's like typing, like now we have voice translation.

So we don't know typing anymore.

I mean, these types of things like are influential in a society.

So

Does that come into play here?

Like where I've talked about before, you know, thinking about doing something like entering the flow state, right?

When we talked about the flow last live stream, you know, it's like you have the intention to do something and like you think about doing something, but when you're really a skilled performer, you enter that flow state and you forget about doing it.

You just do it.

It's just magically accomplished.

So is that like flow state comparable to this like forgetting of like

as a society right so so when you enter that flow state and like you're doing something magically like just with your kinesthetic memory and you're perfect at it does that compare to society like forgetting a task because we've already mastered it like we're we forgot about that we're on to the next thing i wonder if that's relevant anyway sorry if i rambled


SPEAKER_01:
No, it's really nice.

Here's what it made me think about was instructions, again, implicitly or explicitly, they have to be remembered or forgotten.

Because if they're not remembered along the chain or at least in the RAM of the computer, it's like they're never carried out.

If you started a sentence and they forgot what the first part was by the end of the step, they can't carry out the instructions.

So instructions, we think about symbolic, representation, remembering, and forgetting.

But with interactions...

it doesn't have to be remembered or forgotten.

It's actually just experienced.

Like in the ant colony, the interactions between ants, they don't have to be remembered.

It updates the generative model of each nestmate, and then they continue on their path.

but it's actually just experienced and that's enough in an interactionist framework rather than being remembered.

I'm not sure if that gets at it.

I think it's a great point about how as something becomes pervasive and other skills and scaffolds are layered over it, there is a forgetting that can happen, but also it's like we don't even need to have memorization of everything.

I remember hearing from different college majors and somebody would say, somebody would say what major they were and somebody else would say, oh, well that one always was too much memorization.

Like there was, that was too much memorizing.

And then for that person, it wouldn't be who it was their major.

It wouldn't be too much memorizing.

It just seemed like it was parts of a bigger picture.

And so they didn't feel like they were memorizing little factoids, but rather just interacting with the material.

Not sure.

Dean, what do you think about that?


SPEAKER_02:
Yeah, well, Blue, you didn't say this, but you touched on something that's mattered to me for a really long time, and that is

Should we scale bottom up or does it sort of exist in its own realm?

Because that's the thing that you basically said.

I taught for a long time and it bothered me greatly that all the learning from haptic movement was disappearing into a keyboard.

So we top down that one and then we forgot about it because top down basically erased the bottom up.

We seem to think that if we top down it, if we give it an app, we can now forget about it.

And I find that crazy because I've had many quite...

heated debates with people who want to take another bottom-up exercise where we can really learn something and get some joy out of discovery and say, well, I'm going to scale that.

And I say, leave it alone.

Leave it alone.

It's a bottom-up thing.

What are you doing?

I know you can top down it, but why can't we just let it explore a little bit and figure things out for itself?


SPEAKER_00:
So Dean, you really touched on something there with like the haptic movement.

And, you know, I like personally learn super well by writing things down.

Like I take notes, I throw the notes away.

I never look back at them again.

They're all processing.

It's the act of physically writing something down that helps me learn.

And I mean, sometimes I do look back at my notes, but mostly not.

I just take them to commit things to memory.

And, you know, my daughter was really struggling with learning her times tables, right?

She's like doing these flashcards and the Quizlet app and all this stuff.

And I had her manually copy, you know, like the times tables and, you know, instantly like within a month she had them down and just like destroyed the standardized tests, like where they do math computation, which is just like rote memorization of your math facts and how fast can you do it?

She got like a hundred percent and she's, you know, at like off the charts for her grade level in testing.

So anyway, it's, it's really very interesting.

real and actual, but in that kinesthetic memory.

And this goes back to that motor command and the disappearance of the motor command.

And so this is what I think about these two juxtapositions.

And I think there is a space where you do issue a motor command, at least for me.

There is a space where it's like, okay, I need to put my right foot in front of my left

foot and walk along to learn to balance.

I'm issuing a command to myself to execute some task.

But there are many times where you do not issue that motor command.

I mean, think about if you've ever tried to learn to play the piano, placing your fingers on the keys and stuff, and then you just do it.

There's no command at that space.

And so there's a mental, a kinesthetic something that happens where you transition between having to issue the command and not having to issue the command.

And this is something that I'm excited to talk to the authors about if they are able to join us on a live stream.

Because I don't know, where does that step?

Where does that step get erased in active inference?

I mean, we aren't always just, we aren't always commandless, I think.

I don't know.


SPEAKER_02:
I'll just put one more, one last thing on that.

If I think of myself, if I think of myself separately from the neck down, everything from the neck down is giving me the bottom up.

My brain is way up here.

There's things that are supporting that, that are giving me that chance to bottom up.

I don't want those things to disappear.

I don't want to be a head on a cart.

I don't want to be like that plant with just my head going back and forth between lights.

When do we stop saying that everything has to... Like I said, you didn't say this.

But I've had so many people say, oh, Dean, all the stuff that you're doing is great and you create all these unicorns and all these young people are able to go out and contribute in professional settings, but it's not scalable.

And I go, what do you mean it's not scalable?

Every one of these things is a bottom-up example that it can happen as long as you don't try to top down it to death.


SPEAKER_01:
interesting the part about the body and the neck reminded me of ken wilbur's centaur stage of development which is sort of like uh along the integral psychological trajectory there's a step where there it's like half human half horse and so it's like one step beyond kind of a human in dialogue with a horse as two separate entities there starts to be like a fusion

in his framework moving towards non-dual framings but there's that stage where it's like uh the top down the bottom up but you know our brain is further out just gravitationally so it makes it seem like it's the top down piece but you know what about a person upside down

Then is it bottom-up signaling?


SPEAKER_02:
Well, you've already pointed him out.

He's on the edge of a building back there about 10 slides.


SPEAKER_01:
Or people on the other side of the world.

They're upside down.

And I think asking about speech and sign language...

could be interesting because I think those are gonna be the challenge cases for symbolic, the last bastion of instructionism and symbolic messages being passed

maybe is happening through language.

Whereas with this sort of elegant, skillful performance model, maybe you go, okay, I can see where predictive processing is coming into play, where it's not just about value.

Okay, so if predictive processing is an improvement from reinforcement learning or from optimal motor control, then I guess I could see why active inference builds upon predictive processing.

So that's the pipeline, the act-inf.

down the rabbit hole pipeline for some but i think when it actually is semantic or symbolic what is being performed that'll be where on one hand there's going to be resistance because it's going to seem the most instructionist but on the other hand i think we're going to tap into the richness of active inference to have a deep generative model including semantic information whereas the semantics are not in this motor control

framing so it'll be like double or nothing with active inference for some of the symbolic cases uh blue yeah i just wanted to go back to what um dean was saying earlier about bottom up and um like i don't know uh


SPEAKER_00:
like using active inference and modeling active inference in like a bottom up and nested way is super, super interesting to me.

And I just am wondering, like, when are we going to crack that walnut?

Because it's going to happen.

I feel like we're we're teetering, you know, on the edge of that.

What will that look like?


SPEAKER_01:
I mean, yeah.

What will it look like or what will be a system where we can explore it in?


SPEAKER_00:
I mean, maybe the active in France, I think is maybe maybe Daniel will grace us with we get to do his paper one day.

We can do it soon.

Yeah.


SPEAKER_02:
The only thing I'll add is that we have to people that are participating in this and really are going, oh, my goodness, we're really on the cusp of something.

Just have to be willing to go over the edge of the cliff.

And I'm not joking.

It's the letting go of all of the habits that we formed to get to this place because most people didn't get to, we didn't, the three of us didn't get here through active inference.

That came after a whole bunch of things that were more instructionalist.

And to step back, it would be much easier than to go over.

If we've got the prospecting, the proposition, and the provisions in place, we'll go over the edge.

And it'll all be fine.

It'll actually be quite thrilling.


SPEAKER_01:
I really like that.

Sort of that come to the edge.

There's a different thought chain when you're climbing the ladder to the high jump.

We've all jumped off of something that was...

scary or something like that.

There's a different thought process when you're climbing, maybe because your motor behavior is grounded.

You're on the ladder or you're on the mountain going up.

That's one mode.

That's actually like approach.

But then right at the end, the mind goes blank.

and you know the mind will say jump jump jump but there's that resistance and that reminds me one of the few times that i've used vr goggles um it was like you walked into an elevator this was like a scenario walk into an elevator and then it carried you up a building and you could see yourself getting higher and higher up and then the elevator doors opened and you looked down and it was just like dropping off a building and

it felt like my foot was just glued to the ground.

Like I felt like I could not take a step forward, even though I could inch my foot forward and I could see that it was, that I hadn't moved, that I was still just on a flat ground.

It was like,

it just stopped motor behavior to know that it would be resulting in some unpleasant situations in the usual case.

So Dean, what do we say to those who are not sure if they want to go to the cliff?

What do we say to those who are walking towards the cliff?

And then what do we do with those who are on the edge?


SPEAKER_02:
This is a fantastic question because this is the nut of the problem.

So do you want instructionalism extended into the active inference realm?

Or do you realize that whatever identity you take on in terms of learning

with both eyes open with some instructionalism and some interactionism, I don't know what that will be for you or Blue or me.

I just know it won't be an extension of instructionism alone.

That's the counterfactual here.

I don't know what that will feel like as different any more than you knew

what the difference was going to be in terms of releasing to gravity as opposed to pushing against it as you were climbing up those stairs.

I just know that if you considered it to be just two more stairs as an extension of what you were already doing, you're going to be disappointed.

So I think that's the big question here.

When I used to say to kids, as long as you don't think that a field researcher is simply an intern outside of school, I don't know what that's going to feel like.

And I certainly don't know what that's going to look like because I'm not out there with you and your sponsors.

So how can you let go of what you know in order to realize this thing that nobody can give you a direct answer to?

That's a beautiful question, Daniel, because that for active inference is going to be the, that's the rule that's going to have to be discovered that even people who are spending a lot of time focusing on this right now and giving it formalisms and developing the,

the way to formalize the math are going to have to ask themselves.

Otherwise it's just going to be an extension of instructionalism.

And that would be sad.


SPEAKER_04:
Hmm.


SPEAKER_01:
Yep.

It's like jumping off.

It's not a staircase in reverse.

right and um I think the idea would be maybe we already have flight suit on where it's like if you climb up that's the provision you climb you climb up with the provisions and then you know when you jump you're going to be able to do something that was just qualitatively different it's going to feel different it's going to be different it's going to be a different action

and wasn't the point of listening to instructions to change to update to be better or to be different and then it's like by being different and following that path we become who we are like somebody said i always wanted to be skilled in this martial art so then they trained along the way to become who they wanted to be and that was them being who they wanted to be it's a lot of

sort of loose associations.

But again, I think we're working towards making it happen.


SPEAKER_02:
It is and it isn't though, because instructionalism, my point was that the instruction stopped.

I cannot give you a description of what that will look and feel like.

So you're going to have to interact with it

That's, there's not, it's not a negotiable.

If you really want to be there, you have to let go of the instructionalism.

So I don't think that's a loose association.

That's a non-negotiable.

Now you may not like it and you may not go there.

You may step back from the edge and that's fine.

But don't think that I'm, or other people that are actually

looking at active inferences as a second eye open, won't be aware of what you're transpiring, whether you're going over or whether you're stepping back.

That's not a loose association.

That's pretty clear.


SPEAKER_01:
Lou, any...

Thoughts on that?

I guess my question would be, let's just stay with this sort of like climbing the instructions to get to the space of interactions.

What?

Yeah, Blue, go ahead.


SPEAKER_00:
So it just as like climbing the instructions to get to the space of interactions, like I feel like something is there that is has to do with like the bottom up and the scaling.

Like, you know, in the systems, like we are climbing the instructions as you know, parts of a system until we get to to that space as a system.


SPEAKER_01:
the rules well it's like okay we have the ladder going up or you know staircase going up to the jumping off point you could frame that in terms of instructions go to the second step go to the third step go to the fourth step instructionism all the way i mean our interactionism all the way it's like it gives you the rule walk forward

so you can replace on a structured ascension you can replace the sequential instructions with a rule or a pattern so that it's interactionism all the way down all the way up and that kind of relates to active as a scale free framework like bottom up from where blue

Are you going to start with subatomic or where is the kernel going to be?

And maybe just interactions all the way down.

And then at some sufficient level, you can granularize or you can coarse grain, you can make something look as if it has instructions.


SPEAKER_00:
So I wonder if it's like, you know, you see this loop, right?

The active inference loop, and it's like an oval like this.

And so I wonder if it's like, starts to be like the structure of an atom.

Like, okay, there's like this oval that's this way.

And then I wonder if I could superimpose one going the other way, a vertical and a horizontal, like a little one of these things.

So that, you know, because there's this across scales as we scale up and down.

You know, is there a loop going between and then a loop going this way?

Possibly.

Probably.

I don't know.

I think about it in that way.


SPEAKER_01:
So this could be the S orbital.

This is just like a spherical one.

And maybe there's other trajectories or flows that have different shapes.

so dave wrote in there and anyone else in this last little bit is welcome to write a comment dave wrote in most effective military units troops are told what to accomplish not what to do so that's the difference between for me like push and pull push you know lift the bar is like it's a command about what to do versus like

when it's an accomplishment.

And so it's the teleos or the end directedness that pulls the person.

And then in that pull, there is the space to have the solenoidal flow, to walk straight towards the goal where there's a clear path.

but then to be like, oh yeah, but then I'm hitting a wall.

So in order to accomplish, I do have to walk around.

Of course, that makes sense in the context of being pulled by a goal, but that's where the instruction-based robotics always fails because anytime there's something that requires a deviation from value, you need a total second layer of the model to reintroduce curiosity or epistemic gain into the value framework.

So then it's this question, how do you balance all these second layer bolt-ons so that you can still salvage your value-driven model, even when there's aspects that are just clearly better framed within a pragmatic epistemic distinction, Blue?


SPEAKER_00:
Yeah, it's like solving the problem without ground truth data, right?

Like, so how do we, you know, if we don't know, if we've never been exposed to the system before, if it's not programmed into our robotic function,

You know, how do we account for that, right?

So I think that that's where the exploration and the play a lot comes in.


SPEAKER_01:
Or maybe tossing and turning.

Like you want to be comfortable and then it just sort of uncoordinated behavior that's just rummaging around, searching for something in a box or all these examples where it's so, you couldn't say that that twist of your side, it was, it's not skillful.

least for me but it's also not reward driven again you need a way second level bolt on to be explaining how the rummaging behavior is itself value driven you can say that there is a value that's pulling or you want the valuable thing in that box but that's we all agree on that we all agree that there's something valuable in the box and that search behavior is going to be required

are we going to have a process theory that allows for exploration and then zeroing in on a goal or will we have a process theory that tries to go like well if the end is valuable then let's just back propagate value


SPEAKER_00:
Yeah, or if we don't know what's valuable in the box, right?

Something is valuable in here.

Like, how do we find out what is it that's valuable?

Okay, so we implement the search function, but then exploring what is the valuable item out of, you know, 50 items in the box, right?


SPEAKER_01:
Yep, it's almost like in the simplest cases...

the value learning is defensible.

When we have this hill climbing robot on a single hill, okay, but now you got a triple bottom line.

You got the financial success, but you also have environmental and social considerations of a business.

So will you reduce all three of them to one of them or try to generate a fourth standard that you're going to reduce them all like a common currency for all of your values and rewards?

Or could there be a deep generative model where the organization has preferences in the financial, social and environmental realm, and then take stock of its action possibilities, not even described in the value mindset.

Maybe every time you have a meeting, it's like square zero, what can we do?

Whereas in active inference, we start with the space of policies, the affordances that the niche provides.

And so you don't need to consider policies that cannot be done.

And you should reweight policies accordingly to how likely or tractable they are.

So there's just so many ways that we see that the mathematical framings get expanded on through relaxation of some of their attributes, just like Frist in 2011 wrote, which is that optimal control can be cast as active inference with three simplifications.

And then he walked through those, which we discussed a little bit last time, but this is kind of cool how we're building out some differences between the motor control approaches that have been used in the past and active inference as a process theory.

And then the way that that encompasses what we've seen before, and then maybe also opens up the discussion

into just areas that weren't even considered.

Like we can add in affordances plus preferences.


SPEAKER_02:
I think that embodied skillful and active inference implies a huge leap of faith back to that jumping off the, because it is.

And I mean, that's not, that's a, that's a cliche that people can probably appreciate.


SPEAKER_01:
What do you think the trust or faith is in?


SPEAKER_02:
Yeah, that's it.

Yourself.

Yourself, right?

Or lack thereof.


SPEAKER_01:
Act or act not, there is no infer.

No, there is, there is.

So it's interesting, yeah.

How can we distill the similarities and differences so that when we see one of those limitations,

being like okay we had um uh curiosity slash pragmatic plus semistemic so that when we see a sort of here's the new hack on value we can see that as a saddle point

for where that model could move towards an active inference framing just by kind of rewiring some of the modules that it has.

Here's a great question from the live chat.

Bill wrote, would a priority parameter according to depletion levels of different resources be applicable?


SPEAKER_02:
Yeah, that's back to the pools thing.

Yeah, I would say yes.


SPEAKER_01:
Okay.

Dean with the pools, here would be my thought from the multi-scale decision making.

just think about a bee colony the resources that they need to forage for include like pollen which has a lot of protein and fat and it's helpful for the developing larva then nectar which is like high octane gasoline a lot of carbs good for the adults um and then depending on the environment they might need like water or salt or other different resources

So the depletion of, there might be an imbalance of the nutrients.

And you can think about that similarly for an organism, like rabbit starvation.

When you only eat protein, your body will enter starvation mode because other fats and stuff are needed.

So definitely multiple resources are being balanced.

And part of the challenge of decision-making under uncertainty, just as we've been getting at, is that there's not just one kind of outcome.

Like it's enough to be uncertain about value.

But now when we're thinking about these multi-dimensional resource landscapes, whether it's just protein versus carbs, or whether it's a lot more nuanced, like the triple bottom line, we really do need a principled way of talking about the relative depletion of different resources.

So in the bee colony case,

selection has shaped nest mates so that they use the rate and the type of interactions they have in order to update their nestmate level behavior so i'm having a lot of interactions with hungry larvae maybe we need more pollen i'm having a lot of interactions with food reservoirs maybe that can slow me down because we probably have enough um forage for now

so colonies that don't consist of nest mates with that productive way of interpreting their interactions not instructions those colonies are swept off the table and so we end up seeing distributed systems succeed where they act as if there is a correct prioritization amidst uncertainty of different kinds of resources

and then if we use active inference instrumentally in the deep generative model of the body's nutrient ratios or the colony's relative balance between protein and carbs then it's as if there is a priority parameter where when something is depleted it's the one that's prioritized but we don't need that expressively in the model

we can have a multi-dimensional generative model of different resources, and then actions will be selected according to their expected free energy being minimized, almost going along the curve that takes us on that edge of explore and exploit from wherever we are in that resource depletion landscape towards our preferences.

would be totally open to hearing other explanations or maybe there is a priority parameter that can come into play but one sort of longish response would be organisms do act adaptively to prioritize depleted resources but that doesn't mean that there needs to be a parameter in our model that explicitly prioritizes specific resources it's enough just to have a preference vector that includes multiple types of resources blue


SPEAKER_00:
No, I think that that's right.

So you can make it as simple or complicated as you want, but I always think less parameters in the model is better.


SPEAKER_01:
It just makes me think, how do we get those preferences?

And then what happens when the niche changes so that preferences that were adaptive

like to act as if prioritization of sugar and salt over all other preferences, for example.

What happens when the situation changes?

So how do we integrate high precision priors

with highly accurate sensory input that's something we've talked about before how do we get the best of both worlds with being able to like fly blind because we have a deep generative model but then also when there is sensory input that requires a categorical shift in cognitive model for example we want to have the fluidity to do that and we don't want to be wasting our time in one mode when

It's the wrong mode.

We don't want to be hard when hardness is a flaw or be soft when softness is a flaw.


SPEAKER_00:
So I wonder if there's, like, you know, I mean, for organisms like bees and birds, like, there's some programmed... I mean, things are shifting all the time, right?

Like, there's, you know, a huge amount of, like, migratory stuff that comes into play and hibernating and all these things, right?

And so, like, for us, like, we notice that prioritized, like...

shift like i need water right now right like you know if we're suddenly like parched right like the need for water is overwhelming but there's not this like because we have offloaded so much of our needs into our niche like the need for to stay warm or whatever we build houses we wear clothes so we've offloaded a lot of this stuff so i i wonder if it's like um

the instinct becomes less instinctual.

I wonder if that happens, like the instinct to sequester food or fly south for the winter or these types of things, just because we've just offloaded our need to do those things.

So it just becomes, I don't know, there.


SPEAKER_01:
I think that's another distinction here.

Here we can include extended slash embedded 4Es, 7Es, 11Es, however many there are.

We can at least frame those situations in terms of niche modification or niche construction.

Where is that in motor control?

It's nowhere.

Where's the golf club with a squishy handle?

that is being interacted with as an instrument, we don't have those nice interfaces.

Whereas Active Inference has excellent interfaces quantitatively and qualitatively for being enriched by pieces that are, as Dean would say, maybe non-negotiable for the actual creature.

but it'd be totally ad hoc, where would you put the instrumentation in here?

Is it a state estimator?

Should I be estimating where my golf club is?

Or is it enough just to estimate my hands and the angle of the hands and then do another second level prediction?

Not quite clear.

You could probably implement it multiple ways.

And here's another nice comment from Dave.

So Dave said, the term in cybernetics, so it's always good to connect back to related areas,

for putting drives into a model is algodonic.

So here's the definition of algodonic.

It comes from, I guess, algos meaning pain and hedon meaning pleasure.

Sorry, Dave, for the mispronunciation.

um putting multiple algodonic drives like pains and pleasures may yield complex instructive behaviors but there are so many advantages in having a model i think active inference so sophisticated that it generates its drives the drives come out of the model rather than being put in so yes and he wrote then clarifying i mean the innumerable drives emerge from the model's internal dynamics

If your robot is spontaneously curious, spontaneously attends to events or responsive externals, it's as if it has a curiosity parameter.

So it's true.

Maybe we could even write like drives, quote, you know, as if... I'm going to take Shakespeare.

Thanks, Hamlet.

You are a great prince.

Drives... Drives emerge from model...

don't need to be put in.

Instead of maybe the rabbit being put in the hat, this is like the rabbits emerge from the hat if you put in enough hydrogen and enough time.

That's interesting to think about where cybernetic models come into play here.

Let's give just a few final minutes.

Any final questions in the chat?

and thanks of course to dave and to phil for the great questions we can just think about um maybe dot one dean is um being on the edge dot zero is climbing and so it's a two-directional trail you know there's people going up to half dome and there's people coming down so dot zero is two-directional

Highway, lots of on-ramps and off-ramps, but we try to make the topics accessible for those who are not in the Active Inference game, but they're familiar with related topics like the keywords usually.

And in the .zero, we're going to go from bridging the keywords and the topics of broader concern to Active Inference.

So that's the onRamp to Active Inference.

But then also for those who are already in the Active Inference mode of learning by doing and working, then it's their window out to like, oh, wow, this idea that I had been working on Active Inference in one context, it's also applying outwards.

So that's in the .0.

.1, whoever and whenever it is,

uh we are in the the bathtub face the part between the bookends that's we're at the edge and we can look back to the dot zero and see again recapping the the steps that we took but also we want to start looking out and then i don't know where dot two would be but dot two is when we sort of take the next step and


SPEAKER_02:
The dot two is the no going back.

I mean, I can add a twist to the fact that I'm going to be hitting the water soon, and that's a skillful embodied movement, right?

We actually watch people that do the 10-meter platform and can add quite a few things before they hit the water and regain control.

But I think this is what interactionism is versus instructionalism.

I mean, the way that this is set up, the 0-1-2, is interactionism.

It's more about this than it is about bidirectionality.

And I think you talked about that at the beginning of today's episode.


SPEAKER_01:
Right, we have a structure that we hold to, a rail that we could modify as well, but we hold to the rail so that we don't have to frame it like instructions.

um we weren't instructed to do this and i don't know i hope that people don't feel like these are instructions but rather interactions or engagements with them and then just like so many other things that we're seeing online the new technological affordances allow it to actually be an interaction we actually can have people asking questions live

being a part of the conversation.

Whereas if it were just recording a video and releasing it or making a book and releasing it, it'd be hard to break out of the instructionist frame because the deliverable would be static and very unidirectional.

Here, we have a different affordance that helps us break out of that frame basically for free because even if instructions are being conveyed on the live stream,

it would still be within an interaction of participants, of individual and collective and of the community.

So any final thoughts?

on one no fun times thanks both of you for the the dot zero and dot one fun we've had a few hours to think about it but you know the paper is the distillation of many more hours so there's always value dare i say and going back and playing with it because it's fun

and it's just yep they're great topics to be considering about and learning so cool thanks everyone for watching thanks dean and blue and we'll see you next week for 23.2 thanks guys bye