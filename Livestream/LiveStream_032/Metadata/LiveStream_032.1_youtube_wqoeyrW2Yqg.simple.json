[
  {
    "start": 33.063,
    "end": 35.804,
    "text": " Hello and welcome to the Active Inference Lab.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 36.004,
    "end": 43.745,
    "text": "This is Active Lab live stream number 32.1321 Stochastic Chaos and Markov Blankets.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 45.666,
    "end": 47.346,
    "text": "Welcome to the Active Inference Lab.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 47.986,
    "end": 55.108,
    "text": "We are a participatory online lab that is learning, communicating, and practicing applied active inference.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 55.728,
    "end": 58.469,
    "text": "You can find us at some of the links here on this slide.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 59.482,
    "end": 61.864,
    "text": " This is a recorded and an archived live stream.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 62.405,
    "end": 65.488,
    "text": "So please provide us with feedback so that we can improve on our work.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 66.469,
    "end": 72.555,
    "text": "All backgrounds and perspectives are welcome here and we'll be following good video etiquette for live streams.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 74.281,
    "end": 78.863,
    "text": " At this short link, you can see some of the past, present, and upcoming live streams.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 79.523,
    "end": 87.526,
    "text": "We are here in the early November 2021-32 discussions on Stochastic Chaos and Markov Blankets.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 88.407,
    "end": 95.75,
    "text": "And in the second half of November, we'll be talking about the paper Thinking Like a State, and we haven't yet set the papers for 34 and 35.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 96.29,
    "end": 103.213,
    "text": "So if you have any ideas, or if you're an author, you want to come on to discuss for these dates, then get in touch with us.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 105.322,
    "end": 119.903,
    "text": " Today in Active Stream 32.1, the goal is to learn and discuss this extremely interesting paper, Stochastic Chaos and Markov Blankets by Fristin, Heinz, Oltshofer, DaCosta, and Parr from 2021.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 121.625,
    "end": 143.707,
    "text": " and there's a lot to cover in this paper there's a lot of formalisms and figures and keywords and broader questions so i'm sure we'll have a lot to think about and discuss if you're watching live then please feel free to write a question in the chat because otherwise stephen and i are just chilling here",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 144.568,
    "end": 150.211,
    "text": " So let's get into it with just intros and warmups.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 150.812,
    "end": 155.014,
    "text": "And if others join, we'll have them introduce themselves when they do join.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 155.575,
    "end": 165.1,
    "text": "But for now, let's just say hello and maybe bring up just something that excited us about coming to this discussion or something that we wanted to resolve today.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 165.861,
    "end": 167.341,
    "text": "So I'm Daniel.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 167.622,
    "end": 169.203,
    "text": "I'm a researcher in California.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 170.203,
    "end": 175.969,
    "text": " And something that I liked or remembered about the paper was that there was",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 177.409,
    "end": 183.814,
    "text": " seemingly some changes or updates to the formalism of core terms.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 184.855,
    "end": 192.82,
    "text": "And so how to understand that in the broader trajectory of the literature, which one of these changes are like updates?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 193.021,
    "end": 194.281,
    "text": "Where is it a software update?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 194.442,
    "end": 195.743,
    "text": "Where is it a breaking change?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 196.403,
    "end": 205.43,
    "text": "And then what are the implications of those changes for some of the broader conclusions that people do or want to draw from active inference and the FEP",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 206.23,
    "end": 211.516,
    "text": " like the nature of thingness or biological systems or levels of nested organization.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 212.677,
    "end": 213.618,
    "text": "So, Stephen?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 215.7,
    "end": 216.14,
    "text": "Yes.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 216.841,
    "end": 218.322,
    "text": "Good morning from Toronto.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 218.342,
    "end": 220.945,
    "text": "I'm Stephen.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 221.205,
    "end": 225.73,
    "text": "I'm doing a practice-based PhD, which has kind of moved into a methods-based PhD.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 227.572,
    "end": 228.332,
    "text": "I work a lot with...",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 230.658,
    "end": 236.822,
    "text": " group processes and working with creative spatial approaches to help do sense-making.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 238.263,
    "end": 253.411,
    "text": "So I'm really interested in active inference within that as a kind of unifying way to help to close a lot of the loops and the fragmented questions that come up when trying to do sense-making with different types of people in different types of spaces.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 253.712,
    "end": 257.914,
    "text": "So as with Daniel, I'm really interested about this paper as",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 260.476,
    "end": 285.065,
    "text": " After the initial view of it, because you see stochastic chaos and unconsciously trying to not go too far down sort of an abstract academic aspects of things, but I realized that actually these underlying processes have got quite a lot of applications in this ability to understand why and how things are unifying.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 286.766,
    "end": 288.347,
    "text": "And I think that's really exciting.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 290.094,
    "end": 296.198,
    "text": " because there's a lot of sort of semi-Markovian looks at larger cognitive processes.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 296.258,
    "end": 300.061,
    "text": "There's certain practices and inactivist processes.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 301.262,
    "end": 315.211,
    "text": "But what we tend to see when it gets down into the nitty gritty is it's how are things bubbling up through the kind of stochastic chaos of the world and life?",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 315.952,
    "end": 317.693,
    "text": "Or should I just say stochastic chaos?",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 319.134,
    "end": 322.377,
    "text": " separated, chaotic processes.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 323.017,
    "end": 335.667,
    "text": "So the idea of having stochastic chaos and what that means, and this paper does that, is quite useful to start to look at what it means to have to be able to reconcile those approaches.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 335.767,
    "end": 340.391,
    "text": "So it actually does start to help think about more applied approaches.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 340.451,
    "end": 344.094,
    "text": "So that's something I'm interested and excited about this paper.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 345.216,
    "end": 345.897,
    "text": " Thank you, Steven.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 346.878,
    "end": 351.963,
    "text": "In the 32.0, this is kind of the lead in was this topic of flow.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 356.158,
    "end": 365.964,
    "text": " And that is in a way what might start to bridge this distinction that you raised and will definitely return to between kind of abstractions and applications.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 366.865,
    "end": 377.512,
    "text": "Flow is a term that has applications across domains from the flow of water, flow of people, flow of information and money to psychological flow.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 377.852,
    "end": 379.653,
    "text": "It's kind of a nomadic term.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 379.713,
    "end": 381.334,
    "text": "It's a transdisciplinary term.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 382.475,
    "end": 384.336,
    "text": " And then that's an abstraction.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 384.957,
    "end": 391.901,
    "text": "We're abstracting to the patterns of flow that help us connect the dots across these different systems.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 392.561,
    "end": 393.782,
    "text": "But also we want to apply it.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 393.862,
    "end": 398.124,
    "text": "We don't just want to say, well, water's flow and information is flow and that's the end of the story.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 398.784,
    "end": 406.969,
    "text": "So how abstractions and applications kind of work like the left and the right foot together to",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 408.57,
    "end": 430.029,
    "text": " build our knowledge and our application almost like our epistemic and our pragmatic value I think that'll be a thread that's important to um pull out what do you think about that yeah that's a really helpful connection and I think this also speaks to that um usefulness of this",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 431.112,
    "end": 442.035,
    "text": " work beyond modeling directly is when this idea of flow is talked about in these ways, it's kind of a bit vague, right?",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 442.155,
    "end": 446.356,
    "text": "And it still has this idea of things flowing in a certain direction.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 447.636,
    "end": 449.377,
    "text": "And are you in the flow?",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 449.577,
    "end": 454.458,
    "text": "And so I think when we start to also have the potential for stochastic",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 455.435,
    "end": 477.873,
    "text": " processes and in a way the sense that everything's flow and you know how does what does low and high requirements mean you know what does low and high competencies preferences mean and they kind of these are quite bucket terms right and essentially they they are what they are because they are workable",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 478.783,
    "end": 479.483,
    "text": " truth be told.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 480.124,
    "end": 485.486,
    "text": "But we can start to look for something which can hold those in a more unified way.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 486.607,
    "end": 507.077,
    "text": "Because I think that the way that we might feel in the flow when we're in a zone where we can both do things and we're immersed in it may well be maybe what we're in all the time anyway, but it's just a different form of.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 508.983,
    "end": 514.884,
    "text": " So that also changes the kind of ramifications out there.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 517.225,
    "end": 518.265,
    "text": "Great point.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 518.585,
    "end": 526.987,
    "text": "And we can actually connect that to this sort of view from the outside and view from the inside, which we talk about a lot in Act-Inf.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 527.547,
    "end": 536.709,
    "text": "So it's almost like there's the skier going down the hill and the view from the outside, the behavioral view is like, given the angle of the hill,",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 537.529,
    "end": 553.889,
    "text": " they're optimally flowing that river is physically optimally flowing down that hill as you'd expect from the friction and the potential energy and just the physics of the setup and then there's this internal experience of flow so it's kind of like um",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 555.17,
    "end": 562.292,
    "text": " Maybe we are in flow all the time, even when we are getting, for example, distracted or bored or frustrated.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 562.912,
    "end": 565.213,
    "text": "In what ways is that still flow?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 565.993,
    "end": 568.394,
    "text": "Because if we think about flow, well, flow's good.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 569.234,
    "end": 573.215,
    "text": "It's a state where we're productive and happy and things like that, and then we're out of flow.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 573.555,
    "end": 576.196,
    "text": "That's what you'd hear in the psychological literature.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 576.796,
    "end": 580.637,
    "text": "But let's just say that the river, we're flowing and flooding.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 581.317,
    "end": 585.399,
    "text": " We don't say, well, we're done using flow models because now it doesn't do what I thought it was gonna do.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 586.079,
    "end": 588.3,
    "text": "Flow is the whole space.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 589.28,
    "end": 600.105,
    "text": "So how do we think about this whole psychological space as being particular regimes of flow and flows the big topic that connects stress",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 601.035,
    "end": 606.318,
    "text": " fear of failing, overwhelm, concern, excitation, et cetera, those are all flow states.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 606.978,
    "end": 614.682,
    "text": "Maybe it's not the flow state that we expect, maybe not the one that we prefer, but a river can have flow states that we don't expect or prefer either.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 615.222,
    "end": 621.246,
    "text": "And so it's like when we do abstract to the physical systems, we get a whole quantitative toolkit",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 622.046,
    "end": 634.31,
    "text": " And we also get the ability to maybe look beyond phrasings that see flow as just something to be obtained and rather flow as the nature of perhaps interior experience.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 634.83,
    "end": 638.111,
    "text": "And then we can talk about designing or perturbing regimes of flow.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 638.431,
    "end": 638.951,
    "text": "Yeah, go ahead.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 641.032,
    "end": 649.855,
    "text": "Yeah, that's a good point, because from the out, there's the outside system, like, say, seeing someone skiing down a hill and you could say there's different",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 650.717,
    "end": 651.378,
    "text": " ways of doing that.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 651.398,
    "end": 663.677,
    "text": "And then there's from the inside, you've got essentially a dynamic, nonlinear dynamical organism that's kind of trying to sort of thrive and survive.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 665.064,
    "end": 665.885,
    "text": " It's different.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 666.145,
    "end": 667.446,
    "text": "There's no getting away from that.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 667.666,
    "end": 672.65,
    "text": "And the nature of that difference is, that's another question beyond.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 672.711,
    "end": 682.959,
    "text": "But the interesting thing is on that graph as well, is often that graph only, the flow is only shown on the top right and not on the bottom left, even though it could be seen to flow down.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 682.979,
    "end": 688.543,
    "text": "And so some of it is like a quadrant and it's just the top right which is seen as the flow.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 689.864,
    "end": 691.526,
    "text": "But what's also interesting is,",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 693.823,
    "end": 696.666,
    "text": " It kind of depends, again, on these multi-scale dynamics.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 697.506,
    "end": 715.842,
    "text": "So within certain scales and temporal scales, things start to fit our organism's preferred states, some of which is kind of built into our morphology.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 716.763,
    "end": 720.787,
    "text": "So if something becomes so easy, for instance,",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 722.253,
    "end": 731.813,
    "text": " It's a lot easier if I'm trying to protect a building just to stand in front of the front door as a security guard and nothing happens all day.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 734.403,
    "end": 760.021,
    "text": " And I may end up in some sort of flow, but there's a point at which there's a desire for some stimulation, there's a desire for some change, and there's also maybe changes that happen at the kind of... This sort of ties in with Adam Saffron's work about windows of experience, both in real time and over time, is...",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 761.022,
    "end": 765.509,
    "text": " When is it kind of in the same sort of time scales that we consciously function in?",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 766.771,
    "end": 769.174,
    "text": "And when is something beyond that?",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 769.194,
    "end": 776.085,
    "text": "So that could be where stress and boredom or stress and burnout can be both because of the nature of the activity,",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 777.026,
    "end": 781.607,
    "text": " is too rapid, it's too disjointed for our morphology.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 783.008,
    "end": 792.55,
    "text": "Or it may be that we perceive it that way because we have some depression or anxiety that's also not enabling us to engage in those ways.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 793.231,
    "end": 793.811,
    "text": "What's your thoughts?",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 794.611,
    "end": 794.851,
    "text": " Great.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 794.951,
    "end": 799.233,
    "text": "Let's take that point to one of the formalisms of the paper.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 799.773,
    "end": 810.657,
    "text": "So you just mentioned how there's like multiple timescales and there might be slower timescales as well as faster ones, which might even be faster than our rate of perception or modeling.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 811.414,
    "end": 814.437,
    "text": " which are one and the same if perception is indeed a generative model.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 815.578,
    "end": 821.422,
    "text": "And this is very early in the paper in section two, from dynamics to densities.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 822.103,
    "end": 830.09,
    "text": "So they write, the aim of this section is to get from the specification of a random dynamical system in terms of its equations of motion.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 830.73,
    "end": 836.935,
    "text": "So the, for example, differential equations that define the time evolution of a dynamical system",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 837.936,
    "end": 858.294,
    "text": " to the probability density over its states in the long-term future from any initial conditions so going from dynamical systems which takes us um into the temporal realm to the density realm and so there we think about ocean water of different physical densities there's",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 859.719,
    "end": 864.2,
    "text": " a motion to the densities because denser things go down.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 864.901,
    "end": 874.784,
    "text": "And so that idea of denser things going down or flow from high to low density regions, just like in the atmosphere, just like in the ocean,",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 876.033,
    "end": 891.738,
    "text": " that is going to be connected to the behavior of random dynamical systems and to information geometry so that's a little bit of the next piece but the two time scales are here you",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 892.498,
    "end": 894.459,
    "text": " Here's a classic flow model.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 895.039,
    "end": 897.58,
    "text": "There's a flow and then there's the fast fluctuations.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 898.32,
    "end": 909.803,
    "text": "So it's like there's the river moving ahead at one kilometer per hour, but each molecule in that river is not always going at exactly that speed rates.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 910.463,
    "end": 913.704,
    "text": "There's a fast fluctuation, which might average out to zero.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 914.085,
    "end": 921.607,
    "text": "So in the bulk aggregate or in the time aggregate, the flow dominates the behavior of the river.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 922.691,
    "end": 931.076,
    "text": " but the fast fluctuations are also occurring and they can often be equivalent to a well-behaved i.e.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 931.136,
    "end": 932.637,
    "text": "Gaussian error term.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 933.297,
    "end": 941.742,
    "text": "So this is where we see the separation of timescales into sort of the flow of the river and then the vibration of the molecules.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 943.183,
    "end": 947.966,
    "text": "And those have two different partitionings of the system.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 949.23,
    "end": 975.68,
    "text": " flow is well behaved because it is just like a single number for the whole river in this simple example and the fast fluctuations are well behaved because they're smaller if they were larger than the flow they would become the flow itself so they're smaller than the flow and they might be uncorrelated or have a zero mean which allows us to do gaussian statistics on them and then this idea of separation to slow and fast time scales",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 976.889,
    "end": 980.69,
    "text": " is connected to density dynamics through the Fokker-Planck equation.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 981.09,
    "end": 981.65,
    "text": "Yeah, Stephen.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 984.711,
    "end": 987.092,
    "text": "Yeah, just a little question on that.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 987.152,
    "end": 1003.636,
    "text": "So this time dynamic, so flow is both a time scale of interest, I suppose you could say, and potentially one which has a net kind of change in some sort of",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1005.12,
    "end": 1032.294,
    "text": " directional kind of gradient descent i suppose and then the fast fluctuations it doesn't say random but it's probably more stochastic um but could also have flows going on so is this um is this is this um you know how how much difference in in the in the rate that they need to be to be classes",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1035.671,
    "end": 1036.611,
    "text": " Good question.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1038.092,
    "end": 1048.277,
    "text": "So the X with a dot is kind of like the derivative of X. It's the rate of change in X. It's the flow in X is going to be decomposed to these two terms.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1048.997,
    "end": 1053.66,
    "text": "Now we might be interested in a very special solution to this equation.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1054.847,
    "end": 1063.273,
    "text": " So again, we have X dot is kind of the change in X, which is being broken down to these two dynamical variables.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1063.733,
    "end": 1068.236,
    "text": "And then that's being equivalent to the Fokker plank, which is more of a density framing.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1068.416,
    "end": 1079.404,
    "text": "So that's the key introductory step in the paper is just to build this really strong equivalence, AKA they're the same picture between the dynamical specification and the density specification.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1080.546,
    "end": 1087.65,
    "text": " So if we could solve when the dynamics were at a steady point, that would be equivalent to when the density would be at a steady point.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1089.211,
    "end": 1095.654,
    "text": "There might be some methods to help solve it in one phrasing or the other phrasing.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1096.515,
    "end": 1098.256,
    "text": "It turns out that there's a...",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1099.264,
    "end": 1105.848,
    "text": " way to solve with a little bit more feasibility when P of X equals zero.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1106.449,
    "end": 1112.493,
    "text": "So that's when the density flow given this is zero.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1113.413,
    "end": 1116.235,
    "text": "And so that's what they're discussing here.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1117.456,
    "end": 1123.241,
    "text": " is basically asking, when does that equal zero?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1123.941,
    "end": 1126.063,
    "text": "And that is a stationary point.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1126.824,
    "end": 1137.913,
    "text": "So it's kind of like, doesn't mean it's just simply flat in the reservoir, but there's a pump bringing water up to the reservoir at 10 gallons per minute, and then the reservoir is dumping at 10 gallons per minute.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1139.474,
    "end": 1146.48,
    "text": "Then that is going to be a point where there's a stationarity in the overall flow",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1147.591,
    "end": 1153.279,
    "text": " densities of those two bodies of water, just like if it were two bodies of heat.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1154.321,
    "end": 1159.308,
    "text": "And so we're solving for a special place, which is where the total flow rate is zero.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1162.398,
    "end": 1165.139,
    "text": " Can I just ask a question on that without going too deep?",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1165.799,
    "end": 1191.925,
    "text": "But so in a way, the, the, the flow is the, the ability of having this relationship to the flow is it gives, it gives you a sense, I suppose you could say it's like when the graph, the gradient zero, you know, that the top of a graph between two types of descent and it's, it's, it's got like that, that flat gradient, it gives you a chance to choose moments, which could have a particular,",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1193.472,
    "end": 1197.735,
    "text": " set of properties without having to calculate everything about it.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1198.775,
    "end": 1200.977,
    "text": "Now when that happens, what happens then?",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1201.437,
    "end": 1207.661,
    "text": "Is it then that you then measure the density and just keep measuring lots of density points when you find the flow points to be at",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1209.204,
    "end": 1212.247,
    "text": " at a state of equilibrium or is there something else?",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1212.707,
    "end": 1213.948,
    "text": "So very good question.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1214.569,
    "end": 1219.954,
    "text": "Taking samples and using that to say something about the landscape is something we are going to get to.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1220.735,
    "end": 1221.455,
    "text": "Welcome, Dean.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1222.116,
    "end": 1231.264,
    "text": "So we will talk about how samples can be empirically taken to say things and do inference on the flow density.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1233.393,
    "end": 1238.755,
    "text": " But you made a good point, which is that we want to figure out something about a special point.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1238.795,
    "end": 1244.057,
    "text": "Let's just say that we knew that we were solving for a quadratic equation, which is going to come into play later.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1244.578,
    "end": 1246.458,
    "text": "So it is going to look like a bowl.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1247.119,
    "end": 1257.503,
    "text": "Now, it'd be awesome to know every single point on the whole bowl, but it turns out we might only be interested or mostly interested in one point, the bottom of the bowl.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1258.323,
    "end": 1265.107,
    "text": " And for a quadratic function, the bottom of the bowl is the only time that the derivative is zero.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1266.068,
    "end": 1270.011,
    "text": "So we can have this big nasty quadratic equation and then",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1270.97,
    "end": 1279.755,
    "text": " take the derivative of it, the first derivative, and then just ask, when does the first derivative, the slope of the curve equal zero?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1280.416,
    "end": 1284.278,
    "text": "And we know that for a quadratic equation, there's only one point where that happens.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1284.518,
    "end": 1295.085,
    "text": "And either it's like a bowl or it's like an upside down bowl, but because we constrained the discussion to a specific family of equations, which is gonna be important for variational inference,",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1295.925,
    "end": 1311.669,
    "text": " we can then solve some very reduced equations like the derivative, which is of a lower order of computational complexity, and then just get the one point that we actually wanted, which is like the location of the bottom of the bowl.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1312.33,
    "end": 1319.092,
    "text": "And then from the bottom of the bowl and some of the coefficient estimates that we have, we actually do get the whole bowl.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1319.872,
    "end": 1323.353,
    "text": "So this is kind of like we're taking some big family",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1324.293,
    "end": 1343.389,
    "text": " of equations and then we're going to be looking for special points like especially where the flow is at equilibrium or stationarity and then fitting a family of equations with a form that we know we can compute with to approximate",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1344.733,
    "end": 1348.376,
    "text": " a flow that has a different underlying dynamic.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1348.636,
    "end": 1357.123,
    "text": "And that is going to come into play where they show very early, you can take a Lorenz attractor, which has some equations that govern its motion.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1357.564,
    "end": 1361.687,
    "text": "So again, those can be moved from the equations of motion to the density dynamics.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1362.728,
    "end": 1368.192,
    "text": "And then you can reconstruct an approximation of its dynamics",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1369.358,
    "end": 1377.304,
    "text": " And your approximation to the dynamics doesn't have to be even of the same form as the generative process itself.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1377.865,
    "end": 1386.692,
    "text": "So it's like you could fit a linear model between height and weight with some error, but that doesn't mean that there is a linear model relating height and weight.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1387.092,
    "end": 1391.095,
    "text": "It just means it's an approximation heuristic with a form that's very easy to solve.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1392.076,
    "end": 1394.578,
    "text": "Stephen, and then welcome Dean, feel free to add anything you'd like.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1395.755,
    "end": 1406.401,
    "text": " So in some ways, this is a bit like that particle wave challenge, whereby you have to use a particle to find where something is in time and space.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1406.441,
    "end": 1421.59,
    "text": "You have to use a very simplified understanding of the wave to say, OK, at this point, I can't have all that other information but to have my location information, even if it's an informational location.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1421.67,
    "end": 1423.351,
    "text": "So it's like the flow...",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1424.534,
    "end": 1433.401,
    "text": " finding a point in the flow gives you a way to identify the location, maybe in the information space.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1433.901,
    "end": 1435.662,
    "text": "And then the Fokker plank,",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1436.445,
    "end": 1453.328,
    "text": " gives you a way to then embellish that with another type of, you know, put information back in a way, back into the cake mix, put a bit more, you know, a bit more salt and a few more chocolate buttons in there.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1453.648,
    "end": 1455.289,
    "text": "And so you can see what's going on.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1456.769,
    "end": 1458.889,
    "text": "Okay, that's quite useful to think about that.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1459.069,
    "end": 1461.93,
    "text": "Would I be right in the sense of like what those two equations are doing?",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1463.03,
    "end": 1471.616,
    "text": " giving you, okay, some chance to choose a moment in information space or physical space.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1472.276,
    "end": 1479.922,
    "text": "So at least you've got something to, and then the other one is giving you a way to then put some information in which you can then start to do some variational processing on.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1482.403,
    "end": 1489.708,
    "text": "I'll give a short thought and then Dean and Blue, feel free to say hello and just any overall thoughts and take it wherever you want to go.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1489.728,
    "end": 1489.808,
    "text": "Most",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1492.574,
    "end": 1499.679,
    "text": " dynamical systems have been framed classically using these equations of motion.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1500.319,
    "end": 1507.784,
    "text": "So you get like a matrix that describes the differential equations that describe the unfolding of the Lorenz attractor.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1508.104,
    "end": 1510.726,
    "text": "So it's framed as a series of dynamical equations.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1511.367,
    "end": 1516.35,
    "text": "So this early equivalence allows us to bring some of the tools of",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1518.237,
    "end": 1526.9,
    "text": " fluid mechanics and density dynamics and flow to bear on these dynamical systems.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1528.68,
    "end": 1540.284,
    "text": "So there are some ingredients or some kitchen tools that make approximations to flow very useful",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1541.428,
    "end": 1546.789,
    "text": " for equations of motion that might be intractable if you try to solve it on just that domain.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1547.47,
    "end": 1555.312,
    "text": "Like figuring out a chaotic system's underlying generative process, it's basically not possible.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1556.572,
    "end": 1567.375,
    "text": "But potentially by approximating it with a very specific type of approximation, families of functions that we know have certain behaviors, which we're gonna talk more about,",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1568.562,
    "end": 1582.974,
    "text": " using approximation families that are well behaved and using some of the things that have been developed from flow decomposition, like the Helmholtz decomposition, that doesn't exist for dynamical systems.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1583.755,
    "end": 1596.105,
    "text": "So by making that equivalence between dynamical systems and flowing systems, we can then use flow tools to study dynamical systems",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1597.245,
    "end": 1602.826,
    "text": " as well as making it clear that we're describing the flow of our approximation.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1603.666,
    "end": 1608.288,
    "text": "But it turns out that that does pretty well, at least in some of these examples that they're going to present in the paper.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1609.008,
    "end": 1611.408,
    "text": "So, Dean, and then Blue.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1613.269,
    "end": 1613.909,
    "text": "Hi, I'm Dean.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 1613.949,
    "end": 1618.27,
    "text": "I wasn't going to come on today, but the conversation was stimulating enough.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 1618.37,
    "end": 1623.731,
    "text": "I figured I had to jump in here and maybe add my two cents at some point.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 1625.796,
    "end": 1626.096,
    "text": " Thanks.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1626.716,
    "end": 1627.037,
    "text": "And Blue.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1628.217,
    "end": 1629.038,
    "text": "Hi, I'm Blue.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1629.218,
    "end": 1631.419,
    "text": "I'm a research assistant in New Mexico.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1631.819,
    "end": 1642.484,
    "text": "And I was into this paper because it, I don't know, kind of piqued my interest in information geometry.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1642.564,
    "end": 1646.847,
    "text": "And Daniel, I saw like in the dot zero that you had mentioned that course that's online.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1646.887,
    "end": 1648.327,
    "text": "I'm like going to look into that for sure.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1649.608,
    "end": 1655.571,
    "text": "And, you know, I am curious about like a lot of the leaps that were maybe made in this paper between like",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1656.171,
    "end": 1659.454,
    "text": " particles from particles to cells and back to particles again.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1659.554,
    "end": 1662.836,
    "text": "And those kinds of transitions get a little fuzzy for me.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1662.996,
    "end": 1665.958,
    "text": "So I'm curious to see kind of where this flows to.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1667.239,
    "end": 1667.4,
    "text": "Yep.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1667.6,
    "end": 1672.183,
    "text": "I think that was the information geometry course of John Bayes.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1672.263,
    "end": 1672.844,
    "text": "So that's like,",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1673.749,
    "end": 1678.295,
    "text": " Again, I haven't taken that, but I know that that's recommended and very cool.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1680.317,
    "end": 1692.472,
    "text": "So we talked a little bit about flow, about that's kind of one of the dreams that we could have a unified flow model for heat and people, information, behavior, strategy, etc.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1693.653,
    "end": 1714.353,
    "text": " um and one of the earliest moves that they do in the paper is just to really lock down this connection between dynamical systems systems through time and systems with density so it's worth just repeating that because that's the second section of the paper and that's going to be a lot of the build up another",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1715.376,
    "end": 1735.736,
    "text": " term that comes into play is the lyopinib exponent and chaotic systems so if anyone has a thought of course just raise your hand but one way that chaotic is quantified and formalized this doesn't mean it's the only sense of the word chaotic because sometimes people do use it non-technically",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1736.437,
    "end": 1748.785,
    "text": " But the technical definition of chaotic is referring to the extent of the sensitivity of the system to small changes, for example, in initial conditions or in perturbations.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1749.665,
    "end": 1759.672,
    "text": "And so there's what's known as a Lyapunov exponent, which is something that can be calculated from the model of a dynamical system.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1760.652,
    "end": 1762.714,
    "text": "And there are some dynamical systems where",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1763.945,
    "end": 1766.208,
    "text": " adjacent points stay adjacent.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1766.468,
    "end": 1770.033,
    "text": "So it's like two pieces of wood that are just put in a river that's moving straight forward.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1770.613,
    "end": 1775.5,
    "text": "There's other systems where adjacent points converge or where adjacent points diverge.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1775.9,
    "end": 1777.602,
    "text": "And it depends where you are in the system.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1777.782,
    "end": 1780.185,
    "text": "Like if you're at the bottom of the bowl, then",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1782.164,
    "end": 1783.785,
    "text": " either way you go, it's like a stable equilibrium.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1783.805,
    "end": 1785.066,
    "text": "You're going to get pushed back in.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1785.707,
    "end": 1792.891,
    "text": "But if the bowl were upside down, then either point to the side of the top of the bowl would push you and diverge.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1793.372,
    "end": 1795.733,
    "text": "So that's the Lyapunov exponent.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1796.614,
    "end": 1796.754,
    "text": "And",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1798.277,
    "end": 1820.409,
    "text": " there's a lot of technical detail in exploring chaotic systems from this perspective um so that's one matrix term that comes into play is using the lyopinib exponents especially the leading lyopinib exponents to characterize some of the attributes of a system stephen",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1822.773,
    "end": 1840.603,
    "text": " I think it's good to mention that idea of a system, two things coming together, and when they can meet, the system as well, they can converge or they diverge, but they could also, when they bump into each other, there's also the dynamics of the system",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1841.513,
    "end": 1851.277,
    "text": " So as well as the system's dynamics merging, the dynamics of the change, it will stop changing once they meet, right?",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1851.757,
    "end": 1862.341,
    "text": "So there's also that extra level of dynamical change, which you get with these nonlinear dynamical systems, which are actually working with the dynamics of the change.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1862.701,
    "end": 1864.001,
    "text": "So it can sort of reset itself.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1864.061,
    "end": 1868.083,
    "text": "It's not like once they're in a physical system, they've come together, that's kind of it.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1868.503,
    "end": 1870.744,
    "text": "When you're dealing with variations on change,",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1872.358,
    "end": 1873.679,
    "text": " it becomes much more generative.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1873.699,
    "end": 1875.821,
    "text": "Okay.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1875.861,
    "end": 1876.121,
    "text": "Yes.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1876.381,
    "end": 1885.227,
    "text": "So sometimes these exquisite sensitivities to tiny, tiny differences in initial conditions, they get swamped by random fluctuations.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1886.168,
    "end": 1886.308,
    "text": "So,",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1889.102,
    "end": 1910.347,
    "text": " that's what's interesting about their approach here is again they're partitioning out the flow from the fast fluctuations and then they're describing how when random fluctuations are added in then the strange attractor is going to be replaced by a pullback attractor",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1911.519,
    "end": 1913.28,
    "text": " And then the flow is the expected motion.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1913.5,
    "end": 1918.364,
    "text": "So that's the movement of the river of the flow term.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1919.144,
    "end": 1922.967,
    "text": "If this flow shows exponential divergence of trajectories, i.e.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1923.467,
    "end": 1927.25,
    "text": "positively operative exponents, we can impute stochastic chaos.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1930.052,
    "end": 1938.037,
    "text": "They then use this approach to investigate one of the classic equations",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1938.615,
    "end": 1945.281,
    "text": " chaotic systems which has also been one of the earliest chaotic systems of lorenz who",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1946.673,
    "end": 1953.578,
    "text": " Maybe there was some other livestream where we did a little bit more on the Lorenz, but it was a meteorology question.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1954.199,
    "end": 1964.347,
    "text": "Lorenz and colleagues were studying the weather and how it changes and about some of the sensitivity of the dynamical models to tiny changes.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1964.727,
    "end": 1975.755,
    "text": "Like it seems like if it's, you know, 21.1 C, it seems like that should be very similar in its behavior in the long run to it being just 0.1 degree higher.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1976.696,
    "end": 1996.922,
    "text": " and then as you got further away it's like well then it'd be way more different in the future if it's more different today but then it could actually turn out that a tiny difference ends up sending your equations haywire whereas a very different initial condition might actually like feed back and come back to a similar attractor through time",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1997.742,
    "end": 2001.267,
    "text": " So that's the kind of systems that they were investigating in like the 1950s.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2002.008,
    "end": 2007.194,
    "text": "And there's been a lot of computer and technical work since then.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2007.615,
    "end": 2015.705,
    "text": "But this is still a total classic and a beautiful strange attractor for them to be working on as the first example in their paper.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2015.866,
    "end": 2016.086,
    "text": "Stephen?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2018.314,
    "end": 2036.429,
    "text": " So from what you're saying, the strange attractor is the kind of complexity science idea of these mathematical models where things get caught in, as you just described, and initial conditions can change the nature of what that becomes within a certain range.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2036.469,
    "end": 2039.492,
    "text": "And obviously outside that range, it doesn't form.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2039.592,
    "end": 2041.454,
    "text": "So it's still kind of off equilibrium.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2042.434,
    "end": 2045.297,
    "text": "This pullback attractor is a...",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2048.422,
    "end": 2061.022,
    "text": " is a almost a set of states which can be moved towards through looking at the flows within",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2062.395,
    "end": 2064.216,
    "text": " other types of chaotic attractors.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2064.816,
    "end": 2066.517,
    "text": "So it's making a difference.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2067.297,
    "end": 2080.322,
    "text": "In some ways, the pullback attractor would need or involve some sort of inference or some sort of driver to make it happen.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2080.382,
    "end": 2087.865,
    "text": "It's not inherent to the nature of the mathematics of that particular thing once you let it roll.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2088.026,
    "end": 2088.886,
    "text": "Would I be right in that?",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2090.279,
    "end": 2115.932,
    "text": " so the pull back attractor it's kind of like let's just imagine the attractor is like a post in the ground and there's a bungee cord so if we were looking at that quadratic bowl it'd be like there's an attractor at the bottom of the bowl and then if all you saw was the lateral movement of the particle so we don't know anything about the height necessarily or the shape of the graph we just observe that when we push the ball to the left",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2116.872,
    "end": 2122.895,
    "text": " it gets pulled back as if it's being on a bungee cord, pulled left, maybe it even overshoots and it kind of dampens.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2123.475,
    "end": 2126.637,
    "text": "So that's like a pullback attractor to a point attractor.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2128.547,
    "end": 2132.93,
    "text": " What's being shown here is an attractor that is in higher dimensions.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2133.431,
    "end": 2140.436,
    "text": "So if you had a two-dimensional pullback attractor, it'd be like the line Y equals X. And if you get perturbed off the line, you come back down into the valley.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2141.057,
    "end": 2145.4,
    "text": "So that's like where you start to see vector fields and the flow of water into a river.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2146.181,
    "end": 2153.026,
    "text": "And now we're in a three-dimensional attractor, at least three spatial dimensions.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2153.886,
    "end": 2157.709,
    "text": "And so it's kind of like there's a race car going around this butterfly track.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2158.69,
    "end": 2159.971,
    "text": " And then it has the bungee cord.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2160.331,
    "end": 2163.754,
    "text": "So you're getting pulled to this car that's moving.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2164.215,
    "end": 2182.869,
    "text": "And then if you sample your location at different times, you're being drawn to a pullback attractor, which is the compromise between the flow as defined by the equations of motions of Lorenz attractor and the fast stochastic fluctuations.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2183.69,
    "end": 2184.871,
    "text": "Dean and then Steven.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2186.65,
    "end": 2201.502,
    "text": " Yeah, just quickly, I think this is why sometimes using the metaphor of building a bridge is difficult because not all times is as convenient as the lowest energy state in a bowl.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 2202.243,
    "end": 2207.987,
    "text": "Sometimes what we have to look at is the fact that one end, call it point A,",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 2210.499,
    "end": 2216.622,
    "text": " we're trying to figure out what point B is, and it isn't always the lowest energy state.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 2216.662,
    "end": 2218.102,
    "text": "I think here's an example.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 2218.282,
    "end": 2227.427,
    "text": "So if you've been to Hudson Yards in New York, it's a fascinating translation of a space over time.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 2228.539,
    "end": 2248.949,
    "text": " And if you were to ask the people who actually constructed those high trestles at the point that they were built, if you had asked them X number of years later whether or not that was going to be the lowest possible energy state or a tractor state, I don't think they could have predicted that.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 2250.049,
    "end": 2260.947,
    "text": " And so that's why I think it's difficult at times when we, for the sake of convenience, to expedite our sense of what's going to happen next, we use a connector metaphor.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 2261.728,
    "end": 2264.493,
    "text": "But in fact, that's not exactly what stochastic communication",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 2265.216,
    "end": 2267.177,
    "text": " possibility is about.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 2267.998,
    "end": 2275.562,
    "text": "So what we tend to do is collapse down too quickly, down to the particulars of what purpose a product can serve.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 2276.323,
    "end": 2289.651,
    "text": "And if we're going to build a bridge from a product to a process, which is what I think looking at stochastic separation is about, we should maybe drop the idea of",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 2291.246,
    "end": 2302.795,
    "text": " a static connector and maybe look at the back and forth and the actual dynamics of those dynamic situations, which were now the tool of active inference affords.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 2305.043,
    "end": 2306.183,
    "text": " Oh, interesting.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2306.243,
    "end": 2309.344,
    "text": "It just made me think about like throwing a Frisbee and it catches on a roof.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2310.044,
    "end": 2312.065,
    "text": "That's its lowest local energy state.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2312.445,
    "end": 2316.106,
    "text": "But if you just thought about gravity, maybe you'd say, well, it's going to fall to the ground.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2316.566,
    "end": 2324.108,
    "text": "So one particular trajectory may not realize the ultimate lowest energy state yet.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2324.728,
    "end": 2326.589,
    "text": "In a way, it's in its own energy state.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2327.269,
    "end": 2327.849,
    "text": "So Stephen.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2331.078,
    "end": 2341.743,
    "text": " Yeah, so thinking again about applications, I think what Dean mentions is a good point, is there's an actual tendency to want to have that kind of bridge between two stable things.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2342.683,
    "end": 2356.089,
    "text": "The thing with two stable things is they're stable, as we just mentioned, so therefore if you're trying to get information about variations within them, particularly chaotic variations, you're not going to get much, right?",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2356.109,
    "end": 2357.65,
    "text": "So you kind of need...",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2358.476,
    "end": 2373.504,
    "text": " there's, there's a need to be off out of equilibrium to, to give the conditions where things can move in potentially a strange attractor or potentially other types of solenoidal flows or something.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2373.524,
    "end": 2375.565,
    "text": "There needs to be some way for flows to happen.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2376.526,
    "end": 2381.909,
    "text": "And then within that, which I think that might explain why that last graph.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2382.029,
    "end": 2385.551,
    "text": "So if I'm, if I'm right in thinking that those four graphs that you showed there,",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2386.308,
    "end": 2415.04,
    "text": " kind of showing that you've got this strange tract that you can sort of look at the state space using points of where something has become momentarily zero in the flow calculation gives you a zero so you can then take a point and then the bottom right is basically saying you can recapitulate that as a global potential so you can sort of",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2416.124,
    "end": 2425.391,
    "text": " by taking the changes that happen in the second order, you can sort of recapitulate some kind of understanding of the structure of the information.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2426.051,
    "end": 2426.511,
    "text": "Is that right?",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2429.533,
    "end": 2431.315,
    "text": "There's a lot there.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2433.191,
    "end": 2449.667,
    "text": " So I cannot reduce it to a binary, but yes, it is showing different aspects of how strange attractors, which are found in these sort of exotic deterministic chaos systems, like a perfectly clean double pendulum.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2450.688,
    "end": 2455.953,
    "text": "And then how, when we take the approximation, we find a pullback attractor empirically in",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2458.22,
    "end": 2482.109,
    "text": " approximation so now we're describing a nicer still stochastic but much nicer and more approachable pullback attractor like it's being pulled back to some butterfly shape now we don't get these like rings of jupiter situation from our sampling because we're taking particular samples and we're fitting then",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2483.266,
    "end": 2506.349,
    "text": " a flow what flow generated those samples so we never see rings of jupiter strange attractor we're dealing with approximations of random attractors and then we have at least two tools slash helpful techniques to apply that are going to help us come to terms with that",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2507.458,
    "end": 2508.099,
    "text": " approximation.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2508.719,
    "end": 2513.883,
    "text": "So one of them is we're dealing with flow, so we can talk about the Helmholtz decomposition.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2514.363,
    "end": 2528.654,
    "text": "So this was discussed a lot in Act Inf 26, and as mentioned in the .0, Stochastic Chaos in Markov Blankets was submitted like a few weeks after 26 was submitted, Bayesian Mechanics.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2529.335,
    "end": 2529.435,
    "text": "So",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2531.414,
    "end": 2540.482,
    "text": " The Helmholtz decomposition describes this partitioning into the irrotational, kind of the gradient, putting the ruler on the hill.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2540.723,
    "end": 2541.824,
    "text": "What is the angle of the ruler?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2541.944,
    "end": 2543.665,
    "text": "If you're on the top of the hill, it's flat.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2544.186,
    "end": 2546.108,
    "text": "If you're on the hill, it's going to be at an angle.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2546.728,
    "end": 2554.475,
    "text": "So separating that ruler on the hill to the hiking map, the isocontour.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2554.976,
    "end": 2556.717,
    "text": "So let's make the ruler flat.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2557.56,
    "end": 2564.687,
    "text": " wherever it is, whatever the slope is, and then let's just take that ruler and kind of move it side to side as we go around this hill.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2565.367,
    "end": 2571.113,
    "text": "Now, if you're on the very top of the hill, then the ruler is flat and there's no isocontour.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2571.894,
    "end": 2575.897,
    "text": "But if you're anywhere else on that whole landscape other than a local maxima,",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2576.658,
    "end": 2581.504,
    "text": " there's going to be some angle to the ruler and some way to get around the hill.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2582.225,
    "end": 2583.827,
    "text": "So that's the Helmholtz decomposition.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2583.847,
    "end": 2586.811,
    "text": "So that's one piece that we get to bring to the puzzle.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2587.392,
    "end": 2594.421,
    "text": "And then one piece that would be interesting to ask the authors or someone with more technical experience is,",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2595.242,
    "end": 2615.624,
    "text": " We've seen the Helmholtz decomposition before into the solenoidal and the gradient components, but then there's this housekeeping term, capital Lambda, and that's described in an appendix and it gets quite technical, but it has to do with the density landscape changing.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2616.685,
    "end": 2636.882,
    "text": " as a function of flow so it's not just like we're going to have one mountain topography and then we're going to have rain falling on that one mountain there's going to be some changes as we flow around so that it's more like you know you have a jet of hot water into a cold water",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2638.553,
    "end": 2646.415,
    "text": " you can't just take the mountain of temperature and then just ask, well, what happens if we pour hot water on top of that mountain?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2647.135,
    "end": 2649.556,
    "text": "Because the mountain is actually changing.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2649.596,
    "end": 2651.856,
    "text": "The landscape is changing as a function of the flow.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2652.476,
    "end": 2655.157,
    "text": "And some of that gets incorporated into this housekeeping term.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2655.637,
    "end": 2667.78,
    "text": "So one tool that we have is from the flow toolkit is the Helmholtz decomposition into these different components that help us reconstruct",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2669.181,
    "end": 2672.364,
    "text": " a flow that is a much better approximation.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2673.745,
    "end": 2675.787,
    "text": "Stephen?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2675.807,
    "end": 2681.252,
    "text": "You mentioned there that we've seen solenoidal and gradient before with Helmholtz decomposition.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2682.173,
    "end": 2686.897,
    "text": "When you say we've seen it before, you're saying we've seen it more recently with the solenoidal work.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2686.917,
    "end": 2691.001,
    "text": "Or has the solenoidal been in there all along?",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2691.962,
    "end": 2693.363,
    "text": "Like this was drawn...",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2695.578,
    "end": 2695.838,
    "text": " Oh yeah.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2695.858,
    "end": 2700.302,
    "text": "Like we've discussed it in paper number 26 and other papers.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2700.382,
    "end": 2715.716,
    "text": "Like this is not a novel partitioning by the authors and it's very linked to other discussions that we've had about Helmholtz decomposition in the context of distributional approximation.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2716.677,
    "end": 2716.737,
    "text": "Hmm."
  },
  {
    "start": 2717.602,
    "end": 2717.862,
    "text": " Got you.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2718.323,
    "end": 2721.989,
    "text": "But previously, was there... It was more of a focus on gradient descent.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2722.75,
    "end": 2725.234,
    "text": "The focus was in your regime of attention, potentially.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2725.254,
    "end": 2726.355,
    "text": "Right.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2726.375,
    "end": 2728.679,
    "text": "It was... Okay, right.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2728.699,
    "end": 2730.161,
    "text": "Going way back to early days.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2730.261,
    "end": 2730.462,
    "text": "Okay.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2731.63,
    "end": 2742.876,
    "text": " Okay, so in that paper that was looking at solenoidal flow, it was giving more weight to that, wasn't it?",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2743.056,
    "end": 2746.438,
    "text": "Would you say it was giving more weight, or was it using that in a different explanatory way?",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2746.458,
    "end": 2758.284,
    "text": "Because there has been this shift around solenoidal flow to give another way beyond ergodicity to explain how these dynamics can work.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2759.645,
    "end": 2765.448,
    "text": " They're kind of co-instantiated because they're partitionings from each other of the same underlying model.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2765.748,
    "end": 2788.38,
    "text": "So which one is emphasized more is totally a question of situation and flourish, but it also may be the case that over the previous three years, there's more of an emphasis on the importance of the isocontours in complex problem solving, as opposed to just run and gun gradient descent.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2789.628,
    "end": 2791.709,
    "text": " So I agree with that.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2791.789,
    "end": 2793.15,
    "text": "So that's one tool we have.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2793.35,
    "end": 2800.553,
    "text": "Okay, so we do the Helmholtz decomposition because again, we're making this deep equivalence between dynamical systems and flow systems.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2801.814,
    "end": 2806.736,
    "text": "So one tool we have from the flow world is the Helmholtz decomposition for vector fields.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2807.976,
    "end": 2815.34,
    "text": "Now, they write in section 3.1, our objective is to identify the functional form",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2816.624,
    "end": 2820.265,
    "text": " So it could be used in the sense like, what function does it play?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2820.405,
    "end": 2822.405,
    "text": "Or a functional is like a function of a function.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2823.546,
    "end": 2830.287,
    "text": "A functional form of the self-information or potential function that describes the non-equilibrium steady state density.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2831.087,
    "end": 2833.268,
    "text": "Okay, so we go back to in three.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2834.088,
    "end": 2838.169,
    "text": "The fancy I, the fancy J, they write...",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2839.11,
    "end": 2853.054,
    "text": " The first dissipative part performs a Riemannian gradient descent on a manifold on the negative logarithm of the steady state density, which can be interpreted as the self-information of any given state or as some potential function.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2853.614,
    "end": 2856.575,
    "text": "So this is how surprised should I be to be in this state?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2857.095,
    "end": 2858.436,
    "text": "So now let's go back to our bowl.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2859.141,
    "end": 2861.522,
    "text": " You shouldn't be surprised if you're at the bottom.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2862.263,
    "end": 2865.505,
    "text": "You should be surprised if you're at the top, there's high potential.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2865.945,
    "end": 2872.469,
    "text": "Now, if it were gravity that were pulling us down, that would be potential energy, gravitational potential energy.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2873.029,
    "end": 2877.272,
    "text": "You have higher gravitational potential energy that can get dissipated",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2878.103,
    "end": 2899.108,
    "text": " free energy can be dissipated if you have greater potential energy so we want something that is just like you could have the bowl and the ball and know where's the ball expected to be and where is it going to roll down from where's their potential that's high and where's the potential low and then",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2900.908,
    "end": 2906.613,
    "text": " Here in figure one, they're going to plot self-information on the bottom left.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2907.094,
    "end": 2908.595,
    "text": "That's the wax, self-information.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2909.416,
    "end": 2912.378,
    "text": "And then that is fluctuating through time.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2913.199,
    "end": 2921.586,
    "text": "As the system is cranked, it's kind of like if the self-information were staying at a constant value, it'd be like, if you're in that race car going around the track,",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2922.347,
    "end": 2945.38,
    "text": " then you're always where you expect to be because again the bowl it's like a point attractor and then the lorenz approximation is going to be to a dynamical approximation so we want to find the function of the non-equilibrium steady state that's going to be describing how surprised you should be the potential function for that system",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2947.034,
    "end": 2952.618,
    "text": " So these are big questions like how is the self-information measured or calculated?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2953.478,
    "end": 2957.741,
    "text": "And then what does it mean for the self-information to be high or low?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2958.94,
    "end": 2968.629,
    "text": " And how does the self-information for different states that we might care about, like homeostasis, how does the self-information in those cases differ?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2969.029,
    "end": 2975.615,
    "text": "Like, is the self-information higher or lower when homeostatically you're in a good attractor?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2975.855,
    "end": 2976.896,
    "text": "So Dean, then Stephen.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2978.846,
    "end": 3000.064,
    "text": " So I don't know this, but I would guess that on some basic level, the measure is on its most absolute terms, greater or less than to begin with, because I think that relative difference is something that anybody doesn't even have to be aware of consciously calculating.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3000.625,
    "end": 3006.77,
    "text": "They can just, you can kind of tell, but I'm not really sure, but I would think",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3008.151,
    "end": 3025.401,
    "text": " that as we go up in terms of the determination and the accuracy of the measure, we could find ourselves getting more precise, but on its most basic level, I would think it would, from a functional standpoint, that's where we would have to begin.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3029.063,
    "end": 3035.207,
    "text": "Yes, and being less surprised about the state that one is in,",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3036.471,
    "end": 3041.535,
    "text": " entails having a richer and a more accurate generative self-model.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3042.395,
    "end": 3046.238,
    "text": "So if you have a model that's just totally off base, you're going to be recurrently surprised.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3047.099,
    "end": 3059.348,
    "text": "If you have a very nuanced self-model, your location and your circadian rhythm, then different observations will be less surprising.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3060.775,
    "end": 3064.157,
    "text": " I was just feeding back what you were saying because you did a really good explanation.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3064.797,
    "end": 3072.52,
    "text": "But in your explanation, the key thing was I should be more surprised or I should be less surprised.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3072.58,
    "end": 3077.703,
    "text": "You yourself in doing the explanation, come back to that basic difference.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3078.7,
    "end": 3086.828,
    "text": " And so again, as we get more precise, I think we can have more sophisticated ways of being able to show how we arrived there.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3087.048,
    "end": 3093.554,
    "text": "But at the beginning, even a two-year-old can somehow tell the difference between more and less.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3094.074,
    "end": 3095.716,
    "text": "That's why they dig in their heels, right?",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3096.637,
    "end": 3103.764,
    "text": "So it seems like on that basic level, before we get into some of the more sophisticated stuff,",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3104.409,
    "end": 3113.134,
    "text": " we all can, where it says addresses these questions for one simple case, I think on its simplest terms, that's where we can probably start.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3115.296,
    "end": 3116.457,
    "text": "We can look there first.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3116.717,
    "end": 3120.999,
    "text": "If that's not available, I don't know that the other math matters.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3121.58,
    "end": 3126.483,
    "text": "I know it does, but to the person who can't see that first, I'm not sure where they go.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3128.154,
    "end": 3142.525,
    "text": " This past weekend, we were hanging out with some larva, with some children, and we were really struck by how there would be some times where it seemed like you just would tell them something totally different, like switch topic in the middle of a sentence, and they just went along with it.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3143.206,
    "end": 3150.691,
    "text": "And then other times where they needed something really specific, like they wanted that piece of food and they want it in this part of the plate and they want to touch it this way.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3151.272,
    "end": 3155.835,
    "text": "And so it's like, they have a generative model and there's certain parts",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3156.809,
    "end": 3158.47,
    "text": " that they're surprised by or not.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3158.91,
    "end": 3163.271,
    "text": "And so we're just like, we want that piece of food and I'm not too surprised at the route it takes to my plate.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3163.832,
    "end": 3170.614,
    "text": "But if their generative model entails a specific way that that is going to get to their plate, they're going to be surprised by anything other than that.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3170.714,
    "end": 3183.138,
    "text": "And if they don't have a generative model of topics in the world, then switching topics and talking about this event and then that event, it's just like, it's as if any other set of topics were addressed.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3183.599,
    "end": 3183.719,
    "text": "So,",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3184.719,
    "end": 3191.425,
    "text": " Great point about our intuitive connection to surprising information, how that's related to our generative modeling.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3191.665,
    "end": 3192.746,
    "text": "So Blue and then Steven.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3196.63,
    "end": 3209.441,
    "text": "So just to go to your child model, like having, you know, had lots of kids around for a lot of time, you know, food is something particularly that they like fixate on, right?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3210.049,
    "end": 3214.771,
    "text": " I mean, my younger stepdaughter is like one of the easiest kids ever.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3214.891,
    "end": 3216.572,
    "text": "Like she's so chill and so laid back.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3216.972,
    "end": 3219.873,
    "text": "But like I remember when she was about two years old, she would like freak out.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3219.893,
    "end": 3225.375,
    "text": "Like one time I cut an apple for her, like sliced it up, you know, just to make it like easy to eat.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3225.834,
    "end": 3229.199,
    "text": " And she like got so mad because she wanted the whole apple, the whole thing.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3229.779,
    "end": 3232.163,
    "text": "And she thought I was only giving her part of it.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3232.203,
    "end": 3240.855,
    "text": "But I think maybe food is, I mean, my point is I'm rambling about the story, but maybe food is one of these things that is like so baked in.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3241.375,
    "end": 3265.432,
    "text": " to our generative model because otherwise the children have an attention span of a gnat like you know you're in the car and they start to argue and you just say oh look at that pretty yellow car right there and then they're done they're over it like so so generally like the you can surprise a child and completely shift them but when it comes to food it's like this weird and many kids like that just you know aspen with the apple but then there's also like this food can't touch that food",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3265.992,
    "end": 3289.205,
    "text": " and like they have a bigger piece of cake than me and all this stuff so so this food like this fundamental like baked in thing that that's like central to survival and therefore it's like very deeply ingrained in our generative model maybe nice agree steven yeah so the idea of children i'll keep that analogy in there um",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3291.36,
    "end": 3315.728,
    "text": " if so we've got this these flows happening and we we have um state spaces that get readings off so the very first state space reading i mean unless you've got a prior somehow to go on you don't really know what that means and you get another one another one and so you get a series of state space insights so to speak and then you'll start to get a sense of whether something's more or less than",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3316.681,
    "end": 3318.603,
    "text": " I mean, the simplest term, the average, right?",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3318.623,
    "end": 3324.268,
    "text": "But we can then use gradient descent and that to sort of get an understanding of that.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3324.348,
    "end": 3326.15,
    "text": "And with children, that can be interesting is,",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3327.042,
    "end": 3329.064,
    "text": " So, yeah, sometimes I just want to go with everything.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3329.204,
    "end": 3332.947,
    "text": "And I notice also, like, I get that with my daughter, Layla.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3332.987,
    "end": 3339.272,
    "text": "Sometimes it's like, you know, she'll say, like, I want something very specific.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3339.332,
    "end": 3342.095,
    "text": "Or that school there, so-and-so went to that school.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3342.435,
    "end": 3343.756,
    "text": "Like, now she knows that.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3344.056,
    "end": 3348.2,
    "text": "Well, I know because that's what happened when I was little, meaning when she was a small baby.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3349.081,
    "end": 3350.262,
    "text": "And it's all kind of made up stories.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3350.802,
    "end": 3377.163,
    "text": " stories in some extent but it's kind of like she's converging on she's got enough state space information to say okay and and probably you've got that with food right it's like there's there's enough state space information to say this and and they can be proud as and i know that and you didn't know that she said to me you know i knew that you didn't know that i knew that uh this is quite cute but you you've got that okay so she's got enough state space awareness",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3378.442,
    "end": 3405.961,
    "text": " they're going to converge down and then there's other times like when you want them to just stay on the football pitch and not run off the swings uh they just go crazy so there's something about you know sampling the space and saying you've got enough information and synchronization onto joint action manifolds is going to be one of the prices of the paper so blue as a response and then dean",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3408.846,
    "end": 3419.43,
    "text": " So, you know, super interesting about like asking your daughter, Steven, like, you know, or the thing she says that she remembers from when she was a baby, something that's really fun to do with kids.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3419.73,
    "end": 3424.832,
    "text": "And it's also leads to like the synchronization where I feel like maybe we're going, but yeah.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3425.743,
    "end": 3434.385,
    "text": " ask a kid when they can first talk, like when they can barely talk, maybe like, you know, two years old ish, um, ask a kid where they were before they were born.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3434.405,
    "end": 3436.406,
    "text": "Um, the answers are awesome.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3436.466,
    "end": 3438.646,
    "text": "Or like, do you remember being in your mommy's tummy?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3438.706,
    "end": 3445.508,
    "text": "Like, and like, you know, I've, I've heard ranges and ranges of, of answers from kids and it's really super interesting.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3445.548,
    "end": 3446.348,
    "text": "So where is this?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3446.408,
    "end": 3448.528,
    "text": "Like, is this some inherited prior?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3448.588,
    "end": 3450.969,
    "text": "Is this like past life regression or is it just like",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3451.309,
    "end": 3452.91,
    "text": " They're falling into synchronization.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3452.95,
    "end": 3456.593,
    "text": "They're making something up because children have these like great imaginations at that age.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3457.313,
    "end": 3459.054,
    "text": "But where does this come from?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3459.134,
    "end": 3462.997,
    "text": "Like, are they just responding back to what they think you want to hear?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3463.057,
    "end": 3465.778,
    "text": "This is like an absurd question to ask a kid, right?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3465.798,
    "end": 3473.664,
    "text": "Like, I mean, you can't really expect a reasonable answer, but ask because it's fun to find out what they think that they were doing before they got here.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3474.344,
    "end": 3474.684,
    "text": "It's fun.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3475.225,
    "end": 3477.286,
    "text": "And Dean, first.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3478.53,
    "end": 3488.255,
    "text": " Yeah, I think it's interesting because if you're going to go back to that geometry aspect of, you know, can two-year-olds think in the abstract state?",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3488.315,
    "end": 3490.356,
    "text": "Yes, they can, number one.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3491.157,
    "end": 3502.722,
    "text": "And the other part I think we're sort of, we're all sort of synchronizing around is that if it's less or more, that can be represented by the X and the Y on a graph.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3503.443,
    "end": 3504.443,
    "text": "We've already shown that.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3505.024,
    "end": 3507.345,
    "text": "But if you want to think whether it's in or out,",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3508.086,
    "end": 3510.327,
    "text": " You have to add that Z vector.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3510.887,
    "end": 3517.03,
    "text": "And that is the part that most learning doesn't necessarily explicate.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3517.311,
    "end": 3517.831,
    "text": "It's there.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3518.151,
    "end": 3519.011,
    "text": "Two-year-olds do it.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3519.492,
    "end": 3520.852,
    "text": "They know whether they're in or out.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3521.353,
    "end": 3524.194,
    "text": "They know whether they're getting the whole apple or a slice.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3525.174,
    "end": 3527.856,
    "text": "So again, I ask,",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3528.928,
    "end": 3536.535,
    "text": " Are we attempting as people who are trying to help the two-year-old to build a bridge from point A to point B?",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3537.215,
    "end": 3545.803,
    "text": "Or should we be actually understanding this as building something that is a product that is material to something that is possible?",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3545.843,
    "end": 3551.989,
    "text": "That's what the stochastic field is until we collapse it to that point B, right?",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3553.523,
    "end": 3560.927,
    "text": " And the only way that that happens is if we include in and out, if we include the Z dimension to this.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3561.407,
    "end": 3572.712,
    "text": "So, again, if we can't get in our own minds, if we can't get that correct, then we're actually going to get in the way of developing pedagogy.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3574.249,
    "end": 3577.051,
    "text": " I'm sorry to say that, but it's actually true.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3577.532,
    "end": 3583.556,
    "text": "So we can think of these little people as these wonderful little right brains.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3583.656,
    "end": 3589.961,
    "text": "The right brain hasn't been brought down to these equations at the bottom of this page.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3590.261,
    "end": 3591.903,
    "text": "And yet they're still able to function.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3592.563,
    "end": 3599.769,
    "text": "Their functional form is self-information based on product to process, to be determined.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3602.925,
    "end": 3620.778,
    "text": " So, again, I'm not saying this because I've got it all figured out, but because I don't want to have this active inference tool, which is a fantastic potentiator, to be collapsed to, now, here's the potential outcomes that we can engineer A through Z.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3622.277,
    "end": 3627.119,
    "text": " That doesn't allow for a Hudson Yards, and yet there's a Hudson Yards.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3627.559,
    "end": 3637.162,
    "text": "So if we're going to help people, let's not, as you say, Daniel, let's not over reduce prematurely here in the hopes of actually helping people.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3637.562,
    "end": 3651.367,
    "text": "When in fact, what that does is it says, as you fall out of the sky raindrop, you shall depart this flow in Surrey, British Columbia, or the Gulf of California, or",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3652.409,
    "end": 3653.95,
    "text": " at the mouth of the St.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3653.99,
    "end": 3654.57,
    "text": "Lawrence River.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3655.05,
    "end": 3658.612,
    "text": "We can't do that, or we shouldn't, but we do.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3659.052,
    "end": 3662.934,
    "text": "And I can't understand why the greatest thinkers do that.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3662.974,
    "end": 3664.935,
    "text": "Well, I can, because we like to talk.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3665.835,
    "end": 3669.237,
    "text": "But bottom line is, we've got to rethink this.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3669.557,
    "end": 3671.358,
    "text": "That's what active inference supports.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3674.301,
    "end": 3675.981,
    "text": " Totally agreed.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3676.642,
    "end": 3679.722,
    "text": "And we can engineer the landscape of flow.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3680.062,
    "end": 3684.083,
    "text": "You can add a dam so that the water droplets do go one place or another.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3684.323,
    "end": 3686.964,
    "text": "But very interesting metaphor.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3687.124,
    "end": 3690.824,
    "text": "So Stephen on this, and then we're going to go to the next tool that gets introduced.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3693.025,
    "end": 3696.966,
    "text": "Yeah, I think, well, I think, I feel, I know.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3696.986,
    "end": 3700.607,
    "text": "So there's a question of, it's an interesting question as well.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3700.627,
    "end": 3701.787,
    "text": "When you say you've got a two-year-old,",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3703.484,
    "end": 3706.586,
    "text": " is where do they get their knowing from?",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3707.146,
    "end": 3710.047,
    "text": "So we have abstraction in terms of thinking abstraction.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3711.268,
    "end": 3717.951,
    "text": "So we have, well, and the sort of ontological abstractions that we can create around our knowledge structures.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3718.532,
    "end": 3729.057,
    "text": "But they have access to two years of state space, experiential sensations, of which they can then make a story from.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3730.287,
    "end": 3732.43,
    "text": " whichever way they so please, as they can.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3732.45,
    "end": 3740.102,
    "text": "So there's an interesting question that what it means to know that's abstract, i.e., or what's outside of",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3741.394,
    "end": 3743.756,
    "text": " the sort of lived experience level.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3744.156,
    "end": 3746.478,
    "text": "And there's that other way.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3746.678,
    "end": 3757.826,
    "text": "And one thing I always find interesting is I see a child is around the age of two, three, you really see a change in the fingers that the whole morphology of the body shifts.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3758.406,
    "end": 3768.214,
    "text": "And I think one of the reasons that maybe that memories aren't accessible from before the age of three is literally they were encoded in a different body that's too far removed",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3768.934,
    "end": 3775.499,
    "text": " to revisit the priors or the likelihoods from the state spaces that had been laid down.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3775.519,
    "end": 3785.245,
    "text": "So it may be partly a natural way that we sort of forget, but we don't necessarily forget thoughts that we had cognitively.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3785.666,
    "end": 3796.333,
    "text": "We just forget the embodied stuff because we're going to lay down some new stuff, unless you have a trauma, in which case that can lock in certain states.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3797.964,
    "end": 3798.925,
    "text": " Blue, any comments on that?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3803.108,
    "end": 3803.508,
    "text": "Of course.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3804.069,
    "end": 3812.735,
    "text": "So, you know, it's interesting that the encoding in a different body, I mean, we're doing that every seven years, right?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3813.435,
    "end": 3818.519,
    "text": "Like we have full cells turned over, but, you know, there's this process of synaptic pruning that happens.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3819.68,
    "end": 3826.205,
    "text": "So as like we're babies, you know, we grow bazillions of neurons and then synaptic pruning happens like around the age of two or three.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3826.616,
    "end": 3828.337,
    "text": " where a lot of those neurons die back.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3828.477,
    "end": 3834.181,
    "text": "And then the ones that stay exist and continue to build stronger and build better.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3834.242,
    "end": 3841.867,
    "text": "But everyone is so completely different in terms of like their ability to remember things from when they were a baby and not always related to trauma.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3841.887,
    "end": 3847.071,
    "text": "Like I have no conscious memory stream until like I was 10, which is super late.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3847.131,
    "end": 3852.735,
    "text": "And like, there's no, I mean, maybe I might do some like hypnosis and reveal some kind of trauma, like at some point in my life, but",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3853.395,
    "end": 3857.137,
    "text": " I mean, for me to not have any, like, I remember like some flashes of some stuff.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3857.177,
    "end": 3858.097,
    "text": "I remember the photograph.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3858.117,
    "end": 3858.777,
    "text": "You showed me the picture.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3858.858,
    "end": 3859.158,
    "text": "Oh yeah.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3859.498,
    "end": 3859.978,
    "text": "I remember that.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3860.058,
    "end": 3860.678,
    "text": "Do I remember it?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3860.758,
    "end": 3862.179,
    "text": "No, I probably remember the picture of it.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3862.719,
    "end": 3862.899,
    "text": "Right.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3862.939,
    "end": 3872.803,
    "text": "Like, so there's this whole other level of thing, but, but the idea of being encoded in a different body is super interesting because of course my body's different now also from when I was 10.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3872.843,
    "end": 3873.204,
    "text": "Right.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3874.184,
    "end": 3877.986,
    "text": "But I mean, also like, you know, when you're 90, your body's different from when you were 50.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3878.426,
    "end": 3881.407,
    "text": "So what stays, what goes, how is it chosen?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3881.932,
    "end": 3892.741,
    "text": " Is it this embodied aspect of it, or is it just like, you know, we lock into the things that we think are important for our model, and if it's not relevant for our model, maybe we just let it go.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3892.761,
    "end": 3896.204,
    "text": "Dean?",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3897.285,
    "end": 3908.434,
    "text": "I just want to say this real quick, because I know you want to move forward, Daniel, but everything that we describe here, in order to get to a concept of between, whether it's between",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3909.807,
    "end": 3926.703,
    "text": " us today and us seven years plus a day before, that between, or any other between that we want to describe, at some fundamental level, we have to be able to discriminate between more and less and what's in and what's out.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3927.764,
    "end": 3933.269,
    "text": "If we can do those things, we in any situation can describe between.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3934.147,
    "end": 3946.68,
    "text": " Now, once we can describe between, we can see a difference between what a product is, the bottom of this slide, and a process, something that that equation can do.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3948.202,
    "end": 3953.367,
    "text": "If we can get that clear, then stochastic chaos",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3954.542,
    "end": 3963.487,
    "text": " is a between thing that we can then manipulate to a certain outcome, or we can leave open to possibility.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3963.987,
    "end": 3980.036,
    "text": "If we can get that, just that, we will have conquered more than most people have conquered in their lifetime because they use the word between, but I don't think they necessarily understand what makes that up.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3980.916,
    "end": 3982.237,
    "text": "And I think that's what we,",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3983.098,
    "end": 4003.943,
    "text": " That's what I would like to be able to share with others and co-learn with others as opposed to, excuse me, building another set of specific outcomes that we can measure and say, this was you one month ago, you A, and this is you now seven years plus a day.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 4003.963,
    "end": 4008.904,
    "text": "And now we're going to decide whether or not you're closer to some",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 4009.332,
    "end": 4014.615,
    "text": " thing that I've arbitrarily selected as the thing that makes you have learned something.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 4015.435,
    "end": 4019.517,
    "text": "If we can get there, could you imagine how amazing that would be?",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 4019.837,
    "end": 4021.198,
    "text": "That's just that one thing.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 4021.698,
    "end": 4032.344,
    "text": "Sorry, I get really passionate about this, but holy crap, I'm actually talking to people who can actually hear that and go, oh, that's interesting.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 4032.464,
    "end": 4038.127,
    "text": "Instead of just dismissing it out of hand and going, we don't need to learn that because we already know what between means.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 4041.889,
    "end": 4043.29,
    "text": " Between is geometric.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4043.891,
    "end": 4046.473,
    "text": "So for sure, information geometry will come into play.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4047.054,
    "end": 4061.887,
    "text": "And then the idea of taking vast situations and through time with uncertainty and then calculating more or less cough, cough, expected free energy, that could be an extremely helpful approach.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4062.528,
    "end": 4064.21,
    "text": "So Blue, anything on this or we'll continue.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4064.918,
    "end": 4066.199,
    "text": " Yeah, so what's the next tool?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 4066.219,
    "end": 4067.82,
    "text": "Are we going right into the Markov blanket?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 4068.001,
    "end": 4068.141,
    "text": "No.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 4068.161,
    "end": 4069.962,
    "text": "Because, man, when we talk about between.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 4069.982,
    "end": 4070.723,
    "text": "Not yet.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 4070.883,
    "end": 4072.284,
    "text": "I just want to get to the Markov blanket.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 4073.845,
    "end": 4077.608,
    "text": "When we talk about between, I think that having that idea of the Markov blanket.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 4077.709,
    "end": 4079.11,
    "text": "Anyway, I'll add it at that time.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 4079.21,
    "end": 4079.93,
    "text": "So go on.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 4080.211,
    "end": 4080.551,
    "text": "Carry on.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 4080.831,
    "end": 4087.214,
    "text": " Absolutely, the Markov blanket is even understood by the non-technical as a betweenness.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4087.875,
    "end": 4091.916,
    "text": "But is it the betweenness that is your epithelium mechanically?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4092.517,
    "end": 4095.538,
    "text": "Or what kind of betweenness are we actually talking about?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4096.699,
    "end": 4097.359,
    "text": "We need the tools.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4098.52,
    "end": 4099.66,
    "text": "Let's go to the next tool.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4100.281,
    "end": 4100.401,
    "text": "So...",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4102.682,
    "end": 4103.963,
    "text": " However, this is the quote.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4104.163,
    "end": 4109.627,
    "text": "In general, we cannot discount the correction term that arises when flow operators are a function of states.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4110.548,
    "end": 4122.015,
    "text": "So if it were just Mount Everest, we could just do the solenoid and the gradient decomposition and then figure out how to combine isocontours with gradient climbing and we would get to the top.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4122.596,
    "end": 4131.042,
    "text": "However, swept under the rug by the housekeeping term is this change in the underlying structure.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4131.9,
    "end": 4133.021,
    "text": " mountain landscape.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4134.222,
    "end": 4137.564,
    "text": "Indeed, it is this state dependency that underwrites stochastic chaos.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4138.244,
    "end": 4140.266,
    "text": "So a way to think about that is like the double pendulum.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4141.127,
    "end": 4147.431,
    "text": "The chaoticness of that system arises from the exact angle that the double pendulums are in.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4147.871,
    "end": 4150.333,
    "text": "You can't just say there's a Mount Everest and it's the bottom.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4150.613,
    "end": 4155.657,
    "text": "It's like, okay, not very helpful for me predicting these wacky waving shapes it's doing.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4156.537,
    "end": 4158.379,
    "text": "This presents us with a more difficult problem.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4159.261,
    "end": 4168.555,
    "text": " The problem can be finessed by using polynomial expansions of the flow operator and the potential as follows for n states.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4168.756,
    "end": 4171.9,
    "text": "So it could be one, two, three, four n dimensions",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4173.638,
    "end": 4185.407,
    "text": " up to polynomial order m. So a linear approximation has a polynomial order of one, a quadratic approximation has a polynomial order of two, and so on.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4185.708,
    "end": 4187.789,
    "text": "So it's like fitting higher and higher order terms.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4188.49,
    "end": 4197.217,
    "text": "So the big idea is that we're going to use polynomial expansions to approximate complex underlying flow functionals.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4198.746,
    "end": 4212.13,
    "text": " Polynomial expansions do many things, but most importantly, they restrict or scaffold our model selection approach to a very specific form and function and size and tractable computation.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4212.591,
    "end": 4220.653,
    "text": "So individuals might be familiar with a Taylor series, which is where you take a given point and you say, well, what is this function at that point?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4220.833,
    "end": 4222.454,
    "text": "Like the sign of zero is zero.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4222.914,
    "end": 4224.554,
    "text": "And then you say, what's the first derivative?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4224.775,
    "end": 4225.595,
    "text": "That's this red line.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4226.215,
    "end": 4228.056,
    "text": " And then you say, what's the second derivative?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4228.136,
    "end": 4229.876,
    "text": "Okay, it's starting to curve a little down.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4230.216,
    "end": 4231.437,
    "text": "Okay, what's the third derivative?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4231.817,
    "end": 4232.337,
    "text": "And so on.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4232.877,
    "end": 4244.941,
    "text": "And you can use the Taylor series to approximate that function further and further out from your entry point that you're calculating the first, second, third, fourth, fifth derivative on, et cetera.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4245.922,
    "end": 4249.823,
    "text": "And then this is a static approximation.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4250.343,
    "end": 4254.765,
    "text": "So this is something that might be learned in high school or college level maths.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4256.164,
    "end": 4259.647,
    "text": " A topic that's very related but not always discussed is the Volterra series.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4260.328,
    "end": 4265.132,
    "text": "And so the Volterra series is a model for nonlinear behavior similar to the Taylor series.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4265.813,
    "end": 4269.396,
    "text": "It differs from the Taylor series in its ability to capture memory effects.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4270.097,
    "end": 4279.785,
    "text": "The Taylor series can be used for approximating the response of a nonlinear system to a given input if the output of the system strictly depends on the input at the given time.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4280.746,
    "end": 4308.179,
    "text": " and this is developed quite extensively the volterra in spm textbook by friston et al so again many of the seeds and roots of what we're talking about today check the spm textbook and documentation because that's where a huge amount of this competency in these authors arose from and how they represented it almost 15 years ago so",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4309.781,
    "end": 4314.505,
    "text": " What happens when we do this polynomial expansion of the functional form?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4315.045,
    "end": 4324.512,
    "text": "Well, first off, we moved the problem that we were solving from static mountains only to trampolines that are moving as we're walking.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4325.353,
    "end": 4330.656,
    "text": " That's what brings state-dependent changes into the mix and action as well.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4331.436,
    "end": 4340.582,
    "text": "And it moves us from, again, a static landscape that we can just calculate where the rulers are flat on and then just figure out the best way to get there.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4341.162,
    "end": 4351.248,
    "text": "Well, you can't just lay a flat ruler if there's state-dependent changes because where the ruler is flat at T0 is not where the ruler is flat literally the next moment.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4351.688,
    "end": 4351.828,
    "text": "Dean?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4352.81,
    "end": 4377.118,
    "text": " Yeah, I think this is excellent, Daniel, because what this now says is now we can explain why there are impressions, why there's some residue left over, why the in and out aspect of this, not just the bump, but the in and out going through that bump also has to be accommodated or at least acknowledged as part of everything that we're looking at here, the whole thing.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 4377.818,
    "end": 4380.539,
    "text": "So, yes, that's a great explanation.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 4380.699,
    "end": 4381.039,
    "text": "Thank you.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 4381.707,
    "end": 4384.689,
    "text": " And the learning landscape isn't just the mountains.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4385.27,
    "end": 4395.538,
    "text": "The interaction landscape is more like, well, it's like the coupled systems we'll get to soon, but it's even one person learning landscape is like being in trampoline world sometimes.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4396.279,
    "end": 4407.108,
    "text": "So that brings us into this space with many important topics that are discussed in an earlier and different way by the SPM textbook.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4408.1,
    "end": 4412.843,
    "text": " Now how good is or could be this polynomial expansion?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4414.484,
    "end": 4422.768,
    "text": "They write, inspection of the Lorenz system suggests that a second order polynomial approximation is sufficient given the flow is second order in the states.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4423.469,
    "end": 4428.512,
    "text": "So we're fitting an approximation that has two terms.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4428.992,
    "end": 4430.153,
    "text": "So it's like a quadratic,",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4431.297,
    "end": 4445.304,
    "text": " So that's why we talked so much about the bowl, because the approximation that we're fitting is bowl-like, which allows optimization techniques that are simple, like convex optimization.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4445.604,
    "end": 4446.205,
    "text": "Those are easy.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4446.485,
    "end": 4450.107,
    "text": "Roll the ball to the bottom of the hill by minimizing the potential function.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4450.787,
    "end": 4451.727,
    "text": "Which potential function?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4452.028,
    "end": 4455.109,
    "text": "The free energy potential function, the free energy functional.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4455.769,
    "end": 4458.191,
    "text": "Whereas if it was a rugged optimization landscape,",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4459.13,
    "end": 4462.153,
    "text": " you get the whole headache of how do you know when to stop?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4462.213,
    "end": 4464.756,
    "text": "And what if there's just a whole neighborhood you didn't even go to?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4465.277,
    "end": 4470.943,
    "text": "So it seems like potentially a second order approximation is sufficient.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4472.315,
    "end": 4475.636,
    "text": " Then they use this word ansatz, which is nice.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4475.896,
    "end": 4482.199,
    "text": "It's an assumption about the form of an unknown function made in order to facilitate solution of an equation or other problem.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4482.819,
    "end": 4489.802,
    "text": "So now we're gonna go with this idea that if we can have a second order approximation to Lorentz, we're gonna be doing good enough.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4490.182,
    "end": 4492.343,
    "text": "Let's work with that and see if that turns out to be the case.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4493.362,
    "end": 4507.97,
    "text": " So it turns out if this thing that's so hard to model, the self-information, the surprise, the potential function is modeled by a second order polynomial, then the non-equilibrium steady state is approximately Gaussian.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4509.411,
    "end": 4514.794,
    "text": "This is known as the Laplace approximation in statistics, which is also in SPM very helpfully.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4516.226,
    "end": 4525.288,
    "text": " Here we generalize the notion of Laplace approximation to cover not just the quadratic form of the log density, but also the solenoidal flow that underwrites non-equilibrium dynamics.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4525.968,
    "end": 4543.993,
    "text": "So the Laplace approximation in classical statistics is like, we're going to take the density distribution of what we're trying to estimate, and we're going to find the peak, the maximum point, and then we're going to fit a Gaussian over that peak.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4544.929,
    "end": 4550.412,
    "text": " And so if there's like a big shoulder and then a tiny shoulder, you're just not going to get that tiny shoulder, right?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4550.432,
    "end": 4554.154,
    "text": "But that's a very rich distribution if it really has that structure in the real world.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4554.935,
    "end": 4559.957,
    "text": "What you're going to get for that distribution is a Gaussian centered around the big peak.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4560.898,
    "end": 4563.559,
    "text": "So for some distributions, you're going to be way off.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4563.719,
    "end": 4566.621,
    "text": "There are things that are hard to estimate.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4567.623,
    "end": 4570.485,
    "text": " and there's things that don't work well with the Laplace approximation.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4571.146,
    "end": 4572.707,
    "text": "It's not a solution, it's an approximation.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4573.187,
    "end": 4592.761,
    "text": "However, if we're interested in the mean and in the variance around potentially the bulk of a distribution, then solving the parameters for the Laplace approximation is as easy as fitting a quadratic, which is to say the ball sliding to the bottom of the bowl.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4593.241,
    "end": 4595.623,
    "text": "And once you go beyond second order approximation,",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4596.53,
    "end": 4606.958,
    "text": " you have a third order quadratic, there's a whole nother world because then the ball could get caught in that first little elbow, or it could fall off the other side.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4607.698,
    "end": 4612.902,
    "text": "So higher order approximations, they take more computational resources.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4613.823,
    "end": 4619.407,
    "text": "And while they might have increased accuracy, they can often be less tractable to actually solve.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4619.987,
    "end": 4622.049,
    "text": "So this is at least,",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4623.45,
    "end": 4646.276,
    "text": " in my reading, a pretty fundamental contribution to the statistics of complex systems, because they've taken the notion of Laplace approximation, not just towards estimating the mean and the variance of some distribution out there, but to the solenoidal component of flow post-Helmholtz decomposition related to non-equilibrium dynamics.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4646.716,
    "end": 4646.936,
    "text": "Stephen?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4650.071,
    "end": 4654.376,
    "text": " So up to this point, we actually don't need Markov blankets yet.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 4655.077,
    "end": 4656.598,
    "text": "We haven't used the word.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4656.918,
    "end": 4659.101,
    "text": "So it has not come into play yet at all.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4659.862,
    "end": 4660.983,
    "text": "Exactly, exactly.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 4661.744,
    "end": 4670.994,
    "text": "So you've told the story of what needs to be in place for there to be the kind of...",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 4672.549,
    "end": 4692.04,
    "text": " state spaces and then the nature of these state spaces being so changeable and non-linear and then there's this on top of that then there's a way to attractively work within that which is the la passe approximation in statistics which gives you",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 4693.171,
    "end": 4697.634,
    "text": " Does it always give one Gaussian on any landscape, or is there multiple?",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 4697.914,
    "end": 4699.335,
    "text": "Is it just one per landscape?",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 4699.955,
    "end": 4706.799,
    "text": "Yes, per dimension, per state, the Laplace returns one and only one mean invariance.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4707.439,
    "end": 4710.821,
    "text": "It's like fitting a Gaussian distribution to the log density.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4711.742,
    "end": 4714.984,
    "text": "So it does only give one, which is why I gave the example of the two hump.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4715.564,
    "end": 4716.385,
    "text": "It's going to pick one.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4717.594,
    "end": 4717.974,
    "text": " and go there.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4718.655,
    "end": 4721.298,
    "text": "And so, yeah, let's look at figure two.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4721.619,
    "end": 4731.87,
    "text": "And so how interesting though, that the paper is Markov blankets and stochastic chaos, but we're not even at the Markov blanket, but the way that it gets led into",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4732.939,
    "end": 4739.204,
    "text": " is very improved and different than what we've seen before.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4739.965,
    "end": 4745.83,
    "text": "Instead of assume a partition, dot, dot, dot, dot, dot, we're starting way back.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4746.33,
    "end": 4751.514,
    "text": "So now here on the left is the flow of the Lorenz system",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4752.612,
    "end": 4753.953,
    "text": " using the Helmholtz decomposition.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4754.694,
    "end": 4758.597,
    "text": "So here are the three components of the flow as they've described it.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4758.617,
    "end": 4766.464,
    "text": "The blue is the gradient, the orange is the solenoidal flow, and then the gold is the correction housekeeping term.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4768.626,
    "end": 4774.23,
    "text": "Right, this uses the same format, but for a Laplacian system based upon the Lorenz in the upper panel.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4775.311,
    "end": 4776.873,
    "text": "So we're gonna be fitting,",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4778.496,
    "end": 4786.481,
    "text": " a Laplace-like approximation to each of the states, each of the dimensions of this Lorentz strange attractor.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4788.82,
    "end": 4794.144,
    "text": " the key difference is that the dissipative part of the flow operator and the Hessian are positive definite.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4794.745,
    "end": 4797.467,
    "text": "So just really quick matrix vocabulary.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4798.087,
    "end": 4803.512,
    "text": "The Jacobian matrix is the matrix of the first partial derivatives.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4804.252,
    "end": 4809.056,
    "text": "So in the X, Y, and Z dimensions, or however many there are, what is the angle of the ruler?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4809.536,
    "end": 4811.057,
    "text": "That's the first partial derivative.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4812.063,
    "end": 4838.759,
    "text": " hessian is the second order partial derivatives so it's describing the local curvature so if someone said my ruler's flat and it's curving down you're on the top of a hill if your ruler's flat and it's curving up you're at the bottom of a hill and so on so that's how the zeroth the value of the function the first derivative and the second curvature are used like in calculus so",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4840.779,
    "end": 4847.144,
    "text": " The Hessian is positive definite, which means the gradient flows converge to the maximum of the non-equilibrium steady state density.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4847.764,
    "end": 4851.307,
    "text": "This is reflected by the blue arrows that point to the center of the state space.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4852.127,
    "end": 4856.351,
    "text": "So in the Lorenz world, you're getting race card around.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4856.751,
    "end": 4859.153,
    "text": "The flow is taking you all over the place.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4860.345,
    "end": 4873.035,
    "text": " Yet, by making the Laplacian approximation, all of a sudden the flow, the attractive part that's dominating the movement within that space, it's actually convergent.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4873.736,
    "end": 4877.439,
    "text": "So that's not to say the Lorenz system converges to a stable point.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4878.479,
    "end": 4889.168,
    "text": "It's to say our approximation parameters converge towards potentially a more tractable and simple attractor in the abstract approximation space",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4890.765,
    "end": 4893.806,
    "text": " and we'll see how well of an approximation that indeed is.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4894.307,
    "end": 4901.41,
    "text": "But that's the key difference is here, the blue arrows are taking you on a wild ride as the gradient takes you around the Lorenz flow.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4902.25,
    "end": 4914.416,
    "text": "Here, we're doing a flow composition on our approximation, which we constructed to be of a certain type, and it turns out to have properties in its attractor that are very different than the Lorenz.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4915.357,
    "end": 4916.217,
    "text": "Dean, and then Steven.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4919.279,
    "end": 4920.119,
    "text": "Unmute Dean, and then yes.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4924.11,
    "end": 4925.491,
    "text": " Here's a question for everybody here.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 4926.172,
    "end": 4943.387,
    "text": "If we're talking about a process, could we be looking at those over time, seeing those arrows in both the Lorenz and the Laplace decomposition thickening or expanding or like having water added to them?",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 4944.729,
    "end": 4949.633,
    "text": "Has anybody contemplated whether in fact that is what is happening over time?",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 4951.297,
    "end": 4953.621,
    "text": " So the fit is actually from a within.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 4953.641,
    "end": 4961.132,
    "text": "The space is getting filled up by these arrows growing in terms of their circumference.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 4963.373,
    "end": 4964.674,
    "text": " Very interesting question.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4965.715,
    "end": 4970.8,
    "text": "The length of the arrow usually describes the amplitude, like the speed of the flow in that moment.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4971.3,
    "end": 4980.289,
    "text": "I do not know if I've seen a visualization where the tree rings, the arrows represent thicker or thinner vectors, but great question.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4980.329,
    "end": 4985.653,
    "text": "And if anybody with more experience in vector math has a thought, that could be very interesting to know.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4985.673,
    "end": 4986.714,
    "text": "Okay.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4987.575,
    "end": 4988.336,
    "text": "Stephen, and then Blue.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 4990.908,
    "end": 5011.088,
    "text": " And just to clarify that I've got this right, but each of those points where you've got the blue arrow and the solenoidal flows, so each one would be solved, so to speak, for that point as a Gaussian approximation.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 5011.628,
    "end": 5015.252,
    "text": "And then this is like an assemblage of multiple points.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 5016.758,
    "end": 5021.342,
    "text": " results of a Gaussian approximation and it's sort of mapping them out, so to speak.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 5021.682,
    "end": 5024.905,
    "text": "And so, you know, this idea of multiple",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 5026.459,
    "end": 5030.1,
    "text": " pieces of information and nestedness is it sort of comes into play with this.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 5030.72,
    "end": 5030.88,
    "text": "Yeah.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5031.08,
    "end": 5037.643,
    "text": "There's some landscape and we go out there with our ruler, our Jacobian and our curvature ruler, our Hessian.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5038.123,
    "end": 5039.883,
    "text": "And then we're going to make just transects on the hill.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5040.363,
    "end": 5048.446,
    "text": "And we're going to just sample a bunch of points and add a bunch of points, you know, one comma one, one comma two, we're going to use the ruler and the curvature.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5049.326,
    "end": 5053.908,
    "text": "And we're going to look at, at that point where the field is, uh,",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5055.847,
    "end": 5062.829,
    "text": " And then if you've sampled at an inadequate resolution, you're not gonna see a coherent vector field.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5063.71,
    "end": 5069.691,
    "text": "So you need to sample at a resolution that allows the vector field to be kind of obvious.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5071.892,
    "end": 5072.592,
    "text": "So, Blue.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5074.353,
    "end": 5082.115,
    "text": "So I just wanna point out for people who might not know that you need to have a positive definite Hessian",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 5083.16,
    "end": 5085.462,
    "text": " to calculate a covariance matrix.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 5085.722,
    "end": 5090.446,
    "text": "Like in statistical analyses that I've done, this is like one critical point.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 5090.727,
    "end": 5102.337,
    "text": "And if you don't have an invertible Hessian, then you have to recalculate your model because all of your factors are too entangled to find out how they are covariate together or separately.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 5102.357,
    "end": 5107.902,
    "text": "So I just wanted to, for anybody who doesn't have the background in matrix math, just point that out.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 5108.883,
    "end": 5109.103,
    "text": "Yes.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5109.543,
    "end": 5109.803,
    "text": "Thanks.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5110.024,
    "end": 5110.184,
    "text": "Dean?",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 5111.428,
    "end": 5112.369,
    "text": " So, Blue, help me.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 5112.749,
    "end": 5120.254,
    "text": "Does that mean, literally, that you can't thin one of those arrows?",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 5123.736,
    "end": 5129.039,
    "text": "You can't let certain things be purged from your state space?",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 5130.0,
    "end": 5132.301,
    "text": "Because that's... I really don't know.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 5132.321,
    "end": 5133.202,
    "text": "I'm not questioning.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 5133.522,
    "end": 5139.526,
    "text": "I'm asking a question from a physical standpoint, and then being able to translate that to the physical...",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 5140.819,
    "end": 5141.239,
    "text": " reality?",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 5142.04,
    "end": 5144.581,
    "text": "So I don't translate to physical reality.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 5144.622,
    "end": 5158.511,
    "text": "Well, my brain just like doesn't work that way, but, but what has to happen is what that really means is you can't establish conditional independence without having some idea of the covariance.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 5158.671,
    "end": 5165.175,
    "text": "And so if you can't calculate the covariance, you can't discover this conditional independence, which is where we're building up to.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 5166.516,
    "end": 5168.237,
    "text": " in specifying the Markov blanket.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 5168.477,
    "end": 5174.659,
    "text": "So that's why I wanted to just point that out because you have to have that ability to find that covariance.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 5175.219,
    "end": 5175.319,
    "text": "Okay."
  },
  {
    "start": 5175.7,
    "end": 5179.401,
    "text": "Let's go to where the covariance comes into play and then Steven.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5179.601,
    "end": 5183.883,
    "text": "So we're going to address how well does this approximation work?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5184.223,
    "end": 5189.344,
    "text": "Because I mean, we're fitting a few quadratics to like the OG complex system.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5189.605,
    "end": 5190.585,
    "text": "Is that really going to work?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5194.079,
    "end": 5198.903,
    "text": " What's being shown in figure three is on the very top.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5199.444,
    "end": 5204.528,
    "text": "So this is the left one is second versus third, first versus third and first versus second.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5204.648,
    "end": 5207.31,
    "text": "So these are like three projections on a cube.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5207.751,
    "end": 5214.376,
    "text": "So we're looking on a flat screen or piece of paper about a three-dimensional state space.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5215.517,
    "end": 5219.06,
    "text": "And the red dots are the sampled trajectory",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5220.117,
    "end": 5221.218,
    "text": " in that cube.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5221.718,
    "end": 5225.119,
    "text": "So it's like there's a firefly moving around in the cube and we're looking at it this way.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5225.159,
    "end": 5228.0,
    "text": "And so we're projecting it onto that screen.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5228.941,
    "end": 5236.744,
    "text": "And then in the background, we see this very nice unimodal Gaussian attractor.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5237.764,
    "end": 5240.165,
    "text": "So the lighter part is like the attractor part.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5240.785,
    "end": 5246.888,
    "text": "And then the darker part is higher potential function, more surprising, less likely.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5247.782,
    "end": 5250.208,
    "text": " So that is the Lorenz trajectory",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5251.547,
    "end": 5256.749,
    "text": " being played out in our Laplace-like approximation cube.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5257.79,
    "end": 5267.994,
    "text": "And so it can be shown that the flow of the Laplace approximation, it has some of that kind of butterfly race car dynamics.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5268.814,
    "end": 5277.038,
    "text": "It's probably doing a lot better than just sticking a linear equation through it, but it's not perfectly recapitulating the underlying Lorenz system.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5277.378,
    "end": 5278.898,
    "text": "So how good is the approximation?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5281.118,
    "end": 5289.363,
    "text": " One thing that this approximation is going to live or die by is whether it can characterize the Lorenz system as chaotic or not.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5289.904,
    "end": 5300.511,
    "text": "Because if it turns out that the way we're going to deal with chaos, systems with a positively operative exponent, is fit a non-chaotic model, oh, I made an oscillator pendulum to describe homeostasis.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5301.548,
    "end": 5304.41,
    "text": " Okay, so you made a simple model, great.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5305.11,
    "end": 5312.474,
    "text": "But what's really interesting is if our approximation could also reflect chaos yet handle it tractably.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5313.114,
    "end": 5323.459,
    "text": "So what they do in formalism 12 is they show that the estimated Lyapunov dimension for the approximation is 2.48.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5325.34,
    "end": 5330.323,
    "text": "And they use some numerical approximation techniques here, like by sampling a grid,",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5331.997,
    "end": 5353.011,
    "text": " of that transect sampling idea but for the lyopinib exponent at those points rather than say just the gradient and that favors um or that compares very favorably 2.48 2.43 importantly they're both like similar and way over one with the actual analytical lyopinib dimension so",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5353.851,
    "end": 5364.875,
    "text": " the approximation is actually highlighting the chaotic nature and almost quantitatively the extent of the chaos because there's more and less chaotic systems.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5365.615,
    "end": 5374.398,
    "text": "And so for our purposes, the Laplace approximation is easier to handle than the Lorenz system because the functional forms of the flow and potential are immediately at hand.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5375.404,
    "end": 5376.124,
    "text": " That's the whole point.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5376.664,
    "end": 5387.006,
    "text": "We used an approximation family of equations that's going to be like having a ball rolling down to the bottom of a bowl rather than being swept up in turbulent flow.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5388.566,
    "end": 5392.427,
    "text": "Figure four is where we get to the covariance that Blue mentioned.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5393.227,
    "end": 5395.808,
    "text": "Okay, so we're gonna have three states.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5396.108,
    "end": 5399.469,
    "text": "Those are the X, Y, and Z states or dimensions of the Lorenz system.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5400.369,
    "end": 5400.789,
    "text": "And now,",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5402.652,
    "end": 5411.134,
    "text": " we can look at the log of, so the log is just sort of a transformation to help highlight some of the differences between zero and one, especially.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5412.495,
    "end": 5426.578,
    "text": "We can see the log of the Jacobian, which is that first partial derivative, the log of the Hessian, which is the second partial derivative, and then the log of the covariance in the middle, which is like what Blue was referencing.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5426.718,
    "end": 5429.299,
    "text": "So here, the first and the second",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5431.027,
    "end": 5434.5,
    "text": " states dimensions have very high correlations.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5436.067,
    "end": 5437.988,
    "text": " neither of them are correlated with the third.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5438.228,
    "end": 5440.749,
    "text": "So the on diagonals are states being correlated with themself.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5441.35,
    "end": 5443.451,
    "text": "The first and the second dimensions have high correlation.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5444.091,
    "end": 5448.173,
    "text": "Well, what does that look like when we use that cube shining light?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5448.613,
    "end": 5455.316,
    "text": "So on the bottom left here, we can see like the first and the second have like an oblong relationship.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5455.957,
    "end": 5460.159,
    "text": "That scatter plot has a significant regression through it.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5460.439,
    "end": 5462.94,
    "text": "There's a correlation coefficient, there's mutual information there.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5464.11,
    "end": 5465.21,
    "text": " there's non-sphericity.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5465.93,
    "end": 5473.932,
    "text": "Whereas the other ones that are uncorrelated relationships have what looks to be more of a spherical correlation.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5474.112,
    "end": 5479.693,
    "text": "Like if you sample variable A and B and it's just a circle, there's no mutual information.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5480.653,
    "end": 5488.715,
    "text": "And so interestingly, the covariance matrix looks a lot like the Hessian matrix.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5489.969,
    "end": 5507.581,
    "text": " So that is providing evidence that if what we care about is the covariance amongst the states, we're getting a very similar structure when we use the second order polynomial approximation to those states.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5508.762,
    "end": 5517.088,
    "text": "And it turns out that it does pretty well if you want to, for example, estimate the first state given the second.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5518.106,
    "end": 5520.729,
    "text": " So what if we could only measure two dimensions?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5520.989,
    "end": 5524.932,
    "text": "Well, we wouldn't want to pick one and two because they're basically correlated in their measurements.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5525.773,
    "end": 5538.465,
    "text": "We would want to pick two and three and then do a really good job at predicting one given two, which is to say that the informational dimension of this system is between two and three.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5539.166,
    "end": 5540.787,
    "text": "It's two and a half, basically.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5541.71,
    "end": 5556.749,
    "text": " So those are some of the connections between covariance amongst different dimensions and polynomial expansions to dynamical systems based upon flow approximation.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5560.148,
    "end": 5562.73,
    "text": " And then just to summarize here, then we can have any questions.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5562.81,
    "end": 5566.072,
    "text": "And then in the last 20 minutes, we'll look towards the Markov blanket.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5566.693,
    "end": 5569.655,
    "text": "We still haven't even gotten to the Markov blanket yet.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5570.455,
    "end": 5575.118,
    "text": "So just, this is the foothills of Mount Markov.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5576.119,
    "end": 5580.562,
    "text": "And they write, it's important not to conflate.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5581.303,
    "end": 5585.245,
    "text": "It's important not to conflate the simplicity of a non-equilibrium steady state density.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5586.586,
    "end": 5587.587,
    "text": "That's this one.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5589.639,
    "end": 5592.341,
    "text": " with the complexity of the underlying density dynamics.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5593.082,
    "end": 5594.363,
    "text": "The map is not the territory.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5594.623,
    "end": 5596.905,
    "text": "You just cannot say it enough.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5597.325,
    "end": 5600.427,
    "text": "Simple approximations are not claims about system simplicity.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5601.248,
    "end": 5611.456,
    "text": "In other words, when prepared or observed in initial state, the probability density can evolve in a complex and itinerant fashion on various sub-manifolds of the pullback attractor.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5612.136,
    "end": 5614.578,
    "text": " And they're going to use information length to talk about that.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5615.018,
    "end": 5629.128,
    "text": "But the important thing to know is just that our approximation has attributes that resonate with the original underlying systems dynamics, as well as attributes that we specifically know are different, or they might be different or not.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5629.668,
    "end": 5632.55,
    "text": "But no matter what, they're not claims about the underlying system.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5632.91,
    "end": 5634.191,
    "text": "So that's not a pipe.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5635.712,
    "end": 5635.953,
    "text": "Steven?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5638.174,
    "end": 5640.135,
    "text": "Yeah, I think this also speaks to",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 5641.448,
    "end": 5656.42,
    "text": " this idea of triangulation or multimodality is, like you say, this isn't directly speaking to what's out there, or what the system, or what you could say, whatever the things are that are being inferred.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 5657.981,
    "end": 5660.804,
    "text": "So there needs to be, or the more",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 5662.637,
    "end": 5689.147,
    "text": " approximations that can be triangulated as i say which is kind of what happens in qualitative research qualitative research is all about the triangulation of research not about the exact measures and accuracy within research then you can get a better grip potentially on what might be out there if that makes sense so like you say with that pipe you kind of you know if i could if i could go in and",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 5690.26,
    "end": 5699.226,
    "text": " You know, I've only got one aspect of that reality, so I can only resolve it to a certain degree, and it is what it is.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 5699.266,
    "end": 5706.851,
    "text": "And then I'd have to see, I don't know how big that is as a painting, you know, until I see it in a gallery, et cetera, et cetera, right?",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 5706.891,
    "end": 5715.757,
    "text": "So, yeah, I think that this, the need to find the way to get an approximate way in",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 5716.573,
    "end": 5724.975,
    "text": " means that you need to have many approximate ways in to start to make a higher level confidence in what you're thinking.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 5726.315,
    "end": 5726.815,
    "text": "Thanks, Stephen.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 5726.975,
    "end": 5727.215,
    "text": "Dean?",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 5728.576,
    "end": 5730.756,
    "text": "Yeah, Danny, can you go back to slide 48 for a second?",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 5730.996,
    "end": 5731.236,
    "text": "Yes.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5734.317,
    "end": 5737.518,
    "text": "So this is the fascinating thing about contrast and proportion.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 5738.578,
    "end": 5743.099,
    "text": "Because you've got nine squares up in the upper right there with the Jacobian and the",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 5744.895,
    "end": 5748.178,
    "text": " And the covariance and the Hessian, trying to translate that.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 5748.258,
    "end": 5756.964,
    "text": "And I understand this is the big, this is the sort of the grail of translation.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 5757.044,
    "end": 5762.469,
    "text": "To translate that and the contrast and the proportion that you see there to fresh eyes, to new eyes.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 5762.749,
    "end": 5770.675,
    "text": "They might look at that middle one with a completely different sense of what that pattern is describing for us than the two outside patterns.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 5772.956,
    "end": 5773.817,
    "text": " slices of bread.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 5774.477,
    "end": 5783.28,
    "text": "To us, because we're a little bit more familiar with it, the contrast and the proportion, you can actually see where the Hessian matters from a statistical standpoint.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 5783.56,
    "end": 5789.522,
    "text": "But drop that into a context now, where you've got mountains and rivers and lakes and forests and streams,",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 5790.282,
    "end": 5806.766,
    "text": " And how do we take that information there, which is really quite clear to people who are familiar with it, and translate it to the context, the situation in which we find ourselves, and are now trying, processing to a converged sense of context.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 5807.166,
    "end": 5811.007,
    "text": "What does this envelope tell us, right?",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 5811.327,
    "end": 5813.047,
    "text": "We're inside of this cube now.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 5813.567,
    "end": 5816.408,
    "text": "How do we get outside of it, use this tool,",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 5817.321,
    "end": 5829.543,
    "text": " to reenter the context and have an agreed upon sense of what co-variation means.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 5829.743,
    "end": 5845.806,
    "text": "This is the grail if we can set up our learning experience as a situated one where we take this tool in, but don't confuse the tool, as you say, don't confuse the math with the field.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 5846.789,
    "end": 5855.552,
    "text": " That's again, it's fantastic if you can get a whole bunch of people seeing what's the big picture here?",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 5855.873,
    "end": 5856.633,
    "text": "What is the tool?",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 5857.333,
    "end": 5859.754,
    "text": "What's the contrast in proportion with a tool?",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 5860.675,
    "end": 5862.515,
    "text": "And then what is the context?",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 5862.955,
    "end": 5869.518,
    "text": "What's all of this fractalized stuff out there in different colors and different shapes and different sizes?",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 5869.938,
    "end": 5874.2,
    "text": "How do we put those two things together into some sort of coherent narrative?",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 5876.195,
    "end": 5898.06,
    "text": " point so in the last 10 to 13 minutes we're going to finally verge to the m word markov blanket um and then next week it would be awesome to speak with any of the authors or anyone else who would like to share their perspective or will continue because like",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5898.92,
    "end": 5917.815,
    "text": " we're basically halfway through and we haven't gotten to the core piece of the markov blanket so we're gonna just look where we're going in the last little bit of dot one and then in dot two we're gonna like you know land on that markov trampoline and then see where we go okay in section four",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5919.241,
    "end": 5928.064,
    "text": " they're going to repeat the analyses of the previous section, approximating two Lorenz systems coupled to each other through their respective first states.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5929.064,
    "end": 5937.627,
    "text": "This induces a richer conditional independent structure from which one can identify internal and external states that are independent when conditioned upon blanket states.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5938.227,
    "end": 5939.428,
    "text": "So this is",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5940.609,
    "end": 5952.572,
    "text": " the more classical Markov blanket definition, which is blanket states are those that conditioned upon them make internal and external states conditionally independent.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5953.192,
    "end": 5954.773,
    "text": "So that's a definition that we've seen before.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5955.273,
    "end": 5959.434,
    "text": "And the internal, external, and blanket states, they all are co-instantiated.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5959.714,
    "end": 5962.074,
    "text": "It doesn't make sense to talk about one without the other.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5963.075,
    "end": 5965.235,
    "text": "And we've mentioned that before.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5966.155,
    "end": 5966.616,
    "text": "So in...",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5969.175,
    "end": 5971.17,
    "text": " Figure seven, it's a lot like figure three.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5972.247,
    "end": 5976.43,
    "text": " where we were looking at those three projections of the cube of one Lorentz system.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5976.57,
    "end": 5985.535,
    "text": "Well, now we're looking at two and it's pretty clear from looking at their trajectories, as well as just from their movement in the state space, like these are pretty synchronized.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 5986.056,
    "end": 5999.524,
    "text": "So some coupling has been instantiated, no different than if you had like two engines and then you connect them with a heat transfer device, they're gonna have coupled temperature fluctuations, except now it's like more statistical.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6000.831,
    "end": 6003.172,
    "text": " Figure eight is a lot like figure four.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6003.432,
    "end": 6014.696,
    "text": "So in figure four, we had this three by three matrix describing the first partial derivatives, second partial derivatives, or the covariances of states one, two, and three.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6015.236,
    "end": 6018.877,
    "text": "And the on diagonals were states with themselves and the off diagonals were states with other states.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6019.637,
    "end": 6021.478,
    "text": "Now we're going to have",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6022.512,
    "end": 6024.055,
    "text": " three plus three states.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6024.776,
    "end": 6027.521,
    "text": "Two sets of three, two coupled Lorentz.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6027.782,
    "end": 6029.565,
    "text": "One, two, and three is the first Lorentz.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6030.206,
    "end": 6032.971,
    "text": "And then four, five, six are the three states of the second Lorentz.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6033.803,
    "end": 6039.968,
    "text": " you see that in the Jacobian, there's high correlation within each Lorenz system.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6040.569,
    "end": 6044.572,
    "text": "And then there's that one in four where there's a strong value.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6045.113,
    "end": 6045.954,
    "text": "That's the coupling.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6046.494,
    "end": 6053.6,
    "text": "Like that is the cell that represents the coupling between the first upper quadrant and then the lower right quadrant.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6055.182,
    "end": 6059.466,
    "text": "And that induces some extremely interesting covariance structures.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6061.363,
    "end": 6063.104,
    "text": " That is what we want to investigate.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6063.704,
    "end": 6070.589,
    "text": "It turns out that by looking at the Hessian of this system, some partitions fall out.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6072.01,
    "end": 6088.5,
    "text": "Those partitions can be numerically analyzed to show that basically there's partial correlations that approximate the Hessian of the Lorenz systems that are coupled.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6090.143,
    "end": 6097.546,
    "text": " So we can use the Hessian, which we already established the second order polynomial expansion is like basically adequate.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6098.246,
    "end": 6103.868,
    "text": "We can use the Hessian of our approximation, not of the system, not the system has a Hessian.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6104.368,
    "end": 6107.789,
    "text": "Our model of the Hessian approximation",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6110.003,
    "end": 6113.185,
    "text": " very well aligns with the partial correlation.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6113.926,
    "end": 6120.69,
    "text": "And so that's demonstrated by showing that two states that shouldn't have correlation, third and sixth and fourth and fifth.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6121.311,
    "end": 6123.953,
    "text": "So like here, three and six are not correlated.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6125.714,
    "end": 6137.342,
    "text": "We can show that even if they start very correlated, like they just happen to start at a similar value, the dynamics of the system actually move them towards having a zero or even a slightly negative partial correlation.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6137.942,
    "end": 6138.043,
    "text": "So.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6138.988,
    "end": 6145.112,
    "text": " our Hessian approximation is giving us deep insight into the partial correlations.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6146.053,
    "end": 6149.295,
    "text": "And then I think a great place to sort of,",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6152.189,
    "end": 6163.478,
    "text": " is with this connection of the graphical Bayesian network that we've looked at before with that same partitioning into four states, internal, external, and blanket states.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6164.038,
    "end": 6169.362,
    "text": "Now, Friston and others then partitioned the Markov slash Perl blanket states",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6170.163,
    "end": 6179.469,
    "text": " which are of one kind, into these two kinds of blanket states, incoming sensory states, and outgoing action states.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6180.15,
    "end": 6186.714,
    "text": "That's what links us with perception, cognition, action, and control theory, and planning as inference.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6187.374,
    "end": 6188.755,
    "text": "So this is an image we've seen before.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6189.416,
    "end": 6190.977,
    "text": "And here are those six states.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6191.897,
    "end": 6192.838,
    "text": "So 1, 2, and 3, that's Lorenz system 1.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6192.898,
    "end": 6193.598,
    "text": "Then 4, 5, 6 is Lorenz system 2.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6197.148,
    "end": 6201.55,
    "text": " And one and four is the only cross coupling that we're putting into the model.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6202.03,
    "end": 6203.09,
    "text": "That's this cell right here.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6203.711,
    "end": 6205.791,
    "text": "So we're cross coupling one and four.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6206.152,
    "end": 6209.173,
    "text": "You have two neurons, they have two neurons.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6209.313,
    "end": 6211.934,
    "text": "And then there's a little tin can between the two of you.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6212.734,
    "end": 6218.236,
    "text": "And that's inducing a global structure to all six nodes.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6218.816,
    "end": 6221.697,
    "text": "So you don't need to have every neuron wired to every neuron.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6222.318,
    "end": 6225.339,
    "text": "There's sparsity in this connection structure.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6226.724,
    "end": 6245.536,
    "text": " And technical details aside, that is going to relate to the partitioning, which we're going to be deriving a partitioning on the Hessian, which is a second order polynomial expansion of our model.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6246.517,
    "end": 6255.103,
    "text": "So I think that is a great place to go for today.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6256.568,
    "end": 6260.91,
    "text": " And then just to close, and then we can have last thoughts or what we want to talk about next week.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6261.41,
    "end": 6269.213,
    "text": "Just to reiterate, there's no claim either the original Lorenz system or coupled Lorenz system possesses a Markov blanket.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6269.713,
    "end": 6272.394,
    "text": "So the territory doesn't have a Markov blanket.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6272.914,
    "end": 6275.655,
    "text": "Our coupling doesn't even have a Markov blanket.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6276.772,
    "end": 6286.216,
    "text": " The claim here is that there exists a Laplace approximation to these kinds of systems that in a virtue of the zero elements of the Hessian feature Markov blankets.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6287.336,
    "end": 6290.898,
    "text": "So not has a Markov blanket, is, wants to be, did have.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6291.558,
    "end": 6298.701,
    "text": "Those are speculative interpretations that maybe future larva will discover to be the case or not.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6299.341,
    "end": 6302.603,
    "text": "But what this paper actually claims is very far from that.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6304.183,
    "end": 6305.264,
    "text": "Blue and then Steven.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6308.484,
    "end": 6312.245,
    "text": " Okay, so here we're going to stop just as we're getting good, just as it's getting really good.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 6312.665,
    "end": 6313.445,
    "text": "Okay.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 6313.765,
    "end": 6315.505,
    "text": "It's the cliffhanger for next week.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 6315.705,
    "end": 6320.426,
    "text": "I just wanted to leave off with where this figure is in the paper.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 6320.966,
    "end": 6333.569,
    "text": "Like right under that figure, it says the names active and sensory or blanket states inherit from the literature where these states are often associated with biotic systems that act on and sense their external milieu.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 6334.483,
    "end": 6339.748,
    "text": " So I'm like, why are they imputing sensory states onto particles?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 6340.088,
    "end": 6343.791,
    "text": "Like this is where the great leap in the paper kind of happens for me.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 6344.232,
    "end": 6351.318,
    "text": "And I'm like, okay, now my particle is sensing, which is like to me, okay, like I'm actually okay with that.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 6351.338,
    "end": 6357.804,
    "text": "Like you guys know, you've seen me, like I'm pretty good with panpsychism at all or at overall.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 6358.385,
    "end": 6360.867,
    "text": "And it doesn't really make a big deal to",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 6361.417,
    "end": 6362.378,
    "text": " big difference for me.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 6362.778,
    "end": 6369.244,
    "text": "I'm still very interested, but it's something that a lot of people I think are going to get maybe tripped up by.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 6369.404,
    "end": 6371.186,
    "text": "So I would like to hash that out.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 6372.227,
    "end": 6378.933,
    "text": "And to say, well, there's absolutely no claim that real systems have a Markov blanket, you know, like the skin.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6379.654,
    "end": 6387.521,
    "text": "It's like, are we going to be talking about real systems and how it maps onto physical components of the real world and the mechanisms of sensory transduction or",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6388.709,
    "end": 6392.512,
    "text": " Or is this about the Hessian approximation to the Laplace?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6393.292,
    "end": 6399.917,
    "text": "So sometimes very close to each other in the text, so that can make it a little bit ambiguous.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6400.257,
    "end": 6400.537,
    "text": "Stephen?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6402.979,
    "end": 6405.461,
    "text": "Yeah, very, very cool.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 6405.641,
    "end": 6407.722,
    "text": "Yeah, Blue makes a good point.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 6408.543,
    "end": 6417.149,
    "text": "I suppose what I'm sensing here, and correct me if I'm wrong, is that this is showing a way to show that patterns can be existing",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 6418.513,
    "end": 6444.128,
    "text": " within the covariance of attractor states or tractors just in themselves it could just be a blob of stuff right in amongst blobs of things and stuff and particles and then it also shows that there can be the ability for those dynamics to partition out so it's",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 6445.649,
    "end": 6469.902,
    "text": " kind of gives a bit of two ways it gives the partition out piece and then it also gives a way to have a blob this is a very technical term a blob of very useful stochastic chaotic states which don't need to be themselves blanketed but could be what becomes just sort of sensory states for instance but could be a reservoir",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 6471.206,
    "end": 6472.588,
    "text": " within a bigger reservoir.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 6473.108,
    "end": 6476.972,
    "text": "Would that be a correct sort of assumption?",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 6477.333,
    "end": 6485.542,
    "text": "If we truly had no difference between our approximation and our incoming observations, like we had a perfect model,",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6486.536,
    "end": 6490.878,
    "text": " then maybe there'd be a valid claim that the map was the territory.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6491.038,
    "end": 6495.08,
    "text": "And for systems that we define in software, it actually can be that way.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6495.76,
    "end": 6505.265,
    "text": "But for any real system, this approximation, there's always going to be a delta between the incoming observations and our approximation.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6505.865,
    "end": 6511.248,
    "text": "And so the claim here is that it's the Hessian, the second level polynomial expansion,",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6512.188,
    "end": 6539.671,
    "text": " of our approximation that has some very nice mathematical properties not that the system has that or any specific properties dean yeah i would just speak to the idea that the skin is a great example because you can look at it only as a product as a limit or you can look at skin as a process i mean we know that all the processing that's going on there so",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 6541.223,
    "end": 6561.835,
    "text": " Again, do we collapse it down to one type of function as a product, as a limit, or do we see it actually as a process as well, as something that's dynamical, something that's constantly changing, and then that opens up the idea of what between means.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 6561.895,
    "end": 6563.756,
    "text": "Now, I don't know if it takes it down to the particle level.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 6563.776,
    "end": 6567.138,
    "text": "It seems like it does at those Planck scales,",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 6568.345,
    "end": 6581.687,
    "text": " I'm not really worried about that so much as I'm interested in the idea of what betweenness is because I don't know that skin automatically is a partition.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 6581.928,
    "end": 6583.628,
    "text": "Sometimes it's a process as well.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 6584.088,
    "end": 6587.729,
    "text": "So if we keep that open, that'd be something interesting to take up next week.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 6590.089,
    "end": 6590.329,
    "text": "Great.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6590.509,
    "end": 6590.709,
    "text": "Yeah.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6590.749,
    "end": 6594.55,
    "text": "I think if anyone else has any comments, like what a fun,",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6595.66,
    "end": 6597.301,
    "text": " paper and dot one.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6597.802,
    "end": 6613.615,
    "text": "We hit a lot of the warmup stretching and preliminary topics and contextualization that brought us like right to the vista of Mount Markov with further clouds behind even that.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6614.335,
    "end": 6621.581,
    "text": "But we're where we know that we can step into the dot two with a backpack that's prepared.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6622.241,
    "end": 6624.663,
    "text": "And then these are really interesting and clearly",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6625.879,
    "end": 6640.872,
    "text": " either unresolved and or uncommunicated and or unapplied questions in literature in the state of the art, which is what is the relationship between these formalisms and specific nouns and verbs",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6641.773,
    "end": 6645.217,
    "text": " in the world, the kinds of things that we're semantically engaging with.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6645.598,
    "end": 6659.635,
    "text": "And if it turns out that the semantics of a Markov blanket are not like the semantics of any other thing, or they're importantly different from the semantics of what we currently feel familiar with, great.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6660.746,
    "end": 6669.132,
    "text": " Or it would be interesting if they do map or overlap or encompass or nest within some other semantics that already exist.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6669.712,
    "end": 6671.073,
    "text": "But that's the question.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6671.673,
    "end": 6677.777,
    "text": "So we can just look at our final closing questions.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6677.817,
    "end": 6680.919,
    "text": "And if anyone has a thought, otherwise 32.2 next week on November 16th.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6685.57,
    "end": 6688.753,
    "text": " And we hope to hear from you.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6689.173,
    "end": 6702.064,
    "text": "If you would like to join the discussion live, just get in touch with us or contact us at active inference at gmail.com or just show up and ask questions or make comments in the live chat.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6704.927,
    "end": 6706.929,
    "text": "But interesting stuff.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6707.769,
    "end": 6708.19,
    "text": "We were, uh,",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6710.051,
    "end": 6729.838,
    "text": " Little trepidatious with such a complex paper, but I think bringing simplicity and simple rules underlying complex behavior and how can our approximations be tractable even when the world is just infinitely surprising, those are some of the fundamental questions that this paper and Active Inference address.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6730.338,
    "end": 6736.92,
    "text": "So Blue, Stephen, and Dean, great work, and we will see everybody next week.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 6738.881,
    "end": 6739.041,
    "text": "Bye.",
    "speaker": "SPEAKER_01"
  }
]