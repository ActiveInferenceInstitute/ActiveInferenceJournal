SPEAKER_01:
hello everyone welcome to actinflab to actinflab live stream number 32.2 it's november 16 2021

Welcome to the Act-Inf Lab.

We are a participatory online lab that is communicating, learning, and practicing applied active inference.

You can find us at some of the links here on this slide.

This is a recorded and an archived live stream, so please provide us with feedback so we can improve on our work.

All backgrounds and perspectives are welcome here, and we'll be following good and fun video etiquette for live streams.

At this short link, you can see some of the upcoming streams.

This is our second participatory group discussion on the Stochastic Chaos and Markov Blankets paper.

And then in the second two weeks of November, we're going to be discussing Thinking Like a State by our friend and co-participant, Avil.

And we haven't yet set the papers for December.

So if you know an author who you'd like to invite, or if you yourself would like to join for several weeks of discussion of one of your works, then just let us know.

today in act imp stream number 32.2 we're aiming to learn and discuss and ask what if and what is and hold all these different questions at once we're in the second participatory discussion around the paper stochastic chaos and markov blankets by friston heinz ulzhofer da costa and parr and

And last week we had an awesome discussion in the .1 and we got right up to the cliffhanger where the M word actually was deployed.

And I think today we're going to sprint up to that cliff and then jump off.

So it'll be a fun discussion for those who are watching live.

totally write questions and comments in the live chat and steven and dean and i and anyone else who joins will be just more than happy to hear what you have to share and to um

roll with it as you write things.

So let's begin just by giving a introduction or a warmup.

So we can say hello, and then also just maybe what was exciting about the paper overall, or since we all participated in the dot one, what are you looking forward to in the dot two, or maybe how have you changed how you thought about it over the previous week?

So I'm Daniel, I'm a researcher in California and

I'll save what I'm excited for until a little bit later and I'll pass it to Dean.


SPEAKER_03:
Hi, good morning.

My name is Dean.

I'm in Calgary.

In the one week's time since we left off, I think this paper more than many of the other papers we've had conversations around breathes life into something that is typically perceived as

not very alive, it's just sort of a point to and an explanation of, but I think this is one of those papers where when people pick it up and start having conversations with one another about the kind of work that's being done here, it makes it really, really interesting.

It doesn't give us necessarily the answers that the authors could project would be given, and I really like that.


SPEAKER_01:
Thank you, Dean.

Stephen?


SPEAKER_03:
And I'll pass it to Stephen.


SPEAKER_05:
Yeah, good morning as well from Toronto.

I'm really interested in this paper, I think, because it does give a unifying perspective.

It does help with that unifying perspective, even though at first when you see things like stochastic chaos, it can be like, oh, we're going down another rabbit hole, et cetera, et cetera.

But actually...

rather than always justifying or talking about applied active influence through applications and quotient applications, there is some benefit to this kind of coming to the foundation.

So I'm excited by that.

And also actually following a conversation we were having earlier and the fact that we have this complexity weekend is some of the ways that complexity can be talked about outside of a more woo-woo kind of,

conversational sense at these foundational levels, which again seems to get into unnecessary detail.

Ultimately, I think it starts to allow some of these crossovers between applications of complexity and this to happen, which for me personally, I don't think I was necessarily able to articulate a year ago.

So I think some of this work does just help fill in some of those gaps.


SPEAKER_01:
Thanks.

I agree.

The system that's picked up and turned around and remodeled throughout the course of the paper in a very narrative-driven way is the Lorenz attractor, which is the classic complex systems model.

So it just kind of plays into contemporary work on complexity and

so many other areas but and then also dean i really like what you said like the authors i hope will be able to join for a future presentation so we're in contact they probably won't join today but what the authors are putting out there and then how that's received and um communicated around and explored that's what's fun and um i know that we'll have many cool things to explore today

So let's jump to the big questions.

Then we'll look at the roadmap and try to remember where we got to yesterday.

And maybe a different big question is,

striking either of you or anyone in the live chat today.

And then we'll try to remember how far on our road trip we got last Tuesday.

And then let's see which sections we're going to get to.

And we have a bunch of other things kind of written down.

So the big questions that we had previously asked were, what is a good model of thingness in a chaotic, dynamic, and dissipative world?

How might this model or approach to thingness speak to system sentience?

And then there in little tiny font, it's sentience not in the phenomenological, like experiential, but greeting Serval, good to see you.

But sentience in the sense of thinking and feeling systems.

without worrying about the first person experience side, at least in this paper.

And then the key technical question of this paper, which broaches onto a million and a half other areas is what is a Markov blanket?

Just what are these blankets?

And how is one modeled, identified, defined statistically?

What are the pros and cons of different approaches?

And so that's some of the technical details that we'll get to.

So Stephen, thanks for raising your hand.

And then welcome, Serval.

After that, feel free to say hello and introduce yourself if you'd like.


SPEAKER_05:
Yeah, I'm curious.

I notice here that we start with thingness, which I do agree is this big question of thingness is something that Carl Friston brings up quite a lot, but I think he's often...

he's the he in that part i feel he's often a bit of a lone voice in terms of really pushing the thing this side of things and i and i think it's really interesting that second question then of okay how does that speak to system sentience and you see now we move into systems right and okay thing this sort of to me is it gives rise to systems and gives rise to sentience however

I think it's thing.

This is still there, right?

Thing.

This is still the game in some ways of being maintained.

So that first question, because when we then get into the third question, thing, this can get lost and it's all about system sentience.

And I think there's something really interesting there because, um, there is a question of, I mean, it's, it's even as we say in those brackets, what it really means to have system sentience or even just system is, um,

probably rather ill-defined.

And I suppose to some extent is how much is it even needed?

How much can thingness be maintained as an equal partner in the game and not sort of passed over once we scale?

So I think that's a good piece of a provocation.


SPEAKER_01:
Thank you.

And to what extent can things and systems be identified in a bottom-up way from measurements of dynamical systems?

Serval, would you like to add anything?

Or say hello?

Or bonjour?


SPEAKER_00:
Hello, I'm Serval.

I'm a complexity scientist.

I founded the Cambridge Research Laboratory, which is interested in building inactive models of social political changes, and I'm here to

see the discussion around the formalism of the paper, which I did not revise, and I therefore cannot make informed comments on.


SPEAKER_01:
Thank you, Sir Val.

Dean?


SPEAKER_03:
I just want to add one thing to what Steve was talking about there.

I think what the big questions and what this paper addresses pretty directly is, can we accept a minimum of two, that there's an abstraction

and that there's a material aspect to thingness.

And marrying those two things is kind of what we're hoping to be able to do.

But it comes in two very discrete forms.

So what of that?

we call it thingness because it kind of spans both realms.

And that's what I think I take away from the idea that it can be chaotic and not.


SPEAKER_01:
Absolutely.

There's the map in the territory and the,

one thing that we're gonna return to is like the first map that we apply to the territory.

So already we're separating the territory and the map, but even the first map can be chaotic.

And then can we put a second map, the Laplacian approximation, as it turns out in the paper, can that second map

be one that gives us some properties that make it more tractable to handle like you know potholders taking something hot out of the oven give a better grip on the first map which gives a better grip in terms of actionable insight into the territory can that second level

both be more tractable, especially using computers, but also retain those chaotic properties, which we're going to see when they estimate the Lyapunov exponent of the Laplacian approximation.

So, Stephen?


SPEAKER_03:
That's the recursion prior to the repetitiveness.

That's what I think this really gets into, recursion modeling.


SPEAKER_01:
Thanks, Dean.


SPEAKER_05:
So, Stephen?

Yeah, I'm going to put this as maybe a little bit of a question as well, but it's rhetorical if it doesn't want to be answered.

But I think that the thingness and the mark of blanket, because we get into that stage here, there is this, I think there tends to be a sense that, okay, we have a thing and because it's,

trying to sort of maintain itself in a dissipative world, then that's effectively a system, because it's got a Markov blanket and we're in that world.

But with this, it's like, well, look, you've got Lorenz attractor.

Then Lorenz attractor goes into thingness, right?

Now, and then thingness potentially goes into, probably with a few phases, system, sentient system.

So the question is, which side of thingness

is Markov blanket.

Does Markov blanket emerge from going from Lorenzo Tractor into thingness and then continue, or is it like Lorenzo Tractor into thingness, into Markovian blanketed thingness?

Curious what your thoughts are on that, and maybe this paper must shed some light on that.


SPEAKER_01:
Great question.

Let's look at the roadmap and just see how that comes into play.

So we talked in 32.1 about a few different ideas and we have some slides ready with just tabula rasa if we'd like to add notes or we can always modify slides and deal with questions as people are raising them.

Let's go to the roadmap though.

Okay.

So the roadmap of the paper is as follows.

In section one, there's an introduction.

In section two, there is from dynamics to densities.

So this is one of the really fundamental kind of linking events early in the paper

where dynamical systems dynamics are linked to flow systems like densities so this equivalence between dynamical systems and density driven systems is going to be finessed extensively in the paper so that's an introductory step that's very important to note

The Helmholtz decomposition is a tool from vector calculus that applies very well to densities and flows where it's usually applied, but because of what links were made in section 2, it becomes possible to take that Helmholtz decomposition approach to dynamical systems.

that is specifically visited and revisited and then moved beyond in the lorenz system that's one of those classical chaotic systems and a favorite toy of complexity analysis

The Lorenz system is moved beyond and then approximated with the Laplacian and then even moved beyond there.

So that's pretty much where we got to last week.

We tried to do a really solid grounding in first the equivalence between dynamical systems and density driven systems or two kind of representations of underlying systems that could be seen as equivalent.

And then we talked about the Lorenz system and about how it's chaotic and how chaotic means like sensitivity to small changes as quantified by the Lyapunov exponent.

And then we talked about how the Laplacian approximation, which is kind of like fitting a quadratic, which is kind of like letting the ball roll to the bottom of the bowl.

And this idea of like, well, if we can phrase the problem like a bowl,

then all we have to do is roll to the bottom there's only one bottom and we know which slope we're on so that's also called convex optimization because no matter where you are if you know that the problem is shaped like a quadratic curve like a bowl you can just instantaneously estimate the slope of the bowl and then just run downhill whereas if you're on a rugged landscape just you know you're lost in a mountain region we'll go downhill

you're going to get trapped into a valley potentially, and you might not make it out to the ocean.

But if you could reimagine that rugged landscape in a way that was more bowl-like, it would allow for tractable estimation of which way to move.

In section four, we get to the Markov blanket concept and the free energy principle.

And I think that's gonna be the really fascinating discussion is like, okay, so let's get what that Markov blanket, what is that partitioning?

What are we really talking about?

And then are we talking about the territory?

Are we talking about the Lorenz map or are we talking about the Laplacian map?

Where is this blanket partitioning coming into the picture?

And then how does that help us reduce our uncertainty about systems?

And what does it say or not about that underlying system?

And that's where we're going to be talking about particular partitions.

Of course, a favorite and recurrent pun, which is that particular means specific.

but also it means like a particle, like a autonomous particle drifting around in space.

And then section five really comes to a...

culmination with a discussion of the free energy principle alone.

And so I think it'll be interesting to discuss like what is subsumed into the free energy principle and why do we need one section Markov blankets and free energy principle, and then another section on just the free energy principle.

So that's kind of the roadmap, Stephen, and then deep.


SPEAKER_05:
yeah just a quick question see if this clarifies something which i think is what you're saying dynamics is um the dynamics more particular flow like so it's and densities while you could have a density of particles it's actually more like a probability density on wave functions would i be right in thinking is there's a kind of a wave particle

or actually a particle then wave way into this.

And that's partly how they're playing this out.


SPEAKER_01:
Someone with more experience with the formalism would be totally open to their contributions on that question.

My first take would be, you could make a dynamical systems model, like equations of motion for a particle floating around.

And so it's like, you're focusing on the first, second and third derivatives of movements

in XYZ space or tetrahedral space for some particles.

So a dynamical system model could be describing the movement of a particle.

But the flow that gives rise to the movement of that particle, it's kind of like figure and ground.

Like the dynamical equation features the movement of that particle.

Like I want to know the pendulum's location.

And so that's going to be a dynamical model of the pendulum.

Whereas the flow-based models,

like you pointed out, are much more about, well, what is the underlying space of the flow of that pendulum?

So it's like, if it's to the left of the bottom, it's like it flows this way.

And if it's to the right, it's like it flows that way.

And so that is about asking what is the underlying flow dynamics that do give rise to movement of potentially particles.

And those are why this meme is on the slide and why they are made in equivalence early in the paper, because it is like talking about the difference between the movements of a point through a space versus understanding the flow dynamics of that space that, yes, does give rise to the movement of particles.


SPEAKER_05:
And could I just ask one?

So almost it goes from just purely the momentum of a particle to this flow.

And the flow is kind of a bridge then between density dynamics, which is maybe more of a probability density of where it could be, which can map both to an object where an object might be, but also where a wave function might be in broad sense.

So then you're sort of going from literal particles in a classical sense to the flow.

And then the flow then bridges into density dynamics, which can be more probability orientated.

Is that fair to say?


SPEAKER_01:
yes particle is going to take a particular meaning a little bit later when we talk about the partitioning of states but i believe that's correct and also the density like you suggested ties much more closely to statistical density distributions like in statistics we're often interested in density distributions

of a special type like the area under the distribution summing to one the integral over a distribution being one allows us to treat it like a probability distribution and so that's the whole debate in quantum is it actually a wave or does that distribution of positional uncertainty merely describe our statistical inference on the location of something that's at a specific point so

Whichever side we want to come at this from, section two says it's going to be okay to use both.

And we're going to sometimes lean more on our left leg, and sometimes we're going to lean more on our right leg because there's tools that exist for one but not the other.

Dean?


SPEAKER_03:
Yeah, I don't know if this begins to answer Stephen's rhetorical question, but I think where most people get introduced to a Markov blanket, they get introduced to the idea that it's either a way of partitioning and dividing, or it's a way of being able to envelop or blanket.

And I think what the paper points out is that it's both all the time.

So you can, for example, find a box of cookies,

and see all the cookies settling at the bottom, or the person who's described as being creative uses that box of cookies as a leverage point to get more cookies off the top shelf.

Now it's a platform.

And now it's a mound.

And so we can see it both ways at once if we think of it as both ways at once.

It's not an or question.

It's that minimum of two piece again that is really fascinating about this that really kind of blows people up.

It's really both at once.

Then you decide which it's going to be.

And that's what I think is really fascinating for people who are just sort of start getting into this because they've been so habituated to saying, oh, it's a cookie jar.

Oh, it's a platform.

No, it's both.

And that's what we want to do.


SPEAKER_01:
Thanks, Dean.

And Marco in the chat wrote, like a boat in a stormy sea, it moves at the mercy of the seas and winds flowing forces with only its rudder, sails, and other limited mechanisms to steward the world's influence on its journey.

So Bucky meme one, unity is plural at minimum two.

Bucky meme two on his gravestone, call me trim tab, kind of like the rudder.

And that is exactly getting at the point of this paper, which is,

If we just were talking about a dust molecule floating in the air, then we could say, well, we could use the dynamical systems model of the position of the dust particle, or we could do inference on the flow of the room, and that gives us a different and complimentary totally co-extant picture, but that's a dust molecule.

What about active systems that have affordances that are able to do inference on action selection, choose different policies?

How do those active systems

do inference, that's the winged snowflake, that's the moth to the flame.

And those are the really exciting systems.

And that also speaks to the difference between what's called mere active inference, like the particle where we can still have this partitioning and still see it as a dynamics or a flow versus the adaptive active inference, which is then we're thinking about those systems where the particle, the particular states

are able to affect different policies and select between them in a way that acts as if it's resisting dissipation.

And those are the kind of exciting systems that we want to get to by the end of the paper.

Stephen?


SPEAKER_05:
And pulling on that idea of cookie jar, is the cookie jar is maybe almost a particle, a thing,

that is like leveraged, and there's a thingness which it becomes.

So say it has a thing about it, but there's a thingness of being an affordance.

So this is an interesting, just sort of came to me, but the thingness in itself is slightly emergent, because only by the process of trying to use it to get the higher cookie does another kind of thing emerge, which becomes a step.

So there's something interesting there about the Ness as an emergent, you know, is it ever a step?

Really?

But it's always, it's never not a thing at the same time.

So there's a, I think there's something quite interesting there in that emergent stroke, flow stroke, you know, literal sense.


SPEAKER_01:
And also, I don't know to what extent this is intentional, but thingness, we talk a lot about N-E-S-S, the non-equilibrium steady state or non-equilibrium stationary states.

And so it's like the things-ness, that's the thing.

The thing we're talking about is the things-ness.

So we're not talking and saying that the system is at stationarity.

We're saying that the things-ness exists

by virtue of how we're modeling it, has stationary characteristics.

And that is the thing as we model it, which is that always existing difference between the map and the territory.

We're not saying that the territory is even a thing.

We're saying the way we're relating and interacting with the map, which we totally made, no one's going to deny that, that maps everything.

is tractable.

I can hold the map in my hands.

That gives me better grip on my road trip.

Stephen?


SPEAKER_05:
That's a really... Yeah, I think also the thingness can tie into the idea that something ontologically...

comes into being through relation, through some sort of network dynamic in which it acts.

And actually, that speaks to this Lorenz attractor.

So the Lorenz becomes part of a network of an ontology of thing, which is really a thing in relation to what some other thing is.

Because obviously, the scale of the cookie box is quite a lot different to the scale of the atoms in the cookie box or the

Whatever scale we want to.

And then there's some sort of affordance level.

And maybe we can get out of the whole sentient system thing.

And it's like it's just an affordance for the thingness to maintain thingness.

It doesn't need to know about systems as such unless some creature happens to evolve a brain which starts to sit down working out system diagrams.

Yeah.


SPEAKER_01:
two-legged ones potentially um otherwise it's like it's just things all the way up right let's now that we're 30 fun minutes in let's um sprint up to that markov cliff and then see where we go so figure one of the paper

is kind of making this first fundamental connection between the Lorenz system as defined by dynamical equations.

So the traditional Lorenz is defined more like the blue version with an equations of motion.

Well, it has a positive lyopinib exponent, which is to say that very closely located points diverge rather than stay in like a laminar flow parallel line world or converging.

So they diverge.

And that's what makes Lorenz system chaotic, ergo difficult to predict given measurement error and tiny perturbations due to even thermal noise, which is like kind of how pseudo random number generators work.

And then there's going to be an approximation based upon this stochastic solution.

And so the trajectory in the right panel here, it's the deterministic solution to the Laplacian form of the Lorenz

based upon the Helmholtz decomposition.

And so this is sort of like the version on the right that's usually seen in the state space model is almost like we're sampling stochastically from points along that racetrack.

So that was figure one.


SPEAKER_05:
We- Could you just explain that, just go over that one more time, just to clarify that bit.

I think I understand what you're saying, but it's kind of an important point you make there.

When you say deterministic solution,

That, I didn't, there is that, just to clarify what that means.


SPEAKER_01:
So the deterministic solution would have no noise so that the

The position at the following time is entirely determined by the non-stochastic state that it's in at the preceding moment.

Whereas when we talk about a stochastic form, it's like, that's like your car's driving

and there's thermal vibrations on the road.

Now, the Lyapunov exponent on that car at non-zero temperature is small so that the flow term dominates the vibratory term.

But there could be some other system where the difference between, well, if it's in an absolute zero world and just on the road, then it's going to go straight.

But once you introduce any wiggling,

When the system is chaotic, it has that positive Lyapunov exponent, then the tiniest wiggle causes the system to diverge.


SPEAKER_05:
That's really helpful.

So basically, normally we just, like with the deterministic thing, it's just whatever the initial conditions, if it varies slightly, but then once it runs, it will settle into something.

But if you've got the initial condition and you've got the perturbations due to noise...

as it's actually running, which adds, I suppose you could say, a little bit of an extra change in initial conditions to each state that the Lorenz attractor is moving through.

So, okay, that's helpful.

Thanks, Daniel.


SPEAKER_01:
Yes, and I'm going to just show this image.

This is, I don't know if it's the very, very first, but this is the image that Lorenz

used to talk about chaos in 1961. so i mean what's the difference between 76.8 and 76.85 it's imperceptible if your thermometer only had like three significant figures you wouldn't even be able to talk about the difference but i mean how different can it be and it turns out that they those two systems start imperceptibly different but

nearby points in chaotic systems do diverge.

And so it's like, okay, but they're still tracking each other, right?

It's like, well, no, wrong, later on.

And so, of course, a more chaotic system with a more positive lyopinib exponent diverges faster.

But any system with a positive leading lyopinib exponent is going to have divergence.

And so if you have a purely deterministic system,

or one without this kind of the operative induced chaos, then you can predict far out.

However, prediction matter experts, as Dean I'm sure will revisit us too, meet their match with chaotic systems.

And that's actually one thing I hope that we get to by the end, which is that by putting action in every loop and inference on action, we can still, whichever of these timelines we end up on,

we're going to be doing okay.

Because we're always readjusting our inference to whichever of these mountains we're on.

It's not like one of these is better or worse or more or less challenging.

Like they have the exact same upper and lower bound.

The only mistake would be to make a prediction and be super confident about it and be on the wrong predictive timeline.

but as long as we're always updating our predictions then either of these days are going to be okay but if we put on the jacket because we thought that it was going to be cold here and that's when it was hottest then we're injured but if we just think okay well we know we have the jacket afford in so we're just going to keep an eye on that as we watch the temperature and continue to update our predictions maybe then it'll be okay

So that was the initial Lorenz attractor.

Section three goes into the Helmholtz decomposition, which we've talked about in several other streams.

And we've seen it introduced as the breaking down of a vector field, the total current in this kind of electromagnetic representation into the irrotational, which is kind of like the straight line.

There's no rotation in those straight lines and the purely rotational solenoidal current flow, currency.

We've talked about solenoidal ingredient partitioning.

And then what this paper does, and I think the technical details are in the Appendix B of 16.

So that was the Bayesian Mechanics paper.

And then also there's this housekeeping big lambda.

that's in one of the appendices to this paper so that would be like something for someone else to help us understand a little bit of because it does matter and it's actually a key contribution because if

the landscape is changing moment to moment.

You can't just do the Helmholtz decomposition once and sail on that sea without updating your estimate of the partitioning here, of the decomposition here.

That decomposition, so again, dynamical systems, that's like the position of the car.

And then we're going to, because of section two,

having an equivalence between that dynamics and the flow modeling.

And one of the terms that shows up on both of these is the fancy J, fancy I. It's the self-information.

The first part performs a Riemannian gradient descent on the negative log of the steady state density, which can be interpreted as self-information.

So how surprised should one be to be at a given location relative to expectation?

So we talked about how like the potential energy of the ball higher up on the bowl is higher, and then the potential function drops, and that's the physical analogy to this more informational statistical distribution approach to the self-information.

And then in 3.1,

that self-information is going to be pursued and expanded upon for a relatively more simple case.

So we're going to identify, due to the Helmholtz decomposition, that there's this key variable which can be interpreted as like a potential function corresponding to the self-surprisal, and that self-surprisal term may have functional forms.

so we can have a function that describes how surprised we should be.

Stephen?


SPEAKER_05:
Yeah, if you could go to that last slide, the previous one there,

I like this.

It's quite useful.

So the Fokker Planck, if it's at an equilibrium, which we're not at because we're doing non-equilibrium steady state, but if it were, then it would be zero, basically.

It's at equilibrium, so it's not changing.

So there's no divergence because it's zero.

And then he's taking this Helmholtz composition, which in a way is like a vector, isn't it?

With a vector, you can split something's movement into x and y. So the gradient is coming out, and the solenoid is at right angles to the gradient.

So it's kind of like that trick that he does with accuracy and complexity.

He can say that there's a solenoid and gradient which go together.

for when it's still in a kind of a particular angular momentum sense.

And then there's that ability to, with the housekeeping, to then move it into the flow, which I'm not entirely sure.

I think that's the bit where we might need some, quite what, because flow could probably be more specifically thought about.

So now you've got this ability to sort of structure

through the kind of more particular context, the solenoidal and gradient.

And then there's this transition to a more kind of general variable, which can be just, we don't need to get the particulars now because it's a variational metric that just gets used in an approximation sense.

And then it follows into what you're saying.

Would I be on the right tracks with that?


SPEAKER_01:
I'm not sure who he is, even though I have an expectation because it's a multi-person paper.

But just looking at these as like circles and triangles and squares, we can see that upside down triangle, fancy I of X is in both terms.

So there's like a Q multiplied by something and then a gamma multiplied by something.

And we see that omega

is defined as like the Q minus the gamma.

So these two terms, which were decomposed out from each other, get recombined into the final flow.

So that's just like if it were like A times X minus B times X, and then omega were defined as A minus B times X. So we're recomposing

a flow equation that still features this fancy eye.

And yes, we're solving that for a specific point that matters.

We want to solve that for where the ball is at the bottom of the bowl.

So there's a function that's going to tell us more or less in multiple ways, whether we're more or less away from the bottom of the bowl.

And again, it's not about the system being at stationarity.

It's about this decomposition having a Fock or Planck steady state.

Dean?

Oh, yes, you've got it.


SPEAKER_05:
Just one quick thing.

So at the bottom of the bowl, the gradient can effectively be zero, but solenoidal could still have a value because it can still be spinning around at the bottom of the bowl, but the gradient then... Because I noticed the gradient...


SPEAKER_01:
term isn't in the flow but the solenoidal term is oh the gradient is because q minus gamma is in omega so omega is this omega del fancy i is just these two terms combined okay okay yeah dean yeah i was just gonna say what


SPEAKER_03:
Typically when this is brought forward, it's easier to understand the decomposition and the recompiling if we view the blanket as a partition.

Where it gets a little bit more interesting is when the blanket is literally an envelopment.

And there's a physicist by the name of Keith Humphries who talks about emergence and he looks at that piece of it as well, because there's a polar aspect to this.

We can think of that in terms of positive and negative fields, magnetization and stuff like that, and how that is also a decomposition and a recompiling.

So I understand how it was presented in this paper,

That's the partition way of looking at it, right?

It's more or less, but there's also the positive and negative polar piece to this when we look at the Markov blanket as a blanket, as opposed to a separator.

And again, if we're holding up two things at once, this doesn't change that.

It's just making sure that we hold both things up at once, the envelopment and the divider.

I just want to bring that out there because, again, we can see it easier as a partition, like the skin as a partition.

We don't typically see the skin as a platform for sunscreen.

That's my point.


SPEAKER_01:
Thanks, Dean.

Stephen?


SPEAKER_05:
Yeah, this is a good point in terms of

You can imagine, at first I was thinking about gradient.

It's obvious that you've got a gradient that you can pass through maybe where the gradient's zero, but also solenoidal flow, I suppose, if things are moving around this way and it starts to turn and it starts to go the other way, at some point the solenoidal flow is also passing through a zero.

So they can both pass through a zero point.

It just wasn't as intuitive when I first thought about it.


SPEAKER_01:
Yeah.

And even if you have something that's spinning around, like something that's spinning in a circle, like a hammer thrower, it's actually continual acceleration.

That doesn't mean it's speeding up.

It means that the vector is continually changing.

So now our map is of that acceleration and it is unchanging in how it changes.

So that is to say that the system can have

in a different way of thinking about it.

Yes, a solenoidal component.

We're not saying that balls at the bottom of bowls are dead and unmoving.

We're saying in our map, there's only one point because we set it up to be like a bowl map where the derivative is zero.

That's the solution where the rate of change is zero.

So that's not to say that the system isn't moving.

That's to say that the flow steady state has been achieved.

In figure four, well, in figure three, we see the three states.

So this is like the cover of the GEB book, like kind of three different projections from a three-dimensional system.

The second versus the third, the first versus the third, and the first versus the second.

And we're seeing how there's,

movements of sampled trajectories, and they're kind of coming back to something that's bowl-like for any set of two dimensions.

So it's kind of like a three-dimensional bowl now, because any two of these dimensions, it's more like a regular bowl, the kind that soup goes in, but then the soup bowl is like

a down projection of a system that has an attractor in a higher dimension, potentially a much higher dimension, but the Lorenz, they're only modeling three because the particle only moves in three dimensions.

When we continue to investigate the bowl-like properties of our Laplacian approximation to that Lorenz system,

we see that there's a few different shapes of bowls depending on which angle we're gonna shine the flashlight from.

Some of them are like spherical.

So a spherical bowl doesn't have any specific correlation between the two dimensions.

It's like a cloud of points.

The regression is just like flat through it.

However, there are some

where the bowl is non-random.

So it's almost like if we were tracking the movement of a ball, it's getting jostled around in these bowls.

Well, like the one of the first and third, if that was the light we were shining, it would just look like it was a scatterplot.

There's a totally... The regression's flat.

There's not much information being provided.

It's...

within the bowl so it already has some nice dynamics but it's kind of within that attractor zone it's a scatter there's no pattern but clearly for the first and the second we see that there is a coupling now imagine if we didn't see the bowl because of course we don't it's not there that's part of our map we're just seeing the movement of that ball as we sample it through time and it would be only on this manifold

kind of being like spending more time going from the top left to the bottom right in these images.

So we're gonna take that idea and then connect it to the Jacobian and the Hessian, which is again, throwback to our matrix math slide and an awesome opportunity for anyone who wants to bring more of a technical interpretation to the stream.

The Jacobian is like the first,

the unnamed matrix is just like the matrix of position.

So that's like the first moment of the distribution.

And then higher moments are like the partial derivatives.

So Jacobian is like the first order partial derivative.

So that's like the slope of the ruler at that point.

And then the Hessian is the second partial derivative.

That's like the curvature.

So if it's a bowl, there's only one point where it's flat.

And then it could be flat and the bowl could be like up or the bowl could be upside down.

And so that's why it's important to also have this second curvature term to understand whether we're at a bowl like this or a bowl like that.

So that's kind of like calculus.

And those...

bowls, those bowl attractor shapes, which we're inferring using the Laplacian quadratic assumption.

So it's not saying that the Lorenz has these, possesses these, is these, it's saying that's the approximation that we're going to make.

It turns out that although there's somewhat of an unclear correlation pattern in the first derivatives, so like the movement to the left, it's not like it's correlated with movement up.

However, the second

partial derivative, the Hessian matrix, starts to look a lot like the covariance matrix.

So the actual positional covariance of these states with each other, so like the on diagonal is kind of obvious, like of course your position on the x-axis is correlated well with your position on the x-axis.

But there are correlations between state one and two, and the

That is recapitulated in the structure of the second order polynomial approximation to these attractors that are Laplacian approximations.

So again, up until that point in 3.5 and in figure six, Markov has not been introduced.

nothing has been said that word hasn't come into play it didn't come into the system's definition and so that's just really important because it's just showing like there's a lot of groundwork to get to where we make the markovian partitioning and so there's power and challenge in that stephen


SPEAKER_05:
Would I be correct in saying that effectively it's a case of approximating the states of the Lorenz attractor and that's what's currently there so this is different ways of showing that within some manifold state space and by approaching it in different ways it

reveals a different type of approximation.

The only thing I would ask, I'm a little bit confused why it does squish.

Maybe I'm missing something.

I can see why there'd be kind of a round one.

I'm just trying to work out how it squishes.

Is it something to do because of the solenoidal piece or the gradient piece, or is there something else?


SPEAKER_01:
Okay.

So if we were talking about just a particle undergoing Brownian diffusion in three dimensions...

So it doesn't have any kind of correlations or any sort of structure.

It's just a random walk in three dimensions.

Well, then it would have a spherical error profile for all of these images.

But we are capturing structure that exists because Lorenz attractor has a specific specification.

So the states are whichever are being modeled.

If you cared about pressure and volume, that's your state space, that two-dimensional state space of the map.

It's not saying those are the only states of that system.

It's just, those are the ones that you're modeling.

In the Lorenz system, we have three states.

It's positioned in three dimensions.

But those three dimensions, again, also apply to a Brownian diffusing particle, which has a different Jacobian covariance and Hessian.

We're talking about those being calculated for the Lorenz system with the parameters that they selected.

And so we are pulling out covariances and connecting it to this second order polynomial approximation in the Hessian

for a system where the movement is not just a Brownian diffusion.

And so that's why there's structure in the covariance, and that's why the structure is interestingly recapitulated in the Hessian.

Dean?


SPEAKER_03:
Yeah, and all I would supplement that with is things, things, here we go, things that are in something that's moving, the thing that's moving, that's in something that's moving, that's on something that's moving has a tendency to have the negative charge things all congregate in one place down in the lower right corner and all the positive things all congregate in another place.

in the upper left corner.

That's the nature of movement.

And so that polar part of it is in play as well, if we consider it as part of these statistical transitions.

And that's, again, it's fascinating if you look at it a minimum of two things, so not just

not just as a partition, but also as an envelope, those things suddenly pop out at you and you see the pattern in a different way.


SPEAKER_01:
So I want to think about a physical system that's not chaotic, but will help us understand what this covariance matrix is.

So let's think about a children's carousel.

So it moves, the horsey is moving around in a circle.

And so that's like our unit circle, like the four quadrants.

And then also the horsey is going up and down.

okay so when you're you know so again it's like you know if you were at 12 o'clock on the carousel it's like you have a one for the y and a zero for x okay so i hope that makes sense now as it goes around it's like 0.5 and 0.5 again just using simple numbers here like the x and the y are correlated and then they're also correlated here so

one could say that there's like a correlation between the x and the y like they have a covariance together but now the z-axis is moving up and down independently so a system like that you'd see a covariance between the x and the y positions of the horsey and not that they're a different system but that they are

uncorrelated.

They don't provide mutual information on the Z axis, which is oscillating.

Now, if this paper had done, we model a deterministic carousel and it's kind of like putting the rabbit in the hat because the covariance matrix, it looking like this would be no surprise because it would have been defined that way.

So that's the key insight.

And one of the key contributions is like, they didn't put this in the hat.

This is

the OG complex system.

Yet the approximation, the Laplacian approximation pulls out a covariance structure that's extremely tractable.

And it turns out that it still has a very strongly positive and very similar Lyapunov exponent.

So it's like, now it's like a chaotic carousel,

And yet our approximation, our map of that chaotic carousel still holds the chaotic nature of the system while also giving these bowl-like attractors for any given two and even all dimensions or states considered simultaneously.

we're not conflating the simplicity of a non-equilibrium steady state with the complexity of the underlying density dynamics so just because the map is simple doesn't mean that the territory is and so that to me is a knockout blow against realism and for instrumentalism because this paper's saying nothing about the underlying system

Act-inf doesn't say anything about the underlying system.

We're talking about approximations and our maps of territories.

In other words, the probability density can evolve in a complicated fashion in attractors.


SPEAKER_05:
Go ahead, Steven.

And from what you're saying, it's like if I was to take that Lorenzo tractor, which is like a saddle.

People often talk about a saddle.

And you took the most...

agreeable way of viewing it.

So you view it in a box space this way and look for how it's moving that way and then flip the box like this and see how it's moving that way and flip the box like this and see how it's working that way.

Those approximations would be those three different distributions.

However, if you'd have moved it by like one degree,

that would be like messy, right?

So it's like, if you look, it's almost like this is how the Lorenz attractor taking the most optimal view of X, Y, Z can be mapped out as it transgresses through the saddle, if that makes sense, to bring it into a physical space.

But again, it's more complex than that because this is taking it where there's

the Fokker plank is zero to try and get the most optimum sort of, that's why those things are, follow a nice stable transition.

Whereas if you'd taken a sort of an odd angle, it might all be completely a mess.

Would that be a fair way of saying it?


SPEAKER_01:
If you were to take a perspective, a projection down,

that was a mixture of other axes than, I'm not sure what is gained by that, but I see what you're saying.

There's some particle moving in three dimensions and you can have a projection into any side of that cube, or you could take some sort of off kilter view that would be still some type of linear summation of all three.

So it hasn't really reduced the challenge of estimating, but yes, I mean, that's one way to see it.

Dean?


SPEAKER_03:
So I'm in complete agreement.

It has to be instrumental so that you can compare to the real, so the minimum of two.

You have to have multiple maths, not one, in order to be able to see this.

And that basically then reinforces the idea that the Markov blanket has to both, at the same time, be a partition and be an envelope.

It's both at the same time, a minimum of two again.

So again, all we keep reinforcing is this idea that if we over reduce, if we get to a place of under two, we may be deceiving ourselves.


SPEAKER_01:
And I think we'll come back to that soon.

So now, one hour in, we're able to get to the Markov blankets.

okay so previously we were talking about the case of a single markov blanket and so if we thought about like a bayesian graph so now we're thinking about three nodes each corresponding to the x y and z axis nodes a and b you know the first two axes would have like an edge between them because they have some type of statistical relationship

And then it would be disconnected from the third node because it doesn't have a statistical relationship with them.

Okay, so now to actually start to get towards more like the communicating systems or system in the niche that we're interested in, that's the target that we're trying to aim towards in section four.

The authors repeat the analysis of the previous section, but approximate two Lorenz systems that are coupled to each other through their respective first states.

Okay, so we're going to look at this matrix.

Okay, so notice that there are two, this, make that transparent.

So here's one Lorenz system

Here's the other Lorenz system, the red one and the blue one.

And then there in these other cells, these are the coupling terms.

So these are couples.

This is saying that the first state of each are coupled.

So it's a bidirectional coupling and that it's saying like state one, the fourth state on the matrix, like matrix row and column four is the first state of the blue system.

The first state of the blue one, the top left of the blue and the top left of the red are coupled through the off-diagonal green boxed terms.

If this was all zeros, nine zeros here and nine zeros here, we would have two independently evolving Lorenz systems.

So we kind of took the Lorenz system

the three by three matrix that specified the dynamics of that system.

And then we just made another, now a six by six matrix with two Lorenz systems that would be evolving statistically independently unless we introduce this targeted coupling.

And they say this form of coupling was chosen to be as simple and symmetric as possible.

Okay, so this is like the next step, but it's a difference that makes a difference because this is going to change the total dynamics of it.

If you had just the red and just the blue, you could like split that matrix and you'd be getting the exact same modelability because the systems wouldn't be interacting.

But now we've introduced these terms, even if we only had one, where you can no longer divide this matrix into sub matrices that perfectly describe the time evolution of the system.

So seven, figure seven,

is like figure three.

So it's similar, we're taking like sort of pinpoint locations on the Laplacian approximation of the Lorenz system.

And now seven is doing the same, but it's looking at these two synchronized systems.

Or maybe it's better to say that

there's two coupled systems.

Yes.

And due to the structure of their coupling, it results in an entangled movement pattern such that their trajectories have very, their trajectories are informative of each other.

And that's also reflected by this flow diagram where clearly they're,

movements exist on a manifold

that's in a restricted space of the possible.

So two people, Brownian diffusing in two separate rooms, you'd get that circle scatterplot.

Two people who are tied to each other, you would see a perfect correlation.

And so we're seeing something, even though each system has complex and even chaotic endogenous dynamics, we're seeing that the introduction of this coupling term


SPEAKER_05:
allows the systems to actually empirically have entangled behavior steven we've now got lorenz systems as opposed to an attractor and i'm curious when does it go from an attractor to a system is it because is that does the coupling effectively start to create more systemic

nature or, you know, I'm just curious about that.


SPEAKER_01:
Um, systems, the Lorenz system is just these three.

This is the specification of a Lorenz system and it has, it's a chaotic attractor.

And so now we're talking about two of them.

So there's two coupled Lorenz systems, but it doesn't make sense to talk about two coupled attractors because that's not what's coupled.

The systems are coupled as per the matrix specification.

And then it doesn't even make sense to couple the attractors.

The whole point is there is an attractor now by virtue of the coupling of the Lorenz systems.


SPEAKER_05:
Is it almost like once you start to have something and you're going to relate them,

As soon as things relate, there's a system because there's a relational quality to it.

Whereas previous that it could be a mathematical formalism.


SPEAKER_01:
It was still described as Lorenz system.

So I wouldn't get too hung up on that word, but yes, systems have multiple interacting parts.

Okay.

Figure eight, just like seven revisited the format of three, eight is going to revisit four

And now we're going to get to where we start to see the partitioning.

Figure eight's going to revisit four.

So remember the first partial derivative, the second partial derivative, and the Jacobian and the Hessian respectively, and then the covariance.

So we're going to do that same thing that we did on a three by three, but now we're going to do it on a six by six.

The log Jacobian looks a lot like this.

The non-zero cells in the specification of the system

which is the system itself for systems that we get to specify.

It looks a lot like this.

But again, for territories we don't get to specify, the map looking like this does not say something specific about the territory, but it's not super surprising that we actually see like similar this top right has like no correlation, like one and three are not correlated.

and we see that little chip missing here and here.

So we see a lot of the same dynamics at play within each of the coupled Lorenz systems, but also we've introduced a coupling.

Now that coupling induces a new and different covariance structure.

Look at these gray squares in the off diagonals.

Now one and two of system A are coupled to one and two of system B. Less so, a little bit grayer than the one that are within each system, but still very marked bidirectional synchronies being induced.

interesting piece comes into play when we look at this second order approximation and that's where we see that several cells can be identified so here we have like the magenta uh mute please steven thank you the magenta and the red are those first states of system a and b those are the ones that have the coupling on the fourth okay

then you have the other two states of system a in teal and the other two states of system b in dark blue so it's almost like we have four kinds of states four kinds of states out of these six of course you could say well each each state is unique great totally true they're different states that's why we have those different dimensions in our model but

there's going to be some interesting things that fall out as a function of us separating out the two systems and then separating out parts of the system that interface internally and externally, and then parts of the system that do not directly, by virtue of how we know we specified the system, do not couple out.

Again, the fascinating thing is that like state two of system A and state two of system B have a covariance.

That's like maybe a mirror neuron.

Again, using a more like realistic mapping, it's like there's some internal part that is only interacting with other internal parts by virtue of how the system is defined.

And yet these two parts in each system, which are not directly interacting by virtue of how we set up the system, have covariance.

So that is what leads us to this numerical analysis, which kind of

provides a little bit stronger and different empirical evidence.

So it's not just an analytical formulation, it's a numerical simulation where we can see that when we actually let that system play out, that even when states start very correlated, like we just start the third and the sixth states in a very similar position, so they start out with a high partial correlation coefficient,

when we run out that simulation through time, it ends up trending towards zero partial correlation.

So we're recapitulating the correlation patterns of the system, even when it starts in a more correlated place.

And so that suggests that some very essential

aspects of the system are being isolated and tractably handled by this kind of partitioning of coupled systems so it's pretty interesting now we've seen this top dive oh dean yes and then we'll just just real quickly daniel what it also says is that hyperbolic is also existing in this pattern although it's not necessarily being um


SPEAKER_03:
materialized in these diagrams, it's also there.

I mean, what that's what this explains is that there can be continuity, there can be alignment, and there can be hyperbolic function within all at the same time.

Again, that's I just want to, again, I just want to point to the non obvious, but it's still there.


SPEAKER_01:
Great.

So we've seen this top of Stephen.

Yes.


SPEAKER_05:
I was also going to add that by showing the nature of the coupling, like varying the nature of the coupling that you showed, it can reach a different sort of state, non-equilibrium steady state in some ways.

Would that be true?

There's a different pattern emerges as, so it could speak, maybe I'm overextending this, but changing the nature of how things couple is,

could in a way change the sort of states which things can fall into.

So you could almost have multiple states being inferred based on how the coupling is set up.


SPEAKER_01:
Oh yes.

I mean, we would throw out any model that treated two people tied to each other as simply moving the same way as two people in different rooms.

It is the coupling of systems that influence their behavior.

And again, we're not talking about the causal structure of the world territory.

We're talking about the models that we got to specify and how changing the coupling pattern changes their behavior.

Dean.


SPEAKER_03:
And Stephen, when you're taking the abstraction here off the page, so you could set up your programming, for example, that says, okay, I'm willing to sponsor somebody because I want to mentor them in bricklaying.

You can start with that, or you can start with, there's two people that are interested in bricklaying, but the first thing we have to address is whether there's a potential for positive entanglement.

In real terms, that's how you can flip the abstraction into the likelihood of those entanglements turning out, extending, because the people will actually be relatable to one another.

So that, I just, again, I'll bring that up because that's how we turn the abstraction into the, so what does that look like?


SPEAKER_01:
Okay, Stephen, something quick on this, otherwise we'll get to 10.


SPEAKER_05:
Oh, yeah, just very quickly.

Yeah, so that speaks to, because we often think about the model on the inside, the generative model and the external states and, you know, the model trying to understand what the external states are doing.

But this speaks to the ability to change the way the blanket is coupling.

So, you know, how much work is going on in terms of,

enabling there to be information, variational free energy information being used in the generative models, how much is being done by actually changing coupling dynamics in the blanket

Is that, it's even feasible that, you know, because that in itself will start to yield more and more ways for the generative model to start to extract and make inferences based on what's going on externally.

So that also helps, I think.


SPEAKER_01:
So as a heuristic thought pump, yes, great.

But actually the blanket is downstream of the coupling pattern.

So it's like changing the coupling of a blanket is a little bit of a cart before the horse because there is the coupling of the system.

And that is what induces partitionings, which we can then map to Markovian assumptions.

So it's like, you know, when you put on headphones and you're listening to this, yes, a different blanket is in play because the partitioning is different, because the coupling is different between other states in the world.

Dean on this?

And then let's go to 10.


SPEAKER_03:
Yeah, I'll be real quick.

So Charles Saunders Peirce's abduction doesn't guarantee that when you walk in later and see beans in one hand and a bag of beans in the other, that you'll get to a... Okay, I just lost Dean, so I'm going to continue.


SPEAKER_01:
So in figure 10, but he was talking about abduction in C.S.

Peirce.

kind of that flipping that.


SPEAKER_03:
I understand, you're right.

It is the cart ahead of the horse.

And sometimes that helps.

Not saying it's, and I know you're agreeing with me, but all I'm saying is we shouldn't just assume that it only goes one way.

Horse first, cart second.


SPEAKER_01:
yes and in fact partitioning different imagining differences ways it could be different absolutely this is how we are going to apply and ask what is if for active inference like what is is like what is the blanket states given a coupling pattern well there's an answer

Sensory states are the ones with incoming statistical dependencies, and active states are the ones with outgoing statistical dependencies.

Those are the blanket states.

What if the coupling were different?

Then what would the blanket be?

So yeah, it's not that that first blanket that you identified is being changed.

What's being changed is the coupling, which induces a different kind of covariance amongst the states, but it can be almost thought of

in a cart before the horse way.

So just to recap this nomenclature, which we've seen before,

So we have external states, sensory states, active states, and internal states.

B is the set of blanket states.

So this is one of the innovations of Friston et al.

beyond Pearl 1988, beyond Markov et al.

earlier, earlier, earlier, is that blanket states, which in the non-FEP act-inf world are the set of states upon which

Conditionally, internal and external states are independent.

Those blanket states, again, we're going to partition them into incoming and outgoing statistical dependencies, sense and action.

Now we have autonomous states alpha, which is the set of

active states and internal states.

Autonomous states are the ones that for systems that we design, we get to control.

We get to control our internal states.

We get to control our actions.

We don't get to control directly the sensory input.

You can close your eyes so that it's darker, or you can move your head so it looks differently.

And maybe you'll even be right about what sensory information comes in then.

but you can't just say, I want different sensory information coming in.

So those are the autonomous states.

And then there's the particular states.

The particular states are the whole particle.

That's the blanket states, which are a sense and action, and the internal states.

So the particular states are like the whole particle floating around in the room or the whole cell or whatever, again, to give physical interpretations.

And then the autonomous ones are like the things that the cell can control.

or the thing that the system designer can control.

So we have autonomous states, which composed of internal and action states, blanket states, action and sense, particular, all three on the right side.

And these are all being defined as a partitioning, a cleaving apart from external states as modeled, not of the territory of the map only.

Steven?


SPEAKER_05:
And as we mentioned here, this paper gives a way for this to emerge from the very most basic principles.

And then we have, like you described, the blanket states, the autonomous states.

But of course, in...

any sort of system, organism, non-equilibrium steady state, they're always nested.

So it's not like there will be a whole nested levels of Markovian blankets.

So when we emerge at higher levels,

we might be emerging.

It's not like, unless we made our blanket, there'd be no blanket.

There's going to be blankets all the way up and down.

So as a blanket starts to be formed or brought into play, then the,

the nature of how those blankets come into play starts to draw in the idea of coupling.

So maybe there's some of those things that you just mentioned there about there's not a dependency.

The fact that we're creating something from first principles doesn't mean in the real world without the first principles, we can't make a blanket.

because in other cases it's going to be sort of emergent through more coupling between blankets because i know we're talking about the blanket but it's also good about the blanket in this scale and then the blankets in plural at the multi-scale okay yeah so within


SPEAKER_01:
internal states, again, these are statistical dependencies.

So this one can have other things happening.

It's like a black box within each one.

And so that is for people who expect to see the mechanics of the system, that's a disappointment.

But for people who want to model real systems, including machines, it's a huge advantage because it allows us to go in keeping the map territory distinction totally apparent, which is the real transparency we need from our machine learning models.

You know, there's not going to be a transparent explanation for how 500 variables interact, but we can transparently see potentially how the map and the territory are distinguished.

Now that's where we get to their definition of Markov blankets.

So let others read through and work through the math and critique it and build on it.

But we're talking about boundaries based upon sub matrices of the total state space of the system.

So like, this is just two coupled systems that we're talking about here, where we were studying like system A and system B, each is Lorenz.

We added the coupling to one and four, and that's where we saw a new pattern arising.

Why does a particular partition comprise four sets of states?

Is it because tetrahedra are the minimum polyhedra in our world?

In other words, why does a particular partition consider two Markov boundaries?

The reason is that the particular partition, again, particular states, blanket and internal.

The particular partition is the minimal partition that allows for directed coupling with blanket states.

Sensory states can influence internal states, incoming dependencies, and active states can influence external states, outgoing dependencies, without destroying the conditional independencies of the particular partition, as shown in the upper panel of figure 10.

So very cool how we went from one coupled system or from one system with chaotic dynamics, made an approximation, and then showed that it had certain well-behaved aspects.

And then we took like the next step up, which is to couple systems in a way that we designed.

And that gave a new manifold that the systems were using.

acting entangled as if within and then here's where we get that very fun claim that there's no claim either the original Lorenz system or coupled Lorenz system possesses a Markov blanket we're not describing the territory I don't even think we're even describing the first level of the map

The claim here is that there exists a Laplacian approximation to these kinds of systems that in virtue of the zero elements of the Hessian feature Markov blankets.

So,

This is one reason why, while also acknowledging that there's many perspectives and so much to learn, that we do want to be precise with our language, because it's easy enough to say that the system has a Markov blanket, or there is a Markov blanket in the system, or all these other ways which prepositions and nouns might be combined.

And those might be so misleading, it could be truly incredible.

So it's a word of warning because as we figure out exactly what the technical details are and continue to clarify here, it will matter which natural language words we use to describe it.

And it really does matter.

Dean?


SPEAKER_03:
So let me add to that, Daniel.

So on an abstracted level, we can frame the problem as in or out.

And then when we translate that into the physical space, we know when something is entangled or when something is different.

But I think what this allows us for on the abstract level is to sample the Markov blanket

as in and out.

It gives us the potential for a second way of looking at how those two things work together.

The Markov blanket has both a divider and an enveloper.

Do you agree?

So on an abstracted level, it's very important to be precise, but if we include this,

we have to accept the fact that on an abstracted level, in and out must be part of our repertoire, not just in or out.

Because one is more precise, what is active inference, while the other allows for what if active inference, the and.

Would you agree?


SPEAKER_01:
I think I agree.

I'm just imagining that it could be possible to design a system where there was one coupling going out, but there was no coupling back in.

So one could devise edge case matrices that have various kinds of properties.

Would those even be good maps of systems that we care about?

Probably not.

So for some of the basic attributes like of communication, like of course, if one person's not wearing their headphones, like, yeah, the systems are coupled.

One person's talking and the other person can hear them, but not return any information.

So it's like, that's interesting.

It's a type of coupling that systems can have.

And it has a different blanket because of that.

But especially for systems where we want to think about states that are influencing the environment and vice versa, whether it's communication or stigmergy or coupling or collective behavior, that whole class of systems, it's extremely important to have, of course, in and out and more and less and different.


SPEAKER_03:
I wouldn't drop or.

Sorry, Stephen, I just got to get this in.

I wouldn't drop or.

I'm actually suggesting that this tells us we must also contemplate and.

So that's like saying, okay, so which is more important, the positive ions or the negative ions?

They're going to congregate.

And we can tell the difference, but we shouldn't apply a value all the time.

There are times when we can just see the difference and accept that for what it is, as opposed to always jumping to the idea that something has to be more or less, that the positive ions are more important than the negative ones.

Maybe they are, but we shouldn't jump to that right away.

Done, I'm done.


SPEAKER_01:
Okay, closing thought on this, Stephen, and then we're going to get to free energy principle.


SPEAKER_05:
Yeah, so yeah, just mention a little bit to what Dean said there, like, yeah, if something's a charged particle, how much is the system of the molecule showing the distribution of charge, and how much is it the quality of the thingness of that thing, right?

So I suppose, and that becomes, I don't think there's a definite transition.

And I'm glad you went back to this diagram.

This is the one I just wanted to mention there then, just to...

The arrows there on the right, so where sensory states, it shows that the sensory states are related to the same external states as the action states are affecting.

So it shows it's almost like there's a regime of attention.

So it's not, the sensory states aren't reading something coming in

about something which is completely unrelated to you know it's not like i'm looking i'm acting in front of me but actually my eyes in the back of my head right so my sensory state there's there's an alignment and and then when i look to the the left this this coupling that's going on then between

in the way that it's set up between this, it's saying it's not a Markov blanket when it's saying it's a coupled system.

So it's sort of saying in a way that this more slightly more nascent version, there's kind of, there's still a spookiness about it, I suppose we might say.

There's sort of a, it's not, it doesn't drop out as far as a Markov blanket.

There's that kind of,

resonation going on and i suppose somewhere between left and right you start to become you you meet the the conditions of a markov blanket and i suppose you know that's an interesting point


SPEAKER_01:
I don't want to just make the water murky with too many terminology.

We haven't brought attention in.

It's not related to what we are discussing here.

But I see what you mean that, yes, if actions were influencing state A, you know, your actions were moving something up or down, but you were observing the left-right.

Yes, that's a different kind of system than if you're observing and acting on the up-down movement of something.

That's not a regime of attention, but I know what you mean.

let's get to the fep okay finally remember that edges reflect statistical relationships which is the other side of the coin of saying that the absence of an edge reflects a conditional independence

so one can provide a definition of the conditional density over external states so probability density that's why it was so important to go from dynamics to densities in section two and we're going to think about that external density probability density conditional statistical density as being parameterized by the conditional expectations of internal states given external states here's the formalism

see how the coupled systems have a flow where like, given where you were on one, even if it were a little noisier, as long as it looked like an oval, as long as you were like, you'd know that if you were low on the left, you were going to be low on the up and down.

And if you were further to the right, you'd be higher up on the Y axis.

Okay.

But imagine if the flow was like in a circle, you'd say, okay, we're at X on the zero.

Well,

you really don't know because you could be low, you could be high.

Or imagine if it was just like a scatter cloud, no matter where you were, you wouldn't, like it was everywhere in the box, you wouldn't really know.

But because there's a manifold, then this admits the possibility of a diffeomorphic, which means like sort of like function-like and stretchable map between the sufficient statistics of the respective densities.

not the territory not the first map i don't even know if we're at the second map anymore we're talking about sufficient statistics of densities of approximations okay i think it's a death blow for realism personally but i would love to hear somebody who thinks it's not the existence of this mapping rests upon a continuously differentiable and invertible map which is linear under laplace approximation

There's a few technical pieces there, but it's almost like we set up the system in a way that was defined only by its coupling.

But then we also got to choose our approximation approach

And it turns out that with a system with interesting coupling dynamics, enough to befuddle almost every other kind of model out there, the approximation has a really nice relationship that recapitulates aspects of the system and lets us map, like if we're on low on here, we can go to low on here and low on here to low on here.

Like it's a kind of, it's a function that can go both ways.

And so that is going to be the relationship sigma mapping between the internal and the external states, which was explored more in the Bayesian mechanics paper number 26.

This means the autonomous flow can be expressed as a gradient flow on a free energy functional of the variational density.

Here are those four states, four kinds of states, external, sense, action, internal.

And those are going to be expressed as a tuple.

It has to be, because it has to be all four of those states co-evolving.

And those have a gradient flow, gamma and then the upside down triangle.

plus the solenoidal flow.

So remember way back when, when we saw that we had Q solenoidal, G gamma for gradients, and then lambda for housekeeping.

Okay, so now that is coming back into play

The solenoidal is still a single term.

That's just the potential function, that self-surprisal and one solenoidal term.

Then we have a gradient over these four states and then the lambda housekeeping.

That can be rewritten.

And now pi, again,

let the ontology develop so that we can resolve some of this, but notice how particular states pi are the blanket and the internal, okay?

But how have we usually used pi?

Policy, action selection.

So this is a different pi.

the free energy functional on particular states, particular states, let's call them, equals the self-surprisal on the particular states plus a divergence term.

That is the form that then lends the ability to interpret that free energy functional on particular states

to be rewritten in several ways including energy minus entropy that's a very classical chemical way to talk about free energy to be phrased as the divergence between the q distribution on external states and the p distribution on external states conditioned on particular states

plus the self-surprisal of those particular states, or the one that's closest to the Bayesian information criteria on Bayesian modeling world, but still being shown as equivalent to, is the accuracy minus model complexity and the evidence lower bound.

So that's where we've seen these formalisms come out many, many times, but we're approaching it from a very different way and a lot more bottom up.

And again,

I think, but again, would be open to people correcting in a way that fully embraces the map territory distinction and makes no bones about it.

Whereas if you just pop in from the top with these formalisms, it might seem like they're describing aspects of the system.

But I hope that the way we've approached this over the last like six hours of live streams, literally, and the way that the authors wrote it so carefully makes it clear we're talking about these formalisms on,

probably not even the first map and maybe the second map or summary statistics thereof.

These are relationships that are intrinsic to our approach of map making because we did the Laplacian approximation, et cetera, et cetera, et cetera.

Steven, and then Deep.


SPEAKER_05:
Yeah, this is very helpful.

I might just ask we go and walk through the very first sentence again in a second, just because I think it'd be helpful just to reiterate.

But from what you're saying, and I hear this really clearly, is that the particular states and the thingness of maintaining particular states, potentially, or of whatever those particular states persist,

effectively then is the same when at a higher order level over time and space as a policy because let's not bring policy in picture yet we just haven't gotten there but states and internal states okay i won't i won't jump the gun on that but so um i i suppose the the the point is just to say that we we can still be in the realm of thingness

Okay, we can still be in the realm of thingness because we're talking about particular states of things.

So we haven't got, and I won't say beyond that.

And then maybe just to go through the ontology, not just of that first sentence, just to reiterate, just to get it clearer.

Again, autonomous flow, expected internal state.

Could you just recap that just to just unpack that a little bit more, just so that it's a little bit clearer?

Okay.


SPEAKER_01:
So the autonomous flow, so autonomous states are actions, which are not, we're not even bringing policy selection in.

So it's the right direction we want to go.

We want to be talking about internal states that are actually doing planning as inference

that affect their action states.

But for now, we're just treating the action states as outgoing statistical dependencies.

And then we're just, we're pausing on how the actions are selected.

We're just, because in the Lorenz system, there's no policy selection, but there are external states that are modified by states.

Those are the active states.

So it's almost like we can talk about action without policy inference.

So the autonomous states, the autonomous flow,

at the expected internal state.

So these are expectations of autonomous states, action, outgoing, and internal states can be expressed as a gradient flow.

So now it's like, we're going to, rather than have a six state system, we're going to rewrite as four states.

remember we pulled out four kinds of nodes and now we're going to express a flow, not in a six dimensional space where each dimension was a measurement that we were making, but express a flow over the four kinds of states.

And then that means that even if there was a bunch of internal nodes that were communicating to each other,

we could still use this fourfold breakdown, hashtag William Blake, hashtag Bucky, hashtag Fristin, no matter how many specifics were inside the internal or how many blanket states there were, like how many nodes in the graph or how many external states, because now it's like a flow over kinds of nodes

And then that, because the nodes are defined by their directionality of relationship, like how they influence each other, right?

Like internal and external, we know don't directly influence each other.

They're conditionally independent based upon blanket states, et cetera.

That allows us to write formalisms that are like evergreen and can be expressed as flow.

Dean?


SPEAKER_03:
Yeah, I would just say that when I first encountered these kind of formalisms, I always ask, and then what happened?

And that's when I coined the phrase, when in doubt, zoom in, zoom out.

But I didn't want that zooming in and zooming out to be collapsed just to the optical zoom.

I assumed that your legs wouldn't become paralyzed when you picked up a telescope or a microscope, that you would still zoom in and zoom out by moving.

So the inference is in doubt.

So how do you overcome that?

You become more active, but not just with your eyes.

You actually pick yourself up and move yourself around a little bit more.

You don't just have to be on the north end of the carousel.

Sometimes you can pick up a ladder and look down on it as well.

And that'll give you a whole new set of data or more complimentary data, a different collection.

And so that's why I think it's really, really good to be able to see that and understand what it implies.

It basically says, if you're not sure, act some more.


SPEAKER_01:
How could I disagree with Acton for a surf?

Let's just look at this slide then, Stephen.

So this functional, the flow over the four kinds of states that is using this blanket partitioning paradigm can be expressed in several forms.

Expected energy,

E, big E is expectation.

Expected energy minus the entropy of the variational distribution.

Remember the Q variational distribution is like the one that we get to control.

Q of mu, that's the Q of internal states, which is equivalent to the self-information

fancy I, plus the KL divergence between the variational and conditional density.

That's this KL divergence term, which is always greater than zero.

So self-surprisal is always zero or greater.

You can't have negative surprisal.

And then the divergence is always gonna be positive as well.

This can be decomposed into accuracy and complexity.

So that's this third framing.

And in that setting,

Negative free energy becomes the evidence lower bound or ELBO, which will be familiar to many people with machine learning backgrounds.

Okay, amazing.

So those are the three different formalisms and how they fell out.

This is the basis of the free energy principle.

Wait, what's the free energy principle?

Put simply, it means that the expected internal states of a particular partition at non-equilibrium steady state can be cast as encoding conditional or Bayesian beliefs about external states.

That's the free energy principle in this paper, not the first and not the last way it'll be defined and not the only, but that's how they discuss it here.

And basically we moved from early on, it's like tying our shoe with the density to dynamics side.

And now we have this whole universe of formalisms that connect

free energy looking formalisms like chemistry with information theory formalisms.

So thermochemistry with energy and entropy with thermo information, divergence and self-information to information and inference with accuracy minus complexity as a modeling heuristic.

So that's big.

Re-energy is big.

And then they immediately go to talk about physiological perspectives and how that surprisal function that constitutes the potential is log model evidence.

So if you're getting good evidence for your physiological model, you're spending a lot of times in your preferred and expected physiological states.

Stephen?

Stephen?


SPEAKER_05:
amazing this this really ties into the active inference paradigm shift because okay traditionally if we're going to have represented like traditionally representationism for instance like you were saying it does really really um throw that out in a way because if i have 100 cameras normally

and I took 100 different cameras all taking a photo, it's going to make it 100 times more blurry in that sense.

However, in this sense, 100 sources in this noisy dynamical gives me 100 ways to integrate free energy reduction

And even actually the noise of me moving it a hundred ways by a hundred cameras gives me more and more informational thermodynamic ways in.

So that just shifts very much the way we might think about how to know about how to act in the world.


SPEAKER_01:
Cool.

Let's continue on and we'll probably do a few minutes after the hour to get to these last few points.

So

we've been talking about different ways that we can talk about the free energy functional of the particular states 5.1 is where this idea of the internal states as a generative model and self-evidencing or like the minimization of self-surprise

is really leaned into so the alternative and deflationary perspective rests on noting that the free energy gradients are also the gradients of self-information so it's like the free energy itself is a wind that's difficult to latch on to so the free energy bowl the one where you'd be doing strictly as well as you could if you were on the bottom of it

we're not on that bowl.

But the one that we can be keenly aware of is our self-surprisal.

So if the self-surprisal gradient is aligned with the free energy gradients, then reducing our uncertainty about sensory states incoming helps us on the way towards minimizing free energy gradients, reducing that difference.

The organism wants to be minimally surprised about expected and preferred observations.

And those are the perceptions or measurements.

More technically, it wants to be minimally surprised about expected states.

And then preferences are going to play a key role when we talk about active systems that do resist dissipation.

This is where the moth to the flame comes.

And I just, I love this plot arc from 2006.

Ice Queen Fristin with the winged snowflake.

And then, you know, things are heating up for Act Dymph.

Others are being drawn like a chaotic moth to the flame.

They come close, but then it burns.

And then they fly away.


SPEAKER_02:
Oh, dear.


SPEAKER_01:
So one could imagine these kinds of systems to be like stochastic chaos.

And that could be, now again, we're thinking about, previously the Lorenz system was like maybe a particle in a chaotic weather system.

So that was like the weather systems that Lorenz was studying.

But now we're gonna be thinking about particular states, like a particular moth, that's able to not just have outgoing statistical dependencies,

but to do policy selection.

So this is where we actually get adaptive active inference.

And again, if there's two kinds of moths, some of them are just particles and then they get burnt when they get burnt and they don't when they don't, some will survive and some won't.

But the ones that do enact effective policy selection

are going to be persistent even a day later so then the lepidoptera have been around for millions of years so is it really any surprise that the moths have adaptive behavioral systems but that when the niche changes like with electric nighttime lighting that that doesn't entail that it's going to instantly be the adaptive system for that new niche

We can think about the motion of a moth attracted towards a flame, but constantly thwarted by turbulent or solenoidal air currents.

Because active states influence sensory states and possibly external states, this would look as if the particle, the moth, was trying to attain its most likely state in the face of random fluctuations and solenoidal dynamics.

So it's like, there's those arrows, the irrotational component are like converging the moth to the flame, but then like overshoot and the windy room are blowing it around.

And so again, there's the moth in the room and we could look at it in the X, Y, and the Z. And if the candle were in the center of the room, it would be like a bowl

that the moth were converging towards for any two dimensions that you looked at and indeed all three dimensions when considered together.

And the movement of that particle, the dynamics of that particle would be related to something about the flow of the air in that room with a pullback attractor.

This perspective emphasizes the active part of self-evidencing, sometimes referred to as active inference.

So we were calculating the potential, the self-surprisal, the outgoing dependencies for particles before we talked about policy selection.

And that is showing mere active inference as it's called.

But then when you think about the real world where only the anti-dissipative systems persist and the successful ones even more so, that's where policy selection comes in to play.

And that's actually where this paper ends.

They basically just bring it to that point

and say all systems are gonna be able to be framed within this way, again, not the territories, all of the approximations that we make will have these attributes.

And then we can imagine that there are some systems where the internal states are not just acting as if they're doing conditional expectations on external states, but then they take those conditional expectations, like about the weather, and then there's another node for policy selection, like the other pie,

policy selection in the models we've seen.

And then that pie can be like put on the jacket or not.

Those are like the two affordances or those are the two states in the affordance variable.

And then in a dissipative world, you're going to see adaptive agents as the ones that are able to recurrently adapt to changing and chaotic circumstance to repeatedly come back to that candle.

And so just to summarize, then we'll just, if there's any implications we want to touch, but we'll summarize.

They constructed a Laplacian system that's quadratic, aka bowl-like, in its potential function and flow operators, state-dependent flow operators, by the way, that includes the housekeeping function.

that evinces, so provides evidence for stochastic chaos because it has that Lyapunov exponent that was very similar to the ones that were calculated from the non-Laplace assumptions or approximations.

The way that the polynomial approximation played out with the first and second order approximations gave a sparsity which can be interpreted as conditional independencies

and a partitioning into four kinds of states.

Coupled systems have a conditional synchronization map.

In this example, it had a linear form.

They were on that manifold that was like Y equals X.

And this is important because in these Laplacian coupled systems, the conditional synchronization map is necessarily diffeomorphic.

Again, would be awesome if somebody wanted to come on and like help us see what the technical implications of the diffeomorphism is.

But...

The simplest level is like, it doesn't bend back on itself.

So it's a good function.

So that means for every sensory state, there's a unique expected internal state and conditional density over external states.

So it'd be like, yeah, when the thermometer says like 20, it could be 20 or 50.

that's not a very helpful thermometer now if you say the thermometer always reads half of the temperature or it's always double or it's a little noisy those are all workable but like the thermometer could just totally be deceiving you and then it just is a it's a wacky world with what the thermometer says not going to be a very adaptive system the resulting formulation can be read as bayesian mechanics

in which internal states on average parameterize belief of a Bayesian sort about external states.

Just like these equations when applied to particles and statistical distributions were a statistical mechanics, we're taking the full Bayesian insight and reading these equivalencies and formalisms as a Bayesian mechanics.

So that's the summary of 5.2.

And then there's a few implications that they get into, but we'll first have any questions.

So Dean, then Steven.


SPEAKER_03:
Well, I just think it's fascinating that it doesn't matter whether we're talking moths or people, we're kind of blissfully unaware of the statistical manifold

floating around us prior to us being pulled back to that flame and either becoming the hero moth or the fool moth.

We don't discover that until afterwards, but if we could be aware of the kind of the statistical distribution in play prior to us being pulled, it might help.

I don't think it determines much, but it certainly enlightens as opposed to being lit up.


SPEAKER_01:
Yeah, and the moth example, I think, well, you know, but if it really reaches the flame, it dies.

So maybe that's not even the final perfect example for how attractors work.

That'd be like a bowl with a hole at the bottom.

So again, it's just, it's a heuristic.

It helps us think about the kinds of systems that we're talking about.

But realism interpretation asides, even that example doesn't capture the whole thing because it's a metaphor, because it's like map of map of territory.

So it's totally chill.

Steven?


SPEAKER_05:
Yeah, the evinces, stochastic chaos, which wasn't a word I'd heard of before, to be honest, is this idea of equality.

So that's really useful, how it gives a sense of how both there can be chaos in the attractor and the noise maintained, at least at some level,

throughout because in most cases, the noise is just averaged away in other scenarios.

So this piece where we're tapping into that quality is really interesting.

And then that then tying into the Bayesian mechanics all the way down is very, very useful, especially when I think the Bayesian mechanics, as I've mentioned before,

is stacked it's like it's not saying this is where everything is different to evidence in it's like like we're going to give better evidence which or better evidence which make us think we're going to show a more accurate Lorenz attractor solution no it's

evinces and we can stack up and add these fuzzy qualities together and we'll still have a fuzzy quality but maybe we'll have one which is a little bit more practical and that's the game in town here is practicality so i like that cool also um it does average out noise


SPEAKER_01:
the internal states on average, the expectation parameterizes beliefs.

And so that's going to be a major challenge is to go from these expectation and mean field approximations without going into ergodicity.

That is literally the whole challenge.

The Laplacian is like a quadratic that's fit on another distribution, which we're not even caring to learn the form of.

And so we could say that the expectation, the single number expectation, the expectation of a child in that class is five feet tall, but maybe it's all four and six feet.

But if we fit Laplacian on that, it's gonna be at five looking like a quadratic.

So the map and the territory are not the same, and it is a significant challenge across domains to connect some of the approximations

that are double-edged swords.

Like let's approximate over a bunch of possible futures, or let's approximate this way.

Like there's no free lunch.

So the internal states on average parameterize beliefs, but does any given internal state parameterize beliefs?

Evolution kind of helps us out by saying like, well, on average, it's gonna get better and better.

That's like the fundamental theorem of natural selection, FTNS.

And then the ones that don't do as well, they die.

So evolution in a way helps us get out of this, but the formalism doesn't have that as we saw it right now.

Yeah, Steven on that.


SPEAKER_05:
That's a really good point.

And so it also does tie into the... So it gives a way to sort of the word average, but to average or approximate these faster perturbations, yet it still maintains perturbations, which could be used at the next nested level or in other ways.

So there's an interesting thing about it's reducing and...

the overwhelming noise

yet it's also not doing what traditional statistical averaging does, which is basically crash everything down to, you know, a fixed point.

It gives this ability for it still to be alive in a way.


SPEAKER_01:
Absolutely.

Like if we just took the expectation, the single average point of the Lorenz attractor itself, it would just be one point in the middle of the saddle.

Okay, but we have something that still has a dynamical nature with a tractable approximation and the dynamics have a positively operative exponent.

So we didn't squash the system down to a point or a racetrack.

We kept some of the dynamical and even chaotic aspects of the system

while still being able to talk about things on average.

But we're not talking about the average position of the particle.

Yeah, Stephen, quickly on that.


SPEAKER_05:
Yeah, I think that's a good point.

And also, just one thing that caught my mind is with that butterfly, with the moth going to the flame, is it talks about a perspective that's been taken.

And this is probably useful when people are thinking in the applied active inference.

This is the perspective that we're having.

And it's possibly more used, the word perspective, because we see a picture of a moth.

If there was no picture there, we might say a description.

of the scenario okay so there's this perspective on the moth yet the moth isn't necessarily in this scenario taking a perspective it's doing it's it's doing its mothness


SPEAKER_01:
Yep, it's definitely moths gonna moth.

Although the picture was not in the paper, I added that one.

But the winged snowflake was indeed in the 2006 paper.

So let's just recap a few of the domains of implication and then we'll close because like, what a fun pape and discussion.

So one, implication.

but also sort of note of caution, is that just because we took the OG complex system Lorenz and coupled it, so two chess moves beyond some sort of simple scenario, it doesn't mean that a synchronization map exists, let alone a good one for any given system.

But

One of the implications of this paper was that now we know that for a non-zero subset of dynamical systems, a non-zero subset of chaotic dynamical systems, and a non-zero subset of dynamical chaotic coupled systems, we can get this well-behaved approximation map.

So not to say all, but we know that the answer is now not none.

So that's a key implication.

Another implication was to really start to bring in the variational free energy in terms of generalized synchrony.

That's what opens up to the DaCosta discrete state space synthesis active inference, Bayesian surprise, optimal Bayesian design, intrinsic motivation, InfoMax, risk-sensitive policies, KL control, Occam's principle, decision theory, utility theory, Max-Ent, constructal theory.

this is not all in this paper so a lot more has to be done to get to some of these places especially in such a uh reasoned and bottom-up way um another implication of the paper is that they

took the Helmholtz decomposition in a new way.

And it might provide a generic model for random dynamical systems.

Importantly, because we connected it so closely to Bayesian generative modeling, it could be possible to do less just like, let's do descriptive analytics on flow to like, let's have a map that we can run both ways, where we're updating the parameters of our flow map

with what we're observing, but then we can also generate data sets.

We can generate counterfactuals.

And so that is what allows sparse data sets to play into Active Infant FEP and ties us more closely to modern machine learning like variational autoencoders.

Another implication or next step would be like we were looking at a three-dimensional system, the X, Y, and Z of the Lorenz attractor.

but how could we approach high dimensional dynamical systems?

So attractors in 50 dimensions, that's a little bit different and hard to solve.

So they suggest that a way to approach this, probably hint, hint, cough, cough, wink, wink, et cetera, is to learn the state dependent flow operator and the Ness using deep neural networks.

So it's kind of like you have a neural network now that recognizes bulls.

And so we're still kind of keeping some of the same things that we had a intuitive interpretation of in lower dimensions.

It's just like, you go like, okay, I know about the cube.

And then someone says, well, there's like an 11 dimensional cube.

And you go, okay, I kind of know what, I don't really see exactly what that means, but I kind of see what is being discussed.

How are we going to compute on the 11 dimensional cube though?

Well, neural networks.

And that is actually very close to neural stochastic differential equations.

And I think this is super exciting.

One could, ergo hasn't been done, probably, hint, hint, use a separate feed forward neural network to parameterize different components of the flow operator and self-information.

So in other words, we're taking what we talked about here

And we can think about combining it with the types of stochastic differential equations, neural stochastic differential equations and Bayesian neural networks, all of these advances in machine learning.

And now we're actually coming back to the table with new architectures for deep learning, because this would be a deep learning model.

It would have a deep neural network.

You would benefit from having a GPU,

but it's an architecture that was inspired by the discussions that we had here and then just the final implications and then we'll just have a little closing um the flows across the boundary also notice that a little bit of the blanket starting to potentially be inched away from talking more about a markov boundary

And connecting the FEP to the constructal law and the work of Professor Adrian Bajon, who honestly is a lot like Friston in some ways, and a really gracious person and communicator as well, with a long career of working towards this kind of a unifying structure.

flow theory to get towards the evolution of design in nature and as the image shows like kind of like from floodplains to lung alveoli that similar kind of a unifying model and then a final set of implications

is that we take covariances all the time from time series that's like how we do crypto trading that's how we do weather prediction that's all kinds of systems take covariance matrices on time series and so potentially because the hessian is recapitulating elements of the covariance matrix it could be possible to have an empirical data set

and empirically take the covariance and then learn something about the Hessian, the curvature of the underlying flow states.

So in other words, if you use the Laplacian approximation, even if it's stochastic, chaotic, and dynamic, that empirical covariance could identify conditional independencies where there's a zero.

And so in principle,

you could furnish a description of expected flow and the Lyapunov exponents to establish whether the system was chaotic or not, because we found that the Hessian approximation gave us a Lyapunov estimate that was like the actual Lyapunov exponent in the Lorenz system.

So we could go from empirical covariances, which people do literally every day, C, O, V, open parentheses and R, empirical covariances,

two estimated Hessians, two estimates of things like the Lyapunov exponents.

And that's why people often study chaotic systems in the super toy models, like the double pendulum and Lorenz, because it turns out it's shockingly hard to find chaotic systems in nature outside of those toy examples, because the real noise in the system swamps your signal.

And so in conclusion, having a simple functional form for the flow of random dynamical systems may be useful for modeling and analyzing time series generated by real world processes that are far from equilibrium and may or may not be chaotic.

And so that's the closing question.

Human flow, physical flow, supply chains, information flow, narrative flow, semantic flow, ants bringing seeds in and taking the mid and out, all of these flows

we have data sets for them.

And now we have a new kind of model that we can use to model those flows.

So we'll just chill and talk for a few more minutes, but what a great discussion.

So thanks a lot, Dean and Stephen and everybody else who participated in 32.

So Stephen first.


SPEAKER_05:
Deep breath.

Yeah, there was a couple of things there that seems to have a big impact because

As well as Markovian monism and the idea that active inference brings in this partitioning and the active inference field, which can then also have relationships to deep learning and how predictive processing is thought about, what's being said here that there's also evincing or evince, the idea of the evince and statistic chaos itself

also being a paradigm, paradigmatic part of evidence being arrived at.

So which in some ways is not dependent purely on Markovian monism being the overarching game in town.

So that is quite an interesting additional way for

deep learning to be um to be impacted by is this a field of practice is it a domain i don't know what we call it but that that that does it does it does make everything does it doesn't mean it's all markovian monism in terms of the ability to then infer you've also got this other um ability to get

information and from what you're saying it almost as much by inferring if there is chaotic presence or if there's not maybe not having maybe going and seeing if there's not chaos present may give an idea of there's maybe no correlations present and that's that's jumping the gun but you know maybe there's other ways of being able to interrogate statistical dependencies in time series analysis

that can be sitting alongside the Markovian monism.


SPEAKER_01:
So how that's connected to Markovian monism is definitely a good question, but yes, these are general tools for complex systems analysis.

So I hope people don't read this paper as like frist in apologetics or some sort of fringe development in ACT-INF only.

It's pretty clear from the nouns that we used that this is actually like a fundamental contribution towards analyzing dynamical, stochastic, chaotic systems.

However, just because you find, for example, a low lyopinib exponent of your approximation, it's not a statement about the system.

So we will always be able to just halt right there.

You know, it's not that it's not a chaotic system.

Your approximation doesn't have a chaotic leading lyopinib exponent.

So say what you want to say about your map.

And now if your map isn't chaotic and you're doing a great job,

predicting, explaining, controlling, designing, creating.

Wonderful.

I hope the business is successful and that you can have friendship and health and all those things.

But that's not a claim about the territory.

And so there's going to be so many fun ways to talk and explore that.

Dean, what are your closing thoughts?


SPEAKER_03:
Just real quick.

I think what the covariation piece, which is basically statistics and an abstraction to sort of explain things, points out is that if we can understand the world as being both within, enveloped, and between, partitioned, at the same time, that's a good fundamental place to start.

And I completely agree with your last statement.

We're not...

We're not counting fairies on pins and then just leaving it there.

We're actually hoping at some point to be able to turn this into something useful and functional.

But if you can't start from a place of seeing it as two things at once, within and between, you're going to struggle.

You're going to tend to collapse prematurely and you're not going to get very creative and active inference will

Well, you'll be able to define it and describe it, but I'm not sure how much new information you'll be able to derive with it, unless you can hold up both at once.

It's within in between.


SPEAKER_01:
Great.

There's so much more that we all have to learn, the appendices, the formalisms we didn't go into, the citations, other perspectives.

you know, it's just the beginning.

And that's what dot two is about.

Like how far we've come, you know, when we can go back to our roadmap and just be like, wait, dynamical systems and densities.

And then we're, you know,

300 miles past there but where have we gotten and so it's like just really exciting and i'm glad that we're doing it in a participatory way because um there's a lot to it so dean and steven thank you again everybody watching live and replay hope that you get involved and stay involved with act and flap see you later bye