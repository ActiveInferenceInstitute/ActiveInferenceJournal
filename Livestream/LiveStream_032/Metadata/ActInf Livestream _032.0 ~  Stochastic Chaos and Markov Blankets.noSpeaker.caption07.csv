"Speaker Name","Start Time","End Time","Transcript"
"Unknown","00;00;07;27","00;01;10;04","Hello and welcome everyone to act in flab live stream number 32.0 at the actin flab. The paper were discussing is going to be stochastic chaos and Markoff blankets. And it's November 7th, 2021. Let's play our theme welcome to the Active Lab, everyone. We are a participatory online lab that is communicating, learning and practicing applied active inference. You can find us at the links on this page."
"Unknown","00;01;11;00","00;01;33;15","This is a recorded and an archive live stream, so please provide us with feedback. So that we can improve on our work. All backgrounds and perspectives are welcome here and we'll be following video etiquette for live streams this short link you can see our past and upcoming live streams. And here on the main tab, the live stream calendar for 2021."
"Unknown","00;01;34;02","00;01;57;21","We're here in early November we had our fourth quarterly lab roundtable summarizing the kinds of projects that you can get involved in and what we had done in the previous year, what we're looking forward to next year and then the first two weeks of discussion are going to be on November 9th and 16th for this paper that will be discussed tonight in extreme number 33."
"Unknown","00;01;57;21","00;02;28;01","We'll have Abel's paper thinking like a state and we haven't set the papers yet for 34 and 35 the goal of 32.0 is to learn and discuss this paper. Stochastic Chaos and Markoff's Blankets 2021 by Carl First and Connor Hinds can also offer Lancelot to Costa and Thomas part. And just like all the dot zeros, this is just an introduction to some of the ideas."
"Unknown","00;02;28;01","00;02;50;27","It's not a review or a final word, and especially if you have any experience or you want to learn more about any of these areas and help improve our presentation or understanding of that, they'll be very helpful. You can join a live stream or just come get involved in some of the aspects of the lab because these are things that we want to understand, but also there's a lot to learn."
"Unknown","00;02;51;26","00;03;26;10","And in the coming two weeks, we're going to discuss this paper so I'm Daniel and I'm in California. The big questions of this paper are related to the general discussion in the active inference and free energy principle, literature and beyond. What is a good model of thickness in a chaotic dynamic and disappeared of world? So do we think of things as as they are in the snapshot, or do we have to think of them through time at what spatial or temporal scale or with what kind of measuring stick?"
"Unknown","00;03;26;19","00;03;58;00","Does it make sense to talk about things? And then how does the result of that first question, this model or approach to thickness speak to system sentience, which is going to be a word that is used in this paper. And notably, this is not being defined in terms of feeling like experiencing. It's defined in the paper as where internal states look as if they're inferring external states so perhaps closer to what Dennett would call the intentional stance."
"Unknown","00;03;58;19","00;04;25;17","But this is sort of just pragmatism meets anti dissipated ism third point, what is a Markov blanket and how is one modeled and identified or defined? Statistically, this is going to be the technical bulk and contribution of the paper. So if anyone wants to learn more and help us present some of the technical details which we're going to go through in this lecture."
"Unknown","00;04;25;17","00;04;56;20","But total disclaimer, if it's not accurate or it's an incorrect generalization, a word that wasn't a keyword per se, but maybe is just a qualitative entry point, is this idea of flow. And here we have people flowing like a long time exposure in a subway station, and there's water flow, which has several aspects. The water itself is moving, but also there's the flow of energy there's information flow, and then there's this psychological concept of flow."
"Unknown","00;04;57;06","00;05;48;07","And so different aspects of these could be said to be flowing in different ways and people jump across these different areas. So wouldn't it be cool if there were a quantitative model that kind of incorporated some of what was meant by all these concepts, including a science of perhaps perception and cognition in action? So the big picture is how are we going to connect kind of physical flow models to potentially other kinds like macro systems and informational and even psychological or behavioral the paper is stochastic chaos and Markov like it's 20, 21 and two of the aims and claims of the paper of which there are definitely multiple."
"Unknown","00;05;48;07","00;06;11;16","So this is just a few of them. In this work, we attempt in end to end derivation of a miracle blanket, starting with a normal form of stochastic chaos and ending with a functional form of a synchronization map the second aim, or really a summary of the paper is we conclude with a discussion of the implications and generalizations of the following here."
"Unknown","00;06;11;18","00;06;47;01","Mystic. So not necessarily formal, but more like using empirical simulation or approximation proof of principle for understanding, simulating, and characterizing an elemental form of sentence in systems that self-organized to non equilibria. So that is where sentence comes in. And again, this isn't just saying that because we did some matrix math, we think it has phenomenological awareness. Sentence is going to be more like intentional stance it's resisting dissipation, perhaps it's acting strategically given the affordances in its niche."
"Unknown","00;06;48;19","00;07;19;04","So one really relevant paper for Stochastic Chaos and Markov Blankets is the paper Bayesian mechanics for stationary processes with multiple of the same authors and this one was put on archive on June 25th 20, 21. And then this one looks like it was received by the Journal at July 9th. 20, 21. So one question is like to what extent are these complementary?"
"Unknown","00;07;19;22","00;07;34;18","Are these requisite or are they somehow related to each other or are they to independent kind of dimensions of advance? There's some overlapping areas, but also there are some different areas. So that would be good to learn about."
"Unknown","00;07;37;00","00;08;16;29","Spheres. The key words of the paper were Bayesian thermodynamics, information, geometry, Variational Inference and Markov Blanket So let's go just one level deeper into the flow example. We have a lot of fields like math, physics, information computing, thermodynamics, geometry, a few other fields where there are models of physical flow. So everything from heat engines and heat flow to quantum and classical computation, clouds and everything else."
"Unknown","00;08;16;29","00;08;56;24","So this is an engineering experience and ontology and from multiple different areas of mathematical formalisms that sometimes map very closely to the real world or not. Then there's these again, flow models or process models for mental flow, for example, thinking about attentional allocation or informational processing. And the big idea which is proposed in first at all 2006, at least one phrasing of it and an image that gets referenced back many times is this idea of like a winged snowflake."
"Unknown","00;08;57;11","00;09;52;11","And so below the phase boundary, so above the temperature of melting ice, the droplets are unable to enact policy, so they simply fall from phase and then they become rain. But above the solid phase boundary, so below the freezing point of water, there are the snowflake structures. So there's an organization and then one can imagine that if this shape above the phase boundary is able to enact action on the environment first, if nothing other, then by chance you would find that there would be, for example, persistence of the most adaptive action policies so that is the exchange and the interfacing of active systems with their environments that precludes the phase transition."
"Unknown","00;09;52;11","00;10;24;27","So that's the winged snowflake example of early or first aid, and it will come back at the end in a pretty interesting way. So one of the first keywords is Bayesian. Here's Rev Bayes, and we've talked a lot about Bayesian things. So just to kind of pick a few new images, here's some overlapping between frequent ism here and Bayesian ism here and some of the overlaps so it's just kind of interesting to look at."
"Unknown","00;10;25;10","00;10;55;22","And what exactly does it mean for a theory or for statistics to be Bayesian explicit modeling of priors? And here's the sort of classic Bayes theorem, which just not going to go into right now. I'm sure there's awesome resources to learn more about Bayesian statistics and just sort of the way that it becomes meaningful is just embodied how we want to be able to bring our full knowledge to bear on scientific questions or any other kind of question."
"Unknown","00;10;56;03","00;11;09;25","We want to be able to integrate different kinds of data sets and have models that can be able to receive data as well as generate it. These things are all tractable in modern Bayesian frameworks."
"Unknown","00;11;12;25","00;11;45;14","Thermodynamics is the voting Wikipedia here branch of physics that deals with heat work and temperature and the relation to energy radiation and physical properties of matter. So there's the sort of thermodynamic patterns or laws and the way that they relate to statistical mechanics. So how the kind of jostling of molecules leads to the ideal gas law or kind of work capacity in temperature engines."
"Unknown","00;11;46;25","00;12;17;20","And then just looking around, there was kind of just some old ideas, some new ideas so this is something we've talked about before with decision making, but also it's how we think about chemical reactions in terms of the lower activation. Energy is the kinetic product that's like the one that is easily jostled to and then the one that has a higher activation energy is not favored to occur, but then it sometimes can be like a lower thermodynamic product."
"Unknown","00;12;17;29","00;12;51;21","So releasing more Delta G. And then if we're going to have some sort of an information thermo synthesis, what does Delta G Informationally look like? Like what is the informational imperative the title of the paper has Stochastic Chaos, so just found a few different citations on it. And it's an idea that has been going back since before to thousands."
"Unknown","00;12;52;00","00;13;27;24","So I don't know when the exact beginning was but it's been around. So that was just one question for the authors or for anyone who's knowledgeable about it. What is the scope of stochastic chaos and how? How do we think about the relative importance or meaning of solving one category of dynamic systems? So what is stochastic chaos? Stochastic subject to probabilistic variation in one way or another?"
"Unknown","00;13;27;24","00;13;56;06","And we'll kind of like look at multiple ways that that can come into the picture through sampling or approximation of an chaos, which is sensitivity to small changes, which is summarized at least in one way by the the opposite exponent which is a measure of how closely separated points either converge or diverge as a feature of the shape and a type of a matrices that describe the systems."
"Unknown","00;13;57;22","00;14;26;18","Another keyword was information geometry. So I'm definitely not the person to give a specific definition. It would be great to learn more from someone who could link this to the specific modern advances. So a few people who have emailed us, but John Beyers, who is a professor in the UC system, wrote on his site, which has a whole curriculum on information geometry."
"Unknown","00;14;27;15","00;15;04;22","Not that I've taken it, but heard it was good information geometry is the study of statistical manifolds, which are spaces where each point is a hypothesis about some state of affairs. This subject, usually considered a branch of statistics, has important applications to machine learning and somewhat unexpected connections to evolutionary biology. So this image, it just kind of was like, if these are dimensions of something abstract that projected down onto the graph paper is going to look like a triangle."
"Unknown","00;15;05;09","00;15;36;11","And then this shape, which maybe is kind of like a saddle shape or if the to distal parts are connected, it's like a tetrahedra in a way then that projected down from a specific angle is going to look like a right angled square, but from a different angle it would have a different profile. So the same tetrahedra rotated in different ways can project down into a different geometry."
"Unknown","00;15;37;02","00;15;51;03","So kind of interesting to think about that with information. And if you're measuring several axes of information, you have an informational tetrahedra as if it doesn't need to be saying that it is actually that way."
"Unknown","00;15;54;11","00;16;21;14","One of the other keywords was Variational Bayesian Inference, and this was from the slides of 26 and some also good blog posts that others have written. It was defined in this blog post by variational inference methods that consist consists in finding the best approximation of a distribution among a parameter sized family. So it's kind of like finding the best linear model for a dataset."
"Unknown","00;16;21;25","00;16;49;17","This is a way to fit more complex data and models, but it keeps it constrained within a family so that you're just tuning the knobs that, you know, interact in a good way versus all the possible degrees of freedom in modeling, which is basically infinite. And then two ways that Bayesian approaches can be deployed, many more than this."
"Unknown","00;16;49;17","00;17;19;14","Two, there's the sampling based approach or the Monte Carlo like gambling approach, which is like pointillism, where it kind of samples. And then this is the underlying distribution. You're kind of agnostic to it. If you run this properly and the underlying distribution has the right properties, you can sample something that's totally adequate for making good decisions. And then the alternate approach is kind of like the SVG approach, the variational inference."
"Unknown","00;17;19;14","00;17;51;11","You kind of have a library of cat or mammal subunit vectors, and then that vector set gets fit in a way that's more tractable than just this sort of endless sampling. Oh, what if there was a whole body and you just missed it? Type questions. However, if there was a whole body and your library or the family of functions you were trying to fit were only whole body, then I mean, you can have a mismatch there, just like you could fit any other model incorrectly."
"Unknown","00;17;53;00","00;18;49;05","So the Markov blanket is one of the terms that I think many people are curious about certainly ourselves included. And from number 14 last year or 14, we talked about this continuum slash development of the concept from the way it was phrased by Markov, by the way, we're still trying to figure out which one slash exactly which contribution the father and the son made towards the development in Perl 1988 in the textbook shown here and this is where computational methods start to come in and some of the pure math assumptions get deployed in real data sets."
"Unknown","00;18;49;17","00;19;24;24","So then the Markov blanket is defined as the set in a Bayesian graph of insulating nodes. So moving from this matrix representation towards this graphical Bayesian representation and then there's some of the developments by Carl Fish and others which this paper is part of that do a few different things relating to connecting or separating the blanketing states into incoming sensory and outgoing action."
"Unknown","00;19;25;11","00;20;04;05","So partitioning of the blanket as well as implementing some of these components of principle of least action, which is not implicit in just mere statistical installation on a Bayesian graph. So we'll talk about some of that stuff. But I think there's enough to cover in what this paper here adds and number 14, number 20, number 26, many other papers that we've discussed and many that we haven't had very insightful uses as well as criticisms of Markov concept so what is the free energy principle?"
"Unknown","00;20;04;07","00;20;27;14","This keyword? One way to answer it, since it's the key word in many papers, what are three possible attentional regimes that you might be able to expect will reduce your uncertainty about this question, because if you're not worried about this question, it's all good, then but if you are, you want to reduce your uncertainty. So what are the actions to reduce your uncertainty?"
"Unknown","00;20;28;15","00;20;54;02","Well, the third sentence of this paper that we're discussing here is in brief, the free energy principle is a variational principle of stationary action apply to a particular partition of states where this partition rests upon conditional in dependencies, which is the other side of the coin of which which things influence each other and which don't kind of two sides of the coin there."
"Unknown","00;20;55;26","00;21;23;03","There's then a link to citation 15. So citation 15 if you want to go one more layer into establishing whether this is a emeritus claim or not. There's first in 2019 monograph free energy principle for a particular physics particular being specific but also referring to particular or autonomous states as they're known and also much discussion has occurred since this paper."
"Unknown","00;21;23;03","00;21;52;22","So look forward to seeing how it develops. And then a third possible attention or regime would be to come participate and contribute with Active Lab because every day we are reducing our uncertainty about terms as well as any participant can attest. And we're always trying to improve our informational niche through projects like educational courses and ontology development so that the questions that people ask every day, like what is the mark of a blanket?"
"Unknown","00;21;52;22","00;22;21;07","Why does it matter? What is the FSP, why does it matter? There will be awesome resources to share about those questions. One other piece before we jump into the paper is just a little bit of matrix math vocabulary. So I hope that I'm just even quoting the definitions correctly because I'm not super familiar with a lot of these distinctions and would think that there's a lot more expertize that people could share, which would be awesome."
"Unknown","00;22;21;17","00;22;43;29","So the Jacobian matrix and the determinant is a construct in vector calculus and what's relevant here is that it's the matrix of the first order, partial derivatives. So if you have just like a lump in space, you can take the partial derivative. It's like putting a ruler and finding the derivative of a certain axis of a certain variable at that spot."
"Unknown","00;22;44;15","00;23;28;24","And so you can find the partial derivatives of higher order models. The hessian matrix is defined as the square matrix of second order, partial derivatives of a function or field. It describes the local curvature of the function of many variables. So same idea. It's like how the linear slope and then also the curvature. So that can tell you a lot in especially a certain case that's going to come into play in how this paper defines its analysis approach, specifically the Laplacian approximation so the abstract."
"Unknown","00;23;29;22","00;24;13;14","In this treatment of random dynamical systems, we consider the existence and identification of conditional independence is non equilibrium steady state. These independence is underwrite a particular partition of states in which internal states are statistically secluded from external states by blanket states. The existence of such partitions has interesting implications for the information geometry of internal states in brief, this geometry can be read as a physics of sentiments where internal states look as if they are inferring external states however, the existence of such partitions and the functional form of the underlying densities have yet to be established."
"Unknown","00;24;19;11","00;24;57;06","Here, using the Laurens system as the basis of stochastic chaos, we leverage the Helmholtz decomposition and polynomial expansions parameter eyes the steady state density in terms of surprise or self information. We then show how Markov blankets can be identified using the accompanying Hessian to characterize the coupling between internal and external states in terms of a generalized synchrony or synchronization of chaos, we conclude by suggesting that this kind of synchronization may provide a mathematical basis for an elemental form of autonomous or active sentence in biology."
"Unknown","00;24;59;11","00;25;40;21","OK, cool. How will that happen? Here's the roadmap the first section is the introduction. The second section from dynamics to densities makes the connection between dynamical models and densities, which takes one towards flow. Like if you have water in the ocean of different temperature and densities, you can do the flow modeling. Section three is the Helmholtz decomposition, which we've also revisited elsewhere, and it relates to splitting apart a vector field into two components."
"Unknown","00;25;41;01","00;26;19;03","One that's kind of like hill climbing and one that's more like curvature the Lorentz system, a classic complexity model, is brought up and used as an initial case for this kind of dynamics, two densities, plus Helmholtz decomposition then some further Lorenz systems other than the Lorenz are analyzed, then the Laplace and systems other than Laplace are analyzed, searching for Markov blankets."
"Unknown","00;26;19;03","00;27;08;03","And the free energy principle talks about sparsely coupled systems and specifically where the different partitions are engaging in some type of synchrony, which is going to be like correlated action conditioned upon the blanketing states. That leads to a discussion of particular partitions, boundaries and blankets, and a kind of revisiting using a simulation analysis of Markov blankets. The last section is about the free energy principle and mentions active inference so it's pretty interesting just to start with the data availability statement, they wrote that the code used to run the simulations and create the figures for the paper are freely available in the DSM toolbox."
"Unknown","00;27;08;03","00;27;45;22","Of the MATLAB package. SPM 12. So if anyone maybe wants to like do SPM live with us, that who knows how to do it, that'd be awesome. SPM stream, it'd be great. So let's start with the introduction slowly because there's going to be some more technical parts later. The last sentence of the first paragraph of introduction is from this one can elaborate a physics of sentence or Bayesian mechanics that would be recognized in theoretical neuroscience in biology."
"Unknown","00;27;46;07","00;28;10;00","So imagine if the top half were redacted. What do you think would allow for, quote, the elaboration of a physics of sentence or a Bayesian mechanics? So not possible or it's already been done. Who did it or well, it would have to have this attribute. It has to be able to run on this type of computer or it have to have this many variables or fewer."
"Unknown","00;28;10;00","00;28;40;20","So what are we looking for here? What would justify this sentence that they start the paper with, and why would it matter? Which is kind of tied up with maybe what would be the motivation for developing it, however much effort it involved? Why would it matter to have a physics of sentence? Well, why did it matter to have a physics of heat let's pull back one more sentence."
"Unknown","00;28;42;24","00;29;09;01","The internal states can then be cast as representing in a probabilistic fashion, external states. So that's what they're going to elaborate a physics of sentence on from this partitioning of internal and external states, but not just any partitioning, a particular partitioning where internal states can be cast as representing external states. So this is kind of a minimal representation."
"Unknown","00;29;09;01","00;29;34;18","We have internal and external states, and we're not going to define them as even action or sense partitions in the blanket yet just there's some partition between internal and external states. And the question is, is this how you think the world is partitioned or how our statistical models are partitioned? What is this partition? And we've talked about that in a few different papers, and that's going to be a big part of this paper."
"Unknown","00;29;36;16","00;30;04;11","Then we can pull back one more sentences in the abstract framing in this first paragraph where they define the free energy principle, which were which we read previously, and then specifically if the states of a system whose dynamics can be described with random or stochastic differential equation, e.g. an equation, possess a Markov blanket, then an interesting interpretation of their dynamics emerges."
"Unknown","00;30;04;28","00;30;32;19","The conditional independence in question means that a set of internal states are independent of another external states, another external set when conditioned upon blanket states. And so that is the blue. Here is the precondition for the read claim which is going to be what is the basis for, in the author's words, elaborating a physics or sentence. So that is kind of where we're going in this paper."
"Unknown","00;30;33;16","00;30;59;23","Agree or disagree, there's going to be a lot of specific points where one can raise a qualm, and that's totally OK. And I think a lot of the discussion, I hope will be very interesting with people seeing which parts of this presentation resonate with them or their understanding or not. Those are the big questions. What kind of blankets line up with different parts, aspects or partitions of the world?"
"Unknown","00;31;00;09","00;31;32;01","Map is not the territory, etc. What makes some partitioning in the world? Act informationally like inferentially anticipatory predictively, et cetera. Why are some partitions able to be cpu's and other partitions are just divided halves of a cup of water how do partitioning of variables that model the world lead to a physics of sentence and action? Is there another way to get to a physics of sentence and action?"
"Unknown","00;31;32;15","00;32;02;21","Is there another way to do physics they describe their approach to part one by applying the Helmholtz decomposition, which we're going to return to. So this is just kind of a preamble and we'll talk more about some of the key words, but they're going to apply the Helmholtz decomposition to the solution of the Fokker Planck equation, describing the density dynamics of any random system."
"Unknown","00;32;03;28","00;32;36;24","Then later on, they're still summarizing part one and they're going to say We approximate the flow from the yellow part with a quadratic expansion, which means the steady state density reduces to a Gaussian form. So it's kind of like if you fit a quadratic model, A X squared plus B, X plus C to some data set, it's not a statement that the dataset is going to have a derivative that's linear and then a derivative of that."
"Unknown","00;32;36;24","00;33;17;11","That's a constant that's not part of the dataset of the world. That's about the quadratic model, which is a very constrained model set that you chose to fit and maybe other models would have fit it better. Other ones would have had more or fewer parameters, but you knew something about the form of the solution because you constrained it to a certain set of parameter arranged equations, which is why they talk about variational inference and then they're going to show that for a Lawrence system subject to appropriate random fluctuation, there's going to be this third state, which is independent of the first two states are dimensions."
"Unknown","00;33;17;24","00;33;49;17","And this means that the third state has no blanket states and therefore is not is no, there's no particular partition of interest so one question for anyone who maybe understands the formalism, just why does this claim specifically matter so section two, the aim of this section is to get from the specification of any of a random dynamical systems in terms of its equations of motion to the probability density over its states in the long term future from any initial conditions."
"Unknown","00;33;50;17","00;34;25;15","We are only interested in systems that have a limit set in other words, systems that possess in a tractor. We want to describe systems that do not necessarily visit. All possible states are not necessarily time reversible or stochastic in nature and potentially chaotic. In short, we are interested in stochastic chaos in systems with a pullback attractor. And then there's several citations from the nineties and maybe that some of the earlier models of it that's how they describe it."
"Unknown","00;34;25;26","00;34;59;04","And then they show this formalism where the length of the change in the state of X that's kind of like a derivative sign sometimes is equivalent to a flow. And then these faster fluctuations so kind of like a wave and a ripple, but that's going to describe the change overall of some location. And then that is Equivocally equivalent to the Focker plank density dynamics."
"Unknown","00;34;59;04","00;35;42;28","So they're the same thing. That's the equal sign. So that I can't say whether this is just a total tautology, super obvious, or whether this is a conclusion that was only more recently understood. That would be helpful to know, but that's one of the baseline equivalencies in the paper. It's going to be you can have a specification of a random dynamical system, like here's the set of equations that describe how this sensor is returning data and then turn it into a flow in a density estimation framework."
"Unknown","00;35;44;22","00;36;37;26","So the Focker Planck they write the product, the DOT notation indicates a partial temporal derivative in the absence of random fluctuations, i.e. gamma equals zero. The attractor corresponds to a limit set, namely the set of states onto which the solutions of one converge. So there's kind of like some steady state attractor, which is when there's a heat differential, like there's it's warmer outside, it's cooler inside and then there's some point where the thing gets zero when the flow shows exponential diversions of trajectories with positive, we often have accidents, i.e. real positive eigenvalues in the jacobian of the flow, the system can be said to be chaotic."
"Unknown","00;36;38;15","00;37;25;20","So there are systems that kind of converge nicely when they're pulled away a little bit. So let's just say that it stay the same temperature inside and outside in that previous example. Then that equilibrium would be like pretty nice because it would return to it if it slightly were moved away from it. But there's also systems where nearby points diverge, and that's a measure of this approximated by this lyapunov exponent and then the question is for systems that do have positive leading lyapunov vectors then what happens to those low models?"
"Unknown","00;37;26;22","00;37;59;21","And then what happens when there's a re-instating of the random fluctuations? How does that sort of system that would be chaotic if it were allowed to just somehow deterministically evolve? So it's like you're fitting the underlying model and it's a little noisy around it. And then you swap out the actual scattering of the real world populations of deer and rabbit for just the partial derivatives that you were estimating."
"Unknown","00;38;01;01","00;38;24;00","And then maybe you see that there's some bifurcation in the population density. But of course any real population is either going to experience one branch or the other of that bifurcation. So that's kind of the modeling that they're working on. And then when you go from that dynamical systems approximation to the flow, if the flow shows exponential divergence of trajectories, we can impute stochastic chaos."
"Unknown","00;38;25;29","00;39;01;29","So they take one of the classic systems of deterministic chaos, the and dynamical chaos, the Lorentz system, which is kind of a butterfly looking attractor and they first show the trajectory of Lauren's attractor with and without this reinstating of random fluctuations so we know that there's a divergence, lyapunov divergence that's making the system chaotic when there's no random fluctuations."
"Unknown","00;39;02;06","00;39;34;07","So what happens when that is reintroduced? The middle panels show the corresponding solutions in the three dimensional state space, illustrating the butterfly shape of the limit set. So even when the in the random attractor, so the deterministic one is the kind of clean butterfly and then the one with the random fluctuation, the points are outside of the butterfly."
"Unknown","00;39;34;07","00;40;01;13","It's a slightly different shape. But then it it still illustrates it's not a, you know, a, an X in the state space. So it's still is kind of following this, but just it's of course it's not following the exact tracks that it's on because there's a random fluctuation term but it still is going to have a certain geometry because this is a model and information geometry."
"Unknown","00;40;02;06","00;40;28;14","So that's going to get some transformations in approximations. Lower left panel plots, the fluctuations in the potential evaluated using the laplacian form. This is kind of formalism that is going to come later, but expresses the self information as an analytic function of the states and then the states I was not exactly sure why they were called states rather than dimensions."
"Unknown","00;40;28;23","00;41;02;25","So if anyone has a thought on that, that'd be interesting. And then the lower right is the potential function of the first two states basically, or dimensions is shown as an image with the trajectory superimposed. So this is kind of the if this smoothly varying global potential plot with a lighter and the darker representing different values. There's this like dynamical butterfly that's fit from the RI sampling of the true Lorenz all right."
"Unknown","00;41;02;25","00;41;30;21","So the key insight from Fig. one is that the underlying system, this is kind of key complexity insight that the underlying system can have very simple and defined rules, yet unpredictable dynamics. So in the case of dynamical equations, it's systems like the Lorenz attractor and many other systems that are just very simple and they only have a few parts yet they result in these very incredible and rich behavior."
"Unknown","00;41;31;06","00;42;01;14","And then there's also kind of like simple rules, complex outcomes, you know, ants and humans. So just a simple rule can be underlying something that's giving an extraordinarily complex pattern. And yet if we measure these systems empirically, that have some simple rules underlying them, but there's also this random fluctuation or we don't sample at all, there will be some, but not overwhelming noise."
"Unknown","00;42;01;23","00;42;33;07","There will still be dynamical patterns to pull out. So we can still reduce our uncertainty about the location of future points by using a statistical model that we defined that doesn't even have to be similar to the generative process. So if someone said, well, you get money for getting predictions closer to the actual position of the sampling, even if your model that you're fitting to it is like a neural network, or is this kind of model that we're going to discuss here rather than a differential equation, that's actually the true generative model."
"Unknown","00;42;33;24","00;43;12;13","You can still do better than just guessing within this cube. So Section three goes to the Helmholtz decomposition and they write. So that was the previous section was we can regard the deterministic Lorenz system as describing the expected flow of a random random dynamical system that is subject to random fluctuation. That was what we just talked about, the flow of such systems which possess a non equilibrium, steady state density, can be expressed using a generalization of the Helmholtz decomposition into this, a bit of which is zero ear rotational and curl free and conservative, which is rotational divergence."
"Unknown","00;43;12;13","00;43;53;02","Free components with the latter are referred to as solenoid or flow. For an introduction to the generalization of this, Helmholtz Decompositions see Appendix B of 16, which is basically mechanics stream number 26. So we're looking for where P dot. So the partials of P partial different derivatives a p are zero. So where is that flow equilibrium? Well, that is going to be a function F that has a few terms, including one that's I think introduced in this paper, the housekeeping function."
"Unknown","00;43;54;09","00;44;22;08","But it has two terms that are the classic Helmholtz decomposition, which is the solenoid or the tangential current. That's just the spire, the ISO contour and the gradient, which is kind of like the up and down. So that's how a total current, an electromagnetic gets decomposed. And it's related to kind of fundamental vector field math so let's go and uncover what was hidden by the square box."
"Unknown","00;44;22;26","00;44;50;01","So we have the Focker Planck steady state p of X equals zero, P of X is zero. There's some function that's going to be a decomposition of that into a solenoid and a gradient flow component, the Helmholtz decomposition and then this housekeeping term which is in independent in appendix, but it didn't go into in super depth so I'm curious about what that is, but it results in this whole flow term."
"Unknown","00;44;51;29","00;45;17;06","Here is the fancy I the is a fancy j the first deceptive part performs a remaining gram gradient descent on the negative logarithm of the steady state density, which can be interpreted as the self information, which is the negative natural log of P of any given state or as some potential function. So that's kind of like how surprising is that state?"
"Unknown","00;45;17;18","00;45;47;13","The second part of the flow is the sole idle circulation on the ISO contours of the steady state density. And then the third form is this housekeeping term that accounts for how changes in the flow operator change so it's an extension of the Helmholtz decomposition, thinking about how to solve dynamical equations. So this is from active takes the synchronization map and I'm not going to go into the whole thing because you can check out 26."
"Unknown","00;45;47;24","00;46;17;01","But the key question is about this Sigma this synchronization manifold between the internal and the external states conditioned on the blinkered states. So how do you insulate yet have anticipation across that installation and then also from 26, this is kind of what it looks like to see a stochastic trajectory decomposed into a gradient and a rotational component. All right."
"Unknown","00;46;17;12","00;46;50;22","3.1 our objective is to identify the functional forms form of the self information or potential function that describes the non equilibrium steady state density. So why that's how surprised you should be? That's the potential function. That's sort of the the fun, the fundamental frequency of both the solenoid and the gradient. So it's an important variable to know. But how is self information measured or calculated?"
"Unknown","00;46;51;10","00;47;20;19","How does the self information for different non equilibrium steady state or equilibrium steady states compare? What does it mean for self information to be high or low? So to be surprised or not, so first they in formalism for address this set of questions basically for one simple case which I'm not super familiar with the matrix math. So we'll leave it to others to evaluate some of the technical details."
"Unknown","00;47;21;22","00;47;50;27","So then the follow up. And so basically we could solve that easily without that correction term that arises when flow operators are a function of the states. Indeed it is the state dependency that underwrites stochastic chaos. So that's like the double pendulum. The reason why it's a chaotic system is because the states at the time depend on the previous time in a way that generates chaos."
"Unknown","00;47;51;24","00;48;14;00","So there's so much dependance over short term that things can diverge really fast this present, this presents us with a more difficult problem. The problem can be financed by using polynomial expansions of the flow operator and the potential as follows. For end states up to polynomial order m so they're going to use polynomial expansion approximation on a complex underlying flow."
"Unknown","00;48;14;05","00;48;46;11","Functional polynomial expansions restrict and scaffold our model selection approach to a manageable size and tractable computation. So it's kind of like the Taylor series and the Voltaire series and other polynomial expansions which can fit functions often that are very complex. Well, and so this is showing the Taylor approximation to a sine wave and showing how the first approximation gets you like between one and -1."
"Unknown","00;48;46;20","00;49;07;16","The red line might be totally more than enough, but with only a few more terms being added all of a sudden starts fitting really well further and further out. So that doesn't mean it can go forever but the polynomial expansions can be very powerful in the numerical case, like just doing good enough with quick and dirty as well as in the analytical case."
"Unknown","00;49;09;14","00;49;56;15","Here's a figure from SPM 27 textbook, which is a great textbook by the way, and it's talking about the Voltaire series as a general nonlinear input state output characterization system. So and B not have been a good note to you. Voltaire kernels are synonymous with affective connectivity and then they write this is from the SPM 12 so later than this but right up from the point of view of regression models modulatory effects can be modeled with nonlinear input output models and in particular the Volterra formulation described above because the kernels are high order, they embody interactions over time and among inputs and can be thought of as explicit measures of effective connectivity."
"Unknown","00;49;57;13","00;50;27;11","An important thing about the Volterra formulation is that it has a high face validity and biological plausibility. The only thing it assumes is that the response of a region is some analytic nonlinear function of the inputs over the recent past this function exists even for many complicated dynamical systems with many unobservable state variables. So cool why does it matter to do a polynomial expansion of the functional form of the solution to this flow problem?"
"Unknown","00;50;28;03","00;50;57;10","The parameters issued in five allows for state dependent changes in the amplitude of random fluctuations encoded by the leading diagonal of the flow operator. With that functional form of the polynomial it is straightforward to solve for polynomial coefficients. The flow operator by solving the following simultaneous equations for a series of sample points some of the key words that are from SPM and elsewhere that might come into play."
"Unknown","00;50;57;10","00;51;23;23","To learn more about these topics are expectation maximization optimization, parametric empirical base dynamical systems identification and generalized linearization schemes for fitting GLM to nonlinear systems and then something that's not as much in SPM, but comes into play later with active inference and hopefully we'll be able to demonstrate this in the literature as we sort of sift through it."
"Unknown","00;51;24;11","00;51;58;05","Is that action planning amidst uncertainty and feedback with the environment radically changes the nature of that kind of flow estimation problem. You can't use the same model necessarily for the leaf on the stream, something like the winged snowflake that's actively resisting. So how good is this approximation to use the polynomial expansion of the fitting of the random fluctuations of the rate of inevitable system that is chaotic."
"Unknown","00;51;58;28","00;52;31;11","Inspection of the Lorenz system suggests that a second order polynomial approximation is sufficient given the flow second order in the states this onslaughts. So vocab onslaughts an assumption about the form of an unknown function which is made in order to facilitate solution of an equation or other problem has an interesting implication. If the self information can be approximated with a second order polynomial, it means the non equilibrium steady state is approximately Gaussian."
"Unknown","00;52;31;26","00;53;10;10","This is known as the lip loss approximation in statistics here we generalized the notion of a plural Laplace approximation to cover not just the quadratic form of the log density, but also the sullen oil flow that underwrites non equilibrium dynamics. Big if true, it has to be. So here's the Helmholtz decomposition. So now we're taking that solution that we had earlier and thinking about it in terms of fitting only up to the second order polynomial expansion of the flow solution."
"Unknown","00;53;10;20","00;53;39;04","So that is, as I say, what is known as the lip gloss approximation in statistics and it's in a SPM textbook. Two. Here's the actual flow decomposition of the Laurens system the solenoid, all flows red, the gradient flows blue, and the correction term is gold. The flow is shown as a quiver plot at equally spaced points so it's kind of like the vectors of different direction at different points and then the rate is the same."
"Unknown","00;53;39;04","00;54;22;04","But for the laplacian based upon the one on the left here, the key difference is that the deceptive part of the flow operator and hessian are positive, definite indicators of inflation, which means the gradient flows converge to the maximum of the non equilibrium steady state density. This is reflected in the blue arrows that point to the center of the space so even though the gradient of the real flow is pointing all the different directions because it's kind of like a mixing flow, so there's all the vectors are going in different directions but then in the laplacian second order polynomial expansion, the blue arrows are all pointing to the center or to some manifold that's much"
"Unknown","00;54;22;04","00;54;50;16","more compact. So it's kind of like a converging solution, even though the actual system we defined it to have stochastic, chaotic properties. So here's SPM looking at the Lawrence tractor. Alas, poor Lorenz. I knew it. Horatio a model of infinite citations of most excellent fancy. It hath returned to the pull back a tractor a thousand times. And now how aboard in my imagination it is."
"Unknown","00;54;51;07","00;55;09;05","So that's modified from Hamlet. Because right after that seemingly very cool solution they say indeed the equations of motions we have written down are deterministic, implying that there is no stochastic city in the sample parts of the process."
"Unknown","00;55;11;29","00;55;32;20","Assuming a fixed initial condition. This speaks to the fact that Helmholtz decomposition of the deterministic Lawrence system is not a description of a dynamical system with random fluctuations, i.e. systems in which the discipline of part of the flow operator is positive definite. We therefore need to look beyond the Lauren's attractor, so that takes us to appropriately 3.34 beyond the Lawrence system."
"Unknown","00;55;32;21","00;56;06;10","So, OK, cool. Now, beyond the Lawrence system, we go to the chaotic Laplacian. So Fig. three, this is a trajectory, kind of like a pointillist trajectory of three states, kind of three dimensions comprising a laplacian approximation to a stochastic Lawrence system. So here it's second by third, first by third, first by second of the less density. So it's showing three projections like the GB cover onto a two dimensional and notice how the light is in the center."
"Unknown","00;56;06;20","00;56;35;21","So it's like they're getting pulled back to the peak of the Gaussian on each dimension so that's the non equilibrium steady state, which by construction in the Laplacian is a multivariate Gaussian. That's super key and extremely interesting the middle panels show the deterministic and stochastic solutions as a function of time, while the right panel plots the same trajectories and states bits."
"Unknown","00;56;36;09","00;57;10;22","The shape of the attractor retains a butterfly like form, but is clearly different from the Lauren's attractor. So what do you see when you look at this attractor? Be honest, but it has a butterfly like shape and the generated trajectory has some similarity with the underlying generator function, but it has such a nicer form to solve. And then the lower left is the self information, the potential as a function of time based upon the analytic form for the equations of motion and the deterministic trajectories of the previous panel."
"Unknown","00;57;11;25","00;57;51;04","And then the flow of the laplacian, which is the approximated expansion, nicely solvable, etc. against the Lorenz that's the true flow is evaluated at 64 spaced points. It can be seen that although there is a high correlation between the flow of the laplacian or around systems, they are not identical. So not super visible could have provided like an R squared or some other information, but clearly they are drawing from the same manifold so if this is good enough to stay alive, then society upper panels, does this focus on those?"
"Unknown","00;57;51;04","00;58;49;10","So this is again the projection onto two by three, one by three and one by two. Of three of this multivariate Gaussian, the plus in approximation, which makes it really nicely solvable. So one can then estimate the Lyapunov dimension which is approximating to how store, how store dimension, which in this example was 2.48. So the laplacian approximation was used to sample and then estimate the Lyapunov dimension and then it turns out that that compares very closely 2.43 and 2.48, which in the grand scale of things where above one means chaotic system it means that the Laplacian expansion has some of the nicely solvable characteristics of the generalized laplacian like the multivariate Gaussian and the easy"
"Unknown","00;58;49;10","00;59;20;08","computation. Yet it also identifies this system as chaotic because it still gives a positive we often the exponent from this sampling. In short, the flows of the LORAN system and its the plus approximation have an attractive set with between two and three dimensions for our purposes, the pass approximation is easier to handle than the Lawrence system because the functional forms of the flow and potential are immediately at hint so pretty interesting."
"Unknown","00;59;21;15","00;59;57;10","Figure four. So now this recalls our earlier discussion of the Jacobian and the Hessian. So let us recall the Jacobian is the first order partial derivatives, the hessian is the second order partial derivatives. OK, so we have the Jacobian, the Hessian and the covariance between these three dimensions. So the Lorenzo character was in three dimensions. OK, it was in state one, two, and three."
"Unknown","00;59;57;19","01;00;33;18","That's kind of why it's like thermodynamic states. So they are dimensions. So the learned structure was this like kind of, you know, ants flying around in space in three dimensions. So we fit a polynomial expansion specifically to those three dimensions, the measurements of them. Now for those three dimensions we can talk about their correlations in the first partial derivative and the second partial derivative and the covariance that's in the top here."
"Unknown","01;00;34;29","01;01;02;04","In this example, the third state is independent of the first pair where the independence rests on the directed coupling from the third to the first state. And so it's logged to show the scarcity. So do you see where we're going with the mark out blanket? See how this third state, not part of the Lauren's system, underlying differential questions, it's actually just a total figment of the Laplace approximation model."
"Unknown","01;01;03;00","01;01;36;11","But it's quite an interesting pattern the middle panel shows slices through the steady state density over the two states and increasing values of the remaining state so the only correlation in place between the first and second state. So this is related to sphere, a city error correction and evaluation. And it's a topic that is discussed in a SPM textbook but basically spherical errors are the ones where the two axes are not correlated."
"Unknown","01;01;36;11","01;02;04;24","But then when there's nonphysical errors, then there's you get a different shape. The lower panel, the correlation is illustrated in terms of the conditional density over the first state given the second. And so this is kind of showing that by and large it's doing well largely confined to the 90% credible intervals would be good to see some, you know, simulation statistics and raw data on it."
"Unknown","01;02;05;21","01;02;38;29","So again, alas, I knew him well. The preceding treatment leverages the simplicity of the low price approximation to stochastic chaos in which specific constraints on the Hessian are easy to identify or implement. Now, just like Lorenz was dropped, now this is going to be going beyond the applause system. So I'm going to go into too much detail here, but that's it with that's the section that people could explain more about."
"Unknown","01;02;38;29","01;03;01;14","Or we could look at more in the dot one, the dot two. So 3.5 summary. It is important to not conflate the simplicity of a mass density with the complexity of the underlying density dynamics. In other words, when prepared or observed in some initial state, the probability density can evolve in a complicated and itinerant fashion on various sub manifolds or the pull back attractor."
"Unknown","01;03;02;08","01;03;37;25","So the map is not the territory. That's something that has come up many times. The Laplacian is not the Lorenz, but the Laplacian is a good approximation to the Lorenz in their simulations. Fig. six So now the chaotic Laplacian system is it's kind of shown in a time series way where this is the true relationship between the first and the second state."
"Unknown","01;03;37;25","01;04;12;14","So let's go here. So we see the first and the second state here is like where there's this nonphysical error and so this is kind of like an interesting like coupling in the model that's independent of the random fluctuations. And so that represents something very deep about the structure of the Laplacian approximation to the Lorenz. Now, using the analysis in in a generative capacity, there's this initial mis attunement in there set up."
"Unknown","01;04;12;17","01;04;39;19","It starts somewhere far from the pull back attractor and then like the correlation evolves through time and then they say the density converges to the steady state density after about 16 seconds. However, it takes a rather circuitous route from this particular set of states. OK, so that's interesting. It starts with like there were different correlated because of they starting in a weird place and then they found their true correlation structure."
"Unknown","01;04;40;07","01;05;07;22","Note that the average density over short periods of time can be highly non Gaussian even though the density at any point is by construction Gaussian something to think about so then we get to finally mark all blankets so they repeat the analysis, but now they approximate to Lauren's systems that are coupled to each other through the respective first states."
"Unknown","01;05;08;02","01;05;34;15","So the first and the second states were coupled. So it's almost like one of our coupled states we're going to couple out now this induces a richer, conditional, independent structure from which one can identify internal and external states that are independent when conditioned upon blanket states. So what does it mean to sparsely couple systems and what are these quote first states, the first dimension FIG. seven."
"Unknown","01;05;34;15","01;06;13;16","So now there's generalized synchrony in a Laplacian system so this is now the same figure as FIG. three like this, except now we're looking at the generalized synchrony. So now there's a synchronization manifold in the first state. When those two got linked up so now there's more lines because there's like two coupled chaotic systems, but the middle is showing that they're state spaces are coupled and this is illustrating the degree of synchronization and then again showing that their flows are correlated."
"Unknown","01;06;13;24","01;06;48;07","Those starts figure eight now instead of having three by three in the matrix correlation and covariance in the first and the second derivatives now it's six by six. So here is now the identification of using the log of the Jacobian and the Hessian to identify different partitions so that partitioning between the one and the four between that first state of both is the one that we knew about."
"Unknown","01;06;48;07","01;07;28;21","That's like the one that was wired into the system. But then the other ones are showing other correlation patterns. Now for I don't know why this four and five connection is not included in the box, but these are the partitioning and so the specific structure of the covariance supports a particular partition into internal states. Five and six dark blue, active fourth state, the one that induces the one that connects here sensory first state and external second and third state."
"Unknown","01;07;29;07","01;08;04;16","This partition is illustrated here. And the remarkable thing is that despite their conditional independence, there are correlations between internal and external states and here between the second and fifth states so interesting patterns showing these evolving three time nine. So now they're going to look at the partial correlation of states and showing that the Hessian is recovered so here is like that hessian on the top, right?"
"Unknown","01;08;05;24","01;08;34;07","And then now they're going to show that it's recovered. It's a little bit light, but it's showing how these so so these squares are showing the partial correlation coefficients and hopefully pulling out the similar structure as identified here then like the strong correlation. Well, yeah, we'll investigate that more in the dot one, the dot two and then showing how like the third and the sixth state, for example."
"Unknown","01;08;34;18","01;09;05;24","So that's like three and six. They're not supposed to be coupled. And so then they initially start off with a high correlation because maybe they start in the same neighborhood, but then they converge towards a zero correlation so that is sparse coupling it does not depend upon Gaussian assumptions about the non equilibrium steady state density. It implies that the dynamical influence graphs with absent or directed edges admit a mark called blanket, which may or may not be empty."
"Unknown","01;09;06;13","01;09;31;22","These independent CS can be used to build a particular partition using following rules, capture the flag figure ten so here's where we see kind of the classic bacteria example. But now it's two bacteria communicating. I'm not sure if it was always that way. And then here is a little bit more of a coupled system, as with two times three, which is pretty interesting."
"Unknown","01;09;32;24","01;09;47;25","So here is where we see the mark all blanket as we've seen it before, but also in a new way. How great. Here's some technical definitions of the mark called Blanket. So not for tonight, but for another night."
"Unknown","01;09;49;26","01;10;19;01","So here's a question they ask themselves why? Why? One might ask, why does a particular partition comprise four sets of states? I don't know why is the tetrahedra the smallest polyhedra? Who knows? In other words, why does a particular partition consider two Markov boundaries? Sensory and active states? So why can we skip straight to the first and blanket rather than just identifying the purple 1988 or the Markov earlier model?"
"Unknown","01;10;19;26","01;10;43;27","The reason is that the particular partition is the minimal partition that allows for directed coupling with blank, it states, so that again is from Fig. ten. And the key thing to note from FIG. eight is that there are profound variances between some internal and external states, despite the fact they're conditionally independent so we're defining like nodes that are not connected or conditionally independent."
"Unknown","01;10;43;27","01;11;10;04","That's how the Bayesian graph works. So here one and four get correlated, get a connection with each other. That's this connection right here, right there and right there. So now they're coupled one in four. So even though some of the internal states are so now it's like the external states are at minimum two and Bucky Fuller, famous quote, unity is plural."
"Unknown","01;11;10;04","01;11;49;11","At minimum two, the internal states have to be at minimum two external states have to be at minimum to so that's pretty interesting because they. Yeah, yeah. The particular partition is the minimal partition that allows for directed coupling with blanket states that then there the second the fit states are highly correlated yet are twice removed. And so this is leading to a general synchrony through partial coupling of dynamical systems."
"Unknown","01;11;51;02","01;12;29;23","Note this is their note. There is no claim that either the original Lorenz system or coupled Lorenz system possesses a miracle blanket. The claim here is that there exists a Laplace approximation to these kinds of systems that in virtue of the zero elements of the ocean, feature more called blankets. So, oh, how many days we having a Markov being a Markov modeling a Markov no claim of applause approximation approach to systems identification can add constraints and make the problem easier to solve."
"Unknown","01;12;30;19","01;12;58;12","The Markov blanket is arising literally within the Laplace approximation, which is just an approximation. It's not a description of the system. So onto the free energy principle the existence of this. Any particular partition means that one can provide a stipulated of definition of the conditional density over external states being parameter ized by the conditional expectation of internal states."
"Unknown","01;12;58;12","01;13;37;21","Given sensory states, we call this a variational density parameter rise by expected internal states. You so going from the minimal coupled systems to there are still some persistent covariance s and these covariance is partitioned out into a markup blanket what if the expectation of the internal states were of external states, in other words, or inwards for every sensory state there's a conditional, but it has to be conditional."
"Unknown","01;13;37;22","01;14;04;15","The blanket state, which is how the whole thing is set up inwards. For every sensory state, there's a conditional density over external states and conditional density over internal states, where internal and external states are conditionally independent. This admits the possibility of a diffuse morphic map between the sufficient statistics of the respective densities. The existence of this mapping rests upon a continuously differentiable and invertible map, which is linear under a loop loss approximation."
"Unknown","01;14;04;15","01;14;28;10","So defined morphic is like stretchable, so that allows some of these formalisms to arise again. Would be awesome. To hear what other people can bring to the table about this. But this is like the energy minus entropy form, the divergence term, plus the self information about the policy and then the accuracy minus the complexity. So will be awesome to learn more about this."
"Unknown","01;14;29;27","01;14;56;27","OK, the phone got a little out of control here, but this functional, the big one is going to be expressed in a few different forms. So it's an expected energy minus the entropy, that's energy minus entropy, self information plus scale divergence. OK, self information plus cat negative log likelihood of particular states and the scale divergence accuracy minus complexity."
"Unknown","01;14;57;04","01;15;47;08","OK, accuracy minus complexity. It's also in the machine learning context evidence lower about elbow. This is the basis of the free energy principle. Put simply, it means that the expected internal states of a particular partition at non equilibrium steady state can be cast as encoding conditional or Bayesian beliefs about external states. Equivalently the equivalently the flow in the internal manifold can be expressed as a gradient flow on a variation of free energy that can be read as self information this lesson is a somewhat teleological and directed description of self-organization as self evidencing in the sense that the surprise or self information that constitutes the potential is known as log model evidence or marginal likelihood in"
"Unknown","01;15;47;08","01;16;18;16","Bayesian statistics. So wow, great FFP work. What does it mean to talk about the physiology perspective here though? So what does it mean for self evidencing in the biological context? The blood vessels want to observe themself working. So now in section 51 getting hopefully towards the end here an alternative. This is later in section five, one in alternative and deflationary perspective."
"Unknown","01;16;19;10","01;16;52;14","Ruslan noting that free energy gradients are also the gradients of self information so the organism wants to be minimally surprised about some chaotic pullback attractor. So whether or not things are wacky out there or not, having this updating flow model that comes to a pullback attractor, that is of the approximation that the model controls is very important and the organism wants to be minimally surprised about the expectations of preferences that it has over observations, and that is defined with some technical details here."
"Unknown","01;16;53;11","01;17;29;01","So this formulation of gradient flows is simpler and shows that they're effectively minimizing a different sort of prediction error, namely the difference between particular states and the expected values of non equilibrium steady states this leads to exactly the same gradient flows, but a complimentary interpretation in which autonomous states are drawn towards their steady state expectation. Here, mystically one could imagine this kind of stochastic chaos as opt to describe the motion of a moth attraction towards a flame, but constantly being thwarted by turbulence, i.e. sullen oil air currents, because active states influence sensory states and possibly external states."
"Unknown","01;17;29;09","01;18;30;19","This would look as if the particle, e.g. the moth, was trying to attain its most likely state in the face of random fluctuations and soil dynamics. This perspective emphasizes the active part of self evidencing, sometimes referred to as active inference so how cool. First in 2006 the winged snowflake 21 like a moth to the flame 5.2. So they give more summarization here about that sequence that they took of constructing the laplacian approximation with a quadratic form and then looking at that first and second partial differential partial derivatives matrices, the Jacobian and the Hessian looking at the conditional in dependencies, then the generalized synchronization synchronizing given the partitioning and then suggesting that there's some diffuse morphic"
"Unknown","01;18;30;19","01;19;13;22","like stretchable connection between the internal and external states conditioned upon all of that. And then that's the Bayesian mechanics in which internal states on average parameters, beliefs of a Bayesian sort about external states. OK, so some of the implications in the last few slides here. So clearly the work example based upon sparsely coupled Lorenz systems does not mean that a conditional synchronization map exists or is indeed invertible, which would allow the tale of two densities, the recognition and the generative model in any given system so you can't just specify any system potentially and find a conditional synchronization map."
"Unknown","01;19;14;19","01;19;41;23","However, the above derivations can be taken as existence of proof that such manifolds and accompanying variation of free energy formulation can emerge from sufficiently sparse coupling. So this is one system, classic system of complexity analysis, and it worked here. Maybe there's other systems where it will or won't. A particular partition is necessary to talk about states that are internal to some particle or person in which can be distinguished from external states."
"Unknown","01;19;42;06","01;20;19;02","One way of understanding the ensuing coupling between internal and external states is in terms of generalized synchrony. That's that synchronization manifold. This synchronization can be expressed as a variational principle of least action using the notation notion of variation free energy. So this is from another de Costa paper the synthesis on discrete state spaces and it is talking about how that variation of free energy minimization of perception and planning as inference about observations can be seen as a generalization."
"Unknown","01;20;19;19","01;20;52;18","Here's active inference. If you have no prior, then you're you have surprise, pure surprise, optimal surprise, intrinsic motivation info gain info max principle because it's just about what's surprising, given no priors when there's no ambiguity. So when there is a model that abstracts away from, for example, measurement error, you have risk sensitive policies and scale divergence based control in the arms principle and in other cases like Bayesian decision theory, expected utility theory, as well as maximum entropy."
"Unknown","01;20;52;25","01;21;24;00","And Jane, so it's kind of there's a lot of pieces that are coming into play when we talk about active inference, probably some that will still are yet to learn but there are some pretty interesting patterns arising from this partitioning. Here's another form another implication. So the polynomial form of the Helmholtz decomposition from formalism five may provide a generic model for observe random dynamical systems."
"Unknown","01;21;24;13","01;21;44;02","In other words, it could be the basis of a forward or generative model that explains some empirically observed flow estimated using the first and second moments to quantify the flow info variance of random fluctuations overstate space respectively. This kind of generative model is appealing because of its parameter position in terms of the underlying non equilibrium steady state density."
"Unknown","01;21;44;16","01;22;25;11","In other words, one could in principle try to explain empirical data in terms of a Gaussian steady state density, which may include constraints on conditional dependencies. So let's think back to the beginning with flow and information flow and mental flow and brain, it moving down a quarry or all these kinds of flow. And then could there be something that integrates across them another option for scaling this approach to high dimensional dynamical systems would be to learn the state dependency of the flow operator and the non equilibrium steady state density using unsupervised learning approaches such as deep neural networks."
"Unknown","01;22;26;07","01;22;55;23","A similar approach has become popular in the deep learning literature in the form of neural stochastic differential equations so here's two recent stochastic differential equation papers, and then they bring up this very interesting suggestion. One could use a separate feedforward neural network to parameter ize the different components of the flow operator and the self information. This would require differential transforms to be applied to the output layers of the network to constrain the question."
"Unknown","01;22;55;23","01;23;23;09","And so an oil flow operator to be positive, definite and anti symmetric respectively. So suggest ing some neural network architectures that might facilitate active inference then this is a pretty nice piece. It is interesting to relate flows across a markup boundary to the construct of law, which, like the free energy principle, sinks in normative account of the structure and dynamics of complex systems."
"Unknown","01;23;23;28","01;23;54;14","In the case of the Construct A Law, this is articulated in terms of maximizing external access to the currents, internal to the system. So here is Adrian Bhajan, who's like an awesome professor and researcher who's done many years of work like Kristen in some ways on this construct a law. So I was quite happy to see that connection here's another final implication."
"Unknown","01;23;54;27","01;24;21;02","One practical implication, finally, the practical implication. Great. It licenses the use of inverse sample covariance matrices of a sufficiently long time series as partition, potentially sufficient description of the steady state density. So we could take a real time series and fit that laplacian approximation this would furnish a description of the expected flow and la often of expense to establish whether the system was chaotic or not."
"Unknown","01;24;22;11","01;24;56;13","In conclusion, last sentence Having a simple functional form for the flow of random dynamical systems may be useful for both modeling and analyzing time series generated by real world processes. That are far from equilibrium that may or may not be chaotic. So we can think of two chaotic systems the humans and the ants and then everything else. So pretty interesting paper the coming two weeks."
"Unknown","01;24;56;18","01;25;08;04","Hopefully we'll have some good group discussions. We're going to email the authors. Now that we've done our work on the zero and would be awesome to have them on for the two discussions we'll have or for any other time."
"Unknown","01;25;10;05","01;25;43;07","Thanks everybody who was watching I hope if you are watching to the end, you found this interesting and can get involved with Active Lab because we could all have some shared resources so that some of these questions that are really being advanced in this paper, like the connections to complexity and dynamical systems theory and statistical thermodynamics, these are important contributions and this is not a fringe apologetics for active inference."
"Unknown","01;25;43;13","01;26;07;08","It's barely mentioned in the paper. It's actually some really fundamental work that I hope is understood and critiqued where valid. So what would a good understanding here enable of the kinds of things that are discussed in this paper which came out in 20, 21? But think into the future, what are the unique predictions and implications of this paper?"
"Unknown","01;26;07;23","01;26;28;16","What are the next steps for FFP and active inference? What are the goals of this research and what are you still curious about? So thanks for sticking around for a long live stream at a different time, but so it goes. So have a good one everyone. Hopefully see you around the lab or around by."
