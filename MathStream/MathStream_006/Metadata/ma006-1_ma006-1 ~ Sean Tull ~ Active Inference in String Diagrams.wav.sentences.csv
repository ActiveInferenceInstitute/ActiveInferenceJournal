start	end	sentNum	speaker	confidence	text
7690	9480	2	A	0.85811	Hello and welcome, everyone.
9850	12598	3	A	0.52488	It is September 1, 2023.
12764	19042	4	A	0.95233	We're here in active inference math stream number 6.1 here with Sean Toll.
19186	25650	5	A	0.99801	We'll be hearing a presentation, active inference in string diagrams followed by a discussion.
25810	27250	6	A	0.99997	This is super exciting.
27330	32430	7	A	0.59403	So if you're watching live, please feel feel free to write your questions in the Live chat.
33170	34446	8	A	0.99998	Really looking forward to this.
34468	38510	9	A	0.65608	So thank you, Sean, again for joining and to you for the presentation.
40130	41166	10	B	0.93901	All right, thanks very much.
41188	41934	11	B	0.99083	Thanks everyone who's watching.
41972	46510	12	B	0.96	And thanks to the organizers for this chance to speak to you and to Daniel for getting in touch and inviting me to speak.
46580	55940	13	B	0.87454	So, yeah, I'm really excited to share this work with this community, basically, and to hear from those people who work with active inference and do any formal work, what they think of what I'll present today.
56470	65378	14	B	0.94131	So I'm going to be presenting a formal approach to how you can describe active inference in terms of an entirely graphical language called the language of string diagrams.
65394	67618	15	B	1	And it's based on this mathematics called category theory.
67714	72694	16	B	1	And I won't assume that you're too familiar with this already and try and introduce it to you in the talk.
72812	81434	17	B	1	And ultimately, I'd like to sort of convince you that this diagrammatic language will be really useful for those of you who work formally with active inference and encourage you to pick it up in your own work.
81632	83406	18	B	0.70916	I've just introduced myself a bit.
83428	84074	19	B	0.94642	I'm Sean Tull.
84122	101346	20	B	0.97912	I'm a researcher at Continuum, formerly a postdoc in computer science in Oxford, and a Continuum in this Oxford team where I'm based, where we study what we call compositional intelligence, which includes applying category theory to topics in AI and as well as this.
101368	104158	21	B	0.99	The project was supported by a grant from FQXi.
104254	109030	22	B	0.79838	It's located at the bottom and hosted at Topos Institute, which is the center for Applied Category Theory.
110330	111734	23	B	0.99311	So let me get think.
111772	114870	24	B	0.69272	So, yeah, here we go.
114940	118358	25	B	0.95548	So for active inference, won't spend too much time introducing it.
118364	122940	26	B	0.96339	I'll assume most people here are familiar with it, and many of you probably know more about it than I do, in fact.
124350	128266	27	B	0.99633	So I'll just mention the parts of it that I'll be addressing in the talk.
128368	136030	28	B	0.99978	So thinking of it as a model of cognition that simply we can think of as applying at many levels, say from a whole organism or just to a single neuron.
136530	150290	29	B	1	And the key idea is that in this approach, you think of an agent that's coming with this generative model that it uses to explain the observations it receives from the world in terms of some hidden states, which you might call perception, and in terms of its own actions.
150710	160774	30	B	0.98	And in active inference, it achieves both of these things through this form of Bayesian inference or an approximate form of Bayesian inference by minimizing this quantity called free energy.
160892	163670	31	B	1	And these are the ingredients we'll be talking about in the talk.
163740	176118	32	B	0.93	And the thing that's really exciting about active inference, I think, for those of a formal background as well, is that it aims to offer like a very principled approach to cognition that you can hopefully apply at all these many levels.
176294	180300	33	B	0.99996	But I think at the moment it could also benefit from more formal work.
180830	182042	34	B	1	And that's what this talks about.
182096	191726	35	B	0.99816	It's about formal approaches to the theory in particular, I think nice clear formatations or active instances would help to clarify sort of what the core of the key ideas of the theory are.
191748	198100	36	B	0.99979	So we'd like it to be this very succinct principle that ideally we just apply to a generative model and everything else follows from.
198710	212600	37	B	1	And once we've got to this, we can hopefully generalize it, understand it better, and also make it just more accessible to those who come from formal backgrounds, like in mathematics and so on, and get them working on the topic very quickly and connect it with approaches in artificial intelligence as well.
213130	220906	38	B	0.9631	But the most important thing about a good formalization, I think, should just be to make learning about active inference easier, make the framework simpler to understand.
221008	223500	39	B	0.82182	So that's what we're aiming for in this work.
224110	234938	40	B	1	And I'd say in other places already there's been some calls that some suggestions that an is formalization of active inference should be a diagrammatic one.
235024	241950	41	B	0.99607	So when you look at the generative models that come up in active inference a lot, they're very compositional in their nature and it's very natural to draw them in diagrams.
242610	246834	42	B	0.98785	So it would be nice if our whole approach to describing it could be graphical in this way.
246952	261894	43	B	0.95543	So just for example, there's this paper called The Graphical Brain by Kristen Par, and in general, we've probably seen loads of these diagrams describing generative models where you draw many compositional features of different spaces of hidden states, observations, interacting and so on.
262092	265942	44	B	0.99844	So these diagrams are used, but they're just used to represent the model.
265996	272294	45	B	0.99996	You still have to then go to doing sort of traditional probability of theory calculations when you reason about them normally.
272422	281718	46	B	0.67552	But in fact, there is a whole graphical, formalism and mathematical language for describing these kind of interacting processes just entirely with the diagrams.
281814	297854	47	B	0.87842	So the area of mathematics is called category theory and the language are these string diagrams I'm going to talk today, and in particular, there's a lot of work going on in applied category theory now in how you can describe aspects of probability theory and causality and causal models in terms of string diagrams.
297982	300526	48	B	0.96	And these causal models are basically based on Bayesian networks.
300558	304062	49	B	0.40984	So the same formal structure as the generative models in active inference.
304206	313106	50	B	0.88	And in particular, what I'll talk about today kind of draws on this paper co authored with Robin Lorenz, talking about causal models in the sense of pearl in terms of these string diagrams.
313138	320140	51	B	0.88244	So it's basically causal Bayesian networks, which is the same formal structure as we'll be talking about today.
320750	332618	52	B	0.92021	So in this talk I'm talking about this paper, which was joint work with Johannes Kleiner and Ive, which is called Active Inference in String Diagrams, a categorical account of processing and free energy.
332704	339322	53	B	0.99	And basically what we do is try to give a formalization of active inference that's nice and clear conceptually just entirely in terms of string diagrams.
339386	345490	54	B	0.99768	So we're basically taking the kind of formal content that's in something like the active inference book and turning it into these diagrams.
347190	356830	55	B	0.98	And as I mentioned, it was done as part of this FQXi project that was actually on a project about consciousness as about ways that category theory can be applied to theories of consciousness.
356910	364950	56	B	0.99	And we've done some previous work looking at the integrated information theory of consciousness and of course there's all sorts of ways that active inference has been proposed to connect to consciousness.
366010	367958	57	B	0.9999	But for the purpose of this talk, we won't go into any of that.
367964	369954	58	B	0.79869	It's just a theory of cognition.
370002	375340	59	B	1	I take it to be here and I'll just mention at the end it'd be nice to connect it back up to consciousness in future.
375710	386880	60	B	0.98	And there's also lots of other related work going on in category theory that's very close to this, that often goes by the name of categorical cybernetics, and this might include some of the things Toby has talked about on the stream in the past.
387250	395746	61	B	0.97193	So what I'll do now is introduce categories and string diagrams and then later we'll apply them to all these basic ingredients of active inference that I've alluded to so far.
395768	401060	62	B	0.99659	So that would be generative models updating them, free energy and active inference itself.
402710	405730	63	B	0.96711	Let's start with these categories and string diagrams.
406550	412018	64	B	0.9996	So you can think of a category in general as a sort of world of interacting processes.
412114	415698	65	B	1	And the categories we're talking about here are always going to be these symmetric minoidal categories.
415794	421260	66	B	0.96843	But don't worry too much about the formal language because the way we talk about them is just going to come down to the diagrams here today.
421630	431898	67	B	0.99722	So a category amounts to a collection of these objects, or sometimes called systems, like this Capital ABC here, and what are called morphisms, or you might want to typically call processes between them.
431984	437662	68	B	0.99943	So when you're writing normally, you can just write a morphism from A to B as like this f colon A to B.
437796	442942	69	B	0.99996	In string diagrams, though, you draw it like this, where we're reading all the diagrams from bottom to top in this talk.
443076	448514	70	B	0.99949	So you have a wire for the A input at the bottom and a wire for the B output at the top.
448552	459960	71	B	1	And the morphism is just drawn as a box F here and you just read the diagram up thinking about, okay, it takes in this input coming in on this wire, a process applies and then you have your output of type B at the top.
461610	464102	72	B	0.99715	So what you can do with these processes is compose them.
464156	470998	73	B	0.99922	So if you have two processes, say your F from A to B and G from B to C, so the types line up, you can just compose them in sequence.
471094	474630	74	B	1	And this just means plugging the boxes together in your diagrams.
474790	478614	75	B	0.99	And because we're in this Minoidal category, you can also compose in parallel.
478742	484054	76	B	0.98601	So you have this operation called the tensor, which means given two objects, you can put them together to build this composite object.
484112	490480	77	B	0.99959	So AB goes to a tensor B, you'd say, and you can also do this to morphisms, so you can build this F tensor G.
490850	493086	78	B	0.71566	But in the pictures it just means drawing them side by side.
493108	499950	79	B	1	And you just think of this as meaning we have F from A to C and G from B to D, and they're just running in parallel and they're not interacting essentially.
500690	504418	80	B	0.99931	So most of the time you just draw a picture like this and you don't even need to write the tensor symbols.
504554	511430	81	B	0.99562	So if these two basic modes of composition and from these you can build much more elaborate string diagrams in your category.
512650	518770	82	B	0.99982	So if you're writing things very mathematically, you have to write lots of equations that a category or Minoidal category needs to satisfy.
518850	523242	83	B	0.81289	But when you're working the diagrams, they basically do some of the work for you because these things just come out for free.
523376	530506	84	B	0.99674	So, for example, you have equations like this that you'd have to think about when you're working with them in the conventional mathematical way.
530528	534726	85	B	0.99995	But in the diagrams it just means if you have two boxes, you can kind of slide them along the wires.
534758	538714	86	B	0.99995	It doesn't really matter where they are on the wires, it tends to just be the connectivity that matters.
538842	547646	87	B	0.99954	Similarly, we can cross wires over each other because we're in the symmetric setting and there's a few just useful features that you'll have in a category.
547678	552962	88	B	0.97681	So every object comes with this identity morphism, which you just think of as meaning nothing happening basically.
553016	554862	89	B	0.99884	So it's just drawn as a blank wire.
555006	561346	90	B	0.93405	There's also a kind of identity object, as it were, called a unit object, which is just empty space, so you don't even draw the wire.
561458	563302	91	B	0.63846	This dashbox just means nothing.
563356	564950	92	B	0.8232	It's meant to be an empty picture.
565450	571110	93	B	1	And the latter thing is just useful because it now means we can talk about amorphism, which doesn't even have an input or an output.
571270	577126	94	B	0.99991	More formally, it has this object I as it's input by output, and we give these things special names.
577238	584822	95	B	0.99952	So the most important one probably is that of a state, which is a morphism with no input, as it were, or really with input I.
584896	586286	96	B	0.76373	So in the pictures it just looks like this.
586308	587470	97	B	0.95599	So there's no wire going in.
587540	589390	98	B	1	And you'd call this a state of A.
589540	594930	99	B	0.99999	You can also have a process that takes in a if it has no output that you'd call an effect.
595080	596926	100	B	1	And if you have naive, you just call this a scalar.
596958	601570	101	B	0.99976	So this is just going to be like a number basically floating around next to your diagram.
603430	606706	102	B	0.99925	So there are many categories out there.
606728	608230	103	B	1	The point of category three is extremely general.
608300	614726	104	B	0.99957	So this could be talking about computational processes or physical processes or quantum processes in particular, and all sorts of things.
614828	617250	105	B	0.74772	For this talk we'll only actually need about one category.
617330	619146	106	B	0.74833	We'll just keep it simple with this one.
619248	620326	107	B	0.61405	That's the category.
620438	621642	108	B	0.6	I call it matar plus.
621696	624010	109	B	0.99956	So it's positive real matrices.
624510	632666	110	B	0.64826	So you can just take objects for the wires to be finite sets and the morphisms to be positive matrices indexed by these, as I'll explain.
632768	639694	111	B	0.98491	So if we draw a box like this, M, going from X to Y, this is like a matrix indexed by X and Y.
639732	650180	112	B	1	And for each input in this little set X, sorry, in the set X and each output in Y, you'd get a positive real number and we'll write it like M of Y given X.
650790	654020	113	B	0.79761	So this box would mean a function like this.
655270	659874	114	B	0.99999	Now, when we plug them together, they let us turn some things that you normally have to do with equations into kind of simpler pictures.
659922	661126	115	B	0.84	I mean, mainly this middle one.
661148	666242	116	B	0.99999	So if we have two in sequence, we just compose them by matrix multiplication.
666306	672106	117	B	0.99994	So instead of having to write this formula where we sum over Y, we can just draw this picture above it where we just plug them on top.
672288	678906	118	B	0.99	And if we run them in parallel here, we take the cartesian product of the sets and the tensor product of the matrices, as it were.
678928	683310	119	B	0.99794	But it's just the obvious thing where you have two things running independently.
685010	691406	120	B	0.99032	So in particular a state tier ends up the minority unit is just a singleton set and you can basically just ignore it.
691428	698562	121	B	0.99992	So a state tier amounts to just a function sending each X to a positive real and affect the same thing.
698616	701346	122	B	0.71	And a scalar would just be a positive real.
701528	707614	123	B	0.99	The intuition though is that we're going to restrict the particular morphisms in here, which are probabilistic in the nature.
707662	710694	124	B	0.99996	So they need to send each X to an actual distribution over Y.
710812	714040	125	B	0.99988	So I want to talk about how you actually pick those up next.
714970	717958	126	B	0.99937	So to do that, you use some extra structure that this category has.
718044	720450	127	B	0.99879	It forms what's called a copy discard category.
720530	724282	128	B	0.8604	So this is one more bit of mathematical sort of gadgets we have around.
724416	727302	129	B	0.99967	So that is that each object comes with these distinguished processes.
727366	735920	130	B	0.56109	There's one that we call copy that takes in a say and brings up two copies of A at the top and one called discard where you just throw A away so you have no output at the top.
737970	745122	131	B	0.95828	These satisfy some equations that are quite intuitive if you think about like copying and then throwing away one of the outputs is the same as doing nothing.
745176	745438	132	B	0.99878	So it's.
745454	749954	133	B	0.73432	This blank wire copying is symmetric and associative is the last one.
750072	756100	134	B	0.93322	So in this category, mad or plus discard would be just the function sending each element to one.
756550	758206	135	B	1	And the copy would be like a delta.
758238	761046	136	B	0.9985	So A comes in and two copies of A come out.
761068	762790	137	B	1	At the top is the intuition.
763690	772294	138	B	1	The reason we introduced this stuff is because it's been shown recently that you can do a lot of probability theory just in terms of these CD categories and particular ones called Markov categories.
772342	782166	139	B	0.9938	So there's a lot of what's going on in applied category theory at the moment, using this language of CD categories in particular, they let you pick out some things to do with probability theory.
782198	784014	140	B	0.59952	I'll just talk about a couple of them here.
784052	786094	141	B	0.96	The most important one is the notion of a channel.
786292	791258	142	B	0.60915	So this is what lets us pick out the actual normalized matrices, as it were, from earlier.
791434	795738	143	B	0.99984	So in general, you call amorphism a channel when it preserves this discarding.
795914	800446	144	B	1	And a special case is a state in which when it's a channel, you call it normalized.
800638	803598	145	B	0.68998	So for a state, this means it would actually be a probability distribution.
803694	807634	146	B	0.99994	So it's actually normalized if you sum over the values with this omega, you'll get one.
807752	812098	147	B	1	And for a morphism being a channel, it means it sends each input to a distribution.
812194	815080	148	B	0.99989	So it actually is a probability channel in the usual sense.
815610	818690	149	B	0.78302	Equivalently, the matrix for F would be stochastic.
818850	821980	150	B	0.99855	So these are the ones we'll use in generative models, for example.
824270	828086	151	B	0.98	And as I said, there's lots of probability theory you can describe with these diagrams.
828118	829862	152	B	0.41467	It's very two simple examples.
829926	833466	153	B	0.93939	You can describe marginalization in probability theory with this discarding thing.
833488	837134	154	B	0.99879	So if you have box omega like this, it would be a joint distribution over X and Y.
837172	839918	155	B	0.99999	If you just discard Y, you'll get the marginal on X.
840084	850930	156	B	1	And if you plug omega A distribution on X into an effect, that would just be any function on X, this would be giving you a scalar now, and that would be the expectation value of E in this distribution.
852150	857506	157	B	0.9995	So I'll meet lots more of this as we go, but let's actually start doing some stuff related to active inference in particular now.
857528	861618	158	B	0.99997	So I want to talk about generative models and how you view these in the diagrams.
861794	869320	159	B	0.99962	So, as we've said, we're going to be talking about agents having generative models that relate things like actions, observations and world states.
869850	878346	160	B	0.77	And these are normally quite compositional in active inference, right, and might involve many different spaces of states and observations and these processes relating them.
878448	886830	161	B	0.93092	You'd usually treat these as something like a Bayesian network, claiming you can view it really as a causal Bayesian network because it's sort of describing how states are causing these observations.
888290	889246	162	B	0.99223	Formally, it's the same thing.
889268	903934	163	B	0.84761	It's just Bayesian network, which you could normally say is described as something like a dag, a directed asynchronous graph, which describe the different variables that are being related and then sets the values for each and probability channels, describing each one in terms of its parents in the Dag.
903982	907570	164	B	1	And then you often look at its whole distribution over all the variables.
907910	919074	165	B	0.99176	But already I'd say the way that these visual networks are drawn in active inference text and stuff is kind of converging on something a bit closer to string diagrams because you don't actually just draw the Dag and the variables.
919122	925450	166	B	0.95618	It's very useful to actually give names to the mechanisms themselves, as it were, like you have in this picture, the A and the B's.
926190	936190	167	B	0.99703	So yeah, my claim is that it's sort of converging on the way that string diagrams will look, as we'll see on the next slide, which is where you really do label everything, not just the variables.
937330	947250	168	B	0.99036	So to describe those sort of Bayesian networks with string diagrams, the key observation is really that Dags correspond to a certain class of string diagrams that we're called network diagrams.
948310	951538	169	B	0.99894	There's a definition here, but which is better just to see an example in a second.
951624	961270	170	B	0.99982	But the diagrams built from copying and sometimes discarding and the key thing is just that they only have processes with maybe many inputs but only one output.
961610	965030	171	B	0.99639	So this is going to be like a mechanism that produces each variable.
965930	978966	172	B	0.99858	So the result is that if you have a Dag G and you choose some of the vertices to be outputs, so those are like the observed variables, you can draw a network diagram which expresses the same equivalent structure with those things as the outputs.
979078	980106	173	B	0.99575	So here's an example.
980208	983180	174	B	0.99999	We have a Dag with these four variables, x one to x four.
983870	990638	175	B	1	And what you do is you have a wire for each variable in your diagram on the right and you draw a box that produces it.
990644	992480	176	B	0.85021	It doesn't really matter what you label the box.
994290	999374	177	B	0.97806	So this box C, for example, produces x two and it will produce it in terms of its parents in the Dag.
999422	1001714	178	B	0.99792	So x one and x four in this case.
1001752	1005650	179	B	0.7	And if it doesn't have any parents, it would just be a state, as it were, box and no input.
1006310	1013794	180	B	1	And then what you do is you take each variable and you copy it and you pass it to all of its children in the Dag and also out of the diagram if it's an output.
1013842	1021180	181	B	0.99714	So this now means you've sort of expressed the whole structure of the Dag and also which variables are sort of leaving the system for the output ones.
1022190	1035230	182	B	0.99533	So this allows us to turn Dag into a string diagram and then if we want to make a generative model that expresses like a Bayesian network that's structured according to this Dag, you just have to now interpret this diagram in a certain sense.
1035300	1047926	183	B	0.98133	So in general, working in any one of these CD categories, this copy discard categories, we can say that a generative model in there is given by one of these network diagrams without any inputs and an interpretation of the diagram.
1047978	1053186	184	B	0.99999	Meaning you actually say what the objects are for each of the wires in the diagram and what the actual channels are.
1053208	1058142	185	B	0.91069	So they need to be channels, not just morphisms in your category are for each of the boxes.
1058286	1065670	186	B	0.9997	So for a gender model like this, you would say you pick objects x one, x two, x two, x four and pick channels for the ABCD.
1066090	1071080	187	B	1	And we'll think of the output of the diagram as like the observed variables and the rest of the hidden ones.
1071870	1078218	188	B	0.99785	So for example, if you're working in this category, Mat R Plus, that is the only category I've actually introduced here.
1078224	1079674	189	B	0.67376	So this is going to be our running example.
1079792	1082378	190	B	0.57615	This is the same thing as one of these causal Bayesian networks.
1082394	1087710	191	B	0.99704	So it just means picking sets of values for variables and picking probability channels for the boxes.
1089330	1094170	192	B	0.87197	So you might ask why would you use this representation rather than the usual one, which I think is a good question.
1094340	1099250	193	B	0.99386	So it's equivalent to the Dag and probability channel description.
1099670	1115654	194	B	0.99982	But the thing that's nice is that in the conventional approach of these networks, you sort of have to switch between the Dags, which are split the variables and then doing calculations with probabilities, whereas in the categorical approach you can use just one formatism because you can do probability theory with the string diagrams as well.
1115692	1116934	195	B	0.99989	So it's quite natural in that sense.
1116972	1122458	196	B	0.99781	You have this one language of both just intuitively drawing what's going on in a model and then reasoning about it.
1122624	1126314	197	B	0.99996	It also lets you start to generalize things in a useful way, I think.
1126432	1133920	198	B	0.99948	So I kept having to say that you have no inputs to your diagram, but there's nothing really fundamental about that and it's not really clear why we need that.
1134530	1137870	199	B	0.99997	What you can do instead is start to allow inputs to your model as well.
1138020	1142238	200	B	0.80681	So we'll call this an open generative model.
1142324	1145262	201	B	0.99997	So an open generative model is the same thing.
1145316	1148686	202	B	0.99999	But now I've just dropped this requirement, the diagram doesn't have any inputs.
1148878	1151246	203	B	0.99876	So here's an example of a general network diagram.
1151278	1153170	204	B	0.99999	Now, with these inputs x two, x three.
1153240	1156354	205	B	0.99999	So there's no mechanism specified for these new variables, x two, x three.
1156392	1160134	206	B	0.99083	They're just input variables to the system and they can be outputs as well.
1160172	1162662	207	B	0.99992	For example, x three is both an input and an output here.
1162796	1167670	208	B	1	And again, an interpretation of this general network diagram just means picking the objects and the channels.
1168650	1175302	209	B	0.94583	This is the same definition we use to define what we call an open calls and model in the paper with Robin Lorenz I mentioned earlier.
1175446	1182940	210	B	0.98195	So an emergenerative model is formally just the same thing, but we're just thinking of it as a generative model possessed by a cognitive agent.
1183630	1187306	211	B	0.99964	If you run this definition in mathar plus then this is just like a causal Bayern network.
1187338	1190122	212	B	0.90042	But now you have some of your variables just have no mechanism specified.
1190186	1192240	213	B	0.99931	So they're just inputs to the whole thing.
1193730	1199778	214	B	0.75	The nice thing about these open generative models is that because they can have these inputs, you can plug them together and compose them.
1199944	1201726	215	B	0.9614	These things in fact form their own category.
1201758	1203220	216	B	0.99996	But I won't go into that today.
1205270	1212360	217	B	0.99977	So that was the general theory of these generative models that just actually described some examples that you'll see in active inference coming up all the time.
1212730	1214198	218	B	0.65901	So it's a simple example.
1214364	1218146	219	B	0.63798	Let's just imagine we have one space of hidden states and one space of observations.
1218258	1225580	220	B	0.99978	Then it would be generative model of that form would just look like this network diagram where there's just two wires, there's just S and O.
1226510	1229978	221	B	0.78	S doesn't have any parents, so it just has this prior distribution sigma over it.
1229984	1234350	222	B	1	And there's just this one channel often called the likelihood from S to O.
1234500	1242522	223	B	0.58784	If you just draw that network diagram, say that model in C or in Matar plus it would be the same as one of these simple generative models.
1242666	1247730	224	B	0.99959	When you're looking at these, you're often introduced interested in this distribution over both variables together.
1247800	1259926	225	B	0.67827	This joint distribution that you might write as P of S times P of O given S normally or bit more specifically here introducing the names for the two distribution in the channel here in string diagrams, it's just the same as this.
1259948	1263286	226	B	0.8848	So you just take the prior and you make it an output now.
1263388	1267090	227	B	1	And then you compose those channels together and this would give you a distribution.
1267170	1271962	228	B	0.96564	So a normalized state M over snow at this.
1272016	1275674	229	B	0.98958	So this is just the resulting joint distribution you get from the generative model.
1275712	1277180	230	B	1	And we'll come back to that later.
1279230	1287870	231	B	0.98967	So, a more elaborate example of generative model that you'll see example in the active infants textbook are these discrete time models that are used a lot.
1287940	1296398	232	B	0.98551	So I'll walk through this diagram now, so this is an example of a more complex network diagram and a generative model it describes.
1296574	1299220	233	B	0.59926	So here we've got these end time steps going.
1299590	1304658	234	B	0.99985	Remember, we read from bottom to top, but I'll just talk about I'll describe things from the top down here.
1304664	1315480	235	B	0.99996	So at the top we have the observations one, two up to on the observations at each time being caused by these hidden states s one, S two and SN at each time by these channels A.
1317290	1324666	236	B	0.94	And the hidden state is evolving over time by this transition channel B, where it takes the previous state as an input and then choose the next one.
1324768	1331938	237	B	0.9998	It also takes us one extra wire that's coming from the bottom and that's this space P of policies, which is how the agent sort of actions enter the picture.
1331974	1336894	238	B	0.97427	So these policies describe its behaviors, its behavioral policies it can carry out.
1337012	1339770	239	B	0.56267	So, based on the previous hidden state and the way it's acting.
1339930	1350660	240	B	0.99706	This channel B would determine the probabilities for the next states and then there's supplier over the policies that you can think of as the habits or the typical behaviors of the system.
1351270	1361286	241	B	0.69613	So you can just draw this diagram and say, like, interpret this in math plus and that would for any given interpretation, meaning any choice of what the values for these variables can possibly take are.
1361308	1366520	242	B	0.57	And any choice for what these channels are would then give you this type of punitive model.
1368170	1374806	243	B	1	And often you will see models sort of of this form or similar forms being plugged together to form these hierarchical models.
1374838	1387998	244	B	1	And I think the compositional language is very nice for these because you really want to talk about open models to define this so hierarchical model you can view as really as just being given by taking lots of these open generative models I mentioned and plugging them together in a certain sense.
1388084	1400100	245	B	0.99967	So here you can see a picture of a hierarchical model where we just have these layers where different copies of the same model at each layer and the inputs from one layer match the outputs of the layer below so we can compose them together.
1401510	1403406	246	B	0.5846	So that's generative models.
1403598	1406306	247	B	0.99829	So so far we've just been using the diagrams to represent them.
1406328	1408962	248	B	0.99833	We'd like to actually do a bit more though and reason about these models.
1409026	1418806	249	B	0.81937	In particular, we'll talk about how you update a model or update the beliefs within a model, which is very important in active inference and how this looks in the string diagrams.
1418838	1431354	250	B	0.99983	Now, so let's say we've got an agent M, we have a model M and it's just a simple one where we say there's just one space of hidden space S and one space of observations O.
1431392	1440254	251	B	0.99994	So they have this joint distribution that I mentioned earlier and they had these prior beliefs about s which you can get back from the joint distribution by just taking the marginal, if you like.
1440292	1441290	252	B	0.99707	So that's sigma.
1441370	1446686	253	B	0.51009	So they've got their model, they've got their beliefs about what states are likely and then they receive a new observation.
1446878	1454610	254	B	1	And here the kind of observations we'll think about in general can be soft, meaning they're described by a distribution over O, not necessarily just one element.
1455510	1459238	255	B	0.99644	So that would be one of these normalized states.
1459404	1462390	256	B	0.94651	I'll try not to use the word state here because it's a bit confusing with this S around.
1462460	1468038	257	B	0.99988	So this distribution over O is their new observation, this bold font O.
1468204	1477094	258	B	0.97	And now they want to update the margin, want to update M in some way so that the marginal basically is different and describes the updated posterior beliefs.
1477222	1484234	259	B	1	And this comes up of course in perception where you're updating your sort of state of the world given some observation you receive.
1484282	1491550	260	B	0.91821	But it could also be used to model like planning behavior where updating your plan of action, your policy given something like.
1491620	1497460	261	B	0.99998	Which outcomes you'd like to see in the future and we'll come back to that later in the talk.
1498230	1501490	262	B	0.99888	So we want to talk about how you can do this updating.
1502230	1506782	263	B	0.99786	So you might think there's just a standard answer or at least in the ideal case, which is this Bayesian updating.
1506846	1509038	264	B	1	And that's true when your observations are sharp.
1509134	1510822	265	B	0.99636	We'll start by talking about that case.
1510956	1512982	266	B	0.99895	So I'll say what sharp means in a second.
1513116	1516914	267	B	0.9988	But first I'll just talk about how you treat Bayesian conditioning in these string diagrams.
1517042	1531690	268	B	0.99899	So on the right here we have if you view this process from O to S, this describes the sort of Bayesian conditional channel, or in general a partial channel in fact that the agent would have from the introduced by their model.
1531760	1536958	269	B	0.99129	So you can describe this in string diagrams with a couple of extra gadgets I hadn't mentioned yet.
1537124	1539600	270	B	0.99919	So you have your distribution m over S and O.
1539970	1546718	271	B	0.99407	You can have this in math there's this effect that we call the cat which just takes two inputs and compares if they're equal.
1546814	1549166	272	B	0.94849	This allows for you to turn an output into an input.
1549198	1550994	273	B	0.97944	So that's what this part here is.
1551192	1554126	274	B	0.81	And then you can introduce this extra thing of normalization.
1554238	1567720	275	B	0.99996	So what you'd like to do is take a general morphism and for each possible input normalize that so that it's a distribution if you can or set it to zero if it's just zero and there's nothing you can do, that's what this blue dash box is.
1568490	1574650	276	B	1	And in the paper and in the related calls and models paper, we talk about the axioms normalization feature satisfies.
1575150	1579338	277	B	1	The point is if you compute this thing in Matar Plus, it will give you kind of what you'd expect.
1579424	1592510	278	B	0.98621	So it will give you the usual notion for each .0 of the space O, you plug it into this, you'll get a kind of conditional M of S given O that you'd expect whenever that's defined.
1593010	1599300	279	B	0.91722	There's a strange diagram way to describe this kind of Bayesian conditional channel or partial channel.
1599670	1602526	280	B	1	And I said this is what you would use when your observation is sharp.
1602558	1606114	281	B	1	And I also drew it differently with this triangle to sort of distinguish that case.
1606152	1607974	282	B	0.99845	So what does that mean in general?
1608012	1618230	283	B	0.99027	You say that a state in one of these CD categories, so a distribution basically would be sharp when it's copied by the copy map, which isn't true for general distributions.
1618730	1626922	284	B	0.98	And if you run this definition in math or plus, this really means that this thing O really is just point distribution at some specific element of O.
1626976	1629146	285	B	0.99566	So it really is sharp in that sense.
1629168	1630298	286	B	0.99368	It's just a point.
1630464	1634960	287	B	0.99809	There's no real probabilities probabilistic aspects to it there.
1635410	1638926	288	B	0.99491	But in any CP category you can just talk about the sharp states like this.
1638948	1641070	289	B	0.99929	They're often also called deterministic.
1641970	1645882	290	B	0.99635	So for these sharp ones, you ideally think you'd like to do the spacing updating.
1646026	1647666	291	B	0.81414	But in fact when you've got soft ones.
1647688	1648980	292	B	0.99177	So it doesn't have this property.
1649510	1652814	293	B	0.72647	There's actually at least two good ways to do this kind of updating.
1652942	1660120	294	B	1	I don't know if this is as well known, so I'll just mention it now anyway, and they've been studied in some detail by Bart Jacobs, this paper at the bottom.
1660970	1663714	295	B	0.99138	So let's say you don't get one of these sharp observations.
1663762	1665910	296	B	0.99954	You have just a distribution over o.
1666060	1671090	297	B	0.99798	There's at least two reasonable ways to generalize sort of the picture from the last slide to give a notion of updating.
1671170	1674330	298	B	0.82	And Jacobs calls them Jeffries and Pearl's update rules.
1675230	1679146	299	B	0.98658	So in Jefferies Update, you basically do it like we did before.
1679248	1686094	300	B	0.99996	You have this Bayesian conditional kind of channel or partial channel, the normalized box here, and you just plug a distribution into it.
1686212	1689902	301	B	0.37823	But in Pearl's Update, you turn a distribution into an effect.
1689956	1692506	302	B	0.99747	So you just compose it with this cap to bend it around in the picture.
1692538	1693614	303	B	0.9997	That's what it means.
1693812	1696722	304	B	0.98996	So you plug that into M and then normalize everything.
1696776	1700034	305	B	0.9992	So the difference is where the normalization happens.
1700232	1705006	306	B	1	And yes, it's basically just interesting that both of these are reasonable notions, generalization, they have different properties.
1705118	1708454	307	B	0.99965	It's not obvious that one of them is sort of more rational or something than the other.
1708572	1710470	308	B	0.99958	They just behave a bit differently.
1711770	1716226	309	B	0.99924	In the formula you can see that the normalization is being applied differently.
1716258	1719880	310	B	0.99674	So if you turn this picture into these little notations, it would look like this.
1720650	1728166	311	B	0.99717	So in the top case you're normalizing for each possible sharp o and then taking an expectation over this distribution here.
1728188	1731950	312	B	0.97668	Whereas in the Pearl case, you plug the whole thing together and then just normalize.
1732770	1735498	313	B	0.99637	Either way you do it though, the point is that these things are actually hard to compute.
1735514	1739790	314	B	0.99885	So we don't expect a cognitive agent to be doing either of these exactly, even in the sharp case.
1739940	1746340	315	B	1	And so, as we know, we want to instead approximate these kind of things using free energy, which is what I'll talk about next.
1749350	1759938	316	B	0.99903	So our aim is to try and accommodate free energy somehow in the diagrammatic approach and free energy sort of formula that come up are often given in terms of what you call the Surprise, these negative logarithm quantities.
1760034	1766738	317	B	0.99753	So we'll start by introducing just a new graphical component for treating those that we call log boxes.
1766914	1776554	318	B	0.42524	If you have any function E on a set X, a positive real, remember that made in A, that would look like an effect in your category X in Math Plus.
1776592	1785466	319	B	0.97163	Let's say then what we want to do is talk about this function X goes to minus log of e of X, which we call the Surprise.
1785498	1791262	320	B	0.98739	So we just introduce this graphical feature where we draw a green box around it and say that denotes this function.
1791316	1798750	321	B	0.99995	Now, and using rules, the nice properties of logarithm, you can turn these into nice graphical rules.
1798830	1807240	322	B	0.99996	This log box feature would satisfy for example, this is sort of the way that logarithms turn multiplication into addition on the left here.
1809770	1812466	323	B	0.99998	If you have this around, then you can start talking about surprise.
1812578	1822442	324	B	0.99805	So if you have two distributions, sigma and Omega, the surprise of one distribution relative to the other is defined by this expectation value.
1822496	1834414	325	B	0.97863	So just the expectation of a surprise of sigma according to Omega which if you remember I said expectation values are given by sort of plugging a state for the distribution into the thing you're looking at the expectation value of.
1834452	1835886	326	B	0.99987	So that would be the log box here.
1835988	1841354	327	B	0.99958	So we can just define surprise omega, Sigma in this way if we like in the pictures.
1841482	1846366	328	B	0.74	And important special cases where this come up are when you're calculating entropy, which is the self surprise.
1846398	1850690	329	B	1	And the KL divergence can be calculated from the surprise and the entropy.
1851590	1859480	330	B	0.99953	So it means that whenever we have formula given in terms of these if we like, we can instead denote them with this graphical symbol, at least with the log box.
1861370	1864342	331	B	0.99874	So now let's talk about how we use this to describe free energy.
1864396	1870194	332	B	0.99996	So what we wanted to do in the paper is sort of help clarify the kind of different notions of free energy that we found in active instruments.
1870242	1873482	333	B	0.99989	In particular the variational and the expected free energy energy.
1873536	1878858	334	B	0.99924	So we want one more general quantity that we can understand both of those in terms of.
1878944	1881530	335	B	0.54867	I'm just calling out the free energy here.
1881600	1886080	336	B	0.8262	I'm interested to know what other people think of this sort of naming for what we're doing.
1886610	1891502	337	B	0.9	The situation is that we've got some generative model that's fixed over these two variables Sno like before.
1891556	1896650	338	B	0.99762	So remember we had this distribution, this box M over Sno distribution.
1896810	1902194	339	B	0.98	And let's just say we have another distribution Q now and we'll see examples of this in a second what sort of Q they would be.
1902392	1906966	340	B	0.99916	Then we just define this quantity of free energy of the one relative to the other in this way.
1906988	1912466	341	B	0.99987	So it's the surprise minus the entropy of Q in the string diagrams.
1912498	1914370	342	B	0.99605	Then it's just this feature we plug.
1914450	1921900	343	B	0.99998	So it's like the expected surprise of M for Q minus the entropy of Q's marginal on S.
1922590	1929622	344	B	0.80661	Or this is the formula if you want to use the conventional notation which is useful for relating it to existing approaches.
1929766	1938720	345	B	0.99963	So we can define this very general free energy quantity and then we'll meet two special cases of it that we're interested in, which is the variational and expected free energy.
1939250	1942250	346	B	0.52263	It all comes down basically to having a definition of surprise.
1942410	1945120	347	B	0.91379	You just need this notion of surprise to define everything else.
1946370	1948260	348	B	0.99987	So with a variational free energy.
1948950	1953282	349	B	0.99957	So we have this fixed model M and we have this soft observation o like we did before.
1953336	1962130	350	B	0.99953	So that's this box here and then what we're doing is we're considering different possible distributions over S that we think of as different updates we could consider for our beliefs.
1962290	1970454	351	B	1	And we define the variational free energy of any of those states, those distributions Q as the special case of the definition from the previous slide.
1970502	1974602	352	B	0.99996	So it's like the general free energy where that capital Q just takes this form.
1974656	1979980	353	B	0.99993	So it just consists of our new beliefs, lowercase Q and our observation O.
1981390	1983966	354	B	0.99859	So in formula you could also just draw it like this.
1983988	1994560	355	B	0.99506	So you take the surprise from your model M and you just see how its expected value for those beliefs and that observation subtracted the entropy of Q.
1996610	2005330	356	B	0.99	And what you can show is that this VFV value satisfies this bound of the KL in relation to this kind of Jeffrey update of your model with respect to this observation.
2005750	2013750	357	B	0.9809	In particular, when it's a sharp observation, then the minimal of this VFE will be given by the Bayesian Updating.
2014650	2016920	358	B	0.99947	In general, though, we might think about what happens.
2017290	2025050	359	B	0.97895	So in general we can think of minimizing this VFP quantity as doing this, as finding this Q that approximates this kind of updates we were looking at earlier.
2025870	2030300	360	B	0.98	And yeah, in the sharp case it will coincide as all of the notions of Updating do.
2030990	2033930	361	B	0.99473	So the minimal VFP will be given by the Bayesian update.
2034010	2037294	362	B	0.95985	But for these soft observations, it's something else.
2037332	2041626	363	B	0.82208	It's not exactly either of the two notions Updating we met earlier.
2041658	2049298	364	B	0.99196	So this is actually a third notion of updating for soft observations, which I think is an interesting way to think about what VFE minimization is doing.
2049384	2051310	365	B	0.98686	So we just call this the VFE update.
2051390	2056834	366	B	0.98551	So you've got many different Q, you could calculate the sphere quantity for each and you've got a soft observation O here.
2056872	2058158	367	B	0.46098	So it's some distribution.
2058334	2062790	368	B	0.99	And if you find the one with the minimal value of sphere, you call that the VFE update.
2063450	2068120	369	B	0.98	And this wouldn't be equal to either those Pearl or Jeffrey style updates that we met.
2068970	2076300	370	B	0.9596	So that's the VFE which we'll come back to, the other notion of free energy we want to talk about, it's the expected free energy.
2077230	2079626	371	B	0.9977	So that's where we still have our model M.
2079728	2088254	372	B	0.96103	But rather than an observation, we think of ourselves as having some preferences of observations we'd like to see they're again encoded in a distribution, though over O.
2088292	2095680	373	B	0.99545	So that's this C just with that fixed, we can define this one quantity called the expected free energy.
2096050	2101938	374	B	0.99987	So that's given by the free energy of M compared with this other generative model where you have used the same.
2102024	2105838	375	B	0.99775	So this M here would really be the inverse channel from O to S of M.
2105864	2113522	376	B	0.92461	So like the Bayesian inverse here, but where you just assert that the preference is actually is the prior on the observation.
2113586	2120150	377	B	0.99268	So you're comparing these two in terms of this generic free energy quantity we defined earlier.
2120490	2122238	378	B	0.99177	So again, you can turn this into formulae.
2122274	2129580	379	B	0.79	And there's loads of stuff in active inference about the different rewritings of EFE and the ways to interpret them in terms of uncertainty and risk and so on.
2130190	2141390	380	B	0.98	And it has this property that you can show it will be bounded by the surprise of those preferences for your model and it kind of gives you a way to approximate them as we'll see.
2141540	2144154	381	B	0.98091	So I won't talk, I don't think I have time to go too much more into EFE.
2144202	2157430	382	B	0.99984	But the point really in terms of what this work's done is just to try and have just one generic free energy quantity we met earlier where we can see the VFE and the EFE both coming up special cases depending on what we plug in here for the two distributions.
2159610	2165554	383	B	0.99458	So what I'd like to do now is to sort of put some of these pieces together to show what active inference itself will kind of look like in terms of string diagrams.
2165602	2175530	384	B	0.98	And in particular, what we'll do is derive this formula that you'll find in active inference textbooks in a graphical way and I think quite a transparent way, that's the claim.
2177150	2182554	385	B	0.96746	So to do so, we basically need to give a nice high level conceptual view of what active inference is.
2182592	2184480	386	B	0.9993	So this is the way that we do it in the paper.
2185490	2191790	387	B	0.99976	So when inactive inference, the key thing for stating all the definitions is that our model takes the following form at a high level.
2191860	2193758	388	B	0.99952	So there's some notion of so.
2193764	2197086	389	B	0.58748	It's like our discrete time model we had earlier, but just with two time steps.
2197118	2202446	390	B	0.99994	If you like, each of those time steps could break down in terms of further subtime steps.
2202478	2203394	391	B	0.99998	But that won't matter.
2203432	2206418	392	B	0.95417	We've just obstructed here at this higher level.
2206584	2213574	393	B	0.99458	So at the higher level, we just have a notion of the current time, or maybe like all the time steps up to the current time, and that's this S and O here.
2213612	2220290	394	B	0.99997	So there's current states and current observations and then there's some notion of future times, these future states and future observations.
2220370	2228010	395	B	0.9999	So that could be all the time steps up to some big number, something like that, all grouped together in one of those discrete time models.
2228430	2243200	396	B	0.96	And again, we have the policies and we have the same sort of shape of model where there's some channels here which I haven't bothered giving letters to, but showing the way that the policy influences the transition from the state to the future state and observations from each.
2243890	2250862	397	B	0.99981	So we just have a generative model where we have policies, we have states and observations, and we have future states and future observations.
2251006	2253794	398	B	0.56691	In active inference, what we're doing is we're receiving two things.
2253832	2260200	399	B	0.97652	We're receiving an observation in the current time and we have some preferences about what we'd like to see in the future.
2260650	2270010	400	B	0.99826	So these are each given by these two distributions, bolton, O over O, and the preferences C over the future observations, and then we're doing updating with those.
2270080	2282634	401	B	0.99964	So I think updating is just our habits, the prior over the policies to give our new distribution over policies which we can think of as the agent's plan of how it wants to act.
2282752	2287360	402	B	0.99998	So we're going to try and do this updating like before to obtain a new distribution over P.
2287810	2293918	403	B	1	And that is now telling us how we want to behave in the future in a way that will basically you can.
2293924	2301220	404	B	0.99998	Think of it as saying, we want to explain why we're seeing what we're currently seeing and how we're going to obtain what we'd like in the future.
2303670	2310646	405	B	0.99981	In the books kind of inference and various places you can find a formula like this that there will be justified as coming from the free energy principle in some way.
2310748	2323862	406	B	0.66546	It's basically saying you can do this approximately by making your plan distribution take the following form there's a soft max, there's a part relating to the habits of your model so that's your prior over policies.
2323926	2330090	407	B	0.9998	These pi are the individual policies in P and then there's parts of formula related to the VFE and the EFE.
2331390	2338906	408	B	0.98	And what we wanted to do is see where this formula comes from in a sort of nice high level way from the structure of the diagram.
2339018	2352306	409	B	0.96241	So there are explanations for this formula there, but I found them quite hard to follow, to be honest, because they were talking about the EFE as being a prior that you then do EFE kind of minimization on top of.
2352328	2357090	410	B	0.99881	But you kind of need to do the part about the present time first before you can do the EFE.
2358070	2362342	411	B	1	And so what we wanted, this is a really clear way to see how this just drops out from the structure of the model.
2362396	2365560	412	B	0.99863	So that's what I'll try and show now.
2367450	2371166	413	B	0.88656	So what we'd like to do then is to do this approximate updating.
2371218	2374278	414	B	0.46569	We're going to do the pearl style updating which looked like this in the pictures.
2374374	2383162	415	B	0.99824	So we want to get our new plan so our distribution over policies by updating, by plugging in our observation and our preferences and then normalizing everything.
2383216	2388080	416	B	0.99774	So the thing on the right is what we'd like to have ideally but we're just going to have to approximate it in some way.
2388850	2392770	417	B	0.97121	Let's just take the distribution that's inside the dash normalization box.
2392840	2400162	418	B	0.99858	Now this is the thing we'd like to basically approximate this in the structure of our model.
2400216	2408402	419	B	1	We can write it like this and I'll just show then some graphical steps for how we can apply approximations to obtain the formula that we saw.
2408456	2415346	420	B	1	And obviously we won't be able to go through every detail of the proof but it should give hopefully just some intuition for what it's like to actually work with a string diagram.
2415378	2416822	421	B	0.97613	So that's really why I'm showing it.
2416956	2418950	422	B	0.99954	So we knew our model take roughly this form.
2419020	2423974	423	B	0.99454	There's some part relating to current states and current observations and also future observations.
2424022	2431500	424	B	0.80795	I've just called them both M here, but we just know there's that part of the model relating to the present time and future time.
2432670	2438986	425	B	0.56	And so what we're going to do is first focus on this part of the model relating to the current state and the current observation.
2439098	2442638	426	B	0.69	And we want to approximate what's in that blue dashed box.
2442804	2449650	427	B	0.99	And what you can show is that if you do this VFE updating, that will be approximately equal to this part of the diagram.
2450150	2457958	428	B	0.98961	So this Q is given by for each policy doing this VSE updating, so minimizing your variation of free energy.
2458124	2459862	429	B	0.98995	So you do that for each policy.
2459996	2466454	430	B	0.98149	Then you can view the collection of all of those belief updates as just one channel from P to S.
2466652	2475482	431	B	0.99375	So if you think about it back here, basically for each policy you could plug in you would obtain just a distribution now of snow and you could do updating with respect to that.
2475616	2492670	432	B	0.9552	That's what Q of that particular policy pi would be and you put them all together into this one channel Q and you can show then for each one, if you do this overall process where you multiply by this E to the minus VFD quantity here, it will be approximately equal to this part of the diagram.
2494130	2497086	433	B	0.72722	Okay, so that's our first step and that's how the VfB entered the picture.
2497118	2504334	434	B	0.99945	Then we've got this top part of the diagram, we'll collapse it together and just view this as one process going into future observations and our preferences.
2504382	2506820	435	B	1	And we'd like to approximate what's in this box now.
2507430	2509046	436	B	0.91	And this is where the EFB comes in.
2509068	2525482	437	B	0.64758	So you can basically show because you have this, the expected free energy will give you an approximation to this here where this is basically like an expectation value for your preferences for each policy.
2525536	2531660	438	B	0.99799	So this would be like the density C of those preferences being plugged into your model for each policy.
2533630	2535446	439	B	0.99957	So I haven't had time to go into the full details.
2535472	2549060	440	B	0.66652	These of approximation steps but they're essentially the same approximations you'll find in active inference text and so on, just turned into the string diagrammatic setting and we talk about how they come about from Jensen's inequality and things like this.
2549510	2556180	441	B	0.74936	So this step where you think about the future times is called the prediction step and the previous one was the perception step.
2556630	2563670	442	B	0.99164	So now we've rewritten that diagram in terms of some e to the minus of the VFE and e to the minus of the EFE as well as our habits.
2565930	2569766	443	B	0.92	And remember what we wanted to do was approximate the normalization of this whole thing.
2569788	2575994	444	B	0.99601	So that's when you apply this blue dash box around the whole thing and now if we do that, this is exactly the same as the formula we were after.
2576032	2583894	445	B	0.99129	So we've obtained the formula now and that's because you're normalizing something but it's got these e to the minuses in it.
2584032	2592510	446	B	0.99993	So you can also rewrite that in terms of this soft max where now you just replace the E with this log and the other ones you lose the exponentials.
2593010	2600082	447	B	0.99984	So this formula, if you wanted to, if you wrote out the formula for what this was for each policy, it would be equal to this down here.
2600216	2606206	448	B	0.99485	So the claim is that this is a nice way to derive this formula and is a bit more transparent than the ones that exist.
2606238	2609170	449	B	0.99988	So the idea was really just to see we draw what's going on.
2609240	2619660	450	B	0.98234	Okay, we're doing updating with the model of this form and we're trying to do this approximate form of updating and just see where we're applying the approximations and from the structure of the model itself, see how this formula comes about.
2622110	2628794	451	B	0.99692	Okay, so that so far basically just talked about things that are already there in active inference as it's new derivation, but it's existing stuff.
2628912	2635390	452	B	0.99972	Before wrapping up, I'd just like to also talk about something bit more new that we do with the string diagrammatic approach.
2635890	2641230	453	B	0.61202	That's to talk about the way in which free energy itself is compositional.
2641650	2647940	454	B	0.99984	So the motivation for this is that the idea is that we want to think of this one free energy principle applying at all levels of a system.
2649270	2659186	455	B	0.99966	So to do that, you'd want to know that an agent can say if you've got one of these big composite generative models, that it can do its free energy minimization on the whole thing by doing it on the parts.
2659218	2664194	456	B	0.99911	Because we want to ultimately think it just comes down to each part doing its own bit of free energy minimization.
2664322	2666390	457	B	0.99774	So that's what we want to make precise.
2668010	2671338	458	B	0.9742	In particular, we're going to be talking about the VFE here really all the time.
2671504	2673834	459	B	0.99	And if you recall in the diagrams, it looked like this.
2673872	2677980	460	B	0.99825	So we use this log boxes and it just took this particular shape here.
2678510	2692094	461	B	0.99279	So what we do in the paper in order to address this compositionality problem is introduce a notion of this VFE that we can apply not just to generative models, but ones which actually have these inputs as well.
2692132	2703650	462	B	0.99902	So these were what I called open generative models earlier because we need to really talk about pieces of generative models plugging together and give them a notion of free energy to even make sense of this notion of free energy being compositional.
2704310	2707250	463	B	0.99847	So we proposed this definition of what we call the open VFE.
2707590	2715110	464	B	0.5933	So now instead of just a distribution M over S and O, we have a channel from some inputs to S and O given by one of these open models.
2715530	2720006	465	B	0.99	And our Q, the thing we're doing the VFE minimization with respect to.
2720028	2723018	466	B	0.36232	So the thing we're calculating, it would now have an input as well.
2723024	2728460	467	B	0.99944	So it's a joint distribution over the states and inputs and observation takes the same shape as before.
2730050	2738074	468	B	0.99109	So you get this other formula that's basically just a natural way to generalize the previous VFE formula to accommodate this extra input wire.
2738202	2746654	469	B	0.92	I now and what we show is that this thing is compositional in a sensor that I alluded to.
2746692	2752654	470	B	0.99883	So I'll walk through that and the way you do it is just using these graphical properties that these log boxes have that I mentioned earlier.
2752702	2756594	471	B	0.99988	So you could turn all of that into a proof and standard probability notation if you like.
2756632	2764840	472	B	0.99999	But it's quite instructive to always just be able to work in the diagrams to keep track of the compositional structure of the models and so on.
2765690	2770950	473	B	0.99701	So the result says that this open VFE quantity is compositional in two ways.
2771100	2773066	474	B	0.81	The first one here is this quite trivial way.
2773088	2780570	475	B	0.99775	So if we have two models running in parallel, so like taking the tensor of them and they're just both doing their own, we're calculating the VF for each of them.
2780640	2788558	476	B	0.93019	Sorry for the whole thing, but it's just given by two running in parallel, then it's just the same as calculating the V of V for each individually and adding them together.
2788644	2791360	477	B	0.99739	So that certainly what we'd like to happen.
2791730	2794690	478	B	1	And it just follows from the properties of these log boxes.
2795670	2802466	479	B	0.66666	More interestingly, there's the second way in which it's compositional, which is the sequential mode of plugging models together.
2802568	2811910	480	B	0.99998	So if we have an open model M one and some inputs into some outputs one, but those are now actually the inputs for the second model and we have these running.
2812060	2815960	481	B	0.54968	So the first generation model is passing stuff up to the second one.
2816330	2822970	482	B	1	And now we want to calculate that result VFE in terms of an observation.
2823710	2827002	483	B	0.99994	We can again write it as a sum of two of them, but in a slightly different way.
2827056	2829914	484	B	0.99773	So observation is just existing on the top wire, right?
2829952	2833126	485	B	1	Because it's just the output of the whole thing that gets this observation.
2833158	2834560	486	B	0.98143	So it's just on O two.
2835010	2845682	487	B	0.94701	So first we calculate the VFE for this model at the top m two in the usual way and then we add on a Vfe calculated for the first model, but it doesn't really have an observation one, right?
2845736	2850674	488	B	0.99966	But instead the observation it uses is one that's being passed down from M two.
2850712	2857526	489	B	0.99997	So that's the queue that M two is using is passed down now as if it's an observation down to M one.
2857548	2865720	490	B	0.99998	So it's kind of like O two receives this observation, does its updating about Q or whatever, and passes that down to M one.
2866810	2881930	491	B	0.86779	So in this way we can say that the VFE composers in that okay, both of these are minimizing VFE locally, where for the M one model we mean it's minimizing it with respect to these cues that are coming, for these O ones that are coming down from above.
2882350	2887680	492	B	0.99987	Then the whole system is also minimizing its VFE because it's just given by summing those two together.
2889570	2891214	493	B	0.99998	So I talked about a lot of stuff.
2891252	2894500	494	B	0.99992	Now I'm just going to wrap up now and then we can go to a discussion, I hope.
2895750	2903010	495	B	0.68694	So the main takeaway was just meant to be to try and show that these string diagrams provide some natural language for talking about active inference.
2904150	2911046	496	B	1	And I would encourage you to try anyone working on active inference formally to take a look and see if they would be useful to you in some way.
2911228	2919350	497	B	0.96	And in particular, I focused on some of the what I was calling the main ingredients of active inference, so that were generative models, the way you update them, and free energy.
2919420	2923990	498	B	0.98	And we saw sort of ways you can describe all of those notions in the string diagrams.
2924070	2932826	499	B	1	And the thing that I think is useful about them is that they give you a nice representational language for just drawing pictures of your generative models and composing them like hierarchical models and so on.
2933008	2936318	500	B	0.6843	But they also let you do the reasoning because you can do probability theory with them.
2936404	2941200	501	B	0.89472	So you can actually reason about what's going on in active inference just with the diagrams themselves.
2942850	2943738	502	B	0.94765	There's loads of directions.
2943754	2944482	503	B	0.7018	You can take this in the future.
2944536	2949742	504	B	0.99977	Obviously we could keep absorbing more of the work without the native inference into the diagrams.
2949886	2958630	505	B	0.49572	Bit more interestingly, we introduced this new notion at the end of how to make free energy compositional.
2958970	2966098	506	B	0.99891	In particular, we gave this definition of VFE for an open system now so it has a generative model which can have inputs.
2966114	2967506	507	B	0.98414	We call this the open Vfe.
2967618	2972250	508	B	0.93	I just be very interested in what people think of this definition we introduced and whether it seems meaningful.
2973070	2978342	509	B	0.57472	Secondly, well, throughout the talk I kept talking about just minimizing free energy and that's all I said already, the Vfe.
2978486	2979914	510	B	0.61	I didn't say how you do it.
2979952	2985226	511	B	0.81274	So in fact, this is normally done with these various algorithms of message passing algorithms.
2985338	2988446	512	B	0.99951	So they're an important part of active inference as well.
2988468	2994480	513	B	1	And I think it would be great to include these in the setup by having some diagrammatic story of them.
2995730	2997394	514	B	0.53302	There's lots of other questions around.
2997432	3003278	515	B	0.99994	So one of them is that I talked about these two notions of updating with respect to soft observations.
3003374	3007406	516	B	1	And I think normally people tend to focus on sharp observations, so they perhaps haven't.
3007598	3015106	517	B	0.99989	Not everyone has heard of these before, but it's very natural to treat the soft ones when you're working this compositional setup.
3015298	3023718	518	B	0.98	And so there you start to wonder about which of these, the Pearl style updating or the Jeffrey style updating is more natural to think about in the context of cognition.
3023894	3028394	519	B	0.85	And maybe we'll say, okay, well really VSE updating is the one you should be thinking about.
3028432	3034126	520	B	0.98041	That's probably the claim accurate inference would make, but it'd still be nice to think about how this relates to the other two.
3034148	3040430	521	B	0.99958	Is it best thought of as approximating the former or the latter style of sort of precise updating?
3041410	3042446	522	B	1	And then finally we.
3042468	3045706	523	B	0.9928	Could try and connect this up to lots of further topics.
3045738	3049822	524	B	0.82	I mentioned I'm a continuum, and we're interested in this notion of compositional intelligence.
3049886	3059394	525	B	0.99688	So it would be nice to connect this now to topics in AI and so on, and think about how it relates to other, basically applications of category theory in AI.
3059522	3060070	526	B	0.99995	In particular.
3060140	3071180	527	B	0.99398	There's also this whole world of categorical cybernetics I mentioned at the beginning, and I'd like to connect this a bit more precisely with what people are doing there with their stories in terms of lenses and so on.
3071630	3077334	528	B	0.88	And something else we were also interested in that I mentioned is that we got into the topic by thinking about consciousness.
3077382	3093694	529	B	1	And there's lots of ways, as a major theory of cognition, there's been just loads of proposals for how active inference is related to consciousness, and it'd be nice to see how those can be described formally and in this setup and whether the string diagrammatic approach helps you make any more sense of those.
3093812	3095700	530	B	0.61869	So that's something we'd love to do in future.
3096630	3101774	531	B	0.86235	But for now, I'd like to say thanks again to all of you for listening, and I'd love to go to a discussion.
3101822	3102420	532	B	0.99709	Thanks.
3107510	3110450	533	A	0.99745	Thank you, Sean, for the wonderful presentation.
3111270	3112258	534	B	0.96738	Thank you.
3112424	3119720	535	A	1	I will first pass to Ali for an opening remark, please.
3122170	3123670	536	C	0.99988	Thank you, Daniel.
3124570	3128630	537	C	0.99982	Thanks so much, Sean, for your really fascinating presentation.
3129290	3131094	538	C	1	I truly enjoyed it.
3131292	3133400	539	C	0.96518	So I have a number of questions.
3134670	3140860	540	C	0.99996	Let me begin by asking the first know.
3141230	3189542	541	C	0.97023	When Bob Kirky and others took Hamiltonian formulation of quantum mechanics and kind of turned it into the string diagram formulation of it, namely ZX calculus, the claim was that regardless of its possible verity, but the claim was that one of the advantages of looking at quantum mechanics in terms of string diagrams, it's more than just a convenient way of looking at quantum formulation, and it actually unveils some properties of quantum mechanics that would be extremely difficult to see with Hamiltonian formulation.
3189686	3212990	542	C	1	And even in some of their papers, they claim one of the reasons for somehow the stagnant development in quantum technologies and quantum theory is exactly related to the difficulty of working with Hamiltonian formulations.
3213070	3229762	543	C	0.95129	So would you say string diagram formulation of active inference kind of takes a similar approach to somehow providing more than just handy tool for representing active inference modeling.
3229826	3255390	544	C	1	And actually it kind of opens up new possibilities for further developments of active inference theory, possibilities which would somehow, I don't know, impossible or at least extremely difficult for the current traditional formulation of active inference to see in the current formulation of the active inference.
3256770	3257326	545	B	0.83461	Thanks.
3257428	3258270	546	B	0.99604	That's an amazing question.
3258340	3259854	547	B	0.89184	Yeah, I would agree.
3259892	3268498	548	B	1	I think my idea for work at Oxford is actually in this categorical quantum mechanics area I talked about so string diagrams for quantum theory and everything.
3268664	3285370	549	B	0.99	And I agree that that language helps you talk about a lot of things that you would maybe never get round to so much in other mathematical formulations of quantum theory, basically things that make use of the tensor, as it were, the composition a lot.
3285440	3294934	550	B	0.99506	So if this led to stagnation in quantum theory, it's probably because people weren't focusing as much on the tensor and entanglement and stuff, which became very central.
3294982	3299182	551	B	0.99975	Obviously in the end that's what people needed to do, quantum computing and stuff.
3299236	3313214	552	B	0.99878	So now what people are doing with quantum theories includes quantum computing where they're drawing these circuits and so you're drawing they're basically like string diagrams describing sometimes these string diagrams, sometimes they just use the slightly different conventions for quantum circuits.
3313262	3317906	553	B	0.99999	But it's similarly a compositional language where you have got tensor products.
3318008	3324360	554	B	0.83484	So that as in things running in parallel states of these products so that you can talk about entanglement and so on.
3325850	3338966	555	B	0.88844	It's the language that makes it very immediate to represent that, because you just draw a box with two eyes and it encodes entangled state, and it makes you want to plug these things together and compose them, which is what you want to do in quantum computing.
3339158	3352686	556	B	0.99941	So I think similarly, if you never use that kind of language, you might think of a system often as a fixed thing and not about the way it interacts with other ones so much and that could lead to overlooking all sorts of things.
3352708	3354334	557	B	0.99998	So that's true in any area.
3354532	3358494	558	B	1	And I think in active inference it's certainly very true.
3358532	3371254	559	B	1	I think that it's natural to think compositionally in this way because you're wanting to talk about generative models being composed from pieces and you're maybe thinking about how the whole brain works in relation to interactions between parts of it and so on.
3371452	3377078	560	B	0.99698	So if you never used this kind of compositional view, there is stuff you would miss, I think.
3377244	3389420	561	B	0.6	I think in some sense people weren't as behind already because they already were working kind of compositionally right, because they're using these Bayesian network diagrams like the Dags and the way they're normally drawn are very close.
3390110	3396502	562	B	0.99999	They are basically the string diagrams, they just don't do the equations and the rewriting of the diagrams.
3396646	3409054	563	B	0.99866	So it's not as far back maybe as quantum theory was, in the sense that people are thinking compositionally, but it feels like you just want to go one step further to having a fully compositional language you're working in.
3409092	3421214	564	B	0.99946	Where you have the advantage now that you can just talk about taking a whole model and plugging it into another one and it has a completely clear formal meaning and so on, which I think is what you want to do in areas like active inference.
3421262	3429670	565	B	0.99138	So going from the diagrams which are currently used to string diagrams is like the logical next step and in terms of new stuff it lets you do.
3429740	3433866	566	B	0.99	I think an example is something like this open BFE thing, I guess.
3433888	3440758	567	B	0.89689	So if you're just always thinking about just a generative model meaning one without inputs.
3440934	3451902	568	B	0.99988	You might not think of a notion I'm not saying this is necessarily the right notion, but you might not think about this problem of how you want to give your definition for something that is allowed to have inputs as well.
3452036	3462094	569	B	0.99	And once you have that have definition, you can sort of apply to parts of a composite system more easily, so it becomes more natural to use compositionally.
3462142	3468434	570	B	0.99996	So that's the kind of thing where without something like string diagrams, people can end up overlooking it.
3468472	3470514	571	B	0.99961	It wouldn't be impossible to do without them.
3470552	3478470	572	B	0.34	I just need to talk about this notion of a kind of open generative model, which just means throwing away some mechanisms to make things be inputs.
3479050	3483610	573	B	0.9938	But you could miss it, but you really won't once you start thinking categorically.
3488590	3489494	574	A	0.99989	Thank you, Ollie.
3489542	3491260	575	A	0.99997	Please continue if you would like.
3494510	3494874	576	B	0.99888	Thanks.
3494912	3517250	577	C	0.99982	So, yeah, my other perhaps related question is comparing this kind of formulation to this recent formulation of constructor theory in terms of string diagrams or categorical formulation of constructor theory.
3518790	3531942	578	C	1	Before going into this question, you see, you mentioned that this project is a part of a larger project for developing collective intelligence, right?
3532076	3567230	579	C	0.99867	So the similar kind of situation happens for constructor theory in which it is a kind of meta theory that tries to somehow discriminate between the possibilities of physical laws as opposed to counterfactual laws, and how physical laws, how there can be a theory, accounts for the emergence of possible physical laws.
3567390	3585190	580	C	0.98841	So in this sense, would you say this kind of formulation category, theoretical formulation, or possibly this specific String diagram formulation of active inference?
3585710	3592166	581	C	0.99989	Or maybe other theories of consciousness can be seen as a kind of providing a path?
3592198	3604480	582	C	0.89616	Toward developing a kind of meta theory of consciousness and possibly unifying many different strands of theories of consciousness into.
3606290	3606606	583	B	1	I.
3606628	3626978	584	C	0.92672	Don'T know, a holistic picture that can somehow be compared and positively reconciled with one another and ultimately reaching the ultimate theory of consciousness.
3627074	3659150	585	C	0.98928	Or, I don't know, do you see this line of work providing enough evidence for this line of development research or, I don't know, somehow maybe even not specifically consciousness, but unifying the different aspects of cognition, intelligence and consciousness altogether?
3663490	3664574	586	C	0.85282	What would you say?
3664692	3665360	587	B	0.95365	Thanks.
3665810	3668770	588	B	0.99785	Keep giving me ideal selling points.
3668840	3672100	589	B	0.99973	So, yeah, that's also something I would like to say.
3674390	3684818	590	B	1	I tend to think of it that way and that my background is in applying category theory to just lots of topics and I so naturally do think of it as quite a unifying language.
3684914	3695638	591	B	1	And the grant on consciousness that I mentioned was building on earlier work we did on looking at integrated information theory of consciousness, which in the end basically was done in terms of categorical probability.
3695734	3698774	592	B	0.99992	So it's like the same setup of the diagrams.
3698902	3702522	593	B	1	And so we kind of wanted to do the same thing for directive inference.
3702586	3707850	594	B	0.82753	So there it's like we've taken both of these things and put them in this common language.
3707930	3710510	595	B	0.99998	You could have put them in the common language of probability theory before.
3710580	3716658	596	B	0.99999	But I think I do have an intuition that there is something more clear about it.
3716664	3724674	597	B	0.9496	Does make it easier to get a conceptual grasp of both theories, I think, once you've done it this way and somehow also, yeah, the diagrammatic view does make it much easier to compare them.
3724712	3731826	598	B	0.99986	So the hope was basically to, and still is to keep going and to keep understanding various notions in that language.
3731858	3735254	599	B	0.99109	So there's things I've looked at in cognitive science I've also done this way.
3735292	3742570	600	B	0.95977	So this theory of conceptual spaces, garden force have worked on treating that in terms of diagrams and so on.
3742640	3748746	601	B	0.99045	So I would love to see basically many theories put into this language to make it easier to compare them.
3748928	3754350	602	B	0.99989	You could try and compare them directly already, but I think you want one clear formalization to put them all in.
3754420	3763262	603	B	1	And I would say that the categories and diagrams is the right one to pick because it tends to just give a very clear conceptual view of things.
3763396	3772050	604	B	1	The question is whether you have some theory that's very important, where the things categories are good at, just doesn't quite capture the essence of what you want to talk about there.
3772120	3781286	605	B	0.99886	But for things like active inference and IIT, so far it seemed very natural because on the case of IIT, it's about talking about how integrated something is.
3781308	3785282	606	B	0.98364	So you basically want to talk about the opposite of that, which is something being decomposed.
3785346	3791174	607	B	1	And the diagrams basically talk about parts and how they're related, which is what you need to make sense of that notion of integration.
3791302	3792860	608	B	0.9997	So it's very natural there.
3793310	3800874	609	B	0.9999	But yeah, I would love basically to see various aspects of cognitive science understood categorically.
3800922	3803520	610	B	0.80233	That's something I'd love to do myself as well.
3805090	3811786	611	B	0.98	And the hope would be then to try and gain insights from all of them and build a theory.
3811818	3816526	612	B	0.95524	It's not the category theory itself is a theory of cognition or consciousness.
3816558	3819522	613	B	0.6391	It's just a very useful language for relating them.
3819576	3826920	614	B	1	And then it would be very exciting to see something natively defined in terms of category theory as well at the end.
3827370	3837798	615	B	1	And there's a feeling that some of what's going on in applied category theory, I think, like in categorical, cybernetics and so on, is kind of taking that approach for perhaps some of the first time.
3837884	3843514	616	B	0.99999	Previously, I've always thought category theory is basically you take existing things and you get a really nice abstract view of them.
3843632	3852080	617	B	0.99997	But now I think people are comfortable enough with it that they're sort of defining things categorically from the outset in areas like that.
3855410	3856062	618	A	0.99993	Awesome.
3856196	3856880	619	B	0.94285	Well.
3858770	3861026	620	A	0.95182	Yeah, I have many thank you.
3861208	3862450	621	B	0.71629	These are great questions.
3862600	3864180	622	B	0.33125	There's like ideal questions.
3866790	3867714	623	A	0.95536	You'Ve pointed in.
3867752	3891020	624	A	1	And we've explored a little bit of the utility and the simplicity and how that could help with accessibility and rigor and applicability all these awesome things leading to reaccounting and reframing consolidating as well as discovering some new trails between, for example, expected free energy energy and variational free energy energy.
3891710	3906990	625	A	0.99999	Looking at the equations, you might be able to say that they rhyme, but you would be many, many lines deep into understanding what, if any, generalizations could encompass the both of them.
3907140	3910820	626	A	0.99994	So that was just a very salient example.
3912790	3915746	627	A	1	A few different kinds of questions.
3915928	3920590	628	A	0.99949	So how is time treated in category theory?
3920670	3928146	629	A	0.71646	Or how does active inference treat time today and how do you see the way that time is treated?
3928258	3931634	630	A	0.99999	We talk about discrete time and continuous time generative models.
3931682	3937622	631	A	0.99998	Then there's the past, present and future multi agent systems federated or asynchronous communication.
3937686	3945210	632	A	0.99066	So how is time treated and how does that give us a different grasp on dynamical modeling?
3946590	3947500	633	B	0.62309	Thank you.
3948990	3950586	634	B	0.9988	I'd love to have a better answer for that.
3950608	3967010	635	B	0.98739	Basically, I think it's a tough one at the moment in the talks if I just talked about discrete time and that's sort of very easy to treat with the Bayesian network setup and with these kind of string diagrams because you can just lay out the discrete time steps as processes in your picture like we see here.
3967080	3980306	636	B	0.99435	We have the end time steps here, but I don't have anything satisfying worked out yet to say about how you would treat a continuous time case, which I think is important in active inference.
3980338	3985302	637	B	0.99777	You'd like to basically take.
3985356	3993514	638	B	0.53	I guess basically what you want to do is take the way that you describe this thing with the end time steps and kind of have a formula for folding it together and just saying, okay, but you're unpacking this.
3993552	3994794	639	B	0.99935	Thing n times.
3994992	3999338	640	B	0.92	And then you can take that thing and imagine this abstract view of unpacking.
3999354	4008990	641	B	0.99764	It just not discreetly anymore in this continuous way, so that you can capture something like the differential equation kind of definition of continuous time thing in active inference.
4011030	4011780	642	B	0.51	I?
4014550	4023762	643	B	0.60762	Yeah so you can certainly work with continuous time things in the sense of, you know, the stuff going on in categorical cybernetics or sort of categorical systems theory I guess it would be called.
4023896	4035746	644	B	0.99462	Act world is kind know it has continuous time dynamical systems and talks about plugging them together but that diagram is sort of just relating their variables is my understanding.
4035778	4043082	645	B	0.97207	It's not like a diagram isn't exactly showing the time and in some sense they kind of have to synchronize, I think.
4043216	4045066	646	B	0.99915	It's not an area I'm totally familiar with.
4045168	4054894	647	B	0.99871	So it would have been really cool to basically have this work and then have another part of it talking about like we've done for discrete time here.
4054932	4065474	648	B	0.99996	Having a nice description of a continuous time case, I think it will end up being some work to take that into account there would be really nice to see.
4065512	4070706	649	B	0.99969	So it just needs the right abstraction, I think, for taking a picture like this.
4070808	4080578	650	B	0.51828	Not drawing the time steps as like bits in your diagram, but just saying that it's like this b thing with like a feedback loop basically is what this is describing.
4080674	4095210	651	B	1	And then giving a semantics to that in terms of time evolution, to give a continuous version of this, for example, with like state unfurling continuously and observations for each time step in general.
4095280	4099206	652	B	1	I wouldn't say there's like an answer to the question of how is time treated in category theory.
4099238	4112910	653	B	0.99996	There wouldn't really be one answer because category is going to be so generally they tend to be very effective for discrete things in general, like algebra and so on, because they kind of are discrete in some sense, like the composition is discrete.
4112990	4118722	654	B	0.99581	So continuous aspects and things like continuous time tend to be more difficult in a sense.
4118776	4121826	655	B	0.99927	Or they're just sort of inside the morphisms, as it were.
4121848	4124082	656	B	0.98575	They're not in the composition.
4124146	4127430	657	B	0.99742	So it doesn't end up looking like this when you're composing continuously.
4129370	4136842	658	B	0.99375	But yeah, I think there will be people in act who sort of would come at you with a particular answer.
4136896	4144140	659	B	0.79717	So they've got a way they like to treat continuous time that I'm just not familiar with yet.
4145310	4146060	660	B	0.50314	Cool.
4147070	4150560	661	A	1	A little bit of a more educational or applied question.
4151010	4155246	662	A	0.99991	So how do we go about drawing and learning to draw?
4155348	4157274	663	A	0.99998	Is there a software package?
4157402	4167378	664	A	0.99999	Is there a way that we can get a step by step process to building that familiarity with like when I see this shape, then here's what I know.
4167464	4170500	665	A	1	And then how do we know what we can and can't do?
4170950	4177894	666	A	1	And does that drawing software flag us or do we need to send it to a friend?
4178012	4179350	667	A	0.99993	So how do we look at something?
4179420	4195046	668	A	1	And then part one, build up the motifs in our own aesthetic understanding so that we can understand the compositionality of this as you do today and as we all do today, for example, for Language English.
4195238	4206398	669	A	1	And then part two, how do we go from having built that motif based compositional understanding to like now what can we do?
4206484	4212394	670	A	1	And then when are we just totally freewheeling and off the rails of the free energy principle?
4212442	4215620	671	A	0.99995	Or does anything go if the motifs allow it?
4216710	4219442	672	B	0.99968	Yeah, I wish I should have the standard answer.
4219496	4222626	673	B	1	The best way to learn string diagrams, I think, if I'm going to talk about it like this.
4222648	4224850	674	B	0.87257	So you prompted me to come up with that.
4224920	4226326	675	B	1	I don't have something on top of my head.
4226348	4226966	676	B	0.929	That's the best way.
4226988	4238646	677	B	0.99715	But there's so much stuff out there I think it tends to be because if you want to get really comfortable with the diagrams, you're learning category theory in some sense, but it's not like you need to learn all of category theory.
4238678	4260634	678	B	0.99649	It's kind of a relatively modern offshoot in this applied category theory world that's very diagrammatically focused and there will be various nice introductions out there to using them another way is to think I'm pretty sure recently yeah, there was a nice paper that came out, there was an introduction to string diagrams for computer scientists, for example.
4260692	4271266	679	B	0.99972	So there tends to be different introductions kind of for different audiences because they just want to pick categories that those people are familiar with.
4271288	4271426	680	B	0.92089	Right.
4271448	4272862	681	B	0.99993	So they can actually have some examples.
4272926	4276850	682	B	0.99933	You could just learn the diagrams totally abstractly, but it helps to have some examples.
4277590	4284706	683	B	1	And the old category free textbooks are all things mathematicians have looked at and other people haven't heard of, so they're not particularly helpful.
4284818	4291370	684	B	0.97876	So there's know Bob has paper categories for the practicing physicist that's aimed at physicists that would basically introduce string diagrams to them.
4291520	4293274	685	B	0.966	There's this recent computer science one.
4293312	4303760	686	B	1	I know there's some work going on in producing one for cognitive science, which I think would be really good having an introduction to the string diagrams for those people.
4304450	4309006	687	B	0.99997	So you basically look for one in an area you're comfortable with and you find a good paper on it.
4309028	4318926	688	B	0.99977	But it would be nice to have a good online resource, I guess, right, that gathers these together so people can just see a great guide for all the introductions.
4319118	4327078	689	B	0.99795	If you do something like there's courses you can do in the sense of the Bob's book.
4327164	4332562	690	B	0.99995	In the case of learning quantum, there's something like Bob's Long book with Alex Kissinger picturing quantum processes.
4332706	4337014	691	B	0.99845	That's the kind of thing I learned from like it was in the form of a lecture course.
4337052	4349514	692	B	0.76742	But it's basically the same book because then there's just loads of exercises that will make you have to reason with string diagrams and then you pick the rules up because at first you don't have the same intuition, obviously, but the rules what can I do with these?
4349552	4351562	693	B	0.99991	Can I slide them around like this or whatever?
4351696	4355486	694	B	0.93199	But it doesn't take too long to get quite used to it, I think, which is the nice thing about them.
4355508	4361790	695	B	0.96455	They're kind of natural, they're just these elastic strings and boxes and you have that sort of geometrical intuition.
4362210	4366020	696	B	0.17413	So things like that with exercises are the way I'd recommend getting used to using them.
4366870	4375480	697	B	1	I didn't use any software in a sense of the diagrams I draw in this program called Tixit, but it doesn't tell you how string diagrams will work or anything, it's just for drawing them.
4376970	4380680	698	B	0.95883	But I know there's more work to develop.
4381370	4393290	699	B	0.98272	Libraries like the Algebraic Julia project is sort of like an applied category theory language, but I wouldn't know if it was recommended as a way to first learn categories.
4395150	4395610	700	B	0.84497	Yeah.
4395680	4402560	701	B	0.7757	So I would recommend finding a nice introductory paper in whatever field you're most used to playing with some exercises to get really used to them.
4403170	4406766	702	B	0.99772	For causal models, there's this paper Robin and I put out.
4406868	4412986	703	B	0.99945	It's not necessarily the very first place to learn string diagrams, but the aim is to introduce to people who've heard of causal models.
4413018	4413838	704	B	0.30784	So in a sense of pearl.
4413854	4421278	705	B	0.96686	So just Bayesian networks, basically, but maybe the course interpretation of them to get them used to string diagrams.
4421454	4425960	706	B	0.98	And this paper hopes to be a little bit introductory as well.
4428170	4428918	707	B	0.96604	Cool.
4429084	4430280	708	A	0.75858	Ali, please.
4433690	4434370	709	C	0.9999	Thank you.
4434460	4440170	710	C	0.54295	So getting back to the question about the time representation in this formulation.
4440830	4458762	711	C	0.93773	So I take it that this kind of formulation of Bayesian inference, I mean, category theoretical formulation of Bayesian inference is largely based on tobi's Fritz definition of Markov categories as CD categories.
4458826	4459450	712	C	0.87255	Right.
4459620	4480550	713	C	0.97421	So as far as I understand it, Fritz paper kind of one of its basic assumptions is this kind of unidirectional inference, I mean, from earlier times to later times, right, or in other words, the prediction.
4480970	4499790	714	C	0.99968	But in quantum formulation of active inference or quantum active inference, there's this attempt to also develop the retradiction aspect of inference as well.
4499860	4500574	715	C	0.99863	Right.
4500772	4511742	716	C	0.88989	So would you say this recent formulation can also be accounted for, this kind of retradiction?
4511806	4519460	717	C	0.99995	In other words, can this formulation be reconciled with quantum Bayesianism as well?
4521030	4524030	718	B	0.97163	Yeah, I basically wish yeah, sorry, go ahead.
4524120	4557120	719	C	0.44898	Because to add one more context here, I think it was in Kirk and Speckin's paper, there was this clear distinction between classical Bayesian inference and non classical Bayesian inference, in which the classical one does not allow for the retrodiction, but non classical Bayesian inference can be applied for both prediction and retrodiction as well.
4558370	4566162	720	B	0.99547	Okay, yeah, I would love to be a bit more familiar with the quantum active inference stuff, basically, to compare a bit.
4566216	4573678	721	B	0.99637	So I'm not as familiar with the sort of retro sorry, what was the other version of prediction?
4573694	4574610	722	B	0.99853	It's retro.
4574950	4578050	723	C	0.40828	Retrodiction, yeah, prediction and retradiction.
4581690	4583430	724	B	1	I would have to compare with this.
4583580	4592540	725	B	0.7	I know the paper you mean Bob's Paper Frog on both forms of Asian inference to see what they say there about the classical one.
4593390	4599502	726	B	0.99996	Can you give some intuition as to why it isn't something you can do classically, basically, the retro one?
4599556	4604974	727	B	0.90499	Because if that's a general case about probabilities, then it will be true in some sense here.
4605012	4605214	728	B	0.99932	Right.
4605252	4608986	729	B	0.98929	So here it's just being modeled in this probabilistic category.
4609098	4617074	730	B	0.93	And so at the moment they're separate in that you have the model which basically goes forward and then you do your updating to try and approximate something going back.
4617112	4618980	731	B	0.99995	But you don't really have like this one.
4625610	4635670	732	C	1	The whole idea was that for predictive quantum mechanics, we only need to account for the inference from earlier times to later times.
4635820	4655550	733	C	0.99999	But if we want to account for retrodictive quantum mechanics as well, we need to somehow account for because as we know, not every quantum formulation follows the Bell's principle of local causality.
4658930	4670900	734	C	0.99948	In order to account for all the entanglement phenomenon so on, we need to somehow put this bi directional inference into our model.
4671430	4678470	735	C	0.94988	So, yeah, that was the basic idea behind developing this kind of non classical Bayesian inference.
4679290	4684498	736	B	0.87516	Does it have something to do with the unitary evolution in quantum theory the way that you have this reversible thing?
4684524	4692890	737	B	0.99624	Or is it exactly that was the gist of it, yeah.
4693040	4698438	738	B	1	And so you don't expect to have something like that classically, basically, where you have this reversible thing built in.
4698464	4713070	739	B	0.9929	Well, yeah, so I wouldn't expect to see that exact feature here in the sense of if it's treated, if it's basically something that you can't have in classical probabilities, it won't exist in this category matar plus.
4713220	4721326	740	B	1	I think that would be basically the same category they would use in that paper, and they work with dagger combat categories, and they'll work with something like this Matar Plus category.
4721358	4739450	741	B	0.37591	But the classical case, if it's just a general it's less of a sort of physical notion, but it's just an idea that the model comes with a forward part and a backward part, then I think that's the kind of here how you go from a forward part to approximate this backward thing.
4739520	4745718	742	B	0.99995	But the sort of lens type view of what's going on that's more studied in category cybernetics would be imagining.
4745734	4760740	743	B	0.97	I think the model kind of carrying this backward inference process with it as well, so that for each forward part of the model, you would have this approximate inference sort of channel stored with it.
4761270	4766260	744	B	0.98008	So I don't know if that would address what you're asking, but it would have a backward and forward part together.
4770070	4781174	745	A	0.99255	Well, Ollie, do you have any kind of closing opening remarks or questions or where do you see this going from the active inference side?
4781292	4795130	746	A	0.99999	What does this bring to us and what is opened through what has happened largely this year in active inference and category theory?
4796430	4802010	747	C	0.99956	Well, actually, I'm really excited to see this line of development in active inference theory.
4802090	4812180	748	C	1	And as you know, I'm a big, big fan of meta theories and all kinds of unification theories and so on.
4815430	4851866	749	C	0.99	I don't know, I kind of have this feeling, have this hunch that this line of development in active inference theory, it looks quite promising, especially for kind of tying up all the loose ends and transcending many, many other areas and discourses and ultimately reaching a kind of coherent picture of quote unquote reality, whatever it means.
4852048	4876898	750	C	0.94629	So, yeah, these kinds of development, I mean, the last year we had tremendous advances in Bayesian mechanical theories, and in recent months we have this fabulous line of research in category theoretical account of active inference.
4877074	4888870	751	C	0.99995	My hope is that ultimately these different strands can be unified into coherent and overarching framework.
4889030	4891020	752	C	0.99681	So exciting times.
4898270	4907422	753	B	0.856	So do you mean that you're thinking of it as it sounded like you're basically alluding to the work going on in cognition and work going on in physics coming together.
4907476	4907694	754	B	0.99208	Right.
4907732	4911034	755	B	0.99726	Like one really meta really open.
4911092	4912580	756	C	0.76102	Exactly, yeah.
4913110	4933750	757	C	1	The idea behind Bayesian mechanics, one of its premises or assertions was that there isn't any clear distinction between cognitive and non cognitive things or agents and they rest on a continuum.
4935310	4947078	758	C	1	The same kind of mathematical technology can be applied both for inert and conscious agents or sentient agents or whatever we choose to call them.
4947264	4975800	759	C	0.99932	So, yeah, this overarching theory unveiled many interesting phenomena regarding, well, self organizing systems, and it changed the whole perspective about how we can look at and even define consciousness, cognition, intelligence, sentience, and all of these related terms.
4976250	5005070	760	C	0.99926	So my hope is that category theoretical account of active inference can also be used for clearly seeing many of these emerging elements in Bayesian mechanics and active inference theory and hopefully, well, gaining some interesting and potentially groundbreaking insights.
5006690	5007610	761	B	0.93144	That'd be wonderful.
5007690	5015074	762	B	0.92775	Yeah, I'd love to apply for those topics, and I'd be very curious to see how categories can come in.
5015112	5015774	763	B	0.75853	Sorry, Daniel.
5015822	5016082	764	B	0.5577	Yeah.
5016136	5016786	765	B	0.63	Oh, yeah.
5016888	5019374	766	A	0.9996	I'll just give my closing thoughts then to you, Sean.
5019422	5023480	767	A	0.96402	Just a few loose notes that, again, open probably more than they close.
5024250	5039510	768	A	0.88077	Ali was right in suggesting and expressing that Bayesian mechanics recently has helped us develop a continuum of active and passive systems, so called living and non living, or inanimate and animate.
5039670	5048462	769	A	1	And that brings us to another dialectic to resolve, which is life and mind, which is where the physical and the cognitive science come together.
5048596	5050154	770	A	0.99992	You said they're on a continuum.
5050202	5052270	771	A	0.99985	Maybe we could say they're on a quantinium.
5052850	5059070	772	A	0.97	And what language could express such work?
5059220	5064366	773	A	0.9938	Well, right now we're speaking in English with the active inference ontology dialect.
5064558	5068046	774	A	0.99997	However, the phonemes are not intrinsically meaningful.
5068238	5073062	775	A	1	The M in a Markov blanket or category does not mean something.
5073196	5074920	776	A	0.99963	It's a sound.
5075530	5099246	777	A	1	And so the string diagram language and representation I see as a way to fuse and integrate semantics into the syntax of the actual inscription, which enables us to generalize in new ways.
5099428	5103374	778	A	0.99998	Also, recognizing string diagrams are not everything, and so on.
5103572	5129190	779	A	1	And then with all of these intersecting vectors from the cognitive and the physical sciences, we are able to take the compositional cartographic approach for cognitive ecosystems and talk about diverse intelligences, biological, quantum, classical architectures, all of these synthetic intelligences.
5129530	5158720	780	A	0.99	And so it's super exciting, and I appreciate again your visit and look forward to people's curiosity taking them and also the development of tools and educational materials that make this easier and then being able to display and use something where the meaning is primal rather than like, well, this letter represents this.
5160150	5175220	781	A	0.99843	It already introduces such a space between the analytical representation and really the string diagram, which exists isomorphically with it.
5179190	5182310	782	B	0.99457	Yes, I find this very exciting way of thinking.
5182460	5197882	783	B	0.99994	It sounds like you're advocating a kind of structural ontology kind of thing in some sense, right, where you're taking the compositional structure of what's going on to really be the meaning or really be the real thing that's there, not just like I don't know.
5197936	5206086	784	B	0.86468	Yeah, we could talk about it for a while, I imagine, but I would love to see string diagrams and other approaches.
5206118	5209142	785	B	0.97043	I'm sure that take that role.
5209206	5212580	786	B	0.78	And you've got me very excited about this kind of unification that's going on.
5214630	5215854	787	A	0.99993	Thank you again, Sean.
5215902	5219300	788	A	0.99969	You're always welcome, and we look forward to seeing where this all goes.
5219670	5220322	789	B	0.80101	Yeah.
5220456	5221474	790	B	0.99994	Thanks again for having me.
5221512	5221810	791	B	0.9198	Yeah.
5221880	5223150	792	B	0.99977	Really great discussion.
5223310	5224180	793	B	0.99883	Thank you.
5224790	5225970	794	C	0.95707	Thank you so much.
5226120	5226878	795	B	0.91123	Thanks, Ali.
5226974	5227394	796	B	0.77004	All right.
5227432	5227694	797	B	0.73749	Bye.
5227742	5227840	798	B	0.98725	Thanks.
