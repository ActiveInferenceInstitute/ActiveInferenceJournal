
00:07 Daniel Friedman:
Hello and welcome, everyone. It is September 1, 2023. We're here in active inference math stream number 6.1 here with Sean Toll. We'll be hearing a presentation, active inference in string diagrams followed by a discussion. This is super exciting. So if you're watching live, please feel feel free to write your questions in the Live chat. Really looking forward to this. So thank you, Sean, again for joining and to you for the presentation.

00:40 Sean Tull:
All right, thanks very much. Thanks everyone who's watching. And thanks to the organizers for this chance to speak to you and to Daniel for getting in touch and inviting me to speak. So, yeah, I'm really excited to share this work with this community, basically, and to hear from those people who work with active inference and do any formal work, what they think of what I'll present today. So I'm going to be presenting a formal approach to how you can describe active inference in terms of an entirely graphical language called the language of string diagrams. And it's based on this mathematics called category theory. And I won't assume that you're too familiar with this already and try and introduce it to you in the talk. And ultimately, I'd like to sort of convince you that this diagrammatic language will be really useful for those of you who work formally with active inference and encourage you to pick it up in your own work. I've just introduced myself a bit. I'm Sean Tull. I'm a researcher at Continuum, formerly a postdoc in computer science in Oxford, and a Continuum in this Oxford team where I'm based, where we study what we call compositional intelligence, which includes applying category theory to topics in AI and as well as this.
01:41 The project was supported by a grant from FQXi. It's located at the bottom and hosted at Topos Institute, which is the center for Applied Category Theory. So let me get think. So, yeah, here we go. So for active inference, won't spend too much time introducing it. I'll assume most people here are familiar with it, and many of you probably know more about it than I do, in fact. So I'll just mention the parts of it that I'll be addressing in the talk. So thinking of it as a model of cognition that simply we can think of as applying at many levels, say from a whole organism or just to a single neuron. And the key idea is that in this approach, you think of an agent that's coming with this generative model that it uses to explain the observations it receives from the world in terms of some hidden states, which you might call perception, and in terms of its own actions. And in active inference, it achieves both of these things through this form of Bayesian inference or an approximate form of Bayesian inference by minimizing this quantity called free energy. And these are the ingredients we'll be talking about in the talk.
02:43 And the thing that's really exciting about active inference, I think, for those of a formal background as well, is that it aims to offer like a very principled approach to cognition that you can hopefully apply at all these many levels. But I think at the moment it could also benefit from more formal work. And that's what this talks about. It's about formal approaches to the theory in particular, I think nice clear formatations or active instances would help to clarify sort of what the core of the key ideas of the theory are. So we'd like it to be this very succinct principle that ideally we just apply to a generative model and everything else follows from. And once we've got to this, we can hopefully generalize it, understand it better, and also make it just more accessible to those who come from formal backgrounds, like in mathematics and so on, and get them working on the topic very quickly and connect it with approaches in artificial intelligence as well. But the most important thing about a good formalization, I think, should just be to make learning about active inference easier, make the framework simpler to understand. So that's what we're aiming for in this work.
03:44 And I'd say in other places already there's been some calls that some suggestions that an is formalization of active inference should be a diagrammatic one. So when you look at the generative models that come up in active inference a lot, they're very compositional in their nature and it's very natural to draw them in diagrams. So it would be nice if our whole approach to describing it could be graphical in this way. So just for example, there's this paper called The Graphical Brain by Kristen Par, and in general, we've probably seen loads of these diagrams describing generative models where you draw many compositional features of different spaces of hidden states, observations, interacting and so on. So these diagrams are used, but they're just used to represent the model. You still have to then go to doing sort of traditional probability of theory calculations when you reason about them normally. But in fact, there is a whole graphical, formalism and mathematical language for describing these kind of interacting processes just entirely with the diagrams. So the area of mathematics is called category theory and the language are these string diagrams I'm going to talk today, and in particular, there's a lot of work going on in applied category theory now in how you can describe aspects of probability theory and causality and causal models in terms of string diagrams.
04:57 And these causal models are basically based on Bayesian networks. So the same formal structure as the generative models in active inference. And in particular, what I'll talk about today kind of draws on this paper co authored with Robin Lorenz, talking about causal models in the sense of pearl in terms of these string diagrams. So it's basically causal Bayesian networks, which is the same formal structure as we'll be talking about today. So in this talk I'm talking about this paper, which was joint work with Johannes Kleiner and Ive, which is called Active Inference in String Diagrams, a categorical account of processing and free energy. And basically what we do is try to give a formalization of active inference that's nice and clear conceptually just entirely in terms of string diagrams. So we're basically taking the kind of formal content that's in something like the active inference book and turning it into these diagrams. And as I mentioned, it was done as part of this FQXi project that was actually on a project about consciousness as about ways that category theory can be applied to theories of consciousness. And we've done some previous work looking at the integrated information theory of consciousness and of course there's all sorts of ways that active inference has been proposed to connect to consciousness.
06:06 But for the purpose of this talk, we won't go into any of that. It's just a theory of cognition. I take it to be here and I'll just mention at the end it'd be nice to connect it back up to consciousness in future. And there's also lots of other related work going on in category theory that's very close to this, that often goes by the name of categorical cybernetics, and this might include some of the things Toby has talked about on the stream in the past. So what I'll do now is introduce categories and string diagrams and then later we'll apply them to all these basic ingredients of active inference that I've alluded to so far. So that would be generative models updating them, free energy and active inference itself. Let's start with these categories and string diagrams. So you can think of a category in general as a sort of world of interacting processes. And the categories we're talking about here are always going to be these symmetric minoidal categories. But don't worry too much about the formal language because the way we talk about them is just going to come down to the diagrams here today. So a category amounts to a collection of these objects, or sometimes called systems, like this Capital ABC here, and what are called morphisms, or you might want to typically call processes between them.
07:11 So when you're writing normally, you can just write a morphism from A to B as like this f colon A to B. In string diagrams, though, you draw it like this, where we're reading all the diagrams from bottom to top in this talk. So you have a wire for the A input at the bottom and a wire for the B output at the top. And the morphism is just drawn as a box F here and you just read the diagram up thinking about, okay, it takes in this input coming in on this wire, a process applies and then you have your output of type B at the top. So what you can do with these processes is compose them. So if you have two processes, say your F from A to B and G from B to C, so the types line up, you can just compose them in sequence. And this just means plugging the boxes together in your diagrams. And because we're in this Minoidal category, you can also compose in parallel. So you have this operation called the tensor, which means given two objects, you can put them together to build this composite object. So AB goes to a tensor B, you'd say, and you can also do this to morphisms, so you can build this F tensor G. But in the pictures it just means drawing them side by side.
08:13 And you just think of this as meaning we have F from A to C and G from B to D, and they're just running in parallel and they're not interacting essentially. So most of the time you just draw a picture like this and you don't even need to write the tensor symbols. So if these two basic modes of composition and from these you can build much more elaborate string diagrams in your category. So if you're writing things very mathematically, you have to write lots of equations that a category or Minoidal category needs to satisfy. But when you're working the diagrams, they basically do some of the work for you because these things just come out for free. So, for example, you have equations like this that you'd have to think about when you're working with them in the conventional mathematical way. But in the diagrams it just means if you have two boxes, you can kind of slide them along the wires. It doesn't really matter where they are on the wires, it tends to just be the connectivity that matters. Similarly, we can cross wires over each other because we're in the symmetric setting and there's a few just useful features that you'll have in a category. So every object comes with this identity morphism, which you just think of as meaning nothing happening basically. So it's just drawn as a blank wire.
09:15 There's also a kind of identity object, as it were, called a unit object, which is just empty space, so you don't even draw the wire. This dashbox just means nothing. It's meant to be an empty picture. And the latter thing is just useful because it now means we can talk about amorphism, which doesn't even have an input or an output. More formally, it has this object I as it's input by output, and we give these things special names. So the most important one probably is that of a state, which is a morphism with no input, as it were, or really with input I. So in the pictures it just looks like this. So there's no wire going in. And you'd call this a state of A. You can also have a process that takes in a if it has no output that you'd call an effect. And if you have naive, you just call this a scalar. So this is just going to be like a number basically floating around next to your diagram. So there are many categories out there. The point of category three is extremely general. So this could be talking about computational processes or physical processes or quantum processes in particular, and all sorts of things. For this talk we'll only actually need about one category.
10:17 We'll just keep it simple with this one. That's the category. I call it matar plus. So it's positive real matrices. So you can just take objects for the wires to be finite sets and the morphisms to be positive matrices indexed by these, as I'll explain. So if we draw a box like this, M, going from X to Y, this is like a matrix indexed by X and Y. And for each input in this little set X, sorry, in the set X and each output in Y, you'd get a positive real number and we'll write it like M of Y given X. So this box would mean a function like this. Now, when we plug them together, they let us turn some things that you normally have to do with equations into kind of simpler pictures. I mean, mainly this middle one. So if we have two in sequence, we just compose them by matrix multiplication. So instead of having to write this formula where we sum over Y, we can just draw this picture above it where we just plug them on top. And if we run them in parallel here, we take the cartesian product of the sets and the tensor product of the matrices, as it were.
11:18 But it's just the obvious thing where you have two things running independently. So in particular a state tier ends up the minority unit is just a singleton set and you can basically just ignore it. So a state tier amounts to just a function sending each X to a positive real and affect the same thing. And a scalar would just be a positive real. The intuition though is that we're going to restrict the particular morphisms in here, which are probabilistic in the nature. So they need to send each X to an actual distribution over Y. So I want to talk about how you actually pick those up next. So to do that, you use some extra structure that this category has. It forms what's called a copy discard category. So this is one more bit of mathematical sort of gadgets we have around. So that is that each object comes with these distinguished processes. There's one that we call copy that takes in a say and brings up two copies of A at the top and one called discard where you just throw A away so you have no output at the top. These satisfy some equations that are quite intuitive if you think about like copying and then throwing away one of the outputs is the same as doing nothing.
12:25 So it's. This blank wire copying is symmetric and associative is the last one. So in this category, mad or plus discard would be just the function sending each element to one. And the copy would be like a delta. So A comes in and two copies of A come out. At the top is the intuition. The reason we introduced this stuff is because it's been shown recently that you can do a lot of probability theory just in terms of these CD categories and particular ones called Markov categories. So there's a lot of what's going on in applied category theory at the moment, using this language of CD categories in particular, they let you pick out some things to do with probability theory. I'll just talk about a couple of them here. The most important one is the notion of a channel. So this is what lets us pick out the actual normalized matrices, as it were, from earlier. So in general, you call amorphism a channel when it preserves this discarding. And a special case is a state in which when it's a channel, you call it normalized. So for a state, this means it would actually be a probability distribution. So it's actually normalized if you sum over the values with this omega, you'll get one.
13:27 And for a morphism being a channel, it means it sends each input to a distribution. So it actually is a probability channel in the usual sense. Equivalently, the matrix for F would be stochastic. So these are the ones we'll use in generative models, for example. And as I said, there's lots of probability theory you can describe with these diagrams. It's very two simple examples. You can describe marginalization in probability theory with this discarding thing. So if you have box omega like this, it would be a joint distribution over X and Y. If you just discard Y, you'll get the marginal on X. And if you plug omega A distribution on X into an effect, that would just be any function on X, this would be giving you a scalar now, and that would be the expectation value of E in this distribution. So I'll meet lots more of this as we go, but let's actually start doing some stuff related to active inference in particular now. So I want to talk about generative models and how you view these in the diagrams. So, as we've said, we're going to be talking about agents having generative models that relate things like actions, observations and world states.
14:29 And these are normally quite compositional in active inference, right, and might involve many different spaces of states and observations and these processes relating them. You'd usually treat these as something like a Bayesian network, claiming you can view it really as a causal Bayesian network because it's sort of describing how states are causing these observations. Formally, it's the same thing. It's just Bayesian network, which you could normally say is described as something like a dag, a directed asynchronous graph, which describe the different variables that are being related and then sets the values for each and probability channels, describing each one in terms of its parents in the Dag. And then you often look at its whole distribution over all the variables. But already I'd say the way that these visual networks are drawn in active inference text and stuff is kind of converging on something a bit closer to string diagrams because you don't actually just draw the Dag and the variables. It's very useful to actually give names to the mechanisms themselves, as it were, like you have in this picture, the A and the B's. So yeah, my claim is that it's sort of converging on the way that string diagrams will look, as we'll see on the next slide, which is where you really do label everything, not just the variables.
15:37 So to describe those sort of Bayesian networks with string diagrams, the key observation is really that Dags correspond to a certain class of string diagrams that we're called network diagrams. There's a definition here, but which is better just to see an example in a second. But the diagrams built from copying and sometimes discarding and the key thing is just that they only have processes with maybe many inputs but only one output. So this is going to be like a mechanism that produces each variable. So the result is that if you have a Dag G and you choose some of the vertices to be outputs, so those are like the observed variables, you can draw a network diagram which expresses the same equivalent structure with those things as the outputs. So here's an example. We have a Dag with these four variables, x one to x four. And what you do is you have a wire for each variable in your diagram on the right and you draw a box that produces it. It doesn't really matter what you label the box. So this box C, for example, produces x two and it will produce it in terms of its parents in the Dag.
16:39 So x one and x four in this case. And if it doesn't have any parents, it would just be a state, as it were, box and no input. And then what you do is you take each variable and you copy it and you pass it to all of its children in the Dag and also out of the diagram if it's an output. So this now means you've sort of expressed the whole structure of the Dag and also which variables are sort of leaving the system for the output ones. So this allows us to turn Dag into a string diagram and then if we want to make a generative model that expresses like a Bayesian network that's structured according to this Dag, you just have to now interpret this diagram in a certain sense. So in general, working in any one of these CD categories, this copy discard categories, we can say that a generative model in there is given by one of these network diagrams without any inputs and an interpretation of the diagram. Meaning you actually say what the objects are for each of the wires in the diagram and what the actual channels are. So they need to be channels, not just morphisms in your category are for each of the boxes. So for a gender model like this, you would say you pick objects x one, x two, x two, x four and pick channels for the ABCD.
17:46 And we'll think of the output of the diagram as like the observed variables and the rest of the hidden ones. So for example, if you're working in this category, Mat R Plus, that is the only category I've actually introduced here. So this is going to be our running example. This is the same thing as one of these causal Bayesian networks. So it just means picking sets of values for variables and picking probability channels for the boxes. So you might ask why would you use this representation rather than the usual one, which I think is a good question. So it's equivalent to the Dag and probability channel description. But the thing that's nice is that in the conventional approach of these networks, you sort of have to switch between the Dags, which are split the variables and then doing calculations with probabilities, whereas in the categorical approach you can use just one formatism because you can do probability theory with the string diagrams as well. So it's quite natural in that sense. You have this one language of both just intuitively drawing what's going on in a model and then reasoning about it. It also lets you start to generalize things in a useful way, I think.
18:46 So I kept having to say that you have no inputs to your diagram, but there's nothing really fundamental about that and it's not really clear why we need that. What you can do instead is start to allow inputs to your model as well. So we'll call this an open generative model. So an open generative model is the same thing. But now I've just dropped this requirement, the diagram doesn't have any inputs. So here's an example of a general network diagram. Now, with these inputs x two, x three. So there's no mechanism specified for these new variables, x two, x three. They're just input variables to the system and they can be outputs as well. For example, x three is both an input and an output here. And again, an interpretation of this general network diagram just means picking the objects and the channels. This is the same definition we use to define what we call an open calls and model in the paper with Robin Lorenz I mentioned earlier. So an emergenerative model is formally just the same thing, but we're just thinking of it as a generative model possessed by a cognitive agent. If you run this definition in mathar plus then this is just like a causal Bayern network.
19:47 But now you have some of your variables just have no mechanism specified. So they're just inputs to the whole thing. The nice thing about these open generative models is that because they can have these inputs, you can plug them together and compose them. These things in fact form their own category. But I won't go into that today. So that was the general theory of these generative models that just actually described some examples that you'll see in active inference coming up all the time. So it's a simple example. Let's just imagine we have one space of hidden states and one space of observations. Then it would be generative model of that form would just look like this network diagram where there's just two wires, there's just S and O. S doesn't have any parents, so it just has this prior distribution sigma over it. And there's just this one channel often called the likelihood from S to O. If you just draw that network diagram, say that model in C or in Matar plus it would be the same as one of these simple generative models. When you're looking at these, you're often introduced interested in this distribution over both variables together.
20:47 This joint distribution that you might write as P of S times P of O given S normally or bit more specifically here introducing the names for the two distribution in the channel here in string diagrams, it's just the same as this. So you just take the prior and you make it an output now. And then you compose those channels together and this would give you a distribution. So a normalized state M over snow at this. So this is just the resulting joint distribution you get from the generative model. And we'll come back to that later. So, a more elaborate example of generative model that you'll see example in the active infants textbook are these discrete time models that are used a lot. So I'll walk through this diagram now, so this is an example of a more complex network diagram and a generative model it describes. So here we've got these end time steps going. Remember, we read from bottom to top, but I'll just talk about I'll describe things from the top down here. So at the top we have the observations one, two up to on the observations at each time being caused by these hidden states s one, S two and SN at each time by these channels A.
21:57 And the hidden state is evolving over time by this transition channel B, where it takes the previous state as an input and then choose the next one. It also takes us one extra wire that's coming from the bottom and that's this space P of policies, which is how the agent sort of actions enter the picture. So these policies describe its behaviors, its behavioral policies it can carry out. So, based on the previous hidden state and the way it's acting. This channel B would determine the probabilities for the next states and then there's supplier over the policies that you can think of as the habits or the typical behaviors of the system. So you can just draw this diagram and say, like, interpret this in math plus and that would for any given interpretation, meaning any choice of what the values for these variables can possibly take are. And any choice for what these channels are would then give you this type of punitive model. And often you will see models sort of of this form or similar forms being plugged together to form these hierarchical models. And I think the compositional language is very nice for these because you really want to talk about open models to define this so hierarchical model you can view as really as just being given by taking lots of these open generative models I mentioned and plugging them together in a certain sense.
23:08 So here you can see a picture of a hierarchical model where we just have these layers where different copies of the same model at each layer and the inputs from one layer match the outputs of the layer below so we can compose them together. So that's generative models. So so far we've just been using the diagrams to represent them. We'd like to actually do a bit more though and reason about these models. In particular, we'll talk about how you update a model or update the beliefs within a model, which is very important in active inference and how this looks in the string diagrams. Now, so let's say we've got an agent M, we have a model M and it's just a simple one where we say there's just one space of hidden space S and one space of observations O. So they have this joint distribution that I mentioned earlier and they had these prior beliefs about s which you can get back from the joint distribution by just taking the marginal, if you like. So that's sigma. So they've got their model, they've got their beliefs about what states are likely and then they receive a new observation. And here the kind of observations we'll think about in general can be soft, meaning they're described by a distribution over O, not necessarily just one element.
24:15 So that would be one of these normalized states. I'll try not to use the word state here because it's a bit confusing with this S around. So this distribution over O is their new observation, this bold font O. And now they want to update the margin, want to update M in some way so that the marginal basically is different and describes the updated posterior beliefs. And this comes up of course in perception where you're updating your sort of state of the world given some observation you receive. But it could also be used to model like planning behavior where updating your plan of action, your policy given something like. Which outcomes you'd like to see in the future and we'll come back to that later in the talk. So we want to talk about how you can do this updating. So you might think there's just a standard answer or at least in the ideal case, which is this Bayesian updating. And that's true when your observations are sharp. We'll start by talking about that case. So I'll say what sharp means in a second. But first I'll just talk about how you treat Bayesian conditioning in these string diagrams.
25:17 So on the right here we have if you view this process from O to S, this describes the sort of Bayesian conditional channel, or in general a partial channel in fact that the agent would have from the introduced by their model. So you can describe this in string diagrams with a couple of extra gadgets I hadn't mentioned yet. So you have your distribution m over S and O. You can have this in math there's this effect that we call the cat which just takes two inputs and compares if they're equal. This allows for you to turn an output into an input. So that's what this part here is. And then you can introduce this extra thing of normalization. So what you'd like to do is take a general morphism and for each possible input normalize that so that it's a distribution if you can or set it to zero if it's just zero and there's nothing you can do, that's what this blue dash box is. And in the paper and in the related calls and models paper, we talk about the axioms normalization feature satisfies. The point is if you compute this thing in Matar Plus, it will give you kind of what you'd expect.
26:19 So it will give you the usual notion for each .0 of the space O, you plug it into this, you'll get a kind of conditional M of S given O that you'd expect whenever that's defined. There's a strange diagram way to describe this kind of Bayesian conditional channel or partial channel. And I said this is what you would use when your observation is sharp. And I also drew it differently with this triangle to sort of distinguish that case. So what does that mean in general? You say that a state in one of these CD categories, so a distribution basically would be sharp when it's copied by the copy map, which isn't true for general distributions. And if you run this definition in math or plus, this really means that this thing O really is just point distribution at some specific element of O. So it really is sharp in that sense. It's just a point. There's no real probabilities probabilistic aspects to it there. But in any CP category you can just talk about the sharp states like this. They're often also called deterministic.
27:21 So for these sharp ones, you ideally think you'd like to do the spacing updating. But in fact when you've got soft ones. So it doesn't have this property. There's actually at least two good ways to do this kind of updating. I don't know if this is as well known, so I'll just mention it now anyway, and they've been studied in some detail by Bart Jacobs, this paper at the bottom. So let's say you don't get one of these sharp observations. You have just a distribution over o. There's at least two reasonable ways to generalize sort of the picture from the last slide to give a notion of updating. And Jacobs calls them Jeffries and Pearl's update rules. So in Jefferies Update, you basically do it like we did before. You have this Bayesian conditional kind of channel or partial channel, the normalized box here, and you just plug a distribution into it. But in Pearl's Update, you turn a distribution into an effect. So you just compose it with this cap to bend it around in the picture. That's what it means. So you plug that into M and then normalize everything. So the difference is where the normalization happens. And yes, it's basically just interesting that both of these are reasonable notions, generalization, they have different properties.
28:25 It's not obvious that one of them is sort of more rational or something than the other. They just behave a bit differently. In the formula you can see that the normalization is being applied differently. So if you turn this picture into these little notations, it would look like this. So in the top case you're normalizing for each possible sharp o and then taking an expectation over this distribution here. Whereas in the Pearl case, you plug the whole thing together and then just normalize. Either way you do it though, the point is that these things are actually hard to compute. So we don't expect a cognitive agent to be doing either of these exactly, even in the sharp case. And so, as we know, we want to instead approximate these kind of things using free energy, which is what I'll talk about next. So our aim is to try and accommodate free energy somehow in the diagrammatic approach and free energy sort of formula that come up are often given in terms of what you call the Surprise, these negative logarithm quantities. So we'll start by introducing just a new graphical component for treating those that we call log boxes.
29:26 If you have any function E on a set X, a positive real, remember that made in A, that would look like an effect in your category X in Math Plus. Let's say then what we want to do is talk about this function X goes to minus log of e of X, which we call the Surprise. So we just introduce this graphical feature where we draw a green box around it and say that denotes this function. Now, and using rules, the nice properties of logarithm, you can turn these into nice graphical rules. This log box feature would satisfy for example, this is sort of the way that logarithms turn multiplication into addition on the left here. If you have this around, then you can start talking about surprise. So if you have two distributions, sigma and Omega, the surprise of one distribution relative to the other is defined by this expectation value. So just the expectation of a surprise of sigma according to Omega which if you remember I said expectation values are given by sort of plugging a state for the distribution into the thing you're looking at the expectation value of.
30:34 So that would be the log box here. So we can just define surprise omega, Sigma in this way if we like in the pictures. And important special cases where this come up are when you're calculating entropy, which is the self surprise. And the KL divergence can be calculated from the surprise and the entropy. So it means that whenever we have formula given in terms of these if we like, we can instead denote them with this graphical symbol, at least with the log box. So now let's talk about how we use this to describe free energy. So what we wanted to do in the paper is sort of help clarify the kind of different notions of free energy that we found in active instruments. In particular the variational and the expected free energy energy. So we want one more general quantity that we can understand both of those in terms of. I'm just calling out the free energy here. I'm interested to know what other people think of this sort of naming for what we're doing. The situation is that we've got some generative model that's fixed over these two variables Sno like before. So remember we had this distribution, this box M over Sno distribution.
31:36 And let's just say we have another distribution Q now and we'll see examples of this in a second what sort of Q they would be. Then we just define this quantity of free energy of the one relative to the other in this way. So it's the surprise minus the entropy of Q in the string diagrams. Then it's just this feature we plug. So it's like the expected surprise of M for Q minus the entropy of Q's marginal on S. Or this is the formula if you want to use the conventional notation which is useful for relating it to existing approaches. So we can define this very general free energy quantity and then we'll meet two special cases of it that we're interested in, which is the variational and expected free energy. It all comes down basically to having a definition of surprise. You just need this notion of surprise to define everything else. So with a variational free energy. So we have this fixed model M and we have this soft observation o like we did before. So that's this box here and then what we're doing is we're considering different possible distributions over S that we think of as different updates we could consider for our beliefs.
32:42 And we define the variational free energy of any of those states, those distributions Q as the special case of the definition from the previous slide. So it's like the general free energy where that capital Q just takes this form. So it just consists of our new beliefs, lowercase Q and our observation O. So in formula you could also just draw it like this. So you take the surprise from your model M and you just see how its expected value for those beliefs and that observation subtracted the entropy of Q. And what you can show is that this VFV value satisfies this bound of the KL in relation to this kind of Jeffrey update of your model with respect to this observation. In particular, when it's a sharp observation, then the minimal of this VFE will be given by the Bayesian Updating. In general, though, we might think about what happens. So in general we can think of minimizing this VFP quantity as doing this, as finding this Q that approximates this kind of updates we were looking at earlier.
33:45 And yeah, in the sharp case it will coincide as all of the notions of Updating do. So the minimal VFP will be given by the Bayesian update. But for these soft observations, it's something else. It's not exactly either of the two notions Updating we met earlier. So this is actually a third notion of updating for soft observations, which I think is an interesting way to think about what VFE minimization is doing. So we just call this the VFE update. So you've got many different Q, you could calculate the sphere quantity for each and you've got a soft observation O here. So it's some distribution. And if you find the one with the minimal value of sphere, you call that the VFE update. And this wouldn't be equal to either those Pearl or Jeffrey style updates that we met. So that's the VFE which we'll come back to, the other notion of free energy we want to talk about, it's the expected free energy. So that's where we still have our model M. But rather than an observation, we think of ourselves as having some preferences of observations we'd like to see they're again encoded in a distribution, though over O.
34:48 So that's this C just with that fixed, we can define this one quantity called the expected free energy. So that's given by the free energy of M compared with this other generative model where you have used the same. So this M here would really be the inverse channel from O to S of M. So like the Bayesian inverse here, but where you just assert that the preference is actually is the prior on the observation. So you're comparing these two in terms of this generic free energy quantity we defined earlier. So again, you can turn this into formulae. And there's loads of stuff in active inference about the different rewritings of EFE and the ways to interpret them in terms of uncertainty and risk and so on. And it has this property that you can show it will be bounded by the surprise of those preferences for your model and it kind of gives you a way to approximate them as we'll see. So I won't talk, I don't think I have time to go too much more into EFE. But the point really in terms of what this work's done is just to try and have just one generic free energy quantity we met earlier where we can see the VFE and the EFE both coming up special cases depending on what we plug in here for the two distributions.
35:59 So what I'd like to do now is to sort of put some of these pieces together to show what active inference itself will kind of look like in terms of string diagrams. And in particular, what we'll do is derive this formula that you'll find in active inference textbooks in a graphical way and I think quite a transparent way, that's the claim. So to do so, we basically need to give a nice high level conceptual view of what active inference is. So this is the way that we do it in the paper. So when inactive inference, the key thing for stating all the definitions is that our model takes the following form at a high level. So there's some notion of so. It's like our discrete time model we had earlier, but just with two time steps. If you like, each of those time steps could break down in terms of further subtime steps. But that won't matter. We've just obstructed here at this higher level. So at the higher level, we just have a notion of the current time, or maybe like all the time steps up to the current time, and that's this S and O here. So there's current states and current observations and then there's some notion of future times, these future states and future observations.
37:00 So that could be all the time steps up to some big number, something like that, all grouped together in one of those discrete time models. And again, we have the policies and we have the same sort of shape of model where there's some channels here which I haven't bothered giving letters to, but showing the way that the policy influences the transition from the state to the future state and observations from each. So we just have a generative model where we have policies, we have states and observations, and we have future states and future observations. In active inference, what we're doing is we're receiving two things. We're receiving an observation in the current time and we have some preferences about what we'd like to see in the future. So these are each given by these two distributions, bolton, O over O, and the preferences C over the future observations, and then we're doing updating with those. So I think updating is just our habits, the prior over the policies to give our new distribution over policies which we can think of as the agent's plan of how it wants to act.
38:02 So we're going to try and do this updating like before to obtain a new distribution over P. And that is now telling us how we want to behave in the future in a way that will basically you can. Think of it as saying, we want to explain why we're seeing what we're currently seeing and how we're going to obtain what we'd like in the future. In the books kind of inference and various places you can find a formula like this that there will be justified as coming from the free energy principle in some way. It's basically saying you can do this approximately by making your plan distribution take the following form there's a soft max, there's a part relating to the habits of your model so that's your prior over policies. These pi are the individual policies in P and then there's parts of formula related to the VFE and the EFE. And what we wanted to do is see where this formula comes from in a sort of nice high level way from the structure of the diagram. So there are explanations for this formula there, but I found them quite hard to follow, to be honest, because they were talking about the EFE as being a prior that you then do EFE kind of minimization on top of.
39:12 But you kind of need to do the part about the present time first before you can do the EFE. And so what we wanted, this is a really clear way to see how this just drops out from the structure of the model. So that's what I'll try and show now. So what we'd like to do then is to do this approximate updating. We're going to do the pearl style updating which looked like this in the pictures. So we want to get our new plan so our distribution over policies by updating, by plugging in our observation and our preferences and then normalizing everything. So the thing on the right is what we'd like to have ideally but we're just going to have to approximate it in some way. Let's just take the distribution that's inside the dash normalization box. Now this is the thing we'd like to basically approximate this in the structure of our model. We can write it like this and I'll just show then some graphical steps for how we can apply approximations to obtain the formula that we saw. And obviously we won't be able to go through every detail of the proof but it should give hopefully just some intuition for what it's like to actually work with a string diagram.
40:15 So that's really why I'm showing it. So we knew our model take roughly this form. There's some part relating to current states and current observations and also future observations. I've just called them both M here, but we just know there's that part of the model relating to the present time and future time. And so what we're going to do is first focus on this part of the model relating to the current state and the current observation. And we want to approximate what's in that blue dashed box. And what you can show is that if you do this VFE updating, that will be approximately equal to this part of the diagram. So this Q is given by for each policy doing this VSE updating, so minimizing your variation of free energy. So you do that for each policy. Then you can view the collection of all of those belief updates as just one channel from P to S. So if you think about it back here, basically for each policy you could plug in you would obtain just a distribution now of snow and you could do updating with respect to that.
41:15 That's what Q of that particular policy pi would be and you put them all together into this one channel Q and you can show then for each one, if you do this overall process where you multiply by this E to the minus VFD quantity here, it will be approximately equal to this part of the diagram. Okay, so that's our first step and that's how the VfB entered the picture. Then we've got this top part of the diagram, we'll collapse it together and just view this as one process going into future observations and our preferences. And we'd like to approximate what's in this box now. And this is where the EFB comes in. So you can basically show because you have this, the expected free energy will give you an approximation to this here where this is basically like an expectation value for your preferences for each policy. So this would be like the density C of those preferences being plugged into your model for each policy. So I haven't had time to go into the full details. These of approximation steps but they're essentially the same approximations you'll find in active inference text and so on, just turned into the string diagrammatic setting and we talk about how they come about from Jensen's inequality and things like this.
42:29 So this step where you think about the future times is called the prediction step and the previous one was the perception step. So now we've rewritten that diagram in terms of some e to the minus of the VFE and e to the minus of the EFE as well as our habits. And remember what we wanted to do was approximate the normalization of this whole thing. So that's when you apply this blue dash box around the whole thing and now if we do that, this is exactly the same as the formula we were after. So we've obtained the formula now and that's because you're normalizing something but it's got these e to the minuses in it. So you can also rewrite that in terms of this soft max where now you just replace the E with this log and the other ones you lose the exponentials. So this formula, if you wanted to, if you wrote out the formula for what this was for each policy, it would be equal to this down here. So the claim is that this is a nice way to derive this formula and is a bit more transparent than the ones that exist. So the idea was really just to see we draw what's going on. Okay, we're doing updating with the model of this form and we're trying to do this approximate form of updating and just see where we're applying the approximations and from the structure of the model itself, see how this formula comes about.
43:42 Okay, so that so far basically just talked about things that are already there in active inference as it's new derivation, but it's existing stuff. Before wrapping up, I'd just like to also talk about something bit more new that we do with the string diagrammatic approach. That's to talk about the way in which free energy itself is compositional. So the motivation for this is that the idea is that we want to think of this one free energy principle applying at all levels of a system. So to do that, you'd want to know that an agent can say if you've got one of these big composite generative models, that it can do its free energy minimization on the whole thing by doing it on the parts. Because we want to ultimately think it just comes down to each part doing its own bit of free energy minimization. So that's what we want to make precise. In particular, we're going to be talking about the VFE here really all the time. And if you recall in the diagrams, it looked like this. So we use this log boxes and it just took this particular shape here. So what we do in the paper in order to address this compositionality problem is introduce a notion of this VFE that we can apply not just to generative models, but ones which actually have these inputs as well.
44:52 So these were what I called open generative models earlier because we need to really talk about pieces of generative models plugging together and give them a notion of free energy to even make sense of this notion of free energy being compositional. So we proposed this definition of what we call the open VFE. So now instead of just a distribution M over S and O, we have a channel from some inputs to S and O given by one of these open models. And our Q, the thing we're doing the VFE minimization with respect to. So the thing we're calculating, it would now have an input as well. So it's a joint distribution over the states and inputs and observation takes the same shape as before. So you get this other formula that's basically just a natural way to generalize the previous VFE formula to accommodate this extra input wire. I now and what we show is that this thing is compositional in a sensor that I alluded to. So I'll walk through that and the way you do it is just using these graphical properties that these log boxes have that I mentioned earlier.
45:52 So you could turn all of that into a proof and standard probability notation if you like. But it's quite instructive to always just be able to work in the diagrams to keep track of the compositional structure of the models and so on. So the result says that this open VFE quantity is compositional in two ways. The first one here is this quite trivial way. So if we have two models running in parallel, so like taking the tensor of them and they're just both doing their own, we're calculating the VF for each of them. Sorry for the whole thing, but it's just given by two running in parallel, then it's just the same as calculating the V of V for each individually and adding them together. So that certainly what we'd like to happen. And it just follows from the properties of these log boxes. More interestingly, there's the second way in which it's compositional, which is the sequential mode of plugging models together. So if we have an open model M one and some inputs into some outputs one, but those are now actually the inputs for the second model and we have these running. So the first generation model is passing stuff up to the second one.
46:56 And now we want to calculate that result VFE in terms of an observation. We can again write it as a sum of two of them, but in a slightly different way. So observation is just existing on the top wire, right? Because it's just the output of the whole thing that gets this observation. So it's just on O two. So first we calculate the VFE for this model at the top m two in the usual way and then we add on a Vfe calculated for the first model, but it doesn't really have an observation one, right? But instead the observation it uses is one that's being passed down from M two. So that's the queue that M two is using is passed down now as if it's an observation down to M one. So it's kind of like O two receives this observation, does its updating about Q or whatever, and passes that down to M one. So in this way we can say that the VFE composers in that okay, both of these are minimizing VFE locally, where for the M one model we mean it's minimizing it with respect to these cues that are coming, for these O ones that are coming down from above.
48:02 Then the whole system is also minimizing its VFE because it's just given by summing those two together. So I talked about a lot of stuff. Now I'm just going to wrap up now and then we can go to a discussion, I hope. So the main takeaway was just meant to be to try and show that these string diagrams provide some natural language for talking about active inference. And I would encourage you to try anyone working on active inference formally to take a look and see if they would be useful to you in some way. And in particular, I focused on some of the what I was calling the main ingredients of active inference, so that were generative models, the way you update them, and free energy. And we saw sort of ways you can describe all of those notions in the string diagrams. And the thing that I think is useful about them is that they give you a nice representational language for just drawing pictures of your generative models and composing them like hierarchical models and so on. But they also let you do the reasoning because you can do probability theory with them. So you can actually reason about what's going on in active inference just with the diagrams themselves.
49:02 There's loads of directions. You can take this in the future. Obviously we could keep absorbing more of the work without the native inference into the diagrams. Bit more interestingly, we introduced this new notion at the end of how to make free energy compositional. In particular, we gave this definition of VFE for an open system now so it has a generative model which can have inputs. We call this the open Vfe. I just be very interested in what people think of this definition we introduced and whether it seems meaningful. Secondly, well, throughout the talk I kept talking about just minimizing free energy and that's all I said already, the Vfe. I didn't say how you do it. So in fact, this is normally done with these various algorithms of message passing algorithms. So they're an important part of active inference as well. And I think it would be great to include these in the setup by having some diagrammatic story of them. There's lots of other questions around. So one of them is that I talked about these two notions of updating with respect to soft observations.
50:03 And I think normally people tend to focus on sharp observations, so they perhaps haven't. Not everyone has heard of these before, but it's very natural to treat the soft ones when you're working this compositional setup. And so there you start to wonder about which of these, the Pearl style updating or the Jeffrey style updating is more natural to think about in the context of cognition. And maybe we'll say, okay, well really VSE updating is the one you should be thinking about. That's probably the claim accurate inference would make, but it'd still be nice to think about how this relates to the other two. Is it best thought of as approximating the former or the latter style of sort of precise updating? And then finally we. Could try and connect this up to lots of further topics. I mentioned I'm a continuum, and we're interested in this notion of compositional intelligence. So it would be nice to connect this now to topics in AI and so on, and think about how it relates to other, basically applications of category theory in AI. In particular. There's also this whole world of categorical cybernetics I mentioned at the beginning, and I'd like to connect this a bit more precisely with what people are doing there with their stories in terms of lenses and so on.
51:11 And something else we were also interested in that I mentioned is that we got into the topic by thinking about consciousness. And there's lots of ways, as a major theory of cognition, there's been just loads of proposals for how active inference is related to consciousness, and it'd be nice to see how those can be described formally and in this setup and whether the string diagrammatic approach helps you make any more sense of those. So that's something we'd love to do in future. But for now, I'd like to say thanks again to all of you for listening, and I'd love to go to a discussion. Thanks.

51:47 Daniel:
Thank you, Sean, for the wonderful presentation.

51:51 Sean:
Thank you.

51:52 Daniel:
I will first pass to Ali for an opening remark, please.

52:02 Ali:
Thank you, Daniel. Thanks so much, Sean, for your really fascinating presentation. I truly enjoyed it. So I have a number of questions. Let me begin by asking the first know. When Bob Kirky and others took Hamiltonian formulation of quantum mechanics and kind of turned it into the string diagram formulation of it, namely ZX calculus, the claim was that regardless of its possible verity, but the claim was that one of the advantages of looking at quantum mechanics in terms of string diagrams, it's more than just a convenient way of looking at quantum formulation, and it actually unveils some properties of quantum mechanics that would be extremely difficult to see with Hamiltonian formulation.
53:09 And even in some of their papers, they claim one of the reasons for somehow the stagnant development in quantum technologies and quantum theory is exactly related to the difficulty of working with Hamiltonian formulations. So would you say string diagram formulation of active inference kind of takes a similar approach to somehow providing more than just handy tool for representing active inference modeling. And actually it kind of opens up new possibilities for further developments of active inference theory, possibilities which would somehow, I don't know, impossible or at least extremely difficult for the current traditional formulation of active inference to see in the current formulation of the active inference.

54:16 Sean:
Thanks. That's an amazing question. Yeah, I would agree. I think my idea for work at Oxford is actually in this categorical quantum mechanics area I talked about so string diagrams for quantum theory and everything. And I agree that that language helps you talk about a lot of things that you would maybe never get round to so much in other mathematical formulations of quantum theory, basically things that make use of the tensor, as it were, the composition a lot. So if this led to stagnation in quantum theory, it's probably because people weren't focusing as much on the tensor and entanglement and stuff, which became very central. Obviously in the end that's what people needed to do, quantum computing and stuff. So now what people are doing with quantum theories includes quantum computing where they're drawing these circuits and so you're drawing they're basically like string diagrams describing sometimes these string diagrams, sometimes they just use the slightly different conventions for quantum circuits. But it's similarly a compositional language where you have got tensor products.
55:18 So that as in things running in parallel states of these products so that you can talk about entanglement and so on. It's the language that makes it very immediate to represent that, because you just draw a box with two eyes and it encodes entangled state, and it makes you want to plug these things together and compose them, which is what you want to do in quantum computing. So I think similarly, if you never use that kind of language, you might think of a system often as a fixed thing and not about the way it interacts with other ones so much and that could lead to overlooking all sorts of things. So that's true in any area. And I think in active inference it's certainly very true. I think that it's natural to think compositionally in this way because you're wanting to talk about generative models being composed from pieces and you're maybe thinking about how the whole brain works in relation to interactions between parts of it and so on. So if you never used this kind of compositional view, there is stuff you would miss, I think. I think in some sense people weren't as behind already because they already were working kind of compositionally right, because they're using these Bayesian network diagrams like the Dags and the way they're normally drawn are very close.
56:30 They are basically the string diagrams, they just don't do the equations and the rewriting of the diagrams. So it's not as far back maybe as quantum theory was, in the sense that people are thinking compositionally, but it feels like you just want to go one step further to having a fully compositional language you're working in. Where you have the advantage now that you can just talk about taking a whole model and plugging it into another one and it has a completely clear formal meaning and so on, which I think is what you want to do in areas like active inference. So going from the diagrams which are currently used to string diagrams is like the logical next step and in terms of new stuff it lets you do. I think an example is something like this open BFE thing, I guess. So if you're just always thinking about just a generative model meaning one without inputs. You might not think of a notion I'm not saying this is necessarily the right notion, but you might not think about this problem of how you want to give your definition for something that is allowed to have inputs as well.
57:32 And once you have that have definition, you can sort of apply to parts of a composite system more easily, so it becomes more natural to use compositionally. So that's the kind of thing where without something like string diagrams, people can end up overlooking it. It wouldn't be impossible to do without them. I just need to talk about this notion of a kind of open generative model, which just means throwing away some mechanisms to make things be inputs. But you could miss it, but you really won't once you start thinking categorically.

58:08 Daniel:
Thank you, Ollie. Please continue if you would like.

58:14 Sean:
Thanks.

58:14 Ali:
So, yeah, my other perhaps related question is comparing this kind of formulation to this recent formulation of constructor theory in terms of string diagrams or categorical formulation of constructor theory. Before going into this question, you see, you mentioned that this project is a part of a larger project for developing collective intelligence, right? So the similar kind of situation happens for constructor theory in which it is a kind of meta theory that tries to somehow discriminate between the possibilities of physical laws as opposed to counterfactual laws, and how physical laws, how there can be a theory, accounts for the emergence of possible physical laws.
59:27 So in this sense, would you say this kind of formulation category, theoretical formulation, or possibly this specific String diagram formulation of active inference? Or maybe other theories of consciousness can be seen as a kind of providing a path? Toward developing a kind of meta theory of consciousness and possibly unifying many different strands of theories of consciousness into.

1:00:06 Sean:
I.

1:00:06 Ali:
Don'T know, a holistic picture that can somehow be compared and positively reconciled with one another and ultimately reaching the ultimate theory of consciousness. Or, I don't know, do you see this line of work providing enough evidence for this line of development research or, I don't know, somehow maybe even not specifically consciousness, but unifying the different aspects of cognition, intelligence and consciousness altogether? What would you say?

1:01:04 Sean:
Thanks. Keep giving me ideal selling points. So, yeah, that's also something I would like to say. I tend to think of it that way and that my background is in applying category theory to just lots of topics and I so naturally do think of it as quite a unifying language. And the grant on consciousness that I mentioned was building on earlier work we did on looking at integrated information theory of consciousness, which in the end basically was done in terms of categorical probability. So it's like the same setup of the diagrams. And so we kind of wanted to do the same thing for directive inference. So there it's like we've taken both of these things and put them in this common language. You could have put them in the common language of probability theory before. But I think I do have an intuition that there is something more clear about it. Does make it easier to get a conceptual grasp of both theories, I think, once you've done it this way and somehow also, yeah, the diagrammatic view does make it much easier to compare them.
1:02:04 So the hope was basically to, and still is to keep going and to keep understanding various notions in that language. So there's things I've looked at in cognitive science I've also done this way. So this theory of conceptual spaces, garden force have worked on treating that in terms of diagrams and so on. So I would love to see basically many theories put into this language to make it easier to compare them. You could try and compare them directly already, but I think you want one clear formalization to put them all in. And I would say that the categories and diagrams is the right one to pick because it tends to just give a very clear conceptual view of things. The question is whether you have some theory that's very important, where the things categories are good at, just doesn't quite capture the essence of what you want to talk about there. But for things like active inference and IIT, so far it seemed very natural because on the case of IIT, it's about talking about how integrated something is. So you basically want to talk about the opposite of that, which is something being decomposed.
1:03:05 And the diagrams basically talk about parts and how they're related, which is what you need to make sense of that notion of integration. So it's very natural there. But yeah, I would love basically to see various aspects of cognitive science understood categorically. That's something I'd love to do myself as well. And the hope would be then to try and gain insights from all of them and build a theory. It's not the category theory itself is a theory of cognition or consciousness. It's just a very useful language for relating them. And then it would be very exciting to see something natively defined in terms of category theory as well at the end. And there's a feeling that some of what's going on in applied category theory, I think, like in categorical, cybernetics and so on, is kind of taking that approach for perhaps some of the first time. Previously, I've always thought category theory is basically you take existing things and you get a really nice abstract view of them. But now I think people are comfortable enough with it that they're sort of defining things categorically from the outset in areas like that.

1:04:15 Daniel:
Awesome.

1:04:16 Sean:
Well.

1:04:18 Daniel:
Yeah, I have many thank you.

1:04:21 Sean:
These are great questions. There's like ideal questions.

1:04:26 Daniel:
You'Ve pointed in. And we've explored a little bit of the utility and the simplicity and how that could help with accessibility and rigor and applicability all these awesome things leading to reaccounting and reframing consolidating as well as discovering some new trails between, for example, expected free energy energy and variational free energy energy. Looking at the equations, you might be able to say that they rhyme, but you would be many, many lines deep into understanding what, if any, generalizations could encompass the both of them. So that was just a very salient example. A few different kinds of questions. So how is time treated in category theory? Or how does active inference treat time today and how do you see the way that time is treated?
1:05:28 We talk about discrete time and continuous time generative models. Then there's the past, present and future multi agent systems federated or asynchronous communication. So how is time treated and how does that give us a different grasp on dynamical modeling?

1:05:46 Sean:
Thank you. I'd love to have a better answer for that. Basically, I think it's a tough one at the moment in the talks if I just talked about discrete time and that's sort of very easy to treat with the Bayesian network setup and with these kind of string diagrams because you can just lay out the discrete time steps as processes in your picture like we see here. We have the end time steps here, but I don't have anything satisfying worked out yet to say about how you would treat a continuous time case, which I think is important in active inference. You'd like to basically take. I guess basically what you want to do is take the way that you describe this thing with the end time steps and kind of have a formula for folding it together and just saying, okay, but you're unpacking this. Thing n times. And then you can take that thing and imagine this abstract view of unpacking. It just not discreetly anymore in this continuous way, so that you can capture something like the differential equation kind of definition of continuous time thing in active inference.
1:06:51 I? Yeah so you can certainly work with continuous time things in the sense of, you know, the stuff going on in categorical cybernetics or sort of categorical systems theory I guess it would be called. Act world is kind know it has continuous time dynamical systems and talks about plugging them together but that diagram is sort of just relating their variables is my understanding. It's not like a diagram isn't exactly showing the time and in some sense they kind of have to synchronize, I think. It's not an area I'm totally familiar with. So it would have been really cool to basically have this work and then have another part of it talking about like we've done for discrete time here. Having a nice description of a continuous time case, I think it will end up being some work to take that into account there would be really nice to see. So it just needs the right abstraction, I think, for taking a picture like this. Not drawing the time steps as like bits in your diagram, but just saying that it's like this b thing with like a feedback loop basically is what this is describing.
1:08:00 And then giving a semantics to that in terms of time evolution, to give a continuous version of this, for example, with like state unfurling continuously and observations for each time step in general. I wouldn't say there's like an answer to the question of how is time treated in category theory. There wouldn't really be one answer because category is going to be so generally they tend to be very effective for discrete things in general, like algebra and so on, because they kind of are discrete in some sense, like the composition is discrete. So continuous aspects and things like continuous time tend to be more difficult in a sense. Or they're just sort of inside the morphisms, as it were. They're not in the composition. So it doesn't end up looking like this when you're composing continuously. But yeah, I think there will be people in act who sort of would come at you with a particular answer. So they've got a way they like to treat continuous time that I'm just not familiar with yet.
1:09:05 Cool.

1:09:07 Daniel:
A little bit of a more educational or applied question. So how do we go about drawing and learning to draw? Is there a software package? Is there a way that we can get a step by step process to building that familiarity with like when I see this shape, then here's what I know. And then how do we know what we can and can't do? And does that drawing software flag us or do we need to send it to a friend? So how do we look at something? And then part one, build up the motifs in our own aesthetic understanding so that we can understand the compositionality of this as you do today and as we all do today, for example, for Language English. And then part two, how do we go from having built that motif based compositional understanding to like now what can we do? And then when are we just totally freewheeling and off the rails of the free energy principle?
1:10:12 Or does anything go if the motifs allow it?

1:10:16 Sean:
Yeah, I wish I should have the standard answer. The best way to learn string diagrams, I think, if I'm going to talk about it like this. So you prompted me to come up with that. I don't have something on top of my head. That's the best way. But there's so much stuff out there I think it tends to be because if you want to get really comfortable with the diagrams, you're learning category theory in some sense, but it's not like you need to learn all of category theory. It's kind of a relatively modern offshoot in this applied category theory world that's very diagrammatically focused and there will be various nice introductions out there to using them another way is to think I'm pretty sure recently yeah, there was a nice paper that came out, there was an introduction to string diagrams for computer scientists, for example. So there tends to be different introductions kind of for different audiences because they just want to pick categories that those people are familiar with. Right. So they can actually have some examples. You could just learn the diagrams totally abstractly, but it helps to have some examples.
1:11:17 And the old category free textbooks are all things mathematicians have looked at and other people haven't heard of, so they're not particularly helpful. So there's know Bob has paper categories for the practicing physicist that's aimed at physicists that would basically introduce string diagrams to them. There's this recent computer science one. I know there's some work going on in producing one for cognitive science, which I think would be really good having an introduction to the string diagrams for those people. So you basically look for one in an area you're comfortable with and you find a good paper on it. But it would be nice to have a good online resource, I guess, right, that gathers these together so people can just see a great guide for all the introductions. If you do something like there's courses you can do in the sense of the Bob's book. In the case of learning quantum, there's something like Bob's Long book with Alex Kissinger picturing quantum processes. That's the kind of thing I learned from like it was in the form of a lecture course. But it's basically the same book because then there's just loads of exercises that will make you have to reason with string diagrams and then you pick the rules up because at first you don't have the same intuition, obviously, but the rules what can I do with these?
1:12:29 Can I slide them around like this or whatever? But it doesn't take too long to get quite used to it, I think, which is the nice thing about them. They're kind of natural, they're just these elastic strings and boxes and you have that sort of geometrical intuition. So things like that with exercises are the way I'd recommend getting used to using them. I didn't use any software in a sense of the diagrams I draw in this program called Tixit, but it doesn't tell you how string diagrams will work or anything, it's just for drawing them. But I know there's more work to develop. Libraries like the Algebraic Julia project is sort of like an applied category theory language, but I wouldn't know if it was recommended as a way to first learn categories. Yeah. So I would recommend finding a nice introductory paper in whatever field you're most used to playing with some exercises to get really used to them. For causal models, there's this paper Robin and I put out. It's not necessarily the very first place to learn string diagrams, but the aim is to introduce to people who've heard of causal models.
1:13:33 So in a sense of pearl. So just Bayesian networks, basically, but maybe the course interpretation of them to get them used to string diagrams. And this paper hopes to be a little bit introductory as well. Cool.

1:13:49 Daniel:
Ali, please.

1:13:53 Ali:
Thank you. So getting back to the question about the time representation in this formulation. So I take it that this kind of formulation of Bayesian inference, I mean, category theoretical formulation of Bayesian inference is largely based on tobi's Fritz definition of Markov categories as CD categories. Right. So as far as I understand it, Fritz paper kind of one of its basic assumptions is this kind of unidirectional inference, I mean, from earlier times to later times, right, or in other words, the prediction. But in quantum formulation of active inference or quantum active inference, there's this attempt to also develop the retradiction aspect of inference as well.
1:14:59 Right. So would you say this recent formulation can also be accounted for, this kind of retradiction? In other words, can this formulation be reconciled with quantum Bayesianism as well?

1:15:21 Sean:
Yeah, I basically wish yeah, sorry, go ahead.

1:15:24 Ali:
Because to add one more context here, I think it was in Kirk and Speckin's paper, there was this clear distinction between classical Bayesian inference and non classical Bayesian inference, in which the classical one does not allow for the retrodiction, but non classical Bayesian inference can be applied for both prediction and retrodiction as well.

1:15:58 Sean:
Okay, yeah, I would love to be a bit more familiar with the quantum active inference stuff, basically, to compare a bit. So I'm not as familiar with the sort of retro sorry, what was the other version of prediction? It's retro.

1:16:14 Ali:
Retrodiction, yeah, prediction and retradiction.

1:16:21 Sean:
I would have to compare with this. I know the paper you mean Bob's Paper Frog on both forms of Asian inference to see what they say there about the classical one. Can you give some intuition as to why it isn't something you can do classically, basically, the retro one? Because if that's a general case about probabilities, then it will be true in some sense here. Right. So here it's just being modeled in this probabilistic category. And so at the moment they're separate in that you have the model which basically goes forward and then you do your updating to try and approximate something going back. But you don't really have like this one.

1:17:05 Ali:
The whole idea was that for predictive quantum mechanics, we only need to account for the inference from earlier times to later times. But if we want to account for retrodictive quantum mechanics as well, we need to somehow account for because as we know, not every quantum formulation follows the Bell's principle of local causality. In order to account for all the entanglement phenomenon so on, we need to somehow put this bi directional inference into our model. So, yeah, that was the basic idea behind developing this kind of non classical Bayesian inference.

1:17:59 Sean:
Does it have something to do with the unitary evolution in quantum theory the way that you have this reversible thing? Or is it exactly that was the gist of it, yeah. And so you don't expect to have something like that classically, basically, where you have this reversible thing built in. Well, yeah, so I wouldn't expect to see that exact feature here in the sense of if it's treated, if it's basically something that you can't have in classical probabilities, it won't exist in this category matar plus. I think that would be basically the same category they would use in that paper, and they work with dagger combat categories, and they'll work with something like this Matar Plus category. But the classical case, if it's just a general it's less of a sort of physical notion, but it's just an idea that the model comes with a forward part and a backward part, then I think that's the kind of here how you go from a forward part to approximate this backward thing.
1:18:59 But the sort of lens type view of what's going on that's more studied in category cybernetics would be imagining. I think the model kind of carrying this backward inference process with it as well, so that for each forward part of the model, you would have this approximate inference sort of channel stored with it. So I don't know if that would address what you're asking, but it would have a backward and forward part together.

1:19:30 Daniel:
Well, Ollie, do you have any kind of closing opening remarks or questions or where do you see this going from the active inference side? What does this bring to us and what is opened through what has happened largely this year in active inference and category theory?

1:19:56 Ali:
Well, actually, I'm really excited to see this line of development in active inference theory. And as you know, I'm a big, big fan of meta theories and all kinds of unification theories and so on. I don't know, I kind of have this feeling, have this hunch that this line of development in active inference theory, it looks quite promising, especially for kind of tying up all the loose ends and transcending many, many other areas and discourses and ultimately reaching a kind of coherent picture of quote unquote reality, whatever it means. So, yeah, these kinds of development, I mean, the last year we had tremendous advances in Bayesian mechanical theories, and in recent months we have this fabulous line of research in category theoretical account of active inference.
1:21:17 My hope is that ultimately these different strands can be unified into coherent and overarching framework. So exciting times.

1:21:38 Sean:
So do you mean that you're thinking of it as it sounded like you're basically alluding to the work going on in cognition and work going on in physics coming together. Right. Like one really meta really open.

1:21:51 Ali:
Exactly, yeah. The idea behind Bayesian mechanics, one of its premises or assertions was that there isn't any clear distinction between cognitive and non cognitive things or agents and they rest on a continuum. The same kind of mathematical technology can be applied both for inert and conscious agents or sentient agents or whatever we choose to call them. So, yeah, this overarching theory unveiled many interesting phenomena regarding, well, self organizing systems, and it changed the whole perspective about how we can look at and even define consciousness, cognition, intelligence, sentience, and all of these related terms.
1:22:56 So my hope is that category theoretical account of active inference can also be used for clearly seeing many of these emerging elements in Bayesian mechanics and active inference theory and hopefully, well, gaining some interesting and potentially groundbreaking insights.

1:23:26 Sean:
That'd be wonderful. Yeah, I'd love to apply for those topics, and I'd be very curious to see how categories can come in. Sorry, Daniel. Yeah. Oh, yeah.

1:23:36 Daniel:
I'll just give my closing thoughts then to you, Sean. Just a few loose notes that, again, open probably more than they close. Ali was right in suggesting and expressing that Bayesian mechanics recently has helped us develop a continuum of active and passive systems, so called living and non living, or inanimate and animate. And that brings us to another dialectic to resolve, which is life and mind, which is where the physical and the cognitive science come together. You said they're on a continuum. Maybe we could say they're on a quantinium. And what language could express such work? Well, right now we're speaking in English with the active inference ontology dialect. However, the phonemes are not intrinsically meaningful. The M in a Markov blanket or category does not mean something. It's a sound. And so the string diagram language and representation I see as a way to fuse and integrate semantics into the syntax of the actual inscription, which enables us to generalize in new ways.
1:24:59 Also, recognizing string diagrams are not everything, and so on. And then with all of these intersecting vectors from the cognitive and the physical sciences, we are able to take the compositional cartographic approach for cognitive ecosystems and talk about diverse intelligences, biological, quantum, classical architectures, all of these synthetic intelligences. And so it's super exciting, and I appreciate again your visit and look forward to people's curiosity taking them and also the development of tools and educational materials that make this easier and then being able to display and use something where the meaning is primal rather than like, well, this letter represents this.
1:26:00 It already introduces such a space between the analytical representation and really the string diagram, which exists isomorphically with it.

1:26:19 Sean:
Yes, I find this very exciting way of thinking. It sounds like you're advocating a kind of structural ontology kind of thing in some sense, right, where you're taking the compositional structure of what's going on to really be the meaning or really be the real thing that's there, not just like I don't know. Yeah, we could talk about it for a while, I imagine, but I would love to see string diagrams and other approaches. I'm sure that take that role. And you've got me very excited about this kind of unification that's going on.

1:26:54 Daniel:
Thank you again, Sean. You're always welcome, and we look forward to seeing where this all goes.

1:26:59 Sean:
Yeah. Thanks again for having me. Yeah. Really great discussion. Thank you.

1:27:04 Ali:
Thank you so much.

1:27:06 Sean:
Thanks, Ali. All right. Bye. Thanks.
