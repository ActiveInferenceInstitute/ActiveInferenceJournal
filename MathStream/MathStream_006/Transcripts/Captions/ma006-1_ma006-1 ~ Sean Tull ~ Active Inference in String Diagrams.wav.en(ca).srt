1
00:00:04,770 --> 00:00:08,726
Hello and welcome,

2
00:00:08,828 --> 00:00:11,222
everyone. It is September 1,

3
00:00:11,276 --> 00:00:14,594
2023. We're here in active inference

4
00:00:14,642 --> 00:00:18,322
math stream number 6.1 here with Sean

5
00:00:18,386 --> 00:00:21,190
Toll. We'll be hearing a presentation,

6
00:00:21,530 --> 00:00:23,874
active inference in string diagrams

7
00:00:23,922 --> 00:00:26,598
followed by a discussion. This is super

8
00:00:26,684 --> 00:00:28,806
exciting. So if you're watching Live,

9
00:00:28,908 --> 00:00:30,734
please feel feel free to write your

10
00:00:30,772 --> 00:00:33,534
questions in the Live chat. Really

11
00:00:33,572 --> 00:00:35,134
looking forward to this. So thank you,

12
00:00:35,172 --> 00:00:37,566
Sean, again for joining and to you for

13
00:00:37,588 --> 00:00:41,006
the presentation. All right, thanks very

14
00:00:41,028 --> 00:00:41,934
much. Thanks everyone who's watching.

15
00:00:41,972 --> 00:00:43,406
And thanks to the organizers for this

16
00:00:43,428 --> 00:00:45,038
chance to speak to you and to Daniel for

17
00:00:45,044 --> 00:00:46,206
getting in touch and inviting me to

18
00:00:46,228 --> 00:00:48,498
speak. So, yeah, I'm really excited to

19
00:00:48,504 --> 00:00:49,490
share this work with this community,

20
00:00:49,560 --> 00:00:51,746
basically, and to hear from those people

21
00:00:51,768 --> 00:00:53,186
who work with active inference and do

22
00:00:53,208 --> 00:00:54,818
any formal work, what they think of what

23
00:00:54,824 --> 00:00:57,700
I'll present today. So I'm going to be

24
00:00:58,470 --> 00:01:00,518
presenting a formal approach to how you

25
00:01:00,524 --> 00:01:01,814
can describe active inference in terms

26
00:01:01,852 --> 00:01:04,166
of an entirely graphical language called

27
00:01:04,188 --> 00:01:05,526
the language of string diagrams. And

28
00:01:05,548 --> 00:01:06,646
it's based on this mathematics called

29
00:01:06,668 --> 00:01:08,806
category theory. And I won't assume that

30
00:01:08,828 --> 00:01:10,406
you're too familiar with this already

31
00:01:10,588 --> 00:01:12,246
and try and introduce it to you in the

32
00:01:12,268 --> 00:01:14,186
talk. And ultimately, I'd like to sort

33
00:01:14,208 --> 00:01:15,574
of convince you that this diagrammatic

34
00:01:15,622 --> 00:01:16,938
language will be really useful for those

35
00:01:16,944 --> 00:01:18,326
of you who work formally with active

36
00:01:18,358 --> 00:01:19,626
inference and encourage you to pick it

37
00:01:19,648 --> 00:01:22,366
up in your own work. I've just

38
00:01:22,468 --> 00:01:24,074
introduced myself a bit. I'm Sean Tull.

39
00:01:24,122 --> 00:01:26,590
I'm a researcher at Continuum,

40
00:01:27,250 --> 00:01:28,906
formerly a postdoc in computer science

41
00:01:28,938 --> 00:01:31,006
in Oxford, and a Continuum in this

42
00:01:31,028 --> 00:01:32,786
Oxford team where I'm based, where we

43
00:01:32,808 --> 00:01:33,854
study what we call compositional

44
00:01:33,902 --> 00:01:35,646
intelligence, which includes applying

45
00:01:35,678 --> 00:01:40,530
category theory to topics in AI and

46
00:01:40,680 --> 00:01:41,858
as well as this. The project was

47
00:01:41,864 --> 00:01:44,478
supported by a grant from FQXi. It's

48
00:01:44,494 --> 00:01:45,826
located at the bottom and hosted at

49
00:01:45,848 --> 00:01:47,462
Topos Institute, which is the center for

50
00:01:47,516 --> 00:01:49,030
Applied Category Theory.

51
00:01:50,330 --> 00:01:52,360
So let me get think. So,

52
00:01:53,850 --> 00:01:56,306
yeah, here we go. So for active

53
00:01:56,338 --> 00:01:57,894
inference, won't spend too much time

54
00:01:57,932 --> 00:01:59,094
introducing it. I'll assume most people

55
00:01:59,132 --> 00:02:00,646
here are familiar with it, and many of

56
00:02:00,668 --> 00:02:02,058
you probably know more about it than I

57
00:02:02,064 --> 00:02:05,466
do, in fact. So I'll just

58
00:02:05,488 --> 00:02:06,746
mention the parts of it that I'll be

59
00:02:06,768 --> 00:02:08,938
addressing in the talk. So thinking of

60
00:02:08,944 --> 00:02:11,126
it as a model of cognition that simply

61
00:02:11,158 --> 00:02:12,714
we can think of as applying at many

62
00:02:12,752 --> 00:02:14,462
levels, say from a whole organism or

63
00:02:14,516 --> 00:02:17,086
just to a single neuron. And the key

64
00:02:17,108 --> 00:02:19,118
idea is that in this approach, you think

65
00:02:19,124 --> 00:02:20,302
of an agent that's coming with this

66
00:02:20,356 --> 00:02:22,910
generative model that it uses to explain

67
00:02:22,980 --> 00:02:24,546
the observations it receives from the

68
00:02:24,568 --> 00:02:27,378
world in terms of some hidden states,

69
00:02:27,464 --> 00:02:28,946
which you might call perception, and in

70
00:02:28,968 --> 00:02:33,026
terms of its own actions. And in

71
00:02:33,048 --> 00:02:34,306
active inference, it achieves both of

72
00:02:34,328 --> 00:02:35,940
these things through this form of

73
00:02:36,310 --> 00:02:37,838
Bayesian inference or an approximate

74
00:02:37,854 --> 00:02:39,458
form of Bayesian inference by minimizing

75
00:02:39,474 --> 00:02:41,126
this quantity called free energy. And

76
00:02:41,148 --> 00:02:42,662
these are the ingredients we'll be

77
00:02:42,716 --> 00:02:44,118
talking about in the talk. And the thing

78
00:02:44,124 --> 00:02:45,058
that's really exciting about active

79
00:02:45,074 --> 00:02:47,398
inference, I think, for those of a

80
00:02:47,404 --> 00:02:49,366
formal background as well, is that it

81
00:02:49,548 --> 00:02:51,526
aims to offer like a very principled

82
00:02:51,558 --> 00:02:54,106
approach to cognition that you can

83
00:02:54,128 --> 00:02:55,274
hopefully apply at all these many

84
00:02:55,312 --> 00:02:57,386
levels. But I think at the moment it

85
00:02:57,408 --> 00:02:59,654
could also benefit from more formal

86
00:02:59,702 --> 00:03:02,042
work. And that's what this talks about.

87
00:03:02,096 --> 00:03:03,326
It's about formal approaches to the

88
00:03:03,348 --> 00:03:06,574
theory in particular, I think nice

89
00:03:06,612 --> 00:03:08,106
clear formatations or active instances

90
00:03:08,138 --> 00:03:10,046
would help to clarify sort of what the

91
00:03:10,068 --> 00:03:11,726
core of the key ideas of the theory are.

92
00:03:11,748 --> 00:03:13,610
So we'd like it to be this very succinct

93
00:03:13,770 --> 00:03:15,586
principle that ideally we just apply to

94
00:03:15,608 --> 00:03:17,074
a generative model and everything else

95
00:03:17,112 --> 00:03:19,618
follows from. And once we've got to

96
00:03:19,624 --> 00:03:20,946
this, we can hopefully generalize it,

97
00:03:20,968 --> 00:03:23,586
understand it better, and also make it

98
00:03:23,608 --> 00:03:24,946
just more accessible to those who come

99
00:03:24,968 --> 00:03:25,858
from formal backgrounds, like in

100
00:03:25,864 --> 00:03:27,122
mathematics and so on, and get them

101
00:03:27,176 --> 00:03:29,478
working on the topic very quickly and

102
00:03:29,564 --> 00:03:31,266
connect it with approaches in artificial

103
00:03:31,298 --> 00:03:33,766
intelligence as well. But the most

104
00:03:33,788 --> 00:03:34,854
important thing about a good

105
00:03:34,892 --> 00:03:36,806
formalization, I think, should just be

106
00:03:36,828 --> 00:03:38,454
to make learning about active inference

107
00:03:38,502 --> 00:03:40,346
easier, make the framework simpler to

108
00:03:40,448 --> 00:03:42,326
understand. So that's what we're aiming

109
00:03:42,358 --> 00:03:47,260
for in this work. And I'd say in

110
00:03:47,630 --> 00:03:49,914
other places already there's been some

111
00:03:49,952 --> 00:03:52,218
calls that some suggestions that an is

112
00:03:52,224 --> 00:03:53,626
formalization of active inference should

113
00:03:53,648 --> 00:03:55,598
be a diagrammatic one. So when you look

114
00:03:55,604 --> 00:03:57,166
at the generative models that come up in

115
00:03:57,188 --> 00:03:58,174
active inference a lot, they're very

116
00:03:58,212 --> 00:03:59,598
compositional in their nature and it's

117
00:03:59,604 --> 00:04:01,950
very natural to draw them in diagrams.

118
00:04:02,610 --> 00:04:04,174
So it would be nice if our whole

119
00:04:04,212 --> 00:04:05,586
approach to describing it could be

120
00:04:05,608 --> 00:04:07,666
graphical in this way. So just for

121
00:04:07,688 --> 00:04:08,706
example, there's this paper called The

122
00:04:08,728 --> 00:04:12,146
Graphical Brain by Kristen Par, and in

123
00:04:12,168 --> 00:04:13,538
general, we've probably seen loads of

124
00:04:13,544 --> 00:04:14,734
these diagrams describing generative

125
00:04:14,782 --> 00:04:17,454
models where you draw many compositional

126
00:04:17,502 --> 00:04:19,426
features of different spaces of hidden

127
00:04:19,458 --> 00:04:21,174
states, observations, interacting and so

128
00:04:21,212 --> 00:04:24,498
on. So these diagrams

129
00:04:24,514 --> 00:04:25,238
are used, but they're just used to

130
00:04:25,244 --> 00:04:26,518
represent the model. You still have to

131
00:04:26,524 --> 00:04:28,834
then go to doing sort of traditional

132
00:04:28,882 --> 00:04:30,778
probability of theory calculations when

133
00:04:30,784 --> 00:04:32,906
you reason about them normally. But in

134
00:04:32,928 --> 00:04:34,934
fact, there is a whole graphical,

135
00:04:34,982 --> 00:04:36,634
formalism and mathematical language for

136
00:04:36,672 --> 00:04:38,006
describing these kind of interacting

137
00:04:38,038 --> 00:04:40,986
processes just entirely with the

138
00:04:41,008 --> 00:04:42,986
diagrams. So the area of mathematics is

139
00:04:43,008 --> 00:04:44,026
called category theory and the language

140
00:04:44,058 --> 00:04:45,278
are these string diagrams I'm going to

141
00:04:45,284 --> 00:04:48,798
talk today, and in particular, there's a

142
00:04:48,804 --> 00:04:50,346
lot of work going on in applied category

143
00:04:50,378 --> 00:04:52,538
theory now in how you can describe

144
00:04:52,634 --> 00:04:54,334
aspects of probability theory and

145
00:04:54,372 --> 00:04:56,706
causality and causal models in terms of

146
00:04:56,728 --> 00:04:59,038
string diagrams. And these causal models

147
00:04:59,054 --> 00:05:00,206
are basically based on Bayesian

148
00:05:00,238 --> 00:05:01,774
networks. So the same formal structure

149
00:05:01,822 --> 00:05:03,326
as the generative models in active

150
00:05:03,358 --> 00:05:05,678
inference. And in particular, what I'll

151
00:05:05,694 --> 00:05:07,014
talk about today kind of draws on this

152
00:05:07,052 --> 00:05:09,154
paper co authored with Robin Lorenz,

153
00:05:09,202 --> 00:05:11,606
talking about causal models in the sense

154
00:05:11,628 --> 00:05:12,738
of pearl in terms of these string

155
00:05:12,754 --> 00:05:13,986
diagrams. So it's basically causal

156
00:05:14,018 --> 00:05:17,606
Bayesian networks, which is the same

157
00:05:17,628 --> 00:05:19,274
formal structure as we'll be talking

158
00:05:19,312 --> 00:05:22,678
about today. So in this talk I'm

159
00:05:22,694 --> 00:05:24,186
talking about this paper, which was

160
00:05:24,208 --> 00:05:26,026
joint work with Johannes Kleiner and

161
00:05:26,208 --> 00:05:28,378
Ive, which is called Active Inference in

162
00:05:28,384 --> 00:05:30,794
String Diagrams, a categorical account

163
00:05:30,832 --> 00:05:32,906
of processing and free energy. And

164
00:05:32,928 --> 00:05:34,254
basically what we do is try to give a

165
00:05:34,292 --> 00:05:36,266
formalization of active inference that's

166
00:05:36,298 --> 00:05:37,486
nice and clear conceptually just

167
00:05:37,508 --> 00:05:39,322
entirely in terms of string diagrams.

168
00:05:39,386 --> 00:05:40,814
So we're basically taking the kind of

169
00:05:40,852 --> 00:05:41,998
formal content that's in something like

170
00:05:42,004 --> 00:05:43,794
the active inference book and turning it

171
00:05:43,912 --> 00:05:47,826
into these diagrams. And as

172
00:05:47,848 --> 00:05:49,986
I mentioned, it was done as part of this

173
00:05:50,008 --> 00:05:52,066
FQXi project that was actually on a

174
00:05:52,088 --> 00:05:53,506
project about consciousness as about

175
00:05:53,528 --> 00:05:55,566
ways that category theory can be applied

176
00:05:55,598 --> 00:05:57,326
to theories of consciousness. And we've

177
00:05:57,358 --> 00:05:58,886
done some previous work looking at the

178
00:05:58,908 --> 00:06:00,118
integrated information theory of

179
00:06:00,124 --> 00:06:01,766
consciousness and of course there's all

180
00:06:01,788 --> 00:06:03,046
sorts of ways that active inference has

181
00:06:03,068 --> 00:06:04,086
been proposed to connect to

182
00:06:04,108 --> 00:06:06,838
consciousness. But for the purpose of

183
00:06:06,844 --> 00:06:07,958
this talk, we won't go into any of that.

184
00:06:07,964 --> 00:06:10,246
It's just a theory of cognition. I take

185
00:06:10,268 --> 00:06:12,378
it to be here and I'll just mention at

186
00:06:12,384 --> 00:06:13,946
the end it'd be nice to connect it back

187
00:06:13,968 --> 00:06:16,122
up to consciousness in future. And

188
00:06:16,176 --> 00:06:17,594
there's also lots of other related work

189
00:06:17,632 --> 00:06:19,594
going on in category theory that's very

190
00:06:19,632 --> 00:06:21,018
close to this, that often goes by the

191
00:06:21,024 --> 00:06:22,630
name of categorical cybernetics, and

192
00:06:22,640 --> 00:06:24,014
this might include some of the things

193
00:06:24,132 --> 00:06:26,158
Toby has talked about on the stream in

194
00:06:26,164 --> 00:06:28,574
the past. So what I'll do now is

195
00:06:28,612 --> 00:06:31,082
introduce categories and string diagrams

196
00:06:31,226 --> 00:06:32,958
and then later we'll apply them to all

197
00:06:32,964 --> 00:06:34,138
these basic ingredients of active

198
00:06:34,154 --> 00:06:35,746
inference that I've alluded to so far.

199
00:06:35,768 --> 00:06:37,422
So that would be generative models

200
00:06:37,566 --> 00:06:40,046
updating them, free energy and active

201
00:06:40,078 --> 00:06:43,394
inference itself. Let's start

202
00:06:43,432 --> 00:06:44,734
with these categories and string

203
00:06:44,782 --> 00:06:48,238
diagrams. So you can think of a category

204
00:06:48,334 --> 00:06:50,694
in general as a sort of world of

205
00:06:50,732 --> 00:06:52,486
interacting processes. And the

206
00:06:52,508 --> 00:06:53,526
categories we're talking about here are

207
00:06:53,548 --> 00:06:54,626
always going to be these symmetric

208
00:06:54,658 --> 00:06:56,518
minoidal categories. But don't worry too

209
00:06:56,524 --> 00:06:58,134
much about the formal language because

210
00:06:58,252 --> 00:06:59,466
the way we talk about them is just going

211
00:06:59,468 --> 00:07:01,260
to come down to the diagrams here today.

212
00:07:01,630 --> 00:07:03,866
So a category amounts to a collection of

213
00:07:03,888 --> 00:07:05,354
these objects, or sometimes called

214
00:07:05,392 --> 00:07:07,738
systems, like this Capital ABC here,

215
00:07:07,904 --> 00:07:09,658
and what are called morphisms, or you

216
00:07:09,664 --> 00:07:11,094
might want to typically call processes

217
00:07:11,142 --> 00:07:12,854
between them. So when you're writing

218
00:07:12,902 --> 00:07:15,206
normally, you can just write a morphism

219
00:07:15,238 --> 00:07:17,662
from A to B as like this f colon A to B.

220
00:07:17,796 --> 00:07:19,326
In string diagrams, though, you draw it

221
00:07:19,348 --> 00:07:20,638
like this, where we're reading all the

222
00:07:20,644 --> 00:07:22,446
diagrams from bottom to top in this

223
00:07:22,468 --> 00:07:25,514
talk. So you have a wire for the A input

224
00:07:25,562 --> 00:07:27,786
at the bottom and a wire for the B

225
00:07:27,828 --> 00:07:29,506
output at the top. And the morphism is

226
00:07:29,528 --> 00:07:31,826
just drawn as a box F here and you just

227
00:07:31,848 --> 00:07:32,866
read the diagram up thinking about,

228
00:07:32,888 --> 00:07:34,786
okay, it takes in this input coming in

229
00:07:34,808 --> 00:07:37,586
on this wire, a process applies and then

230
00:07:37,608 --> 00:07:39,334
you have your output of type B at the

231
00:07:39,372 --> 00:07:42,646
top. So what you can do with

232
00:07:42,668 --> 00:07:44,438
these processes is compose them. So if

233
00:07:44,444 --> 00:07:46,966
you have two processes, say your F from

234
00:07:46,988 --> 00:07:49,138
A to B and G from B to C, so the types

235
00:07:49,154 --> 00:07:50,378
line up, you can just compose them in

236
00:07:50,384 --> 00:07:52,326
sequence. And this just means plugging

237
00:07:52,358 --> 00:07:54,630
the boxes together in your diagrams.

238
00:07:54,790 --> 00:07:56,038
And because we're in this Minoidal

239
00:07:56,054 --> 00:07:57,834
category, you can also compose in

240
00:07:57,872 --> 00:07:59,734
parallel. So you have this operation

241
00:07:59,782 --> 00:08:01,354
called the tensor, which means given two

242
00:08:01,392 --> 00:08:02,986
objects, you can put them together to

243
00:08:03,008 --> 00:08:04,926
build this composite object. So AB goes

244
00:08:04,948 --> 00:08:07,278
to a tensor B, you'd say, and you can

245
00:08:07,284 --> 00:08:08,798
also do this to morphisms, so you can

246
00:08:08,804 --> 00:08:11,438
build this F tensor G. But in the

247
00:08:11,444 --> 00:08:12,734
pictures it just means drawing them side

248
00:08:12,772 --> 00:08:14,126
by side. And you just think of this as

249
00:08:14,148 --> 00:08:16,718
meaning we have F from A to C and G from

250
00:08:16,724 --> 00:08:17,838
B to D, and they're just running in

251
00:08:17,844 --> 00:08:19,274
parallel and they're not interacting

252
00:08:19,322 --> 00:08:21,646
essentially. So most of the time you

253
00:08:21,668 --> 00:08:22,638
just draw a picture like this and you

254
00:08:22,644 --> 00:08:23,706
don't even need to write the tensor

255
00:08:23,738 --> 00:08:25,926
symbols. So if these two basic modes of

256
00:08:25,948 --> 00:08:27,654
composition and from these you can build

257
00:08:27,692 --> 00:08:30,438
much more elaborate string diagrams in

258
00:08:30,444 --> 00:08:33,554
your category. So if you're writing

259
00:08:33,602 --> 00:08:34,918
things very mathematically, you have to

260
00:08:34,924 --> 00:08:36,882
write lots of equations that a category

261
00:08:36,946 --> 00:08:38,770
or Minoidal category needs to satisfy.

262
00:08:38,850 --> 00:08:40,066
But when you're working the diagrams,

263
00:08:40,098 --> 00:08:41,378
they basically do some of the work for

264
00:08:41,404 --> 00:08:42,554
you because these things just come out

265
00:08:42,592 --> 00:08:44,394
for free. So, for example, you have

266
00:08:44,432 --> 00:08:46,778
equations like this that you'd have to

267
00:08:46,864 --> 00:08:48,714
think about when you're working with

268
00:08:48,752 --> 00:08:50,358
them in the conventional mathematical

269
00:08:50,374 --> 00:08:52,282
way. But in the diagrams it just means

270
00:08:52,336 --> 00:08:53,706
if you have two boxes, you can kind of

271
00:08:53,728 --> 00:08:54,962
slide them along the wires. It doesn't

272
00:08:54,966 --> 00:08:56,078
really matter where they are on the

273
00:08:56,084 --> 00:08:57,406
wires, it tends to just be the

274
00:08:57,428 --> 00:08:59,306
connectivity that matters. Similarly,

275
00:08:59,338 --> 00:09:00,654
we can cross wires over each other

276
00:09:00,692 --> 00:09:02,430
because we're in the symmetric setting

277
00:09:03,170 --> 00:09:06,778
and there's a few just useful features

278
00:09:06,794 --> 00:09:08,562
that you'll have in a category. So every

279
00:09:08,616 --> 00:09:09,806
object comes with this identity

280
00:09:09,838 --> 00:09:11,154
morphism, which you just think of as

281
00:09:11,192 --> 00:09:13,186
meaning nothing happening basically. So

282
00:09:13,208 --> 00:09:14,862
it's just drawn as a blank wire.

283
00:09:15,006 --> 00:09:16,786
There's also a kind of identity object,

284
00:09:16,888 --> 00:09:18,478
as it were, called a unit object, which

285
00:09:18,504 --> 00:09:20,486
is just empty space, so you don't even

286
00:09:20,508 --> 00:09:22,918
draw the wire. This dashbox just means

287
00:09:23,004 --> 00:09:24,226
nothing. It's meant to be an empty

288
00:09:24,258 --> 00:09:26,726
picture. And the latter thing is just

289
00:09:26,748 --> 00:09:28,326
useful because it now means we can talk

290
00:09:28,348 --> 00:09:29,606
about amorphism, which doesn't even have

291
00:09:29,628 --> 00:09:31,926
an input or an output. More formally,

292
00:09:31,958 --> 00:09:33,946
it has this object I as it's input by

293
00:09:33,968 --> 00:09:36,410
output, and we give these things special

294
00:09:36,480 --> 00:09:38,186
names. So the most important one

295
00:09:38,208 --> 00:09:40,060
probably is that of a state,

296
00:09:41,150 --> 00:09:43,498
which is a morphism with no input, as it

297
00:09:43,504 --> 00:09:45,358
were, or really with input I. So in the

298
00:09:45,364 --> 00:09:46,398
pictures it just looks like this. So

299
00:09:46,404 --> 00:09:48,046
there's no wire going in. And you'd call

300
00:09:48,068 --> 00:09:50,686
this a state of A. You can also have a

301
00:09:50,708 --> 00:09:53,166
process that takes in a if it has no

302
00:09:53,188 --> 00:09:55,458
output that you'd call an effect. And if

303
00:09:55,464 --> 00:09:56,546
you have naive, you just call this a

304
00:09:56,568 --> 00:09:58,226
scalar. So this is just going to be like

305
00:09:58,248 --> 00:10:00,386
a number basically floating around next

306
00:10:00,408 --> 00:10:01,570
to your diagram.

307
00:10:03,430 --> 00:10:06,706
So there are many categories out there.

308
00:10:06,728 --> 00:10:07,906
The point of category three is extremely

309
00:10:07,938 --> 00:10:09,254
general. So this could be talking about

310
00:10:09,292 --> 00:10:11,314
computational processes or physical

311
00:10:11,362 --> 00:10:13,478
processes or quantum processes in

312
00:10:13,484 --> 00:10:14,726
particular, and all sorts of things.

313
00:10:14,828 --> 00:10:16,262
For this talk we'll only actually need

314
00:10:16,316 --> 00:10:18,166
about one category. We'll just keep it

315
00:10:18,188 --> 00:10:19,706
simple with this one. That's the

316
00:10:19,728 --> 00:10:22,182
category. I call it matar plus. So it's

317
00:10:22,246 --> 00:10:25,386
positive real matrices. So you can just

318
00:10:25,408 --> 00:10:27,302
take objects for the wires to be finite

319
00:10:27,366 --> 00:10:30,342
sets and the morphisms to be positive

320
00:10:30,406 --> 00:10:32,246
matrices indexed by these, as I'll

321
00:10:32,278 --> 00:10:35,102
explain. So if we draw a box like this,

322
00:10:35,156 --> 00:10:38,126
M, going from X to Y, this is like a

323
00:10:38,148 --> 00:10:40,542
matrix indexed by X and Y. And for each

324
00:10:40,676 --> 00:10:43,278
input in this little set X, sorry, in

325
00:10:43,284 --> 00:10:45,598
the set X and each output in Y, you'd

326
00:10:45,614 --> 00:10:47,726
get a positive real number and we'll

327
00:10:47,758 --> 00:10:50,180
write it like M of Y given X.

328
00:10:50,790 --> 00:10:53,426
So this box would mean a function like

329
00:10:53,448 --> 00:10:56,482
this. Now, when we plug them together,

330
00:10:56,536 --> 00:10:57,618
they let us turn some things that you

331
00:10:57,624 --> 00:10:58,742
normally have to do with equations into

332
00:10:58,796 --> 00:11:00,246
kind of simpler pictures. I mean,

333
00:11:00,268 --> 00:11:01,686
mainly this middle one. So if we have

334
00:11:01,708 --> 00:11:04,342
two in sequence, we just compose them by

335
00:11:04,396 --> 00:11:06,838
matrix multiplication. So instead of

336
00:11:06,844 --> 00:11:08,086
having to write this formula where we

337
00:11:08,108 --> 00:11:09,446
sum over Y, we can just draw this

338
00:11:09,468 --> 00:11:11,286
picture above it where we just plug them

339
00:11:11,308 --> 00:11:13,526
on top. And if we run them in parallel

340
00:11:13,558 --> 00:11:15,738
here, we take the cartesian product of

341
00:11:15,744 --> 00:11:18,138
the sets and the tensor product of the

342
00:11:18,144 --> 00:11:19,466
matrices, as it were. But it's just the

343
00:11:19,488 --> 00:11:22,014
obvious thing where you have two things

344
00:11:22,052 --> 00:11:25,486
running independently. So in

345
00:11:25,508 --> 00:11:28,574
particular a state tier ends up the

346
00:11:28,612 --> 00:11:30,174
minority unit is just a singleton set

347
00:11:30,212 --> 00:11:31,406
and you can basically just ignore it.

348
00:11:31,428 --> 00:11:34,078
So a state tier amounts to just a

349
00:11:34,084 --> 00:11:36,074
function sending each X to a positive

350
00:11:36,122 --> 00:11:38,978
real and affect the same thing. And a

351
00:11:38,984 --> 00:11:41,346
scalar would just be a positive real.

352
00:11:41,528 --> 00:11:42,946
The intuition though is that we're going

353
00:11:42,968 --> 00:11:46,066
to restrict the particular morphisms in

354
00:11:46,088 --> 00:11:47,378
here, which are probabilistic in the

355
00:11:47,384 --> 00:11:48,966
nature. So they need to send each X to

356
00:11:48,988 --> 00:11:51,366
an actual distribution over Y. So I want

357
00:11:51,388 --> 00:11:52,662
to talk about how you actually pick

358
00:11:52,716 --> 00:11:56,086
those up next. So to do that, you use

359
00:11:56,108 --> 00:11:57,554
some extra structure that this category

360
00:11:57,602 --> 00:11:59,346
has. It forms what's called a copy

361
00:11:59,378 --> 00:12:01,674
discard category. So this is one more

362
00:12:01,712 --> 00:12:03,658
bit of mathematical sort of gadgets we

363
00:12:03,664 --> 00:12:05,562
have around. So that is that each object

364
00:12:05,616 --> 00:12:06,646
comes with these distinguished

365
00:12:06,678 --> 00:12:08,726
processes. There's one that we call copy

366
00:12:08,758 --> 00:12:10,618
that takes in a say and brings up two

367
00:12:10,624 --> 00:12:12,526
copies of A at the top and one called

368
00:12:12,548 --> 00:12:14,046
discard where you just throw A away so

369
00:12:14,068 --> 00:12:15,920
you have no output at the top.

370
00:12:17,970 --> 00:12:20,926
These satisfy some equations that are

371
00:12:20,948 --> 00:12:22,158
quite intuitive if you think about like

372
00:12:22,164 --> 00:12:23,758
copying and then throwing away one of

373
00:12:23,764 --> 00:12:24,858
the outputs is the same as doing

374
00:12:24,884 --> 00:12:26,462
nothing. So it's. This blank wire

375
00:12:26,606 --> 00:12:29,058
copying is symmetric and associative is

376
00:12:29,064 --> 00:12:31,118
the last one. So in this category, mad

377
00:12:31,134 --> 00:12:33,330
or plus discard would be just the

378
00:12:33,400 --> 00:12:36,100
function sending each element to one.

379
00:12:36,550 --> 00:12:38,594
And the copy would be like a delta. So A

380
00:12:38,632 --> 00:12:41,046
comes in and two copies of A come out.

381
00:12:41,068 --> 00:12:44,166
At the top is the intuition. The reason

382
00:12:44,188 --> 00:12:45,538
we introduced this stuff is because it's

383
00:12:45,554 --> 00:12:46,758
been shown recently that you can do a

384
00:12:46,764 --> 00:12:49,174
lot of probability theory just in terms

385
00:12:49,212 --> 00:12:50,970
of these CD categories and particular

386
00:12:51,040 --> 00:12:52,458
ones called Markov categories. So

387
00:12:52,464 --> 00:12:53,466
there's a lot of what's going on in

388
00:12:53,488 --> 00:12:55,178
applied category theory at the moment,

389
00:12:55,344 --> 00:12:59,546
using this language of CD categories in

390
00:12:59,568 --> 00:13:00,618
particular, they let you pick out some

391
00:13:00,624 --> 00:13:02,166
things to do with probability theory.

392
00:13:02,198 --> 00:13:03,838
I'll just talk about a couple of them

393
00:13:03,844 --> 00:13:04,958
here. The most important one is the

394
00:13:04,964 --> 00:13:07,166
notion of a channel. So this is what

395
00:13:07,188 --> 00:13:08,986
lets us pick out the actual normalized

396
00:13:09,098 --> 00:13:11,918
matrices, as it were, from earlier. So

397
00:13:12,004 --> 00:13:13,774
in general, you call amorphism a channel

398
00:13:13,812 --> 00:13:16,526
when it preserves this discarding. And a

399
00:13:16,548 --> 00:13:18,546
special case is a state in which when

400
00:13:18,568 --> 00:13:20,446
it's a channel, you call it normalized.

401
00:13:20,638 --> 00:13:22,066
So for a state, this means it would

402
00:13:22,088 --> 00:13:23,598
actually be a probability distribution.

403
00:13:23,694 --> 00:13:25,278
So it's actually normalized if you sum

404
00:13:25,294 --> 00:13:26,958
over the values with this omega, you'll

405
00:13:26,974 --> 00:13:29,398
get one. And for a morphism being a

406
00:13:29,404 --> 00:13:31,366
channel, it means it sends each input to

407
00:13:31,388 --> 00:13:33,126
a distribution. So it actually is a

408
00:13:33,148 --> 00:13:35,080
probability channel in the usual sense.

409
00:13:35,610 --> 00:13:37,686
Equivalently, the matrix for F would be

410
00:13:37,708 --> 00:13:39,846
stochastic. So these are the ones we'll

411
00:13:39,878 --> 00:13:41,980
use in generative models, for example.

412
00:13:44,270 --> 00:13:45,946
And as I said, there's lots of

413
00:13:45,968 --> 00:13:47,546
probability theory you can describe with

414
00:13:47,568 --> 00:13:49,242
these diagrams. It's very two simple

415
00:13:49,296 --> 00:13:50,662
examples. You can describe

416
00:13:50,726 --> 00:13:52,454
marginalization in probability theory

417
00:13:52,502 --> 00:13:53,866
with this discarding thing. So if you

418
00:13:53,888 --> 00:13:55,758
have box omega like this, it would be a

419
00:13:55,764 --> 00:13:57,438
joint distribution over X and Y. If you

420
00:13:57,444 --> 00:13:59,034
just discard Y, you'll get the marginal

421
00:13:59,082 --> 00:14:01,998
on X. And if you plug omega A

422
00:14:02,004 --> 00:14:04,366
distribution on X into an effect, that

423
00:14:04,388 --> 00:14:06,186
would just be any function on X, this

424
00:14:06,228 --> 00:14:07,858
would be giving you a scalar now, and

425
00:14:07,864 --> 00:14:09,714
that would be the expectation value of E

426
00:14:09,752 --> 00:14:13,166
in this distribution. So I'll meet lots

427
00:14:13,198 --> 00:14:14,606
more of this as we go, but let's

428
00:14:14,638 --> 00:14:16,206
actually start doing some stuff related

429
00:14:16,238 --> 00:14:17,506
to active inference in particular now.

430
00:14:17,528 --> 00:14:19,074
So I want to talk about generative

431
00:14:19,122 --> 00:14:20,598
models and how you view these in the

432
00:14:20,604 --> 00:14:23,318
diagrams. So, as we've said, we're going

433
00:14:23,324 --> 00:14:25,046
to be talking about agents having

434
00:14:25,068 --> 00:14:26,646
generative models that relate things

435
00:14:26,668 --> 00:14:28,662
like actions, observations and world

436
00:14:28,716 --> 00:14:31,126
states. And these are normally quite

437
00:14:31,148 --> 00:14:32,366
compositional in active inference,

438
00:14:32,418 --> 00:14:34,538
right, and might involve many different

439
00:14:34,624 --> 00:14:36,906
spaces of states and observations and

440
00:14:36,928 --> 00:14:38,758
these processes relating them. You'd

441
00:14:38,774 --> 00:14:39,818
usually treat these as something like a

442
00:14:39,824 --> 00:14:41,946
Bayesian network, claiming you can view

443
00:14:41,968 --> 00:14:43,306
it really as a causal Bayesian network

444
00:14:43,338 --> 00:14:44,878
because it's sort of describing how

445
00:14:44,964 --> 00:14:46,830
states are causing these observations.

446
00:14:48,290 --> 00:14:49,486
Formally, it's the same thing. It's just

447
00:14:49,508 --> 00:14:51,326
Bayesian network, which you could

448
00:14:51,348 --> 00:14:52,654
normally say is described as something

449
00:14:52,692 --> 00:14:54,058
like a dag, a directed asynchronous

450
00:14:54,074 --> 00:14:56,402
graph, which describe the different

451
00:14:56,456 --> 00:14:57,986
variables that are being related and

452
00:14:58,008 --> 00:14:59,666
then sets the values for each and

453
00:14:59,688 --> 00:15:01,826
probability channels, describing each

454
00:15:01,848 --> 00:15:03,934
one in terms of its parents in the Dag.

455
00:15:03,982 --> 00:15:05,314
And then you often look at its whole

456
00:15:05,352 --> 00:15:07,570
distribution over all the variables.

457
00:15:07,910 --> 00:15:10,306
But already I'd say the way that these

458
00:15:10,488 --> 00:15:12,066
visual networks are drawn in active

459
00:15:12,098 --> 00:15:13,366
inference text and stuff is kind of

460
00:15:13,388 --> 00:15:14,886
converging on something a bit closer to

461
00:15:14,908 --> 00:15:16,386
string diagrams because you don't

462
00:15:16,498 --> 00:15:18,678
actually just draw the Dag and the

463
00:15:18,684 --> 00:15:20,294
variables. It's very useful to actually

464
00:15:20,332 --> 00:15:22,650
give names to the mechanisms themselves,

465
00:15:22,720 --> 00:15:23,946
as it were, like you have in this

466
00:15:23,968 --> 00:15:26,858
picture, the A and the B's. So yeah, my

467
00:15:26,864 --> 00:15:28,682
claim is that it's sort of converging on

468
00:15:28,816 --> 00:15:30,586
the way that string diagrams will look,

469
00:15:30,608 --> 00:15:31,966
as we'll see on the next slide, which is

470
00:15:31,988 --> 00:15:34,174
where you really do label everything,

471
00:15:34,372 --> 00:15:36,190
not just the variables.

472
00:15:37,330 --> 00:15:39,898
So to describe those sort of Bayesian

473
00:15:39,914 --> 00:15:41,534
networks with string diagrams, the key

474
00:15:41,572 --> 00:15:42,826
observation is really that Dags

475
00:15:42,858 --> 00:15:44,278
correspond to a certain class of string

476
00:15:44,314 --> 00:15:46,142
diagrams that we're called network

477
00:15:46,206 --> 00:15:49,346
diagrams. There's a definition here,

478
00:15:49,368 --> 00:15:50,546
but which is better just to see an

479
00:15:50,568 --> 00:15:52,622
example in a second. But the diagrams

480
00:15:52,686 --> 00:15:54,082
built from copying and sometimes

481
00:15:54,136 --> 00:15:56,158
discarding and the key thing is just

482
00:15:56,184 --> 00:15:58,614
that they only have processes with maybe

483
00:15:58,652 --> 00:16:02,166
many inputs but only one output. So this

484
00:16:02,188 --> 00:16:03,526
is going to be like a mechanism that

485
00:16:03,548 --> 00:16:06,886
produces each variable. So the result is

486
00:16:06,908 --> 00:16:09,222
that if you have a Dag G and you choose

487
00:16:09,276 --> 00:16:11,626
some of the vertices to be outputs, so

488
00:16:11,648 --> 00:16:13,430
those are like the observed variables,

489
00:16:13,590 --> 00:16:15,242
you can draw a network diagram which

490
00:16:15,296 --> 00:16:17,222
expresses the same equivalent structure

491
00:16:17,286 --> 00:16:19,306
with those things as the outputs. So

492
00:16:19,328 --> 00:16:21,034
here's an example. We have a Dag with

493
00:16:21,072 --> 00:16:23,180
these four variables, x one to x four.

494
00:16:23,870 --> 00:16:26,046
And what you do is you have a wire for

495
00:16:26,068 --> 00:16:28,078
each variable in your diagram on the

496
00:16:28,084 --> 00:16:30,506
right and you draw a box that produces

497
00:16:30,538 --> 00:16:31,486
it. It doesn't really matter what you

498
00:16:31,508 --> 00:16:35,150
label the box. So this

499
00:16:35,220 --> 00:16:37,486
box C, for example, produces x two and

500
00:16:37,508 --> 00:16:38,546
it will produce it in terms of its

501
00:16:38,568 --> 00:16:41,234
parents in the Dag. So x one and x four

502
00:16:41,272 --> 00:16:42,546
in this case. And if it doesn't have any

503
00:16:42,568 --> 00:16:44,178
parents, it would just be a state, as it

504
00:16:44,184 --> 00:16:46,946
were, box and no input. And then what

505
00:16:46,968 --> 00:16:48,338
you do is you take each variable and you

506
00:16:48,344 --> 00:16:49,894
copy it and you pass it to all of its

507
00:16:49,932 --> 00:16:52,518
children in the Dag and also out of the

508
00:16:52,524 --> 00:16:54,374
diagram if it's an output. So this now

509
00:16:54,412 --> 00:16:55,654
means you've sort of expressed the whole

510
00:16:55,692 --> 00:16:57,814
structure of the Dag and also which

511
00:16:57,852 --> 00:16:59,906
variables are sort of leaving the system

512
00:16:59,948 --> 00:17:03,466
for the output ones. So this allows us

513
00:17:03,488 --> 00:17:05,386
to turn Dag into a string diagram and

514
00:17:05,408 --> 00:17:06,534
then if we want to make a generative

515
00:17:06,582 --> 00:17:09,398
model that expresses like a Bayesian

516
00:17:09,414 --> 00:17:10,858
network that's structured according to

517
00:17:10,864 --> 00:17:12,874
this Dag, you just have to now interpret

518
00:17:12,922 --> 00:17:16,174
this diagram in a certain sense. So in

519
00:17:16,212 --> 00:17:17,994
general, working in any one of these CD

520
00:17:18,042 --> 00:17:19,546
categories, this copy discard

521
00:17:19,578 --> 00:17:21,754
categories, we can say that a generative

522
00:17:21,802 --> 00:17:23,438
model in there is given by one of these

523
00:17:23,444 --> 00:17:26,574
network diagrams without any inputs and

524
00:17:26,612 --> 00:17:27,926
an interpretation of the diagram.

525
00:17:27,978 --> 00:17:29,346
Meaning you actually say what the

526
00:17:29,368 --> 00:17:31,058
objects are for each of the wires in the

527
00:17:31,064 --> 00:17:33,006
diagram and what the actual channels

528
00:17:33,038 --> 00:17:34,226
are. So they need to be channels, not

529
00:17:34,248 --> 00:17:36,946
just morphisms in your category are for

530
00:17:36,968 --> 00:17:39,814
each of the boxes. So for a gender model

531
00:17:39,852 --> 00:17:41,254
like this, you would say you pick

532
00:17:41,292 --> 00:17:43,574
objects x one, x two, x two, x four and

533
00:17:43,612 --> 00:17:46,658
pick channels for the ABCD. And we'll

534
00:17:46,674 --> 00:17:48,838
think of the output of the diagram as

535
00:17:48,844 --> 00:17:50,006
like the observed variables and the rest

536
00:17:50,028 --> 00:17:53,178
of the hidden ones. So for example, if

537
00:17:53,184 --> 00:17:55,386
you're working in this category, Mat R

538
00:17:55,408 --> 00:17:57,546
Plus, that is the only category I've

539
00:17:57,568 --> 00:17:58,586
actually introduced here. So this is

540
00:17:58,608 --> 00:18:00,186
going to be our running example. This is

541
00:18:00,208 --> 00:18:01,706
the same thing as one of these causal

542
00:18:01,738 --> 00:18:02,894
Bayesian networks. So it just means

543
00:18:02,932 --> 00:18:04,526
picking sets of values for variables and

544
00:18:04,548 --> 00:18:06,878
picking probability channels for the

545
00:18:06,884 --> 00:18:10,702
boxes. So you might ask why

546
00:18:10,756 --> 00:18:12,206
would you use this representation rather

547
00:18:12,228 --> 00:18:13,358
than the usual one, which I think is a

548
00:18:13,364 --> 00:18:16,146
good question. So it's equivalent to the

549
00:18:16,168 --> 00:18:19,250
Dag and probability channel description.

550
00:18:19,670 --> 00:18:21,954
But the thing that's nice is that in the

551
00:18:21,992 --> 00:18:23,326
conventional approach of these networks,

552
00:18:23,358 --> 00:18:24,946
you sort of have to switch between the

553
00:18:24,968 --> 00:18:26,338
Dags, which are split the variables and

554
00:18:26,344 --> 00:18:28,674
then doing calculations with

555
00:18:28,712 --> 00:18:30,998
probabilities, whereas in the

556
00:18:31,004 --> 00:18:32,326
categorical approach you can use just

557
00:18:32,348 --> 00:18:33,606
one formatism because you can do

558
00:18:33,628 --> 00:18:34,786
probability theory with the string

559
00:18:34,818 --> 00:18:36,466
diagrams as well. So it's quite natural

560
00:18:36,498 --> 00:18:37,574
in that sense. You have this one

561
00:18:37,612 --> 00:18:39,506
language of both just intuitively

562
00:18:39,538 --> 00:18:40,966
drawing what's going on in a model and

563
00:18:40,988 --> 00:18:43,366
then reasoning about it. It also lets

564
00:18:43,398 --> 00:18:45,258
you start to generalize things in a

565
00:18:45,264 --> 00:18:47,706
useful way, I think. So I kept having to

566
00:18:47,728 --> 00:18:49,418
say that you have no inputs to your

567
00:18:49,424 --> 00:18:50,986
diagram, but there's nothing really

568
00:18:51,088 --> 00:18:52,526
fundamental about that and it's not

569
00:18:52,548 --> 00:18:54,958
really clear why we need that. What you

570
00:18:54,964 --> 00:18:56,586
can do instead is start to allow inputs

571
00:18:56,618 --> 00:19:00,734
to your model as well. So we'll call

572
00:19:00,772 --> 00:19:02,686
this an open generative model. So an

573
00:19:02,708 --> 00:19:05,262
open generative model is the same thing.

574
00:19:05,316 --> 00:19:06,206
But now I've just dropped this

575
00:19:06,228 --> 00:19:07,506
requirement, the diagram doesn't have

576
00:19:07,528 --> 00:19:10,258
any inputs. So here's an example of a

577
00:19:10,264 --> 00:19:11,826
general network diagram. Now, with these

578
00:19:11,848 --> 00:19:13,746
inputs x two, x three. So there's no

579
00:19:13,768 --> 00:19:15,426
mechanism specified for these new

580
00:19:15,448 --> 00:19:16,626
variables, x two, x three. They're just

581
00:19:16,648 --> 00:19:19,186
input variables to the system and they

582
00:19:19,208 --> 00:19:20,726
can be outputs as well. For example, x

583
00:19:20,748 --> 00:19:22,146
three is both an input and an output

584
00:19:22,178 --> 00:19:24,326
here. And again, an interpretation of

585
00:19:24,348 --> 00:19:25,766
this general network diagram just means

586
00:19:25,788 --> 00:19:27,670
picking the objects and the channels.

587
00:19:28,650 --> 00:19:30,166
This is the same definition we use to

588
00:19:30,188 --> 00:19:31,490
define what we call an open calls and

589
00:19:31,500 --> 00:19:34,266
model in the paper with Robin Lorenz I

590
00:19:34,288 --> 00:19:36,566
mentioned earlier. So an emergenerative

591
00:19:36,598 --> 00:19:38,154
model is formally just the same thing,

592
00:19:38,272 --> 00:19:39,786
but we're just thinking of it as a

593
00:19:39,808 --> 00:19:41,818
generative model possessed by a

594
00:19:41,824 --> 00:19:44,346
cognitive agent. If you run this

595
00:19:44,368 --> 00:19:46,078
definition in mathar plus then this is

596
00:19:46,084 --> 00:19:47,486
just like a causal Bayern network. But

597
00:19:47,508 --> 00:19:48,798
now you have some of your variables just

598
00:19:48,804 --> 00:19:50,538
have no mechanism specified. So they're

599
00:19:50,554 --> 00:19:52,240
just inputs to the whole thing.

600
00:19:53,730 --> 00:19:54,814
The nice thing about these open

601
00:19:54,852 --> 00:19:56,578
generative models is that because they

602
00:19:56,584 --> 00:19:57,986
can have these inputs, you can plug them

603
00:19:58,008 --> 00:20:00,514
together and compose them. These things

604
00:20:00,552 --> 00:20:02,018
in fact form their own category. But I

605
00:20:02,024 --> 00:20:03,220
won't go into that today.

606
00:20:05,270 --> 00:20:07,026
So that was the general theory of these

607
00:20:07,048 --> 00:20:08,482
generative models that just actually

608
00:20:08,536 --> 00:20:10,326
described some examples that you'll see

609
00:20:10,348 --> 00:20:11,798
in active inference coming up all the

610
00:20:11,804 --> 00:20:14,738
time. So it's a simple example. Let's

611
00:20:14,754 --> 00:20:16,226
just imagine we have one space of hidden

612
00:20:16,258 --> 00:20:18,146
states and one space of observations.

613
00:20:18,258 --> 00:20:19,958
Then it would be generative model of

614
00:20:19,964 --> 00:20:21,146
that form would just look like this

615
00:20:21,168 --> 00:20:23,866
network diagram where there's just two

616
00:20:23,888 --> 00:20:27,206
wires, there's just S and O. S doesn't

617
00:20:27,238 --> 00:20:28,426
have any parents, so it just has this

618
00:20:28,448 --> 00:20:30,106
prior distribution sigma over it. And

619
00:20:30,128 --> 00:20:32,042
there's just this one channel often

620
00:20:32,096 --> 00:20:34,766
called the likelihood from S to O. If

621
00:20:34,788 --> 00:20:36,158
you just draw that network diagram, say

622
00:20:36,244 --> 00:20:39,486
that model in C or in Matar plus it

623
00:20:39,508 --> 00:20:41,294
would be the same as one of these simple

624
00:20:41,332 --> 00:20:43,246
generative models. When you're looking

625
00:20:43,268 --> 00:20:44,922
at these, you're often introduced

626
00:20:45,066 --> 00:20:46,642
interested in this distribution over

627
00:20:46,696 --> 00:20:48,286
both variables together. This joint

628
00:20:48,318 --> 00:20:50,706
distribution that you might write as P

629
00:20:50,728 --> 00:20:53,298
of S times P of O given S normally or

630
00:20:53,384 --> 00:20:54,926
bit more specifically here introducing

631
00:20:54,958 --> 00:20:57,058
the names for the two distribution in

632
00:20:57,064 --> 00:20:59,198
the channel here in string diagrams,

633
00:20:59,214 --> 00:21:00,374
it's just the same as this. So you just

634
00:21:00,412 --> 00:21:02,866
take the prior and you make it an output

635
00:21:02,898 --> 00:21:04,786
now. And then you compose those channels

636
00:21:04,818 --> 00:21:06,566
together and this would give you a

637
00:21:06,588 --> 00:21:09,320
distribution. So a normalized state M

638
00:21:10,250 --> 00:21:12,746
over snow at this. So this is just the

639
00:21:12,768 --> 00:21:14,746
resulting joint distribution you get

640
00:21:14,768 --> 00:21:15,958
from the generative model. And we'll

641
00:21:15,974 --> 00:21:17,180
come back to that later.

642
00:21:19,230 --> 00:21:22,026
So, a more elaborate example of

643
00:21:22,048 --> 00:21:24,122
generative model that you'll see example

644
00:21:24,176 --> 00:21:26,126
in the active infants textbook are these

645
00:21:26,148 --> 00:21:27,598
discrete time models that are used a

646
00:21:27,604 --> 00:21:30,634
lot. So I'll walk through this diagram

647
00:21:30,682 --> 00:21:32,526
now, so this is an example of a more

648
00:21:32,548 --> 00:21:34,534
complex network diagram and a generative

649
00:21:34,602 --> 00:21:37,426
model it describes. So here we've got

650
00:21:37,448 --> 00:21:40,002
these end time steps going. Remember,

651
00:21:40,056 --> 00:21:41,518
we read from bottom to top, but I'll

652
00:21:41,534 --> 00:21:43,906
just talk about I'll describe things

653
00:21:43,928 --> 00:21:45,266
from the top down here. So at the top we

654
00:21:45,288 --> 00:21:47,720
have the observations one, two up to on

655
00:21:48,090 --> 00:21:50,262
the observations at each time being

656
00:21:50,316 --> 00:21:52,086
caused by these hidden states s one, S

657
00:21:52,108 --> 00:21:54,406
two and SN at each time by these

658
00:21:54,428 --> 00:21:58,066
channels A. And the hidden

659
00:21:58,098 --> 00:21:59,686
state is evolving over time by this

660
00:21:59,708 --> 00:22:01,526
transition channel B, where it takes the

661
00:22:01,548 --> 00:22:03,674
previous state as an input and then

662
00:22:03,712 --> 00:22:05,626
choose the next one. It also takes us

663
00:22:05,648 --> 00:22:07,018
one extra wire that's coming from the

664
00:22:07,024 --> 00:22:08,554
bottom and that's this space P of

665
00:22:08,592 --> 00:22:10,458
policies, which is how the agent sort of

666
00:22:10,464 --> 00:22:12,286
actions enter the picture. So these

667
00:22:12,308 --> 00:22:14,414
policies describe its behaviors, its

668
00:22:14,452 --> 00:22:16,894
behavioral policies it can carry out.

669
00:22:17,012 --> 00:22:18,526
So, based on the previous hidden state

670
00:22:18,548 --> 00:22:21,134
and the way it's acting. This channel B

671
00:22:21,172 --> 00:22:23,086
would determine the probabilities for

672
00:22:23,108 --> 00:22:24,986
the next states and then there's

673
00:22:25,018 --> 00:22:27,858
supplier over the policies that you can

674
00:22:27,864 --> 00:22:29,182
think of as the habits or the typical

675
00:22:29,246 --> 00:22:31,858
behaviors of the system. So you can just

676
00:22:31,864 --> 00:22:32,946
draw this diagram and say, like,

677
00:22:32,968 --> 00:22:35,026
interpret this in math plus and that

678
00:22:35,048 --> 00:22:36,782
would for any given interpretation,

679
00:22:36,926 --> 00:22:38,866
meaning any choice of what the values

680
00:22:38,898 --> 00:22:41,062
for these variables can possibly take

681
00:22:41,116 --> 00:22:42,454
are. And any choice for what these

682
00:22:42,492 --> 00:22:44,614
channels are would then give you this

683
00:22:44,652 --> 00:22:46,520
type of punitive model.

684
00:22:48,170 --> 00:22:51,318
And often you will see models sort of of

685
00:22:51,324 --> 00:22:53,046
this form or similar forms being plugged

686
00:22:53,078 --> 00:22:54,374
together to form these hierarchical

687
00:22:54,422 --> 00:22:56,182
models. And I think the compositional

688
00:22:56,326 --> 00:22:57,786
language is very nice for these because

689
00:22:57,808 --> 00:22:58,794
you really want to talk about open

690
00:22:58,832 --> 00:23:01,398
models to define this so hierarchical

691
00:23:01,494 --> 00:23:03,338
model you can view as really as just

692
00:23:03,344 --> 00:23:04,734
being given by taking lots of these open

693
00:23:04,772 --> 00:23:06,286
generative models I mentioned and

694
00:23:06,308 --> 00:23:07,582
plugging them together in a certain

695
00:23:07,636 --> 00:23:09,966
sense. So here you can see a picture of

696
00:23:09,988 --> 00:23:11,406
a hierarchical model where we just have

697
00:23:11,428 --> 00:23:13,758
these layers where different copies of

698
00:23:13,764 --> 00:23:15,474
the same model at each layer and the

699
00:23:15,512 --> 00:23:17,758
inputs from one layer match the outputs

700
00:23:17,774 --> 00:23:19,246
of the layer below so we can compose

701
00:23:19,278 --> 00:23:22,462
them together. So that's generative

702
00:23:22,526 --> 00:23:25,026
models. So so far we've just been using

703
00:23:25,048 --> 00:23:26,526
the diagrams to represent them. We'd

704
00:23:26,558 --> 00:23:27,666
like to actually do a bit more though

705
00:23:27,688 --> 00:23:29,206
and reason about these models. In

706
00:23:29,228 --> 00:23:30,294
particular, we'll talk about how you

707
00:23:30,332 --> 00:23:33,554
update a model or update the beliefs

708
00:23:33,602 --> 00:23:35,894
within a model, which is very important

709
00:23:35,932 --> 00:23:37,574
in active inference and how this looks

710
00:23:37,692 --> 00:23:41,734
in the string diagrams. Now, so let's

711
00:23:41,782 --> 00:23:44,538
say we've got an agent M, we have a

712
00:23:44,544 --> 00:23:47,834
model M and it's just a simple one

713
00:23:47,872 --> 00:23:49,306
where we say there's just one space of

714
00:23:49,328 --> 00:23:50,698
hidden space S and one space of

715
00:23:50,704 --> 00:23:52,214
observations O. So they have this joint

716
00:23:52,262 --> 00:23:54,330
distribution that I mentioned earlier

717
00:23:54,670 --> 00:23:57,038
and they had these prior beliefs about s

718
00:23:57,124 --> 00:23:58,538
which you can get back from the joint

719
00:23:58,554 --> 00:23:59,518
distribution by just taking the

720
00:23:59,524 --> 00:24:01,290
marginal, if you like. So that's sigma.

721
00:24:01,370 --> 00:24:02,686
So they've got their model, they've got

722
00:24:02,708 --> 00:24:04,238
their beliefs about what states are

723
00:24:04,244 --> 00:24:05,634
likely and then they receive a new

724
00:24:05,672 --> 00:24:07,938
observation. And here the kind of

725
00:24:07,944 --> 00:24:08,818
observations we'll think about in

726
00:24:08,824 --> 00:24:10,686
general can be soft, meaning they're

727
00:24:10,718 --> 00:24:12,994
described by a distribution over O, not

728
00:24:13,032 --> 00:24:15,986
necessarily just one element. So that

729
00:24:16,008 --> 00:24:19,238
would be one of these normalized states.

730
00:24:19,404 --> 00:24:20,806
I'll try not to use the word state here

731
00:24:20,828 --> 00:24:22,054
because it's a bit confusing with this S

732
00:24:22,092 --> 00:24:25,766
around. So this distribution over O is

733
00:24:25,788 --> 00:24:28,038
their new observation, this bold font O.

734
00:24:28,204 --> 00:24:30,510
And now they want to update the margin,

735
00:24:30,610 --> 00:24:32,458
want to update M in some way so that the

736
00:24:32,464 --> 00:24:34,826
marginal basically is different and

737
00:24:34,848 --> 00:24:37,094
describes the updated posterior beliefs.

738
00:24:37,222 --> 00:24:38,826
And this comes up of course in

739
00:24:38,848 --> 00:24:41,466
perception where you're updating your

740
00:24:41,488 --> 00:24:43,326
sort of state of the world given some

741
00:24:43,348 --> 00:24:44,638
observation you receive. But it could

742
00:24:44,644 --> 00:24:45,914
also be used to model like planning

743
00:24:45,962 --> 00:24:48,286
behavior where updating your plan of

744
00:24:48,308 --> 00:24:51,182
action, your policy given something

745
00:24:51,236 --> 00:24:53,742
like. Which outcomes you'd like to see

746
00:24:53,796 --> 00:24:55,938
in the future and we'll come back to

747
00:24:55,944 --> 00:24:59,106
that later in the talk. So we want

748
00:24:59,128 --> 00:25:00,594
to talk about how you can do this

749
00:25:00,632 --> 00:25:03,518
updating. So you might think there's

750
00:25:03,534 --> 00:25:04,898
just a standard answer or at least in

751
00:25:04,904 --> 00:25:06,286
the ideal case, which is this Bayesian

752
00:25:06,318 --> 00:25:07,746
updating. And that's true when your

753
00:25:07,768 --> 00:25:09,686
observations are sharp. We'll start by

754
00:25:09,708 --> 00:25:11,526
talking about that case. So I'll say

755
00:25:11,548 --> 00:25:13,606
what sharp means in a second. But first

756
00:25:13,628 --> 00:25:14,534
I'll just talk about how you treat

757
00:25:14,572 --> 00:25:16,066
Bayesian conditioning in these string

758
00:25:16,098 --> 00:25:19,420
diagrams. So on the right here we have

759
00:25:19,950 --> 00:25:22,154
if you view this process from O to S,

760
00:25:22,272 --> 00:25:24,054
this describes the sort of Bayesian

761
00:25:24,102 --> 00:25:26,586
conditional channel, or in general a

762
00:25:26,608 --> 00:25:29,162
partial channel in fact that the agent

763
00:25:29,216 --> 00:25:31,386
would have from the introduced by their

764
00:25:31,408 --> 00:25:33,598
model. So you can describe this in

765
00:25:33,604 --> 00:25:35,038
string diagrams with a couple of extra

766
00:25:35,124 --> 00:25:37,518
gadgets I hadn't mentioned yet. So you

767
00:25:37,524 --> 00:25:39,600
have your distribution m over S and O.

768
00:25:39,970 --> 00:25:42,286
You can have this in math there's this

769
00:25:42,308 --> 00:25:44,542
effect that we call the cat which just

770
00:25:44,676 --> 00:25:46,238
takes two inputs and compares if they're

771
00:25:46,254 --> 00:25:48,146
equal. This allows for you to turn an

772
00:25:48,168 --> 00:25:49,586
output into an input. So that's what

773
00:25:49,608 --> 00:25:51,906
this part here is. And then you can

774
00:25:51,928 --> 00:25:53,426
introduce this extra thing of

775
00:25:53,448 --> 00:25:55,282
normalization. So what you'd like to do

776
00:25:55,336 --> 00:25:58,514
is take a general morphism and for each

777
00:25:58,552 --> 00:26:01,046
possible input normalize that so that

778
00:26:01,068 --> 00:26:02,918
it's a distribution if you can or set it

779
00:26:02,924 --> 00:26:04,418
to zero if it's just zero and there's

780
00:26:04,434 --> 00:26:06,246
nothing you can do, that's what this

781
00:26:06,268 --> 00:26:09,718
blue dash box is. And in the paper and

782
00:26:09,804 --> 00:26:11,274
in the related calls and models paper,

783
00:26:11,312 --> 00:26:13,238
we talk about the axioms normalization

784
00:26:13,334 --> 00:26:16,234
feature satisfies. The point is if you

785
00:26:16,272 --> 00:26:17,898
compute this thing in Matar Plus, it

786
00:26:17,904 --> 00:26:19,338
will give you kind of what you'd expect.

787
00:26:19,424 --> 00:26:21,806
So it will give you the usual notion for

788
00:26:21,828 --> 00:26:25,150
each .0 of the space O,

789
00:26:25,300 --> 00:26:27,038
you plug it into this, you'll get a kind

790
00:26:27,044 --> 00:26:30,526
of conditional M of S given O that

791
00:26:30,548 --> 00:26:32,510
you'd expect whenever that's defined.

792
00:26:33,010 --> 00:26:34,526
There's a strange diagram way to

793
00:26:34,548 --> 00:26:36,494
describe this kind of Bayesian

794
00:26:36,542 --> 00:26:39,300
conditional channel or partial channel.

795
00:26:39,670 --> 00:26:41,186
And I said this is what you would use

796
00:26:41,208 --> 00:26:43,202
when your observation is sharp. And I

797
00:26:43,256 --> 00:26:44,386
also drew it differently with this

798
00:26:44,408 --> 00:26:45,906
triangle to sort of distinguish that

799
00:26:45,928 --> 00:26:47,974
case. So what does that mean in general?

800
00:26:48,012 --> 00:26:50,626
You say that a state in one of these CD

801
00:26:50,658 --> 00:26:53,382
categories, so a distribution basically

802
00:26:53,516 --> 00:26:55,638
would be sharp when it's copied by the

803
00:26:55,644 --> 00:26:57,142
copy map, which isn't true for general

804
00:26:57,196 --> 00:27:00,406
distributions. And if you run this

805
00:27:00,428 --> 00:27:02,154
definition in math or plus, this really

806
00:27:02,192 --> 00:27:03,994
means that this thing O really is just

807
00:27:04,032 --> 00:27:05,866
point distribution at some specific

808
00:27:05,968 --> 00:27:08,858
element of O. So it really is sharp in

809
00:27:08,864 --> 00:27:10,806
that sense. It's just a point. There's

810
00:27:10,838 --> 00:27:13,626
no real probabilities probabilistic

811
00:27:13,658 --> 00:27:16,586
aspects to it there. But in any CP

812
00:27:16,618 --> 00:27:18,046
category you can just talk about the

813
00:27:18,068 --> 00:27:19,390
sharp states like this. They're often

814
00:27:19,460 --> 00:27:22,606
also called deterministic. So for these

815
00:27:22,628 --> 00:27:24,558
sharp ones, you ideally think you'd like

816
00:27:24,564 --> 00:27:26,654
to do the spacing updating. But in fact

817
00:27:26,692 --> 00:27:28,078
when you've got soft ones. So it doesn't

818
00:27:28,094 --> 00:27:30,658
have this property. There's actually at

819
00:27:30,664 --> 00:27:32,146
least two good ways to do this kind of

820
00:27:32,168 --> 00:27:34,034
updating. I don't know if this is as

821
00:27:34,072 --> 00:27:36,434
well known, so I'll just mention it now

822
00:27:36,472 --> 00:27:37,698
anyway, and they've been studied in some

823
00:27:37,704 --> 00:27:39,558
detail by Bart Jacobs, this paper at the

824
00:27:39,564 --> 00:27:42,278
bottom. So let's say you don't get one

825
00:27:42,284 --> 00:27:44,038
of these sharp observations. You have

826
00:27:44,044 --> 00:27:46,518
just a distribution over o. There's at

827
00:27:46,524 --> 00:27:48,114
least two reasonable ways to generalize

828
00:27:48,162 --> 00:27:49,586
sort of the picture from the last slide

829
00:27:49,618 --> 00:27:51,918
to give a notion of updating. And Jacobs

830
00:27:51,954 --> 00:27:53,526
calls them Jeffries and Pearl's update

831
00:27:53,558 --> 00:27:57,190
rules. So in Jefferies Update,

832
00:27:57,350 --> 00:27:59,146
you basically do it like we did before.

833
00:27:59,248 --> 00:28:01,786
You have this Bayesian conditional kind

834
00:28:01,808 --> 00:28:03,498
of channel or partial channel, the

835
00:28:03,504 --> 00:28:04,926
normalized box here, and you just plug a

836
00:28:04,948 --> 00:28:06,986
distribution into it. But in Pearl's

837
00:28:07,018 --> 00:28:09,646
Update, you turn a distribution into an

838
00:28:09,668 --> 00:28:11,006
effect. So you just compose it with this

839
00:28:11,028 --> 00:28:12,506
cap to bend it around in the picture.

840
00:28:12,538 --> 00:28:14,814
That's what it means. So you plug that

841
00:28:14,852 --> 00:28:16,722
into M and then normalize everything.

842
00:28:16,776 --> 00:28:17,746
So the difference is where the

843
00:28:17,768 --> 00:28:20,754
normalization happens. And yes,

844
00:28:20,792 --> 00:28:21,922
it's basically just interesting that

845
00:28:21,976 --> 00:28:23,342
both of these are reasonable notions,

846
00:28:23,406 --> 00:28:24,386
generalization, they have different

847
00:28:24,408 --> 00:28:26,098
properties. It's not obvious that one of

848
00:28:26,104 --> 00:28:27,366
them is sort of more rational or

849
00:28:27,388 --> 00:28:29,062
something than the other. They just

850
00:28:29,116 --> 00:28:32,626
behave a bit differently. In the formula

851
00:28:32,658 --> 00:28:35,286
you can see that the normalization is

852
00:28:35,308 --> 00:28:36,598
being applied differently. So if you

853
00:28:36,604 --> 00:28:38,262
turn this picture into these little

854
00:28:38,316 --> 00:28:41,014
notations, it would look like this. So

855
00:28:41,052 --> 00:28:43,302
in the top case you're normalizing for

856
00:28:43,356 --> 00:28:46,486
each possible sharp o and then taking an

857
00:28:46,508 --> 00:28:48,166
expectation over this distribution here.

858
00:28:48,188 --> 00:28:50,206
Whereas in the Pearl case, you plug the

859
00:28:50,228 --> 00:28:51,086
whole thing together and then just

860
00:28:51,108 --> 00:28:53,806
normalize. Either way you do it though,

861
00:28:53,828 --> 00:28:54,686
the point is that these things are

862
00:28:54,708 --> 00:28:55,898
actually hard to compute. So we don't

863
00:28:55,914 --> 00:28:57,566
expect a cognitive agent to be doing

864
00:28:57,588 --> 00:28:58,878
either of these exactly, even in the

865
00:28:58,884 --> 00:29:01,246
sharp case. And so, as we know, we want

866
00:29:01,268 --> 00:29:02,738
to instead approximate these kind of

867
00:29:02,744 --> 00:29:05,090
things using free energy, which is what

868
00:29:05,160 --> 00:29:06,340
I'll talk about next.

869
00:29:09,350 --> 00:29:11,406
So our aim is to try and accommodate

870
00:29:11,438 --> 00:29:12,734
free energy somehow in the diagrammatic

871
00:29:12,782 --> 00:29:15,838
approach and free energy sort of formula

872
00:29:15,854 --> 00:29:17,158
that come up are often given in terms of

873
00:29:17,164 --> 00:29:18,406
what you call the Surprise, these

874
00:29:18,428 --> 00:29:20,418
negative logarithm quantities. So we'll

875
00:29:20,434 --> 00:29:22,726
start by introducing just a new

876
00:29:22,748 --> 00:29:24,534
graphical component for treating those

877
00:29:24,572 --> 00:29:27,782
that we call log boxes. If you have any

878
00:29:27,836 --> 00:29:31,202
function E on a set X, a positive

879
00:29:31,266 --> 00:29:32,586
real, remember that made in A, that

880
00:29:32,608 --> 00:29:33,898
would look like an effect in your

881
00:29:33,984 --> 00:29:39,914
category X in Math Plus. Let's say then

882
00:29:39,952 --> 00:29:41,226
what we want to do is talk about this

883
00:29:41,248 --> 00:29:44,094
function X goes to minus log of e of X,

884
00:29:44,292 --> 00:29:45,934
which we call the Surprise. So we just

885
00:29:45,972 --> 00:29:47,886
introduce this graphical feature where

886
00:29:47,908 --> 00:29:49,966
we draw a green box around it and say

887
00:29:49,988 --> 00:29:51,920
that denotes this function. Now,

888
00:29:53,970 --> 00:29:56,578
and using rules, the nice properties of

889
00:29:56,584 --> 00:29:57,874
logarithm, you can turn these into nice

890
00:29:57,912 --> 00:29:59,886
graphical rules. This log box feature

891
00:29:59,918 --> 00:30:02,786
would satisfy for example, this is sort

892
00:30:02,808 --> 00:30:04,194
of the way that logarithms turn

893
00:30:04,232 --> 00:30:06,614
multiplication into addition on the left

894
00:30:06,652 --> 00:30:10,486
here. If you have this

895
00:30:10,508 --> 00:30:11,814
around, then you can start talking about

896
00:30:11,852 --> 00:30:14,454
surprise. So if you have two

897
00:30:14,492 --> 00:30:18,086
distributions, sigma and Omega, the

898
00:30:18,108 --> 00:30:20,418
surprise of one distribution relative to

899
00:30:20,444 --> 00:30:22,102
the other is defined by this expectation

900
00:30:22,166 --> 00:30:24,666
value. So just the expectation of a

901
00:30:24,688 --> 00:30:27,318
surprise of sigma according to Omega

902
00:30:27,334 --> 00:30:28,806
which if you remember I said expectation

903
00:30:28,838 --> 00:30:30,586
values are given by sort of plugging a

904
00:30:30,608 --> 00:30:32,586
state for the distribution into the

905
00:30:32,608 --> 00:30:33,834
thing you're looking at the expectation

906
00:30:33,882 --> 00:30:35,422
value of. So that would be the log box

907
00:30:35,476 --> 00:30:38,110
here. So we can just define surprise

908
00:30:38,690 --> 00:30:40,638
omega, Sigma in this way if we like in

909
00:30:40,644 --> 00:30:42,334
the pictures. And important special

910
00:30:42,372 --> 00:30:44,058
cases where this come up are when you're

911
00:30:44,074 --> 00:30:45,978
calculating entropy, which is the self

912
00:30:46,004 --> 00:30:48,210
surprise. And the KL divergence can be

913
00:30:48,360 --> 00:30:49,906
calculated from the surprise and the

914
00:30:49,928 --> 00:30:52,818
entropy. So it means that whenever we

915
00:30:52,824 --> 00:30:54,178
have formula given in terms of these if

916
00:30:54,184 --> 00:30:56,322
we like, we can instead denote them with

917
00:30:56,376 --> 00:30:58,598
this graphical symbol, at least with the

918
00:30:58,604 --> 00:30:59,480
log box.

919
00:31:01,370 --> 00:31:03,366
So now let's talk about how we use this

920
00:31:03,388 --> 00:31:04,806
to describe free energy. So what we

921
00:31:04,828 --> 00:31:06,326
wanted to do in the paper is sort of

922
00:31:06,428 --> 00:31:07,766
help clarify the kind of different

923
00:31:07,788 --> 00:31:09,462
notions of free energy that we found in

924
00:31:09,516 --> 00:31:11,302
active instruments. In particular the

925
00:31:11,436 --> 00:31:13,250
variational and the expected free energy

926
00:31:13,260 --> 00:31:15,338
energy. So we want one more general

927
00:31:15,424 --> 00:31:17,738
quantity that we can understand both of

928
00:31:17,744 --> 00:31:19,786
those in terms of. I'm just calling out

929
00:31:19,808 --> 00:31:22,426
the free energy here. I'm interested to

930
00:31:22,448 --> 00:31:24,126
know what other people think of this

931
00:31:24,148 --> 00:31:26,080
sort of naming for what we're doing.

932
00:31:26,610 --> 00:31:28,206
The situation is that we've got some

933
00:31:28,228 --> 00:31:29,966
generative model that's fixed over these

934
00:31:29,988 --> 00:31:31,726
two variables Sno like before. So

935
00:31:31,748 --> 00:31:33,294
remember we had this distribution, this

936
00:31:33,332 --> 00:31:37,258
box M over Sno distribution. And let's

937
00:31:37,274 --> 00:31:38,802
just say we have another distribution Q

938
00:31:38,856 --> 00:31:40,418
now and we'll see examples of this in a

939
00:31:40,424 --> 00:31:42,194
second what sort of Q they would be.

940
00:31:42,392 --> 00:31:44,002
Then we just define this quantity of

941
00:31:44,056 --> 00:31:45,746
free energy of the one relative to the

942
00:31:45,768 --> 00:31:48,310
other in this way. So it's the surprise

943
00:31:48,730 --> 00:31:51,938
minus the entropy of Q in the string

944
00:31:51,954 --> 00:31:53,894
diagrams. Then it's just this feature we

945
00:31:53,932 --> 00:31:56,386
plug. So it's like the expected surprise

946
00:31:56,418 --> 00:32:00,086
of M for Q minus the entropy of Q's

947
00:32:00,118 --> 00:32:03,766
marginal on S. Or this is the formula

948
00:32:03,798 --> 00:32:05,366
if you want to use the conventional

949
00:32:05,398 --> 00:32:07,306
notation which is useful for relating it

950
00:32:07,328 --> 00:32:10,518
to existing approaches. So we can define

951
00:32:10,534 --> 00:32:12,134
this very general free energy quantity

952
00:32:12,182 --> 00:32:13,998
and then we'll meet two special cases of

953
00:32:14,004 --> 00:32:15,166
it that we're interested in, which is

954
00:32:15,188 --> 00:32:18,062
the variational and expected free

955
00:32:18,116 --> 00:32:20,526
energy. It all comes down basically to

956
00:32:20,548 --> 00:32:22,686
having a definition of surprise. You

957
00:32:22,708 --> 00:32:23,966
just need this notion of surprise to

958
00:32:23,988 --> 00:32:27,038
define everything else. So with a

959
00:32:27,044 --> 00:32:29,666
variational free energy. So we have this

960
00:32:29,688 --> 00:32:31,442
fixed model M and we have this soft

961
00:32:31,496 --> 00:32:33,506
observation o like we did before. So

962
00:32:33,528 --> 00:32:35,678
that's this box here and then what we're

963
00:32:35,694 --> 00:32:36,754
doing is we're considering different

964
00:32:36,792 --> 00:32:38,406
possible distributions over S that we

965
00:32:38,428 --> 00:32:40,486
think of as different updates we could

966
00:32:40,508 --> 00:32:43,058
consider for our beliefs. And we define

967
00:32:43,074 --> 00:32:45,046
the variational free energy of any of

968
00:32:45,068 --> 00:32:48,294
those states, those distributions Q as

969
00:32:48,332 --> 00:32:49,686
the special case of the definition from

970
00:32:49,708 --> 00:32:51,178
the previous slide. So it's like the

971
00:32:51,184 --> 00:32:53,722
general free energy where that capital Q

972
00:32:53,776 --> 00:32:55,114
just takes this form. So it just

973
00:32:55,152 --> 00:32:58,378
consists of our new beliefs, lowercase Q

974
00:32:58,464 --> 00:32:59,980
and our observation O.

975
00:33:01,390 --> 00:33:03,598
So in formula you could also just draw

976
00:33:03,604 --> 00:33:05,002
it like this. So you take the surprise

977
00:33:05,066 --> 00:33:07,134
from your model M and you just see how

978
00:33:07,332 --> 00:33:09,646
its expected value for those beliefs and

979
00:33:09,668 --> 00:33:12,986
that observation subtracted the entropy

980
00:33:13,018 --> 00:33:14,560
of Q.

981
00:33:16,610 --> 00:33:18,470
And what you can show is that this VFV

982
00:33:18,490 --> 00:33:20,786
value satisfies this bound of the KL in

983
00:33:20,808 --> 00:33:22,942
relation to this kind of Jeffrey update

984
00:33:23,086 --> 00:33:24,434
of your model with respect to this

985
00:33:24,472 --> 00:33:28,098
observation. In particular, when it's a

986
00:33:28,104 --> 00:33:30,306
sharp observation, then the minimal of

987
00:33:30,328 --> 00:33:32,946
this VFE will be given by the Bayesian

988
00:33:32,978 --> 00:33:35,734
Updating. In general, though, we might

989
00:33:35,772 --> 00:33:37,974
think about what happens. So in general

990
00:33:38,012 --> 00:33:39,746
we can think of minimizing this VFP

991
00:33:39,778 --> 00:33:41,674
quantity as doing this, as finding this

992
00:33:41,712 --> 00:33:43,654
Q that approximates this kind of updates

993
00:33:43,702 --> 00:33:46,346
we were looking at earlier. And yeah,

994
00:33:46,368 --> 00:33:48,394
in the sharp case it will coincide as

995
00:33:48,432 --> 00:33:51,306
all of the notions of Updating do. So

996
00:33:51,328 --> 00:33:53,086
the minimal VFP will be given by the

997
00:33:53,108 --> 00:33:54,862
Bayesian update. But for these soft

998
00:33:54,916 --> 00:33:57,498
observations, it's something else. It's

999
00:33:57,514 --> 00:34:00,602
not exactly either of the two notions

1000
00:34:00,666 --> 00:34:01,998
Updating we met earlier. So this is

1001
00:34:02,004 --> 00:34:03,646
actually a third notion of updating for

1002
00:34:03,668 --> 00:34:06,286
soft observations, which I think is an

1003
00:34:06,308 --> 00:34:07,998
interesting way to think about what VFE

1004
00:34:08,094 --> 00:34:09,986
minimization is doing. So we just call

1005
00:34:10,008 --> 00:34:12,114
this the VFE update. So you've got many

1006
00:34:12,152 --> 00:34:13,426
different Q, you could calculate the

1007
00:34:13,448 --> 00:34:15,538
sphere quantity for each and you've got

1008
00:34:15,544 --> 00:34:17,346
a soft observation O here. So it's some

1009
00:34:17,368 --> 00:34:19,526
distribution. And if you find the one

1010
00:34:19,548 --> 00:34:21,078
with the minimal value of sphere, you

1011
00:34:21,084 --> 00:34:23,974
call that the VFE update. And this

1012
00:34:24,012 --> 00:34:25,506
wouldn't be equal to either those Pearl

1013
00:34:25,538 --> 00:34:28,120
or Jeffrey style updates that we met.

1014
00:34:28,970 --> 00:34:31,306
So that's the VFE which we'll come back

1015
00:34:31,328 --> 00:34:34,298
to, the other notion of free energy we

1016
00:34:34,304 --> 00:34:35,414
want to talk about, it's the expected

1017
00:34:35,462 --> 00:34:38,586
free energy. So that's where we still

1018
00:34:38,608 --> 00:34:40,606
have our model M. But rather than an

1019
00:34:40,628 --> 00:34:41,934
observation, we think of ourselves as

1020
00:34:41,972 --> 00:34:43,754
having some preferences of observations

1021
00:34:43,802 --> 00:34:45,946
we'd like to see they're again encoded

1022
00:34:45,978 --> 00:34:48,398
in a distribution, though over O. So

1023
00:34:48,404 --> 00:34:52,206
that's this C just

1024
00:34:52,228 --> 00:34:53,646
with that fixed, we can define this one

1025
00:34:53,668 --> 00:34:55,054
quantity called the expected free

1026
00:34:55,092 --> 00:34:57,314
energy. So that's given by the free

1027
00:34:57,352 --> 00:34:58,962
energy of M compared with this other

1028
00:34:59,016 --> 00:35:01,618
generative model where you have used the

1029
00:35:01,624 --> 00:35:03,346
same. So this M here would really be the

1030
00:35:03,368 --> 00:35:06,006
inverse channel from O to S of M. So

1031
00:35:06,028 --> 00:35:09,174
like the Bayesian inverse here, but

1032
00:35:09,212 --> 00:35:10,678
where you just assert that the

1033
00:35:10,684 --> 00:35:12,886
preference is actually is the prior on

1034
00:35:12,908 --> 00:35:14,322
the observation. So you're comparing

1035
00:35:14,386 --> 00:35:17,734
these two in terms of this generic free

1036
00:35:17,772 --> 00:35:20,806
energy quantity we defined earlier. So

1037
00:35:20,828 --> 00:35:22,238
again, you can turn this into formulae.

1038
00:35:22,274 --> 00:35:23,638
And there's loads of stuff in active

1039
00:35:23,654 --> 00:35:25,478
inference about the different rewritings

1040
00:35:25,494 --> 00:35:27,338
of EFE and the ways to interpret them in

1041
00:35:27,344 --> 00:35:29,580
terms of uncertainty and risk and so on.

1042
00:35:30,190 --> 00:35:32,606
And it has this property that you can

1043
00:35:32,628 --> 00:35:35,722
show it will be bounded by the surprise

1044
00:35:35,786 --> 00:35:38,238
of those preferences for your model and

1045
00:35:38,244 --> 00:35:39,118
it kind of gives you a way to

1046
00:35:39,124 --> 00:35:41,886
approximate them as we'll see. So I

1047
00:35:41,908 --> 00:35:43,278
won't talk, I don't think I have time to

1048
00:35:43,284 --> 00:35:44,750
go too much more into EFE. But the point

1049
00:35:44,820 --> 00:35:46,366
really in terms of what this work's done

1050
00:35:46,388 --> 00:35:49,034
is just to try and have just one generic

1051
00:35:49,082 --> 00:35:50,762
free energy quantity we met earlier

1052
00:35:50,826 --> 00:35:52,282
where we can see the VFE and the EFE

1053
00:35:52,346 --> 00:35:54,138
both coming up special cases depending

1054
00:35:54,154 --> 00:35:56,326
on what we plug in here for the two

1055
00:35:56,348 --> 00:35:57,430
distributions.

1056
00:35:59,610 --> 00:36:01,366
So what I'd like to do now is to sort of

1057
00:36:01,388 --> 00:36:02,486
put some of these pieces together to

1058
00:36:02,508 --> 00:36:03,718
show what active inference itself will

1059
00:36:03,724 --> 00:36:04,866
kind of look like in terms of string

1060
00:36:04,898 --> 00:36:06,438
diagrams. And in particular, what we'll

1061
00:36:06,444 --> 00:36:07,958
do is derive this formula that you'll

1062
00:36:07,974 --> 00:36:11,578
find in active inference textbooks in a

1063
00:36:11,584 --> 00:36:13,386
graphical way and I think quite a

1064
00:36:13,408 --> 00:36:15,530
transparent way, that's the claim.

1065
00:36:17,150 --> 00:36:20,138
So to do so, we basically need to give a

1066
00:36:20,144 --> 00:36:21,626
nice high level conceptual view of what

1067
00:36:21,648 --> 00:36:23,258
active inference is. So this is the way

1068
00:36:23,264 --> 00:36:26,094
that we do it in the paper. So when

1069
00:36:26,132 --> 00:36:28,030
inactive inference, the key thing for

1070
00:36:28,100 --> 00:36:29,406
stating all the definitions is that our

1071
00:36:29,428 --> 00:36:31,454
model takes the following form at a high

1072
00:36:31,492 --> 00:36:33,758
level. So there's some notion of so.

1073
00:36:33,764 --> 00:36:35,342
It's like our discrete time model we had

1074
00:36:35,396 --> 00:36:37,086
earlier, but just with two time steps.

1075
00:36:37,118 --> 00:36:39,166
If you like, each of those time steps

1076
00:36:39,198 --> 00:36:41,358
could break down in terms of further

1077
00:36:41,454 --> 00:36:43,394
subtime steps. But that won't matter.

1078
00:36:43,432 --> 00:36:45,554
We've just obstructed here at this

1079
00:36:45,592 --> 00:36:47,506
higher level. So at the higher level,

1080
00:36:47,528 --> 00:36:48,742
we just have a notion of the current

1081
00:36:48,796 --> 00:36:50,466
time, or maybe like all the time steps

1082
00:36:50,498 --> 00:36:52,662
up to the current time, and that's this

1083
00:36:52,716 --> 00:36:54,742
S and O here. So there's current states

1084
00:36:54,796 --> 00:36:56,806
and current observations and then

1085
00:36:56,828 --> 00:36:58,198
there's some notion of future times,

1086
00:36:58,284 --> 00:36:59,622
these future states and future

1087
00:36:59,676 --> 00:37:01,898
observations. So that could be all the

1088
00:37:01,904 --> 00:37:03,562
time steps up to some big number,

1089
00:37:03,696 --> 00:37:04,726
something like that, all grouped

1090
00:37:04,758 --> 00:37:07,114
together in one of those discrete time

1091
00:37:07,152 --> 00:37:09,734
models. And again, we have the policies

1092
00:37:09,782 --> 00:37:10,906
and we have the same sort of shape of

1093
00:37:10,928 --> 00:37:12,766
model where there's some channels here

1094
00:37:12,788 --> 00:37:14,026
which I haven't bothered giving letters

1095
00:37:14,058 --> 00:37:16,160
to, but showing the way that the policy

1096
00:37:17,810 --> 00:37:20,030
influences the transition from the state

1097
00:37:20,180 --> 00:37:22,138
to the future state and observations

1098
00:37:22,234 --> 00:37:25,114
from each. So we just have a generative

1099
00:37:25,162 --> 00:37:27,570
model where we have policies, we have

1100
00:37:27,640 --> 00:37:28,866
states and observations, and we have

1101
00:37:28,888 --> 00:37:30,862
future states and future observations.

1102
00:37:31,006 --> 00:37:32,546
In active inference, what we're doing is

1103
00:37:32,568 --> 00:37:33,998
we're receiving two things. We're

1104
00:37:34,014 --> 00:37:35,682
receiving an observation in the current

1105
00:37:35,736 --> 00:37:37,798
time and we have some preferences about

1106
00:37:37,884 --> 00:37:40,966
what we'd like to see in the future. So

1107
00:37:40,988 --> 00:37:42,086
these are each given by these two

1108
00:37:42,108 --> 00:37:45,446
distributions, bolton, O over O, and the

1109
00:37:45,468 --> 00:37:47,042
preferences C over the future

1110
00:37:47,116 --> 00:37:48,954
observations, and then we're doing

1111
00:37:48,992 --> 00:37:51,414
updating with those. So I think updating

1112
00:37:51,462 --> 00:37:54,438
is just our habits,

1113
00:37:54,614 --> 00:37:57,386
the prior over the policies to give our

1114
00:37:57,408 --> 00:37:59,818
new distribution over policies which we

1115
00:37:59,824 --> 00:38:01,546
can think of as the agent's plan of how

1116
00:38:01,568 --> 00:38:03,358
it wants to act. So we're going to try

1117
00:38:03,364 --> 00:38:05,342
and do this updating like before to

1118
00:38:05,396 --> 00:38:08,174
obtain a new distribution over P. And

1119
00:38:08,212 --> 00:38:10,462
that is now telling us how we want to

1120
00:38:10,516 --> 00:38:13,294
behave in the future in a way that will

1121
00:38:13,332 --> 00:38:14,386
basically you can. Think of it as

1122
00:38:14,408 --> 00:38:16,366
saying, we want to explain why we're

1123
00:38:16,398 --> 00:38:18,002
seeing what we're currently seeing and

1124
00:38:18,056 --> 00:38:20,210
how we're going to obtain what we'd like

1125
00:38:20,280 --> 00:38:21,220
in the future.

1126
00:38:23,670 --> 00:38:25,186
In the books kind of inference and

1127
00:38:25,208 --> 00:38:26,558
various places you can find a formula

1128
00:38:26,574 --> 00:38:28,482
like this that there will be justified

1129
00:38:28,546 --> 00:38:29,906
as coming from the free energy principle

1130
00:38:29,938 --> 00:38:32,294
in some way. It's basically saying you

1131
00:38:32,332 --> 00:38:35,638
can do this approximately by making your

1132
00:38:35,644 --> 00:38:37,074
plan distribution take the following

1133
00:38:37,122 --> 00:38:39,990
form there's a soft max, there's a part

1134
00:38:40,060 --> 00:38:42,346
relating to the habits of your model so

1135
00:38:42,368 --> 00:38:44,154
that's your prior over policies. These

1136
00:38:44,192 --> 00:38:46,986
pi are the individual policies in P and

1137
00:38:47,008 --> 00:38:48,666
then there's parts of formula related to

1138
00:38:48,688 --> 00:38:52,074
the VFE and the EFE. And what we

1139
00:38:52,112 --> 00:38:53,546
wanted to do is see where this formula

1140
00:38:53,578 --> 00:38:56,846
comes from in a sort of nice high

1141
00:38:56,868 --> 00:38:58,286
level way from the structure of the

1142
00:38:58,308 --> 00:39:00,958
diagram. So there are explanations for

1143
00:39:00,964 --> 00:39:02,894
this formula there, but I found them

1144
00:39:02,932 --> 00:39:04,106
quite hard to follow, to be honest,

1145
00:39:04,148 --> 00:39:07,566
because they were talking about the EFE

1146
00:39:07,758 --> 00:39:11,182
as being a prior that you then do EFE

1147
00:39:11,246 --> 00:39:12,546
kind of minimization on top of. But you

1148
00:39:12,568 --> 00:39:14,818
kind of need to do the part about the

1149
00:39:14,824 --> 00:39:16,466
present time first before you can do the

1150
00:39:16,488 --> 00:39:19,478
EFE. And so what we wanted, this is a

1151
00:39:19,484 --> 00:39:20,646
really clear way to see how this just

1152
00:39:20,668 --> 00:39:22,118
drops out from the structure of the

1153
00:39:22,124 --> 00:39:23,960
model. So that's what I'll try and show

1154
00:39:24,810 --> 00:39:28,966
now. So what

1155
00:39:28,988 --> 00:39:30,246
we'd like to do then is to do this

1156
00:39:30,268 --> 00:39:31,658
approximate updating. We're going to do

1157
00:39:31,664 --> 00:39:33,194
the pearl style updating which looked

1158
00:39:33,232 --> 00:39:34,938
like this in the pictures. So we want to

1159
00:39:34,944 --> 00:39:36,614
get our new plan so our distribution

1160
00:39:36,662 --> 00:39:39,606
over policies by updating, by plugging

1161
00:39:39,638 --> 00:39:41,450
in our observation and our preferences

1162
00:39:41,870 --> 00:39:43,546
and then normalizing everything. So the

1163
00:39:43,568 --> 00:39:44,798
thing on the right is what we'd like to

1164
00:39:44,804 --> 00:39:46,318
have ideally but we're just going to

1165
00:39:46,324 --> 00:39:48,080
have to approximate it in some way.

1166
00:39:48,850 --> 00:39:50,778
Let's just take the distribution that's

1167
00:39:50,794 --> 00:39:53,460
inside the dash normalization box. Now

1168
00:39:54,310 --> 00:39:56,130
this is the thing we'd like to basically

1169
00:39:56,200 --> 00:39:59,906
approximate this in the structure of our

1170
00:39:59,928 --> 00:40:02,706
model. We can write it like this and

1171
00:40:02,728 --> 00:40:05,038
I'll just show then some graphical steps

1172
00:40:05,054 --> 00:40:06,706
for how we can apply approximations to

1173
00:40:06,728 --> 00:40:08,722
obtain the formula that we saw. And

1174
00:40:08,776 --> 00:40:10,194
obviously we won't be able to go through

1175
00:40:10,232 --> 00:40:12,326
every detail of the proof but it should

1176
00:40:12,348 --> 00:40:13,478
give hopefully just some intuition for

1177
00:40:13,484 --> 00:40:14,678
what it's like to actually work with a

1178
00:40:14,684 --> 00:40:16,086
string diagram. So that's really why I'm

1179
00:40:16,108 --> 00:40:18,086
showing it. So we knew our model take

1180
00:40:18,108 --> 00:40:19,666
roughly this form. There's some part

1181
00:40:19,708 --> 00:40:22,362
relating to current states and current

1182
00:40:22,416 --> 00:40:23,482
observations and also future

1183
00:40:23,536 --> 00:40:24,874
observations. I've just called them both

1184
00:40:24,912 --> 00:40:27,386
M here, but we just know there's that

1185
00:40:27,408 --> 00:40:29,450
part of the model relating to the

1186
00:40:29,600 --> 00:40:33,578
present time and future time. And so

1187
00:40:33,664 --> 00:40:35,038
what we're going to do is first focus on

1188
00:40:35,044 --> 00:40:36,446
this part of the model relating to the

1189
00:40:36,468 --> 00:40:38,174
current state and the current

1190
00:40:38,212 --> 00:40:40,394
observation. And we want to approximate

1191
00:40:40,442 --> 00:40:43,246
what's in that blue dashed box. And what

1192
00:40:43,268 --> 00:40:45,070
you can show is that if you do this VFE

1193
00:40:45,150 --> 00:40:47,502
updating, that will be approximately

1194
00:40:47,566 --> 00:40:50,466
equal to this part of the diagram. So

1195
00:40:50,488 --> 00:40:54,002
this Q is given by for each policy doing

1196
00:40:54,056 --> 00:40:56,578
this VSE updating, so minimizing your

1197
00:40:56,584 --> 00:40:58,806
variation of free energy. So you do that

1198
00:40:58,828 --> 00:41:00,886
for each policy. Then you can view the

1199
00:41:00,908 --> 00:41:03,154
collection of all of those belief

1200
00:41:03,202 --> 00:41:06,454
updates as just one channel from P to S.

1201
00:41:06,652 --> 00:41:07,974
So if you think about it back here,

1202
00:41:08,012 --> 00:41:10,166
basically for each policy you could plug

1203
00:41:10,198 --> 00:41:12,454
in you would obtain just a distribution

1204
00:41:12,502 --> 00:41:14,262
now of snow and you could do updating

1205
00:41:14,326 --> 00:41:16,586
with respect to that. That's what Q of

1206
00:41:16,608 --> 00:41:19,386
that particular policy pi would be and

1207
00:41:19,408 --> 00:41:20,794
you put them all together into this one

1208
00:41:20,832 --> 00:41:24,118
channel Q and you can show then for each

1209
00:41:24,144 --> 00:41:25,902
one, if you do this overall process

1210
00:41:25,956 --> 00:41:27,358
where you multiply by this E to the

1211
00:41:27,364 --> 00:41:29,694
minus VFD quantity here, it will be

1212
00:41:29,732 --> 00:41:31,918
approximately equal to this part of the

1213
00:41:31,924 --> 00:41:35,358
diagram. Okay, so that's our

1214
00:41:35,364 --> 00:41:36,550
first step and that's how the VfB

1215
00:41:36,570 --> 00:41:37,666
entered the picture. Then we've got this

1216
00:41:37,688 --> 00:41:39,246
top part of the diagram, we'll collapse

1217
00:41:39,278 --> 00:41:40,514
it together and just view this as one

1218
00:41:40,552 --> 00:41:43,010
process going into future observations

1219
00:41:43,430 --> 00:41:44,818
and our preferences. And we'd like to

1220
00:41:44,824 --> 00:41:47,746
approximate what's in this box now. And

1221
00:41:47,768 --> 00:41:50,086
this is where the EFB comes in. So you

1222
00:41:50,108 --> 00:41:51,526
can basically show because you have

1223
00:41:51,548 --> 00:41:55,800
this, the expected free energy

1224
00:41:56,330 --> 00:41:58,874
will give you an approximation to this

1225
00:41:58,912 --> 00:42:01,034
here where this is basically like an

1226
00:42:01,072 --> 00:42:03,530
expectation value for your preferences

1227
00:42:04,590 --> 00:42:06,346
for each policy. So this would be like

1228
00:42:06,368 --> 00:42:08,586
the density C of those preferences being

1229
00:42:08,608 --> 00:42:11,660
plugged into your model for each policy.

1230
00:42:13,630 --> 00:42:15,018
So I haven't had time to go into the

1231
00:42:15,024 --> 00:42:16,154
full details. These of approximation

1232
00:42:16,202 --> 00:42:17,966
steps but they're essentially the same

1233
00:42:18,068 --> 00:42:20,186
approximations you'll find in active

1234
00:42:20,218 --> 00:42:21,786
inference text and so on, just turned

1235
00:42:21,818 --> 00:42:23,886
into the string diagrammatic setting and

1236
00:42:23,908 --> 00:42:26,994
we talk about how they come about from

1237
00:42:27,032 --> 00:42:28,466
Jensen's inequality and things like

1238
00:42:28,488 --> 00:42:31,106
this. So this step where you think about

1239
00:42:31,128 --> 00:42:32,258
the future times is called the

1240
00:42:32,264 --> 00:42:34,866
prediction step and the previous one was

1241
00:42:34,888 --> 00:42:37,326
the perception step. So now we've

1242
00:42:37,358 --> 00:42:39,158
rewritten that diagram in terms of some

1243
00:42:39,244 --> 00:42:40,758
e to the minus of the VFE and e to the

1244
00:42:40,764 --> 00:42:43,670
minus of the EFE as well as our habits.

1245
00:42:45,930 --> 00:42:47,686
And remember what we wanted to do was

1246
00:42:47,708 --> 00:42:49,366
approximate the normalization of this

1247
00:42:49,388 --> 00:42:50,454
whole thing. So that's when you apply

1248
00:42:50,492 --> 00:42:51,786
this blue dash box around the whole

1249
00:42:51,808 --> 00:42:54,266
thing and now if we do that, this is

1250
00:42:54,288 --> 00:42:55,786
exactly the same as the formula we were

1251
00:42:55,808 --> 00:42:58,140
after. So we've obtained the formula now

1252
00:42:59,070 --> 00:43:01,046
and that's because you're normalizing

1253
00:43:01,078 --> 00:43:02,778
something but it's got these e to the

1254
00:43:02,784 --> 00:43:05,338
minuses in it. So you can also rewrite

1255
00:43:05,354 --> 00:43:08,302
that in terms of this soft max where now

1256
00:43:08,356 --> 00:43:10,286
you just replace the E with this log and

1257
00:43:10,308 --> 00:43:11,374
the other ones you lose the

1258
00:43:11,412 --> 00:43:14,478
exponentials. So this formula, if you

1259
00:43:14,484 --> 00:43:16,106
wanted to, if you wrote out the formula

1260
00:43:16,138 --> 00:43:18,434
for what this was for each policy, it

1261
00:43:18,472 --> 00:43:22,306
would be equal to this down here. So the

1262
00:43:22,328 --> 00:43:23,458
claim is that this is a nice way to

1263
00:43:23,464 --> 00:43:24,626
derive this formula and is a bit more

1264
00:43:24,648 --> 00:43:26,206
transparent than the ones that exist.

1265
00:43:26,238 --> 00:43:27,986
So the idea was really just to see we

1266
00:43:28,008 --> 00:43:29,714
draw what's going on. Okay, we're doing

1267
00:43:29,752 --> 00:43:31,894
updating with the model of this form and

1268
00:43:31,932 --> 00:43:33,254
we're trying to do this approximate form

1269
00:43:33,292 --> 00:43:34,738
of updating and just see where we're

1270
00:43:34,754 --> 00:43:36,246
applying the approximations and from the

1271
00:43:36,268 --> 00:43:38,214
structure of the model itself, see how

1272
00:43:38,252 --> 00:43:39,660
this formula comes about.

1273
00:43:42,110 --> 00:43:43,786
Okay, so that so far basically just

1274
00:43:43,808 --> 00:43:45,514
talked about things that are already

1275
00:43:45,632 --> 00:43:47,066
there in active inference as it's new

1276
00:43:47,088 --> 00:43:48,794
derivation, but it's existing stuff.

1277
00:43:48,912 --> 00:43:50,206
Before wrapping up, I'd just like to

1278
00:43:50,228 --> 00:43:52,734
also talk about something bit more new

1279
00:43:52,772 --> 00:43:54,634
that we do with the string diagrammatic

1280
00:43:54,682 --> 00:43:57,662
approach. That's to talk about the way

1281
00:43:57,716 --> 00:44:00,334
in which free energy itself is

1282
00:44:00,372 --> 00:44:02,718
compositional. So the motivation for

1283
00:44:02,724 --> 00:44:04,238
this is that the idea is that we want to

1284
00:44:04,244 --> 00:44:05,766
think of this one free energy principle

1285
00:44:05,818 --> 00:44:07,940
applying at all levels of a system.

1286
00:44:09,270 --> 00:44:10,786
So to do that, you'd want to know that

1287
00:44:10,808 --> 00:44:12,418
an agent can say if you've got one of

1288
00:44:12,424 --> 00:44:14,382
these big composite generative models,

1289
00:44:14,526 --> 00:44:16,610
that it can do its free energy

1290
00:44:16,680 --> 00:44:18,434
minimization on the whole thing by doing

1291
00:44:18,472 --> 00:44:19,766
it on the parts. Because we want to

1292
00:44:19,788 --> 00:44:20,998
ultimately think it just comes down to

1293
00:44:21,004 --> 00:44:23,126
each part doing its own bit of free

1294
00:44:23,148 --> 00:44:25,046
energy minimization. So that's what we

1295
00:44:25,068 --> 00:44:28,502
want to make precise. In particular,

1296
00:44:28,556 --> 00:44:29,922
we're going to be talking about the VFE

1297
00:44:29,986 --> 00:44:32,106
here really all the time. And if you

1298
00:44:32,128 --> 00:44:33,626
recall in the diagrams, it looked like

1299
00:44:33,648 --> 00:44:35,818
this. So we use this log boxes and it

1300
00:44:35,824 --> 00:44:37,980
just took this particular shape here.

1301
00:44:38,510 --> 00:44:41,306
So what we do in the paper in order to

1302
00:44:41,328 --> 00:44:44,922
address this compositionality problem is

1303
00:44:44,976 --> 00:44:47,886
introduce a notion of this VFE that we

1304
00:44:47,908 --> 00:44:50,090
can apply not just to generative models,

1305
00:44:50,170 --> 00:44:51,214
but ones which actually have these

1306
00:44:51,252 --> 00:44:52,798
inputs as well. So these were what I

1307
00:44:52,804 --> 00:44:55,002
called open generative models earlier

1308
00:44:55,146 --> 00:44:56,354
because we need to really talk about

1309
00:44:56,392 --> 00:44:57,806
pieces of generative models plugging

1310
00:44:57,838 --> 00:44:59,666
together and give them a notion of free

1311
00:44:59,688 --> 00:45:01,646
energy to even make sense of this notion

1312
00:45:01,758 --> 00:45:04,626
of free energy being compositional. So

1313
00:45:04,648 --> 00:45:05,938
we proposed this definition of what we

1314
00:45:05,944 --> 00:45:08,578
call the open VFE. So now instead of

1315
00:45:08,584 --> 00:45:10,966
just a distribution M over S and O, we

1316
00:45:10,988 --> 00:45:12,886
have a channel from some inputs to S and

1317
00:45:12,908 --> 00:45:15,110
O given by one of these open models.

1318
00:45:15,530 --> 00:45:17,474
And our Q, the thing we're doing the VFE

1319
00:45:17,522 --> 00:45:20,298
minimization with respect to. So the

1320
00:45:20,304 --> 00:45:21,866
thing we're calculating, it would now

1321
00:45:21,888 --> 00:45:23,702
have an input as well. So it's a joint

1322
00:45:23,766 --> 00:45:25,958
distribution over the states and inputs

1323
00:45:26,054 --> 00:45:27,834
and observation takes the same shape as

1324
00:45:27,872 --> 00:45:31,338
before. So you get this other formula

1325
00:45:31,354 --> 00:45:33,054
that's basically just a natural way to

1326
00:45:33,092 --> 00:45:36,174
generalize the previous VFE formula to

1327
00:45:36,212 --> 00:45:39,200
accommodate this extra input wire. I now

1328
00:45:42,050 --> 00:45:44,334
and what we show is that this thing is

1329
00:45:44,372 --> 00:45:46,458
compositional in a sensor that I alluded

1330
00:45:46,474 --> 00:45:48,098
to. So I'll walk through that and the

1331
00:45:48,104 --> 00:45:49,234
way you do it is just using these

1332
00:45:49,272 --> 00:45:50,594
graphical properties that these log

1333
00:45:50,632 --> 00:45:52,866
boxes have that I mentioned earlier. So

1334
00:45:52,888 --> 00:45:54,254
you could turn all of that into a proof

1335
00:45:54,302 --> 00:45:56,386
and standard probability notation if you

1336
00:45:56,408 --> 00:45:59,446
like. But it's quite instructive to

1337
00:45:59,628 --> 00:46:00,678
always just be able to work in the

1338
00:46:00,684 --> 00:46:02,342
diagrams to keep track of the

1339
00:46:02,476 --> 00:46:03,906
compositional structure of the models

1340
00:46:03,938 --> 00:46:07,126
and so on. So the result says that

1341
00:46:07,148 --> 00:46:09,778
this open VFE quantity is compositional

1342
00:46:09,874 --> 00:46:12,426
in two ways. The first one here is this

1343
00:46:12,448 --> 00:46:13,786
quite trivial way. So if we have two

1344
00:46:13,808 --> 00:46:15,354
models running in parallel, so like

1345
00:46:15,392 --> 00:46:17,078
taking the tensor of them and they're

1346
00:46:17,094 --> 00:46:18,918
just both doing their own, we're

1347
00:46:18,934 --> 00:46:20,570
calculating the VF for each of them.

1348
00:46:20,640 --> 00:46:22,026
Sorry for the whole thing, but it's just

1349
00:46:22,048 --> 00:46:24,126
given by two running in parallel, then

1350
00:46:24,148 --> 00:46:25,806
it's just the same as calculating the V

1351
00:46:25,828 --> 00:46:28,026
of V for each individually and adding

1352
00:46:28,058 --> 00:46:30,238
them together. So that certainly what

1353
00:46:30,244 --> 00:46:32,698
we'd like to happen. And it just follows

1354
00:46:32,714 --> 00:46:34,690
from the properties of these log boxes.

1355
00:46:35,670 --> 00:46:37,122
More interestingly, there's the second

1356
00:46:37,176 --> 00:46:38,626
way in which it's compositional, which

1357
00:46:38,648 --> 00:46:41,310
is the sequential mode of plugging

1358
00:46:41,470 --> 00:46:43,890
models together. So if we have an open

1359
00:46:43,960 --> 00:46:46,386
model M one and some inputs into some

1360
00:46:46,408 --> 00:46:49,266
outputs one, but those are now actually

1361
00:46:49,288 --> 00:46:51,014
the inputs for the second model and we

1362
00:46:51,052 --> 00:46:52,694
have these running. So the first

1363
00:46:52,732 --> 00:46:54,966
generation model is passing stuff up to

1364
00:46:54,988 --> 00:46:57,206
the second one. And now we want to

1365
00:46:57,228 --> 00:47:01,650
calculate that result VFE in

1366
00:47:01,660 --> 00:47:04,442
terms of an observation. We can again

1367
00:47:04,496 --> 00:47:06,106
write it as a sum of two of them, but in

1368
00:47:06,128 --> 00:47:07,814
a slightly different way. So observation

1369
00:47:07,862 --> 00:47:09,686
is just existing on the top wire,

1370
00:47:09,718 --> 00:47:11,658
right? Because it's just the output of

1371
00:47:11,664 --> 00:47:12,746
the whole thing that gets this

1372
00:47:12,768 --> 00:47:15,374
observation. So it's just on O two. So

1373
00:47:15,412 --> 00:47:17,006
first we calculate the VFE for this

1374
00:47:17,028 --> 00:47:19,440
model at the top m two in the usual way

1375
00:47:19,970 --> 00:47:22,126
and then we add on a Vfe calculated for

1376
00:47:22,148 --> 00:47:24,306
the first model, but it doesn't really

1377
00:47:24,328 --> 00:47:26,290
have an observation one, right? But

1378
00:47:26,440 --> 00:47:28,226
instead the observation it uses is one

1379
00:47:28,248 --> 00:47:30,914
that's being passed down from M two. So

1380
00:47:30,952 --> 00:47:34,562
that's the queue that M two is using is

1381
00:47:34,616 --> 00:47:35,766
passed down now as if it's an

1382
00:47:35,788 --> 00:47:37,958
observation down to M one. So it's kind

1383
00:47:37,964 --> 00:47:40,322
of like O two receives this observation,

1384
00:47:40,386 --> 00:47:43,302
does its updating about Q or whatever,

1385
00:47:43,356 --> 00:47:45,720
and passes that down to M one.

1386
00:47:46,810 --> 00:47:50,110
So in this way we can say that the VFE

1387
00:47:50,210 --> 00:47:52,074
composers in that okay, both of these

1388
00:47:52,192 --> 00:47:55,498
are minimizing VFE locally, where for

1389
00:47:55,504 --> 00:47:56,998
the M one model we mean it's minimizing

1390
00:47:57,014 --> 00:47:59,306
it with respect to these cues that are

1391
00:47:59,328 --> 00:48:00,746
coming, for these O ones that are coming

1392
00:48:00,768 --> 00:48:03,242
down from above. Then the whole system

1393
00:48:03,296 --> 00:48:05,818
is also minimizing its VFE because it's

1394
00:48:05,834 --> 00:48:07,054
just given by summing those two

1395
00:48:07,092 --> 00:48:10,558
together. So I talked about

1396
00:48:10,644 --> 00:48:11,758
a lot of stuff. Now I'm just going to

1397
00:48:11,764 --> 00:48:13,450
wrap up now and then we can go to a

1398
00:48:13,460 --> 00:48:16,846
discussion, I hope. So the main takeaway

1399
00:48:16,878 --> 00:48:18,306
was just meant to be to try and show

1400
00:48:18,328 --> 00:48:19,666
that these string diagrams provide some

1401
00:48:19,688 --> 00:48:21,650
natural language for talking about

1402
00:48:21,720 --> 00:48:25,038
active inference. And I would encourage

1403
00:48:25,054 --> 00:48:27,278
you to try anyone working on active

1404
00:48:27,294 --> 00:48:28,546
inference formally to take a look and

1405
00:48:28,568 --> 00:48:30,246
see if they would be useful to you in

1406
00:48:30,268 --> 00:48:32,546
some way. And in particular, I focused

1407
00:48:32,578 --> 00:48:34,678
on some of the what I was calling the

1408
00:48:34,684 --> 00:48:35,826
main ingredients of active inference,

1409
00:48:35,858 --> 00:48:37,798
so that were generative models, the way

1410
00:48:37,804 --> 00:48:39,766
you update them, and free energy. And we

1411
00:48:39,788 --> 00:48:41,846
saw sort of ways you can describe all of

1412
00:48:41,868 --> 00:48:43,990
those notions in the string diagrams.

1413
00:48:44,070 --> 00:48:46,166
And the thing that I think is useful

1414
00:48:46,198 --> 00:48:47,402
about them is that they give you a nice

1415
00:48:47,456 --> 00:48:48,618
representational language for just

1416
00:48:48,624 --> 00:48:49,734
drawing pictures of your generative

1417
00:48:49,782 --> 00:48:50,954
models and composing them like

1418
00:48:50,992 --> 00:48:53,466
hierarchical models and so on. But they

1419
00:48:53,488 --> 00:48:54,526
also let you do the reasoning because

1420
00:48:54,548 --> 00:48:56,318
you can do probability theory with them.

1421
00:48:56,404 --> 00:48:57,978
So you can actually reason about what's

1422
00:48:57,994 --> 00:48:59,966
going on in active inference just with

1423
00:48:59,988 --> 00:49:03,418
the diagrams themselves. There's loads

1424
00:49:03,434 --> 00:49:04,258
of directions. You can take this in the

1425
00:49:04,264 --> 00:49:05,186
future. Obviously we could keep

1426
00:49:05,208 --> 00:49:07,506
absorbing more of the work without the

1427
00:49:07,528 --> 00:49:10,194
native inference into the diagrams. Bit

1428
00:49:10,232 --> 00:49:14,158
more interestingly, we introduced

1429
00:49:14,174 --> 00:49:16,866
this new notion at the end of how to

1430
00:49:16,888 --> 00:49:19,286
make free energy compositional. In

1431
00:49:19,308 --> 00:49:21,606
particular, we gave this definition of

1432
00:49:21,788 --> 00:49:24,774
VFE for an open system now so it has a

1433
00:49:24,812 --> 00:49:26,098
generative model which can have inputs.

1434
00:49:26,114 --> 00:49:28,118
We call this the open Vfe. I just be

1435
00:49:28,124 --> 00:49:29,206
very interested in what people think of

1436
00:49:29,228 --> 00:49:30,850
this definition we introduced and

1437
00:49:30,860 --> 00:49:33,894
whether it seems meaningful. Secondly,

1438
00:49:34,022 --> 00:49:35,226
well, throughout the talk I kept talking

1439
00:49:35,248 --> 00:49:36,538
about just minimizing free energy and

1440
00:49:36,544 --> 00:49:38,794
that's all I said already, the Vfe. I

1441
00:49:38,832 --> 00:49:41,866
didn't say how you do it. So in fact,

1442
00:49:41,888 --> 00:49:43,066
this is normally done with these various

1443
00:49:43,098 --> 00:49:44,506
algorithms of message passing

1444
00:49:44,538 --> 00:49:46,286
algorithms. So they're an important part

1445
00:49:46,308 --> 00:49:48,846
of active inference as well. And I think

1446
00:49:48,868 --> 00:49:51,838
it would be great to include these in

1447
00:49:51,844 --> 00:49:53,354
the setup by having some diagrammatic

1448
00:49:53,402 --> 00:49:56,914
story of them. There's lots of other

1449
00:49:56,952 --> 00:49:58,706
questions around. So one of them is that

1450
00:49:58,888 --> 00:50:00,306
I talked about these two notions of

1451
00:50:00,328 --> 00:50:02,322
updating with respect to soft

1452
00:50:02,456 --> 00:50:04,126
observations. And I think normally

1453
00:50:04,158 --> 00:50:05,518
people tend to focus on sharp

1454
00:50:05,534 --> 00:50:07,406
observations, so they perhaps haven't.

1455
00:50:07,598 --> 00:50:09,480
Not everyone has heard of these before,

1456
00:50:10,570 --> 00:50:12,214
but it's very natural to treat the soft

1457
00:50:12,252 --> 00:50:13,142
ones when you're working this

1458
00:50:13,196 --> 00:50:16,214
compositional setup. And so there you

1459
00:50:16,252 --> 00:50:17,926
start to wonder about which of these,

1460
00:50:18,028 --> 00:50:19,746
the Pearl style updating or the Jeffrey

1461
00:50:19,778 --> 00:50:21,866
style updating is more natural to think

1462
00:50:21,888 --> 00:50:24,186
about in the context of cognition. And

1463
00:50:24,208 --> 00:50:26,422
maybe we'll say, okay, well really VSE

1464
00:50:26,486 --> 00:50:27,978
updating is the one you should be

1465
00:50:27,984 --> 00:50:29,034
thinking about. That's probably the

1466
00:50:29,072 --> 00:50:30,922
claim accurate inference would make,

1467
00:50:30,976 --> 00:50:32,766
but it'd still be nice to think about

1468
00:50:32,788 --> 00:50:34,398
how this relates to the other two. Is it

1469
00:50:34,404 --> 00:50:36,366
best thought of as approximating the

1470
00:50:36,388 --> 00:50:39,278
former or the latter style of sort of

1471
00:50:39,284 --> 00:50:42,446
precise updating? And then finally we.

1472
00:50:42,468 --> 00:50:44,830
Could try and connect this up to lots of

1473
00:50:44,980 --> 00:50:47,086
further topics. I mentioned I'm a

1474
00:50:47,108 --> 00:50:48,226
continuum, and we're interested in this

1475
00:50:48,248 --> 00:50:49,822
notion of compositional intelligence.

1476
00:50:49,886 --> 00:50:51,906
So it would be nice to connect this now

1477
00:50:51,928 --> 00:50:55,234
to topics in AI and so on, and think

1478
00:50:55,272 --> 00:50:56,982
about how it relates to other,

1479
00:50:57,036 --> 00:50:58,386
basically applications of category

1480
00:50:58,418 --> 00:51:00,578
theory in AI. In particular. There's

1481
00:51:00,674 --> 00:51:02,914
also this whole world of categorical

1482
00:51:02,962 --> 00:51:04,246
cybernetics I mentioned at the

1483
00:51:04,268 --> 00:51:06,886
beginning, and I'd like to connect this

1484
00:51:06,908 --> 00:51:08,214
a bit more precisely with what people

1485
00:51:08,252 --> 00:51:09,638
are doing there with their stories in

1486
00:51:09,644 --> 00:51:12,314
terms of lenses and so on. And something

1487
00:51:12,352 --> 00:51:13,898
else we were also interested in that I

1488
00:51:13,904 --> 00:51:16,246
mentioned is that we got into the topic

1489
00:51:16,278 --> 00:51:17,594
by thinking about consciousness. And

1490
00:51:17,632 --> 00:51:20,726
there's lots of ways, as a major theory

1491
00:51:20,758 --> 00:51:22,138
of cognition, there's been just loads of

1492
00:51:22,144 --> 00:51:24,014
proposals for how active inference is

1493
00:51:24,052 --> 00:51:26,046
related to consciousness, and it'd be

1494
00:51:26,068 --> 00:51:27,834
nice to see how those can be described

1495
00:51:27,882 --> 00:51:29,694
formally and in this setup and whether

1496
00:51:29,732 --> 00:51:31,946
the string diagrammatic approach helps

1497
00:51:31,978 --> 00:51:34,046
you make any more sense of those. So

1498
00:51:34,068 --> 00:51:35,106
that's something we'd love to do in

1499
00:51:35,128 --> 00:51:37,746
future. But for now, I'd like to say

1500
00:51:37,768 --> 00:51:39,314
thanks again to all of you for

1501
00:51:39,352 --> 00:51:41,378
listening, and I'd love to go to a

1502
00:51:41,384 --> 00:51:42,420
discussion. Thanks.

1503
00:51:47,510 --> 00:51:49,470
Thank you, Sean, for the wonderful

1504
00:51:49,550 --> 00:51:52,258
presentation. Thank you.

1505
00:51:52,424 --> 00:51:55,634
I will first pass to Ali for

1506
00:51:55,672 --> 00:51:57,650
an opening remark,

1507
00:51:58,970 --> 00:51:59,720
please.

1508
00:52:02,170 --> 00:52:05,286
Thank you, Daniel. Thanks so much,

1509
00:52:05,308 --> 00:52:07,410
Sean, for your really fascinating

1510
00:52:07,570 --> 00:52:11,094
presentation. I truly enjoyed it.

1511
00:52:11,292 --> 00:52:13,400
So I have a number of questions.

1512
00:52:14,670 --> 00:52:18,700
Let me begin by asking the first

1513
00:52:20,110 --> 00:52:24,318
know. When Bob Kirky and others took

1514
00:52:24,404 --> 00:52:26,234
Hamiltonian formulation of quantum

1515
00:52:26,282 --> 00:52:30,480
mechanics and kind of turned it into

1516
00:52:31,010 --> 00:52:33,760
the string diagram formulation of it,

1517
00:52:34,130 --> 00:52:37,954
namely ZX calculus, the claim was

1518
00:52:37,992 --> 00:52:40,974
that regardless of its possible verity,

1519
00:52:41,102 --> 00:52:44,306
but the claim was that one of the

1520
00:52:44,328 --> 00:52:46,526
advantages of looking at quantum

1521
00:52:46,558 --> 00:52:49,990
mechanics in terms of string diagrams,

1522
00:52:53,290 --> 00:52:55,974
it's more than just a convenient way of

1523
00:52:56,012 --> 00:52:59,174
looking at quantum formulation, and it

1524
00:52:59,212 --> 00:53:02,026
actually unveils some properties of

1525
00:53:02,048 --> 00:53:04,940
quantum mechanics that would be

1526
00:53:05,470 --> 00:53:07,802
extremely difficult to see with

1527
00:53:07,856 --> 00:53:11,034
Hamiltonian formulation. And even in

1528
00:53:11,072 --> 00:53:14,766
some of their papers, they claim one

1529
00:53:14,788 --> 00:53:18,506
of the reasons for somehow

1530
00:53:18,618 --> 00:53:22,286
the stagnant development in

1531
00:53:22,308 --> 00:53:24,750
quantum technologies and quantum theory

1532
00:53:25,730 --> 00:53:29,794
is exactly related to the difficulty of

1533
00:53:29,832 --> 00:53:32,990
working with Hamiltonian formulations.

1534
00:53:33,070 --> 00:53:36,174
So would you say string diagram

1535
00:53:36,222 --> 00:53:39,350
formulation of active inference kind of

1536
00:53:39,500 --> 00:53:43,538
takes a similar approach to somehow

1537
00:53:43,714 --> 00:53:47,238
providing more than just handy tool

1538
00:53:47,324 --> 00:53:49,186
for representing active inference

1539
00:53:49,218 --> 00:53:52,538
modeling. And actually it kind of

1540
00:53:52,704 --> 00:53:56,342
opens up new possibilities for further

1541
00:53:56,406 --> 00:53:58,758
developments of active inference theory,

1542
00:53:58,934 --> 00:54:02,586
possibilities which would somehow, I

1543
00:54:02,608 --> 00:54:05,246
don't know, impossible or at least

1544
00:54:05,348 --> 00:54:08,318
extremely difficult for the current

1545
00:54:08,484 --> 00:54:10,266
traditional formulation of active

1546
00:54:10,298 --> 00:54:13,502
inference to see in the current

1547
00:54:13,556 --> 00:54:15,390
formulation of the active inference.

1548
00:54:16,770 --> 00:54:18,270
Thanks. That's an amazing question.

1549
00:54:18,340 --> 00:54:22,158
Yeah, I would agree. I think my

1550
00:54:22,164 --> 00:54:23,586
idea for work at Oxford is actually in

1551
00:54:23,608 --> 00:54:25,314
this categorical quantum mechanics area

1552
00:54:25,352 --> 00:54:27,186
I talked about so string diagrams for

1553
00:54:27,208 --> 00:54:29,186
quantum theory and everything. And I

1554
00:54:29,208 --> 00:54:31,926
agree that that language helps you talk

1555
00:54:31,948 --> 00:54:34,950
about a lot of things that you would

1556
00:54:35,020 --> 00:54:37,078
maybe never get round to so much in

1557
00:54:37,164 --> 00:54:39,638
other mathematical formulations of

1558
00:54:39,644 --> 00:54:41,446
quantum theory, basically things that

1559
00:54:41,468 --> 00:54:44,266
make use of the tensor, as it were, the

1560
00:54:44,288 --> 00:54:47,546
composition a lot. So if this led to

1561
00:54:47,568 --> 00:54:48,778
stagnation in quantum theory, it's

1562
00:54:48,784 --> 00:54:50,006
probably because people weren't focusing

1563
00:54:50,038 --> 00:54:51,494
as much on the tensor and entanglement

1564
00:54:51,542 --> 00:54:54,934
and stuff, which became very central.

1565
00:54:54,982 --> 00:54:57,182
Obviously in the end that's what people

1566
00:54:57,236 --> 00:54:58,926
needed to do, quantum computing and

1567
00:54:58,948 --> 00:55:01,518
stuff. So now what people are doing with

1568
00:55:01,524 --> 00:55:03,546
quantum theories includes quantum

1569
00:55:03,578 --> 00:55:04,446
computing where they're drawing these

1570
00:55:04,468 --> 00:55:06,218
circuits and so you're drawing they're

1571
00:55:06,234 --> 00:55:08,106
basically like string diagrams

1572
00:55:08,138 --> 00:55:09,466
describing sometimes these string

1573
00:55:09,498 --> 00:55:11,086
diagrams, sometimes they just use the

1574
00:55:11,188 --> 00:55:12,434
slightly different conventions for

1575
00:55:12,472 --> 00:55:14,098
quantum circuits. But it's similarly a

1576
00:55:14,104 --> 00:55:16,626
compositional language where you have

1577
00:55:16,648 --> 00:55:19,218
got tensor products. So that as in

1578
00:55:19,304 --> 00:55:21,426
things running in parallel states of

1579
00:55:21,448 --> 00:55:22,678
these products so that you can talk

1580
00:55:22,684 --> 00:55:26,406
about entanglement and so on. It's the

1581
00:55:26,428 --> 00:55:28,566
language that makes it very immediate to

1582
00:55:28,668 --> 00:55:30,358
represent that, because you just draw a

1583
00:55:30,364 --> 00:55:31,970
box with two eyes and it encodes

1584
00:55:32,050 --> 00:55:33,686
entangled state, and it makes you want

1585
00:55:33,708 --> 00:55:35,322
to plug these things together and

1586
00:55:35,376 --> 00:55:37,418
compose them, which is what you want to

1587
00:55:37,424 --> 00:55:40,410
do in quantum computing. So I think

1588
00:55:40,560 --> 00:55:43,306
similarly, if you never use that kind of

1589
00:55:43,328 --> 00:55:45,562
language, you might think of a system

1590
00:55:45,616 --> 00:55:47,510
often as a fixed thing and not about the

1591
00:55:47,520 --> 00:55:49,550
way it interacts with other ones so much

1592
00:55:49,620 --> 00:55:52,206
and that could lead to overlooking all

1593
00:55:52,228 --> 00:55:53,646
sorts of things. So that's true in any

1594
00:55:53,668 --> 00:55:56,670
area. And I think in active inference

1595
00:55:57,410 --> 00:55:58,926
it's certainly very true. I think that

1596
00:55:58,948 --> 00:56:00,706
it's natural to think compositionally in

1597
00:56:00,728 --> 00:56:03,346
this way because you're wanting to talk

1598
00:56:03,368 --> 00:56:05,134
about generative models being composed

1599
00:56:05,182 --> 00:56:06,514
from pieces and you're maybe thinking

1600
00:56:06,552 --> 00:56:08,066
about how the whole brain works in

1601
00:56:08,088 --> 00:56:09,966
relation to interactions between parts

1602
00:56:09,998 --> 00:56:13,062
of it and so on. So if you never used

1603
00:56:13,116 --> 00:56:15,206
this kind of compositional view, there

1604
00:56:15,228 --> 00:56:17,574
is stuff you would miss, I think. I

1605
00:56:17,612 --> 00:56:20,358
think in some sense people weren't as

1606
00:56:20,444 --> 00:56:22,118
behind already because they already were

1607
00:56:22,204 --> 00:56:23,814
working kind of compositionally right,

1608
00:56:23,852 --> 00:56:25,038
because they're using these Bayesian

1609
00:56:25,074 --> 00:56:27,786
network diagrams like the Dags and the

1610
00:56:27,808 --> 00:56:28,826
way they're normally drawn are very

1611
00:56:28,848 --> 00:56:31,206
close. They are basically the string

1612
00:56:31,238 --> 00:56:32,940
diagrams, they just don't do the

1613
00:56:33,470 --> 00:56:35,546
equations and the rewriting of the

1614
00:56:35,568 --> 00:56:38,654
diagrams. So it's not as far back maybe

1615
00:56:38,692 --> 00:56:41,070
as quantum theory was, in the sense that

1616
00:56:41,220 --> 00:56:43,050
people are thinking compositionally,

1617
00:56:43,130 --> 00:56:45,246
but it feels like you just want to go

1618
00:56:45,268 --> 00:56:47,482
one step further to having a fully

1619
00:56:47,546 --> 00:56:48,814
compositional language you're working

1620
00:56:48,852 --> 00:56:51,314
in. Where you have the advantage now

1621
00:56:51,352 --> 00:56:53,090
that you can just talk about taking a

1622
00:56:53,160 --> 00:56:54,962
whole model and plugging it into another

1623
00:56:55,016 --> 00:56:57,006
one and it has a completely clear formal

1624
00:56:57,038 --> 00:56:59,058
meaning and so on, which I think is what

1625
00:56:59,064 --> 00:57:00,798
you want to do in areas like active

1626
00:57:00,814 --> 00:57:03,106
inference. So going from the diagrams

1627
00:57:03,138 --> 00:57:04,786
which are currently used to string

1628
00:57:04,818 --> 00:57:07,398
diagrams is like the logical next step

1629
00:57:07,484 --> 00:57:09,366
and in terms of new stuff it lets you

1630
00:57:09,388 --> 00:57:12,486
do. I think an example is something like

1631
00:57:12,508 --> 00:57:16,746
this open BFE thing, I guess. So if

1632
00:57:16,768 --> 00:57:18,218
you're just always thinking about just a

1633
00:57:18,224 --> 00:57:19,722
generative model meaning one without

1634
00:57:19,776 --> 00:57:23,014
inputs. You might not think of a notion

1635
00:57:23,062 --> 00:57:24,618
I'm not saying this is necessarily the

1636
00:57:24,624 --> 00:57:26,826
right notion, but you might not think

1637
00:57:26,848 --> 00:57:27,978
about this problem of how you want to

1638
00:57:27,984 --> 00:57:29,502
give your definition for something that

1639
00:57:29,636 --> 00:57:32,334
is allowed to have inputs as well. And

1640
00:57:32,372 --> 00:57:34,078
once you have that have definition, you

1641
00:57:34,084 --> 00:57:35,646
can sort of apply to parts of a

1642
00:57:35,668 --> 00:57:37,826
composite system more easily, so it

1643
00:57:37,848 --> 00:57:40,994
becomes more natural to

1644
00:57:41,032 --> 00:57:42,946
use compositionally. So that's the kind

1645
00:57:42,968 --> 00:57:44,946
of thing where without something like

1646
00:57:44,968 --> 00:57:47,714
string diagrams, people can end up

1647
00:57:47,752 --> 00:57:48,946
overlooking it. It wouldn't be

1648
00:57:48,968 --> 00:57:50,866
impossible to do without them. I just

1649
00:57:50,888 --> 00:57:52,198
need to talk about this notion of a kind

1650
00:57:52,204 --> 00:57:54,454
of open generative model, which just

1651
00:57:54,492 --> 00:57:57,158
means throwing away some mechanisms to

1652
00:57:57,164 --> 00:57:59,894
make things be inputs. But you could

1653
00:57:59,932 --> 00:58:01,978
miss it, but you really won't once you

1654
00:58:01,984 --> 00:58:03,610
start thinking categorically.

1655
00:58:08,590 --> 00:58:10,458
Thank you, Ollie. Please continue if you

1656
00:58:10,464 --> 00:58:11,260
would like.

1657
00:58:14,510 --> 00:58:18,480
Thanks. So, yeah, my other

1658
00:58:19,810 --> 00:58:24,510
perhaps related question is comparing

1659
00:58:24,850 --> 00:58:28,990
this kind of formulation to this recent

1660
00:58:30,550 --> 00:58:32,946
formulation of constructor theory in

1661
00:58:32,968 --> 00:58:34,974
terms of string diagrams or categorical

1662
00:58:35,022 --> 00:58:37,250
formulation of constructor theory.

1663
00:58:38,790 --> 00:58:41,314
Before going into this question, you

1664
00:58:41,352 --> 00:58:44,614
see, you mentioned that this

1665
00:58:44,732 --> 00:58:48,146
project is a part of a larger

1666
00:58:48,178 --> 00:58:50,514
project for developing collective

1667
00:58:50,562 --> 00:58:55,578
intelligence, right? So the similar

1668
00:58:55,664 --> 00:58:57,322
kind of situation happens for

1669
00:58:57,376 --> 00:59:00,746
constructor theory in which it is a

1670
00:59:00,768 --> 00:59:02,874
kind of meta theory that tries to

1671
00:59:02,912 --> 00:59:07,434
somehow discriminate

1672
00:59:07,482 --> 00:59:11,534
between the possibilities of

1673
00:59:11,652 --> 00:59:13,902
physical laws as opposed to

1674
00:59:13,956 --> 00:59:17,630
counterfactual laws, and how

1675
00:59:17,780 --> 00:59:21,554
physical laws, how there

1676
00:59:21,592 --> 00:59:24,386
can be a theory, accounts for the

1677
00:59:24,408 --> 00:59:27,230
emergence of possible physical laws.

1678
00:59:27,390 --> 00:59:30,020
So in this sense,

1679
00:59:31,750 --> 00:59:34,390
would you say this kind of formulation

1680
00:59:35,850 --> 00:59:38,440
category, theoretical formulation, or

1681
00:59:39,370 --> 00:59:42,962
possibly this specific String diagram

1682
00:59:43,026 --> 00:59:46,122
formulation of active inference? Or

1683
00:59:46,176 --> 00:59:48,950
maybe other theories of consciousness

1684
00:59:49,110 --> 00:59:51,834
can be seen as a kind of providing a

1685
00:59:51,872 --> 00:59:55,238
path? Toward developing a kind of meta

1686
00:59:55,254 --> 00:59:58,410
theory of consciousness and possibly

1687
00:59:58,570 --> 01:00:02,094
unifying many different strands of

1688
01:00:02,292 --> 01:00:04,480
theories of consciousness into.

1689
01:00:06,290 --> 01:00:10,066
I. Don'T know, a holistic picture that

1690
01:00:10,248 --> 01:00:14,180
can somehow be compared and

1691
01:00:14,950 --> 01:00:19,954
positively reconciled with one

1692
01:00:19,992 --> 01:00:24,006
another and ultimately reaching the

1693
01:00:24,188 --> 01:00:27,720
ultimate theory of consciousness. Or,

1694
01:00:29,210 --> 01:00:32,454
I don't know, do you see this line of

1695
01:00:32,492 --> 01:00:36,010
work providing

1696
01:00:36,510 --> 01:00:39,994
enough evidence for this line of

1697
01:00:40,032 --> 01:00:43,638
development research or, I don't

1698
01:00:43,654 --> 01:00:47,774
know, somehow maybe even

1699
01:00:47,972 --> 01:00:50,480
not specifically consciousness, but

1700
01:00:51,090 --> 01:00:54,240
unifying the different aspects of

1701
01:00:55,650 --> 01:00:57,710
cognition, intelligence and

1702
01:00:57,780 --> 01:00:59,150
consciousness altogether?

1703
01:01:03,490 --> 01:01:06,366
What would you say? Thanks. Keep giving

1704
01:01:06,388 --> 01:01:09,314
me ideal selling points. So, yeah,

1705
01:01:09,352 --> 01:01:11,506
that's also something I would like to

1706
01:01:11,528 --> 01:01:12,100
say.

1707
01:01:14,390 --> 01:01:16,886
I tend to think of it that way and that

1708
01:01:17,068 --> 01:01:18,946
my background is in applying category

1709
01:01:18,978 --> 01:01:21,126
theory to just lots of topics and I so

1710
01:01:21,228 --> 01:01:23,302
naturally do think of it as quite a

1711
01:01:23,436 --> 01:01:26,326
unifying language. And the grant on

1712
01:01:26,348 --> 01:01:28,422
consciousness that I mentioned was

1713
01:01:28,476 --> 01:01:29,706
building on earlier work we did on

1714
01:01:29,728 --> 01:01:31,606
looking at integrated information theory

1715
01:01:31,638 --> 01:01:33,354
of consciousness, which in the end

1716
01:01:33,392 --> 01:01:34,618
basically was done in terms of

1717
01:01:34,624 --> 01:01:36,314
categorical probability. So it's like

1718
01:01:36,352 --> 01:01:39,626
the same setup of the diagrams. And so

1719
01:01:39,728 --> 01:01:41,158
we kind of wanted to do the same thing

1720
01:01:41,184 --> 01:01:45,134
for directive inference. So there

1721
01:01:45,172 --> 01:01:46,286
it's like we've taken both of these

1722
01:01:46,308 --> 01:01:47,262
things and put them in this common

1723
01:01:47,316 --> 01:01:48,718
language. You could have put them in the

1724
01:01:48,724 --> 01:01:50,154
common language of probability theory

1725
01:01:50,202 --> 01:01:51,998
before. But I think I do have an

1726
01:01:52,004 --> 01:01:55,394
intuition that there is something more

1727
01:01:55,432 --> 01:01:57,378
clear about it. Does make it easier to

1728
01:01:57,384 --> 01:01:59,006
get a conceptual grasp of both theories,

1729
01:01:59,038 --> 01:02:00,274
I think, once you've done it this way

1730
01:02:00,312 --> 01:02:02,814
and somehow also, yeah, the diagrammatic

1731
01:02:02,862 --> 01:02:04,446
view does make it much easier to compare

1732
01:02:04,478 --> 01:02:07,230
them. So the hope was basically to, and

1733
01:02:07,240 --> 01:02:09,750
still is to keep going and to keep

1734
01:02:09,900 --> 01:02:11,526
understanding various notions in that

1735
01:02:11,548 --> 01:02:12,694
language. So there's things I've looked

1736
01:02:12,732 --> 01:02:14,886
at in cognitive science I've also done

1737
01:02:14,908 --> 01:02:17,474
this way. So this theory of conceptual

1738
01:02:17,522 --> 01:02:20,442
spaces, garden force have worked on

1739
01:02:20,576 --> 01:02:22,058
treating that in terms of diagrams and

1740
01:02:22,064 --> 01:02:24,218
so on. So I would love to see basically

1741
01:02:24,384 --> 01:02:26,858
many theories put into this language to

1742
01:02:26,864 --> 01:02:29,178
make it easier to compare them. You

1743
01:02:29,184 --> 01:02:30,178
could try and compare them directly

1744
01:02:30,214 --> 01:02:32,814
already, but I think you want one clear

1745
01:02:32,852 --> 01:02:34,846
formalization to put them all in. And I

1746
01:02:34,868 --> 01:02:36,334
would say that the categories and

1747
01:02:36,372 --> 01:02:38,190
diagrams is the right one to pick

1748
01:02:38,260 --> 01:02:41,262
because it tends to just give a very

1749
01:02:41,316 --> 01:02:43,646
clear conceptual view of things. The

1750
01:02:43,668 --> 01:02:45,086
question is whether you have some theory

1751
01:02:45,118 --> 01:02:47,682
that's very important, where the things

1752
01:02:47,736 --> 01:02:49,006
categories are good at, just doesn't

1753
01:02:49,038 --> 01:02:51,106
quite capture the essence of what you

1754
01:02:51,128 --> 01:02:52,706
want to talk about there. But for things

1755
01:02:52,728 --> 01:02:56,226
like active inference and IIT, so far it

1756
01:02:56,248 --> 01:02:58,886
seemed very natural because on the case

1757
01:02:58,908 --> 01:03:00,246
of IIT, it's about talking about how

1758
01:03:00,268 --> 01:03:01,606
integrated something is. So you

1759
01:03:01,628 --> 01:03:03,206
basically want to talk about the

1760
01:03:03,228 --> 01:03:04,422
opposite of that, which is something

1761
01:03:04,476 --> 01:03:06,386
being decomposed. And the diagrams

1762
01:03:06,418 --> 01:03:08,278
basically talk about parts and how

1763
01:03:08,284 --> 01:03:09,258
they're related, which is what you need

1764
01:03:09,264 --> 01:03:10,426
to make sense of that notion of

1765
01:03:10,448 --> 01:03:12,860
integration. So it's very natural there.

1766
01:03:13,310 --> 01:03:15,500
But yeah, I would love basically to see

1767
01:03:15,950 --> 01:03:18,110
various aspects of cognitive science

1768
01:03:19,410 --> 01:03:21,178
understood categorically. That's

1769
01:03:21,194 --> 01:03:23,520
something I'd love to do myself as well.

1770
01:03:25,090 --> 01:03:28,686
And the hope would be then to

1771
01:03:28,868 --> 01:03:30,782
try and gain insights from all of them

1772
01:03:30,916 --> 01:03:32,250
and build a theory. It's not the

1773
01:03:32,260 --> 01:03:35,506
category theory itself is a theory of

1774
01:03:35,528 --> 01:03:37,106
cognition or consciousness. It's just a

1775
01:03:37,128 --> 01:03:39,522
very useful language for relating them.

1776
01:03:39,576 --> 01:03:42,306
And then it would be very exciting to

1777
01:03:42,328 --> 01:03:44,466
see something natively defined in terms

1778
01:03:44,488 --> 01:03:46,920
of category theory as well at the end.

1779
01:03:47,370 --> 01:03:48,518
And there's a feeling that some of

1780
01:03:48,524 --> 01:03:49,874
what's going on in applied category

1781
01:03:49,922 --> 01:03:51,874
theory, I think, like in categorical,

1782
01:03:51,922 --> 01:03:54,406
cybernetics and so on, is kind of taking

1783
01:03:54,588 --> 01:03:57,206
that approach for perhaps some of the

1784
01:03:57,228 --> 01:03:58,726
first time. Previously, I've always

1785
01:03:58,748 --> 01:04:00,058
thought category theory is basically you

1786
01:04:00,064 --> 01:04:01,418
take existing things and you get a

1787
01:04:01,424 --> 01:04:03,866
really nice abstract view of them. But

1788
01:04:03,888 --> 01:04:05,734
now I think people are comfortable

1789
01:04:05,782 --> 01:04:07,198
enough with it that they're sort of

1790
01:04:07,204 --> 01:04:09,246
defining things categorically from the

1791
01:04:09,268 --> 01:04:12,080
outset in areas like that.

1792
01:04:15,410 --> 01:04:16,880
Awesome. Well.

1793
01:04:18,770 --> 01:04:21,698
Yeah, I have many thank you. These are

1794
01:04:21,704 --> 01:04:23,534
great questions. There's like ideal

1795
01:04:23,582 --> 01:04:24,180
questions.

1796
01:04:26,790 --> 01:04:29,218
You'Ve pointed in. And we've explored a

1797
01:04:29,224 --> 01:04:30,946
little bit of the utility and the

1798
01:04:30,968 --> 01:04:32,774
simplicity and how that could help with

1799
01:04:32,812 --> 01:04:34,646
accessibility and rigor and

1800
01:04:34,668 --> 01:04:37,366
applicability all these awesome things

1801
01:04:37,548 --> 01:04:41,442
leading to reaccounting and reframing

1802
01:04:41,586 --> 01:04:44,706
consolidating as well as discovering

1803
01:04:44,818 --> 01:04:47,894
some new trails between, for example,

1804
01:04:48,092 --> 01:04:49,526
expected free energy energy and

1805
01:04:49,548 --> 01:04:52,074
variational free energy energy. Looking

1806
01:04:52,112 --> 01:04:54,138
at the equations, you might be able to

1807
01:04:54,144 --> 01:04:56,762
say that they rhyme, but you would be

1808
01:04:56,816 --> 01:05:00,858
many, many lines deep into understanding

1809
01:05:01,034 --> 01:05:04,830
what, if any, generalizations could

1810
01:05:04,900 --> 01:05:07,966
encompass the both of them. So that was

1811
01:05:07,988 --> 01:05:10,820
just a very salient example.

1812
01:05:12,790 --> 01:05:15,746
A few different kinds of questions.

1813
01:05:15,928 --> 01:05:20,142
So how is time treated in category

1814
01:05:20,206 --> 01:05:22,654
theory? Or how does active inference

1815
01:05:22,702 --> 01:05:26,406
treat time today and how do you see the

1816
01:05:26,428 --> 01:05:28,886
way that time is treated? We talk about

1817
01:05:28,908 --> 01:05:30,582
discrete time and continuous time

1818
01:05:30,636 --> 01:05:32,198
generative models. Then there's the

1819
01:05:32,204 --> 01:05:34,890
past, present and future multi agent

1820
01:05:34,960 --> 01:05:37,014
systems federated or asynchronous

1821
01:05:37,062 --> 01:05:39,770
communication. So how is time treated

1822
01:05:40,110 --> 01:05:42,410
and how does that give us a different

1823
01:05:42,480 --> 01:05:45,210
grasp on dynamical modeling?

1824
01:05:46,590 --> 01:05:49,818
Thank you. I'd love to have

1825
01:05:49,824 --> 01:05:50,938
a better answer for that. Basically, I

1826
01:05:50,944 --> 01:05:52,798
think it's a tough one at the moment in

1827
01:05:52,804 --> 01:05:53,854
the talks if I just talked about

1828
01:05:53,892 --> 01:05:56,382
discrete time and that's sort of very

1829
01:05:56,516 --> 01:05:59,210
easy to treat with the Bayesian network

1830
01:05:59,290 --> 01:06:01,318
setup and with these kind of string

1831
01:06:01,354 --> 01:06:03,202
diagrams because you can just lay out

1832
01:06:03,336 --> 01:06:05,858
the discrete time steps as processes in

1833
01:06:05,864 --> 01:06:07,346
your picture like we see here. We have

1834
01:06:07,368 --> 01:06:11,826
the end time steps here, but I

1835
01:06:11,848 --> 01:06:14,502
don't have anything satisfying worked

1836
01:06:14,556 --> 01:06:16,840
out yet to say about how you would treat

1837
01:06:17,370 --> 01:06:19,206
a continuous time case, which I think is

1838
01:06:19,228 --> 01:06:20,626
important in active inference. You'd

1839
01:06:20,658 --> 01:06:25,302
like to basically take.

1840
01:06:25,356 --> 01:06:26,566
I guess basically what you want to do is

1841
01:06:26,588 --> 01:06:28,374
take the way that you describe this

1842
01:06:28,412 --> 01:06:30,026
thing with the end time steps and kind

1843
01:06:30,048 --> 01:06:31,866
of have a formula for folding it

1844
01:06:31,888 --> 01:06:32,778
together and just saying, okay, but

1845
01:06:32,784 --> 01:06:34,794
you're unpacking this. Thing n times.

1846
01:06:34,992 --> 01:06:36,826
And then you can take that thing and

1847
01:06:36,848 --> 01:06:39,338
imagine this abstract view of unpacking.

1848
01:06:39,354 --> 01:06:41,166
It just not discreetly anymore in this

1849
01:06:41,188 --> 01:06:43,114
continuous way, so that you can capture

1850
01:06:43,162 --> 01:06:45,578
something like the differential equation

1851
01:06:45,674 --> 01:06:47,390
kind of definition of continuous time

1852
01:06:47,460 --> 01:06:48,990
thing in active inference.

1853
01:06:51,030 --> 01:06:55,330
I? Yeah so

1854
01:06:55,400 --> 01:06:57,166
you can certainly work with continuous

1855
01:06:57,198 --> 01:06:58,914
time things in the sense of, you know,

1856
01:06:58,952 --> 01:07:00,334
the stuff going on in categorical

1857
01:07:00,382 --> 01:07:01,854
cybernetics or sort of categorical

1858
01:07:01,902 --> 01:07:03,266
systems theory I guess it would be

1859
01:07:03,288 --> 01:07:07,102
called. Act world is kind know

1860
01:07:07,256 --> 01:07:09,346
it has continuous time dynamical systems

1861
01:07:09,378 --> 01:07:11,158
and talks about plugging them together

1862
01:07:11,324 --> 01:07:13,270
but that diagram is sort of just

1863
01:07:13,340 --> 01:07:15,254
relating their variables is my

1864
01:07:15,292 --> 01:07:17,414
understanding. It's not like a diagram

1865
01:07:17,462 --> 01:07:20,778
isn't exactly showing the time and in

1866
01:07:20,784 --> 01:07:21,866
some sense they kind of have to

1867
01:07:21,888 --> 01:07:23,834
synchronize, I think. It's not an area

1868
01:07:23,872 --> 01:07:26,858
I'm totally familiar with. So it would

1869
01:07:26,864 --> 01:07:29,274
have been really cool to basically have

1870
01:07:29,312 --> 01:07:31,326
this work and then have another part of

1871
01:07:31,348 --> 01:07:34,286
it talking about like we've done for

1872
01:07:34,308 --> 01:07:35,374
discrete time here. Having a nice

1873
01:07:35,412 --> 01:07:37,774
description of a continuous time case,

1874
01:07:37,892 --> 01:07:40,574
I think it will end up being some work

1875
01:07:40,612 --> 01:07:43,826
to take that into account there would

1876
01:07:43,848 --> 01:07:46,114
be really nice to see. So it just needs

1877
01:07:46,152 --> 01:07:48,020
the right abstraction, I think, for

1878
01:07:49,270 --> 01:07:51,566
taking a picture like this. Not drawing

1879
01:07:51,598 --> 01:07:53,426
the time steps as like bits in your

1880
01:07:53,448 --> 01:07:56,406
diagram, but just saying that it's like

1881
01:07:56,428 --> 01:07:58,738
this b thing with like a feedback loop

1882
01:07:58,834 --> 01:08:00,578
basically is what this is describing.

1883
01:08:00,674 --> 01:08:02,406
And then giving a semantics to that in

1884
01:08:02,428 --> 01:08:05,558
terms of time evolution, to give a

1885
01:08:05,564 --> 01:08:06,950
continuous version of this, for example,

1886
01:08:07,020 --> 01:08:09,446
with like state unfurling continuously

1887
01:08:09,478 --> 01:08:12,940
and observations for each time step

1888
01:08:14,590 --> 01:08:15,946
in general. I wouldn't say there's like

1889
01:08:15,968 --> 01:08:18,122
an answer to the question of how is time

1890
01:08:18,176 --> 01:08:19,386
treated in category theory. There

1891
01:08:19,408 --> 01:08:20,670
wouldn't really be one answer because

1892
01:08:20,740 --> 01:08:22,510
category is going to be so generally

1893
01:08:23,090 --> 01:08:25,086
they tend to be very effective for

1894
01:08:25,108 --> 01:08:28,058
discrete things in general, like algebra

1895
01:08:28,074 --> 01:08:30,142
and so on, because they kind of are

1896
01:08:30,276 --> 01:08:31,678
discrete in some sense, like the

1897
01:08:31,684 --> 01:08:33,854
composition is discrete. So continuous

1898
01:08:33,902 --> 01:08:36,354
aspects and things like continuous time

1899
01:08:36,472 --> 01:08:38,722
tend to be more difficult in a sense.

1900
01:08:38,776 --> 01:08:40,786
Or they're just sort of inside the

1901
01:08:40,808 --> 01:08:43,366
morphisms, as it were. They're not in

1902
01:08:43,388 --> 01:08:45,046
the composition. So it doesn't end up

1903
01:08:45,068 --> 01:08:46,354
looking like this when you're composing

1904
01:08:46,402 --> 01:08:47,430
continuously.

1905
01:08:49,370 --> 01:08:51,366
But yeah, I think there will be people

1906
01:08:51,548 --> 01:08:55,306
in act who sort of would

1907
01:08:55,408 --> 01:08:56,842
come at you with a particular answer.

1908
01:08:56,896 --> 01:08:59,274
So they've got a way they like to treat

1909
01:08:59,312 --> 01:09:02,678
continuous time that I'm

1910
01:09:02,694 --> 01:09:06,060
just not familiar with yet. Cool.

1911
01:09:07,070 --> 01:09:09,406
A little bit of a more educational or

1912
01:09:09,428 --> 01:09:13,038
applied question. So how do we go about

1913
01:09:13,204 --> 01:09:16,046
drawing and learning to draw? Is there a

1914
01:09:16,068 --> 01:09:18,526
software package? Is there a way that we

1915
01:09:18,548 --> 01:09:21,786
can get a step by step process to

1916
01:09:21,828 --> 01:09:24,226
building that familiarity with like when

1917
01:09:24,248 --> 01:09:27,026
I see this shape, then here's what I

1918
01:09:27,048 --> 01:09:29,074
know. And then how do we know what we

1919
01:09:29,112 --> 01:09:32,542
can and can't do? And does that drawing

1920
01:09:32,606 --> 01:09:36,086
software flag us or do

1921
01:09:36,108 --> 01:09:38,358
we need to send it to a friend? So how

1922
01:09:38,364 --> 01:09:40,102
do we look at something? And then part

1923
01:09:40,156 --> 01:09:43,574
one, build up the motifs in our own

1924
01:09:43,692 --> 01:09:47,180
aesthetic understanding so that we can

1925
01:09:47,950 --> 01:09:50,122
understand the compositionality of this

1926
01:09:50,176 --> 01:09:52,602
as you do today and as we all do today,

1927
01:09:52,656 --> 01:09:55,546
for example, for Language English. And

1928
01:09:55,568 --> 01:09:59,198
then part two, how do we go from having

1929
01:09:59,284 --> 01:10:02,010
built that motif based compositional

1930
01:10:02,090 --> 01:10:05,534
understanding to like now what

1931
01:10:05,572 --> 01:10:08,238
can we do? And then when are we just

1932
01:10:08,324 --> 01:10:11,306
totally freewheeling and off the rails

1933
01:10:11,338 --> 01:10:12,994
of the free energy principle? Or does

1934
01:10:13,032 --> 01:10:15,620
anything go if the motifs allow it?

1935
01:10:16,710 --> 01:10:19,090
Yeah, I wish I should have the standard

1936
01:10:19,160 --> 01:10:20,766
answer. The best way to learn string

1937
01:10:20,798 --> 01:10:22,066
diagrams, I think, if I'm going to talk

1938
01:10:22,088 --> 01:10:23,506
about it like this. So you prompted me

1939
01:10:23,528 --> 01:10:25,522
to come up with that. I don't have

1940
01:10:25,576 --> 01:10:26,598
something on top of my head. That's the

1941
01:10:26,604 --> 01:10:28,342
best way. But there's so much stuff out

1942
01:10:28,396 --> 01:10:32,726
there I think it tends to be because if

1943
01:10:32,748 --> 01:10:33,958
you want to get really comfortable with

1944
01:10:33,964 --> 01:10:35,266
the diagrams, you're learning category

1945
01:10:35,298 --> 01:10:36,770
theory in some sense, but it's not like

1946
01:10:36,780 --> 01:10:38,406
you need to learn all of category

1947
01:10:38,438 --> 01:10:40,646
theory. It's kind of a relatively modern

1948
01:10:40,678 --> 01:10:42,486
offshoot in this applied category theory

1949
01:10:42,518 --> 01:10:43,974
world that's very diagrammatically

1950
01:10:44,022 --> 01:10:47,210
focused and there will be various nice

1951
01:10:47,280 --> 01:10:49,820
introductions out there to using them

1952
01:10:50,750 --> 01:10:54,446
another way is to

1953
01:10:54,468 --> 01:10:56,574
think I'm pretty sure recently yeah,

1954
01:10:56,612 --> 01:10:57,758
there was a nice paper that came out,

1955
01:10:57,764 --> 01:10:58,906
there was an introduction to string

1956
01:10:58,938 --> 01:11:00,366
diagrams for computer scientists, for

1957
01:11:00,388 --> 01:11:01,554
example. So there tends to be different

1958
01:11:01,592 --> 01:11:03,154
introductions kind of for different

1959
01:11:03,192 --> 01:11:05,042
audiences because they just want to pick

1960
01:11:05,176 --> 01:11:10,178
categories that

1961
01:11:10,264 --> 01:11:11,426
those people are familiar with. Right.

1962
01:11:11,448 --> 01:11:12,862
So they can actually have some examples.

1963
01:11:12,926 --> 01:11:14,126
You could just learn the diagrams

1964
01:11:14,158 --> 01:11:15,746
totally abstractly, but it helps to have

1965
01:11:15,768 --> 01:11:19,358
some examples. And the old category free

1966
01:11:19,384 --> 01:11:20,898
textbooks are all things mathematicians

1967
01:11:20,914 --> 01:11:22,786
have looked at and other people haven't

1968
01:11:22,818 --> 01:11:24,066
heard of, so they're not particularly

1969
01:11:24,098 --> 01:11:26,566
helpful. So there's know Bob has paper

1970
01:11:26,668 --> 01:11:28,158
categories for the practicing physicist

1971
01:11:28,194 --> 01:11:29,386
that's aimed at physicists that would

1972
01:11:29,408 --> 01:11:30,858
basically introduce string diagrams to

1973
01:11:30,864 --> 01:11:32,682
them. There's this recent computer

1974
01:11:32,736 --> 01:11:35,034
science one. I know there's some work

1975
01:11:35,072 --> 01:11:36,934
going on in producing one for cognitive

1976
01:11:36,982 --> 01:11:38,026
science, which I think would be really

1977
01:11:38,048 --> 01:11:42,126
good having an introduction to

1978
01:11:42,148 --> 01:11:43,760
the string diagrams for those people.

1979
01:11:44,450 --> 01:11:46,222
So you basically look for one in an area

1980
01:11:46,276 --> 01:11:48,158
you're comfortable with and you find a

1981
01:11:48,164 --> 01:11:50,858
good paper on it. But it would be nice

1982
01:11:50,884 --> 01:11:53,426
to have a good online resource, I guess,

1983
01:11:53,448 --> 01:11:55,186
right, that gathers these together so

1984
01:11:55,208 --> 01:11:57,362
people can just see a great guide for

1985
01:11:57,496 --> 01:11:59,714
all the introductions. If you do

1986
01:11:59,752 --> 01:12:02,978
something like there's courses you can

1987
01:12:02,984 --> 01:12:07,078
do in the sense of the Bob's book.

1988
01:12:07,164 --> 01:12:08,386
In the case of learning quantum,

1989
01:12:08,418 --> 01:12:10,086
there's something like Bob's Long book

1990
01:12:10,108 --> 01:12:11,634
with Alex Kissinger picturing quantum

1991
01:12:11,682 --> 01:12:14,310
processes. That's the kind of thing I

1992
01:12:14,380 --> 01:12:16,486
learned from like it was in the form of

1993
01:12:16,508 --> 01:12:17,638
a lecture course. But it's basically the

1994
01:12:17,644 --> 01:12:19,338
same book because then there's just

1995
01:12:19,344 --> 01:12:20,618
loads of exercises that will make you

1996
01:12:20,624 --> 01:12:22,618
have to reason with string diagrams and

1997
01:12:22,624 --> 01:12:24,346
then you pick the rules up because at

1998
01:12:24,368 --> 01:12:26,934
first you don't have the same intuition,

1999
01:12:26,982 --> 01:12:29,146
obviously, but the rules what can I do

2000
01:12:29,168 --> 01:12:30,666
with these? Can I slide them around like

2001
01:12:30,688 --> 01:12:32,366
this or whatever? But it doesn't take

2002
01:12:32,388 --> 01:12:33,646
too long to get quite used to it, I

2003
01:12:33,668 --> 01:12:35,326
think, which is the nice thing about

2004
01:12:35,348 --> 01:12:36,538
them. They're kind of natural, they're

2005
01:12:36,554 --> 01:12:39,646
just these elastic strings and boxes and

2006
01:12:39,668 --> 01:12:40,986
you have that sort of geometrical

2007
01:12:41,018 --> 01:12:43,086
intuition. So things like that with

2008
01:12:43,108 --> 01:12:44,418
exercises are the way I'd recommend

2009
01:12:44,504 --> 01:12:47,586
getting used to using them. I didn't use

2010
01:12:47,608 --> 01:12:49,758
any software in a sense of the diagrams

2011
01:12:49,774 --> 01:12:50,958
I draw in this program called Tixit,

2012
01:12:50,974 --> 01:12:52,846
but it doesn't tell you how string

2013
01:12:52,878 --> 01:12:54,178
diagrams will work or anything, it's

2014
01:12:54,194 --> 01:12:55,480
just for drawing them.

2015
01:12:56,970 --> 01:13:00,680
But I know there's more work to develop.

2016
01:13:01,370 --> 01:13:03,394
Libraries like the Algebraic Julia

2017
01:13:03,442 --> 01:13:04,966
project is sort of like an applied

2018
01:13:04,998 --> 01:13:08,406
category theory language,

2019
01:13:08,518 --> 01:13:10,074
but I wouldn't know if it was

2020
01:13:10,112 --> 01:13:12,218
recommended as a way to first learn

2021
01:13:12,384 --> 01:13:13,290
categories.

2022
01:13:15,150 --> 01:13:17,018
Yeah. So I would recommend finding a

2023
01:13:17,024 --> 01:13:18,394
nice introductory paper in whatever

2024
01:13:18,432 --> 01:13:20,506
field you're most used to playing with

2025
01:13:20,528 --> 01:13:21,966
some exercises to get really used to

2026
01:13:21,988 --> 01:13:25,086
them. For causal models, there's this

2027
01:13:25,108 --> 01:13:27,246
paper Robin and I put out. It's not

2028
01:13:27,268 --> 01:13:28,478
necessarily the very first place to

2029
01:13:28,484 --> 01:13:30,318
learn string diagrams, but the aim is to

2030
01:13:30,484 --> 01:13:32,366
introduce to people who've heard of

2031
01:13:32,388 --> 01:13:33,838
causal models. So in a sense of pearl.

2032
01:13:33,854 --> 01:13:35,346
So just Bayesian networks, basically,

2033
01:13:35,448 --> 01:13:37,106
but maybe the course interpretation of

2034
01:13:37,128 --> 01:13:40,286
them to get them used to string

2035
01:13:40,318 --> 01:13:43,478
diagrams. And this paper hopes to be a

2036
01:13:43,484 --> 01:13:45,960
little bit introductory as well.

2037
01:13:48,170 --> 01:13:50,280
Cool. Ali, please.

2038
01:13:53,690 --> 01:13:56,074
Thank you. So getting back to the

2039
01:13:56,112 --> 01:13:58,662
question about the time representation

2040
01:13:58,806 --> 01:14:02,394
in this formulation. So I

2041
01:14:02,432 --> 01:14:05,734
take it that this kind of formulation

2042
01:14:05,782 --> 01:14:07,962
of Bayesian inference, I mean, category

2043
01:14:08,026 --> 01:14:09,546
theoretical formulation of Bayesian

2044
01:14:09,578 --> 01:14:13,098
inference is largely based on tobi's

2045
01:14:13,114 --> 01:14:16,410
Fritz definition of Markov categories

2046
01:14:16,490 --> 01:14:19,450
as CD categories. Right.

2047
01:14:19,620 --> 01:14:22,740
So as far as I understand it,

2048
01:14:23,270 --> 01:14:27,666
Fritz paper kind of one

2049
01:14:27,688 --> 01:14:30,882
of its basic assumptions is this kind of

2050
01:14:30,936 --> 01:14:34,294
unidirectional inference, I mean,

2051
01:14:34,332 --> 01:14:36,310
from earlier times to later times,

2052
01:14:36,380 --> 01:14:39,302
right, or in other words, the

2053
01:14:39,356 --> 01:14:44,520
prediction. But in

2054
01:14:44,910 --> 01:14:47,302
quantum formulation of active inference

2055
01:14:47,366 --> 01:14:51,050
or quantum active inference,

2056
01:14:51,630 --> 01:14:56,790
there's this attempt to also develop the

2057
01:14:56,960 --> 01:14:59,454
retradiction aspect of inference as

2058
01:14:59,492 --> 01:15:04,190
well. Right. So would you say this

2059
01:15:04,260 --> 01:15:07,870
recent formulation can also be accounted

2060
01:15:09,910 --> 01:15:12,194
for, this kind of retradiction? In other

2061
01:15:12,232 --> 01:15:15,618
words, can this formulation be

2062
01:15:15,704 --> 01:15:18,866
reconciled with quantum Bayesianism as

2063
01:15:18,888 --> 01:15:23,234
well? Yeah, I basically wish yeah,

2064
01:15:23,272 --> 01:15:25,894
sorry, go ahead. Because to add one more

2065
01:15:25,932 --> 01:15:29,238
context here, I think

2066
01:15:29,324 --> 01:15:32,278
it was in Kirk and Speckin's paper,

2067
01:15:32,444 --> 01:15:34,358
there was this clear distinction between

2068
01:15:34,444 --> 01:15:36,878
classical Bayesian inference and non

2069
01:15:36,914 --> 01:15:39,818
classical Bayesian inference, in which

2070
01:15:39,904 --> 01:15:46,058
the classical one does not allow

2071
01:15:46,144 --> 01:15:49,882
for the retrodiction, but non classical

2072
01:15:49,946 --> 01:15:53,454
Bayesian inference can be applied for

2073
01:15:53,492 --> 01:15:56,526
both prediction and retrodiction as

2074
01:15:56,548 --> 01:16:00,090
well. Okay, yeah, I would

2075
01:16:00,100 --> 01:16:02,674
love to be a bit more familiar with the

2076
01:16:02,712 --> 01:16:04,802
quantum active inference stuff,

2077
01:16:04,856 --> 01:16:07,554
basically, to compare a bit. So I'm not

2078
01:16:07,672 --> 01:16:11,326
as familiar with the sort of retro

2079
01:16:11,438 --> 01:16:13,378
sorry, what was the other version of

2080
01:16:13,384 --> 01:16:15,854
prediction? It's retro. Retrodiction,

2081
01:16:15,902 --> 01:16:18,050
yeah, prediction and retradiction.

2082
01:16:21,690 --> 01:16:23,846
I would have to compare with this. I

2083
01:16:23,868 --> 01:16:26,834
know the paper you mean Bob's Paper Frog

2084
01:16:26,962 --> 01:16:29,546
on both forms of Asian inference to see

2085
01:16:29,568 --> 01:16:31,862
what they say there about the classical

2086
01:16:31,926 --> 01:16:34,826
one. Can you give some intuition as to

2087
01:16:34,848 --> 01:16:37,226
why it isn't something you can do

2088
01:16:37,248 --> 01:16:39,502
classically, basically, the retro one?

2089
01:16:39,556 --> 01:16:41,614
Because if that's a general case about

2090
01:16:41,652 --> 01:16:44,286
probabilities, then it will be true in

2091
01:16:44,308 --> 01:16:46,938
some sense here. Right. So here it's

2092
01:16:46,954 --> 01:16:48,346
just being modeled in this probabilistic

2093
01:16:48,378 --> 01:16:50,586
category. And so at the moment they're

2094
01:16:50,618 --> 01:16:52,242
separate in that you have the model

2095
01:16:52,296 --> 01:16:53,538
which basically goes forward and then

2096
01:16:53,544 --> 01:16:55,314
you do your updating to try and

2097
01:16:55,512 --> 01:16:57,266
approximate something going back. But

2098
01:16:57,288 --> 01:16:58,980
you don't really have like this one.

2099
01:17:05,610 --> 01:17:09,298
The whole idea was that for predictive

2100
01:17:09,394 --> 01:17:11,814
quantum mechanics, we only need to

2101
01:17:11,852 --> 01:17:14,162
account for the inference from earlier

2102
01:17:14,226 --> 01:17:17,862
times to later times. But if we want

2103
01:17:17,916 --> 01:17:20,086
to account for retrodictive quantum

2104
01:17:20,118 --> 01:17:23,078
mechanics as well, we need to somehow

2105
01:17:23,254 --> 01:17:26,060
account for because as we know,

2106
01:17:27,090 --> 01:17:31,630
not every quantum formulation

2107
01:17:32,210 --> 01:17:34,510
follows the Bell's principle of local

2108
01:17:34,580 --> 01:17:35,550
causality.

2109
01:17:38,930 --> 01:17:41,534
In order to account for all the

2110
01:17:41,572 --> 01:17:44,146
entanglement phenomenon so on, we need

2111
01:17:44,168 --> 01:17:48,510
to somehow put this bi directional

2112
01:17:48,670 --> 01:17:50,900
inference into our model.

2113
01:17:51,430 --> 01:17:54,862
So, yeah, that was the basic idea

2114
01:17:54,936 --> 01:17:56,546
behind developing this kind of non

2115
01:17:56,578 --> 01:17:59,798
classical Bayesian inference. Does it

2116
01:17:59,804 --> 01:18:01,874
have something to do with the unitary

2117
01:18:01,922 --> 01:18:03,286
evolution in quantum theory the way that

2118
01:18:03,308 --> 01:18:05,420
you have this reversible thing? Or is it

2119
01:18:05,870 --> 01:18:10,074
exactly that

2120
01:18:10,112 --> 01:18:13,626
was the gist of it, yeah. And so you

2121
01:18:13,648 --> 01:18:14,826
don't expect to have something like that

2122
01:18:14,848 --> 01:18:16,234
classically, basically, where you have

2123
01:18:16,272 --> 01:18:18,606
this reversible thing built in. Well,

2124
01:18:18,628 --> 01:18:22,734
yeah, so I wouldn't expect to see that

2125
01:18:22,772 --> 01:18:24,606
exact feature here in the sense of if

2126
01:18:24,628 --> 01:18:26,782
it's treated, if it's basically

2127
01:18:26,836 --> 01:18:28,574
something that you can't have in

2128
01:18:28,612 --> 01:18:31,386
classical probabilities, it won't exist

2129
01:18:31,418 --> 01:18:33,566
in this category matar plus. I think

2130
01:18:33,588 --> 01:18:34,626
that would be basically the same

2131
01:18:34,648 --> 01:18:36,018
category they would use in that paper,

2132
01:18:36,104 --> 01:18:37,118
and they work with dagger combat

2133
01:18:37,134 --> 01:18:39,554
categories, and they'll work with

2134
01:18:39,752 --> 01:18:41,326
something like this Matar Plus category.

2135
01:18:41,358 --> 01:18:43,540
But the classical case,

2136
01:18:44,870 --> 01:18:48,278
if it's just a general it's less of a

2137
01:18:48,284 --> 01:18:49,686
sort of physical notion, but it's just

2138
01:18:49,708 --> 01:18:52,038
an idea that the model comes with a

2139
01:18:52,044 --> 01:18:53,798
forward part and a backward part, then I

2140
01:18:53,804 --> 01:18:56,726
think that's the kind of here how you go

2141
01:18:56,748 --> 01:18:58,266
from a forward part to approximate this

2142
01:18:58,288 --> 01:19:00,646
backward thing. But the sort of lens

2143
01:19:00,678 --> 01:19:02,634
type view of what's going on that's more

2144
01:19:02,752 --> 01:19:05,034
studied in category cybernetics would be

2145
01:19:05,152 --> 01:19:07,094
imagining. I think the model kind of

2146
01:19:07,232 --> 01:19:09,630
carrying this backward inference process

2147
01:19:09,700 --> 01:19:12,894
with it as well, so that for each

2148
01:19:12,932 --> 01:19:14,800
forward part of the model, you would

2149
01:19:16,210 --> 01:19:19,198
have this approximate inference sort of

2150
01:19:19,204 --> 01:19:22,178
channel stored with it. So I don't know

2151
01:19:22,184 --> 01:19:23,198
if that would address what you're

2152
01:19:23,214 --> 01:19:25,106
asking, but it would have a backward and

2153
01:19:25,128 --> 01:19:26,260
forward part together.

2154
01:19:30,070 --> 01:19:33,240
Well, Ollie, do you have any kind of

2155
01:19:34,410 --> 01:19:38,278
closing opening remarks or questions or

2156
01:19:38,364 --> 01:19:39,846
where do you see this going from the

2157
01:19:39,868 --> 01:19:42,278
active inference side? What does this

2158
01:19:42,444 --> 01:19:45,930
bring to us and what is

2159
01:19:46,000 --> 01:19:49,740
opened through what has happened

2160
01:19:50,350 --> 01:19:53,766
largely this year in active inference

2161
01:19:53,798 --> 01:19:57,082
and category theory? Well, actually,

2162
01:19:57,136 --> 01:19:59,546
I'm really excited to see this line of

2163
01:19:59,568 --> 01:20:02,010
development in active inference theory.

2164
01:20:02,090 --> 01:20:05,120
And as you know, I'm a big, big fan of

2165
01:20:05,570 --> 01:20:09,360
meta theories and all kinds of

2166
01:20:09,990 --> 01:20:12,180
unification theories and so on.

2167
01:20:15,430 --> 01:20:18,834
I don't know, I kind of have

2168
01:20:18,872 --> 01:20:22,030
this feeling, have this hunch that this

2169
01:20:22,120 --> 01:20:25,430
line of development in active inference

2170
01:20:25,850 --> 01:20:30,230
theory, it looks quite promising,

2171
01:20:31,130 --> 01:20:35,626
especially for kind

2172
01:20:35,648 --> 01:20:38,042
of tying up all the loose ends and

2173
01:20:38,096 --> 01:20:41,434
transcending many, many other areas and

2174
01:20:41,472 --> 01:20:45,066
discourses and ultimately reaching a

2175
01:20:45,088 --> 01:20:48,726
kind of coherent picture of quote

2176
01:20:48,758 --> 01:20:51,866
unquote reality, whatever it means.

2177
01:20:52,048 --> 01:20:55,646
So, yeah, these kinds of development, I

2178
01:20:55,668 --> 01:20:59,150
mean, the last year we had tremendous

2179
01:21:00,550 --> 01:21:03,838
advances in Bayesian mechanical

2180
01:21:04,014 --> 01:21:07,650
theories, and in recent months

2181
01:21:07,720 --> 01:21:11,714
we have this fabulous line of research

2182
01:21:11,832 --> 01:21:15,686
in category theoretical account of

2183
01:21:15,708 --> 01:21:18,406
active inference. My hope is that

2184
01:21:18,508 --> 01:21:21,974
ultimately these different strands can

2185
01:21:22,012 --> 01:21:26,182
be unified into coherent

2186
01:21:26,246 --> 01:21:30,374
and overarching framework. So exciting

2187
01:21:30,422 --> 01:21:31,020
times.

2188
01:21:38,270 --> 01:21:39,806
So do you mean that you're thinking of

2189
01:21:39,828 --> 01:21:41,342
it as it sounded like you're basically

2190
01:21:41,396 --> 01:21:44,606
alluding to the work going on in

2191
01:21:44,628 --> 01:21:46,874
cognition and work going on in physics

2192
01:21:46,922 --> 01:21:49,198
coming together. Right. Like one really

2193
01:21:49,364 --> 01:21:51,698
meta really open. Exactly,

2194
01:21:51,864 --> 01:21:54,574
yeah. The idea behind Bayesian

2195
01:21:54,622 --> 01:21:58,194
mechanics, one of its premises or

2196
01:21:58,232 --> 01:22:01,282
assertions was that there isn't any

2197
01:22:01,336 --> 01:22:05,842
clear distinction between cognitive

2198
01:22:05,906 --> 01:22:09,958
and non cognitive things or agents and

2199
01:22:10,124 --> 01:22:13,750
they rest on a continuum.

2200
01:22:15,310 --> 01:22:17,754
The same kind of mathematical technology

2201
01:22:17,872 --> 01:22:20,460
can be applied both for inert and

2202
01:22:21,150 --> 01:22:25,194
conscious agents or sentient agents or

2203
01:22:25,232 --> 01:22:27,902
whatever we choose to call them. So,

2204
01:22:28,036 --> 01:22:33,834
yeah, this overarching theory unveiled

2205
01:22:33,962 --> 01:22:38,042
many interesting phenomena regarding,

2206
01:22:38,186 --> 01:22:43,314
well, self organizing systems, and it

2207
01:22:43,352 --> 01:22:46,770
changed the whole perspective about how

2208
01:22:46,840 --> 01:22:50,254
we can look at and even define

2209
01:22:50,302 --> 01:22:52,882
consciousness, cognition, intelligence,

2210
01:22:52,946 --> 01:22:55,122
sentience, and all of these related

2211
01:22:55,186 --> 01:22:59,810
terms. So my hope is that category

2212
01:22:59,890 --> 01:23:03,282
theoretical account of active inference

2213
01:23:03,426 --> 01:23:07,082
can also be used for

2214
01:23:07,216 --> 01:23:12,374
clearly seeing many of these emerging

2215
01:23:12,502 --> 01:23:15,146
elements in Bayesian mechanics and

2216
01:23:15,168 --> 01:23:17,870
active inference theory and hopefully,

2217
01:23:19,010 --> 01:23:22,734
well, gaining some interesting and

2218
01:23:22,772 --> 01:23:25,070
potentially groundbreaking insights.

2219
01:23:26,690 --> 01:23:28,320
That'd be wonderful. Yeah,

2220
01:23:29,650 --> 01:23:32,174
I'd love to apply for those topics, and

2221
01:23:32,212 --> 01:23:34,114
I'd be very curious to see how

2222
01:23:34,152 --> 01:23:35,774
categories can come in. Sorry, Daniel.

2223
01:23:35,822 --> 01:23:37,634
Yeah. Oh, yeah. I'll just give my

2224
01:23:37,672 --> 01:23:39,374
closing thoughts then to you, Sean.

2225
01:23:39,422 --> 01:23:41,762
Just a few loose notes that, again,

2226
01:23:41,816 --> 01:23:44,834
open probably more than they close. Ali

2227
01:23:44,882 --> 01:23:49,394
was right in suggesting and expressing

2228
01:23:49,442 --> 01:23:51,606
that Bayesian mechanics recently has

2229
01:23:51,708 --> 01:23:55,378
helped us develop a continuum of active

2230
01:23:55,394 --> 01:23:57,254
and passive systems, so called living

2231
01:23:57,292 --> 01:23:58,746
and non living, or inanimate and

2232
01:23:58,768 --> 01:24:01,994
animate. And that brings us to another

2233
01:24:02,192 --> 01:24:04,314
dialectic to resolve, which is life and

2234
01:24:04,352 --> 01:24:06,586
mind, which is where the physical and

2235
01:24:06,608 --> 01:24:08,462
the cognitive science come together.

2236
01:24:08,596 --> 01:24:10,414
You said they're on a continuum. Maybe

2237
01:24:10,452 --> 01:24:12,270
we could say they're on a quantinium.

2238
01:24:12,850 --> 01:24:18,270
And what language could express such

2239
01:24:18,420 --> 01:24:21,394
work? Well, right now we're speaking in

2240
01:24:21,432 --> 01:24:22,814
English with the active inference

2241
01:24:22,862 --> 01:24:25,934
ontology dialect. However, the phonemes

2242
01:24:25,982 --> 01:24:29,138
are not intrinsically meaningful. The M

2243
01:24:29,224 --> 01:24:31,870
in a Markov blanket or category does not

2244
01:24:31,960 --> 01:24:34,920
mean something. It's a sound.

2245
01:24:35,530 --> 01:24:39,270
And so the string diagram

2246
01:24:39,610 --> 01:24:42,918
language and representation I see as a

2247
01:24:42,924 --> 01:24:46,918
way to fuse and integrate

2248
01:24:47,094 --> 01:24:50,860
semantics into the syntax of the actual

2249
01:24:52,190 --> 01:24:55,834
inscription, which enables us

2250
01:24:55,952 --> 01:24:59,246
to generalize in new ways.

2251
01:24:59,428 --> 01:25:01,038
Also, recognizing string diagrams are

2252
01:25:01,044 --> 01:25:05,278
not everything, and so on. And then

2253
01:25:05,364 --> 01:25:07,850
with all of these intersecting vectors

2254
01:25:07,930 --> 01:25:09,590
from the cognitive and the physical

2255
01:25:09,690 --> 01:25:13,474
sciences, we are able to

2256
01:25:13,592 --> 01:25:16,238
take the compositional cartographic

2257
01:25:16,334 --> 01:25:20,434
approach for cognitive ecosystems and

2258
01:25:20,552 --> 01:25:22,450
talk about diverse intelligences,

2259
01:25:22,970 --> 01:25:25,650
biological, quantum, classical

2260
01:25:25,730 --> 01:25:28,226
architectures, all of these synthetic

2261
01:25:28,258 --> 01:25:31,606
intelligences. And so it's super

2262
01:25:31,708 --> 01:25:35,258
exciting, and I appreciate again your

2263
01:25:35,344 --> 01:25:38,246
visit and look forward to people's

2264
01:25:38,278 --> 01:25:41,066
curiosity taking them and also the

2265
01:25:41,088 --> 01:25:42,566
development of tools and educational

2266
01:25:42,598 --> 01:25:45,962
materials that make this easier and then

2267
01:25:46,016 --> 01:25:49,120
being able to display and use something

2268
01:25:49,490 --> 01:25:52,880
where the meaning is

2269
01:25:53,490 --> 01:25:56,670
primal rather than like, well, this

2270
01:25:56,740 --> 01:25:58,720
letter represents this.

2271
01:26:00,150 --> 01:26:02,338
It already introduces such a space

2272
01:26:02,424 --> 01:26:06,130
between the analytical representation

2273
01:26:06,710 --> 01:26:10,254
and really the string

2274
01:26:10,302 --> 01:26:14,334
diagram, which exists isomorphically

2275
01:26:14,382 --> 01:26:15,220
with it.

2276
01:26:19,190 --> 01:26:21,798
Yes, I find this very exciting way of

2277
01:26:21,804 --> 01:26:24,070
thinking. It sounds like you're

2278
01:26:24,970 --> 01:26:27,730
advocating a kind of structural ontology

2279
01:26:27,810 --> 01:26:29,114
kind of thing in some sense, right,

2280
01:26:29,152 --> 01:26:31,494
where you're taking the compositional

2281
01:26:31,542 --> 01:26:32,634
structure of what's going on to really

2282
01:26:32,672 --> 01:26:34,970
be the meaning or really be the real

2283
01:26:35,040 --> 01:26:37,466
thing that's there, not just like I

2284
01:26:37,488 --> 01:26:38,986
don't know. Yeah, we could talk about it

2285
01:26:39,008 --> 01:26:41,434
for a while, I imagine, but I would love

2286
01:26:41,472 --> 01:26:45,674
to see string diagrams and other

2287
01:26:45,712 --> 01:26:48,746
approaches. I'm sure that take that

2288
01:26:48,768 --> 01:26:50,254
role. And you've got me very excited

2289
01:26:50,302 --> 01:26:51,758
about this kind of unification that's

2290
01:26:51,774 --> 01:26:55,490
going on. Thank you again,

2291
01:26:55,560 --> 01:26:57,154
Sean. You're always welcome, and we look

2292
01:26:57,192 --> 01:26:59,300
forward to seeing where this all goes.

2293
01:26:59,670 --> 01:27:01,810
Yeah. Thanks again for having me. Yeah.

2294
01:27:01,880 --> 01:27:04,180
Really great discussion. Thank you.

2295
01:27:04,790 --> 01:27:07,186
Thank you so much. Thanks, Ali. All

2296
01:27:07,208 --> 01:27:07,694
right. Bye.


