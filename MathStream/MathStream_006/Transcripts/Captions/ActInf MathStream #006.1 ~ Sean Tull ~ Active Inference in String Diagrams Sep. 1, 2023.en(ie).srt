1
00:00:07,340 --> 00:00:09,960
hello and welcome everyone

2
00:00:09,960 --> 00:00:12,840
it is September 1st 2023

3
00:00:12,840 --> 00:00:15,000
we're here in active inference math

4
00:00:15,000 --> 00:00:17,520
stream number 6.1

5
00:00:17,520 --> 00:00:20,340
here with Sean Tull we'll be hearing a

6
00:00:20,340 --> 00:00:23,340
presentation active inference in string

7
00:00:23,340 --> 00:00:26,279
diagrams followed by a discussion this

8
00:00:26,279 --> 00:00:28,500
is super exciting so if you're watching

9
00:00:28,500 --> 00:00:30,840
live please feel free to write your

10
00:00:30,840 --> 00:00:33,180
questions in the live chat

11
00:00:33,180 --> 00:00:35,100
really looking forward to this so thank

12
00:00:35,100 --> 00:00:37,620
you Sean again for joining and to you

13
00:00:37,620 --> 00:00:40,260
for the presentation

14
00:00:40,260 --> 00:00:41,460
all right thanks very much thanks

15
00:00:41,460 --> 00:00:42,840
everyone for watching and thanks to the

16
00:00:42,840 --> 00:00:44,219
organizers for this chance to speak to

17
00:00:44,219 --> 00:00:45,540
you and for the Daniel for getting in

18
00:00:45,540 --> 00:00:47,820
touch and inviting me to speak so

19
00:00:47,820 --> 00:00:48,899
um yeah I'm really excited to share this

20
00:00:48,899 --> 00:00:50,700
work with this community basically and

21
00:00:50,700 --> 00:00:52,440
to hear from those people who work with

22
00:00:52,440 --> 00:00:53,940
active inference and do any formal work

23
00:00:53,940 --> 00:00:55,079
what they what they think of what I'll

24
00:00:55,079 --> 00:00:56,820
present today

25
00:00:56,820 --> 00:00:58,160
um so I'm going to be

26
00:00:58,160 --> 00:01:00,719
presenting a formal approach to how you

27
00:01:00,719 --> 00:01:01,980
can describe active inference in terms

28
00:01:01,980 --> 00:01:04,319
of a entirely graphical language called

29
00:01:04,319 --> 00:01:05,820
language of string diagrams and it's

30
00:01:05,820 --> 00:01:06,840
based on this mathematics called

31
00:01:06,840 --> 00:01:09,000
category Theory and I won't assume that

32
00:01:09,000 --> 00:01:10,080
you're too familiar with this already

33
00:01:10,080 --> 00:01:12,420
and try and introduce it to you in the

34
00:01:12,420 --> 00:01:14,520
talk and ultimately I'd like to sort of

35
00:01:14,520 --> 00:01:15,780
convince you that this diagrammatic

36
00:01:15,780 --> 00:01:17,100
language will be really useful for those

37
00:01:17,100 --> 00:01:18,540
of you who work formally with active

38
00:01:18,540 --> 00:01:19,920
infants I'd encourage you to pick it up

39
00:01:19,920 --> 00:01:21,720
in your own work

40
00:01:21,720 --> 00:01:23,700
I'll just introduce myself about I'm

41
00:01:23,700 --> 00:01:27,299
Sean tile I'm a researcher at Continuum

42
00:01:27,299 --> 00:01:28,740
um formerly a postdoc and computer

43
00:01:28,740 --> 00:01:30,900
science in Oxford and a Continuum in

44
00:01:30,900 --> 00:01:32,520
this Oxford team where I'm based where

45
00:01:32,520 --> 00:01:34,080
we study what we call compositional

46
00:01:34,080 --> 00:01:35,820
intelligence which includes cat applying

47
00:01:35,820 --> 00:01:39,659
category Theory uh to topics in AI

48
00:01:39,659 --> 00:01:42,060
um and as well as this the project was

49
00:01:42,060 --> 00:01:44,640
supported by a grant from fqxi it's

50
00:01:44,640 --> 00:01:46,079
focus at the bottom and posted it at

51
00:01:46,079 --> 00:01:47,280
topless Institute which is the Center

52
00:01:47,280 --> 00:01:50,460
for Applied category Theory

53
00:01:50,460 --> 00:01:54,060
um so let me get started I think so

54
00:01:54,060 --> 00:01:56,520
yeah here we go so um for active

55
00:01:56,520 --> 00:01:58,020
inference I'll won't spend too much time

56
00:01:58,020 --> 00:01:59,220
introducing it I'll assume most people

57
00:01:59,220 --> 00:02:00,899
here are familiar with it and many of

58
00:02:00,899 --> 00:02:02,220
you probably know more about it than I

59
00:02:02,220 --> 00:02:03,780
do intact

60
00:02:03,780 --> 00:02:06,299
um so I just mentioned the parts of it

61
00:02:06,299 --> 00:02:08,038
that I'll be interestingly in in the

62
00:02:08,038 --> 00:02:09,720
talk so thinking of it as a model of

63
00:02:09,720 --> 00:02:11,940
cognition that simply we can think of as

64
00:02:11,940 --> 00:02:13,860
applying many levels say from a whole

65
00:02:13,860 --> 00:02:16,680
organism or just to a single neuron

66
00:02:16,680 --> 00:02:18,599
um and the key idea is that in the in a

67
00:02:18,599 --> 00:02:20,220
you think of an agent as coming with

68
00:02:20,220 --> 00:02:22,800
this generative model that it uses to

69
00:02:22,800 --> 00:02:24,239
explain the observations it receives

70
00:02:24,239 --> 00:02:26,700
from the world in terms of some some

71
00:02:26,700 --> 00:02:28,319
hidden states which you might call

72
00:02:28,319 --> 00:02:29,640
perception and in terms of its own

73
00:02:29,640 --> 00:02:30,720
actions

74
00:02:30,720 --> 00:02:32,400
and

75
00:02:32,400 --> 00:02:34,379
um and active infants it achieves both

76
00:02:34,379 --> 00:02:36,599
of these things for this formal

77
00:02:36,599 --> 00:02:38,040
um patient inference or an approximate

78
00:02:38,040 --> 00:02:39,660
form of Asian inference by minimizing

79
00:02:39,660 --> 00:02:41,220
this quantity called free energy and

80
00:02:41,220 --> 00:02:42,540
these are the ingredients we'll be we'll

81
00:02:42,540 --> 00:02:44,280
be looking at in the talk and the thing

82
00:02:44,280 --> 00:02:45,300
that's really exciting about activism

83
00:02:45,300 --> 00:02:46,800
inside think

84
00:02:46,800 --> 00:02:48,239
um for those of a formal background as

85
00:02:48,239 --> 00:02:50,760
well is that it you know aims to offer

86
00:02:50,760 --> 00:02:52,080
like a very principled approach to

87
00:02:52,080 --> 00:02:53,760
cognition

88
00:02:53,760 --> 00:02:55,080
um that you can hopefully apply at all

89
00:02:55,080 --> 00:02:56,459
these many levels

90
00:02:56,459 --> 00:02:57,840
but I think at the moment it could also

91
00:02:57,840 --> 00:03:00,720
benefit from more uh formal work

92
00:03:00,720 --> 00:03:02,340
and that's what this talks about it's

93
00:03:02,340 --> 00:03:04,620
about formal approaches to theory in

94
00:03:04,620 --> 00:03:06,900
particular I think a nice clear

95
00:03:06,900 --> 00:03:08,459
organizations or active instances would

96
00:03:08,459 --> 00:03:10,319
help to to clarify sort of what the core

97
00:03:10,319 --> 00:03:12,060
or the key ideas of the theory are so

98
00:03:12,060 --> 00:03:13,980
we'd like to be this very succinct

99
00:03:13,980 --> 00:03:15,540
um principle that ideally we just apply

100
00:03:15,540 --> 00:03:16,920
to a generative model and everything

101
00:03:16,920 --> 00:03:18,720
else follows from

102
00:03:18,720 --> 00:03:20,159
um and once we've got to this we can

103
00:03:20,159 --> 00:03:21,540
hopefully generalize it understand it

104
00:03:21,540 --> 00:03:22,319
better

105
00:03:22,319 --> 00:03:24,599
and also make it just more acceptable to

106
00:03:24,599 --> 00:03:25,739
those who come from formal backgrounds

107
00:03:25,739 --> 00:03:27,000
like in mathematics and so on and get

108
00:03:27,000 --> 00:03:28,620
them working on the topic very quickly

109
00:03:28,620 --> 00:03:30,959
and and connect it with approaches in in

110
00:03:30,959 --> 00:03:33,540
artificial intelligence as well

111
00:03:33,540 --> 00:03:34,739
um but the most important thing about a

112
00:03:34,739 --> 00:03:36,900
good formalization I think should just

113
00:03:36,900 --> 00:03:38,640
be to make learning reactive inference

114
00:03:38,640 --> 00:03:40,319
easier make the framework simpler to

115
00:03:40,319 --> 00:03:42,540
understand the sort of what we're aiming

116
00:03:42,540 --> 00:03:44,159
for in this work

117
00:03:44,159 --> 00:03:46,440
and I'd say in them

118
00:03:46,440 --> 00:03:49,860
in other places already there's been

119
00:03:49,860 --> 00:03:51,659
some calls that got some suggestions

120
00:03:51,659 --> 00:03:53,400
that a nice finalization of active

121
00:03:53,400 --> 00:03:55,379
infants should be a diagrammatic one so

122
00:03:55,379 --> 00:03:56,519
when you look at the generative models

123
00:03:56,519 --> 00:03:58,140
that come up in experience a lot they're

124
00:03:58,140 --> 00:03:59,580
very compositional in their nature and

125
00:03:59,580 --> 00:04:01,140
it's very natural to draw them in

126
00:04:01,140 --> 00:04:02,760
diagrams

127
00:04:02,760 --> 00:04:04,140
um so in the United States like our

128
00:04:04,140 --> 00:04:05,700
whole approach to describing it could be

129
00:04:05,700 --> 00:04:07,799
graphical in this way so just for

130
00:04:07,799 --> 00:04:08,819
example this is paper called The

131
00:04:08,819 --> 00:04:10,980
graphical brain by by Kristen power and

132
00:04:10,980 --> 00:04:13,019
abuse and in general you know we've

133
00:04:13,019 --> 00:04:14,220
probably seen loads of these diagrams

134
00:04:14,220 --> 00:04:16,079
describing generative models where you

135
00:04:16,079 --> 00:04:18,120
draw many um compositional features of

136
00:04:18,120 --> 00:04:19,738
different uh spaces of hidden States

137
00:04:19,738 --> 00:04:22,139
observations interacting and so on

138
00:04:22,139 --> 00:04:23,360
so

139
00:04:23,360 --> 00:04:25,199
these diagrams are used but they just

140
00:04:25,199 --> 00:04:26,340
used to represent the model you still

141
00:04:26,340 --> 00:04:28,560
have to then go to doing um sort of

142
00:04:28,560 --> 00:04:30,240
traditional probability Theory

143
00:04:30,240 --> 00:04:31,740
calculations when you reason about them

144
00:04:31,740 --> 00:04:34,199
normally and in fact there is a whole

145
00:04:34,199 --> 00:04:36,120
graphical formalism and mathematical

146
00:04:36,120 --> 00:04:37,620
language for describing these kind of

147
00:04:37,620 --> 00:04:39,900
interacting processes

148
00:04:39,900 --> 00:04:42,300
um just entirely with the diagrams so

149
00:04:42,300 --> 00:04:43,560
the area of an accessible category

150
00:04:43,560 --> 00:04:44,699
Theory and the language are these string

151
00:04:44,699 --> 00:04:47,580
diagrams I'm going to talk today

152
00:04:47,580 --> 00:04:49,259
and in particular there's a lot of work

153
00:04:49,259 --> 00:04:51,960
going on in applied category now in how

154
00:04:51,960 --> 00:04:53,820
you can describe aspects of probability

155
00:04:53,820 --> 00:04:56,040
Theory and causality and causal models

156
00:04:56,040 --> 00:04:58,620
in terms of string diagrams and these

157
00:04:58,620 --> 00:04:59,940
called the models are basically based on

158
00:04:59,940 --> 00:05:01,440
data networks so the same formal

159
00:05:01,440 --> 00:05:03,120
structure as the generative models in

160
00:05:03,120 --> 00:05:04,560
active inference

161
00:05:04,560 --> 00:05:06,060
in particular what we'll talk about

162
00:05:06,060 --> 00:05:07,520
today kind of draws on this paper

163
00:05:07,520 --> 00:05:09,479
Cooperative with Robin Lorenz talking

164
00:05:09,479 --> 00:05:12,240
about causal models and a sense of pearl

165
00:05:12,240 --> 00:05:13,500
in terms of these string diagrams that's

166
00:05:13,500 --> 00:05:15,840
basically caused of Asian networks

167
00:05:15,840 --> 00:05:16,860
um

168
00:05:16,860 --> 00:05:18,660
which has the same formal structure as

169
00:05:18,660 --> 00:05:20,820
we'll be talking about today

170
00:05:20,820 --> 00:05:21,840
so

171
00:05:21,840 --> 00:05:23,280
in this talk I'm talking about this

172
00:05:23,280 --> 00:05:25,199
paper which is joint work with Johannes

173
00:05:25,199 --> 00:05:27,800
Kleiner and services

174
00:05:27,800 --> 00:05:30,900
string diagrams a categorical account

175
00:05:30,900 --> 00:05:33,060
effective processing and free energy and

176
00:05:33,060 --> 00:05:34,440
basically what we do is try to give a

177
00:05:34,440 --> 00:05:36,360
formalization of active inference that's

178
00:05:36,360 --> 00:05:37,620
nice and clear conceptually just

179
00:05:37,620 --> 00:05:39,780
entirely in terms of string diagrams so

180
00:05:39,780 --> 00:05:40,919
we're basically taking the kind of

181
00:05:40,919 --> 00:05:42,300
formal components in something like the

182
00:05:42,300 --> 00:05:44,400
active infants book and turning it into

183
00:05:44,400 --> 00:05:47,239
these diagrams

184
00:05:47,280 --> 00:05:49,979
and as I mentioned it was done as part

185
00:05:49,979 --> 00:05:51,900
of this fqxi project that's actually on

186
00:05:51,900 --> 00:05:53,580
a project about Consciousness it's about

187
00:05:53,580 --> 00:05:55,740
ways that category Theory can be applied

188
00:05:55,740 --> 00:05:57,479
to theories of Consciousness and we've

189
00:05:57,479 --> 00:05:59,039
done some previous work looking at the

190
00:05:59,039 --> 00:06:00,240
integrated information Theory Of

191
00:06:00,240 --> 00:06:01,860
Consciousness and of course there's all

192
00:06:01,860 --> 00:06:03,120
sorts of ways that active inference has

193
00:06:03,120 --> 00:06:04,199
been proposed to connect to

194
00:06:04,199 --> 00:06:06,060
consciousness

195
00:06:06,060 --> 00:06:07,380
um but for the purpose of this talk we

196
00:06:07,380 --> 00:06:08,460
won't go into any of that it's just a

197
00:06:08,460 --> 00:06:10,979
period of cognition I take it to be here

198
00:06:10,979 --> 00:06:13,080
and I'll just mention at the end it'd be

199
00:06:13,080 --> 00:06:14,340
nice to connect it back up to

200
00:06:14,340 --> 00:06:15,780
Consciousness in future

201
00:06:15,780 --> 00:06:17,520
and there's also lots of other related

202
00:06:17,520 --> 00:06:19,800
work going on in KB Theory that's very

203
00:06:19,800 --> 00:06:21,240
close to this that often goes by the

204
00:06:21,240 --> 00:06:22,979
name of categorical cybernetics and this

205
00:06:22,979 --> 00:06:24,780
might include some of the things Toby

206
00:06:24,780 --> 00:06:26,340
has talked about on the on the stream in

207
00:06:26,340 --> 00:06:27,419
the past

208
00:06:27,419 --> 00:06:29,940
so what I do now is introduce categories

209
00:06:29,940 --> 00:06:32,460
and string diagrams and then later we'll

210
00:06:32,460 --> 00:06:33,840
apply them for these basic ingredients

211
00:06:33,840 --> 00:06:35,460
of active infants that I've alluded to

212
00:06:35,460 --> 00:06:37,259
so far so that would be generated models

213
00:06:37,259 --> 00:06:40,259
updating them free energy and active

214
00:06:40,259 --> 00:06:42,380
inference itself

215
00:06:42,380 --> 00:06:44,580
let's start with with these categories

216
00:06:44,580 --> 00:06:46,740
and string diagrams

217
00:06:46,740 --> 00:06:48,780
so you can think of a category in

218
00:06:48,780 --> 00:06:50,580
general as a sort of world of

219
00:06:50,580 --> 00:06:52,979
interacting processes and the categories

220
00:06:52,979 --> 00:06:53,940
we'll talk about here are always going

221
00:06:53,940 --> 00:06:55,680
to be the symmetric monoidal categories

222
00:06:55,680 --> 00:06:56,940
but don't worry too much about the

223
00:06:56,940 --> 00:06:58,979
formal language because the way we talk

224
00:06:58,979 --> 00:07:00,000
about them is just going to come down to

225
00:07:00,000 --> 00:07:01,740
the diagrams here today

226
00:07:01,740 --> 00:07:03,960
so a category amounts to a collection of

227
00:07:03,960 --> 00:07:05,340
these objects or sometimes called

228
00:07:05,340 --> 00:07:07,919
systems like this Capital ABC here

229
00:07:07,919 --> 00:07:09,960
and what are called morphisms or you

230
00:07:09,960 --> 00:07:11,580
might monitor typical processes between

231
00:07:11,580 --> 00:07:13,680
them so when you're writing normally you

232
00:07:13,680 --> 00:07:16,080
can just write a more person from A to B

233
00:07:16,080 --> 00:07:18,600
it's like this at colon A to B in string

234
00:07:18,600 --> 00:07:20,099
diagrams so you draw it like this where

235
00:07:20,099 --> 00:07:21,419
we're reading all the diagrams from

236
00:07:21,419 --> 00:07:23,699
bottom to top in in this talk so you

237
00:07:23,699 --> 00:07:25,979
have a wire for the a input at the

238
00:07:25,979 --> 00:07:28,560
bottom and a YF heavy B output at the

239
00:07:28,560 --> 00:07:30,479
top and the morphism is just drawn as a

240
00:07:30,479 --> 00:07:32,460
box F here and you just read the diagram

241
00:07:32,460 --> 00:07:34,080
up thinking about okay it takes in this

242
00:07:34,080 --> 00:07:36,479
input coming in on this y a process

243
00:07:36,479 --> 00:07:38,460
applies and then you have your output

244
00:07:38,460 --> 00:07:40,800
type B at the top

245
00:07:40,800 --> 00:07:41,819
yeah

246
00:07:41,819 --> 00:07:43,500
so what you can do with these processes

247
00:07:43,500 --> 00:07:45,060
is compose them so if you have two

248
00:07:45,060 --> 00:07:46,139
processes

249
00:07:46,139 --> 00:07:48,599
um they get F from A to B and G from B

250
00:07:48,599 --> 00:07:49,979
to C so the type of sign up you can just

251
00:07:49,979 --> 00:07:51,900
compose them in sequence and this just

252
00:07:51,900 --> 00:07:53,699
means plugging the boxes together in

253
00:07:53,699 --> 00:07:55,800
your diagrams and because we're in this

254
00:07:55,800 --> 00:07:57,599
monoidal category you can also compose

255
00:07:57,599 --> 00:07:59,819
in parallel so you have this operation

256
00:07:59,819 --> 00:08:01,440
called the 10th so which means given to

257
00:08:01,440 --> 00:08:03,180
objects you can put them together to

258
00:08:03,180 --> 00:08:05,160
build this composite object so AV goes

259
00:08:05,160 --> 00:08:07,500
to a TENS of B you'd say and you can

260
00:08:07,500 --> 00:08:09,000
also do this to morphisms so you can

261
00:08:09,000 --> 00:08:11,220
build this F tensor G

262
00:08:11,220 --> 00:08:12,360
um but in the pictures it just means

263
00:08:12,360 --> 00:08:13,620
growing them side by side and you just

264
00:08:13,620 --> 00:08:15,960
think of this as meaning we have F from

265
00:08:15,960 --> 00:08:17,460
a to c and G from B to D and they're

266
00:08:17,460 --> 00:08:18,900
just running in parallel and they're not

267
00:08:18,900 --> 00:08:20,879
interacting essentially

268
00:08:20,879 --> 00:08:22,080
um so most of the time you just draw a

269
00:08:22,080 --> 00:08:22,919
picture like this and you don't even

270
00:08:22,919 --> 00:08:25,080
need to write the tensor symbols so if

271
00:08:25,080 --> 00:08:26,940
these two basic modes of composition and

272
00:08:26,940 --> 00:08:28,979
from these you can build much more uh

273
00:08:28,979 --> 00:08:30,720
elaborate string diagrams in your

274
00:08:30,720 --> 00:08:32,360
category

275
00:08:32,360 --> 00:08:34,380
so if you're writing things very

276
00:08:34,380 --> 00:08:35,399
mathematically if there were relative

277
00:08:35,399 --> 00:08:37,020
equations that these that are category

278
00:08:37,020 --> 00:08:38,820
or minodial category needs to satisfy

279
00:08:38,820 --> 00:08:40,380
but when you work in the diagrams they

280
00:08:40,380 --> 00:08:41,700
basically do some of the work for you

281
00:08:41,700 --> 00:08:42,899
because these things just come out for

282
00:08:42,899 --> 00:08:44,820
free so for example you have equations

283
00:08:44,820 --> 00:08:47,399
like this that you'd have to think about

284
00:08:47,399 --> 00:08:49,620
when you're working uh with them in the

285
00:08:49,620 --> 00:08:51,120
conventional mathematical way but in the

286
00:08:51,120 --> 00:08:52,980
diagrams it just means if you have two

287
00:08:52,980 --> 00:08:54,420
boxes you can kind of slide them along

288
00:08:54,420 --> 00:08:55,680
the wires it doesn't really matter where

289
00:08:55,680 --> 00:08:57,360
they are on the wires it tends to just

290
00:08:57,360 --> 00:08:58,560
be the connectivity that matters

291
00:08:58,560 --> 00:09:00,660
similarly we can crosswise over each

292
00:09:00,660 --> 00:09:02,959
other because we're in symmetric setting

293
00:09:02,959 --> 00:09:05,880
and uh there's a few like

294
00:09:05,880 --> 00:09:07,320
um just useful features that you always

295
00:09:07,320 --> 00:09:09,060
have in a category so every every object

296
00:09:09,060 --> 00:09:10,740
comes with this identity morphism you

297
00:09:10,740 --> 00:09:11,760
should just think of as meaning nothing

298
00:09:11,760 --> 00:09:13,500
is nothing happening basically so it's

299
00:09:13,500 --> 00:09:15,720
just drawn as a blank wire there's also

300
00:09:15,720 --> 00:09:17,459
a kind of identity object as it were

301
00:09:17,459 --> 00:09:19,740
called a unit object which is just empty

302
00:09:19,740 --> 00:09:21,240
space so you don't even draw the wire

303
00:09:21,240 --> 00:09:22,980
it's just this Dash box just means

304
00:09:22,980 --> 00:09:24,420
nothing it's going to be an empty

305
00:09:24,420 --> 00:09:25,380
picture

306
00:09:25,380 --> 00:09:27,300
and another thing is just useful because

307
00:09:27,300 --> 00:09:28,980
it now means we can talk about morphism

308
00:09:28,980 --> 00:09:30,540
which doesn't even have an input or an

309
00:09:30,540 --> 00:09:33,600
output more formula has this object I as

310
00:09:33,600 --> 00:09:35,519
it's input might not put and we give

311
00:09:35,519 --> 00:09:37,980
these things special names so the most

312
00:09:37,980 --> 00:09:39,360
important one probably is that of a

313
00:09:39,360 --> 00:09:41,100
state

314
00:09:41,100 --> 00:09:43,500
um which is a morphism with no input as

315
00:09:43,500 --> 00:09:45,540
it were already with input I so in the

316
00:09:45,540 --> 00:09:46,500
pictures it just looks like this so

317
00:09:46,500 --> 00:09:48,360
there's no y going in and you call this

318
00:09:48,360 --> 00:09:49,620
a state of a

319
00:09:49,620 --> 00:09:52,320
you can also have a process that takes

320
00:09:52,320 --> 00:09:54,360
in a if it has no output that you call

321
00:09:54,360 --> 00:09:56,220
an effect and if you have an eye you

322
00:09:56,220 --> 00:09:57,720
just call this a scalar so this is this

323
00:09:57,720 --> 00:09:58,680
is just going to be like a number

324
00:09:58,680 --> 00:10:00,899
basically floating around next to your

325
00:10:00,899 --> 00:10:03,200
diagram

326
00:10:03,480 --> 00:10:06,720
so there's there are many categories out

327
00:10:06,720 --> 00:10:08,040
there the point category is extremely

328
00:10:08,040 --> 00:10:09,300
General so this could be talking about

329
00:10:09,300 --> 00:10:11,279
computational processes or physical

330
00:10:11,279 --> 00:10:13,620
processes or Quantum processes in

331
00:10:13,620 --> 00:10:15,240
particular and all sorts of things but

332
00:10:15,240 --> 00:10:16,500
this talk will only actually need to do

333
00:10:16,500 --> 00:10:18,180
about one category we'll just keep it

334
00:10:18,180 --> 00:10:20,220
simple with this one that's the category

335
00:10:20,220 --> 00:10:22,800
I call it matar plus so it's positive

336
00:10:22,800 --> 00:10:24,600
three or matrices

337
00:10:24,600 --> 00:10:26,519
so you can just take objects so the

338
00:10:26,519 --> 00:10:28,860
wires to be finite sets and the more

339
00:10:28,860 --> 00:10:30,480
things that morphisms to be positive

340
00:10:30,480 --> 00:10:32,760
matrices indexed by these as I explained

341
00:10:32,760 --> 00:10:35,760
so if we draw a box like this m going

342
00:10:35,760 --> 00:10:37,200
from X to y

343
00:10:37,200 --> 00:10:39,720
this is like a matrix indexed by X and Y

344
00:10:39,720 --> 00:10:43,080
for each input in the cells of set X so

345
00:10:43,080 --> 00:10:45,660
in the set X and each output in y you

346
00:10:45,660 --> 00:10:47,760
get a positive real number and you and

347
00:10:47,760 --> 00:10:50,940
we'll write it like M of Y given X

348
00:10:50,940 --> 00:10:53,640
so this box would mean a function like

349
00:10:53,640 --> 00:10:55,320
this

350
00:10:55,320 --> 00:10:57,000
now when we plug them together they let

351
00:10:57,000 --> 00:10:57,839
us turn some things that you normally

352
00:10:57,839 --> 00:10:59,279
have to do with equations it's a kind of

353
00:10:59,279 --> 00:11:00,779
simpler pictures I mean mainly this

354
00:11:00,779 --> 00:11:03,300
middle one so if we have two in sequence

355
00:11:03,300 --> 00:11:05,180
we just compose them by matrix

356
00:11:05,180 --> 00:11:07,140
multiplication so instead of having to

357
00:11:07,140 --> 00:11:09,060
write this formula what we sum over y we

358
00:11:09,060 --> 00:11:10,200
can just draw this picture above it

359
00:11:10,200 --> 00:11:12,480
where we just float them on top

360
00:11:12,480 --> 00:11:13,980
and if we run them in parallel here we

361
00:11:13,980 --> 00:11:16,440
take the Cartesian product of the sets

362
00:11:16,440 --> 00:11:18,660
and the tensor product of the matrices

363
00:11:18,660 --> 00:11:19,920
as it were but it's just the obvious

364
00:11:19,920 --> 00:11:21,839
thing where you have two

365
00:11:21,839 --> 00:11:25,160
um things running independently

366
00:11:25,260 --> 00:11:27,839
so in particular a state here ends up

367
00:11:27,839 --> 00:11:30,360
the the minority unit is Singleton set

368
00:11:30,360 --> 00:11:31,740
and you can basically just ignore it so

369
00:11:31,740 --> 00:11:34,560
a state here amounts to just a function

370
00:11:34,560 --> 00:11:37,260
sending each X to a positive real and

371
00:11:37,260 --> 00:11:39,660
effect the same thing and a scalar would

372
00:11:39,660 --> 00:11:41,640
just be a positive real

373
00:11:41,640 --> 00:11:43,440
the intuition knows that we're going to

374
00:11:43,440 --> 00:11:45,899
restrict to the particular more business

375
00:11:45,899 --> 00:11:47,579
in here which are probabilistic in the

376
00:11:47,579 --> 00:11:49,200
nature so they need to send each X to

377
00:11:49,200 --> 00:11:51,660
actual distribution over y so I want to

378
00:11:51,660 --> 00:11:53,100
talk about how you actually pick those

379
00:11:53,100 --> 00:11:56,399
out next so to do that you use some

380
00:11:56,399 --> 00:11:57,899
extra structure that this category has

381
00:11:57,899 --> 00:11:59,940
it forms what's called a copy discard

382
00:11:59,940 --> 00:12:02,220
category so this is one more bit of

383
00:12:02,220 --> 00:12:03,959
mathematical sort of gadgets we have

384
00:12:03,959 --> 00:12:06,060
around so that is that each object comes

385
00:12:06,060 --> 00:12:07,740
with these distinguished processes it's

386
00:12:07,740 --> 00:12:09,959
one that we call copy that takes in a

387
00:12:09,959 --> 00:12:11,640
saying we've got two copies of a at the

388
00:12:11,640 --> 00:12:13,320
top and one called discard where you

389
00:12:13,320 --> 00:12:15,000
just throw a away so you have no output

390
00:12:15,000 --> 00:12:17,660
at the top

391
00:12:18,120 --> 00:12:20,579
um these satisfy some equations

392
00:12:20,579 --> 00:12:22,079
um that are quite intuitive if you think

393
00:12:22,079 --> 00:12:23,579
about like copying and then throwing

394
00:12:23,579 --> 00:12:24,839
away one of the outputs is the same as

395
00:12:24,839 --> 00:12:26,220
doing that thing so let's explain why

396
00:12:26,220 --> 00:12:28,920
I'm copying is symmetric and associative

397
00:12:28,920 --> 00:12:30,899
is the Earth One so in this category

398
00:12:30,899 --> 00:12:33,420
matter plus discard would be just the

399
00:12:33,420 --> 00:12:36,779
function sending each element to one

400
00:12:36,779 --> 00:12:38,760
and the copy would be like a Delta so a

401
00:12:38,760 --> 00:12:40,980
comes in and two copies of eight come

402
00:12:40,980 --> 00:12:43,860
out at the top is the intuition

403
00:12:43,860 --> 00:12:45,420
the reason we introduce this stuff is

404
00:12:45,420 --> 00:12:46,800
because it's been shown recently you can

405
00:12:46,800 --> 00:12:49,079
do a lot of probability Theory uh just

406
00:12:49,079 --> 00:12:50,820
in terms of these CD categories and

407
00:12:50,820 --> 00:12:52,500
particular ones called Markov category

408
00:12:52,500 --> 00:12:53,639
so there's a lot of what's going on in

409
00:12:53,639 --> 00:12:55,019
applied to category Theory at the moment

410
00:12:55,019 --> 00:12:57,120
it's using this language of CD

411
00:12:57,120 --> 00:12:58,139
categories

412
00:12:58,139 --> 00:12:59,420
foreign

413
00:12:59,420 --> 00:13:01,440
let me pick out some things to do with

414
00:13:01,440 --> 00:13:03,420
probability Theory I'll just talk about

415
00:13:03,420 --> 00:13:04,680
a couple of them here the most important

416
00:13:04,680 --> 00:13:06,420
one is the notion of a channel

417
00:13:06,420 --> 00:13:08,160
so this is what lets us pick out the

418
00:13:08,160 --> 00:13:10,260
actual normalized uh matrices as it were

419
00:13:10,260 --> 00:13:11,459
from earlier

420
00:13:11,459 --> 00:13:13,380
so in general you call a more business

421
00:13:13,380 --> 00:13:14,760
Channel when it preserves it's

422
00:13:14,760 --> 00:13:15,959
discarding

423
00:13:15,959 --> 00:13:18,540
and a special case is a state in which

424
00:13:18,540 --> 00:13:21,180
it's a channel you call it normalized so

425
00:13:21,180 --> 00:13:22,380
for a state this means it would actually

426
00:13:22,380 --> 00:13:24,180
be a probability distribution so it's

427
00:13:24,180 --> 00:13:25,740
actually normalized if you sum over the

428
00:13:25,740 --> 00:13:27,420
values with this Omega you'll get one

429
00:13:27,420 --> 00:13:29,700
and for for a morphism being a channel

430
00:13:29,700 --> 00:13:31,620
it means it sends each input to a

431
00:13:31,620 --> 00:13:33,300
distribution so it actually is a

432
00:13:33,300 --> 00:13:35,399
probability channel in a usual sense

433
00:13:35,399 --> 00:13:37,800
uh equivalently The Matrix for f would

434
00:13:37,800 --> 00:13:39,000
be stochastic

435
00:13:39,000 --> 00:13:40,680
so these are the ones who would use in

436
00:13:40,680 --> 00:13:43,819
generative models for example

437
00:13:44,279 --> 00:13:46,079
and this as I said Associated

438
00:13:46,079 --> 00:13:47,399
probability for you can describe these

439
00:13:47,399 --> 00:13:49,320
with these diagrams it's very two simple

440
00:13:49,320 --> 00:13:50,760
examples you can describe

441
00:13:50,760 --> 00:13:52,620
marginalization in probability Theory

442
00:13:52,620 --> 00:13:54,060
with this discarding thing so if you

443
00:13:54,060 --> 00:13:55,920
have box Omega like this it would be a

444
00:13:55,920 --> 00:13:57,600
joint distribution over X and Y if you

445
00:13:57,600 --> 00:13:59,100
just describe y you'll get the marginal

446
00:13:59,100 --> 00:14:00,180
on x

447
00:14:00,180 --> 00:14:02,399
and if you plug uh Omega a distribution

448
00:14:02,399 --> 00:14:04,800
on X into an effect that would just be

449
00:14:04,800 --> 00:14:07,139
any function on X this would be giving

450
00:14:07,139 --> 00:14:08,399
you a scalar now and that would be the

451
00:14:08,399 --> 00:14:10,260
expectation value of the in this

452
00:14:10,260 --> 00:14:12,180
distribution

453
00:14:12,180 --> 00:14:14,459
so I'll meet lots more of this as we go

454
00:14:14,459 --> 00:14:15,600
but let's actually start doing some

455
00:14:15,600 --> 00:14:17,220
stuff uh rated active inference in

456
00:14:17,220 --> 00:14:18,360
particular now so I want to talk about

457
00:14:18,360 --> 00:14:20,519
generative models and how you view these

458
00:14:20,519 --> 00:14:21,959
in the diagrams

459
00:14:21,959 --> 00:14:23,760
so as we've said uh we're going to talk

460
00:14:23,760 --> 00:14:25,920
about agents having different models

461
00:14:25,920 --> 00:14:27,360
that relate things like actions

462
00:14:27,360 --> 00:14:30,000
observations and World States

463
00:14:30,000 --> 00:14:31,260
and these are normally quite

464
00:14:31,260 --> 00:14:32,700
compositional and active infants right

465
00:14:32,700 --> 00:14:34,560
and it might involve many different

466
00:14:34,560 --> 00:14:37,139
spaces of states and observations and

467
00:14:37,139 --> 00:14:38,880
these processes relating them and you

468
00:14:38,880 --> 00:14:39,839
usually treat these with something like

469
00:14:39,839 --> 00:14:41,339
evasion Network

470
00:14:41,339 --> 00:14:42,660
um claiming you can view it really as a

471
00:14:42,660 --> 00:14:44,100
causal version Network because it's sort

472
00:14:44,100 --> 00:14:46,019
of describing how states are causing

473
00:14:46,019 --> 00:14:48,060
these observations

474
00:14:48,060 --> 00:14:49,620
um performing it's the same thing so

475
00:14:49,620 --> 00:14:51,839
spatial Network which you could normally

476
00:14:51,839 --> 00:14:53,279
say a subscriber something like a dag

477
00:14:53,279 --> 00:14:55,079
the director is like a graph

478
00:14:55,079 --> 00:14:57,060
which describe the different variables

479
00:14:57,060 --> 00:14:59,100
that are being related and then sets of

480
00:14:59,100 --> 00:15:00,779
values for each and probability channels

481
00:15:00,779 --> 00:15:02,820
described in each one in terms of its

482
00:15:02,820 --> 00:15:04,920
parents in the dag and then you often

483
00:15:04,920 --> 00:15:06,180
look at this whole distribution over

484
00:15:06,180 --> 00:15:07,980
over all the variables

485
00:15:07,980 --> 00:15:10,139
but already I'd say the way that these

486
00:15:10,139 --> 00:15:12,240
uh data networks are drawn in active

487
00:15:12,240 --> 00:15:13,560
infants text and stuff is kind of

488
00:15:13,560 --> 00:15:15,060
converging on something a bit closer to

489
00:15:15,060 --> 00:15:16,260
string diagrams because you don't

490
00:15:16,260 --> 00:15:17,519
actually

491
00:15:17,519 --> 00:15:19,260
um just draw the Diagon the variables

492
00:15:19,260 --> 00:15:20,880
it's very useful to actually give names

493
00:15:20,880 --> 00:15:23,339
to the mechanisms themselves as it were

494
00:15:23,339 --> 00:15:24,779
like you have in this picture the A and

495
00:15:24,779 --> 00:15:26,519
the B's

496
00:15:26,519 --> 00:15:27,899
um so yeah my claim is sort of

497
00:15:27,899 --> 00:15:29,820
converging on the way that string

498
00:15:29,820 --> 00:15:31,560
diagrams will look as we'll see on the

499
00:15:31,560 --> 00:15:32,760
next slide which is where you really do

500
00:15:32,760 --> 00:15:34,620
label everything

501
00:15:34,620 --> 00:15:37,380
um not just the the variables

502
00:15:37,380 --> 00:15:40,019
so to describe those sort of Bayesian

503
00:15:40,019 --> 00:15:41,579
networks with string diagrams the key

504
00:15:41,579 --> 00:15:42,959
observation is really that dags

505
00:15:42,959 --> 00:15:44,399
correspond to a certain class extreme

506
00:15:44,399 --> 00:15:46,139
diagrams that we'll call Network

507
00:15:46,139 --> 00:15:48,480
diagrams

508
00:15:48,480 --> 00:15:49,800
um there's a definition here but we're

509
00:15:49,800 --> 00:15:51,300
just better just to see an example in a

510
00:15:51,300 --> 00:15:53,279
second but the diagrams built from

511
00:15:53,279 --> 00:15:55,740
copying and sometimes discarding and the

512
00:15:55,740 --> 00:15:56,820
key thing is just that they only have

513
00:15:56,820 --> 00:15:59,699
processes with maybe many inputs but

514
00:15:59,699 --> 00:16:01,800
only one output

515
00:16:01,800 --> 00:16:03,480
so this is going to be like a mechanism

516
00:16:03,480 --> 00:16:05,940
that produces each variable

517
00:16:05,940 --> 00:16:08,040
so the result is that if you have a dag

518
00:16:08,040 --> 00:16:10,199
G and you choose some of the the

519
00:16:10,199 --> 00:16:12,180
vertices to the outputs so there's like

520
00:16:12,180 --> 00:16:14,459
The observed variables you can draw a

521
00:16:14,459 --> 00:16:16,260
network diagram which expresses the same

522
00:16:16,260 --> 00:16:17,940
equivalent structure with those things

523
00:16:17,940 --> 00:16:20,579
as the outputs so here's an example we

524
00:16:20,579 --> 00:16:22,320
have a dag with these four variables X1

525
00:16:22,320 --> 00:16:23,639
to X4

526
00:16:23,639 --> 00:16:26,220
and what you do is you have a wire for

527
00:16:26,220 --> 00:16:28,199
each variable in your diagram on the

528
00:16:28,199 --> 00:16:29,100
right

529
00:16:29,100 --> 00:16:30,899
and you draw a box that produces it

530
00:16:30,899 --> 00:16:32,100
doesn't really matter what you label the

531
00:16:32,100 --> 00:16:33,720
Box

532
00:16:33,720 --> 00:16:34,380
um

533
00:16:34,380 --> 00:16:36,540
so with this box C for example which

534
00:16:36,540 --> 00:16:38,399
uses X2 and you'll produce it in terms

535
00:16:38,399 --> 00:16:41,339
of its parents in the dag so X1 and X4

536
00:16:41,339 --> 00:16:42,660
in this case and if it doesn't have any

537
00:16:42,660 --> 00:16:44,399
parents it would just be a state as it

538
00:16:44,399 --> 00:16:46,380
work box or no input

539
00:16:46,380 --> 00:16:48,000
and then what you do is you take each

540
00:16:48,000 --> 00:16:49,560
row or you copy it and you pass it

541
00:16:49,560 --> 00:16:52,139
toward its children in the dag and also

542
00:16:52,139 --> 00:16:54,120
out of the diagram if it's an output so

543
00:16:54,120 --> 00:16:55,560
this now means you've sort of expressed

544
00:16:55,560 --> 00:16:57,000
the whole structure of the of the day

545
00:16:57,000 --> 00:16:58,860
and also which variables are sort of

546
00:16:58,860 --> 00:17:02,279
leaving the system the output ones

547
00:17:02,279 --> 00:17:04,439
so this allows us to turn dag into a

548
00:17:04,439 --> 00:17:06,119
string diagram and then if you want to

549
00:17:06,119 --> 00:17:07,559
make a generative model like that

550
00:17:07,559 --> 00:17:09,359
expresses the you know like a baby

551
00:17:09,359 --> 00:17:11,160
Network that's structurally go into this

552
00:17:11,160 --> 00:17:13,319
dag you just have to now interpret this

553
00:17:13,319 --> 00:17:16,500
diagram in a certain sense so in general

554
00:17:16,500 --> 00:17:18,179
working in any one of these CD

555
00:17:18,179 --> 00:17:19,679
categories there's copy discard

556
00:17:19,679 --> 00:17:21,959
categories we can say that a generative

557
00:17:21,959 --> 00:17:23,699
model in there is given by one of these

558
00:17:23,699 --> 00:17:26,339
Network diagrams without any inputs

559
00:17:26,339 --> 00:17:28,020
and an interpretation of the diagram

560
00:17:28,020 --> 00:17:29,580
meaning you actually say what the

561
00:17:29,580 --> 00:17:31,260
objects are for each of the wires in the

562
00:17:31,260 --> 00:17:33,360
diagram and what the actual channels are

563
00:17:33,360 --> 00:17:34,500
so they need to be channels not just

564
00:17:34,500 --> 00:17:35,700
morphisms

565
00:17:35,700 --> 00:17:37,559
um in your category are for each of the

566
00:17:37,559 --> 00:17:40,320
boxes so for a gender model like this

567
00:17:40,320 --> 00:17:43,440
you would say you pick objects X1 x64

568
00:17:43,440 --> 00:17:46,260
and pick channels for the ABCD

569
00:17:46,260 --> 00:17:48,720
and we'll think of the outputs of the

570
00:17:48,720 --> 00:17:50,039
diagrams like The Observer variables and

571
00:17:50,039 --> 00:17:51,559
the rest of the Hidden ones

572
00:17:51,559 --> 00:17:54,780
so for example if you're working in this

573
00:17:54,780 --> 00:17:56,340
category matter Plus

574
00:17:56,340 --> 00:17:57,900
that is there any category I've actually

575
00:17:57,900 --> 00:17:59,160
introduced here so this is going to be a

576
00:17:59,160 --> 00:18:00,780
running example this is the same thing

577
00:18:00,780 --> 00:18:02,520
as one of these cause evasion networks

578
00:18:02,520 --> 00:18:04,020
so it just means picking sets of values

579
00:18:04,020 --> 00:18:05,700
for variables and picking property

580
00:18:05,700 --> 00:18:09,419
channels for the boxes

581
00:18:09,419 --> 00:18:11,280
um so you might ask why would you use

582
00:18:11,280 --> 00:18:12,539
this representation rather than the

583
00:18:12,539 --> 00:18:13,799
usual one I think it's a good question

584
00:18:13,799 --> 00:18:17,280
so it's equivalent to the the DAC

585
00:18:17,280 --> 00:18:19,919
um and probability Channel description

586
00:18:19,919 --> 00:18:22,020
um but the thing that's nice is that in

587
00:18:22,020 --> 00:18:23,400
the conventional approach these networks

588
00:18:23,400 --> 00:18:25,080
you sort of have to switch between the

589
00:18:25,080 --> 00:18:26,700
dags which is for the variables and then

590
00:18:26,700 --> 00:18:29,340
doing calculations with probabilities

591
00:18:29,340 --> 00:18:32,160
whereas and the categorical approach you

592
00:18:32,160 --> 00:18:33,539
can use just one formalism because you

593
00:18:33,539 --> 00:18:34,980
can do probability Theory with a string

594
00:18:34,980 --> 00:18:36,480
diagrams as well so it's quite natural

595
00:18:36,480 --> 00:18:37,980
in that sense you have this one language

596
00:18:37,980 --> 00:18:39,900
that both just intuitively drawing

597
00:18:39,900 --> 00:18:41,220
what's going on in a model and then

598
00:18:41,220 --> 00:18:42,720
reasoning about it

599
00:18:42,720 --> 00:18:44,640
it also lets you start to generalize

600
00:18:44,640 --> 00:18:47,220
things in a useful way I think so we I

601
00:18:47,220 --> 00:18:48,960
kept having to say that you have no

602
00:18:48,960 --> 00:18:50,400
inputs to your diagram but there's

603
00:18:50,400 --> 00:18:52,200
nothing really fundamental about that

604
00:18:52,200 --> 00:18:53,460
one it's not really clear why we need

605
00:18:53,460 --> 00:18:55,559
that so what we what you can do instead

606
00:18:55,559 --> 00:18:57,179
is start to allow inputs to your model

607
00:18:57,179 --> 00:18:59,940
as well so we'll

608
00:18:59,940 --> 00:19:02,640
um call this an open generated model so

609
00:19:02,640 --> 00:19:04,200
an open generative model

610
00:19:04,200 --> 00:19:06,299
is the same thing but now just drop this

611
00:19:06,299 --> 00:19:07,799
requirement the diagram doesn't have any

612
00:19:07,799 --> 00:19:09,059
inputs

613
00:19:09,059 --> 00:19:10,679
so here's an example of a general

614
00:19:10,679 --> 00:19:12,539
Network diagram now with these inputs

615
00:19:12,539 --> 00:19:15,000
x2x3 so there's no mechanism specified

616
00:19:15,000 --> 00:19:16,740
for these new variables X2 X3 they're

617
00:19:16,740 --> 00:19:18,900
just input variables to the system

618
00:19:18,900 --> 00:19:20,460
and they can be outputs as well for

619
00:19:20,460 --> 00:19:22,320
example X3 is broken input and an output

620
00:19:22,320 --> 00:19:24,660
here and again an interpretation of this

621
00:19:24,660 --> 00:19:25,919
General Network diagram this means

622
00:19:25,919 --> 00:19:28,380
picking the objects and the channels

623
00:19:28,380 --> 00:19:30,120
and this is the same definition we use

624
00:19:30,120 --> 00:19:31,620
to define what we call an open cause a

625
00:19:31,620 --> 00:19:33,840
model in in the paper with Robin Lorenz

626
00:19:33,840 --> 00:19:36,419
that I mentioned earlier so enabled

627
00:19:36,419 --> 00:19:37,679
generative model is formally just the

628
00:19:37,679 --> 00:19:39,660
same thing but we're just thinking of it

629
00:19:39,660 --> 00:19:41,880
as a generative model possessed by a

630
00:19:41,880 --> 00:19:43,740
cognitive agent

631
00:19:43,740 --> 00:19:45,600
if you run the definition in math.plus

632
00:19:45,600 --> 00:19:47,280
then this is just like it goes on laser

633
00:19:47,280 --> 00:19:48,419
Network and now you have some of your

634
00:19:48,419 --> 00:19:49,799
variables just have no mechanisms

635
00:19:49,799 --> 00:19:51,720
specifies so they're just inputs to the

636
00:19:51,720 --> 00:19:53,940
whole thing

637
00:19:53,940 --> 00:19:54,960
um a nice thing about these open

638
00:19:54,960 --> 00:19:56,760
generative models is that because they

639
00:19:56,760 --> 00:19:58,080
can have these inputs you can plug them

640
00:19:58,080 --> 00:20:00,539
together and compose them and these

641
00:20:00,539 --> 00:20:01,860
things in fact form their own category

642
00:20:01,860 --> 00:20:04,939
but I won't go into that today

643
00:20:05,520 --> 00:20:07,020
um so that was the general theory of

644
00:20:07,020 --> 00:20:08,340
these generative models that just

645
00:20:08,340 --> 00:20:09,840
actually describe some examples that

646
00:20:09,840 --> 00:20:11,220
you'll you'll see in active inference

647
00:20:11,220 --> 00:20:12,960
coming up all the time

648
00:20:12,960 --> 00:20:15,120
so it's a simple example let's just

649
00:20:15,120 --> 00:20:16,440
imagine we have one space of hidden

650
00:20:16,440 --> 00:20:18,059
States and one space of observations

651
00:20:18,059 --> 00:20:20,280
then it would be a generative model that

652
00:20:20,280 --> 00:20:21,539
form which is that like this network

653
00:20:21,539 --> 00:20:24,419
diagram where it's just two wires

654
00:20:24,419 --> 00:20:26,460
there's just Sno

655
00:20:26,460 --> 00:20:28,260
um s doesn't have any parents so it just

656
00:20:28,260 --> 00:20:29,940
has this prior distribution Sigma over

657
00:20:29,940 --> 00:20:31,740
it and it's just this one channel

658
00:20:31,740 --> 00:20:34,320
often called the likelihood from s to O

659
00:20:34,320 --> 00:20:35,880
if you just draw that Network diagram

660
00:20:35,880 --> 00:20:38,700
and say that that model in in C that or

661
00:20:38,700 --> 00:20:40,440
in Mata plus it would be the same as

662
00:20:40,440 --> 00:20:41,880
it's one of these simple generative

663
00:20:41,880 --> 00:20:43,620
models when you're looking at these

664
00:20:43,620 --> 00:20:45,840
you're often introduced interested in

665
00:20:45,840 --> 00:20:47,460
this distribution over both variables

666
00:20:47,460 --> 00:20:49,140
together this joint distribution that

667
00:20:49,140 --> 00:20:51,539
you might write as you know P of s times

668
00:20:51,539 --> 00:20:54,000
P of O given s normally or a bit more

669
00:20:54,000 --> 00:20:55,200
specifically here introducing their

670
00:20:55,200 --> 00:20:57,299
names for the two distribution in the

671
00:20:57,299 --> 00:20:58,260
channel here

672
00:20:58,260 --> 00:21:00,000
and string diagrams is just the same as

673
00:21:00,000 --> 00:21:02,280
this so you just take the prior and you

674
00:21:02,280 --> 00:21:04,020
make it an output now and then you

675
00:21:04,020 --> 00:21:06,179
compose those channels together and this

676
00:21:06,179 --> 00:21:07,860
would give you a distribution so a

677
00:21:07,860 --> 00:21:10,320
normalized state m

678
00:21:10,320 --> 00:21:12,840
um over Sno at this so this is just the

679
00:21:12,840 --> 00:21:14,940
resulting joint distribution you get

680
00:21:14,940 --> 00:21:16,260
from the generator model and we'll come

681
00:21:16,260 --> 00:21:18,860
back to that later

682
00:21:19,260 --> 00:21:21,120
um so a more

683
00:21:21,120 --> 00:21:22,799
elaborate example of generative model

684
00:21:22,799 --> 00:21:24,660
that you'll see for example in the

685
00:21:24,660 --> 00:21:26,400
active infants textbook are these

686
00:21:26,400 --> 00:21:27,960
discrete time models that are used a lot

687
00:21:27,960 --> 00:21:31,200
so I'll walk through this diagram now so

688
00:21:31,200 --> 00:21:33,120
this is an example of a more complex

689
00:21:33,120 --> 00:21:34,980
Network diagram and a generative model

690
00:21:34,980 --> 00:21:38,039
it describes so here we've got these n

691
00:21:38,039 --> 00:21:40,559
time steps going uh remember we read

692
00:21:40,559 --> 00:21:42,000
from bottom to top but I'll just talk

693
00:21:42,000 --> 00:21:44,340
about the I'll describe things from the

694
00:21:44,340 --> 00:21:45,659
top down here so the top we have the

695
00:21:45,659 --> 00:21:48,179
observations o102 up to om

696
00:21:48,179 --> 00:21:50,460
the observations at each time being

697
00:21:50,460 --> 00:21:52,679
caused by these hidden States S1 S2 and

698
00:21:52,679 --> 00:21:56,820
SN at each time by these channels a

699
00:21:56,820 --> 00:21:57,480
um

700
00:21:57,480 --> 00:21:59,159
and the hidden state is evolving over

701
00:21:59,159 --> 00:22:01,020
time by this transition Channel B where

702
00:22:01,020 --> 00:22:03,299
it takes the previous state as an input

703
00:22:03,299 --> 00:22:05,400
and then choose the next one it also

704
00:22:05,400 --> 00:22:07,320
takes us one extra wires on the bottom

705
00:22:07,320 --> 00:22:09,419
and that's the space p of policies which

706
00:22:09,419 --> 00:22:11,520
is how the agent sort of actions enter

707
00:22:11,520 --> 00:22:13,559
the pictures these policies describe its

708
00:22:13,559 --> 00:22:16,320
behaviors its behavioral policies it can

709
00:22:16,320 --> 00:22:18,059
carry out so based on the previous

710
00:22:18,059 --> 00:22:20,520
interstate and the way it's acting this

711
00:22:20,520 --> 00:22:22,260
channel B would determine the

712
00:22:22,260 --> 00:22:24,419
probabilities for the next States

713
00:22:24,419 --> 00:22:26,820
and then there's a prior over

714
00:22:26,820 --> 00:22:28,380
um the policies that you can think of as

715
00:22:28,380 --> 00:22:30,299
a habits or the typical behaviors of the

716
00:22:30,299 --> 00:22:31,500
system

717
00:22:31,500 --> 00:22:32,760
so you can just draw this diagram and

718
00:22:32,760 --> 00:22:35,100
say like interpret this in Mata plus and

719
00:22:35,100 --> 00:22:36,539
that would for any given interpretation

720
00:22:36,539 --> 00:22:38,940
meaning any choice of what the values

721
00:22:38,940 --> 00:22:41,100
for these variables can possibly take

722
00:22:41,100 --> 00:22:42,720
are and any choice of what these

723
00:22:42,720 --> 00:22:44,760
channels are but then give you this this

724
00:22:44,760 --> 00:22:48,120
type of primitive model

725
00:22:48,120 --> 00:22:49,980
and

726
00:22:49,980 --> 00:22:51,600
um often you will see models sort of at

727
00:22:51,600 --> 00:22:53,340
this form or similar forms being plugged

728
00:22:53,340 --> 00:22:54,960
together from these hierarchical models

729
00:22:54,960 --> 00:22:56,820
and I think the compositional language

730
00:22:56,820 --> 00:22:58,140
is very nice for these because you

731
00:22:58,140 --> 00:22:59,520
really want to talk about open models to

732
00:22:59,520 --> 00:23:02,100
Define this so hierarchical model you

733
00:23:02,100 --> 00:23:03,900
can view as really as just being given

734
00:23:03,900 --> 00:23:05,340
by taking us to these open genitive

735
00:23:05,340 --> 00:23:06,960
models I mentioned and plugging them

736
00:23:06,960 --> 00:23:09,360
together in a certain sense so here you

737
00:23:09,360 --> 00:23:10,679
can see a picture of a hierarchical

738
00:23:10,679 --> 00:23:12,179
model where we just have these layers

739
00:23:12,179 --> 00:23:14,400
where different copies of the same model

740
00:23:14,400 --> 00:23:17,100
at each layer and the inputs from one

741
00:23:17,100 --> 00:23:18,360
layer match the output to the layer

742
00:23:18,360 --> 00:23:21,780
below so we can compose them together

743
00:23:21,780 --> 00:23:23,880
first generative models

744
00:23:23,880 --> 00:23:25,380
um so so far we've just been using the

745
00:23:25,380 --> 00:23:26,940
diagrams to represent them we'd like to

746
00:23:26,940 --> 00:23:28,200
actually do a bit more their own reason

747
00:23:28,200 --> 00:23:30,000
about these models and particularly talk

748
00:23:30,000 --> 00:23:32,400
about how you update a model or update

749
00:23:32,400 --> 00:23:35,280
the beliefs within a model

750
00:23:35,280 --> 00:23:36,360
um which is very important in active

751
00:23:36,360 --> 00:23:37,980
inference and how this looks in the in

752
00:23:37,980 --> 00:23:41,059
the string diagrams now

753
00:23:41,280 --> 00:23:44,460
so let's say we've got an agent M we

754
00:23:44,460 --> 00:23:45,960
have a model m

755
00:23:45,960 --> 00:23:48,360
and it's just the simple one where we

756
00:23:48,360 --> 00:23:49,679
say there's just one space of hidden

757
00:23:49,679 --> 00:23:51,600
States s and one space observations o so

758
00:23:51,600 --> 00:23:53,400
they have this joint distribution that I

759
00:23:53,400 --> 00:23:54,720
mentioned earlier

760
00:23:54,720 --> 00:23:56,640
and they have these prior beliefs about

761
00:23:56,640 --> 00:23:58,740
s which you can get back from the joint

762
00:23:58,740 --> 00:24:00,000
distribution by it's taking the marginal

763
00:24:00,000 --> 00:24:01,980
if you like so that's a signal so we've

764
00:24:01,980 --> 00:24:02,940
got their model they've got their

765
00:24:02,940 --> 00:24:04,860
beliefs about what states are likely and

766
00:24:04,860 --> 00:24:07,380
then they receive a new observation and

767
00:24:07,380 --> 00:24:08,520
here the kind of observations we'll

768
00:24:08,520 --> 00:24:09,720
think about in general can be soft

769
00:24:09,720 --> 00:24:11,520
meaning they're described by a

770
00:24:11,520 --> 00:24:13,740
distribution over not necessarily just

771
00:24:13,740 --> 00:24:15,360
one element

772
00:24:15,360 --> 00:24:18,000
so that would be one of these normalized

773
00:24:18,000 --> 00:24:20,580
um States but we'll try not to use the

774
00:24:20,580 --> 00:24:21,360
word State here because it's a bit

775
00:24:21,360 --> 00:24:23,100
confusing with this s around so this

776
00:24:23,100 --> 00:24:25,559
distribution over o

777
00:24:25,559 --> 00:24:27,480
is then your observation this bold font

778
00:24:27,480 --> 00:24:28,320
o

779
00:24:28,320 --> 00:24:30,960
another one update the margin they want

780
00:24:30,960 --> 00:24:32,580
to update m in some ways so that the

781
00:24:32,580 --> 00:24:34,260
marginal basically is

782
00:24:34,260 --> 00:24:35,760
different and describes the updated

783
00:24:35,760 --> 00:24:38,340
posterior beliefs and this comes up of

784
00:24:38,340 --> 00:24:40,559
course in perception where you're

785
00:24:40,559 --> 00:24:42,780
completing your sort of state of the

786
00:24:42,780 --> 00:24:44,340
world given to Observation you receive

787
00:24:44,340 --> 00:24:45,600
they could also be used to model like

788
00:24:45,600 --> 00:24:48,000
planning Behavior where updating your

789
00:24:48,000 --> 00:24:50,640
plan of action your policy uh given

790
00:24:50,640 --> 00:24:53,400
something like which outcomes you'd like

791
00:24:53,400 --> 00:24:55,080
to see in the future

792
00:24:55,080 --> 00:24:57,059
and we'll come back to that later in the

793
00:24:57,059 --> 00:24:58,320
talk

794
00:24:58,320 --> 00:25:00,539
so we want to talk about how you can do

795
00:25:00,539 --> 00:25:02,220
this updating

796
00:25:02,220 --> 00:25:03,960
so you might think there's just a

797
00:25:03,960 --> 00:25:05,400
standard answer or at least in the ideal

798
00:25:05,400 --> 00:25:07,200
case which is this Bayesian updating and

799
00:25:07,200 --> 00:25:08,580
that's true when your observations are

800
00:25:08,580 --> 00:25:10,080
sharp and we'll start by talking about

801
00:25:10,080 --> 00:25:12,299
that case so I'll see what sharp means

802
00:25:12,299 --> 00:25:14,100
in a second but first we'll just talk

803
00:25:14,100 --> 00:25:15,059
about how you treat Bayesian

804
00:25:15,059 --> 00:25:17,460
conditioning in these string diagrams so

805
00:25:17,460 --> 00:25:20,700
on the right here we have uh if you do

806
00:25:20,700 --> 00:25:23,220
this process from o to S this describes

807
00:25:23,220 --> 00:25:25,200
the sort of Bayesian conditional

808
00:25:25,200 --> 00:25:27,120
a Channel or in general the partial

809
00:25:27,120 --> 00:25:28,679
Channel impact

810
00:25:28,679 --> 00:25:30,360
um that the agent would have

811
00:25:30,360 --> 00:25:32,159
from the introduced by their model so

812
00:25:32,159 --> 00:25:34,320
you can describe this in string diagrams

813
00:25:34,320 --> 00:25:36,120
with a couple of extra gadgets I hadn't

814
00:25:36,120 --> 00:25:37,200
mentioned yet

815
00:25:37,200 --> 00:25:40,020
so you have your distribution M over Sno

816
00:25:40,020 --> 00:25:42,240
you can have this a mapper plus there's

817
00:25:42,240 --> 00:25:43,980
this effect that we call the cat which

818
00:25:43,980 --> 00:25:46,200
is just takes two inputs and Compares if

819
00:25:46,200 --> 00:25:48,000
they're equal and as allows for you to

820
00:25:48,000 --> 00:25:49,620
turn an output into an input so that's

821
00:25:49,620 --> 00:25:51,360
what this part here is

822
00:25:51,360 --> 00:25:52,919
and then you can introduce this extra

823
00:25:52,919 --> 00:25:54,960
thing of normalization so what you'd

824
00:25:54,960 --> 00:25:56,279
like to do is

825
00:25:56,279 --> 00:25:58,679
take a general morphism and for each

826
00:25:58,679 --> 00:26:01,260
possible input normalized factor that

827
00:26:01,260 --> 00:26:03,179
it's a distribution if you can or set it

828
00:26:03,179 --> 00:26:04,559
to zero if it's just zero and there's

829
00:26:04,559 --> 00:26:06,539
nothing you can do that's what this blue

830
00:26:06,539 --> 00:26:08,520
dash box is

831
00:26:08,520 --> 00:26:10,320
um and in the paper and in the in the

832
00:26:10,320 --> 00:26:11,700
related course and models paper we talk

833
00:26:11,700 --> 00:26:13,380
about the the axioms normalization

834
00:26:13,380 --> 00:26:15,120
feature satisfies

835
00:26:15,120 --> 00:26:16,919
and the point is if you compute this

836
00:26:16,919 --> 00:26:18,659
thing in Mata plus it will give you kind

837
00:26:18,659 --> 00:26:20,820
of what you'd expect so it'll give you

838
00:26:20,820 --> 00:26:24,200
the usual notion for each

839
00:26:24,860 --> 00:26:27,299
you plug it into this you'll get a kind

840
00:26:27,299 --> 00:26:30,900
of conditional M of s given o that you'd

841
00:26:30,900 --> 00:26:33,059
expect whenever that's defined

842
00:26:33,059 --> 00:26:35,039
there's a string diagram way to describe

843
00:26:35,039 --> 00:26:37,140
this kind of Bayesian conditional

844
00:26:37,140 --> 00:26:39,840
Channel or partial Channel

845
00:26:39,840 --> 00:26:41,340
and I said this is what you would use

846
00:26:41,340 --> 00:26:43,380
when your observation is sharp and I I

847
00:26:43,380 --> 00:26:44,640
also drew it definitely with this

848
00:26:44,640 --> 00:26:46,080
triangle to sort of distinguish that

849
00:26:46,080 --> 00:26:48,059
case so what does that mean so in

850
00:26:48,059 --> 00:26:50,460
general you say that a a state in one of

851
00:26:50,460 --> 00:26:52,080
these CD categories

852
00:26:52,080 --> 00:26:54,120
um so a distribution basically would be

853
00:26:54,120 --> 00:26:56,400
sharp when it's copied by copy map which

854
00:26:56,400 --> 00:26:58,740
isn't true for General distributions

855
00:26:58,740 --> 00:27:01,440
and if you run this definition in method

856
00:27:01,440 --> 00:27:03,419
plus this really means that this thing

857
00:27:03,419 --> 00:27:05,400
already is just point distribution at

858
00:27:05,400 --> 00:27:08,100
some specific element of O so you know

859
00:27:08,100 --> 00:27:09,480
it really is sharp in that sense it's

860
00:27:09,480 --> 00:27:11,520
just a point there's no real

861
00:27:11,520 --> 00:27:14,159
probabilities yeah probabilistic aspects

862
00:27:14,159 --> 00:27:15,480
to it there

863
00:27:15,480 --> 00:27:17,880
in any CP category you can just talk

864
00:27:17,880 --> 00:27:19,320
about the sharp States like this they're

865
00:27:19,320 --> 00:27:22,080
often also called deterministic

866
00:27:22,080 --> 00:27:23,820
so for these sharp ones you know you

867
00:27:23,820 --> 00:27:25,020
ideally think you'd like to do this

868
00:27:25,020 --> 00:27:27,179
patient updating but in fact when you've

869
00:27:27,179 --> 00:27:28,500
got soft ones so it doesn't have this

870
00:27:28,500 --> 00:27:30,779
property uh there's actually two at

871
00:27:30,779 --> 00:27:32,220
least two good ways to do this kind of

872
00:27:32,220 --> 00:27:34,320
updating I don't know if this is as well

873
00:27:34,320 --> 00:27:36,539
known so I'll just mention it um now

874
00:27:36,539 --> 00:27:37,860
anyway and they've been studied in some

875
00:27:37,860 --> 00:27:39,720
detail by Bart Jacobs this paper at the

876
00:27:39,720 --> 00:27:41,159
bottom

877
00:27:41,159 --> 00:27:42,600
so let's say you don't get one of these

878
00:27:42,600 --> 00:27:44,460
sharp observations you have just a

879
00:27:44,460 --> 00:27:47,100
distribution over o there's these two

880
00:27:47,100 --> 00:27:48,659
reasonable ways to generalize sort of

881
00:27:48,659 --> 00:27:50,039
the picture from the last slide to give

882
00:27:50,039 --> 00:27:52,500
a notion of updating and yeah because on

883
00:27:52,500 --> 00:27:55,200
Jeffries and Pearls update rules

884
00:27:55,200 --> 00:27:58,440
so in Jeffrey's update you basically do

885
00:27:58,440 --> 00:28:00,179
it like we did before you you have this

886
00:28:00,179 --> 00:28:02,700
Asian conditional kind of Channel or

887
00:28:02,700 --> 00:28:04,559
partial channel the normalized boxer and

888
00:28:04,559 --> 00:28:05,940
you just plug the distribution into it

889
00:28:05,940 --> 00:28:09,000
other than Pals update you turn a

890
00:28:09,000 --> 00:28:10,440
distribution into an effect so you just

891
00:28:10,440 --> 00:28:11,940
compose it with this cap to bend it

892
00:28:11,940 --> 00:28:13,080
around in the picture that's what it

893
00:28:13,080 --> 00:28:14,039
means

894
00:28:14,039 --> 00:28:16,020
so you plug that into M and then

895
00:28:16,020 --> 00:28:17,340
normalize everything so the difference

896
00:28:17,340 --> 00:28:19,260
is where the normalization

897
00:28:19,260 --> 00:28:21,419
happens and yes it's basically just

898
00:28:21,419 --> 00:28:22,740
interesting that both of these are

899
00:28:22,740 --> 00:28:24,179
reasonable Notions generalization they

900
00:28:24,179 --> 00:28:25,620
have different properties it's not

901
00:28:25,620 --> 00:28:26,880
obvious that one of them is sort of more

902
00:28:26,880 --> 00:28:28,260
rational or something than the other

903
00:28:28,260 --> 00:28:31,919
they just behave a bit differently

904
00:28:31,919 --> 00:28:34,320
um in the formula you can see that the

905
00:28:34,320 --> 00:28:36,000
normalization is being applied

906
00:28:36,000 --> 00:28:37,320
definitely so if you turn this picture

907
00:28:37,320 --> 00:28:39,299
into the usual notation that will look

908
00:28:39,299 --> 00:28:40,799
like this

909
00:28:40,799 --> 00:28:42,840
um so in the top case you're normalizing

910
00:28:42,840 --> 00:28:46,080
for each possible sharp o and then

911
00:28:46,080 --> 00:28:47,820
taking an expectation over this

912
00:28:47,820 --> 00:28:49,799
distribution here as anything whole case

913
00:28:49,799 --> 00:28:50,940
you plug the whole thing together and

914
00:28:50,940 --> 00:28:52,860
then just normalize

915
00:28:52,860 --> 00:28:54,419
the way you do it though the points that

916
00:28:54,419 --> 00:28:55,380
these things are actually hard to

917
00:28:55,380 --> 00:28:56,820
compute so don't expect the cognitive

918
00:28:56,820 --> 00:28:58,500
agent to be doing either these exactly

919
00:28:58,500 --> 00:29:00,120
even in the sharp case

920
00:29:00,120 --> 00:29:01,799
and so as we know we want to instead

921
00:29:01,799 --> 00:29:03,720
approximate these kind of things using

922
00:29:03,720 --> 00:29:08,059
free energy so I'll talk about next

923
00:29:09,360 --> 00:29:11,640
um so we are able to try and accommodate

924
00:29:11,640 --> 00:29:12,960
free energy somehow in a diagrammatic

925
00:29:12,960 --> 00:29:15,659
approach and the free energy sort of

926
00:29:15,659 --> 00:29:17,100
formerly that come up are often given in

927
00:29:17,100 --> 00:29:18,240
terms of what you call the surprise

928
00:29:18,240 --> 00:29:20,399
these negative logarithm quantities so

929
00:29:20,399 --> 00:29:22,799
we'll start by introducing just a new

930
00:29:22,799 --> 00:29:24,600
graphical component for treating those

931
00:29:24,600 --> 00:29:27,840
that we call log boxes do you have any

932
00:29:27,840 --> 00:29:31,320
function e on the honestly x a positive

933
00:29:31,320 --> 00:29:32,940
real remember that made in a that would

934
00:29:32,940 --> 00:29:36,980
look like an effect in your category X

935
00:29:38,760 --> 00:29:39,600
um

936
00:29:39,600 --> 00:29:41,159
then what we want to do is talk about

937
00:29:41,159 --> 00:29:43,440
this function X goes to minus log of e

938
00:29:43,440 --> 00:29:44,399
of x

939
00:29:44,399 --> 00:29:46,020
let's record the surprise so just

940
00:29:46,020 --> 00:29:48,000
introduce this graphical feature where

941
00:29:48,000 --> 00:29:50,100
we draw a green box around it and say

942
00:29:50,100 --> 00:29:53,600
that denotes this function now

943
00:29:54,000 --> 00:29:56,760
and using rules the nice property is the

944
00:29:56,760 --> 00:29:58,020
logarithm you can turn this into nice

945
00:29:58,020 --> 00:29:59,640
graphical rules this this lockbox

946
00:29:59,640 --> 00:30:01,980
feature would satisfy

947
00:30:01,980 --> 00:30:03,360
um for example this is sort of the way

948
00:30:03,360 --> 00:30:04,980
that an algorithms have multiplication

949
00:30:04,980 --> 00:30:08,960
into addition on the left here

950
00:30:10,080 --> 00:30:11,399
um if you have this around then you can

951
00:30:11,399 --> 00:30:13,380
start talking about surprise so if you

952
00:30:13,380 --> 00:30:16,919
have two distributions Sigma and Omega

953
00:30:16,919 --> 00:30:19,620
you can do the surprise that's the one

954
00:30:19,620 --> 00:30:21,120
distribution relative to the other is

955
00:30:21,120 --> 00:30:22,860
defined by this expectation value so

956
00:30:22,860 --> 00:30:25,200
these just the expectation of a surprise

957
00:30:25,200 --> 00:30:26,399
of Sigma

958
00:30:26,399 --> 00:30:28,260
according to Amazon if you remember I

959
00:30:28,260 --> 00:30:29,760
said expectation values are given by

960
00:30:29,760 --> 00:30:31,740
sort of plugging a state for the

961
00:30:31,740 --> 00:30:33,120
distribution into the thing you're

962
00:30:33,120 --> 00:30:34,679
looking at the expectation value of so

963
00:30:34,679 --> 00:30:36,659
that would be the log box here so we can

964
00:30:36,659 --> 00:30:39,360
just Define surprise uh and we're

965
00:30:39,360 --> 00:30:40,980
assuming that in this way for in the

966
00:30:40,980 --> 00:30:42,960
pictures an important special cases for

967
00:30:42,960 --> 00:30:44,520
this camera bar when you're calculating

968
00:30:44,520 --> 00:30:46,740
entropy which is the self-surprise and

969
00:30:46,740 --> 00:30:49,080
the chaotic Merchants can be calculated

970
00:30:49,080 --> 00:30:51,779
from a surprise in the entropy

971
00:30:51,779 --> 00:30:53,100
so it means that whenever we have

972
00:30:53,100 --> 00:30:54,480
formula given in terms of these if we

973
00:30:54,480 --> 00:30:56,399
like we can instead denote them with

974
00:30:56,399 --> 00:30:58,440
this this graphical symbol at least with

975
00:30:58,440 --> 00:31:01,220
the log box

976
00:31:01,320 --> 00:31:03,539
so now let's talk about how we use this

977
00:31:03,539 --> 00:31:05,039
to describe free energy so what we want

978
00:31:05,039 --> 00:31:06,840
to do in the paper is sort of help

979
00:31:06,840 --> 00:31:08,340
clarify the kind of different Notions of

980
00:31:08,340 --> 00:31:10,020
free energy that we found in in active

981
00:31:10,020 --> 00:31:12,120
inference in particular the variational

982
00:31:12,120 --> 00:31:14,159
and the expected free energy so we want

983
00:31:14,159 --> 00:31:16,919
one more General quantity that we can

984
00:31:16,919 --> 00:31:19,380
understand both of those in terms of I'm

985
00:31:19,380 --> 00:31:21,419
just calling that the free energy uh

986
00:31:21,419 --> 00:31:23,520
here I'm interested to know what other

987
00:31:23,520 --> 00:31:25,320
people think of this sort of naming for

988
00:31:25,320 --> 00:31:26,700
what we're doing

989
00:31:26,700 --> 00:31:28,380
the situation is that we've got some

990
00:31:28,380 --> 00:31:30,179
generative model that's fixed over these

991
00:31:30,179 --> 00:31:31,860
two variables Sno like before so

992
00:31:31,860 --> 00:31:33,360
remember we had this distribution this

993
00:31:33,360 --> 00:31:34,440
box m

994
00:31:34,440 --> 00:31:37,440
uh over Sno it's distribution and let's

995
00:31:37,440 --> 00:31:38,640
just say we have another distribution

996
00:31:38,640 --> 00:31:40,380
queue now and we'll see examples of this

997
00:31:40,380 --> 00:31:41,520
in a second what sort of queue they

998
00:31:41,520 --> 00:31:42,480
would be

999
00:31:42,480 --> 00:31:43,980
then we just Define this quantity you've

1000
00:31:43,980 --> 00:31:45,480
got the free energy of the one relative

1001
00:31:45,480 --> 00:31:47,640
to the other in this way so it's the

1002
00:31:47,640 --> 00:31:51,840
surprise uh minus the entropy of Q in

1003
00:31:51,840 --> 00:31:53,340
the string diagrams then it's just this

1004
00:31:53,340 --> 00:31:55,320
feature we plug so it's like the

1005
00:31:55,320 --> 00:31:58,640
expected surprise of M for Q minus the

1006
00:31:58,640 --> 00:32:02,700
entropy of Q's marginal on S

1007
00:32:02,700 --> 00:32:04,500
or this is performing art if you want to

1008
00:32:04,500 --> 00:32:05,940
use the the conventional notation which

1009
00:32:05,940 --> 00:32:08,220
is useful for relating it to

1010
00:32:08,220 --> 00:32:09,899
existing approaches

1011
00:32:09,899 --> 00:32:11,460
so we can Define this very general free

1012
00:32:11,460 --> 00:32:13,200
energy quantity and then we'll meet two

1013
00:32:13,200 --> 00:32:14,460
special cases of it that we're

1014
00:32:14,460 --> 00:32:15,840
interested in which is the variational

1015
00:32:15,840 --> 00:32:17,820
and expected

1016
00:32:17,820 --> 00:32:19,380
free energy

1017
00:32:19,380 --> 00:32:20,940
it all comes down basically to having a

1018
00:32:20,940 --> 00:32:22,980
definition of surprise you know you just

1019
00:32:22,980 --> 00:32:24,240
need this notion of surprise to Define

1020
00:32:24,240 --> 00:32:26,520
everything else

1021
00:32:26,520 --> 00:32:28,919
so the variation of free energy

1022
00:32:28,919 --> 00:32:31,020
so we have this fixed model M and we

1023
00:32:31,020 --> 00:32:33,120
have the soft observation o like we did

1024
00:32:33,120 --> 00:32:35,039
before so this box here

1025
00:32:35,039 --> 00:32:36,299
and then what we're doing is we're

1026
00:32:36,299 --> 00:32:37,320
considering different possible

1027
00:32:37,320 --> 00:32:39,000
distributions over s that we think of as

1028
00:32:39,000 --> 00:32:41,220
different updates we could consider for

1029
00:32:41,220 --> 00:32:43,679
our beliefs and we Define the variation

1030
00:32:43,679 --> 00:32:45,659
of free energy of any of those States

1031
00:32:45,659 --> 00:32:48,000
those distributions Q

1032
00:32:48,000 --> 00:32:49,559
as the special case of the definition

1033
00:32:49,559 --> 00:32:51,419
for the previous slide so it's like the

1034
00:32:51,419 --> 00:32:52,620
general free energy

1035
00:32:52,620 --> 00:32:54,480
where that capital Q just takes this

1036
00:32:54,480 --> 00:32:57,240
form so it just consists of our new

1037
00:32:57,240 --> 00:32:59,399
beliefs lowercase q and our observation

1038
00:32:59,399 --> 00:33:00,980
O

1039
00:33:00,980 --> 00:33:03,960
So in Formula you can just draw like

1040
00:33:03,960 --> 00:33:05,520
this so you take the surprise from your

1041
00:33:05,520 --> 00:33:07,980
model M and you just see how it its

1042
00:33:07,980 --> 00:33:09,779
expected value for those beliefs and

1043
00:33:09,779 --> 00:33:11,039
that observation

1044
00:33:11,039 --> 00:33:16,019
subtracted the the entropy of Q

1045
00:33:16,019 --> 00:33:16,799
um

1046
00:33:16,799 --> 00:33:18,059
and what you're going to show is that

1047
00:33:18,059 --> 00:33:20,399
this vfv value satisfies this bound with

1048
00:33:20,399 --> 00:33:22,019
the KL in relation to the kind of

1049
00:33:22,019 --> 00:33:24,299
Jeffrey update I mean model with respect

1050
00:33:24,299 --> 00:33:25,799
to this observation

1051
00:33:25,799 --> 00:33:27,840
in particular when

1052
00:33:27,840 --> 00:33:29,580
um it's a sharp observation then the

1053
00:33:29,580 --> 00:33:31,019
minimal of this

1054
00:33:31,019 --> 00:33:33,120
BFF will be given by the the Basin

1055
00:33:33,120 --> 00:33:33,480
updating

1056
00:33:33,480 --> 00:33:34,679
[Music]

1057
00:33:34,679 --> 00:33:36,059
in general though we might think about

1058
00:33:36,059 --> 00:33:37,380
what happens

1059
00:33:37,380 --> 00:33:38,519
um so in general we can think of

1060
00:33:38,519 --> 00:33:40,380
minimizing this the SP quantity it's

1061
00:33:40,380 --> 00:33:42,179
doing this as finding this queue that

1062
00:33:42,179 --> 00:33:43,919
approximates this kind of update so

1063
00:33:43,919 --> 00:33:46,019
we're looking at earlier

1064
00:33:46,019 --> 00:33:47,640
and yeah in the sharp case it will

1065
00:33:47,640 --> 00:33:49,440
coincide as all of the Notions of

1066
00:33:49,440 --> 00:33:51,240
updating do

1067
00:33:51,240 --> 00:33:52,919
um so the minimal vfp will be given by

1068
00:33:52,919 --> 00:33:54,960
the Bayesian update but for these soft

1069
00:33:54,960 --> 00:33:56,700
observations

1070
00:33:56,700 --> 00:33:57,840
um it's something else that's not

1071
00:33:57,840 --> 00:34:00,600
exactly the the either the two Nations

1072
00:34:00,600 --> 00:34:02,100
updating we met earlier so this is

1073
00:34:02,100 --> 00:34:03,779
actually a third notion of updating for

1074
00:34:03,779 --> 00:34:05,760
soft observations

1075
00:34:05,760 --> 00:34:06,840
um which I think is an interesting way

1076
00:34:06,840 --> 00:34:09,239
to think about vfp minimization is doing

1077
00:34:09,239 --> 00:34:11,820
so we just call this the vfv update so

1078
00:34:11,820 --> 00:34:13,139
you've got many different queue you can

1079
00:34:13,139 --> 00:34:14,580
calculate the sphere of the quantity for

1080
00:34:14,580 --> 00:34:16,500
each and you've got a soft observation

1081
00:34:16,500 --> 00:34:18,540
over here so it's some distribution

1082
00:34:18,540 --> 00:34:20,219
and if you find the one with the minimal

1083
00:34:20,219 --> 00:34:21,599
value of sphere that you call that the

1084
00:34:21,599 --> 00:34:23,580
fear fee update

1085
00:34:23,580 --> 00:34:25,080
and this wouldn't be equal to either

1086
00:34:25,080 --> 00:34:26,879
those Pearl or Jeffrey style updates

1087
00:34:26,879 --> 00:34:29,339
that we met earlier

1088
00:34:29,339 --> 00:34:31,139
so that's the vfv which will which we'll

1089
00:34:31,139 --> 00:34:34,080
come back to the other notion of uh free

1090
00:34:34,080 --> 00:34:35,159
energy we want to talk about the

1091
00:34:35,159 --> 00:34:37,320
expected free energy

1092
00:34:37,320 --> 00:34:39,239
so that's where we still have our model

1093
00:34:39,239 --> 00:34:41,399
M but rather than an observation we

1094
00:34:41,399 --> 00:34:42,659
think of ourselves as having some

1095
00:34:42,659 --> 00:34:44,580
preferences of observations we'd like to

1096
00:34:44,580 --> 00:34:46,379
see they're again encoded in a

1097
00:34:46,379 --> 00:34:48,659
distribution though over over o so

1098
00:34:48,659 --> 00:34:49,800
that's just C

1099
00:34:49,800 --> 00:34:51,659
and that and so

1100
00:34:51,659 --> 00:34:53,399
in just with that fixed we can Define

1101
00:34:53,399 --> 00:34:54,960
this one quantity called the expected

1102
00:34:54,960 --> 00:34:56,219
free energy

1103
00:34:56,219 --> 00:34:58,020
so that's given by the free energy of M

1104
00:34:58,020 --> 00:34:59,900
compared to this other generative model

1105
00:34:59,900 --> 00:35:02,339
where you have to use the same in so

1106
00:35:02,339 --> 00:35:03,839
this m here would really be the inverse

1107
00:35:03,839 --> 00:35:06,480
channels from o to S of M so like the

1108
00:35:06,480 --> 00:35:08,820
Bayesian inverse here

1109
00:35:08,820 --> 00:35:10,740
um but where you just assert that the

1110
00:35:10,740 --> 00:35:13,020
preferences actually is the Pariah on

1111
00:35:13,020 --> 00:35:14,520
the observation so you're comparing

1112
00:35:14,520 --> 00:35:16,560
these two

1113
00:35:16,560 --> 00:35:18,119
um in terms of this generic free energy

1114
00:35:18,119 --> 00:35:20,700
quantity we defined earlier

1115
00:35:20,700 --> 00:35:22,320
so again you can turn this into formulas

1116
00:35:22,320 --> 00:35:23,760
and there's loads of stuff going after

1117
00:35:23,760 --> 00:35:25,619
inference about the different rewritings

1118
00:35:25,619 --> 00:35:27,240
of the efe and the ways to interpret

1119
00:35:27,240 --> 00:35:28,440
with them in terms of uncertainty and

1120
00:35:28,440 --> 00:35:29,940
risk and so on

1121
00:35:29,940 --> 00:35:32,760
and it has this property that you can

1122
00:35:32,760 --> 00:35:35,040
show it'll be a bounded by

1123
00:35:35,040 --> 00:35:37,079
um the surprise of those preferences for

1124
00:35:37,079 --> 00:35:38,880
your your model so and it kind of gives

1125
00:35:38,880 --> 00:35:40,980
you a way to approximate them as we'll

1126
00:35:40,980 --> 00:35:43,200
see so I went and talked I don't have

1127
00:35:43,200 --> 00:35:44,700
time to get too much at efe but the

1128
00:35:44,700 --> 00:35:46,140
point really in terms of what this

1129
00:35:46,140 --> 00:35:48,060
work's done is just to try and um

1130
00:35:48,060 --> 00:35:49,619
have just one generic free energy

1131
00:35:49,619 --> 00:35:51,420
quantity we met earlier where we can see

1132
00:35:51,420 --> 00:35:53,339
the vfp in the ESU book coming out the

1133
00:35:53,339 --> 00:35:54,900
special cases depending on what we plug

1134
00:35:54,900 --> 00:35:58,940
in here for the the two distributions

1135
00:35:59,400 --> 00:36:01,500
so what I'd like to do now is to sort of

1136
00:36:01,500 --> 00:36:02,640
put some of these pieces together to

1137
00:36:02,640 --> 00:36:04,020
show active inference itself will kind

1138
00:36:04,020 --> 00:36:05,579
of look like in terms of string diagrams

1139
00:36:05,579 --> 00:36:07,200
and particular what we'll do is derive

1140
00:36:07,200 --> 00:36:08,400
this formula that you'll find in

1141
00:36:08,400 --> 00:36:10,740
actually inference textbooks um in a

1142
00:36:10,740 --> 00:36:12,839
graphical in a graphical way and I think

1143
00:36:12,839 --> 00:36:14,880
uh quite a transparent way but that's

1144
00:36:14,880 --> 00:36:17,280
the claim

1145
00:36:17,280 --> 00:36:20,099
so and to do so we basically need to

1146
00:36:20,099 --> 00:36:21,359
give a nice high level conceptual

1147
00:36:21,359 --> 00:36:23,160
viewable active inference is so this is

1148
00:36:23,160 --> 00:36:25,619
the way that we do it in the paper

1149
00:36:25,619 --> 00:36:27,599
so when inactory interference team the

1150
00:36:27,599 --> 00:36:29,099
key thing for statement with admissions

1151
00:36:29,099 --> 00:36:30,660
is that our model takes the following

1152
00:36:30,660 --> 00:36:32,460
the form at a higher level so there's

1153
00:36:32,460 --> 00:36:34,740
some notion of so it's like our discrete

1154
00:36:34,740 --> 00:36:36,540
time model we had earlier but just with

1155
00:36:36,540 --> 00:36:38,880
two time steps if you like each of those

1156
00:36:38,880 --> 00:36:40,859
time steps could break down in terms of

1157
00:36:40,859 --> 00:36:43,320
further sub time sets but that won't

1158
00:36:43,320 --> 00:36:45,599
matter we've just obstructive here uh at

1159
00:36:45,599 --> 00:36:46,740
this higher level

1160
00:36:46,740 --> 00:36:48,119
so at the higher level we just have a

1161
00:36:48,119 --> 00:36:49,800
notion of the current time or maybe like

1162
00:36:49,800 --> 00:36:51,180
all the time steps up to the current

1163
00:36:51,180 --> 00:36:53,940
time and that's this s and O here so

1164
00:36:53,940 --> 00:36:55,200
there's current states and current

1165
00:36:55,200 --> 00:36:56,579
observations

1166
00:36:56,579 --> 00:36:58,260
then it's the notion of future times

1167
00:36:58,260 --> 00:36:59,760
these future States and future

1168
00:36:59,760 --> 00:37:02,160
observations so that could be all the

1169
00:37:02,160 --> 00:37:03,359
time steps up to some big number

1170
00:37:03,359 --> 00:37:05,640
something like that all grouped together

1171
00:37:05,640 --> 00:37:08,579
in one of those discrete time models

1172
00:37:08,579 --> 00:37:10,079
and again we have the policies and we

1173
00:37:10,079 --> 00:37:11,099
have the same sort of shape of model

1174
00:37:11,099 --> 00:37:12,119
where there's

1175
00:37:12,119 --> 00:37:13,260
some channels here which you haven't

1176
00:37:13,260 --> 00:37:14,520
bothered of giving letters to but

1177
00:37:14,520 --> 00:37:17,160
showing the way that the policy

1178
00:37:17,160 --> 00:37:17,880
um

1179
00:37:17,880 --> 00:37:19,859
influences the transition from the state

1180
00:37:19,859 --> 00:37:22,140
to the Future State and observations

1181
00:37:22,140 --> 00:37:24,119
from each

1182
00:37:24,119 --> 00:37:26,460
so we just have a generative model where

1183
00:37:26,460 --> 00:37:28,320
we have policies that we have States and

1184
00:37:28,320 --> 00:37:29,520
observations and we have future States

1185
00:37:29,520 --> 00:37:31,859
and future observations in active

1186
00:37:31,859 --> 00:37:32,940
inference what we're doing is we're

1187
00:37:32,940 --> 00:37:34,680
receiving two things we're receiving an

1188
00:37:34,680 --> 00:37:36,900
observation in the current time and we

1189
00:37:36,900 --> 00:37:38,400
have some preferences about what we'd

1190
00:37:38,400 --> 00:37:40,800
like to see in the future

1191
00:37:40,800 --> 00:37:42,240
so these are each given by these two

1192
00:37:42,240 --> 00:37:45,119
distributions however Voltron 0 over 0

1193
00:37:45,119 --> 00:37:47,160
and the preferences C over the future

1194
00:37:47,160 --> 00:37:48,359
observations

1195
00:37:48,359 --> 00:37:50,040
and then we're doing updating with those

1196
00:37:50,040 --> 00:37:53,520
so I think that dating is just our

1197
00:37:53,520 --> 00:37:55,680
um our habits the the prior over the

1198
00:37:55,680 --> 00:37:56,760
policies

1199
00:37:56,760 --> 00:37:59,040
to give our new distribution over

1200
00:37:59,040 --> 00:38:00,660
policies which we can think of as the

1201
00:38:00,660 --> 00:38:03,180
agent's plan of how it wants to act so

1202
00:38:03,180 --> 00:38:04,140
we're going to try and do this updating

1203
00:38:04,140 --> 00:38:06,420
like before to obtain a new distribution

1204
00:38:06,420 --> 00:38:07,920
over p

1205
00:38:07,920 --> 00:38:10,380
and that is now telling us how we want

1206
00:38:10,380 --> 00:38:13,200
to behave in the future in a way that

1207
00:38:13,200 --> 00:38:14,579
well basically you can think of it as

1208
00:38:14,579 --> 00:38:16,500
saying we want to explain why we're

1209
00:38:16,500 --> 00:38:18,180
seeing what we're currently seeing and

1210
00:38:18,180 --> 00:38:20,220
how we're going to obtain what we'd like

1211
00:38:20,220 --> 00:38:22,939
in the future

1212
00:38:23,280 --> 00:38:25,079
so in the in the book stand for infants

1213
00:38:25,079 --> 00:38:26,460
and various places you can find a

1214
00:38:26,460 --> 00:38:28,619
formula like this that will be justified

1215
00:38:28,619 --> 00:38:30,060
as coming from the free energy principle

1216
00:38:30,060 --> 00:38:32,700
in some way but basically saying you can

1217
00:38:32,700 --> 00:38:35,880
do this um approximately by making a

1218
00:38:35,880 --> 00:38:37,320
plan distribution take the following the

1219
00:38:37,320 --> 00:38:39,599
form so there's a soft Max there's a

1220
00:38:39,599 --> 00:38:41,760
apartment relating to the habits of your

1221
00:38:41,760 --> 00:38:43,980
model so that's your prior over policies

1222
00:38:43,980 --> 00:38:45,780
these Pi are the individual policies in

1223
00:38:45,780 --> 00:38:46,740
p

1224
00:38:46,740 --> 00:38:48,300
and then there's two there's parts of

1225
00:38:48,300 --> 00:38:51,660
One Direction to the vfv and the efe

1226
00:38:51,660 --> 00:38:53,280
um and what we wanted to do is see where

1227
00:38:53,280 --> 00:38:55,020
this formula comes from in a sort of

1228
00:38:55,020 --> 00:38:58,200
nice uh I love away from the structure

1229
00:38:58,200 --> 00:39:00,540
of the diagram so the usual there are

1230
00:39:00,540 --> 00:39:02,040
explanations for this formula there but

1231
00:39:02,040 --> 00:39:04,079
I found them quite hard to follow to be

1232
00:39:04,079 --> 00:39:05,220
honest because they were talking about

1233
00:39:05,220 --> 00:39:06,599
the

1234
00:39:06,599 --> 00:39:10,560
um efe as being a prior that you then do

1235
00:39:10,560 --> 00:39:12,720
um DFE carbonization on top of but you

1236
00:39:12,720 --> 00:39:14,520
kind of need to do the the forward the

1237
00:39:14,520 --> 00:39:16,020
part about the present time first before

1238
00:39:16,020 --> 00:39:17,820
you can do the ESV

1239
00:39:17,820 --> 00:39:19,859
and so what we wanted this is a really

1240
00:39:19,859 --> 00:39:21,300
clear way to see how this just drops out

1241
00:39:21,300 --> 00:39:22,740
from the structure of the model so

1242
00:39:22,740 --> 00:39:26,759
that's what I'll try and show now

1243
00:39:27,420 --> 00:39:28,740
so

1244
00:39:28,740 --> 00:39:30,359
what we'd like to do then is to do this

1245
00:39:30,359 --> 00:39:31,800
approximate updating we're going to do

1246
00:39:31,800 --> 00:39:33,480
the Pearl style updating which look like

1247
00:39:33,480 --> 00:39:35,160
this in the pictures so we want to get

1248
00:39:35,160 --> 00:39:36,900
our new plan so our distribution over

1249
00:39:36,900 --> 00:39:39,839
policies by updating by plugging in

1250
00:39:39,839 --> 00:39:42,060
observation and our preferences

1251
00:39:42,060 --> 00:39:43,619
and then normalizing everything so the

1252
00:39:43,619 --> 00:39:44,940
thing on the right is what we'd like to

1253
00:39:44,940 --> 00:39:46,619
have ideally but we're just gonna have

1254
00:39:46,619 --> 00:39:48,900
to approximate it in some way

1255
00:39:48,900 --> 00:39:50,700
so let's just take the distribution

1256
00:39:50,700 --> 00:39:52,920
that's inside the dash normalization box

1257
00:39:52,920 --> 00:39:54,300
now

1258
00:39:54,300 --> 00:39:55,980
this is the thing you know we'd like to

1259
00:39:55,980 --> 00:39:59,040
basically approximate this

1260
00:39:59,040 --> 00:40:00,660
in the structure of our model we can

1261
00:40:00,660 --> 00:40:02,460
write it like this

1262
00:40:02,460 --> 00:40:04,920
and I'll just show then some graphical

1263
00:40:04,920 --> 00:40:06,119
steps for how we can apply

1264
00:40:06,119 --> 00:40:07,980
approximations to obtain the formula

1265
00:40:07,980 --> 00:40:09,660
that we saw and obviously we weren't

1266
00:40:09,660 --> 00:40:11,820
able to go through every detail of the

1267
00:40:11,820 --> 00:40:13,200
proof but it should give hopefully some

1268
00:40:13,200 --> 00:40:14,280
intuition for what it's like to actually

1269
00:40:14,280 --> 00:40:15,780
work with a string diagram so that's

1270
00:40:15,780 --> 00:40:17,760
really why I'm showing it so we knew our

1271
00:40:17,760 --> 00:40:19,380
model take roughly this form there's

1272
00:40:19,380 --> 00:40:22,140
some part relating to current states and

1273
00:40:22,140 --> 00:40:23,579
current observations and also future

1274
00:40:23,579 --> 00:40:25,200
observations I just called them both M

1275
00:40:25,200 --> 00:40:26,280
here

1276
00:40:26,280 --> 00:40:28,680
um but yeah we just noticed that part

1277
00:40:28,680 --> 00:40:32,760
to the present time and future time

1278
00:40:32,760 --> 00:40:34,740
and so what we're going to do is first

1279
00:40:34,740 --> 00:40:36,240
focus on this part of the model relating

1280
00:40:36,240 --> 00:40:38,280
to the current state and the current

1281
00:40:38,280 --> 00:40:40,440
observation and we want to approximate

1282
00:40:40,440 --> 00:40:43,380
what's in that blue dash box and what

1283
00:40:43,380 --> 00:40:44,940
you can show is that if you do this via

1284
00:40:44,940 --> 00:40:47,520
the updating that will be approximately

1285
00:40:47,520 --> 00:40:50,220
equal to this part of the diagram

1286
00:40:50,220 --> 00:40:53,280
so this Q is given by for each policy

1287
00:40:53,280 --> 00:40:56,579
doing this um BFE updating so minimizing

1288
00:40:56,579 --> 00:40:58,200
your variation of free energy

1289
00:40:58,200 --> 00:41:00,480
so you do that for each policy and then

1290
00:41:00,480 --> 00:41:01,859
you can view the collection of all of

1291
00:41:01,859 --> 00:41:04,619
those up belief updates as just one

1292
00:41:04,619 --> 00:41:06,660
channel from P to s

1293
00:41:06,660 --> 00:41:08,160
so if you think about back here

1294
00:41:08,160 --> 00:41:10,320
basically for each policy you could plug

1295
00:41:10,320 --> 00:41:12,480
in you would obtain just a distribution

1296
00:41:12,480 --> 00:41:14,339
now over Sno and you could do updating

1297
00:41:14,339 --> 00:41:16,859
with respect to that that's what Pew of

1298
00:41:16,859 --> 00:41:19,320
that particular policy Pi would be

1299
00:41:19,320 --> 00:41:20,760
and you put them all together into this

1300
00:41:20,760 --> 00:41:22,740
one channel queue

1301
00:41:22,740 --> 00:41:24,599
and you can show then for each one if

1302
00:41:24,599 --> 00:41:26,460
you do this overall process where you

1303
00:41:26,460 --> 00:41:28,260
multiply by this e to the minus V of the

1304
00:41:28,260 --> 00:41:30,300
quantity here it will be approximately

1305
00:41:30,300 --> 00:41:32,099
uh equal to this this part of the

1306
00:41:32,099 --> 00:41:34,140
diagram

1307
00:41:34,140 --> 00:41:36,119
okay so that's our first step and that's

1308
00:41:36,119 --> 00:41:37,380
how the vfb entered the picture then

1309
00:41:37,380 --> 00:41:38,579
we've got this top part of the diagram

1310
00:41:38,579 --> 00:41:40,140
we'll collapse it together and just view

1311
00:41:40,140 --> 00:41:42,000
this as one process going into future

1312
00:41:42,000 --> 00:41:43,560
observations

1313
00:41:43,560 --> 00:41:45,060
and our preferences and we'd like to

1314
00:41:45,060 --> 00:41:47,400
approximate what's in this box now

1315
00:41:47,400 --> 00:41:49,440
and this is where the efv comes in so

1316
00:41:49,440 --> 00:41:51,780
you can basically show because we have

1317
00:41:51,780 --> 00:41:52,500
this

1318
00:41:52,500 --> 00:41:56,339
um yeah that the expected free energy

1319
00:41:56,339 --> 00:41:58,980
will give you an approximation to this

1320
00:41:58,980 --> 00:42:01,200
here where this is basically like an

1321
00:42:01,200 --> 00:42:04,440
expectation value for your preferences

1322
00:42:04,440 --> 00:42:06,480
um for each policy so this would be like

1323
00:42:06,480 --> 00:42:08,700
the density C of the preferences being

1324
00:42:08,700 --> 00:42:10,560
plugged into your model

1325
00:42:10,560 --> 00:42:13,020
for each policy

1326
00:42:13,020 --> 00:42:13,740
um

1327
00:42:13,740 --> 00:42:15,300
so I have no time to go into the full

1328
00:42:15,300 --> 00:42:16,859
details the approximation steps but

1329
00:42:16,859 --> 00:42:18,000
they're essentially the same

1330
00:42:18,000 --> 00:42:20,040
approximations you'll find in you know

1331
00:42:20,040 --> 00:42:21,720
active inference text and so on just

1332
00:42:21,720 --> 00:42:23,460
turn it into the string diagrammatic

1333
00:42:23,460 --> 00:42:25,380
setting and we talk about how you figure

1334
00:42:25,380 --> 00:42:27,060
out how how they come about from

1335
00:42:27,060 --> 00:42:29,640
Jensen's inequality and things like this

1336
00:42:29,640 --> 00:42:31,440
so this step where you think about the

1337
00:42:31,440 --> 00:42:32,460
future times sometimes it's got the

1338
00:42:32,460 --> 00:42:34,680
prediction step and the previous one was

1339
00:42:34,680 --> 00:42:36,780
the was the perception step

1340
00:42:36,780 --> 00:42:38,520
so now we've Rewritten that diagram in

1341
00:42:38,520 --> 00:42:40,500
terms of some e to the minus of the v f

1342
00:42:40,500 --> 00:42:42,900
e and e to the minus of the efv as well

1343
00:42:42,900 --> 00:42:45,560
as our habits

1344
00:42:45,960 --> 00:42:47,579
um I'll remember what we wanted to do

1345
00:42:47,579 --> 00:42:49,380
was approximate the normalization of

1346
00:42:49,380 --> 00:42:50,400
this whole thing so that's when you

1347
00:42:50,400 --> 00:42:51,780
apply this blue dash box around the

1348
00:42:51,780 --> 00:42:52,619
whole thing

1349
00:42:52,619 --> 00:42:54,720
and now if we do that we this is exactly

1350
00:42:54,720 --> 00:42:56,400
the same as the formula we're after so

1351
00:42:56,400 --> 00:42:59,400
we've obtained the formula now

1352
00:42:59,400 --> 00:43:00,540
um and that's because you know you're

1353
00:43:00,540 --> 00:43:02,579
normalizing something but it's got these

1354
00:43:02,579 --> 00:43:05,099
e to the minuses in it so you can also

1355
00:43:05,099 --> 00:43:07,680
rewrite that in terms of the softmax

1356
00:43:07,680 --> 00:43:09,660
where now that you just replace the E

1357
00:43:09,660 --> 00:43:11,099
with this log and the other ones you

1358
00:43:11,099 --> 00:43:12,960
lose the exponentials

1359
00:43:12,960 --> 00:43:15,300
so this formula if you wanted to yeah if

1360
00:43:15,300 --> 00:43:16,619
you're on a Roadhouse one of what this

1361
00:43:16,619 --> 00:43:19,200
was for each policy it would be equal to

1362
00:43:19,200 --> 00:43:21,839
this down here so

1363
00:43:21,839 --> 00:43:23,640
uh the claims that this is a nice way to

1364
00:43:23,640 --> 00:43:24,780
derive this formula and it's a bit more

1365
00:43:24,780 --> 00:43:26,280
transparent than the the ones that exist

1366
00:43:26,280 --> 00:43:28,140
so the idea was really just to see we

1367
00:43:28,140 --> 00:43:29,819
draw what's going on okay we're doing

1368
00:43:29,819 --> 00:43:31,800
updating with the model of this form

1369
00:43:31,800 --> 00:43:33,300
and we're trying to do this approximate

1370
00:43:33,300 --> 00:43:34,800
form of updating and just see where

1371
00:43:34,800 --> 00:43:36,180
we're applying the approximations and

1372
00:43:36,180 --> 00:43:37,500
from the structure of the model itself

1373
00:43:37,500 --> 00:43:40,980
to see how this formula comes about

1374
00:43:40,980 --> 00:43:42,180
um

1375
00:43:42,180 --> 00:43:43,980
okay so that so far basically just

1376
00:43:43,980 --> 00:43:45,480
talked about things that are already

1377
00:43:45,480 --> 00:43:47,220
there in active infants such as new

1378
00:43:47,220 --> 00:43:48,720
derivation but it's existing and stuff

1379
00:43:48,720 --> 00:43:50,579
before wrapping up I just like to also

1380
00:43:50,579 --> 00:43:53,099
talk about something a bit more new that

1381
00:43:53,099 --> 00:43:54,780
we do with the string diagrammatic

1382
00:43:54,780 --> 00:43:55,980
approach

1383
00:43:55,980 --> 00:43:58,260
first to talk about the way in which

1384
00:43:58,260 --> 00:44:01,859
free energy itself uh is compositional

1385
00:44:01,859 --> 00:44:03,420
so the motivation of this is that you

1386
00:44:03,420 --> 00:44:04,500
know the idea is that we want to think

1387
00:44:04,500 --> 00:44:05,880
of this one free energy principle

1388
00:44:05,880 --> 00:44:09,300
applying at all levels of a system

1389
00:44:09,300 --> 00:44:10,980
um so to do that you'd want to know that

1390
00:44:10,980 --> 00:44:12,720
an agent can say if you've got one of

1391
00:44:12,720 --> 00:44:14,220
these big composite generative models

1392
00:44:14,220 --> 00:44:16,680
that it can do its free energy

1393
00:44:16,680 --> 00:44:18,540
minimization on the whole thing by doing

1394
00:44:18,540 --> 00:44:19,920
it on the parts because we want to

1395
00:44:19,920 --> 00:44:21,119
ultimately think it just comes down to

1396
00:44:21,119 --> 00:44:23,220
each part doing its own bit of free

1397
00:44:23,220 --> 00:44:25,140
energy minimization so that's what we

1398
00:44:25,140 --> 00:44:27,839
want to make precise

1399
00:44:27,839 --> 00:44:29,040
and particularly we're going to be

1400
00:44:29,040 --> 00:44:30,540
talking about the the vfe here really

1401
00:44:30,540 --> 00:44:31,680
all the time

1402
00:44:31,680 --> 00:44:33,480
and if you recall in the diagrams that

1403
00:44:33,480 --> 00:44:35,220
look like this so we use these log boxes

1404
00:44:35,220 --> 00:44:37,079
and it just had took this particular

1405
00:44:37,079 --> 00:44:38,700
shape here

1406
00:44:38,700 --> 00:44:40,680
so what we do in the paper

1407
00:44:40,680 --> 00:44:41,880
in order to address this

1408
00:44:41,880 --> 00:44:44,520
compositionality problem

1409
00:44:44,520 --> 00:44:47,940
is introduce a notion of this BFE that

1410
00:44:47,940 --> 00:44:49,560
we can apply not just to generative

1411
00:44:49,560 --> 00:44:51,180
models but once which actually have

1412
00:44:51,180 --> 00:44:52,920
these inputs as well so these are what I

1413
00:44:52,920 --> 00:44:55,140
call open generated models earlier

1414
00:44:55,140 --> 00:44:56,460
because we need to really talk about

1415
00:44:56,460 --> 00:44:58,020
pieces of generative models plugging

1416
00:44:58,020 --> 00:44:59,880
together and give them a notion of free

1417
00:44:59,880 --> 00:45:01,619
energy to even make sense of this notion

1418
00:45:01,619 --> 00:45:04,500
of free energy being compositional

1419
00:45:04,500 --> 00:45:06,060
so we propose this definition of what we

1420
00:45:06,060 --> 00:45:07,740
call the open vfe

1421
00:45:07,740 --> 00:45:09,720
but now instead of just a distribution M

1422
00:45:09,720 --> 00:45:12,060
over s and O we have a channel from some

1423
00:45:12,060 --> 00:45:14,220
inputs to Sno given by one of these open

1424
00:45:14,220 --> 00:45:15,839
models

1425
00:45:15,839 --> 00:45:17,520
and our Q the thing we're doing the Via

1426
00:45:17,520 --> 00:45:18,960
humanization

1427
00:45:18,960 --> 00:45:20,700
um with respect to so the thing we're

1428
00:45:20,700 --> 00:45:22,619
calculating it would now have in an

1429
00:45:22,619 --> 00:45:23,880
input as well so it's a joint

1430
00:45:23,880 --> 00:45:25,920
distribution over the states and inputs

1431
00:45:25,920 --> 00:45:27,960
and observation takes the same shape as

1432
00:45:27,960 --> 00:45:30,140
before

1433
00:45:30,300 --> 00:45:31,740
um so you get this other formula that's

1434
00:45:31,740 --> 00:45:33,300
basically just a natural way to

1435
00:45:33,300 --> 00:45:36,420
generalize the previous vme formula to

1436
00:45:36,420 --> 00:45:40,859
accommodate this extra input wire I now

1437
00:45:40,859 --> 00:45:42,119
um

1438
00:45:42,119 --> 00:45:44,460
and what we show is that this thing is

1439
00:45:44,460 --> 00:45:46,260
compositional in the sensor that I

1440
00:45:46,260 --> 00:45:48,119
alluded to so I'll walk through that and

1441
00:45:48,119 --> 00:45:49,380
the way you do it is just using these

1442
00:45:49,380 --> 00:45:50,700
graphical properties that these log

1443
00:45:50,700 --> 00:45:53,040
boxes have that I mentioned earlier so

1444
00:45:53,040 --> 00:45:54,660
you could turn all that into a proof in

1445
00:45:54,660 --> 00:45:56,520
standard probability notation if you

1446
00:45:56,520 --> 00:45:59,160
like but it's quite uh instructive to

1447
00:45:59,160 --> 00:46:00,900
always just be able to work in the

1448
00:46:00,900 --> 00:46:02,579
diagrams to keep track of the

1449
00:46:02,579 --> 00:46:04,140
compositional structure of the models

1450
00:46:04,140 --> 00:46:05,760
and so on

1451
00:46:05,760 --> 00:46:08,099
so the result says that this open vfe

1452
00:46:08,099 --> 00:46:11,280
quantity is compositional in two ways

1453
00:46:11,280 --> 00:46:13,260
first one here is this quite trivial way

1454
00:46:13,260 --> 00:46:14,819
so if we have two models running in

1455
00:46:14,819 --> 00:46:16,619
parallel so like taking a tensor of them

1456
00:46:16,619 --> 00:46:18,960
and they're just both doing their own uh

1457
00:46:18,960 --> 00:46:20,460
or kind of taking the bfv for each of

1458
00:46:20,460 --> 00:46:22,020
them sorry for the whole thing but it's

1459
00:46:22,020 --> 00:46:24,000
just given by two running in parallel

1460
00:46:24,000 --> 00:46:25,560
then it's just the same as calculating

1461
00:46:25,560 --> 00:46:28,200
the V of each individually and adding

1462
00:46:28,200 --> 00:46:30,000
them together so that should that is

1463
00:46:30,000 --> 00:46:32,280
certainly what we'd like to happen and

1464
00:46:32,280 --> 00:46:33,599
it just follows from the properties of

1465
00:46:33,599 --> 00:46:35,700
these log boxes

1466
00:46:35,700 --> 00:46:37,260
more interestingly there's the second

1467
00:46:37,260 --> 00:46:38,880
way in which it's compositional which is

1468
00:46:38,880 --> 00:46:42,240
the sequential mode of plugging models

1469
00:46:42,240 --> 00:46:45,060
together so if we have an open model M1

1470
00:46:45,060 --> 00:46:48,720
and some inputs into some outputs o1 but

1471
00:46:48,720 --> 00:46:50,220
those are now actually the inputs for

1472
00:46:50,220 --> 00:46:51,720
the second model I have these running

1473
00:46:51,720 --> 00:46:53,760
for the first generated model is still

1474
00:46:53,760 --> 00:46:56,520
passing step up to the second one

1475
00:46:56,520 --> 00:46:58,200
and now we want to calculate that

1476
00:46:58,200 --> 00:47:01,380
results vfb

1477
00:47:01,380 --> 00:47:03,540
in terms of an observation

1478
00:47:03,540 --> 00:47:05,579
and we can again write it as a sum of

1479
00:47:05,579 --> 00:47:06,839
two of them but in a slightly different

1480
00:47:06,839 --> 00:47:09,119
way so observation is just existing on

1481
00:47:09,119 --> 00:47:10,619
the top why all right because it's just

1482
00:47:10,619 --> 00:47:12,540
the output of the whole thing against

1483
00:47:12,540 --> 00:47:15,119
this observations it's just on O2

1484
00:47:15,119 --> 00:47:17,099
so first we calculate the vfv for this

1485
00:47:17,099 --> 00:47:20,160
model at the top M2 in the usual way

1486
00:47:20,160 --> 00:47:22,380
and then we add on a vfv calculator for

1487
00:47:22,380 --> 00:47:24,480
the first model but it doesn't really

1488
00:47:24,480 --> 00:47:27,119
have an observation o1 right but instead

1489
00:47:27,119 --> 00:47:28,500
the observation it uses is one that's

1490
00:47:28,500 --> 00:47:29,940
being passed down

1491
00:47:29,940 --> 00:47:32,640
from empty so that's the

1492
00:47:32,640 --> 00:47:35,160
um the queue that M2 is using is passed

1493
00:47:35,160 --> 00:47:36,839
down now as if it's an observation down

1494
00:47:36,839 --> 00:47:39,720
so M1 so it's kind of like O2 receives

1495
00:47:39,720 --> 00:47:42,000
this observation does its uh

1496
00:47:42,000 --> 00:47:43,619
updating about queue or whatever and

1497
00:47:43,619 --> 00:47:46,920
passes that down to M1

1498
00:47:46,920 --> 00:47:50,280
so in this way we can say that the vfp

1499
00:47:50,280 --> 00:47:52,680
composes in that okay both of these are

1500
00:47:52,680 --> 00:47:54,960
minimizing vfp locally

1501
00:47:54,960 --> 00:47:56,700
where for the M1 model we mean it's

1502
00:47:56,700 --> 00:47:58,619
minimizing it with respect to these

1503
00:47:58,619 --> 00:48:00,599
views that are coming but these o ones

1504
00:48:00,599 --> 00:48:02,460
that are coming down from above

1505
00:48:02,460 --> 00:48:05,099
then the whole system is also minimizing

1506
00:48:05,099 --> 00:48:06,420
its fear because it's just given by

1507
00:48:06,420 --> 00:48:09,300
summing those two together

1508
00:48:09,300 --> 00:48:11,579
so I talked about a lot of stuff now I'm

1509
00:48:11,579 --> 00:48:13,200
just going to wrap up now and then we

1510
00:48:13,200 --> 00:48:15,480
can go to a discussion I hope

1511
00:48:15,480 --> 00:48:17,400
um so the main takeaway was just meant

1512
00:48:17,400 --> 00:48:18,960
to be to try and show that these string

1513
00:48:18,960 --> 00:48:20,339
diagrams provide some natural language

1514
00:48:20,339 --> 00:48:24,060
for talking about active inference

1515
00:48:24,060 --> 00:48:26,220
um and I would encourage you to try if

1516
00:48:26,220 --> 00:48:27,960
anyone working on natural business for

1517
00:48:27,960 --> 00:48:29,520
me to take a look and see if they would

1518
00:48:29,520 --> 00:48:31,319
be useful to you in some way

1519
00:48:31,319 --> 00:48:33,599
and in particular focused on some other

1520
00:48:33,599 --> 00:48:35,339
what I was calling the main ingredients

1521
00:48:35,339 --> 00:48:36,420
of active inference so that were

1522
00:48:36,420 --> 00:48:38,640
generated models the way you update them

1523
00:48:38,640 --> 00:48:40,740
and free energy and we saw sort of ways

1524
00:48:40,740 --> 00:48:43,020
you can describe all those Notions in

1525
00:48:43,020 --> 00:48:45,060
the string diagrams and the thing that I

1526
00:48:45,060 --> 00:48:46,980
think is useful about them is that they

1527
00:48:46,980 --> 00:48:48,060
give you a nice representational

1528
00:48:48,060 --> 00:48:49,380
language of just drawing pictures of

1529
00:48:49,380 --> 00:48:50,760
your generative models and composing

1530
00:48:50,760 --> 00:48:53,160
them like hierarchical models and so on

1531
00:48:53,160 --> 00:48:54,540
they also let you do the reasoning

1532
00:48:54,540 --> 00:48:55,980
because you can do probability Theory

1533
00:48:55,980 --> 00:48:57,540
with them so you can actually reason

1534
00:48:57,540 --> 00:48:59,220
about what's going on in active events

1535
00:48:59,220 --> 00:49:03,020
just with the diagrams themselves

1536
00:49:03,060 --> 00:49:04,500
um there's loads of electricity in the

1537
00:49:04,500 --> 00:49:05,819
future obviously we can keep absorbing

1538
00:49:05,819 --> 00:49:07,680
more of the of the work without an

1539
00:49:07,680 --> 00:49:08,940
active inference into the into the

1540
00:49:08,940 --> 00:49:10,079
diagrams

1541
00:49:10,079 --> 00:49:12,359
um a bit more interestingly

1542
00:49:12,359 --> 00:49:13,319
um

1543
00:49:13,319 --> 00:49:15,240
I we introduced this new notion at the

1544
00:49:15,240 --> 00:49:16,140
end

1545
00:49:16,140 --> 00:49:17,760
um of how to make free energy

1546
00:49:17,760 --> 00:49:19,079
compositional

1547
00:49:19,079 --> 00:49:20,880
in particularly we gave this definition

1548
00:49:20,880 --> 00:49:24,599
of vfe for an open system now so it has

1549
00:49:24,599 --> 00:49:26,280
a generative model which can have inputs

1550
00:49:26,280 --> 00:49:28,319
we call just the open vfb and it's been

1551
00:49:28,319 --> 00:49:29,339
very interesting what people think of

1552
00:49:29,339 --> 00:49:31,140
this definition we we introduce however

1553
00:49:31,140 --> 00:49:33,119
it seems meaningful

1554
00:49:33,119 --> 00:49:35,099
secondly um well throughout the topic I

1555
00:49:35,099 --> 00:49:36,240
get to talk about just minimizing free

1556
00:49:36,240 --> 00:49:37,500
energy and that's what I said probably

1557
00:49:37,500 --> 00:49:41,400
the vfp if I didn't say how you do it so

1558
00:49:41,400 --> 00:49:42,839
um in fact this is normally done with

1559
00:49:42,839 --> 00:49:44,160
these various algorithms with message

1560
00:49:44,160 --> 00:49:46,020
passing algorithms so they're an

1561
00:49:46,020 --> 00:49:47,220
important part of accurate for instance

1562
00:49:47,220 --> 00:49:49,140
active inference as well and I think it

1563
00:49:49,140 --> 00:49:51,839
would be great to include these in the

1564
00:49:51,839 --> 00:49:53,520
in the setup by having some diagrammatic

1565
00:49:53,520 --> 00:49:56,160
story of them

1566
00:49:56,160 --> 00:49:57,300
um there's also lots of other questions

1567
00:49:57,300 --> 00:49:59,640
around so one of them is that I talked

1568
00:49:59,640 --> 00:50:01,380
about these two Notions updating with

1569
00:50:01,380 --> 00:50:03,960
respect to soft observations and I think

1570
00:50:03,960 --> 00:50:05,579
normally people tend to focus on child

1571
00:50:05,579 --> 00:50:08,099
observations so they perhaps haven't not

1572
00:50:08,099 --> 00:50:10,920
everyone has heard of these before

1573
00:50:10,920 --> 00:50:12,240
um but it's very natural to treat the

1574
00:50:12,240 --> 00:50:13,260
soft ones when you're working this

1575
00:50:13,260 --> 00:50:15,480
compositional setup

1576
00:50:15,480 --> 00:50:17,040
and so there you start to wonder about

1577
00:50:17,040 --> 00:50:19,380
which of these the Pearl style of dating

1578
00:50:19,380 --> 00:50:21,300
or the Jeffree style updating is more

1579
00:50:21,300 --> 00:50:22,740
natural to think of that in the context

1580
00:50:22,740 --> 00:50:24,060
of cognition

1581
00:50:24,060 --> 00:50:26,520
and maybe we'll say okay one really BFE

1582
00:50:26,520 --> 00:50:28,079
updating is the one you should be

1583
00:50:28,079 --> 00:50:29,520
thinking about that's probably the claim

1584
00:50:29,520 --> 00:50:32,099
active infants would make but it should

1585
00:50:32,099 --> 00:50:33,540
be nice to think about how this relates

1586
00:50:33,540 --> 00:50:35,280
to the other two is it better support of

1587
00:50:35,280 --> 00:50:37,079
this approximating the former or the

1588
00:50:37,079 --> 00:50:41,520
latter style of sort of precise updating

1589
00:50:41,520 --> 00:50:43,140
and then finally we can try and connect

1590
00:50:43,140 --> 00:50:45,540
this up to as much lots of further

1591
00:50:45,540 --> 00:50:47,760
topics I mentioned um I continue I'm

1592
00:50:47,760 --> 00:50:48,839
interested in this notion of

1593
00:50:48,839 --> 00:50:50,579
compositional intelligence so it would

1594
00:50:50,579 --> 00:50:52,619
be nice to to connect this now to topics

1595
00:50:52,619 --> 00:50:54,720
in Ai and so on

1596
00:50:54,720 --> 00:50:56,700
um and think about how it relates to

1597
00:50:56,700 --> 00:50:58,440
other basically applications of category

1598
00:50:58,440 --> 00:51:01,140
theory in AI in particular this is also

1599
00:51:01,140 --> 00:51:03,000
this whole world of categorical

1600
00:51:03,000 --> 00:51:05,579
cybernetics I mentioned at the beginning

1601
00:51:05,579 --> 00:51:07,260
um and I'd like to connect this a bit

1602
00:51:07,260 --> 00:51:08,460
more precisely with what people are

1603
00:51:08,460 --> 00:51:09,960
doing there with their stories in terms

1604
00:51:09,960 --> 00:51:11,700
of lenses and so on

1605
00:51:11,700 --> 00:51:13,380
and something else we were also

1606
00:51:13,380 --> 00:51:15,180
interested in that I mentioned is that

1607
00:51:15,180 --> 00:51:16,920
we got into the topic by thinking about

1608
00:51:16,920 --> 00:51:19,980
Consciousness and there's lots of ways

1609
00:51:19,980 --> 00:51:21,599
as a major theory of cognition there's

1610
00:51:21,599 --> 00:51:22,920
been just loads of reversals for how

1611
00:51:22,920 --> 00:51:24,660
active inference is related to

1612
00:51:24,660 --> 00:51:26,579
Consciousness and it'd be nice to see

1613
00:51:26,579 --> 00:51:28,800
how those can be described formally and

1614
00:51:28,800 --> 00:51:30,480
in this setup and however the streaming

1615
00:51:30,480 --> 00:51:32,819
diagrammatic approach helps you make any

1616
00:51:32,819 --> 00:51:34,500
more sense of those so that's something

1617
00:51:34,500 --> 00:51:37,079
we'd love to do in future

1618
00:51:37,079 --> 00:51:38,280
um and I just like to say thanks again

1619
00:51:38,280 --> 00:51:41,040
to all of you for listening and yep I'd

1620
00:51:41,040 --> 00:51:44,180
love to go to a discussion thanks

1621
00:51:47,579 --> 00:51:49,500
thank you Sean for the wonderful

1622
00:51:49,500 --> 00:51:51,420
presentation

1623
00:51:51,420 --> 00:51:55,800
thank you I will first pass to Ali for

1624
00:51:55,800 --> 00:51:59,099
opening remark

1625
00:51:59,099 --> 00:52:01,460
please

1626
00:52:01,920 --> 00:52:04,559
uh thank you Daniel

1627
00:52:04,559 --> 00:52:06,480
um thanks so much Sean for your really

1628
00:52:06,480 --> 00:52:09,660
fascinating uh presentation

1629
00:52:09,660 --> 00:52:12,599
um I truly enjoyed it uh so I have a

1630
00:52:12,599 --> 00:52:15,540
number of questions uh so let me Begin

1631
00:52:15,540 --> 00:52:17,099
by asking

1632
00:52:17,099 --> 00:52:19,680
um uh the first one

1633
00:52:19,680 --> 00:52:22,980
um so you know uh when Bob kirkey and

1634
00:52:22,980 --> 00:52:25,800
others uh took hamiltonian formulation

1635
00:52:25,800 --> 00:52:28,980
of quantum mechanics and uh kind of

1636
00:52:28,980 --> 00:52:32,280
turned it into uh the string diagram

1637
00:52:32,280 --> 00:52:34,380
formulation of it

1638
00:52:34,380 --> 00:52:38,040
um namely ZX calculus uh the claim was

1639
00:52:38,040 --> 00:52:40,440
that I mean regardless of its possible

1640
00:52:40,440 --> 00:52:44,520
Verity but the claim was that one of the

1641
00:52:44,520 --> 00:52:46,680
advantages of looking at quantum

1642
00:52:46,680 --> 00:52:50,819
mechanics in terms of string diagrams is

1643
00:52:50,819 --> 00:52:54,720
uh is more than uh it's more than just a

1644
00:52:54,720 --> 00:52:57,480
convenient way of looking at a Quantum

1645
00:52:57,480 --> 00:53:01,380
formulation and it actually unveils some

1646
00:53:01,380 --> 00:53:04,260
properties of quantum mechanics that

1647
00:53:04,260 --> 00:53:07,559
would be uh extremely difficult to see

1648
00:53:07,559 --> 00:53:10,920
with hamiltonian formulation and uh even

1649
00:53:10,920 --> 00:53:14,099
in some of their papers uh they claim

1650
00:53:14,099 --> 00:53:18,540
one one of the reasons for uh somehow

1651
00:53:18,540 --> 00:53:20,040
the

1652
00:53:20,040 --> 00:53:22,920
um stagnant development in Quantum

1653
00:53:22,920 --> 00:53:26,520
Technologies and quantum theory is uh is

1654
00:53:26,520 --> 00:53:29,940
exactly related to uh the difficulty of

1655
00:53:29,940 --> 00:53:33,000
working uh with hamiltonian formulation

1656
00:53:33,000 --> 00:53:36,240
so uh would you say string diagram

1657
00:53:36,240 --> 00:53:38,339
formulation of active inference kind of

1658
00:53:38,339 --> 00:53:42,780
uh takes a similar approach to uh

1659
00:53:42,780 --> 00:53:47,040
somehow providing more than just handy

1660
00:53:47,040 --> 00:53:49,319
tool for representing active inference

1661
00:53:49,319 --> 00:53:52,980
modeling and actually it kind of uh

1662
00:53:52,980 --> 00:53:56,520
opens up new possibilities for further

1663
00:53:56,520 --> 00:53:58,559
developments of active inference Theory

1664
00:53:58,559 --> 00:54:02,520
uh possibilities which would somehow uh

1665
00:54:02,520 --> 00:54:05,339
I don't know impossible or at least

1666
00:54:05,339 --> 00:54:08,240
extremely difficult for the current

1667
00:54:08,240 --> 00:54:10,380
traditional formulation of active

1668
00:54:10,380 --> 00:54:11,579
inference

1669
00:54:11,579 --> 00:54:14,339
um to see in the current formulation of

1670
00:54:14,339 --> 00:54:16,740
active inference

1671
00:54:16,740 --> 00:54:19,319
I think so that's amazing question yeah

1672
00:54:19,319 --> 00:54:20,760
um yeah I would agree I think the the

1673
00:54:20,760 --> 00:54:23,339
you know my the idea for work I also

1674
00:54:23,339 --> 00:54:24,900
actually in this categorical quantum

1675
00:54:24,900 --> 00:54:26,819
mechanics area talked about so string

1676
00:54:26,819 --> 00:54:28,140
diagrams for quantum theory and

1677
00:54:28,140 --> 00:54:30,900
everything and I agree that

1678
00:54:30,900 --> 00:54:32,160
um that language helps you talk about

1679
00:54:32,160 --> 00:54:33,720
other things

1680
00:54:33,720 --> 00:54:36,359
that you would maybe never get around to

1681
00:54:36,359 --> 00:54:38,599
so much in in other mathematical

1682
00:54:38,599 --> 00:54:41,040
conversations of quantum theory these

1683
00:54:41,040 --> 00:54:42,599
are these things that make use of the

1684
00:54:42,599 --> 00:54:45,300
the tensor that the the composition a

1685
00:54:45,300 --> 00:54:46,380
lot so

1686
00:54:46,380 --> 00:54:48,599
if this led to stagnation in quantum

1687
00:54:48,599 --> 00:54:49,740
theories probably because people weren't

1688
00:54:49,740 --> 00:54:51,119
focusing as much on the tensor and

1689
00:54:51,119 --> 00:54:53,339
entanglement and stuff which

1690
00:54:53,339 --> 00:54:56,220
um became very Central obviously like in

1691
00:54:56,220 --> 00:54:57,660
the end that that's what people needed

1692
00:54:57,660 --> 00:54:59,520
to to do Quantum Computing and stuff so

1693
00:54:59,520 --> 00:55:01,680
now you what people are doing with

1694
00:55:01,680 --> 00:55:03,780
quantum theory is includes going for

1695
00:55:03,780 --> 00:55:04,680
computing where they're drawing these

1696
00:55:04,680 --> 00:55:06,359
circuits and so you're drawing they're

1697
00:55:06,359 --> 00:55:08,220
basically you know like string diagrams

1698
00:55:08,220 --> 00:55:09,720
describing sometimes these string

1699
00:55:09,720 --> 00:55:11,220
diagrams sometimes they just use the

1700
00:55:11,220 --> 00:55:12,660
slightly different conventions for

1701
00:55:12,660 --> 00:55:14,339
Quantum circuits but it's similarly a

1702
00:55:14,339 --> 00:55:16,200
compositional language where

1703
00:55:16,200 --> 00:55:19,079
you've got tensor products certainly as

1704
00:55:19,079 --> 00:55:21,660
in things running in parallel states of

1705
00:55:21,660 --> 00:55:22,859
these products so that you can talk

1706
00:55:22,859 --> 00:55:24,900
about entanglement and so on

1707
00:55:24,900 --> 00:55:26,040
um as

1708
00:55:26,040 --> 00:55:27,480
is the language that makes it very

1709
00:55:27,480 --> 00:55:29,819
immediate to to represent that because

1710
00:55:29,819 --> 00:55:31,319
you just draw a box of two eyes you know

1711
00:55:31,319 --> 00:55:33,240
name because entangled State and it

1712
00:55:33,240 --> 00:55:34,440
makes you want to plug these things

1713
00:55:34,440 --> 00:55:36,599
together and compose them

1714
00:55:36,599 --> 00:55:38,099
which is what you want to do in Quantum

1715
00:55:38,099 --> 00:55:39,180
computing

1716
00:55:39,180 --> 00:55:42,300
so I think similarly

1717
00:55:42,300 --> 00:55:43,440
um if you never use that kind of

1718
00:55:43,440 --> 00:55:44,640
language you might

1719
00:55:44,640 --> 00:55:46,920
think of a system often as a fixed thing

1720
00:55:46,920 --> 00:55:48,480
and not about the way it interacts with

1721
00:55:48,480 --> 00:55:50,520
other ones so much and that could lead

1722
00:55:50,520 --> 00:55:51,540
to

1723
00:55:51,540 --> 00:55:52,980
overlooking all sorts of things so

1724
00:55:52,980 --> 00:55:55,680
that's true in any area and I think in

1725
00:55:55,680 --> 00:55:57,240
active inference

1726
00:55:57,240 --> 00:55:59,400
um is certainly very true I think it is

1727
00:55:59,400 --> 00:56:00,960
natural to think compositionally in this

1728
00:56:00,960 --> 00:56:02,520
way because you're

1729
00:56:02,520 --> 00:56:04,079
you're wanting to talk about generative

1730
00:56:04,079 --> 00:56:06,000
models being composed from pieces and

1731
00:56:06,000 --> 00:56:07,680
maybe thinking about how the whole brain

1732
00:56:07,680 --> 00:56:09,540
works in relation to interactions

1733
00:56:09,540 --> 00:56:11,520
between parts of it and so on

1734
00:56:11,520 --> 00:56:13,740
so if you never use this kind of

1735
00:56:13,740 --> 00:56:15,960
compositional view there is stuff you

1736
00:56:15,960 --> 00:56:18,599
would miss I think I think in some sense

1737
00:56:18,599 --> 00:56:21,480
people weren't as behind already because

1738
00:56:21,480 --> 00:56:23,160
they already were working kind of

1739
00:56:23,160 --> 00:56:24,359
compositionally right because they're

1740
00:56:24,359 --> 00:56:26,640
using these Bayesian networks diagrams

1741
00:56:26,640 --> 00:56:28,260
like the dags and the way they're

1742
00:56:28,260 --> 00:56:30,240
normally drawn a very close they're like

1743
00:56:30,240 --> 00:56:31,859
they are basically the string diagrams

1744
00:56:31,859 --> 00:56:34,380
they just don't do the the equations and

1745
00:56:34,380 --> 00:56:37,200
the rewriting of the of the diagrams so

1746
00:56:37,200 --> 00:56:39,720
it's not as far back maybe as quantum

1747
00:56:39,720 --> 00:56:42,059
theory was in the sense that people are

1748
00:56:42,059 --> 00:56:43,859
thinking compositionally but it's like

1749
00:56:43,859 --> 00:56:45,780
it feels I just want to go one step

1750
00:56:45,780 --> 00:56:48,180
further to having a fully compositional

1751
00:56:48,180 --> 00:56:50,339
language or working in where you know

1752
00:56:50,339 --> 00:56:52,020
you have the advantage now that you can

1753
00:56:52,020 --> 00:56:54,119
just talk about taking a whole model and

1754
00:56:54,119 --> 00:56:56,099
plugging it into another one and it has

1755
00:56:56,099 --> 00:56:57,839
a completely clear formal meaning and so

1756
00:56:57,839 --> 00:56:59,640
on which I think is what you want to do

1757
00:56:59,640 --> 00:57:02,400
in areas like active infants so going

1758
00:57:02,400 --> 00:57:03,960
from the diagrams as they're currently

1759
00:57:03,960 --> 00:57:06,000
used to string diagrams is like The

1760
00:57:06,000 --> 00:57:08,400
Logical next step and in terms of new

1761
00:57:08,400 --> 00:57:11,520
stuff it lets you do I think

1762
00:57:11,520 --> 00:57:12,839
um an example with something like this

1763
00:57:12,839 --> 00:57:15,720
open BFE thing I guess so it's

1764
00:57:15,720 --> 00:57:16,500
um

1765
00:57:16,500 --> 00:57:18,059
if you're just always thinking about

1766
00:57:18,059 --> 00:57:19,559
just a generative model meaning on

1767
00:57:19,559 --> 00:57:22,859
without inputs you might not think of a

1768
00:57:22,859 --> 00:57:23,940
notion I'm not saying this is

1769
00:57:23,940 --> 00:57:26,400
necessarily the right notion but you

1770
00:57:26,400 --> 00:57:27,660
might not think about this problem of

1771
00:57:27,660 --> 00:57:28,800
how you want to give your definition for

1772
00:57:28,800 --> 00:57:29,700
some payment

1773
00:57:29,700 --> 00:57:32,520
is allowed to have inputs as well and

1774
00:57:32,520 --> 00:57:33,720
once you have that you know have

1775
00:57:33,720 --> 00:57:35,040
definition you can sort of apply to

1776
00:57:35,040 --> 00:57:37,559
parts of a composite system more easily

1777
00:57:37,559 --> 00:57:39,300
so it becomes

1778
00:57:39,300 --> 00:57:41,400
um more natural to to use

1779
00:57:41,400 --> 00:57:43,260
compositionally so that's the kind of

1780
00:57:43,260 --> 00:57:45,119
thing where without something like

1781
00:57:45,119 --> 00:57:47,819
string diagrams it people can end up

1782
00:57:47,819 --> 00:57:49,500
overlooking it it wouldn't be impossible

1783
00:57:49,500 --> 00:57:51,300
to do without them right you need to

1784
00:57:51,300 --> 00:57:52,680
talk about this notion of a kind of open

1785
00:57:52,680 --> 00:57:54,960
generative model which just means

1786
00:57:54,960 --> 00:57:57,480
throwing away so mechanisms to make

1787
00:57:57,480 --> 00:57:59,339
things be inputs

1788
00:57:59,339 --> 00:58:00,839
um but you could miss it you know and

1789
00:58:00,839 --> 00:58:02,400
you but you really won't once you start

1790
00:58:02,400 --> 00:58:05,480
thinking categorically

1791
00:58:08,700 --> 00:58:10,619
thank you ollie please continue if you

1792
00:58:10,619 --> 00:58:12,859
would like

1793
00:58:14,339 --> 00:58:19,200
uh thanks so much so uh yeah my uh other

1794
00:58:19,200 --> 00:58:22,740
um perhaps related question is

1795
00:58:22,740 --> 00:58:25,680
um I mean comparing uh this kind of

1796
00:58:25,680 --> 00:58:30,599
formulation to uh this recent uh

1797
00:58:30,599 --> 00:58:33,240
formulation of Constructor theory in

1798
00:58:33,240 --> 00:58:35,099
terms of string diagrams or categorical

1799
00:58:35,099 --> 00:58:38,299
formulation of Constructor Theory

1800
00:58:38,299 --> 00:58:41,579
before going into this question uh you

1801
00:58:41,579 --> 00:58:46,559
see you mentioned that this project is a

1802
00:58:46,559 --> 00:58:48,540
part of a larger Pro a larger project

1803
00:58:48,540 --> 00:58:51,420
for developing collective intelligence

1804
00:58:51,420 --> 00:58:56,160
right so uh the similar similar kind of

1805
00:58:56,160 --> 00:58:58,680
situation happens for Constructor theory

1806
00:58:58,680 --> 00:59:02,040
in which it is a kind of meta theory

1807
00:59:02,040 --> 00:59:05,460
that tries to somehow

1808
00:59:05,460 --> 00:59:09,799
um uh discriminate between the uh

1809
00:59:09,799 --> 00:59:13,440
possibilities of physical laws as

1810
00:59:13,440 --> 00:59:17,640
opposed to counterfactual laws and how

1811
00:59:17,640 --> 00:59:19,700
physical laws

1812
00:59:19,700 --> 00:59:24,059
how there can be a theory against for

1813
00:59:24,059 --> 00:59:27,079
the emergence of possible physical laws

1814
00:59:27,079 --> 00:59:32,700
so uh in this sense can you we just say

1815
00:59:32,700 --> 00:59:35,599
this kind of formulation categorical

1816
00:59:35,599 --> 00:59:39,119
category theoretical formulation or

1817
00:59:39,119 --> 00:59:43,020
um possibly this specific string diagram

1818
00:59:43,020 --> 00:59:46,380
formulation of active inference uh or

1819
00:59:46,380 --> 00:59:49,500
maybe other theories of Consciousness it

1820
00:59:49,500 --> 00:59:52,140
can be seen as a kind of providing a

1821
00:59:52,140 --> 00:59:55,500
path toward developing a kind of meta

1822
00:59:55,500 --> 00:59:58,640
Theory Of Consciousness and possibly

1823
00:59:58,640 --> 01:00:02,640
unifying many different strands of uh

1824
01:00:02,640 --> 01:00:06,359
theories of Consciousness into to um

1825
01:00:06,359 --> 01:00:10,920
I don't know a holistic picture that can

1826
01:00:10,920 --> 01:00:12,619
somehow be

1827
01:00:12,619 --> 01:00:14,960
compared and

1828
01:00:14,960 --> 01:00:20,099
positively reconciled with uh with one

1829
01:00:20,099 --> 01:00:23,960
another and ultimately reaching uh the

1830
01:00:23,960 --> 01:00:27,680
ultimate theory of uh Consciousness or

1831
01:00:27,680 --> 01:00:32,640
uh I don't know do you see this line of

1832
01:00:32,640 --> 01:00:36,540
work uh I mean providing

1833
01:00:36,540 --> 01:00:40,200
enough evidence for this line of

1834
01:00:40,200 --> 01:00:44,040
development research or I don't know

1835
01:00:44,040 --> 01:00:46,040
somehow

1836
01:00:46,040 --> 01:00:49,319
maybe even not specifically

1837
01:00:49,319 --> 01:00:52,559
Consciousness but uh unifying the

1838
01:00:52,559 --> 01:00:55,020
different aspects of

1839
01:00:55,020 --> 01:00:57,900
um cognition intelligence and

1840
01:00:57,900 --> 01:01:02,040
Consciousness all together so

1841
01:01:02,400 --> 01:01:04,400
um

1842
01:01:05,359 --> 01:01:08,640
keep giving me like ideal um selling

1843
01:01:08,640 --> 01:01:10,619
points so yeah there's also something I

1844
01:01:10,619 --> 01:01:12,180
would I would like to say you know I

1845
01:01:12,180 --> 01:01:13,559
mean that that um

1846
01:01:13,559 --> 01:01:16,440
yeah I I tend to think of it that way in

1847
01:01:16,440 --> 01:01:18,299
that you know my background is in

1848
01:01:18,299 --> 01:01:20,280
applying category to just lots of topics

1849
01:01:20,280 --> 01:01:22,680
and I so naturally do think of it as

1850
01:01:22,680 --> 01:01:25,559
quite a unifying language and you know

1851
01:01:25,559 --> 01:01:27,240
the the ground and Consciousness that I

1852
01:01:27,240 --> 01:01:29,400
mentioned was building on earlier what

1853
01:01:29,400 --> 01:01:30,780
we did on looking at integrated

1854
01:01:30,780 --> 01:01:32,339
information Theory Of Consciousness

1855
01:01:32,339 --> 01:01:34,500
which in the end basically was done in

1856
01:01:34,500 --> 01:01:36,180
terms of categorical probability so it's

1857
01:01:36,180 --> 01:01:39,420
like the same setup of the diagrams and

1858
01:01:39,420 --> 01:01:41,040
so we kind of wanted to do the same

1859
01:01:41,040 --> 01:01:44,040
thing for directive inference so

1860
01:01:44,040 --> 01:01:44,819
um

1861
01:01:44,819 --> 01:01:46,440
there it's like we've taken both of

1862
01:01:46,440 --> 01:01:47,460
these things and put them in this common

1863
01:01:47,460 --> 01:01:49,020
language you could have put them in a

1864
01:01:49,020 --> 01:01:50,339
Common Language a probability Theory

1865
01:01:50,339 --> 01:01:52,260
before but I think you know I do have an

1866
01:01:52,260 --> 01:01:54,000
intuition that

1867
01:01:54,000 --> 01:01:56,040
um there is something more clear about

1868
01:01:56,040 --> 01:01:57,720
it does make it easier to get a

1869
01:01:57,720 --> 01:01:59,400
conceptual graph but if there's I think

1870
01:01:59,400 --> 01:02:01,140
once you've done it this way and

1871
01:02:01,140 --> 01:02:03,059
somehow also yeah the diagrammatic view

1872
01:02:03,059 --> 01:02:04,740
does make it much easier to compare them

1873
01:02:04,740 --> 01:02:06,839
so the Hope was basically to

1874
01:02:06,839 --> 01:02:08,819
you know it still is to keep going and

1875
01:02:08,819 --> 01:02:10,020
to keep

1876
01:02:10,020 --> 01:02:11,760
understanding various Notions in that

1877
01:02:11,760 --> 01:02:13,319
language those things I've looked at on

1878
01:02:13,319 --> 01:02:15,240
cognitive science I've also done this

1879
01:02:15,240 --> 01:02:17,640
way since the three of them conceptual

1880
01:02:17,640 --> 01:02:18,980
spaces

1881
01:02:18,980 --> 01:02:21,720
have worked on creating that in terms of

1882
01:02:21,720 --> 01:02:23,520
diagrams and so on so I would love to

1883
01:02:23,520 --> 01:02:26,099
see basically many theories put into

1884
01:02:26,099 --> 01:02:27,839
this language to make it easier to

1885
01:02:27,839 --> 01:02:29,819
compare them yeah you could try and

1886
01:02:29,819 --> 01:02:31,859
compelling directly already but I think

1887
01:02:31,859 --> 01:02:33,960
you want one clear formalization to put

1888
01:02:33,960 --> 01:02:35,760
them all in and I would say that the

1889
01:02:35,760 --> 01:02:37,740
categories and the diagrams is the right

1890
01:02:37,740 --> 01:02:39,900
one to pick because

1891
01:02:39,900 --> 01:02:41,760
um it tends to just give a very clear

1892
01:02:41,760 --> 01:02:43,920
conceptual view of things the question

1893
01:02:43,920 --> 01:02:45,480
is whether you have some Theory that's

1894
01:02:45,480 --> 01:02:47,099
very important where

1895
01:02:47,099 --> 01:02:48,780
the things categories are good at just

1896
01:02:48,780 --> 01:02:49,859
doesn't quite

1897
01:02:49,859 --> 01:02:51,480
capture the essence of what you want to

1898
01:02:51,480 --> 01:02:53,040
talk about there but for things like

1899
01:02:53,040 --> 01:02:54,480
active inference and

1900
01:02:54,480 --> 01:02:57,599
and IIT so far it's it's very natural

1901
01:02:57,599 --> 01:02:59,880
because on a case of IIT it's about

1902
01:02:59,880 --> 01:03:01,140
talking about how integrated something

1903
01:03:01,140 --> 01:03:02,760
is so you basically want to talk about

1904
01:03:02,760 --> 01:03:04,500
the opposite of that which is something

1905
01:03:04,500 --> 01:03:06,599
being decomposed and the diagrams

1906
01:03:06,599 --> 01:03:08,339
basically that you talk about parts and

1907
01:03:08,339 --> 01:03:09,240
how they're related which is what you

1908
01:03:09,240 --> 01:03:10,619
need to make sense of that notion of

1909
01:03:10,619 --> 01:03:13,440
integration so it's very natural there

1910
01:03:13,440 --> 01:03:15,000
but yeah I would love to basically to

1911
01:03:15,000 --> 01:03:17,400
see um various aspects of cognitive

1912
01:03:17,400 --> 01:03:19,140
science

1913
01:03:19,140 --> 01:03:21,299
um understood categorically that's

1914
01:03:21,299 --> 01:03:24,480
something I'd love to do myself as well

1915
01:03:24,480 --> 01:03:25,140
um

1916
01:03:25,140 --> 01:03:28,140
and as a you know the hope would be then

1917
01:03:28,140 --> 01:03:30,420
to try and gain insights from all of

1918
01:03:30,420 --> 01:03:32,099
them you know and build a theory it's

1919
01:03:32,099 --> 01:03:34,799
not the category Theory itself is a

1920
01:03:34,799 --> 01:03:36,599
theory of cognition or Consciousness

1921
01:03:36,599 --> 01:03:38,460
it's just a very useful language for

1922
01:03:38,460 --> 01:03:40,799
relating them and then

1923
01:03:40,799 --> 01:03:42,660
it would be very exciting to see

1924
01:03:42,660 --> 01:03:44,520
something you know natively defined in

1925
01:03:44,520 --> 01:03:46,500
terms of Academy Theory as well at the

1926
01:03:46,500 --> 01:03:47,520
end

1927
01:03:47,520 --> 01:03:48,780
and there's a feeling that some of

1928
01:03:48,780 --> 01:03:50,099
what's going on in applied categories

1929
01:03:50,099 --> 01:03:52,020
Theory I think like in categorical

1930
01:03:52,020 --> 01:03:54,119
cybernetics and so on is kind of taking

1931
01:03:54,119 --> 01:03:57,240
that that approach for perhaps some of

1932
01:03:57,240 --> 01:03:58,859
the first time previously I've always

1933
01:03:58,859 --> 01:04:00,119
thought category theory is basically

1934
01:04:00,119 --> 01:04:01,619
take existing things and you get a

1935
01:04:01,619 --> 01:04:04,079
really nice abstract view of them but

1936
01:04:04,079 --> 01:04:05,819
now I think if people are comfortable

1937
01:04:05,819 --> 01:04:07,380
enough with it that they're like sort of

1938
01:04:07,380 --> 01:04:09,299
defining things categorically from from

1939
01:04:09,299 --> 01:04:14,000
the outset in areas like that yeah

1940
01:04:15,420 --> 01:04:18,619
awesome well

1941
01:04:18,720 --> 01:04:21,960
yeah I I have many thank you that's a

1942
01:04:21,960 --> 01:04:23,640
great question there's like ideal

1943
01:04:23,640 --> 01:04:25,879
questions

1944
01:04:26,359 --> 01:04:29,400
you've pointed and we've explored a

1945
01:04:29,400 --> 01:04:31,079
little bit of the utility and the

1946
01:04:31,079 --> 01:04:32,819
Simplicity and how that could help with

1947
01:04:32,819 --> 01:04:34,740
accessibility and rigor and

1948
01:04:34,740 --> 01:04:37,220
applicability all these awesome things

1949
01:04:37,220 --> 01:04:39,079
leading to

1950
01:04:39,079 --> 01:04:42,559
reaccounting and reframing consolidating

1951
01:04:42,559 --> 01:04:46,500
as well as discovering some new trails

1952
01:04:46,500 --> 01:04:49,319
between for example expected free energy

1953
01:04:49,319 --> 01:04:51,660
and variational free energy

1954
01:04:51,660 --> 01:04:54,000
looking at the equations you might be

1955
01:04:54,000 --> 01:04:55,859
able to say that they rhyme

1956
01:04:55,859 --> 01:04:58,760
but you would be many many lines deep

1957
01:04:58,760 --> 01:05:03,140
into understanding what if any

1958
01:05:03,140 --> 01:05:06,240
generalizations could Encompass the both

1959
01:05:06,240 --> 01:05:07,200
of them

1960
01:05:07,200 --> 01:05:09,299
so that that was just a very

1961
01:05:09,299 --> 01:05:12,740
Salient example

1962
01:05:12,780 --> 01:05:16,440
a few different kinds of questions so

1963
01:05:16,440 --> 01:05:19,140
how is time treated

1964
01:05:19,140 --> 01:05:22,380
in category Theory or how does active

1965
01:05:22,380 --> 01:05:24,839
inference treat time today

1966
01:05:24,839 --> 01:05:27,599
and how do you see the way that time is

1967
01:05:27,599 --> 01:05:29,940
treated we talk about discrete time and

1968
01:05:29,940 --> 01:05:31,920
continuous time generative models then

1969
01:05:31,920 --> 01:05:34,040
there's the past present and future

1970
01:05:34,040 --> 01:05:36,420
multi-agent systems Federated or

1971
01:05:36,420 --> 01:05:38,760
asynchronous communication so how is

1972
01:05:38,760 --> 01:05:40,200
time treated

1973
01:05:40,200 --> 01:05:42,420
and how does that give us a different

1974
01:05:42,420 --> 01:05:45,839
grasp on dynamical modeling

1975
01:05:45,839 --> 01:05:46,680
um

1976
01:05:46,680 --> 01:05:48,839
thank you I think that's already

1977
01:05:48,839 --> 01:05:50,700
I'd love to have a better answer for

1978
01:05:50,700 --> 01:05:51,780
that basically I think it's a tough one

1979
01:05:51,780 --> 01:05:53,099
you know so at the moment yeah in the

1980
01:05:53,099 --> 01:05:53,940
talk so far I've just talked about

1981
01:05:53,940 --> 01:05:56,339
discrete time and that's sort of very

1982
01:05:56,339 --> 01:05:59,760
easy to treatment Invasion network setup

1983
01:05:59,760 --> 01:06:01,380
and with the these kind of thing

1984
01:06:01,380 --> 01:06:03,059
diagrams because you can just lay out

1985
01:06:03,059 --> 01:06:06,059
the discrete time steps as processes in

1986
01:06:06,059 --> 01:06:07,440
your picture like we see here where we

1987
01:06:07,440 --> 01:06:09,900
have the end and time steps here

1988
01:06:09,900 --> 01:06:11,400
but

1989
01:06:11,400 --> 01:06:13,500
um I don't have anything

1990
01:06:13,500 --> 01:06:15,960
satisfying worked out yet to say about

1991
01:06:15,960 --> 01:06:17,460
how you would treat

1992
01:06:17,460 --> 01:06:19,440
a continuous time case search I think is

1993
01:06:19,440 --> 01:06:20,940
important in active inference you'd like

1994
01:06:20,940 --> 01:06:23,220
to basically

1995
01:06:23,220 --> 01:06:24,839
um

1996
01:06:24,839 --> 01:06:26,460
take I guess basically what you want to

1997
01:06:26,460 --> 01:06:28,200
do is take the way that you describe

1998
01:06:28,200 --> 01:06:30,059
this thing with the end time steps and

1999
01:06:30,059 --> 01:06:32,039
kind of have a form of folding it

2000
01:06:32,039 --> 01:06:33,119
together and just say okay but you're

2001
01:06:33,119 --> 01:06:35,099
unpacking this thing end times

2002
01:06:35,099 --> 01:06:36,960
and then you can take that thing and

2003
01:06:36,960 --> 01:06:38,819
imagine you know this abstract view of

2004
01:06:38,819 --> 01:06:40,859
unpacking it just not discreetly anymore

2005
01:06:40,859 --> 01:06:42,900
in this continuous way so that you can

2006
01:06:42,900 --> 01:06:45,180
capture something like a differential

2007
01:06:45,180 --> 01:06:47,160
equation and a definition of continuous

2008
01:06:47,160 --> 01:06:49,740
time thing and active inference

2009
01:06:49,740 --> 01:06:50,460
um

2010
01:06:50,460 --> 01:06:53,220
I

2011
01:06:53,220 --> 01:06:54,780
um

2012
01:06:54,780 --> 01:06:56,880
yeah so you can certainly work with

2013
01:06:56,880 --> 01:06:58,680
continuous time thinking in the sense of

2014
01:06:58,680 --> 01:06:59,940
you know the stuff going on in

2015
01:06:59,940 --> 01:07:01,559
categorical cybernetics or sort of

2016
01:07:01,559 --> 01:07:03,299
categorical systems cereal I guess it

2017
01:07:03,299 --> 01:07:06,900
would be called act world is kind of you

2018
01:07:06,900 --> 01:07:09,119
know it has continuous time dynamical

2019
01:07:09,119 --> 01:07:10,559
systems and talks about plugging them

2020
01:07:10,559 --> 01:07:13,020
together but that that diagram is sort

2021
01:07:13,020 --> 01:07:14,760
of just relating their variables though

2022
01:07:14,760 --> 01:07:17,280
is my understanding it's not like the

2023
01:07:17,280 --> 01:07:20,280
diagram isn't exactly showing the time

2024
01:07:20,280 --> 01:07:22,079
and in some sense they kind of have to

2025
01:07:22,079 --> 01:07:23,880
synchronize I think you know it's not an

2026
01:07:23,880 --> 01:07:25,920
area I'm totally familiar with so it

2027
01:07:25,920 --> 01:07:27,480
would be yeah it would have been really

2028
01:07:27,480 --> 01:07:29,039
really cool basically

2029
01:07:29,039 --> 01:07:30,720
have this work and then have another

2030
01:07:30,720 --> 01:07:33,299
part of it talking about

2031
01:07:33,299 --> 01:07:34,740
you know like we've done for discrete

2032
01:07:34,740 --> 01:07:36,240
time here having a nice description of

2033
01:07:36,240 --> 01:07:38,520
of a continuous time case I think it

2034
01:07:38,520 --> 01:07:41,099
will end up being some some work to take

2035
01:07:41,099 --> 01:07:43,020
that into account

2036
01:07:43,020 --> 01:07:45,839
um there would be really nice to see so

2037
01:07:45,839 --> 01:07:47,400
it just needs the right abstraction I

2038
01:07:47,400 --> 01:07:49,079
think or

2039
01:07:49,079 --> 01:07:51,359
yeah taking a picture like this not

2040
01:07:51,359 --> 01:07:53,520
drawing the time steps as like bits in

2041
01:07:53,520 --> 01:07:55,500
your diagram but just saying

2042
01:07:55,500 --> 01:07:57,359
you know that it's like this B thing

2043
01:07:57,359 --> 01:07:59,520
with like a feedback loop basically is

2044
01:07:59,520 --> 01:08:01,380
what this is describing and then giving

2045
01:08:01,380 --> 01:08:03,480
a semantics to that in terms of time

2046
01:08:03,480 --> 01:08:05,160
evolution

2047
01:08:05,160 --> 01:08:06,599
um to give a continuous version of this

2048
01:08:06,599 --> 01:08:08,880
for example with like State confirming

2049
01:08:08,880 --> 01:08:11,059
continuously in observations

2050
01:08:11,059 --> 01:08:14,220
for each time step

2051
01:08:14,220 --> 01:08:15,960
um in general I wouldn't say there's

2052
01:08:15,960 --> 01:08:17,939
like an answer to the question of how is

2053
01:08:17,939 --> 01:08:19,560
time treated in category Theory there

2054
01:08:19,560 --> 01:08:20,698
wouldn't really be one answer because

2055
01:08:20,698 --> 01:08:23,279
categories can be so generally

2056
01:08:23,279 --> 01:08:24,719
um they tend to be very effective for

2057
01:08:24,719 --> 01:08:26,520
the just for discrete things in general

2058
01:08:26,520 --> 01:08:29,399
like like algebra and so on because they

2059
01:08:29,399 --> 01:08:31,799
kind of are screen in some sense that

2060
01:08:31,799 --> 01:08:33,540
the composition is discrete so

2061
01:08:33,540 --> 01:08:35,580
continuous aspects and things like

2062
01:08:35,580 --> 01:08:37,920
continuous time tend to be more

2063
01:08:37,920 --> 01:08:39,479
difficult in a sense or they're just

2064
01:08:39,479 --> 01:08:42,000
sort of inside the morphisms as it were

2065
01:08:42,000 --> 01:08:43,080
they're not

2066
01:08:43,080 --> 01:08:45,120
in the composition so it doesn't end up

2067
01:08:45,120 --> 01:08:46,500
looking like this when you're composing

2068
01:08:46,500 --> 01:08:48,600
continuously

2069
01:08:48,600 --> 01:08:49,439
um

2070
01:08:49,439 --> 01:08:52,020
but yeah I think there will be people in

2071
01:08:52,020 --> 01:08:54,319
act who've sort of

2072
01:08:54,319 --> 01:08:56,339
would come come at you with this

2073
01:08:56,339 --> 01:08:58,859
particular answer so they've got a way

2074
01:08:58,859 --> 01:09:01,198
they like to treat continuous time

2075
01:09:01,198 --> 01:09:03,540
um no I'm I'm just not familiar with

2076
01:09:03,540 --> 01:09:05,399
yeah yeah

2077
01:09:05,399 --> 01:09:06,660
cool

2078
01:09:06,660 --> 01:09:09,600
a little bit of a more educational or

2079
01:09:09,600 --> 01:09:11,100
applied question

2080
01:09:11,100 --> 01:09:14,399
so how do we go about drawing and

2081
01:09:14,399 --> 01:09:16,620
learning to draw is there a software

2082
01:09:16,620 --> 01:09:19,380
package is there a way that we can get a

2083
01:09:19,380 --> 01:09:22,799
step-by-step process to building that

2084
01:09:22,799 --> 01:09:25,080
familiarity with like when I see this

2085
01:09:25,080 --> 01:09:27,960
shape then here's what I know and then

2086
01:09:27,960 --> 01:09:31,020
how do we know what we can and can't do

2087
01:09:31,020 --> 01:09:35,060
and does that drawing software flag us

2088
01:09:35,060 --> 01:09:38,339
or do we need to send it to a friend so

2089
01:09:38,339 --> 01:09:39,960
how do we look at something and then

2090
01:09:39,960 --> 01:09:43,560
part one build up the motifs in our own

2091
01:09:43,560 --> 01:09:47,939
aesthetic understanding so that we can

2092
01:09:47,939 --> 01:09:50,279
understand the compositionality of this

2093
01:09:50,279 --> 01:09:52,679
as you do today and as we all do today

2094
01:09:52,679 --> 01:09:55,320
for example for language English

2095
01:09:55,320 --> 01:09:58,980
and then part two how do we go from

2096
01:09:58,980 --> 01:10:01,440
having built that Motif based

2097
01:10:01,440 --> 01:10:04,739
compositional understanding to like

2098
01:10:04,739 --> 01:10:07,980
now what can we do and then when are we

2099
01:10:07,980 --> 01:10:11,040
just totally freewheeling and off the

2100
01:10:11,040 --> 01:10:12,719
rails or the free energy principle or

2101
01:10:12,719 --> 01:10:14,820
like Does anything go if the motifs

2102
01:10:14,820 --> 01:10:16,560
allow it

2103
01:10:16,560 --> 01:10:18,960
um yeah I wish I I should I should have

2104
01:10:18,960 --> 01:10:20,580
a standard answer the best way to learn

2105
01:10:20,580 --> 01:10:22,140
string diagrams I think if I'm going to

2106
01:10:22,140 --> 01:10:23,280
talk about it like this so you've

2107
01:10:23,280 --> 01:10:25,380
prompted me to to come up with that I

2108
01:10:25,380 --> 01:10:26,580
don't have something on top of my head

2109
01:10:26,580 --> 01:10:27,780
that's the best way but there's so much

2110
01:10:27,780 --> 01:10:30,300
stuff out there you know if you're I

2111
01:10:30,300 --> 01:10:32,159
think it tends to be because

2112
01:10:32,159 --> 01:10:33,719
yeah if you want to get really

2113
01:10:33,719 --> 01:10:34,800
comfortable with the diagrams he was

2114
01:10:34,800 --> 01:10:36,300
learning category theory in some sense

2115
01:10:36,300 --> 01:10:37,980
but it's not like you need to learn all

2116
01:10:37,980 --> 01:10:39,540
of category Theory it's kind of a

2117
01:10:39,540 --> 01:10:41,580
relatively modern offshoot in this

2118
01:10:41,580 --> 01:10:43,260
applied category very well that's very

2119
01:10:43,260 --> 01:10:45,179
diagrammatically focused

2120
01:10:45,179 --> 01:10:47,340
and there will be various nice

2121
01:10:47,340 --> 01:10:50,580
introductions out there to using them

2122
01:10:50,580 --> 01:10:53,580
um another way is to so

2123
01:10:53,580 --> 01:10:56,040
I'm trying to think I'm pretty sure

2124
01:10:56,040 --> 01:10:57,420
recently yeah there was a nice figure

2125
01:10:57,420 --> 01:10:58,560
that came out there was an introduction

2126
01:10:58,560 --> 01:10:59,699
to string diagrams for computer

2127
01:10:59,699 --> 01:11:01,380
scientists for example so there tends to

2128
01:11:01,380 --> 01:11:03,000
be different introductions kind of for

2129
01:11:03,000 --> 01:11:04,440
different audiences because they just

2130
01:11:04,440 --> 01:11:06,900
want to pick categories

2131
01:11:06,900 --> 01:11:09,120
um that

2132
01:11:09,120 --> 01:11:11,400
um that those people are familiar with

2133
01:11:11,400 --> 01:11:12,360
right so they can actually have some

2134
01:11:12,360 --> 01:11:13,920
examples you could just learn the

2135
01:11:13,920 --> 01:11:15,360
diagrams totally up straightly but it

2136
01:11:15,360 --> 01:11:17,520
helps to have some examples

2137
01:11:17,520 --> 01:11:19,440
um and you know the old category three

2138
01:11:19,440 --> 01:11:21,000
textbooks are all things mathematicians

2139
01:11:21,000 --> 01:11:22,620
have looked at and a lot of people

2140
01:11:22,620 --> 01:11:23,880
haven't heard of so they're not

2141
01:11:23,880 --> 01:11:25,679
particularly helpful so there's like you

2142
01:11:25,679 --> 01:11:27,600
know Bob has paper categories for the

2143
01:11:27,600 --> 01:11:28,860
practicing physicist it's aim to

2144
01:11:28,860 --> 01:11:29,760
physicists that would basically

2145
01:11:29,760 --> 01:11:31,140
introduce string diagrams to them

2146
01:11:31,140 --> 01:11:33,300
there's this recent computer science one

2147
01:11:33,300 --> 01:11:35,640
I know there's some work going on in

2148
01:11:35,640 --> 01:11:37,320
producing one for cognitive science

2149
01:11:37,320 --> 01:11:39,719
which I think would be really good

2150
01:11:39,719 --> 01:11:42,360
um having an introduction yeah to the to

2151
01:11:42,360 --> 01:11:44,699
the string diagrams for those people

2152
01:11:44,699 --> 01:11:46,199
um so you basically look for one in an

2153
01:11:46,199 --> 01:11:47,820
area you're comfortable with and if you

2154
01:11:47,820 --> 01:11:50,219
find it in paper on it but

2155
01:11:50,219 --> 01:11:52,260
um it would be nice to have a good

2156
01:11:52,260 --> 01:11:53,880
online resource I guess right that

2157
01:11:53,880 --> 01:11:56,040
gathers these together so people can can

2158
01:11:56,040 --> 01:11:58,080
just see a great guide for the all the

2159
01:11:58,080 --> 01:11:59,219
introductions

2160
01:11:59,219 --> 01:12:01,860
if you do something like um

2161
01:12:01,860 --> 01:12:03,480
yeah there's courses you can do in a

2162
01:12:03,480 --> 01:12:06,019
sense of the

2163
01:12:06,300 --> 01:12:08,280
um Bobs but but in the case of learning

2164
01:12:08,280 --> 01:12:09,719
Quantum there's something like Bob's

2165
01:12:09,719 --> 01:12:11,460
long book about Kissinger picturing

2166
01:12:11,460 --> 01:12:13,620
contemporary processors that's the kind

2167
01:12:13,620 --> 01:12:16,380
of thing I learned from like it was in

2168
01:12:16,380 --> 01:12:17,699
the form of electrical so it's basically

2169
01:12:17,699 --> 01:12:19,380
the same book so because then there's

2170
01:12:19,380 --> 01:12:20,760
loads of exercises that will make you

2171
01:12:20,760 --> 01:12:22,800
have to reason with string diagrams and

2172
01:12:22,800 --> 01:12:24,600
then you pick the rules up because at

2173
01:12:24,600 --> 01:12:26,400
first it's yeah you don't you don't have

2174
01:12:26,400 --> 01:12:28,620
the same intuition obviously but the

2175
01:12:28,620 --> 01:12:30,120
rules what can I do with these can I

2176
01:12:30,120 --> 01:12:31,380
slide them around like this or whatever

2177
01:12:31,380 --> 01:12:33,060
but it doesn't take too long to get

2178
01:12:33,060 --> 01:12:34,860
quite used to it I think which is the

2179
01:12:34,860 --> 01:12:36,179
nice thing about them they're kind of

2180
01:12:36,179 --> 01:12:37,980
natural they're just these elastic

2181
01:12:37,980 --> 01:12:40,080
strings and boxes you know and you have

2182
01:12:40,080 --> 01:12:42,360
a sort of geometrical intuition

2183
01:12:42,360 --> 01:12:43,980
depends on the lack of exercises are the

2184
01:12:43,980 --> 01:12:45,540
way I'd recommend getting used to using

2185
01:12:45,540 --> 01:12:46,800
them

2186
01:12:46,800 --> 01:12:49,199
um I didn't use any like software in a

2187
01:12:49,199 --> 01:12:50,400
sense of the diagrams I draw on this

2188
01:12:50,400 --> 01:12:51,480
program called ticks it but it doesn't

2189
01:12:51,480 --> 01:12:53,640
like tell you how string diagrams work

2190
01:12:53,640 --> 01:12:56,219
or anything it's just for drawing them

2191
01:12:56,219 --> 01:13:00,239
um but I know there's more work to

2192
01:13:00,239 --> 01:13:02,640
develop you know libraries like the

2193
01:13:02,640 --> 01:13:04,620
algebraic Julia project is sort of like

2194
01:13:04,620 --> 01:13:07,739
an applied category Theory

2195
01:13:07,739 --> 01:13:10,199
um language but I wouldn't know if it

2196
01:13:10,199 --> 01:13:12,060
was recommended as a way to First learn

2197
01:13:12,060 --> 01:13:13,920
categories

2198
01:13:13,920 --> 01:13:15,060
and

2199
01:13:15,060 --> 01:13:17,340
yeah so I would recommend finding a nice

2200
01:13:17,340 --> 01:13:18,719
introductory paper in whatever field

2201
01:13:18,719 --> 01:13:20,820
you're most used to playing with some

2202
01:13:20,820 --> 01:13:23,340
exercises to get really used to them

2203
01:13:23,340 --> 01:13:25,440
um for causal models there's this paper

2204
01:13:25,440 --> 01:13:27,840
Robin and I put out it's not necessarily

2205
01:13:27,840 --> 01:13:28,980
the very first place to learn screen

2206
01:13:28,980 --> 01:13:31,260
diagrams but the game is to to introduce

2207
01:13:31,260 --> 01:13:33,000
to people who've heard of calls and

2208
01:13:33,000 --> 01:13:34,380
models saying a sense of pearl so it's

2209
01:13:34,380 --> 01:13:36,060
Bayesian networks basically but maybe

2210
01:13:36,060 --> 01:13:38,820
the course interpretation of them

2211
01:13:38,820 --> 01:13:41,520
um to get them used to string diagrams

2212
01:13:41,520 --> 01:13:43,800
and this this paper hopes to be a little

2213
01:13:43,800 --> 01:13:48,020
bit introductory as well yeah

2214
01:13:48,239 --> 01:13:52,040
cool Ollie please

2215
01:13:53,340 --> 01:13:56,159
uh thank you so uh getting back to the

2216
01:13:56,159 --> 01:13:58,440
question about the time representation

2217
01:13:58,440 --> 01:14:02,760
uh in this formulation uh so uh I take

2218
01:14:02,760 --> 01:14:06,179
it that this kind of the formulation of

2219
01:14:06,179 --> 01:14:08,100
Bayesian inference I mean category

2220
01:14:08,100 --> 01:14:10,080
theoretical formulation of Bayesian for

2221
01:14:10,080 --> 01:14:13,560
instance is largely based on Toby Spritz

2222
01:14:13,560 --> 01:14:17,159
definition of Markov uh categories as a

2223
01:14:17,159 --> 01:14:21,719
CD categories right so as far as I

2224
01:14:21,719 --> 01:14:26,840
understand it uh Fritz paper uh kind of

2225
01:14:26,840 --> 01:14:30,659
one of its basic assumptions is this

2226
01:14:30,659 --> 01:14:32,719
kind of unidirectional

2227
01:14:32,719 --> 01:14:35,760
inference I mean from earlier times to

2228
01:14:35,760 --> 01:14:37,500
later times right

2229
01:14:37,500 --> 01:14:41,760
or in other words the prediction uh but

2230
01:14:41,760 --> 01:14:43,560
uh

2231
01:14:43,560 --> 01:14:46,980
um in uh Quantum formulation of active

2232
01:14:46,980 --> 01:14:49,100
inference or

2233
01:14:49,100 --> 01:14:52,980
Quantum active inference uh there's this

2234
01:14:52,980 --> 01:14:56,780
attempt to also develop uh the

2235
01:14:56,780 --> 01:14:59,760
retroduction aspect of inference as well

2236
01:14:59,760 --> 01:15:04,860
right uh so would you say uh this recent

2237
01:15:04,860 --> 01:15:08,300
formulation uh can also be accounted for

2238
01:15:08,300 --> 01:15:12,120
uh for this kind of retroduction you

2239
01:15:12,120 --> 01:15:15,239
know the words uh can this formulation

2240
01:15:15,239 --> 01:15:18,659
be reconciled with a Quantum bayesianism

2241
01:15:18,659 --> 01:15:21,139
as well

2242
01:15:23,179 --> 01:15:26,400
yeah because to add uh one more context

2243
01:15:26,400 --> 01:15:31,020
here uh in uh I think it was in kirkens

2244
01:15:31,020 --> 01:15:33,420
beckon's paper there was this clear

2245
01:15:33,420 --> 01:15:35,580
distinction between classical Bayesian

2246
01:15:35,580 --> 01:15:38,040
uh inference and non-classical Bayesian

2247
01:15:38,040 --> 01:15:41,719
inference uh which the classical one

2248
01:15:41,719 --> 01:15:44,040
does not

2249
01:15:44,040 --> 01:15:48,659
um I mean allow for uh the retroduction

2250
01:15:48,659 --> 01:15:52,020
but non-classical Bayesian inference uh

2251
01:15:52,020 --> 01:15:55,320
can be applied for both prediction and

2252
01:15:55,320 --> 01:15:58,199
retroduction as well

2253
01:15:58,199 --> 01:16:01,140
oh okay yeah I would love to be a bit

2254
01:16:01,140 --> 01:16:03,480
more familiar with the the quantum

2255
01:16:03,480 --> 01:16:06,060
active infant stuff basically to compare

2256
01:16:06,060 --> 01:16:08,520
a bit so I'm not I'm not as familiar

2257
01:16:08,520 --> 01:16:10,260
with the sort of

2258
01:16:10,260 --> 01:16:13,020
and then retro sorry obviously the

2259
01:16:13,020 --> 01:16:14,900
elevation prediction is retro

2260
01:16:14,900 --> 01:16:17,159
retroduction yeah prediction and

2261
01:16:17,159 --> 01:16:19,980
retroduction yeah so I think

2262
01:16:19,980 --> 01:16:21,540
um

2263
01:16:21,540 --> 01:16:23,340
yeah I would have to compare with this

2264
01:16:23,340 --> 01:16:26,400
the another paper member box paper

2265
01:16:26,400 --> 01:16:28,860
problem on both forms of Asian inference

2266
01:16:28,860 --> 01:16:31,679
to see what they say they're about the

2267
01:16:31,679 --> 01:16:33,239
classical one

2268
01:16:33,239 --> 01:16:35,940
um can you give some intuition as to why

2269
01:16:35,940 --> 01:16:37,860
isn't something you can do basically

2270
01:16:37,860 --> 01:16:40,260
basically the the Retro one because if

2271
01:16:40,260 --> 01:16:43,739
that's in general probabilities then it

2272
01:16:43,739 --> 01:16:45,560
will be true in some sense here right so

2273
01:16:45,560 --> 01:16:47,880
you know here it's just being modeled in

2274
01:16:47,880 --> 01:16:49,980
this probabilistic category and so at

2275
01:16:49,980 --> 01:16:51,600
the moment they're separate in that you

2276
01:16:51,600 --> 01:16:52,920
know you have the model which basically

2277
01:16:52,920 --> 01:16:54,060
goes forward and then you do your

2278
01:16:54,060 --> 01:16:55,620
updating to try and

2279
01:16:55,620 --> 01:16:57,600
approximate something going back but you

2280
01:16:57,600 --> 01:17:00,060
don't really have like this one

2281
01:17:00,060 --> 01:17:01,140
um

2282
01:17:01,140 --> 01:17:06,420
yeah yeah so uh so um I mean the whole

2283
01:17:06,420 --> 01:17:09,719
idea was that uh for a predictive uh

2284
01:17:09,719 --> 01:17:12,000
quantum mechanics uh we only need to

2285
01:17:12,000 --> 01:17:14,280
account for the inference from earlier

2286
01:17:14,280 --> 01:17:18,480
times later times but uh if we want to

2287
01:17:18,480 --> 01:17:20,280
account for retroductive quantum

2288
01:17:20,280 --> 01:17:22,800
mechanics as well uh we need to somehow

2289
01:17:22,800 --> 01:17:26,640
uh account for uh because as we know

2290
01:17:26,640 --> 01:17:29,280
um not every

2291
01:17:29,280 --> 01:17:33,000
um I mean Quantum formulation uh follows

2292
01:17:33,000 --> 01:17:35,340
the bell's principle of local causality

2293
01:17:35,340 --> 01:17:40,199
uh so uh that's uh I mean in order to

2294
01:17:40,199 --> 01:17:42,300
account for all the entanglement

2295
01:17:42,300 --> 01:17:44,640
phenomena and so on and we need to

2296
01:17:44,640 --> 01:17:48,239
somehow uh put these this bi-directional

2297
01:17:48,239 --> 01:17:53,040
uh inference into our model uh so uh

2298
01:17:53,040 --> 01:17:55,500
yeah that was the basic idea behind

2299
01:17:55,500 --> 01:17:57,179
developing this kind of non-classical

2300
01:17:57,179 --> 01:17:58,800
Bayesian and Prince

2301
01:17:58,800 --> 01:17:59,580
um

2302
01:17:59,580 --> 01:18:01,260
does it have something to do with like

2303
01:18:01,260 --> 01:18:03,179
the unitary evolution in content Theory

2304
01:18:03,179 --> 01:18:04,860
the way it has this reversible thing or

2305
01:18:04,860 --> 01:18:05,699
is it

2306
01:18:05,699 --> 01:18:09,379
exactly yeah yeah

2307
01:18:09,659 --> 01:18:12,120
that was the interest of it

2308
01:18:12,120 --> 01:18:14,580
yeah and so you don't expect to have

2309
01:18:14,580 --> 01:18:15,540
something like that classically

2310
01:18:15,540 --> 01:18:17,219
basically where you have this

2311
01:18:17,219 --> 01:18:19,199
reversible thing built in well yeah I I

2312
01:18:19,199 --> 01:18:22,440
so I wouldn't expect to see uh

2313
01:18:22,440 --> 01:18:24,179
that exact feature here in the sense of

2314
01:18:24,179 --> 01:18:25,380
you know if it's

2315
01:18:25,380 --> 01:18:27,300
treated if it's basically something that

2316
01:18:27,300 --> 01:18:28,920
you can't uh have in classical

2317
01:18:28,920 --> 01:18:31,140
probabilities it's not gonna it won't

2318
01:18:31,140 --> 01:18:32,760
exist in this category matter plus

2319
01:18:32,760 --> 01:18:34,140
because that's I think that would be

2320
01:18:34,140 --> 01:18:35,340
basically the same category they would

2321
01:18:35,340 --> 01:18:36,960
use in that paper and they were dagger

2322
01:18:36,960 --> 01:18:38,280
combat categories

2323
01:18:38,280 --> 01:18:40,320
and they'll work with metal something

2324
01:18:40,320 --> 01:18:42,120
like this metal plus category but the

2325
01:18:42,120 --> 01:18:44,760
classical case

2326
01:18:44,760 --> 01:18:48,239
um if it's just a general like it's left

2327
01:18:48,239 --> 01:18:49,679
of a sort of physical notion but it's

2328
01:18:49,679 --> 01:18:51,900
just an idea that the the model comes

2329
01:18:51,900 --> 01:18:53,460
with a forward part and an accurate part

2330
01:18:53,460 --> 01:18:55,620
then I think that's the kind of

2331
01:18:55,620 --> 01:18:57,239
here obviously how you go from forward

2332
01:18:57,239 --> 01:18:59,520
path to approximate this backward thing

2333
01:18:59,520 --> 01:19:01,560
but the sort of lens type view of what's

2334
01:19:01,560 --> 01:19:03,840
going on that's more voted in category

2335
01:19:03,840 --> 01:19:06,120
cybernetics would be imagining I think

2336
01:19:06,120 --> 01:19:09,179
the model kind of carrying this backward

2337
01:19:09,179 --> 01:19:11,400
inference process with it as well so

2338
01:19:11,400 --> 01:19:13,320
there it's you know for each forward

2339
01:19:13,320 --> 01:19:15,840
part of the model they would

2340
01:19:15,840 --> 01:19:19,320
um have this approximate inference sort

2341
01:19:19,320 --> 01:19:21,420
of Channel stored with it

2342
01:19:21,420 --> 01:19:22,860
um so I don't know if that would address

2343
01:19:22,860 --> 01:19:24,060
what you're after but it would have

2344
01:19:24,060 --> 01:19:25,679
either a backward and forward part

2345
01:19:25,679 --> 01:19:28,980
together yeah

2346
01:19:30,000 --> 01:19:34,440
well Ollie do you have any kind of

2347
01:19:34,440 --> 01:19:37,620
closing slash opening remarks or

2348
01:19:37,620 --> 01:19:39,360
questions or where where do you see this

2349
01:19:39,360 --> 01:19:41,040
going from the active inference side

2350
01:19:41,040 --> 01:19:44,219
what what is this bring to us

2351
01:19:44,219 --> 01:19:48,360
and what is opened through

2352
01:19:48,360 --> 01:19:50,060
what has happened

2353
01:19:50,060 --> 01:19:53,940
largely this year in active inference

2354
01:19:53,940 --> 01:19:56,040
and category Theory

2355
01:19:56,040 --> 01:19:58,739
well actually I'm really excited to see

2356
01:19:58,739 --> 01:20:01,140
this line of development uh an active

2357
01:20:01,140 --> 01:20:03,840
inference Theory and uh as you know I'm

2358
01:20:03,840 --> 01:20:07,739
a big big fan of meta theories and uh

2359
01:20:07,739 --> 01:20:09,920
all kinds of

2360
01:20:09,920 --> 01:20:14,120
unification theories and so on so uh

2361
01:20:14,120 --> 01:20:18,080
it's uh I don't know I kind of

2362
01:20:18,080 --> 01:20:22,320
have this feeling at this time that this

2363
01:20:22,320 --> 01:20:25,260
line of development in active inference

2364
01:20:25,260 --> 01:20:29,340
uh Theory uh is I mean it looks quite

2365
01:20:29,340 --> 01:20:34,260
promising uh especially for

2366
01:20:34,260 --> 01:20:35,340
um

2367
01:20:35,340 --> 01:20:38,340
kind of tying up all the Loose Ends and

2368
01:20:38,340 --> 01:20:41,340
transcending and many many other areas

2369
01:20:41,340 --> 01:20:45,300
and discourses and ultimately reaching a

2370
01:20:45,300 --> 01:20:48,320
kind of uh coherent picture of

2371
01:20:48,320 --> 01:20:51,800
quote-unquote reality whatever it means

2372
01:20:51,800 --> 01:20:55,860
so uh yeah these kinds of development I

2373
01:20:55,860 --> 01:21:00,560
mean the last year we had a tremendous

2374
01:21:00,560 --> 01:21:05,060
advances in Bayesian mechanical theories

2375
01:21:05,060 --> 01:21:09,600
and in recent month we have this

2376
01:21:09,600 --> 01:21:13,500
fabulous line of research in category

2377
01:21:13,500 --> 01:21:16,679
theoretical accounts of active inference

2378
01:21:16,679 --> 01:21:20,520
My Hope Is that ultimately these

2379
01:21:20,520 --> 01:21:25,260
different strands can be unified into as

2380
01:21:25,260 --> 01:21:28,140
I said coherent and overarching

2381
01:21:28,140 --> 01:21:32,719
framework so exciting times

2382
01:21:37,880 --> 01:21:40,020
so do you mean that you're thinking of

2383
01:21:40,020 --> 01:21:41,280
it as um it sounded like you're

2384
01:21:41,280 --> 01:21:43,199
basically alluding to the

2385
01:21:43,199 --> 01:21:45,239
I think I have working on in cognition

2386
01:21:45,239 --> 01:21:47,280
and work going on into physics going

2387
01:21:47,280 --> 01:21:49,440
together right like one really really

2388
01:21:49,440 --> 01:21:53,699
matter really exactly so yeah the I the

2389
01:21:53,699 --> 01:21:56,520
idea behind Bayesian mechanics uh one of

2390
01:21:56,520 --> 01:21:59,460
its uh premises or assertions was that

2391
01:21:59,460 --> 01:22:03,360
uh there isn't any clear uh distinction

2392
01:22:03,360 --> 01:22:07,219
between uh cognitive and non-cognitive

2393
01:22:07,219 --> 01:22:12,420
things or agents and uh they rest uh and

2394
01:22:12,420 --> 01:22:16,020
a Continuum and it's uh I mean the same

2395
01:22:16,020 --> 01:22:18,480
kind of mathematical technology can be

2396
01:22:18,480 --> 01:22:21,900
applied both for inert and uh conscious

2397
01:22:21,900 --> 01:22:25,380
agents or in the absentient agents uh or

2398
01:22:25,380 --> 01:22:28,020
whatever we choose to call them uh so

2399
01:22:28,020 --> 01:22:32,760
yeah this overarching uh Theory uh I

2400
01:22:32,760 --> 01:22:35,760
mean unveiled many interesting uh

2401
01:22:35,760 --> 01:22:38,780
phenomena regarding uh well

2402
01:22:38,780 --> 01:22:42,719
self-organizing systems and

2403
01:22:42,719 --> 01:22:46,020
um it changed the whole perspective uh

2404
01:22:46,020 --> 01:22:49,860
about how we can look at and Define even

2405
01:22:49,860 --> 01:22:52,040
define consciousness cognition

2406
01:22:52,040 --> 01:22:54,840
intelligence sentience and all of these

2407
01:22:54,840 --> 01:22:59,159
related terms uh so my hope is that uh

2408
01:22:59,159 --> 01:23:01,739
category theoretical accountability

2409
01:23:01,739 --> 01:23:07,260
active inference can also be uh used for

2410
01:23:07,260 --> 01:23:11,300
clearly seeing many of these

2411
01:23:11,300 --> 01:23:15,120
emerging elements in Bayesian mechanics

2412
01:23:15,120 --> 01:23:17,340
and active inference Theory and

2413
01:23:17,340 --> 01:23:18,800
hopefully

2414
01:23:18,800 --> 01:23:21,719
well gaining some

2415
01:23:21,719 --> 01:23:23,340
interesting and potentially

2416
01:23:23,340 --> 01:23:26,699
groundbreaking insights

2417
01:23:26,699 --> 01:23:29,880
that'd be wonderful yeah I

2418
01:23:29,880 --> 01:23:32,400
love to apply for those topics yeah and

2419
01:23:32,400 --> 01:23:34,320
I'd be very curious to see how

2420
01:23:34,320 --> 01:23:35,460
categories can come in there sorry

2421
01:23:35,460 --> 01:23:37,679
Daniel yeah oh yeah I'll just give my

2422
01:23:37,679 --> 01:23:39,480
closing thoughts then then to you Sean

2423
01:23:39,480 --> 01:23:41,760
just just a few loose notes that again

2424
01:23:41,760 --> 01:23:43,940
open probably more than they close

2425
01:23:43,940 --> 01:23:46,800
Ali was right in

2426
01:23:46,800 --> 01:23:49,860
suggesting and and expressing that

2427
01:23:49,860 --> 01:23:52,320
Bayesian mechanics recently has helped

2428
01:23:52,320 --> 01:23:52,980
us

2429
01:23:52,980 --> 01:23:55,739
develop a Continuum of active and

2430
01:23:55,739 --> 01:23:57,600
passive systems so-called living and

2431
01:23:57,600 --> 01:24:00,239
non-living or inanimate and animate and

2432
01:24:00,239 --> 01:24:03,239
that brings us to another dialectic to

2433
01:24:03,239 --> 01:24:05,280
resolve which is life and mind which is

2434
01:24:05,280 --> 01:24:07,260
where the physical and the cognitive

2435
01:24:07,260 --> 01:24:09,300
science come together you said they're

2436
01:24:09,300 --> 01:24:10,920
on a Continuum maybe we could say

2437
01:24:10,920 --> 01:24:12,840
they're on a quantitium

2438
01:24:12,840 --> 01:24:17,400
and what language could express

2439
01:24:17,400 --> 01:24:21,000
such work well right now we're speaking

2440
01:24:21,000 --> 01:24:22,920
in English with the active inference

2441
01:24:22,920 --> 01:24:24,659
ontology dialect

2442
01:24:24,659 --> 01:24:26,580
however the phonemes are not

2443
01:24:26,580 --> 01:24:29,880
intrinsically meaningful the um in a

2444
01:24:29,880 --> 01:24:32,400
Markov blanket or category does not mean

2445
01:24:32,400 --> 01:24:35,300
something it's it's a sound

2446
01:24:35,300 --> 01:24:37,920
and so the

2447
01:24:37,920 --> 01:24:40,500
string diagram language and

2448
01:24:40,500 --> 01:24:42,120
representation

2449
01:24:42,120 --> 01:24:47,000
I see as a way to fuse and integrate

2450
01:24:47,000 --> 01:24:52,140
semantics into the syntax of the actual

2451
01:24:52,140 --> 01:24:54,179
inscription

2452
01:24:54,179 --> 01:24:57,600
which enables us to

2453
01:24:57,600 --> 01:25:00,360
generalize in new ways also recognizing

2454
01:25:00,360 --> 01:25:02,640
string diagrams or not everything or and

2455
01:25:02,640 --> 01:25:03,540
so on

2456
01:25:03,540 --> 01:25:07,320
and then with all of these intersecting

2457
01:25:07,320 --> 01:25:09,420
vectors from cognitive and the physical

2458
01:25:09,420 --> 01:25:11,340
sciences

2459
01:25:11,340 --> 01:25:15,239
we are able to take the compositional

2460
01:25:15,239 --> 01:25:17,640
cartographic approach

2461
01:25:17,640 --> 01:25:21,120
for cognitive ecosystems and talk about

2462
01:25:21,120 --> 01:25:22,980
diverse intelligences

2463
01:25:22,980 --> 01:25:25,500
biological Quantum classical

2464
01:25:25,500 --> 01:25:28,320
architectures all of these synthetic

2465
01:25:28,320 --> 01:25:32,400
intelligences and so it's super exciting

2466
01:25:32,400 --> 01:25:33,600
and

2467
01:25:33,600 --> 01:25:36,239
I appreciate again your visit and look

2468
01:25:36,239 --> 01:25:37,739
forward to

2469
01:25:37,739 --> 01:25:41,159
people's curiosity taking them and also

2470
01:25:41,159 --> 01:25:42,600
the development of tools and educational

2471
01:25:42,600 --> 01:25:45,840
materials that that make this easier and

2472
01:25:45,840 --> 01:25:48,540
then being able to display and use

2473
01:25:48,540 --> 01:25:52,080
something where the meaning

2474
01:25:52,080 --> 01:25:54,840
is primal

2475
01:25:54,840 --> 01:25:57,139
rather than like well this letter

2476
01:25:57,139 --> 01:25:59,840
represents this

2477
01:25:59,840 --> 01:26:02,460
it already introduces such a space

2478
01:26:02,460 --> 01:26:03,780
between

2479
01:26:03,780 --> 01:26:08,400
the analytical representation and

2480
01:26:08,400 --> 01:26:12,300
really the string diagram

2481
01:26:12,300 --> 01:26:15,960
which exists isomorphically with it

2482
01:26:15,960 --> 01:26:18,560
hmm

2483
01:26:19,260 --> 01:26:22,080
yes but it's very exciting way of

2484
01:26:22,080 --> 01:26:23,460
thinking yeah yeah it sounds like you're

2485
01:26:23,460 --> 01:26:24,960
you're um

2486
01:26:24,960 --> 01:26:27,719
advocating a kind of structural ontology

2487
01:26:27,719 --> 01:26:29,159
kind of thing in some sense right

2488
01:26:29,159 --> 01:26:30,840
whether you're taking the

2489
01:26:30,840 --> 01:26:32,280
compositional stretch of what's going on

2490
01:26:32,280 --> 01:26:34,380
to really be the meaning already be the

2491
01:26:34,380 --> 01:26:36,300
the real thing that's there not just

2492
01:26:36,300 --> 01:26:37,260
like

2493
01:26:37,260 --> 01:26:39,239
I don't know yeah we could talk about it

2494
01:26:39,239 --> 01:26:41,460
for a while I'm actually but I would

2495
01:26:41,460 --> 01:26:44,820
love to yeah see string diagrams and you

2496
01:26:44,820 --> 01:26:46,679
know other other approaches I'm sure

2497
01:26:46,679 --> 01:26:48,300
that um

2498
01:26:48,300 --> 01:26:50,159
pick that role and you've got me very

2499
01:26:50,159 --> 01:26:51,540
excited about this kind of unification

2500
01:26:51,540 --> 01:26:54,320
that's going on

2501
01:26:54,719 --> 01:26:56,340
thank you again Sean you're always

2502
01:26:56,340 --> 01:26:58,380
welcome and we look forward to seeing

2503
01:26:58,380 --> 01:26:59,820
where this all goes

2504
01:26:59,820 --> 01:27:01,500
yeah thanks thanks again for having me

2505
01:27:01,500 --> 01:27:04,860
yeah really great discussion thank you

2506
01:27:04,860 --> 01:27:06,380
thank you so much

2507
01:27:06,380 --> 01:27:10,159
all right bye thanks

