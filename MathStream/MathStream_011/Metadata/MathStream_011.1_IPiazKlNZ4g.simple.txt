SPEAKER_00:
hello and welcome it is august 12 2024 and we are in active math stream number 11.1 111111 and with repeat friend toby smythe today we're going to talk about structured active inference there will be a presentation followed by a discussion so thank you toby for joining and everybody for watching and asking questions and looking forward to learning more here so go for it

Cool.

Great.

Thanks, Daniel.


SPEAKER_01:
Thanks for having me on again.

As Daniel says, this is going to be a talk about structured active inference, which is really my account of the structure of active inference systems.

And really, it kind of extends beyond active inference to any kind of system that you could think of as being kind of agential and that has some kind of compositional structure in particular.

But we'll get to that.

Okay.

um the way i like to begin thinking about structure and x inferences at the moment is it's kind of like

If you wanted to model in Active Inference an agent or a person getting onto a bicycle or getting into a car, then I think as things stand, it might be a bit tricky because that process involves changing the agent's Markov blanket, or how I like to think of it is changing the agent's interface.

And to be able to talk about that precisely, you need to have a good notion of what interface is.

you know you as you're you know getting into the getting onto the bike let's say you move you change from you know walking by taking steps one after another to you know um like changing your direction by like leaning and pedaling so the kind of type of actions you can take and the things that you pay attention to change yes because you're now this kind of composite system you and the bicycle and it's a similar story when you get into the car

That really that means that you don't just have one set of observations and one set of actions you can take.

This kind of composing process means that you have to have a bit more flexibility.

And in particular, you need to say precisely what those sets of observations and sets of actions should be.

So the basic idea behind structured active inference is really just to put the ideas of active inference into categorical systems theory.

And so categorical systems theory is just an account of how dynamical systems of very general kind

um yeah are made up of parts and how those parts compose together and it separates out the notion of the system from the notion of its interface and so this allows us to be very precise about what is the kind of agent marker blanket and how does that change

So we inherited a number of features of categorical systems theory in this notion of structured active inference.

In particular, we inherit this kind of idea of structured interface.

And that means not only do we have to be precise about what the interfaces are, but we also are able to say what the structure in some sense of the interface is and how does it change and how does it interact with other kinds of interface.

I'll say a lot more about that in the next few slides.

um because categorical systems theory is all about the composition of systems and their interfaces so is structured active inference and that means that we get a nice kind of modular account of active inference and we can compare active inference with other accounts of agency and we can compare active inference systems of various different kinds in a nice precise way and so that means we could sort of

translate between continuous time and discrete time systems or various different kinds of continuous time or stochastic systems those are all different systems theories of their own and active inference has lots to say about how to do inference and policy selection on those different kinds of systems but categorical systems theory means that we're very precise about what what those different systems and how that inference process works

And so this kind of comparability is formalized by the notion of morphism of systems.

So these morphisms, they come into two kinds in systems theory.

We get morphisms of interface.

Those are the things that allow you to sort of plug yourself into another sort of bigger system in some sense.

That is, as you get onto the car, you get onto the bicycle, you're sort of wiring yourself into this composite human bicycle system.

But they also, these morphisms, they also encompass changing the model, that is changing the model of system, but also changing an individual model itself.

So doing things like structure learning, parameter change, so normal learning, meta learning, or things that we might think of in neuroscience as effective connectivity.

These are all kinds of morphism of system.

And all of this stuff comes out of packaging active inference into this categorical systems theory language.

So with this, we gain a lot of things, not only do we sort of inherit these features, but we gain some nice new capabilities as well.

So I've already talked about what we get from structured interfaces.

So that means that we get systems where you can,

The kinds of actions you take might depend on the situation or context or mode that you're in or that can act on very sort of precisely defined structured interfaces like computer APIs.

We get notions of agents that manage agents in a precise compositional way or sort of meta agents that can use active inference itself to change their structure.

There seems to be an interesting link between

um structure learning as in within one model and and planning as in choosing your sort of policy your series of actions both of those seem to be about composing sequences of morphisms and another thing that comes out of putting active inference into the language of categorical systems theory is that we can also

make contact with categorical logic which can also be applied to categorical systems theory and that means that we can do things like or you know we in principle can do things like specify systems goals as logical predicates um talk about uh contracts that might have to hold between agents or um or sort of uh on their behaviors that you might you might something you might care about if you're interested in safety of artificial intelligences um

And this logic, because it's in this systems theoretic framework, has to be compatible with the patterns of interaction of the systems.

Now, I'm not going to say very much about this because there's really quite a big and open problem, like spelling out all of the details here, but I've got a couple of slides at the end about it.

um and in in that same kind of vein and similar to this notion of policies as kind of being sequences of morphisms um structured active inference because we uh give some kind of typing or context information to the actions that are available that means that we can do things like type checking in principle on policies and that's a kind of rudimentary way to verify the safety of a policy i.e just that it makes sense

So the basic idea of categorical systems theory, this is the math stream, so I'm going to be quite mathematical here.

So there are two ingredients, as I mentioned.

One is that we have a category of interfaces.

So that is just something very syntactic.

It says, OK, here are the interfaces and Markov blankets of all my different systems.

And those interfaces form the object of this category.

And then here are all the ways that these interfaces could link up or connect.

And these wirings, they become the morphisms of this category of interfaces.

But there's no information in the category of interfaces

yeah about the systems themselves it's really just a sort of syntactic gadget for talking about how things connect up and so to to attach systems to interfaces we have what's known as an index category so we have for each

possible interface there's a whole category of systems that might somehow like fill that interface with a system so we think of the interface as like a box and then the index category of systems over that category of interfaces fills that box with an actual system it sort of brings it to life and it being indexed category means that this um

These categories of systems over interfaces have to be compatible with wiring up.

So if you have an interface, one box and another box side by side, and you connect them together using one of the morphisms, you're also able to connect the systems in this way compatibly.

That is, you know, once you've plugged your boxes together, the systems sort of interact in this way accordingly.

um so that allows us to do this kind of um connection of systems um it's not normally just a category we also typically have what's known as the monoidal structure on the category of interfaces and that means that we can place systems side by side we don't just plug systems like one into another we can have like two systems next to each other and then sort of connect them into a bigger system

that is like you know your body is made of lots and lots of cells next to each other but they're all sort of interconnected in parallel and that's that's sort of um um formalized by this monoidal structure which is sometimes called tensor and represented with this symbol here

And so the system's theory again has to be compatible with this tensor, which means if you put two boxes side by side and systems in them, then you also get a system in the sort of composite double box system.

And so to do wiring, really often what happens is you have one box.

I've written it as P here and another box written as P prime.

You put them together into this p tensor p prime.

That means that you can connect a system over this and a system over this into a system over the joint interface.

And then say you've got some wiring.

So wiring would be a morphism p tensor p prime to q.

then the systems theory allows you to take that wiring and wire the systems together accordingly.

And then that means you've got a system on this Q interface.

And so often you see diagrams in systems theory which are a bit like this.

This is P. This is P prime.

This is Q. And then this is some way of wiring the systems together.

And then this is your wiring, and then you've got the systems, and you get a sort of composite system like this.

So I've gone very fast.

This is the basics of categorical systems theory.

As I say, it's a language for talking about building complex systems from their parts in a nice sort of formal compositional mathematical way.

And so what we're going to do is put active inference into this language in a way that generalizes active inference in this sort of quite big new direction that allows for things like mode dependence of actions.

And so to do that, I want to introduce a particular category of interfaces, the category of polynomial functors.

If you know the work of David Spivak and his colleagues, he's a big proponent of this category for talking about things like systems and dynamics.

And so I'm going to adopt his notation in talking about this category.

He calls it poly, and there's a nice book about this by David and Nelson New that you can read.

It's freely available online.

So a polynomial, it's really, again, as I say, it's like a syntactic gadget to talk about the interface of a system.

And it has kind of two key ingredients.

And it's really just like a polynomial that you see in high school algebra.

So it has like a set of summands, which are these like y to the somethings.

And they're indexed by this p of 1 set.

This is a set.

And each sum and has another set attached to it, which is the exponent.

So it's really just like y squared plus 3y plus 1.

This is a polynomial.

And this could be like sum over i y to the xi.

If we think of the three y's, like y plus y plus y.

Rupert Clayton, And so, this is a sort of general representation of a polynomial and we think of the indexing set P of one as the set of the.

Rupert Clayton, Of a set of the systems outputs or the configurations that it could adopt or an active inference language, like the observable states of a generative model.

And then to each possible configuration of the system, as I say, you have this set which represents the inputs or the actions that a system might take in that corresponding configuration.

And so that's just how we think of a polynomial.

And then there are some things you can do with polynomials.

In particular, there's one trivial polynomial, one that has just one configuration and one possible input.

So there's no possible variation in its configurations and no interesting actions that it can take.

We can put polynomials side by side using this 10th of product.

And this has the expected effect on the polynomials.

A configuration of a tensor is like a configuration of each part, and an input or an action is an action or an input of the corresponding part like that.

And mathematically, we can translate between this kind of polynomial representation and what's known as a bundle, which is just a function.

So these are all sets, the p of i's and the p of 1.

And so we can do the coproduct or disjoint union of these sets by summing over the i's.

And this means that the elements of this big set here are pairs of an i, an indexing i in p of 1,

and an element of the corresponding exponent set.

And this bundle is just a function that maps ix down to i.

And this is useful for defining the morphisms of polynomials, which will do the things that I think of as wiring.

And I'll talk about that in a moment.

But before I do so, I want to introduce one important example of polynomial, which are the monomials, because they don't have many interesting non-trivial summands.

They're just like one term.

So, and we write these as OY to the A, and these are going to be familiar because they capture the kind of classical active inference.

So here I think of the O as like the set of observations of an agent, and the exponent A as the set of actions.

And so these actions are like the inputs to a generative model that makes it transition, and the observations are like the sort of data that the generative model or the environment produces that the agent receives.

And this is a polynomial because you're just summing over the O's, and for each O you have the same A. And the bundle just takes a pair of O and A and projects down to O. Okay, cool.

So let me talk about how these things sort of wire up briefly.

This is done using the morphisms of polynomials, which are otherwise known as dependent lenses, if you know about functional programming, for instance.

So

Amorphism is going to represent taking a system and putting inside a bigger system.

That is like if you've got two small boxes and you wire them together to build a big box, or you take two cells and you take multiple cells and you put them together to sort of make a multicellular organism.

So if we've got polynomials P and Q, a morphism from P to Q is given by two things.

One sort of goes forward from P to Q and one sort of goes backwards.

And the forward one sort of takes the outputs of the inner systems and turns them into an output of the big system.

And the backwards one takes the inputs to the big system and the outputs of the inner systems and uses them to produce inputs to the small systems.

So one of them goes from inside the box to the out.

That's the phi 1 map.

And then the other one goes in.

But it might take into account the internal inputs as well.

So it can be used for feedback.

So that is to say, we've got this outputs map.

So we take outputs of the inner box to the outer box.

And for the corresponding inputs in the outer box, so that's these y's, we go backwards.

But we have to account for this mode dependence, which is a bit sort of funky.

But this just says that if we've got an output corresponding to position or configuration i of the inner box,

then we're allowed to look at the inputs that correspond to the corresponding output and then we sort of back propagate those to the inputs again in configuration i so there's a bit of sort of accounting um you have to do to keep track of these like the sort of um of the configurations of all the systems but that just means that you know there's some like mode dependence or some like you know you might have some

you think of the sort of multi-cellular organism thing then you might have some like you know ion channels which are open or closed on the in on the membranes of the cells and what they do sort of depends on the state of all of those cells and so you have to account for that in these morphisms but in the monomial case where you don't have this like con context or configuration dependence

the morphisms become a little bit simpler.

They just become like a forwards thing.

So here we've got an A and an S going forwards, and we have to figure out a way of giving an X. And in the backwards direction, we have an A and an S on the inside and a Y as well coming in.

Then we have to figure out a way of giving a B and a T. So this really just encodes the wiring of these two boxes into the bigger box, like I said.

So using this category poly, whose morphisms are the dependent lenses and objects of the polynomials, we can give a system theory which captures generative models.

I'm going to just talk about discrete time ones in the traditional sense on the monomials, but also has some kind of more complicated mode dependent structure that I think could be useful in general as well.

So this is going to be an index category, like I said.

It maps the polynomial, i.e.

an interface of the kind that I was just talking about, to a category whose objects are generative models on that interface.

So that means that they are going to be a quadruple like this.

So that is a state space, S. I'm just going to think of it as a set.

A prior on the state space, which we could think of as like a goal or just prior beliefs about the agent states.

um a likelihood which is a sort of stochastic output morphism um in the case that this is um just a monomial O Y to the A then that's just like P of O given S and then there's also this transition map which says okay well given that I am in this state um I I sort of can sample

Gareth J. An input that has to correspond to the configuration that i'm in so I sample from my pie and then okay i'm allowed to receive an input in this corresponding.

Gareth J. At like configuration P of one which is given by my likelihood and then okay i've received an input and i've got a state and I get a new stage so that's like the transition function.

Gareth J. Again, in this monomial case this is exactly what we normally have an active inference.

we have a state S and an action in A, and we get a new state.

It's just that now we're allowed to have the possible inputs to the system, i.e.

the possible actions that you could take on this generative model to be dependent on the state of the system or the state that the environment is in, according to that model.

And so that captures this idea that, say, if I have my eyes closed, I can't receive

you know visual signals anymore uh or you know if i open my eyes then i can so there's a sort of difference in the sort of input signals that i can receive or if i'm sort of plugged into my computer i can't sort of easily get up and walk around because you know i might like have to like unplug a wire or something so that it captures this mode dependence

There are sort of important sort of mathematical bookkeeping duties we have to do, which I'm not going to do, but it's easy to check that it's like functorial, which means that it's indexed in the right way, and that it's monoidal, which means we can put systems side by side.

And I've only just told you what the objects of this category gen of p are, but it also has morphisms, and these are ways of like comparing systems that are known in computer science as co-algebra homomorphisms.

um so this captures the notion of generative model that we're used to in active inference but it allows for a lot more structure um in particular this kind of mode dependent structure and this compositional structure so just to sort of say like what kind of thing i mean by structured interface um i'm taking an example from computer science because um

There are lots of uses of polynomials in computer science, and one of them is defining domain-specific programming languages.

And I think that one use of this could be for defining artificial agents that behave nicely with respect to computer interfaces.

And so we can encode the data of a domain-specific language into a polynomial,

Because, say, we've got a little calculator language.

It has two binary operations, like plus and times.

They each take in an input, take in two inputs.

We've got a unary operation.

It just takes in one thing, and it negates it.

And we've got some constants, uncountably many, that represent

real numbers then we can encode the data of this as like you know 2y squared plus y plus r because we've got these two little operations one two binary operations they've got two possible inputs one unary operation it's got one input and like these constants which don't take in inputs and then we can

you know, represent the set of all terms of this language as, like, a set by applying the polynomial to, like, some x. Those x terms, those x elements represent the inputs.

And then we could think, okay, well,

what would be um a machine that like takes in terms of my little domain specific language and returns values it's it's something like r y to the p of x which is again another polynomial and you can do lots of things like this basically you can encode like any small um programming language or any any sort of abstract syntax tree into a polynomial um

It's not just examples from computer science that are relevant, but they have a lot of structure.

And so I wanted to show off those examples.

I think you could do a lot of things in biology as well using this language.

But it's kind of more sophisticated than we can do with just sort of a set of observations and a set of actions.

Another thing that I wanted to mention is that in this context, it's quite natural to think of the actions that an agent takes as morphisms in a category.

And this is where this typing information or this typing idea comes from.

Because in categories, morphisms have to compose.

And so we can check that they are sort of compatible before we compose them.

And so to give you an idea of how this works, we can think of categories as like little state machines.

So here I've drawn a little category.

It's got objects x, y, and z. And it's got these morphisms.

It's got two morphisms from x to y, f and f prime.

And we've got g from y to z. And we can go along f and then along g to go from x to y to z. And that takes us from x to z. Or we can go f prime to z and blah, blah, blah.

But these are like steps or paths in a little space.

And so we go from x to y and then y to z. But it doesn't make sense.

If we had another object over here that wasn't connected to z, we could go over here.

But then we wouldn't immediately be able to go over z. That's to say, if we had an island or a peninsula or an island with just one bridge onto it, we could go onto the island.

But then to go somewhere else, we'd have to go back along the bridge

Sometimes the places you can go depend on where you are.

And this encodes that data into the notion of action.

And indeed, every category is itself can be turned into a polynomial.

The configurations of the polynomial are the object of the category.

And then the inputs to a system would be the morphisms of that category out of each object.

That is to say, all the steps you could take out of each object.

And then a policy would have to be a composable sequence of morphisms.

Or in active inference, you might have something more stochastic, so you have a belief over such sequences.

But because you have this type of information, it means that you can check that your policies make sense.

You don't try to go somewhere and then somewhere from that intermediate destination, you don't try to go somewhere that is not connected or take an action that doesn't make sense in some other way.

And so we can use this to start to think about like safety of policies using the logic that comes with category theory.

This isn't something that I elaborated, but I think it's a sort of starting step to talk about safe active inference systems in a very rigorous way.

And I already mentioned that other kinds of

important notion are also morphisms in structured active inference, like changes of interface or changes of structure.

And that means, I think, that we can rigorously apply active inference to itself to do things like structure learning or to choose how you connect yourself into a bigger unit, like into an organization.

And on that note, let me tell you about how, in this setting, we talk about systems that manage systems.

This is a generalization, or will become a generalization, of what is known in the active inference literature as deep or hierarchical active inference.

And so the sort of formal gadget that we use to talk about this is known as the closure of the category of interfaces.

That is to say, it has what's known as an internal home home because morphism is otherwise known as homomorphism.

And the category of polynomials and also the category of lenses has one of these internal homes.

That is a way to refer to the category within itself.

And that internal home has to be given a polynomial form.

And so the sort of configurations of this polynomial from say from P to Q, they are the ways of wiring P into Q, i.e.

the set of lenses from P to Q.

And then, you know, we have to give as well exponents to provide a polynomial.

And these exponents are going to be all the sort of data that the inputs to these sort of P systems, if we think of the P as like the inner systems that they require.

And so they require outputs from P and inputs from Q. And that's exactly what this like input data is here.

so if we so we've got a polynomial that represents how p's connect into q's and we can think about what uh generative models would be over such a polynomial that is just like systems that control the wiring of p's into q's or as i've done in this example control the wiring of a p1 and a p2 into q

and so what would these systems be well they would observe the outputs of p1 and p2 and then the inputs of q and they would update their states accordingly having made these observations and then they would output ways to connect p1 and p2 into q and that really is like what a manager does in an organization or sort of high level system does in a sort of hierarchical structure um and

There's a sort of nice fact that I'll use later on, that if you have a sort of trivial inner system, i.e.

just with this polynomial y, then the generative models on this hom polynomial are just the same as generative models on the outer polynomial.

So we can use this to capture not only these hierarchical systems, but just kind of regular systems as well.

uh there's an interesting or you know the sort of side fact or reason why this is known as the closed structure is that

This is the same as something that's known in computer science as currying.

You might have seen this, that if you have a function that takes inputs in A and B and produces C, like this maps A, B to F of A and B, we could also write this as a function that maps from A to maps from B to C.

And that says, OK, well, this maps A to F of A something, which is a map from B to C. So this is the same idea.

It says, OK, well, the ways of mapping into this hom polynomial are the same as mappings of the joint systems.

It's an important structure that gets used a lot in this context.

Okay, so I spent a lot of time talking about structured generative models.

In particular, I introduced this hierarchical structure, and I talked about the structure of mode dependence in an abstract and general way.

But it was always about generative models, and I haven't really talked much about doing action selection or state inference, which is, of course, a very important part of active inference, and in some sense is kind of what active inference is all about.

But those processes fit very naturally into the same framework.

They're something that you attach to a generative model.

Active inference always starts from a generative model and then describes the process for providing a policy to control it.

And so an active inference agent, or I think an agent more generally, is made up of two things.

It's made up of the generative model and then something that I call a controller, which basically chooses the policy to provide to the generative model.

It's a way to sort of take this generative model, which is an open system,

like sort of meant to render it closed it sort of takes the observations that are produced by the generative model and then turns them into actions that can go into the generative model and so there's some sort of nice duality between the generative model and the controller and it's this duality that allows us to formalize um active inference in a nice compositional way

One way I sort of started to like to think about this, and I don't really know much about this subject, so I won't make any claims that it's rigorous or sensible, but I think of the sort of generative model as somehow like the consciousness of the agent.

It represents how the agent perceives the world, and then the policy part is it's sort of the subconscious processes which sort of drive the agent in that generative model.

I mean, this is just sort of my thinking.

I don't know if it's very sensible.

But as I say, we can fit all of this into the same framework by kind of taking poly and this category of generative models and the home structure and sort of putting them all together into a sort of nice bundle or nice mix.

So I had this two category called GenPoly made up of all of these ingredients.

The objects are the interfaces, the polynomials, you can think of them as generalized Markov blankets.

And then now it's a two category.

So instead of between one object and another having a set of morphisms, now we have a whole category of morphisms.

So we have both one cells and two cells.

So it's a two dimensional structure.

But the HOM category from P to Q is just the systems on the HOM interface.

So that is generative models on the structured interface that sort of takes P systems and turns them into Q systems.

So they're sort of hierarchical manager systems.

And then the two cells are ways of comparing these systems.

And I haven't really talked much about that.

And they won't feature much in this talk.

And they don't feature in the paper either.

But they're important if you want to talk about things like structure learning or logic.

then the composition of systems is as i've been saying all along we take a system over over one sort of home polynomial and the system over another home polynomial and then we wire them together so then we have like a sort of high level manager here and a sort of lower level manager and they talk to each other to produce what we could think of as like a hierarchical organization which takes sort of very low level things and turns them into high level things um

And yeah, so we're out of tensor polynomials, and that makes this gen poly two category into monoidal two categories, so we can put systems side by side in the way you'd expect.

And it means we can draw an active inference system in this kind of string diagram way that category theory people like.

So the generative model is something like this.

It takes in nothing and it produces p things.

That is, produces, well, I guess this is a bidirectional thing.

So it sort of is a morphism from a trivial object into p.

And it produces P outputs and takes P inputs.

And then the policy is like it's dual.

So it takes in P inputs and it produces what the generative model expects as output.

And then, as I may have mentioned, no, I didn't mention yet, that this, as I said before, at least in the case of just a single system, just on P, the hom from Y to P is just the same as P, so that's good.

This captures what I was saying before about generative models on an interface.

And then the controller is the model from P to Y. That means it

doesn't sort of it produces a sort of closed system when you compose it with p and that is that is to capture this picture that i drew before where you have like um a box which is the genetic model which is open and then this controller which sort of closes it off and that's encoded in this sort of formality

Okay, and so now we've got this definition of a controller of a generative model as like being dual to it.

We can sort of unwind or decompress what that means mathematically.

So the home polynomial from P to Y has this form.

It's just something that you can work through if you write down that expression and figure out what it means.

The outputs or configurations of this polynomial are what are known as sections of P.

So a section of this P

taken as a bundle is a way of going from the outputs and for each output giving an input that matches the corresponding configuration.

So it's just a way of making this diagram commute, as we would say in category theory.

That is to say, OK, we're in an output or a configuration, and we say, OK, well, I need to provide an input.

And yes, that's nice.

It matches what configuration I'm in.

And we think of this as like being the data that the world supplies to the system.

So the system or like we think of the system as producing output, the environment takes those outputs and then turns them into inputs.

And so that's exactly what these sections do.

So those sections are the things that are outputted by this policy part.

And then the inputs to the policy part are the outputs produced by the P system.

And so, as I say, it's exactly dual.

So the outputs are the things that the inputs that P needs and the inputs are the things that P produces.

And so we can unravel this in the case of this monomial interface, which is going to give us what we get in classical active inference.

The output path of one of these systems is going to do action selection.

So it has a little state space, which I just called R here.

It takes an observation, and it produces an action.

And this is exactly what the sort of action selection process and active inference does.

It takes a state and an observation that produces an action that is to be taken in the generative model.

And it also has this part which does state inference, or you might see it called the recognition model, or it computes the Bayesian posterior over the states.

So we're in a state, and we have an observation, and then we get a new state.

So these sort of four things, these two parts of the policy system and then the transition model and the likelihood in the generative model are basically all of what an active inference system is.

You might include the prior in that as well, I suppose.

And so that means that we've got all the data of an active inference system in this very neat little package.

It's a generative model and it's dual, and that's kind of it.

There are obviously some ways you can extend this.

That's not something I'm doing in this paper or in this talk.

But basically, you can do things like consider trajectories over actions or continuous time models or do lots of other things like this.

But I'm going to try to keep it as simple as I can.

I know I've introduced a lot of mathematical detail so far.

And then Okay, so, then there are three further generalizations that kind of prop up pretty immediately from this that I think are quite important, and I want to just introduce to you all, and the first of them is that now we've got this home structure.

and this nice two category, we can think about, as I've indicated already, think about hierarchical deep systems.

And that really corresponds to nesting small systems in bigger systems.

And that formally means going from generative models with trivial inner boundary to

generation models which have a sort of non-trivial inner boundary and now unfortunately I've swapped my direction of my home so it goes from Q to P um the story still holds I've just changed P and Q round um and I'll say in a moment like how this unwinds so you can get a sense of what it does and then we do the same to the policy it just does the same thing in the opposite direction now it's a system from P to Q

But they're still dual, so the intuitions are still good, I think.

That's one thing we can do.

This produces a sort of bicategory, a two category, or what ultimately becomes a double category, where the arrows are pairs of a system and a controller.

And so the next thing we can do to this is to think about how do we model in a sort of rigorous way the changes of model, changes of interface that I introduced at the beginning.

That corresponds to adding yet another dimension to this structure, and that formally encodes changes of model as extra morphisms categorically, and that makes them kind of accessible to this formalism.

Not something that I'm going to talk about today, because I've introduced enough stuff here just to sort of whet your appetite, I think.

But in this formalism, even in this sort of just two-dimensional setting,

Because it's quite general, because it says that active inference is really made up of two key ingredients, a system and a controller, it allows us to ask precisely how active inference relates to other theories of agency or other notions of system.

And of course, lots of people have thought about the relationship between active inference and other accounts like reinforcement learning.

But I think this framework allows us to make those

relationships very very precise indeed and to say okay well you there is say one might hope uh a particular like possibly universal way of mapping any reinforcement learning system into an active inference system in a compositional way so that you could do it for the parts and also for the like complex system and you get something that makes sense

um and possibly one could go and I think it's quite likely that one could also go in the other direction and there would be nice sort of we might expect like nice formal results like these two processes were adjoint or something like that um but

I'd like to highlight at this point that active inference, I think, in this setting is really not just one theory of agency, but really it's a whole family of theories of agency parameterized by things like whether or not you take continuous time or discrete time systems, because those, of course, give you different systems theories, or whether you do planning by sophisticated inference or inductive inference or just one time step, or whether you...

or whether you think about like multiple time steps or whether you take the expected free energy or the free energy of the expected future.

So there are all these different variations and they give you like different like notions of active inference.

And so probably different theories of agency in this sense.

And I think that's important for like making sense of the whole active inference landscape and in particular the sort of landscape of theories of agency itself.

because it means that we can have a nice rigorous map of all of these things and connect one thing into another quite nicely.

Again, I'm not going to say very much about this, but I just wanted to flag it up that that's something that you get out of making precise these structures.

So I mentioned that I wanted to highlight how this captures deep or hierarchical active inference.

And this happens in, I think, quite a natural way.

I mean, I've introduced an awful lot of formalism here, but once you get used to it, I think it works okay.

But hierarchical active inference just corresponds to a sequence of composite arrows in this two category whose arrows are made up of, you know,

generative model and uh controller actually is upside down but doesn't matter um so in this setting again as i've mentioned the monomial interfaces correspond to the kind of normal marker blankets that are just made up of a set of observations and a set of actions but we get this hierarchical structure in the one cells of this two category and if we think of

the sort of composition in this two category is basically by nesting, then I sort of draw it schematically like this.

I'm indexing the higher levels of the sort of interior levels of the system as higher in this context.

So i plus 1 is kind of more inside the system than i.

Often that corresponds to a higher level of explanation in active inference.

But because there's this duality between the generative model and the controller or the policy part, I don't like to say high level or low level because it gets confusing.

I prefer to think about how deep you are inside your agent or how close you are to the exterior world when I'm talking about the direction of this kind of hierarchy.

And so to the left, we go sort of more interior.

To the right, we go more exterior.

And these arrows point in the exterior direction like this.

And so a sort of hierarchical active inference system goes from interior to exterior.

It's an arrow of this kind that unwinds to the following data.

It's a state f.

The likelihood that is parameterized by the state and the interior belief about observations.

So which you could think of as like high level in some context observations, and it produces a prediction about the more exterior observations.

There's a prior on the.

in more interior actions which again you could possibly think of as a high level that this is parameterized by the or conditioned on the state and the and the sort of interior observations and the exterior um uh some more exterior actions um or the system's belief about the more exterior actions

And then a transition model, which, again, depends on the actions taken at this kind of exterior level.

In this case, this is the high level actions.

And it gives us a new state on the basis of the old state.

And then there's this other part, which is dual, which is the controller.

So the control here, I've written the state space is like beliefs over the generative model state space.

So that says it takes, it has this, again, these three parts.

So one is like a generative process, which takes the, in the sort of exterior observations, the signals which impinge on the,

the sort of outer mark of blanket and translates them onto the inner mark of blankets so it goes in the other direction like this um there's a sort of policy part which does action selection so it takes in a belief over the state space and um like a high level or

more interior belief about over the actions and it produces um what we could think of as more exterior uh choice of action so that could be like passing down a sort of high level motor signal um into like low level sequence of like muscle contractions

Because I think of the sort of closer to the exterior systems as like the ones being made of lots of, say, cells, rather than the interior model of myself as just a body with arms that move.

And then finally, there's this component which does Bayesian inference over the states.

It takes in a state and an exterior observation, that is the signals which they impinge on my retina, and it updates the internal state.

that's you know the part that does like um you know that gives you your posterior overstates

This is a lot of data.

In the literature, it sometimes comes out in a slightly less or maybe slightly more familiar way or a slightly less detailed way where you don't have the interior observations, which I think was like sort of beliefs about high level patches of information, like the object rather than the sort of individual like retinal ganglion data or something like that.

And if you imagine not having these OIs, OI plus ones,

in this model then you wouldn't have like this generative process and you would only have a likelihood which takes a state to an observation but you still get this like hierarchical action selection process so it just takes like high level action like high level beliefs about sort of actions like I'm moving my arm into sort of lower level sort of signals that I pass to my muscles but I think it's nice to allow for this hierarchy in the opposite direction on the observations as well

Okay, so the final thing I want to mention is that the categorical systems theory lets us talk about, lets us use categorical logic for talking about

goals and behaviors of systems and formally it's quite easy to say what we need to do that it's not something that i've done because actually there are a lot of details but formally like it's relatively simple all you need is the ability to define what's known as the vibration

And a vibration is just like a collection of things indexed by the other things.

So again, this index category thing notion that I introduced at the beginning is basically equivalent to vibrations.

But the idea is now that over each system we have a vibration of predicates of logical statements about those systems.

um that it's indexed by the systems and the systems are indexed by interfaces and it's compatible with all the changes of system and changes of interface and things like that um but one notion one sort of simple idea of like logical structure or predicate you might attach to systems is just notion of um goal for a system so these priors on the state space um and I haven't elaborated this um but you know once you've got this we can kind of

use the structures of category theory to do things like define quantifiers or logical connectives and to build up statements about goals out of sort of more primitive statements and compare systems goals and to say possibly things like oh now if i've got a bunch of systems connected together

Maybe they work together to achieve their goal, possibly by some process of consensus.

This allows us to talk about that kind of thing in a mathematically rigorous way.

Or now we've got this formal logic to talk about the goals of systems.

Can we use this to talk about notions of safety or to guarantee that the goals will be achieved within certain bounds or that they won't try to do this thing or this other thing, which we don't like?

I think this is important, again, as I've mentioned at the beginning, for thinking about safe artificial systems.

That's all I wanted to talk about.

It was a lot.

I think we can go back and elaborate on any of this.

And I'm sure we'll come back to it in the future as well.

Thank you so much for having me.

I hope it wasn't too bamboozling, but I'm always willing to answer questions.

And if people have more questions, please feel free to get in touch afterwards as well.


SPEAKER_00:
thank you toby wow okay yeah while people are asking some questions in live chat which i'll read to you could you reiterate how does what you refer to as classic active inference with markov blanket bayesian graphical formalism how does that overall literature relate to what you discussed today in terms of applied category theory


SPEAKER_01:
Right.

Okay.

So I think the very concise way of putting it, let me see if I can go back to a slide where it's relatively or not too intimidating.

The concise way of putting it is that

the systems in active inference that i like classical that we're more familiar with heretofore are basically like sub theory or a sub category of this whole structure that is spanned we would say in mathematics by these monomial interfaces these are the ones that don't have this like complicated state dependence on the actions they just have a space of possible observations and a space of actions

um and in particular if you don't think about like these hierarchical or deep systems then it's relatively simple to see that those systems that those kind of generative models are captured by this formalism um because you get uh you know on over one of these monomials the monomial represents the markov blanket um the uh coefficient here is the

observations the exponent is the actions um we have a state space we have a prior we have a likelihood and we have a transition model and that's kind of the whole deal with a generated model um the the sort of policy part the thing that i call the controller

Excuse me.

It kind of remains, like I said, it's the same as dual.

It does.

Let's see if I can go back to the slide.

It does.

Gareth J. yeah it does action selection I planning and it does base and inference I produces the posterior here is this like a placeholder usually this least in the story that I told him the paper, this would be like police overstate the here means distributions.

Gareth J. So this is distributions overstate.

Gareth J. it's just a way of like packaging all of that up into a kind of nice compositional framework.

so that we can because you see a lot of you know if you look at complicated hierarchical active inference pictures they often have like really complicated structure but actually these structures typically have like some kind of common repeating elements that in principle should just be able to be boxed up and repeated and plugged in in a nice way that is

mathematically sound and reusable and kind of uh you know i like category theory because it's a kind of lingua franca and and it means that you don't have like small variations in formalism like what does message passing mean well it means lots of different things lots of different people um in this setting you have you can be very precise about like what your theory of agency is um what the notion of markov blanket is

One of the things I often find a bit tricky about the active inference literature is the notion of Markov blanket is quite, it's kind of intuitively quite easy to graph.

But in this kind of dynamical setting,

It doesn't quite correspond to the notion of marker blanket that originally came out of statistics.

Unless you do some kind of maneuvers that unwind your dynamics into a big graphical model and draw certain boxes around some repeating elements, then you can say that the marker blanket of the system is the parents, children, co-parents, like you would say in statistics.

But it's kind of not really what the job of the Markov blanket is, not in active inference and not in statistics.

They sort of play different roles.

In active inference, the Markov blanket is the agent's interface.

It's like the boundary of the agent, how it interacts with the world.

And I think it's nice to be precise about that.

It's nice to say that when we say Markov blanket, we mean interface and our interfaces come together and they can connect up and they can produce bigger systems with interfaces.

And that has a particular grammar to it, which is not the same as the grammar of Markov blankets and statistics.

It might be in certain cases, but if we want to talk about the sort of

um whole world of different kinds of dynamical systems from these discrete time ones that i was talking about to various different models of continuous time ones then it's it's not it's not so easy to make the connection back to market blanket and so i think to some people who come from statistics um this terminology can be a bit confusing and one of the things that comes out of this structured active inference is that it

says hey this is how we can be precise about this um it says okay well we have this notion of interface it can be whatever you want as long as it's you know it behaves like we think of as interface and i've just told you about one story of interfaces and and basically one story of systems like over the interface but categorical systems theory is very very general it lets you talk about lots of different kinds of interface lots of different kinds of systems and this is why i think that this story of structured active inference whilst it

captures the kinds of active inference systems that we're familiar with it's really a theory of the structure of agents generally and i think active inference wants to be that um and that's why i think that you know here we might want to expect that there's like traditional there's like um canonical ways of

relating other theories of agency to active inference or to a particular flavor of active inference and that we can make those mappings precise precise not just for an individual model or an individual system but for all systems of a particular kind um and and that's the kind of universality that I think we should be aiming for um I can explain what these arrows on this page mean but I don't you know I think you get the idea that like

this is to say if you've got an agent it's a system and a controller you can like

Forget the controller and you've just got a system.

Active inference is a way of saying, okay, given my system, I've got a story about how to attach controllers to it, how to do policy, how to do planning, how to do action selection, how to do state inference.

Active inference is a recipe to take a generative model and provide a controller.

And reinforcement learning is a rest, or the variants of reinforcement learning are also recipes for doing something similar.

So it's a sort of mapping in the other direction.

So I think the thing to take away is that if you're just interested in simple models with one set of actions and one set of observations, then you don't have to worry about this.

But if you're interested in building big, complex models of big, complex systems like organizations, or if you're interested in talking about systems whose interfaces can be dependent

or whose like actions might depend on where they are or what they're doing or who can change their interfaces or who can come together to form organizations that themselves are like dynamical and changing then we need stronger mathematical tools for describing those systems and those processes and those kinds of agents and that's what this framework and that's what categorical systems theory gives us


SPEAKER_00:
Awesome.

So many great points and things.

I'll just highlight two pieces that I think really hit.

You called it a particular grammar that knowingly or unknowingly plays on the particular partition, splitting things into particles and being that partitioning.

And this is also a grammar of particles.

it's a particular grammar like there are sentences that are syntactically or grammatically correct so that's this kind of like syntactic level of typing there are certain expressions within the active inference ontology or grammar that would be syntactically valid or not or would be examples of an instance or an existential claim or have these other kinds of statuses and then also there's this sort of conceptual

connection that is the semantics that separates from the strong typing of the syntax so it brings up a lot of linguistic and then also you said it's a recipe for how to do action and that is like if we were to do dynamical systems modeling of a predator prey system or of temperature in a room but then to bring in the upstairs control section can open up multiple possible

like cascading state space ramifications especially if you allow for the heading in and out of the nested system that opens up a lot of dependencies that at least need to be accounted for or just go with a special case where it's nothing other than just like a fixed situation which is kind of where the buck stops ultimately for any hyper hyper hyper prior


SPEAKER_01:
yeah i i like i like those reflections so i think um yeah there's a this like particles idea you know i tried to sort of capture in this very feeble way i'm not very good at drawing here like you've got this kind of nesting of systems um and i'm trying to capture that in this formalism um so

you could think of like these like outer the outer boundary as being like as i say your body's boundary or like the boundary of like a whole organization or society or something like that or ecosystem and then the the sort of outer

Like the job of the outer system is like to pass messages into the inner parts, which are like your organs or the sort of units of an organization or departments or something like that, or sort of lower.

So we often think of a lower level, but like the more like smaller scale or more like interior systems.

um one thing that's not so easy is to talk about like the sort of birth and death of these things i haven't really thought much about like how systems are like created from others but i'm i'm trying to like get at least some framework for talking about like what it means to be one um before we talk about how to like split them up um you said some things about grammar um yes and i think it's

I'm trying to use this very, in some sense, quite sparse mathematical grammar of category theory.

But I'm trying to do so in a way that, as I say, is quite general.

And it ends up being inherently a bit alien.

But I think the thing you gain from that is this ability to talk about lots of different kinds of things.

And hopefully, this is just the beginning of this project, that we get tools and stories for how to express things in this kind of language.

It's, I think, most suited for trying to understand complex systems.

So as I say, I think if you're happy with just normal active inference, then it's probably fine.


SPEAKER_00:
Great.

And also I'm wearing an appropriate embroidered onion shirt on the birth and death.

even though from each nucleus's or cores perspective, it is like being at the center of a bull's eye from where it is, taking another view might look more like a chocolate chip cookie or like multiple nested organs.

So it's not that it's like just a bull's eye, even though that's just the two layers, that's just the motif of nesting.

And then when you described how the systems can be put side by side,

then you could have a situation where it's like the cookie has two chocolate chips and then the next time step there's a third one but it's disconnected so it's the island and then another kind of actor comes in and changes the wiring secondarily so one thing i wanted to i haven't really talked about at all but one thing i want to be able to talk about and it's kind of related to this question of like when the system's like


SPEAKER_01:
dissolve into other systems or how can we see things as like uh you know a chocolate chip cookie or a bullseye or something like this um or you know how do we you know or a group of trees or a forest or something um you know this is this this thing it reduces systems and you know it's category theory so it turns systems into arrows um but really this structure like wants to be what's known as a double category so here we would

the arrows would be like the changes of interface.

And then we would maybe have like some other structure down here which represents another system.

And then we have like what are known as squares.

And these squares would represent how we could see this system up here as a composite or as a different kind of system, how we could see the forest as trees or something like that.

So it allows us to represent these kinds of dissolving or these kinds of changes.

I haven't explained in detail how this works, but it's a step towards that kind of process.


SPEAKER_00:
cool and then of course all the great juxtapositions with more topologically stable systems uh neural networks and then more like the ant nest mates okay i'll ask a question from the live chat math for wisdom wrote i wonder if it is possible to interpret it in the opposite way that the policy is the consciousness

So in that speculation, what led you to see or identify one with the other?


SPEAKER_01:
Yeah, because really, I always find that the generative model encapsulates the world as I perceive it.

There's nothing really that I can do to change.

So the generative model is a system.

Yeah.

So there's one peculiarity about this, which is that

the key ingredient is like a system whose outputs are observations and that seems a bit weird sometimes to me and it may seem weird to people who are used to active inference where you could think of the outputs of an agent should surely be the actions but the the degenerative model i.e the the agent's beliefs about the world is a dynamical system which outputs observations so the agent receives

And so that seems like the wrong way around, but it is just how the mathematics requires it to be.

And so this thing being so like crucial in the structure says to me that like, this is like the sort of, this is, you know, when we see, you know, active inference texts, it's often like S given O and M. So it's like conditioned on a particular kind of model.

This gamma is M.

And this M doesn't typically change in active inference unless it's by some process of evolution.

For an individual agent, this model is fixed.

And this thing represents everything that I see, and it represents how I expect the world to change given the actions I take.

And it is, in some sense, the agent's world.

In active inference, the agent can't access what the real world is like, only has the generative model.

And so that's why I think this is like my world.

This is like my conscious experience.

so what actions i take i mean maybe so maybe this includes some self-model and i think you know i'm doing planning or i think i'm you know behaving in a way that's reasoned but actually i'm just acting on instinct according to these subconscious processes i mean i don't know much about consciousness science but i think that that kind of story is possible and so this stuff seems to be

the things that I don't necessarily directly experience in the same way that I directly experience my visual signals, but they are the things that make me like me.

They are the things that provide my input to the world.

and again you know that's all like dynamics and it's maybe stuff that i observe but maybe i only observe it because it forms like an interior part of this model which might have some complex structure of the kind that i was talking about um so that's why i thought of it that way around um and of course like you know maybe there is some deliberative planning process or like you know some internal like reasoning that goes on in my conscious experience and i do have an inner monologue and often it does seem like that so i think there is some like

interplay between these, but possibly I think that stuff is borne out by having some complex structure in this rather than in these things that I think of as subconscious processes.

I don't

I don't experience my own Bayesian inference processes, except in the cases that they go wrong, or I have some illusion.

Sometimes I'm in a building that's particularly symmetrical, and I go out of a lift, and I go into one place, and I'm on the wrong side, and it all feels really weird.

But that's not the same kind of construct.

That's kind of an unusual experience.

Anyway, that's my feeling there.


SPEAKER_00:
what an unusual experience I'll read from math wisdom he wrote I think that makes sense and now I understand the distinction better the generative model creates beliefs the policy creates actions but our actions are faded we are only free to choose our beliefs so our Consciousness has to do with the beliefs we take our will did I understand the distinction correctly

I think so.


SPEAKER_01:
I think that sounds like a good good way of putting it.

I mean, this is this is really just my basically this is like my answer philosophizing.

I don't know.

I mean, it would be nice if this matched like, what people think is actually going on.

But it's just what the sort of mathematics seem to be saying to me at least.


SPEAKER_00:
towards the applied side, what kinds of programming languages or approaches or open source software or methods can people use to start exploring this?

That is a great question.


SPEAKER_01:
And you know what, at the moment, that doesn't have a great answer.

The best answer

um for now is that i mean at least for like modeling is that in julia um the guys at the topos institute have been producing a collection of packages in the sort of milieu of their project algebraic julia which is all about representing categorical structures and um doing compositional modeling in in julia um

But Julia itself is not necessarily well suited to describing things, describing the world in this particular kind of compositional way.

It has its nice compositional features.

But basically, in Algebraic Julia, they've written a little sub-language in Julia itself that encodes these categorical structures.

one of the things that's quite nice about category theory is that it's very like you know it's about composition so it's very modular and it gives you a lot of things that you can change um i'll let me go back to where i talked about um systems theory right at the very beginning

Yeah.

So, you know, I just write down this arrow and maps from like my category of interfaces to the category of categories.

And in principle, I could just, this should be like a little program which takes in which, or I just like, right, I provide it with a polynomial and it gives me back this other data structure.

um this category of systems um and then i should yeah i could i should be able to talk about morphisms between these things and i could be a map like this or make like changes to this and have my computer automatically do it um but that's just not possible with any kind of computational tools that we have right now um and i often feel that it should be

possible to do this in a way that's not necessarily, like, tied to a single programming language, like, like, algebraic Julia is to Julia, there are also like, dependently type programming languages for like proof of systems.

But if you write in those, then you're stuck in that world.

One of the things that's nice about like, the World Wide Web is that

These days, you can write into lots of languages, and they get compiled to WebAssembly, and we can interact in a sort of language-agnostic way.

And this mathematics should be language-agnostic, but we don't have any languages or tools to talk about it yet.

It's something that I think should change.

People who are interested in changing it should talk to the top of people or talk to me, and I would like to see it.

I would like to see tools which are really nicely compositional.

And people, as I say, the top of people that worked on it, they're building other things in Rust.

Those are the best answers I know of for now, but they're not like optimal.


SPEAKER_00:
Thank you.

Well, it's an optimal agenda, so that's very cool.

And to be able to connect even potentially in the coming months between the algebraic Julia and rxinferred.jl could already offer some cool opportunities.

Yes, I think that would be a great project.

Cool.

Over the last years, like working on this from your dissertation, which we discussed in the live stream 54 series, all the other fun and learnings that we've had, how have you seen like the process of going about that recipe

evolve from like the chapter six in the 2020 textbook how do you feel like as more and more of the applied category theory developments are formalized and then also like operationalized how is that trajectory of like what it looks like to apply active inference yeah i think it's it's been very interesting and very exciting i would say for a long time i i was also like quite i guess relatively confused about things um in some way and this is a thing that this is


SPEAKER_01:
um something that i haven't yet been able to resolve uh and and i'm sure some people know how it could be resolved um but i'm just not yet one of them which is that active inference has come out of the sort of free energy principle world where the

idea is that actions are selected in like the same kind of way that you do perceptual inference by like minimizing surprise or free energy um but the sort of formal yeah so the formal structure of uh like pure perceptual inference is

it has a similar feeling right so it has something that goes from like effectively like inside to outside and then something that like goes back this is like the thing that does prediction or and then this is the thing that like does you know inference um

And so the structure of these two things, by no surprise, obviously, has this similar bidirectional feel.

But I haven't yet shown that

this action selection process is exactly of the same type as basic inference for perception and I would like it to be it's it's kind of frustrating to me that so I thought for a long time how do I get action when I was writing my thesis how do I get action into this um and that's what this project really has been about it's like getting action into the story finally

But the relationship between them isn't as neat as I would like.

And so if anybody wants to talk about that, I'm always interested in trying to show that action selection really is a kind of surprise minimization or approximate inference.

So far, it's only kind of vaguely in the structure.

And this reminds me of something that I wanted to say in response to your remarks when I just finished, Daniel.

that i've said here roughly like the data of an active inference there's like a hierarchical active inference system it has these components it's got like a likelihood model a transition model uh you know policy thing a state inference thing and you know maybe it's got this like generative process part and this action prior part as well um but

this is all just structure this is structured active inference this is all just about structure none of this yet is about like how you actually choose this likelihood or how do you actually do like action selection or how do you actually do state inference um the stuff that i was doing in the work that i was doing in my thesis was about

various different ways that we actually do inference like particularly um inference in the brain using the variational inference under the laplace approximation um

but what one what well like what i want at least is to say that active inference or a particular flavor of active inference is like in some sense universal and that means that there is like a canonical choice for a given system so like we assume that somebody comes along and gives you the data of your generative model it could be you daniel or it could be like evolution science or something like that and then it says okay well

active inference says there's a canonical way of choosing actions that is like as optimal as you can be and there's a canonical way of doing inference that is as optimal as you can be and this story that I've told doesn't is agnostic to that um I'm you know a lot of people have spent time saying here are proposals um this framework although being agnostic allows you to state like

what are known in category theory as universal properties.

And so those are ways of saying that this is, in some sense, canonical or optimal in some mathematically precise way.

And it would be nice to have those stories about the universality of active inference, i.e.

the ways of spelling out these functions, to be expressed in that language.

So yeah, that's my answer.

Two answers.

One was about this annoying thing with inference and here about the universality.


SPEAKER_00:
yeah there's so much to go into and you mentioned like dual a lot and the interface can be seen it's like two onions where you could peel off the interface and associate it with one but that would be a symmetry break because you could also see it as being peeled off with the other because it's an interface and this gets into like systems engineering what what is the interface and uh

it's very interesting topic so i'll see if anyone else has any final questions like what are your next steps on the research how do you see it being applied and continued okay right so my next steps are really to produce a longer or more detailed


SPEAKER_01:
paper about this than the abstract that is available at the moment.

In particular, the abstract that's available at the moment, it doesn't really spell out some of this stuff in particularly nice detail.

To keep things as simple as I could, I didn't really explain how you can have this kind of mode-dependent transition model

as as that that is stochastic as well as having uh likelihoods that are stochastic for technical reasons it's a lot easier if you just have the outputs of your systems be deterministic this notation right like some with a sampling is is not something that is um I I think um

canonical or widely known.

So I'd have to spell that out.

So there are lots of like mathematical details, but that's like the first thing.

And the second thing I think is to get people using this framework, actually talking about building complex systems or actually building tools for building complex systems using it.

um and relating those to you know the the tools that people already use for doing that kind of thing like um pine dp or just like you said daniel rx and um it would be great to like actually turn this into something that people can use rather than just a mathematical theory i like this although it's kind of um

Often people think it's quite an alien language because it's unfamiliar, but it is in some ways quite ergonomic.

It is quite demanding because to prove that something is an index category, you have to check all of these annoying conditions.

And by God, they are often really, really annoying.

I would love, as a test case for this, to build an artificial proof assistant or system that can help me do these checks.

Because as I said, doing policies like action selection is very much like choosing a series of morphisms.

And it's well known in mathematics that proof is also choosing a series of morphisms.

So I'm pretty sure that we can use this for doing things like proof in a way that's nicer than large language models.

So once we've got tools, I want to actually start applying them to things, complicated structured models that are probably beyond the systems that we have right now.


SPEAKER_00:
Okay, the Toby signal has gone out.

I'll ask one more question from the chat.

Math for Wisdom wrote, Toby, it sounds like you want to set up a free functor, so that suggests considering the adjoint functor.

What is it that you want to forget?

If you could define a functor...

what he wants to forget, then mathematically that could yield the functor that freely optimally constructs the canonical way to choose the action or do the inference.


SPEAKER_01:
Yeah, what do I want to forget?

In some sense, what I want to forget is, like,

all the stuff that I might have learned that confuses me.

But the thing is, it's very hard to distinguish the stuff that is confusing from the stuff that is not confusing until you've done all the work.

So it may be the case that you have to construct that adjoint in order to see that you've got the forgetful funct in the first place.

And that's, unfortunately, I think the situation that I'm in.

A lot of this process, I think, has really been about

figuring out the essence of these systems like in before it was like approximate inference in the brain and here it's like the essence sort of the structure of active inference really distilling it down into something quite abstract

And really, just to say something about forgetful functions, this arrow here that goes from agents, the category of agents, which has these bidirectional gelatin model policy things as its morphisms, and just goes down to systems, this is a forgetful function.

It forgets the controller, the thing that is the policy.

and um possibly hopefully the the way to see active inference is universal is to say that it's like um adjoint in a particular way or at least it has like at least it is a section we would say of this thing um so yeah it's true what i'm trying to do is find out what those adjoints are um but it's it's hard to know what to forget until you've forgotten it and then it's gone


SPEAKER_00:
don't know what you got till it's gone then there's the reconstructed pretty much the reconstructed trace and our niche is becoming increasingly capable from a perception and action standpoint which is bringing up so many fascinating topics so do you have any final comments not today i'm sure there'll be other opportunities down there i hope so at least

I do too.

It's been a pleasure.

Thank you.

Thank you, Toby.

This was an awesome presentation.

It's like big structural evolution and development in active inference.

And so there's so many pieces for people to pick up and work in all ways, developing like the background needed to get to some of these cliffs and then the better structures to jump off them with.


SPEAKER_01:
Yeah, please, everybody, get in touch if you have questions or projects in mind.


SPEAKER_00:
I'm always interested to hear them.

Cool, and I hope that we can reactivate some category theory act-inf in the RxInfer project or just in some other standalone project.

I'm sure it'll happen.

So thank you.

Cool.

Peace, Toby.

Thanks, everybody, in the live chat.

Cheers.