start	end	speaker	sentiment	confidence	text
2220	2770	A	0.546256959438324	You.
5460	6770	B	0.872096598148346	Hello and welcome.
7140	9696	B	0.8644924759864807	It's July 17, 2023.
9798	19372	B	0.8523033857345581	We're here in Active Inference math stream number 5.1 with Chris Bodner on topological deep learning graphs, complexes, and sheaves.
19516	21740	B	0.9713072776794434	So thank you for joining, Chris.
21820	24720	B	0.9802257418632507	Looking forward to your presentation and discussion.
25780	28312	A	0.8943170309066772	Yeah, thanks so for having me.
28366	35832	A	0.8403141498565674	So, yeah, as I was just saying, this is my PhD thesis, which I finished a couple of months ago.
35886	37480	A	0.8598530888557434	It's also kind of public online.
37550	45020	A	0.6125179529190063	So if you want to go into the details, just kind of look this up on the Internet and you should be able to find it easily.
45360	47644	A	0.6965752840042114	Obviously, there's lots of stuff in there.
47682	58370	A	0.7284908294677734	So I kind of try to give an overview today and maybe also go in a little bit more detail in certain aspects since there's not a lot of time to go through.
60180	67540	A	0.75449138879776	Yeah, now I'm Microsoft Research, so this is basically all work that I did in the past and when I was at University of Cambridge.
68040	70950	A	0.5406469106674194	All right, so let's get started.
72600	76020	A	0.6431881189346313	Right, so let's start very easily.
76760	94972	A	0.8294191956520081	Now, I'm actually not sure exactly what's kind of the background of the people who are watching, but in machine learning there's all these kind of subfield that emerged a few years ago which is called geometric deep learning, which is essentially looking at how to apply these kind of deep learning.
95026	105970	A	0.8106204271316528	Neural network architectures on data, living on all sorts of structures or geometries or spaces if you want.
106580	109740	A	0.6926403045654297	And this has a lot of application, especially in the life sciences.
109820	116924	A	0.7492709755897522	And there's kind of been a lot of instances of this in kind of very famous publications, some of which you see here.
116982	125300	A	0.9008052349090576	But just to give some examples, for instance, if you have proteins or molecules or things like that, they usually represented as graphs.
125720	131530	A	0.8885977268218994	And you kind of have some data living on these graphs, like kind of the properties of certain atoms and so on.
132380	150380	A	0.8456928133964539	So these kind of things and so far, these kind of spaces or these kind of problems, learning problems, if you want, they have been approached mostly kind of with a geometrical mindset, as the kind of name of this subfield also mentions.
151200	162960	A	0.49544528126716614	But something that I would argue is that geometry is not everything that you need and there's kind of other non geometrical aspects when you are in such a setting.
164180	174608	A	0.6081830263137817	And this is kind of quite obvious once you realize that the spaces that kind of show up in the field and in many applications, they are very heterogeneous.
174704	178340	A	0.768187403678894	So, as I mentioned, for instance, you could have graphs that could represent anything.
178410	182360	A	0.7035236954689026	In this case, it's the caffeine molecule that you see here on the left.
182510	187832	A	0.8964456915855408	And you want to have some models that predict certain properties of this molecule and so on.
187966	189572	A	0.8319875597953796	But for instance, you can have grids.
189636	193256	A	0.8217580318450928	And we see grids all the time and data living on grids.
193288	198140	A	0.6239545941352844	And I'm referring to images, videos, they are all kind of pixels living on a grid.
198720	200892	A	0.5565348863601685	And then you can have more sophisticated things.
200946	202960	A	0.8468050956726074	You could have some meshes, for instance.
204260	208716	A	0.7512329816818237	They're all over in computer graphics and then you could have some sort of manifold.
208748	217030	A	0.884064793586731	So for instance, if you're doing maybe weather modeling or something, we live on a sphere, topologically speaking.
217720	222310	A	0.8795027732849121	So you might want to model your data as living on a sphere and so on.
224360	244110	A	0.7600483894348145	But nonetheless, even if these spaces are kind of geometrically, kind of heterogeneous, and some of them don't even have a geometrical structure in kind of a strict mathematical sense, they all have what's called a topological structure, which is kind of like kind of a weaker kind of structure, but it's kind of more general.
244560	249212	A	0.9195458889007568	And I'm going to talk a bit in a few seconds about what that means by in general.
249266	261024	A	0.5426901578903198	When you do kind of mathematical physics, you kind of have a ladder of structures where you kind of keep building on top and the more structure you have, the more sophisticated things you can do and so on.
261062	275510	A	0.8729932904243469	And kind of at the base of this diagram just have sets, just kind of a collection of elements with no kind of extra structure and then you kind of keep going up in this ladder and you add stuff on top of sets and so on.
275880	291160	A	0.5625448226928711	And as I was saying, kind of most of the work is kind of focused on maybe the top levels of this hierarchy, but it's kind of topological level, which are kind of the weakest kind of level you can add on top of sets has kind of been neglected to a large extent.
291580	305040	A	0.8450389504432678	And part of what I've been doing in my PhD thesis was essentially looking at these kind of learning problems on these kind of spaces from a more topological perspective and kind of try to fill in these blanks.
305780	315424	A	0.8852536678314209	So this is kind of the overview, okay, so if we are to adopt this topological perspective, what would that actually mean or how would that look like?
315622	321012	A	0.7603307366371155	I guess it could look in different ways, but in what I've done, in my cases, it looks kind of like this.
321146	326340	A	0.7078032493591309	So we have horizontally, we kind of have a space that could be anything.
326410	328196	A	0.7479130029678345	This is just kind of an abstract space.
328378	336712	A	0.9041954278945923	It could be a grid or things like we've seen in the previous example and kind of vertically attached to the regions of this space.
336766	337816	A	0.7257692813873291	We have data.
337998	346120	A	0.8904262781143188	So data is kind of this vertical component and you kind of see these flags kind of being kind of anchored in these regions.
346200	351256	A	0.9110904335975647	So that kind of signifies you have some data that's kind of associated with that region.
351448	357890	A	0.8573344945907593	So that's kind of the high level perspective and I'm going to make that a bit more concrete a bit later.
358340	361840	A	0.7735785245895386	And there's kind of two essential things about this picture.
362580	365312	A	0.6562756896018982	A first thing is locality.
365456	376944	A	0.8709678053855896	So the data is attached to some regions of this space, this topological space, and in that sense it's local, so it's kind of associated with the region.
376992	391336	A	0.8899514079093933	And maybe to give a concrete example, if you kind of have a temperature sensor somewhere in space, right, you could think of whatever that sensor is measuring is kind of a property of kind of the immediate surrounding around that sensor.
391368	395470	A	0.8827446699142456	So it's kind of describing some property of a region in space.
396160	398110	A	0.8687105774879456	So that'll be kind of a concrete example.
398800	406620	A	0.8814749121665955	And another kind of axiom that we're starting with is that the space has structure.
407040	420992	A	0.8720035552978516	So the space has kind of, it's kind of made up of various regions and these regions intersect in various ways and that implicitly also makes our data structured because the data is attached to these regions.
421136	424390	A	0.877248227596283	So there is kind of some structure in the data.
425800	430724	A	0.8627521395683289	All right, so that's kind of the picture and actually many of these things relate to category theory.
430772	444540	A	0.5845963954925537	I'm not going to go in depth into this because it's kind of sophisticated and I'm not an expert myself in category theory, but kind of the high level here is that category theory is kind of a nice way.
444610	457692	A	0.8886019587516785	To translate between different structure in mathematics and kind of discuss about properties of certain kinds of objects and translate that to some different kinds of objects and find all these kind of relations and connections.
457756	474096	A	0.88357013463974	And a concrete example is, for instance, if you want to study some manifolds, some surfaces, you could associate some groups to these surfaces and then any sorts of relations between these kind of surfaces, also translating some relations about these groups or some other algebraic structures.
474208	480250	A	0.7452361583709717	So you could study these manifolds by doing algebra instead of doing geometry or topology or something else.
481100	488200	A	0.8597313165664673	So also in this case, it's kind of manifesting the fact that we kind of translate these from spaces to data.
488270	497192	A	0.8488814830780029	So kind of because we associate the regions in a space, certain kinds of data, this is kind of how this translation manifests in what I've just described in the previous picture.
497256	505810	A	0.9055814146995544	So you could think of this as some sort of translation or mapping from spaces and regions in that space to kind of data attached to that space.
506580	516500	A	0.7444012761116028	But yeah, I'm not going to go in a lot of detail into this, but just kind of to keep in the back of your mind that there's this stuff lurking in the background.
517160	523910	A	0.6755017042160034	All right, so I promise this is the only math definition I'm giving in this talk and then I'll stop.
524600	540152	A	0.6522151231765747	But just because I'm mentioning topological spaces quite often, I just wanted to kind of give this axiomatic definition, which might sound sophisticated, but I have a picture at the end and hopefully it'll be clear what is it.
540286	541640	A	0.7309131622314453	So it's just a set.
541710	544444	A	0.8584356904029846	As I was saying, we start with sets and we put stuff on top, right?
544482	553448	A	0.8940395712852478	So you start with a set and then you also have a collection of subsets of this set called the open sets that need to satisfy certain axioms.
553464	557890	A	0.8503051400184631	So you could think of these open sets as kind of regions of this space, very informally speaking.
558900	568660	A	0.8305022716522217	So something that kind of has to be satisfied is that, well, the empty set and the set itself need to be open set.
568730	579380	A	0.802291989326477	So in some sense, you could think of this as saying the set itself is a region of that space very informally, which it's kind of, let's say, obvious.
579530	586484	A	0.7906084060668945	And then there's some kind of constraints about intersecting and taking units of this region.
586532	592140	A	0.8567614555358887	So if we take the intersection of two regions, we should get another one of these regions.
592800	597580	A	0.8512596487998962	And if we take a union of these regions, we should get another region.
598080	603916	A	0.5635510087013245	And there are some constraints again, like, okay, how big these intersections should be.
604018	607132	A	0.7806282639503479	There should be finite intersections, but you could have infinite unions.
607196	610796	A	0.6281118988990784	But that's a technicality and we can just skip anyways.
610828	615984	A	0.8659791946411133	But to see a picture so on the left, you just see the set x itself.
616102	622612	A	0.9075889587402344	And here I've put like a potential neighborhood structure or kind of like open set structure on this space.
622666	626068	A	0.8183173537254333	So we have an open set U, another open set V.
626154	628804	A	0.8293201327323914	By this axiom, their intersection should also be an open set.
628842	633976	A	0.8644236326217651	So you see this intersection in the middle being another open set, and then the set itself is another open set.
633998	637130	A	0.6390716433525085	So it's just kind of splitting stuff into regions, kind of.
637580	639290	A	0.6881652474403381	You could think of it like that.
640160	646604	A	0.8080716729164124	All right, so this is a topological space, and now let's add data, right?
646642	653500	A	0.8629345893859863	So we mentioned that we have data and then we have a space, and then we add data on top.
653650	656480	A	0.8634765148162842	So so far we've seen how a topological space looks like.
656550	660176	A	0.8285012245178223	Now let's add this kind of vertical stuff, these flags that you saw before.
660358	662960	A	0.8814941048622131	We just put some data on top of these regions.
663460	684644	A	0.6789523959159851	And if we put data on all the regions of the space, on all the open sets, we get these structures that in categories here, like in algebraic topology, also geometry, they are called presheaves, which sounds very fancy, but all is just kind of a definition of what I was already describing.
684692	687720	A	0.8867615461349487	Essentially, you have some data for each region.
688780	696668	A	0.8968035578727722	For instance, for region U, you have this f of U, which is kind of the data attached to region U.
696754	703680	A	0.8916600942611694	So you could think of f of U, some set with describing the data that lives there in that region.
704180	705856	A	0.7764995694160461	But there's also an extra thing.
705958	714076	A	0.8834794163703918	You have some sort of maps going between these kind of pieces of data, and these are called restriction maps.
714188	715312	A	0.6448124051094055	And why is that?
715446	720164	A	0.6569297313690186	They provide you a way to kind of zoom in if you want, right?
720202	726676	A	0.8230812549591064	Like you have the data attached to the whole set x, and then you could think, okay, how do I take this data?
726778	731128	A	0.8425187468528748	How do I go from this data to data on a smaller region on x?
731214	736388	A	0.842785120010376	So it's kind of a way to zoom in on that data, essentially.
736484	739784	A	0.8288018107414246	And I'm going to show some example in a second.
739902	742436	A	0.8799009919166565	So these are called pre sheaves.
742468	749276	A	0.7512864470481873	And just to see an example, our space here is kind of one of the simplest kind of space you could think of.
749298	751244	A	0.8695371747016907	It's just 1D or horizontal line, right?
751282	752450	A	0.7280766367912292	Just the real line.
752900	761376	A	0.8441784381866455	And then you have some regions which are just given by open intervals on the real line.
761478	766816	A	0.8816824555397034	And then some pieces of data could be functions like continuous functions on those regions.
766928	771376	A	0.8984942436218262	So here's some sample data on this first interval.
771488	773696	A	0.8353749513626099	Here's another function on the second interval.
773808	775728	A	0.8930647373199463	Here's some data on this third interval.
775824	781396	A	0.49473774433135986	And actually in this case, it happens that all these functions agree on the overlap.
781428	790760	A	0.8306799530982971	So where these regions overlap, they take the same values and we can actually glue them together in a single function over the entire region.
791120	797928	A	0.7809839248657227	So this is just an example of a preshief and it's called the preshift of continuous functions.
798104	805920	A	0.8570187091827393	So our data in this case is continuous functions and the space is just the realign and we put these functions on top of the realign.
806260	814272	A	0.6018342971801758	But it turns out because of this kind of special property, that we can kind of glue data and we uniquely get some other piece of data, right?
814406	815884	A	0.7899691462516785	We can take these three pieces.
815932	818244	A	0.7168632745742798	It's just exactly like a puzzle, right?
818282	826470	A	0.8580964803695679	We put these things together and we get a fourth thing, which is kind of a single function where we just overlap these functions, right?
826940	836024	A	0.6721583008766174	And these presheaves that satisfy these kind of properties where you can kind of glue them to get a unique piece of data.
836142	843400	A	0.6598346829414368	They are called sheaves and basically the preshave of continuous functions is actually a sheep.
844160	849070	A	0.8834517002105713	So this is kind of a way to formalize data attached to these things.
849600	852190	A	0.5763795375823975	It's going to get less technical in a second.
852960	855128	A	0.8592793345451355	So just to give more examples.
855224	858960	A	0.874367892742157	So for instance, in this way we could describe data on a sphere.
859380	862364	A	0.8544101119041443	And let's say if this data is just some vector field on a sphere.
862412	866576	A	0.8656888604164124	So let's say if this is Earth, right, this could be some wind vector field, right?
866598	874790	A	0.8619663119316101	Like if we do weather modeling or something, you just have a vector field describing the wind on the surface of Earth, right?
875160	892020	A	0.8205240368843079	And you might want to do some machine learning on top of this, where this kind of vector field has a sheet structure, and you could think of it as a sheath, because if you have some vector field on the red region, a vector field on the yellow region, I can kind of glue them together uniquely if they overlap.
892100	896140	A	0.6629760265350342	If they agree on the overlap and we get the vector field on this bigger region.
896960	915244	A	0.8168827891349792	But something that's quite nice is that even if we have a very different kind of space namely a graph which is very different from a sphere in all points of view, we can still apply the exact same kind of axioms and terminology and kind of definitions and we can have a sheath of our graph.
915292	931130	A	0.8185104727745056	So in this way we could have, for instance, some features associated to the nodes of the graph, some features associated with the edges of the graph, and there's another node which has its own features and this is actually the exact same thing we have in graph machine learning.
931500	932744	A	0.9878619909286499	So this is quite nice.
932782	950044	A	0.6040207147598267	What this kind of topological perspective allows us to do is we kind of have a unified way of thinking, if you want, about very kind of heterogeneous spaces and we can model on all of them data attached to them by using this kind of sheet terminology and other ways as well.
950082	952990	A	0.6926301717758179	But I'm not going into that in this talk.
953300	958320	A	0.8881984353065491	All right, so this is kind of an overview of what I've been doing in my thesis.
958980	970404	A	0.8223373293876648	And just to kind of dive a bit deeper into this, I just wanted to go into one paper that we did at Europe last year.
970442	970596	A	0.5491447448730469	Yeah.
970618	975648	A	0.9107572436332703	So this was last year on what's called shift diffusion.
975744	985064	A	0.570112407207489	So essentially, how can we use what I've just described to do some useful stuff when doing machine learning on graphs, all right?
985102	992540	A	0.8600005507469177	And this was a collaboration with Francesco de Giovanni ben Chamberlain pietro Leo, my advisor and Michael Bronstein.
993520	993932	A	0.7123861312866211	Okay?
993986	1000030	A	0.7889167070388794	So before I dive into this, I just want to give some background in case people are not familiar with this.
1000480	1013740	A	0.604863166809082	So the kind of favorite architecture of people doing machine learning on graphs these days are these things called graph neural networks, which are actually very simple kind of models.
1013900	1018500	A	0.8356755971908569	So in the setting you have some features.
1019000	1021744	A	0.8742779493331909	So each node in your graph will have some features.
1021792	1025936	A	0.598992109298706	This is what this h vector here denotes.
1025968	1033930	A	0.901045560836792	So it's the vector h associated with node A at layer or time t, whatever.
1034380	1047420	A	0.9096331000328064	So you have some features for each of these nodes and what you're doing each of if you're at a certain node, you want to kind of compute a new representation or new features for this node at the next layer.
1048400	1054192	A	0.8857394456863403	So essentially are learning representations and what the graph neural networks are doing.
1054326	1061600	A	0.9163810610771179	This node will receive a message from all the other nodes that are neighbors with this node.
1061940	1075140	A	0.8644809126853943	And this message can also be passed, can use some neural networks in there, but essentially it's some processing of these features of the neighbors and these are aggregated into this message.
1075210	1088580	A	0.8471949696540833	So here in Green and then this is passed through some update function that combines the message from the neighbors with the old representation of this node and it gives you a new representation at the next layer.
1088740	1090296	A	0.5515637397766113	And this happens for all the nodes, right?
1090318	1096860	A	0.8433611392974854	So then you get some new representations for this node and this is one layer and then you kind of keep repeating this for as many layers as you like.
1097010	1100376	A	0.818902850151062	So this is kind of how you do deep learning on graphs.
1100568	1112076	A	0.826515793800354	It's kind of a very simple recipe and most models actually vary in the way they kind of compute these messages and in the way this update function is designed.
1112268	1116176	A	0.6667495369911194	But that's kind of the parameters most of these models use.
1116358	1121430	A	0.7274169325828552	Otherwise they all kind of respect this framework and work in this kind of particular way.
1122520	1129536	A	0.8628069758415222	And to give you maybe an example for why you would want to do this, you might want to do node classification.
1129648	1132472	A	0.6543693542480469	This is kind of a classic problem in graph machine learning.
1132526	1136120	A	0.5265653133392334	There are others, but I'm just going to talk about this because it's easier.
1136860	1141912	A	0.8657877445220947	So you have a graph and this graph has nodes that have different labels.
1141976	1145980	A	0.6762994527816772	Here there's just two kinds of labels, this orange and blue.
1147600	1151384	A	0.8129851818084717	And you have some edges between these nodes.
1151432	1164560	A	0.801880419254303	And what you want is you want to do this kind of message passing that I was describing to compute some representations for these nodes where you can easily classify the blue and orange nodes.
1165080	1179496	A	0.8115062117576599	Now something that's quite interesting is that for many kind of graph neural networks, depending on the properties of these graphs and how these kind of different nodes are connected, their performance might vary quite a lot.
1179678	1183876	A	0.6000169515609741	So in particular they're affected by this property called heterophili.
1184068	1189144	A	0.6860752701759338	So this is kind of a measure of how much opposites attractive you want, right?
1189182	1192360	A	0.7951197028160095	So it has a very simple formula.
1192780	1198524	A	0.8704242706298828	Basically you take the number of edges between orange and blue nodes and you divide by the total number of edges, right?
1198642	1209836	A	0.8111861944198608	So basically you kind of check how many connections we have in this graph between things that are quite opposite to each other versus connections that are between similar kind of nodes.
1210028	1216240	A	0.7710238695144653	So if you have a lot of these kind of heterogeneous connections, then you have very high heterophili.
1216400	1219536	A	0.7059036493301392	And it turns out that many graphene networks actually struggle in that setting.
1219568	1223460	A	0.5420103669166565	It's very hard to classify things in that setting.
1223800	1237384	A	0.7585976123809814	And intuitively you could kind of also figure out why because you could easily apply some kind of reasoning where oh, this node looks a lot like this other node is connected to.
1237422	1241480	A	0.880760133266449	So they kind of must be in the same community if you want or in the same label.
1241560	1251336	A	0.8399107456207275	But it's much harder to do that when all things are kind of different from each other and these communities kind of don't form right, even visually.
1251448	1260032	A	0.5987512469291687	If you see a graph and it has some nicely clustered communities, it's quite easy to draw a line between those and say, oh, this is a community, is another community.
1260166	1263692	A	0.49971678853034973	But if things are very mixed, then it's quite challenging.
1263756	1270950	A	0.4947654604911804	And it turns out it's also challenging for these models, not just for kind of our intuition when we would have to do this.
1271880	1282090	A	0.5275303721427917	So this is kind of some problem where this topological perspective I was mentioning will be used to do some useful stuff.
1283580	1283992	A	0.7123861312866211	Okay?
1284046	1287476	A	0.9004957675933838	So coming back to Sheaves on graphs.
1287668	1294910	A	0.5060175657272339	And at this point I think you can largely forget what I mentioned in the introduction or if there's something you misunderstood there.
1296000	1300300	A	0.6224119663238525	We kind of start from zero bit here, so there's no problem.
1300370	1307660	A	0.8874201774597168	So on the left you just have a graph which is kind of the incidence structure of a graph.
1307740	1312112	A	0.6840696930885315	I just drawn here the simplest possible graph that has two nodes v and U.
1312246	1314112	A	0.8344789743423462	And then there's an edge between them.
1314166	1316108	A	0.7386149168014526	So this is just a graph with one edge.
1316204	1317812	A	0.8031253218650818	That's all that's going on here.
1317946	1323236	A	0.818507730960846	And I've just represented it by kind of in this kind of incidence structure kind of way, right?
1323338	1330272	A	0.4933832287788391	Node v is incident to node e and node u, sorry, edge e and node U is incident to edge e.
1330346	1337076	A	0.6743574738502502	So this is just an incident structure and what this kind of triangle symbol is showing is just this incident structure.
1337108	1340568	A	0.7899169921875	It's just a way to symbolize this incidence relation if you want.
1340734	1342716	A	0.7396792769432068	Okay, so this is just a graph, right?
1342818	1348584	A	0.8473966121673584	And a way we can kind of think of field zone graphs is just mapping this graph structure.
1348632	1351528	A	0.8607516288757324	So this is kind of this categorical theory translation.
1351624	1356720	A	0.6636114120483398	We translate this graph into something else which looks very similar.
1356790	1361024	A	0.8362774848937988	The structure is kind of the same, it's just kind of the meaning of these things change.
1361142	1366160	A	0.8869661092758179	So for each node v we have here, this will be a vector space.
1366310	1368340	A	0.799959123134613	So F of v is a vector space.
1368490	1372564	A	0.844013512134552	For each node u we have F of U which is another vector space.
1372762	1377190	A	0.8256165981292725	For each edge e we have this Fe which is another vector space.
1377640	1384900	A	0.8921027183532715	So all nodes have their own vector spaces and the features associated to those nodes leaving those vector spaces.
1384980	1389992	A	0.8962261080741882	So basically for each node we have a vector space of features that's all that's going on so far.
1390126	1398744	A	0.8670569062232971	And also these arrows that these incidence relations also translate into something and they translate into the obvious thing linear maps.
1398792	1404272	A	0.8516928553581238	So if these are vector spaces, then these things should be linear maps or just some matrices essentially, right?
1404326	1427220	A	0.8187862634658813	So for each arrow you see here we have a matrix and something that I'll argue and show in a few slides is that basically message passing is very similar on graphs, is very similar with group actions in group theory.
1427800	1430008	A	0.701712429523468	So let me explain exactly why.
1430094	1436708	A	0.9063793420791626	So we kind of can think of what we have on the left these arrows from the incidence relation.
1436804	1440552	A	0.8687551021575928	We could think of these arrows as kind of some buttons we can press.
1440686	1442476	A	0.7983575463294983	So what do I mean by that?
1442578	1462400	A	0.8883082866668701	So if we have this node v on the left, right, and this e, now if we have some features, some feature living in FOV, right, we could just kind of press this arrow button here and then if we multiply this matrix by this feature, we will get an edge feature.
1462740	1472816	A	0.844435453414917	So it's kind of like if you go along this arrow, this matrix will multiply this feature and this vertex feature and it will give you an edge feature.
1473008	1481328	A	0.8798547983169556	So you could think of these arrows as kind of giving you some sort of actions that you can play with to move features from vertex to edge and edge to vertex.
1481424	1483544	A	0.8387325406074524	So in this case it's kind of a left action, right?
1483582	1484472	A	0.8219601511955261	So this is what I'm saying.
1484526	1490872	A	0.8886126279830933	I'm taking this arrow, which is this one here, and I act on some features of node v.
1490926	1503528	A	0.8955641388893127	So this HOV that lives here and how I do that is I just take this matrix, this matrix associated with this arrow, and I multiply this vector HOV.
1503624	1506620	A	0.8401705622673035	So just matrix times vector, that's all.
1506690	1508236	A	0.8136661052703857	And then we get an edge feature.
1508348	1511184	A	0.8493030667304993	So this is just kind of a way to move from here to here.
1511222	1513616	A	0.4878786504268646	So this already kind of looks a bit like message passing, right?
1513638	1523412	A	0.915052056312561	We're kind of passing a message from this vertex to this edge, but now we also need to pass a message from this edge to these other vertex U.
1523466	1529592	A	0.8475250601768494	So we need to get from V to U and we did that by passing through e.
1529726	1533236	A	0.8542361855506897	So by doing that, we could do that by kind of going in reverse.
1533268	1541012	A	0.8188572525978088	So we could have a right action where instead of applying this matrix, we applied adjoint matrix.
1541076	1543016	A	0.6042621731758118	So that's just a transpose matrix.
1543128	1551870	A	0.7675190567970276	So if we want to go from here to here, instead of applying this matrix, we apply it transpose because we want to go the other way around.
1553620	1557392	A	0.8242504596710205	If we compose these things, then we can move features from V to U.
1557526	1568224	A	0.9045253396034241	So this is just a way that kind of we can apply these actions to do message passing and these are called shift actions or preshift actions.
1568352	1576260	A	0.9078419208526611	And I'm going to now show what's kind of the relation between this and what we have in group theory.
1577100	1586248	A	0.8840700387954712	So one way to represent a group is by kind of having some sort of graph, like here on the left.
1586414	1593244	A	0.7276109457015991	So we kind of have some star object, it's just kind of a dummy thing there.
1593442	1596044	A	0.8720499873161316	But all the group structure is in these arrows, right?
1596082	1597816	A	0.727845311164856	So for each group element.
1597928	1601500	A	0.8981056809425354	So let's say this g is a 90 degree rotation, for instance.
1602160	1606530	A	0.8986326456069946	Let's say we do have a group of rotations, just to have some concrete example.
1608820	1611868	A	0.8927578330039978	So this arrow could correspond to a 90 degree rotation.
1611964	1616236	A	0.6545064449310303	We have another arrow that does the opposite, minus kind of 90 degree rotation.
1616268	1618496	A	0.7497345805168152	That's the inverse of that transformation.
1618688	1620756	A	0.8816009163856506	So this is kind of the structure of this group.
1620858	1625750	A	0.9048011898994446	And if we have, we also do this similar kind of translation as we've just seen.
1626360	1629590	A	0.8671416640281677	So basically we define a preshift on this group.
1630060	1632504	A	0.771609365940094	We map this star to a vector space.
1632542	1636120	A	0.8633613586425781	So the star kind of replaces the vertex we had before.
1636190	1640536	A	0.5174221396446228	Now we just have a single vertex and it's just these arrows we have.
1640718	1645356	A	0.8631905913352966	So the star is mapped, this vector space that you show here in blue, right?
1645538	1657452	A	0.7969241142272949	And now, if we actually do group actions, which are kind of a very well established concept in group theory, well, for instance, if you want to act on this vertex sorry, not vertex on this vector.
1657516	1658656	A	0.6041891574859619	V right here.
1658758	1665120	A	0.8783178925514221	You have a vector in this vector space, and you want to act on it by this group transformation g.
1665190	1667184	A	0.8035278916358948	So, essentially, you want to press this arrow.
1667232	1669350	A	0.7984856367111206	So you apply some action on it.
1670040	1686904	A	0.8833891153335571	Then what you do is well, because of this translation, this g has been mapped to some matrix, which is the rotation matrix, the corresponding rotation matrix, and you apply this rotation matrix on v and you get like a 90 degree rotation here.
1687102	1688792	A	0.6494236588478088	So this is what's going on.
1688846	1691900	A	0.8668022751808167	This kind of vertical vector is showing the rotated vector.
1693040	1697180	A	0.8546896576881409	So this is completely analogous with what we've seen on the previous slide.
1699040	1702792	A	0.8331906795501709	This is how kind of sheaves connect these kind of actions.
1702936	1711196	A	0.7774448394775391	So essentially what you could think of as message passing is same as group actions in group theory, but you just replace this group with a graph.
1711308	1713344	A	0.8646742701530457	So it's kind of analogous to that, right?
1713382	1719270	A	0.7992970943450928	So it's just kind of a different kind of translations where we replace the object on the left.
1719720	1722916	A	0.7367460131645203	Now it looks like this is a graph, this is a group, right?
1723018	1725750	A	0.7900190353393555	But kind of the rest stays exactly the same.
1726840	1741740	A	0.6638006567955017	And this kind of gives us a way to formalize in a way by looking in this topological perspective to connect all these kind of symmetries and things like that that have been explored quite a lot in machine learning to message passing on graphs and to see one way in which they are related.
1742720	1750190	A	0.6336923837661743	Okay, so now you might say, okay, this was all very sophisticated and nice, but you know, what, is this going anywhere, basically?
1750880	1754688	A	0.8348080515861511	And I'm just going to show you kind of a very short example.
1754854	1757760	A	0.7378340363502502	There's more, but the time is limited.
1758180	1766508	A	0.7925701141357422	And something we showed is that, as I was saying in the beginning, many graph neural networks kind of struggle in these heterophilic graphs.
1766604	1787688	A	0.654438853263855	And what we showed is that no matter how heterophilic or kind of weird your graph is, you can always kind of find some shift structure, essentially kind of a message passing neural network, that if you use sufficient layers, it will be able to disentangle the classes of the nodes, right?
1787774	1796748	A	0.6949585676193237	So just to show you in this picture what you have here on the very far left, the colors of the nodes, they show the class.
1796834	1799644	A	0.7870526909828186	So there's three colors here.
1799682	1801150	A	0.8618589043617249	So three classes, right?
1801520	1807404	A	0.8983420133590698	And this is kind of the graph in the beginning and the position of the nodes in this box denotes the features.
1807452	1810320	A	0.8311507701873779	So that's a way to kind of just to visualize the features.
1812660	1817100	A	0.8440203070640564	The 2D position is actually the 2D feature vector of each node.
1817260	1820884	A	0.7626388669013977	And you can see in the beginning, everything is kind of super messy and entangled, right?
1820922	1830280	A	0.8129675388336182	Like if you want to classify these nodes, it's kind of very hard because their representations, their initial representations are very messy and kind of intertwined.
1830780	1844516	A	0.651178240776062	But as we stack more layers of a particular kind of sheath or a message passing model, you see how progressively these classes get kind of more disentangled and more disentangled at each new layer.
1844708	1850220	A	0.5254949331283569	So these representations kind of collapse and they form these kind of clusterings, right?
1850290	1858640	A	0.6980245113372803	And then when you get with something like at the end, you can kind of see these three communities very clearly and it's extremely easy to separate.
1859140	1871908	A	0.8147289156913757	And kind of the essence behind these results was we showed for different kinds of problems what sorts of chief or message passing models you need by using this theory to solve kind of problems.
1871994	1885432	A	0.7384700179100037	And this is quite important because it kind of shows you some important bits and pieces in the architecture that you might want to kind of change or use in order to solve certain kinds of problems.
1885566	1888196	A	0.7031841278076172	And we also had some sort of impossibility resolved.
1888228	1894510	A	0.7383549213409424	So if you use a graph neural network of some kind, you can't solve this problem or you'll struggle to solve this problem.
1894960	1900430	A	0.5025492906570435	And we also saw, okay, if you use some more general ones, then you might have a chance.
1901440	1907890	A	0.8664440512657166	So this is kind of some high level view behind this theoretical stuff.
1908500	1919072	A	0.9064328074455261	And what we actually do in practice is to essentially learn these message passing functions or to learn the sheath or these matrices.
1919216	1934280	A	0.6046176552772522	So in practice, like when someone gives you a node classification task, it's very hard to know beforehand what exactly is the right sheep or the right message passing model to solve that task.
1934940	1937976	A	0.8365873694419861	And what we do essentially, we learn that from data.
1938078	1941144	A	0.8703369498252869	So we learn these matrices that do the message passing.
1941192	1948350	A	0.8559052348136902	We learn them from data by using some neural networks which are shown here in red.
1949040	1955116	A	0.8466173410415649	And then you learn how to kind of transfer features between these vector spaces and kind of move them around.
1955218	1965460	A	0.8969371318817139	So this is just showing how these vectors, which are features of these nodes and edges, how they're kind of moved around by kind of going through via these matrices, just some matrix multiplications.
1967400	1970916	A	0.8705361485481262	Okay, so that's kind of the high level view behind this model.
1971018	1983348	A	0.8925224542617798	And we evaluated this on some kind of real world heterophilic data sets where you have to classify nodes based on kind of various communities or different kinds of labels.
1983444	1989876	A	0.5602892637252808	And these data sets going from right to left, they are getting more heterophilic.
1989908	1993224	A	0.6983432173728943	So in some sense more challenging for classic architectures.
1993352	2001020	A	0.9039286375045776	And our models, which are kind of inspired by all this stuff that I mentioned, they score quite highly in these benchmarks.
2001520	2010016	A	0.8050827980041504	And at the same time, they also revealed some or justified some various choices that other models in this space have done.
2010118	2014252	A	0.6064751148223877	But maybe they were not so well justified, or maybe they had different kind of motivations.
2014316	2024420	A	0.7966228127479553	We also managed to kind of show why various things they were already doing, why they made sense from the point of view of this kind of theory.
2025560	2029450	A	0.705487072467804	All right, well, that's all I had.
2030140	2041470	A	0.9150128364562988	Yeah, thanks for listening and yeah, happy to chat more about this and also have lots of backup slides in case, depending on how far we venture off with this question.
2044320	2044828	A	0.84200119972229	Cool.
2044914	2046780	B	0.9400209784507751	Well, awesome work.
2046850	2048568	B	0.9769351482391357	Thank you for the presentation.
2048744	2055648	B	0.5992335677146912	For people who are in the live chat, they can write some questions, but there's many things I think we could talk about.
2055814	2076096	B	0.7245103120803833	So I want to start with reading a quote from an abstract of the paper by von der Laur, Kudal and DeVries just to kind of ground this in the active inference context and really justify why the message passing approaches that you are describing are helping in the active inference modeling.
2076288	2077216	B	0.7479000091552734	It's two papers.
2077248	2096856	B	0.7065712213516235	It's called Realizing Synthetic Active Inference Agents and they wrote, with a full message passing account of synthetic active inference agents, it becomes possible to derive and reuse message updates across models and move closer to industrial applications of synthetic active inference framework.
2097048	2108690	B	0.8339656591415405	So how does knowing the message passing structure help reuse a model across different settings or facilitate the legibility of the model?
2110100	2110752	A	0.7360090017318726	Right?
2110886	2124036	A	0.6095791459083557	So first of all, I'm not super familiar with the kind of active inference literature, so you'll have to help me there a bit to anchor maybe the discussions a bit more into that.
2124218	2140520	A	0.8731854557991028	But I think if I understand correctly, the kind of question you're getting at is basically how can kind of message passing help us generalize in kind of various kinds of settings or maybe from one graph to another and things like that?
2140590	2147470	A	0.6621302962303162	And this is a kind of active area of research, how exactly digitalization is happening.
2147840	2159616	A	0.7182665467262268	But something you could notice, for instance, something that for instance, was shown like these models are quite good at, for instance, plotting patterns or structures depending on how exactly you implement them.
2159638	2166852	A	0.8458621501922607	But for instance, let's say you have a triangle in your graph or that'll be kind of the simplest structure, right?
2166986	2177136	A	0.8814029693603516	You have a triangle or some other kind of kind of gadget in your graph, like particular subgraphs that might show up in different kinds of various graphs.
2177168	2190584	A	0.7313076853752136	The graphs themselves might look completely different from each other, but these kind of patterns might kind of be reemerging in multiple like local patterns might reemerge in multiple graphs and that could help you a way to kind of generalize, right?
2190622	2201404	A	0.7070363163948059	Like you could see, for instance, if you have clicks, they're super important in kind of when you do social network modeling and things like that because they kind of show this kind of close group of friends, right?
2201442	2205648	A	0.6684018969535828	They all talk to each other, so they kind of form a click like everyone's connected to each other, right?
2205734	2220230	A	0.785116970539093	And then you might be able to use that engine like another completely different social context where these agents are again kind of communicating in a similar manner or are connected in a similar manner, even if the kind of overall pattern is quite different.
2220920	2226692	A	0.5553942918777466	And it goes way beyond just kind of structural similarities because there's also features in there.
2226746	2233944	A	0.7467164397239685	So there's combinations of kind of structural patterns and features that give you even more complicated patterns, right?
2233982	2243708	A	0.8607045412063599	Like you might have a triangle, but then also two of the features in this triangle look in a certain way and one that looks in another way.
2243874	2251500	A	0.8541488647460938	So that gives you even more kind of refinement and even kind of richer pattern detection abilities.
2252880	2259296	A	0.8769034147262573	So you have essentially this ability to kind of spot patterns at multiple scales as well.
2259318	2261948	A	0.8298588991165161	So you could see this happening at multiple scales.
2261964	2263792	A	0.8523328304290771	You could have patterns of patterns, right?
2263846	2269110	A	0.7777146100997925	You could have entire communities connected in various patterns and so on.
2269480	2271732	A	0.836811363697052	And again, it's kind of also a research question.
2271786	2275030	A	0.8442772030830383	How do you capture these hierarchical patterns and so on.
2275960	2284250	A	0.6338273286819458	In general, you have to do more message passing if you want to capture things that are further away from each other because otherwise they can't talk to each other, right?
2284700	2291130	A	0.6815387010574341	So, yeah, I don't know if that actually answered your question or if I was kind of going in the right direction there.
2291580	2292148	B	0.9619264006614685	It's great.
2292174	2297756	B	0.9322397112846375	It brings up a lot of different cool ideas like this patterns all the way down, but totally agree.
2297858	2309516	B	0.5395265817642212	I think we can now perhaps explore some more specific connections to active inference because hopefully the listenership or viewership of this, it's kind of like a two way street.
2309548	2318036	B	0.8469820022583008	Like some people may be coming from more of your background and then learning about active inference and generative models as a specific system of interest for The First time.
2318058	2334504	B	0.6420800685882568	But also, certainly for A lot of people in the active inference space, these methods coming from category theory have only recently come up to, I guess, more prominence in Bayesian modeling, at least where we are.
2334542	2336410	B	0.9614154100418091	So it's a cool connection to make.
2336940	2346184	B	0.6564193367958069	I think one of the biggest touch points off the bat was, like you mentioned, multiplying a matrix by a vector and interpreting that as an edge.
2346312	2358160	B	0.8912906050682068	So just in the inference part of the generative model about sensory observations, we always talk about the thermometer observation and then the underlying hidden state temperature.
2358580	2361890	B	0.6586312651634216	So that exactly describes that case.
2362340	2371088	B	0.797710657119751	And that's why we can represent the active inference generative models, the perceptual parts and the action parts in terms of matrix multiplication.
2371264	2382330	B	0.7025789022445679	It's why the MATLAB code for generative models does look mostly like matrix multiplication and it can all be done explicitly that way.
2386220	2388440	B	0.7252988815307617	Are there models that don't have this feature?
2389360	2404880	B	0.8857765793800354	Or what do we gain by having all of our edges defined as appreciative action with a matrix and a vector in this setting of agent generative models with perception and action?
2406500	2407890	B	0.809051513671875	Any thoughts on that?
2408420	2417812	A	0.8812209367752075	Yeah, I think essentially kind of the graph structure is kind of telling you these things interact in some way, right?
2417866	2443710	A	0.897508978843689	So there's some communication between these vertices if we're kind of in a crash setting, right, and then kind of what the sheath is giving you or any message passing model essentially is expressing a way in which way that connection should manifest in the model or in what way that connection should be used to process information.
2444480	2455600	A	0.8725543022155762	So in this case I was mentioning, okay, you have linear maps because you could go on the type if your type of data are vector spaces, then this transformation will be some sort of linear maps.
2456740	2458864	A	0.7578309178352356	But it doesn't necessarily have to be.
2458982	2462848	A	0.8894234299659729	So for instance, it could go to any nonlinear transformation, right?
2463014	2464384	A	0.5417941212654114	And this is what's happening in general.
2464422	2473620	A	0.8812729120254517	In practice, if you have a neighbor, the message coming from that neighbor could be modulated by any sort of transformation you want.
2473690	2482344	A	0.8031812310218811	So it could be linear, it could be nonlinear, it could be something, I don't know, you can specify it basically.
2482542	2489640	A	0.8146396279335022	But essentially you could think of this as you have a structure level telling you who should communicate to whom.
2489980	2497192	A	0.7832650542259216	And then you kind of have some semantics that this kind of shift is adding on top saying how should these things communicate?
2497256	2497484	A	0.7360090017318726	Right?
2497522	2502508	A	0.7762243151664734	Like the first thing is who should communicate or what should communicate.
2502604	2510988	A	0.8988994359970093	And then the semantics we add on top essentially describe how should that communication manifest.
2511164	2512000	A	0.6528839468955994	Essentially.
2514340	2515456	B	0.9677404165267944	Very cool.
2515558	2521444	B	0.8230693936347961	I think that maps exactly to how we talk about the sparsity of variables in degenerative model.
2521642	2534772	B	0.8990694284439087	So here the topology of the nodes in the graph that we want to do message passing on are going to be describing the agent and the environment or the generative model that includes perception, cognition and action.
2534916	2544232	B	0.8303785920143127	So a lot of people have proposed different sparsity architectures for integrated modeling of perception, cognition, action.
2544376	2551592	B	0.8554201126098633	So one example would just be like kind of around the clock, like action influences the environment, environment influences perception.
2551656	2576832	B	0.8865319490432739	Back to cognition, you could add a self loop using an arkov blanket and different kinds of connectivities and that defines the sparsity topologically, which is where you showed the stack and you were on the second and the third levels, I think, of the stack and then what flows it has to be described, what that edge does.
2576986	2579272	B	0.7636006474494934	So what is that?
2579326	2581880	B	0.7777818441390991	That is also being provided.
2582940	2584008	A	0.5121256113052368	Yeah, exactly.
2584094	2588408	A	0.6764559745788574	And it could even go to the extreme where does that edge actually do anything?
2588494	2602716	A	0.7427229881286621	So for instance, if you have a matrix that's just the zero matrix, for instance, associated to that edge, it will just kind of multiply by zero and that gives you zero and it's kind of essentially pruning that edge, right?
2602738	2606224	A	0.8534746170043945	Like I kind of get rid of it, I don't want that communication to happen.
2606342	2619108	A	0.660598874092102	But there's also kind of this possibility where these kind of semantics, they override the structural level where you say, okay, I don't need to communicate with this other agent person or whatever.
2619194	2624196	A	0.8415782451629639	It depends on what these rates actually mean and in what context you are.
2624298	2635892	A	0.9068949818611145	And then there's also the case where you could do some sort of selective pruning where this matrix depending on so in kind of linear algebra, the matrix has a kernel.
2635956	2639560	A	0.5502668619155884	So it's all the stuff that that matrix sends to zero.
2639630	2641800	A	0.7046289443969727	So what vectors are sent to zero, right?
2641870	2645180	A	0.7055173516273499	But not everything will be sent to zero unless you're the zero matrix.
2645840	2651964	A	0.8283044099807739	So depending on the features of the neighbors, you could also just send some of the neighbors to zero, right?
2652002	2654732	A	0.7816260457038879	And that kind of removes those neighbors from the equation.
2654796	2660044	A	0.6135683655738831	They just kind of get they're not factored in anymore.
2660172	2682230	A	0.8385850191116333	So you kind of have this it's a way to get this parsity, I guess, that you were also talking about where certain only maybe a small subset of the inputs or kind of only subset of the features are actually kind of doing some meaningful stuff among the neighbors and everything else will be kind of zeroed out.
2683260	2694520	B	0.49051976203918457	Yeah, that makes me think of the Lasso regression, which tries to set most variables of having an impact of zero so that a few hopefully important variables really pop out in the analysis.
2694600	2707730	B	0.7992309927940369	But also there's newer techniques, I guess, of attention modeling and reweighting that isn't just like, okay, set five of them to one and then the rest of them to zero.
2708260	2709420	B	0.7382645606994629	More nuanced.
2709500	2721156	B	0.4970230460166931	So I think that sparsity with the expressivity is basically the best of both worlds because you do want to have a situation where there is an edge, but the attention being paid to it is zero.
2721338	2728980	B	0.678756833076477	So functionally, that doesn't have an update on the belief state, even though in principle the edge exists.
2729320	2735624	B	0.6606781482696533	And that's why we can model situations where the agent believes they have impact in the world.
2735662	2740824	B	0.7235007286071777	But actually, just because the edge in principle exists doesn't mean that it has any given impact.
2740952	2754460	B	0.7196840047836304	And so that allows the articulation of these models where they factorize and keeps interpretable motifs in terms of just little clusters of motifs.
2754620	2761024	B	0.9032792448997498	Here in our case describing the action perception and cognition types of systems of interest.
2761142	2763970	B	0.5297592878341675	But people, I believe, already implicitly do this.
2764900	2769376	B	0.9127746224403381	They will often add an adjective and refer to x kind of active inference.
2769408	2774740	B	0.866860568523407	So like deep active inference with a temporal horizon, sophisticated active inference with this kind of nesting.
2775160	2777844	B	0.8689639568328857	And those are pointing to a given feature.
2777892	2782600	B	0.5245848298072815	But of course, those features, as we're hoping, should be composable.
2783500	2797884	B	0.5759275555610657	And so this seems to be bringing tools that are even more general than just action perception modeling because they're at a lower level of abstraction than any specific system of interest.
2798082	2812800	B	0.9545148611068726	But where this work and kind of timeless thinking around cybernetic systems come together through the active inference generative model as a Bayes graph, it gets very exciting.
2813460	2814208	A	0.5491447448730469	Yeah.
2814374	2824224	A	0.749299943447113	And maybe also something worth emphasizing here is that even if this kind of semantic level can get rid of some edges, right, by doing this kind of pruning.
2824352	2828020	A	0.7111459374427795	Something it cannot get rid of is the computation.
2828180	2834952	A	0.8238813281059265	So something that kind of that structural graphs level forces you to do.
2835006	2838392	A	0.8212101459503174	It kind of tells you what should you spend compute time on, right?
2838446	2846252	A	0.823894739151001	Because even if you're going to decide to prune an edge, you still need to decide that which takes compute time.
2846306	2851976	A	0.8417947888374329	So you still need to look at all your neighbors if you're a node, right, and decide what to prune.
2852008	2855948	A	0.7860864996910095	Or maybe you don't prune anything or whatever, but you have to look at every edge.
2856044	2869168	A	0.8709639310836792	And one way to look at this is the graph structure defines you a computational graph or kind of a computational series of computational steps you have to execute.
2869264	2877464	A	0.8865243196487427	And then the kind of the sheet structure or the message passing model actually specifies what those steps are and in what particular way they look.
2877502	2878090	A	0.5662814974784851	Exactly.
2879900	2880840	A	0.7161270976066589	That's one point.
2880910	2889376	A	0.8347424864768982	And you also mentioned attention, and actually I'm glad you did, because this is actually quite related and in certain ways more general than attention.
2889428	2896332	A	0.9165484309196472	And actually, maybe going back to this slide, it might be a nice way to see this.
2896466	2900380	A	0.6741468906402588	So here basically what happens in attention.
2900880	2906848	A	0.49153533577919006	Instead of learning these matrices that we learn here in attention, you learn attention coefficients here.
2906934	2908316	A	0.7243790626525879	So you just learn a scalar.
2908348	2909804	A	0.6795499324798584	That's the attention coefficient.
2909852	2917948	A	0.8678916096687317	How much attention should I pay to essentially this overall edge, let's say, which will be just a scalar?
2918044	2923056	A	0.5098913908004761	What we do is kind of a bit more complicated because you just learn, how do I transform these neighbors?
2923088	2929412	A	0.8348561525344849	So it's kind of a whole matrix rather than a single scalar, but there's also some subtle differences.
2929476	2940472	A	0.9449264407157898	But in a follow up work we did, we also combined this with attention and went a bit more general and that also worked quite well.
2940526	2943820	A	0.7961430549621582	But the kind of underlying idea is very similar.
2943890	2949644	A	0.8678728342056274	You want to modulate the way you transform information based on the information itself, right?
2949682	2953544	A	0.7675768733024597	So you have this kind of one level of recursivity.
2953592	2957584	A	0.7832660675048828	If you want that, you are also alluding to that.
2957702	2973364	A	0.8597444891929626	It happens in active inference, where, okay, so if I'm node v, right, my neighbor knew it has some features, and based on these features, which are xu, I'm going to find out the matrix that will be used to process xu, right.
2973402	2977348	A	0.6064347624778748	So it's kind of very recursive and it's what happens with attention, right.
2977434	2985144	A	0.8899942636489868	Based on the features of node u, I'm going to compute an attention coefficient that I'm going to apply to this feature of you, right?
2985182	2989460	A	0.8855398893356323	I'm going to decide based on this feature, how much attention should I pay to it.
2989630	2995310	A	0.8822463154792786	And here we decide how should I process it more generally in a linear way.
2996320	3000910	A	0.5536164045333862	So you have this kind of loopiness structure embedded in there.
3002880	3003676	B	0.9184247851371765	Awesome.
3003858	3008060	B	0.969913899898529	I'll bring up a few more points because I think there's so many great pieces.
3008140	3010464	B	0.8054931163787842	So Toby St.
3010502	3022176	B	0.9197902083396912	Clair, Smyth who we recently discussed his dissertation in Livestream 54, introduced a term or at least a phrasing, the compositional cognitive cartography.
3022288	3045208	B	0.7714293003082275	And so thinking about the compositionality of cognitive systems, and I think what you're describing here with this notion that the mappings are more general than the kind of attention mechanisms known, famously today, that those represent, like a lower dimensional special case of one kind of architecture.
3045384	3056130	B	0.6967335343360901	Makes me think about how the Bayesian graph is kind of semantic in principle and can have all of these nice categorical formalisms around them.
3058180	3069636	B	0.5874196290969849	And you can even build the connector to empirical data with the presheaf and the sheaf, which may be news to even many empirical researchers doing data analysis certainly was for me.
3069738	3089412	B	0.813930094242096	But the message passing provides a rigorous translation from whatever semantic model is proposed topologically to an implementation procedure that can be planned for and executed in linear time or at least with definable characteristics.
3089476	3099576	B	0.6692497730255127	So message passing plays a really important part in going from the abstract what is possible, to the implementations of any of these actual models.
3099608	3123140	B	0.5527318120002747	And it does it in a really general way where is it accurate to say that we hope that implementation with message passing compatible generative models will kind of roll out better because we won't have some of the engineering challenges that less reusable abstractions might carry?
3125880	3127012	A	0.610451340675354	It's hard to say.
3127066	3132760	A	0.7268763184547424	I think there's also certainly some limitations to this paradigm as well.
3132830	3145052	A	0.6819101572036743	So just kind of doing this kind of message passing, I think, as you were mentioning, one thing is that it kind of scales up quite easily, like linearly with the size of the graph, but that also come at a cost.
3145106	3150060	A	0.6435951590538025	So there's certain results showing this has limits in expressivity.
3150640	3169576	A	0.8481661081314087	So if you actually want to go beyond this, for instance, instead of just looking at pairs of nodes, you have to look at tuples and these kind of high order groupings of nodes in order to kind of get higher explicitity.
3169628	3184280	A	0.7426267862319946	There's all sorts of techniques to do that and there's always this kind of tension between being more expressive and being efficient that will always be there in any sort of algorithm or method.
3186780	3188410	A	0.5073633790016174	It's kind of hard to say.
3189340	3192424	A	0.7414620518684387	We can definitely say this is kind of not the optimist solution.
3192472	3211884	A	0.6616026163101196	Let's say if you want to do things message passing in itself but maybe doing some sort of computations on graphs could be maybe also something that's kind of maybe missing a bit in kind of the graph ML setting.
3211932	3219620	A	0.7285499572753906	Is the context where you assume your graph is known.
3220280	3227704	A	0.8441236019134521	And you need to have some graph structure, at least a sensible way to construct it.
3227742	3227944	A	0.5664745569229126	Right.
3227982	3237370	A	0.6893501877784729	But for many kind of more I don't know, how should I phrase that?
3237900	3244670	A	0.7003851532936096	I guess for less clearly defined things like, okay, if I'm an agent doing perception in the real world or something, right?
3245600	3254844	A	0.8608033061027527	If I'm trying to create a graph of the world, what's an object, what do I create a node for?
3254882	3255084	A	0.7360090017318726	Right?
3255122	3259888	A	0.865709125995636	If I want to have one note or object and there's some connections between objects and things like that.
3260054	3263968	A	0.6558468341827393	I know it's like some wild example that comes to mind.
3263974	3266956	A	0.7287916541099548	I don't know if you actually want to do that but let's say you want, right?
3267078	3272292	A	0.5385657548904419	Then there's also all these kind of blurry things like what's an object and what's not an object?
3272346	3276352	A	0.8971344232559204	What's kind of somewhere in between maybe is that a node?
3276496	3281110	A	0.8741438984870911	So it's kind of like what I'm trying to say, that the graph structure is kind of very discreet, right?
3281560	3284856	A	0.7083876729011536	The node is either there or it's not there and edges there is not there.
3284958	3287096	A	0.575935423374176	But then the world is kind of very fuzzy, right?
3287118	3298140	A	0.7650439143180847	So if you use graphs as a model for your world then there probably has to be some decision to be made somewhere about these kind of fuzzy concepts.
3299200	3308720	A	0.8831053376197815	They actually translate in a concrete graph entity like an object, an edge or whatever or not based on some kind of inference procedure.
3309860	3319152	A	0.6850100755691528	And I don't know if we do that or not as kind of humans as intelligent agents, but that's kind of some interesting thing to think about.
3319206	3324292	A	0.7593690156936646	Maybe you could also well, maybe one way to solve that is also kind of stuff like soft edges and things like that.
3324346	3328920	A	0.736607551574707	And in some way if you have attention coefficients, it's a bit like that.
3329070	3336392	A	0.7761345505714417	If an edge has a weight of 0.1 or something, it's almost like not being there but it's still kind of there.
3336446	3341720	A	0.8636873960494995	So it's a bit of a soft graph architecture.
3342940	3348604	A	0.5231500267982483	I guess at the edge level you can implement this softness but I think it's a bit harder at kind of the node level, right?
3348642	3353410	A	0.7517110109329224	Like how do you kind of model a node that's kind of there and not there?
3353860	3357916	A	0.7190188765525818	Yeah, there's just some random thoughts that's.
3357948	3371924	B	0.8557403683662415	Very interesting about the fuzzy object identification and kind of similarities and differences between nodes and edges even though in some ways they have some similarities too or interoperabilities too.
3372122	3397212	B	0.8423519134521484	One other point of contact was like an underlying hidden space that we understand topologically that projects a vector space from different places so that could be a vector of thermometer readings and we want to have a smooth path within the homeostatic range defined up to a boundary point.
3397346	3414828	B	0.8461201786994934	Not saying that that's the structure of the world but a structure of a very heuristic and simple model might be to aim for continuity and have a defined hidden estate space that has continuity underneath and is able to emit vectors.
3415004	3433780	B	0.749566912651062	That kind of brings some of these classifier type discussions that you brought up and the kind of fundamental impossibility of geometric classification because you are going to end up with gray zones whereas even if it takes a bitwise description, you can separate the network.
3433940	3446696	B	0.6386306881904602	So that gives an actual completeness measure and that allows measures like I mean amount of computational resources or in a more statistically principled way like the Bayesian Information criterion.
3446808	3448668	B	0.8744263648986816	So how many nodes should we have?
3448834	3453360	B	0.8649625778198242	We should be on some trade off front in some modeling space.
3453430	3454336	B	0.4937661588191986	I don't know what to tell you.
3454358	3456028	B	0.6944064497947693	It's a map, not a territory.
3456204	3458284	B	0.6241801977157593	And that's more justifiable.
3458332	3467590	B	0.8391366004943848	And so even lifelike organisms might want to self evidence staying emitting from a living state.
3468040	3475440	B	0.6097411513328552	And so that provides a really simple graphical architecture to cybernetic systems.
3475600	3487316	B	0.9017844200134277	And then active Inference explores a lot of different more specific motifs within that broader blanket persistence picture and the path of least action.
3487428	3502830	B	0.6654906868934631	So that's what enables the physics in that space and why these methods, which as far as I understand are often used in quantum mechanics, are being able to come together with active inference this way.
3503520	3521012	A	0.6786724328994751	Yeah, something that comes to mind when you mention this, I think there's also like a recent avenue of research in this area where people and it's again kind of generated by the fact that you don't know the graph beforehand many times.
3521066	3526564	A	0.8167492747306824	And I think kind of the old school approach was, well, you construct it based on some rules, right?
3526602	3535770	A	0.8175314664840698	Like you're going to say, I don't know, some things are similar, I'm going to put an edge between them and you define similar in whatever way you like and so on.
3536220	3547368	A	0.8616032600402832	And there was this kind of recent trend where what you try to do is kind of latent graph inference, or some people call it manifold learning, if you think of the graph as some sort of manifold.
3547384	3559168	A	0.8928171396255493	But this kind of very informally speaking and essentially what you would do is like you would map whatever you try to learn the raw observations into some latent space.
3559254	3561836	A	0.8262502551078796	And that's where you actually construct the graph.
3561868	3567140	A	0.7979763150215149	You construct the graph in the latent space rather than kind of in the raw space.
3567210	3572324	A	0.828091561794281	So that might be kind of a way to deal with fuzziness as well.
3572362	3572900	A	0.7360090017318726	Right?
3573050	3586410	A	0.7044960856437683	Because then I guess you might lose some of these kind of very concrete one to one mappings because you might learn some node in the latent space that maybe corresponds to three or four concepts kind of mixed together.
3586940	3597816	A	0.8400673270225525	There's all these kind of nice experiments with neurons in deep networks, kind of visualized, and they learn maybe kind of a mixture of concepts.
3598008	3605264	A	0.8939626812934875	If you see what actually activates that neuron is actually maybe a few classes or different kinds of things.
3605302	3607010	A	0.7654024362564087	It's not necessarily a single thing.
3608260	3617216	A	0.8618622422218323	So it could be something very similar here where you have some very entangled representations that are kind of distilled in this latent graph.
3617328	3629300	A	0.7273243069648743	And then in a way, at least in concept space, even if in the latent space, that's still kind of a very clear combinatorial structure with respect to kind of your raw observations.
3631640	3642628	A	0.8770560622215271	That structure can still kind of encode the fuzziness of the world to some degree because you have this kind of mixture of concepts that got distilled in the same node or things like that.
3642654	3648664	A	0.8894340395927429	Or maybe some concepts could be represented by multiple nodes depending on what way you see these concepts.
3648712	3652496	A	0.8107779622077942	There might be all sorts of variations or concept or points of view and so on.
3652518	3662924	A	0.8697436451911926	So I think kind of latent graph inference could be quite an interesting way maybe to address some of these issues we were discussing.
3662972	3668804	A	0.4911387264728546	Although I think it kind of died off a bit in the recent year, at least as far as I've seen.
3668842	3673540	A	0.8409414291381836	There were a few slightly fewer papers on the topic.
3675800	3687480	B	0.8420453071594238	Well, certainly the agent's proposed latent structure of the world, the causal structure of the world is just mapped on the territory and so it enables maybe some of those core screenings.
3687980	3693660	B	0.9249735474586487	Could you go to the slide where there was a mapping between a smooth sphere and then a regular geometric shape?
3695680	3700220	A	0.7059627771377563	Yeah, let's see in this one.
3700370	3705120	B	0.8399679660797119	Yeah, just wanted to make one point and see if you had any comments.
3705940	3738792	B	0.8601925373077393	At the heart of some of the relationships that you're describing and where you pulled back to in terms of generalization helps us understand this relationship between the sphere and the geometry and the implications for data processing and all of the computational science areas is if you are preserving or learning or analyzing geometry but not topology or the other way around, you might get these different data set.
3738846	3739700	B	0.6818482875823975	Aberrations.
3739780	3744956	B	0.7208805084228516	Like you might have the topology of the coffee cup, but it looks like something totally different.
3745138	3751740	B	0.837830126285553	And so what we would really want to do would be understand the relationship between geometry and topology.
3752240	3775344	B	0.7854588627815247	Because if we could understand it in principle, like you have it on the left side and then in practice with the data scheme on the right side or insert your own left and right side there, then we'd be able to do data analysis in a way that respected preserved both the topology and the geometry.
3775472	3798350	B	0.6535300016403198	So it's like two compatible perspectives that have their different strengths and weaknesses and heuristics and so understanding that relationship between geometry and topology and the implicit spaces that geometry requires and so on, that has tremendous use.
3798800	3821792	B	0.6680713891983032	And it just in closing, reminds me of Buckminster Fuller's Synergetics, which uses a close packing architecture and a tetrahedron centric model of coordinates to find more continuity between surface area and volume and between the smooth surfaces and the great circles on them and like the points of connectivity on shapes.
3821936	3828372	B	0.7293071746826172	So I think it's an incredibly deep area and really has fundamental impact in active inference.
3828516	3840040	B	0.5553369522094727	Helps us think about our models in this way, kind of like the inflated balloon with the fuzziness and the architecture and the finiteness.
3840960	3843144	B	0.7915645241737366	It really brings a lot to active inference.
3843192	3849150	B	0.9667250514030457	And so I appreciate you sharing the work with us today and continuing to work in this way.
3850000	3851210	A	0.915550708770752	Thanks a lot.
3852260	3853840	B	0.7845550179481506	Any last thoughts?
3854420	3860416	A	0.8061925768852234	Yeah, what you mentioned, I think it's been all over my thesis this.
3860438	3864140	A	0.7269676923751831	Kind of tension between topology and geometry.
3864220	3873364	A	0.6071057915687561	And maybe what I want to emphasize is that I'm not saying kind of the previous perspective of looking maybe more geometrically at things was wrong in any way.
3873482	3878108	A	0.7965143322944641	And on the contrary, actually, there's lots of interesting places where these things intersect.
3878144	3886164	A	0.8591047525405884	Even in kind of this chief paper I briefly went through, like, if you actually read the paper, there's a lot of beautiful intersections.
3886212	3895688	A	0.6844940185546875	Actually, my main collaborator, Francesco, he's a differential geometry, so he actually had lots of kind of inputs from that side.
3895774	3906400	A	0.7985318899154663	And indeed, I think we should try to use all these kind of layers of structure are in the best way possible for all our methods.
3907380	3907888	B	0.9184247851371765	Awesome.
3907974	3909392	B	0.8092430830001831	All right, thank you.
3909526	3910336	B	0.6996942758560181	Till next time.
3910358	3910784	A	0.915550708770752	Thanks a lot.
3910822	3911970	A	0.9428794384002686	Thanks for having me.
3912500	3912780	A	0.5137446522712708	Bye.
