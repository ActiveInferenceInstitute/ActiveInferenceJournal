SPEAKER_00:
All right.

Welcome, everybody, and thanks for joining.

Today, it is June 9th, 2021, and we're here in ACT-INF Lab Math Stream number 3.1 with Dobson, Safran, Knight, Prentner, and Friedman.

Today is going to be a fun discussion.

We hope that you're also able to, if you're watching live, ask us some questions because certainly we don't have much planned and would appreciate from that feedback with you.

We're just going to jump right into it and by way of introduction and welcome, ask what is Active Inference and how we got here.

We're going to go around and give just some initial conditions, initial thoughts on these questions.

wherever we're coming from as we sort of converge on this discussion and then we'll just be writing down thoughts and ready to jump in and continue the discussion so who would like to give a first pass on either or both of these questions i could try thank you adam go for it um


SPEAKER_03:
So for me, active inference is a normative process theory for how a principle of what it takes to exist, the free energy principle, or what it takes to persist, can be realized.

And it's what are the things you have to do if you're going to, however you want to say it, outsource your entropy or avoid getting all mixed up in the meat grinder of existence or whatever.

What kind of intelligence, what kind of modeling will you need to exhibit to do this?

And so in a way, it's for me the answer to the question of what is mind?

And potentially with certain versions of it, what is life?

And with other versions of it, what is consciousness?

And maybe even what is free will?

nice big questions and how did you get here i have no idea um i think it all started with an existential crisis when i was young that went on for a very long time um but then i would say i found my way to uh the architect aka carl friston um when i was

Basically, through Jeff Hawkins' book on intelligence, I learned about predictive coding, and that was my on-ramp to Carl's work and the rest is history.


SPEAKER_00:
Awesome.

So we heard some big general ideas.

What is mind?

What is life?

Who else would like to go, or I'll give a thought?

Blue, want to go for it?


SPEAKER_02:
Sure.

I came to Active Inference through my interest in scaling.

So how do you scale processes from very small, like subatomic, to cellular, to organismal, to societal?

So that was kind of how I got hooked into the Active Inference framework.

And for me, it's a framework that pretty...

it gives a pretty good representation of how we tend to represent and think about the world.

We predict, we have feedback from, like we predict something will happen, you know, if I turn the thermometer on, if I turn the temperature up, that the heat will go on.

So we predict that, we take the action.

And if the heat doesn't go on, we have a surprise.

And so, you know, then we go, well, what made our model go wrong, right?

Like maybe my heater's broken.

So it's kind of minimizing the surprise and uncertainty in our interactions in the world.


SPEAKER_00:
Awesome.

Would either of the two of you like to go or?


SPEAKER_01:
Sure, Shanna, do you want or should I?


SPEAKER_05:
Go ahead.

I'll go after you.

Go ahead.


SPEAKER_01:
okay well so i'm i'm perhaps in some sense the outsider because i'm not um i'm not doing research with active inference but i'm a philosopher my background is in philosophy and i think active inference is a very interesting thing first of course first of course i like this big general questions that adam raised at the beginning what is mind what is life what is consciousness and it's very close to

what I normally think about.

I'm a philosopher, I'm a bit skeptical whether one could actually answer this big question in a very... But that's a different story.

I think active inference is very interesting from a philosophical, historical perspective as well, because it kind of...

embodies a tension which ran through philosophy or through the history of thinking, which more or less started with the very famous philosopher Immanuel Kant, the distinction between an object, a world, he called it a world in itself, like an outside world, and the way how we represent it.

And now we can go two ways from here.

One could stay in this Kantian paradigm where the question is, how do we actually perceive or are able to make representations of the outside world?

Or one could go into the different direction, say, oh, it's really about acting in this world.

And active inference is a kind of interesting twist mix between these two ideas.

And my experience with it that some thinkers in the active inference camp, they tend to align closer with Kant or the new Kantian tradition.

And the other line of thinkers, they tend to align more closely to this perception-action way of thinking.

So I'm very interested in this tension, maybe it could be.

to think about how it could be resolved.

And so I'm curious.

And how did I get there?

Well, I worked a lot with Shana here, and Shana basically got me in.

So yeah, thanks to Shana.


SPEAKER_00:
Thank you, Robert.

Shana, go for it.


SPEAKER_05:
Yes.

So, right.

What is active inference?

So I too, I'm probably more outside than Robert is.

I'm the math person here.

So I'm just sort of off in the woods trying to think about, like Lou said, how to scale all of these theories.

So you have this formalism of an activism and, you know, inference based on sort of discriminating between system and its environment.

And I think that's predicated upon a

kind of a very serious boundary argument.

So I'm really interested in boundaries.

I'm interested in also how boundaries are predicated upon a possible holography theorem.

So when we say agent is interacting with its environment, how does that actually work in a categorical way?

So we have a Bayesianism probability way, but I'm sort of interested in how do you do that categorically?

And can you mathematize that even more and sort of infinity categorify that?

Perhaps the definition between inside and outside is, I think,

a very, very beautiful one.

And so how can we actually say that what is represented in the outside is the inside inferred?

What are the mathematics of that?

Also, this seems to be happening in a certain version of a simultaneousness.

So I'm really interested in the mathematics of simultaneity and also this sort of synchronic and diachronic emergence sort of phenomena.

So I think that what's happening also, I think the active inference formalism

is dynamical enough to allow for these sort of mathematical ideas to come in.

And if you can mathematize that, then perhaps you can answer these questions that Adam's asking.

What is consciousness?

What is mind?

And those are the heavyweights.

And I think that's why you have the heavyweights at this panel.

As opposed like for the question, how did you get here?

I'm trying to figure that out myself.

So I didn't know if that meant like existentially or whatever.

Somehow I just kind of came online.

If you want to know how I got like in this interface, I don't know.

And then, but my very good colleague Chris Fields gave a talk and I sort of attended and he was asked a math question and I sort of answered it and then the community welcomed me.

So that's how I got here, but I don't know how I got here.


SPEAKER_00:
Awesome.

Thank you.

And excuse any strange noises in my background.

What is active inference?

I really liked just a bunch of pieces that people brought up.

Robert, you brought up that there's this action element, this pragmatic turn, looking at action and perception in the world.

And then right there, the second word is inference.

And that's that transcendental or like a Kantian type approach.

So when I look at active inference, I see action and inference sounds a little

uh first level but those are the two pieces that are coming together which is traditions of action in the world and traditions of inference in the world now as compared with reinforcement learning or other approaches to thinking about agency and action in the world

or other economic metaphors, active inference diverges in a few key ways.

It focuses on the reduction of uncertainty rather than the maximization of, for example, reward or value alone.

Uncertainty reduction is a key component of active inference and also what Adam brought up, which is the resistance to dissipation and the characteristics of living systems to be actively resisting by making increasingly adequate generative models of their niche

resisting dissipation.

And then also I see active inference as a bridge to disciplines and communities such as systems engineering or ecological psychology or embodiment.

And so all these different areas that relate in one way to action and inference or to philosophy, there's so many roads that come together at active inference.

And that's a little bit about how I think I got here as well.

I remember hearing about it for the first time from Jelle Brunnenburg, who came on an earlier stream.

And it was a picture of, I think, a Dutch person holding a cup of coffee and listening to music and biking with one hand and asking about this question of skill and of action in the world and just raising this provocative notion that current models that we had for action planning weren't...

doing their job.

They weren't able to explain that person on a bicycle.

So since then, I've just been learning by doing.

So cool for this first question, and I'm sure we can return back to it and ask more questions about Active Inference as we head on.

And of course, anybody who's watching live is more than welcome to ask us a question, which I'll relay on.

Let's go to some of our questions that we've thought about before.

And this slide asks,

what is the role of space in active inference or in other areas that people are familiar with working and what is the role of time and then we have that non-locality for both space and time because maybe we're curious about what non-locality looks like in space and time so anyone's welcome to raise their hand or give a first thought


SPEAKER_05:
Danielle, can I give a first thought?

Absolutely.

Yeah, yeah.

So in the probabilistic setting and the statistical mechanics, that's the mathematics that fuels active inference, right?

And before you have me trying to come in and categorify everything, just for the active inference kind of experts in the crowd, I was going to ask you, the role of space

like, what is it?

So are you, you know, modeling all of this on some kind of Euclidean sort of manifold?

Or are we looking at, you know, something a little more interesting?

So where I come from, I'm sort of, if you really believe there's only now, then what does that actually translate to?

So if we're going to take these sort of powerful philosophies of like,

You know, if there really is no future, or the future is some kind of potential that you only actualize now, can you translate that for me into what your space looks like?

So quantum mechanics is working over sort of non-Archimedean space, where you have a very severe cutoff.

You don't have these infinitesimals and things.

So what does this space actually look like?

For someone like me who really believes that this interface is discretized, that every other nanosecond it does not exist, whatever that means.

So this whole thing is a grand interpolation.

I just wanted to know what you all thought about in this inference model, if space is actually jagged and singular, or if you're assuming that it's some sort of interpolated continuity.


SPEAKER_00:
Nice question.

Adam, you have a thought there?


SPEAKER_03:
A few.

So most of my thinking has been in focusing on goal-oriented behavior, consciousness, agency, pursuing goals.

And this is in general, that's what I'm gunning for.

And that's like all questions end up getting filtered through that for me.

So for instance, I could see space and time in different senses showing up in different ways.

So in a theory of consciousness I recently proposed, I was suggesting that we can think of it in terms of world modeling, but for this world modeling to actually be capable of bringing forth the world or being experienceable,

it has to have certain coherence properties.

And so I was thinking of consynthetic a priori categories as not just preconditions for judgment, space, time, cause, maybe some sort of unifying minimal selfhood.

But these are also preconditions for any kind of sense-making whatsoever and for the appearance of a world.

People could object to that.

But then the question is, well, what exactly do you mean by space, time, and cause and self?

How much and what kinds and which circumstances?

And so for me, space, I tend to think of it more in terms of locality, where there's like relative degrees of proximity among things.

And then there's, for time, it would be things changing within space

in a kind of proportional sense.

There's other senses of time.

You could have some sort of clock-like processes that are either in parallel and coming to agreement, or centralized, and another sense of certain bottlenecks that force a kind of temporal ordering.

Or you could just think about things changing to things at different rates.

There's, I think, problematic circularity in what I said.

But in terms of the senses of space,

Well, I'll stop there, but I could keep going later.


SPEAKER_00:
Cool.

Just a few, I guess, basic thoughts on space.

I thought about embodied agents and how an agent has a location in a spatial model.

So like the active inference paper that we had where different ants were at a different location in space.

Now, there's a difference between the space that the actual physical thing is in and then the model, which kind of relates to this Kantian distinction, perhaps.

But even when we have a disembodied agent, there's a state space.

So, I don't know.

What is the relationship between a mathematical state space and...

whatever you were mentioning there previously.

And then as for time, it just made me think about the distinction between Kronos and Kyros, where Kronos being like sort of a metric or a measured time, like a model of time or something that's regularized.

And then Kyros being timeliness and action happens kind of in both.

Action takes clock time to carry out, but also action has its own timescale and actions have their own sort of story arc.

Yeah, Blue, go for it.

And then anyone else who raised their hand.


SPEAKER_02:
So space is something that I've thought about a lot relative to like my previous work.

And I think about it a lot also in terms of boundaries, right?

So where does one thing stop and another thing start?

And even something so simple as how do I define my fingernail?

Where's the boundary between your fingernail and your cuticle?

And anybody who's really dug in there, there's some parts of your cuticle that you're like, am I supposed to cut this or what?

So there's not a clear distinction or line that can be drawn around what is my fingernail.

Right.

And so trying to find this this distinct boundary also in terms of inclusion in a group.

And I listened to your last math stream, Shanna and Daniel.

And I was I was really kind of thinking about this and I've been thinking about cancer a lot in terms of inclusion in a group as you guys were talking about that.

And it's like, I also think about it as like a school shooter, like a cancer cell goes rogue.

Like they're somehow not included in the group.

They're not part of the collective anymore.

And then they take on their own like self-interested agenda.

And I also think about that, like in terms of a school shooter or someone that like commits mass violence,

And, you know, like when you have this kind of, it's someone that's not included in a group.

It's someone that even is not included in like a rebel group, like the Al-Qaeda or something.

They're rejected from that group also.

So when they can't find inclusion, they become like this rogue agent.

And so kind of I think about space as in where do you draw that line?

I have a hard time...

finding that space and it's something I like to push on.

Then time, I don't really work with time too much actually per se other than I have to deal with this linear time that we're trapped in.

But I do think about expansion and compression of time relative to age.

So like as a young person, like time seems to be so expanded, like five minutes is forever.

And as you get older in life, like a year just flies by, right?

So like as time, it's expanded as a young person and then compressed as you seem to age through life.

Thank you, Blue.


SPEAKER_01:
Robert, then Shana.

Yeah, thank you.

So I more have a question than something really interesting to say.

But it's a question for you, or maybe you can give me a good answer.

Because here on this slide, there's the second world, which is in parentheses, which is non-locality.

And my guess is that Shanna put it there.

And my question would be whether there is anything that remotely resembles some notion of non-locality in active inference.

To make that a bit more concrete, my impression when I read articles by people who endorse active inference or work in that area, is that they usually work against a very classical notion of space and time as a background.

So you mentioned the ants that move in physical space, and that's usually assumed to be a classical one.

Or if you, I don't know, if you think about the cells

and you apply the concepts to a cell, then you say, okay, the molecules, it's a classical thing.

So there's no notion of non-locality there, I guess, I don't know.

And my question would be whether and how an active inference could accommodate some notion of non-locality.


SPEAKER_00:
Nice question.

We can definitely wander and come back to that.

Shauna and then Adam.


SPEAKER_05:
Yeah.

Thanks.

Yeah.

So just to get to the time part, because I hadn't talked about that.

So thanks, Blue, for watching the last stream.

I'm really fascinated by time.

And I don't think my time really works linear.

It's really hard to say, like, where is yesterday?

You can do this sort of light cone sort of formulation.

And if you want a general, like, relativity, then you can say, oh, yeah, yesterday is in the light cone of whatever, you know.

So, but like, what is it and where is it?

So when I asked like about the role of time, the thing that I'm sort of, that I've proposed in that FMOF K theory diamond paper that I have about like the applications of all this stuff, of this higher category stuff, is to think that maybe time is more like a pro time.

So in math, you have this pro object, which is glued together from a bunch of like morphisms and other collections of it.

So it seems that if time is this,

thing that is also emergent.

I'm the advocate that it's not fixed, right?

I'm also an advocate that I don't really know how you measure time without constructing it.

So I'm not sure that we're actually constructing a notion of now, or does it actually exist?

So in active inference, since you're constructing, you know, every, every second of whatever, every unit of time, you know, how, how can you actually measure the inference without constructing a parallel notion of time, like in the same thing?

So when Adam's talking about coherence, and if you need a coherence property for temporality to actually give you a singular now or something, what does that actually look like?

So Robert's right.

That was me that put the nonlocality in there.

Because we have a rough idea of the nonlocality of space.

You can have a two-point perspective of space, something like,

you know, in my state where I'm not like an entangled pair of photons, I can clearly say, oh, Silver Lake is over there and I'm in my condo on the other side.

There's a sort of separated distance.

But according to a pair of entangled photons, there is no separated distance.

And so you have a two-point perspective of space.

So in the mastering that I did last time with Daniel, we were trying to figure out, is there actually a two-point perspective of time?

Can you actually be a macro system and say that this is purely non-local?

So I really like Robert's question saying, where is the non-locality?

I'm trying to build that into the very mathematics of the thing, of trying to categorify this awesome formalism.

But yeah, so just time, I think it's very strange.

And I think it's something that we should all probably try to tackle instead of assuming that it's always there.

It's just some background phenomena.

But if time is emergent and space is emergent also, then it sounds like active inference is the right dynamical formalism that could actually kind of help that too.

Because maybe the agent is also making time at the, quote, same time that it's making a world.


SPEAKER_00:
Thanks.

Yeah.

We've seen active inference models where at each time step of the model, the agent does like a rollout through the future.

That's called sophisticated active inference.

And then also it's a great point about the multiple reference points.

We have two eyes at different spatial locations and that's how we infer depth, which isn't just a feature of the world because it's something that we have to infer and therefore it's susceptible to optical illusions.

And then the question with time, do we have a monocle?

We only have one reference point on time, because then we're going to be just totally unable to calculate depth.

Or if we can calculate or experience temporal depth, does that entail that we're having multiple reference points in time?

So Adam, and then anyone else?


SPEAKER_03:
So to try to bring a few threads together.

So some of the

So what I'm really liking about what Blue and Shannon were just saying is this sort of relational realism.

So instead of saying, like, what is time, what is space, period, well, what is it relative to what?

And then what is it, and when I say coherence, coherence relative to what?

And so let's kind of backtrack some.

in the Kantian issue of, is it that we're just interacting?

Or is it that we're modeling?

And the modeling is just a pretense that's useful for describing this sea of forces that goes beyond description.

I think we can have both.

And so what I tend to do is view interesting systems

terms of an active inference also like you have nested Markov blankets and you have nested kind of nested hierarchy of dynamics and so you could think of for instance um a set of coupling uh processes some sort of chaining together of dissipative systems that manages to stitch itself you know hold itself together through the way it's chained and this could couple with the world in a way that doesn't require necessarily there might be like an implicit representation to it

want to use the word in that way of like a correspondence between the dynamics and like what is evolving um or you could that's like but it's not necessarily it may not be inference in the sense of like the model like whether you want to say that this modeling process is is real or a way of viewing things that's it's a matter of perspective but then as you add layers of complexity then you can get things like um

interloop processes that could refer to this set of kind of action relations and bringing things together.

And then you could even maybe have on top of those or within those another process which points to those.

So graphs pointing at graphs pointing at graphs.

And so Shanna's category of theoretical perspective would be very relevant here.

And so at some levels you might talk of things like

representations in a cartesian sense like in good old-fashioned cognitive science we may have those and we have an activist intelligent coupling where it's just implicit representation and maybe we shouldn't even use that word or maybe we should use that word i'm not going to say but i think we can have it all and so the um

way that you would think like space and time um from these nested systems i think there could be in a way a kind of non-locality and that they would be evolving independently they're evolving on their own time scale so you have like a nested deep hierarchy of dynamics there's a sense which they're all kind of brought together by virtue of like sharing this markov blanket

that they ultimately agree, so I guess, I don't know if that would be, but there's potentially ways in which they can diverge also, and so it seems like you could have maybe periods of non-locality and locality, and actually this kind of going in and out, I'm probably butchering and abusing the terminology, I apologize, but this going in and out might even be like necessary, like necessary for a kind of dual phase evolution for the systems to couple, for them to like trade off their free energy, for them to

do what they do as this sort of like iterative inferring their own existence and doing what they need to do process.

But so within this view, it seems like time can show up in multiple ways.

There's like the time of just the world as this evolving graph, as a generative process in that way, in terms of if there's a kind of

If we narrow it in to a particular system, there's like some things were before and some things were after in terms of this sea of causal influences.

But then you might get another kind of time of this psychological time of spatializing time and then navigating through spatialized time and same things for space.

And then it comes in again.

One more thing I guess I would say is the issue of space and time

I think it's going to be two things about that.

So one idea I'm playing with is actually that our consciousness is actually the spatial kind of it, in terms of visual spatial at least, it's actually always 2D.

And that to the extent that we have something like a 3D awareness of space, it's coherent state transitions of these 2D projections.

And there might be a relevance to holography there.

That's one thing to

But then one more thing would be, and then you have maybe like a 3D type space in terms of body space.

So you'd have like a visual spatial Cartesian space, but then like space relative to the body, maybe like a kind of quasi polar coordinate space.

And between the two of them, you can get a kind of like 3D space coming out of this or 4D space because there's dynamics.

But the one more thing about subsuming space and time to action relative to what,

is I think this will be crucial for boundaries in terms of what counts as a living system or not, and what would count as a conscious system or not of what kinds.

What are the physical and computational substrates of consciousness?

What kind of closure is achieved on what scales?

That issue, I think... So what I would like to have happen is either some sort of...

definitive handling of this, some sort of category theoretic definitive handling that would basically nail it.

Hard problem, solved.

Schrodinger's question, answered.

Unambiguous.

Or I want a proof that this is impossible.

And then I can rest.


SPEAKER_00:
Thanks, Adam.

Maybe Robert was alluding to this with the skepticism.

But for me, whether something is answered or not, it's a psychological story that we're telling.

And you could be convinced about something that whether it's proven to be impossible or proven to be ruled in, that would be a story.

And then also nice about the projective geometry.

We talked about the projective geometry paper some time ago, about how we can look at something like the corner of a room, and even though the angles are going in weird directions, we kind of infer it to be rectilinear.

So that's pretty cool.

Any thoughts here?


SPEAKER_03:
A quick thing on the projective geometry, actually.

I really love David Rudroff's work on that, because it's a discussion of consciousness that puts

a person or puts an observer and subjectivity and interest like right at the center of it.

One thing I'm wondering about is what is like the realization of this sort of projective geometric perspective engine that he's thinking we have for spatial awareness.

It seems like there could be

like a sense that this is something the brain can do.

And there's some proposals for something like this.

Like Hinton has capsule networks.

Numenta has their 1,000 brains.

There is a kind of reference frame dependent modeling happening in a distributed way.

And that's part of the architecture.

They're just like somehow through it, it works as this graphics engine.

I actually think it might be a more

an active type thing where actually the reason you get this projective geometric perspective capacity is because of this coupling between body space and visual space linked by different kinds of affordance relations.

And that this is actually part of what's letting you do these state transitions and do this kind of projective geometric modeling rather than it being baked in in a distributed way like some sort of graphics engine.

But this is another way in which, for instance, embodiment, and interest, and value, other things get subsumed to that.


SPEAKER_00:
Thanks, and anyone can raise their hand.

Just one thought on that is action requires time.

Action is almost defined as a sequence, and then we have the policy variables, the pi, that's our Active Lab pi, because policy is at the level above a certain active state.

but action and policies, they do take time.

So there's something time-like built into our models because what we're talking about and the inferring the state transitions, just like you described, all those are temporal.

And then the non-locality, it's kind of like when...

and drawing on Friston's older work with dynamic causal modeling and statistical parametric mapping, you have an image of the brain that's changing through time.

And then you can make one type of connected graph with pieces of the brain that are anatomically connected.

And so when people think about space, usually that's what they're thinking about, things that are touching.

but then also you could have effective or functional connectivity so you could have regions that are local in cause but that local link in the causal network could be due to some upstream factor that's influencing them both so causal proximity or functional proximity may or may not be the same as some things that's touching so

Not sure where that puts us, but cool stuff.


SPEAKER_05:
Daniel, can you say a little bit more with regards to what you just laid out with action requiring time and the minimization of surprise?

So is there something in the active inference formalism

When we say minimization of surprise, is there an agent that is creating scenarios like dinosaur?

There's no dinosaur in Silver Lake, but there can be a dinosaur.

I don't not want dinosaurs, so I'm going to act in such a way as to preclude the very possibility of dinosaur, right?

So when we say minimization, where is that coming from?

So again, is there a profound creativity

that is the basis of this system that is launching these probabilities, right?

Because Bayesian probabilities, it doesn't, like, it seems kind of dull, right?

It never says that there's this highly creative being that is imagining these scenarios that it wants to preclude.

So can you all tell me, like, where is that coming from?

Or has the agent seen a dinosaur in, you know, in L.A.

walking down the street, and they go, I don't want to see that again, therefore preclude, therefore action, like the action of minimizing surprise?

requires time, but it's an imaginary time.

It's sort of like, I don't want that to happen again, therefore I'm going to act in such a way as to preclude the very existence of dinosaur.

Does any of that make sense?


SPEAKER_00:
Well, as for dinosaurs, we know that they're in the land before time.

So that is, you know...


SPEAKER_05:
Well, it's something called scary, minimizing surprise, you know?


SPEAKER_00:
Yes.

As for the minimizing the expected free energy or minimizing the surprise, one of the sort of tricks of active inference is to condition that upon a policy.

If you look at the topology of the graphical model, policies...

are getting plugged into the state transitions between hidden states.

And then what's being minimized is the surprise of the sensory outcomes that are emitted by the hidden states.

So at the first pass without getting into this like,

meta Bayesian creative energy, the agent has a set of policies that it can carry out.

Those are the affordances.

And then conditioning on each of these policy options, if they're discrete, like I could turn left or turn right, and then I'm going to do a conditional expectation on turning left as my policy or a conditional expectation on turning right on my policy, which one of those is going to, in my prediction of how that policy changes the state transition matrix,

what is going to result in less surprising sensory outcomes that is for a sort of fixed set of policy options that can be conditioned on but it's a great question about how do we go from the known into the unknown how does the agent learn a new affordance or maybe even generate a new affordance internally so there's probably a lot to be said on that but one way that active inference

speaks to it is that when we focus on action hand in hand with inference, we can think like, how could the agent ever navigate a new kind of physical obstacle?

Like there's some kind of a wall that you've never climbed before.

But what has to be inferred isn't like what's on the other side of the wall or to the nth degree the details of the wall.

It's enough to have a model of bodily action and a preference for being higher up and potentially the affordances that the agent does control, it does know about those things.

like the movement of the joints that will help it deal with the unknown because it's not just approaching uncertainty as like something that has to be eradicated by determining exactly what's out there in the world uncertainty is something that's actively negotiated with through usage of the affordances that the agent already has


SPEAKER_05:
Right.

And when you say that, are the affordances constructed?

Are they conditions of the system?

Are they properties of the system?

Like, what is the space of affordances?

And is there, like, a topology on the affordances?

Because I'm still, like, you know, if we categorify any of this, there's a, you know, people can choose spaces or anything like this, like, you know, or in the reflective subcategory, which I always talk about, these objects have reflections and

I'm still not thoroughly convinced that there is no duality between a system and its environment, right?

So if they're working together, perhaps these are like, you know, dually in a sort of mathematical sense.

So if that's the case, then I just want to know, are affordances like a property of the system constructed or conditions?

Like, do they change radically?

Is it dynamical?


SPEAKER_00:
nice questions the instrumentalist take so active inference is a statistical model that we made and it doesn't make metaphysical claims about what systems really can do it's a modeling approach in that case affordances are whatever the investigator puts into the model as affordances right then the question about what the system's affordances truly are that's a great question it comes back to how do systems

apparently negotiate completely new affordances.

Where was flying a plane?

Where does that come into play?

Well, is that part of our extended niche, part of our constructed niche?

And so we can think about that in terms of just the same eyesight that we had before and the same finger movements that we had access to before, but now it's being deployed in a different niche.

So the extended cognitive outcome is just radically different.

So in the case of tooling and language as a tool and usage of instruments,

potentially one could argue that it's still the bodily affordances that are being used, but higher order contingencies are being learned by the system to be able to play piano or fly a plane.

So the affordance of turning the plane left can be still seen as moving your hand to the left on a joystick, conditioned on an agent who understands that their preference is to move that way and now has this sort of mapping between what they do with their hand on the joystick and where the plane goes.

but what kinds of new bodily affordances, you know, can we have?

That's right.


SPEAKER_05:
And they shape and they take different forms.

That's what's cool.


SPEAKER_00:
Blue.

And then anyone else with a raised hand.


SPEAKER_02:
So I was thinking about affordances in relation to time and also like in relation to the last mass stream, when you guys were talking about how, like when does memory start to form, right?

And so like, as you're looking at your reflections in the diamond, like there's, you're looking at your reflections and then there comes a space maybe where you can reach your reflection.

I don't remember if that was exactly how it was worded, but that's like when maybe memory starts to crystallize, something like that.

Maybe I butchered it.

Do you want to step in and correct me?

No?

Okay.

Sorry.

So then, you know, I was thinking about like when you have young kids and they perceive time, right?

I talked about expansion and compression about time a little bit earlier.

So when a kid perceives time, a small child, everything is like yesterday or tomorrow, right?

Like there's no like concept of next week.

Like they don't even know what a week is, right?

So like you have these new affordances like that come with learning, right?

Otherwise it's just before or next, right?


SPEAKER_00:
right like it's interesting and so when do these affordances like does that correspond to maybe the ability to to reach your own reflection in the diamond and i flipped it here to what are thoughts so maybe if anyone has a thought on that what are thoughts or yep adam and then anyone else but actually before i go on if shanna wants to


SPEAKER_03:
speak to a blue gist set, I'd actually really like to hear that.

Go for it.

But then I have thoughts.


SPEAKER_05:
Yeah, yeah.

Okay, feel free.

Well, I think it's sort of integrated.

Yeah, you know, the diamonds are very difficult objects, right, that I was thinking could be

the perfect model, I shouldn't say perfect, a more perfect model of what's going on with memory, right?

So you have these, you know, cases that I always talk about, you know, beautiful people like Clive Waring who have a three second memory from a retrograde amnesia.

And so you have to ask someone like Clyde, like, is he experiencing, you know, a complete temporal non-locality every two seconds?

The child, right?

Child mind, which I have a lot of, right?

Like for a child, what are the conditions for object persistence, right?

In their own very state, you know, like with the diamond and things like that, I think you can model what it means to have Shanna when I'm six, right?

you know in shana when i'm 85 or something why is it the same shana and i don't think it is like at all um so when you say something like like memory and what are you actually looking at so um i'm you know again if i think there is this duality between like the system and its environment um how can you actually visualize that in this in this sort of diamond mentality and so the thing about the diamond right is that if perhaps memory is some kind of impurity

and you'll never actually get to it.

So if memory is like a mineralogical impurity, then you never actually get the impurity, you just get the reflections of the whole thing.

And so to sort of take what Blue said and just tighten it just a little bit, that might be more of what's actually going on.

But perhaps the mineralogical impurity is that maybe if you only have a now,

And that if you're not able to access all the other reflections that are on the diamond, you may not have a future, and you may not have an extended time.

But there's also something to say that has that diminished your vibrant experience.

Somebody like me who can really drop in, can drop in very Deleuzian, like I am a degree of heat.

I am a degree of white.

I am a unit of sand.

His formalism is super powerful because it's giving, becoming an action to these individualities, these hesaides, right?

That somebody else would say have no permanent unit of consciousness or something.

So I think what I'm trying to do is combine this notion of becoming that is super individualistic, like, you know, I am a spoon of coconut, like a spoonful of coconut, like that's it.

With this notion of this diamond being

and they're not just reflections right they're like pro-finite reflections so they are um totally disconnected so that's sort of the mess that i'm sort of i think is like underlying the beginnings of memory maybe it's just this kind of pure mess and as you age or whatever age is sort of involved in these pro hotel coverings and so in the covering space uh you know if you're working uh

through proprioception and things like that.

There's a lot of work in neurology saying that, you know, your brain probably processes more topologically.

If you're a child and you only have like a now and a bunch of points, you don't really have a lot of covering spaces, right?

Yeah, so I think working with diamonds, which, you know, we'll get to in a little bit.

So I think there's something definitely at play with you're staring at your memories, right?

You're walking around in your past, like all the time.

So I don't ever think you can actually get to the true memory unless you've reached like the infant state again.


SPEAKER_00:
Thanks, Adam and Robert.


SPEAKER_03:
So to revisit the affordance issue, so if I'm understanding things, there could be in a way, you could say like in any given moment, there's like a view from the outside, like what was the scope of the possibility of the actual interactions for the system

given its configuration.

But because of niche construction, that's also a moving target.

But then there could be another set of like perception of these affordances by the system where that perception itself changes the affordance structure.

And this can be of different varieties.

So like the system in a kind of dynamically self-configuration and like jostling around and doing like implicit inference just

figuring out, sussing out what the affordance structure is, and then this kind of implicit perception.

And then there could be on another level of like explicit affordance perception, and each of these influencing the other and maybe operating differently and across purposes.

With respect to, I was just paraphrasing, trying to paraphrase what I've written and add my own twist on it.

This seems like a lot of things will connect to this.

From memory, I've been thinking of getting back to consciousness and different forms of it.

What do we mean when we're accessing something?

What does it take to remember things in different ways?

And how does

our different kinds of awareness of what happened relate to our ability to remember these things.

And so you can have a kind of memory that's just a sort of like baked in, what would they say, a hysteresis, a kind of like you push on the thing and then through its dynamics or through its material properties just kind of holds the shape and you got a memory there of the indentation, like a desire path.

But in terms of this holding on to memory, like a Clive Waring type memory.

And time does seem key for contextualization.

And like Blue was saying about the way time changes with age.

It seems like that kind of time and the way we construct it, one of the things you would say, we spatialize it.

And we spatialize it relative to what?

Probably relative to us as an agent pursuing goals in the world with this

the inference of different affordance structures.

But what are the different ways, though, that you can relate to this spatialized time and to this maybe objectified you and then different ways of doing this?

What are the different kinds of self-reference involved?

That's an issue we can maybe get into later.

But one of the things I'm wondering in terms of memory, and this might relate to impurities in the crystals, is that

the ability of things to get entangled, to point to themselves in different ways.

So within this three-second window, there's maybe a sequence of frames of sense-making, but there's a broader frame of sense-making of a causal unfolding that has a certain stability over which it can hold itself together.

But part of what would let this specious presence, this inherent depth to the now, might be this kind of self-reference where

The earlier frames of experience have predictive information about what follows, but then what follows has information and points to what was in the past, predicting the future and postdicting the past as part of this process of unfolding sensemaking.

And it seems like the degree to which you could do this and the ways in which you do this, that would be the degree to which

things might be likely to stick around, that they might be likely to be made salient, to find hooks in this process where everything's competing with everything to keep going, that the ability of something to get entangled with itself in different ways would provide different degrees of sticking power.

and that this would involve things like just multi-modality, like a heterogeneous code, like maybe my direct first-person shooter point of view is pointing to a linguistic code or some sort of iconic symbolization or some sort of other interoceptive intuitive code.

But these all cross-referencing each other, that'd be one way of hooking things together.

But you could also hook things together in terms of an explicit causal sequence, where it's just this to this to this.

The ball kicked the shoe.

The boot kicked the ball.

The ball went down the ramp.

The mouse got the chew.

The whole Rube Goldberg thing, that could be part of it too, but actually more so if it's coherent and maybe agentic.

If it's related to basically, I think we're going to have to get personhood into this and the nature of it.

relative, like the causal streams that you have the most familiarity with, and that fit into most of this meaning making hierarchy that has like a visceral thing, a visceral ground, a symbolic grounding, the more of these you can come together, probably the better it'll, it'll persist.

And the more that impurity will give the sparkle.

So


SPEAKER_00:
Thanks, Adam.

Robert, and then we'll probably move to the next slide.


SPEAKER_01:
Yeah, this slide with the thoughts, I wanted to say something about the thoughts.

If you still have something else, then we... No, go for it.

Okay.

So first, of course, I would be curious how Active Influence people would kind of, what they would say, what the thought is or what it means.

And just philosophically, I think that's a very interesting question.

And there are certain kind of traditional ways how we think about thinking.

And it seems to me that active inference is challenging some of those very traditional assumptions.

But I'm not quite sure how exactly.

So the first assumption

That's the obvious way.

It's kind of obvious how active inference challenges that.

But the first assumption is that thinking is something which is like a counterpart to what's happening physically.

So in the physical world, and there's thinking, which is kind of opposed to it.

And I think in active inference, this dichotomy is kind of erased.

That's kind of obvious.

The second question is,

There was a long tradition in thinking about thinking which has to do or which says that thinking is something which is rule-based or law-like laws of thought or in a more modern saying one would say, oh, it's about information processing or probabilistic reasoning or whatever.

But that seems to me to kind of clash at least with the phenomenological way or with the phenomenology of thinking in some sense.

Thinking seems to be something direct.

unmediated and we talked about it now which is a particular example of that and I wasn't quite sure how that hangs together with the whole active inference theory basically with the mathematics of it I mean as I would naively assume you talk about inferences processes which are happening defined over some bounded system

So that seems to lend itself more to this information processing view of thinking, but that seems to be somehow opposed to the phenomenology of thinking.

And I was wondering how you kind of bring these things together.


SPEAKER_00:
great questions one thought might be that the way that we've seen things like anxiety or affective states be addressed in active inference is with a parameter reflecting that and so it's almost like there's the core active inference model

one that you know data comes into and then there's this interpretive layer and so i might say at this point that the active inference framework doesn't make strong claims as to the you know what is a packet called thought or what is the nature of thought because as a scale free framework first off there's the whole instrumentalism realism so it could be a totally defensible stance active inference says nothing about thought

Um, or maybe somebody wants to unpack it in a way where they think it does.

But at the first pass, the things that we've seen models of active inference about that people experience as thought like anxiety or excitement or something like that, those are parameters that are named in a mathematical model and they don't seem to make strong claims on the nature of thought.

Adam, what do you think about that?


SPEAKER_03:
Um,

So in terms of, I guess, the good folk and how they relate to thought, this notion of it being in a way separable from action and distinguished from this in the world, just doing and just acting, that seems like a good place to work with.

And so if we're talking about that, it seems like it would relate to different species of sophisticated inference.

where you would be doing these kinds of counterfactual rollouts of what it would be to pursue different policies or patterns of action selection.

And for me, it would be, to the extent that it's conscious, it would have to be grounded out as some sort of embodied simulation.

I want to build everything out of action perception cycles and everything out of sensory motor things that I can.

Ultimately, that's going to be the grounding.

That'll be the experience.

That's not to say that thought would only be determined by what you simulated in your rollout.

For instance, like you could have a lot of spreading semantic association of just like a kind of priming effect and then words come to mind.

That's part of it and that's not necessarily like something you're controlling in terms of pursuing a policy.

That's just happening.

Or some sort of association, again, with interoception, with just like a kind of resonance in your body that might play into and parameterize

this process, but the thinking, it seems like it would be a mode of sophisticated inference, of generating these counterfactual possibilities and using them for things like different kinds of causal reasoning, different ways of situating what you think is happening or could happen.

That's how I would relate to thought, I think.

I don't know if the, like, what do we want from thought?

Do we want more?

And so that might help.


SPEAKER_00:
Great question.

And do we want to experience the phenomenology of human thought, which is an encultured phenomena, or are we trying to talk about trees and all kinds of other things?

So everyone, awesome.

Thanks for the raised hand.

Blue, Shauna, Robert.

I think Shauna was first, so I'll defer to her.


SPEAKER_02:
Yep, go for it.


SPEAKER_05:
Oh, OK.

Awesome.

Yeah.

Just a couple of things.

Just like Daniel was saying, when we say thought, right?

So I don't think thought is like recognition of a truth and a proposition.

I'm of the mindset that I think Kierkegaard said, all thought is a self-repeating falsorities, which it's like, so I'm not of the sense that thought is logic or anything like that.

Because there's first order logic, second order logic, and it's just you can get

what is pro finite thought so i really think we need to actually when we say what our thoughts we need to say like what do we mean by thought right so robert and i have this model of like in awareness so it could be that the level of your awareness

you know, dictates the levels of time you have, and then also what these thoughts are.

So, you know, someone can say, oh, a rock has no thought, but perhaps the units of thought of the rock are just lower than our units of perception, something like that.

So I think it's very strong to say that things do not have thought, right?

So to ask like what a thought is,

It's interesting also to say what is not a thought, you know.

So, you know, I have these kind of, you know, interesting ideas, like if you can model the brain as this, you know, pro hotel sheaf in a perfectoid space, which is what this diamond is, then if you can actually model neurons as, you know, these points in the diamonds, these mathematical impurities that are actually morphisms of schemes, and you would say that, okay, thoughts are these morphisms.

But, you know, thoughts are a little more messy than just satisfying strict associativity and up to conditions.

So the math can only give you a model of the thing because perhaps it's not strictly associative.

So, I mean, we all know that you do have a sodium potassium like channel, like kind of neurotransmitter cluster network happening.

You always want it to be springtime in your head.

You would not want like a winter in your head where all the synapses and the trees die and things.

But nobody can tell you how the trees in your head sort of photosynthesize.

So I know after I gave that first talk, someone asked, well, what are actually thoughts?

So again, if these neurons are these geometric points, and I still think the brain is some sort of non-local hologram sort of thing.

Its ability to rewire is profound.

We also don't want to get injured, right, because there is a detrimental effect.

But so, like, how do you sustain this sort of, you know, temporal nonlocality inside this pro-finite condition?

Maybe Robert and I are under this with this sort of n levels of awareness.

If you're able to achieve sort of simultaneous states of awareness, then perhaps you could probably get out of the idea of thought as the truth of a proposition.

And then maybe you could try to probably figure out what that is.

Again, I'm not convinced that we're doing anything new.

like what a new thought is.

I'm not really sure what that is.

Or if you can actually, like you say scale free, right?

So scale free would be able to, for us to make this in awareness sort of phenomena.

And so I agree with Robert, I'm not sure if there's a contention there between the phenomenology of what is thought and then

the sort of perception of like what thought is again, really tricky to say, you know, well, but real thought is getting new connections, you know?

And then it's like, okay, what new connections in my same interface?

Like not really sure how that is.

So I'm glad active inference allows for like new, but I'm not sure if it's like radically new.

I'm not sure if any of us would be able to recognize something radically new, you know?

Okay.

I'll stop there.


SPEAKER_00:
Nice.

Thank you.

More is different blue.

And then Robert, then Adam.


SPEAKER_02:
so just so i was like gonna piggyback off of your point and get into that so and then i have a question so really my background is neuroscience and so when you look at like the brain the fundamental unit of a thought like has to come from the action potential right like the sodium and potassium and whatever that is happening but like not one action potential makes a thought so so but

like you were talking about how do you measure emergence?

And, you know, there's like the criticality hypothesis, right?

So like a certain number of action potentials could lead to a thought perhaps, but how do you quantify emergence without a counter object, right?

And so you kept saying this, and so I'm going to maybe ask you to clarify or push on this a little bit because a counter object, like when I think of a counter, I think about a counter in terms of computer programming for IQ.

from zero to 50, count, count, count, count.

So is it like counting the number of action potentials or the number of ants leaving pheromone traces or the number of pheromones dropped, right?

So when you think about a counter object, is that what you mean by a counter object or is there some fundamental thing that I'm missing?


SPEAKER_05:
I don't think I ever said the word counter objects.

So can you tell me where I said that?


SPEAKER_02:
Yeah.

So talking, it was when you were quantifying emergence and I took some notes.

So you have built in emergence is built into the system versus having a counter.


SPEAKER_05:
So maybe not counter objects, but you said- Oh yeah, it wasn't, yeah, it wasn't, not an index, right?

So I'm not, I'm not of the, why does I have to start at one?

You know, so I don't think real numbers exist.

So that you're, that's, it's a bunch of equivalence classes.

So just 50 of these things happened.

I don't really know what that means.

Right.

But I agree with you that how do you actually quantify emergence?

Because if you have too much hypersynchronous activity, you have a seizure and a seizure is not a thought.

Right, everyone.

So it seems to be that there is and that's what Chris Fields and I and everyone are after is like, what is this stop mechanism?

stop mechanism that you can have you need a clustering happening in the neurons right to actually have thought thought doesn't seem to come out of your elbow but if the if the nervous system is non-local like i believe it is um which is why i'm an advocate for the active inference of the you know embodied cognition if the neural system is non-local and nobody's proved that it's not um

then how do you actually say when the amount of clustering gives you, like look at all this, our synapses are bright and perfect and leaves and everything is like beautiful in here, right?

And effortlessly, how does it come, how does thought come so effortless, right, sometimes?

And then, but if you have too much firing,

then you don't get it and it's not like the you know there's a an actual rest in the action potential like um blue what's the order of neuron firing what are you smaller than nanometers at that point between firing it has to be right it's not plank scale it's not like 10 to the negative 42 but it's small right

And so with that kind of time happening, I'm just I'm perplexed.

You have so many layers of time happening, neuronal firing time, like the stem cell firing time.

You know, so when I said counter, I don't think I wasn't referring to like an actual.

Yeah, when I, yeah, well, I think I was saying counter as in most people just take time to do some kind of Geiger counter, and there's no emergence, like, at all, you know?

Hope I answered that and didn't make it worse.


SPEAKER_02:
Yeah, so I couldn't figure out if you were, like, trying to talk about, like, a counterfactual, like, the opposite of emergence, like, what's the opposite of emergence, or if you're talking about a counter, like, you know, when you sum things up.

Yeah, it would be a summation, yeah.

Got it.


SPEAKER_00:
Great.

Robert and Adam, you want to go to the next one or do you want to continue on the thought?

Up to you.


SPEAKER_01:
Well, I just had a very quick clarification of my question.

Actually, Adam can reply immediately after.

That's good.

Because Adam said something like, what do we want a theory of thought to be or what do we want it for?

Which kind of thought are we talking?

When I was asking my question about the nature of thought, I was...

It's mainly thinking about conscious thought.

I mean, there's this tradition that is, which says something like, oh, the mind is whatever the brain does.

And then you talk about, I don't know, potentials about firing, about calcium.

And I don't know what.

And if you then say, okay, well, that's a very abstract thing, and you call that thought, I think that's fine on one hand, but it doesn't really give you a good answer to what you mean with conscious thought.

And the standard way how psychologists normally answer that question is to say, okay, well, there is this unconscious processing happening, and then something magically happens, and that turns into conscious thought.

And I wasn't quite clear whether predictive processing or active inference or whatever framework we want to take really answers that question or whether it says, oh, it's actually not a good question.

It kind of dissolves this question.

And well, that's a bit more specific about my question.


SPEAKER_00:
JOHN MUELLER, Adam, go for it.


SPEAKER_03:
ADAM POWELL, To try to tie a few things together,

So, yeah, so what we want from thought and what our sensibilities might be, what boundaries we establish for where we find it and don't, that'll be relative to what do we want.

But to try to build up, so I think there is a sense in which you could say a rock is a mind or is thought, even though it's of an extremely dumb variety.

It's action, because we can point to it,

It's a kind of density.

And you can think of it as just going to probably, unlike a crystal, which can grow, it can do one thing, which is steadily degrade over time on some kind of entropic gradient.

But to the extent it doesn't, that's the intelligence it's got.

But then we get to systems that can actually, through sophisticated dynamics, start to do things like suss out different things that could happen and do a more flexible policy selection.

And they might be potentially

In order to do this, they might have to be critically organized.

And that's the only thing that could allow for generalized evolution or generalized Bayesian model selection, that you actually have to be poised at this inter-regime in order to have the right properties, in order to have both the variation where you can suss out the possibilities, but also the stability

you're not pouring over into chaos or disorder, that you can actually build structure upon structure.

So it seems like that's going to be critical.

In terms of, like, if we're talking about something like, and so like, sort of something like, you know, a life form, maybe that's like, some people say, like, that's kind of like, like, this sort of more sophisticated mentality

that with optionality, maybe that's the hallmark of life.

Maybe this hierarchical nested modeling, if some of these inner loop processes are capable of bifurcating in different ways and giving you a kind of intelligent optionality, maybe that's a kind of thought.

But let's keep working up.

So if we're talking about something like the brain, I would think of a

a hierarchy of nested coupling processes evolving on different time scales.

And in the community, they'll tend to call these things non-equilibrium steady state densities.

I call them self-organizing harmonic modes.

And it's a way I interpret, um, uh, neural synchrony, um, to the degree that you get it, it's facilitating communication through coherence, uh, making sure that, um, within these systems, not just like tuning and excitation inhibition balance to, uh, and then it works, but that to actually within this maelstrom to get, um, coherent dynamics, coherent inference, uh, you would, you, you need the neurons need to team up.

So you need synchrony, you need synchrony for, um,

I guess what they would call a marginal message passing.

So it'd be like marginalization, like a joint belief.

And then you packet your beliefs and these like coalitions are doing like, like these units, this quantization of sense-making of prediction error and prediction.

And so there would be like this nested hierarchy.

And so if you're talking about something like, let's say like gamma frequency, that might be like a very small local unit of like synchrony and sense-making.

And maybe that's like a,

a quantization of prediction error that will be passed upwards.

So that's like an observation.

Within the scope of this gamma packet, though, maybe that's like a prediction for whatever is inside it.

But you keep going up, so then maybe that's something like beta.

And then, so gamma like 40 times a second.

And then beta would be something like maybe high and low.

These are terms for somewhere between 13 to 30 times a second.

And maybe you're starting to get

depends where you're at, but these higher order attractors and these higher order predictions, like a composition, something like a hand reaching, something like that.

But where's consciousness going to come into this and why?

It seems if you can take these different recognition, these recognition of different patterns, and you can stitch them together such that you have

within the organizing principle of, I would suggest an egocentric perspective of a particular point of view, and you can arrange them in some kind of space.

What kind of coherence?

How much?

That's a good question.

Some kind of time, some kind of causal relation.

Well, now this inference, you might start to say, well, now you might be inferring a world, specifically a structured world model with spatial, temporal, and causal properties where things can unfold.

And you can have something like a stream of experience

if this synchronization manifold is basically giving you a joint belief over your sensorium.

And so it seems like alpha is a frequency where you can get a big enough of a agreement, of a negotiated agreement on a harmonic, on a

collective sense-making, that you could bring together all the different embodied causes pegged by an egocentric reference frame in terms of anatomy and what would be a scope.

And something that I might have said that's implicit is there's this inverse relationship, it seems, between the frequency at which you can get oscillations or harmonics and the scope of what can be synchronized.

So you can get a little thing to agree really quickly.

But to get a big thing, it's going to necessarily take more time.

And so more things can come into the mix.

And consciousness, I'm wondering if that is basically at a scope where you're doing these joint estimates of system world states that lets you both inform and be informed by evolving action perception cycles.

That actually the functional closure that you achieve for this estimation process is on a proportion of

the events in the world that are relevant to your affordances, that actually would be part of your policy selection.

And that if you can get this kind of alignment of temporal dynamics, and if you're having these things brought together in a way that gives you a point of view of some kind, well, I might say, okay, now it's something like conscious thought, this stream of experience doing different things.

But the thinking part of it, we might want to save that or not for something like imaginative planning or some sort of like you're thinking of something other than what is.

And that's actually what's happening at this intermediate level where you're conscious, but you're sussing out different possibilities as you're trying to situate something in some sort of coherent spatial temporal unfolding that you can make sense of.

And so the idea would be like everything that we can think of, we're necessarily temporalizing and spatializing just so we can grok it.

By grok it, I mean literally so we can bring it into some sort of relation with this intermediate level embodied simulation.

Otherwise, we can't think of anything.

But I'd say there could be a kind of unconscious thought also.

This actually might relate to something like a counter.

I think you get one counter in that this bundling, if there's a certain time scale which you can get a big enough of a coalition, there's a timeframe for achieving that.

In some ways, that's a kind of counter.

That's a kind of discretization.

And you might think of this in active inference terms as kind of discrete updating of the generative model.

But it seems like you can get something like unconscious thought potentially via the hippocampal system to kind of loop around to Clive Waring again.

And that one way I would think of thought is as generalized or navigation through generalized space.

hitting a particular, not arbitrary target, being able to find your way there.

And so I've been working with these roboticists who are building these SLAM systems.

It means simultaneous localization and mapping.

And so what these robots are doing, they're trying to figure out where am I in this environment?

What is the sense of this environment?

And they're doing this actively in terms of they're moving around, scouting out what's happening,

And there's this mutually concerning inference of what is this world I'm in, and where am I, and what is this world, and where am I, and figuring this out.

But this core system would seem to have within it these place fields, these locations that could be in physical space, like the tree is there, I'm here, my kitchen's down there.

But it could also be within a conceptual space.

so um they're sometimes modeled as like bump attractors or like you get these like local recurrences within this like centrally located thing and basically this chaining of these bump attractors would then chain together broader dynamics for the rest of the brain and so in theory this could operate um in a way where you're not aware of it it's like coordinating sense making

and a kind of, I wouldn't say propositional, but in an orderly way.

There's like a topology to it, and you went from here to here to here to here.

So in theory, that could bypass consciousness.

I don't know if it can or not.

But in terms of this nested graphs of graphs of graphs, there could also be a kind of holography there, potentially, in terms of, well,

Not holography, non-locality, let me say.

Not holography, non-locality there.

In terms of when you coarse-grain, at some level of coarse-graining, locality falls away.

I'm not sure about that.

But yeah, so those are some thoughts on thought.

But one more thing, though.

So ultimately, I think this is going to be crucial

understanding the principles underlying this system, not this system in a narrow sense, but of this graphs of graphs of graphs, where these inner loop processes have these different capabilities, it will be the secret to advanced intelligence, understand what do we want from thought and cognition, and I also suspect it will be the answer to Schrodinger's question.

And that what would make, I think, life,

clever and more than a whirlpool like you can so dissipative systems they can be extremely impressive extremely lifelike but this sort of inner loop process that can um give you this sort of optionality that this potentially a critically organized inner loop process that can bind together overall dynamics and give the overall system because of this bifurcating potential

this sort of optionality that's going to be important.

Now, what if then this interloop system is also a kind of counter or a kind of like thing that stitches itself together where basically like genetic inheritance, like it gives you,

over time, the ability to basically get better priors into it.

It lets you transfer learn.

It lets you what happens here can influence the next thing, can influence the next thing.

And so this could be a way of what you could think of Cheblanka.

I think I'm ruining the name.

But this unlimited associative learning as a hallmark of consciousness, this kind of transition, something like that, though, this unlimited learning, open-ended learning,

as phylogeny, as basically an inner loop process capable of coordinating the overall system, which has some sort of pointer relation, some sort of semantic pointers, semantics, which itself allows for a kind of heredity, a kind of inheritance of whatever happened.

And so I think we bring in those two things together, an inner loop process capable of some kind of counterfactual processing,

and link that to inheritance, now we'll have what we need to have either life or a potentially conscious system.


SPEAKER_00:
Thank you, Adam.

I flipped to the next slide on diamonds and holographs.

Where does this come into play?

It's not something that you'd find in the active inference literature today, but maybe it will be found there tomorrow.

Why?

Calling on our diamond experts.


SPEAKER_05:
Yeah, yeah.

Are we bypassing the dichronic synchronic thing?


SPEAKER_00:
Either.

Yep.

Wherever you want to go on this slide.

Yes.


SPEAKER_05:
Okay.

Yeah.

So...

you know, so again, if we're, if you know, like Robert is saying, okay, is the mind what the brain does?

Like, what is this?

What do we want from font?

When you're when we're generating, you know, in the like, pro adversarial kind of, or in a, you know, generative adversarial network, you have this generator talking to, you know, you know, the

you know like itself saying no no no this is a cat this is not a cat and it's sort of this ai is talking to itself um what what is that in us when we're sort of talking to ourself so again you have someone like me in the category theory side saying okay um i do think there is some kind of strong duality between the agent and the environment

So if minds are modeled in this diamond way, then what you're actually doing is just engaging with your reflections.

How do you actually engage with your reflections?

Do your reflections have your reflections?

So based on what Adam was saying, it's like, what's the role of priors in holography?

what does it actually mean to sort of have, that was my original question, when an agent is figuring out how to jump over a wall it's never seen before, how is it doing that?

If affordances are just a set of parameters that are built into the thing, right?

So let's try to do this in

If you could do this parameter free, what would that model actually look like?

So for someone like me, I am fascinated how when I speak to you, the speech doesn't last, doesn't last, doesn't last, doesn't last.

But somehow you remember what I say.

Do you remember what I say?

You must probably construct a holographic copy of me and what I'm saying.

So that you store that somehow.

So someone like me with almost like a total recall can remember stuff like this.

I know I can talk to people and I have seven different versions of time going on, you know?

How do you align like all of those seven and you're just focusing on like on what's happening now?

So you aren't really, so you have a crazy feedback processing going on and none of this is happening in real time, right?

Because there's neural transmitters happening.

So this is already the past, all of this, whatever that means when we say the past.

And so I'm just wondering what the, you know, when you have a very strict set of priors governing how your agent behaves, where do those come into play and how do those work?

if the very way that the agent operates is through holography.

So again, holography is like you have some kind of dimensional relation going on that perhaps we have a 2D retina for a 3D creature.

2D retina is taking in information and compressing it and then

reconstructing it in a higher way.

So that's just for that.

I have this model of, you know, instead of just having the normal holographic principle, which relates anti-de Sitter space field theory, I'm trying to get it in sort of a diamond way where you actually use the italical homology of diamonds, which are these functors or concomiters.

and build up a holography from an image functor of sheaves.

So it's purely mathematical.

Let's just build up a holographic space from image functors, which is really relevant to active inference because you're acting.

You're acting, you're acting, you're acting.

There's no other definition than a functor than some kind of relation.

So building up holography from relations and the conformal aspect, which is the metric-free, sort of gravity-free space, would be in the profinite condition of the diamonds.

So you have a six-factor formalism, which is replacing ante-de-sitter space.

You have a profinite condition, which is replacing the gravity-free.

So that seems to me like a very interesting way to figure out how an agent is navigating

if there are reflections.

So the math part aside, just what does the active inference experts here think about engaging with your reflections?

That it's never really anything new.

You're just sort of walking around in your echo space.


SPEAKER_00:
Thanks for the comment there, Adam.

And then anyone else with a raised hand?


SPEAKER_03:
So this might not dock, but let's try.

Um, in terms of like the nature of like, how would I remember Shanna or how can I know anyone or anything?

Um, I'm wondering if it always has to be through some kind of, um, generalized mirroring with your own embodied experience.

And ultimately it's gotta be cashed out that way.

And that this, the particular, um, nature of like the, the holographic terms, like the ability to like

reconstitute and you know reducing the dimensions and then expanding them again would be by virtue of you having this system which would just through a variety of reasons be able to generate intelligent coupling with the world of a sensory motor variety but also run this same process in an offline mode so that you can imagine

you know, embodied simulation.

And that if you then, um, so this, so the inactive inference, this, uh, the sensory motor processes are understood as these self realizing predictions where you'll set these equilibrium points.

And then this hierarchy will just sort of reconfigure and unfold.

And as it's jostling around,

and passing these implicit predictions and prediction errors around, it just dynamically, or just, it'll, by Hamilton's principle of least action, as like water flowing downhill, it'll find this minimal state of minimal prediction error that it's ultimately cashed out in reflex arcs in the world, but for thought would be the virtualization of that.

So you're imagining this pattern of reaching out.

So you have this construction system and this virtual reality system.

And then if there's,

a reliable patterns of coherent state transitions that I'm likely to do in different circumstances.

Well, now I'm starting to get like an agent model of myself of a kind, and you're starting to get, if there's a reliable set of policies that will happen in different circumstances, it's like, okay, we're not yet self-reflective though.

It seems you're gonna have to objectify the self somehow.

And I'm thinking this likely comes through mirroring actually.

through relationships between parents and children at first, and where the parents seem to be actually soliciting.

Some people say the mirroring is innate.

I actually don't think it is.

It seems like parents help to solicit it.

But they mirror with you so that you learn to mirror.

And so that creates the learning curriculum.

But through these games played between caretaker and child,

you learn to get this mapping between what's out there and what's here.

Somewhere along the way, you'll learn to basically associate what other people are doing in any way.

You'll learn just to mirror with them.

They're over there, and then you see that and you draw this analogy to your own embodiment.

You put yourself in the same pose, the same situation.

And then this now gives you a basis for a kind of objectified selfhood.

It's still always from like this egocentric perspective, but now you're able to like get this other person.

And I'm thinking that that's like this kind of interface for like my Shannon model would have to be like the docking point would be something like this third person objectified selfhood, which then would let you cash it out or unpack it in a coherent embodied simulation, something like that.

One thought about...

like a GAN setup and discriminators.

It seems like that might be, again, crucial for both hard problems and Schrodinger questions, I think.

There's this one thinker, he's this academic psychiatrist, a rucker.

Did you plan on having him on, Daniel?

He wrote this one paper...

He's fantastic, actually.

I think that'd be a good idea.

But it's this idea of like, so a system basically, he calls it like allostatic overload in a collapse model, where basically through these systems that have these functional bottlenecks, these bottlenecks will tend to kind of, that are helping to establish the synchronization manifold over a system, the coordination, that these heavily trafficked and contingent areas

will tend to fail first when you stress the system too much.

And this would give you, for instance, a kind of flexible hierarchy where either you're doing things maybe unconsciously, but just like fast feedback loops of the environment.

You're not getting fancy, quick in the dead.

Or you're letting yourself build models upon models, reflection upon reflection.

But that these more rarefied things, they'll fail first.

And so you got this like, you can move up and down in sophistication.

I'm wondering whether in terms of, and so this would apply not just to all intelligent, all interesting intelligent systems is the claim.

But while you have this like natural kind of adjustment of your sophistication, I'm wondering if it could be good to have something that preemptively anticipates this so you're not just having reactive regime collapses.

Or it's actually, you can actually be like, you know, maybe not.

Yeah.

I could switch to an unconscious berserker mode right now.

Maybe I don't want to be in that position.

And so if I can get something that's like giving me a read on my degree of like stress of allostatic load of degree of like how, how close am I to the edge?

Um, that can be a good thing.

And so for the brain, this would appear to be largely the interior cingulate would be probably the main, uh, uh, free energy or prediction error integrator.

It's centrally located.

It has like, in every sense, it's like, boom, got the most connectivity.

And it's just perfectly suited to say like, how well are you doing in self-evidencing?

I'm wondering like within cells, if you have a similar kind of GAN-like discriminator, some sort of like inner metabolic cycle that like accumulates in it, like maybe like mitochondria accumulating like radicals or like some sort of like

gene expression loop i don't know but something like this that's highly central that like when it starts to go this would then influence your policy selection this would then influence your orchestration i don't know what that would look like in a cell but for the brain this appears to be um there does appear to be some fairly centralized structures literally that allow for that kind of gam-like function and that is key to any to basically intelligent agency

and is also key for things potentially like, I don't know if I believe this actually, so Sam Gershman has argued this is like reality monitoring, like a higher order thought sense, that I think something like that could work, but the idea is that, you know, how do I distinguish if I just imagine something or if I actually experienced it, and that there is some sort of like GAN-like discriminator who treats the whole frontal lobes like this.

That's something else, but it seems like this though GAN framework though,

This idea of discriminators is extremely flexible, extremely powerful, and will apply across a broad range of systems, and I think is actually really essential.

So, yeah.


SPEAKER_00:
Thanks.

Adam?

to bring it back to act in the diamond holograph.

I kind of drew two diamond shapes on my page.

One was person A and person B and their shared informational niche.

They're both looking at a whiteboard.

And so there's two people communicating to the shared screen and unpacking.

And that was something we talked about with Chris Fields.

And then to relate it to this diachronic,

through time and synchronic at the same time, I kind of thought about like a bow tie or two diamonds where in the current moment is the agent now.

And then there's the agent in the future at a inferred trajectory point, and then also in the past.

So we're sort of like retrodicting, we're now casting, and we're also predicting the future.

And maybe the pathway through the past, present, future, it's like a narrative that helps the organism make sense of where it is at that time.

Any other points on diamonds or I think we can kind of go to the future and give some, okay, awesome.

Our closing thoughts and anyone who's watching live can add a thought or we can go around here as well.

What is the future of Active Inference or a future or a direction?

Where do we see this field in the future, 10 years from now or some other time point out?

Will we be adapting active inference to high-level unsupervised learning?

Will we merge with strong artificial intelligence?

And where do we see embodied cognition scaling to or applying to next?

Blue, and then Robert, and then anyone else.

Robert, why don't you go ahead?


SPEAKER_01:
Well, sure.

Thanks.

So just my personal opinion, it would be very interesting to see to what extent active inference would or could move from... I think now a lot of discussions are kind of mechanistic.

I mean, complicated mechanisms which are happening in the brain or in a cell or wherever.

I would be very interested whether that...

where the active inference could be a way of, precisely speaking, about norms, normativity.

I think someone mentioned at the very beginning, said something about normativity.

What I mean with that is the distinction between inferring what is the case, or focusing on what is the case, what physical stuff is going on, and what should go on,

In philosophy, there is this famous distinction that one could not be derived from the other.

It goes back to David Hume.

The odd from is, it's a problem.

And I was wondering whether active inference could be an interesting middle way here.

And the second related thought is, which has to do with AI and reinforcement learning.

We mentioned that in the very beginning.

That seems to me to be a good... I mean, one could be very critical and could say, well, in some sense, active inference, that's very nice and interesting, and one could do nice biology with it.

But it's not so obvious what the benefit would be compared to reinforcement paradigms.

And if one would be able to say something reasonable to this normativity question, then I think that would be a very big plus point for active inference.

But that's why I hope that I kind of see in the future work which goes more into that direction as well.

Thank you, Robert.


SPEAKER_00:
Luke?


SPEAKER_02:
So Robert, just to kind of respond to that, I don't know if you've seen the Scaling Active Inference paper that we looked at.

It's been a while.

Yeah, number eight.

Who was the first author?

I forget.

Alex Shantz.

Oh, Alex Shantz.

Of course.

So but he definitely compared active inference and a computational paradigm to reinforcement learning.

So I don't know if you've seen that work and, you know, in different testing, different paradigms, the hopper and the car and the hills.

And it was a nice paper anyway.

So where I would really like to see active inference in 10 years, I mean, we talked about how active inference is scale-free, a scale-free model.

So theoretically, it should also be multi-scale.

I think that there's a little bit, we have a little bit of work to do.

to get it to be multi-scale.

And I think that that work definitely centers around emergence.

When does the next scale emerge?

When does a collection of cells become a tissue?

When does a collection of tissues become an organ, et cetera?

So I would really like to see active inference incorporate the bidirectional information flow that was talked about in Krakauer's paper, the information theory of individuality.

I would like to see that merge with active inference and give us a way to,

talk about how the cells in my code constitute me in the society that I live in, right?

So.


SPEAKER_00:
Nice.

Shauna, then Adam.


SPEAKER_05:
Yeah, that's great.

I totally agree and support you there.

I am obviously a heavy advocate of mirror phenomena.

So while there may not be mirror neurons, which I hope there are, there is a mirror function.

So I'm an advocate not just for reinforcement, but for imitative learning.

So what I would like to see active inference move towards

is a new mathematical, you know, adding to the mathematical framework just some new notions.

So in the other math stream, I talked about condensed sets, which are Peter, Tulsa, Dulce, and Clausen's idea of sheaves over points.

So if we could actually get time to be modeled as singular, which I think sounds catastrophic, but it might be more apropos to what's happening here instead of assuming it's continuous or

a fluid that you move through, whatever that is.

So if you can reframe things and condense sets, this would actually help us incorporate this mirror phenomena.

So Adam and I really think the GAN network is going to be really nice.

So I have this idea of constructing this pro-generative adversarial network and having a perceptron that's an actual V-stack.

So V-stack is just a higher notion of the diamond.

So whereas you take, you know, you glue together certain vector spaces and you get a diamond, you can also gather diamonds and get this V stack.

So I'm interested in this phenomenon, but if we can actually take a general adversarial network and make a pro version of it, so then this would become like a certain pro object in the category of all possible generative adversarial networks.

So the goal here is to categorify embodiment for AI.

which I think is very strong.

So then you can model the perceptron as this VStack perceptron so that the output is hopefully some kind of condensed set.

It's not just a function anymore.

It's going to be either like a sheaf of things or it's going to be a whole bunch of categories of something.

So this pro-formalism would also be a model of embodied meta-learning.

So I'm an advocate through this mirror formalism to get meta-learning going, which is going to reframe the frame problem in terms of condensed sets or category.

So I think the frame problem is huge, and to categorify it would actually be really nice.

So if you can actually model inactive robots as advanced AI in this kind of pro-finite formalism, and you can model mirror neurons as this play of imitation, emulation, GANs in a sort of mirror game theory for inactive neurons.

This is what I think active inference formalism can actually do, because you can actually construct a correspondence between embodied cognition in my profinite formalism and computability.

and sort of pro version of the synchronic and diachronic emergence but have that already built in to the pro-GAN so if it's like diachronic and synchronic emergence could be built in as affordances I think that's that's really nice because I think I think active inference needs to have something like there's something about the synchronic emergence about it being sort of higher level phenomena being you know

you know, supervening, you know, on like these, you know, subvenient neural structures to get this vertical emergence.

But then you also have this sort of horizontal emergence where it's like, wait, you know, the novel property that emerged over time, like existed prior to emergent.

So I think emergence is going to be really beautiful.

And so I think if we can incorporate the GAN, the pro-GAN, some kind of condensate and higher, like scaling up.

When we say scale, let's also not be afraid to scale things like the perceptron and affordances and inactive robotics.


SPEAKER_00:
Thanks.

When you were talking about the generative adversarial neural network, I wondered if there was a collaborative one, just two networks that were teaching each other helpful examples.

And then when you pull back a level, even if it's framed in an adversarial context between two models, it's actually being done in a collaborative sense.

So that is almost that multi-scale emergence right there.


SPEAKER_05:
pretty cool.

Let's talk about the category of the GANs.

Let's have GANs talking to each other.

That's what I want.

Awesome, Daniel.


SPEAKER_03:
Adam?

With respect to what you were just saying, Daniel, I think that's actually a really good model of play in terms of this ultimately benevolent attempted adversarially attacking yourself.

But in terms of future directions, no.

many things I'm not thinking of, but the things that would particularly interest me would be getting actually meta-learning.

That would be really quite key and different forms of meta-learning.

The ability to build up the sophistication and to have across episodes and contexts, actually making sure that what's inferred and learned there will update.

And so it seems to me that

To help with that, maybe more crosstalk with machine learning.

That could be useful.

And more crosstalk with people like Shanna, who can give us the precision of knowing which mappings are legit and what are our mappings actually doing.

So for instance, I have notions that, for instance, you could think of the brain as a whole as a kind of like of sorts, where it's like if the variational

autoencoder doing this dimensionality reduction, getting into this latent space.

This latent space has a kind of graph structure, like a graph neural network that has like geometric deep learning happening within it.

And then on top of this, like the hippocampal system would give you like a kind of a higher order semantics on top of that.

But is that legit?

And what's the relation?

And from there, like there's going to be particular operations happening, some of which would correspond potentially to things like experience.

So is your experience a kind of discrete updating of like snapshots or is it actually a continuous flow?

What are the, like, is it like, for instance, within like the association cortex, like the latent space is just like fast message passing there.

Or is it like the enslavement of the whole hierarchy?

So the question is like, what computational objects are we dealing with?

It seems like we're gonna need crosstalk with

people who have expertise in things like category theory and machine learning to actually understand those well.

And I think if we bring those together, a lot of the debates might end up being resolved.

Like we can have, for instance, both instrumentism and realism.

We can then at certain points start to have enough constraints that we can work our way towards things like applying sophisticated inference to yourself in ways that like, I don't want to criticize active inference, but

it does seem like sometimes a failure mode is the power of the framework can result in kind of the same failures, good old fashioned cognitive science of like, don't bother me with plumbing functionalism.

And ideally, if we can go across the more perspectives we can bring to bear on something, going across implementational algorithmic and computational and cross-reference them and bring in phenomenology too, that would be really helpful.

And so sometimes it seems like we're a little bit anemic

on the implementation.

We're squinting a bit more than we might realize.

And so how do we beef up the algorithms?

So ultimately though, for me, the end game is I think I want to bring active inference to explain consciousness.

I think it's a major transition in evolution.

It's the elephant in the room.

It is the room.

By and large, it's not the only thing going on, but we should not underestimate its power, no matter how much it's fashionable to denigrate it.

Things like the nature of selfhood as constructed process and getting metacognition out of that, and not just reducing metacognition to a kind of hyperparameter, but actually as a process with particular epistemics that are realized in particular ways constructively of that kind.

And then ultimately, what I would like

So I think active inference will be capable of making major inroads into answering Schrodinger's question more than we've done in the past.

I think we might even have a definitive answer, and maybe in the not too distant future.

I think we might have a definitive answer, potentially or not, to the hard problem.

And ultimately, I want free will to be a part of it.

And by free will, I know there's a lot of ways

word is used, but actually use it.

I like refer back to the language.

We want the degrees of freedom and the directed drive.

We want this optionality, this empowerment of our options being open, but we want those options to be able to steer in particular ways.

And this like free will is like what meaningful power is.

It's what enables meaning.

It's what enables open-ended evolution of

particular directed kind where we're actually getting teleology we're actually having you know the things we care about and the things that actually move the world and uh you know that let us let us get to the moon you know bombs that leveled cities all these things uh that the future will depend on uh free will is going to be part of that story precisely operationalizing what we mean you could just say agency that's fine but that's what we're going to need and so something like uh

And potentially, a GAN framework would be part of that.

How well am I doing?

Precisely narrowing down the micromechanics of agency.


SPEAKER_00:
Thanks.

Thanks, Adam.

i would love to see and expect and will enact policy to improve communication and education you're right there's so much more to be done it's worthwhile to criticize or to see where it could improve because those are the affordances for a contribution so it would be awesome to see everything that people just mentioned

arise as well as to include a lot of voices in the conversation that maybe know about active inference today but don't feel like they're in a position to contribute even beginners especially contribute through their questions and for those who have disciplinary expertise or who want to be a new kind of generalist for this new way of doing science i hope they'll find a home in active inference as well so fun times the math stream is always a wild ride

We really appreciate it.

It's an awesome convo.

I hope that people will stay in touch.

If you're watching in replay, leave a comment and the lab will still be there.

And for all of you here, just thanks so much for participating.

And each of you would be awesome to give a solo or have a conversation to explore some of these ideas.

So it's great times, everyone.

Bye.

Bye, everyone.

Bye-bye.