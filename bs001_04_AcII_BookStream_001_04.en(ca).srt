1
00:00:12,020 --> 00:00:14,532
DANIEL FRIEDMAN: Hello and welcome everyone. It's January

2
00:00:14,596 --> 00:00:17,876
3, 2023. We're in active

3
00:00:17,908 --> 00:00:21,000
bookstream. Number 1.4

4
00:00:21,150 --> 00:00:23,556
on governing continuous transformation.

5
00:00:23,748 --> 00:00:25,240
Off to you, Bleu.

6
00:00:27,340 --> 00:00:30,156
BLEU KNIGHT: Great. So we are the Active Inference

7
00:00:30,228 --> 00:00:33,264
Institute and this discussion is over.

8
00:00:33,382 --> 00:00:35,820
Governing continuous transformation.

9
00:00:35,980 --> 00:00:38,796
This is a recorded and an archived

10
00:00:38,828 --> 00:00:41,216
Livestream. So please provide us with

11
00:00:41,238 --> 00:00:43,260
feedback so we can improve upon our

12
00:00:43,270 --> 00:00:46,068
work. We are a participatory online

13
00:00:46,154 --> 00:00:47,760
institute that is communicating,

14
00:00:47,840 --> 00:00:49,696
learning, and practicing applied active

15
00:00:49,728 --> 00:00:51,892
inference. You can reach us on social

16
00:00:51,946 --> 00:00:54,576
media at all of these different links

17
00:00:54,608 --> 00:00:57,392
here. All backgrounds and perspectives

18
00:00:57,456 --> 00:00:59,976
are welcome to discuss and contribute to

19
00:00:59,998 --> 00:01:02,472
this work. And we will be following good

20
00:01:02,526 --> 00:01:05,176
video etiquette for live streams. If you

21
00:01:05,198 --> 00:01:06,248
would like to get in touch to

22
00:01:06,254 --> 00:01:09,056
participate in a future Zero Livestream

23
00:01:09,188 --> 00:01:11,864
or one of the upcoming discussions,

24
00:01:11,992 --> 00:01:14,012
please reach out to us via social media

25
00:01:14,066 --> 00:01:17,932
or email. And again,

26
00:01:17,986 --> 00:01:21,068
our links. So today we are

27
00:01:21,154 --> 00:01:24,128
going to cover section 1.4.

28
00:01:24,214 --> 00:01:25,936
So we're just going to go kind of over

29
00:01:25,958 --> 00:01:28,460
where we are in the book, the keywords,

30
00:01:28,540 --> 00:01:32,048
and then the different subjects and

31
00:01:32,214 --> 00:01:34,228
things that we pulled out of this

32
00:01:34,394 --> 00:01:38,116
section. So just to start off, we will

33
00:01:38,298 --> 00:01:40,900
maybe just introduce ourselves. I am

34
00:01:40,970 --> 00:01:44,144
Bleu. I am a longtime institute

35
00:01:44,192 --> 00:01:46,884
participant and an independent

36
00:01:46,932 --> 00:01:49,384
researcher in New Mexico. And I'll pass it to Daniel.

37
00:01:49,422 --> 00:01:52,760
Daniel: I'm Daniel, I'm a

38
00:01:52,910 --> 00:01:55,428
researcher and institute participant. I'll pass to Tyler.

39
00:01:55,524 --> 00:01:58,776
TYLER SULLBERG: I'm Tyler. I'm a DAO

40
00:01:58,808 --> 00:02:00,396
researcher and practitioner in

41
00:02:00,418 --> 00:02:04,204
California. Is there

42
00:02:04,242 --> 00:02:06,284
any introductory comments or do you guys

43
00:02:06,322 --> 00:02:10,136
just want to jump right into it? Jump

44
00:02:10,168 --> 00:02:13,664
in. Okay, here we go. So this is the

45
00:02:13,702 --> 00:02:15,552
section that covers the free energy

46
00:02:15,606 --> 00:02:18,256
principle. And that's also the title of

47
00:02:18,358 --> 00:02:20,752
this chapter. And I think the first

48
00:02:20,806 --> 00:02:24,188
keyword on our keyword. So we pulled

49
00:02:24,204 --> 00:02:26,596
out a lot of these keywords. I mean, we

50
00:02:26,618 --> 00:02:28,176
pulled them out, they weren't

51
00:02:28,208 --> 00:02:30,964
highlighted by Bijan or selected by him

52
00:02:31,002 --> 00:02:34,276
at all. And this is just kind of the

53
00:02:34,298 --> 00:02:36,020
topics that we thought that would be

54
00:02:36,170 --> 00:02:38,264
better to dive deeper into for a more

55
00:02:38,302 --> 00:02:39,940
thorough understanding of the material

56
00:02:40,020 --> 00:02:42,968
presented in this chapter. And this is

57
00:02:42,974 --> 00:02:44,904
not like a final word. This is maybe

58
00:02:44,942 --> 00:02:47,684
just an introductory perspective and our

59
00:02:47,742 --> 00:02:51,036
take on what's maybe happening in this

60
00:02:51,058 --> 00:02:52,936
chapter, not a review. So we're

61
00:02:52,968 --> 00:02:55,228
definitely open to correction and

62
00:02:55,394 --> 00:02:58,590
updating our model of this model.

63
00:02:59,440 --> 00:03:02,668
All right, so abstract. Tyler, do you

64
00:03:02,674 --> 00:03:04,188
want to read this first? Action force

65
00:03:04,194 --> 00:03:07,356
us. Sure. So the Free Energy principle,

66
00:03:07,468 --> 00:03:09,116
the first order principle of police

67
00:03:09,148 --> 00:03:10,960
action empowering self communication.

68
00:03:11,300 --> 00:03:13,220
FTP commands the generative process

69
00:03:13,290 --> 00:03:15,236
active coherence lab dedicated to

70
00:03:15,258 --> 00:03:17,220
minimizing the information theoretical

71
00:03:18,440 --> 00:03:20,276
mathematical difference between top down

72
00:03:20,298 --> 00:03:21,956
predictions and action generated bottom

73
00:03:21,978 --> 00:03:23,428
up upstream line in pursuit of

74
00:03:23,434 --> 00:03:25,700
minimizing error, surprise and entropy.

75
00:03:26,040 --> 00:03:28,096
The power of forsonian active inference

76
00:03:28,128 --> 00:03:30,596
is fundamentally fourfold. It's a pure

77
00:03:30,628 --> 00:03:32,596
belief setting in dynamic and non

78
00:03:32,628 --> 00:03:34,196
stationary environments, the active

79
00:03:34,228 --> 00:03:36,004
inference agent carries out ensemble

80
00:03:36,052 --> 00:03:38,448
exploration to account for uncertainty

81
00:03:38,564 --> 00:03:40,696
by making inferences in Bay's optimal

82
00:03:40,728 --> 00:03:42,924
fashion. The reward signal, so

83
00:03:42,962 --> 00:03:44,572
characteristic of reinforcement learning

84
00:03:44,626 --> 00:03:46,856
is removed. And finally, active

85
00:03:46,888 --> 00:03:48,652
inference sets the collaborative human

86
00:03:48,706 --> 00:03:51,884
machine AI potential so integral

87
00:03:51,932 --> 00:03:53,872
to the multi intelligence firm as the

88
00:03:53,926 --> 00:03:56,016
mathematical expression of beliefs form

89
00:03:56,038 --> 00:03:57,712
of probabilities, provides the very

90
00:03:57,766 --> 00:03:59,936
common denominator to line humans with

91
00:03:59,958 --> 00:04:02,928
machines. Wow.

92
00:04:03,014 --> 00:04:06,816
Big is true. Okay. And the author

93
00:04:06,848 --> 00:04:09,140
goes on to say there are only two

94
00:04:09,210 --> 00:04:11,392
distinctions that matter what is known

95
00:04:11,456 --> 00:04:13,780
and unknown and what is in our control

96
00:04:13,850 --> 00:04:16,104
and what is not. There are four states

97
00:04:16,222 --> 00:04:19,668
active action, internal firm resources,

98
00:04:19,764 --> 00:04:22,868
sensory perception and external unknown

99
00:04:22,884 --> 00:04:25,188
and hidden behind the Markov blanket

100
00:04:25,364 --> 00:04:27,912
according to Free Energy Governance free

101
00:04:27,966 --> 00:04:31,484
Energy Principle powered AI, which he

102
00:04:31,522 --> 00:04:34,008
uses here, this capital A and lower keys

103
00:04:34,024 --> 00:04:35,804
I to mean active inference. So free

104
00:04:35,842 --> 00:04:37,896
energy principle powered active

105
00:04:37,928 --> 00:04:39,884
inference is the future site of

106
00:04:39,922 --> 00:04:42,992
organizational becoming. So we can

107
00:04:43,046 --> 00:04:46,784
unpack that, I guess, starting with this

108
00:04:46,822 --> 00:04:48,656
claim, which was in the abstract itself.

109
00:04:48,758 --> 00:04:51,948
So maybe we don't need to reread

110
00:04:51,964 --> 00:04:55,552
it. Or was it exactly stated there maybe

111
00:04:55,606 --> 00:04:57,680
not fourfold,

112
00:05:01,320 --> 00:05:03,124
the four claims. We'll just start off

113
00:05:03,162 --> 00:05:06,524
this first one. The power of personian

114
00:05:06,592 --> 00:05:09,256
active is fundamentally fourfold. It is

115
00:05:09,278 --> 00:05:12,052
a pure belief based setting in dynamics

116
00:05:12,116 --> 00:05:16,136
and non stationary environments. So what

117
00:05:16,158 --> 00:05:19,032
does that mean? Like, what is Friston

118
00:05:19,096 --> 00:05:21,516
active inference? So maybe we want to

119
00:05:21,618 --> 00:05:24,124
just step back a little bit and talk

120
00:05:24,162 --> 00:05:28,632
about the FEP. And the definition

121
00:05:28,696 --> 00:05:31,696
or explanation that Bijan picked out for

122
00:05:31,718 --> 00:05:33,952
this chapter is the free energy

123
00:05:34,006 --> 00:05:35,856
principle stems from the idea that

124
00:05:35,878 --> 00:05:37,904
living systems can be distinguished from

125
00:05:37,942 --> 00:05:40,192
other self organizing systems because

126
00:05:40,246 --> 00:05:42,764
they active. Avoid deleterious phase

127
00:05:42,812 --> 00:05:45,476
transitions by bounding the entropy of

128
00:05:45,498 --> 00:05:47,764
their sensory and physical states under

129
00:05:47,802 --> 00:05:50,116
the FEP. To be alive simply means to

130
00:05:50,138 --> 00:05:52,548
revisit a bounded set of states with a

131
00:05:52,554 --> 00:05:55,092
high probability. And that's from this

132
00:05:55,146 --> 00:05:58,090
2019 Badcock et al. Paper.

133
00:05:58,620 --> 00:06:01,480
And this image is from Kirkhoff et al.

134
00:06:01,550 --> 00:06:04,968
2018. And I always like this

135
00:06:05,054 --> 00:06:08,348
when I think about life and self

136
00:06:08,514 --> 00:06:10,140
organizing systems.

137
00:06:12,320 --> 00:06:14,876
This picture just really speaks to what

138
00:06:14,898 --> 00:06:17,660
it is to kind of be self organizing,

139
00:06:19,120 --> 00:06:22,320
a hierarchical scale.

140
00:06:23,540 --> 00:06:26,064
And this like revisiting a bounded set

141
00:06:26,102 --> 00:06:27,776
of states with a high probability kind

142
00:06:27,798 --> 00:06:29,884
of speaks to the non equilibrium steady

143
00:06:29,932 --> 00:06:33,664
state density that is like a constraint

144
00:06:33,712 --> 00:06:36,230
of life. We kind of have to live within

145
00:06:37,480 --> 00:06:41,140
a certain temperature range, a certain

146
00:06:41,290 --> 00:06:44,276
glucose range, and all life has like an

147
00:06:44,298 --> 00:06:46,804
optimal range of states that they stay

148
00:06:46,842 --> 00:06:49,044
in. But if your fever gets too high,

149
00:06:49,082 --> 00:06:50,328
like if the temperature goes too high or

150
00:06:50,334 --> 00:06:52,344
too low, like you will dissipate. So you

151
00:06:52,382 --> 00:06:55,256
revisit this bounded set of states with

152
00:06:55,278 --> 00:06:56,808
a high probability and that's kind of

153
00:06:56,814 --> 00:06:58,584
your non equilibrium steady state

154
00:06:58,622 --> 00:07:01,012
density. Do you guys have any comments

155
00:07:01,076 --> 00:07:03,656
here on the FTP and self organizing?

156
00:07:03,688 --> 00:07:07,352
Maybe? I'll give one comment.

157
00:07:07,496 --> 00:07:10,564
This is a via positive. It's describing

158
00:07:10,632 --> 00:07:13,472
what the FEP is. But we could look back

159
00:07:13,526 --> 00:07:15,824
to those four claims and think about

160
00:07:15,942 --> 00:07:19,068
what this is not the Via negativa.

161
00:07:19,164 --> 00:07:22,608
So rather than being believe based in

162
00:07:22,694 --> 00:07:25,056
dynamic settings and adaptive autonomous

163
00:07:25,088 --> 00:07:27,472
agents, it might be a framework oriented

164
00:07:27,536 --> 00:07:29,824
around some sort of static or perennial

165
00:07:29,872 --> 00:07:31,924
understanding of the world. The second

166
00:07:31,962 --> 00:07:34,052
point. Rather than being centered around

167
00:07:34,106 --> 00:07:36,664
epistemic exploration and the value of

168
00:07:36,702 --> 00:07:38,564
reducing uncertainty and gaining

169
00:07:38,612 --> 00:07:40,564
information, hearing new perspectives,

170
00:07:40,692 --> 00:07:43,672
it could be oriented around pragmatic or

171
00:07:43,726 --> 00:07:46,436
utility value, which ties very closely

172
00:07:46,468 --> 00:07:49,724
to the third point, which is that a

173
00:07:49,762 --> 00:07:52,408
framework, contrary to active inference,

174
00:07:52,504 --> 00:07:55,672
might center a reward function that maps

175
00:07:55,736 --> 00:07:57,916
different states of the agent or the

176
00:07:57,938 --> 00:08:00,464
organization or the world to some sort

177
00:08:00,502 --> 00:08:03,296
of reward function which is the heart of

178
00:08:03,398 --> 00:08:06,508
reward learning. And then the fourth

179
00:08:06,604 --> 00:08:09,632
point also kind of ties in that rather

180
00:08:09,686 --> 00:08:12,156
than thinking about ecosystem of shared

181
00:08:12,188 --> 00:08:15,664
intelligence intermediated by composable

182
00:08:15,712 --> 00:08:17,396
frameworks like active inference, we

183
00:08:17,418 --> 00:08:19,108
might be looking for like the one

184
00:08:19,194 --> 00:08:22,100
framework to simply rule them all and

185
00:08:22,170 --> 00:08:24,020
therefore not think about the human

186
00:08:24,090 --> 00:08:26,952
machine or HumanHuman relationships as

187
00:08:27,006 --> 00:08:28,952
collaborative and emergent but rather

188
00:08:29,006 --> 00:08:30,920
just be looking for the one computer.

189
00:08:30,990 --> 00:08:32,168
We're just going to turn it on. The

190
00:08:32,174 --> 00:08:33,370
business is going to run.

191
00:08:40,370 --> 00:08:44,586
Awesome. So getting into active

192
00:08:44,618 --> 00:08:46,794
inference a little bit more, so we're

193
00:08:46,842 --> 00:08:48,686
kind of unpacking here. We're going to

194
00:08:48,708 --> 00:08:51,310
unpack slowly these, like, four claims.

195
00:08:51,890 --> 00:08:54,030
And so Prestonian,

196
00:08:54,630 --> 00:08:57,490
active inference or FEP powered active.

197
00:08:58,070 --> 00:09:00,194
So in active inference, there are four

198
00:09:00,232 --> 00:09:02,574
states. This is what Bijan claims active

199
00:09:02,622 --> 00:09:05,074
action, internal, firm resources,

200
00:09:05,202 --> 00:09:07,526
sensory perception and external, which

201
00:09:07,548 --> 00:09:09,906
is unknown and hidden behind the markup

202
00:09:09,938 --> 00:09:13,634
blanket. And Bijan quotes Friston

203
00:09:13,682 --> 00:09:16,326
here and says, in active inference, the

204
00:09:16,348 --> 00:09:18,882
agent makes choices based on its belief

205
00:09:19,026 --> 00:09:21,482
about state of the world and not based

206
00:09:21,536 --> 00:09:24,858
on the value of the states. And so that

207
00:09:24,944 --> 00:09:26,506
speaks to what Daniel was maybe just

208
00:09:26,528 --> 00:09:28,794
mentioning about reinforcement learning,

209
00:09:28,832 --> 00:09:31,466
and we'll start to unravel reinforcement

210
00:09:31,498 --> 00:09:33,054
learning a little bit more, but where

211
00:09:33,092 --> 00:09:35,198
reinforcement learning is really kind of

212
00:09:35,204 --> 00:09:37,760
driven by that pragmatic value function,

213
00:09:39,970 --> 00:09:42,546
active inference is driven by your

214
00:09:42,568 --> 00:09:45,618
beliefs about the world. So not how much

215
00:09:45,784 --> 00:09:48,898
value can you gain out of moving left or

216
00:09:48,984 --> 00:09:50,782
moving right? But I fundamentally

217
00:09:50,846 --> 00:09:54,062
believe that I should move right because

218
00:09:54,136 --> 00:09:57,586
that's my policy that I operate

219
00:09:57,618 --> 00:09:58,200
on.

220
00:10:01,130 --> 00:10:05,494
All right. And where

221
00:10:05,532 --> 00:10:07,466
these claims start to be unpacked in the

222
00:10:07,488 --> 00:10:11,494
paper, Bijan says, one could argue

223
00:10:11,542 --> 00:10:14,234
that nearly all physical sciences can be

224
00:10:14,272 --> 00:10:16,554
reduced to a metrology in service of

225
00:10:16,592 --> 00:10:18,618
confirming a variant of the principle of

226
00:10:18,624 --> 00:10:21,486
least action. This is important because

227
00:10:21,668 --> 00:10:24,174
it means that physics does not offer any

228
00:10:24,212 --> 00:10:26,094
ground truth. It is just search for

229
00:10:26,132 --> 00:10:27,966
measurements that endorse an

230
00:10:27,988 --> 00:10:29,946
appropriately formulated prediction

231
00:10:30,058 --> 00:10:32,878
based upon a variational principle. And

232
00:10:32,964 --> 00:10:35,518
this quotes a Friston 2019 paper. I

233
00:10:35,524 --> 00:10:36,738
don't know that paper off the top of my

234
00:10:36,744 --> 00:10:39,166
head, but as funny as I said, Bijan

235
00:10:39,198 --> 00:10:40,338
says, and then I started reading it,

236
00:10:40,344 --> 00:10:43,922
I'm like, no, Karl said this sounds

237
00:10:43,976 --> 00:10:45,766
very much like something that would come

238
00:10:45,788 --> 00:10:49,814
out of a Karl paper. Okay. And so

239
00:10:49,932 --> 00:10:52,434
what is this principle of least action?

240
00:10:52,482 --> 00:10:54,246
We've talked about this a lot before in

241
00:10:54,268 --> 00:10:57,174
many different livestreams, but I looked

242
00:10:57,212 --> 00:11:00,394
it up just for what is like a really

243
00:11:00,592 --> 00:11:03,306
easy, simple way that I could explain it

244
00:11:03,328 --> 00:11:06,154
in a minute or less. And I found this

245
00:11:06,192 --> 00:11:09,722
definition on scholar PDF that says

246
00:11:09,856 --> 00:11:11,830
a true dynamical trajectory of the

247
00:11:11,840 --> 00:11:13,790
system between an initial and final

248
00:11:13,860 --> 00:11:16,462
conversation in a specified time is

249
00:11:16,516 --> 00:11:18,286
found by imagining all possible

250
00:11:18,388 --> 00:11:20,174
trajectories that the system could

251
00:11:20,212 --> 00:11:22,762
conceivably take computing the action,

252
00:11:22,826 --> 00:11:24,634
which is a functional of the trajectory.

253
00:11:24,682 --> 00:11:26,546
And just as a reminder, a functional is

254
00:11:26,568 --> 00:11:28,834
like a function of a function. So

255
00:11:28,872 --> 00:11:30,498
computing the action a functional of the

256
00:11:30,504 --> 00:11:31,794
trajectory for each of these

257
00:11:31,832 --> 00:11:34,146
trajectories and selecting one that

258
00:11:34,168 --> 00:11:36,234
makes the action locally stationary,

259
00:11:36,302 --> 00:11:38,534
traditionally called least true

260
00:11:38,572 --> 00:11:40,246
trajectories are those that have the

261
00:11:40,268 --> 00:11:42,246
least action. And so this is like the

262
00:11:42,268 --> 00:11:44,390
Laziness. The lazy society. Everybody

263
00:11:44,460 --> 00:11:47,334
makes the lazy choice. Right? The true

264
00:11:47,372 --> 00:11:49,306
trajectory is the one where you kind of

265
00:11:49,328 --> 00:11:51,258
just stay put. Daniel, do you have a

266
00:11:51,264 --> 00:11:54,426
comment here? Yes, although on the

267
00:11:54,448 --> 00:11:56,042
previous slide, we looked at the

268
00:11:56,096 --> 00:11:58,730
particular partition where action states

269
00:11:58,800 --> 00:12:01,054
are the outgoing dependencies. And here

270
00:12:01,092 --> 00:12:03,082
we see action again with principle of

271
00:12:03,146 --> 00:12:05,950
least action action. But importantly,

272
00:12:06,370 --> 00:12:08,922
to abide by a principle of least action

273
00:12:08,986 --> 00:12:11,760
isn't simply to take the lowest energy

274
00:12:12,310 --> 00:12:15,010
action or the least movement. It's more

275
00:12:15,080 --> 00:12:17,986
akin to a conservation law. Like, the

276
00:12:18,008 --> 00:12:21,102
total energy is conserved of potential

277
00:12:21,166 --> 00:12:23,586
plus kinetic when the ball falls off the

278
00:12:23,608 --> 00:12:25,666
platform. So that means that there's a

279
00:12:25,688 --> 00:12:28,082
path of least action with the Bull

280
00:12:28,146 --> 00:12:31,474
dropping. Now, that is not the path

281
00:12:31,522 --> 00:12:34,326
of leased movement, but it's a path of

282
00:12:34,348 --> 00:12:36,766
least action given an individual setup

283
00:12:36,898 --> 00:12:39,238
because the total energy is conserved.

284
00:12:39,334 --> 00:12:41,594
And so we're interested in paths of

285
00:12:41,632 --> 00:12:44,794
least action over the particular

286
00:12:44,912 --> 00:12:47,734
partitioned states, internal, external,

287
00:12:47,782 --> 00:12:50,414
and blanket states. And so it's a little

288
00:12:50,452 --> 00:12:54,622
bit like, not just

289
00:12:54,676 --> 00:12:57,662
simply confusing, but least action can

290
00:12:57,716 --> 00:13:00,874
include the selection of very energetic

291
00:13:00,922 --> 00:13:02,770
or risky behaviors.

292
00:13:06,390 --> 00:13:08,434
That's cool and just kind of, like,

293
00:13:08,472 --> 00:13:11,586
maybe tie that to a real world example.

294
00:13:11,688 --> 00:13:14,002
I think about the principle of least

295
00:13:14,056 --> 00:13:17,182
action. I prefer my body temperature

296
00:13:17,246 --> 00:13:20,210
to be, like, 75 degrees all the time.

297
00:13:20,280 --> 00:13:23,640
Right? Do I live in the tropics? No,

298
00:13:24,410 --> 00:13:25,750
because there's, like, a lot of things

299
00:13:25,820 --> 00:13:28,058
about living on a tropical island that

300
00:13:28,064 --> 00:13:31,546
are not optimal for me. So I live in New

301
00:13:31,568 --> 00:13:34,620
Mexico because that's my optimal place.

302
00:13:35,070 --> 00:13:38,330
But I wear a jacket in the winter, and

303
00:13:38,400 --> 00:13:41,254
in the summertime, I wear less clothes

304
00:13:41,302 --> 00:13:42,826
or drive around in my air conditioned

305
00:13:42,858 --> 00:13:44,702
car. I live in my air conditioned house.

306
00:13:44,836 --> 00:13:46,874
So even though I'm still expending

307
00:13:46,922 --> 00:13:48,554
energy to maintain my physical

308
00:13:48,602 --> 00:13:51,198
temperature, that is the path of least

309
00:13:51,364 --> 00:13:55,118
action for me. I compensate

310
00:13:55,214 --> 00:13:58,420
for the change in my equilibrium state

311
00:13:59,270 --> 00:14:02,386
through my actions. Okay.

312
00:14:02,568 --> 00:14:06,130
And we will talk

313
00:14:06,200 --> 00:14:08,706
more about energy in a minute. So

314
00:14:08,808 --> 00:14:10,834
unpacking hae jeong Parr of the claim.

315
00:14:10,882 --> 00:14:13,890
The active agent carries out epistemic

316
00:14:13,970 --> 00:14:16,002
exploration to account for uncertainty

317
00:14:16,066 --> 00:14:18,694
by active coherence in Bay's optimal

318
00:14:18,742 --> 00:14:19,530
fashion.

319
00:14:21,550 --> 00:14:25,114
Okay, I know

320
00:14:25,152 --> 00:14:27,386
what Bayes optimal is, or I think I know

321
00:14:27,408 --> 00:14:30,154
what Bayes optimal is. But just to kind

322
00:14:30,192 --> 00:14:32,954
of like, what is Bayes optimal fashion,

323
00:14:33,002 --> 00:14:35,134
and how do you make coherence in

324
00:14:35,172 --> 00:14:37,006
Bayesian optimal fashion? And it's cool

325
00:14:37,028 --> 00:14:38,958
because in a quick Google search. I

326
00:14:38,964 --> 00:14:41,162
always like to search these fundamental

327
00:14:41,306 --> 00:14:44,222
things just to see kind of what pops up.

328
00:14:44,276 --> 00:14:45,934
I think I know what Bay's optimal is.

329
00:14:45,972 --> 00:14:49,234
And I pulled out this 2019 paper, like,

330
00:14:49,352 --> 00:14:52,766
what is optimal in optimal inference?

331
00:14:52,958 --> 00:14:54,674
And it's interesting because going

332
00:14:54,712 --> 00:14:56,486
Hinton Bayes optimal. I mean, I think

333
00:14:56,508 --> 00:14:58,530
about Bayes optimal as like minimizing

334
00:14:58,610 --> 00:15:00,902
prediction error. Or it says here

335
00:15:00,956 --> 00:15:02,866
classically optimal Bayesian inference

336
00:15:02,898 --> 00:15:05,074
balances prior knowledge and encoding

337
00:15:05,122 --> 00:15:07,754
observations to identify the model with

338
00:15:07,792 --> 00:15:09,930
maximum posterior probability.

339
00:15:11,470 --> 00:15:14,682
And so these authors actually take this

340
00:15:14,736 --> 00:15:16,742
a step further. And I really enjoyed

341
00:15:16,806 --> 00:15:20,254
their thought process here. So they

342
00:15:20,292 --> 00:15:22,046
said completely, we might say that an

343
00:15:22,068 --> 00:15:24,286
inference procedure is optimal if it

344
00:15:24,308 --> 00:15:26,638
maximizes benefit per unit cost, in

345
00:15:26,644 --> 00:15:28,890
which the benefit is some monotonically

346
00:15:28,970 --> 00:15:31,150
increasing function of accuracy.

347
00:15:32,230 --> 00:15:34,466
But they proposed a generalization of

348
00:15:34,488 --> 00:15:36,962
this approach that kind of splits this

349
00:15:37,016 --> 00:15:39,486
cost benefit curve into two components

350
00:15:39,598 --> 00:15:41,426
where the first component describes the

351
00:15:41,448 --> 00:15:44,306
benefit, perhaps the reward obtained as

352
00:15:44,328 --> 00:15:46,674
a function of accuracy. But then the

353
00:15:46,712 --> 00:15:48,086
second component, so that's the

354
00:15:48,108 --> 00:15:49,958
minimizing prediction error that I was

355
00:15:50,044 --> 00:15:52,134
speaking to earlier, right, in terms of

356
00:15:52,172 --> 00:15:54,482
accuracy. And then the second component

357
00:15:54,546 --> 00:15:56,374
describes accuracy as a function DA

358
00:15:56,412 --> 00:15:59,302
Costa, which can include time, memory

359
00:15:59,366 --> 00:16:01,466
and computational resources needed to

360
00:16:01,488 --> 00:16:02,906
process information. And I think that

361
00:16:02,928 --> 00:16:05,594
this is like a fundamental thing that I

362
00:16:05,632 --> 00:16:09,306
might overlook. I might be able to get a

363
00:16:09,328 --> 00:16:11,660
way more accuracy answer.

364
00:16:13,870 --> 00:16:16,602
Say, for example, what is the number

365
00:16:16,656 --> 00:16:19,198
pie? And I could just say like 3.14. I

366
00:16:19,204 --> 00:16:20,174
could actually go through, I could say

367
00:16:20,212 --> 00:16:22,638
like 3.14,159, like off the top of my

368
00:16:22,644 --> 00:16:25,018
head that's like whatever number of

369
00:16:25,044 --> 00:16:27,378
digits of pi that I have memorized to

370
00:16:27,464 --> 00:16:30,866
some accurate point. But I could come to

371
00:16:30,888 --> 00:16:33,346
a far more accuracy answer of that if I

372
00:16:33,368 --> 00:16:34,990
sat there with a pencil and a piece of

373
00:16:35,000 --> 00:16:37,286
paper for the entire rest of my life

374
00:16:37,468 --> 00:16:40,870
doing long division. So I could come to

375
00:16:40,940 --> 00:16:44,614
some infinite number of units past

376
00:16:44,652 --> 00:16:46,758
the decimal point and I could go on and

377
00:16:46,764 --> 00:16:49,820
on and on forever. But is it worth it?

378
00:16:50,430 --> 00:16:53,542
Is it worth it in terms of memory effort

379
00:16:53,606 --> 00:16:56,326
to calculate that increasing accuracy?

380
00:16:56,438 --> 00:16:59,500
Or is 3.14 good enough? Right.

381
00:16:59,870 --> 00:17:02,894
That is kind of the thing that the

382
00:17:02,932 --> 00:17:04,494
functions that they're describing here,

383
00:17:04,532 --> 00:17:06,874
like this benefit, this two dual

384
00:17:06,922 --> 00:17:08,874
component, like, yes, we want accuracy,

385
00:17:08,922 --> 00:17:12,206
but we also want it to be fast or want

386
00:17:12,228 --> 00:17:15,726
it to be we want to get the maximum

387
00:17:15,758 --> 00:17:17,742
benefit for the minimum resource

388
00:17:17,806 --> 00:17:21,060
expenditure. So I like that they are

389
00:17:21,430 --> 00:17:23,346
describing accuracy as a function of the

390
00:17:23,368 --> 00:17:26,278
Costa, the effort that goes into it. Do

391
00:17:26,284 --> 00:17:27,800
you guys have any comments here?

392
00:17:30,810 --> 00:17:34,566
Okay, why am I going into this?

393
00:17:34,588 --> 00:17:36,182
Okay, so Tyler and I got into this long

394
00:17:36,236 --> 00:17:40,102
talk about energy. And we

395
00:17:40,236 --> 00:17:43,366
got into I can't remember, I guess it's

396
00:17:43,398 --> 00:17:45,434
not maybe in this claim, but it was

397
00:17:45,472 --> 00:17:47,706
somewhere in the paper. Maybe I should

398
00:17:47,728 --> 00:17:49,226
look and try to pull it up. But we

399
00:17:49,248 --> 00:17:51,466
really got into discussing energy, like

400
00:17:51,568 --> 00:17:53,286
what is free energy? What is like

401
00:17:53,328 --> 00:17:57,086
kinetic and potential energy and

402
00:17:57,108 --> 00:18:00,382
what is free energy like in FEP? And

403
00:18:00,436 --> 00:18:02,638
we've gone to ActInf Livestream that

404
00:18:02,724 --> 00:18:06,174
dive way deeper into this. And I think

405
00:18:06,212 --> 00:18:08,546
it's live stream 17. That is the one I

406
00:18:08,568 --> 00:18:12,126
pointed you to, Tyler. Alex Kiefer

407
00:18:12,158 --> 00:18:15,058
does a great unpacking unraveling of

408
00:18:15,144 --> 00:18:17,586
free energy in that way. But I think

409
00:18:17,608 --> 00:18:19,862
it's important here to point out maybe,

410
00:18:19,916 --> 00:18:21,318
Tyler, you can pull that quote out of

411
00:18:21,324 --> 00:18:23,174
the paper while I'm talking about this,

412
00:18:23,212 --> 00:18:24,614
but I think it's important to point out

413
00:18:24,652 --> 00:18:27,450
that information theoretic entropy is

414
00:18:27,520 --> 00:18:30,822
different than thermodynamic

415
00:18:30,886 --> 00:18:34,330
entropy in information theory.

416
00:18:34,990 --> 00:18:36,522
And there are many times in the paper

417
00:18:36,576 --> 00:18:39,690
where the author specifically says,

418
00:18:39,760 --> 00:18:40,986
like, we're talking about information

419
00:18:41,088 --> 00:18:43,470
theoretic entropy. But then it seems

420
00:18:43,540 --> 00:18:46,094
like that the other kind of entropy is

421
00:18:46,132 --> 00:18:47,758
Hinton at. And so I kind of wanted to

422
00:18:47,764 --> 00:18:49,582
just like, draw a line between

423
00:18:49,716 --> 00:18:52,018
information theoretic entropy and the

424
00:18:52,024 --> 00:18:54,754
other kind of entropy, like the second

425
00:18:54,792 --> 00:18:56,046
law of thermodynamics entropy,

426
00:18:56,078 --> 00:18:59,378
thermodynamic entropy. And these two are

427
00:18:59,544 --> 00:19:02,882
distinct but not entirely unrelated. So

428
00:19:02,936 --> 00:19:06,254
information theoretic entropy is defined

429
00:19:06,302 --> 00:19:09,606
as like in if you have a function x or

430
00:19:09,628 --> 00:19:12,726
some event x, the negative log of the

431
00:19:12,748 --> 00:19:15,606
probability of x is equal to the

432
00:19:15,628 --> 00:19:17,226
information. So here you can see like,

433
00:19:17,248 --> 00:19:19,020
the probability versus the information

434
00:19:19,390 --> 00:19:23,354
is this graph on the left. So where

435
00:19:23,392 --> 00:19:25,706
there's a high probability of an event,

436
00:19:25,808 --> 00:19:29,178
there's like, low information. There's a

437
00:19:29,184 --> 00:19:32,398
high probability that I will take a

438
00:19:32,404 --> 00:19:35,934
breath in the next 30 seconds. So me

439
00:19:35,972 --> 00:19:37,802
taking a breath in the next 30 seconds

440
00:19:37,866 --> 00:19:41,246
doesn't contain any information, but you

441
00:19:41,268 --> 00:19:44,660
guys can predict that I will talk about

442
00:19:45,110 --> 00:19:48,386
the FEP and free energy governance in

443
00:19:48,408 --> 00:19:50,770
the next minute if I start talking about

444
00:19:50,840 --> 00:19:52,802
my dead dog. There's like low

445
00:19:52,856 --> 00:19:55,026
probability of that happening. And so

446
00:19:55,048 --> 00:19:56,466
there's maybe a much higher level of

447
00:19:56,488 --> 00:19:57,686
information, like, whoa, where did this

448
00:19:57,708 --> 00:19:58,886
come from? This is way out of left

449
00:19:58,908 --> 00:20:00,646
field. So there's more information in

450
00:20:00,668 --> 00:20:04,134
like, an unexpected claim. And so

451
00:20:04,172 --> 00:20:05,858
you can see like a probability

452
00:20:05,954 --> 00:20:08,186
distinctions versus entropy. But that

453
00:20:08,208 --> 00:20:11,100
relates like the Shannon entropy. Where

454
00:20:11,630 --> 00:20:15,546
the entropy? If there's a

455
00:20:15,568 --> 00:20:17,654
high probability, it's low entropy,

456
00:20:17,702 --> 00:20:21,542
right? So I look at this in a coin flip.

457
00:20:21,606 --> 00:20:23,482
So if we know that the coin is always

458
00:20:23,536 --> 00:20:25,694
going to come out heads, there's not any

459
00:20:25,732 --> 00:20:27,422
entropy in that. Like, say it's a two

460
00:20:27,476 --> 00:20:29,598
sided head coin, so it's always going to

461
00:20:29,604 --> 00:20:31,070
come out heads. There's no other option.

462
00:20:31,140 --> 00:20:33,182
The coin always flips heads. But where

463
00:20:33,236 --> 00:20:36,706
in a fair coin, it's 50 50, right? So at

464
00:20:36,728 --> 00:20:39,918
the right end of the second graph, it's

465
00:20:39,934 --> 00:20:42,514
a probability of 0.5.5, like half of

466
00:20:42,552 --> 00:20:44,386
probability that it's heads and half of

467
00:20:44,408 --> 00:20:46,838
a probability that it's tails. This has

468
00:20:46,924 --> 00:20:48,914
the highest entropy because it's random.

469
00:20:48,962 --> 00:20:50,694
Like we don't know what's going to come

470
00:20:50,732 --> 00:20:53,286
out. And so that is what is meant here

471
00:20:53,388 --> 00:20:57,334
by information theoretic entropy in

472
00:20:57,372 --> 00:21:00,250
contrast to thermodynamic entropy,

473
00:21:00,990 --> 00:21:02,826
where that is like what we think about

474
00:21:02,848 --> 00:21:04,298
when we think about physics and the

475
00:21:04,304 --> 00:21:06,854
Second law of thermodynamics entropy.

476
00:21:06,902 --> 00:21:08,218
We think entropy in the universe is

477
00:21:08,224 --> 00:21:10,586
always increasing. There's like a lot of

478
00:21:10,768 --> 00:21:12,758
disorder, the disorder in the Universe,

479
00:21:12,774 --> 00:21:14,846
like, if you clean your house and you go

480
00:21:14,868 --> 00:21:16,846
away for 20 years and you come back and

481
00:21:16,868 --> 00:21:18,718
your house is a mess, you're not going

482
00:21:18,724 --> 00:21:21,646
to be surprised at all, right? But if

483
00:21:21,668 --> 00:21:23,646
your house is a mess and you go away for

484
00:21:23,668 --> 00:21:25,938
20 years and you come back and your

485
00:21:25,944 --> 00:21:27,618
house is perfectly spotless, that would

486
00:21:27,624 --> 00:21:29,806
be weird, right? That's like you're

487
00:21:29,838 --> 00:21:30,898
scheduled for someone to come in and

488
00:21:30,904 --> 00:21:33,586
clean it. But the disorder in the

489
00:21:33,608 --> 00:21:36,546
universe is always increasing. And that

490
00:21:36,568 --> 00:21:38,310
is what it's meant by entropy in terms

491
00:21:38,380 --> 00:21:41,734
of the Second Law. And we also think

492
00:21:41,772 --> 00:21:43,878
about this kind of entropy as energy.

493
00:21:43,964 --> 00:21:45,462
This is where Tyler and I got into

494
00:21:45,516 --> 00:21:48,778
talking about energy. But entropy is

495
00:21:48,784 --> 00:21:50,794
the energy that is not available to do

496
00:21:50,832 --> 00:21:54,330
work. Right. In a system,

497
00:21:54,400 --> 00:21:56,602
there's like some amount of energy. I

498
00:21:56,736 --> 00:21:59,450
consume so many calories in a day, and

499
00:21:59,520 --> 00:22:01,434
this is like very simplified. But of

500
00:22:01,472 --> 00:22:04,382
those calories, I say I consume 2000

501
00:22:04,436 --> 00:22:06,574
calories in a day. I can use only like

502
00:22:06,612 --> 00:22:09,710
1500 of them for work because some

503
00:22:09,780 --> 00:22:12,286
energy is always lost in heat in the

504
00:22:12,308 --> 00:22:14,074
conversion. In any energy conversion

505
00:22:14,122 --> 00:22:15,794
process, like converting energy to work,

506
00:22:15,832 --> 00:22:17,346
you will always lose some energy as

507
00:22:17,368 --> 00:22:19,506
heat. And so that is kind of another way

508
00:22:19,528 --> 00:22:21,502
to think about this, thermodynamic

509
00:22:21,566 --> 00:22:24,066
entropy. Tyler, were you able to find

510
00:22:24,088 --> 00:22:25,586
that quote where we talked about this,

511
00:22:25,608 --> 00:22:28,994
or now? Yeah, the quote is fairly subtle

512
00:22:29,042 --> 00:22:31,000
and that he goes right between

513
00:22:32,730 --> 00:22:34,386
information theory and thermodynamic

514
00:22:34,418 --> 00:22:35,638
theory kind of seamlessly, and he

515
00:22:35,644 --> 00:22:37,126
doesn't make it clear that these are

516
00:22:37,148 --> 00:22:39,098
like two very different things, that

517
00:22:39,104 --> 00:22:40,806
there's a potential tenuous connection

518
00:22:40,838 --> 00:22:43,434
between. So he says, FEP hence has no

519
00:22:43,472 --> 00:22:46,346
purpose of its own. It powers the

520
00:22:46,368 --> 00:22:49,050
process of active active inference lab

521
00:22:49,120 --> 00:22:51,146
dedicated to minimizing the information

522
00:22:51,248 --> 00:22:52,862
theoretical maximum difference between

523
00:22:52,916 --> 00:22:54,602
the top down predictions and action

524
00:22:54,666 --> 00:22:56,618
generated bottom up stimuli in pursuit

525
00:22:56,634 --> 00:22:58,698
of minimizing errors of present entropy.

526
00:22:58,874 --> 00:23:00,350
Variational free energy and

527
00:23:00,420 --> 00:23:02,266
thermodynamic free energy are inversely

528
00:23:02,298 --> 00:23:04,046
related. If variational free energy is

529
00:23:04,068 --> 00:23:06,546
high, then thermodynamic entropy will be

530
00:23:06,568 --> 00:23:08,546
high, and thermodynamic free energy,

531
00:23:08,728 --> 00:23:09,954
the energy available for doing

532
00:23:09,992 --> 00:23:12,386
productive work will be low. So I think

533
00:23:12,408 --> 00:23:14,034
what he did there was a subtle he just

534
00:23:14,072 --> 00:23:16,094
goes between informational and

535
00:23:16,152 --> 00:23:18,502
thermodynamic free energy kind of

536
00:23:18,556 --> 00:23:20,358
interchangeably, and they were like,

537
00:23:20,364 --> 00:23:21,686
wait a minute, there's actually a

538
00:23:21,708 --> 00:23:23,330
difference between these two concepts,

539
00:23:23,410 --> 00:23:24,806
and the connection between them is

540
00:23:24,828 --> 00:23:27,238
something that the community doesn't

541
00:23:27,254 --> 00:23:29,500
have a great handle on. Ant this point.

542
00:23:30,030 --> 00:23:31,786
Very cool. Daniel, do you have any

543
00:23:31,808 --> 00:23:33,180
comments there on that?

544
00:23:35,390 --> 00:23:38,598
It's a pretty complex and developing

545
00:23:38,774 --> 00:23:42,126
area how the informational entropy is

546
00:23:42,148 --> 00:23:44,894
related to the actual physics and

547
00:23:44,932 --> 00:23:46,766
biology. It's kind of like the

548
00:23:46,788 --> 00:23:49,918
connection between Friston free energy

549
00:23:50,004 --> 00:23:52,806
and Gibbs free energy. How does reducing

550
00:23:52,858 --> 00:23:55,662
divergences on informational spaces

551
00:23:55,806 --> 00:23:57,506
translate to the amount of available

552
00:23:57,608 --> 00:23:59,842
energy? And there are situations where

553
00:23:59,896 --> 00:24:02,946
survival could be secured one way or the

554
00:24:02,968 --> 00:24:04,594
other. There just isn't, at this point,

555
00:24:04,632 --> 00:24:06,286
a general answer to how they're

556
00:24:06,318 --> 00:24:07,170
connected.

557
00:24:09,830 --> 00:24:12,018
So when Tyler asked me how they're

558
00:24:12,034 --> 00:24:14,742
connected, what is the relationship? My

559
00:24:14,796 --> 00:24:18,474
answer is Maxwell's Demon is the

560
00:24:18,512 --> 00:24:20,694
connection really between thermodynamic

561
00:24:20,742 --> 00:24:22,986
and informational free energy? And

562
00:24:23,008 --> 00:24:25,146
there's actually, I think, a 2018 or

563
00:24:25,168 --> 00:24:28,554
2019 paper that quantifies this

564
00:24:28,592 --> 00:24:30,634
relationship between thermodynamic and

565
00:24:30,672 --> 00:24:33,446
informational entropy at the quantum

566
00:24:33,478 --> 00:24:35,146
level. So I don't know if that applies

567
00:24:35,178 --> 00:24:37,230
to all scales, but it's at least cool

568
00:24:37,300 --> 00:24:38,734
that and I don't remember the paper

569
00:24:38,772 --> 00:24:40,746
offhand, but if you search it, maxwell

570
00:24:40,778 --> 00:24:42,594
Semen quantum information, you'll find

571
00:24:42,632 --> 00:24:45,166
it, and it's pretty recent. So it's neat

572
00:24:45,198 --> 00:24:47,838
that people are thinking about concrete

573
00:24:47,854 --> 00:24:50,946
and direct ways to transform and

574
00:24:50,968 --> 00:24:52,498
translate information theoretic and

575
00:24:52,504 --> 00:24:54,466
thermodynamic entropy. And so we just

576
00:24:54,488 --> 00:24:56,626
kind of wanted to unpack that because in

577
00:24:56,648 --> 00:24:58,598
that claim, it was like, whoa, there's a

578
00:24:58,604 --> 00:25:00,438
lot of things happening here that it

579
00:25:00,444 --> 00:25:02,486
might be more useful for the audience to

580
00:25:02,508 --> 00:25:06,006
have a deeper understanding of what

581
00:25:06,028 --> 00:25:07,910
is known and what is unknown. And how

582
00:25:07,980 --> 00:25:09,880
deep does this rabbit hole really go?

583
00:25:10,590 --> 00:25:13,050
So it gets pretty hairy.

584
00:25:14,910 --> 00:25:17,386
Okay, cool. All right, so back to

585
00:25:17,408 --> 00:25:18,906
reality, but back to things that we can

586
00:25:18,928 --> 00:25:21,274
concretely talk about. So, the reward

587
00:25:21,322 --> 00:25:22,766
signal, so characteristic of

588
00:25:22,788 --> 00:25:24,574
reinforcement learning, is removed and

589
00:25:24,612 --> 00:25:26,634
replaced with one sole purpose surprise

590
00:25:26,682 --> 00:25:29,406
minimization. Effectively, the agent is

591
00:25:29,428 --> 00:25:31,598
empowered to minimize surprise by way of

592
00:25:31,604 --> 00:25:33,182
a generative model of the partially

593
00:25:33,246 --> 00:25:35,954
observable world only perceiving itself

594
00:25:36,072 --> 00:25:40,034
and the world via outcomes. And so just

595
00:25:40,072 --> 00:25:42,670
for people who might not be familiar

596
00:25:42,750 --> 00:25:45,766
with reinforcement learning hold on just

597
00:25:45,788 --> 00:25:46,680
a second. Sorry.

598
00:25:49,690 --> 00:25:51,318
Getting over a sickness sometimes. I

599
00:25:51,324 --> 00:25:52,038
didn't want to cough up to the

600
00:25:52,044 --> 00:25:54,054
microphone. All right, so in

601
00:25:54,092 --> 00:25:55,654
reinforcement learning, there's, like,

602
00:25:55,692 --> 00:25:58,266
a couple required components. So you

603
00:25:58,288 --> 00:26:01,738
have a policy which maps the state of

604
00:26:01,744 --> 00:26:04,554
the environment to an action, and

605
00:26:04,592 --> 00:26:06,362
that's, like, for an agent, right? So

606
00:26:06,496 --> 00:26:08,874
we're always talking about agent here.

607
00:26:08,912 --> 00:26:11,110
So an agent has a policy. Like, if the

608
00:26:11,120 --> 00:26:12,846
environment is in this state, I will

609
00:26:12,868 --> 00:26:14,686
take this action, and policies can

610
00:26:14,708 --> 00:26:17,006
change and update. And then there's a

611
00:26:17,028 --> 00:26:20,878
reward signal, which is given at each

612
00:26:20,964 --> 00:26:22,286
step. So we're talking about, like, a

613
00:26:22,308 --> 00:26:25,650
time step type of thing. Second one, I

614
00:26:25,720 --> 00:26:28,514
take this action. My reward is two

615
00:26:28,552 --> 00:26:30,866
carats, right? So say my policy is to

616
00:26:30,888 --> 00:26:33,182
turn right unless I see immediate danger

617
00:26:33,246 --> 00:26:36,706
on my left. So I turn right, and I turn

618
00:26:36,728 --> 00:26:38,434
right, and I get two carats. I turn

619
00:26:38,472 --> 00:26:40,166
left, and I can't turn left because

620
00:26:40,188 --> 00:26:41,378
there's a media danger over there. It's

621
00:26:41,394 --> 00:26:44,038
against my policy, whatever. So the

622
00:26:44,044 --> 00:26:45,794
reward signal is the number of carrots

623
00:26:45,842 --> 00:26:48,522
that I received right there at that

624
00:26:48,576 --> 00:26:50,490
first step. And then there's a value

625
00:26:50,560 --> 00:26:52,714
function which actually tracks the

626
00:26:52,752 --> 00:26:56,374
reward over time. And the objective

627
00:26:56,422 --> 00:26:58,234
in reinforcement learning is not to

628
00:26:58,272 --> 00:27:00,910
maximize the reward signal at each

629
00:27:00,980 --> 00:27:03,950
instance, but it's to maximize the value

630
00:27:04,020 --> 00:27:06,238
function over time. And so in a

631
00:27:06,244 --> 00:27:09,086
circumstance where I turn right to get

632
00:27:09,108 --> 00:27:12,640
two carats, but I could have gone

633
00:27:13,010 --> 00:27:15,822
down and then right and gotten 50

634
00:27:15,876 --> 00:27:17,886
carats. So maybe I should have gone down

635
00:27:17,908 --> 00:27:20,354
and right. And so this is kind of how an

636
00:27:20,392 --> 00:27:22,174
agent will learn in a reinforcement

637
00:27:22,222 --> 00:27:25,506
learning environment to maximize the

638
00:27:25,528 --> 00:27:27,098
value as opposed to just maximizing

639
00:27:27,134 --> 00:27:30,054
incrementally the reward. So after every

640
00:27:30,092 --> 00:27:31,506
action the agent takes, the environment

641
00:27:31,538 --> 00:27:32,806
sends a single number. That's the

642
00:27:32,828 --> 00:27:34,614
reward. The reward that the agent

643
00:27:34,652 --> 00:27:36,466
receives depends on the agent's action

644
00:27:36,498 --> 00:27:38,454
and the state. And so the agent's only

645
00:27:38,492 --> 00:27:40,158
goal is to maximize the total reward,

646
00:27:40,194 --> 00:27:42,186
which is the value function over the

647
00:27:42,208 --> 00:27:44,860
long term. Any comments here?

648
00:27:48,270 --> 00:27:52,986
All right, so precision tyler,

649
00:27:53,018 --> 00:27:54,206
do you want to read the quote at the top

650
00:27:54,228 --> 00:27:57,262
of this? Sure. So the Beijing brand has

651
00:27:57,316 --> 00:27:59,774
optimized not its expectations. It also

652
00:27:59,812 --> 00:28:01,854
has to optimize precision. This means

653
00:28:01,892 --> 00:28:03,166
that one has to predict how much

654
00:28:03,188 --> 00:28:04,526
precision is affordance to various

655
00:28:04,558 --> 00:28:06,866
sources of sensory evidence relative to

656
00:28:06,888 --> 00:28:10,290
prior beliefs. Thank you.

657
00:28:10,440 --> 00:28:12,450
And so this is like a definition from

658
00:28:12,520 --> 00:28:15,922
Wikipedia talking about like classifier

659
00:28:15,986 --> 00:28:18,806
systems and precision and recall in a

660
00:28:18,828 --> 00:28:21,158
classifier system, which is like a

661
00:28:21,164 --> 00:28:23,026
predictive system, or it can be Bayesian

662
00:28:23,058 --> 00:28:27,234
classification. So there are retrieved

663
00:28:27,282 --> 00:28:30,266
items. So we're going to say of this

664
00:28:30,288 --> 00:28:32,294
field of images, the ones in the circle

665
00:28:32,342 --> 00:28:34,454
are cats. Right. So we're identifying

666
00:28:34,502 --> 00:28:37,674
these circles, the data points within

667
00:28:37,792 --> 00:28:40,042
the larger circle as all these things

668
00:28:40,096 --> 00:28:41,934
that the classifier says, these are all

669
00:28:41,972 --> 00:28:44,926
cats. The precision is of all of the

670
00:28:44,948 --> 00:28:46,926
things that the classifier says are

671
00:28:46,948 --> 00:28:49,774
cats, how many are actually cats? So

672
00:28:49,812 --> 00:28:54,066
it's the true positives that are in

673
00:28:54,088 --> 00:28:56,050
the system. And then the recall is like

674
00:28:56,120 --> 00:28:59,246
how many total how many relevant items

675
00:28:59,278 --> 00:29:01,854
are returned. So that's the precision

676
00:29:01,902 --> 00:29:05,570
here that's referenced by Frustrated.

677
00:29:07,350 --> 00:29:08,686
Do you want to read this one toothbrush,

678
00:29:08,718 --> 00:29:11,406
Tyler? Sure. All right. So when dynamics

679
00:29:11,438 --> 00:29:13,090
change, sailings should be prevented

680
00:29:13,170 --> 00:29:14,918
from potentially increasing free energy.

681
00:29:15,004 --> 00:29:16,562
In the context of corporate governance,

682
00:29:16,626 --> 00:29:18,479
1 may think of pattern recognition as a

683
00:29:18,979 --> 00:29:20,406
one form of salience. The more senior

684
00:29:20,438 --> 00:29:22,186
and experienced board members are, the

685
00:29:22,208 --> 00:29:23,766
more likely and they feel comfortable

686
00:29:23,798 --> 00:29:25,606
with mental shortcuts such as pattern

687
00:29:25,638 --> 00:29:26,886
recognition built through prior

688
00:29:26,918 --> 00:29:27,500
experience.

689
00:29:31,390 --> 00:29:33,306
When I search for salience, I just

690
00:29:33,328 --> 00:29:35,434
randomly search for pictures of salience

691
00:29:35,482 --> 00:29:37,866
to make this pretty red apple picture

692
00:29:37,898 --> 00:29:40,826
appear here. But when I searched

693
00:29:40,858 --> 00:29:43,266
salience and I looked at images, a lot

694
00:29:43,288 --> 00:29:46,318
of them were like stakeholder salience.

695
00:29:46,414 --> 00:29:49,346
And so I couldn't even start to try to

696
00:29:49,368 --> 00:29:52,190
unpack this. Like it was some corporate

697
00:29:52,350 --> 00:29:54,194
definition of salience and some

698
00:29:54,232 --> 00:29:56,066
corporate model of salience that I don't

699
00:29:56,098 --> 00:29:59,894
know if Bijan is referring here to more

700
00:29:59,932 --> 00:30:01,334
indirectly, or Tyler, if you know

701
00:30:01,372 --> 00:30:04,482
anything about the stakeholders salience

702
00:30:04,546 --> 00:30:06,710
model, but maybe we could ask Bijan if

703
00:30:06,780 --> 00:30:10,246
he is referencing that or if he's just

704
00:30:10,268 --> 00:30:12,054
talking about salience the way that we

705
00:30:12,172 --> 00:30:14,362
talk about it. As in things that we

706
00:30:14,416 --> 00:30:16,278
attune our attention to because they're

707
00:30:16,294 --> 00:30:18,106
relevant for the task at hand. Or like

708
00:30:18,128 --> 00:30:19,466
things that stick out or things that are

709
00:30:19,488 --> 00:30:21,626
memorable or relevant. Right, yeah, I

710
00:30:21,648 --> 00:30:22,566
don't think there's like a corporate

711
00:30:22,598 --> 00:30:24,006
governance, like, technical definition

712
00:30:24,038 --> 00:30:25,566
force. It I think it's just like you

713
00:30:25,588 --> 00:30:27,870
have limited attention. There are things

714
00:30:27,940 --> 00:30:29,710
that the portal is more likely to focus

715
00:30:29,780 --> 00:30:31,086
on and they have to constrain their

716
00:30:31,108 --> 00:30:34,094
attention on limited information. Yeah,

717
00:30:34,132 --> 00:30:35,586
but I was intrigued by the fact that

718
00:30:35,608 --> 00:30:37,150
there is like a corporate salience

719
00:30:37,230 --> 00:30:39,394
model. Like oh, it's beyond talking

720
00:30:39,432 --> 00:30:41,380
about corporate salience. What's that?

721
00:30:41,910 --> 00:30:43,838
Because it's just something that I've

722
00:30:43,854 --> 00:30:46,338
never heard of before. Well, it's

723
00:30:46,354 --> 00:30:47,906
something we've seen with many active

724
00:30:47,938 --> 00:30:50,646
coherence ontology terms, that there's a

725
00:30:50,668 --> 00:30:53,510
broad everyday qualitative sense,

726
00:30:53,660 --> 00:30:55,286
like salience is something that you pay

727
00:30:55,308 --> 00:30:57,386
attention to. And then there's also a

728
00:30:57,408 --> 00:30:59,770
more technical, usually Bayesian sense

729
00:30:59,840 --> 00:31:02,726
such as salience is actually referring

730
00:31:02,758 --> 00:31:05,254
to the precision in terms of a variance

731
00:31:05,302 --> 00:31:07,606
estimator that we place on incoming

732
00:31:07,638 --> 00:31:10,746
sensory data. Whereas low attention

733
00:31:10,938 --> 00:31:13,262
means that data points coming in are not

734
00:31:13,316 --> 00:31:15,246
salient. They're not used to update the

735
00:31:15,268 --> 00:31:18,910
model. High attention is coming

736
00:31:18,980 --> 00:31:21,658
together with high attention to incoming

737
00:31:21,674 --> 00:31:24,810
data that does update the prior

738
00:31:24,890 --> 00:31:27,970
a lot into the posterior. And so which

739
00:31:28,040 --> 00:31:31,522
patterns are salient is

740
00:31:31,576 --> 00:31:34,334
itself learnt. And we can think about

741
00:31:34,392 --> 00:31:36,486
that as the regime of attention with all

742
00:31:36,508 --> 00:31:37,974
the strengths and weaknesses, the

743
00:31:38,012 --> 00:31:39,622
expertise and heuristics bring along

744
00:31:39,676 --> 00:31:40,280
with.

745
00:31:45,850 --> 00:31:49,734
Yeah, and I think they go on

746
00:31:49,772 --> 00:31:53,434
to say, I think gen impacts that more

747
00:31:53,472 --> 00:31:55,846
in the book about salience and pattern

748
00:31:55,878 --> 00:31:56,730
recognition.

749
00:31:59,310 --> 00:32:02,666
Okay, so single and double loop

750
00:32:02,698 --> 00:32:03,774
learning. Tyler, do you want to take

751
00:32:03,812 --> 00:32:06,926
that? Single loop learning occurs when

752
00:32:06,948 --> 00:32:08,586
errors are detected and corrected

753
00:32:08,618 --> 00:32:10,238
without altering the governing values of

754
00:32:10,244 --> 00:32:12,142
the master program. Double loop learning

755
00:32:12,196 --> 00:32:14,594
occurs when Northern Dalton and error is

756
00:32:14,632 --> 00:32:16,366
necessary to alter the governing values

757
00:32:16,398 --> 00:32:18,654
of the master programs. Most governance

758
00:32:18,702 --> 00:32:20,686
models are at best, single loop, rule

759
00:32:20,718 --> 00:32:22,786
based learning systems that struggle to

760
00:32:22,808 --> 00:32:24,340
activate double loop learning.

761
00:32:28,710 --> 00:32:31,860
Thank you. And I found this little

762
00:32:32,970 --> 00:32:36,134
loop, this loop diagram, which is like

763
00:32:36,252 --> 00:32:38,006
actions and consequences. Actions and

764
00:32:38,028 --> 00:32:39,786
consequences. And that's like the single

765
00:32:39,888 --> 00:32:43,642
loop. But this double loop learning goes

766
00:32:43,696 --> 00:32:46,294
into understanding governing variables.

767
00:32:46,342 --> 00:32:48,826
And this is kind of like, I think about

768
00:32:49,008 --> 00:32:52,140
some kind of meta analysis where you can

769
00:32:52,770 --> 00:32:54,666
zoomed out more in the double loop

770
00:32:54,698 --> 00:32:57,434
learning. Yeah, with our favorite

771
00:32:57,482 --> 00:33:00,400
example of the temperature in the room,

772
00:33:00,770 --> 00:33:03,326
if the single loop is just the knob that

773
00:33:03,348 --> 00:33:05,006
we're controlling on the heater or the

774
00:33:05,028 --> 00:33:07,806
air conditioning, the double loop would

775
00:33:07,828 --> 00:33:09,522
be taking a step back and thinking,

776
00:33:09,576 --> 00:33:11,746
well, could we also open or close a

777
00:33:11,768 --> 00:33:14,034
window? And so if we only stay within

778
00:33:14,072 --> 00:33:15,746
the single loop, maybe our heater or

779
00:33:15,768 --> 00:33:18,550
cooler has limited capacity. And so

780
00:33:18,620 --> 00:33:21,682
there's times where the environmental

781
00:33:21,826 --> 00:33:25,286
challenges are going to take us outside

782
00:33:25,388 --> 00:33:27,286
of the range of what can be learned or

783
00:33:27,308 --> 00:33:29,546
accommodated with a single loop. And

784
00:33:29,568 --> 00:33:31,562
it's those times, especially when

785
00:33:31,696 --> 00:33:34,746
opening up into a double loop space or

786
00:33:34,768 --> 00:33:37,354
like a hyper prior space is what is

787
00:33:37,392 --> 00:33:40,374
actually required to get the generative

788
00:33:40,422 --> 00:33:42,426
model operating in a way that's

789
00:33:42,458 --> 00:33:43,390
survivable.

790
00:33:45,730 --> 00:33:47,358
I would never open the window with the

791
00:33:47,364 --> 00:33:48,846
heater on, but boy, I changed the

792
00:33:48,868 --> 00:33:50,366
weather shipping on my back door this

793
00:33:50,388 --> 00:33:52,686
year and it. Made such a difference. So

794
00:33:52,708 --> 00:33:56,366
that's a more realistic like a governing

795
00:33:56,398 --> 00:33:58,114
variable like you have a leaky house or

796
00:33:58,152 --> 00:34:00,100
poor insulation or something like that.

797
00:34:02,150 --> 00:34:06,254
All right, deliberate ignorance.

798
00:34:06,382 --> 00:34:08,920
So that is choosing not to know.

799
00:34:09,450 --> 00:34:12,326
So Bijan talks about this and says the

800
00:34:12,348 --> 00:34:14,134
more senior and experienced board

801
00:34:14,172 --> 00:34:16,374
members are the more likely that they

802
00:34:16,412 --> 00:34:18,274
feel comfortable with mental shortcuts

803
00:34:18,322 --> 00:34:19,814
such as pattern recognition built

804
00:34:19,852 --> 00:34:21,498
through prior experience. That's what I

805
00:34:21,504 --> 00:34:23,034
was going to say earlier about this.

806
00:34:23,152 --> 00:34:24,646
Again, I thought it was this next slide

807
00:34:24,678 --> 00:34:28,566
but when they talked about here pattern

808
00:34:28,598 --> 00:34:32,266
recognition as one form of salient but

809
00:34:32,288 --> 00:34:35,966
in this deliberate ignorance it says it

810
00:34:35,988 --> 00:34:38,590
is a form of prior based heuristic or

811
00:34:38,740 --> 00:34:40,906
too often simply deliberate ignorance.

812
00:34:41,018 --> 00:34:44,286
However, in a discontinuously non repeat

813
00:34:44,318 --> 00:34:46,126
game environment, pattern recognition

814
00:34:46,238 --> 00:34:48,114
without maintaining sensitivity for

815
00:34:48,152 --> 00:34:50,382
small but nonetheless transformative

816
00:34:50,446 --> 00:34:52,734
variations put survival at risk.

817
00:34:52,862 --> 00:34:54,818
Therefore we need a process and a

818
00:34:54,824 --> 00:34:56,386
measure of errors that optimizes

819
00:34:56,418 --> 00:34:59,014
survival. Hence action, centric free

820
00:34:59,052 --> 00:35:01,474
energy, minimization powering, inactive

821
00:35:01,522 --> 00:35:04,102
AI. And so I thought about this like

822
00:35:04,156 --> 00:35:06,098
okay, we're talking about corporate

823
00:35:06,194 --> 00:35:08,802
strategies. So in pattern recognition

824
00:35:08,866 --> 00:35:10,710
that's super useful force something like

825
00:35:10,780 --> 00:35:13,866
a game of chess. Chess has like

826
00:35:13,968 --> 00:35:15,546
these are the pieces, these are the

827
00:35:15,568 --> 00:35:18,618
rules. There's only so many ways that a

828
00:35:18,624 --> 00:35:19,994
piece can move and yes, super

829
00:35:20,032 --> 00:35:22,394
complicated. But over time a master

830
00:35:22,442 --> 00:35:24,122
chess player can start to recognize

831
00:35:24,186 --> 00:35:27,102
patterns in the game or like certain

832
00:35:27,236 --> 00:35:30,000
sequences of moves that result in

833
00:35:31,090 --> 00:35:33,534
success. And so if you know those

834
00:35:33,572 --> 00:35:35,374
sequences of moves that result in

835
00:35:35,412 --> 00:35:37,390
success, that's pattern recognition.

836
00:35:37,890 --> 00:35:40,738
But in a non repeat game like where the

837
00:35:40,744 --> 00:35:42,366
rules are always changing and the pieces

838
00:35:42,398 --> 00:35:44,206
can move in a different way like imagine

839
00:35:44,238 --> 00:35:47,026
now we're playing 4D chess where we

840
00:35:47,048 --> 00:35:49,094
could go also like XY but we can also

841
00:35:49,132 --> 00:35:50,582
move in the z direction, jump over

842
00:35:50,636 --> 00:35:52,486
pieces and so forth. Like if you add an

843
00:35:52,508 --> 00:35:55,890
extra dimension, those prior

844
00:35:56,050 --> 00:35:59,414
patterns that you knew for XY chess

845
00:35:59,542 --> 00:36:02,426
now doesn't happen, right? They don't

846
00:36:02,448 --> 00:36:04,154
even apply or aren't even relevant here.

847
00:36:04,192 --> 00:36:07,510
So failing to update your prior

848
00:36:07,590 --> 00:36:10,026
pattern cognition is going to not lead

849
00:36:10,048 --> 00:36:13,034
to successful strategies. Just to make

850
00:36:13,072 --> 00:36:16,042
this a little bit more concept. A very

851
00:36:16,096 --> 00:36:17,178
common example of this that I've

852
00:36:17,194 --> 00:36:19,178
emergence is that sometimes when you're

853
00:36:19,194 --> 00:36:20,974
doing business strategy and the business

854
00:36:21,012 --> 00:36:22,126
is still running and you might have

855
00:36:22,148 --> 00:36:24,286
customer service claims incoming while

856
00:36:24,308 --> 00:36:25,902
you're doing this core business

857
00:36:25,956 --> 00:36:27,966
strategy, generally you want to ignore

858
00:36:27,998 --> 00:36:29,678
all these customer service claims

859
00:36:29,694 --> 00:36:31,058
because that's just like noise and you

860
00:36:31,064 --> 00:36:32,638
don't want to pay attention to it. It's

861
00:36:32,654 --> 00:36:34,594
going to overwhelm you though

862
00:36:34,632 --> 00:36:36,254
occasionally you'll sometimes hear some

863
00:36:36,312 --> 00:36:39,590
very unusual customer experience claims

864
00:36:40,570 --> 00:36:42,214
that kind of implies something much

865
00:36:42,252 --> 00:36:44,694
bigger and much more serious is going

866
00:36:44,732 --> 00:36:45,766
on. System will be within the

867
00:36:45,788 --> 00:36:47,686
organization and you need to have this

868
00:36:47,708 --> 00:36:49,046
like spidey sense and this is where

869
00:36:49,068 --> 00:36:50,386
there's often used in business settings

870
00:36:50,418 --> 00:36:51,734
like the Spidey sense of knowing like oh

871
00:36:51,772 --> 00:36:54,058
wait, something bigger is going on. I

872
00:36:54,064 --> 00:36:56,250
need to switch gears into being super

873
00:36:56,320 --> 00:36:59,418
micro rather than being macro. So I

874
00:36:59,424 --> 00:37:00,666
think it's a good example of when you

875
00:37:00,688 --> 00:37:02,798
have to kind of switch your model of how

876
00:37:02,804 --> 00:37:04,174
the organization is working really

877
00:37:04,212 --> 00:37:06,842
dynamically and go from deliberate

878
00:37:06,906 --> 00:37:08,494
ignorance to choosing what information

879
00:37:08,612 --> 00:37:10,160
will be selling to you.

880
00:37:13,270 --> 00:37:17,598
Conor okay, and then sophistication

881
00:37:17,774 --> 00:37:19,618
which I thought this was relevant, I

882
00:37:19,624 --> 00:37:22,386
can't remember the quote that said this

883
00:37:22,408 --> 00:37:25,646
again. Bijan actually started to unpack

884
00:37:25,678 --> 00:37:28,118
this in figure four. And he said we

885
00:37:28,124 --> 00:37:30,006
alluded to. Sophistication back in

886
00:37:30,028 --> 00:37:32,966
chapter one. And this also applies to

887
00:37:32,988 --> 00:37:34,470
this like double loop learning.

888
00:37:34,540 --> 00:37:36,646
Sophisticated inference is where you

889
00:37:36,668 --> 00:37:40,374
have many tangential steps that

890
00:37:40,412 --> 00:37:44,010
can unfold. And this also

891
00:37:44,080 --> 00:37:45,274
applies to the principle of least

892
00:37:45,312 --> 00:37:46,346
action, which we're talking about,

893
00:37:46,368 --> 00:37:48,058
which is like a decision tree search.

894
00:37:48,224 --> 00:37:50,314
Like if you're standing here at step

895
00:37:50,352 --> 00:37:52,714
one, you can go which is like the top

896
00:37:52,752 --> 00:37:54,830
level here. You can go to any of these

897
00:37:54,900 --> 00:37:57,614
four points. You one u, two u, three,

898
00:37:57,652 --> 00:38:00,654
you four. So if you're here at the very

899
00:38:00,692 --> 00:38:02,286
beginning step and then each one of

900
00:38:02,308 --> 00:38:04,202
these points have their own branch

901
00:38:04,266 --> 00:38:06,254
choices that you can make. And then each

902
00:38:06,292 --> 00:38:07,874
one of those choices have their own

903
00:38:07,912 --> 00:38:10,834
choices. And so this is the

904
00:38:10,872 --> 00:38:12,386
sophisticated inference which is

905
00:38:12,408 --> 00:38:15,054
unpacked in this paper, sophisticated

906
00:38:15,102 --> 00:38:16,406
inference. And then we've done on

907
00:38:16,428 --> 00:38:18,582
different live streams here before.

908
00:38:18,636 --> 00:38:20,006
Also, we didn't do this paper, but we

909
00:38:20,028 --> 00:38:23,170
did deep effective inference.

910
00:38:23,330 --> 00:38:26,646
I think that was maybe also 1713. I

911
00:38:26,668 --> 00:38:29,638
can't remember, but a long time ago it

912
00:38:29,644 --> 00:38:31,974
was like a 2020 early Livestream with

913
00:38:32,012 --> 00:38:34,406
Dayan. Smith so in this sophisticated

914
00:38:34,518 --> 00:38:37,254
model, it's unfolding temporarily

915
00:38:37,302 --> 00:38:39,082
through time. And this applies to both

916
00:38:39,136 --> 00:38:40,746
like the trajectory when we're talking

917
00:38:40,768 --> 00:38:43,002
about least action trajectories and also

918
00:38:43,056 --> 00:38:44,358
to double loop learning where you're

919
00:38:44,374 --> 00:38:45,834
looking at like maybe governing

920
00:38:45,882 --> 00:38:47,840
variables over time.

921
00:38:48,930 --> 00:38:51,662
So he starts to unpack that here in this

922
00:38:51,716 --> 00:38:53,326
chapter. Goes a little bit more into it

923
00:38:53,348 --> 00:38:56,978
than in chapter one. All right,

924
00:38:57,064 --> 00:38:59,314
so now we're on the fourth part of this

925
00:38:59,352 --> 00:39:02,194
claim. We made it all the way to them.

926
00:39:02,392 --> 00:39:04,226
Active inference should provide the

927
00:39:04,248 --> 00:39:06,346
basis to set free the collaborative

928
00:39:06,478 --> 00:39:09,122
human machine artificial intelligence

929
00:39:09,186 --> 00:39:11,746
potential so integral to the multi

930
00:39:11,778 --> 00:39:14,822
intelligence firm. And note those two

931
00:39:14,876 --> 00:39:18,630
separate like AI abbreviations.

932
00:39:20,090 --> 00:39:23,786
So Bijan makes a claim social Fields are

933
00:39:23,808 --> 00:39:25,974
not as real time as electrically charged

934
00:39:26,022 --> 00:39:27,654
and chemically powered, neural

935
00:39:27,702 --> 00:39:30,054
responsiveness. But the underlying logic

936
00:39:30,102 --> 00:39:32,074
and principles nonetheless determines

937
00:39:32,122 --> 00:39:34,382
firm performance and survival. All

938
00:39:34,436 --> 00:39:36,686
living self organizing systems, as is

939
00:39:36,708 --> 00:39:39,354
true for organizations, strive to reduce

940
00:39:39,402 --> 00:39:41,066
entropy in pursuit of minimizing

941
00:39:41,098 --> 00:39:43,726
surprise. But organizations other than

942
00:39:43,748 --> 00:39:46,066
living systems are too often trapped in

943
00:39:46,088 --> 00:39:49,166
what anger is 1995 termed skilled

944
00:39:49,198 --> 00:39:51,486
incompetence, meaning that organizations

945
00:39:51,518 --> 00:39:53,266
are programmed to deal with error and

946
00:39:53,288 --> 00:39:54,338
threat in ways that are

947
00:39:54,344 --> 00:39:55,474
counterproductive to their own

948
00:39:55,512 --> 00:39:57,422
intentions, not least because

949
00:39:57,496 --> 00:39:59,602
organizations struggle with unlearning

950
00:39:59,666 --> 00:40:02,470
and deliberately suppress subtlety.

951
00:40:03,050 --> 00:40:05,266
Maybe refers back to that deliberate

952
00:40:05,298 --> 00:40:08,230
ignorance that we talked about earlier.

953
00:40:08,810 --> 00:40:10,534
Do you want to talk here, Tyler, about

954
00:40:10,572 --> 00:40:13,558
organizational becoming? Yeah, sure. So

955
00:40:13,644 --> 00:40:15,194
just on that last slide, I got a couple

956
00:40:15,232 --> 00:40:17,738
of thoughts on that one part that was

957
00:40:17,744 --> 00:40:19,420
interesting. About this was like

958
00:40:19,870 --> 00:40:22,426
explicitly connecting free energy to the

959
00:40:22,448 --> 00:40:24,026
firm, which I guess that's the whole

960
00:40:24,048 --> 00:40:25,226
point of this book. But I think that's

961
00:40:25,258 --> 00:40:28,046
actually quite a large claim to say that

962
00:40:28,148 --> 00:40:31,358
firms also exhibit free energy. So I

963
00:40:31,364 --> 00:40:32,414
just want to point that out. But then

964
00:40:32,452 --> 00:40:34,714
also I think a really important aspect

965
00:40:34,762 --> 00:40:36,874
of free Energy governance is the DAG

966
00:40:36,922 --> 00:40:40,086
between stimuli and action and action

967
00:40:40,138 --> 00:40:42,994
stimuli where that is a lot larger in an

968
00:40:43,032 --> 00:40:44,466
organizational space rather than

969
00:40:44,488 --> 00:40:46,066
something kind of like a neuron, for

970
00:40:46,088 --> 00:40:48,406
example. And that makes, I think a lot

971
00:40:48,588 --> 00:40:50,614
harder to operationalize and really

972
00:40:50,652 --> 00:40:52,306
understand free energy in like a firm

973
00:40:52,338 --> 00:40:53,560
context as well.

974
00:40:55,130 --> 00:40:57,382
So the next slide that goes into

975
00:40:57,436 --> 00:40:59,746
organizational becoming, this is a term

976
00:40:59,778 --> 00:41:02,810
he doesn't really define explicitly

977
00:41:03,630 --> 00:41:05,754
throughout the book, but he does mention

978
00:41:05,792 --> 00:41:08,058
it quite a number of times, so I think

979
00:41:08,064 --> 00:41:09,594
it's worth calling out. So he says

980
00:41:09,632 --> 00:41:11,618
strategic renewal is as organizational

981
00:41:11,654 --> 00:41:14,878
becoming categorical imperative of being

982
00:41:14,964 --> 00:41:17,466
in the game. And so again, he doesn't

983
00:41:17,498 --> 00:41:18,846
explicitly define this, but I think what

984
00:41:18,868 --> 00:41:21,706
he's implying is this idea of becoming

985
00:41:21,738 --> 00:41:23,434
as like this, like deeper philosophical

986
00:41:23,482 --> 00:41:25,280
term that goes back thousands of years

987
00:41:25,810 --> 00:41:29,150
where the organization isn't a static

988
00:41:29,230 --> 00:41:31,278
thing or it's not something that becomes

989
00:41:31,294 --> 00:41:32,962
something into an end state, but rather

990
00:41:33,016 --> 00:41:34,866
it is like a dynamic process. And it is

991
00:41:34,888 --> 00:41:36,260
always a dynamic process.

992
00:41:38,550 --> 00:41:39,958
Bleu Daniel, do you have anything you

993
00:41:39,964 --> 00:41:43,558
want to add to this? You have the

994
00:41:43,644 --> 00:41:47,074
Heraclitus River quote,

995
00:41:47,202 --> 00:41:50,250
which is a statement of the dynamic

996
00:41:50,830 --> 00:41:54,202
nature of becoming. And then

997
00:41:54,336 --> 00:41:57,242
in contrast we have being. And so people

998
00:41:57,296 --> 00:42:00,774
often talk about being and becoming as

999
00:42:00,912 --> 00:42:04,254
a noun centric and a verb centric way to

1000
00:42:04,292 --> 00:42:08,720
describe something is something is

1001
00:42:09,090 --> 00:42:11,594
that's like being or is it becoming?

1002
00:42:11,722 --> 00:42:14,890
Which is more of a process based focus.

1003
00:42:15,060 --> 00:42:16,834
So he refers to it as the site of

1004
00:42:16,872 --> 00:42:19,506
organizational becoming, not some sort

1005
00:42:19,528 --> 00:42:23,394
of ready made tool that's going to be,

1006
00:42:23,592 --> 00:42:25,822
but rather a process that will be

1007
00:42:25,896 --> 00:42:29,062
applied, or is already being applied as

1008
00:42:29,196 --> 00:42:31,830
a distributed site of becoming.

1009
00:42:37,530 --> 00:42:39,414
Cool. Do you want to read this one too?

1010
00:42:39,452 --> 00:42:42,246
Tyler sure. So FPP is not supposed to be

1011
00:42:42,268 --> 00:42:44,486
craving the powers assistant to exploit

1012
00:42:44,518 --> 00:42:46,134
uncertainty and complexity in pursuit

1013
00:42:46,182 --> 00:42:48,186
performance and survival by way of

1014
00:42:48,208 --> 00:42:50,266
curiosity driven epidemic foraging and

1015
00:42:50,288 --> 00:42:52,238
exploration. Correspondingly, Free

1016
00:42:52,244 --> 00:42:54,074
Energy Governance is a next generation

1017
00:42:54,122 --> 00:42:55,598
learning system designed for a

1018
00:42:55,604 --> 00:42:57,914
discontinuous world. Eachaining the firm

1019
00:42:57,962 --> 00:43:00,826
from dominant top down logics empowering

1020
00:43:00,858 --> 00:43:02,414
continuous strategic renewal through

1021
00:43:02,452 --> 00:43:07,502
purpose directed generative inferential

1022
00:43:07,566 --> 00:43:09,646
and cross hierarchical prediction error

1023
00:43:09,678 --> 00:43:10,530
minimization.

1024
00:43:15,700 --> 00:43:18,160
I wonder here if organizational becoming

1025
00:43:18,240 --> 00:43:21,156
and strategic renewal, I wonder if those

1026
00:43:21,178 --> 00:43:23,620
are maybe being used interchangeably.

1027
00:43:24,600 --> 00:43:26,660
We've talked about strategic renewal or

1028
00:43:26,730 --> 00:43:28,436
maybe strategic renewal is like a

1029
00:43:28,458 --> 00:43:30,416
fundamental like an organizational

1030
00:43:30,448 --> 00:43:32,636
becoming or organizational becoming

1031
00:43:32,688 --> 00:43:35,352
includes strategic renewal and other

1032
00:43:35,406 --> 00:43:36,856
things. I don't know. That's a good

1033
00:43:36,878 --> 00:43:39,130
question for Bijan, who we will get to

1034
00:43:39,740 --> 00:43:42,136
ask lots of questions of next week. Do

1035
00:43:42,158 --> 00:43:43,740
you have any additional concepts here,

1036
00:43:43,810 --> 00:43:50,430
Daniel or tyler okay,

1037
00:43:51,200 --> 00:43:53,196
Free Energy Governance, I'll let you

1038
00:43:53,218 --> 00:43:56,052
take this one. So free Energy Governance

1039
00:43:56,136 --> 00:43:57,676
effectively transposes the active

1040
00:43:57,708 --> 00:43:59,376
coherence framework to the firm and

1041
00:43:59,398 --> 00:44:01,804
adopts FEP as a first order principle

1042
00:44:01,852 --> 00:44:04,192
underlying a new logic organizing built

1043
00:44:04,246 --> 00:44:06,512
around three core dimension so

1044
00:44:06,566 --> 00:44:08,320
structure, hierarchy, cognition,

1045
00:44:08,480 --> 00:44:10,800
environmental enactment, capabilities,

1046
00:44:10,960 --> 00:44:13,376
sensing and sense making. The framework

1047
00:44:13,408 --> 00:44:14,916
is centered around crosshair will

1048
00:44:14,938 --> 00:44:16,884
generative process of sensing and sense

1049
00:44:16,922 --> 00:44:19,104
making to institutionalize continuum

1050
00:44:19,152 --> 00:44:21,124
strategic renewal as a matter of active

1051
00:44:21,172 --> 00:44:23,300
inference in pursuit of firm

1052
00:44:23,380 --> 00:44:25,240
outperformance and survival.

1053
00:44:29,910 --> 00:44:33,762
Nice. So here we are at the

1054
00:44:33,896 --> 00:44:35,426
end of the Free Energy Principle

1055
00:44:35,458 --> 00:44:39,622
chapter, the end of the first section on

1056
00:44:39,676 --> 00:44:41,938
the FEP in the Free Energy Governance

1057
00:44:42,114 --> 00:44:44,662
textbook. Looking forward to having a

1058
00:44:44,716 --> 00:44:46,314
good discussion with the author next

1059
00:44:46,352 --> 00:44:48,650
week. Do you guys have any final

1060
00:44:48,720 --> 00:44:51,130
thoughts on this section or chapter or

1061
00:44:51,280 --> 00:44:52,490
anything? Overall.

1062
00:44:55,550 --> 00:44:58,678
I think a question to unpack is going to

1063
00:44:58,704 --> 00:45:02,062
be how does a descriptive theory of

1064
00:45:02,116 --> 00:45:06,014
everything in Free Energy Principle help

1065
00:45:06,052 --> 00:45:09,434
us make normative or even adaptive

1066
00:45:09,482 --> 00:45:11,322
decisions for ourselves and for our

1067
00:45:11,396 --> 00:45:14,274
organizations? Every single information

1068
00:45:14,392 --> 00:45:17,394
architecture or strategy that a given

1069
00:45:17,432 --> 00:45:20,786
group implements will be describable in

1070
00:45:20,808 --> 00:45:22,702
terms of the particular partitioning

1071
00:45:22,766 --> 00:45:24,286
into internal, external, and blanket

1072
00:45:24,318 --> 00:45:25,910
states. They're all going to be

1073
00:45:25,980 --> 00:45:28,418
describable in terms of Bayesian optimal

1074
00:45:28,514 --> 00:45:31,266
inference, given some generative models

1075
00:45:31,298 --> 00:45:33,526
and encoding stream of data. So how do

1076
00:45:33,548 --> 00:45:35,734
we take something that is kind of like

1077
00:45:35,772 --> 00:45:39,002
the number line, it just is, and it is

1078
00:45:39,056 --> 00:45:42,460
neutral and then proactively apply it

1079
00:45:43,310 --> 00:45:45,946
up to and including the last mile? Do

1080
00:45:45,968 --> 00:45:47,482
people need to actually know about

1081
00:45:47,536 --> 00:45:49,726
information entropy to be part of a

1082
00:45:49,748 --> 00:45:52,046
system that's designed with these

1083
00:45:52,148 --> 00:45:55,486
strategies in mind, or is there going to

1084
00:45:55,508 --> 00:45:57,406
be some other way to communicate and

1085
00:45:57,428 --> 00:46:00,942
apply it? So how we actually move it

1086
00:46:01,076 --> 00:46:04,694
to the space of proactive decisionmaking

1087
00:46:04,762 --> 00:46:07,234
today and what that looks like in

1088
00:46:07,272 --> 00:46:08,610
different sectors and for different

1089
00:46:08,680 --> 00:46:10,930
organizations is really exciting.

1090
00:46:16,010 --> 00:46:19,462
Awesome. Well, I'm also looking forward

1091
00:46:19,516 --> 00:46:22,022
to reading the next sections of the book

1092
00:46:22,076 --> 00:46:25,762
and kind of going beyond the background

1093
00:46:25,826 --> 00:46:28,378
section into what's next, what is the

1094
00:46:28,464 --> 00:46:31,114
implication? And looking forward to

1095
00:46:31,152 --> 00:46:33,834
Bijon's comments next week. Tyler, any

1096
00:46:33,872 --> 00:46:36,682
comments are good. All good for me.

1097
00:46:36,736 --> 00:46:38,906
Looking forward to next week. Yeah, me

1098
00:46:38,928 --> 00:46:41,162
too. So if anybody has questions,

1099
00:46:41,296 --> 00:46:44,086
please go ahead and submit them. You're

1100
00:46:44,118 --> 00:46:47,206
welcome to email them to us or submit

1101
00:46:47,238 --> 00:46:49,546
them here in the comments, but do it

1102
00:46:49,568 --> 00:46:52,018
before the 11th, which is why our

1103
00:46:52,184 --> 00:46:54,818
meeting with Bijan will be and if you

1104
00:46:54,824 --> 00:46:56,238
want to participate on the live stream

1105
00:46:56,254 --> 00:46:58,770
and have read the chapters in the book

1106
00:46:58,840 --> 00:47:01,138
and watch the live streams or one or the

1107
00:47:01,144 --> 00:47:03,602
other, get in touch. Okay? Thanks,

1108
00:47:03,656 --> 00:47:04,260
guys.


