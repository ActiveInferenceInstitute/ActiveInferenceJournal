1010
00:00:29,037 --> 00:00:32,257
>> DANIEL FRIEDMAN: All right, welcome. It is

1020
00:00:32,335 --> 00:00:35,225
active livestream. Number 510.

1030
00:00:35,662 --> 00:00:37,587
This is the background in context.

1040
00:00:37,662 --> 00:00:40,332
First discussion for canonical neural

1050
00:00:40,347 --> 00:00:42,817
networks performance active inference by

1060
00:00:42,865 --> 00:00:45,907
Isa Mara et al. It's October 26,

1070
00:00:45,985 --> 00:00:50,127
2022. Welcome to the active inference

1080
00:00:50,157 --> 00:00:52,807
institute. We're a participatory online

1090
00:00:52,885 --> 00:00:54,582
institute that is communicating,

1100
00:00:54,672 --> 00:00:56,652
learning and plasticity applied active

1110
00:00:56,682 --> 00:00:59,152
inference. You can find us at some of

1120
00:00:59,170 --> 00:01:01,402
the links on the page. This is recorded

1130
00:01:01,495 --> 00:01:03,397
in an archive livestream, so please

1140
00:01:03,430 --> 00:01:04,777
provide us with feedback so we can

1150
00:01:04,795 --> 00:01:07,477
improve our work. All backgrounds and

1160
00:01:07,495 --> 00:01:09,097
perspectives are welcome and will be

1170
00:01:09,130 --> 00:01:11,547
following video etiquette for Solo

1180
00:01:11,592 --> 00:01:16,392
Livestreams head to Active Inference.org

1190
00:01:16,527 --> 00:01:19,377
to learn how to get involved with Active

1200
00:01:19,407 --> 00:01:23,602
Inference Institute projects today.

1210
00:01:23,695 --> 00:01:26,022
It's the first of several discussions

1220
00:01:26,067 --> 00:01:28,722
that we'll have on the paper. Canonical

1230
00:01:28,767 --> 00:01:30,207
neural networks perform active

1240
00:01:30,222 --> 00:01:34,347
inference. 2022 by Tequia Isomura,

1250
00:01:34,467 --> 00:01:37,932
Hijacki Shimazaki and Karl Friston

1260
00:01:38,097 --> 00:01:40,567
The video is just an introduction to

1270
00:01:40,615 --> 00:01:42,547
some of the ideas. It's not a review or

1280
00:01:42,580 --> 00:01:45,652
final word. There will be an overview of

1290
00:01:45,670 --> 00:01:47,647
the structure of the paper and then

1300
00:01:47,755 --> 00:01:49,582
we'll go through many of the set point.

1310
00:01:49,735 --> 00:01:53,347
Also just to disclaim, there's many,

1320
00:01:53,380 --> 00:01:56,542
many other and better resources to learn

1330
00:01:56,590 --> 00:01:59,272
about neural networks. So I would very

1340
00:01:59,305 --> 00:02:02,162
much welcome those with a technical

1350
00:02:02,587 --> 00:02:05,857
understanding of neural networks and or

1360
00:02:06,010 --> 00:02:09,417
some of the more applied computational

1370
00:02:09,552 --> 00:02:13,077
or otherwise aspects of neural networks.

1380
00:02:13,107 --> 00:02:15,322
It would be awesome to have them on for

1390
00:02:15,355 --> 00:02:17,497
the dot one and the dot two, because it

1400
00:02:17,530 --> 00:02:20,422
was not an area I was familiar with and

1410
00:02:20,455 --> 00:02:23,272
so hope that I can hear more from the

1420
00:02:23,305 --> 00:02:25,775
authors in our coming weeks and others.

1430
00:02:26,137 --> 00:02:28,327
I'm Daniel, I'm a researcher in

1440
00:02:28,345 --> 00:02:32,187
California, and this will just be a solo

1450
00:02:32,337 --> 00:02:34,327
zero, which I guess hasn't happened in a

1460
00:02:34,345 --> 00:02:37,717
while in the making of

1470
00:02:37,765 --> 00:02:41,317
this. Here are some of the generated art

1480
00:02:41,440 --> 00:02:44,887
prompts area 51 Active Inference Brea.

1490
00:02:44,950 --> 00:02:48,027
51 neural network. Area 51 active

1500
00:02:48,057 --> 00:02:51,177
inference. Ant Brea. 51 Active Inference

1510
00:02:51,207 --> 00:02:53,557
Neural Network just some interesting

1520
00:02:53,635 --> 00:02:55,712
images coming out of stable diffusion.

1530
00:02:56,362 --> 00:02:59,422
So as to some big questions that the

1540
00:02:59,455 --> 00:03:01,327
paper is addressing and that one might

1550
00:03:01,345 --> 00:03:03,247
be interested in to come to the paper.

1560
00:03:03,355 --> 00:03:05,797
How can artificial neural networks be

1570
00:03:05,830 --> 00:03:07,482
understood as generic optimization

1580
00:03:07,572 --> 00:03:10,092
processes and what is the correspondence

1590
00:03:10,152 --> 00:03:11,997
between hemodynamics and modern

1600
00:03:12,042 --> 00:03:14,087
statistical inference methods?

1610
00:03:15,187 --> 00:03:18,247
Other big questions are about the

1620
00:03:18,280 --> 00:03:20,667
history and next steps of the enmeshment

1630
00:03:20,727 --> 00:03:22,722
of natural intelligence, eg.

1640
00:03:22,767 --> 00:03:24,072
Neuroscience and artificial

1650
00:03:24,117 --> 00:03:26,362
intelligence, as well as, of course,

1660
00:03:26,425 --> 00:03:29,002
whether to even play into this kind of

1670
00:03:29,095 --> 00:03:31,582
distinction at all and have different

1680
00:03:31,660 --> 00:03:34,657
integrated intelligence frameworks. And

1690
00:03:34,735 --> 00:03:37,297
one paper where any of the authors or

1700
00:03:37,330 --> 00:03:40,027
anyone who has kind of resonated with

1710
00:03:40,045 --> 00:03:42,817
this work is recent by Zidore at all

1720
00:03:42,865 --> 00:03:45,552
2022 towards the Next Generation

1730
00:03:45,657 --> 00:03:47,527
artificial Intelligence catalyzing the

1740
00:03:47,545 --> 00:03:50,677
NeuroAI Revolution and so this is a

1750
00:03:50,695 --> 00:03:52,662
bunch of authors. And so it's

1760
00:03:52,737 --> 00:03:54,277
interesting just to quote in terms of

1770
00:03:54,295 --> 00:03:56,647
what some areas of discourse are saying

1780
00:03:56,680 --> 00:03:58,747
right now, which is neuroscience has

1790
00:03:58,780 --> 00:04:00,202
long been an important driver of

1800
00:04:00,220 --> 00:04:02,517
progress in artificial intelligence AI.

1810
00:04:02,577 --> 00:04:04,617
We propose that to accelerate progress

1820
00:04:04,677 --> 00:04:07,677
in AI, we must invest in fundamental

1830
00:04:07,707 --> 00:04:10,447
research in NeuroAI. So that's one way

1840
00:04:10,480 --> 00:04:13,072
to lead some of the developments that

1850
00:04:13,105 --> 00:04:15,650
are happening in the paper we'll discuss

1860
00:04:17,137 --> 00:04:19,042
what does it mean to be particular but

1870
00:04:19,090 --> 00:04:20,977
generic? That's a phrase used in the

1880
00:04:20,995 --> 00:04:22,632
paper, so maybe that's kind of a jumping

1890
00:04:22,647 --> 00:04:24,957
off point. And then how can active

1900
00:04:24,972 --> 00:04:26,872
inference help us understand the past,

1910
00:04:26,905 --> 00:04:30,217
present and future here of the

1920
00:04:30,265 --> 00:04:31,752
interface with neural networks,

1930
00:04:31,782 --> 00:04:34,112
statistics and neural AI?

1940
00:04:38,887 --> 00:04:40,412
Here's the abstract.

1950
00:04:42,187 --> 00:04:44,622
This work considers a class of canonical

1960
00:04:44,667 --> 00:04:46,752
neural networks comprising rate coding

1970
00:04:46,782 --> 00:04:48,877
models where neural activity and

1980
00:04:48,895 --> 00:04:50,992
plasticity minimize a common cost

1990
00:04:51,040 --> 00:04:53,922
function and plasticity is modulated

2000
00:04:54,042 --> 00:04:56,782
with a certain delay. We show that such

2010
00:04:56,860 --> 00:04:58,537
neural networks implicitly perform

2020
00:04:58,600 --> 00:04:59,977
active inference and learning to

2030
00:04:59,995 --> 00:05:01,792
minimize the risk associated with future

2040
00:05:01,840 --> 00:05:03,972
outcomes. Mathematical analyses

2050
00:05:04,017 --> 00:05:05,562
demonstrate that this biological

2060
00:05:05,637 --> 00:05:08,502
optimization can be cast as maximization

2070
00:05:08,607 --> 00:05:11,217
of model evidence or equivalently

2080
00:05:11,277 --> 00:05:13,700
minimization of variational free energy

2090
00:05:14,062 --> 00:05:17,022
under the wellknown form of a partially

2100
00:05:17,067 --> 00:05:19,250
observed Markov decision process model.

2110
00:05:19,837 --> 00:05:21,577
This equivalence indicates that the

2120
00:05:21,595 --> 00:05:23,257
delayed modularity of heavy and

2130
00:05:23,260 --> 00:05:25,527
plasticity accompanied with adaptation

2140
00:05:25,557 --> 00:05:27,552
of firing thresholds is a sufficient

2150
00:05:27,582 --> 00:05:29,667
neuronal substrate to attain Bayes

2160
00:05:29,727 --> 00:05:32,077
optimal inference and control. We

2170
00:05:32,095 --> 00:05:34,117
corroborated this proposition using

2180
00:05:34,165 --> 00:05:37,112
numerical analyses of maze tasks.

2190
00:05:37,462 --> 00:05:39,852
This theory offers a universal

2200
00:05:39,882 --> 00:05:41,652
characterization of canonical neural

2210
00:05:41,682 --> 00:05:43,872
networks in terms of Bayesian belief

2220
00:05:43,917 --> 00:05:46,207
updating and provides insight into the

2230
00:05:46,210 --> 00:05:48,372
neuronal mechanisms underlying planning

2240
00:05:48,417 --> 00:05:50,600
and adaptive behavioral control.

2250
00:05:53,137 --> 00:05:56,257
Here is the roadmap I'll be driving. On

2260
00:05:56,260 --> 00:05:59,452
the right side of the road, there's an

2270
00:05:59,470 --> 00:06:02,142
introduction and a table with glossary

2280
00:06:02,202 --> 00:06:05,437
of different expressions used. Then

2290
00:06:05,575 --> 00:06:08,750
there's the Results sections, which has

2300
00:06:09,562 --> 00:06:11,422
first an overview of equivalence between

2310
00:06:11,455 --> 00:06:13,400
neural networks and variational base

2320
00:06:14,137 --> 00:06:16,027
active inference formulated using a

2330
00:06:16,045 --> 00:06:17,727
postdiction of past decisions.

2340
00:06:17,832 --> 00:06:19,902
Canonical neural networks perform active

2350
00:06:19,932 --> 00:06:22,597
inference and numerical simulations. So

2360
00:06:22,705 --> 00:06:25,087
they work on the interface between

2370
00:06:25,150 --> 00:06:27,522
neural networks and variational Bayesian

2380
00:06:27,567 --> 00:06:31,507
methods and start with a more

2390
00:06:31,585 --> 00:06:35,202
theoretical and mathematical background

2400
00:06:35,307 --> 00:06:37,947
and then eventually present some maze

2410
00:06:37,992 --> 00:06:41,392
simulations that are in MATLAB. Then

2420
00:06:41,440 --> 00:06:42,877
there's a discussion, and then the

2430
00:06:42,895 --> 00:06:45,322
methods section is following the

2440
00:06:45,355 --> 00:06:48,567
discussion and it has the subsections

2450
00:06:48,627 --> 00:06:50,647
generative model variational free energy

2460
00:06:50,755 --> 00:06:52,647
inference and learning, neural networks,

2470
00:06:52,692 --> 00:06:56,677
simulations and data analysis. And I

2480
00:06:56,770 --> 00:06:59,392
think that I have kept to the right

2490
00:06:59,590 --> 00:07:02,572
color codes consistently from here on

2500
00:07:02,605 --> 00:07:05,092
forward. The black quotes are the direct

2510
00:07:05,140 --> 00:07:08,082
quotes from the paper Bleu quotes quotes

2520
00:07:08,097 --> 00:07:09,737
are related to perception,

2530
00:07:11,587 --> 00:07:14,542
orange for action, complete class

2540
00:07:14,590 --> 00:07:16,402
theorems and neural networks together in

2550
00:07:16,420 --> 00:07:20,077
purple. And then red is commentary and

2560
00:07:20,170 --> 00:07:22,497
then the highlighting for red is related

2570
00:07:22,542 --> 00:07:25,782
to the variational methods,

2580
00:07:25,797 --> 00:07:27,587
but it's kind of redish.

2590
00:07:29,962 --> 00:07:31,932
Okay, the papers canonical neural

2600
00:07:31,947 --> 00:07:34,477
networks perform active inference by the

2610
00:07:34,495 --> 00:07:37,102
authors listed previously. It's in

2620
00:07:37,120 --> 00:07:39,922
communications biology from 2022.

2630
00:07:39,955 --> 00:07:43,567
And the key aims of the paper are

2640
00:07:43,615 --> 00:07:45,492
laid out well in the first paragraph.

2650
00:07:45,552 --> 00:07:47,922
So that's in black and other colors.

2660
00:07:47,967 --> 00:07:51,425
And here the red is just kind of

2670
00:07:52,837 --> 00:07:55,447
settling point initial conversation with

2680
00:07:55,480 --> 00:07:57,952
the paper and connecting a little bit

2690
00:07:57,970 --> 00:07:59,962
more to some previous streams before we

2700
00:08:00,025 --> 00:08:02,842
go more into the specifics of the paper.

2710
00:08:03,040 --> 00:08:04,722
The sentient behavior of biological

2720
00:08:04,767 --> 00:08:06,127
organisms is characterized by

2730
00:08:06,145 --> 00:08:08,802
optimization biological organisms

2740
00:08:08,832 --> 00:08:10,152
recognize the state of their environment

2750
00:08:10,182 --> 00:08:12,297
by optimizing internal representations

2760
00:08:12,417 --> 00:08:14,742
of the external environmental dynamics

2770
00:08:14,802 --> 00:08:17,092
generating sensory inputs. So that's the

2780
00:08:17,140 --> 00:08:20,817
sensory recognition model. In addition,

2790
00:08:20,952 --> 00:08:22,702
they optimize their behavior for

2800
00:08:22,720 --> 00:08:24,597
adaptation to the environment thereby

2810
00:08:24,642 --> 00:08:26,577
increasing their probability of survival

2820
00:08:26,607 --> 00:08:29,622
and reproduction. So that is bringing

2830
00:08:29,667 --> 00:08:33,682
the entire active and inactive control

2840
00:08:33,760 --> 00:08:35,802
theory. Formal theories of action.

2850
00:08:35,982 --> 00:08:38,577
Action selections. Planning and planning

2860
00:08:38,607 --> 00:08:41,847
as inference all of these actionoriented

2870
00:08:41,892 --> 00:08:44,737
pragmatic term type ideas come into play

2880
00:08:44,800 --> 00:08:47,652
when this actionorange aspect is brought

2890
00:08:47,682 --> 00:08:50,992
in and it is.

2900
00:08:51,190 --> 00:08:54,937
Must be. Should be. Etc oriented towards

2910
00:08:55,000 --> 00:08:58,357
survival and persistence otherwise we

2920
00:08:58,360 --> 00:09:00,382
don't see that kind of thing for long

2930
00:09:00,535 --> 00:09:03,322
over appropriate definitions for thing

2940
00:09:03,355 --> 00:09:07,567
and long. Et cetera. And this few

2950
00:09:07,615 --> 00:09:09,967
sentences that the paper begins with

2960
00:09:10,015 --> 00:09:13,227
summarizes a common theme in actinF

2970
00:09:13,257 --> 00:09:14,887
which is that there's basically two

2980
00:09:14,950 --> 00:09:17,752
pathways towards proficiency in the

2990
00:09:17,770 --> 00:09:20,527
niche. There's changing the mind, which

3000
00:09:20,545 --> 00:09:22,927
is the perceptual and learning and then

3010
00:09:22,945 --> 00:09:24,187
there's changing the world through

3020
00:09:24,250 --> 00:09:26,722
action. And that kind of integration of

3030
00:09:26,755 --> 00:09:28,747
inference, cognitive inference, whether

3040
00:09:28,780 --> 00:09:31,732
it's perceptual or learning or other and

3050
00:09:31,810 --> 00:09:34,867
action as enacted is part of the

3060
00:09:34,915 --> 00:09:37,867
active formula and shared with other

3070
00:09:37,915 --> 00:09:41,112
areas. This biological selforganization

3080
00:09:41,187 --> 00:09:42,607
is typically formulated as the

3090
00:09:42,610 --> 00:09:44,602
minimization of cost functions where in

3100
00:09:44,620 --> 00:09:46,252
a gradient descent on a cost function

3110
00:09:46,345 --> 00:09:48,222
furnishes neurodynamics and synaptic

3120
00:09:48,267 --> 00:09:51,577
plasticity. So they are working with

3130
00:09:51,595 --> 00:09:53,542
a framework where the way that this

3140
00:09:53,590 --> 00:09:57,642
perception action flow is tractable

3150
00:09:57,702 --> 00:10:00,292
computationally either just for our

3160
00:10:00,340 --> 00:10:02,107
current computers so that we can

3170
00:10:02,185 --> 00:10:04,437
implement simulations and data fitting

3180
00:10:04,587 --> 00:10:07,192
or whether more fundamentally like this

3190
00:10:07,240 --> 00:10:10,337
is the computational context of action

3200
00:10:11,212 --> 00:10:12,697
they're suggesting there's a way to

3210
00:10:12,730 --> 00:10:15,007
think of it in terms of a cost function

3220
00:10:15,160 --> 00:10:17,497
minimization and also note like

3230
00:10:17,530 --> 00:10:19,702
minimization maximization. In a way

3240
00:10:19,720 --> 00:10:22,077
they're interchangeable because there's

3250
00:10:22,107 --> 00:10:23,872
just sometimes negative signs that can

3260
00:10:23,905 --> 00:10:26,527
flip them. So it's the same energy and

3270
00:10:26,545 --> 00:10:29,317
fitness landscape that is being

3280
00:10:29,365 --> 00:10:31,852
navigated whether you're minimizing to

3290
00:10:31,870 --> 00:10:33,952
the bottom of the bowl and thinking of

3300
00:10:33,970 --> 00:10:36,762
action selection that way and inference

3310
00:10:36,912 --> 00:10:38,632
or whether you're climbing to the top of

3320
00:10:38,635 --> 00:10:40,347
the hill gradient descent. Gradient

3330
00:10:40,392 --> 00:10:42,307
ascent they're both kind of two sides of

3340
00:10:42,310 --> 00:10:46,072
the same .2

3350
00:10:46,105 --> 00:10:47,377
fundamental issues remain to be

3360
00:10:47,395 --> 00:10:50,077
established. Namely so this is what the

3370
00:10:50,095 --> 00:10:51,852
paper is saying they're filling the gap

3380
00:10:51,882 --> 00:10:53,602
in literature the characterization of

3390
00:10:53,620 --> 00:10:55,107
the dynamics of an arbitrary neural

3400
00:10:55,122 --> 00:10:56,757
network as a generic optimization

3410
00:10:56,847 --> 00:11:00,442
process and the correspondence between

3420
00:11:00,490 --> 00:11:02,547
such neural dynamics and statistical

3430
00:11:02,592 --> 00:11:04,107
inference found in applied mathematics

3440
00:11:04,122 --> 00:11:06,217
and machine learning. The present work

3450
00:11:06,265 --> 00:11:08,022
addresses these issues by demonstrating

3460
00:11:08,067 --> 00:11:09,732
that a class of canonical neural

3470
00:11:09,747 --> 00:11:12,022
networks of rate coding models is

3480
00:11:12,055 --> 00:11:14,592
functioning as and thus universally

3490
00:11:14,652 --> 00:11:17,352
characterized in terms of variational

3500
00:11:17,382 --> 00:11:20,092
bayesian inference under a particular

3510
00:11:20,215 --> 00:11:22,017
but generic form of the generative

3520
00:11:22,077 --> 00:11:26,197
model. This is maybe the

3530
00:11:26,230 --> 00:11:30,097
only slide that has resources from too

3540
00:11:30,130 --> 00:11:33,067
far a field from paper. Well,

3550
00:11:33,190 --> 00:11:36,777
almost a few more. It's just on neural

3560
00:11:36,807 --> 00:11:40,522
networks. The search on a very common

3570
00:11:40,705 --> 00:11:44,167
search tool resulted in five

3580
00:11:44,215 --> 00:11:46,482
plus million results for what are neural

3590
00:11:46,497 --> 00:11:49,072
networks? And the first one was three

3600
00:11:49,105 --> 00:11:52,402
Bleu one brown in 2017 which is just a

3610
00:11:52,420 --> 00:11:55,312
nice YouTube video as they very often

3620
00:11:55,450 --> 00:11:58,187
make with these beautiful renditions,

3630
00:11:58,687 --> 00:12:00,327
and it's a very great video. And there's

3640
00:12:00,357 --> 00:12:02,557
many, many others. A neural network is a

3650
00:12:02,560 --> 00:12:04,227
network or circuit of biological

3660
00:12:04,257 --> 00:12:07,977
neurons, and that is variously purely

3670
00:12:08,007 --> 00:12:11,462
computational and or biological

3680
00:12:12,487 --> 00:12:16,297
map territory stuff. And they

3690
00:12:16,330 --> 00:12:18,087
can be thought of as nodes and edges,

3700
00:12:18,237 --> 00:12:21,987
which are the firing rates

3710
00:12:22,137 --> 00:12:23,557
and the connections between the

3720
00:12:23,560 --> 00:12:25,867
biological neurons being modeled as

3730
00:12:25,915 --> 00:12:29,547
weights between nodes. A positive

3740
00:12:29,592 --> 00:12:31,422
weight reflects an excitatory

3750
00:12:31,542 --> 00:12:33,202
connection, while negative values mean

3760
00:12:33,220 --> 00:12:35,782
inhibitory connections. And here is data

3770
00:12:35,860 --> 00:12:38,592
coming in and ending up activating

3780
00:12:38,652 --> 00:12:40,572
different neurons in this final layer.

3790
00:12:40,692 --> 00:12:43,957
So this is kind of doing inference in a

3800
00:12:43,960 --> 00:12:46,972
neural network, and then there's an

3810
00:12:47,005 --> 00:12:50,677
action part. Okay, the paper

3820
00:12:50,770 --> 00:12:52,422
says variational Bayesian inference

3830
00:12:52,467 --> 00:12:54,247
offers a unified explanation for

3840
00:12:54,280 --> 00:12:56,397
inference learning, prediction,

3850
00:12:56,517 --> 00:12:58,282
decision making and the evolution of

3860
00:12:58,285 --> 00:13:00,252
biological form, which can be considered

3870
00:13:00,282 --> 00:13:01,837
over multiple timescales. So this

3880
00:13:01,900 --> 00:13:03,697
returns to the earlier theme of like

3890
00:13:03,730 --> 00:13:07,422
exteroception action and persistence

3900
00:13:07,467 --> 00:13:09,907
within and among generations. And the

3910
00:13:09,910 --> 00:13:11,902
citations that are provided here for

3920
00:13:11,920 --> 00:13:16,147
this are Friston, Kilner Harrison 2006

3930
00:13:16,180 --> 00:13:19,147
and Friston 2010,

3940
00:13:19,330 --> 00:13:23,937
both very classic acne FEP

3950
00:13:24,087 --> 00:13:26,572
papers, just to show one figure from

3960
00:13:26,605 --> 00:13:30,957
each here's from the first citation

3970
00:13:31,122 --> 00:13:34,252
with a winged snowflake, where if the

3980
00:13:34,270 --> 00:13:36,702
snowflake ends up being somewhere that's

3990
00:13:36,732 --> 00:13:39,547
too warm, that's not able for it to

4000
00:13:39,580 --> 00:13:43,107
maintain the structure, then it melts,

4010
00:13:43,272 --> 00:13:47,722
melts into a dew, etc. And it

4020
00:13:47,755 --> 00:13:49,852
must be acting as if in one way or

4030
00:13:49,870 --> 00:13:52,152
another, it's staying above that phase

4040
00:13:52,257 --> 00:13:54,192
boundary. That's how it's statistically

4050
00:13:54,252 --> 00:13:56,462
identified, it's how it's

4060
00:13:57,037 --> 00:13:59,097
autogenetically identified,

4070
00:13:59,292 --> 00:14:00,737
functionally identified.

4080
00:14:02,212 --> 00:14:08,182
And then here is one of the kind

4090
00:14:08,185 --> 00:14:11,692
of path setting figures in the first

4100
00:14:11,740 --> 00:14:15,487
and 2010 paper with a tree of many

4110
00:14:15,550 --> 00:14:18,952
different areas to connect to,

4120
00:14:18,970 --> 00:14:21,822
informalisms to represent as including

4130
00:14:21,867 --> 00:14:24,362
probabilistic, neural coding,

4140
00:14:24,937 --> 00:14:26,387
Bayesian brain,

4150
00:14:27,487 --> 00:14:29,750
optimal control and value learning.

4160
00:14:30,637 --> 00:14:34,237
These three and others can be

4170
00:14:34,300 --> 00:14:38,150
really seen at play in this paper.

4180
00:14:41,062 --> 00:14:43,317
The kind of inference variational basing

4190
00:14:43,377 --> 00:14:46,122
methods use rests upon a generative

4200
00:14:46,167 --> 00:14:48,052
model that expresses a hypothesis about

4210
00:14:48,070 --> 00:14:49,947
the generation of sensory input.

4220
00:14:50,142 --> 00:14:52,147
Perception and behavior can then be read

4230
00:14:52,180 --> 00:14:53,527
as optimizing the evidence for a

4240
00:14:53,545 --> 00:14:55,077
generative model inherent in sensory

4250
00:14:55,107 --> 00:14:57,907
exchanges for the environment, and

4260
00:14:57,985 --> 00:14:59,677
that's the integration of perception and

4270
00:14:59,695 --> 00:15:02,227
action within a single imperative in

4280
00:15:02,245 --> 00:15:04,487
terms of if only computation.

4290
00:15:05,062 --> 00:15:08,467
And that is described more on this

4300
00:15:08,590 --> 00:15:10,897
slide, which one can pause and read,

4310
00:15:10,930 --> 00:15:13,372
but the rest of the quotes are from the

4320
00:15:13,405 --> 00:15:14,000
paper.

4330
00:15:20,475 --> 00:15:24,315
One eformalism that

4340
00:15:24,407 --> 00:15:28,737
I had no familiarity with before this

4350
00:15:29,700 --> 00:15:31,950
paper and associated readings and

4360
00:15:32,012 --> 00:15:35,580
conversations with Ali was the Complete

4370
00:15:35,702 --> 00:15:39,630
Class Theorem. So it would be great

4380
00:15:39,677 --> 00:15:41,205
for anyone who's familiar with Complete

4390
00:15:41,252 --> 00:15:44,205
Class Theorem to help a little bit here,

4400
00:15:44,252 --> 00:15:46,530
but here's some interesting things that

4410
00:15:46,652 --> 00:15:49,785
I came across crucially from the paper

4420
00:15:49,892 --> 00:15:51,930
as a corollary of the Complete Class

4430
00:15:51,977 --> 00:15:55,035
Theorem citations 19 through 21. Any

4440
00:15:55,067 --> 00:15:56,460
neural network minimizing a class

4450
00:15:56,492 --> 00:15:57,785
function can be viewed as performing

4460
00:15:57,830 --> 00:16:00,045
variational Bayesian inference under

4470
00:16:00,122 --> 00:16:03,375
some prior beliefs. Here are the

4480
00:16:03,437 --> 00:16:06,600
citations 19 through 21 from

4490
00:16:06,662 --> 00:16:09,060
1940 719 81 2013,

4500
00:16:09,092 --> 00:16:13,062
and also found some

4510
00:16:13,575 --> 00:16:16,995
interesting resources. So quoting from

4520
00:16:17,072 --> 00:16:19,362
this less wrong post linked here,

4530
00:16:20,775 --> 00:16:23,585
dutch book defines belief as willingness

4540
00:16:23,630 --> 00:16:26,480
to bet and Money Pump defines preference

4550
00:16:26,540 --> 00:16:29,055
as willingness to pay. This is in terms

4560
00:16:29,102 --> 00:16:32,565
of the foundational arguments for a

4570
00:16:32,582 --> 00:16:36,440
Bayesian Epistemological worldview.

4580
00:16:36,620 --> 00:16:38,370
Hope that's correct. Again, it would be

4590
00:16:38,447 --> 00:16:41,085
good to hear from anyone who knows more

4600
00:16:41,117 --> 00:16:42,990
here, but in terms of different ways

4610
00:16:43,007 --> 00:16:45,175
that one can consider the Bayesian

4620
00:16:45,525 --> 00:16:48,885
proposition, which perhaps these are

4630
00:16:48,917 --> 00:16:52,350
even better to use than referencing any

4640
00:16:52,412 --> 00:16:54,660
person's last name. Because the

4650
00:16:54,692 --> 00:16:56,787
interesting thing will be the different

4660
00:16:58,875 --> 00:17:02,330
lenses that these different framings

4670
00:17:02,390 --> 00:17:06,705
on Bayesian probabilities are

4680
00:17:06,752 --> 00:17:09,215
interpreted as. Just like what a Pvalue

4690
00:17:09,245 --> 00:17:10,910
is interpreted as in the frequentist

4700
00:17:10,955 --> 00:17:13,415
worldlessly, like a beta factor

4710
00:17:13,520 --> 00:17:16,835
interpretation. So Dutch book defines

4720
00:17:16,880 --> 00:17:18,750
belief as willingness to bet and Money

4730
00:17:18,812 --> 00:17:20,820
pump defines preferences willingness to

4740
00:17:20,822 --> 00:17:23,415
pay. In doing so, both arguments put the

4750
00:17:23,432 --> 00:17:25,185
justification of decision theory into

4760
00:17:25,217 --> 00:17:27,710
hypothetical exploitation scenarios

4770
00:17:27,830 --> 00:17:29,265
which are not quite the same as the

4780
00:17:29,282 --> 00:17:32,460
actual decisions we face. If these were

4790
00:17:32,492 --> 00:17:33,840
the best justifications for

4800
00:17:33,857 --> 00:17:36,435
consequentialism we could muster, I

4810
00:17:36,467 --> 00:17:38,310
would be somewhat dissatisfied, but

4820
00:17:38,342 --> 00:17:39,920
would likely leave it alone.

4830
00:17:40,085 --> 00:17:41,855
Fortunately, a better alternative

4840
00:17:41,915 --> 00:17:44,050
exists. The complete Class theorem.

4850
00:17:46,125 --> 00:17:49,755
So here's an image from that

4860
00:17:49,802 --> 00:17:53,910
post possible world states

4870
00:17:54,017 --> 00:17:55,845
observation likelihood maps to the

4880
00:17:55,847 --> 00:17:59,240
possible observations hashtag a matrix,

4890
00:17:59,420 --> 00:18:01,815
then decisionmaking rule may be

4900
00:18:01,832 --> 00:18:05,160
probabilistic action selection as

4910
00:18:05,192 --> 00:18:08,350
inference a possible actions

4920
00:18:08,700 --> 00:18:12,215
affordances. And here we commonly

4930
00:18:12,245 --> 00:18:14,150
see the loop being closed from actions

4940
00:18:14,225 --> 00:18:15,615
to world states like through the B

4950
00:18:15,632 --> 00:18:17,355
matrix changing how the world changes

4960
00:18:17,402 --> 00:18:19,980
through time. And here these are both

4970
00:18:20,027 --> 00:18:23,562
going to be mapped to a loss function l

4980
00:18:24,300 --> 00:18:26,610
a real valued score from taking an

4990
00:18:26,642 --> 00:18:30,015
action A when the world turned out to be

5000
00:18:30,107 --> 00:18:33,990
theta realized theta. So that's quite an

5010
00:18:34,007 --> 00:18:37,470
interesting framing and there were

5020
00:18:37,472 --> 00:18:39,810
some other useful posts online. And from

5030
00:18:39,842 --> 00:18:43,785
this Zhang blog the

5040
00:18:43,817 --> 00:18:46,035
argument boils down to if you agree with

5050
00:18:46,067 --> 00:18:47,990
expected utility as your objective,

5060
00:18:48,095 --> 00:18:50,670
then you have to be Bayesian. In a

5070
00:18:50,672 --> 00:18:52,740
nutshell, a strategy is inadmissible if

5080
00:18:52,757 --> 00:18:55,455
there exists another state that is as

5090
00:18:55,502 --> 00:18:57,485
good in all situations and strictly

5100
00:18:57,530 --> 00:19:00,285
better in at least one. If you want your

5110
00:19:00,317 --> 00:19:03,465
strategy to be admissible, it should be

5120
00:19:03,482 --> 00:19:06,612
equivalent to a Bayes estimator Complete

5130
00:19:07,350 --> 00:19:10,985
Class Theorems. Only Bayes strategies

5140
00:19:11,030 --> 00:19:13,760
are admissible and admissible strategies

5150
00:19:13,805 --> 00:19:17,840
are Bayes. So there's

5160
00:19:17,870 --> 00:19:19,215
probably a lot of interpretations of

5170
00:19:19,232 --> 00:19:21,690
this, but it seems kind of related to

5180
00:19:21,782 --> 00:19:24,800
optimal control or Bayes optimal

5190
00:19:24,875 --> 00:19:27,060
inference, perhaps a little bit more

5200
00:19:27,092 --> 00:19:30,960
keenly. So these are some next

5210
00:19:30,992 --> 00:19:33,420
two slides were contributed by Ali, so

5220
00:19:33,497 --> 00:19:35,115
if you or if anyone familiar in this

5230
00:19:35,132 --> 00:19:37,445
area wants to come on and the discussion

5240
00:19:37,460 --> 00:19:41,190
would be great, but Ali pointed me

5250
00:19:41,207 --> 00:19:42,965
to this book fundamentals of Bayesian

5260
00:19:42,995 --> 00:19:46,845
Epistemology by title Bomb 2022

5270
00:19:46,997 --> 00:19:50,550
table of contents shown here, and some

5280
00:19:50,687 --> 00:19:53,780
challenges and objections to Bayesian

5290
00:19:53,840 --> 00:19:56,565
Epistemology are listed which can be

5300
00:19:56,582 --> 00:20:00,345
read. And then also there's some

5310
00:20:00,422 --> 00:20:03,710
quite interesting logical structures

5320
00:20:03,905 --> 00:20:06,090
which can be read here in terms of their

5330
00:20:06,107 --> 00:20:09,360
premise, theorem and conclusion. In the

5340
00:20:09,392 --> 00:20:12,870
areas of arguments for Bayesianism being

5350
00:20:13,022 --> 00:20:14,985
representation theorem, argument for

5360
00:20:15,017 --> 00:20:17,790
probabilism, the dutch book argument for

5370
00:20:17,807 --> 00:20:20,735
probabilism and the Gradational accuracy

5380
00:20:20,780 --> 00:20:24,795
argument for probabilism. So pretty

5390
00:20:24,947 --> 00:20:28,290
interesting. Back to the

5400
00:20:28,307 --> 00:20:30,710
paper they wrote we have previously

5410
00:20:30,755 --> 00:20:32,360
introduced a reverse engineering

5420
00:20:32,405 --> 00:20:34,365
approach that identifies a class of

5430
00:20:34,382 --> 00:20:35,990
biologically plausible cost functions

5440
00:20:36,020 --> 00:20:38,787
for neural networks. Citation 22

5450
00:20:39,300 --> 00:20:42,980
previous Paper of Isomura Karl Friston

5460
00:20:43,115 --> 00:20:46,880
2020 the paper was reverse engineering

5470
00:20:46,940 --> 00:20:48,660
neural networks to characterize their

5480
00:20:48,692 --> 00:20:51,590
cost functions, the abstracts shown

5490
00:20:51,620 --> 00:20:54,255
here. But this letter considers a class

5500
00:20:54,302 --> 00:20:56,495
of biologically plausible cost functions

5510
00:20:56,585 --> 00:21:00,335
for neural networks using generative

5520
00:21:00,380 --> 00:21:02,285
models based on partially observable

5530
00:21:02,330 --> 00:21:04,075
Markov decision processes.

5540
00:21:05,700 --> 00:21:07,290
We show that neural activity and

5550
00:21:07,307 --> 00:21:09,440
plasticity perform Bayesian inference

5560
00:21:09,470 --> 00:21:11,765
and learning respectively by maximizing

5570
00:21:11,795 --> 00:21:14,465
model evidence. So this is a precursor

5580
00:21:14,570 --> 00:21:18,450
paper from 2020 that is cited and

5590
00:21:18,587 --> 00:21:21,612
foundational for the 2022 paper.

5600
00:21:22,800 --> 00:21:24,762
Here are some figures from that paper.

5610
00:21:25,200 --> 00:21:29,210
They have comparisons among Markov

5620
00:21:29,255 --> 00:21:31,745
decision process scheme and a neural

5630
00:21:31,760 --> 00:21:34,880
network. For example, a Markov decision

5640
00:21:34,940 --> 00:21:36,815
process scheme expressed as a formy

5650
00:21:36,845 --> 00:21:40,355
factor graph based on the formulation

5660
00:21:40,415 --> 00:21:44,690
in Friston. So here is the Markov

5670
00:21:44,720 --> 00:21:48,110
decision process as a formy factor

5680
00:21:48,155 --> 00:21:50,490
graph and on the right side is the

5690
00:21:50,507 --> 00:21:53,760
neural network with the hidden state

5700
00:21:53,792 --> 00:21:56,130
sensory inputs and neural activity and

5710
00:21:56,177 --> 00:22:00,012
some figures and

5720
00:22:00,825 --> 00:22:02,125
concordances.

5730
00:22:06,212 --> 00:22:07,907
And they wrote in this context, the

5740
00:22:07,910 --> 00:22:09,902
neural network can in principle be used

5750
00:22:09,995 --> 00:22:12,202
as a dynamic causal model to estimate

5760
00:22:12,232 --> 00:22:14,122
threshold, constants and implicit

5770
00:22:14,167 --> 00:22:16,627
priors. This reverse engineering speaks

5780
00:22:16,657 --> 00:22:18,347
to estimating the priors used by real

5790
00:22:18,380 --> 00:22:20,752
neuronal systems under ideal Bayesian

5800
00:22:20,782 --> 00:22:23,042
assumptions, sometimes referred to as

5810
00:22:23,090 --> 00:22:26,787
metabasian inference. So they're

5820
00:22:27,212 --> 00:22:31,575
laying out their research agenda and

5830
00:22:32,387 --> 00:22:34,822
much of the work is going to reference

5840
00:22:34,942 --> 00:22:38,222
this earlier paper and other work. And

5850
00:22:38,255 --> 00:22:41,262
then there's also some new integrations

5860
00:22:41,612 --> 00:22:45,077
and especially the maze simulation in

5870
00:22:45,095 --> 00:22:48,412
this paper, and probably more so let's

5880
00:22:48,487 --> 00:22:52,217
find out. Referring to

5890
00:22:52,265 --> 00:22:54,817
the earlier paper, this foundational

5900
00:22:54,877 --> 00:22:56,492
work identified a class of cost

5910
00:22:56,540 --> 00:22:58,372
functions for single layer field feed

5920
00:22:58,417 --> 00:23:00,532
forward neural networks of state coding

5930
00:23:00,547 --> 00:23:02,347
models with a sigmoid or logistic

5940
00:23:02,392 --> 00:23:05,152
activation function. We subsequently

5950
00:23:05,182 --> 00:23:06,427
demonstrated that mathematical

5960
00:23:06,457 --> 00:23:08,267
equivalence between the class of cost

5970
00:23:08,315 --> 00:23:09,827
functions for such neural networks and

5980
00:23:09,845 --> 00:23:11,552
variational free energy under a

5990
00:23:11,570 --> 00:23:13,622
particular form of the generative model,

6000
00:23:13,805 --> 00:23:16,997
which is similar broadly to what the 22

6010
00:23:17,030 --> 00:23:20,977
paper dot. Two, this equivalent licenses

6020
00:23:21,007 --> 00:23:22,757
variational Bayesian inference as a

6030
00:23:22,760 --> 00:23:24,377
fundamental optimization process that

6040
00:23:24,395 --> 00:23:26,342
underlies both the dynamics and function

6050
00:23:26,390 --> 00:23:28,062
of such neural networks.

6060
00:23:30,362 --> 00:23:32,302
However, it remains to be established

6070
00:23:32,332 --> 00:23:35,122
whether the active inference is an apt

6080
00:23:35,167 --> 00:23:37,027
explanation for any given neural network

6090
00:23:37,057 --> 00:23:39,122
that actively exchanges with its

6100
00:23:39,155 --> 00:23:41,462
environment. In this paper, we address

6110
00:23:41,525 --> 00:23:43,622
this inactive or control aspect to

6120
00:23:43,655 --> 00:23:45,577
complete the formal equivalent of neural

6130
00:23:45,607 --> 00:23:47,912
network optimization and the free energy

6140
00:23:47,975 --> 00:23:51,817
principle. So this earlier

6150
00:23:51,877 --> 00:23:55,447
work was not including

6160
00:23:55,567 --> 00:23:58,950
action. And so this paper's key

6170
00:23:59,537 --> 00:24:01,847
addition, as I understand it,

6180
00:24:01,880 --> 00:24:06,992
hopefully, is that they bring

6190
00:24:07,190 --> 00:24:10,967
action more formally into the

6200
00:24:11,165 --> 00:24:14,207
model. And it would

6210
00:24:14,210 --> 00:24:15,677
be interesting to know like what else is

6220
00:24:15,695 --> 00:24:17,747
that change associated with? Or what

6230
00:24:17,780 --> 00:24:20,412
else happens or doesn't?

6240
00:24:23,162 --> 00:24:27,317
Here's some more text about

6250
00:24:27,440 --> 00:24:29,325
the approach that they're going to take,

6260
00:24:30,137 --> 00:24:31,982
and many of these details are going to

6270
00:24:31,985 --> 00:24:33,750
be addressed later on.

6280
00:24:36,887 --> 00:24:39,392
Here's table one glossary of

6290
00:24:39,440 --> 00:24:43,037
expressions, so these will also

6300
00:24:43,100 --> 00:24:47,087
be broadly addressed later

6310
00:24:47,150 --> 00:24:47,775
on.

6320
00:24:50,912 --> 00:24:52,652
Maybe it's useful though just to read

6330
00:24:52,670 --> 00:24:55,072
the first one a canonical neural network

6340
00:24:55,267 --> 00:24:57,457
in this work, the canonical neural

6350
00:24:57,472 --> 00:24:58,822
network is defined by differential

6360
00:24:58,867 --> 00:25:01,547
equations of neural activity derived as

6370
00:25:01,580 --> 00:25:03,547
reduction of realistic neuron models

6380
00:25:03,592 --> 00:25:06,347
through some approximations which give a

6390
00:25:06,380 --> 00:25:08,852
network of rate coding neurons with a

6400
00:25:08,870 --> 00:25:11,522
sigmoid activation function. In

6410
00:25:11,555 --> 00:25:13,297
particular, we consider networks

6420
00:25:13,342 --> 00:25:15,892
comprising a middle layer that involves

6430
00:25:15,952 --> 00:25:18,727
recurrent connections and the output

6440
00:25:18,757 --> 00:25:20,677
layer that provides feedback responses

6450
00:25:20,707 --> 00:25:24,802
to the environment. So some category

6460
00:25:24,907 --> 00:25:28,172
of neural network architecture or

6470
00:25:28,205 --> 00:25:31,397
anatomy, physiology, whatever with

6480
00:25:31,505 --> 00:25:34,512
sensory, cognitive and actionlike

6490
00:25:35,012 --> 00:25:37,352
features in an environment or a

6500
00:25:37,370 --> 00:25:41,242
generative process. So the results

6510
00:25:41,302 --> 00:25:42,087
section,

6520
00:25:46,112 --> 00:25:49,222
they write an overview of equivalence

6530
00:25:49,267 --> 00:25:50,932
between neural networks and variational

6540
00:25:50,947 --> 00:25:53,197
base. First we summarize the formal

6550
00:25:53,242 --> 00:25:54,757
correspondence between neural networks

6560
00:25:54,772 --> 00:25:57,242
and variational base. A biological agent

6570
00:25:57,290 --> 00:25:59,602
is formulated here as an autonomous

6580
00:25:59,632 --> 00:26:01,592
system comprising a network of rate

6590
00:26:01,640 --> 00:26:04,457
coding neurons. Figure one A so here's a

6600
00:26:04,460 --> 00:26:06,837
small figure one A. We'll see it larger

6610
00:26:07,787 --> 00:26:10,097
based upon the assumptions which will be

6620
00:26:10,130 --> 00:26:12,542
brought up later on in a different

6630
00:26:12,665 --> 00:26:16,117
fuller form. The update rule for the ith

6640
00:26:16,177 --> 00:26:19,802
component of phi, which is the

6650
00:26:19,820 --> 00:26:22,592
internal states so the cognitive states

6660
00:26:22,715 --> 00:26:25,522
and the output layer y. So middle layer

6670
00:26:25,567 --> 00:26:27,300
x and output layer y,

6680
00:26:28,862 --> 00:26:31,922
these can be seen as the cognitive and

6690
00:26:31,955 --> 00:26:35,672
the actinF selective aspects which are

6700
00:26:35,705 --> 00:26:39,277
the autonomous states in contrast

6710
00:26:39,307 --> 00:26:41,152
to the particular state of the active

6720
00:26:41,182 --> 00:26:43,322
inference entity which is the whole

6730
00:26:43,355 --> 00:26:45,902
blanket, and the cognitive states so

6740
00:26:45,920 --> 00:26:47,852
including the sensory state. But the

6750
00:26:47,870 --> 00:26:49,852
sensory states can't be directly

6760
00:26:49,957 --> 00:26:52,747
controlled, however action can influence

6770
00:26:52,792 --> 00:26:55,082
them. And so that's what closes the

6780
00:26:55,160 --> 00:26:59,672
causal loop and that

6790
00:26:59,705 --> 00:27:02,227
set of the particular states comprising

6800
00:27:02,257 --> 00:27:05,347
the autonomous states the update rule

6810
00:27:05,392 --> 00:27:08,827
for the ith component of phi is derived

6820
00:27:08,857 --> 00:27:10,367
as the gradient descent on the cost

6830
00:27:10,415 --> 00:27:14,222
function. So the change in that by

6840
00:27:14,330 --> 00:27:18,187
sub I is proportional to a derivative

6850
00:27:18,262 --> 00:27:20,707
on the loss function. This determines

6860
00:27:20,722 --> 00:27:22,252
the dynamics of neural networks

6870
00:27:22,282 --> 00:27:24,097
including their activity and plasticity.

6880
00:27:24,142 --> 00:27:27,032
So. L common loss function O

6890
00:27:27,110 --> 00:27:31,022
observations sensory states by

6900
00:27:31,130 --> 00:27:32,702
internal state comprising the middle and

6910
00:27:32,720 --> 00:27:34,727
output layer neural activity that's the

6920
00:27:34,745 --> 00:27:37,307
rate coding part and synaptic strength w

6930
00:27:37,385 --> 00:27:39,872
the parameterization and other free

6940
00:27:39,905 --> 00:27:41,447
parameters including that that

6950
00:27:41,480 --> 00:27:44,722
characterize L. Then there's the output

6960
00:27:44,767 --> 00:27:48,152
layer activity y is determining the

6970
00:27:48,170 --> 00:27:53,522
network's actions or decisions delta o

6980
00:27:53,630 --> 00:27:56,062
x and y y is outputting action

6990
00:27:56,137 --> 00:27:57,997
environment generative process hidden

7000
00:27:58,042 --> 00:28:01,157
state passing observations to the

7010
00:28:01,235 --> 00:28:03,977
sensory cognitive active layers the

7020
00:28:03,995 --> 00:28:07,362
neural network and that is analogous

7030
00:28:07,862 --> 00:28:09,997
topologically to the variational

7040
00:28:10,042 --> 00:28:13,097
Bayesian formulation in

7050
00:28:13,130 --> 00:28:16,822
figure one B. And so left side gradient

7060
00:28:16,867 --> 00:28:18,317
descent on a neural network cost

7070
00:28:18,365 --> 00:28:19,952
function L determines the dynamics of

7080
00:28:19,970 --> 00:28:22,322
neural activity and plasticity. Thus L

7090
00:28:22,355 --> 00:28:24,202
is sufficient to characterize the neural

7100
00:28:24,232 --> 00:28:28,972
network and then being shown

7110
00:28:29,017 --> 00:28:31,717
next to on the right side variational

7120
00:28:31,777 --> 00:28:33,647
free energy minimization allows an agent

7130
00:28:33,680 --> 00:28:36,127
to self organize, to encode the hidden

7140
00:28:36,157 --> 00:28:38,627
states of the external milieu and to

7150
00:28:38,645 --> 00:28:40,927
make decisions minimizing future risk.

7160
00:28:41,107 --> 00:28:43,697
Here, variational free energy F is

7170
00:28:43,730 --> 00:28:44,972
sufficient to characterize active

7180
00:28:45,005 --> 00:28:47,717
inference and behaviors of the agent.

7190
00:28:47,915 --> 00:28:50,937
So sentence structure parallelism,

7200
00:28:51,287 --> 00:28:54,997
and these two schemes

7210
00:28:55,042 --> 00:28:58,837
or approaches being Linsker and applied

7220
00:28:58,912 --> 00:29:02,250
is a focus of this area.

7230
00:29:05,237 --> 00:29:07,322
So neural networks are minimizing the

7240
00:29:07,355 --> 00:29:09,367
cost function L. In contrast,

7250
00:29:09,427 --> 00:29:11,402
variational Bayesian inference depicts a

7260
00:29:11,420 --> 00:29:12,652
process of updating the prior

7270
00:29:12,682 --> 00:29:16,082
distribution of external states P of

7280
00:29:16,235 --> 00:29:18,352
theta, so the corresponding posterior

7290
00:29:18,382 --> 00:29:20,402
distribution Q of theta based upon the

7300
00:29:20,420 --> 00:29:23,747
sequence of observations. And we see

7310
00:29:23,780 --> 00:29:26,372
other familiar terms from discussions on

7320
00:29:26,405 --> 00:29:28,952
variational DAGs like minimization of

7330
00:29:28,970 --> 00:29:32,462
surprise. And there's some more model

7340
00:29:32,525 --> 00:29:36,767
details shown here. A few points are

7350
00:29:36,815 --> 00:29:39,122
about choosing the family of

7360
00:29:39,155 --> 00:29:41,462
distributions that one is doing

7370
00:29:41,525 --> 00:29:45,572
variational inference with, and that

7380
00:29:45,755 --> 00:29:49,247
allows for the gradient update rules in

7390
00:29:49,280 --> 00:29:52,892
that family of distributions to be maze

7400
00:29:53,015 --> 00:29:55,852
simpler. For example, choosing a linear

7410
00:29:55,882 --> 00:29:58,877
regression with an L two norm. At the

7420
00:29:58,895 --> 00:30:01,232
very least, you can say that it has a

7430
00:30:01,235 --> 00:30:03,917
simple decision rule for being fit.

7440
00:30:04,040 --> 00:30:06,352
I'm sure there's like also counter

7450
00:30:06,457 --> 00:30:08,282
arguments and other algorithms that are

7460
00:30:08,285 --> 00:30:10,652
better and so on. But just to say that a

7470
00:30:10,670 --> 00:30:12,467
simple decision rule in a known family

7480
00:30:12,515 --> 00:30:15,047
of distributions can often be good

7490
00:30:15,080 --> 00:30:18,675
enough as an approximation, if not more

7500
00:30:20,837 --> 00:30:22,622
crucially. According to the Complete

7510
00:30:22,730 --> 00:30:26,992
Class theorem from earlier, a dynamical

7520
00:30:27,052 --> 00:30:29,222
system that minimizes its cost function

7530
00:30:29,405 --> 00:30:31,147
can be viewed as performing Bayesian

7540
00:30:31,192 --> 00:30:32,717
inference under some generative model

7550
00:30:32,765 --> 00:30:35,042
and prior beliefs. The Complete Class

7560
00:30:35,090 --> 00:30:38,512
theorem goes on to describe it ensures

7570
00:30:38,587 --> 00:30:41,042
the presence of a generative model that

7580
00:30:41,090 --> 00:30:43,042
formally corresponds to the above

7590
00:30:43,102 --> 00:30:45,722
defined neural network characterized by

7600
00:30:45,755 --> 00:30:47,827
L. Hence, this speaks to the equivalence

7610
00:30:47,857 --> 00:30:49,442
between the class of neural network cost

7620
00:30:49,490 --> 00:30:50,957
functions and variational free energy

7630
00:30:51,035 --> 00:30:53,767
under such a generative model equation

7640
00:30:53,827 --> 00:30:57,047
one loss function on the time

7650
00:30:57,080 --> 00:31:00,087
series of observations comma parameters.

7660
00:31:00,737 --> 00:31:04,547
Three ines is defined as f the free

7670
00:31:04,580 --> 00:31:08,400
energy function on the same O

7680
00:31:08,837 --> 00:31:11,562
through time comma parameters.

7690
00:31:12,287 --> 00:31:16,747
So there's a parallel being shown

7700
00:31:16,867 --> 00:31:20,342
defined wherein the internal states

7710
00:31:20,390 --> 00:31:24,172
of a network by encode or parameterize

7720
00:31:24,217 --> 00:31:27,012
the posterior expectation theta.

7730
00:31:28,487 --> 00:31:30,707
This mathematical equivalence means that

7740
00:31:30,710 --> 00:31:32,567
an arbitrary neural network in the class

7750
00:31:32,615 --> 00:31:34,897
under consideration is implicitly

7760
00:31:34,942 --> 00:31:36,347
performing active inference through

7770
00:31:36,380 --> 00:31:39,932
variational free energy minimization and

7780
00:31:40,085 --> 00:31:42,257
more is written. But this is one of many

7790
00:31:42,335 --> 00:31:44,925
statements that will be made

7800
00:31:45,437 --> 00:31:50,362
corresponding to correspondences

7810
00:31:50,437 --> 00:31:53,417
between neural network loss function,

7820
00:31:53,615 --> 00:31:56,462
generative model, active free energy

7830
00:31:56,525 --> 00:32:00,462
minimization, and associated formalisms.

7840
00:32:02,612 --> 00:32:04,502
Note that being able to characterize the

7850
00:32:04,520 --> 00:32:06,202
neural network in terms of maximizing

7860
00:32:06,232 --> 00:32:07,427
model evidence lends it in

7870
00:32:07,445 --> 00:32:10,097
explainability in the sense that

7880
00:32:10,130 --> 00:32:12,122
internal neural network states and

7890
00:32:12,155 --> 00:32:14,072
parameters encode Bayesian beliefs or

7900
00:32:14,105 --> 00:32:15,902
expectations about the causes of

7910
00:32:15,920 --> 00:32:18,302
observations. In other words, the

7920
00:32:18,320 --> 00:32:20,257
generative model explains how outcomes

7930
00:32:20,272 --> 00:32:23,357
were generated. However, the Complete

7940
00:32:23,435 --> 00:32:25,517
Class theorem does not specify the form

7950
00:32:25,565 --> 00:32:27,317
of a generative model for any given

7960
00:32:27,365 --> 00:32:31,112
neural network. To address this issue

7970
00:32:31,175 --> 00:32:32,972
in the remainder of the paper, we

7980
00:32:33,005 --> 00:32:34,727
formulate active inference using a

7990
00:32:34,745 --> 00:32:36,997
particular form of partially observable

8000
00:32:37,042 --> 00:32:40,837
Markov decision processes PMDP models

8010
00:32:40,987 --> 00:32:43,532
whose states take binary values. So this

8020
00:32:43,535 --> 00:32:46,202
is one of several simplifications is one

8030
00:32:46,220 --> 00:32:49,217
way to see it or areas for later

8040
00:32:49,265 --> 00:32:52,937
generalization. Figure Two

8050
00:32:53,000 --> 00:32:54,667
in this section, we define a generative

8060
00:32:54,727 --> 00:32:56,597
model and ensuing variational free

8070
00:32:56,630 --> 00:32:58,352
energy that corresponds to a class of

8080
00:32:58,370 --> 00:33:00,752
canonical neural networks that will be

8090
00:33:00,770 --> 00:33:02,617
considered in the subsequent section.

8100
00:33:02,752 --> 00:33:05,282
The internal model is expressed as a

8110
00:33:05,285 --> 00:33:07,577
discrete state space in the form of a

8120
00:33:07,595 --> 00:33:11,702
POMDP figure two. So to

8130
00:33:11,720 --> 00:33:13,887
make figure two larger,

8140
00:33:20,562 --> 00:33:23,650
there's a lot to probably say about this

8150
00:33:24,312 --> 00:33:28,727
bigger. I'll just note

8160
00:33:28,832 --> 00:33:33,325
that the caption is informative and

8170
00:33:33,912 --> 00:33:37,227
some of the highlighted lines. It'll be

8180
00:33:37,245 --> 00:33:39,402
awesome to have the author and other

8190
00:33:39,570 --> 00:33:42,177
people who's familiar with some of the

8200
00:33:42,195 --> 00:33:44,637
differences and symmetries between the,

8210
00:33:44,700 --> 00:33:48,100
for example, bottom and top,

8220
00:33:48,462 --> 00:33:51,537
above and below the observations, and

8230
00:33:51,600 --> 00:33:54,822
also about the role of time and what

8240
00:33:54,855 --> 00:33:57,302
these two risks are. What is fictive

8250
00:33:57,332 --> 00:33:58,312
causality?

8260
00:34:00,537 --> 00:34:06,282
Here's more details on that POMDP then

8270
00:34:06,435 --> 00:34:09,317
equation two. This is in this section

8280
00:34:09,377 --> 00:34:11,082
active inference formulated using a

8290
00:34:11,085 --> 00:34:14,232
postdiction of past decisions. So if it

8300
00:34:14,235 --> 00:34:16,217
was a prediction of future decisions,

8310
00:34:16,277 --> 00:34:19,542
it's the opposite, a postdiction of past

8320
00:34:19,590 --> 00:34:22,572
decisions. Hence, we define the

8330
00:34:22,605 --> 00:34:26,642
generative model as follows PO delta

8340
00:34:26,702 --> 00:34:29,877
s gamma theta, which is the model of

8350
00:34:30,045 --> 00:34:33,482
observations decisions, observations

8360
00:34:33,572 --> 00:34:36,862
decisions, hidden states risk and theta

8370
00:34:39,237 --> 00:34:43,397
theta equals A, b and C constitutes

8380
00:34:43,442 --> 00:34:46,572
a set of parameters and more details are

8390
00:34:46,605 --> 00:34:51,412
provided. This is the familiar notation

8400
00:34:51,912 --> 00:34:55,002
with some slight differences that will

8410
00:34:55,020 --> 00:34:59,012
be described. And equation two reflects

8420
00:34:59,162 --> 00:35:03,177
the factorizability and the

8430
00:35:03,270 --> 00:35:05,582
dimensions and the kind of computational

8440
00:35:05,672 --> 00:35:09,862
tractability expression.

8450
00:35:10,212 --> 00:35:12,567
So that would be interesting to also

8460
00:35:12,615 --> 00:35:16,442
learn about like under what conditions

8470
00:35:16,577 --> 00:35:19,992
can this joint distribution be

8480
00:35:20,040 --> 00:35:23,852
factorized? Under what simplifications

8490
00:35:23,882 --> 00:35:28,827
or constructions the

8500
00:35:28,845 --> 00:35:31,002
agent is making decisions to minimize a

8510
00:35:31,020 --> 00:35:33,327
risk function capital gamma that's on

8520
00:35:33,345 --> 00:35:37,052
the bottom of figure two, victim

8530
00:35:37,082 --> 00:35:39,482
causality. Leading to this gamma.

8540
00:35:39,647 --> 00:35:41,362
Coming from that gamma,

8550
00:35:43,737 --> 00:35:46,277
equation three is shown.

8560
00:35:46,457 --> 00:35:48,827
And to characterize the optimal

8570
00:35:48,857 --> 00:35:50,877
decisions as minimizing expected risk in

8580
00:35:50,895 --> 00:35:52,952
our POMDP model, we use effective

8590
00:35:52,982 --> 00:35:54,702
mapping from the current risk gamma to

8600
00:35:54,720 --> 00:35:57,272
past decisions that's that retro

8610
00:35:57,317 --> 00:36:00,347
addictive fictive causality. Although

8620
00:36:00,392 --> 00:36:02,427
this is not the true causality in the

8630
00:36:02,445 --> 00:36:03,977
real generative process that generates

8640
00:36:04,007 --> 00:36:06,462
sensory data. Here we intend to model

8650
00:36:06,525 --> 00:36:08,252
the manner that an agent subjectively

8660
00:36:08,282 --> 00:36:10,512
evaluates its previous decisions after

8670
00:36:10,575 --> 00:36:13,017
experiencing their consequences. This

8680
00:36:13,065 --> 00:36:14,952
fictive causality is expressed in the

8690
00:36:14,970 --> 00:36:18,702
form of a canonical distribution. So it

8700
00:36:18,720 --> 00:36:21,487
could be other families hypothetically.

8710
00:36:21,912 --> 00:36:24,737
But this equation three is describing

8720
00:36:24,887 --> 00:36:28,150
fictive causality and this interesting

8730
00:36:28,812 --> 00:36:32,567
sign indicates the element

8740
00:36:32,627 --> 00:36:35,147
noise division operator. Also note

8750
00:36:35,192 --> 00:36:36,932
throughout the manuscript the overline

8760
00:36:37,022 --> 00:36:39,072
variable indicates one minus that

8770
00:36:39,105 --> 00:36:42,422
variable. So gamma bar equals one minus

8780
00:36:42,467 --> 00:36:44,772
gamma. Or it can be understood as the

8790
00:36:44,805 --> 00:36:48,037
complement of a statistical probability

8800
00:36:48,387 --> 00:36:50,052
probability of a happening and the

8810
00:36:50,070 --> 00:36:52,017
probability of not a happening in that

8820
00:36:52,065 --> 00:36:53,425
one way.

8830
00:36:56,487 --> 00:36:58,647
Importantly, the agent needs to keep

8840
00:36:58,680 --> 00:37:00,797
selecting good decisions while avoiding

8850
00:37:00,842 --> 00:37:02,597
bad decisions. To this end, equation

8860
00:37:02,642 --> 00:37:04,382
three supposes that the agent learns

8870
00:37:04,397 --> 00:37:06,072
from the failure of decisions by

8880
00:37:06,105 --> 00:37:07,872
assuming that the bad decisions were

8890
00:37:07,905 --> 00:37:10,472
sampled from the opposite of the optimal

8900
00:37:10,517 --> 00:37:14,737
policy. Mapping some more details

8910
00:37:15,612 --> 00:37:19,517
and then by convention, active inference

8920
00:37:19,577 --> 00:37:22,387
uses C to denote the prior preference.

8930
00:37:22,812 --> 00:37:26,867
That's how we've seen the C variable

8940
00:37:27,002 --> 00:37:30,047
in many models as preferences. Prior

8950
00:37:30,092 --> 00:37:32,832
Preference this work uses C to denote a

8960
00:37:32,835 --> 00:37:34,982
mapping to determine a decision

8970
00:37:35,147 --> 00:37:38,417
depending on the previous state. Herein

8980
00:37:38,477 --> 00:37:40,827
the prior preference is implicit in the

8990
00:37:40,845 --> 00:37:43,612
risk function due to construction.

9000
00:37:44,037 --> 00:37:47,522
C does not explicitly appear

9010
00:37:47,642 --> 00:37:50,202
in the inference. Thus it is omitted in

9020
00:37:50,220 --> 00:37:53,277
the following formulations. So that's a

9030
00:37:53,295 --> 00:37:54,942
key point about the notation of the

9040
00:37:54,990 --> 00:37:57,612
variable C and something kind of maybe

9050
00:37:57,675 --> 00:38:01,600
interesting to explore. Equation Four

9060
00:38:02,262 --> 00:38:04,497
variational Bayesian inference refers to

9070
00:38:04,530 --> 00:38:06,602
the process that optimizes the posterior

9080
00:38:06,632 --> 00:38:09,447
belief q of theta based on the mean

9090
00:38:09,480 --> 00:38:11,202
field approximation q of theta is

9100
00:38:11,220 --> 00:38:14,575
expressed as and here is the

9110
00:38:15,912 --> 00:38:20,757
factorization representation of

9120
00:38:20,910 --> 00:38:24,162
the q of theta variational and another

9130
00:38:24,225 --> 00:38:25,677
notation. Note throughout the

9140
00:38:25,695 --> 00:38:28,572
manuscript, bold case variables such as

9150
00:38:28,755 --> 00:38:31,922
bold s subtow denote the posterior

9160
00:38:31,967 --> 00:38:34,547
expectations of the corresponding italic

9170
00:38:34,592 --> 00:38:38,472
case random variables and some

9180
00:38:38,505 --> 00:38:41,022
more details about the model. For

9190
00:38:41,055 --> 00:38:43,862
example, for simplicity, here we suppose

9200
00:38:43,937 --> 00:38:46,647
that state and decision prior D and E

9210
00:38:46,755 --> 00:38:49,827
are fixed, so one could imagine they

9220
00:38:49,845 --> 00:38:52,537
don't have to be, but for simplicity

9230
00:38:53,037 --> 00:38:54,700
they will be. Here,

9240
00:38:56,712 --> 00:38:58,857
under the abovedefined generative model

9250
00:38:58,935 --> 00:39:00,752
and posterior beliefs, the ensuing

9260
00:39:00,782 --> 00:39:02,342
variational free energy is analytically

9270
00:39:02,402 --> 00:39:06,177
expressed as follows equation Five this

9280
00:39:06,195 --> 00:39:09,822
is a variational free energy F and

9290
00:39:09,930 --> 00:39:13,197
recall equation one that it is being

9300
00:39:13,380 --> 00:39:16,167
connected to, juxtapose with,

9310
00:39:16,215 --> 00:39:20,877
etc. The loss function the

9320
00:39:20,895 --> 00:39:22,497
gradient descent on variational free

9330
00:39:22,530 --> 00:39:25,982
energy updates the posterior beliefs

9340
00:39:25,997 --> 00:39:28,322
about hidden states s decisions, delta

9350
00:39:28,367 --> 00:39:31,007
and parameters theta. The optimal

9360
00:39:31,022 --> 00:39:32,447
posterior beliefs that minimize

9370
00:39:32,492 --> 00:39:34,227
variational free energy are obtained as

9380
00:39:34,245 --> 00:39:36,002
the fixed point of the implicit gradient

9390
00:39:36,032 --> 00:39:40,242
descent, which ensures that change in

9400
00:39:40,290 --> 00:39:43,172
F with respect to the change in hidden

9410
00:39:43,217 --> 00:39:46,572
state through time equals zero. And some

9420
00:39:46,605 --> 00:39:49,737
more definitions. All of them are zero,

9430
00:39:49,875 --> 00:39:51,972
that one might be an O, but they're all

9440
00:39:52,005 --> 00:39:55,322
zero. And this is saying the ball

9450
00:39:55,367 --> 00:39:57,867
rolls to the bottom of the hill in this

9460
00:39:57,915 --> 00:39:59,952
gradient descent, and when the rate of

9470
00:39:59,970 --> 00:40:02,597
change is zero, then that is a fixed

9480
00:40:02,642 --> 00:40:05,892
point attractor like dynamic, and that

9490
00:40:05,940 --> 00:40:09,627
can be used as a way to

9500
00:40:09,795 --> 00:40:14,212
incrementally fit statistical models

9510
00:40:15,162 --> 00:40:17,007
like the loss function is used to

9520
00:40:17,010 --> 00:40:20,212
incrementally fit neural networks.

9530
00:40:21,987 --> 00:40:23,627
To explicitly demonstrate the formal

9540
00:40:23,657 --> 00:40:25,017
correspondence with the cost function

9550
00:40:25,065 --> 00:40:26,502
for neural networks considered in the

9560
00:40:26,520 --> 00:40:28,077
next section, we further transformed the

9570
00:40:28,095 --> 00:40:31,197
variational free energy as follows some

9580
00:40:31,305 --> 00:40:33,902
details Using these relationships,

9590
00:40:33,932 --> 00:40:36,252
equation five is transformed into the

9600
00:40:36,270 --> 00:40:38,877
form shown in Figure three. See the

9610
00:40:38,895 --> 00:40:40,437
Methods section variational Free Energy

9620
00:40:40,500 --> 00:40:43,682
for further details. In what follows,

9630
00:40:43,697 --> 00:40:45,567
we demonstrate that the internal states

9640
00:40:45,615 --> 00:40:47,297
of canonical neural networks encode

9650
00:40:47,342 --> 00:40:50,125
posterior beliefs. Here's figure three

9660
00:40:51,237 --> 00:40:53,697
on the top from the caption figure three

9670
00:40:53,730 --> 00:40:56,187
is the mathematical equivalence between

9680
00:40:56,250 --> 00:40:57,782
variational free energy and neural

9690
00:40:57,797 --> 00:40:59,727
network cost functions depicted by one

9700
00:40:59,745 --> 00:41:01,317
to one correspondence of their

9710
00:41:01,365 --> 00:41:04,602
components. Top variational free energy

9720
00:41:04,695 --> 00:41:07,002
transformed from equation five using the

9730
00:41:07,020 --> 00:41:12,152
Bayes theorem and foreshadowing.

9740
00:41:12,182 --> 00:41:15,162
Equation seven. Using this relationship,

9750
00:41:15,300 --> 00:41:17,652
equation seven is transformed into the

9760
00:41:17,670 --> 00:41:19,600
form presented at the bottom of the figure.

20010
00:41:20,537 --> 00:41:23,487
So here's f variational free energy and

20020
00:41:23,550 --> 00:41:26,517
L the neural network cost function and

20030
00:41:26,640 --> 00:41:28,697
different elements as they're

20040
00:41:28,742 --> 00:41:32,125
represented here with some

20050
00:41:33,012 --> 00:41:35,812
resonances and concordance and beyond

20060
00:41:36,762 --> 00:41:39,747
which we can explore, they're being

20070
00:41:39,930 --> 00:41:43,287
shown to be equivalent. And it was

20080
00:41:43,425 --> 00:41:46,167
in the conversation preparing for this

20090
00:41:46,365 --> 00:41:50,412
dot zero with Dean, where we

20100
00:41:50,475 --> 00:41:52,912
saw this as some chromosomes.

20110
00:41:57,912 --> 00:41:59,507
In this section, canonical Neural

20120
00:41:59,522 --> 00:42:01,227
Networks Perform Active Inference in

20130
00:42:01,245 --> 00:42:03,002
this section we identify the neuronal

20140
00:42:03,032 --> 00:42:04,877
substrates that correspond to components

20150
00:42:04,907 --> 00:42:06,452
of the active inference scheme defined

20160
00:42:06,482 --> 00:42:08,727
above. We consider a class of two

20170
00:42:08,745 --> 00:42:10,202
layered neural networks with reafferent

20180
00:42:10,232 --> 00:42:11,892
connections in the middle layer. Figure

20190
00:42:11,940 --> 00:42:15,072
one a those are those connections with

20200
00:42:15,105 --> 00:42:18,637
loops recurrent in the middle layer.

20210
00:42:19,512 --> 00:42:21,252
The modeling of the networks in this

20220
00:42:21,270 --> 00:42:23,207
section, referred to as canonical neural

20230
00:42:23,222 --> 00:42:24,647
networks, is based on the following

20240
00:42:24,692 --> 00:42:25,817
three assumptions that reflect

20250
00:42:25,877 --> 00:42:28,502
physiological knowledge. One gradient

20260
00:42:28,532 --> 00:42:29,967
descent on a cost function l,

20270
00:42:30,015 --> 00:42:31,502
determines the updates of neural

20280
00:42:31,532 --> 00:42:34,622
activity and synaptic weights. Method

20290
00:42:34,667 --> 00:42:37,872
Section neural Networks Neural Two

20300
00:42:37,980 --> 00:42:39,822
assumption two neural activity is

20310
00:42:39,855 --> 00:42:41,777
updated by the weighted sum of inputs

20320
00:42:41,807 --> 00:42:43,377
and its fixed point is expressed in a

20330
00:42:43,395 --> 00:42:45,207
form of a sigmoid or logistic function.

20340
00:42:45,285 --> 00:42:47,522
And assumption three, a modulatory

20350
00:42:47,567 --> 00:42:49,902
factor mediate synaptic plasticity in a

20360
00:42:49,920 --> 00:42:51,187
post hoc manner.

20370
00:42:55,812 --> 00:42:58,422
They write based upon assumption two,

20380
00:42:58,530 --> 00:43:01,227
which is neural activity is updated by

20390
00:43:01,245 --> 00:43:03,077
the weighted sum of inputs and its fixed

20400
00:43:03,107 --> 00:43:05,982
point is expressed in the form of a

20410
00:43:05,985 --> 00:43:09,222
sigmoid or logistic function. Based on

20420
00:43:09,255 --> 00:43:11,327
assumption two, we formulate neural

20430
00:43:11,357 --> 00:43:13,127
activity in the middle layer and output

20440
00:43:13,157 --> 00:43:16,392
layer the autonomous states as

20450
00:43:16,440 --> 00:43:19,975
follows equation six

20460
00:43:21,762 --> 00:43:23,662
without loss of generality,

20470
00:43:25,662 --> 00:43:28,022
equation six can be cast as the gradient

20480
00:43:28,067 --> 00:43:31,842
descent on cost function l. Such a cost

20490
00:43:31,890 --> 00:43:33,467
function can be identified by simply

20500
00:43:33,527 --> 00:43:34,902
integrating the righthand side of

20510
00:43:34,920 --> 00:43:36,792
equation six with respect to x and y,

20520
00:43:36,840 --> 00:43:38,507
consistent with previous treatments.

20530
00:43:38,597 --> 00:43:42,597
Citations because neural activity and

20540
00:43:42,630 --> 00:43:44,787
synaptic plasticity minimize the same

20550
00:43:44,850 --> 00:43:48,192
cost function l, the derivatives of l

20560
00:43:48,315 --> 00:43:50,972
must generate the modulated synaptic

20570
00:43:51,017 --> 00:43:54,167
plasticity under these constraints,

20580
00:43:54,227 --> 00:43:55,647
reflecting assumptions one through

20590
00:43:55,680 --> 00:43:58,302
three, a class of cost functions is

20600
00:43:58,320 --> 00:44:02,247
identified as follows equation seven

20610
00:44:02,430 --> 00:44:05,727
loss function. Awesome to hear somebody

20620
00:44:05,820 --> 00:44:08,212
read this directly.

20630
00:44:10,662 --> 00:44:15,047
So there's a firing rate aspect that's

20640
00:44:15,092 --> 00:44:17,817
related to neural firing in the short

20650
00:44:17,865 --> 00:44:21,752
term more perceptual aspect

20660
00:44:21,932 --> 00:44:24,862
of function. And there's a slower

20670
00:44:25,287 --> 00:44:27,302
neurotransmitter neuroglial

20680
00:44:27,332 --> 00:44:30,700
factormediated learning

20690
00:44:31,812 --> 00:44:33,852
over perhaps a different time scale and

20700
00:44:33,870 --> 00:44:36,102
with some different features, and

20710
00:44:36,120 --> 00:44:38,142
they're being included as a joint model

20720
00:44:38,190 --> 00:44:40,797
of inference. And here that is being

20730
00:44:40,830 --> 00:44:42,937
connected to doing inference on action.

20740
00:44:44,262 --> 00:44:46,322
Synaptic Plasticity in Neural Networks

20750
00:44:46,367 --> 00:44:48,752
so synaptic plasticity rules conjugate

20760
00:44:48,782 --> 00:44:51,102
to the above rate coding model can now

20770
00:44:51,120 --> 00:44:52,677
be expressed as a gradient descent on

20780
00:44:52,695 --> 00:44:54,522
the same cost function l, according to

20790
00:44:54,555 --> 00:44:57,567
assumption one, equations eight and nine

20800
00:44:57,765 --> 00:45:01,172
showing that neural networks

20810
00:45:01,217 --> 00:45:05,517
can integrate those modes of

20820
00:45:05,640 --> 00:45:09,287
firing rate like and synaptic

20830
00:45:09,362 --> 00:45:10,825
modulatory like.

20840
00:45:12,687 --> 00:45:14,622
Neural networks. Cost Functions and

20850
00:45:14,655 --> 00:45:18,447
Variational Free Energy Based on

20860
00:45:18,480 --> 00:45:19,977
the above considerations, we now

20870
00:45:19,995 --> 00:45:21,572
establish the formal correspondence

20880
00:45:21,617 --> 00:45:23,112
between the neural network cost function

20890
00:45:23,175 --> 00:45:26,397
and variational free energy. Using under

20900
00:45:26,430 --> 00:45:27,752
the aforementioned three minimal

20910
00:45:27,782 --> 00:45:29,327
assumptions, we identified the neural

20920
00:45:29,357 --> 00:45:31,422
network cost function as equation seven.

20930
00:45:31,530 --> 00:45:33,332
Equation seven can be transformed.

20940
00:45:33,347 --> 00:45:35,517
Hinton the form shown in figure three

20950
00:45:35,565 --> 00:45:37,527
bottom using sigmoid functions of

20960
00:45:37,545 --> 00:45:41,457
synaptic strengths. So equation seven

20970
00:45:41,610 --> 00:45:45,147
loss function transformed into the

20980
00:45:45,180 --> 00:45:49,900
form shown in figure three bottom.

20990
00:45:58,375 --> 00:45:59,300
Hence,

21000
00:46:03,587 --> 00:46:05,177
this class of cost functions for

21010
00:46:05,195 --> 00:46:06,772
canonical neural networks is formally

21020
00:46:06,817 --> 00:46:09,150
homologous to variational free energy

21030
00:46:09,512 --> 00:46:12,247
under the particular form of the POMDP

21040
00:46:12,292 --> 00:46:13,942
generative model defined in the previous

21050
00:46:14,002 --> 00:46:17,642
section. We obtain this result based on

21060
00:46:17,690 --> 00:46:20,452
analytic derivations without reference

21070
00:46:20,482 --> 00:46:23,017
to the complete class theorem, thereby

21080
00:46:23,077 --> 00:46:25,387
confirming the proposition of equation

21090
00:46:25,462 --> 00:46:29,025
one loss function and free energy.

21100
00:46:29,837 --> 00:46:32,122
This in turn suggests that any canonical

21110
00:46:32,167 --> 00:46:34,022
neural network in this class is

21120
00:46:34,055 --> 00:46:36,687
implicitly performing active inference.

21130
00:46:37,787 --> 00:46:39,997
Table two summarizes the correspondence

21140
00:46:40,042 --> 00:46:41,977
between the quantities of the neural

21150
00:46:42,007 --> 00:46:43,997
network and their homologues in

21160
00:46:44,030 --> 00:46:46,650
variational Bayes. So two,

21170
00:46:48,212 --> 00:46:51,087
a great concordance table.

21180
00:46:51,812 --> 00:46:53,992
On the left side, neural network

21190
00:46:54,052 --> 00:46:56,462
formation. On the right side,

21200
00:46:56,600 --> 00:46:58,737
variational Bayes formulation.

21210
00:46:59,612 --> 00:47:03,197
So just like in figure three,

21220
00:47:03,305 --> 00:47:07,502
we had the two

21230
00:47:07,595 --> 00:47:11,692
long lines. Then table

21240
00:47:11,752 --> 00:47:15,167
two, we have rotated 90

21250
00:47:15,215 --> 00:47:18,902
degrees and the variables for

21260
00:47:18,920 --> 00:47:22,212
different parts of these models

21270
00:47:22,562 --> 00:47:25,725
are laid next to each other.

21280
00:47:28,112 --> 00:47:32,032
So what papers of neural

21290
00:47:32,047 --> 00:47:35,977
networks can we make active

21300
00:47:36,007 --> 00:47:39,572
models for? Is it already done or

21310
00:47:39,605 --> 00:47:42,752
is there just one script that needs to

21320
00:47:42,770 --> 00:47:45,782
be done? And then conversely, what

21330
00:47:45,860 --> 00:47:48,837
interesting, variational Bayesian models

21340
00:47:49,712 --> 00:47:54,075
have interesting applications or

21350
00:47:54,812 --> 00:47:58,702
some other value or information gain

21360
00:47:58,882 --> 00:48:01,172
from being cast as neural networks or

21370
00:48:01,205 --> 00:48:04,142
integrating neural networks into what

21380
00:48:04,190 --> 00:48:07,732
had previously been only analytical

21390
00:48:07,822 --> 00:48:10,322
variational Bayesian models as well as

21400
00:48:10,355 --> 00:48:13,577
the empirical data fitting aspect which

21410
00:48:13,595 --> 00:48:15,377
is related that's highlighted by the

21420
00:48:15,395 --> 00:48:18,742
authors. So, in summary,

21430
00:48:18,802 --> 00:48:20,567
when a neural network minimizes the cost

21440
00:48:20,615 --> 00:48:22,147
function with respect to its activity

21450
00:48:22,192 --> 00:48:24,952
and plasticity the network selforganizes

21460
00:48:24,982 --> 00:48:26,552
to furnish responses that minimize the

21470
00:48:26,570 --> 00:48:28,352
risk implicit in the cost function,

21480
00:48:28,520 --> 00:48:30,527
this biological optimization is

21490
00:48:30,545 --> 00:48:32,267
identical to variational free energy

21500
00:48:32,315 --> 00:48:35,027
minimization under a particular form of

21510
00:48:35,045 --> 00:48:38,152
the POMDP model. Hence, this equivalence

21520
00:48:38,257 --> 00:48:40,072
indicates that minimizing the expected

21530
00:48:40,117 --> 00:48:41,492
risk through variational free energy

21540
00:48:41,540 --> 00:48:43,502
minimization is an inherent property of

21550
00:48:43,520 --> 00:48:45,352
canonical neural networks featuring

21560
00:48:45,382 --> 00:48:48,162
delayed modulation of hebion plasticity.

21570
00:48:49,112 --> 00:48:53,087
Okay, brief seconds to

21580
00:48:53,150 --> 00:48:56,657
view some image memes and

21590
00:48:56,735 --> 00:48:58,437
take a breath in a stretch.

21600
00:49:09,062 --> 00:49:11,372
On the left side, the top panel says

21610
00:49:11,405 --> 00:49:13,147
Epineural network is implicitly

21620
00:49:13,192 --> 00:49:14,937
performing active inference.

21630
00:49:15,812 --> 00:49:19,027
That's awesome. In the middle image

21640
00:49:19,057 --> 00:49:21,837
meme, one simply makes a neural network

21650
00:49:22,487 --> 00:49:24,877
and it is implicitly performing active

21660
00:49:24,907 --> 00:49:27,750
inference. Also question mark.

21670
00:49:28,562 --> 00:49:31,397
And then in the right image meme, there

21680
00:49:31,430 --> 00:49:33,727
are two pieces of paper neural network

21690
00:49:33,832 --> 00:49:35,602
and implicit performance of active

21700
00:49:35,632 --> 00:49:37,622
inference. Corporate needs you to find

21710
00:49:37,655 --> 00:49:39,227
the differences between this picture and

21720
00:49:39,245 --> 00:49:42,692
this picture. And here is the paper.

21730
00:49:42,890 --> 00:49:44,412
They're the same picture.

21740
00:49:45,812 --> 00:49:49,275
So the previous sections have

21750
00:49:50,162 --> 00:49:54,167
successfully extended the

21760
00:49:54,365 --> 00:49:57,517
variational Bayes meets inference.

21770
00:49:57,577 --> 00:50:00,922
Neural network results

21780
00:50:01,042 --> 00:50:06,087
from the 2020 paper with an action loop

21790
00:50:06,437 --> 00:50:09,647
and a loss function only on the

21800
00:50:09,680 --> 00:50:13,082
autonomous states. So that was the

21810
00:50:13,235 --> 00:50:17,197
conceptual and technical feature

21820
00:50:17,392 --> 00:50:21,225
that this paper brought in.

21830
00:50:22,187 --> 00:50:23,747
Again, it'll be awesome to hear the

21840
00:50:23,780 --> 00:50:26,722
author describe it more and differently.

21850
00:50:26,917 --> 00:50:29,432
And then in this part of the paper,

21860
00:50:29,585 --> 00:50:33,592
they turn from that kind of analytical

21870
00:50:33,727 --> 00:50:37,597
theoretical towards some numerical

21880
00:50:37,717 --> 00:50:40,362
simulations in MATLAB.

21890
00:50:41,312 --> 00:50:43,547
Here we demonstrate the performance of

21900
00:50:43,580 --> 00:50:45,742
canonical neural networks using maze

21910
00:50:45,802 --> 00:50:48,637
tasks. As an example of a delayed reward

21920
00:50:48,712 --> 00:50:52,232
task, the agent comprised the

21930
00:50:52,235 --> 00:50:54,277
aforementioned canonical neural

21940
00:50:54,307 --> 00:50:57,872
networks. Figure four a thus it

21950
00:50:57,905 --> 00:50:59,897
implicitly performs active inference by

21960
00:50:59,930 --> 00:51:02,147
minimizing variational free energy. So

21970
00:51:02,180 --> 00:51:04,997
now some entity or agent is going to be

21980
00:51:05,030 --> 00:51:09,150
constructed and numerically simulated to

21990
00:51:09,737 --> 00:51:16,207
support some of the aspects

22000
00:51:16,222 --> 00:51:18,912
of their model and point towards utility

22010
00:51:19,562 --> 00:51:21,975
in other settings. So here's figure four

22020
00:51:22,412 --> 00:51:24,802
simulation of neural networks solving

22030
00:51:24,907 --> 00:51:26,562
maze tasks.

22040
00:51:28,562 --> 00:51:33,000
In part A, there is the architecture of

22050
00:51:33,362 --> 00:51:37,217
the agent sensory input layer O

22060
00:51:37,265 --> 00:51:41,112
of T synaptic weights

22070
00:51:42,062 --> 00:51:45,375
into the middle layer x internal states

22080
00:51:47,762 --> 00:51:51,217
and the output layer y decision action

22090
00:51:51,352 --> 00:51:55,200
with risk gamma of T.

22100
00:51:57,437 --> 00:52:00,997
The sensation comes in a neural network

22110
00:52:01,192 --> 00:52:03,237
then outputs a decision.

22120
00:52:04,937 --> 00:52:08,612
There's some task that the

22130
00:52:08,750 --> 00:52:13,050
entity must perform

22140
00:52:14,312 --> 00:52:17,972
which is to

22150
00:52:18,005 --> 00:52:20,672
move towards the goal from the start

22160
00:52:20,855 --> 00:52:23,337
across this lateral maze.

22170
00:52:23,912 --> 00:52:27,377
So one could imagine that if it

22180
00:52:27,395 --> 00:52:30,352
were just a hallway with no maze

22190
00:52:30,382 --> 00:52:33,347
features, simple strategies would be

22200
00:52:33,380 --> 00:52:36,137
very overfit but effective like always

22210
00:52:36,200 --> 00:52:40,097
move simply towards the goal. Whereas in

22220
00:52:40,130 --> 00:52:43,052
more complex settings, which this is an

22230
00:52:43,070 --> 00:52:46,867
example of where there's uncertainty

22240
00:52:47,002 --> 00:52:50,107
as well as many local optima.

22250
00:52:50,272 --> 00:52:52,997
So one has to sometimes take one or two

22260
00:52:53,030 --> 00:52:55,352
or three or four or more steps or

22270
00:52:55,370 --> 00:52:59,112
however many to get closer to the goal

22280
00:53:00,137 --> 00:53:02,357
and sometimes may not know, for example

22290
00:53:02,435 --> 00:53:06,997
how long those backtracking situations

22300
00:53:07,042 --> 00:53:09,662
are going to be and all these other

22310
00:53:09,725 --> 00:53:11,925
complexities for which this maze example

22320
00:53:12,587 --> 00:53:17,872
is symbolic

22330
00:53:17,992 --> 00:53:21,227
of. So maybe there's some interesting

22340
00:53:21,320 --> 00:53:23,477
mythos maze connections and

22350
00:53:23,495 --> 00:53:26,625
computational and here's some

22360
00:53:27,062 --> 00:53:31,287
performance measures on the maze task

22370
00:53:31,862 --> 00:53:34,022
with the neural network entity. This

22380
00:53:34,055 --> 00:53:37,577
way, before training,

22390
00:53:37,670 --> 00:53:40,192
the agent moved to a random direction,

22400
00:53:40,252 --> 00:53:41,927
each step resulting in a failure to

22410
00:53:41,945 --> 00:53:44,237
reach the goal position right end within

22420
00:53:44,300 --> 00:53:46,502
the time limit. During training, the

22430
00:53:46,520 --> 00:53:48,052
neural network updated synaptic

22440
00:53:48,082 --> 00:53:49,627
strengths depending on its neural

22450
00:53:49,657 --> 00:53:51,917
activity and ensuing outcomes I e.

22460
00:53:51,965 --> 00:53:55,627
Risk. This training comprised

22470
00:53:55,657 --> 00:53:58,062
a cycle of action and learning phases.

22480
00:53:58,937 --> 00:54:00,877
This treatment renders neural activity

22490
00:54:00,907 --> 00:54:02,492
and adaptive behaviors of the agent

22500
00:54:02,540 --> 00:54:04,577
highly explainable and manipulatable in

22510
00:54:04,595 --> 00:54:06,667
terms of the appropriate prior beliefs

22520
00:54:06,802 --> 00:54:09,377
implicit in firing thresholds for a

22530
00:54:09,395 --> 00:54:11,747
given task or environment. In other

22540
00:54:11,780 --> 00:54:13,972
words, these results suggest that firing

22550
00:54:14,017 --> 00:54:15,727
thresholds are the neuronal substrates

22560
00:54:15,757 --> 00:54:18,467
that encode state and decision priors as

22570
00:54:18,515 --> 00:54:21,900
predicted. Mathematically big if true.

22580
00:54:24,287 --> 00:54:26,477
Furthermore, when the updating of

22590
00:54:26,495 --> 00:54:30,722
parameters is slow across these two now

22600
00:54:30,905 --> 00:54:34,082
linked domains parameters of the

22610
00:54:34,085 --> 00:54:36,092
variational Bayesian autonomous state

22620
00:54:36,140 --> 00:54:39,292
inference and the neural network loss

22630
00:54:39,352 --> 00:54:42,742
function parameters when the updating

22640
00:54:42,802 --> 00:54:45,592
of these parameters are slow in relation

22650
00:54:45,652 --> 00:54:48,677
to the experimental observations, the

22660
00:54:48,695 --> 00:54:50,072
parameters can be estimated through

22670
00:54:50,105 --> 00:54:52,342
Bayesian inference based on empirically

22680
00:54:52,402 --> 00:54:54,847
observed neuronal response curve method.

22690
00:54:54,892 --> 00:54:57,692
Section data Analysis for details using

22700
00:54:57,740 --> 00:54:59,797
this approach, we estimated implicit

22710
00:54:59,842 --> 00:55:03,887
prior E, which is encoded by PSI from

22720
00:55:03,950 --> 00:55:06,292
sequences of neural activity generated

22730
00:55:06,427 --> 00:55:08,717
from the synthetic neural networks used

22740
00:55:08,765 --> 00:55:10,562
in the simulations reported in figure

22750
00:55:10,625 --> 00:55:13,882
four. We confirmed that this estimator

22760
00:55:13,972 --> 00:55:16,922
was a good approximation to the true e.

22770
00:55:17,105 --> 00:55:20,072
So that's also pretty interesting. This

22780
00:55:20,105 --> 00:55:23,837
is showing they don't just

22790
00:55:23,900 --> 00:55:27,947
lay out this architecture and show

22800
00:55:28,055 --> 00:55:32,227
that it's possible to fulfill this maze

22810
00:55:32,257 --> 00:55:36,450
task with the best whatever.

22820
00:55:37,037 --> 00:55:39,427
It's not a classification accuracy

22830
00:55:39,532 --> 00:55:41,562
imperative alone.

22840
00:55:42,662 --> 00:55:47,467
They're describing that from empirically

22850
00:55:47,527 --> 00:55:49,437
observed neuronal responses,

22860
00:55:50,912 --> 00:55:53,287
which is to say the experimenters

22870
00:55:53,362 --> 00:55:55,927
observation the sequences of neural

22880
00:55:55,957 --> 00:55:57,727
activity generated from the synthetic

22890
00:55:57,757 --> 00:56:00,525
neural networks used in that figure

22900
00:56:01,637 --> 00:56:04,702
numerically. So statistically,

22910
00:56:04,882 --> 00:56:07,042
that estimator was a good approximation

22920
00:56:07,102 --> 00:56:11,117
to the true e. Figure five a so

22930
00:56:11,165 --> 00:56:12,525
here's figure five.

22940
00:56:14,237 --> 00:56:17,752
Estimation of implicit priors enables

22950
00:56:17,782 --> 00:56:20,175
the prediction of subsequent learning.

22960
00:56:21,212 --> 00:56:24,900
So that's pretty interesting and

22970
00:56:25,262 --> 00:56:28,532
will be great to hear what each of the

22980
00:56:28,535 --> 00:56:31,447
axes are and what all the variables

22990
00:56:31,492 --> 00:56:35,672
mean. With this

23000
00:56:35,855 --> 00:56:39,217
setup in place, they did some numerical

23010
00:56:39,277 --> 00:56:42,227
validation and talked a little bit more

23020
00:56:42,245 --> 00:56:46,082
about fitting data from this

23030
00:56:46,235 --> 00:56:48,000
simulation model.

23040
00:56:51,137 --> 00:56:54,677
Here's the discussion section. So the

23050
00:56:54,695 --> 00:56:57,312
first paragraph of the discussion

23060
00:56:57,812 --> 00:57:00,377
biological organisms formulate plans to

23070
00:57:00,395 --> 00:57:02,822
minimize future risks. In this work, we

23080
00:57:02,855 --> 00:57:04,427
captured this characteristic in

23090
00:57:04,445 --> 00:57:06,092
biologically plausible terms under

23100
00:57:06,140 --> 00:57:08,762
minimal assumptions. We Deneve simple

23110
00:57:08,825 --> 00:57:10,442
differential equations that can be

23120
00:57:10,490 --> 00:57:12,302
plausibly interpreted in terms of a

23130
00:57:12,320 --> 00:57:14,377
neural network architecture that entails

23140
00:57:14,407 --> 00:57:15,902
degrees of freedom with respect to

23150
00:57:15,920 --> 00:57:17,902
certain free parameters, e. G firing

23160
00:57:17,932 --> 00:57:20,522
threshold. These three parameters play

23170
00:57:20,555 --> 00:57:22,927
the role of prior beliefs in variational

23180
00:57:22,957 --> 00:57:25,852
Bayesian formulation. Thus,

23190
00:57:26,032 --> 00:57:28,427
the accuracies of inferences and

23200
00:57:28,445 --> 00:57:31,102
decisions depend upon prior beliefs

23210
00:57:31,207 --> 00:57:33,832
implicit in neural networks. And here's

23220
00:57:33,847 --> 00:57:36,682
some more stable diffusion ant neural

23230
00:57:36,697 --> 00:57:40,587
network ant gain neural network

23240
00:57:42,587 --> 00:57:45,347
so some more summarization of what they

23250
00:57:45,380 --> 00:57:48,527
did based on the view of the brain as an

23260
00:57:48,545 --> 00:57:50,947
agent that performs Bayesian inference.

23270
00:57:51,142 --> 00:57:53,227
Internal representation of Bayesian

23280
00:57:53,257 --> 00:57:55,892
belief updating have been proposed which

23290
00:57:55,940 --> 00:57:58,202
enables neural networks to store and

23300
00:57:58,220 --> 00:58:01,367
recall spiking sequences eight learn

23310
00:58:01,415 --> 00:58:03,577
temporal dynamics and causal hierarchy

23320
00:58:03,682 --> 00:58:07,027
nine. Extract hidden causes ten, solve

23330
00:58:07,057 --> 00:58:10,022
maze tasks eleven, and make plans to

23340
00:58:10,055 --> 00:58:12,217
control robots twelve. So citations

23350
00:58:12,277 --> 00:58:14,700
eight through twelve listed here.

23360
00:58:16,187 --> 00:58:18,877
In these approaches, the update rules

23370
00:58:18,907 --> 00:58:20,867
are generally derived from Bayesian cost

23380
00:58:20,915 --> 00:58:23,417
functions e. G variational free energy.

23390
00:58:23,615 --> 00:58:25,892
However, the precise relationship

23400
00:58:26,015 --> 00:58:28,127
between these update rules and the

23410
00:58:28,145 --> 00:58:30,422
neural activity and plasticity of

23420
00:58:30,455 --> 00:58:32,897
canonical neural networks has yet to be

23430
00:58:32,930 --> 00:58:34,287
fully established.

23440
00:58:37,337 --> 00:58:40,117
We identified a onetoone correspondence

23450
00:58:40,177 --> 00:58:42,302
between neural network architecture and

23460
00:58:42,320 --> 00:58:44,822
a specific POMDP implicit in that

23470
00:58:44,855 --> 00:58:48,502
network. Equation two speaks

23480
00:58:48,532 --> 00:58:50,852
to a unique POMDP model consistent with

23490
00:58:50,870 --> 00:58:52,657
the neural network architecture defined

23500
00:58:52,672 --> 00:58:55,172
in equation six, where their

23510
00:58:55,205 --> 00:58:57,022
correspondences are summarized in table

23520
00:58:57,067 --> 00:59:01,112
two and the figures. This means

23530
00:59:01,175 --> 00:59:03,637
that our scheme can be used to identify

23540
00:59:03,712 --> 00:59:06,872
the form of the POMDP given an

23550
00:59:06,905 --> 00:59:09,787
observable circuit structure. Moreover,

23560
00:59:09,862 --> 00:59:11,827
the free parameters zhat parameterize

23570
00:59:11,857 --> 00:59:13,787
equation six can be estimated using

23580
00:59:13,850 --> 00:59:17,552
equation 24. This means that the

23590
00:59:17,570 --> 00:59:19,057
generative model and ensuring

23600
00:59:19,147 --> 00:59:21,022
variational free energy can in principle

23610
00:59:21,067 --> 00:59:23,550
be reconstructed from empirical data.

23620
00:59:24,212 --> 00:59:27,197
This offers a formal characterization of

23630
00:59:27,230 --> 00:59:28,952
implicit Bayesian models entailed by

23640
00:59:28,970 --> 00:59:31,352
neural circuits, thereby enabling a

23650
00:59:31,370 --> 00:59:34,187
prediction of subsequent learning. So

23660
00:59:34,325 --> 00:59:36,825
what can be done with this?

23670
00:59:37,562 --> 00:59:40,725
What is this new?

23680
00:59:41,687 --> 00:59:45,152
What is new here? Does this second

23690
00:59:45,245 --> 00:59:48,622
selection fully

23700
00:59:48,667 --> 00:59:51,150
establish the precise relationship

23710
00:59:51,812 --> 00:59:54,932
between these update rules and the

23720
00:59:54,935 --> 00:59:56,777
neural activity and plasticity of

23730
00:59:56,795 --> 00:59:58,512
canonical neural networks.

23740
01:00:03,212 --> 01:00:05,722
Here is a discussion section on hebion

23750
01:00:05,767 --> 01:00:08,287
plasticity, neurotransmitters and glia

23760
01:00:08,437 --> 01:00:11,337
with a lot of citations listed.

23770
01:00:11,687 --> 01:00:14,417
And here is just one interesting

23780
01:00:14,615 --> 01:00:16,997
followon discussion from the

23790
01:00:17,105 --> 01:00:20,092
computational aspects. Neurocognitive

23800
01:00:20,152 --> 01:00:21,902
and computational aspects of heavy and

23810
01:00:21,920 --> 01:00:25,502
plasticity is these modulations have

23820
01:00:25,520 --> 01:00:27,562
been observed empirically with various

23830
01:00:27,637 --> 01:00:30,307
neuromodulators and neurotransmitters

23840
01:00:30,397 --> 01:00:33,472
such as Dopamine, Noradrenaline,

23850
01:00:33,592 --> 01:00:37,162
Lescreen, and GABA, as well as glial

23860
01:00:37,237 --> 01:00:40,337
factors. So here's a picture by

23870
01:00:40,400 --> 01:00:43,887
Alexandra Michaelova Cultured astrocytes

23880
01:00:44,312 --> 01:00:46,192
release, signaling and growth factors

23890
01:00:46,252 --> 01:00:48,337
that regulate proper neuronal

23900
01:00:48,412 --> 01:00:50,550
development so Cool,

23910
01:00:51,212 --> 01:00:52,425
Glial, Pick,

23920
01:00:54,437 --> 01:00:57,347
Dopamine and reinforcement learning. In

23930
01:00:57,380 --> 01:00:59,552
particular, a delayed modulation of

23940
01:00:59,570 --> 01:01:02,072
synaptic plasticity is well known with

23950
01:01:02,105 --> 01:01:05,507
Dopamine neurons citations 35 through

23960
01:01:05,585 --> 01:01:09,227
37. Those citations are

23970
01:01:09,395 --> 01:01:13,037
listed here. This speaks to a learning

23980
01:01:13,100 --> 01:01:14,782
scheme that is conceptually distinct

23990
01:01:14,797 --> 01:01:16,217
from standard reinforcement learning

24000
01:01:16,265 --> 01:01:18,922
algorithms, such as the temporal

24010
01:01:18,967 --> 01:01:20,752
difference learning with actorcritic

24020
01:01:20,782 --> 01:01:23,087
model based on state action value

24030
01:01:23,150 --> 01:01:25,697
objective function. Please see the

24040
01:01:25,730 --> 01:01:29,047
previous work citation 50 for a detailed

24050
01:01:29,092 --> 01:01:31,052
comparison between active inference and

24060
01:01:31,070 --> 01:01:34,462
reinforcement learning that is state

24070
01:01:34,537 --> 01:01:37,627
ball par Karl Friston active inference

24080
01:01:37,657 --> 01:01:41,327
demystified and compared from 2021 and

24090
01:01:41,345 --> 01:01:44,042
that's also active model stream number

24100
01:01:44,090 --> 01:01:48,052
two. One, we mathematically demonstrated

24110
01:01:48,082 --> 01:01:50,327
that such plasticity enhances the

24120
01:01:50,345 --> 01:01:52,897
association between the pre post mapping

24130
01:01:53,017 --> 01:01:55,252
and the future value of the modulatory

24140
01:01:55,282 --> 01:01:57,902
factor, where the latter is cast as a

24150
01:01:57,920 --> 01:02:00,347
risk function. This means that

24160
01:02:00,380 --> 01:02:03,077
postsynaptic neurons selforganized to

24170
01:02:03,095 --> 01:02:05,537
react in a manner that minimizes future

24180
01:02:05,600 --> 01:02:09,347
risk. So the neural network had three

24190
01:02:09,380 --> 01:02:12,167
layers. It's the second and the third

24200
01:02:12,215 --> 01:02:15,517
layer, not the initial sensory layer,

24210
01:02:15,577 --> 01:02:18,197
but the second and the third layer, the

24220
01:02:18,230 --> 01:02:21,242
cognitive and the active states, which

24230
01:02:21,290 --> 01:02:25,247
are the autonomous states of the

24240
01:02:25,280 --> 01:02:31,172
particular state. So that's quite

24250
01:02:31,355 --> 01:02:34,687
interesting the self organization

24260
01:02:34,762 --> 01:02:38,372
of synaptic neurons to

24270
01:02:38,405 --> 01:02:40,592
react in a manner that minimizes future

24280
01:02:40,640 --> 01:02:44,317
risk. Crucially, this computation

24290
01:02:44,377 --> 01:02:46,132
corresponds formally to variational

24300
01:02:46,147 --> 01:02:47,807
Bayesian inference under a particular

24310
01:02:47,885 --> 01:02:49,927
form of Pom DP generative model,

24320
01:02:50,032 --> 01:02:51,802
suggesting that the delayed modulation

24330
01:02:51,832 --> 01:02:54,742
of Hebbian plasticity is a realization

24340
01:02:54,802 --> 01:02:58,642
of active inference and regionally

24350
01:02:58,702 --> 01:03:01,312
specific projections of neuromodulators

24360
01:03:01,462 --> 01:03:03,547
may allow each brain region to optimize

24370
01:03:03,592 --> 01:03:05,702
activity to minimize risk and leverage a

24380
01:03:05,720 --> 01:03:08,227
hierarchical generative model implicit

24390
01:03:08,257 --> 01:03:10,962
in cortical and subcortical hierarchies.

24400
01:03:11,687 --> 01:03:13,427
This is reminiscent of theories of

24410
01:03:13,445 --> 01:03:15,527
neuromodulator and meta learning

24420
01:03:15,620 --> 01:03:19,162
developed previously. Citation 52 Doya

24430
01:03:19,312 --> 01:03:23,112
2002 metal learning and neuromodulator

24440
01:03:23,462 --> 01:03:27,592
cool. Our work may be potentially useful

24450
01:03:27,727 --> 01:03:30,122
when casting these theories in terms of

24460
01:03:30,155 --> 01:03:32,747
generative model and variational free

24470
01:03:32,780 --> 01:03:34,362
energy minimization.

24480
01:03:37,262 --> 01:03:40,352
They then return the discussion to the

24490
01:03:40,370 --> 01:03:42,382
complete class theorem and neural

24500
01:03:42,397 --> 01:03:45,022
networks. So the Complete Class Theorem

24510
01:03:45,217 --> 01:03:48,902
same citations from before ensures that

24520
01:03:48,920 --> 01:03:51,227
any neural network whose activity and

24530
01:03:51,245 --> 01:03:53,042
plasticity minimize the same cost

24540
01:03:53,090 --> 01:03:55,627
function can be cast as performing

24550
01:03:55,657 --> 01:03:57,857
Bayesian inference. However,

24560
01:03:57,935 --> 01:03:59,422
identifying the implicit generative

24570
01:03:59,467 --> 01:04:01,657
model that underwrites any canonical

24580
01:04:01,747 --> 01:04:03,727
neural network is a more delicate

24590
01:04:03,757 --> 01:04:05,147
problem, because the theorem does not

24600
01:04:05,180 --> 01:04:08,312
specify a form of the generative model

24610
01:04:08,450 --> 01:04:10,812
for a given canonical neural network.

24620
01:04:12,512 --> 01:04:15,302
Which is pretty interesting. Is that to

24630
01:04:15,320 --> 01:04:16,597
say that the form of the generative

24640
01:04:16,642 --> 01:04:20,477
model as modeled is

24650
01:04:20,645 --> 01:04:24,437
different in what ways? From the given

24660
01:04:24,500 --> 01:04:28,597
canonical neural network, the posterior

24670
01:04:28,642 --> 01:04:30,277
beliefs are largely shaped by prior

24680
01:04:30,307 --> 01:04:31,952
beliefs, making it challenging to

24690
01:04:31,970 --> 01:04:33,697
identify the generative model by simply

24700
01:04:33,742 --> 01:04:36,497
observing systemic dynamics. To this

24710
01:04:36,530 --> 01:04:38,402
end, it is necessary to commit to a

24720
01:04:38,420 --> 01:04:40,562
particular form of the generative model

24730
01:04:40,700 --> 01:04:43,547
and elucidate how posterior beliefs are

24740
01:04:43,580 --> 01:04:45,427
encoded or parameterized by the neural

24750
01:04:45,457 --> 01:04:48,127
network states. This work addresses

24760
01:04:48,157 --> 01:04:50,482
these issues by establishing a reverse

24770
01:04:50,497 --> 01:04:52,802
engineering approach to identify a

24780
01:04:52,820 --> 01:04:56,062
generative model implicit in a canonical

24790
01:04:56,212 --> 01:04:59,902
neural network, thereby establishing

24800
01:04:59,932 --> 01:05:02,012
onetoone correspondences between their

24810
01:05:02,075 --> 01:05:05,102
components. Remarkably, a network of

24820
01:05:05,120 --> 01:05:06,727
rate coding models with sigmoid

24830
01:05:06,757 --> 01:05:08,782
activation function formally corresponds

24840
01:05:08,797 --> 01:05:11,487
to a class of POMDP models,

24850
01:05:11,837 --> 01:05:14,317
which provide an analytically trackable

24860
01:05:14,377 --> 01:05:17,047
example of the present equivalents.

24870
01:05:17,242 --> 01:05:18,992
Please refer to the previous paper

24880
01:05:19,040 --> 01:05:22,172
citation 22 for further discussion. So

24890
01:05:22,205 --> 01:05:24,162
some of the analytical details,

24900
01:05:24,962 --> 01:05:28,575
especially on the inferential side

24910
01:05:29,012 --> 01:05:34,207
cognitive side burr

24920
01:05:34,372 --> 01:05:37,575
captured in the earlier paper.

24930
01:05:38,687 --> 01:05:45,352
This paper goes further into mapping

24940
01:05:45,457 --> 01:05:49,027
the potentially necessary

24950
01:05:49,132 --> 01:05:52,577
and sufficient aspects of the

24960
01:05:52,595 --> 01:05:55,847
particular entity, which is to say the

24970
01:05:55,880 --> 01:05:59,252
risk minimizing features of the

24980
01:05:59,270 --> 01:06:02,102
autonomous states with respect to the

24990
01:06:02,120 --> 01:06:03,952
entire particular states, including

25000
01:06:03,982 --> 01:06:07,800
sensory states. Connecting that

25010
01:06:09,662 --> 01:06:12,592
back of the envelope verbally

25020
01:06:12,652 --> 01:06:16,050
expressible formulation to

25030
01:06:17,387 --> 01:06:21,112
some complete class of neural networks.

25040
01:06:21,262 --> 01:06:23,912
So what's outside of the complete class,

25050
01:06:23,975 --> 01:06:26,372
and why? And then what groups within the

25060
01:06:26,405 --> 01:06:29,550
class have special or different

25070
01:06:30,437 --> 01:06:34,477
features? It is remarkable

25080
01:06:34,582 --> 01:06:36,377
that the proposed equivalence can be

25090
01:06:36,395 --> 01:06:37,997
leveraged to identify a generative model

25100
01:06:38,030 --> 01:06:39,397
zhat an arbitrary neural network

25110
01:06:39,442 --> 01:06:42,362
implicitly employs this contrast with

25120
01:06:42,425 --> 01:06:44,312
naive neural network models that address

25130
01:06:44,375 --> 01:06:46,502
only the dynamics of neural activity and

25140
01:06:46,520 --> 01:06:50,287
plasticity. If the generative

25150
01:06:50,362 --> 01:06:51,967
model differs from the true generative

25160
01:06:52,027 --> 01:06:54,577
process that generates the sensory

25170
01:06:54,607 --> 01:06:57,377
input, inferences and decisions are

25180
01:06:57,395 --> 01:06:59,912
biased, ie. Suboptimal relative to base

25190
01:06:59,975 --> 01:07:01,892
optimal inferences and decisions based

25200
01:07:01,940 --> 01:07:04,327
upon the right sort of beliefs. Prior

25210
01:07:04,357 --> 01:07:08,137
beliefs in general, the implicit priors

25220
01:07:08,212 --> 01:07:10,397
may or may not be equal to the true

25230
01:07:10,430 --> 01:07:12,667
priors. Thus, a generic neural network

25240
01:07:12,727 --> 01:07:14,712
is typically suboptimal.

25250
01:07:15,062 --> 01:07:17,777
Nevertheless, these implicit priors can

25260
01:07:17,795 --> 01:07:20,422
be optimized by updating free parameters

25270
01:07:20,542 --> 01:07:24,612
e. G threshold factors, phi PSI

25280
01:07:25,562 --> 01:07:27,782
based on the gradient descent on cost

25290
01:07:27,860 --> 01:07:30,422
function l. By updating the free

25300
01:07:30,455 --> 01:07:33,412
parameters, the network will eventually

25310
01:07:33,487 --> 01:07:36,572
in principle become Bayes optimal for

25320
01:07:36,605 --> 01:07:39,797
any given task. In essence, when the

25330
01:07:39,830 --> 01:07:41,647
cost function is minimized with respect

25340
01:07:41,692 --> 01:07:45,067
to neural activity, synaptic strengths,

25350
01:07:45,127 --> 01:07:46,547
and any other constants that

25360
01:07:46,580 --> 01:07:48,225
characterize the cost function,

25370
01:07:50,387 --> 01:07:52,472
the cost function becomes equivalent to

25380
01:07:52,505 --> 01:07:55,102
variational free energy with the optimal

25390
01:07:55,132 --> 01:07:56,412
prior beliefs.

25400
01:08:00,750 --> 01:08:04,190
So the cost function for the neural

25410
01:08:04,220 --> 01:08:07,450
network activity and synaptic strengths

25420
01:08:08,100 --> 01:08:12,435
underlying the loss function are

25430
01:08:12,467 --> 01:08:16,460
equivalent to the kind of gradient

25440
01:08:16,505 --> 01:08:20,045
descent enabled variational

25450
01:08:20,135 --> 01:08:23,535
free energy minimization under the

25460
01:08:23,567 --> 01:08:27,250
Bayes optimality scenario

25470
01:08:29,400 --> 01:08:31,150
from a risk perspective.

25480
01:08:32,100 --> 01:08:34,935
Simultaneously, the expected risk is

25490
01:08:34,967 --> 01:08:36,810
minimized because variational free

25500
01:08:36,842 --> 01:08:39,915
energy is minimized only when the

25510
01:08:39,932 --> 01:08:43,530
precision of the risk gamma is

25520
01:08:43,577 --> 01:08:47,060
maximized. C method section generative

25530
01:08:47,105 --> 01:08:50,625
model for further details. Very

25540
01:08:50,687 --> 01:08:55,212
interesting. They then say

25550
01:08:55,650 --> 01:08:58,140
the class of neural networks we consider

25560
01:08:58,232 --> 01:09:00,620
can be viewed as a class of reservoir

25570
01:09:00,710 --> 01:09:04,905
networks. Citation 54 citation 55

25580
01:09:05,102 --> 01:09:08,390
here, the proposed equivalents

25590
01:09:08,420 --> 01:09:10,310
could render such reservoir networks

25600
01:09:10,355 --> 01:09:13,640
explainable and may provide the optimal

25610
01:09:13,670 --> 01:09:15,765
plasticity rules for these networks to

25620
01:09:15,782 --> 01:09:19,290
minimize future risk by using the

25630
01:09:19,307 --> 01:09:21,630
formal analogy to variational free

25640
01:09:21,677 --> 01:09:24,090
energy minimization under the particular

25650
01:09:24,182 --> 01:09:27,945
form of PMDP models. A clear

25660
01:09:28,022 --> 01:09:30,260
interpretation of reservoir networks

25670
01:09:30,305 --> 01:09:32,760
remains an important open issue in

25680
01:09:32,792 --> 01:09:35,360
computational neuroscience and machine

25690
01:09:35,405 --> 01:09:39,015
learning. So from

25700
01:09:39,107 --> 01:09:41,895
Wikipedia reciprocal computing is a

25710
01:09:41,897 --> 01:09:43,710
framework for computation derived from

25720
01:09:43,742 --> 01:09:45,915
recurrent neural network theory that

25730
01:09:45,932 --> 01:09:47,580
maps input signals into higher

25740
01:09:47,627 --> 01:09:49,410
dimensional computational spaces through

25750
01:09:49,442 --> 01:09:51,600
the dynamics of a fixed nonlinear system

25760
01:09:51,662 --> 01:09:54,960
called a reservoir. After the

25770
01:09:54,992 --> 01:09:57,125
input signal is fed into the reservoir,

25780
01:09:57,200 --> 01:09:59,415
which is treated as a black box, a

25790
01:09:59,432 --> 01:10:01,065
simple readout mechanism is trained to

25800
01:10:01,082 --> 01:10:02,840
read the state of the reservoir and map

25810
01:10:02,870 --> 01:10:05,990
it to the desired output. Then there's

25820
01:10:06,020 --> 01:10:08,640
two key benefits of this approach. The

25830
01:10:08,657 --> 01:10:10,365
first key benefit of this framework is

25840
01:10:10,382 --> 01:10:11,940
that training is performed only at the

25850
01:10:11,957 --> 01:10:14,555
readout stage as the reservoir dynamics

25860
01:10:14,615 --> 01:10:18,135
are fixed. The second is that the

25870
01:10:18,167 --> 01:10:19,835
computational power of naturally

25880
01:10:19,880 --> 01:10:22,485
available systems, both classical and

25890
01:10:22,517 --> 01:10:24,735
quantum mechanical, can be used to

25900
01:10:24,767 --> 01:10:27,237
reduce the effective computational cost.

25910
01:10:29,850 --> 01:10:32,885
Here some stable diffusion reservoir

25920
01:10:32,930 --> 01:10:35,240
computing, active inference neural

25930
01:10:35,270 --> 01:10:40,975
network so

25940
01:10:41,037 --> 01:10:42,700
this would be interesting to discuss.

25950
01:10:42,762 --> 01:10:45,510
And I remember some Octave institute

25960
01:10:45,555 --> 01:10:47,535
participants who are specifically

25970
01:10:47,580 --> 01:10:52,155
interested empirical analysis

25980
01:10:52,215 --> 01:10:55,240
and hypotheses. They write the

25990
01:10:55,257 --> 01:10:57,315
equivalent between neural network

26000
01:10:57,345 --> 01:10:58,840
dynamics and gradient flows on

26010
01:10:58,857 --> 01:11:00,630
variational free energy is empirically

26020
01:11:00,690 --> 01:11:02,730
testable using electrophysiological

26030
01:11:02,790 --> 01:11:05,110
recordings or functional imaging of

26040
01:11:05,142 --> 01:11:08,725
brain activity. So then

26050
01:11:08,787 --> 01:11:12,760
another summarization crucially the

26060
01:11:12,792 --> 01:11:14,710
proposed equivalence guarantees that an

26070
01:11:14,742 --> 01:11:16,740
arbitrary neural network that minimizes

26080
01:11:16,770 --> 01:11:19,440
its cost function, possibly implemented

26090
01:11:19,470 --> 01:11:21,915
in biological organisms or neuromorphic

26100
01:11:21,945 --> 01:11:24,495
hardware, can be cast as performing

26110
01:11:24,585 --> 01:11:29,905
variational Bayesian inference. So to

26120
01:11:29,952 --> 01:11:32,530
state it a few more times in the final

26130
01:11:32,577 --> 01:11:35,910
paragraph, in summary,

26140
01:11:36,030 --> 01:11:38,680
a class of biologically plausible cost

26150
01:11:38,727 --> 01:11:40,740
functions for canonical neural networks

26160
01:11:40,770 --> 01:11:43,762
can be cast as variational free energy.

26170
01:11:45,775 --> 01:11:47,950
Formal correspondences exist between

26180
01:11:48,012 --> 01:11:50,775
priors posteriors and cost functions.

26190
01:11:50,925 --> 01:11:52,470
This means that canonical neural

26200
01:11:52,485 --> 01:11:53,860
networks that optimize their cost

26210
01:11:53,892 --> 01:11:56,565
functions implicitly perform active

26220
01:11:56,595 --> 01:11:59,235
inference. This approach enables

26230
01:11:59,280 --> 01:12:00,930
identification of the implicit

26240
01:12:00,990 --> 01:12:02,890
generative model and reconstruction of

26250
01:12:02,907 --> 01:12:04,515
variational free energy that neural

26260
01:12:04,545 --> 01:12:07,690
networks employ. This means that in

26270
01:12:07,707 --> 01:12:11,335
principle, neural activity, behavior and

26280
01:12:11,367 --> 01:12:13,690
learning through plasticity can be

26290
01:12:13,707 --> 01:12:15,750
predicted under Bayes optimality

26300
01:12:15,825 --> 01:12:16,625
assumptions.

26310
01:12:21,362 --> 01:12:23,317
There's a code availability statement.

26320
01:12:23,377 --> 01:12:25,637
The MATLAB scripts are available at

26330
01:12:25,700 --> 01:12:29,167
GitHub in the repo

26340
01:12:29,227 --> 01:12:32,192
of the first author, and it would be

26350
01:12:32,240 --> 01:12:36,825
awesome for the author or anyone to

26360
01:12:37,862 --> 01:12:41,902
bring this working MATLAB script

26370
01:12:42,007 --> 01:12:47,262
up and see if we could do some realtime

26380
01:12:49,637 --> 01:12:52,862
active inference. Then,

26390
01:12:53,000 --> 01:12:55,702
as mentioned earlier, from the roadmap

26400
01:12:55,732 --> 01:12:56,927
the methods are following the

26410
01:12:56,945 --> 01:13:00,667
discussion. I'll just show the equations

26420
01:13:00,727 --> 01:13:03,917
but not go into any details because

26430
01:13:04,115 --> 01:13:08,257
there is not time nor familiarity.

26440
01:13:08,422 --> 01:13:11,477
So those who have more of one or the

26450
01:13:11,495 --> 01:13:13,547
other would be welcome to fill in some

26460
01:13:13,580 --> 01:13:17,057
dots because this is a really awesome

26470
01:13:17,135 --> 01:13:20,267
and important paper. So I hope that it

26480
01:13:20,315 --> 01:13:24,212
can be interpreted and critiqued and

26490
01:13:24,275 --> 01:13:28,112
elaborated on and so on by

26500
01:13:28,175 --> 01:13:31,277
those with familiarity in both sides of

26510
01:13:31,295 --> 01:13:33,975
that free energy loss function.

26520
01:13:36,137 --> 01:13:40,192
Equation one generative

26530
01:13:40,252 --> 01:13:42,377
model section, many details are

26540
01:13:42,395 --> 01:13:45,167
provided. Equation ten is shown. So

26550
01:13:45,215 --> 01:13:47,775
larger unpacking of the generative model

26560
01:13:49,487 --> 01:13:51,467
section variational free energy many

26570
01:13:51,515 --> 01:13:54,857
details are provided, equation 1112,

26580
01:13:55,010 --> 01:14:00,337
1314 and 15 section

26590
01:14:00,412 --> 01:14:02,597
inference and learning details are

26600
01:14:02,630 --> 01:14:06,312
provided. Equations 16 1718

26610
01:14:08,762 --> 01:14:11,972
then section on neural networks so

26620
01:14:12,080 --> 01:14:13,642
there's just some interesting writing

26630
01:14:13,702 --> 01:14:15,977
here. So I wanted to highlight that in

26640
01:14:15,995 --> 01:14:18,497
this section we elaborate the one to one

26650
01:14:18,530 --> 01:14:20,252
correspondences between components of

26660
01:14:20,270 --> 01:14:21,752
the canonical neural networks and

26670
01:14:21,770 --> 01:14:24,532
variational Bayes via an analytically

26680
01:14:24,622 --> 01:14:27,602
tractable model. So that's the figure

26690
01:14:27,695 --> 01:14:31,177
three that we've been returning

26700
01:14:31,207 --> 01:14:35,062
to. Neurons respond

26710
01:14:35,212 --> 01:14:37,957
quickly to a continuous stimulus stream

26720
01:14:38,047 --> 01:14:40,117
with a time scale faster than typical

26730
01:14:40,177 --> 01:14:43,342
changes in sensory input. For instance,

26740
01:14:43,477 --> 01:14:45,547
a peak of spiking neurons in the visual

26750
01:14:45,592 --> 01:14:48,922
cortex of V one appears within 50 and 80

26760
01:14:48,967 --> 01:14:51,762
milliseconds after a visual stimulation

26770
01:14:52,112 --> 01:14:55,717
citation 62 63, which is substantially

26780
01:14:55,777 --> 01:14:58,642
faster than the temporal autocorrelation

26790
01:14:58,702 --> 01:15:01,012
timescale of natural image sequences

26800
01:15:01,162 --> 01:15:05,100
about 500 milliseconds. Citation 64 65.

26810
01:15:05,462 --> 01:15:07,425
So that's pretty interesting.

26820
01:15:08,987 --> 01:15:11,242
What is the temporal autocorrelation

26830
01:15:11,302 --> 01:15:14,187
timescale of natural sequences?

26840
01:15:16,787 --> 01:15:21,662
What timescale do neural firing and

26850
01:15:21,800 --> 01:15:25,792
neuroplasticity etc processes

26860
01:15:25,852 --> 01:15:29,732
actually occur at? And when

26870
01:15:29,810 --> 01:15:33,452
might some type of function at

26880
01:15:33,470 --> 01:15:37,067
a given time scale be understood to be

26890
01:15:37,265 --> 01:15:39,075
functional or not?

26900
01:15:41,387 --> 01:15:45,287
Thus, in other words, downstream of

26910
01:15:45,350 --> 01:15:49,802
the fact that neurons respond quickly at

26920
01:15:49,820 --> 01:15:51,812
a time scale faster than typical changes

26930
01:15:51,875 --> 01:15:54,887
in sensory input, we consider the case

26940
01:15:54,950 --> 01:15:56,777
where the neural activity converges to a

26950
01:15:56,795 --> 01:15:59,262
fixed point given a sensory stimulus.

26960
01:15:59,987 --> 01:16:02,027
We note that the present equivalence is

26970
01:16:02,045 --> 01:16:03,562
derived from the differential equations

26980
01:16:03,637 --> 01:16:06,277
equation six, but not from its fixed

26990
01:16:06,307 --> 01:16:09,467
point. Thus, the equivalence holds true

27000
01:16:09,515 --> 01:16:11,672
irrespective of the time constant of

27010
01:16:11,705 --> 01:16:15,202
neurons to rephrase neural networks

27020
01:16:15,232 --> 01:16:18,487
with a large time constant formally

27030
01:16:18,562 --> 01:16:21,067
correspond to Bayesian belief updating

27040
01:16:21,202 --> 01:16:23,897
with a large time constant, which

27050
01:16:23,930 --> 01:16:26,972
implies an insufficient coverage of the

27060
01:16:27,005 --> 01:16:31,575
posterior beliefs. Pretty interesting

27070
01:16:32,312 --> 01:16:36,217
related to learning rates and Bayesian

27080
01:16:36,277 --> 01:16:41,197
updating rates and all of the nooks

27090
01:16:41,242 --> 01:16:45,212
and crannies of Bayesian inference and

27100
01:16:45,275 --> 01:16:47,782
the challenges associated with dynamic

27110
01:16:47,872 --> 01:16:51,322
uncertain, rugged fitness

27120
01:16:51,442 --> 01:16:54,912
and free energy landscapes.

27130
01:16:56,537 --> 01:17:00,242
These optimization challenges, which are

27140
01:17:00,290 --> 01:17:03,232
addressed differently methodologically,

27150
01:17:03,322 --> 01:17:06,052
culturally, etc. In the variational

27160
01:17:06,082 --> 01:17:09,312
Bayesian and in the neural cases,

27170
01:17:11,687 --> 01:17:14,700
they have to deal with time.

27180
01:17:15,287 --> 01:17:18,032
And so all of those different nooks and

27190
01:17:18,035 --> 01:17:21,202
crannies mentioned, like catastrophic

27200
01:17:21,232 --> 01:17:23,302
learning, catastrophic forgetting,

27210
01:17:23,482 --> 01:17:26,862
simply memory, anticipation, attention,

27220
01:17:28,787 --> 01:17:31,212
local maxima,

27230
01:17:32,312 --> 01:17:34,712
choosing when to play all these higher

27240
01:17:34,775 --> 01:17:40,635
order questions are

27250
01:17:40,817 --> 01:17:44,505
connected here does that

27260
01:17:44,552 --> 01:17:47,145
maze it? What kind of a problem space

27270
01:17:47,222 --> 01:17:50,037
now or just what kind of space?

27280
01:17:50,550 --> 01:17:54,020
Pretty interesting. And equation

27290
01:17:54,110 --> 01:17:59,865
19 202-021-2223 they

27300
01:17:59,957 --> 01:18:01,545
have some more details on the

27310
01:18:01,547 --> 01:18:04,770
simulation. Maybe we could see the

27320
01:18:04,772 --> 01:18:08,520
simulation go and in the last

27330
01:18:08,597 --> 01:18:12,255
section data analysis. So this is

27340
01:18:12,302 --> 01:18:14,430
kind of returning to that point about

27350
01:18:14,477 --> 01:18:18,140
the time constants in Bayesian

27360
01:18:18,245 --> 01:18:22,065
and neural network systems when

27370
01:18:22,082 --> 01:18:24,135
the belief updating of implicit priors D

27380
01:18:24,167 --> 01:18:25,710
and E is slow in relation to

27390
01:18:25,742 --> 01:18:29,220
experimental observations, d and E,

27400
01:18:29,372 --> 01:18:32,135
which are encoded by phi and PSI,

27410
01:18:32,330 --> 01:18:34,770
can be viewed as being fixed over a

27420
01:18:34,772 --> 01:18:37,560
short period of time as an analogy to

27430
01:18:37,592 --> 01:18:40,935
homeostatic plasticity over longer time

27440
01:18:40,967 --> 01:18:44,865
scales. 66 homeostatic Plasticity in the

27450
01:18:44,882 --> 01:18:49,995
developing nervous System 2004 very

27460
01:18:50,147 --> 01:18:52,610
interesting in light of our recent

27470
01:18:52,655 --> 01:18:55,275
discussions on allostasis and other

27480
01:18:55,337 --> 01:18:59,385
topics. Thus by and

27490
01:18:59,417 --> 01:19:01,590
PSI can be statistically estimated by a

27500
01:19:01,607 --> 01:19:03,555
conventional Bayesian inference or

27510
01:19:03,602 --> 01:19:05,595
maximum likelihood estimation given a

27520
01:19:05,597 --> 01:19:08,540
flat prior based on empirically observed

27530
01:19:08,570 --> 01:19:11,190
neuronal responses. In this case, the

27540
01:19:11,207 --> 01:19:13,205
estimators of phi and PSI are obtained

27550
01:19:13,265 --> 01:19:17,100
as follows Nice equation number 24

27560
01:19:17,237 --> 01:19:18,475
mentioned earlier,

27570
01:19:20,625 --> 01:19:23,835
so that will be definitely one to look

27580
01:19:23,867 --> 01:19:24,987
into more.

27590
01:19:27,900 --> 01:19:31,200
Well, I hope you found this

27600
01:19:31,337 --> 01:19:35,112
a useful and interesting zero.

27610
01:19:36,675 --> 01:19:39,025
I'm looking forward to the discussion

27620
01:19:39,375 --> 01:19:42,987
with the author and again, any other

27630
01:19:43,725 --> 01:19:47,637
institute participants or those with

27640
01:19:48,000 --> 01:19:51,285
knowledge or strong feelings to

27650
01:19:51,317 --> 01:19:53,645
express about neural networks, active

27660
01:19:53,660 --> 01:19:56,350
inference, applied, active inference,

27670
01:19:57,075 --> 01:19:59,540
computational modeling of perception,

27680
01:19:59,570 --> 01:20:03,270
cognition and action, neural networks in

27690
01:20:03,272 --> 01:20:06,930
the wild, AI ethics, all these different

27700
01:20:06,977 --> 01:20:10,695
areas can hopefully have

27710
01:20:10,847 --> 01:20:15,105
a nice discussion in 51.1

27720
01:20:15,152 --> 01:20:19,437
and .2. That'll be the last paper

27730
01:20:34,200 --> 01:20:38,355
streams for 2022. And yeah,

27740
01:20:38,477 --> 01:20:40,215
if you want to be more involved with

27750
01:20:40,232 --> 01:20:41,570
live streams whenever you're listening

27760
01:20:41,585 --> 01:20:45,615
to this, join or recommend

27770
01:20:45,707 --> 01:20:49,035
someone to join or help in any number of

27780
01:20:49,067 --> 01:20:53,225
other ways. Just listening

27790
01:20:53,375 --> 01:20:56,580
and learning is awesome. And we also

27800
01:20:56,627 --> 01:20:59,160
really look forward to those who want to

27810
01:20:59,267 --> 01:21:01,965
help make some of these connections that

27820
01:21:01,982 --> 01:21:05,385
are latent and sometimes exposed in

27830
01:21:05,417 --> 01:21:07,975
these papers and conversations,

27840
01:21:08,775 --> 01:21:12,165
and with a few motivated people who want

27850
01:21:12,182 --> 01:21:14,270
to connect, for example, to the neural

27860
01:21:14,285 --> 01:21:17,865
network communities and those who

27870
01:21:17,882 --> 01:21:21,150
can facilitate discussions on these

27880
01:21:21,212 --> 01:21:24,762
topics, that would be awesome.

27890
01:21:25,800 --> 01:21:29,585
Just using my final thoughts

27900
01:21:29,630 --> 01:21:32,175
on this dot zero, because it's always

27910
01:21:32,237 --> 01:21:34,470
great to have others also join in the

27920
01:21:34,472 --> 01:21:37,035
preparation for the dot zero. So just

27930
01:21:37,067 --> 01:21:41,135
want to add that note on this rare solo

27940
01:21:41,255 --> 01:21:44,400
stream. So thanks again, looking forward

27950
01:21:44,462 --> 01:21:47,955
to talking or seeing you later.
