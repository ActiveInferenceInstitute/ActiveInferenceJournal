SPEAKER_02:
to organization and today should be

a good one because we are here with Eugene, who's going to be talking to us about decentralization and smart contracts and all kinds of other things.

We also have this interactive whiteboard slash slide deck here.

So please write any comments in the chat.

And as soon as Eugene is back, I'm sure he'll begin his initial presentation.

But welcome, everybody.

Looking forward to seeing your comments in the chat and

Welcome back.

Your re-entry.

Please provide a introduction and some context and really looking forward to this.


SPEAKER_00:
Of course, I got so excited to begin with that I closed out the wrong tab.

So that's always a good beginning, but.

Thank you for hosting me, Daniel.

Excited to be here with the Act-Inf Lab and to get to talk a little bit about decentralization and yeah, kind of see where the conversation goes.

So definitely really excited to hear what folks are thinking about.

And so please, at any point, if this isn't going kind of deep enough on any specific term, you want more clarity on anything, please, please feel free to mention it in the chat and we will definitely be happy to bring it up in conversation.

So just to begin, I'm Eugene Leventhal.

I'm currently the head of operations at the Smart Contract Research Forum.

We're a grant funded organization in the smart contract space or in the Web3 space overall, excuse me.

And our focus is very much on helping to advance research around Web3.

The starting point for that is just connecting folks from industry and academia.

And we're exploring a lot of various questions around what is public good infrastructure,

for research in Web3, but also for science more broadly look like.

So very happy to talk about Smart Contract Research Forum or SCIRF as we colloquially call it ad nauseum.

But yeah, for today, the focus is on decentralization itself.

So I want to take it there.

But the thing I wanted to kind of start off with and mention as the

Genesis of this conversation is the fact that the space of web three, even the term web three, right?

It's one, uh, I came across this, uh, uh, GitHub repo of just all these articles that where it's very well-known technologists, uh, explaining why web three is all a bunch of baloney.

And none of this makes sense.

And, uh, in all fairness, there is a lot of enthusiasm in this space that leads to there probably being more focused on areas that, um, you know, uh, might have a rockier grounds than others.

But the goal of this session is really to delve into a term that if you've been part of anything, blockchain, crypto, Web3, in any kind of way, you've definitely heard the term decentralization thrown around.

Because the whole dichotomy, and I don't know if it's even fair to call it a dichotomy because that oversimplifies the idea, but at least this idea of a spectrum between there's centralized and somewhere along the line there's decentralized.

What does that actually mean to be decentralized?

And for me, another thing, which I always love thinking, not in binaries, but sort of in spectra, is decentralization an endpoint or is it itself only a certain checkmark on a much wider spectra where maybe centralization to full peer-to-peer distribution is the actual ends of it, where everything goes through one party or goes through everyone in the system and there's sort of a, you know, gradients in between.

But I think we can delve right into more of the technical definition of the architecture, the history of the term of decentralization or something like that.

But to zoom out, I kind of like thinking about decentralization from at least two high-level buckets.

One is, who are we talking about?

And the other is, what are we talking about?

The who pertains to, are we talking about owners of a system or users of a system?

And that was users of a system.

Those vary greatly, right?

Because if we're talking about ownership, that's where things like co-ops, the whole cooperative ownership movement, I mean, that has had millennia behind it, right?

That's where that pertains.

But there's also, there could be a scenario where users use a system that on an architecture perspective is decentralized in terms of there not being a single point of centralization.

I know I still haven't defined it yet.

That's intentional.

But

the for the user right they could have no ownership in the state so it's not as though we mean to centralize decentralization itself does not mean cooperatively owned per se right so let's suss apart who is actually using it and who is owning the thing that we're talking about and then when it comes to actually thinking about the what gets decentralized right i think that's where it's important to think on the one hand there is the infrastructure layer and more the application layer

And alongside that, it's sort of what is the actual domain of whatever we're talking about, right?

Because infrastructure or application is more of the dimension of kind of architecture, so to say.

And the actual domain can be in terms of knowledge, right?

Are databases, are they with known knowledge?

Is that easily accessible?

One can argue that libraries, right, the whole goal of libraries was to make information more accessible.

It's taking it away from a single place and opening it up to have more people being able to interact with it.

And that can relate to knowledge, to decision making or communications, to actual resources.

Right.

I'm kind of dancing around a few of these concepts around decentralization.

But again, what am I actually talking about?

Right.

So for me, it always comes down to if we're talking about decentralization, it needs to be in the context of a system.

Right.

Decentralization is not just something that appears or disappears.

Right.

It's only in the context of systems.

And when we think of those systems again, are we we can be thinking about.

And let's just think of this from, say, the what perspective, right?

Infrastructure apps, what are the actual domain of those infrastructure apps?

When we talk about those things, centralization or decentralization can relate to power dynamics or who actually gets to make the decision of how all of these things are run at the end of the day.

I know in the Web3 space, there's been a lot of exit to DAO, just exiting to community is a more broad term that I believe came from Nathan Schneider and some

other folks working on now the project exit to community, but the whole idea of how can we actually let some of the decision-making and knowledge creation in our community

be both owned by and used by the same set of folks and, and kind of keep expanding that set.

And I think that's a lovely concept, but a lot of the time decentralization, at least from some of the conversations around web three that I hear, they start conflating a lot of things and which is why I like breaking it down to, well, are we actually talking about the owners and users?

And are we talking to the infrastructure app layer or, and what is the actual domain of those things?

And once you map that out,

then you can start being a little more nuanced in trying to break out what exactly it is we want to explore the idea of decentralizing because the decentralization and power go hand in hand but again you need to be more specific in your terms and thinking about which part of a system you actually want to expand that scope of power around otherwise it can be very tough to build the necessary requirements of culture and community around this because again

If you are trying to truly decentralize something, that means you're going off to let more people have power in the system and more people just equals more messiness.

Right.

And that's not a judgment call.

I think that can at least for anyone who's genuinely try to make a decision with one other people or with 100 other people.

And let me know the scenario where it's easier with 100 than with the one.

And I'm sure you can always find an exception.

Right.

But as a rule of thumb, that does seem to hold.

And so

That's kind of one thing I wanted to start with in terms of decentralization overall and this kind of diffusion of power.

And again, being particular with the terms of where in the system are we thinking of power and for whom does that power apply or apply to?

And now that we've gotten at least some kind of a baseline of decentralization, now let's jump into what do I actually mean when I say something like decentralizing science?

Because if you've been following certain niches of crypto Twitter, which I recognize crypto Twitter is already a niche, so niche among niches, but you might have seen the terms DeSci coming up, I think,

October was the first time I believe I could find some kind of record of it on Twitter.

But this is a relatively new term, de-sci, decentralizing science or decentralized science.

So we're diffusing the power around the creation or the propagation around what of science.

Science is itself a very high-level term that can mean a lot of different things to a lot of people.

So

I like to think of, right, if we're breaking it down into the highest level, but separate parts, there's the actual research side.

So there is someone who has an existing base of knowledge, who has a theory about something that is not captured in that base of knowledge and wants to run some kind of tests to somehow amend or append the existing base of knowledge with new information.

So that's what I see as the actual research function.

Then there's the review function.

Some people looked into a thing and want to claim that it is true or not.

How do we double check that, right?

So the quality assurance layer over research.

And then there's the publication of research, which should not be conflated with media or publications overall, because research publication as it stands today, and I can't speak this confidently globally, but at least in the States, research publication and usable information

kind of interactable publication are two very different things.

Sort of, you know, the Springers, the ACMs, the IEEEs, their goal is not to get 10 million hits in academic paper.

You know, they're working within a very specific system of producing academic research that is connected to the existing structures of research and review.

When it comes to just pure media, there it becomes a lot of the time how do you get it to as many people as possible, which means how do you sometimes lose the depth of the point to make it easier to digest in a short amount of time, which is inherently contradictory to research, which is let's go as deep as possible on as narrow a set of things as we can to actually learn something or add to some kind of base of knowledge around that more narrow, deep set of things.

So in my sort of pipeline of high level pipeline of science, it's there's research which gets reviewed and then it gets published.

But that inherently does not capture everything coming out of academia or inherently coming out of any brilliant minds around the planet who have good ideas that should be explored.

And there's the question of who has access to be doing research in the first place, right?

In the States today, if you're not at a top 10, top 50 at least research institution, you're not in a top corporation that actually has an R&D department that's meaningfully funded, which is not the case at all corporations.

and you're not at a government agency dedicated to research, you're probably going to have a hard time having a seat at the table unless you find a way to break into one of those areas, right?

So we can start thinking of, well, do we mean decentralizing research means everyone should get to do research?

Maybe I'm not here to sort of give a yay or an A, but it's starting to think of, well, what do we mean about the power there?

Is it who actually gets access to be a researcher?

Is it who gets to have a call and be part of the decision of what gets funded?

Is it something about the actual interaction with the research information?

Right.

Those are all different aspects of what could we be talking about when we're talking about or changing around the power dynamics around research itself.

But again, that's just the first step, because then we've got to jump to review.

Even if we've ironed all that out, we have a clear sense of what it means to decentralize research.

Well, who is actually going to be responsible for quality assurance?

And I think that there's no shortage of information on some of the current challenges in peer review.

I don't want to distract myself now, but I can put together a link later when I have a moment.

A professor from Carnegie Mellon, Nihar Shah, he and another professor from CMU, Zach Lipton, did a great joint presentation that I know that their slides are publicly available that I'll add the link to.

They did a great outline of all of the known research studies delving into the current problems with peer review.

I don't want to be misquoting, but I think it's somewhere in the 70 to 100 range of academic studies just exploring very particular problems in peer review.

Right.

So this is not as though I'm someone from outside academia raising a red flag that doesn't exist.

Right.

Talk to a tenured faculty member and they will probably be the first one to tell you all the problems with the peer review structure of today.

So one of the challenges is if you ask the people who are doing the research to be their own reviewers,

There's a clear conflict of interest there.

If you tell me to produce something and review it, there's reason to believe that I will have the incentive to be light on the review and just push whatever I want to produce.

So the separation of those two functions is very important.

But the question of should reviewers be anonymous or not?

Should reviewers be compensated or not?

Again, should everyone be able to be a reviewer?

Should everyone have a seat at the table of being to review?

Or do you need a bare minimum set of qualifications to even be allowed to be a reviewer in whatever a future system of review might be?

And then finally, there's the aspect of the actual publication of you've done the research, you've gotten it reviewed, now it has to go somewhere.

at least the current norm a lot of the time in the top research institution is via a journal or conference or some kind of very high level or very esteemed publication.

You might have heard the motto, so to say, publish or perish, which I think is a good encapsulation of the incentive problems around academia for research faculty, where a lot of the time, if you're in the

top kind of 1% of institutions, you might be focused on more headline catching research because you might actually be the pipeline where you have the relationships with the largest media organizations and they come to you for some kind of fancy, you know, new breaking research on people and the brain.

And this is what this means for how all of us, you know, the kind of stuff mainstream media likes to oversimplify when it comes to talking about research publicly.

On the other side of it,

there's also, or sort of, excuse me, with the aspect of publish or perish, that's just in the top 1%.

If you go into more of the kind of the global majority of research institutions, the game that's being played is different where it's a volume play, where your ability to progress as a tenured faculty member has pressures on it to see how many things you've actually published that hits some kind of reputable journal.

And, right, those are all incentives that make it

tough for people to just focus on the purity of the act of review.

And there's a whole separate question, right?

Does the purity of the act matter as long as we can figure out a system and function so that we minimize the amount of questionable science that gets put out, right?

What is the bad side of review?

Research happens that comes to faulty conclusions.

No one captures it and someone tries building on it, right?

And that could actually lead to some kind of problems if we think of the hard sciences and

you know imagine a medical device going out uh built on a fundamental research premise that is false right like people's lives could actually be at risk in those kind of scenarios so this isn't just some like people playing with defy money online kinds of questions right this is science more broadly so but again that whole cycle of research

review and publish still doesn't actually get to how do we get this research out of the ivory walls of universities into the hands of people who need to build it?

How do we actually make this relevant to your average person anywhere on the planet who might wonder what is the cutting edge of, I don't know, quantum computing have to do with me if I don't even know how to type a line of code or explain how an email gets from my phone to my computer or to anything else, nor do I care, right?

I'm busy with my own life and I have my own priorities and problems.

Why should I care about any of this in the first place?

Right.

So there's already there's the full research apparatus that we talked about and a lot of the institutions that do science reporting or any kind of let's actually get this contextualized in larger narratives.

What are the actual incentives aligning them with the researchers or them with the public?

So there's a number of things in all of these separate nodes of the large system that is science that themselves have a multitude of different areas where we can explore what decentralization might mean and how that might impact the people in the system or how that might impact people who don't care about the system at all, but just want to have less suffering, more prosperity in their life.

And how does it actually go from theoretical science to genuinely improving people's lives?

And the last bit I'll kind of touch on before bringing this to be the actual conversation it's intended to be is more on the behavioral side.

Because I know when I first got interested in blockchain and DAOs in the 2016 timeline, it felt very much that there was just so much excitement that, oh, we could be at the precipice of making the thing that solves all of humanity's problems.

Right.

And if you've studied the history of technology or of any kind of advances, that's a sentiment that is not new.

A lot of people at a lot of cutting edge advances at their point in time thought that, oh, this could be the thing that actually, you know, ends world hunger, poverty or whatever.

Right.

That it could actually have these mass global scale positive effects.

But especially when it comes to something like decentralization, I feel as though one of the questions that I'm hoping we'll get into this through conversation, right?

But a decentralized world, right?

If we have this kind of world where power gets distributed from a very limited set of players to a much wider base of individuals, there's just more uncertainty there, right?

Because like it or not, right?

And again, look at political governance in the full history there.

democracies are messier in the sense of decision-making because more people have to come together, but there's a lot of benefits of that messiness.

I am personally a huge fan of that messiness because I think us working through messiness is that it's the most human thing we can be doing, right?

We are a social species and us working through the messiness of coordination is part of the exciting things that we get to build higher order ideas as a species, like these laptops we're talking on or any of the other great advances that we now have.

And so I think

At the core of decentralization for me is an increase in uncertainty.

And I think that that is something that we don't like talking about a lot in the space, or at least I have not heard many open discussions about it, because it runs counter to human nature and desire.

And let's look at that at a few different dimensions.

Let's just think of us as a pure biological creature.

Let's take away all of our sociocultural constructs.

We are just a biological mass.

I am personally of the camp.

I am not a neuroscientist, but in my limited knowledge and in following some neuroscientists, I am fully in the camp of the Lisa Feldman Barrett's and the many others who are now part of this growing school.

Yeah, our brains are prediction machines.

That's literally what they evolved to do is to be much better at predicting what's about to happen.

And so, right.

What does prediction mean?

It means that we, we like to model things out, right.

And there's a Lex Friedman has a great series of interviews with Lisa Feldman Barrett and Yosha Bach and a few others that I'd be happy to link to that.

I just love those three to four hour discussions, jumping around neuroscience and consciousness and everything else.

that, you know, that makes sense to me that there's these sort of, there's cortical columns that are focused on certain activities.

There are sort of columns of neurons being bunched together, or really of neural nets being bunched together to sort of execute certain functions.

As you kind of get more and more of these together, you need consolidation functions, right?

And we have models at all different kinds of levels ranging from very narrowly focused ones to like, hey, what do I want to do with my life tomorrow or a year from now, right?

Like those are very complicated modeling exercises.

But our brains are constantly trying to model and modeling means you're trying to map on, you're trying to limit uncertainty and create an actual projection into the future of what might happen.

And why does centralization show up in a lot of sociocultural environments?

Because there is efficiency to centralization.

Right.

If one person gets to make all the calls, assuming they are good at making calls and they are a good person with or that they are shooting towards a beneficial end.

Right.

We will all be able to move more quickly with that one as opposed to 10,000 trying to make that decision.

So a lot of this natural evolution has pushed us to want to minimize uncertainty.

And yet we are inherently trying to introduce a cultural element that actually increases uncertainty, which for me, again, is very just counter our biology.

And I think that we don't just have to think on that level of our brain as prediction machines and along those lines.

How easy is it at the start of my day?

And I'll just use a personal example as an abstraction.

At the start of my day, especially as someone with chronic sleep issues and whatever, I start every day at the center of my universe.

And I have to be intentional about reminding myself that that voice inside my head that's yapping as soon as my eyes open up

That is not the entirety of me.

That's actually one of the nodes that constitute the entire being and system that is Eugene.

But at the end of the day, that's the thing that I hear first and foremost.

And it's very easy for me to just get caught up in the emotionality of whatever that voice is yammering on about and to pretend that I need to be going with it wherever it's taking me.

where I have the ability through meditation, mindfulness, through all different kinds of practices to be like, timeout, let's go ahead and quiet that voice and let's listen to other modes.

Let's listen to other nodes in the system of Eugene.

And for me, decentralization is a psychological concept too if we think of ourselves as a system.

Do I just give credence to the centralized view of the voice of consciousness?

Or do I actually try to have a more decentralized view of my being where I'm listening to every single node that is part of my constitution?

Right.

Before I started meditating, I never actually thought about how does my back feel against the chair that I'm sitting in as I'm right.

Like these little elements of focusing attention and being intentional.

I think those two words of intention and attention are so important for where behavioral level change begins.

And what I don't see enough of in this space or in a lot of spaces is the bridge between behavioral level change and high level philosophy.

So that's really why I wanted to have this discussion today is because I'm happy to espouse on blue in the face of my views on why certain decentralization is great and good for humanity and all this other stuff.

But at the end of the day, you can have the best philosophical theory in the history of humanity.

And if you don't actually know how to get a single person to start taking a step towards it, is it really useful?

So for me, I love jumping between the two, between what can I do to be a better collective citizen of the groups and systems that I'm in, and jump to what does that mean to inform my philosophy of life, and what is the link between those two, and how do I get a feedback loop going, and not just punting off to philosophizing and abstracting, which is much easier than the lower level of understanding myself, emotions, and all of the internal world side.

So that might have gone on a little longer than I intended, but that's where I'd like to kind of kick us off.


SPEAKER_02:
okay great thank you for the introduction and opening set of ideas a lot of places to jump in there did you ever get to what decentralization is let's return to maybe that and then yeah sure so yeah pop into a few other places absolutely yeah so uh


SPEAKER_00:
I like to think of decentralization, right?

The overly simple view of it is it's a diffusion of power in a system, right?

And that's where I came back to power for whom, over whom, and of what, and the whom and the what are very important there.

But effectively, it's taking power from a single source and sharing it out.

Most simple version, think of a kingdom when there is literally a single king or queen.

They get power over everything.

A democracy such as the, let's say, American democracy, we have three different branches.

We have a bunch of people in each of the branches.

That's trying to take a step towards decentralizing power away from a single person to a larger set.

And then you can argue that truly communal living or certain versions of anarchic living

where there is no, it's kind of a leaderless true organization where everyone has equal power, that might be on sort of the other end of the spectrum of sort of true everyone is on, I don't know if everyone is on the same level, but like this peer-to-peer system on the one end and more of a truly centralized everything comes out of one node on the other end.


SPEAKER_02:
So I wrote down, does that change the nature of the system?

If we have one set of rules or one state that we're in, or an area of state space for some system features, and one person has all of the tokens, and then the system changes so that the distribution, the non-equilibrium steady state, like we might say in active inference, is at a new normal.

It's at a new stationarity or meta stationarity.

it's kind of like, isn't that a different system?

So even implying that power can be spread out, it's a non-fungible asset and it's an irreversible asset, time-dependent one too.

These are just like some of the, as we open the conversation, I think today, but also on a broader timescale, there are the known unknowns and then there's the unknown unknowns.

And


SPEAKER_00:
going to bump up against all of them yeah and i really like the the i i've never used this term exactly but i really like that you put it together the the non-fungibility of power uh because i i think that's an interesting and important one to recognize because right being aware of that especially for people who are actively designing a system and who are

the first ones building it, you inherently are going to have way too much power in that system, whether or not you want that power.

I think, let's say Vitalik Buterin and Ethereum is a great example, right?

He doesn't want

I don't know him personally.

I don't want to speak on his behalf, but I have a lot of reason to believe that he is not looking to be the authoritarian over Ethereum.

That is my genuine view of that based on all of the reading and following of the space that I've done.

But Vitalik says something and everyone in the space listens, and that might have impact on Ethereum price.

So there are these relationships whether or not you like it.

But at the same time, there's also

As a person designing these systems, you have to be willing to recognize that in order to gain efficiency at a certain point, I actually might need to centralize the power under me, but design the system in a way so that I cannot maintain it over time.

And how to give away power and make sure that you don't have the ability to usurp it again is very interesting from a system design perspective.

And even if you came into this discussion thinking like blockchain is a joke, Web3 is a joke.

Sure, like it's an open question how much usefulness is going to come out of this on a hundred to thousand year timeline.

I'm open and understanding of the lack of clarity of the future.

But I just think the space at least DAOs are worth paying attention to.

Because I don't see anywhere else where there's so much open experimentation in that direction of supposedly saying we're here to diffuse power and then watching the actual social dynamics play and system structuring around it.

So that's one of the reasons of Calls of Light.

Just go check out some DAOs.

It's fascinating social experiments, if nothing else.


SPEAKER_02:
A few thoughts.

One thing is I lived in cooperatives for many years and so it's just so interesting to see some of those traditions and failure modes and

patterns translated.

And then I know it's a big theme in web three, where the first steps involve translating like what has already been done.

Okay.

Oh, you've worked in an office before.

Well, now you're in a virtual office.

And then the future steps can be elaborations that take it into a different direction or use something that couldn't have been engineered in the physical world.

So we're beginning to form the motifs and the grammar for describing the

organizational patterns design patterns and atlases of risk for organizations and before there was uh money attached to numbers it was probably hard to do counterfactuals and long-term tracking of money quantitatively and if your decision making is

um based upon a secret handshake well then it might be so esoteric that it has never been investigated doesn't mean it doesn't work it's just that now we're implementing computational governance hashtag metagov and implementing programmable money and

involved in totally surveillable communications oh just vote on this poll well now you have the time and did someone vote and unvote and get into so many other pieces that weren't there in the paper ballot and that wasn't there until that was there so it's a whole new set of observations that are coming in about systems that we had already been engaged in

But then where you get that second level cybernetics and complexity is when we're modifying the system with new affordances, new ways we can modify.

And then that's feeding back into like very rapid change, but by no means even maximal.


SPEAKER_00:
Yeah, and to what you mentioned earlier on with the first question, or with the whole idea of, well, once you start decentralizing, is that even the same system at that point, right?

Once you change sort of the power dynamics, can it be argued that we're looking at something fundamentally different there?

And I think that part of the exciter, right, there's another area that we need to explore and define more terminology around in terms of that feedback loop of system

system architecting, system running and management, and culture.

Because even if nothing else, I mean, I don't know how nothing would change in the system going from a centralized to decentralized, decision-making has to open up.

There are literal operational things that need to go into account to be able to manage more people being involved in certain decision-making capacities.

But at the same time, it inherently requires culture shift.

And that's where it comes down to that behavioral level change for me.

Because if it goes from, hey, Daniel is our benevolent dictator in this community and no one questions it, to all of a sudden, both of us are making choices and so are 50 other people, I now need to be willing and ready to be called out for the appropriate level of responsibility that I hold.

And like, hey, why'd you do that?

That was actually not in line with everything else you've said before and your views on the system.

Like, why are you going in?

And like, now I'm accountable.

Now I'm responsible to my peers.

And I just think that

I get worried about not enough of that behavioral and human level coverage.

And again, one of the things I'm excited about with the current experimentation in DAOs, when I first got in in 2016, the amount of people, myself included, who were like, oh, DAOs, brand new, shiny, cool thing.

And this is back in 2016 when there was zero tooling or anything for it.

And there were people who were there much well before then even.

But there was this view of

It's a brand new thing.

And then all of a sudden folks, and I know like my colleague, Richard Brown at Scurf, when he joined MakerDAO, he was in one of these positions where it's like, y'all have heard of co-ops before, right?

This isn't like the tech might be new, but the concept is, and you've heard of a co-op, right?

And people would be like, oh, a co-op?

And like, they had never really looked into that background and full history.

And so, right, first there's this just catch up of, right, different domains have relative knowledge.

But then once it's these different disparate domains are aligned, and this is where I really, you called out the Medigov community that we're both in, right?

I really love the Medigov community because it's not just a Web3 governance community.

It's a governance community, which means people from inherently different backgrounds with inherently different views and different desires of the kind of applications they want to bring this back to are coming together to talk about a topic.

And I think once you have those layers of true interdisciplinary, coordinated, supported action towards trying to change a system, at least that's where I get really excited about people coming together, because I do just love that those kind of different backgrounds kind of being able to chime in on some kind of thinking there.


SPEAKER_02:
a lot of places we could go as always but these org streams at the active lab it's a it's a multi uh street juncture there's people who might be familiar with or curious about active inference but then some of these questions and approaches they're hearing about for the first time and then there might be somebody who's interested in the governance approaches who might be hearing about active inference for the first time so that's kind of the fun but

It's the microcosm of how we make decisions and how the differences in what our experiences and perspectives are contribute to something that's bigger than us.

And I think that is related to your point about uncertainty and about changes in certainty of different types, which I think we can take some time and think about.

Like if the plan is big enough for one person to feel like they understand it,

there's a limit to the complexity of that plan.

If you allow for stigmergy, for the ability of the plan to be understood by one person plus their environments, like blueprints or the computer system,

it's bigger than that person's one onboard cognition.

So that's what a lot of cognitive scientists call like extended or inactive cognitive processes that can involve physical parts or modification of the niche.

So that's been one trend in neuroscience since the sort of like brain region A connected to brain region B, still very cool and interesting.

But one of the important recent trends

is people looking into this embodied and extended element.

Little aside.

So you have the project that that one person can operate by themself.

But we're talking about projects that are either

requiring multiple expertises, like almost any scientific project, or the case where we not just could use multiple people, we might benefit from, but we're talking about governance, which is like decision-making where it is explicitly about creating a layer where multiple people are harmonising their view.

So I think

where does uncertainty fit into that is a fascinating area i'd love to hear more on because uncertainty is such a core component to active inference and the management of uncertainty so maybe you could give some thoughts on that and then we can bring it back to active yeah so i think there's a couple of dimensions there that i don't want to conflate either so one thing is that


SPEAKER_00:
Right.

I know, uh, personality psychology.

I feel like let's just go with the big five to avoid it.

Let's go with the one with the most research behind it.

Um, right.

Research, uh, personality psych, its own big school, a lot of differing opinions.

Uh, that's not necessarily the focus of the current, the reason why I'm bringing it up.

Right.

But there is reason to believe there is some biological difference between people.

And again, not trying to dive into all of the nuance of that at the moment, but one element is the ease of the ability to deal with something like uncertainty, I do not think is biologically uniform, right?

I think there's going to be people who have easier time dealing with uncertainty and people who have harder time dealing with uncertainty.

And that's just the natural disposition, right?

Then there's the actual lived environment that they are raised in, grow up in, the culture they're in.

all of that, which also heavily affects that.

So

A question that I remember Seth Frey, Professor Seth Frey, who's also in the MediGov community, asked during a conference panel we had organized last summer.

He brought up this idea that he likes to ask people of, hey, you, when you envision your version of utopia, right?

Imagine, and I'm butchering his exact example, but it was sort of, oh yeah, for Dow, sort of the perfect Dow, and envision it as a building, right?

Do you see that building full of people or lacking people?

And I think the answer to that starts with a big dichotomy of viewpoints around the question of uncertainty.

Do you view uncertainty as an inherent human flaw that we have to get rid of the people and create systems that can live in spite of humans?

Or do you embrace the fact that uncertainty is just part of who we are and we will never, ever, ever get rid of it fully?

And we just kind of have to be okay with letting the current wash over us and take us where it takes us, right?

And

I am fundamentally of the camp of like, this is all quarterly human.

I don't think we can automate away human problems.

So I just, I'm giving my own bias here.

I'm very much taking this in the camp of like, let's just dig into the assumption that these are core human issues and we will have to deal with the human, the human side.

So that, that is an important distinction I want to make.

Cause I do think some people are naturally predisposed.

or now are predisposed due to culture and environment to be like, oh, humans are the bane of existence.

And what was the Jean Paul Sartre quote, hell is other people, right?

Like there's people who genuinely just have a harder time for a variety of reasons being with humans, which adds complexity to uncertainty, right?

So I don't want to pretend that everything else I'm going to say is a blanket statement for others.

I myself am a bit of an ambivert.

I have extroversion, I have introversion, but I am fundamentally human in the sense of I need other humans around me and I will always prefer a messier conversation than no conversation.

So that is my bias and predisposition into answering your question.

So on the actual side of uncertainty, so existence is inherently uncertain.

Parts of us want to create certainty for a variety of reasons.

Biologically, we want certainty so that our brain can be less freaking out about whether or not we're going to die soon.

On an evolutionary scale, that's oversimplifying where fear responses and whatnot came from naturally.

But if you think of it on a sociocultural perspective,

those did not naturally evolve over millennia or over millions of years right those were instituted and provided for a variety of very different perspectives right uh why we may have been trained that a good worker is someone who shows up to work at 9 00 a.m and leaves at 5 p.m or whatever the norms are around whatever you were raised in right there are very different uh pulls and incentives around why that was kind of indoctrinated into your brain aside from oh this is just how the natural world works right so that's also an important gap to recognize because

Why I love the lens of existential psychology and psychotherapy is that there's more and more research pointing in the direction that once something is a core enough assumption for someone,

attacking that core assumption feels like you're attacking them as a human being.

And it feels like it's a fundamental survival environment for them, right?

You might have been in a conversation with someone where you ask an opinion where you just really disagree.

And all of a sudden, they get into like hyper defensive mode.

And it's like, whoa, I was just exploring an idea.

Why are you like, I'm not trying to cut your head off, like what's happening here.

And but that's how we respond when people can question certain aspects that are that are so based to us.

So

I think that again, and I realize I'm just kind of dancing around the exact question, but just uncertainty is such a hyper complicated topic because on the one hand it's everywhere and it's fundamentally part of existence, right?

This is one thing where it's interesting how psychedelics and Buddhism and meditation and all these other dimensions come back to the same thing of, oh yeah, life is super complicated and I'm just never going to get all of it.

And like, that's cool.

And you got to learn how to be okay with that.

Right.

And like, that's on the very behavioral personal level.

learning how to deal with uncertainty is not easy for people.

I know I have some folks who I absolutely adore in my life, why I tell them all the time, stop being a control freak, you're making your life harder, right?

But that's not easy feedback to give someone.

And it's kind of useless feedback, unless you actually sit down and walk them through step by step how to do it.

And what are the things and when are you going to be uncomfortable?

And when are you going to be comfortable?

So part of the tricky part of uncertainty is that it is inherently uncomfortable.

And most of us don't want to be more uncomfortable.

So how do you learn how to be

of knowledge of where things are going.

Like, how do you give up control?

How are you okay with knowing I have no clue where my next step is going?

And yet you're like, Oh, no, but this is awesome and amazing.

And like, that's actually that is a series of contradictions internally, that is hard to consolidate, unless you have

the disposition, the privilege, and a few other factors in your life to allow you to explore it.

And I recognize that I've spent the amount of time digging into these things in the last 10 to 15 years because of the specific dynamics that I was born into and other factors that I don't want to turn this into a personal outward facing therapy session.

But I'm happy to disclose those because I think that that's the dimensions of connection, right?

It does run that deep.


SPEAKER_02:
Okay, a lot to say there.

I think I'll just sort of retouch on a few points because they're great and bear reflecting upon and also because they're some of the core nodes in the active inference

contextualizing and implications.

So existence is uncertain.

You said biologically we want certainty relative to our generative model to maintain persistence.

So this ties together like a few key things.

First, the desire for certainty, arising of that desire.

I added relative degenerative model which is an active inference term like a generative model just like in statistics it's a reduced representation of a complex process that spits out numbers so it's like a generative model of the weather and then you have one model that takes the data and updates the generative model and then you have a generative model that can create

expected data and then compare incoming results so that's a key part of the predictive brain the bayesian brain active inference and then to maintain persistence is where it ties in with um identity and with thermodynamic survival so that's kind of on also on that more technical side that's what ties us to like non-equilibrium thermodynamics

Now for cultural entities, oh, if we were only a thermobacterium, that uncertainty is tied up with other people.

so yes we also are dealing with uncertainty about other things too and different people in different situations different phenomena they deal with but across the board it's pretty much other people and so that brings up some active themes like having a shared generative model reflected by a shared narrative so like we don't all have to agree what role in the movie we are but if it's different genre

That doesn't even mean it's bad.

It just means that some people might get surprised if that's what they expect.

And then some other active things we talk about are like ostensive cues, which are used to signal attention.

And then the way that we talk about how and where attention is directed

that's the regime of attention and so when the music stops after the middle of the orchestra but everybody knows that's not the time to clap what does that say about the culture and about what everyone's attention is and that's how they signal that they're all part of the same listening community for example

when they do or don't take the action of clapping so social entities again whether it's just social projects like exchanging value for shoes or whether we're talking about the social meta which is the governance and decision making implicitly and explicitly that's where

It's such a great topic, Eugene, that you've brought because it is about that individual micro level decision making and regime of attention.

I'm scanning a proposal in my Web3 dashboard, but my literal pupil gazing and my blood sugar is going to be mattering.

And so how can we really think holistically about the regime of attention and the cues and the affordances and all of that for humans who we're designing for?

We don't want to be in the matrix pods.

We want them to have a thriving life, which is going to be different for different people.

And so it's just such a great nexus that you've brought together.

So any thoughts?

And then a few more active points.


SPEAKER_00:
Oh, yeah, I know.

I love that because that directly also ties into and I love the way you articulated that.

So thank you for running through that.

And I also an element that I that I've been thinking about in the last couple of days that feeds nicely into that in terms of right.

How do our how do our models get updated in terms of some of these social dynamics and the importance of.

exposure as a step to better managing uncertainty.

I know as someone who, like I'm not a coder, that was not what my parents showed me.

The process that I went down as a kid, I was not the kind to just figure it out on my own.

So I still have this weird fear of technology.

Like the first time I need to go do something deeply technical, I'm like, I'm just going to break everything.

It's like, it's illogical.

I know it's illogical.

I've done enough to know that it does not make sense.

And each time I do it, it feels a little better.

And sort of my internal models get updated by all the, you know, by deciding to direct my attention to

and understanding the fact that because this is something my existing models don't know how to accurately predict, I'm going to experience a certain amount of discomfort there.

taking the meta-level attention to realize that that's happening is already a great step to being able to work through more and more of that kind of uncertainty and discomfort.

Because for me, it's whatever the tools are for individuals that are important to have like, hey, are you noticing you're uncomfortable now?

Great, next time try to like catch it a little earlier and a little earlier and a little earlier.

And eventually you'll hopefully start gaining enough of a sense of what series of actions or thoughts leads to an unpleasant state and then being able to modulate certain elements of that.

right so again there's also the the other dimension of this of privilege right i've kind of alluded to it a few times but i also never want to be critical about these things because we're all coming from vastly different areas of our lives and i know in times in my life where i was you know living paycheck to paycheck and barely making ends meet it's not possible to focus on these higher order things it's just like i was i was very much struggling with that at those points in time

Now that I have a little more luxury and comfort, I'm able to spend my free time pondering in a different way, which I think is also very important to recognize when some of us think about financial distribution and paying it forward and sharing in abundance and all those kind of or effective altruism or all these other things.

At the end of the day, we all have so many options to just inject a little bit of positivity for someone else.

And the more that we choose to do that, the more we can potentially free them up to have a little more room in their cycle in a day-to-day to put their attention somewhere where it might not have been going before.

And of course it's,

it's utopic to think of like, Oh, I see someone struggling.

I do a nice thing for them.

Great.

They ponder the philosophy of life as right.

Like that's a lovely ideal that probably happens almost never, but like more realistically, right.

If we, as a, because we are inherently social because coordination is so at the core of what we do,

And because there's a lot of systems and other pressures around us telling us who we supposedly are, right.

And us trying that, having to navigate of, well, supposedly I'm selfish or I'm collective, right.

Depending on which part of the world you're coming from, that could be a core narrative you hear or all these other dimensions.

And all of this just comes back to, in my mind, like uncertainty equals complexity and control in different areas, right?

Because.

life is wild.

Like I don't even pretend to be able for my brain to be able to grasp the level of complexity and to be able to put it into words.

Cause it's just beyond what I am capable of comprehending.

But yeah,

I'm okay with that.

And the being okay with that and the desire of control of complexity is a much more dangerous thing.

And directly related to that, it might seem like a tangent, but is the idea of like FOMO or fear of missing out, right?

It's this control desire of wanting to have like, oh, I know these things and I have to be able to control my schedule so that I can get all these supposed desires out of it, right?

And the whole idea of knowing yourself and how to really know yourself is a whole separate thread I'm not going to go down in a moment.

But I recently heard the term JOMO,

And not just to give more whatever terms, but like the whole idea of joy of missing out, right?

To know that, hey, if I'm choosing to be here with you right now doing this, sure, in the back of my mind, I can cycle through all of the things I chose not to do as a result of this and I'm missing out on in this window.

Or I could just be like, no, I'm super freaking lucky that you asked me to be here with you.

And we now get to share this experience and whoever hears it gets to hear it.

And boom, I've focused all of my attention.

I don't have to worry about adding all of those other things, which in turn, right, the whole idea of fear of missing out and being always worried and wanting to like control these other factors where it just leads to this place where you are stealing your own attention from yourself away from the things that on your deathbed you might be realized were the most important to you.

And this is also to take another side step, why, in my opinion, meditating on death is very important, because that's one of the few things that can help you realize of like, oh, this was literally the last second.

How do I feel about everything that got here?

Like, that's one of the only ways, in my opinion, you can like deeply understand how truly satisfied are you with the suite of

activities you choose to fill your time.

Because a lot of us have, we are shackled by things we have to deal with.

And that is a different set of thinking and emotional judgment that should go to that direction.

If you are hyper privileged and not happy with how you're spending your time, you deserve a very different conversation than someone who, you know, is barely making ends meet, putting food on the table for a family of three or whatever, right?

Like, we also have to be realistic with ourselves and know how harsh we should or should not be with ourselves.

So I'm happy to go into more like some of my own personal psychological tools on that side, but I don't want to just keep rambling.


SPEAKER_02:
Well, this is already quite a unique and different discussion on ACT-INF.

It's really interesting.

So a few thoughts.

Uncertainty is the core of decentralization.

That's what you had brought up earlier.

And then you connected that to treating each other nicely.

So it's up to us on the edge to act, infer and serve.

the way that we expect and prefer.

It signals to ourselves, not the least of all, what kind of person we are.

Like, are you the kind of person where when the NFT is worth 100, you give five away?

Or are you stressed about 130?

Because it could be higher, because it's a number.

So it's like,

if we are gonna have that different system with decentralization, it will be not just like part of the picture that people are nice to each other on the edges, that will be the system.

So either we're not in that world or we are.

And so expecting that somebody else is going to redistribute our centralized taxes to do that is at the very least emboldening that system.

And then also it signals to others what kind of people they are

expecting to see if you pull 10 red and one blue out of an urn bayesian statistics works a certain way to update priors it could be very tight precision or very loose precision but at some point you're going to be like are there more of this one kind than the other kind and so that's related to statistics but also the way that our brain bayesian brain predictive brain uses things like statistics and that includes our cognitive

biases as they say, but of course to bias is to take signal out of the world.

So what will those signals be?

And then also when we provide people with material support, you're bringing it back to like, again, it's not just a solipsistic single trajectory optimizing strategy.

There's like a level of strategy where it's not like the individual must lose because the group has benefited.

It's like, it's an ensemble.

and one's agency and their perception and action their peripersonal space has a certain spatial and temporal scale and if one doesn't care about leaving the future a wasteland then we can talk about that in this model with their expectations and preferences maybe they have other reasons to think that way but

there's a lot there too.


SPEAKER_00:
Yeah.

Yeah.

No, I mean, just to start at the end there, I mean, the thing that, that I think about a lot in that sense is I wish that, and I'm just taking Forbes because I believe Forbes or Bloomberg, whoever does the billionaires list, right?

I wish instead of doing the list of here's the people with the most wealth in their bank account or that they can just claim their name as directly affiliated with that.

We tracked,

who's created the most jobs in the last year?

Who's actually distributed the most wealth on the planet?

Like how many people get to put food on the table that they didn't afford if it wasn't for someone else or some kind of other metrics that can be deemed socially impressive that actually reside on the,

the social dimension and not just thinking of us as individuals.

I don't want to take us more off the pathway with just like the history and wealth and whatnot in the States and any questions around that.

But for me, it does

I know one piece of research that I really appreciate in this direction is the, oh, I'm forgetting all of their names, but the group in Siberia, far out in Russia, that starting in the 70s, if not the 80s, did the training of the Arctic foxes to see how quickly, right, and Arctic foxes are notoriously not friendly or pleasant.

How quickly can they get them to be fully domesticated?

And I believe it was within 10 generations, if I'm remembering correctly.

But roughly at the time, this is still when, I mean, especially in the Soviet Union, where science was complicated for a variety of reasons, especially anything that had social implications to it and not just pure math or physics.

But there were not many people at the time who truly thought, yes, you can domesticate a wild animal shortly because there was still much more of the, you know, on the human level of we're just rigid creatures.

We are the way we are.

We don't change.

So all of a sudden that we saw that, hey, no, you can actually very select, very clearly select for certain features that get us there, right?

The interesting question for me becomes what were the features, right?

What's the thing that you pick generation to generation for selective mating that actually led to a much more domesticated version of the fox?

Not that domestication is an end goal, but it is one of a few strands of research that is trying to explore

on our evolutionary scale, what were the actual features that led to us being such good coordinating creatures up until society and modern civilization kicked in, because then things got much more complicated.

But there's very good reason to believe that it's niceness, it's kindness, right?

And like, think about a social dynamic.

Sure, there might be the super strong, macho, whatever, you know, not even trying to gender it, right?

There could be the pure, like traditional, like there's the person that can squash everyone else in the system, right?

And to think of like, oh, we all have to defer to that person.

But that seems itself to be a social construct, right?

If you actually look at what decent amounts of scientific literature are starting to point to, that it is niceness.

And that the more,

We can try to create a system where that is what is rewarded and encouraged.

Am I pretending that everyone is going to become nice?

No, there's always going to be assholes.

Like there's always going to be people who don't want to play well.

I'm just not going to let that stop me from being nice to other people, right?

You can either have someone be mean to you and be like, well, why should I bother being nice if they're not going to be nice to me?

Or I can be like, yeah, people are people, right?

Some are just going to suck.

And that's just how it goes.

Because when you have this much uncertainty, there's no way you can like all of what's in that uncertainty, right?

If you can find certain strands of it and just be okay with the complexity of it and find comfort in knowing that I will never solve this riddle.

but I get to be part of just playing around and tinkering with it.

Like that alone can be really empowering and exciting.

So I don't know, for me, I keep trying to reframe niceness as not just like a,

a either a, you know, a thing that your parents taught you to do, because that's just the thing that they want you to do.

Whereas this, you know, it's thing, it's actually socially weak.

And I don't know, I don't buy in any of that.

And I as someone who enjoys it, I now enjoys genuinely just being nice to people or when people are nice to me.

It's nice to see that there is research coming out to say, hey, hey, there's reasons on a on a neural level why that feels good, but also be on a longer evolutionary scale, why that is the feature set that we should focus on in system design to actually get us collaborating better together.

But that doesn't solve the fact that there's a lot of incentives around not pushing us towards niceness.

And for me, that means if we're trying to create systems where that is a thing we want to optimize towards, but that is in a larger structure where that is not a key priority, that just means we're going to have a tremendous amount of dissonance between those two systems.

And if you're trying to fight that good fight, good just in the sense of being kind to each other,

it's going to suck, right?

There's no way it cannot unless all of these systems break down and we build a new.

And to me, that's a much scarier option.

Because anything that involves like truly bringing down mass global systems, I don't see how that happens without very intense international affairs that I would personally be okay without seeing.

So I think that you just have to be, unless you truly want World War III and near extinction, and then we rebuild from there, I think the only alternative is we just got to suffer through the fact that it's going to take us a while

But we'll get there eventually.

But just be good to people.

And a lot of amazing things can happen from that.


SPEAKER_02:
WGMI.

Well, thanks for bringing that important perspective.

Sometimes it's easy to get caught up in how many papers are written on active inference and just the rhythm and the micro.

that's exactly what you're really calling towards.

So let me bring it back towards some active core terms and like ideas, and let's see where maybe the niceness and some of those ideas come back into play.

So we already talked about uncertainty being one of the key

factors and that not being like a hot take or contrary an opinion it's like a de facto understanding that what is happening from a sensory perspective is not mere signal processing and filtering and the way that a one directional neural network processes sense but actually like an active generative process that's compared to incoming scarce data that's why we like don't have a blind spot in our eyes and things like that so

that is not contentious it is a core piece of active inference however now in active inference there's action amidst uncertainty and so that's a lot like the action perception loop or the OODA loop for those who are familiar with it and

Every single cycle, every crank that's run, inference and action are co-occurring.

And so there's a few angles to that.

First is that we never make a system where we're expecting to do something that it's not enabled to do or vice versa.

So even just qualitatively before the computers come out, this helps think about how subunits are connected.

Like if the forager ant is waiting for the interaction from the nurse ant,

but the nurse aunt doesn't have that affordance, there's a missing piece in the system's design.

And so, yes, it is going to be a whole other level of emergence with fine-tuning that interaction, but just at the level of thinking about what the entities and their connections are and how they influence the niche, Active reminds us that action and perception are integrated at that level.

Also not unique to Active Inference, very similar to any kind of cybernetic or agent-based modeling framework.

But what is different is the way that we can talk about different types of uncertainty and even things like multi-scale uncertainty, or for example, uncertainty about events.

And there's other talks.

I hope people go down the rabbit hole 101 ways because we've talked a lot about different uncertainty formalisms on ActifLab.

And I hope there's a lot more developed on those areas.

But just to say that

Again, one could imagine like using that earlier example of being in a movie in a genre, you could have high precision on the genre, but then maximum uncertainty about what is going to occur next in that, like a thriller with a stereotypical in culture set of music and lights and all of that.

Or you could know exactly what was happening.

Oh, it's just counting down the numbers one after another with high precision, but not understand the narrative component.

So I think to connect it to web, whatever, and systems design, what is it that we want to reduce our uncertainty on?

And how can we really bring our attention to the types of uncertainty that matter for humans' affect, for how we feel in our phenomenology, and the system uncertainty nodes?

Like if the block arrival time starts getting too wild,

we don't want that to go off the rail that's like a technical use of uncertainty minimization and control but then this embodied perspective on humans as active agents brings the human level of uncertainty in and not everybody wants to be on a live stream not everybody even wants to


SPEAKER_00:
have a say on a decision-making proposal but how could we reduce their uncertainty about what they do expect and prefer and customize that and i think that's where cognitive frameworks like active could come into play yeah i mean that's one where i guess it's also important to note that i don't know if the quote-unquote average person in web 3 and i have no clue what that even means but if if if you pulled you know there's going to be eat denver next month i would actually

This would be a fun study to run if I had the time and energy.

But you ask 10,000-ish people or whatever absurd amount of people are flocking to Denver for this conference,

what term is at the core of Web3?

And I actually wonder how many of them would put uncertainty and how many people would tell me I'm a madman for thinking that that's a core of decentralization.

Because I think that a lot of what I hear at least is the idea of, oh, we're adding an automated trust layer, right?

So that's actually minimizing uncertainty.

What are you talking about?

We're adding uncertainty.

We're trying to, you don't have to trust in people.

You can trust in systems.

You know, you don't have to trust in a banker at someone at J.P.

Morgan.

You can trust the protocol instead.

And then, you know, it's all great.

But I mean, I think that goes back to some of the other aspects we were talking about on what level and what part of the system, because if you're actually talking on technical architecture, yes, you could just have less humans needing to interact at a certain point.

But if then you're talking the complete set of full human interactions using that protocol,

A few years ago, there was the debate on what's more relevant for blockchains, off-chain governance or on-chain governance?

Can you automate things that it's a quick yay or nay and it's all automatable and it's all interacted purely through code?

Or do you need humans talking to each other?

And I feel like there are some, you know, like an interest rate going up or down.

Yeah, sure.

Those things might be on-chain governance oriented.

Anything that actually involves more complex questions or even more complicated, right?

With the distinction being that complicated is still modelable, complex has emergent behavior, right?

Even with complicated things that could already kind of get challenging in terms of just getting humans to agree on things.

So, yeah.

I am not a big proponent of the goal of all of this being humans have to decide less.

I think that, yes, it's always great to, you know, do we, right?

There's a few aspects here of which I am myself uncertain about, right?

There's almost an unstoppable force that is more technology, advancements of technology.

Automation, to a certain degree, is happening to the world, to us, whether or not we like it.

Um, the question is, what are we trying to automate?

And I feel like that's still very much an open question.

And I, I am, I don't know.

The, let me see the best way to move this forward.

I think at its core, I've heard one thing, the idea of it's coordination all the way down.

Right.

In the crypto space or web three space, whatever that at the end of the day, what is the most base thing that human, that as a species we are doing, we are coordinating.

Right.

Because if we're already taking for given that we exist, there's many of us here and we have desires, then we have to ask of like, oh, well, how did we get here?

But it seems that coordination was a very key part of differentiating us from some of our other ancestors down the line.

And so.

For me, coordinating is inherently uncertain.

People being people together is an inherently uncertain task because unless you heavily constrain and force people to be less themselves, right?

If you're telling someone, don't be yourself, be this thing I want you to be, then you're minimizing uncertainty, right?

You're telling like, I don't want Daniel.

I want a version of Daniel that I would like to see, right?

That is minimizing uncertainty.

The whole idea of seeing people for who they are and where they're at, that's adding complexity.

That's adding uncertainty.

That's saying, I don't need to know where you're at.

I just need to recognize the fact that I will never know where you're at because I'm a different human.

I have a different lived experience than you.

All I can do is, with my limited abilities, try to project and understand what's going on with you and use a mix of empathy.

Can I just feel those emotions?

And compassion, can I rationalize that feeling and do something about it?

And for me, compassion is much more important than empathy.

Because empathy is deep and psychologically taxing and very limiting in terms of the amount of people we can direct it towards.

Compassion, and I just finished Rutger Bregman's Human Kind book, right, where he, and it's not as though it's his idea, but the whole idea of rational compassion being much more of a scalable concept than pure empathy.

Because if you try to empathize with all people on the planet, that's just not going to work in any way possible.

Rational empathy can be something that we utilize as a more focused, rational compassion, excuse me, can be more of a tool in our tool belt to not just fall into tribal camps, but to try to actually think of how can I see your pain as a person who is totally different than me in every way, shape or form as our pain.

And that kind of reframing is a very, very powerful thing.

But I also want to jump back to what you started with, because I know it's a given in certain circles.

But for me, that's actually part of the problem, where you were talking about the whole idea that we don't know our realities, our brains are prediction machines, all these.

You mentioned the blind spot.

I don't know.

Do most people realize that we literally have a blind spot in our vision, and the only reason we still think we always see things is because our brains predict over it effectively?

I wonder if you came up to a person on the street and you're like, hey, look around.

That's not objective reality.

Would they tell you that you're on drugs and crazy?

Or would they be like, yes, yes, let's have a scientific dialogue, right?

And I, excuse me for the previous statement, but like, it's the point being there, right?

People don't react kindly.

At least I've had that reaction a lot of the time, even with well-educated people.

So it's not a pure education perspective.

And for me, getting people, like that comes back to people embracing uncertainty.

How do we encourage people to recognize that I fundamentally don't know anything about anything?

Hopefully, through education and a lot of intention about my attention, I will try to learn a few things.

But in the grand scheme of collective knowledge, I will never know anything.

And like, that's a weird thing to admit to myself.

Like as much as I really try hard, I can hopefully learn some concepts and frameworks that broadly apply to whatever environments I find myself in.

But in the grand scheme of information, even if you have photographic memory, you practically know nothing just because there's so, so much of it.

And.

I don't know, for me, that's also been more of a liberating thought.

Whereas when I was younger, it was always a very fear based like, oh, no, that just means work harder.

Whereas now it's like, no, just embrace the uncertainty.

Embrace the washing over of I will never do everything.

So just be intentional about your attention and what you do want to do and make the most out of that.

So I feel like I went on a hard tangent on that one.

That just felt important to call out.


SPEAKER_02:
I have some points directly to this.

So thanks for sharing it.

So yes, there are niches on the internet or in real life where it is a beginning point that the brain is a predictive entity or at least could be modeled like that, which we...

discusses the difference between instrumentalism, are we just applying statistical models and we're just making no claims to the territory?

We're just talking about maps.

We're like cartographers.

Or are we making ontological statements like the brain does active inference?

Realism, instrumentalism is like, I find it useful to study the brain using this model.

So if someone used a linear regression, they wouldn't say the brain was a linear regressor.

We're doing that with instrumentalism for actinth.

Also there's realism.

So that's like one point to make, but you pointed like how some people resist that sense of realigning their generative model to this idea that we are,

experiencing our generative model.

So I think there's a few pieces.

The meta is we've all been wrong before.

We've been convinced on something and been wrong.

So your emotional conscious experience, which is only the tiniest fraction of the iceberg, just simply can be incorrect by virtue of the way you've had interactions in the past.

So it doesn't need to be framed as right or wrong.

There's some useful components to thinking about the brain as a predictive machine, and it gives us unique predictions and explanations.

So for people who enjoy those features, this is a useful way to think about the brain.

So one example is like vision, where the anatomy of the eye

is clear that there's a blind spot that's off on the side.

And also there's different resolution and color perception across the eye.

So we're perceiving with our mind, not our eye.

But of course, input to the retina and light activation matters.

It just turns out that there's a lot more of an actively updating process.

And it turns out that's the one that we're perceiving without the blind spot rather than the incoming sensory data.

And that also applies to our other sensory features.

what's cool and closes the loop between individual decision making and behavior and like science as a human endeavor is that it turns out that in order to get good information about that generative model one has to do informed sampling like our eyes are circadian around we don't perceive that so that's another example of why we're perceiving the stable version of vision which is not being received by any sensor and it

secades around the vision to reduce uncertainty goes where there is visual uncertainty and so that generative model isn't just like a sort of one frame per second of what is predicted to be there it also carries like extra information like where are you uncertain in your visual field um

So that is like the process of being a scientist where you're getting experimental observations, but then there's a system you didn't observe.

Sometimes you destroy the cell to measure it, or you have to kill the animal or whatever it is, but there's observations and then there's the hidden system state.

And it turns out that that maps onto a lot of statistical models like the partially observable Markov decision processes, which integrate that separation between observation and hidden state inference

in the context of action selection.

So that's kind of the family that active inference is in.

And then just the second point was about the empathy and complex online systems.

And another active inference term is this thinking through other minds.

So it's related to theory of mind, just like it sounds.

and it's referring to when one's uh counterfactuals or their cognition is based upon how they expect something will be evaluated by others like i will do x with my clothing or speech this could be implicit or an explicit uh self-talk because others will see me this way because my partner will see me this way or because my dao will see me this way so that helps us

get a handle on complex social cognition if we can have models of cognitive entities that can engage in reflection and have anxiety and then um that's where roles in complex systems might come into play so you said that roles reduce uncertainty um i agree sometimes they reduce uncertainty about one node but then they expand it like you're gonna be the saxophone soloist

and I'm looking forward to how you improvise then.

So it's like, we reduce the group's uncertainty, who's gonna be the soloist?

But then that's what opens up the certainty distribution in another way.

Or like, we're playing chess.

Well, you can have brilliant games of chess,

because there's constraint and there's like roles and but if if people were always mutating the games of chess there wouldn't be as many classic games because like the structure would just be a lot more superficial and so roles might be able to help us reduce uncertainty about certain features

And then humanize because, oh, they're a learner in this meeting.

Amazing.

Citizen science is so great.

I love working with people who are just learning about research.

And then everyone can feel included in that.

Even if it takes them 15 years to learn linear algebra in that one meeting, it could be very okay.

And nobody would be getting graded, for example.


UNKNOWN:
Yeah.


SPEAKER_00:
And I think that especially the last element that you were talking about there,

I think it's important to stress the difference between embracing uncertainty and maximizing for uncertainty, because I feel as though people might unintentionally hear the idea of embracing uncertainty as that is an implication that more uncertainty is always a good thing.

Where I actually think when you're designing a system, if you want people to flourish, giving them too much uncertainty is a debilitating factor.

So there's the system design component from the actual function of the system, and then there's the cultural psychological component around it.

And on the cultural psychological component, that's where, as a designer of a system or community or company or whatever, you think of how you set that cultural tone.

And you, by interacting with people in various ways that you do in your organization,

you set a certain tone of, are you embracing uncertainty or do you always want to, especially if you're the leader in your organization, do you need to show this facade of like, no, I'm always certain on everything, right?

Because that actually sets a cultural tone of it's okay to be fakely certain, right?

Like there's no way you're certain about everything.

I think every leader is inherently uncertain about things because just of how many options there are, but you also need to know when to be okay with that uncertainty.

And in spite of it to still be like, no, we're doing this one thing and that's the direction we're headed in, right?

And like, that's its own,

its own interesting aspect.

But I think that when it comes to designing any system, whether it's web three, crypto, whatever you're, you know, you're carving out an internship for someone like whatever it is, but creating constraints, and a sandbox is very important for people's comfort level.

So I think the way I like to think of it is the amount of constraints need to be greater

while people are newer to things, and the more they're exposed to it, potentially, the more you can open up for them, right?

Again, not everyone is going to be, not everyone thrives in having uncertainty.

Some people need their hand held through it, and then they can start thriving.

Some people, at least I, right, I don't have enough evidence over a long enough time period to know, but there are some people for whom adding uncertainty, just everything collapses and crumbles around them, and like their role in the system just cannot proceed.

And like, if you're building, right, you can think of DAOs as these fantastic new futuristic, these are employment opportunities for people, right?

Like people need to buy food and they get it now from decentralized ecosystems in some capacity.

So, right, you can't, this is where I actually, I still am unclear on how I think.

Because if you go to a lot of these communities and you're like, oh, how do I get started?

Just do stuff.

And that's great for the privilege, right?

What happens when someone's like, well, I hate my job.

I think I can help you here.

I want to help out, but I need you to like help me help you out because how else am I going to pay for my kids' food tomorrow?

And I can't make a change in my ecosystem and I can't just spend, I don't know how many hours your listeners have spent trying to get onboarded into various DAOs.

It can be a painful experience, right?

A lot of these groups were started by a bunch of brilliant people who come together and it's other brilliant people who get pulled in.

And then all of a sudden when it's, well, what's the ramp way for someone who has no clue what the heck is going on here?

That was an afterthought.

And that was kind of produced after the fact when someone complained about it or once we had enough time.

And so, yeah, uncertainty is this fascinating concept because you have to know when adding more of it is a good thing versus when adding it is a bad thing.

And you have to know from a system design perspective, where do you culturally embrace it versus where do you actively try to get rid of it at all costs?

Because that's, what's going to help your team thrive and you can still embrace it and want to get rid of it in certain areas.

Like those are not inherently contradictory.

You could be like, I don't know what the next year holds from the market, but in this specific function of operations, I'm going to hyper control this in every possible way so that I know the outcome of high probability.

Think of anyone in a supply chain.

If they tell you where they know what's happening with the resources three years from now,

They're lying.

No one knows what's happening three years from now, right?

But they could model it better than someone else, right?

But in their actual supply chain, they could control that fabricated room so that they literally know every speck of dust in the air, right?

And that might be worth mitigating uncertainty there while still embracing it in the longer term.


SPEAKER_02:
okay few points first inactive inference where we put action on an important grounding with other kinds of inference processes it's not just uncertainty about the outside world which of course it's easy to spiral on it's actually also uncertainty about our action so huddle i have high precision on my action policy with respect to btc no matter what

color on that site that day so that helps uncouple and put space between or it's staked it's locked or it's a multi-sig so that can offload individual level uncertainty and anxiety onto programmatic systems so then the certainty in systems design so i don't remember who initially told me this anecdote but like

The people who we today call politicians will say things like, we're not going to sleep until this happens and it will happen.

But no one says, it's so important the bridge be designed properly that we're not going to sleep.

It's a serious issue.

Yes, lives are on the line.

We're building a bridge.

So how do we do it?

We have bridge management and design and processes around making sure that it actually works.

So as governance becomes less about the virtue signal of we're not going to sleep until we figure this out and more about we're actually doing systems engineering,

we can treat it more like the bridge and say, yeah, oh yeah, we're all here.

We direct the regime because we care about the people on the bridge and that's why we're doing it this way.

And so that will be a huge difference than just who can signal loudest.

And then just one other,

point was like research to bring this back to decentralized science and research is a multi-year task like i've been doing entomology insect biology and insect genetics for 10 years and i'm only beginning in this area

So it's cool to be excited about many areas.

That's why there's always been like complexity and it's awesome to be open-ended and love exploring those areas.

But for research and application, like the cutting edge, it is a multi-year upskilling, reskilling process if you're not on the cutting edge.

And on the cutting edge, it's just continually that, plus sometimes even more.

So being okay with all of that

And then just recognizing that it's a multi-year process and whatever mechanisms for whomever and when and however, we need something that's going to not just rapid assemble the bounty team and then do the multi-sig and then leave.

some people might find those opportunities appealing.

But we need to recognize that a huge amount of this is going to be like multi-year communities and the kinds of relationships and small teams that will only scale if we're all engaged in it.


SPEAKER_00:
Yeah.

Yeah, that makes me particularly think about two aspects, kind of community size and temporality of change or the time dimensions of change.

And on the community size front,

And again, this is not an area where I think anyone has the answer.

This is just me kind of giving my own views and personal biases here.

But I strongly believe, and especially just exploring what I've been exploring in this world and generally trying to learn in the direction that I've been trying to learn, what I get excited about DAOs is actually providing the digital infrastructure for a super nuanced global landscape of communities of communities.

Where at the end, when it's humans actually organizing and making decisions together actively, or at least most on kind of the consumer end, so to say that those are going to be in tiny pockets and above those pockets will be bigger and bigger communities and points of connection that are more global and bring them all together.

Right.

The whole idea of say for something like a supply chain, how can you have a system that you have the global benefits, right.

For consumers.

It would be great if Amazon covered all of the global distribution, right?

For the people working in those factories, it would not be great for that and possibly for our planet.

I don't know on their global footprint well enough.

But right there is this idea of how can we get to a point where we have global efficiency around a variety of topics while still having very localized interaction and nuance?

And this for me on a very abstract level is why decentralization is important.

because we are currently barreling towards a world of more and more centralization, right?

It's the monopolies because, or whatever, I don't want to have pointed terms, but you know, companies tend to have more market share.

They try to like, their only goal is how do we not just grow the pie, but how do we make the biggest share of the pie hours, right?

There's a lot of fundamental incentives that, um,

that are not the healthiest, so to say.

But at the same time, having global efficiency around certain functions, such as a supply chain, such as global money, such as global identity, would be great.

But having those certain infrastructures available on the global scale is very different than what you would actually, the environments you would organize in as an individual.

And I don't want to be part of 50 million person communities because then I'm going to be overwhelmed and I'm going to have no clue how to navigate it.

And I have no clue what the heck to do in that.

I'm just going to find my core group of people of a few, a handful to a few hundred and somewhere in there.

And that's probably going to be more of those size communities that I play in.

So bringing it back to more DAOs and especially research DAOs right now.

So I can also share with you the link.

I don't remember if I did ahead of time, but I'm just putting together a different organizations that are in one way or another playing around with the intersection of DAOs and science in some kind of capacity.

And some of these groups have nothing to do with Web3, except that they're using it as a DAO as a mechanism of coordinating and funding, right?

The actual science is all non-related to Web3.

Um, and that gets me super excited.

And I think, uh, thinking from the course tiniest aspects of like us as a group of scientists, where do we want our research or whatever we're doing to have an impact?

Great.

And then for people like me who, for whatever weird reason, love building infrastructure or just open source and just operational layers, how do I work with those separate pockets to be like, hey, y'all shouldn't be worried about the operations.

There should be a DAO of operations wrapped around all of the science DAOs that help you do the operations.

And there should be a fundraising DAO wrapped around all the science DAOs that can connect all the main science funders across the planet.

And there are these mechanisms that just incentives have never existed there before.

and i honestly don't think they're there yet these are still from my vantage point these are still public goods that in any other context but web 3 would comfortably say yeah we need tax or charity to make this run but web 3 being web 3 those are both bad words right so we have to pretend that it's oh we'll just keep having money trickle in because right now money grows on trees and no one's working about worried about sustainable funding 50 years from now right but at some point

this fun part of our dance comes to an end and we have, you know, we're not just growing on the HODL beliefs at some point.

At some point we recognize like, no, we've reached probably the zenith, right?

And at that point, how are we actually going to fund anything that's an infrastructure layer?

And right now there's some really interesting experimentation.

I know we've met a Gov, the community we've mentioned, they have a DAO to fund research

uh in the direction of governance like i love these kind of experiments but again peer review and that's one that we want to take a serious focus at at smart contract research forum because we don't see who's playing in that direction we see some people playing on the publishing side we see people wanting to do the research side right but the core infrastructure is just it's less sexy it's not as fun to build and you don't get to have your name out on things right so like that that's where it's like i that's where we want to take a focus on what we want to add but i want to be respectful at times i know we're getting dangerously close to the end here


SPEAKER_02:
Let's have some last thoughts and then we can do a dot too, we can do more.

So yes, BOLTS, business, operational, legal, technical, social, that's one acronym that we use.

Those are all important for research.

And if the person who has the most knowledge of equations is doing the accounting,

it is not efficient allocation and then font like formal documents ontology narrative and tools so those are some of the frameworks first thinking about systems design and then review um well here on the live stream where we've done like 36 paper discussions over the last two years or so um we often wonder about where that could go so um

having 10 people look through it and different people do different thing.

One person runs the code, one really digs in the citations.

It's a live stream.

People are rewarded by participating in the lab.

We're learning by doing.

I'm spending more time reading active inference papers than writing them by far.

And most researchers probably are too.

Otherwise one starts getting disconnected from the pack.

So how can we make that contribution, those notes that people make in review

not like accept or reject but yes and and then we have other people's perspective on something it doesn't mean that it's right so there's so many things that can be done with knowledge annotation and that sounds like a great area to look into i totally agree that there's been a lot of focus on financialization tokenization um conceptualization in research and the parts that i would like to hear more from

is that recognition of the multi-year challenge and about what kind of research people want to specifically do and spearhead and hold on tight through because even when you're getting paid as a grad student in a really lucky situation it can still be challenging so when those features like healthcare and weekly check-ins with a mentor aren't in place that's the situation where

research will be happening.

So what are your last thoughts?

Or where do you think we should go from here?


SPEAKER_00:
I mean, I think right careful experimentation, I think is very important right now.

And I also think it's important for the folks who are experimenting to be aware of the potentiality of their experiments.

And I think we've all seen the how

move fast and break things without any concern for potentialities of outcomes can lead to very bad outcomes so you know for folks who are experimenting with something that realistically is almost has a you know a sub one percent probability of ever having a meaningful negative impact on a person yeah go crazy have as much fun as you can experimenting in that direction right the more it's actually closer to where people are making their livelihood and are spending their lives and that it can negatively affect a lot of people the more that review focus and the more

questioning their needs to be about how do we make sure that we're doing this right?

So honestly, I'm just really excited.

We're still early in 22.

It's been a whirlwind these last few years in so many different ways.

I'm just hoping that there's more chances for coordination, for collaboration, and especially for folks in the Web3 space.

I don't mean to make whatever predictions.

At some point, the market is going to turn, right?

I'm hoping we haven't started yet.

Maybe we're already at the beginning of the bear market.

Who knows?

I'm not going to pretend to... Not financial advice, not scientific advice, not legal... No, no, no.

No formal advice.

Human to human personal advice, maybe.

Nothing beyond that.

Right, but...

I'm very interested to see once we hit the bear market, what does the collaboration look like?

Because I think that's actually going to be where a lot of gold comes and a lot of just intellectual brilliance comes out because then a lot of the noise is going to run away.

So I know a lot of people because of their bank accounts are horrified of when the market turns and I get it, but I actually think it's going to be very good and healthy for the industry over the next three to five years.


SPEAKER_02:
And the way you...

raised so many important issues, big thanks for that.

And with the review, it's almost like we are focusing on the publication and the research and the funding sides, but that piece of review, it's almost like the first one we need.

That is a strange loop of science and we need review on the plans for DeSci and review on the frameworks for building the plans for DeSci and on all of that.

And so that's like Review Guild is really a strong place for people who want to learn by doing and be a big leverage point.

It's like the coefficient of the grants.

And the way that knowledge by people who are off doing field work gets incorporated is through review, especially in these new structures, which we probably haven't even seen yet.

But they're not going to look like proceedings of the UK 1600 alchemists.

It's going to be quite different.


SPEAKER_00:
That is for sure.

Yeah.

And for anyone, if you are interested in peer review or these kind of decentralized science, decentralized peer review, decentralized publication of research,

please let me know.

Always feel free to reach out.

I love connecting with folks and talking to a lot of folks who are trying to solve this problem from different perspectives and trying to figure out how we all come together to at least share our learnings, if nothing else.

And I'll definitely make sure to coordinate with you and the active community on that side.


SPEAKER_02:
Let's do a dot two with a panel in one or a few months.

Let's check back in on some of these themes, revisit the slides, hear from some new perspectives, update on the projects that we talked about today, and just see where we're at.


SPEAKER_00:
Sounds like a plan.

Thanks for having me again, Daniel.


SPEAKER_02:
Thank you, Eugene.

Awesome conversation.

Much appreciated.

Bye.