1
00:00:39,287 --> 00:00:41,727
>>> DANIEL FRIEDMAN: All right, hello everyone. Welcome.

2
00:00:41,895 --> 00:00:45,507
This is active livestream number 51 one.

3
00:00:45,660 --> 00:00:49,197
We are in the second discussion of this

4
00:00:49,230 --> 00:00:51,372
paper, canonical Neural networks perform

5
00:00:51,480 --> 00:00:54,482
active inference. Welcome to the active

6
00:00:54,497 --> 00:00:56,382
inference institute. We're a

7
00:00:56,385 --> 00:00:58,677
participatory online institute that is

8
00:00:58,695 --> 00:01:00,527
communication, learning and practicing

9
00:01:00,557 --> 00:01:02,817
applied active inference. You can find

10
00:01:02,865 --> 00:01:06,207
us on this slide and this is recorded in

11
00:01:06,210 --> 00:01:08,262
an archived livestream. So please

12
00:01:08,325 --> 00:01:09,977
provide us feedback so we can improve

13
00:01:10,007 --> 00:01:12,177
our work. All backgrounds and

14
00:01:12,195 --> 00:01:14,157
perspectives are welcome and cell follow

15
00:01:14,235 --> 00:01:16,387
good video etiquette for live streams,

16
00:01:16,887 --> 00:01:20,097
head over active inference.org to learn

17
00:01:20,130 --> 00:01:21,897
more about the institute and how to

18
00:01:21,930 --> 00:01:24,162
participants in projects and learning

19
00:01:24,225 --> 00:01:27,867
groups. All right, we're in

20
00:01:27,915 --> 00:01:31,647
act instream number 51 one, and having

21
00:01:31,755 --> 00:01:35,792
our first nonsolo discussion

22
00:01:35,852 --> 00:01:38,072
on this paper, canonical Neural Networks

23
00:01:38,117 --> 00:01:41,217
perform active inference and really

24
00:01:41,265 --> 00:01:44,877
appreciative that you've joined today.

25
00:01:44,970 --> 00:01:47,282
It's going to be a great discussion.

26
00:01:47,447 --> 00:01:49,917
We'll begin with introductions. I'll say

27
00:01:49,965 --> 00:01:53,307
hello and then please just jump in

28
00:01:53,385 --> 00:01:56,382
however you'd like and we can start by

29
00:01:56,535 --> 00:01:59,942
settling plant context. So I'm Daniel,

30
00:02:00,002 --> 00:02:03,252
I'm a researcher in California, and I

31
00:02:03,270 --> 00:02:05,862
was interested in this paper because

32
00:02:06,000 --> 00:02:08,252
we've been talking a lot about active

33
00:02:08,282 --> 00:02:10,512
inference from a variety of different

34
00:02:10,575 --> 00:02:13,592
perspective, from the more fundamental

35
00:02:13,727 --> 00:02:17,387
math and physics to some applications,

36
00:02:17,462 --> 00:02:20,562
philosophy embodiment, all these really

37
00:02:20,700 --> 00:02:23,382
interesting threads. And this paper

38
00:02:23,460 --> 00:02:26,822
seems to make a really clear meaningful

39
00:02:26,942 --> 00:02:29,517
contribution and connection by

40
00:02:29,565 --> 00:02:32,862
connecting act of inference entities and

41
00:02:32,925 --> 00:02:35,852
this approach of modeling to neural

42
00:02:35,882 --> 00:02:38,367
networks which are in daily use

43
00:02:38,490 --> 00:02:40,827
globally. So thought it was a

44
00:02:40,845 --> 00:02:43,647
fascinating connection and really

45
00:02:43,680 --> 00:02:45,897
appreciate that we can talk about this

46
00:02:45,930 --> 00:02:48,550
today. So to you and welcome.

47
00:02:54,375 --> 00:02:56,580
Go forward takuya, however you'd like to

48
00:02:56,702 --> 00:02:59,337
introduce and say hello. Yeah.

49
00:02:59,700 --> 00:03:03,135
>>> TAKUYA ISOMURA: Hi. I'm Tafia Isomura, neuroscientist in

50
00:03:03,167 --> 00:03:06,175
Lique Brain Science Institute in Japan.

51
00:03:06,525 --> 00:03:10,355
I'm particularly interested in universal

52
00:03:10,490 --> 00:03:13,680
characterization of neural network and

53
00:03:13,727 --> 00:03:16,370
brain using mathematical techniques.

54
00:03:16,535 --> 00:03:19,785
So this work I

55
00:03:19,817 --> 00:03:23,262
believe important as a link between

56
00:03:23,925 --> 00:03:26,500
active brain forest aspect, Bayesian

57
00:03:26,925 --> 00:03:29,495
aspect of the brain, and the dynamics

58
00:03:29,585 --> 00:03:33,500
system aspect of the neural network.

59
00:03:33,650 --> 00:03:36,600
So I'm very happy to join this

60
00:03:36,662 --> 00:03:38,535
discussion question. Thank you for

61
00:03:38,567 --> 00:03:40,962
invitation. Nice to meet you.

62
00:03:42,000 --> 00:03:44,337
>>> DANIEL: Nice to meet you as well.

63
00:03:46,350 --> 00:03:49,445
The first thing you added, the universal

64
00:03:49,535 --> 00:03:51,700
characterization of neural networks.

65
00:03:52,275 --> 00:03:55,175
What is the universal characterization

66
00:03:55,250 --> 00:03:57,480
of neural networks? Why is it being

67
00:03:57,527 --> 00:03:59,712
pursued in this area of research?

68
00:04:01,200 --> 00:04:04,437
>>> TAKUYA: So as a narrow sense,

69
00:04:05,100 --> 00:04:08,835
my gain aim of

70
00:04:08,867 --> 00:04:11,712
this paper is that so, you know,

71
00:04:13,275 --> 00:04:15,305
people use active inference

72
00:04:15,440 --> 00:04:20,150
communication to characterize brain

73
00:04:20,225 --> 00:04:24,030
activity, behavior, so on, so on bit,

74
00:04:24,227 --> 00:04:27,375
which would be different from

75
00:04:27,512 --> 00:04:30,300
conventional neural network. So there is

76
00:04:30,437 --> 00:04:34,125
a crossover program which is

77
00:04:34,187 --> 00:04:37,190
associated with conventional neural

78
00:04:37,220 --> 00:04:41,187
network and it is not very clear whether

79
00:04:41,925 --> 00:04:44,510
all characterization of computational

80
00:04:44,555 --> 00:04:47,025
neural network can be explained by

81
00:04:47,087 --> 00:04:49,935
activity structure principle or not.

82
00:04:50,042 --> 00:04:53,030
So here, universal characterization

83
00:04:53,165 --> 00:04:55,770
means that characterization of every

84
00:04:55,847 --> 00:04:58,750
aspect of conventional neural network,

85
00:05:00,000 --> 00:05:03,135
which is a kind of dynamics system

86
00:05:03,317 --> 00:05:07,287
derived as association between

87
00:05:07,800 --> 00:05:11,400
biological phenomena and simple

88
00:05:11,537 --> 00:05:14,390
mathematics, car formula using gift

89
00:05:14,420 --> 00:05:18,360
card, using differential equations as

90
00:05:18,392 --> 00:05:21,860
the broad sense, I think universal

91
00:05:21,905 --> 00:05:25,062
characterization means that?

92
00:05:26,025 --> 00:05:29,690
Well, it is a characterization

93
00:05:29,795 --> 00:05:32,625
of brain intelligence, but it's a big

94
00:05:32,687 --> 00:05:36,960
picture and the paper particular

95
00:05:37,067 --> 00:05:40,440
address is only one aspect of

96
00:05:40,532 --> 00:05:42,250
the Bull picture.

97
00:05:46,200 --> 00:05:49,950
All right? So it'll be great

98
00:05:50,012 --> 00:05:53,370
to pull back to really understand what

99
00:05:53,522 --> 00:05:56,565
synthesis is happening. So I'm going to

100
00:05:56,582 --> 00:05:59,790
ask what makes a neural network model,

101
00:05:59,882 --> 00:06:02,790
a neural network model and what makes an

102
00:06:02,807 --> 00:06:04,490
active internal model, an active

103
00:06:04,520 --> 00:06:07,515
inference model? Is this synthesis and

104
00:06:07,532 --> 00:06:10,860
connection you've made true because of

105
00:06:10,892 --> 00:06:11,487
what?

106
00:06:14,175 --> 00:06:17,760
Because basically what

107
00:06:17,792 --> 00:06:22,525
we show is the mathematical

108
00:06:22,875 --> 00:06:26,655
equivalence between the formulation of

109
00:06:26,852 --> 00:06:28,740
canonical neural networks and the

110
00:06:28,757 --> 00:06:31,890
formulation of active inference. In the

111
00:06:31,907 --> 00:06:35,430
sense that we show that as possibility,

112
00:06:35,552 --> 00:06:38,610
neural networks can be characterized by

113
00:06:38,717 --> 00:06:41,075
minimization of some biological

114
00:06:41,150 --> 00:06:43,530
plausible cost function. And we show

115
00:06:43,577 --> 00:06:46,812
that that cost function can be lead as

116
00:06:51,225 --> 00:06:53,430
variational based on inference and a

117
00:06:53,477 --> 00:06:57,465
particular cross of gentlemen model in

118
00:06:57,482 --> 00:07:00,860
terms of well known partially observable

119
00:07:00,980 --> 00:07:02,187
position process.

120
00:07:06,000 --> 00:07:09,560
Alright, shall we perhaps

121
00:07:09,680 --> 00:07:13,215
walk thought some of the sections of the

122
00:07:13,232 --> 00:07:17,790
paper? It would be awesome just for

123
00:07:17,807 --> 00:07:20,415
each of these sections, maybe the

124
00:07:20,432 --> 00:07:22,800
numbers and the lettered sections. What

125
00:07:22,862 --> 00:07:25,260
does the section aim to show and why was

126
00:07:25,292 --> 00:07:27,087
it there in the paper?

127
00:07:37,125 --> 00:07:41,090
Briefly it's

128
00:07:41,120 --> 00:07:45,180
order, right? So briefly so

129
00:07:45,227 --> 00:07:49,150
first we introduce

130
00:07:50,550 --> 00:07:53,490
so the gain issue main program,

131
00:07:53,657 --> 00:07:56,787
our interest which is relationship.

132
00:08:00,975 --> 00:08:04,005
We try to make a formal ring between

133
00:08:04,052 --> 00:08:05,915
neural network and active reinforcements

134
00:08:05,945 --> 00:08:09,935
that gain program background.

135
00:08:10,055 --> 00:08:14,125
And then we first formulate

136
00:08:14,850 --> 00:08:16,640
the equivalence, mathematical

137
00:08:16,670 --> 00:08:19,535
equivalence in a very Brea manner.

138
00:08:19,730 --> 00:08:23,175
So in the first section in

139
00:08:23,237 --> 00:08:28,785
results, we formulate the

140
00:08:28,817 --> 00:08:33,285
relationships using complete

141
00:08:33,392 --> 00:08:35,960
craft serum, which is well known

142
00:08:36,080 --> 00:08:40,155
statistical theorem proposed very

143
00:08:40,352 --> 00:08:44,520
long time ago. And using

144
00:08:44,597 --> 00:08:48,585
that we link a

145
00:08:48,617 --> 00:08:51,615
general form of neural network with a

146
00:08:51,632 --> 00:08:54,720
general form of variational data

147
00:08:54,797 --> 00:08:59,250
impress. But a problem is that this

148
00:08:59,312 --> 00:09:01,815
characterization does not address a

149
00:09:01,832 --> 00:09:05,205
specific generative model which

150
00:09:05,252 --> 00:09:09,915
is crucial to characterize a

151
00:09:09,932 --> 00:09:13,160
specific model, specific neural network

152
00:09:13,205 --> 00:09:18,245
dynamics. So in the following sections,

153
00:09:18,335 --> 00:09:21,615
we characterize the problem

154
00:09:21,707 --> 00:09:24,335
using POMDP or partially observation

155
00:09:24,380 --> 00:09:28,125
position process and link that

156
00:09:28,262 --> 00:09:31,605
model with a particular class force

157
00:09:31,727 --> 00:09:33,925
canonical neural network.

158
00:09:35,625 --> 00:09:40,110
And then we simulated we

159
00:09:40,142 --> 00:09:44,645
use the simulation to propagate

160
00:09:44,810 --> 00:09:48,330
that property in terms of some majid

161
00:09:48,377 --> 00:09:49,150
tasks.

162
00:09:55,000 --> 00:09:58,945
All right, thank you for this. Could we

163
00:09:59,022 --> 00:10:02,225
talk about the complete class theorem?

164
00:10:02,650 --> 00:10:05,290
So what is the scope of the complete

165
00:10:05,382 --> 00:10:09,310
class theorem and why was

166
00:10:09,342 --> 00:10:11,040
it the relevant set of the neural

167
00:10:11,070 --> 00:10:13,240
networks to pursue or the right way to

168
00:10:13,257 --> 00:10:16,570
frame it? Thank you for asking

169
00:10:16,647 --> 00:10:20,520
that. So, I like the slide

170
00:10:20,610 --> 00:10:24,240
you showed last week's

171
00:10:24,345 --> 00:10:27,750
video. So, computer process theory

172
00:10:27,825 --> 00:10:30,565
basically indicates the relationship

173
00:10:30,732 --> 00:10:34,185
between some crossover vision rules

174
00:10:34,230 --> 00:10:36,125
and vision in France.

175
00:10:37,150 --> 00:10:43,095
Here a crucial keyword is admissible

176
00:10:43,260 --> 00:10:47,335
decision rule, which is a rule which

177
00:10:47,367 --> 00:10:52,375
is as

178
00:10:52,437 --> 00:10:56,820
good as other decision rules

179
00:10:56,910 --> 00:11:00,625
or at least at one

180
00:11:00,687 --> 00:11:04,200
point better than other decision

181
00:11:04,275 --> 00:11:06,562
rules. So, simply speaking,

182
00:11:06,925 --> 00:11:10,060
possibility indicates in some sense it

183
00:11:10,092 --> 00:11:14,175
is the best rule for some aspect.

184
00:11:14,325 --> 00:11:17,560
And usually we characterize such a

185
00:11:17,667 --> 00:11:20,665
goodness using cost function,

186
00:11:20,757 --> 00:11:23,290
loss function or risk function.

187
00:11:23,457 --> 00:11:28,237
And here what we did is we

188
00:11:29,275 --> 00:11:32,935
established some association with this

189
00:11:32,967 --> 00:11:35,170
type of loss function or risk function

190
00:11:35,322 --> 00:11:39,855
with canonical

191
00:11:39,915 --> 00:11:42,700
neural network which is we call cost

192
00:11:42,762 --> 00:11:46,555
function or biotic role cost function or

193
00:11:46,677 --> 00:11:50,005
neural network. So our assumption is

194
00:11:50,052 --> 00:11:52,780
that neural network minimize cost

195
00:11:52,827 --> 00:11:55,615
function. So if it active the

196
00:11:55,632 --> 00:12:00,510
minimization and it is virusly

197
00:12:00,705 --> 00:12:04,315
active some sort of optimality so we

198
00:12:04,332 --> 00:12:07,785
can say it is adommissible with respect

199
00:12:07,830 --> 00:12:12,535
to that cost function. So the

200
00:12:12,567 --> 00:12:15,280
beauty of complete process theory is

201
00:12:15,327 --> 00:12:19,135
that if we find some

202
00:12:19,167 --> 00:12:20,890
admissible decision rules then

203
00:12:20,982 --> 00:12:23,065
automatically we can say that it is

204
00:12:23,157 --> 00:12:26,530
based on inference in terms

205
00:12:26,577 --> 00:12:29,185
of some Bayesian cost function with

206
00:12:29,292 --> 00:12:32,740
gentlemen model or prior beliefs. So

207
00:12:32,907 --> 00:12:35,925
this computer chaos theorem is crucial

208
00:12:36,000 --> 00:12:40,210
as abstract characterization of

209
00:12:40,242 --> 00:12:42,810
the relationship between conventional

210
00:12:42,855 --> 00:12:45,225
neural network architecture, dynamics

211
00:12:45,300 --> 00:12:48,350
and variational beijing influence.

212
00:12:51,650 --> 00:12:53,762
All right, thank you.

213
00:12:55,325 --> 00:12:57,110
What does it mean when you said it was

214
00:12:57,142 --> 00:12:59,635
biologically plausible of a loss

215
00:12:59,680 --> 00:13:02,900
function? The term is

216
00:13:02,962 --> 00:13:06,455
a little bit arbitrary because in

217
00:13:06,577 --> 00:13:10,487
this paper we mean by

218
00:13:12,200 --> 00:13:17,540
possibility in

219
00:13:17,557 --> 00:13:21,070
the sense that this neural network

220
00:13:21,160 --> 00:13:24,820
model can be derived from realistic

221
00:13:24,985 --> 00:13:28,050
neural model through some approximation.

222
00:13:28,625 --> 00:13:32,625
And so here barricade probability,

223
00:13:34,025 --> 00:13:39,375
suggest means possibility

224
00:13:39,875 --> 00:13:42,910
as a neural model or synaptic processing

225
00:13:42,955 --> 00:13:46,670
model. And if this cost function

226
00:13:46,747 --> 00:13:49,520
loss function can derive such a

227
00:13:49,672 --> 00:13:53,105
plausible algorithm, then we can say

228
00:13:53,152 --> 00:13:55,300
that this cost function is barely

229
00:13:55,375 --> 00:13:56,175
plausible.

230
00:13:59,525 --> 00:14:01,700
So what is the distinction between those

231
00:14:01,762 --> 00:14:05,045
neural and synaptic components in the

232
00:14:05,047 --> 00:14:07,235
loss function or what equation to look

233
00:14:07,267 --> 00:14:11,110
at? You mean distinction

234
00:14:11,305 --> 00:14:14,035
between thermodynamics and synaptic?

235
00:14:14,155 --> 00:14:15,830
Yeah. What is the distinction between

236
00:14:15,877 --> 00:14:18,065
them and how is it represented in the

237
00:14:18,157 --> 00:14:18,975
equations?

238
00:14:20,525 --> 00:14:24,460
Okay, basically neuropathivity

239
00:14:24,655 --> 00:14:28,045
equation means differentiate

240
00:14:28,135 --> 00:14:31,205
equation about a variable that

241
00:14:31,252 --> 00:14:35,312
representations firing intensity or

242
00:14:36,200 --> 00:14:39,445
some sort of variables associated

243
00:14:39,460 --> 00:14:43,050
with the firing.

244
00:14:43,625 --> 00:14:44,912
On the other hand,

245
00:14:46,325 --> 00:14:50,150
dusty equation means an

246
00:14:50,212 --> 00:14:53,555
update rule about the synaptic weight or

247
00:14:53,602 --> 00:14:57,140
synaptic strengths which is

248
00:14:57,232 --> 00:15:00,450
a connection between two neurons.

249
00:15:01,025 --> 00:15:05,555
And beauty of this

250
00:15:05,602 --> 00:15:09,335
formulation proposed in this paper is

251
00:15:09,367 --> 00:15:12,235
that we characterize both heuristic

252
00:15:12,280 --> 00:15:14,935
questions synaptic procedure equations

253
00:15:15,130 --> 00:15:21,205
in terms of gradient

254
00:15:21,265 --> 00:15:23,987
descent on a same cost function,

255
00:15:24,875 --> 00:15:29,585
common cost function. So we

256
00:15:29,617 --> 00:15:33,662
can say that if we

257
00:15:34,100 --> 00:15:37,660
consider the partial narrative

258
00:15:37,780 --> 00:15:41,285
of some cost function with respect to

259
00:15:41,392 --> 00:15:44,837
new activity, then it's derived by

260
00:15:45,275 --> 00:15:51,260
gradient descent rule about if

261
00:15:51,292 --> 00:15:53,675
we consider a partial derivative of

262
00:15:53,737 --> 00:15:55,760
chaos function errors with respect to

263
00:15:55,792 --> 00:15:58,145
synaptic weights, then we derive a

264
00:15:58,297 --> 00:15:59,625
prosthesis rule.

265
00:16:10,187 --> 00:16:13,622
Are those the only two aspects of

266
00:16:13,655 --> 00:16:16,472
a neural network or why are those the

267
00:16:16,505 --> 00:16:18,312
two key aspects?

268
00:16:20,837 --> 00:16:22,500
Bit is a main,

269
00:16:23,912 --> 00:16:28,622
I think it's the main body

270
00:16:28,730 --> 00:16:32,867
of the neural activity. If we consider

271
00:16:33,065 --> 00:16:36,347
some inference running

272
00:16:36,455 --> 00:16:39,722
or action exhibit by

273
00:16:39,830 --> 00:16:42,757
neural networks in the sense that neural

274
00:16:42,772 --> 00:16:45,517
activity correspond to fast dynamics,

275
00:16:45,577 --> 00:16:49,350
fast gradient dynamics mix and

276
00:16:50,987 --> 00:16:53,357
scientific processing indicate thought

277
00:16:53,435 --> 00:16:56,462
dynamics that minimize least function

278
00:16:56,525 --> 00:17:00,047
and cost function. But in general we can

279
00:17:00,080 --> 00:17:02,572
consider any aspects, any variables

280
00:17:02,617 --> 00:17:04,202
associated. Switch your method for

281
00:17:04,220 --> 00:17:07,577
example, at least what we show in the

282
00:17:07,595 --> 00:17:10,877
paper is any free parameter which may

283
00:17:10,895 --> 00:17:14,612
be associated with firing threshold or

284
00:17:14,750 --> 00:17:17,432
although we don't discuss in this paper

285
00:17:17,585 --> 00:17:20,625
it would be possible to add other

286
00:17:22,262 --> 00:17:24,892
variables related to neural network.

287
00:17:24,952 --> 00:17:28,327
For example, here we ignored

288
00:17:28,507 --> 00:17:32,522
contribution of griad factor but

289
00:17:32,705 --> 00:17:35,152
it would be possible to add the prior

290
00:17:35,182 --> 00:17:37,922
factor in this correlation or any other

291
00:17:38,030 --> 00:17:39,652
aspect of virus corporate neural

292
00:17:39,682 --> 00:17:40,362
network.

293
00:17:44,612 --> 00:17:48,047
That's very interesting and it

294
00:17:48,080 --> 00:17:52,142
speaks also to a general separation of

295
00:17:52,190 --> 00:17:55,892
time scales. For example in different

296
00:17:56,015 --> 00:17:57,602
multi scale systems or in the

297
00:17:57,620 --> 00:18:00,652
renormalization group where it's

298
00:18:00,682 --> 00:18:04,237
describing some minimal

299
00:18:04,387 --> 00:18:07,847
multi time scale system where the

300
00:18:07,880 --> 00:18:10,532
faster time scale can be seen as

301
00:18:10,685 --> 00:18:14,027
perception like a slower time scale can

302
00:18:14,045 --> 00:18:17,192
be seen as more learning like. And then

303
00:18:17,315 --> 00:18:19,522
in some hierarchical model what's

304
00:18:19,567 --> 00:18:21,647
learning of one time scale can be

305
00:18:21,680 --> 00:18:23,972
perceptual for a slower time scale? So

306
00:18:24,005 --> 00:18:27,237
it's a very nice generalization.

307
00:18:32,387 --> 00:18:35,917
Are there any examples of decision

308
00:18:35,977 --> 00:18:38,867
rules that will help us think about the

309
00:18:38,915 --> 00:18:42,002
action components of what the neural

310
00:18:42,020 --> 00:18:45,497
network is doing? Because it may be more

311
00:18:45,530 --> 00:18:48,232
familiar to think about digit

312
00:18:48,322 --> 00:18:50,527
characterization and image

313
00:18:50,557 --> 00:18:52,942
classification, some kind of classical

314
00:18:53,077 --> 00:18:56,372
tasks for neural networks. But how

315
00:18:56,405 --> 00:18:59,552
does the decision rule play out in the

316
00:18:59,570 --> 00:19:01,362
context of neural networks?

317
00:19:04,187 --> 00:19:07,502
Okay, so in this paper

318
00:19:07,595 --> 00:19:11,807
we basically assume a closed loop so

319
00:19:11,885 --> 00:19:14,657
comprising a neural network part and

320
00:19:14,735 --> 00:19:18,277
environmental part. So Neuron receives

321
00:19:18,382 --> 00:19:21,150
sensor input from environment and

322
00:19:23,687 --> 00:19:26,312
provide some feedback to the

323
00:19:26,450 --> 00:19:27,387
environment.

324
00:19:31,787 --> 00:19:37,177
Even with the example of classification

325
00:19:37,357 --> 00:19:40,875
we can say that output correspond to

326
00:19:42,137 --> 00:19:45,647
classification output which is

327
00:19:45,680 --> 00:19:49,062
kind of generative model relevant

328
00:19:49,412 --> 00:19:51,302
example would be for example,

329
00:19:51,395 --> 00:19:55,125
controlling agent like a robot control

330
00:19:55,637 --> 00:19:58,772
or any kind of control errors

331
00:19:58,805 --> 00:20:01,622
decision making tasks. For example,

332
00:20:01,730 --> 00:20:05,447
when we encounter some

333
00:20:05,630 --> 00:20:09,322
choice tasks we need to advertise,

334
00:20:09,517 --> 00:20:12,375
for example, left or right or something.

335
00:20:12,887 --> 00:20:16,362
Any kind of such a decision

336
00:20:16,937 --> 00:20:20,587
can be associated with the possibility

337
00:20:20,662 --> 00:20:22,362
or admissible decision.

338
00:20:27,050 --> 00:20:30,260
So what would an example of an

339
00:20:30,292 --> 00:20:33,655
inadmissible or admissible

340
00:20:33,715 --> 00:20:38,175
strategy be in the decision making task?

341
00:20:40,850 --> 00:20:45,175
Possibility usually characterized

342
00:20:45,250 --> 00:20:48,962
by loss function or risk function.

343
00:20:52,925 --> 00:20:56,455
Here admissivity indicates

344
00:20:56,515 --> 00:20:59,710
that there is another decision rule

345
00:20:59,755 --> 00:21:02,855
which is at least one

346
00:21:03,052 --> 00:21:07,085
point better than the

347
00:21:07,117 --> 00:21:10,500
forecast decision rule.

348
00:21:12,575 --> 00:21:16,285
Simply speaking in Adobe CBD indicates

349
00:21:16,330 --> 00:21:19,430
that decision rules is

350
00:21:19,477 --> 00:21:26,025
not good relatively.

351
00:21:27,050 --> 00:21:29,105
Let's just say our decision rules is we

352
00:21:29,152 --> 00:21:32,315
always turn right. Is that an

353
00:21:32,332 --> 00:21:34,010
example of a decision rule? Because

354
00:21:34,042 --> 00:21:35,510
there might be settings where that is

355
00:21:35,542 --> 00:21:38,925
strictly effective and the simplest rule

356
00:21:39,275 --> 00:21:40,715
whereas there's other settings where

357
00:21:40,732 --> 00:21:43,535
that's going to be tragic. So what does

358
00:21:43,567 --> 00:21:47,180
it mean to be admissible for an agent in

359
00:21:47,227 --> 00:21:49,645
light of different environmental

360
00:21:49,810 --> 00:21:53,390
contexts? That's an interesting

361
00:21:53,557 --> 00:21:58,205
point. So even with such

362
00:21:58,252 --> 00:22:02,470
a too much simplified

363
00:22:02,560 --> 00:22:06,625
rules it can be admissible

364
00:22:06,700 --> 00:22:09,425
under some particular situation,

365
00:22:09,562 --> 00:22:12,887
particular loss function. For example,

366
00:22:13,250 --> 00:22:17,375
the rules that always turn right maybe

367
00:22:17,437 --> 00:22:20,285
the best under some situation,

368
00:22:20,392 --> 00:22:24,905
right? So the

369
00:22:24,952 --> 00:22:27,770
relationship of possibility or enough

370
00:22:27,847 --> 00:22:32,060
possibility depends on both agent

371
00:22:32,167 --> 00:22:34,345
characteristics and environmental

372
00:22:34,435 --> 00:22:35,625
characteristics.

373
00:22:39,350 --> 00:22:42,300
What aspects of the environment.

374
00:22:44,975 --> 00:22:49,130
For example? For example, if that

375
00:22:49,177 --> 00:22:52,600
decision group matches the structure

376
00:22:52,675 --> 00:22:58,505
architecture of environment then maybe

377
00:22:58,702 --> 00:23:02,815
that decision always downright active

378
00:23:02,845 --> 00:23:07,070
the shortest past under some

379
00:23:07,222 --> 00:23:09,225
situation, some environment.

380
00:23:11,675 --> 00:23:15,230
How does this possibility help us think

381
00:23:15,277 --> 00:23:19,025
about like overfitting and how

382
00:23:19,087 --> 00:23:21,320
does it help us think about the way that

383
00:23:21,472 --> 00:23:24,710
different practices are used for

384
00:23:24,742 --> 00:23:26,510
neural networks to prevent them from

385
00:23:26,542 --> 00:23:28,500
being over fit in practice?

386
00:23:30,725 --> 00:23:31,487
Well,

387
00:23:38,075 --> 00:23:41,500
strictly admissivity is characterized

388
00:23:41,575 --> 00:23:44,100
with the Bayesian risk.

389
00:23:50,225 --> 00:23:54,155
We cannot observe a hidden states of

390
00:23:54,352 --> 00:23:58,505
the environment, only we can observe is

391
00:23:58,627 --> 00:24:02,860
a part of the entire universe.

392
00:24:02,905 --> 00:24:06,935
So the question is, an important

393
00:24:07,117 --> 00:24:10,285
question is what is the best choice

394
00:24:10,405 --> 00:24:13,955
under such a limited information?

395
00:24:14,077 --> 00:24:19,250
Limited information?

396
00:24:19,387 --> 00:24:22,637
So this Bayesian list

397
00:24:23,600 --> 00:24:27,000
possibility or computer credit theorem

398
00:24:32,225 --> 00:24:36,980
tell us that well

399
00:24:37,027 --> 00:24:40,800
known. Only the well known

400
00:24:41,525 --> 00:24:45,340
Bayesian framework achieved

401
00:24:45,445 --> 00:24:49,180
the adommissible

402
00:24:49,315 --> 00:24:53,285
decision. Which means that in

403
00:24:53,317 --> 00:24:58,160
this aspects Bayesian optimization give

404
00:24:58,192 --> 00:25:03,335
us a best choice strategy, otherwise we

405
00:25:03,442 --> 00:25:08,975
overfit or find

406
00:25:09,112 --> 00:25:12,900
the suboptima evolution.

407
00:25:13,700 --> 00:25:17,200
So it's a nice association, nice linkage

408
00:25:17,275 --> 00:25:19,655
between the decision bit is a good

409
00:25:19,702 --> 00:25:23,135
decision about the decision and more

410
00:25:23,167 --> 00:25:26,470
established statistical inference.

411
00:25:26,560 --> 00:25:27,662
Freedom work.

412
00:25:31,137 --> 00:25:35,897
Thank you, that's very helpful. So we're

413
00:25:35,942 --> 00:25:39,717
reducing our uncertainty and

414
00:25:39,765 --> 00:25:43,077
risk about hidden states in the

415
00:25:43,095 --> 00:25:46,377
environment. So in the special case

416
00:25:46,470 --> 00:25:48,747
where the entire environment is

417
00:25:48,780 --> 00:25:51,347
observable without errors like a chess

418
00:25:51,392 --> 00:25:55,067
game, then there's

419
00:25:55,202 --> 00:25:58,452
an equivalence between correlation of

420
00:25:58,620 --> 00:26:02,217
risk or loss on observables or

421
00:26:02,265 --> 00:26:04,017
on hidden states. But they're not really

422
00:26:04,065 --> 00:26:06,272
hidden, but they are environmental

423
00:26:06,317 --> 00:26:10,362
states. Whereas any amount

424
00:26:10,425 --> 00:26:13,647
of uncertainty in the

425
00:26:13,680 --> 00:26:17,297
mapping between observation and hidden

426
00:26:17,342 --> 00:26:21,102
states, which is usually shown as a in

427
00:26:21,120 --> 00:26:23,117
the partially observable Markov decision

428
00:26:23,177 --> 00:26:26,787
process, any amount of uncertainty about

429
00:26:26,850 --> 00:26:28,712
unobserved or partially observed

430
00:26:28,787 --> 00:26:32,852
environmental states enables

431
00:26:32,882 --> 00:26:36,632
you to fit your uncertainty optimally

432
00:26:36,722 --> 00:26:40,317
about that hidden state and

433
00:26:40,365 --> 00:26:44,397
fit that uncertainty simply with

434
00:26:44,430 --> 00:26:47,067
the gradient descent. And by doing so,

435
00:26:47,115 --> 00:26:49,797
you don't overfit a model of

436
00:26:49,830 --> 00:26:50,962
observables,

437
00:26:53,562 --> 00:26:57,177
which might be the fallacy or the issue

438
00:26:57,270 --> 00:26:59,962
with simply doing descriptive statistics

439
00:27:00,687 --> 00:27:03,012
you might get an infinitely small

440
00:27:03,150 --> 00:27:07,202
variance with a frequentist estimate

441
00:27:07,382 --> 00:27:10,287
because you have 1000 data points.

442
00:27:10,425 --> 00:27:13,922
So the variance from a descriptive

443
00:27:13,967 --> 00:27:15,717
statistics perspective might be very

444
00:27:15,765 --> 00:27:16,375
small.

445
00:27:21,012 --> 00:27:24,387
I think it speaks very much to why

446
00:27:24,450 --> 00:27:26,612
neural networks are useful in practice

447
00:27:26,687 --> 00:27:29,137
from training with limited data set

448
00:27:29,862 --> 00:27:32,642
because that's an empirical observation

449
00:27:32,702 --> 00:27:35,397
that they don't entirely over bit. But

450
00:27:35,430 --> 00:27:37,292
also I'm sure there's ways to construct

451
00:27:37,352 --> 00:27:40,237
them that are overfit.

452
00:27:41,112 --> 00:27:41,875
Yeah,

453
00:27:43,962 --> 00:27:47,697
overfit will occur if we select

454
00:27:47,805 --> 00:27:51,550
some optimal priorities. For example.

455
00:27:53,712 --> 00:27:57,850
Well, I'm not sure if it

456
00:27:58,812 --> 00:28:02,547
is overfit in the

457
00:28:02,580 --> 00:28:06,597
sense what you mentioned because if

458
00:28:06,630 --> 00:28:09,777
we select some priorities then the

459
00:28:09,795 --> 00:28:12,897
Bayesian function itself changes and the

460
00:28:13,080 --> 00:28:15,942
neural networks that try to fit to that

461
00:28:15,990 --> 00:28:18,357
cost function. So cost function

462
00:28:18,510 --> 00:28:22,587
minimization will be achieved agent

463
00:28:22,650 --> 00:28:26,442
such a situation. But that solution is

464
00:28:26,490 --> 00:28:30,100
not good for our

465
00:28:30,537 --> 00:28:33,752
original help us. That's the tricky

466
00:28:33,782 --> 00:28:37,742
part. Yeah, that is reminiscent

467
00:28:37,802 --> 00:28:40,547
of some discussions we've had discussing

468
00:28:40,592 --> 00:28:44,327
like driving off a cliff or blowing

469
00:28:44,357 --> 00:28:47,217
up is also reducing free energy. Like

470
00:28:47,265 --> 00:28:49,092
dropping up a building reduces your

471
00:28:49,140 --> 00:28:51,882
potential energy. And so there are

472
00:28:51,960 --> 00:28:54,937
potentially decisionmaking or strategic

473
00:28:55,287 --> 00:28:58,992
trajectories that do for some time

474
00:28:59,040 --> 00:29:02,575
horizon minimize free energy,

475
00:29:03,612 --> 00:29:06,562
perhaps even or maybe even guaranteed

476
00:29:06,912 --> 00:29:09,437
better than some longer time horizon.

477
00:29:09,587 --> 00:29:11,922
Because if the shortterm strategies were

478
00:29:11,955 --> 00:29:13,367
somehow better than the longterm

479
00:29:13,427 --> 00:29:16,227
horizon, it would be difficult to

480
00:29:16,245 --> 00:29:18,257
imagine because the long term horizon

481
00:29:18,272 --> 00:29:20,177
would be at least as good as a shortterm

482
00:29:20,207 --> 00:29:23,652
strategy. So that speaks to

483
00:29:23,670 --> 00:29:27,342
the challenges of planning in

484
00:29:27,390 --> 00:29:31,000
action. So how is planning addressed in

485
00:29:31,662 --> 00:29:35,022
modern neural networks and how does this

486
00:29:35,055 --> 00:29:37,000
work help us think about that?

487
00:29:39,837 --> 00:29:43,162
That's another very important aspect.

488
00:29:45,612 --> 00:29:48,992
I have to say that this framework

489
00:29:49,052 --> 00:29:51,497
addresses planning aspect,

490
00:29:51,617 --> 00:29:55,462
but that planning is not necessarily

491
00:29:57,612 --> 00:30:01,577
the optimal

492
00:30:01,607 --> 00:30:04,375
solution in the sense that what we

493
00:30:04,737 --> 00:30:08,412
interested in is optimization or

494
00:30:08,550 --> 00:30:12,187
learning under limited structure.

495
00:30:14,112 --> 00:30:17,575
The structure is characterized by here

496
00:30:18,087 --> 00:30:21,422
Prosperia neural networks.

497
00:30:21,617 --> 00:30:25,652
So yeah, planning occurred

498
00:30:25,757 --> 00:30:30,347
by association between risk

499
00:30:30,392 --> 00:30:34,122
in the future and our decision in the

500
00:30:34,155 --> 00:30:37,975
past. Here we model that aspects using

501
00:30:39,387 --> 00:30:42,542
delayed moderation of scientific

502
00:30:42,602 --> 00:30:45,357
plasticity mediated by some

503
00:30:45,435 --> 00:30:49,162
neuromodulator or neurotransmitters.

504
00:30:50,712 --> 00:30:52,075
This is the model.

505
00:30:58,812 --> 00:31:05,697
This is model as the

506
00:31:05,730 --> 00:31:09,925
risk factor and the heavy product

507
00:31:10,587 --> 00:31:16,052
holding the neural

508
00:31:16,082 --> 00:31:16,837
network.

509
00:31:21,987 --> 00:31:24,237
All right, I'm going to ask a great

510
00:31:24,300 --> 00:31:26,927
question from the chat and then we'll

511
00:31:27,032 --> 00:31:29,342
look at the figures a little closer.

512
00:31:29,477 --> 00:31:33,752
So ML Don wrote a question stock

513
00:31:33,782 --> 00:31:36,222
in my mind for a long time. Could you

514
00:31:36,255 --> 00:31:38,922
please put it to rest? Do we need to

515
00:31:38,955 --> 00:31:42,372
have knowledge about all states possible

516
00:31:42,480 --> 00:31:45,677
actions and sensory inputs for active

517
00:31:45,707 --> 00:31:46,612
inference?

518
00:31:50,812 --> 00:31:51,575
Well,

519
00:31:54,337 --> 00:31:57,667
you mean if you seek the

520
00:31:57,790 --> 00:32:01,407
exact solution, exact optimal solution,

521
00:32:01,497 --> 00:32:05,812
then maybe more information would

522
00:32:05,875 --> 00:32:08,000
help you to find that.

523
00:32:08,887 --> 00:32:17,577
But under some ideal

524
00:32:17,757 --> 00:32:22,252
assumptions then the is

525
00:32:22,270 --> 00:32:27,402
not necessary to achieve the optimal

526
00:32:27,432 --> 00:32:30,787
solution. I'm not sure

527
00:32:30,850 --> 00:32:33,800
if I correctly answer your point.

528
00:32:35,512 --> 00:32:38,300
So just to restate it.

529
00:32:39,037 --> 00:32:40,872
Of course, knowing all the state's

530
00:32:40,917 --> 00:32:43,242
possible actions and sensory inputs,

531
00:32:43,377 --> 00:32:45,637
it's not a bad thing. Worst case,

532
00:32:45,700 --> 00:32:47,952
there's some computational complexity,

533
00:32:48,057 --> 00:32:50,472
trade offs, but the problem becomes

534
00:32:50,517 --> 00:32:53,977
fully stateable. But I

535
00:32:53,995 --> 00:32:57,267
think ML Dawn is asking about cases

536
00:32:57,327 --> 00:33:00,800
where you don't know all of the

537
00:33:01,612 --> 00:33:03,967
state state scale or potentially even

538
00:33:04,015 --> 00:33:08,450
the dimension or the semantics of

539
00:33:10,162 --> 00:33:12,712
hidden states, active states,

540
00:33:12,850 --> 00:33:15,472
sensory inputs and why not even add

541
00:33:15,505 --> 00:33:16,625
cognitive states?

542
00:33:18,412 --> 00:33:21,472
So in not just partially observed but

543
00:33:21,505 --> 00:33:23,987
partially known state state scale,

544
00:33:25,087 --> 00:33:27,777
how are these address in neural

545
00:33:27,807 --> 00:33:30,597
networks? And how does active inference

546
00:33:30,642 --> 00:33:32,225
help us? Think about it.

547
00:33:37,762 --> 00:33:41,437
Okay, I think the question

548
00:33:41,500 --> 00:33:45,417
is about how can we separate

549
00:33:45,552 --> 00:33:48,787
those states like

550
00:33:48,925 --> 00:33:52,862
sensory function, interface material.

551
00:33:57,100 --> 00:34:00,115
How can we separate not just in

552
00:34:00,132 --> 00:34:02,035
principle have these states be

553
00:34:02,067 --> 00:34:05,185
separated, but deal with the fact that

554
00:34:05,217 --> 00:34:08,575
some of these states we might have good

555
00:34:08,637 --> 00:34:11,515
knowledge on and some states like the

556
00:34:11,532 --> 00:34:13,570
hidden states we might not even know,

557
00:34:13,722 --> 00:34:16,060
like we don't know the dimension of the

558
00:34:16,092 --> 00:34:18,880
cause vector in the world.

559
00:34:19,077 --> 00:34:20,062
I see.

560
00:34:22,525 --> 00:34:26,635
In terms of dimension, there is

561
00:34:26,667 --> 00:34:30,435
a statistical technique to estimate

562
00:34:30,630 --> 00:34:33,800
the dimensionality, for example via

563
00:34:34,750 --> 00:34:37,210
information criteria. Like I set

564
00:34:37,242 --> 00:34:39,415
information criteria, based information

565
00:34:39,507 --> 00:34:44,300
criteria, all them try to info estimate

566
00:34:44,725 --> 00:34:47,887
plausible dimension about the

567
00:34:48,250 --> 00:34:51,937
environmental hidden states.

568
00:34:53,650 --> 00:34:56,035
There is an ontology with those

569
00:34:56,142 --> 00:34:58,690
information criteria and vision of free

570
00:34:58,707 --> 00:35:01,990
energy minimization. So with vision of

571
00:35:02,007 --> 00:35:05,625
free energy minimization we can identify

572
00:35:05,700 --> 00:35:10,162
the plausible model structure which

573
00:35:10,600 --> 00:35:13,850
in principle involves the dimension

574
00:35:14,350 --> 00:35:17,710
aspect. But in terms of

575
00:35:17,742 --> 00:35:21,875
Neural network in this paper we don't

576
00:35:22,375 --> 00:35:25,765
carefully consider about the

577
00:35:25,857 --> 00:35:30,280
dimensionality optimization because we

578
00:35:30,402 --> 00:35:34,525
first define the number of neurons and

579
00:35:34,662 --> 00:35:36,937
don't change during the training.

580
00:35:37,600 --> 00:35:41,125
But in principle we can

581
00:35:41,262 --> 00:35:45,010
consider the change in the number of

582
00:35:45,042 --> 00:35:48,370
neurons which is associated with

583
00:35:48,447 --> 00:35:52,635
the neurogenesis adult neurogenesis

584
00:35:52,680 --> 00:35:56,235
or development during the developmental

585
00:35:56,280 --> 00:35:59,512
state. That would be an important

586
00:36:00,475 --> 00:36:06,125
expansion of this direction.

587
00:36:13,450 --> 00:36:17,710
That's very interesting. Here's a

588
00:36:17,742 --> 00:36:21,135
remark. Well, one note

589
00:36:21,180 --> 00:36:25,410
is equation one summarizes

590
00:36:25,605 --> 00:36:27,875
a lot of what you've been describing.

591
00:36:28,300 --> 00:36:31,200
There's a parallelism or a concordance

592
00:36:31,275 --> 00:36:33,910
being drawn between the loss function of

593
00:36:33,942 --> 00:36:36,835
Neural networks and the variational free

594
00:36:36,867 --> 00:36:41,470
energy of the parameterized model there.

595
00:36:41,622 --> 00:36:45,800
So to come back to these processes

596
00:36:46,375 --> 00:36:49,270
that influence learning which we could

597
00:36:49,272 --> 00:36:51,060
think of as the Neural network becoming

598
00:36:51,105 --> 00:36:53,170
more fit from a loss function

599
00:36:53,247 --> 00:36:56,750
perspective or the variational Bayesian

600
00:36:57,400 --> 00:36:59,730
Partially observation Markov decision

601
00:36:59,790 --> 00:37:03,480
process entity generative model encoding

602
00:37:03,540 --> 00:37:06,645
better at doing what it does. So there's

603
00:37:06,735 --> 00:37:09,180
the firing rate on the Neural network

604
00:37:09,240 --> 00:37:12,585
side the synaptic plasticity at a slower

605
00:37:12,630 --> 00:37:14,755
time scale which we discussed a little

606
00:37:14,802 --> 00:37:16,870
earlier. And then now there's a third

607
00:37:17,022 --> 00:37:20,710
time scale with the birth and

608
00:37:20,742 --> 00:37:23,980
death of new cell and maybe even

609
00:37:24,027 --> 00:37:27,745
new layers. And that

610
00:37:27,822 --> 00:37:31,625
kind of multiscale temporal

611
00:37:32,875 --> 00:37:36,045
structuring is not intrinsic

612
00:37:36,135 --> 00:37:40,660
to the Bayes graph to

613
00:37:40,692 --> 00:37:43,015
represent multiple nested timescales in

614
00:37:43,032 --> 00:37:46,035
a Bayesian graph in the act of inference

615
00:37:46,080 --> 00:37:48,115
literature it's more common to make a

616
00:37:48,132 --> 00:37:51,010
hierarchically nested model, right?

617
00:37:51,192 --> 00:37:56,040
And just say that the time handling

618
00:37:56,145 --> 00:37:58,485
on one level is happening more rapidly

619
00:37:58,530 --> 00:38:02,265
with respect to clock time than deeper

620
00:38:02,295 --> 00:38:05,365
nested, slower models. Whereas the

621
00:38:05,382 --> 00:38:10,110
Neural formulation allows

622
00:38:10,155 --> 00:38:13,935
us to deal with multiple ongoing

623
00:38:13,980 --> 00:38:17,725
active states without appealing to

624
00:38:17,787 --> 00:38:21,535
hierarchical nesting which

625
00:38:21,567 --> 00:38:23,750
is a very important feature.

626
00:38:31,450 --> 00:38:35,205
Cell. Both distinctions

627
00:38:35,265 --> 00:38:38,740
will be possible. So without

628
00:38:38,907 --> 00:38:42,262
hierarchical or with

629
00:38:42,925 --> 00:38:46,120
higher car model so even with

630
00:38:46,197 --> 00:38:49,410
hierarchical modeling the optimization

631
00:38:49,530 --> 00:38:53,155
of dimensionality should

632
00:38:53,202 --> 00:38:55,162
be possible. Bit would be possible.

633
00:38:55,525 --> 00:38:59,550
But in other distinctions

634
00:38:59,700 --> 00:39:03,430
we can consider that a population of

635
00:39:03,552 --> 00:39:07,455
Neural models so one has a single layer,

636
00:39:07,590 --> 00:39:10,325
another has two layers,

637
00:39:11,275 --> 00:39:14,815
three layers, four layers. And consider

638
00:39:14,907 --> 00:39:18,750
the possibility of network

639
00:39:18,825 --> 00:39:23,362
architecture associated with

640
00:39:27,625 --> 00:39:30,562
Costa minimization and a particular

641
00:39:31,225 --> 00:39:35,455
environment which is in principle have

642
00:39:35,502 --> 00:39:38,737
the same computational architecture with

643
00:39:39,925 --> 00:39:42,787
the hierarchy model.

644
00:39:46,800 --> 00:39:50,790
Very interesting. Yes, perhaps I

645
00:39:50,957 --> 00:39:54,585
over generalized or speculated because I

646
00:39:54,617 --> 00:39:58,080
thought about how one could have a

647
00:39:58,127 --> 00:40:02,235
100 timestep POMDP that

648
00:40:02,267 --> 00:40:05,090
also performs multiscale behavior

649
00:40:05,270 --> 00:40:08,090
potentially extremely wastefully.

650
00:40:08,270 --> 00:40:10,675
But at least bit could in principle.

651
00:40:11,100 --> 00:40:14,790
And similarly, within a neuron there

652
00:40:14,807 --> 00:40:19,410
could be another Neural network or

653
00:40:19,442 --> 00:40:21,435
some other structure approximated by

654
00:40:21,467 --> 00:40:25,525
that. So they almost both enable

655
00:40:26,925 --> 00:40:30,120
hierarchical and non hierarchical model

656
00:40:30,122 --> 00:40:33,225
modeling as you described, but in very

657
00:40:33,287 --> 00:40:37,095
different ways that

658
00:40:37,247 --> 00:40:40,900
lead to very different implementations.

659
00:40:44,025 --> 00:40:47,835
Yes. I think this brings us to

660
00:40:47,942 --> 00:40:51,350
the topic of forward and reverse

661
00:40:51,425 --> 00:40:54,987
engineering. So you talked a lot about

662
00:40:55,350 --> 00:40:57,025
reverse engineering.

663
00:40:58,650 --> 00:41:01,920
What is reverse engineering and what is

664
00:41:01,997 --> 00:41:06,060
forward engineering and what has been

665
00:41:06,092 --> 00:41:08,500
done in these areas of engineering?

666
00:41:10,350 --> 00:41:11,112
Okay,

667
00:41:13,350 --> 00:41:17,370
I'm not an expert in this

668
00:41:17,447 --> 00:41:21,545
process. But I believe that liver

669
00:41:21,635 --> 00:41:25,560
here means your

670
00:41:25,592 --> 00:41:29,495
characterization of the blueprint

671
00:41:29,660 --> 00:41:33,500
of some device or machine

672
00:41:33,650 --> 00:41:37,530
from data observable information like

673
00:41:37,727 --> 00:41:41,150
activity or action

674
00:41:41,225 --> 00:41:43,212
behavior of some agent.

675
00:41:44,400 --> 00:41:48,400
Goal is identification of blueprint

676
00:41:49,125 --> 00:41:51,755
and the crucially here blueprint

677
00:41:51,815 --> 00:41:54,225
correspond to generative model because

678
00:41:54,287 --> 00:41:56,265
once we define generative model, we can

679
00:41:56,282 --> 00:41:59,585
Deneve evolution energy algorithm,

680
00:41:59,630 --> 00:42:02,190
running inference algorithm and any

681
00:42:02,282 --> 00:42:06,475
behavior of the agent. So here reverse

682
00:42:07,200 --> 00:42:10,620
means that we first observe some

683
00:42:10,697 --> 00:42:15,050
activity of agent and its mechanism

684
00:42:15,125 --> 00:42:19,365
is still unknown for us, but we

685
00:42:19,382 --> 00:42:23,337
can estimate its mechanism using

686
00:42:24,825 --> 00:42:28,815
that activity by identifying the

687
00:42:28,907 --> 00:42:32,840
most plausible guarantee

688
00:42:32,870 --> 00:42:36,005
model which can minimize

689
00:42:36,065 --> 00:42:39,860
some cost function or risk

690
00:42:39,905 --> 00:42:43,335
function when we

691
00:42:43,367 --> 00:42:47,835
feed the data to the

692
00:42:47,867 --> 00:42:50,655
model. So on the other hand for the

693
00:42:50,702 --> 00:42:54,890
engineering would be more mainstream

694
00:42:55,070 --> 00:42:58,715
way fast defined model blueprint gently

695
00:42:58,745 --> 00:43:02,487
model then drive everything

696
00:43:03,000 --> 00:43:06,410
including transfer function,

697
00:43:06,605 --> 00:43:10,000
running algorithms and behavior

698
00:43:10,875 --> 00:43:15,250
action prediction algorithm.

699
00:43:19,875 --> 00:43:23,420
So, by reverse engineering neural

700
00:43:23,435 --> 00:43:26,940
networks, we're observing some

701
00:43:27,032 --> 00:43:30,100
already parameterized neural network

702
00:43:30,450 --> 00:43:34,070
and then fitting a POMDP

703
00:43:34,235 --> 00:43:37,730
to it. To what extent

704
00:43:37,865 --> 00:43:42,987
is it possible to take a given POMDP and

705
00:43:43,350 --> 00:43:47,090
create a neural network that performs

706
00:43:47,120 --> 00:43:48,250
that inference?

707
00:43:52,875 --> 00:43:57,525
Okay, in this paper or

708
00:43:57,662 --> 00:44:01,545
in the following paper, what we

709
00:44:01,697 --> 00:44:05,085
consider is a strategy that we

710
00:44:05,117 --> 00:44:08,925
first feed empirical data whether

711
00:44:08,987 --> 00:44:13,460
force neural response data to scale

712
00:44:13,505 --> 00:44:16,812
prosper neural network model

713
00:44:17,850 --> 00:44:20,775
which is similar to a conventional model

714
00:44:20,837 --> 00:44:23,835
fitting approach where we have

715
00:44:23,942 --> 00:44:27,462
differential equation data and

716
00:44:28,800 --> 00:44:32,235
differential equation to explain

717
00:44:32,417 --> 00:44:37,185
the behavior with

718
00:44:37,217 --> 00:44:42,090
the minimum prediction. So now a

719
00:44:42,257 --> 00:44:46,385
virtue of this framework we established

720
00:44:46,505 --> 00:44:50,120
is that we can naturally

721
00:44:50,210 --> 00:44:52,925
transfer such neural network

722
00:44:53,075 --> 00:44:57,060
architecture with the very

723
00:44:57,092 --> 00:44:59,300
known partial observable Markov action

724
00:44:59,375 --> 00:45:03,075
process architecture because for

725
00:45:03,137 --> 00:45:05,855
any kind of canonical neural network

726
00:45:05,915 --> 00:45:07,962
there is a cost function.

727
00:45:09,900 --> 00:45:12,945
So we Deneve cost function

728
00:45:13,022 --> 00:45:16,410
through narrative vision which is

729
00:45:16,517 --> 00:45:20,250
opposite with

730
00:45:20,387 --> 00:45:23,430
the conventional way we define cost

731
00:45:23,477 --> 00:45:27,525
function derived algorithm and then we

732
00:45:27,662 --> 00:45:32,210
use the formal equivalence

733
00:45:32,255 --> 00:45:34,755
between neural network cost function and

734
00:45:34,802 --> 00:45:38,925
variable queen energy. So now

735
00:45:38,987 --> 00:45:42,462
transform the journal architecture to

736
00:45:43,275 --> 00:45:47,190
Beijing model architecture. And once we

737
00:45:47,357 --> 00:45:50,430
characterize vital energy, there should

738
00:45:50,477 --> 00:45:53,760
be some

739
00:45:53,942 --> 00:45:57,850
general that define

740
00:45:59,250 --> 00:46:01,790
that variational energy functional.

741
00:46:01,970 --> 00:46:05,535
So in

742
00:46:05,567 --> 00:46:09,087
particular, in this example,

743
00:46:09,525 --> 00:46:13,305
canon network nicely correspond to well

744
00:46:13,352 --> 00:46:17,540
known across Macquarlin

745
00:46:17,570 --> 00:46:21,612
process. So, by using this

746
00:46:23,775 --> 00:46:29,160
procedure, we identify a

747
00:46:29,192 --> 00:46:33,200
plausible home DP architecture

748
00:46:33,275 --> 00:46:36,980
which correspond

749
00:46:37,040 --> 00:46:50,100
to observed activity data cell.

750
00:46:50,912 --> 00:46:55,200
Let's stay on this last point.

751
00:46:55,862 --> 00:46:58,927
So after all those transformations,

752
00:46:59,107 --> 00:47:03,422
first the measurements of neurons using

753
00:47:03,455 --> 00:47:06,122
that data to fit the neural network and

754
00:47:06,155 --> 00:47:10,027
then by virtue of the relationships

755
00:47:10,057 --> 00:47:13,322
unpacked in the paper, transforming the

756
00:47:13,355 --> 00:47:16,052
neural network in the left side of

757
00:47:16,070 --> 00:47:20,267
figure one into a particular

758
00:47:20,390 --> 00:47:24,000
form of the P-O-M DP. So first,

759
00:47:24,362 --> 00:47:27,152
what are the constraints on that form of

760
00:47:27,170 --> 00:47:30,272
the P-O-M DP? Is this a little corner of

761
00:47:30,305 --> 00:47:33,767
model space or what are the space of

762
00:47:33,890 --> 00:47:35,862
acceptable P-O-M DPS?

763
00:47:38,012 --> 00:47:40,922
That totally depends on what kind of

764
00:47:40,955 --> 00:47:42,887
neural network model you are

765
00:47:42,950 --> 00:47:46,350
considering. So for example,

766
00:47:47,387 --> 00:47:50,447
in this paper we discussed about a

767
00:47:50,480 --> 00:47:54,975
particular crossover from DP in which

768
00:47:55,487 --> 00:47:59,597
each state takes either zero or one.

769
00:47:59,780 --> 00:48:03,322
So it's very restricted compared

770
00:48:03,367 --> 00:48:06,862
to the general form of POMDP

771
00:48:06,937 --> 00:48:10,747
but we consider a factorization

772
00:48:10,867 --> 00:48:14,550
so in the sense that although each

773
00:48:16,412 --> 00:48:19,837
but we consider a vector of observation,

774
00:48:19,912 --> 00:48:23,732
a vector of hidden states where each

775
00:48:23,885 --> 00:48:28,500
element correspond to one

776
00:48:29,537 --> 00:48:33,182
single one hot vector but as an entire

777
00:48:33,260 --> 00:48:37,812
state it can represent

778
00:48:38,237 --> 00:48:42,000
high dimension discrete state space.

779
00:48:43,112 --> 00:48:46,912
And this architecture nicely correspond

780
00:48:46,987 --> 00:48:50,497
to neural network architecture

781
00:48:50,617 --> 00:48:54,225
because usually each neuron takes

782
00:48:54,812 --> 00:48:58,292
either zero, one or some

783
00:48:58,340 --> 00:49:02,612
value continuous variable between zero

784
00:49:02,750 --> 00:49:06,722
and one. So we use

785
00:49:06,755 --> 00:49:09,602
this association to characterize a

786
00:49:09,620 --> 00:49:12,722
particular POMDP which correspond to

787
00:49:12,830 --> 00:49:17,862
neural networks and this follows

788
00:49:19,412 --> 00:49:23,302
a particular mind field approximation.

789
00:49:23,407 --> 00:49:26,057
Approximation or approximation in

790
00:49:26,210 --> 00:49:29,642
generative model because we

791
00:49:29,840 --> 00:49:34,487
associate posterior belief in

792
00:49:34,550 --> 00:49:38,452
this particular homo DP with the neural

793
00:49:38,482 --> 00:49:43,342
activity which means that posterior

794
00:49:43,402 --> 00:49:48,087
of action also has a factorization

795
00:49:48,662 --> 00:49:54,347
architecture in the sense that we

796
00:49:54,380 --> 00:49:57,752
don't fully consider about the

797
00:49:57,770 --> 00:50:01,102
second order statistics between neurons

798
00:50:01,132 --> 00:50:03,917
activity and activity which is outside

799
00:50:04,040 --> 00:50:06,612
of this poem RASM.

800
00:50:07,337 --> 00:50:11,717
So each

801
00:50:11,765 --> 00:50:17,512
neuron activity correspond to posterior

802
00:50:17,587 --> 00:50:22,887
expectation about a particular element

803
00:50:24,662 --> 00:50:28,950
of the state and we don't consider the

804
00:50:32,762 --> 00:50:36,600
joint posterior property of all state.

805
00:50:40,700 --> 00:50:45,305
So although this is a minimization we

806
00:50:45,352 --> 00:50:49,885
see this Asia

807
00:50:49,930 --> 00:50:54,020
impress but otherwise for

808
00:50:54,022 --> 00:50:58,645
example we can consider any recurrent

809
00:50:58,735 --> 00:51:01,460
network architecture which correspond to

810
00:51:01,492 --> 00:51:06,065
state to transition metrics and it

811
00:51:06,082 --> 00:51:08,510
would be possible to extend this

812
00:51:08,542 --> 00:51:12,140
architecture to higher cell structure in

813
00:51:12,157 --> 00:51:16,045
the sense that it is straightforward

814
00:51:16,135 --> 00:51:19,460
consider a tree structure or any kind of

815
00:51:19,567 --> 00:51:22,520
higher car structure by assumptions that

816
00:51:22,672 --> 00:51:26,105
some neurons connect to other neuron but

817
00:51:26,152 --> 00:51:29,830
not connect to other neurons.

818
00:51:29,890 --> 00:51:33,065
So this is Lamme as considering the

819
00:51:33,082 --> 00:51:36,812
higher car structure in general.

820
00:51:43,675 --> 00:51:46,837
That's very interesting.

821
00:51:48,175 --> 00:51:51,412
It's commonly remarked in

822
00:51:52,300 --> 00:51:55,465
the base graphs that

823
00:51:55,632 --> 00:51:58,305
they represent the connections amongst

824
00:51:58,365 --> 00:52:00,820
random variables and there's a

825
00:52:00,822 --> 00:52:02,110
relationships between their

826
00:52:02,142 --> 00:52:05,290
computability and their sparsity. The

827
00:52:05,307 --> 00:52:08,085
sparsity structure as in which variables

828
00:52:08,130 --> 00:52:12,130
do or do not influence each other makes

829
00:52:12,177 --> 00:52:15,187
the problem tractable through

830
00:52:15,625 --> 00:52:17,785
factorization and just kind of

831
00:52:17,817 --> 00:52:19,990
conceptually like if every one of a

832
00:52:20,007 --> 00:52:22,060
thousand variables or an unknown number

833
00:52:22,092 --> 00:52:24,610
of large variables if it was all by all

834
00:52:24,792 --> 00:52:27,505
the number of parameters to fit on that

835
00:52:27,552 --> 00:52:29,635
connectivity matrix would be very high.

836
00:52:29,742 --> 00:52:32,200
So statistical power would be very low

837
00:52:32,337 --> 00:52:35,440
for any given edge whereas the more and

838
00:52:35,457 --> 00:52:37,735
more constrained you make the

839
00:52:37,767 --> 00:52:40,480
connectivity of the variables the more

840
00:52:40,527 --> 00:52:44,140
statistical power you have to resolve or

841
00:52:44,157 --> 00:52:46,920
kind of spend on fitting those edges

842
00:52:47,010 --> 00:52:50,530
like in a structural equation but you

843
00:52:50,577 --> 00:52:53,910
might be losing sight of the unknown

844
00:52:53,955 --> 00:52:56,410
unknowns by constraining yourself to a

845
00:52:56,442 --> 00:53:00,735
very limited or fallacious teleology

846
00:53:00,855 --> 00:53:03,115
of the variables. So there's this kind

847
00:53:03,132 --> 00:53:06,075
of structure learning statistical

848
00:53:06,150 --> 00:53:08,900
inference question in the Bayes graphs

849
00:53:09,850 --> 00:53:13,240
then on the neural side from the

850
00:53:13,257 --> 00:53:16,735
biological much

851
00:53:16,767 --> 00:53:19,080
of neuroscience is about understanding

852
00:53:19,140 --> 00:53:21,685
how the firing rate,

853
00:53:21,867 --> 00:53:25,100
connectivity patterns and other factors

854
00:53:25,450 --> 00:53:27,810
Hohwy the structure of those neural

855
00:53:27,855 --> 00:53:30,715
systems and their function like form and

856
00:53:30,732 --> 00:53:34,755
function enable adequate

857
00:53:34,815 --> 00:53:38,300
inference and inference on action.

858
00:53:38,875 --> 00:53:42,585
So it's like in both of those area

859
00:53:42,705 --> 00:53:44,715
or really like in neural network

860
00:53:44,820 --> 00:53:48,805
artificial and neural networks and

861
00:53:48,852 --> 00:53:52,165
in variational DAGs the discussion is

862
00:53:52,182 --> 00:53:55,705
about how the structure and the fine

863
00:53:55,752 --> 00:53:59,635
tuning work together to

864
00:53:59,667 --> 00:54:02,605
generate function and about some of the

865
00:54:02,652 --> 00:54:06,195
statistical or biological challenges

866
00:54:06,285 --> 00:54:10,225
of balancing different needs while

867
00:54:10,287 --> 00:54:13,930
also constraining the cost in terms of

868
00:54:13,977 --> 00:54:17,150
materials and biometabolism.

869
00:54:17,650 --> 00:54:21,650
So it's a very rich interoception

870
00:54:23,350 --> 00:54:25,537
that is being explored here.

871
00:54:29,462 --> 00:54:31,577
If these models can really be moving

872
00:54:31,670 --> 00:54:32,787
back and forth.

873
00:54:38,137 --> 00:54:42,587
In the sense that back and forth.

874
00:54:45,487 --> 00:54:48,907
Moving back and forth like there's some

875
00:54:49,060 --> 00:54:52,087
imprints of the model that is

876
00:54:52,150 --> 00:54:54,472
implementation independent or like some

877
00:54:54,505 --> 00:54:58,387
interlingua or some semantics or

878
00:54:58,450 --> 00:55:00,082
compatibility, I don't reality know. I

879
00:55:00,085 --> 00:55:01,822
mean that's something we can explore is

880
00:55:01,855 --> 00:55:04,822
like what is it that is such that one

881
00:55:04,855 --> 00:55:08,082
could forward engineer and then reverse

882
00:55:08,097 --> 00:55:11,302
engineer and have like kind of an

883
00:55:11,320 --> 00:55:14,872
expectation maximization between these

884
00:55:14,905 --> 00:55:17,300
two areas. So what is it that's being

885
00:55:18,562 --> 00:55:19,412
solved?

886
00:55:25,087 --> 00:55:29,047
Yes important

887
00:55:29,155 --> 00:55:34,987
point, for example about

888
00:55:35,050 --> 00:55:38,347
you is

889
00:55:38,380 --> 00:55:40,912
that we can use the knowledge of

890
00:55:41,050 --> 00:55:43,372
Bayesian inference to explain your

891
00:55:43,405 --> 00:55:46,037
activity thermodynamics,

892
00:55:46,387 --> 00:55:49,612
which is crucial because people often

893
00:55:49,675 --> 00:55:54,447
say that characterizing

894
00:55:54,492 --> 00:55:57,587
neurodynamics is no straightforward,

895
00:56:00,112 --> 00:56:03,637
we may obtain some solution on your set

896
00:56:03,700 --> 00:56:06,892
dynamics, but the meaning of that

897
00:56:07,015 --> 00:56:09,567
dynamics in terms of the functional

898
00:56:09,627 --> 00:56:12,187
aspect is very unclear. We don't know

899
00:56:12,250 --> 00:56:16,002
the meaning of connectivity strength

900
00:56:16,182 --> 00:56:19,447
matrices and what is the learning of the

901
00:56:19,480 --> 00:56:22,267
threshold factor, so on and so on those

902
00:56:22,315 --> 00:56:25,925
area drives from

903
00:56:27,637 --> 00:56:31,017
the model physiological phenomena,

904
00:56:31,077 --> 00:56:34,775
but it is not necessary to have

905
00:56:35,212 --> 00:56:39,702
clear linkage to functional exploration.

906
00:56:39,882 --> 00:56:43,452
So explanation of function of the brain,

907
00:56:43,557 --> 00:56:47,527
but once we transfer translate this

908
00:56:47,620 --> 00:56:50,677
dynamics into Bayesian inference, then

909
00:56:50,770 --> 00:56:54,207
we can explain every functional aspect

910
00:56:54,297 --> 00:56:56,802
of the neural network diagrams

911
00:56:56,832 --> 00:56:59,212
architecture in terms of where

912
00:56:59,275 --> 00:57:01,627
established Bayesian inference under a

913
00:57:01,645 --> 00:57:04,372
particular crossover Bayesian model, in

914
00:57:04,405 --> 00:57:06,425
this case palm DP model.

915
00:57:08,287 --> 00:57:12,217
So now bit turns out that

916
00:57:12,415 --> 00:57:15,072
synaptic strength correspond to a matrix

917
00:57:15,117 --> 00:57:18,287
B matrix, which are very established

918
00:57:19,687 --> 00:57:23,407
culture meaning. So yeah,

919
00:57:23,560 --> 00:57:30,812
this is useful to explain neuronsynatic

920
00:57:31,387 --> 00:57:34,687
property in terms

921
00:57:34,750 --> 00:57:37,937
of established statistics.

922
00:57:44,287 --> 00:57:47,347
Also, for the people in

923
00:57:47,380 --> 00:57:51,172
the active inference site, it would be

924
00:57:51,205 --> 00:57:54,447
helpful to understand the neuronounce

925
00:57:54,492 --> 00:57:57,950
master straight about particular

926
00:57:59,362 --> 00:58:01,775
active internal model model.

927
00:58:03,712 --> 00:58:07,567
So I think it related to forward

928
00:58:07,690 --> 00:58:11,452
modeling but finally to discuss

929
00:58:11,545 --> 00:58:15,682
with discuss about the order service

930
00:58:15,760 --> 00:58:19,522
state of that forward model, we need to

931
00:58:19,555 --> 00:58:25,262
address the neural network architecture

932
00:58:26,662 --> 00:58:30,022
service property. So in

933
00:58:30,055 --> 00:58:33,292
that case we

934
00:58:33,340 --> 00:58:36,462
can transform a particular force DP

935
00:58:36,537 --> 00:58:39,987
invasion model to a neural network

936
00:58:40,062 --> 00:58:43,492
architecture using this relationship and

937
00:58:43,540 --> 00:58:48,397
then get prediction about the

938
00:58:48,505 --> 00:58:51,997
substrate. So, if we have this based on

939
00:58:52,030 --> 00:58:55,137
model, this particular quantity

940
00:58:55,212 --> 00:59:05,632
in this model should be bit

941
00:59:05,635 --> 00:59:07,175
would be possible using.

942
00:59:14,737 --> 00:59:16,227
Oh, it's all good. Can you just repeat

943
00:59:16,257 --> 00:59:19,402
the last 20 seconds? Yes.

944
00:59:19,570 --> 00:59:22,957
So in the last part I

945
00:59:23,035 --> 00:59:26,467
mentioned about first

946
00:59:26,515 --> 00:59:29,137
we define the Bayesian model and then

947
00:59:29,200 --> 00:59:32,652
can predict what is the neural

948
00:59:32,682 --> 00:59:36,727
net states that correspond to that

949
00:59:36,820 --> 00:59:38,825
particular Beijing model.

950
00:59:39,337 --> 00:59:43,787
So this will be useful to identify

951
00:59:44,437 --> 00:59:48,812
the biological quantities

952
00:59:49,537 --> 00:59:53,412
that correspond to a quantum in Beijing

953
00:59:53,487 --> 00:59:54,125
chaos.

954
01:00:03,562 --> 01:00:07,372
There'S a lot there. It makes

955
01:00:07,405 --> 01:00:10,927
me think about the inference. Of

956
01:00:11,020 --> 01:00:14,497
representation and heuristics in the

957
01:00:14,530 --> 01:00:17,917
computational setting, which is often

958
01:00:18,040 --> 01:00:21,202
in the extreme disembodied, and the

959
01:00:21,220 --> 01:00:23,797
biological setting, which is in the

960
01:00:23,830 --> 01:00:26,997
extreme entirely embodied.

961
01:00:27,192 --> 01:00:30,237
And for a given generative

962
01:00:30,312 --> 01:00:33,667
model, the kinds of

963
01:00:33,790 --> 01:00:35,902
computational heuristics that can be

964
01:00:35,920 --> 01:00:40,362
applied include a whole host

965
01:00:40,437 --> 01:00:43,312
of different strategies ranging from

966
01:00:43,375 --> 01:00:46,522
sampling to tree exploration and

967
01:00:46,555 --> 01:00:50,697
branching to paralyzing

968
01:00:50,892 --> 01:00:54,547
the data architecture and all these

969
01:00:54,580 --> 01:00:59,917
other kinds of disparate strategies and

970
01:00:59,965 --> 01:01:02,237
software packages and representations.

971
01:01:04,387 --> 01:01:06,500
But on the biological side,

972
01:01:07,312 --> 01:01:11,137
what is needed is something

973
01:01:11,200 --> 01:01:14,452
that's very simple but also

974
01:01:14,545 --> 01:01:18,112
very inscrutable, which is

975
01:01:18,175 --> 01:01:23,257
a given pattern of interactions must

976
01:01:23,335 --> 01:01:26,387
embody that calculation.

977
01:01:28,387 --> 01:01:32,272
So that might mean that it

978
01:01:32,305 --> 01:01:34,977
can add three digit numbers but it can't

979
01:01:35,007 --> 01:01:38,092
add two digit numbers under some

980
01:01:38,140 --> 01:01:41,647
constraints. But what

981
01:01:41,680 --> 01:01:43,477
isn't accessible to that kind of

982
01:01:43,495 --> 01:01:46,192
morphological, biological or like form

983
01:01:46,240 --> 01:01:48,547
and functional computing? What's not

984
01:01:48,580 --> 01:01:51,962
accessible are the tree branching,

985
01:01:52,687 --> 01:01:54,812
the database decentralization,

986
01:01:56,062 --> 01:01:58,400
like they're a different set of

987
01:01:59,137 --> 01:02:02,317
heuristics. Right. But they're both very

988
01:02:02,365 --> 01:02:06,397
useful when we're thinking about making

989
01:02:06,505 --> 01:02:10,377
sentience artifacts or benefiting

990
01:02:10,482 --> 01:02:13,672
simply from the explainability across

991
01:02:13,780 --> 01:02:16,550
both sides of this figure.

992
01:02:18,562 --> 01:02:21,950
Yeah. So you now address an important

993
01:02:22,312 --> 01:02:26,092
point. So Homistry, it is very

994
01:02:26,140 --> 01:02:29,075
nontrivial whether there is a

995
01:02:29,587 --> 01:02:31,992
corresponding valve car architecture

996
01:02:32,052 --> 01:02:36,252
force any given Bayesian architecture.

997
01:02:36,357 --> 01:02:39,802
I believe it is impossible to design

998
01:02:39,895 --> 01:02:43,102
biography architecture to respond to

999
01:02:43,120 --> 01:02:47,092
arbitrary Bayesian architecture. So only

1000
01:02:47,140 --> 01:02:51,487
a limited aspect of recognition model

1001
01:02:51,550 --> 01:02:54,237
can be implemented in a vertical

1002
01:02:54,312 --> 01:02:57,712
plausible manner. And that point

1003
01:02:57,850 --> 01:03:01,582
is crucial as capitalization of

1004
01:03:01,660 --> 01:03:05,237
biological network. Biological brain.

1005
01:03:09,412 --> 01:03:13,027
Yeah. Wow. Well, just to kind of

1006
01:03:13,195 --> 01:03:15,027
touch again on this forward in reverse

1007
01:03:15,057 --> 01:03:16,112
engineering.

1008
01:03:18,412 --> 01:03:20,987
For. A given POMDP,

1009
01:03:21,637 --> 01:03:24,727
if we're willing to compose it within a

1010
01:03:24,745 --> 01:03:27,607
certain class, which might be quite

1011
01:03:27,685 --> 01:03:31,412
general still, but some class of POMDP

1012
01:03:31,837 --> 01:03:33,725
as written on the paper,

1013
01:03:34,912 --> 01:03:38,307
we may be able to have a neural

1014
01:03:38,322 --> 01:03:41,362
network architecture that would be very

1015
01:03:41,425 --> 01:03:44,450
amenable to deep learning,

1016
01:03:44,887 --> 01:03:46,857
low energy computing,

1017
01:03:47,022 --> 01:03:50,517
pretraining, various features.

1018
01:03:50,652 --> 01:03:54,725
And then on the other side, for a given

1019
01:03:55,237 --> 01:03:57,697
artificial neural network that we come

1020
01:03:57,730 --> 01:04:01,325
across in the wild or

1021
01:04:01,762 --> 01:04:05,242
a model of neural dynamics that we

1022
01:04:05,290 --> 01:04:08,000
fit using a neural network model.

1023
01:04:08,737 --> 01:04:10,497
So something in a neuroscience

1024
01:04:10,542 --> 01:04:13,775
laboratory that model

1025
01:04:14,437 --> 01:04:17,502
can have interpretability corresponding

1026
01:04:17,532 --> 01:04:22,337
to the variables of a given POMDP.

1027
01:04:22,762 --> 01:04:24,907
And just to kind of give one more point

1028
01:04:24,985 --> 01:04:28,072
on how that's going deeper than, for

1029
01:04:28,105 --> 01:04:31,137
example, statistical parameter mapping

1030
01:04:31,212 --> 01:04:34,462
SPM. So let's just

1031
01:04:34,525 --> 01:04:36,102
assume that the neural network we're

1032
01:04:36,132 --> 01:04:39,802
dealing with is fit from brain data

1033
01:04:39,970 --> 01:04:43,897
from some lucky ant right?

1034
01:04:43,930 --> 01:04:47,202
Now, what would be possible or prior

1035
01:04:47,232 --> 01:04:49,147
to this line of work or without this

1036
01:04:49,180 --> 01:04:53,242
line of work, one could fit

1037
01:04:53,365 --> 01:04:56,752
a neural dynamics model and then do all

1038
01:04:56,770 --> 01:04:59,187
kinds of analyses, like power analyses

1039
01:04:59,262 --> 01:05:02,122
on the different frequency spectra and

1040
01:05:02,155 --> 01:05:05,017
say, look at the average firing rate or

1041
01:05:05,065 --> 01:05:07,752
the correlation coefficients of firing

1042
01:05:07,782 --> 01:05:10,027
rate. So fit the firing rates and the

1043
01:05:10,045 --> 01:05:13,417
synaptic Plasticities and store all that

1044
01:05:13,465 --> 01:05:17,227
data. And then we could just pick a

1045
01:05:17,245 --> 01:05:19,262
POMDP that we've seen in the literature

1046
01:05:19,762 --> 01:05:21,327
without any reference to the neural

1047
01:05:21,357 --> 01:05:24,877
network and optimize the POMDP. And then

1048
01:05:24,895 --> 01:05:26,677
we could say well, it turns out that

1049
01:05:26,695 --> 01:05:30,472
when the POMDP o is high

1050
01:05:30,655 --> 01:05:33,787
there's increased theta power in this

1051
01:05:33,850 --> 01:05:36,837
firing pattern. So it's like comparing

1052
01:05:36,912 --> 01:05:39,652
the descriptive statistics from the

1053
01:05:39,670 --> 01:05:42,897
neural model to the descriptive summary

1054
01:05:42,942 --> 01:05:46,387
statistics of the POMDP decision making

1055
01:05:46,450 --> 01:05:50,217
model. However, with this formal

1056
01:05:50,277 --> 01:05:53,077
connection there is actually an

1057
01:05:53,095 --> 01:05:57,342
interpretability to the unobserved

1058
01:05:57,402 --> 01:05:59,572
neural states which are what area being

1059
01:05:59,605 --> 01:06:02,037
inferred from the fMRI measurement,

1060
01:06:02,112 --> 01:06:04,492
from the EEG measurement and so on.

1061
01:06:04,690 --> 01:06:08,092
Those underlying variables have

1062
01:06:08,140 --> 01:06:11,242
a specific interpretability in

1063
01:06:11,290 --> 01:06:13,477
relationship to the structure of the

1064
01:06:13,495 --> 01:06:14,687
P-O-M DP.

1065
01:06:21,337 --> 01:06:24,952
Right? So yeah, that's also

1066
01:06:25,120 --> 01:06:28,937
very interesting important aspect.

1067
01:06:29,587 --> 01:06:33,352
So what you

1068
01:06:33,370 --> 01:06:36,922
said is I think more

1069
01:06:36,955 --> 01:06:41,152
conventional strategy and it

1070
01:06:41,170 --> 01:06:44,557
is also formally related to model

1071
01:06:44,635 --> 01:06:48,412
comparison aspect. So we usually think

1072
01:06:48,475 --> 01:06:51,772
various modeling and identify or

1073
01:06:51,805 --> 01:06:55,762
select what is the best model

1074
01:06:55,825 --> 01:06:58,100
to explain a given data.

1075
01:06:58,612 --> 01:07:02,362
And this reverse engineering idea

1076
01:07:02,500 --> 01:07:05,637
involves such a model comparison

1077
01:07:05,787 --> 01:07:09,622
aspect in the sense that we try to

1078
01:07:09,655 --> 01:07:12,187
find the model with the best

1079
01:07:12,250 --> 01:07:16,117
expandability which should we have

1080
01:07:16,165 --> 01:07:19,700
the identical functionality, right

1081
01:07:21,637 --> 01:07:25,175
directory address the exact same

1082
01:07:26,362 --> 01:07:28,867
cost function architecture using the

1083
01:07:28,915 --> 01:07:31,262
information natural transformation.

1084
01:07:31,687 --> 01:07:36,667
So it should be up to explain

1085
01:07:36,790 --> 01:07:40,025
the neural data in the Bayesian sense.

1086
01:07:42,412 --> 01:07:46,567
Yeah, one can imagine how

1087
01:07:46,615 --> 01:07:50,900
that would transform the way that

1088
01:07:51,862 --> 01:07:54,472
current neuroimaging studies and

1089
01:07:54,505 --> 01:07:58,222
technologies describe what

1090
01:07:58,255 --> 01:08:00,367
it is about the measurement that

1091
01:08:00,415 --> 01:08:03,697
provides information about the

1092
01:08:03,730 --> 01:08:06,067
recognition model. So,

1093
01:08:06,265 --> 01:08:09,477
to give another related example, let's

1094
01:08:09,507 --> 01:08:12,672
just say a person was wearing an EEG

1095
01:08:12,867 --> 01:08:16,462
headset and a previous study

1096
01:08:16,525 --> 01:08:20,967
had shown that increased alphaband

1097
01:08:21,027 --> 01:08:23,152
activity was associated with this

1098
01:08:23,245 --> 01:08:26,892
behavior. That's comparing

1099
01:08:26,952 --> 01:08:29,587
a descriptive statistic of the

1100
01:08:29,650 --> 01:08:34,402
observations of the sensor and

1101
01:08:34,495 --> 01:08:37,712
correlating the summarized observable

1102
01:08:38,062 --> 01:08:41,997
to some other variable

1103
01:08:42,192 --> 01:08:44,677
like anxiety or performance on a

1104
01:08:44,695 --> 01:08:48,887
behavior. In contrast,

1105
01:08:50,212 --> 01:08:53,932
an unobserved variable in this

1106
01:08:54,010 --> 01:08:57,737
settling range actual underlying

1107
01:08:58,312 --> 01:09:01,562
neural state is being correlated

1108
01:09:02,962 --> 01:09:07,812
to some semantic generative

1109
01:09:07,887 --> 01:09:09,887
model component.

1110
01:09:11,437 --> 01:09:15,575
So it's no longer necessarily that any

1111
01:09:17,437 --> 01:09:20,077
single frequency band would be

1112
01:09:20,095 --> 01:09:23,257
associated more or less with a given

1113
01:09:23,335 --> 01:09:27,567
outcome, but it's actually some hidden

1114
01:09:27,627 --> 01:09:31,937
state stability

1115
01:09:33,562 --> 01:09:36,772
which gains the interpretability across

1116
01:09:36,880 --> 01:09:40,262
this transformation. Which is a subtle

1117
01:09:40,912 --> 01:09:44,612
point, but it speaks to how broadly

1118
01:09:45,487 --> 01:09:48,962
the equivalents would reinterpret

1119
01:09:49,837 --> 01:09:54,247
empirical neuroimaging results as

1120
01:09:54,280 --> 01:09:57,777
well as a variety of artificial neural

1121
01:09:57,807 --> 01:10:01,187
network experiments and diagnostics

1122
01:10:01,912 --> 01:10:04,717
where people do lesion studies and

1123
01:10:04,840 --> 01:10:07,677
double knockouts on artificial neural

1124
01:10:07,707 --> 01:10:08,687
networks.

1125
01:10:11,062 --> 01:10:14,422
So anywhere where

1126
01:10:14,530 --> 01:10:17,572
somebody with awareness sees that a

1127
01:10:17,605 --> 01:10:20,537
neural network, artificial or biological

1128
01:10:21,037 --> 01:10:24,442
is having summary features described and

1129
01:10:24,490 --> 01:10:26,317
correlated to something that's more

1130
01:10:26,365 --> 01:10:30,137
semantic in a quest for meaning

1131
01:10:30,862 --> 01:10:35,317
may now have a different approach that

1132
01:10:35,365 --> 01:10:38,525
involves formalizing the model

1133
01:10:39,037 --> 01:10:43,412
explicitly in terms of unobserved hidden

1134
01:10:43,762 --> 01:10:48,492
states with a cost function akin

1135
01:10:48,552 --> 01:10:50,892
to a variational free energy minimizing

1136
01:10:50,952 --> 01:10:53,677
risk bounding surprise on the

1137
01:10:53,695 --> 01:10:57,127
unobservables. So even though

1138
01:10:57,145 --> 01:11:01,072
the unobservables were modeled in

1139
01:11:01,105 --> 01:11:05,592
a sense in the other conventional

1140
01:11:05,652 --> 01:11:09,352
strategy like neural activity is a

1141
01:11:09,370 --> 01:11:12,882
variable in fMRI

1142
01:11:12,972 --> 01:11:15,642
experiments, it's underlying the bold

1143
01:11:15,777 --> 01:11:19,332
signal yet this formalism

1144
01:11:19,422 --> 01:11:24,282
concordance is a more coherent

1145
01:11:24,372 --> 01:11:27,512
and powerful connection.

1146
01:11:35,362 --> 01:11:39,682
Lib sold. So you now address

1147
01:11:39,760 --> 01:11:42,787
this very important point.

1148
01:11:42,850 --> 01:11:46,507
So first to address

1149
01:11:46,585 --> 01:11:50,647
that so we need to clarify about

1150
01:11:50,830 --> 01:11:54,292
what is a program consider

1151
01:11:54,490 --> 01:11:58,212
here. So this is a program scale

1152
01:11:58,287 --> 01:12:01,927
metabasian problem in the sense that

1153
01:12:02,095 --> 01:12:05,262
researchers try to infer

1154
01:12:05,337 --> 01:12:08,797
or estimate neuro activity or

1155
01:12:08,830 --> 01:12:12,117
brain activity which infer

1156
01:12:12,177 --> 01:12:15,042
the external world dynamics.

1157
01:12:15,177 --> 01:12:18,972
Right. So neuron or brain environment

1158
01:12:19,092 --> 01:12:22,992
and we research brain activity.

1159
01:12:23,127 --> 01:12:28,812
So there area two step process

1160
01:12:28,962 --> 01:12:33,187
noise. This sort of meta Bay is

1161
01:12:33,250 --> 01:12:38,525
quite tricky intractable because

1162
01:12:38,887 --> 01:12:44,322
sometimes London

1163
01:12:44,367 --> 01:12:48,892
variable becomes posterior about

1164
01:12:49,090 --> 01:12:53,437
other aspects. So I think

1165
01:12:53,575 --> 01:12:56,512
there is some established approach about

1166
01:12:56,575 --> 01:13:00,427
metabolism. But this

1167
01:13:00,520 --> 01:13:03,772
paper provides some alternative in the

1168
01:13:03,805 --> 01:13:07,412
sense that we separate two program

1169
01:13:08,737 --> 01:13:12,907
by saying that here what we

1170
01:13:12,985 --> 01:13:17,907
import is simply neural

1171
01:13:17,922 --> 01:13:21,275
network dynamics which is shown in the

1172
01:13:21,712 --> 01:13:24,967
left hand side of this figure.

1173
01:13:25,165 --> 01:13:28,887
So we feed data to conventional

1174
01:13:28,962 --> 01:13:32,707
neural network model which is a simple

1175
01:13:32,785 --> 01:13:36,517
differential creation. But thanks to

1176
01:13:36,640 --> 01:13:39,627
this formal recovery between neural

1177
01:13:39,657 --> 01:13:43,262
network dynamics and home VP

1178
01:13:44,437 --> 01:13:48,007
behavior, then we can transfer the

1179
01:13:48,160 --> 01:13:51,142
resulting neural network architecture or

1180
01:13:51,190 --> 01:13:55,632
dynamics into the page and in force

1181
01:13:55,797 --> 01:13:58,562
in some sense post hog mana.

1182
01:14:00,487 --> 01:14:04,582
So we nicely avoid the

1183
01:14:04,735 --> 01:14:08,422
directory addressing the meta agent

1184
01:14:08,530 --> 01:14:11,497
program but obtain the same kind of

1185
01:14:11,530 --> 01:14:14,587
solution in that sense.

1186
01:14:14,650 --> 01:14:18,297
Yes, switch combining with brain

1187
01:14:18,417 --> 01:14:22,332
activity recording like EEG or imaging.

1188
01:14:22,497 --> 01:14:25,927
Yeah, we can

1189
01:14:26,095 --> 01:14:28,827
estimate a plausible neural network

1190
01:14:29,007 --> 01:14:32,450
model in the right hand side and we can

1191
01:14:33,037 --> 01:14:36,367
transform that to home DB in the right

1192
01:14:36,415 --> 01:14:37,250
hand side.

1193
01:14:40,537 --> 01:14:43,822
Awesome. I'm going to show an image and

1194
01:14:43,855 --> 01:14:47,012
ask a question from Dave in the chat.

1195
01:14:47,437 --> 01:14:49,637
So, Dave made this image,

1196
01:14:52,462 --> 01:14:55,357
it's the right side of figure one that

1197
01:14:55,360 --> 01:14:56,752
we've just been looking at with the

1198
01:14:56,770 --> 01:15:00,547
variational Bayesian information and

1199
01:15:00,655 --> 01:15:02,902
he wrote the arc shown as impinging on

1200
01:15:02,920 --> 01:15:04,562
the S self arc.

1201
01:15:06,412 --> 01:15:09,472
Is this intentional? If so, it could

1202
01:15:09,505 --> 01:15:11,677
represent tuning or modulation of the

1203
01:15:11,695 --> 01:15:14,150
feedback of S into itself.

1204
01:15:17,587 --> 01:15:19,325
Do you have a thought on this?

1205
01:15:20,737 --> 01:15:24,212
It's attention? Yes. I think it's

1206
01:15:24,787 --> 01:15:29,037
related to the usual formulation

1207
01:15:29,187 --> 01:15:33,262
of home DP architecture and

1208
01:15:33,400 --> 01:15:36,862
active inference concept in the sense

1209
01:15:36,925 --> 01:15:41,150
that our decision or policy

1210
01:15:42,787 --> 01:15:47,212
in the usual setting modify the

1211
01:15:47,275 --> 01:15:51,137
state transition material b material.

1212
01:15:53,662 --> 01:15:57,067
Here delta is an alternative of

1213
01:15:57,115 --> 01:16:00,472
policy of agent.

1214
01:16:00,580 --> 01:16:04,787
So basically the director indicates

1215
01:16:05,962 --> 01:16:08,347
state transition metrics under a

1216
01:16:08,380 --> 01:16:11,797
particular decision which

1217
01:16:11,905 --> 01:16:15,172
agent maze. In that sense,

1218
01:16:15,355 --> 01:16:18,337
what the agent changes is state

1219
01:16:18,400 --> 01:16:21,082
transition metrics, not state itself

1220
01:16:21,160 --> 01:16:24,562
directly. That's why we use

1221
01:16:24,700 --> 01:16:27,062
this illustration.

1222
01:16:29,362 --> 01:16:32,952
Awesome. Very subtle

1223
01:16:32,982 --> 01:16:35,947
but important point, which is when we

1224
01:16:35,980 --> 01:16:40,487
look at the classical POMDP formulation.

1225
01:16:40,837 --> 01:16:43,597
So here we'll look at a version shown in

1226
01:16:43,630 --> 01:16:45,517
figure two. I'll just bring just figure

1227
01:16:45,565 --> 01:16:46,550
two in.

1228
01:16:49,312 --> 01:16:52,327
Could you describe what you just did

1229
01:16:52,495 --> 01:16:56,750
about the role of the B matrix in

1230
01:16:57,787 --> 01:17:00,127
influencing how hidden states change and

1231
01:17:00,145 --> 01:17:02,572
how that is where our policies have

1232
01:17:02,605 --> 01:17:06,052
impact? And also please, how do the

1233
01:17:06,070 --> 01:17:09,500
top and the bottom of figure two differ?

1234
01:17:13,087 --> 01:17:17,387
Okay, so in the usual correlation

1235
01:17:17,887 --> 01:17:21,597
and active inference

1236
01:17:21,792 --> 01:17:25,402
with palm DB structure so we for

1237
01:17:25,420 --> 01:17:30,350
us to consider the

1238
01:17:32,512 --> 01:17:37,002
prior preference and depending

1239
01:17:37,032 --> 01:17:40,712
on the prior preference, we compute

1240
01:17:41,062 --> 01:17:43,747
the expect free energy and its

1241
01:17:43,780 --> 01:17:48,127
minimization provide the policy and

1242
01:17:48,295 --> 01:17:52,657
the policy moderate state

1243
01:17:52,735 --> 01:17:56,242
transition. So now in the

1244
01:17:56,290 --> 01:17:59,962
upper area we instead use

1245
01:18:00,100 --> 01:18:03,817
the builder which is the

1246
01:18:03,940 --> 01:18:08,452
option of the agent. So here

1247
01:18:08,620 --> 01:18:12,425
option or decision was made

1248
01:18:13,462 --> 01:18:16,762
for each timestep so

1249
01:18:16,825 --> 01:18:20,237
that online the conventional formation

1250
01:18:21,187 --> 01:18:25,562
we have a sequence of delta

1251
01:18:25,912 --> 01:18:29,517
and for each time step delta moderates

1252
01:18:29,652 --> 01:18:33,022
active states transition matrix B. So B

1253
01:18:33,055 --> 01:18:38,292
is a matrix that transfer hidden

1254
01:18:38,352 --> 01:18:41,887
state in the previous step to the

1255
01:18:41,950 --> 01:18:45,612
current time step and its moderation

1256
01:18:45,687 --> 01:18:49,602
indicate that under a specific decision

1257
01:18:49,707 --> 01:18:52,475
rules. For example,

1258
01:18:53,062 --> 01:18:56,407
if this F indicates our

1259
01:18:56,560 --> 01:19:00,337
position in the virtual environment with

1260
01:19:00,475 --> 01:19:04,250
the Gold decision move forward

1261
01:19:05,287 --> 01:19:09,612
bit, if we choose the no go decision,

1262
01:19:09,687 --> 01:19:14,075
then it unchanged. So such a

1263
01:19:15,262 --> 01:19:19,132
moderation of state transition was made

1264
01:19:19,285 --> 01:19:23,122
by choosing debuta and the

1265
01:19:23,155 --> 01:19:27,237
lower part correspond to Beijing

1266
01:19:27,312 --> 01:19:30,950
inference made by Bayesian agent.

1267
01:19:31,687 --> 01:19:35,197
So basically there is

1268
01:19:35,230 --> 01:19:38,847
a symmetry between a third part and Roar

1269
01:19:38,892 --> 01:19:42,547
parse because we assume that this

1270
01:19:42,580 --> 01:19:46,937
Beijing agent has a plausible

1271
01:19:47,437 --> 01:19:50,547
guarantee model which nicely

1272
01:19:50,592 --> 01:19:54,192
correspond to given environment defined

1273
01:19:54,252 --> 01:19:59,802
in the above upper

1274
01:19:59,832 --> 01:20:03,800
part in this figure. But one

1275
01:20:04,312 --> 01:20:10,100
interesting thing

1276
01:20:10,762 --> 01:20:14,632
asymmetry is that to

1277
01:20:14,710 --> 01:20:18,027
model this particular canonical neural

1278
01:20:18,057 --> 01:20:23,467
network. We don't consider an

1279
01:20:23,515 --> 01:20:27,762
arrow or link from delta posteria

1280
01:20:27,837 --> 01:20:31,462
to S posteria. Which is

1281
01:20:31,525 --> 01:20:35,367
in the environment data

1282
01:20:35,427 --> 01:20:39,172
moderate S in the

1283
01:20:39,205 --> 01:20:42,942
next step through P material

1284
01:20:43,077 --> 01:20:46,925
moderation in this particular

1285
01:20:47,962 --> 01:20:50,932
Bay jets. Which formally correspond to a

1286
01:20:50,935 --> 01:20:54,492
canonical neural network. We don't

1287
01:20:54,552 --> 01:20:57,877
consider that it is

1288
01:20:57,970 --> 01:21:02,287
correspond to an salience of

1289
01:21:02,425 --> 01:21:06,712
the projection from

1290
01:21:06,850 --> 01:21:11,947
output layer to the

1291
01:21:11,980 --> 01:21:13,037
middle layer.

1292
01:21:19,087 --> 01:21:19,850
Okay,

1293
01:21:25,837 --> 01:21:30,367
this is from the 2020

1294
01:21:30,490 --> 01:21:33,462
paper, but it shows the neural network

1295
01:21:33,537 --> 01:21:35,172
architecture, the two layer

1296
01:21:35,217 --> 01:21:41,612
architecture. So could you restate

1297
01:21:42,412 --> 01:21:46,882
the top and the bottom of figure two in

1298
01:21:46,885 --> 01:21:50,217
the 22 paper and connect it to why it's

1299
01:21:50,277 --> 01:21:52,902
important that you're studying two layer

1300
01:21:53,007 --> 01:21:57,050
neural network models? I miss you.

1301
01:21:58,162 --> 01:22:03,142
Yeah, can you just connect the

1302
01:22:03,340 --> 01:22:06,877
asymmetry between the top and the

1303
01:22:06,895 --> 01:22:10,267
bottom on figure two with

1304
01:22:10,315 --> 01:22:13,152
the two layer neural network

1305
01:22:13,257 --> 01:22:16,177
architecture? You said that the

1306
01:22:16,195 --> 01:22:18,200
asymmetry there's no direct link

1307
01:22:19,612 --> 01:22:20,375
between.

1308
01:22:27,475 --> 01:22:31,612
This is another story. So in

1309
01:22:32,425 --> 01:22:38,680
the previous paper there

1310
01:22:38,727 --> 01:22:44,655
is only output or concept

1311
01:22:44,715 --> 01:22:49,420
layer because we basically consider a

1312
01:22:49,497 --> 01:22:54,160
single layer feedforward network. So my

1313
01:22:54,192 --> 01:22:59,455
apologies for some confusion about the

1314
01:22:59,502 --> 01:23:03,145
network architecture in the 2020 paper.

1315
01:23:03,222 --> 01:23:07,045
So now upper part of this

1316
01:23:07,122 --> 01:23:09,820
network architecture correspond to

1317
01:23:09,897 --> 01:23:13,060
environmental generative process and

1318
01:23:13,092 --> 01:23:17,125
only a lower part correspond to single

1319
01:23:17,187 --> 01:23:19,365
foot feed for neural network

1320
01:23:19,545 --> 01:23:24,250
architecture. So now this

1321
01:23:24,312 --> 01:23:28,255
part is identical to

1322
01:23:28,452 --> 01:23:32,062
a map from O to

1323
01:23:32,425 --> 01:23:36,730
S OSS area in the 2022

1324
01:23:36,777 --> 01:23:37,625
papers.

1325
01:23:43,225 --> 01:23:46,795
Okay? So on the top of figure

1326
01:23:46,872 --> 01:23:50,475
two is the actual generative

1327
01:23:50,550 --> 01:23:54,325
process. It's the true structure of

1328
01:23:54,387 --> 01:23:56,965
causation in the environment, which is

1329
01:23:56,982 --> 01:24:01,025
to say that actions delta

1330
01:24:01,900 --> 01:24:04,450
actually influence how states change

1331
01:24:04,512 --> 01:24:07,925
through time via B delta.

1332
01:24:09,625 --> 01:24:12,160
The generative process through the A

1333
01:24:12,192 --> 01:24:15,930
matrix emits observation sequences

1334
01:24:15,990 --> 01:24:19,645
of observations. And here

1335
01:24:19,797 --> 01:24:25,400
on the bottom with a mirrored structure

1336
01:24:26,500 --> 01:24:30,125
is the generative model of the entity.

1337
01:24:30,625 --> 01:24:33,425
So what's the relevance of the arrows

1338
01:24:34,225 --> 01:24:36,795
and the more force factor graph

1339
01:24:36,885 --> 01:24:38,887
structure on the bottom.

1340
01:24:40,675 --> 01:24:44,662
The arrow indicates active

1341
01:24:47,050 --> 01:24:48,275
inference.

1342
01:24:50,425 --> 01:24:54,187
So it's a flow of the

1343
01:24:55,225 --> 01:24:58,435
information in the sense that to

1344
01:24:58,467 --> 01:25:02,125
calculate in the step two,

1345
01:25:02,262 --> 01:25:05,680
we use the information of step

1346
01:25:05,727 --> 01:25:09,660
two observation and step one's posterior

1347
01:25:09,705 --> 01:25:12,310
expectation about hidden states. So

1348
01:25:12,417 --> 01:25:16,590
those two determine the s two's

1349
01:25:16,770 --> 01:25:20,760
expectation. Usually in the following

1350
01:25:20,805 --> 01:25:25,625
graph, we consider perspective

1351
01:25:27,025 --> 01:25:31,387
arrow so in the sense that s three also

1352
01:25:33,100 --> 01:25:37,762
affect the S two inference. But this

1353
01:25:38,425 --> 01:25:43,090
corresponds to Bayesian smoother in

1354
01:25:43,107 --> 01:25:46,912
the sense that we update every time step

1355
01:25:47,875 --> 01:25:51,555
simultaneously to better inference.

1356
01:25:51,690 --> 01:25:55,762
However, what we consider here is more

1357
01:25:57,550 --> 01:26:00,130
filtering approach in the sense that for

1358
01:26:00,177 --> 01:26:03,480
each step we compute the latest hidden

1359
01:26:03,540 --> 01:26:07,735
state space, then we don't change any

1360
01:26:07,767 --> 01:26:11,230
other states in the past.

1361
01:26:11,427 --> 01:26:14,860
So that's why we don't consider the

1362
01:26:14,892 --> 01:26:18,712
arrow from future to the past.

1363
01:26:22,337 --> 01:26:27,002
Awesome. Yeah. Just to highlight that in

1364
01:26:27,020 --> 01:26:29,902
the Bayesian smoothing approach. It's

1365
01:26:29,932 --> 01:26:32,882
kind of like fitting a spline because it

1366
01:26:32,885 --> 01:26:34,727
state space whole time series and it

1367
01:26:34,745 --> 01:26:38,475
fits the smoothest possible line

1368
01:26:39,587 --> 01:26:43,262
or the line whose smoothness is on the

1369
01:26:43,400 --> 01:26:46,587
AIC BIC frontier.

1370
01:26:47,612 --> 01:26:51,000
But here on the bottom with the

1371
01:26:51,737 --> 01:26:54,547
almost pseudocode implementation

1372
01:26:54,742 --> 01:26:57,612
provided by the force factor graph.

1373
01:26:58,037 --> 01:27:00,217
Which was demonstrated to be equivalent

1374
01:27:00,277 --> 01:27:04,837
with the Bayesian graph in the 2017

1375
01:27:04,987 --> 01:27:07,362
work with Friston. Par and de Vries.

1376
01:27:08,237 --> 01:27:11,177
This architecture is reflecting a

1377
01:27:11,195 --> 01:27:14,117
filtering scheme like a common filter or

1378
01:27:14,165 --> 01:27:15,922
just generalized Bayesian filtering

1379
01:27:15,967 --> 01:27:20,272
through time. Where estimates

1380
01:27:20,317 --> 01:27:23,482
are being carried forward and changed

1381
01:27:23,572 --> 01:27:26,867
time point to time point. Such that the

1382
01:27:26,915 --> 01:27:29,827
decision rules or the updates perhaps

1383
01:27:29,857 --> 01:27:32,492
more accurately are defined between time

1384
01:27:32,540 --> 01:27:36,337
points and the total time series

1385
01:27:36,412 --> 01:27:38,797
does not have to be loaded into memory

1386
01:27:38,917 --> 01:27:41,567
or remembered at once.

1387
01:27:41,765 --> 01:27:44,562
And then the Bayesian filtering approach

1388
01:27:45,887 --> 01:27:49,427
has the asymmetry with a different

1389
01:27:49,520 --> 01:27:52,362
consideration of action.

1390
01:27:53,987 --> 01:27:56,897
So why again is it that action is

1391
01:27:56,930 --> 01:27:59,842
considered differently in the Bayesian

1392
01:27:59,902 --> 01:28:02,552
filtering approach on the bottom of the

1393
01:28:02,570 --> 01:28:05,692
generative model than the consideration

1394
01:28:05,752 --> 01:28:07,875
of action in the generative process.

1395
01:28:11,162 --> 01:28:15,202
That correspond to lack

1396
01:28:15,232 --> 01:28:19,112
of cognition from y to x

1397
01:28:19,175 --> 01:28:22,125
in the figure one?

1398
01:28:23,387 --> 01:28:27,632
Or probably a figure four

1399
01:28:27,710 --> 01:28:31,292
is helpful to that

1400
01:28:31,415 --> 01:28:32,100
relationship.

1401
01:28:37,487 --> 01:28:41,402
Four? Yeah, this is an example

1402
01:28:41,570 --> 01:28:44,722
network architecture comprising input

1403
01:28:44,767 --> 01:28:49,112
area, output area. What we consider is

1404
01:28:49,250 --> 01:28:52,667
information flow from sensory to

1405
01:28:52,715 --> 01:28:55,292
middle area and middle area have a self

1406
01:28:55,340 --> 01:28:57,767
connection, recurrent connection and

1407
01:28:57,815 --> 01:29:00,907
middle area project to output layer.

1408
01:29:01,072 --> 01:29:04,952
So theorem is no connection from all

1409
01:29:05,120 --> 01:29:07,812
output layer to middle layer.

1410
01:29:08,387 --> 01:29:12,182
Right? So that's why

1411
01:29:12,335 --> 01:29:15,675
we don't consider the

1412
01:29:16,262 --> 01:29:19,472
link from data in the

1413
01:29:19,505 --> 01:29:25,362
bottom layer of the figure to posterior.

1414
01:29:27,062 --> 01:29:29,925
So this is different from truth

1415
01:29:30,737 --> 01:29:34,662
generative process in the environment.

1416
01:29:37,975 --> 01:29:41,185
This is a kind of simplification. So

1417
01:29:41,292 --> 01:29:44,812
because our purpose is identifying the

1418
01:29:46,975 --> 01:29:48,835
plausible Bayesian model which

1419
01:29:48,867 --> 01:29:52,515
correspond to this type of neural

1420
01:29:52,545 --> 01:29:54,650
network canonical network.

1421
01:29:56,200 --> 01:30:00,495
So in other words, this neural network

1422
01:30:00,660 --> 01:30:04,687
rules approximation about that point or

1423
01:30:08,725 --> 01:30:12,337
use limited form of

1424
01:30:14,275 --> 01:30:17,300
palm DP scheme.

1425
01:30:23,700 --> 01:30:27,100
Thanks. So could you describe

1426
01:30:29,100 --> 01:30:32,340
W-V-K and

1427
01:30:32,357 --> 01:30:36,810
Gamma? Just what is the biological or

1428
01:30:36,842 --> 01:30:38,850
functional interpretation of those

1429
01:30:38,912 --> 01:30:42,555
variables? What brain regions or what

1430
01:30:42,602 --> 01:30:45,837
processes or pathologies do they map to?

1431
01:30:47,025 --> 01:30:51,475
Okay, so basically WVK

1432
01:30:52,200 --> 01:30:55,485
synaptic strength is in the form of

1433
01:30:55,592 --> 01:30:59,862
material and active inference.

1434
01:31:04,875 --> 01:31:08,255
They represent connection

1435
01:31:08,315 --> 01:31:10,620
in the different layer or different

1436
01:31:10,772 --> 01:31:15,012
architecture in the sense that W

1437
01:31:15,750 --> 01:31:19,625
means forward connectivity from sensory

1438
01:31:19,700 --> 01:31:22,800
leave to middle Laje. K correspond to

1439
01:31:22,862 --> 01:31:25,520
recurrent network recurrent connectivity

1440
01:31:25,685 --> 01:31:30,155
and V correspond to projection

1441
01:31:30,215 --> 01:31:33,990
from middle area to output layer. So in

1442
01:31:34,007 --> 01:31:37,080
this paper, we don't discuss the

1443
01:31:37,277 --> 01:31:40,755
relation to brain anatomy in detail,

1444
01:31:40,877 --> 01:31:47,385
but what one

1445
01:31:47,417 --> 01:31:50,862
can consider ontology, for example,

1446
01:31:51,900 --> 01:31:57,800
say x corresponds to several

1447
01:31:57,875 --> 01:32:02,985
cortex activity and Y,

1448
01:32:03,167 --> 01:32:06,435
for example correspond to cerebral wrong

1449
01:32:06,542 --> 01:32:09,700
in the sense that it determines

1450
01:32:13,125 --> 01:32:17,015
the action. So it is considered

1451
01:32:17,045 --> 01:32:20,075
that in the cerebrum there is a signal

1452
01:32:20,150 --> 01:32:23,310
that representations choice. This is

1453
01:32:23,342 --> 01:32:26,875
joined for examples goal no go decision

1454
01:32:27,300 --> 01:32:29,200
made in cergram.

1455
01:32:31,575 --> 01:32:35,700
It's analogous to this

1456
01:32:35,762 --> 01:32:38,310
particular architecture. On the other

1457
01:32:38,342 --> 01:32:41,855
hand, in the several cortex

1458
01:32:41,990 --> 01:32:45,785
we compute the sensory

1459
01:32:45,830 --> 01:32:49,985
information to generate

1460
01:32:50,030 --> 01:32:55,300
some inference, prediction and planning

1461
01:32:56,850 --> 01:33:00,855
the way it is computer by

1462
01:33:00,977 --> 01:33:03,300
this recurrent network. In this

1463
01:33:03,362 --> 01:33:06,600
particular modeling, although we

1464
01:33:06,662 --> 01:33:10,185
don't separate brain region in

1465
01:33:10,217 --> 01:33:13,575
detail, but this recurrent network is

1466
01:33:13,637 --> 01:33:17,465
sufficient this graph

1467
01:33:17,495 --> 01:33:19,635
of recurrent network is sufficient to

1468
01:33:19,667 --> 01:33:23,350
characterize any type of architectures

1469
01:33:24,450 --> 01:33:28,770
in the sense that we can design

1470
01:33:28,847 --> 01:33:32,850
any higher

1471
01:33:32,912 --> 01:33:37,520
car or mutually

1472
01:33:37,610 --> 01:33:41,405
connected architecture using a generic

1473
01:33:41,465 --> 01:33:45,815
crossover recurrent network by changing

1474
01:33:45,995 --> 01:33:46,750
weight.

1475
01:33:54,750 --> 01:33:58,125
Awesome. So the middle

1476
01:33:58,187 --> 01:34:00,705
layer we can think of as like the

1477
01:34:00,752 --> 01:34:03,665
cognition stuff. It's the internal

1478
01:34:03,695 --> 01:34:05,705
states when we talk about perception,

1479
01:34:05,765 --> 01:34:10,475
cognition, action in the active scheme

1480
01:34:10,550 --> 01:34:12,810
or even in the sandwich model of

1481
01:34:12,842 --> 01:34:16,300
cognition perception, cognition action.

1482
01:34:17,250 --> 01:34:21,405
So W is describing how

1483
01:34:21,452 --> 01:34:24,195
those sensory inputs either in one step

1484
01:34:24,272 --> 01:34:27,740
or composably in multiple steps

1485
01:34:27,920 --> 01:34:31,437
become processed to these internal

1486
01:34:32,475 --> 01:34:36,260
representation of hidden external causes

1487
01:34:36,455 --> 01:34:38,760
inferred external state space. So these

1488
01:34:38,792 --> 01:34:42,630
are the states that have that

1489
01:34:42,827 --> 01:34:45,915
sigma relationship and a

1490
01:34:45,932 --> 01:34:47,585
generalized synchrony with external

1491
01:34:47,630 --> 01:34:49,715
states. The sigma and the generalized

1492
01:34:49,745 --> 01:34:51,960
synchrony are not discussed in your

1493
01:34:51,992 --> 01:34:55,305
paper, but it connects to other work and

1494
01:34:55,502 --> 01:34:59,160
the recurrent connections are

1495
01:34:59,342 --> 01:35:03,095
facilitating attention

1496
01:35:03,260 --> 01:35:06,550
or waiting of the stimuli.

1497
01:35:08,250 --> 01:35:11,685
This is the recurrent learning loop and

1498
01:35:11,717 --> 01:35:13,965
the relationship of the A between

1499
01:35:14,057 --> 01:35:16,450
observation and hidden state estimates.

1500
01:35:18,225 --> 01:35:20,875
And then a different kind of modulation

1501
01:35:21,675 --> 01:35:24,710
comes Hinton play between the hidden

1502
01:35:24,755 --> 01:35:27,195
state estimate of the internal state

1503
01:35:27,197 --> 01:35:30,435
scale and the action selection. So what

1504
01:35:30,467 --> 01:35:34,190
is gamma corresponding

1505
01:35:34,220 --> 01:35:36,625
to? And why is the gamma modulation

1506
01:35:37,275 --> 01:35:40,450
between layers two and three differing

1507
01:35:40,950 --> 01:35:44,510
functionally from the k synaptic

1508
01:35:44,555 --> 01:35:46,812
modulation of one and two?

1509
01:35:47,850 --> 01:35:53,037
Yeah, so K material basically

1510
01:35:53,925 --> 01:35:56,730
formally correspond to b matrix in the

1511
01:35:56,777 --> 01:36:00,470
Bayesian information. So we state

1512
01:36:00,560 --> 01:36:04,235
the information about the prediction,

1513
01:36:04,280 --> 01:36:07,865
right, our narrative or our expectation

1514
01:36:07,970 --> 01:36:11,910
about the next state

1515
01:36:12,092 --> 01:36:15,315
based on the previous state. On the

1516
01:36:15,332 --> 01:36:18,765
other hand, Laurel gamma is

1517
01:36:18,857 --> 01:36:22,550
quite different from such a computation.

1518
01:36:22,625 --> 01:36:28,160
Gamma basically means risk

1519
01:36:28,205 --> 01:36:32,535
function, which is in

1520
01:36:32,567 --> 01:36:35,780
principle can we use arbitrary risk

1521
01:36:35,840 --> 01:36:38,610
function. So this is a part of

1522
01:36:38,792 --> 01:36:42,180
generative model we designed and the

1523
01:36:42,227 --> 01:36:44,855
rules of risk function in generative

1524
01:36:44,915 --> 01:36:48,710
model formulation is attention

1525
01:36:48,830 --> 01:36:51,825
form of generative model depending on

1526
01:36:51,962 --> 01:36:56,875
that value of gamma which examples

1527
01:37:02,025 --> 01:37:06,650
perspective, moderation of evaluation

1528
01:37:06,725 --> 01:37:11,130
of task decisions given an

1529
01:37:11,252 --> 01:37:13,587
outcome in the future.

1530
01:37:15,225 --> 01:37:19,185
In terms of neural network, of course it

1531
01:37:19,217 --> 01:37:21,485
corresponds to some neural modulation.

1532
01:37:21,605 --> 01:37:24,195
For example, Dopaminergic moderation is

1533
01:37:24,272 --> 01:37:28,375
famous in the literature which moderates

1534
01:37:29,025 --> 01:37:33,250
the activity and plasticity of various

1535
01:37:33,675 --> 01:37:37,290
brain vision. But we particularly focus

1536
01:37:37,382 --> 01:37:40,785
on Dopaminergic or

1537
01:37:40,892 --> 01:37:44,930
any kind of neuromodulator of cyanogic

1538
01:37:44,990 --> 01:37:48,555
prosthesis in the output trigger which

1539
01:37:48,602 --> 01:37:52,710
may correspond to Cergram. So in

1540
01:37:52,742 --> 01:37:55,635
the Serbram neural activity or

1541
01:37:55,667 --> 01:37:59,000
processing moderated by Dopaminergic

1542
01:37:59,150 --> 01:38:07,812
input from is

1543
01:38:08,250 --> 01:38:14,187
used as the optimization action

1544
01:38:15,600 --> 01:38:19,260
rules, decision rules or sometimes

1545
01:38:19,367 --> 01:38:24,675
attention help

1546
01:38:24,737 --> 01:38:25,362
us.

1547
01:38:29,212 --> 01:38:32,917
Awesome. Very interesting because in

1548
01:38:32,965 --> 01:38:36,007
some previous papers and models that

1549
01:38:36,010 --> 01:38:40,012
we've looked at attention is

1550
01:38:40,150 --> 01:38:44,497
dealt switch as policy selection on

1551
01:38:44,605 --> 01:38:47,622
mental states. So internal action

1552
01:38:47,667 --> 01:38:50,892
selection, it's an action

1553
01:38:50,952 --> 01:38:53,752
like variable describing attention and

1554
01:38:53,770 --> 01:38:56,012
awareness and even metacognition.

1555
01:38:56,737 --> 01:39:00,217
And so that connects the

1556
01:39:00,265 --> 01:39:03,717
role of Dopamine in motor decision

1557
01:39:03,777 --> 01:39:08,652
making seen in many Dyskinesias

1558
01:39:08,832 --> 01:39:12,007
but also with the role of Dopamine in

1559
01:39:12,085 --> 01:39:16,937
seemingly nonmotor based decisionmaking

1560
01:39:17,287 --> 01:39:20,687
like gambling or investing

1561
01:39:21,412 --> 01:39:23,457
where it doesn't seem to immediately

1562
01:39:23,547 --> 01:39:27,962
translate to a given motor sequence.

1563
01:39:28,912 --> 01:39:31,332
Yet it has analogous computational

1564
01:39:31,422 --> 01:39:35,067
characteristics and the comorbidities

1565
01:39:35,127 --> 01:39:37,152
and the side effects of different drugs

1566
01:39:37,182 --> 01:39:39,957
that affect the Dopamine neurophysiology

1567
01:39:40,122 --> 01:39:43,822
are known to have carryover in

1568
01:39:43,855 --> 01:39:45,862
terms of like the rigidity or

1569
01:39:45,925 --> 01:39:50,047
excessivity of motor and decision making

1570
01:39:50,230 --> 01:39:52,327
aspects. So it's like interesting that

1571
01:39:52,345 --> 01:39:55,102
Dopamine has long been understood to

1572
01:39:55,120 --> 01:39:59,212
have that parallel role in

1573
01:39:59,350 --> 01:40:03,157
attention as cognitive action and

1574
01:40:03,235 --> 01:40:07,527
motor action and that was established

1575
01:40:07,557 --> 01:40:10,897
empirically through modifications of

1576
01:40:10,930 --> 01:40:14,317
Dopamine signaling and also had been

1577
01:40:14,365 --> 01:40:17,237
modeled analogously with computational

1578
01:40:18,112 --> 01:40:21,437
neuroscience. And this is providing

1579
01:40:22,087 --> 01:40:23,602
again a slightly different

1580
01:40:23,695 --> 01:40:27,217
interpretation of

1581
01:40:27,265 --> 01:40:31,542
that very well studied Dofaminergic

1582
01:40:31,602 --> 01:40:35,900
modulation of attention and policy.

1583
01:40:40,837 --> 01:40:44,722
Yes. In addition to

1584
01:40:44,755 --> 01:40:46,777
that, I believe another important

1585
01:40:46,870 --> 01:40:49,437
aspects is modularity of scientific

1586
01:40:49,512 --> 01:40:51,887
process noise document.

1587
01:41:15,850 --> 01:41:18,937
Do you want to show something or yeah.

1588
01:41:20,875 --> 01:41:24,670
Can you see this

1589
01:41:24,747 --> 01:41:28,150
paper? I sent

1590
01:41:28,212 --> 01:41:31,325
you a chat.

1591
01:41:32,275 --> 01:41:36,275
If you can't, I'll send you a PDF.

1592
01:41:37,450 --> 01:41:39,037
Okay, let me see.

1593
01:41:40,300 --> 01:41:42,412
I'll look at it up now.

1594
01:41:47,425 --> 01:41:50,965
All right. The paper is a

1595
01:41:50,982 --> 01:41:54,105
critical time window for Dopamine

1596
01:41:54,165 --> 01:41:57,735
actions on the structural plasticity

1597
01:41:57,780 --> 01:42:02,460
of dendritic spines from 2014 byagasha

1598
01:42:02,580 --> 01:42:05,155
so what is interesting about this paper

1599
01:42:05,352 --> 01:42:10,995
yeah. It basically explained operating

1600
01:42:11,085 --> 01:42:14,160
point plasticity by Dopamine,

1601
01:42:14,280 --> 01:42:18,885
which is common but crucial

1602
01:42:19,080 --> 01:42:22,330
point of this paper is that it shows

1603
01:42:22,377 --> 01:42:26,355
that it proved that Dopaminezic input

1604
01:42:26,490 --> 01:42:31,495
can moderate after

1605
01:42:31,647 --> 01:42:34,395
hebion prosthesis is established.

1606
01:42:34,485 --> 01:42:37,915
So this paper showed that they

1607
01:42:38,007 --> 01:42:41,635
add domain topic input for

1608
01:42:41,667 --> 01:42:44,835
about 2 seconds after or several seconds

1609
01:42:44,880 --> 01:42:48,050
after the Hebbian

1610
01:42:48,550 --> 01:42:52,450
process is established. But such a post

1611
01:42:52,512 --> 01:42:58,080
hoc moderation, post hoc introduction

1612
01:42:58,215 --> 01:43:01,110
of heterotopamagic Impetu is sufficient

1613
01:43:01,155 --> 01:43:04,815
to change the past capacity

1614
01:43:04,995 --> 01:43:09,340
which may be associated with the

1615
01:43:09,432 --> 01:43:13,075
post hoc evolution of our

1616
01:43:13,137 --> 01:43:17,020
past decisions. So by decision making

1617
01:43:17,097 --> 01:43:21,625
we of course changes the changes

1618
01:43:21,687 --> 01:43:25,180
the weight matrix by thought truth 50.

1619
01:43:25,377 --> 01:43:29,335
But to evaluate the

1620
01:43:29,367 --> 01:43:32,230
goodness or badness of our decision, we

1621
01:43:32,277 --> 01:43:35,620
need to set observe the future

1622
01:43:35,697 --> 01:43:39,160
outcome which is propagated by

1623
01:43:39,342 --> 01:43:42,325
for example, Dopamine. And this paper

1624
01:43:42,387 --> 01:43:48,300
nicely show empirically that Dopamine

1625
01:43:48,450 --> 01:43:52,045
actually can change

1626
01:43:52,122 --> 01:43:56,610
the past evaluation

1627
01:43:56,805 --> 01:44:01,012
maze after such a psychic level very

1628
01:44:01,825 --> 01:44:05,437
local level, ecoscopic level.

1629
01:44:12,250 --> 01:44:15,690
So there's

1630
01:44:15,720 --> 01:44:19,100
a short term window,

1631
01:44:20,275 --> 01:44:22,815
the critical time window that they're

1632
01:44:22,845 --> 01:44:25,935
describing, but there's some window,

1633
01:44:26,130 --> 01:44:29,812
yeah, some window by which

1634
01:44:30,925 --> 01:44:33,910
Dopamine potentially unrelated to the

1635
01:44:33,942 --> 01:44:37,550
initial heavy and plasticity events,

1636
01:44:37,975 --> 01:44:41,100
right, where secondary Dopamine

1637
01:44:41,175 --> 01:44:45,180
signaling or not secondary,

1638
01:44:45,240 --> 01:44:47,737
just after the initial fact,

1639
01:44:48,925 --> 01:44:50,890
potentially of a different valence or

1640
01:44:50,907 --> 01:44:56,730
the same valence can synergize

1641
01:44:56,865 --> 01:45:00,160
or cancel the

1642
01:45:00,267 --> 01:45:02,662
plasticity formed in the moment.

1643
01:45:03,100 --> 01:45:06,595
Exactly. And this is not

1644
01:45:06,672 --> 01:45:09,360
limited to Dopamine, but other neuro

1645
01:45:09,405 --> 01:45:12,862
moderator can also do this.

1646
01:45:18,250 --> 01:45:20,755
Well, on one hand, how does this change

1647
01:45:20,802 --> 01:45:23,460
our understanding of animal

1648
01:45:23,505 --> 01:45:26,395
neurophysiology? And then I guess, on

1649
01:45:26,397 --> 01:45:28,830
the other hand, how does this influence

1650
01:45:28,890 --> 01:45:32,430
how we would design sentient

1651
01:45:32,490 --> 01:45:33,575
artifacts.

1652
01:45:42,625 --> 01:45:45,787
For both animals and

1653
01:45:49,675 --> 01:45:51,112
artificial agent?

1654
01:45:53,350 --> 01:45:56,830
One important message I area

1655
01:45:56,877 --> 01:46:02,185
with us. So this tells us possible

1656
01:46:02,292 --> 01:46:06,275
simple architecture to make learning.

1657
01:46:07,900 --> 01:46:09,955
This is association between past

1658
01:46:10,002 --> 01:46:13,870
decision and future reward or any

1659
01:46:13,947 --> 01:46:17,280
risk factors, which is otherwise

1660
01:46:17,415 --> 01:46:21,510
computed by computing forward prediction

1661
01:46:21,630 --> 01:46:24,875
by iterating some computational.

1662
01:46:26,500 --> 01:46:31,710
This is a usual way to predict

1663
01:46:31,755 --> 01:46:35,320
the future event and then select the

1664
01:46:35,397 --> 01:46:40,405
option. But using this property,

1665
01:46:40,527 --> 01:46:43,185
biological property, which is observed

1666
01:46:43,230 --> 01:46:45,725
in experiment,

1667
01:46:46,525 --> 01:46:50,512
we can design, we can imagine other

1668
01:46:51,325 --> 01:46:55,100
simpler architecture to make a planning.

1669
01:46:57,250 --> 01:47:02,490
So for both animals and synthetic

1670
01:47:02,670 --> 01:47:05,650
Bayesian agent, it provides an

1671
01:47:05,712 --> 01:47:09,610
alternative explanation about the

1672
01:47:09,642 --> 01:47:12,480
association between our past decision

1673
01:47:12,540 --> 01:47:15,125
and the future risk and the optimization

1674
01:47:15,550 --> 01:47:18,930
of our decision to maximize reward

1675
01:47:18,990 --> 01:47:20,600
or minimize risk.

1676
01:47:25,075 --> 01:47:28,590
Well, one interesting noise is we spoke

1677
01:47:28,620 --> 01:47:30,640
earlier about the difference between the

1678
01:47:30,657 --> 01:47:33,975
Bayesian smoothing all at once approach

1679
01:47:34,125 --> 01:47:36,445
and the Bayesian filtering step by step

1680
01:47:36,522 --> 01:47:39,655
approach. Now, if one had

1681
01:47:39,702 --> 01:47:41,550
infinite knowledge and computational

1682
01:47:41,625 --> 01:47:44,190
resources, the Bayesian smoothing

1683
01:47:44,220 --> 01:47:47,020
approach is the way to go. Like, you

1684
01:47:47,022 --> 01:47:48,610
don't want the decision rule for

1685
01:47:48,642 --> 01:47:50,815
investment. You want to look at the

1686
01:47:50,832 --> 01:47:52,690
whole time series past, present and

1687
01:47:52,707 --> 01:47:55,765
future, and know the best moments to

1688
01:47:55,782 --> 01:47:57,835
have made the trades. I mean, there's no

1689
01:47:57,867 --> 01:47:59,695
comparison. You're going to do better

1690
01:47:59,772 --> 01:48:02,170
with the Bayesian smoothing. However,

1691
01:48:02,247 --> 01:48:04,635
it's just implausible computationally

1692
01:48:04,680 --> 01:48:07,495
and because it requires total memory of

1693
01:48:07,497 --> 01:48:09,640
the past and knowledge of the future.

1694
01:48:09,807 --> 01:48:13,050
So that's what motivates the development

1695
01:48:13,125 --> 01:48:16,250
of Bayesian filtering approaches,

1696
01:48:16,900 --> 01:48:20,025
which are tractable and calculable

1697
01:48:20,100 --> 01:48:23,800
through time. Yet with this

1698
01:48:23,862 --> 01:48:25,625
time delayed modulation,

1699
01:48:27,400 --> 01:48:30,870
part of the Bayesian smoothing strength

1700
01:48:30,960 --> 01:48:35,445
comes back into play. It doesn't enable

1701
01:48:35,610 --> 01:48:39,325
true anticipation of future

1702
01:48:39,387 --> 01:48:42,315
states, but that's what the expected

1703
01:48:42,345 --> 01:48:46,065
free energy does. However, the delayed

1704
01:48:46,095 --> 01:48:48,430
neuromodulation allows for

1705
01:48:48,477 --> 01:48:51,055
reconsideration of a window of past

1706
01:48:51,102 --> 01:48:54,175
states. And so in that way, it

1707
01:48:54,237 --> 01:48:57,937
corresponds to like a

1708
01:48:58,525 --> 01:49:01,475
slightly deeper filter,

1709
01:49:01,975 --> 01:49:04,375
not just a filter of a time step of one,

1710
01:49:04,437 --> 01:49:06,835
but a filter of like a rolling window of

1711
01:49:06,867 --> 01:49:10,380
five, or with some decay. And you don't

1712
01:49:10,440 --> 01:49:12,745
want that window to be too big because

1713
01:49:12,822 --> 01:49:14,887
if the window were ten minutes,

1714
01:49:15,850 --> 01:49:19,860
then too many contrasting stimuli

1715
01:49:19,905 --> 01:49:24,180
would get piled together. The Dopamine

1716
01:49:24,240 --> 01:49:25,855
level would just converge to a mean

1717
01:49:25,902 --> 01:49:29,050
field average. But there's some time

1718
01:49:29,112 --> 01:49:32,680
decay or time constant on the post

1719
01:49:32,727 --> 01:49:35,740
hoc modulation where that

1720
01:49:35,832 --> 01:49:39,040
neuromodulatory signal is

1721
01:49:39,132 --> 01:49:42,412
actually a parameter of interest.

1722
01:49:43,000 --> 01:49:44,965
And that's not an infinitely long or

1723
01:49:44,982 --> 01:49:47,437
infinitely short window, but it's some

1724
01:49:48,325 --> 01:49:51,787
niche dependent amount of time.

1725
01:49:52,450 --> 01:49:55,515
And that's a very interpretable

1726
01:49:55,620 --> 01:50:00,310
and first principle interpretation of

1727
01:50:00,492 --> 01:50:03,425
the computational role of neuromodulator

1728
01:50:04,900 --> 01:50:07,690
in a way that is also consistent with

1729
01:50:07,707 --> 01:50:09,955
all these other concordances we've been

1730
01:50:10,002 --> 01:50:13,660
exploring. So it's quite

1731
01:50:13,692 --> 01:50:16,387
an interesting connection back,

1732
01:50:17,875 --> 01:50:21,250
I guess in our final minutes of this

1733
01:50:21,387 --> 01:50:22,400
discussion.

1734
01:50:26,850 --> 01:50:29,400
What are you? Well,

1735
01:50:29,537 --> 01:50:33,087
maybe go to the beginning at the end,

1736
01:50:33,525 --> 01:50:36,015
which I meant to ask earlier, but it's a

1737
01:50:36,032 --> 01:50:39,420
good way that we can sort of close today

1738
01:50:39,497 --> 01:50:42,420
and look forward, which is how did you

1739
01:50:42,497 --> 01:50:44,712
come to this online of research

1740
01:50:45,750 --> 01:50:49,335
specifically studying neural networks in

1741
01:50:49,367 --> 01:50:53,010
this way with Karl Friston and your

1742
01:50:53,042 --> 01:50:53,800
colleagues?

1743
01:50:58,275 --> 01:51:00,837
So, yes,

1744
01:51:08,550 --> 01:51:13,335
so my interest was the

1745
01:51:13,367 --> 01:51:17,915
characterization of Barricade network.

1746
01:51:18,095 --> 01:51:21,885
So my first motivation is to make

1747
01:51:21,992 --> 01:51:26,210
biologically plausible artificial

1748
01:51:26,405 --> 01:51:29,610
intelligence. But to achieve that, we

1749
01:51:29,642 --> 01:51:32,790
need to know about biological brain or

1750
01:51:32,882 --> 01:51:35,725
biological neural networking.

1751
01:51:41,100 --> 01:51:44,160
In these several years I

1752
01:51:44,192 --> 01:51:49,205
collaborated with the doctor professor

1753
01:51:49,265 --> 01:51:53,145
Californiston to study about

1754
01:51:53,222 --> 01:51:56,725
his salary principle after doing forest.

1755
01:52:01,125 --> 01:52:05,040
My question during that

1756
01:52:05,132 --> 01:52:09,705
period was the

1757
01:52:09,752 --> 01:52:13,812
prior principle, is everything

1758
01:52:14,175 --> 01:52:18,435
about the biological possible

1759
01:52:18,542 --> 01:52:22,305
neural network? Or is theorem another

1760
01:52:22,427 --> 01:52:27,285
aspect that can characterize the

1761
01:52:27,317 --> 01:52:30,795
virus car neural network? So it is

1762
01:52:30,947 --> 01:52:35,015
non trivial. It was non trivial.

1763
01:52:35,195 --> 01:52:39,705
So that's why I

1764
01:52:39,752 --> 01:52:44,450
tried to start from characterizing

1765
01:52:44,525 --> 01:52:48,830
the neural network first. So our state

1766
01:52:48,890 --> 01:52:54,960
is not

1767
01:52:55,067 --> 01:52:59,190
considering the way of implementing any

1768
01:52:59,282 --> 01:53:02,960
Bayesian algorithm as the brain

1769
01:53:03,155 --> 01:53:06,675
architecture, but my interest

1770
01:53:06,737 --> 01:53:10,125
is rather characterization of a given

1771
01:53:10,262 --> 01:53:15,405
vertical network in terms of some

1772
01:53:15,452 --> 01:53:19,095
other things. One possible way is

1773
01:53:19,172 --> 01:53:21,330
of course based on inference free energy

1774
01:53:21,377 --> 01:53:25,062
transplant reinforce. So that's why I

1775
01:53:26,100 --> 01:53:28,520
start from characterizing power's

1776
01:53:28,610 --> 01:53:32,580
network. But just

1777
01:53:32,702 --> 01:53:37,470
defining neural network architecture is

1778
01:53:37,547 --> 01:53:38,575
insufficient.

1779
01:53:41,625 --> 01:53:46,000
Bit is not tractable, it is far beyond

1780
01:53:46,500 --> 01:53:50,235
the computational tractability as

1781
01:53:50,267 --> 01:53:54,030
the mathematical analysis and

1782
01:53:54,077 --> 01:53:58,130
we need some assumptions

1783
01:53:58,190 --> 01:54:02,280
or some trick to increase the

1784
01:54:02,402 --> 01:54:06,762
stability. One day I came up

1785
01:54:07,200 --> 01:54:14,955
with an idea that in

1786
01:54:15,002 --> 01:54:18,810
which we consider that both new

1787
01:54:18,842 --> 01:54:22,545
activity and fastest follow the

1788
01:54:22,622 --> 01:54:25,580
same cost function gradient.

1789
01:54:25,715 --> 01:54:29,787
This is very much an allergy with

1790
01:54:30,675 --> 01:54:34,150
physical system like Lagrangian

1791
01:54:34,575 --> 01:54:37,295
information or Hamiltonian formation.

1792
01:54:37,385 --> 01:54:40,575
So usually we consider some

1793
01:54:40,637 --> 01:54:44,337
energy landscape and design

1794
01:54:45,600 --> 01:54:50,090
plausible trajectory

1795
01:54:50,195 --> 01:54:54,387
as the evolution of some principle of

1796
01:54:54,825 --> 01:54:58,040
minimum action

1797
01:54:58,070 --> 01:55:01,512
or restruction. So we

1798
01:55:02,700 --> 01:55:05,775
imagine that what if we applied such

1799
01:55:05,837 --> 01:55:09,925
idea to computational

1800
01:55:10,650 --> 01:55:12,395
neural network or biological neural

1801
01:55:12,410 --> 01:55:15,462
networks to characterize thermodynamics

1802
01:55:17,025 --> 01:55:20,430
of the brain first

1803
01:55:20,477 --> 01:55:24,615
principle. That's the first

1804
01:55:24,782 --> 01:55:28,515
variational step to come up with this

1805
01:55:28,682 --> 01:55:29,575
framework.

1806
01:55:31,425 --> 01:55:34,935
And finally we noticed that

1807
01:55:35,042 --> 01:55:38,330
it is not easy to connect the Newtonian

1808
01:55:38,390 --> 01:55:40,910
dynamics with this type of neural

1809
01:55:40,955 --> 01:55:44,735
activity study because neural

1810
01:55:44,780 --> 01:55:47,640
activification not necessary to be a

1811
01:55:47,732 --> 01:55:51,305
second order differential

1812
01:55:51,365 --> 01:55:55,137
equation, but rather it is fast order

1813
01:55:55,500 --> 01:55:58,335
and considering many things.

1814
01:55:58,442 --> 01:56:04,287
Then we finally

1815
01:56:06,000 --> 01:56:09,687
use DA Costa function

1816
01:56:11,250 --> 01:56:13,975
proposal in the papers,

1817
01:56:16,125 --> 01:56:20,200
which is not necessary to have a former

1818
01:56:22,050 --> 01:56:25,535
identity with the so called lavalier

1819
01:56:25,655 --> 01:56:29,030
in the Newtonian physics,

1820
01:56:29,090 --> 01:56:32,535
but it is rather plausible as

1821
01:56:32,567 --> 01:56:37,925
the rules or underlying

1822
01:56:38,000 --> 01:56:41,700
mechanism of such

1823
01:56:41,762 --> 01:56:43,675
type of network.

1824
01:56:51,800 --> 01:56:54,287
Awesome. Well,

1825
01:56:55,400 --> 01:56:59,080
it has been quite an interesting dot

1826
01:56:59,140 --> 01:57:02,485
one. I really appreciate

1827
01:57:02,530 --> 01:57:05,540
everything you've shared today. Is there

1828
01:57:05,557 --> 01:57:07,040
anything else you want to add at this

1829
01:57:07,057 --> 01:57:08,912
point? Otherwise we'll talk again.

1830
01:57:10,325 --> 01:57:11,087
Yeah,

1831
01:57:13,775 --> 01:57:16,050
I already speak a role.

1832
01:57:17,675 --> 01:57:20,675
Thank you. Alright, talk to you later.

1833
01:57:20,737 --> 01:57:23,900
Bye. Thank you very much for a nice


