SPEAKER_01:
hello and welcome everyone it's december 6 2022 we're in act inf book stream number 001.01 a numbering convention that will be explained soon it's a discussion on the book governing continuous transformation by bijan khazri and i'll pass the blue


SPEAKER_00:
Hi, everyone.

I guess that's my job is to explain the bookstream numbering.

So this is our first bookstream.

That's why it's bookstream 001.

And this is our first dot zero contextualization video for this bookstream series.

So each week we will present a chapter-ish, a chapter or so of the book, and then periodically we will get together for the 001.1, 001.2, and so forth, those discussion sections.

So if you want to participate either in a contextualization video or in a discussion video, please get in touch with us, and we would love to have you on the stream.

And I'm blue.

I've been here before, so hopefully you've seen me before and know me by now.

And I'm an independent researcher in New Mexico.

And I will pass it off to Tyler, first time appearance, I think, in the Active Inference Institute.

So Tyler, do you want to introduce yourself?


SPEAKER_02:
Yeah, cool.

Thanks for having me.

This is my first time here to Active Inference.

So I have an unusual background.

I actually don't come from an academic background at all.

A lot has been about applied governance.

So I actually started as a strategy consultant working in major corporations.

More recently, it's gotten more to DAO governance.

I currently lead product and protocol design for the 4K protocol.

It's a project that

It's connecting the physical world to the on-chain world.

And I'm also a contributor at MediGov, where I think about how we can model these abstract formalisms about governance in a real-world setting.

And so a lot of times I think about DAO governance, but most recently it's been thinking about active inference and implications for real-world settings.


SPEAKER_00:
So we are a participatory online lab that is communicating, learning, and practicing applied active inference.

These are all of our media links, and we will be recording and archiving this live stream for future reference.

Everyone is welcome, and hopefully we will be following good etiquette for live streams and not arguing or talking over each other for the duration of the book streams.

Okay.

So this is our first book stream.

Our goal is to learn and discuss this textbook, Governing Continuous Transformation, Reframing the Strategy Governance Conversation.

It's a 2022 book by Bijan Kesri.

And this video, like always, is just an introduction to some of the ideas, not a review or a final word at all.

So we will just go through here.

The sections of this book stream, we're going to do the book map and the roadmap, some keywords, the preface part one and chapter one will be covered in today's video.

And in the coming weeks, we will be continuing to discuss this.

So get in touch if you want to partake in these conversations.

So I guess we introduced ourselves briefly.

Oh, backwards.

So if either you guys want to maybe mention something you're excited about or that you liked or remembered from the book, from these first sessions, otherwise we can go on to just cover it.

I think we have a lot of material.

Tyler, what are you most excited about?


SPEAKER_02:
Yeah, I mean, I think for me, like, especially being in like real world organizations, nonprofits, a lot of times we think of like uncertainty as something that could be wished away or something that we're incrementally going to solve.

Like, oh, if we only were collecting like more information, we would be in a better spot or I don't think we had more capabilities.

We wouldn't have this problem.

But a lot of times we kind of get confused.

very anxious about the uncertainty rather than we're an active inference and free energy governance that uncertainty is placed at the center.

And it's something you could actually take ownership over, but also be a source of, you know, creative growth.

And so I think that's really exciting and inspirational and yeah, really excited to be here today.


SPEAKER_00:
Cool.

I'm excited, too, to unify some of the concepts of active inference with governance, which I know a little bit about, but not very much.

And now that we're like formalizing our structure as an institutional entity in the Active Inference Institute, I'm excited to learn more about governance and how things should work.

Okay, so this book has four parts.

So we're here.

Well, we're not even in part one yet, but we're going to go over to the beginning of part one today.

So part one is reframing the strategy governance conversation.

Part two is about free energy governance.

And part three is a conclusion for the book.

And then there are some interviews in part four.

along with acknowledgements and an epilogue.

And this is from the bookmap software.

So this is like our roadmap for a book, but this bookmap software is used in trading.

So if you guys have never seen it, that's what these graphs are from.

So when I think about bookmap, I always think about that.

Okay, so our roadmap for today.

So we're going to get into the preface.

There are no section headings.

So we just kind of chunked out like what makes sense in terms of the text and how it reads.

So we're going to go over a summary of the FEP, how to ground firms in the framework of active inference, strategy governance models versus meta governance, the triplet structure of free energy governance.

And then realists and anti-realists in management science.

And then just a brief intro to part one.

And then chapter one, which is pretty short.

Thinking born of curiosity, revolt, and change.

So here is like a huge list of keywords that we're going to get into today.

And I think Tyler is going to start us off in section one in the preface.

In the summary of the free energy principle, Tyler is going to start us off.


SPEAKER_04:
talking about the FEP.

Tyler, unmute.


SPEAKER_02:
Sorry.

So the free energy principle, or FEP, as we're going to be calling it, this is John's definition that he gives in the preface.

So the FEP is a mathematical formulation that explains from first principles the characteristics of biological systems that are able to resist decay and persist over time.

It rests on the idea that all biological systems instantiate a hierarchical generative model of the world and firstly minimizes its internal entropy by minimizing free energy.

Blue, anything you'd want to add there?


SPEAKER_00:
No, I think it's best like we could take a deep dive into the FEP.

There are many live streams where that's done.

So if you want to learn more about the free energy principle, I would just refer out to other live streams.

It's best here to take what Bijan presents, the aspect that he's using and go forward from there.


SPEAKER_02:
Cool.

And I think similarly, we'll do a similar cursory treatment of Markov blankets.

And so Markov blankets, the way you can think about it is that it's a statistical formulation for defining the internal versus the external.

So the definition that he gives is Markov blankets establish a conditional independence between internal and external states that renders the inside open to the outside, but only in a conditional sense.

So the internal states only see the external states and

through the veil of the Markov blanket.

Again, huge topic.

I'm not going to go super into it.

And what's going to add anything blue?


SPEAKER_00:
No, it's great.

And there are many, many live streams.

Like really, if you want to get into it, probably the emperor's new Markov blankets is maybe where we undertake like a very thorough discussion of the Markov blanket.

If you want more information there.


UNKNOWN:
Cool.


SPEAKER_00:
All right.

So grounding firms in the framework of active inference.

So here's a claim from the book.

Learning to actively infer will determine the firm's competitive advantage and survival in a discontinuous and distributed world.

The more fluid the boundaries between firm and eco niche, the more important the definition of what constitutes a system

and how non-dissipative Markovian boundaries preserve the firm's integrity, i.e.

belief systems.

Our interest is shifting away from pursuing deterministic truth through clever analysis towards designing entailing a generative self-organizing model that empowers the firm to master the shifting conditional independencies between the known and unknown and what lies within and beyond its control.

Well, so there's a lot there.

So I think these next keyword slides hopefully will unpack it a little bit.

Active inference, which we've seen many times in the Active Inference Institute, is a process theory grounded in the free energy principle that explains behavior, perception, planning, and action in terms of probabilistic inference.

Bijan doesn't yet mention active inference, but he talks about learning to actively infer, which I'm going to actively infer means active inference.

And here we see this classic action perception loop where we have internal states and external states separated by a Markov blanket or a non-deceptive Markovian boundary.

And we have sensory input and action.

And these are the ways in which an agent can interact with its world.

Do either of you guys have anything to add here?

Daniel?


SPEAKER_01:
Sure.

Um, in that framing, I found it really interesting when there's increased fluidity or fuzziness or blurriness of the engagement of the firm with the niche or the context or the community.

In those cases, it's like more important to have a uncertainty oriented definition of what the thing is.

And that is what confronts every organization today.


SPEAKER_00:
Yeah, interesting.

Okay, so he talked a little bit about shifting away from deterministic truth.

And so I Googled, because I'm a truth person.

I'm weird about truth, if you've ever listened to me talk about it before.

So deterministic truth is like the truth.

And I liked this paper.

I just Googled it.

What do people talk about?

What is deterministic truth?

And I found this paper, Approaching Deterministic and Probabilistic Truth, a Unified Account.

And in this paper, it's a 2021 paper, so pretty new.

In this paper, they talked about the truth itself, like the truth being either deterministic, like I think about that like hitting a bullseye, like the truth is the number seven, right?

And then probabilistic truth is more like a probability distribution around that truth, like hitting seven plus or minus the standard deviation or like a probability density, right?

And this paper talks about like deterministic and probabilistic truths.

Like that the truth is one of those things.

And then also there are ways to approach it.

Like you're approaching your search of the truth in either a deterministic or probabilistic way.

So I thought that this was an interesting read and kind of, if you are interested in delving deeper into like deterministic versus probabilistic and these theories and approaches and truth likeness, I thought that this was a cool read.

Yeah.


SPEAKER_02:
Yeah, I think one thing, oh, sorry.

No, go ahead.

One thing to add there is just that I think like,

our personal ideas about what truth are, like whether it's terministic versus a probabilistic conception of truth, really carry over onto the organization level.

And so whatever kind of delusions you have about your personal truth in your personal life, a lot of times they view the organization as, like the CEO views the organization as an extension of their own self.

And so their own worldview gets carried over and strapped onto the organization's worldview.

And so it's really interesting that you could kind of


SPEAKER_03:
frame these like philosophical ideas about truth that are often applied at an individual level and then kind of like scale that up into an organization.


SPEAKER_04:
Yeah, very cool.


SPEAKER_00:
And we see that in this generative self-organizing model.

Again, this is kind of like it was cool to just search up what is a self-organizing model.

And we see generative model a lot.

We don't really see self-organizing model.

We see generative model in terms of self-organization, but a generative self-organizing model, like what is this really?

And so this is just from this Stanford

machine learning cheat sheet, supervised learning cheat sheet.

So here it says discriminative models divide the data space into classes by learning the boundaries.

And this is like the different neural networks, whereas generative models understand how the data is embedded into the space.

like an autoencoder or Boltzmann machine or self-organizing maps.

So this is like a self-organizing model.

And you can really see here, like this is like a decision boundary on the left in the discriminative model.

And like either it's a cat or a dog.

right and on the right it's there's a generative model like it's a cat with some degree of certainty or it's a dog with some degree of of certainty and so you see these like probability distributions like probably it's a cat but then there's like some fuzzy like if your data point lands like a little bit in the red or a little bit in the blue like then then it might be a cat or it might be a dog or maybe we don't have enough information to tell um so i thought that this was a cool like

replication of the probabilistic truth versus deterministic truth.

Like either you're looking for cat or dog, or you're looking for with what probability is this a cat or a dog?

Do you guys have anything to add here?

Cool.

Okay.

So this is moving on out of this claim into the next claim.

The firm is envisioned as an inactive, sophisticated and resource dependent inference machine.

in form of a generative learning model.

Essentially, it is a statistical model linking in circular causality, action, perception, firm resources, and the unknown external world.

And I just put this active inference loop up here again.

So you have like the firm and the world, the firm would be the agent, and then you have the resources of the firm, which would be like the internal states, and then the external world.

which is everything that's not the firm.

And I highlighted these terms inactive and sophisticated because there's a lot to unpack here.

And I think it's kind of in the textbook, maybe like just you can say the words, but unless you like open them up and look what they mean inside, look inside of them, like you don't have any idea the kind of depth that goes behind these things.

So do you guys have anything to add there on that?

OK, inactivism is a position in cognitive science that argues that cognition arises through a dynamic interaction between an acting organism and its environment.

And so these are the four Es of cognitive science or cognition.

And they're embodied, inactive, extended, and encultured.

So cognition is grounded in our senses and concrete experience that's embodied.

Enacted means it's goal-directed action in the real world.

Extended is cognitive systems include the tools, the devices, the people around us, our smartphone, these kinds of things.

And embedded, or that's kind of what we always refer to as encultured, but I think that they kind of mean the same thing.

So this is cognition is woven into culture and learning is done in a social context.

So these are the embodied.

So when you say the firm is inactive, yeah, that's it.

It's for goal-directed, it's doing goal-directed action in the real world, inactive.

and sophisticated, or do you guys have anything to add there on the four E's?

Okay.

Sophisticated is from this paper, I believe, Sophisticated Inference by Friston and colleagues, and we've done Sophisticated Affective Inference, I think, on a live stream, but I don't think we've ever done Sophisticated Inference, but the Affective Inference is...

like a later paper and covers this one a lot.

So sophisticated inference is really like in deep time, right?

So here, I'll just read this, the figure caption.

So I have this like decision tree model picture from the paper.

And it says, this schematic summarizes the accumulation of expected free energy over past

and trajectories into the future.

This can be construed as a deep tree search where the tree branches of allowable actions at each point in time and the likely outcomes consequent upon each action.

So this is one, two, three, four time steps here and going off.

So this is like a trajectory, the path of least action.

So we talk about the way that a system can decide and go forward in space.

So that's what's meant by sophisticated, I think.

Oh, Daniel.


SPEAKER_01:
Yeah, the purpose of introducing these terms from cognitive sciences and neuroscience like the 4E cognition and of this type of model, it's not a novel idea to make a decision tree.

That's how, for example, early chess playing artificial intelligences work.

It's the way that the expected free energy can be calculated across these different paths of consideration with respect to a generative model.

that are allowing new ways of thinking about these kinds of deep time and nested strategic questions.


SPEAKER_00:
Yeah, definitely.

Okay.

So temporal thickness and counterfactual depth.

Here in this claim, Bijan says, the proposal on offer here is that the mind comes into being when self-evidencing has a temporal thickness.

Models can be thicker and thinner, deeper or shallower, depending on how far forward they predict, or counterfactual depth.

How far back they post it, that is, whether they can capture how things might have ended up if they had acted differently.

There is no real reason for minds to exist.

They appear to do so simply because existence itself is the endpoint of a process of reasoning.

Consciousness, I'd contend, is nothing grander than inference about my future.

And in this, this is from Bajan's book, but he's quoting a Friston 2017 paper.

So that temporal thickness goes back to the sophistication, right?

Which is why, like, so here you can see how far back you can post it.

Like if I had done something differently, what could have happened?

This counterfactual reasoning and prediction going forward into the future.

Okay, going on to strategy governance models versus meta governance.

All right, so I'm kind of out of my comfort zone here, so I might call on Tyler to help me out a little bit.

But Bijan says, the common understanding underlying entrenched strategy governance models rather erroneously has been that action is a consequence of perception, and therefore, strategy must be environment-driven.

So I look up strategy governance model, and it gave me some figures.

And this is one of them.

And it appears to be...

pretty linear, but there's not a lot of feedback happening with the external environment.

Like there's a vision, a strategy, a roadmap, design, and then insights come forward to the design and back to the vision.

And then there's like a performance review.

So I don't know, Tyler, do you want to give any additional comments here on this?


SPEAKER_02:
Yeah, I mean, I think something that could be potentially confusing for people who are maybe not coming from an academic background is that a lot of times when business leaders are thinking about how they're going to plan for the action that their organization is going to take, what the strategy looks like, they're getting data, right?

And they're having feedback from the bottom levels of the organization, feedback to the top levels, right?

And so that they're taking information, they're creating a perception of that, and then they're creating a strategy based on that that

kind of in a linear fashion, the organization executes.

And at some point they reflect back and be like, Hey, did this work or not?

What do we do with our new information?

Right.

But really what they're not realizing in the process of that is like in that linear flow, they're not recognizing how they're constraining the perceptions and actions of their organization and a top-down fashion and allowing people

and allowing bottom of the information to change how information and actions can be changed in the future so like that kind of cyclical nature really is understood it's really more conceived in this linear way of like hey we're going to collect as much information as we can uh our information is going to be imperfect but we're going to get better over time um rather than like hey fundamentally

Our actions and perceptions are constrained by the actions we're taking right now.

So it's like just a different model for thinking, but it's a lot more linear and not doesn't have that cyclical causality baked into it.


SPEAKER_00:
Cool and I think about here like it seems like it's very like sequential like one after another after another after another whereas like the active inference kind of method like you have to sometimes act in order to perceive right like the if you want to know whether like the surface is rough or smooth you have to move over the surface with your finger to determine if it's rough or smooth so it's action and perception that are happening simultaneously and I think that that

That is the shift that Bijan is calling for, as he says.


SPEAKER_02:
Yeah, and I think just to add on that a little bit, I think a lot of times business leaders conceive of reality as independently existing out there, and it's just a limitation of their tools and resources to understand reality, rather than the nature of perception itself of being able to understand reality.

And so I think that's really...

the fundamental difference.

And a lot of times people don't realize that that's even like relevant at all.

And so that's why this is fun to talk about.


SPEAKER_00:
It's for sure.

Why, like, what is deterministic truth?

Like, where is that reality?

And it all kind of links together.

So Bijan goes on to say, in fact, action upon the firm's eco-niche akin to pointing the light torch in the dark determines perception.

Inference is inactive.

The generative model itself never encodes anything.

It just expresses the circular causality among all four states.

The generative model, hence, is a model of the firm's eco-niche.

If not, it is no good regulator, and consequently, the firm will rather sooner than later dissipate in the face of entropic forces.

And so I included here a different kind of strategy governance model that's like the lean startup model that's like a little bit more action and perception happening in companies

like a more simultaneous way.

I don't know if you want to add anything here, Tyler.


SPEAKER_02:
Yeah, I think a lot of the way we talk about like lean startup model of really, the lean startup model is basically like, you don't necessarily know what people want.

And also it's not that you're discovering what people want, it's that you're putting ideas out there and finding how people respond to them.

And so it's basically truth is something that you create.

You can create a new state of the world rather than like,

uncovering it so it's kind of like a method for uncovering something that's going to work and a lot of times it's kind of done how it's like very like fluffy and also just like experiential terms like hey this works we've done this we built this company this way but what's interesting about active inference is that can take that very like fluffy wispy framework and apply that into a more rigorous context

So yeah, a lot of these ideas that we're talking about now, they're not necessarily new, especially in the startup world, but there hasn't been great language for talking about it.


SPEAKER_04:
Cool.


SPEAKER_00:
All right, so here's another claim.

Therefore, the firm's true governance challenge is a matter of meta-governing its generative model as an enacted, sophisticated, and resource-dependent belief system

exercising the entire organization, quote, the body itself, in contours, we should now start seeing a model emerging that underwrites a form of autopoiesis, i.e.

self-organization.

Effectively, it is all about casting inference as optimization, mathematically by way of gradient descent, starting with two essential constituents.

First, a hyperprior, which is the firm's resistance to entropy in order to persist, and two, epistemic foraging and hypothesis testing.

i.e.

acting upon the eco-niche to generate belief-evidencing data.

Do you guys have any comments here?

Do you want to delve into this a little more?

Daniel?


SPEAKER_01:
yeah one interesting uh usage of a term there is that the firm's true governance challenge is meta governance and that's a term that is used differently or compatibly but with a different focus in metagov and so just to kind of flesh that out here meta governance

is being used in the sense of metacognition, like self-reflection, memory, anticipation, attention, planning, all of these individual level cognitive and metacognitive processes that we model in active inference.

Often meta gov in another sense is meant like social cognition, like relationships amongst organizations or amongst teams.

So like within a team, you have their own governance structure, then also there's teams of teams, and that's a meta governance structure with respect to the team.

And then that's very interesting because the two times that we've seen nested models, nested generative models in active inference are the metacognition models and then the ecosystem nested models.

So it really brings integrity between thinking about what happens like within and across groups.


SPEAKER_00:
Cool, thank you.

OK, so hyper prior.

In Bayesian statistics, a hyperparameter is a prior distribution on a hyperparameter.

That is, on a parameter of a prior distribution.

As with the term hyperparameter, the use of hyper is to distinguish it from a prior distribution of a parameter of the model for the underlying system.

So, like, the hyperparameters influence the prior here.

And like the hyper parameters here influence the parameters here.

And so it's backwards at least one step in time in this sophisticated format.

So there's, oh yeah, this is a better diagnosis or illustration.

The hyper prior goes to the prior, goes to the data.

So it's just in a previous time step in some way.

Anything to add here?

All right.

Epistemic foraging.

I pulled this from Active Inference and Learning, this quote.

It says, in Active Inference, behavior has explorative, epistemic, and exploitative pragmatic aspects that are sensitive to ambiguity and risk, respectively, where epistemic ambiguity-resolving behavior enables pragmatic reward-seeking behavior

and the subsequent emergence of habits.

And I just wanted to kind of point out here that active inference is kind of like, has been illustrated as like a balance, a way to balance exploration and exploitation.

and epistemic and pragmatic value.

And like in business, is this like knowledge and money?

Is that like epistemic and pragmatic value, like knowledge of your customers, your clients?

So it's just trying to think of like how this might translate to that.

Like money, pragmatic value is like more resources and like epistemic value is like more knowledge of your client base or of the future maybe, uncertainty reduction.

Yeah.


SPEAKER_02:
I mean, I could just give a concrete example of that because this is especially true in software engineering where that is actually framed in explicitly these terms in growth organizations.

So if you're on a growth team, you're like,

okay, we can either like turn up the dial on this thing that's working.

We're like, okay, like we know this flow is working.

This wizard, this checkout flow is working.

Let's make it like 10% faster would be an example of exploitation where like, we know that's going to work in some level where exploration could be something we have like really no idea.

This is like a shot in the dark.

Let's figure out the minimum amount of effort we can put out to uncover new territory.


SPEAKER_03:
And so like this exact trade-off is very much explicitly thought of in a lot of tech organizations.


SPEAKER_04:
Very cool.


SPEAKER_00:
Thank you.

Yeah, so epistemic foraging is like, you know, searching around, like, you know, for epistemic, seeking out epistemic value.

Okay, so moving on to the triplet structure of free energy governance.

Tyler, this is for you, I think.


SPEAKER_02:
So,

You know, John's frames, like really there's like a key question of free energy governance when you're thinking about your organization, how do you embody that in your personal organization?

And it's really about how you create and update your generative model so that the firm can survive.

And he presents this framework of thinking about it, and he calls it the triplet structure of free energy governance.

There is structure, cognition, and then capabilities.

So we'll go through each of these in turn.


SPEAKER_03:
All right, structure.

So, oh, sorry.

This is confusing me.


SPEAKER_04:
That header is wrong.

Just get to the next slide.

All right, structure.


SPEAKER_02:
So John writes that connectivity emerges in flow and language.

Bottom-up stimuli emanating from resource markets such as clients, technologies, suppliers, and others are only as relevant and meaningful to resource reconfiguration asset allocation as clearly as top-down predictions and prediction models articulated, communicated, and above all, programmed to process bottom-up incoming signals.

So like kind of touched on this earlier, but like a lot of times decision-making at organization is very linear.

where like you have the very top you're coming from the strategy and then like that's executed in turn at every rung of the hierarchy a lot of times like okrs if you've ever heard of this it's like a really good example of this it's like objective key results where like there's an objective that the top organization comes with and then like the minions the next run have their subs the subsequent parts of that tree and it kind of filters down to the rest of the organization

Um, where sometimes what's not as clearly articulated is about the interconnections between different parts of the hierarchy and how those different parts of the stack, uh, have to relate to each other.

So like a really good example of this is that, you know, this is very true in tech companies.

Tech companies collect a ton of data and none of that data is like ever processed in a meaningful way.

And so like a lot of times they'll say like, Oh, like we got, we're data driven company.

We collect all this information.

But in reality, a lot of the information is trapped at the bottom rungs of the organization.

It may not have the political ability or also even the technical ability to process that in a meaningful way and bubble that up through the organization.

And a lot of times, there's a huge gap in being able to actually process that information and bubble it up appropriately in a way that can actually crater the organization.

And so designing this in a really thoughtful way is...

much harder than it would seem.

And even if you call yourself a data-driven organization, there's a good chance you're not processing data in a way that can actually generate new top-down models later on.


SPEAKER_03:
So yeah, anything to add there, Daniel?

All right, let's go to the next one, cognition.


SPEAKER_02:
All right, so cognition embraces the environment as enacted through relations and interactions constructed in our brains.

Environment does not objectively, actor independently exist, but it's revealed by a firm's actions and perceptions that those firms, that those very actions generate.

In fact, the consequences of a firm's activity construct its eco niche.

And so we've already touched on some of the earlier slides, but a lot of times these firms conceive of external reality existing independently of their own actions and perceptions.

And then it's just up to them to get better tools and information to be able to understand that reality, understanding this fog of war that they're slowly uncovering.

but they actually do real insights.

Then also the actions that they're able to take.

So like to make this like a little bit more concrete, you can say like, I mean, if you're not, this very much applies in a real sense on like a website where like, if you're not collecting information on views on your page in a very basic level, it's really hard to like generate actual information out of that.

Right.

And so you have to basically make a decision of like, this is the information we want to gather.

This is what we care about.

And that's going to structure everything.

the insights you can glean in the future and what you can do with that information.

In a similar way, if you're not putting resources out for interacting with the world, like creating a new department that's maybe a little bit more exploratory, that's going to constrain the actions you can take in the future.

So all this is saying is that the reality doesn't exist independently of you.


SPEAKER_03:
It's something that you actively perceive through your actions and perceptions.

Daniel and Blue, want to add anything there?


SPEAKER_00:
Is it like actively perceive or actively create?


SPEAKER_02:
Sorry, actively create is a better way of saying it.


SPEAKER_00:
Well, or both.

I mean, I think like you have to be actively perceiving, but I don't know.

I think it's a rare treat when someone takes responsibility or even like a company takes responsibility for the reality that they're creating.

And like we see this, especially like in tech companies, like

I don't know, Facebook.

And I mean, like just like a lot of the technology has been life-changing and world-changing.

So like they're really actively creating reality.

Daniel?


SPEAKER_01:
Yeah, this is interesting about the revealing of the firm's generative model through its actions.

And we've talked about that fourfold partition with the internal, external states and then the sense and action blanket states.

So the firm has access to sense and internal states to some extent.

But the world or others have access to one's actions and or inference on their consequences in the niche.

And so it's a way to talk about what the entire action perception loop is with all of its different inward facing and outward facing dynamics.


SPEAKER_02:
Yeah, to add a little more here too, there's a lot of folk wisdom around this idea as well in startup culture.

And so I'm going to totally butcher it.

This is like a Steve Jobs quote.

I'm going to totally butcher it.

But it's something around the lines of if you had done a marketing survey of people before they made the iPod and asked them how they want to listen to music, they wouldn't have told you that they wanted an iPod.

They would have told you something else that was conditioned based on their previous experiences with products.

And so the idea is that you just put something out in the world.

It's a creative act.

And then you create something in the world and then the world responds to it.

And so there's like this big idea, especially in like tech culture around like reality is something that you will into existence rather than discover independently.


SPEAKER_00:
Yeah, it's interesting, too, to like think about, I mean, especially you think about Google Glass that came out like, I don't know, 10 years ago or something.

Now, probably not that long ago, but it's been a little while.

And I think like now there's like the re-release of like Google Glass or some kind of similar products.

Like the world just wasn't ready when the Google Glass version came out.

But like we'll be ready soon.

They've willed it into existence and it'll be that way soon.


SPEAKER_03:
All right, capabilities.

The last one is capabilities.


SPEAKER_02:
So the inferring firm is constantly optimizing belief propagation as well as updating beliefs sophistication.

That process of optimizing recognition densities is only as good as the firm's general world model.

So we are no longer just interested in the actions consequences per se, but how the actions consequences impact ulterior beliefs.

So

Another way of saying this is that the firm has to actively balance this exploiting versus exploring.

And I think there's a lot of, again, folk wisdom, especially in Silicon Valley culture, around this trade-off, whereas a lot of times we say, hey, failure is good, as long as you're learning and creating those insights.


SPEAKER_03:
And so, yeah, Blue, anything to add there?


SPEAKER_04:
No, good.

All right.


SPEAKER_00:
Okay, so realists and anti-realists in management science.

All right, so here's a claim from Bijan.

Management science is equally divided along not too dissimilar realist and anti-realist fault lines.

It is best captured by Carl Week, 1977, when he states that environment is located in the mind of the actor and is imposed by him on experience in order to make that experience more meaningful.

It seldom dawns on organizational theorists to look for environments inside the heads rather than outside of them.

Indeed, the rise of cognitive lens in strategy management and governance research has enriched our understanding around improving the design of strategy governance processes, but has largely remained constrained by the notion that environment is something objective out there waiting to be analyzed and adapted to.

And in this section, Bijan talks about blitz scaling and mentions some examples of this anti-realist claim.

So he says, Google, Uber, Airbnb, and Facebook are the product of a fundamentally anti-realist enactment of an interaction with,

the respective eco niches powered by unique and continuously evolving sets of capabilities, fostering action generated top-down bottom-up prediction error minimization to iteratively optimize the very generative models and implied recognition, posterior probabilities of beliefs about the actions consequences.

These companies redesign while they fly, which is in the words of Silicon Valley veteran, Reid Hoffman, equivalent to throwing yourself off a cliff and assembling your airplane on the way down.

Sullivan 2016.

In fact, we are more in control than we resist to believe.

Blitz scaling has been integral to the founding DNA of these super outperformers.

They listen to and sense what wants to emerge.

They are the enacting designers of their very eco-niche.

For these companies, strategy is rather a matter of ex-post-sense-making than ex-anti-long-term planning.

It is a matter of survival.

And I just thought that that was maybe a good example of this anti-realism, um,

thing that he was talking about here.


SPEAKER_02:
Do you guys have anything to add?

An idea that kind of arose as you were talking about this is that one interesting point about Google is that they're also kind of famous for trying really hard to do this but failing to create new products.

So they have created and killed hundreds of different new products that people genuinely truly loved even that were quite innovative.

And so it's kind of interesting of how you even think about

what is trying to emerge and whether that's best done in like a single monolithic organization versus in a more like decentralized distributed way.

So I don't know, this has been like a tension I've been kind of feeling throughout the book as well as kind of like, what is it that this entity is trying to exist or needs to exist?

Or is it something that is more distributed and decentralized is more appropriate in certain cases?


SPEAKER_00:
So having loved and lost several Google things in the past that have like, you know,

Yeah, Google or Google App Maker, like the low-code app development thing.

I mean, just like tons of things, right?

Having loved and lost.

I wonder if this is like epistemic exploration on the part of Google, really.

So if like you're, you know, I don't know.

I feel like people come in and like, I'm going to build this app.

And Google gives them a lot of freedom.

And they're like, go ahead, build the app or build the platform or build the thing and do the thing.

And they build it and it's great and people love it.

And then they move on and do something else.

And then nobody steps up to support them.

The love of this part or what what was this person's like child at Google right so as I feel like maybe that might be a lot of what's happening but but perhaps in this like creation and then unsupporting creation and unsupporting Google is continuously generating like epistemic knowledge right it's epistemic foraging.

of, and learning about the niche and what people like and what they will use, you know, like on the grand scheme.


SPEAKER_02:
Well, I think it's, I think that's true, but I'm not going to make this argument, but a lot of people have made the argument that what they should have been doing the whole time is exploiting.

Cause like their whole business is just ads and they're like, just like run that till you die.

Like, that's the only thing that matters.

Like your resources aren't well used here by like trying to do like all of these random things.

And so like, there is like a legitimate argument too, of like the limits to which you can explore maybe, but,

I don't know, that's probably out of scope for our discussion today, but Daniel?


SPEAKER_01:
Yeah, just one short note.

The entire discussion of epistemic and pragmatic value is motivated by the fact that they're unified in the free energy functions that are used to determine perception, cognition, and action in an integrated way.

So at the very least, conversation can be had about adaptive changes in these variables at different levels of the organization in a different, if not better way that's very integrated with how we think about the world internally.

and built upon neuroscience in that area as well as about thinking about the complex dynamics and the relational dynamics of the niche which for information doesn't exist until you're seeking it out and in feedback with it and in attention of your previous data in anticipation of future data all of these cognitive dynamics so the anti-realist take doesn't need to be

um someone who doesn't think like a real world exists or anything like that even though that's like too deep for this current discussion it's just a purely pragmatic approach to thinking about and modeling these kinds of scenarios


SPEAKER_00:
Very cool.

All right.

What else?

Ah, okay.

So here we are.

We got through the preface.

That was the preface.

And so getting into part one of the book, there's just a small quote, which I'll read.

It says, reframing the strategy governance conversation.

The evidence suggests that we are in the midst of an evolutionary punctuation.

We are witnessing a mass extinction in the corporate world in the early decades of the 21st century.

Since 2000, 52% of the Fortune 500 companies have either been acquired, merged, or have declared bankruptcy.

It is estimated that 40% of the companies in existence today will shutter their operations in the next 10 years.

Merely following the trends of change is not enough.

Just like organisms facing the great oxidation event, organizations need to reinvent the way they interact with the changing world.

And this is a quote from Digital Transformation, Survive and Thrive in an Era of Mass Extinction, 2019 by Siebel.

All right.

Chapter one, Thinking Born of Curiosity, Revolt, and Change.

All right.

Here's our abstract.

Tyler, I'm gonna let you read this one.


SPEAKER_04:
All right.


SPEAKER_02:
Environmental complexity and velocity have been dominant monitors in strategy and governance research.

The underlying structure of environmental change is becoming increasingly distributed and discontinuous.

The disintermediating nature of information technologies is challenging entrenched business models as well as the logics of organizing.

Centralized top-down strategy processes are rather anti-clocked unless dynamically and generatively intertwined in real time with bottom-up stimuli and data emanating from field operations in pursuit of prediction error minimization.

Neither established logics of organizing nor prevalent corporate governance models are a match for wholesale digital reinvention and continuous strategic renewal.


SPEAKER_00:
Nice.

And going on, he says...

In fact, akin to the AI evolution from a supervised to a deep learning logic, corporate governance is challenged to evolve from a supervised and rule-based best practices learning system to one of unsupervised unlearning, i.e.

self-organization.

To survive, the firm must be conceived as one cross-hierarchically integrated inference machine.

Organizing is generative prediction error minimization.

Strategy is redefined as top-down, bottom-up predictions processing.

The search for knowledge is not nourished by certainty.

It is nourished by a radical absence of certainty, thinking born of curiosity, revolt, and change.

And that's a quote from Rovelli 2021.

All right.


SPEAKER_03:
All right.

All right.


SPEAKER_02:
So one of the core premises of the abstract is saying, hey, the environmental complexity and velocity have been increasing over time, and that makes it more challenging for organizations to survive.

So what he says is environmental complexity and velocity have been dominant moderators in strategy and governance research.

Indeed, the rate of change has not only been accelerating, but the underlying structure of change has become increasingly distributed and discontinuous.

sense of urgency and heedful interrelating are critical to survival in a world that is now commonly perceived as uh full of surprises and so you know this is something just by being on like the inside of a lot of these organizations including corporations a lot of times it's perceived as hey there's it's a scary world out there we just need to get our information better to kind of understand what's actually happening so we don't have um any problems

But I think the problem is that, like, that world is changing so much faster than it had been before, where, like, this kind of relentless approach of, hey, we're just going to get more, we're going to gradually improve our processes to wash away this uncertainty that doesn't work as well anymore.

And I think this kind of former approach strategy is very much encapsulated by, like, Six Sigma design.

I don't know if you guys are familiar with that, but it's kind of like a manufacturing idea of, like, hey, we're just going to slowly and incrementally increase the precision of our

techniques and our processes, because these any inserts you have cascades across your whole supply chain and all of your other processes.

So we just need to figure everything out.

And so everything will be perfect, and we won't have any issues.

And that may be like somewhat of a illusion that you can tell yourself if things aren't changing that quickly.

And maybe they'll work for like some constrained amount of time.


SPEAKER_03:
But in the modern world, it's hard, really hard to have that illusion, you have to have a different mental model of the world.

All right, move on to the unless blue Daniel had anything.

No.

All right.


SPEAKER_02:
So the second piece of this is like, yes, the world is changing really quickly.

And that means that there's going to be more discontinuities.

And so he says our discontinuities are fundamentally a function of the cost of interacting with the outer world in form of generating and testing predictions.

And so when he says discontinuity, it's really about like this gap between perceiving the world and saying, okay,

how are we going to take action?

How are we going to update our generative model accordingly?

what he's saying is that, you know, as the world becomes more complex, changes much faster than ever before, there are more of these discontinuities, but also the discontinuities are larger.

There's just more information to integrate.

And so like on one level, you could say like, this is really terrifying, world's changing, what do we do?

But he also sounds this optimistic note of saying like, well, yes, the modern world creates more discontinuities, but it also creates more tools for navigating those discontinuities.

And so the first one he says is, well, you know,

is about disintermediation and decentralization.

So it's a lot easier to aggregate data and process that information and have backup plans in case plan A fails, you have plans B through Z instead.

The other aspect of this is AI.

And so it's a lot easier to process bigger and deeper sets of data.

And so he's trying to sound this optimistic note that, hey, not all is lost.


SPEAKER_03:
There is a way to navigate through this uncertainty.


SPEAKER_00:
I just have to say, I love this meme as someone, as someone who's like tried to like organize and restructure my life, probably, I don't know, 500,000 times at this point.

Like, it's like, do I just do the work or do I spend time like agonizing about how to like document and structure and like time plan my day into five minute blocks.

So like, like I invest so much time in like some method.

Right.

And then I'm just like, okay, well I methodized it.

And then I never used the method.

I just go back to doing the work.

So it's like,

It's like this weird, like all this time analyzing what it like, or dumping it into like moderating my efficiency is like wasting my efficiency.


SPEAKER_01:
To connect that to the earlier discussion about the two senses of meta, this time cost associated with strategy and with consequences in the real world, that time cost can be understood as a cognitive cost.

and something internal that's happening, metacognitive, how should I decide how to decide how to perceive this?

Some of those are variables and knobs you can understand and change.

Other ones are really subliminal.

And then also that time cost strategy nexus

of course, exists for organizations and teams and all of these nested and complex interactions.

So we want to use active inference as an integrative principle because it helps us connect what's happening on either side of the Markov blanket, which might be like a data set passed between two areas of a community or of an organization, understanding how the emission model and the reception model work together.


SPEAKER_02:
Yeah, to touch that a little more, is that like,

Yeah, I've been a product analyst at a couple of different startups.

And you actually see this in a real way where sometimes you can get an okay answer by just taking a super simple average of a couple different categories.

Or you could try to do something really clever and create an ML model or something over...

um to predict something and a lot of times just like it doesn't the predictive power you gain doesn't match the time cost of that and by the time you created this really sophisticated like publishable uh model the world has fundamentally changed so much that your model just like doesn't matter anymore uh and so like you're very like time bounded and like how you can even like use the information you gather and the results you you glean so for example if you even if you have like a

a checkout flow and you say, Oh yeah, like with this button, the checkout flow is 10% more effective than with this button.

Well, it could, it will very likely be the change in six months.

The context of that checkout flow has changed so much that it's actually just kind of meaningless information.

And so like the time boundedness of the information you collect and the perceptions you can form of that matter a lot.


SPEAKER_04:
All right, so the inference machine.


SPEAKER_02:
So to survive, the firm must become one cross-hierarchically integrated inference machine that continuously builds predictions, which are calling to be bottom-up challenge.

And so I think this very much aligns with what we talked about before, like agile methodology, this kind of lean start-up method of you build,

see if it worked.

You integrate those perceptions and learn from it.

Use that to ideate in something that is a creative act into the world, not necessarily something that is fully informed by data.

And then you build and act on it.

And he uses this quote a few times, both in the preface, I think he actually opens the book with this.

He says, this is a Carlo Revelli quote, the search for knowledge is not nourished by certainty, it is nourished by a radical absence of certainty, thinking born of curiosity, revolt, and change.

So this is actually very important because I've actually encountered this tension very often in a lot of organizations where

like a lot of organizations want to be data driven and they don't actually, another way to say this is this is the best product advice that was ever given.

And he, it was from a CEO of one of my last companies.

He said, there's two types of product work.

There's art and there's science.

And the science work is like, you're like, hey, like, we know this works, we know we can speed up this checkout flow, it might get like incrementally better, we kind of can just keep going down is like the exploit path.

But then there's art, which is really just like not informed by the data.

And a lot of times organizations have trouble with this, because it is truly a creative act.

And they're not comfortable taking that leap of faith.

And that's really what like you have to do to do anything meaningful.

and a lot of people are much more comfortable in the exploit path which is a lot easier to sell to your bosses it's a lot more comfortable and you have to really like like very consciously create a culture within your firm that like the explore path is like even okay and something that can be rewarded um all right anything that you guys want to add here before we on the next slide


SPEAKER_03:
All right.


SPEAKER_02:
So something that I found, something I found that was interesting with, you know, reading this preface and the first chapter was that like a lot of the themes are kind of emerging in a less technical frameworks and also kind of like, or more like pseudo spiritual ideas about business management.

And so this is like a quote that was from the paper or from the book.

It said that firms are called to open up all four channels of listening and

listen from what you know, what surprises you from the whole and what, and what you, and what you sense wants to emerge the emerging home.

Right.

And so if we kind of think about integrating information across different levels of the hierarchy, like the genre was talking about, like you can think about that from a more like rigorous academic perspective, but there's like a lot of other folks, especially that come over the last five years that are conceiving the organization in almost like a pseudo spiritual perspective.

lens where it's conceiving the organization not as like the extension of the CEO's ego, but really as like this entity that needs to be nurtured and cultivated and understood on its own terms.

One of the most famous books about this is called Reinventing Organizations.

And this is rewriting organizations introduced the idea of teal organizations.

These are like non-hierarchical heterogeneous organizations.

So in that book, he says, instead of trying to predict and control the future, members of the organization are invited to listen in and understand what the organization wants to become, what purpose it wants to serve.

Which like on first reading, like that can feel very like pseudo spiritual and kind of like hand wavy.

is actually like a very real thing that can actually be modeled in a more rigorous way with active inference.

So I think that's really exciting.

Another way that this has been talked about has been in Brian J. Robertson's book, Holacracy.

Holacracy is another similar to like tool organizations.

It is a non-hierarchical form of governance.


SPEAKER_03:
And so he says, each tension human beings sense is a signpost telling us how the organization could evolve to better express its purpose.


SPEAKER_04:
All right.

Anything you guys want to add there?


UNKNOWN:
Cool.


SPEAKER_00:
Cool.

So I don't know.

Anything else that you guys want to add?

Just thanks for being here and going over this stuff with me.

And is there anything else you're looking forward to?

Or what's next?


SPEAKER_01:
I'm really excited.

Just logistically, how is the series going to continue?


SPEAKER_00:
Sure.

So we'll finish one chapter a week is the goal.

Maybe like we're trying to still work out the logistics of the holiday, but I think it looks consistent.

So one chapter of the book per week, something about that, something like along those lines, and then a discussion after each like section of the book.

So there's part one, part two, part three.

And we will get in touch with the author and see maybe if he is willing to come and discuss some of these ideas with us or, and hopefully we'll have other questions.

people that want to participate in the discussions of the work.


SPEAKER_01:
Tyler, then I'll give a thought.


SPEAKER_02:
Yeah, I mean, I think the thing I'm looking forward to is, you know, so far what I've been excited about is that putting a concrete framework behind ideas that have so far been expressed in very abstract kind of hand-wavy terms across, you know, different kind of startup folklore and kind of business type, business-y books.

And so I'm curious as a next step about how it can become a little more like tangible and practical and like,

For someone who is from the perspective of being in an organization, how would you actually design an organization to embody free energy governance?

And so I'm really excited to see how that can become a little more concrete and clear.


SPEAKER_01:
Cool.

The part I'm looking forward to is continuing to explore that explore-exploit dialectic.

Both of those in the extreme...

lead to failure in some way, or at least increase risk.

And so this frames our strategizing as being like in some sort of landscape with explore and exploit, which of course is really complex with these nested organizations.

And then you brought in the art and science or science and engineering or just art and communication or whatever other dialectic.

And then even within an artist's day, there's realities like accounting and the mixing of the paint and even the prompt engineering for someone who's using those kinds of artistic forms.

So it lets there be sort of a light

and adaptive, quote, explore-exploit scenario happening within the context of something that's a lot more meaningful, which is the integration of like art, science, personal meaning, collective meaning, and so on, without denying that those kinds of explore-exploit, attentional and strategic dynamics must happen also.


SPEAKER_00:
Cool.

Well, thanks for participating, guys.

And we'll see you next time.


SPEAKER_04:
Bye, y'all.