start	end	speaker	sentiment	confidence	text
3600	4150	A	0.546256959438324	You.
7800	18710	B	0.7077708840370178	Hello, it's July 28, 2023, and we're in active inference textbook group Slash Bookstream 2.02.
19240	20832	B	0.9276800155639648	Thanks Ali, for joining.
20896	29710	B	0.9117200970649719	So what we're going to do today is give a short overview of the chapters from the par at all 2022 book.
30640	45548	B	0.8446685671806335	We're going to do chapters four, five, seven, and eight, and we're just going to pause between them because then we'll clip them into the shorter videos, append that to the playlist.
45724	52610	B	0.8999598622322083	Just so there's a first video overview of each of the chapters and this is the second in that work.
53400	58550	B	0.6683099269866943	All right, so we'll do chapter four.
59000	61750	B	0.857240617275238	We'll just wait a few seconds and then start chapter four.
66100	77120	B	0.49778664112091064	Okay, chapter four is called Degenerative Models of Active Inference, and it begins with a quotation, everything should be made as simple as possible, but not simpler by Albert Einstein.
77280	83290	B	0.9089686274528503	Ali, what is your overview, thought or warning for chapter four?
85340	110748	A	0.6148109436035156	Okay, so after the preliminary materials in chapters two and three, which was basically largely based on providing some conceptual framework for developing the further theory, chapter four delves into much more detail in terms of mathematical formulation.
110924	128020	A	0.7699069976806641	And it unpacks a lot more the way that the central equations of active inference is derived and how to construct the important elements of active inference models.
128600	139720	A	0.856343150138855	So say matrices A-B-C and D, and also how to put together generative models in different situations.
140140	161744	A	0.8893591165542603	So it basically lays out the foundation constructing active inference models both for discrete time situations and continuous time ones, which will be used later in chapters seven and eight.
161942	172100	A	0.8117560148239136	But this is probably one of the most challenging and at least mathematically dense chapters in the book.
172250	178816	A	0.5203217267990112	So I would personally suggest reading through this chapter really slowly.
179008	192860	A	0.7250087857246399	And even if we don't get to understand every single detail of the chapter, obviously we can return required as we go through the textbook.
194000	195336	B	0.8810703158378601	Thank you, Ali.
195528	196270	B	0.46103888750076294	Yes.
196640	198760	B	0.8456140160560608	So let's look through the sections.
198840	214512	B	0.7547868490219116	Just to add on, though, chapter four is one of the larger and more equation dense chapters because it is the common kernel or basis that's then going to get applied in chapter five.
214566	220068	B	0.9043914675712585	In the Neurobiological case, there's a recipe for making chapter four in chapter six.
220154	222720	B	0.8171608448028564	That's the recipe for active inference modeling.
222880	234276	B	0.9205425381660461	Chapter seven and eight are about the discrete and the continuous time variant or subtype or motif of these kinds of things called generative models.
234388	241210	B	0.8709723353385925	So this is the real common route and we'll just look at what the sections are.
242720	249020	B	0.6769379377365112	This chapter complements the preceding chapter's conceptual treatment of active inference with a more formal treatment.
249760	253630	B	0.8821115493774414	Section 4.2 from Bayesian inference to free energy.
254000	256860	B	0.9052360653877258	What would you say about this section, Ali?
258480	279140	A	0.8671756386756897	Okay, so as we know, the free energy principle is inspired by previous work on Bayesian inference, I mean all the way back to Helmholt's theory about unconscious inference or something to that effect.
279290	299660	A	0.7701635956764221	I can't remember the exact term, but here it provides in a bit more detail how we can derive free energy principle formalism using the established Bayesian inference formulation.
301120	332932	A	0.8625088930130005	And particularly one of the key movements or at least one of the key decisions through the derivation of free energy principle formulation is using Jane's inequality principle to derive an upper bound instead of just using the exact values to compute or to achieve the required parameters.
333076	363920	A	0.8285142183303833	So that's basically, in my opinion, the key premise of section 4.2 and to see in a bit more detail how we can achieve those upper bounds using Jane's inequality directly by using manipulations of Bayesian statistical formalism.
365620	366032	B	0.6283750534057617	Thanks.
366086	370060	B	0.8828299641609192	I'll just add one point from this section broadly.
370140	375868	B	0.539458155632019	These are the problems of inferring states of the world perception and inferring a course of action planning.
375964	385236	B	0.8831576704978943	So this is again referring to the perception and everything that happens in between is the internal or the cognitive part of the inference.
385268	389252	B	0.5014926791191101	But this is like the blanket state cybernetic input output.
389396	398940	B	0.9109768271446228	And then let's look at the first equation or how much equations overall or what equations do you think we should highlight?
402960	413840	A	0.8659055233001709	Okay, just as a general comment about these different equations.
414260	423680	A	0.8277612924575806	Well, each of these equations provide a distinct step toward deriving the ultimate whole picture.
423840	445864	A	0.6625972986221313	So even if we don't quite understand how we can derive from each step to the other one, it's good to know that it's only required to understand how we get to that ultimate whole picture.
445992	458364	A	0.8668407797813416	But ultimately what we would need in order to develop active inference models is the ultimate equation or ultimate whole picture.
458492	468144	A	0.7492175698280334	So this is just a way to elucidate the steps toward developing that whole picture.
468272	478870	A	0.741287887096405	But again, it's not an essential requirement to understand the materials of the rest of the book.
479320	504840	A	0.8684638738632202	But if we go from equations 4.1 toward the 4.4 or other words, a variational free energy, well, equation 4.1 is just a basic definition of some properties of probabilities in terms of conditional probability and so on.
504930	522560	A	0.9072373509407043	So equation 4.2 provides the central Jane's inequality principle and how it relates to conditional probabilities and of course joint probabilities.
522720	551580	A	0.8636600375175476	And then by using those two properties or those two equations, we ultimately get to 4.4, which is the definition of variation free energy parameter, which is the parameter of interest that needs to be optimized in order to inference to happen or at least perceptual inference to happen in active inference models.
553280	553740	B	0.6283750534057617	Thanks.
553810	560560	B	0.8711544275283813	Only thing I'll add is F is the letter used for variational free energy.
560710	576630	B	0.8288653492927551	Think of it like a computer program and the arguments that it takes in or the variables that it takes in are q, which is the distribution that's under the statistician's control and Y, which are the data which are outside of the statistician's control.
577080	584090	B	0.8577244877815247	And do you want to describe more about anything in this equation or carry on?
586060	605968	A	0.5658535361289978	Just one thing that can probably be helpful is to somehow compare these steps with the initial picture we had from chapter two because variation free energy was first introduced in chapter two.
606134	618310	A	0.5969728827476501	So it can be helpful to go back and forth between chapters two and four and try to connect the dots between the related points there.
624420	630720	B	0.8856172561645508	Section 4.3 generative Models all right, I'll read the first sentence, then you can give some thoughts.
631300	642180	B	0.8787422776222229	To calculate the free energy, we need three things data, a family of variational distributions and a generative model comprising a prior and a likelihood.
646280	654090	B	0.8548016548156738	In this section, we outlined two very general sorts of generative model used for active inference and the form the free energy takes in relation to each.
661430	671270	A	0.902995228767395	Okay, so as mentioned earlier, this chapter deals both with discrete time and continuous time situations.
671610	677260	A	0.8239457607269287	So clearly we would need two different types of generative models for each situation.
678190	693870	A	0.7665179371833801	And obviously the generative models or the way to construct generative models for discrete time situations would vary quite a bit from the one for continuous time situations.
695170	731114	A	0.820247232913971	But the general principle underlying those generative models are basically the same, which is to somehow construct a model of the environment, either be it for the situation that is sequential in time or for the situations that need to be somehow each moment of the situation needs to be accommodated in terms of a continuous time situation.
731232	737660	A	0.9141525030136108	So Figure 4.2 provides some examples of both.
741970	743120	A	0.6551274657249451	Let me see.
744450	757460	A	0.7163275480270386	Yes, so we have some examples of different kinds of generative models, some case studies if you like.
757830	771506	A	0.7255187630653381	And it provides various ways to show how the dependencies between variables can be modeled using these kinds of graphical probabilistic models.
771538	803330	A	0.8587365746498108	So one common way to represent generative models is to use these kinds of graphical probabilistic models in active inference literature, which is at least in this case, the circles would represent the random variables and the squares would represent the distributions, which would describe the dependencies between those random variables.
803830	822354	A	0.830307126045227	So we can see the clear relationships between those parameters here, which is basically what this whole graph, what constitutes the generative model that needs to be used for different situations.
822402	838694	A	0.8763089776039124	And then in Figure 4.3, we can compare the two different types of generative models based on whether it's discrete time or continuous time situations.
838822	852914	A	0.8824580311775208	So the upper picture is a generative model for the discrete time situation and the lower picture is the parallel continuous time version of it.
853112	861074	A	0.8027870059013367	And as we can see, the general topology of these models are the same.
861272	873990	A	0.6052197217941284	The only things that differ is the use of parameters for policies or I mean, discrete time policies or the continuous time ones.
874060	891040	A	0.8633754849433899	And we can obviously compare the different elements for both priors states and external states, internal states and so on by comparing these two models here.
892530	895758	B	0.861114501953125	Yeah, we often return to Figure 4.3.
895844	905682	B	0.8515705466270447	It's kind of the Rosetta Stone of generative modeling for the context of this book because it's then going to develop out into chapter seven and eight.
905816	914622	B	0.7091000080108643	And it represents a really fundamental decision made in modeling and in the later chapters.
914686	928890	B	0.7878665924072266	It's also shown how it can be made into a hierarchical model that combines aspects of both, but within each level of modeling still, these are the kinds of decisions that modelers are presented with when it comes to statistical modeling overall.
930430	938640	B	0.930658221244812	So Section 4.4 goes into essentially the top half of Figure 4.3 discrete time.
939810	941920	B	0.8839502334594727	What would you say about discrete time?
943570	955966	A	0.8286280632019043	Okay, so the discrete time situation is obviously the archetype discrete time situation, which is the Palm DP models.
956078	977834	A	0.812580406665802	So at this point I would very much like to recommend following the material from step by step paper, because in that paper, the way to construct Palm DP models is described in a bit more detail.
977952	991840	A	0.8032849431037903	So if anyone feels like they should learn a bit more about the gaps in the details, I would very much like to recommend that particular paper.
995730	1021270	A	0.6535919904708862	I don't know how much detail we should go into because although it's not maybe detailed enough for some tastes, but it goes in a quite extensive detail about how we can construct these models using the concepts we've learned in previous chapters.
1022010	1041120	A	0.8905863165855408	So ultimately we reach equations 4.13 and 4.14, which are basically the culmination of Palm DP formulation using the vector notations and gradients and so on.
1046130	1049120	A	0.7365954518318176	Then we go to continuous time situation.
1050550	1051300	B	0.7671424746513367	Great.
1053030	1068274	B	0.8610149621963501	A few things intervene in the continuous time chapter ones that we'll just mention here because they're kind of boxed or partitioned from the continuous time part, but they're following pages versus Markov blankets.
1068402	1074654	B	0.8980658054351807	We won't go into it here, but kind of footnote that or look at some other places where we talk about it outside of this chapter.
1074722	1079690	B	0.8944852352142334	Overview figure 4.4 Bayesian message passing.
1080110	1082410	B	0.7364699840545654	Again, a big topic.
1082750	1092430	B	0.8468753099441528	Let's kind of just go past it now back to the regularly scheduled continuous time generative model discussion.
1092850	1098110	B	0.8540791869163513	And then another box to the generalized coordinates of motion.
1098450	1102660	B	0.8889392614364624	So taking position plus derivatives of position.
1103190	1109730	B	0.8027761578559875	And that has some beneficial properties that are described and unpacked also elsewhere.
1112890	1115800	B	0.87782883644104	Do you want to say anything about 4.5.2?
1120570	1137590	A	0.583692729473114	Well, the only thing that comes to mind is although as I said before, all the formulations here may look more, I mean, a bit too dense to understand at the first pass.
1137760	1180140	A	0.7219284772872925	But some of the key maybe components here could be obviously the material from box 4.2 and 4.3 I think are quite essential to understand the underlying principle behind deriving the continuous time situation because without LaPlace approximation, what we would have in terms of free energy minimization is it would look very much like the Gibbs free energy.
1182670	1196762	A	0.86686110496521	The key distinction between the free energy principle as described in active inference literature, as opposed to Gibbs free energy is this distinction, is the LaPlace approximation.
1196826	1206690	A	0.6107893586158752	So this is what enables us to go from Gibbs free energy to the variation of free energy.
1206840	1216386	A	0.7030894756317139	So yeah, that's quite essential to make this to be familiar with this essential approximation.
1216578	1229020	A	0.8380473256111145	And obviously the concept of generalized coordinates of motion will come time and time again throughout the whole book, particularly in chapters eight and nine.
1229710	1237870	A	0.5745013356208801	So, yeah, those two concepts, I believe, needs a bit more attention.
1242450	1243838	B	0.9498600363731384	Yeah, sounds good.
1243924	1256078	B	0.8838371634483337	Box 4.3 LaPlace approximation equations, another message passing, representation, and a summary.
1256254	1264646	B	0.8401587009429932	The key message to take away is that approximate Bayesian inference may be framed as minimizing a quantity known as variational free energy.
1264828	1269970	B	0.8331480622291565	This depends on a generative model that expresses our belief about how data are generated.
1270130	1271800	B	0.8537741899490356	Anything else you want to add?
1275930	1291982	A	0.7666287422180176	Ah, nothing comes to mind at the moment because, as I said, we're still in the stage that we want to develop our essential tools to be used in the rest of the book.
1292036	1303838	A	0.6564756035804749	So here, up until now, I believe by the end of chapter four, we have acquired all the essential, necessary mathematical tools.
1304014	1321110	A	0.6253902912139893	And the next chapter, chapter five, kind of acts like an interlude, and I don't think it's the direct continuation of chapters one through four.
1321260	1331290	A	0.8586212992668152	So I believe the first part of the book, conceptually and mathematically, ends here.
1331440	1333580	A	0.5897592306137085	So, yeah, that's it.
1334590	1344750	B	0.8483458161354065	Yes, it's a little bit like the Pragmatic modeling part gets foreshadowed or explored in five now that we're all built up with four.
1344900	1363020	B	0.8136299848556519	All right, that's the end of the overview for 14.
1363700	1368080	B	0.8743802309036255	Chapter five is called Message Passing and Neurobiology.
1368760	1372070	B	0.9141360521316528	What is your overview thought on chapter five?
1374840	1379828	A	0.6043249368667603	Okay, I don't know.
1379834	1399870	A	0.6155025362968445	I have mixed feelings about this chapter because on one hand, you see, as far as I understand active inference, although it originated as, quote unquote, a unified theory of the brain, I don't think it's a neurobiological theory per se.
1400640	1443370	A	0.718070387840271	Of course, there can be some correlations between neurobiological components or concepts with active inference concepts, but it's not an essential premise of active inference theory to provide a comprehensive theory about how the neurobiology of human brain or other organisms brain behave at detailed and neuroanatomical anatomical level.
1443680	1457200	A	0.6276163458824158	But then again, it's nice to have these kinds of empirical correlations between the findings of neurobiology and the active inference theory.
1457540	1468080	A	0.6993415355682373	But I don't think it's one of active inference central assertions, at least to my understanding.
1469720	1470548	B	0.7286635637283325	Well said.
1470634	1472660	B	0.9199516773223877	Very interesting framing.
1473480	1491320	B	0.8343570828437805	Well, chapter five definitely takes a very specific system of interest approach by highlighting one of the most studied areas, also one of the most relevant areas, which is mammalian neuroscience.
1491740	1519510	B	0.9087178707122803	And the chapter is going to introduce a few different motifs in the nervous system and essentially build up towards figure 5.5, which is at the end of the chapter, and 5.5 wires together three specific neural systems that the chapter is going to focus on work in that area from.
1519960	1527476	B	0.6715272068977356	So Ali said it very well, active inference was built up to in chapter four.
1527658	1535528	B	0.8992215991020203	Here is another level or type of science with assertions or with representations or mappings to any specific system.
1535694	1559250	B	0.85763019323349	But this is the kind of modeling that has been built up and done by Friston Parr Pazulo and others over the decades, with a focus coming from a human neuroimaging laboratory setting a lot of focus and study and attention and funding and everything on the mammalian nervous system.
1561380	1573088	B	0.6068375706672668	But claims about the nervous system are not the basis of what active inference claims or how it's derived.
1573264	1583510	B	0.8919488787651062	But this is like an example case study in neurobiology connecting back to some of the formalisms that we've just seen introduced in chapter four.
1584440	1596812	A	0.8089023232460022	Yeah, and to add a minor point to what you just said, I think it's important to draw attention to the last sentence of the last paragraph of the first page.
1596946	1601596	A	0.8247882723808289	It is important to draw a distinction between a principle I, e.
1601618	1607920	A	0.8944427371025085	The minimization of free energy, and a process theory about how this principle may be implemented in a certain kind of system.
1608070	1618948	A	0.8932228684425354	So I think this sentence here frames this chapter in relation to all the other technical chapters of this book.
1619034	1643992	A	0.6558178067207336	So if every other chapter is about developing, or at least up to now, was about developing the principled formalism of active inference, now, chapter five provides a kind of preliminary sketch for the process theory of active inference, which is obviously far from an extensive theory.
1644056	1645640	A	0.7288811206817627	It's just a single chapter.
1645720	1661600	A	0.7563168406486511	But then again, it can provide some important signposts for anyone who wants to further investigate this area awesome free energy.
1661670	1671430	B	0.7018880248069763	Principle, Bayesian mechanics, all things in that area are, on this principle, not responsive to empirical data.
1672040	1675984	B	0.848063051700592	And then the process theory is about how the principle is implemented.
1676112	1688824	B	0.8375769853591919	So the specific generative models that are made and how well they map or how well they do in a portfolio of models that can have very different goals and assumptions and all of this.
1689022	1710320	B	0.8506448864936829	But the process theory implementation lets us develop hypotheses that are answerable to empirical data, like what is the kind of information or relationship between photons hitting the retina and changes in activity in neural systems?
1711220	1723520	B	0.6171568632125854	And that's an informational question or can be abstracted in a way to an informational question that, it turns out, does have empirical support and results in unique explanations and predictions.
1723680	1730550	B	0.5931712985038757	That doesn't mean that it always results in unique explanations and predictions, but a lot of citations are provided here.
1731580	1733850	B	0.6325761675834656	That's what we can explore in chapter five.
1736860	1747420	B	0.9189368486404419	The last paragraph of the first section describes that they're going to look at the three different neural systems.
1747760	1751580	B	0.8416576981544495	Okay, section 5.2, microcircuits and messages.
1755290	1756710	B	0.8850217461585999	What do you think, Ali?
1758030	1758860	A	0.4896698594093323	All right.
1761310	1777546	A	0.9114851355552673	This chapter begins from how message passing happens in neurobiological terms and compare it to the way active inference frames this message passing mechanism.
1777738	1809398	A	0.8266484141349792	And specifically, if we look at Figure 5.1 and compare this figure to the ones we've seen before in chapters one through four I think it was in chapter four, we can see some clear parallels between how this kind of cortical message passaging happens in the brain versus how it is framed in active inference literature.
1809494	1817478	A	0.780512809753418	And as we can see it's clearly inspired by the neurobiology of the brain.
1817654	1829230	A	0.8330547213554382	But then it's important to keep in mind that it's not a direct one to one mapping between these two models.
1830290	1854630	A	0.6096685528755188	This is just a kind of, I don't know, an interesting or illuminating, if you like, parallel to keep in mind to somehow be a bit more confident about the viability of the theory we want to use for message passing and active inference.
1855610	1862890	A	0.7988219261169434	Which is to say, it's not some haphazard theory that's just been developed for practical reasons.
1863230	1876490	A	0.8118047118186951	It has some basis in neurobiology, although it's not necessarily fully congruent with every detail of neurobiology.
1879390	1879850	B	0.7671424746513367	Great.
1879920	1890850	B	0.8646529912948608	The specific example is going to involve this one region of mammalian cortex tissue that has these six layers, and there's a ton of neurobiology.
1892630	1907750	B	0.5561335682868958	The big takeaway for Figure 5.1 is that it's possible to graphically lay out nodes and variables and find some empirical correspondences, again, some unique explanations and predictions in certain cases.
1908890	1925678	B	0.5916631817817688	And that's one kind of modeling where it's really trying to understand and improve the ability to do correlation and intervention and counterfactual causal type analysis with the real system of interest.
1925844	1940706	B	0.7531650066375732	Or in a more pedagogical setting or in a research setting or an industrial setting, you might sweep across large families of structures of models and there's no need to be grounded to any biological structure at all.
1940888	1951106	B	0.8846314549446106	So this is just describing the specific neuroanatomical research that really arose out of the imaging work at UCL and the SPM package.
1951218	1952920	B	0.6133910417556763	That's where a lot of this comes from.
1954250	1955334	B	0.596367597579956	5.2.
1955452	1956518	B	0.639731764793396	Yeah, go ahead.
1956684	1957110	A	0.5092127919197083	Sorry.
1957180	1972190	A	0.8354936838150024	Just as a side note, I think watching one of Thomas Parr's lectures on neurobiology of active inference, which is available on YouTube, would really help to understand the materials of this chapter better.
1972260	1975040	A	0.9492547512054443	So I highly recommend watching that one.
1975890	1976640	B	0.6283750534057617	Thanks.
1979170	1992820	B	0.9026150107383728	Figure 5.2 gives a rerendering of a kind of classical view of a hierarchical predictive coding system works.
1993750	2002178	B	0.883786141872406	So here abstracting a layer from the tissue six layer to just two layers.
2002274	2014294	B	0.8818649649620056	Here computational layers now and then showing how there's hierarchical communication within a layer, but also there's signaling within a layer.
2014342	2023834	B	0.8740308284759521	And there's a hierarchy in Bayesian modeling with variables that are higher order predictions about other variables.
2023962	2027790	B	0.8278951644897461	And that's the basis of the predictive coding architecture.
2028370	2055030	B	0.7303481698036194	So 5.2 looks at some ways that something that resonates with the cerebral cortical architecture enables what might computationally look like or have some really strong and explanatory values in actually relating to computationally a hierarchical Bayesian model which could do various general tasks.
2056330	2065900	B	0.8946563005447388	All right, 5.3 is motor commands leaving the prefrontal cortex, going down to the butterfly looking cross section here.
2066270	2068220	B	0.8488991260528564	What is 5.3?
2070510	2099750	A	0.8539865016937256	Okay, so 5.3 moves to the other half of active inference framework, which is how it can model the decision making and ultimately the movement of the agent in order to minimize the expected free energy as opposed to variational free energy that we saw in perceptual half of active inference.
2100090	2125790	A	0.8622022271156311	So it again provides a kind of correlation or analogy between the structural neuroanatomy particularly related to the motor commands and how it can relates to active inference, particularly the continuous time active inference.
2126210	2142878	A	0.7901851534843445	So we can see that for the external event or, I'm sorry, for the external state, we can take, for example, the proprioceptive afferent.
2143054	2167130	A	0.830387532711029	And then this proprioceptive afferent acts as a kind of y for the continuous time active inference which needs to be processed in a way to optimize the expected free energy and how it relates to both attention and precision.
2168670	2178190	A	0.92656010389328	We will see a bit more detail about those terms and the relation between them in chapter eight.
2178260	2193250	A	0.7061991691589355	But I think here Section 5.3 provides a good summary about the general paths through the motor command systems of neurobiology.
2194230	2194978	B	0.7671424746513367	Great.
2195144	2195890	B	0.7270170450210571	I'd say.
2195960	2212150	B	0.8869330883026123	While the previous case study focused on how the connectivity within and between the Cortical columns could have a computational relationship with a Bayesian hierarchical predictive coding architecture.
2212650	2241170	B	0.8943319916725159	The argument of the second case study is that a continuous input, continuous output kind of set point seeking, reflexive motor behavior with a moving set point with a descending moving set point enabling motion by changing ultimately the set point and enabling variation in the strategies to reach that set point through different mechanisms.
2242230	2250866	B	0.6945681571960449	This is also describable in a compatible way that's a shorter section.
2250978	2254870	B	0.8420521020889282	Now, section 5.4 subcortical structures.
2256810	2258790	B	0.8797345757484436	What would you say about this section?
2261070	2276286	A	0.6966186761856079	Okay, so subcortical structures are very important in the decision making and the planning of the agents.
2276388	2298626	A	0.8443023562431335	So obviously here we need another kind of analogy between the way that these plannings and decision making happen neuroanatomically with the way that it's framed in active inference.
2298738	2311130	A	0.6238365769386292	But again, we can see it's clearly based on at least some of the important elements we've seen from the previous chapters.
2311710	2321718	A	0.872738242149353	So for example, we saw how policy is described or how it relates to outcomes and preference and so on.
2321904	2328910	A	0.8710916042327881	We can see those elements are directly inspired by neuroanatomical structures.
2329250	2359374	A	0.5457888245582581	So I guess that's at least in my opinion, this section here 5.4 seems a bit more sketchy in the meaning that it doesn't go into quite the extensive details about how those structures can be compared.
2359442	2376320	A	0.7377492785453796	But for anyone who wants to further investigate these topics, there are some useful references put on here on pages 93 and 94.
2379650	2380062	B	0.6283750534057617	Thanks.
2380116	2390350	B	0.7846474647521973	Yeah, it's really abbreviated and overviewed but we get an interlude from Table 5.1 with putative roles of neurotransmitters.
2390430	2404182	B	0.8570609092712402	So same perspective that we took before on neuroanatomical functionalism here directly translates to neurotransmitters reductionism or essentialism or something like that.
2404236	2419260	B	0.6193960905075073	So certainly all neurotransmitters and molecules, they play variable roles in different settings and this is the neat and Scruffy manifold all over again.
2419870	2425454	B	0.8072584867477417	One person might say well, we need a theory for every acetylcholine molecule in the world.
2425572	2427354	B	0.7023439407348633	They're all in a unique context.
2427482	2431354	B	0.5868396162986755	And someone else says all neurotransmitters are described by one parameter.
2431402	2433326	B	0.5268990397453308	In this model I'm getting value from it.
2433348	2434960	B	0.7808387875556946	So to me, that's an account.
2435270	2455474	B	0.8378040790557861	And somewhere in between is the work in this space, which is making an attempt to have a principled and falsifiable approach to model the computational aspects of specific regions and contexts and settings.
2455602	2463820	B	0.8142120242118835	And so Acetylcholine, Noradrenaline, Dopamine, and Serotonin are given a little mini review here.
2464510	2467894	B	0.7418112754821777	And so it's not an exhaustive or an exclusive claim.
2467942	2478800	B	0.8777337670326233	It's kind of a provocation from computational and molecular neuroscience, and people can look into the papers and also ones that probably have been published since.
2480930	2487874	B	0.8731015920639038	5.6 goes to Continuous and Discrete Hierarchies, which is graphically overviewed in Figure 5.5.
2487912	2489620	B	0.8665773272514343	So what would you say about this?
2491750	2510030	A	0.913609504699707	Yeah, one interesting thing about this section is the observation that our lower level engagement with the environment can be most successfully characterized with continuous time formulations.
2510210	2542706	A	0.7731875777244568	But as we go up on the level of cognitive concepts or at the level of cognitive hierarchies and we come to concepts such as, I don't know, decisions or even beliefs and so on, we can reach the area that the discrete time situation would probably be more efficient to characterize the behavior of the agent.
2542888	2572382	A	0.603757917881012	So this multiscale structure of active inference modeling is quite evident in the way that our message passing happens in our brain in terms of our lower level data processing up into consolidating the higher level cognitive concepts and ontologies awesome.
2572516	2573440	B	0.8529649972915649	Thank you.
2575410	2582330	B	0.7935900688171387	To me, Figure 5.5 demonstrates the kind of whole of body approach that you could imagine.
2582410	2587670	B	0.5577778220176697	There's so many organs and systems and phenomena for which there aren't specific generative models.
2587690	2594434	B	0.5820542573928833	So little can be said about situations where no generative model has been articulated, and here's one where it has.
2594472	2597598	B	0.7675789594650269	So it gives you also it's kind of like reading a Drosophila.
2597614	2600734	B	0.8940903544425964	Melanogaster review paper relatively.
2600782	2605874	B	0.5167856216430664	It's like, this is how much work it takes to get to this state of knowledge in an insect.
2606002	2611350	B	0.6554831862449646	So then in another insect, do we know less about that insect empirically and genetically?
2611510	2623854	B	0.8073895573616028	So consider this to be what's known to be a lot, however, also about one of the most sophisticated or specific cognitive systems at least we know.
2623972	2636980	B	0.8016369342803955	So there's that additional kind of like, self reflexive aspect to this chapter that is not a cornerstone of active inference, but here it's just presented in a synthetic case study.
2638230	2640500	B	0.8728330135345459	Anything else you want to say about five?
2642870	2644900	A	0.680777907371521	Nothing particular comes to mind.
2645670	2646500	B	0.4896698594093323	All right.
2671000	2671748	B	0.584351658821106	Okay.
2671914	2675350	B	0.8992920517921448	Chapter seven is called Active Inference and Discrete Time.
2675880	2683560	B	0.9302054643630981	Chapter seven is the first in a pair of chapters with chapter eight on Discrete and Continuous Time.
2683630	2693964	B	0.9372973442077637	So they're kind of like two forks of a river that we discussed in chapter four and before and described the recipe in chapter six.
2694082	2713564	B	0.8884879946708679	Now, seven and eight are kind of like one level deeper, going from the kind of all of this group of animals to one level deeper into its classification scheme on the way to the specific generative model for which it's actually given in its totality.
2713692	2718984	B	0.8807096481323242	But everything prior to that is about the learning about its principles.
2719132	2724400	B	0.8958385586738586	And this is kind of on the trunk of the path to discrete time modeling.
2724480	2727392	B	0.876757800579071	Just like chapter eight will be about continuous time modeling.
2727536	2729590	B	0.829795777797699	What would you add in?
2732300	2749660	A	0.7328897714614868	Okay, so I think chapters seven and eight really helps to understand in a more practical way how the materials from particularly chapters one through five applies in real time situations.
2750160	2778820	A	0.7401735782623291	So even if we somehow didn't get to understand every details of chapters one through four, when we come to chapters seven and eight, I think some of those uncertainties about our understandings can be clarified, at least in a practical sense.
2778890	2788680	A	0.9552664160728455	So I believe these two chapters are really helpful in order to consolidate our understandings from the previous chapters.
2789740	2791210	B	0.9636558890342712	Awesome, well said.
2792060	2796620	B	0.8969277143478394	So it's going to involve specifying some discrete time models.
2798880	2828470	B	0.8690163493156433	7.2 goes into perceptual processing and the general structure of the chapter is going to walk through a series of examples that build in complexity where they first start with perception in 7.2, introduce decision making and then describe a few more types of motifs or cognitive structure or patterns and also check out step by step and model stream one where it's built up to in a different way.
2829160	2835000	B	0.8131363987922668	So the first example is I'll let you describe it since it's musical.
2836860	2837272	A	0.584351658821106	Okay.
2837326	2870176	A	0.7335650324821472	So yeah, the first example is the situation in which we try to describe the performance of an amateur musician in terms of how we listen to the performance of an amateur musicians in terms of the predictions we get from our anticipation of the following notes as opposed to the actual notes that's being played.
2870288	2934090	A	0.8411986827850342	So these kinds of anticipatory reaction listening reaction to the musician can be successfully formalized using discrete time active inference by putting up by putting together the matrices A for the states and matrix B for the transition between the states or the transition probabilities, which in this case describes the probability from going from one note to the other and obviously the actual sequence that's been played which can be described with the matrix d another point I wanted to mention is for anyone who has downloaded this chapter before I don't know, I think about June or something.
2934700	2947470	A	0.5520719885826111	I recommend redownloading it from MIT's website because they have corrected some of the typos that was previously present in this chapter, particularly in Figure 7.2.
2950560	2951020	B	0.84200119972229	Cool.
2951090	2960076	B	0.8843073844909668	So this graphical model where a person is listening, this is a general perceptual Bayesian framing.
2960188	2965500	B	0.7250807881355286	It's specified just like with any other equations.
2965580	2972470	B	0.8388185501098633	There's a lot to look into but A indicates the probability of an outcome given a state.
2973080	2982328	B	0.8938161730766296	This is saying if it were all on the diagonal like an identity matrix, this is kind of a common motif then states kind of map to themselves.
2982494	2999132	B	0.9089714288711548	So in the context of this model, a represents the mapping between the observed note and the underlying hidden true note and then B.
2999186	3002924	B	0.8447858095169067	Describes the transition matrix of how those change to time.
3002962	3005340	B	0.7716536521911621	D is the prior they're specified.
3008180	3011650	B	0.9019310474395752	Figure 7.2, do you want to describe it?
3015220	3048460	A	0.8814242482185364	All right, so in figure 7.2, or at least the incomplete version of Figure 7.2 we see here well, at the upper left part of the picture we see the beliefs about each note at each time step and at upper right we somehow translate those beliefs into specific numerical values.
3051040	3065628	A	0.7449749708175659	So instead of just assigning some continuous values, we've simplified the situation by assigning some discrete numerical values for each node.
3065804	3092520	A	0.5875726938247681	And then the lower left is supposed to show the free energy gradients over time or in other terms the prediction errors we get from comparing our predictions with the actual outcomes.
3092960	3106640	A	0.7953433394432068	So lastly, the lower right picture shows in parallel to the upper right picture, determines the values of these errors.
3107060	3131800	A	0.8904747366905212	So we can see both the initial or at least initial continuous assignment and values and then the further discretizing of the values in order to get the discrete time situation or the more tractable discrete time situations.
3133980	3143676	B	0.8714375495910645	Okay, so it's a general passive inference task where there's priors about how states are going to change through time and then there's real data coming in.
3143778	3159980	B	0.8295315504074097	So that's the kind of classical predictive coding video compression coleman filter Bayesian setting 7.3 introduces a key motif which is decision making and planning as inference.
3160140	3166032	B	0.8719158172607422	So this is the idea of having a Bayes graph where the variables can relate to different things.
3166086	3178896	B	0.7848660945892334	There's high composability and here the idea is that a variable is going to be proposed that we can do inference about that describes the process of decision making or policy selection.
3179008	3181530	B	0.9028080701828003	So what would you say about 7.3?
3184780	3193630	A	0.7958938479423523	Okay, so 7.3 is obviously similar to what we saw in chapter four.
3194080	3202300	A	0.8051517009735107	And if I'm not mistaken, even the topology is exactly the same with that picture we saw previously.
3204900	3227344	A	0.9070947170257568	This is the initial setup which acts also as a review about how these different components of palmdp generative models needs to be described in such situations.
3227472	3258624	A	0.8701611161231995	But ultimately the specific case study we come across in this section is the attempt to model the behavior of a mouse in a teammate of a rat and a teammate, especially teammates, containing an aversive stimulus in one arm and an attractive stimulus on the other.
3258822	3272660	A	0.8049585819244385	So this can act as a kind of toy example to use this kind of probabilistic modeling to describe these situations.
3275850	3276310	B	0.6283750534057617	Thanks.
3276380	3278870	B	0.8634017705917358	So that leads us right to figure 7.4.
3279020	3308320	B	0.8096593618392944	Here's a visualization of the situation with the rat in this case where there's a pleasant and aversive stimuli on each end of a decision point and there's also an epistemic opportunity to receive some information about the context that the animal is in.
3308710	3317954	B	0.8890992403030396	And so that setting is described for both the case with white on the left, black on the right and black on the left, white on the right.
3318152	3321842	B	0.8806708455085754	And those are shown in terms of their differences in the matrices.
3321906	3336730	B	0.895927906036377	The explicit specification of the generative model visualizations show some of the slices of the B variable which reflect different transition probabilities.
3337630	3352350	B	0.8792917728424072	C represents the preferences which are expressed over the observable states, d reflects the priors on the different states that need priors.
3353890	3357300	B	0.883283793926239	7.4, what would you say about this?
3359750	3400490	A	0.8699845671653748	Okay, so in 7.4, it builds up on the previous section and adds other elements that we previously saw in chapters two and four, which is how the exact formulation for expected free energy can be used sorry, variation free energy can be used to formulate the trade off between the information seeking, or at least between the epistemic value and information seeking.
3400570	3418450	A	0.854863166809082	So here it uses again that rad example in a bit more extended and elaborate form to formulate the epistemic value of observing a queue in a given location.
3419210	3425960	A	0.8656978011131287	And figure 7.7 is a representation of this situation.
3427530	3461522	A	0.659194827079773	But another situation that's been, let me see yeah, in 7.9, another case study discussed here is the situation of the psychotic eye movements because it is something that can be quite successfully described or characterized in terms of information seeking versus the epistemic value.
3461656	3466498	A	0.8078843951225281	And the situation here is let me see.
3466584	3467220	A	0.5491447448730469	Yeah.
3467750	3510450	A	0.6985388994216919	Shown visually in Figure 7.9, which clearly shows how our visual psychotic eye movement can be described in such a way as to kind of trace the trajectory of our eye movement among different regions of the visual space and how the information we gather from a given region can affect the subsequent trajectories of our psychotic eye movements.
3513190	3521400	A	0.7965365052223206	That's basically the main premise of this section, I guess.
3521850	3522310	B	0.7344964146614075	Nice.
3522380	3523000	B	0.7671424746513367	Great.
3524010	3528520	B	0.8838881850242615	7.5, what would you say about it?
3531870	3571542	A	0.551533579826355	Okay, so 7.5 again adds another dimension to the previous formulations, and this time, we get to update the generative models by learning and the so the generative models for this situation is a bit more complicated than the previous ones because it now needs to account for a mechanism or a way to update the matrices we had before.
3571676	3588886	A	0.47313934564590454	So in the previous situations we didn't account for learning per se, but here we directly update our general sorry, the word update can be confusing.
3588918	3601390	A	0.5309599041938782	Here we get to somehow improve our generative models to accommodate for these updating accounts.
3607330	3647630	A	0.8278165459632874	The situation here or the case study here, which somehow elucidate the way that the learning can be accounted for with these models is again a toy example of a creature in a simple world of black and white tiles which kind of tries to find a path to reach a given destination, a certain destination.
3648130	3664366	A	0.5015578269958496	So it is more complicated than the situation we had for the Rat example because it only had simple trajectories that needed to traverse.
3664398	3678854	A	0.6742703318595886	But here the creature, or the agent in this case needs to do lots more learning and information seeking and so on.
3678972	3694974	A	0.9172899127006531	So all the previous elements is kind of combined in this example and it's a really good example to see how the different components of active inference can be connected to each other.
3695172	3699630	B	0.6978298425674438	Nice and 76 hierarchical or deep inference.
3699970	3725080	B	0.8489654660224915	First, a box 7.3 interlude on structure learning, boxed off topic and a lot to say, but structure learning broadly refers to learning the structure about a model using the same types of methods that you might to do inference on, for example, a more observable sensor data reading, something like that.
3726730	3735850	B	0.8002059459686279	This section works towards the idea of nested inference or multiscale modeling.
3736190	3738700	B	0.91593337059021	What would you say about figure 712?
3742190	3755898	A	0.5906604528427124	Okay, so again, this situation is, I think, the most complex situations of this chapter, which builds up from the previous sections.
3756074	3769986	A	0.85448157787323	And this time it adds another layer to accommodate for the inferences that happen in different time steps.
3770098	3784022	A	0.8608006238937378	So in this case we have multi time or multiscale inference and learning happening both at the levels of learning and at the levels of information seeking.
3784166	3816820	A	0.8846563696861267	So this is represented in figure seven, point twelve, which represents how kind of this fractal generative model can be seen as a component in this multiscale bigger generative or as a kind of leaf in this bigger generative model.
3817350	3839980	A	0.8554686903953552	So it can be seen as a lower level inference happening at the leaf level, going up to the hierarchy and influencing sorry, collaborating on the whole process of learning and inference at the higher level.
3843070	3849134	A	0.7898396253585815	Yeah, I guess that somehow summarizes this figure.
3849252	3854320	A	0.9559033513069153	So if you have anything to add, that's great.
3854770	3860290	B	0.5620144009590149	It's an example of the composability of generative models.
3860710	3887066	B	0.878888726234436	What we've talked about and had Toby Sinclair Smith describe as as the compositional cognitive cartography and just what kinds of connectors can and can't you do and how can that motif that the discrete time model introduces and then the rest of these features, including action and learning and so on, get layered in on top?
3887248	3889260	B	0.7959252595901489	What can you do with that?
3890430	3893980	B	0.7517085671424866	713 gives another example.
3894450	3897920	B	0.8833735585212708	Do you want to say anything about it or maybe continue on?
3898530	3908782	A	0.8333085775375366	Yeah, so the case study here is the example of linguistic, I mean, language learning through reading.
3908846	3916830	A	0.5609838366508484	So not language learning, maybe just what happens sentence comprehension reading.
3916990	3918654	A	0.7161356210708618	Yeah, in comprehension.
3918702	3932074	A	0.8381972908973694	So what happens when reading in an anticipatory way the words that comes each after the other.
3932112	3961538	A	0.6574568748474121	So why this kind of situation can be most successfully characterized with this kind of modeling because it involves different scales of learning and comprehension, both at the level of at the level of somehow observing the letters and then going onto the words and then word groups and so on.
3961704	3991980	A	0.9296395182609558	So, yeah, that's really interesting way to again combine all of those elements into a single unified model to see how those different timescales, slow and fast timescales operate together to build this more encompassing model of more encompassing generative model of the situation.
3993550	3994022	B	0.7671424746513367	Great.
3994096	3995760	B	0.880761981010437	Any closing thoughts on seven?
4000610	4002800	A	0.7424761056900024	Nothing particular now, thanks.
4003730	4008980	B	0.7123365998268127	All right, next chapter is chapter eight, which is going to go into the continuous time.
4021560	4027810	B	0.5812106728553772	It's all right.
4027900	4031162	B	0.8890256881713867	Chapter eight is called active inference in continuous time.
4031296	4035738	B	0.6946020722389221	Begins with that timeless quote, everything flows, nothing stands still.
4035904	4038380	B	0.9176849722862244	So what would you say about chapter eight?
4039870	4055780	A	0.9725717306137085	All right, so this chapter probably is my most favorite chapter in the book because of my own personal interest in, I don't know, process materialism and so on.
4058230	4074962	A	0.8962493538856506	Chapter seven acts as a really good starting point for anyone who wants to develop the discrete time situations to model discrete time situations within active inference framework.
4075106	4089210	A	0.8182801008224487	But in chapter eight, we kind of get to model a bit more interesting or let's say more involving situations.
4089630	4099440	A	0.6990167498588562	And they're not necessarily kind of toy examples we saw at least at the beginning of chapter seven.
4099970	4107890	A	0.7994436621665955	So obviously, as the title suggests, this chapter deals with the continuous time situation.
4108040	4127160	A	0.8624985814094543	So in that case we'll need to maybe at this point refresh our memory about what continuous time situation involves by reading the relevant parts, reading or reviewing relevant parts of chapter four.
4129870	4164146	A	0.8906539082527161	In chapter four, we saw that the generative model for continuous time situation derives from the Edo's Stochastic calculus in terms of putting the whole process into two elements of Stochastic equations, one of which is the actual states, the condition of actual states or the behavior of the actual states.
4164248	4173250	A	0.7870064973831177	And the other one is the randomness that we need to account for in each real time continuous time situations.
4173330	4178778	A	0.8348879814147949	So that's what we get here in equation 8.1.
4178944	4201802	A	0.8724002242088318	And then building up from that equation, it generalizes that equation to involve the functionals of G and F instead of just the single valued functions of GNF.
4201866	4224310	A	0.8042888641357422	So then we get to put that into the situation that can be used for describing the behavior of dynamical systems, which is a very well known situation to use these kinds of Stochastic equations.
4224650	4239260	A	0.7506929636001587	And it's widely studied how those kinds of dynamics can be characterized, especially in recent Bayesian mechanics paper by Dalton Saktivetevel and others.
4241250	4272070	A	0.7009181976318359	And then it gets to some more specific examples such as Lotgobal Terra dynamics and synchronicity and so on, in order to show how these kinds of dynamics can be elaborated upon and can be generalized and enables them to characterize more complex situations.
4275930	4281398	A	0.6858965158462524	That's a really short and brief overview of the whole chapter.
4281494	4286220	A	0.8713969588279724	Maybe we can talk about a bit more details as we go through it.
4288110	4289306	B	0.9330628514289856	Great, well said.
4289408	4298714	B	0.7867292761802673	Well, I'm sure for another day the philosophical implications of eight, Seven and Eight and High Road and Low Road and all these other parts of the textbook.
4298762	4299790	B	0.9183654189109802	Great topics.
4300530	4301230	B	0.6408694982528687	I agree.
4301300	4319698	B	0.6872438788414001	I would see chapter eight as demonstrating continuity with some classical continuous time modeling motifs from a few different areas of dynamical systems science, which is applied in many, many fields.
4319714	4321298	B	0.5762810707092285	But these are some classic examples.
4321394	4344618	B	0.9270087480545044	So figure 8.1 goes a little bit more into depth or at least into more formalism detail about exactly what we saw in chapter five with the spinal reflex arc with the proprioceptive data coming in and then a differential being calculated with the set point which reflects a descending prediction from a decision making layer.
4344794	4364340	B	0.906048059463501	And that can be viewed as this kind of mechanics that plays out in a phase space in continuous time, like a spring moving around with someone making a certain path within a tractor and a spring being dragged around something in that area.
4365610	4369266	B	0.9497605562210083	Box 8.1 goes into a very fascinating topic.
4369298	4370760	B	0.8259787559509277	Do you want to describe it?
4373690	4383290	A	0.9643955826759338	Well, it's maybe one of the most thought provoking pages of the whole book.
4383360	4405940	A	0.5611158609390259	And if I remember correctly, in all of the cohorts, this particular box always gives rise to lots of questions because of some of the interesting and at least initially counterintuitive claims here.
4406630	4409860	A	0.4953426420688629	But I don't want to spoil it.
4412710	4447120	A	0.47085708379745483	But as a kind of spoiler alert, it kind of gets to really interesting, but alas, very brief discussion about the comparing these terms precision, attention and sensory attenuation and the relation and similarities and difference between these three terms and how understanding each of them is essential to understanding the other ones.
4447570	4471480	A	0.9591317176818848	But as I said, it's a really interesting topic which gives rise to lots of discussions and I believe it's one of those topics that's worth looking a bit more looking into in some other literature as well.
4472010	4472518	B	0.7671424746513367	Great.
4472604	4473318	B	0.7286635637283325	Well said.
4473404	4474790	B	0.7227254509925842	What a cliffhanger.
4475130	4480710	B	0.9192312955856323	Next they go to a classic model family called Lockable Terra.
4481230	4486310	B	0.8410657644271851	These dynamics inherit from characterizations of predator prey dynamics in ecology.
4486470	4491566	B	0.9181169867515564	So it's kind of a classical ecology model shown in Figure 8.2 on the top.
4491668	4502478	B	0.8876368999481201	It's actually the ecosystem model plants, herbivores and carnivores which follow different kinds of oscillatory trends in continuous time.
4502644	4509662	B	0.714631974697113	And so that also has enabled it to be applied for other so called winnerless competitions.
4509806	4528978	B	0.8381015062332153	And that relates to topics like neural Darwinism and also neural dynamics where things have kind of oscillatory relationships with each other which are being modeled as a continuous time underlying process with a lot of measurement, noise and discretization through space and time.
4529084	4537286	B	0.8478104472160339	Those are the kinds of algorithms that SPM explores more and there's lock of Voltera and a lot of other dynamical systems theory in SPM.
4537478	4548746	B	0.7700251936912537	So active inference kind of adds action and more to what was laid out from a pure dynamical systems theory in SPM.
4548938	4549390	A	0.571090042591095	Here.
4549460	4570150	B	0.8356258273124695	It really is just showing the ecology example and how you can project if you have three different species, you can think about that motion in a cube or tetrahedron, and then you could project onto kind of like looking at a lower dimensional manifold relating just two of the three species.
4570490	4582214	B	0.8896508812904358	And that evinces this kind of oscillatory but also moving behavior that gets connected in Figure 8.3 to neurobiology.
4582342	4583980	B	0.866743803024292	What would you say about this?
4586830	4596106	A	0.8127063512802124	Okay, so here in Figure 8.3 we see some applications of a lot of altera dynamics.
4596298	4611486	A	0.7803687453269958	So the left column here represents what happens in eye blink conditioning.
4611678	4631974	A	0.8627535700798035	So of course here we need to account for the expected states of the sequences of events that happens in the eye blinking.
4632022	4640700	A	0.8587251901626587	So the upper left figure shows the expectations in terms of time.
4641090	4659714	A	0.7540680766105652	And then the parallel right hand side equation, sorry, right hand side figures shows the Lotka volterra systems that is applied in the handwriting situation.
4659912	4688730	A	0.7853132486343384	So, as we can see, although the mathematical technology is the same, or at least the modeling technology is the same, the outcome of each situation varies drastically in two distinct two distinct neurobiological behavior, not neurobiological, but biological behavior.
4689070	4711234	A	0.8336275219917297	So, yeah, we can see how the same modeling framework can give rise to different outcomes based on what parameters needs to be optimized, what parameters are selected for the modeling, and so on.
4711432	4730410	A	0.9226444959640503	So I believe it's a quite interesting example to compare handwriting and a blinking together and how those can be compared to each other using the lotkobal thermodynamics great.
4730480	4731340	B	0.8529649972915649	Thank you.
4731710	4739686	B	0.9049356579780579	Box 8.2 gives a variant on the learning here presented with the formalism for continuous models.
4739718	4745546	B	0.8539328575134277	Kind of a technical aside, section 8.4 is about generalized synchrony.
4745658	4753334	B	0.9011668562889099	So figure 8.4 is going to visualize one of the classic dynamical systems, which is the Lorenz attractor.
4753402	4756722	B	0.9044834971427917	So what would you say about this figure?
4756856	4780198	A	0.9434974789619446	Okay, so this section is truly interesting because when one thinks of active inference, probably the first situations that comes to mind is the situations in which we have quite well defined probability distributions for different parameters.
4780374	4802142	A	0.5077291131019592	But as we can see here in Section 8.4, actually some of the formalism of active inference can be successfully used to characterize even chaotic systems, and in particular the way in which two chaotic systems can be synchronized with each other.
4802276	4819910	A	0.8487743735313416	So this is a classic example of chaotic Lorentz system and it draws upon from some of Professor Prison's earlier work on birdsong synchrony.
4820490	4833850	A	0.7952366471290588	And as a side note, any literature before 2016 is considered earlier history in active inference literature because it evolves quite rapidly.
4837870	4886458	A	0.8602794408798218	This kind of synchrony between two chaotic systems can be interpreted as providing evidence or even, let's say, a way to model a kind of primitive theory of mind, in the sense that how exactly can we understand or two agents can trace each other's trajectories without any I mean, engaging in any direct exchange of observations between their internal and external states.
4886544	4898830	A	0.9171632528305054	So, yeah, that's a really good example, and I believe one of the most interesting examples of how active inference can even account for these kinds of behavior.
4900770	4922950	A	0.8894706964492798	And the rest of the section goes into the details of how this kind of synchrony between multiscale Lorentz systems can happen and how can we formulate it mathematically in terms of continuous time active inference.
4924330	4925126	B	0.9184247851371765	Awesome.
4925308	4930646	B	0.8751410841941833	And there's been more recent work on Markov Blankets and Stochastic chaos.
4930758	4937606	B	0.8267847895622253	But the Bird example is a classic 8.5 goes into hybrid discrete and continuous models.
4937718	4943150	B	0.9158201813697815	So this could be kind of like an in between chapter of seven and eight.
4943220	4968178	B	0.7674567699432373	But now that we've been introduced to the pure form of discrete and the pure form of continuous models here shown that that composability extends to so called hybrid models where here the lower level visually is using the continuous time formalism and the higher level is describing a little line added here, the discrete time formalism.
4968354	4975318	B	0.9110837578773499	And this was the similar structure described by the authors of the paper.
4975404	4989622	B	0.8298559784889221	Active inference does not contradict folk psychology where they described this lower level as motor active inference which was closely allied with the spinal arc reflex shown above.
4989766	4997258	B	0.8729191422462463	And then this higher level they called decision active inference because in that case it was referring to a discrete decision.
4997434	5019910	B	0.8701785206794739	And so they used that kind of basic motif of continuous activity or continuous time modeling at the more peripheral aspects of a cognitive entity and like Ali said, more discretization and hybridization as well at higher levels of the cognitive modeling.
5021850	5051998	B	0.8609768748283386	And that type of an architecture here, instead of describing who wants the ice cream cone, I believe here it's going to be a mixed or a hybrid model that is going to call back the Icicade system where there's a fixed point that is able to be moved as a set point, and then there's a continuous time icicade that pursues the new fixed point.
5052164	5063906	B	0.9192568063735962	And so that's analogous to a new set point or fixed point being specified from the top down muscle command about a new location for a muscle followed by movement towards it.
5064008	5071362	B	0.7949365973472595	This is a muscular activity that is realizing that but not in the elbow coming away from the hot stove.
5071506	5081050	B	0.8494073152542114	This is about the eye circading to an epistemic foraging location specified by top down hierarchical systems.
5081950	5092406	B	0.8440700769424438	8.3 describes little technical aside on mixture of Gaussian gaussian mixture models, kind of a technical modeling note.
5092518	5098414	B	0.49242040514945984	And 8.6 closes it says it's a huge topic and much has been left out.
5098452	5102506	B	0.6317490339279175	And so they list in Table 8.1 key advances in continuous time models.
5102538	5119110	B	0.6811221837997437	And those areas are synthetic birdsong, ocular, motor delays, conditioned reflexes, smooth pursuit, eye movements, psychosis illusions, cicades action, observation attention, hybrid models and self organization.
5119930	5121686	B	0.7999820113182068	And that's chapter eight.
5121868	5123238	B	0.7788555026054382	What else would you say?
5123324	5129338	B	0.896453857421875	And also what would you kind of lead someone to in the philosophical implications of eight?
5129424	5131020	B	0.9438460469245911	Because it sounds kind of cool.
5134190	5163620	A	0.8704969882965088	Okay, well, the case of continuous time active inference, I think it leads to really interesting questions both in terms of philosophical questions and also more practical modeling questions about what parameters needs to be accounted for and so on.
5164390	5180150	A	0.7240979671478271	And as I said, I believe it's a more interesting way of it's not interesting, but at least more involved way of doing active inference modeling.
5180230	5217560	A	0.865868091583252	But one thing that one of the philosophical questions that Mahault and I have explored in our paper is how the processes, ontological processes can philosophically described using FEP assertions in terms of their intraaction with the environment in which they co constitute themselves.
5217930	5226358	A	0.7036983370780945	And we don't necessarily distinguish between the internal and the external states.
5226444	5248730	A	0.729523241519928	So one obvious example of this is that generalized synchrony example that we saw in this chapter in which we don't necessarily distinguish between which of the birds act as the agent and which one is the environment or the vice versa.
5248890	5271574	A	0.6944376230239868	So these kind of co constitution of the environment and the agent which gives rise to the partitioning of state space through markup blanket is one of the interesting philosophical points that I think needs to be elaborated a bit.
5271612	5288022	A	0.7150660753250122	More using some of the recent advances in philosophy, such as the tools that's been developed in New Materialism School or some other philosophical approaches.
5288086	5294442	A	0.7623606324195862	But yeah, these kinds of what exactly gives rise to emergence?
5294506	5306002	A	0.7572546005249023	What is the ontological status of emergent properties and so on, are some of the burning questions for many philosophers today.
5306136	5336122	A	0.6849768161773682	And I believe active inference, and particularly continuous time active inference, provides a clear, precise mathematical formalism, even if not to answer these questions, but at least to explore it in a more rigorous and practical way, and also practical and attractable way.
5336256	5355060	A	0.9032255411148071	So this is the area that I believe philosophy and science are beautifully intertwined into a coherent view of not only the phenomena of interest, but even about the whole world.
5357430	5358180	B	0.7093686461448669	Wow.
5361350	5362274	A	0.9739540815353394	Pretty cool.
5362392	5362674	B	0.5491447448730469	Yeah.
5362712	5365250	B	0.8248088359832764	A lot to say about that topic.
5366330	5376946	B	0.9047585129737854	After completing chapters seven and eight, you've seen the kind of two major branches or two major motifs of just one kind of modeling.
5376978	5388490	B	0.8382979035377502	But these kind of models have so many different forms that that's why it's such a hands on process to specify the generative model in chapter six and fit it with data in chapter nine.
5388640	5390054	B	0.7350940704345703	Those are all what's required.
5390102	5397280	B	0.7669288516044617	And that's kind of the last mile of where these discussions about general motifs gets you.
5397650	5419300	B	0.7408531308174133	But also playing with these pedagogical models can be really helpful because it will help you understand the basic patterns and relationships and start to see different patterns in the graphical models and know from there what levels of technical processes can be kind of coarse grained over.
5420950	5421860	B	0.4896698594093323	All right.
5427140	5427648	B	0.584351658821106	Okay.
5427734	5429440	B	0.5885887145996094	Well, that's it.
5429590	5436170	B	0.870998740196228	I guess next time we will do probably 910 and maybe something else.
5438060	5439752	B	0.7251645922660828	All right, I'll end it now.
5439806	5440840	B	0.7680783271789551	Thanks, Ali.
5441260	5442330	A	0.8529649972915649	Thank you.
5443500	5443780	A	0.5137447118759155	Bye.
