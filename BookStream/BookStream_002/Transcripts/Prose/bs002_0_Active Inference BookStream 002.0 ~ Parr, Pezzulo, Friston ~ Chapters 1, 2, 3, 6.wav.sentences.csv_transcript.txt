
00:05 Daniel:
All right. Hello and welcome everyone. This is ActInf BookStream number 002 dot 0. We are going to be discussing the textbook “Active Inference: The Free Energy Principle in Mind, Brain and Behavior,”
2022 a textbook by Thomas Parr, Giovanni Pezzulo, and Karl Friston. In this Livestream with Ali and I, we're going to be giving some overviews and some kind of points that you'll want to have in mind, little bit of background and context. Specifically on chapters one, two, three and six, we're going to do more live streams in the future that will cover the other chapters. There's ten chapters overall, and the goal of this live stream is to use the live stream format to produce materials that we can then clip out so that the textbook groups, which we have multiple ongoing cohorts at the institute so that those textbook groups can be really engaging and discussion oriented.
01:11 Because after several cohorts of going through this, ali and I and others have started to kind of hone our understanding of the textbook.
And so we are starting to feel ready to put down some background and context zero videos. And then ideally, people who are participating in the textbook group cohorts will be able to view and think about those videos leading up to a discussion so that when we do have the discussions in the textbook group, that those can be maximally interactive and engaging. So before we jump into chapter one, Ali, do you want to just add anything about the textbook or anything else?

01:53 Ali:
Hello. I'm Ali.
I'm very happy and excited to be here to discuss the book that we've fallen in love for the last year. And despite the fact that we've been studying and discussing this book for more than a year, there's still a lot to learn and unpack. So yeah, great.

02:15 Daniel:
All right, so then we will begin in just a few seconds the chapter one and overview.
All right, this section is going to be the chapter one and overview of the active inference textbook. So shown here are the table of contents. There are ten chapters and three appendices in this book, and they're separated into part one with chapters one through five. Andy Clark, two, chapters six through ten. Ollie, do you want to give any overview thoughts on the organization or structure of the book?

02:55 Ali:
Okay.
Can you hear me now?

03:00 Daniel:
Sorry. Yes.

03:01 Ali:
Okay, so part one is basically more line in terms of the theoretical construction of the active inference, and it provides some conceptual and theoretical tools to be utilized in the second part, because for the second part, we mostly deal with the practical side of active inference, how to actually implement active inference to model some of the systems of interest. So that's basically the main justification behind dividing up these chapters into two.

03:45 Daniel:
Great. All right, we're going to pass over the short preface written by Karl Friston, but it's worth a read. It's only several pages long, so let's go to chapter one overview. So do you have any opening thoughts on chapter one or where does one even begin with such a book?

04:06 Ali:
Sure, yeah. For chapter one, I think probably the most central theme of chapter one is about the two different approaches to active inference, namely the high road and the low road. And I think it provides a really nice perspective to view kind of the whole picture and how the different components of active inference fit together. But also I highly recommend chapter 13 from this book, andy Clark and andy Clark and his critics, written by chapter 13, I think is entitled beyond the Desert Landscape, written by Karl Friston in which he provides more elaborate and a bit philosophical reasoning behind what exactly are low road and high road and what are the aims of each approach and the distinction between those two?
05:14 So for chapter one we begin obviously with an introductory paragraph which sets the stage for all the components that would be discussed in this chapter.
But a very important section I believe is section two here which is how do living organisms persist and act adaptively? Which is basically the main question active inference is trying to address. So if we want to describe active inference minimalistically with only one sentence or two, probably we can say something to the effect that it's a theory that address this very question here. So I why they've opened up this chapter with important question and then section three, which is again a continuation of section one but a bit more specifically about active inference and how active inference is addressing the question provided in the section two.
06:39 So basically again, ActInf inference is a modeling framework for modeling the behaviors from first principles and what is meant by first principles will be elaborated upon in the following chapters, following sections and also obviously in the following chapters.
But very briefly, it's a kind of modeling framework that tries to somehow use variational principles such as free free energy principle, construct modeling and mathematical tools that would enable us to describe dynamical systems of living and even nonliving agents in terms of those variational principles and how those agents or those systems are coupled with their environment.
07:48 So that's basically the unificatory principle that is at the heart of this active inference approach because yes, exactly here it's a kind of description of this action perception loop that is at the heart of active inference or FEP framework. And then we go to chapter sorry, section 1.4 which is again a description of the structure of the book and why those two parts are divided as such. So as I said earlier, first part is more concerned with the theoretical underpinnings of active inference and the second part is more about the practical side of it as we see in these subsection headings here.
08:52 And then a very important diagram which will provide very helpful as we whole book is provided in Figure 1.2 which kind of ties all the different strands of various related theories such as predictive coding, predictive processing, Bayesian brain hypothesis and so on into a kind of unified and integrated framework by using those two trajectories of constructing active inference, namely the high road and the low road. So it literally here is represented as the high road and the low road in this diagram. So, very briefly, high road is a kind of top down approach to active inference.
09:52 It begins with the question how things should act if they exist, if they persist through time. Sorry.
In other words, it kind of sets the stage for developing the concept of markup blankets. And then obviously by setting that also surprise minimization, it attempts to elaborate that road by adding other aspects of modeling other aspects of theory such as predictive processing, self evidencing, autopoiesis and so on and then reach an integrated version of active inference which is basically an integration between perception and action.
10:53 So I believe the main thing that sets active inference apart from all the other related theories such as predictive processing and predictive coding is the very deep integration of action and perception. So action is not just some afterthought or some additional component that needs to be accounted for. It is deeply woven into the fabric of the theory.
So, as we'll see especially in chapters two and three, even the mathematical formalism for perception and action are interestingly similar to each other and even symmetric. And it shows that perception and ActInf are actually not separate and distinct, totally distinct entities and concepts.
11:54 And active inference definitely provides a very promising framework to integrate them into a holistic framework. And another approach to construct that same theory is to begin with the probabilistic description of Bayes theorem and try to build up the formalism of active inference using theorem and Bayesian statistical inference. So again, we here see some very apparently different and distinct strands such as predictive coding, Bayesian brain hypothesis and so on.
But as we see, all of those different strands can be united and tied together within this low road approach to ActInf inference.

13:05 Daniel:
I'll just give one short thought.
Yeah, just one short thought. Thank you Ollie, for these great summaries. The low road and the high road are going to be explored in a lot more detail in the coming chapters two and three. We can think of the high road as being a why because it describes how persistent or remeasurable systems exist. Now, they might be using base theorem or they might be using any other kind of mechanism internally.
But the high road is describing the why of existence from the low road. The bottom up approach is kind of like a how you could use base theorem to describe persistent autopoietic entities, or you could use base theorem for other purposes too. So where these two roads intersect is active inference, and we have a lot more discussion coming and of course unpacked in the textbook groups about how these really map on to bottom up and top down causation and the plurality of whys that we approach in different settings.
14:10 Good to continue?

14:14 Ali:
Yes, sure.

14:17 Daniel:
Some of the coming sections of this chapter, continuing from page eight, are going to describe what are happening in the next chapters. So chapter two is going to set out the low road perspective. Chapter three is going to describe the high road. Chapter four we will unpack active inference more formally.
That's one of the math heavy chapters. Chapter five will move from formal treatments to biological implications of active inference with a special focus on mammalian neurophysiology. Chapter five sets out the process theory associated with active inference and gives a lot of hands on and empirical examples. And that's a lot of the first part of the book. They're then going to summarize some of the key points and distillations from that theory heavy first section.
One of them is that, as Ali mentioned, perception and action are complementary processes and ways that fulfill the same imperative free energy minimization.
15:22 We sometimes summarize that by saying that in the pursuit of the minimization of free energy, agents can either change their mind or change the world. Change your mind is associated with perception and learning and those are distinguished later and changing the world is associated with action. There's some discussion about action selection and optimal policy selection and all cognitive operations in active inference are conceptualized as inference over generative models. So the true kernel, the cognitive kernel of active inference is going to be the generative model.
Want to pick up from here or give any thoughts on generative models and then carry on? Thanks Ollie.

16:12 Ali:
Just one point is there is a common misconception about generative models, which is that generative models only refers to the inner states of the system and also its markup blanket. But actually generative model kind of encompass all the states of interest of the situation we're trying to model. So it also encodes the probabilistic information about the external states as well. So generative model can be thought of as kind of the whole state of the system and by system here I dean the coupled dynamics between the internal and external states. So that might be helpful to keep in mind.

17:09 Daniel:
Great. One other distinction that comes up and is used a lot nowadays, although it's not always used in prior literature, is the distinction between the generative model and the generative process. We're going to come back to it, but usually the generative model is being used to describe our statistical model of the agent of interest. And the generative process is the process that generates observations that are then passed to the generative model as observations. However, because generative models can be generative processes for each other, these two are not necessarily distinct in principle.
So in different simulations and in different specific cases, generative models can also be generative processes for each other. That leads us towards talking about ecosystems of shared intelligence and interactions amongst generative models. But when we're talking about generative model, it's like the organism or the system of interest that we're focused on.
18:12 There are some more themes that arise from the first half of the book. Now we're on page eleven action is quintessentially, goal directed and purpose of we talk a lot about how preference plays a role in shaping action prediction in active inference. And the goal directed nature of active inference will be unpacked. In chapters two and three, they discuss how various constructs of active inference have plausible biological analogues in the brain. Once one has defined a specific generative model for a problem at hand, one can move from active inference as a normative theory to active inference as a process theory which makes specific empirical predictions.
And there's many, many interesting philosophy of science type discussions that we have about explain predict, design control. And then we get to section 1.4.2, giving overview on part two, active inference in practice. So I'll just continue on.
19:14 Chapter six is going to introduce a recipe for building active inference ModelStream. So this is where the step by step comes into play.
It's going to give a sequence of steps and approaches that you can take to go from understanding the structural aspects of a system or phenomena of interest and build your way towards having an active inference model that can then be implemented in code. And we have various examples and we're there in the textbook group to work with everyone who wants to take this journey. But chapter six is going to describe that process of building the active inference generative model. So that's a recipe chapter and there's a lot more that goes into the restaurant also as we kind of have fun exploring. Chapters seven and eight are like a pair and they describe two different broad families of generative models.
Now these two families of generative models, they work well, they play well with each other, but they are very educationally relevant to also consider separately.
20:21 Chapter seven is going to focus on the discrete time generative model and chapter eight is going to focus on the continuous time generative models. And again, these discrete and continuous time models can be nested and interoperable. However, they do describe some very important different situations. And so chapter seven and eight have a lot of technical information on the discrete and continuous time formulations of active inference and also about how they integrate together.
Chapter nine is illustrations of how active inference models can be used to analyze data from behavioral experiments. And so this kind of goes beyond chapter six's recipe and it talks about some of the process of making a behavioral experiment and then using the outcomes of that behavioral experiment, the data from that experiment and using that to parameterize and do statistics with the active inference generative model, and chapter ten brings it all together.
21:22 Chapter ten is a lot like chapter one, and we've even joked of reading the book backwards. That's how great chapter ten is. So for those who are reading chapter one, consider reading chapter ten next and then picking back up with chapter two because chapter ten is going to give some judgments and also sketch some exciting future directions for where active inference is in relationship to other fields and where it's going.

21:50 Ali:
I also second that.

21:52 Daniel:
Yeah, the second part of the book illustrates a broad variety of models of biological and cognitive phenomena. So it's an application oriented second half of the book, and we have a lot of accessory code and approaches and notebooks, so 1 may not find that this is the one stop shop that they were looking for. However, for those who dive in, there's absolutely more than enough to scaffold their learning journey. And then section 1.5 is the summary.
The chapter introduces the active inference approach to explain biological problems from a normative perspective and previews some implications of this perspective that will be unpacked in later chapters. It describes the structural outline of the book, chapters one through five being theory, chapters six through ten being practice. And then it signals that the next two chapters are going to develop the low and the high road perspectives. And altogether, that is chapter one. Any other thoughts on chapter one?

22:56 Ali:
Not as specifically, but I think it provides a really good context to the rest of the book in terms of how all the different elements of active inference comes into play in addressing different problems. Different problems.

23:14 Daniel:
Awesome.
On to chapter two, the low road to active inference. So all chapters begin with a short quotation, and the quotation here reads, my thinking is first and last and always for the sake of my doing. William James so even before reading the chapter, these quotations are often great places to jump off and have a discussion. So Ollie, please begin and go as long as you want on the low road to active inference.

23:47 Ali:
Okay, I guess chapter two, as the title suggests, it's the construction of active inference theory from the viewpoint of the low road active inference. So it begins by providing this notion of perception as inference, because more often than not, we usually think of perception as something just in a computational sense of sense is processing of the inputs, or rather it's a raw processing of the inputs. But here it shows that it can also be described as, or even more accurately described as a kind of inference. So it's not just a simple and raw processing of the inputs, as my computational model or a computer analogy might suggest.
24:51 It's more like something that we predict and then we compare our inputs or the inputs we get from the stimuli with our prediction and then try to somehow minimize that prediction error.
So I believe that this notion of perception as inference is the most central notion of all the related theories of predictive coding, predictive processing, Bayesian brain hypothesis. So up to now, active inference is not very different from all the other theories. It's basically a subset or a variant of those theories, but then it progresses into distinguishing the active inference from all the other theories and how it stands apart from the other ones.
26:02 So in section 2.1, we began with some of the basics of probability theory, namely the base theorem in box 2.1 and some simple examples about how base theorem can be applied. And again, a very important page or important part of this section will be page 20, which describes the concept of surprisal and specifically the statistical surprisal and how it differs from the phenomenological surprise or psychological surprise.
How we can formulate the statistical surprise.

26:57 Daniel:
Yes, just to catch up here this example that's going to come back again and again is a person who's guessing the object that's in their hand and it could be a frog or an apple and the object is going to jump or not. And so that's used as a way to talk about the Bayesian updating that forms the kernel of a variety of Bayesian brain like models, including ActInf inference. And then there are the presentation of the exact Bayes. So in simple cases, you can compute exactly what you want.
With Bayes theorem, however, it's a lot more effective on large data sets to use certain approximations and heuristics that we're going to be discussing. And then Ali has highlighted that there are two concepts that are very closely related to each other regarding surprise. There's surprise by itself and then there's Bayesian surprise. So please pick up there. What are surprise and Bayesian surprise and why do they matter here?

28:02 Ali:
Yes, well, surprise, I mean the regular surprise as we're all familiar with is something more related to our sense of surprise or psychological sense of surprise of observing some unexpected phenomena or unexpected behavior. But Bayesian surprise or statistical surprise is of course closely related with the psychological sense of surprise, but a bit more rigorous in which it's a way to compare two probabilistic information using callback libel or divergence and somehow getting the I mean how unexpected that information emerging from callback divergence and they call it the surprisal.
29:04 So surprisal in other words, is a way to formulating those unexpected probabilistic information and it doesn't necessarily align war maps unto perfectly our psychological sense of surprisal. But as I said, it's closely related with that.

29:28 Daniel:
Yes, by surprise, please.
No, you take it, Allie.

29:35 Ali:
I know, I was just going to say that. I was just going to say that by surprise, almost in the rest all the other sections and chapters of the book, we basically mean this Bayesian surprise sense of the world. And in order to distinguish that with the regular sense of surprise, sometimes in the literature surprisal is used to refer to Bayesian Surprise.

30:07 Daniel:
Yes.
So they're both measured in information theoretic units. This is all happening in information geometric spaces. The first concepts of surprise is applied to a given single observations. How surprising is that one observation? And so in that sense it's a lot like the Z score of a data point coming in with respect to a statistical distribution.
So it's like you have a height distribution in a classroom and you measure one person and then you can say what is the Z score of that measurement? Was it right at the center of the distribution with a z score of zero or were they two standard deviations higher with a zscore of two? So it's kind of like that. And that's why there's a discussion of probability distributions and their support, which is the x values for which they're defined. And surprise function with the fancy I.
And that's going to be a function that helps you compute how surprising each observation is given a parameterization of that distribution.
31:09 Whereas this Bayesian Surprise is more related to learning. It has to do with how much updating happens between the prior and the posterior and that's before and after the observation. So one could imagine a surprising observation surprise concept, one that either does or doesn't update the prior into a very different posterior. So as Ollie mentioned, they are not exactly the same, but it's going to be important to understand how they're different.
And that's worked out again in the case of the apple jumping box 2.2 continues with a discussion of expectations. Now, expectation in everyday parlance might be specifically referring to something in the future like I expect it to rain tomorrow. And in statistics, when we talk about the expectation, we're talking about the weighted average or the center of gravity of a distribution.
32:09 And that can be in both a discrete distribution, at which point you have a weighted sum, or a continuous distribution, in which case it's an integral. So you can have an expectation for the humidity tomorrow.
And so that might refer to the center of gravity at a t equals plus one. But just taken alone, expectation means center of gravity of a statistical distribution, not anticipation. Section 2.3 is going to describe how some of this, how this low road that we're on is going to connect to biological inference.
There's more discussion of the generative model and the generative process and a little bit of a hint that the generative model captures aspects of the generative process, which is where we see a lot of the classical cybernetic theorems and concepts like Requisite diversity, good regulator theorem and so on.
33:11 However, the generative model does not have to be exactly isomorphic with the generative process. For example, the generative process, the temperature in the room might be a continuous variable, but then the generative model might be discrete only, modeling integer based temperatures or might be categorical like too hot, just right, and too cold. So there's a lot of articulations that can be done because of how flexible and interoperable generative models are with each other. Figure two is going to expand upon that chapter one representation of the cybernetic action perception loop.
And we're going to see this more in terms of a generative model and generative process articulation. And there are incoming speaking from the perspective of the generative model, the agent. There are incoming and outgoing dependencies in this graph. And this is a little bit like a schema, more so than a formal graph, but also it is like a Bayesian graph where nodes are variables and edges are causal relationships.
34:22 And so we have the internal states of the model, the external states of the generative process, and then the blanket states that make internal and external states conditionally independent.
And again, speaking from the perspective of the agent, although there is a symmetry, we can talk about the incoming sensory signals happening from the observations handed from the process passed on to the internal states of the generative model and then the outgoing actions that are selected that then can influence the hidden state of the world. For example, going and turning on the heater to increase the temperature in the room. And so this action perception loop or particular partition is going to get explored in a lot more detail in the coming sections. Previous section 2.3 was on perception as inference and now action as inference is going to be discussed. And that is where they say the discussion to this point is common to all Bayesian brain theories.
35:25 We now introduce the simple but fundamental advance offered by active inference, which is the extension of this inferential perspective to consideration of action as inference. Perception and action cooperate to realize a single objective.
Section two five is about minimizing the discrepancy between the model and the world. We already described that there's two ways for this to happen change your mind and change the world. That's how the discrepancy can be reduced or managed. We see a variant of the action perception loop where the agent is making action prediction models of the world that through perception are being juxtaposed with observations handed from the generative process the world and a discrepancy is realized, some nonzero discrepancy. And then here are those two paths to minimize free energy, change beliefs by perception and learning, or change the world through action prediction two six is going to discuss how the exact Bayesian approach described earlier is absolutely spot on if you have infinite computing resources.
36:47 However, we're often interested in rapid or large data sets where we want to be able to get approximate Bayesian computation or probably approximately correct computation in a vastly accelerated fashion. And so that is going to be approached using what's called variational Bayesian inference. That's unpacked in chapter four. But it suffices to say that variational Bayesian inference implies substituting two intractable quantities the posterior probability and log model evidence with two quantities that approximate them but can be computed efficiently the approximate posterior Q and A variational free energy. So it transforms an intractable estimation problem into a highly tractable optimization problem.
Pick up from there. Ali.

37:42 Ali:
Yes, but sorry. I just wanted to point out a couple of things, especially about section 2.3, because I believe it. It is one of the crucial sections of this chapter and in fact, the whole book, because it provides some of the justifications of using Bayesian inference as opposed to some other mathematical techniques such as maximum likelihood estimation. But more important than that, I think it's this concept of optimality which comes into play in almost everywhere in the literature and of course, in this book. So there are actually two notions of optimality which is not discussed in detail here, namely Bayesian optimality and Jane's optimality.
But in some of the recent papers on Bayesian mechanics, dalton, Sactavato, Maxwell, Ramstead and others have shown that those two concepts of optimality are actually congruent with each other.
38:53 So that's one of the reasons that the duality between FEP free energy principle and constrained maximum entropy principle can be I mean, it's one of the justifications for providing that dual formalism between those two. But another point I wanted to mention here is because I've seen that using the word hidden state can be a bit confusing for some people because when we observe something as an observation, obviously it is not, quote unquote, hidden, right? So what a hidden state here refers to is actually the hidden cause of that observation. So it's not that the observation itself is hidden from the observation or it's unobserved.
So that might be a bit confusing if we don't take into consideration the exact meaning of the hidden state or latent state here and in the rest of the literature.
40:05 So continuing from Section 2.6 here we see one of the two central equations of active inference, which is equation 2.5 for variational free energy. So it's, as I said, understanding this equation and how each line of its formulation represents in terms of the trade off between energy, entropy or complexity and accuracy or divergence. And evidence is key to understanding almost everything in the rest of the book and in many other literature on active inference. So this is the perceptual part of active inference.
So variation free energy is a parameter, that is a notion that parameterizes the surprisal of our perceptual information we have about the external states.
41:17 And then we'll see in the next section the related and almost symmetrical formulation to variation of free energy, namely expected free energy, which is basically the action part of the active inference. So we can see how those two can somehow be seen as a kind of unified formalism but described in alternate expressions. But another thing about equation 2.5 is it may be a bit, I don't know, daunting to see all. The relations between those three lines of equation and how we can get from one to the other.
So there are some supplementary materials that we have developed in the past weeks which I think can help in clarifying how the derivations of these three lines of equation be done.
42:28 So I hope they would be clarifying and help to understand how those three lines relate to each other.
But the key point here is to understand that variation of free energy is not something absolute, but it's just an upper bound for the minimization. So as Daniel just mentioned, it's untractable to have an absolute amount for the surprisal to be minimized. So we need to have an upper bound in order to make that more tractable because by Jane's inequality, as we'll saw in chapter four, I think we can see that how the upper bound of a surprisal necessarily provides a condition for minimizing the precise or the exact free energy.
43:45 And that's the key insight of equation 2.5 or the notion of variation of free energy which is to provide this upper bound instead of the exact amount of surprisal to be minimized.

44:00 Daniel:
Yeah, what I'll add there is if you knew exactly how well you should be surprised by a given data point Y, then you would have had the optimal model.
However, that is not tractable. And so by making a quantity that's always higher or an upper bound, the variational free energy F, which is a function of broadly Q, our beliefs or variational beliefs which are built in a way that makes them very compositional, very optimizable, very interpretable and data. And we can reduce the divergence here, the KL divergence with a double line between Q, our beliefs and P, the kind of actuality of it. And if we can reduce this divergence, in other words, minimize the free energy, then we will come closer and closer to the true surprise function and do that in an attractable, incrementally, optimizable way.
45:03 So equation 2.5 is going to be the variational free energy, different ways that it can be represented as it takes in data and beliefs about the world Q.
And then this is going to be expanded into the future to include action with G, the expected free energy. Now, there's a lot more that we can say about this. There's a lot of technicalities to go into. But broadly, notice that g the expected free energy is a functional of policy pi because it's only being evaluated to select amongst different action outcomes. Pi and another important difference is that it's going to be describing sensory outcomes that haven't yet happened.
A sort of what would I perceive if I did A or what if I did B? And it's that kind of comparison that allows the expected free energy functional here to be used in action selection or policy selection as inference, planning as inference.
46:16 That section is expanded upon. And in figure two six, we see a very nice representation of the expected free energy equation. And then how, when certain aspects of this equation or situation are zeroed out, we get certain other familiar cases. For example, where there is no epistemic value, there's no information to learn. Then you get ruthless expected utility theory.
And conversely, where there is no pragmatic value to extract. So all outcomes are equally valid or preferable. Then you get things like Infomax principle and optimal Bayesian design and then everything in between is the space that we're interested in. And so this figure 2.6 shows that the expected free energy functional can be seen as like a generalization of a lot of other settings related to perception and action and planning amidst uncertainty.
47:21 And section 2.9 closes the low road.
They took us all the way to active inference, from Bayes theorem through the generative model onto active inference and clarifies these two notions of variational free energy that's the real time perceptual unfolding evidence, lower bound, unsurprisal tractable optimizable, and so on and f and g, the expected free energy which is able to do planning as inference or policy selection as inference. Expected free energy is fundamentally prospective and that enables counterfactual cognition. Section 210 summarizes active inference is the theory of how living artifacts underwrite their existence by minimizing surprise or attractable proxy to surprise variational free energy via perception and action. And they motivate that from a first principles base theorem starting place.
48:23 Any closing thoughts on chapter two, Ali?

48:27 Ali:
I would just humbly suggest for the people who want to go through this chapter to try their best to really understand specifically what equation 2.5 and 2.6 represents and how I mean, how to use those equations to describe different situations with some missing elements as well. Because I believe those sections, and particularly those equations are absolutely essential for understanding everything active inference related both in the rest of this book and in almost all.

49:20 Daniel:
Thanks. And just the last thought I'll give on chapter two is this is exactly the work that we do in the active inference textbook group. We really welcome all backgrounds, every single question and uncertainty you have is beautiful.
We have a lot of resources that Ali and others make to make the math approachable and rigorous and natural language descriptions of the equations and so on. So yes, it's really important to understand the equations because after all, that's like the skeleton that gives meaning to our usage and fluency of the active inference ontology which Ali and I are speaking right now. We're not just saying surprise is related to this because we felt it that way. There is an underpinning and it is a really interesting life's work to explore it, but we're finding ways to communicate it and learn and teach it better and better every time. So that's chapter two, that's the low road moving on to chapter three, the high road to active inference.
50:21 And so recall that the high road is like the why. So, Ali, please begin, just go as long as you want on through the high road to active inference.

50:33 Ali:
Okay, so the high road to active inference begin with the question about the conditions for the persistence of things. I mean, what would we expect for a thing to behave if it persists through time? And that's why sometimes FEP is referred to as the theory of every space thing. And it's not absolutely everything, but just in this sense of I mean, persisting through time. And the notion that allows for this thing to act as it persists through time is markup blanket.
So Markov blanket is one of the most essential ingredients of the high road approach to active inference.
51:34 And that's why this section opens up with describing how markup blanket allows to describe the situation of interest through this conceptual and mathematical tool. But one thing that I always point out in almost all our textbook cohorts is in this section. It doesn't exactly describe markup blankets rigorously enough in terms of it's carving up the state space and so on. So one thing I think can be clarifying in following all the discussions around markup blanket is to keep in mind that it's just a boundary in the state space.
52:36 So it's not necessarily spatial temporal boundary, although in many cases it manifests itself as spatial temporal boundaries, such as the, I don't know, cell membranes or organelle membranes and so on. But it's not necessarily the case. So I think it can be helpful to keep that in mind when we every everywhere we see markup blanket. But in a very simply, markup blanket is what allows for the agent or the system to be statistically separated from its environment, as is shown here in Figure 3.1. So basically, markup blanket mathematically is just the sensory and active states together.
It consists of both of those states and it statistically separates what happened externally or internally from each other.
53:45 So in other words, internal states cannot observe or infer anything about the external states directly, but only through the Markov blanket. And that's why it's essential to describe the systems in this way, because obviously, in any sparse coupled systems, there isn't the possibility to observe the external states directly, but only through those sensory and active states. And one other thing that I also believe can be a bit confusing in this picture is that, yes, typo in the ActInf estates and sensory states because it's important to observe that active estate only or the flow in the active states more precisely, only depends on internal and markup states or blanket states.
54:50 And on the other hand, in sensory states only depend on the external and blanket states.
So Mu and X in those two equations should be exchanged. Yes.

55:06 Daniel:
Let me just unpack before we continue.

55:08 Ali:
To add before we continue.

55:11 Daniel:
Yes.
So this is what's known as the particular partition. And that terminology was brought to the fore by Carl Friston's famous monograph in 2019. And it's a little bit of a pun. It's a particular partition because this is just one way to partition agent from environment, figure from ground. And we call what it partitions out the blankets and internal states as the particle.
So we can think about the most inert least cognitive particle is like a speck of dust doing brownie and diffusion. But also there are more sophisticated kinds of cognitive particles that can include world models, counterfactuals what would happen if I did this, all of those kinds of sophisticated cognitive operations that we can explore in active inference. So note the small typo that Ali mentioned, internal states. And also these edges reflect causal possibilities amongst internal, external and blanket states.
56:17 Blanket constituting the active U and sensory y states.
So these are map, not territory. This is not a spatiotemporal articulation. These are like causal maps of the world that may have to do with spatial temporal boundaries but are not simply that. And sensory data or sensory states flow onto internal states. Internal states are involved in action selection resulting in active states which have some causal consequence in the world, the generative process, the external states which results in different sensory states coming in again.
And so the Markov blanket is what makes the internal and the external states conditionally independent. And that can be thought of as just a no telekinesis, no telepathy clause. The only way that information comes across internal and external states which are symmetrical with each other is through the boundary or the Holographic screen or the Markov blanket.
57:28 You can continue on ali.

57:33 Ali:
Okay, so the next section is about surprise, minimization and self evidencing. So again, this term self evidencing is a common term in active inference literature first proposed by Jacob Howie. So basically it refers to how a system or agent or in other words a particular state can gather the evidence for its self persistence or self existence through time. In other words, by inferring the state of the environment and comparing that inference with its internal states or in other words, with its generative model.
It's basically a way, I mean an interpretation of that kind of inference is on the one hand, there is this dynamical interaction between the internal and external state.
58:41 But we can somehow interpret that physical dynamics as engaging in the active inference or as model for the persistence of the agent through time. So that's basically what refers to as self evidencing. And then we go through the subsection 3.3.1, which sets the stage for the recent formulation of active inference mechanics, which is to somehow to interpret the ActInf surprise minimization as minimizing the action through the Hamiltonian principle of least action, which is a variational principle. And by variational principle, what is meant here is just a computational or mathematical tool that allows for the computation or specific derivations to happen.
59:58 So it's not identical to scientific theories or scientific, I don't know, facts or observations. It's just a tool, a principle mathematical tool. So again, one of the main misconceptions about free free energy principle, that it is unfalsifiable. Obviously, if we see it in this way, it doesn't make sense to say that a mathematical tool or principle is unfalsifiable because it doesn't say anything about the empirical evidence of the phenomena we're talking about. So that's why here it's important to understand how the surprise minimization can be seen as this kind of variational principle.
And then equation 3.1 draws the parallel between the surprisal as defined in section in chapter two sorry.
1:01:11 And this chapter. So it kind of ties up all the arguments provided in the previous chapter with this one and how everything comes together in a single formulation of active inference. But they're just the two distinct approaches to arrive at same destination.
And then we go also sorry, the other important equation, and again, another key equation here is equation 3.2, which is kind of sorry, yes, equation I meant to say equation 3.2, not equation 3.1. Sorry, my bad. So yes. The other section is about the relations between inference, cognition and stochastic dynamics, as all the previous discussions around how the active inference can be seen as a kind of self evidencing through the variational principles such as FEP comes together to reframe the previous discussions we saw in chapter two about perception as inference and action as inference, and to see the concepts of variational free energy and expected free energy through the lens of variational free energy.
1:02:56 Variational principle of least action.
So it unifies nicely all the material from chapters two and three into something not necessarily distinct from each other, but just two sides of.

1:03:24 Daniel:
Awesome. Yeah, I find Table 31 to be very exciting. It draws together statistical physics, Bayesian information, information theory and cognitive interpretations. So it's kind of like learn one thing, learn many things. Statistical physics has been talking about minimization of variational free energy for a long time, and such methods are absolutely everyday and professionalized.
In Bayesian statistics, active inference is using exactly just that to describe perception and action and so on. So that's very exciting. Box 3.2 describes free energy in statistical physics and active inference. I sometimes joke that we have a few kinds of free energy. We have Tesla like electrical power should be available to everybody for no cost.
We're not talking about that right now. There's Gibbs free energy, which is the quantity that makes chemical or thermochemical reactions irreversible, like the hydrolysis of ATP.
1:04:30 And when we're talking about variational free energy, we're talking about an information geometric space with similar dynamics, similar kinetics and thermodynamics. But rather than describing the reaction coordinates of a chemical reaction, we're thinking about it in terms of Bayesian updating. And this is all called the Bayesian mechanics.
3.41 continues on with variational free energy. 3.42 goes into expected free energy. So we see this a lot f variational, free energy, that's the real time unfolding sensory flow and then g expected free energy and the policy planning as Inference section 3.5 concludes with a novel foundation active inference to understand behavior and cognition. And it describes a few features of active inference, including its distinguishing features from a few other ways that people have looked at behavior and cybernetics.
1:05:40 Section 3.6 goes into a bit more detail on models, policies and trajectories having to do with agency and policy selection.
3.7 reconciliation of inactive cybernetic and predictive theories under active inference. Again, the exact kind of thing that there's a whole literature on and it's always amazing to hear everybody's perspective on in the textbook groups. Three eight active inference from the emergence of life to agency and three nine summary. You want to just give any other thoughts that you have on chapter three.

1:06:19 Ali:
Again, it's one of the probably most fundamental chapters and the topics covered in this chapter is essential, are absolutely essential to understand everything active inference related. But specifically the discussions in section 3.73.6 onward again, I believe is really important to understand the broader context of active inference and how it relates to all the other theories. But specifically, section 3.8 provides a nice view of how we can use the same theoretical tools to model both nonliving dynamical systems or sparse coupled stochastic systems and also to the systems that has agency or sentience.
1:07:32 So it's a much broader theoretical framework that doesn't restrict itself to only particular kinds of systems or agents and we'll see much more elaboration on that in the later.

1:07:52 Daniel:
Wonderful. All right, that concludes our overview on chapter three. Now we're going to skip to chapter six.
So again, this live stream is just providing some materials on chapters one, two, three and six. Eventually we're going to get to all chapters and version them and have as many of you as want join into the process of constructing these. But this is all so that our textbook groups can be really interactive and people can show up having listened to these background and context videos. All right, so now we are in chapter six, a recipe for designing active inference models. Abraham Lincoln give me 6 hours to chop down a tree and I will spend the first four sharpening the axe.
All right, Ali, what does the quote mean? And please lead us into this discussion.

1:08:52 Ali:
Okay, so as the opening quotation suggests, it's about honing the skill set and skill set for applying ActInf inference framework to model the actual empirical situations that we may use active inference for. And it frames it as a four step recipe to actually do this kind of model, although it's termed as recipe. But I believe it's more like a guideline and it's not like, I don't know, cooking recipe that needs to be observed strictly. So it's more like suggestions or guidelines to begin to apply active inference framework in any kind of situation we'd like.
1:09:57 So section 6.2 outlines those four steps.
So the first step is which system are we modeling in terms of how we can define the Markup blanket that most effectively and efficient the problem or question we want to explore through that modeling through the modeling of that situation. So first step is about defining those boundaries through Markov blanket. And the second step is about what's the most appropriate form for the generative model because obviously we can have many different types of generative models depending on, again, what phenomena or what questions we're trying to address. The third stage is how to set up Degenerative Model.
1:11:00 So after settling upon the type of Degenerative Model we want to use, we can talk about the details of Degenerative Model and how it can be efficiently modeled to be both tractable and also useful to address the situation of interest.
And finally, how to set up the generative process. So, as we saw in chapter two, there's important but slight distinction between generative process and generative model. So they're not always the same, but they're closely related to each other. Generative process, the hidden states of the external world. And generative model is how the agent infer about those hidden states provided by generative process.
So, considering that the environment is always very complex to be modeled precisely and exactly with every parameter accounted for, we need to have a restricted set of parameters to account for in the generative process.
1:12:23 So that's what stage four deals for deals about. So all of these steps, even if not observed or followed sequentially, are really essential to setting up or the initial setup of the situation we're trying to model. And I cannot imagine how any scenario can progress without observing any of these steps at least, I mean, just by thinking about how to set up the situation or scenario.

1:13:15 Daniel:
Awesome.

1:13:16 Ali:
And in the rest of the chapter.

1:13:20 Daniel:
Yes, just wanted to highlight again, these steps don't have to be followed in order. They really are like a summary as Mark has just written in the live chat here. It really is like a summary of the earlier parts of the book in terms of things that you want to capture in your consideration. And also it's a great way to connect a lot of the technical ideas that are brought up about generative model, generative process and so on with some bigger questions like who are we?
Why are we making this model? How is the model going to be used? So we take that in a lot of different ways in the textbook groups. But which system are we modeling? What is the most appropriate form for the generative model?
How should we set up the generative model? And how to set up the generative process are all questions that must be addressed, at least when actually coming through with carrying out a theoretical or empirical active inference modeling task. And the following sections are going to go into more detail on each of those four questions.
1:14:26 So Ollie, do you want to go for this? 63 and carry on.

1:14:32 Ali:
Okay, so section six one three is the elaboration of the first step that we just saw. What systems are we modeling? And by this question we mean how the system carves up the state space using the markup blanket or more precisely, the active states and sensory states. And I believe it is both one of the most fundamental and also one of the most challenging steps to be carried out because, well, markup blanket is just a conceptual tool we use to frame the natural phenomena or any other scenario we want to model.
1:15:36 So that scenario or that model obviously doesn't care about how we set up our Markov blanket or how we knit our markup blanket.
But deciding on a proper set of active states and sensory states that would allow us to address the problems we need to explore or the questions we need to answer, is not a trivial task. And it needs lots of lots of consideration and even creativity on part of the researcher or anyone who wants to design an active inference based model for the problem. So that's where the significance of doing these kinds of modeling with the insights and creativity of a researcher will be obvious because it's not just something mechanical or despite the fact that the word recipe can somehow make us believe that it's just a recipe to follow.
1:16:56 But in actuality it's not the case at all. So that's the discussion of markup blanket and what criteria we need to keep in mind to settle upon proper Markov blanket around our system.
And the next section, what is the most appropriate form for the generative model? So here again, we can have various way to set up our generative model in terms of whether it's discrete or continuous variables we want to account for about the timescale, is it shallow or hierarchical about the temporal depth of the inference and planning. So these are all problems we need to be precise about or questions we need to precise about whenever we want to set up our generative model.
1:18:03 And then we go to section 6.5, how to set up the generative model. So after precisely describing what needs to be accounted or what parameters and the nature of the generative model needs to be accounted for, then we need to address this question of how can that generative model be actually set up.
So setting up the variables for the generative model will be concerned about how those matrices as A-B-C and D matrices can be defined, as we saw in chapter four. And then which parts of the generator model are fixed and what is learned.
1:19:05 So again, it's really important to know what are the dynamics of those parameters are in terms of the learning process and what needs to be updated consistently or learned as opposed to the variables that either don't require consistent updating or they vary quite slowly as compared to the timescale of the generative model. And then we go through the process of setting up the generative process. And as I mentioned earlier, it is probably one of the most complicated steps of the recipe because of the complexity, the enormous complexity of any real time situation and particularly the environment that the agent will act and behave.
1:20:15 But even if there is not any strict or, I don't know, obvious way to go through this stage of setting up the generative process, this section provides some helpful criteria or helpful points in order to help us in that stage as well. So finally, after going through all of these stages, we need to somehow get I mean, obviously we need results, and we need to provide our results in a we get our results from our active inference model, and section 6.7 addresses that very idea of how to simulate, visualize, analyze, and fit data using active inference.
1:21:21 Because it's not just enough to set up the model, we need to get the model to work. So how can we feed the data into the model? How can we read the data?
And finally, how can we analyze the simulated data through the active inference? So this is in a way a kind of preliminary recipe or preliminary procedure for doing active inference or active inference modeling, or at least suggested way to do those kinds of modeling. But in the subsequent chapters, in particular chapters seven and eight, we'll go through some helpful cases, studies for how to actually use these procedures to model some real world situations.

1:22:22 Daniel:
Awesome, thanks. Well, there's a lot to say on chapter six. One piece that comes up a lot is what is in the active inference kernel, the cognitive kernel, and what are situations that we can model with active inference. There's a huge variety of cognitive phenomena and statistical outcomes that we might be interested to study like counterfactuals and planning, like multiscale attention covert action, like the complex ways in which memories might influence decision making in the moment based upon associations made between different sensory modalities, every amazing real world situation you can imagine. And it's really helpful to think about active inference as more like a framework of interoperable motifs that we can compose and indeed even be creative with rather than giving us all the answers at the core model.
1:23:23 Because the kind of essential minimal active inference model doesn't necessarily include every single attribute that you might be interested in, just like any given linear regression isn't going to include every single feature that you're looking for. This is happening in a different type of modeling framework. But still, there's a lot of customization and development that goes into adapting or elaborating an active inference type model for your given system or scenario of interest. Chapter six gives us some helpful guidelines and things to consider, which we've unpacked and expanded on elsewhere. And in the textbook group, we work together to characterize different systems of interest, to map different parts or different observables from that system, using the active inference ontology into a unified ActInf inference type model.
So chapter six starts the second half of the book, which is the more practice oriented part of the book.
1:24:28 And the rest of the part two is going to be a lot more about the specific kinds of generative models that you can use discrete and continuous time and about using them with empirical data in chapter nine. But chapter six just stands alone as a summary of part one of the book in some ways, and a set of four questions which system are we modeling? What is the most appropriate form for the generative model, how to set up the generative model, and how to set up the generative process so that we can be active inference modelers ourselves?
All right, well, Ali, thanks so much for all of these great conversations and cohorts. We will be able to process this video to clip out these first versions of the background and context overviews, and we'll distribute them to the cohorts so that people can show up with their curiosities and passions and we'll see where that goes.
1:25:32 Any last thoughts?

1:25:36 Ali:
Thank you. It was a pleasure to go through these chapters once again with each time, obviously with a bit more understanding than the previous one. So I'm looking forward to the next cohorts.

1:25:54 Daniel:
Awesome.

1:25:55 Ali:
All right.

1:25:55 Daniel:
Thanks, Ali! Farewell.
