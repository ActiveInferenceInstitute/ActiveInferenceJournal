---
title:  'Physics as Information Processing - Lecture 3, "Quantum Reference Frames"'
author:
- 'Chris Fields (Allen Discovery Center at Tufts University) [![Orcid](images/orcid.png)](https://orcid.org/0000-0002-4812-0744)'
- 'Ander Aguirre (Ohio State University) [![Orcid](images/orcid.png)](https://orcid.org/0000-0002-6337-8292)'
- 'Daniel Friedman (Active Inference Institute; University of California, Davis) [![Orcid](images/orcid.png)](https://orcid.org/0000-0001-6232-9096)'
date: "2023-07-13 Version 1.0"
...

## Lecture 3, "Quantum Reference Frames"

_Daniel:_
 Hello and welcome everyone.
 It's July 13, 2023.
 We're here in physics as information processing with the third lecture by Chris Fields.
 So please check out the course website, Coda Document, where you can submit questions, check out the recordings and descriptions of all sessions, and register if you want to participate in one of the discussion sections.

 So thank you again, Chris, to you.

_Chris:_
 Thank you and welcome to Physics as Information Processing, session Three, which is about quantum reference frames.
 So in this course, we've talked about quantum information theory, which we characterized as a general theory that describes the exchange of information, exchange of finite information between two finite agents that are separated by some boundary.
 And we emphasize that this is a topological theory, not a geometric theory, so it makes no assumptions about an embedding spacetime.
 And last time we showed how to characterize this boundary of script B as an array of N, some finite N quantum bits or qubits, and how to characterize the interaction of the agents A and B with the boundary as an alternating cycle of preparing and measuring the qubits in this array.

 And we showed that their interaction could be represented as a sum of operators, each of which act on just one of the qubits.
 And we also talked about the need for each of the agents A and B to choose a reference frame for their interaction with the qubits that defined which way was up.
 So what the orientations of the qubits meant and emphasized that the two observers A and B could choose different reference frames, so different ways of measuring and preparing their qubits that use different meanings for the idea of up for each qubit.
 And we ended the last session with a pointer forward toward the quantum formulation of the free energy principle, which can be stated as the claim that interacting systems behave in a way that aligns their reference frames.

 And pointed out at that time that what this means is that the two agents A and B approach entanglement asymptotically, and that therefore the FEP is a classical limit of the principle of unitarity, which is the core principle of quantum theory.

 So we'll see in this session why this is true.
 So what we'll talk about today is what reference frames are in general, how they make observations and actions meaningful, so how they give physics a semantics, and then we'll talk about the free energy principle.

 So what is a reference frame?
 The idea that physics involves reference frames goes back at least to Galileo, but was probably familiar well before that, just not formalized in the way that Galileo formalized it.

 So the key idea can be thought of in terms of motion.
 And you're all familiar, for example, with riding a bicycle or driving a car and seeing the world as if it's passing by you at some velocity, with some velocity.
 And of course, with respect to the world you're passing by it with some velocity.

 And this idea that velocity is not absolute but that's relative to some observer who measures it in some reference frame is the foundation for theories of relativity.
 So Galileo developed his theory of relativity which basically was just a way of converting from classical velocities measured by one observer to classical velocities measured by another observer that was moving with respect to the first one.
 And this provided the foundation for Einstein's theories of relativity which modified Galileo's by adding the concept that the observers have to exchange information and can only exchange it at the speed of light which is finite.

 So this idea in physics has a long history.
 Of course, the core idea is that measurements are always with respect to something or other.
 And the something or other is a reference frame and different agents can choose different reference frames.
 And this idea is very old.
 Here we have a picture of Anubis choosing a feather as the reference frame with which to measure the heart of the pharaoh.

 So this goes back to well before the common era.
 This is about 2000 BCE.
 So this is a very old idea that's been elaborated over the centuries as science has developed and in the 90s a fairly big change in how this idea was thought about occurred. In classical physics reference frames were always thought of as mathematical abstractions and an observer and a reference frame were more or less identified by Galileo...

 ...and that identification is carried forward into Einstein who thinks about observers, for example, sitting on photons and observers in spaceships and observers riding on railroad trains and this sort of thing...
 ...and always that just means, think of a reference frame that's doing something or other.

 So a reference frame in classical physics is essentially just a coordinate system and these abstract coordinate systems can be employed in thought experiments and so they are a way to illustrate classical intuitions about motion.
 And in the 90s, as quantum information theory developed it was realized that a reference frame actually consists of a physical object.
 I mean, even in the picture from the Egyptian tomb the reference frame is a physical feather.

 And that means that the reference frame itself is described by quantum theory.
 It's some quantum system.

 And if you think about reference frames that are familiar for example, meter sticks for measuring distance or clocks for measuring time or gyroscopes or batteries or even the Earth's gravitational fields which typically defines up for us; those are all physical objects that can be described by quantum theory.
 Well, this was an important insight because it led to the realization that reference frames as quantum systems are unique.
 And uniqueness in quantum theory is very strong.
 There's the no-cloning theorem which states that you can't reproduce, exactly reproduce, any unknown quantum state.

 And that applies to reference frames because they encode what Bartlett et al.

 ...in that paper called nonfungible information which just means information that can't be completely represented in any finite bit string.
 So unless you know the state of a reference frame, you can't clone it.
 Since these reference frames encode more than any bit string's worth of information in their quantum phases, they're unique and their states are unknown.
 And the consequence of this is that if Alice wants Bob to use her reference frame to make a measurement, she can't just send him a description.
 She has to actually send the reference frame.

 And this has an important consequence for physics because it makes all replicate measurements approximate because observers obviously aren't using exactly the same physical objects as their reference frames.

 But there's a deeper implication of this, which is that Alice's ultimate rock bottom reference frame is actually implemented by her body, by her brain.
 And using any external reference frame requires having this internal reference frame that makes the external reference frame meaningful and usable.
 So, for example, this thing is a piece of a meter stick, a third of a meter stick.
 But for me to use it to make measurements, I have to actually have some concept of distance.

 And that concept of distance is implemented by my nervous system.
 And that implementation is my reference frame for length.
 And it's what gives meaning to any external measurement of length.
 It's what makes my measurements of length actionable by me using my effectors or action capabilities, whatever they are.

 So my internal reference frames are what make information I get from the world actionable.

 And in Bateson's sense of differences that make a difference, actionability is the core of semantics.
 Something is meaningful if I can do something about it.
 So this idea that we all contain embodied reference frames gives physics a semantics by giving observers a semantics.
 And this is new.
 This is an idea that never really appeared in physics before that measurements automatically had to have some kind of semantics.

 But reference frames give semantics to measurements.

 So here's an example of an embodied reference frame.
 This is the reference frame that bacteria use for chemotaxis, i.

 e,
 ...to move toward molecules in the environment that they like, like sugars and to move away from molecules that they don't like, like acids.
 And it's been worked out in great detail over decades of experimental work.

 And this is a rough schematic.
 The reference frame has three parts.
 There's the measurement part, which is conveniently located in the front of the bacterium.
 And it consists of a bunch of receptors that probe the environment.
 And they can bind molecules, which are called ligands, out in the environment.

 And when they bind them, they send a signal into the back of the bacterium.
 And it turns out that there's a little miniature reference frame attached directly to these ligands which is this R and B system which control the ligands--not the ligands--the receptor sensitivity.

 Then the back of the reference frame is the action component and it consists of a set of molecules that control a motor--a molecular motor--that drives the flagella on the bacteria.
 And the flagellum allows it to swim forwards or turn in some other direction.
 And depending on how it spins, the creature either goes in the direction of something it likes or it stops and turns around.

 And the stuff in the middle is a little molecular feedback loop that represents the amount of ligand in the environment that the bacterium expects to see.
 So this is the middle of the reference frame and it defines the default value for what the bacterium is observing in its environment.
 And if you're thinking in terms of the free energy principle or Bayesian inference, then you'll immediately see the concentration of this molecule is encoding a prior probability, the bacterium's prior probability for what its environment is like.

 And the zero point, the default value of that encoding, is the ligand concentration in which the bacterium does nothing.
 So a QRF in general can be characterized as an expected value, which is here the concentration of this molecule pY phosphorylated plus a bunch of computation, which is all the rest of the things in this diagram.

 So this is a very simple QRF that's embodied by a bacteria.
 Here's a more complicated QRF that's embodied by eukaryotic cells, or more complicated cells like our cells.
 And this is the reference frame that makes decisions about whether cells are going to divide.
 So on the top you see the cell's membrane, and there are all sorts of receptors sticking out of it that detect hormones and neurotransmitters and growth factors and this, that, and the other thing, many of which are produced by other cells.

 And those receptors communicate via a lot of chemistry with the nucleus, which is contained in another membrane and so serves as, in a sense, the outside upon which the reference frame is acting.

 And what this reference frame does is control the transcription of large numbers of molecules from DNA.
 So it basically controls what proteins the cell is making.
 And those proteins end up doing something like restructuring the cytoplasm and actually driving cell division.
 And the stuff in the middle of this reference frame, which I've labeled the integrative center, are three molecules called RAF, mech and ERC.
 And they're connected by positive bi-directional feedback loops.

 And they basically negotiate the default value of the environment at which the cell does nothing.
 So they're the middle of the reference frame that represents the cell's expectation values about what's going on in its environment.
 So you can imagine now what reference frames encoded by our nervous system look like.
 They're extremely complicated and exist at multiple scales, from the scale of molecules in cells to the scale of large scale connections between parts of our brains.

 So how do we represent all this stuff?
 There are many ways to do this, but this is a particularly simple way.
 It assumes that whatever's in the middle, which is here called C prime, is the most general thing that the inputs can give information to and the most general thing that can give information to the outputs.

 And most general here has a category-theoretic definition so it can be stated in a way that's equivalent across many different specific mathematical forms.
 But if you're familiar with neural networks, this will look to you a lot like the skeleton of a variational autoencoder.

 And that's basically what it is.
 And I don't want to deal with this formalism except to say that it exists and is very convenient, except to say that we can attach this kind of formal diagram as a representation of a QRF to our representation of the boundary between two interacting agents.
 And we can use these formal structures to drive the measurement operators that actually implement physical changes on this boundary.

 And I'll represent this whole business with just a triangle labeled Q for some QRF that's attached to the boundary.
 And we can use this simple notation then to investigate what sorts of structures one gets when one starts to think about systems as implementing specific QRFs.

 And here's the structure of the minimal system that we can really think of as an interesting observer.
 And this is a system that has some QRF that I've called E that looks at its environment, the part of its environment that it can actually observe and act on, and it defines a sector of the boundary which mathematically is just the image of this QRF-E that the system can manipulate.

 So this is the part of the environment or the part of the boundary that the system actually sees and can do something about.
 And for this observer to be interesting, it needs to be able to detect the difference between what it sees now and what it saw just then so that it can decide whether to take some action or other.
 So it needs a memory and that requires another QRF that has some allocated piece of the boundary. Recall...

 ...the boundary is where classical information gets written in this purely quantum theoretic formalism.
 So it needs a memory sector that that QRF can act on.
 And then in order to do this computation and specifically in order to write information to the boundary--in order to actually flip bits on the boundary--it needs free energy.

 So the rest of its boundary gets devoted to extracting free energy from the environment and exhausting free energy, waste heat, in other words, into the environment.
 And so it has this nice little thermodynamic cycle that drives everything else.

 And finally, in order to tell now from just a second ago the information in memory, it needs a clock that marks the information in memory as not current, so as past information.
 And if it can store multiple memory records, it needs to be able to count and say this piece of remembered information is actually more recent than that piece over there.
 So it has to implement a little internal clock, and that clock is its internal time QRF.

 And we've seen that QRFs act on boundaries.
 This clock acts on a boundary, but it doesn't act on B.

 It acts on an internal boundary that's essentially the boundary between it the clock and the points at the ends of these QRFs that actually encode information that's either read from the environment or written to the environment.
 So already this minimal observer has a little bit of hierarchical structure, which is that its clock has to, in some sense, be higher up in the hierarchy than the parts, the QRFs that interact directly with the environment.
 So if you have a structure like this, you face a metabolic trade off for a fixed amount of energy that you can extract from the environment.
 You can allocate it either into learning more about the environment or remembering more about what you learned before.

 So any system has to make this decision about how they're going to use energy.
 Are they going to devote it to learning more or remembering more.
 And your laptop makes that decision.
 Memory is cheap for your laptop.
 Your brain makes that decision.

 Memory is much more expensive for your brain.
 And all cells have to make that decision.
 And the universal solution to this trade off is coarse graining memory...
 ...i.e.,
 ...remembering things in less detail than you saw them in the beginning.

 Ander, you have a comment?

_Ander:_
 Yes.
 I wanted to ask a question now before it gets too late.
 So two or three slides ago, when we were looking at the diagram of the co-cone diagrams, I was wondering if the classifiers identified with measurement and preparation...
 ...those correspond to sensory and action degrees of freedom in the earlier picture with the bacteria and the classifier in the middle in that picture, would it correspond to the default chemical concentration?

_Chris:_
 That yes, exactly.

_Ander:_
 Okay, perfect.

_Chris:_
 Yeah.

 That crossing point in the middle is specifically where the default is encoded.
 Thank you for pointing that out.

 Okay, so let's follow the consequences of this metabolic issue.

 If you have a system that's a little bit smarter than our minimal system that can actually detect and measure the states of objects, it has to do even more work because it has to encode even more QRFs.
 So think of measuring the state of some object like a volt meter in a laboratory.
 If I tell you to go into the lab and tell me what the voltmeter is reading, then the first thing you have to do is find the voltmeter.
 And your process of finding the voltmeter is independent of your process of reading what it's actually saying on its dial.

 So in order to measure the state of an object, you have to have two QRFs one that lets you find the object, and then the other that lets you measure the state of interest of the object.

 And we call these the R sector for reference that lets you find the object and the P sector for pointer because old instruments used to have pointers on dials that read analog numbers.

 But what thinking about object identification tells you is that every object that you can identify leads to having to sector both the informative part of your boundary and the memory part of your boundary into two new sectors one to store information about object identification and one to store information about the states of those objects.

 So this requires much more metabolism.
 And again, the solution is coarse grained.
 Typically, what we coarse grain is our memory of the object that we've identified.
 So what does this do to systems?

 Because making measurements costs energy and recording memories costs energy...
 ...we have to make decisions about what QRFs to use at what time.
 Given our finite energy budgets, we can't look at the world with all of our measurement capabilities at the same time because it's too expensive.
 And now we see the effect of a theorem in quantum information theory which is that if two QRFs can't be deployed simultaneously for whatever reason that corresponds to them not commuting as operators and if they don't commute as operators, they have to be implemented by compartments that are separable.

 So compartments that only communicate classically.

 The consequence of this theorem is that as soon as one has too many sensory and motor capabilities to run all at the same time, given your energy budget you end up being compartmentalized into compartments that only communicate classically.
 So you end up looking like this diagram where there are a bunch of components that do sensory motor loops or memory, one or the other and they can only communicate classically.
 And they're controlled by some sort of attention system that selects which ones to activate depending on the amount of free energy that's available.
 And clearly, this clock function becomes part of this control system.

 So, the physics alone of any system that's acting as, that executes a fairly complicated interaction with its environment gives us this hierarchical compartmentalized structure without having to add any biological or cognitive science type assumptions at all.

 So we can go in three directions from this.
 We can go deeper into the biology which we're going to do in October.
 We can go deeper into the physics which we're going to do in August and September and we can go deeper into this issue of alignment which is what we're going to do today.
 So there are four possibilities.
 If you think about two agents that have QRFs that are interacting across this boundary and the first one is trivial.

 If the B agent, the agent on the right side, doesn't actually employ any QRFs if it just interacts with the boundary thermally, then there is no alignment.
 You're in a trivial situation where A can measure something about B, but not in return.
 If the B agent deploys a QRF that's much broader in scope than the A agent what we show here in panel B, then the A agent can learn something about the B agent but misses most of what the B agent is doing.
 In panel C, we have agents with QRFs of the same size on the boundary, but they're not lined up correctly.
 So each one misses part of what the other is doing.

 And finally, indeed, we have the optimal situation where they have QRFs of the same size and they're actually lined up.

 So each sees what the other is doing, at least on this sector of the boundary.
 And since the agents have to allocate some of the boundary to free energy supply and can't look at that part, then they can't tell what's happening across their entire boundaries.
 They can only tell what's happening in this sector where they can actually deploy a QRF.
 But let's now look at this interesting situation, situation D, where the QRFs are aligned between A and B.

 As I said, that's the optimal channel for A and B.
 And if we think about this, we can write the variational free energy or the uncertainty or the prediction error for A for the QRF X as the action that it sees, i.e., B's action, the difference between that and what it expects B to do.

 So what it can predict about B's action.
 And this is just the notion of free energy from the free energy principle, except translated into this situation where we have two QRFs and A can measure what B has done, but it can also use its QRF to predict, because it's predicting the very state that it's going to observe next of the same sector that B is using.
 Now, if we look at this diagram, we can see easily that the way to minimize the variational free energy and therefore maximize predictive capability is for these two QRFs to actually be the same.

 So if A is doing the same thing to the boundary that B is, A can predict B's next action perfectly because B is going to do whatever A is doing.

 So what the free energy principle tells us in this case is that A and B, as they minimize their variational free energies, will approach having identical QRFs.
 Well, again, we have a theorem that tells us that if these QRFs are shared, A and B are not separable but entangled.
 And this is also fairly easy to see because it depends on this notion of nonfungibility.
 If XA and XB both encode nonfungible information, which is quantum systems, they do...
 ..their states aren't clonable, so they can't be copies of each other because one can't clone an unknown system.

 So they can only be identical if they're actually identical systems.

 This is exactly the same point made earlier about Alice having to actually send her QRF to Bob if she wants Bob to use her QRF.
 So minimizing VFE for quantum systems is becoming entangled.
 So the classical free energy principle, which tells us to minimize VFE actually drives quantum systems toward entanglement.
 And that's why it's a special case of the principle of unitarity which just says that any isolated joint system is going to asymptotically approach entanglement.

 So this raises an obvious question, which is why all of us aren't entangled with our environments all the time and entangled with each other?
 And the answer is that entanglement is really hard for complex systems.

 And this illustrates the sense in which the FEP is moving systems in two different directions at once.
 The FEP is driving systems to maintain their separability but it's also driving systems toward entanglement.
 And as the system becomes more and more complex the difference between those two outcomes becomes larger and larger.

 So recall from last time that the condition for separability is that the two systems have dimensions that are much larger than the dimension of their boundary.
 And this is the condition that allows them to have internal states, to have them have states that aren't located on their boundaries.
 And clearly, to formulate the free energy principle you have to have internal states.
 So if you do a complex QRF that's in a lot of computation then you need a lot of internal degrees of freedom to implement that computation.

 So you need a lot of internal state.

 So you have to have large dimensions.
 So complexity favors separability.
 As a system becomes more complex, it has to have more internal states.
 So it has to be, in a sense, more separable from whatever it's interacting with.
 Now, think about this classically.

 If you have a complex system that's doing a lot of computation then it requires a lot of free energy and it has to dissipate a lot of entropy in the form of heat, typically, but something, some form of energy transfer that its environment is going to see as noise, as not informative.
 So a complex system is working very hard to predict its environment's next state.
 But by working very hard it's dumping a lot of entropy into its environment.

 And putting in that extra entropy makes the environment's behavior even harder to predict.
 So the more you work at predicting what the environment is going to do the more you yourself make the environment's behavior less predictable.

 And this is the paradox of the FEP, which is not really a paradox.
 It's just what the physics does.
 So we can think of the FEP by driving systems to increase their distinctness from their environments or to self evidence, as Karl Friston calls it, as driving this increased complexity that both makes predictions better and makes predictions harder by transferring entropy into the environment.
 So what this tells us is that the FEP by itself will drive the development of systems with larger and larger complexity.

 And this clearly has enormous implications for evolutionary theory which we'll talk about in October.

 But I want to emphasize here that this is just the physics.
 It's just what the FEP does when it's forced to maintain a boundary.

 And before stopping here, I want to consider one aspect of this in particular, which is language.
 For example, human language, but any kind of language connecting any systems that are communicating with QRFs that are fairly close.
 And language is a complex QRF that we basically share.
 Otherwise, things like this interaction would be impossible, but we also remain distinct systems.

 So the question arises, how do we manage to do this?

 How do we manage to largely share a QRF while escaping, becoming entangled?
 And this is a question that's largely been ignored in physics because physicists have tended to ignore language and just assume that observers can communicate classically.
 So, for example, in talking about a Bell/PR experiment, which is a canonical experiment for measuring entanglement, the observers have to be able to share their results, or they can't observe entanglement, right?
 The observed result is a bunch of observational statistics that violate Bell's inequality, and those statistics can only be computed given the results that both of the observers obtain.
 So the observers have to share language to encode these results.

 So how come the observers aren't entangled?
 How come they are still separable?
 What we end up appealing to is some sort of common cause in the past to explain why they share a language.
 They both learned it from their culture, so their culture is some sort of common cause.
 But all such assumptions are fine tuning assumptions.

 So they all have basically the status of the value of something like the fine structure constant, without which we wouldn't have atoms and so we wouldn't have us.
 This value has to be within very small limits of the value we actually observe.
 And that's a case of fine tuning.
 The universe seems fine tuned in a way that allows us to exist.

 And if it wasn't fine tuned in that way, we wouldn't exist, and so we wouldn't observe anything.

 But fine tuning assumptions are a problem.
 They're a pointer to something we don't understand.
 And so I just want to leave you with the point that we have to be very careful when talking about interacting observers.
 So in talking about two components of some system that jointly interact with some environment but also communicate classically, and if you think back a few slides, that's exactly the structure that we've shown that the physics forces any complicated system to have.
 So next time, what we're going to focus on is this very question of how we describe observers that are both interacting with the quantum system and communicating classically in some language.

 So that session will be in August.
 At the end of this month, there's a discussion of this session with Ander, and I encourage you all to use the interactive Q and A to ask questions.
 You've been asking very good questions that I hope I've been managing to answer.
 So thank you very much.
 And Daniel.

 Over to you.
 Cool.
 Well.

_Daniel:_
 We have a few minutes for some questions maybe and or if you want to bring up any questions first, then go for it.

_Ander:_
 I was curious if you could say any words on the slide where you had all the possible alignments of QRFs and what you meant more by interacting thermally.
 So when you have a trivial agent on one side, what exactly does it mean to say that you're interacting thermally?

_Chris:_
 If you think about a system that is only interacting thermally with its environment, you end up thinking classically about, for example, an ideal gas that's in some sort of container and some of the molecules are very near the surface and their motions depend on the motions of all the other molecules that are inside.
 So there's a set of internal states that interact randomly with the external states that are near the boundary and so those external states interact randomly with the boundary.
 But notice in thinking in this way, you've imposed a spacetime embedding, so you've actually used space as a way of separating the internal states from the boundary states.
 And a system that if you drop this assumption of a spatial boundary, then a system that's only interacting thermally with its environment is going to look like a system that doesn't have any real internal states.

 It's going to look like a system that just has boundary states.

 And so a pure thermal interaction is going to start to look like entanglement.
 So we're actually only really interested in systems that aren't interacting only purely thermally with their environments.
 We're interested in systems that have enough internal structure that they're using that thermal energy to do something internally.
 So to give their internal dynamics some particular shape, so that their internal dynamics is actually circling around some well-defined attractor that requires some energy to maintain itself.

_Ander:_
 Yeah, I'm continuing with that question.
 I saw in the paper free energy principle for Quantum Systems that if you're in that situation when both keras are nontrivial, but perhaps B's is larger than A's, A's perceives non-local hidden variables.
 So I wonder if there is a way to relate those by taking a limit of making A small and recover the thermal interaction.
 Presumably if you let A become small, you should recover that thermal interaction, so to speak.
 Right?

_Chris:_
 Yeah, that's a very interesting comment actually.
 So if you're a system and all of your environments variables are effectively hidden to you, then you can't do any information processing because you don't have any access to any of your system, your environments' variables.
 So yeah, your interaction can only be thermal.
 I think that's correct.
 Thank you.

_Ander:_
 Since we're in this, in this topic and we don't have to context switch in that way.
 On the other hand, you have noise, right?
 In one of those other situations, I can't recall which one.
 I guess in the reversed one, right.
 When A's QRF is larger than that of B, so it encompasses more of the boundary degrees of freedom, those that are not overlapping A perceives as noises.

 That's correct.
 Right?

_Chris:_
 Yeah.
 A will be looking at B's thermal sector, B's free energy sector.
 Right.

 So A may be interpreting, in a sense, what it's doing as informative, and A may even be seeing what B is doing as informative.

 So noise for B may be signal for A, depending on how a's QRF is structured, but A is seeing more information than B is trying to send it.
 So it's essentially the reverse of the hidden variable case.
 There are variables in the other system that aren't telling you anything about what the other system is actually doing.

_Daniel:_
 That's very interesting in terms of reading too much or too little between the lines, connecting too many dots or connecting not enough dots.
 But these challenges where noise for one quantum cognitive agent might be signal for another and vice versa, those are the challenges that we want to address...
 ...because to have a physics that doesn't recognize those situations is kind of taking the view from nowhere or not really addressing the complexity of a cognitive engagement.

_Chris:_
 Yeah, it's describing interactions between, effectively, systems that don't share the same language.

_Daniel:_
 I have a question about the free energy principle here.
 Only in the last several years has the quantum free energy principle relationship come into light.
 So maybe could you just share a little bit about what incremental or quantum advances enabled that to happen?
 Or what degrees of freedom were pre-existing or added to enable work arising from perception and action in neural systems to also so naturally enter this context with the quantum information?

_Chris:_
 Well, I think, at least from a historical point of view, that connection was made based on the analogy between a Markov blanket and a Holographic screen.
 So these are structures developed in different parts of physics that essentially serve the same function of limiting the information that one system can have about another system.
 So it's that functional analogy between a Markov blanket defined classically and a Holographic screen defined in quantum theory that made it seem obvious that we could translate the free energy principle into a quantum theoretic principle.

_Daniel:_
 Yes.
 In live stream 40, we talked a lot about this, but I think that remains one of the most remarkable advances inside or outside the free energy principle literature based upon this functional acknowledgment of boundaries and the conditions that they entail, which, again, are the challenges that we want to address lest we ignore boundaries.

_Chris:_
 Right
 Yeah, precisely.
 I mean, the free energy principle is all about what happens when you have a boundary.

_Daniel:_
 The waste heat.

 Is this the actual thermal exhaust from our CPU?
 Or how can we think about the heat being released topologically rather than geometrically, like the location where it's released?
 What does it mean to consider physical processes topologically that we might otherwise just use a geometric way of thinking about?

_Chris:_
 Well, you basically put your finger on it and that you're not worried about the spatial difference between the geometric spatial difference between where one kind of information flows through the boundary and where another kind of information flows through the boundary.
 And you can think about this in Markov blanket terms.
 And the Markov blanket is just a network.
 And some of the causal arrows flowing through that blanket network are effectively transmitting noise.

 And you can think in the same way with respect to a holographic screen if you're doing a certain amount of information processing.
 And this brings up the whole issue of how efficient is a system in its information processing?

 How close is it to the Landauder limit,
 basically.

 Can it extract more energy from some bits than it has to use to modify the states of other bits?
 That's what this, if you will, metabolic question is all about.

 In the case of an organism, is it, can I get more energy from some of the chemistry that I have access to than I need to use to modify the chemistry that I need to modify?
 And if not, then life stops.
 Everything grinds to a halt.

_Daniel:_
 Now, can the heat exhaust informationally be useful for another agent somehow?
 I mean, can't we recover heat in a steam engine and use it to do useful work?
 Not to the point of a perpetual motion machine, but how can we recover exhaust?
 And then what does the perpetual motion machine look like?

_Chris:_
 Well, the environment is the system sitting over on the other side of the boundary that is absorbing whatever waste heat is generated by the system.
 Let's call it Alice that we're interested in.
 So that environment may be Alice, and Alice can't tell this, but it may be divided up into lots of different compartments, some of which are basically sucking in Alice's waste heat and doing something with it.
 So this is really a question about how is the environment structured and what operations does the environment execute with the input that it gets?
 How does it interpret that input?

_Daniel:_
 And what would.

_Chris:_
 This gets back to this question about how do we talk about multiple agents that are communicating with each other instead of talking about an environment that we don't characterize at all?

 How do we talk about an environment that includes some specified or preferred systems that are treated as or known to be other agents?

 Let me get back to your question about perpetual motion machine.
 Notice that in classical thermodynamics there's always the assumption that there's a big environment out there the rest of the universe or whatever, the whole environment that's not on Earth.
 That is an arbitrarily large source of, or it's not an arbitrarily large source of free energy, but it's a large source of free energy.

 And it's a large sink for entropy, a kind of arbitrarily large sink for entropy.
 So the second law of thermodynamics says the entropy of this entire system counting the whole surrounding environment doesn't decrease, so it can increase and still satisfy the second law.

 So this gives you the classical 19th century heat death of the Universe idea.
 And so your proposed machine is sitting somewhere embedded in this gigantic environment that can provide some finite amount of free energy but can exhaust effectively an arbitrary amount of entropy.
 So any machine has to dissipate entropy as it runs to fill up this kind of arbitrary sink of entropy that's the classical rest of the Universe.

 Now, compare that to the picture in quantum theory.
 The picture in quantum theory is the universe, by definition, is an isolated system.

 So its total information content doesn't change, right?
 It's evolving...
 ...unitarily, unitary operations preserve information, so they're just moving information around.

 So from the point of view of any local system, the local system is getting information from its environment, so it sees its environment losing information, so gaining entropy.

 What this tells us is that entropy is, in fact, not a globally definable quantity.
 Entropy is always defined relative to some observer, some division, some boundary.

1: And this is another kind of big change in the last few decades and has led to, for example, entropic definitions of time.
 My local external time arrow is whatever direction I see entropy increasing the most.

1: So, again, I would refer to people like Rovelli and Max Tegmark, who developed many of these ideas.

1:_Daniel:_
 Awesome.
 All right, thank you, Chris, and Ander, looking forward to seeing everyone's questions submitted and their preparation and participation and measurement in the discussion section.
 So thank you.
 Till next time.

1:_Chris:_
 All right.

1: Thanks again, Daniel.
 Thank you.
 Ander, we'll see you later.

1:_Ander:_
 Bye.
