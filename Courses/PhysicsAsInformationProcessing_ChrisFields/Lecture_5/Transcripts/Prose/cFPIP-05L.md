---
title:  'Physics as Information Processing - Lecture 5, "Spacetime"'
author:
- 'Chris Fields (Allen Discovery Center at Tufts University) [![Orcid](images/orcid.png)](https://orcid.org/0000-0002-4812-0744)'
- 'Daniel Friedman (Active Inference Institute; University of California, Davis) [![Orcid](images/orcid.png)](https://orcid.org/0000-0001-6232-9096)'
date: "2023-09-14 Version 1.0"
...

# Lecture 5, "Spacetime"

_Daniel:_
 Hello and welcome, everyone.
 It is September 14th, 2023, and we are in the course: Physics as information processing.
 It's lecture 5.
 Looking forward to this lecture and then a little conversation.

 Chris, off to you.
 Thank you.

_Chris:_
 Okay.
 Thank you, Daniel.
 And, welcome to session 5 of Physics of information processing.
 And, today we're going to talk about Spacetime, and particularly about the idea that Spacetime is emergent from information processing.
 And, this has now become a very mainstream idea in the quantum information and quantum gravity communities.

 And there are still, of course, some people holding out for the idea that Spacetime is fundamental.
 But I would say that, at least in these communities, I expect it's become now the dominant idea that Spacetime is not fundamental, that Spacetime is not part of the basic ontology of reality or something like that, and that instead, Spacetime is a construct.

 So, that's what today's Session is going to be about.
 So, for those of you who are just joining or who would like a little review, we started this course talking about Quantum Information Theory and the idea that Quantum Information Theory is actually a new science about systems that communicate across a boundary.
 And, the systems are always called Alice and Bob for kind of historical reasons. And, we emphasized that this new science is topological.

 It's about connectivity between systems.
 It's not geometric.
 So, it doesn't assume a Spacetime embedding.
 So, it leaves open the possibility that Spacetime is actually a construct.
 It doesn't assume Spacetime up front.

 And, in the 2nd Session of the course, I think, we talked about how this boundary could always be represented as an array of qubits, and that what the systems on each side of the boundary do to communicate is prepare and then measure the states of these qubits.
 So, they communicate by exchanging classical information via a quantum channel.
 And, this introduces a particular kind of quantum noise whenever they don't share the reference frames that they use to prepare the bits and measure the bits.
 So, it's not necessarily a perfect communication channel from a classical fidelity point of view, but all of the noise is quantum noise.

 It's not classical, and it always derives from differences in the reference frames that are used by the two agents.

 We reformulated the Free Energy Principle in this setting, and the Free Energy Principle turned out to be very simple.
 It turns out to be a classical limit of the Principle of Unitarity, which is just the principle that information is conserved.
 And, we saw that the approach to perfect alignment between the two agents, or perfect prediction on the part of the two agents, becomes more challenging.
 Not surprisingly, as system complexity increases.
 So, the more complex the communication, the harder it is to predict, as one would expect.

 In the last Session, we talked about how constraints on thermodynamic free energy induce compartmentalization in agents.

 So, whenever agents interact with their environments in fairly complex ways, then they end up being compartmentalized into compartments that have to communicate classically.
 And, this is solely a result of Quantum Information Theory.
 You don't have to assume any biology to get this compartmentalization, but clearly, this is something that we see in biological systems.
 Not only do we see compartments, we also see hierarchical control, which is likewise a sort of automatic outcome of the theory for complex systems.

 And finally, last time, we talked a little bit about how these compartments communicate and introduced the idea of communication protocols that involve local operations on a shared quantum resource of some kind and classical communication.
 We talked to fair amount about how classical communication is a little bit problematic to define in Quantum Theory, because, of course, you're introducing classicality.
 And so, you have to make some very specific assumptions about what's classical.
 And, we'll see later on today what the key assumption that gives you classicality is, as we talk about Spacetime.

 But before I go into the topic of Spacetime, I want to spend a little time.
 Okay, sorry.
 This is where we're going.
 We're talking about Spacetime, and we'll talk about applications to biology next time.
 But before we get going on this, I want to spend a little bit of time talking about the explanation.

 And, this is motivated by a question that came up, a very long question that touched on many different topics that came up in the interactive Q&A last time.
 And, a fair amount of that question had to do with, directly or indirectly, the question of what scale-free explanation looks like and how it compares to scientific explanation in general, most of which is reductive.
 So, I want to make a short detour into the question of how reductionist theories, which all of you are probably very familiar with, relate to scale-free theories, and particularly the Free Energy Principle is a scale-free theory.

 So, it's a theory that's unlike most of the theories that most of you probably learned about in college.

 So, we're all familiar with reductionist theories and the reductionist idea of scientific explanation, which is really an outcome of the Philosophy of Science in the 1920s and 1930s.
 People like Rudolph Carnap were among the first to actually make precise what this idea of reductive explanation is.
 But the basic idea is that the laws or the dynamics or the formalism that describes the behavior at some microscale, the behavior of little things actually explains the behavior of big things.
 So, the basic reductionist idea is that what the little things are doing is what's important.

 And, what big things are doing are either emergent phenomena, or they're just epiphenomena.

 They're essentially just appearances.
 And, this defines a fundamental scale.
 So, the real assumption in any reductionist theory is that there's some fundamental scale at which the "real dynamics" takes place and everything else is just an appearance, or it's some sort of emergent phenomenon.
 And, I try to be very careful when I use the word "emergence" because it's one of the most ambiguous words in the Philosophy of Science.

 And people use it to mean all sorts of different things.

 But whenever you say "emergent", it always sort of implies the idea that it's emergent from something.
 And, so the idea of emergence is essentially a reductionist idea because it at least implicitly assumes that there's some microscale from which the macroscale is emergent.

 And so, the discussions of emergent phenomena are often very consistent with reductionism, even if they claim not to be.
 And, we're all taught that science is reductionist.
 And, there are certainly people who publicly claim that science is reductionist.

 Richard Dawkins is certainly a shining example of this.
 But I suspect that a lot of scientists just kind of play lip service to reductionism without really believing in it, because they don't really believe that the macroscopic phenomena that they are studying, life, for example, is completely determined by what's going on at the microscale, or what's going on at the microscale, plus some stochastic noise or something like that.

 So, I want to explicitly contrast this with a scale-free theory.
 In a scale-free theory is not simply a holistic theory, it's much more precise.
 In a scale-free theory, little things and big things obey the same laws, or they have the same dynamics, or they're described by the same formalism.

 So it's not that the macro scale is emergent from the microscale.
 The macro scale and the microscale actually obey the same laws.
 And, the relationship between macro and micro is probably best stated as one of implementation.

 Macro scale things have microscale components, and those microscale components are doing something or other.

 And, whatever they're doing implements the macroscale system and its behavior.
 But this implementation is not an explanation, or at least it's not an explanation all by itself.
 And the bumper sticker version of scale-free theories is just as above, so below. Whatever laws you have at the macro scale, are the ones, the same ones you have at the microscale, and vice versa.

 So, scale-free theories, in a sense, are simple.
 It's the same theory at every level of description.
 So, what is this idea of scale, and how does it relate to what we've talked about in this course?
 Well, what we've talked about in this course all has to do with what an agent can observe on its boundary.
 So, scale has to do with how information is encoded on the boundary, and we can describe that scale in many different ways.

 Here's a commonplace way to describe it in Physics by a relationship between energy and distance, or size.
 And, you've probably all heard of the Planck scale.
 The Planck scale is the smallest scale at which current Physics makes any sense.

 And, in energetic terms, it's defined by energies on the order of 10 to the 19th GEV, which is gigaelectronvolt.

 The LHC (the Large Hadron Collider) in Switzerland gets to about 10 to the 4th GEV.
 So many, many orders of magnitude less than the Planck scale.
 So the Planck scale is extremely energetic compared to what we can probe experimentally.
 The Planck scale energy of 10 to the 9th GEV corresponds to a distance of about 10 to the -35 meters, which is incredibly tiny.

 An intermediate scale on this diagram is about the scale of a nucleon.

 So, for example, a proton or a neutron, they have a rest mass of about 1 GEV and a size of about 1 femtometer.
 So, this intermediate scale is roughly the scale of nucleon Physics.
 And, then if you go to our scale, the scale of things that are about a meter in size, human beings, tables, and chairs, lots of animals, the things we're most familiar with, that corresponds to an incredibly tiny energy 10 to the -5 electron volts, which is about the energy of a photon of radio... radiation. And, a meter is about the wavelength of long wave Radio.
 So, if you think about visible light, it has a wavelength of about 10 to the -5 meters, an energy of about an electron volt.

 So, it's not surprising that visible light feels energetic to us because it's orders of magnitude above our natural scale of energy of this sort of thermal environment in which we exist.
 So, it's the encoding scale and the boundary that is going to relate theories of things that we see to each other.
 And, this ends up giving a kind of complicated picture.
 If you think of Alice interacting with Bob and measuring things on the boundary...

 Sorry, I'm a little bit ahead of myself.
 I just wanted to show you a picture of a Reductive Theory.
 This is the Big Bang.
 You're all familiar with this.
 Something happens at the Planck scale, and the entire universe results from it by just a scale change.

 So this is a Reductive Theory.
 A scale-free theory is much more complicated.
 So here's what a scale-free theory looks like.
 Alice interacts with Bob, and she's looking at her boundary, and her boundary states, the boundary states she sees could be encoded at different scales.

 So, there may be a small-scale scale1 and a bigger scale scale2.
 And, what Alice is looking for is some sort of theory that relates the first scale, the microscale, to the macro scale.

 So, it's not that the microscale came first like it did in the Big Bang, and the macro scale came later.

 These are encodings that can be happening simultaneously.
 And the theoretical task is to find theories that relate between these scales.

 And these are implementation theories, or you might call them embedding theories from one scale into another.
 And what we want as a consistency criterion is for these theories to be constant in time.
 So as Bob evolves in time and what Alice sees are these encodings on her boundary.
 She wants the relationship between encodings at different scales to stay constant, because if it doesn't, she'll never be able to figure anything out.
 She'll just have this chaotic relationship between things happening at different scales, and nothing will make sense.
 So, you have this complicated picture in scale-free theories.
 And, if you look at this and it seems vaguely familiar, or even vaguely... even very familiar then it should, because this is exactly the kind of explanatory structure or semantic structure that you have in Computer Science.

 If you're studying the behavior of a computer, which is just some piece of hardware, some physical system, then you can describe what that piece of hardware is doing at different scales.
 And, in fact, what we call "the hardware level of description" when we talk about our laptops, for example, is typically the level of description of circuits and transistors inside microprocessors.
 We think of that as "the hardware level".
 But of course, that's just a description, too, that's layered on top of lots of much smaller scale dynamics, all the way down to the scale of atoms and eventually nuclei and elementary particles and all that other stuff.
 So, there's some quantum stuff that's going on that we describe as having a classical hardware level of bit exchange.

 And then, we describe the behavior of programs on top of that.
 So, what we want, what makes a computer useful is that we can assign semantics to programs, and we can talk about semantic relationships between programs.
 For example, the relationship between the internet protocol stuff that Zoom is doing and what you actually see on your user interface and hear on your user interface. That needs to stay fixed over time or Zoom becomes incomprehensible and not programmable and, in fact, not even well defined as an algorithmic system.
 And, the same is true for the relationship between the operating system and the hardware description, or between the operating system and Zoom as a program.

 So, Computer Science works in exactly this scale-free way.

 And so, in a sense, the scale-free explanation is very familiar.
 It's exactly the kind of explanation that we have in Computer Science.
 And, that's why I referred to the relationship between scales as one of implementation because that's a term that we're familiar with from thinking about computers implementing programs.
 So, what are these theories?

 If we think in biological terms, we can think of pathways being embedded in a cell, or cells being embedded in tissues, all the way up to niches of various kinds, which may be social niches being embedded in ecosystems, and ecosystems being embedded in the biosphere.
 And so, we have all of these essentially semantic theories that talk about how one scale embeds in another scale.

 And, if we have these sorts of scale transitions, we can think of representing the relationship between transitions at different scales in terms of the activity of some kind of renormalization group, which is transforming entities and processes at one scale into entities and processes at another scale.
 And I think in Biology, we can at least put forward the hypothesis that in all the way from pathways embedding in cells to ecosystems embedding in the biosphere, we could put forward the hypothesis, at least, that the renormalization group flow across all of these scales is trivial.
 That is that the embedding theories all have the same formal structure, that the structure that describes how pathways embed into cells is the same structure that describes how ecosystems embed into the biosphere.

 Now, I certainly can't prove that.
 I believe that it's likely.
 So, I think it's an interesting hypothesis to investigate.
 And, this is a hypothesis that I want to leave you with as a result of this class is something to think about.
 To what extent, in thinking about biological systems or even social systems, are the embedding theories the same?

 So, in thinking this way, that the physics of the situation has the same formal structure as Computer Science has in terms of explanation, we're of course, faced with a problem, which is that we're not just reconstructing physics, we're talking about the physics of interacting observers.

 We're talking about the physics of communication.
 So, we're modeling how we do physics.
 And, that makes our theory self-referential.
 And so, we have to face the music from Gödel's theorem, which tells us essentially that powerful self-referential theories can't be both consistent and complete.

 And, by powerful I just mean powerful enough to express arithmetic, so, not terribly powerful.
 So, this becomes an issue that we have to live with.

 We will always be faced with this issue of having to construct meta-theories which tell us how our lower-level theories work, but we never get to the end of that process.
 We never can get to theories that are both consistent and complete, because our tower of theories becomes progressively, actually more powerful as it goes up.

 So Gödel, in a sense, poses a problem, but in another sense just tells us what life is like as a scientist, that you can't have everything all the time doing science, but we probably all already knew that.
 So, let's now talk about space, end of digression, and see how these ideas apply to a system or a tower of systems that can construct a spatial embedding in its world, in its observed world.
 So, let's start out thinking about a system that can see its environment, but what it sees is a completely uniform environment where nothing is happening.

 So, if you have a uniform environment where nothing is happening, you can't distinguish one part of the environment from another.
 You have no sense of space.
 So, what I want to do is build up from scratch what's needed to have a sense of space, and then we'll talk a little bit about what organisms are doing.
 And I think a very interesting question is, if you look at phylogeny, at what points in phylogeny, what lineages in phylogeny actually need to have a sense of space, and what do they have to have in terms of computational power to have that sense of space?
 So, if you just have a uniform environment, you don't have a sense of space.

 But the first thing we can do with an environment is to divide it up into some number of parts that are somehow distinguishable.
 So suppose we can segment the environment into two different parts.
 And if you think about E.Coli, for example, E.Coli has a bunch of sensors on the front and a bunch of effectors on the back. So, it can sense much more about the front part of the environment than the back part of the environment.

 So, already with E.Coli, you have this kind of segmentation of the environment into parts, but so far, nothing is happening in this environment.
 We just have segments that can be distinguished.
 So, let's consider an environment like this, that has distinguishable segments.

 What one next wants to know about these segments is whether they're next to each other.
 And, if we just have a bunch of segments, we just have a set, and a set doesn't have any order or any relationship information.
 So, I've drawn this environment as a rectangle of rectangles, but that's just a representation.

 And, it looks like there are relationships between these rectangles, but if they're just a set, then there are no relationships.
 If we want to add relationships, then we have to add them explicitly.
 So, let's add some connections between these different segments of the environment to turn that set into a graph that says explicitly, for example, that the light green segment is attached to the light blue segment, and it's also attached to the dark green segment, and the dark blue segment is attached to the light blue segment and attached to the dark green segment.

 So, now we have something that's much more mathematically complicated than a set.
 We have a graph that has some connection information.

 So, we have a connection topology.
 Now, adding this topology does something very important.
 It breaks the exchange symmetry that is there if you just have a set.
 So if we just have a set, it doesn't make any difference if I exchange, for example, the positions of the upper right light blue segment with the upper left light green segment.
 But if we have this connection topology, then it does make a difference.

 Right, I've twisted the graph around, and if I have to break connections to exchange things, then I've actually changed the topology.
 So, adding a topology, adding connections, can disrupt a symmetry that's there if there is no topology.

 So, now let's think about, now we have the structure that's required to think about something happening.
 So, suppose that at some time, as measured in the bit counter time reference frame of the observing system, something happens.
 So, a dot appears in the light green segment.

 And, we can express this actually in the notation of quantum field theory.
 We can think of the light green segment as a field and the dot appearing is the occurrence of an excitation in that field.
 And so, we can write this notation that says that the green field was excited to produce a dot which is up arrow green dot.

 And, sometime after that it may turn out that the dot disappears in the green field and some sort of dot appears down in the dark blue field.

 And again, we can write this in this kind of creation and destruction operator notation that one has in quantum field theory.
 And so, this says that the green field is no longer excited, but now the dark blue field is excited.
 So, this doesn't imply anything about these excitations being the same.
 In fact, they're completely different.

 One is an excitation of the green field and one is an excitation of the blue field.
 But at least now something is happening in the environment.
 So, we can think about what does it take for an observer to notice that something is happening in its environment?
 It has to be able to detect a change occurring in some segment of its environment, and that change can involve something happening or something stopping happening in that segment of its environment.

 But it doesn't yet have to have any idea of what an object is.

 But we can add that if the system has a memory, we can have the system connect these events happening in different parts of its environment.
 So, if the system has a memory that has some number of steps, I'll say n steps, but here it could even just be 2 steps.

 It can see transitions between these two different states, where there's a dot in the green field and then a dot in the dark blue field, and then a dot in the green field, and then a dot in the dark blue field, and then a dot in the green field, etc.

 So, I've expressed this in this sort of field theory notation over on the right side.
 And, what this is is a flip-flop.
 It's an observed periodic behavior.
 So, this is the basic idea behind a clock.

 So, any observer that can see this number of time steps internally can interpret what's going on in its external environment as a clock ticking.
 It can see some periodicity.
 So, as long as you can have memory and the ability to detect change, you can see periodic behavior in the environment.
 So, you can see the environment acting like a clock.

 So, let's think a bit about what this does and does not require.

 So, seeing a clock in the environment requires having distinguishable, non-exchangeable sectors of the environment.
 So, you have to have this connection topology that breaks the exchange symmetry.
 It requires having these sectors implement some sort of flip-flop.
 So, something periodic happening, and you have to have enough memory to see that periodicity, but it doesn't require any sense of object identity.

 So, the excitation in the green part and the excitation in the blue part can still just be field excitations of the green part and the blue part.

 There's nothing that says that those have to be the same thing.
 They just have to appear and disappear in some periodic way.
 And, having a clock doesn't require a metric space.

 You don't need to have any sense of distance defined by the environment.
 You just have to have this segmentation that is not rearrangeable.

 So, this tells us something extremely important, which is that time is more fundamental than space.
 Time in the exterior environment is much simpler and easier to observe than space in the exterior environment.
 So, if we're thinking biologically about phylogeny, we might expect to see organisms that can detect periodic behavior in the external environment long before they can detect spatial organization in the exterior environment.
 And, we know that organisms, even down to microbial mats, can respond to the diurnal cycle.
 So, we know that organisms, in a sense, can detect environmental clocks, even organisms that we have no reason to believe, divide the environment up into spaces or the sort of space that we're used to, like a Euclidean space.

 So, adding space to this idea of time in the environment.

 So, the next step is to be able to see motion. And, being able to see one thing move from one segment of the environment to another segment, as opposed to something happening in one segment, and then something happening in another segment.
 One has to have this idea of object persistence, that there's a thing that has an identity, and its identity doesn't change over time, and it doesn't change when you move it someplace else.
 When it appears someplace else in the environment, it's the same object.
 So, this is an idea that psychologists call "object persistence", and it's an idea that physicists call "translational invariance".

 Translational invariance means two things.

 It means that if I have an object and I move it to a different location, I don't change the object.
 It's the same object that I move from here to there.
 So, the location doesn't change the object.
 And, it also means the reverse of that.
 It means that the object doesn't change the location.

 My container remains invariant even though I move the object around in it.
 So these are kind of the two phases of translational invariance, and they're the two faces of object persistence.
 As the object moves through time, its identity remains fixed, and it doesn't change the time that it's moving through.
 So, if I'm measuring its motion with a clock, moving the object doesn't change the clock.

 These are clearly very classical ideas.

 And, we talked about earlier classical communication.
 And, when we talked about classical communication in, for example, the context of a Bell EPR experiment, we talked about the observers being able to write down some data on a piece of paper or on a disk drive or something and hand those data to someone else.
 So, this is translational invariance.
 The data can't change when Alice gives it to Bob.
 Otherwise, there isn't classical communication taking place.

 And of course, there's an up to noise built into here, right?
 The piece of paper might get wet and the ink might run a little bit, but it's still the same message.
 There's still some identity being assumed.

 So, object persistence is not an idea we get from Quantum Theory.
 It's an idea that we impose on top of Quantum Theory.

 And, it's this idea that's intrinsically classical.
 So, we're looking right here at the quantum to classical transition.
 This is it.
 This is what gets added to Quantum Theory to get classical physics.
 It's this idea of object persistence.

 Now, once we have object persistence, we can kind of go to town constructing space, and here's how we do it.

 We all learned about object persistence this way when we were six months old, doing motor babbling and observing our hands and feeling how our bodies worked and seeing objects that we could manipulate and that didn't change when we manipulated them.

 So, this is the birth of object persistence.
 This is the birth of classicality in human psychology.

 So, now let's start thinking about building a coordinate system.
 What's a coordinate system?
 A coordinate system is just a set of labels that are attached to these segments of the environment.
 And, to build a coordinate system, you have to have an origin.
 And, an origin means an object, something that's fixed, something that doesn't move around.

 And, so a coordinate system requires the ability to identify a stigmergic memory. It requires the ability to find something in the environment that has a meaning that stays constant over time.
 And, that's what a stigmergic memory is.
 It's something in the environment that provides us with a memory resource that we can count on being the same.

 And, it's having this fixed point that allows us to label these connected segments of the environment that contain objects that move and be able to say, okay, the object moved from this part of the environment to another part. And, I can give those parts labels with respect to this other part that doesn't move, this origin point.

 And, once I have this, I can construct other invariances.
 So, for example, I can consider an object that rotates around this origin without changing its identity. And that defines what's called rotational invariance.
 And, I can also talk about an object that gets bigger and smaller compared to this fixed point and that defines radial distance.

 And, if you think about the baby in the previous slide that's doing motor babbling, it sees things getting smaller as it moves them farther away. So, the visual system does this computation for us and constructs this radial coordinate for us with respect to our bodies, or specifically our heads, our eyes.
 So, in doing this very early motor activity, we're actually building the spatial coordinate system for our brains that's implemented by the hippocampus, the place cells in the hippocampus.

 And, if I have an origin point in the environment, I can also infer that I am moving, that I have changed my location with respect to that object.

 And, that's a considerably more complicated inference because you have to have a representation of the self of you to say "I moved".
 So, this is something that comes after you've developed this spatial coordinate system.
 You have to be able to locate, in a sense, metacognitively, a particular object that's you in that coordinate system.
 So, we're going to set that aside and now talk about adding some numbers, so, adding a metric. And, adding a metric requires another particular kind of object, which is a ruler, a particular fixed object that can be moved around and that has translational invariance, and rotational invariance up to some transformation, up to some tensor.

 And, in Euclidean space, that tensor is the identity.
 So, in Euclidean space, you have perfect translational and rotational invariance.
 As you get into general relativity, then the ruler can actually change its length as you rotate, or the ruler can change its length as it moves through space.
 So effectively, your spacetime can deform, the coordinates of your spacetime can deform, and that gives you the representation of mass, of course, in general relativity.

 So, we talked several sessions ago about quantum reference frames, and I used the example of rulers and clocks as quantum reference frames.
 So, now we see how to construct those from observations and symmetry breaking and object identity, all of which we need to define a quantum reference frame out in the environment, like a ruler.

 And, notice that we don't need any of that environmental stuff to define those QRFs within our own processing.
 And in fact, the ones that exist within us, we have no direct access to.
 We can look at someone else's brain and talk about their spatial representation system, but we can't look inside our own brains and talk about our spatial representation system.

 So, this is how we get a metric space from the ground up.
 And, we've talked about this from a very psychological or biological point of view: starting from sort of motor capabilities, motor babbling, for example, a measure of effort which gives you some sense of mass.

 So, if it's easy to move something, it's light, and if it's hard to move something, it's heavy.
 And, we understand that when we're six months old because we can measure how much force we're having to apply with our muscles.
 We have a reference internally for this force that we're applying, and we use that internal measurement to attribute this idea of mass to things in the environment.

 We have to have memory from manipulations.
 We have to be able to identify invariances that define object persistence.
 And we have to be able to build a ruler that we can move around and use to define a metric space.
 Now, this is very different from the way physicists approach this.
 If you look at the physics literature, people start with information transfer.

 They talk about entanglement as a basic resource.

 There's a lot of discussion of bulkboundary duality.
 And, the most well-known one is the duality between anti-de Sitter space, which is the sort of space you see inside a black hole, and conformal field theory, a quantum field theory on the boundary of the black hole.
 So, how things you can see, for example, going on, on the horizon of a black hole are dual to the geometry and the interior by this mathematical relationship. You can use that mathematical relationship to construct quantum error-correcting code by using the symmetries of the field theory as a resource for redundancy that allows you to represent the same thing in different places.

 And, as soon as you can do that, you can build up a network of elements that look basically like elements of a lattice.
 And, a lattice is a graph to which you can assign symmetric relationships, and you get a metric space.
 And in physics, typically, the goal is to get Einstein's equations out of this to start with some information-theoretic sorts of constructs and get the equations of general relativity.
 But what are the equations of general relativity?
 These are things that Einstein derived by doing fairly simple thought experiments, using the invariances of ordinary Euclidean space, combined with ideas from special relativity about the speed of light being constant.

 And, he added the Principle of Equivalence, which is the idea that essentially mass and acceleration are the same thing, or that gravity and acceleration are the same, that weight and acceleration are the same thing.
 So, it's at least reasonable to expect that this inferential process that's going on in theoretical physics is generating the same thing, although in a very formalized way that we can generate by thinking about how organisms deal with their environments.
 And so, I want to leave this with you as the second hypothesis here.

 The first one was the hypothesis about a trivial renormalization group flow across scales and biology.

 The second hypothesis is that these two approaches to emergent spacetime are actually giving us the same information.
 And, maybe starting out with the same information, in fact, that we may be able to think about these fundamental building blocks of information flow and entanglement in terms of the sorts of perceptual relationships that we've been talking about in this class.
 So there's our second hypothesis to think about going forward.

 And I just want to leave you with the idea that organisms at least manage this very interesting process that we can think of starting with the construct of memory.

 Organisms have memory at multiple scales, and it's memory that allows them to formulate the idea that there are objects.
 And, as soon as you have objects that persist, you have a source of redundancy.
 So, you can do error correction.
 And, if you can do error correction, if you can move the same thing from one place to another and have it encode the same information, then you can build spacetime.

 And, as soon as you have spacetime, you can use the spacetime as more memory.
 You can use the spacetime itself, as the error correcting code because spacetime has the nice ability to hold lots of copies of some informative structures.
 So, you can build libraries, or you can build computers, or you can build the internet, if you have spacetime, which gives you more memory, which gives you more object persistence, which gives you more error correction.

 And, the circle just spins around.
 So, organisms do this, and the question is, how does it get off the ground?
 And, next time, we can at least speculate about that kind of origin of life type of question in the context of the FEP and its realization in simple systems of communicating observers.
 So, as always, I encourage you to use the interactive Q&A.
 The 5th discussion session with Ander, who's unfortunately not here today, will be the last day of September, Saturday 5:00, as usual, European time, California time.

 And then, the last session of the class will be the 12th of October.
 So, thank you very much, and I look forward to your questions in the interactive Q&A.

_Daniel:_
 Awesome.

 Thank you, Chris.
 Can I ask some short questions?

_Chris:_
 Sure.

_Daniel:_
 All right.
 So, first Lana wrote: is the periodicity, the time lengths between and during the excitations built in?

 So this was when we had the four cells and there were the inklings of a clock coming into play.

_Chris:_
 I think the simplest answer is that if nothing else is happening in the environment except this periodic behavior, then it's not actually meaningful to talk yet about the time between the events.
 So, if I have a system that's quasiperiodic, for example, and nothing else is going on in my environment, then I can't distinguish that from a perfectly periodic system because I would have to have a perfectly periodic reference to know that the other system was aperiodic.

 And, if you think about the internal clock being driven by information flow into the system, then something has to be happening in the environment for information to be flowing into the system and being counted.
 So, again, as we talked about a few sessions ago, the internal memory only gets updated when something happens.
 So, internal and external get tied together.

 This is why we can use external clocks, but it's also why we depend on external clocks because our intuitive sense of time is very malleable.
 And so, we actually, as humans, use external clocks to correct for the malleability of our own intuitive sense of time.

_Daniel:_
 Wow.
 And there's probably a lot to be said for that procrustean nature of having the chronometer, the clock on the wall, and the tick, tick, tick as an evolutionarily novel ruler of time, playing a logistical role in time bound society.

_Chris:_
 Yeah, think of earlier clocks that earlier cultures have used and that animals use.
 I mean, we have the solar clock, the lunar clock, etc., and the orbit of Venus clock that was so important to the Mayans and so on.
 So there are lots of available clocks in the environment if you have the ability to notice them and enough memory to realize that they're clocks.

_Daniel:_
 Awesome.
 All right, here's a question from Upcycle Club.

 They wrote: how does representing the network structure and dynamics with quantum embeddings affect the semantic interpretation of the network?

_Chris:_
 The embedding theory is the simplest semantic interpretation of the network.
 So...

 And again, a good way to think of this is through the lens of Computer Science.
 As soon as you have a programming language that allows variable binding, then you've built a very simple kind of semantics into the language.

 If you have X as a variable and you have variable binding, then at different times in the execution of the program, X can have different causal consequences for downstream computation because it's been bound to a different value, so it has different semantics.

 So, the semantics of X, again, go back to Gregory Bateson.

 The basis of semantics is differences that make a difference, make a difference to behavior, make a difference to actionability.
 So, variable binding gives you differences that actually make a difference to what the program does.
 So, what is that?
 That is the semantics that's assigned by your embedding theory between what the programming language is doing and what the operating system is doing and so forth.
 And, I think it's no surprise that the semantics of programming languages end up being represented with these very general mathematical constructs like Category Theory, which are essentially tools for representing arbitrary relations between systems.

 And, that's what embedding theories are.
 They're theories that state relationships between systems.

_Daniel:_
 Awesome, and very provocative to explore on the biological and life and on the spacetime and matter sides, which are of course, seamlessly integrated through, if only our own experiences.

_Chris:_
 Yeah, this is another place where it's useful to go back to this difference between reductive theories and scale-free theories.
 Scale-free theories are all about semantics because they represent the existence of stuff happening at different scales.
 And so, they naturally raise the question of what are these relationships, what are these embedding theories?
 And, in reductive theories there's a very deep sense in which semantics doesn't matter.

 If you think that all that's going on that's important is the stuff that's going on at the Planck scale, then you don't need any semantics, right?

 You see this in the late 60s, early 70s, old-fashioned AI, where people talk about computation, is purely syntactic.

 And, this is a very reductionist view of computation.
 It leaves out the semantics, and without the semantics, the computation is useless.
 It doesn't tell us anything at all unless we can map it to something.
 So, we have this philosophy of science tradition that tells us that semantics is not important, and we end up with tools like the FEP that essentially tell us that semantics is all important.

 And, from a biological point of view, the most natural response is, of course, we knew that all the time.
 That's why we're doing biology.

 So all of this ties together.

_Daniel:_
 Would you say that FEP says semantics is important, and then what does it say about what semantics are important?
 Or is that entirely left up to the modeler?

_Chris:_
 Well, it tells you a lot about what's important for the system itself, right?
 The system itself is dealing with its environment and it's trying to increase its predictive power.
 So, it's building a theory of the environment, and that theory is intrinsically semantic, right?
 It's about the environment and it's actionable.
 The theory is meant to drive action on the environment that will either yield more information or get the environment to behave, to do what I'm predicting it's going to do.

 So, I think the FEP is intrinsically semantic in that sense, that it's about an agent modeling its environment.

_Daniel:_
 Yes.
 And about the semantics of action, as opposed to a partial or limited semantics of passive inference or semantics of abstraction, which kind of leaves the important link between the agent and the environment through sense-making and decision selection basically unaddressed because it's kind of Descartes in the thought experiment in the room.
 And here, when we actually engage with the boundary of the room, that's where we start.

_Chris:_
 Yeah, yeah.

 The FEP completely destroys this classical notion of the passive observer, as does Quantum Theory.
 There are no passive observers in quantum theory.
 So, this is a construct that we inherited from a classical worldview that is seriously misleading.

_Daniel:_
 A lot more to say, but that's a great place to end.
 Thank you, Chris.

_Chris:_
 OK.
 Thank you, Daniel.
 And thanks to you all.

 And ask questions.

_Daniel:_
 See you next time.

_Chris:_
 Cheers.
 We'll see you next time.
