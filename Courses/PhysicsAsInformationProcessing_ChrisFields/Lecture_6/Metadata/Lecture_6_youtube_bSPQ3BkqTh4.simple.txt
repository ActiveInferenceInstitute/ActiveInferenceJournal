SPEAKER_00:
Hello and welcome everyone.

It is October 12th, 2023, and we are in the final lecture, session six in physics is information processing with Chris Fields.

So Chris, thank you for this journey.

Exciting to get to this final lecture, which will be followed only by the last discussion for this go around.

So it's really awesome.

And to you for this lecture.


SPEAKER_01:
Thank you, Daniel, and welcome everyone to this last session that I'll be doing with a focus on biology.

And just to give a brief review, as usual, we've focused in this course on generic quantum systems, by which I mean just any quantum system that has some number of degrees of freedom.

And we really haven't made any assumptions about these systems other than the assumption that both interacting partners have sufficient degrees of freedom that they can be considered separable.

So their boundary is small with respect to the total size of each of the interacting systems.

And I want to emphasize again that the approach we've taken is completely topological, so we haven't assumed anything about embedding in space.

And as we've characterized these systems, we focused really on two things.

One, the amount of information that the two systems can exchange.

And that amount is determined by the size of their boundary.

It's determined by this number N, which is the Hilbert space dimension of the boundary.

And as we've discussed now in several of the sessions, we can think of this boundary as a collection of N qubits via which the two systems A and B communicate.

The other feature of the interaction on which we focused

is the reference frames that are used by the two systems to interact with this set of qubits.

And it's these reference frames that assign the information that flows between A and B meaning or functional significance or actionability or however you want to refer to

the idea that when a system gets some information, it does something useful with it.

So those are very generic kinds of ways of characterizing an interaction.

You can think of it as a qualitative characterization, the semantics of the information, and a quantitative characterization, the amount of information.

But other than that, we've left the nature of these systems open.

And this characterization allowed us to reformulate the free energy principle in quantum information theoretic terms as the principle that interacting systems behave in a way that will asymptotically align their reference frames.

And we saw that

full alignment of reference frames is equivalent to entanglement.

So the FEP drives systems toward entanglement, which is not surprising because that's what happens to generic quantum systems.

They may start out separable, but if they interact long enough, they'll become entangled.

So we've had a discussion that is really very generic.

Now, we showed a couple of sessions ago that under these very generic assumptions, we got some interesting outcomes.

And one is that if systems have sufficient degrees of freedom, under the action of the FEP, they will be driven toward making

a diverse set of measurements of their environment because they're trying to get information about it so that they can predict what it's going to do.

And that as they add ways of making measurements, they'll come up against non-commutativity of their measurements.

And this may be due to intrinsic mathematical facts about their measurements, and it may just be due to their limited supply of free energy.

So either way, what this induces is compartmentalization and the requirement for internal classical communication on internal boundaries.

So I just wanted to reemphasize that this is a result of basic physics, and we see compartmentalization, of course, ubiquitously in biology.

But this suggests to us that features of biology that are very familiar actually follow from fairly deep physics, and compartmentalization is one of them.

We then talked last time about space and time and the computational requirements

on any system that is able to perceive an external clock or perceive an external spatial layout.

And we discussed these from a very kind of developmental psychology point of view.

We discussed it using essentially the kinds of terms on the right here.

as opposed to the kind of language that's much more technical and mathematical that's used in physics to derive spacetime as emergent from information transactions.

But we at least hypothesize that both of these are ways of getting to the same sense of emergent spacetime.

And one important outcome of this discussion was that systems can perceive external clocks, so external periodic behavior, with fewer computational resources, so before they're able to perceive spatial layouts.

And we'll get back to this later.

So organisms and maybe other complex systems seem to manage

a collection of capabilities that are all mutually dependent.

So memory depends on having layouts of persistent things that can be distinguished.

So it depends on space, and it certainly depends on time.

Space gives structure to persistent objects.

Memory allows you to identify persistent objects.

And objects, in turn, give structure to space by being located in different places.

And objects enable the fundamental requirement for memory, which is some form of error correction, so that one has enough redundancy

in the memory to check to see whether a memory has been degraded.

So organisms seem to manage a physically very important process, which is the use of space-time and memory as a basis for cognition.

You'll recognize these four functions that are mutually interdependent.

as underlying complex cognition across the board.

And you can't really do complex cognition unless you have these capabilities.

So today we're going to put some of these things together in a discussion of biology and end by looking forward to future directions, not just in biology, but in all of quantum information theory.

So let's talk about biological systems, living systems, which of course includes us, but also includes all other organisms and communities of organisms and so forth at multiple scales.

And I want to put forward a fairly radical hypothesis that living systems are just generic quantum systems

that the FEP has driven to a high level of computational complexity.

So what does this really say?

It suggests that living systems are just quantum systems that have enough degrees of freedom and a sufficiently complicated internal dynamics

that the FEP, by requiring them to predict what their environment is going to do next, has driven them to make complicated measurements and complicated inferences on the basis of those measurements that enable fairly complicated actions on the environment.

So these are systems that you would characterize as computers, essentially, information processing systems,

with a high degree of computational capability.

Now this is clearly as much a philosophical hypothesis as an empirical hypothesis, and that's due in part to the fact that we don't really have a good definition of what a living system is.

We can just point and say that's a living system and that thing over there isn't.

But beyond that, we don't have much of the theory.

And of course, people have worked on a theory of what is life for decades.

But there's not a lot of agreement.

And so this is, in a sense, a definitional kind of hypothesis, and we test such kinds of hypotheses by seeing if they're useful conceptually to help us understand what living systems are doing.

Now, as soon as we put forward something like this, inevitably the question comes up, are living systems really quantum systems, or are they classical in some intrinsic sense?

This question is really an artifact of two things.

One, the continuing association between quantum systems and microscopic systems, which is, of course, traditional.

Quantum theory was developed to deal with microscopic phenomena.

It was first tested.

is the theory of microscopic phenomena.

And it's only in the past couple of decades that quantum theory is being applied to big things, to cosmology, for example.

So there's a long tradition of association between quantum and microscopic, and living systems are mesoscopic, much bigger than atoms, bigger than molecules.

So, and they're not nearly as big as cosmological systems, so they're somewhere in between.

And those systems have traditionally been regarded as classical.

And even chemistry, even biochemistry is still taught in a very classical way.

So we're not used to thinking of these things as quantum systems.

But at least in the approach we've taken in this course,

All physical systems are quantum systems, and classical information exists only on boundaries, only on boundaries between systems, and it only describes their interaction.

And I want to emphasize, I've said it before, but since this is the last class, I want to say it again, that this is not a universally held view.

It's a view that's becoming more common, and I think a generation from now it will probably be the dominant view of things.

But it's not fair to say that it's the dominant view now.

It's, I think, quite fair to say that it's a view on the rise, especially in the quantum information and quantum gravity communities.

But from a strict empirical perspective, we know a number of things.

We know that accurate molecular dynamics calculations require quantum theory.

We know that a lot of biologically important molecular processes use quantum coherence.

We know that things like hydrogen bonding can only be understood using quantum theory.

We know that cellular free energy budgets are way too small to support fully classical information processing if we think of information processing in terms of what proteins are doing or what other molecules are doing in terms of changing shape.

We know that shape changes in proteins and other molecules underlie all cellular information processing.

So if we think of them as actually implementing cellular information processing, we have way more information processing than could be funded classically.

And finally, we know that human cognition exhibits contextuality.

So human cognition uses quantum coherence.

It's not a classical causal process in all cases.

But this is still a very nascent field.

And it's a field with a lot of potential.

And I think, again, a generation from now, quantum biology is going to be regarded as a very mainstream endeavor, even though it's something of a small emerging field now.

And I'll just show you one picture in support of this third point.

This is a plot of measured free energy usage converted to numbers of bits processed at one kilohertz for a number of prokaryotic and eukaryotic cells, all that I could find a few years ago that had good caliometric measurements, versus the log of their area, their membrane surface area.

And the thing to note here is that these cells are processing classical information at pretty low rates, kilohertz to gigahertz rates for a thousand bits at a time.

And we know that a lot more is happening in cells than that.

Cells have many more than 1,000 proteins, and those proteins are all moving all the time.

And if that motion is processing information, then there's not nearly enough thermodynamic power to power all of that information processing.

So let's now talk a little bit about life and living systems and what they look like.

Here's a view of living systems from the point of view of genome diversity.

This is a few years old, so it's out of date by now.

But it tells us a lot qualitatively.

It tells us that almost all genome diversity is microbial, that the sorts of organisms that we're familiar with, medium-sized organisms like us, animals and plants, have only a tiny amount of genome diversity.

So we think of ourselves as pretty diverse.

We think of ourselves as quite different from other animals, from flies or worms or

sponges or something like that.

But in fact, we're not all that different from them.

We share many, many proteins with all of those other organisms.

We share the same cellular organization and so forth.

We're not, in fact, all that different from plants.

And we're much more similar to the fungi than to the plants.

So

We get a very biased view of genome diversity when we just look at familiar large types of living systems.

Most genome diversity is buried down there in the microbial world.

This isn't the only way we can look at life as a diverse set of organisms.

We can also look at it in terms of a cell lineage.

The fact that we're all related at the DNA level tells us that we're all descendants of a common ancestor, which is usually called LUCA, the last universal common ancestor.

And LUCA is generally modeled as being a cell, more or less like a bacterial cell, so fairly simple, with not very many pathways.

with maybe a DNA genome.

And if LUCA didn't have one, then they arose fairly shortly thereafter because all organisms that we know of have DNA genomes.

But the point of looking at life as a lineage is that we get a diagram that looks very much like the cell lineage

from an embryological situation, much like the cell lineage of our own body is growing from a fertilized egg.

And in particular, looking at life as a lineage shows us that not only do we share DNA with all other organisms, we actually share a membrane, a cytoplasm that's continuous in time all the way back to Leuco.

and so continuous in time between us and bacteria.

So if you look at life this way, you realize that life is in a sense all one organism, all one connected structure that's developed over time through division, cell division.

And so we're very closely related to all other parts of life in the same way that different cells in our bodies are closely related to each other.

The time spans just longer.

I mean, here the time spans three and a half or four billion years between us and Luca.

These lineages have been diverging for that long, but they're still continuous.

And in particular, they form a continuous cell membrane.

So when we think of life in this way, we realize that we're reasoning from just one example when we think about terrestrial life.

And this strongly limits what we can say about living systems, what we can say about biology.

that we really only have one example, the lineage that descends from LUCA here on Earth.

And at some point we may have more examples, and there's certainly groups working on artificial organisms that aren't part of this lineage, that are constructed from parts derived from this lineage, but aren't members of this lineage themselves.

And that may tell us something new about life.

But if we think of life this way, we see something very important, which is that as life grows, its boundary gets bigger.

And since the boundary of a system constitutes its informational environment, its dimension getting bigger,

means that more information flows into it from its environment, and more information flows out of it into its environment.

So as life develops from LUCA, it gets a larger and larger informational environment, and this dimension of its boundary grows and grows.

Now what that means, if you go back to our original picture of two interacting systems,

is that the number of the dimensionality of the physical environment is decreasing.

And we think of the physical environment as increasing in size.

We have the expanding universe and all that.

But what's increasing in size is space.

And if space is emergent, then that increase is not a real increase in degrees of freedom.

What we're really interested in is

the Hilbert space of the physical environment as distinct from the Hilbert space of life.

And as life gets bigger, it literally, quite literally, eats the physical environment and turns it into more life.

So there's less physical environment around.

So the trajectory of life is toward a bigger informational environment and a smaller physical environment.

And as the physical environment gets smaller, you might imagine it gets easier to predict.

And as the informational environment gets bigger, you have more information with which to predict the behavior of the physical environment.

So this all hangs together very nicely with the free energy principle.

Here's another picture of this same thing.

If we start with some boundary here on the left labeled B around some system labeled S, and it's embedded in an environment E, then as S makes copies of itself through some process like cell division,

then it starts to fill up more of E. It's actually converting degrees of freedom of E into degrees of freedom of its copies that it's made of itself.

And if we think of some larger boundary drawn somewhere in E, here on the right side, I've labeled that B prime, what happens is that B prime gets slowly filled up with copies of S,

And it starts to look like a large organism.

And that's what life is doing in the physical environment.

It's making a bigger boundary for itself at the expense of degrees of freedom of its physical environment.

So we can ask, what drives this process?

Why is life doing this?

Why is it making copies of itself?

And the answer to that question, at least one answer to that question, is the free energy principle drives it to do this.

And I'll just show you some simulations from several years ago of a cell population in this upper left panel.

The green cells are stem cells that divide.

And they've been embedded in an environment that's safe on the left side and 100% lethal on the right side.

So they're embedded in an environment that's conducive to life on one side and very dangerous as you get toward the middle.

And the purpose of these simulations was to study what happens

When the stem cells are able to divide and create not just other stem cells, but create specialized progeny that don't divide, so somatic progeny that don't divide, and hence have free energy resources, thermodynamic resources, that they can devote to doing something other than dividing.

Cell division is incredibly expensive when it comes to energy.

So if you take that energy and apply it not to cell division, but to protecting the stem cells, you can allow the stem cell population to expand.

And that's what these other simulations show.

The blue cells are somatic cells that have very varying ability to protect the stem cells.

And if they're fairly good at protection and they're fairly hard to kill down in the right bottom quadrant, you can actually get a population expanding well into the highly lethal part of the environment.

So this shows you the FEP in action.

What the stem cells are doing

is constructing a very predictable neighborhood around themselves in the environment by dividing to make progeny that don't themselves divide, that just sit there and help protect the stem cells.

So the stem cells are now living in a safer, more predictable environment.

And that allows them to invade more and more of their physical environment by having this fairly benign informational environment.

So this is the FEP in action, driving the expansion of life at the expense of the physical environment.

So that lets us go back to this question that was raised last time.

about the mechanism of these scale transitions that we see ubiquitously in life.

Life gets bigger and bigger as time goes on phylogenetically and as time goes on developmentally.

We start with some molecular pathways that somehow get assembled into a cell.

That's the origin of life question.

How does that happen?

And about 2 billion years later, cells start to group together to make multicellular organisms.

Now, bacteria group together to make facultative multicellular systems like microbial maps 3 billion years ago, very, very early on.

But we don't see the emergence of obligate multicellulars until much, much later.

before the Cambrian explosion, but still less than a billion years ago.

And from there, things get more complicated very quickly.

So one has large multicellular organisms.

They develop complicated social relations that probably first emerged with social insects.

but are certainly well developed in invertebrates, including in mammals.

Organisms group together in very complex ecosystems.

And recall here that it's now known that all multicellular organisms have obligate microbial symbionts.

So all of our bodies are in fact very complex

ecosystems populated by many, many different species of bacteria.

And that's true not just for us, but for trees and insects and worms and sponges and everything else.

So organisms from a body point of view are themselves ecosystems, and organisms organize themselves into ecosystems.

And these ecosystems come into contact across the entire biosphere.

So processes as simple as the wind disperse organisms as small as bacteria all over the planet.

So this scaling of life toward larger and larger organizational structures

is in a sense the major thing for biology to explain.

And the hypothesis that we floated last time was that this transition from very small scales to very large scales uses the same mechanism over and over again, or a mechanism that has the same structure over and over again.

So the renormalization group is trivial, basically.

It's just the identity operating at different scales, or mapping from one scale to the next.

So the question is, can we approach this in any way?

Does this make sense?

And to try to make sense of it, we can go to the one real developed theory that we have in biology,

which has been formulated by Dawkins and others as universal Darwinism.

This is just kind of an abstraction of the modern synthesis between Darwinian evolution and genetics.

But universal Darwinism is incredibly simple and very obvious.

It says if you have systems and they can copy each other, they can copy themselves and the copies can diversify,

Then if you want to know what's going to happen at the population level, what you will find is the systems that copy themselves and diversify most efficiently will win because there'll be more of them.

So they end up dominating the population.

And winning gets called natural selection.

But natural selection is not an extra part of the Darwinian process.

It's just the outcome of efficiency, of the systems that copy themselves most efficiently coming to dominate any population.

So there's no sort of...

kind of hand of God or whatever reaching down and selecting some organisms and not others.

And of course, when Darwin put the idea of natural selection together, he was thinking very explicitly of the analogy of a gardener or a farmer selecting the crops or the animals or whatever that the gardener liked best and keeping those.

And that's where this selection metaphor comes from.

But there's no real process of selection in evolution by natural selection.

It's just copying and diversifying.

But this clearly is just the outline of what a real mechanistic theory would be, because we need to have a story about what copying is and what diversifying is,

and what efficiently means.

And in particular, to address the question that we raised a couple of slides ago, we need to know whether these mechanisms are the same or at least isomorphic of the same form at different scales.

So that's what I want to talk about for the next little bit.

Let's start with copying.

Up until the 70s, copying in biology really meant DNA replication and, to some extent, cell division.

But the focus in evolutionary theory was on DNA replication.

And in the 70s, it was realized that whole genes could be duplicated, so whole genes could be copied.

And then shortly after that, it was realized that particularly in prokaryotes, where functionally related genes are next to each other in chromosomes often,

in what are called operons, that operons could be duplicated, and so entire pathways could be duplicated.

And as genomes began to be sequenced and structures of genomes were understood, it became clear that genomes could be copied.

And of course, we have two copies in each of our cells, with the exception of red blood cells, of our complete genome.

But some plants, for example, have six or eight or even more copies of their genome in each of their cells.

So there's large-scale genome duplication.

Cell division is clonal duplication of cells.

Organismal reproduction works by cell division in all known systems.

colonies or societies of organisms reproduce themselves, in part through cultural transmission, and entire niches reproduce themselves.

For example, in processes like forest evolution or desertification or even urbanization, we see humans reproducing the same sorts of niches in city after city, for example.

So these forms of copying have the kind of hierarchical dependencies that one might expect.

So to duplicate pathways, you have to duplicate genes.

To duplicate cells, you have to duplicate the genome.

To duplicate organisms, you have to duplicate cells.

And this suggests that this copying operation

is indeed scale-free, that each level, the copying operation at each level enables the copying operation at the next level.

Now, with diversification, we see much the same thing.

In the early days of the modern synthesis and still in the work of people like Richard Dawkins,

diversification is is generally thought of as random so mutation for example is thought of as random and um here i have barbara mcclintock who is kind of the hero of non-randomness in doggedly over decades pointing out that much of genome diversification is not random at all and um

that genomes actively diversify by moving whole clusters of genes around and duplicating them or just changing their positions so that they're under the influence of different local control.

So at the gene and genome level, you have active diversification by various processes.

enzymatic processes, as McClintock showed us, transposon-mediated mechanisms, which are enzymatic at the bottom.

Cells actively diversify by lots of different mechanisms.

And in the 70s, Carl Woese was, in part, personally responsible for pointing out that

In the microbial world, there's a lot of horizontal gene transfer.

And again, no one believed him for quite a while.

But now it's broadly accepted that microbes exchange DNA very frequently and across large distances phylogenetically.

And this is how things like microbial resistance to antibiotics spread so quickly, or one way that it spreads so quickly.

And it's a tremendous agent of essentially speciation, to the extent that that even makes any sense in the microbial world.

Of course, in our cells, we have functional differentiation.

As mentioned earlier, there are lots of symbiotic interactions that lead to diversification in cells by radically altering their local environments.

And of course, sex is a mechanism for diversification.

Organisms actively diversify in many different ways.

The most obvious one is just by moving around, by moving to a different environment.

the organism is exposed to different inputs and is allowed different outputs.

And so it can move into a different direction, morphologically, genetically, etc.

Organisms can regulate their own evolvability by altering things like DNA repair systems or activating transposons.

Again, these are sorts of things that...

went very much against the grain when they were first discovered, but are now pretty well accepted.

And of course, organisms can learn and so can diversify their behavior by diversifying their computational capabilities.

And social groups, of course, actively diversify in many different ways.

And organisms are increasingly, non-human organisms are increasingly regarded as having cultures that they pass on intergenerationally by intergenerational learning and can exchange with other groups.

So diversification is active.

and occurs at every scale.

And again, diversity, although this is a bit less clear than in the case of copying, diversification mechanisms at one scale enable diversification mechanisms at other scales.

So, for example, transposon-mediated mechanisms enable horizontal gene transfer in microorganisms.

And the FEP tells us that efficiency is actually about intelligence because the FEP drives systems to build good models of their environments or the behavior of their environments.

And what a good model lets a system do is reach a single goal by many different means because it allows, in a sense, planning.

and it allows flexibility and adaptability.

And I put William James here on this slide because he was the first, as far as I know, to define intelligence as this ability to use different means to reach the same goal.

Now, in evolution, that's long been known, and it's called convergent evolution.

When you see two lineages adapting to a single environment,

with very different genetics and very different morphologies.

And often the organisms will end up with similar morphologies that work well in that environment, but very different genetics and very different biochemistry.

So throughout evolution, we see this phenomenon of functional convergence

balancing structural divergence at many, many different levels.

So we have multiple genes for very similar proteins.

We have multiple pathways that do more or less the same thing.

We have different cell types that support the same basic functions.

We have tissues that are fairly different, but that have the same functions.

For example, eyes and different kinds of organisms that allow vision, but have very different structure.

And of course, we have functional convergence and social relations.

And if we look at how cells interact, traditional evolutionary theory really focuses on competition.

But

We now know that cells cooperate, that they exchange resources in various ways, even across vast differences in phylogeny.

For example, the interchange between plants and fungi, or between bacteria and us.

We know that cells, in a sense, persuade each other by secreting things like hormones that cause other cells to do different things.

Cells deceive each other.

For example, microbes that are trying to escape the immune system.

And cells coerce each other.

Cells even kill each other when they detect, for example, genetic defects.

So these sorts of social and economic and even political ideas are useful for describing living systems.

from the level of cells on up.

I mean, they were developed in social settings to describe what goes on in human societies and then extended to other animals.

And now it's very clear that they extend to individual cells.

So when we think about social intelligence, we can think about social intelligence even at the level of individual cells.

And we see these sorts of competition, cooperation, resource exchange, et cetera, even at the level of microbial mass, so biological structures that are 3 billion years old.

Now, of course, intelligence is necessary, but it's not sufficient for being selected.

It won't protect you from impacts of asteroids that happen to land on your planet.

which has happened often in the evolution of the Earth, and we're now trying to figure out how to predict and prevent such things.

But it's, you know, who knows whether we'll be successful at that.

But this intelligence

is necessary when it's viewed in this FEP sort of way.

Intelligence is what lets you build models that enable you to predict the environment.

So where does this leave us?

By thinking of evolutionary theory in terms of scale-free mechanisms, we seem to have a picture

in which we start with quantum systems with a certain level of complexity, and the FEP actually gives us scale-free biology or something very close to scale-free biology.

And that's very interesting because the FEP, of course, is a generic principle.

It just says that systems do what they need to do to keep existing.

And this way of thinking gives us some predictions.

One is that we'll find compartmentalized problem solving everywhere because the FEP drives compartmentalization.

And the reason is just non-commutativity of measurement processes.

It predicts that we'll see hierarchical organization everywhere, in the same way we did on that first compartmentalization slide, where once you have a number of compartments, you need a metacompartment that, if nothing else, distributes free energy.

So some sort of very basic attention system.

And we see attention systems, of course, throughout biology.

It predicts that living systems will have very limited classical data structures.

So since they have to write classical data on their boundaries, and their boundaries are much smaller than they are, then they'll, and because writing classical data is expensive, living systems will tend to use as little classical data as they can get away with.

Since classical data is needed for

thermodynamic irreversibility.

Where we see thermodynamic irreversibility, that's where we look for classical data.

We saw that organisms will be able to detect time first before they can detect space.

So we can expect organisms to have clocks even before they can represent space.

And of course, we see things like diurnal variation throughout biology.

And finally, the FEP predicts this asymptotic collapse of separability back to entanglement.

So it predicts that living systems will eventually degrade and become indistinguishable from their environments.

And we know that happens at the cell level and the individual organism level.

We call it death.

So

The FEP seems to give us a lot of the features of biology, and it gives us these features in a scale-free way, and it derives them from this very basic physics.

So where does that leave us?

I think it leaves us here with a challenge, not just to thinking about the FEP, which is what this course has been about,

but to quantum information theory in general.

And that challenge is to evolve from the kind of conceptual and theoretical utility that we've been discussing in this course, and which is very well developed in the physics community, to some sorts of empirical and technological utility

And I've listed three areas here where QIT is very active.

One in quantum gravity and cosmology.

And you're probably familiar with things like string theory that sort of fairly famously seem not to be empirically testable.

And the quantum gravity community is enormous.

Many thousands of people working in this area

But coming up with theories that can be tested empirically at the scales that we can actually do experiments, so at accessible energy scales, for example, has proved to be very difficult.

So this is a real challenge to the field, is somehow getting not just to empirical testability, but to some sort of technological utility.

And you can imagine that if the main prediction of

quantum gravity is that space-time is emergent, that there could be enormous utility in that, some ability to manipulate the way space-time emerges.

The second area, of course, is quantum information and computing.

And here, massive resources are being put into technological utility.

And I think it's reasonable to expect that we'll have useful quantum computers within a generation at any rate.

So there I think the field is going quite well.

And the last area of what we've talked about here is quantum biochemistry and biology.

And this, I think, is an area with enormous promise that maybe some of you will actually contribute to.

making this area more useful technologically and more accessible empirically.

But at least we have a picture of how these different areas fit together.

So that's it.

Thank you very much for participating in this class.


SPEAKER_00:
sorry um could you just repeat the last like 30 seconds from andrew will be chris


SPEAKER_01:
And it will be a discussion session on Saturday, the 20th of October at the usual time, 8 a.m.

Pacific time.

And the interactive Q&A is open.

I really appreciate your questions.

I try to answer them.

And thank you very much.

Awesome.


SPEAKER_00:
Can I ask a question or do you want to call it here?

Sure, go ahead.

All right.

Inks wrote, Chris spoke last time

Introducing the mechanisms of scale transition.

I'll read your question, then I'll fix the cropping on the live stream.

Chris spoke last time introducing the mechanisms of scale transition of these essentially semantic theories about how one scale embeds in another scale.

I would love to learn more about this, especially in terms of natural language semantics and human cognition semantics versus machine learning.


SPEAKER_01:
Wow.

Well, that's a very good question.

I think that's a very relevant question given the sorts of machine learning that we see deployed in systems like ChatGPT.

And especially as these systems

start to associate language with images, for example, and as such systems are embedded in robotic systems that can actually move around in the world and interact with real objects.

I think one of the key questions in natural language semantics is to what extent does it depend on reference?

To what extent

do the meanings we attach to words or the usages that we allow for words depend on our ability to connect words to external objects?

And to what extent do those abilities rely on connections between words themselves?

So if you think of an LLM like ChatGPT by itself, it's just a statistical model of relationships between words as used in some corpus of text, which is large, of course, but we can debate its representativeness.

And so that's a model of semantics that's entirely self-contained.

It's entirely relations between different pieces of language.

Whereas when we start to connect those words, statistics to images, or better yet, to actual objects that are interacted with, not just visually, but haptically, for example, by a robot,

they start to be connected to external reference.

And that transition, I think, is going to be very, very interesting to watch.

And it's just starting, so we all have ringside seats on an incredible experiment in semantics.

And so that would be my response really to that question is keep your eyes on this experiment and see how it goes, because it's bound to tell us something about how semantics really works.

And I suspect that there will be enormous opportunity to start relating the results of that experiment to what we see in developmental psychology, for example.


SPEAKER_00:
Wow.

Awesome.

All right.

Tucker asks, Areas of macroscopic quantum-mediated phenomena in biology that get Chris Fields excited?


SPEAKER_01:
I think the one that excites me the most right now is just this question of how cells are managing to do the information processing that they're doing.

And how much of it

they can accomplish, or I think the right way to put it is, how can they get away with so little classical information?

And I don't think we have the cell biology yet to answer that question, but I think asking the question may help us design the right kinds of cell biology to look for an answer.

And our cell biology has been organized around the idea that the structures that we see are essentially static, that they're classical, and that they're constructed in a way that's thermodynamically irreversible.

But if we think of what we measure as not necessarily reflecting a static structure,

I think we'll start to conceptualize it differently and build models of it differently.

I mean, clearly, when we look at things like protein structure, we're looking at snapshots of something that's very dynamic.

And when we look in a chemistry textbook and we see pictures of this conformation that changes to that conformation, we think of those as static, stable structures, that that's kind of a switch.

But it's not actually a switch the way a light switch is.

It's a much more dynamic process.

And the kinds of molecular dynamic simulations that allow you to study that process are incredibly complicated and time expensive and uncertain.

Good resolution problems and other things.

But

I think thinking of these as kind of fluid, reversible processes is going to change the way we think about them.


SPEAKER_00:
That's a great point.

And it reminds me of the more physics-based way of thinking about the paths that could happen between observations or the statistics-based way of samples of a dynamical process.

And in biology,

we know that even if we take a snapshot, okay, this organism is one centimeter today, it's two centimeters tomorrow, something changed.

So we know there was a developmental process, then we know there's an ecological process, and then there's an evolutionary context, eco, evo, devo.

And then from that more biological understanding of contextual developing organisms, all of these different biological phenomena,

actually help us expand our space of measurement and analysis for material that on one hand some people may have called inanimate but then they have their own dynamics different time scales and so bringing some of those like the challenges of measuring and observing intervening in historical and biological

things gives us a big understanding even on measuring and summarizing analyzing ensembles or scales that that don't immediately appear to have that kind of historiosity like pieces of silicon or carbon yeah that's that's that's well put and and i think uh we have the same problem as we go up in scale also


SPEAKER_01:
We tend not to think of things like societies as living systems.

But in one sense, they clearly are.

And to the extent that we can think of these structures that are much larger than we are individually as living systems, cognitive systems, etc., I think we'll understand their dynamics better.


SPEAKER_00:
Okay, final question.

upcycle club wrote how can a quantum system detect and respond to quantum context shifts switches which are changes in the measurement basis or the entanglement structure of the system um well uh


SPEAKER_01:
The answer here is simple and not very informative.

It's by making measurements, which is all that quantum systems can actually do, and making measurements that follow probing actions that try to push the boundaries of the model of a context.

When having this discussion, I always like to go back to the frame problem in artificial intelligence, which is the problem formulated in the late 60s of predicting what won't change as the result of an action.

So it's sort of the inverse of the problem of predicting the side effects.

And if you could predict all of the side effects, you can predict what doesn't change.

So it's equivalent to the question of predicting all the side effects.

And context change is a side effect.

And it's often an unobserved and maybe unobservable side effect.

But if you have a model,

that says, I'm working in this context, then you can intentionally probe the boundaries of that model and see if you can actually alter the context you're in as a way of discovering what context you're in.

And humans do that in social settings all the time.

But I think this is something that we need to...


SPEAKER_00:
think about happening at many different scales i suspect that cells are doing this all the time we just don't know how there's so much to say there it just makes me think of the the paradox or the tension between expecting the expected expecting the unexpected and life needing to expect both of that right

so thank you chris it's been an amazing lecture series many people in the live chat are very appreciative and and um we'll look forward to their submitted questions and their participation in the final discussion coming soon so thank you chris until next time okay and thank you all bye ciao