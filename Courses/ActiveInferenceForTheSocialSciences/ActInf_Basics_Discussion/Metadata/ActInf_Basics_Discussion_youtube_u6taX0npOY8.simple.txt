SPEAKER_04:
July 25th 2023 and we are in the discussion section basics of active inference this is the first discussion section that we've had for this course so thank you all for joining and it's going to be regarding the topics that Ben White introduced in his recent lecture so everyone will be welcome to

pop in and introduce themselves and then i know that ben has some ideas to discuss and many other spontaneous and written questions will come into play so i will uh with that exit for now and pass to perhaps some of our first time live stream guests


SPEAKER_05:
I guess I've already spoken, so I may as well continue.

So I'm Darius.

I am a master's student.

I'm just about to finish at UCL in social distributed cognition.

I work in a social cognition lab looking at salience regulation and attentional mechanisms within social contexts, but all within an active inference framework, within the Bayesian brain hypothesis framework.

And yeah, it's a sort of recent...

discovery and obsession.

And so I'm sort of getting to grips with both the high road and the low road.

And so I've had the opportunity to chat to Mark and some other researchers who have been super informative, but always looking to learn more and get my head around even more of the sort of philosophical and mathematical theory.


SPEAKER_03:
Cool.

Sounds good.


SPEAKER_09:
Hi, everyone.

Can you hear me?

Yep.

I'm Francesco Balzani.

I'm a PhD student at the University of Bologna, Italy.

Actually working on the intersection between artificial intelligence and education.

I have a background in cognitive anthropology and philosophy of science and I met Axel and Maxelina a few years ago.

So I dive into the rabbit hole.

and active inference and currently pretty much interested in multi-scale active inference models of scientific cognition so pretty interested about the agent level modeling of scientific reasoning assumption that might emerge from the interaction with the scientific environments so we're referring to scientific construction and all this type of top-down and bottom-up interaction so super interested to

Thank you.


SPEAKER_03:
Thank you very much.


SPEAKER_07:
Would anybody else like to introduce themselves before we start?

So you go first.


SPEAKER_10:
Okay.

Hi, I'm Regina.

I'm from Guatemala.

Well, I'm not from the social sciences.

I come from biology and neuroscience.

And I'm here because I'm working on a project as a technical operator in this big project in the exescape and material mines.

And I do the technical part and experiments, but I want to learn the philosophical part.

That's the background that, you know, makes the theory of everything we're going to, you know, experiment.

So I'm here to learn.

um and also i am like you know when you see the olympics that you you see all the swimmers and you always say i wish there was a normal guy to see how good these people are so you could compare so that's me today right i i understand half of what's going on but i'm happy to be here so yeah hi


SPEAKER_06:
yeah sorry i'm late um sorry my name's lee um i'm a phd student at the uh university of york studying systems transformation um and i'm i'm joining because i'm using uh perceptual control theory at the minute to uh to model examples of effective practice um in organizations and and i've read quite a lot of um

active inference papers and I understand that there's a lot of resonance and overlap between perceptual control theory and active inference, although I understand it's within a predictive framework and also it's a kind of a level of abstraction higher.

So you're able to kind of quantify the difference between sort of the predictive state or the outcome state and the current state.

So what I'm really trying to understand is how might that level of abstraction be useful in what I'm doing, actually, because I understand it's a much more kind of concurrent theory and framework than perceptual control theory.


SPEAKER_07:
yeah very cool um anybody else i think there's is that everybody okay well um was everybody um present at the has everybody seen the lecture that i gave uh a couple of weeks ago six

Okay, so I think it might be helpful then if I kind of very, very briefly go over what we covered in that lecture, just to kind of jog people's memories, and then we can maybe pick up some questions from there.

So the lecture last week was on the basics of active inference, and it was...

intended to be an introduction to the framework on a very abstract philosophical level.

So it left out all of the kind of mathematics and technical aspects of the framework.

And the objective really was to lay the groundwork for future weeks in this course, because

This is obviously a course on active inference in the social sciences.

And so in the subsequent weeks, we're going to be looking at topics like collective behavior, social cognition, shared norms and niche construction.

And so what I wanted to do was to put on the table

a kind of fully fleshed out picture of what the individual agent looks like in active inference.

And so to do this, we looked at emotion, agency, mind.

So we looked at kind of the role of action and perception, the role of internal representations.

in active inference.

And then as a case study, we kind of we looked at a active inference based account of addiction to kind of bring all of these threads together to kind of articulate a lot of the things that I'd said in the previous sections.

so i'm i mean the questions here don't have to be specifically um tethered to that lecture i suppose we can just start with any general questions about active inference and philosophy and how active inference applies to individual agents or if anybody did want to pick up on any threads from the lecture then we can go from there can i ask something just for the basic questions yeah of course


SPEAKER_10:
I don't understand, because I think you explain it later, but how does creativity and science in general enters active inference?

How does trying to be creative and not doing what you predict enters this world?


SPEAKER_07:
Yeah, this is a really good question.

So were you there?

Did you see the lecture?


SPEAKER_10:
Yeah, but I remember half of it.


SPEAKER_07:
That's fine.

But I think, do you remember the dark room problem?


SPEAKER_10:
Yeah, I know that's where the answer is.


SPEAKER_07:
I think there are several interesting dark room problems, some of them more interesting than others.

And I tried to cover, I obviously didn't have time to cover all of those in the lecture.

But for those that perhaps aren't familiar, the dark room problem is this kind of canonical philosophical worry about predictive processing and active inference that says, essentially, if all we're trying to do is minimize prediction errors, why don't we just find maximally predictable environments?

And why do we not just lay in a dark room hooked up to an intravenous drip and enjoy an error-free lifestyle?

um so i think that's the kind of that's the question that you're articulating there um i just quickly see a hand from darius darius did you want to jump in or was it a separate question

it's a separate question so I would just do it in advance but yeah I'll circle back around in a second then but everybody feel free um I should say actually um this is the first time I've kind of chaired a discussion like this so I'll be explicit and say um people should just feel free to jump in whenever they want if you want to take the disco if you want to kind of um add something or or kind of build on a question that we're answering feel free to jump in

But yeah, with the dark room problem, as I'm aware, the first answer to that question, and this is something that I did cover in the lecture, is

Essentially, a big part of active inference is to recognize that the agents are it's a kind of fundamentally embodied framework.

OK, so what that that can be kind of cashed out in various ways.

But one of the one of the most important ways is that the expected states of the organism or the agent are necessarily rooted in the phenotype of the organism and the kind of evolutionary biological needs that come with having a particular body.

So there was a paper that I referenced in a lecture by.

There's three authors on this paper.

It's Andy Clark, Carl Friston, and then I'm forgetting the name of the third author.

If anybody can recall, feel free to drop it in the chat.

But this is this is an answer to the dark room where it builds on that notion of embodiment and says, look,

creatures like us humanate and could and sit in the dark room and do nothing and just uh kind of enjoy the very predictable march of hunger thirst Etc but obviously those particular biological sets of the room and so you have this very fundamental level um

we have this very fundamental kind of basis upon which we have these needs that need to be met, and so we need to engage in exploratory behaviors.

On the topic of novelty, because that's a kind of base, I take that to be a kind of baseline answer, but there are clearly kinds of activities and behaviors that we do engage in going beyond the dark room, kind of curiosity,

play um creativity engaging in kind of why do we create works of art and it there's not an obvious link between those kinds of behaviors and the kinds of biological needs um that are emphasized in the original answer to the dark room worry

um so in answer to regina's question about creativity i think that a good starting point for this is the section on aerodynamics that i introduced in the lecture so this was the idea that

it there's this strong connection between affectivity as a kind of emotional embodied feeling state and the changes to the rate in prediction error minimization so i don't know um i am now very much uh articulating mark's work here so i don't know if mark wants to jump in at any point and do a much better job than i can um

I think there's certainly work on the horizon.

I know that there are people who are currently building up theories of artistic creativity that

that are based on this idea of aerodynamics.

So Mark's paper on play with Mark Anderton that I mentioned has a really interesting idea where if you explain playful behaviours, which are kind of fundamentally creative and we are

It's an inherently creative exercise.

I think the really interesting idea that comes out of that is one thing that we engage in because it feels good is we create niches of very manageable prediction error that we can then minimize.

So, yeah, that's playful behavior is a kind of the answer to the puzzle of play.

So why do we the puzzle of play is why do we engage in metabolically quite costly and they don't have any obvious benefit.

And the idea there is that, well, there's kind of several ideas in there, but one of them is that it just literally feels good because minimizing prediction error feels good to us.

So whenever we do better than expected at minimizing prediction error, it feels good.

And so I think

So obviously I don't know for sure, but I think that any answer that we give regarding artistic creativity is going to fall within that kind of bulk.

That essentially we engage in the part of the creative process is just constructing those that give us tasks.

caves of manageable prediction error that ideally sit at the boundaries of our skill capabilities.


SPEAKER_00:
Can I add two quick things there, Ben?

So that was a great explanation.

But just to hit two points a little bit harder.

One, you might think all that matters is existing error.

That's why it looked a little bit paradoxical that we also create errors.

antithetical to our modus operandi, which is to reduce error.

But when you remember that for our kind prediction error minimizing system, we have a really deep temporal model.

We're managing uncertainty at a big horizon, maybe even multi-generational, you know, where we're thinking about our kids or our kids.

I mean, who knows how deep the generative model actually runs.

It turns out that in that kind of


SPEAKER_01:
Last air is over the run.


SPEAKER_00:
that stops developing error-minimizing skills and abilities and just hangs out in one micro-niche, because that micro-niche is going to be upset sooner or later, right?

I mean, it's such a great example of where we thought we were in a really set vector state, and then suddenly it gets jostled, and all of us go, oh, my goodness, like, what do we do?

We've been bumped.

And it turns out that the best error-minimizer will be the one we're responsive to,

of errors that are and hates those errors are digestible.

So that means not too complex that you can't do anything with it.

You can't learn anything from it, but also not so boring that there's nothing to learn.

If we hang out, if we're sensitive to, and we hang out at the edge of our capability,

then we keep developing new error-minimizing abilities, which actually sets us up to be good error-minimizing systems over the long run.

So even though we're investing metabolism now, we're setting ourselves up to be able to manage, especially in the deep end of the pool, black swans, manage uncertainty that we're not going to be able to predict.

They're really unpredictable, unpredictable.

That comes from hanging out at this edge.

So part of our curiosity and playfulness and creativity are going to be about us making and digesting novel slopes of volatility.

I think that's one really great answer for why you get playfulness and curiosity out of this and creativity.

I'll just drop one more and we don't have to get into it too deeply here, but here's one other one that we're thinking of.

There's something really special in the creation of art, especially in a public sphere, that I think is so interesting and that somebody needs to be sort of looking at this.

There's actually a new collection coming out in Philosophical Trends B on art and predictive processing, which I think you should check out if you're interested in these topics.

But the idea that we've been thinking about is there are ways that we can bring our generative model

out and put it into a public sphere.

You can take something which is typically on the inside and you can put it outside.

And then you can have other error-minimizing systems look at it and fiddle around with it, and then we can re-imbibe it

I mean, we're doing this all the time.

I mean, that's what language allows us to do and what writing allows us to do.

Think about maths.

You're bringing a part of your predictive understanding.

You're laying it out, and then other predictive agents can fiddle around with it, and then you can take it back in as part of your updating your own model.

And I don't know how much more I can say here.

I just think this is a kind of horizon, but I think there's a really juicy thing to say here about where real art is like Tolstoy, maybe Leo Tolstoy was already on this, where you put something of the creator in the creation and then other people receive that and then they can do something else with it.

And then you're able to sort of take it back in all under the guise of sort of minimizing volatility or understanding volatility.


SPEAKER_07:
maybe that was a bit deep but uh no that was really that was really good yeah yeah and um I just didn't so in the chat I just dropped a link to um

Yeah.

So somebody just asked about papers related to hanging out at the edge of our capabilities.

I'll do that right now.

There sure are some papers on that.

Mark's got a few.

I already dropped a link in there to an Aon article by some of the old Expect Project crew, including Mark, Kate Knave, George Deed and Andy Clark on the value of uncertainty, which is.

I think it's a really good start point for some of these questions, just because Aon is a kind of non-academic place where you can, you know, it's a non-technical introduction.

And there's a wonderful example in that paper of a guy named, I think it's Max Hawkins.

Is that right, Max Hawkins?

who he's a kind of tech guy and he realized he was getting kind of bored with his life.

He inadvertently trapped himself in a dark room because his life had become so robed and scheduled and systematic.

He realized that he would be kind of incredibly easy to kidnap because he was in the same place at the same time every single day.

and to get he took drastic action to break out of that dark room so he he kind of introduced a a randomization algorithm that would it would kind of choose for him where he was going to eat where he was going to go which shows he was going to attend and this example is a really nice centerpiece in this article so and i think yeah i think this is a nice place to start because it's also grounded in discussions about epistemic actions as well because there's also

know as cool as play and art and creativity are there's also really really good reasons that uncertainty is valuable as well right because while we might want to exploit all of the opportunities for kind of nourishment and valuable prediction error minimization in our environment there are of course going to be times where

um those uh those opportunities are exhausted and we need to go and explore different ones and i think there's some there's it there's some stuff in there as well on epistemic actions within the context of navigation as well so sometimes we're going to have to we're going to have to temporarily move further away from our target in order to minimize our uncertainty about where we're going so there's lots and lots of stuff on the value of uncertainty um and it kind of is

very much at the forefront of some of the really interesting philosophical applications of the framework, for sure.


SPEAKER_10:
Okay.


SPEAKER_07:
By all means, yeah, we've got time.


SPEAKER_10:
You just said something, I know you have a question that is, but with the value of uncertainty, it's just that I'm thinking, because I've been working a lot with magicians,

and there's a way of using uncertainty as entertainment and it's very difficult to understand as a you know as a concept for entertainment why would you like to be in a place where you cannot you want to predict but you cannot and you still want to participate in this activity so for me magic shows it's kind of breaking a little bit um yeah i think my i spoke to um


SPEAKER_07:
I forget the person's name, but there was a Xscape meeting here at Sussex and I spoke to one of the guys on Xscape who had been working on magic.

I don't know if you know who I'm talking about, but I think they have a book on magic.

And I think that's really cool to think about from a predictive processing perspective, the idea that magic is just these wonderful kind of violations of expectations in a certain sense.

I think predictive processing provides a nice, really intuitive framework for thinking about those kinds of things.


SPEAKER_00:
One little point there, Regina, just about, again, if it feels paradoxical, just to sort of complexify your view, remember that this is always happening in a hierarchical system.

So just because you have errors at one level of the system doesn't mean you're going to have sort of critical, cascading, unbearable errors at higher levels.

So that's why it's fun to go to horror movies.

So I dropped the paper here.

Also, we have a new paper coming out on horror movies.

I'm pretty interested in this.

But it's the same as going to the magic show in some way.

Now, the reason why those errors are fun is because we're safe in a theater.

We're with our friends.

We have lots of sugar in our system from eating popcorn and candy.

We can control the amount of scary by covering our eyes or...

like there's lots of control here and yet we're getting media that is that's pinging all of our evolutionarily ancient error tracking systems so that we're getting jumps in the physiology as if there's a bunch of volatility that we need to manage and yet we're in a completely safe space which is really fun for our kind of system because we're hierarchically deep predictive systems the high level here isn't jeopardized

It knows I'm in a theater, but the low level stuff is still registering all sorts of little volatilities, but of course they get squashed.

They don't cascade all the way up.

Or if you're the kind of person where they do tend to cast all the way up, then you're also the kind of person who doesn't like going to horror movies because it kind of scares you go home and think, oh goodness, maybe ghosts are real.

And maybe I live with them.

You wouldn't be going there then.

So with magic, it's the same sort of thing.

I don't know if you've ever seen a famous magician.

Who does the really extreme magic?

David Blaine.

he like was in a block yeah david blaine have you ever seen him he goes to haiti where you have a community that really believes in magic and he does some magic and he gets into trouble like suddenly all the young men are like oh no no no no that's that's no bueno that that you're doing this and then he had to the camera pans back he goes no no hold on i'll show you here i'll show you how it's done it was just a trick i'll just show you outside it's not real magic

Because there, they're not having fun with it anymore.

They're like, no, that's not a good thing to do.

So it just goes to show that our engagement with magic is mostly a sort of scary play.


SPEAKER_07:
I think one thing I just kind of... Sorry about the seagulls.

I don't know if you can hear those.

There are seagulls going crazy just outside my window.

One thing I would add is I think...

another aspect to this this part of the framework wherein you have this value of prediction error kind of epistemic and affective emotional value of prediction error it's one of the kind of key elements in this notion of uh agency get in active inference that I think is really it's gonna be really important in mind as you go through the further weeks of this course as well so what is

know like i said in the lecture it's not necessarily speaking to a quite the metaphysical question of free will but it's certainly moving us away from this picture of of the agent as a kind of automaton that's just following rules there's real space here for kind of individuality and creativity as well okay darius has been waiting a little while so um let's go over to him


SPEAKER_05:
Happily patient, happily patient.

Yeah, I mean, this is, this question, I guess, is deriving from my thoughts about the meeting of the high road and the low road.

Some of the recent work that's been coming out of Maxwell Ramsey and actually a conversation I had with him, which is the generative model of the state.

So my question, given that, given and taught by

regarding the notion of affordances i think it's natural that as cognitive scientists and philosophers we take the perspective intuitively of the agent in the agent arena relationship and how the agent is in the business of reducing prediction error i was just wondering whether as philosophers um you and mark have thought about what it would what is it like

for the whole system to be in the business of reducing its prediction error.

So I'm interested in flow states.

And so, for example, my thinking is that in the canonical example of a flow state, let's say a rock climber, the climbing wall is also in the business of reducing its prediction error as to afford the opportunity for it to be exploited itself or themselves are in the business of reducing prediction error.

So I'm wondering whether this expansion of affordances

It is bi-directional, tri-directional, infinitely directional.


SPEAKER_02:
That's an amazing request.


SPEAKER_07:
You mentioned Axel Constant, but is that somebody else?


SPEAKER_05:
Someone else, but I spoke to Maxwell Ramstein last week.

Yeah, yeah.


SPEAKER_07:
There's a paper on, I'll find it in a second, on Nishka Instruction and affordances.

I think it's Axel Conti-Farber.

where they talk about the symmetry between a niche and an agent, very much in the same vein as you were just talking about there, this idea that there's not just this unidirectional kind of fit between the agent and the environment, but the niche is actually modeling generative model of the agent as well, implicitly.

So I think the best I can do that direction of some really interesting work on that, but it's certainly, it's not, it's, it's, it's not something that plays a central role in my thinking recently.

Yeah.

So we have to just chat.

Yeah.

A variational approach to niche construction.

Yeah.

I don't know if, if Mark has anything to add or anybody else, which we're thinking of.

Yeah.


SPEAKER_00:
Darius, can I just check one thing you asked?

I don't know how much I need to add here, but did you think that the wall was reducing free energy relative to the climber?

Did you say that?


SPEAKER_05:
That's right.

So my...


SPEAKER_00:
So I don't know how that, can that be the case?

Can that be the case?

The wall, the wall as a thing is maintaining itself.

And I mean, relative self-evidence thing, right?


SPEAKER_05:
Yeah.


SPEAKER_00:
But, but it's not really a duet of one here.

It's not like it has a generative model that's deep where it's modeling the climber modeling it.

Like the same way as tango dancers do.

A tango duo are having cooperative flow states because each movement opens a vista of possible error-minimizing opportunities for the partner who in turn opens a vista of error-minimizing opportunities for the partner.

And backwards and forwards into this ever-opening expanse of affordance capabilities.

But an inanimate object and an agent don't really have that same dynamic.

So I was wondering what you were thinking there.


SPEAKER_05:
So my thinking is that this kind of bleeds into the notion of fluidity of affordances, in the kind of Gibsonian sense, and the fluidity of concepts.

So I agree in the sense of physical self-evidencing, it needs to model the rain, it needs to model the physical environment, so as to maintain itself.

But what about...

So a sheer rock face is not a climbing wall.

And that's because it doesn't self-evidence as a climbing wall.

It doesn't offer the affordances to be climbed.

That's what I was kind of referring to, which is that affordances change based on the age and arena relationship, right?

Your car's affordances change whether it's working or broken down.

Similarly, the climbing will change whether it's got footholds, handholds, or whether it's just a sheer rock face.

That was my thinking.


SPEAKER_00:
It seems slightly spooky to me that we'd think of the wall as self-evidencing in that way.

I think the language that we tend to use, because Julian Kivstein, Eric Reitfeld, Eli Brunberg, and folks often use the idea of affordances and fields of affordances in the active inference way.

The radical end of the pool there is typically that the affordances don't only happen on the agent side, but rather happen from a dynamic of the changing volatile environment

and the generative model of the agent, and that they're collaborating in dynamic, ongoing ways such that the affordances are emergent between them.

That certainly seems right to me.

The idea to push it a little bit further and think about the wall self-evidencing, I think it's a step too spooky for me.

I think I would feel safer a little bit closer to thinking about, yeah, the affordances are changing relative to the dynamics of the wall, but I don't know what it would mean for the wall to be evidencing the climber or itself.


SPEAKER_07:
Ben, do you have something to add there?

Yeah, just to kind of, that's stirred a couple of thoughts.

Yeah.

a little longer on the work by affordances because there's this really nice distinction in their work between what they call, well, I'm not sure if they, I think the term landscape of affordances is a little bit older, but they make this distinction between a landscape of affordances and a field of affordances.

And I think the reason this is really important to get on the table is because this distinction is kind of directly targeting the dynamic, shifting, very affective nature of affordances.

So on the one hand, you have this landscape of affordances that is relatively static.

So right now, my landscape of affordances is Brighton, and the landscape of affordances in that sense is not really going to change very rapidly unless I kind of jump on a plane and go somewhere else.

But the field of affordances has this thoroughly kind of normative, affective character to it.

So depending on my internal state at any given time, depending on my expectations or my desires, say my field of affordances is going to shift very, very rapidly.

And it's so not just not just predicated on my internal state, but also kind of contextual cues as well.

So if something were to happen in the environment that was afforded very high precision weighting, then that's likely to shift my field of affordances significantly.

think that the reason that i'm kind of emphasizing this to darius's point is and kind of building on what mark said it it doesn't seem like this distinction at least would apply from the perspective of the perspective of the wall say because this kind of affectivity and normativity just isn't a feature of the walls experience of the world and also to kind of run with that the i mean affordances perhaps you could say a bit more about how you would kind of think about this darius because

Affordances are kind of opportunities for actions.

There's some debate about this, but I like to think of them as like a relational property.

You have the skilled capabilities of an embodied agent, and then you have some feature of the environment.

So I think when you're thinking in from the perspective of the wall, you have the features of the environment because you have the embodied characteristics of the agent are kind of playing that role.

But it's not clear to me what the kind of skilled capabilities of the wall is.

So, yeah, if you could just say a bit more about that.


SPEAKER_05:
Yeah, I mean, it may be the case, as you pointed out, that actually the technical term affordance as being opportunities for action is misplaced here.

Again, a lot of this I've been formulating having read this very new paper by Ramstein and colleagues on Bayesian mechanics of physics of and by beliefs.

where he really rams home this point that the system, the generative model is the system of the kind of stochastic differential equations across the state space.

So across the Markov blanket, across the particle with its Markov blanket and the external states.

And that is the system which is in, that system itself is in the business.

of reducing free energy.

So it's not just the active inference agent, it's the whole system, which is embedded in the whole system of other things.

And so that was my general thinking, is that just on the prerequisite that these systems exist, just on that a priori axiom, there has to be some kind of self-evidencing of that system itself.

So maybe affordances is the wrong word here.


SPEAKER_00:
Yeah, that might be the trick right there.

As soon as you provoke affordance, you're provoking phenomenology.

And so now we're not talking just about statistical variations.

Now we're talking about lived experience.

That might be the linchpin right there, I think.


SPEAKER_07:
I think that is right.

Yeah.

And I would say, I think, Darius, you're absolutely on the right track.

And you're in, I mean, there is this ambiguity about affordances.

But aside from that, I think you're absolutely right.

I mean, it's

It's just nonsensical to think about an agent absent an environment under active inference.

It is this agent environment system in its totality that's minimizing free energy.

They have to be taken together as one.

And I know, Abel, you've had your hand up for a little while there.

Is there something you wanted to add?


SPEAKER_08:
Yep.

Do you hear me well?


SPEAKER_07:
We do.

I do, anyway.


SPEAKER_08:
OK.

So about the afferences, wall-having afferences.

Basically, the symmetry of agents and environment is a property of active inference, well, of the Ferengi principle.

So if you buy the Ferengi principle, and you also buy that it entails that agents have afferences or any proximal notion, then you also buy that walls have afferences.

So there are basically three positions you can have on that.

One is that active inference is correct.

All are fucking affordances and they do self-evidencing, which I would not go with.

Another option is that you have basically devolved in the details.

So for example, maybe

The adjunct environment is not the wall.

It's something that is broader, like Gaia system, whatever.

And it just so happens it includes the wall, but it is not the wall.

And it does do self-referencing.

And the third is that active inference is wrong.

We don't have affordances based on whatever is the formal presentation of active inference.

And I would go in that direction.

of this phenomenology stuff.

So we have, I would say, philosophical evidence in the sense that denying this would lead to nonsense.

But information is based on observation.

And some systems do observing much more actively than others.

And maybe it's a good thing to have in your formalism, I'd say.

So you have maybe a stronger case for the way phenomenology affordances are constructed in the quantum formulation of the FEP.

If there is such a thing, which like Chris Fields, someone who we should baseline believe claims there is,

Because then you have formalization, which is not in terms of dynamics per se, so causal constraints, but observation and directly phenomenology.

Maybe you have something that is stronger there, but right now the link... Oh, sorry, there is actually a bunch of people who have a quite good hold on science, which are the

is based on the ecological activity and cognition on one hand, and between cognition and the metabolism, the constitution of the living thing that cognites on the other.

And that definition of agency, cognition, and PIC1 entails interactional asymmetry, I think is the word.

that maybe something we would need to translate into active inference well into the fep for active inference to have a strong grip over this affordance thing until then we have a kind of hand waving weight related to more conceptual approaches uh that are related to an active and ecological approach to psychology and um

Yeah, the formalism lags basically behind the concept for now.

Sorry for the long talk.


SPEAKER_07:
No, that was great.

Much appreciated.

Does anybody else want to come in on a question of affordances?

Because I know affordances played a fairly substantial role in the lectures.

so anybody has any questions related to affordances or you know action perception affordances then now's the time


SPEAKER_09:
Yeah, I do have one, but it's not well structured yet.

That could be fine, go ahead.

It's something that I've been thinking about for the last months because I started to keep an artificial intelligence field coming from a humanities background and philosophical background, so I'm mixing many things in this period.

mainly following the active influence as a as a crossroad between many disciplines that and this is very beautiful about the framework and i was super curious about the the question proposed by darius and i was then thinking about now we're actually facing a a new environment and a new landscape in which we're like interacting with the um actually generating


SPEAKER_07:
over evolutionary time and synchronizing over... logical alien agencies operating within our landscape and field of affordances.

So I think there's...

A lot of really interesting work to potentially be done there.

I will take the opportunity to shamelessly plug a preprint that Mark and I have released recently where one thing that I'm really interested in that I can kind of speak with some confidence on is the fact that I do think there's a point at which the theory of affordances or the language of affordances starts to break down.

So the preprint that I'll share around is looking at ambient technology specifically.

So this is technology that the whole kind of impetus behind its design and conceptualization is that the user doesn't have to actually do anything.

So it precedes the user pragmatically and epistemically.

It knows what kinds of things you want it to do, and it just does them in the background.

And it works by shifting

It subtly shifts the material environment such that it impacts your field of affordances in real time.

And the argument that we make in that paper is essentially that the affordances approach doesn't really work for this and that we need to kind of think again.

So, yeah, I mean, I think that that might be a nice point.

But like how to conceptualize generative AI, for example, under the affordances framework, I don't have anybody that's done any work on that, but it would certainly make a really cool project.


SPEAKER_08:
You are making it right now.

what's that you are making it right now i know because you sent me the paper to review oh yeah thank you thank you so um we were looking at we so we uh


SPEAKER_07:
early stages of a paper on the role of generative AI in classrooms.

So from the perspective of thinking about what kinds of affordances generative AI represent in a learning environment, particularly we're kind of applying active inference to classroom design and looking at it from the different angles of different educational and pedagogical theories.

But it's very early days, but that's

Yeah, I suppose it partly depends on your view of generative AI in general.

I mean, it depends whether you would consider it a real cognitive agent or not.

I think some people are more inclined to think of it as, you know, this is a thing that has agency, it has real understanding, it has like, you know, and other people are maybe less inclined to think of it in those terms.

And I think that might bear significantly on how you think of it.


SPEAKER_09:
Yeah, that's super cool.

Basically, the last project you mentioned is very, very in line with my PhD project right now, because my main PhD project is European farming, so it's about the AI for personalized education, and I'm trying to follow it through the active inference framework from a multilevel perspective.

So, yeah.


SPEAKER_07:
Very cool.

Yeah, we should probably talk more about that.

Okay, Darius.


SPEAKER_05:
Yeah, I wanted to ask, I mean, this may be directed more at Mark, because I know this is kind of his work, in terms of slopes of uncertainty and about doing better than expected at reducing prediction error over time.

I was wondering kind of how the architecture of that is built into the particle, into the generative model.

Because we have the kind of, for me, I don't know if it's an out and out sort of conflict, but we have these kind of implicit priors that we're going to fulfill certain expectations or minimize prediction error regarding certain things, right?

So homeostatic priors or happiness, well-being, whatever it is.

But then your claim is that we have the higher order beliefs, the higher order predictions that over and above that, I also need to do well, better than expected at reducing prediction error over time.

So it's still quite fuzzy in my mind.

But is there a kind of potential conflict there between the general priors that the system has

and then go actually in a sense, violating those expectations by going over and above them, which itself constitutes an expectation.

How do you kind of resolve that tension?


SPEAKER_00:
Yeah, that's interesting.

But this is very much in Ben's wheelhouse, too.

Ben and I have been working on slopey stuff for almost as long as I've been doing.

Yeah.

What was his original paper called?

We'll get it up.

They do a really good job of showing technically where this sits within a deep parametric model.

Lara Senved-Smith's paper on metacognition also does this by showing you have these depths of modeling where models above are modeling models below, and optimizing over those models below.

So we have some good computational backbone for not only thinking that this is the case, but

beginning to express how it does the work it does um so let's let's leave that for digging into it though technically on sort of on our own let me say sort of a at a higher more abstract level still hopefully it's useful um it's not weird to think that this kind of anticipatory system is not only making predictions about the world but it's also um

Part of what it's predicting is how fast or slow, how efficient it is in particular contexts at resolving certain kinds of errors.

That's a perfectly fine thing to think that we're also predicting slopes of engagement.

And then all we're saying then is system also pays attention to when those expectations are breached and it's learning from those breaches.

That should just be the bread and butter for what the system does anyway.

So precision is a second order process in much the same way.

Precision is about how reliable are lower-level predictions, and then using that amount to toggle how impactful either errors or predictions are.

So we've already got baked into the system right from early days, this idea that the system is not only making predictions but monitoring its own predictive processing regimes and then toggling based on how reliable those substreams are.

All we're adding here is when we first thought about those mechanisms, one thing that can happen, this is just good for everybody who's interested in active inference because I bump into this with my students all the time.

When we say something like precision weighting,

a tendency to think it's a thing.

So we go to find this precision weight, like where's the biological instead or like this precision weighting.

When we actually get into a bio system and we look for these things, the truth is precision is going to be weighted in lots of different ways.

I mean, that's the real frontier question.

of this research is to actually find how these things are instantiated.

And the answer is going to be multifarious.

I mean, it's going to be, you're going to have precision adjustments happening throughout the system in lots of ways.

It could be synchrony and asynchronous and desynchronies between systems.

It can be neuromodulatory chemicals.

It can be structural, structural, um, uh, shapes within the brain.

I mean, um, precision is going to be set in, in lots of different ways.

So, um,

All that we're pointing out here is that one of the ways that the precision is being set, one of the ways that the system is tracking how efficient it is and then upping or lowering the amount of impact error signals or predictions have is that it's happening in an embodied way.

So we've looked over to the affective search

And lo and behold, there are all these signatures that we were looking for this part of the machinery.

So not weird that the system is tracking its own regularities and adjusting.

That was baked in right from the beginning.

Now it does that.

That's one of the frontiers.

It's going to happen in lots of different ways.

Lo and behold, affect the dynamics.

The shoe fits.

They look like they do that stuff.

And then you bring it to the lab and you go back to like reward prediction error research.

And sure enough, neuromodulatory chemicals, reward systems are tuning affective dynamics relative to better than and worse than slopes of uncertainty management.

It's exactly what we would expect given the computational model.

So then it was an easy next step to start saying, well, look, there's one of the ways that precision is.

There's one of the ways that affect.

system now just notice there it's the only decision and not the only thing the affective system is doing we never want to say we never sort of we're careful not to be reductionist to say oh affect is always aerodynamics i don't think that's right i think it's that aerodynamics are expressed in part affectively and they have this impact on the system um that we can that we that we've known about for a long time even from just a reward prediction error um literature does that help or was that a


SPEAKER_05:
Yeah, yeah, yeah, yeah.


SPEAKER_07:
Yeah.

Just to add two things really quickly there, because I know time is kind of catching up with us.

I would emphasize as well, like just as a kind of general point, one of the things I really like about the work on aerodynamics and affect is it has this nice kind of broad capture of the kinds of affectivity that agents can experience.

So we're not just when we talk about affectivity, we're not just talking about

full blooded emotions or even just moods.

But we're talking about what is it?

One of the things I kind of drew attention to in the lecture was Matthew Ratcliffe's work on existential feelings, which I think is just such a the connection between active inference and phenomenology that you find in some of this work is just insanely powerful.

And it's one of the things that really drew me into the framework.

The second thing, just build the model.

One thing that I don't think I mentioned in the lecture is active inference.

It has been described as a quintessentially metacognitive framework.

So you have kind of built into the architecture, you have expectations over expectations.

So you have kind of predictions about predictions.

And this has proved to be just, you know, again, just phenomenally useful for thinking about certain aspects of phenomenology as well.

So, yeah, I think that these are these are like real strengths of the framework.

OK.

I don't know how we're doing for time.

Are we strictly limited, or can we?


SPEAKER_08:
We are not, as far as I know.

Daniel?


SPEAKER_07:
Well, I can probably do, definitely do another 15 if anybody has any more questions.

And people, I should say as well, that doesn't mean that we're all held captive to my timeframe.

So if people do need to leave within the next five or 10 minutes, that's absolutely fine.

But I'm certainly happy to carry on if anybody has any more questions or comments.


SPEAKER_06:
If no one else has got any, I would quite like to go back to earlier in the discussion, you were talking about the value of uncertainty.

Because in organizations in which I'm working with,

We often have conversations about uncertainty and what we find is over time there tends to be a drift towards risk aversion.

So we're working with a large international construction company at the minute and they used to have a culture in which innovation

uh was uh was quite well embedded and and over time it's kind of drifted towards very very risk averse culture where actually rather than learning through the process and being able to tolerate uncertainty you know around opportunities and you know what can be accomplished and that kind of the valence that comes with uh the intrinsic reward i suppose of being able to reduce uncertainty about capabilities to a situation where they're trying to anticipate

all of the risks upfront before they even get involved in the project.

So, you know, there's some kind of valence switch mark.

And you mentioned David Blaine earlier, you know, and something about the context, you know, there was a switch in valence from, yeah, this is a kind of a play.

This is a safe thing to do to actually know this is, you know, this has real consequences.

So I'm just kind of, I'd like to explore that a little bit more, actually, if anyone's got kind of any insights or papers or comments.


SPEAKER_07:
yeah so i think that's a really interesting question actually and i i think um so it seems like one of the things one of the things we've been talking about is this connection between uncertainty prediction error minimization and affectivity in individual agents and it sounds like what you're asking is like how does that

translate to like collectives so one of the things about active inference that we're going to see in subsequent weeks is how it scales up to kind of larger systems like companies or you know groups that are trying to achieve some kind of shared goal how do you how does the value of uncertainty translate onto like how is it scalable in that sense right is that would that be a fair kind of


SPEAKER_06:
Yeah, I guess so.

I guess it's... I mean...

So uncertainty, often when it's talked about, uncertainty is talked about as risk, which is, I suppose, is predictions or anticipation of outcomes that we don't want, right?

Whereas there's also positive uncertainty, which is, I suppose, simply stated opportunities.

Through curiosity, what might we be able to achieve?

This kind of novelty seeking, I guess, that new opportunities that we haven't exploited.

And they're just, you know, in the kind of organizational systems, you know, I think there are various pressures that cause it.

But over time, you see these cultural shifts towards, you know, a very, very kind of risk averse, you know, where, you know, where the valence is obviously quite negative, you know, you know, quite an unpleasant situation.

feeling for people.

And yeah.

Yeah, this is good.


SPEAKER_00:
This is right at the heart of my current work.

I'm really interested.

So we just had a big stint where active inference models were starting to be used in computational psychiatry, especially for pathological disorders.

So addiction, depression, dissociative disorders, OCD, PTSD.

It's quite a sexy framework for thinking about some of the ways that the cognitive system breaks down.

And the sort of new move right now, I mean, we have a collection coming out right now in neuroscience of consciousness, is to think about these things in terms of, okay, if we are predictive systems and we have a sufficiently rich model of how that system works in a particular niche, what sorts of ways can we intervene on that system in order to have positive outcomes rather than just modeling what the negative outcomes are?

And I hear that a lot in what you're saying now.

So I'm just going to drop one link for you there.

This is Casper Hesp again, wrote a little, a very small paper with a nice little model called sophisticated affective inference.

He has a little bot that tends towards catastrophe, catastrophizing the future.

If it's given, if it's given like fun, medium fun, medium fun, dangerous,

over time, it tends to expect the dangerous one.

After 10,000 iterations, it basically lives in the worst possible scenario, which is a nice little thought.

This is my wife.

This is most people today.

So the question is, I want to know, given the model, why does that happen?

And what can we be doing to intervene?

And part of the answer is going to be

we need to become more tolerant of uncertainty.

That's one of the things that the system can be better or worse at.

So this just takes the computational modeling and then looks to things that we already know about emotional regulation.

That's part of the story.

So we've done a little bit of work on this with our predictive dynamics of happiness and well-being.

And Ryan Smith is definitely doing work on this with active inference and well-being.

So definitely check that out if you're interested here.

I'll just flag one interesting thing here that relates just to what we were just talking about, about layers of modeling.

One way, let's say two ways.

There's two ways that a system, and it's probably going to be lots, but the two that come to mind that a system can become more tolerant to uncertainty is one, exposure.

So this is why exposure therapy might be useful for our kind of a system.

You want to expose the system to volatility at the lower and middle levels of the hierarchy and have it turn out okay.

So that one of the things that the system can come to predict is not only, you know,

particular outcomes, but it can also predict how much error is involved in particular outcomes.

So for instance, when I used to give a pro talk, I was always really nervous.

And I don't know if that ever really went away, but I've had so much exposure to the anxiety of giving a professional talk that basically I don't notice it anymore.

But if you were to ask me at the beginning of my talk, Mark, right now, what's your phenomenology?

and I sort of meditatively looked, I'd probably say, yeah, I'm nervous.

But if you hadn't have said that and you were just like, hey, what's up?

I'd have been like, oh yeah, I'm great.

Like, it's all good.

I don't even notice it anymore.

That's because the system knows that I have errors

but as soon as i start talking they drop away and because i know the arc that even error in the system it becomes non-newsworthy it's no longer interesting volatility to be tracking that's just from exposure okay so what's happening is you're having errors at a lower middle level that a higher level is now modeling saying when we come here we should expect this arc of error same thing when you work out like real gym rats they can feel good

you're having your jet your tiller skeletal system right but at the higher level it's now learned not only that that has a natural arc but that that's a good sign at a higher level so now you're getting a positive you're getting positive prediction error slope high and negative prediction error slope low

Okay.

So one is exposure.

Two, you can model your own responses.

This is something Ben and I work on with horror movies.

You can take an active role in mindfully observing your own reactions to volatility.

And this comes up in our paper on horror.

We've already dropped the link today if you want to check it out.

something really special happens when the system models its own reaction to volatility it starts to learn that um even reactions to volatility uh don't need to be um they don't need to be compounded up into dangers that it's okay it's okay to be uncertain at certain levels of the system so how that translates into business i'm not sure other than i know tolerance to uncertainty is a marker of business success

and um i suspect the framework in a fit like lots of mindfulness mindfulness work about learning to tolerate uncertainty is there anything about um the role of language in kind of modulating those metacognitive oh it's good if i'm there i was uh preparing an answer on that specifically and i was nervously waiting for the opportunity so um


SPEAKER_08:
Like meta, in terms of evolutionary, cognitive archaeology, we don't know when language emerge, but we do know that it's an anchoring semantic system.

So you can build things in language and you can expect things in the world to correspond to things in language.

So for example, if you, that's abstract, as I say, it's abstract, but you can, for example, have a self-identity and I'm French, I'm a French.

And I communicate with the expectations that are embedded in that identity with other people.

And that means we communicate over norms.

So we have specific expectations of what we will do.

And those expectations, they become embedded in specific symbolic markers that are embedded in language.

And something that, like the thing that it was strongly evoked in my mind when you talked of tolerance to insecurity is that

As far as documented history goes, Europeans, well, Indo-Europeans, they are pretty strong on the idea that things have a nature and they act lawfully and their nature and their laws, they somehow correspond to linguistic categories.

So I can say stuff like chickens quack, and that's a proper explanation of what are chicken and why they quack.

And if you look in Chinese philosophy, as far as written history goes, you have a much better accent on Wei Wu Wei, so a poor translation would be an effortless action.

A closer translation would be action without action.

So it's a form, it's something that is quite close to the phenomenology of flow in that you observe yourself doing things and you do not apply a conscious effort to the flow of what you're doing.

And that looks like something that is closer to the phenomenology you'd expect if you apply, you know, recursive predictive cognition with less or less heavy or more effectively integrated symbolic occurring, like use of language as something that you actually expect to be meaningful and to constrain strongly your actions.

And marginally, I'd expect very strongly symbolic

expect that linguistic categories will map and what you build with it so i don't know self identities plans whatever uh will map cleanly onto what you observe you will be very very anxious about things because that does not happen usually um and yeah um besides uh grand discourse on the interpreter prefer um traits which are usually not that constructive i'd um

Sorry, I got lost because I did not have the speech.


SPEAKER_00:
Let me just say one thing before we move off this point.

A simple way that language might help is by invoking cognitive flexibility.

So oftentimes, we think about the management of error being either updating predictions or acting on the world.

That's the dyad, usually.

What it overlooks is the third one, which is we can also manage volatility by redeploying precision in a better way.

So rather than just updating your model to fit the world or updating the world to fit your model, you can just change the set of what matters so that you're not really updating the model and you're not really changing the world.

You're just changing the problem landscape.

And that's something language allows us to do.

It's maybe one of the really...

Amazing things that language allows us to do is we can use language to bootstrap that kind of precision adjustment.

So if the train doesn't come on time, we both notice it, okay, and we feel bad.

That's perceptual updating.

We might go and get a taxi.

That's active updating.

But I might just say to you, wow, look, isn't it lovely that now we get a little bit more time to read our book or to continue our conversation or let's finish our coffee with a little bit of ease.

I mean, we get an extra 20 minutes now.

Even just saying that redeploys precision over the problem space.

Now, the train being late isn't volatility in the system.

The train being late is signaling to the system that a better than expected slope has been achieved.

Isn't that so interesting?

The exact same occurrence is either undigestible volatility, right?

Like you're going to be late.

Oh my goodness.

Or it's an opportunity for an improvement in the system, which is now you get more time with the person that you're taking the train with.

And that was just a matter of linguistic perturbance of the way that precision is being deployed.

So if you're looking at, if you wanted to dig into the research here, I would look up cognitive flexibility and language or coaching.

Cognitive flexibility is such a good point here.


SPEAKER_08:
So you have a paper by Nick Clark on this specific and current role of language, and something it entails is that basically you've got

Like, if the active infrastructure is correct, you flexibly predict the flow in the interoceptive, proprioceptive, exteroceptive, is that even a thing, space.

And that is what builds an integrated experience, integrated cognition.

And language, it adds another layer of complexity.

If you can just talk to yourself in your head, that is another dimension that you can predict and that can be coherent or incoherent with your world.

And so that is an extremely powerful anchoring system because I just have to tell a plan to myself and boom, that pushes me, nudges me nicely for the plan.

But then you can have a different level of meta expectation over how language corresponds to reality.

And I'd say,

a very, very strong factor of, you know, aversion to uncertainty is whether you expect your plans or your linguistic structure to nicely map them to reality because it will not happen.

But if you expect strongly that it will be the case, you will have to make it happen somehow.

And here you will adapt rigid strategies and you will like lose flexibility, but also language and story for flexibility to be the case in the first place.

So it's about coupling between dimension of cognition.


SPEAKER_07:
Yeah, and I would just kind of, risk and danger are two things that I've been really interested in across a kind of variety of different contexts.

And I would say,

some of the things that have been said like the kind of how you can influence the system by externalizing things through language and the different strategies that systems whatever scale they're on have minimizing prediction error um minimizing free energy but also I would just emphasize the importance of like external context here as well so even in the case of like a collective like a business you still have to

take into account the environment in which the business is operating.

And I've been really interested in a particularly extreme example of context.

I used to still do some work in philosophy of sport, and I've been really interested in dangerous sports and why there seems to be this insane contextual effect where

within a very kind of narrow contextual band of sporting practice people seem willing to take on risks that outside of that context would just be completely insane um and i think this is something that's probably going to come up again again in uh you know subsequent weeks as well here when we talk about um the way that expectations on an individual or a collective basis can be set but through other minds uh like


SPEAKER_05:
patient so what somebody else and expect myself to do and and so on and so on uh darius you've had your hand up a while do you want to jump in yes please i'm not sure this is the sort of grand synthesis of any of this but um flow was mentioned as i said it's a kind of um pet topic of mine and something that we know about flow and this way it's integrated into this idea of language and agency

is that at least in its original conception of Success Mahali and the qualitative experience associated with flow, you would find stuff like not only the dilation of time, but also the reduction in self-consciousness.

And now this is sort of picking up a lot of work that happens at UCL and people like Jeremy Skipper, how integrated language is into the sense of self.

And it seems to me, and I, you know, this is kind of shooting from the hip, that all of these very deep rooted, I guess they're kind of psycho technologies, the self language seem to dissipate at this Goldilocks zone, at this point of, at this edge of criticality, at this flow state.

Which makes me think if the flow state is a phenomenological offshoot of being optimally reducing prediction error, what is the kind of role of the concept of the self or linguistic functions?

Because it seems to me that that becomes a regulatory function when that optimality is reduced, when stuff starts going wrong.

um so i think you can also think about this in the kind of heideggerian or dreyfus sense of just opening a door you only start to represent the door in yourself you only give it the linguistic object of a door when you can't open it when you open the door standard there is no representation going there i mean you could even argue there's no qualia there so i'm wondering how deep that runs and what the kind of what we can say about the role of agency selfhood maybe even consciousness

because they don't seem to be that prevalent, at least from my understanding, when we are at the edge of criticality.


SPEAKER_07:
is the suggestion you're making there is um it sounds like what you're saying that these you call them psycho technologies which i really like uh you know like language and uh and and self like certain aspects of self-modeling they are a kind of scaffolding uh or like a ladder that you then kind of gets kicked away once you reach a certain kind of edge of criticality like where the performance becomes

I don't know what you're performing at such a level that you just don't need those, those scaffolding.


SPEAKER_05:
Yeah.

Or, or the self regulatory mechanisms that we harness when we're not in flow are linguistic or agentic in essence.

And once, yes, once you sort of, you don't need that when you're the sort of, yes, when you're at this edge of criticality, um,

And I only postulate that because I'm only thinking how deep does that go?

Because I know obviously the active inference framework is trying to tackle in some ways the hard problem as well.

And there are some flotations of the idea, at least within the flow community, about the kind of

want to say elimination but the moderation the modulation of qualia under flow states so could that could we also consider that to be an a construct um which happens when we're not necessarily

are optimally producing prediction error.


SPEAKER_07:
So a couple of things.

So I'm certainly not the person to stop talking about consciousness, so I won't.

But I would just... Some of the readings that I mentioned in the lecture might be interesting for you on this topic.

So if we're talking about certain structures that seem...

very, very pervasive in our phenomenology and how those structures can sometimes kind of dissolve away and how that might be accounted for under an active inference framework.

There's some really interesting work on psychedelics by George Dean and some of George Dean's co-conspirators.

I know Mark and Sam Wilkinson worked on a paper with George.

So George Dean's done some work on kind of ego dissolution and certain kinds of experiences related to selfhood kind of, and I, I,

kind of don't want to overstep the mark, but I think they kind of come, they fall generally under this kind of rebus model of psychedelic efficacy.

So I don't know if people are familiar with this, but this kind of finds natural articulation through predictive processing and hierarchical self-modeling and that kind of stuff.

I also wanted to really quickly flag on this topic.

I'll find the paper and I'll put it up on the Coda because I don't think I'll be able to find it quickly enough now, but there was a paper that came out very recently

that showed the efficacy of internal self-talk on sports performance.

So they did an experiment with cyclists and they found that when cyclists were allowed to engage in kind of constant self-talk with them, so like an inner monologue in their head, their performance at cycling was like measurably boosted, which I thought was really interesting and kind of relevant here.

But it's interesting because it kind of just kind of,

uh it sounds like it might prima facie be in tension with what we were saying about flow states as well right so it's if if the real edge of performance is is a place where these structures of phenomenology phenomenology bleed away um it kind of calls into question like to what extent are these psychotechnologies effective and in what way are they effective and yeah there's like yeah just a whole kind of universe of really interesting questions there


SPEAKER_08:
So if I may, selfhood indirectly will be the central topic of the last two sessions.

My position about it is that it's selfhood in a sense we use all of the time.

It's a quite high level construct that emerged from the ability we have to compare our activity to a

socially embedded model of our activity so that is something that is quite specific to humans because of their linguistic ability and or because of their tendency to um what tomasello calls a shared intentionality so the ability to collectively define and like plants

So basically this is something that enables a very deep, very profound and robust transmission of cultural knowledge and transmission of norms.

This is what enables the construction of norms, but it's quite heavy cognitively and

it is predictable that if you're busy comparing what you do to what an idealized version of yourself is doing you're gonna invest less creative energy in actually doing the thing that you would if you just you know did a thing so i'd say you have a pretty direct entitlement of the uh this flow thing uh from this model


SPEAKER_07:
Yeah.


SPEAKER_08:
Yes.

This is my question.

Sorry.


SPEAKER_07:
I think so.

We've run almost 30 minutes over time and I know Mark's had to go and I'm going to have to go very, I think I pretty much have to go.

So I just wondered if anybody has any final kind of quick questions or comments, maybe we can move towards wrapping it up.


SPEAKER_04:
I'll make a few comments, but Ben, you're welcome to leave other

So, thank you for... Yeah.

Well, first, just on a...

Logistical note, there was a little bit of lag, so I'll encourage everyone who's listening as well as who's participating that we eventually plan to, as with all of our live streams, develop a transcript, which will be curated and published, and eventually, not so far away in the future, that'll be enabled with speech modeling to generate podcast quality audio.

But a few really interesting pieces that I picked out while I was embodying and listening.

So Regina, you opened the discussion with surprise and creativity and indeed it sounds like it's going to be a tension.

How can a framework whose imperative is bounded

in a framework whose imperative is surprise, minimization, and bounding be used to generate novelty?

And I felt like people provided a lot of really cool answers.

And one other thing it reminds me of is Doug Hofstadter's

s h n e s s and it's the specs wasp and so he says well forget this whole creativity thing because when we talk about creativity it's like some sort of you know pantheon like divine status the muses have to be uh you know called in and so then oh that's not real creativity and this isn't real creativity so instead he says well let's just focus on what would be the opposite and that would be the rote

There's an opportunity for what we would call creativity.

And then there's a continuum.

So why does somebody paint that painting?

Why didn't they invent a new genre?

Why didn't they invent a new media?

And so all activity is existing within this continuum of creativeness.

generativity and productivity, but also novelty, but abounded novelty.

It's not creative to knock the chessboard pieces off in a way that there might be an elegant chess move who only

I think that was awesome.

And then the second piece that really was powerful was Mark's train.

I guess the trains don't run on time where Mark is, but that's okay, because he was able to, rather than treat that,

metabolized into like an opportunity for friendship through language as a social medium and then he connected that to cognitive flexibility and coaching and I thought about self-talk and our inner monologue inner voice

talk potentially not even having a self in the flow manifold experience of the self or the speech self self-talk or again potentially even the total actual self as a technology and so then like healthy self-talk would guide us to the flow and be kind of like a self-limiting technology

because it would be like used in order to not be needed to be used, which is kind of how we would hope adaptive technologies would be versus a maladaptive technology would be something that, um, entrenches its own utilization potentially at the expense of the functionality, kind of like doom scrolling status, but that's internal rumination.

And those are the kinds of things that people have simulated in active inference

So those were some really cool pieces.

That was a great discussion.


SPEAKER_07:
Could I just add something on the topic of creativity that I should have said earlier as well, because I think it's really relevant to Regina's question and just the topic of

creative and novel behaviours in general under active inference, I think that whenever we talk about, especially artistic creativity, there's a tendency, even for people who are very well-burrowed into active inference and

and activism and these kinds of frameworks from cognitive science, I think there's a tendency to think of creativity as still like it's almost like the last bastion of internal cognitivist thinking.

Like you think creativity is something that happens in here and bursts outwards.

And so how does that happen with this kind of whatever cognitive architecture we're positing?

But there's really very cool work by, I have to give a shout out to Mike Wheeler, who has written some papers on the extended mind and creativity.

And one thing that's not really come up very much that I didn't get time to talk about in the lecture is this really nice natural marriage between the extended mind and active inference, something that Andy Clark has been working on.

And I know he's going to be doing a lot more work on it.

But the claim Wheeler makes and some others

I think Joanna Zielinska has written a little bit about this as well, is the fact that creativity itself is just as subject to kind of material, but the sculpting effects of material environments and socio-cultural environments as everything else is.

So creativity is not this kind of romantic with a capital R kind of internal process that kind of bursts forth, but it's creative thinking is just as much extended and embedded as everything else.

And there's some really great examples in Mike Wheeler's essay.

I don't know.

Is anybody familiar with the band Alt-J?

They're a British band.

They were kind of really big a few years ago.

They won the Mercury Music Award because they have a super original sound.

So Alt-J have this really quiet tinkling.

Yeah, they are a great band.

They're one of my favorites.

And they have this really quiet tinky sound that everybody kind of assumed was just the result of some kind of internal genius on the part of the band.

as it turns out alt j originally they they tried to rehearse as a as an indie rock band but they were confined to rehearsing in an apartment block and they kept getting noise complaints and so they ended up developing this quiet tinkly sound because it was the only sounds they could rehearse that wouldn't get them kicked out of their apartment and i think this is a really beautiful example of how like even the most creative processors that seem on the face of it really creative are in fact


SPEAKER_04:
just a subject these external kind of this kind of agent environment system that underpins the whole framework so it's that's something that's going to apply to absolutely everything awesome and just the last question people are welcome to to drop off um the next section that we're heading into I'll be doing the lecture that's going to be

on collective behavior.

So what would people like to learn or focus on about collective behavior?

Anyone who hasn't spoken or it can just be a thought question.

But I haven't prepared the slides at all, so.

I'm happy to take suggestions.

Yeah, Darius, and then anyone else.


SPEAKER_05:
I think what might be interesting is if we're saying that these systems are all in the business of reducing prediction error of self-evidencing, why do we see a diversity of social cultures, of norms, of standards,

at a global scale, why do we not just see some homogenous way to reduce friction there, which would manifest as a kind of singular culture, which is in the kind of business of self-evidencing?

That just kind of popped in my mind.


SPEAKER_04:
Anyone else want to give a thought on collective behavior or on any other aspect?

Otherwise, it's been great.


SPEAKER_08:
I'd like to make a comment of creativity.

So, but does anyone, like, at the moment, if you want to make a comment on the next session, I'd want to get that.

Okay.

Go for it.

I'd say that, to complement what Ben said, that creativity is intrinsically very hard to model because, by definition, creativity is something that brings about something new, let us say, and the mathematics we have to describe physics and life, they are not very good at new things because the most basic tool you have

the basic way to represent a system that literally everyone uses is a state space which is uh the least of all possibilities of the system if you say something is creative you're likely to think that it means it can bring about new possibilities and this intuition it conflicts directly

with the very basic use of math to describe it.

So it is basically the same issues I was referring to earlier when I talked about the comparison between active inference and an activist, so let's say,

activity biology inspired model of cognition and a core concept historically in those circles is autopoiesis so the ability of the living to self-create literally this is greek for self-creation and you had a lot of drift and conceptualization and ambiguities that were resolved or not resolved and led to the crisis of framework blah blah but today we talk of autonomy rather than autopoiesis

And we define autonomy as the property for a system of constraints over the activity of a system to reproduce themselves.

And because we're talking constraints, just the ability to influence causality outcomes, there is no really a prior that dynamics in this space would be conservative.

So we have a possibility for constraints to bring about new things and reconfigure themselves.

And the notion of agency at use is based on that.

It's the ability to, let's say, reconfigure constraints in your environments.

And so is the notion of creativity, which would be likely a very close proxy to that.

But it's something that we do not know how to prevent.

And most of the mathematics that exist are structurally enabled to represent.

And so, yeah, that's a big one.


SPEAKER_04:
So true.

Michael?


SPEAKER_11:
Good to be here.

Sorry I was late.

What comes to mind for me at the collective, you know, I mentioned units of collective life.

What is it a we?

Is it a we a pair?

And, you know, what

you know, what are the units of we and any thoughts or insights about that?

The stages of the emergence of formation into a collective from a me to a we, for example, or I had one that was on the tip of my tongue and it just escaped me.

Oh, you know, this idea of precision that I think it was Mark Miller was talking about from Matt saying,

If there's options in the looking at collectives and what might be some of the most well-understood limiting beliefs about when we use language of collective that keeps us repeating the same blind spots.

and how might we think differently about collectives so that we escape those predispositions, if you will.

Make sense?


SPEAKER_04:
I'll do what I can do in the solo lecture, and I'll look forward to the conversation where we can unpack it.


SPEAKER_11:
Yeah.

Exciting.

Thank you for doing it.

I'm looking forward to it.


SPEAKER_04:
Yeah, it's awesome.

Nathan or David, you want to add anything?

All right, then thank you all.

Hope everyone is enjoying the course so far.

Thanks, Aval, again for coordinating it and to Ben for this great section.

Now you can put on your student hat again.


SPEAKER_08:
And to you for organizing.


SPEAKER_04:
Thank you.

See you all next time.


SPEAKER_08:
Thanks, everyone.

Bye.


SPEAKER_11:
Bye.

Thanks, everyone.