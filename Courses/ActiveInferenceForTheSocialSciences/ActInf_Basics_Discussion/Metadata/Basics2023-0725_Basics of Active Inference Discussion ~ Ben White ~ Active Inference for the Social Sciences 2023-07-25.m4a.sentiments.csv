start	end	speaker	sentiment	confidence	text
420	970	A	0.546256959438324	You.
5180	5896	B	0.4896697998046875	All right.
5998	7896	C	0.7935150861740112	July 25, 2023.
7918	13780	C	0.8907151222229004	And we are in the discussion section, basics of Active Inference.
13860	20148	C	0.9640112519264221	This is the first discussion section that we've had for this course, so thank you all for joining.
20324	27260	C	0.8387646675109863	And it's going to be regarding the topics that Ben White introduced in his recent lecture.
27420	33810	C	0.9196909666061401	So everyone will be welcome to pop in and introduce themselves.
34260	44468	C	0.8141082525253296	And then I know that Ben has some ideas to discuss and many other spontaneous and written questions will come into play.
44634	55240	C	0.878035306930542	So with that exit for now and pass to perhaps some of our first time live streaming guests.
67850	71686	D	0.8164643049240112	I guess I've already spoken, so I may as well continue.
71788	73050	D	0.7840184569358826	So I'm Darius.
73790	75002	D	0.8548741340637207	I am Master's student.
75056	80006	D	0.906737744808197	I'm just about to finish at UCL in sort of social distributed cognition.
80118	94202	D	0.8028303384780884	I work in a social cognition lab looking at salience regulation and attentional mechanisms within social contexts, but all within an active inference framework, within the Bayesian brain hypothesis framework.
94346	98762	D	0.7448081374168396	And, yeah, it's a sort of recent discovery and obsession.
98826	102740	D	0.8164845705032349	And so I'm sort of getting to grips with both the high road and the low road.
103350	113430	D	0.9093448519706726	And so I've had the opportunity to chat to Mark and some other researchers who have been super informative, but always looking to learn more and get my head around even more of the sort of philosophical and mathematical theory.
115770	116520	A	0.84200119972229	Cool.
117530	118600	A	0.9471787214279175	Sounds good.
124170	124822	E	0.5403040051460266	Hi, everyone.
124876	125880	E	0.8097810745239258	Can you hear me?
126410	127298	A	0.560655415058136	Yep.
127474	129022	E	0.8386948108673096	I'm Francisco Balsan.
129106	137040	E	0.6882557272911072	I'm a PhD student at the University of Bologna, Italy, actually working on intersection between artificial intelligence and education.
137890	146494	E	0.7766591310501099	I have a background in cognitive anthropology and philosophy of science, and I met Axel and Maxlin a few years ago.
146692	160222	E	0.6910268664360046	So I dive into the rabbit hole of active inference and currently pretty much interested in multiscale active inference models of scientific cognition.
160286	169842	E	0.9046385288238525	So pretty interested about the agent level modeling of scientific reasoning assumption that might emerge from the interaction with a scientific environment.
169906	176398	E	0.8504559397697449	So we're referring to scientific nature, construction and all these type of top down and bottom up interactions.
176434	180202	E	0.9760401248931885	So super interested to hear something from you.
180336	181260	A	0.8529649972915649	Thank you.
183630	185020	A	0.9599630236625671	Thank you very much.
188760	191990	A	0.9211029410362244	Would anybody else like to introduce themselves before we start?
194840	196310	A	0.7793062925338745	So you go first.
196840	197348	F	0.584351658821106	Okay.
197434	199504	F	0.821316659450531	Hi, I'm Regina Sagin.
199632	200844	F	0.8521580696105957	You can call me Gina.
200912	202340	F	0.8259249329566956	I'm from Guatemala.
202420	205348	F	0.5858137607574463	And well, I'm not from the social sciences.
205444	207828	F	0.8430191874504089	I come from biology and neuroscience.
207924	218008	F	0.5613861680030823	And I'm here because I'm working on a project as a technical operator in this big project in the Xscape and material minds.
218104	224680	F	0.7691895961761475	And I do the technical part and experiments, but I want to learn the philosophical part.
224770	228880	F	0.8359853625297546	That's the background that makes the theory of everything.
228950	231436	F	0.8079877495765686	We're going to experiment.
231548	233330	F	0.7701315879821777	So I'm here to learn.
234340	246384	F	0.46918997168540955	And also, I am like when you see the Olympics, that you see all the swimmers, and I wish there was a normal guy to see how good these people are so you could compare.
246432	248292	F	0.8226778507232666	So that's me today, right?
248426	253656	F	0.8895686268806458	I understand half of what's going on, but I'm happy to be here, so yeah.
253758	254410	F	0.5325649380683899	Hi.
261560	261924	A	0.509212851524353	Sorry.
261962	262736	G	0.7025122046470642	I'm Leigh.
262848	264128	G	0.7676509022712708	So my name is Lee.
264224	270120	G	0.9163766503334045	I'm a PhD student at the University of York studying systems transformation.
271420	283748	G	0.5431267023086548	And I'm joining because I'm using perceptual control theory at the minute to model examples of effective practice in organizations.
283844	299404	G	0.6935843229293823	And I've read quite a lot of active inference papers, and I understand that there's a lot of resonance overlap between perceptual control theory and active inference, although I understand it's within a predictive framework.
299532	311684	G	0.8600203990936279	And also it's kind of a level of abstraction higher, so you're able to kind of quantify the difference between sort of the predictive state or the outcome state and the current state.
311802	327080	G	0.726503849029541	So what I'm really trying to understand is how might that level of abstraction be useful in what I'm doing, actually, because I understand it's a much more kind of concurrent theory and framework than perceptual control theory.
330950	332260	A	0.9540662169456482	Yeah, very cool.
333350	334500	A	0.7172255516052246	Anybody else?
337830	338980	A	0.7712940573692322	Is that everybody?
341670	349240	A	0.847224235534668	Okay, well, has everybody seen the lecture that I gave a couple of weeks ago?
350170	362540	A	0.5562635660171509	Okay, so I think it might be helpful then, if I kind of very briefly go over what we covered in that lecture just to kind of jog people's memories, and then we can maybe pick up some questions from there.
363070	373374	A	0.682892382144928	So the lecture last week was on the basics of active inference, and it was intended to be an introduction to the framework on a very abstract, philosophical level.
373412	377818	A	0.6492314338684082	So it left out all of the kind of mathematics and technical aspects of the framework.
377994	389454	A	0.8273401856422424	And the objective really was to lay the groundwork for future weeks in this course, because this is obviously a course on active inference in the social sciences.
389582	398914	A	0.8423524498939514	And so in the subsequent weeks, we're going to be looking at topics like collective behavior, social cognition, shared norms, and niche construction.
399042	410534	A	0.8835188150405884	And so what I wanted to do was to put on the table a kind of fully fleshed out picture of what the individual agent looks like in active inference.
410662	427066	A	0.8705742359161377	And so to do this, we looked at emotion, agency, mind, so we looked at kind of the role of action and perception, the role of internal representations in active inference.
427178	441490	A	0.8993029594421387	And then as a case study, we looked at an active inference based account of addiction to kind of bring all of these threads together, to kind of articulate a lot of the things that I'd said in the previous sections.
446250	450786	A	0.7491850256919861	The questions here don't have to be specifically tethered to that lecture.
450898	461980	A	0.8640114665031433	I suppose we can just start with any general questions about active inference and philosophy and how active inference applies to individual agents, or if anybody did want to pick up on any threads from the lecture, then we can go from there.
466210	469858	F	0.8640369176864624	Can I ask something just for the basic questions?
470024	471140	A	0.5765852928161621	Yeah, of course.
471830	482770	F	0.5423322319984436	I don't understand because I think you explain it later, but how does creativity and science in general enters active imperents?
483130	490360	F	0.48804202675819397	How does trying to be creative and not doing what you predict enters this room?
490810	493640	A	0.9551777839660645	Yeah, this is a really good question.
495710	497210	A	0.8426229357719421	Did you see the lecture?
498670	501100	F	0.7503365278244019	Yeah, but I remember half of it.
501630	506620	A	0.7930019497871399	That's fine, but do you remember the dark room problem?
507090	510000	F	0.6872494220733643	Yeah, I know that's where the answer is.
513090	521410	A	0.9468338489532471	I think there are several interesting dark room problem, some of them more interesting than others.
521480	525890	A	0.4757654070854187	And I tried to cover I obviously didn't have time to cover all of those in the lecture.
527750	548810	A	0.6201332211494446	But for those that perhaps aren't familiar, the dark room problem is this kind of canonical philosophical worry about predictive processing and active inference that says essentially, if all we're trying to do is minimize prediction errors, why don't we just find maximally predictable environments?
549150	556250	A	0.5760122537612915	And why do we not just lay in a dark room hooked up to an intravenous drip and enjoy kind of error free lifestyle?
556910	560894	A	0.8464134931564331	So I think that's the question that you're articulating there.
561092	563306	A	0.862256646156311	I just quickly see a hand from Darius.
563338	565760	A	0.9020272493362427	Darius, did you want to jump in, or was it a separate question?
567490	568814	D	0.8072672486305237	It's a separate question.
568932	570794	D	0.7614536881446838	So I thought I would just do it in advance.
570842	571806	D	0.5029982924461365	But yeah, no, ignore me.
571828	573218	A	0.8499592542648315	I'll circle a call background in a second then.
573224	575506	A	0.5379385948181152	But feel free, I should say.
575528	584514	A	0.5908802151679993	Actually, this is the first time I've kind of chaired a discussion like this, so I'll be explicit and say people should just feel free to jump in whenever they want.
584552	591880	A	0.7298332452774048	If you want to take the disco, if you want to kind of add something or kind of build on a question that we're answering, feel free to jump in.
592970	610510	A	0.8253755569458008	But, yeah, with the dark room problem, as I'm aware, the first answer to that question and this is something that I did cover in the lecture, is essentially a big part of active inference is to recognize that agents are it's a kind of fundamentally embodied framework, okay?
610580	614462	A	0.8599046468734741	So that can be kind of cashed out in various ways.
614516	630210	A	0.7417095899581909	But one of the most important ways is that the expected states of the organism or that the agent are necessarily rooted in the phenotype of the organism and the kind of evolutionary biological needs that come with having a particular body.
630360	636774	A	0.8586033582687378	So there was a paper that I referenced in a lecture by there's three authors on this paper.
636892	641794	A	0.6858000755310059	It's andy Clark, Karl Friston, and then I'm forgetting the name of the third author.
641842	645494	A	0.8726421594619751	If anybody can recall, feel free to drop it in the chat.
645622	665146	A	0.5363256931304932	But this is an answer to the dark room, where it builds on that notion of embodiment and says, look, creatures like us, human agents, could sit in the dark room and do nothing and just kind of enjoy the very predictable march of hunger, thirst, et cetera.
665178	668110	A	0.6088433265686035	But obviously, those particular biologists out of the room.
668260	671060	A	0.7886621356010437	And so you have this very fundamental level.
673830	679314	A	0.8466964960098267	We have this very fundamental kind of basis upon which we have these needs that need to be met.
679352	686614	A	0.6762626767158508	And so we need to engage in exploratory behaviors on the topic of novelty, because that's a kind of base.
686652	689160	A	0.8773618340492249	I take that to be a kind of baseline answer.
689770	706230	A	0.719567060470581	But there are clearly kinds of activities and behaviors that we do engage in going beyond the dark room kind of curiosity play, creativity, engaging in kind of why do we create works of art?
706400	716990	A	0.494266152381897	And there's not an obvious link between those kinds of behaviors and the kinds of biological needs that are emphasized in the original answer to the dark room worry.
717970	730174	A	0.8669648766517639	So in answer to Regina's question about creativity, I think that a good starting point for this is the section on aerodynamics that I introduced in the lecture.
730222	744690	A	0.8295315504074097	So this was the idea that there's this strong connection between affectivity as a kind of emotional, embodied feeling state and the changes to the rate in prediction error minimization.
744850	746070	A	0.6297039985656738	So I don't know.
746220	749994	A	0.6278085708618164	I am now very much articulating Mark's work here.
750032	754940	A	0.5147870779037476	So I don't know if Mark wants to jump in at any point and do a much better job than I can.
758530	762170	A	0.6953840255737305	I think there's certainly work on the horizon.
762330	772770	A	0.8336614966392517	I know that there are people who are currently building up theories of artisticity that are based on this idea of aerodynamics.
773110	805290	A	0.9724881649017334	So Mark's paper on play with Mark Anderson that I mentioned has a really interesting idea where if you explore playful behaviors which are kind of fundamentally creative and it's an inherently creative exercise, I think the really interesting idea that comes out of that is one thing that we engage in because it feels good is we create niches of very manageable prediction error that we can then minimize.
807410	812382	A	0.5888967514038086	So, yeah, that's playful behavior is the answer to the puzzle of play.
812436	823374	A	0.6048761010169983	So the puzzle of play is why do we engage in metabolically quite costly and they don't have any obvious benefit.
823502	833566	A	0.8960092663764954	And the idea there is that, well, there's kind of several ideas in there, but one of them is that it just literally feels good because minimizing prediction error feels good to us.
833608	837480	A	0.9149097204208374	So whenever we do better than expect at minimizing prediction error, it feels good.
840010	851980	A	0.8317066431045532	Obviously, I don't know for sure, but I think that any answer that we give regarding artistic creativity is going to fall within that kind of bulb that essentially we engage in.
852350	869306	A	0.7391327023506165	The part of the creative process is just constructing those that give us tasks of manageable prediction error that ideally fit at the boundaries of our skilled capabilities.
869338	871170	B	0.8896574974060059	Can I add two quick things there, Ben?
871510	881250	B	0.5173985362052917	So that was a great explanation, but just to hit two points a little bit harder, one, you might think all that matters error.
882250	891938	B	0.6516022682189941	That's why it looked a little bit paradoxical that we also create antithetical to our modus operandi, which is to reduce error.
892034	898330	B	0.6943957805633545	But when you remember that for our kind prediction error minimizing system, we have a really deep temporal model.
898480	906310	B	0.7511594891548157	We're managing uncertainty at a big horizon, maybe even multigenerational, where we're thinking about our kids or our kids.
906400	909354	B	0.6908501982688904	I mean, who knows how deep the Generative model actually runs?
909482	929490	B	0.6908882260322571	It turns out that error over that stops developing error minimizing skills and abilities and just hangs out in one microniche, because that microniche is going to be upset sooner, right?
929560	939014	B	0.444419801235199	I mean, it's such a great example of where we thought we were in a really set vector state and then suddenly it gets jostled and all of us go, oh my goodness, what do we do?
939052	940230	B	0.592689573764801	We've been bumped.
940810	951174	B	0.4616859257221222	And it turns out that the best error minimize will be the two kinds of errors that are hates.
951222	953782	B	0.6434359550476074	Those errors are digestible.
953926	959614	B	0.4262303113937378	So that means not too complex that you can't do anything with it, you can't learn anything from it, but also not so boring that there's nothing to learn.
959732	971714	B	0.7517982721328735	If we hang out, if we're sensitive to and we hang out at the edge of our capability, then we keep developing new error minimizing abilities, which actually sets us up to be good error minimizing systems over the long run.
971752	982978	B	0.6274870038032532	So even though we're investing metabolism now, we're setting ourselves up to be able to manage, especially in the deep end of the pool, black swans manage uncertainty that we're not going to be able to predict.
983074	984242	B	0.6944743990898132	They're really unpredictable.
984306	988050	B	0.6617169380187988	Unpredictable that comes from hanging out at this edge.
988130	997906	B	0.5835339426994324	So part of our curiosity and playfulness and creativity are going to be about us making and digesting novel slopes of Volatility.
998018	1004038	B	0.9251992106437683	I think that's one really great answer for why you get playfulness and curiosity out of this and creativity.
1004134	1007194	B	0.823130190372467	I'll just drop one more and we don't have to get into it too deeply here.
1007232	1009580	B	0.8409956693649292	But here's one other one that we're thinking of.
1010030	1018640	B	0.9692948460578918	There's something really special in the creation of art, especially in a public sphere, that I think is so interesting and that somebody needs to be sort of looking at this.
1019330	1029730	B	0.7961505055427551	There's actually a new collection coming out in Philosophical Trans B on Art and Predictive Processing, which I think you should check out if you're interested in these topics.
1030310	1037922	B	0.5482221245765686	But the idea that we've been thinking about is there are ways that we can bring our Generative model out and put it into a public sphere.
1038066	1049580	B	0.6262415051460266	You can take something which is typically on the inside and you can put it outside, and then you can have other error minimizing systems look at it and fiddle around with it and then we can reimbibe it.
1050110	1051674	B	0.8007394075393677	We're doing this all the time.
1051792	1054554	B	0.6221433877944946	That's what language allows us to do and what writing allows us to do.
1054592	1055542	B	0.7764422297477722	Think about maths.
1055606	1065150	B	0.8023385405540466	You're bringing up part of your predictive understanding, you're laying it out and then other predictive agents can fiddle around with it and then you can take it back in as part of your updating your own model.
1065300	1067902	B	0.5346524715423584	And I don't know how much more I can say here.
1068036	1069834	B	0.6102436184883118	I just think this is a kind of horizon.
1069882	1071906	B	0.6764832139015198	But I think there's a really juicy thing to say here.
1072008	1074434	B	0.8087528944015503	About where real art is.
1074472	1075214	B	0.7519111633300781	Like Tolstoy.
1075262	1095574	B	0.8341416716575623	Maybe Leo Tolstoy was already on this, where you put something of the Creator in the Creation and then other people receive that and then they can do something else with it, and then you're able to sort of take it back in all under the guise of sort of Minimizing Volatility or understanding Volatility, maybe.
1095612	1096790	B	0.6615753173828125	That was a bit deep.
1097130	1099046	A	0.9282854199409485	No, that was really good.
1099148	1099800	A	0.5491447448730469	Yeah.
1101390	1110554	A	0.8866896629333496	So in the chat I just dropped a link to yeah, so somebody just asked about papers related to hanging out at Edge of Our Capabilities.
1110682	1111920	B	0.7579621076583862	I'll do that right now.
1112370	1114446	A	0.8338371515274048	There sure are some papers on that.
1114548	1115598	A	0.6896330714225769	Mark's got a few.
1115684	1131380	A	0.8998052477836609	I already dropped a link in there to an Aon article by some of the old Expect project crew, including Mark Kate Nave, George Dean and Andy Clark on the value of uncertainty, which is I think it's a really good start point for some of these questions.
1132390	1140642	A	0.7564897537231445	Just because Aeon is a kind of non academic place where, you know, it's a non technical introduction.
1140706	1145922	A	0.93314129114151	And there's a wonderful example in that paper of a guy named I think it's Max Hawkings.
1145986	1146474	A	0.7965733408927917	Is that right?
1146512	1146810	A	0.7144628167152405	Mark?
1146880	1148314	A	0.7910289168357849	Max who?
1148512	1153338	A	0.49688684940338135	He's a kind of tech guy and he realized he was getting kind of bored with his life.
1153504	1161850	A	0.7782512903213501	He'd inadvertently trapped himself in a dark room because his life had become so rote and scheduled and systematic.
1161930	1172722	A	0.5395401120185852	He realized that he would be kind of incredibly easy to kidnap because he was in the same place at the same time every single day and he took drastic action to break out of that dark room.
1172776	1184498	A	0.9182873368263245	So he kind of introduced a randomization algorithm that it would kind of choose for him where he was going to eat, where he was going to go, which shows he was going to attend.
1184674	1188310	A	0.968235433101654	And this example is a really nice centerpiece in this article.
1189370	1204202	A	0.9652709364891052	I think this is a nice place to start because it's also grounded in discussions about epistemic actions as well, because there's also as cool as play and art and creativity are there's also really good reasons that uncertainty is valuable as well?
1204256	1204522	A	0.7360090017318726	Right?
1204576	1223282	A	0.6227468252182007	Because while we might want to exploit all of the opportunities for kind of nourishment and valuable prediction error minimization in our environment, there are of course going to be times where those opportunities are exhausted and we need to go and explore different ones.
1223416	1230482	A	0.9139562845230103	And I think there's some stuff in there as well on epistemic actions within the context of navigation as well.
1230536	1239014	A	0.6455457806587219	So sometimes we're going to have to temporarily move further away from our target in order to minimize our uncertainty about where we're going.
1239132	1250230	A	0.8957132697105408	So there's lots and lots of stuff on the value of uncertainty and it kind of is very much at the forefront of some of the really interesting philosophical applications of the framework.
1250310	1251100	A	0.5574129819869995	For sure.
1252110	1254522	A	0.6667354106903076	Okay, by all means.
1254576	1255660	A	0.5203197002410889	Yeah, we've got time.
1256350	1260442	F	0.7790988087654114	I know you have a question that is but with the value of uncertainty.
1260506	1275406	F	0.5348576903343201	It's just that I'm thinking because I've been working a lot with the magicians and there's a way of using uncertainty as entertainment that it's very difficult to understand as a concept for entertainment.
1275438	1283458	F	0.4966859817504883	Why would you like to be in a place where you want to predict but you cannot, and you still want to participate in this activity?
1283554	1287320	F	0.5113704800605774	So for me, magic shows, it's kind of breaking a little.
1290730	1300998	A	0.8822294473648071	Spoke to I forget the person's name, but there was an Xcape meeting here at Sussex and I spoke to one of the guys on Escape who had been working on magic.
1301174	1305210	A	0.836908221244812	I don't know if you know who I'm talking about, but I think they have a book on magic.
1305710	1314410	A	0.9757048487663269	And I think that's really cool to think about from a predictive processing perspective, the idea that magic is just these wonderful kind of violations of expectations.
1314570	1321300	A	0.8770984411239624	In a certain sense, I think predictive processing provides a nice, really intuitive framework for thinking about those kinds of things.
1321670	1323502	B	0.813517689704895	One little point there, Regina.
1323566	1333998	B	0.626110851764679	Just about again, if it feels paradoxical just to sort of complexify your view, remember that this is always happening in a hierarchical system.
1334184	1342802	B	0.754831850528717	So just because you have errors at one level of the system doesn't mean you're going to have sort of critical, cascading, unbearable errors at higher levels.
1342946	1345826	B	0.8517723083496094	So that's why it's fun to go to horror movies.
1345938	1347334	B	0.6084022521972656	So I dropped the paper here.
1347372	1349606	B	0.8150122165679932	Also, we have a new paper coming out on horror movies.
1349638	1354714	B	0.9066901206970215	I'm pretty interested in this, but it's the same as going to the magic show in some way.
1354832	1361150	B	0.6103087067604065	Now, the reason why those errors are fun is because we're safe in a theater.
1361570	1363054	B	0.6228154301643372	We're with our friends.
1363252	1366910	B	0.8148411512374878	We have lots of sugar in our system from eating popcorn and candy.
1367490	1373220	B	0.7028262615203857	We can control the amount of scary by covering our eyes.
1374870	1376738	B	0.7412645816802979	There's lots of control here.
1376824	1395490	B	0.7668731808662415	And yet we're getting media that's pinging all of our evolutionarily ancient error tracking systems so that we're getting jumps in the physiology as if there's a bunch of volatility that we need to manage, and yet we're in a completely safe space, which is really fun for our kind of system because we're hierarchically deep predictive systems.
1395570	1397798	B	0.6065211892127991	The high level here isn't jeopardized.
1397974	1404054	B	0.4910990297794342	It knows I'm in a theater, but the low level stuff is still registering all sorts of literal volatilities.
1404102	1405574	B	0.6241371631622314	But of course, they get squashed.
1405702	1407740	B	0.6601732969284058	They don't cascade all the way up.
1408990	1418286	B	0.8453240394592285	Or if you're the kind of person where they do tend to cascade all the way up, then you're also the kind of person who doesn't like going to horror movies because it kind of scares you.
1418388	1422626	B	0.5940628051757812	Go home and think, oh, goodness, maybe ghosts are real and maybe I live with them.
1422648	1423650	B	0.6307246088981628	You wouldn't be going there then.
1423720	1431570	B	0.7401474714279175	So with magic, it's the same sort of thing with error.
1432810	1441938	B	0.6570945382118225	I don't know if you've ever who does the really extreme magic.
1442034	1444002	B	0.8135828375816345	David Blaine, where he was in a block.
1444066	1445318	B	0.828724205493927	Yeah, david Blaine, have you ever seen him?
1445324	1449270	B	0.6346544027328491	He goes to Haiti where you have a community that really believes in magic, and he does some magic and he gets into trouble.
1449350	1454550	B	0.6890082359313965	Like suddenly all the young men are, no, no, that's no bueno.
1454710	1455834	B	0.7399013638496399	That you're doing this.
1455872	1460326	B	0.7944827675819397	And then the camera pans back and he, no, no, hold you here, I'll show you how it's done.
1460368	1461514	B	0.6913089156150818	It was just a trick.
1461642	1462494	B	0.8201072216033936	I'll just show you outside.
1462532	1466410	B	0.7950870990753174	It's not real magic because there they're not having fun with it anymore.
1466490	1470434	B	0.9288825392723083	They're like, no, that's not a good thing to do.
1470632	1479794	B	0.5071012377738953	So it just goes to show that our engagement with magic is mostly a sort of scary play, I think.
1479832	1482526	A	0.9052518606185913	One thing I just kind of sorry about the seagulls.
1482558	1483574	A	0.5243358016014099	I don't know if you can hear those.
1483612	1486710	A	0.5427897572517395	There are seagulls going crazy just outside my window.
1487450	1501526	A	0.8386868834495544	One thing I would add is, I think, another aspect to this part of the framework wherein you have this value of prediction error, kind of epistemic and effective emotional value of prediction error.
1501558	1513902	A	0.7322760820388794	It's one of the kind of key elements in this notion of agency get in active inference that I think is really going to be really important to in mind as you go through the further weeks of this course.
1513956	1527822	A	0.753237247467041	As well, like I said in the lecture, it's not necessarily speaking to the metaphysical question of free will, but it's certainly moving us away from this picture of the agent as a kind of automaton that's just following rules.
1527886	1532360	A	0.5258752107620239	There's real space here for kind of individuality and creativity as well.
1534730	1540310	A	0.8673121929168701	Okay, Darius has been waiting a little while, so let's go over to him.
1540460	1543846	D	0.8127453327178955	Happily patient, happily mean.
1543868	1559420	D	0.9097013473510742	This is this question, I guess, is deriving from my thoughts about the meeting of the high road and the low road, some of the recent work that's been coming out of Maxwell Ramstead and actually a conversation I had with him, which is that the generative model.
1562450	1567006	D	0.8589624166488647	So my question, given that given and.
1567108	1567760	E	0.6679844856262207	Talk.
1569810	1584002	D	0.7672463059425354	Is regarding the notion of affordances, I think it's natural that as cognitive scientists and philosophers, we take the perspective intuitively of the agent in the agent arena relationship and how the agent is in the business of reducing prediction error.
1584146	1596354	D	0.8658958077430725	I was just wondering whether, as philosophers, you and Mark have thought about what is it like for the whole system to be in the business of reducing its prediction error?
1596402	1598578	D	0.6738324165344238	So I'm interested in flow states.
1598764	1617514	D	0.8026328682899475	And so, for example, my thinking is that in a canonical example of a flow state, let's say a rock climber, the climbing wall, is also in the business of reducing its prediction error as to afford the opportunity for it to be exploited stealth or themselves are in the business of reducing prediction error.
1617562	1624500	D	0.7827123999595642	So I'm wondering whether this expansion of affordances is bi directional trial, infinitely directional, better?
1629430	1632020	A	0.9059880971908569	That's an amazing question.
1633050	1642150	A	0.7089260220527649	You mentioned Axel constant, but somebody else.
1642220	1642646	D	0.6128636598587036	Someone else.
1642668	1645240	D	0.9117639660835266	But I spoke to Maxwell Ramsey's last week.
1648350	1651210	A	0.8002246022224426	There's a paper on I'll find it in a second.
1651280	1657462	A	0.8053233623504639	On niche construction and affordances.
1657526	1660250	A	0.767538845539093	I think it's Axel comps.
1662110	1668640	A	0.8705787658691406	They talk about the kind of the symmetry between a niche and an agent.
1669250	1671634	A	0.7799971699714661	Very much in the same vein as you were just talking about.
1671672	1685510	A	0.8701016902923584	There this idea that there's not just this unidirectional kind of fit between the agent and the environment or the niche is actually modeling generative model of the agent as well, implicitly.
1686250	1698250	A	0.4781120717525482	So I think the best I can do there direction of some really interesting work on that, but certainly it's not something that plays a central role in my thinking recently.
1698590	1698954	A	0.5491447448730469	Yeah.
1698992	1702650	A	0.868851900100708	So we have the participants chat.
1703470	1704220	A	0.5491447448730469	Yeah.
1704590	1706886	A	0.863412082195282	A variation approach to niche construction.
1706998	1707274	A	0.5491447448730469	Yeah.
1707312	1715082	A	0.5094971060752869	I don't know if Mark has anything to add or anybody else worth thinking about.
1715136	1715798	B	0.5491447448730469	Yeah.
1715984	1717406	B	0.8556791543960571	Darius, can I just check one thing?
1717428	1717822	B	0.7501002550125122	You asked.
1717876	1725006	B	0.6889093518257141	I don't know how much I need to add here, but did you think that the wall was reducing free energy relative to the climber?
1725038	1725954	B	0.766930341720581	Did you say that?
1726072	1726980	D	0.5689783096313477	That's right.
1729270	1731042	B	0.7112667560577393	I don't know how that can that be the case?
1731096	1732280	B	0.7885685563087463	Can that be the case?
1732650	1739202	B	0.8113126754760742	The wall as a thing is maintaining itself relative self evidencing.
1739266	1739494	H	0.7360090017318726	Right?
1739532	1740214	B	0.5491447448730469	Yeah.
1740412	1742454	B	0.7872673273086548	But it's not really a duet of one here.
1742492	1749740	B	0.5383119583129883	It's not like it has a generative model that's deep, where it's modeling the climber, modeling it the same way as tango dancers do.
1750830	1771466	B	0.7487816214561462	A tango duo are having cooperative flow states because each movement opens a vista of possible error, minimizing opportunities for the partner, who in turn opens a vista of error minimizing opportunities for the partner and backwards and forwards into this ever opening expanse of affordance capabilities.
1771578	1774926	B	0.5437918305397034	But an inanimate object and an agent don't really have that same dynamic.
1774958	1776642	B	0.844143807888031	So I was wondering what you were thinking there.
1776776	1786610	D	0.7337145209312439	So my thinking was that this kind of bleeds into the notion of fluidity of affordances in the kind of Gibsonian sense and the fluidity of concepts.
1786690	1794762	D	0.855757474899292	So I agree in the sense of physical self evidencing, it needs to model the rain, it needs to model the physical environment so as to maintain itself.
1794896	1807498	D	0.7912217974662781	But what about as it's a for it's it's so a sheer rock face is not a climbing wall.
1807584	1812378	D	0.543999433517456	And that's because it doesn't self evidence as a climbing wall, it doesn't offer the affordances to be climbed.
1812474	1818606	D	0.8930537104606628	That's why I was kind of referring to which is that affordances change based on the agent arena relationship, right.
1818628	1821150	D	0.6838465332984924	Your car's affordances change whether it's working or broken down.
1821220	1825762	D	0.8845227956771851	Similarly, the climbing wall changes whether it's got footholds handholds or whether it's just a sheer rock face.
1825816	1826740	D	0.8158707022666931	That was my thinking.
1827590	1832660	B	0.600517213344574	It seems slightly spooky to me that we'd think of the wall as self evidencing in that way.
1833190	1844600	B	0.874743640422821	I think the language that we tend to use because Julian Kirsten, Eric Reitfeld, Yelly Brunberg and folks often use the idea of affordances and fields of affordances in the active inference way.
1846250	1865360	B	0.8038251996040344	The radical end of the pool there is typically that the affordances don't only happen on the agent side, but rather happen from a dynamic of the changing volatile environment and the generative model of the agent and that they're collaborating in dynamic ongoing ways such that the affordances are emergent between them.
1866050	1868142	B	0.6817827224731445	That certainly seems right to me.
1868276	1875300	B	0.5269047021865845	The idea to push it a little bit further and think about the wall self evidencing, I think it's a step too spooky for me.
1875750	1891000	B	0.6754929423332214	I think I would feel safer a little bit closer to thinking about the affordances are changing relative to the dynamics of the wall, but I don't know what it would mean for the wall to be evidencing, the climber or itself.
1891450	1922290	A	0.5229587554931641	Ben that's stirred a couple of thoughts a little longer on the work by affordances because there's this really nice distinction in their work between what they call well, I'm not sure if they I think I think that the term landscape of affordances is a little bit older, but they make this distinction between a landscape of affordances and a field of affordances.
1922710	1935762	A	0.566964328289032	And I think the reason this is really important to get on the table is because this distinction is kind of directly targeting the dynamic, shifting, very affective nature of affordances.
1935826	1941030	A	0.7830274701118469	So on the one hand, you have this landscape of affordances that is relatively static.
1941850	1945510	A	0.8833712339401245	So right now my landscape of affordances is Brighton.
1946250	1953018	A	0.5196682214736938	And the landscape of affordances in that sense is not really going to change very rapidly unless I kind of jump on a plane and go somewhere else.
1953184	1960030	A	0.8354582190513611	But the field of affordances has this thoroughly kind of normative, affective character to it.
1960180	1970746	A	0.8191483020782471	So depending on my internal state at any given time, depending on my expectations or my desires, say, my field of affordances is going to shift very rapidly.
1970938	1976066	A	0.8912298083305359	So not just predicated on my internal state, but also kind of contextual cues as well.
1976168	1984710	A	0.7552300691604614	So if something were to happen in the environment that was afforded very high precision weight in, then that's likely to shift my field of affordances significantly.
1986570	2008154	A	0.5203486084938049	I think that the reason that I'm kind of emphasizing this to Darius's point is and kind of building on what Mark said, it doesn't seem like this distinction at least would apply from the perspective of the wall, say, because this kind of affectivity and normativity just isn't a feature of the wall's experience of the world.
2008272	2011482	A	0.8096894025802612	And also to kind of run with affordances.
2011626	2014926	A	0.8819807767868042	Perhaps you could say a bit more about how you would kind of think about this.
2014948	2023594	A	0.7539286017417908	Darius because affordances are kind of opportunities for to.
2023652	2033150	A	0.7174307703971863	There's some debate about this, but I like to think of them as like a relational property between you have the skilled capabilities of an embodied agent and then you have some feature of the environment.
2033310	2038854	A	0.849873960018158	So I think when you're thinking from the perspective of the wall, you have the features of the environment because you.
2038892	2043522	A	0.9047204852104187	Have the embodied characteristics of the agent are kind of playing that role.
2043666	2048506	A	0.5779763460159302	But it's not clear to me what the kind of skilled capabilities of the wall is.
2048608	2051226	A	0.8352087736129761	So yeah, if you could just say a bit more about that.
2051408	2059450	D	0.5816502571105957	Yeah, I mean, it may be the case, as you pointed out, that actually the technical term affordance as being opportunities for action is misplaced.
2061390	2080370	D	0.8011672496795654	This is a lot of this I've been formulating, having read this very new paper by Ramsey and colleagues on Bayesian mechanics of physics of and by beliefs, where he really rams home this point, that the system, the generative model is the system of the kind of stochastic differential equations across the state space.
2080440	2085398	D	0.8830382227897644	So across the Marko blanca, across the particle with its Marko blanket and the external states.
2085564	2091638	D	0.5762547850608826	And that is the system which is in that system itself is in the business of reducing free energy.
2091724	2098282	D	0.7927365899085999	So it's not just the active inference agent, it's the whole system which is embedded in a whole system of other things.
2098336	2110446	D	0.8269145488739014	And so that was my general thinking, is that just on the prerequisite that these systems exist just on that a prior axiom, there has to be some kind of self evidencing of that system itself.
2110548	2112640	D	0.6531553864479065	So maybe affordance is the wrong word.
2114850	2116142	B	0.7779300808906555	That might be the trick right there.
2116196	2120538	B	0.791370153427124	As soon as you provoke affordance, you're provoking phenomenology.
2120634	2123582	B	0.5524540543556213	And so now we're not talking just about statistical variations.
2123646	2125460	B	0.8510234355926514	Now we're talking about lived experience.
2126310	2128994	B	0.8838158249855042	That might be the linchpin right there, I think.
2129112	2130034	A	0.6482130885124207	I think that is right.
2130072	2130418	A	0.5491447448730469	Yeah.
2130504	2136858	A	0.6584498286247253	And I would say I think, Darius, you're absolutely on the right track and there is this ambiguity about affordances.
2136894	2148154	A	0.7884793281555176	But aside from that, I think you're absolutely mean it's just nonsensical to think about an agent absent an environment under active to.
2148352	2152860	A	0.7265670299530029	It is this agent environment system in its totality that's minimizing free energy.
2153310	2154986	A	0.6787237524986267	They have to be taken together as one.
2155008	2158366	A	0.8304846882820129	And I know Avel, you've had your hand up for a little while there.
2158468	2160080	A	0.8935360908508301	Is there something you wanted to add?
2162050	2162798	H	0.46103888750076294	Yes.
2162964	2163886	H	0.7720435261726379	Do you hear me?
2163908	2165230	A	0.7311861515045166	Well, we do.
2165300	2166126	A	0.5834073424339294	I do anyway.
2166228	2177070	H	0.8638351559638977	Okay, so about the afferences world having afferences and basically the symmetry of agents and environment is a property of active inference.
2177150	2179038	H	0.7787895202636719	Well, of the frenzy principle.
2179214	2193106	H	0.8003242015838623	So if you buy the frenzy principle and you also buy that it entails that agent have affordances or any approximal notion, then you also buy that walls have affordances.
2193298	2197100	H	0.8898339867591858	So there are basically three position you can have on that.
2198030	2200746	H	0.5937017798423767	One is that active inference is correct.
2200848	2205900	H	0.9598032832145691	Wall are fucking affordances and they do self evidencing, which I would not go with.
2206450	2213038	H	0.758147656917572	Another option is that you have basically devolved in the detail.
2213124	2217358	H	0.7233341932296753	So, for example, maybe the adjunct environment is not the wall.
2217444	2223058	H	0.8352316617965698	It's something that is broader, like Gaia system, whatever, and it just happens.
2223144	2226562	H	0.5864124894142151	It includes the wall, but it is not the wall.
2226616	2229010	H	0.8420088887214661	And it does do self balancing.
2229830	2232774	H	0.7766114473342896	And the third is that active inference is wrong.
2232972	2239030	H	0.5090923309326172	We don't have affordances based on whatever is the formal presentation of active inference.
2239450	2247402	H	0.8502054214477539	And I would go in that direction of this phenomenology stuff.
2247456	2255334	H	0.5902075171470642	So we have, I would say, philosophical evidence in the sense that denying this would lead to nonsense.
2255382	2263198	H	0.7201265692710876	But information is based on observation, and some system do observing much more actively than others.
2263364	2265946	H	0.7052206993103027	And maybe it's a good thing to have in your formalism.
2266058	2268400	H	0.7331358790397644	I'd say so.
2269190	2286726	H	0.7628551125526428	You have maybe a stronger case for the way phenomenology affordances are constructed in the quantum formulation of the FEP, if there is such a thing, which, like Chris Fields, someone who we should baseline believe claims there is.
2286908	2298486	H	0.8319295048713684	Because then you have formalization which is not in terms of dynamics per se, so causal constraints, but observation and indirectly phenomenology.
2298598	2300522	H	0.5389315485954285	Maybe you have something that is stronger there.
2300576	2334210	H	0.5264936089515686	But right now, the link sorry, there is actually a bunch of people who have a quite good hold on science, which are the ecological activity and cognition on one hand and between cognition and the metabolism, the constitution of the living thing that cognites on the other and one of their definition of agency cognition.
2334290	2341480	H	0.8109616637229919	Pick one entails interactional, asymmetry I think is the word.
2346670	2357530	H	0.8180897235870361	That is something we would need to translate into active inference, well into the FEP for active inference to have a strong grip over this affordancing.
2358030	2362046	H	0.8597522377967834	Until then, we have a kind of handwriting way.
2362068	2369950	H	0.6652222275733948	It relates it to more conceptual approaches that are related to an active and ecological approach to psychology.
2370110	2377460	H	0.679322361946106	And, yeah, the formalism lags basically behind the concept for now.
2378230	2380260	H	0.6870955228805542	Sorry for the long talk.
2381690	2382758	A	0.8244106769561768	No, that was great.
2382844	2383990	A	0.9306212663650513	Much appreciated.
2387210	2390834	A	0.8791057467460632	Anybody else want to come in on a question of affordances?
2390882	2396410	A	0.7279812097549438	Because I know affordance has played a fairly substantial role in the lecture.
2403870	2412080	A	0.833426833152771	Anybody has any questions related to affordances or action perception affordances, then now's the time.
2413090	2417678	E	0.6592355966567993	Yeah, I do have one, but it's not well structured yet.
2417844	2418960	A	0.9304569363594055	That's really fine.
2420130	2430094	E	0.8528971076011658	Something that I've been thinking about for the last month because I started to depend on artificial intelligence field coming from a humanities background and philosophical background.
2430142	2441602	E	0.9556254148483276	So I'm mixing many things in this period, mainly following the active inference as a crossroad between many disciplines, and this is very beautiful about the framework.
2441746	2467418	E	0.5648746490478516	And I was super curious about the question proposed by Darius, and I was then thinking about now we're actually facing a new environment and a new landscape in which we're interacting with actually generating over revolutionary time and synchronizing over evolution.
2467594	2475406	A	0.687252402305603	Technological alien agencies operating within our landscape and field of affordances.
2475518	2481090	A	0.9693875908851624	So I think there's a lot of really interesting work to potentially be done there.
2481160	2503980	A	0.5369252562522888	I will take the opportunity to shamelessly plug a preprint that Mark and I have released recently, where one thing that I'm really interested in, that I can kind of speak with some confidence on is the fact that I do think there's a point at which the theory of affordances or the language of affordances, starts to break down to.
2507410	2515002	A	0.8718968629837036	So the preprint I'll share around is looking at ambient technology specifically.
2515066	2524626	A	0.6703087687492371	So this is technology that the whole kind of impetus behind its design and conceptualization is that the user doesn't have to actually do anything.
2524808	2528062	A	0.8555638194084167	So it precedes the user Pragmatically and epistemically.
2528126	2532354	A	0.8525374531745911	It knows what kinds of things you want it to do, and it just does them in the background.
2532482	2541480	A	0.833121657371521	And it works by shifting kind of it subtly shifts the material environment such that it impacts your field of affordances in real time.
2542890	2562122	A	0.5088552832603455	And the argument that we make in that paper is essentially that the affordances approach doesn't really work for this and that we need to kind of think again, I think that that might be how to conceptualize generative AI, for example, under the affordances framework.
2562266	2566720	A	0.9522356986999512	I don't know of anybody that's done any work on that, but it would certainly make a really cool project.
2570090	2572440	H	0.8323299288749695	You are making it right now.
2573770	2574840	A	0.7330603003501892	What's that?
2576410	2578246	H	0.8323299288749695	You are making it right now.
2578268	2580840	H	0.8037756681442261	I know because you sent me the paper to review.
2581450	2582520	A	0.5585339665412903	Oh, yeah.
2584910	2585820	E	0.8529649972915649	Thank you.
2590030	2594914	A	0.8225982785224915	Early stages of a paper on the role of generative AI in classrooms.
2595062	2614210	A	0.8386902213096619	So, from the perspective of thinking about what kinds of affordance does generative AI represent in a learning environment, particularly, we're kind of applying active inference to classroom design and looking at it from the angles of different educational and pedagogical theories.
2614630	2617700	A	0.6627600789070129	But it's very early days.
2620070	2623122	A	0.8575495481491089	It probably depends on your view of generative II in general.
2623176	2627640	A	0.818335235118866	I mean, it depends whether you would consider it a real cognitive agent or not.
2628490	2641162	A	0.6892711520195007	I think some people are more inclined to think of it as this is a thing that has agency, it has real understanding, and other people are maybe less inclined to think of it in those terms.
2641216	2645580	A	0.8608832359313965	And I think that might bear significantly on how you think of it.
2646930	2647966	E	0.9848061203956604	Yeah, that's super cool.
2647988	2655514	E	0.6355573534965515	That basically the last project you mentioned is very in line with my PhD project right now because my main PhD.
2655562	2665410	E	0.5317949652671814	Project is our European foundings, and it's about the AI for personalized education, and I'm trying to follow it through the active inference framework from a multi level perspective.
2667350	2668130	A	0.9677404165267944	Very cool.
2668200	2670500	A	0.6897581815719604	Yeah, we should we should probably talk more about that.
2673690	2674342	A	0.584351658821106	Okay.
2674476	2675350	A	0.6827870011329651	Darius.
2677930	2678294	B	0.7381101250648499	Yeah?
2678332	2691820	D	0.6217035055160522	I wanted to ask I mean, this may be directed more mark so I know this is kind of his work in terms of slopes of uncertainty and about doing better than expected at reducing prediction error over time.
2692350	2713602	D	0.7911458611488342	I was wondering kind of how the architecture of that is built into the particle, into the generative model because we have the kind of for me, I don't know if it's an hour and out sort of conflict, but we have these kind of implicit priors that we're going to fulfill certain expectations or minimize prediction error regarding certain things.
2713656	2713826	H	0.5664746165275574	Right.
2713848	2718850	D	0.6701031923294067	So homeostatic priors or happiness, well being, whatever it is.
2719000	2731958	D	0.5712866187095642	But then your claim is that we have the higher order beliefs, the higher order predictions that over and above, that I also need to do well, better than expected at reducing prediction error over time.
2732124	2735434	D	0.7366185188293457	So it's still quite fuzzy in my mind.
2735472	2751002	D	0.5108585357666016	But is there a kind of potential conflict there between the general priors that the system has and then actually, in a sense, violating those expectations by going over and above them, which itself constitutes an expectation?
2751066	2754110	D	0.7659983038902283	How do you kind of resolve that tension?
2755810	2760366	B	0.8324413299560547	Yeah, that's interesting, but this is very much in Ben's wheelhouse too.
2760468	2786146	B	0.6401664614677429	Ben and I have been working on sloppy stuff for almost as long as I've been doing on his original paper called We'll Get It Up.
2786168	2792500	B	0.9307831525802612	They do a really good job of showing technically where this sits within a deep parametric model.
2793430	2806278	B	0.7404506802558899	Lara Senved Smith's paper on metacognition also does this by showing you have these depths of modeling where models above are modeling models below, and optimizing over those models below.
2806364	2817100	B	0.7265035510063171	So we have some good computational backbone for thinking, for not only thinking that this is the case, but beginning to express how it does the work it does.
2817630	2826830	B	0.7789794206619263	So let's leave that for digging into it, though, technically, sort of on our own, let me say sort of at a higher, more abstract level still, hopefully it's useful.
2827490	2844462	B	0.5849024057388306	It's not weird to think that this kind of anticipatory system is not only making predictions about the world, but it's also part of what it's predicting is how fast or slow, how efficient it is in particular contexts at resolving certain kinds of errors.
2844606	2849990	B	0.5497953295707703	That's a perfectly fine thing to think that we're also predicting slopes of engagement.
2851050	2860634	B	0.6359196305274963	And then all we're saying then is system also pays attention to when those expectations are breached and it's learning from those breaches that should just be the bread and butter for what the system does anyway.
2860752	2882318	B	0.7429998517036438	So precision is a second order process in much the same way precision is about how reliable are lower level predictions and then using that amount to toggle how impactful either errors or predictions are.
2882404	2897860	B	0.8273999691009521	So we've already got baked into the system, right from early days, this idea that the system is not only making predictions, but monitoring its own predictive processing regimes and then toggling based on how reliable those substreams are.
2898310	2915100	B	0.831941545009613	All we're adding here is when we first thought about those mechanisms, one thing that can happen, this is just good for everybody who's interested in active inference, because I bump into this with my students all the time when we say something like precision weighting, a tendency to think of thing.
2916830	2924566	B	0.8285582661628723	So we go to find this precision like where's the biological or precision weighting?
2924598	2932414	B	0.7660130858421326	But when we actually get into a biosystem and we look for these things, the truth is precision is going to be weighted in lots of different ways.
2932452	2939086	B	0.706448495388031	I mean, that's the real frontier of this research is to actually find how these things are instantiated and the answer is going to be multifarious.
2939118	2943138	B	0.863680362701416	I mean, you're going to have precision adjustments happening throughout the system in lots of ways.
2943224	2947042	B	0.8236300945281982	It could be synchrony and asynchronous and desynchronies between systems.
2947106	2953842	B	0.8675143718719482	It can be neuromodulatory chemicals, it can be structural shapes within the brain.
2953906	2957718	B	0.8372575640678406	I mean, precision is going to be set in lots of different ways.
2957884	2983486	B	0.817521870136261	So all that we're pointing out here is that one of the ways that precision is being set, one of the ways that the system is tracking how efficient it is and then upping or lowering the amount of impact error signals or predictions have, is that it's happening in an embodied way.
2983588	2994690	B	0.691169798374176	So we've looked over to the effective search and lo and behold, there are all these signatures that we were looking for for this part of the machinery.
2996470	3000394	B	0.6817412376403809	So not weird that the system is tracking its own regularities and adjusting.
3000462	3002338	B	0.6172475218772888	That was baked in right from the beginning.
3002514	3005826	B	0.6999838352203369	How it does that, that's one of the frontiers.
3005858	3007654	B	0.7731349468231201	It's going to happen in lots of different ways.
3007772	3008594	B	0.527556836605072	Lo and behold.
3008642	3027898	B	0.49744147062301636	Affect the dynamics, the shoe fits, they look like they do that stuff and then you bring it to the lab and you go back to like reward prediction error research and sure enough, neuromodulatory chemicals, reward systems are tuning affective dynamics relative to better than and worse than slopes of uncertainty management.
3027994	3031760	B	0.6976091265678406	It's exactly what we would expect given the computational model.
3032290	3046242	B	0.6835237145423889	So then it was an easy next step to start saying, well look, there's one of the ways that precision, there's one of the ways that affect system.
3046376	3051554	B	0.82005774974823	Now just notice there it's the only precision, it's not the only thing the affected system is doing.
3051592	3057570	B	0.6133680939674377	We never want to say we're careful not to be reductionist to say, oh, affect is always aerodynamics.
3057650	3058678	B	0.8846431970596313	I don't think that's right.
3058764	3070390	B	0.7438820004463196	I think it's that aerodynamics are expressed in part effectively and they have this impact on the system that we've known about for a long time, even from just the reward prediction error literature.
3070550	3073340	B	0.8037517070770264	Does that help or was that a bit is that okay?
3074190	3074940	D	0.5491447448730469	Yeah.
3078370	3083950	A	0.5779224038124084	Just to add two things really quickly there because I know time is kind of catching up with us.
3084020	3097586	A	0.9498250484466553	I would emphasize as well, just as a kind of general .1 of the things I really like about the work on aerodynamics and affect is it has this nice kind of broad capture of the kinds of affectivity that agents can experience.
3097688	3106934	A	0.6752986311912537	So when we talk about affectivity, we're not just talking about full blooded emotions or even just moods, but we're talking about what?
3107052	3121142	A	0.904721736907959	One of the things I kind of drew attention to in the lecture was Matthew Ratcliffe's work on existential feelings, which I think is just such the connection between active inference and phenomenology that you find in some of this work is just insanely powerful.
3121206	3133626	A	0.5259090065956116	And it's one of the things that really drew me into the framework the second thing, just building one thing that I don't think I mentioned in the lecture is active inference.
3133738	3138190	A	0.8678843975067139	It has been described as a quintessentially metacognitive framework.
3138350	3154534	A	0.6510085463523865	So you have kind of built into the architecture, you have expectations over expect, so you have kind of predictions about predictions and this has proved to be just, again, just phenomenally useful for thinking about certain aspects of phenomenology as well.
3154572	3159590	A	0.6231132745742798	So yeah, I think that these are like real strengths of the framework.
3165140	3171600	A	0.7790949940681458	Okay, I don't know how we're doing for time.
3171750	3174256	A	0.8177191019058228	Are we strictly limited on or can.
3174278	3177190	H	0.6374264359474182	We we are not as far as I know.
3177800	3178980	H	0.6503534317016602	Daniel.
3181480	3187270	A	0.708082914352417	Well, I can probably do I definitely do another 15 if anybody has any more questions.
3187640	3193284	A	0.6785396337509155	And people, I should say as well, that doesn't mean that we're all held captive to my time frame.
3193332	3202620	A	0.6133822798728943	So if people do need to leave within the next five or ten minutes, that's absolutely fine, but I'm certainly happy to carry on if anybody has any more questions or comments.
3207060	3229796	G	0.713940441608429	If no one else has got any, I would quite like to go back to earlier in the discussion you were talking about the value of uncertainty because in organizations in which I'm working with, we often have conversations about uncertainty and what we find is over time there tends to be a drift towards risk aversion.
3229908	3242312	G	0.8002852201461792	So we're working with a large international construction company at the Minute, and they used to have a culture in which innovation was quite well embedded.
3242376	3270900	G	0.592409610748291	And over time, it's kind of drifted towards very, very risk averse culture where actually, rather than learning through the process and being able to tolerate uncertainty around opportunities and what can be accomplished and that kind of surveillance that comes with the intrinsic reward, I suppose, of being able to reduce uncertainty about capabilities to a situation where they're trying to anticipate all of the risks upfront before they even get involved in the project.
3270970	3273616	G	0.8405737280845642	So there's some kind of valence switch.
3273728	3289184	G	0.7321596741676331	Mark and you mentioned David Blaine earlier and something about the context there was a switch in valence from yeah, this is a kind of a play, this is a safe thing to do, to actually know this has real consequences.
3289332	3297100	G	0.7945700287818909	So I'd like to explore that a little bit more actually, if anyone's got kind of any insights or papers or comments.
3300000	3303090	A	0.9398671984672546	Yeah, I think that's a really interesting question, actually.
3304900	3317380	A	0.7093769311904907	It seems like one of the things we've been talking about is this connection between uncertainty, prediction, error, minimization and affectivity in individual agents.
3317450	3324576	A	0.7753053903579712	And it sounds like what you're asking is how does that translate to collectives?
3324688	3338360	A	0.7526708245277405	So one of the things about active inference that we're going to see in subsequent weeks is how it scales up to kind of larger systems like companies or groups that are trying to achieve some kind of shared goal.
3339820	3344764	A	0.8213671445846558	How does the value of uncertainty translate onto how is it scalable in that sense?
3344802	3345390	A	0.7360090017318726	Right?
3345760	3347470	A	0.7050967216491699	Would that be a fair kind of.
3348640	3350430	G	0.6842135787010193	Yeah, I guess so.
3355940	3366388	G	0.5850920677185059	Uncertainty often when it's talked about uncertainty is talked about as risk, which is, I suppose, is predictions or anticipation of outcomes that we don't want.
3366474	3366916	D	0.5664746165275574	Right.
3367018	3375824	G	0.5164853930473328	Whereas there's also positive uncertainty, which is, I suppose, simply stated opportunities through curiosity.
3375952	3388600	G	0.7047962546348572	What might we be able to achieve this kind of novelty seeking, I guess that new opportunities that we haven't exploited, and they're just in the kind of organizational systems.
3389500	3405570	G	0.9054365754127502	I think there are various pressures that cause it, but over time, you see these cultural shifts towards a very kind of risk averse where the valence is obviously quite negative, quite an unpleasant feeling for people.
3407780	3408928	B	0.9812131524085999	Yeah, this is good.
3409014	3411090	B	0.6434900164604187	This is right at the heart of my current work.
3411620	3412608	B	0.9431540966033936	I'm really interested.
3412694	3421136	B	0.7760461568832397	So we just had a big stint where active inference models were starting to be used in computational psychiatry, especially for pathological disorders.
3421248	3425780	B	0.8804796934127808	So addiction, depression, disassociative disorders, OCD PTSD.
3427800	3435096	B	0.4961596429347992	It's quite a sexy framework for thinking about some of the ways that the cognitive system breaks down and the sort of new move right now.
3435118	3437860	B	0.8495831489562988	I mean, we have a collection coming out right now in Neuroscience of Consciousness.
3437940	3456168	B	0.7339867353439331	Is to think about these things in terms of, okay, if we are predictive systems and we have a sufficiently rich model of how that system works in a particular niche, what sorts of ways can we intervene on that system in order to have positive outcomes, rather than just modeling what the negative outcomes are?
3456274	3458224	B	0.6478317975997925	And I hear that a lot in what you're saying now.
3458262	3460976	B	0.8572680354118347	So I'm just going to drop one link for you there.
3461078	3467948	B	0.8186506032943726	This is Casper Hess again wrote a very small paper with a nice little model called Sophisticated Affective Inference.
3468044	3473670	B	0.5930553078651428	Here's a little bot that tends towards catastrophe catastrophizing the future.
3474760	3480100	B	0.48037251830101013	If it's given like, fun medium fun medium fun dangerous.
3480260	3485850	B	0.5841273069381714	Over time, it tends to expect the dangerous one.
3487100	3497260	B	0.6220903396606445	Like after 10,000 iterations, it basically lives in the worst possible scenario, which is a nice little this is my wife, this is most people today.
3497410	3504724	B	0.7273459434509277	So the question is, I want to know, given the model, why does that happen and what can we be doing to intervene?
3504872	3511644	B	0.7156062722206116	And part of the answer is going to be we need to become more tolerant of uncertainty.
3511692	3514384	B	0.4650222957134247	That's one of the things that the system can be better or worse at.
3514502	3520020	B	0.8203279376029968	So this just takes the computational modeling and then looks to things that we already know about emotional regulation.
3520760	3522310	B	0.7621719837188721	That's part of the story.
3523480	3533336	B	0.8314940333366394	So we've done a little bit of work on this with our predictive dynamics of happiness and wellbeing, and Ryan Smith is definitely doing work on this with active inference and well being.
3533518	3536810	B	0.737133264541626	So definitely check that out if you're interested here.
3538540	3544860	B	0.794136643409729	I'll just flag one interesting thing here that relates just to what we were just talking about, about layers of modeling.
3545600	3548316	B	0.7774780988693237	One way that let's say two ways.
3548418	3550776	B	0.7087785005569458	There's two ways that a system, and it's probably going to be lots.
3550808	3556988	B	0.5977464914321899	But the two that come to mind that a system can become more tolerant to uncertainty is one exposure.
3557164	3561440	B	0.583760142326355	So this is why exposure therapy might be useful for our kind of a system.
3561590	3569268	B	0.7310594916343689	You want to expose the system to volatility at the lower and middle levels of the hierarchy and have it turn out okay.
3569434	3579588	B	0.591011643409729	So that one of the things that the system can come to predict is not only particular outcomes, but it can also predict how much error is involved in particular outcomes.
3579684	3595256	B	0.6622477173805237	So, for instance, when I used to give a pro talk, I was always really nervous, and I don't know if that ever really went away, but I've had so much exposure to the anxiety of giving a professional talk that basically I don't notice it anymore.
3595288	3600488	B	0.9221961498260498	But if you were to ask me at the beginning of my talk, mark right now, what's your phenomenology?
3600664	3604536	B	0.5021248459815979	And I sort of meditatively looked, I'd probably say, yeah, I'm nervous.
3604648	3607052	B	0.7378330230712891	But if you hadn't have said that and you were just like, hey, what's up?
3607106	3608720	B	0.8923346400260925	I've been like, oh yeah, I'm great.
3608870	3609424	B	0.8811412453651428	It's all good.
3609462	3610588	B	0.45399346947669983	I don't even notice it anymore.
3610684	3617828	B	0.7101297974586487	That's because the system knows that I have errors go up, but as soon as I start talking, they drop away.
3617914	3622256	B	0.773970901966095	And because I know the arc that even error in the system, it becomes non newsworthy.
3622288	3626288	B	0.8752816915512085	It's no longer interesting volatility to be tracking that's just from exposure.
3626464	3634596	B	0.5591006278991699	So what's happening is you're having errors at a lower or middle level that a higher level is now modeling, saying when we come here, we should expect this arc of error.
3634628	3639370	B	0.7376617193222046	Same thing when you work out like real gym rats, they can feel good.
3642400	3655360	B	0.8951185345649719	You're having your system right, but at the higher level, it's now learned not only that that has a natural arc, but that that's a good sign at a higher level.
3655430	3662976	B	0.5589913725852966	So now you're getting positive prediction error slope high and negative prediction error slope low.
3663158	3666160	B	0.6796293258666992	Okay, so one exposure.
3666320	3669840	B	0.8074010014533997	Two, you can model your own responses.
3669920	3672900	B	0.8086286187171936	This is something Ben and I work on with horror movies.
3675800	3682900	B	0.8062405586242676	You can take an active role in mindfully observing your own reactions to volatility.
3683060	3685956	B	0.5256770253181458	And this comes up in our paper on horror.
3685988	3688120	B	0.8568071126937866	We've already dropped the link today if you want to check it out.
3688190	3692232	B	0.49598944187164307	Something really special happens when the system models its own reaction to volatility.
3692376	3703536	B	0.6638034582138062	It starts to learn that even reactions to volatility, they don't need to be compounded up into dangers, that it's okay to be uncertain at certain levels of the system.
3703718	3711650	B	0.7992717623710632	So how that translates into business, I'm not sure, other than I know tolerance to uncertainty is a marker of business success.
3712180	3722100	B	0.7777010202407837	And I suspect the framework in a fit with lots of mindfulness work about learning to tolerate uncertainty.
3722440	3728932	G	0.8980385661125183	Is there anything about the role of language in kind of modulating those metacognitive?
3729076	3730024	B	0.9699504971504211	Oh, it's good.
3730142	3736170	H	0.7149224281311035	If I may, I was preparing an answer on that specifically, and I was nervously waiting for opportunity.
3736540	3737530	A	0.49048712849617004	Sorry, Mark.
3742400	3753708	H	0.8105926513671875	Meta in terms of evolutionary cognitive archaeology, we don't know when language emerge, but we do know that, let's say an encouraging semantic system.
3753794	3760400	H	0.7605483531951904	So you can build things in language, and you can expect things in the world to correspond to things in language.
3760820	3775924	H	0.8307419419288635	So, for example, if you that's abstract, as I say, it's abstract, but you can, for example, have a self identity, and I'm a French, and I communicate with the expectation that are embedded in that identity with other people.
3776042	3777844	H	0.8154623508453369	And that means we communicate over norms.
3777892	3781656	H	0.8266622424125671	So we have specific expectation of what we will do.
3781838	3788280	H	0.7700647711753845	And those expectations, they become embedded in specific symbolic markers that are embedded in language.
3788960	3814240	H	0.689990758895874	And something that the thing that it was strongly evoked in my mind when you talked of tolerance to insecurity is that as far as documented history goes, Europeans well, Indo Europeans, they are pretty strong on the idea that things have a nature and they act lawfully.
3814680	3819760	H	0.8577017784118652	And their nature and their laws, they somehow correspond to linguistic categories.
3819920	3829240	H	0.5899402499198914	So I can say stuff like chickens quack, and that's a proper explanation of what are chicken and why they quack.
3829980	3839536	H	0.8434748649597168	And if you look in Chinese philosophy, as far as written history goes, you have a much accent on Wei Wu Wei.
3839588	3845100	H	0.4831344783306122	So a poor translation would be effortless action.
3846400	3850296	H	0.68232661485672	Closer translation would be action without action.
3850488	3864790	H	0.7955174446105957	So it's something that is quite close to the phenomenology of flow in that you observe yourself doing things and you do not apply a conscious effort to the flow of what you're doing.
3865560	3871332	H	0.7189223170280457	And that looks like something that is closer to the phenomenology you'd expect.
3871386	3898156	H	0.6927765607833862	If you apply recursive preactive cognition with less or less heavy or more effectively integrated symbolic concurring like use of language as something that you actually expect to be meaningful and to constrain strongly your actions and marginally, I'd expect, very strongly expect that linguistic categories will map and what you build with it.
3898178	3903420	H	0.7957977056503296	So, I don't know, self identities, plans, whatever will map cleanly onto what you observe.
3903500	3907570	H	0.5811535716056824	You will be very anxious about things, because that does not happen usually.
3910020	3924676	H	0.6367630362510681	And yeah, besides grand discourse on interpret traits, which are usually not that constructive sorry, I got lost because I did.
3924698	3930330	B	0.7503963112831116	Not let me just say one thing before we move off this point.
3931340	3935396	B	0.5712705254554749	A simple way that language might help is by invoking cognitive flexibility.
3935508	3942844	B	0.7898938655853271	So oftentimes we think about the management of error being either updating predictions or acting on the world.
3943042	3944072	B	0.5807886719703674	That's the dyad.
3944136	3951868	B	0.6737999320030212	Usually what it overlooks is the third one, which is we can also manage volatility by redeploying precision in a better way.
3952034	3963264	B	0.6072816252708435	So rather than just updating your model to fit the world or updating the world to fit your model, you can just change the set of what matters so that you're not really updating the model and you're not really changing the world.
3963302	3965308	B	0.4784952700138092	You're just changing the problem landscape.
3965404	3967620	B	0.6570049524307251	And that's something language allows us to do.
3967690	3976832	B	0.9515309929847717	It's maybe one of the really amazing things that language allows us to do is we can use language to bootstrap that kind of precision adjustment.
3976896	3980744	B	0.4971621632575989	So if the train doesn't come on time, we both notice it.
3980782	3980984	B	0.584351658821106	Okay.
3981022	3983492	B	0.8416550159454346	And we feel bad that's perceptual updating.
3983636	3987044	B	0.8259223103523254	We might go and get a taxi that's active updating.
3987172	3996776	B	0.9511275291442871	But I might just say to you, wow, look, isn't it lovely that now we get a little bit more time to read our book or to continue our conversation or let's finish our coffee with a little bit of ease.
3996808	3998060	B	0.805943489074707	I mean, we get an extra 20 minutes.
3998130	4002012	B	0.6206493973731995	Now even just saying that redeploys precision over the problem.
4002066	4006690	B	0.583540141582489	Space now the train being late isn't volatility in the system.
4007220	4011836	B	0.6024191975593567	The train being late is signaling to the system that a better than expected slope has been achieved.
4012028	4013136	B	0.9271600842475891	Isn't that so interesting?
4013238	4018896	B	0.6818840503692627	The exact same occurrence is either undigestible volatility, right, like you're going to be late.
4018928	4019600	B	0.45354869961738586	Oh my goodness.
4019680	4026676	B	0.662220299243927	Or it's an opportunity for an improvement in the system, which is now you get more time with the person that you're taking the train with.
4026778	4034552	B	0.8396866917610168	And that was just a matter of linguistic perturbance of the way that precision is being looking at.
4034606	4042750	B	0.8591461181640625	If you wanted to dig into the research here, I would look up cognitive flexibility and language or coaching cognitive flexibility is such a good point here.
4045520	4050952	H	0.7452872395515442	So you have a paper by Nick Clark on this specific encouraging role of language.
4051016	4062876	H	0.8344263434410095	And something it entails is that basically you get like if the active infrastructure is correct, you flexibly predict a flow in the interoceptive proprioceptive exteriorceptive.
4062908	4064864	H	0.7047873139381409	Is that even a thing space?
4065062	4071344	H	0.7542603611946106	And that is what builds an integrated experience and integrated cognition and language.
4071392	4073024	H	0.4853915274143219	It adds another layer of complexity.
4073072	4081016	H	0.7618725895881653	If you can just talk to yourself in your head, that is another dimension that you can predict and that can be coherent or incoherent with your world.
4081198	4091228	H	0.9622061848640442	And so that is an extremely powerful encouraging system because I just have to tell a plan to myself and boom, that pushes me, nudges me nicely throughout the plan.
4091314	4097144	H	0.7049145102500916	But then you can have a different level of meta expectation over how language corresponds to reality.
4097192	4109664	H	0.7161980271339417	And I'd say a very strong factor of aversion to uncertainty is whether you expect your plans or your linguistic structure to nicely map onto reality because it will not happen.
4109782	4115036	H	0.7116177082061768	But if you expect strongly that it will be the case, you will have to make it happen somehow.
4115148	4124292	H	0.5419605374336243	And here you will adapt rigid strategies and you will lose flexibility, but also language necessary for flexibility to be the case in the first place.
4124346	4127960	H	0.8536527156829834	So it's about coupling between dimension of cognition.
4130540	4130856	A	0.5491447448730469	Yeah.
4130878	4141256	A	0.5419866442680359	And I would just kind of risk and danger are two things that I've been really interested in across a kind of variety of different contexts.
4141288	4145548	A	0.7722464203834534	And I would say some of the.
4145554	4161152	A	0.8267934322357178	Things that have been said like how you can influence the system by externalizing things through language and the different strategies that systems, whatever scale they're on, have minimizing prediction error, minimizing free energy.
4161286	4165344	A	0.7855534553527832	But also I would just emphasize the importance of external context here as well.
4165382	4172432	A	0.820580244064331	So even in the case of a collective like a business, you still have to take into account the environment in which the business is operating.
4172496	4177100	A	0.6718517541885376	And I've been really interested in a particularly extreme example of context.
4177280	4199020	A	0.45118826627731323	I used to still do some work in philosophy of sport and I've been really interested in dangerous sports and why there seems to be this insane contextual effect where within a very kind of narrow contextual band of sporting practice, people seem willing to take on risks that outside of that context would just be completely insane.
4199680	4215620	A	0.8489065766334534	And I think this is something that's probably going to come up again in subsequent weeks as well here when we talk about the way that expectations on an individual or a collective basis can be set through other minds.
4219400	4223012	A	0.6575909852981567	So what somebody else expect myself to do?
4223146	4224710	A	0.7275934219360352	And so on and so on.
4226120	4227780	A	0.7404229044914246	Darius, you've had your hand up a while.
4227850	4229112	A	0.8640403151512146	Do you want to jump in?
4229246	4229960	D	0.6413175463676453	Yes, please.
4230030	4236760	D	0.7860957980155945	I'm not sure this is the sort of grand synthesis of any of this, but flow was mentioned.
4236830	4243596	D	0.77805095911026	As I said, it's a kind of pet topic of mine and something that.
4243618	4245192	A	0.7645770311355591	We know about flow.
4245256	4262268	D	0.7997458577156067	And this is why it's integrated into this idea of language and agency, is that at least in its original conception, success, mahali, and the sort of qualitative experience associated with flow, you would find stuff like not only the dilation of time, but also the reduction in self consciousness.
4262444	4271188	D	0.6302734017372131	And now this is sort of picking up a lot of work that happens at UCL and people like Jeremy Skipper how integrated language is into the sense of self.
4271354	4290510	D	0.6252543926239014	And it seems to me, and this is kind of shooting from the hip, that all of these very deep rooted, I guess they're kind of psychotechnologies the self language seem to dissipate at this goldilocks zone, at this point of at this edge of criticality, at this flow state.
4291040	4307068	D	0.7933658957481384	Which makes me think if the flow state is a phenomenological offshoot of being optimally reducing prediction error, what is the kind of role of the concept of the self or linguistic functions?
4307244	4313250	D	0.8730373978614807	Because it seems to me that that becomes a regulatory function when that optimality is reduced, when stuff starts going wrong.
4313940	4319408	D	0.862295389175415	So I think you can also think about this in the kind of Heideggerian or draythe's sense of just opening a door.
4319504	4321988	D	0.7949738502502441	You only start to represent the door in yourself.
4322154	4326740	D	0.5971009731292725	You only give it the linguistic object of a door when you can't open it.
4326810	4330884	D	0.5004258155822754	When you open a door standard, there is no representation going there.
4330922	4332952	D	0.794069230556488	I mean, you could even argue there's no qualia there.
4333006	4346328	D	0.741199791431427	So I'm wondering how deep that runs and what we can say about the role of agency, selfhood, maybe even consciousness because they don't seem to be that prevalent, at least from my understanding.
4346504	4348700	D	0.7823001742362976	When we are at the edge of criticality.
4349360	4357390	A	0.7411468029022217	The suggestion you're making there is it sounds like what you're saying that these things you call them psychotenologies, which I really like.
4357760	4362604	A	0.8050870895385742	Like language, like certain aspects of self modeling.
4362652	4381480	A	0.6101651191711426	They are a kind of scaffolding or like a ladder that you then kind of gets kicked away once you reach a certain kind of edge of criticality, like where the performance becomes I don't know what you're performing at such a level that you just don't need those scaffolding.
4382060	4382664	D	0.5491447448730469	Yeah.
4382782	4393800	D	0.8046905994415283	Or the self regulatory mechanisms that we harness when we're not in flow are linguistic or agentic in essence.
4393880	4401340	D	0.5503488779067993	And you don't need that when you're at this edge of criticality.
4402820	4410944	D	0.6856203675270081	And I only postulate that because I'm only thinking, how deep does that go?
4411142	4416868	D	0.7428699135780334	Because I know, obviously the active inference framework is trying to tackle in some ways the hard problem as well.
4417034	4431496	D	0.8733471035957336	And there are some flotations of the idea, at least within the flow community, about the kind of I don't want to say elimination, but the moderation, the modulation of qualia under flow states.
4431678	4445708	D	0.5300044417381287	So could we also consider that to be a construct which happens when we're not necessarily optimally producing prediction error, a couple of things.
4445794	4451348	A	0.609370768070221	So I'm certainly not the person to stop talking about consciousness, so I won't.
4451544	4459292	A	0.8700606822967529	But some of the readings that I mentioned in the lecture might be interesting for you on this topic.
4459356	4486628	A	0.878084123134613	So if we're talking about certain structures that seem very pervasive in our phenomenology and how those structures can sometimes kind of dissolve away and how that might be accounted for under an active inference framework, there's some really interesting work on psychedelics by George Dean and some of George Dean's co conspirators.
4486724	4509004	A	0.8496295809745789	I know Mark and Sam Wilkinson worked on a paper with George so George Dean's done some work on kind of ego dissolution and certain kinds of experiences related to selfhood, kind of and I kind of don't want to overstep the mark, but I think they fall generally under this kind of rebus model of psychedelic efficacy.
4509052	4517200	A	0.8399950265884399	So I don't know if people are familiar with this, but this kind of finds natural articulation through predictive processing and hierarchical self modeling and that kind of stuff.
4517270	4520124	A	0.7638478875160217	I also wanted to really quickly flag on this topic.
4520252	4525284	A	0.4653216302394867	I'll find the paper and I'll put it up on the coder because I don't think I'll be able to find it quickly enough now.
4525322	4535400	A	0.5183573961257935	But there was a paper that came out very recently that showed the efficacy of internal self talk on sports performance.
4537660	4555984	A	0.9458064436912537	They did an experiment with cyclists and they found that when cyclists were allowed to engage in kind of constant self talk with them, like an inner monologue in their head, their performance at cycling was measurably boosted, which I thought was really interesting and kind of relevant here.
4556102	4567716	A	0.6111497282981873	But it's interesting because it sounds like it might prima facia be in tension with what we were saying about flow states as well.
4567738	4567924	A	0.5664746165275574	Right.
4567962	4582680	A	0.634498655796051	So if the real edge of performance is a place where these structures of phenomenology bleed away, it kind of calls into question, like, to what extent are these psychotechnologies effective and in what way are they effective?
4583740	4587690	A	0.9220317602157593	There's just a whole kind of universe of really interesting questions there.
4588380	4594620	H	0.9232745170593262	So, if I may, self food, indirectly will be the central topic of the last two sessions.
4595520	4614344	H	0.8558453917503357	My position about it is that self food, in a sense, we use all of the time, is a quite high level construct that emerges from the ability we have to compare our activity to a socially embedded model of our activity.
4614492	4626352	H	0.8789768815040588	So that is something that is quite specific to humans because of their linguistic ability and or because of their tendency to what Thomaslo calls shared intentionality.
4626416	4628970	H	0.8521925806999207	So the ability to collectively define an.
4631180	4641368	H	0.7420675754547119	So basically, this is something that enables a very deep, very profound and robust transmission of cultural knowledge and transmission of norms.
4641464	4643980	H	0.7292647361755371	This is what enables the construction of norms.
4645360	4662784	H	0.660419225692749	But it's quite heavy cognitively and it is predictable that if you're busy comparing what you do to what an idealized version of yourself is doing, you're going to invest less creative energy in actually doing the thing that you would if you just did a thing.
4662982	4670870	H	0.8760159015655518	So I'd say you have a pretty direct entailment of this flow thing from this model.
4675720	4676228	A	0.5491447448730469	Yeah.
4676314	4676708	H	0.46103888750076294	Yes.
4676794	4677744	H	0.8370274305343628	This is my conclusion.
4677792	4678390	A	0.509212851524353	Sorry.
4680120	4688024	A	0.6108999848365784	So we've run almost 30 minutes over time and I know Mark's had to go and I'm going to have to go very I think I pretty much have to go.
4688062	4695710	A	0.8975116610527039	So I just wondered if anybody has any final kind of quick questions or comments, maybe we can move towards wrapping it up.
4698560	4706130	C	0.5101945400238037	I'll make a few comments, but Ben, you're welcome to leave and other people welcome to stay if they would like.
4707700	4708770	A	0.8983839750289917	Thank you for.
4712180	4717856	C	0.607023298740387	Well, first, just on a logistical note, there was a little bit of lag.
4717968	4736724	C	0.8889966607093811	So I'll encourage everyone who's listening, as well as who's participating, that we eventually plan to, as with all of our live streams, develop a transcript which will be curated and published, and eventually not so far away in the future, that'll be enabled with speech modeling to generate podcast quality audio.
4736852	4739560	C	0.8938248753547668	So the future will be smooth, we promise.
4740380	4748040	C	0.9591444134712219	But a few really interesting pieces that I picked out while I was embodying and listening.
4749420	4758028	C	0.8201000094413757	So, Regina, you opened the discussion with surprise and creativity, and indeed, it sounds like it's going to be attention.
4758124	4764220	C	0.6687021255493164	How can a framework whose imperative is bounded surprise as opposed to, say, maximized reward?
4764380	4770704	C	0.7169616222381592	How can a framework whose imperative is surprise, minimization and bounding be used to generate novelty?
4770752	4774224	C	0.9556100964546204	And I felt like people provided a lot of really cool answers.
4774352	4781884	C	0.8342289328575134	And one other thing it reminds me of is Doug Hofstadter's notion of spectishnish.
4781952	4788692	C	0.6633186936378479	I don't know, how do you pronounce it, but sphexishness, and it's the specs wasp.
4788836	4798392	C	0.6121279001235962	And so he says, well, forget this whole creativity thing, because when we talk about creativity, it's like some sort of pantheon, like divine status.
4798456	4801116	C	0.7814856767654419	The muses have to be called in.
4801218	4804540	C	0.8075814247131348	And so then, oh, that's not real creativity, and this isn't real creativity.
4804620	4808108	C	0.5264297723770142	So instead, he says, well, let's just focus on what would be the opposite.
4808284	4815660	C	0.7044073343276978	And that would be the rote procedural following, even when there's an opportunity for what we would call creativity.
4815820	4817048	C	0.721049427986145	And then there's a continuum.
4817084	4819056	C	0.5061601400375366	So why does somebody paint that painting?
4819168	4821328	C	0.5114824771881104	Well, why didn't they invent a new genre?
4821424	4823668	C	0.49595871567726135	Well, why didn't they invent a new media?
4823834	4839204	C	0.5134572982788086	And so all activity is existing within this continuum of creativeness, which has many features such as generativity and productivity, but also novelty, but abounded novelty.
4839252	4851824	C	0.472333699464798	It's not creative to knock the chessboard pieces off in a way that there might be an elegant chess move who only somebody in a certain cognitive setting could detect the aesthetics of.
4851862	4853330	C	0.9737138152122498	But I think that was awesome.
4854100	4862370	C	0.6355745792388916	And then the second piece that really was powerful was what mark's train.
4862900	4883000	C	0.5212627649307251	I guess the trains don't run on time where Mark is, but that's okay, because he was able to, rather than treat that as an undigestible surprise, that was able to be basically cognitively metabolized into an opportunity for friendship through language as a social medium.
4883500	4888340	C	0.8030664920806885	And then he connected that to cognitive flexibility and coaching.
4888500	4894140	C	0.8591057062149048	And then I thought about self talk and our inner monologue inner voice.
4894800	4913730	C	0.5867578387260437	And then Darius, that was very provocative, that we aren't having self talk, potentially not even having a self in the flow, manifold experience of the self or the self talk, or again, potentially even the total actual self as a technology.
4914120	4947576	C	0.5192226767539978	And so then healthy self talk would guide us to the flow and be kind of like a self limiting technology because it would be used in order to not be needed to be used, which is kind of how we would hope adaptive technologies would be versus a maladaptive technology would be something that entrenches its own utilization potentially at the expense of the functionality.
4947768	4949992	C	0.7179575562477112	Kind of like doom scrolling status.
4950136	4951864	C	0.7138368487358093	But that's internal rumination.
4951912	4955360	C	0.5541167855262756	And those are the kinds of things that people have simulated in active inference.
4955700	4958412	C	0.9669694304466248	So those were some really cool pieces.
4958476	4960000	C	0.9658024907112122	That was a great discussion.
4961060	4967284	A	0.8830983638763428	Could I just add something on the topic of creativity that I should have said earlier as well?
4967322	4975024	A	0.6428972482681274	Because I think it's really relevant to Regina's question and just the topic of creative and novel behaviors in general under active inference.
4975072	5000876	A	0.752882182598114	I think that whenever we talk about especially artistic creativity, there's a tendency, even for people who are kind of very well burrowed into active inference and activism and these kinds of frameworks from cognitive science, I think there's a tendency to think of creativity as still like it's almost like the last bastion of internal cognitiveist thinking.
5001058	5004780	A	0.6155133247375488	We think creativity is something that happens in here and bursts outwards.
5004860	5010300	A	0.686672031879425	And so how does that happen with this kind of whatever cognitive architecture we're positing?
5010460	5020064	A	0.9842286109924316	But there's really very cool work by I have to give a shout out to Mike Wheeler, who has written some papers on the extended mind and creativity.
5020192	5031896	A	0.6889199614524841	And one thing that's not really come up very much that I didn't get time to talk about in the lecture is this really nice natural marriage between the extended mind and active inference, something that Andy Clark has been working on.
5031918	5035016	A	0.7151265740394592	And I know he's going to be doing a lot more work on it.
5035038	5055680	A	0.8552495837211609	But the claim Wheeler makes and some others I think Joanna Zelenska has written a little bit about this as well, is the fact that creativity itself is just as subject to kind of material, the sculpting effects of material environments and sociocultural environments as everything else is.
5055830	5069204	A	0.7411553859710693	So creativity is not this kind of romantic with a capital R kind of internal process that kind of bursts forth, but creative thinking is just as much extended and embedded as everything else.
5069242	5073940	A	0.9618576765060425	And there's some really great examples in Mike Wheeler's essay.
5074280	5077190	A	0.8425531983375549	I don't know, is anybody familiar with the band Alt J?
5077640	5079116	A	0.8286452889442444	They're a British band.
5079168	5081080	A	0.6658831238746643	They were kind of really big a few years ago.
5081150	5085130	A	0.963958203792572	They won the Mercury Music Award because they have a super original sound.
5085900	5089320	A	0.8448431491851807	So AltJ have this really quiet tinkling.
5089740	5090868	A	0.9753783941268921	Yeah, they are a great band.
5090884	5091876	A	0.9784144163131714	They're one of my favorites.
5091908	5101340	A	0.5827736258506775	And they have this really quiet tinky sound that everybody kind of assumed was just the result of some kind of internal genius on the part of the band.
5101840	5114460	A	0.624242901802063	And as it turns out, AltJ, originally they tried to rehearse as an indie rock band, but they were confined to rehearsing in an apartment block, and they kept getting noise complaints.
5114620	5123200	A	0.6756986975669861	And so they ended up developing this quiet tinkly sound because it was the only sound they could rehearse that wouldn't get them kicked out of their apartment.
5123360	5139024	A	0.9266257882118225	And I think this is a really beautiful example of how even the most creative processes that seem, on the face of it, really creative, are in fact just a subject to these external kind of this kind of agent environment system that underpins the whole framework.
5139092	5142750	A	0.7329691648483276	So that's something that's going to apply to absolutely everything.
5144000	5144748	C	0.918424665927887	Awesome.
5144914	5152896	C	0.668083131313324	And just the last question, people are welcome to drop off the next section that we're heading into.
5152998	5158988	C	0.8386939167976379	I'll be doing the lecture that's going to be in August, and it's going to be on collective behavior.
5159084	5167220	C	0.905264675617218	So what would people like to learn or focus on about collective behavior?
5177640	5189320	C	0.4782073497772217	Anyone who hasn't spoken or it can just be a thought question, but I haven't prepared the slides at all, so I'm happy to take suggestions.
5192620	5194590	C	0.8245015144348145	Yeah, Darius and then anyone else?
5194960	5203260	D	0.5028728246688843	I think what might be interesting is if we're saying that these systems are all in the business of reducing prediction error, of self evidencing.
5203760	5217080	D	0.6152309775352478	Why do we see a diversity why do we see a diversity of social cultures, of norms, of standards at a global scale?
5217260	5232372	D	0.6631340980529785	Why do we not just see some homogeneous way to reduce picture there, which would manifest as the kind of singular culture which is in the kind of business of self evidencing?
5232516	5234250	D	0.7262774109840393	That just kind of popped in my mind.
5236060	5236810	A	0.84200119972229	Cool.
5241920	5246024	C	0.9017841219902039	Anyone else want to give a thought on collective behavior or on any other aspect?
5246152	5247710	C	0.8976056575775146	Otherwise it's been great.
5248320	5261330	H	0.8623712062835693	I'd like to make a comment of creativity, but does anyone like at the moment, if you want to make a comment on the next session, I want to put that.
5262900	5264290	I	0.5060662031173706	Okay, go for it.
5265460	5280890	H	0.6064929366111755	I'd say that to complement what Ben said, that creativity is intrinsically very hard to model because by definition, creativity is something that brings about something new, let us say.
5281340	5288410	H	0.7568326592445374	And the mathematics we have to describe physics and life, they are not very good at new things.
5289340	5305070	H	0.6061879992485046	Because the most basic tool you have, the basic way to represent a system that literally everyone uses, is a stead space, which is the least of all possibilities of a system.
5305440	5311404	H	0.7291901707649231	If you say something is creative, you're likely to think that it means it can bring about new possibilities.
5311532	5316824	H	0.8336054086685181	And this intuition, it conflicts directly with the very basic use of math.
5316972	5317924	H	0.7205078601837158	Describe it.
5318042	5326960	H	0.6885234117507935	So it is basically the same issues I was referring to earlier when I talked about the comparison between active inference and an activist.
5327120	5337364	H	0.8948488831520081	So let's say activity biology inspired model of cognition, and a core concept historically in those circles is autopoiesis.
5337412	5342940	H	0.812836229801178	So the ability of the living to self create, literally, this is Greek for self creation.
5343360	5353096	H	0.7710438966751099	And you had a lot of drift and conceptualization and ambiguities that were resolved or not resolved and led to the crisis of framework, blah, blah, blah.
5353208	5357476	H	0.7041847109794617	But today we talk of autonomy rather than autopoiesis.
5357608	5367090	H	0.8677956461906433	And we define autonomy as the property for a system of constraints over the activity of a system to reproduce themselves.
5367480	5379712	H	0.6882476806640625	And because we're talking constraints, just the ability to influence causality outcomes, there is no really a prior that dynamics in this space would be conservative.
5379776	5385144	H	0.7850883603096008	So we have a possibility for constraints to bring about new things and reconfigure themselves.
5385342	5389050	H	0.8876727819442749	And the notion of Hydrancy ADUs is based on that.
5389500	5400028	H	0.7515552043914795	It's the ability to, let's say, reconfigure constraints in your environment, and so is the notion of creativity, which would be likely a very close proxy to that.
5400114	5404110	H	0.5422441363334656	But it's something that we do not know how to present.
5405220	5410316	H	0.8372746109962463	And most of the mathematics that exist are structurally enabled, represent.
5410508	5413330	H	0.5056536793708801	And so, yeah, that's a big one.
5417400	5418390	C	0.6716039180755615	So true.
5421000	5421860	A	0.6781592965126038	Michael.
5426600	5427396	I	0.9721079468727112	Good to be here.
5427418	5428580	I	0.7696136832237244	Sorry I was late.
5429800	5435320	I	0.8785660266876221	What comes to mind for me at the know, I mentioned units of collective, like, what is it, a we?
5435390	5436840	I	0.8990155458450317	Is it a we a pair?
5439420	5440584	I	0.7769302129745483	What are the units of we.
5440622	5442910	I	0.8653398752212524	And any thoughts or insights about that?
5444000	5458944	I	0.6259485483169556	The stages of the emergence of formation into a collective from a me to a we, for example, or god, I had one was on the tip of my tongue, and it just escaped me.
5459062	5459730	I	0.5443295240402222	Oh.
5460740	5495740	I	0.767669141292572	This idea of precision that I think it was Mark Miller was talking about, or Matt saying at the if there's options in the looking at collective what might be some of the most well understood limiting beliefs about when we use language of collective that keeps us repeating the same blind spots.
5497520	5505310	I	0.8446542620658875	And how might we think differently about collective so that we escape those predispositions, if you will?
5505760	5506770	I	0.534262478351593	Makes sense.
5509700	5511824	C	0.7884845733642578	They'll do what I can do in.
5511862	5515392	I	0.9015175104141235	The solo lecture, and I'll look forward.
5515526	5517884	C	0.8773220777511597	To the conversation where we can unpack.
5517932	5518530	D	0.5428685545921326	It.
5520260	5520812	I	0.9694170355796814	Exciting.
5520876	5521664	I	0.9701927900314331	Thank you for doing it.
5521702	5523376	I	0.9753931164741516	I'm looking forward to it.
5523478	5524336	C	0.9711287021636963	Yeah, it's awesome.
5524438	5526690	C	0.932039201259613	Nathan or David, you want to add anything?
5532170	5533414	C	0.5821025967597961	All right, then.
5533452	5534150	C	0.9195932745933533	Thank you all.
5534220	5536902	C	0.9752427339553833	Hope everyone is enjoying the course so far.
5536956	5539414	C	0.9368686079978943	Thanks, Avel, again for coordinating it.
5539452	5542482	C	0.9591468572616577	And to Ben for this great section.
5542626	5545320	C	0.6470521688461304	Now you can put on your student hat again.
5546010	5547750	H	0.5114417672157288	And to you for organizing.
5548650	5549318	C	0.8529649972915649	Thank you.
5549404	5550214	C	0.5591034889221191	See you all next time.
5550252	5550840	E	0.6283750534057617	Thanks.
5551610	5552210	B	0.5137446522712708	Bye.
5552290	5553080	I	0.8529649972915649	Thank you.
5554010	5554660	D	0.8315965533256531	Thanks, everyone.
