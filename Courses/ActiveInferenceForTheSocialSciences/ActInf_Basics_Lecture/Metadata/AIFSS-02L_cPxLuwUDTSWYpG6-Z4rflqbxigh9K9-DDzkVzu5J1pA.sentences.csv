start	end	sentNum	speaker	confidence	text
410	670	1	A	0.3922	Hello.
740	1520	2	A	0.55	All right.
1970	3374	3	B	0.99985	Hello and welcome, everyone.
3492	7646	4	B	0.61819	It is July 11, 2023.
7828	17774	5	B	0.99999	We are in active inference for the social sciences, and today is going to be a lecture by Ben White on basics of active inference, the active inference agent.
17892	19994	6	B	1.0	So, Ben, thank you for the lecture.
20122	23566	7	B	0.99937	Off to you, and we're looking forward to it.
23748	24702	8	A	0.99996	Thank you very much.
24756	25960	9	A	0.98365	Yeah, me too.
26330	33320	10	A	0.99111	Very happy to be a part of this, to be kicking things off with the first module on this course.
33930	39350	11	A	0.99802	I'm going to be talking about the active inference agent and trying to cover some of the basics.
40010	41878	12	A	1.0	I won't take too long introducing myself.
41964	64020	13	A	0.47412	Ava gave a very thorough introduction in his talk recently, but I'm a second year PhD student in philosophy at the University of Sussex, and I work with Andy Clark and with Avel and some other people using active inference to try and find things out about our relationship with technology and within the context of well being and mental health.
65590	85350	14	A	1.0	The aims for today I'm going to try and provide quite a wide ranging overview of how active inference has connected with areas of philosophical interest, and particularly how they relate to the individual agent and the experience of the agent and how the agent finds themselves in the world.
85420	90118	15	A	1.0	So I've split this up to look at several different defined topics.
90214	99530	16	A	1.0	So I'm going to move quite quickly through mind, agency, emotion, and phenomenology, and I'm going to say a little bit about the self as well.
99600	104160	17	A	1.0	And then there's going to be a case study at the end that I'm going to move through if we have time.
104690	115270	18	A	1.0	So one of the other aims that I have is to lay out very clearly some of the core concepts and core mechanisms like precision, weighting, and prediction error enactive models.
115450	118942	19	A	0.87825	I'm not going to go into any technical details whatsoever.
119006	121006	20	A	1.0	This is all going to be fairly abstract.
121118	128920	21	A	0.99999	My background and my interest in these frameworks is philosophical, so it's quite abstract in terms of how everything fits together.
129370	150454	22	A	1.0	And I'm going to try and bring some of these threads together to build up a layered picture of what the active inference agent is like, because this course is kind of aimed towards seeing how active inference applies to larger scales, collective behavior, social norms, sociocultural landscapes.
150582	158538	23	A	1.0	And I think in order to do justice to those things, we need to first have a good idea of the individual in active inference.
158714	161454	24	A	0.99	So we've got our work cut out for us.
161572	162880	25	A	1.0	So I'll get started.
163570	168658	26	A	0.9	So before I dive in, I wanted to just say a little bit about how these frameworks hang together.
168744	173982	27	A	0.85	So active inference is based on Karl Friston's free energy principle.
174046	175794	28	A	1.0	I think most of us are familiar with that.
175832	192102	29	A	0.94521	But the free energy principle just states that in order to persist through time, biological organisms must occupy only those states that it would expect to occupy, given the type of thing that it is so free energy is essentially a measure of the disatunment between a system and its environment.
192166	198780	30	A	1.0	And I'm going to say a little bit more about attunement and how that gets cashed out in various ways as we go on.
199150	206926	31	A	0.99977	Active inference is a process theory that essentially explains how embodied organisms actually go about remaining in those expected states.
207028	211120	32	A	1.0	So how we actually go about minimizing free energy.
211490	220290	33	A	1.0	And the idea is that all adaptive behavior is explained by agents garnering evidence to confirm their own expectations.
221510	222654	34	A	0.99363	Predictive processing.
222702	233490	35	A	1.0	For the purposes of the lecture today, I'm going to treat these as synonymous because most of the work that I kind of came up through as I was learning about this was predictive processing.
233650	244934	36	A	1.0	And all of the papers that we're using today that refer to predictive processing refer to a predictive processing that I take to be more or less synonymous with active inference.
244982	250566	37	A	1.0	So that's a very embodied, inactive flavor of predictive processing.
250678	258442	38	A	1.0	I think generally the difference is that predictive processing can be a much broader term and predictive processing can also apply to passive models of perception.
258506	260960	39	A	1.0	But we're not going to concern ourselves with that.
262630	268100	40	A	0.52	Okay, so some key concepts of active inference, predictive processing then.
268630	288674	41	A	1.0	So the framework says that agents embody or agents have we won't concern ourselves with the nuance there, but they have a generative model, which is essentially a kind of understanding or a model of the regularities that underpin the dynamics between the agent and the environment.
288802	297660	42	A	1.0	So another way to think about this in very rough terms is a kind of mental model of the regularities in the world and how the agent exists in the world.
298030	303278	43	A	1.0	And using that model, the agent can generate predictions about its own sensory states.
303444	310510	44	A	0.84	So given the model, what kinds of sensory states would it expect to find itself in in a particular set of circumstances?
311170	316174	45	A	1.0	And so where those predictions don't actually match the sensory inputs.
316222	326306	46	A	1.0	So where there's a discrepancy between the actual incoming sense data and the prediction, prediction errors are generated and prediction errors are going to flow upwards through the hierarchy.
326338	333538	47	A	0.5	So the generative model is said to be a hierarchical model and predictions flow downwards and prediction errors flow upwards.
333714	341050	48	A	0.58	And the sole imperative of the brain body system, according to this framework is to minimize those prediction errors.
342830	349878	49	A	1.0	So a good way to kind of get a little handle on this is to think about just the example of perception.
349974	353454	50	A	0.93	So perception traditionally so I'm talking about visual perception here.
353492	356254	51	A	0.72502	It's traditionally been understood as a bottom up process.
356452	366370	52	A	1.0	And what that means is that the brain waits for incoming sensory signals and then it processes them as they come in and it combines them in kind of increasingly abstract ways.
366520	372750	53	A	1.0	And what we see is some combination of those sensory signals that have come in and been processed and combined.
372910	380194	54	A	1.0	So if you think about me leaving my apartment in the morning and stepping out onto the street and seeing some cars.
380322	391046	55	A	0.99776	What's happening there is some sensory information is hitting my retina and it's being processed first with very basic features like light shade, edges and so on and so forth.
391158	396346	56	A	1.0	And then it's being combined with my understanding of what a car is or what a bus stop is.
396448	399020	57	A	1.0	And that gives me my kind of visual field.
400850	406382	58	A	0.95576	Predictive processing, famously at this point, flips this picture upside down on its head.
406436	410858	59	A	0.6	So visual perception under predictive processing is a top down affair.
411034	416494	60	A	1.0	So the Generative model is going to encode multilevel expectations about the likely scene.
416542	430390	61	A	1.0	So, just to be very clear, when we talk about multilevel and hierarchical, the higher up levels are going to be tracking longer timescales and higher levels of abstraction, and the lower levels are going to be much faster and much more concrete.
430730	440626	62	A	1.0	So a changeable scene, so there's going to be some variation in what I see when I leave my apartment every day is going to mean that there's always going to be some error in that picture.
440658	445546	63	A	0.99	So it's never going to be the same two days in a row or it's extremely unlikely to be.
445648	452910	64	A	1.0	So no matter how well I can predict what I'm going to see when I leave my house, it's always going to be cleaned up by some prediction errors.
453250	460880	65	A	1.0	So essentially, when I step outside and I step into the street, my brain is already anticipating what it's going to see out there.
461570	467342	66	A	1.0	So I know where particular cars are going to be parked, I know where the bus stop is, so on and so forth.
467486	471490	67	A	1.0	And the perceptual experience that we have is a construction.
472150	478050	68	A	0.9997	We actually experience the expectation that has been kind of cleaned up post prediction error.
478210	482102	69	A	0.83869	There's a little bit of debate there about exactly what it is that we experience.
482236	488650	70	A	0.99999	But for our purposes today, we can say that visual perception is essentially a construction.
490510	497420	71	A	1.0	So on the face of it, prediction errors can be minimized using one of two strategies, and this is going to be really important.
499790	503386	72	A	1.0	So we have what I just described there, which is perceptual inference.
503498	507082	73	A	0.99986	That's where we revise our predictions to better fit the evidence.
507146	511630	74	A	1.0	So essentially we update our model to better reflect the regularities in the environment.
512290	520660	75	A	1.0	Or we can engage in active inference, which is where the framework gets its name from, which is where we essentially make the evidence fit the model.
521190	527042	76	A	1.0	So that's where we in some sense update the world so it conforms to the original prediction.
527186	538890	77	A	0.87	And active inference agents bring about those expected states by sampling the world in a bias way, so they have certain expectations and then we sample the world to confirm the predictions.
539230	550758	78	A	0.99	And I put perceptual inference there in scare quotes because perceptual inference on kind of readings of most readings of active inference just becomes a kind of action readiness.
550854	554202	79	A	1.0	Or as Ramstead and colleagues put it, a state estimation.
554346	558938	80	A	0.99	So it's just perception and action are just wrapped up in this continuous loop.
559034	560714	81	A	0.99617	But it's really all about the action.
560762	567186	82	A	0.9991	It's really all about bringing about those expected states, and perception is just kind of in service of that process.
567368	576194	83	A	0.98	And so Bruineberg and colleagues refer to the enactive inference agent as a crooked scientist, which is something I really like.
576232	577746	84	A	1.0	I think that's a very charming image.
577778	586422	85	A	0.79	So we are scientists that are engaging in some very dodgy behavior because we're not really interested in having an accurate model.
586476	590810	86	A	0.69711	We're more interested in confirming our original predictions.
592350	601462	87	A	1.0	Okay, so that was a very rapid overview of some of the core concepts and mechanisms, but they're going to crop up continuously.
601526	605340	88	A	1.0	So I think we're going to get a much better grasp on them as we go on.
605870	617460	89	A	0.99999	In this section, I'm going to start to expand on some of those things that we've just put on the table, and I'm going to begin to flesh them out in terms of thinking about how active inference agents actually exist in the world.
619030	621442	90	A	1.0	So I should say I put this here to remind me.
621496	635250	91	A	1.0	So those of you who are taking part in the course, I'm going to make available a document with all of the readings that I firstly, all of the readings that I've used to make these slides, and then a bunch of other readings as well that I think are going to be very relevant.
635330	640214	92	A	1.0	And obviously, they're going to be organized in terms of the structure of this presentation as well.
640252	645450	93	A	1.0	So this is just I've put a little sample up on these slides, but there's going to be much more in the document.
646510	649740	94	A	1.0	So I think it's always good to start with some guiding questions.
650350	652240	95	A	1.0	So I've thrown up three here.
654690	657690	96	A	1.0	The first is how does enactive inference characterize cognition?
657770	662990	97	A	1.0	So we've just looked at predictions and prediction errors, but we're going to expand on that a little bit.
663060	666718	98	A	1.0	And we're going to ask what kinds of processes does cognition involve?
666894	669550	99	A	1.0	How is cognition related to the material environment?
669630	675426	100	A	0.99989	This is going to be something how cognition relates to the environment is going to be very important in subsequent weeks.
675608	681030	101	A	1.0	And we're going to ask quite briefly what kinds of vehicles might realize cognitive processing.
681610	684482	102	A	0.93	So here's a couple of whales.
684546	700362	103	A	0.73451	Whales are going to be a recurring theme in this lecture, but I wanted to take a step back and ask about Attunement because this is one of those concepts that gets thrown around a lot, and I think once it's grasped, it becomes very clear and very easy to use.
700416	704842	104	A	0.99985	But I think prior to it being grasped, it can be a little bit opaque and a bit slippery.
704986	711050	105	A	0.99	So on the left we have a humpback whale that was found dead in the Amazon rainforest, allegedly.
711130	712590	106	A	1.0	I don't know if this was true.
712740	715626	107	A	1.0	And on the right we have a whale in its natural environment.
715738	722946	108	A	0.97	And I think clearly the intuition here is that in one case the whale is very well attuned to its environment and in the other case it's not.
723128	730130	109	A	1.0	And I think that we can start by asking what is it about the ocean that allows the whale to be well attuned?
730210	740970	110	A	0.99	And what I want to say here is that the particular dynamics between the ocean and the whale allow the whale to do certain things that it can't do when it's in the Amazon.
741710	756686	111	A	0.99	So in other words, we might say that the ocean affords certain things to the whale, specifically filter feeding, being able to move its vast weight around with ease, things that, unfortunately, a whale in the Amazon can't do.
756868	759950	112	A	0.99	So affordances are opportunities for action.
760770	765902	113	A	0.94343	They are things, roughly speaking, in the environment that the agent can act upon.
766046	780438	114	A	1.0	And there's some debate about the proper way to really characterize affordances, but I like to think of them as relational properties emerging from an environmental feature and some skilled embodied ability of the agent.
780524	786210	115	A	1.0	So the same thing in the environment will not afford the same thing to different organisms.
786370	795738	116	A	1.0	So for example, soil to a human agent might afford walking on or laying down on, but to an Earthworm it affords very different things.
795824	806560	117	A	1.0	And also, even amongst the same organisms with humans, especially, different surfaces and features of the environment will afford different things depending on your particular skill set.
807890	817834	118	A	1.0	And agents are going to go about minimizing their uncertainty, so minimizing prediction errors, staying attuned to their environment through an engagement with affordances.
817962	825060	119	A	1.0	And this is going to be something that is going to drift away slightly as we move through some sections and then it's going to come back very heavily at the end.
825830	834962	120	A	0.99	And I should say that the idea of affordances, to my knowledge, it first emerges in the work of James Gibson the Ecological Approach to Visual Perception.
835026	839530	121	A	1.0	I think it's chapter eight in that book that really lays out a theory of affordances.
844560	858160	122	A	0.97	So this idea that systems or organisms maintain their organization through ongoing action means that active inference has been labeled as quintessentially inactive by Karl Friston's.
858580	871216	123	A	0.98	And I think that this is a nice inactivism is an older framework from theoretical cognitive science and I think it's a nice way to understand some of the key features of active inference.
871328	875184	124	A	0.99999	But it does come with a little bit of historical philosophical baggage.
875232	886090	125	A	1.0	And I'm going to try and unpack that really quickly because I want to unpack exactly what it is that we're committing ourselves to when we think about cognition in activist terms.
887100	899144	126	A	1.0	So inactivism comes in various strands very, very quickly and roughly, you have autopoietic inactivism, which commits itself to what's known as the mind life continuity thesis.
899272	909840	127	A	0.99999	This is essentially that the structures that give a ground to life itself are the same structures that instantiate cognitive processes.
910900	917616	128	A	0.59354	Sensing on this view is teleological because it's oriented around supporting vital systems.
917648	926810	129	A	0.98	So things in the environment have intrinsic meaning to the organism because they support the vital functioning of the organism in some way.
927660	939544	130	A	0.99873	Sensory motor in activism emphasizes how mobile and embodied agents essentially enact the grounds and conditions for their own sensory engagements with the world.
939662	958124	131	A	1.0	So the world is not a kind of neutral static given that we're parachuted into actually the conditions through which we sense the world are the conditions that we can move and kind of interact with the world in various ways and then there's radical enactivism.
958252	964864	132	A	1.0	And this is the view that cognition is purely grounded in these agent environment dynamics.
964912	972064	133	A	0.99997	It's a purely dynamicist account of cognition and there's no role whatsoever for internal representations.
972192	981540	134	A	1.0	So certainly in certain brands of sensory motor in enactivism there remains a role for internal manipulation of representations.
981700	987240	135	A	1.0	And mental representations are just mental states that are about something in the world.
987390	992172	136	A	1.0	So some mental state is reconstructing some feature of the world.
992306	1008064	137	A	1.0	And this all harks back to kind of old debates in philosophy of cognitive science between internalist notions of cognition and more embodied, embedded, extended and we'll take more of a look at that in a second.
1008182	1013964	138	A	0.65191	But the question here is what are we committing ourselves to with active inference?
1014092	1019300	139	A	1.0	And I need to be a little bit careful because I think that people are going to disagree with this to certain extents.
1021080	1024512	140	A	0.99341	But I think we're certainly committing ourselves to sensory motor in activism.
1024576	1026384	141	A	1.0	I think that's fairly uncontroversial.
1026512	1040920	142	A	1.0	And I would say as well that the underpinning of active inference by the free energy principle by my lights also commits us or it certainly chimes very deeply with the core tenets of autopoetic inactivism.
1041660	1049800	143	A	0.99979	But I think what's really interesting in trying to understand cognition in the active inference agent is to understand what role, if any, there are for representations.
1050300	1065024	144	A	1.0	So if you have any familiarity with the literature on active inference, you'll know that active inference people are always banging on about models, prediction errors, various other computationally sounding things.
1065222	1075712	145	A	1.0	And so the worry here is at least for well, it's not necessarily a worry, but the thought would be are we committing ourselves to a form of cognitivism?
1075776	1092350	146	A	1.0	And again, cognitivism is this it's generally considered to be an old fashioned notion of cognition as like computation over symbolic representations in the brain according to some syntactic set of rules or something.
1093440	1099468	147	A	0.98	And typically over the last couple of decades in cognitive science people have been moving away from that view.
1099634	1108172	148	A	1.0	So it would be interesting if we were committing ourselves to something that we'd already moved away from and some people think that we are making that commitment.
1108236	1121216	149	A	0.99	So Jakob Hohwy, for example, has argued in various places that essentially predictive processing or enactive inference commits us to these very rich reconstructive notions of representation.
1121408	1131384	150	A	1.0	And even Andy Clark, Jakob Howie's foil in many places has said himself that he thinks that representations play a role here as well.
1131502	1136644	151	A	0.56	So in a talk in 2016, Clark said it's internal representation.
1136772	1137640	152	A	1.0	I think it is.
1137710	1145948	153	A	0.99995	These are representation using stories, but it's not internal representation in quite the way that we originally thought about it.
1146114	1152432	154	A	1.0	So there's some differences, perhaps major differences between Howie and Clark there, but others have pushed back.
1152486	1169300	155	A	1.0	So there's a paper by Maxwell Ramstead and colleagues from 2020, I think it's the tale of two densities paper where they say that a proper understanding of the generative models in active inference suggests that there's no role for representations.
1170040	1172470	156	A	0.99	So this is the kind of anti Howie view.
1175800	1190660	157	A	0.88	So I really like this paper from Avel Constant and Andy Clark and Karl Friston's which essentially tries to broker some kind of peace in a debate that in some form or another has been raging for decades.
1190740	1194108	158	A	0.99	So it'd be quite nice to finally put this to bed.
1194274	1201150	159	A	1.0	So they argue that we can find, in the formalisms of active inference, we can find grounds for an armistice here.
1201940	1213672	160	A	1.0	So they argue that the formalisms of active inference show that, quote representational and non representational cognitive processes can be implemented by the brain under active inference.
1213836	1218976	161	A	1.0	And they do this by showing that active inference accommodates a dual architecture.
1219168	1237240	162	A	1.0	So they show that on the one hand, in some sense the brain has to represent because under active inference action selection policies are happening over extended timescales and so the agent has to engage in some kind of counterfactual thinking.
1237390	1239272	163	A	1.0	So if I do X, what happens?
1239326	1240780	164	A	1.0	If I do, y what happens?
1240850	1241644	165	A	1.0	And so on.
1241762	1248460	166	A	1.0	And the argument, very roughly speaking, is that that is going to entail some kind of representational, some use of representations.
1249360	1259564	167	A	0.99994	But on the other hand, they argue that what they call deontic actions are processed through different mappings in the generative model and they're directly triggered by sensory input.
1259692	1267088	168	A	1.0	So a deontic action is an action that is ingrained by our sense of the expectations of others.
1267254	1273828	169	A	1.0	So the example that the authors use is stopping at some red traffic lights in the middle of the night when there's nobody else around.
1273994	1292780	170	A	1.0	So in a sense the claim is that through a kind of social conditioning we know what other people would expect us to do in those circumstances and that allows for this kind of dynamic reflexive action policy setting.
1295120	1300670	171	A	1.0	And in those cases there's no room for representative or there's no need for representations there.
1301380	1319910	172	A	1.0	I would definitely suggest people interested in this go and read this paper because you might already have thought of some potential objections here to the claim that representations aren't needed for deontic action and they do go into some detail in talking about potential objections there.
1321320	1326500	173	A	0.98	So that's the kind of status of the role of representations.
1327260	1330916	174	A	0.98478	It's a live debate, not everybody agrees.
1331108	1339012	175	A	0.99995	But it certainly looks as though active inference has the formal tools to accommodate both sides of the debate.
1339076	1349070	176	A	1.0	And it might turn out that that's a good thing because we can make everybody happy or it might turn out to be a bad thing because you might think, well, we've not really settled anything one way or another.
1350640	1356748	177	A	1.0	I wanted to take some time, though, to mention extended active inference.
1356844	1371552	178	A	1.0	So I've been talking about inactivism and I've mentioned this debate between cognitiveism and older ways of thinking about sorry, cognitiveism and newer ways of thinking about cognition as embodied or embedded.
1371696	1374736	179	A	1.0	And these are part of what's known as the four E paradigm.
1374848	1383992	180	A	1.0	And clearly I think we are talking about inactive cognition and you get embodied and embedded kind of for free with this.
1384046	1387416	181	A	0.56	So the only one left on the table is the extended mind.
1387598	1400750	182	A	1.0	And this is just the claim that under some conditions the system that's realizing cognitive processing can literally extend outwards from the mind.
1401200	1405984	183	A	0.99	So I'll put some nice read ins for this up if anybody's unfamiliar and interested.
1406102	1409280	184	A	0.99853	But it's usually the most controversial of the four E's.
1410980	1421392	185	A	0.98	And Andy Clark, who is one of the original authors of the extended mind paper, really thinks that active inference accommodates the extended mind theory.
1421456	1435140	186	A	0.58	And it's not just that it accommodates it, but it actually solves some old problems in the extended mind about knowing how and why the brain knows when and where to recruit certain extra neural resources.
1435300	1448968	187	A	0.95	And part of the argument for this, what really sits at the core is Clark develops this argument based on the fact that the generative models in active inference are always in this, always making a trade off between accuracy and complexity.
1449144	1462348	188	A	0.99	So you want your model of the world to be accurate enough that you can act effectively on the world, but you also want to minimize the metabolic costs of having models that are overly complex.
1462524	1477690	189	A	0.99	And so Clark utilizes this insight to make the case that this explains that in some cases as agents we make use of these extra neural kind of props and tools and things.
1478540	1488970	190	A	1.0	And he says that the imperative to reduce uncertainty provides a location neutral cost function that's always been missing from the older arguments around extended mind.
1490160	1498360	191	A	1.0	So the upshot to this, I think, is that you end up with a view of agents as deeply coupled with their environments.
1498520	1505196	192	A	1.0	So under active inference it's just nonsensical to try and think about agents as decoupled from their environment.
1505308	1510700	193	A	0.51	The generative models themselves are of the dynamics between the agent and the environment.
1510780	1516400	194	A	1.0	So these two things can't be decoupled perception, action loops.
1516480	1520612	195	A	1.0	So remember I said that perceptual and active inference are essentially the same thing.
1520666	1527720	196	A	0.96914	They're part of this circular causality and they see the agent constantly producing their own worlds.
1528220	1532040	197	A	0.99994	They occupy the states that they're expecting to through action.
1532540	1540536	198	A	1.0	And we might think, based on the literature that I've gone through, that there's some role here for representations.
1540728	1543100	199	A	1.0	So we're not committing ourselves.
1544560	1551100	200	A	1.0	The active inference agent is not one that fits with very radical interpretations of inactivism.
1551940	1556972	201	A	0.99	And active inference agents are porous.
1557116	1568790	202	A	0.79382	They're open to recruiting external material features of the environment to reduce complexity and therefore minimize the metabolic costs of realizing those expected states.
1571000	1584402	203	A	1.0	Okay, so that was a bit of active inference set against the backdrop of some older questions in philosophy of mind theoretical cognitive science.
1584546	1589720	204	A	0.99976	But I'm going to jump straight into agency and motivation now because there's a lot to get through here.
1590890	1592966	205	A	0.50868	I'm going to start with a dark room problem.
1593068	1597094	206	A	0.99999	This is a canonical philosophical worry in active inference.
1597142	1599770	207	A	0.99	So a lot of people, I think, will be familiar with this.
1599920	1603020	208	A	0.98	And in really brief terms, it's really easy to state.
1603390	1614686	209	A	1.0	The challenge here is to say, if it's all about minimizing prediction error, why don't we just find the most predictable environments possible and stay there and live a nice error free life?
1614868	1625060	210	A	0.99	So Andy Clark paints a picture of a dark room, and you can just be strapped up to an intravenous drip, feeding you the nutrients you need, and you can just be really happy.
1625510	1627586	211	A	0.99997	But clearly, we don't do that.
1627768	1629362	212	A	0.98929	Active inference sorry.
1629416	1637718	213	A	0.99989	Agents in the world, us, we generally typically sometimes we do enjoy dark rooms, but most of the time we don't for any extended period of time.
1637804	1650810	214	A	1.0	And so there's a challenge here about how active inference can account for what appear to be motivated agential actions that necessarily mean we're confronted with some degree of uncertainty.
1651790	1660890	215	A	1.0	And I'm going to set active inference up in a kind of dialectic with folk psychology here, because folk psychology faces no such concerns.
1661050	1673070	216	A	1.0	So, to be very clear, folk psychology is just the kind of propositional linguistic framework that the folk use to talk about and describe motivated action.
1673150	1679606	217	A	1.0	So it's a language we typically use every day to describe the reasons people are doing things.
1679788	1689490	218	A	1.0	So folk psychology has this belief, desire, intention, schema, where, if I want to explain, my friend going to grab a beer.
1689650	1692822	219	A	1.0	I would say, my friend believes there's beer in the fridge.
1692886	1694806	220	A	0.99998	My friend desires beer.
1694918	1698774	221	A	1.0	And so those are combined to form the intention to go and get beer.
1698822	1702060	222	A	1.0	So folk psychology doesn't have these kinds of problems.
1704030	1707390	223	A	1.0	So just a little bit more on the dark room problem and another whale.
1708770	1711630	224	A	0.99	So the dark room problem invites more than one answer.
1711700	1714400	225	A	0.99159	We're going to see more than one answer to it as we go along.
1715090	1722162	226	A	1.0	One response is to talk about what drives curiosity and play and exploration, and we are going to see more of that.
1722296	1738882	227	A	0.99805	But the first response offered by Friston Thornton and Clark is to highlight the fact that organisms have basic needs to eat, drink, and reproduce what you might call evolutionarily ingrained needs, and that those needs are going to necessitate some form of exploratory behavior.
1739026	1747210	228	A	0.67	So staying in the dark room will inevitably, under most circumstances, going to lead to physical dissipation.
1749790	1753980	229	A	1.0	So the question is, are these kinds of appeals enough?
1755950	1762570	230	A	1.0	And I wanted to pull up a paper by Colin Klein 2018 that I think is like a really nice articulation of these challenges.
1762650	1768118	231	A	0.97732	Ultimately, I think he's wrong and it falls flat, but I think it's a strong articulation.
1768314	1774770	232	A	0.99	So Klein argues that predictions alone simply can't account for the motivational character of these needs.
1774840	1777890	233	A	0.99	So Klein says, look, it's fine that you've got these needs.
1777960	1788054	234	A	0.99962	Nobody's going to deny that, but you just have this one primitive to describe how those needs motivate you, and prediction is just not going to do it.
1788092	1795900	235	A	0.99	So prediction alone, as your sole primitive is not going to be able it's like predicting is not the same thing as being motivated by something.
1797550	1803466	236	A	0.91	And Klein is really not happy with appeals to these phenotypic needs.
1803648	1811406	237	A	0.99	And he construes these in the relevance of the evolutionary history of the organism and goes into a little bit of detail.
1811508	1829758	238	A	1.0	So he says, look, these expectations are either going to be about states, possible states, so the state of being fed or clothed or warm, or they're going to be about state transitions, about what the appropriate action is in one state to move to another state.
1829944	1838802	239	A	1.0	And he says expectations about states themselves aren't going to work because you have this problem of accounting for novelty.
1838946	1847942	240	A	1.0	So it might be the case that in my evolutionary past, all of my ancestors have had the same expectations about which states they're going to occupy.
1848086	1857280	241	A	1.0	But there are lots of states in my life that I could be motivated to occupy that there's simply no evolutionary history to account for.
1857810	1868378	242	A	1.0	And he says there's a very similar or similarly difficult problem with state transitions where essentially what we're talking about with state transitions are the most appropriate actions.
1868554	1878786	243	A	1.0	So I have expectations about the actions that are going to fill foot that I need to take under certain circumstances that are going to get me to a particular expected state.
1878968	1884694	244	A	0.82	And Klein's worry is that there's just going to be too many possible actions in any given situation.
1884812	1891658	245	A	0.99	So there's just a kind of explosion that's just going to be unaccountable for.
1891744	1900860	246	A	0.99994	There's just going to be too many different ways of getting to an expected state that we won't be able to account for in our past.
1901470	1908574	247	A	1.0	So it's fairly robust, thorough challenge built on the dark room problem.
1908772	1912330	248	A	1.0	And I think actually it's a worry with two faces.
1912410	1922414	249	A	0.99	So I think the first is about how active inference can describe agential behavior with its austere, purely doxastic landscape.
1922462	1932662	250	A	1.0	So if you imagine somebody looking at their house burning down, it seems like you need more than beliefs to explain any course of action they take.
1932716	1935314	251	A	0.99	So there has to be desire in there somewhere.
1935442	1938594	252	A	0.99	So this is an example Andy Clark uses in one of his papers.
1938642	1951606	253	A	1.0	And he know the desire to run in and rescue some item that you want from the house or the desire to claim on the insurance is the thing that's.
1951638	1954538	254	A	0.99986	Going to dictate how you explain the person's behavior.
1954714	1956206	255	A	1.0	So that's the first problem.
1956308	1962590	256	A	0.99995	We need to look at how folk psychology tessellates with prediction.
1962930	1971582	257	A	1.0	And the other problem is maybe a little bit deeper, and that's to ask, how does active inference actually account for agential behavior?
1971726	1979880	258	A	0.99	So can we even tell some story using just predictions and prediction error about what really moves agents to act?
1981130	1988946	259	A	1.0	So firstly, thinking about folk psychology, there's a couple of ways to go here and I think ultimately we can answer this worry.
1989138	1997210	260	A	1.0	So Ryan Smith and colleagues in 2022 in their paper active inference models do not contradict folk psychology.
1997630	2003926	261	A	1.0	They argue that the formalisms of active inference can accommodate a belief desire distinction.
2004118	2012954	262	A	1.0	Now, I'll admit that it's a very math heavy paper and it's a little bit beyond my capabilities, but the claim here is simply that there's no contradiction.
2013082	2018214	263	A	0.92	That actually the worry that the important thing we have in folk psychology is desire.
2018362	2020494	264	A	1.0	And we're not getting that in active inference.
2020542	2022530	265	A	0.92921	This is just an unfounded worry.
2023030	2025042	266	A	0.99998	But there's another strategy as well.
2025176	2034386	267	A	1.0	So Joe Dewhurst, in his 2017 paper, he employs a different strategy and he says, look, what are we even doing with folk psychology?
2034498	2043820	268	A	0.99961	Let's not kind of be too hasty and we need to think about what are we doing when we talk about these propositional kind of states.
2045070	2048842	269	A	0.85	So he says the first option is to say, well, we're just being realists here.
2048896	2058880	270	A	1.0	So when I say that X desires Y, I'm actually positing the real existence as a fine grained mental state in X's head.
2059650	2062430	271	A	0.98	And he thinks that this is actually the wrong way to think about things.
2062500	2067086	272	A	0.99959	He thinks that folk psychology actually it's an instrumentalist tool.
2067188	2074834	273	A	0.96707	It's a kind of framework that we use just for picking out coarse grained behavioral patterns in some useful way.
2075032	2097162	274	A	0.99	So if we agree with Duhurst here and we just become instrumentalists about folk psychology again, it looks as though there's different we're not forced to kind of worry that there's some kind of empirical problem here where the mechanisms of enactive inference are in some sense incommensurable with real properties that we're positing the existence of.
2097216	2103420	275	A	0.99997	Because we're just going to say that those things don't really exist in the way that we've typically assumed that they might.
2104050	2115710	276	A	1.0	So either way, whichever route you go down here, it looks like active inference agents have beliefs and that we're going to be fine in describing motivated action.
2117990	2119940	277	A	1.0	So what about the second problem?
2122870	2126930	278	A	1.0	So Andy Clark in 2020 authored a direct response decline.
2127830	2140390	279	A	1.0	So Clark wants to argue that actually using predictions and prediction errors and precision weighting, which I'll explain in a second, we can get a picture of agential action.
2142830	2153414	280	A	0.98	So the first thing Clark does is to outline the fact that under active inference we have a very nice, well worn account of embodied action.
2153462	2165226	281	A	0.99	So, in other words, what it takes to actually move the body to perform different actions is perfectly folded into active inference under the same kind of computational flow of prediction error minimization.
2165418	2174050	282	A	0.9921	Just in a nutshell, for me to move my arm, what I'm doing is making a prediction that my arm is in someplace and then minimizing the prediction error.
2175510	2182600	283	A	0.99	So once that's on the table, Clark says, OK, that's fine, we have this account of action, but that's not really what Klein means.
2183370	2201510	284	A	1.0	So the move Clark makes is to appeal to the hierarchical nested structure of the generative model and to say that higher level beliefs, which are about temporarily extended future states, these are going to perform a really important role as a kind of controller for lower level actions.
2201670	2226130	285	A	1.0	So the idea is that if I have a high level, temporarily extended expectation to attain a PhD, what happens is that high level belief becomes unpacked at lower levels in the hierarchy, and what you get are more fine grained, faster action policies that the system expects to help support that higher level expectation.
2226550	2242934	286	A	0.98	And there's a mechanism in play here called precision weighting, which applies to prediction error signals, because obviously not all of the predictions we make about the environment are going to be equally important.
2243052	2248890	287	A	0.99945	We're not going to have equal confidence in all of our actions to bring about an expected state.
2249040	2261626	288	A	1.0	And so what precision weighting does is essentially communicate how much confidence we have in a particular action policy to move us into that expected state under perceptual inference.
2261818	2269170	289	A	0.62205	Precision weighting just signals how newsworthy prediction errors are, so how important they are for the system.
2269240	2275566	290	A	0.92	So precision weighting drives attention, for example, when we're talking about predictive processing.
2275678	2291350	291	A	0.9936	But in this case, Clark's claim is that when you have this kind of nested hierarchy of expectations, so you have temporarily extended expectations at the high level, unpacked into a kind of web of lower level action policies.
2291770	2301020	292	A	1.0	And precision waiting is kind of modulating the system's expectations about which of those policies are most likely to bring about the expected states.
2301470	2307178	293	A	1.0	You get something that looks a lot like motivated directed action.
2307354	2321826	294	A	1.0	And agency is kind of inherent in this model because the system rather has to model itself as a cause of those expected states.
2321928	2332598	295	A	1.0	So if I have these high level expectations, I, in a very inherent way, have to model my own causal efficacy to bring about those states.
2332764	2343654	296	A	1.0	So on a very low level, the system has to model some form of agent because I can be the cause of change to my own sensory states, so I can cover my own eyes and so on and so forth.
2343782	2354182	297	A	0.97	So kind of on this view, agency is a latent variable in these systems when it's making these predictions, so it just kind of turns up.
2354336	2363466	298	A	0.69	And Clark argues that you essentially end up with something that looks very much like agents under folk psychology.
2363658	2374206	299	A	0.99894	But he thinks this is a better view because we end up with a, quote, different and arguably much more unified internal architecture trading in a single currency.
2374318	2378910	300	A	0.99	So Clark thinks, look, okay, Klein's worry is we have this one primitive.
2378990	2380718	301	A	0.99977	We have just prediction.
2380894	2384802	302	A	0.99	And the concern is that we're not going to be able to explain agential action.
2384866	2391346	303	A	0.99944	But actually there are ways that we can appeal to the hierarchical structure of the model and precision weighting.
2391458	2395260	304	A	1.0	And it turns out that this is a much more elegant picture as well.
2395950	2407120	305	A	0.99659	But Klein might press the worry, and anybody listening might kind of think, well, we've kind of done some work there, but why do we expect the things that we expect in the first place?
2408530	2415934	306	A	0.99	So why is my long term expectation to attain a PhD and not to join the French Foreign Legion, for example?
2416132	2419300	307	A	0.99942	What means that I expect one thing rather than another?
2419750	2425380	308	A	0.99	And here Clark just bites a bullet and says, nobody can explain that.
2425750	2431314	309	A	0.77161	We've kind of shifted to talking about questions, know, spookier questions about free will.
2431432	2450220	310	A	1.0	And Clark says, look, if this is what you want, if this is what you're demanding, then you have to recognize that simply appealing to folks psychology doesn't get you that, know, people with these kinds of worries need to be careful in how much they demand from the active inference agent.
2450830	2460942	311	A	1.0	And I think the real answer to that question actually, this is more speculative, but the real answer to a deeper answer to these kinds of questions will lie in the kinds of things that we're going to look at in subsequent weeks.
2461076	2481640	312	A	1.0	So, for example, the reason I have the expectation to attain a PhD rather than join the French Foreign Legion is because I exist in a particular kind of sociocultural landscape with specific norms, and a lot of my actions and beliefs are tempered and shaped by the expectations of people around me.
2483370	2485110	313	A	1.0	So this is just an overview.
2485530	2487560	314	A	0.99999	We went over the dark room problem.
2488490	2497478	315	A	0.99999	Why do we do anything at all if it's all about certainty and prediction error minimization this worry?
2497574	2502070	316	A	0.87	I said you can kind of highlight two aspects of this worry.
2502150	2506718	317	A	1.0	One is an actual account of agency under active inference, which we have.
2506804	2516106	318	A	0.99931	We have this Andy Clark model of agency to do with hierarchical nested, unfolding action policies over time and different precision mappings.
2516298	2519806	319	A	0.99	And then we have this worry about the relationship with folk psychology.
2519918	2526254	320	A	1.0	So how do we describe agential behavior and motivated behavior?
2526302	2531970	321	A	1.0	How do we describe the behavior of agents if we only have recourse to prediction?
2533990	2543010	322	A	1.0	And as we saw, there's one argument here is that actually active inference, the formalisms can accommodate this belief desire distinction.
2543170	2548890	323	A	1.0	And the other move that I really like is to just say, look, folk psychology is just this instrumental tool.
2548960	2561258	324	A	0.96999	It is, in effect, it's part of the sociocultural landscape that we use to shape each other's expectations by putting these labels to explain our actions.
2561434	2563760	325	A	0.49154	This kind of form of active inference itself.
2564690	2580920	326	A	1.0	So there's this kind of philosophically interesting debate about folk psychology, but it turns out that everything's okay and active inference agents are in fact agents with beliefs, desires and hopes and dreams and so on.
2582410	2583206	327	A	1.0	Okay?
2583388	2584630	328	A	0.63752	That's agency.
2585770	2587240	329	A	0.9998	We're making good time.
2591290	2591750	330	A	1.0	Okay.
2591820	2602554	331	A	1.0	So in this section I'm going to introduce quite a lot of stuff, but it's going to be all tied together hopefully rather neatly in the case study.
2602592	2606074	332	A	1.0	At the end, I'm going to talk about allostatis and emotion.
2606202	2610960	333	A	0.54704	I'm going to say very briefly a little bit about the self as well.
2612930	2615694	334	A	0.9961	Here's some examples of some of the core readings I've used.
2615732	2619940	335	A	0.99999	Again, these are all going to be up in the document as well, which will be made available.
2620630	2623922	336	A	0.96	And I thoroughly advise you to just have a browse through these.
2623976	2626020	337	A	0.99662	There's some really interesting stuff there.
2626470	2641810	338	A	0.99951	I'm not going to talk about psychedelics or meditation or depersonalization, but there is some really cool active inference literature on those topics as well, particularly papers on psychedelics and ego dissolution by George Dean.
2641970	2651194	339	A	0.88	A new paper just came out by inezito Jonas Mago and Robert Carhartt harris and I think Fernando Rosas as well.
2651232	2655520	340	A	1.0	I think I might be mistaken on the authors there, but it's a very new paper.
2657170	2657630	341	A	0.63	Okay?
2657700	2665310	342	A	1.0	So the thing that is going to underpin a lot of what I'm now going to go on to say is going to be this notion of allostatis.
2666770	2673550	343	A	0.99	And this plays a major role in a lot of work on emotion and the self in active inference.
2673710	2688770	344	A	0.84015	Lisa Feldman Barrett, whose theory of emotion we're going to look at in a second, has argued that the brain's fundamental purpose, what it evolved to do through that imperative to minimize prediction error, is to manage the body's metabolic budget.
2688850	2694620	345	A	1.0	So the first prior is kind of our most expected state.
2695230	2706158	346	A	1.0	The first prior in the sense of our strongest prior probability, our highest expectation is to have good allostatic control.
2706244	2707662	347	A	0.99898	But I'm getting ahead of myself there.
2707716	2714560	348	A	1.0	All that means is that we're balancing our body's metabolic budget, our energy budget, in an effective way.
2714930	2722718	349	A	1.0	So error signals, like I said before, that are highly precise are those that are weighted very highly.
2722894	2740600	350	A	1.0	So prediction error signals that have high precision weighting are the synaptic gain on those error signals is going to be increased and that's going to drive learning, which means in future our expectations around those kinds of error signals is going to be we're going to pay more attention to those.
2741710	2751306	351	A	1.0	And the most highly weighted error signals that we're going to get are to do with our own homeostatic set points within our own body.
2751488	2768354	352	A	1.0	So if my temperature started to rise rapidly, my body temperature started to rise or drop rapidly, that prediction error signal, the violation of those expectations is really going to grab my attention and I'm going to do something about it.
2768552	2776398	353	A	1.0	And one way that we maintain these homeostatic states is through the body's own autonomic reactions.
2776574	2781874	354	A	0.8	So were I to start getting very cold, I would probably start to shiver.
2782002	2788760	355	A	1.0	And so the body is trying to kind of rectify those deviations from homeostatic set points.
2789450	2796694	356	A	0.99997	But another thing that organisms engage in, and humans do this to really remarkable degrees.
2796742	2809850	357	A	1.0	And again, this is going to be something that I suspect is going to come out in the subsequent weeks, is that we engage in quite complex and sophisticated anticipatory actions to maintain homeostasis.
2809930	2812350	358	A	1.0	And this is something called allostasis.
2812930	2822686	359	A	1.0	So allostatic control, which I mentioned earlier as this first prior, is essentially the regulation of homeostasis through action.
2822798	2829002	360	A	1.0	So it's actions that I can take to ensure that I stay within those important bounds.
2829086	2835400	361	A	0.99	So shivering is good, but living in a house with central heating is better.
2836090	2849580	362	A	1.0	Having a warm bed and living in a community where we've had these people of kind of engineers have worked to create a kind of material environment that acts as a kind of background support to a lot of these needs.
2851230	2855274	363	A	0.99995	Something that's another important concept here is allostatic load.
2855402	2859966	364	A	1.0	So this is essentially the result of not having good allostatic control.
2860068	2873186	365	A	1.0	So again, allostatic control is just engaging effectively in actions that are maintaining those set points, whereas allostatic load is the physiological costs to the agent of losing that control.
2873368	2885286	366	A	1.0	So there's so many studies here that have just shown the immense physiological costs of operating beyond those set points and not having good control.
2885388	2898730	367	A	1.0	So allostatis load has been linked with reduced cardiac health, sleep problems, gut issues, mental health issues, depression, basically everything.
2898800	2908480	368	A	0.85326	It's really bad and so good allostatic control is very important and as we're going to see, it underpins quite a few very important things.
2911250	2921458	369	A	0.77	So really we could dedicate a whole hour to looking at emotion, but I'm going to blast through it very quickly right now.
2921544	2933030	370	A	1.0	And this slide, I should say one of the core readings on the document and the reading that I'm basing this on is Lisa Feldman Barrett's 2017 paper, the Theory of Constructed Emotion.
2935450	2944220	371	A	1.0	The main idea here is this is one of those theories that on the face of it, it seems quite simple, but actually there's quite a lot of subtlety and nuance to it.
2944830	2950730	372	A	0.60073	Allostatis control means inferring the causes of changes to the body's internal state.
2950880	2961038	373	A	1.0	So in other words, if I want to keep good allostatic control, I need to know not just what's going on out there, but I need to know what's going on inside me as well.
2961124	2961422	374	A	0.89	Okay?
2961476	2965406	375	A	1.0	So if there's some crucial change happening, I need to be on top of it.
2965508	2974242	376	A	1.0	And this happens through exactly the same process as the same enactive, error, minimization process that I'm engaging with with the outside world.
2974376	2985026	377	A	1.0	So the brain is making predictions about its own internal states and then it's going to engage in some kind of action to minimize any prediction errors.
2985138	2987730	378	A	1.0	And these prediction errors are going to be very highly weighted.
2987810	2988840	379	A	0.99995	They're very important.
2989770	2991990	380	A	0.99991	But here's an interesting thing.
2992060	3009594	381	A	1.0	So there was a very unethical experiment done by Shaktor and Singer, I think in the 60s, who they were emotion researchers and they conducted an experiment where they injected subjects without the subject's knowledge.
3009642	3018494	382	A	1.0	I think they injected them with adrenaline and then they exposed the subjects to different stimuli.
3018622	3024146	383	A	1.0	So some subjects were exposed to one type of stimulus and some subjects were exposed to another.
3024328	3042906	384	A	1.0	And even though the subjects had essentially been they'd been pushed to have the same, to experience the same physiological changes in their body, they reported different emotional like different kinds of feelings depending on the stimulus that they'd been exposed to.
3043088	3046058	385	A	1.0	So this highlights something really important.
3046144	3050938	386	A	1.0	And again, I feel compelled to say that I am moving through this incredibly quickly.
3051024	3052940	387	A	0.91218	There's so much to say here.
3053390	3073102	388	A	0.99956	But the nub of it is this in order to keep good allostatic control, in order to know what to do, the brain needs to contextualize those changes in the body because there's not a one to one mapping between changes in the body and an external stimulus.
3073246	3080340	389	A	1.0	So sometimes changes, physiological changes in our body are about something in the world, they're a response to something.
3081030	3091782	390	A	0.74	And it's very, very important that the brain is kind of taking a confluence of those inputs to try and contextualize, okay, what's actually happening and what do I need to do?
3091916	3103130	391	A	0.99	So an example of this is if you imagine running into a bear while you're hiking in Wyoming, which is something that's actually happened to me, I've experienced it, it's terrifying.
3103630	3108240	392	A	1.0	And you imagine going on a scary or a date that you're really nervous about.
3109570	3115678	393	A	1.0	The physiological changes that are happening in the body are, give or take, more or less the same.
3115764	3120820	394	A	1.0	So perspiration, elevated heart rate, breathing changes.
3121990	3125938	395	A	1.0	So the underlying physiological footprint is very similar.
3126104	3131958	396	A	0.99998	But what you need to do to manage that situation, that apt action is very, very different.
3132124	3145226	397	A	1.0	And so the claim here, the kind of revolutionary claim in a way is that emotions, the things we experience subjectively are constructions, just like percepts are.
3145328	3156366	398	A	0.69	So just like my experience of the car when I step outside my flat is a construction that explains away the prediction error and gives me a cleaned up picture of the world.
3156548	3158494	399	A	0.8843	Emotions are essentially doing the same thing.
3158532	3170062	400	A	0.91311	They're explaining away these prediction errors and telling me this is the best explanation of these changes within your body contextualized against this external stimulus.
3170126	3178398	401	A	1.0	So in the case of the date, apt action is to chill out and be normal to a certain extent.
3178494	3181650	402	A	1.0	And in the case of the bear, you get the hell out of that.
3181720	3183342	403	A	0.97107	Although interestingly, you don't.
3183406	3185480	404	A	0.99998	Running away from a bear is a terrible idea.
3185850	3193340	405	A	0.99999	You should not turn your back and run away but you get the idea that it's going to be what you should do in each situation is completely different.
3194990	3212414	406	A	1.0	So that's emotion for the active inference agent and something I don't want to lose here is what you get with this is really kind of cool because it turns out emotions and subject we're kind of moving into subjectivity here.
3212532	3219534	407	A	0.99998	It turns out emotions are really they're just part of the same cognitive architecture.
3219582	3220994	408	A	1.0	So there's no difference here.
3221032	3224814	409	A	0.9999	There's no dualism between here's thinking and here's emotion.
3224862	3229798	410	A	1.0	And emotion is this kind of fuzzy stuff that we're not really interested in.
3229884	3235218	411	A	0.79171	Actually emotion, subjective embodied feeling is core.
3235314	3248550	412	A	0.73953	It's absolutely vital to understanding how we maintain this allostatic control and how we engage in adaptive behaviors and how we remain gripped to our affordances in the environment.
3248630	3252620	413	A	1.0	And the notion of grip is going to be something that comes up again very soon.
3255870	3263520	414	A	1.0	So very briefly, because this is something that I've really already talked about, but I want to put a slightly different spin on it right now.
3264930	3271726	415	A	0.88981	I've already said that allostatic control for humans can involve very temporarily extended scales.
3271758	3275246	416	A	0.99	And we saw this with Andy's model of agency.
3275438	3292040	417	A	0.99	So if you think about something like saving into a retirement fund, for example, we're doing something that the idea is that maybe decades from now is going to kind of minor spikes in prediction error or the disappointment of not having as much money right now is going to pay off later.
3292410	3295322	418	A	0.99991	These are the kind of things that humans engage in.
3295456	3298810	419	A	0.98	And our generative models have to be temporally thick.
3299230	3304646	420	A	0.98	So George Ben white that the levels of temporal extension are hierarchically interlocked.
3304758	3310738	421	A	0.99	So shorter scales inform expectations of what the agent can do over longer scales.
3310854	3320020	422	A	1.0	So these different levels of the hierarchy are in a kind of dialogue with each other telling you what kinds of things are possible and what kinds of things you should expect.
3320630	3328638	423	A	1.0	And when we were talking about agency, we talked about the way that agency is kind of baked into active inference.
3328814	3336360	424	A	1.0	Because in order for any of this to work, the system has to have as a hypothesis, I can do things okay?
3337130	3346890	425	A	1.0	And this is more or less taken to be the same thing that underpins the sense of self under active inference.
3347310	3353570	426	A	0.99	So the system implicitly infers its own ability to bring about intended sensory consequences.
3353750	3365070	427	A	0.99	And so Dean writes here, quote in Pristine it is in this sense that implicit in a model of sampling is a representation or sense of agency.
3366230	3373090	428	A	0.82	So a minimal sense of self, it's kind of like the flip side of agency comes baked in here.
3373160	3381362	429	A	0.87	So one has to model oneself as a potential cause of sensory inputs.
3381506	3392860	430	A	0.98	So George Dean and colleagues, I think George Deane, Mark Miller and Sam Wilkinson propose a model of the self under active inference called the allostatic control model.
3393870	3402598	431	A	1.0	And the move they make here is that we have to recognize that it's not just our self efficacy that has to be modeled.
3402694	3407822	432	A	0.78667	We also have to have some kind of idea in there of how we're actually doing.
3407876	3413390	433	A	1.0	So we have to model our own capabilities in order to set precision weighting on future action.
3413890	3424094	434	A	0.63	So we don't simply infer that we can be the cause of sensory states, but also infer our own capabilities to successfully bring about expected states at longer timescales.
3424222	3431014	435	A	1.0	So the phrasing that they use is tracking the performance or fitness of the model over time.
3431212	3439106	436	A	0.97	So part of that tracking is going to be affective and emotional.
3439218	3441070	437	A	0.73	And so there are strong links.
3441170	3444460	438	A	0.68322	We're kind of really digging our hooks into subjectivity at this point.
3446830	3470660	439	A	0.57184	But the claim with the Allostatic Control model is you get this rather than just a minimal self, you actually get a longer term phenomenological self emerge from these interlocking timescales, which are modeling not only the agent's own causal efficacy, but also modeling how good your own model is at doing what you need it to do.
3471830	3482054	440	A	1.0	And like I said, I said when I was talking about the reading and I want to flag this again because I'm really not doing justice to this in the way that I should.
3482172	3500406	441	A	0.99999	But this has formed the basis for a lot of really interesting work on phenomena like depersonalization on the role of psychedelics and the potential for psychedelics in therapy and in meditation, ego dissolution and kind of that kind of stuff in meditative settings.
3500518	3511870	442	A	1.0	So anybody with any interest in the self or in those kinds of practices should definitely go and give a closer look to these readings that I'll make sure in a document.
3513730	3516000	443	A	1.0	Okay, so quick overview here.
3516390	3524020	444	A	1.0	So active inference agents maintain homeostasis through anticipatory action, and this is something we call Allostatic Control.
3524390	3530662	445	A	1.0	To do this, the system must engage in interceptive prediction over its own internal states.
3530796	3535186	446	A	0.95	And actually, I think I've got time to do this, so I'll just deviate slightly.
3535378	3541518	447	A	0.67	The topic of interceptive inference is really interesting in the context of active inference.
3541634	3548278	448	A	0.96	So I want to flag work by Sarah Garfinkel, who I believe is at UCL, who used to be at Sussex.
3548454	3565882	449	A	0.95	And Professor Garfinkel's work looks at the central importance of interceptive predictions in various psychopathologies especially, I think she's looked very closely at PTSD and anxiety disorders.
3566026	3582470	450	A	1.0	And it turns out that an agent's accuracy in their interoceptive predictions is a good indicator as to the kinds of symptoms that they're going to like, the strength and severity of their symptoms in these kinds of disorders.
3583130	3594214	451	A	1.0	And what she's shown is that if you can increase the accuracy of interceptive predictions, this forms the basis of treatment for these symptoms.
3594262	3598886	452	A	1.0	So in short, the better you are at interceptive predicting.
3599078	3607514	453	A	1.0	I think one of the measures that they use there in herlab is how well people can track their own heartbeats without feeling their pulse.
3607562	3618430	454	A	1.0	So if you just sit there and try and say like, my heart's beating like this, then the more accurate you are and the more any training you can be given to be more accurate.
3618590	3623198	455	A	0.99741	It forms the basis of effective treatments for these kinds of symptoms.
3623374	3636680	456	A	1.0	So I just wanted to flag that because the world of research in enactive inference large, diverse, vibrant, super interesting and very much worth our time.
3637610	3638694	457	A	0.86	Okay, where was I?
3638732	3639270	458	A	0.99966	Here.
3639420	3639782	459	A	0.99	Okay.
3639836	3646266	460	A	1.0	So to maintain allostatis control, the system has to engage in interceptive prediction over its internal states.
3646448	3663082	461	A	1.0	And then to best explain changes in those internal states, the system has to contextualize those changes against some extraceptive input and that emotion categories serve that role.
3663146	3668050	462	A	0.96	So just to be very clear, on this view, emotions are constructions.
3668550	3678210	463	A	0.99997	There are some important deviations from other theories of emotion here, particularly what Barrett calls the basic theory of emotion.
3678810	3685714	464	A	1.0	So on her view, emotions themselves have no underlying kind of essence or neural footprint.
3685842	3690150	465	A	0.64	And there's an ongoing live debate there as well between these theories.
3693800	3703504	466	A	0.95	And also just at the end, the good allostatic control in human agents is this very temporally thick phenomena.
3703552	3711976	467	A	1.0	So we engage in very long term planning that involves a lot of the kinds of counterfactual representations that we talked about with the Axel Constant paper.
3712158	3725770	468	A	0.99	And this is hypothesized to form the basis of our phenomenological sense of so, okay, we're up to an hour.
3726220	3726824	469	A	0.99986	Good.
3726942	3728410	470	A	0.99732	We're running on time.
3729340	3735100	471	A	0.99943	This is the final section and it's probably going to be probably going to be the longest section.
3735260	3750196	472	A	0.99996	What I want to do here is I want to try and pull together some of the things I've been talking about because it's been very fast and very abstract and I want to try and pull some of these things together in a slightly more concrete example.
3750298	3752960	473	A	1.0	So the case study I'm going to use is addiction.
3753120	3768490	474	A	1.0	So there's a particular account of addiction in the predictive process in literature that I think in a very succinct, sharp way highlights a lot of the things I've been talking about and puts them within a context that is quite stark and easy to understand.
3769680	3781740	475	A	0.99997	But in order to do that, I'm going to have to introduce a new, slightly more difficult to understand mechanism within the framework that crops up in a lot of the predictive processing literature.
3781900	3787836	476	A	1.0	And what this is going to do, hopefully as well, is give us a direct bridge to phenomenology.
3787948	3800870	477	A	0.78	So when we talk about things like neurocomputational phenomenology, the things I'm going to be talking about here have underpinned a lot of the work in that area.
3802440	3808836	478	A	0.99	So these are some of the readings we're going to look at some work by mostly a lot of the papers.
3808868	3814468	479	A	0.99907	We're going to look at first author, Mark Miller, or Mark Miller's been second or third author.
3814564	3826072	480	A	1.0	And I bring that up because in the discussion section on the 25th, when we have an hour to kind of unpack and answer people's questions, we're actually going to be joined by Mark Miller.
3826136	3830044	481	A	1.0	So if anybody has any specific questions about the things I'm going to talk about.
3830082	3842130	482	A	0.86	Now in this section, he's going to be the man to answer those, but also I'm going to put a lot of secondary readings up again in the document so you'd be able to find them all there.
3843400	3844004	483	A	1.0	Okay?
3844122	3848660	484	A	1.0	So let's suppose switch gears slightly.
3850520	3860808	485	A	1.0	I want to keep the focus on feelings, although what I'm going to be talking about here are not what might be called like full blooded emotion states.
3860974	3863924	486	A	0.99998	But I want to talk about something a little bit more subtle.
3864052	3878284	487	A	1.0	So one thing that might seem really obvious, kind of so obvious that we often overlook it when things are going okay, is that it generally feels like something to be an agent.
3878482	3890352	488	A	1.0	So when we're going about whatever business we have in the world, we always feel like something, and it's not entirely clear how best to characterize that.
3890406	3900004	489	A	1.0	So I want to draw on some work in phenomenology that some active inference theorists have also drawn on and made use of.
3900122	3905510	490	A	0.9999	Because I think this is a really good grounding for some of the things I'm going to go on to say.
3905960	3910280	491	A	0.99952	Certainly proved to be a good grounding for some of the work that I'm going to highlight.
3910620	3929160	492	A	0.99	So these are two books by Matthew Ratcliffe, who I think is at the University of York and has done really cool work in kind of really getting to grips with the what it's likeness to live in certain conditions.
3929320	3944260	493	A	0.96	And Ratcliffe, he argues that he's identified this certain area, this space of feelings that have been largely neglected in the wider literature, and he describes these as existential feelings.
3944760	3957912	494	A	1.0	So he says existential feelings are, quote, they are not intentional states directed at however many objects, and they are not feelings of the body or some part of it.
3958046	3961480	495	A	0.99999	Instead, they amount to a felt sense of belonging in the world.
3961630	3970332	496	A	0.61	So the main difference between a full blooded emotion state and an existential feeling is that the emotion state is about something.
3970466	3970812	497	A	0.53	Okay?
3970866	3978412	498	A	1.0	So if I'm disgusted, I'm typically all the time I'm disgusted about something in the world.
3978546	3980930	499	A	1.0	So emotions are intentional in that way.
3982340	3989744	500	A	0.41552	Radcliffe elaborates on existential feelings by I'm going to quote this at length because I quite like it.
3989782	4017210	501	A	0.99192	He says people sometimes talk of feeling alive, dead, distant, detached, dislodged, estranged, isolated, otherworldly, indifferent to everything, overwhelmed, suffocated, cut off, lost, disconnected, out of sorts, not oneself, out of touch with things, out of it, not quite with it, separate, in harmony with things, at peace with things.
4017520	4036050	502	A	0.99738	There are reference to feelings of unreality, heightened existence, surreality, familiarity, unfamiliarity, strangeness, isolation, emptiness, belonging, being at home in the world, being at one with things, significance, insignificance, and the list goes on.
4036820	4044476	503	A	0.77	So this is really cool work, and I recommend everybody to go and read Matthew Ratcliffe.
4044508	4050228	504	A	0.99752	But some of the work I really like in Predictive Processing and Active Inference has taken this idea of.
4050234	4051328	505	A	0.99981	An existential feeling.
4051344	4060376	506	A	1.0	And what they've recognized is that these kinds of feelings are really about how we are orientated in regards to the world and the affordances in it.
4060398	4064484	507	A	1.0	So they're background bodily states of action readiness.
4064612	4071612	508	A	1.0	So how are we relating to how do we find ourselves in relation to the world?
4071746	4077352	509	A	1.0	So we're talking about the general structuring that's present in our everyday phenomenology.
4077496	4090930	510	A	0.99	So I really want to make that clear that what this work is doing is building a bridge between computational models and the way even the underpinnings of those models in neurobiology and phenomenological experience.
4092660	4101488	511	A	0.75	So the thing that I need to introduce, and this can be, it's fairly straightforward, but it can be a little bit tricky at times, is this notion error dynamics.
4101664	4103030	512	A	0.78909	This is really important.
4103400	4120424	513	A	1.0	So like I just said, aerodynamics is going to provide this conceptual bridge between different levels of analysis and it elaborates on how systems are sensitive to the success or failure of their own action policies unfolding across multiple timescales.
4120552	4138160	514	A	1.0	So the recognition here is that we talk a lot about action policies and expected states, but the reality is that we have a multitude of goals and action policies and expected states that are interlocking, overlapping, constantly shifting.
4138580	4140124	515	A	1.0	The picture is messy.
4140252	4154416	516	A	1.0	And so I like this quote from the 2019 paper that says the roller coaster of continual increases and decreases of errors that accompany life become expected and are folded into our expectations.
4154608	4166468	517	A	0.72643	For such a system it becomes important not only to track the constantly fluctuating instantaneous errors, but also to pay attention to the dynamics of error reduction over longer timescales.
4166644	4182428	518	A	1.0	So the systems, the upshot of this is that these authors believe, building on some other work in computational modeling, that systems must track the rate of change in overall error reduction relative to the system's expectations.
4182604	4189804	519	A	0.97	So this is the kind of global upwards or downwards trend in prediction error.
4189932	4194980	520	A	0.99999	That's what the system is sensitive to, how that relates to the expectations.
4196920	4209544	521	A	1.0	So the idea here is that aerodynamics provide a system with a much broader ongoing sense of how they're doing to their multitude of goals over time.
4209742	4217572	522	A	1.0	So a big step here is that those changes in the rate of reduction feed back into the system.
4217646	4224472	523	A	1.0	So they're folded back within the system and they serve the role of modulating precision on action policies.
4224616	4228664	524	A	1.0	So let's say I'm engaged in some task.
4228792	4232892	525	A	0.55	I have a particular expectation about how I'm going to do at that task.
4233036	4237360	526	A	1.0	And when I actually engage with the task, I do slightly worse than expected.
4238340	4249648	527	A	1.0	The idea there is that that rate of change, so the rate of error reduction is going to decrease until I'm reducing error worse than my expectations.
4249824	4259284	528	A	0.58	And in a typical healthily functioning system, that rate of change, the sensitivity to that rate of change is going to feed back and reset the precision weighting on those actions.
4259332	4273900	529	A	1.0	So it's going to reduce my confidence in that particular action policy such that I might try a different strategy, I might try a different tactic, or I might just throw whatever it is that I'm doing away and go and do something else.
4273970	4283492	530	A	1.0	So we're starting to see this picture of through expectations, sensitivity to change and feedback onto precision waiting.
4283656	4289100	531	A	0.98279	It's starting to dictate how I manage my action policies.
4289260	4295300	532	A	1.0	So there's this ongoing reciprocal relationship between aerodynamics and my future expectations.
4295640	4305204	533	A	0.55	Now, crucially, the claim here is that on the subject level, all of this manifests as these existential feelings of some kind.
4305322	4315204	534	A	0.69	So the way that I feel on a kind of day to day basis is a reflection of how I'm doing in terms of these sensitivity to aerodynamics.
4315332	4331808	535	A	1.0	So when I fail at the task and precision weighting is down regulated on that particular action policy, the thing that actually kind of oomph that moves me to go and do something else are my embodied feelings of frustration that I experience.
4331974	4339680	536	A	1.0	So as conscious agents, those embodied feelings are what are tuning us towards acting more effectively.
4340900	4348864	537	A	1.0	So optimal behavior on this account is characterized as a feeling of grip towards a shifting field of affordances.
4348912	4350484	538	A	1.0	So I'm going to unpack this quickly.
4350602	4367760	539	A	0.97684	But the feeling of grip in a nutshell is just this feeling that we're engaging with our affordances in the best way that we can and that we're either meeting or exceeding our expectations for prediction, error, minimization what they mean by a field of affordances.
4367860	4370350	540	A	0.99	And this is again really important.
4371360	4375656	541	A	0.94	A landscape of affordances is just the total opportunities in my niche.
4375768	4379448	542	A	1.0	So my landscape of affordances right now is Brighton.
4379624	4384050	543	A	0.72482	It's not really going to change very quickly unless I get on a plane and fly somewhere else.
4384900	4388144	544	A	0.99999	But affordances aren't neutral in that way.
4388182	4390370	545	A	1.0	They don't just exist there.
4391060	4403044	546	A	0.88	The affordances that stand out to me as relevant or attractive is going to change quite rapidly depending on what it is I'm doing, on my internal state, on the context and so on.
4403082	4409636	547	A	1.0	So right now my water bottle stands out as attractive, a couple of keys on my keyboard stand out as attractive.
4409748	4414312	548	A	0.99994	But that's going to shift quite rapidly once this lecture is over and I turn to do something else.
4414446	4425470	549	A	1.0	So the idea of grip is that we exhibit a stability in our attunement such that we can remain attuned as that field changes.
4426400	4439840	550	A	1.0	And this is part of the skilled intentionality framework which I won't get into because I don't want theoretical overload, but I've put some papers up on this slide as references and of course the reading will be in the document.
4440340	4449684	551	A	0.99966	But skilled intentionality refers to the enactive, openness and responsiveness to multiple relevant affordances in a concrete situation.
4449882	4460600	552	A	1.0	So it's just this recognition that things change quickly for multiple reasons and we really need to exhibit a kind of flexibility and stability in those engagements.
4461820	4467064	553	A	1.0	And aerodynamics has been applied in lots of very, very cool ways.
4467182	4469790	554	A	0.99	I can't recommend this work highly enough.
4470240	4479260	555	A	1.0	So aerodynamics, I won't run through how everything has been explained just for time reasons, but you can kind of take a look at this yourself.
4479330	4496416	556	A	0.99978	But aerodynamics has been proposed as a more complete answer to the dark room problem that we were talking about earlier, because it can explain the drive for exploration and curiosity, because it literally feels good to minimize prediction errors better than expected.
4496528	4500464	557	A	0.99	So again, that rate of change manifests as embodied feeling.
4500592	4505520	558	A	0.99	So we're always looking for opportunities to do better than expected.
4505680	4512632	559	A	0.99	And kind of this has been suggested to account for feelings of boredom, prompting us to go out and find new things to do.
4512766	4529516	560	A	0.99	And similarly, aerodynamics has provided a computational account of play, which for a while has remained a kind of mystery because it's on the face of it like, why would we engage in play when it's metabolically costly and we need that energy for other things?
4529618	4533488	561	A	0.97882	Like Lisa Feldman, barrett says managing energy is super important.
4533654	4536476	562	A	0.99	So why do baby animals burn?
4536508	4539440	563	A	0.99965	It all engaging in playful behavior.
4539940	4543010	564	A	0.65904	Aerodynamics has a story for us there.
4543460	4550388	565	A	0.98	And there are also aerodynamics based accounts of happiness and wellbeing and depression as well.
4550474	4552132	566	A	1.0	So I won't go into the details there.
4552186	4568110	567	A	0.99994	But it turns out that aerodynamics and this connection to phenomenology is this super malleable, flexible kind of feature of the framework that really underpins a lot of what we experience and do as active inference agents.
4569680	4576650	568	A	0.99	Okay, so I'm going to talk a little bit about addiction.
4578750	4579754	569	A	0.99998	Got some time here.
4579792	4593246	570	A	0.99998	Things are going well, so I take so I had some options here because I wanted to use a case study that really brought out some of the things I was talking about.
4593348	4600562	571	A	1.0	And as I've just said, aerodynamics has been applied in a bunch of different areas and it's all very much worth talking about.
4600616	4624860	572	A	0.91407	But I chose addiction because, well, as you'll see, as I kind of make clear, I think it also brings out not just the way that all of this fits together, but also why it's good and why seeing people as active inference agents and broader structures as active inference structures is actually a worthwhile thing to do.
4625230	4629750	573	A	0.83	So addiction was once viewed as a moral failing.
4629910	4636190	574	A	1.0	So the kind of Victorian addict is too rotten to make the right choice, too self indulgent.
4636530	4642000	575	A	1.0	I say Victorian unless you're Peter Hitchens and then you still subscribe to this view.
4642930	4644718	576	A	0.99854	But that's the old fashioned view.
4644804	4652980	577	A	0.93395	There was something wrong with the addict, some moral or spiritual failing, and gradually that changed to what the dominant view is today, which is the disease model.
4653670	4671606	578	A	1.0	And the idea here is that addiction is a disease and that disease is characterized by changes in the brain, which changes to brain structures, which mean the addict can't help but act in a certain way when confronted with a certain stimulus.
4671718	4677062	579	A	1.0	So it's this loss of control that's engendered through these brain structures.
4677206	4680650	580	A	1.0	And this is the idea of it being a disease.
4683090	4700274	581	A	1.0	The work that I'm going to describe now, I won't go into too much detail here, but it's kind of founded on this thought that this disease model, it can't be quite right because these changes in brain structure, essentially that's what the brain does.
4700472	4701906	582	A	0.99991	It's just learning.
4702088	4703794	583	A	0.97977	This is what we do all the time.
4703912	4716440	584	A	0.99999	Essentially, me completing my PhD is a process of me undergoing changes to my brain such that I'm kind of disposed to act in certain ways.
4719050	4728234	585	A	1.0	I think it's mark Lewis in his book 2018 The Biology of Desire, argues, look, addiction is more of just a dysfunction in learning.
4728352	4730090	586	A	0.99987	It's not really a disease.
4730430	4734138	587	A	1.0	So we need to think about it a little bit differently.
4734314	4740542	588	A	1.0	And this work by Miller and colleagues, 2020, that's where it picks up.
4740596	4740862	589	A	0.96	Okay?
4740916	4747454	590	A	1.0	So the idea is that those brain changes engendered through exposure to a stimulus.
4747502	4749726	591	A	1.0	In this case we're going to talk about a drug.
4749838	4754958	592	A	0.64561	We're going to leave behavioral addiction aside for a second that clearly plays a critical role.
4755054	4764546	593	A	0.96	So nobody's going to deny the kind of chemical, the importance of the biology here that's going on in the brain.
4764578	4768374	594	A	1.0	And of course, different drugs have different chemical profiles in that regard.
4768572	4781222	595	A	0.99999	But on this view we're going to kind of shift focus from that slightly and we're going to have a much more active picture where we view addiction as a self organizing process of whole agent environment systems.
4781286	4791150	596	A	0.97	Okay, so I have this extract here it is in the dynamic interaction between the agent and its environment that addiction is born and endures.
4791490	4802354	597	A	1.0	So the harm of addiction emerges from a breakdown in the broader stable dynamics that typically underpin a flourishing life work, family, friends, health, and so on.
4802472	4811090	598	A	1.0	So a typically flourishing life has a broad kind of bush of concerns over different timescales in different areas.
4811250	4816630	599	A	1.0	And what we're going to see is that the harm of addiction is in a narrowing of those concerns.
4819470	4837946	600	A	1.0	So what happens is when somebody takes a drug to some people who are exposed to drugs, that drug is going to, through direct action on some neural mechanisms, is going to signal to the agent that they've done better than expected at reducing prediction error.
4837978	4839482	601	A	1.0	Of course this is a losery.
4839626	4842938	602	A	0.99999	They haven't really done better than expected in anything that matters.
4843034	4864226	603	A	0.99913	But the signal they get is, wow, like we have just reduced prediction error at this insane rate and repeated use through this aerodynamics mechanism, repeated use is going to tune our expectations about the kinds of prediction error slopes, the kind of slopes of prediction error that are available to us in the environment.
4864338	4871830	604	A	1.0	And we're going to start to expect those vertiginous slopes of error reduction if we continue to engage with the drug.
4871990	4880086	605	A	1.0	And once those expectations become deeply ingrained, anything else we do is going to start to feel like failure.
4880198	4880570	606	A	0.53	Okay?
4880640	4894720	607	A	1.0	So if I get used to taking cocaine all the time and then I have to sit through a family meal where I don't have any drugs and I have to kind of sit still and there's no dopamine available, I don't have my phone.
4895490	4902994	608	A	0.94063	I'm going to experience that as feelings of frustration and as if I'm being prevented from doing something I want to do.
4903192	4906766	609	A	1.0	And I'm going to experience that as doing worse than expected.
4906878	4914050	610	A	1.0	So I've learnt these expectations for prediction error minimization and I'm not getting them unless I engage with the drug.
4914130	4922534	611	A	1.0	And of course it's worth noting that in many cases these drugs are going to have chemical withdrawal effects that compound that as well, especially things like nicotine.
4922582	4924806	612	A	1.0	And alcohol in particular is very nasty.
4924838	4929002	613	A	1.0	So alcohol can kill you if you try and withdraw from it too quickly.
4929056	4932906	614	A	1.0	So they really do pull the agent into a grip.
4933098	4937130	615	A	1.0	So what happens here is the agent develops a kind of suboptimal grip.
4937290	4942330	616	A	1.0	So you start to enact a new world, a new identity.
4942410	4958194	617	A	1.0	So instead of doing all the things you once cared about, like different hobbies, you start to hang out with different people, you start to frequent different places like a dealer's house or wherever, and very slowly you start to carve out essentially a niche.
4958322	4965650	618	A	1.0	The addict enacts a particular niche through their actions and they have quite a good grip on that niche.
4965730	4970090	619	A	0.98634	It's just that it doesn't speak to a broader array of concerns.
4970750	4986590	620	A	1.0	So what's really important is that this pushes back against the disease model because on this view, the active inference agent, well, the system is doing essentially what it was evolved to do.
4986740	5002946	621	A	0.99	So there's another quote from the paper here that I like that says their habits allow them to remain well attuned and keep prediction errors under tight control so long as they remain within the narrow confines of such a that.
5003128	5010342	622	A	0.95	And this is important because it shows that allostatic control and prediction error minimization are not the same thing.
5010396	5011154	623	A	0.99948	They come apart.
5011202	5019626	624	A	1.0	And this really speaks to a question that was asked after Avel's session recently about what does prediction error actually look like?
5019728	5039866	625	A	0.99999	Well, in this case you have a system that has learned that engagement with certain affordances gives it's an illusion, but it has this feedback that says this is the state you expect to occupy, or this is the state that the agent has learned to expect to occupy.
5039978	5046242	626	A	1.0	And it's carved out a niche of affordances that means it's very likely to occupy that state.
5046296	5048900	627	A	1.0	So it actually has a really good grip on the situation.
5049350	5069900	628	A	0.99988	It's just that that niche is very narrow and it's constricted, meaning it's simply those habits and that web of habitual action policies are just not well suited to maintain good allostatic control.
5073420	5077080	629	A	1.0	So everything else in the addict's life starts to suffer.
5077900	5082216	630	A	1.0	So we can kind of think of this as a form of niche construction gone wrong.
5082318	5086350	631	A	1.0	And I think we're going to look at niche construction in the coming weeks as well.
5087600	5091532	632	A	0.99	So why is this whole agent well, so I should say just to back up a second.
5091586	5097116	633	A	0.83	So what I like about this account of addiction is that it's thoroughly an enactive account of addiction.
5097148	5101916	634	A	0.99995	It really brings out the kind of inactive core of active inference.
5102028	5106204	635	A	1.0	So the addict is addiction becomes an identity.
5106332	5111056	636	A	0.99999	It becomes a world that the person actually produces through their actions.
5111168	5122296	637	A	0.65	So rather than the disease model where you have a person and a stimulus and exposure, whenever they're exposed to that stimulus, they're going to have problems because of these brain changes.
5122478	5126120	638	A	1.0	What this does justice to is actually the activity of the agent.
5126270	5139310	639	A	1.0	So they're not accidentally bumping into this stimulus in the environment and they're not just seeking it out, but they're deliberately restructuring their environment to make this state more and more likely over time.
5139760	5152848	640	A	1.0	So it really does justice to the efficacy and the agency of the agent rather than giving that agency a more backseat role that it takes in the disease model.
5153014	5161264	641	A	0.99999	But the other thing that it does, because it's this inactive picture, is that it also does justice to the environmental features.
5161392	5168228	642	A	1.0	So it kind of speaks to the fact that addiction is not just all in the head.
5168394	5178184	643	A	0.99993	Actually, some of the problems of addiction come with the fact that it is this procedural, constructive process.
5178382	5185224	644	A	0.97	And one of my favorite experiments of all time is I don't know if people are familiar with the Rat City experiments.
5185272	5187230	645	A	0.9999	This is why I've got the image up here.
5187680	5202876	646	A	0.99	And this was a very cool experiment where originally it was found that if you exposed rats to a drug laced stimulus in the environment, I think it was heroin laced water or it might have been cocaine.
5202988	5213392	647	A	0.99999	But the original experiments found that nearly all the rats would kill themselves with the drug, so they would just keep at the drug until they died.
5213456	5224072	648	A	1.0	And it was a very high percentage of the rats would engage in that destructive behavior until the experiments were rerun sometime later.
5224206	5236504	649	A	1.0	And instead of having the rat just in a boring cage on its own, it had the rats in Rat Park, which was a very social, exciting, brightly colored environment with lots of different affordances.
5236632	5244056	650	A	1.0	And what they found was that given the same choice, a vastly reduced proportion of the rats would choose to engage with the drug.
5244168	5251504	651	A	0.96	Okay, so it's capturing the importance of niche construction that I think is really nice here.
5251622	5257680	652	A	1.0	And it also speaks to the role played by embodied affect in phenomenology.
5258040	5262672	653	A	0.96307	There's something that it's like to be an addict and that really matters.
5262816	5271240	654	A	0.99991	It really matters that the addict has these embodied experiences when they're engaging with particular sets of affordances.
5273500	5276392	655	A	1.0	So that's really summed up in the overview that I've put here.
5276446	5278920	656	A	1.0	So these were the things that I wanted to emphasize.
5279740	5282728	657	A	0.98893	Active inference agents are embodied.
5282824	5284780	658	A	0.99763	They're embedded in a landscape.
5285200	5288888	659	A	1.0	That landscape is constituted by particular affordances.
5288984	5294152	660	A	1.0	And we can distinguish between a landscape of affordances and a field of affordances.
5294216	5308256	661	A	0.99	And that distinction really speaks to the inherent affectivity and normativity of affordances, which affordances stand out to us at a particular time, which exert a pull over us and enactive inference.
5308288	5311008	662	A	0.91234	Agents enact their worlds through action.
5311104	5314100	663	A	1.0	And this is nowhere starker than in the case of addiction.
5315800	5318400	664	A	0.99953	Active inference agents are effective.
5318480	5330730	665	A	1.0	So emotion plays this super crucial role, keeping us tuned, keeping us in that grip with our affordances, and helping us contextualize those important physiological changes.
5331920	5335180	666	A	0.99877	Active inference agents are agents, okay?
5335250	5346972	667	A	1.0	So we do have a way to describe behavior as agential and motivated, and we do have these cognitive architectures that can make sense of agential action.
5347116	5353330	668	A	1.0	And active inference agents have this inbuilt sense of self that comes with agency as well.
5354820	5356576	669	A	1.0	So that's pretty much it.
5356678	5360644	670	A	0.99997	This final slide just goes over some of the things that we can expect.
5360762	5370416	671	A	1.0	So what I've done today, I hope, has laid a good groundwork and has installed some higher level expectations to learn more about active inference.
5370608	5384300	672	A	1.0	And what we're going to do in the subsequent weeks is now scale this up to see how, when you have more than one active inference agent together, how the expectations of some can impact the expectations of others and individuals.
5384800	5388380	673	A	0.99	And I look forward to learning more about that.
5388450	5391550	674	A	0.99692	But as for me, that's it.
5395430	5395938	675	B	0.99966	Amazing.
5396024	5397700	676	B	0.52397	Ben, awesome work.
5398150	5404546	677	B	0.99972	What can people look forward to next week or in two weeks if they join the discussions section?
5404578	5405494	678	B	0.96371	Like, what's it going to be like?
5405532	5407350	679	B	1.0	Or who would you encourage to join?
5408810	5412102	680	A	0.99582	Definitely, I mean, the more people that come along, I think the better it's going to be.
5412156	5413914	681	A	0.84813	I'm really looking forward to it.
5414032	5419254	682	A	0.75661	I'm kind of just in the first place, intrigued to see we covered so much ground.
5419302	5424830	683	A	0.99984	I'm just interested to see where people want to go with this and see where people's interests lie.
5425410	5435914	684	A	1.0	I assume that people are going to have questions, and I think maybe the best way to do it would be to explore some of people's questions during the discussion.
5435962	5447560	685	A	0.99999	We can use them to kick things off and keep things going, but I think it's likely that we have a whole hour, so we've certainly got time to really dig into things in some detail.
5448010	5452214	686	A	0.99	And like I said before, we're going to have Mark Miller with us.
5452332	5455986	687	A	0.98	And Mark is just awesome in discussion.
5456098	5463866	688	A	0.49176	It's very, very passionate and enthusiastic about his work, and he can do a much better job than I can in explaining it.
5463888	5470060	689	A	0.89	So just to have the opportunity to speak with Mark about his work, I would say definitely come along.
5471870	5472382	690	A	0.94	All right.
5472436	5473022	691	A	0.99988	Anything else?
5473076	5474880	692	B	0.84863	Otherwise, again, awesome job.
5475890	5477406	693	A	0.75737	No, I think that's it.
5477588	5478862	694	A	0.9965	Thanks for listening, I guess.
5478916	5479662	695	A	0.77974	Well, thanks.
5479796	5480762	696	A	0.99767	It was a pleasure.
5480906	5482218	697	B	0.99985	It was ambitious.
5482394	5500962	698	B	0.72	To what you did elegantly with no equations or getting snagged on any of the potentially infinite philosophical and technical and normative and all these different layers of challenge and divergence.
5501106	5505910	699	B	1.0	So to really cut a path there is great.
5506060	5506374	700	A	0.99992	Yeah.
5506412	5512806	701	A	1.0	I think it just speaks to there's so much good philosophical work in these areas in enactive inference and predictive processing.
5512838	5519002	702	A	1.0	And I should say, again, we didn't really do justice to any of the work I talked about.
5519056	5531260	703	A	1.0	So the final thing I would say is definitely the document is there with the reading, and please go and actually look at the work of these people, because some of it's really good.
5531950	5532954	704	A	0.99	All right.
5533152	5534354	705	B	0.97756	Till next time.
5534512	5534882	706	A	0.99636	Cool.
5534936	5535940	707	A	0.99886	Thank you very much.
5539590	5539870	708	A	0.35728	Bye.
