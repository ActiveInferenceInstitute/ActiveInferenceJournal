start	end	sentNum	speaker	confidence	text
650	1200	1	A	0.52571	Alright.
1810	3422	2	B	0.74579	Hello and welcome everyone.
3556	7678	3	B	1.0	It is July 11, 2023.
7844	17774	4	B	1.0	We are in active inference for the social sciences and today is going to be a lecture by Ben White on basics of active inference, the active inference agent.
17892	19994	5	B	0.99	So Ben, thank you for the lecture.
20122	23566	6	B	0.99705	Off to you and we're looking forward to it.
23748	24702	7	A	0.99976	Thank you very much.
24756	25960	8	A	0.96	Yeah, me too.
26330	33320	9	A	0.90023	Very happy to be a part of this, to be kicking things off with the first module on this course.
33850	39350	10	A	0.84511	I'm going to be talking about the active inference agent and trying to cover some of the basics.
39930	41830	11	A	0.98	I won't take too long introducing myself.
41900	64020	12	A	0.22586	Avil gave a very thorough introduction in his talk recently, but I'm a second year PhD student in philosophy at the University of Sussex, and I work with Andy Clark and with Avel and some other people using active inference to try and find things out about our relationship with technology and within the context of well being and mental health.
65590	85350	13	A	1.0	The aims for today I'm going to try and provide quite a wide ranging overview of how active inference has connected with areas of philosophical interest and particularly how they relate to the individual agent and the experience of the agent and how the agent finds themselves in the world.
85420	90118	14	A	1.0	So I've split this up to look at several different defined topics.
90214	99530	15	A	1.0	So I'm going to move quite quickly through mind, agency, emotion and phenomenology, and I'm going to say a little bit about the self as well.
99600	104160	16	A	1.0	And then there's going to be a case study at the end that I'm going to move through if we have time.
104690	115270	17	A	1.0	So one of the other aims that I have is to lay out very clearly some of the core concepts and core mechanisms like precision, weighting and prediction error generative models.
115450	118942	18	A	0.55242	I'm not going to go into any technical details whatsoever.
119006	121006	19	A	1.0	This is all going to be fairly abstract.
121118	128920	20	A	1.0	My background and my interest in these frameworks is philosophical, so it's quite abstract in terms of how everything fits together.
129370	138490	21	A	1.0	And I'm going to try and bring some of these threads together to build up a layered picture of what the active inference agent is like.
138560	150406	22	A	0.99999	Because this course is kind of aimed towards seeing how active inference applies to larger scales, collective behavioral, social norms, sociocultural landscapes.
150518	158522	23	A	0.92	And I think in order to do justice to those things, we need to first have a good idea of the individual in active inference.
158666	161454	24	A	0.52	So we've got our work cut out for us.
161572	162880	25	A	1.0	So I'll get started.
163490	168658	26	A	0.91	So before I dive in, I wanted to just say a little bit about how these frameworks hang together.
168744	173950	27	A	0.99	So active inference is based on Carl Fristen's free energy principle.
174030	175794	28	A	1.0	I think most of us are familiar with that.
175832	186822	29	A	0.99987	But the free energy principle just states that in order to persist through time, biological organisms must occupy only those states that it would expect to occupy, given the type of thing that it is.
186956	192102	30	A	1.0	So free energy is essentially a measure of the disatunement between a system and its environment.
192166	198780	31	A	0.76	And I'm going to say a little bit more about attunement and how that gets cashed out in various ways as we go on.
199150	206926	32	A	0.9999	Active inference is a process theory that essentially explains how embodied organisms actually go about remaining in those expected states.
207028	211120	33	A	1.0	So how we actually go about minimizing free energy.
211490	220290	34	A	1.0	And the idea is that all adaptive behavior is explained by agents garnering evidence to confirm their own expectations.
221430	222622	35	A	0.86773	Predictive processing.
222686	233474	36	A	1.0	For the purposes of the lecture today, I'm going to treat these as synonymous because most of the work that I kind of came up through as I was learning about this was predictive processing.
233602	244966	37	A	0.86	And all of the papers that we're using today that refer to predictive processing refer to a predictive processing that I take to be more or less synonymous with active inference.
244998	250566	38	A	1.0	So that's a very embodied, inactive flavor of predictive processing.
250678	258474	39	A	1.0	I think generally the difference is that predictive processing can be a much broader term and predictive processing can also apply to passive models of perception.
258522	260960	40	A	0.99999	But we're not going to concern ourselves with that.
262630	268180	41	A	0.56656	Okay, so some key concepts of active inference, predictive processing then.
268630	288626	42	A	1.0	So the framework phase that agents embody or agents have, we won't concern ourselves with the nuance there, but they have a generative model, which is essentially a kind of understanding or a model of the regularities that underpin the dynamics between the agent and the environment.
288738	297754	43	A	0.91	So another way to think about this in very rough terms is a kind of mental model of the regularities in the world and how the agent exists in the world.
297952	303278	44	A	0.98	And using that model, the agent can generate predictions about its own sensory states.
303444	310510	45	A	1.0	So given the model, what kinds of sensory states would it expect to find itself in in a particular set of circumstances?
311170	316174	46	A	1.0	And so where those predictions don't actually match the sensory inputs.
316222	326306	47	A	1.0	So where there's a discrepancy between the actual incoming sense data and the prediction, prediction errors are generated and prediction errors are going to flow upwards through the hierarchy.
326338	333538	48	A	1.0	So the generative model is said to be a hierarchical model and predictions flow downwards and prediction errors flow upwards.
333714	341050	49	A	0.92	And the sole imperative of the brain body system according to this framework is to minimize those prediction errors.
342830	349878	50	A	0.99	So a good way to kind of get a little handle on this is to think about just the example of perception.
349974	353454	51	A	0.86	So perception traditionally so I'm talking about visual perception here.
353492	356206	52	A	0.66042	It's traditionally been understood as a bottom up process.
356388	366402	53	A	0.64	And what that means is that the brain waits for incoming sensory signals and then it processes them as they come in and it combines them in kind of increasingly abstract ways.
366536	372750	54	A	1.0	And what we see is some combination of those sensory signals that have come in and been processed and combined.
372910	380194	55	A	1.0	So if you think about me leaving my apartment in the morning and stepping out onto the street and seeing some cars.
380322	391046	56	A	0.99939	What's happening there is some sensory information is hitting my retina and it's being processed first with very basic features like light shade, edges and so on and so forth.
391158	396346	57	A	1.0	And then it's being combined with my understanding of what a car is or what a bus stop is.
396448	399020	58	A	1.0	And that gives me my kind of visual field.
400850	406382	59	A	0.56109	Predictive processing, famously, at this point, flips this picture upside down on its head.
406436	410858	60	A	1.0	So visual perception under predictive processing is a top down affair.
411034	416494	61	A	1.0	So the generative model is going to encode multilevel expectations about the likely scene.
416542	426814	62	A	1.0	So just to be very clear, when we talk about multilevel and hierarchical, the higher up levels are going to be tracking longer time scales and higher levels of abstraction.
426942	430466	63	A	0.67	The lower levels are going to be much faster, much more concrete.
430658	433650	64	A	0.73	So a changeable scene.
433730	440626	65	A	1.0	So there's going to be some variation in what I see when I leave my apartment every day is going to mean that there's always going to be some error in that picture.
440658	445546	66	A	1.0	So it's never going to be the same two days in a row or it's extremely unlikely to be.
445648	452986	67	A	1.0	So no matter how well I can predict what I'm going to see when I leave my house, it's always going to be cleaned up by some prediction errors.
453178	460880	68	A	0.7	So essentially, when I step outside and I step into the street, my brain is already anticipating what it's going to see out there.
461490	467326	69	A	0.93	So I know where particular cars are going to be parked, I know where the bus stop is, so on and so forth.
467438	471490	70	A	0.81	And the perceptual experience that we have is a construction.
472150	478050	71	A	1.0	We actually experience the expectation that has been kind of cleaned up post prediction error.
478210	482102	72	A	0.99984	There's a little bit of debate there about exactly what it is that we experience.
482236	488650	73	A	0.99975	But for our purposes today, we can say that visual perception is essentially a construction.
490430	495334	74	A	0.5	So on the face of it, prediction errors can be minimized using one of two strategies.
495382	497420	75	A	1.0	And this is going to be really important.
499790	503386	76	A	1.0	So we have what I just described there, which is perceptual inference.
503498	507082	77	A	0.96105	That's where we revise our predictions to better fit the evidence.
507146	511630	78	A	1.0	So essentially we update our model to better reflect the regularities in the environment.
512290	520740	79	A	1.0	Or we can engage in active inference, which is where the framework gets its name from, which is where we essentially make the evidence fit the model.
521190	527042	80	A	1.0	So that's where we in some sense update the world so it conforms to the original prediction.
527186	538890	81	A	0.91	And active inference agents bring about those expected states by sampling the world in a biased way, so they have certain expectations and then we sample the world to confirm the predictions.
539230	550710	82	A	1.0	And I put perceptual inference there in scare quotes because perceptual inference on kind of readings of most readings of active inference just becomes a kind of action readiness.
550790	558938	83	A	0.52	Or as Ramstard and colleagues put it, a state estimation so it's just perception and action are just wrapped up in this continuous loop.
559034	560666	84	A	0.99988	But it's really all about the action.
560698	567186	85	A	0.98938	It's really all about bringing about those expected states, and perception is just kind of in service of that process.
567368	576194	86	A	1.0	And so Berenberg and colleagues refer to the active inference agent as a crooked scientist, which is something I really like.
576232	577746	87	A	1.0	I think that's a very charming image.
577778	586422	88	A	1.0	So we are scientists that are engaging in some very dodgy behavior because we're not really interested in having an accurate model.
586476	590790	89	A	0.62488	We're more interested in confirming our original predictions.
592330	601462	90	A	0.99869	Okay, so that was a very rapid overview of some of the core concepts and mechanisms, but they're going to crop up continuously.
601526	605340	91	A	1.0	So I think we're going to get a much better grasp on them as we go on.
605790	617460	92	A	0.74121	In this section, I'm going to start to expand on some of those things that we've just put on the table, and I'm going to begin to flesh them out in terms of thinking about how active inference agents actually exist in the world.
618950	621442	93	A	0.59	So I should say I put this here to remind me.
621496	635250	94	A	1.0	So those of you who are taking part in the course, I'm going to make available a document with all of the readings that firstly, all of the readings that I've used to make these slides and then a bunch of other readings as well that I think are going to be very relevant.
635330	640214	95	A	1.0	And obviously, they're going to be organized in terms of the structure of this presentation as well.
640252	645450	96	A	0.99	So this is just I've put a little sample up on these slides, but there's going to be much more in the document.
646510	649740	97	A	1.0	So I think it's always good to start with some guiding questions.
650350	652240	98	A	1.0	So I've thrown up three here.
654610	657690	99	A	0.91	The first is how does active inference characterize cognition?
657770	662990	100	A	1.0	So we've just looked at predictions and prediction errors, but we're going to expand on that a little bit.
663060	666750	101	A	1.0	And we're going to ask what kinds of processes does cognition involve?
666910	669582	102	A	0.99998	How is cognition related to the material environment?
669646	675458	103	A	1.0	This is going to be something how cognition relates to the environment is going to be very important in subsequent weeks.
675624	681106	104	A	1.0	And we're going to ask quite briefly what kinds of vehicles might realize cognitive processing.
681298	684450	105	A	0.54633	Okay, so here's a couple of whales.
684530	695082	106	A	0.9484	Whales are going to be a recurring theme in this lecture, but I wanted to take a step back and ask about Attunement because this is one of those concepts that gets thrown around a lot.
695216	700362	107	A	1.0	And I think once it's grasped, it becomes very clear, very easy to use.
700416	704842	108	A	0.99997	But I think prior to it being grasped, it can be a little bit opaque and a bit slippery.
704986	711050	109	A	1.0	So on the left we have a humback whale that was found dead in the Amazon rainforest, allegedly.
711130	712590	110	A	1.0	I don't know if this was true.
712740	715658	111	A	1.0	And on the right we have a whale in its natural environment.
715754	722946	112	A	1.0	And I think clearly the intuition here is that in one case the whale is very well attuned to its environment and in the other case it's not.
723128	730050	113	A	1.0	And I think that we can start by asking what is it about the ocean that allows the whale to be well attuned?
730130	740970	114	A	0.84	And what I want to say here is that the particular dynamics between the ocean and the whale allow the whale to do certain things that it can't do when it's in the Amazon.
741710	756718	115	A	1.0	So in other words, we might say that the ocean affords certain things to the whale, specifically filter feeding, being able to move its vast weight around with ease, things that, unfortunately, a whale in the Amazon can't do.
756884	759950	116	A	1.0	So affordances are opportunities for action.
760770	765854	117	A	0.99962	They are things, roughly speaking, in the environment that the agent can act upon.
765982	780406	118	A	0.59	And there's some debate about the proper way to really characterize affordances, but I like to think of them as relational properties emerging from an environmental feature and some skilled embodied ability of the agent.
780508	786242	119	A	1.0	So the same thing in the environment will not afford the same thing to different organisms.
786386	795738	120	A	1.0	So, for example, soil to a human agent might afford walking on or laying down on, but to an Earthworm it affords very different things.
795824	806480	121	A	1.0	And also, even amongst the same organisms with humans, especially, different surfaces and features of the environment will afford different things depending on your particular skill set.
807890	817834	122	A	1.0	And agents are going to go about minimizing their uncertainty, so minimizing prediction errors, staying attuned to their environment through an engagement with affordances.
817962	824980	123	A	1.0	And this is going to be something that is going to drift away slightly as we move through some sections and then it's going to come back very heavily at the end.
825830	834962	124	A	1.0	And I should say that the idea of affordances, to my knowledge, it first emerges in the work of James Gibson the Ecological Approach to Visual Perception.
835026	839530	125	A	1.0	I think it's chapter eight in that book that really lays out a theory of affordances.
844480	858160	126	A	1.0	So this idea that systems or organisms maintain their organization through ongoing action means that active inference has been labeled as quintessentially inactive by Cole Friston.
858580	865964	127	A	1.0	And I think that this is a nice inactivism is an older framework from theoretical cognitive science.
866092	871248	128	A	1.0	And I think it's a nice way to understand some of the key features of active inference.
871344	875184	129	A	0.99999	But it does come with a little bit of historical philosophical baggage.
875232	886090	130	A	1.0	And I'm going to try and unpack that really quickly because I want to unpack exactly what it is that we're committing ourselves to when we think about cognition in inactivist terms.
887100	899144	131	A	1.0	So inactivism comes in various strands very, very quickly and roughly, you have autopoietic inactivism, which commits itself to what's known as the mind life continuity thesis.
899272	909840	132	A	1.0	This is essentially that the structures that give a ground to life itself are the same structures that instantiate cognitive processes.
910820	917616	133	A	0.42834	Sensing on this view is teleological because it's oriented around supporting vital systems.
917648	926890	134	A	0.98	So things in the environment have intrinsic meaning to the organism because they support the vital functioning of the organism in some way.
927660	939544	135	A	0.78915	Sensory motor inactivism emphasizes how mobile and embodied agents essentially enact the grounds and conditions for their own sensory engagements with the world.
939662	954850	136	A	1.0	So the world is not a kind of neutral static, given that we're parachuted into actually the conditions through which we sense the world are the conditions that we can move and kind of interact with the world in various ways.
956020	958124	137	A	1.0	And then there's radical inactivism.
958252	964864	138	A	1.0	And this is the view that cognition is purely grounded in these agent environment dynamics.
964912	972064	139	A	0.99996	It's a purely dynamicist account of cognition and there's no role whatsoever for internal representations.
972192	981540	140	A	1.0	So certainly in certain brands of sensory motor inactivism, there remains a role for internal manipulation of representations.
981700	987240	141	A	1.0	And mental representations are just mental states that are about something in the world.
987390	992204	142	A	1.0	So some mental state is reconstructing some feature of the world.
992322	1004252	143	A	1.0	And this all harks back to kind of old debates in philosophy of cognitive science between internalist notions of cognition and more embodied, embedded, extended.
1004316	1008064	144	A	0.97	And we'll take more of a look at that in a second.
1008182	1012636	145	A	0.90779	But the question here is what are we committing ourselves to with active inference?
1012748	1013948	146	A	0.99822	Active inference?
1014044	1024512	147	A	0.67	And I need to be a little bit careful because I think that people are going to disagree with this to certain extents, but I think we're certainly committing ourselves to sensory motor and activism.
1024576	1026336	148	A	1.0	I think that's fairly uncontroversial.
1026448	1040940	149	A	0.64	And I would say as well that the underpinning of active inference by the free energy principle, by my lights, also commits us, or it certainly chimes very deeply with the core tenets of autopoietic inactivism.
1041680	1049820	150	A	0.99998	But I think what's really interesting in trying to understand cognition in the active inference agent is to understand what role, if any, there are for representations.
1050240	1065024	151	A	0.99	So if you have any familiarity with the literature on active inference, you'll know that active inference people are always banging on about models, prediction errors, various other computationally sounding things.
1065222	1075712	152	A	1.0	And so the worry here is at least for well, it's not necessarily a worry, but the thought would be are we committing ourselves to a form of cognitivism?
1075776	1092350	153	A	1.0	And again, cognitivism is generally considered to be an old fashioned notion of cognition as like computation over symbolic representations in the brain according to some syntactic set of rules or something.
1093360	1099468	154	A	0.7	And typically over the last couple of decades in cognitive science, people have been moving away from that view.
1099634	1105024	155	A	1.0	So it would be interesting if we were committing ourselves to something that we'd already moved away from.
1105142	1108204	156	A	1.0	And some people think that we are making that commitment.
1108252	1121168	157	A	1.0	So Jacob Howie, for example, has argued in various places that essentially predictive processing or active inference commits us to these very rich reconstructive notions of representation.
1121344	1131384	158	A	0.57	And even Andy Clark Jacob Howie's foil in many places has said himself that he thinks that representations play a role here as well.
1131502	1133348	159	A	0.93	So in a talk in 2016.
1133444	1136596	160	A	0.99992	Clark said it's internal representation.
1136708	1137640	161	A	0.88	I think it is.
1137710	1145948	162	A	1.0	These are representation using stories, but it's not internal representation in quite the way that we originally thought about it.
1146114	1152432	163	A	1.0	So there's some differences, perhaps major differences between Howie and Clark there, but others have pushed back.
1152486	1169300	164	A	1.0	So there's a paper by Maxwell Ramstead and colleagues from 2020, I think it's the tale of two densities paper where they say that a proper understanding of the generative models in active inference suggests that there's no role for representations.
1170040	1172470	165	A	1.0	So this is the kind of anti Howie view.
1175800	1190628	166	A	1.0	So I really like this paper from Axel Constant and Andy Clark and Carl Friston which essentially tries to broker some kind of peace in a debate that in some form or another has been raging for decades.
1190724	1194108	167	A	1.0	So it'd be quite nice to finally put this to bed.
1194274	1201150	168	A	1.0	So they argue that we can find, in the formalisms of active inference, we can find grounds for an armistice here.
1201940	1213672	169	A	1.0	So they argue that the formalisms of active inference show that, quote representational and non representational cognitive processes can be implemented by the brain under active inference.
1213836	1218928	170	A	1.0	And they do this by showing that active inference accommodates a dual architecture.
1219104	1233476	171	A	1.0	So they show that on the one hand, in some sense the brain has to represent because under active inference action selection policies are happening over extended timescales.
1233508	1237240	172	A	1.0	And so the agent has to engage in some kind of counterfactual thinking.
1237390	1239272	173	A	1.0	So if I do X, what happens?
1239326	1240760	174	A	1.0	If I do, y what happens?
1240830	1241628	175	A	1.0	And so on.
1241714	1248460	176	A	1.0	And the argument, very roughly speaking, is that that is going to entail some kind of representational, some use of representations.
1249360	1259564	177	A	1.0	But on the other hand, they argue that what they call deontic actions are processed through different mappings in the generative model and they're directly triggered by sensory input.
1259692	1267056	178	A	1.0	So a deontic action is an action that is ingrained by our sense of the expectations of others.
1267238	1273828	179	A	1.0	So the example that the authors use is stopping at some red traffic lights in the middle of the night when there's nobody else around.
1273994	1280020	180	A	1.0	So in a sense the claim is that we through a kind of social conditioning.
1280180	1292780	181	A	1.0	We know what other people would expect us to do in those circumstances and that allows for this kind of dynamic reflexive action policy setting.
1295040	1300590	182	A	0.7	And in those cases there's no room for representative or there's no need for representations there.
1301380	1315440	183	A	1.0	I would definitely suggest people interested in this go and read this paper because you might already have thought of some potential objections here to the claim that representations aren't needed for deontic action.
1315520	1319910	184	A	0.96	And they do go into some detail in talking about potential objections there.
1321240	1326500	185	A	0.97	So that's the kind of status of the role of representations.
1327260	1330916	186	A	0.99905	It's a live debate, not everybody agrees.
1331108	1339012	187	A	0.99996	But it certainly looks as though active inference has the formal tools to accommodate both sides of the debate.
1339076	1349070	188	A	1.0	And it might turn out that that's a good thing because we can make everybody happy or it might turn out to be a bad thing because you might think, well, we've not really settled anything one way or another.
1350640	1356700	189	A	1.0	I wanted to take some time though, to mention extended active inference.
1356780	1371552	190	A	0.85	So I've been talking about inactivism and I've mentioned that I've mentioned this debate between cognitivism and older ways of thinking about sorry, cognitivism and newer ways of thinking about cognition as embodied or embedded.
1371696	1374720	191	A	1.0	And these are part of what's known as the four e paradigm.
1374800	1384024	192	A	0.84	And clearly I think we are talking about inactive cognition and you get embodied and embedded kind of for free with this.
1384062	1387416	193	A	0.92	So the only one left on the table is the extended mind.
1387598	1400750	194	A	1.0	And this is just the claim that under some conditions the system that's realizing cognitive processing can literally extend outwards from the mind.
1401200	1405984	195	A	0.99	So I'll put some nice readings for this up if anybody's unfamiliar and interested.
1406102	1409360	196	A	0.99994	But it's usually the most controversial of the four ease.
1410900	1421392	197	A	0.52	And Andy Clark, who is one of the original authors of the extended mind paper, really thinks that active inference accommodates the extended mind theory.
1421456	1435140	198	A	0.95	And it's not just that it accommodates it, but it actually solves some old problems in the extended mind about knowing how and why the brain knows when and where to recruit certain extraneural resources.
1435300	1449000	199	A	0.99	And part of the argument for this, what really sits at the core is Clark develops this argument based on the fact that the generative models in active inference are always in this, always making a trade off between accuracy and complexity.
1449160	1462348	200	A	1.0	So you want your model of the world to be accurate enough that you can act effectively on the world, but you also want to minimize the metabolic costs of having models that are overly complex.
1462524	1477690	201	A	1.0	And so Clark utilizes this insight to make the case that this explains that in some cases as agents we make use of these extra neural kind of props and tools and things.
1478540	1488970	202	A	1.0	And he says that the imperative to reduce uncertainty provides a location neutral cost function that's always been missing from the older arguments around extended mind.
1490160	1498344	203	A	1.0	So the upshot to this, I think, is that you end up with a view of agents as deeply coupled with their environments.
1498472	1505228	204	A	0.91	So under active inference it's just nonsensical to try and think about agents as decoupled from their environment.
1505324	1510732	205	A	0.93	The generative models themselves are of the dynamics between the agent and the environment.
1510796	1516400	206	A	1.0	So these two things can't be decoupled perception, action loops.
1516480	1520612	207	A	1.0	So remember I said that perceptual and active inference are essentially the same thing.
1520666	1527720	208	A	0.94404	They're the part of this circular causality and they see the agent constantly producing their own worlds.
1528220	1532040	209	A	0.99996	They occupy the states that they're expecting to through action.
1532460	1540536	210	A	0.84	And we might think, based on the literature that I've gone through, that there's some role here for representations.
1540728	1543100	211	A	1.0	So we're not committing ourselves.
1544560	1557004	212	A	1.0	The active inference agent is not one that fits with very radical interpretations of inactivism and active inference agents are porous.
1557132	1568790	213	A	0.99014	They're open to recruiting external material features of the environment to reduce complexity and therefore minimize the metabolic costs of realizing those expected states.
1571000	1584354	214	A	0.99549	Okay, so that was a bit of active inference set against the backdrop of some older questions in philosophy of mind theoretical cognitive science.
1584482	1589720	215	A	0.62711	But I'm going to jump straight into agency and motivation now, because there's a lot to get through here.
1590890	1592966	216	A	0.83441	I'm going to start with a dark room problem.
1593068	1597126	217	A	1.0	This is a canonical philosophical worry in active inference.
1597158	1599802	218	A	1.0	So a lot of people, I think, will be familiar with this.
1599936	1603020	219	A	1.0	And in really brief terms, it's really easy to state.
1603390	1614686	220	A	1.0	The challenge here is to say, if it's all about minimizing prediction error, why don't we just find the most predictable environments possible and stay there and live a nice error free life?
1614868	1625060	221	A	0.94	So Andy Clark paints a picture of a dark room, and you can just be strapped up to an intravenous drip, feeding you the nutrients you need, and you can just be really happy.
1625510	1627586	222	A	0.99997	But clearly, we don't do that.
1627768	1629362	223	A	0.82697	Active inference sorry.
1629416	1637718	224	A	0.9999	Agents in the world, us, we generally typically sometimes we do enjoy dark rooms, but most of the time we don't for any extended period of time.
1637804	1650810	225	A	1.0	And so there's a challenge here about how active inference can account for what appear to be motivated agential actions that necessarily mean we're confronted with some degree of uncertainty.
1651710	1660890	226	A	0.55	And I'm going to set active inference up in a kind of dialectic with folk psychology here, because folk psychology faces no such concerns.
1661050	1673070	227	A	1.0	So, to be very clear, folk psychology is just the kind of propositional linguistic framework that the folk use to talk about and describe motivated action.
1673150	1679606	228	A	0.96	So it's a language we typically use every day to describe the reasons people are doing things.
1679788	1689474	229	A	1.0	So folk psychology has this belief, desire, intention, schema, where, if I want to explain, my friend going to grab a beer.
1689602	1692822	230	A	0.75	I would say, my friend believes there's beer in the fridge.
1692886	1694806	231	A	1.0	My friend desires beer.
1694918	1698774	232	A	1.0	And so those are combined to form the intention to go and get beer.
1698822	1702060	233	A	1.0	So folk psychology doesn't have these kinds of problems.
1704030	1707390	234	A	1.0	So just a little bit more on the dark room problem and another whale.
1708690	1711630	235	A	1.0	So the dark room problem invites more than one answer.
1711700	1714400	236	A	0.9983	We're going to see more than one answer to it as we go along.
1715090	1722162	237	A	1.0	One response is to talk about what drives curiosity and play and exploration, and we are going to see more of that.
1722296	1738882	238	A	0.99992	But the first response offered by Fristen, Thornton, and Clark is to highlight the fact that organisms have basic needs to eat, drink, and reproduce what you might call evolutionarily ingrained needs, and that those needs are going to necessitate some form of exploratory behavior.
1739026	1747210	239	A	1.0	So staying in the dark room will inevitably, under most circumstances, going to lead to physical dissipation.
1749790	1753980	240	A	1.0	So the question is, are these kinds of appeals enough?
1755870	1762618	241	A	0.98	And I wanted to pull up a paper by Colin Klein 2018 that I think is like a really nice articulation of these challenges.
1762714	1768106	242	A	0.99946	Ultimately, I think he's wrong and it falls flat, but I think it's a strong articulation.
1768298	1774770	243	A	0.75	So Klein argues that predictions alone simply can't account for the motivational character of these needs.
1774840	1788054	244	A	1.0	So Klein says, look, it's fine that you've got these needs, nobody's going to deny that, but you just have this one primitive to describe how those needs motivate you, and prediction is just not going to do it.
1788092	1795900	245	A	1.0	So prediction alone, as your sole primitive is not going to be able it's like predicting is not the same thing as being motivated by something.
1797550	1803466	246	A	1.0	And Klein is really not happy with appeals to these phenotypic needs.
1803648	1811438	247	A	1.0	And he construes these in the relevance of the evolutionary history of the organism and goes into a little bit of detail.
1811524	1829758	248	A	1.0	So he says, look, these expectations are either going to be about states, possible states, so the state of being fed or clothed or warm, or they're going to be about state transitions, about what the appropriate action is in one state to move to another state.
1829944	1838834	249	A	1.0	And he says expectations about states themselves aren't going to work because you have this problem of accounting for novelty.
1838962	1847942	250	A	1.0	So it might be the case that in my evolutionary past, all of my ancestors have had the same expectations about which states they're going to occupy.
1848086	1857280	251	A	0.99999	But there are lots of states in my life that I could be motivated to occupy that there's simply no evolutionary history to account for.
1857810	1868378	252	A	1.0	And he says there's a very similar or similarly difficult problem with state transitions, where essentially what we're talking about with state transitions are the most appropriate actions.
1868554	1878786	253	A	1.0	So I have expectations about the actions that are going to fill foot that I need to take under certain circumstances that are going to get me to a particular expected state.
1878968	1884694	254	A	0.99	And Klein's worry is that there's just going to be too many possible actions in any given situation.
1884812	1891606	255	A	1.0	So there's just a kind of explosion that's just going to be unaccountable for.
1891708	1900780	256	A	0.99953	There's just going to be too many different ways of getting to an expected state that we won't be able to account for in our past.
1901470	1908606	257	A	1.0	So it's fairly robust, thorough, challenge used, built on the dark room problem.
1908788	1912330	258	A	1.0	And I think actually it's a worry with two faces.
1912410	1922414	259	A	0.75	So I think the first is about how active inference can describe agential behavior with its austere, purely docsastic landscape.
1922462	1932614	260	A	1.0	So if you imagine somebody looking at their house burning down, it seems like you need more than beliefs to explain any course of action they take.
1932652	1935314	261	A	0.95	So there has to be desire in there somewhere.
1935442	1938594	262	A	1.0	So this is an example Andy Clark uses in one of his papers.
1938642	1951818	263	A	1.0	And he says the desire to run in and rescue some item that you want from the house or the desire to claim on the insurance is the thing that's going to.
1951824	1954506	264	A	0.87713	Dictate how you explain the person's behavior.
1954698	1956238	265	A	1.0	So that's the first problem.
1956324	1962590	266	A	1.0	We need to look at how folk psychology tessellates with prediction.
1962930	1971582	267	A	1.0	And the other problem is maybe a little bit, maybe a little bit deeper, and that's to ask, how does active inference actually account for agential behavior?
1971726	1979880	268	A	1.0	So can we even tell some story using just predictions and prediction error about what really moves agents to act?
1981130	1988946	269	A	1.0	So firstly, thinking about folk psychology, there's a couple of ways to go here and I think ultimately we can answer this worry.
1989138	1997366	270	A	1.0	So Ryan Smith and colleagues in 2022 in their paper active inference models do not contradict folk psychology.
1997558	2003926	271	A	0.52814	They argue that the formalisms of active inference can accommodate a belief desire distinction.
2004118	2012954	272	A	0.99999	Now, I'll admit that it's a very math heavy paper and it's a little bit beyond my capabilities, but the claim here is simply that there's no contradiction.
2013082	2018170	273	A	0.48799	That actually the worry that the important thing we have in folk psychology is desire.
2018330	2020542	274	A	1.0	And we're not getting that in active inference.
2020606	2022530	275	A	1.0	This is just an unfounded worry.
2023030	2024994	276	A	0.99996	But there's another strategy as well.
2025112	2034386	277	A	0.56	So Joe Deuhurst, in his 2017 paper, he employs a different strategy and he says, look, what are we even doing with folk psychology?
2034498	2043740	278	A	0.99989	Let's not kind of be too hasty and we need to think about what are we doing when we talk about these propositional kind of states.
2045070	2048842	279	A	0.89	So he says the first option is to say, well, we're just being realists here.
2048896	2058880	280	A	1.0	So when I say that X desires Y, I'm actually positing the real existence as a fine grained mental state in X's head.
2059570	2062430	281	A	0.84	And he thinks that this is actually the wrong way to think about things.
2062500	2067086	282	A	0.99999	He thinks that folk psychology actually it's an instrumentalist tool.
2067188	2074818	283	A	0.99938	It's a kind of framework that we use just for picking out coarse grained behavioral patterns in some useful way.
2074984	2097162	284	A	0.5	So if we agree with Deuhurst here and we just become instrumentalists about folk psychology again, it looks as though there's different we're not forced to kind of worry that there's some kind of empirical problem here where the mechanisms of active inference are in some sense incommensurable with real properties that we're positing the existence of.
2097216	2103340	285	A	1.0	Because we're just going to say that those things don't really exist in the way that we've typically assumed that they might.
2104050	2115710	286	A	1.0	So either way, whichever route you go down here, it looks like active inference agents have beliefs and that we're going to be fine in describing motivated action.
2117990	2119940	287	A	0.99	So what about the second problem?
2122870	2126930	288	A	1.0	So Andy Clark in 2020 authored a direct response decline.
2127830	2140390	289	A	1.0	So Clark wants to argue that actually using predictions and prediction errors and precision weighting, which I'll explain in a second, we can get a picture of agential action.
2142830	2153414	290	A	0.92	So the first thing Clark does is to outline the fact that under active inference, we have a very nice, well worn account of embodied action.
2153462	2165226	291	A	1.0	So, in other words, what it takes to actually move the body to perform different actions is perfectly folded into active inference under the same kind of computational flow of prediction error minimization.
2165418	2174050	292	A	1.0	Just in a nutshell, for me to move my arm, what I'm doing is making a prediction that my arm is in someplace and then minimizing the prediction error.
2175510	2178962	293	A	1.0	So once that's on the table, Clark says, okay, that's fine.
2179096	2182600	294	A	1.0	We have this account of action, but that's not really what Klein means.
2183290	2201510	295	A	0.9	So the move Clark makes is to appeal to the hierarchical nested structure of the generative model and to say that higher level beliefs, which are about temporally extended future states, these are going to perform a really important role as a kind of controller for lower level actions.
2201670	2216550	296	A	1.0	So the idea is that if I have a high level temporally extended expectation to attain a PhD, what happens is that high level belief becomes unpacked at lower levels in the hierarchy.
2216650	2226130	297	A	1.0	And what you get are more fine grained, faster action policies that the system expects to help support that higher level expectation.
2226550	2242934	298	A	1.0	And there's a mechanism in play here called precision weighting, which applies to prediction error signals because obviously not all of the predictions we make about the environment are going to be equally important.
2243052	2248890	299	A	0.9996	We're not going to have equal confidence in all of our actions to bring about an expected state.
2249040	2261626	300	A	1.0	And so what precision waiting does is essentially communicate how much confidence we have in a particular action policy to move us into that expected state under perceptual inference.
2261818	2269198	301	A	0.99841	Precision waiting just signals how newsworthy prediction errors are, so how important they are for the system.
2269284	2275566	302	A	1.0	So precision weighting drives attention, for example, when we're talking about predictive processing.
2275678	2291350	303	A	0.99999	But in this case, Clark's claim is that when you have this kind of nested hierarchy of expectations, so you have temporarily extended expectations at the high level, unpacked into a kind of web of lower level action policies.
2291690	2301020	304	A	0.79	And precision waiting is kind of modulating the system's expectations about which of those policies are most likely to bring about the expected state.
2301470	2307178	305	A	1.0	You get something that looks a lot like motivated directed action.
2307354	2321778	306	A	1.0	And agency is kind of inherent in this model because the system rather has to model itself as a cause of those expected states.
2321864	2332598	307	A	0.69	So if I have these high level expectations, I, in a very inherent way, have to model my own cause or efficacy to bring about those states.
2332764	2343654	308	A	1.0	So on a very low level, the system has to model some form of agent because I can be the cause of change to my own sensory states, so I can cover my own eyes and so on and so forth.
2343782	2351958	309	A	0.98	So kind of on this view, agency is a latent variable in these systems when it's making these predictions.
2352054	2354182	310	A	0.91	So it just kind of turns up.
2354336	2363498	311	A	0.99	And Clark argues that you essentially end up with something that looks very much like agents on the folk psychology.
2363674	2374206	312	A	0.99996	But he thinks this is a better view because we end up with a, quote, different and arguably much more unified internal architecture trading in a single currency.
2374318	2378910	313	A	1.0	So Clark thinks, look, okay, Klein's worry is we have this one primitive.
2378990	2384802	314	A	1.0	We have just prediction, and the concern is that we're not going to be able to explain agential action.
2384866	2391346	315	A	0.99992	But actually there are ways that we can appeal to the hierarchical structure of the model and precision weighting.
2391458	2395260	316	A	1.0	And it turns out that this is a much more elegant picture as well.
2395950	2407120	317	A	0.99986	But Klein might press the worry, and anybody listening might kind of think, well, we've kind of done some work there, but why do we expect the things that we expect in the first place?
2408530	2415854	318	A	1.0	So why is my long term expectation to attain a PhD and not to join the French Foreign Legion, for example?
2416052	2419300	319	A	0.99747	What means that I expect one thing rather than another?
2419750	2425380	320	A	1.0	And here Clark just bites a bullet and says, nobody can explain that.
2425750	2431266	321	A	0.69829	We've kind of shifted to talking about questions about spookier, questions about free will.
2431368	2440440	322	A	0.62	And Clark says, look, if this is what you want, if this is what you're demanding, then you have to recognize that simply appealing to folk psychology doesn't get you that either.
2442730	2450220	323	A	0.99897	People with these kinds of worries need to be careful in how much they demand from the active inference agent.
2450750	2460910	324	A	0.57	And I think the real answer to that question actually, this is more speculative, but the real answer to that, a deeper answer to these kinds of questions will lie in the kinds of things that we're going to look at in subsequent weeks.
2461060	2481640	325	A	1.0	So, for example, the reason I have the expectation to attain a PhD rather than join the French Foreign Legion is because I exist in a particular kind of sociocultural landscape with specific norms, and a lot of my actions and beliefs are tempered and shaped by the expectations of people around me.
2483370	2485110	326	A	1.0	So this is just an overview.
2485450	2487640	327	A	0.87	We went over the dark room problem.
2488490	2497478	328	A	1.0	Why do we do anything at all if it's all about certainty and prediction error minimization this worry?
2497574	2502070	329	A	1.0	I said you can kind of highlight two aspects of this worry.
2502150	2506718	330	A	1.0	One is an actual account of agency under active inference, which we have.
2506804	2516058	331	A	1.0	We have this Andy Clark model of agency to do with hierarchical nested, unfolding action policies over time and different precision mappings.
2516234	2519806	332	A	0.77	And then we have this worry about the relationship with folk psychology.
2519918	2526254	333	A	1.0	So how do we describe agential behavior, motivated behavior?
2526302	2531910	334	A	1.0	How do we describe the behavior of agents if we only have recourse to prediction?
2533930	2542962	335	A	0.93	And as we saw, there's one argument here is that actually active inference, the formalisms can accommodate this belief desire distinction.
2543106	2548890	336	A	0.91	And the other move that I really like is to just say, look, folk psychology is just this instrumental tool.
2548960	2561258	337	A	0.94	It is, in effect, it's part of the sociocultural landscape that we use to shape each other's expectations by putting these labels to explain our actions.
2561434	2563760	338	A	0.60495	It's a kind of form of active inference itself.
2564690	2580920	339	A	1.0	So there's this kind of philosophically interesting debate about folk psychology, but it turns out that everything's okay and active inference agents are in fact agents with beliefs, desires and hopes and dreams and so on.
2582410	2583206	340	A	0.99798	Okay?
2583388	2584630	341	A	0.5945	That's agency.
2585690	2587240	342	A	0.84318	We're making good time.
2591210	2591718	343	A	0.98748	Okay?
2591804	2602554	344	A	1.0	So in this section I'm going to introduce quite a lot of stuff, but it's going to be all tied together hopefully rather neatly in the case study.
2602592	2606042	345	A	1.0	At the end, I'm going to talk about alistasis and emotion.
2606186	2610880	346	A	0.75536	I'm going to say very briefly a little bit about the self as well.
2612930	2615694	347	A	0.98655	Here's some examples of some of the core readings I've used.
2615732	2619940	348	A	0.99998	Again, these are all going to be up in the document as well, which will be made available.
2620630	2623922	349	A	1.0	And I thoroughly advise you to just have a browse through these.
2623976	2626020	350	A	0.99606	There's some really interesting stuff there.
2626390	2641790	351	A	0.96876	I'm not going to talk about psychedelics or meditation or depersonalization, but there is some really cool active inference literature on those topics as well, particularly papers on psychedelics and ego dissolution by George Dean.
2641970	2651194	352	A	0.87	A new paper just came out by Sipolito jonas Mago and Robert Carhartt harris and I think Fernando Rosas as well.
2651232	2655580	353	A	0.99	I think I might be mistaken on the authors there, but it's a very new paper.
2657150	2665310	354	A	0.99853	Okay, so the, the thing that is going to underpin a lot of what I'm now going to go on to say is going to be this notion of alistasis.
2666690	2673502	355	A	0.89	And this plays a major role in a lot of work on emotion and the self in active inference.
2673646	2688802	356	A	0.59691	Lisa Feldman Barrett, whose theory of emotion we're going to look at in a second, has argued that the brain's fundamental purpose, what it evolved to do through that imperative to minimize prediction error, is to manage the body's metabolic budget.
2688866	2694620	357	A	1.0	So the first prior is kind of our most expected state.
2695150	2706158	358	A	1.0	The first prior in the sense of our strongest prior, prior probability, our highest expectation is to have good allostatic control.
2706244	2707662	359	A	0.99158	But I'm getting ahead of myself there.
2707716	2714734	360	A	1.0	All that means is that we're balancing our body's metabolic budget or like energy budget in an effective way.
2714932	2722718	361	A	1.0	So error signals, like I said before, that are highly precise are those that are weighted very highly.
2722894	2731390	362	A	1.0	So prediction error signals that have high precision weighting are the synaptic gain on those error signals is going to be increased.
2731470	2740600	363	A	0.76	And that's going to drive learning, which means in future our expectations around those kinds of error signals is going to be we're going to pay more attention to those.
2741710	2751306	364	A	1.0	And the most highly weighted error signals that we're going to get are to do with our own homeostatic set points within our own body.
2751488	2768354	365	A	0.95	So if my temperature started to rise rapidly, my body temperature started to rise or drop rapidly, that prediction error signal, the violation of those expectations is really going to grab my attention and I'm going to do something about it.
2768552	2776398	366	A	0.94	And one way that we maintain these homeostatic states is through the body's own autonomic reactions.
2776574	2781826	367	A	0.9	So were I to start getting very cold, I would probably start to shiver.
2781938	2788760	368	A	0.55	And so the body is trying to kind of rectify those deviations from homeostatic set points.
2789450	2796694	369	A	0.99993	But another thing that organisms engage in, and humans do this to really remarkable degrees.
2796742	2809850	370	A	1.0	And again, this is going to be something that I suspect is going to come out in the subsequent weeks, is that we engage in quite complex and sophisticated anticipatory actions to maintain homeostasis.
2809930	2812350	371	A	1.0	And this is something called allostasis.
2812850	2822686	372	A	0.78	So allostatic control, which I mentioned earlier as this first prior, is essentially the regulation of homeostasis through action.
2822798	2828954	373	A	1.0	So it's actions that I can take to ensure that I stay within those important bounds.
2829022	2835400	374	A	0.73	So shivering is good, but living in a house with central heating is better.
2836010	2849580	375	A	1.0	Having a warm bed and living in a community where we've had these people of kind of engineers have worked to create a kind of material environment that acts as a kind of background support to a lot of these needs.
2851150	2855274	376	A	0.99993	Something that's another important concept here is allostatic load.
2855402	2859966	377	A	1.0	So this is essentially the result of not having good allostatic control.
2860068	2873186	378	A	1.0	So again, allostatic control is just engaging effectively in actions that are maintaining those set points, whereas allostatic load is the physiological costs to the agent of losing that control.
2873368	2885286	379	A	1.0	So there's so many studies here that have just shown the immense physiological costs of operating beyond those set points and not having good control.
2885388	2898778	380	A	1.0	So allostatic load has been linked with reduced cardiac health, sleep problems, gut issues, mental health issues, depression, basically everything.
2898864	2908480	381	A	0.94481	It's really, really bad and so good allostatic control is very important and as we're going to see, it, underpins quite a few very important things.
2911170	2921458	382	A	0.99	So really we could dedicate a whole hour to looking at emotion, but I'm going to blast through it very quickly right now.
2921544	2933030	383	A	1.0	And this slide, I should say one of the core readings on the document and the reading that I'm basing this on is Lisa Feldman Barrett's 2017 paper, the Theory of Constructed Emotion.
2935450	2944220	384	A	1.0	The main idea here is this is one of those theories that on the face of it, it seems quite simple, but actually there's quite a lot of subtlety and nuance to it.
2944830	2950682	385	A	0.77007	Allostatic control means inferring the causes of changes to the body's internal state.
2950816	2961038	386	A	0.7	So in other words, if I want to keep good allostatic control, I need to know not just what's going on out there, but I need to know what's going on inside me as well.
2961124	2961422	387	A	0.81183	Okay?
2961476	2965406	388	A	1.0	So if there's some crucial change happening, I need to be on top of it.
2965508	2974274	389	A	1.0	And this happens through exactly the same process as the same predictive error, minimization process that I'm engaging with with the outside world.
2974392	2984978	390	A	1.0	So the brain is making predictions about its own internal states and then it's going to engage in some kind of action to minimize any prediction errors.
2985074	2987682	391	A	1.0	And these prediction errors are going to be very highly weighted.
2987746	2988840	392	A	0.99706	They're very important.
2989770	2991962	393	A	0.99999	But here's an interesting thing.
2992016	3002838	394	A	0.7	So there was a very unethical experiment done by Shaktor and Singer, I think in the 60s, who they were emotion researchers.
3003014	3009594	395	A	1.0	And they conducted an experiment where they injected subjects without the subject's knowledge.
3009642	3018446	396	A	0.96	I think they injected them with adrenaline and then they exposed the subjects to different stimuli.
3018558	3024146	397	A	0.98	So some subjects were exposed to one type of stimulus and some subjects were exposed to another.
3024328	3042858	398	A	1.0	And even though the subjects had essentially been pushed to have the same, to experience the same physiological changes in their body, they reported different emotional, different kinds of feelings, depended on depending on the stimulus that they'd been exposed to.
3043024	3046058	399	A	1.0	So this highlights something really important.
3046144	3050938	400	A	0.67	And again, I feel compelled to say that I am moving through this incredibly quickly.
3051024	3052940	401	A	0.98919	There's so much to say here.
3053390	3073102	402	A	0.99996	But the nub of it is this in order to keep good allostatic control, in order to know what to do, the brain needs to contextualize those changes in the body because there's not a one to one mapping between changes in the body and an external stimulus.
3073246	3080340	403	A	0.9	So sometimes changes, physiological changes in our body are about something in the world, they're a response to something.
3081030	3091814	404	A	1.0	And it's very, very important that the brain is kind of taking a confluence of those inputs to try and contextualize, okay, what's actually happening and what do I need to do?
3091932	3103210	405	A	1.0	So an example of this is if you imagine running into a bear while you're hiking in Wyoming, which is something that's actually happened to me, I've experienced it, it's terrifying.
3103550	3108240	406	A	0.99	And you imagine going on a scary or a date that you're really nervous about.
3109570	3115646	407	A	1.0	The physiological changes that are happening in the body are, give or take, more or less the same.
3115748	3120820	408	A	1.0	So perspiration, elevated heart rate, breathing changes.
3121990	3125986	409	A	1.0	So the underlying physiological footprint is very, very similar.
3126168	3131958	410	A	0.99982	But what you need to do to manage that situation, the apt action, is very, very different.
3132124	3145274	411	A	1.0	And so the claim here, the kind of revolutionary claim in a way, is that emotions, the things we experience subjectively, are constructions, just like percepts are.
3145392	3156398	412	A	1.0	So just like my experience of the car when I step outside my flat, is a construction that explains away the prediction error and gives me a cleaned up picture of the world.
3156564	3158494	413	A	0.99974	Emotions are essentially doing the same thing.
3158532	3170042	414	A	0.94047	They're explaining away these prediction errors and telling me this is the best explanation of these changes within your body contextualized against this external stimulus.
3170106	3178398	415	A	1.0	So in the case of the date, the apt action is to chill out and be normal to a certain extent.
3178494	3181650	416	A	0.99	And in the case of the bear, you get the hell out of that.
3181720	3183342	417	A	0.99913	Although, interestingly, you don't.
3183406	3185574	418	A	0.97386	Running away from a bear is a terrible idea.
3185772	3193340	419	A	0.77	You should not turn your back and run away, but you get the idea that it's going to be, what you should do in each situation is completely different.
3194910	3212414	420	A	0.99	So that's emotion for the active inference agent and something I don't want to lose here is what you get with this is really kind of cool because it turns out emotions and subject we're kind of moving into subjectivity here.
3212532	3219534	421	A	1.0	It turns out emotions are really they're just part of the same cognitive architecture.
3219582	3220994	422	A	0.61	So there's no difference here.
3221032	3224814	423	A	0.99996	There's no dualism between his thinking and his emotion.
3224862	3229846	424	A	0.9	And emotion is this kind of fuzzy stuff that we're not really interested in.
3229948	3235218	425	A	0.99999	Actually emotion, subjective embodied feeling is core.
3235314	3248582	426	A	0.94597	It's absolutely vital to understanding how we maintain this allostatic control and how we engage in adaptive behaviors and how we remain gripped to our affordances in the environment.
3248646	3252620	427	A	1.0	And the notion of grip is going to be something that comes up again very soon.
3255890	3263520	428	A	0.99	So very briefly, because this is something that I've really already talked about, but I want to put a slightly different spin on it right now.
3264850	3271726	429	A	0.51864	I've already said that allostatic control for humans can involve very, very temporarily extended timescales.
3271758	3275278	430	A	1.0	And we saw this with Andy's model of agency.
3275454	3292134	431	A	1.0	So if you think about something like saving into a retirement fund, for example, we're doing something that the idea is that maybe decades from now is going to kind of minor spikes in prediction error called the disappointment of not having as much money right now is going to pay off later.
3292332	3298810	432	A	1.0	These are the kind of things that humans engage in and our generative models have to be temporarily thick.
3299230	3304598	433	A	1.0	So George Dean writes that the levels of temporal extension are hierarchically interlocked.
3304694	3310746	434	A	0.57	So shorter timescales inform expectations of what the agent can do over longer timescales.
3310858	3320020	435	A	1.0	So these different levels of the hierarchy are in a kind of dialogue with each other telling you what kinds of things are possible and what kinds of things you should expect.
3320550	3336360	436	A	0.96	And when we were talking about agency, we talked about the way that agency is kind of baked into active inference because in order for any of this to work, the system has to have as a hypothesis, I can do things okay?
3337050	3346970	437	A	0.95	And this is more or less taken to be the same thing that underpins the sense of self under active inference.
3347310	3353570	438	A	1.0	So the system implicitly infers its own ability to bring about intended sensory consequences.
3353750	3365070	439	A	0.82	And so Dean writes here, quote in Pristine it is in this sense that implicit in a model of sampling is a representation or sense of agency.
3366230	3373090	440	A	1.0	So a minimal sense of self, it's kind of like the flip side of agency comes baked in here.
3373160	3381362	441	A	1.0	So one has to model oneself as a potential cause of sensory inputs.
3381506	3392860	442	A	1.0	So George Dean and colleagues, I think George Dean, Mark Miller and Sam Wilkinson propose a model of the self under active inference called the allostatic control model.
3393870	3402598	443	A	1.0	And the move they make here is that we have to recognize that it's not just our self efficacy that has to be modeled.
3402694	3407790	444	A	1.0	We also have to have some kind of idea in there of how we're actually doing.
3407860	3413390	445	A	1.0	So we have to model our own capabilities in order to set precision waiting on future action.
3413890	3424094	446	A	0.75	So we don't simply infer that we can be the cause of sensory states, but also infer our own capabilities to successfully bring about expected states at longer time scales.
3424222	3430840	447	A	1.0	So the phrasing that they use is tracking the performance or fitness of the model over time.
3431210	3439138	448	A	0.99	So part of that tracking is going to be affective and emotional.
3439234	3441042	449	A	0.99	And so there are strong links.
3441106	3444460	450	A	0.93964	We're kind of really digging our hooks into subjectivity at this point.
3446910	3470660	451	A	0.96213	But the claim with the Allostatic Control model is you get this rather than just a minimal self, you actually get a longer term phenomenological self emerge from these interlocking timescales, which are modeling not only the agent's own causal efficacy, but also modeling how good your own model is at doing what you need it to do.
3471750	3482054	452	A	0.84	And like I said, I said when I was talking about the reading and I want to flag this again because I'm really not doing justice to this in the way that I should.
3482172	3500406	453	A	1.0	But this has formed the basis for a lot of really interesting work on phenomena like depersonalization on the role of psychedelics and the potential for psychedelics in therapy and in meditation, ego dissolution and kind of that kind of stuff in meditative settings.
3500518	3511870	454	A	1.0	So anybody with any interest in the self or in those kinds of practices should definitely go and give a closer look to these readings that I'll make sure in the document.
3513730	3516000	455	A	0.99918	Okay, so quick overview here.
3516390	3524020	456	A	1.0	So active inference agents maintain homeostasis through anticipatory action, and this is something we call Allostatic Control.
3524390	3530740	457	A	1.0	To do this, the system must engage in interceptive prediction over its own internal states.
3531130	3535186	458	A	0.98811	Actually, I think I've got time to do this, so I'll just deviate slightly.
3535378	3541550	459	A	1.0	The topic of interceptive inference is really interesting in the context of active inference.
3541650	3548278	460	A	1.0	So I want to flag work by Sarah Garfinkle, who I believe is at UCL, who used to be at Sussex.
3548454	3565882	461	A	1.0	And Professor Garfinkle's work looks at the central importance of interceptive predictions in various psychopathologies, especially, I think she's looked very closely at PTSD and anxiety disorders.
3566026	3582550	462	A	0.99	And it turns out that an agent's accuracy in their interceptive predictions is a good indicator as to the kinds of symptoms that they're going to like, the strength and severity of their symptoms in these kinds of disorders.
3583050	3594214	463	A	0.73	And what she's shown is that if you can increase the accuracy of interceptive predictions, this forms the basis of treatment for these symptoms.
3594262	3598838	464	A	1.0	So in short, the better you are at interceptive predicting.
3599014	3607514	465	A	1.0	I think one of the measures that they use there in her lab is how well people can track their own heartbeats without feeling their pulse.
3607562	3623150	466	A	1.0	So if you just sit there and try and say, like, my heart's beating like this, then the more accurate you are and the more any training you can be given to be more accurate, it forms the basis of effective treatments for these kinds of symptoms.
3623310	3636680	467	A	0.69	So I just wanted to flag that because the world of research in interceptive inferences large, diverse, vibrant, super interesting and very much worth our time.
3637690	3638726	468	A	0.99697	Okay, where was I?
3638748	3639222	469	A	0.99803	Here.
3639356	3646266	470	A	0.77181	Okay, so to maintain all the static control, the system has to engage in interceptive prediction over its internal states.
3646448	3663082	471	A	1.0	And then to best explain changes in those internal states, the system has to contextualize those changes against some extraceptive input and that emotion categories serve that role.
3663146	3668050	472	A	1.0	So just to be very clear, on this view, emotions are constructions.
3668470	3678210	473	A	0.96615	There are some important deviations from other theories of emotion here, particularly what Barrett calls the basic theory of emotion.
3678810	3685714	474	A	0.98	So on her view, emotions themselves have no underlying kind of essence or neural footprint.
3685842	3690230	475	A	1.0	And there's an ongoing live debate there as well between these theories.
3693800	3703504	476	A	0.98	And also just at the end, the good allostatic control in human agents is this very temporarily thick phenomena.
3703552	3717850	477	A	1.0	So we engage in very long term planning that involves a lot of the kinds of counterfactual representations that we talked about with the axial constant paper and this is hypothesized to form the basis of our phenomenological sense of self.
3719600	3726812	478	A	0.99566	Okay, we're up to an hour good.
3726946	3728430	479	A	0.66966	We're running on time.
3729360	3735052	480	A	1.0	This is the final section and it's probably going to be probably going to be the longest section.
3735196	3750196	481	A	0.96928	What I want to do here is I want to try and pull together some of the things I've been talking about because it's been very fast and very abstract and I want to try and pull some of these things together in a slightly more concrete example.
3750298	3752960	482	A	1.0	So the case study I'm going to use is addiction.
3753120	3768490	483	A	1.0	So there's a particular account of addiction in the predictive process in literature that I think in a very succinct, sharp way highlights a lot of the things I've been talking about and puts them within a context that is quite stark and easy to understand.
3769680	3781740	484	A	0.9997	But in order to do that, I'm going to have to introduce a new, slightly more difficult to understand mechanism within the framework that crops up in a lot of the predictive process in literature.
3781900	3787868	485	A	1.0	And what this is going to do hopefully as well, is give us a direct bridge to phenomenology.
3787964	3800950	486	A	1.0	So when we talk about things like neurocomputational phenomenology, the things I'm going to be talking about here have underpinned a lot of the work in that area.
3802360	3809928	487	A	0.67	So these are some of the readings we're going to look at some work by mostly a lot of the papers we're going to look at.
3810094	3814420	488	A	1.0	First author mark Miller or Mark Miller's been second or third author.
3814500	3826072	489	A	0.71	And I bring that up because in the discussion section on the 25th when we have an hour to kind of unpack and answer people's questions we're actually going to be joined by Mark Miller.
3826136	3834370	490	A	1.0	So if anybody has any specific questions about the things I want to talk about now in this section, he's going to be the man to answer those.
3835780	3842130	491	A	0.99997	But also I'm going to put a lot of secondary readings up again in the document so you'd be able to find them all there.
3843380	3848660	492	A	0.99756	Okay, so let's switch gears slightly.
3850520	3863924	493	A	1.0	I want to keep the focus on feelings, although what I'm going to be talking about here are not what might be called like full blooded emotion states, but I want to talk about something a little bit more subtle.
3864052	3878284	494	A	1.0	So one thing that might seem really obvious, kind of so obvious that we often overlook it when things are going okay, is that it generally feels like something to be an agent.
3878482	3886450	495	A	1.0	So when we're going about whatever business we have in the world, we always feel like something.
3887060	3890352	496	A	0.64	And it's not entirely clear how best to characterize that.
3890406	3899956	497	A	1.0	So I want to draw on some work in phenomenology that some active inference theorists have also drawn on and made use of.
3900058	3905430	498	A	0.59148	Because I think this is a really good grounding for some of the things I'm going to go on to say.
3905880	3910280	499	A	0.99992	Certainly proved to be a good grounding for some of the work that I'm going to highlight.
3910620	3915892	500	A	1.0	So these are two books by Matthew Ratcliffe.
3915956	3929160	501	A	1.0	I think he's at the University of York and has done really, really cool work in kind of really getting to grips with the what it's likeness to live in certain conditions.
3929320	3944260	502	A	0.97	And Ratcliffe, he argues that he's identified this certain area, this space of feelings that have been largely neglected in the wider literature, and he describes these as existential feelings.
3944760	3957912	503	A	1.0	So he says existential feelings are, quote, they are not intentional states directed at however many objects, and they are not feelings of the body or some part of it.
3958046	3961480	504	A	1.0	Instead, they amount to a felt sense of belonging in the world.
3961630	3970536	505	A	0.64	So the main difference between a full blooded emotion state and an existential feeling is that the emotion state is about something.
3970718	3978412	506	A	0.95	So if I'm disgusted, I'm typically all the time I'm disgusted about something in the world.
3978546	3981010	507	A	1.0	So emotions are intentional in that way.
3982340	3989744	508	A	0.20531	Ratcliffe elaborates on existential feelings by I'm going to quote this at length because I quite like it.
3989782	4017210	509	A	0.99999	He says people sometimes talk of feeling alive, dead, distant, detached, dislodged, estranged, isolated, otherworldly, indifferent to everything, overwhelmed, suffocated, cut off, lost, disconnected, out of sorts, not oneself, out of touch with things, out of it, not quite with it, separate, in harmony with things, at peace with things.
4017520	4036050	510	A	0.999	There are reference to feelings of unreality, heightened existence, surreality, familiarity, unfamiliarity, strangeness, isolation, emptiness, belonging, being at home in the world, being at one with things, significance, insignificance, and the list goes on.
4036740	4044444	511	A	0.94	So this is really, really cool work and I recommend everybody to go and read Matthew Ratcliffe.
4044492	4045676	512	A	0.99999	But some of the work.
4045718	4060376	513	A	1.0	I really like in predictive process, in an active inference, has taken this idea of an existential feeling and what they've recognized is that these kinds of feelings are really about how we are orientated in regards to the world and the affordances in it.
4060398	4064484	514	A	1.0	So they're background bodily states of action readiness.
4064612	4071612	515	A	1.0	So how are we relating to how do we find ourselves in relation to the world?
4071746	4077352	516	A	1.0	So we're talking about the general structuring that's present in our everyday phenomenology.
4077496	4090930	517	A	0.95	So I really want to make that clear that what this work is doing is building a bridge between computational models and the way even the underpinnings of those models in neurobiology and phenomenological experience.
4092660	4101520	518	A	1.0	So the thing that I need to introduce, and this can be, it's fairly straightforward, but it can be a little bit tricky at times, is this notion of error dynamics.
4101680	4103030	519	A	0.9	This is really important.
4103400	4120456	520	A	1.0	So like I just said, aerodynamics is going to provide this conceptual bridge between different levels of analysis and it elaborates on how systems are sensitive to the success or failure of their own action policies unfolding across multiple timescales.
4120568	4138160	521	A	1.0	So the recognition here is that we talk a lot about action policies and expected states, but the reality is that we have a multitude of goals and action policies and expected states that are interlocking, overlapping, constantly shifting.
4138580	4140124	522	A	1.0	The picture is messy.
4140252	4154416	523	A	1.0	And so I like this quote from the 2019 paper that says the roller coaster of continual increases and decreases of errors that accompany life become expected and are folded into our expectations.
4154608	4166420	524	A	1.0	For such a system it becomes important not only to track the constantly fluctuating instantaneous errors, but also to pay attention to the dynamics of error reduction over longer time scales.
4166580	4182428	525	A	1.0	So the systems, the upshot of this is that these authors believe, building on some other work in computational modeling, that systems must track the rate of change in overall error reduction relative to the system's expectations.
4182604	4189804	526	A	1.0	So this is the kind of global upwards or downwards trend in prediction error.
4189932	4194900	527	A	0.99987	That's what the system is sensitive to, how that relates to the expectations.
4196840	4209544	528	A	1.0	So the idea here is that aerodynamics provide a system with a much broader ongoing sense of how they're doing to their multitude of goals over time.
4209742	4217540	529	A	0.99	So a big step here is that those changes in the rate of reduction feed back into the system.
4217630	4224472	530	A	1.0	So they're folded back within the system and they serve the role of modulating precision on action policies.
4224616	4237360	531	A	1.0	So let's say I'm engaged in some task, I have a particular expectation about how I'm going to do at that task and when I actually engage with the task, I do slightly worse than expected.
4238340	4249648	532	A	1.0	The idea there is that that rate of change, so the rate of error reduction is going to decrease until I'm reducing error worse than my expectations.
4249824	4259284	533	A	0.95	And in a typical healthily functioning system, that rate of change, the sensitivity to that rate of change is going to feed back and reset the precision weighting on those actions.
4259332	4273932	534	A	0.99	So it's going to reduce my confidence in that particular action policy such that I might try a different strategy, I might try a different tactic, or I might just throw whatever it is that I'm doing away and go and do something else.
4273986	4283500	535	A	1.0	So we're starting to see this picture of through expectations, sensitivity to change and feedback onto precision waiting.
4283660	4289052	536	A	0.95994	It's starting to dictate how I manage my action policies.
4289196	4295300	537	A	0.63	So there's this ongoing reciprocal relationship between aerodynamics and my future expectations.
4295640	4305204	538	A	0.87815	Now, crucially, the claim here is that on the subject level, all of this manifests as these existential feelings of some kind.
4305322	4315204	539	A	1.0	So the way that I feel on a kind of day to day basis is a reflection of how I'm doing in terms of these sensitivity to aerodynamics.
4315332	4331808	540	A	1.0	So when I fail at the task and precision waiting is down regulated on that particular action policy, the thing that actually kind of that moves me to go and do something else are my embodied feelings of frustration that I experience.
4331974	4339680	541	A	1.0	So as conscious agents, those embodied feelings are what are tuning us towards acting more effectively.
4340820	4348864	542	A	0.98	So optimal behavioral on this account is characterized as a feeling of grip towards a shifting field of affordances.
4348912	4350484	543	A	0.68	So I'm going to unpack this quickly.
4350602	4367760	544	A	0.99562	But the feeling of grip in a nutshell is just this feeling that we're engaging with our affordances in the best way that we can and that we're either meeting or exceeding our expectations for prediction error, minimization what they mean by a field of affordances.
4367860	4370350	545	A	1.0	And this is again really important.
4371360	4375608	546	A	1.0	A landscape of affordances is just the total opportunities in my niche.
4375704	4379448	547	A	1.0	So my landscape of affordances right now is Brighton.
4379624	4384050	548	A	0.69011	It's not really going to change very quickly unless I get on a plane and fly somewhere else.
4384900	4388144	549	A	0.99998	But affordances aren't neutral in that way.
4388182	4390370	550	A	0.93691	They don't just exist there.
4391060	4403044	551	A	0.95	The affordances that stand out to me as relevant or attractive is going to change quite rapidly depending on what it is I'm doing, on my internal state, on the context and so on.
4403082	4409636	552	A	1.0	So right now my water bottle stands out as attractive, a couple of keys on my keyboard stand out as attractive.
4409748	4414264	553	A	0.99998	But that's going to shift quite rapidly once this lecture is over and I turn to do something else.
4414382	4425390	554	A	0.99	So the idea of grip is that we exhibit a stability in our attunement such that we can remain attuned as that field changes.
4426320	4439840	555	A	1.0	And this is part of the skilled intentionality framework, which I won't get into because I don't want theoretical overload, but I've put some papers up on this slide as references and of course the reading will be in the document.
4440340	4449684	556	A	0.97892	But skilled intentionality refers to the selective openness and responsiveness to multiple relevant affordances in a concrete situation.
4449882	4460600	557	A	1.0	So it's just this recognition that things change quickly for multiple reasons and we really need to exhibit a kind of flexibility and stability in those engagements.
4461740	4467064	558	A	0.68	And aerodynamics has been applied in lots of very, very cool ways.
4467182	4479260	559	A	1.0	I can't recommend this work highly enough so aerodynamics, I won't run through how everything has been explained just for time reasons, but you can kind of take a look at this yourself.
4479330	4496448	560	A	0.95559	But aerodynamics has been proposed as a more complete answer to the dark room problem that we were talking about earlier, because it can explain the drive for exploration and curiosity, because it literally feels good to minimize prediction errors better than expected.
4496544	4500464	561	A	1.0	So again, that rate of change manifests as embodied feeling.
4500592	4505520	562	A	1.0	So we're always looking for opportunities to do better than expected.
4505680	4512632	563	A	0.94	And kind of this has been suggested to account for feelings of boredom, prompting us to go out and find new things to do.
4512766	4529516	564	A	1.0	And similarly, aerodynamics has provided a computational account of play, which has for a while has remained a kind of mystery because it's on the face of it like, why would we engage in play when it's metabolically costly and we need that energy for other things?
4529618	4533488	565	A	1.0	Like Lisa Feldman, barrett says managing energy is super important.
4533654	4536476	566	A	1.0	So why do baby animals burn?
4536508	4539440	567	A	1.0	It all engaging in playful behavior.
4539940	4543010	568	A	0.99723	Aerodynamics has a story for us there.
4543460	4550356	569	A	1.0	And there are also aerodynamics based accounts of happiness and well being and depression as well.
4550458	4552084	570	A	1.0	So I won't go into the details there.
4552122	4568110	571	A	0.52129	But it turns out that aerodynamics and this connection to phenomenology is this super malleable, flexible kind of feature of the framework that really underpins a lot of what we experience and do as active inference agents.
4569680	4576650	572	A	0.99731	Okay, so I'm going to talk a little bit about addiction.
4578750	4579754	573	A	0.99997	Got some time here.
4579792	4580860	574	A	0.99998	Things are going well.
4586370	4593198	575	A	0.63	So I had some options here because I wanted to use a case study that really brought out some of the things I was talking about.
4593284	4600610	576	A	0.63	And as I've just said, aerodynamics has been applied in a bunch of different areas and it's all very much worth talking about.
4600680	4624860	577	A	0.99582	But I chose addiction because, well, as you'll see, as I kind of make clear, I think it also brings out not just the way that all of this fits together, but also why it's good and why seeing people as active inference agents and broader structures as active inference structures is actually a worthwhile thing to do.
4625230	4629702	578	A	1.0	So addiction was once viewed as a moral failing.
4629846	4636266	579	A	1.0	So the kind of Victorian addict is too rotten to make the right choice, too self indulgent.
4636458	4642000	580	A	1.0	I say Victorian unless you're Peter Hitchens and then you still subscribe to this view.
4642930	4644718	581	A	0.99999	But that's the old fashioned view.
4644804	4652980	582	A	0.99993	There was something wrong with the addict, some moral or spiritual failing, and gradually that changed to what the dominant view is today, which is the disease model.
4653590	4671606	583	A	0.74	And the idea here is that addiction is a disease and that disease is characterized by changes in the brain, which changes to brain structures, which mean the addict can't help but act in a certain way when confronted with a certain stimulus.
4671718	4677014	584	A	1.0	So it's this loss of control that's engendered through these brain structures.
4677142	4680650	585	A	0.62	And this is the idea of it being a disease.
4683070	4700274	586	A	1.0	The work that I'm going to describe now, I won't go into too much detail here, but it's kind of founded on this thought that this disease model, it can't be quite right because these changes in brain structure, essentially that's what the brain does.
4700472	4701954	587	A	0.7485	It's just learning.
4702152	4703762	588	A	1.0	This is what we do all the time.
4703896	4716520	589	A	0.99996	Essentially, me completing my PhD is a process of me undergoing changes to my brain such that I'm kind of disposed to act in certain ways.
4718250	4728234	590	A	0.94	Mark Lewis I think it's Mark Lewis in his book 2018 The Biology of Desire, argues, look, addiction is more of just a dysfunction in learning.
4728352	4730166	591	A	0.99982	It's not really a disease.
4730358	4734090	592	A	0.95	So we need to think about it a little bit differently.
4734250	4740542	593	A	0.86	And this work by Miller and colleagues, 2020, that's where it picks up.
4740596	4740862	594	A	0.61476	Okay?
4740916	4747434	595	A	1.0	So the idea is that those brain changes engendered through exposure to a stimulus.
4747482	4749726	596	A	1.0	In this case we're going to talk about a drug.
4749838	4754958	597	A	0.96418	We're going to leave behavioral addiction aside for a second that clearly plays a critical role.
4755054	4764546	598	A	1.0	So nobody's going to deny the kind of chemical, like the importance of the biology here that's going on in the brain.
4764578	4768406	599	A	1.0	And of course, different drugs have different chemical profiles in that regard.
4768588	4781222	600	A	1.0	But on this view we're going to kind of shift focus from that slightly and we're going to have a much more active picture where we view addiction as a self organizing process of whole agent environment systems.
4781286	4791150	601	A	0.63446	Okay, so I have this extract here it is in the dynamic interaction between the agent and its environment that addiction is born and endures.
4791490	4802386	602	A	0.98	So the harm of addiction emerges from a breakdown in the broader stable dynamics that typically underpin a flourishing life work, family, friends, health, and so on.
4802488	4811042	603	A	0.94	So a typically flourishing life has a broad kind of bush of concerns over different timescales in different areas.
4811186	4816630	604	A	0.7	And what we're going to see is that the harm of addiction is in a narrowing of those concerns.
4819470	4837946	605	A	1.0	So what happens is when somebody takes a drug to some people who are exposed to drugs, that drug is going to, through direct action on some neural mechanisms, is going to signal to the agent that they've done better than expected at reducing prediction error.
4837978	4839434	606	A	1.0	Of course this is a losery.
4839562	4842938	607	A	0.82245	They haven't really done better than expected in anything that matters.
4843034	4848420	608	A	0.99511	But the signal they get is, wow, like, we have just reduced prediction error at this insane rate.
4849190	4864226	609	A	1.0	And repeated use through this aerodynamics mechanism, repeated use is going to tune our expectations about the kinds of prediction error slopes, the kind of slopes of prediction error that are available to us in the environment.
4864338	4871830	610	A	1.0	And we're going to start to expect those vertiginous slopes of error reduction if we continue to engage with the drug.
4871990	4880326	611	A	1.0	And once those expectations become deeply ingrained, anything else we do is going to start to feel like failure.
4880518	4894720	612	A	0.97	So if I get used to taking cocaine all the time and then I have to sit through a family meal where I don't have any drugs and I have to kind of sit still and there's no dopamine available, I don't have my phone.
4895490	4902978	613	A	0.99305	I'm going to experience that as feelings of frustration and as if I'm being prevented from doing something I want to do.
4903144	4906766	614	A	0.77	And I'm going to experience that as doing worse than expected.
4906878	4914050	615	A	1.0	So I've learnt these expectations for prediction error minimization and I'm not getting them unless I engage with the drug.
4914130	4922502	616	A	1.0	And of course, it's worth noting that in many cases, these drugs are going to have chemical withdrawal effects that compound that as well, especially things like nicotine.
4922566	4924774	617	A	1.0	And alcohol in particular is very nasty.
4924822	4929002	618	A	1.0	So alcohol can kill you if you try and withdraw from it too quickly.
4929056	4932906	619	A	1.0	So they really do pull the agent into a grip.
4933098	4937130	620	A	1.0	So what happens here is the agent develops a kind of suboptimal grip.
4937290	4942330	621	A	1.0	So you start to enact a new world, a new identity.
4942410	4958194	622	A	1.0	So instead of doing all the things you once cared about, like different hobbies, you start to hang out with different people, you start to frequent different places, like a dealer's house or wherever, and very slowly you start to carve out essentially a niche.
4958322	4965570	623	A	1.0	The addict enacts a particular niche through their actions and they have quite a good grip on that niche.
4965650	4970090	624	A	0.58606	It's just that it doesn't speak to a broader array of concerns.
4970750	4986590	625	A	0.94	So what's really important is that this pushes back against the disease model, because on this view, the active inference agent, well, the system is doing essentially what it was evolved to do.
4986740	5001410	626	A	1.0	So there's another quote from the paper here that I like that says their habits allow them to remain well attuned and keep prediction errors under tight control so long as they remain within the narrow confines of such a niche.
5003110	5010342	627	A	0.92	And this is important because it shows that allostatic control and prediction error minimization are not the same thing.
5010396	5011154	628	A	0.99988	They come apart.
5011202	5019626	629	A	1.0	And this really speaks to a question that was asked after Avil session recently about what does prediction error actually look like?
5019728	5039866	630	A	0.99998	Well, in this case, you have a system that has learned that engagement with certain affordances gives it an illusion, but it has this feedback that says, this is the state you expect to occupy, or this is the state that the agent has learned to expect to occupy.
5039978	5046242	631	A	1.0	And it's carved out a niche of affordances that means it's very likely to occupy that state.
5046296	5048980	632	A	1.0	So it actually has a really good grip on the situation.
5049350	5069900	633	A	0.99972	It's just that that niche is very narrow and it's constricted, meaning it's simply those habits and that web of habitual action policies are just not well suited to maintain good allostatic control.
5073420	5077080	634	A	1.0	So everything else in the addict's life starts to suffer.
5077900	5082168	635	A	1.0	So we can kind of think of this as a form of niche construction gone wrong.
5082254	5086270	636	A	0.65	And I think we're going to look at niche construction in the coming weeks as well.
5087600	5091532	637	A	0.96	So why is this whole agent well, so I should say, just to back up a second.
5091586	5097116	638	A	0.63	So what I like about this account of addiction is that it's a thoroughly inactive account of addiction.
5097148	5101916	639	A	1.0	It really brings out the kind of inactive core of active inference.
5102028	5106156	640	A	1.0	So the addict is addiction becomes an identity.
5106268	5111056	641	A	0.6	It becomes a world that the person actually produces through their actions.
5111168	5122248	642	A	1.0	So rather than the disease model where you have a person and a stimulus and exposure, whenever they're exposed to that stimulus, they're going to have problems because of these brain changes.
5122414	5126120	643	A	1.0	What this does justice to is actually the activity of the agent.
5126270	5139230	644	A	1.0	So they're not accidentally bumping into this stimulus in the environment and they're not just seeking it out, but they're deliberately restructuring their environment to make this state more and more likely over time.
5139760	5152848	645	A	0.88	So it really does justice to the efficacy and the agency of the agent rather than giving that agency a more backseat role that it takes in the disease model.
5153014	5161264	646	A	1.0	But the other thing that it does, because it's this inactive picture, is that it also does justice to the environmental features.
5161392	5168196	647	A	1.0	So it kind of speaks to the fact that addiction is not just all in the head.
5168378	5178184	648	A	0.99999	Actually, some of the problems of addiction come with the fact that it is this procedural, constructive process.
5178382	5185224	649	A	1.0	And one of my favorite experiments of all time is I don't know if people are familiar with the Rat City experiments.
5185272	5187230	650	A	1.0	This is why I've got the image up here.
5187680	5202876	651	A	1.0	And this was a very cool experiment where originally it was found that if you exposed rats to a drug laced stimulus in the environment, I think it was heroin laced water, or it might have been cocaine.
5202988	5213392	652	A	1.0	But the original experiments found that nearly all the rats would kill themselves with the drug, so they would just keep at the drug until they died.
5213456	5223992	653	A	1.0	And it was a very high percentage of the rats would engage in that destructive behavior until the experiments were rerun some time later.
5224126	5236504	654	A	0.8	And instead of having the rat just in a boring cage on its own, it had the rats in Rat Park, which was a very social, exciting, brightly colored environment with lots of different affordances.
5236632	5244056	655	A	1.0	And what they found was that given the same choice, a vastly reduced proportion of the rats would choose to engage with the drug.
5244168	5251504	656	A	0.79829	Okay, so it's capturing the importance of niche construction that I think is really nice here.
5251622	5257768	657	A	1.0	And it also speaks to the role played by embodied affect in phenomenology.
5257964	5262640	658	A	0.9582	There's something that it's like to be an addict and that really matters.
5262800	5276344	659	A	1.0	It really matters that the addict has these embodied experiences when they're engaging with particular sets of affordances so that's really summed up in the overview that I've put here.
5276382	5278920	660	A	0.95	So these were the things that I wanted to emphasize.
5279660	5282728	661	A	0.99958	Active inference agents are embodied.
5282824	5284780	662	A	0.99894	They're embedded in a landscape.
5285200	5288888	663	A	0.99997	That landscape is constituted by particular affordances.
5288984	5294152	664	A	0.99	And we can distinguish between a landscape of affordances and a field of affordances.
5294216	5306610	665	A	0.92	And that distinction really speaks to the inherent affectivity and normativity of affordances, which affordances stand out to us at a particular time, which exert a pull over us.
5307160	5311008	666	A	0.68	And active inference agents enact their worlds through action.
5311104	5314100	667	A	1.0	And this is nowhere starker than in the case of addiction.
5315800	5318400	668	A	0.99964	Active inference agents are effective.
5318480	5330730	669	A	1.0	So emotion plays this super crucial role, keeping us tuned, keeping us in that grip with our affordances, and helping us contextualize those important physiological changes.
5331920	5335180	670	A	0.99868	Active inference agents are agents, okay?
5335250	5346972	671	A	1.0	So we do have a way to describe behavior as agential and motivated, and we do have these cognitive architectures that can make sense of agential action.
5347116	5353330	672	A	1.0	And active inference agents have this inbuilt sense of self that comes with agency as well.
5354820	5356576	673	A	1.0	So that's pretty much it.
5356678	5360644	674	A	1.0	This final slide just goes over some of the things that we can expect.
5360762	5370400	675	A	1.0	So what I've done today, I hope, has laid a good groundwork and has installed some higher level expectations to learn more about active inference.
5370560	5384380	676	A	1.0	And what we're going to do in the subsequent weeks is now scale this up to see how when you have more than one active inference agent together, how the expectations of some can impact the expectations of others and individuals.
5384800	5388380	677	A	1.0	And I look forward to learning more about that.
5388450	5391550	678	A	0.99835	But as for me, that's it.
5395430	5395986	679	B	0.99981	Amazing.
5396088	5397700	680	B	0.81358	Ben, awesome work.
5398070	5404546	681	B	0.50267	What can people look forward to next week or in two weeks if they join the discussions section?
5404578	5407430	682	B	0.94	Like, what's it going to be like or who would you encourage to join?
5408810	5412102	683	A	0.88473	Definitely, I mean, the more people that come along, I think the better it's going to be.
5412156	5413914	684	A	0.96222	I'm really looking forward to it.
5414032	5419254	685	A	0.73592	I'm kind of just in the first place, intrigued to see we covered so much ground.
5419302	5424830	686	A	0.99972	I'm just interested to see where people want to go with this and see where people's interests lie.
5425410	5435914	687	A	1.0	I assume that people are going to have questions, and I think maybe the best way to do it would be to explore some of people's questions during the discussion.
5435962	5447640	688	A	1.0	We can use them to kick things off and keep things going, but I think it's likely that we have a whole hour, so we've certainly got time to really dig into things in some detail.
5448010	5452134	689	A	1.0	And like I said before, we're going to have Mark Miller with us.
5452252	5463866	690	A	0.61	And Mark is just awesome in discussion, very passionate and enthusiastic about his work, and he can do a much better job than I can in explaining it.
5463888	5470060	691	A	0.98	So just to have the opportunity to speak with Mark about his work, I would say definitely come along.
5471870	5472362	692	A	0.96	All right.
5472416	5473002	693	A	0.99733	Anything else?
5473056	5474780	694	B	0.99989	Otherwise, again, awesome job.
5475950	5477430	695	A	0.99409	No, I think that's it.
5477600	5478862	696	A	0.99981	Thanks for listening, I guess.
5478916	5479662	697	A	0.63444	Well, thanks.
5479796	5480714	698	A	0.99	It was a pleasure.
5480842	5500962	699	B	0.55	It was ambitious to do what you did elegantly with no equations or getting snagged on any of the potentially infinite philosophical and technical and normative and all these different layers of challenge and diversions.
5501106	5505910	700	B	1.0	So to really cut a path there is great.
5506060	5506374	701	A	1.0	Yeah.
5506412	5512806	702	A	1.0	I think it just speaks to there's so much good philosophical work in these areas in active inference and predictive processing.
5512838	5519002	703	A	1.0	And I should say, again, we didn't really do justice to any of the work I talked about.
5519056	5531260	704	A	1.0	So the final thing I would say is definitely the document is there with the reading, and please go and actually look at the work of these people, because some of it's really good.
5531950	5532954	705	A	0.88	All right.
5533152	5534354	706	B	0.84804	Till next time.
5534512	5534882	707	A	0.99915	Cool.
5534936	5535842	708	A	0.75805	Thank you very much.
5535976	5536480	709	A	0.79078	See you.
