start	end	speaker	sentiment	confidence	text
650	1200	A	0.5707480907440186	Alright.
1810	3422	B	0.915437638759613	Hello and welcome everyone.
3556	7678	B	0.9027140736579895	It is July 11, 2023.
7844	17774	B	0.8163204193115234	We are in active inference for the social sciences and today is going to be a lecture by Ben White on basics of active inference, the active inference agent.
17892	19994	B	0.9573825597763062	So Ben, thank you for the lecture.
20122	23566	B	0.9413906931877136	Off to you and we're looking forward to it.
23748	24702	A	0.9599630236625671	Thank you very much.
24756	25960	A	0.6296377182006836	Yeah, me too.
26330	33320	A	0.9903799295425415	Very happy to be a part of this, to be kicking things off with the first module on this course.
33850	39350	A	0.9245157241821289	I'm going to be talking about the active inference agent and trying to cover some of the basics.
39930	41830	A	0.7504063248634338	I won't take too long introducing myself.
41900	64020	A	0.5762626528739929	Avil gave a very thorough introduction in his talk recently, but I'm a second year PhD student in philosophy at the University of Sussex, and I work with Andy Clark and with Avel and some other people using active inference to try and find things out about our relationship with technology and within the context of well being and mental health.
65590	85350	A	0.7659643292427063	The aims for today I'm going to try and provide quite a wide ranging overview of how active inference has connected with areas of philosophical interest and particularly how they relate to the individual agent and the experience of the agent and how the agent finds themselves in the world.
85420	90118	A	0.8884831070899963	So I've split this up to look at several different defined topics.
90214	99530	A	0.8074092864990234	So I'm going to move quite quickly through mind, agency, emotion and phenomenology, and I'm going to say a little bit about the self as well.
99600	104160	A	0.8448309898376465	And then there's going to be a case study at the end that I'm going to move through if we have time.
104690	115270	A	0.8177531361579895	So one of the other aims that I have is to lay out very clearly some of the core concepts and core mechanisms like precision, weighting and prediction error generative models.
115450	118942	A	0.7099107503890991	I'm not going to go into any technical details whatsoever.
119006	121006	A	0.4976896047592163	This is all going to be fairly abstract.
121118	128920	A	0.5282092690467834	My background and my interest in these frameworks is philosophical, so it's quite abstract in terms of how everything fits together.
129370	138490	A	0.8610305190086365	And I'm going to try and bring some of these threads together to build up a layered picture of what the active inference agent is like.
138560	150406	A	0.8200750350952148	Because this course is kind of aimed towards seeing how active inference applies to larger scales, collective behavioral, social norms, sociocultural landscapes.
150518	158522	A	0.7868788242340088	And I think in order to do justice to those things, we need to first have a good idea of the individual in active inference.
158666	161454	A	0.6414414048194885	So we've got our work cut out for us.
161572	162880	A	0.7044853568077087	So I'll get started.
163490	168658	A	0.8721210360527039	So before I dive in, I wanted to just say a little bit about how these frameworks hang together.
168744	173950	A	0.8518356084823608	So active inference is based on Carl Fristen's free energy principle.
174030	175794	A	0.8344447612762451	I think most of us are familiar with that.
175832	186822	A	0.8543701171875	But the free energy principle just states that in order to persist through time, biological organisms must occupy only those states that it would expect to occupy, given the type of thing that it is.
186956	192102	A	0.7498888969421387	So free energy is essentially a measure of the disatunement between a system and its environment.
192166	198780	A	0.915721595287323	And I'm going to say a little bit more about attunement and how that gets cashed out in various ways as we go on.
199150	206926	A	0.8744662404060364	Active inference is a process theory that essentially explains how embodied organisms actually go about remaining in those expected states.
207028	211120	A	0.833063006401062	So how we actually go about minimizing free energy.
211490	220290	A	0.7826073169708252	And the idea is that all adaptive behavior is explained by agents garnering evidence to confirm their own expectations.
221430	222622	A	0.7206593155860901	Predictive processing.
222686	233474	A	0.8459410667419434	For the purposes of the lecture today, I'm going to treat these as synonymous because most of the work that I kind of came up through as I was learning about this was predictive processing.
233602	244966	A	0.8507997989654541	And all of the papers that we're using today that refer to predictive processing refer to a predictive processing that I take to be more or less synonymous with active inference.
244998	250566	A	0.6095883250236511	So that's a very embodied, inactive flavor of predictive processing.
250678	258474	A	0.7438157200813293	I think generally the difference is that predictive processing can be a much broader term and predictive processing can also apply to passive models of perception.
258522	260960	A	0.5826656222343445	But we're not going to concern ourselves with that.
262630	268180	A	0.8480321168899536	Okay, so some key concepts of active inference, predictive processing then.
268630	288626	A	0.880487322807312	So the framework phase that agents embody or agents have, we won't concern ourselves with the nuance there, but they have a generative model, which is essentially a kind of understanding or a model of the regularities that underpin the dynamics between the agent and the environment.
288738	297754	A	0.8544149994850159	So another way to think about this in very rough terms is a kind of mental model of the regularities in the world and how the agent exists in the world.
297952	303278	A	0.8677428364753723	And using that model, the agent can generate predictions about its own sensory states.
303444	310510	A	0.8901127576828003	So given the model, what kinds of sensory states would it expect to find itself in in a particular set of circumstances?
311170	316174	A	0.5650300979614258	And so where those predictions don't actually match the sensory inputs.
316222	326306	A	0.6466748714447021	So where there's a discrepancy between the actual incoming sense data and the prediction, prediction errors are generated and prediction errors are going to flow upwards through the hierarchy.
326338	333538	A	0.6578905582427979	So the generative model is said to be a hierarchical model and predictions flow downwards and prediction errors flow upwards.
333714	341050	A	0.7657333612442017	And the sole imperative of the brain body system according to this framework is to minimize those prediction errors.
342830	349878	A	0.6186321973800659	So a good way to kind of get a little handle on this is to think about just the example of perception.
349974	353454	A	0.8735868334770203	So perception traditionally so I'm talking about visual perception here.
353492	356206	A	0.7519596219062805	It's traditionally been understood as a bottom up process.
356388	366402	A	0.8371545672416687	And what that means is that the brain waits for incoming sensory signals and then it processes them as they come in and it combines them in kind of increasingly abstract ways.
366536	372750	A	0.853432834148407	And what we see is some combination of those sensory signals that have come in and been processed and combined.
372910	380194	A	0.8657242059707642	So if you think about me leaving my apartment in the morning and stepping out onto the street and seeing some cars.
380322	391046	A	0.8167493343353271	What's happening there is some sensory information is hitting my retina and it's being processed first with very basic features like light shade, edges and so on and so forth.
391158	396346	A	0.6905813813209534	And then it's being combined with my understanding of what a car is or what a bus stop is.
396448	399020	A	0.5244432091712952	And that gives me my kind of visual field.
400850	406382	A	0.5341128706932068	Predictive processing, famously, at this point, flips this picture upside down on its head.
406436	410858	A	0.6202375292778015	So visual perception under predictive processing is a top down affair.
411034	416494	A	0.895331859588623	So the generative model is going to encode multilevel expectations about the likely scene.
416542	426814	A	0.8432567119598389	So just to be very clear, when we talk about multilevel and hierarchical, the higher up levels are going to be tracking longer time scales and higher levels of abstraction.
426942	430466	A	0.7037742733955383	The lower levels are going to be much faster, much more concrete.
430658	433650	A	0.6506490707397461	So a changeable scene.
433730	440626	A	0.52298903465271	So there's going to be some variation in what I see when I leave my apartment every day is going to mean that there's always going to be some error in that picture.
440658	445546	A	0.7037034630775452	So it's never going to be the same two days in a row or it's extremely unlikely to be.
445648	452986	A	0.7448234558105469	So no matter how well I can predict what I'm going to see when I leave my house, it's always going to be cleaned up by some prediction errors.
453178	460880	A	0.777610719203949	So essentially, when I step outside and I step into the street, my brain is already anticipating what it's going to see out there.
461490	467326	A	0.8420947194099426	So I know where particular cars are going to be parked, I know where the bus stop is, so on and so forth.
467438	471490	A	0.697536826133728	And the perceptual experience that we have is a construction.
472150	478050	A	0.7034376263618469	We actually experience the expectation that has been kind of cleaned up post prediction error.
478210	482102	A	0.733631432056427	There's a little bit of debate there about exactly what it is that we experience.
482236	488650	A	0.8054961562156677	But for our purposes today, we can say that visual perception is essentially a construction.
490430	495334	A	0.7382817268371582	So on the face of it, prediction errors can be minimized using one of two strategies.
495382	497420	A	0.9248270988464355	And this is going to be really important.
499790	503386	A	0.863861083984375	So we have what I just described there, which is perceptual inference.
503498	507082	A	0.8521119952201843	That's where we revise our predictions to better fit the evidence.
507146	511630	A	0.8279286623001099	So essentially we update our model to better reflect the regularities in the environment.
512290	520740	A	0.860824465751648	Or we can engage in active inference, which is where the framework gets its name from, which is where we essentially make the evidence fit the model.
521190	527042	A	0.8663983345031738	So that's where we in some sense update the world so it conforms to the original prediction.
527186	538890	A	0.8314738273620605	And active inference agents bring about those expected states by sampling the world in a biased way, so they have certain expectations and then we sample the world to confirm the predictions.
539230	550710	A	0.688154935836792	And I put perceptual inference there in scare quotes because perceptual inference on kind of readings of most readings of active inference just becomes a kind of action readiness.
550790	558938	A	0.8132563829421997	Or as Ramstard and colleagues put it, a state estimation so it's just perception and action are just wrapped up in this continuous loop.
559034	560666	A	0.8063724637031555	But it's really all about the action.
560698	567186	A	0.817465603351593	It's really all about bringing about those expected states, and perception is just kind of in service of that process.
567368	576194	A	0.6258638501167297	And so Berenberg and colleagues refer to the active inference agent as a crooked scientist, which is something I really like.
576232	577746	A	0.9789976477622986	I think that's a very charming image.
577778	586422	A	0.8913854956626892	So we are scientists that are engaging in some very dodgy behavior because we're not really interested in having an accurate model.
586476	590790	A	0.7395047545433044	We're more interested in confirming our original predictions.
592330	601462	A	0.6217285394668579	Okay, so that was a very rapid overview of some of the core concepts and mechanisms, but they're going to crop up continuously.
601526	605340	A	0.7523685097694397	So I think we're going to get a much better grasp on them as we go on.
605790	617460	A	0.8643121719360352	In this section, I'm going to start to expand on some of those things that we've just put on the table, and I'm going to begin to flesh them out in terms of thinking about how active inference agents actually exist in the world.
618950	621442	A	0.861520528793335	So I should say I put this here to remind me.
621496	635250	A	0.640744149684906	So those of you who are taking part in the course, I'm going to make available a document with all of the readings that firstly, all of the readings that I've used to make these slides and then a bunch of other readings as well that I think are going to be very relevant.
635330	640214	A	0.8764875531196594	And obviously, they're going to be organized in terms of the structure of this presentation as well.
640252	645450	A	0.7376689314842224	So this is just I've put a little sample up on these slides, but there's going to be much more in the document.
646510	649740	A	0.7865634560585022	So I think it's always good to start with some guiding questions.
650350	652240	A	0.813105046749115	So I've thrown up three here.
654610	657690	A	0.8824241161346436	The first is how does active inference characterize cognition?
657770	662990	A	0.8420875072479248	So we've just looked at predictions and prediction errors, but we're going to expand on that a little bit.
663060	666750	A	0.8222811222076416	And we're going to ask what kinds of processes does cognition involve?
666910	669582	A	0.8528915643692017	How is cognition related to the material environment?
669646	675458	A	0.6961589455604553	This is going to be something how cognition relates to the environment is going to be very important in subsequent weeks.
675624	681106	A	0.8769270777702332	And we're going to ask quite briefly what kinds of vehicles might realize cognitive processing.
681298	684450	A	0.8261314630508423	Okay, so here's a couple of whales.
684530	695082	A	0.6425607204437256	Whales are going to be a recurring theme in this lecture, but I wanted to take a step back and ask about Attunement because this is one of those concepts that gets thrown around a lot.
695216	700362	A	0.862453818321228	And I think once it's grasped, it becomes very clear, very easy to use.
700416	704842	A	0.6622175574302673	But I think prior to it being grasped, it can be a little bit opaque and a bit slippery.
704986	711050	A	0.7396372556686401	So on the left we have a humback whale that was found dead in the Amazon rainforest, allegedly.
711130	712590	A	0.5067209005355835	I don't know if this was true.
712740	715658	A	0.762941300868988	And on the right we have a whale in its natural environment.
715754	722946	A	0.7163735628128052	And I think clearly the intuition here is that in one case the whale is very well attuned to its environment and in the other case it's not.
723128	730050	A	0.8688746690750122	And I think that we can start by asking what is it about the ocean that allows the whale to be well attuned?
730130	740970	A	0.7256506085395813	And what I want to say here is that the particular dynamics between the ocean and the whale allow the whale to do certain things that it can't do when it's in the Amazon.
741710	756718	A	0.5255983471870422	So in other words, we might say that the ocean affords certain things to the whale, specifically filter feeding, being able to move its vast weight around with ease, things that, unfortunately, a whale in the Amazon can't do.
756884	759950	A	0.6404981017112732	So affordances are opportunities for action.
760770	765854	A	0.8743399381637573	They are things, roughly speaking, in the environment that the agent can act upon.
765982	780406	A	0.7119550704956055	And there's some debate about the proper way to really characterize affordances, but I like to think of them as relational properties emerging from an environmental feature and some skilled embodied ability of the agent.
780508	786242	A	0.6214379072189331	So the same thing in the environment will not afford the same thing to different organisms.
786386	795738	A	0.694755494594574	So, for example, soil to a human agent might afford walking on or laying down on, but to an Earthworm it affords very different things.
795824	806480	A	0.8318864107131958	And also, even amongst the same organisms with humans, especially, different surfaces and features of the environment will afford different things depending on your particular skill set.
807890	817834	A	0.8273406624794006	And agents are going to go about minimizing their uncertainty, so minimizing prediction errors, staying attuned to their environment through an engagement with affordances.
817962	824980	A	0.7552153468132019	And this is going to be something that is going to drift away slightly as we move through some sections and then it's going to come back very heavily at the end.
825830	834962	A	0.8623313903808594	And I should say that the idea of affordances, to my knowledge, it first emerges in the work of James Gibson the Ecological Approach to Visual Perception.
835026	839530	A	0.7642595171928406	I think it's chapter eight in that book that really lays out a theory of affordances.
844480	858160	A	0.5555959343910217	So this idea that systems or organisms maintain their organization through ongoing action means that active inference has been labeled as quintessentially inactive by Cole Friston.
858580	865964	A	0.9206124544143677	And I think that this is a nice inactivism is an older framework from theoretical cognitive science.
866092	871248	A	0.9235771894454956	And I think it's a nice way to understand some of the key features of active inference.
871344	875184	A	0.5968243479728699	But it does come with a little bit of historical philosophical baggage.
875232	886090	A	0.6888856291770935	And I'm going to try and unpack that really quickly because I want to unpack exactly what it is that we're committing ourselves to when we think about cognition in inactivist terms.
887100	899144	A	0.8287690281867981	So inactivism comes in various strands very, very quickly and roughly, you have autopoietic inactivism, which commits itself to what's known as the mind life continuity thesis.
899272	909840	A	0.8268594145774841	This is essentially that the structures that give a ground to life itself are the same structures that instantiate cognitive processes.
910820	917616	A	0.6899459362030029	Sensing on this view is teleological because it's oriented around supporting vital systems.
917648	926890	A	0.6169211864471436	So things in the environment have intrinsic meaning to the organism because they support the vital functioning of the organism in some way.
927660	939544	A	0.8078502416610718	Sensory motor inactivism emphasizes how mobile and embodied agents essentially enact the grounds and conditions for their own sensory engagements with the world.
939662	954850	A	0.820235013961792	So the world is not a kind of neutral static, given that we're parachuted into actually the conditions through which we sense the world are the conditions that we can move and kind of interact with the world in various ways.
956020	958124	A	0.5897108316421509	And then there's radical inactivism.
958252	964864	A	0.8704533576965332	And this is the view that cognition is purely grounded in these agent environment dynamics.
964912	972064	A	0.7431139945983887	It's a purely dynamicist account of cognition and there's no role whatsoever for internal representations.
972192	981540	A	0.815233051776886	So certainly in certain brands of sensory motor inactivism, there remains a role for internal manipulation of representations.
981700	987240	A	0.565285325050354	And mental representations are just mental states that are about something in the world.
987390	992204	A	0.6742097735404968	So some mental state is reconstructing some feature of the world.
992322	1004252	A	0.8656136393547058	And this all harks back to kind of old debates in philosophy of cognitive science between internalist notions of cognition and more embodied, embedded, extended.
1004316	1008064	A	0.8502421379089355	And we'll take more of a look at that in a second.
1008182	1012636	A	0.829731822013855	But the question here is what are we committing ourselves to with active inference?
1012748	1013948	A	0.8051292896270752	Active inference?
1014044	1024512	A	0.6161364912986755	And I need to be a little bit careful because I think that people are going to disagree with this to certain extents, but I think we're certainly committing ourselves to sensory motor and activism.
1024576	1026336	A	0.6473411917686462	I think that's fairly uncontroversial.
1026448	1040940	A	0.7966455817222595	And I would say as well that the underpinning of active inference by the free energy principle, by my lights, also commits us, or it certainly chimes very deeply with the core tenets of autopoietic inactivism.
1041680	1049820	A	0.7857019305229187	But I think what's really interesting in trying to understand cognition in the active inference agent is to understand what role, if any, there are for representations.
1050240	1065024	A	0.4996812045574188	So if you have any familiarity with the literature on active inference, you'll know that active inference people are always banging on about models, prediction errors, various other computationally sounding things.
1065222	1075712	A	0.7635101079940796	And so the worry here is at least for well, it's not necessarily a worry, but the thought would be are we committing ourselves to a form of cognitivism?
1075776	1092350	A	0.7894379496574402	And again, cognitivism is generally considered to be an old fashioned notion of cognition as like computation over symbolic representations in the brain according to some syntactic set of rules or something.
1093360	1099468	A	0.6664300560951233	And typically over the last couple of decades in cognitive science, people have been moving away from that view.
1099634	1105024	A	0.6441592574119568	So it would be interesting if we were committing ourselves to something that we'd already moved away from.
1105142	1108204	A	0.6326152682304382	And some people think that we are making that commitment.
1108252	1121168	A	0.5850857496261597	So Jacob Howie, for example, has argued in various places that essentially predictive processing or active inference commits us to these very rich reconstructive notions of representation.
1121344	1131384	A	0.9123230576515198	And even Andy Clark Jacob Howie's foil in many places has said himself that he thinks that representations play a role here as well.
1131502	1133348	A	0.8856449127197266	So in a talk in 2016.
1133444	1136596	A	0.686316967010498	Clark said it's internal representation.
1136708	1137640	A	0.6437970995903015	I think it is.
1137710	1145948	A	0.6183047890663147	These are representation using stories, but it's not internal representation in quite the way that we originally thought about it.
1146114	1152432	A	0.744920551776886	So there's some differences, perhaps major differences between Howie and Clark there, but others have pushed back.
1152486	1169300	A	0.6970395445823669	So there's a paper by Maxwell Ramstead and colleagues from 2020, I think it's the tale of two densities paper where they say that a proper understanding of the generative models in active inference suggests that there's no role for representations.
1170040	1172470	A	0.6726586818695068	So this is the kind of anti Howie view.
1175800	1190628	A	0.9248052835464478	So I really like this paper from Axel Constant and Andy Clark and Carl Friston which essentially tries to broker some kind of peace in a debate that in some form or another has been raging for decades.
1190724	1194108	A	0.7238441109657288	So it'd be quite nice to finally put this to bed.
1194274	1201150	A	0.8560822606086731	So they argue that we can find, in the formalisms of active inference, we can find grounds for an armistice here.
1201940	1213672	A	0.8598061800003052	So they argue that the formalisms of active inference show that, quote representational and non representational cognitive processes can be implemented by the brain under active inference.
1213836	1218928	A	0.6231175065040588	And they do this by showing that active inference accommodates a dual architecture.
1219104	1233476	A	0.8034263849258423	So they show that on the one hand, in some sense the brain has to represent because under active inference action selection policies are happening over extended timescales.
1233508	1237240	A	0.7889638543128967	And so the agent has to engage in some kind of counterfactual thinking.
1237390	1239272	A	0.8513728380203247	So if I do X, what happens?
1239326	1240760	A	0.8075971007347107	If I do, y what happens?
1240830	1241628	A	0.6936384439468384	And so on.
1241714	1248460	A	0.8411242365837097	And the argument, very roughly speaking, is that that is going to entail some kind of representational, some use of representations.
1249360	1259564	A	0.8174925446510315	But on the other hand, they argue that what they call deontic actions are processed through different mappings in the generative model and they're directly triggered by sensory input.
1259692	1267056	A	0.8003578186035156	So a deontic action is an action that is ingrained by our sense of the expectations of others.
1267238	1273828	A	0.6064462661743164	So the example that the authors use is stopping at some red traffic lights in the middle of the night when there's nobody else around.
1273994	1280020	A	0.5212226510047913	So in a sense the claim is that we through a kind of social conditioning.
1280180	1292780	A	0.8270097374916077	We know what other people would expect us to do in those circumstances and that allows for this kind of dynamic reflexive action policy setting.
1295040	1300590	A	0.526187539100647	And in those cases there's no room for representative or there's no need for representations there.
1301380	1315440	A	0.6489445567131042	I would definitely suggest people interested in this go and read this paper because you might already have thought of some potential objections here to the claim that representations aren't needed for deontic action.
1315520	1319910	A	0.8595999479293823	And they do go into some detail in talking about potential objections there.
1321240	1326500	A	0.7612519264221191	So that's the kind of status of the role of representations.
1327260	1330916	A	0.566940188407898	It's a live debate, not everybody agrees.
1331108	1339012	A	0.6833955645561218	But it certainly looks as though active inference has the formal tools to accommodate both sides of the debate.
1339076	1349070	A	0.5310382843017578	And it might turn out that that's a good thing because we can make everybody happy or it might turn out to be a bad thing because you might think, well, we've not really settled anything one way or another.
1350640	1356700	A	0.8547959923744202	I wanted to take some time though, to mention extended active inference.
1356780	1371552	A	0.8985610008239746	So I've been talking about inactivism and I've mentioned that I've mentioned this debate between cognitivism and older ways of thinking about sorry, cognitivism and newer ways of thinking about cognition as embodied or embedded.
1371696	1374720	A	0.8877134323120117	And these are part of what's known as the four e paradigm.
1374800	1384024	A	0.764464795589447	And clearly I think we are talking about inactive cognition and you get embodied and embedded kind of for free with this.
1384062	1387416	A	0.7588768601417542	So the only one left on the table is the extended mind.
1387598	1400750	A	0.7398719787597656	And this is just the claim that under some conditions the system that's realizing cognitive processing can literally extend outwards from the mind.
1401200	1405984	A	0.8551931977272034	So I'll put some nice readings for this up if anybody's unfamiliar and interested.
1406102	1409360	A	0.6426259279251099	But it's usually the most controversial of the four ease.
1410900	1421392	A	0.5648068785667419	And Andy Clark, who is one of the original authors of the extended mind paper, really thinks that active inference accommodates the extended mind theory.
1421456	1435140	A	0.5498262643814087	And it's not just that it accommodates it, but it actually solves some old problems in the extended mind about knowing how and why the brain knows when and where to recruit certain extraneural resources.
1435300	1449000	A	0.7149278521537781	And part of the argument for this, what really sits at the core is Clark develops this argument based on the fact that the generative models in active inference are always in this, always making a trade off between accuracy and complexity.
1449160	1462348	A	0.6926804184913635	So you want your model of the world to be accurate enough that you can act effectively on the world, but you also want to minimize the metabolic costs of having models that are overly complex.
1462524	1477690	A	0.807231068611145	And so Clark utilizes this insight to make the case that this explains that in some cases as agents we make use of these extra neural kind of props and tools and things.
1478540	1488970	A	0.723846971988678	And he says that the imperative to reduce uncertainty provides a location neutral cost function that's always been missing from the older arguments around extended mind.
1490160	1498344	A	0.788092315196991	So the upshot to this, I think, is that you end up with a view of agents as deeply coupled with their environments.
1498472	1505228	A	0.6707139015197754	So under active inference it's just nonsensical to try and think about agents as decoupled from their environment.
1505324	1510732	A	0.8548033833503723	The generative models themselves are of the dynamics between the agent and the environment.
1510796	1516400	A	0.557366132736206	So these two things can't be decoupled perception, action loops.
1516480	1520612	A	0.8186764717102051	So remember I said that perceptual and active inference are essentially the same thing.
1520666	1527720	A	0.5219130516052246	They're the part of this circular causality and they see the agent constantly producing their own worlds.
1528220	1532040	A	0.712101936340332	They occupy the states that they're expecting to through action.
1532460	1540536	A	0.9012725949287415	And we might think, based on the literature that I've gone through, that there's some role here for representations.
1540728	1543100	A	0.699407160282135	So we're not committing ourselves.
1544560	1557004	A	0.5946624279022217	The active inference agent is not one that fits with very radical interpretations of inactivism and active inference agents are porous.
1557132	1568790	A	0.6542693376541138	They're open to recruiting external material features of the environment to reduce complexity and therefore minimize the metabolic costs of realizing those expected states.
1571000	1584354	A	0.8863551020622253	Okay, so that was a bit of active inference set against the backdrop of some older questions in philosophy of mind theoretical cognitive science.
1584482	1589720	A	0.6203434467315674	But I'm going to jump straight into agency and motivation now, because there's a lot to get through here.
1590890	1592966	A	0.6570909023284912	I'm going to start with a dark room problem.
1593068	1597126	A	0.7332918643951416	This is a canonical philosophical worry in active inference.
1597158	1599802	A	0.8278072476387024	So a lot of people, I think, will be familiar with this.
1599936	1603020	A	0.7503028512001038	And in really brief terms, it's really easy to state.
1603390	1614686	A	0.5076195001602173	The challenge here is to say, if it's all about minimizing prediction error, why don't we just find the most predictable environments possible and stay there and live a nice error free life?
1614868	1625060	A	0.8310708403587341	So Andy Clark paints a picture of a dark room, and you can just be strapped up to an intravenous drip, feeding you the nutrients you need, and you can just be really happy.
1625510	1627586	A	0.5465433597564697	But clearly, we don't do that.
1627768	1629362	A	0.524993896484375	Active inference sorry.
1629416	1637718	A	0.6385343670845032	Agents in the world, us, we generally typically sometimes we do enjoy dark rooms, but most of the time we don't for any extended period of time.
1637804	1650810	A	0.5953752994537354	And so there's a challenge here about how active inference can account for what appear to be motivated agential actions that necessarily mean we're confronted with some degree of uncertainty.
1651710	1660890	A	0.7801206707954407	And I'm going to set active inference up in a kind of dialectic with folk psychology here, because folk psychology faces no such concerns.
1661050	1673070	A	0.8239747285842896	So, to be very clear, folk psychology is just the kind of propositional linguistic framework that the folk use to talk about and describe motivated action.
1673150	1679606	A	0.6732223629951477	So it's a language we typically use every day to describe the reasons people are doing things.
1679788	1689474	A	0.8556351065635681	So folk psychology has this belief, desire, intention, schema, where, if I want to explain, my friend going to grab a beer.
1689602	1692822	A	0.7456357479095459	I would say, my friend believes there's beer in the fridge.
1692886	1694806	A	0.5393000245094299	My friend desires beer.
1694918	1698774	A	0.78470379114151	And so those are combined to form the intention to go and get beer.
1698822	1702060	A	0.5292710065841675	So folk psychology doesn't have these kinds of problems.
1704030	1707390	A	0.8234832286834717	So just a little bit more on the dark room problem and another whale.
1708690	1711630	A	0.6505230665206909	So the dark room problem invites more than one answer.
1711700	1714400	A	0.8515473008155823	We're going to see more than one answer to it as we go along.
1715090	1722162	A	0.6084682941436768	One response is to talk about what drives curiosity and play and exploration, and we are going to see more of that.
1722296	1738882	A	0.8580544590950012	But the first response offered by Fristen, Thornton, and Clark is to highlight the fact that organisms have basic needs to eat, drink, and reproduce what you might call evolutionarily ingrained needs, and that those needs are going to necessitate some form of exploratory behavior.
1739026	1747210	A	0.7467414140701294	So staying in the dark room will inevitably, under most circumstances, going to lead to physical dissipation.
1749790	1753980	A	0.7192143797874451	So the question is, are these kinds of appeals enough?
1755870	1762618	A	0.8767950534820557	And I wanted to pull up a paper by Colin Klein 2018 that I think is like a really nice articulation of these challenges.
1762714	1768106	A	0.500545084476471	Ultimately, I think he's wrong and it falls flat, but I think it's a strong articulation.
1768298	1774770	A	0.5755297541618347	So Klein argues that predictions alone simply can't account for the motivational character of these needs.
1774840	1788054	A	0.5703774690628052	So Klein says, look, it's fine that you've got these needs, nobody's going to deny that, but you just have this one primitive to describe how those needs motivate you, and prediction is just not going to do it.
1788092	1795900	A	0.5347291231155396	So prediction alone, as your sole primitive is not going to be able it's like predicting is not the same thing as being motivated by something.
1797550	1803466	A	0.8859192132949829	And Klein is really not happy with appeals to these phenotypic needs.
1803648	1811438	A	0.8470355272293091	And he construes these in the relevance of the evolutionary history of the organism and goes into a little bit of detail.
1811524	1829758	A	0.7883811593055725	So he says, look, these expectations are either going to be about states, possible states, so the state of being fed or clothed or warm, or they're going to be about state transitions, about what the appropriate action is in one state to move to another state.
1829944	1838834	A	0.8066797852516174	And he says expectations about states themselves aren't going to work because you have this problem of accounting for novelty.
1838962	1847942	A	0.7668477296829224	So it might be the case that in my evolutionary past, all of my ancestors have had the same expectations about which states they're going to occupy.
1848086	1857280	A	0.6185137629508972	But there are lots of states in my life that I could be motivated to occupy that there's simply no evolutionary history to account for.
1857810	1868378	A	0.6332351565361023	And he says there's a very similar or similarly difficult problem with state transitions, where essentially what we're talking about with state transitions are the most appropriate actions.
1868554	1878786	A	0.7304787039756775	So I have expectations about the actions that are going to fill foot that I need to take under certain circumstances that are going to get me to a particular expected state.
1878968	1884694	A	0.5802165269851685	And Klein's worry is that there's just going to be too many possible actions in any given situation.
1884812	1891606	A	0.6811585426330566	So there's just a kind of explosion that's just going to be unaccountable for.
1891708	1900780	A	0.6328540444374084	There's just going to be too many different ways of getting to an expected state that we won't be able to account for in our past.
1901470	1908606	A	0.5964271426200867	So it's fairly robust, thorough, challenge used, built on the dark room problem.
1908788	1912330	A	0.48647937178611755	And I think actually it's a worry with two faces.
1912410	1922414	A	0.8509784936904907	So I think the first is about how active inference can describe agential behavior with its austere, purely docsastic landscape.
1922462	1932614	A	0.7462348341941833	So if you imagine somebody looking at their house burning down, it seems like you need more than beliefs to explain any course of action they take.
1932652	1935314	A	0.8018584251403809	So there has to be desire in there somewhere.
1935442	1938594	A	0.9011422395706177	So this is an example Andy Clark uses in one of his papers.
1938642	1951818	A	0.8821292519569397	And he says the desire to run in and rescue some item that you want from the house or the desire to claim on the insurance is the thing that's going to.
1951824	1954506	A	0.663553774356842	Dictate how you explain the person's behavior.
1954698	1956238	A	0.7962943911552429	So that's the first problem.
1956324	1962590	A	0.849570631980896	We need to look at how folk psychology tessellates with prediction.
1962930	1971582	A	0.5117736458778381	And the other problem is maybe a little bit, maybe a little bit deeper, and that's to ask, how does active inference actually account for agential behavior?
1971726	1979880	A	0.6817681789398193	So can we even tell some story using just predictions and prediction error about what really moves agents to act?
1981130	1988946	A	0.7377519011497498	So firstly, thinking about folk psychology, there's a couple of ways to go here and I think ultimately we can answer this worry.
1989138	1997366	A	0.59127277135849	So Ryan Smith and colleagues in 2022 in their paper active inference models do not contradict folk psychology.
1997558	2003926	A	0.8571592569351196	They argue that the formalisms of active inference can accommodate a belief desire distinction.
2004118	2012954	A	0.6674333214759827	Now, I'll admit that it's a very math heavy paper and it's a little bit beyond my capabilities, but the claim here is simply that there's no contradiction.
2013082	2018170	A	0.6602120399475098	That actually the worry that the important thing we have in folk psychology is desire.
2018330	2020542	A	0.6163430213928223	And we're not getting that in active inference.
2020606	2022530	A	0.7119764685630798	This is just an unfounded worry.
2023030	2024994	A	0.8534023761749268	But there's another strategy as well.
2025112	2034386	A	0.7426245212554932	So Joe Deuhurst, in his 2017 paper, he employs a different strategy and he says, look, what are we even doing with folk psychology?
2034498	2043740	A	0.7069228291511536	Let's not kind of be too hasty and we need to think about what are we doing when we talk about these propositional kind of states.
2045070	2048842	A	0.7298561334609985	So he says the first option is to say, well, we're just being realists here.
2048896	2058880	A	0.779384970664978	So when I say that X desires Y, I'm actually positing the real existence as a fine grained mental state in X's head.
2059570	2062430	A	0.906814694404602	And he thinks that this is actually the wrong way to think about things.
2062500	2067086	A	0.5532199740409851	He thinks that folk psychology actually it's an instrumentalist tool.
2067188	2074818	A	0.7123478055000305	It's a kind of framework that we use just for picking out coarse grained behavioral patterns in some useful way.
2074984	2097162	A	0.6626867055892944	So if we agree with Deuhurst here and we just become instrumentalists about folk psychology again, it looks as though there's different we're not forced to kind of worry that there's some kind of empirical problem here where the mechanisms of active inference are in some sense incommensurable with real properties that we're positing the existence of.
2097216	2103340	A	0.5136224627494812	Because we're just going to say that those things don't really exist in the way that we've typically assumed that they might.
2104050	2115710	A	0.5685567855834961	So either way, whichever route you go down here, it looks like active inference agents have beliefs and that we're going to be fine in describing motivated action.
2117990	2119940	A	0.6828852891921997	So what about the second problem?
2122870	2126930	A	0.7254214882850647	So Andy Clark in 2020 authored a direct response decline.
2127830	2140390	A	0.8537740111351013	So Clark wants to argue that actually using predictions and prediction errors and precision weighting, which I'll explain in a second, we can get a picture of agential action.
2142830	2153414	A	0.8043257594108582	So the first thing Clark does is to outline the fact that under active inference, we have a very nice, well worn account of embodied action.
2153462	2165226	A	0.683542013168335	So, in other words, what it takes to actually move the body to perform different actions is perfectly folded into active inference under the same kind of computational flow of prediction error minimization.
2165418	2174050	A	0.6719267964363098	Just in a nutshell, for me to move my arm, what I'm doing is making a prediction that my arm is in someplace and then minimizing the prediction error.
2175510	2178962	A	0.5300896167755127	So once that's on the table, Clark says, okay, that's fine.
2179096	2182600	A	0.6008356809616089	We have this account of action, but that's not really what Klein means.
2183290	2201510	A	0.5670338273048401	So the move Clark makes is to appeal to the hierarchical nested structure of the generative model and to say that higher level beliefs, which are about temporally extended future states, these are going to perform a really important role as a kind of controller for lower level actions.
2201670	2216550	A	0.6921700835227966	So the idea is that if I have a high level temporally extended expectation to attain a PhD, what happens is that high level belief becomes unpacked at lower levels in the hierarchy.
2216650	2226130	A	0.5814051628112793	And what you get are more fine grained, faster action policies that the system expects to help support that higher level expectation.
2226550	2242934	A	0.574844479560852	And there's a mechanism in play here called precision weighting, which applies to prediction error signals because obviously not all of the predictions we make about the environment are going to be equally important.
2243052	2248890	A	0.5655217170715332	We're not going to have equal confidence in all of our actions to bring about an expected state.
2249040	2261626	A	0.8603065013885498	And so what precision waiting does is essentially communicate how much confidence we have in a particular action policy to move us into that expected state under perceptual inference.
2261818	2269198	A	0.6220411658287048	Precision waiting just signals how newsworthy prediction errors are, so how important they are for the system.
2269284	2275566	A	0.7580181360244751	So precision weighting drives attention, for example, when we're talking about predictive processing.
2275678	2291350	A	0.6399933695793152	But in this case, Clark's claim is that when you have this kind of nested hierarchy of expectations, so you have temporarily extended expectations at the high level, unpacked into a kind of web of lower level action policies.
2291690	2301020	A	0.8768693208694458	And precision waiting is kind of modulating the system's expectations about which of those policies are most likely to bring about the expected state.
2301470	2307178	A	0.8068873882293701	You get something that looks a lot like motivated directed action.
2307354	2321778	A	0.7636079788208008	And agency is kind of inherent in this model because the system rather has to model itself as a cause of those expected states.
2321864	2332598	A	0.7510839700698853	So if I have these high level expectations, I, in a very inherent way, have to model my own cause or efficacy to bring about those states.
2332764	2343654	A	0.7106802463531494	So on a very low level, the system has to model some form of agent because I can be the cause of change to my own sensory states, so I can cover my own eyes and so on and so forth.
2343782	2351958	A	0.8380836248397827	So kind of on this view, agency is a latent variable in these systems when it's making these predictions.
2352054	2354182	A	0.6898269653320312	So it just kind of turns up.
2354336	2363498	A	0.6810108423233032	And Clark argues that you essentially end up with something that looks very much like agents on the folk psychology.
2363674	2374206	A	0.6782247424125671	But he thinks this is a better view because we end up with a, quote, different and arguably much more unified internal architecture trading in a single currency.
2374318	2378910	A	0.6842040419578552	So Clark thinks, look, okay, Klein's worry is we have this one primitive.
2378990	2384802	A	0.539469838142395	We have just prediction, and the concern is that we're not going to be able to explain agential action.
2384866	2391346	A	0.7557573318481445	But actually there are ways that we can appeal to the hierarchical structure of the model and precision weighting.
2391458	2395260	A	0.9447405338287354	And it turns out that this is a much more elegant picture as well.
2395950	2407120	A	0.553127646446228	But Klein might press the worry, and anybody listening might kind of think, well, we've kind of done some work there, but why do we expect the things that we expect in the first place?
2408530	2415854	A	0.5036686062812805	So why is my long term expectation to attain a PhD and not to join the French Foreign Legion, for example?
2416052	2419300	A	0.5468922853469849	What means that I expect one thing rather than another?
2419750	2425380	A	0.8276055455207825	And here Clark just bites a bullet and says, nobody can explain that.
2425750	2431266	A	0.763963520526886	We've kind of shifted to talking about questions about spookier, questions about free will.
2431368	2440440	A	0.5595884323120117	And Clark says, look, if this is what you want, if this is what you're demanding, then you have to recognize that simply appealing to folk psychology doesn't get you that either.
2442730	2450220	A	0.5100997686386108	People with these kinds of worries need to be careful in how much they demand from the active inference agent.
2450750	2460910	A	0.8011569976806641	And I think the real answer to that question actually, this is more speculative, but the real answer to that, a deeper answer to these kinds of questions will lie in the kinds of things that we're going to look at in subsequent weeks.
2461060	2481640	A	0.6542782187461853	So, for example, the reason I have the expectation to attain a PhD rather than join the French Foreign Legion is because I exist in a particular kind of sociocultural landscape with specific norms, and a lot of my actions and beliefs are tempered and shaped by the expectations of people around me.
2483370	2485110	A	0.7085714936256409	So this is just an overview.
2485450	2487640	A	0.845946192741394	We went over the dark room problem.
2488490	2497478	A	0.49708065390586853	Why do we do anything at all if it's all about certainty and prediction error minimization this worry?
2497574	2502070	A	0.7366523742675781	I said you can kind of highlight two aspects of this worry.
2502150	2506718	A	0.853123664855957	One is an actual account of agency under active inference, which we have.
2506804	2516058	A	0.9031449556350708	We have this Andy Clark model of agency to do with hierarchical nested, unfolding action policies over time and different precision mappings.
2516234	2519806	A	0.49748244881629944	And then we have this worry about the relationship with folk psychology.
2519918	2526254	A	0.8832510709762573	So how do we describe agential behavior, motivated behavior?
2526302	2531910	A	0.7517290115356445	How do we describe the behavior of agents if we only have recourse to prediction?
2533930	2542962	A	0.8244390487670898	And as we saw, there's one argument here is that actually active inference, the formalisms can accommodate this belief desire distinction.
2543106	2548890	A	0.5409014225006104	And the other move that I really like is to just say, look, folk psychology is just this instrumental tool.
2548960	2561258	A	0.6977080702781677	It is, in effect, it's part of the sociocultural landscape that we use to shape each other's expectations by putting these labels to explain our actions.
2561434	2563760	A	0.8502569794654846	It's a kind of form of active inference itself.
2564690	2580920	A	0.7484431266784668	So there's this kind of philosophically interesting debate about folk psychology, but it turns out that everything's okay and active inference agents are in fact agents with beliefs, desires and hopes and dreams and so on.
2582410	2583206	A	0.7123860716819763	Okay?
2583388	2584630	A	0.7325160503387451	That's agency.
2585690	2587240	A	0.9459227919578552	We're making good time.
2591210	2591718	A	0.7123860716819763	Okay?
2591804	2602554	A	0.8053181767463684	So in this section I'm going to introduce quite a lot of stuff, but it's going to be all tied together hopefully rather neatly in the case study.
2602592	2606042	A	0.8893718719482422	At the end, I'm going to talk about alistasis and emotion.
2606186	2610880	A	0.9066528677940369	I'm going to say very briefly a little bit about the self as well.
2612930	2615694	A	0.9167488813400269	Here's some examples of some of the core readings I've used.
2615732	2619940	A	0.8322476744651794	Again, these are all going to be up in the document as well, which will be made available.
2620630	2623922	A	0.556306779384613	And I thoroughly advise you to just have a browse through these.
2623976	2626020	A	0.9619715213775635	There's some really interesting stuff there.
2626390	2641790	A	0.9337055683135986	I'm not going to talk about psychedelics or meditation or depersonalization, but there is some really cool active inference literature on those topics as well, particularly papers on psychedelics and ego dissolution by George Dean.
2641970	2651194	A	0.8638644218444824	A new paper just came out by Sipolito jonas Mago and Robert Carhartt harris and I think Fernando Rosas as well.
2651232	2655580	A	0.6325720548629761	I think I might be mistaken on the authors there, but it's a very new paper.
2657150	2665310	A	0.9009320735931396	Okay, so the, the thing that is going to underpin a lot of what I'm now going to go on to say is going to be this notion of alistasis.
2666690	2673502	A	0.8512372970581055	And this plays a major role in a lot of work on emotion and the self in active inference.
2673646	2688802	A	0.8785738945007324	Lisa Feldman Barrett, whose theory of emotion we're going to look at in a second, has argued that the brain's fundamental purpose, what it evolved to do through that imperative to minimize prediction error, is to manage the body's metabolic budget.
2688866	2694620	A	0.8381443619728088	So the first prior is kind of our most expected state.
2695150	2706158	A	0.579648494720459	The first prior in the sense of our strongest prior, prior probability, our highest expectation is to have good allostatic control.
2706244	2707662	A	0.5214834809303284	But I'm getting ahead of myself there.
2707716	2714734	A	0.7468233108520508	All that means is that we're balancing our body's metabolic budget or like energy budget in an effective way.
2714932	2722718	A	0.8123889565467834	So error signals, like I said before, that are highly precise are those that are weighted very highly.
2722894	2731390	A	0.7631127238273621	So prediction error signals that have high precision weighting are the synaptic gain on those error signals is going to be increased.
2731470	2740600	A	0.6129235625267029	And that's going to drive learning, which means in future our expectations around those kinds of error signals is going to be we're going to pay more attention to those.
2741710	2751306	A	0.7172080874443054	And the most highly weighted error signals that we're going to get are to do with our own homeostatic set points within our own body.
2751488	2768354	A	0.583299994468689	So if my temperature started to rise rapidly, my body temperature started to rise or drop rapidly, that prediction error signal, the violation of those expectations is really going to grab my attention and I'm going to do something about it.
2768552	2776398	A	0.8749673962593079	And one way that we maintain these homeostatic states is through the body's own autonomic reactions.
2776574	2781826	A	0.734990656375885	So were I to start getting very cold, I would probably start to shiver.
2781938	2788760	A	0.8533161282539368	And so the body is trying to kind of rectify those deviations from homeostatic set points.
2789450	2796694	A	0.6326520442962646	But another thing that organisms engage in, and humans do this to really remarkable degrees.
2796742	2809850	A	0.7935659885406494	And again, this is going to be something that I suspect is going to come out in the subsequent weeks, is that we engage in quite complex and sophisticated anticipatory actions to maintain homeostasis.
2809930	2812350	A	0.6820088624954224	And this is something called allostasis.
2812850	2822686	A	0.914149820804596	So allostatic control, which I mentioned earlier as this first prior, is essentially the regulation of homeostasis through action.
2822798	2828954	A	0.6313169002532959	So it's actions that I can take to ensure that I stay within those important bounds.
2829022	2835400	A	0.7494478225708008	So shivering is good, but living in a house with central heating is better.
2836010	2849580	A	0.5642645955085754	Having a warm bed and living in a community where we've had these people of kind of engineers have worked to create a kind of material environment that acts as a kind of background support to a lot of these needs.
2851150	2855274	A	0.5116211175918579	Something that's another important concept here is allostatic load.
2855402	2859966	A	0.8061200976371765	So this is essentially the result of not having good allostatic control.
2860068	2873186	A	0.6442015767097473	So again, allostatic control is just engaging effectively in actions that are maintaining those set points, whereas allostatic load is the physiological costs to the agent of losing that control.
2873368	2885286	A	0.6585839986801147	So there's so many studies here that have just shown the immense physiological costs of operating beyond those set points and not having good control.
2885388	2898778	A	0.8726632595062256	So allostatic load has been linked with reduced cardiac health, sleep problems, gut issues, mental health issues, depression, basically everything.
2898864	2908480	A	0.42241212725639343	It's really, really bad and so good allostatic control is very important and as we're going to see, it, underpins quite a few very important things.
2911170	2921458	A	0.5060844421386719	So really we could dedicate a whole hour to looking at emotion, but I'm going to blast through it very quickly right now.
2921544	2933030	A	0.9008942246437073	And this slide, I should say one of the core readings on the document and the reading that I'm basing this on is Lisa Feldman Barrett's 2017 paper, the Theory of Constructed Emotion.
2935450	2944220	A	0.5850533246994019	The main idea here is this is one of those theories that on the face of it, it seems quite simple, but actually there's quite a lot of subtlety and nuance to it.
2944830	2950682	A	0.831300675868988	Allostatic control means inferring the causes of changes to the body's internal state.
2950816	2961038	A	0.8025163412094116	So in other words, if I want to keep good allostatic control, I need to know not just what's going on out there, but I need to know what's going on inside me as well.
2961124	2961422	A	0.7123860716819763	Okay?
2961476	2965406	A	0.7728639841079712	So if there's some crucial change happening, I need to be on top of it.
2965508	2974274	A	0.5913188457489014	And this happens through exactly the same process as the same predictive error, minimization process that I'm engaging with with the outside world.
2974392	2984978	A	0.7681609988212585	So the brain is making predictions about its own internal states and then it's going to engage in some kind of action to minimize any prediction errors.
2985074	2987682	A	0.5995919704437256	And these prediction errors are going to be very highly weighted.
2987746	2988840	A	0.8657040596008301	They're very important.
2989770	2991962	A	0.7741371393203735	But here's an interesting thing.
2992016	3002838	A	0.7151337265968323	So there was a very unethical experiment done by Shaktor and Singer, I think in the 60s, who they were emotion researchers.
3003014	3009594	A	0.624173104763031	And they conducted an experiment where they injected subjects without the subject's knowledge.
3009642	3018446	A	0.5959225296974182	I think they injected them with adrenaline and then they exposed the subjects to different stimuli.
3018558	3024146	A	0.8329386115074158	So some subjects were exposed to one type of stimulus and some subjects were exposed to another.
3024328	3042858	A	0.8172397613525391	And even though the subjects had essentially been pushed to have the same, to experience the same physiological changes in their body, they reported different emotional, different kinds of feelings, depended on depending on the stimulus that they'd been exposed to.
3043024	3046058	A	0.8727698922157288	So this highlights something really important.
3046144	3050938	A	0.5430465340614319	And again, I feel compelled to say that I am moving through this incredibly quickly.
3051024	3052940	A	0.7144014835357666	There's so much to say here.
3053390	3073102	A	0.7683712244033813	But the nub of it is this in order to keep good allostatic control, in order to know what to do, the brain needs to contextualize those changes in the body because there's not a one to one mapping between changes in the body and an external stimulus.
3073246	3080340	A	0.8379830718040466	So sometimes changes, physiological changes in our body are about something in the world, they're a response to something.
3081030	3091814	A	0.7677181363105774	And it's very, very important that the brain is kind of taking a confluence of those inputs to try and contextualize, okay, what's actually happening and what do I need to do?
3091932	3103210	A	0.8661389946937561	So an example of this is if you imagine running into a bear while you're hiking in Wyoming, which is something that's actually happened to me, I've experienced it, it's terrifying.
3103550	3108240	A	0.6734418869018555	And you imagine going on a scary or a date that you're really nervous about.
3109570	3115646	A	0.8781900405883789	The physiological changes that are happening in the body are, give or take, more or less the same.
3115748	3120820	A	0.8098182082176208	So perspiration, elevated heart rate, breathing changes.
3121990	3125986	A	0.581529974937439	So the underlying physiological footprint is very, very similar.
3126168	3131958	A	0.7764105200767517	But what you need to do to manage that situation, the apt action, is very, very different.
3132124	3145274	A	0.762047529220581	And so the claim here, the kind of revolutionary claim in a way, is that emotions, the things we experience subjectively, are constructions, just like percepts are.
3145392	3156398	A	0.5627424716949463	So just like my experience of the car when I step outside my flat, is a construction that explains away the prediction error and gives me a cleaned up picture of the world.
3156564	3158494	A	0.5895593166351318	Emotions are essentially doing the same thing.
3158532	3170042	A	0.6346313953399658	They're explaining away these prediction errors and telling me this is the best explanation of these changes within your body contextualized against this external stimulus.
3170106	3178398	A	0.8227081298828125	So in the case of the date, the apt action is to chill out and be normal to a certain extent.
3178494	3181650	A	0.6656702160835266	And in the case of the bear, you get the hell out of that.
3181720	3183342	A	0.7082532644271851	Although, interestingly, you don't.
3183406	3185574	A	0.9635632038116455	Running away from a bear is a terrible idea.
3185772	3193340	A	0.7172983884811401	You should not turn your back and run away, but you get the idea that it's going to be, what you should do in each situation is completely different.
3194910	3212414	A	0.8894518613815308	So that's emotion for the active inference agent and something I don't want to lose here is what you get with this is really kind of cool because it turns out emotions and subject we're kind of moving into subjectivity here.
3212532	3219534	A	0.5138306617736816	It turns out emotions are really they're just part of the same cognitive architecture.
3219582	3220994	A	0.7066472172737122	So there's no difference here.
3221032	3224814	A	0.7567881345748901	There's no dualism between his thinking and his emotion.
3224862	3229846	A	0.8031488060951233	And emotion is this kind of fuzzy stuff that we're not really interested in.
3229948	3235218	A	0.8342483043670654	Actually emotion, subjective embodied feeling is core.
3235314	3248582	A	0.7781538963317871	It's absolutely vital to understanding how we maintain this allostatic control and how we engage in adaptive behaviors and how we remain gripped to our affordances in the environment.
3248646	3252620	A	0.826267659664154	And the notion of grip is going to be something that comes up again very soon.
3255890	3263520	A	0.7622209787368774	So very briefly, because this is something that I've really already talked about, but I want to put a slightly different spin on it right now.
3264850	3271726	A	0.7576242089271545	I've already said that allostatic control for humans can involve very, very temporarily extended timescales.
3271758	3275278	A	0.8612272143363953	And we saw this with Andy's model of agency.
3275454	3292134	A	0.47775474190711975	So if you think about something like saving into a retirement fund, for example, we're doing something that the idea is that maybe decades from now is going to kind of minor spikes in prediction error called the disappointment of not having as much money right now is going to pay off later.
3292332	3298810	A	0.7508137822151184	These are the kind of things that humans engage in and our generative models have to be temporarily thick.
3299230	3304598	A	0.8631521463394165	So George Dean writes that the levels of temporal extension are hierarchically interlocked.
3304694	3310746	A	0.8815683126449585	So shorter timescales inform expectations of what the agent can do over longer timescales.
3310858	3320020	A	0.851607084274292	So these different levels of the hierarchy are in a kind of dialogue with each other telling you what kinds of things are possible and what kinds of things you should expect.
3320550	3336360	A	0.8183905482292175	And when we were talking about agency, we talked about the way that agency is kind of baked into active inference because in order for any of this to work, the system has to have as a hypothesis, I can do things okay?
3337050	3346970	A	0.6656193733215332	And this is more or less taken to be the same thing that underpins the sense of self under active inference.
3347310	3353570	A	0.7513211965560913	So the system implicitly infers its own ability to bring about intended sensory consequences.
3353750	3365070	A	0.9066972732543945	And so Dean writes here, quote in Pristine it is in this sense that implicit in a model of sampling is a representation or sense of agency.
3366230	3373090	A	0.7939849495887756	So a minimal sense of self, it's kind of like the flip side of agency comes baked in here.
3373160	3381362	A	0.7895147800445557	So one has to model oneself as a potential cause of sensory inputs.
3381506	3392860	A	0.9035190343856812	So George Dean and colleagues, I think George Dean, Mark Miller and Sam Wilkinson propose a model of the self under active inference called the allostatic control model.
3393870	3402598	A	0.804867148399353	And the move they make here is that we have to recognize that it's not just our self efficacy that has to be modeled.
3402694	3407790	A	0.8619030714035034	We also have to have some kind of idea in there of how we're actually doing.
3407860	3413390	A	0.8788400888442993	So we have to model our own capabilities in order to set precision waiting on future action.
3413890	3424094	A	0.8080084323883057	So we don't simply infer that we can be the cause of sensory states, but also infer our own capabilities to successfully bring about expected states at longer time scales.
3424222	3430840	A	0.9083661437034607	So the phrasing that they use is tracking the performance or fitness of the model over time.
3431210	3439138	A	0.8413152694702148	So part of that tracking is going to be affective and emotional.
3439234	3441042	A	0.5373907685279846	And so there are strong links.
3441106	3444460	A	0.5699048042297363	We're kind of really digging our hooks into subjectivity at this point.
3446910	3470660	A	0.6526839137077332	But the claim with the Allostatic Control model is you get this rather than just a minimal self, you actually get a longer term phenomenological self emerge from these interlocking timescales, which are modeling not only the agent's own causal efficacy, but also modeling how good your own model is at doing what you need it to do.
3471750	3482054	A	0.7908033728599548	And like I said, I said when I was talking about the reading and I want to flag this again because I'm really not doing justice to this in the way that I should.
3482172	3500406	A	0.8577058911323547	But this has formed the basis for a lot of really interesting work on phenomena like depersonalization on the role of psychedelics and the potential for psychedelics in therapy and in meditation, ego dissolution and kind of that kind of stuff in meditative settings.
3500518	3511870	A	0.6130887269973755	So anybody with any interest in the self or in those kinds of practices should definitely go and give a closer look to these readings that I'll make sure in the document.
3513730	3516000	A	0.7752344608306885	Okay, so quick overview here.
3516390	3524020	A	0.8133684992790222	So active inference agents maintain homeostasis through anticipatory action, and this is something we call Allostatic Control.
3524390	3530740	A	0.8805522322654724	To do this, the system must engage in interceptive prediction over its own internal states.
3531130	3535186	A	0.7089753746986389	Actually, I think I've got time to do this, so I'll just deviate slightly.
3535378	3541550	A	0.955863893032074	The topic of interceptive inference is really interesting in the context of active inference.
3541650	3548278	A	0.8492733240127563	So I want to flag work by Sarah Garfinkle, who I believe is at UCL, who used to be at Sussex.
3548454	3565882	A	0.5644752979278564	And Professor Garfinkle's work looks at the central importance of interceptive predictions in various psychopathologies, especially, I think she's looked very closely at PTSD and anxiety disorders.
3566026	3582550	A	0.5912840366363525	And it turns out that an agent's accuracy in their interceptive predictions is a good indicator as to the kinds of symptoms that they're going to like, the strength and severity of their symptoms in these kinds of disorders.
3583050	3594214	A	0.7177426218986511	And what she's shown is that if you can increase the accuracy of interceptive predictions, this forms the basis of treatment for these symptoms.
3594262	3598838	A	0.584675133228302	So in short, the better you are at interceptive predicting.
3599014	3607514	A	0.8201256990432739	I think one of the measures that they use there in her lab is how well people can track their own heartbeats without feeling their pulse.
3607562	3623150	A	0.5828313827514648	So if you just sit there and try and say, like, my heart's beating like this, then the more accurate you are and the more any training you can be given to be more accurate, it forms the basis of effective treatments for these kinds of symptoms.
3623310	3636680	A	0.9595528841018677	So I just wanted to flag that because the world of research in interceptive inferences large, diverse, vibrant, super interesting and very much worth our time.
3637690	3638726	A	0.7396498918533325	Okay, where was I?
3638748	3639222	A	0.5710901021957397	Here.
3639356	3646266	A	0.8475790023803711	Okay, so to maintain all the static control, the system has to engage in interceptive prediction over its internal states.
3646448	3663082	A	0.8507686853408813	And then to best explain changes in those internal states, the system has to contextualize those changes against some extraceptive input and that emotion categories serve that role.
3663146	3668050	A	0.8146803379058838	So just to be very clear, on this view, emotions are constructions.
3668470	3678210	A	0.7218152284622192	There are some important deviations from other theories of emotion here, particularly what Barrett calls the basic theory of emotion.
3678810	3685714	A	0.5574934482574463	So on her view, emotions themselves have no underlying kind of essence or neural footprint.
3685842	3690230	A	0.8555368185043335	And there's an ongoing live debate there as well between these theories.
3693800	3703504	A	0.6134390830993652	And also just at the end, the good allostatic control in human agents is this very temporarily thick phenomena.
3703552	3717850	A	0.8515522480010986	So we engage in very long term planning that involves a lot of the kinds of counterfactual representations that we talked about with the axial constant paper and this is hypothesized to form the basis of our phenomenological sense of self.
3719600	3726812	A	0.908250629901886	Okay, we're up to an hour good.
3726946	3728430	A	0.5619860887527466	We're running on time.
3729360	3735052	A	0.6165619492530823	This is the final section and it's probably going to be probably going to be the longest section.
3735196	3750196	A	0.558488667011261	What I want to do here is I want to try and pull together some of the things I've been talking about because it's been very fast and very abstract and I want to try and pull some of these things together in a slightly more concrete example.
3750298	3752960	A	0.7705848217010498	So the case study I'm going to use is addiction.
3753120	3768490	A	0.620635449886322	So there's a particular account of addiction in the predictive process in literature that I think in a very succinct, sharp way highlights a lot of the things I've been talking about and puts them within a context that is quite stark and easy to understand.
3769680	3781740	A	0.49554243683815	But in order to do that, I'm going to have to introduce a new, slightly more difficult to understand mechanism within the framework that crops up in a lot of the predictive process in literature.
3781900	3787868	A	0.7162942290306091	And what this is going to do hopefully as well, is give us a direct bridge to phenomenology.
3787964	3800950	A	0.8183856010437012	So when we talk about things like neurocomputational phenomenology, the things I'm going to be talking about here have underpinned a lot of the work in that area.
3802360	3809928	A	0.914590060710907	So these are some of the readings we're going to look at some work by mostly a lot of the papers we're going to look at.
3810094	3814420	A	0.9318966865539551	First author mark Miller or Mark Miller's been second or third author.
3814500	3826072	A	0.8071749806404114	And I bring that up because in the discussion section on the 25th when we have an hour to kind of unpack and answer people's questions we're actually going to be joined by Mark Miller.
3826136	3834370	A	0.8233161568641663	So if anybody has any specific questions about the things I want to talk about now in this section, he's going to be the man to answer those.
3835780	3842130	A	0.6552499532699585	But also I'm going to put a lot of secondary readings up again in the document so you'd be able to find them all there.
3843380	3848660	A	0.8680979013442993	Okay, so let's switch gears slightly.
3850520	3863924	A	0.7695100903511047	I want to keep the focus on feelings, although what I'm going to be talking about here are not what might be called like full blooded emotion states, but I want to talk about something a little bit more subtle.
3864052	3878284	A	0.5889008641242981	So one thing that might seem really obvious, kind of so obvious that we often overlook it when things are going okay, is that it generally feels like something to be an agent.
3878482	3886450	A	0.5175901651382446	So when we're going about whatever business we have in the world, we always feel like something.
3887060	3890352	A	0.49537840485572815	And it's not entirely clear how best to characterize that.
3890406	3899956	A	0.7648242712020874	So I want to draw on some work in phenomenology that some active inference theorists have also drawn on and made use of.
3900058	3905430	A	0.9437733888626099	Because I think this is a really good grounding for some of the things I'm going to go on to say.
3905880	3910280	A	0.9216903448104858	Certainly proved to be a good grounding for some of the work that I'm going to highlight.
3910620	3915892	A	0.937175989151001	So these are two books by Matthew Ratcliffe.
3915956	3929160	A	0.9633502960205078	I think he's at the University of York and has done really, really cool work in kind of really getting to grips with the what it's likeness to live in certain conditions.
3929320	3944260	A	0.8046611547470093	And Ratcliffe, he argues that he's identified this certain area, this space of feelings that have been largely neglected in the wider literature, and he describes these as existential feelings.
3944760	3957912	A	0.6758438348770142	So he says existential feelings are, quote, they are not intentional states directed at however many objects, and they are not feelings of the body or some part of it.
3958046	3961480	A	0.5865893363952637	Instead, they amount to a felt sense of belonging in the world.
3961630	3970536	A	0.7073916792869568	So the main difference between a full blooded emotion state and an existential feeling is that the emotion state is about something.
3970718	3978412	A	0.8731260299682617	So if I'm disgusted, I'm typically all the time I'm disgusted about something in the world.
3978546	3981010	A	0.8468706607818604	So emotions are intentional in that way.
3982340	3989744	A	0.9132481217384338	Ratcliffe elaborates on existential feelings by I'm going to quote this at length because I quite like it.
3989782	4017210	A	0.577302098274231	He says people sometimes talk of feeling alive, dead, distant, detached, dislodged, estranged, isolated, otherworldly, indifferent to everything, overwhelmed, suffocated, cut off, lost, disconnected, out of sorts, not oneself, out of touch with things, out of it, not quite with it, separate, in harmony with things, at peace with things.
4017520	4036050	A	0.620648980140686	There are reference to feelings of unreality, heightened existence, surreality, familiarity, unfamiliarity, strangeness, isolation, emptiness, belonging, being at home in the world, being at one with things, significance, insignificance, and the list goes on.
4036740	4044444	A	0.9881054162979126	So this is really, really cool work and I recommend everybody to go and read Matthew Ratcliffe.
4044492	4045676	A	0.6795516610145569	But some of the work.
4045718	4060376	A	0.5860017538070679	I really like in predictive process, in an active inference, has taken this idea of an existential feeling and what they've recognized is that these kinds of feelings are really about how we are orientated in regards to the world and the affordances in it.
4060398	4064484	A	0.8215065002441406	So they're background bodily states of action readiness.
4064612	4071612	A	0.8565236926078796	So how are we relating to how do we find ourselves in relation to the world?
4071746	4077352	A	0.9027383923530579	So we're talking about the general structuring that's present in our everyday phenomenology.
4077496	4090930	A	0.5045515298843384	So I really want to make that clear that what this work is doing is building a bridge between computational models and the way even the underpinnings of those models in neurobiology and phenomenological experience.
4092660	4101520	A	0.7172186970710754	So the thing that I need to introduce, and this can be, it's fairly straightforward, but it can be a little bit tricky at times, is this notion of error dynamics.
4101680	4103030	A	0.8935160040855408	This is really important.
4103400	4120456	A	0.812078595161438	So like I just said, aerodynamics is going to provide this conceptual bridge between different levels of analysis and it elaborates on how systems are sensitive to the success or failure of their own action policies unfolding across multiple timescales.
4120568	4138160	A	0.6908453702926636	So the recognition here is that we talk a lot about action policies and expected states, but the reality is that we have a multitude of goals and action policies and expected states that are interlocking, overlapping, constantly shifting.
4138580	4140124	A	0.8834180235862732	The picture is messy.
4140252	4154416	A	0.6962682604789734	And so I like this quote from the 2019 paper that says the roller coaster of continual increases and decreases of errors that accompany life become expected and are folded into our expectations.
4154608	4166420	A	0.7653350830078125	For such a system it becomes important not only to track the constantly fluctuating instantaneous errors, but also to pay attention to the dynamics of error reduction over longer time scales.
4166580	4182428	A	0.7833727598190308	So the systems, the upshot of this is that these authors believe, building on some other work in computational modeling, that systems must track the rate of change in overall error reduction relative to the system's expectations.
4182604	4189804	A	0.6145464181900024	So this is the kind of global upwards or downwards trend in prediction error.
4189932	4194900	A	0.8023844957351685	That's what the system is sensitive to, how that relates to the expectations.
4196840	4209544	A	0.6959645748138428	So the idea here is that aerodynamics provide a system with a much broader ongoing sense of how they're doing to their multitude of goals over time.
4209742	4217540	A	0.7509706616401672	So a big step here is that those changes in the rate of reduction feed back into the system.
4217630	4224472	A	0.8124433159828186	So they're folded back within the system and they serve the role of modulating precision on action policies.
4224616	4237360	A	0.8034423589706421	So let's say I'm engaged in some task, I have a particular expectation about how I'm going to do at that task and when I actually engage with the task, I do slightly worse than expected.
4238340	4249648	A	0.5588946342468262	The idea there is that that rate of change, so the rate of error reduction is going to decrease until I'm reducing error worse than my expectations.
4249824	4259284	A	0.862545907497406	And in a typical healthily functioning system, that rate of change, the sensitivity to that rate of change is going to feed back and reset the precision weighting on those actions.
4259332	4273932	A	0.7041745781898499	So it's going to reduce my confidence in that particular action policy such that I might try a different strategy, I might try a different tactic, or I might just throw whatever it is that I'm doing away and go and do something else.
4273986	4283500	A	0.8810209035873413	So we're starting to see this picture of through expectations, sensitivity to change and feedback onto precision waiting.
4283660	4289052	A	0.7653908133506775	It's starting to dictate how I manage my action policies.
4289196	4295300	A	0.8842964768409729	So there's this ongoing reciprocal relationship between aerodynamics and my future expectations.
4295640	4305204	A	0.7575739622116089	Now, crucially, the claim here is that on the subject level, all of this manifests as these existential feelings of some kind.
4305322	4315204	A	0.8997557163238525	So the way that I feel on a kind of day to day basis is a reflection of how I'm doing in terms of these sensitivity to aerodynamics.
4315332	4331808	A	0.717323899269104	So when I fail at the task and precision waiting is down regulated on that particular action policy, the thing that actually kind of that moves me to go and do something else are my embodied feelings of frustration that I experience.
4331974	4339680	A	0.6451295614242554	So as conscious agents, those embodied feelings are what are tuning us towards acting more effectively.
4340820	4348864	A	0.7893550395965576	So optimal behavioral on this account is characterized as a feeling of grip towards a shifting field of affordances.
4348912	4350484	A	0.6477040648460388	So I'm going to unpack this quickly.
4350602	4367760	A	0.722463846206665	But the feeling of grip in a nutshell is just this feeling that we're engaging with our affordances in the best way that we can and that we're either meeting or exceeding our expectations for prediction error, minimization what they mean by a field of affordances.
4367860	4370350	A	0.8592532873153687	And this is again really important.
4371360	4375608	A	0.533240556716919	A landscape of affordances is just the total opportunities in my niche.
4375704	4379448	A	0.8918829560279846	So my landscape of affordances right now is Brighton.
4379624	4384050	A	0.5620465874671936	It's not really going to change very quickly unless I get on a plane and fly somewhere else.
4384900	4388144	A	0.6299517750740051	But affordances aren't neutral in that way.
4388182	4390370	A	0.6853826642036438	They don't just exist there.
4391060	4403044	A	0.6432614922523499	The affordances that stand out to me as relevant or attractive is going to change quite rapidly depending on what it is I'm doing, on my internal state, on the context and so on.
4403082	4409636	A	0.9552350640296936	So right now my water bottle stands out as attractive, a couple of keys on my keyboard stand out as attractive.
4409748	4414264	A	0.6885590553283691	But that's going to shift quite rapidly once this lecture is over and I turn to do something else.
4414382	4425390	A	0.7600042819976807	So the idea of grip is that we exhibit a stability in our attunement such that we can remain attuned as that field changes.
4426320	4439840	A	0.6428766250610352	And this is part of the skilled intentionality framework, which I won't get into because I don't want theoretical overload, but I've put some papers up on this slide as references and of course the reading will be in the document.
4440340	4449684	A	0.8305899500846863	But skilled intentionality refers to the selective openness and responsiveness to multiple relevant affordances in a concrete situation.
4449882	4460600	A	0.6889296770095825	So it's just this recognition that things change quickly for multiple reasons and we really need to exhibit a kind of flexibility and stability in those engagements.
4461740	4467064	A	0.929680347442627	And aerodynamics has been applied in lots of very, very cool ways.
4467182	4479260	A	0.6710767149925232	I can't recommend this work highly enough so aerodynamics, I won't run through how everything has been explained just for time reasons, but you can kind of take a look at this yourself.
4479330	4496448	A	0.7834151387214661	But aerodynamics has been proposed as a more complete answer to the dark room problem that we were talking about earlier, because it can explain the drive for exploration and curiosity, because it literally feels good to minimize prediction errors better than expected.
4496544	4500464	A	0.8744785785675049	So again, that rate of change manifests as embodied feeling.
4500592	4505520	A	0.7811580896377563	So we're always looking for opportunities to do better than expected.
4505680	4512632	A	0.5649349093437195	And kind of this has been suggested to account for feelings of boredom, prompting us to go out and find new things to do.
4512766	4529516	A	0.5603330135345459	And similarly, aerodynamics has provided a computational account of play, which has for a while has remained a kind of mystery because it's on the face of it like, why would we engage in play when it's metabolically costly and we need that energy for other things?
4529618	4533488	A	0.6021940112113953	Like Lisa Feldman, barrett says managing energy is super important.
4533654	4536476	A	0.9384390115737915	So why do baby animals burn?
4536508	4539440	A	0.6786307692527771	It all engaging in playful behavior.
4539940	4543010	A	0.8704673051834106	Aerodynamics has a story for us there.
4543460	4550356	A	0.5761876106262207	And there are also aerodynamics based accounts of happiness and well being and depression as well.
4550458	4552084	A	0.7779144644737244	So I won't go into the details there.
4552122	4568110	A	0.7123265266418457	But it turns out that aerodynamics and this connection to phenomenology is this super malleable, flexible kind of feature of the framework that really underpins a lot of what we experience and do as active inference agents.
4569680	4576650	A	0.800069272518158	Okay, so I'm going to talk a little bit about addiction.
4578750	4579754	A	0.7337897419929504	Got some time here.
4579792	4580860	A	0.9073706269264221	Things are going well.
4586370	4593198	A	0.6379344463348389	So I had some options here because I wanted to use a case study that really brought out some of the things I was talking about.
4593284	4600610	A	0.8585464358329773	And as I've just said, aerodynamics has been applied in a bunch of different areas and it's all very much worth talking about.
4600680	4624860	A	0.8765715956687927	But I chose addiction because, well, as you'll see, as I kind of make clear, I think it also brings out not just the way that all of this fits together, but also why it's good and why seeing people as active inference agents and broader structures as active inference structures is actually a worthwhile thing to do.
4625230	4629702	A	0.8274308443069458	So addiction was once viewed as a moral failing.
4629846	4636266	A	0.9608826041221619	So the kind of Victorian addict is too rotten to make the right choice, too self indulgent.
4636458	4642000	A	0.5391384363174438	I say Victorian unless you're Peter Hitchens and then you still subscribe to this view.
4642930	4644718	A	0.7647711634635925	But that's the old fashioned view.
4644804	4652980	A	0.8393242955207825	There was something wrong with the addict, some moral or spiritual failing, and gradually that changed to what the dominant view is today, which is the disease model.
4653590	4671606	A	0.6346858143806458	And the idea here is that addiction is a disease and that disease is characterized by changes in the brain, which changes to brain structures, which mean the addict can't help but act in a certain way when confronted with a certain stimulus.
4671718	4677014	A	0.8168783783912659	So it's this loss of control that's engendered through these brain structures.
4677142	4680650	A	0.7603951692581177	And this is the idea of it being a disease.
4683070	4700274	A	0.5182365775108337	The work that I'm going to describe now, I won't go into too much detail here, but it's kind of founded on this thought that this disease model, it can't be quite right because these changes in brain structure, essentially that's what the brain does.
4700472	4701954	A	0.6847467422485352	It's just learning.
4702152	4703762	A	0.6907173991203308	This is what we do all the time.
4703896	4716520	A	0.8726614117622375	Essentially, me completing my PhD is a process of me undergoing changes to my brain such that I'm kind of disposed to act in certain ways.
4718250	4728234	A	0.7368043661117554	Mark Lewis I think it's Mark Lewis in his book 2018 The Biology of Desire, argues, look, addiction is more of just a dysfunction in learning.
4728352	4730166	A	0.6091373562812805	It's not really a disease.
4730358	4734090	A	0.7694270610809326	So we need to think about it a little bit differently.
4734250	4740542	A	0.6756517291069031	And this work by Miller and colleagues, 2020, that's where it picks up.
4740596	4740862	A	0.7123860716819763	Okay?
4740916	4747434	A	0.7975230813026428	So the idea is that those brain changes engendered through exposure to a stimulus.
4747482	4749726	A	0.7582593560218811	In this case we're going to talk about a drug.
4749838	4754958	A	0.65130215883255	We're going to leave behavioral addiction aside for a second that clearly plays a critical role.
4755054	4764546	A	0.7743847370147705	So nobody's going to deny the kind of chemical, like the importance of the biology here that's going on in the brain.
4764578	4768406	A	0.7780751585960388	And of course, different drugs have different chemical profiles in that regard.
4768588	4781222	A	0.7111948132514954	But on this view we're going to kind of shift focus from that slightly and we're going to have a much more active picture where we view addiction as a self organizing process of whole agent environment systems.
4781286	4791150	A	0.6761779189109802	Okay, so I have this extract here it is in the dynamic interaction between the agent and its environment that addiction is born and endures.
4791490	4802386	A	0.637935221195221	So the harm of addiction emerges from a breakdown in the broader stable dynamics that typically underpin a flourishing life work, family, friends, health, and so on.
4802488	4811042	A	0.667434811592102	So a typically flourishing life has a broad kind of bush of concerns over different timescales in different areas.
4811186	4816630	A	0.5704920291900635	And what we're going to see is that the harm of addiction is in a narrowing of those concerns.
4819470	4837946	A	0.6864898204803467	So what happens is when somebody takes a drug to some people who are exposed to drugs, that drug is going to, through direct action on some neural mechanisms, is going to signal to the agent that they've done better than expected at reducing prediction error.
4837978	4839434	A	0.8430522084236145	Of course this is a losery.
4839562	4842938	A	0.5238635540008545	They haven't really done better than expected in anything that matters.
4843034	4848420	A	0.6291537880897522	But the signal they get is, wow, like, we have just reduced prediction error at this insane rate.
4849190	4864226	A	0.8330448269844055	And repeated use through this aerodynamics mechanism, repeated use is going to tune our expectations about the kinds of prediction error slopes, the kind of slopes of prediction error that are available to us in the environment.
4864338	4871830	A	0.7957800626754761	And we're going to start to expect those vertiginous slopes of error reduction if we continue to engage with the drug.
4871990	4880326	A	0.8979246616363525	And once those expectations become deeply ingrained, anything else we do is going to start to feel like failure.
4880518	4894720	A	0.6894466876983643	So if I get used to taking cocaine all the time and then I have to sit through a family meal where I don't have any drugs and I have to kind of sit still and there's no dopamine available, I don't have my phone.
4895490	4902978	A	0.7489344477653503	I'm going to experience that as feelings of frustration and as if I'm being prevented from doing something I want to do.
4903144	4906766	A	0.9240335822105408	And I'm going to experience that as doing worse than expected.
4906878	4914050	A	0.7759875059127808	So I've learnt these expectations for prediction error minimization and I'm not getting them unless I engage with the drug.
4914130	4922502	A	0.5974752306938171	And of course, it's worth noting that in many cases, these drugs are going to have chemical withdrawal effects that compound that as well, especially things like nicotine.
4922566	4924774	A	0.9681563377380371	And alcohol in particular is very nasty.
4924822	4929002	A	0.9359434247016907	So alcohol can kill you if you try and withdraw from it too quickly.
4929056	4932906	A	0.7184048295021057	So they really do pull the agent into a grip.
4933098	4937130	A	0.8096964359283447	So what happens here is the agent develops a kind of suboptimal grip.
4937290	4942330	A	0.7429000735282898	So you start to enact a new world, a new identity.
4942410	4958194	A	0.6184378862380981	So instead of doing all the things you once cared about, like different hobbies, you start to hang out with different people, you start to frequent different places, like a dealer's house or wherever, and very slowly you start to carve out essentially a niche.
4958322	4965570	A	0.5680423974990845	The addict enacts a particular niche through their actions and they have quite a good grip on that niche.
4965650	4970090	A	0.6618208289146423	It's just that it doesn't speak to a broader array of concerns.
4970750	4986590	A	0.7026515007019043	So what's really important is that this pushes back against the disease model, because on this view, the active inference agent, well, the system is doing essentially what it was evolved to do.
4986740	5001410	A	0.7335578799247742	So there's another quote from the paper here that I like that says their habits allow them to remain well attuned and keep prediction errors under tight control so long as they remain within the narrow confines of such a niche.
5003110	5010342	A	0.4973030388355255	And this is important because it shows that allostatic control and prediction error minimization are not the same thing.
5010396	5011154	A	0.5400797128677368	They come apart.
5011202	5019626	A	0.7205830812454224	And this really speaks to a question that was asked after Avil session recently about what does prediction error actually look like?
5019728	5039866	A	0.6645488142967224	Well, in this case, you have a system that has learned that engagement with certain affordances gives it an illusion, but it has this feedback that says, this is the state you expect to occupy, or this is the state that the agent has learned to expect to occupy.
5039978	5046242	A	0.7607603073120117	And it's carved out a niche of affordances that means it's very likely to occupy that state.
5046296	5048980	A	0.8471261858940125	So it actually has a really good grip on the situation.
5049350	5069900	A	0.8465664386749268	It's just that that niche is very narrow and it's constricted, meaning it's simply those habits and that web of habitual action policies are just not well suited to maintain good allostatic control.
5073420	5077080	A	0.9126182198524475	So everything else in the addict's life starts to suffer.
5077900	5082168	A	0.7340152859687805	So we can kind of think of this as a form of niche construction gone wrong.
5082254	5086270	A	0.8452882170677185	And I think we're going to look at niche construction in the coming weeks as well.
5087600	5091532	A	0.5173258781433105	So why is this whole agent well, so I should say, just to back up a second.
5091586	5097116	A	0.6447871327400208	So what I like about this account of addiction is that it's a thoroughly inactive account of addiction.
5097148	5101916	A	0.7092266082763672	It really brings out the kind of inactive core of active inference.
5102028	5106156	A	0.5945188999176025	So the addict is addiction becomes an identity.
5106268	5111056	A	0.8461241722106934	It becomes a world that the person actually produces through their actions.
5111168	5122248	A	0.8590681552886963	So rather than the disease model where you have a person and a stimulus and exposure, whenever they're exposed to that stimulus, they're going to have problems because of these brain changes.
5122414	5126120	A	0.8488258719444275	What this does justice to is actually the activity of the agent.
5126270	5139230	A	0.5505280494689941	So they're not accidentally bumping into this stimulus in the environment and they're not just seeking it out, but they're deliberately restructuring their environment to make this state more and more likely over time.
5139760	5152848	A	0.617239773273468	So it really does justice to the efficacy and the agency of the agent rather than giving that agency a more backseat role that it takes in the disease model.
5153014	5161264	A	0.6740413904190063	But the other thing that it does, because it's this inactive picture, is that it also does justice to the environmental features.
5161392	5168196	A	0.7922291159629822	So it kind of speaks to the fact that addiction is not just all in the head.
5168378	5178184	A	0.807731032371521	Actually, some of the problems of addiction come with the fact that it is this procedural, constructive process.
5178382	5185224	A	0.625722348690033	And one of my favorite experiments of all time is I don't know if people are familiar with the Rat City experiments.
5185272	5187230	A	0.850387692451477	This is why I've got the image up here.
5187680	5202876	A	0.6190553307533264	And this was a very cool experiment where originally it was found that if you exposed rats to a drug laced stimulus in the environment, I think it was heroin laced water, or it might have been cocaine.
5202988	5213392	A	0.7508223652839661	But the original experiments found that nearly all the rats would kill themselves with the drug, so they would just keep at the drug until they died.
5213456	5223992	A	0.7655450105667114	And it was a very high percentage of the rats would engage in that destructive behavior until the experiments were rerun some time later.
5224126	5236504	A	0.8710178136825562	And instead of having the rat just in a boring cage on its own, it had the rats in Rat Park, which was a very social, exciting, brightly colored environment with lots of different affordances.
5236632	5244056	A	0.5280575156211853	And what they found was that given the same choice, a vastly reduced proportion of the rats would choose to engage with the drug.
5244168	5251504	A	0.966164231300354	Okay, so it's capturing the importance of niche construction that I think is really nice here.
5251622	5257768	A	0.8560513257980347	And it also speaks to the role played by embodied affect in phenomenology.
5257964	5262640	A	0.703199565410614	There's something that it's like to be an addict and that really matters.
5262800	5276344	A	0.8211963176727295	It really matters that the addict has these embodied experiences when they're engaging with particular sets of affordances so that's really summed up in the overview that I've put here.
5276382	5278920	A	0.645648717880249	So these were the things that I wanted to emphasize.
5279660	5282728	A	0.8012387156486511	Active inference agents are embodied.
5282824	5284780	A	0.7051923871040344	They're embedded in a landscape.
5285200	5288888	A	0.7242846488952637	That landscape is constituted by particular affordances.
5288984	5294152	A	0.8474962711334229	And we can distinguish between a landscape of affordances and a field of affordances.
5294216	5306610	A	0.8645880222320557	And that distinction really speaks to the inherent affectivity and normativity of affordances, which affordances stand out to us at a particular time, which exert a pull over us.
5307160	5311008	A	0.8867207765579224	And active inference agents enact their worlds through action.
5311104	5314100	A	0.6916466951370239	And this is nowhere starker than in the case of addiction.
5315800	5318400	A	0.5935502648353577	Active inference agents are effective.
5318480	5330730	A	0.5050941705703735	So emotion plays this super crucial role, keeping us tuned, keeping us in that grip with our affordances, and helping us contextualize those important physiological changes.
5331920	5335180	A	0.7460654377937317	Active inference agents are agents, okay?
5335250	5346972	A	0.7394900321960449	So we do have a way to describe behavior as agential and motivated, and we do have these cognitive architectures that can make sense of agential action.
5347116	5353330	A	0.8990219831466675	And active inference agents have this inbuilt sense of self that comes with agency as well.
5354820	5356576	A	0.5845398306846619	So that's pretty much it.
5356678	5360644	A	0.6270508766174316	This final slide just goes over some of the things that we can expect.
5360762	5370400	A	0.9436662793159485	So what I've done today, I hope, has laid a good groundwork and has installed some higher level expectations to learn more about active inference.
5370560	5384380	A	0.8937259316444397	And what we're going to do in the subsequent weeks is now scale this up to see how when you have more than one active inference agent together, how the expectations of some can impact the expectations of others and individuals.
5384800	5388380	A	0.928948163986206	And I look forward to learning more about that.
5388450	5391550	A	0.7221759557723999	But as for me, that's it.
5395430	5395986	B	0.8019313812255859	Amazing.
5396088	5397700	B	0.9418561458587646	Ben, awesome work.
5398070	5404546	B	0.8964037299156189	What can people look forward to next week or in two weeks if they join the discussions section?
5404578	5407430	B	0.9053009152412415	Like, what's it going to be like or who would you encourage to join?
5408810	5412102	A	0.9596806764602661	Definitely, I mean, the more people that come along, I think the better it's going to be.
5412156	5413914	A	0.9863155484199524	I'm really looking forward to it.
5414032	5419254	A	0.9557861089706421	I'm kind of just in the first place, intrigued to see we covered so much ground.
5419302	5424830	A	0.8137431740760803	I'm just interested to see where people want to go with this and see where people's interests lie.
5425410	5435914	A	0.5035312175750732	I assume that people are going to have questions, and I think maybe the best way to do it would be to explore some of people's questions during the discussion.
5435962	5447640	A	0.5631563067436218	We can use them to kick things off and keep things going, but I think it's likely that we have a whole hour, so we've certainly got time to really dig into things in some detail.
5448010	5452134	A	0.6742905974388123	And like I said before, we're going to have Mark Miller with us.
5452252	5463866	A	0.970524787902832	And Mark is just awesome in discussion, very passionate and enthusiastic about his work, and he can do a much better job than I can in explaining it.
5463888	5470060	A	0.8640166521072388	So just to have the opportunity to speak with Mark about his work, I would say definitely come along.
5471870	5472362	A	0.4896697998046875	All right.
5472416	5473002	A	0.7329490780830383	Anything else?
5473056	5474780	B	0.915721595287323	Otherwise, again, awesome job.
5475950	5477430	A	0.6655771136283875	No, I think that's it.
5477600	5478862	A	0.8959478139877319	Thanks for listening, I guess.
5478916	5479662	A	0.6758424639701843	Well, thanks.
5479796	5480714	A	0.9547486901283264	It was a pleasure.
5480842	5500962	B	0.5298160910606384	It was ambitious to do what you did elegantly with no equations or getting snagged on any of the potentially infinite philosophical and technical and normative and all these different layers of challenge and diversions.
5501106	5505910	B	0.8369476199150085	So to really cut a path there is great.
5506060	5506374	A	0.5491447448730469	Yeah.
5506412	5512806	A	0.884425699710846	I think it just speaks to there's so much good philosophical work in these areas in active inference and predictive processing.
5512838	5519002	A	0.8404423594474792	And I should say, again, we didn't really do justice to any of the work I talked about.
5519056	5531260	A	0.9191014766693115	So the final thing I would say is definitely the document is there with the reading, and please go and actually look at the work of these people, because some of it's really good.
5531950	5532954	A	0.4896697998046875	All right.
5533152	5534354	B	0.6996943354606628	Till next time.
5534512	5534882	A	0.84200119972229	Cool.
5534936	5535842	A	0.9599630236625671	Thank you very much.
5535976	5536480	A	0.6398490071296692	See you.
