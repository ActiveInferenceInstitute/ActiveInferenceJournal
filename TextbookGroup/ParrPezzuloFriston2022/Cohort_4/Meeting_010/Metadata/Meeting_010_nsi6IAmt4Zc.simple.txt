SPEAKER_00:
All right.

Greetings, everyone.

Thanks for joining.

We're on 8.8 in our second discussion on Chapter 4.

So one question was brought up that we'll definitely come to, but is there just anything else that anyone else wants to add about for any just reflection or any question that's kind of surfacing that we want to add to the stack?

All right, let's go to the message passing.

Okay.

So in message passing, is there a decay of information as the distance between the variable X and individual Markov blanket constituents increases?

Is implementation of information decay in message passing an option for model implementation?

Who wants to give a first thought on that or any other kind of curiosity around it?


SPEAKER_03:
I'm not sure if I'm understanding it very well other than intuitively, but what it

I mean, would it be the case that, like, information decay wouldn't necessarily, I suppose, make sense here given the models that are already working in terms of, like, time steps?

And so you're already kind of, you know, you're recomputing your gradients and your posteriors and so on in every given time step such that,

you know, the idea of some kind of holistic piece of information that's being carried from time step to time step doesn't quite make sense.

That is each time step involves an entire set of like recalculations.

Does that make any kind of sense?


SPEAKER_00:
Yeah.

So just to start with, one uncertainty is I'm not exactly sure about message passing in the continuous versus discrete time setting.

Again, hopefully something that we can unpack and talk to Magnus Kudal at all, since I know that he's an expert on the continuous time setting.

But any other thoughts on this?

Or I'll try to give...

an answer.

Ali?


SPEAKER_04:
Yeah, just one quick note about message passing is, I mean, before going into the details of how exactly message passing happens in Active Inference Framework, it's probably worth noting that it's inversely proportional to the robustness of any self-organization systems because

You see, if we consider an agent and its peripheral systems or peripheral, let's say, limbs as a kind of fully centralized system in which the message passing happens almost

in a fully centralized way from the brain or, I don't know, the central processing unit onto the lens, then this system would not be as robust as the system in which this kind of message passing is distributed among the elements of the system.

I think that's one of the reasons why we see signal decay or the loss of information as we go up to the hierarchy.

The more we go up to the hierarchy, the less precise the information becomes.

But in order to have more and more precise information, we need to somehow

acknowledge a kind of autonomy onto the peripheral nervous system as opposed to central nervous system.

So that's one of the ways, I mean, in humans, nervous system is organized in which this kind of distribution of agency, I mean, autonomous

agency is distributed among both peripheral system and the central system.

And coming back to active inference framework, I also believe in this framework, it beautifully captures this kind of hierarchical model because

Obviously, as we move farther away from the peripheral elements of any system, the elements which have direct access to the environment, not direct access, but closer access to environment, then the accumulation of probabilistic errors becomes larger and larger.

And that's why

In order to have reliable information, we need to discretize these kinds of information at some point without necessarily having to take into account every single bit of information that we receive.

on the lower levels of the I mean, when we're dealing with the lower level systems, we mostly deal with continuous time models, which allow for more precise kind of formulation of message passing.

But as we go up to the

central nervous system and conceive discretized elements of organizations such as cognition, emotion, and so on, or decision-making, this process becomes much more discretized.

So that's basically the idea behind the hybrid models of active inference in which we can incorporate both continuous time and discrete time elements into a single system.


SPEAKER_00:
That's awesome.

Thank you, Ali.

Alexi?


SPEAKER_05:
I wonder if I can ask you, Ali, to clarify.

So let's imagine that I'm a shark, right?

And if I go up the hierarchy of beliefs, then perhaps the most firm, coarse-grained belief is that I will survive.

One step down from that is that I can breathe in water, right?

So as the message comes up in the hierarchy, I don't need as many details like,

because these are not going to change.

If they change, I die.

Is that kind of what you're saying?

Exactly.


SPEAKER_04:
Exactly.

Yes.

Because as you said, as we go up to the hierarchy, we'll need much, much less detail.

And we just need to take into account, I mean, the general gist of the information we get in order to survive or I don't know, achieve a goal or something.

But obviously, if we want to, I mean,

take into account every single detail of every endeavor, we'll need much more precise channels for information passing.


SPEAKER_05:
And if I may, one more quick question.

In Chapter 5, they make a point to say that ascending messages, which are prediction errors, are usually higher frequency than descending messages.

I mean, they declare it, but I didn't exactly see where they take it from.

And so I was trying to, they illustrated with a cortical column.

And I was thinking that, you know, indeed, this is very interesting research that we have top-down messages that are, you know, beta, rhythm, or something like that.

And they govern the gamma, which is higher frequency.

Could you talk a little bit about why prediction errors and ascending messages are higher frequency nonlinear functions?


SPEAKER_04:
OK, I mean, on this question, I can only take a guess because I don't honestly know the exact answer, but I believe the reason that the ascending information is I mean, they're on a higher frequency level than I mean, the descending information is because

Again, coming back to this hybrid model of continuous time and discrete time, ascending information deals with, let's say, a continuous discretization of information.

And that's why, as we go up in the hierarchy,

we'll need to have much higher frequency for the information gain because we need to construct those discrete information as quickly as possible.

Based on those discrete elements of our information, we can then infer any necessary prediction, any necessary information about the error that we get or any other kinds of manipulation or optimization we need to take into account.

And I believe this kind of

bidirectionality maps quite well on adaptive resonance theory, Grossberg's adaptive resonance theory, because in that theory as well, this kind of bidirectionality between the ascending information and descending information comes in a kind of resonance.

they adjust their frequency as to become the resonance fully cyclic passage for information, both going up and going down.

So that's why I believe in this kind of framework also it's necessary to take into account

different rates of frequency for both ascending information and descending information in order to allow for this kind of resonance to happen between those two lanes.


SPEAKER_00:
This is awesome.

It's a lot of great information.

Let's try to add a few pieces because I think there's different aspects here.

So first, I'll let you point into the topology of message passing.

Messages are being passed on the topology of the variables.

So how the variables are connected is how the messages are being passed.

Sounds kind of circular, but that's the whole reason why this box discusses basically the Markov blanket.

which is just describing any given node is going to be surrounded by a blanket for that node.

There's an absolute tag on a given node.

So it can't be said just singularly, this node is an internal state or a blanket state only with respect to the whole partition.

But that's why two message passing strategies are being described directly alongside the Markov blanket.

So a lot of times we see that particular partition

in active inference, or just more broadly, we see a Bayesian graph and how the variables are connected.

And this is going to be an implementational or operational procedure that's going to compute what it's going to turn the crank one gear for a given

topology of connectivity um so this point about the robustness is similar to to the robustness of a distributed system i mean if you have a fabric with only local connections then it may take some time to propagate or percolate with the information but on the other hand there's not a single note of failure and all these other um features um

message passing graphs can include discrete and continuous time and street continuous state spaces like all of these different variants that we've been discussing play nicely together chapter 8 comes back with a hybrid model and Livestream 46 on the folk psychology where in the periphery it's more like continuous sensation and action and then as you um get towards like the cognitive decision-making states you're dealing with discretization um okay

uh another point is about like the computational tractability so there are um works like this one from 2019 with par at all where let's learn more about the technical details but basically there's a few different flavors of this message passing implementation

that are also kind of hinted at in the um in the box but suffice to say that like for a given topology of a bayesian graph which might be describing a cybernetic system active agent or it could just be any other bayesian graph this isn't about perception action specifically but on any base graph you can basically define an implementational procedural pseudocode for how to just

bring it that much closer towards harmonization, where if it's kind of the ball is already at the bottom of the bowl, it's not going to go anywhere.

But then if it's not at the bottom of the bowl, from like a variational inference perspective, it will go there.

And there's a procedure for doing that that's tractable.

Why is the frequency higher on ascending messages than descending?

So first, these kinds of phenomena

constitute empirical evidence for hierarchical predictive processing architectures but but the framework doesn't depend on these phenomena being the case for our real nervous systems but but they're always nice to find and there's a few ways to go here um one connections with the nyquist frequency so this is um if you're going to be sampling from vinyl from analog

Then that's a smooth curve.

That's the continuous time.

That's like the motor perception.

That's the peripheral nervous system.

That's the record.

That's like a clock with a smooth moving minute hand.

And then you're gonna have it translate to digitization.

Like you're digitizing the record.

So if there are top-down predictions, like about the hour in the clock metaphor, we could have ascending predictions about minutes and descending predictions about hours happening every clock cycle.

There's no reason why you wouldn't do that.

But at the same time, you can bake in this structural understanding that hours are top-down and slower.

which is consistent with more broadly in nested outer layers, deeper, however you want to think about it, they are slower and bigger.

So you only need to send down that hour expectation more infrequently.

And then just lastly, like signal decay.

If you have a Markov chain, so just think really simply about some, just without bringing action too much into it,

think about just the perceptual part here.

So just like the music listening example that I think is in seven.

So here we are, this is a partially observable Markov process happening through time, emitting an observation.

So it could be the temperature changing in the room through time, but we're not intervening.

So no action yet.

Imagine if B were the identity matrix, like all ones on the diagonal, you would just be carrying S forward with perfect fidelity.

but if b were like 0.7 on the diagonal and then 0.1 on the off diagonal which is like what the case that it was in the music example then you you can if you set up a hundred of those runs next to each other it'd be like the signal was kind of like blurring by ten percent um each time so

The signal, it depends on like if there's a degradation of the signal as it's being passed.

Here it's being passed in time.

If it's being passed noiselessly, then the signal propagates more distantly in space and or time.

Whereas if the insulation around a node is such that it blurs half the information upon its immediate exit, then that information, like that perturbation of the Bayes graph, it just dampens more rapidly.


SPEAKER_04:
Ali?

Thanks, Steph.

Connection to Nyquist frequency was really insightful and helpful.

But to add to your point here, I also believe that if there wasn't any gradation of frequency between those two paths of information passing, I believe something like an aliasing effect would happen if the brain or any

kind of agent wanted to reconstruct the information from the input system and then produce the necessary output system because I mean it's necessary to

somehow distinguish between the frequency of incoming information as opposed to the frequency of the reconstructed information in order to evade these kinds of aliasing type effects, which obviously would be undesirable.


SPEAKER_00:
yeah cool and also ties to the um ultimately the audio visual roots of predictive processing it was not generated to describe or explain biological phenomena it it arose in the 70s 20 years before round ballard 1999 in the context of maximum information compression for audio visual and then the other um sort of connection back to the more like bodily

maybe a book that that some of you are are more familiar than than i but the body has a head it's kind of like a exploratory narrative um biology physiology book but but of course the title is the provocation about the body's primacy in i guess what we would say action inference alexi yeah i wanted to reflect on what you and ali said um


SPEAKER_05:
about the Nyquist frequency and also going back to, please forgive me, ascending messages, prediction errors, higher frequency.

If we take this evolutionary kind of thought that the higher in the hierarchy I go, the more difficult it is to update a prediction.

They're more well entrenched, right?

So let's imagine that I'm a rat and I have an inborn phobia of cats.

One strand of cat hair

you know, causes freezing.

But if I'm in the environment where there's mortal danger, like a trap, and the only escape route smells like cats, then I have to update that very firm prediction to get out.

So it takes high energy, which in like Planck's equation means high frequency to update the high level predictions.

I know it's very speculative, but what do you think about that?


SPEAKER_00:
Yeah, I think there's a few ways that you could model that.

Let's just say we have an aversion to cat smell.

It's a negative value in C, or it's a lower value in the C vector, just to be clear.

We're talking about some sensory vector.

And in our generative model, we have some value that just is called cat smell.

And we prefer it to be lower.

Well, if there are two paths on the maze, then to take the path with the cat smell, it has to have pragmatic or epistemic value.

So if we have a 10 to one aversion to the cat smell, but then the expected free energy of the cat path is greater than 10 to one, then you could think about that as like the circumstances

reflected by the epistemic or the pragmatic value of a course of action, but the circumstances would lead to selection against that.

There's probably other ways that it could be explored.

One would, yeah, but yeah, higher, and there may or may not be these kind of, it may or may not be in

option like i'm thinking about trying to trying just like trying to see two colors as indifferent when you can clearly see them as different or something like that like you're gonna butt up against some fundamental like the wavelength of light or like maybe there's a sound that maybe you know some sounds are maybe culturally aversive or not or pleasant

maybe there's also just a volume or some type of sound that that it's like yeah probably you can't can't but then again if that was the only path to escape a burning building then that kind of stuff would happen so then i think it you gotta zoom out beyond the single dimensional generative model

And then consider more holistic generative model.

Like we have 10 to one preference against cat, but we have a hundred to one preference for blood glucose.

So then right there, you've constructed a generative model that enables you to make risky decisions.


SPEAKER_05:
Thank you.

That's very, very useful.


SPEAKER_00:
Yeah.

And in the end, it's not about the rat.

That's the territory.

It's about the generative model.

So different modelers may construct different generative models that display certain kinds of behavior or not.

So we have the portfolio of models, and then we ask, well, what experiment is going to help us update our attention to these different models?

And someone has one where there's only, you know, cat smell, yes or no.

Somebody else has no, a little bit and a lot.

Somebody else treats it like a continuous variable.

none of those are the true map, but we have all the maps on the table.

And then that allows us to design the experiments or the circumstances that would differentiate the unique predictions and explanations from those maps.

Ali?


SPEAKER_04:
It also reminds me of Terence Deacon's nested conceptions of information.

So instead of representing these kinds of relations, hierarchical relations as higher order or lower level, lower order processing of information,

Uh, he represents them as three nested, um, kinds of information, uh, in which the Shannon information is, would be the most basic one.

And then, uh, referential information, uh, which is, um, he also refers to as aboutness information, uh, incorporates a kind of medium susceptibility to, um, any error.

And it is an emergent information rising from those Shannon information.

And ultimately, we come to significant information, or in other words, information about usefulness, which is what actually dictates how the survival of the species ultimately is determined

I mean, through the evolution and so on, and it incorporates a kind of, I mean, the connection or association between the

Reference of that usefulness information and the teleodynamic requirements of the species is what dictates what would happen in the significant information or in terms of FEP, the minimization of free energy.


SPEAKER_00:
Nice, that's awesome.

Yeah, information's like one of the most overloaded terms or just loaded terms, but Shannon, 1948, studying signal transmission in the telegraph networks.

So it has to do with that pure Morse code level of being able to distinguish like a signal from noise and then projecting all that down to the Shannon entropy.

And then to the extent that a signal can be detected from noise, which is about the observer, not the system in itself already, then there's this like semantic or symbolic information.

But symbolic or semantic information, if we're going to continue with this evolutionary line, like, okay, so here are the photons.

We can pick out the signal in the photons, a signal in photons.

It looks like it's yellow and red.

is that a good caterpillar to eat?

So one has to go beyond the kind of Shannon information.

If you just had the entropy, Shannon entropy of different natural settings as a bird, that's still two structured jumps away from like, should I go for this caterpillar or not?

But a lot of times this is taught as information theory, kind of the beginning and the end of information theory, when this is the syntactic information and then the semantic.

But the abstract semantic is still not the actionable information.

Let's see, someone has added, the key things, how you define the Markov blanket.

I mean, yeah, but we're not playing with the definition of what a Markov blanket is.

Maybe this could be rephrased as the key thing is around which node you choose to highlight as your system of interest, call it internal states, and then the Markov blanket is trivially defined around it.

IE, there's a partition between whatever, or there's no partition.

Well, again, if you're using a plural definition,

There is a partition between them.

That's what makes you think that they're two different things.

Or there's no partition and everything under the blanket is conditionally dependent.

Well, the fact that you have modeled a blanket or a partition at a given scale doesn't preclude there from being, as they say, message passing within the same blanket.

Because blankets are not something fundamental.

It's like saying, could messages be passed inside of California?

Yeah.

but but then also you could go to the county level and there can be messages between the counties or between the cities or or you know between the agricultural objects within the the region I've not seen this with love of so many point references I'm not sure exactly which exact reference but more broadly nested um Markov blankets

could look to the kind of earth systems modeling or our uh variational eco evo devo paper nested markup blankets they're having message passing within and across and the kind of like lateral same type of thing same scale message passing

then now that you're you know you you passed all the messages amongst the states and now we're in california and then you pass all the messages amongst the counties and then but i don't have a specific reference where that is is written out but yeah what an interesting question and and message passing is so cool because it really connects like this

But what if this was just an abstraction and there wasn't any procedure known for how to compute it?

Then you'd have kind of like the blueprint of a building, but it'd be awesome if you could build it.

But in fact, this is the blueprint and the blueprint can basically be rendered or operationalized into a procedure.

So that is a super, super strong connection and also one that's not unique to active inference.

Although as far as I know, the 2017, this paper, I believe is far more general.

Somebody can add more here, but basically here's the continuous and the discrete representations.

And in this paper or some other one from this era, like they showed that every Bayes graph has a Forney factor representation.

And then previously it had been shown that every Forney graph had a message passing implementation.

So in this paper or some other one,

um like it kind of connected all the pieces up and said yeah now there is a message passing procedure on arbitrary bayesian graphs again that doesn't have to be about even a perception action system i'm i think it just made the general case um

So message passing is definitely important.

And also it's another example of like perhaps even a difference in practice between like deep learning, reinforcement learning, machine learning, AI, and active inference to the extent that the distinctions can be drawn.

Just to highlight, because there's of course multiple differences that we've talked about, but a lot of the work in AI and ML goes into like

figuring out the implementational detail like kind of getting um getting in there with the specifics of the model whereas once something is stated as a base graph then it's kind of like standard methods like you don't need to intervene in how your source code is compiled

And so, similarly, the message passing step kind of compiles it into a procedure.

But you don't need to step in to fine tune how the blueprint goes to the construction.

Which I believe is a great advantage.

anyone want to want to go to the specific question or we'll just try to look there's so many questions on on chapter four so anyone can just like bring up one or or some topic that they thought was cool in the chapter um actually i did want to briefly just kind of harken back very quickly to something ali brought up earlier um


SPEAKER_03:
which is adaptive resonance theory and maybe how it relates to the asymmetrical frequencies found in message passing.

And I know in chapter five, where we start discussing kind of, or we start seeing more discussion of like neurobiological correlates and things like that, you know, there are these references to

nonlinear functions being involved in the computation of prediction errors such that, what is it, sending messages tend to be much higher in frequency or faster than descending messages?

I mean, are all of these things kind of related, you know, as far as message passing goes?

I'm rather into things like fMRI and EEG analysis.

I kind of have a personal interest in the asymmetrical frequencies question, if all of that tracks.


SPEAKER_00:
Yeah.

Well, I think that the sensor fusion neuroimaging world is where a lot of these statistical methods can be traced.

by virtue of the SPM origins.

And here, this live stream

was um excellently prepared for by ali uh professor grossberg was one of the uh relatively small fraction of guests who prefer full-sighted referenced questions before joining but also he prepared excellent answers and there was a great discussions


SPEAKER_05:
about the uh compatibility or or reconcilability of of art fep active everything alexi yeah i'm just grateful for your question again going back to it and i have the same interest but um you know come come join us on august 23rd if you can on uh the chaos theory paper i mean i think i'll try to talk about how

the higher the frequency of the EEG, the higher the Kolmogorov-Sinai entropy, the higher the level of chaoticity.

And there's much evidence kind of converging on that stuff.

Today on Twitter, of all places, Earl Miller from MIT was talking about better frequencies governing the

exchange between medial prefrontal cortex and right hippocampus for spatial work in memory.

So that does seem to kind of not only be theoretical, but also confirmed empirically that we have kind of control signals are slower.

Think about the brain, you know, subcortical neurons are firing one at one tenth of the frequency of cortical neurons and subcortical neurons and brainstem are arousing the cortex.

They are

kind of the blood and the energy, the arousal, generalized arousal comes, you know, that way.

And another thing I wanted to mention is about the prioritization of sort of, Mark Solms talks in his book about how working memory is a very small space, like seven chunks of information plus minus two.

And when we feel something, it has to get into working memory.

Otherwise, you know, we have to be conscious of an intense feeling.

And ordinarily, for example,

We don't like urinate or defecate in public.

This is embarrassing.

So we hold it.

We inhibit the wish.

But when people go through like public execution or hanging, that wish is completely released because there is a higher priority.

There's an existential catastrophic threat.

And then this sort of fear of social embarrassment is completely deprioritized.

So it does suggest that we need a very high energy signal to kind of overcome very well entrenched predictions.

So

It's a vast topic and I'm highly interested in it.

So if you're interested, maybe we can talk and collaborate.


SPEAKER_00:
Cool.

Cool.

Thank you.

And again, to connect that to the Terrence Deakins, like a high energy signal, are we talking about an informative signal?

Because an informative signal could just be 10101010 cleanly or something like that.

Are we talking about a powerful, meaningful, just some cultural landmark that has a specific aboutness but isn't situationally relevant?

Now, the high energy is happening at this higher cognitive level.

It might even be a subtle signal informationally.

or it might even be a subtle signal symbolically or semantically.

But that's the whole thing with like early warning systems and like, you know, just the movement of a shadow or the rope coiled up on the ground might convey extreme actionable information.

Whereas there might be something in a different quadrant that's like very clear, but not survival relevant.


SPEAKER_05:
exactly i mean i think that if you go into like ecological evolutionary goal of mammals to survive and reproduce then okay so survive means eat and don't get killed and so uh sexual functioning and uh gastrointestinal functioning is disabled when we are in a state of acute fear acute fear takes precedent because if i'm dead it doesn't matter

you know, I will not be able to reproduce.

So my first job is to sort of, there's a prioritization happening and that's going to be an intense single that just, you know, uh, occupies the entire mind and just casts everything else out.

Right.

Um,


SPEAKER_00:
yeah I mean a lot of these um whether we approach it from like a circulatory system or like a more abstract information like a lot of these um patterns are explained or predicted or or so-called paradoxes are are um kind of shown to be otherwise when it's like

yeah, you can't have max blood flow to every region at the same time.

Like if you could do that, then you would just have some higher level of allocation to do.

So yeah, when you're running, your gastrointestinal tract slows down.

Like there's just a shunting of resources and there's a shunting of attention as well.

So it doesn't make sense to have a system where equal maximal attention is being

uh deployed it it it's just not viable but we can describe it so that's like why the the active motifs and and all these like like concepts these are our grammar or our ontology that gives us the expressivity that we need to do the modeling

But so we can describe systems that, yeah, maybe there is a system that pays equal attention to all of its 10 ideas, but or not.

Or, you know, it doesn't have any ability, an organism that doesn't have the ability to shunt or redirect blood flow or attention.

Or it doesn't have the ability to do sensory attenuation or something.

I mean, you can build it.

Okay, a lot of these questions are about specific variables.

We may have come to this one last week.

Why is the marginal likelihood called marginal?

Does anyone know this or have a thought?

Yeah, Ali, go for it.


SPEAKER_04:
It's a remnant of statistical theory, because you see, when we sum the probabilities of a given event in a tabular form, the ultimate sum would be written in the margin of the table.

So that's where this marginal probability term comes from.


SPEAKER_00:
Perfect.

Yeah.

What a great, what a great term in the margin of the spreadsheet when they summed across, um, kind of collapsing on one thing, conditioning on one thing happening, you can collapse across the other dimension on the spreadsheet and then it's in the margin.

um yeah so so many questions um another another kind of uh uh clear one uh belief updating about policies to update beliefs about policies we find the posterior that minimizes the free energy does the posterior at time t become a prior at time t plus one

Yes, it does.

So like D, we call that variable in the generative model, the prior, because it gets the whole chain rolling.

But you could also think of this as just like kind of being like a starting position on this unfolding sequence.

So there's a temperature in the room and we're just gonna say, well, our data or our modeling started at midnight and it was 30 degrees.

We're just going to inherit 30 degrees if it was a precise prior.

Or you could say we're going to start the chain by pulling from a prior distribution.

So we're going to start the chain with 30 plus or minus 10.

And then we're just going to let it play on.

And then in that situation, with respect to the present moment, S sub T, this is a posterior with respect to what just happened.

But it's a prior for what is about to happen.

So just like Markov blanket is not kind of absolute, it's about which variable you're talking about.

Also prior and posterior are relative to the incoming observation.

So one, after you've updated to the posterior, it's not like you just stop.

Then that updated value for the hidden state becomes the prior for the next incoming piece of sensory data.

a lot of equations that I hope we can unpack and develop in in math group and and otherwise um and and like annotate richly and make sure that for all the equations that we have those um descriptions and yeah chapter four's a big one I mean there's a lot to it and

Brings up a lot of big topics.

That was our second discussion on it.

We are close to the end.

We'll go into chapter five next.

Also, I remember.

Thank you, Lexi.

Bronwyn, I think you, some discussions that we had, what is the specific message passing neurobiology in the setting of chapter five?

So how should we prepare ourselves?


SPEAKER_02:
Yeah, that was a while ago.

Yeah, it's a tricky subject.

I've been listening and thinking through today.

I've just gone back to equation 2.6 because I got a bit confused.

But it was just about, you know, message passing in the relationship to the reduction of free energy and expected free energy.

But I'm still thinking about it.

So I might discuss it next week if I come up with something.

But I think it's...

It's very complex.

And then you've got the hierarchical thing happening.

But one question I had was that over a synapse, there's sort of two functions.

One is a facilitation, one's an inhibitory process.

And I think we don't consider the inhibitory process or ability to inhibit very much.

It's sort of all about action.

Yeah, I have to think about all that.

that's um i mean in this yeah in that in that equation you've got all of your um all of what you were talking about taking risk um you know that that that thing about the cat the cat smell example but within that selection of a policy for the uh reducing expected free energy um you want the one with the least expected free energy but you're also balancing up

other factors in terms of the three nest.

I think the three nested thing was really interesting because it gave you that hierarchy of habitual responses as opposed to considered ones and higher referential or significant evolutionary considerations.

But underneath it is this equation.

I think the relationships between these things in that moment when someone makes a decision,

Yeah, it's quite a complex thing that the brain does, really.

That's my thoughts.

Oh, yeah.

Very basic, but here I sit.

So anyway, I've been doing other things lately, so I'm a little bit lost and I haven't had a good re-look at Chapter 4, but I will between now and next time.


SPEAKER_00:
awesome yeah a lot of ways to go there this um functional this this um can apply to a nested system it's just all kind of abstracted there and again this is kind of like that blueprint view message passing helps us get there

with the how so it's kind of like the low road which is where this equation comes from chapter two yeah this is it's it's like it's explaining the how and then the message passing is like the how on the how and then also like what you said about

um you know one one uh world view is like the central uh operator central governor is kind of being like spurred into action it's all about like excitatory signaling from the outside um or um it having to stimulate a passive exterior through like um you know carrot and stick or just stimulus in general um and then that reminds me of tom froze um with his guest stream on the eruption

which is like, yeah, what if it's like, there's just this like seething activity and then what's happening is like inhibition and breaking.

And then like in those spaces that are opened up through inhibitions and breaks,

things unfold so it's not like the decision making was was like you know shining the laser on where to go it's like no there's there's more than enough energy to go around mental energy and it's just about um knowing when to inhibit when to break


SPEAKER_02:
Yeah absolutely.

I think the problem is it's not about making a decision it's knowing when to inhibit and that's from the work that I do really is a strong point of

Summit HQ.

: inhibition as a very important part of decision making and action in the world, just how we behave.

Summit HQ.

: Really, I mean you know, if you look at the basis of the sign up so you're in facilitating or inhibiting and that's the balance between those two in terms of message passing but nobody talks about inhibition very often.

Yeah.


SPEAKER_00:
Yeah.

Great.

I mean, in the number go up world, reward is good.

More reward is better.

Stimulate reward.

Reward is stimulating.

Sugar is good.

All that.

Versus in the predictive processing, at least we open the discussion to both hands of up and down and stimulate and inhibit.

Or maybe neither stimulate nor inhibit, just different.

yeah yeah so it's it we have all the axes we need and and that's why chapter six exists because so much of the challenge is like what building do you want to build so if we said okay well from this we can optimize it super tractably it's not going to be an issue but what is it what is that model going to be

And how are you gonna iterate on that in a real setting?

Which brings the whole understanding into action.

And earlier, yeah, this was just the last paragraph of the book.

Active inference is not something that can be learned purely in theory.


SPEAKER_01:
No.

Boom, boom.


SPEAKER_00:
that's the action people keep forgetting about the action the two are entwined you can't separate any of it uh so yeah awesome yeah well fun fun discussion thanks andrew for for highlighting the message passing um angle and it's going to be a perfect lead-in to um chapter five

where we will revisit message passing again from this like nervous system angle yeah great okay thank you all until next time thank you thanks everyone so much bye