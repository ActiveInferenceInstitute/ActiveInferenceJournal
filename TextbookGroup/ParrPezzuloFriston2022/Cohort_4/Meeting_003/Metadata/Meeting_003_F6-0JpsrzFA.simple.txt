SPEAKER_01:
All right.

Greetings, everyone.

Welcome to cohort four on June 20th for chapter one discussion.

We're going to get to chapter one discussion in one second, but I wanted to just show one area of development and something that people can explore and then mention one thing about math learning group.

So first, in the equations page.

there's a few sub pages that might be interesting to explore.

First, where we previously had the equation screenshots, so you could like mouse over equation 2.1 and click on the screenshot, we added the LaTeX.

So this is just a plain text code that renders in Coda.

Then there's some sub views that use Coda AI.

So this explanations view,

These prompts, basically, just to show what it looks like in code AI, explain the LaTeX as if I'm not familiar.

How would a high schooler be interested in this?

What's some summary code?

Where is this equation important?

And can you explain the variables?

It's not perfect, but it gets pretty far.

Very cool.

This is the explanations page.

There's a philosophy page.

Just one column, but it's just bring up 10 philosophy questions.

And a lot of these are like awesome discussion starting points.

You know, what does divergence mean?

All these things.

And then also languages.

So here's just a few languages.

But we can add...

people's preferred languages just totally feel free to make a suggestion and we can add more AI columns um so we have to keep on exploring this because the latech representation with plain text is really amenable to this kind of language model work so just mention that and then also um someone in cohort 4 is interested in math learning group I think they're um

potentially interested in like a morning time UTC but if somebody else is interested then we can kind of get this going so it could be in the discord but if anyone is interested to pick up with math learning group and basically just it can be an unrecorded session in the discord another hour um to go over the equations um


SPEAKER_00:
Sorry about that.


SPEAKER_01:
So if anyone is interested, maybe just write a comment here and just say, here's some times I'd want to do this.

Just basically like a math study time.

And then let's just see if there's any specific options for what times people want to do such activities.

Okay.

on either the AI or the math learning group.

Does anyone have any just general thoughts or questions?

Otherwise, we'll move to chapter one.


SPEAKER_00:
All right, so let's head over to chapter one.


SPEAKER_01:
um just right off the bat before we get to the um questions it would be awesome if anyone could just share any of their reflections on chapter one just

Anything about their experience reading it or what what they felt it was like or what stuck with them.

or anything that kind of raised after they.

read Chapter one.


SPEAKER_04:
um yeah yeah um so i've had some familiarity with active inference for a while so a lot of what i read already tracks for me um but that said i'm curious about variational uh free energy is like a particular it seems that

So active inference seems to be based on a particular form of Bayesian inference that it relies upon like this variational formulation.

I'm more curious about that.

I assume the textbook will get much more into what's specific to variational free energy as opposed to some other formulation of it.

But yeah, that's something that I'm kind of still chewing on.


SPEAKER_03:
right now thank you anyone else yeah I read uh chapter one a while ago and I think I just dove deeper into it knowing that you know we're looking for questions and stuff but I really appreciated the um the video that you and Ali did so I watched that for the first time

um today and I really appreciated the heads up to actually read ahead to chapter 10 which I'll do yeah that looks good um for me in this this more in-depth reading um action really stuck out to me um so I went to the ontology to look at the definition of action uh that's like central to my area I'm in motor neuroscience

uh and I can relate to the idea that action has to have a goal purpose but I noted that in the ontology that gold purpose is not in the definitions it's more of a general sort of behavioral definition um and then I started to think about you know in our area we also use uh in action so like action imagery

and observational learning which you're not really acting you're you're watching somebody else and and so I posted that question about um does action have to change the world and what do we mean by that do we mean like I'm going to change the physical world that we all share or am I actually sharing my internal uh changing my internal model of the world through action


SPEAKER_01:
yeah so in summary I really got hung up on this this action um terminology cool but those are some great things to explore anyone else with uh just any thought about chapter one am


SPEAKER_08:
yeah i i'm i was familiar with the bayesian brain hypothesis about like the you know our mind is kind of a predictive mechanism and yeah but but like this framework and you know the more i thought about it the more i started seeing like these patterns around me like thinking about

you know the different uh things that I observe in in that sense of active inference like uh the action and the perception and and like specifically I saw it like in children's behavior uh for example like uh you know the ability to to change their mind and and the relief in

in contrast with like stubbornness sometimes you know when they're very stubborn and kind of like uh you know they will do whatever they can to change their reality although you know they can't necessarily do so but so it was it was very interesting just uh thinking about like uh various behavioral um patterns that i see around me and translate them into this framework

Cool.

Thank you.


SPEAKER_02:
I have a question about saliency, because I'm quite familiar with the definition of saliency in visual science, in which something is silent if the visual features involved are different from what you have in a neighborhood.

But I think that saliency has a much more general definition in active inference.

so quite interesting to understand you know uh how it is quantified uh and what's the yeah it's proper definition you know it's generalization uh how we generalize you know the very simple definition in uh in vision science cool


SPEAKER_07:
uh for me uh i'm a psychiatrist so um talking about helen freud who invented the psychoanalytic theory was influenced by helen holtz and as you can see in the chapter one and also at chapter two helen holtz said that perception is an unconscious inference process and which is quite interesting because um

So the psychoanalytic theories are based on the assumption that individuals make interrelationship based on their childhood memories and experiences.

Based on the fact, I got quite curious about whether we can explain psychoanalytic theories based on active inference or other computational models that are based on these assumptions or theories that are inspired by Helmholtz or other scientists who are also having similar points.


SPEAKER_01:
cool there's definitely some other people in the in the textbook group and around so i hope that they can continue on this topic anyone else want like a general um topic or we can return to some of these mentioned points as well as some of the other asked questions um just uh i don't want to


SPEAKER_04:
track too much, but just in response to Junghoon, I, and maybe you're already familiar with this, but the way I ended up at Active Inference was through the work of Mark Soames and neuropsychoanalysis.

My dad, so I would strongly recommend checking him out.

And he wrote a piece where he completely wrote rewrites

Freud's early scientific paper using the terminology of active inference, I think it's great.

And I'd be happy to explore the relationship between psychoanalysis and active inference more potentially within the confines of this group in the textbook.


SPEAKER_07:
Oh, yeah.

I heard about him.

I never actually read his papers, so I'll look it up.

Thanks.

Thanks for bringing up.


SPEAKER_00:
Sure.

I think you're muted, Daniel.


SPEAKER_01:
Ali, you want to unmute and go for it, or?


SPEAKER_09:
Yeah, I just wanted to mention your work in relation to

I mean psychoanalytic understanding of active inference.

It's not completely in line with Mark Stone's line of research, but it provides an alternative path through some of the psychoanalytic ideas of active inference based on his own spatio-temporal philosophy of neuroscience.


SPEAKER_01:
Okay, cool.

right well let's just revisit some of these topics and then turn to the questions but we're totally just chilling and and whichever um ways that people want to go or anyone who wants to raise your hand like you know what whatever comes to mind let's just do it while we're here um some of these

as with the many coats of paint idea we're just gonna kind of give like a first or a few thoughts on and we're gonna be revisiting in the coming chapters because like this is the topic chapter one is just kind of like opening the door so let's we're gonna certainly address all of this once

all these topics are going to come back like again and again because the ontology gets revisited so much so um active inference being based upon the variational free energy as opposed to some other formulation we're going to talk about this a lot more in chapter 2 and in equation 2.5 we're going to meet the variational free energy

And so leading up to equation 2.5 and in the discussion around 2.5 and in chapter two and elsewhere, we're going to talk about like, what do we mean by variational free energy and why is active inference using it?

Essentially, it's a really tractable and optimizable heuristic.

that lets us carry out Bayesian inference efficiently.

Because there's situations where if you had infinite computing resource, you could do exact Bayes, you could just plug and chug and just do the matrix multiplication and get the exact correct answer.

However, with large data sets, that's not really tractable.

And so in Bayesian statistics, and this is even outside and before active inference, people use variational methods because they're super effective computationally.

So, for example, a variational autoencoder.

A variational autoencoder is a widely used machine learning method or a Bayesian statistical method

And a variational autoencoder finds the optimal fit for data, not underfitting or overfitting, through finding the variational free energy.

So in active inference, a lot of times there's a lot of interpretation and a lot of extension of what free energy is in all of this.

But it's also possible to kind of pull back to this pretty non-contentious Bayesian statistical interpretation

and just consider variational methods as being part of Bayesian statistics and used to tractably optimize challenging inference problems.

So we're going to talk more about that in chapter two.

Anyone have a thought or a question on this?

Ali, please.


SPEAKER_09:
I wanted to...

point to the distinction between variation of free energy and expected free energy, because as it says here, active inference is based upon the variation formulation.

It's true, but the perceptual part of active inference theory is based on variation of free energy.

But when it comes to action policy selection and decision-making, the parameter to be optimized is actually expected free energy,

which is expressed in equation 2.6.

So basically those two equations between variation of free energy expressed in equation 2.5 and expected free energy expressed in equation 2.6 can be seen as parallel to each other, but they're used to formulate different aspects of active inference.

One is for perception and the other one is for action.


SPEAKER_01:
Awesome.

Thank you, Ali.

Two ways to minimize free energy.

Update your mind through perception and learning.

Action through change in the world.

The only thing you can't do is put your thumb on the scale and directly change your sensory outcomes.

So you prevent the thumb going on the scale because you don't have a line going from the internal states out to the sense states.

so that the set states are only coming in that's the inbound dependency and then that leaves two avenues for reducing um free energy perception and action and we're going to talk a lot more about this in chapter two when equation 2.5 and 2.6 come into play okay

continuing on this theme of action so action was brought up and obviously like this is one of the really exciting pieces this is what is going to be referenced throughout the book a unified approach on perception and action or all these different ways which we see active inference presented like going beyond passive or perceptual inference

So does action have to change the world?

Is this changing the physical environment or can we change the generative model through action?

Thank you, Holly.


SPEAKER_05:
yeah so maybe i'll just yeah please so i think you know i think you know the when ali brought up expected free energy you know you're you're making changes to your policy your brain uh your model and um and so then what's happening is that and what i find interesting uh is the leverage points and this concept that making a very slight change in your understanding of the world has a much larger effect than

an actual, you know, physical action.

You can see it there in that image.

So I thought, and I don't know if, I don't know if a variation of the energy and the expected free energy really take that into account that, you know, that these, you know, the leverage points or not.

I thought maybe some people have some ideas.


SPEAKER_01:
Well, it's like, like in nested modeling,

like for a generative model that only sees up to this point the optimal leverage point that's detected is going to be so and so but that a deeper generative model might be able to see uh more leverage points Ali uh well rather than uh describing action as something that changes the environment


SPEAKER_09:
If we want to talk a bit more precisely, what action means in active inference is actually

one in which active states intervene causally in external dynamics.

And formally, it means a kind of Jacobian coupling between the external states that depend upon the active states or active intervention.

So what we mean by changing the environment

we mean more precisely the kind of active state that would lead to a kind of causal intervention in the environment and not something that just, I don't know,

changes something per se and this kind of distinction comes into play when we want to talk about covert and overt actions as discussed in phenomenology which will come to later in the book but yeah I think that would be helpful to


SPEAKER_01:
awesome yeah so many things to look ahead to overt action is physically manifested embodied action covert action or internal action is attention or mental action and so that is like something that doesn't necessarily um

change outside of the generative model but it's it's modeled with attention and action inside the model and there's actually um even a very cool um recent work on uh transparent and explainable artificial intelligence and again just looking ahead

Here, they use attention and meta-awareness as internal or covert attention generative models in an artificial intelligence way.

But this model was actually developed in a meditation and phenomenology setting where the action selection was internal attentional control, not external control.

um yeah i'll put the um this is the explainable ai paper in the chat and then also just again looking ahead one place to to what is this concept of action this is figure 4.3 which is kind of like a rosetta stone figure pi are going to be the actions that are selected from

And where those actions intervene is how the hidden states of the world change through time.

So if the hidden states S changing through time is like the true temperature in the room,

and at each time point t you have a thermometer reading that gets emitted from the true temperature so we're only able to observe the observables which is the thermometer readings and there's the true underlying changes in temperature or you could think of this as the true underlying activity of the neural system and the observation is the fmri that's kind of where this comes from in terms of like friston's lineage with spm and then

if there's two actions you can take, turn on the heater or not, it causally intervenes in how states change through time.

Maybe if you don't turn on the heater, it just passes the hidden state on forward without changing it.

And if you do turn on the heater, it increases it by one per time step.

So that's one sense of action.

then also just by by mousing over um we see it from the ontology and also we we can update the ontology it's it's never like these things are locked definitions just to be clear but we see a really common pattern which is that there's like a broad and a narrow sense a lot of these terms in the acting of ontology action belief attention salience

things that people have brought up today there's like a broad sense qualitative definition which largely or exactly is how we would use this day to day just action is what occurs super general term and then there's like a narrow or a more technical definition which sometimes conveys how this is operationalized in generative modeling

So more specifically, actions are the active states that the agent generative model is going to select.

And so that's like more of the quantitative and formal definition of action.

And then we'll explore a lot about how is action selected.

Because that is the entire expected free energy imperative, is the selection of action and how goal orientation, preference orientation, expectation orientation is embedded within action, despite there not being a reward function, as we might see in reward learning, reinforcement learning.

we're going to have a different approach for adaptive and flexible behavior that's not based upon reward learning or a reward function.

Okay.

Any other thoughts or just any other ideas on this in action?

Martin?


SPEAKER_03:
So does action have to have movement?

It's one thing I'm looking at here.

I mean, the overt versus the covert.

So overall, I have to have some movement that I could observe.

But you said earlier that you could have the covert, like, for example, attention being a covert action.


SPEAKER_01:
Yeah, well, depending on the system of interest, action could be an API call.

So certainly it doesn't have to be a person's body that we're modeling.

It could be a computational or a purely informational system.

And then covert or internal attention.

I mean, you could argue it has some physical informational substrate.

So it's not like it's happening in some...

know alternative plane of existence but for the purposes of the modeling it might not be realized through gross morphological movements yeah thanks yeah and and it's going to be super cool like how we're going to when we look at um figure 4.3 as kind of this cognitive kernel or this kind of firmware element

And then, again, when we take it to, when we look at how these models compose, even just starting to see familiarity here in figure two, we see basically this figure 4.3.

Downward facing E, that's the inference part.

Hidden state and observations and policy intervening.

That's like this.

Downward facing E.

policy intervening and then that just gets nested and so that speaks to the composability of these kinds of Bayesian graphs and then in when you look at a specific model it becomes clear which actions are associated with overt movement and which actions are associated with covert attention um

Okay, any other thoughts or questions?


SPEAKER_04:
Yeah, I guess just to briefly kind of add to the table under action, like on page 10, ever so briefly, the authors make the distinction between exploration and exploitation.

And that seems like a really interesting or useful

division to me.

So both of them seem to be both of them are related to minimizing free energy or expected free energy in this context.

And yeah, exploration is to resolve uncertainty.

So I view that as like taking in new information versus exploitation, which has to do more with, yeah, acting on the world to bring your

your observations into line with whatever your goal is or your plan is, your set point, to use that word from cybernetics.


SPEAKER_01:
Thank you.

And here's a really clear claim.

In contrast with other frameworks, policy selection, so behavioral selection, inactive inference automatically balances exploration and exploitation.

Now,

This is a very strong version of the claim, as we'll explore.

It's not that simply making an active inference model does automatically balance it.

It's not like just writing it out is going to make the startup work and the ship work and the plane fly and all of this.

It can be read too strongly.

It's not that it's automatically going to be effective.

However, it sets the stage or it provides an accounting system for the adaptive finessing between exploration and exploitation.

And we'll explore that more in chapter two.

When we look at what is it that expected free energy and variational free energy are, and then how is it that

that policies are selected behaviors are selected that are able to adaptively finesse between more exploratory behavior when there's information to learn and more exploitative behavior when there's kind of pragmatic value on the table and maybe it's more important to just get the pragmatic value rather than to um continue learning but that's where we see um variation in

behavior, ultimately, variation in cognition and behavior, when there's too much attention paid to epistemic or to pragmatic value.

And that's a lot of where like these like precision psychiatry, cognitive modeling things come into play.

And it even Yeah.

Any other thoughts or questions on this?

it kind of connects to even the next point that was on salience.

So salience, again, just as it is in the ontology, not that it's the only or the final definition, but it's just the extent to which a cue is going to be attended to.

A cue that is not salient has no attention to it.

and something that's not being attended to, the consequences for the queue are diminished.

In the limit case, if you didn't pay attention to something, it just, you know, didn't cross your radar, it doesn't update the generative model.

that's like attention to zero in the other extreme case when the attention is super high it's like you're updating your prior to just whatever it is the new data point is you perfectly attend to it and it is like the same as having like no memory so no attention is like totally pushing your prior forward full memory full attention no memory

then finding out what is an adaptive amount of remembering and learning and forgetting um salient observations are those that resolve uncertainty that's the information that we're seeking out is the information that reduces our uncertainty about something and then how much it reduces it

We're going to talk about some formalisms, especially in chapter two for comparing like, is this sequence of observations or that sequence of observations going to be more salient?

Which one is going to have higher epistemic value?

Which one is going to reduce my uncertainty more?

Which one will I learn more by viewing?

Which one will update my priors more?

Which one should I pay attention to more?

Those are all kind of like related questions for like which information is going to be the good information.

And these are the two sides of the joint imperative for expected free energy.

Information gain and pragmatic value.

Epistemic value, how good is the information?

Pragmatic value, what is the utility?

Am I gonna be at homeostasis?

Exploration, exploitation.

And so expected free energy is like this unified imperative that contains both of those elements such that different policies can be ranked or evaluated or upweighted based upon how well they contribute to both information gain and pragmatic value.

Comes up in chapter two, but just wanted to kind of preview it.

Any other thoughts or questions or let's go to the questions table and just like the questions that people are most interested in.

Okay, first I'm gonna go to the chapter four or cohort four questions.

So just to make sure that even if they have few upvotes that all of your questions can be addressed.

So we'll first look at this question.

and then we'll turn to chapter one questions overall so as always like you know whenever you're watching or participating even if it's a chapter that was long discussed ago or you know up ahead just add questions it's it's really awesome and upvote them so that and develop the discourse so we can have good short answers for these okay

Page nine, action minimizes free energy and surprise by changing the world.

Okay, so I talked a little bit about that previously.

Does this imply that the agent implements action to alter their world or the action is implemented to change the agent's model of the world or both?

Can an agent implement action not solely to minimize their free energy, but free energy in another agent, for example, using action demonstration for observational learning?


SPEAKER_00:
Does anyone have any thoughts on this?


SPEAKER_01:
okay just starting with the observational learning two two quick angles so this again everyone can add more in live stream 53 um sequence there were some paleoanthropologists and we discussed observation learning a lot

they highlighted how a lot of times people have focused on the kind of moment of innovation for example in um creating stone tools in in human cultures and history but it's not just about the one innovator making the stone tool it's actually in the moment of observational learning when the onlooker

is able to either understand or not understand and ultimately adopt or not adopt or to copy or not to copy that behavior.

And so they approach this from an active inference perspective.

And this also brings up ideas like thinking through other minds, T-T-O-M, which is kind of like the active version of theory of mind.

But thinking through other minds or thinking with other minds is more explicitly like one's generative model in a social environment also includes a generative model of what the other is thinking and doing.

And so if one is in an encultured setting where action demonstration can be used for observational learning, then these are the kinds of dynamics that are possible to model.

So that's one angle is, yes, it's been considered in a social encultured setting, how like gesture and demonstration and observation might play a role in transfer learning.

A more technical and general response is,

in multi-agent systems you have agent reducing their own free energy making their own perception action cycle but also you have like the joint distribution now you have the nest mate going about their own way but then in the aligned or the healthiest or adaptive setting the colony is also reducing its expected free energy so one agent or neuron or an estimate or a person

might undertake an action that increases their own surprise transiently as part of a distributed cognitive system that has a joint free energy that is reduced through that action so it's not necessarily like every single subunit is always and only reducing its free energy per se but the adaptive hole

is going to reduce its free energy and that might be um entailing some subunit increasing its surprise uh yes young then anyone else uh yeah i mean i think i'm i keep thinking in a way as a psychiatrist so uh


SPEAKER_07:
It feels like psychoanalytic therapy itself is something a therapist is doing, trying to minimize the free energy of the client.

because like they provide explanations and interpretations about why they are doing such behavior or why they are making such relationships with others so I guess maybe in a broad aspect I would say uh giving providing explanations about why some individuals are behaving in such way would be another action that actually reduces the free energy of another agent


SPEAKER_01:
that's very cool yeah like by providing a narrative summary it's a sense-making tool that helps explain and make sense of their perceptions and actions uh Martin


SPEAKER_03:
yeah it's really interesting thanks for that uh it just got me thinking um you know sometimes we we I guess we try to free um minimize energy and others directly like I'm a university teacher so by teaching I'm trying to reduce you know their free energy um but sometimes you find it's best to let them

find their own way so I'm just thinking about like in psychoanalytics which is a very distant field from my area but uh letting others interpret meaning from their situation rather than framing it for them if that makes sense and just thinking you know maybe this is a side topic but would active inference speak to what's a better approach

or want to do it for the other or to let the other explore in a way let them work through that space of energy free energy and then find their own way to minimize that yeah great topics oh yeah I think that's a really good uh point because like at in psychoanalysis we sometimes like um


SPEAKER_07:
have to choose whether to give a very direct interpretation, or sometimes we let the patient to understand what's going on by themselves.

But it's always a controversial question about what to do.

Well, we do have some theories and some sense about what to do on certain situations, but


SPEAKER_03:
it's quite a pity that we don't really have like a very uh scientific grounds for what to do in psychoanalysis so I think that's a really good point the other thing that's just come to mind is uh this this came up with this chapter in fact is so if we're working to minimize our free energy right and we sort of acting in a world to minimize surprise how do we avoid confirmatory bias

you know so I'm thinking now that the world is flat so I I am going to reinforce that model because if I don't then that's going to create some uh free energy right it's going to create surprise so I'm going to act in the world I'm going to hang out with people who who don't challenge that and I'm thinking back into psycho um a psychiatry practice or counseling maybe uh


SPEAKER_01:
people may have ingrained sort of models in the perceiving the world just based on that model um resulting confirm it's very biased yeah this is a is a very important topic especially as the as they put it existential imperative is self-evidencing

to repeatedly remeasure my body at homeostatic temperature, to be unsurprised about remeasuring myself at homeostatic temperature is to maintain homeostasis.

So in reward learning, you would say, well, homeostatic temperatures are the most rewarding, that's the top of the reward function, and then we're gonna basically hill climb to get to the most rewarding body temperature.

That's the reward learning paradigm.

In Act-Inf, your preferences, your expectations, the C vector, is what you expect.

I expect to find myself at body temperature.

That's the bottom of the bowl.

I'd be the least surprised at 37C, and I'd get more surprised as I went out.

and now we're going to go to the bottom of the bowl and we're going to pursue the most likely course of action bound our surprise with expected and variational free energy and so with the imperative as self-evidencing and surprise bounding we're going to pursue likely paths of action rather than with the imperative being reward learning the imperative is to maximize reward

However, does self-evidencing mean that we seek out homophily?

Does it mean that we just shut our eyes and go into the dark room?

These are really important topics.

And for example, in the dark room problem,

It has been discussed for many years.

People say, well, if the imperative of the generative model is to reduce surprise, then why don't people just go into sensory deprivation where there's highly predictable sensory inputs?

And this has been discussed and addressed for a long time.

But the short answer is while you're in the room, reducing your uncertainty about your visual field

you're increasing your uncertainty about a variety of other aspects that are required for operation of the organism and so you kind of net on balance uncertainty is rising while you're in the room which is why we are always adaptively moving around and seeking information and all of this

However, you can always set up a constrained or a toy generative model that exhibits any given limitation or pathology.

That's not too surprising itself.

But to actually use this as an accounting system for the kinds of adaptive and interesting behavior that organisms do exhibit, that's the interesting piece, not whether you can make a...

visual input only generative model that may select to be in a dark room but if you have an active visual entity that can turn on a light it may turn on the light or if it has a hunger uh cue it may need to seek food eventually so it's a little bit of a non-sequitur a kind of over interpretation of a thought experiment that's just really in a little bit of a um partial

way trying to come at this.

So you can imagine that there are situations where self-evidencing goes right and where it goes wrong.

And that's exactly the space that we're exploring.


SPEAKER_06:
A lot of times when I think about homeostasis and temperature, I think about, you know, like Huberman and many kind of biohackers want you to

uh you know experience cold contrast therapy and especially if you are sensitive to cold you know it's very important that you get in there and do your cold punch your cold showers and so that's that's i think that's an interesting example where you're changing that you know that set point basically by by doing other activities that seem opposite to what you know what would what would make you comfortable


SPEAKER_01:
Cool, thank you.

Okay.

Any other thoughts or questions?

Or let's look at like one or a few of these asked questions.


SPEAKER_03:
Just a general question, Daniel.

So when we post questions, because I posted that one, I had to go to the main table to post a question and then it feeds into the cohort four.

Is that how it works?


SPEAKER_01:
couldn't actually post yeah directly into there yeah um all the uh it's it's all there's only one underlying questions object so each of these like different views so if you just go here and just like hit enter you'll add a new row and you can ask a question in cohort four and then that'll be like in chapter one and in cohort four

um and so that it'll come up when we go to chapter one questions as well or you could um go the other way yeah or you could ask and but then it might not necessarily be tagged to cohort four but it doesn't really matter what cohort it you know as long as it's in the chapter that's a good place got it thanks cool well

um one distinction and and you know i look forward to seeing some of you um next week in the other time also discussing chapter one um or next week at this time where we'll be in chapter six with cohort four you're all welcome to join but a really key distinction that's that's um raised in figure 1.2

is the high road and the low road and this is basically going to structure chapters two and three the low road is going to describe how the low road is basically Bayesian statistics that's how we're going to do cognitive modeling

But you could use Bayesian statistics to model anything.

You could do it on health records.

You could do it on weather data.

So Bayesian modeling doesn't have to be about adaptive, cybernetic, autopoetic agents.

Bayesian statistics, the how can be about anything.

Chapter two, low road.

chapter three is going to be the high road and the high road is like the kind of what or why and it's self-organized self-evidencing systems and so this describes more like the specifications for adaptive agents this is like what they need to be doing to be observed repeatedly

by an observer and or by themselves in this kind of like sophisticated reflexive sense but it doesn't necessarily say how that happens it turns out where the why and the how meet is active inference we're going to be using Bayesian statistics that's how to model adaptive cybernetic entities that's why and so that's kind of going to be explored in the chapters two and three low road high road

So that's kind of the big structuring motif, ultimately, of this textbook.

Olivier?


SPEAKER_02:
Yeah.

In the figures, there is an order, you know, in all the items on the lower road and the high road.

Is the order important to understand anything or just, you know, one group and another group?


SPEAKER_01:
It's a schematic ordering.

I believe that there is a way to read them in order, but it's not an exhaustive or a unique ordering.

So, for example...

Sorry, is someone closing the... Okay.

So Bayes' theorem is just describing basically tautological statements about conditional and joint probabilities.

This gets used in a generative model, which is basically a model that can be used in a recognition capacity or in a generative capacity.

That's the tail of two densities.

In simple settings or passive settings, we're interested in perception as inference.

But once we go into the anticipatory or the predictive setting, we're interested not just in dealing with incoming streaming data, but basically making ongoing predictions, now casting.

The next kind of into the unknown step that now casting can take is action as inference, because it's not enough to just deal with incoming streams of data.

Sometimes you want to take the action to open the book to find out.

that idea of perception and planning as inference is unified in the Bayesian brain and it turns out that variational Bayesian methods are going to give us some tractable optimizable approaches for approximate Bayesian computation where exact base probably doesn't apply or is really challenging just like we kind of mentioned earlier so that gets us to doing variational Bayesian optimization

on perception and planning as inference in the Bayesian brain that's active inference so that's kind of low road ordering the high road ordering is starting with the free energy principle which is a non-falsifiable principle just like the principle of least action in classical mechanics this is like a principle for informational systems and systems

under this principle are seen as being in the game of self-organization via surprise minimization you'll continue to find yourself organized if you're continually minimizing your surprise about who and what you are that is um supported or described by a partitioning conditional independent structure called a markov blanket which we're going to explore

And the Markov blanket can be seen as carrying out self-evidencing through this kind of anticipatory real-time predictive processing, which is related to predictive coding.

And in the extended, embedded, inactive setting, that can be understood as basically self-authoring, self-meaningmaking, and ultimately even extended niche construction, which gets us to active inference from the high road.

So again, not exhaustive or unique ordering, but certainly something that they have considered and laid out a certain way.

Thank you everyone for this awesome chapter one discussion.

I hope to see you either next week at the other time or whenever.

And just leave a comment on this page here if you want to start up the math group, so thank you all.

Thank you.