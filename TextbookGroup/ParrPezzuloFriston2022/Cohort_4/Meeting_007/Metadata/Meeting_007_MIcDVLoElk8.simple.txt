SPEAKER_03:
Hello, it's July 18th and we're in our first discussion of chapter three in cohort four.

So before we go to any questions or anything, does anyone want to just bring up any overall thoughts they had on chapter three, just about the chapter, where it is in the book or what they remember or got from that chapter?


SPEAKER_01:
yeah i would add that i actually just generally think the chapter was written very well and it was very clear um i think the high road can be philosophically and mathematically very abstract so i personally appreciated the kind of clarity that the authors took to discussing things like markov blankets and um existential imperatives i guess it's it's a the high road

perhaps more than low road provokes further questions, further ontological and philosophical metaphysical questions.

How deep does the hierarchy of Markov blankets run or what's the fundamental base layer of this whole system?

But on the whole, at least in so far as the free energy principle is a very simple explanation of something very fundamental.

Yeah, I thought it did a really good job outlining that particular point.


SPEAKER_03:
Nice.

Thank you.

Anyone else?

Any thoughts?

Low road, high road, anything?

Yeah.


SPEAKER_10:
Yeah, I really enjoyed it.

this chapter probably because there's less equations to uh get hung up on but especially section 3.7 just the idea of using active inference to reconcile um different theoretical perspectives so in my reaction we have debates about whether uh movement commands are represented centrally versus self-organizing or are inactive this is hotly debated for decades now

And that's something that's really attracted me to active inference is to have more unifying view rather than keep going with debating.

So I really appreciated section 3.7 for me personally.


SPEAKER_03:
Any other thoughts on 3 or about how somebody is seeing the low road and the high road?


SPEAKER_09:
But then I want to see about the figures.

When I look at the figures, for example, figure 3.1, where the figure explains the blanket states.


SPEAKER_06:
But in addition to those blanket states, there are many other notations and

and formulas.


SPEAKER_09:
So it seems quite intimidating, those formulas.

Like, for example, the first equation on the left, you have x, you know, dot x equal to f of x, et cetera.

So all this notation is not explained.

that it seems to me that it creates blocks for understanding of the concepts.

So basically, I found it is kind of a little bit incomplete.

I know it's difficult, because in order to understand these concepts, you need more


SPEAKER_06:
background explanations.


SPEAKER_09:
So when I read those figures, I hope to understand all the information that contains in the figures.

If there are things that are not understandable, that creates kind of a mental block in my mind.


SPEAKER_03:
sure totally makes sense so and it's good to want to understand all the notation so this is a representation that is going to come up again and again um it's the markov blanket and there's kind of two uh types of notation happening here there's like the variables that are being locally assigned

and then there's some more conventional notation so like some of the conventional notation is f is a function of something and then omega is a noise term on something that's conventional and also the dot being a rate of change so it's kind of like having like a prime or a first derivative

And then there's the locally assigned variables.

So external X, internal mu, active U, sensory Y. And then now there is a typo in this figure.

A small one.

Just it's in the errata.

Okay.

Okay.

But the visuals are correct.

Each of these functions, the rates of change of each of these four kinds of states, we're describing the rate of change.

So it's kind of like a flow map for all four of these nodes on a graph for the internal, external states in the blanket.


SPEAKER_09:
Right.


SPEAKER_03:
Rate of change.

Yeah.

And each of those rates of change is broken up into two components, kind of like a signal and a noise.

That's and noise could be zero or it could be all noise and the signal component on the rate of change of each of the, um, nodes in this particular partition, the signal component is a function of all the incoming arrows.

and itself at that time.


SPEAKER_09:
Right.

So in chapter two, we understand the low road, we understand the active inference as a kind of an optimization problem where you have a choice of action and perception.

So how does action and perception play a role in this figure, in this Markov blanket, in the figure you just showed?


SPEAKER_03:
Yeah, good question.

Well, we associate this incoming sensory state according to perception.

And then the outgoing statistical dependencies according to action.

And then what happens here, which could be nothing if it's a very simple system, or it could be sophisticated or unknown, same as external.

We just call this the cognitive states.

So this is the perception, cognition, and action of the agent.

Blanket plus internal states.

That's the particular thing.

insulated off from the external states.

So that's why this is like the minimal Bayes graph for the cybernetic agent is having the input cognition and output and the work of Isomura and Friston and others like maps this onto neural networks that have like an input processing and output layer.


SPEAKER_09:
right but i don't think what are the choices because in the chapter two it talks about the the perception and the action are the choices made by the agent right so those are the choices not the states it's a decision kind of decision can make you can choose to to to to percept this way or the other way you can choose to take that action or another action


SPEAKER_03:
so here you're you're are you seeing the action state is is the action is the choice two um ways to think about this first is that's why we talk about beliefs about action action prior uh policy prior policy posterior so because we're talking about our beliefs about action and the second thing is

This is coming from a high road.

So this is kind of like a, forget what you knew about chapter one and two.

Start with just this particular partition on a Bayes graph.

And then the chapter continues with connecting it more to perception and action.

But start with like, this is the topology of systems that can sense and act.

Or you could propose a different topology of that system.

Um, younger than anyone else.


SPEAKER_00:
Yeah, I just wondered.

So the sensory states are the perception, and the active states are the action intuitively, and well, those 2 are directly connected to each other.

which means that they can bypass the cognition.

And it's really hard for me to imagine a state of active states just bypassing the cognition and just going directly to the sensory state and also vice versa.

So can anyone come up with a good example of it?


SPEAKER_03:
Awesome question.

Does anyone want to give a thought on that about this?

What is this double headed arrow in the center?


SPEAKER_09:
So my understanding of this error means that the active state is affected by the sensory data you connect.

So basically, you can see here, fu is a function of y. y is the sensory data that the agent gathered from the external world, gathered from there.

The expectation.

On the other hand, also the U is that your action also will affect your sensor data Y. For example, in the separate two, the apple and frog example, if you choose your action to look at apple tree, this U, if you move your eye towards apple tree,

that will generate sensory data about Apple, you know, what do you observe will be Apple.

So that will be the action will affect your sensory data Y. And your sensory data Y will affect your action.

Yeah, I'm just thinking how that example.


SPEAKER_03:
These are all true.

Another thing to keep in mind is like the effect of a given edge in a model or system of interest.

It might not be relevant, but it's kind of like in principle.

So if you have a computer system where one computer is getting input and sending it to a second one, sending it to a third one and then emitting it.

there is no effect of this arrow.

Or if you have some other system where this in practice is zero.

So just because there's an edge doesn't mean that in that simulation or that model, it's like it matters in a certain way.

And the reason why it's there in principle is because the definition of the Markov blanket for a given node is all the nodes that kind of insulate it and the co-parents.

And so just in principle, they could be connected under the Markov blanket definition, like the Markov blanket nodes could all be connected to each other and be connected into the node of interest.

And also these assignments of internal, external, active sensory, these are all relative to a given internal node of interest.

If you call this one internal,

then this would be sensory and that would be active.

Or if you picked one over here, it would be different.

So these are not like essential features of nodes.

These are just with respect to a chosen internal state on a created model.

Darius?


SPEAKER_01:
Yeah, I mean, I'm just staying on the Markov blanket for a bit.

I've seen quite a lot of conflicting literature and opinions on to what degree it constitutes a metaphysical reality.

So I think one can't help but think of a kind of cell when you think of a Markov blanket and the blanket states that are the boundary between the cell and the external environment.

To what degree are Markov blankets from the biggest Markov blanket

a universe within the universe all the way down to the smallest of markov blankets and all the ones embedded in between to what degree do current um free energy principle theorists believe that there's a genuine metaphysical reality or is it just a way of visualizing and understanding statistical regularities yeah big question what does anyone think


SPEAKER_07:
Ajit or anyone else?


SPEAKER_02:
Um, I guess like, I would think it would.

So would that be connected to like, our subjective experience would be this statistical model.

So that would be the Markov blanket.

Uh,

Is that what you mean?


SPEAKER_01:
I don't mean that it's observer relative.

You have the universe as is, and observations indicate to us that there are separate patterns of existence, things that are distinct from one another.

All those boundaries which are defined by the Markov blanket, metaphysical as in they exist,

I mean, I think the only way of kind of conceptualizing that is as a material distinction, or do they just exist?

Do they solely serve to be a statistical representation of the actual distinctions that we observe, but perhaps there is no physical substrate underlying those regularities?

That's my question.


SPEAKER_03:
Yeah, it's a huge question.

There's, there's a ton to say on it.

Definitely a lot of perspective.

So like there there's a way broader range.

One topic that comes up in that setting is the different flavors of instrumentalism and realism and scientific realism pragmatism.

So instrumentalism is like the least metaphysically committed.

And just says, look, linear regressions help us understand the relationship between this and that.

That gives a sort of cognitive realism to the linear regression.

It might influence someone's life, so it does matter.

So that doesn't mean that we don't take it seriously, but no one is going to mistake the map for the territory.

Then, for various reasons, there's also more of a realist, not necessarily like a platonic realist, but like a scientific realism.

It's like, yeah, the objects that are under study are real.

Now the finger isn't the moon.

So pointing at the phenomena, it's still like not map territory.

The model and the equations is not the system.

That's obvious.

So just saying, but the model doesn't have this feature of the system is like, yes, but we're talking about the reality of this system.

Six people and the elephant, they can still be talking about the reality of the elephant.

So that's kind of a scientific realism thing.

um and uh mel andrews's work and the math is not the territory live stream 14 and a lot of other discussions on that and then um there's a lot more to say but that's a great question area brynn


SPEAKER_08:
And I was when I read this chapter I I met the example that I thought I intuitively kind of found helpful was a playing the piano.

And I wondered if you could verify the veracity of that example if it doesn't indeed explain many of the dynamics between my internal states, my active states, the hidden states, and in turn the sensory states that I receive to complete an action kind of feedback loop.

And I think it also might explain the.

The edge is between and the active states in the example of playing the piano and.

The sensory state that might ensue should you take a particular action or, in this instance of that hope to explain not take a particular action, so I thought of the piano kind of sitting at the piano with the intention of playing and I.

The I believe I want to play piano i'm not 100% certain of what might be fall under you know what can.

would.

fall under the internal states, but other than a belief that I can play i'm sure there are many, many other factors there that would be necessary for one to play initiate the action, but then I touch a key.

A note, and that is that has.

that entrains an effect on the perception of the piano, which then in turn, I don't play that note directly.

I elicit sound from the piano, which then in turn gives me the noise, which hopefully sounds good.

And so I continue that effect by playing the next notes.

accordance with the previous one and so i build the tune as i go hopefully and hopefully that's pleasing rather than full of kind of dissonance and off beats and and irregularities and i thought about the relationship between the active states and the and the the blanket states the sensory states if you were to omit a note thereby inhibiting the effect

of the action on the piano, thereby, you won't perceive anything in its, you won't get anything in return, so to speak, from the piano because you have omitted a note.

So yeah, I kind of thought about this around playing the piano.

Yeah.


SPEAKER_03:
Awesome.

That's a really cool example.

And in chapter seven, there's going to be like a musical example.

and music cognition there's a lot more um work on as well but in this example like the wrong note is played quote wrong note different than the expected tune but the expected the expected note is still heard because the prior is so strong and so like um ali and and several others have have a lot of interest in in that um


SPEAKER_08:
music perception it's like very rich with with music perception and generation improvisation it's a really cool area daniel if i can just ask if you can go back to diagram 3.1 i think it was i just wanted to clarify something that's just come to mind now i'm not very good at all the uh the technical uh details yet but how is a the noise from the external state how does that

How does that relate to or how does it correlate to the impact or the effect of the noise at the sensory states?

How is that kind of transduced?

I'm thinking of the piano example again.

How does that dissipate through the system?

Is it equivalent?

So a particular noise at the external state, how is that experienced or understood as


SPEAKER_03:
how is it similar or dissimilar from the the noise perceived at the um or generated in the sensory state yeah very interesting question so think about each of these four nodes as being like a sensor or a thermometer

in and of themselves, like there are probes that are tracking these flows.

So what would it mean to have this be high and this below?

Well, maybe the temperature in the ecosystem is constant, but it has a lot of variability.

there's like no signal really but there's a high variability but we have a very accurate thermometer that we're taking in information from or conversely maybe it's a deterministic temperature outside and our thermometer is highly variable so this is kind of just like the outline

that gets filled in like a hundred percent during the modeling process but this is just extremely general outlining like where the same just saying that each of them are partitioned into a signal and noise component in principle but but that's why it really helps to also to think about specific examples and um

Yeah.

Younghoon, go ahead.


SPEAKER_00:
Oh, yeah.

Because I'm a psychiatrist, what keeps to my mind about this microplastic is that it's really a cool concept if you think of the process of psychoanalysis.

Because the therapist, by using his own internal state and inferring the internal state of the patient,

and then by uh making decisions and influencing these sensory states and these active states active states active states active states to change the internal state or the internal model of the patient so i mean that's quite interesting because like the basic concept of mark blanket is that you can't really have access to external states

which means that you don't have any access to the internal state of others.

But you can change the internal state by having very good inference about it and doing the right active actions or providing good sensory states, like maybe making the patient comfortable.

Or sometimes you use many different techniques with psychotherapy, such as hypnotics or

I don't know, maybe other relaxation techniques.

So, well, the basic market bank is really cool for me.

So, like, it wasn't a question, it was just a comment.


SPEAKER_03:
That's awesome.

Thank you.

That is absolutely the core of the Markov blanket concept.

Definitely a lot of philosophical like smoke and fire is in that area for, I think, a variety of interesting reasons, partially because it touches upon like how things really are in some people's eyes.

Or it's something that seems to explain like everything and nothing.

But at the end of the day, it's just a description of the sensorium.

And the real important missing, the missing piece or the missing edge, not missing piece, that really embodies the constraints here is the no telepathy, no telekinesis clause.

No edge between internal and external states except via insulating nodes.

So by making the fully insulating nodes

shell, then you you don't need to make any claims about what's in the on the other side of the blanket.

Now you could, you might happen to know, or you might have a really good model of what is happening or something like that.

But those models aren't free information takes energy.

And they're always understood as projections of onto hidden states or trackings of hidden states.

So it's really just a recognition of the sensorium and the cybernetic system boundaries with actually a lot of generalizations that make it really exciting and even more flexible than people might initially consider just from looking at this relatively simple system.

Darius?


SPEAKER_01:
Yeah, I was wondering, this makes perfect sense to me in terms of a sentient non-steady state equilibrium system like a human brain.

But if, in terms of this equation, in terms of the Markov blanket generally, but to what degree can we think that entities that don't act, that exist in steady state equilibria, so like Friston's classic example of a drop of oil in water,

I understand that you can't necessarily attribute action to the drop of oil, or at least purposeful action.

When we look at that diagram in 3.1, do we have to think of it as if the drop of oil, it's as if they're behaving in this manner?

Or are we committed to some notion, of course, the external and the internal states,

but they are maximizing its model evidence, it actually is sensing and it is being active.

So where is the kind of dividing line here between sort of sentience and non-sentience?

And to what degree, if there is one, is it just that the drop of oil basically exists?

It just seems to be maximizing its model evidence, but there's no real telos to it.

Yeah, because the action here, the act of inference seems to me to be very highly linked to sentience.


SPEAKER_03:
Yeah, great, great questions.

Well, one angle is an instrumentalist goes into that area without feeling like they're taking on descriptions, like it's a sentient as they extract the signal of.

So it's very like relational or sort of like perspectival view on sentience, whereas somebody taking on more ontological commitments would say that they are exploring or characterizing the true nature of sentience or intelligence.

Here's a really early 2006 or so image from a Friston paper.

This is the winged snowflake.

And it's like systems that persist conditioned on seeing this snowflake.

It's not conditioned upon all possible, you know, a room that's 100 degrees C. Conditioned on seeing this snowflake, there's going to be snowflakes that through wind blowing them around,

So just doing no better than you'd expect from the wind currents or doing better than the wind currents, they preclude phase transition of melting.

Once they cease to exist, then they cease to exist.

So that's like one.

And then because you asked about how to describe these simple systems too.

And then this path integrals paper made the clearest taxonomy of systems from inert systems where like some of these nodes are trivial.

So some of these nodes can be trivial or null in effect.

And that's what gives the ability to model a really simple system.

But then the composability of the Bayesian graph format allows the construction of also more sophisticated cognitive models.

all keeping the Markov blanket condition, because you could have internal states could just be like a pass through, or you could like imagine they functionally didn't exist, or it could just, it could be this, or it could be that.


SPEAKER_04:
Andrew?

I just wanted to add to that, that, I mean, in the chapter itself, later on, I guess, section 3.6, page 56, they attempt to

kind of provide their own answer to the distinction between like a sentient or perhaps non sentient.

Organism and they just say this is one answer so not you know, an exhaustive answer to the question, but like having the capacity for like for an organism to have the capacity to model alternative futures and to have that level of temporal depth.

um that that's one answer that makes sense to me and thinking about like the drop of oil in the water like perhaps it is you know it's reacting to something like sensory input and acting but nonetheless like i can't imagine that the the oil is you know anticipating future

um you know sensory information and and coming up with its own representation of the proper action to take in the future and what it should be moving towards so that's kind of how i viewed you know a way of deriving an answer for the sentience versus non-sentience question yeah cool thought and yeah


SPEAKER_03:
like an inner object or even a simple active object may not provide any evidence, like you don't need to appeal to any counterfactual generation in order to explain even potentially lifelike behavior in certain, you know, basal cognitive behavior may not need explicit entertaining of alternatives.

Wanshan?


SPEAKER_09:
Yes, I have the question about the figures, about the direction of the arrows.


SPEAKER_07:
Can you go back to the figures?

Ming Lei, Ph.D.

: Figure 3.1 right.

Ming Lei, Ph.D.

: So.

Ming Lei, Ph.D.


SPEAKER_09:
: If you're looking here, there are on the upper right, there is a two direction figure between active states and internal states.

Ming Lei, Ph.D.

: What i'm thinking is that the internal state will affect the active states right, so what action you take depends on your internal state.

but how does active state actually change the internal states?

So- Does anyone want to directly?


SPEAKER_03:
Yeah, yeah, totally.


SPEAKER_09:
The internal states will be affected by your sensory states, right?


SPEAKER_03:
This isn't what does happen in a given model.

This is what can happen

in one arrangement of an abstract base graph so don't connect it to the actual structure of causality even in the world this is just saying this is like a template sketch of a cybernetic agent with and what's mainly ruled out are the telepathy and telekinesis

and the other one that you can think of as ruled out instead of asking why this is too edged in principle what's ruled out backwards causation of action we want to be entirely in control of action and backwards causation of sense states we don't want to have our thumb on the scale so there's just many many ways to think about it and in any actual modeling situation this level of abstraction is not engaged with

it becomes a lot clearer when you're talking about specific functions describing different states in a specific system of interest.

Young-Hoon?


SPEAKER_00:
Oh yeah, it's a totally different question, but like considering the reinforcement learning, sometimes when you sample a lot of sequences and then like

There are some models like Thomann-Eichenbaum machine or successor representation, which actually updates the state to state transition based on the experience that you had.

Um, it, it, even though you don't really perceive additional information, you can update the transition metrics based on your memory.

So you replay and playback the memory and it actually updates your, um, internal states.

So, uh, considering that fact, um, where should be, where should we put the memory replay in that figure?

Is it like, do we have to say that the memory replay is some kind of action or is there another alternative solution?

Great question.


SPEAKER_03:
I'll just try to set it up indirectly because I think it's a real direction.

There's going to be kind of two ways, main families of ways of representing a cybernetic agent.

that we're going to see one of them is this Markov blanket type so here it's like a very physics based that's why we're coming from the high road with the free energy principle because it starts from this kind of like flow of physics space the other representation which we saw in

chapter two and gets used in chapter four and so on is this Bayesian generative model.

But like, you don't see the internal, external and blanket states, though here's different notation, but they're both ostensibly about the same active inference agent, right?

Where one can view the observations here

as the sensory states and then one can understand that the actions taken have causal impact on the world but that's reflected by the b matrix and learning on the b matrix learning how actions are associated with changes in the world so when it's coming more from like a high road perspective that's more in the physics and that's where you see more of the physics type formalisms

and then in more of the um uh decision making and signal processing area from the low road that's where we see more of these like just um not physics based in principle Bayesian methods there's probably a lot more to say about that in other ways to say it but um like

This representation is about a cybernetic agent.

Also, this representation is about a cybernetic agent.

And they meet in active inference where those models have some relationship.

Okay.

Figure three point or does anyone else want to make a comment or question?


SPEAKER_10:
Steve Grafton, I wanted to just follow up on that note, so we look at equation 3.2 very similar to equation 2.5 except in 3.2.

Steve Grafton, variational free energies contingent on a model.

Steve Grafton, So i'm trying to relate that with the previous comment about the cybernetic unit in the mark off blanket is that related to the model.

Steve Grafton, The contingent model.


SPEAKER_03:
yeah exactly so free energy like expected free energy variational free energy it's a quantity about a model like sum of squares is a quantity about a given linear regression that you might do as like an error term if you're fitting a regression

variational free energy is like an error term that is about a specific model.

I mean, if you put another node, you made a different model, the free energy would be a different number.

If you didn't have a model, a map, then you can't calculate a free energy for a model that doesn't exist.

So it's a descriptor of a map.

So everything is really conditioned upon


SPEAKER_01:
the parameters and the values that are in that specific model that that is yeah Darius yeah um just maybe a point of clarification for myself I presume it can't be entirely internalist um because at least just like looking at the KL divergence in the equation

the difference between the approximate posterior and the true posterior requires some commitment to there being an external state that you're trying to predict um so where

Is that just, you've got the variational model, so you've got the variational free energy, which is tied to your model, but ultimately it's also subserved by the fact that you are an agent in the world and that you're making Bayesian inferences about the world and it can be closer to the real world state or not.

I just don't know if I've got that the right way around.


SPEAKER_03:
yes that's true and the kale divergence gives us this optimizable incremental way to update our beliefs cue

to bring them to where they aren't moving anymore, just as a first approximation, where we can't believe any better about perception or action or cognition with respect to, as you pointed out, the underlying true distribution.

But this can be understood in practice as just not wanting to update your belief.

and achieving preferred states which is the maximum evidence model for the incoming data if you literally knew where what photons were going to come at you next and that is um minimized surprise

So this is kind of just like these three parts, they're being equated here, but they're different framings.

This is saying, this is the most performant model, best model evidence.

This is the least surprising model.

If you knew how much to be surprised, you would have the best performing model.

This is a well-understood relationship.

This is saying because of how free energy is defined, which isn't invented by active inference, look up energy-based method or evidence lower bound, this quantity is tractably optimizable.

And if we can reduce the divergence,

where there's the KL diversions shrinking, will be doing strictly better.

That doesn't mean good enough necessarily, but strictly better towards this situation.

Wanshun?


SPEAKER_09:
Yes, I have the question about this model concept.

Does the model refer to all those dynamic equations in figure 3.1?

What do we mean by model here?

here yeah yeah the model we have about how wire generated so so it could relate to everything in in figure 3.1 including like the the because why is generated based on your internal state based on external state right also it's also affected by the x active state yeah um yeah


SPEAKER_03:
if you had the total understanding of what photons would come next including how the world changes and how your action influences it that's the this is like an agent level loss function for understanding how wire generated but you could use energy-based methods on any bayesian distribution

But this is just introducing an important relationship amongst surprise minimization equals model evidence maximization.

That's the first part.

And variational free energy is a well-used method to tractably optimize this interface.


SPEAKER_09:
Right.

So 3.2 QX is a decision variable.

So to minimize, I mean, or to maximize, you want to minimize, right?


SPEAKER_03:
QX is the total beliefs.

Those are the beliefs that we control.

But take it again from just this level of the high road.

So not explicit counterfactuals yet, just flow across these four states.


SPEAKER_09:
So the generation of Y actually are connected in all those four equations or four states, right?

How those four states are changed.

How those four states changes.

So M refers to all the...


SPEAKER_03:
on the this process how this process are described yeah M could be a linear regression and Y would be the data and then we'd say the surprise is minimized the evidence is maximized and the variational free energy is minimized when we have the model in the data and the model is as good as it can be for the data so it's the exact same thing like the two pieces that come into play here are the model and the data


SPEAKER_09:
Right.

So, so the decision is your QX, right?

So it's a function.


SPEAKER_03:
It's not just the decision though.

QX refers to all of the optimizable beliefs, not just about action.


SPEAKER_09:
All right.

So it's, I mean, I mean, it's, it's a, that is, it's a belief that you, you may choose to minimize your total surprise, right?

Or to minimize your variation of free energy.

So am I all,

QX, you choose one to minimize this expression on the right side of 3.2.

Is that right?

So QX, what is X here?

X, does it refer to the internal state of their mind?


SPEAKER_03:
X is the external states.

Those are the hidden causes about how Y are generated.

Figure 3.1x, external states, how sensory causes are generated.

No thumb on the scale.

Only the external world causes sensory states.

So the generative model of sensory states being produced as they are, maximize your evidence about incoming data, minimize your surprise about incoming data, minimize your variational free energy about incoming data.

All of those are causal modeling of external states.

Analogously to how internal states are like doing that for action.

Because which one you call internal and external, you could flip and do the other one.

At this level of generality, not when you actually build a model, but this is there's there's still nothing that's really fundamentally different between internal and external.

Other than which side the modeler chose to do internal.

There is.


SPEAKER_01:
This will be my final question, I promise.

I just wanted to ask about the kind of architecture of the generative model.

So the agent is constituted by the internal states and the Markov blanket and the agent.

this was in Ben White's talk as well, this point of potential conflict or confusion that the agent has a generative model or the agent is a generative model, and that generative model has priors based on its optimism bias of the preferred states, the attractive states it wants to be in.

Can we consider the generative model, therefore, the internal states which are encoding

beliefs about the world and the Markov blanket.

And in that case, how could you say, if it is that, why would you say that the agent has a generative model?

And if you do hold that claim, what's extra about the agent beyond the generative model?


SPEAKER_03:
Yeah, those are great questions.

Well, what's extra about a person beyond their health record, which you do a linear regression on?

I mean, the territory itself.

So that's the instrumentalist answer is this is all just about the model.

We're just talking about base graphs and statistics.

So we're obviously talking about maps, not territories.

So that's, again, trying to take on minimal commitments.

But the question about like, does it have a generative model or is it a generative model?

Well, if you're talking about a software agent you designed, they might be the same thing.

You might say it literally does active inference because I actually have it implementing that.

Here's the script.

But if it isn't literally slash actually an active inference simulation, it seems like you're going to be in the situation described in figure 9.1.

So here you're building, this is the figure 4.3 generative model for the subject of a behavioral experiment.

That's why it's subjective.

It's their perspective as the mouse in the maze or whatever, but it's also like they are subject to the behavioral experiment.

And then here's the outer loop.

So would you say that the mouse is subjective?

the cognitive model that the researcher made?

Probably not.

So in practice, a lot of this like metaphysics doesn't come into play.

When you're talking about a specific generative model, it's a lot clearer that it's just like a very hopefully well designed, but just a reduced model of the system of interest.

Chapter 9 is about this kind of empirical modeling.

Minky?

Oh, I cannot hear you, actually.


SPEAKER_05:
Can you hear me now?


SPEAKER_03:
Yeah, yeah, go for it.


SPEAKER_05:
Okay, great.

No, I have a question that's very much related to that.

I think there are lots of sort of general comments about the systems to which we can apply active inference and what sort of the specific formal criteria are to describe a system as adaptive.

And I'm also very much interested in these philosophical perspectives and seeing sort of how

um in which sense you can view could view a whole organism um as um as sort of following the principles that specify by active inference or in which sense you could sort of use active inference to describe maybe um systems that are lower um lowering within that hierarchy that are maybe like um smaller regulatory systems in the body

So I was just wondering if there's any.

yeah sort of research on sort of the general applicability of active inference as sort of a way to analyze adaptive systems.

And I think it all comes down to the mathematics which I don't fully understand yet but.


SPEAKER_03:
Oh awesome question that's very cool one direction of research that comes to mind is like here's a 2019 paper so there's been a lot since then, and a lot more integration with with active inference to but.

Some of these representations of multi scale.

systems.

nested systems so being able to um unlike chapter five in the textbook there's going to be like a motor circuit that's influenced by a higher order decision making um circuit so then you you maybe you've been be able to to sketch out some of those lower level units okay what which paper was this again i'll put it into the um

put it into the chat thank you all right well cool um about chapter three i guess if uh next week or in in yeah next week at the other time we'll come back and if people can have added or voted on different questions and we'll talk more about the questions next week so thank you see you all thank you daniel