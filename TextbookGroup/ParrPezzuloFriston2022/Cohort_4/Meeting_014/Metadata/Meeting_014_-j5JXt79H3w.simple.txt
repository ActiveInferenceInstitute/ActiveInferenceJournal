SPEAKER_00:
Hey everyone, welcome back.

It is September 26th, 2023, and we're in cohort four, meeting 14 on our second discussion of chapter six.

So before we jump over to the text, does anyone want to just give any thought or take on six?

yeah briefly just Charles it's it alternates time so the earlier time now we're in cohort four chapter six and vice versa but it's all different angles on the same thing so it's not like there's something that won't make sense in six because that's cool I'll just hang around and absolutely carry on thanks yeah so you want to

give a thought on six or we can look at the questions that haven't been addressed yet okay let's just go to a question and then if somebody has another question they can write in the chat or raise their hand

The authors talk about language.

But in language processing, one usually assumes recursive processes, e.g.

a context-free grammar.

How can FEP active inference account for recursivity?

In my understanding, hidden Markov models implement types of regular grammars.

I assume that hierarchical extensions, i.e.

section 642, does not fundamentally change this, does it?

Did anyone here ask the question or does anyone want to give a thought on this?

I'm not exactly sure what the question is getting at.

However, some senses of recursion can be accommodated by hierarchical modeling.

So active inference models of reading have, for example, letters nested within words, words nested within sentences, and so on.

So

this hierarchical model embodies the sparsity associated with this kind of a recursive process.

And then another kind of related notion of recursion is closer to reentry, where something is more like self-reflexive.

And so that is less referring to like the hierarchically nested

like kind of nested for loops notion and more having to do with like re-entry of input and reference which we might point to first off just the fundamental re-entry of the consequences of action through perception via the niche for the agent

And then a little bit more, um, on the sophisticated cognitive entity, the recursive identity concept and like identity reentering in reference to itself.

Ali go for it.

Yeah.


SPEAKER_04:
Well, perhaps the question also, I'm not sure, but maybe

one angle to answer this question is to answer whether generative models are exclusively recursive models or not.

So I believe in active inference framework, and especially its current formulation, there isn't any restrictions for generative models to be exclusively recursive.

So they can be applied for both.

I mean, nested and recursive models, and also in some situations, we can have purely, I mean, non-recursive or sequential models as well.

So yeah, in its current standing, it is much more broader than only a recursive kind of structure as HHMs.


SPEAKER_00:
that we're dealing with a couple of decades ago great point and it kind of returns to the theme of chapter six and the questions that are asked in chapter six it's like is or what kind of recursive phenomena is being desired to to be modeled and then

They're sort of like what you intentionally include in your model.

Like you know that you want to have this phenomena and you're going to engineer and implement motifs or mechanics to get this phenomena.

Like it's your target phenomena.

You want to have a phase transition associated with people like leaving a crowded room.

And then like you want to like kind of like build that into the model super explicitly.

And then a little bit more indirectly would be you want to have some phenomena arising

but you don't want that phenomena to be like explicitly a parameter in the model.

that's the chapter six question what do you actually want to model what system of interest do you want to model and and that's non-trivial to identify the boundaries of the system and to subset what you actually want to model about it and what's interesting what questions you want to model because otherwise you're just making a map that's the territory

And there's no point in doing so.

Okay.

How is the active inference modeling recipe or approach to modeling similar and different from other modeling approaches?

That's a very good question.

just from what people have seen or what they feel what's what's one or more similarities or differences whether people have have done some quantitative modeling like statistics or systems engineering or whether they've done some other informal analysis approach how is or could be active inference chapter six recipe different


SPEAKER_03:
Yeah, Ali.


SPEAKER_04:
Well, I think this question is, I don't know, perhaps too general to be answered sufficiently or helpfully.

But when it comes to active inference modeling, my own understanding is that the main thing that sets it apart from perhaps all the other or many other approaches is

It's emphasis on constructing the useful and appropriate generative model.

In all the other approaches,

the representation of the world or the phenomena we're trying to model is not something that, it's not on very clear probabilistic representation terms.

uh so to speak but in active inference uh there is this clear distinction between what ex what kind of phenomena or uh what

Maybe we can say what kind of structure the phenomena or the the system we're trying to model encapsulates in terms of its probabilistic behavior.

So it is much more clear than other modeling approaches.

when it comes to the representation of that specific system, world, or the phenomena of interest in relation to its generative model construction.

So yeah, I think the main distinction lies exactly in the approach to constructing that representation.


SPEAKER_00:
Thanks anyone else feel free to raise your hand or go for it all also point to recent work by now at all from.

This year.

where they designing explainable artificial intelligence with active inference, a framework for transparent introspection and decision making.

It points towards some of the motifs that make it different and which give it a semantic interpretability.

because when features of the system including its own introspection its own confidence on its answers or its sense making are framed in terms of probabilistic parameters that are just what it says on the label then there is a clear sense of what structure or phenomena arising from structure of the system that we're modeling

that doesn't mean that the model in hand is going to be the system we're modeling obviously that's the whole map territory fallacy map territory fallacy fallacy situation but when we have um interpretable parameters that play explicit roles in semantic Bayesian networks

then um at least we're on that path yeah i'll um i'll bring that paper into i don't i'm sure it's somewhere else in in here but um charles this is the paper of uh ramstead at all on the map territory fallacy fallacy

And just in brief, commonly people talk about map territory fallacy, which would be the fallacious equivalence of a map in a territory.

People are pretty familiar with map territory fallacy.

Map is not the territory, all of that, maps are useful, some are, all of that.

And in this paper, they point to a kind of

extreme case where people will look at active inference free energy principle modeling and say oh well it's just making a map so it's just making a map of the territory so it's not the territory so it's kind of like what's what's the issue like what's the value add um

and so uh there's a few aspects to this and uh it relates to on one side um reification of the map and the territory like you go with the map to the territory and then like you you know that it's that the map's not the territory yet still they are used to kind of co-justify each other

then another flavor is oh well then free energy principle does nothing if it's just helping us build maps that's nothing that's just a mapping framework and that's like a fallacy on the map territory fallacy ollie or or anyone else what what what other angles are there i i can actually just chime in quickly because it relates to the one or sort of two-part


SPEAKER_05:
question comment that I did put in Dakota last week relating to chapter one, but maybe it's another angle on the same thing, which is the modeling versus action.

It's kind of a can of worms, but I don't know if that's enough of a prompt to kind of address these terms.


SPEAKER_00:
Yeah, how do you see it?


SPEAKER_05:
Well, I'm not sure.

This is just one of my initial questions that came up right away.

Is

I guess the answer is in the definitions, but in practice, how is the modeling as action compared to modeling in contrast to action?


SPEAKER_03:
I guess that's the best I can put it right now.


SPEAKER_00:
That's very interesting.

like modeling is an action it's an iterated process that a modeler takes in fact we could even do a chapter six on chapter six and make a cognitive model of somebody applying active inference to modeling

eventually I expect that that would be relevant so there is a sense in which modeling is an action it's a practice it has explicit and implicit skills associated with it so modeling is action however modeling throwing a baseball isn't throwing a baseball


SPEAKER_05:
There's a tiny bit more I can add, which I see I had written also, I think, in Code Word 5.

Of course, observing and documenting are both also action.

However, the systems and behaviors being observed would be the primary actors in the sense of action.

Yeah, anyway, it has to do with that.

Observing as action relates to that, too.


SPEAKER_00:
thank you yeah we'll um return to these but but um think about the setting of of so let's just say we're chapter sixing a baseball game so we have a person who's a spectator they are still taking action with their eye Cicade to look at different parts of the field reducing their uncertainty and then covertly internally

they are deploying attention as action, attending to different parts of their experience.

So even a seemingly passive, perhaps overtly passive observer is active at least in the attentional covert internal sense, if not also in the epistemic foraging

eye Cicade sense like choosing where to look but none of that activity happening in the spectator is the action happening on the field and then to connect this back to the map territory fallacy fallacy no matter how deep we go into this um model of like a spectator and an athlete

it does the end of the process isn't going to be like a material spectator and an athlete the map of that setting that cognitive setting isn't the territory that's so so now now we're immune to the map territory fallacy map is not the territory but then what is it it's a map and then um

I'll also note that Ramstad and Saktiva Devel and Friston go a little bit further than just naming their critique of this deployment.

They come back even stronger and say, actually, free energy principle is the ideal model.

And any model that doesn't conform to the free energy principle with respect to the map territory scenario is either saying too much or too little.

Ali.


SPEAKER_04:
Uh, so there's this heated debate in, uh, the philosophy of mind and, um, um, I don't know the philosophy of neuroscience about the meteorological fallacy, um, which, uh, says something to the effect that, uh, it is a fallacy to ascribe, uh, a psychological action to a part of a cognitive agent.

Uh, so when we say that, uh, the brain does something, it's not actually what brain.

that does that specific action, but the whole agent that possess the brain is responsible for the action.

So I'm not sure how, I mean, in this kind of self-referential scenario of modeling, this meteorological fallacy

holds or not, or whether at what point we can escape this meteorological fallacy.

But when it comes to map territory fallacy fallacy, my understanding is that the FEP and active inference escape this exact meteorological fallacy right from the beginning by not

uh conflating map and the territory and uh or in other words by taking a totally different approach to the concept of agency uh uh and uh it it's not something that's just metaphorically uh ascribed to uh part of the system so

when they say that a part of a system looks as if it does some kind of inference or

any action, it's not just a pure metaphor.

It's built into the very fabric of active inference theory.

So yeah, I believe in that case, this kind of self-referential scenario can be applied indefinitely if we wanted to with this specific kind of approach.


SPEAKER_00:
Thank you, Ali.

see if this is kind of another piece of it when we say a system looks as if it is bounding surprise or it's reducing surprise that's not metaphorical or the realist claim about the territory it's a narrow and limited claim about the map

which, and now all claims about maps, unless they're being considered in some abstract mapping setting, are on the foundation of the relationship between the map and the territory.

How is it being approached differently in ACT-INF?

We have figure 9.2, 9.1.

the meta Bayesian so here in the center we have the cognitive model of the system of interest of the subject of the modeling subject and then outside of the subject is the the this is figure and ground

So we're being explicit that we're making a map about the cognitive model of the subject.

Now, that subject's cognitive model could be a map of the environment as well.

But once we enter into this mode of modeling, we're not making claims about the subject.

we're either making claims about our map of the subject, and then a subset of that is maps that the subject makes about the environment.

I hope that didn't say too much or too little, but I think that is what it resonates with me when Alisa says that we kind of head off that fallacy from the beginning.

because the task that we're doing in cognitive modeling, if this is a rat in a T maze, or if this is some digital environment or something like that is we set up our work explicitly as making a map rather than like, well, what does the amygdala do?

It's like, well, then you're gonna get into a situation.

It's like, are we making claims about the amygdala?

Because that's a claim about the territory.

But if we say, well, we're building a map of the amygdala

and one of the functionalities in our map is that the amygdala is making a map of its environment so that's the kind of nested mapping and that's this that may relate to the earlier recursion question but now if we have um prevented or stymied off this map territory fallacy which is actually fairly easy to identify if it's approached hygienically

then we're just not making claims about the amygdala directly we're building the map which can include sub maps but then there doesn't have to be

I mean, this is the Scylla and the Charybdis.

Map territory fallacy on one hand, and then the fallacy fallacy on the other hand.

Because the map's utility and relevance is related to its mapping, of course.

Which we want to be able to say things like, yeah, 4th Street and 5th Street run in parallel.

And I'm not just talking about my map.

But that's the empirical question.


SPEAKER_01:
I had a question about the map and territory.

Could you explain more about what the fallacy is?


SPEAKER_00:
yeah i'll give a first take broadly the map territory fallacy is when a constructed map which is to say an abstraction or a model of some real material system of interest or territory when especially in a science or research or modeling setting it can be easy to kind of

conflate or use rhetoric from one regarding the other.

So we have a bunch of healthcare data on doing this and this health outcome.

And we did a linear regression and we found that smoking was increasing the risk of lung cancer.

Sounds like a relevant thing to say, but the more narrow statistical claim would be

there was a statistically significant positive regression slope between this measure and that measure so that's on the mapping we did a linear regression and we want to be able to I mean it's like look at the line don't we want to be able to say that there's like a positive relationship between these things in the real world so that's the tension

Because you'd want to be able to just, first off, look at your statistical results on the map and make a statement about the territory.

Like doing this increases that.

But that's already leaving the map.

It's like you're looking at the map.

It's like, well, it looks like these two roads intersect at this GPS coordinate.

But that doesn't mean that they do.

Especially if you're like extrapolating.

so so then if somebody were to have smoked twice as much then they would have this much more so the map territory fallacy is just it's done in science communication it's done in self-talk it's done in so many different settings where something is gleaned or constructed in the map as all maps are and then that is used to justify and sometimes even linguistically is is woven

or completely mixed into claims about the territory which may be valid or aligned or resonance or like pointing in the same direction so it's not like we're not in a situation where like maps are like deceptive unless they are but that is the tension what can you say about

the map and the territory but it starts with just the fundamental recognition and and the repeated exhortation that the map is not the territory which is why you hear that as well as like all models are wrong some are useful or the Borges story of the the map maker who like makes a map that's so detailed that it covers everything and then like it becomes the territory those are all kind of allegorical ways to talk about it

but the big issue is when we're doing scientific modeling we're doing map making and there's this complexity of relationship between any map and any territory and again it would be so simple and straightforward to just make the map do the statistics and then the statistics should just apply right back to the territory

You know, I have GPS locations on these two objects.

I made a statistical model of their location.

In the statistical model, they're close.

So can we say that the objects are close?

It's like, just let me say that.

But if it were that way, yeah, exactly.

As Charles says, it's not so clean and distinct.

There are settings where it is clean and distinct.

But those are not every setting.

that makes sense and it happens a ton in neuroscience as well because the territory is so messy and ineffable that it's like somebody will make some list of terms or they'll make some axes that they're studying summary statistics or um personality traits or just

Somebody brings some framework to reckon or to grasp with neuroscience or with psychology, and then they start reifying the existence.

It's like, I can't believe there's things in the upper left quadrant of this thing that I made.

But that's, again, it's a statement on maps, not territories.

Ajith, or Ali, sorry, go ahead.


SPEAKER_04:
I just wanted to mention a probably useful distinction made by Deleuze between representation and cartography.

He makes a clear distinction between what we want to represent, in other words, what we want to trace in our models, and the cartography or the action of mapping something in the model.

or diagramming or metamodeling or whatever.

So in this sense, I think what active inference does, I mean, in light of this distinction between representation and cartography, more maps into the representation side of modeling, in other words,

the very act of constructing a generative model of the world or the phenomenon of interest is done by tracing the probabilistic states of the world.

So it's not cartography in the sense of mapping or diagramming or metamodeling, but rather it actually does

this very active tracing representation.

So I think it also helps to distinguish between the usual way of talking about mapping or modeling in other scientific endeavors and the active inference way of doing things.


SPEAKER_02:
Would there ever be a case where you are talking about the territory like i'm just kind of wondering like when you would ever talk about the territory and science because wouldn't it always be sort of some representation you're working with.


SPEAKER_00:
What do you think.


SPEAKER_04:
Ali?

Yeah, so it depends on what we mean by representation in relation to the territory we're trying to, quote unquote, represent.

But I mean, even the simplest act of observing the world and observing

anything that we want to model entails at least an elementary kind of representational cartography combined.

So maybe

I mean, it's not possible theoretically and philosophically even to have a direct access to the territory we want to study.

But the only way we can we can have anything useful to say about that specific territory is through the representation and cartography.

At least this is one of the

Hamed Nademiya, views held held by structural realists.

Hamed Nademiya, and specifically ontological structural realists so it's not.

Hamed Nademiya, it's not about the content of the world, but the structure.

Hamed Nademiya, structure, the content of that world manifest themselves.

that scientists are interested in so yeah at least in in some perspectives it's not possible to have that direct knowledge of the territory I think it's an excellent question as many we just kind of surface them and it's for people to consider but but


SPEAKER_00:
we were engineers and if we were building a bridge and we had the blueprint and we were talking about the blueprint like is it sufficient to just make strong claims about blueprints that we have in hand on the table and then understand that there's a relationship between the blueprints that we make and the territory that we care about is that enough like is that like a firewalled approach where we're only going to talk about the blueprint that we have on the table

And blueprints are related to bridges.

Or are there times where we want to bypass the blueprint and just say, um, you know, maybe look at the bridge and say, these two things look like they're this way.

Um, and then, yeah.

What do you think about this?


SPEAKER_02:
Yeah.

Like, I guess there are some cases where you'd have to make sure, you know, that they're distinct, um,

especially when you're considering the things the blueprint can't really capture about the bridge.


SPEAKER_00:
Yeah.

And in neuro and psychology, these come up, especially when classifying brain regions or when classifying different neurodiversities.

One topic that Ollie's mentioned of the traces is,

in the world this reminded me of bruno latour's work on actor network theory and ants and this is a very like proto-active approach it's all about resuming the task of tracing

And it's very provocative, and another, I think, provocative philosophical term in this space is always already.

Like, these are just two English words.

Come on now.

The perception of phenomena by the mind of an observer, the features of phenomena that seem to precede any perception of it are said to be always already present.

that is very provocative I believe or evocative it's like it was already that way so we're showing up in the stream of things potentially resuming the tracing of associativity in a map making

setting charles quick context definition of blueprint and bridge there i was being completely exoteric i really was talking about a civil engineering setting with people sketching out a blueprint like an architectural grounds plan about a bridge that like cars would drive over so compared to the actual bridge then

yeah and then a neuroscience setting you know we'd have we have the person's body is the territory okay and then yeah and then the blueprint would be some some you know chapter five like well here's how you know the elbow bone is connected to the knee bone but the body is a complex territory which is why so much has been written and explored on it indeed thank you yeah

cool bridge too right sorry go ahead and the body's a bridge and the body's body as map body as void you know this as that this already always as that like that's that's the fun um okay let's go to this question from andrew

Okay, self talk is one of the topics or activities where map territory concerns apply any direct work or paper references on this topic, you could share.

What do people think.


SPEAKER_06:
And yeah, just to chime in, I mean, I just heard you say that along the way whenever we were discussing the fallacy there, and it just really piqued my interest.

But I mean, I can already imagine how that could play out as far as someone considering, you know, the self, the cognitive process of like they're attempting to map

whatever it is that's going on with them, whatever it is they're directing their attention towards versus the territory that is an entire generative process going on that probably from an active inference framework, they're only gonna be able to kind of approximate in their own model of that territory.

In any case, I just feel like I could get into an infinite regress here with just thinking of what's going on whenever I self-talk.

And I was curious if there was any published work here or anything along those lines.


SPEAKER_00:
I don't know of any.

published work on this I'm sure there are analyses on like self-reported self-talk

but it's something that is understandably hard to measure in flow.

And you get into all these kind of like recursive questions.

What have you remembered saying it to yourself, but you didn't in the moment, or you did say it in the moment, but you didn't remember it or tend to it.

Yeah.

I, I mentioned it just because it is like the kind of,

singularity of map and territory like okay let's just say that the that a cognitive activity is making maps so um just you know putting ourselves in the driver's seat not figure 9.1 not behavioral researcher but you could take that stance too but view from the inside

we are making maps of our territory you know where our objects are in the room and all these other things and then that map re-enters through heard language and sub vocalized language so it is embodied action as well Ajith

to myself talk do you mean like an inner monologue um I think I might be missing some context yeah yeah like stream of consciousness whether they just the the internal flow and imagination or even explicit self-coaching


SPEAKER_02:
I've seen a paper published where they use like FMRI data to predict what people's inner monologues are, if that might be something that could be some way of mapping out this territory.

Also what people are sort of imagining visually and also what they're listening, like what they're perceiving in terms of music.

Things like that.

I think, like the latest sort of deep learning models are actually getting sophisticated enough where they can be able to predict what people are intuiting.

Just using like the right type of data.


UNKNOWN:
um.


SPEAKER_06:
And just to say that very much is in line with the kind of thing i'd be interested in I guess bonus points that i'm interested in neuro imaging data, especially so I just shared is this.


SPEAKER_02:
I can send some papers that.

Actually.


SPEAKER_00:
yeah put them in here just follow the little token and then add them in here.

Oh.


SPEAKER_06:
I just shared one, just to see if I could confirm with you.

Is this at all in line with what you were referring to there, Ajit?


SPEAKER_02:
AJIT ACHARYA- Is it on the screen?

Oh, yeah.

Yeah, that is .


SPEAKER_06:
Quick Google search.

I'm trying to throw a self-check here.


SPEAKER_02:
This is not the one I was referring to, but I can find the one I was referring to.

I think it was like recent.

It was like in 2023.


SPEAKER_06:
Oh, that's even better.

Great.

I really appreciate it.

Thank you.


SPEAKER_00:
wow yeah it's this is very I mean and to kind of return to chapter six like this is why we have a chapter six this is why unified approaches to perception cognition action matter this is why having an active inference ontology is important this is why having a recipe for making generative models

and having some of this meta theory or meta position on the relationship of map and territory fallacy and fallacy fallacy and fallacy cubed um because these are not just massively interactive and non-linear systems of interest they're also ones that were always already experiencing

So if it was just a Rube Goldberg machine, that would be one thing, but it still wouldn't even be of the type qualitatively of, without even going too deep into phenomenology and like experience and awareness, it just wouldn't necessarily be of the type

that would be a recursive re-entrant cognitive system and this is why um i think the textbook ends with these lines important rights of passage in theoretical neurobiology

are trying to write down a generative model experiencing the frustration when simulations misbehave and learning from violations of your prior belief when something unexpected happens so it's like this isn't just a hot take like there's what can you say about some of these settings that's just like oh okay it's it's you don't just like

dropped the mic and like dust off your hands in this iterated generative modeling practice it's like especially if we're applying it to a setting like self-talk let's say or some other psychological phenomena um which you know impinges or overlaps on self-talk um you write down the generative model

there's a recipe it's chapter six plus some of the other pieces that people have added in you write it down you roll it out you see what happens did you expect what happens well if you understand act inf and you made a simple example you may have you may expect get exactly what you expect back like well I made it I made an oscillating pendulum

and it did exactly that it's like great well that might be like a homework assignment for like a certain course but if we're interested in something with more richness than like a pendulum then when we unroll that generative model we will be surprised

and then what do we do with surprise well we know there's two ways to bound it change mine change the world change your mind learn and update change the world re-enter change the generative model itself on the table so having a structured approach profession ontology methodology toolkit et cetera et cetera comes into play

And chapter six is kind of the transition point or like the fulcrum that the book is actually organized around.

Chapters one through three get us to active inference.

Context, low road, high road, to or of.

Chapter four.

generative models themselves, chapter five, generative models in the mammalian neuroscience setting.

And then pretty much as soon as we can, chapter six, now it's us making that generative model.

And even without extensive math or programming experience, we can start to address some of these questions.

And then we're already in the flow of things.

It can definitely feel like chapter four is like, well, chapters two and three can feel like waiting through like every single department of learning.

just to get to, and then chapter four can feel like getting through is like impossible slash improbable.

All totally makes sense in terms of their evaluation and how they're experienced.

but then like we break out on the other side of four just from a page Turner perspective in six and this is like such an incredible open conversation about modeling and these they're hard questions to talk about but

hopefully people can see that at the single entity or at the research group scale having alignment or shared reference frames around some of these topics are make or break

Thanks.

You can add and just, you know, add, make little sub pages or add your own question or just, you know, just the more references and the more things people add, the better.

It's awesome.


SPEAKER_02:
Okay.

Yeah, I can do that.


SPEAKER_00:
Thank you.

One other piece I'll just add on this kind of map territory is that the digital introduces a very interesting setting that's kind of like a chessboard in the sense that it's fully observable and that these are virtualized settings where

strong concordances between maps and territories can be constructed to exist so like there can be a schema an abstract pattern or scheme that then generates the territory

In a we know, ultimately it's embodied through like thermodynamics and information all this so not but but to a first approximation.

The digital systems.

have a different map territory relationship than.

birds.

to the inner talk point, body's eye, this is just making things like inner talk is, is reentrance auditory action and perception, even though it doesn't go through the ear.

I assume that these imaging studies ask the question, maybe even find the result that there's like activation of, of auditory processing or something like that.

Then we have visual

So those are internalized exteroceptive processes, inner eye, inner ear, inner touch.

But then like, do we have internalized interoceptive as well?

Like, can we take an inner virtual view on something that's already inner?

And is that, you know, different?

Where is it more or less relevant than self-talk?

But if you could take an inner position on the interpretation of the self-talk, then I think we get into Andrew's infinite regresses.


SPEAKER_06:
Yeah, I don't know.

It just brings up so many questions for me about how to conceptualize that one, because I mean, in a certain way, if someone were to engage in self-talk, I could view it as like they're

If we view the self itself as like a kind of map that the person has constructed so you're you're you've taken your map and now you're making a map of your map, perhaps like analyzing it or.

Maybe you're just engaging in some kind of nested structure learning like Oh, let me revise my model of myself I don't know there's only.

I think, you know, some kind of more empirical work would need something a little bit more finesse than the way I'm talking about it right now, but it's very interesting ways it could go, I could imagine.


SPEAKER_00:
Yeah, like,

the system can't a system cannot just provide if it if it just represents everything then it's just a pass-through system there's no attention or distillation or representation just a straight pass-through so whether we're talking about ourselves or some other hypothetical system

the self-representation that it explicitly makes to itself is a sample or a selection or an attention distribute reallocation of something else like that's just like kind of light and dark like is it all equally lit and it's just a pass-through or is there going to be some area that is brought more into focus in

the re-presentation and then so what should be re-presented maybe that's where people have different um views obviously but there's the preference to have our re-presentation be amicable or like pleasant that's clearly one drive another drive is for meaning


SPEAKER_06:
all these different things and i think you recall somewhere earlier in the textbook uh tristan will the author say something about a an agent having a model of itself in order to differentiate itself from its environment i.e the generative process around it and how that may be an essential

possibly an essential aspect, at least for certain entities in maintaining something along the lines of homeostasis.

That is, if you don't have a sense of what you need and what you need to do, which is part of you, then potentially you dissipate, you know, to the entropic processes around you.

So anyway, I don't want to keep us off here, but it's interesting, yeah.


SPEAKER_00:
It's fun.

Yeah, as usual, another great chapter six journey.

Chapter six is like an inflection point in the book and in how we approach things.

So we will then, in the coming weeks with alternating times, head into chapter seven and eight on discrete and continuous time models.

Chapter 9 on data-based analysis.

Chapter 10, wrapping things up.

All right.

Thanks, everyone.

Until next time.


UNKNOWN:
Bye.