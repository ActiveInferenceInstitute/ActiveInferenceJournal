SPEAKER_01:
All right, welcome.

Thank you, everyone.

It's August 15th, 23, and we're in cohort four in our first discussion of chapter five.

So soon we will screen share.

But first, any remarks that anybody wants to make on chapter five?

Just anything that stayed with them after reading it or


SPEAKER_04:
feelings that they had or anything else about chapter five um I will say um I found this to convert and conversely to chapter four being rather mathematically dense this one is a little bit more um neurobiologically dense at least for those who maybe are new to

thinking about the relationship between this and areas of the brain.

But I did appreciate in this chapter, there was much more on precision, which we didn't get too much before, even though it was brought up many a time in preceding chapters.

And I really appreciated the relationship that was made between different forms of precision and different neurotransmitters and neuromodulation.

I found that to be very

interesting and helpful and maybe kind of reinforcing the idea of like, they're not just probability distributions here, but also precision of each or like confidence in each probability distribution.

My big takeaway from this chapter.


SPEAKER_03:
Cool.


SPEAKER_01:
Thank you.

Anyone else just any thoughts on five?

Any other thoughts or any question that somebody wants to lead with?

Or we can just explore the chapter and look at some written questions.


SPEAKER_04:
I did want to ask what everyone makes of the relationship

Justin Delacruz- made here, I mean in preceding chapters we're talking a lot about.

Justin Delacruz- You know kind of the differences between viewing variables as categorical versus continuous and it's a big kind of bifurcation throughout many of these chapters like we have continuous models versus you know palm dps and.

Justin Delacruz- different ways of looking at things, but at one point in this chapter they point to the idea that.

There's actually a big relationship, a connection between the two that maybe what's going on in the upper levels of say the brain cortical regions and so on is that they're working with categorical variables, but in a way it's not simply categorical variables, but rather these are like looking at discrete trajectories that the continuous variables could take.

um that was a nice way of maybe putting making some kind of thread between the two ways of looking variables that is there's still a continuous aspect within the categorical states um it's just it's looking at it as a discrete trajectory didn't know if anyone made anything that found it to be useful for anything or anything they're working cool thanks um darius then anyone else


SPEAKER_02:
Yeah, it's not so much a comment on the previous point about discrete versus continuous variables.

I wanted to ask, really, a question more concerned with the mechanisms behind prediction coding, at least as it's embodied in the brain.

so you I can't understand this idea of sort of the shuttling up of prediction errors and the shuttling down of expectations I guess Daniel my question is we kind of just take this idea that prediction errors arise for granted um something I've been trying to kind of wrap my head around is to what degree is that a kind of just um

immediate mismatch between the priors at one layer and the incoming sense data or is it that those there's some Bayesian inference required to even compute the prediction error so you know I have a prior X I compute variable base to work out the probability of my prior given Y

Is that, in a sense, that distinction between the prior and the posterior, is that what is constituting surprise?

Or is it just the pure sense data coming up the chain, which then is discordant with my prior X, if any of that makes sense?


SPEAKER_01:
Yeah.

what a lot of the a lot of angles of this just first very briefly yeah this uh hierarchical hybrid type of model where the higher levels of the system are discretized

and then the lower levels are kind of like where the rubber hits the road is being more continuous that's a motif that comes up like again and again for example in ryan smith's at all's uh work live stream 46 active inference does not contradict folk psychology this is a common motif and a big reason is that counterfactuals are not really so clear in a continuous setting

Like if there's three discrete choices, you can really quickly talk about the tree of all choices.

But if it's just like a cone of options, you could take like an infinite amount of paths because technically even paths that are only one infinitesimal apart in the continuous space are still distinct trajectories.

So in the continuous time, you don't really get a kind of

explicit planning or explicit counterfactual and so in order to deal with cognitive decisions which which often are um categorical or discrete or deal with like explicit symbolic actuals then you need some kind of discretization and yes the good news is that they work well together and that gets revisited in chapter five

in practice when all of the um difference neural models are going to get brought together and shown that there's no issue with the continuous uh model here and the discrete model up here and then also comes back in chapter eight okay about mechanisms of predictive coding the brain well it's interesting to look at the first words in this um section

chapter four gave us a lot of general information about variational inference about generative models um essentially following from free energy principle in this chapter we focus on the process theories which are are explicitly about a system of interest so whereas a principle can't be falsified or not it's just it's it's something that is um

in the realm of decisions that you take towards modeling, process theories are more in line with scientific hypotheses.

They're actually like kind of living and dying with empirical evidence.

But the amount of empirical evidence for any given statistical model of brain has nothing to do with whether the principle is valid or not.

Now, that doesn't mean it obviously it's good when we see empirical support for process theories under the principle, but there's no piece of evidence that could be found.

I mean, maybe this is an overstatement that would validate a principle because principles aren't validated by evidence, but nor are they rejected by evidence.

However, it's super interesting to connect them to specific systems.

going to be applying generative models to the brain bayesian brain plus action and one of the kinds of models but but not the only kind of generative model that exists for the brain is like the hierarchical predictive coding architecture and so in that architecture um which arose from video compression but then was later found to capture a lot of biological phenomena

there's an alternating stack of error units and kind of estimator units.

So that the different levels of estimator units are sending ascending error signals and descending predictions.

So Darius, you're asking, is that mismatch

immediate or is it computed through a bayesian update i mean is that the question yes basically well the trivial deflationary answer is bayesian updates happen in bayesian statistics so if you want to make a statistical model that calculates an exact mismatch or if you want to have it do bayesian updating

that's about the map not the territory so we're already lifted away from what the system's already doing um in this chapter in the motor unit here it is just a direct mismatch descending predictions of the of the um mean

incoming proprioception and it's just a simple differential but that simple but there's no reason why you couldn't make it slightly different um like you could have i mean you you could do anything with the legos that doesn't mean it would be more effective or or give unique explanations or predictions

but in its simplest form, which is embodied here, it is just a differential, denominated in units of the measurement.

Could you do a Bayesian update?

I mean, could this variable

what would that do or what would we get by having this do a Bayesian update?


SPEAKER_02:
I mean, I sense the difference between the two models would be one, you have predictions coming down the stream and you get the mismatch coming from what the higher levels are expecting and it's kind of meeting at this point where the prediction error is occurring.

The other one is that the prediction occurring is just happening within a level where there is a prior

That prior is then getting updated, given evidence, and there's going to be a mismatch between the posterior and the prior.

So that's all happening within the level, the prior of the level and the posterior of the level.

Whereas the other way of thinking about it is the kind of prior of a higher level, the proximate level, and that's shuttling down.

You get prediction error shuttling up, but the kind of level where it's all happening is just a meeting point under that model.


SPEAKER_01:
yeah i i see what you're saying so like if if this were instead of just a simple simple differential if this were like a common filter so it had its own inertia and it was get it was doing its it was getting input and then it was doing some like filtering just like common filter and then it was sending some signal back up yeah

there's an infinite amount of model architectures.

You could compose it however you want in principle, and no piece of evidence can support or reject the in principle construction or composition.

So there are definitely some interesting properties of that.

And then this is where we get to the process theories.

So then we look at specific measurements or cognitive or behavioral phenomena in biological systems, for example.

and then we seek to compose something that um captures some of the phenomena that we want to capture recognizing that maps and territories uh are not the same thing and then you have a whole portfolio of models and you compare them in terms of their um

accuracy, explainability, adequacy, all of these standard statistical modeling methods, then you write the paper with all the compared models and you publish the code, then other people continue developing.

So that's kind of more normal science than it can sometimes seem.

But the earlier chapters talked a lot about what could be done.

I mean, and other literature goes beyond that.

And then they're not saying this is how it is.

It's not the final word on process theories for active inference.

It's simply the interpretation consistent with available evidence.

So they're just saying, here's one model architecture that we're using for unique explanations and predictions in these different neural systems.

now those specific model architectures are at the mercy of data like if someone said I think these three factors contribute to this health outcome that's a hypothesis and then someone's good thing I oh no I think it's just these two and someone else says I think there's a fourth factor those are all going to be compared just like regular scientific modeling

whereas none of those discussions are going to be like well the the three-factor model doesn't fit the health condition so linear regressions are incorrect that's like a category error but now in chapter five we've kind of crossed the river from the general high road low road to now I guess I don't know specific cars on the high road and the low road or something like that um

So this gives us a very different like flavor and deployment of active inference because we're so directly talking about process theories.

And these are the ones that are in contact with the empirical.

Any other thoughts or questions on this?

okay well chapter five is going to um go through three neural systems from the mammalian nervous system and in the end it's going to be kind of a frontal cortex a midbrain region

and the spinal cord region and the chapter is going to introduce these three different models which essentially um cover some connected though distinct cognitive phenomena and those three systems are going to be considered separately and then it all gets built up to figure 5.5

which composes these three systems and starts getting you towards that whole iguana.

So this is like how functional composition for these kinds of generative models works.

We're not gonna go into the whole category theory elements of compositionality here, but it's just encouraging to know that the generative models that somebody makes

are able to be synthesized and play nicely together.

So you could also compose one of the brain, and then you could compose one of a computer, and then that would be your human-computer interface.

Or you could have two humans, and then that would be your communication system.

So that kind of model compositionality is a very nice feature that Chapter 5 makes kind of an understated argument in support of.

highly okay 5.2 microcircuits and messages any any overall thoughts or anyone want to like give a summary on what they read or what they were left with from this section um just a comment and this kind of follows from something we


SPEAKER_04:
briefly discussed last week in chapter four in one of the meetings, but I found it very interesting, the idea that they're kind of like asymmetrical frequencies implied in this 5.2 section, that you can have nonlinear functions in the lower level, computing errors related to incoming sensory information versus a prediction.

And that's set up in a narrow imaging that seems to be commonly associated with like a gamma band frequency versus the descending predictions that are made, which tend to be at like a slower rate, like somewhere around theta, I suppose.

And so it's just, it felt like this was giving a little bit more concreteness to

predictive coding and saying like there are differences in frequencies there are various functions or differences here it's not as simple as um taking a simple vector of the predictions from the upper layer and the sensory information like and just doing some simple subtraction right but

of the actual minus the predicted.

It's rather that there's different speeds of information movement here and different components, different parts, and different ways you could potentially model it.


SPEAKER_01:
awesome yeah and one short note i'll add i'll add there and bring in to the notes um the reactive message passing paradigm which i hope we'll hear more about from dimitri and bert in the symposium um these are computational implementations where different nodes in the graph can update at different frequencies so it's perfectly amenable to that terry's


SPEAKER_03:
yes i mean it's um it's in this section so it's page 87 yes yeah you were just there um if you go down a little bit yeah this is

Is that where it is?

It's above the middle schematic.


SPEAKER_02:
Oh, yes.

Perfect.

So if you just leave it there, I think this is exactly what I was talking about, which is it says here in the bit sort of the middle part of the bottom paragraph, you send the output from layer three, superficial pyramidal, pyramidal, blah, blah, blah.

So that layer is shooting prediction error up.

then you get the descending input represents a prediction from the higher level presumably, while descending output is a prediction for the lower level.

So I think that is kind of maybe worth unpacking because it's, I mean, there seems to be a lot going on and a lot of predictions going down and

prediction error going up so it would be good just to get some clarity on exactly where all this is happening and you know what layers we're exactly talking about here yeah yeah good good point there's a few things so first I'm gonna I'll bring in one one blog post that kind of contextualizes like why are we focusing on this cortical architecture at all


SPEAKER_01:
Jeff Hawkins has a book and I guess some startup or something related to this cortical architecture.

So a lot of people have, whether they've looked at the gross neuroanatomy or they've looked more into the finer scale neuroanatomy, a lot of people have centered on the cortical regions of the brain

which it's in the mammalian frontal part of the brain, and it's the part that's wrinkly and on the outside, that that type of tissue organization supports different cognitive phenomena that people are interested in.

Of course, not to say that other regions of the brain are not also doing different cognitive phenomena, but that for certain kinds of cognition, understanding the connections within and across the stereotypical units of the cortex called columns,

this has been a super active area of research now a really important note is that while there are six layers so-called six layers in this in the cortex these six layers are histologically defined basically so they're defined on tissue properties like what you can see out of the microscope and like gene expression things like that

this is not a six layer sandwich with prediction error prediction error six times so this is not a six level hierarchical model this is actually a but now this does have a hierarchical modeling but if you look at the subscripts or the superscripts we see i and i plus one

So actually these six histological layers together are composing like kind of a single multi-scale jump.

And then the idea is that across cortical units, because they also signal laterally, not just within the column, higher nested models could be constructed cognitively, but this is not like a six layer nested model.

it just happens to be the case that this tissue has these six laminar histological layers.

Okay.

So the layers with numerals, these are just anatomically defined.

These are not statistically defined at all.

And on the left,

the anatomy of this column stereotypical column is shown and each of these nodes represents like a cell population so not necessarily just a single cell but perhaps like a group of cells that have some similarities and like the spdp ssii these are like different cell populations

and this on the left is showing their empirical anatomical connections that's not to say that's all of their relevant connections just like there's a subway map and then also there's footpath so there's bioelectricity there's neurohormones there's a lot more in play but this is just the wiring associated with these cell populations okay um

Now, as common in computational neuroscience, a given single cell or population of cells is going to be associated with some variable on a statistical model.

And here we basically have two main letters.

So first the tilde means through time.

The two main letters here are the mu and

And the, um, the E the mu is like the mean estimate and the E is, um, the error signal.

Um, I'm.

I'm a little bit not sure why G is being discussed here rather than Mu.

Ali, do you have a thought on this?


SPEAKER_06:
Well, yeah, actually, I guess that's because you see, based on some framework,

You see, all the brain's needs or the way that the signals need to be passed through this bidirectional path, they don't need to be satisfied all at once.

So obviously they're prioritized by a decision-making triangle in which the immediate current needs

or in other words, the residual prediction errors, they converge on the, as Holmes described in his book, periaqueductal gray, and they're ranked in relation to the current needs and opportunities.

And this opportunity is manifested in the form of a kind of two-dimensional saliency map.

in the superior colliculi.

So this prioritization triggers a kind of conditioned action programs, which in turn unfolds in expected context over a kind of deep hierarchy of predictions, or in other words, the generative model of the forebrain.

So these actions, uh, they're generated by, uh, prioritize, uh, affects, uh, that are generalized, uh, that are generated, uh, by, uh, prioritize ethics.

They're somehow voluntary.

Uh, in other words, they're subject to the immediate, uh, here and now choices, rather, uh, kind of pre-established programs or pre-established algorithms.

And, um, on the other hand, these choices are, uh, kind of felt in, uh, if we want to talk about the higher order, um, higher order elements of the brain, uh, they're kind of felt in the extra receptive, uh, consciousness, which, uh, again, contextualizes this kind of affect, uh, and, um,

They're made on the basis of this fluctuating precision weighting.

In other words, arousal, modulation, and postsynaptic gain of the incoming error signals that are, on the other hand, rendered salient by these prioritized needs.

And they're also buffered in working memory.

with the aim of minimizing uncertainty or maximizing confidence, which also correlates with the current prediction as to how that particular need or particular desire to minimize the prediction error needs to be met.

Briefly, what this amounts to is a bit unsettling, which says that the higher order elements of the brain or the consciousness would only be required to mediate mismatches between the internal and external states.

And the more adaptively and predictively reliable our model becomes, the more our behavior will become automated.

In other words, operating below the level of conscious experience.

So, yeah, I guess that balance between the

I mean, the precision making of the G and the E comes from, or at least can be explained from Solm's framework in this way.


SPEAKER_01:
Awesome.

But there's no G in this figure.

Well, here's G. Here's the full descending G. So just like the knee bones connected to the leg bone and all of that, ascending and descending are relative to obviously which node we're talking about.

So the ultimate descending, um, prediction again in a, in a, a standing person, the ultimate descending prediction is gonna be like the, the main big output of this model.

And that's, what's going to, um, uh, it's not shown here, but it's, it's what is the, the full output of this whole column is this G.

I mean, there's so many.

Oh yeah, Ali, go for it.


SPEAKER_06:
I just wanted to add another

point here, which you see these kinds of errors.

Well, the word error can somehow connote negative needs.

I believe in the free energy principle framework or active inference framework, or at least Mark Soms interpretation of it.

That's exactly what our consciousness feeds on.

so um in other words uh the the surprisal uh i mean uh the consciousness as i said is only needed uh i mean roughly speaking in situations where a surprisal needs to be minimized uh if no surprise though there would be not much need for uh consciousness or

to put it in a different terms, consciousness is a kind of process that seeks to somehow overcome itself.

So these kinds of error are essential for any higher order activity of the brain,

Amit Singer- Be it I mean consciousness decision making or any kind of higher order activity, so it would never be exactly equated to zero because that would basically mean to go unconscious and to not have any higher order activity.

in the brain.

So this also maps onto Anil Seth's theory of consciousness as a kind of process that seeks to minimize the surprisal.


SPEAKER_01:
Yeah, also error.

Yeah, like you said, error can seem like it's a bad thing, but it's like a set point and half the time

your error is going to be well in a calibrated system half the time the error is positive and half the time the error is negative if you're spending more time uh if 90 of the time your estimates are too high in a Gaussian world then that would be a signal to update um there's a lot more detail to go into with the exact um

mechanics here um including the the difference between the middle version and then the version on the right which is more connected with the notation that we saw from the pomdp um but this is kind of like a um

it's like I have for some reason I'm thinking of a fancy iced coffee percolator with something is coming in and this is like a percolation mechanism and there's a there's a descending from I plus one that's the G here prediction from the higher level and then there's the um ascending

uh differential this isn't the raw signal data coming in this is already the differential coming up and then those are able to meet through a statistical mechanism

that also recapitulates but but not exactly I mean it's not like it's this five and three it's it's it's not exactly intended to to be but this is the result of the this is a falsifiable process theory that then somebody can explore like well what statistically happens when this when you transiently suppress this exact connection and then the process of model building continues Darius


SPEAKER_02:
I asked whether the I in this, um, is that referring to the tilde?

Is it referring to time where I plus one is, uh, future or past predictions and whatever, or is it actual, is it part of, is it relating to the level of the hierarchy?


SPEAKER_01:
Correct.

I is the Ith level of the hierarchy.

I plus one is a higher level of the hierarchy.

Tilda means through time.

Um,

now they're going to abstract a little bit from this six layer showing all the nodes so here we still have one two three four five six with figure five or I mean uh with a uh layer four um being shown now it's being clarified how

nothing's falling in my room now it's um being clarified how here we have I minus one I and I plus one so these are three cortical columns that are next to each other and now those three cortical columns are able to actually instantiate a three-layer nested model

So it's almost like we get the vertical stacking through horizontal concatenation or composition where the outputs of one column can be errors like here from I. And also notice that I, that they're not bound within a column.

Here's I minus one.

And then the error unit of I.

then the mean and the error units of i and then the error units of i plus one and then the highest nested layer on the right um which is uh only sending descending predictions and getting the highest level ascending predictions uh Daniel mm-hmm


SPEAKER_00:
Yeah, I'm just a bit lost with what you just said in terms of what I, I minus one and I plus one mean here.

So for me, that was, you know, three different time steps within the tilde, you know, big vector of states and not, you know, communication between different columns.


SPEAKER_01:
Yeah, the I, the superscript is not time.

subscript is used for time but here this is referring to three nested levels so let's just say this cortical column we're we're guessing the hundreds place this one with the tens place and this were the ones place so together this is a three layer nested model that's um doing predictive processing on a three digit number but time is not shown here it's just saying tilde it's all happening through time

and here the I superscripts are related to the level of the hierarchical model.


SPEAKER_00:
Okay.


SPEAKER_02:
Darius?

Sorry, I don't know why it keeps going into clapping.

I do mean to clap.

Everyone's making excellent contributions.

So just to summarize, it seems like there's hierarchy both within and across.

So if you go back up to that, so the way you spoke of that before is there's a three layered nested hierarchy, but we also have superficial and deep down the vertical.

So

what I mean it's a very general question but why is this computationally efficient to have both vertical and horizontal hierarchies why can't we just shuttle predictions and prediction error across one dimension yeah well as stated this though it has six tissue layers


SPEAKER_01:
is really like is this is like a minimal multi-scale model um you could make a model you could make a um predictive processing hierarchy that's like a skyscraper and just simply has three on top but it just turns out that this is actually capturing the structure of the brain so i guess what i mean is we what do we what's what's gained


SPEAKER_02:
by, you know, it makes complete sense.

I mean, whether it's vertical or horizontal, I think is a moot point because it's just, you know, it's just way of, I guess, picturing it.

But what's gained by having two dimensions rather than one.

So what I mean by that is what is the function of the verticality, the deep and superficial verticality


SPEAKER_01:
if ascending and descending predictions is compensated for or counted for by the horizontal axis in this picture in this diagram yeah one answer is that the the the histological um verticality let's just say the fact that there's multiple layers of tissue gives you a really nice packet or motif

that has both the units that you need, the mu and the E. So it has the two pieces that you need.

So you could have your workshop with just a bunch of mus and Es, and then just compose it however you needed it without caring if you were reusing motifs.

But if we construct a motif, like a cortical column,

That that's able to do what it does by itself and also contribute to more nested models just through a diagram and combining them like this.

It just makes a scalable, reusable motif that's developmentally plausible and actually has support in neurobiology.

Olivier, then Javier.


SPEAKER_00:
Stavros Stavridovich, yeah isn't the the horizontality here mustn't think about different areas in the rain, but could also be seen as a hierarchy, you know vertical hierarchy between you know lower area like no v1 v2 and v4 in a in a visual system.

So we will have, you know, both verticality within, you know, each of this area and, you know, a more general connection between areas in which, you know, you have a more and more complex invariant message.


SPEAKER_01:
Yes.

You could coarse grain and you could look at other neural systems in terms of message passing and hierarchical models.

Go for it, Javier.


SPEAKER_05:
Yeah.

Connecting back with a thousand brains theory of Hawking's wouldn't disconnect as well with the fact that Hawking says that you have just one model.

You have all these columns and micro columns, like creating lots of different models, and then you have this sort of voting system.

that is connected is related to the horizontal connections in which the different columns are influencing each other is that a sort of way of explaining this you know vertical versus horizontal so maybe the horizontal sort of voting or influencing uh the models created by the different columns or micro columns something like


SPEAKER_01:
yeah that's a great a great um comment one paper that kind of approaches that is this fame in the brain fame in the predictive brain um Dennett had this fame in the brain meme

um and and uh this paper argues that basically like the the unit the unity of consciousness is like kind of like underlying it there's this subconscious process of selection amongst those models

I mean, again, this is running fast and loose with the map and the territory because we're talking about a system of interest, but we're obviously talking about the act in fontology.

But if 10 counterfactuals are imagined...

each one of them in deliberation might be transiently famous and explicitly considered.

Like, you know, I could go to coffee shop A, I could go to B, I could go to C. But then for things that are experienced, that can be understood as like the outcome of this election or selection process.

So it's like the winning hypothesis is what is...

you know, in the spotlight of consciousness or awareness at a given time.

Ali?


SPEAKER_06:
Yeah, and also, aside from that saliency map that I mentioned before, I don't believe the representation of the nested hierarchy is about, I mean, necessarily, it's not necessarily spatially

distributed horizontally distributed representation.

It's more like the unpacking of a single

let's say, tangled neurons that's unpacking that figure.

The real physical or spatially distributed hierarchy is the vertical one in which the clusters of different types of neurons

are packaged into vertical columns.

And that's also, I believe, so Darius asked, what's the computational justification for such an organization?

Well, that kind of packaging can be efficient if we consider the different types of neuron with different length of axons for each neuron.

Each of those types of neurons can be assigned with specific tasks or can be more efficient in doing some tasks other than the others.

I believe that's also one of the reasons for

the vertical distribution of those types of neurons.

But again, that nested hierarchy is just schematic representation or unpacking of a single tangled neurons and it doesn't refer to any spatially distributed hierarchy.


SPEAKER_01:
Yeah.

Also, we can think back to the neats and the scruffies.

I mean, the extreme scruffy position is every synapse needs its own framework and university department and software package.

the other end you have the extreme meat framework and and so real work exists on that continuum and that's part of the unfolding discussion and one can only imagine how much neuroimaging and and molecular histology goes into the development of these really elegant computational um models and then

people take them in different ways some people take these and abstract or generalize them even more and aren't as worried about whether it actually adheres to the structure of the brain um like what if we had two cortices on top of each other and we had this and we had that um someone else might want to um make it more directly connected to the measurements they were taking in their lab

So again, chapter five is a five switch from chapter four because chapter five really is getting into the empirical and the specific systems of interest.

That's going to come back again in chapter six when we talk about the recipe and chapter nine when we talk about integration with data.

um but that's kind of the the breadth that that we're in between on one hand the more theoretical work like free energy principle and active inference in principle and on the other hand these are specific models and and um

What do you call somebody who makes an evidence-based critique of this model?

A computational neuroscience student or researcher.

I mean, that's all there is to that field.

Looking at how other people have integrated the information and made models and then offering positive developments and critiques beyond that.

So it's kind of interesting after all, like the math and philosophy that it can feel like in the earlier chapters here, we're just like dumped squarely into empirical neuroscience and the connections just signaled by a new chapter.

just so that we see it before we write down our questions and hopefully people can add as much discourse.

It's super, super helpful to vote or add your own thoughts and curate the answers of others in the coming week.

But basically, here's what's going to be upcoming.

We're going to go from looking at the cortical column to descending predictions playing a role in motor control.

proprioceptive information is going to come in.

And then in the ventral and dorsal horns, but basically in this cross section of the mammalian spiral cord, the descending predictions are going to meet with the proprioceptive incoming information.

And that's going to result in kind of this differential guided motor activity selection.

Like I want my arm to be here.

It is where I want it to be.

It's not moving.

Move the set point.

Now the arm moves.

then um going back up to the cortical column we're going to now trace another projection so not just a projection to the spinal cord but also cortical layer 5 targeting some deep brain structures like the stratum and other aspects basal ganglia very interesting very cool dopaminergic and and uh brain regions

uh several topics and cognitive phenomena are discussed that the midbrain regions are important for here in figure 5.4 we also talk about policy selection and the direct and the indirect pathways of policy selection one of which the indirect is basically a pass-through on habit

And the other, the direct pathway involving an expected free energy calculation, so thus updating prior probabilities on policies, habit, updating that according to the expected free energy of policies, which is to say their epistemic and pragmatic value.

So this is kind of a type one, type two, or like a habit pass-through versus deliberative decision-making distinction.

Table 5.1.

provides some empirical work connecting different computational uh variables to neurotransmitters of course neurotransmitters do different things in different brain regions different synapses different contexts this is the neat and scruffy again we could have a framework for every single specific neurotransmitter um or we could just say all neurotransmitters are the same and this is somewhere in the middle this is saying

we can actually understand some uniquely valuable insights and unique predictions from associating different neurotransmitters in certain contexts with different computational roles.

5.6 comes to this hybrid theme.

which is about connecting the continuous and the discrete hierarchies.

It's a total major theme of the textbook, though we are often distinguishing between discrete and continuous state spaces and also a special focus on the continuous and the discrete treatment of time.

as with other modeling um it's it's revisited multiple times that you can make hybrid models for example with continuous modeling at a lower level and categorical modeling at a higher level um finally in the closing pages they stitch together all three of the systems that were introduced

So the descending signaling coming from the cortical column on one hand, going down to the motor selection unit, however, also going down to the behavioral planning and selection components.

And in fact, those behavioral selection and planning components then reentering into the cortical

so that the action can be decided.

So just one example of compositional cognitive cartography and bringing together different modeled subsystems of interest and using active inference to integrate diverse cognitive phenomena.

And that's chapter five.

Any last comments?

Well, next week will be our, it's the symposium.

So hopefully people can view it or rewatch it.

Then it'll be our final discussion on chapter five.

and the following week will be an unrecorded session for for like feedback um we really need everyone truly so we will be especially interested to hear everyone's feedback with this anonymous feedback form for people's um suggestions on how to develop and improve there's many many notes

so it it for those who want to stay active and and leverage their contribution reading what people have already suggested which is quite copious and then curating or adding it and then maybe even finding a place where like you want to continue to get more involved in the coming months and years then we'll uh take some weeks off

And then restart the second half of cohort four with chapter six.

Meanwhile, start cohort five from the beginning of the book.

And the work goes on.

Okay.

Thank you, everyone.

See you next time.


SPEAKER_02:
Thank you, Daniel.

Bye.