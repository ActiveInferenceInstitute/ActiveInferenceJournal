SPEAKER_00:
All right.

Hello, everyone.

It is July 11th, and we're in the second discussion on Chapter 2.

So before we go into any of the questions, does anyone just want to bring up anything or just start with anything about Chapter 2?

Ali?

And then anyone else who raised their hand.


SPEAKER_02:
Amit Singer- Thank you yeah I just uploaded the equation 2.5 walkthrough in the I guess I put it in the equations table if i'm not mistaken, but equation 2.6 needs a little bit more fine tuning before it's ready, but i'm sure it will be ready for the next week so.

I think I put it at the top of the notes section of equation 2.5.

So if anyone wants to, but yeah, that's it.


SPEAKER_00:
All right.

looks awesome can we maybe uh go over it or can you just walk through it or yeah sure yeah uh well first of all um


SPEAKER_02:
We began with just basic definitions, such as some fundamental definitions, such as the Shannon entropy.

And then to derive the first line, we substitute the Shannon entropy term into the first line of equations.

uh we can see there's uh an interesting parallel between uh this kind of formulation between energy and entropy and also the path integral formulation of variation free energy but the essential difference here is that

Here, the first term represents only the energy, but for the path integral, it can be best described as the energy constraint.

So that's more of a side note there.

And then for the second line of equation, 2.5, we get, but before going into the equation,

The second line.

Just let me unpack the first line a little bit more.

So for for the people who who are not familiar with callback libeler diversions, we put the definition of callback libeler at the top of the

or at the top of the page one.

And then by using Jane's inequality, we get the callback Leibler divergence bounded by the expectation of the log p over q.

and that allows us to substitute the shannon entropy term into the expectation of the log p over q so that was the essential move for unpacking the first line of equations so i mean without jensen's inequality we wouldn't exactly get the the exact term of the first line of the equation because

Obviously, the order of the log operator and the expectation operator is different than we need here.

So yeah, that's basically straightforward algebraic manipulation.

And the second line of equation 2.5, or the terms, the trade-off between complexity and accuracy, similarly can resolve from

uh substituting uh i mean by uh expanding uh the first line of the equation and then substituting some of the term as the callback libler divergence and then we get the complexity term

and the rest will be the accuracy.

So what it means is that, as pointed at the bottom of the page, the greater complexity is, in other words, the more one needs to change beliefs to explain observations, the lesser predictive accuracy will become.

So in this case, variational free energy would be just the minimization of the complexity or at the same time, maximizing the accuracy.

And again, it can be compared to the path integral formulation.

It's almost identical to the path integral formulation of the tradeoff between complexity and the accuracy.

All right, so for the third line of equation 2.5,

uh we've tried to somehow get the trade-off between the divergence and the evidence but in this case evidence is just something that acts as as the bound or the evidence lower bound so it's something that's always greater than or equal to surprising right so

uh by unpacking the um the last line of equation 2.5 into these two distinct terms or this trade-off between divergence and evidence uh we are allowed to have this um

elbow or evidence lower bound or in other words the negative upper bound that would enable us to regard BFE as the optimization parameter or the parameter to be optimized rather than trying to achieve the exact value of

free energy, but just some optimization parameter, which would be much more tractable than trying to achieve the exact amount of the free energy.


SPEAKER_00:
Awesome work.

Nice.

Cool stuff.

anyone want to ask a question or or make a comment on this could you maybe explain a little more like zoomed out from this document what does the variational free energy uh do in the model like in the textbook okay so a variation free energy is


SPEAKER_02:
variational technique that, sorry, as I mentioned, allows us to do the approximate computations of Bayesian inference in terms of optimizing a certain parameter, namely the variational free energy.

Because computing the exact Bayesian inference of, or Bayesian output, sorry, Bayesian inference,

with regard to both posterior and prior would be almost impossible, especially in complicated situations.

And by complicated, I mean everything that's not a trivial, simple situation.

So that would basically are all real-time situations that we encounter.

And obviously we're interested in modeling.

So this approximate Bayesian inference technique is a very useful way to overcome this shortcoming of exact Bayesian inference in terms of its intractability.

And it makes the computation or the optimization of the variation of free energy much more computable and tractable as compared to

um exact bayesian inference uh which would obviously have uh many practical um i mean it can have uh many practical benefits uh and not just something uh that's described in theory and doesn't have any practical applications and modeling and so on

So yeah, that's basically the idea behind using the variational technique and using a certain parameter as the upper bound, or in other words, the negative of a lower bound that needs to be optimized, whether maximized or minimized, instead of just trying to compute the exact value of interest.

So variation-free energy, on the other hand, includes all the established frameworks for doing Bayesian inferences.

So for example, the techniques developed by James Kahneman and others that I think it was...

which table was, which figure, in one of the figures in the book, I suppose it was in chapter two, I guess, there's a nice comparison between the different terms of variation of free energy and all the other theories of Bayesian inference.

Yeah, exactly.

So we can see that it's more generalized theory of optimizing

the Bayesian inference than risk sensitive KL control and other techniques of Bayesian inference that have been developed throughout, I mean, the past several decades.

And so each of those terms can be accounted for by

Roozbeh Gharakhloo, Including or, let me put it this way by vomiting some of the terms and we can basically get the exact same formulation or the exact same previous formulations we had before, but, as we see this is the much more general way of.

Roozbeh Gharakhloo, calculating the approximate bayesian inference.


SPEAKER_00:
Okay.

Anuj, do you want to answer a question or do you want me to read it?


SPEAKER_01:
Yeah, I just had this curious, like, is there a case, like, when we already know that, like, I cannot do exact inference, but are there cases when I should also avoid optimizing this variation-free energy, given that in any case I cannot do exact inference?


SPEAKER_00:
I'll give a first thought on that.

You always could.

You could choose your models however you want, but you will be doing strictly worse with respect to the accuracy complexity trade-off.

But you can invent an arbitrary statistical method, but you will not outperform the information geometric maximum possible performance.

okay okay yeah thank you in any given free energy that you do compute the the model may just be rolling to the bottom of the hill and you might just be way off base for a real system so this isn't the model adequacy problem this is the model optimization problem

So it's analogous to the L2 norm in the linear regression framework.

Like every scatter plot, you always converge to the one L2 norm regression, R squared, p-value, all of this.

So this plays somewhat of an analogous role by enabling these different generative models

to be optimized in a real-time sequential way.

And it turns out that it's the same optimization strategy that variational autoencoders use and just variational methods in physics.

So it's not like variational methods comes from FEP or ACT-INF.

It's just using Bayes optimal model fitting, just like L2 regression, let's just say is optimal linear regression fitting, optimal Bayes fitting with the variational free energy, which is a functional because it's a function of a function.

It's a function of Q, the function that you're optimizing over and Y, the data that are coming in.

So generative model of vision and sensory incoming data, which is what is like the thing that is getting the best trade-off of accuracy and variance.

Thank you.

Okay, and then...


SPEAKER_02:
Ali or oh and yeah go for it uh sorry yeah and one um i think crucial point here is uh the reason for using the callback library divergence

for comparing the two distributions.

So I suppose the justification for using KL divergence is not explicitly stated in the textbook, but it derives from the Neyman-Pearson lemma, which basically says something to the effect that the most efficient

Roozbeh Gharakhloo, way to compare two distributions would be to compare the logarithm of their I mean to compute the logarithm of their likelihood ratios.

Roozbeh Gharakhloo, So that's basically what's meant by callback Leibler so it's not just an arbitrary technique for comparing to district distributions it's actually a proven theorem or lemma.


SPEAKER_00:
uh that uh that this is actually actually the most uh efficient way to compare to distribution so uh yeah I wanted to point that out as well yeah thanks and just adding one piece I'll put this in the notes there this is uh with nor Sajid and others and Carl and they use the rainy divergence so in principle

you could use different divergence or distance measures but the kind of um I mean it's a it's definitely an interesting question about where one might have different properties but KL is kind of like the go-to in at least this sense


SPEAKER_04:
yeah alexi and then anyone else this may seem like a silly question and i think ali gave a fantastic mathematical uh road but is there a metaphor for variational free energy versus free energy as free energy is explained in the book well but variational cell this one is intractable this one is tractable this is an estimation but uh i don't know in terms of you know uh

Is there an example or a metaphor that you bring home of the variational free energy specifically?

Does anybody have one?


SPEAKER_00:
Yeah, I'll think about it.

I'm happy to say one.

But does anyone else want to give a thought?

Like, what is free energy and variational free energy?

How can we think about these?

Ali?

And then anyone else who wants to?


SPEAKER_02:
Yeah, I'm not sure about a particular metaphor, but you see, I mean, the optimization approach, as opposed to calculating the exact value of something, basically comes

or can be likened to the situation we have when in a very simple situations, we have a function that can get an exact value of something as compared to the asymptotes of getting increasingly close to the value but never reaching the value.

By optimization, we allow for even the exact, even for the situations for which we don't have any information with which we would be able to calculate the exact value of something.

But instead, we can get closer and closer to the exact value with the information we have, but

nonetheless we can reach a very good approximation and obviously we can define what do we mean by the good approximation based on the error we want to reach but yeah in most situations we don't have enough information to calculate the exact value of

the parameter we want to calculate.

So it's more than the question of intractability versus tractability.

In some cases, it is impossible to compute the exact value based on the information we have.

So I believe in these cases, the optimization technique or variational technique is the only way we can get close enough to the real value.

or to the exact value.


SPEAKER_00:
that's a great point um that like even if the the variational model is just woefully not structurally mapping onto the real external uh generating function

like the generative model is a unimodal distribution.

And then out there in the world, there's like five bins.

And so then there would be different patterns of model fit, like it might just fit the one that has the most or the one that not the most or blur the whole thing.

But according to its generative model, it would never get worse in terms of

all of the considerations in equation 2.5.

It will never get worse on the complexity minus accuracy frontier, or it will learn that trade-off manifold optimally.

So those are some fairly good statistical aspects just of any Bayesian model that's fit this way.

So that doesn't guarantee like adequacy in the real world, because again, you could just have an inadequate generative model then cease to get to the charging station or whatever.

So it's not a success or a function guarantee, but it's a model fit.

Or it doesn't mean that you'll have adequately balanced, you know, or had a memory window that's optimal or all these other things, unless you've really taken them all into account.

And, and then just to Alexi's question or Bronwyn, do you want to add anything?

Equation 2.6 is the expected free energy.

Ali, maybe do you want to summarize how is equation 2.5 different than 2.6?


SPEAKER_02:
Yeah, so basically they're very, very similar structurally, but obviously we need to take into account the pie or the policy that needs to be

I mean, in variation-free energy, we only deal with the situation in which the perceptual data is, we only deal with perceptual data.

So we don't need to act upon the environment in order to fit the data better to our generative model.

But in expected free energy,

uh we delve into the action domain of the uh i mean action perception loop so obviously in this case we need to take into account uh the effect of the policies on our both priors and posteriors so uh the point of commencement uh

for derivation of equation 2.6 from equation 2.5 is exactly how applying the policies to those prior and posterior terms can affect the whole equation.

And that's where we get equation 2.6 and its variance in other lines of the equation.


SPEAKER_00:
awesome one point about equation 2.6 is uh first off it's g not f and it is uh like the argument that it takes is pi which is the vector the list of all of the policy trajectory possibilities

So variational free energy, which was described really comprehensively earlier, is basically that trade-off frontier between accuracy and variance estimator according to a generative model.

That's the Q and the Y. On the variational free energy, this is like a sense-making or perceptual model.

real time and the self-evidencing component of variational free energy is like if you're repeatedly measuring your body to be at homeostasis and you expect and prefer that then like things are working out and that's sort of the closure of the adaptive organism is like by fitting the variational free energy about homeostasis

then it stays within homeostatic bound but expected free energy uses this pi or policy variable and so whereas variational free energy is more like signals processing expected free energy is more like control theory because it's an explicit evaluation of different possible futures

Does anyone have any other thoughts or ways of thinking about variational and expected free energy?


SPEAKER_05:
I did have a, this is more in the form of a question, sorry, but I thought it might be useful.

So we have here in chapter 2, page 34, when evaluating the free energy of outcomes, the outcomes are the consequences

However, when evaluating the expected free energy, the outcomes play the role of causes and sense their variables that are in the future, but explain decisions in the present.

As you said, everything you said thus far has kind of gotten to that, kind of explaining what that quote means.


SPEAKER_00:
Can you maybe paste the quote here just so we can see it?

Thank you.

Meanwhile, let's look at this question.

Can anyone throw some light on these terms?

Both are posterior.

So indeed, sometimes the initial prior d is called the prior.

But technically, every variable that gets an observation coming to it in a Bayesian framework

is a prior an observation and a posterior update on something it's not like a free floating prior so every distribution that's bayesian that's why it's like prior on state space or prior on policy which is like habit that gets sharpened by expected free energy so then the output of this um operation is like habit

Matthew Evertson, Ph.D.

: policy prior sharpened by G into policy posterior, and then that policy posterior can be sampled from or just selected with the best option.

Matthew Evertson, Ph.D.

: Then about the specific

Matthew Shollin- Interesting as you paste it in all um we'll look at it, but just now to these two terms mentioned so Q X given pie and Q X given wine pie, so this is a question about the kale diversions um so.

the computation of the expected free energy for a given policy, everything is conditioned on that policy happening.

And so between these two things, two sides of the double line,

they're both conditional policy and they're both have an aboutness of the hidden state through time, X tilde.

So the only difference is that there's this Y tilde observations through time on the left side.

So if the observations that you expect under that course of action

aren't going to update your hidden state beliefs then the divergence between these two cues is zero the information is meaningless there's no information gain you're not learning anything you're not updating your hidden state model based upon the observation whereas if it was a epistemically informative course of action and you expected to reduce your uncertainty

um on this course of action then y tilde um would lead to an update on x tilde so there would be a divergence here so that policy would have epistemic value whereas the pragmatic value is about the alignment of preferences with the observations that you expect


SPEAKER_03:
All right.

Does anyone have a thought on or on this quote from Andrew?


SPEAKER_00:
I'll just give one reading, not sure if this is the full or only way, which is like when we're talking about the sensory data themselves, which are sometimes just called outcomes, sensory outcomes.

So like when we're talking about the why that we're, the outcomes that we're actually observing,

Those are the consequences of hidden states that are like emitting those.

So we're doing equation 2.5, where the consequences of the causal model are what we're trying to fit.

In contrast, in 2.6, those observations in y tilde have not happened yet.

So they're projected observations.

So they are unobserved.

It's the opposite of time travel.

Say you and I haven't observed the temperature in two hours, but I can have a tight or a wide prior on that variable.

But it's a type of hidden cause analysis to say, well, if this happens under this condition,

and then basically kind of backpropagate that into the present.

So it's a causal impact of an informational state that's expected.

And that's not like a paradox or anything like that.

So there are the outcomes of a causal process, but then in the EFE,

they also have a causal Force because differences in them lead to differences different differences in expected observations lead to different action selection


SPEAKER_03:
Anyone else want to ask a question?

Or it looks like there's at least one that's from the cohort.

Alexi, yeah?


SPEAKER_04:
So I was really happy to read this paragraph where they talk about generative process and generative model.

And they're saying that

They could be in different state spaces.

One could be five dimensional.

One could be two dimensional, continuous, and categorical.

I think that's a very profound statement.

And for example, if I talk about temperature outside, and I use words, and I say things like hot and cold, right?

So I place a continuous outside variable in my two categories.

So I could model this way, but it's a bit of a distortion, if you wish.

I don't know if you have any comments.

I'm just thinking out loud about this, that this is, I think, it's just mind blowing that, you know, we're modeling something, but we will be in a completely different state space and different variables, different variable structure.


SPEAKER_00:
Yeah, that's a great insight.

One thing I'd add to that is like, if you measure the height of the people in the classroom,

you can optimize a binary classifier, tall or short.

And then you can do optimal model fit to make the line between tall and short optimize some trade-off, like recall or something like that, accuracy minus complexity.

You could do a three-category model, four-category model.

You can do a continuous model, all these statistical distributions.

And they're all going to not complain.

They're all going to get optimized.

So that's kind of the blindness, but the power of essentially just Bayesian statistics is that once it's all lined up, it just is going to get optimized.

Now, it may be hard to optimize.

It may be easy.

Again, it may be adequate or not, but it's kind of like within.

So just that, yeah.

Yeah.

It just, this is what the strengths and the weaknesses of empirical modeling, which is that modeling doesn't have to reflect the structure of the modeled system at all.

And it doesn't for scientists and it doesn't for the models that are made.

But some of them are adaptive still.

So those are the lifelike ones.

But pedagogically, they don't have to be lifelike.


SPEAKER_04:
That's a very great example, Nithya, that helps.

And one more question, if I may, and then I'll be silent.

At the end of the chapter, they use the word intention.

And I posted in the chat the exact quote where they say, in psychological terms, this implies that creature's belief about policies directly corresponds to its intention, which it fulfills by acting.

I'm just a little puzzled by the use of the word intention, which typically means motive.

of an agent, you know.

I don't know how it's meant here.

This is where I got really lost in what exactly do they mean by intention.

Seems an unconventional use of the term.


SPEAKER_00:
Anyone want to give a thought on that?

Okay.

I, uh,

Oh yeah, go for it.


SPEAKER_02:
Yeah, this is just a speculation, but maybe the meaning of the word intention here, and particularly in this paragraph, is related to the way it's used in

some of the literature on action philosophy.

So for instance, Alicia Huarero has developed a theory of intention as kind of the process that results from the causation of constraints.

So by intention, she means basically the process that puts the system of interest in its causal constraints.

So it's not necessarily

maps onto or at least precisely maps onto the psychological sense of the term so but that's just as i said only a speculative thinking i may be wrong okay another um angle is from the paper um active inference models do not contradict folk psychology


SPEAKER_00:
it was live stream 46. does anyone who participated in that or was there want to just like summarize what they thought this paper's argument was about that issue so basically they use the belief desire intention framework BDI

um which i i had not heard of but it's a commonly used framework um and it actually came up in the um first lecture by avell in the um active inference for the social sciences ben white mentioned folk psychology and avell kind of like followed up was like what do you mean by like by this basically um but the belief desire intention model is just widely used to um explain

everyday behavior and intentionality.

It's like what people kind of slip to, you know, this enzyme wants to bind to this or, you know, prefers to bind to this in a way, just kind of broadly.

And they identified those constructs, belief, desire, and intention with different constructs in the active inference generative model.

So they just basically said, like, you're not wrong.

It's just a description.

But the beliefs are the hidden state beliefs.

And they kind of unpack this in the context of also distinguishing between the discrete time active inference, Chapter 7, and the continuous time active inference, Chapter 8.

And so they kind of do simulations that pull out the belief, desire, and intention pieces in the context of someone who's going to the fridge and getting ice cream, which Dean had a field day with.

um yeah but but another more deflationary way not necessarily like an experienced intentionality like the set point of a thermostat or the set point of a motor limb you can call it what you and it's just as long as you understand the map territory then such such an intentionality is is not massively metaphysical


SPEAKER_05:
I found the use of the word intention there just like from within the confines of the models is described as far as.

To just be referring to like we're, including a C vector that is preferences like those are included along the way, like there's a yes, something like desire or.

You know direct the agent is heading, as opposed to just total free form, you know going for anything right.


SPEAKER_00:
Yeah, good point about how these intentions or preferences or expectations for observed outcomes, that those form kind of like explicit intentions.

Like if you have, in terms of the directionality and the amplitude.

and uh yeah there's a lot to say on on that this is what goal oriented or um adaptive behavior would look like not saying that every single um implementation of such a system is like you know or taking on any of that like we don't really talk about reward um or goal in the active ontology

So that's why some people have very broad views on like intentionality and action.

But the deflationary and instrumental answer is always, it's a variational Bayesian model with action, signal processing plus control theory, Bayesian statistics.

That's not even including free energy principle or Bayesian mechanics or going into any of that part at all.

So it's purely defensible even without FEP.

Just thought I would say that.

Did whoever added this question want to explain it?

Or anyone else who's here want to ask something just while they're here?

Okay.

So about equation 2.6 and epistemic value.

So value of new information.

Instead of minimizing the divergence, we want to select policies that maximize the expected diversions, hence information gain.

Okay, so only with respect to the epistemic value, more informative observations is more epistemic value.

That doesn't mean that those highly informative policies are going to have a pragmatic value.

Like discovering what's at the bottom of the ocean may disrupt pragmatic value about your body temperature.

But it is an epistemic policy.

How can we reconcile the above statement with page six all facets of behavior and cognition living organisms follow unique imperative minimizing the surprise and the approximate variational free energy of their sensory observations.

Anyone have a thought on this.

So.

models of perception and action that do surprise minimization have the best possible generative model.

Minimization of surprise is equivalent to maximization of model evidence.

If you knew exactly what to expect, how much to expect it,

That's the same thing as saying that you have the best fitting model.

So maximization of model evidence is surprise minimization.

That can't be exactly solved.

That's the exact Bayes issue that we discussed earlier.

The most modern way to solve it is variational accelerated optimization on the Bayesian evidence lower bound.

Now, you could do that about any variable in principle.

But what this imperative does is it connects it back to sensory observations, which can be interpreted as, for example, homeostatic.

So minimizing surprise on homeostatic variables, minimizing surprise via FE of any variable is doing the optimal Bayesian inference on it.

You could do strictly worse on accuracy or variance estimation, but if you want to use the Bayes optimal, Bayes information criterion optimal model, this is just how it's done.

But this connects it to the homeostatic potentially adaptive imperative, but it doesn't have to be seen as like super adaptive and strategic.

It can be seen also for like an inert object.

That's the variational free energy.

So that's the kind of unified imperative of real-time self-evidencing behavior.

But as was mentioned, it does not address action selection.

It's a functional of beliefs Q and the data Y. So we need the expected free energy, which is explicitly prospective.

Now, within the expected free energy, there's the two terms that different policies are evaluated based on, epistemic value and the pragmatic value.

That's just one of the decompositions that we'll all look forward to the breakdowns on.

But yes, it is the case that for a given evaluation of a policy, the more divergent the sensory information are,

the higher the epistemic value would be.

But that doesn't mean that it would be associated with a pragmatic value.

So an adaptive agent would, you'd hope, avoid extremes of both extreme information seeking that risk pragmatic value or vice versa.

So that's the model fitting, questioned, balancing all the parameters so that the strategy is actually adaptive.


SPEAKER_04:
um okay alexi and then we'll continue with this question i wanted to add to what you just said uh daniel which is a very nice way to summarize it that um seeking epistemic value seeking knowledge is for humans pleasurable you know this is an effective neuroscience called the seeking drive literally the dopaminergic exploratory system we enjoy that this is the enthusiasm curiosity that drives scientists and artists and other things and

When all our biological needs are met, when we're not hungry anymore, when we're safe, we default back to that system.

We start exploring the environment around us to see what's out there, to gain epistemic knowledge, to maximize evidence, to decrease the surprise, the negative surprise in the future so that we're not killed and we're not dying from hunger.

Once we explore the environment and find out where's the orchard and where are the predators, that helps us in the future to avoid unpleasant surprises.


SPEAKER_00:
Nice.

So the divergence for the variational free energy.

Let's look at two point.

Well, we've seen them previously.

Maximizing divergence to maximize information gain appears logical.

However, maximizing information gain would maximize ambiguity and risk, which is the uncertainty about consequences of action in the world.

Or this could be describing risk in these two lines.

which are two very similar representations of equation 2.6.

Like the left term is the same, and here is observations.

So this is the risk of like sort of conditional policy about how much uncertainty there is about observation sequences.

And here is about hidden states.

And I believe that this number is always less than this number because you're always more certain of proposing something hidden.

You're always more uncertain about.

I believe there may be a different reason, but it's like.

You're always more uncertain about proposed latent causes.

Above and beyond.

surprise uh bounding of observables maybe there's another way to think about that too thank you lexi wouldn't beliefs assign low probability to policies that will maximize discrepancy expected free energy ambiguity and risk well kind of yes and no um

what would be the the most epistemically salient would be something where you were sure about the outcomes and they were going to contribute to information gain like I have a trusty book and I know that so I have 100 certainty about how opening the book to this page about kind of like the epistemic quality

So it's a salient in the mapping between the underlying semantics and the observation.

So this representation just, maybe there's another way to see it too, or I mean, I'm sure there are, but just like, this isn't like risk, like danger.

This is, as far as I understand, looking at,

how your action maps cleanly and preferably.

And here's the more sensory mapping, not to get too deep in that one point.

But yeah, anyone else have any questions or thoughts on chapter two?

Ali, that was awesome work.

How are you going to continue?


SPEAKER_02:
Well, we'll continue to unpack all the other, at least essential equations, if not all the single equations in the textbook, but we're focusing on developing similar derivations for all the central equations in the textbook and particularly

from chapters two, three, and four, which I believe constitute the most fundamental chapters of the textbook.

So I hope we can prepare it in time so it can be hopefully useful for anyone who wants to understand them a bit better.


SPEAKER_00:
Awesome.

Anyone else have any thoughts?

Well, we will head next into Chapter 3.

So, why do we seem interested only in discrete state space, discrete actions policy?

Discrete time is fine.

yeah um well chapter eight you're gonna love but uh it is presented as as um there there's always a um discrete and continuous time are just two options or two two families of models that can be hybridized in chapter eight but yeah 100 the book focuses on both um and thomas parr's book stream

is he describes the history and the differential focus between continuous and discrete time models.

And it's a big topic that we talk about in chapter seven and eight.

Do you have any other comments on that?


SPEAKER_02:
And even before those chapters, we encounter preliminary formulation for continuous time active imprints in chapter four as well.


SPEAKER_00:
Yeah, and five with a spinal reflex arc.

So they're just different.

And I mean, the figure 4.3, the kind of Rosetta Stone figure is about the structural similarities between discrete time and continuous time models, but also understanding their differences.

So chapter three is going to be the high road.

So figure 1.2.

Chapter two was the Bayes theorem.

So that's why we were talking a lot about like the fundamentals of Bayesian statistics, because up until this point, this is the same thing as just saying variational Bayes with perception and action.

That is exactly, someone can implement the variational Bayes with perception and action differently, but kind of,

Thinking cybernetically, that's what they would need to make any kind of active inference agent, whether it's using Fristonian active inference or not, but if it has to do perception and action.

Chapter three is going to take a very different approach that's not going to focus as much on the how as on the why of self-organization.

and the way that this is modeled with different Bayesian architectures.

This kind of prepared us on how it's going to be done.

Chapter 3 is a focus on the why and the free energy principle, and then also it's going to arrive at active inference.

Chapter 4 is more about the generative model, discrete time or continuous.

Chapter five is neurobiology, kind of a sampling of different kinds of generative models, how they connect.

That's kind of the next three chapters.

All right, so enjoy everyone.

Thank you.

Thanks again, Ali, and everyone else who helps with the math.

Oh yeah, there will be math learning groups.

I believe they are Wednesdays at 13 UTC.

They're on the calendar.

So, you know, whether there's one person or more than one person, I hope people enjoy studying there and connecting and just improve the documentation.

do whatever people feel like doing.

But there's not a specific focus or facilitation around these sessions at this point.

But if someone wants to, whether they're familiar with math or not, they're welcome to.

But just good luck in the math learning group.

All right.

Thank you.

Bye.

Thanks, everyone.

See you.