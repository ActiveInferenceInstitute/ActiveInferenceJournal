SPEAKER_01:
all right welcome back everyone we're in cohort four of active inference textbook group and picking up on the second round of activity over the last few months in cohort four some of you were there there were some people who were not there who are here now and vice versa

we went through the first five chapters and now in this last three months of 2023 we're going to head through the second half of the book so before we like go into anything even remotely active conceptual does anyone just want to share like where did the first half of the book leave them

And or what are they excited about in the second half of the book for this interval?

Or any questions that are kind of guiding people's curiosity and learning journeys?


SPEAKER_00:
I thought that this was the first meeting for cohort five, but I'm still works for me.


SPEAKER_01:
Yeah, just just briefly to that note.

It's every Tuesday.

There's a core five and a cohort four, and they're like an alternating times.

So sometimes people just join whichever time is more convenient for them.

But by the way, it's all recorded.

It's all here.

It's all the same textbook and it's many coats of paint.

So there's like literally no reason to even read one chapter for another.

In fact, chapter six is a very great entry point in certain ways.


SPEAKER_00:
Excellent.

I'll probably come to both.


SPEAKER_01:
Anyway.

Cool.

Esmail, and then anyone else who wants to raise their hand.


SPEAKER_02:
My question is about our Discord group.

Long time I'm looking for...

some mass group for learning but i don't know i can't find there is some group about mathematics in the discord or no now it's stopped


SPEAKER_01:
Um.

So you're referencing the math learning group.

There's no special place in discord.

This this math learning group.

It just kind of like it's like a team name that if there's people who are motivated to like pick up that banner and commit to doing some organizing, like, say, I will be here weekly.

to do this and that or here's where we're going to take notes people are welcome to do that so it's just kind of like there for people who would love to see it be there but we're not doing anything further and it's not like there's like another forum or anything like that everybody who registered is added to all the calendar events and this is the shared document for everything yeah thanks

yeah where does the first half of the book leave us and then how do we set an intention or what is exciting about the second half of the book yeah i smell or anyone else uh i thought the first half was pretty comprehensive um and i do


SPEAKER_03:
I like your description of many coats of paint, because it is like each chapter, you are going over a lot of things that you covered in a different way in the previous chapter, but in a sort of new light.

And I do wonder how that will come back up.

A lot of the concepts will come back up when we're designing the models, which I think the next half is more focused on actual applications.

And I'd say, you know, there are certain things I want to like go back over on myself just later in the previous chapters, especially like message passing and more of the neurobiology stuff, which I, uh, am very interested in, but, um, not as familiar as like maybe just some of the regular like Bayesian statistics aspects of it.


SPEAKER_01:
Cool.

Thank you.

Yeah, again, anyone can use their hand or write anything.

Just to recap though, the first five chapters, the authors say is the epistemic or the learning part.

And that's where the kind of what is active inference is covered.

First, there's a context provided, then the low and the high road are gone through.

Low road is how, that's Bayesian statistics.

The high road is why, that's that persistence imperative.

chapter four goes into the generative models of active inference which are exactly what the second half of the book is about applying however chapter four gives a pretty long and comprehensive treatment of what a generative model is and then chapter five studies the setting where the most generative models have been constructed and deployed and associated with empirical data which is mammalian neuroscience so it's a very tight first half of the book

then we get into the second half of the book and in the beginning of chapter six they call their shot they said this chapter provides a four-step recipe to construct an active inference model and it discusses a bunch of other design choices the quote here give me six hours to chop down a tree and i will spend the first four sharpening the axe

pretty interesting it's like okay well how much time do you have to make this active inference generative model do you have 10 minutes and you're scribbling it on a napkin or do you have four years or 15 years to develop this and then here we are in this chapter where it's like yeah what is sharpening the axe what is the tree that we're going to cut down

kind of starts it on an interesting note.

Is there anything anyone wants to like, ask or say about just active inference generative modeling?

We can dip into chapter six now and look at the recipe itself.

But is there anything people are thinking or curious about in terms of like, active inference generative modeling?

It's an exciting moment, and this in certain ways is the topic itself in practice.

All of the discussion around an active inference model of this and of the eye saccade and of depression and of organizations and of Gaia, those are active inference generative models of insert system of interest here.

So that's what the earlier part of the textbook approaches in theory.

And chapter six is where the recipe is laid out.

And there's a lot of dots to connect and some of it, we can add detail and connective tissue.

But this is kind of like the real moment where active inference goes from being like something that's being discussed on stage or conceptualized by others in their mind into being something that we enact through constructing a generative model.

Like reading the first five chapters to continue with this culinary analogy is like reading recipe books or reading a molecular gastronomy textbook.

or reading about micro and macronutrients or the mylar reaction or like all these like sort of like ideas about cooking and here's the recipe and then there's still more guidebooks and play-by-plays and workplace training and all these kinds of things would be associated with the practice of cooking but this is where that culinary textbook does a crossover moment into talking about the recipe itself

thank you Andrea yes we can definitely overview six also on the top of each chapter page there there is a short textual or a video with a short overview that Ollie and I have prepared for for the chapters um okay so let's look at the the recipe itself

So section one, they're just talking, section one of chapter six is an introduction and they do make some very relevant points.

And then in section 6.2, we see the recipe itself.

So we've pulled the recipe out just so we can kind of expand and discuss.

The recipe asks four questions.

Which system are we modeling?

what is the most appropriate form for the generative model, how to set up the generative model, and how to set up the generative process.

And then they write, these four steps in most cases suffice to design an active inference model.

Once completed, the behavior of the system is determined by the standard schemes of active inference.

Specifically, or technically, the descent of the active and internal states, the autonomous states,

on the free energy functional associated with the model so the recipe is asking us questions that only we can address situationally that help us set up the landscape could be a very dynamic landscape it might be a very trivial one that just kind of rolls to a single Valley but these questions are going to help us construct the landscape that then the ball rolls downhill on

so it's kind of like making a pinball machine or like making some other kind of um Rube Goldberg machine we're at the second level conceptualizing of a system and then asking that's like what what system are we modeling what do we want to model and it uh isn't necessarily always uh easy which system we're modeling someone's joining we'll see

But this question about system of interest is in common to active inference generative modeling, as well as to just broader systems engineering.

And we get into the active inference specific questions here about the appropriate form of the generative model.

So this is the first... This is the first of the three practical challenges.

And this...

is brought up in chapter four earlier when discussing generative models in discrete or continuous time and then it's revisited in chapter seven and eight which are going to go into more detail on time but it's one of the big upfront questions that come into play after the system of interest has been determined is where and how time is going to be traded

maybe if anyone wants to, like, what's a system of interest that we could kind of carry through for the rest of this discussion as an example, or just to kind of ground some of these more general topics?


SPEAKER_03:
Like an example of something like, example of what we would want to model with this recipe?


SPEAKER_01:
Yeah.

Like,

What would you answer to the first question?


SPEAKER_03:
Could be like, you know, a robot that we're trying to model using active inference.


SPEAKER_01:
Sounds good.

Let's continue with the robot setting.

What is the most appropriate form for the generative model?

So that brings up this time question.

And you could imagine different time conceptions, maybe even different sensors and actuators on the robot have a different time conception.

From that early question, steps three and four are really where the work happens.

The second question with time is an early modeling decision that sets up broadly which branch, chapter seven or chapter eight, the model is going to be built in line with.

These are kind of like two architectural styles with their associated technical differences.

As they write, if you have a process that's more in terms of categorical inferences,

That leads you to the discrete case.

So like chess, the moves in the board are discrete in time.

There's like a click of time.

Anywhere that there's a click of time, discrete time is usually appropriate.

Where there's a flow or an unfolding of time, then the continuous time models are specialized on this.

And then as they point out, you can make hybrid models.

So a really common example of a hybrid model has at the lower or the sensory motor level, continuous models, and then at the higher cognitive level, something more discreet.

But that question about time sets up all of the work itself.

And this is where

really the iterated modeling comes out so we're dealing with this robot and um we're going to make a discrete time model because it's a digital computer and so this discrete formulation represents well how this robot works we could zoom out and make a continuous time model with a person or we can zoom in and um

make a continuous model for some sensor or actuator, but just at the robot level, think about discrete time.

So then that just sets up really the canvas for all of these questions.

What are the generative models most appropriate variables and priors?

Which parts are fixed and what must be learned?

If anyone wants to add anything, please raise your hand or give a thought.

But there's little else we can say.

This is the work itself of the modeling after you've kind of unrolled the canvas and decided that we're going to be talking about discrete time model.

These are all of the real modeling questions that basically take you from

I'm interested in a robot and I'm going to do a discrete time model all the way on through a description of a system that's necessary and sufficient for understanding its behavior.

Does anyone have like thoughts or ideas on this?


SPEAKER_00:
Sorry, the last thing you said, you were muted there for a second.

just does anyone have a thought or question on this well i think it's it's pretty interesting uh one thing that stuck out to me not from the textbook but from listening to the last panel in the symposium was what burt devries was talking about you know needing to be able to scale

HAB-Jacques Juilland, models according like say for an autonomous let's say the robot is an autonomous.

HAB-Jacques Juilland, self driving car and.

HAB-Jacques Juilland, It needs to be able to to calculate with a different degree of precision, whether it's driving you know straight down a freeway or going around a roundabout.

HAB-Jacques Juilland, And so I guess would that be an example of you know, trying to build a. HAB-Jacques Juilland, hybrid you know, a hybrid model that.

based off that circumstances is following a different route in that pathway in the tree?


SPEAKER_01:
Is that appropriate?

It's a great connection.

We're in the room talking about the generative model of the self-driving car.

Now we're thinking about two possible ways we could go.

We could have a fixed precision model or we could have a variable precision model.

Even if somebody doesn't have a lot of background in modeling, it's pretty clear what the strengths and weaknesses would be.

Well, in the fixed precision model, it's simpler.

And if you fix it at an adequate frequency or precision, it might work totally fine.

okay and what do you get with a variable precision model well you have this hyper parameter which is like how variable or how should i change how i change the precision so it's not like you've answered the last mile by saying we'll make it variable precision you could imagine a variable precision model that just adds hyper parameters that don't make it a more effective robot

or take up a huge amount more computational resources.

So that's exactly the conversation about which features of the model do we want to combine?

Yes, please, Jesse.


SPEAKER_00:
Could you give an example of, like, in that case, what would be an example of a hyperparameter that you might program in?


SPEAKER_01:
Yeah, in that specific case, the hyperparameter

So the parameter itself would be how precise.

The fixed parameter model would just say precision level 10.

You could think of that as the function y equals 10.

It's just a static line.

And then the hyperparameter would now say, well, let's do inference on what that precision parameter should be.

And you might say, I'm going to draw precisions from a distribution that has this and that shape.

Do you want to draw precisions?

So let's just say the fixed example is 10.

Do we want to draw our precisions from 10 plus or minus 2 or 10 plus or minus 8?

Or do we want to sweep between 10 and 100?

Whatever strategy you take in a Bayesian setting is like the hyperprior.

That's you kind of surveying out or mapping out another space that you explore the parameters of the distribution on.

And the double-edged sword is almost always, quite literally, hyperparameters are more expressive and they can fit situations better.

However, they introduce compounding exponential search spaces.

So if you just have to do something, you could get into a lot of recursive, especially in cognitive modeling, a lot of recursive possibilities that are like way past the point of diminishing return of being relevant.

Bayesian model selection is a principled way to understand how many parameters to include in a model and so on.

So there are methods to address this question of how many parameters should we have?

How meta do we have to go?

And those are exactly the kinds of evaluative criteria that would come into play.

Again, we're in the room talking about the two different generative models, fixed precision, variable precision, or time horizon of three and time horizon of 12.

Are we getting a better model period with a longer time horizon?

Is it worth it?

Those are exactly the kinds of questions that come into like model evaluation.

So it'd be like the cooking evaluation stage.

Here's the recipe and the questions that you ask when you're the chef preparing this recipe.

And then there could be another chapter on how do you evaluate cuisine in general or for some specific genre?

Yeah, Jesse.


SPEAKER_00:
Um, with the limiting variable on that generally be computational power, or just just uninterpretable results both great great suggestions.


SPEAKER_01:
Yeah, in principle.

you can always add more hyper parameters.

You might be making a bigger search space and just sifting through a progressively larger space to find little needles in the haystack.

And then exactly the second piece, which is like the interpretability and AI interpretability and all these things are very important.

And sometimes a parameter can be constructed to have a certain semantics or interpretability.

Other times there are parameters that you could kind of describe, but parameters don't need to necessarily be interpretable.

However, one of the cool things about active inference, especially because we're taking such a hands-on approach to building these generative models, is we can design interpretable systems.

And that's something that Ines Hippolito and colleagues have recently explored in a little bit more detail as well.

But it's exactly that approach

interpretability, that we're like, in the farmers market boutique generative model construction workshop here, talking about what's the game plan for how we're going to make this artisan dinner.

That's kind of where chapter six sits.


SPEAKER_00:
And maybe if at some point you could put in the chat, maybe a link to like a paper in respect to the interpreted, what you were just saying via interpretability or maybe in the textbook, in the CODA.


SPEAKER_01:
Oh yeah, I'll add it to this page.


SPEAKER_00:
I see you right here.


SPEAKER_01:
But yeah, I'll add it to the page.

Totally good call.

All right, thank you.

Yeah, from June.

Oh, no, it's good.

I mean, this is like we want to be hands on with the models so that we can understand them.

And this is the textbook shows some simple settings.

So from earlier in the book, we had the frog that did or didn't jump out of the person's hand or the object that was in their hands that did or didn't jump.

And that was a kind of case study in passive inference.

The person's just holding the object, it jumps or it doesn't, and then they're gonna update their beliefs about whether it's a frog or an apple.

So that brings up a lot of important topics like Bayesian belief updating and learning, surprise, Bayesian surprise, sensor fusion, multimodal inference, but it's passive.

In the second half of the book,

a kind of canonical active inference setting is going to be the rat in the tea maze.

That's a setting where the world doesn't just happen to the animal.

It's like its actions matter for what sensory stimuli it gets.

And so this example of like a tea maze, where there's something that's rewarding or preferred at the ends or either or both end, and then there's something informational at the bottom of the tea maze,

that's kind of like a minimal model system for active inference because it captures different things that you might want to emphasize, like the value of information or habit, all these different features.

So these are kind of like pedagogical or toy examples that are very graspable and very small scale models.

And then in the literature, you see more like medium to large scale models, or really more in the small to medium space.

And then in applications, you might see large scale models.

From the research and development side, oftentimes people are just like, I introduced a new motif and made a small scale model that demonstrates the motif.

And then they move on developing motifs.

because if you can develop the motif and make it rock solid in a small case that's actually clearer and more preferable and then people can introduce that motif into medium and large scale models a lot more to say about modeling but but yeah anyone can like give a thought or a question about modeling


SPEAKER_00:
Hal Hallstein, yeah I guess in that respect i'm just curious about.

Hal Hallstein, You know model switching.

Hal Hallstein, And if there.

Hal Hallstein, I guess, are the if there's master models that can determine when to switch between models in a given you know, based off updating.

Hal Hallstein, You know, updating either a belief system or or essentially learning your environment learning and environmental circumstance.


SPEAKER_01:
yeah a lot to say on that um let's look at figure 4.3 this is our Rosetta Stone figure on the top is the discrete time generative model on the bottoms the continuous time generative model they're being positioned provocatively

to highlight their structural similarities.

There's the downstairs part that looks like an E, and that's like the passive part going through time.

And then on the top part and upstairs of each, there's the policy selection.

action policy selections being treated a little bit differently between these two settings and what the world is is treated differently between the two settings in the discrete time setting we have a past present and a future time point that emit observations and then you have policies that intervene into how the world changes through time and thus which observations it emits

But in the discrete time setting, you have a past, a present, and a future.

And you could have it look 100 time steps in the past and one in the future or none in the past and 100 in the future.

Those are the kinds of parameters that the modeler plays with.

Whereas in the continuous time model, you have only the present.

And then you have derivatives of the present, like the first, second, third derivative that reflect how the present is changing through time.

So we have like the car's location is at location 100 and it's going 10 miles per hour.

So that means at the next time point, we expect it to be at 110.

Now, if we said, well, it's at 100 and its speed is 10 and its acceleration is one,

So then it's going to get to a little bit more than 110 by the next time point in continuous time, but you're all at every moment you can like recheck the flow.

Okay, so you asked about model switching.

So let's look ahead a bit to figure 8.6.

So here, the upstairs part is a discrete model.

We know we're in the discrete setting because we have like the past, present, and future.

So that's the discrete time, partially observable Markov decision process.

And then coming out of each observation, we have like another little figure 4.3.

And it's the bottom part of figure 4.3 with the continuous time model.

So you could compose discrete on discrete, continuous on continuous, and so on.

But in this case, let's think about model switching.

There's a world where there's two possibilities.

Either the weight is 5 pounds or the weight is 50 pounds.

And so you have some belief before anything else happens about how likely is it to be 5 versus 50.

And then there's a descending expectation, like I'm in five, that then is going to set a policy on the sensory motor model.

And so you could imagine that if you expected five,

then it was five or if you expected 50 and it was 50 it would be not surprising that's like when the step is at the distance that you expect the step to be those are like literally the things that we don't attend to when our descending predictions are accurate however if there was a mismatch there's a prediction error that some that it was heavier than you thought

that would update your belief at the higher level in the way you'd expect and vice versa.

So descending predictions, one example or one way we could think about those is like, those are the models that you can switch over.

And then that sets the top down expectation, which includes action policies, because we're not just expecting sensory data, we're expecting ourselves to do things.

That's why we select the most likely thing.

Because the top down expectations are over the sense and the action.

And then

when what we get back from the ascending levels is what we expect it's the least surprising which means that we had the most model evidence the prediction error was lowest the surprise was lowest the free energy was lowest things are good the ball is on the bottom of the hill and then as sensory feedback diverges you have more surprise

That means the ball is not on the bottom of the bowl.

There's a higher free energy and so on.


SPEAKER_00:
Sorry.

Yeah.

In that respect, could you consider prediction error almost as like a thermostat for model switching?

Where


SPEAKER_01:
could be used as such if you made the model that had that kind of a feature or or attribute then it literally would be if you didn't it wouldn't be and this is what and that's what carl friston and others sometimes call a deflationary account which is like deflating all the hot air out of the account and just ending up with the lean

distilled you know if and only if necessary and sufficient whole truth nothing but the truth status that's the deflationary account is like well I made a cognitive model where ascending prediction errors are used as a cue for model switching then the deed is done but until the generative models on the table the discussion is very speculative

It's like until you have on the table, the linear regression, connecting smoking and cancer, you might have a super strong anecdotal belief.

You might have a strong prior, but if you're just speculating, especially if you think, well, depending on how you include covariates, it's not so simple before you make the model, even for very large effect phenomena in the world, which is why statistics is a process and why it matters.

So chapter six shows us the recipe and is like, hey, there is a bright line between like the recipe talking about the food and having the food on the plate in front of you.

The recipe is how you get from being like, I would like to have this dish to a dish.

Your version of the dish isn't necessarily going to look like food channel status, but it will be what you did do.

And so that is really the clear line between ultra speculative hypotheticals.

Like what does active inference say about attention?

There's not even a system of interest in that sentence.

Realistically, that's not even a complete question because you could, depending on the system of interest, do any number of things, just too many to even say in one sentence.

but we have a recipe and a process that actually works towards giving a deflationary account.

So here is one case where Michael Karl, I believe, we looked a little bit about like translation and eye gaze.

So humans translating, that could even be understood as a translation or switching behavior.

Great point that several have raised, like the steps in the recipe don't need to be sequential or separate.

So in a way, these are kind of like, these are everything you need to think about when you want to serve dinner.

But depending on different people's kitchen and setup, like they might do one thing before another.

Now there's some things that you might suffer if you do one before the other, but there's other things where the order doesn't really matter, but just in a book or in a verbal speech, you have to present one in front of another.

But just because things are,

presented in a order doesn't mean that that's like from most to least important or least to most important, any of that.

So these are like just questions that we ask ourself as part of the iterated modeling process.

And they're big questions that aren't going away.

And none of them are too simple to speed over.

What system are we modeling?

Well, it's like, is it going to be the robot and the niche?

But then where do you go with the niche?

Does that include the power plant?

I mean, where do you really develop these reasonable bounds?

And that's, again, to give a deflationary account.

It's like, what is this model for?

So you can never, even from the very outset, disentangle the generative model from it being specifically constructed by a team in a place where

And that's like a kind of radical scientific inactivism, perhaps, or scientific realism.

And again, it's really fascinating how there is a clear line between generative model on the table, maybe limping along, maybe simple,

but generative model on the table exhibiting simulated behavior being used to process data and then we have like the space of the cognitive so productive but that's the conversation around the dinner table and if all the chefs walk away from the table and there's no food on the table maybe it was just a conversation group but

If the business plan was to produce a certain kind of food with reliability, then just speculating about variants to the recipe wouldn't have gotten you there.

then there's a lot of just big topics that come up repeatedly like having multiple time scales of inference and like real systems are happening all scales all times at once and this is a fact that's often pointed to for example with biological systems but for a given system of interest or phenomena of interest there may be some spatial temporal scales that are more relevant to model

Like if we're simulating eye movement behavior, if we make something that is iterating every picosecond, we're just way oversampling.

And so there'd be a lot of boring time steps and then there'd be some shocking time steps and we would have like a really...

inadequate model.

Conversely, if we were to grain over hours, then we would think there was nothing interesting about gaze behavior because it ended up being just kind of sampled, looking no different than an inanimate gas particle.

But then there's certain observations, certain scales of interest that have these rich cognitive dynamics.

And the meaning isn't just simply like out there ready for us to pick it up.

it's actually in the co-construction of the model and in the analysis and the unfolding of a system of interest.

One other useful figure from chapter nine, they described this as the meta-Bayesian perspective.

here we have figure 4.3 in the center generative model discrete time generative model past present future so this is going to be the subjective model which is to say that of the subject of the experiment and then a little bit more philosophically or metaphysically the subjective model

could be that which is subjectively experienced.

But putting that aside, Anil, not sure if you're actually here or not, but it'd be very cool if you were.

This model is of the experimental subject.

And then here we're out in the room now.

So inside was the rat in the maze.

That's our experimental subject.

But then from the perspective of the researcher, the subject is the object and the behavior that it emits is objective behavior.

So just like if we were doing an animal behavior experiment, you'd have like, well, what does the animal know?

What is its input stimuli and what actions can it do?

What are its affordances?

So that's like the system of interest.

And then now what else is in the room?

And then if you can develop that thin wrapper around your system of interest, you have the minimal benefit.

set up to have something on the table and maybe it's good enough with just that first framing or maybe you want to go way way way deeper in a certain way or you want to explore some other cognitive phenomena but broadly just connecting it to behavioral sciences and just like looking at like what is the animal under observation and its cognitive model

And then what's the thin wrapper around that that helps bring a closure to this encounter so that we can get a grasp on it?


SPEAKER_03:
Ajith?

I didn't have a question.


SPEAKER_01:
Okay.

So I think it's super cool because a lot of these conversations aren't necessarily active inference specific.

Spatial and temporal scale system of interest, identification, um, positioning of your model, multimotor sensor fusion.

Um, like in certain ways, the active inference part in chapter six, it's like, that's the work again.

All the part that gets us to the kitchen are general modeling commentaries.

And then we have the specific work itself, which is setting up the generative model.

And then they just have a very, very brief section 6.7, which gets revisited in chapter nine about interfacing data to these generative models.

So there's a lot of ways to go in this chapter is like the recipe for it.

What are anyone's thoughts or questions on this?


SPEAKER_03:
yeah so i was wondering like i know like in the active inference institute they have a lot of projects and sort of uh github repositories where they show examples of using these to model like cognitive agents and things like that but i was wondering like does this textbook itself have sort of maybe like a github repo with examples of sort of them using these recipes or things like that


SPEAKER_01:
um great great question very important question in appendix C they do provide some matlab code we have our own repo for the textbook so like we might just want to bring that code in and also develop other examples like I would love to see

the chef and the sous chef and, and the client, everyone's notes and just everyone's thoughts about like what could be developed.

A lot of times people pick really ambitious systems of interest to model.

And that can be like daunting because these are, you can go arbitrarily sophisticated cognitive modeling and three humbling

and often seen as like not the real work to build these simpler pedagogical examples to get a feel for these models by hand and like kind of start with the lighter weights basically so that people can develop an intuition for these different tools and skills and practices um

seeing examples is helpful especially really simple ones seeing complex examples may actually not give the kind of information that people are always looking for because for really well-built examples the kernel is kind of lost in the specifics so if you have something that's taking in these five different kinds of sensors and doing this kind of a planning on this kind it's like

the real essence of active inference is spread across thousands of lines of code.

And then you have to abstract away from those five different sensors and specific action setting to kind of reconstruct what?

Your own

carrying on board sense of active inference.

So the small and the medium models are really important.

And then that helps you scope whether a large scale model is even possible.

So don't be discouraged.

Yeah, that the large scale model is not in hand.

That, um, you know, that you're not a factory kitchen today.

Because you got curious about the cuisine of cooking.

Maybe we can have a whole restaurant analogy thread.


SPEAKER_00:
Well, I got an analogy for you on that to go off topic a little bit.

But out here, there's like tons of prickly pears.

They probably have them up in Davis too.

They're right there right now.

So I just went and collected like a whole bucket full and I've been making like juice from it.

But my hands are just so full of thorns.

same way with active inference i'm trying to just make a cup of juice and i have like got thorns all over my body now that's funny yeah


SPEAKER_01:
just just like right at the very beginning we're discussing like chapter six I feel like chapter one and chapter 10 are great entry points into the um theory in the context of active inference chapter six is like the sort of doing out because chapter six grounds the fulcrum of this book in a almost boringly inactive framework

That's the deflationary angle.

And it's the real work of building the generative model.

Not everyone's going to build every generative model, but it's super exciting that the bright line exists, that the culinary sector exists, and that actually dancing amongst different metaphors and systems of interests, we're able to have the conversations we want to have.

So like for systems design,

these questions from chapter six these are things maybe you don't call it a generative model or generative process but like what are you interested in what matters to you about it what phenomena do you think are relevant like

Those are questions that everyone can be addressing.

And then to bring those questions and awarenesses legibly into a modeling process that can have the integrity of all other engineering, it's super exciting.

And it's what, among other things, differentiates academic from being just like a hot take or like a kind of mic drop.

It's like, yeah, chapters one, two, three, four, five.

The mic is dropped repeatedly.

And then what do we do?


SPEAKER_00:
Cool.


SPEAKER_01:
Well, we're in the game now.

Cohort four, we're back.

we out there we back um we'll continue in chapter six earlier times uh slot next week and we'll be in the game and and let's think about how we can kind of curate and improve our niche for future cohorts also maybe develop along the weeks if someone has like a system of interest that they want to kind of develop out and play with different features of like if you had a system of interest robot

and you kind of answered the four questions the recipe and then in week uh three and four in chapter seven you explored the discrete time model and then in the next weeks we explored a continuous time feature of the model and then in chapter nine you thought about how data comes into play and in chapter 10 recontextualized you know you'd have a transformative understanding and trail of work

for a very limited amount of time regarding your system of interest so if you choose something that cares uh that you care about then that kind of work sequence should be as meaningful as anything could be what time is the earlier time um uh it will be uh it's at 13 UTC all right 13.

And I feel like there's going to be some time zone changes or something like that, or daylight savings or something.

But yeah, it's all on the calendar.

It's all also written here.

So thank you all.

I hope that you have a great rest of your day.


SPEAKER_00:
Thank you.

Likewise.

Thank you so much, Daniel.


SPEAKER_01:
Yeah.

Peace.

Bye.