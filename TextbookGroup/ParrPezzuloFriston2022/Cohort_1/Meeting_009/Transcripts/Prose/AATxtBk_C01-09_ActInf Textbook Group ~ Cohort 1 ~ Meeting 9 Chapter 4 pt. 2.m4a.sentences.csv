start	end	sentNum	speaker	confidence	text
250	1920	1	A	0.63	Of these questions.
3410	6720	2	A	1.0	I think we talked about the oh, this is chapter two.
7650	9360	3	A	0.99781	Let's go to chapter four.
10370	16960	4	A	0.99684	Okay, so we talked about belief, policy, state.
17810	20320	5	A	0.96975	I'm not sure if we talked about this question.
21730	32630	6	A	0.99987	In the discussion of active inference in POMDP t belief updating about policies, we find that the posterior that minimizes the free energy does the posterior at time t.
32700	34120	7	A	0.73	Oh, we did discuss this.
34810	37080	8	A	0.82296	Yeah, we did discuss this last time.
37470	49834	9	A	0.99356	So this question, I think we did not discuss pi being a policy or a model last time.
49872	50860	10	A	1.0	Or did we?
51230	53200	11	A	1.0	I think we didn't get to this.
53650	55614	12	B	0.99915	Yeah, I don't think we discussed that.
55732	61786	13	A	0.97196	All right, so we can open it up and we'll start here, I guess, with the most upvoted.
61898	64874	14	A	0.99939	So the question reads, what is pi?
64922	75118	15	A	0.99745	On page 69, the authors write, at each time step, the current state is conditionally dependent on the state at the previous time and on the policy pi currently being pursued.
75214	87250	16	A	0.99669	Then on page 71, they write, thus we can interpret the priors of equation 4.6 combined with the likelihood of equation 4.5 as expressing a model pi of a behavioral sequence.
87330	89414	17	A	0.89611	So which is it, policy or model?
89612	92918	18	A	0.61	And then they suggest a rewrite of the sentence.
93014	109230	19	A	0.99998	They say that, thus we can interpret the priors of equation 4.6 combined with the likelihood of equation 4.5 and the transition probabilities b sub tau pi as expressing a model for a behavioral sequence where the model is a function of policy pi.
110610	113854	20	A	1.0	And then there's some discourse here.
114052	121700	21	A	0.88099	So in this reframing, can we say that the model simulates the agent in the environment as if it had taken the actions in the policy?
123430	127400	22	A	0.78	And I don't know who asked that question.
129530	130694	23	A	0.83	Oh, Eric, that was you.
130732	131880	24	A	0.8338	That was your question.
132410	137078	25	A	1.0	And then does anyone want to maybe take a stab at answering that question?
137164	139900	26	A	0.84	Or we can continue reading what was written here.
142990	155258	27	A	0.9787	So what's written here says that on page 69, the authors also say policies here may be thought of as indexing alternative trajectories or sequences of actions that could be followed.
155354	162906	28	A	0.99846	On page 71, they define the likelihood in equation four five as a matrix A that expresses the probability of an outcome.
163018	174402	29	A	1.0	They describe the priors of equation 4.6 as the prior over the initial state vector D, and beliefs about how the state at one time transitions to the state at the next time, matrix B.
174456	178914	30	A	1.0	And they also say that the transitions are conditionally dependent on the policy chosen.
179042	188230	31	A	1.0	Because of this conditional dependence, we can see how the policy influences the model and why the authors may use the terms interchangeably.
192990	203290	32	A	0.98963	So does anyone have any comments there's?
204850	225798	33	C	0.82	I guess I would say that that answer in discourse kind of agrees with what I proposed, which is that strictly speaking, we should treat the pi as policy, but it behaves as a model.
225884	228354	34	C	0.9998	Once it's executed, it's implemented.
228482	237970	35	C	0.99993	Then the model has become a function of the policy that's been we've seen so far.
238140	244646	36	C	0.99207	So I'd say that's compatible interpretation.
244758	258682	37	C	0.99962	So I think strictly speaking, it would be better if the text was consistent and called Pi policy and then say, yeah, the model is a function of Pi.
258826	260990	38	C	0.56507	That'd be my interpretation.
262370	263874	39	A	0.7683	Yeah, I definitely agree with that.
263912	278360	40	A	0.55	I think that the model is policy specific, but they could do a better job of I mean, the variables as we've seen are so ambiguous anyway, so it could definitely be a lot better.
284180	309044	41	B	0.71	And by the way, about the topic of consistency, actually I gave some thoughts about the issue we were discussing in yesterday's math learning session and I also consulted some other papers and active inference and in all of them the notation for matrices and vectors is used consistently, as in almost every linear algebra textbook.
309172	324792	42	B	0.99988	So I'm seriously beginning to suspect that every instance of a matrix or a vector not written in Bold face is a typo either in chapters or appendices because otherwise I really cannot find any justification behind using two different types of notation.
324936	333570	43	B	0.9999	So I'm going to use this assumption as my prior for the rest of the book, unless someone has any belief updating observation she wants to share.
336740	346416	44	A	0.7898	So just to summarize, for the people that weren't there yesterday, we had a big debate about what does the Bold typeface signify?
346608	352272	45	A	0.56	And it wasn't so much a debate, but just like trying to come to a mutual understanding.
352336	353588	46	A	0.99996	So it's this question here.
353674	359604	47	A	0.99999	Does bold lettering mean this is a matrix, but seemingly also many non bold letters are a matrix?
359652	365080	48	A	1.0	Or does bold lettering mean sufficient statistics of as on these page examples?
365580	386320	49	A	0.95	And it really was yeah, we couldn't come to a single unified answer there because there are many instances where it seems like it should be a matrix, but it's not bold and there are many instances where sufficient statistics are used but it's also not bold.
386900	391068	50	A	0.6139	So yeah, we couldn't really conclude that, but I think I'll lead it.
391094	393590	51	A	0.93764	That's a good assumption there.
412470	418434	52	A	0.60748	So we also talked about this a little bit last time, but we didn't really get fully into this question.
418552	422694	53	A	1.0	What is the use of categorical distributions in equation 4.5?
422812	428402	54	A	0.83	The second line is supposed to explain the cat notation, but I have problems to understand the advantage of the notation.
428546	431480	55	A	0.57767	Could someone explain it in simple words?
432190	434986	56	A	0.9999	Does anyone want to try to explain that?
435088	436490	57	A	1.0	I can pull up the equation.
443600	452960	58	B	0.99905	Well, I think every regular matrix and vector is by definition an array of ordered elements.
453620	461840	59	B	0.99953	But in a categorical distribution we don't necessarily assign any specific order to the elements.
461920	480280	60	B	0.99981	So the reason behind using the categorical distribution might be to just jettison any orderness in the elements and treat them as just an unordered set of the probabilities.
482880	499870	61	C	1.0	I wrote an answer to this one if you want to pull that up, so you can just read that's.
517460	519200	62	C	0.99581	So I hope this is helpful.
521540	533190	63	C	0.75489	It's basically the way I see it is you have the math, the math notation there, but when you need to actually implement that, you need to carry it out, then you need to turn that into operations you can perform.
533720	548404	64	C	0.95	And so when you say that A is this categorical object, that means that you're turning it into an actual matrix with elements.
548532	564510	65	C	1.0	And so the ordering is important, actually, because the ordering of the elements in the matrix says how that matrix is going to apply to the objects it applies to, which are the belief state S, and then your observation O.
565280	580100	66	C	0.66802	So basically it says the way you carry out inferring what O will be the probability of O given a belief state is you do a matrix multiply.
582200	605292	67	C	0.67	And because in this example, the states are not continuous, they're categorical, then you need a categorical matrix element in order to do map from the categories of belief states to the categories of observation states.
605346	610780	68	C	1.0	And those are both distributions that gets transformed by the matrix.
613600	616660	69	A	0.50666	Thanks, Eric, that was super helpful.
616840	620770	70	A	0.78716	Does anybody have any further question or comment on this one?
625310	630658	71	B	0.99997	Sorry, Eric, but isn't the categorical notation special case of multinomial distribution?
630774	636270	72	B	0.9738	Categorical distribution special cases of multinomial distribution?
639090	640160	73	B	0.97	I don't know that.
641810	669526	74	B	0.69978	Yeah, because that was my understanding that the main difference between any categorical distribution and well, I mean, for instance, of course you're right that in any matrix we necessarily have some ordered elements in order for us to be able to compute the math on those matrices.
669718	691754	75	B	0.9997	But on the other hand, for categorical distributions, at least that was my understanding that we don't necessarily treat them as ordered elements, such as, I don't know, the ordered vectors or ordered matrices as the normal matrix.
691802	702542	76	B	1.0	Because if that was the case, well, we could just designate this distribution as just a regular matrix.
702606	703074	77	B	1.0	Right.
703192	718886	78	B	0.92993	So I don't get what's the reason behind using the notation here, cat A or cat, instead of just using the.
718908	720230	79	D	0.94	Name of the matrix?
723150	726220	80	A	0.59967	Steven, can you mute you're super loud over there.
739450	740200	81	A	0.99831	Sorry.
742970	744840	82	C	0.99799	Yeah, I guess so.
748170	750326	83	C	1.0	The mathematical notation doesn't have an ordering.
750358	757766	84	C	0.99923	It just says distribution is related to another distribution through this relation.
757878	762414	85	C	0.98	And when you get to the mechanics of how do you do that?
762452	766826	86	C	0.90397	That's where you care that you have the matrix with the vector ordering.
766938	775940	87	C	0.99712	So, yeah, I don't know what cat A actually means other than it's just describing it.
777030	780500	88	C	0.99	I don't think it's like an operator, I think it's just saying what it is.
780950	782180	89	C	0.72503	Does that make sense?
793790	796480	90	A	0.58009	Steven, if you're trying to talk, we can't hear.
798770	799520	91	D	0.53766	What.
815860	825510	92	A	0.99	I feel like Steven is trying to share an idea with us, but is unable to communicate effectively through the technological affordances he's been given at the time.
826440	837160	93	C	0.73913	Like the gain on your mic is way up or something, so it's picking up more background noise than you're.
882020	884124	94	A	0.99922	Just looking at this equation.
884252	885810	95	A	0.99986	Can you guys hear me okay?
893560	894068	96	A	0.60117	Yeah.
894154	924030	97	A	0.99846	Okay, so just looking at this equation, the second part, it's like the, it's like an ordered matrix A-I-J where the probability of the observations are equal to index I and the states equal to index j, something like that.
925680	929100	98	A	0.98	I don't know, it looks like it is ordered.
930260	932880	99	B	0.91983	Yeah, the matrix itself is ordered.
933460	933920	100	A	0.99809	Yeah.
933990	940370	101	A	0.99	And so the second line is actually by how the authors are defining this cat A.
940980	944580	102	A	0.65192	So cat A represents this ordered matrix AIG?
946920	953780	103	A	0.99606	Yeah, that's at least what it says in the textbook.
978190	989680	104	A	0.92183	So it says the likelihood expressing the probability of observations conditioned on time tau given states s conditioned on time tau is equal to the categorical distribution A.
1005990	1006594	105	B	0.99496	Sorry.
1006712	1008962	106	B	0.90752	Yaku, go ahead.
1009016	1015094	107	E	0.9998	Sorry, my internet is lagging a bit, so there might be a delay and I might break off.
1015132	1027322	108	E	0.99999	But I just want to comment that I think that the cat notation is really just to reinforce the notion that it's in discrete time.
1027376	1043760	109	E	1.0	But I think it's kind of redundant in this case because since we know that we are in discrete time, we could have just written a bolt to signify that it's a matrix and where it's a matrix, it's probably not going to be a continuous distribution anyway.
1045890	1051330	110	E	0.99927	So I think cat bold A and bold A is pretty much interchangeable.
1055470	1064714	111	A	0.89914	So I think that some of the new math is using some of the affordances from category theory more like some of the newer things.
1064752	1082882	112	A	0.78	And I think the forward direction that Karl and Thomas and some of the people that really helped derive and advance some of this math, I think that they're going to be leveraging category theory methods like the renormalization group and the pullback attractor more in the future.
1082936	1090674	113	A	0.99	And so that might be also part of the reason that they are moving toward this categorical notation.
1090802	1094760	114	A	0.98391	So just a little maybe foreshadowing there too.
1100810	1106010	115	B	0.69	May I just make one additional note about this categorical distribution?
1106590	1125578	116	B	0.52315	Well, the thing that confused me about this concept of categorical distribution is the Wikipedia's definition of it, because here it says there is no innate underlying ordering of these outcomes, but numerical labels are often attached for convenience in describing the distribution.
1125754	1128290	117	B	0.99958	So that was my confusion.
1135940	1144944	118	A	0.97	I don't think it would be the first time that we've seen traditional mathematical notation slightly and somewhat abused in active inference.
1145072	1146900	119	A	0.99974	Probably also won't be the last.
1147050	1154580	120	A	0.70479	But definitely I think it's a point that we can put forward to the authors for additional clarification.
1157020	1166490	121	A	0.99706	If there's no further anybody has anything else to say about the categorical distributions here, if not, we can move on to maybe the next question.
1175470	1187710	122	A	0.99344	So this next question reads in message passing, is there a decay of information as the distance between the variable X and individual Markov blanket constituents increases?
1188130	1190522	123	A	0.9998	Is implementation of information decay?
1190586	1195390	124	A	0.97029	In message passing an option for model implementation?
1195810	1201380	125	A	0.72	I think that this is a super interesting question and it's something that I've thought about before a lot.
1202710	1210530	126	A	0.74209	But I think, yeah, let me open it up to anyone and see if they want to address it before we can get into some of the discourse.
1215750	1224294	127	C	0.98599	Well, doesn't that all depend upon the chain of loss between one stage of the message passing and another?
1224332	1227846	128	C	1.0	And if you have no loss, then you don't have any decay.
1228038	1237470	129	C	0.99997	But the more stages you have where you get a little bit of diffusion or loss, then you're going to have decay, just a function of the parameters.
1238210	1248606	130	A	0.93206	Well, so are messages passed within the same Markov blanket or between things that are partitioned with their own Markov blanket?
1248638	1249860	131	A	0.99995	That's another question.
1264640	1269420	132	B	1.0	I also agree with Eric, as I mentioned yesterday.
1270580	1304200	133	B	0.91	I also believe that, well, this information loss is not accounted for at least inherently in active inference formalism because it depends on the specific situations that those information propagate because otherwise we couldn't have any general or all encompassing formalism for accounting for these information loss.
1307580	1316984	134	A	0.99857	So we see in this box they talk about Markov blankets and the message passing.
1317032	1319272	135	A	0.99988	So here is variational message passing.
1319336	1328608	136	A	1.0	This involves messages from all constituents of the Markov blanket of X, including the parents via the conditional probability of X given its parents and the children.
1328774	1334464	137	A	1.0	The latter depends on the conditional probability of the children of X given all of their parents, which include X.
1334582	1343190	138	A	0.9999	Note the expectation includes the children and parents of the children as parents of the children x, we divide by Q of X to ensure the expectation includes the blanket only.
1344600	1352452	139	A	0.98808	So I think the messages are like all of the things inside of the blanket, send a message to something else in another blanket.
1352516	1357844	140	A	1.0	At least that's how I interpret this way of active inference.
1357892	1370788	141	A	1.0	And so it would make sense that from within the blanket, does everyone have the same is there like a high degree of mutual information shared in the Markov blanket?
1370904	1382028	142	A	0.99	I think conditional dependence is what qualifies as conditional independence is what establishes the markup blanket.
1382124	1387268	143	A	0.52808	So within constituents under the blanket, do they all have all of the same information all of the time?
1387354	1389990	144	A	0.84639	That's something that's kind of confusing to me.
1391320	1424588	145	C	1.0	One thing I'd point out about figure 4.3, so in the previous chapters we have this picture of there being the world and your model of the world and your model of the world is a Markov blanket itself and it interfaces with the world through the observation variables and the action variables.
1424764	1426828	146	C	1.0	This picture doesn't have that breakdown.
1426924	1431616	147	C	0.99999	So it's got state there, but it doesn't say is that state all internal state?
1431718	1434624	148	C	0.99996	Is it external state or a mixture of them?
1434662	1447190	149	C	1.0	And it apparently is mixture because you've got policy that can affect state, which means that you're going to have action, is going to be part of the state transition as well as and then you have the observations coming out the bottom.
1448200	1462412	150	C	0.99929	But I think if we're going to talk about Markov blankets, then I would like to see this picture be exploded into the state of the machine versus the state of the external world and how those interact with one another.
1462466	1464140	151	C	1.0	Because that's what the markup blanket does.
1464210	1466190	152	C	0.99902	Is it compartmentalizes the information?
1472930	1485858	153	A	0.69366	Well, that is the POMDP model and Figure 4.3 and this really Figure 4.4 makes me scratch my head quite a bit.
1485944	1494770	154	A	0.75	This is the image that is going to represent message passing in a Bayesian framework.
1494930	1505100	155	A	1.0	And so the caption says on the right dependencies between different variables in the belief updating scheme outlined in the main text.
1505870	1515840	156	A	0.99739	Intuitively, current beliefs about states under each policy at each time are compared with those that would be predicted given beliefs about states at other times, this is one.
1516930	1520378	157	A	0.63	And current outcomes to calculate prediction errors.
1520474	1524320	158	A	0.99999	These errors then drive updating and beliefs, this is two.
1524930	1530418	159	A	0.98617	Given beliefs about states under each policy we can then calculate the gradients of the expected free energy.
1530504	1531700	160	A	1.0	This is three.
1533350	1538022	161	A	0.99996	These are combined with the outcomes predicted under each policy omitted from the figure.
1538076	1541320	162	A	1.0	To compute beliefs about policies, this is four.
1542410	1548674	163	A	1.0	And then using a Bayesian model average, we can then compute posterior beliefs about states averaged over policies.
1548802	1549960	164	A	1.0	This is five.
1555050	1557590	165	A	0.99	And this kind of leads us into the next question.
1557660	1563566	166	A	0.99854	But I am not able to really interpret this Figure 4.4 in any better way.
1563668	1571440	167	A	0.98178	So if anybody has like a plain English description of how this works, I would love to hear it.
1588300	1607836	168	A	0.94775	We can talk a little bit about a question that was raised about this figure and also about this squiggle sigma because there's a great I don't know, we kind of had a hard time figuring out the equation and the squiggle sigma and what that actually stands for.
1607938	1614076	169	A	0.99996	So we could move to that discussion because I think it's maybe related to this message passing discussion.
1614108	1621570	170	A	1.0	But let's read the discourse here first on the message passing question.
1624280	1631728	171	A	0.9777	So in the discourse, what is the mechanism for signal decay?
1631824	1636352	172	A	0.99787	So this is information decay, implementation of information decay.
1636496	1645130	173	A	0.9941	Is the message a thing behaving as an active inference agent itself or a special piece of information not behaving as an active inference system itself?
1645660	1648276	174	A	1.0	Is there a blanket impedance mismatch?
1648308	1649804	175	A	0.92	I think Brock contributed this.
1649842	1651310	176	A	0.99375	I'm not sure if he's here today.
1651840	1660872	177	A	1.0	And then message passing as described through active inference usually is a hierarchy, not a lateral transfer like within constituents in the blanket.
1660936	1663736	178	A	0.99974	So the key thing here is how you define the markup blanket.
1663848	1671964	179	A	0.99998	Either there's a partition between particles, cells or whatever, or there's no partition in blanket and everything under the blanket is conditionally dependent.
1672092	1675148	180	A	0.99997	Does conditional dependence preclude message passing?
1675244	1677744	181	A	0.61534	Our message passed within nodes in the same blanket.
1677792	1681232	182	A	1.0	I have not seen this and would love if someone pointed me to some references.
1681376	1682596	183	A	0.67537	So that was me.
1682618	1688628	184	A	1.0	I wrote the last part because I haven't seen message passing under the same Markov blanket.
1688644	1696410	185	A	0.9604	It's always been like from one Markov blanket partitioned object to a different Markov blanket partitioned object.
1698460	1702380	186	A	0.79845	But that moves us into if anybody has any comments, feel free.
1702450	1705064	187	C	0.88367	Well, I would say message passing is used to do the inference.
1705112	1707100	188	C	0.99995	So it's within a markup blanket.
1707920	1713330	189	C	0.80607	That's pretty common, I think the way message passes is used.
1715460	1725456	190	A	0.99834	So here, as it's shown in Figure 4.4, although this is totally beyond me to describe here, this is a temporal message passing.
1725488	1744484	191	A	0.99996	So it's like from one time point to another time point and then on the left it depicts the hierarchical, like a hierarchical expansion collapsing over time steps but that a higher level network might predict the states and policies at the lower level and use these to draw inferences about the context in which these occur.
1744612	1759816	192	A	0.99356	So the way that I've always seen the message passing used is from one time point to another or from one layer of a hierarchy to the next layer of a hierarchy and I've not seen it passed within constituents under the same Markov blanket.
1759848	1772544	193	A	0.99998	So Eric, if you have references that depict some kind of message passing in active inference that's not through time steps or through hierarchical levels, I would love to see that because I have not seen it.
1772662	1781028	194	C	0.73113	Well, I would just go back to box 4.1 where they talk about the variational message passing and how you get information.
1781194	1794196	195	C	0.99	And I would say within a blanket you've got various nodes and they have this hierarchical parent child relations and in order to do inference about, hey, what's our belief in one of these parents?
1794308	1799130	196	C	0.51	You got to kind of go up and down and say well, what are the children of that and what do the other parents think?
1799580	1810228	197	C	0.99977	So that's all within a single Markov blanket, the parents and children, the hierarchical relation and the message passing happens to circulate that information within the blanket.
1810424	1812050	198	C	0.76517	That's how I read.
1815380	1835916	199	B	1.0	And I also put a link here to a paper by Champion at all in which they have actually explicitly defined the active inference, or better say, reformulated the active inference formalism according to variation of message passing.
1836048	1847400	200	B	1.0	And if you just give me a second, I can find exactly the place where they have stated this in plain English.
1868700	1875372	201	B	0.96	You can continue with the other questions if you like, but I need a moment to check this paper.
1875506	1878348	202	A	0.82094	Sure, yeah, I'll check it out also and yeah, thank you for that.
1878434	1885216	203	A	0.72528	So like when I'm reading this variational message passing, this involves messages from all constituents of the Markov blanket of X.
1885318	1890930	204	A	0.99977	So the message is coming from all the constituents in the blanket, but it doesn't say where the message is going.
1891380	1908360	205	A	0.97419	So it does make sense, I guess, that it's an interchangeable or within would be a better word than from within all constituents of the Markov blanket because I was reading it as like the message is coming from everything under that blanket, which I guess is an incorrect interpretation.
1912490	1916040	206	A	0.99675	So thank you Eric for pointing that out because I was like what?
1930380	1935916	207	A	0.99594	So this is a really hard question that I looked to try to answer.
1936098	1938412	208	A	0.58645	Actually a bunch of us looked yesterday a lot.
1938546	1954560	209	A	0.9991	So it says in equation four point ten, the sigma variable, squiggle sigma, we'll call it whatever, I'm not sure how to say it is used to describe the difference between the natural log of observations conditioned on policy and preferences.
1954900	1956716	210	A	1.0	What is the function of this variable?
1956828	1967408	211	A	0.99999	It also comes up in figure 4.4, the message passing figure we're just looking at, and it would be great to have a verbal description of this figure, what other papers or equations use this squiggle sigma?
1967504	1975352	212	A	0.5	And we looked at length, like through the entire textbook, through the other chapters it refers to like we'll unpack this later in chapter seven.
1975406	1981336	213	A	0.99999	We looked through chapter seven, we looked through the appendices, we saw a variable that almost looks like that, but I think it's a gamma.
1981368	1988204	214	A	0.90902	It looks like a little bit more fancy than this squiggle sigma and could not find that at all.
1988322	1992016	215	A	0.99949	So we went to unpack equation 410.
1992018	2002050	216	A	0.92	And so here is the equation itself.
2004500	2011780	217	A	0.49709	I'm not sure how to pull this up next to the actually maybe I'll put it up here, 419.
2015000	2023064	218	A	0.77	And this equation four point ten is a rewriting of equation 4.7 in linear algebraic form.
2023262	2027432	219	A	0.92552	So we tried to kind of unpack this a little bit.
2027486	2032632	220	A	0.99958	So the first line states the prior probability for each policy.
2032766	2040590	221	A	1.0	This is that pi sub zero is equal to the soft maps function sigma times the negative expected free energy G.
2041920	2043584	222	A	0.99	And so that's this first line.
2043702	2065860	223	A	1.0	The next line is the expected free energy conditioned on policy g sub pi is equal to the entropy or negative expected log probability h times the states conditioned on policy and time, which is S sub pi times tau or both of those sub pi and tau plus the observations conditioned on policy and time.
2065930	2076404	224	A	1.0	This O sub pi times tau times the beliefs conditioned on policy and time, which is a squiggle sigma maybe sub pi times tau.
2076532	2079656	225	A	0.83349	So we were kind of unsure if beliefs is correct here.
2079758	2085228	226	A	0.92619	We kind of pulled that out of the legend for figure 4.4.
2085394	2104284	227	A	0.99989	But if anybody knows, and just to maybe unpack that a little bit more, the beliefs conditioned on policy and time, the squiggle sigma, sub pi times tau is equal to the difference between the observations conditioned on policy and time o sub pi times tau and preferences conditioned on time C sub pi or sub tau.
2104332	2107110	228	A	0.99791	So we were unsure if belief is correct here also.
2108360	2121240	229	A	0.53	And so if anybody knows if beliefs is the difference between observations and preferences, that would be great to have some kind of feedback or input here because we couldn't really reach a conclusion.
2159770	2173610	230	C	0.99751	Well, I guess one tiny step toward figuring this out, I would say, is that that funny squiggle thing there has to do with the C.
2173760	2185550	231	C	0.33647	We've got, we've got this probability of observations given C and C is this mysterious object that expresses preferences which has also been under explained.
2186690	2213362	232	C	0.84316	So if you look at the two terms of the expected free energy G as a function of functional policy in 4.7, and then look at how it looks like in four point ten, that sigma thing there, we've got the dot, which I guess is a multiplier by observation.
2213426	2218214	233	C	0.99867	So that's the same as that's like saying your probability of observation given C.
2218252	2231500	234	C	0.79558	So that's, I guess, a matrix multiplier version of this log probability of sequence of observations given your preference prior C.
2250490	2252246	235	A	0.67365	Yeah, so they do unpack.
2252278	2266182	236	A	0.80694	It a little bit more in equation 4.7 or it seems to be like maybe we could extrapolate from 4.7 if this is beliefs, because it is this natural log of observations minus the natural log of preferences.
2266266	2291110	237	A	0.91666	But up in the top that just the free energy is the entropy or maybe the dot product of the entropy times the states plus the observations times or the dot product of the observations and maybe beliefs here I can't recall a mathematical representation of belief ever using this squiggle sigma before.
2291180	2305710	238	A	0.97	And I looked through the recent Ryan Smith paper and I looked even at the message passing paper by Friston and I was not able to really get any additional references to this squiggle sigma at all.
2305780	2308430	239	C	0.95954	So why do you say belief as opposed to preferences?
2308930	2326580	240	A	0.94464	Well, so it says here that the squiggle sigma is equal to the difference between the natural log of the observations conditioned on policy and time and the natural log of the preferences at a certain time.
2327030	2333830	241	A	0.99208	So the sigma is defined by the natural log of the preferences, but it's more than just the preferences.
2334170	2335014	242	A	0.99976	Does that make sense?
2335052	2335670	243	A	0.99014	Eric?
2336170	2339800	244	C	0.78688	Yeah, but that's not claim as belief, right?
2340170	2343740	245	C	0.91834	That's observations versus preferences, right.
2345630	2353450	246	D	0.99719	From expected deviation or how much risk is being taken relative to the policy that's applied.
2356290	2368442	247	D	0.98	The dot product is between the observation and that wiggle sigma, right, which is in turn like, okay, this is what I've observed, this is what I expected.
2368506	2371170	248	D	0.99986	So it's like a divergence between two.
2371320	2378820	249	D	0.99994	So how much more risk am I taking and how far is this pushing me away from my free from minimizing free energy?
2381030	2382420	250	D	0.9997	So maybe it's something.
2384650	2389720	251	C	0.99995	Whereas belief is wrapped up in the s because that's your model of the world.
2392510	2396886	252	A	0.9761	So risk is maybe how the squiggle sigma is defined.
2396918	2401814	253	A	0.99845	But then if you look into this figure 4.4 like that's, that's why we used belief.
2401942	2404800	254	A	0.99269	So here, let's, let's I'll, I'll pull it up right now.
2428990	2432620	255	A	0.99062	So I'm not sure how easy this is to see.
2433150	2447934	256	A	0.99767	But before we get to number one here, we have like on the right hand side the second to lowest level is states conditioned on policy and time.
2447972	2449694	257	A	0.88	I think I'm going to read it off this bigger screen.
2449812	2450190	258	A	0.79058	Yeah.
2450260	2452986	259	A	1.0	States conditioned on policy and time at different time steps.
2453018	2459540	260	A	0.99855	So like the current time is in the middle, the forward time step is on the right and the backward time step is on the left.
2460310	2462580	261	A	0.95	And so that's what we start with.
2463210	2474200	262	A	0.40564	So intuitively, current beliefs about states under each policy at each time are compared with those that would be predicted given beliefs about states at other times.
2475370	2484214	263	A	0.9546	So maybe beliefs is this f and that's kind of what Eric was saying because it's defined earlier.
2484262	2488378	264	A	1.0	This epsilon here is a prediction error, right?
2488464	2494074	265	A	0.9523	So what we come to after step one, it says and current outcomes to calculate prediction errors.
2494122	2496640	266	A	0.99426	That's what we arrive at after number one.
2497250	2500154	267	A	1.0	The errors then drive updating in the beliefs.
2500202	2500974	268	A	0.99993	That's number two.
2501012	2512100	269	A	0.94903	So here we go from the current state at the present time to a prediction error that drives the belief updating at this forward time step after number two.
2512790	2521000	270	A	0.8	And then it says given beliefs about states under each policy, we can then calculate the gradients of expected free energy.
2521450	2522294	271	A	0.97	Three.
2522492	2526130	272	A	0.71627	So what gives us this gradient of expected free energy?
2526220	2530842	273	A	0.98349	Is it this s sub tau plus one?
2530896	2532118	274	A	1.0	Or is that a tau?
2532214	2533530	275	A	1.0	I think that's a tau.
2535150	2535900	276	A	0.55527	Yeah.
2536510	2539674	277	A	0.98757	So is it a future state not conditioned on policy?
2539792	2542506	278	A	1.0	Or here we get to this squiggle sigma.
2542618	2547120	279	A	0.9948	So it's a squiggle sigma conditioned on policy and time plus one.
2547650	2552578	280	A	0.99917	So it looks like a belief update there, which is why belief made sense.
2552744	2554670	281	A	0.99775	So is that a risk update?
2554750	2559540	282	A	0.99999	Is that a possible interpretation there in this message passing figure?
2565590	2585050	283	C	0.99928	Well, they say it's a gradient, which means it's saying how much do we have to change our policy, I think in order to get our objectives yeah.
2585120	2586860	284	D	0.9996	Gradient makes sense to me.
2587790	2591020	285	D	0.88032	It's how much information you've gained, right?
2592530	2604020	286	D	0.99545	So if you actually look at the change in the state with respect to so I apply some force, or let's just take a simple example.
2604390	2615350	287	D	0.89464	If you have an actuator that just applies force and all it does is it moves forward and has to follow a trajectory.
2615690	2620118	288	D	0.96476	So the error is at each time step.
2620204	2625334	289	D	0.99987	If it's a deterministic system, you expect it to follow a straight line and it's deviating up way.
2625372	2626726	290	D	0.99922	So that's epsilon.
2626918	2632746	291	D	0.99986	So you have to update, okay, this is how far up I am from the state that I'm supposed to be.
2632768	2639390	292	D	0.99999	So I need to apply slightly less force or maybe force in a different direction.
2643650	2650402	293	D	0.90115	It's also how much I have to overcorrect in the future depending on what I've done currently, right?
2650456	2662870	294	D	0.83018	It's not just if I've applied some force right now, I might deviate in the opposite direction and I have to come back, so I have to figure out how much force to apply.
2662940	2666182	295	D	0.97095	So that's why I said risk or.
2666236	2674694	296	D	0.67555	Yeah, gradient, you would have to take the change with respect to the state change with respect to the error.
2674822	2677914	297	D	0.99322	So yeah, that would be one interpretation of it.
2677952	2683740	298	D	0.9	Right, so it's a gradient of the state change with respect to what you have done.
2686210	2690160	299	A	0.84078	So I also heard the term information gain in there.
2690770	2693614	300	D	0.90329	Yeah, I'm just generally saying.
2693652	2705490	301	D	0.6693	So in neural networks, for example, we would have some sort of loss function and we would calculate the weight change with respect to the change of the loss function.
2705560	2705746	302	D	0.91	Right.
2705768	2715842	303	D	0.93713	So, like, I have a weight vector and then this particular example is giving me a certain amount of gradient and I need to minimize this gradient.
2715906	2723918	304	D	0.99994	So I need to change the weights in turn so the gradient actually interfaces between this loss function and all these weights.
2724114	2731562	305	D	0.99714	So effectively, the gradient passes on information as to how much the weight has to change in order to minimize that loss function.
2731616	2732780	306	D	0.99988	That's why I said information.
2736450	2751410	307	B	0.99	And also, as a side note, I think I found this sigma in Ryan Smith's paper too, and it is defined as the expected prediction error.
2753510	2759038	308	A	0.84643	So the expected prediction error versus the actual prediction error.
2759214	2764738	309	A	0.93	And they distinguish it from epsilon in the Ryan Smith paper because I did look at that, but I didn't find it in there.
2764824	2771810	310	B	0.9992	Yeah, it's in equation 27 under the section outcome prediction errors.
2772950	2787520	311	C	0.23	You it may be that the expected means it's an expectation over the Q distribution, which is your distribution over belief states.
2808590	2809900	312	A	0.99765	Yeah, that's great.
2811390	2822846	313	A	0.47655	Ali and I and some others worked on this yesterday a lot and it's great that it kept you up late at night, clearly, Ali, so you went digging around for some more information.
2822948	2823870	314	A	0.68483	That's awesome.
2824020	2824750	315	A	0.99106	Yeah, great.
2824820	2825662	316	A	0.9937	Okay, perfect.
2825796	2828240	317	A	0.98358	Well, that resolves that very well.
2829570	2832580	318	A	0.96	And then let's get into maybe the next question.
2845530	2849814	319	A	0.68152	In equation 4.16, the X has a dot over.
2849852	2854040	320	A	0.99928	It changed through time but not the Y data.
2854970	2858780	321	A	0.957	So there's some discourse on this.
2860270	2863478	322	A	0.93	Or maybe we should go to the next question, actually, because it's maybe more related.
2863574	2870320	323	A	0.98958	So, Figure 4.6 uses an epsilon for prediction error as described in equation 4.21.
2870770	2883890	324	A	0.99998	Is this predictive processing framing a part of the active inference model or is this presented for contrast to illustrate the similarities and differences between active inference and predictive processing?
2884390	2891938	325	A	0.99823	So this is equation 4.1 and this is the epsilon, but I think we see it way before equation 4.21.
2892024	2893062	326	A	0.96701	Like it's even there.
2893116	2907698	327	A	0.99998	In equation 4.4, it says this predictive coding schema is part of the active inference model illustrating the hierarchical structure of predictions and beliefs.
2907794	2916886	328	A	1.0	The authors say one way to think about this is as if we had equipped a predictive coding scheme with classical reflex arcs at the lowest level of the hierarchy.
2916918	2923802	329	A	1.0	And they give this reference in this setting, active inference is just predictive coding plus reflex arcs.
2923946	2925934	330	A	1.0	Does anybody know what a reflex arc is?
2925972	2930962	331	A	0.53	Because I'm a little bit lost with respect to that or have any comments on this prediction area?
2931016	2939250	332	B	0.71011	Yeah, reflex arc is basically the stimuli that doesn't go through the sensory cortex.
2950000	2952640	333	A	0.99	I thought it was like a mathematical construct.
2959510	2961780	334	C	0.99998	Maybe you think of it as a control system.
2963590	2964386	335	C	0.99998	No thinking.
2964488	2967250	336	C	0.2634	It's just like you bang your knee.
2967750	2969140	337	A	0.44976	Your foot goes up.
2970490	2971382	338	A	0.99957	That makes sense.
2971436	2974978	339	A	1.0	And it says, we minimize free energy through action.
2975074	2979606	340	A	1.0	And the only part of the free energy that depends on action is the lowest level of prediction error.
2979638	2987660	341	A	1.0	In this hierarchical schema, action fulfills descending predictions by minimizing the error between the predicted and observed sensory data.
2999540	3004500	342	A	0.99999	Any additional comments here about predictive coding and active inference?
3024190	3026806	343	A	0.77	Or we can look at this equation 4.16.
3026838	3027994	344	A	0.59	The x has the dot over.
3028032	3030474	345	A	0.99465	It changed through time, but not the y data.
3030672	3032080	346	A	0.62	Y is this.
3034290	3043890	347	A	0.93	And here the discourse says, the top equation depends on f of x and v, which is a deterministic function describing how a hidden state changes over time.
3044040	3050482	348	A	1.0	The bottom equation depends on g of x and v, which describes how data are generated from a single hidden state.
3050616	3053142	349	A	0.52	The tilde indicates change through time.
3053196	3056150	350	A	1.0	The dot indicates the first order derivative.
3061690	3065900	351	A	0.99714	Any comments here on this equation or your question?
3100790	3103666	352	A	0.93535	Maybe we can ask one more question, or maybe a couple more.
3103768	3113554	353	A	0.99579	So here it says on page 63, it says specifically, the Bayesian brain helps us frame the problems that an agent engaging in active inference must solve broadly.
3113602	3119030	354	A	0.99999	These are the problem of inferring states of the world perception and inferring a course of action planning.
3119190	3125642	355	A	0.99969	Other than perception and action planning, are there other tasks or challenges that the brain or organisms engage in?
3125776	3127100	356	A	0.99995	How would we know?
3128590	3132480	357	A	0.9806	There's no discourse here, but let's open it up and see what you guys think.
3153730	3158800	358	C	0.96567	Yeah, people wonder, hey, what's on that star out there?
3159810	3160990	359	C	0.58417	That's neither?
3161670	3162514	360	C	0.95	I don't know.
3162632	3163954	361	C	0.96962	Is that inferring State of the world?
3163992	3165634	362	C	0.86	I guess not.
3165672	3166530	363	C	0.99971	Planning.
3169610	3173430	364	D	0.78	And it could just be a hallucination of generative model.
3173500	3177720	365	D	0.94612	You're not really measuring anything, you're just measuring yourself over and over again.
3179050	3180600	366	D	0.99994	That could be one thing.
3199690	3206262	367	A	0.55736	Okay, so here there's another question for each of the graphical models in Figure 4.2.
3206316	3210090	368	A	0.99996	What is an intuitive example for each structure?
3230040	3232580	369	D	0.75	One would be disease diagnosis.
3233500	3239800	370	D	0.99719	So you have symptom that is causative or predictive of some condition.
3248550	3251620	371	A	0.7	I think that was the example that they gave in the text, right?
3254630	3257140	372	A	0.8	Or did we talk about this last week maybe?
3262250	3270520	373	B	0.70953	Yeah, I actually don't get the question because each of them we have an example, at least an example in the text.
3280310	3281540	374	A	0.98234	Yeah, that's true.
3285300	3289490	375	A	0.51	And I think we're going to maybe see more examples as we go through the book.
3300580	3316360	376	B	0.98767	But just in case, if anyone wants to see some more examples actually, that paper, I put the link in the chat, realizing Active Inference in Variation Message Passing contains some more examples for each of these diagrams.
3322640	3324140	377	A	1.0	This is a fun last question.
3324210	3340028	378	A	0.59599	Maybe it says this reiterates that active inference uses two constructs, variational free energy and expected free energy, which are mathematically related but play distinct and complementary roles.
3340124	3344980	379	A	0.99976	In your own words, what are the definitions of variational free energy and expected free energy?
3345050	3349540	380	A	1.0	And what role do they play individually or together in active inference?
3365890	3372562	381	D	0.99454	My view of expected free energy was given a certain action that might be taken.
3372616	3384440	382	D	0.66299	It might produce this or reduce the free energy or something, or it talks about some future reduction on free energy or something like that.
3384810	3387970	383	D	0.54627	Variational free energy is more objective.
3388130	3389800	384	D	0.83	I don't know how to put it.
3391470	3396860	385	D	0.60799	It's like, okay, actual kinetic energy versus perceived kinetic energy kind of thing.
3398670	3412766	386	D	0.99952	So if you're rolling down a hill, like rolling down a hill, we can actually measure the kinetic energy at the bottom of the hill, right?
3412948	3425380	387	D	0.55245	If you put the ball at the top, expected free energy would be like using a model to calculate that and then finding out actually corresponds if you look the model.
3425750	3427220	388	D	0.67	At least that's my view.
3439070	3439806	389	A	0.8343	So I don't know.
3439828	3445262	390	A	0.83612	I'm probably like I think about this in a lot of different ways, but I think about variational free energy.
3445316	3460610	391	A	1.0	I mean, this is one way to think about it, is maximizing the trade off between epistemic value and pragmatic value right now and expected for free energy is like maximizing that difference at some point in the future.
3460680	3462840	392	A	0.99998	So you can plan ahead.
3463370	3469800	393	A	0.9997	It might be cold out, so I'm going to take a jacket or like it's cold right now, I'm going to put my jacket on.
3472170	3475206	394	A	0.99967	That's how I think about the difference between those two.
3475388	3476518	395	A	0.9965	So it's ten.
3476604	3477782	396	A	0.99998	Thanks, everyone, for coming.
3477836	3481142	397	A	1.0	I hope I didn't muddle this up too much.
3481276	3485950	398	A	0.99998	Trying to be substitute teacher for Daniel, and it's ten.
3486020	3488222	399	A	0.99971	So we're going to have tools right now in this room.
3488276	3497710	400	A	0.99998	But if anybody wants to continue discussing these ideas and gather, you're welcome to migrate up to one of the different spaces.
3498850	3502140	401	A	0.88723	Yeah, and I think we'll stop the recording now, Alex, if you haven't already.
