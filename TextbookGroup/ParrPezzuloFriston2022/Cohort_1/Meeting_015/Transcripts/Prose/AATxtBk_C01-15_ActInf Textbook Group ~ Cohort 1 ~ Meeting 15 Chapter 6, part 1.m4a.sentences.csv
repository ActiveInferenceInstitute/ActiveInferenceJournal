start	end	sentNum	speaker	confidence	text
810	2286	1	A	0.38	All right, greetings everyone.
2468	5822	2	A	1.0	It is September 9, 2022.
5876	12318	3	A	0.9922	It's the 15th meeting for Cohort one and we are discussing chapter six.
12404	17870	4	A	0.69381	We're in the first of two discussions on chapter six of the textbook.
19410	30614	5	A	0.99904	We're going to go to the questions page and start there where we have one question that we explored a bit last week in our welcome back.
30812	39370	6	A	1.0	And then there's at least one question prepared, but anyone is welcome to add more questions here while we turn first to this question.
39440	44060	7	A	0.98922	What are the four steps in the recipe to construct an active inference model?
53740	60060	8	A	0.99	And can we make templates that facilitate people walking through some of these stages?
70940	78410	9	A	0.99907	How much model building do people prefer to be engaged in in this section of the textbook group?
79260	84940	10	A	0.77932	Do people want to have one or more model that they're personally developing?
86480	96572	11	A	0.98807	Do they want those to be scaffolded in a shared page to help increment models along and see models at different stages?
96636	98210	12	A	0.9559	Yeah, Brock and anyone else?
99940	105196	13	B	0.99633	It's the same problem as, like, the first half of the textbook without math.
105388	106850	14	C	0.99796	It'S not going to go well.
107320	113108	15	B	0.99	This half without modeling, it's going to be quite difficult, I think.
113194	121670	16	B	0.97545	So I think we should just get that out of the way that it's not about whether you want to or not or whatever.
122440	126984	17	B	0.87763	If you want to just understand it at a cursory, philosophical, perhaps level, then maybe not.
127022	129448	18	C	0.99999	But if you actually want to understand it, then, yeah, we are going to.
129454	131256	19	B	0.99998	Have to model something some way.
131278	146890	20	B	0.8	It doesn't have to be the most complex, most precise one, but yeah, I wonder if we could develop like maybe a couple examples or simple.
149100	149656	21	A	1.0	Ones that.
149678	151070	22	B	1.0	People might like to model.
152080	153150	23	B	1.0	I don't know.
154000	156270	24	B	0.99991	Those are all going to be purely agent based.
159220	159970	25	A	0.99977	Thanks.
160420	161330	26	A	1.0	I agree.
161700	166000	27	A	1.0	I wanted to frame it as a question, but I agree with that perspective.
167380	193210	28	A	1.0	And following along as we structure a few specific cases, the rat and the team maze, the icicating which are used in the textbook, then some of the examples that are used recurrently in the literature, like birdsong and a few others.
193980	207256	29	A	1.0	And for these, many scripts exist and helping people who might not have the setup either by with some walkthroughs.
207288	209152	30	A	1.0	Okay, here's how you get octave running.
209206	220480	31	A	0.99998	So you can do this MATLAB script or here's the standalone dem demo because this textbook really only gives the pointer to MATLAB scripts and methods.
220900	229540	32	A	0.83976	Like when they say that the standard schemes can be applied, they mean a MATLAB script.
229880	235930	33	A	1.0	And that's exactly what the step by step guide model stream one is built around.
237340	247208	34	A	1.0	And chapter seven on modeling in discrete time is going to be akin to the step by step guide.
247384	250990	35	A	0.99999	But it's not step by step by step by step.
251360	254540	36	A	0.91592	It's more like it takes two bigger steps.
256480	282272	37	A	1.0	Okay, how is this four step recipe for active inference modeling similar or different than approaches that people have seen for systems modeling from other frameworks, for example, in a reinforcement learning or cybernetic modeling.
282336	291800	38	A	0.99988	So something more recent and computational or something more pre formal or computational.
294220	298780	39	A	0.99706	Should this recipe be surprising to people coming from a certain background?
302200	304532	40	A	0.99997	Are there substeps that are relevant to consider?
304666	305750	41	A	0.48222	Brock yes.
309160	324092	42	B	0.85	I don't have extensive formal modeling experience, but most of the things that I've done for the last half decade entail some form of this.
324146	335150	43	B	1.0	And I don't see how you could model anything without going through these basic questions here.
339380	348364	44	B	0.8	I don't see how this is specific or exclusive or whatever to active inference.
348492	353566	45	B	0.9966	It's a bit ambiguous to me.
353588	357202	46	B	0.96486	How that besides specifically degenerative model, I guess.
357256	357860	47	A	0.97075	But.
359670	361166	48	B	0.99998	Which system are we modeling?
361198	367720	49	C	0.99984	Another way to ask that is what questions are we trying to answer or who?
368730	372854	50	C	0.54	I think Lyle brought this up like, who are you making the model for?
372892	373880	51	C	0.94458	Sort of thing.
378030	405502	52	C	0.99983	Because the same like you were saying just earlier about the particular choice of how you're modeling it is just a choice on that system, and that entails particular kind of hidden states, mark on blanket, et cetera.
405566	420520	53	C	0.99	That may be relevant or may not be, depending on the questions, what you're trying to model, but that arises from those questions, I guess, is what I'm saying.
421850	422550	54	A	0.82879	Thank you.
422620	423430	55	A	0.98582	Ali.
426990	448350	56	D	0.99771	Well, yeah, I just wanted to mention that, referring back to your previous question, I also am currently developing a model, actually an emotion perceiving agent by pretty much closely following those four steps.
449670	458260	57	D	0.9629	But I'm getting some helps in that regard in how to actually implement those four steps in my particular situation.
458710	480662	58	D	0.99908	But on the topic of modeling, well, at a very basic level, we can categorize different approaches to modelings in terms of answering to three different questions the what models, the how models, and the why models.
480806	486914	59	D	1.0	At least that's the kind of approach mostly done in neuroscientific modeling.
487062	502260	60	D	0.99942	So in my opinion, these four steps and this recipe can be applied mostly to the how and the why.
516730	523350	61	D	0.89686	What models are mostly mostly descriptive models.
523930	551780	62	D	0.95362	But when we want to model an agent and self evidencing agent, which behaves as if it infers something about its environment, we have moved beyond just the descriptive stage and we're dealing with the how and probably even the why questions there.
555430	555986	63	A	0.99991	Thanks.
556088	563190	64	A	0.99999	When I hear why, I always think of Tin Bergen's four questions, the four whys, aristotle's four whys.
563610	582118	65	A	0.96425	Why is a subjective modeler's pluralistic playground, and it doesn't lend itself to one specific even type of answer, let alone a framing or a specific parameter combination.
582294	589038	66	A	1.0	And I think that's a huge aspect of the move from like what are systems to how am I going to model the system?
589124	596830	67	A	0.99999	Which is a part of the turn that happens when we start to model is we dispense with absolutism.
597170	617750	68	A	1.0	All of a sudden, these questions about what we're trying to do, our preferences and affordances and constraints and limitations and everything come into play and we might make a portfolio of models that are shining light on different aspects of even the very same phenomena.
618330	627530	69	A	0.9839	So it's kind of like an empirically grounded pluralism and pragmatism when we start to be engaged in real useful modeling.
628030	639626	70	A	0.73	And that is something that I feel that one learns on the field, not necessarily bystanding.
639738	663480	71	A	0.99968	So that's just to say that the modeling is really important, even for philosophical reasons, to say nothing of some of the things that are coming to play in chapter seven and beyond, where it's like, yeah, the C vector has this many entries because why and how many rows and columns does this have?
663850	690800	72	A	0.99983	But once we understand why the rows and the columns and the shapes of these different entities are the way they are, then we just have to use this scaffold to think about certain systems, consider their form at a very structural level, like is it in discrete time or in continuous time and so on.
691250	698400	73	A	1.0	And then we might set up not just one generative model, but again, families of them.
699090	709010	74	A	0.99999	In the future, we hope and expect that active block, for instance, will facilitate us doing parameter sweeps across families of cognitive models and generative models.
709430	726234	75	A	0.99999	But even in this boutique phase of model construction that we're in in current year, one would still say, okay, I want to have one model where it's either acceptable temperature or too hot, and I want to have one with a three state model.
726352	728522	76	A	0.999	Too cold, just right, too hot.
728656	730538	77	A	0.99879	Here's going to be a four stage model.
730704	755940	78	A	0.84	And just being able to specify that, again, instills pluralism through action about how we're modeling a system, which is a philosophical point that it seems like sometimes isn't grasped by those who don't engage in the specific discussions around modeling a system.
758950	763800	79	A	0.99	Okay, so where does Figure 6.1 come into play?
771800	780680	80	A	0.9943	It's a rehearsal of some of the figures we've seen earlier in the book and many, many other places.
781020	783480	81	A	1.0	This is the particular partition.
784140	790284	82	A	1.0	The particle is the internal and the active sensory states.
790402	794364	83	A	0.99995	So internal plus blanket states equals particular states.
794562	796248	84	A	0.55427	Those are the particles.
796344	814630	85	A	0.99406	If we were looking at dust under the microscope, like Brownian Motion was describing, initially the particles were the dust particle, and then the external states were like that, which was not the dust particle partitioning the generative process and the generative model off from each other.
815080	828520	86	A	0.83071	We're dealing in Bayesian mechanics with particular states, with particles, with things that are able to engage in sensory motor type loops.
829660	844140	87	A	1.0	This is just bringing in a few more pieces than that, which is just to call attention to the direction and the existence of the arrows in the work.
844210	848492	88	A	0.99997	How particular is the free energy principle of aguilera at all?
848626	864290	89	A	1.0	And in follow up work, there's discussion around which topologies on this particular partition facilitate or enable which kinds of formal claims to be made.
864760	884970	90	A	1.0	For example, one might find it kind of interesting that sensory states have a bi directional arrow with external states or might find it equally interesting or differently interesting or less interesting that also active states have an arrow pointing back to internal states.
885740	896700	91	A	1.0	And of course the questions that we have raised all along the way of like, okay, let's just say that we're going to model a person's arm.
897840	902690	92	A	0.99991	What are the active states, what are the sensory states?
903220	906656	93	A	0.99999	What does it mean that there's a bi directional arrow connecting them?
906838	911360	94	A	0.99999	Is this the only topology for this particular partition?
911940	926740	95	A	0.99997	Could we have the around the clock model external states influencing sensory, then internal, then active and just going around the clock without any cross talk in the blanket, without any back arrows?
927980	930340	96	A	0.9999	Is that plausible?
930500	932440	97	A	0.99998	Does that change the formalism?
933820	941710	98	A	1.0	On one hand, how could it not change the formalism when it's changing the structure of how variables are related to each other?
943760	963360	99	A	0.83	Or maybe there are formalisms that are actually abstracted away from any topology choice because what is being described are the flows and the gradients on these variables.
964280	966820	100	A	0.99402	But then what are those variables.
980380	980744	101	B	1.0	That.
980782	983364	102	C	0.99971	Just highlights this need for modeling?
983412	985976	103	C	0.99997	But if we just really briefly go.
985998	1004816	104	B	0.99999	Back to that, it's like the fact that there's this bi directional arrow between external states and sensory states is bit confusing in that.
1004998	1015190	105	B	0.99989	Again, the language like well if it is acting on the environment, isn't that an action state or something like this?
1017640	1020144	106	B	0.54326	In what way is it bi directional?
1020272	1031800	107	B	0.90478	So could you not draw that as one arrow going to the sensory state and one arrow from the sensory state back to the environment and then say what functionally does that entail?
1032380	1035588	108	B	1.0	And then you're doing this particular selection.
1035764	1037380	109	C	0.85	Of how you're modeling.
1037460	1038184	110	C	0.99172	Right.
1038382	1040830	111	B	0.99999	But I think you have to do that.
1042880	1047132	112	C	1.0	To understand why that is bi directional there right.
1047266	1052850	113	C	0.62057	In that particular framing of the generative process generate model there right.
1058500	1063532	114	C	0.99789	Which is still to me also slightly nebulous.
1063596	1078792	115	C	0.99921	But I think yeah, just the bi directionality of it between the action and sense states that kind of makes sense almost that you sense your actions and your actions or response to your sense.
1078846	1082440	116	C	1.0	But that's not really what's being done there precisely either.
1082510	1083130	117	C	0.99721	Right.
1087660	1088724	118	B	0.8822	Just explicating.
1088772	1096990	119	B	0.98	That is what we need to separate and explicate what yeah.
1097520	1107410	120	A	0.99984	Another really important question is like this action perception loop is appealed to early and often.
1107860	1116000	121	A	0.5446	It's the first picture in the textbook before the high road and the low road in 1.2 is eleven.
1116520	1131930	122	A	0.99975	We're talking about agents and their interfacing with the niche and we're going to end up calling how we model agents a generative model and we're going to end up calling the niche and the dynamics of the niche and how it's influenced as the generative process.
1132620	1145964	123	A	1.0	And we're going to call the interface between the generative model and the generative process a Markov blanket and it's going to inherit this technical definition from Bayes graphs and we're going to add these variables and we're going to connect them a certain way.
1146162	1150380	124	A	0.73964	But we're talking about the feedback loop with the agent in the niche.
1153700	1156930	125	A	0.62	Oh, so what is this then?
1159380	1163490	126	A	0.99991	Are the observations the sensory states?
1164740	1172180	127	A	0.83	And this isn't just like a low hanging fruit like well then why couldn't we call them?
1172330	1175956	128	A	0.87	I mean, they are called as X and Y.
1176138	1190040	129	A	0.67873	Interestingly in the continuous time formulation and I get it that they're being distinguished here because this is the continuous time POMDP and the discrete time POMDP.
1191840	1197870	130	A	0.60662	But where do we see active states here?
1200320	1201900	131	A	0.99983	We see policies.
1205390	1213740	132	A	0.66331	So are active states along the branch influencing the B matrix how the hidden states change through time?
1215710	1232370	133	A	0.99012	So there may be a very simple trail from this action perception loop framing to the discrete and continuous time POMDPs.
1235110	1257398	134	B	0.9995	Yeah, I think just to me, the simple way instead of thinking of this as a circular thing where you're literally going from one state to the next state to the way you might to in a normal state machine if you're thinking of no when you have an active state, however, it is changing.
1257574	1260794	135	B	1.0	That is necessarily entailing change in the.
1260832	1265526	136	C	0.7053	Sensory external state and the internal states and vice versa.
1265558	1268190	137	C	0.99999	Here with the sensory states like that.
1268340	1270734	138	B	0.99251	If you perform some action of some.
1270772	1273918	139	C	0.99846	Kind, there's some active change in that state.
1274004	1280420	140	C	0.71103	Like you're necessarily changing the internal hidden state, right?
1282870	1295910	141	C	0.98866	If you grab a glass of water or something like this, what you're modeling now has changed slightly, right?
1296060	1317838	142	C	0.9	And your internal states and the sensory states are doing the same thing where the glass of water or whatever was this object just sitting there doing nothing, but now it's become a thing to drink out of.
1318004	1327040	143	C	1.0	And that's changed in some sense the kind of external states that are being fed into your sensory states.
1327810	1334900	144	C	0.99826	It's changed the Markov blanket that you're kind of selecting for or relating to.
1341990	1363754	145	C	0.99	I think that is visibly they're doing the same sort of thing where if you have this observation, you're necessarily creating a new internal or sense state that is going to change your policy selection and that's going to change your sense states.
1363952	1364700	146	C	0.6557	So.
1377670	1412278	147	A	0.72543	Returning to the recipe, one question that I think will reduce our uncertainty about as we really do the modeling is how do we account for residuals and understand which modeling residuals, which is to say variability in data that are not explained by the model, which and what amounts of residuals are acceptable?
1412454	1437170	148	A	0.99996	So if we were doing a linear regression and the only data we had on hand was height, and the only data that we wanted to predict were weight, then we could just say we've used all the data and whether the model fits with an R value of zero one or zero nine, we know what the residual is of height on weight regression.
1437590	1443666	149	A	1.0	And here's a number that describes what fraction of the variability was described with this regression?
1443778	1447510	150	A	0.91	R value of one being like it's all perfectly on a line.
1447660	1451190	151	A	0.8	R value of zero being like it's just a total scatter plot.
1452270	1459594	152	A	0.99996	We can say how much variability is explained and then we're done with the empirical data that we had.
1459712	1475130	153	A	0.99999	So we can't explain any more variability when we're looking at empirical traces of behavior to explain even a small fraction of behavior.
1475210	1481090	154	A	1.0	For some systems, it might be the case that the generative models already must be quite complex.
1482710	1495960	155	A	0.99883	In another scenario, it might be the case that a very simple model like looks to the left are 90% of the time followed by looking to the right.
1496890	1499880	156	A	0.96	I mean on average, isn't that true?
1500890	1516960	157	A	0.99995	So then when we are evaluating models, whether in block, for instance, sweeping across models or just qualitatively or in a boutique way, are we looking to reduce the residual to zero?
1518690	1523200	158	A	0.99999	What traces of data are we looking to explain variability in?
1524690	1562390	159	A	1.0	And then if we're not going to be with empirical traces of behavior looking to reduce our unexplained variance, what is going to be the criteria by which we do model selection on the AIC and the BIC, which are information criteria, balance variability explained across families of models with their degree of parameterization penalizing having more parameters, rewarding better explanations.
1562470	1573742	160	A	0.50551	So seeking to find a balance with models that are on the kind of pareto frontier of explanatory and simple, that's great.
1573796	1575498	161	A	0.8917	That's like one extra nuance.
1575594	1583902	162	A	0.54451	On top of merely explaining more variability with a smaller residual, it also adds in the penalty for having more parameters.
1584046	1599106	163	A	0.95943	So that in theory and in practice stops the modeler from just, okay, well now we're going to add in the temperature in this other part of the world because 1% of the variability just happened to be explained.
1599218	1608460	164	A	0.85823	So now we're just developing these like totally spiraling looking for more and more data sources to explain a decreasing amount of variability that's left.
1608830	1614530	165	A	0.99994	So it's good to pull back from that edge through the use of information criterion.
1614710	1631438	166	A	0.99999	But at the core of the criterion is still the imperative to reduce the residual, to have a model that fits within a model the way that we fine tune it so that it fits data well, but not overfitting.
1631614	1641350	167	A	0.5	And then across models we can see an analogous process of wanting the model structure that fits without, for example, overfitting or over including parameters.
1643930	1666750	168	A	0.99891	So I think one question which might be added here is like what data do we have if we're doing a didactic model and we just want to sketch it out and run a simulation and just purely generate data that might be useful in certain settings.
1667810	1675710	169	A	0.99991	But the question of what behavioral data we have is very nontrivial if we're going to be approaching this as an empirical analysis problem.
1675780	1679780	170	B	0.8248	Brock just another question there.
1684150	1690440	171	C	0.99993	What observations must we make or something is related to what data do we have?
1690890	1698520	172	C	0.99967	If you don't have the data that if there's not sufficient affordance information contained in the data to model the problem, then.
1708720	1717790	173	A	0.99668	Do we have to model our action selection at a second or third order?
1719060	1720610	174	B	0.99583	Yeah, exactly.
1721140	1723410	175	C	1.0	To realize the right epistemic value.
1727220	1741460	176	A	1.0	Okay, so that was figure 61, discrete and continuous, shallow, deep and hierarchical.
1742040	1761070	177	A	0.99991	So just to address this, which might come up shallow versus deep is describing how iterated the model is through time, within one type of time.
1761440	1775136	178	A	0.99841	So you could have the 1 hour shallow model where hours are our units, or you could have the 10 hours where it goes 1234-5678, 910, or you could have 100 depth of 100 with a time click of one.
1775318	1791940	179	A	1.0	Or one could have a hierarchical model where there's 10 hours that make like a deca hour and then there's ten clicks of the deca hour to reach a planning horizon of 100 time steps.
1792380	1821920	180	A	0.98517	So deep is describing within one unit or counter of time how iterated that counter is depth is describing strict hierarchical nesting and so they can both be used separately or together to describe events over longer and longer time horizons.
1823540	1827132	181	A	0.60451	Crucially, this is in the context of language processing.
1827276	1835380	182	A	1.0	The duration of the word transcends that of any phoneme and the sentence transcends that of any word in the sequence.
1835720	1843456	183	A	1.0	And if we assume paragraphs are made of multiple sentences, paragraphs always transcend and encompass sentences.
1843568	1846328	184	A	0.82819	So anyone else want to just add a point?
1846414	1862700	185	A	0.95739	I'm sure that you fellows are familiar with this distinction, but just wanted to point it out since temporality in these models and doing model selection on different forms of temporality is going to be an essential piece of the puzzle.
1869600	1869916	186	A	0.62848	Yeah.
1869938	1882720	187	D	0.92	And it also reminds me of the Shankarian analysis theory that, if you remember, we talked about earlier, and it's hierarchical.
1883960	1917372	188	D	0.56277	It's temporal hierarchy that tries to describe the whole musical piece as a kind of hierarchical layers, which I think maps perfectly into this specific example of language parsing because that also is a kind of thing that should ideally be modeled in a very hierarchical way.
1917506	1931244	189	D	1.0	But the caveat here is unlike language, which is at least in some languages, are necessarily hierarchical, music is at least tonal.
1931292	1941760	190	D	0.99999	Music or even nontonal music are not necessarily they don't necessarily have this hierarchical structure.
1941840	1954440	191	D	0.66889	So depending on the kind of music or the genre of music, we might have either a very shallow and non hierarchical structure or a very deep one.
1954590	1965820	192	D	0.82343	So that's something that I think again refers back to the kind of system we're trying to model.
1965970	1981650	193	D	0.99823	But even that kind of system needs to be more specified in a more granular level in order to have an effective modeling strategy there.
1982980	1985460	194	A	0.99998	Thanks for bringing it in that domain.
1985880	1993296	195	A	0.94	It makes me think of the intro, the chorus, the bridge, the verse.
1993488	2006840	196	A	0.99801	Perhaps these are only in certain genre of music, but analogously and then the measure transcends any beat in the measure with a special case of like a one one time signature or something and so on.
2006990	2018872	197	A	1.0	And then, although language is described in a strictly hierarchical sense, I'm wondering how syntax and grammar actually create kind of a strange loop.
2019016	2031680	198	A	1.0	For example, it's trivial to say that phonemes are nested within words and sentences and so on, but what about the semantics of a sentence that contains commas and exceptions?
2032020	2036630	199	A	1.0	And then at the end the speaker says the previous sentence is not how you think it is.
2037800	2049960	200	A	1.0	That is also causing kind of like a deep linguistic recall that can be trivially modeled as containing nested units.
2051340	2063470	201	A	0.99999	But will a model that narrowly considers the semantics of words, then the semantics of clauses, how will it be able to address some of these questions?
2064800	2071980	202	A	0.99994	Here I think we can point to a really excellent attribute of the active inference modeling framework.
2072580	2087750	203	A	0.99444	So in this discussion where the LW paper was cited, we could just marvel at nested systems and draw blankets on blankets and so on.
2088120	2094512	204	A	0.99998	They could be drawn around every organelle and every little lipid granule in the neurons or the brain regions.
2094576	2100920	205	A	0.53	And so we discussed a little earlier like doing structural model selection on which one of those are relevant.
2102380	2111550	206	A	1.0	However, this does not mean we need to attempt to model the entire brain to develop meaningful pragmatic simulations of a single level.
2112480	2118700	207	A	1.0	For example, if we wanted to focus on word processing, we could address some aspects without having to deal with phoneme processes.
2120720	2129040	208	A	1.0	This means we can treat inputs from parts of the brain drawing inference about phonemes as providing observations from the perspective of word processing areas.
2129940	2144630	209	A	0.99947	So one could say I'm going to make a figure 4.3 where S is the true word and phonemes are being passed as observations to my word inference engine.
2145560	2149236	210	A	1.0	And someone can say but aren't phonemes the result of inference?
2149268	2158010	211	A	1.0	And someone can say great, make that module in blockprints, make that module and pass me that data.
2158940	2179600	212	A	1.0	And then we can do a nested model and we can graft those models together, but through the Markov blanket formalism, not even the whole Markov blanket bounding a specific particular entity, but just the trivial Markov blanket that exists insulating any two unconnected nodes in a base graph.
2180260	2199016	213	A	0.99405	We can use that broader, still technical concept of a Markov blanket and just say all right, phoneium observations come in and surely we could make a model where another type of information comes in and the inference is on phoneme and that's what's passed out.
2199198	2205080	214	A	0.999	So I think again to point to this advantage of active inference modeling.
2205980	2230480	215	A	1.0	It allows us to situate phenomena as complex multiscale nested systems and also bite off what we can chew and makes it an empirical question of how grafting together which different structures might be useful.
2231380	2238950	216	A	0.99999	But we don't need to go all the way like turtles all the way down.
2239720	2242948	217	A	0.99604	We can just say, even if it were turtles all the way down.
2243114	2246020	218	A	0.67992	We're modeling the third through the fifth turtle.
2246360	2253530	219	A	1.0	And the fifth turtle gets a top down prior, and the third turtle gets sensory input from one below it.
2253900	2255940	220	A	1.0	And that's the part of the stack.
2256100	2259640	221	A	0.78	And this is the lateral width that we're modeling.
2264720	2295220	222	A	0.99999	Another advantage of active inference, which not even saying this is a unique advantage, is that this goal directedness and corollary capacities like counterfactuals on goals and the way that counterfactuals on world states influence our goal selection, nested goals and transient goals or conditional goals can be resolved in an unfolding action perception loop.
2296780	2313012	223	A	0.79991	That's something that as this example of like wanting to enter an apartment, of being goal driven over multiple timescales and then being able to again zoom in.
2313086	2314824	224	A	0.99996	So it's like, oh, grab the keys.
2314872	2316664	225	A	1.0	Okay, well here's the key grabbing module.
2316712	2326012	226	A	0.89	And someone says, well, the key grabbing is actually accomplished through this kind of grasping behavior, then that could be modeled.
2326076	2344660	227	A	0.63	Or you can just say we're subsuming finger grasping kinetics in the grasping module because the phenomena that we're trying to explain and the data we have is just about when things were grasped or maybe the only observations we have is when apartments were entered.
2345640	2359060	228	A	0.99856	So we can actually, I expect, frame systems extremely expansively and clarify where we're doing formal modeling.
2372760	2404370	229	B	0.86	I think maybe this is just a philosophical or ontological framing of it, but I don't see how you can model anything well without admitting that it is either incomplete or partially consistent or that there is some hidden state which is probably not included in the model.
2405220	2408784	230	B	1.0	And to me, active inference kind of.
2408822	2417350	231	C	0.9996	Natively has an affordance, at least at the very least a bookmark to do that.
2419400	2425690	232	B	1.0	And so whatever depth or hierarchy you model the system.
2428540	2429528	233	C	0.69004	It'S okay.
2429694	2433480	234	B	0.8655	It's okay that there's still hidden state and it's incomplete.
2434060	2443992	235	B	0.99697	If it sufficiently models answers the question at hand, then you can always add another layer or make the model more complex.
2444136	2447420	236	B	1.0	And that's just what we were going to do anyways.
2449540	2451004	237	A	0.99883	Nice comment.
2451052	2452608	238	A	1.0	I totally agree with that.
2452774	2464950	239	A	0.99986	Again, thinking back to the linear model example, where is that extra information about adjacent possibles for the model?
2466920	2468420	240	A	0.91785	It's unstructured.
2469160	2483930	241	A	0.99525	It's kind of like either the structured information is going to enter your linear regression just so and everything that's outside of your linear regression is we're going to need to go back to the square one.
2484780	2492510	242	A	1.0	If we include a second observable, we're going to have to go to square one and do the model selection all over again and test for all the repeat interactions again.
2493600	2497784	243	A	1.0	But in these multiscale models that we're discussing, like you said, it was a bookmark.
2497832	2508370	244	A	0.99992	It's kind of a nice way to frame it, which is like the phonemes you're bookmarking or leaving an open USB port or something.
2510180	2528120	245	A	0.95457	Anything that outputs a phoneme will plug into that part of the model anything that is able to hear can be plugged in to the frog riveting.
2528780	2534520	246	A	0.99724	Anything that can see can be plugged into the visual component of the frog.
2535580	2558800	247	A	0.51	And so it's almost like consistent with all of this blanket talk, we're being clear about what is modeled formally, and the borders of the formal model are degrees of freedom as formulated to be expanded upon and composed.
2563560	2582484	248	B	0.99	One other, I'm not sure the context is something I heard Ben Gertzel say attributed to Pink Schweight, but Pei Wang that in circular reasoning, when your circle.
2582532	2585000	249	C	0.99749	Gets big enough, it becomes coherent.
2588640	2595884	250	C	0.88655	Maybe another way of saying like, that if your model is insufficient, that if.
2595922	2596510	251	A	1.0	You.
2599200	2623280	252	C	0.80756	Add enough states enough, if you expand your blanket enough, eventually if you're modeling something correctly, I guess the generative process can match your blanket states can can come into alignment.
2628440	2629190	253	A	0.99842	Nice.
2630680	2637300	254	A	0.99948	Some more active inference isms so exteriorceptive proprioceptive, interceptive.
2638620	2646500	255	A	0.92058	We're going to use active inference modeling memory, attention, anticipation, planning as inference.
2646660	2648680	256	A	0.99911	We're going to use active inference.
2649820	2651356	257	A	1.0	That is what it looks like.
2651378	2659100	258	A	1.0	To integrate disparate fields using one model, one family of models.
2663700	2672130	259	A	0.99977	Others can work out some fun ways to communicate and frame it.
2672900	2685892	260	A	0.99999	But I think when people are like, how is this simplifying when it might feel like it's bringing in a lot or even stepping on namespaces that people already have familiarity in?
2685946	2693280	261	A	0.99992	Like we discussed earlier, you could ask, how is memory related to attention?
2694020	2700080	262	A	1.0	Or perhaps more saliently, how will you model how memory is related to attention?
2701780	2705300	263	A	0.99998	Are you going to go on archive and just look for neural network architectures?
2706120	2714180	264	A	0.99949	Are you going to read a book written before computers were invented and look at prose?
2715580	2728430	265	A	0.99979	Are you going to dive into the psychoanalytic tradition or something that's maybe even clinically, biomedical what's the move?
2729920	2751468	266	A	0.53	And active inference addresses that's in these theme of words that people use that mean different things.
2751634	2757040	267	A	1.0	For 400, we have Bay's optimal behavior.
2758500	2760770	268	A	0.9999	Well, then why do things go wrong?
2762500	2764880	269	A	1.0	And there's multiple layers to unpack.
2765220	2775956	270	A	1.0	First is going wrong is about your perspective on how the system, perhaps how you prefer it to be or how you expected it to be.
2776138	2787240	271	A	0.99987	But given where you put the dish when it fell off the table, that was just compatible with gravity.
2787660	2793550	272	A	0.99947	So it was finding its optimal position and fragmentation where you placed it.
2794720	2812800	273	A	1.0	The ball rolled downhill as a consequence of where it was placed and the slope it was on, and framing behavior in that light, we're modeling behavior as rolling to the bottom of a bowl.
2814260	2815212	274	A	0.99704	What's the bowl?
2815276	2815916	275	A	0.99984	What's the ball?
2815948	2816950	276	A	0.99998	Those are the questions.
2817800	2832920	277	A	0.94214	But it's like chemical reactions proceeding under Gibbs free energy minimization when we have policy selection driven by variational and expected free energy minimization.
2835180	2838680	278	A	0.99999	But how can things that go wrong be optimal?
2840620	2846990	279	A	0.8345	Well, it has to do with different parameters in the model, given how they are.
2847840	2849900	280	A	1.0	The model performs optimally.
2850880	2853448	281	A	1.0	That doesn't mean computationally efficiently.
2853624	2872340	282	A	0.99	It doesn't mean adequately, doesn't mean it satisfies, but it may be framed as Bayes optimal fixed and learned behaviors.
2873160	2876630	283	A	0.99	This is going to come into play in chapter seven.
2877160	2897240	284	A	0.99786	There's an amazing continuity in theory and in simple examples with perception and learning, which is to say that perception happens over faster timescales or perceptive like processes happen over faster timescales while learning like processes happen over slower timescales.
2897400	2909072	285	A	1.0	Or even just more generally, perception and learning refer to parametric update processes, and you might even be able to situate the same example both ways.
2909206	2915708	286	A	0.99983	Like if we see a ball move across our visual field, are we perceiving the location of the ball?
2915884	2921780	287	A	0.99997	Are we inferring the location of the ball or are we updating and learning our position of the ball?
2922200	2928820	288	A	1.0	For those with a computational background, learning often equates to parameter updating.
2929340	2934410	289	A	0.92	And so in that sense any kind of dynamical perception is learning.
2935660	2944120	290	A	0.9989	So for some backgrounds the difference between perception and learning will be seamless.
2944480	2948504	291	A	0.87	For other backgrounds, those are going to sound like totally different processes.
2948552	2950124	292	A	1.0	I mean, isn't perception when you see the book?
2950162	2972304	293	A	0.99999	But then learning is like when you understand something about the book and then speaking from a more modeling perspective, here a fixed model or fixing a parameter of a model reduces the model's complexity immensely.
2972352	2982760	294	A	0.53	Or another way to say it taking a fixed parameter and making it learnable introduces multiple hyperparameters.
2984380	2988890	295	A	1.0	And there's no single way to address parameter learning.
2989740	2996568	296	A	1.0	You could say, well, we're doing moving average learning like a column filter or just a simple sliding window.
2996664	2998988	297	A	0.99989	We're taking the average of the last three.
2999154	3002030	298	A	1.0	But now you have to parameter sweep across how many.
3002400	3031960	299	A	0.73	And with a single trial of data, it may not be clear which learning strategy is implemented because especially if we want to differentiate learning strategies empirically, we would want to see like multiple comparable trajectories within and amongst individuals in similar and different contexts.
3032780	3053580	300	A	0.5351	But now our lab has gotten quite big and we're doing quite large model selections even for learning and updating parameters that might just conversationally seem really simple like preferences being updated.
3058510	3072880	301	A	0.98672	So here's this description of when it comes to inference and perception as being fast changes and learning as slower changes, though they're being modeled in a really analogous way.
3074850	3081394	302	A	1.0	It is worth noting in this book we exemplify rather simple generative models that are defined using tabular methods, e.
3081432	3087650	303	A	0.93	G with explicit matrices or tensors for priors and likelihoods in small state spaces.
3089350	3097830	304	A	0.99994	In comparison, more sophisticated GMs are being developed in machine learning, deep learning, robotics, et cetera.
3100950	3120966	305	A	0.59086	So is active inference deep learning okay, good fellow generative, adversarial networks, but with Bengio and Mirza.
3121098	3137990	306	A	0.61524	But are we saying those are formally active inference systems or are we just saying that we can think of it like birdsong conceptually?
3141770	3155450	307	A	1.0	And then are we just adding a wrapper or a descriptor to the gans that our non active colleagues are building is it shining any new epistemic or Pragmatic light on Gans?
3160550	3177160	308	A	0.51	I mean, here's a whole paragraph on Gans behind.
3177530	3179080	309	A	1.0	Oh, that's chapter ten.
3180030	3180940	310	A	0.90703	What happened?
3182190	3184570	311	A	0.99941	But there's still a whole paragraph on Gantz.
3189420	3190730	312	A	0.99959	Did you see that?
3205680	3207070	313	A	0.99644	How did that happen?
3211190	3212050	314	A	0.84641	Whoa.
3217620	3227008	315	B	0.66709	I'm not sure what the optimal way to view a PDF is or that one exists, but I don't think it's the browser.
3227184	3230820	316	C	0.99241	It's not bad, but it's not optimal.
3234200	3239768	317	B	0.80556	I'm interested in, again the generative model.
3239934	3241192	318	B	1.0	Oh, I know what those are.
3241246	3248120	319	B	0.77955	So, generative model and how specifically Gans here an active inference.
3250160	3253310	320	B	0.54509	Is the rectangle a square?
3253920	3256236	321	B	0.63101	Sorry, square rectangle rectangle not a square here.
3256258	3269440	322	B	0.99042	Is that what is being said or is there an indexed blanket here of varying degree?
3270420	3278084	323	A	0.28	Yes, as far as I know.
3278122	3299340	324	A	0.94	And and also you fellows might know like this is being pointed to variational auto encoders and variational Bayesian inference are directly implicated as potentially recursive cortical networks are and world models.
3300720	3318610	325	A	0.99996	But if these bridges can be made solid, like you said, with squares and rectangles so that we can say all some or none of X-R-Y or here's how you project this model to that model.
3319940	3330980	326	A	0.99991	It's going to just break a dam with possibly certain applications of active.
3331880	3359544	327	A	0.99997	Any final comments on six, and I think certainly by two weeks from now, let's look at the SPM implementation and look at some of those that are pointed towards in the book, as well as some of like the epistemic chaining and Pi MDP type models, as well as anything that anyone else builds.
3359592	3361280	328	A	0.96294	So, any final comments?
3363380	3378470	329	D	0.70049	Yeah, I just wanted to point out the recent work by Fields at all, especially the two papers that first and was also the co author of.
3379880	3388648	330	D	1.0	One of their main objectives is to cross that bridge between active inference and VAE via the CCCD system.
3388734	3397512	331	D	0.99953	So that bridge they're talking about in this book is already being investigated to be filled.
3397576	3403950	332	D	0.99676	So yeah, they're pretty interesting developments going in that regard.
3406480	3409340	333	A	0.93	Okay, any last notes before I stop the recording?
3410020	3411250	334	B	0.99998	What is that paper?
3413380	3415564	335	D	0.9529	I'll send you the link from the discord.
3415612	3416400	336	D	1.0	I forgot.
3417700	3419056	337	B	0.99023	Maybe just one.
3419238	3420290	338	B	0.72	I don't know.
3421400	3436330	339	B	0.99771	We haven't trying to make an effort on the code to lay down some basic examples from the first half, but should there be some?
3439180	3447308	340	B	0.95119	If we're going to model stuff, should we have a sub page for that or do put something somewhere in the code of for that?
3447314	3448012	341	B	1.0	I don't know.
3448146	3450700	342	A	0.99995	We've had this code section from the beginning.
3452800	3458236	343	A	0.98656	However, it should be totally modifiable, full control.
3458338	3473030	344	A	0.99988	So however this and anything sub pages need to be modified and the GitHub link to a textbook, anything that people suggests, just let us know.
3480870	3482020	345	A	0.99836	Anything else.
3483910	3484160	346	B	1.0	Okay?
