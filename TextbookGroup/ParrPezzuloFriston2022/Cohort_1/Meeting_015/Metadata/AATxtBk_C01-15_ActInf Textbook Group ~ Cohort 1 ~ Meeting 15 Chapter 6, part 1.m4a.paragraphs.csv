start	end	paragNum	speaker	confidence	startTime	wordCount	text
810	30614	1	A	0.38	00:00	62	All right, greetings everyone. It is September 9, 2022. It's the 15th meeting for Cohort one and we are discussing chapter six. We're in the first of two discussions on chapter six of the textbook. We're going to go to the questions page and start there where we have one question that we explored a bit last week in our welcome back.
30812	44060	2	A	1.0	00:30	38	And then there's at least one question prepared, but anyone is welcome to add more questions here while we turn first to this question. What are the four steps in the recipe to construct an active inference model?
53740	60060	3	A	0.99	00:53	14	And can we make templates that facilitate people walking through some of these stages?
70940	105196	4	A	0.99907	01:10	72	How much model building do people prefer to be engaged in in this section of the textbook group? Do people want to have one or more model that they're personally developing? Do they want those to be scaffolded in a shared page to help increment models along and see models at different stages? Yeah, Brock and anyone else? It's the same problem as, like, the first half of the textbook without math.
105388	129448	5	C	0.99796	01:45	72	It'S not going to go well. This half without modeling, it's going to be quite difficult, I think. So I think we should just get that out of the way that it's not about whether you want to or not or whatever. If you want to just understand it at a cursory, philosophical, perhaps level, then maybe not. But if you actually want to understand it, then, yeah, we are going to.
129454	146890	6	B	0.99998	02:09	32	Have to model something some way. It doesn't have to be the most complex, most precise one, but yeah, I wonder if we could develop like maybe a couple examples or simple.
149100	156270	7	A	1.0	02:29	19	Ones that. People might like to model. I don't know. Those are all going to be purely agent based.
159220	207256	8	A	0.99977	02:39	79	Thanks. I agree. I wanted to frame it as a question, but I agree with that perspective. And following along as we structure a few specific cases, the rat and the team maze, the icicating which are used in the textbook, then some of the examples that are used recurrently in the literature, like birdsong and a few others. And for these, many scripts exist and helping people who might not have the setup either by with some walkthroughs.
207288	247208	9	A	1.0	03:27	83	Okay, here's how you get octave running. So you can do this MATLAB script or here's the standalone dem demo because this textbook really only gives the pointer to MATLAB scripts and methods. Like when they say that the standard schemes can be applied, they mean a MATLAB script. And that's exactly what the step by step guide model stream one is built around. And chapter seven on modeling in discrete time is going to be akin to the step by step guide.
247384	291800	10	A	0.99999	04:07	66	But it's not step by step by step by step. It's more like it takes two bigger steps. Okay, how is this four step recipe for active inference modeling similar or different than approaches that people have seen for systems modeling from other frameworks, for example, in a reinforcement learning or cybernetic modeling. So something more recent and computational or something more pre formal or computational.
294220	298780	11	A	0.99706	04:54	12	Should this recipe be surprising to people coming from a certain background?
302200	305750	12	A	0.99997	05:02	10	Are there substeps that are relevant to consider? Brock yes.
309160	335150	13	B	0.85	05:09	41	I don't have extensive formal modeling experience, but most of the things that I've done for the last half decade entail some form of this. And I don't see how you could model anything without going through these basic questions here.
339380	361166	14	B	0.8	05:39	34	I don't see how this is specific or exclusive or whatever to active inference. It's a bit ambiguous to me. How that besides specifically degenerative model, I guess. But. Which system are we modeling?
361198	373880	15	C	0.99984	06:01	32	Another way to ask that is what questions are we trying to answer or who? I think Lyle brought this up like, who are you making the model for? Sort of thing.
378030	423430	16	C	0.99983	06:18	70	Because the same like you were saying just earlier about the particular choice of how you're modeling it is just a choice on that system, and that entails particular kind of hidden states, mark on blanket, et cetera. That may be relevant or may not be, depending on the questions, what you're trying to model, but that arises from those questions, I guess, is what I'm saying. Thank you. Ali.
426990	502260	17	D	0.99771	07:06	123	Well, yeah, I just wanted to mention that, referring back to your previous question, I also am currently developing a model, actually an emotion perceiving agent by pretty much closely following those four steps. But I'm getting some helps in that regard in how to actually implement those four steps in my particular situation. But on the topic of modeling, well, at a very basic level, we can categorize different approaches to modelings in terms of answering to three different questions the what models, the how models, and the why models. At least that's the kind of approach mostly done in neuroscientific modeling. So in my opinion, these four steps and this recipe can be applied mostly to the how and the why.
516730	551780	18	D	0.89686	08:36	50	What models are mostly mostly descriptive models. But when we want to model an agent and self evidencing agent, which behaves as if it infers something about its environment, we have moved beyond just the descriptive stage and we're dealing with the how and probably even the why questions there.
555430	596830	19	A	0.99991	09:15	90	Thanks. When I hear why, I always think of Tin Bergen's four questions, the four whys, aristotle's four whys. Why is a subjective modeler's pluralistic playground, and it doesn't lend itself to one specific even type of answer, let alone a framing or a specific parameter combination. And I think that's a huge aspect of the move from like what are systems to how am I going to model the system? Which is a part of the turn that happens when we start to model is we dispense with absolutism.
597170	690800	20	A	1.0	09:57	194	All of a sudden, these questions about what we're trying to do, our preferences and affordances and constraints and limitations and everything come into play and we might make a portfolio of models that are shining light on different aspects of even the very same phenomena. So it's kind of like an empirically grounded pluralism and pragmatism when we start to be engaged in real useful modeling. And that is something that I feel that one learns on the field, not necessarily bystanding. So that's just to say that the modeling is really important, even for philosophical reasons, to say nothing of some of the things that are coming to play in chapter seven and beyond, where it's like, yeah, the C vector has this many entries because why and how many rows and columns does this have? But once we understand why the rows and the columns and the shapes of these different entities are the way they are, then we just have to use this scaffold to think about certain systems, consider their form at a very structural level, like is it in discrete time or in continuous time and so on.
691250	730538	21	A	1.0	11:31	101	And then we might set up not just one generative model, but again, families of them. In the future, we hope and expect that active block, for instance, will facilitate us doing parameter sweeps across families of cognitive models and generative models. But even in this boutique phase of model construction that we're in in current year, one would still say, okay, I want to have one model where it's either acceptable temperature or too hot, and I want to have one with a three state model. Too cold, just right, too hot. Here's going to be a four stage model.
730704	755940	22	A	0.84	12:10	43	And just being able to specify that, again, instills pluralism through action about how we're modeling a system, which is a philosophical point that it seems like sometimes isn't grasped by those who don't engage in the specific discussions around modeling a system.
758950	763800	23	A	0.99	12:38	9	Okay, so where does Figure 6.1 come into play?
771800	796248	24	A	0.9943	12:51	46	It's a rehearsal of some of the figures we've seen earlier in the book and many, many other places. This is the particular partition. The particle is the internal and the active sensory states. So internal plus blanket states equals particular states. Those are the particles.
796344	864290	25	A	0.99406	13:16	134	If we were looking at dust under the microscope, like Brownian Motion was describing, initially the particles were the dust particle, and then the external states were like that, which was not the dust particle partitioning the generative process and the generative model off from each other. We're dealing in Bayesian mechanics with particular states, with particles, with things that are able to engage in sensory motor type loops. This is just bringing in a few more pieces than that, which is just to call attention to the direction and the existence of the arrows in the work. How particular is the free energy principle of aguilera at all? And in follow up work, there's discussion around which topologies on this particular partition facilitate or enable which kinds of formal claims to be made.
864760	911360	26	A	1.0	14:24	102	For example, one might find it kind of interesting that sensory states have a bi directional arrow with external states or might find it equally interesting or differently interesting or less interesting that also active states have an arrow pointing back to internal states. And of course the questions that we have raised all along the way of like, okay, let's just say that we're going to model a person's arm. What are the active states, what are the sensory states? What does it mean that there's a bi directional arrow connecting them? Is this the only topology for this particular partition?
911940	941710	27	A	0.99997	15:11	64	Could we have the around the clock model external states influencing sensory, then internal, then active and just going around the clock without any cross talk in the blanket, without any back arrows? Is that plausible? Does that change the formalism? On one hand, how could it not change the formalism when it's changing the structure of how variables are related to each other?
943760	966820	28	A	0.83	15:43	34	Or maybe there are formalisms that are actually abstracted away from any topology choice because what is being described are the flows and the gradients on these variables. But then what are those variables.
980380	1015190	29	B	1.0	16:20	59	That. Just highlights this need for modeling? But if we just really briefly go. Back to that, it's like the fact that there's this bi directional arrow between external states and sensory states is bit confusing in that. Again, the language like well if it is acting on the environment, isn't that an action state or something like this?
1017640	1038184	30	B	0.54326	16:57	52	In what way is it bi directional? So could you not draw that as one arrow going to the sensory state and one arrow from the sensory state back to the environment and then say what functionally does that entail? And then you're doing this particular selection. Of how you're modeling. Right.
1038382	1040830	31	B	0.99999	17:18	8	But I think you have to do that.
1042880	1052850	32	C	1.0	17:22	21	To understand why that is bi directional there right. In that particular framing of the generative process generate model there right.
1058500	1083130	33	C	0.99789	17:38	54	Which is still to me also slightly nebulous. But I think yeah, just the bi directionality of it between the action and sense states that kind of makes sense almost that you sense your actions and your actions or response to your sense. But that's not really what's being done there precisely either. Right.
1087660	1131930	34	B	0.8822	18:07	95	Just explicating. That is what we need to separate and explicate what yeah. Another really important question is like this action perception loop is appealed to early and often. It's the first picture in the textbook before the high road and the low road in 1.2 is eleven. We're talking about agents and their interfacing with the niche and we're going to end up calling how we model agents a generative model and we're going to end up calling the niche and the dynamics of the niche and how it's influenced as the generative process.
1132620	1150380	35	A	1.0	18:52	58	And we're going to call the interface between the generative model and the generative process a Markov blanket and it's going to inherit this technical definition from Bayes graphs and we're going to add these variables and we're going to connect them a certain way. But we're talking about the feedback loop with the agent in the niche.
1153700	1156930	36	A	0.62	19:13	6	Oh, so what is this then?
1159380	1197870	37	A	0.99991	19:19	67	Are the observations the sensory states? And this isn't just like a low hanging fruit like well then why couldn't we call them? I mean, they are called as X and Y. Interestingly in the continuous time formulation and I get it that they're being distinguished here because this is the continuous time POMDP and the discrete time POMDP. But where do we see active states here?
1200320	1201900	38	A	0.99983	20:00	3	We see policies.
1205390	1232370	39	A	0.66331	20:05	39	So are active states along the branch influencing the B matrix how the hidden states change through time? So there may be a very simple trail from this action perception loop framing to the discrete and continuous time POMDPs.
1235110	1270734	40	B	0.9995	20:35	86	Yeah, I think just to me, the simple way instead of thinking of this as a circular thing where you're literally going from one state to the next state to the way you might to in a normal state machine if you're thinking of no when you have an active state, however, it is changing. That is necessarily entailing change in the. Sensory external state and the internal states and vice versa. Here with the sensory states like that. If you perform some action of some.
1270772	1280420	41	C	0.99846	21:10	17	Kind, there's some active change in that state. Like you're necessarily changing the internal hidden state, right?
1282870	1334900	42	C	0.98866	21:22	90	If you grab a glass of water or something like this, what you're modeling now has changed slightly, right? And your internal states and the sensory states are doing the same thing where the glass of water or whatever was this object just sitting there doing nothing, but now it's become a thing to drink out of. And that's changed in some sense the kind of external states that are being fed into your sensory states. It's changed the Markov blanket that you're kind of selecting for or relating to.
1341990	1364700	43	C	0.99	22:21	44	I think that is visibly they're doing the same sort of thing where if you have this observation, you're necessarily creating a new internal or sense state that is going to change your policy selection and that's going to change your sense states. So.
1377670	1451190	44	A	0.72543	22:57	159	Returning to the recipe, one question that I think will reduce our uncertainty about as we really do the modeling is how do we account for residuals and understand which modeling residuals, which is to say variability in data that are not explained by the model, which and what amounts of residuals are acceptable? So if we were doing a linear regression and the only data we had on hand was height, and the only data that we wanted to predict were weight, then we could just say we've used all the data and whether the model fits with an R value of zero one or zero nine, we know what the residual is of height on weight regression. And here's a number that describes what fraction of the variability was described with this regression? R value of one being like it's all perfectly on a line. R value of zero being like it's just a total scatter plot.
1452270	1499880	45	A	0.99996	24:12	95	We can say how much variability is explained and then we're done with the empirical data that we had. So we can't explain any more variability when we're looking at empirical traces of behavior to explain even a small fraction of behavior. For some systems, it might be the case that the generative models already must be quite complex. In another scenario, it might be the case that a very simple model like looks to the left are 90% of the time followed by looking to the right. I mean on average, isn't that true?
1500890	1575498	46	A	0.99995	25:00	131	So then when we are evaluating models, whether in block, for instance, sweeping across models or just qualitatively or in a boutique way, are we looking to reduce the residual to zero? What traces of data are we looking to explain variability in? And then if we're not going to be with empirical traces of behavior looking to reduce our unexplained variance, what is going to be the criteria by which we do model selection on the AIC and the BIC, which are information criteria, balance variability explained across families of models with their degree of parameterization penalizing having more parameters, rewarding better explanations. So seeking to find a balance with models that are on the kind of pareto frontier of explanatory and simple, that's great. That's like one extra nuance.
1575594	1631438	47	A	0.54451	26:15	140	On top of merely explaining more variability with a smaller residual, it also adds in the penalty for having more parameters. So that in theory and in practice stops the modeler from just, okay, well now we're going to add in the temperature in this other part of the world because 1% of the variability just happened to be explained. So now we're just developing these like totally spiraling looking for more and more data sources to explain a decreasing amount of variability that's left. So it's good to pull back from that edge through the use of information criterion. But at the core of the criterion is still the imperative to reduce the residual, to have a model that fits within a model the way that we fine tune it so that it fits data well, but not overfitting.
1631614	1641350	48	A	0.5	27:11	25	And then across models we can see an analogous process of wanting the model structure that fits without, for example, overfitting or over including parameters.
1643930	1679780	49	A	0.99891	27:23	76	So I think one question which might be added here is like what data do we have if we're doing a didactic model and we just want to sketch it out and run a simulation and just purely generate data that might be useful in certain settings. But the question of what behavioral data we have is very nontrivial if we're going to be approaching this as an empirical analysis problem. Brock just another question there.
1684150	1698520	50	C	0.99993	28:04	37	What observations must we make or something is related to what data do we have? If you don't have the data that if there's not sufficient affordance information contained in the data to model the problem, then.
1708720	1723410	51	A	0.99668	28:28	22	Do we have to model our action selection at a second or third order? Yeah, exactly. To realize the right epistemic value.
1727220	1821920	52	A	1.0	28:47	155	Okay, so that was figure 61, discrete and continuous, shallow, deep and hierarchical. So just to address this, which might come up shallow versus deep is describing how iterated the model is through time, within one type of time. So you could have the 1 hour shallow model where hours are our units, or you could have the 10 hours where it goes 1234-5678, 910, or you could have 100 depth of 100 with a time click of one. Or one could have a hierarchical model where there's 10 hours that make like a deca hour and then there's ten clicks of the deca hour to reach a planning horizon of 100 time steps. So deep is describing within one unit or counter of time how iterated that counter is depth is describing strict hierarchical nesting and so they can both be used separately or together to describe events over longer and longer time horizons.
1823540	1862700	53	A	0.60451	30:23	96	Crucially, this is in the context of language processing. The duration of the word transcends that of any phoneme and the sentence transcends that of any word in the sequence. And if we assume paragraphs are made of multiple sentences, paragraphs always transcend and encompass sentences. So anyone else want to just add a point? I'm sure that you fellows are familiar with this distinction, but just wanted to point it out since temporality in these models and doing model selection on different forms of temporality is going to be an essential piece of the puzzle.
1869600	1941760	54	A	0.62848	31:09	106	Yeah. And it also reminds me of the Shankarian analysis theory that, if you remember, we talked about earlier, and it's hierarchical. It's temporal hierarchy that tries to describe the whole musical piece as a kind of hierarchical layers, which I think maps perfectly into this specific example of language parsing because that also is a kind of thing that should ideally be modeled in a very hierarchical way. But the caveat here is unlike language, which is at least in some languages, are necessarily hierarchical, music is at least tonal. Music or even nontonal music are not necessarily they don't necessarily have this hierarchical structure.
1941840	1993296	55	D	0.66889	32:21	91	So depending on the kind of music or the genre of music, we might have either a very shallow and non hierarchical structure or a very deep one. So that's something that I think again refers back to the kind of system we're trying to model. But even that kind of system needs to be more specified in a more granular level in order to have an effective modeling strategy there. Thanks for bringing it in that domain. It makes me think of the intro, the chorus, the bridge, the verse.
1993488	2049960	56	A	0.99801	33:13	129	Perhaps these are only in certain genre of music, but analogously and then the measure transcends any beat in the measure with a special case of like a one one time signature or something and so on. And then, although language is described in a strictly hierarchical sense, I'm wondering how syntax and grammar actually create kind of a strange loop. For example, it's trivial to say that phonemes are nested within words and sentences and so on, but what about the semantics of a sentence that contains commas and exceptions? And then at the end the speaker says the previous sentence is not how you think it is. That is also causing kind of like a deep linguistic recall that can be trivially modeled as containing nested units.
2051340	2100920	57	A	0.99999	34:11	107	But will a model that narrowly considers the semantics of words, then the semantics of clauses, how will it be able to address some of these questions? Here I think we can point to a really excellent attribute of the active inference modeling framework. So in this discussion where the LW paper was cited, we could just marvel at nested systems and draw blankets on blankets and so on. They could be drawn around every organelle and every little lipid granule in the neurons or the brain regions. And so we discussed a little earlier like doing structural model selection on which one of those are relevant.
2102380	2118700	58	A	1.0	35:02	45	However, this does not mean we need to attempt to model the entire brain to develop meaningful pragmatic simulations of a single level. For example, if we wanted to focus on word processing, we could address some aspects without having to deal with phoneme processes.
2120720	2179600	59	A	1.0	35:20	132	This means we can treat inputs from parts of the brain drawing inference about phonemes as providing observations from the perspective of word processing areas. So one could say I'm going to make a figure 4.3 where S is the true word and phonemes are being passed as observations to my word inference engine. And someone can say but aren't phonemes the result of inference? And someone can say great, make that module in blockprints, make that module and pass me that data. And then we can do a nested model and we can graft those models together, but through the Markov blanket formalism, not even the whole Markov blanket bounding a specific particular entity, but just the trivial Markov blanket that exists insulating any two unconnected nodes in a base graph.
2180260	2242948	60	A	0.99405	36:20	122	We can use that broader, still technical concept of a Markov blanket and just say all right, phoneium observations come in and surely we could make a model where another type of information comes in and the inference is on phoneme and that's what's passed out. So I think again to point to this advantage of active inference modeling. It allows us to situate phenomena as complex multiscale nested systems and also bite off what we can chew and makes it an empirical question of how grafting together which different structures might be useful. But we don't need to go all the way like turtles all the way down. We can just say, even if it were turtles all the way down.
2243114	2259640	61	A	0.67992	37:23	44	We're modeling the third through the fifth turtle. And the fifth turtle gets a top down prior, and the third turtle gets sensory input from one below it. And that's the part of the stack. And this is the lateral width that we're modeling.
2264720	2326012	62	A	0.99999	37:44	118	Another advantage of active inference, which not even saying this is a unique advantage, is that this goal directedness and corollary capacities like counterfactuals on goals and the way that counterfactuals on world states influence our goal selection, nested goals and transient goals or conditional goals can be resolved in an unfolding action perception loop. That's something that as this example of like wanting to enter an apartment, of being goal driven over multiple timescales and then being able to again zoom in. So it's like, oh, grab the keys. Okay, well here's the key grabbing module. And someone says, well, the key grabbing is actually accomplished through this kind of grasping behavior, then that could be modeled.
2326076	2359060	63	A	0.63	38:46	63	Or you can just say we're subsuming finger grasping kinetics in the grasping module because the phenomena that we're trying to explain and the data we have is just about when things were grasped or maybe the only observations we have is when apartments were entered. So we can actually, I expect, frame systems extremely expansively and clarify where we're doing formal modeling.
2372760	2417350	64	B	0.86	39:32	70	I think maybe this is just a philosophical or ontological framing of it, but I don't see how you can model anything well without admitting that it is either incomplete or partially consistent or that there is some hidden state which is probably not included in the model. And to me, active inference kind of. Natively has an affordance, at least at the very least a bookmark to do that.
2419400	2425690	65	B	1.0	40:19	10	And so whatever depth or hierarchy you model the system.
2428540	2447420	66	C	0.69004	40:28	44	It'S okay. It's okay that there's still hidden state and it's incomplete. If it sufficiently models answers the question at hand, then you can always add another layer or make the model more complex. And that's just what we were going to do anyways.
2449540	2483930	67	A	0.99883	40:49	65	Nice comment. I totally agree with that. Again, thinking back to the linear model example, where is that extra information about adjacent possibles for the model? It's unstructured. It's kind of like either the structured information is going to enter your linear regression just so and everything that's outside of your linear regression is we're going to need to go back to the square one.
2484780	2534520	68	A	1.0	41:24	111	If we include a second observable, we're going to have to go to square one and do the model selection all over again and test for all the repeat interactions again. But in these multiscale models that we're discussing, like you said, it was a bookmark. It's kind of a nice way to frame it, which is like the phonemes you're bookmarking or leaving an open USB port or something. Anything that outputs a phoneme will plug into that part of the model anything that is able to hear can be plugged in to the frog riveting. Anything that can see can be plugged into the visual component of the frog.
2535580	2558800	69	A	0.51	42:15	39	And so it's almost like consistent with all of this blanket talk, we're being clear about what is modeled formally, and the borders of the formal model are degrees of freedom as formulated to be expanded upon and composed.
2563560	2585000	70	B	0.99	42:43	34	One other, I'm not sure the context is something I heard Ben Gertzel say attributed to Pink Schweight, but Pei Wang that in circular reasoning, when your circle. Gets big enough, it becomes coherent.
2588640	2596510	71	C	0.88655	43:08	15	Maybe another way of saying like, that if your model is insufficient, that if. You.
2599200	2623280	72	C	0.80756	43:19	31	Add enough states enough, if you expand your blanket enough, eventually if you're modeling something correctly, I guess the generative process can match your blanket states can can come into alignment.
2628440	2651356	73	A	0.99842	43:48	35	Nice. Some more active inference isms so exteriorceptive proprioceptive, interceptive. We're going to use active inference modeling memory, attention, anticipation, planning as inference. We're going to use active inference. That is what it looks like.
2651378	2659100	74	A	1.0	44:11	11	To integrate disparate fields using one model, one family of models.
2663700	2705300	75	A	0.99977	44:23	85	Others can work out some fun ways to communicate and frame it. But I think when people are like, how is this simplifying when it might feel like it's bringing in a lot or even stepping on namespaces that people already have familiarity in? Like we discussed earlier, you could ask, how is memory related to attention? Or perhaps more saliently, how will you model how memory is related to attention? Are you going to go on archive and just look for neural network architectures?
2706120	2760770	76	A	0.99949	45:06	66	Are you going to read a book written before computers were invented and look at prose? Are you going to dive into the psychoanalytic tradition or something that's maybe even clinically, biomedical what's the move? And active inference addresses that's in these theme of words that people use that mean different things. For 400, we have Bay's optimal behavior. Well, then why do things go wrong?
2762500	2812800	77	A	1.0	46:02	99	And there's multiple layers to unpack. First is going wrong is about your perspective on how the system, perhaps how you prefer it to be or how you expected it to be. But given where you put the dish when it fell off the table, that was just compatible with gravity. So it was finding its optimal position and fragmentation where you placed it. The ball rolled downhill as a consequence of where it was placed and the slope it was on, and framing behavior in that light, we're modeling behavior as rolling to the bottom of a bowl.
2814260	2832920	78	A	0.99704	46:54	34	What's the bowl? What's the ball? Those are the questions. But it's like chemical reactions proceeding under Gibbs free energy minimization when we have policy selection driven by variational and expected free energy minimization.
2835180	2872340	79	A	0.99999	47:15	53	But how can things that go wrong be optimal? Well, it has to do with different parameters in the model, given how they are. The model performs optimally. That doesn't mean computationally efficiently. It doesn't mean adequately, doesn't mean it satisfies, but it may be framed as Bayes optimal fixed and learned behaviors.
2873160	2921780	80	A	0.99	47:53	114	This is going to come into play in chapter seven. There's an amazing continuity in theory and in simple examples with perception and learning, which is to say that perception happens over faster timescales or perceptive like processes happen over faster timescales while learning like processes happen over slower timescales. Or even just more generally, perception and learning refer to parametric update processes, and you might even be able to situate the same example both ways. Like if we see a ball move across our visual field, are we perceiving the location of the ball? Are we inferring the location of the ball or are we updating and learning our position of the ball?
2922200	2950124	81	A	1.0	48:42	58	For those with a computational background, learning often equates to parameter updating. And so in that sense any kind of dynamical perception is learning. So for some backgrounds the difference between perception and learning will be seamless. For other backgrounds, those are going to sound like totally different processes. I mean, isn't perception when you see the book?
2950162	2998988	82	A	0.99999	49:10	89	But then learning is like when you understand something about the book and then speaking from a more modeling perspective, here a fixed model or fixing a parameter of a model reduces the model's complexity immensely. Or another way to say it taking a fixed parameter and making it learnable introduces multiple hyperparameters. And there's no single way to address parameter learning. You could say, well, we're doing moving average learning like a column filter or just a simple sliding window. We're taking the average of the last three.
2999154	3053580	83	A	1.0	49:59	87	But now you have to parameter sweep across how many. And with a single trial of data, it may not be clear which learning strategy is implemented because especially if we want to differentiate learning strategies empirically, we would want to see like multiple comparable trajectories within and amongst individuals in similar and different contexts. But now our lab has gotten quite big and we're doing quite large model selections even for learning and updating parameters that might just conversationally seem really simple like preferences being updated.
3058510	3097830	84	A	0.98672	50:58	80	So here's this description of when it comes to inference and perception as being fast changes and learning as slower changes, though they're being modeled in a really analogous way. It is worth noting in this book we exemplify rather simple generative models that are defined using tabular methods, e. G with explicit matrices or tensors for priors and likelihoods in small state spaces. In comparison, more sophisticated GMs are being developed in machine learning, deep learning, robotics, et cetera.
3100950	3137990	85	A	0.59086	51:40	41	So is active inference deep learning okay, good fellow generative, adversarial networks, but with Bengio and Mirza. But are we saying those are formally active inference systems or are we just saying that we can think of it like birdsong conceptually?
3141770	3155450	86	A	1.0	52:21	32	And then are we just adding a wrapper or a descriptor to the gans that our non active colleagues are building is it shining any new epistemic or Pragmatic light on Gans?
3160550	3184570	87	A	0.51	52:40	23	I mean, here's a whole paragraph on Gans behind. Oh, that's chapter ten. What happened? But there's still a whole paragraph on Gantz.
3189420	3190730	88	A	0.99959	53:09	4	Did you see that?
3205680	3207070	89	A	0.99644	53:25	4	How did that happen?
3211190	3212050	90	A	0.84641	53:31	1	Whoa.
3217620	3230820	91	B	0.66709	53:37	30	I'm not sure what the optimal way to view a PDF is or that one exists, but I don't think it's the browser. It's not bad, but it's not optimal.
3234200	3248120	92	B	0.80556	53:54	24	I'm interested in, again the generative model. Oh, I know what those are. So, generative model and how specifically Gans here an active inference.
3250160	3299340	93	B	0.54509	54:10	67	Is the rectangle a square? Sorry, square rectangle rectangle not a square here. Is that what is being said or is there an indexed blanket here of varying degree? Yes, as far as I know. And and also you fellows might know like this is being pointed to variational auto encoders and variational Bayesian inference are directly implicated as potentially recursive cortical networks are and world models.
3300720	3361280	94	A	0.99996	55:00	108	But if these bridges can be made solid, like you said, with squares and rectangles so that we can say all some or none of X-R-Y or here's how you project this model to that model. It's going to just break a dam with possibly certain applications of active. Any final comments on six, and I think certainly by two weeks from now, let's look at the SPM implementation and look at some of those that are pointed towards in the book, as well as some of like the epistemic chaining and Pi MDP type models, as well as anything that anyone else builds. So, any final comments?
3363380	3403950	95	D	0.70049	56:03	72	Yeah, I just wanted to point out the recent work by Fields at all, especially the two papers that first and was also the co author of. One of their main objectives is to cross that bridge between active inference and VAE via the CCCD system. So that bridge they're talking about in this book is already being investigated to be filled. So yeah, they're pretty interesting developments going in that regard.
3406480	3411250	96	A	0.93	56:46	13	Okay, any last notes before I stop the recording? What is that paper?
3413380	3436330	97	D	0.9529	56:53	41	I'll send you the link from the discord. I forgot. Maybe just one. I don't know. We haven't trying to make an effort on the code to lay down some basic examples from the first half, but should there be some?
3439180	3450700	98	B	0.95119	57:19	36	If we're going to model stuff, should we have a sub page for that or do put something somewhere in the code of for that? I don't know. We've had this code section from the beginning.
3452800	3473030	99	A	0.98656	57:32	34	However, it should be totally modifiable, full control. So however this and anything sub pages need to be modified and the GitHub link to a textbook, anything that people suggests, just let us know.
3480870	3484160	100	A	0.99836	58:00	3	Anything else. Okay?
