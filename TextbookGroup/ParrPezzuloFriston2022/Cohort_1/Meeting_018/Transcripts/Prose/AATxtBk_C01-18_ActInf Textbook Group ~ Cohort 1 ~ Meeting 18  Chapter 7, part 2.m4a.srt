1
00:00:00,650 --> 00:00:04,074
Hello, cohort one. It's meeting 18.

2
00:00:04,202 --> 00:00:07,280
We're in our second discussion on

3
00:00:07,730 --> 00:00:11,374
chapter seven. Let's go to the questions

4
00:00:11,572 --> 00:00:16,494
and see what we can explore today or

5
00:00:16,532 --> 00:00:20,382
see where else to go and or look

6
00:00:20,436 --> 00:00:22,782
towards chapter eight. But there's any

7
00:00:22,916 --> 00:00:25,640
number of ways we can do it. So go

8
00:00:26,810 --> 00:00:29,400
first, just on chapter seven.

9
00:00:30,650 --> 00:00:34,326
Does anyone want to turn to

10
00:00:34,348 --> 00:00:35,910
any of these questions, add another

11
00:00:35,980 --> 00:00:39,754
question, add another reflection or

12
00:00:39,792 --> 00:00:42,300
a thought that arose in the last week?

13
00:01:00,330 --> 00:01:04,520
One question that I had was,

14
00:01:05,130 --> 00:01:09,350
are there any ways or suites

15
00:01:10,010 --> 00:01:12,546
for, for example, taking in an

16
00:01:12,588 --> 00:01:16,278
analytical expression and then providing

17
00:01:16,374 --> 00:01:20,074
equivalent phrasings that might

18
00:01:20,112 --> 00:01:21,610
have other advantages?

19
00:01:26,360 --> 00:01:29,864
Ali you mean by translating it into

20
00:01:29,902 --> 00:01:33,130
natural language or.

21
00:01:36,060 --> 00:01:38,296
Like what we saw in equation 2.5 and

22
00:01:38,318 --> 00:01:41,724
2.6, like, to take in an

23
00:01:41,762 --> 00:01:45,580
expression and then output

24
00:01:48,160 --> 00:01:50,856
isomorphic or I guess not isomorphic,

25
00:01:50,888 --> 00:01:53,276
but equivalent expressions, expressions

26
00:01:53,308 --> 00:01:56,112
that have the exact same value as

27
00:01:56,166 --> 00:01:57,120
calculated.

28
00:02:01,380 --> 00:02:03,692
And when we look through the derivation,

29
00:02:03,756 --> 00:02:05,328
sometimes it's possible to trace the

30
00:02:05,334 --> 00:02:08,368
trail. But to know which representations

31
00:02:08,464 --> 00:02:12,420
of perhaps even the same functional

32
00:02:12,840 --> 00:02:15,860
or same term,

33
00:02:16,520 --> 00:02:18,680
it seems quite relevant.

34
00:02:20,620 --> 00:02:23,828
Actually. There's an AI assistant

35
00:02:23,924 --> 00:02:27,384
for deriving formal proofs for

36
00:02:27,422 --> 00:02:30,904
mathematical theorems, but I haven't

37
00:02:30,952 --> 00:02:33,292
used it myself, but I'm not sure if

38
00:02:33,346 --> 00:02:37,836
that's what you mean. I'll look at the

39
00:02:37,858 --> 00:02:40,296
name of that and just 1 second, I'll

40
00:02:40,328 --> 00:02:43,632
post. Maybe.

41
00:02:43,766 --> 00:02:48,960
There'S a way to reformulate

42
00:02:50,500 --> 00:02:54,208
these specific terms from, like, a

43
00:02:54,214 --> 00:02:58,608
Bayesian mechanics formalism,

44
00:02:58,704 --> 00:03:01,696
like posterior predictive, predicted

45
00:03:01,728 --> 00:03:04,564
entropy. That looks like something that

46
00:03:04,602 --> 00:03:06,790
Dalton probably described as well.

47
00:03:09,180 --> 00:03:10,424
Question is whether you can just

48
00:03:10,462 --> 00:03:11,530
interchange it.

49
00:03:15,380 --> 00:03:19,072
Yeah. Does working with the particular

50
00:03:19,206 --> 00:03:23,620
partition enable

51
00:03:24,120 --> 00:03:28,180
equations to be operated with more

52
00:03:28,250 --> 00:03:29,220
composably?

53
00:03:33,660 --> 00:03:37,772
Because we can know that there are

54
00:03:37,826 --> 00:03:41,150
certain operations that are

55
00:03:42,320 --> 00:03:44,284
always, sometimes never going to be

56
00:03:44,322 --> 00:03:47,916
valid. I'm just

57
00:03:47,938 --> 00:03:50,048
kind of asking. I don't even know if

58
00:03:50,054 --> 00:03:53,040
that's the right way to have it. Um,

59
00:04:01,510 --> 00:04:05,038
so last time, we talked primarily

60
00:04:05,134 --> 00:04:09,270
about the mouse

61
00:04:09,850 --> 00:04:13,320
in the maze, and we are going through

62
00:04:15,690 --> 00:04:19,166
the way that the chapter is layering

63
00:04:19,218 --> 00:04:23,796
on features

64
00:04:23,908 --> 00:04:27,450
of the model. So first we saw

65
00:04:28,540 --> 00:04:31,370
the mouse just go for it,

66
00:04:32,220 --> 00:04:36,796
and now we're going to be where

67
00:04:36,818 --> 00:04:37,980
it gets the queue.

68
00:04:44,240 --> 00:04:46,300
And this comes to our earlier points

69
00:04:46,370 --> 00:04:48,204
about the resolution of the Explore

70
00:04:48,252 --> 00:04:50,560
exploit tradeoff.

71
00:05:07,150 --> 00:05:08,798
I'm going to add a question. Anyone can

72
00:05:08,804 --> 00:05:10,318
give a thought while I'm adding it.

73
00:05:10,484 --> 00:05:13,130
What are posterior predictive entropy

74
00:05:13,210 --> 00:05:15,150
and expected ambiguity?

75
00:05:41,070 --> 00:05:43,518
They're part of the decomposition of

76
00:05:43,604 --> 00:05:48,830
epistemic value posterior.

77
00:05:52,400 --> 00:05:54,524
Let me just make sure to say the

78
00:05:54,562 --> 00:05:59,904
posterior predictive entropy is

79
00:05:59,942 --> 00:06:03,280
the expected surprise or the entropy

80
00:06:04,820 --> 00:06:07,900
of the distribution of observations

81
00:06:07,980 --> 00:06:11,172
conditioned on a policy. So we're in

82
00:06:11,306 --> 00:06:14,736
expected free energy world. We're

83
00:06:14,768 --> 00:06:19,540
talking about evaluating policies

84
00:06:20,360 --> 00:06:23,524
with respect to now, putting aside

85
00:06:23,572 --> 00:06:25,864
pragmatic value. We're talking about

86
00:06:25,982 --> 00:06:29,124
decompositions of how the informational

87
00:06:29,172 --> 00:06:33,064
or the epistemic value of a

88
00:06:33,102 --> 00:06:36,556
policy is evaluated. So there's two

89
00:06:36,578 --> 00:06:38,750
terms here. First,

90
00:06:40,160 --> 00:06:43,544
how dispersed is your distribution

91
00:06:43,672 --> 00:06:46,830
of outcomes for that policy?

92
00:06:48,900 --> 00:06:50,576
One can imagine that, all things being

93
00:06:50,598 --> 00:06:53,340
equal, you would want to select policies

94
00:06:53,500 --> 00:06:55,904
that have a tighter distribution of

95
00:06:55,942 --> 00:06:56,880
outcomes.

96
00:06:59,080 --> 00:07:02,304
Here we have an expectation.

97
00:07:02,432 --> 00:07:05,990
Interestingly, this is italics e,

98
00:07:06,360 --> 00:07:08,230
but it's not a fancy e.

99
00:07:09,560 --> 00:07:10,804
Do people think there's a difference

100
00:07:10,842 --> 00:07:12,488
that matters or do they think that's a

101
00:07:12,494 --> 00:07:13,480
slight error?

102
00:07:18,300 --> 00:07:20,472
I think that should be a typo. Yeah,

103
00:07:20,526 --> 00:07:31,172
I'm going to add it to erata e

104
00:07:31,226 --> 00:07:35,220
is TALIX

105
00:07:35,800 --> 00:07:37,590
should be fancy e.

106
00:07:49,980 --> 00:07:54,808
It's the expectation over

107
00:07:54,894 --> 00:07:57,496
our hidden state estimates condition on

108
00:07:57,518 --> 00:08:01,230
a policy and it's the expectation of

109
00:08:03,360 --> 00:08:08,380
the expected ambiguity. So entropy

110
00:08:09,200 --> 00:08:11,980
of the A matrix,

111
00:08:13,220 --> 00:08:15,936
functionally how outcomes depend on

112
00:08:15,958 --> 00:08:20,290
states. So this is saying I want to be

113
00:08:22,420 --> 00:08:29,556
I want to be more is

114
00:08:29,578 --> 00:08:31,284
it the case that it says, I want to be

115
00:08:31,322 --> 00:08:35,684
more certain about observations and

116
00:08:35,722 --> 00:08:41,290
how they map to policy and

117
00:08:42,380 --> 00:08:44,756
I want to have a tighter A matrix?

118
00:08:44,948 --> 00:08:45,800
Eric.

119
00:08:48,140 --> 00:08:51,276
So, nice question. Why is there an

120
00:08:51,298 --> 00:08:52,828
expectation on the right and not on the

121
00:08:52,834 --> 00:08:56,776
left? I was also going to ask this isn't

122
00:08:56,888 --> 00:08:59,630
entropy already the expectation of

123
00:09:01,540 --> 00:09:02,560
surprise?

124
00:09:07,860 --> 00:09:11,996
Just another point of I'm

125
00:09:12,028 --> 00:09:15,684
sorry. So another

126
00:09:15,802 --> 00:09:18,950
point of clarification for myself that

127
00:09:19,560 --> 00:09:23,750
want to make sure this is right is the

128
00:09:24,200 --> 00:09:27,160
O tilde is observations.

129
00:09:28,060 --> 00:09:31,496
And what we're looking at here is a

130
00:09:31,518 --> 00:09:33,690
functional Q.

131
00:09:34,460 --> 00:09:39,444
So that's

132
00:09:39,492 --> 00:09:45,880
a distribution of observations

133
00:09:46,300 --> 00:09:49,016
that will get over policy and that's

134
00:09:49,048 --> 00:09:50,924
what's being adjusted in the free

135
00:09:50,962 --> 00:09:54,384
energy. So we're going to explore the

136
00:09:54,422 --> 00:09:58,828
distributions Q and the O Tilde's

137
00:09:59,004 --> 00:10:02,860
are going to be past observations.

138
00:10:02,940 --> 00:10:04,768
We're not looking forward there. We're

139
00:10:04,784 --> 00:10:07,060
looking past because those are actual

140
00:10:07,130 --> 00:10:09,360
observations. They're not predicted

141
00:10:09,520 --> 00:10:12,950
through the hidden states s.

142
00:10:13,880 --> 00:10:16,150
So straighten that out.

143
00:10:17,340 --> 00:10:19,560
Are we sure that O are only past

144
00:10:19,630 --> 00:10:21,560
observations? I believe that past

145
00:10:21,630 --> 00:10:24,952
observations are accounted for with

146
00:10:25,006 --> 00:10:28,664
respect to how they influence the

147
00:10:28,702 --> 00:10:29,400
prior.

148
00:10:32,640 --> 00:10:38,380
But does O tilde also include future

149
00:10:38,450 --> 00:10:42,304
observations? Well, if so,

150
00:10:42,342 --> 00:10:43,824
then it has to be an expectation over

151
00:10:43,862 --> 00:10:45,730
something, mustn't it?

152
00:10:46,900 --> 00:10:49,072
But this is conditioned upon a given

153
00:10:49,126 --> 00:10:54,228
policy. Then this

154
00:10:54,234 --> 00:10:56,660
is the time series of observations

155
00:10:57,240 --> 00:10:59,350
expected under that policy.

156
00:11:03,160 --> 00:11:07,544
Is the left term the

157
00:11:07,582 --> 00:11:11,690
Q expected distribution of

158
00:11:12,460 --> 00:11:14,840
observations conditioned on policy.

159
00:11:14,990 --> 00:11:15,960
Jacob.

160
00:11:18,460 --> 00:11:20,684
I was just going to say that I think

161
00:11:20,722 --> 00:11:23,868
I've seen this in other parts of the

162
00:11:23,874 --> 00:11:28,060
book as well, and I think they use the h

163
00:11:28,210 --> 00:11:30,424
and then just the expectation notation

164
00:11:30,472 --> 00:11:33,280
for entropy kind of interchangeably.

165
00:11:37,570 --> 00:11:40,126
Okay, if they do, but then isn't this

166
00:11:40,148 --> 00:11:41,710
like a double expectation?

167
00:11:44,050 --> 00:11:47,266
This is the expectation of surprise on

168
00:11:47,288 --> 00:11:50,130
the queue, but this is the expectation

169
00:11:50,790 --> 00:11:53,090
of the expectation of surprise.

170
00:11:57,830 --> 00:11:58,610
That'S.

171
00:12:01,130 --> 00:12:05,186
Yeah, that I don't

172
00:12:05,218 --> 00:12:05,800
know.

173
00:12:11,760 --> 00:12:18,660
Eric okay,

174
00:12:18,810 --> 00:12:22,464
but the left term just Ali,

175
00:12:22,512 --> 00:12:23,110
please.

176
00:12:26,040 --> 00:12:28,470
Well, shouldn't that first line,

177
00:12:29,560 --> 00:12:30,470
I mean,

178
00:12:34,780 --> 00:12:38,312
shouldn't both of them be

179
00:12:38,366 --> 00:12:40,104
at the argument of the expectation

180
00:12:40,152 --> 00:12:42,270
according to equation 7.4?

181
00:12:43,680 --> 00:12:46,524
Because in equation 7.4 we have the

182
00:12:46,562 --> 00:12:48,590
negative Epistemic value,

183
00:12:50,080 --> 00:12:52,352
but it's somehow different from this

184
00:12:52,406 --> 00:12:54,000
equation. Yeah, that's.

185
00:13:05,060 --> 00:13:08,416
Okay. So in 7.4 we see

186
00:13:08,438 --> 00:13:11,990
a restatement of

187
00:13:13,400 --> 00:13:15,796
expected free energy. Equation two,

188
00:13:15,818 --> 00:13:16,390
six.

189
00:13:18,600 --> 00:13:21,844
Let's leave pragmatic value to the side

190
00:13:21,882 --> 00:13:22,710
for now.

191
00:13:24,860 --> 00:13:28,676
Here we see fancy E-Q-S tilde

192
00:13:28,708 --> 00:13:30,840
pi. So this is looking like this

193
00:13:30,910 --> 00:13:34,504
probably could. Or should we

194
00:13:34,542 --> 00:13:38,750
also see Hposhpos

195
00:13:41,760 --> 00:13:45,820
minus H-Q-O

196
00:13:45,890 --> 00:13:46,700
pi?

197
00:13:52,720 --> 00:13:55,564
Okay, so let's take the negative of the

198
00:13:55,602 --> 00:13:59,052
first line. The negative of the first

199
00:13:59,106 --> 00:14:02,856
line. You can kind of just flip

200
00:14:02,888 --> 00:14:05,836
the terms. It's the expected ambiguity.

201
00:14:05,868 --> 00:14:09,404
Now minus the posterior predictive

202
00:14:09,452 --> 00:14:10,400
entropy.

203
00:14:15,120 --> 00:14:18,908
Then an expectation is being taken over.

204
00:14:18,994 --> 00:14:19,630
That.

205
00:14:21,620 --> 00:14:25,872
Sorry, my bad. I thought the square

206
00:14:25,926 --> 00:14:29,264
bracket was encompassing the whole

207
00:14:29,382 --> 00:14:30,930
expectation term. Sorry.

208
00:14:32,500 --> 00:14:35,924
No, you're right, actually. Well,

209
00:14:35,962 --> 00:14:37,670
there's a lot of layers of it,

210
00:14:41,850 --> 00:14:43,990
actually. It's right as it's written.

211
00:14:51,040 --> 00:14:54,680
Okay, wait. I always color my brackets

212
00:14:54,760 --> 00:14:57,836
when I'm trying to do this. Okay. The

213
00:14:57,858 --> 00:15:00,316
outermost bracket there actually may be

214
00:15:00,338 --> 00:15:01,856
a bracket. I don't even know. Let's try

215
00:15:01,878 --> 00:15:03,804
to figure it out. The outer bracket

216
00:15:03,852 --> 00:15:06,656
starts here on the left, and then it

217
00:15:06,678 --> 00:15:09,008
closes. Okay. Pragmatic value. If we

218
00:15:09,014 --> 00:15:13,456
take that as a standalone if

219
00:15:13,478 --> 00:15:15,220
we take that as standalone,

220
00:15:17,320 --> 00:15:19,812
is anyone else seeing a bracket sort of

221
00:15:19,866 --> 00:15:22,516
scenario? If we look at the brackets as

222
00:15:22,538 --> 00:15:27,176
a whole, this first bracket closes this,

223
00:15:27,278 --> 00:15:29,992
right? No, I don't think so. The first

224
00:15:30,046 --> 00:15:33,800
bracket closes at the end of the S tilde

225
00:15:35,820 --> 00:15:39,708
parentheses bracket. Yeah, that's why I

226
00:15:39,714 --> 00:15:43,036
was confused, too. I agree. I was

227
00:15:43,058 --> 00:15:44,748
thinking, should we evaluate the

228
00:15:44,754 --> 00:15:48,590
brackets locally? But yes, they are.

229
00:15:49,680 --> 00:15:50,830
Okay, good.

230
00:15:53,380 --> 00:15:55,820
So it's exactly the negative of equation

231
00:15:55,900 --> 00:16:00,288
7.8. Left side here is the

232
00:16:00,454 --> 00:16:05,924
negative of the

233
00:16:05,962 --> 00:16:06,900
first term.

234
00:16:08,840 --> 00:16:11,136
Let's just say it in terms of picking

235
00:16:11,168 --> 00:16:16,204
good policies. We want policies

236
00:16:16,272 --> 00:16:18,680
are better, with more clarity about

237
00:16:18,750 --> 00:16:20,984
observation outcomes. That's the first

238
00:16:21,022 --> 00:16:24,680
term. And a tighter a matrix.

239
00:16:26,860 --> 00:16:28,440
That's the second term.

240
00:16:29,520 --> 00:16:32,110
Okay. Middle line.

241
00:16:37,360 --> 00:16:41,550
This is a KL divergence between

242
00:16:42,580 --> 00:16:45,216
the product two products of

243
00:16:45,238 --> 00:16:48,432
distributions. Both of them

244
00:16:48,486 --> 00:16:52,496
are dealing with O in

245
00:16:52,518 --> 00:16:56,020
the first and S in the second. The Q

246
00:16:56,090 --> 00:16:58,276
distribution in the second part is the

247
00:16:58,298 --> 00:16:59,350
same for both.

248
00:17:01,080 --> 00:17:04,004
So maybe there's some interactions in

249
00:17:04,042 --> 00:17:05,936
how distributions of different kinds

250
00:17:05,968 --> 00:17:10,296
multiply, but it

251
00:17:10,318 --> 00:17:16,184
may be fair to interpret this as the

252
00:17:16,222 --> 00:17:20,204
POS is

253
00:17:20,402 --> 00:17:25,036
the A matrix and

254
00:17:25,218 --> 00:17:29,644
the Q O. Pi is

255
00:17:29,682 --> 00:17:33,184
how observations are shaped by

256
00:17:33,222 --> 00:17:33,810
policy.

257
00:17:38,790 --> 00:17:43,570
Or another way to say it might be POS is

258
00:17:43,640 --> 00:17:45,854
outcome expectations conditioned upon

259
00:17:45,902 --> 00:17:49,158
hidden states of the world, whereas this

260
00:17:49,164 --> 00:17:51,606
is outcome distributions conditioned on

261
00:17:51,628 --> 00:17:55,174
what we do. To me, that just looks

262
00:17:55,292 --> 00:17:59,080
like base law there because

263
00:17:59,390 --> 00:18:06,446
you've got at

264
00:18:06,468 --> 00:18:10,110
least in the left side

265
00:18:10,260 --> 00:18:12,318
a little bit, because you've got

266
00:18:12,404 --> 00:18:15,198
conditioned on S and then S conditioned

267
00:18:15,214 --> 00:18:19,170
on pi. So you're just basically

268
00:18:19,240 --> 00:18:22,274
saying you're trying to figure out what

269
00:18:22,312 --> 00:18:26,098
O is from pi through this intermediary S

270
00:18:26,264 --> 00:18:27,250
delta.

271
00:18:37,430 --> 00:18:38,962
Another angle would be where is this

272
00:18:39,016 --> 00:18:42,980
zero? Well, this is zero when

273
00:18:44,310 --> 00:18:46,070
these two are identical.

274
00:18:48,490 --> 00:18:51,846
When the

275
00:18:51,868 --> 00:18:54,760
epistemic value of a policy is low,

276
00:18:57,370 --> 00:19:01,370
when the resulting O distribution

277
00:19:02,510 --> 00:19:04,890
is being unconditioned by the policy

278
00:19:04,960 --> 00:19:08,634
that we choose. Whereas for

279
00:19:08,672 --> 00:19:11,374
policies that change how we think about

280
00:19:11,412 --> 00:19:14,922
the A matrix, those policies

281
00:19:14,986 --> 00:19:17,040
have higher informational value.

282
00:19:21,020 --> 00:19:24,216
Because POS is kind of like a policy

283
00:19:24,318 --> 00:19:26,360
agnostic mapping,

284
00:19:28,780 --> 00:19:30,872
but we're like drilling down to kind of

285
00:19:30,926 --> 00:19:34,220
subvariance partitions of

286
00:19:34,290 --> 00:19:36,012
informational value. These are different

287
00:19:36,066 --> 00:19:39,872
ways to look at what makes a

288
00:19:39,926 --> 00:19:43,570
policy have epistemic value.

289
00:19:44,100 --> 00:19:47,330
The first one line was coming down to

290
00:19:48,100 --> 00:19:51,872
clarity around the tightness of outcome

291
00:19:51,936 --> 00:19:55,540
distributions. The second

292
00:19:55,610 --> 00:20:00,870
one is related to how policy

293
00:20:02,700 --> 00:20:05,224
deviates our understanding of the A

294
00:20:05,262 --> 00:20:06,120
matrix.

295
00:20:25,450 --> 00:20:28,940
Now let's turn to here's another.

296
00:20:29,950 --> 00:20:33,066
Italic e. Not a fancy e. Thank you,

297
00:20:33,088 --> 00:20:35,726
Ollie, for this link. I've heard of this

298
00:20:35,748 --> 00:20:39,066
one, the Cock proof assistant, but I've

299
00:20:39,098 --> 00:20:40,960
never seen it used or anything.

300
00:20:44,980 --> 00:20:48,820
Yeah, this looks pretty interesting.

301
00:20:48,890 --> 00:20:50,356
I wonder if anyone has done that kind of

302
00:20:50,378 --> 00:20:53,536
formal work on proving certain parts

303
00:20:53,568 --> 00:20:56,660
of FEP. And then a more

304
00:20:56,810 --> 00:21:01,544
distal question would

305
00:21:01,582 --> 00:21:03,956
be if we have formal ontology

306
00:21:04,068 --> 00:21:06,484
representations, for example with Sumo

307
00:21:06,532 --> 00:21:10,776
or otherwise, could we

308
00:21:10,958 --> 00:21:17,260
make proofs around the ontology and

309
00:21:17,410 --> 00:21:20,264
the Sumo suggested upper merged

310
00:21:20,312 --> 00:21:22,684
ontology? We explored some of those

311
00:21:22,722 --> 00:21:25,470
things but didn't go super, super far.

312
00:21:26,560 --> 00:21:31,656
It was just take

313
00:21:31,698 --> 00:21:35,010
somebody who knows that area. Okay,

314
00:21:37,620 --> 00:21:40,884
the bottom term bottom line an

315
00:21:40,922 --> 00:21:44,550
expectation over Q. But now our Q

316
00:21:45,560 --> 00:21:50,004
is on outcomes not focusing

317
00:21:50,052 --> 00:21:51,450
on the hidden states.

318
00:21:54,780 --> 00:21:59,160
Then it's an expectation about outcomes

319
00:22:01,100 --> 00:22:04,220
of a KL divergence

320
00:22:06,080 --> 00:22:10,076
between this

321
00:22:10,098 --> 00:22:13,912
is about hidden states. This KL

322
00:22:13,976 --> 00:22:19,488
divergence is zero when

323
00:22:19,574 --> 00:22:23,170
outcomes are not

324
00:22:24,340 --> 00:22:27,452
when in addition to policy, outcomes

325
00:22:27,516 --> 00:22:29,196
don't change how we think about hidden

326
00:22:29,228 --> 00:22:33,052
states. So when outcomes

327
00:22:33,116 --> 00:22:34,556
influence how we think about hidden

328
00:22:34,588 --> 00:22:38,370
states, this is going to be higher.

329
00:22:53,060 --> 00:22:56,964
And what

330
00:22:57,002 --> 00:23:00,304
does on the right? This is a triangle,

331
00:23:00,352 --> 00:23:03,712
meaning defined as so QS

332
00:23:03,776 --> 00:23:07,190
pi, O is defined as

333
00:23:08,360 --> 00:23:10,564
and this looks like a Bayes theorem

334
00:23:10,612 --> 00:23:11,210
situation.

335
00:23:13,900 --> 00:23:15,812
Like kind of that chaining that Eric

336
00:23:15,876 --> 00:23:16,730
just mentioned.

337
00:23:19,980 --> 00:23:23,324
Like you have P of O conditioned on S

338
00:23:23,362 --> 00:23:25,480
and then you have S conditioned on pi.

339
00:23:25,640 --> 00:23:30,568
So then those kind of like it's

340
00:23:30,584 --> 00:23:32,796
like a way to get from O through S to

341
00:23:32,818 --> 00:23:36,672
pi. Whereas this one on the bottom is

342
00:23:36,726 --> 00:23:39,680
just like going directly about O

343
00:23:39,750 --> 00:23:41,200
conditioned on pi.

344
00:23:44,420 --> 00:23:46,508
Which interestingly is I don't know if

345
00:23:46,534 --> 00:23:48,660
this is like in one of these or in some

346
00:23:48,730 --> 00:23:52,004
subsets of them. One can think

347
00:23:52,042 --> 00:23:55,590
about that kind of structural model like

348
00:23:55,960 --> 00:23:58,896
the minimum hidden Markov model, not

349
00:23:58,938 --> 00:24:00,632
even in its full framing, but just like

350
00:24:00,686 --> 00:24:02,628
what are the three pillars of the hidden

351
00:24:02,644 --> 00:24:05,124
Markov model? Observations, hidden

352
00:24:05,172 --> 00:24:08,072
states, policy, yes,

353
00:24:08,126 --> 00:24:11,412
transitions and so on. And so what

354
00:24:11,486 --> 00:24:14,412
is gained by going through an

355
00:24:14,466 --> 00:24:16,270
intermediary hidden state?

356
00:24:17,920 --> 00:24:20,140
There's going to be situations where the

357
00:24:20,210 --> 00:24:22,636
observable contains 100% of the

358
00:24:22,658 --> 00:24:26,496
information for policy. Or we

359
00:24:26,518 --> 00:24:29,564
can imagine situations where the ability

360
00:24:29,612 --> 00:24:33,330
to choose policies based upon S,

361
00:24:34,340 --> 00:24:37,204
which is where the actual POMDP is

362
00:24:37,242 --> 00:24:41,670
intervening is better.

363
00:24:42,200 --> 00:24:45,264
Whereas in a fully observable Markov

364
00:24:45,312 --> 00:24:49,156
decision process, you don't

365
00:24:49,188 --> 00:24:52,552
have S, you're just making

366
00:24:52,606 --> 00:24:54,010
decisions on O.

367
00:25:00,730 --> 00:25:03,334
Kind of just revisiting the point I

368
00:25:03,372 --> 00:25:07,114
raised earlier about what Otilda is. It

369
00:25:07,152 --> 00:25:11,034
seems to me that this only works when

370
00:25:11,072 --> 00:25:13,530
you have the observations O tilde.

371
00:25:14,430 --> 00:25:18,106
So I don't see how it could

372
00:25:18,128 --> 00:25:20,398
be anything like looking toward the

373
00:25:20,404 --> 00:25:22,654
future. Because if you actually want to

374
00:25:22,692 --> 00:25:27,002
carry out that expectation,

375
00:25:27,146 --> 00:25:30,354
you want to work out what Q is or use

376
00:25:30,392 --> 00:25:32,098
it, you have to compute it and you have

377
00:25:32,104 --> 00:25:34,226
to have the observations to compute it.

378
00:25:34,408 --> 00:25:36,900
And the S tilde you have to have

379
00:25:37,910 --> 00:25:41,800
actually pipe through and

380
00:25:42,410 --> 00:25:45,158
use them. So help me understand if I'm

381
00:25:45,164 --> 00:25:46,120
wrong with that.

382
00:25:56,640 --> 00:26:00,304
Okay, here would be one thought.

383
00:26:00,422 --> 00:26:03,712
The A matrix captures how hidden states

384
00:26:03,766 --> 00:26:06,336
mapped observations. So whether we have

385
00:26:06,358 --> 00:26:08,608
a really tight A matrix or whether we

386
00:26:08,614 --> 00:26:10,560
have a super dispersed A matrix,

387
00:26:11,560 --> 00:26:14,928
using the Gaussian form for the A matrix

388
00:26:15,104 --> 00:26:17,076
ensures that we can always say what the

389
00:26:17,098 --> 00:26:21,780
most likely observation is for

390
00:26:21,930 --> 00:26:24,456
a given hidden state. If we had a

391
00:26:24,478 --> 00:26:28,216
bimodal A matrix, then there

392
00:26:28,238 --> 00:26:31,976
are some issues. But if we use a

393
00:26:31,998 --> 00:26:33,210
Gaussian form,

394
00:26:35,760 --> 00:26:38,700
which is the Laplacian approximation,

395
00:26:39,360 --> 00:26:42,056
it's more tractable, it's monotonic,

396
00:26:42,088 --> 00:26:45,580
it's more optimizable. So for a given S

397
00:26:45,730 --> 00:26:49,264
sequences of S, we can

398
00:26:49,302 --> 00:26:53,520
always derive the expected observations.

399
00:26:54,100 --> 00:26:55,616
Again, those might have a lot of

400
00:26:55,638 --> 00:26:57,264
uncertainty around them, but we can

401
00:26:57,302 --> 00:26:59,388
always make a sequence of O's

402
00:26:59,564 --> 00:27:01,910
corresponding to any sequence of S.

403
00:27:03,640 --> 00:27:07,232
But this equation makes no expectation

404
00:27:07,296 --> 00:27:08,948
at all. Nothing says nothing about what

405
00:27:08,954 --> 00:27:10,596
the form of the distribution is that you

406
00:27:10,618 --> 00:27:12,676
use, whether it's parametric or not

407
00:27:12,698 --> 00:27:14,584
parametric or whatever. It's just saying

408
00:27:14,622 --> 00:27:16,330
you have a distribution Q.

409
00:27:19,020 --> 00:27:22,010
So this is how we evaluate it?

410
00:27:29,190 --> 00:27:32,754
Yes. Is this true for all families of

411
00:27:32,792 --> 00:27:36,558
distributions q Ali,

412
00:27:36,654 --> 00:27:37,634
what do you think about that or

413
00:27:37,672 --> 00:27:41,558
anything? Actually, it's interesting

414
00:27:41,644 --> 00:27:45,026
that in the step by step active

415
00:27:45,058 --> 00:27:47,974
inference paper, this epistemic value is

416
00:27:48,012 --> 00:27:50,310
defined somewhat differently.

417
00:27:50,890 --> 00:27:53,186
I'm not sure if they're exactly

418
00:27:53,308 --> 00:27:55,946
equivalent with each other or there are

419
00:27:55,968 --> 00:27:59,354
some minor differences between them,

420
00:27:59,392 --> 00:28:03,574
but they've just defined the epistemic

421
00:28:03,622 --> 00:28:06,330
value only in terms of the expectation

422
00:28:08,290 --> 00:28:10,750
over the surprisals.

423
00:28:12,450 --> 00:28:14,254
The. Difference between the Q and P

424
00:28:14,292 --> 00:28:20,418
surprisals. So we don't have this

425
00:28:20,504 --> 00:28:24,386
kind of expression as conditioned on the

426
00:28:24,488 --> 00:28:26,020
S tilde here.

427
00:28:30,070 --> 00:28:33,320
I don't know if they're the same or not.

428
00:28:36,410 --> 00:28:39,542
I don't know how to copy the image into

429
00:28:39,596 --> 00:28:42,806
this chat, but chat of the gatherer or

430
00:28:42,828 --> 00:28:45,660
just put it in here. Put it in the

431
00:28:46,350 --> 00:28:49,466
question. Okay. Yeah,

432
00:28:49,648 --> 00:28:53,786
well, one thought is policy

433
00:28:53,888 --> 00:28:57,440
is not an open ended policy

434
00:28:57,970 --> 00:29:00,078
in its specification is always going to

435
00:29:00,084 --> 00:29:03,226
be of a finite horizon. So if we're

436
00:29:03,258 --> 00:29:08,610
considering policies of length two so

437
00:29:08,680 --> 00:29:12,226
interestingly, this is a policy

438
00:29:12,328 --> 00:29:14,786
that includes leading up to the

439
00:29:14,808 --> 00:29:17,986
Presence. If this is the

440
00:29:18,008 --> 00:29:20,706
presence, I think we had one meme that

441
00:29:20,728 --> 00:29:23,526
was like what if my T minus one was T or

442
00:29:23,548 --> 00:29:26,406
something like that. But this is a

443
00:29:26,428 --> 00:29:29,830
policy that is influencing

444
00:29:31,130 --> 00:29:34,780
and this is just the variant of 43.

445
00:29:35,790 --> 00:29:36,886
But let's just say that we're

446
00:29:36,918 --> 00:29:39,050
considering policy of true future

447
00:29:39,120 --> 00:29:40,620
looking length two,

448
00:29:42,510 --> 00:29:46,942
then we're exploring different ways in

449
00:29:46,996 --> 00:29:50,826
which S is going to unfold with respect

450
00:29:50,858 --> 00:29:53,598
to basically B one and B two.

451
00:29:53,764 --> 00:29:55,886
Not using that in the SuperScript way to

452
00:29:55,908 --> 00:29:58,514
mean like two parallel B's, but just

453
00:29:58,552 --> 00:30:00,594
like there's our current, there's our

454
00:30:00,632 --> 00:30:03,934
estimate now and then there's

455
00:30:03,982 --> 00:30:06,146
the way that we have, let's just say

456
00:30:06,168 --> 00:30:08,754
four affordances. So then there's four B

457
00:30:08,792 --> 00:30:13,094
ones, and then now

458
00:30:13,132 --> 00:30:15,846
there's going to be four options for S.

459
00:30:16,028 --> 00:30:17,606
And then each of those four we could

460
00:30:17,628 --> 00:30:20,470
apply the second affordance again. So

461
00:30:20,540 --> 00:30:23,622
there's 16 policies to evaluate. Each

462
00:30:23,676 --> 00:30:25,994
one is defined by either taking, like,

463
00:30:26,032 --> 00:30:29,114
B one, B three, B one, B one, B four, B

464
00:30:29,152 --> 00:30:32,700
four, and for each of those S,

465
00:30:33,390 --> 00:30:37,610
in the next two time steps, we can emit

466
00:30:38,990 --> 00:30:40,090
observations.

467
00:30:41,550 --> 00:30:44,490
Ali and then rohan.

468
00:30:48,020 --> 00:30:50,984
Sorry, my hand. Just stay away.

469
00:30:51,102 --> 00:30:54,120
Sorry. Rohan.

470
00:31:03,160 --> 00:31:06,552
Hello. Yes, greetings. Yeah.

471
00:31:06,686 --> 00:31:10,660
So coming back to what the posterior

472
00:31:10,740 --> 00:31:12,090
distribution is, right?

473
00:31:15,980 --> 00:31:18,660
Isn't it just that we assume there's a

474
00:31:18,670 --> 00:31:21,772
posterior distribution of states, like

475
00:31:21,826 --> 00:31:24,364
an ideal posterior distribution that we

476
00:31:24,402 --> 00:31:27,996
want to that

477
00:31:28,018 --> 00:31:30,844
the free energy principle moves the

478
00:31:30,882 --> 00:31:32,540
current empirical distribution towards?

479
00:31:32,610 --> 00:31:34,624
Isn't that? I thought that's what we

480
00:31:34,662 --> 00:31:38,064
were doing from context in chapter one.

481
00:31:38,182 --> 00:31:38,850
Yes,

482
00:31:41,860 --> 00:31:45,540
go ahead. Yeah,

483
00:31:45,610 --> 00:31:48,516
sorry, cohort one, I think that's what

484
00:31:48,538 --> 00:31:50,980
we discussed. Right? So it's essentially

485
00:31:51,480 --> 00:31:53,156
trying to maintain some form of

486
00:31:53,178 --> 00:31:56,904
homeostasis. So whatever policies you

487
00:31:56,942 --> 00:31:59,192
have performed should eventually bring

488
00:31:59,246 --> 00:32:03,172
the system to that ideal homeostatic

489
00:32:03,236 --> 00:32:06,216
perspective. Right. So why couldn't we

490
00:32:06,238 --> 00:32:07,716
just assume, like, a normal

491
00:32:07,748 --> 00:32:09,348
distribution? So even if it is fat

492
00:32:09,364 --> 00:32:11,624
tailed, for example, the empirical

493
00:32:11,672 --> 00:32:15,800
distribution is like the P distribution

494
00:32:15,880 --> 00:32:20,492
in this formula has

495
00:32:20,546 --> 00:32:23,132
a heavy left tail, you can essentially

496
00:32:23,196 --> 00:32:25,072
bring it back towards that by

497
00:32:25,126 --> 00:32:27,536
essentially modifying the policy. That

498
00:32:27,558 --> 00:32:29,490
was the context of this. Right?

499
00:32:30,980 --> 00:32:34,116
Yes, broadly, you're right. So when we

500
00:32:34,138 --> 00:32:36,496
look at the full free energy, expected

501
00:32:36,528 --> 00:32:38,736
free energy formalization so here's

502
00:32:38,768 --> 00:32:42,132
equation 7.4 or equation 2.6,

503
00:32:42,266 --> 00:32:44,164
you're absolutely right that there's a

504
00:32:44,202 --> 00:32:47,370
pragmatic value that's based around

505
00:32:47,740 --> 00:32:50,500
reducing divergence between observations

506
00:32:50,580 --> 00:32:53,896
and preferences. But in equation one

507
00:32:53,918 --> 00:32:56,312
that we've been focusing on and trying

508
00:32:56,366 --> 00:32:58,564
to really unpack, because, again, also

509
00:32:58,622 --> 00:33:00,990
like O tilde is used in pragmatic value.

510
00:33:01,600 --> 00:33:03,550
We're only talking here about.

511
00:33:08,400 --> 00:33:10,092
But that would make sense, right?

512
00:33:10,146 --> 00:33:14,028
Because you're conditioning

513
00:33:14,124 --> 00:33:18,080
on your actions, having some effect

514
00:33:18,150 --> 00:33:20,624
on the state, on your own state and your

515
00:33:20,662 --> 00:33:22,704
state in the world or maybe some state

516
00:33:22,742 --> 00:33:25,236
in the world. So you have to

517
00:33:25,258 --> 00:33:27,972
continuously monitor until it comes down

518
00:33:28,026 --> 00:33:30,356
to the expected observation. That's what

519
00:33:30,378 --> 00:33:32,532
the generative model would spit out.

520
00:33:32,586 --> 00:33:35,350
Right, so it makes perfect sense and

521
00:33:36,220 --> 00:33:38,584
it's completely coherent in that way,

522
00:33:38,782 --> 00:33:43,192
right? Yes. I hope

523
00:33:43,246 --> 00:33:45,864
and expect and prefer that to be true.

524
00:33:45,982 --> 00:33:47,748
What you're describing about bringing

525
00:33:47,764 --> 00:33:49,836
the homeostatic variable closer to

526
00:33:49,858 --> 00:33:52,604
preferences expectations, that is

527
00:33:52,642 --> 00:33:53,790
pragmatic. Yeah.

528
00:33:56,640 --> 00:33:58,616
It wouldn't be surprising that Hotel

529
00:33:58,648 --> 00:34:00,524
does that in that P distribution as well

530
00:34:00,562 --> 00:34:02,768
as what I'm saying. No, it would need it

531
00:34:02,774 --> 00:34:05,184
to be there. You're right, it is needed

532
00:34:05,222 --> 00:34:06,892
to be there because these are surprises

533
00:34:06,956 --> 00:34:08,944
and entropies and so on about

534
00:34:09,062 --> 00:34:12,992
observations. And then this part

535
00:34:13,046 --> 00:34:16,848
is really digging into decompositions

536
00:34:16,944 --> 00:34:20,996
of epistemic value. So there

537
00:34:21,018 --> 00:34:23,300
might be two policies that are both

538
00:34:23,370 --> 00:34:25,888
expected to bring your temperature down

539
00:34:26,074 --> 00:34:28,632
or whatever, but they have different

540
00:34:28,686 --> 00:34:30,840
epistemic values.

541
00:34:33,180 --> 00:34:35,208
Does it matter if it just brings your

542
00:34:35,294 --> 00:34:37,976
temperature down? It would look the

543
00:34:37,998 --> 00:34:40,668
same. Essentially, it would have the

544
00:34:40,674 --> 00:34:43,150
same effect. So why does it matter?

545
00:34:45,360 --> 00:34:49,132
Why did we have to have this kind of

546
00:34:49,266 --> 00:34:50,632
yeah, so there would be multiple

547
00:34:50,696 --> 00:34:52,444
policies that would bring it down,

548
00:34:52,562 --> 00:34:54,528
bring the temperature down. If the

549
00:34:54,534 --> 00:34:55,964
preference is to bring the temperature

550
00:34:56,012 --> 00:34:57,936
down, it does not matter which policy is

551
00:34:57,958 --> 00:34:59,612
chosen. Right. So that's essentially

552
00:34:59,676 --> 00:35:02,050
what I think it's being said here.

553
00:35:02,740 --> 00:35:05,680
Okay, so as long as you minimize. The

554
00:35:05,750 --> 00:35:07,504
expected here's two investment

555
00:35:07,552 --> 00:35:11,108
opportunities from $100 150 plus or

556
00:35:11,114 --> 00:35:14,756
minus one or 150 plus or -200 which one

557
00:35:14,778 --> 00:35:18,036
do you want. That'S not

558
00:35:18,058 --> 00:35:21,336
what you were discussing it is the

559
00:35:21,358 --> 00:35:23,320
payoff space is very different. No,

560
00:35:23,390 --> 00:35:24,936
it's not the same thing. They are the

561
00:35:24,958 --> 00:35:27,432
payoff space expected ambiguity in the

562
00:35:27,486 --> 00:35:30,636
$200 plus or minus $200 is very

563
00:35:30,738 --> 00:35:32,940
different and your mutual information

564
00:35:33,010 --> 00:35:34,108
will be very different because the

565
00:35:34,114 --> 00:35:35,916
payoff space is different. Exactly. You

566
00:35:35,938 --> 00:35:38,684
are essentially taking yeah, but if

567
00:35:38,722 --> 00:35:41,070
something is going to bring down

568
00:35:41,600 --> 00:35:43,616
temperature plus or minus two, plus or

569
00:35:43,638 --> 00:35:47,328
minus four, it's not a huge difference

570
00:35:47,414 --> 00:35:49,360
as long as it brings it down. Right. So

571
00:35:49,430 --> 00:35:51,730
that's essentially what I'm getting at,

572
00:35:52,260 --> 00:35:55,604
why does it matter? Okay, so in this

573
00:35:55,802 --> 00:35:58,416
modeling, the body's expected

574
00:35:58,448 --> 00:36:00,644
temperature is like the expected return

575
00:36:00,682 --> 00:36:03,332
on investment and the variance around

576
00:36:03,386 --> 00:36:05,636
the expected temperature is like the

577
00:36:05,658 --> 00:36:08,040
variance around the investments.

578
00:36:09,740 --> 00:36:11,112
Right, but they wouldn't be the same

579
00:36:11,166 --> 00:36:13,096
policy is what I'm saying. Sorry. They

580
00:36:13,118 --> 00:36:14,936
wouldn't be the same payoff space in the

581
00:36:14,958 --> 00:36:18,612
second case. So if something generates

582
00:36:18,676 --> 00:36:22,520
$100 but has a low probability

583
00:36:22,600 --> 00:36:24,364
of going bust so that there's a high

584
00:36:24,402 --> 00:36:26,364
variance, that's not the same payoff as

585
00:36:26,402 --> 00:36:28,860
something that produces the same $100,

586
00:36:28,930 --> 00:36:32,016
but that has a lower variance, the

587
00:36:32,038 --> 00:36:34,704
payoff spaces are different and that

588
00:36:34,742 --> 00:36:37,788
will be captured in that callback

589
00:36:37,964 --> 00:36:40,976
diversions that you have there. It would

590
00:36:40,998 --> 00:36:44,576
prefer the one with the lower that's

591
00:36:44,608 --> 00:36:46,950
right, because the payoffs yeah,

592
00:36:48,440 --> 00:36:51,860
but I think the discussion was around if

593
00:36:51,930 --> 00:36:53,764
multiple things lead to the same

594
00:36:53,802 --> 00:36:56,772
epistemic value and they have the same

595
00:36:56,826 --> 00:37:00,356
payoff, why does it matter which one is

596
00:37:00,378 --> 00:37:03,336
taken? Right. There's that last piece.

597
00:37:03,438 --> 00:37:05,128
There may be multiple policies with the

598
00:37:05,134 --> 00:37:08,644
same pragmatic value and

599
00:37:08,782 --> 00:37:11,132
then epistemic value is the difference

600
00:37:11,186 --> 00:37:14,204
maker that favors policies that have

601
00:37:14,242 --> 00:37:16,780
more clarity about observation outcomes.

602
00:37:18,640 --> 00:37:22,430
Right. So pragmatic value

603
00:37:23,040 --> 00:37:23,950
would say.

604
00:37:26,100 --> 00:37:27,824
That'S not necessarily true. Let's say

605
00:37:27,862 --> 00:37:30,816
that. Okay. When the payoff space is

606
00:37:30,838 --> 00:37:34,036
completely unknown that the steps that

607
00:37:34,058 --> 00:37:37,044
you're taking at T equals one, two,

608
00:37:37,082 --> 00:37:41,060
three will bring down the will

609
00:37:41,130 --> 00:37:44,724
have the same pragmatic value. But one

610
00:37:44,762 --> 00:37:47,764
of these actions will lead to some very

611
00:37:47,802 --> 00:37:50,440
bad consequences at step T equals 15

612
00:37:50,590 --> 00:37:52,650
because you're giving up something else.

613
00:37:54,220 --> 00:37:55,976
It will be like paying space because.

614
00:37:55,998 --> 00:37:56,964
If we're talking about temperature,

615
00:37:57,012 --> 00:37:58,004
we're in the space of temperature.

616
00:37:58,052 --> 00:38:01,496
Okay, all right, so let's

617
00:38:01,528 --> 00:38:03,596
just bring it back to the finance. The

618
00:38:03,618 --> 00:38:05,900
space is dollars. That's the dollars

619
00:38:05,970 --> 00:38:06,590
space.

620
00:38:09,600 --> 00:38:11,964
Yeah. Okay, so we could use dollar as

621
00:38:12,002 --> 00:38:14,272
numerator. So we benchmarked the

622
00:38:14,326 --> 00:38:15,792
dollars. How many dollars we're making

623
00:38:15,846 --> 00:38:18,560
profit. So I have two investments,

624
00:38:20,740 --> 00:38:23,616
both of them generate $100, but one of

625
00:38:23,638 --> 00:38:27,044
them requires me to borrow $100 in order

626
00:38:27,082 --> 00:38:29,444
to generate $100. The other one would

627
00:38:29,482 --> 00:38:32,544
generate $100 over, say, 50 times steps.

628
00:38:32,592 --> 00:38:35,364
This would be quicker. The second one

629
00:38:35,402 --> 00:38:37,704
where you borrow $100. So it would be

630
00:38:37,742 --> 00:38:39,720
quicker because you're borrowing $100.

631
00:38:39,790 --> 00:38:41,816
But there's an interest rate that you

632
00:38:41,838 --> 00:38:44,250
have to pay out.

633
00:38:45,820 --> 00:38:48,996
So you will have to generate much more

634
00:38:49,038 --> 00:38:52,856
than $100 in order for this to be viable

635
00:38:53,048 --> 00:38:55,324
because you have an interest rate to pay

636
00:38:55,362 --> 00:38:58,780
off. Okay, try to follow up here.

637
00:38:58,930 --> 00:39:01,904
Policies are defined in terms of

638
00:39:01,942 --> 00:39:05,536
sequences of affordances to take. So the

639
00:39:05,558 --> 00:39:07,180
affordance here that you're highlighting

640
00:39:07,260 --> 00:39:08,850
is borrowing or not?

641
00:39:10,980 --> 00:39:14,508
Yes, but there are actions that

642
00:39:14,614 --> 00:39:17,412
would be like if you have a very high

643
00:39:17,466 --> 00:39:20,164
fever, in order to bring down that high

644
00:39:20,202 --> 00:39:22,932
fever, sometimes it makes sense to

645
00:39:22,986 --> 00:39:26,496
borrow that $100. Whatever metaphorical

646
00:39:26,688 --> 00:39:28,872
variation of that borrowing that you

647
00:39:28,926 --> 00:39:31,144
have to bring it down to something more

648
00:39:31,182 --> 00:39:34,344
manageable. Right. So it depends on how

649
00:39:34,382 --> 00:39:36,500
close you are to some sort of threshold

650
00:39:36,580 --> 00:39:38,360
where it's intolerable.

651
00:39:40,640 --> 00:39:44,108
I mean, putting it in more mundane terms

652
00:39:44,274 --> 00:39:48,136
that, hey, I have a bad toothache.

653
00:39:48,168 --> 00:39:50,136
It doesn't make sense for me to borrow

654
00:39:50,168 --> 00:39:52,296
$100 to fix my tooth. I could just brush

655
00:39:52,328 --> 00:39:54,204
my teeth and hope that it goes away,

656
00:39:54,322 --> 00:39:56,896
but I have a knife in my back, I need to

657
00:39:56,918 --> 00:39:59,696
get to the hospital. It makes sense to

658
00:39:59,718 --> 00:40:02,576
pay $100 because you're going to die if

659
00:40:02,598 --> 00:40:05,204
you don't. Okay, let me try to try to

660
00:40:05,322 --> 00:40:07,908
see this is how I'm seeing that is when

661
00:40:07,994 --> 00:40:11,780
we're near homeostasis,

662
00:40:12,520 --> 00:40:16,496
then we take actions that basically keep

663
00:40:16,538 --> 00:40:19,736
us there, and we try not to add risk to

664
00:40:19,758 --> 00:40:22,084
the situation. Whereas near the limits

665
00:40:22,132 --> 00:40:25,032
of our homeostatic tolerance, we may

666
00:40:25,086 --> 00:40:27,464
engage in high risk behavior because

667
00:40:27,502 --> 00:40:30,448
there's already a non negligible. Risk

668
00:40:30,484 --> 00:40:32,760
because the payoff space is much larger.

669
00:40:32,840 --> 00:40:34,712
Yeah, the payoff space, the positive

670
00:40:34,776 --> 00:40:37,070
payoff from your own life.

671
00:40:38,480 --> 00:40:44,496
No, it's not. The space is no. So when

672
00:40:44,518 --> 00:40:47,024
you have the knife in your back, the

673
00:40:47,062 --> 00:40:49,584
payoff from borrowing $100 will save

674
00:40:49,622 --> 00:40:51,964
your life. When you have a toothache,

675
00:40:52,012 --> 00:40:54,316
borrowing $100 might cause more risk

676
00:40:54,348 --> 00:40:57,236
that you go bankrupt. Right. But you

677
00:40:57,258 --> 00:40:59,252
will still survive. If you have a

678
00:40:59,386 --> 00:41:01,828
toothache, you're just short $100,

679
00:41:01,994 --> 00:41:03,940
which you could have used elsewhere.

680
00:41:04,280 --> 00:41:07,416
There is no way you can use that $100 if

681
00:41:07,438 --> 00:41:10,632
you're dead. Yeah, there's a much higher

682
00:41:10,686 --> 00:41:13,976
payoff borrowing at that point than it

683
00:41:13,998 --> 00:41:16,904
is with the toothache example. It

684
00:41:16,942 --> 00:41:19,288
depends on where you take these actions.

685
00:41:19,464 --> 00:41:22,796
I got you. I'm seeing the space are the

686
00:41:22,818 --> 00:41:25,790
axes. So here we have dollars and life.

687
00:41:26,640 --> 00:41:28,988
And so you're saying that yeah, but. It

688
00:41:28,994 --> 00:41:31,408
is a multidimensional, this one. So if

689
00:41:31,414 --> 00:41:34,544
you think about it as, let's say yeah,

690
00:41:34,662 --> 00:41:38,112
so let's make it more concrete. Right?

691
00:41:38,166 --> 00:41:41,650
So if you have a drone and

692
00:41:42,020 --> 00:41:44,656
you have a trade off between battery

693
00:41:44,688 --> 00:41:46,950
life and staying in the air,

694
00:41:48,200 --> 00:41:49,984
and let's say one of your propellers

695
00:41:50,032 --> 00:41:53,956
goes out, just redistributing power to

696
00:41:53,978 --> 00:41:55,796
the other motors so that you stay in the

697
00:41:55,818 --> 00:41:59,124
air even though it reduces your hover

698
00:41:59,172 --> 00:42:01,144
time. Makes more sense because you could

699
00:42:01,182 --> 00:42:04,600
land versus trying

700
00:42:04,670 --> 00:42:07,960
to fly around and then crash eventually

701
00:42:08,320 --> 00:42:10,220
because you lost one motor.

702
00:42:11,280 --> 00:42:16,588
But whereas let's say that the

703
00:42:16,674 --> 00:42:19,660
other option would be let's just go

704
00:42:19,730 --> 00:42:23,216
faster to a certain destination when it

705
00:42:23,238 --> 00:42:25,024
doesn't really make sense to do so,

706
00:42:25,062 --> 00:42:26,848
you're just reducing your battery life

707
00:42:26,934 --> 00:42:31,392
to get to a destination faster. But if

708
00:42:31,446 --> 00:42:33,104
something happens on the wave which

709
00:42:33,142 --> 00:42:35,524
causes you to lose your motor, then you

710
00:42:35,562 --> 00:42:38,548
don't have enough battery in order to

711
00:42:38,634 --> 00:42:40,388
enough battery power to distribute to

712
00:42:40,394 --> 00:42:42,324
the automotive so that you can hover and

713
00:42:42,362 --> 00:42:45,750
come down safely. Does that make sense?

714
00:42:47,180 --> 00:42:50,744
Eric. I wonder

715
00:42:50,782 --> 00:42:52,040
if we could table this particular

716
00:42:52,110 --> 00:42:55,528
discussion. It seems to be going and get

717
00:42:55,614 --> 00:42:57,016
back to some of the other questions in

718
00:42:57,038 --> 00:43:01,032
the chapter. We had a question

719
00:43:01,086 --> 00:43:03,816
that was pending from last week that I

720
00:43:03,838 --> 00:43:05,084
think is kind of critical to the

721
00:43:05,122 --> 00:43:06,508
understanding of the chapter, and I

722
00:43:06,514 --> 00:43:07,628
wonder if we could just want to make

723
00:43:07,634 --> 00:43:08,856
sure we have time for it, because we're

724
00:43:08,888 --> 00:43:10,590
running out of time here. Yeah,

725
00:43:12,100 --> 00:43:16,224
and that's the question about what

726
00:43:16,262 --> 00:43:20,656
the relative role is of how

727
00:43:20,678 --> 00:43:23,564
it actually operates, that the rat

728
00:43:23,612 --> 00:43:26,372
learns some information prior to

729
00:43:26,426 --> 00:43:28,628
deciding which of the two branches of

730
00:43:28,634 --> 00:43:31,808
the maze to take. And the way they seem

731
00:43:31,824 --> 00:43:33,716
to frame the chapter is that, well,

732
00:43:33,738 --> 00:43:38,392
they set it up so that the rat has

733
00:43:38,526 --> 00:43:41,544
its preference for epistemic value.

734
00:43:41,662 --> 00:43:43,928
Because of epistemic value of learning

735
00:43:44,014 --> 00:43:47,448
which of the two branches to take is a

736
00:43:47,454 --> 00:43:49,756
bigger term. It'll first go to the

737
00:43:49,778 --> 00:43:53,756
bottom branch and learn

738
00:43:53,858 --> 00:43:56,124
which of the two top branches has the

739
00:43:56,162 --> 00:43:59,036
payoff. Then once that's resolved, it

740
00:43:59,058 --> 00:44:02,064
knows that, then it decides which of the

741
00:44:02,182 --> 00:44:03,856
top branches to go to and it gets its

742
00:44:03,878 --> 00:44:07,072
reward. So my understanding of that is

743
00:44:07,126 --> 00:44:09,936
that and this is my claim in this

744
00:44:09,958 --> 00:44:13,636
question, is that the

745
00:44:13,658 --> 00:44:16,944
rat has a preference to resolve

746
00:44:16,992 --> 00:44:22,144
epistemic uncertainty regardless

747
00:44:22,192 --> 00:44:24,676
of whether it's useful or not. So if you

748
00:44:24,698 --> 00:44:27,690
added more uncertain questions like,

749
00:44:29,660 --> 00:44:33,848
what color is my apple today?

750
00:44:34,014 --> 00:44:36,760
But there's no apple to be gotten,

751
00:44:38,060 --> 00:44:39,724
it'll still want to resolve that

752
00:44:39,762 --> 00:44:42,444
question and any other questions because

753
00:44:42,562 --> 00:44:45,416
those are uncertainties. So epistemic

754
00:44:45,448 --> 00:44:47,656
value, it'll collect that epistemic

755
00:44:47,688 --> 00:44:50,300
value, and then finally it gets around

756
00:44:50,370 --> 00:44:52,880
to collecting its reward.

757
00:44:54,500 --> 00:44:57,424
That's in contrast to a model where the

758
00:44:57,462 --> 00:44:59,324
purpose of resolving epistemic

759
00:44:59,372 --> 00:45:02,108
uncertainty is to gain the reward,

760
00:45:02,204 --> 00:45:04,916
which requires look ahead.

761
00:45:05,098 --> 00:45:08,276
So in other words, the planner or the

762
00:45:08,298 --> 00:45:11,892
policy would be, I try to learn

763
00:45:11,946 --> 00:45:14,772
what's needed to collect the reward. I

764
00:45:14,826 --> 00:45:17,740
do that, and that's posted as epistemic

765
00:45:17,840 --> 00:45:19,880
value with a purpose,

766
00:45:21,420 --> 00:45:24,392
then the order of operation is,

767
00:45:24,446 --> 00:45:26,200
okay, I figure out what I need to know,

768
00:45:26,270 --> 00:45:28,216
I learn what I need to know, then I go

769
00:45:28,238 --> 00:45:32,108
and do the exploitation. So that's what

770
00:45:32,114 --> 00:45:34,504
I would expect that this kind of framing

771
00:45:34,552 --> 00:45:35,836
would give us, but I don't see that

772
00:45:35,858 --> 00:45:38,124
that's what you're actually giving us.

773
00:45:38,322 --> 00:45:41,648
All right, here's how I

774
00:45:41,734 --> 00:45:44,736
see that. The example that we would want

775
00:45:44,758 --> 00:45:48,496
to see would have a

776
00:45:48,518 --> 00:45:51,916
bunch of uncertainty resolving

777
00:45:51,948 --> 00:45:53,136
this one picks a number between one and

778
00:45:53,158 --> 00:45:54,528
ten and tells you what it is. This one's

779
00:45:54,544 --> 00:45:56,148
a number between one and a million. So

780
00:45:56,234 --> 00:45:58,740
it's an incredible information resolving

781
00:45:59,160 --> 00:45:59,910
button.

782
00:46:01,480 --> 00:46:05,380
Then the question is can the relevant

783
00:46:06,540 --> 00:46:09,050
sources of information be sought after?

784
00:46:15,670 --> 00:46:19,534
I think the examples is prepared

785
00:46:19,582 --> 00:46:22,754
in several ways. For example, the rat

786
00:46:22,802 --> 00:46:26,630
already knows the semantics that

787
00:46:26,700 --> 00:46:30,386
this is related to here that's

788
00:46:30,418 --> 00:46:33,946
been just the structure of the model is

789
00:46:33,968 --> 00:46:40,170
already preparing that any

790
00:46:40,240 --> 00:46:43,820
uncertainty reduction about this

791
00:46:44,590 --> 00:46:46,798
basically it's already encoded in the

792
00:46:46,804 --> 00:46:48,782
model that this bottom queue is

793
00:46:48,836 --> 00:46:50,480
information about this.

794
00:46:52,770 --> 00:46:57,326
So this is kind of like saying and

795
00:46:57,348 --> 00:47:00,946
this relates earlier, not only are those

796
00:47:01,048 --> 00:47:06,046
implicit structurally encoded aspects

797
00:47:06,078 --> 00:47:08,670
of knowledge but also there's

798
00:47:08,750 --> 00:47:10,626
parameterization questions like we

799
00:47:10,648 --> 00:47:14,406
discussed if it has a

800
00:47:14,428 --> 00:47:19,206
dire urgency for food to

801
00:47:19,308 --> 00:47:20,806
the earlier questions about like the

802
00:47:20,828 --> 00:47:23,986
urgency of the imperative it may just go

803
00:47:24,028 --> 00:47:26,554
for it. And so I'd rather have a 50 50

804
00:47:26,592 --> 00:47:30,890
shot now than a 98% in two timesteps.

805
00:47:31,310 --> 00:47:34,170
So it depends on how it's parameterized

806
00:47:35,470 --> 00:47:38,222
but even more deeply it depends on the

807
00:47:38,276 --> 00:47:42,062
construction of the model, what kinds of

808
00:47:42,116 --> 00:47:44,174
relationships are implicitly and

809
00:47:44,212 --> 00:47:49,120
explicitly being linked and

810
00:47:50,050 --> 00:47:54,066
it's like a deep level of modeling to

811
00:47:54,088 --> 00:47:56,642
understand what would be like a more

812
00:47:56,696 --> 00:48:00,690
neutral way to frame

813
00:48:01,190 --> 00:48:02,486
this question. And then it's like well,

814
00:48:02,508 --> 00:48:03,718
how many layers back do you want to

815
00:48:03,724 --> 00:48:06,786
pull? Like you could have a preplay

816
00:48:06,978 --> 00:48:10,658
where a rat has an association matrix,

817
00:48:10,834 --> 00:48:13,654
there's three information sources and

818
00:48:13,692 --> 00:48:15,722
it's allowed to freely explore without

819
00:48:15,776 --> 00:48:18,554
any shock or food and determine which

820
00:48:18,592 --> 00:48:21,114
one of these information sources has

821
00:48:21,152 --> 00:48:22,746
like a causal relationship to these

822
00:48:22,768 --> 00:48:25,686
edges. And then there's a learnt queue

823
00:48:25,718 --> 00:48:29,066
that now we're in game time and now it's

824
00:48:29,098 --> 00:48:32,414
going to rely on its past learning about

825
00:48:32,532 --> 00:48:35,834
which information resource is relevant

826
00:48:35,882 --> 00:48:40,716
for the Pragmatic value and

827
00:48:40,738 --> 00:48:42,656
then it's I mean there's just how many

828
00:48:42,678 --> 00:48:46,672
layers back does one need to pull before

829
00:48:46,726 --> 00:48:49,936
the rabbit is not in the hat? I think is

830
00:48:49,958 --> 00:48:53,588
going to be a serious question because

831
00:48:53,674 --> 00:48:55,924
even toy demonstrations have been seen

832
00:48:55,962 --> 00:49:00,390
as slam dunk and they're not.

833
00:49:03,510 --> 00:49:05,742
Well since they're bringing up Palm DPS

834
00:49:05,806 --> 00:49:07,346
here palmdps are really good for

835
00:49:07,368 --> 00:49:09,366
planning but they don't have this rat do

836
00:49:09,388 --> 00:49:10,786
any planning. It seems like they're

837
00:49:10,818 --> 00:49:14,610
really not aspiring very strongly

838
00:49:14,690 --> 00:49:17,058
to build a smart rat here and they're

839
00:49:17,074 --> 00:49:18,360
not achieving it either.

840
00:49:20,830 --> 00:49:28,140
Yeah, it's true because here

841
00:49:29,790 --> 00:49:33,086
the first movement again presuming that

842
00:49:33,108 --> 00:49:34,814
the parameterization is such that

843
00:49:34,852 --> 00:49:36,830
epistemic value is salient.

844
00:49:37,890 --> 00:49:40,266
The first move is dominated by epistemic

845
00:49:40,298 --> 00:49:41,982
value and they say well, now that that

846
00:49:42,036 --> 00:49:44,722
value has been tapped, now it can step

847
00:49:44,776 --> 00:49:47,074
into pursuing Pragmatic value with even

848
00:49:47,112 --> 00:49:48,450
increased confidence.

849
00:49:51,510 --> 00:49:56,302
But it's not considering the

850
00:49:56,376 --> 00:50:02,804
set of time horizon two policies that

851
00:50:02,842 --> 00:50:07,590
is not being explicitly encoded or.

852
00:50:12,460 --> 00:50:14,780
That means that. Even implicit yeah,

853
00:50:14,930 --> 00:50:18,156
these are transition matrices. These are

854
00:50:18,178 --> 00:50:20,716
just the four options depending on where

855
00:50:20,738 --> 00:50:24,750
you are. You can stay,

856
00:50:25,200 --> 00:50:26,690
you can go down.

857
00:50:34,650 --> 00:50:38,278
Yeah. Does section. 73 address

858
00:50:38,364 --> 00:50:39,270
planning.

859
00:50:51,990 --> 00:50:54,740
And if it doesn't, why do we need g?

860
00:50:57,510 --> 00:50:59,854
Why can't we just use a one step

861
00:50:59,912 --> 00:51:03,430
variational free energy approximation?

862
00:51:12,520 --> 00:51:13,936
It's saying, what's the most likely

863
00:51:13,968 --> 00:51:15,750
thing for me to do right now?

864
00:51:17,580 --> 00:51:19,850
Is a question about now in the past.

865
00:51:22,780 --> 00:51:24,344
Well, I think the answer to the question

866
00:51:24,382 --> 00:51:26,024
is exactly as you said it before, which

867
00:51:26,062 --> 00:51:28,804
is they baked in this particular

868
00:51:28,942 --> 00:51:32,030
hardwired rat, for which in this case,

869
00:51:32,880 --> 00:51:34,990
the best thing to do is to first

870
00:51:35,920 --> 00:51:39,112
explore, learn, and then exploit.

871
00:51:39,256 --> 00:51:42,384
So they designed it to do only this by

872
00:51:42,422 --> 00:51:44,764
rote to do the right thing, as opposed

873
00:51:44,812 --> 00:51:48,064
to the rat actually doing any

874
00:51:48,102 --> 00:51:50,368
look ahead or any intelligence to do the

875
00:51:50,374 --> 00:51:52,924
right thing. Yeah, it's structurally

876
00:51:53,052 --> 00:51:54,640
implicitly hardwired,

877
00:51:56,200 --> 00:51:59,572
and then it's fine tuned because again,

878
00:51:59,626 --> 00:52:01,396
there's structures where it wouldn't do

879
00:52:01,418 --> 00:52:03,156
this and there's tunings where it

880
00:52:03,178 --> 00:52:08,520
wouldn't do this, but in

881
00:52:08,590 --> 00:52:11,050
the tens place and in the decimal point.

882
00:52:12,060 --> 00:52:15,044
This example exists in a very limited

883
00:52:15,092 --> 00:52:18,708
manifold of models and parameterizations

884
00:52:18,804 --> 00:52:22,072
where one step optimal policies emulate

885
00:52:22,136 --> 00:52:25,564
two step planning. Like, I just happen

886
00:52:25,602 --> 00:52:28,380
to love sacrificing pawns and taking

887
00:52:28,450 --> 00:52:30,748
castles, so I'm willing to sacrifice a

888
00:52:30,754 --> 00:52:32,444
pawn so that later I can do a castle.

889
00:52:32,492 --> 00:52:34,224
But of course, you can't walk around

890
00:52:34,262 --> 00:52:35,184
with the belief that you love

891
00:52:35,222 --> 00:52:36,720
sacrificing pawns.

892
00:52:38,020 --> 00:52:41,264
Yeah, I actually wondered why

893
00:52:41,302 --> 00:52:43,328
there wasn't enumeration of policies in

894
00:52:43,334 --> 00:52:44,560
the planning section.

895
00:52:50,300 --> 00:52:51,050
Okay,

896
00:52:54,820 --> 00:52:58,784
learning hyperpriers hidden states on

897
00:52:58,822 --> 00:53:02,304
hidden states, seeing hidden

898
00:53:02,352 --> 00:53:06,784
states as outcomes of other hidden

899
00:53:06,832 --> 00:53:10,036
states so that they can be learned or

900
00:53:10,058 --> 00:53:10,820
fixed.

901
00:53:15,100 --> 00:53:19,156
Little bit of technical details on multi

902
00:53:19,188 --> 00:53:21,496
parameter minimization theta being just

903
00:53:21,518 --> 00:53:23,128
the vector of parameters for the

904
00:53:23,134 --> 00:53:25,408
generative model and deer Schlee

905
00:53:25,444 --> 00:53:29,564
distributions, which I think could

906
00:53:29,602 --> 00:53:30,876
be gotten into, but that's kind of

907
00:53:30,898 --> 00:53:36,514
distribution specific creatures

908
00:53:36,562 --> 00:53:37,878
select the most appropriate data to

909
00:53:37,884 --> 00:53:39,510
improve their generative models.

910
00:53:46,850 --> 00:53:48,414
I think there's more that we can dig

911
00:53:48,452 --> 00:53:51,470
into and explore on similar wavelengths

912
00:53:52,370 --> 00:53:55,186
like risk plus ambiguity, but then now

913
00:53:55,208 --> 00:53:58,386
there's an information gain. I thought

914
00:53:58,408 --> 00:54:00,530
we just had risk plus ambiguity.

915
00:54:05,480 --> 00:54:12,670
Then we didn't really yeah,

916
00:54:12,740 --> 00:54:15,246
people point to structure learning, but

917
00:54:15,268 --> 00:54:18,398
don't they always as a way to get around

918
00:54:18,484 --> 00:54:19,840
these questions.

919
00:54:22,150 --> 00:54:23,826
But then it's the structure of the

920
00:54:23,848 --> 00:54:26,706
structure learner, and then people end

921
00:54:26,728 --> 00:54:29,934
up with these turing machines that don't

922
00:54:29,982 --> 00:54:30,580
plan.

923
00:54:34,690 --> 00:54:36,562
People hope that Bayesian model

924
00:54:36,616 --> 00:54:39,394
reduction will be attractable and

925
00:54:39,432 --> 00:54:40,926
provide heuristics for structure

926
00:54:40,958 --> 00:54:44,446
learning. But I haven't

927
00:54:44,478 --> 00:54:46,786
seen any empirical examples that come to

928
00:54:46,808 --> 00:54:49,926
mind where Bayesian model reduction was

929
00:54:49,948 --> 00:54:52,998
used to identify actionable lower

930
00:54:53,084 --> 00:54:57,190
dimensional useful models.

931
00:54:59,210 --> 00:55:02,026
But we know that structure learning on

932
00:55:02,128 --> 00:55:04,646
the state space of hierarchical models

933
00:55:04,678 --> 00:55:06,486
is going to be essential active

934
00:55:06,518 --> 00:55:10,042
inference or beyond, because people

935
00:55:10,096 --> 00:55:11,626
thought that the explosions, the

936
00:55:11,648 --> 00:55:13,486
computational complexity class of just

937
00:55:13,508 --> 00:55:15,214
branching time, active inference or

938
00:55:15,252 --> 00:55:18,206
anything within a model. This is going

939
00:55:18,228 --> 00:55:21,214
to be like exploding upon that by

940
00:55:21,252 --> 00:55:22,590
several exponents.

941
00:55:26,180 --> 00:55:28,240
And we have these fundamental questions

942
00:55:28,310 --> 00:55:29,680
about the continuous time

943
00:55:29,750 --> 00:55:30,880
interpolations.

944
00:55:34,820 --> 00:55:37,120
Why are there continuous interpolations

945
00:55:39,720 --> 00:55:43,844
in chapter seven when

946
00:55:43,882 --> 00:55:47,670
it's the discrete time chapter? Okay,

947
00:55:48,280 --> 00:55:50,756
next time we come to chapter eight, I

948
00:55:50,778 --> 00:55:51,956
think this will be quite interesting.

949
00:55:52,058 --> 00:55:53,344
We're going to talk about dynamical

950
00:55:53,392 --> 00:55:56,960
systems, motor control, lock of Ultera.

951
00:55:57,040 --> 00:55:59,072
We'll have some justified continuous

952
00:55:59,136 --> 00:56:02,032
lines, LaPlace assumption,

953
00:56:02,096 --> 00:56:05,656
Lorenz stream number 32, stochastic

954
00:56:05,688 --> 00:56:07,420
chaos and Markov blankets.

955
00:56:09,200 --> 00:56:11,752
Hybrid models with discrete continuous

956
00:56:11,816 --> 00:56:15,384
fusion and some advances

957
00:56:15,432 --> 00:56:17,260
in continuous time modeling.

958
00:56:18,560 --> 00:56:21,150
Thanks everybody. See you soon.

959
00:56:22,480 --> 00:56:23,050
Thanks everyone.


