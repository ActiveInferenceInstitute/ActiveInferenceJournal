start	end	paragNum	speaker	confidence	startTime	wordCount	text
1690	31320	1	A	0.99987	00:01	57	Hello, everyone. It is June 16, 2022, and it's meeting seven of the active textbook textbook group Cohort one. We're in our second discussion of chapter three today. We'll be looking at the questions that haven't been addressed, so the ones without thumbs. And also, it's not too late to add more questions or to upvote questions.
32170	77720	2	A	0.75	00:32	89	And then additionally, since the Math Learning Group has been quite active in providing synchronous affordances for conversation around some of the background on the Math as well as some aspects of the equations that we'll go through today and also even to applications of the math and developing notebooks and such. We'll take a look at the math in our move through chapter three. Before we go to the questions, does anyone have anything that they just want to remark on chapter three, Ali and then anyone else?
80650	132870	3	B	0.96632	01:20	111	Yeah. Well, last week I talked about how I changed my mind about these bottom up and top down characterizations of low road and high road, respectively, after reading chapter three, but it turns out that they are, in fact, bottom up and top down approaches after all. You see, I came across this, in my opinion, undeservedly lesser known piece of beautiful, beautiful writing by Karl Frisden which explicitly argues for such characterizations and the philosophical importance of this distinction. It's called beyond the Desert Landscape, and it's inconspicuously hidden in this book, Andy Clark and his critics. So I'd like to quote a couple of sentences from this writing.
133530	196300	4	B	1.0	02:13	131	Well, he writes quote the high road stands in for a top down approach that starts by asking fundamental questions about the necessary properties things must possess if they exist. Using mathematical variational principles, one can then show that existence is an embodied exchange of a creature with its environment that necessarily entails predictive processing as one aspect of a self evidencing mechanics. The low road is the purpose. The agenda established is to pursue the agenda established by Kant and Hellholtz and generalize in a bottom up way, the capacity for inference and prediction to see how far it takes us in understanding embodied exchange with the environment. So if anyone likes to gain a deeper understanding about these conceptual characterizations, I highly, highly recommend this chapter of this book.
196990	217118	5	B	1.0	03:16	34	And quite unusually for Frison writing, it also lacks any mathematical formalism. It doesn't include a single mathematical equation there. Thank you. Yeah. In a recent stream, we also talked about the desert landscape.
217134	274082	6	A	0.84	03:37	110	And Clark's concern was that we might do away with what populates are implicitly assumed to be rich ecosystems of psychology, philosophy and so on, with important ecosystem players like goals. And so the fear or concern was that we might be in a quineyan desert landscape. If we replace some of these, again, implicitly or explicitly stated, to be rich constructs like goals, and we're like, well, it's just distribution matching, then we've made some sort of like a desert monoculture. And that would be depoprant of what does Clark say to his desert living critics? All right, if anyone else has a thought, they can raise their hand.
274136	302270	7	A	0.95925	04:34	65	Otherwise we can look at the questions. Okay, so this first question if one defines preferred states as expected states, one can say living organisms must minimize the surprise of their sensory observations. I'm not clear on the ontology here. Is it that preference is the same as expectation or that formally we can use them in the same equation? Is that an ontological claim?
302850	324340	8	A	1.0	05:02	47	And is the free Energy and physics an analogy or an ontological assertion about how things really are? So one starting place was I found the slide and so wanted to highlight it. This was in Free Energy, a user's guide which was live. Stream number 37.
326810	329190	9	A	0.96	05:26	8	The slides will be probably a little bigger.
332250	357710	10	A	0.92442	05:32	64	It's worth restating just how unusual it is to interpret P as a measure of both probabilities and preferences. They both start with P, though there's nothing wrong with treating a distribution as a measure of preferences because distributions can have different interpretations. But what's unorthodox and in need of justification is giving the same mathematical term two different interpretations within the same equation.
359730	404590	11	A	0.94145	05:59	68	They then add some more details that unpack a little bit about how it is the case that the same term, P can be utilized as both a probability and a preference. And then they even extended it into a third P, the, the PH fitness, where by allowing your probabilities and your preferences to converge to reduce the divergence between those two distributions, then fitness is achieved.
407010	421380	12	A	0.55	06:47	22	And so they provided a restatement of the way that that is implemented and then highlighted in additional grounding or interpretive line.
425370	431320	13	A	1.0	07:05	9	So that's at least one part of that question.
437010	463270	14	A	1.0	07:17	58	And also to look towards the equations. It's something that we'll be able to have very clear answers for and thanks to the work of Ali and Blue and others who have been annotating equations. So for example, in equation 3.1, or we can look at like box one, equation one, which is like a Markov blanket definition.
465550	550750	15	A	1.0	07:45	175	In the description field we have a natural language description and then the terms that are used in the description are those that are referenced using variables. So that will help us translate across natural language of different human languages, the discrete and continuous time formalisms which we're going to explore in this textbook, also identical or isomorphic or related formalisms in other papers which sometimes are using the same notation letters, but not always. But we could have another column for first in 2019 and here's first in 2013 and then there's a conversation to be had about where they align or don't. And that's the kind of annotation work that somebody can engage in from the publications and that also helps us connect it to the programmatic implementations like in Active Block, for instance, or in other scripts. So that even that we can promote norms and practices around variable naming in math and in programming, but also where there is divergences or differences which are important for innovating and evolving the norms.
550910	608920	16	A	1.0	09:10	126	We can also map them pretty coherently so all the equations for three can be read naturally. So we discussed this a lot in the math group and again, a lot of people contributed to this with one of the goals or functions being that whenever we are going to bring up an equation, like if there's a question about equation 3.1. We can just briefly read the current state of the description. Because whether you're super familiar with the letters and variables and how they're concatenated, or whether it's just like a first pass on your seeing this equation. Everybody will benefit when we align our regime of attention to actually what it says, and then that will help us do many, many other things.
612620	665450	17	A	0.99991	10:12	78	But to return back to this question, does anyone want to raise their hand and give a thought on the relationship between preference and expectation? Ontological claims about preference and its relationship with expectation and more generally, is the free energy something that is an analogy or mathematical isomorphism or an equation that rhymes or is it also an assertion? It it's an equation that rhymes. What makes you say that? No, just because it's cute, that's all.
669120	678370	18	C	0.99	11:09	21	I just joined the conversation. But preference and expectation, I wouldn't think they were at all referring to the same thing.
681060	711800	19	C	0.99952	11:21	47	Expectation is a mathematical operator. Preference is a statement. Yes. Expectation is used in multiple ways. It can refer to predictions about the mean or the mode or other attributes of a future time point like I'm expecting, what are you expecting to happen on next Monday?
712700	750500	20	A	0.99984	11:52	91	Also, expectation can refer and that's how it's used with the fancy e to refer to the expected value of a distribution which for a gaussian is the mode in the center of a symmetric peak. And that doesn't need to be about a future time point, that can just be the expectation of the height of the classroom. Right now it's not saying that's what we're expecting it to be in a year as it might be used conversationally but it's referring to just like the average of a distribution.
753560	765870	21	C	0.87723	12:33	18	Right? Mathematically it's an operator and verbally it. Can be. A prediction or a desire or something. Yes.
766720	816780	22	A	0.9	12:46	97	And then again in 37 and elsewhere it'll be worth returning to this again and again because it's one of the essential architectural decisions in active inference that enable it's part of the necessity and sufficiency complex. I don't know whether this is the whole meat of it, but it's part of what allows the dispensal of an explicit reward term, like a homeostatic reinforcement. Reward driven learner would be like, I'm more rewarded by being in my homeostatic range. And then there needs to be this architecture around. Well, how are we going to pursue reward?
818480	846150	23	A	0.99584	13:38	61	Alternatively, an organism trying to maintain homeostasis realism or us modeling an organism that is maintaining homeostasis instrumentalism. We can just say it expects to be in the range. That conversationally we're going to describe as a preference. How do we know? We put the animal in the room and it's spending a lot of its time on this warmer side.
847160	890960	24	A	1.0	14:07	99	It prefers to be there. We also expect it to be there. We're less surprised when we see it there. So then it's possible to as they right here interpret that p location distribution in the room for the animal that we're observing or the temperature distribution for the body in the homeostatic context as being a probability density over. Temperatures over locations as well as reflecting the preferences, not the qualia or the phenomenology or anything like too far out about what it means to prefer where preferences arise from, whether they're fixed or learned in the model.
891030	906520	25	A	1.0	14:51	33	All these many, many trails that can come out of that. But just at this essential layer, we don't need to interpolate a reward term between what is expected and what is preferred.
913240	917290	26	A	0.99474	15:13	11	Any other comments from someone? Yes, Eric, and then anyone else?
919980	944224	27	D	0.93381	15:19	60	Yeah, just to remark on that, it seems you're still not removing the free variable of what the preference of the agent organism is. You're just holding it. You're putting it in a different place so that you can use it in this unified equation. But you still have this it's a free variable. What do you want to do?
944262	962900	28	D	1.0	15:44	58	Okay, I'm going to call that an expectation. And that's what I'm going to try to drive for when I optimize my variational, free energy. But in that sense, it's kind of a convenience or it's a trick. It's a little bit of an unnatural act. I don't know the way I think of it, for a purpose.
966540	977800	29	D	0.48269	16:06	20	But you haven't solved any other problem. The deeper problem of what should the organism attempt to achieve the goals.
981680	983900	30	A	1.0	16:21	3	Yes. Thanks, Ali.
988720	1020730	31	B	1.0	16:28	48	Well, I think it also might be quite helpful to refer back to chapter two on page 36, I think. Yeah, page 36 here they have actually distinguished between the term prediction and exactly. Yes. Here the term prediction and expectation quite explicitly in terms of equation 2.6.
1023740	1027290	32	A	0.93	17:03	7	Okay. So let's look at equation 2.6.
1030140	1045180	33	A	0.79	17:10	30	Okay. A few of them, we don't have the third line fully described, but just here's the third line. What does this speak to with respect to preferences and expectations?
1049940	1058870	34	B	0.98081	17:29	15	Here the preference actually is in the second term, the Kullback Leibler divergence. Here. Yeah.
1061400	1087950	35	B	0.87402	17:41	52	It's actually inherent in the second term. And the expectation, expected ambiguity, as it speaks for itself is the first term. So we have here the risk is defined as the divergence between the preference and the states. So I think that we can see the preference in this equation as well.
1090320	1122760	36	A	1.0	18:10	73	One note here is like that this G is equal to the first, the second, and this line. But one way that we can understand the relationship of the second and the third line is like they're very similar. The first term is identical here. The only difference is that instead of a Y, we see an X. And so this is like X being the hidden state and Y being the observation.
1125660	1178760	37	A	1.0	18:45	120	In the case where it's a fully observable Markov process, then the outcomes and the hidden states are going to be like equal uncertainty about them. Because in that case it's functionally that the hidden states are observables. However, if there's any amount of ambiguity like the a matrix between the hidden state and the observable, then there's always going to be more uncertainty about the hidden state relative to the observable. And then importantly, on both sides there's a conditioning vertical line on policy selection. And so that is what prevents us from getting into the like, well, what if it's 95% correct or 96 or 97% correct or any of these sort of like model diminishing returns debates.
1179100	1242620	38	A	0.71008	19:39	143	It's a functional that's calculated for each policy that have been possible of composing given the affordances. A policy is just a sequence of actions. So if there's four movement affordances, there's four policies of time depth one, there's 16 policies of time depth two, and so on and for whatever in this discrete, formalism, finite set of policies, there are they're evaluated here and then there's a policy selection that could choose the lowest expected free energy, or it could proportionally choose from them with different kinds of weighting and so on. But this is comparing the relative expected ambiguity and risk conditioned upon different specific policies. And there's a process by which those specific policies can be enumerated and then this is a process by which they're going to be evaluated and then there's a policy selection by which they're selected.
1243060	1276970	39	A	1.0	20:43	74	So organisms that fail to do this adequately enough will be dissipated. Or systems, whether it's just a molecular system or some other kind of statistical system that fail to do this well enough to remain being that kind of thing, are not amenable to repeated measurements. They are not that thing. But things that remain being that thing for the time horizon of observations will be selecting policies that are consistent with this.
1279660	1286430	40	A	0.99982	21:19	17	Can I ask a question about this? Yeah, about this equation here, say like the second line.
1289600	1310850	41	D	0.51	21:29	51	So first of all, see the preferences is not really spelled out very much in this chapter and I don't know where it will be, but I would have expected something more like preferences given observations like the observations, what's happened in the world that we can measure that's observation. Why?
1313240	1343024	42	D	0.91	21:53	71	And then how does that fit with my preferences? So what I want to optimize is my preference, the achievement of my preferences as delivered by the observations. Now, I understand that in that second equation you're going to do a divergence between observations, the Y tilde. So you can't flip around p of C given y tilde there. So can somebody explain to me how this all fits together then?
1343062	1346560	43	D	0.99999	22:23	8	How do you achieve preferences under that equation?
1348660	1361780	44	A	0.57439	22:28	29	I'll give one thought and I absolutely agree to the first point, which is like c is just like I don't even know if it's described in this chapter.
1363800	1381276	45	B	0.91	22:43	23	34, I think. 34, let me check it again. I mean there is he said parameter. Includes preferences but it includes parameter. Yeah.
1381378	1398370	46	B	0.62	23:01	33	And also if you go to section 7.4 I think yes, in that section it is untangled why these two parameters are related and how these two parameters are related to each other.
1405220	1457184	47	A	0.94054	23:25	115	That's like multiple scales of where the information is not provided before when it needs to be provided. Which is like this I have made as just a helpful diagram of the partially observable Markov decision process which is C is the preferences and it influences how G evaluates policies which are generated from affordances over a given time horizon. Policies intervene upon how hidden states change in the world and there's more in different readings. But to return to Eric's question and then again, anyone with the raised hand so the question was whether we're comparing outcomes or states, how does this second term help us realize our preference? Well, when is the KL?
1457312	1503680	48	A	0.9843	24:17	104	We're trying to minimize g of pi better policies have a lower score. It's like golf, I guess, or you could add negatives and make it higher. And also just it's an interesting note like climbing Mount Improbable, biologists often think about the fitness peak and climbing to fitness peaks, whereas for a physicist it's often framed. And also like computer science gradient descending and local minima, global minima, but they're just actually like the same landscape with some negative signs. So the KL divergence and here we're trying to minimize if it's zero that would mean like we are perfectly realizing our preference.
1504500	1558084	49	A	1.0	25:04	123	So let's just say that there's two policies that we're comparing between and one of them is going to perfectly realize our preferences, the other one isn't. So we have like pi one and pi two and we're going to be calculating the KL divergence of the outcomes that we're expecting under the variational distribution Q under policy one and under policy two. So if policy one is going to perfectly realize if the outcomes of policy one are expected to perfectly realize our preferences, this term will be zero. Whereas if policy two is going to be expected to result in an outcome distribution that's not aligned with our preferences, it doesn't get penalized here. This is just evaluated as a value.
1558282	1585896	50	A	0.99998	25:58	72	Nor does it get penalized here because in this case of fixed preferences that's also not changing as we iterate through policies. However, there would be a divergence that would be nonzero. Like all divergences are between the inferior policy and the superior policy. So by iterating over the finite set of policies that we have taking this term and just leaving it to the side. For now, only the KL divergence.
1586088	1614980	51	A	0.99992	26:26	72	This will lead us to select policies that can be expected to bring alignment between the observations conditioned on policy and our preferences. Preferred outcome distribution. Thank you, that's very helpful. So just to kind of say that slightly differently is given your preferences, that's going to imply some outcomes. And what you're trying to do with that KL divergence is you're trying to get the policy that will achieve those outcomes.
1620300	1666900	52	A	0.99	27:00	114	So if we expect and prefer to be within the homeostatic thermal range and then the two policies in the snowstorm are add the jacket or remove the jacket, which one of those are expected to have the minimum divergence between us being in the homeostatic range and then the policy conditioned expected outcomes? I'm going to have less divergence. It doesn't even mean you're going to live. It just means I'm going to have less divergence by having the jacket on in the snowstorm than by taking it off, which is going to move the expected outcome distribution further from the preference distribution, which here is fixed, but doesn't have to be fixed.
1673020	1691150	53	A	0.99	27:53	26	Okay, so we have several is anyone here the person who has written any of these questions? And then we can just go to that one.
1694960	1695900	54	A	0.95546	28:14	1	Lyle?
1699700	1738860	55	B	0.66	28:19	81	Yes. There we go. I think I'm on here. Okay, so yeah, I wrote the one that is referring to the living organisms and the question about to what extent are these techniques valuable in what I would call social systems of wide ranging sorts. And I know that this book at the outset limits itself to biological systems, at least that's my recollection from the introduction, but it just seems obvious to me that this would have much broader applicability.
1739440	1785992	56	E	0.98026	28:59	71	I'm curious what the state of that is. Well, do I hesitate to put anyone on the spot? John, would you give a first response there while I add some resources? Yeah, my first thought on that is obviously our civilization is struggling and civilizations have failed in the past who collapsed. So it's not necessarily the case that every social structure or societal structure is actually performing functional active inference.
1786136	1839032	57	C	0.61363	29:46	111	But if we were a highly functional organism, if societies were a highly functional organism, we would be doing something like active inference and learning from our mistakes and making sure that we put ourselves in an environment that is sustainable and all that kind of stuff. So my first thought is, I think that all of this is applicable to societal systems, but it doesn't necessarily mean that any existing societal systems actually perform functional active inference. Yeah, thanks. It's almost like saying, hey, we're studying the penguins and their thermostats and homeostats. This model could be parameterized to fit a thriving or a failing society along various different dimensions.
1839176	1876644	58	A	0.82	30:39	85	And so in the sense that this is like a linear aggression that can capture failing as well as succeeding societies. Yes, the Nested Markov blanket formalism has qualitatively, but increasingly quantitatively been applied. And there's multiple startups and applications that are explicitly pursuing this angle. It's been brought up for several years now and in 2020 several of us wrote about it being applied to remote teams and organizations and communities. I can add these links to decentralized science as a system and ecosystem.
1876772	1910900	59	A	0.75	31:16	83	So yes, people have started to sketch that continent out and there's a lot more to understand. What do you think, Lyle? Yeah, I think that makes a ton of sense. I think obviously, I guess the way I was thinking about the question is not so much whether to what extent social systems do this because social systems so you could take two points of view. One is you could say social systems are behaving cognitively in the ways that we're discussing.
1911320	1923880	60	E	0.56	31:51	25	In other words, there are preferred states that are driving behavior. Now, we could say those preferred states are the wrong states for whatever reasons.
1925980	1964160	61	E	0.67	32:05	80	So there's a question between what we actually in any particular social system was actually happening, which I would argue could be described through this technique, or what they should be doing, which we could also describe through this technique. Right? So I think it's important to have that distinction. And there's a really long history of using dynamic systems models to explore those questions, especially in the business context. That's mostly how I made my living through the decades.
1964320	2002576	62	E	0.77	32:44	85	So that sort of as is to be or would prefer to be sort of questioned. It just seems like this technique would potentially be a significant advance over the tools in that space that currently exists, which are primarily things like system dynamics and agent based modeling, stuff like that. But this would seem to have the potential to look at things as they are, why is it broken and what we might do. Yes, so I have added several other references. It's important.
2002678	2075610	63	A	0.94	33:22	185	And the book, again, is like, if it's describing the linear model, then there's the applications of the linear model and as people and as John brought up, like many times in this series of live streams that we did, together with four with just the two of us, with John leading through basically the entire thread of this discussion of three papers and then two more group discussions. There's been recent work on scripts by Mahault and colleagues with a strong and a weak script formalization, like a strong script being when the norms are practiced, like in a ritualistic way, like reading from a script, versus the looser script concept, which could include just norms and social practice. And then more recently they're modeling work using Pi MDP to talk about epistemic communities. And then some of the very earliest live streams that we did were on narrative, human communication, cultural affordances. So these are absolutely topics that have been addressed, although many of the earlier works are like here's people in the world, we're going to use active inference to model it.
2076460	2095470	64	A	0.99997	34:36	47	But then there's so much more beyond that. It's almost like a 1950s cybernetics book. Well, we can just imagine that the person is going to be involved in this feedback loop, but then that's not the end of the discussion on that. Ali and then, John.
2098500	2148192	65	B	0.73	34:58	77	I just wanted to mention that, well, FEP can potentially be applied to any dynamical system with Ergodicity, because you see, any system with Ergotic behavior have some points of attraction, some attractors that all the other states are converging to. So it's pretty general. And well, almost all dynamical systems we know of on different timescales can be potentially modeled with FEP and as its corollary with active inference. Thank you. That's a key point, right?
2148246	2172200	66	E	0.99997	35:48	60	Because that's what we look at. Your gotta this is the tough word for me. And and you can actually look at that even in the context of businesses business strategy and so forth, with some understanding of the absorbing barriers. Right. When does a business dissipate when it's not close enough to its preferred state, like adequate cash flow?
2173980	2206800	67	E	0.97	36:13	88	I think that just seems like a really interesting progression from where the state of the art of dynamic, nonlinear dynamic systems is the way we model businesses now. Well, that's the way some of us do it. A lot of people use a spreadsheet, but this would just seem like a potentially tremendous advancement. Yeah. And then just a few notes then, John, this Stephen Fox who's also joined and talked about industrial engineering, he's recently had this paper come out just a couple of days ago.
2206950	2245448	68	A	0.88	36:46	97	And ironically, a spreadsheet is provided in this paper, but this is also in practice in several places in the world in startup ecosystems, and it's very academic influenced. And then one other more conceptual note, Cadcad, which is the complex systems modeling software, and I know some of you are involved in Cadcad learning as well. They describe it as a language for encoding generalized dynamical systems. And that is what it is. Active Block, for instance, is our project where Yaakob has done much of the initial work that is implementing active inference in Cadcad.
2245544	2311700	69	A	0.99	37:25	148	And we have a whole litany of questions about the relationships between Bayes graphs, generalized dynamical systems variational inference, cadcad, which takes more of like a sampling based approach versus the variational approaches that we're discussing here in Active. And it's going to be very interesting as this systems engineering, complex systems simulation, as well as tokenomic and other things becomes integrated with this analytical framework, especially if we can demonstrate a true concordance between active inference and GDS. John Lyle, I just wanted to say your comments are really spot on. Earlier comments, I think, if I can paraphrase, you had essentially said maybe even a dysfunctional society is performing active inference. And then that would lead us to really to the key components then of that society or that social system is what is its set of preferred states and where is it placing its attention?
2312040	2360000	70	C	1.0	38:32	110	So if, say, an elite group of very wealthy people or powerful people are running the world and they're running it for their preferences, which is to maintain their wealth and to ensure that they stay on top, well, then the world, they could be performing functional, active inference, and the world could suffer the problems that that kind of system would offer. On the other hand, in a highly democratic system, if people understand that they want clean air and clean water and peace and all that kind of stuff and then that's their set of preferred states and their attention is on that and they're performing active inference.
2363320	2382840	71	A	0.9992	39:23	37	Thank you, John Lyle. And then Mike. So John, I'm completely on board with that. I would just amplify a little bit on that. I would say to a certain extent preferences and societal decisions are emergent.
2383260	2418176	72	E	1.0	39:43	77	So you aren't going to find too many people in the world who are going to say they want to be starving or have war or whatever, right, and yet we do. So the interesting thing is to me is how does the individual, I mean this is the whole build up, right? How does the individual behavior somehow. Create. An emergent system that has many bad outcomes even though potentially none of those are bad actors.
2418208	2432824	73	E	0.99995	40:18	45	Some of them are bad actors. But let's just take the simple case. There are no bad actors yet we get bad outcome. Why is that? And we can observe that in existing systems and then we can ask the question, well why is that?
2432862	2474232	74	E	1.0	40:32	109	And then maybe if we understand why that is, maybe we can do something to improve. Yes, great point. And then just a short note, there was in our remote teams we've framed communication and information architectures as organizational affordances so that could assist with decision making, find alignment where people do have similar preferences, like a zone of proximate agreement. In a negotiation context it might be broader, but no matter how broad it is, if you can't forage the path to it, it's going to be a failing system. Mike yeah, I just want to add, I think scaling or the scale factor is hugely important here.
2474286	2491230	75	E	1.0	41:14	42	So if we're talking about interactions amongst a handful of individuals, we're going to see different behaviors and outcomes than we might see on a global scale of cultural interaction. Okay, and then the last comment on that john, go for it.
2493600	2503840	76	A	0.89576	41:33	25	If your hand is still up I don't hear you actually. Okay. Your microphone may have changed or can other people hear? John no. Okay.
2503990	2516070	77	A	0.98316	41:43	24	Eric, go for it. Yeah. How does this all apply to a highly distributed system? I don't see that. Yes, like a society is.
2518840	2538024	78	A	0.99997	41:58	40	Good question. The multi agent case is something that hasn't been studied across the board. But. In 2021 with colleagues. This is like one of the early it's not the first multi agent simulation because there were multi agent simulations.
2538152	2596372	79	A	0.99999	42:18	135	However, it was the first active inference model involving stigma g, which is the feedback process with agents modifying their environments and so on. We can think about even a Nested distributed cognitive system as inheriting some sparsity from a causal perspective. Like there's more connections in the Bayes graph within the Nest mate's head as we're modeling it and then interactions induce like a sparsity between two brains and then they're always coupled with the environment and so on. And that sparsity is a statistical convenience, but also it allows factorizability of models and the models may be factorized in a way where free energy calculations could be, for example, summed within a level of collective behavior. I don't know if that's going that's not the solution in and of itself to the modeling.
2596536	2648384	80	A	0.68125	43:16	109	But when we have systems of like Nested Markov blankets, enclosing systems and closing systems and then also lateral interactions and interfaces like collective behavior, those systems are at least amenable to this kind of principled composition via their sparsity, which does map onto a causal architecture or at least a useful one of the real world. So also remains to be seen. But I think that's a very important question. Lyle yeah, Eric, I would throw in on that question because society of course, broadly speaking is loosely coupled. However, of course there are clicks and densely coupled areas that create the well documented complex connection graphs, right?
2648502	2686168	81	E	0.69	44:08	78	So that connection graph is emergent, right? So the question is, I think this would be actually a really fascinating research project. Can we show that FEP would generate connection graphs or patterns of societal interactions similar to what has been observed? Right, so there's lots and lots of research on what those graphs look like. So is it possible for us to or someone to use FEP to show how those kind of connection patterns would emerge?
2686264	2727384	82	E	0.81	44:46	80	I think that's a really interesting question, yes. How we threshold and parameterize those causal graphs, how we evaluate counterfactuals on those graphs and that's related to the problem of structured learning. But Bayesian model selection and other sort of hierarchical Bayesian methods have the tools. There also just quick pointer to the project ideas table there's some very interesting projects that people have suggested. Jakub, no big deal, sounds like a good one, but we can absolutely do it.
2727422	2767350	83	A	1.0	45:27	90	And that's one of the advantages of being in an activity driven, participatory research and education space is we're hopefully going to be able to help each other identify those projects and where there has or hasn't been overlap and then scaffold those projects, support them and then provide them like a place to communicate about the project. Playing into the ontology active blockprints. All these pieces that one researcher working by themselves would have just not those affordances. Let's just try to quickly look at the last several questions.
2770200	2800828	84	A	0.80412	46:10	69	Must all preferred states and strategies be ultimately linked to survival in some way? Or in the case of some organisms, can free energy be related to something other than survival? So just a quick thought on that. In the context of repeated measurements yes, survival is the capacity for repeated measurements. Free energy energies for domain specific models can be made that have nothing to do with survival.
2801004	2810930	85	A	0.64	46:41	16	And I don't think that there's any contradiction there. John, I still don't hear you, actually.
2818730	2821400	86	A	0.95613	46:58	9	Rohan and then anyone else who raises their hand.
2823530	2833340	87	F	0.99899	47:03	19	Yeah, hi. So I was actually wondering because there's no treatment of time in any of these methods, right?
2836270	2869366	88	F	1.0	47:16	77	Is there any accommodation made? So if you're sampling something, let's say you sample at a minute frequency, you're getting a certain set of events, whereas if you're sampling at a much higher frequency, you would get a very different, much more noisy data set. But that might be essential to capture certain things that might actually enable survival. Maybe there's certain events that act only at certain times. So from the perspective of repeated measurement right.
2869468	2898714	89	F	0.95	47:49	58	So I think free energy principle, as it relates to survival, could it just be related to some sort of creating an internal clock for repeated measurement? Great question. Yes. So far it's been almost time independent, as you suggest. But we're going to be dealing with two ways to deal with time in chapter four and beyond.
2898842	2941514	90	A	0.73	48:18	91	And that's like a discrete time formalization where future and past states are explicitly modeled, partially observable Markov decision process. And then also a continuous time variance where future and past time points are not explicitly modeled. However, a Taylor series approximation, higher and higher derivatives of a function are utilized to glean an approximation to the future behavior of a function. Those are two different ways of dealing with time. And then you talked about, like, sampling rate, and I think you'll see many connections and ways to apply that.
2941712	2979062	91	A	1.0	49:01	98	For example, you could imagine, like, if the sensor is every second, but you're able to think ten times per second, or what about when the sensor is every 10 seconds, but you're only able to think over this timescale. And it's those kinds of situations where actually the frequencies are happening differently that we also might be able to address. Yes. Rohan yeah. Also, like, if there are multiple sensors, some of them react quickly, some of them react slowly, or if there's just or if we look at active inferences, some sort of model averaging phenomena.
2979126	3017880	92	F	0.59081	49:39	85	Right. So you have a model that runs really fast, that reacts really quickly and produces predictions really quickly, and the other one acts more slowly. Would those be valid targets in any sense? Yes, I think it's a very interesting question. I'll just add it here just because it was where we were discussing it, like about different timescales and the way that cognitive clock rates for example and sensory clock rates and then the timescale events, the statistical regularities in the world happen.
3019770	3066626	93	A	0.67	50:19	113	In model stream 4.1 with DeVries and colleagues they talked about the message passing in a factor graph. So anytime that there's a bayes graph there's a way to accomplish variational inference on that base graph using message passing techniques. That's what their package is about for any lab. And then what they hinted at towards the end is actually this reactive message passing development which uses reactive programming techniques. So whereas in message passing, at least in the 40 factor graph formalization it's like you crank the model and a message is passed amongst every node or there's like a given execution order of messages that are passed for the entire graph.
3066818	3102206	94	A	0.99999	51:06	79	However, the reactive message passing paradigm may allow like uncoupling of the frequency of message passing. So you might have one prior that gets one message per hour and then there's another distribution that gets one message per minute and another one is getting 1. Even that one could be doing model averaging of something much faster. So there's many ways that I think your questions will be starting to be explored. Rohan and then John okay John, if.
3102228	3152782	95	G	0.99	51:42	108	Your mic is can you hear me now? Oh good. On the question of survival, I think you would have to identify to answer it, you'd have to identify first what is the organism or what is the agent that you're talking about because obviously if it's an individual person, a person might sacrifice their life for others. So then survival is not necessarily the main driver but if it's a society then any individual might not survive but society as a whole might. I suspect in the bigger picture that it's not really survival of a species it's probably the ability to the propagation of information somehow.
3152846	3191598	96	G	0.99995	52:32	80	That's what I would guess in the biggest picture that's probably what everything is doing is propagating information. And Mike Levin has also explored how changes in the scope of the self can lead to an organism with reduced fitness as a function of a cancer with increased fitness and vision, so to speak. And so just because there's an imperative or normative way that we model behavior doesn't mean that everything works or anything like that. Yes. Ali yes.
3191684	3267910	97	B	0.99872	53:11	131	Adding to what John said well, yes, again, I believe here survival doesn't necessarily mean biological survival and actually it has a much broader sense and it means the existence of things. Actually it's a metaphysical concept here because as I said, Karl Friston has defined the existence or the prerequisite of existence as having two parameters or two features namely being an ergotic system and having markup blankets. So any system which has these any system which has these two properties can basically be considered as an existing system or we can call it a surviving system. Here, just in our last minutes before we go to tools touch on some of these points can markup blanket be considered a decoupling mechanism? So can anything mathematical be considered a mechanism?
3269450	3312526	98	A	0.99996	54:29	131	People use terms in different ways. So that just to raise the point that a linear aggression on height and weight isn't a mechanism of height and weight, it's just a descriptor. So Markov blanket doesn't need to be any kind of mechanism at all, it doesn't need to cut nature at the joints or anything like that. That being said, there are ways in which one could think of the blanket again variously depending on how the real generative model and generative process separated as part of a Markov partition. Sometimes there's ways to think of it as how they're coupled, other times it is a statistical decoupling of a type, it's a partial information encapsulation, but it's not a total encapsulation and that way it is like an interface.
3312638	3358850	99	A	0.6	55:12	98	And yes, thanks to whomever has added this quote this is one reason why the transcripts of all of the live streams and discussions augmented with the ontology will be so helpful and searchable because we could find sentences that have raised similar points and address them. So, good question and then just the last ones, maybe we can come back to this. And then this one is a nice next step question thinking about friction. What is the analogy to friction in a cognitive system? What is the stochastic fluctuation on our cognitive path of least action?
3360150	3423254	100	A	0.99996	56:00	150	What is that in the real world realism ontological claims? And then from the behavioral modeling perspective, where are we using these equations and partitioning variance into a path or a flow of least action and a variable that is analogous to stochastic fluctuation or friction but doesn't take on any of the baggage of describing some feature or component or mechanism of the physical system. So also a great question though and we'll leave this one in case people want to continue to address it. So that brings us to the end of chapter three live meetings. Next week, we'll head into two weeks of chapter four, then two weeks of chapter five, and then we'll have two weeks to sort of ground ourselves, think about what we've learned, talk about project ideas, and then we'll be heading into the second cohort of the first half of the book.
3423452	3456290	101	A	1.0	57:03	91	And for those who are here who want to continue into the back nine, as it were, the second half of the textbook. And also people are welcomed and encouraged to be facilitators or return participants in the second cohort first part because it's many coats of paint for everyone. And so we want to provide that affordance to return again and again. And again because the basics are the classics and the essence and the seed of innovation. All this other important things that happen when we return and clarify.
3456790	3473350	102	A	0.99985	57:36	48	Also we've had to sort of do all of these entering of figures and equations for the first time but now that we have the architecture. People can focus on annotating them, or they can focus on adding new questions or improving the questions that others have written.
3476090	3513460	103	A	0.99993	57:56	118	If anyone else has any comments that they want to make while the recording is still occurring, I'll just give a few seconds for anyone to raise their hand and then we'll end this session and then take a 1 minute break. And then in this room, we'll be continuing on with tools, organizational unit. And if you want to continue speaking with people here about just any topic at all, you can head up to a room up top and then of course always you can join into the discord voice channels and just be working on things like during the math reading group or any other area rojan and then anyone else who raises their hand.
3516230	3546000	104	F	0.99872	58:36	65	Yeah, actually, sorry for this late part. I'm just curious, when you say the free energy principle, it's basically figuring out some set point of states, internal states that the agent wants to be with, right? It's not necessary that it actually couples to the real world. So why wouldn't it be that? Okay, it just becomes a brain in the VAT type of situation.
3548690	3570290	105	F	1.0	59:08	50	It just needs to find a set point that helps it survive. So it doesn't have to actually model the real world, it just has to find a place and no matter what happens, just stay there. So it's not really dynamic. That could be that possibility. It is dynamic.
3570370	3605650	106	A	1.0	59:30	104	It is explicitly modeling time. And one can make a model just like a linear regression could be static, or you could use the linear regression technique and use it in I was more referring it. So if you look at some of the reinforcement, deep reinforcement learning models, right? They usually find some trick within the game. Like if you're looking at Atari games and you say maximize the score, for example, so it tries to find, okay, I can maximize the score by doing the simplest thing that doesn't require me to progress in any way, but it would increase the score.
3606710	3648990	107	A	0.87	1:00:06	103	Okay? So yes, these are important things, so write them down so that we can have infinite discourse on them. The brain, the VAT does still have an interface with the environment, whether it's receive only and then you brought up like it doesn't have to be like modeling the quote real world. This is the architecture that helps us bypass that and say, right, the particulate states, the particular states, which are the blanket states and the internal states are doing inference, acting as if they're doing inference on external states. So it's perfectly compatible with scientific realism, scientific surrealism, aesthetic surrealism.
3654370	3676630	108	F	0.99	1:00:54	56	It could be hallucinating the world, and it's actually just doing inference on the hallucination rather than actual reality as such. Anil Seth and many others who speak of that reality as a controlled hallucination, they're 2ft in that territory without any qualms and feeling like it addresses questions that have been unaddressed by other perspectives.
3678650	3684040	109	F	0.99	1:01:18	11	Okay, so I'll just put this there. Cool. Thank you, everybody.
