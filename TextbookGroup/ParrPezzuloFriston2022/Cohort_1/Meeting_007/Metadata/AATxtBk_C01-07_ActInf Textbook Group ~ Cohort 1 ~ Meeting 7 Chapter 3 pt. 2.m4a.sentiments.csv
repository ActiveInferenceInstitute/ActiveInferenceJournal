start	end	speaker	sentiment	confidence	text
1690	2574	A	0.5148600339889526	Hello, everyone.
2692	10990	A	0.9068883061408997	It is June 16, 2022, and it's meeting seven of the active textbook textbook group Cohort one.
11140	18366	A	0.8902848362922668	We're in our second discussion of chapter three today.
18468	25150	A	0.555976927280426	We'll be looking at the questions that haven't been addressed, so the ones without thumbs.
25770	31320	A	0.6407796740531921	And also, it's not too late to add more questions or to upvote questions.
32170	58720	A	0.6722277998924255	And then additionally, since the Math Learning Group has been quite active in providing synchronous affordances for conversation around some of the background on the Math as well as some aspects of the equations that we'll go through today and also even to applications of the math and developing notebooks and such.
59730	67300	A	0.9090555310249329	We'll take a look at the math in our move through chapter three.
68150	77720	A	0.9087558388710022	Before we go to the questions, does anyone have anything that they just want to remark on chapter three, Ali and then anyone else?
80650	81350	B	0.5491447448730469	Yeah.
81500	99674	B	0.5794817805290222	Well, last week I talked about how I changed my mind about these bottom up and top down characterizations of low road and high road, respectively, after reading chapter three, but it turns out that they are, in fact, bottom up and top down approaches after all.
99792	116450	B	0.6672875881195068	You see, I came across this, in my opinion, undeservedly lesser known piece of beautiful, beautiful writing by Karl Frisden which explicitly argues for such characterizations and the philosophical importance of this distinction.
116790	126146	B	0.6195630431175232	It's called beyond the Desert Landscape, and it's inconspicuously hidden in this book, Andy Clark and his critics.
126338	132870	B	0.735844075679779	So I'd like to quote a couple of sentences from this writing.
133530	146662	B	0.8446156978607178	Well, he writes quote the high road stands in for a top down approach that starts by asking fundamental questions about the necessary properties things must possess if they exist.
146806	161834	B	0.8692920207977295	Using mathematical variational principles, one can then show that existence is an embodied exchange of a creature with its environment that necessarily entails predictive processing as one aspect of a self evidencing mechanics.
161962	163854	B	0.7379104495048523	The low road is the purpose.
163982	183170	B	0.8530676960945129	The agenda established is to pursue the agenda established by Kant and Hellholtz and generalize in a bottom up way, the capacity for inference and prediction to see how far it takes us in understanding embodied exchange with the environment.
183330	196300	B	0.9494956731796265	So if anyone likes to gain a deeper understanding about these conceptual characterizations, I highly, highly recommend this chapter of this book.
196990	205754	B	0.5865772366523743	And quite unusually for Frison writing, it also lacks any mathematical formalism.
205882	209440	B	0.6428942084312439	It doesn't include a single mathematical equation there.
211090	212080	A	0.8529649972915649	Thank you.
212870	213378	A	0.5491447448730469	Yeah.
213464	217118	A	0.8576710820198059	In a recent stream, we also talked about the desert landscape.
217134	237110	A	0.7368505597114563	And Clark's concern was that we might do away with what populates are implicitly assumed to be rich ecosystems of psychology, philosophy and so on, with important ecosystem players like goals.
238110	245078	A	0.5047447085380554	And so the fear or concern was that we might be in a quineyan desert landscape.
245174	259594	A	0.7542725801467896	If we replace some of these, again, implicitly or explicitly stated, to be rich constructs like goals, and we're like, well, it's just distribution matching, then we've made some sort of like a desert monoculture.
259722	267570	A	0.619917631149292	And that would be depoprant of what does Clark say to his desert living critics?
269510	274082	A	0.7935721278190613	All right, if anyone else has a thought, they can raise their hand.
274136	276520	A	0.8053574562072754	Otherwise we can look at the questions.
277610	290810	A	0.8131458759307861	Okay, so this first question if one defines preferred states as expected states, one can say living organisms must minimize the surprise of their sensory observations.
291470	294202	A	0.5768768191337585	I'm not clear on the ontology here.
294336	299858	A	0.8524819016456604	Is it that preference is the same as expectation or that formally we can use them in the same equation?
300054	302270	A	0.8263826966285706	Is that an ontological claim?
302850	309680	A	0.8533015847206116	And is the free Energy and physics an analogy or an ontological assertion about how things really are?
311090	318242	A	0.5114604830741882	So one starting place was I found the slide and so wanted to highlight it.
318296	323026	A	0.8869488835334778	This was in Free Energy, a user's guide which was live.
323048	324340	A	0.8825939297676086	Stream number 37.
326810	329190	A	0.7040619254112244	The slides will be probably a little bigger.
332250	338410	A	0.6927087903022766	It's worth restating just how unusual it is to interpret P as a measure of both probabilities and preferences.
339390	347610	A	0.8073521852493286	They both start with P, though there's nothing wrong with treating a distribution as a measure of preferences because distributions can have different interpretations.
348030	357710	A	0.5171665549278259	But what's unorthodox and in need of justification is giving the same mathematical term two different interpretations within the same equation.
359730	383190	A	0.9100472331047058	They then add some more details that unpack a little bit about how it is the case that the same term, P can be utilized as both a probability and a preference.
383930	404590	A	0.7452549934387207	And then they even extended it into a third P, the, the PH fitness, where by allowing your probabilities and your preferences to converge to reduce the divergence between those two distributions, then fitness is achieved.
407010	421380	A	0.8516710996627808	And so they provided a restatement of the way that that is implemented and then highlighted in additional grounding or interpretive line.
425370	431320	A	0.8187453150749207	So that's at least one part of that question.
437010	440290	A	0.8332102298736572	And also to look towards the equations.
440630	451970	A	0.8240471482276917	It's something that we'll be able to have very clear answers for and thanks to the work of Ali and Blue and others who have been annotating equations.
452890	463270	A	0.9009055495262146	So for example, in equation 3.1, or we can look at like box one, equation one, which is like a Markov blanket definition.
465550	485034	A	0.884457528591156	In the description field we have a natural language description and then the terms that are used in the description are those that are referenced using variables.
485162	510120	A	0.6892354488372803	So that will help us translate across natural language of different human languages, the discrete and continuous time formalisms which we're going to explore in this textbook, also identical or isomorphic or related formalisms in other papers which sometimes are using the same notation letters, but not always.
510810	521350	A	0.8596876859664917	But we could have another column for first in 2019 and here's first in 2013 and then there's a conversation to be had about where they align or don't.
521430	535390	A	0.5859332084655762	And that's the kind of annotation work that somebody can engage in from the publications and that also helps us connect it to the programmatic implementations like in Active Block, for instance, or in other scripts.
535810	550750	A	0.565889835357666	So that even that we can promote norms and practices around variable naming in math and in programming, but also where there is divergences or differences which are important for innovating and evolving the norms.
550910	562630	A	0.6004543304443359	We can also map them pretty coherently so all the equations for three can be read naturally.
563050	577760	A	0.6566441655158997	So we discussed this a lot in the math group and again, a lot of people contributed to this with one of the goals or functions being that whenever we are going to bring up an equation, like if there's a question about equation 3.1.
578530	586910	A	0.8876075148582458	We can just briefly read the current state of the description.
587250	598290	A	0.8420304656028748	Because whether you're super familiar with the letters and variables and how they're concatenated, or whether it's just like a first pass on your seeing this equation.
599430	608920	A	0.7922745943069458	Everybody will benefit when we align our regime of attention to actually what it says, and then that will help us do many, many other things.
612620	625100	A	0.7823750376701355	But to return back to this question, does anyone want to raise their hand and give a thought on the relationship between preference and expectation?
626960	650960	A	0.851756751537323	Ontological claims about preference and its relationship with expectation and more generally, is the free energy something that is an analogy or mathematical isomorphism or an equation that rhymes or is it also an assertion?
652180	655960	C	0.6264447569847107	It it's an equation that rhymes.
657900	659464	A	0.6830353140830994	What makes you say that?
659662	665450	C	0.5711382031440735	No, just because it's cute, that's all.
669120	670792	C	0.8402631878852844	I just joined the conversation.
670856	678370	C	0.6739305853843689	But preference and expectation, I wouldn't think they were at all referring to the same thing.
681060	684000	C	0.7677114009857178	Expectation is a mathematical operator.
685460	691300	C	0.680391788482666	Preference is a statement.
693160	693910	A	0.46103888750076294	Yes.
695560	697910	A	0.7527778148651123	Expectation is used in multiple ways.
698920	711800	A	0.9130929708480835	It can refer to predictions about the mean or the mode or other attributes of a future time point like I'm expecting, what are you expecting to happen on next Monday?
712700	730080	A	0.8663522601127625	Also, expectation can refer and that's how it's used with the fancy e to refer to the expected value of a distribution which for a gaussian is the mode in the center of a symmetric peak.
730820	739852	A	0.7575709819793701	And that doesn't need to be about a future time point, that can just be the expectation of the height of the classroom.
739916	750500	A	0.8390927314758301	Right now it's not saying that's what we're expecting it to be in a year as it might be used conversationally but it's referring to just like the average of a distribution.
753560	754310	C	0.7360090017318726	Right?
754700	758264	C	0.8033202290534973	Mathematically it's an operator and verbally it.
758302	759050	B	0.6040635108947754	Can be.
760780	764010	C	0.7865094542503357	A prediction or a desire or something.
765120	765870	A	0.46103888750076294	Yes.
766720	790736	A	0.5410160422325134	And then again in 37 and elsewhere it'll be worth returning to this again and again because it's one of the essential architectural decisions in active inference that enable it's part of the necessity and sufficiency complex.
790848	805204	A	0.8829220533370972	I don't know whether this is the whole meat of it, but it's part of what allows the dispensal of an explicit reward term, like a homeostatic reinforcement.
805252	811640	A	0.7716423273086548	Reward driven learner would be like, I'm more rewarded by being in my homeostatic range.
811980	814648	A	0.8193545937538147	And then there needs to be this architecture around.
814734	816780	A	0.867748498916626	Well, how are we going to pursue reward?
818480	830240	A	0.8845622539520264	Alternatively, an organism trying to maintain homeostasis realism or us modeling an organism that is maintaining homeostasis instrumentalism.
830900	836716	A	0.840864896774292	We can just say it expects to be in the range.
836748	839920	A	0.8308573365211487	That conversationally we're going to describe as a preference.
840740	841568	A	0.7220153212547302	How do we know?
841654	846150	A	0.602643609046936	We put the animal in the room and it's spending a lot of its time on this warmer side.
847160	849030	A	0.7360509634017944	It prefers to be there.
849480	851652	A	0.7240830659866333	We also expect it to be there.
851786	854090	A	0.6569729447364807	We're less surprised when we see it there.
855020	874172	A	0.9086878299713135	So then it's possible to as they right here interpret that p location distribution in the room for the animal that we're observing or the temperature distribution for the body in the homeostatic context as being a probability density over.
874226	890960	A	0.7957441806793213	Temperatures over locations as well as reflecting the preferences, not the qualia or the phenomenology or anything like too far out about what it means to prefer where preferences arise from, whether they're fixed or learned in the model.
891030	894500	A	0.7343677878379822	All these many, many trails that can come out of that.
894650	906520	A	0.7570776343345642	But just at this essential layer, we don't need to interpolate a reward term between what is expected and what is preferred.
913240	915348	A	0.8227643966674805	Any other comments from someone?
915434	917290	A	0.8548427820205688	Yes, Eric, and then anyone else?
919980	931004	D	0.7407383918762207	Yeah, just to remark on that, it seems you're still not removing the free variable of what the preference of the agent organism is.
931202	932236	D	0.7171211242675781	You're just holding it.
932258	937420	D	0.8020538091659546	You're putting it in a different place so that you can use it in this unified equation.
937760	942860	D	0.7659043669700623	But you still have this it's a free variable.
943200	944224	D	0.8622671961784363	What do you want to do?
944262	945644	D	0.7999809384346008	Okay, I'm going to call that an expectation.
945692	952130	D	0.5958130955696106	And that's what I'm going to try to drive for when I optimize my variational, free energy.
952900	957232	D	0.8116795420646667	But in that sense, it's kind of a convenience or it's a trick.
957296	959140	D	0.5752325057983398	It's a little bit of an unnatural act.
959210	962900	D	0.691003680229187	I don't know the way I think of it, for a purpose.
966540	970810	D	0.5597532391548157	But you haven't solved any other problem.
971420	977800	D	0.7043264508247375	The deeper problem of what should the organism attempt to achieve the goals.
981680	982380	A	0.46103888750076294	Yes.
982530	983900	A	0.7680783271789551	Thanks, Ali.
988720	999168	B	0.7647021412849426	Well, I think it also might be quite helpful to refer back to chapter two on page 36, I think.
999254	1011476	B	0.816036581993103	Yeah, page 36 here they have actually distinguished between the term prediction and exactly.
1011578	1012084	B	0.46103888750076294	Yes.
1012202	1020730	B	0.8877617120742798	Here the term prediction and expectation quite explicitly in terms of equation 2.6.
1023740	1024584	A	0.584351658821106	Okay.
1024782	1027290	A	0.8817168474197388	So let's look at equation 2.6.
1030140	1030744	A	0.584351658821106	Okay.
1030862	1040732	A	0.8186766505241394	A few of them, we don't have the third line fully described, but just here's the third line.
1040866	1045180	A	0.8184036612510681	What does this speak to with respect to preferences and expectations?
1049940	1057840	B	0.8846294283866882	Here the preference actually is in the second term, the Kullback Leibler divergence.
1057920	1058212	A	0.571090042591095	Here.
1058266	1058870	B	0.5491447448730469	Yeah.
1061400	1065360	B	0.8333726525306702	It's actually inherent in the second term.
1065440	1071604	B	0.7736923694610596	And the expectation, expected ambiguity, as it speaks for itself is the first term.
1071652	1081084	B	0.8039179444313049	So we have here the risk is defined as the divergence between the preference and the states.
1081202	1087950	B	0.8924115896224976	So I think that we can see the preference in this equation as well.
1090320	1101010	A	0.7988511323928833	One note here is like that this G is equal to the first, the second, and this line.
1101460	1108868	A	0.49613481760025024	But one way that we can understand the relationship of the second and the third line is like they're very similar.
1108954	1112740	A	0.8276897072792053	The first term is identical here.
1112890	1117350	A	0.7016028761863708	The only difference is that instead of a Y, we see an X.
1118140	1122760	A	0.7965125441551208	And so this is like X being the hidden state and Y being the observation.
1125660	1135260	A	0.7782357931137085	In the case where it's a fully observable Markov process, then the outcomes and the hidden states are going to be like equal uncertainty about them.
1135410	1141336	A	0.7764617204666138	Because in that case it's functionally that the hidden states are observables.
1141528	1155520	A	0.5077325701713562	However, if there's any amount of ambiguity like the a matrix between the hidden state and the observable, then there's always going to be more uncertainty about the hidden state relative to the observable.
1156200	1165780	A	0.8433547019958496	And then importantly, on both sides there's a conditioning vertical line on policy selection.
1166680	1178760	A	0.5633874535560608	And so that is what prevents us from getting into the like, well, what if it's 95% correct or 96 or 97% correct or any of these sort of like model diminishing returns debates.
1179100	1189768	A	0.8409518003463745	It's a functional that's calculated for each policy that have been possible of composing given the affordances.
1189864	1191976	A	0.7648171186447144	A policy is just a sequence of actions.
1192088	1221496	A	0.8111721873283386	So if there's four movement affordances, there's four policies of time depth one, there's 16 policies of time depth two, and so on and for whatever in this discrete, formalism, finite set of policies, there are they're evaluated here and then there's a policy selection that could choose the lowest expected free energy, or it could proportionally choose from them with different kinds of weighting and so on.
1221598	1230596	A	0.8233780860900879	But this is comparing the relative expected ambiguity and risk conditioned upon different specific policies.
1230788	1242620	A	0.8859866261482239	And there's a process by which those specific policies can be enumerated and then this is a process by which they're going to be evaluated and then there's a policy selection by which they're selected.
1243060	1249280	A	0.7397099137306213	So organisms that fail to do this adequately enough will be dissipated.
1249620	1265140	A	0.7839943766593933	Or systems, whether it's just a molecular system or some other kind of statistical system that fail to do this well enough to remain being that kind of thing, are not amenable to repeated measurements.
1265560	1267204	A	0.6461065411567688	They are not that thing.
1267322	1276970	A	0.8735341429710388	But things that remain being that thing for the time horizon of observations will be selecting policies that are consistent with this.
1279660	1281164	A	0.874441385269165	Can I ask a question about this?
1281282	1286430	D	0.855390727519989	Yeah, about this equation here, say like the second line.
1289600	1310140	D	0.6075895428657532	So first of all, see the preferences is not really spelled out very much in this chapter and I don't know where it will be, but I would have expected something more like preferences given observations like the observations, what's happened in the world that we can measure that's observation.
1310220	1310850	D	0.6120101809501648	Why?
1313240	1315280	D	0.6320117115974426	And then how does that fit with my preferences?
1315360	1323476	D	0.7360026836395264	So what I want to optimize is my preference, the achievement of my preferences as delivered by the observations.
1323668	1334584	D	0.8358925580978394	Now, I understand that in that second equation you're going to do a divergence between observations, the Y tilde.
1334712	1338828	D	0.710298478603363	So you can't flip around p of C given y tilde there.
1338994	1343024	D	0.8221728801727295	So can somebody explain to me how this all fits together then?
1343062	1346560	D	0.8301794528961182	How do you achieve preferences under that equation?
1348660	1361780	A	0.4855007529258728	I'll give one thought and I absolutely agree to the first point, which is like c is just like I don't even know if it's described in this chapter.
1363800	1365590	B	0.795786440372467	34, I think.
1366680	1370890	A	0.8215930461883545	34, let me check it again.
1372860	1377748	A	0.7468475103378296	I mean there is he said parameter.
1377844	1380688	D	0.8497490882873535	Includes preferences but it includes parameter.
1380804	1381276	B	0.5491447448730469	Yeah.
1381378	1398370	B	0.8673838376998901	And also if you go to section 7.4 I think yes, in that section it is untangled why these two parameters are related and how these two parameters are related to each other.
1405220	1412336	A	0.6137727499008179	That's like multiple scales of where the information is not provided before when it needs to be provided.
1412528	1430020	A	0.776414692401886	Which is like this I have made as just a helpful diagram of the partially observable Markov decision process which is C is the preferences and it influences how G evaluates policies which are generated from affordances over a given time horizon.
1430180	1435944	A	0.8826624155044556	Policies intervene upon how hidden states change in the world and there's more in different readings.
1435992	1452960	A	0.8420827984809875	But to return to Eric's question and then again, anyone with the raised hand so the question was whether we're comparing outcomes or states, how does this second term help us realize our preference?
1454660	1457184	A	0.8519757986068726	Well, when is the KL?
1457312	1461344	A	0.6819179058074951	We're trying to minimize g of pi better policies have a lower score.
1461392	1466916	A	0.565179169178009	It's like golf, I guess, or you could add negatives and make it higher.
1467098	1479604	A	0.8110456466674805	And also just it's an interesting note like climbing Mount Improbable, biologists often think about the fitness peak and climbing to fitness peaks, whereas for a physicist it's often framed.
1479652	1492804	A	0.5347212553024292	And also like computer science gradient descending and local minima, global minima, but they're just actually like the same landscape with some negative signs.
1492952	1503680	A	0.749427080154419	So the KL divergence and here we're trying to minimize if it's zero that would mean like we are perfectly realizing our preference.
1504500	1513760	A	0.590811014175415	So let's just say that there's two policies that we're comparing between and one of them is going to perfectly realize our preferences, the other one isn't.
1513840	1526330	A	0.8994818329811096	So we have like pi one and pi two and we're going to be calculating the KL divergence of the outcomes that we're expecting under the variational distribution Q under policy one and under policy two.
1527260	1540830	A	0.6022757291793823	So if policy one is going to perfectly realize if the outcomes of policy one are expected to perfectly realize our preferences, this term will be zero.
1542160	1554130	A	0.5065097808837891	Whereas if policy two is going to be expected to result in an outcome distribution that's not aligned with our preferences, it doesn't get penalized here.
1555060	1558084	A	0.7593587040901184	This is just evaluated as a value.
1558282	1566144	A	0.5536617040634155	Nor does it get penalized here because in this case of fixed preferences that's also not changing as we iterate through policies.
1566272	1569124	A	0.8212053775787354	However, there would be a divergence that would be nonzero.
1569172	1575112	A	0.6384167671203613	Like all divergences are between the inferior policy and the superior policy.
1575246	1583692	A	0.8159050941467285	So by iterating over the finite set of policies that we have taking this term and just leaving it to the side.
1583746	1585896	A	0.8235092163085938	For now, only the KL divergence.
1586088	1596460	A	0.5371202826499939	This will lead us to select policies that can be expected to bring alignment between the observations conditioned on policy and our preferences.
1596620	1598320	A	0.8519507050514221	Preferred outcome distribution.
1599940	1601436	D	0.9836751818656921	Thank you, that's very helpful.
1601548	1608820	D	0.8791972994804382	So just to kind of say that slightly differently is given your preferences, that's going to imply some outcomes.
1609480	1614980	D	0.8081146478652954	And what you're trying to do with that KL divergence is you're trying to get the policy that will achieve those outcomes.
1620300	1647760	A	0.8216449022293091	So if we expect and prefer to be within the homeostatic thermal range and then the two policies in the snowstorm are add the jacket or remove the jacket, which one of those are expected to have the minimum divergence between us being in the homeostatic range and then the policy conditioned expected outcomes?
1648340	1649884	A	0.7285787463188171	I'm going to have less divergence.
1649932	1651216	A	0.525296688079834	It doesn't even mean you're going to live.
1651318	1666900	A	0.566990315914154	It just means I'm going to have less divergence by having the jacket on in the snowstorm than by taking it off, which is going to move the expected outcome distribution further from the preference distribution, which here is fixed, but doesn't have to be fixed.
1673020	1689340	A	0.870042085647583	Okay, so we have several is anyone here the person who has written any of these questions?
1689410	1691150	A	0.7669859528541565	And then we can just go to that one.
1694960	1695900	A	0.7665103077888489	Lyle?
1699700	1700450	B	0.46103888750076294	Yes.
1700980	1702096	E	0.5760965347290039	There we go.
1702278	1703552	E	0.8144274353981018	I think I'm on here.
1703686	1723080	E	0.8541356325149536	Okay, so yeah, I wrote the one that is referring to the living organisms and the question about to what extent are these techniques valuable in what I would call social systems of wide ranging sorts.
1723580	1738860	E	0.6141226887702942	And I know that this book at the outset limits itself to biological systems, at least that's my recollection from the introduction, but it just seems obvious to me that this would have much broader applicability.
1739440	1743790	E	0.8294510245323181	I'm curious what the state of that is.
1745520	1751836	A	0.5933300852775574	Well, do I hesitate to put anyone on the spot?
1751948	1756720	A	0.9313524961471558	John, would you give a first response there while I add some resources?
1757380	1773988	C	0.8220078945159912	Yeah, my first thought on that is obviously our civilization is struggling and civilizations have failed in the past who collapsed.
1774164	1785992	C	0.7848078012466431	So it's not necessarily the case that every social structure or societal structure is actually performing functional active inference.
1786136	1805840	C	0.5015711784362793	But if we were a highly functional organism, if societies were a highly functional organism, we would be doing something like active inference and learning from our mistakes and making sure that we put ourselves in an environment that is sustainable and all that kind of stuff.
1805990	1821060	C	0.6530929803848267	So my first thought is, I think that all of this is applicable to societal systems, but it doesn't necessarily mean that any existing societal systems actually perform functional active inference.
1822300	1823752	A	0.6345008015632629	Yeah, thanks.
1823806	1830440	A	0.7620618939399719	It's almost like saying, hey, we're studying the penguins and their thermostats and homeostats.
1831180	1839032	A	0.7518662810325623	This model could be parameterized to fit a thriving or a failing society along various different dimensions.
1839176	1846356	A	0.515175461769104	And so in the sense that this is like a linear aggression that can capture failing as well as succeeding societies.
1846488	1853756	A	0.8390556573867798	Yes, the Nested Markov blanket formalism has qualitatively, but increasingly quantitatively been applied.
1853788	1859368	A	0.5293178558349609	And there's multiple startups and applications that are explicitly pursuing this angle.
1859484	1871692	A	0.6629047989845276	It's been brought up for several years now and in 2020 several of us wrote about it being applied to remote teams and organizations and communities.
1871776	1876644	A	0.5505527853965759	I can add these links to decentralized science as a system and ecosystem.
1876772	1884410	A	0.5139585137367249	So yes, people have started to sketch that continent out and there's a lot more to understand.
1885100	1886620	A	0.875982940196991	What do you think, Lyle?
1887360	1890300	E	0.7021510004997253	Yeah, I think that makes a ton of sense.
1890370	1902064	E	0.7111964821815491	I think obviously, I guess the way I was thinking about the question is not so much whether to what extent social systems do this because social systems so you could take two points of view.
1902102	1910900	E	0.7789141535758972	One is you could say social systems are behaving cognitively in the ways that we're discussing.
1911320	1918064	E	0.6285924911499023	In other words, there are preferred states that are driving behavior.
1918192	1923880	E	0.5469858646392822	Now, we could say those preferred states are the wrong states for whatever reasons.
1925980	1943736	E	0.826501190662384	So there's a question between what we actually in any particular social system was actually happening, which I would argue could be described through this technique, or what they should be doing, which we could also describe through this technique.
1943848	1944316	E	0.7360090017318726	Right?
1944418	1948044	E	0.7070604562759399	So I think it's important to have that distinction.
1948092	1959560	E	0.5760727524757385	And there's a really long history of using dynamic systems models to explore those questions, especially in the business context.
1959660	1964160	E	0.819368302822113	That's mostly how I made my living through the decades.
1964320	1973156	E	0.8677181601524353	So that sort of as is to be or would prefer to be sort of questioned.
1973188	1987692	E	0.8186172842979431	It just seems like this technique would potentially be a significant advance over the tools in that space that currently exists, which are primarily things like system dynamics and agent based modeling, stuff like that.
1987826	1997230	E	0.8030567765235901	But this would seem to have the potential to look at things as they are, why is it broken and what we might do.
1997940	2001660	A	0.7019635438919067	Yes, so I have added several other references.
2001740	2002576	A	0.5484904646873474	It's important.
2002678	2025156	A	0.8537637591362	And the book, again, is like, if it's describing the linear model, then there's the applications of the linear model and as people and as John brought up, like many times in this series of live streams that we did, together with four with just the two of us, with John leading through basically the entire thread of this discussion of three papers and then two more group discussions.
2025348	2047048	A	0.8626363277435303	There's been recent work on scripts by Mahault and colleagues with a strong and a weak script formalization, like a strong script being when the norms are practiced, like in a ritualistic way, like reading from a script, versus the looser script concept, which could include just norms and social practice.
2047224	2053680	A	0.8212671279907227	And then more recently they're modeling work using Pi MDP to talk about epistemic communities.
2054260	2063460	A	0.8289257287979126	And then some of the very earliest live streams that we did were on narrative, human communication, cultural affordances.
2063960	2075610	A	0.740540087223053	So these are absolutely topics that have been addressed, although many of the earlier works are like here's people in the world, we're going to use active inference to model it.
2076460	2080856	A	0.7313566207885742	But then there's so much more beyond that.
2080958	2084744	A	0.4946169853210449	It's almost like a 1950s cybernetics book.
2084942	2093820	A	0.8102468252182007	Well, we can just imagine that the person is going to be involved in this feedback loop, but then that's not the end of the discussion on that.
2093970	2095470	A	0.8029764890670776	Ali and then, John.
2098500	2126250	B	0.8145378828048706	I just wanted to mention that, well, FEP can potentially be applied to any dynamical system with Ergodicity, because you see, any system with Ergotic behavior have some points of attraction, some attractors that all the other states are converging to.
2126620	2129064	B	0.773514449596405	So it's pretty general.
2129182	2145580	B	0.8014105558395386	And well, almost all dynamical systems we know of on different timescales can be potentially modeled with FEP and as its corollary with active inference.
2146480	2147004	A	0.8529649972915649	Thank you.
2147042	2148192	E	0.8012800216674805	That's a key point, right?
2148246	2150176	E	0.7971552610397339	Because that's what we look at.
2150358	2153344	E	0.6438086628913879	Your gotta this is the tough word for me.
2153542	2164640	E	0.8260093927383423	And and you can actually look at that even in the context of businesses business strategy and so forth, with some understanding of the absorbing barriers.
2164720	2165444	A	0.5664746165275574	Right.
2165642	2172200	E	0.5646020770072937	When does a business dissipate when it's not close enough to its preferred state, like adequate cash flow?
2173980	2185050	E	0.9421773552894592	I think that just seems like a really interesting progression from where the state of the art of dynamic, nonlinear dynamic systems is the way we model businesses now.
2185680	2187516	E	0.7339276671409607	Well, that's the way some of us do it.
2187538	2195128	E	0.8291886448860168	A lot of people use a spreadsheet, but this would just seem like a potentially tremendous advancement.
2195304	2195644	B	0.5491447448730469	Yeah.
2195682	2206800	A	0.883251428604126	And then just a few notes then, John, this Stephen Fox who's also joined and talked about industrial engineering, he's recently had this paper come out just a couple of days ago.
2206950	2218144	A	0.5172398686408997	And ironically, a spreadsheet is provided in this paper, but this is also in practice in several places in the world in startup ecosystems, and it's very academic influenced.
2218192	2228250	A	0.8034968376159668	And then one other more conceptual note, Cadcad, which is the complex systems modeling software, and I know some of you are involved in Cadcad learning as well.
2228860	2233940	A	0.867114782333374	They describe it as a language for encoding generalized dynamical systems.
2234100	2235976	A	0.6455256342887878	And that is what it is.
2236158	2245448	A	0.8641160726547241	Active Block, for instance, is our project where Yaakob has done much of the initial work that is implementing active inference in Cadcad.
2245544	2262640	A	0.8357718586921692	And we have a whole litany of questions about the relationships between Bayes graphs, generalized dynamical systems variational inference, cadcad, which takes more of like a sampling based approach versus the variational approaches that we're discussing here in Active.
2262800	2282340	A	0.9230850338935852	And it's going to be very interesting as this systems engineering, complex systems simulation, as well as tokenomic and other things becomes integrated with this analytical framework, especially if we can demonstrate a true concordance between active inference and GDS.
2282500	2287900	C	0.8887087106704712	John Lyle, I just wanted to say your comments are really spot on.
2287970	2298240	C	0.5511733293533325	Earlier comments, I think, if I can paraphrase, you had essentially said maybe even a dysfunctional society is performing active inference.
2298980	2311700	C	0.8769678473472595	And then that would lead us to really to the key components then of that society or that social system is what is its set of preferred states and where is it placing its attention?
2312040	2343740	C	0.5110726356506348	So if, say, an elite group of very wealthy people or powerful people are running the world and they're running it for their preferences, which is to maintain their wealth and to ensure that they stay on top, well, then the world, they could be performing functional, active inference, and the world could suffer the problems that that kind of system would offer.
2343890	2360000	C	0.6008915901184082	On the other hand, in a highly democratic system, if people understand that they want clean air and clean water and peace and all that kind of stuff and then that's their set of preferred states and their attention is on that and they're performing active inference.
2363320	2365984	A	0.9011690616607666	Thank you, John Lyle.
2366032	2367140	A	0.715120255947113	And then Mike.
2368680	2372504	E	0.8435637354850769	So John, I'm completely on board with that.
2372702	2374904	E	0.8592865467071533	I would just amplify a little bit on that.
2374942	2382840	E	0.8651692867279053	I would say to a certain extent preferences and societal decisions are emergent.
2383260	2393196	E	0.7006904482841492	So you aren't going to find too many people in the world who are going to say they want to be starving or have war or whatever, right, and yet we do.
2393378	2405008	E	0.5021619200706482	So the interesting thing is to me is how does the individual, I mean this is the whole build up, right?
2405094	2408080	E	0.7796028852462769	How does the individual behavior somehow.
2409880	2410340	A	0.6296190023422241	Create.
2410410	2418176	E	0.7928633093833923	An emergent system that has many bad outcomes even though potentially none of those are bad actors.
2418208	2419296	E	0.9403979182243347	Some of them are bad actors.
2419328	2421972	E	0.796090841293335	But let's just take the simple case.
2422026	2424388	E	0.6400452852249146	There are no bad actors yet we get bad outcome.
2424484	2425528	E	0.6291940212249756	Why is that?
2425694	2432824	E	0.8516096472740173	And we can observe that in existing systems and then we can ask the question, well why is that?
2432862	2437352	E	0.6286422610282898	And then maybe if we understand why that is, maybe we can do something to improve.
2437416	2440284	A	0.8734541535377502	Yes, great point.
2440322	2456524	A	0.5397095680236816	And then just a short note, there was in our remote teams we've framed communication and information architectures as organizational affordances so that could assist with decision making, find alignment where people do have similar preferences, like a zone of proximate agreement.
2456572	2465380	A	0.6721540689468384	In a negotiation context it might be broader, but no matter how broad it is, if you can't forage the path to it, it's going to be a failing system.
2465530	2474232	E	0.5089768171310425	Mike yeah, I just want to add, I think scaling or the scale factor is hugely important here.
2474286	2486540	E	0.7886492609977722	So if we're talking about interactions amongst a handful of individuals, we're going to see different behaviors and outcomes than we might see on a global scale of cultural interaction.
2488160	2491230	A	0.7555406093597412	Okay, and then the last comment on that john, go for it.
2493600	2496076	A	0.6995274424552917	If your hand is still up I don't hear you actually.
2496178	2496888	A	0.584351658821106	Okay.
2497074	2500640	A	0.7585682272911072	Your microphone may have changed or can other people hear?
2500710	2503072	A	0.618648111820221	John no.
2503206	2503840	A	0.584351658821106	Okay.
2503990	2505570	A	0.5688298940658569	Eric, go for it.
2506660	2507024	A	0.5491447448730469	Yeah.
2507062	2510390	D	0.7772085666656494	How does this all apply to a highly distributed system?
2511720	2513110	D	0.5712078213691711	I don't see that.
2513560	2516070	D	0.6784348487854004	Yes, like a society is.
2518840	2520148	A	0.6243525743484497	Good question.
2520314	2527544	A	0.5150425434112549	The multi agent case is something that hasn't been studied across the board.
2527662	2527944	B	0.6056497097015381	But.
2527982	2530040	A	0.8371428847312927	In 2021 with colleagues.
2531100	2538024	A	0.7741480469703674	This is like one of the early it's not the first multi agent simulation because there were multi agent simulations.
2538152	2546510	A	0.8901551961898804	However, it was the first active inference model involving stigma g, which is the feedback process with agents modifying their environments and so on.
2547700	2557308	A	0.887768030166626	We can think about even a Nested distributed cognitive system as inheriting some sparsity from a causal perspective.
2557404	2568740	A	0.8323385119438171	Like there's more connections in the Bayes graph within the Nest mate's head as we're modeling it and then interactions induce like a sparsity between two brains and then they're always coupled with the environment and so on.
2568890	2590540	A	0.5104517936706543	And that sparsity is a statistical convenience, but also it allows factorizability of models and the models may be factorized in a way where free energy calculations could be, for example, summed within a level of collective behavior.
2591120	2596372	A	0.6006155610084534	I don't know if that's going that's not the solution in and of itself to the modeling.
2596536	2621910	A	0.5549367666244507	But when we have systems of like Nested Markov blankets, enclosing systems and closing systems and then also lateral interactions and interfaces like collective behavior, those systems are at least amenable to this kind of principled composition via their sparsity, which does map onto a causal architecture or at least a useful one of the real world.
2622780	2624952	A	0.8063691854476929	So also remains to be seen.
2625086	2627610	A	0.5683532953262329	But I think that's a very important question.
2629420	2638376	E	0.8302515149116516	Lyle yeah, Eric, I would throw in on that question because society of course, broadly speaking is loosely coupled.
2638408	2648384	E	0.8020793795585632	However, of course there are clicks and densely coupled areas that create the well documented complex connection graphs, right?
2648502	2651744	E	0.8511987328529358	So that connection graph is emergent, right?
2651782	2656128	E	0.9657473564147949	So the question is, I think this would be actually a really fascinating research project.
2656294	2666992	E	0.920827329158783	Can we show that FEP would generate connection graphs or patterns of societal interactions similar to what has been observed?
2667056	2672232	E	0.7799336910247803	Right, so there's lots and lots of research on what those graphs look like.
2672366	2686168	E	0.9238502979278564	So is it possible for us to or someone to use FEP to show how those kind of connection patterns would emerge?
2686264	2689788	E	0.9546644687652588	I think that's a really interesting question, yes.
2689954	2702736	A	0.7898041605949402	How we threshold and parameterize those causal graphs, how we evaluate counterfactuals on those graphs and that's related to the problem of structured learning.
2702918	2710208	A	0.868908166885376	But Bayesian model selection and other sort of hierarchical Bayesian methods have the tools.
2710304	2720340	A	0.9577926993370056	There also just quick pointer to the project ideas table there's some very interesting projects that people have suggested.
2720760	2727384	A	0.9408566355705261	Jakub, no big deal, sounds like a good one, but we can absolutely do it.
2727422	2750770	A	0.8772815465927124	And that's one of the advantages of being in an activity driven, participatory research and education space is we're hopefully going to be able to help each other identify those projects and where there has or hasn't been overlap and then scaffold those projects, support them and then provide them like a place to communicate about the project.
2751460	2755388	A	0.826823353767395	Playing into the ontology active blockprints.
2755564	2764048	A	0.6125699877738953	All these pieces that one researcher working by themselves would have just not those affordances.
2764224	2767350	A	0.8205555081367493	Let's just try to quickly look at the last several questions.
2770200	2775128	A	0.9067944884300232	Must all preferred states and strategies be ultimately linked to survival in some way?
2775214	2781652	A	0.8258294463157654	Or in the case of some organisms, can free energy be related to something other than survival?
2781796	2784364	A	0.8587690591812134	So just a quick thought on that.
2784402	2792300	A	0.7767552733421326	In the context of repeated measurements yes, survival is the capacity for repeated measurements.
2793680	2800828	A	0.7826718688011169	Free energy energies for domain specific models can be made that have nothing to do with survival.
2801004	2804370	A	0.7416269183158875	And I don't think that there's any contradiction there.
2805060	2810930	A	0.640849769115448	John, I still don't hear you, actually.
2818730	2821400	A	0.8725559711456299	Rohan and then anyone else who raises their hand.
2823530	2824600	F	0.6332176923751831	Yeah, hi.
2825290	2833340	F	0.7149984836578369	So I was actually wondering because there's no treatment of time in any of these methods, right?
2836270	2839322	F	0.8611369729042053	Is there any accommodation made?
2839456	2853842	F	0.5145519971847534	So if you're sampling something, let's say you sample at a minute frequency, you're getting a certain set of events, whereas if you're sampling at a much higher frequency, you would get a very different, much more noisy data set.
2853896	2859518	F	0.6796916127204895	But that might be essential to capture certain things that might actually enable survival.
2859614	2863380	F	0.80245041847229	Maybe there's certain events that act only at certain times.
2863930	2869366	F	0.8875514268875122	So from the perspective of repeated measurement right.
2869468	2882650	F	0.8993635773658752	So I think free energy principle, as it relates to survival, could it just be related to some sort of creating an internal clock for repeated measurement?
2883230	2884460	A	0.6860781908035278	Great question.
2885550	2886058	A	0.46103888750076294	Yes.
2886144	2892218	A	0.7434078454971313	So far it's been almost time independent, as you suggest.
2892394	2898714	A	0.8674149513244629	But we're going to be dealing with two ways to deal with time in chapter four and beyond.
2898842	2907780	A	0.8752505779266357	And that's like a discrete time formalization where future and past states are explicitly modeled, partially observable Markov decision process.
2908630	2916386	A	0.6688228249549866	And then also a continuous time variance where future and past time points are not explicitly modeled.
2916498	2927660	A	0.8856191039085388	However, a Taylor series approximation, higher and higher derivatives of a function are utilized to glean an approximation to the future behavior of a function.
2928190	2930538	A	0.7568061947822571	Those are two different ways of dealing with time.
2930624	2941514	A	0.5190473198890686	And then you talked about, like, sampling rate, and I think you'll see many connections and ways to apply that.
2941712	2953742	A	0.7469430565834045	For example, you could imagine, like, if the sensor is every second, but you're able to think ten times per second, or what about when the sensor is every 10 seconds, but you're only able to think over this timescale.
2953886	2961058	A	0.8316715955734253	And it's those kinds of situations where actually the frequencies are happening differently that we also might be able to address.
2961224	2961650	A	0.46103888750076294	Yes.
2961720	2964462	F	0.7531231641769409	Rohan yeah.
2964616	2979062	F	0.8635249137878418	Also, like, if there are multiple sensors, some of them react quickly, some of them react slowly, or if there's just or if we look at active inferences, some sort of model averaging phenomena.
2979126	2979498	F	0.5664746165275574	Right.
2979584	2990910	F	0.6148822903633118	So you have a model that runs really fast, that reacts really quickly and produces predictions really quickly, and the other one acts more slowly.
2991410	2996880	F	0.8674426078796387	Would those be valid targets in any sense?
2997970	3002634	A	0.948867917060852	Yes, I think it's a very interesting question.
3002692	3017880	A	0.855718731880188	I'll just add it here just because it was where we were discussing it, like about different timescales and the way that cognitive clock rates for example and sensory clock rates and then the timescale events, the statistical regularities in the world happen.
3019770	3027894	A	0.852077305316925	In model stream 4.1 with DeVries and colleagues they talked about the message passing in a factor graph.
3028022	3039050	A	0.7210086584091187	So anytime that there's a bayes graph there's a way to accomplish variational inference on that base graph using message passing techniques.
3039570	3042814	A	0.8541346192359924	That's what their package is about for any lab.
3043012	3052506	A	0.8578259348869324	And then what they hinted at towards the end is actually this reactive message passing development which uses reactive programming techniques.
3052618	3066626	A	0.8891885876655579	So whereas in message passing, at least in the 40 factor graph formalization it's like you crank the model and a message is passed amongst every node or there's like a given execution order of messages that are passed for the entire graph.
3066818	3077250	A	0.8693786859512329	However, the reactive message passing paradigm may allow like uncoupling of the frequency of message passing.
3077410	3086106	A	0.8840662240982056	So you might have one prior that gets one message per hour and then there's another distribution that gets one message per minute and another one is getting 1.
3086128	3089202	A	0.549659788608551	Even that one could be doing model averaging of something much faster.
3089366	3093722	A	0.6848739981651306	So there's many ways that I think your questions will be starting to be explored.
3093786	3102206	A	0.9062438607215881	Rohan and then John okay John, if.
3102228	3104562	G	0.8072031140327454	Your mic is can you hear me now?
3104616	3105460	D	0.8534684181213379	Oh good.
3106630	3122742	G	0.582600474357605	On the question of survival, I think you would have to identify to answer it, you'd have to identify first what is the organism or what is the agent that you're talking about because obviously if it's an individual person, a person might sacrifice their life for others.
3122796	3140542	G	0.7023541927337646	So then survival is not necessarily the main driver but if it's a society then any individual might not survive but society as a whole might.
3140676	3152782	G	0.6389589905738831	I suspect in the bigger picture that it's not really survival of a species it's probably the ability to the propagation of information somehow.
3152846	3160020	G	0.5542032122612	That's what I would guess in the biggest picture that's probably what everything is doing is propagating information.
3160950	3175430	A	0.7505795359611511	And Mike Levin has also explored how changes in the scope of the self can lead to an organism with reduced fitness as a function of a cancer with increased fitness and vision, so to speak.
3175580	3184700	A	0.677818775177002	And so just because there's an imperative or normative way that we model behavior doesn't mean that everything works or anything like that.
3185950	3186700	A	0.46103888750076294	Yes.
3187230	3191598	A	0.4950650632381439	Ali yes.
3191684	3211458	B	0.7625629901885986	Adding to what John said well, yes, again, I believe here survival doesn't necessarily mean biological survival and actually it has a much broader sense and it means the existence of things.
3211544	3239494	B	0.8723741173744202	Actually it's a metaphysical concept here because as I said, Karl Friston has defined the existence or the prerequisite of existence as having two parameters or two features namely being an ergotic system and having markup blankets.
3239622	3253202	B	0.8961691856384277	So any system which has these any system which has these two properties can basically be considered as an existing system or we can call it a surviving system.
3253336	3264302	A	0.9209198355674744	Here, just in our last minutes before we go to tools touch on some of these points can markup blanket be considered a decoupling mechanism?
3264446	3267910	A	0.7414748668670654	So can anything mathematical be considered a mechanism?
3269450	3271174	A	0.6822675466537476	People use terms in different ways.
3271212	3278450	A	0.5836735367774963	So that just to raise the point that a linear aggression on height and weight isn't a mechanism of height and weight, it's just a descriptor.
3278530	3284746	A	0.7171447277069092	So Markov blanket doesn't need to be any kind of mechanism at all, it doesn't need to cut nature at the joints or anything like that.
3284848	3296430	A	0.8861764073371887	That being said, there are ways in which one could think of the blanket again variously depending on how the real generative model and generative process separated as part of a Markov partition.
3297570	3312526	A	0.8283916711807251	Sometimes there's ways to think of it as how they're coupled, other times it is a statistical decoupling of a type, it's a partial information encapsulation, but it's not a total encapsulation and that way it is like an interface.
3312638	3330474	A	0.8944513201713562	And yes, thanks to whomever has added this quote this is one reason why the transcripts of all of the live streams and discussions augmented with the ontology will be so helpful and searchable because we could find sentences that have raised similar points and address them.
3330512	3340560	A	0.6628917455673218	So, good question and then just the last ones, maybe we can come back to this.
3341570	3349274	A	0.8247347474098206	And then this one is a nice next step question thinking about friction.
3349322	3352420	A	0.8359456658363342	What is the analogy to friction in a cognitive system?
3353270	3358850	A	0.8242804408073425	What is the stochastic fluctuation on our cognitive path of least action?
3360150	3364554	A	0.8598245978355408	What is that in the real world realism ontological claims?
3364702	3392960	A	0.7707478404045105	And then from the behavioral modeling perspective, where are we using these equations and partitioning variance into a path or a flow of least action and a variable that is analogous to stochastic fluctuation or friction but doesn't take on any of the baggage of describing some feature or component or mechanism of the physical system.
3393330	3398606	A	0.661986768245697	So also a great question though and we'll leave this one in case people want to continue to address it.
3398788	3404210	A	0.8908731937408447	So that brings us to the end of chapter three live meetings.
3404710	3423254	A	0.9032832384109497	Next week, we'll head into two weeks of chapter four, then two weeks of chapter five, and then we'll have two weeks to sort of ground ourselves, think about what we've learned, talk about project ideas, and then we'll be heading into the second cohort of the first half of the book.
3423452	3432598	A	0.8769415616989136	And for those who are here who want to continue into the back nine, as it were, the second half of the textbook.
3432774	3443438	A	0.9415282607078552	And also people are welcomed and encouraged to be facilitators or return participants in the second cohort first part because it's many coats of paint for everyone.
3443604	3446606	A	0.7497138977050781	And so we want to provide that affordance to return again and again.
3446628	3452090	A	0.61183762550354	And again because the basics are the classics and the essence and the seed of innovation.
3452170	3456290	A	0.6508854627609253	All this other important things that happen when we return and clarify.
3456790	3465746	A	0.8060619831085205	Also we've had to sort of do all of these entering of figures and equations for the first time but now that we have the architecture.
3465858	3473350	A	0.7175863981246948	People can focus on annotating them, or they can focus on adding new questions or improving the questions that others have written.
3476090	3490442	A	0.90240478515625	If anyone else has any comments that they want to make while the recording is still occurring, I'll just give a few seconds for anyone to raise their hand and then we'll end this session and then take a 1 minute break.
3490496	3495610	A	0.8753461837768555	And then in this room, we'll be continuing on with tools, organizational unit.
3495770	3513460	A	0.7896648645401001	And if you want to continue speaking with people here about just any topic at all, you can head up to a room up top and then of course always you can join into the discord voice channels and just be working on things like during the math reading group or any other area rojan and then anyone else who raises their hand.
3516230	3520180	F	0.6126701235771179	Yeah, actually, sorry for this late part.
3520890	3534186	F	0.8758545517921448	I'm just curious, when you say the free energy principle, it's basically figuring out some set point of states, internal states that the agent wants to be with, right?
3534288	3539614	F	0.7390438914299011	It's not necessary that it actually couples to the real world.
3539652	3542254	F	0.6952077746391296	So why wouldn't it be that?
3542452	3546000	F	0.6887818574905396	Okay, it just becomes a brain in the VAT type of situation.
3548690	3553550	F	0.6660001277923584	It just needs to find a set point that helps it survive.
3553990	3561938	F	0.7303705811500549	So it doesn't have to actually model the real world, it just has to find a place and no matter what happens, just stay there.
3562024	3564330	F	0.5235722661018372	So it's not really dynamic.
3564510	3568070	F	0.818095326423645	That could be that possibility.
3569130	3570290	A	0.7168442606925964	It is dynamic.
3570370	3572150	A	0.809481143951416	It is explicitly modeling time.
3572220	3582634	A	0.8282743096351624	And one can make a model just like a linear regression could be static, or you could use the linear regression technique and use it in I was more referring it.
3582752	3587194	F	0.8998400568962097	So if you look at some of the reinforcement, deep reinforcement learning models, right?
3587232	3589482	F	0.8172941207885742	They usually find some trick within the game.
3589536	3605650	F	0.5986345410346985	Like if you're looking at Atari games and you say maximize the score, for example, so it tries to find, okay, I can maximize the score by doing the simplest thing that doesn't require me to progress in any way, but it would increase the score.
3606710	3607506	A	0.7123860716819763	Okay?
3607688	3615060	A	0.6578895449638367	So yes, these are important things, so write them down so that we can have infinite discourse on them.
3616230	3625478	A	0.7337464094161987	The brain, the VAT does still have an interface with the environment, whether it's receive only and then you brought up like it doesn't have to be like modeling the quote real world.
3625644	3642080	A	0.8215563297271729	This is the architecture that helps us bypass that and say, right, the particulate states, the particular states, which are the blanket states and the internal states are doing inference, acting as if they're doing inference on external states.
3642450	3648990	A	0.6873975396156311	So it's perfectly compatible with scientific realism, scientific surrealism, aesthetic surrealism.
3654370	3662526	F	0.5019108653068542	It could be hallucinating the world, and it's actually just doing inference on the hallucination rather than actual reality as such.
3662708	3676630	A	0.6393893361091614	Anil Seth and many others who speak of that reality as a controlled hallucination, they're 2ft in that territory without any qualms and feeling like it addresses questions that have been unaddressed by other perspectives.
3678650	3682038	F	0.7751370668411255	Okay, so I'll just put this there.
3682204	3682870	A	0.84200119972229	Cool.
3683020	3684040	A	0.9328439831733704	Thank you, everybody.
