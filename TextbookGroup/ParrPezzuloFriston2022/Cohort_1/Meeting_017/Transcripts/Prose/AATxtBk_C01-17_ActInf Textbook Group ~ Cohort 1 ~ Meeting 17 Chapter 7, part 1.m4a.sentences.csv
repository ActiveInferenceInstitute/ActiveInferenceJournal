start	end	sentNum	speaker	confidence	text
1290	1840	1	A	0.71545	Welcome.
2530	6174	2	A	0.91484	It's cohort one meeting, 17 already.
6372	9422	3	A	1.0	And it's September 23, 2022.
9556	14190	4	A	0.98639	We're having our first discussion of chapter seven in the textbook.
15490	19680	5	A	0.99975	Well, we have many ways to go.
20130	26230	6	A	0.99662	We have questions on chapter seven that people have been adding.
27370	36630	7	A	0.99995	We also have some summaries and overviews and can walk through the text directly.
36970	55150	8	A	0.98254	But first, does anyone want to just raise their hand or unmute and give any thought that they had on chapter seven, their experience reading it, their understanding of where it's situated in the textbook overall, what was in it, or what was not in it, et cetera?
79800	89656	9	A	0.74	Okay, well, open again.
89758	95310	10	A	0.99991	Please raise your hands or write in the chat if you want to address anything at any point.
95680	113490	11	A	1.0	I want to open by acknowledging a lot of the contributions Ali made and in some conversations that he and I had earlier this week that I believe all of you cohort wanderers will find interesting.
115460	118412	12	A	0.99998	But first, let's just start with this quotation.
118476	120800	13	A	0.85477	We're going to start with the opening quotation of the chapter.
120960	127940	14	A	0.83512	Then I'm going to surface some discussions with Ali, and then we're going to go into some details of the chapter.
128280	133360	15	A	0.99966	So the quote is, What I cannot create, I do not understand by RF.
133520	138384	16	A	0.99719	So what does anyone think about that quotation?
138432	141300	17	A	0.79351	Or what does it mean in this context?
144780	145530	18	A	0.1708	Um.
150780	155652	19	B	0.94	I think I mean, it's more applicable.
155796	156760	20	B	0.71259	Applicable?
158000	159340	21	B	0.8452	Applicable.
159680	161464	22	B	1.0	The more complex.
161592	164380	23	B	0.64	The thing is that you're trying to build.
164530	198310	24	B	0.66595	But what priors or what way could your Generative Model create an accurate prediction of the operation of something or the underlying dynamics of something if you do not kind of step by step generate the affordance, take the actions that generate those affordances, I don't see any causal path to doing that.
200380	207740	25	B	0.99	You would have to step through it necessarily, if it's computationally complex.
209920	213550	26	B	0.87229	So that's most things in the world.
214000	217548	27	A	0.6972	But yeah, awesome.
217634	219870	28	A	0.98388	It's like this is the low road answer.
220260	227484	29	A	0.60776	Like, how can the Generative Model have anything like understanding without generating?
227612	229452	30	A	0.85	You can't just have it on the shelf.
229596	233350	31	A	0.83	And then someone has added a mild answer.
234840	247000	32	A	0.99999	We can't have understanding just through mental envisioning that the algorithms need to be implemented for a learner's journey.
248060	268780	33	A	1.0	And then this is also an even deeper or stronger point, which Friston and others have been working on for a long time, which is like it's sentient artifacts in the world that will be the realization of active inference.
269440	272904	34	A	0.99995	It's not just like some nice derivations.
273032	274690	35	A	0.53157	Brock and anyone else.
275300	277808	36	B	0.93	I was just going to add something about hidden states.
277894	291060	37	B	0.99998	There again, coming back to computational complexity, but there's things now that we're starting to build that we don't really 100% understand all of the dynamics of what is or just in general.
291210	294688	38	B	0.99978	We invent things that we don't completely understand first.
294874	316280	39	B	0.59	And then based on the observational, based on the evidence that we observe, that it is consistently exhibiting some behavior that directs our attention that directs where our generative model pursues more observations.
316360	336980	40	B	0.52605	But we're definitely getting towards a point where that's kind of no longer going to be possible in the way that we usually try to use math to just shortcut stuff, where the operation of the dynamics of the things that we're going to build are necessarily going to be the proof.
337560	339700	41	B	1.0	Their existence will be their own proof.
343000	343750	42	A	0.99994	Awesome.
344780	348516	43	A	1.0	Okay, so just fun starting quotation upload.
348548	363052	44	A	0.99553	That one for sure, though there's some detailed things about the examples and some of these I've been working on.
363106	367704	45	A	0.99979	Everyone is welcome for every chapter to be contributing on these pages.
367752	378636	46	A	0.58831	Like kind of just trying to overview what these examples are because a chapter, it states it up front, yet I missed it the first several times reading.
378668	394404	47	A	0.99998	It like these illustrated models of every color in the rainbow are the section titles, and those are the functionalities that are getting layered in sometimes building on the same model.
394522	398410	48	A	0.98854	Like there's like Team A's version one and then there's Team A's version two.
398940	405880	49	A	0.99985	Other times it's switching between models or showing two different models that illustrate the same cognitive functionality.
406800	410908	50	A	0.97261	Other times the simulation outputs are shown, other times they're not.
410994	430770	51	A	0.99993	So there's like a lot of heterogeneity in the observations in this chapter, but it really wasn't until I saw that these first paragraph words were the section titles that it made more sense how the chapter was being laid out.
431460	435060	52	A	0.78483	So that's just kind of one note.
437960	449400	53	A	0.38887	Ali, do you want to raise any thoughts or describe a little bit about our discussion on how we're going to move forward on the equations?
454950	455700	54	A	0.9	Okay.
456150	457858	55	A	0.99993	If you unmute, then go for it.
457864	461270	56	A	0.99982	Otherwise okay.
461340	461574	57	A	0.96	Yes.
461612	462258	58	A	0.54792	No, Mike.
462354	462806	59	A	0.60961	Thank you.
462828	463026	60	A	0.66557	Ellie.
463058	463606	61	A	1.0	All good.
463708	470070	62	A	0.84118	So we were discussing how there are several layers.
470650	474730	63	A	0.71436	As with other scriptural traditions, there's levels of readings.
475470	486330	64	A	0.99975	So there's a level of reading that is even more granular or below where we've been currently targeting.
486490	503838	65	A	0.99872	Like, here's equation 25, there's a reading for accessibility and understanding that would potentially be like F open square bracket, q comma y closed bracket equals negative sign expectation over Q, open parentheses, et cetera.
503934	508530	66	A	0.99961	So it's like the reading of the notation.
510330	523000	67	A	0.77797	Then the notation can be substituted for terms in the active ontology, which is like the level that's being described here, but this is not to be seen here.
526110	539230	68	A	0.99917	This is the level where notation could be aligned across papers because their notational reading would be different, but then they might be referring to the same exact composition of the active ontology.
540530	563800	69	A	0.99992	Then once the ontology definition has been squared, the terms could be condensed into meaningful units like accuracy, complexity, risk, expected risk that gives symbolic in the more conversational sense rather than in the notational sense.
564890	575690	70	A	1.0	And then that's where memes and themes and rhetoric around what active inference formalisms say start to arise.
576430	591738	71	A	0.99	And then there's the consequences of changes in relationships within and outside the formalism because it's kind of like there's this larger structure for like a POMDP and changing one variable.
591834	604340	72	A	0.99997	If you're only looking at one view or one kind of sub formalism, turn it up to eleven yet that might influence other variables that aren't part of that formalism itself.
604790	616150	73	A	1.0	And so this is like a very open question that touches on everything from the implications of changes to relationships that aren't formally specified.
616570	627946	74	A	0.99999	For example, the Bayes graph, the edges reflect a certain type of relationship as we've explored, but changes from one can propagate throughout a whole system, potentially in nonlinear ways.
628128	632060	75	A	0.58023	So it's always going to be this kind of open area.
633630	642430	76	A	0.99991	How changes, including counterfactuals about the formalism, what if risk were situated this way instead of that way?
642580	644798	77	A	0.94259	Or how does that relate in this case?
644884	646382	78	A	0.99207	So this is kind of an open one.
646436	649680	79	A	0.99966	Again, people please update it and modify it.
650290	655300	80	A	0.99954	But some of these equations which we'll get to.
655750	660178	81	A	0.98858	So we'll come to why we had that conversation in a 7.8 later.
660264	664550	82	A	0.99999	But that was like one really interesting conversation.
665530	698498	83	A	1.0	And then there was one other okay, then just to kind of jump into a chapter seven topic but also kind of reframe our learning journey as we're all working through this for the first time in the textbook group.
698664	710166	84	A	0.98956	So they wrote, um, this choice in the teammates and then Eric or anyone else.
710188	723146	85	A	0.92	I know that you had some questions on the teammates, or we can go to the earlier examples, but this choice of what to do do you seek out the informative queue and then go to the arm that you've now reduced your uncertainty about where the reward is?
723248	732650	86	A	0.98625	So do you take an epistemic action and then have a better chance of making the pragmatically good choice or do you just go and make the pragmatic choice?
732730	736320	87	A	0.99957	Do you take one step up or do you take one step back for two steps up?
736930	742226	88	A	0.99861	It speaks to the exploration exploitation dilemma in psychology and machine learning.
742408	745410	89	A	0.9	A dilemma that's resolved under active inference.
746550	761240	90	A	0.99998	So we were just cracking up because first a low familiarity learner might not know what these terms are or like why it's relevant to even talk about this situation.
762810	773100	91	A	0.99495	Familiarity might look like knowing metaphors, examples, intuition, some relevant citations or historical anecdotes about this.
774430	796562	92	A	1.0	The understanding in terms of what the active inference formalism says about this, if it's resolved under active inference then understanding that resolution is about the basis and then from understanding there could be like further developments and applications and then we'll come to this.
796696	810840	93	A	1.0	But what was making us laugh was surely there are parameterizations in which the rat and the teammates always does one thing or always does the other.
811850	847570	94	A	0.99979	So it's not that the explore exploit trade off is simply resolved under active inference even though people commonly point to things like the ability to rapidly switch between exploratory and exploitative behavioral policies because there's parameterization of that model and structure learning including that that has to be accomplished such that the model can be in a kind of critical point where it behaves adaptively and thus in a situation manages the explore exploit tension under certain constraints.
848470	852310	95	A	0.99999	But how could it be said that active inference resolves that dilemma?
853050	856646	96	A	0.9996	So maybe to whomever wrote this one?
856828	858038	97	A	0.9998	What is happening?
858124	858662	98	A	1.0	Yes, please.
858716	861654	99	A	0.79342	Eric, classical Eric writing here.
861692	863800	100	A	0.99992	So what about this?
865870	869434	101	C	0.96557	Yeah, I'm kind of the heckler at the garden party here.
869552	889050	102	C	1.0	You can see in most of my comments and questions but yeah, maybe it's just best to I mean it's maybe better read than spoken but yeah, I don't see this as a valid claim that they well, first of all, I don't know why they call it a dilemma for psychology.
889130	890434	103	C	0.99995	It's a trade off.
890632	895570	104	C	0.76392	It's been understood for years and there's ways of formalizing it and you solve it through optimization.
897510	906760	105	C	0.53771	It might be a dilemma for a creature because they don't know what they should do, but that's not a dilemma for the field.
908170	916170	106	C	0.51	And then I guess the other paragraph is I don't see that they offer any resolution.
916990	921770	107	C	1.0	All they do is they put it into the same they use a common language, free energy.
921840	933082	108	C	0.99999	They put exploration and exploitation into the same equation and call it with this information based term called free energy which is perfectly valid.
933146	933902	109	C	0.82327	That's great.
934036	946180	110	C	1.0	But that doesn't resolve the problem because as you pointed out, you've got parameters and the designer or somebody has to figure out what those relative weights are, the parameters are.
946630	966540	111	C	0.79	And so you really haven't advanced anything fundamentally, simply by using this free energy way of expressing what the trade off is as opposed to some arbitrary measure called energy or preference or something like that.
967230	974940	112	C	0.99948	So I just think that it doesn't help them when they overclaim, which is my opinion and you can convince me otherwise, I'm open.
975550	986270	113	C	0.99999	But it seems to me it doesn't help them by overstating their contribution to resolving exploration versus exploitation.
988210	989934	114	A	0.97	Yes, very insightful.
989982	991298	115	A	1.0	I actually totally agree.
991384	995490	116	A	0.99	I purposely tried to not mention it as a dilemma either.
995560	1024170	117	A	0.99	I think tensions, trade offs, these are all valid but that's kind of micro linguistic and a more serious issue is that claims that do crystallized out from the text and things that people can copy and paste and quote if this were a courtroom scenario did you say that active inference resolves exploration exploitation?
1025150	1028080	118	A	1.0	The answer has to be yes, it was claimed in the book.
1028690	1052550	119	A	0.99999	Could somebody contextualize that like it's providing a first principles way where there are tunable or learnable or parameter sweepable features of models that sit at a really well positioned intersection of human interpretability and manifolds of relevant model variation?
1053850	1063830	120	A	1.0	Yes, in an extremely charitable reading one could kind of bring this from coming off over the edge back onto the table.
1065390	1093778	121	A	0.99955	That would also make active inference less surprising and less realistically hyperbolic and be part of this process of seeing the evidence in the realization, not in the kind of ironic like we have a different partitioning of a statistical variable value.
1093944	1097650	122	A	0.99667	So nice points Brock.
1100470	1129920	123	B	0.87	I guess I wanted to agree with that and then also maybe play a little devil's advocate, it's all information so solved just because it's been formulated or renamed to something pragmatic value, epistemic value, it doesn't seem like that resolves it or something.
1134290	1145566	124	B	0.99623	I'm wondering if the reading of that though could be not that there is still a trade off but that the dilemma.
1145678	1154194	125	B	0.98046	Is that what they're talking about is that the trade off, like when do you explore or when do you exploit?
1154322	1162440	126	B	0.99997	Not that there is a trade off but that is this last sentence and a half here.
1164030	1167100	127	B	1.0	The resolution stems from the minimization of free energy.
1167550	1194114	128	B	0.99682	Is that whether you would seek pragmatic value or epistemic value is conditioned on which your model believes to be the free energy minimizing choice though you still have the dilemma, so to speak, or the trade off.
1194312	1201490	129	B	0.99964	But which side of the trade off you take is maybe resolved.
1203990	1204430	130	C	0.9999	By a.
1204440	1207560	131	B	0.5655	Generative model here or not, I don't know.
1209610	1210498	132	A	0.95069	Thanks Brock.
1210594	1225798	133	A	1.0	I think the field is set for a situational resolution that may be as good or maybe better than other ways that it's been addressed but it comes down to the exact numbers that are chosen.
1225894	1228590	134	A	0.84643	So like in the example of the teammates.
1230210	1237680	135	A	0.98855	So we can look at for example this zero six and negative six.
1239810	1244194	136	A	1.0	What if it was negative 3000 and positive 3000?
1244392	1254098	137	A	1.0	And so this came up in the live stream 45 with Ryan Smith on the folk psychology where the intensity of the preference was represented.
1254274	1264018	138	A	1.0	And so if the preference is so we prefer having more food, is that going to be 1000 versus zero?
1264124	1270422	139	A	0.99973	Because if so even the scantest probability of achieving food will be pursued.
1270486	1280986	140	A	1.0	In other words, that model is going to be parameterized way, way on one side and it's going to exploit only or it's only going to take locally greedy behavior.
1281178	1293570	141	A	0.70875	Whereas if someone said well my behavior for food is zero zero one then maybe even the most obvious strategy would not be undertaken because it's so close to having a flat preference.
1294230	1299746	142	A	0.83796	Why is zero one versus why is 3000 too high and zero one too low?
1299928	1305990	143	A	0.99991	Well it has to do with the ratios and the interactions of a lot of the parameters.
1307290	1311800	144	A	0.98355	So it's not even going to be like well my preference is three comma one.
1312810	1320140	145	A	0.99999	That is going to be just like two parameters being drawn out from a potentially massive parameterization of a model.
1321230	1336320	146	A	1.0	And so preferences just only speaking of preferences may be very hard to compare across situations because it's not like plus six for the preference for food and negative six.
1337410	1341058	147	A	0.99803	It doesn't have a semantic meaning in the world.
1341224	1343410	148	A	0.99964	It's literally a model parameterization.
1344550	1370998	149	A	1.0	And so then the question becomes how can this framework or this way of having of combining probabilistic inference and energy based inference for strategic decision making, how can those parameters be tuned into a region of subspace or manifold where the behavior is flexible and adaptive?
1371174	1381188	150	A	0.99995	So I think the stage is prepared for a first principles resolution in charitable reading.
1381284	1381880	151	B	0.58254	Sorry.
1382030	1382648	152	A	1.0	Yes, please.
1382734	1391640	153	B	0.99963	Yeah, I was just going to say Ali shared this paper meta control of the exploitation exploration exploitation.
1391720	1394556	154	B	0.9988	It's in the nearby chat link.
1394738	1395470	155	A	0.99995	Nice.
1396800	1414768	156	B	0.74367	But yeah, it's not that it solves it like in some grand it eliminates exploration exploitation or that it even completely currently it's just the affordance, I guess seems to be there to explain which one why.
1414854	1424212	157	B	0.99836	Like you're going through that there's a preference heavy here or heavy there and it's not that it's base optimal, right?
1424266	1432570	158	B	0.75993	It's not that it makes sense or it's adaptable or anything like that necessarily, just that there is some causal through line, maybe.
1433500	1434296	159	A	1.0	Yes.
1434478	1440490	160	C	0.99963	Eric yeah, so I want to first read Ali's comment here.
1440960	1456770	161	C	0.94	The critical point to establish is to define action selection as a balance between maximalization of expected reward and expected information gain which are functionals of posterior beliefs about latent states of the world.
1457780	1471110	162	C	0.7175	So that touches on one of the questions which I also wrote comments on, which is about the team, a's example in particular, and I don't know if we'll have time, but we may get to that one today.
1473240	1488116	163	C	0.70187	But the questions specifically I want to raise about this comment, or maybe I guess this is a quote about there being a balance between maximization of expected reward versus expected information gain.
1488308	1491148	164	C	0.97948	That's one way of having a trade off.
1491314	1521280	165	C	0.99997	But you might look for an agent that only wants to maximize reward in the long run, but in order to do that, that entails information gain and that therefore gives a motivation for why you want to attend to the other term, the information based learning based term or knowledge refining a state based term.
1521360	1523248	166	C	0.99999	But that's in the service of the larger gain.
1523264	1536568	167	C	1.0	And that's essentially what a reinforcement learning tries to do is say look, we're going to look ahead so that the moves we take now will bring us advantage in the future and there's a time discounting and all that.
1536734	1546460	168	C	0.5951	So that takes away the idea of information as being a value in and of itself, but it's only for a purpose.
1549200	1551308	169	C	0.41073	I'll raise that specifically with regard to the team.
1551394	1553410	170	C	0.74558	A's example in a different question.
1554660	1557890	171	A	0.97367	Yeah, thank you.
1558740	1565528	172	A	1.0	The balance between Pragmatic and Epistemic is the optimization.
1565724	1585688	173	A	0.99998	So that is the question and that is the critical point and that's the situational balance that modeling is going to be evolving around it's like some situationally optimal or preferable strategy around.
1585854	1589450	174	A	1.0	That is the point.
1590480	1594300	175	A	0.54929	But pointing to the point is not the resolution.
1595520	1602460	176	A	0.71489	Does active inference provide us a natural language grounded first principles approach?
1602980	1612400	177	A	0.9975	It may, but that is also not dilemma resolution.
1612740	1617430	178	A	0.99984	So onto some questions, but these are really great points.
1618840	1632552	179	A	1.0	Okay, this is just an example of a type of question that I encourage people, especially if they're going back to the earlier chapters or just whenever they feel like making a contribution of this kind.
1632606	1634328	180	A	1.0	These are like super helpful questions.
1634414	1646590	181	A	0.99974	Again, the questions we write, some of them may be included in really important educational materials, not the least of which many further textbook groups, but potentially even far beyond that.
1647040	1654460	182	A	0.99987	So what would you ask somebody to understand their comprehension of the materials?
1655440	1660560	183	A	0.90828	So I understand what are the rows, columns and numbers in these equations?
1662740	1664800	184	A	0.54	And it even says it in the text.
1664950	1667076	185	A	0.61654	It's the probability of the next state.
1667258	1672100	186	A	0.9979	So the next state is in the rows, and then the current state is in the columns.
1672520	1687450	187	A	0.52	And this gets distributed across everything so that the rows and columns sum to one as any other transition probability matrix would be expected to have.
1689180	1693468	188	A	0.99985	So we don't need to discuss it unless somebody wants to go into a little more detail.
1693634	1705330	189	A	0.99999	But this is going to be at the core of that third step of the recipe, which is you might have the structural form from the second step of the recipe in chapter six.
1706340	1721680	190	A	0.59	And then the next step is to kind of specify or instantiate, like in code, what the dimensions are of these matrices.
1721840	1723904	191	A	0.99999	This is just saying like they are matrices.
1723952	1731156	192	A	0.9984	There's some prior tensor matrix, some hidden state, some transition matrix, some emission matrix.
1731348	1734708	193	A	0.99	And this is like the structure step two of the recipe.
1734884	1738116	194	A	0.99999	Step three, how many rows and columns.
1738308	1747260	195	A	1.0	And as Yaakov and others have been exploring, there's the rows and columns of the analytical representation with the equations.
1748240	1757010	196	A	1.0	And then there's how Pi MDP does it, and there's how different computational realizations do it.
1757940	1761820	197	A	0.29968	Jacob, would you want to add anything about the dimensionality of these matrices?
1761900	1763010	198	A	0.59137	It could be interesting.
1767060	1782890	199	D	0.50458	Yeah, I can probably speak more to how Pyme DB deals with the dimensionality, which currently is probably adds unnecessary redundancy to them.
1783340	1814160	200	D	0.65459	Like if you're dealing with more complex state space or rather more high dimensional state space, and you have different modalities that you want to encode in these matrices because you're then performing matrix multiplications, you need to keep the dimensions of the matrices in those given modalities equal, at least in time DP not in other methods as far as I'm aware.
1814980	1820310	201	D	0.99998	But that means that then you have dimensions within these matrices that don't contain any information.
1820760	1844590	202	D	0.54034	So say you have a grid that you represent for the likelihood mapping of observation and state in physical world, but then you have another type of observation, like where is another agent located with respect to you?
1845440	1846904	203	D	0.99998	Are they in a certain direction?
1846952	1856688	204	D	1.0	And that might be represented by five observations, say, like they're above, they're below, they're to the right, to the left, or not at all.
1856854	1871072	205	D	0.71281	Then you would need to encode the observation in the nine by nine matrix, but then you need to replicate it five times because that is the same for each of those relative observations.
1871216	1878180	206	D	0.9999	But then when you want to encode the likelihood mapping just for the second type of observation.
1879240	1887252	207	D	0.99458	I'm actually not entirely sure what that would be, but I'm presuming it's going to be like five by five, but then replicated.
1887316	1892824	208	D	1.0	Nine times or something like that, just so the dimensionality matches.
1892872	1906110	209	D	0.99998	Because then you're doing inference over both modalities and at least in prime DP, you're then performing matrix multiplications over both of them.
1907200	1907804	210	A	0.64923	Thank you.
1907842	1908700	211	A	0.20695	Jakub.
1909300	1916660	212	A	1.0	One way I'm kind of like seeing that is there's the sparsity of the graph.
1917560	1948328	213	A	0.99999	But then, in Pym DP or in any given computational implementation, the data structures, including potentially, like, auxiliary data constructs, may have a dimensionality that reflects potentially, at worst, a combination of the dimensionality of other aspects as part of even just a Temp file that you didn't even exactly specify.
1948504	1961120	214	A	0.99998	There might be some intermediates, stated or unstated intermediates whose dimensionality isn't merely the dimensionality of the analytical representation.
1962180	1965650	215	A	0.98874	It's a little bit of a subtle implementational point.
1966200	1972340	216	A	0.99989	But this is the mountain to climb, to implement these kinds of models.
1974120	1994760	217	A	0.8	And also, just while we're on this topic, I think it's one area where CAD CAD is going to be very interesting to explore in active block for its package, because we also can imagine that the execution order of certain operations, even in a single agent setting, not just the multi agent setting, is really relevant.
1994840	1996910	218	A	0.99955	So there's that question.
1998080	2000876	219	A	0.89	All right, so figure 7.2.
2000898	2001116	220	A	0.91	All right.
2001138	2004930	221	A	0.99975	So the first example is about a musician playing music.
2008180	2012130	222	A	0.54593	We are not aware of this example being used anywhere else.
2012820	2014880	223	A	0.99978	Like the citations following those.
2015030	2018800	224	A	0.99912	This musical note type representation is not shown.
2018960	2030436	225	A	0.58	And previously we kind of discussed how some of these trace black and white images are really ambiguous because of being like, intersecting black lines.
2030468	2035770	226	A	1.0	And then, of course, the empty square.
2037500	2038248	227	A	0.91	Yes.
2038414	2040556	228	C	0.97824	Can you say where those black lines come from?
2040578	2042830	229	C	0.47	You want to dive into that right now?
2043360	2044110	230	A	0.99986	Yeah.
2044880	2048110	231	A	0.82336	Well, okay.
2049760	2056320	232	A	0.86	The upper left, each black line, even though it can be hard to trace them, I think they're just being shown like representationally.
2057380	2062752	233	A	0.74692	They're beliefs about each note in the sequence at each time step.
2062806	2075056	234	A	0.99979	So the time steps are on the x axis and the belief in terms of a probability are on the y axis.
2075248	2076276	235	A	0.53626	So initially right.
2076298	2083576	236	C	0.57318	So there's some there's some sort of and this gets to another question that was raised, but maybe this is time to talk about it.
2083678	2090772	237	C	0.8367	There's some sort of engine, some sort of differential equation simulator or something running underneath here right.
2090846	2096440	238	C	0.99969	That is not discussed in the chapter, but that's generating these belief curves.
2096520	2097150	239	A	1.0	Yes.
2097600	2100184	240	A	0.9982	It's related to some functions in MATLAB.
2100232	2114210	241	A	1.0	And I was just going to mention that because my sense from the discrete model would be you'd have five, let's say, points on time zero, then you'd have five points on time one.
2115320	2120870	242	A	0.97526	So I thought, well, what is happening with this kind of like little fractal crash right here?
2121400	2133610	243	A	0.99996	How could you have a continuously differentiable oscillating type behavior when all you're calculating analytically is just 12345?
2134300	2140360	244	A	0.99879	Then I thought, is it meaning is, is the, are the points actually at the midpoint?
2141200	2150380	245	A	0.86	And there's a differential equation that's sort of like ribboning an action perception loop through a discrete time matrix.
2150880	2162560	246	A	0.99992	But then if this is a function that's evaluatable at every point, aren't we in a continuous time setting?
2163700	2175940	247	A	0.99992	So wouldn't that have to imply like a machinery for unpacking a continuous time action perception cycle from discrete time specification?
2177400	2180456	248	A	0.99442	So I agree very much.
2180638	2181370	249	C	0.70737	Yeah.
2183180	2183976	250	A	0.74221	Good.
2184158	2195016	251	C	0.99993	My guess is what they do is they've got the equations, the free energy equations and the parameters are these distributions.
2195048	2198216	252	C	0.92	Okay, what's your belief in these different properties?
2198408	2218384	253	C	0.7	And those parameters evolve over time through a differential equation because you turn these things into a differential equation and when you change state something like, okay, now we've got another note comes in, then that's what's going to trigger the differential equation to go in a different direction, essentially.
2218432	2233270	254	C	0.81	And that's why you've got the five discrete kind of regimes here or target points that it kind of evolves to.
2234440	2240276	255	C	0.65	And then the next note comes in and now the boundary conditions change, essentially.
2240388	2243180	256	C	0.92721	So your differential equation takes you in a different direction.
2244480	2255440	257	C	1.0	I recall that there's something like you guys probably discussed this more than I paid attention, but there's some sort of universal solver that they are providing.
2255940	2269796	258	C	0.99981	So you just plug in your matrices, your state equations, your transition matrices, and then it'll solve it all for you.
2269818	2273348	259	C	1.0	And that may be what this differential equation solver is about.
2273434	2275284	260	C	0.8905	Do you think that sounds right?
2275482	2293980	261	A	1.0	Yes, I think whenever, variously in the method sections and supplemental sections of paper, they'll say in the paper, we're only specifying the generative model and the matrices and then we use standard routines to address it.
2294050	2300056	262	A	0.99	Now, I don't think that has the, it's not the pinnacle of accessibility and reproducibility.
2300248	2302884	263	A	1.0	However, it does at least use standard routines.
2302952	2307330	264	A	0.99994	But again, those are not always specified in the paper, which is an issue.
2307780	2328150	265	A	0.99992	So it'll be important to regenerate examples within SPM and then also to use some of these things that we were discussing with the ability to move between different languages, but like VBX variational, bayes X, I don't know what the X is actually for.
2331420	2334468	266	A	0.76225	It's one of the core functions.
2334644	2338200	267	A	0.9871	It is actually doing the variational inference in SPM.
2338620	2370820	268	A	1.0	And again, SPM is like this sort of like chimera package because it arose from the immediacies of needing to do neuroimaging registration and dynamical analysis that then broached into dynamic causal modeling, random field theory based statistical testing, permutation testing all these areas that are not themselves formally linked per se, but rather useful as part of the toolkit of a Neuroimaging researcher.
2372760	2391870	269	A	0.9996	Then, just as we were a little bit discussing like chapter two, and of course, many times earlier in that generalized Bayesian inferential framework, hierarchical modeling, including action, is actually not the hardest thing.
2392240	2417760	270	A	1.0	Yes, implementing action is one thing, but treating action selection as inference, planning as inference, it has some challenges that arise relative to just doing time series anticipation, but then those functions became compiled into SPM in a limited capacity.
2419540	2423012	271	A	0.69225	So again, they go through some of this.
2423066	2424950	272	A	0.95764	But I think it's a key issue.
2425960	2439944	273	A	0.98499	We'll definitely look forward to what the free energy gradients are, but where the continuous nature of these curves and why?
2439982	2446590	274	A	0.99991	There are the numbers that there are 1234-5678, 910.
2447280	2449340	275	A	1.0	Now there's five notes.
2451040	2452910	276	A	0.68	Ten is two times five.
2455140	2458770	277	A	0.99921	There's a little bit more that needs to be fleshed out there.
2462420	2480948	278	A	1.0	And then one question that was like, again, somewhere between testing our comprehension and being clear about what we're doing here, and in this ambiguity, we can ask it without any bias, the negative free energy gradients.
2481044	2483000	279	A	0.68	I e prediction errors.
2484700	2487156	280	A	0.99971	What is a prediction error?
2487188	2489160	281	A	0.67	A free energy calculation.
2490220	2492636	282	A	0.99447	Well, ignore gradient for a second.
2492818	2495224	283	A	0.99999	Free energy calculations are not prediction errors.
2495272	2498568	284	A	0.71771	Prediction errors are observations minus expectations.
2498744	2503576	285	A	0.99997	So this is like some finite value in the state space of what is being measured.
2503768	2511456	286	A	0.99999	Free energy is not that it references potentially those variables, but it does things that we know about, like KL divergences and such.
2511558	2514556	287	A	0.97	Okay, so free energy is not prediction error.
2514668	2527280	288	A	1.0	And that's a huge difference between, for example, a predictive processing framework and a free energy hierarchical predictive architecture.
2527440	2532360	289	C	0.68215	Eric but they're saying the gradient and free energy is a prediction error.
2532860	2533512	290	A	0.99999	Exactly.
2533646	2540832	291	A	0.93194	So even if it were that's, then that was the next question, which was, what's the difference between free energy and the free energy gradients?
2540996	2553150	292	A	0.99992	Are we talking about a landscape of derivatives, of free energy energies, or are we talking about what here?
2554660	2558508	293	A	0.99997	Is it being described as a gradient, as a landscape?
2558684	2569430	294	A	0.83	And hence gradient ish because it can be calculated over some discrete, bi continuous state space.
2570360	2578410	295	A	0.88147	It's like five skyscrapers that you could have derivatives over in the Y direction, but you couldn't take the partial x.
2579740	2589064	296	A	0.94255	Or is it truly or is it a continuous landscape that just being tethered to the discrete values in x?
2589102	2591836	297	A	0.99996	But then again, that's that whole continuous, discrete question.
2592018	2599580	298	A	0.99991	Or are the values gradients, which has an even more complex interpretation.
2600480	2619780	299	A	0.99484	So we don't have the answers on these, but it's hard to understand how these figures could have epistemic or pragmatic value for learners or practitioners without some of these questions being resolved.
2623080	2630392	300	A	0.92	All right, the first example, this is just kind of from walking through.
2630446	2638484	301	A	0.9999	So the first example was just hidden Markov model hidden states updating through time, Bayesian filter column and filter.
2638532	2642060	302	A	0.80787	This is like just standard signal processing in a Bayesian framework.
2643040	2644376	303	A	0.56	And we're.
2644408	2665410	304	A	0.96523	Going to see a lot of echoes of the step by step model stream one, they give an even simpler example with static perception, one step perception and then go second to the dynamic case, then introduce action pi policy and then nuance policy through like uncertainty and so on.
2666200	2674020	305	A	0.99178	So that's the first inferential case they're then going to head into decision making and planning as inference.
2674360	2686250	306	A	0.94913	So we see policy being introduced as a variable that influences how states change through time.
2688620	2691710	307	A	0.99998	Does policy do that or does action do that?
2693120	2702696	308	A	1.0	In the one step limit, policies are actions are affordances, but Pi is specifically reserved for sequences of actions.
2702728	2710240	309	A	0.99997	So is it that sequences of actions like do that or is this the actual base topology?
2711780	2746430	310	A	1.0	But nonetheless, that architecture allows the evaluation of alternate policies in terms of their relative expect variational or expected free energy, depending on whether a one step policy is accomplishable with variational free energy that's, like the instantaneous move, most consistent instantaneous maneuver versus even one step in advance is going to broach into this whole expected free energy space we had on 130.
2747440	2752300	311	A	0.65526	So there's a really important discussion.
2753140	2757410	312	A	0.62716	Bozaki is also very interesting researcher neural rhythms and so on.
2760420	2773216	313	A	0.99935	Factorization is a really important topic and being able to distinguish like neurologically what do we mean when we talk about the what and the where stream, the dorsal and the ventral stream and critiques of it, et cetera.
2773248	2791150	314	A	0.62672	But just what and where in the brain and then in the factor graphs and computationally because the unfactorized models, if we're just doing the all by all by all by all, those become intractable very fast.
2791520	2802156	315	A	1.0	And the specification of the sparsity of the model is one and the same in the variational base framework as the factorization of the model.
2802338	2813360	316	A	0.99999	So factorization is like kind of focusing your search efforts on manifolds where you've constrained certain things to be like linked or unlinked.
2814740	2830680	317	A	1.0	That is what motivates the structure learning problem and the need to have to not be locked into factorization schemes at a given level of analysis.
2834300	2841580	318	A	0.99	Okay, another just question to explore.
2842880	2847532	319	A	0.98274	Like here we have the top half of figure 43.
2847666	2849500	320	A	0.99996	There's just one A matrix.
2851440	2854210	321	A	0.99991	So why are there two A matrices here?
2855140	2861010	322	A	0.9998	Well, it's not an impossible question and the symbols go a long way.
2861620	2870420	323	A	0.99794	Here's the four locations that the animal can be in starting position, bottom position, left arm or right arm.
2871480	2885656	324	A	0.99989	Then here are the it's five on the X here because that bottom could, could reveal an R or reveal an L.
2885838	2892030	325	A	0.99	In this case it reveals an R and the food is honestly there.
2892560	2903708	326	A	1.0	And then this is a second a matrix that is describing how location is associated with the food.
2903874	2906320	327	A	0.76889	None aversive or positive.
2907220	2909292	328	A	0.57699	But this ties into the earlier discussion.
2909356	2914610	329	A	0.93303	Like it might be all one thing to say well it's four x five and then four by three.
2915560	2919590	330	A	0.76753	But is this actually a four x five by three.
2923240	2924710	331	A	0.99	I know it's not.
2925480	2926950	332	A	0.99991	Eric, what do you think?
2927400	2930730	333	C	0.99984	Yeah, and they'd mentioned in there it's a tensor also.
2932220	2943628	334	C	0.76	And the tensor means that you're stacking this one, this image against the version where the reward is on the left side.
2943794	2949484	335	C	0.99837	So the tensor is going to be four x eight by two.
2949682	2952056	336	C	0.99962	So that makes sense for being the tensor.
2952088	2954384	337	C	0.92313	So the state is another layer on top of this.
2954422	2957090	338	C	0.76	The hidden state is another layer on top of that.
2958180	2968260	339	A	0.57	Yes, section 73.
2968330	2973892	340	A	0.99856	So this would be a fun kind of like PH d.
2973946	2975190	341	A	0.99814	Qualifying level.
2975720	2983450	342	A	0.99983	Question just describe the whole team ace every row, every column and every value.
2983980	2985450	343	A	0.99993	Why is it that way?
2989130	3010426	344	A	0.93089	So we're not going to type it out here, but to understand that example and what the B matrices are, and just to have agility and just identifying the differences between these matrices numerically, like pattern recognition, like, oh, here there's two ones, here two zeros.
3010458	3013182	345	A	0.99998	Here two zeros, here two ones, here one and zero.
3013236	3014480	346	A	0.99901	These stay the same.
3014850	3029460	347	A	1.0	And then to be able to transpose that in your understanding to what this means in terms of transition frequencies, every place where there's a difference, it's a difference that makes a difference.
3029990	3035480	348	A	0.99994	So being able to understand what those are is about understanding this example.
3035930	3064320	349	A	1.0	And one can imagine, especially if they're wanting to make an application of active inference that's more complex than this, four x four, being fluent with how these matrices are constructed, their dimensionality, how differences in the generative process are incorporated, how differences in the generative model are incorporated, all these different features are important.
3068230	3070900	350	A	0.61	Yes, Eric, this is definitely very important.
3071670	3073326	351	A	0.97385	Question agreed.
3073358	3082680	352	A	0.67774	Like it, it looks extremely neural, and these traces come up all the time.
3085450	3097370	353	A	0.99997	Similarly, here we have three discrete time points starting going to the Q, getting the L, and then going to the left arm.
3098750	3099834	354	A	0.58089	But then what is this?
3099872	3106540	355	A	0.98787	Step one and a half is the one, all of these points.
3107470	3111226	356	A	0.95	And then by two, the uncertainty is resolved.
3111258	3115054	357	A	0.67	The belief about certain things goes to zero, the belief about other things goes to one.
3115252	3117418	358	A	1.0	And this is just a pure interpolation.
3117514	3129700	359	A	0.69291	But that is quite a specific interpolation, including what appear to be some like dopaminergic spikes or something that are not reflected at either of the time points.
3130310	3132822	360	C	0.9999	My guess is that you've got three different blocks there.
3132876	3146540	361	C	0.99992	So if you take the one as being the width, one third of the way across the two is another third and the three is another third, then that switch there that you see happens as soon as you transition from the one to the two.
3149860	3156640	362	A	0.87	Yes, although still there's even the graphical interpolation interpolation.
3157560	3166870	363	A	0.88978	Question and it's so easy to be like reading is it just a quirk of the dashed line?
3167960	3170916	364	A	0.98406	But are there two dashed lines?
3171028	3175640	365	A	0.98	And two dashed lines diverged in a neural trace?
3177340	3179560	366	A	0.98799	But it's kind of clear.
3179630	3182120	367	A	0.99291	These ones, the discrete formulations are clearer.
3183340	3184090	368	B	0.68584	Yeah.
3184720	3185470	369	A	1.0	Okay.
3185840	3188040	370	A	0.81334	Are rats prone to useless behavior?
3188200	3189310	371	A	0.99997	What do you think?
3189840	3191420	372	A	0.99961	What useless behavior?
3194640	3195932	373	C	1.0	I wrote it out.
3196066	3202224	374	C	0.99	Okay, this is good time for today, but that's my most provocative comment on this one.
3202262	3204050	375	C	0.98	And maybe we can save that for next week.
3204420	3205280	376	A	1.0	Okay, perfect.
3205350	3209430	377	A	0.61808	Let's pick up with this one and any other questions.
3209960	3214144	378	A	0.99962	Then we'll glance over the visual cicade.
3214272	3215990	379	A	0.99981	Look at the learning example.
3216840	3219140	380	A	0.99991	Consider the hierarchical example.
3219290	3220384	381	A	0.99994	There's the maze.
3220512	3222310	382	A	0.99998	Then there's the hierarchical example.
3222760	3225072	383	A	0.99989	Another nested.
3225136	3228580	384	A	0.91127	Discrete meets neural continuous trace.
3229960	3232040	385	A	1.0	And then we end on Stefan's squared.
3232120	3234524	386	A	0.99685	So thank you all.
3234722	3236270	387	A	0.99868	Have an excellent day.
