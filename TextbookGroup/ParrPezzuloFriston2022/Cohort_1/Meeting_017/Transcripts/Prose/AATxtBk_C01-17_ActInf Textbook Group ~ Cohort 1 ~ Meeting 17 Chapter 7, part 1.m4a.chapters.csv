start	end	startTime	summary	headline	gist
1290	113490	00:01	It's cohort one meeting, 17 already. We're having our first discussion of chapter seven in the textbook. Please raise your hands or write in the chat if you want to address anything at any point.	We're having our first discussion of chapter seven in the textbook	C cohort 1 discussion of chapter 7 in the textbook
115460	463026	01:55	What I cannot create, I do not understand by RF. How can the Generative Model have anything like understanding without generating? Everyone is welcome for every chapter to be contributing on these pages.	Mike: We're going to start with the opening quotation of the chapter	The Power of Active Inference
463058	664550	07:43	There are several layers. As with other scriptural traditions, there's levels of readings. And then there's the consequences of changes in relationships within and outside the formalism. Changes from one can propagate throughout a whole system, potentially in nonlinear ways.	As with other scriptural traditions, there's levels of readings	Active Inference: Several Levels of Reading
665530	1471110	11:05	It speaks to the exploration exploitation dilemma in psychology and machine learning. A dilemma that's resolved under active inference. But how could it be said that active inference resolves that dilemma?	This chapter speaks to the exploration exploitation dilemma in psychology and machine learning	The Exploring Exploitation Dilemma in Psychology and Machine
1473240	1646590	24:33	The balance between Pragmatic and Epistemic is the optimization. Does active inference provide us a natural language grounded first principles approach? It may, but that is also not dilemma resolution. These are like super helpful questions.	There is a balance between expected reward and expected information gain in reinforcement learning	Inference and the Problem of Pleasure
1647040	1996910	27:27	In Pym DP or in any given computational implementation, the data structures may have a dimensionality that reflects potentially, at worst, a combination of the dimensionality of other aspects. This is the mountain to climb, to implement these kinds of models.	Jacob: The dimensionality of transition probability matrices is very important	Pym DP and the dimensionality of the matrices
1998080	2307330	33:18	Figure 7.2 is a musical note type representation. They're beliefs about each note in the sequence at each time step. It's related to some functions in MATLAB. Could this imply a machinery for unpacking a continuous time action perception cycle from discrete time specification?	Figure 7.2. So the first example is about a musician playing music	Intro to the Action Perception Cycle
2307780	2619780	38:27	SPM arose from the immediacies of needing to do neuroimaging registration and dynamical analysis. What's the difference between free energy and the free energy gradients? It's hard to understand how these figures could have practical value for learners or practitioners.	What are free energy gradients and what is a prediction error	Free Energy and the Bayesian inferential framework
2623080	2830680	43:43	The first example was just hidden Markov model hidden states updating through time. We see policy being introduced as a variable that influences how states change. Factorization is a really important topic and being able to distinguish like neurologically.	The architecture allows evaluation of alternate policies in terms of their relative expect variational	Inferring from a Bayesian framework
2834300	3236270	47:14	Why are there two A matrices here? Well, it's not an impossible question. Being fluent with how these matrices are constructed is important. Are rats prone to useless behavior? What do you think?	Question to explore: Why are there two A matrices here?	Neuroanatomy 4, Intelligence
