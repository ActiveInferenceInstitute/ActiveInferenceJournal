start	end	paragNum	speaker	confidence	startTime	wordCount	text
1290	19680	1	A	0.71545	00:01	30	Welcome. It's cohort one meeting, 17 already. And it's September 23, 2022. We're having our first discussion of chapter seven in the textbook. Well, we have many ways to go.
20130	55150	2	A	0.99662	00:20	73	We have questions on chapter seven that people have been adding. We also have some summaries and overviews and can walk through the text directly. But first, does anyone want to just raise their hand or unmute and give any thought that they had on chapter seven, their experience reading it, their understanding of where it's situated in the textbook overall, what was in it, or what was not in it, et cetera?
79800	120800	3	A	0.74	01:19	77	Okay, well, open again. Please raise your hands or write in the chat if you want to address anything at any point. I want to open by acknowledging a lot of the contributions Ali made and in some conversations that he and I had earlier this week that I believe all of you cohort wanderers will find interesting. But first, let's just start with this quotation. We're going to start with the opening quotation of the chapter.
120960	141300	4	A	0.83512	02:00	51	Then I'm going to surface some discussions with Ali, and then we're going to go into some details of the chapter. So the quote is, What I cannot create, I do not understand by RF. So what does anyone think about that quotation? Or what does it mean in this context?
144780	145530	5	A	0.1708	02:24	1	Um.
150780	164380	6	B	0.94	02:30	20	I think I mean, it's more applicable. Applicable? Applicable. The more complex. The thing is that you're trying to build.
164530	198310	7	B	0.66595	02:44	53	But what priors or what way could your Generative Model create an accurate prediction of the operation of something or the underlying dynamics of something if you do not kind of step by step generate the affordance, take the actions that generate those affordances, I don't see any causal path to doing that.
200380	207740	8	B	0.99	03:20	12	You would have to step through it necessarily, if it's computationally complex.
209920	229452	9	B	0.87229	03:29	38	So that's most things in the world. But yeah, awesome. It's like this is the low road answer. Like, how can the Generative Model have anything like understanding without generating? You can't just have it on the shelf.
229596	274690	10	A	0.83	03:49	78	And then someone has added a mild answer. We can't have understanding just through mental envisioning that the algorithms need to be implemented for a learner's journey. And then this is also an even deeper or stronger point, which Friston and others have been working on for a long time, which is like it's sentient artifacts in the world that will be the realization of active inference. It's not just like some nice derivations. Brock and anyone else.
275300	336980	11	B	0.93	04:35	137	I was just going to add something about hidden states. There again, coming back to computational complexity, but there's things now that we're starting to build that we don't really 100% understand all of the dynamics of what is or just in general. We invent things that we don't completely understand first. And then based on the observational, based on the evidence that we observe, that it is consistently exhibiting some behavior that directs our attention that directs where our generative model pursues more observations. But we're definitely getting towards a point where that's kind of no longer going to be possible in the way that we usually try to use math to just shortcut stuff, where the operation of the dynamics of the things that we're going to build are necessarily going to be the proof.
337560	339700	12	B	1.0	05:37	7	Their existence will be their own proof.
343000	378636	13	A	0.99994	05:43	68	Awesome. Okay, so just fun starting quotation upload. That one for sure, though there's some detailed things about the examples and some of these I've been working on. Everyone is welcome for every chapter to be contributing on these pages. Like kind of just trying to overview what these examples are because a chapter, it states it up front, yet I missed it the first several times reading.
378668	430770	14	A	0.99998	06:18	114	It like these illustrated models of every color in the rainbow are the section titles, and those are the functionalities that are getting layered in sometimes building on the same model. Like there's like Team A's version one and then there's Team A's version two. Other times it's switching between models or showing two different models that illustrate the same cognitive functionality. Other times the simulation outputs are shown, other times they're not. So there's like a lot of heterogeneity in the observations in this chapter, but it really wasn't until I saw that these first paragraph words were the section titles that it made more sense how the chapter was being laid out.
431460	435060	15	A	0.78483	07:11	7	So that's just kind of one note.
437960	449400	16	A	0.38887	07:17	26	Ali, do you want to raise any thoughts or describe a little bit about our discussion on how we're going to move forward on the equations?
454950	462258	17	A	0.9	07:34	13	Okay. If you unmute, then go for it. Otherwise okay. Yes. No, Mike.
462354	474730	18	A	0.60961	07:42	23	Thank you. Ellie. All good. So we were discussing how there are several layers. As with other scriptural traditions, there's levels of readings.
475470	523000	19	A	0.99975	07:55	90	So there's a level of reading that is even more granular or below where we've been currently targeting. Like, here's equation 25, there's a reading for accessibility and understanding that would potentially be like F open square bracket, q comma y closed bracket equals negative sign expectation over Q, open parentheses, et cetera. So it's like the reading of the notation. Then the notation can be substituted for terms in the active ontology, which is like the level that's being described here, but this is not to be seen here.
526110	604340	20	A	0.99917	08:46	149	This is the level where notation could be aligned across papers because their notational reading would be different, but then they might be referring to the same exact composition of the active ontology. Then once the ontology definition has been squared, the terms could be condensed into meaningful units like accuracy, complexity, risk, expected risk that gives symbolic in the more conversational sense rather than in the notational sense. And then that's where memes and themes and rhetoric around what active inference formalisms say start to arise. And then there's the consequences of changes in relationships within and outside the formalism because it's kind of like there's this larger structure for like a POMDP and changing one variable. If you're only looking at one view or one kind of sub formalism, turn it up to eleven yet that might influence other variables that aren't part of that formalism itself.
604790	644798	21	A	1.0	10:04	91	And so this is like a very open question that touches on everything from the implications of changes to relationships that aren't formally specified. For example, the Bayes graph, the edges reflect a certain type of relationship as we've explored, but changes from one can propagate throughout a whole system, potentially in nonlinear ways. So it's always going to be this kind of open area. How changes, including counterfactuals about the formalism, what if risk were situated this way instead of that way? Or how does that relate in this case?
644884	664550	22	A	0.99207	10:44	46	So this is kind of an open one. Again, people please update it and modify it. But some of these equations which we'll get to. So we'll come to why we had that conversation in a 7.8 later. But that was like one really interesting conversation.
665530	736320	23	A	1.0	11:05	150	And then there was one other okay, then just to kind of jump into a chapter seven topic but also kind of reframe our learning journey as we're all working through this for the first time in the textbook group. So they wrote, um, this choice in the teammates and then Eric or anyone else. I know that you had some questions on the teammates, or we can go to the earlier examples, but this choice of what to do do you seek out the informative queue and then go to the arm that you've now reduced your uncertainty about where the reward is? So do you take an epistemic action and then have a better chance of making the pragmatically good choice or do you just go and make the pragmatic choice? Do you take one step up or do you take one step back for two steps up?
736930	796562	24	A	0.99861	12:16	110	It speaks to the exploration exploitation dilemma in psychology and machine learning. A dilemma that's resolved under active inference. So we were just cracking up because first a low familiarity learner might not know what these terms are or like why it's relevant to even talk about this situation. Familiarity might look like knowing metaphors, examples, intuition, some relevant citations or historical anecdotes about this. The understanding in terms of what the active inference formalism says about this, if it's resolved under active inference then understanding that resolution is about the basis and then from understanding there could be like further developments and applications and then we'll come to this.
796696	858038	25	A	1.0	13:16	128	But what was making us laugh was surely there are parameterizations in which the rat and the teammates always does one thing or always does the other. So it's not that the explore exploit trade off is simply resolved under active inference even though people commonly point to things like the ability to rapidly switch between exploratory and exploitative behavioral policies because there's parameterization of that model and structure learning including that that has to be accomplished such that the model can be in a kind of critical point where it behaves adaptively and thus in a situation manages the explore exploit tension under certain constraints. But how could it be said that active inference resolves that dilemma? So maybe to whomever wrote this one? What is happening?
858124	863800	26	A	1.0	14:18	11	Yes, please. Eric, classical Eric writing here. So what about this?
865870	906760	27	C	0.96557	14:25	108	Yeah, I'm kind of the heckler at the garden party here. You can see in most of my comments and questions but yeah, maybe it's just best to I mean it's maybe better read than spoken but yeah, I don't see this as a valid claim that they well, first of all, I don't know why they call it a dilemma for psychology. It's a trade off. It's been understood for years and there's ways of formalizing it and you solve it through optimization. It might be a dilemma for a creature because they don't know what they should do, but that's not a dilemma for the field.
908170	946180	28	C	0.51	15:08	90	And then I guess the other paragraph is I don't see that they offer any resolution. All they do is they put it into the same they use a common language, free energy. They put exploration and exploitation into the same equation and call it with this information based term called free energy which is perfectly valid. That's great. But that doesn't resolve the problem because as you pointed out, you've got parameters and the designer or somebody has to figure out what those relative weights are, the parameters are.
946630	991298	29	C	0.79	15:46	85	And so you really haven't advanced anything fundamentally, simply by using this free energy way of expressing what the trade off is as opposed to some arbitrary measure called energy or preference or something like that. So I just think that it doesn't help them when they overclaim, which is my opinion and you can convince me otherwise, I'm open. But it seems to me it doesn't help them by overstating their contribution to resolving exploration versus exploitation. Yes, very insightful. I actually totally agree.
991384	1063830	30	A	0.99	16:31	140	I purposely tried to not mention it as a dilemma either. I think tensions, trade offs, these are all valid but that's kind of micro linguistic and a more serious issue is that claims that do crystallized out from the text and things that people can copy and paste and quote if this were a courtroom scenario did you say that active inference resolves exploration exploitation? The answer has to be yes, it was claimed in the book. Could somebody contextualize that like it's providing a first principles way where there are tunable or learnable or parameter sweepable features of models that sit at a really well positioned intersection of human interpretability and manifolds of relevant model variation? Yes, in an extremely charitable reading one could kind of bring this from coming off over the edge back onto the table.
1065390	1097650	31	A	0.99955	17:45	46	That would also make active inference less surprising and less realistically hyperbolic and be part of this process of seeing the evidence in the realization, not in the kind of ironic like we have a different partitioning of a statistical variable value. So nice points Brock.
1100470	1129920	32	B	0.87	18:20	44	I guess I wanted to agree with that and then also maybe play a little devil's advocate, it's all information so solved just because it's been formulated or renamed to something pragmatic value, epistemic value, it doesn't seem like that resolves it or something.
1134290	1194114	33	B	0.99623	18:54	107	I'm wondering if the reading of that though could be not that there is still a trade off but that the dilemma. Is that what they're talking about is that the trade off, like when do you explore or when do you exploit? Not that there is a trade off but that is this last sentence and a half here. The resolution stems from the minimization of free energy. Is that whether you would seek pragmatic value or epistemic value is conditioned on which your model believes to be the free energy minimizing choice though you still have the dilemma, so to speak, or the trade off.
1194312	1201490	34	B	0.99964	19:54	12	But which side of the trade off you take is maybe resolved.
1203990	1207560	35	C	0.9999	20:03	10	By a. Generative model here or not, I don't know.
1209610	1237680	36	A	0.95069	20:09	59	Thanks Brock. I think the field is set for a situational resolution that may be as good or maybe better than other ways that it's been addressed but it comes down to the exact numbers that are chosen. So like in the example of the teammates. So we can look at for example this zero six and negative six.
1239810	1280986	37	A	1.0	20:39	97	What if it was negative 3000 and positive 3000? And so this came up in the live stream 45 with Ryan Smith on the folk psychology where the intensity of the preference was represented. And so if the preference is so we prefer having more food, is that going to be 1000 versus zero? Because if so even the scantest probability of achieving food will be pursued. In other words, that model is going to be parameterized way, way on one side and it's going to exploit only or it's only going to take locally greedy behavior.
1281178	1320140	38	A	0.70875	21:21	100	Whereas if someone said well my behavior for food is zero zero one then maybe even the most obvious strategy would not be undertaken because it's so close to having a flat preference. Why is zero one versus why is 3000 too high and zero one too low? Well it has to do with the ratios and the interactions of a lot of the parameters. So it's not even going to be like well my preference is three comma one. That is going to be just like two parameters being drawn out from a potentially massive parameterization of a model.
1321230	1381188	39	A	1.0	22:01	106	And so preferences just only speaking of preferences may be very hard to compare across situations because it's not like plus six for the preference for food and negative six. It doesn't have a semantic meaning in the world. It's literally a model parameterization. And so then the question becomes how can this framework or this way of having of combining probabilistic inference and energy based inference for strategic decision making, how can those parameters be tuned into a region of subspace or manifold where the behavior is flexible and adaptive? So I think the stage is prepared for a first principles resolution in charitable reading.
1381284	1395470	40	B	0.58254	23:01	28	Sorry. Yes, please. Yeah, I was just going to say Ali shared this paper meta control of the exploitation exploration exploitation. It's in the nearby chat link. Nice.
1396800	1440490	41	B	0.74367	23:16	93	But yeah, it's not that it solves it like in some grand it eliminates exploration exploitation or that it even completely currently it's just the affordance, I guess seems to be there to explain which one why. Like you're going through that there's a preference heavy here or heavy there and it's not that it's base optimal, right? It's not that it makes sense or it's adaptable or anything like that necessarily, just that there is some causal through line, maybe. Yes. Eric yeah, so I want to first read Ali's comment here.
1440960	1471110	42	C	0.94	24:00	73	The critical point to establish is to define action selection as a balance between maximalization of expected reward and expected information gain which are functionals of posterior beliefs about latent states of the world. So that touches on one of the questions which I also wrote comments on, which is about the team, a's example in particular, and I don't know if we'll have time, but we may get to that one today.
1473240	1536568	43	C	0.70187	24:33	146	But the questions specifically I want to raise about this comment, or maybe I guess this is a quote about there being a balance between maximization of expected reward versus expected information gain. That's one way of having a trade off. But you might look for an agent that only wants to maximize reward in the long run, but in order to do that, that entails information gain and that therefore gives a motivation for why you want to attend to the other term, the information based learning based term or knowledge refining a state based term. But that's in the service of the larger gain. And that's essentially what a reinforcement learning tries to do is say look, we're going to look ahead so that the moves we take now will bring us advantage in the future and there's a time discounting and all that.
1536734	1546460	44	C	0.5951	25:36	22	So that takes away the idea of information as being a value in and of itself, but it's only for a purpose.
1549200	1585688	45	C	0.41073	25:49	60	I'll raise that specifically with regard to the team. A's example in a different question. Yeah, thank you. The balance between Pragmatic and Epistemic is the optimization. So that is the question and that is the critical point and that's the situational balance that modeling is going to be evolving around it's like some situationally optimal or preferable strategy around.
1585854	1617430	46	A	1.0	26:25	44	That is the point. But pointing to the point is not the resolution. Does active inference provide us a natural language grounded first principles approach? It may, but that is also not dilemma resolution. So onto some questions, but these are really great points.
1618840	1660560	47	A	1.0	26:58	99	Okay, this is just an example of a type of question that I encourage people, especially if they're going back to the earlier chapters or just whenever they feel like making a contribution of this kind. These are like super helpful questions. Again, the questions we write, some of them may be included in really important educational materials, not the least of which many further textbook groups, but potentially even far beyond that. So what would you ask somebody to understand their comprehension of the materials? So I understand what are the rows, columns and numbers in these equations?
1662740	1693468	48	A	0.54	27:42	75	And it even says it in the text. It's the probability of the next state. So the next state is in the rows, and then the current state is in the columns. And this gets distributed across everything so that the rows and columns sum to one as any other transition probability matrix would be expected to have. So we don't need to discuss it unless somebody wants to go into a little more detail.
1693634	1734708	49	A	0.99999	28:13	89	But this is going to be at the core of that third step of the recipe, which is you might have the structural form from the second step of the recipe in chapter six. And then the next step is to kind of specify or instantiate, like in code, what the dimensions are of these matrices. This is just saying like they are matrices. There's some prior tensor matrix, some hidden state, some transition matrix, some emission matrix. And this is like the structure step two of the recipe.
1734884	1763010	50	A	0.99999	28:54	60	Step three, how many rows and columns. And as Yaakov and others have been exploring, there's the rows and columns of the analytical representation with the equations. And then there's how Pi MDP does it, and there's how different computational realizations do it. Jacob, would you want to add anything about the dimensionality of these matrices? It could be interesting.
1767060	1846904	51	D	0.50458	29:27	146	Yeah, I can probably speak more to how Pyme DB deals with the dimensionality, which currently is probably adds unnecessary redundancy to them. Like if you're dealing with more complex state space or rather more high dimensional state space, and you have different modalities that you want to encode in these matrices because you're then performing matrix multiplications, you need to keep the dimensions of the matrices in those given modalities equal, at least in time DP not in other methods as far as I'm aware. But that means that then you have dimensions within these matrices that don't contain any information. So say you have a grid that you represent for the likelihood mapping of observation and state in physical world, but then you have another type of observation, like where is another agent located with respect to you? Are they in a certain direction?
1846952	1892824	52	D	1.0	30:46	110	And that might be represented by five observations, say, like they're above, they're below, they're to the right, to the left, or not at all. Then you would need to encode the observation in the nine by nine matrix, but then you need to replicate it five times because that is the same for each of those relative observations. But then when you want to encode the likelihood mapping just for the second type of observation. I'm actually not entirely sure what that would be, but I'm presuming it's going to be like five by five, but then replicated. Nine times or something like that, just so the dimensionality matches.
1892872	1948328	53	D	0.99998	31:32	92	Because then you're doing inference over both modalities and at least in prime DP, you're then performing matrix multiplications over both of them. Thank you. Jakub. One way I'm kind of like seeing that is there's the sparsity of the graph. But then, in Pym DP or in any given computational implementation, the data structures, including potentially, like, auxiliary data constructs, may have a dimensionality that reflects potentially, at worst, a combination of the dimensionality of other aspects as part of even just a Temp file that you didn't even exactly specify.
1948504	1996910	54	A	0.99998	32:28	102	There might be some intermediates, stated or unstated intermediates whose dimensionality isn't merely the dimensionality of the analytical representation. It's a little bit of a subtle implementational point. But this is the mountain to climb, to implement these kinds of models. And also, just while we're on this topic, I think it's one area where CAD CAD is going to be very interesting to explore in active block for its package, because we also can imagine that the execution order of certain operations, even in a single agent setting, not just the multi agent setting, is really relevant. So there's that question.
1998080	2004930	55	A	0.89	33:18	17	All right, so figure 7.2. All right. So the first example is about a musician playing music.
2008180	2035770	56	A	0.54593	33:28	56	We are not aware of this example being used anywhere else. Like the citations following those. This musical note type representation is not shown. And previously we kind of discussed how some of these trace black and white images are really ambiguous because of being like, intersecting black lines. And then, of course, the empty square.
2037500	2048110	57	A	0.91	33:57	21	Yes. Can you say where those black lines come from? You want to dive into that right now? Yeah. Well, okay.
2049760	2083576	58	A	0.86	34:09	85	The upper left, each black line, even though it can be hard to trace them, I think they're just being shown like representationally. They're beliefs about each note in the sequence at each time step. So the time steps are on the x axis and the belief in terms of a probability are on the y axis. So initially right. So there's some there's some sort of and this gets to another question that was raised, but maybe this is time to talk about it.
2083678	2114210	59	C	0.8367	34:43	72	There's some sort of engine, some sort of differential equation simulator or something running underneath here right. That is not discussed in the chapter, but that's generating these belief curves. Yes. It's related to some functions in MATLAB. And I was just going to mention that because my sense from the discrete model would be you'd have five, let's say, points on time zero, then you'd have five points on time one.
2115320	2162560	60	A	0.97526	35:15	89	So I thought, well, what is happening with this kind of like little fractal crash right here? How could you have a continuously differentiable oscillating type behavior when all you're calculating analytically is just 12345? Then I thought, is it meaning is, is the, are the points actually at the midpoint? And there's a differential equation that's sort of like ribboning an action perception loop through a discrete time matrix. But then if this is a function that's evaluatable at every point, aren't we in a continuous time setting?
2163700	2195016	61	A	0.99992	36:03	49	So wouldn't that have to imply like a machinery for unpacking a continuous time action perception cycle from discrete time specification? So I agree very much. Yeah. Good. My guess is what they do is they've got the equations, the free energy equations and the parameters are these distributions.
2195048	2243180	62	C	0.92	36:35	103	Okay, what's your belief in these different properties? And those parameters evolve over time through a differential equation because you turn these things into a differential equation and when you change state something like, okay, now we've got another note comes in, then that's what's going to trigger the differential equation to go in a different direction, essentially. And that's why you've got the five discrete kind of regimes here or target points that it kind of evolves to. And then the next note comes in and now the boundary conditions change, essentially. So your differential equation takes you in a different direction.
2244480	2293980	63	C	1.0	37:24	102	I recall that there's something like you guys probably discussed this more than I paid attention, but there's some sort of universal solver that they are providing. So you just plug in your matrices, your state equations, your transition matrices, and then it'll solve it all for you. And that may be what this differential equation solver is about. Do you think that sounds right? Yes, I think whenever, variously in the method sections and supplemental sections of paper, they'll say in the paper, we're only specifying the generative model and the matrices and then we use standard routines to address it.
2294050	2328150	64	A	0.99	38:14	82	Now, I don't think that has the, it's not the pinnacle of accessibility and reproducibility. However, it does at least use standard routines. But again, those are not always specified in the paper, which is an issue. So it'll be important to regenerate examples within SPM and then also to use some of these things that we were discussing with the ability to move between different languages, but like VBX variational, bayes X, I don't know what the X is actually for.
2331420	2417760	65	A	0.76225	38:51	153	It's one of the core functions. It is actually doing the variational inference in SPM. And again, SPM is like this sort of like chimera package because it arose from the immediacies of needing to do neuroimaging registration and dynamical analysis that then broached into dynamic causal modeling, random field theory based statistical testing, permutation testing all these areas that are not themselves formally linked per se, but rather useful as part of the toolkit of a Neuroimaging researcher. Then, just as we were a little bit discussing like chapter two, and of course, many times earlier in that generalized Bayesian inferential framework, hierarchical modeling, including action, is actually not the hardest thing. Yes, implementing action is one thing, but treating action selection as inference, planning as inference, it has some challenges that arise relative to just doing time series anticipation, but then those functions became compiled into SPM in a limited capacity.
2419540	2449340	66	A	0.69225	40:19	49	So again, they go through some of this. But I think it's a key issue. We'll definitely look forward to what the free energy gradients are, but where the continuous nature of these curves and why? There are the numbers that there are 1234-5678, 910. Now there's five notes.
2451040	2452910	67	A	0.68	40:51	5	Ten is two times five.
2455140	2458770	68	A	0.99921	40:55	12	There's a little bit more that needs to be fleshed out there.
2462420	2492636	69	A	1.0	41:02	56	And then one question that was like, again, somewhere between testing our comprehension and being clear about what we're doing here, and in this ambiguity, we can ask it without any bias, the negative free energy gradients. I e prediction errors. What is a prediction error? A free energy calculation. Well, ignore gradient for a second.
2492818	2514556	70	A	0.99999	41:32	60	Free energy calculations are not prediction errors. Prediction errors are observations minus expectations. So this is like some finite value in the state space of what is being measured. Free energy is not that it references potentially those variables, but it does things that we know about, like KL divergences and such. Okay, so free energy is not prediction error.
2514668	2553150	71	A	1.0	41:54	77	And that's a huge difference between, for example, a predictive processing framework and a free energy hierarchical predictive architecture. Eric but they're saying the gradient and free energy is a prediction error. Exactly. So even if it were that's, then that was the next question, which was, what's the difference between free energy and the free energy gradients? Are we talking about a landscape of derivatives, of free energy energies, or are we talking about what here?
2554660	2591836	72	A	0.99997	42:34	76	Is it being described as a gradient, as a landscape? And hence gradient ish because it can be calculated over some discrete, bi continuous state space. It's like five skyscrapers that you could have derivatives over in the Y direction, but you couldn't take the partial x. Or is it truly or is it a continuous landscape that just being tethered to the discrete values in x? But then again, that's that whole continuous, discrete question.
2592018	2619780	73	A	0.99991	43:12	45	Or are the values gradients, which has an even more complex interpretation. So we don't have the answers on these, but it's hard to understand how these figures could have epistemic or pragmatic value for learners or practitioners without some of these questions being resolved.
2623080	2665410	74	A	0.92	43:43	95	All right, the first example, this is just kind of from walking through. So the first example was just hidden Markov model hidden states updating through time, Bayesian filter column and filter. This is like just standard signal processing in a Bayesian framework. And we're. Going to see a lot of echoes of the step by step model stream one, they give an even simpler example with static perception, one step perception and then go second to the dynamic case, then introduce action pi policy and then nuance policy through like uncertainty and so on.
2666200	2686250	75	A	0.99178	44:26	34	So that's the first inferential case they're then going to head into decision making and planning as inference. So we see policy being introduced as a variable that influences how states change through time.
2688620	2752300	76	A	0.99998	44:48	115	Does policy do that or does action do that? In the one step limit, policies are actions are affordances, but Pi is specifically reserved for sequences of actions. So is it that sequences of actions like do that or is this the actual base topology? But nonetheless, that architecture allows the evaluation of alternate policies in terms of their relative expect variational or expected free energy, depending on whether a one step policy is accomplishable with variational free energy that's, like the instantaneous move, most consistent instantaneous maneuver versus even one step in advance is going to broach into this whole expected free energy space we had on 130. So there's a really important discussion.
2753140	2757410	77	A	0.62716	45:53	11	Bozaki is also very interesting researcher neural rhythms and so on.
2760420	2830680	78	A	0.99935	46:00	150	Factorization is a really important topic and being able to distinguish like neurologically what do we mean when we talk about the what and the where stream, the dorsal and the ventral stream and critiques of it, et cetera. But just what and where in the brain and then in the factor graphs and computationally because the unfactorized models, if we're just doing the all by all by all by all, those become intractable very fast. And the specification of the sparsity of the model is one and the same in the variational base framework as the factorization of the model. So factorization is like kind of focusing your search efforts on manifolds where you've constrained certain things to be like linked or unlinked. That is what motivates the structure learning problem and the need to have to not be locked into factorization schemes at a given level of analysis.
2834300	2861010	79	A	0.99	47:14	42	Okay, another just question to explore. Like here we have the top half of figure 43. There's just one A matrix. So why are there two A matrices here? Well, it's not an impossible question and the symbols go a long way.
2861620	2906320	80	A	0.99794	47:41	76	Here's the four locations that the animal can be in starting position, bottom position, left arm or right arm. Then here are the it's five on the X here because that bottom could, could reveal an R or reveal an L. In this case it reveals an R and the food is honestly there. And then this is a second a matrix that is describing how location is associated with the food. None aversive or positive.
2907220	2919590	81	A	0.57699	48:27	36	But this ties into the earlier discussion. Like it might be all one thing to say well it's four x five and then four by three. But is this actually a four x five by three.
2923240	2949484	82	A	0.99	48:43	53	I know it's not. Eric, what do you think? Yeah, and they'd mentioned in there it's a tensor also. And the tensor means that you're stacking this one, this image against the version where the reward is on the left side. So the tensor is going to be four x eight by two.
2949682	2973892	83	C	0.99962	49:09	42	So that makes sense for being the tensor. So the state is another layer on top of this. The hidden state is another layer on top of that. Yes, section 73. So this would be a fun kind of like PH d.
2973946	2985450	84	A	0.99814	49:33	21	Qualifying level. Question just describe the whole team ace every row, every column and every value. Why is it that way?
2989130	3035480	85	A	0.93089	49:49	106	So we're not going to type it out here, but to understand that example and what the B matrices are, and just to have agility and just identifying the differences between these matrices numerically, like pattern recognition, like, oh, here there's two ones, here two zeros. Here two zeros, here two ones, here one and zero. These stay the same. And then to be able to transpose that in your understanding to what this means in terms of transition frequencies, every place where there's a difference, it's a difference that makes a difference. So being able to understand what those are is about understanding this example.
3035930	3064320	86	A	1.0	50:35	55	And one can imagine, especially if they're wanting to make an application of active inference that's more complex than this, four x four, being fluent with how these matrices are constructed, their dimensionality, how differences in the generative process are incorporated, how differences in the generative model are incorporated, all these different features are important.
3068230	3082680	87	A	0.61	51:08	23	Yes, Eric, this is definitely very important. Question agreed. Like it, it looks extremely neural, and these traces come up all the time.
3085450	3115054	88	A	0.99997	51:25	64	Similarly, here we have three discrete time points starting going to the Q, getting the L, and then going to the left arm. But then what is this? Step one and a half is the one, all of these points. And then by two, the uncertainty is resolved. The belief about certain things goes to zero, the belief about other things goes to one.
3115252	3146540	89	A	1.0	51:55	91	And this is just a pure interpolation. But that is quite a specific interpolation, including what appear to be some like dopaminergic spikes or something that are not reflected at either of the time points. My guess is that you've got three different blocks there. So if you take the one as being the width, one third of the way across the two is another third and the three is another third, then that switch there that you see happens as soon as you transition from the one to the two.
3149860	3179560	90	A	0.87	52:29	47	Yes, although still there's even the graphical interpolation interpolation. Question and it's so easy to be like reading is it just a quirk of the dashed line? But are there two dashed lines? And two dashed lines diverged in a neural trace? But it's kind of clear.
3179630	3189310	91	A	0.99291	52:59	19	These ones, the discrete formulations are clearer. Yeah. Okay. Are rats prone to useless behavior? What do you think?
3189840	3191420	92	A	0.99961	53:09	3	What useless behavior?
3194640	3209430	93	C	1.0	53:14	41	I wrote it out. Okay, this is good time for today, but that's my most provocative comment on this one. And maybe we can save that for next week. Okay, perfect. Let's pick up with this one and any other questions.
3209960	3222310	94	A	0.99962	53:29	24	Then we'll glance over the visual cicade. Look at the learning example. Consider the hierarchical example. There's the maze. Then there's the hierarchical example.
3222760	3236270	95	A	0.99989	53:42	22	Another nested. Discrete meets neural continuous trace. And then we end on Stefan's squared. So thank you all. Have an excellent day.
