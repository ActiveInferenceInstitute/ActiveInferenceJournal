start	end	speaker	sentiment	confidence	text
1290	1840	A	0.7317204475402832	Welcome.
2530	6174	A	0.7903352975845337	It's cohort one meeting, 17 already.
6372	9422	A	0.8699618577957153	And it's September 23, 2022.
9556	14190	A	0.8964382410049438	We're having our first discussion of chapter seven in the textbook.
15490	19680	A	0.6184188723564148	Well, we have many ways to go.
20130	26230	A	0.8704976439476013	We have questions on chapter seven that people have been adding.
27370	36630	A	0.79043048620224	We also have some summaries and overviews and can walk through the text directly.
36970	55150	A	0.8042684197425842	But first, does anyone want to just raise their hand or unmute and give any thought that they had on chapter seven, their experience reading it, their understanding of where it's situated in the textbook overall, what was in it, or what was not in it, et cetera?
79800	89656	A	0.7183558940887451	Okay, well, open again.
89758	95310	A	0.8917907476425171	Please raise your hands or write in the chat if you want to address anything at any point.
95680	113490	A	0.9224663376808167	I want to open by acknowledging a lot of the contributions Ali made and in some conversations that he and I had earlier this week that I believe all of you cohort wanderers will find interesting.
115460	118412	A	0.8100826144218445	But first, let's just start with this quotation.
118476	120800	A	0.9093962907791138	We're going to start with the opening quotation of the chapter.
120960	127940	A	0.9139038324356079	Then I'm going to surface some discussions with Ali, and then we're going to go into some details of the chapter.
128280	133360	A	0.705920934677124	So the quote is, What I cannot create, I do not understand by RF.
133520	138384	A	0.8196949362754822	So what does anyone think about that quotation?
138432	141300	A	0.7998582720756531	Or what does it mean in this context?
144780	145530	A	0.6071171164512634	Um.
150780	155652	B	0.6465053558349609	I think I mean, it's more applicable.
155796	156760	B	0.789348840713501	Applicable?
158000	159340	B	0.578325092792511	Applicable.
159680	161464	B	0.6945770978927612	The more complex.
161592	164380	B	0.7309405207633972	The thing is that you're trying to build.
164530	198310	B	0.5943312048912048	But what priors or what way could your Generative Model create an accurate prediction of the operation of something or the underlying dynamics of something if you do not kind of step by step generate the affordance, take the actions that generate those affordances, I don't see any causal path to doing that.
200380	207740	B	0.7508513927459717	You would have to step through it necessarily, if it's computationally complex.
209920	213550	B	0.6575104594230652	So that's most things in the world.
214000	217548	A	0.9294394254684448	But yeah, awesome.
217634	219870	A	0.5728781819343567	It's like this is the low road answer.
220260	227484	A	0.48515835404396057	Like, how can the Generative Model have anything like understanding without generating?
227612	229452	A	0.5797070264816284	You can't just have it on the shelf.
229596	233350	A	0.7556928992271423	And then someone has added a mild answer.
234840	247000	A	0.5694895386695862	We can't have understanding just through mental envisioning that the algorithms need to be implemented for a learner's journey.
248060	268780	A	0.5862460136413574	And then this is also an even deeper or stronger point, which Friston and others have been working on for a long time, which is like it's sentient artifacts in the world that will be the realization of active inference.
269440	272904	A	0.5603116154670715	It's not just like some nice derivations.
273032	274690	A	0.7690733671188354	Brock and anyone else.
275300	277808	B	0.8563797473907471	I was just going to add something about hidden states.
277894	291060	B	0.5101794600486755	There again, coming back to computational complexity, but there's things now that we're starting to build that we don't really 100% understand all of the dynamics of what is or just in general.
291210	294688	B	0.5175378918647766	We invent things that we don't completely understand first.
294874	316280	B	0.8386785387992859	And then based on the observational, based on the evidence that we observe, that it is consistently exhibiting some behavior that directs our attention that directs where our generative model pursues more observations.
316360	336980	B	0.6023073792457581	But we're definitely getting towards a point where that's kind of no longer going to be possible in the way that we usually try to use math to just shortcut stuff, where the operation of the dynamics of the things that we're going to build are necessarily going to be the proof.
337560	339700	B	0.8436828851699829	Their existence will be their own proof.
343000	343750	A	0.9184247851371765	Awesome.
344780	348516	A	0.8029409646987915	Okay, so just fun starting quotation upload.
348548	363052	A	0.7677198648452759	That one for sure, though there's some detailed things about the examples and some of these I've been working on.
363106	367704	A	0.9544495940208435	Everyone is welcome for every chapter to be contributing on these pages.
367752	378636	A	0.6193658709526062	Like kind of just trying to overview what these examples are because a chapter, it states it up front, yet I missed it the first several times reading.
378668	394404	A	0.8043918609619141	It like these illustrated models of every color in the rainbow are the section titles, and those are the functionalities that are getting layered in sometimes building on the same model.
394522	398410	A	0.8600050806999207	Like there's like Team A's version one and then there's Team A's version two.
398940	405880	A	0.8463990688323975	Other times it's switching between models or showing two different models that illustrate the same cognitive functionality.
406800	410908	A	0.7632906436920166	Other times the simulation outputs are shown, other times they're not.
410994	430770	A	0.653940737247467	So there's like a lot of heterogeneity in the observations in this chapter, but it really wasn't until I saw that these first paragraph words were the section titles that it made more sense how the chapter was being laid out.
431460	435060	A	0.8183512687683105	So that's just kind of one note.
437960	449400	A	0.9348865747451782	Ali, do you want to raise any thoughts or describe a little bit about our discussion on how we're going to move forward on the equations?
454950	455700	A	0.584351658821106	Okay.
456150	457858	A	0.7216646671295166	If you unmute, then go for it.
457864	461270	A	0.6404785513877869	Otherwise okay.
461340	461574	A	0.46103888750076294	Yes.
461612	462258	A	0.5379166007041931	No, Mike.
462354	462806	A	0.8529649376869202	Thank you.
462828	463026	A	0.6944395899772644	Ellie.
463058	463606	A	0.8763931393623352	All good.
463708	470070	A	0.8871449828147888	So we were discussing how there are several layers.
470650	474730	A	0.8176191449165344	As with other scriptural traditions, there's levels of readings.
475470	486330	A	0.7154308557510376	So there's a level of reading that is even more granular or below where we've been currently targeting.
486490	503838	A	0.8286784887313843	Like, here's equation 25, there's a reading for accessibility and understanding that would potentially be like F open square bracket, q comma y closed bracket equals negative sign expectation over Q, open parentheses, et cetera.
503934	508530	A	0.7598310708999634	So it's like the reading of the notation.
510330	523000	A	0.6941781044006348	Then the notation can be substituted for terms in the active ontology, which is like the level that's being described here, but this is not to be seen here.
526110	539230	A	0.8427033424377441	This is the level where notation could be aligned across papers because their notational reading would be different, but then they might be referring to the same exact composition of the active ontology.
540530	563800	A	0.8156463503837585	Then once the ontology definition has been squared, the terms could be condensed into meaningful units like accuracy, complexity, risk, expected risk that gives symbolic in the more conversational sense rather than in the notational sense.
564890	575690	A	0.8209497928619385	And then that's where memes and themes and rhetoric around what active inference formalisms say start to arise.
576430	591738	A	0.7679427266120911	And then there's the consequences of changes in relationships within and outside the formalism because it's kind of like there's this larger structure for like a POMDP and changing one variable.
591834	604340	A	0.7803307175636292	If you're only looking at one view or one kind of sub formalism, turn it up to eleven yet that might influence other variables that aren't part of that formalism itself.
604790	616150	A	0.7873644828796387	And so this is like a very open question that touches on everything from the implications of changes to relationships that aren't formally specified.
616570	627946	A	0.8797296285629272	For example, the Bayes graph, the edges reflect a certain type of relationship as we've explored, but changes from one can propagate throughout a whole system, potentially in nonlinear ways.
628128	632060	A	0.7697833776473999	So it's always going to be this kind of open area.
633630	642430	A	0.8469833135604858	How changes, including counterfactuals about the formalism, what if risk were situated this way instead of that way?
642580	644798	A	0.7125573754310608	Or how does that relate in this case?
644884	646382	A	0.8417850732803345	So this is kind of an open one.
646436	649680	A	0.7086397409439087	Again, people please update it and modify it.
650290	655300	A	0.857445240020752	But some of these equations which we'll get to.
655750	660178	A	0.8899308443069458	So we'll come to why we had that conversation in a 7.8 later.
660264	664550	A	0.9256171584129333	But that was like one really interesting conversation.
665530	698498	A	0.6873804330825806	And then there was one other okay, then just to kind of jump into a chapter seven topic but also kind of reframe our learning journey as we're all working through this for the first time in the textbook group.
698664	710166	A	0.8580345511436462	So they wrote, um, this choice in the teammates and then Eric or anyone else.
710188	723146	A	0.8061602711677551	I know that you had some questions on the teammates, or we can go to the earlier examples, but this choice of what to do do you seek out the informative queue and then go to the arm that you've now reduced your uncertainty about where the reward is?
723248	732650	A	0.7417781949043274	So do you take an epistemic action and then have a better chance of making the pragmatically good choice or do you just go and make the pragmatic choice?
732730	736320	A	0.8577582240104675	Do you take one step up or do you take one step back for two steps up?
736930	742226	A	0.8376307487487793	It speaks to the exploration exploitation dilemma in psychology and machine learning.
742408	745410	A	0.78616863489151	A dilemma that's resolved under active inference.
746550	761240	A	0.7093697786331177	So we were just cracking up because first a low familiarity learner might not know what these terms are or like why it's relevant to even talk about this situation.
762810	773100	A	0.751363217830658	Familiarity might look like knowing metaphors, examples, intuition, some relevant citations or historical anecdotes about this.
774430	796562	A	0.8333644866943359	The understanding in terms of what the active inference formalism says about this, if it's resolved under active inference then understanding that resolution is about the basis and then from understanding there could be like further developments and applications and then we'll come to this.
796696	810840	A	0.5366073250770569	But what was making us laugh was surely there are parameterizations in which the rat and the teammates always does one thing or always does the other.
811850	847570	A	0.7467595338821411	So it's not that the explore exploit trade off is simply resolved under active inference even though people commonly point to things like the ability to rapidly switch between exploratory and exploitative behavioral policies because there's parameterization of that model and structure learning including that that has to be accomplished such that the model can be in a kind of critical point where it behaves adaptively and thus in a situation manages the explore exploit tension under certain constraints.
848470	852310	A	0.6341196298599243	But how could it be said that active inference resolves that dilemma?
853050	856646	A	0.8550716042518616	So maybe to whomever wrote this one?
856828	858038	A	0.6401973366737366	What is happening?
858124	858662	A	0.64131760597229	Yes, please.
858716	861654	A	0.8500357270240784	Eric, classical Eric writing here.
861692	863800	A	0.7931777238845825	So what about this?
865870	869434	C	0.6506507992744446	Yeah, I'm kind of the heckler at the garden party here.
869552	889050	C	0.5353528261184692	You can see in most of my comments and questions but yeah, maybe it's just best to I mean it's maybe better read than spoken but yeah, I don't see this as a valid claim that they well, first of all, I don't know why they call it a dilemma for psychology.
889130	890434	C	0.6369283199310303	It's a trade off.
890632	895570	C	0.6606054902076721	It's been understood for years and there's ways of formalizing it and you solve it through optimization.
897510	906760	C	0.5311005711555481	It might be a dilemma for a creature because they don't know what they should do, but that's not a dilemma for the field.
908170	916170	C	0.6018549799919128	And then I guess the other paragraph is I don't see that they offer any resolution.
916990	921770	C	0.7778126001358032	All they do is they put it into the same they use a common language, free energy.
921840	933082	C	0.5940372347831726	They put exploration and exploitation into the same equation and call it with this information based term called free energy which is perfectly valid.
933146	933902	C	0.9799851179122925	That's great.
934036	946180	C	0.5585858821868896	But that doesn't resolve the problem because as you pointed out, you've got parameters and the designer or somebody has to figure out what those relative weights are, the parameters are.
946630	966540	C	0.5277553796768188	And so you really haven't advanced anything fundamentally, simply by using this free energy way of expressing what the trade off is as opposed to some arbitrary measure called energy or preference or something like that.
967230	974940	C	0.7590376138687134	So I just think that it doesn't help them when they overclaim, which is my opinion and you can convince me otherwise, I'm open.
975550	986270	C	0.7667074203491211	But it seems to me it doesn't help them by overstating their contribution to resolving exploration versus exploitation.
988210	989934	A	0.8165537118911743	Yes, very insightful.
989982	991298	A	0.8836448192596436	I actually totally agree.
991384	995490	A	0.7120022177696228	I purposely tried to not mention it as a dilemma either.
995560	1024170	A	0.7886502742767334	I think tensions, trade offs, these are all valid but that's kind of micro linguistic and a more serious issue is that claims that do crystallized out from the text and things that people can copy and paste and quote if this were a courtroom scenario did you say that active inference resolves exploration exploitation?
1025150	1028080	A	0.7029778361320496	The answer has to be yes, it was claimed in the book.
1028690	1052550	A	0.6886776685714722	Could somebody contextualize that like it's providing a first principles way where there are tunable or learnable or parameter sweepable features of models that sit at a really well positioned intersection of human interpretability and manifolds of relevant model variation?
1053850	1063830	A	0.5106450319290161	Yes, in an extremely charitable reading one could kind of bring this from coming off over the edge back onto the table.
1065390	1093778	A	0.5992661714553833	That would also make active inference less surprising and less realistically hyperbolic and be part of this process of seeing the evidence in the realization, not in the kind of ironic like we have a different partitioning of a statistical variable value.
1093944	1097650	A	0.9398861527442932	So nice points Brock.
1100470	1129920	B	0.5380582809448242	I guess I wanted to agree with that and then also maybe play a little devil's advocate, it's all information so solved just because it's been formulated or renamed to something pragmatic value, epistemic value, it doesn't seem like that resolves it or something.
1134290	1145566	B	0.7310103178024292	I'm wondering if the reading of that though could be not that there is still a trade off but that the dilemma.
1145678	1154194	B	0.7507002353668213	Is that what they're talking about is that the trade off, like when do you explore or when do you exploit?
1154322	1162440	B	0.7410166263580322	Not that there is a trade off but that is this last sentence and a half here.
1164030	1167100	B	0.785102903842926	The resolution stems from the minimization of free energy.
1167550	1194114	B	0.8310140371322632	Is that whether you would seek pragmatic value or epistemic value is conditioned on which your model believes to be the free energy minimizing choice though you still have the dilemma, so to speak, or the trade off.
1194312	1201490	B	0.8693957924842834	But which side of the trade off you take is maybe resolved.
1203990	1204430	C	0.643932044506073	By a.
1204440	1207560	B	0.7467206120491028	Generative model here or not, I don't know.
1209610	1210498	A	0.6973928213119507	Thanks Brock.
1210594	1225798	A	0.5634723901748657	I think the field is set for a situational resolution that may be as good or maybe better than other ways that it's been addressed but it comes down to the exact numbers that are chosen.
1225894	1228590	A	0.8290561437606812	So like in the example of the teammates.
1230210	1237680	A	0.8482620120048523	So we can look at for example this zero six and negative six.
1239810	1244194	A	0.7709663510322571	What if it was negative 3000 and positive 3000?
1244392	1254098	A	0.916174054145813	And so this came up in the live stream 45 with Ryan Smith on the folk psychology where the intensity of the preference was represented.
1254274	1264018	A	0.7107802629470825	And so if the preference is so we prefer having more food, is that going to be 1000 versus zero?
1264124	1270422	A	0.7856879830360413	Because if so even the scantest probability of achieving food will be pursued.
1270486	1280986	A	0.5673930644989014	In other words, that model is going to be parameterized way, way on one side and it's going to exploit only or it's only going to take locally greedy behavior.
1281178	1293570	A	0.5065065026283264	Whereas if someone said well my behavior for food is zero zero one then maybe even the most obvious strategy would not be undertaken because it's so close to having a flat preference.
1294230	1299746	A	0.49871572852134705	Why is zero one versus why is 3000 too high and zero one too low?
1299928	1305990	A	0.8392089605331421	Well it has to do with the ratios and the interactions of a lot of the parameters.
1307290	1311800	A	0.5646486878395081	So it's not even going to be like well my preference is three comma one.
1312810	1320140	A	0.6327112317085266	That is going to be just like two parameters being drawn out from a potentially massive parameterization of a model.
1321230	1336320	A	0.5099048614501953	And so preferences just only speaking of preferences may be very hard to compare across situations because it's not like plus six for the preference for food and negative six.
1337410	1341058	A	0.6472394466400146	It doesn't have a semantic meaning in the world.
1341224	1343410	A	0.7240643501281738	It's literally a model parameterization.
1344550	1370998	A	0.8678838014602661	And so then the question becomes how can this framework or this way of having of combining probabilistic inference and energy based inference for strategic decision making, how can those parameters be tuned into a region of subspace or manifold where the behavior is flexible and adaptive?
1371174	1381188	A	0.723703920841217	So I think the stage is prepared for a first principles resolution in charitable reading.
1381284	1381880	B	0.509212851524353	Sorry.
1382030	1382648	A	0.64131760597229	Yes, please.
1382734	1391640	B	0.9023744463920593	Yeah, I was just going to say Ali shared this paper meta control of the exploitation exploration exploitation.
1391720	1394556	B	0.8627403974533081	It's in the nearby chat link.
1394738	1395470	A	0.7344964742660522	Nice.
1396800	1414768	B	0.6289600133895874	But yeah, it's not that it solves it like in some grand it eliminates exploration exploitation or that it even completely currently it's just the affordance, I guess seems to be there to explain which one why.
1414854	1424212	B	0.7185967564582825	Like you're going through that there's a preference heavy here or heavy there and it's not that it's base optimal, right?
1424266	1432570	B	0.7765747904777527	It's not that it makes sense or it's adaptable or anything like that necessarily, just that there is some causal through line, maybe.
1433500	1434296	A	0.46103888750076294	Yes.
1434478	1440490	C	0.8338779807090759	Eric yeah, so I want to first read Ali's comment here.
1440960	1456770	C	0.8696110248565674	The critical point to establish is to define action selection as a balance between maximalization of expected reward and expected information gain which are functionals of posterior beliefs about latent states of the world.
1457780	1471110	C	0.8482376337051392	So that touches on one of the questions which I also wrote comments on, which is about the team, a's example in particular, and I don't know if we'll have time, but we may get to that one today.
1473240	1488116	C	0.8598518371582031	But the questions specifically I want to raise about this comment, or maybe I guess this is a quote about there being a balance between maximization of expected reward versus expected information gain.
1488308	1491148	C	0.7872697710990906	That's one way of having a trade off.
1491314	1521280	C	0.676555335521698	But you might look for an agent that only wants to maximize reward in the long run, but in order to do that, that entails information gain and that therefore gives a motivation for why you want to attend to the other term, the information based learning based term or knowledge refining a state based term.
1521360	1523248	C	0.7409196496009827	But that's in the service of the larger gain.
1523264	1536568	C	0.5254522562026978	And that's essentially what a reinforcement learning tries to do is say look, we're going to look ahead so that the moves we take now will bring us advantage in the future and there's a time discounting and all that.
1536734	1546460	C	0.4910128116607666	So that takes away the idea of information as being a value in and of itself, but it's only for a purpose.
1549200	1551308	C	0.9119563102722168	I'll raise that specifically with regard to the team.
1551394	1553410	C	0.8528735041618347	A's example in a different question.
1554660	1557890	A	0.7961216568946838	Yeah, thank you.
1558740	1565528	A	0.8436586260795593	The balance between Pragmatic and Epistemic is the optimization.
1565724	1585688	A	0.8346958160400391	So that is the question and that is the critical point and that's the situational balance that modeling is going to be evolving around it's like some situationally optimal or preferable strategy around.
1585854	1589450	A	0.6584176421165466	That is the point.
1590480	1594300	A	0.555213987827301	But pointing to the point is not the resolution.
1595520	1602460	A	0.8933015465736389	Does active inference provide us a natural language grounded first principles approach?
1602980	1612400	A	0.6727269291877747	It may, but that is also not dilemma resolution.
1612740	1617430	A	0.9131602644920349	So onto some questions, but these are really great points.
1618840	1632552	A	0.8017574548721313	Okay, this is just an example of a type of question that I encourage people, especially if they're going back to the earlier chapters or just whenever they feel like making a contribution of this kind.
1632606	1634328	A	0.9501369595527649	These are like super helpful questions.
1634414	1646590	A	0.6261115670204163	Again, the questions we write, some of them may be included in really important educational materials, not the least of which many further textbook groups, but potentially even far beyond that.
1647040	1654460	A	0.7561295032501221	So what would you ask somebody to understand their comprehension of the materials?
1655440	1660560	A	0.8678173422813416	So I understand what are the rows, columns and numbers in these equations?
1662740	1664800	A	0.7083054780960083	And it even says it in the text.
1664950	1667076	A	0.8125953674316406	It's the probability of the next state.
1667258	1672100	A	0.876602292060852	So the next state is in the rows, and then the current state is in the columns.
1672520	1687450	A	0.8859618306159973	And this gets distributed across everything so that the rows and columns sum to one as any other transition probability matrix would be expected to have.
1689180	1693468	A	0.6998602151870728	So we don't need to discuss it unless somebody wants to go into a little more detail.
1693634	1705330	A	0.9301885962486267	But this is going to be at the core of that third step of the recipe, which is you might have the structural form from the second step of the recipe in chapter six.
1706340	1721680	A	0.8991408348083496	And then the next step is to kind of specify or instantiate, like in code, what the dimensions are of these matrices.
1721840	1723904	A	0.712074875831604	This is just saying like they are matrices.
1723952	1731156	A	0.891834020614624	There's some prior tensor matrix, some hidden state, some transition matrix, some emission matrix.
1731348	1734708	A	0.8228265643119812	And this is like the structure step two of the recipe.
1734884	1738116	A	0.8310682773590088	Step three, how many rows and columns.
1738308	1747260	A	0.8846855759620667	And as Yaakov and others have been exploring, there's the rows and columns of the analytical representation with the equations.
1748240	1757010	A	0.8501988649368286	And then there's how Pi MDP does it, and there's how different computational realizations do it.
1757940	1761820	A	0.8991514444351196	Jacob, would you want to add anything about the dimensionality of these matrices?
1761900	1763010	A	0.8774906396865845	It could be interesting.
1767060	1782890	D	0.5012827515602112	Yeah, I can probably speak more to how Pyme DB deals with the dimensionality, which currently is probably adds unnecessary redundancy to them.
1783340	1814160	D	0.8407505750656128	Like if you're dealing with more complex state space or rather more high dimensional state space, and you have different modalities that you want to encode in these matrices because you're then performing matrix multiplications, you need to keep the dimensions of the matrices in those given modalities equal, at least in time DP not in other methods as far as I'm aware.
1814980	1820310	D	0.6106559038162231	But that means that then you have dimensions within these matrices that don't contain any information.
1820760	1844590	D	0.8951779007911682	So say you have a grid that you represent for the likelihood mapping of observation and state in physical world, but then you have another type of observation, like where is another agent located with respect to you?
1845440	1846904	D	0.9058720469474792	Are they in a certain direction?
1846952	1856688	D	0.8745538592338562	And that might be represented by five observations, say, like they're above, they're below, they're to the right, to the left, or not at all.
1856854	1871072	D	0.8713778257369995	Then you would need to encode the observation in the nine by nine matrix, but then you need to replicate it five times because that is the same for each of those relative observations.
1871216	1878180	D	0.8564820885658264	But then when you want to encode the likelihood mapping just for the second type of observation.
1879240	1887252	D	0.8376981019973755	I'm actually not entirely sure what that would be, but I'm presuming it's going to be like five by five, but then replicated.
1887316	1892824	D	0.8443787097930908	Nine times or something like that, just so the dimensionality matches.
1892872	1906110	D	0.8873906135559082	Because then you're doing inference over both modalities and at least in prime DP, you're then performing matrix multiplications over both of them.
1907200	1907804	A	0.8529649376869202	Thank you.
1907842	1908700	A	0.6687629222869873	Jakub.
1909300	1916660	A	0.49725520610809326	One way I'm kind of like seeing that is there's the sparsity of the graph.
1917560	1948328	A	0.5253318548202515	But then, in Pym DP or in any given computational implementation, the data structures, including potentially, like, auxiliary data constructs, may have a dimensionality that reflects potentially, at worst, a combination of the dimensionality of other aspects as part of even just a Temp file that you didn't even exactly specify.
1948504	1961120	A	0.8686652183532715	There might be some intermediates, stated or unstated intermediates whose dimensionality isn't merely the dimensionality of the analytical representation.
1962180	1965650	A	0.8563104271888733	It's a little bit of a subtle implementational point.
1966200	1972340	A	0.6599732041358948	But this is the mountain to climb, to implement these kinds of models.
1974120	1994760	A	0.9055840373039246	And also, just while we're on this topic, I think it's one area where CAD CAD is going to be very interesting to explore in active block for its package, because we also can imagine that the execution order of certain operations, even in a single agent setting, not just the multi agent setting, is really relevant.
1994840	1996910	A	0.7275105714797974	So there's that question.
1998080	2000876	A	0.8203879594802856	All right, so figure 7.2.
2000898	2001116	A	0.4896697998046875	All right.
2001138	2004930	A	0.8685901165008545	So the first example is about a musician playing music.
2008180	2012130	A	0.5398460626602173	We are not aware of this example being used anywhere else.
2012820	2014880	A	0.7912209033966064	Like the citations following those.
2015030	2018800	A	0.564923882484436	This musical note type representation is not shown.
2018960	2030436	A	0.5558487176895142	And previously we kind of discussed how some of these trace black and white images are really ambiguous because of being like, intersecting black lines.
2030468	2035770	A	0.48215267062187195	And then, of course, the empty square.
2037500	2038248	A	0.46103888750076294	Yes.
2038414	2040556	C	0.7961679697036743	Can you say where those black lines come from?
2040578	2042830	C	0.8965508937835693	You want to dive into that right now?
2043360	2044110	A	0.5491447448730469	Yeah.
2044880	2048110	A	0.5966773629188538	Well, okay.
2049760	2056320	A	0.7007637619972229	The upper left, each black line, even though it can be hard to trace them, I think they're just being shown like representationally.
2057380	2062752	A	0.8866236805915833	They're beliefs about each note in the sequence at each time step.
2062806	2075056	A	0.9066709876060486	So the time steps are on the x axis and the belief in terms of a probability are on the y axis.
2075248	2076276	A	0.6564635634422302	So initially right.
2076298	2083576	C	0.8441786170005798	So there's some there's some sort of and this gets to another question that was raised, but maybe this is time to talk about it.
2083678	2090772	C	0.8851462602615356	There's some sort of engine, some sort of differential equation simulator or something running underneath here right.
2090846	2096440	C	0.8048681616783142	That is not discussed in the chapter, but that's generating these belief curves.
2096520	2097150	A	0.46103888750076294	Yes.
2097600	2100184	A	0.9135452508926392	It's related to some functions in MATLAB.
2100232	2114210	A	0.8455663919448853	And I was just going to mention that because my sense from the discrete model would be you'd have five, let's say, points on time zero, then you'd have five points on time one.
2115320	2120870	A	0.55666583776474	So I thought, well, what is happening with this kind of like little fractal crash right here?
2121400	2133610	A	0.5782837271690369	How could you have a continuously differentiable oscillating type behavior when all you're calculating analytically is just 12345?
2134300	2140360	A	0.8648459911346436	Then I thought, is it meaning is, is the, are the points actually at the midpoint?
2141200	2150380	A	0.8580362200737	And there's a differential equation that's sort of like ribboning an action perception loop through a discrete time matrix.
2150880	2162560	A	0.8314452171325684	But then if this is a function that's evaluatable at every point, aren't we in a continuous time setting?
2163700	2175940	A	0.8167852163314819	So wouldn't that have to imply like a machinery for unpacking a continuous time action perception cycle from discrete time specification?
2177400	2180456	A	0.8636725544929504	So I agree very much.
2180638	2181370	C	0.5491447448730469	Yeah.
2183180	2183976	A	0.7732179760932922	Good.
2184158	2195016	C	0.8591799139976501	My guess is what they do is they've got the equations, the free energy equations and the parameters are these distributions.
2195048	2198216	C	0.8973753452301025	Okay, what's your belief in these different properties?
2198408	2218384	C	0.8508238792419434	And those parameters evolve over time through a differential equation because you turn these things into a differential equation and when you change state something like, okay, now we've got another note comes in, then that's what's going to trigger the differential equation to go in a different direction, essentially.
2218432	2233270	C	0.8738694190979004	And that's why you've got the five discrete kind of regimes here or target points that it kind of evolves to.
2234440	2240276	C	0.8122287392616272	And then the next note comes in and now the boundary conditions change, essentially.
2240388	2243180	C	0.8344507813453674	So your differential equation takes you in a different direction.
2244480	2255440	C	0.8275974988937378	I recall that there's something like you guys probably discussed this more than I paid attention, but there's some sort of universal solver that they are providing.
2255940	2269796	C	0.6293888688087463	So you just plug in your matrices, your state equations, your transition matrices, and then it'll solve it all for you.
2269818	2273348	C	0.8623563051223755	And that may be what this differential equation solver is about.
2273434	2275284	C	0.7939222455024719	Do you think that sounds right?
2275482	2293980	A	0.8644523024559021	Yes, I think whenever, variously in the method sections and supplemental sections of paper, they'll say in the paper, we're only specifying the generative model and the matrices and then we use standard routines to address it.
2294050	2300056	A	0.7060546278953552	Now, I don't think that has the, it's not the pinnacle of accessibility and reproducibility.
2300248	2302884	A	0.7815684676170349	However, it does at least use standard routines.
2302952	2307330	A	0.6214393377304077	But again, those are not always specified in the paper, which is an issue.
2307780	2328150	A	0.7395127415657043	So it'll be important to regenerate examples within SPM and then also to use some of these things that we were discussing with the ability to move between different languages, but like VBX variational, bayes X, I don't know what the X is actually for.
2331420	2334468	A	0.7889165282249451	It's one of the core functions.
2334644	2338200	A	0.8720115423202515	It is actually doing the variational inference in SPM.
2338620	2370820	A	0.5964505672454834	And again, SPM is like this sort of like chimera package because it arose from the immediacies of needing to do neuroimaging registration and dynamical analysis that then broached into dynamic causal modeling, random field theory based statistical testing, permutation testing all these areas that are not themselves formally linked per se, but rather useful as part of the toolkit of a Neuroimaging researcher.
2372760	2391870	A	0.5924739837646484	Then, just as we were a little bit discussing like chapter two, and of course, many times earlier in that generalized Bayesian inferential framework, hierarchical modeling, including action, is actually not the hardest thing.
2392240	2417760	A	0.6942325830459595	Yes, implementing action is one thing, but treating action selection as inference, planning as inference, it has some challenges that arise relative to just doing time series anticipation, but then those functions became compiled into SPM in a limited capacity.
2419540	2423012	A	0.6193510293960571	So again, they go through some of this.
2423066	2424950	A	0.7834623456001282	But I think it's a key issue.
2425960	2439944	A	0.73265141248703	We'll definitely look forward to what the free energy gradients are, but where the continuous nature of these curves and why?
2439982	2446590	A	0.898602306842804	There are the numbers that there are 1234-5678, 910.
2447280	2449340	A	0.7428799867630005	Now there's five notes.
2451040	2452910	A	0.7489175796508789	Ten is two times five.
2455140	2458770	A	0.8070534467697144	There's a little bit more that needs to be fleshed out there.
2462420	2480948	A	0.782758891582489	And then one question that was like, again, somewhere between testing our comprehension and being clear about what we're doing here, and in this ambiguity, we can ask it without any bias, the negative free energy gradients.
2481044	2483000	A	0.7512229681015015	I e prediction errors.
2484700	2487156	A	0.5797604322433472	What is a prediction error?
2487188	2489160	A	0.7721086740493774	A free energy calculation.
2490220	2492636	A	0.5252333283424377	Well, ignore gradient for a second.
2492818	2495224	A	0.6406107544898987	Free energy calculations are not prediction errors.
2495272	2498568	A	0.5107216835021973	Prediction errors are observations minus expectations.
2498744	2503576	A	0.7928723096847534	So this is like some finite value in the state space of what is being measured.
2503768	2511456	A	0.8238977193832397	Free energy is not that it references potentially those variables, but it does things that we know about, like KL divergences and such.
2511558	2514556	A	0.7504040598869324	Okay, so free energy is not prediction error.
2514668	2527280	A	0.5110341310501099	And that's a huge difference between, for example, a predictive processing framework and a free energy hierarchical predictive architecture.
2527440	2532360	C	0.5093239545822144	Eric but they're saying the gradient and free energy is a prediction error.
2532860	2533512	A	0.5662814974784851	Exactly.
2533646	2540832	A	0.8469682335853577	So even if it were that's, then that was the next question, which was, what's the difference between free energy and the free energy gradients?
2540996	2553150	A	0.8824801445007324	Are we talking about a landscape of derivatives, of free energy energies, or are we talking about what here?
2554660	2558508	A	0.8478735089302063	Is it being described as a gradient, as a landscape?
2558684	2569430	A	0.8388318419456482	And hence gradient ish because it can be calculated over some discrete, bi continuous state space.
2570360	2578410	A	0.5409826636314392	It's like five skyscrapers that you could have derivatives over in the Y direction, but you couldn't take the partial x.
2579740	2589064	A	0.8529931902885437	Or is it truly or is it a continuous landscape that just being tethered to the discrete values in x?
2589102	2591836	A	0.7689520716667175	But then again, that's that whole continuous, discrete question.
2592018	2599580	A	0.8323104381561279	Or are the values gradients, which has an even more complex interpretation.
2600480	2619780	A	0.5760306715965271	So we don't have the answers on these, but it's hard to understand how these figures could have epistemic or pragmatic value for learners or practitioners without some of these questions being resolved.
2623080	2630392	A	0.8405627608299255	All right, the first example, this is just kind of from walking through.
2630446	2638484	A	0.8222295641899109	So the first example was just hidden Markov model hidden states updating through time, Bayesian filter column and filter.
2638532	2642060	A	0.7936233282089233	This is like just standard signal processing in a Bayesian framework.
2643040	2644376	A	0.6897218227386475	And we're.
2644408	2665410	A	0.5980828404426575	Going to see a lot of echoes of the step by step model stream one, they give an even simpler example with static perception, one step perception and then go second to the dynamic case, then introduce action pi policy and then nuance policy through like uncertainty and so on.
2666200	2674020	A	0.9121819734573364	So that's the first inferential case they're then going to head into decision making and planning as inference.
2674360	2686250	A	0.8847723603248596	So we see policy being introduced as a variable that influences how states change through time.
2688620	2691710	A	0.8115761876106262	Does policy do that or does action do that?
2693120	2702696	A	0.8545868992805481	In the one step limit, policies are actions are affordances, but Pi is specifically reserved for sequences of actions.
2702728	2710240	A	0.8074601292610168	So is it that sequences of actions like do that or is this the actual base topology?
2711780	2746430	A	0.6981859803199768	But nonetheless, that architecture allows the evaluation of alternate policies in terms of their relative expect variational or expected free energy, depending on whether a one step policy is accomplishable with variational free energy that's, like the instantaneous move, most consistent instantaneous maneuver versus even one step in advance is going to broach into this whole expected free energy space we had on 130.
2747440	2752300	A	0.6410452723503113	So there's a really important discussion.
2753140	2757410	A	0.9323577284812927	Bozaki is also very interesting researcher neural rhythms and so on.
2760420	2773216	A	0.6999697685241699	Factorization is a really important topic and being able to distinguish like neurologically what do we mean when we talk about the what and the where stream, the dorsal and the ventral stream and critiques of it, et cetera.
2773248	2791150	A	0.49614769220352173	But just what and where in the brain and then in the factor graphs and computationally because the unfactorized models, if we're just doing the all by all by all by all, those become intractable very fast.
2791520	2802156	A	0.8440868854522705	And the specification of the sparsity of the model is one and the same in the variational base framework as the factorization of the model.
2802338	2813360	A	0.8325095176696777	So factorization is like kind of focusing your search efforts on manifolds where you've constrained certain things to be like linked or unlinked.
2814740	2830680	A	0.7966685891151428	That is what motivates the structure learning problem and the need to have to not be locked into factorization schemes at a given level of analysis.
2834300	2841580	A	0.8229134678840637	Okay, another just question to explore.
2842880	2847532	A	0.8345159888267517	Like here we have the top half of figure 43.
2847666	2849500	A	0.7366846799850464	There's just one A matrix.
2851440	2854210	A	0.7717319130897522	So why are there two A matrices here?
2855140	2861010	A	0.5898584723472595	Well, it's not an impossible question and the symbols go a long way.
2861620	2870420	A	0.9268991947174072	Here's the four locations that the animal can be in starting position, bottom position, left arm or right arm.
2871480	2885656	A	0.8638637661933899	Then here are the it's five on the X here because that bottom could, could reveal an R or reveal an L.
2885838	2892030	A	0.864276647567749	In this case it reveals an R and the food is honestly there.
2892560	2903708	A	0.7930861115455627	And then this is a second a matrix that is describing how location is associated with the food.
2903874	2906320	A	0.6848213076591492	None aversive or positive.
2907220	2909292	A	0.8875057697296143	But this ties into the earlier discussion.
2909356	2914610	A	0.8493207097053528	Like it might be all one thing to say well it's four x five and then four by three.
2915560	2919590	A	0.8599790334701538	But is this actually a four x five by three.
2923240	2924710	A	0.47428008913993835	I know it's not.
2925480	2926950	A	0.8444840312004089	Eric, what do you think?
2927400	2930730	C	0.8687012195587158	Yeah, and they'd mentioned in there it's a tensor also.
2932220	2943628	C	0.8580093383789062	And the tensor means that you're stacking this one, this image against the version where the reward is on the left side.
2943794	2949484	C	0.9257516860961914	So the tensor is going to be four x eight by two.
2949682	2952056	C	0.7567644119262695	So that makes sense for being the tensor.
2952088	2954384	C	0.7369093894958496	So the state is another layer on top of this.
2954422	2957090	C	0.5227761268615723	The hidden state is another layer on top of that.
2958180	2968260	A	0.759562075138092	Yes, section 73.
2968330	2973892	A	0.940300703048706	So this would be a fun kind of like PH d.
2973946	2975190	A	0.7059897184371948	Qualifying level.
2975720	2983450	A	0.8555721044540405	Question just describe the whole team ace every row, every column and every value.
2983980	2985450	A	0.6104702949523926	Why is it that way?
2989130	3010426	A	0.8265123963356018	So we're not going to type it out here, but to understand that example and what the B matrices are, and just to have agility and just identifying the differences between these matrices numerically, like pattern recognition, like, oh, here there's two ones, here two zeros.
3010458	3013182	A	0.7693143486976624	Here two zeros, here two ones, here one and zero.
3013236	3014480	A	0.6443249583244324	These stay the same.
3014850	3029460	A	0.8272691965103149	And then to be able to transpose that in your understanding to what this means in terms of transition frequencies, every place where there's a difference, it's a difference that makes a difference.
3029990	3035480	A	0.8257198929786682	So being able to understand what those are is about understanding this example.
3035930	3064320	A	0.6970610022544861	And one can imagine, especially if they're wanting to make an application of active inference that's more complex than this, four x four, being fluent with how these matrices are constructed, their dimensionality, how differences in the generative process are incorporated, how differences in the generative model are incorporated, all these different features are important.
3068230	3070900	A	0.9417591094970703	Yes, Eric, this is definitely very important.
3071670	3073326	A	0.604174017906189	Question agreed.
3073358	3082680	A	0.7453261017799377	Like it, it looks extremely neural, and these traces come up all the time.
3085450	3097370	A	0.8722420930862427	Similarly, here we have three discrete time points starting going to the Q, getting the L, and then going to the left arm.
3098750	3099834	A	0.648163914680481	But then what is this?
3099872	3106540	A	0.7301508188247681	Step one and a half is the one, all of these points.
3107470	3111226	A	0.7840568423271179	And then by two, the uncertainty is resolved.
3111258	3115054	A	0.6412572264671326	The belief about certain things goes to zero, the belief about other things goes to one.
3115252	3117418	A	0.7480815649032593	And this is just a pure interpolation.
3117514	3129700	A	0.5404712557792664	But that is quite a specific interpolation, including what appear to be some like dopaminergic spikes or something that are not reflected at either of the time points.
3130310	3132822	C	0.8477938175201416	My guess is that you've got three different blocks there.
3132876	3146540	C	0.8838109970092773	So if you take the one as being the width, one third of the way across the two is another third and the three is another third, then that switch there that you see happens as soon as you transition from the one to the two.
3149860	3156640	A	0.7668477296829224	Yes, although still there's even the graphical interpolation interpolation.
3157560	3166870	A	0.6474764347076416	Question and it's so easy to be like reading is it just a quirk of the dashed line?
3167960	3170916	A	0.7865973711013794	But are there two dashed lines?
3171028	3175640	A	0.6424981951713562	And two dashed lines diverged in a neural trace?
3177340	3179560	A	0.7130733132362366	But it's kind of clear.
3179630	3182120	A	0.603013277053833	These ones, the discrete formulations are clearer.
3183340	3184090	B	0.5491447448730469	Yeah.
3184720	3185470	A	0.584351658821106	Okay.
3185840	3188040	A	0.8588808178901672	Are rats prone to useless behavior?
3188200	3189310	A	0.8090039491653442	What do you think?
3189840	3191420	A	0.9600058794021606	What useless behavior?
3194640	3195932	C	0.6940004825592041	I wrote it out.
3196066	3202224	C	0.862672746181488	Okay, this is good time for today, but that's my most provocative comment on this one.
3202262	3204050	C	0.5637059211730957	And maybe we can save that for next week.
3204420	3205280	A	0.8497673273086548	Okay, perfect.
3205350	3209430	A	0.8484976887702942	Let's pick up with this one and any other questions.
3209960	3214144	A	0.8787252902984619	Then we'll glance over the visual cicade.
3214272	3215990	A	0.8432767987251282	Look at the learning example.
3216840	3219140	A	0.7849400043487549	Consider the hierarchical example.
3219290	3220384	A	0.5695875883102417	There's the maze.
3220512	3222310	A	0.6319077014923096	Then there's the hierarchical example.
3222760	3225072	A	0.5966265201568604	Another nested.
3225136	3228580	A	0.7643862366676331	Discrete meets neural continuous trace.
3229960	3232040	A	0.8802003860473633	And then we end on Stefan's squared.
3232120	3234524	A	0.9631696939468384	So thank you all.
3234722	3236270	A	0.9810779690742493	Have an excellent day.
