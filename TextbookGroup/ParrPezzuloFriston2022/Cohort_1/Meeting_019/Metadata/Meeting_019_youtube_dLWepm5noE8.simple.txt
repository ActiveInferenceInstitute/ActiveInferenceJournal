SPEAKER_00:
Hello, everyone.

It's October 7th, 2022.

We are in Meeting 19 for Cohort 1, and we're discussing Chapter 8.

So, there's a bunch of questions and also a lot of things to talk about.

Let us just begin with looking at Chapter 8.

So, does anybody want to...

Give any first thoughts on active inference in continuous time, everything flows, nothing stands still, et cetera.

Yes.


SPEAKER_03:
Not on that specifically.

Okay.

But I will have something to say for this chapter.

I worked on this topic.


SPEAKER_00:
during my my graduate time so once you get to about 8.3 i'll weigh in excellent um any comments like discrete continuous time i know this is something we'll touch on again and again

it's kind of like another low road high road duality with continuous and discrete time and i think the textbook tries to give equal time and highlight the hybridization of these models in a way where realistically in literature most are pure discrete models and continuous time models

have been almost like domain bound certain areas like motor reflexes where there's more of a tradition of continuous models are heavily represented in them whereas decision-making models

tend to use the discrete formalisms and that difference between the sort of like continuous time traditionally motor associated and discrete categorical traditionally decision oriented

models was addressed in the um folk psychology paper and live stream with ryan smith at all okay um also i uh just started kind of an overview got up through a3 of just understanding and just trying to lay out chapter eight so for any chapter everyone's always welcome to just

make summaries and and add their own notes so we can um look at the questions many of which are on the earlier part of the chapter and so maybe we can look at the um earlier part of the chapter more this week and of course then have later time uh okay so 8.1

It's a single paragraph.

It's a complement to Chapter 7, which was a discrete time approach towards generative model construction.

The focus here is on continuous state-space models, which are well-suited for physical fluctuations, sensor receptors, and continuous motion of effectors.

They start with the case of movement control, 8.2.

So, let's get familiar with the notation.

The states, hidden states, are going to be x. The data, the observables, are going to be y. And then, how states evolve over time depends on a static variable v.

So that could be a hidden or slower changing cause or factor in the environment.

Then we have the omega terms associated with each of the data and the hidden states changed through time.

And that variability is like the noise and this is like the signal or the flow.

So it's kind of the Langvin decomposition or Langvin approach towards dynamical systems modeling.

one interesting thing to note is first that this is hugely four-staged in SPM then also that the data are a function of the states at that time whereas the equation for the hidden states is a change in hidden states x dot

Note that action is absent from equation 8.1.

This is because action is part of the generative process, not the generative model.

Thought that was kind of an interesting question.

What does that mean that action is part of the generative process and not the generative model?

Surely action selection is part of the generative model.

the cognitive process of policy inference.

Active states are part of the particular states.

Active states are blanket states.

Particular states are the generative model.

The generative process is referring to the external states, the hidden states

So is action part of both the generative process and the generative model?

Because it kind of sits in between and intermediates?

Or is this referring to the consequences?

The generative model only deals with those variables directly influenced by states external to a Markov blanket.

So is that saying that the generative model is kind of like the complement

of the autonomous states action internal states or is this even more extreme it's only dealing with the variables directly influenced by states external to a markup blanket so then it must only deal with sense states which is like a narrow perceptual control reading and in that such in that sense action execution

is outside of the generative model because the generative model is only dealing with observations does anyone have thoughts on how generative model action and generative process are being used eric i wonder if you can consider your own actions part of what gets observed under that framework

as far as i would uh the apologetics for the narrow view would be exactly that which is like you have um uh proprioceptors in your elbow so you don't observe action but you are getting continuous updating of perceptions that are extremely influenced by action but the hidden state of the world is actually like the angle of your elbow

And so you're not directly observing the hidden state of the world, nor how it changes.

All you have is the proprioceptors.

And of course, you engage in policies to change your proprioceptors, bring them towards alignment, which is what we're going to be discussing in the chapter.

Ali, I saw your hand raise.


SPEAKER_02:
Yeah, I wanted to mention exactly the proprioception, which you mentioned, so I lowered my hand.


SPEAKER_00:
Okay.

Yeah, great.


SPEAKER_03:
But then could you include the fact that you've got signals going to your muscles, your motor neurons firing in there, making your muscles contract?

Can that be part of your observation to say, well, okay, if this is happening, that these muscles are getting activated, then

Sure enough, the arm moves and the proprioception changes.

So you can say, well, from the outside of that box, that's all part of the generative model of seeing, but not part of generating those muscle commands, but just seeing what the effect of them is.

I wonder if that would be an acceptable viewpoint.


SPEAKER_00:
Cool.

We'll return to this, like, where is action?

What is action?

But I think it's just important to note while we're early here.

Okay.

So continuing a little bit on.

This part I thought was also a little curious.

Okay.

So this is equation 8.1.

We mentioned equation 8.2.

So first question, italics versus bold, G and F.

Do you think that that matters?

I don't think it matters.

Does anyone disagree?

Do you think it's moving from one space to another space, or do you think that's just a typographical error?

I think it can be considered as an errata.


SPEAKER_03:
One thing I did notice is that 8.3 and 8.4, the italics they call a generative model, and 8.4 they call a generative process without the italics.

Could that be the distinction?


SPEAKER_00:
Okay, 8.3 and 4?

Yeah.

Ah, okay.

It's a very good question.

Well, let's just say italics in 8.1 and 3.

bold in 8.2 and 8.4 um unclear if relevant difference okay um yvonne's your

question i mean if the meta model you say frames it so if you consider the niche to be a meta model then sure the difference between equation one and two other than the bolding or not is that v

the static variables have been replaced with U actions.

So this takes us from like the sort of SPM where you'd be like, you have neuroimaging data Y as a function of underlying neural states X. And then neural states changing through time are a function of neural states at that time and some conditional factor.

you're testing for like whether they were exposed to treatment one or treatment two v so this is still a um partially observable dynamical model but then it gets moved very neatly into the control theoretic and the policy selectionist inference space by just saying yeah those slowly changing factors that influence how the hidden states change

we control those or we have some ability to influence there okay yeah so this could be a cue towards the bold difference which is like the functions g and f

are not necessarily the same as those used to define the generative process.

If they said not necessarily the same as those used to define the generative process, bold G and F, then it would be unambiguous, but it's a little ambiguous.

We do not need to explicitly write down the dynamics of action in the generative model.

Okay.

they emerge from the choices made for terms in equation 8.1.

We start with a simple sort of generative model.

So g, which is the function that's generating the data, is going to be x. f, the function of how x changes through time,

is a function of x and v, the slower changing causes, and it's the difference between those two.

The hidden state represents the expected value for the data.

Or another way to say that would be, equation three says that the expected value for the data are the hidden state, but those are the same.

And it's a point attractor.

Or in the Bayesian mechanics, we could say it's mode matching.

By attractor, yeah.

Yes, the attractor here is the mode tracking that is being referred to here.

When there's a difference between the hidden state and the hidden cos V, then it moves towards it.

So it's just moving towards a single fixed point attractor.

now the generative process is defined so it looks almost identical except these are replaced with use and this differential tracker this kind of pid control motif is replaced with action it's an expression of the equilibrium point hypothesis

which treats motor control as enacted by reflex arcs that draw limbs towards equilibrium points set by descending motor signals.

And then also this is related to the skilled performance.

Livestream 23.

The scheme does not require specification of inverse models that are widely used in other formulations of motor control.

8.5 makes a slightly more sophisticated model that's based around not just position because of course you can't just like pick up your finger and move it to a different position really the action affordances are in the space of changes in velocity which is to say acceleration

this is kind of a classical mechanical perspective on motor control and it also points towards generalized coordinates of motion and that kind of pid control and the basing mechanics and so on okay now we get to 8.3

Continuous time formulations are well suited to characterization of movements.

Well, certain kinds of movements on a chessboard, maybe not, but some kinds of movements, sure.

Eric?


SPEAKER_03:
Yeah, I'd like to point out with equation...

8.5, just above that, where we've got this spring mass.

So that system oscillates forever, right?

It's got a spring and a mass, and there's no dissipation of energy.

so it's it's a step up i guess better than um you know more advanced than um equation 8.3 in which you have instantaneous acceleration so they recognize okay you can't have instantaneous acceleration but there's no there's no uh damper here so normally the the the true equilibrium point control formulation is is viewed as a spring mass damper system and

That way, if you remember from physics class, you know, depending upon your set, your mass, the spring tension, and the amount of damping, you can get over damping or under damping, and then you can get kind of an optimal settling to the, or approach of the set point with maybe just a little bit of overshoot or no overshoot.

But if you don't have a damper in there, then it just never settles in at the equilibrium point.

But so just to carry this a bit further, I would have to disagree with this statement that continuous time formulations are well suited to characterization of movements because that's assuming that the equilibrium point control model is a good characterization of movement.

I worked on this in grad school for about two years.

When I first got to grad school, we worked on the equilibrium point control

I worked in the Beatsy Lab at MIT.

And we had an apparatus that mimicked an apparatus that was used in monkeys.

We had one that we used on ourselves as human subjects, which would allow you to move your arm.

And then it would kind of give you a little jolt, a little disruption to measure the amount of stiffness in your movement as you're moving your arm.

as a way of trying to deconstruct or work back the parameters of the equilibrium point control model for movement.

And it's attractive because, as they say in the chapter, well, you don't have to have any very sophisticated knowledge of motor planning or inverse model of your plant, the system,

In order to, all you do is you say, well, this is where I want the arm to go.

And passively, it takes care of itself, perhaps through a feedback loop in the, you know, through the spinal cord, which I guess is what 8.1 has.

It's interesting that there's a paper from 2009 of Levin and Feldman that is, you know, reviewing this.

But our conclusion was pretty much that equilibrium point control

for motor control, it really is not a good model.

It doesn't work.

In order to make it work, you have to play all kinds of shenanigans like, well, you not just have a fixed set point.

You might overshoot, and then you bring your set point back, and you actually have to control the stiffness during movement in order to account for observed data.

But still it falls short because many, if not most human movements or any motor movements are ballistic.

So it's not that you set some conditions and then your spinal cord and muscles act to fulfill those conditions that you set once from the top of your brain.

What really happens is,

your descending signals anticipate a whole trajectory or a whole plan in advance of how we're going to accelerate and then we're going to have to decelerate.

And so the motor planning kind of knows what your plant is going to do.

It doesn't wait for the plant to do something and then have to respond to that in kind of a passive way at the lower levels.

It's just like if you play the piano, you're not waiting for your finger to say, am I far enough down on the key?

You learn how hard you have to press it and when you start to release before anything happens, our movements are very fast.

And so there's really no getting around having to model the plant and doing this sort of inverse modeling that they're concerned about in order to account for how any creature really moves or anything above an insect.

And probably an insect, too, is undoubtedly a motor plant.

So I really find that this chapter is really not

I don't think it advances the cause of active inference.

It doesn't really, to me, it doesn't really fit with how water control really has to work and doesn't add anything to the theory of it.

I mean, it's using old theory that doesn't work.


SPEAKER_00:
Thanks for all those points.

my statement that's it that's the tweet um well one uh live stream that other than 49 which has just been like amazing from the physics angle we're preparing also for 50 which is using it's also by um felton barrett and others

And it's specifically on interoceptive reflexes.

So less exploring like the spinal reflex arc and more on the vasopressive interoception, but using those kinds of still classical very differential equation based equilibria control

And showing that those types of formalisms can recapitulate like allostatic behavior, it's always difficult to know.

Like, is that a very narrow and fragile range of parameter space?

Is this a descriptive model that's making unique predictions?

Let's look at figure eight one.

because it's speaking to um the generative model generative process distinction that was mentioned earlier and it was addressed in a question how is this representation of the reflex arc similar or different to what was being used in figure five or in chapter five so in chapter five

Here was the summary statistic or summary graphical abstract.

There was a lot more focus on this kind of like policy selection and so on.

But we did have this kind of a reflex arc.

Y, E, and so on.

Okay.

So now we're in 8.2.

f is the action selection component so here is that simple attractor being shown where it just x is going to be converging to v and this is the change in external states

So here we have mu of x in an equation.

In the lower one, is this one referring to this or is that kind of bleeding out from the bottom panel?

Because here's u of x and here's mu of x. Here it looks like mu of x is a prediction modulator

on a differential so it's like if the observation is where you want to be then there shouldn't be any action but as the observation diverges from where you want to be you have a precision modulated action

is that active inference or is that just a notation um a different notational representation of classical equilibrium point motor control theory do those models integrate

sensory and action together i mean in one sense they definitely do nobody was ever generating reflex arc models without some sensory feedback variable

So that's an open, important question.

How is this, is this didactic with respect to active inference now just kind of saying, yeah, one special case of active inference is the traditionally understood and limited equilibrium point model of motor control.

Or is it like, this is our new way of doing motor point control.

okay just kind of continuing on all right precision attention and sensory attenuation so here's another um

Curious note, so earlier we discussed whether motor control was or wasn't a natural setting for continuous models.

In the box, 8.1, they write, we address the importance of precision in chapter 7, but it's worth recapping its role in continuous time systems.

In many ways, this concept of precision is more naturally addressed in this setting.

as the pi variable appears a direct consequence of Laplace approximation okay but can't you do a Laplace approximation in discrete systems as well Laplace approximation is just mode determination followed by the parameterization of a parabola to create like a Gaussian or at least a concave

optimizable and two parameter approximation to an arbitrary distribution i don't exactly see or is it referring to the laplace approximation is itself a continuous function but you could apply laplace approximation to a categorical distribution as well

so in what ways is precision more naturally addressed in a continuous model is it that precision is a continuous variable like precision isn't an integer valued variable so we can just leave that one

okay but so we went into eight three dynamical systems kind of looked at the spinal cord again but it may or may not just be a sort of like trivialized or didactic representation of extremely traditional representations of motor control then box one precision attenuation attention sensory attenuation all right now we get into the latke Volterra Dynamics

So what are some formal and qualitative implications of the use of Lotka-Volterra dynamics and Lorenz systems?

So I think there's a few interesting angles that us here now, but others just more broadly may be interested in.

So one is Locke-Volterra ties in, of course, with ecology and population ecologies.

And so that is also very interesting to consider in terms of like winnerless competitions and neural dynamics.

And that is basically the analogy, which is like, just like even if you have a negative edge between the predator and the prey,

for any persistent which is to say oscillatory or manifold attracting population at some point like you have to let the prey regrow so the analogy in neuroscience that's fleshed out in spm is like if you have a brain region even with a unilaterally negative um influence on another region at some point it has to like let off the break cyclically

So Locke of Volterra summarizes these kinds of like winnerless dynamics that can give oscillation and time structure, including with like complex dynamics and recurrent dynamics, limit attractors, all these like kinds of dynamical processes can arise from a pretty simple starting point.

And here we see manifolds and like limits on the projection because it's a three-dimensional space plant herbivore carnivore, or that could be the blood oxygenation of three brain regions in SPM.

And this is their neural trace or their inferred activities.

And so then you can find like manifolds of lower dimensional activity.

And then also one kind of related note is the Volterra series.

And this is a pretty nice just technical note.

which is Taylor series does expansion of arbitrary functions from a starting point.

And the Volterra series is able to include like a window of inputs, also known as the memory effect.

And so it's discussed in SPM.

It has a continuous time and a discrete time variant.

And it is just a kind of kernel estimator that can be used for dynamical processes, input, output, dynamical processes with memory.

So it's kind of a classic in that area.

And I think even in some live stream, maybe 45, I asked Friston about the Locke-Volterra models and about why...

like where do we move away from them or something like that but that would be a good answer to kind of come back to

All right, so now those kinds of Lockeville-Terra dynamics are going to be applied monochromatically as ever to active inference.

And that was one question, which is, it didn't finish writing.

How is the Lockeville-Terra model being used in the case of handwriting?

so it i think it's in the friston and herrero's paper which i just brought in but i didn't really investigate deeply um the left there's two different applications here left eye blink conditioning

so here it looks like a condition stimulus unconditioned stimulus where there's like where something happens and you blink as we've mentioned previously like it's a little bit difficult to tell exactly what these expectations are of or anything like that but this is like

some kind of stimulus response blink blink once if no twice if yes once if by land twice if i see and on the right side sequential peaks using an attracting point

but selecting the specific attractor on the basis of which population a Lockeville Terra system is currently highest.

This leads to sequential visiting of each points, giving rise to a type of handwriting.

So this is kind of interesting.

And I know for Jakob and Ali also with our mode tracking, path matching discussion, Bayesian physics,

um so it's like um i um i must it's bart simpson at the chalkboard this is i must rewrite the sentence i must rewrite the sentence i must so your expectations are that you're going to be writing this sentence and then depending on which of those expectations are on top that is going to set

the motor imperative so it'd be like if you were writing the letter um d and it'd be like well it's like first there's like an arc down into the right and then there's an arc down to the left and then it's a straight line up and then it's an arc down to the right and then it's an arc down to the left and then it's a straight line up and so here's kind of like doing this writing as it's picking a mode pursuing the mode

i think it's fair to say uh jacob early please add any more if you feel like it but like this is like shaking off the slumber of the classical physics and still having one foot in both worlds and the three faces of bayesian mechanics are a much more advanced way to discuss this issue

Yeah, Jakob, what do you think?


SPEAKER_01:
I was just going to say that this, well, not the case with writing specifically, but the case of motor control was discussed in Thomas Parr's lecture at the CPC 2022, which I don't know if it was recorded.

Actually, I think it was.

But I don't know if it's public yet.

But it's interesting that this example is in the continuous time chapter because you could think of it as a nested generative model with both discrete and continuous factors.

If you partition it into three decisions,

first straight line up then an arc down then a second arc down.

Those are three discrete decisions that are at the top of the of the hierarchical generative model with the finer grain motor control below.


SPEAKER_00:
Thanks.

Also, just here's that classic three faces figure.

mode tracking this can be seen as using a log of volterra pseudo random number generator to spit out higher level predictions about which mode should be pursued then as to the dynamics of how that mode is approached one can either use the equilibrium point methods discussed in this chapter or

the more advanced Bayesian physics methods to describe that in terms of gauge theory and so on.

Is that fair to say?

Oh.

Is this it, Jakob?

Thank you, Ali, for sending it.


SPEAKER_01:
It's not the same one, but it looks like a lot of the slides are

the same.

I think the thing that I was referring to, I'm just trying to find the slide.

Oh yeah, I think it might be minute 41.

Okay.


SPEAKER_00:
i really can't wait till there's some open source webcam software to do eye saccade analysis and um pupil diameter i don't think it would be that intractable maybe you'd have to be kind of close or you'd have to use a 4k camera or something but is there any software like that available i've never come across it just like

Move the mouse to where I'm looking and then click when I blink twice.

Isn't that kind of like... That exists.

That does exist, but what is it called or where is it being used?


SPEAKER_01:
I know it's being used for people with physical impairments who can't control the computer.

Oh.

Yeah.

Otherwise.

Yes.

I haven't seen an analysis of pupil dilation, but eye tracking is definitely a thing.


SPEAKER_00:
Okay.

Maybe we can explore it.

All right.

So yeah, the blinking example was a puff of air.

So it was just like a beep and then a puff of air.

And so then they learned to preempt the air puff.

Okay.

Learning in continuous models, 8.2.

Continuous time domain accumulating evidence.

This works if we treat data in a series of small time intervals.

Oh no, don't discretize.

This relates, I think, to some of the

finer points on like which stochastic calculus is used like the ito calculus in the bayesian mechanics um we won't go into it unless anybody really wants to say more but this looks like important just to learn about the integrals and the gradients okay pomdp has largely superseded the use of the generalized lockable terrace systems in active inference applications

i was kind of i think related to asking first about why things moved away from the lockable terror formulations lorenz system also explored in stochastic chaos markov blankets live stream 32. it's it's almost it's dealt with as minimally as you could possibly deal with the lorenz system

in 8.7.

Okay.

8.4, generalized synchrony.

So multi-agent inference starts coming into play as well as agent environment synchronization.

And we actually like talked a little bit about the bird song in the previous hour.

Now the Lorenz system comes back and yes, it's dealt with like sort of in the 2015 Frith and Friston paper, active inference communication and hermeneutics.

and that's where the synchronization manifold is kind of displayed and then more recently in um live stream 32 is um and this one has a dot three i think this might be the only dot three as of this point i think connor heinz could only come at a later date yeah so these are good discussions

on the Lorenz attractor coupled Lorenz systems.

This is kind of very similar, if not identical, to the birdsong synchronization manifold in Frist and Frith 2015.

Birds, birds, birds.

Bird synchronization isn't real.

Then hybrid discrete models.

um hybrid mixed models not that kind of like mixed model allow inferences about sequential action plans and translations of those decisions into movements through a continuous model so in that respect it's extremely linked to live stream 46 active inference models do not contradict folk psychology which is all about that continuous time motor active inference

discrete state space decision active inference MAI and DAI and using those motor and decision active inference models while lower level model in the dashed box is the same form as the other models in other words it's continuous

because we have V instead of pi for the causal factors, and F instead of B, and G instead of A. And eta instead of G. Is it?

some mapping between well in this case i think just looking at it a little more narrowly how um outcomes map to slower causes of the world so here this is a discrete model up top with the g oh yeah that was one erotic that we found free floating g can't live with it can't live without it but it should be connected to the pie of course um

There's a discrete time model on top, and then it is kind of cascading its outcomes down to these continuous time models.

So one could think about this, like the Lotka-Volterra handwriting example, kind of could, it's not the exact structure of this, but it's related.

Okay.

This is something I know Jakob has thought about, how discrete and continuous models interface.

Because we've talked about how the temperature could be continuous and the thermometer could be continuous, but then the internal generative model could be like, is it hot or not?

So the question of how to...

move from generative models within and between different parts of the model where where are what kinds of transitions between continuous and discrete state spaces possible okay here's a continuous um isocate

uh ocular motor paradigm where the continuous lines are still confusing but at least they are justified eight three combining categorical and continuous generative models outside of active inference has primarily been framed through the lens of clustering the aim is to assign data points into a discrete cluster

I wasn't exactly sure about that.

I think clustering and thresholding is one discretization approach that's been used.

Also, just binning seems like a simpler method.

How do you take a continuous distribution of 1 through 10 and make it categorical?

just bin it one through ten or you could cluster and do thresholds so then you could have um cluster one with nine point seven to nine point nine and then nine point seven to nine point five um and then eight six there's a big table here's the songbirds this author isomura i believe is the one who will join

for 51 in November and I think that'll be like our last probably one of our last paper streams for the year we have some we have just this last discussion with Dalton next week and then interception and then the canonical neural networks perform active inference papers

isomers worked with par and frist and others oculomotor reflex eye pursuit psychosis illusion saccade action observation attention hybrid and self-organization models well with four minutes left kind of an interesting chapter

but I can only know it how I'm seeing it, and I have serious questions about what it does in the book.

Eric?


SPEAKER_03:
One thing I was puzzled by, and maybe you guys can help me out with on the bird song example, is were they implying that birds start singing, another bird picks it up, synchronizes using these dynamics,

and um the proof of that is this other bird will just step in and take over and the first bird can stop i don't believe i've ever ever heard that happening is are they suggesting that that happens or or what um okay i i agree like whether it's a uh improv whether this is a bird improv conversation in this case they're singing from the same hymn sheet


SPEAKER_00:
So it's like, somebody should be singing the bird anthem and now we're going to be engaging in this sort of quasi-dialogue where we're going to be reducing our surprise about hearing the song that we expect to hear, which goes like, you know, insert your favorite song there.

And then the phenomena that gets highlighted is the way in which

one bird is singing and then as it's singing its precision starts to drift and then it stops singing and then the other bird finds itself picking up at the same point to reduce its surprise about that song being sung at the time but

I think especially with a bold title like laying claim to hermeneutics more broadly singing from the same pre-coordinated hymn sheet is not the same thing as information updating or even just pure expressivity so I think it

it leaves gaping areas for people to actually develop because it's like well we have what don't we have databases of like millions of bird songs and natural soundscapes so like we need some bird watching active inference practitioners who want to actually develop

bird song motif because otherwise it is too easy and ironically becomes singing from the same hymn sheet oh well hermeneutics has been addressed in 2015 synchronization manifold 2015 um whereas this is like a very fringe case of communication that is based upon um

most charitably, high reliability execution of preordained performance, which is a tiny edge case of communication.


SPEAKER_03:
You know, my understanding of bird songs is, you know, the baby birds hear what their parents sing.

You know, they've got some predisposition to sing a certain kind of song.

And for most birds, you know, there are some that are

very adaptable, you know, parents, you know, stuff like that.

But most birds learn the accent or the dialect that they are raised in, and that's the song that they always sing.

And there's some variation on it.

I mean, maybe they'll stop midway through.

But what are the true facts about what I saw to be a claim here where birds will pick up

from each other where one leaves off.

Does that really happen?

I'm not familiar with that happening.

I don't think it's ever already happening.

My impression of the way most birds sing is they'll sing their song all the way through, and there might be a call and response.

Another one might pick up, might answer.

But I don't think I ever hear synchronizing of songs.

But I might be just not well enough informed about the ecology of those things.


SPEAKER_00:
yeah very interesting um questions and the whole area with um game theory of song like it's beneficial that somebody warns about the predator but then you've revealed your location when you sing and things like that like that's the kind of decision making

and uncertainty resolution and risk evaluation that i'd imagine an agent-based birdsong model would orient towards but those are some cool ways for us to go so um next week

I guess this is kind of a shorter chapter and it has some arcane symbolism but also seemingly very skippable symbolism so I'm glad that we could get through the whole thing and we'll return to any further thoughts on 8 and then maybe we can have more of a 7 plus 8 synthesis

Or anyone can look into any of these citations, key advances, as we head into chapter 9 on empirical data, which is not super long, followed by 10, which is just a restatement.

So onwards we go.

Thanks, y'all.

Bye.

Thanks, everyone.