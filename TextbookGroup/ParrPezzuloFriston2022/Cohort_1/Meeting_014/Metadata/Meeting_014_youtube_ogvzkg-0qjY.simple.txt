SPEAKER_00:
Okay, we began.

Welcome, everyone.

It is the resumption of our cohort.

Update the video description.

It's the resumption of cohort one of the Active Inference textbook group.

It's our 14th.

Okay, could someone mute GSP or feel free to say whatever you want to say.


SPEAKER_07:
Can you hear me?


SPEAKER_00:
Yes.


SPEAKER_07:
Yes, okay.

So sorry, but I'm completely new to this interface of Gather and Coda.

So I'm not sure I understand cohort one and cohort two here.

So because cohort one, wasn't it the previous one, like the one that started last year?


SPEAKER_00:
Yes.

Well, from May till July, we did chapters one through five.

Now we are in this cohort.

So if those who did not participate in this part, like respectfully, you know, thanks for the question.

But everyone in general, respectfully, let's try to have people who are in the cohort participate in it.

Everyone's welcome to join.

And of course, rewatch.

But contributions in the questions and the chat are probably best so that we can respect the people who are continuing on.


SPEAKER_07:
sure this is our 14th meeting and now we're heading into the second five chapters of the book okay does any other person want to give context oh yeah go ahead hold on so the the the current one that is going on right now is the cohort one and not cohort two


SPEAKER_00:
we're all learning in different stages so the previous hour was the cohort that is focusing on chapters one through five okay stage they're in and now some of us a different set of people some are joining both so that's why we made the meetings convenient was so that we could like for many of us who want to do both we can join or there's but this is a separate set of people


SPEAKER_07:
I see, I see.

So, okay, so cohort two was first, and then, I mean, in this meeting right now, cohort two was first, and now it's cohort one, which started before.


SPEAKER_00:
We warmed up with chapters one through five.


SPEAKER_07:
Okay.

So I will leave because I subscribe for cohort two.

Excellent.

Okay.

Good.

Thank you so much.

See you next time.

Thanks for setting up all this thing.

Okay.


SPEAKER_00:
Bye-bye.

Yes.

Awesome.

Okay.

Anyone else want to add anything?

We don't need to do a Coda overview.

i would say people who are watching this recording can look at the live recording if they want a coda update that we just went through for the cohort twos live meetings but does anyone want to give any um introductory thoughts otherwise there's a few ways i think we can go for this session but we're here just to rejoin our activities and orient towards chapters six through ten

We can scan through the chapters.

We can have any suggestions or discussions around ways to approach them.

I don't know.

Rohan, and then anyone else.


SPEAKER_03:
I was wondering, when are we going to get to the projects part or discussions about the projects?


SPEAKER_00:
Great question.

Let's look at the chapters and see where that... First off, it can happen however you want with contacting people.

We can make a subpage like I see exists here.

This looks really awesome.

So people can request a subpage, they can mention it, contact them now or however.

So it's up to you for a project that is under your control.

It can be developed in the open here or however.

You can also participate in many ongoing projects like Active Blockfronts, which might all share this

our Gitcoin grant was approved yesterday.

So if people aren't familiar with this or want to become familiar, this is a way to like provide or receive support possibly for their learning in block friends and contributing to that open source package.

Does that address what you were thinking?

Were you thinking about these project ideas or were you thinking more about like the sort of build your own model approach that will be starting in chapter six?


SPEAKER_03:
No, about the project ideas and the code up page.

That answers my question.

Awesome.


SPEAKER_00:
Yeah, like these are, well, they're different types of projects.

Clearly more will be added, but they're of different, they're not necessarily, they might involve building a generative model, but they are not the generative model itself or only.

Let's look at chapter six.

because this is where the generative model construction is going to come into play.

And so again, there's a lot of projects that you would only need to qualitatively think about generative models for like educational material production is related to the generative model, or it could be modeled as the generative model of a learner, but you wouldn't necessarily have to make a generative model.

But in chapter six, um,

It's a recipe for designing active inference models.

It is going to... Brock?


SPEAKER_04:
Sorry, just real quick.

I think Lucas here doesn't have access.


SPEAKER_00:
He asked for access.

Okay.

Message in gather your email address and I'll add you.

Okay.

Sorry, I didn't

Okay, you requested access.

All right, I'll allow you.

That's enough then.

In chapter six, it's going to ask some questions that are driving the design of the generative model.

Which system are we modeling?

System of interest.

What is the appropriate form for the generative model?

reflecting the discrete or continuous distinction that we looked at.

And also all these other questions that aren't exactly within the textbook, like temporal depth, hierarchical nesting, which parameters are learned versus fixed, all these different directions that the models actually have to be elaborated on, even before getting to the data engineering and maybe even code implementation.

Just from a structural perspective, what form is it?

How to set up the generative model is where some of those analytical details begin being introduced.

Not necessarily even the program level implementation or an executable simulation, but like, okay, we have a preference vector that's, is there two states?

Is there some continuous preference distribution?

Whatever it is, what is the actual details of the generative model

And then the other side of the coin slash blanket is the generative process.

So what are the endogenous dynamics and the causal mapping with action for the generative process?

And there's kind of cases where you have more of a communication setting, active inference entities on both sides.

You could also have more of like a simple, simple partnering.

like two deterministic programs that send messages to each other, or it could be like one more cognitive, more agent-like generative model and one more environmental non-living type.

Any thoughts or overviews or how would people think about how can we make this type of a recipe design?

Should we be all designing a model?

Or how do we even go about reading a section of the book in a chapter that begins with a recipe provision?

Lyle?


SPEAKER_06:
Yeah, so I spent a lot of time building what I think would be classed here as generative models.

And

What I find is that this, what I characterize it as the step of framing it up, framing of it, is often far trickier, sometimes much harder, frankly, than building a model, depending on what the situation is.

And in my experience, I find that it all comes down to making sure we understand what is the question that we're trying to answer, right?

It's sort of like, because every modeling process, I'm sure everybody on this call knows, is a process of deciding what to leave out, right?

What to put in, what to leave out, and what level of representation.

Then it all has, everything that's in there, if it's going to be a good model, has to be necessary and necessary to answer a question or provide a particular insight

so forth so that whole issue of framing out uh what you're going to build you know and in all those different the 10 000 questions you know there's more than four you know ultimately it's many then it's all about that which often means understanding the audience if if the model builder is the only audience this is a much simpler if the audience is um

uh you know some much larger group with different perspectives a lack of of homogeneity and insight then there almost has to be uh i'm gonna say almost a pre-modeling or framing process of of sort of of framing up what are the questions we care about and then we can talk about how how those translate into a model so

That's just some general framing.


SPEAKER_00:
Thank you.

That's very interesting.

It makes me think about this audience question for the model.

Why are we building the model?

Why are we shaping our regime of attention to build this model?

Model building can be an end of itself.

It can be creative and expressive and fun and all these other things.

And maybe later there's a road that has some pragmatic value too, but also it can just be like fun.

Like, what would a generative model that could do this look like?

And that can be very didactic.

There's other times where you're presenting information.

Oh, I made a simulation of Twitter discourse and dot, dot, dot.

always going to be presented in a way that's not only just like the model distilling down from the world but then you're communicating it and then when you're actually not just communicating but if you're making an application that does something and communication is doing something as well then the system of interest as lyle mentioned is totally non-trivial and there's the whole framing in some of these early stages especially because they can't always be changed easily later

Um, Ron, and then anyone else?


SPEAKER_03:
Uh, yeah.

Uh, so I'm just curious when you say who's the audience, uh, is it that, uh, like, isn't this part of the active inference model itself that, okay, so whatever makes sense in that framework, wouldn't that be the audience here?

As in, it has to survive, right?

Your agent has to survive.

So whatever generative model helps it survive, would that not be the model of choice over here?

I'm just curious.

I'm not sure.


SPEAKER_00:
That's awesome.

It's an awesome way to frame it.

Maybe someone can share the free energy governance link in the chat.

I just can't look it up right now, but...

It puts this very nicely in a recent, pretty short book slash dissertation about that imperative for organizations.

And yes, in one sense, it can be said the right generative model or the audience for it is whatever its survivability conditions are.

And within our textbook group, the survivability conditions are open.

However, we're also learning about or even just gesturing towards like, okay, not just we're going to imagine a room with a person who can take on a jacket or take it off.

We can make that a didactic model and the audience could be this textbook group or future cohorts of the textbook group and the function could be just sort of like a

neutral exemplar active inference generative model but then of course the considerations for information presentation empirical data analysis any kind of application the system of interest is not just the one person with the jacket on or off two states room with a sign fluctuation so that's a different situation for model building so is that how should we interpret this recipe


SPEAKER_03:
oh okay okay but is there not like a general framework for what a good generative model looks like is what i'm saying like i i guess you could frame that differently so if you want to build pixel level representations for example you can use a gan and that's a pretty decent one but maybe pixel level representations are not a good

not good for the task at hand or something like that.

So it should fit a general category, right?

So this is what a good set of models looks like for active inference.

So that sort of is getting it.


SPEAKER_00:
Yeah, that's a very fascinating framing.

Does anyone want to add something to that?

is i i totally hear you like on what is there is there a rubric like what are we evaluating the generative model and process fit because it's not like there's just simply a best generative model you know bigger or you know whatever no feature about it except outside of a generative process um context is the fitness

and then what is their rubric is our gold standard is it like oh you're dealing with audio data here's the file format that level of standardization certainly not however are there some practices or lenses that we could bring in from people's experience with evaluating model adequacy and relevancy there probably are lyle


SPEAKER_06:
Well, yeah, that really comes right back to purpose, right?

So a model is always fit for purpose.

And you, of course, this also surfaces the questions of model validation, right?

One of the things we haven't talked about here is what's the right model?

How do we frame up the right model?

What do we choose to put in what we leave out?

Part of that is purpose and how would I evaluate, you know, if I do what I'm imagining a model will be?

How do I evaluate its quality, its validity?

Well, what data is actually available?

That's one thing you always have to ask at the outset.

What data is available?

What data can I use?

What's computationally adequate?

And what parts of this then when we kind of project, when we apply this model, if that's its role, then does it fit for the purpose?

Does it provide good

you know, adequate results and improve to be, you know, whatever behavior we're trying to address.

So you can't you can't say if it's good if you don't have a purpose.

So if your purpose is just to explore model building, which is something I love to do, then that's a pretty big there's a lot of things that are fit for that purpose.

Right.

But if the purpose is to, you know,


SPEAKER_00:
pro do a prospective uh analysis of a system and what actions might be taken to intervene then that's a different thing thanks a lot for sharing it I'm I'm really happy and I think it's relevant that we're having this kind of a discussion because we've gone through some of the first chapters and we will continue through chapter six I think into having this conversation but

anybody else want to add something about this more general topic of like how how are we even coming to talk about what system or how are we framing the system that we're modeling that's in section 6.3 i um i mean this is too broad to it's not active inference specific but


SPEAKER_04:
whenever i'm trying to model something the only questions that i mean it is contextual to the purpose it entails a purpose in an audience but all i want to know basically is what are the questions that need this model needs to like generate an answer for um what is the information that is like necessarily therefore kind of required to

model a system that would have such answers in it?

And maybe another way to say the same thing is, like, what affordances would the model require to answer or address whatever the, some set of questions that are posed to the system?

So if you asked, you know,

I don't know.

Like, how frequently does a yellow colored car, I don't know, drive down this particular road, then I wouldn't need to record like, the number of bikes or their colors that are, you know,

using the bike lane or buses or trucks large, you know, like this is maybe outside the scope of what I mean by yellow, how many, you know, cars out of all the cars, how many are yellow or something?

It's right driving down this road or whatever.

It's like, not even exactly a generative model.

But my point is that

modeling that system there, there is obvious data that's like completely irrelevant, right?

And so if you were going to build some sort of simulation of any kind, that's going to be generative, like there's often a lot of data that's just completely extraneous, depending on what questions you're going to ask of it.

So thanks.


SPEAKER_00:
In 63.

in the first paragraphs they're gonna come out hard on the interface concept of markov blanket this is how you'll do system modeling is by finding interfaces that distinguish the internal and external states of a system then that

is critiqued or elaborated because there's an infinite degrees of freedom in the core screenings and those are modeler specific and they suggest that that matters especially if you want to be considering embodied extended perspectives

where just descriptive interfacing models won't give you the whole answer.

There's a great paper, could a neuroscientist understand a microprocessor?

showing that even if you have total access to the microprocessors firing like an EEG and a generated set of single and double lesions, a lot of the interpretations would be strongly misleading.

Yet people want the wiring circuit of the brain, which is dynamic and also involves diffusive molecules.

We have all 302 nematode neurons mapped.

but that also as an interface diagram is not even close.

So if you want to describe the nematode like model building, then it's a fit for purpose.

However, there might be very simple models that could be doing a lot better in nematode behavior observation.

the form is discussed there are three main design choices first discrete and continuous time we had some awesome discussions in the previous months about like similarities and differences and where like in theory they're different and then in practice where they're different the whole question of like discretizing continuous systems um the second choice is between shallow models

and hierarchical models, where inference operates at multiple timescales.

The third choice is the consideration only of the present, kind of the variational free energy, versus models with temporal depth.

Temporal depth consideration could be purely passive and it could also include some element of

affordance which if we remember to like the b matrix actions are influencing how states of the world are changing through time so that is how active inference is unifying policy comparison by kind of embedding action into estimates of how things could evolve probabilistically

Those three design decisions are explored in slightly more detail in the subsections.

6.5, how to set up the generative model.

After specification, then the specific variables have to be included.

okay the latent state temperature is going to be continuous the observations in my thermometer i'm going to take in as just integers and then there's going to be a person who is going to be in a binary state of like whether it's hot or cold or maybe i want hot neutral cold or maybe i want them to have a 10 point scale or i want them to have a scale that's doing dot dot dot

that is in this stage of actually setting up the generative model and giving a little bit of like color to what had been just outlined it's going to be a nested model with this continuous variable and this kind of a discrete variable um here we return to the frog

example from earlier in the book where there's like but it's kind of being generalized a little bit it was introduced with the whole bayesian equation walkthrough now we're returning to it and thinking more about multimodal or like even you could consider this as sensor fusion because there's some hidden cause the jumping or the action of a frog

that is inducing several domains of impact potentially in the generative process.

And then that leads to specific observables from the perspective of the cognitive entity.

Those could be again, two communicative cognitive entities or one and not, or however.

So this is like, okay, we're going to be modeling forest fires.

So forest fires, they change the temperature, they change the chemical composition, they change the vibrations in the ground or something.

Okay, and then maybe there's three sensors, maybe you have three thermometers.

And then what about them?

Are you gonna average them?

Are they gonna be like three parallel modeled time series?

That is where some more specification of the generative model comes into play.

Keeping the active inference ontology in mind.

What are the affordances of the frog?

What are the latent states that are being changing through time?

Like sound, physical presence, or photon emission or something.

And then what are the data that... Oh, the observations.

This box looks like it's about...

different sensory modalities.

I'm sure there's a lot of interesting discussions we could bring in here.

Priors and empirical behavior.

Complete class theorems.

Any statistical decision procedure behavior may be framed as Bayes optimal under the right set of prior beliefs.

discussion of fixed and learned variables.

One can imagine the pros and the cons generally of having fixed and learned variables.

Like computationally, it's simpler to fix hard code a variable.

However, if there's a setting where the model's adequacy depends on being able to update that, maybe you want it learnable.

However, then you have to deal with these questions about like the kinetics of learning, like instantly switch or slow switch or trend averaging.

So there's a lot of discussions around learning.

How is attention regulated?

What is precision on learning?

It's like, it very much complexifies the model.

And there's many variables that you can bring into a learnable setting.

But when it's framed as just static variables and only like the hidden states changing through time, that's like the simplest case.

But more and more cognitive entities probably are going to entail considering learning dynamics.

Setting up the generative process.

The reason we postpone the design of the generative process, so little sleight of hands, entity first, not the niche first, is that in many practical applications discussed in this book, we simply assume the dynamics of the generative process are the same or very similar to the generative model.

We generally assume the agent's generative model closely mimics the process that generates its observation.

that is clearly a simplifying case because it doesn't address what if you're paying attention to predicting width and the world is dependent on height there's so many complexities of that which is really that broader like what is being modeled what matters question but in some

way very upstream or very close to the stream it is like the rabbit being put in the hat like if the rat knows that there's a five by five maze that's a huge amount of information versus if it only has access to pure local information and uh that that's just something to like i think for us to know as we look through models

Like, are we modeling the generative process?

Oh, so the seasons oscillate, so it is a sine wave.

So then the generative model of the agent is also going to be fitting a sine wave.

Well, then it kind of collapses to like a stochastic regression.

And maybe then it looks like the fit is going to be very good.

Active inference modeling brings in another complexity with action influencing outcomes that prevents some, I guess, fallacies of modeling, but by no means all, and probably introduces many others.

Eric?


SPEAKER_02:
Yeah.

Can you hear me?

This is a new one.


SPEAKER_00:
Sounds good.


SPEAKER_02:
So this might be a time to discuss the question I posted.

And I apologize.

I didn't put it in the right place the other day.

I just figured out today that it goes under this particular location.

But this is about the question about...

why modeling of a generative process is necessary is a necessary step for building an active inference model so let me just read it um because it's a lot of words uh so you know we know that an active inference agent employs a generative model as its model of the external world and it uses this general model to perform inferences about perceptual input and to make decisions about actives so in general the external world is complex and unknowable to the um

to the agent.

The generative model may or may not be able to learn, but if learning is supposed to, if it is learning, is supposed to put the generative model in a better alignment with the world's generative process, whatever that may be.

So I can see how one might model the generative process if one is building

an artificial agent in a laboratory where you kind of have access, you control how the world behaves with respect to the agent, and then you might want to study how well the agent design works versus, you know, one versus another under controlled conditions.

But this is not the same as designing an agent to go out and cope with some real-world environment where you really don't know what the generative process is.

So I think that the recipe for designing an active inference models would include formally setting up the generative process only in the kind of the laboratory situation, but not if you're really trying to build something out, you know, for the real world because you don't,

know the generative process.

You might create an artificial laboratory kind of situation by trying to build a model of how the world works and say, well, how does my agent work under those assumptions or not?

But that might set you up for putting the agent in the real world.

But in fact, you don't know the generative process if you're really trying to build something to work in the real world.

That's my comment.

My question.

That's a question.


SPEAKER_00:
It's very insightful.


SPEAKER_02:
That's a question I wanted to bring this with me.


SPEAKER_00:
Thank you, Lyle.


SPEAKER_06:
Well, I love Eric, I love that that framing because I think there's multiple different cases, right?

So I think if you're modeling something that, as you say, goes in the real world, then perhaps it's some sentient creature or being then then obviously there's

The real world, even if we knew everything about it, is too complex to model.

So that's fool's gold to assume you know everything.

And so I'm just going to say, yeah, that's hard.

Typically, I guess we would say, what are the parts of the generative, the real world, the generative process that we're going to consider relevant and deal with that and knowing that we're making a leap of faith?

But there's another case, I think, which is more generalizable just to complex adaptive systems that operate in what I call the built world.

So I work with a bunch of people who build digital twins.

They build digital twins of human infrastructure, right?

So buildings and all this stuff.

They're the generative process that we're concerned with.

is largely knowable right and largely represent representable and so and and what's interesting about that is there are a bunch of blind spots and inadequacies in what we know about that generative process and the ability to do inference about what the real state of that system is then becomes the value of this approach in that setting right so

So I don't think there's a general answer.

Once again, I think it really comes down to purpose and what the specific framing you're looking to do.

To me, this ability to say something about what I like, that idea of decision agents, right?

Decision agents that are going to potentially take action or infer actual states is much richer than what a lot of the historical modeling paradigms have given us.

So I think that's really interesting.


SPEAKER_05:
Thank you, Lyle.

Ollie?


SPEAKER_01:
I also think that the distinction between generative process and generative models becomes significant if we want to simulate learning rather than just inference.

That's the answer I got from Ryan Smith because I asked him almost the same question.

Why do we need generative process in order to simulate the agents?

Because you see, for the generative process,

If the generative model exactly maps them to generative process, we only need that capital D matrix, right?

And that's just when we're just trying to simulate the inference side of the agent, right?

But when the learning comes along, then we need to separate that capital D

from another matrix which maps into the generative process.

So yeah, one of the situations that the distinction between two might be necessary is when those two processes, I mean learning and inference, are taken as two separate phenomena to model.


SPEAKER_00:
Thanks.

One note is also there's work on symmetries in the generative process, generative model, like I think like the bidirectional paper with Matt Sims and Blue discussing it.

And then here will be a defense to Eric's excellent question.

The entity-first modeling approach

that's taken by this chapter.

One can say, I don't know whether I'm going to a forest or a desert, but I'm going to have these sensors on my designed interface, and I'm going to do extensive modeling on interoception and homeostasis.

And if I can learn policies that balance homeostasis, then I've survived.

If I fail, then

failure happens so that doesn't mean that it works or it's doing the right thing fit for purpose any of those aspects but one of the insights from the 4e and the embodied side is like a vast amount of our what is modelable as cognitive isn't necessarily the declarative I think therefore I am

possibly even symbolic type thinking, linguistic.

There's a lot going on.

And many of that a lot going on can be simplified by not even knowing about the external process.

Maybe not even the asmodeled kidney knowing about what the asmodeled liver is doing.

So this type of a focus where it's like, we're gonna define

are entity types and the kinds of observations that they can make the kinds of affordances that they have or do empirically or that they conceptually could do that approach is consistent with embodied biological systems and persistence of organizations and

So I'm wondering how that piece comes into play with this discussion that's very important about, and also their earlier discussion of the embedded and extended cognition is that it kind of blurs the line with what is a generative model, what is a generative process.

So hence there being a lot of thinking and attention on what the system's modeling is

What are the known unknowns and the unknown unknowns gonna be?

Let's just see how the chapter ends.

Six, seven, simulating, visualizing, analyzing, and fitting data using Active Inference.

So standard routines for Active Inference that provide support for all functions are available, hashtag SPM and Appendix C.

step-by-step model is a great look through this this is matlab code one amazing work that we could all iterate on would be porting matlab into the ontology into python and or julia with py mdp or active blockference but

there's a lot in spm and some of its neuroimaging specific some of its very variational base specific not all of it is going to be state of the art or the most useful in every situation however i wonder if only offering certain routines in matlab which is like a traditionally very academic

software platform and potentially non-free can be a limiting factor.

So those who feel like they want to learn more or contribute this way, helping structure some of the code architecture so that cohorts coming through can be doing multiple language.

Maybe first we can just move some of these routines into a folder.

And then people can start to organize those types of aspects.

Summary, it's a four-step recipe.

We walk through it from the consideration of the system of interest broadly, like the entity and the process, focusing in on the entity specifically, thinking structurally about what it is going to be like doing slash composed of, specifying that to a few levels of detail, then doing the same for the generative process.

And then once that is specified, it's not quite, quite there for most people today, but where...

it seems like they are laying out a path towards and where we probably can and will be after that level of setup in some potentially graphical editor or parameter file, then as SPM and MATLAB have done in many, many papers, the generative model specification almost prepares the working script.

but there's still a lot of details and pieces to add in especially in a modern environment and for all of these like non-standard and novel cases that people are wanting to consider but that is once we have a notebook that goes through the recipe then the recipes can be forked and so on and they can be written in different languages pi mdp blockference Ali


SPEAKER_01:
Yeah, just one thing that I think is not made explicit in this chapter is that actually that first step, which system are we modeling, especially the identification of the Markov blanket part, is basically at this point of active inference research is more like a hypothetical step.

because I also had the misapprehension that we can somehow identify the markup blankets from data but then as I went on through my project and by consulting Maxwell and others

Actually, this is the comment Maxwell made about my proposal that he said that identifying markup blanket from data is still an outstanding issue that is not resolved yet.

in the research on active inference.

And one of the most active areas of research they're doing at Versus Lab is just focused on this part of the modeling recipe.

I mean, how we can automatically identify or somehow learn the Markov blanket from just pure data points.


SPEAKER_00:
awesome and that ties in with dalton s's work on the blanket index and like continuous variables for dynamic assemblies of blanketing like it this is gonna get really nuanced and empirical

with the discovery and the thresholding of markov blankets and causal inference in real world systems with many different kinds of sensors and doing structure learning on generative model and process and like everything empirically which is why as a simplifying step um the uh it actually really reminds me of how dave snowden situates the difference between systems thinking and complexity thinking

which is systems often uses like a lot of nodes and flow charts to represent system elements and relationships and like interfaces.

Whereas in Complexity and the Kenevan, especially framing, it's like more like self-organizing sand dunes.

And so causal relationships might be very much in flux and it puts a higher focus on action rather than system description, especially in situations like moving your head where the relationship of different things is gonna be heavily action dependent.

And so for now we're kind of in the systems world where it's like a priori here are the system interfaces

And then we're going to take, whether it's a heuristic or whether you take a literal interpretation, but you don't have to, you could just say, I'm taking heuristically the approach of the systems mapping.

But that's not to say that that generative model couldn't be trained in a systems mapped context and then placed into a different setting

there was a mismatch or a different generative model and so it's going to be an ongoing discussion how are when are these lines drawn one other point um other than not needing to use last names to refer to specific concepts um like are we talking about the blanket that statistically insulates every

partition of nodes in these base graphs which are going to be vast as Ali and Jakob and I were discussing on the branching time active inference from just a few days ago yesterday like these graphs are going to be vast and so just saying there will be a Markov blanket in fact there will be many Markov blankets with different semantics that you might assign to them or not

How does that map onto the real world?

Is the realism instrumentalism, pragmatism, abduction, conversation that we've been having?

Do you come in with these kinds of boundaries heuristically and distinctions?

Or how many levels of uncertainty and nesting?

I don't know how many categories of blank there are.

I don't know if it's a category or a continuum of this.

You can actually still take on multiple levels of uncertainty in the modeling, but then fitting it with empirical data, if it's fit for purpose use, is to do some sort of statistical inference or provide meaning or action.

But just didactically, when the model's purpose is educational, then there's a lot of things in architectures we might play with.

And then the recipe and also this conversation helps, I hope, hold space for the educational and the curiosity-driven model development where we're going to have a lot of fun and interesting GMs and people's applications and working with different real-world constraints

in different settings, we'll all be learning a lot from it.

And hopefully some of it will be in repos we can reference.

Other people may want to play around and version within folders that we can make if anybody wants to be added as a collaborator in this textbook repo, which is just pretty much empty.

except for, I guess, a script from Jakob.

And there'll be more to say on probably GitHub and on as we continue through.

But in these last minutes, does anyone have any thoughts for our continuation of the cohort?


SPEAKER_05:
I have one question, Daniel.

You referenced a paper earlier in the discussion that

I'd love to get the reference to about persistence of organizations and survivability.

Oh, yes.


SPEAKER_00:
All right.

I will put it into resources.

Here's the work.

It's a PhD dissertation that was published as a book and I'll upload the PDF as well.

This is extremely interesting work.

And yeah, just it just came out and okay, in our last minutes, it's too too fun not to share.

so carl friston has written the forward um what is a firm's purpose what is an organization's purpose it's as difficult to answer as why am i here free energy governance and the fep inverts the question instead of asking how a system how must the system behave to survive it asks how do systems that survive behave

The answer is rather deflationary.

They survive.

Their purpose is just sustainability.

So, some classic Fristinisms.

Some very nice framings on page 95.

There's some great juxtapositions.

So, it's always awesome to see this kind of quality work.

And

Who knows what people here will see?

And I don't see any scripts here.

That's the textbook.

But who knows?

Maybe we can do some generative modeling of organizations.

Or we can specify it and iterate on it.

Realize it in BlockFriends and PyMDP and ForneyLab and JF's symbolic suite.

So there'll be a lot of fun things to explore this cohort.

Any other questions or ideas that people want to share?

Thanks and congratulations to people for joining this continuation.

It's a great continuance and

I know that this part is gonna be very interesting.

The next three months will be interesting.