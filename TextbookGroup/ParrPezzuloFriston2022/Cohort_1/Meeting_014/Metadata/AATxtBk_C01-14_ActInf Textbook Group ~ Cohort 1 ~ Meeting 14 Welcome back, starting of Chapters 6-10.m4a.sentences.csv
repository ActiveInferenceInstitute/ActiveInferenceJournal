start	end	sentNum	speaker	confidence	text
650	970	1	A	0.18178	It's.
1050	2430	2	A	0.98	Okay, we began.
3570	4942	3	A	1.0	Welcome everyone.
5076	15050	4	A	0.95	It is the resumption of our cohort update the video description.
15210	20080	5	A	0.63728	It's the resumption of cohort one of the active inference textbook group.
20450	21962	6	A	0.73708	It's our 14.
22026	25640	7	A	0.95	Okay, could someone mute Gsuppie or feel free to say whatever you want to say.
27930	29046	8	B	0.99999	Can you hear me?
29148	29800	9	A	0.92953	Yes.
30490	52780	10	B	1.0	Okay, so sorry, but I'm completely new to this interface of a gather and encoder, so I'm not sure I understand cohort one and cohort two here because cohort one, wasn't it the previous one like the one that start last year?
53310	57630	11	A	0.76883	Well, it's still going on from May till July.
58130	60240	12	A	0.99999	We did chapters one through five.
61010	63226	13	A	0.98	Now we are in this cohort.
63258	73250	14	A	0.99975	So if those who did not participate in this part, thanks for the question, but everyone in general, respectfully, let's try to have people who are in the cohort participate in it.
73320	82200	15	A	0.81182	Everyone's welcome to join and of course rewatch, but contributions and the questions and the chat are probably best so that we can respect the people who are continuing on.
82970	88780	16	A	1.0	This is our 14th meeting and now we're heading into the second five chapters of the book.
89310	91686	17	A	1.0	Okay, does any other person want to give context?
91798	92940	18	A	0.58	Oh, yeah, go ahead.
96430	102302	19	B	0.97	The current one that is going on right now is the cohort one and not cohort two.
102436	105514	20	A	0.99997	We are all learning in different stages.
105642	112542	21	A	0.52981	So the previous hour was the cohort that is focusing on chapters one through five stage they're in.
112596	115906	22	A	0.99	And now some of us, a different set of people, some are joining both.
116008	123410	23	A	0.99998	So that's why we made the meetings convenient, was so that we could like for many of us who want to do both, we can join.
124550	127960	24	A	0.99865	But this is a separate set of people.
128810	129670	25	B	0.95	I see.
129820	130520	26	C	0.9547	Yes.
131130	137394	27	B	0.99	Okay, so cohort two was first and then this meeting.
137442	139642	28	B	1.0	In this meeting right now, cohort two was first.
139696	139914	29	A	0.70241	Yes.
139952	143514	30	B	1.0	And now is cohort one, which started correct.
143712	146140	31	A	0.99985	We warmed up with chapters one through five.
147710	152620	32	B	0.99	Okay, so I will leave because I subscribe for cohort two.
152930	153482	33	A	0.94143	Excellent.
153546	154798	34	B	0.99	Okay, good.
154884	155806	35	B	0.99954	Thank you so much.
155908	157102	36	B	1.0	See you next time.
157236	160640	37	B	0.99992	Thanks for setting up all this thing.
161330	163326	38	B	0.93	Okay, bye bye.
163438	163762	39	A	0.9999	Yes.
163816	164420	40	A	0.99997	Awesome.
166710	169780	41	A	1.0	Okay, anyone else want to add anything?
170950	173970	42	A	0.99998	We don't need to do a Coda overview.
174710	185910	43	A	1.0	I would say people who are watching this recording can look at the live recording if they want a Coda update that we just went through for the cohort two's live meetings.
186730	192246	44	A	0.98615	But does anyone want to give any introductory thoughts?
192278	204160	45	A	0.99995	Otherwise, there's a few ways I think we can go for this session, but we're here just to rejoin our activities and orient towards chapters six or ten.
205330	216002	46	A	0.99975	We can scan through the chapters, we can have any suggestions or discussions around ways to approach them.
216056	216900	47	A	1.0	I don't know.
230280	232150	48	A	0.91653	Rohan and then anyone else?
234620	240820	49	D	0.76	I was wondering, when are we going to get to the projects part or discussions about the projects?
240900	242040	50	D	0.18037	Monetics.
243900	244888	51	A	0.99994	Great question.
245054	253868	52	A	0.99936	Let's look at the chapters and see where that first off, it can happen however you want with contacting people.
253954	258976	53	A	0.99	And we can make a sub page like I see exists here.
258998	260370	54	A	0.56	This looks really awesome.
261540	263328	55	A	0.64762	So people can request a sub page.
263414	265376	56	A	0.9875	They can mention it.
265478	269250	57	A	0.94	That contact them now or however.
269860	274390	58	A	0.93199	So it's up to you for a project that is under your control.
275800	290890	59	A	1.0	It can be developed in the open here or however, you can also participate in many ongoing projects like active blockfronts, which also which might all share this.
291580	295108	60	A	0.99575	Our Gitcoin grant was approved yesterday.
295284	308060	61	A	0.99995	So if people are familiar with this or want to become familiar, this is a way to provide or receive support possibly for their learning in block prints and contributing to that open source package.
312320	314272	62	A	0.9979	Does that address what you were thinking?
314326	321410	63	A	0.99952	Were you thinking about these project ideas or were you thinking more about the sort of build your own model approach that will be starting in chapter six?
323540	326916	64	D	0.7	No, about the project ideas in the code of page.
327098	328548	65	D	0.99	That answers my question.
328714	329476	66	A	0.99922	Awesome.
329658	330390	67	A	0.99133	Yeah.
333240	334916	68	A	0.64765	There are different types of projects.
334948	346636	69	A	0.70335	Clearly more will be added, but they're of different they might involve building a generative model, but they are not the generative model itself.
346738	357500	70	A	0.99999	Or only let's look at chapter six because this is where the generative model construction is going to come into play.
357570	372820	71	A	0.93	And so again, there's a lot of projects that you would only need to qualitatively think about generative models for, like educational material production is related to the generative model or could be modeled as the generative model of a learner.
373960	376692	72	A	0.99999	But you wouldn't necessarily have to make a generative model.
376746	385080	73	A	0.99998	But in chapter six, it's a recipe for designing active inference models.
386860	389108	74	A	0.94	It is going to brock.
389204	390520	75	C	0.99931	Sorry, just real quick.
390590	393192	76	C	0.54	I think Lucas here doesn't have access.
393246	394490	77	C	0.78027	He asked for access.
395100	400452	78	A	0.78	Okay, message in discord.
400516	403870	79	A	0.51417	Or I mean message and gather your email address and I'll add you.
406320	411150	80	A	1.0	Okay, sorry.
412900	414272	81	A	1.0	Okay, you requested access.
414326	415392	82	A	0.95	All right, I will add you.
415446	415952	83	A	0.96953	That's enough.
416006	430230	84	A	0.99849	Then in chapter Six, it's going to ask some questions that are driving the design of the generative model.
431080	432980	85	A	0.99999	Which system are we modeling?
433340	443256	86	A	0.99996	System of interest, what is the appropriate form for the generative model reflecting the discrete or continuous distinction that we looked at?
443438	453016	87	A	1.0	And also all these other questions that aren't exactly within the textbook, like temporal depth, hierarchical nesting, which parameters are learned versus fixed?
453128	462960	88	A	1.0	All these different directions that the models actually have to be elaborated on even before getting to the data engineering and maybe even code implementation.
463300	467890	89	A	0.99991	Just from a structural perspective, what form is it?
469460	476420	90	A	0.99998	How to set up the generative model is where some of those analytical details begin being introduced.
477240	486680	91	A	1.0	Not necessarily even the program level implementation or an executable simulation, but like, okay, we have a preference vector.
487740	489770	92	A	0.99958	Is there two states?
490380	493300	93	A	0.99998	Is there some continuous preference distribution?
493380	498350	94	A	0.99949	Whatever it is, what is the actual details of the generative model?
499440	505070	95	A	1.0	And then the other side of the coinblanket is the generative process.
505520	514850	96	A	0.99948	So what are the endogenous dynamics and the causal mapping with action for the generative process?
516340	524020	97	A	0.91	And there's kind of cases where you have more of a communication setting, active inference entities on both sides.
524440	534456	98	A	1.0	You could also have more of like a simple, simple partnering, like two deterministic programs that send messages to each other.
534478	548750	99	A	0.83328	Or it could be like one more cognitive, more agent like generative model and one more environmental nonliving type.
551280	552616	100	A	0.99999	Any thoughts or overviews?
552648	558944	101	A	0.99901	Or how would people think about how can we make this type of a recipe design?
559062	561440	102	A	0.9997	Should we be all designing a model?
561590	570312	103	A	0.99989	Or how do we even go about reading a section of the book in a chapter that begins with a recipe provision?
570476	578496	104	E	0.39343	Lyle yeah, I spent a lot of time building what I think would be classed here as generative models.
578528	596428	105	E	1.0	And what I find is that I characterize it as the step of framing up is often far trickier, sometimes much harder, frankly, than building a model, depending on what the situation is.
596594	606750	106	E	1.0	And in my experience, I find that it all comes down to making sure we understand what is the question that we're trying to answer.
607520	617760	107	E	0.79772	It's sort of like because every modeling process I'm sure everybody on this call knows is a process of deciding what to leave out, right?
617830	622180	108	E	0.99999	What to put in, what to leave out, and what level of representation.
622520	637076	109	E	0.91654	Then everything that's in there, if it's going to be a good model, has to be necessary and necessary to answer a question or provide a particular insight or so forth.
637108	648252	110	E	0.99991	So that whole issue of framing out what you're going to build in all those different the 10,000 questions, there's more than four.
648386	650030	111	E	0.51619	Ultimately it's many.
650400	655260	112	E	0.99637	Then it's all about that, which often means understanding the audience.
655920	660812	113	E	0.99992	If the model builder is the only audience, this is much simpler.
660956	684968	114	E	0.81116	If the audience is some much larger group with different perspectives, a lack of homogeneity and insight, then there almost has to be, I'm going to say almost a pre modeling or framing process of sort of framing up.
685054	686808	115	E	0.99999	What are the questions we care about?
686894	696940	116	E	1.0	And then we can talk about how those translate into a model that's just some general framing.
698240	698716	117	A	0.99993	Thank you.
698738	700924	118	A	0.66509	That's very interesting.
701122	705324	119	A	0.85	It makes me think about this audience question for the model.
705362	706492	120	A	0.6741	Like, why are we building the model?
706546	710530	121	A	0.99992	Why are we shaping our regime of attention to build this model?
711060	714096	122	A	0.89622	Model building can be an end of itself.
714198	718208	123	A	0.83	It can be creative and expressive and fun and all these other things.
718374	722304	124	A	1.0	And maybe later there's a road that has some Pragmatic value too.
722342	724004	125	A	1.0	But also it can just be like fun.
724042	727732	126	A	0.90581	Like, what would a generative model that could do this look like?
727866	745732	127	A	0.99	And that can be very didactic there's other times where you're presenting information, oh, I made a simulation of Twitter discourse and dot dot, dot is always going to be presented in a way that's not only just like, the model distilling down from the world, but then you're communicating it.
745806	761084	128	A	1.0	And then when you're actually not just communicating, but if you're making an application that does something and communication is doing something as well, then the system of interest, as Lyle mentioned, is totally nontrivial.
761132	769010	129	A	1.0	And there's the whole framing in some of these early stages, especially because they can't always be changed easily later.
770900	773430	130	A	0.16083	Rowan and then anyone else.
776440	789160	131	D	0.58705	Yeah, so I'm just curious, when you say who's the audience, isn't this part of the active inference model itself?
789230	795530	132	D	0.73	That okay, so whatever makes sense in that framework, wouldn't that be the audience here?
798780	800184	133	D	0.99	It has to survive, right?
800222	801524	134	D	0.99998	Your agent has to survive.
801572	811120	135	D	0.99998	So whatever generative model helps it survive, would that not be the it's model of choice over here?
811270	812380	136	D	0.77	And I'm just curious.
812460	824096	137	A	0.46157	I'm not sure it's an awesome way to frame it, and maybe someone can share the free energy governance link in the chat.
824128	825684	138	A	1.0	I just can't look it up right now.
825802	836280	139	A	0.9986	But it puts this very nicely in a recent pretty short book dissertation about that imperative for organizations.
836700	845690	140	A	0.96	And yes, in one sense it can be said the right generative model or like the audience for it is whatever its survivability conditions are.
846560	851470	141	A	0.62	And within our textbook group, the survivability conditions are open.
852880	870690	142	A	0.99999	However, we're also learning about or even just gesturing towards like, okay, not just we're going to imagine a room with a person who can take on a jacket or take it off.
872180	874340	143	A	0.99996	We can make that a didactic model.
874410	889640	144	A	1.0	And the audience could be this textbook group or future cohorts of the textbook group, and the function could be just sort of like a neutral exemplar active inference generative model.
889790	905340	145	A	1.0	But then, of course, the considerations for information presentation, empirical data analysis, any kind of application, the system of interest is not just the one person with the jacket on or off two states room with a sign fluctuation.
906160	908944	146	A	0.99989	So that's a different situation for model building.
909062	912320	147	A	0.96182	So how should we interpret this recipe?
915300	927316	148	D	1.0	Okay, but is there not like, a general framework for what a good generative model looks like is what I'm saying.
927498	930064	149	D	1.0	I guess you could frame that differently.
930112	945016	150	D	0.56408	So if you want to build pixel level representations, for example, you can use a gan, and that's a pretty decent one, but maybe pixel level representations are not good for the task at hand or something like that.
945038	948952	151	D	0.99046	So it should fit a general category.
949016	949244	152	A	0.99981	Right?
949282	953640	153	D	0.99981	So this is what a good set of models looks like for active inference.
953720	955790	154	D	0.99972	So that's sort of getting at.
957360	959516	155	A	0.99004	Yeah, that's a very fascinating framing.
959548	962210	156	A	0.99997	Does anyone want to add something to that?
967500	977230	157	A	1.0	I totally hear you on is there a rubric like, what are we evaluating the generative model and process fit?
977600	982956	158	A	0.99988	Because it's not like there's just simply a best generative model bigger or whatever.
983058	987150	159	A	1.0	No feature about it except outside of a generative process.
988100	992016	160	A	0.78735	Context is the fitness and then what?
992038	992716	161	A	0.85168	Is there a rubric?
992748	993776	162	A	0.99995	Is there a gold standard?
993878	999664	163	A	0.99999	Is it like, oh, you're dealing with audio data here's, the file format, that level of standardization?
999792	1000870	164	A	1.0	Certainly not.
1001480	1013240	165	A	1.0	However, are there some practices or lenses that we could bring in from people's experience with evaluating model adequacy and relevancy?
1013820	1015496	166	A	0.88298	There probably are.
1015678	1021320	167	E	0.79876	Lyle well, yeah, that really comes right back to purpose, right.
1021390	1024380	168	E	0.94367	So a model is always fit for purpose.
1027200	1031468	169	E	0.98	Of course, this also surfaces the questions of model validation, right.
1031554	1035230	170	E	1.0	One of the things we haven't talked about here is what's the right model?
1036080	1037692	171	E	1.0	How do we frame up the right model?
1037746	1040080	172	E	0.99992	What do we choose to put in what we leave out?
1040230	1042332	173	E	0.99998	Part of that is purpose.
1042396	1047408	174	E	0.75	And how would I evaluate if I do what I'm imagining a model will be?
1047494	1050992	175	E	1.0	How do I evaluate its quality, its validity?
1051136	1053300	176	E	0.99667	Well, what data is actually available?
1053450	1058004	177	E	0.9998	That's one thing you always have to ask at the outset what data is available?
1058122	1059604	178	E	1.0	What data can I use?
1059722	1063028	179	E	0.99971	What's computationally adequate?
1063204	1075464	180	E	0.6	And what parts of this then when we kind of project, when we apply this model, if that's its role, then does it fit for the purpose?
1075512	1082830	181	E	0.99989	Does it provide good, adequate results and improve whatever behavior we're trying to address?
1086000	1089596	182	E	1.0	You can't say if it's good if you don't have a purpose.
1089708	1101332	183	E	0.99965	So if your purpose is just to explore model building, which is something I love to do, then that's a pretty big there's a lot of things that are fit for that purpose, right?
1101466	1116010	184	E	0.99958	But if the purpose is to do a prospective analysis of a system and what actions might be taken to intervene, then that's in a different thing.
1119260	1120824	185	A	0.99999	Thanks a lot for sharing it.
1120942	1122920	186	A	0.99869	I'm really happy.
1122990	1135972	187	A	0.94	And I think it's relevant that we're having this kind of a discussion because we've gone through some of the first chapters and we'll continue through chapter six, I think, in having this conversation.
1136136	1156660	188	A	0.55875	But does anybody else want to add something about this more general topic of, like, how are we even coming to talk about what system, or how are we framing the system that we're modeling that's in Section 6.3?
1161110	1163038	189	C	1.0	This is too broad.
1163214	1165254	190	C	0.98956	It's not active inference specific.
1165372	1172402	191	C	0.99992	But whenever I'm trying to model something, the only questions that I mean, it is contextual to the purpose.
1172466	1174770	192	C	1.0	It entails a purpose in an audience.
1174850	1184620	193	C	0.81531	But all I want to know basically is what are the questions that this model needs to generate an answer for?
1186830	1199360	194	C	0.76195	What is the information that is necessarily, therefore kind of required to model a system that would have such answers in it?
1202390	1219190	195	C	0.63	And maybe another way to say the same thing is like, what affordances would the model require to answer, address whatever, some set of questions that are posed to system?
1219260	1248160	196	C	0.52502	So if you asked, I don't know, how frequently does a yellow colored car, I don't know drive down this particular road, then I wouldn't need to record the number of bikes or their colors that are using the bike lane or buses or trucks large.
1249330	1254030	197	C	1.0	This is maybe outside the scope of what I mean by yellow.
1254190	1267122	198	C	0.97003	How many cars out of all the cars, how many are yellow or something driving down this road or whatever, like not even exactly a generative model.
1267176	1274120	199	C	1.0	But my my point is that modeling that system there, there is obvious data that's completely irrelevant, right?
1274490	1290240	200	C	0.68	And so if you were going to build some sort of simulation of any kind that's going to be generative like there's often a lot of data that's just completely extraneous depending on what questions you're going to ask of it.
1294290	1295040	201	A	0.99968	Thanks.
1295970	1306610	202	A	0.98	In 63 in the first paragraphs they're going to come out hard on the interface concept of Markov blanket.
1307190	1315080	203	A	1.0	This is how you'll do system modeling is by finding interfaces that distinguish the internal and external states of a system.
1316010	1333734	204	A	0.99997	Then that is critiqued or elaborated because there's in infinite degrees of freedom in the course gradings and those are modeler specific and they suggest that that matters.
1333782	1346720	205	A	0.99999	Especially if you want to be considering embodied extended perspectives where just descriptive interfacing models won't give you the whole answer.
1347410	1366150	206	A	0.96236	There's a great paper could a neuroscientist understand a microprocessor showing that even if you have total access to the microprocessors firing like an EEG and a generated set of single and double lesions, a lot of the interpretations would be strongly misleading.
1367290	1373266	207	A	0.99926	Yet people want the wiring circuit of the brain which is dynamic and also involves diffusive molecules.
1373458	1383100	208	A	0.99999	We have all 302 nematode neurons mapped but that also as an interface diagram is not even close.
1383710	1388910	209	A	0.99969	So if you want to describe the nematode like model building then it's a fit for purpose.
1389250	1399230	210	A	0.98577	However, there might be very simple models that could be doing a lot better in nematode behavior observation.
1401750	1404286	211	A	0.99	The form is discussed.
1404398	1406670	212	A	0.99957	There are three main design choices.
1406830	1409026	213	A	1.0	First, discrete and continuous time.
1409128	1420040	214	A	0.90579	We had some awesome discussions in the previous months about similarities and differences and where in theory they're different and then in practice where they're different.
1420490	1424070	215	A	1.0	The whole question of discretizing continuous systems.
1425050	1432970	216	A	1.0	The second choice is between shallow models and hierarchical models where inference operates at multiple timescales.
1433790	1442990	217	A	1.0	The third choice is the consideration only of the present kind of the variational free energy versus models with temporal depth.
1443410	1463230	218	A	0.90846	Temporal depth consideration could be purely passive and it could also include some element of affordance which if we remember to like the B matrix actions are influencing how states of the world are changing through time.
1463400	1467670	219	A	0.93083	So that is how active inference is unifying.
1468250	1477210	220	A	0.81958	Policy comparison by kind of embedding action into estimates of how things could evolve probabilistically.
1478910	1487162	221	A	0.99999	Those three design decisions are explored in slightly more detail in the subsections 65.
1487216	1492270	222	A	0.97649	How to set up the generative model after specification.
1492930	1496830	223	A	0.99996	Then the specific variables have to be included.
1497570	1501322	224	A	1.0	Okay, the latent state temperature is going to be continuous.
1501466	1506094	225	A	0.99	The observations in my thermometer I'm going to take in as just integers.
1506222	1516618	226	A	1.0	And then there's going to be a person who is going to be in a binary state of like whether it's hot or cold, or maybe I want hot, neutral and cold.
1516654	1539150	227	A	0.99998	Or maybe I want them to have a ten point scale or I want them to have a scale that's doing dot, dot, dot that is in this stage of actually setting up the generative model and giving a little bit of color to what had been just outlined.
1539490	1543066	228	A	0.97484	It's going to be a nested model with this continuous variable.
1543098	1544910	229	A	0.7	And this kind of a discrete variable.
1547970	1557890	230	A	0.99999	Here we return to the frog example from earlier in the book where there's like but it's kind of being generalized a little bit.
1558040	1561902	231	A	1.0	It was introduced with the whole Bayesian equation walkthrough.
1562046	1583500	232	A	1.0	Now we're returning to it and thinking more about multimodal or like even you could consider this as sensor fusion because there's some hidden cause, the jumping or the action of a frog that is inducing several domains of impact potentially in the generative process.
1584110	1591710	233	A	0.81	And then that leads to specific observables from the perspective of the cognitive entity.
1592850	1604958	234	A	0.99993	Those could be again, two communicative cognitive entities or one and not or however so this is like, okay, we're going to be modeling forest fires.
1605134	1614180	235	A	0.99982	So forest fires, they change the temperature, they change the chemical composition, they change the vibrations in the ground or something.
1615190	1618870	236	A	0.99	Okay, and then maybe there's three sensors, maybe you have three thermometers.
1619210	1620374	237	A	0.9	And then what about them?
1620412	1621798	238	A	1.0	Are you going to average them?
1621964	1625510	239	A	1.0	Are they going to be like three parallel modeled time series?
1626030	1631660	240	A	0.66	That is where some more specification of the generative model comes into play.
1632750	1637420	241	A	0.99941	Keeping the active inference ontology in mind.
1637970	1639706	242	A	0.99955	What are the affordances of the frog?
1639818	1649822	243	A	1.0	What are the latent states that are being changing through time like sound, physical presence or photon emission or something?
1649956	1651378	244	A	0.96	And then what are the data?
1651464	1653410	245	A	0.77	That would be the O, the observations.
1656710	1660814	246	A	0.61	This box looks like it's about different sensory modalities.
1660862	1665720	247	A	0.87353	I'm sure there's a lot of interesting discussions we could bring in here.
1672870	1677890	248	A	0.99392	Priors and empirical behavior complete class theorems.
1678730	1685430	249	A	0.8431	Any statistical decision procedure behavior may be framed as Bayes optimal under the right set of prior beliefs.
1691010	1700530	250	A	0.99845	Discussion of fixed and learned variables one can imagine the pros and the cons generally of having fixed and learned variables.
1701030	1706430	251	A	0.94744	Like computationally it's simpler to fix hard code a variable.
1706590	1714630	252	A	0.99999	However, if there's a setting where the model's adequacy depends on being able to update that, maybe you want it learnable.
1714970	1724742	253	A	0.99998	However, then you have to deal with these questions about the kinetics of learning like instantly switch or slow switch or trend averaging.
1724886	1731342	254	A	0.99992	So there's a lot of discussions around learning how is attention regulated, what is precision on learning?
1731396	1741550	255	A	0.37532	It's like it very much complexifies the model and there's many variables that you can bring into a learnable setting.
1742610	1750082	256	A	0.99996	But when it's framed as just static variables and only like the hidden states changing through time.
1750216	1752020	257	A	0.99997	That's like the simplest case.
1753270	1766280	258	A	0.99989	But more and more cognitive entities probably are going to entail considering learning dynamics, setting up the generative process.
1768810	1789440	259	A	1.0	The reason we postponed the design of the generative process so little slate of hands entity first, not the niche first is that in many practical applications discussed in this book, we simply assume the dynamics of the generative process are the same or very similar to the generative model.
1790050	1795170	260	A	1.0	We generally assume the agent's generative model closely mimics the process that generates its observation.
1797110	1813666	261	A	1.0	That is clearly a simplifying case because it doesn't address what if you're paying attention to predicting width and the world is dependent on height.
1813858	1818654	262	A	0.9458	There's so many complexities of that which is really that broader.
1818722	1832970	263	A	0.99858	Like what is being modeled, what matters question but in some way very upstream or very close to the stream, it is like the rabbit being put in the hat.
1833310	1844980	264	A	0.58894	Like if the rat knows that there's a five x five maze, that's a huge amount of information versus if it only has access to pure local information.
1846070	1851650	265	A	1.0	And that's just something to, I think, for us to note as we look through models.
1852150	1854642	266	A	0.57457	Like are we modeling the generative process?
1854776	1857086	267	A	0.75	Oh, so the seasons oscillate.
1857118	1858710	268	A	0.99999	So it is a sine wave.
1859130	1863350	269	A	0.99885	So then the generative model of the agent is also going to be fitting a sine wave.
1863690	1873980	270	A	0.87436	Well, then it kind of collapses to like a stochastic regression and maybe then it looks like the fit is going to be very good.
1876190	1891950	271	A	0.99455	Active inference modeling brings in another complexity with action influencing outcomes that prevents some, I guess, fallacies of modeling, but by no means and probably introduces many others.
1892020	1892830	272	A	1.0	Eric?
1894290	1894990	273	F	0.86357	Yeah.
1895140	1896030	274	F	0.99905	Can you hear me?
1896100	1898370	275	A	1.0	This is a new sounds good.
1898520	1907798	276	F	0.98931	So this might be a time to discuss the question I posted and I apologize I didn't put it in the right place the other day.
1907964	1911122	277	F	0.98	I just figured out today that it goes under this particular location.
1911186	1922022	278	F	0.99762	But this is about the question about why modeling of a generative process is necessary, is a necessary step for building an active inference model.
1922076	1925580	279	F	0.99986	So let me just read it because it's a lot of words.
1926110	1938666	280	F	0.97708	So we know that an active inference agent employs a generative model as its model of the external world and it uses this generative model to perform inferences about perceptual input and to make decisions about actions.
1938778	1946254	281	F	0.99969	So in general, the external world is complex and unknowable to the agent.
1946452	1949202	282	F	0.91	The generative model may or may not be able to learn.
1949256	1958166	283	F	1.0	But if it is learning is supposed to put the generative model in a better alignment with the world's generative process, whatever that may be.
1958268	1971930	284	F	0.51564	So I can see how one might model the generative process if one is building an artificial agent in a laboratory where you kind of have access, you control how the world behaves with respect to the agent.
1972080	1979574	285	F	1.0	And then you might want to study how well the agent design works versus one versus another under control conditions.
1979702	1987118	286	F	0.99989	But this is not the same as designing an agent to go out and cope with some real world environment where you really don't know what the generative process is.
1987204	2002930	287	F	0.99996	So I think that the recipe for designing an active inference models would include formally setting up the generative process only in the kind of the laboratory situation, but not if you're really trying to build something out for the real world because you don't know the generative process.
2003080	2013446	288	F	1.0	You might create an artificial laboratory kind of situation by trying to build a model of how the world works and say, well, how does my agent work under those assumptions or not?
2013548	2017622	289	F	0.66567	But that might set you up for putting the agent in the real world.
2017676	2023900	290	F	0.99998	But in fact, you don't know the generative process if you're really trying to build something to work in the real world.
2024590	2026250	291	F	0.79768	That's my comment, my question.
2026320	2027260	292	F	0.38955	That's your question.
2031730	2033230	293	A	0.77936	Thank you, Lyle.
2034370	2040142	294	E	0.99635	Well, Eric, I love that framing because I think there's multiple different cases, right?
2040196	2063910	295	E	0.99686	So I think if you're modeling something that, as you say, goes in the real world, then perhaps it's some sentient creature or being, then obviously the real world, even if we knew everything about it, is too complex to model.
2063980	2064598	296	E	0.99987	Right.
2064764	2069980	297	E	0.6575	So that's fool's gold to assume you know everything, right?
2073150	2075146	298	E	0.99555	I'm just going to say, yeah, that's hard.
2075328	2088586	299	E	0.95415	Typically, I guess we would say what are the parts of the generative, the real world, the generative process that we're going to consider relevant and deal with that and knowing that we're making a leap of faith.
2088698	2099620	300	E	0.99999	But there's another case, I think, which is more generalizable, just complex adaptive systems that operate in what I call the built world.
2100150	2105694	301	E	0.70438	So I work with a bunch of people who build digital twins.
2105822	2114454	302	E	0.52398	They build digital twins of human infrastructure, so buildings and all this stuff there.
2114492	2123690	303	E	0.52	The generative process that we're concerned with is largely knowable and largely representable.
2126430	2145086	304	E	0.99976	What's interesting about that is there are a bunch of blind spots and inadequacies in what we know about that generative process and the ability to do inference about what the real state of that system is then becomes the value of this approach in that setting.
2145198	2145860	305	A	0.77728	Right.
2148230	2150050	306	E	1.0	I don't think there's a general answer.
2150120	2154914	307	E	1.0	Once again, I think it really comes down to purpose and what the specific framing you're looking to do?
2155032	2161046	308	E	1.0	To me, this ability to say something about what I I like that idea of decision agents, right.
2161148	2174842	309	E	0.53395	Decision agents that are going to potentially take action or infer actual states is much richer than what a lot of the historical modeling paradigms have given us.
2174976	2177340	310	E	0.93252	So I think that's really interesting.
2178590	2179574	311	A	0.61616	Thank you, Lyle.
2179622	2180410	312	A	0.79476	Ali.
2188450	2202686	313	G	0.99992	Also think that the distinction between generative process and generative models become significant if we want to simulate learning rather than just inference.
2202878	2209960	314	G	0.76	I mean, that's the answer I got from Ryan Smith because I asked him almost the same question.
2210410	2216040	315	G	0.99661	Why do we need generative process in order to simulate the agents?
2217290	2233200	316	G	0.9332	Because, you see, for the generative process, if the generative model exactly maps them to generative process, we only need that capital D matrix, right?
2233970	2240318	317	G	1.0	And that's just when we're just trying to simulate the inference side of the agent, right?
2240404	2255860	318	G	0.99993	But when the learning comes along, then we need to separate that capital D from another matrix, probably dill case D, which maps into the generator process.
2256170	2271820	319	G	0.99963	So yeah, one of the situations that the distinction between two might be necessary is when those two process, I mean learning and inference, are taken as two separate phenomena to model.
2273550	2274300	320	A	0.99975	Thanks.
2275630	2288814	321	A	1.0	One note is also there's work on symmetries in the generative process, generative model, like, I think like the bi directional paper with Matt Sims and Blue discussing it.
2288932	2296500	322	A	0.99	And then here will be a defense to Eric's excellent question.
2299350	2323510	323	A	0.68	The entity first modeling approach that's taken by this chapter, one can say, I don't know whether I'm going to a forest or a desert, but I'm going to have these sensors on my designed interface and I'm going to do extensive modeling on interoception and homeostasis.
2323670	2329530	324	A	1.0	And if I can learn policies that balance homeostasis, then I've survived.
2330110	2333660	325	A	0.99996	If I fail, then failure happens.
2334030	2338970	326	A	0.99111	So that doesn't mean that it works or it's doing the right thing, fit for purpose, any of those aspects.
2339130	2354930	327	A	0.99971	But one of the insights from the four E and the embodied side is like a vast amount of our what is modelable as cognitive isn't necessarily the declarative.
2355350	2363746	328	A	0.59	I think, therefore I am possibly even symbolic type thinking linguistic.
2363938	2380620	329	A	0.95226	There's a lot going on and many of that a lot going on can be simplified by not even knowing about the external process, maybe not even the as modeled kidney knowing about what the as modeled liver is doing.
2381730	2404480	330	A	0.84871	So this type of a focus where it's like we're going to define our entity types and the kinds of observations that they can make, the kinds of affordances that they have or do empirically or that they conceptually could do.
2406450	2416142	331	A	1.0	That approach is consistent with embodied biological systems and persistence of organizations.
2416206	2433980	332	A	0.54	And so I'm wondering how that piece comes into play with this discussion that's very important about and also their earlier discussion of the embedded and extended cognition is that it kind of blurs the line with what is a generative model, what is a generative process.
2434510	2444620	333	A	0.94403	So hence there being a lot of thinking and attention on what the system's modeling is.
2445810	2448880	334	A	0.9885	What are the known unknowns and the unknown unknowns going to be.
2449410	2453550	335	A	0.96256	Let's just see how the chapter ends.
2457860	2462736	336	A	0.56	Six, seven simulating, visualizing, analyzing, and fitting data using active inference.
2462928	2469190	337	A	0.99951	So standard routines for active inference that provide support for all functions are available.
2470040	2478216	338	A	0.51298	Hashtag SPM and Appendix C step by Step model is a great look through this.
2478318	2486588	339	A	0.63	This is MATLAB code one amazing work that we could all iterate on.
2486754	2497660	340	A	0.99987	Would be porting MATLAB into the ontology into Python and or Julia with Pi MDP or active blockference.
2498080	2506144	341	A	0.99838	But there's a lot in SPM and some of it's neuroimaging specific, some of it's very variational base specific.
2506342	2511670	342	A	0.99995	Not all of it is going to be state of the art or the most useful in every situation.
2512040	2529284	343	A	0.99976	However, I wonder if only offering certain routines in MATLAB, which is like a traditionally very academic software platform and potentially non free, can be a limiting factor.
2529412	2547396	344	A	0.99918	So those who feel like they want to learn more or contribute this way helping structure some of the code architecture so that cohorts coming through can be doing multiple language.
2547448	2556480	345	A	0.9968	Maybe first we can just move some of these routines into a folder and then people can start to organize those types of aspects.
2558180	2561360	346	A	0.99791	Summary it's a four step recipe.
2561700	2581384	347	A	0.99748	We walk through it from the consideration of the system of interest broadly, like the entity and the process, focusing in on the entity specifically thinking structurally about what it is going to be like doing composed of specifying that to a few levels of detail, then doing the same for the generative process.
2581582	2600800	348	A	1.0	And then once that is specified, it's not quite, quite there for most people today, but where it seems like they are laying out a path towards and where we probably can and will be after that level of setup.
2601700	2606480	349	A	1.0	In some potentially graphical editor or parameter file.
2607060	2620020	350	A	0.99979	Then, as SPM and MATLAB have done in many, many papers, the generative model specification almost prepares the working script.
2620440	2629896	351	A	0.99999	But there's still a lot of details and pieces to add in, especially in a modern environment and for all of these non standard and novel cases that people are wanting to consider.
2630078	2641692	352	A	0.99997	But that is once we have a notebook that goes through the recipe, then the recipes can be forked and so on and they can be written in different languages, pi MDP, block for instance.
2641826	2642700	353	A	0.91333	Ali.
2645200	2655484	354	G	0.99188	Yeah, just one thing that I think is not made explicit in this chapter is that actually that first step, which system are we modeling?
2655532	2681290	355	G	0.98197	Especially the identification of the markup blanket part is basically at this point of active inference research is more like a hypothetical step because I also had the misapprehension that we can somehow identify the markup blankets from data.
2681660	2708540	356	G	1.0	But then as I went on through my project and by consulting Maxwell and others actually this is the comment Maxwell made about my proposal that he said that identifying markup blanket from data is still an outstanding issue that is not resolved yet in the research on active inference.
2708620	2720048	357	G	0.55	And one of the most active areas, areas of research they're doing at Versus Lab is just focused on this part of the modeling recipe.
2720144	2730330	358	G	0.88	I mean how we can identify, automatically identify or somehow learn the markup blanket from just pure data points.
2731660	2732408	359	A	0.99998	Awesome.
2732574	2741740	360	A	0.8	And that ties in with Dalton s's work on the blanket index and like continuous variables for dynamic assemblies of blanketing.
2743440	2763488	361	A	1.0	This is going to get really nuanced and empirical with the discovery and the thresholding of Markov blankets and causal inference in real world systems with many different kinds of sensors and doing structure learning on generative model and process and like everything empirically.
2763664	2776730	362	A	1.0	Which is why, as a simplifying step, it actually really reminds me of how Dave Snowden situates the difference between systems thinking and complexity thinking.
2777100	2796940	363	A	0.99995	Which is systems often uses, like, a lot of nodes and flowcharts to represent system elements and relationships and interfaces, whereas in complexity and the Knevin especially framing, it's more like self organizing sand dunes.
2797540	2818180	364	A	0.76	And so causal relationships might be very much in flux and it puts a higher focus on action rather than system description, especially in situations like moving your head where the relationship of different things is going to be heavily action dependent.
2819880	2833944	365	A	1.0	And so for now, we're kind of in the systems world where it's like a priori, here are the system interfaces and then we're going to take whether it's a heuristic or whether you take a literal interpretation, but you don't have to.
2834142	2840780	366	A	1.0	You could just say I'm taking heuristically the approach of the system's mapping.
2841760	2858370	367	A	1.0	But that's not to say that that generative model couldn't be trained in a systems mapped context and then placed into a different setting where there was a mismatch or a different generative model.
2859960	2862820	368	A	0.99	And so it's going to be an ongoing discussion.
2863720	2865248	369	A	0.99962	When are these lines drawn?
2865344	2884120	370	A	1.0	One other point, other than not needing to use last names to refer to specific concepts, like are we talking about the blanket that statistically insulates every partition of nodes in these Bayes graphs, which are going to be vast?
2884880	2896860	371	A	0.99497	As Ali and Yaakov and I were discussing on the branching time active inference from just a few days ago yesterday, these graphs are going to be vast.
2897600	2900476	372	A	1.0	And so just saying there will be a Markov blanket.
2900508	2905890	373	A	1.0	In fact, there will be many Markov blankets with different semantics that you might assign to them or not.
2907940	2910132	374	A	1.0	How does that map onto the real world?
2910186	2917990	375	A	0.99611	Is like the realism, instrumentalism, pragmatism abduction conversation that we've been having?
2918360	2931684	376	A	0.99998	Do you come in with these kinds of boundaries, heuristically and distinctions or how many levels of uncertainty and nesting?
2931812	2935050	377	A	0.6	I don't know how many categories of blank there are.
2935420	2938990	378	A	1.0	I don't know if it's a category or a continuum of this.
2940000	2957308	379	A	1.0	You can actually still take on multiple levels of uncertainty in the modeling, but then fitting it with empirical data, if it's fit for purpose use is to do some sort of statistical inference or like provide meaning or action, but just didactically.
2957484	2967168	380	A	1.0	When the model's purpose is educational, then there's a lot of things and architectures we might play with and then the recipe.
2967264	2994584	381	A	0.97	And also this conversation helps, I hope, hold space for the educational and the curiosity driven model development where we're going to have a lot of fun and interesting GMs and people's applications and working with different real world constraints and different settings.
2994632	3003200	382	A	0.88006	We'll all be learning a lot from it, and hopefully some of it will be in repos we can reference.
3004660	3025560	383	A	0.97034	Other people may want to play around and version within folders that we can make if anybody wants to be added as a collaborator in this textbook repo, which is just pretty much empty except for, I guess, a script from Yaakup.
3028060	3032452	384	A	1.0	And there'll be more to say on probably GitHub.
3032516	3035704	385	A	0.65	And as we continue through.
3035742	3042700	386	A	0.99998	But in these last minutes, does anyone have any thoughts for our continuation of the cohort?
3046720	3048216	387	E	0.98	I have one question.
3048338	3058800	388	E	0.99338	Daniel, you referenced a paper earlier in the discussion that I'd love to get the reference to about persistence of organizations and survivability.
3059540	3060530	389	A	0.93	Oh, yes.
3068040	3068950	390	A	0.77	All right.
3069560	3074520	391	A	0.99	I will put it into resources.
3079180	3080410	392	A	0.99676	Here's the work.
3084300	3090236	393	A	0.47769	It's a PhD dissertation that was published as a book, and I'll upload the PDF as well.
3090418	3094510	394	A	1.0	This is extremely interesting work.
3103320	3113190	395	A	0.68371	Yeah, it just came out and and okay, in our last minutes, it's it's too, too fun not to share.
3116920	3121480	396	A	0.99985	So Karl Friston has written a foreword.
3124620	3126224	397	A	0.99997	What is a firm's purpose?
3126292	3128248	398	A	0.82645	What is an organization's purpose?
3128424	3130828	399	A	0.65055	It's as difficult to answer as why am I here?
3130914	3134780	400	A	0.99989	Free energy, governance and the FEP.
3135440	3140716	401	A	0.99984	Inverts the question, instead of asking how must the system behave to survive?
3140748	3143120	402	A	1.0	It asks, how do systems that survive behave?
3143700	3145244	403	A	0.99	The answer is rather deflationary.
3145292	3146012	404	A	0.9312	They survive.
3146076	3148000	405	A	0.99992	Their purpose is just sustainability.
3148820	3158870	406	A	0.9998	So some classic Fristinisms, some very nice framings on page 95.
3160360	3164900	407	A	0.97361	There's some great juxtapositions.
3166300	3172490	408	A	0.70649	So it's always awesome to see this kind of quality work.
3173340	3177804	409	A	1.0	And who knows what people here will see?
3177922	3182408	410	A	1.0	And I don't see any scripts here, thus the textbook.
3182584	3185100	411	A	0.99999	But who knows?
3186160	3203600	412	A	1.0	Maybe we can do some generative modeling of organizations or we can specify it and iterate on it, realize it in block, for instance, and Pymdp and for any lab and JF's symbolic suite.
3206040	3209380	413	A	0.99984	So there'll be a lot of fun things to explore this cohort.
3214050	3217680	414	A	0.99996	Any other questions or ideas that people want to share?
3220650	3221062	415	A	0.99994	Thanks.
3221116	3225110	416	A	1.0	And congratulations to people for joining this continuation.
3225530	3228310	417	A	0.54759	It's a great continuance.
3229530	3236400	418	A	0.76	And and I know that this part is going to be very interesting.
3236930	3238300	419	A	1.0	The next three months will be interesting.
