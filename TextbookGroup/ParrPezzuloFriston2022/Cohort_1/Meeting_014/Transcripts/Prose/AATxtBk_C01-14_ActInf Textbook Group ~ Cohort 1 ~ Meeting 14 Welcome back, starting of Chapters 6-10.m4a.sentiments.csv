start	end	speaker	sentiment	confidence	text
650	970	A	0.6326377391815186	It's.
1050	2430	A	0.692970335483551	Okay, we began.
3570	4942	A	0.7825513482093811	Welcome everyone.
5076	15050	A	0.8908425569534302	It is the resumption of our cohort update the video description.
15210	20080	A	0.9145444631576538	It's the resumption of cohort one of the active inference textbook group.
20450	21962	A	0.7038624882698059	It's our 14.
22026	25640	A	0.7200919985771179	Okay, could someone mute Gsuppie or feel free to say whatever you want to say.
27930	29046	B	0.8097810745239258	Can you hear me?
29148	29800	A	0.46103888750076294	Yes.
30490	52780	B	0.7158476710319519	Okay, so sorry, but I'm completely new to this interface of a gather and encoder, so I'm not sure I understand cohort one and cohort two here because cohort one, wasn't it the previous one like the one that start last year?
53310	57630	A	0.8425648808479309	Well, it's still going on from May till July.
58130	60240	A	0.8820713758468628	We did chapters one through five.
61010	63226	A	0.5758533477783203	Now we are in this cohort.
63258	73250	A	0.733625054359436	So if those who did not participate in this part, thanks for the question, but everyone in general, respectfully, let's try to have people who are in the cohort participate in it.
73320	82200	A	0.9056348204612732	Everyone's welcome to join and of course rewatch, but contributions and the questions and the chat are probably best so that we can respect the people who are continuing on.
82970	88780	A	0.8393825888633728	This is our 14th meeting and now we're heading into the second five chapters of the book.
89310	91686	A	0.8149219155311584	Okay, does any other person want to give context?
91798	92940	A	0.6491861343383789	Oh, yeah, go ahead.
96430	102302	B	0.8437298536300659	The current one that is going on right now is the cohort one and not cohort two.
102436	105514	A	0.759335458278656	We are all learning in different stages.
105642	112542	A	0.9388948678970337	So the previous hour was the cohort that is focusing on chapters one through five stage they're in.
112596	115906	A	0.8541714549064636	And now some of us, a different set of people, some are joining both.
116008	123410	A	0.6625696420669556	So that's why we made the meetings convenient, was so that we could like for many of us who want to do both, we can join.
124550	127960	A	0.7290300726890564	But this is a separate set of people.
128810	129670	B	0.5826064348220825	I see.
129820	130520	C	0.46103888750076294	Yes.
131130	137394	B	0.8740698099136353	Okay, so cohort two was first and then this meeting.
137442	139642	B	0.9252522587776184	In this meeting right now, cohort two was first.
139696	139914	A	0.46103888750076294	Yes.
139952	143514	B	0.5149022340774536	And now is cohort one, which started correct.
143712	146140	A	0.62750244140625	We warmed up with chapters one through five.
147710	152620	B	0.783069908618927	Okay, so I will leave because I subscribe for cohort two.
152930	153482	A	0.5708940029144287	Excellent.
153546	154798	B	0.7295194268226624	Okay, good.
154884	155806	B	0.9793016910552979	Thank you so much.
155908	157102	B	0.6020334959030151	See you next time.
157236	160640	B	0.8295331001281738	Thanks for setting up all this thing.
161330	163326	B	0.5127374529838562	Okay, bye bye.
163438	163762	A	0.46103888750076294	Yes.
163816	164420	A	0.9184247851371765	Awesome.
166710	169780	A	0.8813409805297852	Okay, anyone else want to add anything?
170950	173970	A	0.5351295471191406	We don't need to do a Coda overview.
174710	185910	A	0.883842945098877	I would say people who are watching this recording can look at the live recording if they want a Coda update that we just went through for the cohort two's live meetings.
186730	192246	A	0.6922199726104736	But does anyone want to give any introductory thoughts?
192278	204160	A	0.6463793516159058	Otherwise, there's a few ways I think we can go for this session, but we're here just to rejoin our activities and orient towards chapters six or ten.
205330	216002	A	0.7994853258132935	We can scan through the chapters, we can have any suggestions or discussions around ways to approach them.
216056	216900	A	0.5666733384132385	I don't know.
230280	232150	A	0.883098304271698	Rohan and then anyone else?
234620	240820	D	0.8971537351608276	I was wondering, when are we going to get to the projects part or discussions about the projects?
240900	242040	D	0.7002837061882019	Monetics.
243900	244888	A	0.6860781908035278	Great question.
245054	253868	A	0.8411692976951599	Let's look at the chapters and see where that first off, it can happen however you want with contacting people.
253954	258976	A	0.8006081581115723	And we can make a sub page like I see exists here.
258998	260370	A	0.9870668053627014	This looks really awesome.
261540	263328	A	0.8922942280769348	So people can request a sub page.
263414	265376	A	0.7514948844909668	They can mention it.
265478	269250	A	0.8284655213356018	That contact them now or however.
269860	274390	A	0.7770593762397766	So it's up to you for a project that is under your control.
275800	290890	A	0.6214742064476013	It can be developed in the open here or however, you can also participate in many ongoing projects like active blockfronts, which also which might all share this.
291580	295108	A	0.8594563007354736	Our Gitcoin grant was approved yesterday.
295284	308060	A	0.7213968634605408	So if people are familiar with this or want to become familiar, this is a way to provide or receive support possibly for their learning in block prints and contributing to that open source package.
312320	314272	A	0.8513480424880981	Does that address what you were thinking?
314326	321410	A	0.9206458330154419	Were you thinking about these project ideas or were you thinking more about the sort of build your own model approach that will be starting in chapter six?
323540	326916	D	0.7937914133071899	No, about the project ideas in the code of page.
327098	328548	D	0.7356243133544922	That answers my question.
328714	329476	A	0.9184247851371765	Awesome.
329658	330390	A	0.5491447448730469	Yeah.
333240	334916	A	0.8017256855964661	There are different types of projects.
334948	346636	A	0.7359544038772583	Clearly more will be added, but they're of different they might involve building a generative model, but they are not the generative model itself.
346738	357500	A	0.8615391850471497	Or only let's look at chapter six because this is where the generative model construction is going to come into play.
357570	372820	A	0.7362797856330872	And so again, there's a lot of projects that you would only need to qualitatively think about generative models for, like educational material production is related to the generative model or could be modeled as the generative model of a learner.
373960	376692	A	0.825138509273529	But you wouldn't necessarily have to make a generative model.
376746	385080	A	0.8394348621368408	But in chapter six, it's a recipe for designing active inference models.
386860	389108	A	0.771577775478363	It is going to brock.
389204	390520	C	0.557320237159729	Sorry, just real quick.
390590	393192	C	0.522240400314331	I think Lucas here doesn't have access.
393246	394490	C	0.764081597328186	He asked for access.
395100	400452	A	0.8561674356460571	Okay, message in discord.
400516	403870	A	0.8962506055831909	Or I mean message and gather your email address and I'll add you.
406320	411150	A	0.5028268694877625	Okay, sorry.
412900	414272	A	0.8085213303565979	Okay, you requested access.
414326	415392	A	0.5886157155036926	All right, I will add you.
415446	415952	A	0.49462276697158813	That's enough.
416006	430230	A	0.9104331135749817	Then in chapter Six, it's going to ask some questions that are driving the design of the generative model.
431080	432980	A	0.8361095786094666	Which system are we modeling?
433340	443256	A	0.9158867597579956	System of interest, what is the appropriate form for the generative model reflecting the discrete or continuous distinction that we looked at?
443438	453016	A	0.5788314342498779	And also all these other questions that aren't exactly within the textbook, like temporal depth, hierarchical nesting, which parameters are learned versus fixed?
453128	462960	A	0.8568227291107178	All these different directions that the models actually have to be elaborated on even before getting to the data engineering and maybe even code implementation.
463300	467890	A	0.8916473984718323	Just from a structural perspective, what form is it?
469460	476420	A	0.9064656496047974	How to set up the generative model is where some of those analytical details begin being introduced.
477240	486680	A	0.8312665224075317	Not necessarily even the program level implementation or an executable simulation, but like, okay, we have a preference vector.
487740	489770	A	0.8187971711158752	Is there two states?
490380	493300	A	0.8990852236747742	Is there some continuous preference distribution?
493380	498350	A	0.8860427737236023	Whatever it is, what is the actual details of the generative model?
499440	505070	A	0.8606957197189331	And then the other side of the coinblanket is the generative process.
505520	514850	A	0.9042797684669495	So what are the endogenous dynamics and the causal mapping with action for the generative process?
516340	524020	A	0.873067319393158	And there's kind of cases where you have more of a communication setting, active inference entities on both sides.
524440	534456	A	0.7703187465667725	You could also have more of like a simple, simple partnering, like two deterministic programs that send messages to each other.
534478	548750	A	0.8600110411643982	Or it could be like one more cognitive, more agent like generative model and one more environmental nonliving type.
551280	552616	A	0.827003538608551	Any thoughts or overviews?
552648	558944	A	0.8455058932304382	Or how would people think about how can we make this type of a recipe design?
559062	561440	A	0.8735448718070984	Should we be all designing a model?
561590	570312	A	0.5465903282165527	Or how do we even go about reading a section of the book in a chapter that begins with a recipe provision?
570476	578496	E	0.7646607756614685	Lyle yeah, I spent a lot of time building what I think would be classed here as generative models.
578528	596428	E	0.7347739338874817	And what I find is that I characterize it as the step of framing up is often far trickier, sometimes much harder, frankly, than building a model, depending on what the situation is.
596594	606750	E	0.7767990827560425	And in my experience, I find that it all comes down to making sure we understand what is the question that we're trying to answer.
607520	617760	E	0.7302829027175903	It's sort of like because every modeling process I'm sure everybody on this call knows is a process of deciding what to leave out, right?
617830	622180	E	0.7316312789916992	What to put in, what to leave out, and what level of representation.
622520	637076	E	0.8489837646484375	Then everything that's in there, if it's going to be a good model, has to be necessary and necessary to answer a question or provide a particular insight or so forth.
637108	648252	E	0.7819024920463562	So that whole issue of framing out what you're going to build in all those different the 10,000 questions, there's more than four.
648386	650030	E	0.7281829714775085	Ultimately it's many.
650400	655260	E	0.6611945033073425	Then it's all about that, which often means understanding the audience.
655920	660812	E	0.4999534487724304	If the model builder is the only audience, this is much simpler.
660956	684968	E	0.7657550573348999	If the audience is some much larger group with different perspectives, a lack of homogeneity and insight, then there almost has to be, I'm going to say almost a pre modeling or framing process of sort of framing up.
685054	686808	E	0.7871636152267456	What are the questions we care about?
686894	696940	E	0.8864080905914307	And then we can talk about how those translate into a model that's just some general framing.
698240	698716	A	0.8529649972915649	Thank you.
698738	700924	A	0.959330141544342	That's very interesting.
701122	705324	A	0.8646644353866577	It makes me think about this audience question for the model.
705362	706492	A	0.5067418217658997	Like, why are we building the model?
706546	710530	A	0.5894126296043396	Why are we shaping our regime of attention to build this model?
711060	714096	A	0.7839200496673584	Model building can be an end of itself.
714198	718208	A	0.938802182674408	It can be creative and expressive and fun and all these other things.
718374	722304	A	0.7099387049674988	And maybe later there's a road that has some Pragmatic value too.
722342	724004	A	0.8645908236503601	But also it can just be like fun.
724042	727732	A	0.8692617416381836	Like, what would a generative model that could do this look like?
727866	745732	A	0.7074767351150513	And that can be very didactic there's other times where you're presenting information, oh, I made a simulation of Twitter discourse and dot dot, dot is always going to be presented in a way that's not only just like, the model distilling down from the world, but then you're communicating it.
745806	761084	A	0.6097431182861328	And then when you're actually not just communicating, but if you're making an application that does something and communication is doing something as well, then the system of interest, as Lyle mentioned, is totally nontrivial.
761132	769010	A	0.653423547744751	And there's the whole framing in some of these early stages, especially because they can't always be changed easily later.
770900	773430	A	0.7584234476089478	Rowan and then anyone else.
776440	789160	D	0.8102884292602539	Yeah, so I'm just curious, when you say who's the audience, isn't this part of the active inference model itself?
789230	795530	D	0.6960813403129578	That okay, so whatever makes sense in that framework, wouldn't that be the audience here?
798780	800184	D	0.7308594584465027	It has to survive, right?
800222	801524	D	0.749814510345459	Your agent has to survive.
801572	811120	D	0.7121869921684265	So whatever generative model helps it survive, would that not be the it's model of choice over here?
811270	812380	D	0.7549254894256592	And I'm just curious.
812460	824096	A	0.50954669713974	I'm not sure it's an awesome way to frame it, and maybe someone can share the free energy governance link in the chat.
824128	825684	A	0.7420899271965027	I just can't look it up right now.
825802	836280	A	0.9363464713096619	But it puts this very nicely in a recent pretty short book dissertation about that imperative for organizations.
836700	845690	A	0.7251490950584412	And yes, in one sense it can be said the right generative model or like the audience for it is whatever its survivability conditions are.
846560	851470	A	0.6912776231765747	And within our textbook group, the survivability conditions are open.
852880	870690	A	0.8264269828796387	However, we're also learning about or even just gesturing towards like, okay, not just we're going to imagine a room with a person who can take on a jacket or take it off.
872180	874340	A	0.8127149343490601	We can make that a didactic model.
874410	889640	A	0.8672707676887512	And the audience could be this textbook group or future cohorts of the textbook group, and the function could be just sort of like a neutral exemplar active inference generative model.
889790	905340	A	0.8443399667739868	But then, of course, the considerations for information presentation, empirical data analysis, any kind of application, the system of interest is not just the one person with the jacket on or off two states room with a sign fluctuation.
906160	908944	A	0.8373839855194092	So that's a different situation for model building.
909062	912320	A	0.8637683987617493	So how should we interpret this recipe?
915300	927316	D	0.6878919005393982	Okay, but is there not like, a general framework for what a good generative model looks like is what I'm saying.
927498	930064	D	0.7652110457420349	I guess you could frame that differently.
930112	945016	D	0.5443225502967834	So if you want to build pixel level representations, for example, you can use a gan, and that's a pretty decent one, but maybe pixel level representations are not good for the task at hand or something like that.
945038	948952	D	0.7969905734062195	So it should fit a general category.
949016	949244	A	0.7360090017318726	Right?
949282	953640	D	0.7297905683517456	So this is what a good set of models looks like for active inference.
953720	955790	D	0.7778441905975342	So that's sort of getting at.
957360	959516	A	0.921707272529602	Yeah, that's a very fascinating framing.
959548	962210	A	0.908083975315094	Does anyone want to add something to that?
967500	977230	A	0.8718590140342712	I totally hear you on is there a rubric like, what are we evaluating the generative model and process fit?
977600	982956	A	0.6257150173187256	Because it's not like there's just simply a best generative model bigger or whatever.
983058	987150	A	0.787300169467926	No feature about it except outside of a generative process.
988100	992016	A	0.7928418517112732	Context is the fitness and then what?
992038	992716	A	0.8645477294921875	Is there a rubric?
992748	993776	A	0.7447549104690552	Is there a gold standard?
993878	999664	A	0.7606921792030334	Is it like, oh, you're dealing with audio data here's, the file format, that level of standardization?
999792	1000870	A	0.5190236568450928	Certainly not.
1001480	1013240	A	0.8888933062553406	However, are there some practices or lenses that we could bring in from people's experience with evaluating model adequacy and relevancy?
1013820	1015496	A	0.6956946849822998	There probably are.
1015678	1021320	E	0.6905602216720581	Lyle well, yeah, that really comes right back to purpose, right.
1021390	1024380	E	0.5202307105064392	So a model is always fit for purpose.
1027200	1031468	E	0.8203077912330627	Of course, this also surfaces the questions of model validation, right.
1031554	1035230	E	0.49533456563949585	One of the things we haven't talked about here is what's the right model?
1036080	1037692	E	0.8566745519638062	How do we frame up the right model?
1037746	1040080	E	0.8170093297958374	What do we choose to put in what we leave out?
1040230	1042332	E	0.7935014963150024	Part of that is purpose.
1042396	1047408	E	0.823422908782959	And how would I evaluate if I do what I'm imagining a model will be?
1047494	1050992	E	0.7704488039016724	How do I evaluate its quality, its validity?
1051136	1053300	E	0.7669288516044617	Well, what data is actually available?
1053450	1058004	E	0.7968820333480835	That's one thing you always have to ask at the outset what data is available?
1058122	1059604	E	0.8565182685852051	What data can I use?
1059722	1063028	E	0.6998070478439331	What's computationally adequate?
1063204	1075464	E	0.8791906833648682	And what parts of this then when we kind of project, when we apply this model, if that's its role, then does it fit for the purpose?
1075512	1082830	E	0.5783478617668152	Does it provide good, adequate results and improve whatever behavior we're trying to address?
1086000	1089596	E	0.4991931915283203	You can't say if it's good if you don't have a purpose.
1089708	1101332	E	0.8785637021064758	So if your purpose is just to explore model building, which is something I love to do, then that's a pretty big there's a lot of things that are fit for that purpose, right?
1101466	1116010	E	0.8194735050201416	But if the purpose is to do a prospective analysis of a system and what actions might be taken to intervene, then that's in a different thing.
1119260	1120824	A	0.9743577241897583	Thanks a lot for sharing it.
1120942	1122920	A	0.9838526248931885	I'm really happy.
1122990	1135972	A	0.5404602885246277	And I think it's relevant that we're having this kind of a discussion because we've gone through some of the first chapters and we'll continue through chapter six, I think, in having this conversation.
1136136	1156660	A	0.8327178359031677	But does anybody else want to add something about this more general topic of, like, how are we even coming to talk about what system, or how are we framing the system that we're modeling that's in Section 6.3?
1161110	1163038	C	0.791813313961029	This is too broad.
1163214	1165254	C	0.6587896347045898	It's not active inference specific.
1165372	1172402	C	0.8483619689941406	But whenever I'm trying to model something, the only questions that I mean, it is contextual to the purpose.
1172466	1174770	C	0.8085936903953552	It entails a purpose in an audience.
1174850	1184620	C	0.8377053737640381	But all I want to know basically is what are the questions that this model needs to generate an answer for?
1186830	1199360	C	0.872177004814148	What is the information that is necessarily, therefore kind of required to model a system that would have such answers in it?
1202390	1219190	C	0.8621432185173035	And maybe another way to say the same thing is like, what affordances would the model require to answer, address whatever, some set of questions that are posed to system?
1219260	1248160	C	0.7156524658203125	So if you asked, I don't know, how frequently does a yellow colored car, I don't know drive down this particular road, then I wouldn't need to record the number of bikes or their colors that are using the bike lane or buses or trucks large.
1249330	1254030	C	0.6437128186225891	This is maybe outside the scope of what I mean by yellow.
1254190	1267122	C	0.5646290183067322	How many cars out of all the cars, how many are yellow or something driving down this road or whatever, like not even exactly a generative model.
1267176	1274120	C	0.4814956784248352	But my my point is that modeling that system there, there is obvious data that's completely irrelevant, right?
1274490	1290240	C	0.7181716561317444	And so if you were going to build some sort of simulation of any kind that's going to be generative like there's often a lot of data that's just completely extraneous depending on what questions you're going to ask of it.
1294290	1295040	A	0.6283750534057617	Thanks.
1295970	1306610	A	0.869132936000824	In 63 in the first paragraphs they're going to come out hard on the interface concept of Markov blanket.
1307190	1315080	A	0.7825111746788025	This is how you'll do system modeling is by finding interfaces that distinguish the internal and external states of a system.
1316010	1333734	A	0.711129367351532	Then that is critiqued or elaborated because there's in infinite degrees of freedom in the course gradings and those are modeler specific and they suggest that that matters.
1333782	1346720	A	0.7314959168434143	Especially if you want to be considering embodied extended perspectives where just descriptive interfacing models won't give you the whole answer.
1347410	1366150	A	0.49308937788009644	There's a great paper could a neuroscientist understand a microprocessor showing that even if you have total access to the microprocessors firing like an EEG and a generated set of single and double lesions, a lot of the interpretations would be strongly misleading.
1367290	1373266	A	0.6403050422668457	Yet people want the wiring circuit of the brain which is dynamic and also involves diffusive molecules.
1373458	1383100	A	0.5397306680679321	We have all 302 nematode neurons mapped but that also as an interface diagram is not even close.
1383710	1388910	A	0.737934947013855	So if you want to describe the nematode like model building then it's a fit for purpose.
1389250	1399230	A	0.589290976524353	However, there might be very simple models that could be doing a lot better in nematode behavior observation.
1401750	1404286	A	0.840133011341095	The form is discussed.
1404398	1406670	A	0.8408375382423401	There are three main design choices.
1406830	1409026	A	0.7555333375930786	First, discrete and continuous time.
1409128	1420040	A	0.9495195150375366	We had some awesome discussions in the previous months about similarities and differences and where in theory they're different and then in practice where they're different.
1420490	1424070	A	0.7616048455238342	The whole question of discretizing continuous systems.
1425050	1432970	A	0.855073869228363	The second choice is between shallow models and hierarchical models where inference operates at multiple timescales.
1433790	1442990	A	0.8710184693336487	The third choice is the consideration only of the present kind of the variational free energy versus models with temporal depth.
1443410	1463230	A	0.8584623336791992	Temporal depth consideration could be purely passive and it could also include some element of affordance which if we remember to like the B matrix actions are influencing how states of the world are changing through time.
1463400	1467670	A	0.7743101716041565	So that is how active inference is unifying.
1468250	1477210	A	0.8651571869850159	Policy comparison by kind of embedding action into estimates of how things could evolve probabilistically.
1478910	1487162	A	0.7813843488693237	Those three design decisions are explored in slightly more detail in the subsections 65.
1487216	1492270	A	0.8619362115859985	How to set up the generative model after specification.
1492930	1496830	A	0.7851534485816956	Then the specific variables have to be included.
1497570	1501322	A	0.871218740940094	Okay, the latent state temperature is going to be continuous.
1501466	1506094	A	0.8863228559494019	The observations in my thermometer I'm going to take in as just integers.
1506222	1516618	A	0.8250846862792969	And then there's going to be a person who is going to be in a binary state of like whether it's hot or cold, or maybe I want hot, neutral and cold.
1516654	1539150	A	0.8642374277114868	Or maybe I want them to have a ten point scale or I want them to have a scale that's doing dot, dot, dot that is in this stage of actually setting up the generative model and giving a little bit of color to what had been just outlined.
1539490	1543066	A	0.8601478338241577	It's going to be a nested model with this continuous variable.
1543098	1544910	A	0.764238715171814	And this kind of a discrete variable.
1547970	1557890	A	0.8583370447158813	Here we return to the frog example from earlier in the book where there's like but it's kind of being generalized a little bit.
1558040	1561902	A	0.9051894545555115	It was introduced with the whole Bayesian equation walkthrough.
1562046	1583500	A	0.8690586090087891	Now we're returning to it and thinking more about multimodal or like even you could consider this as sensor fusion because there's some hidden cause, the jumping or the action of a frog that is inducing several domains of impact potentially in the generative process.
1584110	1591710	A	0.8883090615272522	And then that leads to specific observables from the perspective of the cognitive entity.
1592850	1604958	A	0.7085899114608765	Those could be again, two communicative cognitive entities or one and not or however so this is like, okay, we're going to be modeling forest fires.
1605134	1614180	A	0.7713127732276917	So forest fires, they change the temperature, they change the chemical composition, they change the vibrations in the ground or something.
1615190	1618870	A	0.8585702180862427	Okay, and then maybe there's three sensors, maybe you have three thermometers.
1619210	1620374	A	0.7092551589012146	And then what about them?
1620412	1621798	A	0.8421626687049866	Are you going to average them?
1621964	1625510	A	0.911540150642395	Are they going to be like three parallel modeled time series?
1626030	1631660	A	0.8951444625854492	That is where some more specification of the generative model comes into play.
1632750	1637420	A	0.8118258118629456	Keeping the active inference ontology in mind.
1637970	1639706	A	0.8812665343284607	What are the affordances of the frog?
1639818	1649822	A	0.9119386672973633	What are the latent states that are being changing through time like sound, physical presence or photon emission or something?
1649956	1651378	A	0.7331176400184631	And then what are the data?
1651464	1653410	A	0.8469669222831726	That would be the O, the observations.
1656710	1660814	A	0.8294777274131775	This box looks like it's about different sensory modalities.
1660862	1665720	A	0.9389620423316956	I'm sure there's a lot of interesting discussions we could bring in here.
1672870	1677890	A	0.8431020975112915	Priors and empirical behavior complete class theorems.
1678730	1685430	A	0.8208498954772949	Any statistical decision procedure behavior may be framed as Bayes optimal under the right set of prior beliefs.
1691010	1700530	A	0.8383403420448303	Discussion of fixed and learned variables one can imagine the pros and the cons generally of having fixed and learned variables.
1701030	1706430	A	0.6158556342124939	Like computationally it's simpler to fix hard code a variable.
1706590	1714630	A	0.7734575867652893	However, if there's a setting where the model's adequacy depends on being able to update that, maybe you want it learnable.
1714970	1724742	A	0.7749255895614624	However, then you have to deal with these questions about the kinetics of learning like instantly switch or slow switch or trend averaging.
1724886	1731342	A	0.8418142199516296	So there's a lot of discussions around learning how is attention regulated, what is precision on learning?
1731396	1741550	A	0.6632988452911377	It's like it very much complexifies the model and there's many variables that you can bring into a learnable setting.
1742610	1750082	A	0.7431577444076538	But when it's framed as just static variables and only like the hidden states changing through time.
1750216	1752020	A	0.7165740132331848	That's like the simplest case.
1753270	1766280	A	0.8424648642539978	But more and more cognitive entities probably are going to entail considering learning dynamics, setting up the generative process.
1768810	1789440	A	0.6213153600692749	The reason we postponed the design of the generative process so little slate of hands entity first, not the niche first is that in many practical applications discussed in this book, we simply assume the dynamics of the generative process are the same or very similar to the generative model.
1790050	1795170	A	0.8663233518600464	We generally assume the agent's generative model closely mimics the process that generates its observation.
1797110	1813666	A	0.5490351319313049	That is clearly a simplifying case because it doesn't address what if you're paying attention to predicting width and the world is dependent on height.
1813858	1818654	A	0.7543909549713135	There's so many complexities of that which is really that broader.
1818722	1832970	A	0.8014236688613892	Like what is being modeled, what matters question but in some way very upstream or very close to the stream, it is like the rabbit being put in the hat.
1833310	1844980	A	0.6828473806381226	Like if the rat knows that there's a five x five maze, that's a huge amount of information versus if it only has access to pure local information.
1846070	1851650	A	0.8197847604751587	And that's just something to, I think, for us to note as we look through models.
1852150	1854642	A	0.8797557950019836	Like are we modeling the generative process?
1854776	1857086	A	0.7437590956687927	Oh, so the seasons oscillate.
1857118	1858710	A	0.8281470537185669	So it is a sine wave.
1859130	1863350	A	0.866660475730896	So then the generative model of the agent is also going to be fitting a sine wave.
1863690	1873980	A	0.7705652713775635	Well, then it kind of collapses to like a stochastic regression and maybe then it looks like the fit is going to be very good.
1876190	1891950	A	0.6481935977935791	Active inference modeling brings in another complexity with action influencing outcomes that prevents some, I guess, fallacies of modeling, but by no means and probably introduces many others.
1892020	1892830	A	0.7154882550239563	Eric?
1894290	1894990	F	0.5491447448730469	Yeah.
1895140	1896030	F	0.8097810745239258	Can you hear me?
1896100	1898370	A	0.9707255959510803	This is a new sounds good.
1898520	1907798	F	0.48938071727752686	So this might be a time to discuss the question I posted and I apologize I didn't put it in the right place the other day.
1907964	1911122	F	0.8783986568450928	I just figured out today that it goes under this particular location.
1911186	1922022	F	0.7674898505210876	But this is about the question about why modeling of a generative process is necessary, is a necessary step for building an active inference model.
1922076	1925580	F	0.594611406326294	So let me just read it because it's a lot of words.
1926110	1938666	F	0.8673427104949951	So we know that an active inference agent employs a generative model as its model of the external world and it uses this generative model to perform inferences about perceptual input and to make decisions about actions.
1938778	1946254	F	0.7128430008888245	So in general, the external world is complex and unknowable to the agent.
1946452	1949202	F	0.5395956635475159	The generative model may or may not be able to learn.
1949256	1958166	F	0.6402900815010071	But if it is learning is supposed to put the generative model in a better alignment with the world's generative process, whatever that may be.
1958268	1971930	F	0.8575406670570374	So I can see how one might model the generative process if one is building an artificial agent in a laboratory where you kind of have access, you control how the world behaves with respect to the agent.
1972080	1979574	F	0.8357374668121338	And then you might want to study how well the agent design works versus one versus another under control conditions.
1979702	1987118	F	0.5470123291015625	But this is not the same as designing an agent to go out and cope with some real world environment where you really don't know what the generative process is.
1987204	2002930	F	0.6234123706817627	So I think that the recipe for designing an active inference models would include formally setting up the generative process only in the kind of the laboratory situation, but not if you're really trying to build something out for the real world because you don't know the generative process.
2003080	2013446	F	0.7756871581077576	You might create an artificial laboratory kind of situation by trying to build a model of how the world works and say, well, how does my agent work under those assumptions or not?
2013548	2017622	F	0.7694159150123596	But that might set you up for putting the agent in the real world.
2017676	2023900	F	0.5507281422615051	But in fact, you don't know the generative process if you're really trying to build something to work in the real world.
2024590	2026250	F	0.807338297367096	That's my comment, my question.
2026320	2027260	F	0.7211036682128906	That's your question.
2031730	2033230	A	0.9147727489471436	Thank you, Lyle.
2034370	2040142	E	0.8702155351638794	Well, Eric, I love that framing because I think there's multiple different cases, right?
2040196	2063910	E	0.4985634982585907	So I think if you're modeling something that, as you say, goes in the real world, then perhaps it's some sentient creature or being, then obviously the real world, even if we knew everything about it, is too complex to model.
2063980	2064598	E	0.5664746165275574	Right.
2064764	2069980	E	0.6911842823028564	So that's fool's gold to assume you know everything, right?
2073150	2075146	E	0.6925075054168701	I'm just going to say, yeah, that's hard.
2075328	2088586	E	0.8863290548324585	Typically, I guess we would say what are the parts of the generative, the real world, the generative process that we're going to consider relevant and deal with that and knowing that we're making a leap of faith.
2088698	2099620	E	0.7110820412635803	But there's another case, I think, which is more generalizable, just complex adaptive systems that operate in what I call the built world.
2100150	2105694	E	0.802760124206543	So I work with a bunch of people who build digital twins.
2105822	2114454	E	0.787458062171936	They build digital twins of human infrastructure, so buildings and all this stuff there.
2114492	2123690	E	0.7847036719322205	The generative process that we're concerned with is largely knowable and largely representable.
2126430	2145086	E	0.5282555222511292	What's interesting about that is there are a bunch of blind spots and inadequacies in what we know about that generative process and the ability to do inference about what the real state of that system is then becomes the value of this approach in that setting.
2145198	2145860	A	0.5664746165275574	Right.
2148230	2150050	E	0.6368409991264343	I don't think there's a general answer.
2150120	2154914	E	0.8732460737228394	Once again, I think it really comes down to purpose and what the specific framing you're looking to do?
2155032	2161046	E	0.6242256760597229	To me, this ability to say something about what I I like that idea of decision agents, right.
2161148	2174842	E	0.5101120471954346	Decision agents that are going to potentially take action or infer actual states is much richer than what a lot of the historical modeling paradigms have given us.
2174976	2177340	E	0.9818863868713379	So I think that's really interesting.
2178590	2179574	A	0.9147727489471436	Thank you, Lyle.
2179622	2180410	A	0.6077883839607239	Ali.
2188450	2202686	G	0.6826476454734802	Also think that the distinction between generative process and generative models become significant if we want to simulate learning rather than just inference.
2202878	2209960	G	0.8224905133247375	I mean, that's the answer I got from Ryan Smith because I asked him almost the same question.
2210410	2216040	G	0.6565595865249634	Why do we need generative process in order to simulate the agents?
2217290	2233200	G	0.8097115159034729	Because, you see, for the generative process, if the generative model exactly maps them to generative process, we only need that capital D matrix, right?
2233970	2240318	G	0.7182384729385376	And that's just when we're just trying to simulate the inference side of the agent, right?
2240404	2255860	G	0.8844220042228699	But when the learning comes along, then we need to separate that capital D from another matrix, probably dill case D, which maps into the generator process.
2256170	2271820	G	0.8340781927108765	So yeah, one of the situations that the distinction between two might be necessary is when those two process, I mean learning and inference, are taken as two separate phenomena to model.
2273550	2274300	A	0.6283750534057617	Thanks.
2275630	2288814	A	0.7609224319458008	One note is also there's work on symmetries in the generative process, generative model, like, I think like the bi directional paper with Matt Sims and Blue discussing it.
2288932	2296500	A	0.5793130993843079	And then here will be a defense to Eric's excellent question.
2299350	2323510	A	0.8406399488449097	The entity first modeling approach that's taken by this chapter, one can say, I don't know whether I'm going to a forest or a desert, but I'm going to have these sensors on my designed interface and I'm going to do extensive modeling on interoception and homeostasis.
2323670	2329530	A	0.5216240286827087	And if I can learn policies that balance homeostasis, then I've survived.
2330110	2333660	A	0.889976441860199	If I fail, then failure happens.
2334030	2338970	A	0.5035238265991211	So that doesn't mean that it works or it's doing the right thing, fit for purpose, any of those aspects.
2339130	2354930	A	0.8376359939575195	But one of the insights from the four E and the embodied side is like a vast amount of our what is modelable as cognitive isn't necessarily the declarative.
2355350	2363746	A	0.8149434328079224	I think, therefore I am possibly even symbolic type thinking linguistic.
2363938	2380620	A	0.5188895463943481	There's a lot going on and many of that a lot going on can be simplified by not even knowing about the external process, maybe not even the as modeled kidney knowing about what the as modeled liver is doing.
2381730	2404480	A	0.8940136432647705	So this type of a focus where it's like we're going to define our entity types and the kinds of observations that they can make, the kinds of affordances that they have or do empirically or that they conceptually could do.
2406450	2416142	A	0.627683162689209	That approach is consistent with embodied biological systems and persistence of organizations.
2416206	2433980	A	0.7942627668380737	And so I'm wondering how that piece comes into play with this discussion that's very important about and also their earlier discussion of the embedded and extended cognition is that it kind of blurs the line with what is a generative model, what is a generative process.
2434510	2444620	A	0.8608930110931396	So hence there being a lot of thinking and attention on what the system's modeling is.
2445810	2448880	A	0.7460434436798096	What are the known unknowns and the unknown unknowns going to be.
2449410	2453550	A	0.8280759453773499	Let's just see how the chapter ends.
2457860	2462736	A	0.856805145740509	Six, seven simulating, visualizing, analyzing, and fitting data using active inference.
2462928	2469190	A	0.5738274455070496	So standard routines for active inference that provide support for all functions are available.
2470040	2478216	A	0.881313145160675	Hashtag SPM and Appendix C step by Step model is a great look through this.
2478318	2486588	A	0.9697932600975037	This is MATLAB code one amazing work that we could all iterate on.
2486754	2497660	A	0.8755080699920654	Would be porting MATLAB into the ontology into Python and or Julia with Pi MDP or active blockference.
2498080	2506144	A	0.7989679574966431	But there's a lot in SPM and some of it's neuroimaging specific, some of it's very variational base specific.
2506342	2511670	A	0.7014867663383484	Not all of it is going to be state of the art or the most useful in every situation.
2512040	2529284	A	0.681439995765686	However, I wonder if only offering certain routines in MATLAB, which is like a traditionally very academic software platform and potentially non free, can be a limiting factor.
2529412	2547396	A	0.5794116854667664	So those who feel like they want to learn more or contribute this way helping structure some of the code architecture so that cohorts coming through can be doing multiple language.
2547448	2556480	A	0.8515636324882507	Maybe first we can just move some of these routines into a folder and then people can start to organize those types of aspects.
2558180	2561360	A	0.8698879480361938	Summary it's a four step recipe.
2561700	2581384	A	0.886044979095459	We walk through it from the consideration of the system of interest broadly, like the entity and the process, focusing in on the entity specifically thinking structurally about what it is going to be like doing composed of specifying that to a few levels of detail, then doing the same for the generative process.
2581582	2600800	A	0.7233093976974487	And then once that is specified, it's not quite, quite there for most people today, but where it seems like they are laying out a path towards and where we probably can and will be after that level of setup.
2601700	2606480	A	0.8752059936523438	In some potentially graphical editor or parameter file.
2607060	2620020	A	0.7891785502433777	Then, as SPM and MATLAB have done in many, many papers, the generative model specification almost prepares the working script.
2620440	2629896	A	0.7429735660552979	But there's still a lot of details and pieces to add in, especially in a modern environment and for all of these non standard and novel cases that people are wanting to consider.
2630078	2641692	A	0.8758201599121094	But that is once we have a notebook that goes through the recipe, then the recipes can be forked and so on and they can be written in different languages, pi MDP, block for instance.
2641826	2642700	A	0.6077883839607239	Ali.
2645200	2655484	G	0.6055021286010742	Yeah, just one thing that I think is not made explicit in this chapter is that actually that first step, which system are we modeling?
2655532	2681290	G	0.6218737363815308	Especially the identification of the markup blanket part is basically at this point of active inference research is more like a hypothetical step because I also had the misapprehension that we can somehow identify the markup blankets from data.
2681660	2708540	G	0.6723318099975586	But then as I went on through my project and by consulting Maxwell and others actually this is the comment Maxwell made about my proposal that he said that identifying markup blanket from data is still an outstanding issue that is not resolved yet in the research on active inference.
2708620	2720048	G	0.9133774042129517	And one of the most active areas, areas of research they're doing at Versus Lab is just focused on this part of the modeling recipe.
2720144	2730330	G	0.8484999537467957	I mean how we can identify, automatically identify or somehow learn the markup blanket from just pure data points.
2731660	2732408	A	0.9184247851371765	Awesome.
2732574	2741740	A	0.9009526371955872	And that ties in with Dalton s's work on the blanket index and like continuous variables for dynamic assemblies of blanketing.
2743440	2763488	A	0.5934792757034302	This is going to get really nuanced and empirical with the discovery and the thresholding of Markov blankets and causal inference in real world systems with many different kinds of sensors and doing structure learning on generative model and process and like everything empirically.
2763664	2776730	A	0.50318843126297	Which is why, as a simplifying step, it actually really reminds me of how Dave Snowden situates the difference between systems thinking and complexity thinking.
2777100	2796940	A	0.7990608811378479	Which is systems often uses, like, a lot of nodes and flowcharts to represent system elements and relationships and interfaces, whereas in complexity and the Knevin especially framing, it's more like self organizing sand dunes.
2797540	2818180	A	0.7546941637992859	And so causal relationships might be very much in flux and it puts a higher focus on action rather than system description, especially in situations like moving your head where the relationship of different things is going to be heavily action dependent.
2819880	2833944	A	0.8055399060249329	And so for now, we're kind of in the systems world where it's like a priori, here are the system interfaces and then we're going to take whether it's a heuristic or whether you take a literal interpretation, but you don't have to.
2834142	2840780	A	0.8691151142120361	You could just say I'm taking heuristically the approach of the system's mapping.
2841760	2858370	A	0.6065067648887634	But that's not to say that that generative model couldn't be trained in a systems mapped context and then placed into a different setting where there was a mismatch or a different generative model.
2859960	2862820	A	0.8507046699523926	And so it's going to be an ongoing discussion.
2863720	2865248	A	0.777845025062561	When are these lines drawn?
2865344	2884120	A	0.7560833692550659	One other point, other than not needing to use last names to refer to specific concepts, like are we talking about the blanket that statistically insulates every partition of nodes in these Bayes graphs, which are going to be vast?
2884880	2896860	A	0.706551194190979	As Ali and Yaakov and I were discussing on the branching time active inference from just a few days ago yesterday, these graphs are going to be vast.
2897600	2900476	A	0.8733734488487244	And so just saying there will be a Markov blanket.
2900508	2905890	A	0.8893786668777466	In fact, there will be many Markov blankets with different semantics that you might assign to them or not.
2907940	2910132	A	0.8253311514854431	How does that map onto the real world?
2910186	2917990	A	0.8129484057426453	Is like the realism, instrumentalism, pragmatism abduction conversation that we've been having?
2918360	2931684	A	0.8412852883338928	Do you come in with these kinds of boundaries, heuristically and distinctions or how many levels of uncertainty and nesting?
2931812	2935050	A	0.491811066865921	I don't know how many categories of blank there are.
2935420	2938990	A	0.5683912634849548	I don't know if it's a category or a continuum of this.
2940000	2957308	A	0.8634600639343262	You can actually still take on multiple levels of uncertainty in the modeling, but then fitting it with empirical data, if it's fit for purpose use is to do some sort of statistical inference or like provide meaning or action, but just didactically.
2957484	2967168	A	0.8210650086402893	When the model's purpose is educational, then there's a lot of things and architectures we might play with and then the recipe.
2967264	2994584	A	0.9527086019515991	And also this conversation helps, I hope, hold space for the educational and the curiosity driven model development where we're going to have a lot of fun and interesting GMs and people's applications and working with different real world constraints and different settings.
2994632	3003200	A	0.9276188015937805	We'll all be learning a lot from it, and hopefully some of it will be in repos we can reference.
3004660	3025560	A	0.647920548915863	Other people may want to play around and version within folders that we can make if anybody wants to be added as a collaborator in this textbook repo, which is just pretty much empty except for, I guess, a script from Yaakup.
3028060	3032452	A	0.8373417854309082	And there'll be more to say on probably GitHub.
3032516	3035704	A	0.7833918929100037	And as we continue through.
3035742	3042700	A	0.904367208480835	But in these last minutes, does anyone have any thoughts for our continuation of the cohort?
3046720	3048216	E	0.6762973666191101	I have one question.
3048338	3058800	E	0.8800416588783264	Daniel, you referenced a paper earlier in the discussion that I'd love to get the reference to about persistence of organizations and survivability.
3059540	3060530	A	0.6818090081214905	Oh, yes.
3068040	3068950	A	0.4896698594093323	All right.
3069560	3074520	A	0.7354522347450256	I will put it into resources.
3079180	3080410	A	0.6653574705123901	Here's the work.
3084300	3090236	A	0.6974138021469116	It's a PhD dissertation that was published as a book, and I'll upload the PDF as well.
3090418	3094510	A	0.9795698523521423	This is extremely interesting work.
3103320	3113190	A	0.9691672921180725	Yeah, it just came out and and okay, in our last minutes, it's it's too, too fun not to share.
3116920	3121480	A	0.8869789838790894	So Karl Friston has written a foreword.
3124620	3126224	A	0.795606255531311	What is a firm's purpose?
3126292	3128248	A	0.7907456159591675	What is an organization's purpose?
3128424	3130828	A	0.7505587339401245	It's as difficult to answer as why am I here?
3130914	3134780	A	0.6688428521156311	Free energy, governance and the FEP.
3135440	3140716	A	0.6157491207122803	Inverts the question, instead of asking how must the system behave to survive?
3140748	3143120	A	0.7806712985038757	It asks, how do systems that survive behave?
3143700	3145244	A	0.5065346360206604	The answer is rather deflationary.
3145292	3146012	A	0.5220295190811157	They survive.
3146076	3148000	A	0.7090265154838562	Their purpose is just sustainability.
3148820	3158870	A	0.9637055993080139	So some classic Fristinisms, some very nice framings on page 95.
3160360	3164900	A	0.8962255120277405	There's some great juxtapositions.
3166300	3172490	A	0.9851459264755249	So it's always awesome to see this kind of quality work.
3173340	3177804	A	0.6689305305480957	And who knows what people here will see?
3177922	3182408	A	0.5038710832595825	And I don't see any scripts here, thus the textbook.
3182584	3185100	A	0.6999115347862244	But who knows?
3186160	3203600	A	0.7911997437477112	Maybe we can do some generative modeling of organizations or we can specify it and iterate on it, realize it in block, for instance, and Pymdp and for any lab and JF's symbolic suite.
3206040	3209380	A	0.9730970859527588	So there'll be a lot of fun things to explore this cohort.
3214050	3217680	A	0.8875519633293152	Any other questions or ideas that people want to share?
3220650	3221062	A	0.6283750534057617	Thanks.
3221116	3225110	A	0.9516313076019287	And congratulations to people for joining this continuation.
3225530	3228310	A	0.894939124584198	It's a great continuance.
3229530	3236400	A	0.9738335609436035	And and I know that this part is going to be very interesting.
3236930	3238300	A	0.9617454409599304	The next three months will be interesting.
