start	end	paragNum	speaker	confidence	startTime	wordCount	text
650	20080	1	A	0.18178	00:00	29	It's. Okay, we began. Welcome everyone. It is the resumption of our cohort update the video description. It's the resumption of cohort one of the active inference textbook group.
20450	25640	2	A	0.73708	00:20	18	It's our 14. Okay, could someone mute Gsuppie or feel free to say whatever you want to say.
27930	60240	3	B	0.99999	00:27	62	Can you hear me? Yes. Okay, so sorry, but I'm completely new to this interface of a gather and encoder, so I'm not sure I understand cohort one and cohort two here because cohort one, wasn't it the previous one like the one that start last year? Well, it's still going on from May till July. We did chapters one through five.
61010	91686	4	A	0.98	01:01	94	Now we are in this cohort. So if those who did not participate in this part, thanks for the question, but everyone in general, respectfully, let's try to have people who are in the cohort participate in it. Everyone's welcome to join and of course rewatch, but contributions and the questions and the chat are probably best so that we can respect the people who are continuing on. This is our 14th meeting and now we're heading into the second five chapters of the book. Okay, does any other person want to give context?
91798	92940	5	A	0.58	01:31	4	Oh, yeah, go ahead.
96430	123410	6	B	0.97	01:36	82	The current one that is going on right now is the cohort one and not cohort two. We are all learning in different stages. So the previous hour was the cohort that is focusing on chapters one through five stage they're in. And now some of us, a different set of people, some are joining both. So that's why we made the meetings convenient, was so that we could like for many of us who want to do both, we can join.
124550	139642	7	A	0.99865	02:04	30	But this is a separate set of people. I see. Yes. Okay, so cohort two was first and then this meeting. In this meeting right now, cohort two was first.
139696	153482	8	A	0.70241	02:19	29	Yes. And now is cohort one, which started correct. We warmed up with chapters one through five. Okay, so I will leave because I subscribe for cohort two. Excellent.
153546	163326	9	B	0.99	02:33	20	Okay, good. Thank you so much. See you next time. Thanks for setting up all this thing. Okay, bye bye.
163438	164420	10	A	0.9999	02:43	2	Yes. Awesome.
166710	204160	11	A	1.0	02:46	84	Okay, anyone else want to add anything? We don't need to do a Coda overview. I would say people who are watching this recording can look at the live recording if they want a Coda update that we just went through for the cohort two's live meetings. But does anyone want to give any introductory thoughts? Otherwise, there's a few ways I think we can go for this session, but we're here just to rejoin our activities and orient towards chapters six or ten.
205330	216900	12	A	0.99975	03:25	21	We can scan through the chapters, we can have any suggestions or discussions around ways to approach them. I don't know.
230280	232150	13	A	0.91653	03:50	5	Rohan and then anyone else?
234620	258976	14	D	0.76	03:54	53	I was wondering, when are we going to get to the projects part or discussions about the projects? Monetics. Great question. Let's look at the chapters and see where that first off, it can happen however you want with contacting people. And we can make a sub page like I see exists here.
258998	274390	15	A	0.56	04:18	34	This looks really awesome. So people can request a sub page. They can mention it. That contact them now or however. So it's up to you for a project that is under your control.
275800	308060	16	A	1.0	04:35	69	It can be developed in the open here or however, you can also participate in many ongoing projects like active blockfronts, which also which might all share this. Our Gitcoin grant was approved yesterday. So if people are familiar with this or want to become familiar, this is a way to provide or receive support possibly for their learning in block prints and contributing to that open source package.
312320	321410	17	A	0.9979	05:12	35	Does that address what you were thinking? Were you thinking about these project ideas or were you thinking more about the sort of build your own model approach that will be starting in chapter six?
323540	330390	18	D	0.7	05:23	16	No, about the project ideas in the code of page. That answers my question. Awesome. Yeah.
333240	376692	19	A	0.64765	05:33	102	There are different types of projects. Clearly more will be added, but they're of different they might involve building a generative model, but they are not the generative model itself. Or only let's look at chapter six because this is where the generative model construction is going to come into play. And so again, there's a lot of projects that you would only need to qualitatively think about generative models for, like educational material production is related to the generative model or could be modeled as the generative model of a learner. But you wouldn't necessarily have to make a generative model.
376746	394490	20	A	0.99998	06:16	32	But in chapter six, it's a recipe for designing active inference models. It is going to brock. Sorry, just real quick. I think Lucas here doesn't have access. He asked for access.
395100	403870	21	A	0.78	06:35	17	Okay, message in discord. Or I mean message and gather your email address and I'll add you.
406320	430230	22	A	1.0	06:46	33	Okay, sorry. Okay, you requested access. All right, I will add you. That's enough. Then in chapter Six, it's going to ask some questions that are driving the design of the generative model.
431080	467890	23	A	0.99999	07:11	84	Which system are we modeling? System of interest, what is the appropriate form for the generative model reflecting the discrete or continuous distinction that we looked at? And also all these other questions that aren't exactly within the textbook, like temporal depth, hierarchical nesting, which parameters are learned versus fixed? All these different directions that the models actually have to be elaborated on even before getting to the data engineering and maybe even code implementation. Just from a structural perspective, what form is it?
469460	498350	24	A	0.99998	07:49	58	How to set up the generative model is where some of those analytical details begin being introduced. Not necessarily even the program level implementation or an executable simulation, but like, okay, we have a preference vector. Is there two states? Is there some continuous preference distribution? Whatever it is, what is the actual details of the generative model?
499440	548750	25	A	1.0	08:19	87	And then the other side of the coinblanket is the generative process. So what are the endogenous dynamics and the causal mapping with action for the generative process? And there's kind of cases where you have more of a communication setting, active inference entities on both sides. You could also have more of like a simple, simple partnering, like two deterministic programs that send messages to each other. Or it could be like one more cognitive, more agent like generative model and one more environmental nonliving type.
551280	578496	26	A	0.99999	09:11	68	Any thoughts or overviews? Or how would people think about how can we make this type of a recipe design? Should we be all designing a model? Or how do we even go about reading a section of the book in a chapter that begins with a recipe provision? Lyle yeah, I spent a lot of time building what I think would be classed here as generative models.
578528	637076	27	E	1.0	09:38	127	And what I find is that I characterize it as the step of framing up is often far trickier, sometimes much harder, frankly, than building a model, depending on what the situation is. And in my experience, I find that it all comes down to making sure we understand what is the question that we're trying to answer. It's sort of like because every modeling process I'm sure everybody on this call knows is a process of deciding what to leave out, right? What to put in, what to leave out, and what level of representation. Then everything that's in there, if it's going to be a good model, has to be necessary and necessary to answer a question or provide a particular insight or so forth.
637108	684968	28	E	0.99991	10:37	88	So that whole issue of framing out what you're going to build in all those different the 10,000 questions, there's more than four. Ultimately it's many. Then it's all about that, which often means understanding the audience. If the model builder is the only audience, this is much simpler. If the audience is some much larger group with different perspectives, a lack of homogeneity and insight, then there almost has to be, I'm going to say almost a pre modeling or framing process of sort of framing up.
685054	705324	29	E	0.99999	11:25	40	What are the questions we care about? And then we can talk about how those translate into a model that's just some general framing. Thank you. That's very interesting. It makes me think about this audience question for the model.
705362	722304	30	A	0.6741	11:45	52	Like, why are we building the model? Why are we shaping our regime of attention to build this model? Model building can be an end of itself. It can be creative and expressive and fun and all these other things. And maybe later there's a road that has some Pragmatic value too.
722342	769010	31	A	1.0	12:02	126	But also it can just be like fun. Like, what would a generative model that could do this look like? And that can be very didactic there's other times where you're presenting information, oh, I made a simulation of Twitter discourse and dot dot, dot is always going to be presented in a way that's not only just like, the model distilling down from the world, but then you're communicating it. And then when you're actually not just communicating, but if you're making an application that does something and communication is doing something as well, then the system of interest, as Lyle mentioned, is totally nontrivial. And there's the whole framing in some of these early stages, especially because they can't always be changed easily later.
770900	773430	32	A	0.16083	12:50	5	Rowan and then anyone else.
776440	795530	33	D	0.58705	12:56	35	Yeah, so I'm just curious, when you say who's the audience, isn't this part of the active inference model itself? That okay, so whatever makes sense in that framework, wouldn't that be the audience here?
798780	824096	34	D	0.99	13:18	55	It has to survive, right? Your agent has to survive. So whatever generative model helps it survive, would that not be the it's model of choice over here? And I'm just curious. I'm not sure it's an awesome way to frame it, and maybe someone can share the free energy governance link in the chat.
824128	870690	35	A	1.0	13:44	94	I just can't look it up right now. But it puts this very nicely in a recent pretty short book dissertation about that imperative for organizations. And yes, in one sense it can be said the right generative model or like the audience for it is whatever its survivability conditions are. And within our textbook group, the survivability conditions are open. However, we're also learning about or even just gesturing towards like, okay, not just we're going to imagine a room with a person who can take on a jacket or take it off.
872180	912320	36	A	0.99996	14:32	92	We can make that a didactic model. And the audience could be this textbook group or future cohorts of the textbook group, and the function could be just sort of like a neutral exemplar active inference generative model. But then, of course, the considerations for information presentation, empirical data analysis, any kind of application, the system of interest is not just the one person with the jacket on or off two states room with a sign fluctuation. So that's a different situation for model building. So how should we interpret this recipe?
915300	949244	37	D	1.0	15:15	75	Okay, but is there not like, a general framework for what a good generative model looks like is what I'm saying. I guess you could frame that differently. So if you want to build pixel level representations, for example, you can use a gan, and that's a pretty decent one, but maybe pixel level representations are not good for the task at hand or something like that. So it should fit a general category. Right?
949282	962210	38	D	0.99981	15:49	34	So this is what a good set of models looks like for active inference. So that's sort of getting at. Yeah, that's a very fascinating framing. Does anyone want to add something to that?
967500	992716	39	A	1.0	16:07	55	I totally hear you on is there a rubric like, what are we evaluating the generative model and process fit? Because it's not like there's just simply a best generative model bigger or whatever. No feature about it except outside of a generative process. Context is the fitness and then what? Is there a rubric?
992748	1015496	40	A	0.99995	16:32	48	Is there a gold standard? Is it like, oh, you're dealing with audio data here's, the file format, that level of standardization? Certainly not. However, are there some practices or lenses that we could bring in from people's experience with evaluating model adequacy and relevancy? There probably are.
1015678	1024380	41	E	0.79876	16:55	19	Lyle well, yeah, that really comes right back to purpose, right. So a model is always fit for purpose.
1027200	1042332	42	E	0.98	17:07	49	Of course, this also surfaces the questions of model validation, right. One of the things we haven't talked about here is what's the right model? How do we frame up the right model? What do we choose to put in what we leave out? Part of that is purpose.
1042396	1059604	43	E	0.75	17:22	49	And how would I evaluate if I do what I'm imagining a model will be? How do I evaluate its quality, its validity? Well, what data is actually available? That's one thing you always have to ask at the outset what data is available? What data can I use?
1059722	1082830	44	E	0.99971	17:39	44	What's computationally adequate? And what parts of this then when we kind of project, when we apply this model, if that's its role, then does it fit for the purpose? Does it provide good, adequate results and improve whatever behavior we're trying to address?
1086000	1116010	45	E	1.0	18:06	73	You can't say if it's good if you don't have a purpose. So if your purpose is just to explore model building, which is something I love to do, then that's a pretty big there's a lot of things that are fit for that purpose, right? But if the purpose is to do a prospective analysis of a system and what actions might be taken to intervene, then that's in a different thing.
1119260	1156660	46	A	0.99999	18:39	82	Thanks a lot for sharing it. I'm really happy. And I think it's relevant that we're having this kind of a discussion because we've gone through some of the first chapters and we'll continue through chapter six, I think, in having this conversation. But does anybody else want to add something about this more general topic of, like, how are we even coming to talk about what system, or how are we framing the system that we're modeling that's in Section 6.3?
1161110	1184620	47	C	1.0	19:21	56	This is too broad. It's not active inference specific. But whenever I'm trying to model something, the only questions that I mean, it is contextual to the purpose. It entails a purpose in an audience. But all I want to know basically is what are the questions that this model needs to generate an answer for?
1186830	1199360	48	C	0.76195	19:46	22	What is the information that is necessarily, therefore kind of required to model a system that would have such answers in it?
1202390	1274120	49	C	0.63	20:02	133	And maybe another way to say the same thing is like, what affordances would the model require to answer, address whatever, some set of questions that are posed to system? So if you asked, I don't know, how frequently does a yellow colored car, I don't know drive down this particular road, then I wouldn't need to record the number of bikes or their colors that are using the bike lane or buses or trucks large. This is maybe outside the scope of what I mean by yellow. How many cars out of all the cars, how many are yellow or something driving down this road or whatever, like not even exactly a generative model. But my my point is that modeling that system there, there is obvious data that's completely irrelevant, right?
1274490	1290240	50	C	0.68	21:14	41	And so if you were going to build some sort of simulation of any kind that's going to be generative like there's often a lot of data that's just completely extraneous depending on what questions you're going to ask of it.
1294290	1346720	51	A	0.99968	21:34	90	Thanks. In 63 in the first paragraphs they're going to come out hard on the interface concept of Markov blanket. This is how you'll do system modeling is by finding interfaces that distinguish the internal and external states of a system. Then that is critiqued or elaborated because there's in infinite degrees of freedom in the course gradings and those are modeler specific and they suggest that that matters. Especially if you want to be considering embodied extended perspectives where just descriptive interfacing models won't give you the whole answer.
1347410	1399230	52	A	0.96236	22:27	113	There's a great paper could a neuroscientist understand a microprocessor showing that even if you have total access to the microprocessors firing like an EEG and a generated set of single and double lesions, a lot of the interpretations would be strongly misleading. Yet people want the wiring circuit of the brain which is dynamic and also involves diffusive molecules. We have all 302 nematode neurons mapped but that also as an interface diagram is not even close. So if you want to describe the nematode like model building then it's a fit for purpose. However, there might be very simple models that could be doing a lot better in nematode behavior observation.
1401750	1424070	53	A	0.99	23:21	48	The form is discussed. There are three main design choices. First, discrete and continuous time. We had some awesome discussions in the previous months about similarities and differences and where in theory they're different and then in practice where they're different. The whole question of discretizing continuous systems.
1425050	1477210	54	A	1.0	23:45	97	The second choice is between shallow models and hierarchical models where inference operates at multiple timescales. The third choice is the consideration only of the present kind of the variational free energy versus models with temporal depth. Temporal depth consideration could be purely passive and it could also include some element of affordance which if we remember to like the B matrix actions are influencing how states of the world are changing through time. So that is how active inference is unifying. Policy comparison by kind of embedding action into estimates of how things could evolve probabilistically.
1478910	1506094	55	A	0.99999	24:38	54	Those three design decisions are explored in slightly more detail in the subsections 65. How to set up the generative model after specification. Then the specific variables have to be included. Okay, the latent state temperature is going to be continuous. The observations in my thermometer I'm going to take in as just integers.
1506222	1544910	56	A	1.0	25:06	99	And then there's going to be a person who is going to be in a binary state of like whether it's hot or cold, or maybe I want hot, neutral and cold. Or maybe I want them to have a ten point scale or I want them to have a scale that's doing dot, dot, dot that is in this stage of actually setting up the generative model and giving a little bit of color to what had been just outlined. It's going to be a nested model with this continuous variable. And this kind of a discrete variable.
1547970	1604958	57	A	0.99999	25:47	118	Here we return to the frog example from earlier in the book where there's like but it's kind of being generalized a little bit. It was introduced with the whole Bayesian equation walkthrough. Now we're returning to it and thinking more about multimodal or like even you could consider this as sensor fusion because there's some hidden cause, the jumping or the action of a frog that is inducing several domains of impact potentially in the generative process. And then that leads to specific observables from the perspective of the cognitive entity. Those could be again, two communicative cognitive entities or one and not or however so this is like, okay, we're going to be modeling forest fires.
1605134	1625510	58	A	0.99982	26:45	55	So forest fires, they change the temperature, they change the chemical composition, they change the vibrations in the ground or something. Okay, and then maybe there's three sensors, maybe you have three thermometers. And then what about them? Are you going to average them? Are they going to be like three parallel modeled time series?
1626030	1651378	59	A	0.66	27:06	53	That is where some more specification of the generative model comes into play. Keeping the active inference ontology in mind. What are the affordances of the frog? What are the latent states that are being changing through time like sound, physical presence or photon emission or something? And then what are the data?
1651464	1653410	60	A	0.77	27:31	7	That would be the O, the observations.
1656710	1665720	61	A	0.61	27:36	22	This box looks like it's about different sensory modalities. I'm sure there's a lot of interesting discussions we could bring in here.
1672870	1685430	62	A	0.99392	27:52	25	Priors and empirical behavior complete class theorems. Any statistical decision procedure behavior may be framed as Bayes optimal under the right set of prior beliefs.
1691010	1731342	63	A	0.99845	28:11	92	Discussion of fixed and learned variables one can imagine the pros and the cons generally of having fixed and learned variables. Like computationally it's simpler to fix hard code a variable. However, if there's a setting where the model's adequacy depends on being able to update that, maybe you want it learnable. However, then you have to deal with these questions about the kinetics of learning like instantly switch or slow switch or trend averaging. So there's a lot of discussions around learning how is attention regulated, what is precision on learning?
1731396	1766280	64	A	0.37532	28:51	61	It's like it very much complexifies the model and there's many variables that you can bring into a learnable setting. But when it's framed as just static variables and only like the hidden states changing through time. That's like the simplest case. But more and more cognitive entities probably are going to entail considering learning dynamics, setting up the generative process.
1768810	1832970	65	A	1.0	29:28	131	The reason we postponed the design of the generative process so little slate of hands entity first, not the niche first is that in many practical applications discussed in this book, we simply assume the dynamics of the generative process are the same or very similar to the generative model. We generally assume the agent's generative model closely mimics the process that generates its observation. That is clearly a simplifying case because it doesn't address what if you're paying attention to predicting width and the world is dependent on height. There's so many complexities of that which is really that broader. Like what is being modeled, what matters question but in some way very upstream or very close to the stream, it is like the rabbit being put in the hat.
1833310	1858710	66	A	0.58894	30:33	62	Like if the rat knows that there's a five x five maze, that's a huge amount of information versus if it only has access to pure local information. And that's just something to, I think, for us to note as we look through models. Like are we modeling the generative process? Oh, so the seasons oscillate. So it is a sine wave.
1859130	1873980	67	A	0.99885	30:59	42	So then the generative model of the agent is also going to be fitting a sine wave. Well, then it kind of collapses to like a stochastic regression and maybe then it looks like the fit is going to be very good.
1876190	1898370	68	A	0.99455	31:16	40	Active inference modeling brings in another complexity with action influencing outcomes that prevents some, I guess, fallacies of modeling, but by no means and probably introduces many others. Eric? Yeah. Can you hear me? This is a new sounds good.
1898520	1938666	69	F	0.98931	31:38	112	So this might be a time to discuss the question I posted and I apologize I didn't put it in the right place the other day. I just figured out today that it goes under this particular location. But this is about the question about why modeling of a generative process is necessary, is a necessary step for building an active inference model. So let me just read it because it's a lot of words. So we know that an active inference agent employs a generative model as its model of the external world and it uses this generative model to perform inferences about perceptual input and to make decisions about actions.
1938778	1979574	70	F	0.99969	32:18	107	So in general, the external world is complex and unknowable to the agent. The generative model may or may not be able to learn. But if it is learning is supposed to put the generative model in a better alignment with the world's generative process, whatever that may be. So I can see how one might model the generative process if one is building an artificial agent in a laboratory where you kind of have access, you control how the world behaves with respect to the agent. And then you might want to study how well the agent design works versus one versus another under control conditions.
1979702	2023900	71	F	0.99989	32:59	148	But this is not the same as designing an agent to go out and cope with some real world environment where you really don't know what the generative process is. So I think that the recipe for designing an active inference models would include formally setting up the generative process only in the kind of the laboratory situation, but not if you're really trying to build something out for the real world because you don't know the generative process. You might create an artificial laboratory kind of situation by trying to build a model of how the world works and say, well, how does my agent work under those assumptions or not? But that might set you up for putting the agent in the real world. But in fact, you don't know the generative process if you're really trying to build something to work in the real world.
2024590	2027260	72	F	0.79768	33:44	8	That's my comment, my question. That's your question.
2031730	2069980	73	A	0.77936	33:51	69	Thank you, Lyle. Well, Eric, I love that framing because I think there's multiple different cases, right? So I think if you're modeling something that, as you say, goes in the real world, then perhaps it's some sentient creature or being, then obviously the real world, even if we knew everything about it, is too complex to model. Right. So that's fool's gold to assume you know everything, right?
2073150	2114454	74	E	0.99555	34:33	95	I'm just going to say, yeah, that's hard. Typically, I guess we would say what are the parts of the generative, the real world, the generative process that we're going to consider relevant and deal with that and knowing that we're making a leap of faith. But there's another case, I think, which is more generalizable, just complex adaptive systems that operate in what I call the built world. So I work with a bunch of people who build digital twins. They build digital twins of human infrastructure, so buildings and all this stuff there.
2114492	2123690	75	E	0.52	35:14	13	The generative process that we're concerned with is largely knowable and largely representable.
2126430	2145860	76	E	0.99976	35:26	48	What's interesting about that is there are a bunch of blind spots and inadequacies in what we know about that generative process and the ability to do inference about what the real state of that system is then becomes the value of this approach in that setting. Right.
2148230	2177340	77	E	1.0	35:48	78	I don't think there's a general answer. Once again, I think it really comes down to purpose and what the specific framing you're looking to do? To me, this ability to say something about what I I like that idea of decision agents, right. Decision agents that are going to potentially take action or infer actual states is much richer than what a lot of the historical modeling paradigms have given us. So I think that's really interesting.
2178590	2180410	78	A	0.61616	36:18	4	Thank you, Lyle. Ali.
2188450	2240318	79	G	0.99992	36:28	94	Also think that the distinction between generative process and generative models become significant if we want to simulate learning rather than just inference. I mean, that's the answer I got from Ryan Smith because I asked him almost the same question. Why do we need generative process in order to simulate the agents? Because, you see, for the generative process, if the generative model exactly maps them to generative process, we only need that capital D matrix, right? And that's just when we're just trying to simulate the inference side of the agent, right?
2240404	2296500	80	G	0.99993	37:20	100	But when the learning comes along, then we need to separate that capital D from another matrix, probably dill case D, which maps into the generator process. So yeah, one of the situations that the distinction between two might be necessary is when those two process, I mean learning and inference, are taken as two separate phenomena to model. Thanks. One note is also there's work on symmetries in the generative process, generative model, like, I think like the bi directional paper with Matt Sims and Blue discussing it. And then here will be a defense to Eric's excellent question.
2299350	2354930	81	A	0.68	38:19	114	The entity first modeling approach that's taken by this chapter, one can say, I don't know whether I'm going to a forest or a desert, but I'm going to have these sensors on my designed interface and I'm going to do extensive modeling on interoception and homeostasis. And if I can learn policies that balance homeostasis, then I've survived. If I fail, then failure happens. So that doesn't mean that it works or it's doing the right thing, fit for purpose, any of those aspects. But one of the insights from the four E and the embodied side is like a vast amount of our what is modelable as cognitive isn't necessarily the declarative.
2355350	2433980	82	A	0.59	39:15	151	I think, therefore I am possibly even symbolic type thinking linguistic. There's a lot going on and many of that a lot going on can be simplified by not even knowing about the external process, maybe not even the as modeled kidney knowing about what the as modeled liver is doing. So this type of a focus where it's like we're going to define our entity types and the kinds of observations that they can make, the kinds of affordances that they have or do empirically or that they conceptually could do. That approach is consistent with embodied biological systems and persistence of organizations. And so I'm wondering how that piece comes into play with this discussion that's very important about and also their earlier discussion of the embedded and extended cognition is that it kind of blurs the line with what is a generative model, what is a generative process.
2434510	2453550	83	A	0.94403	40:34	35	So hence there being a lot of thinking and attention on what the system's modeling is. What are the known unknowns and the unknown unknowns going to be. Let's just see how the chapter ends.
2457860	2497660	84	A	0.56	40:57	71	Six, seven simulating, visualizing, analyzing, and fitting data using active inference. So standard routines for active inference that provide support for all functions are available. Hashtag SPM and Appendix C step by Step model is a great look through this. This is MATLAB code one amazing work that we could all iterate on. Would be porting MATLAB into the ontology into Python and or Julia with Pi MDP or active blockference.
2498080	2556480	85	A	0.99838	41:38	121	But there's a lot in SPM and some of it's neuroimaging specific, some of it's very variational base specific. Not all of it is going to be state of the art or the most useful in every situation. However, I wonder if only offering certain routines in MATLAB, which is like a traditionally very academic software platform and potentially non free, can be a limiting factor. So those who feel like they want to learn more or contribute this way helping structure some of the code architecture so that cohorts coming through can be doing multiple language. Maybe first we can just move some of these routines into a folder and then people can start to organize those types of aspects.
2558180	2620020	86	A	0.99791	42:38	128	Summary it's a four step recipe. We walk through it from the consideration of the system of interest broadly, like the entity and the process, focusing in on the entity specifically thinking structurally about what it is going to be like doing composed of specifying that to a few levels of detail, then doing the same for the generative process. And then once that is specified, it's not quite, quite there for most people today, but where it seems like they are laying out a path towards and where we probably can and will be after that level of setup. In some potentially graphical editor or parameter file. Then, as SPM and MATLAB have done in many, many papers, the generative model specification almost prepares the working script.
2620440	2642700	87	A	0.99999	43:40	69	But there's still a lot of details and pieces to add in, especially in a modern environment and for all of these non standard and novel cases that people are wanting to consider. But that is once we have a notebook that goes through the recipe, then the recipes can be forked and so on and they can be written in different languages, pi MDP, block for instance. Ali.
2645200	2730330	88	G	0.99188	44:05	158	Yeah, just one thing that I think is not made explicit in this chapter is that actually that first step, which system are we modeling? Especially the identification of the markup blanket part is basically at this point of active inference research is more like a hypothetical step because I also had the misapprehension that we can somehow identify the markup blankets from data. But then as I went on through my project and by consulting Maxwell and others actually this is the comment Maxwell made about my proposal that he said that identifying markup blanket from data is still an outstanding issue that is not resolved yet in the research on active inference. And one of the most active areas, areas of research they're doing at Versus Lab is just focused on this part of the modeling recipe. I mean how we can identify, automatically identify or somehow learn the markup blanket from just pure data points.
2731660	2796940	89	A	0.99998	45:31	126	Awesome. And that ties in with Dalton s's work on the blanket index and like continuous variables for dynamic assemblies of blanketing. This is going to get really nuanced and empirical with the discovery and the thresholding of Markov blankets and causal inference in real world systems with many different kinds of sensors and doing structure learning on generative model and process and like everything empirically. Which is why, as a simplifying step, it actually really reminds me of how Dave Snowden situates the difference between systems thinking and complexity thinking. Which is systems often uses, like, a lot of nodes and flowcharts to represent system elements and relationships and interfaces, whereas in complexity and the Knevin especially framing, it's more like self organizing sand dunes.
2797540	2862820	90	A	0.76	46:37	141	And so causal relationships might be very much in flux and it puts a higher focus on action rather than system description, especially in situations like moving your head where the relationship of different things is going to be heavily action dependent. And so for now, we're kind of in the systems world where it's like a priori, here are the system interfaces and then we're going to take whether it's a heuristic or whether you take a literal interpretation, but you don't have to. You could just say I'm taking heuristically the approach of the system's mapping. But that's not to say that that generative model couldn't be trained in a systems mapped context and then placed into a different setting where there was a mismatch or a different generative model. And so it's going to be an ongoing discussion.
2863720	2905890	91	A	0.99962	47:43	102	When are these lines drawn? One other point, other than not needing to use last names to refer to specific concepts, like are we talking about the blanket that statistically insulates every partition of nodes in these Bayes graphs, which are going to be vast? As Ali and Yaakov and I were discussing on the branching time active inference from just a few days ago yesterday, these graphs are going to be vast. And so just saying there will be a Markov blanket. In fact, there will be many Markov blankets with different semantics that you might assign to them or not.
2907940	2938990	92	A	1.0	48:27	62	How does that map onto the real world? Is like the realism, instrumentalism, pragmatism abduction conversation that we've been having? Do you come in with these kinds of boundaries, heuristically and distinctions or how many levels of uncertainty and nesting? I don't know how many categories of blank there are. I don't know if it's a category or a continuum of this.
2940000	3025560	93	A	1.0	49:00	170	You can actually still take on multiple levels of uncertainty in the modeling, but then fitting it with empirical data, if it's fit for purpose use is to do some sort of statistical inference or like provide meaning or action, but just didactically. When the model's purpose is educational, then there's a lot of things and architectures we might play with and then the recipe. And also this conversation helps, I hope, hold space for the educational and the curiosity driven model development where we're going to have a lot of fun and interesting GMs and people's applications and working with different real world constraints and different settings. We'll all be learning a lot from it, and hopefully some of it will be in repos we can reference. Other people may want to play around and version within folders that we can make if anybody wants to be added as a collaborator in this textbook repo, which is just pretty much empty except for, I guess, a script from Yaakup.
3028060	3042700	94	A	1.0	50:28	30	And there'll be more to say on probably GitHub. And as we continue through. But in these last minutes, does anyone have any thoughts for our continuation of the cohort?
3046720	3060530	95	E	0.98	50:46	29	I have one question. Daniel, you referenced a paper earlier in the discussion that I'd love to get the reference to about persistence of organizations and survivability. Oh, yes.
3068040	3074520	96	A	0.77	51:08	8	All right. I will put it into resources.
3079180	3080410	97	A	0.99676	51:19	3	Here's the work.
3084300	3094510	98	A	0.47769	51:24	22	It's a PhD dissertation that was published as a book, and I'll upload the PDF as well. This is extremely interesting work.
3103320	3113190	99	A	0.68371	51:43	20	Yeah, it just came out and and okay, in our last minutes, it's it's too, too fun not to share.
3116920	3121480	100	A	0.99985	51:56	7	So Karl Friston has written a foreword.
3124620	3140716	101	A	0.99997	52:04	39	What is a firm's purpose? What is an organization's purpose? It's as difficult to answer as why am I here? Free energy, governance and the FEP. Inverts the question, instead of asking how must the system behave to survive?
3140748	3158870	102	A	1.0	52:20	31	It asks, how do systems that survive behave? The answer is rather deflationary. They survive. Their purpose is just sustainability. So some classic Fristinisms, some very nice framings on page 95.
3160360	3185100	103	A	0.97361	52:40	36	There's some great juxtapositions. So it's always awesome to see this kind of quality work. And who knows what people here will see? And I don't see any scripts here, thus the textbook. But who knows?
3186160	3203600	104	A	1.0	53:06	34	Maybe we can do some generative modeling of organizations or we can specify it and iterate on it, realize it in block, for instance, and Pymdp and for any lab and JF's symbolic suite.
3206040	3209380	105	A	0.99984	53:26	12	So there'll be a lot of fun things to explore this cohort.
3214050	3217680	106	A	0.99996	53:34	10	Any other questions or ideas that people want to share?
3220650	3238300	107	A	0.99994	53:40	33	Thanks. And congratulations to people for joining this continuation. It's a great continuance. And and I know that this part is going to be very interesting. The next three months will be interesting.
