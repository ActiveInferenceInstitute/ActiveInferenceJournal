start	end	speaker	confidence	text
1050	139460	A	0.9190867932489445	Hello. It is July 7, 2022. It is cohort One textbook group week ten, chapter five. So we're having the first discussion of chapter five. We'll have two weeks of discussing chapter five. Then in our last two weeks of July, talk about more general thoughts that we have on chapters one through five and look forward to the second half of the book here. There's two new columns. This first one is if you'd like to join for chapters one through five, cohort two beginning in September 22. And that will be in parallel with also this first cohort continuing for chapters six through ten. So just put a check mark if you want to stay in. Otherwise we won't include you in that cohort. Okay, so there's only a few questions prepared for chapter five. So let's start with any general thoughts that people had about chapter five, like how is this chapter similar or different from the previous ones? And what is the function of chapter five here? Or what did they think was an important overall aspect of this chapter? And then of course, anyone who can capture questions that people are asking here, just add them. But other than that, it would be awesome to hear like, what did people think chapter five was doing or what did they wonder about the material or related to it Ali and then anyone else?
142550	197780	B	0.9054419101123592	I think chapter five needs a lot of Neurobiological background and without necessary requisites, it can be probably Daunting chapter. And unlike other chapters, which are at least the previous chapters, which concern themselves with mathematical formalisms, here in chapter five, for the very first time we encounter some empirical evidence or the empirical reasons behind modeling active inference as such. So it's a very important chapter in my opinion, but at the same time, without any prior Neurobiological background, it could be a really daunting chapter as well.
199610	203110	A	0.9332900000000001	Nice. Thanks for the summary, Mike.
208170	224780	C	0.9346976190476189	Yeah, it was an interesting choice to go all the way to the human brain to illustrate how some of these concepts would map to biological systems, as opposed to starting with more simplistic organisms and kind of working up from there.
231670	330950	A	0.911584716981132	Yeah, very nice point. Any other overview thoughts and then we can just scan through it and look at the order of a few things and then continue to write questions again as you're hearing them or as you're just wondering. But let's hear any other general thoughts if anyone wants to raise their hand and then look at the order of the chapter. Okay, well, the chapter is titled message Passing in Neurobiology. Message Passing was brought up in a previous chapter in this box 4.1, in a formal yet slightly nonstandard notation without examples, just generally the quote. Anyone have any thoughts on JF?
333930	393100	D	0.9093481739130432	Yes, I kind of disagree with the quote. I think recently we've learned that plants actually sense and act on what they detect in the environment. For example, certain trees when they're being munched on by, say, like giraffes, will emit molecules that will disperse, and other trees that sense these essentially an alert signal will start producing compounds in the leafs that make the leaves taste very bitter and thus discouraging foraging and so forth and so on. And also, I think it's clear that plants sense and act, respond to their environment and act in order to maintain their integrity or as individuals or as as groups in the example I just mentioned.
400920	418780	A	0.9118703846153846	Nice. Agreed. Also, the quote might have, like, a little bit of hyperbole comedy, like two types of animals, plants. So it's about nervous systems. Ali.
424000	457480	B	0.9263454838709677	Yeah. And one other thing about Rodolfo Linus is in one of his most famous books, eye of the Cortex from Neurons, the Self, actually, he describes thinking as an internalized movement, and it's a very interesting way to describe thinking, in my opinion. And it directly relates to this active inference framework. So putting his quotation here might be quite relevant.
458780	582138	A	0.9267554901960777	Cool. And then I added 2017 paper with Friston and Calvo about plant and predictive processing framework. And then here's, like a non active paper, but about more on the behavioral side, which is kind of the view from the outside without denying the view from the inside as well. But it's just related to behavioral modeling. Okay. In the introduction, they write, let us take a step back from the technical material of chapter four, which, as Ali and others have reminded us, was like, even at the beginning, was like, you can bypass this chapter if you don't want technical detail. So maybe somebody had read it, even 1235, and maybe they did or didn't. Look at the appendix. Turn to the process theories accompanying active inference, drawing a distinction between a principle and a process theory. Does anyone have any thoughts on that? Like how, as they're reading the book, are they thinking about where free energy principle is related to active inference? How does introducing that kind of broad map territory principle process distinction here help transition the book towards focusing on these empirical cases? Ali with a hand raised or anyone else? Okay, just one yeah, go for it.
582304	630874	B	0.8967025581395345	Yeah. Sorry. Just one thing I forgot to mention about that quotation is an interesting research has been emerging that kind of bestow consciousness to plants as well. One of the articles, one of the early articles for that is insights into plant consciousness. So, in fact, we don't necessarily limit it to just human or even animal consciousness. And we are beginning to relate consciousness or any other aspects of nervous system to plants as well. So just one additional remarks about that previous code.
630912	650020	A	0.9125504761904762	Sorry. Yeah. And the mathematical frameworks for behavior and consciousness that are integrative will allow comparisons of different kinds of behavioral systems, and then that leads to people wondering about consciousness and all these other areas. So mike and then anyone else?
652250	704390	C	0.9474920799999998	Yeah. So tying that back to the part of the chapter that you were on previously in terms of moving from principle to process. And you had highlighted that the latter allows us to develop hypotheses that are answerable to empirical data. So I think this is the first instance in the book where they are making a serious effort to tie out to real world observations as opposed to saying, here's a framework for how things might work and how the pieces might be connected. Now we're going to take that framework and think about can we identify things that we see in real systems, in this case in the human brain and tie those back into the ideas that we put forth previously.
705850	869170	A	0.923823533333332	Thanks. Totally agree. It's like partitioning off the principles from the earlier chapters. Like in principle, those two sides of the equation are equal because of how the axioms of math are. Or like in principle one could do this with a Bayesian graph and then that is like in principle you could do a linear regression with a least squares error minimization. Nobody can make any data set that says that you can't do that. And then there's how that least squares regression works on empirical data. So they're saying for chapter five we're going to look at with all the architecture, developed a few specific neural systems and talk about how they're the best current understanding that they have of how these neural systems can be modeled with models of the structures like we've seen before. And they're saying, we're not trying to write a neuro textbook here, but to touch kind of like with both feet, the empirical modeling. And then the systems that they are going to model are like effector systems. So motor control subcortical structures like the thalamus and basal ganglia. So these are more like functional outcomes of the nervous system. Specific anatomical structures of interest, modulation of synaptic efficiency or efficacy, which is like a micro anatomical or like a neurophysiological mechanism of interest and something that is an important, like, leverage point and something that is being modified and found to be changed in different situations. And then the relationship between decision making and movement generation, which is also something that has come up in those 46 live streams on like motor active inference, decision making, active inference. Let's check if there's any questions written. Okay. What could anyone say about the cortical layers or what was in figure 5.1? Mike.
871030	891980	C	0.9546729310344825	I was just observing that in the start of chapter four, they said, well, you can skip this chapter if you don't want to get deep into the math. And then here we are at section 52 in chapter five, I think, and they refer back to the message passing structure that was set up in chapter four.
894190	993660	A	0.9315720134228193	Yes, good point. And it's like, well, if you can skip the details of the formalism to look at the examples or you could skip the examples. Any linear text, 140 characters or textbook or a live stream or anything, it's always going to be some sort of linear presentation question. And with a densely linked and interdisciplinary area, then the linearity becomes challenging. So maybe with more with some notebooks or some other rendering or educational way to have the ordering or have, of course, the connections between sections be a little bit different. The first system that they're focusing on is the cortical column. Does anyone have anything to add on cortical layers or the role of the cortex, even if it's just something that they've heard about? Well, I think that this Menta line of AI and many of the other Ali go for it. Yes.
996510	1044860	B	0.8937345569620251	I want to say that for the past couple of decades, or probably several decades, cortex has traditionally been thought of as the seat of both consciousness intelligence and also, of course, cognition. But recent studies have shown that especially studies such as Mark Som's research has shown that in fact, consciousness actually stems from literally the brain stem, not necessarily the cortex. So there are some challenges about the exact function of cortex, and the debate goes on.
1049650	1223560	A	0.9369499752475261	Nice. Okay, here's a little bit on the cortex. So it is the outer frontal part of the mammalian style brain. Insects don't have cortex, though they share a lot of the same architectures and so on. So this is like neuron tracing. And there's kind of two levels of organization that people are modeling in the cortical models. The first is based upon the histological observation of the layers. These are six layers of cells, and there's a lot of development and all different functionality between the different layers. One important thing to note is it's not that they're like the layers of a Bayesian hierarchical model. It's not like each one is like up and down, up and down. So this isn't like a predictive processing architecture happening simply with these six layers. This is not a six layer model. In fact, they're connected to each other sparsely within a column, as it's shown here in 5.1. So that's like the micro anatomical structure of the cortical column. And it's called a column because it's like the layers are also arranged in this repeating way. And there's just like a lot of different layouts for different regions of this cortical tissue type. And in certain situations, it is organized like linear call nerve structures, which is often seen as one of the evolutionary local maxima of depth of processing and sparsity of connections laterally. So those are the two levels of analysis that are being and as early mentioned, people yes, have gone to the consciousness angle or they've just argued that this is kind of like the massively paralyzable, but also like deep recurrent contextual, et cetera. The anagrams like the patterns that could be activated. The dimensionality is potentially super high, so it could play a role in memory signal processing. And the two levels that people look at, the connections between, like, anatomically by taking these images or by doing like, stainings and stuff. Anatomically and functionally is within the column where there's certain kinds of relationships, and then across columns where there are certain kinds of relationships. Any thoughts or questions on that? But that's just why the cortex is being studied. And that's like a little bit of how the neuroscientists have been approaching this and why this is one of the important systems with a lot of theoretical modeling and empirical evidence and relevance as well.
1224330	1294510	D	0.9126715573770493	JF I remember many years ago taking a course in physiology on the visual cortex and the whole notion that the brain has some kind of structure. Always thought it was fascinating because I feel that the brain is a huge hack, patches upon patches upon patches, broadened by evolution and that there would be some structure in it is interesting. But within those structures, this picture shows it's very messy. I would never implement a system with this kind of wild interconnectivity. So I'm very curious about how much we can infer from what is really a mildly structured but highly messy architecture in terms of process theory that we're trying to elucidate from anatomy and the functionality of the brain.
1295170	1299726	A	0.9413940000000001	Nice. Thank you. Mike. Yeah.
1299828	1312210	C	0.941601666666667	That makes me think that some of that messiness is in support of redundancy. And so how do we think about redundancies in systems in the context of active inference?
1315350	1330780	A	0.9084867647058822	Yeah. And like, neural systems, of course, have amazing, in some dimensions, ability to have redundancy. Other times, seemingly, there's points of failure. Jeff okay. All right. So just on the left side sorry.
1332990	1353390	D	0.9430728260869566	On the comment about redundancy. I agree. But it's worse than that. Every part often plays many different roles and participate in different functions, which makes it quite a tangle in terms of functional analysis of parts of the brain and what they do and whatnot.
1355830	1983540	A	0.9249724550359708	So five one is showing a more like pure Bayes graph with the annotation of the kinds of cells that are in the anatomical layer. So this is like a visualization of the anatomy based upon the regions that it connects, gets inputs and outputs from, and then the micro anatomy labeled according to cell types. Then with a similar but not exactly concordant. There's not a statistical test proposed for how concordant these are. It's not a statistical argument. It's not exclusive of other framings of what this anatomy is doing. Here are labeled with different parameters from the Bayes graph architectures that have been explored in the previous chapters, compatible with message passing implementations that other papers have addressed that aren't here. These are like architectures that recapitulate some of the functional and macro, structural and microstructural aspects. So this is like computational neuroscience, and it's using these models that actually have an underlying structure that is providing utility and interesting reframings of the anatomy. And as the model statistical architecture begins to recapitulate aspects of the Cyto architecture, there's like no specific threshold where it's like, oh, well, now it's like an argument that it's doing that function. Like people get tantalized by it having some, oh, well, we made this network structured like a brain, or we made this network structured like a mushroom, or we did the ant colony optimization. So just because this works for what it does, doesn't mean this works for what anyone wants it to do. It's just in this huge space of bioinspired model architectures. In five, two, they move a little bit from the consideration of the columnar architecture, which are cell populations, to looking now like still the superficial to deep are the six layers of the cortex. But now a few of the variables are highlighted and their relationships. And so the ascending and descending prediction error in a predictive processing framework which is often graphically seen going up and down, bottom up and top down effects. Here is being shown in the context of the columnar cortex where like errors from one. Let's just go to where they the E's are the errors and the G's are predictions and I guess we can find out what Mu is. But basically, like, this architecture within and between columns could be like this being like the base variable being estimated and a hierarchical nested model of that. And a hierarchical model of that. So there's like a generalization statistical architecture that has compatibility with the neural architecture of the brain and it does like a pure statistical function. And that pure statistical function has resemblance with some things that the brain region is believed to do. So that allows this statistical model to be explaining and predicting and useful about the brain, which is like what computational neuroscience does. So that was the first one of the systems that they focus on then. Yeah, I guess this was then the factor systems. Okay, let's see if we can kind of quickly look at all the systems. What did anyone see or what would they like to say about figure five? Three neuroanatomy associated with active inference in modulating spinal motor reflexes. Okay, so five one was the columnar architecture and that was described in terms of what cell types were in it. Here they're going to pick up on one of those cell types, which is like the computational role. The expectations encoded by this cell type that's found in this layer of the motor cortex. And so different regions of the cortex have different apparent functions asterisk, asterisk, asterisk, but there's like a visual cortex and a motor cortex and so on. So this is in a motor region of cortical architecture that plays a certain biological function. The expectations are subtracted from the incoming proprioceptive input in the horn of a spinal cord. This is like lateral cut through a spinal cord. The horns are like the butterfly parts. And so there's a difference in between the incoming intensity of proprioception and the brain expected expectations and then the error drives muscle activity in the direction of suppression. So the motor activity is, like, reducing the divergence based upon the sign and the intensity of the compromise between the brain's expectations potentially arising within, like, layer five from these bet cells and the incoming sensory information, which can be modeled as, like, why? I think Mu is probably the mean of that expectation. I don't know what part it was mentioned. And then here's the expectation, the difference between these two. It's like a causal system flow, but, like a little different. You're getting a five out of ten pressure, you're expecting a five out of ten pressure. The motor reflex is not engaged. You're getting a seven out of ten pressure, you're expecting five out of ten. There's, like a negative two difference or whichever way you want to be subtracting, there's like a two or a negative two difference. And then that triggers some motor neuron units to fire. And then that proportionally brings the expectation into alignment with the measurement. Um, they're gonna just like that example hinged from a cortical layer. And cell type here is going to be hinging on the cortex and looking to an output region of the cortex, which is the striatum. And then they're going to do a more detailed model of a basal ganglia because it's been modeled a lot more and then also have, like, just a textual treatment of the thalamus. There's multiple papers on dopamine and active inference and so from 2012 and then 2015. This is a really interesting area of research with Dopamine because Dopamine is, like, classically described as the reward molecule. More reward, more dopamine, lower reward, lower dopamine. So isn't the whole meme inactive that we replace the reinforcement reward learning paradigm with a different imperative that has elements that reflect pragmatic value, but that isn't the overarching imperative for policy selection. And so these papers show how, like in the context of a generative model with expectations and preferences and Dopamine signaling something related to the predictive processing of stimuli under a mildly optimistic world model, good events and surprising events are still associated with Dopamine release. And things that are going worse than expected are still associated with Dopamine drops. But that actually is, like, a more unified way to talk about Dopamine's empirical outcomes as opposed to the reward learning, which has to hypothesize all of these modules that translate different kinds of things into reward. Jessica.
1985960	2037450	E	0.8938328703703704	Yeah, I think similarly to these I don't remember where I read this, but the brain in regards to the dopamine comment, it's also, like the anticipation of doing something and the fact that you're going to get that Dopamine kick. Basically, you get a release by anticipating something. And that maybe a little bit connects also with the active inference, the fact that you are anticipating something. You expect that to happen. And so you get that release of the dopamine in anticipation of the event happening. I don't know much, but I'm thinking it could be connected with having a predictive unexpected free energy or something.
2038380	2041000	A	0.87824	Nice. Good insight, Rohan.
2043580	2125024	F	0.925314285714286	Yeah, well, I'm not a biologist, but okay, so I just want to clarify. There are other systems in the body apart from just the brain alone, right? So you have like the autonomous or what is it, parasympathetic nervous system that controls your heart rate, your aspiration and other things. Also you have stuff like adrenaline and noradrenaline that do produce responses and other hormones also that produce responses like for hunger or satisfaction. And we basically have figured out how to modulate these things to solve modern issues for things like obesity or something like that. And there are treatments available that modify these hormones levels. Right. So is this not a very limiting perspective to look at dopamine alone as the only thing? And my other question would be how does that convert into, say, motor commands? So I just increased dopamine levels without any stimulus whatsoever. Let's say someone's taking a drug. It would. So that does not necessarily translate to a motor command.
2125072	2125476	A	0.94638	Right.
2125578	2146270	F	0.9301331818181818	So how does it do this? Is there like a specialized system that figures out okay, so here's the previous action here's increase in dopamine and here's how we modulate to further increase dopamine. And where exactly do you set limits on this process?
2146880	2160992	A	0.9169842424242425	Okay, the two questions were about interacting physiological systems and the second one was about dopamine's role in motor selection. Blue, go ahead if it's related or if you want to address anything.
2161126	2202750	G	0.9064602061855668	Yeah, no, I just wanted to respond. The dopamine response is there are a lot of interactions that are happening in the nervous system. Dopamine is one of the best understood, I think it's one of the ones that we've studied for a long time. And if there's an overload of dopamine, the action can actually be nonspecific. And that's what we see in Parkinson's. Right, so it's like an overload of dopamine into that system and it fries it out and then you get nonspecific action in the nervous system, motor action, the tremors and stuff.
2204000	2384760	A	0.9288880722891574	Yes. Good call. And that question about non purposeful behavior and dopamine on the positive and on the negative, like failure to engage, initiate action relating in like catatonic behavior and then like hypermotor activity associated with repetitive motions of various kinds. Dopamine is known to be different in people who are experiencing that differently and modified by drugs that target that system. But to the first question about pluralism with respect to physiological systems, for sure this model does not exclude that, in fact, its flexibility is its advantage because the inputs to a brain region now we could say, well, at this time scale it's electrochemical and at this time scale it's going to be just noradrenaline. And someone says, well, how could you only model noradrenaline? Say, okay, let's look at the model with Noradrenaline and this other one and an unmodeled component so it will allow integration formally of physiological mechanisms that genuinely interact and as to why people write like, specific papers about specific hormone systems. It's just like what is chunked off in that fractal? And then also one important note is like, Colombo and Wright have written about how we don't need a monolithic theory of any neurotransmitter or any brain region. There might be like, features or components of Dopaminergic systems that it just explains and predicts that they do reward, taken lightly, that the explanation is just, of course, our explanation of a biological system. And also you raise like, beyond the brain there's also glia and other cell types. So, yeah, the cool thing would be a framework where we don't a priori exclude factors that are important, but just to kind of go quickly through the example and get to that motor action. So this is an output from some putative processing that happened in the cortex and now it's projecting into some Dopaminergic regions in the subcortical area, like the basal ganglia. It's going to be a model involving outcomes. O, the difference between the preferred and the expected outcomes. The sigma squiggle expected free energy evaluated for a policy and the posterior over policies. The bold pi the figure is like shown after a lot of the description, but here is where they refer to the high and low Dopamine state. So also the movie book Awakenings is about people who have atypical Dopamine signaling and then they're given L DOPA and they come and get reinvived with life and stuff. Rohan.
2387580	2401708	F	0.9128936363636364	Yeah, well, this is a little more general, but okay, so we have the Marco blanket and there are some internal states. And the Marco blanket basically connects us to the external states.
2401794	2402430	A	0.94789	Right.
2403520	2452664	F	0.9244403488372089	Or samples from the external states and then modulates the internal states accordingly. Okay, so my question is, I think if the first imperative is survival and the first imperative is to keep this system in homeostasis, which is composed of multiple interlocking and interacting complex components, right? How exactly would you translate these multiple signaling modalities with multiple hormones into maintaining homeostasis with something like free energy? Because some of these things are compatible entirely. You would have to have some sort of translation mechanism.
2452712	2452972	A	0.99979	Right?
2453026	2470804	F	0.9466203999999999	So let's say that adrenaline is jumping really high and into dangerously high levels, but we only know it's dangerous because there is some system that is able to predict that. Okay, it should not go above this level because it's going to screw up something else in the system.
2470922	2479984	A	0.956427	Right. Multi scale optimization and not over optimizing one lower level parameter at the cost of some higher order parameter.
2480112	2488600	F	0.9234350000000002	Yeah, but then you come to the curse of dimensionality. So how many different things are you going to take up before it comes completely useless?
2489260	2583880	A	0.9226439181286546	Absolutely. Good question. Empirical question about what computational hardware, what measurement data sets? What sparsity of system graph? What extent of application of heuristics how accurate you need that model to be in the empirical setting. None of it in principle addressed by just the equations, all of it related to how they're actually implemented at what scale, just to quickly complete through here though, this is about the depletion of dopamine is being observed creating this akinesia failure to move and exogenous dopamine promotes impulsive behaviors of multiple different kinds. This is what it looks like. Dopamine, as again stated here is balancing modulating the balance as a neuromodulator between inferring what to do and what not to do. And so these two graphs, both of them are getting outcomes from the cerebral cortex of the observations expected under a policy. So those could be considered like predictions about future sensory states here. And the gamma is this uncertainty that's being represented by Dopamine. In this uncertainty function of Dopamine.
2587340	2587656	B	0.99993	In.
2587678	2835160	A	0.930197520491803	The direct pathway, the policies and the difference between the preferences and expectations sigma squiggle with a tilde are being evaluated as part of the expected free energy of future policies and that is resulting in the selection of policies. So that could be like thinking through all the chess moves and then picking the one with the lowest expected free energy. Here the output in the indirect pathway feeds into the prior vector e habit and then that influences policy through this acting anatomically proposed through this other region not defined with a specific variable. So again, this is not like saying necessarily even just what it's doing. This isn't the full model. The papers read more but that's like the two pathways of action selection and it's compatible with the empirical evidence from pathology and from pharmacology and genetic studies in animals other than humans. And this is how it could be modeled with a base graph that recapitulates some of the architecture and the function. Then they describe the roles of some different neurotransmitters that have been modeled in active and like what kinds of phenomena those measurements have been used in models. And then one last important part, it was in the section with the basal ganglia that was talking about this. So they show the graph of the basal ganglia and then only in this last paragraph do they describe the thalamus. So just say we're just going to do one paragraph on it but basically the thalamus has these two divisions and then they provide the interpretation that these two divisions of the thalamus could reflect first and second order statistics on other types of senses and policies. So that's like a unique prediction that potentially modeling observed neural responses or the bold signal from the blood oxygen use in that region. You'll make a better model if you fit into these categories rather than reward or rather than familiarity or any number of other criteria. So just simply fitting better is not the whole substance of validating the formalisms described earlier but it's part of the empirical grounding and examples of unique predictions and explanations. That are provided by active inference. But that was the thalmus part. And then in this very short section 56, they talk about how a lot of our interfaces are continuous like sensory apparatus and motor apparatus have continuous aspects. But then in the cognitive and decision making domains there's often much more discreteness. Even if there's multi scale discreteness resulting in a very finely graded continuum of alternatives, still there is discreteness involved. And this was explored a lot more fully in the 46 live streams. Active inference models do not contradict folk psychology where they really clarify. This is motor active inference in the continuous domain. This is decision making active inference in the discrete domain. Here's what a hybrid model looks like. Blue.
2838540	2841610	G	0.9069691666666667	Oh, do I still have my hand up? Sorry, just been up.
2841980	3097100	A	0.9311235582822089	Yeah. So then they just basically say some of these models dealt with continuous phenomena like specifically the reflex arc example hashtag active incontinence time, figure four, three, et cetera. And then other models presented in this chapter are compatible with discrete alternatives like discrete variables, for example, policy selections. If there's two modeled policy outcomes then this is like a discrete model or the observations could be happening through discrete time. So there's like different opportunities for discreteness and continuous models and variables to be integrated in these architectures. Then in summary, they're outlining the points of connection between the message passing implied by the generative models of chapter four which we asked you not to read gently, and the neurobiology of inference, action and planning. And then here is going to be like a summary figure for the chapter. The top row is showing some computational motifs that are plausible or compatible with different subsets of cells and regions in cortex. The bottom region are showing some extracortical structures. On the left is the basal ganglia shown from one of the previous figures. So it's a subcortical structure within the brain. Here is a spinal cord cross section and one can imagine that other structures within the brain and outside the brain would be amenable to also this kind of graph and they're just doing like kind of linking now even the models together and then showing the difference in planning. Like on the left side the basal ganglia is getting this preference difference is connecting to the expected free energy. So future policies are being, policies are being evaluated on the basis of their future ability to align with preferences. In this pathway here that's planning habits are when the preference versus expectation difference but the outcomes themselves are going to e and habits are being followed which could be seen as multiscale habits and that's influencing policy. And then here's where that kind of continuous decision and modulated handoff between more planning like and more habitual is being related to the motor implementation of the expectations of the proprioceptive loops. So like I want to be sitting still and then all of your muscles in a healthy situation are not moving versus like, I want my leg again, speaking like loosely with it. I want type word, but just like, I want to lift my leg. That model, the expectations have to be updated to allow the leg to realize being up using a non. We don't have to say, well, it's more rewarding for the leg to be up. We can just say this is a computational architecture that facilitated that and generalizes to multi step planning. And then there's been multiple papers 2017 and beyond that summarized and elaborated on different aspects of this more complex continuous architectures, more complex motor and discrete interfacing, more complex decision making, active inference, of course. Rohan.
3099840	3160800	F	0.9208723076923073	Yeah, I'm just wondering because a lot of this has to do with high level, more abstract behaviors or kind of abstract behaviors. Right. So is there any attempt been made to apply this to something simpler like the autonomous nervous system? Because not every signal goes through to the brain, right. Some of them just go to the spinal cord. And we know this because if the spinal damage, sometimes people can't walk or they have trouble rebreathing and so on, or in other animals, like the cuttlefish, for example, that changes in the pigmentation of the skin is not dependent on brain movement, on brain activity. It's just completely autonomous, right. So has there been any attempt made to apply this to much more those kind of systems?
3161860	3234836	A	0.9515092134831455	Well, how simple or complex a system is, is kind of like how complexly we approach it, because people have been modeling single cell graphs, if that could be seen as the simplest electrochemical decision maker as well as morphological computing. And yeah, there's probably a paucity of published models on autonomic nervous system, active inference models. So there are many opportunities because they cited a huge amount of the neural empirical work here, with the goal being to summarize sort of the tip of the iceberg. But there aren't models like this for every single function or region or anything, nor even if there were, would it be the end of research in that area. So, yeah, there's a lot of open space to build specific models, which is exactly what section six and beyond and part two will take us to, which is to go from, like, identifying it, we can quickly find out whether it's been published or not and then build that model with the inputs and outputs that people are seeing as relevance.
3235028	3276310	F	0.944353214285714	Rowan yeah, I'm sorry for monopolizing this question time. So I'm just curious, has this been applied to non biological systems in any way? Because that seems to be something that we could easily do, right? Because we have plenty of data right now. Is there anything like a better vision model than a convolutional neural net, for example, or some sort of swarm robotics attempt using something like this or even like game playing or something? Because I would be interested to read.
3277480	3340360	A	0.9280973943661973	Many of these things have been sketched or are in progress. We have our project ideas in these, like, last minutes. There's a lot of room for building projects, and there's a huge value to creative ideation of areas where it could be applied and also value for checking literature for where it might have been like a model could be reused. Like a visual foraging model that was from about cultural acquisition of pattern preference was repurposed for our ant stigma G model just by adding a pheromone trace so there isn't like a cookbook on what is out there or how models could be modified. We hope that with active block, for instance, and documentation, it'll be clearer and clearer for people to build generative models and compose them and explore different modules. So it should just be done. Yeah.
3340430	3341690	F	0.9721366666666666	Okay, thank you.
3344300	3360530	A	0.9576131250000001	Any last thoughts or questions on chapter five? And then next week, we'll return to the more specific questions. Ali, and then anyone else would like a closing thought on chapter five?
3363140	3396380	B	0.9428969014084506	Yeah, I just want to mention Thomas Parr's speech. I think it was a few weeks ago in center for Cognitive Neuroscience, Berlin, which I'm putting the link here in which he explained most of these topics and some more in perhaps more accessible way. So if anyone wants to yes, that's it. If anyone wants to watch it, I think that can help in understanding the content of this chapter.
3397680	3423270	A	0.9149623214285713	Nice, thank you. Yes, looks like a good one to watch. And using the same figures, maybe we could annotate, like the figures say, at this time, step here's where it's described. Okay. So those who want to, feel free to stay in this room for tools. Otherwise, thanks for joining and see you next week.
