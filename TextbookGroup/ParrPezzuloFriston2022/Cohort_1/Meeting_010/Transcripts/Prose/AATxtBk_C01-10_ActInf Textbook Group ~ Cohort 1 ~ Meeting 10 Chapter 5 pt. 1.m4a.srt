1
00:00:01,050 --> 00:00:03,914
Hello. It is July 7,

2
00:00:03,962 --> 00:00:07,946
2022. It is cohort One textbook

3
00:00:08,058 --> 00:00:10,960
group week ten, chapter five.

4
00:00:12,210 --> 00:00:14,862
So we're having the first discussion of

5
00:00:14,996 --> 00:00:17,342
chapter five. We'll have two weeks of

6
00:00:17,396 --> 00:00:20,782
discussing chapter five. Then in our

7
00:00:20,836 --> 00:00:24,720
last two weeks of July, talk about

8
00:00:25,130 --> 00:00:28,214
more general thoughts that we have on

9
00:00:28,332 --> 00:00:31,654
chapters one through five and look

10
00:00:31,692 --> 00:00:34,934
forward to the second half of the

11
00:00:34,972 --> 00:00:41,290
book here.

12
00:00:41,440 --> 00:00:44,330
There's two new columns.

13
00:00:44,990 --> 00:00:48,342
This first one is if you'd like to join

14
00:00:48,406 --> 00:00:51,434
for chapters one through five, cohort

15
00:00:51,482 --> 00:00:55,440
two beginning in September 22.

16
00:00:56,210 --> 00:00:58,638
And that will be in parallel with also

17
00:00:58,804 --> 00:01:01,118
this first cohort continuing for

18
00:01:01,204 --> 00:01:03,618
chapters six through ten. So just put a

19
00:01:03,624 --> 00:01:05,938
check mark if you want to stay in.

20
00:01:06,024 --> 00:01:08,978
Otherwise we won't include you in that

21
00:01:09,064 --> 00:01:10,050
cohort.

22
00:01:13,780 --> 00:01:20,096
Okay, so there's

23
00:01:20,128 --> 00:01:22,580
only a few questions prepared for

24
00:01:22,650 --> 00:01:25,860
chapter five. So let's start with any

25
00:01:25,930 --> 00:01:29,736
general thoughts that

26
00:01:29,758 --> 00:01:32,824
people had about chapter five, like how

27
00:01:32,862 --> 00:01:34,600
is this chapter similar or different

28
00:01:34,670 --> 00:01:37,768
from the previous ones? And what is the

29
00:01:37,774 --> 00:01:39,770
function of chapter five here?

30
00:01:41,360 --> 00:01:43,596
Or what did they think was an important

31
00:01:43,698 --> 00:01:47,020
overall aspect of this chapter?

32
00:01:49,040 --> 00:01:50,780
And then of course, anyone who can

33
00:01:50,850 --> 00:01:52,668
capture questions that people are asking

34
00:01:52,754 --> 00:01:55,676
here, just add them. But other than

35
00:01:55,698 --> 00:01:57,790
that, it would be awesome to hear like,

36
00:01:58,420 --> 00:02:00,544
what did people think chapter five was

37
00:02:00,582 --> 00:02:03,296
doing or what did they wonder about the

38
00:02:03,318 --> 00:02:17,902
material or related to it Ali

39
00:02:17,966 --> 00:02:19,460
and then anyone else?

40
00:02:22,550 --> 00:02:26,322
I think chapter five needs

41
00:02:26,376 --> 00:02:28,994
a lot of Neurobiological background and

42
00:02:29,032 --> 00:02:32,578
without necessary requisites,

43
00:02:32,754 --> 00:02:36,390
it can be probably Daunting chapter.

44
00:02:37,370 --> 00:02:41,046
And unlike other chapters, which are at

45
00:02:41,068 --> 00:02:43,610
least the previous chapters, which

46
00:02:43,680 --> 00:02:45,814
concern themselves with mathematical

47
00:02:45,862 --> 00:02:49,226
formalisms, here in chapter five, for

48
00:02:49,248 --> 00:02:52,250
the very first time we encounter some

49
00:02:52,320 --> 00:02:56,302
empirical evidence or

50
00:02:56,436 --> 00:03:00,000
the empirical reasons behind

51
00:03:01,090 --> 00:03:04,990
modeling active inference as such.

52
00:03:05,060 --> 00:03:08,434
So it's a very important chapter in my

53
00:03:08,472 --> 00:03:10,866
opinion, but at the same time, without

54
00:03:10,968 --> 00:03:13,810
any prior Neurobiological background,

55
00:03:14,150 --> 00:03:17,186
it could be a really daunting chapter as

56
00:03:17,208 --> 00:03:21,206
well. Nice. Thanks for the

57
00:03:21,228 --> 00:03:23,110
summary, Mike.

58
00:03:28,170 --> 00:03:30,920
Yeah, it was an interesting choice to go

59
00:03:31,770 --> 00:03:33,882
all the way to the human brain to

60
00:03:33,936 --> 00:03:36,166
illustrate how some of these concepts

61
00:03:36,198 --> 00:03:39,706
would map to biological systems, as

62
00:03:39,728 --> 00:03:42,534
opposed to starting with more simplistic

63
00:03:42,582 --> 00:03:44,186
organisms and kind of working up from

64
00:03:44,208 --> 00:03:44,780
there.

65
00:03:51,670 --> 00:03:53,780
Yeah, very nice point.

66
00:04:05,760 --> 00:04:08,328
Any other overview thoughts and then we

67
00:04:08,354 --> 00:04:10,288
can just scan through it and look at the

68
00:04:10,294 --> 00:04:12,768
order of a few things and then continue

69
00:04:12,854 --> 00:04:16,172
to write questions again as you're

70
00:04:16,236 --> 00:04:17,936
hearing them or as you're just

71
00:04:17,958 --> 00:04:22,544
wondering. But let's hear

72
00:04:22,582 --> 00:04:23,904
any other general thoughts if anyone

73
00:04:23,942 --> 00:04:25,456
wants to raise their hand and then look

74
00:04:25,478 --> 00:04:27,680
at the order of the chapter.

75
00:04:30,620 --> 00:04:31,370
Okay,

76
00:04:45,980 --> 00:04:47,832
well, the chapter is titled message

77
00:04:47,886 --> 00:04:49,720
Passing in Neurobiology.

78
00:04:52,080 --> 00:04:55,804
Message Passing was brought up in a

79
00:04:55,842 --> 00:04:59,820
previous chapter

80
00:05:00,800 --> 00:05:05,980
in this box 4.1, in a formal

81
00:05:07,200 --> 00:05:11,740
yet slightly nonstandard

82
00:05:12,740 --> 00:05:15,152
notation without examples, just

83
00:05:15,206 --> 00:05:19,074
generally the

84
00:05:19,112 --> 00:05:30,950
quote. Anyone have any thoughts on JF?

85
00:05:33,930 --> 00:05:36,630
Yes, I kind of disagree with the quote.

86
00:05:36,990 --> 00:05:39,946
I think recently we've learned that

87
00:05:40,048 --> 00:05:44,060
plants actually sense and act on

88
00:05:45,070 --> 00:05:46,854
what they detect in the environment.

89
00:05:46,902 --> 00:05:49,578
For example, certain trees when they're

90
00:05:49,594 --> 00:05:53,562
being munched on by, say, like giraffes,

91
00:05:53,706 --> 00:05:57,946
will emit molecules

92
00:05:57,978 --> 00:06:00,960
that will disperse, and other trees that

93
00:06:01,650 --> 00:06:04,794
sense these essentially an alert signal

94
00:06:04,842 --> 00:06:07,678
will start producing compounds in the

95
00:06:07,684 --> 00:06:09,234
leafs that make the leaves taste very

96
00:06:09,272 --> 00:06:13,010
bitter and thus discouraging foraging

97
00:06:15,190 --> 00:06:18,294
and so forth and so on. And also, I

98
00:06:18,332 --> 00:06:20,422
think it's clear that plants sense and

99
00:06:20,476 --> 00:06:22,774
act, respond to their environment and

100
00:06:22,812 --> 00:06:25,474
act in order to maintain their integrity

101
00:06:25,522 --> 00:06:28,922
or as individuals or as as

102
00:06:28,976 --> 00:06:33,100
groups in the example I just mentioned.

103
00:06:40,920 --> 00:06:42,260
Nice. Agreed.

104
00:06:44,200 --> 00:06:46,088
Also, the quote might have, like, a

105
00:06:46,094 --> 00:06:49,636
little bit of hyperbole comedy,

106
00:06:49,748 --> 00:06:51,480
like two types of animals,

107
00:06:52,540 --> 00:06:56,920
plants. So it's about

108
00:06:57,070 --> 00:06:58,780
nervous systems. Ali.

109
00:07:04,000 --> 00:07:06,728
Yeah. And one other thing about Rodolfo

110
00:07:06,744 --> 00:07:09,924
Linus is in one of his most famous

111
00:07:09,992 --> 00:07:13,004
books, eye of the Cortex from Neurons,

112
00:07:13,052 --> 00:07:16,060
the Self, actually, he describes

113
00:07:16,140 --> 00:07:20,076
thinking as an internalized movement,

114
00:07:20,268 --> 00:07:22,508
and it's a very interesting way to

115
00:07:22,534 --> 00:07:26,788
describe thinking, in my opinion. And it

116
00:07:26,874 --> 00:07:29,024
directly relates to this active

117
00:07:29,072 --> 00:07:34,452
inference framework. So putting

118
00:07:34,586 --> 00:07:36,584
his quotation here might be quite

119
00:07:36,622 --> 00:07:40,964
relevant. Cool. And then I added 2017

120
00:07:41,012 --> 00:07:44,952
paper with Friston and Calvo about

121
00:07:45,086 --> 00:07:46,756
plant and predictive processing

122
00:07:46,788 --> 00:07:49,864
framework. And then here's, like a non

123
00:07:49,912 --> 00:07:52,316
active paper, but about more on the

124
00:07:52,338 --> 00:07:54,876
behavioral side, which is kind of the

125
00:07:54,898 --> 00:07:58,056
view from the outside without denying

126
00:07:58,088 --> 00:08:01,168
the view from the inside as well. But

127
00:08:01,334 --> 00:08:03,036
it's just related to behavioral

128
00:08:03,068 --> 00:08:09,920
modeling. Okay. In the introduction,

129
00:08:12,900 --> 00:08:14,736
they write, let us take a step back from

130
00:08:14,758 --> 00:08:16,756
the technical material of chapter four,

131
00:08:16,858 --> 00:08:20,096
which, as Ali and others have reminded

132
00:08:20,128 --> 00:08:21,984
us, was like, even at the beginning,

133
00:08:22,032 --> 00:08:24,196
was like, you can bypass this chapter if

134
00:08:24,218 --> 00:08:27,210
you don't want technical detail. So

135
00:08:27,580 --> 00:08:31,930
maybe somebody had read it, even 1235,

136
00:08:34,060 --> 00:08:35,528
and maybe they did or didn't. Look at

137
00:08:35,534 --> 00:08:39,388
the appendix. Turn to the process

138
00:08:39,474 --> 00:08:41,580
theories accompanying active inference,

139
00:08:47,340 --> 00:08:48,856
drawing a distinction between a

140
00:08:48,878 --> 00:08:51,880
principle and a process theory.

141
00:08:55,510 --> 00:08:57,940
Does anyone have any thoughts on that?

142
00:08:58,710 --> 00:09:00,546
Like how, as they're reading the book,

143
00:09:00,568 --> 00:09:02,514
are they thinking about where free

144
00:09:02,552 --> 00:09:04,286
energy principle is related to active

145
00:09:04,318 --> 00:09:08,274
inference? How does introducing

146
00:09:08,402 --> 00:09:12,390
that kind of broad map territory

147
00:09:14,250 --> 00:09:17,774
principle process distinction

148
00:09:17,842 --> 00:09:20,490
here help transition the book towards

149
00:09:20,560 --> 00:09:22,650
focusing on these empirical cases?

150
00:09:31,630 --> 00:09:34,220
Ali with a hand raised or anyone else?

151
00:09:39,150 --> 00:09:42,138
Okay, just one yeah, go for it.

152
00:09:42,304 --> 00:09:45,006
Yeah. Sorry. Just one thing I forgot to

153
00:09:45,028 --> 00:09:50,466
mention about that quotation is an

154
00:09:50,488 --> 00:09:53,310
interesting research has been emerging

155
00:09:53,470 --> 00:09:57,694
that kind of bestow

156
00:09:57,742 --> 00:10:01,110
consciousness to plants as well. One of

157
00:10:01,260 --> 00:10:03,750
the articles,

158
00:10:04,730 --> 00:10:06,774
one of the early articles for that is

159
00:10:06,812 --> 00:10:10,040
insights into plant consciousness. So,

160
00:10:10,410 --> 00:10:15,718
in fact, we don't necessarily limit

161
00:10:15,734 --> 00:10:18,774
it to just human or even animal

162
00:10:18,822 --> 00:10:21,402
consciousness. And we are beginning to

163
00:10:21,456 --> 00:10:24,394
relate consciousness or any other

164
00:10:24,512 --> 00:10:27,306
aspects of nervous system to plants as

165
00:10:27,328 --> 00:10:29,574
well. So just one additional remarks

166
00:10:29,622 --> 00:10:31,500
about that previous code. Sorry.

167
00:10:32,930 --> 00:10:35,290
Yeah. And the mathematical frameworks

168
00:10:35,370 --> 00:10:37,594
for behavior and consciousness that are

169
00:10:37,652 --> 00:10:40,754
integrative will allow comparisons of

170
00:10:40,792 --> 00:10:42,366
different kinds of behavioral systems,

171
00:10:42,398 --> 00:10:43,966
and then that leads to people wondering

172
00:10:43,998 --> 00:10:45,362
about consciousness and all these other

173
00:10:45,416 --> 00:10:48,866
areas. So mike and

174
00:10:48,888 --> 00:10:50,020
then anyone else?

175
00:10:52,250 --> 00:10:55,654
Yeah. So tying that back to the

176
00:10:55,692 --> 00:10:56,806
part of the chapter that you were on

177
00:10:56,828 --> 00:10:58,726
previously in terms of moving from

178
00:10:58,908 --> 00:11:01,922
principle to process. And you had

179
00:11:01,996 --> 00:11:04,970
highlighted that the latter allows us to

180
00:11:05,040 --> 00:11:07,286
develop hypotheses that are answerable

181
00:11:07,318 --> 00:11:10,700
to empirical data. So I think this is

182
00:11:14,530 --> 00:11:16,254
the first instance in the book where

183
00:11:16,292 --> 00:11:19,790
they are making a

184
00:11:19,860 --> 00:11:22,510
serious effort to tie out to real world

185
00:11:22,580 --> 00:11:24,750
observations as opposed to saying,

186
00:11:24,900 --> 00:11:27,534
here's a framework for how things might

187
00:11:27,572 --> 00:11:29,794
work and how the pieces might be

188
00:11:29,832 --> 00:11:31,586
connected. Now we're going to take that

189
00:11:31,608 --> 00:11:34,562
framework and think about can we

190
00:11:34,696 --> 00:11:37,202
identify things that we see in real

191
00:11:37,256 --> 00:11:39,970
systems, in this case in the human brain

192
00:11:40,330 --> 00:11:42,758
and tie those back into the ideas that

193
00:11:42,764 --> 00:11:44,390
we put forth previously.

194
00:11:45,850 --> 00:11:47,910
Thanks. Totally agree. It's like

195
00:11:47,980 --> 00:11:51,654
partitioning off the principles from the

196
00:11:51,692 --> 00:11:53,534
earlier chapters. Like in principle,

197
00:11:53,602 --> 00:11:55,594
those two sides of the equation are

198
00:11:55,632 --> 00:11:59,254
equal because of how the axioms of math

199
00:11:59,302 --> 00:12:01,834
are. Or like in principle one could do

200
00:12:01,872 --> 00:12:05,258
this with a Bayesian graph and then that

201
00:12:05,344 --> 00:12:07,166
is like in principle you could do a

202
00:12:07,188 --> 00:12:10,250
linear regression with a least squares

203
00:12:10,330 --> 00:12:13,246
error minimization. Nobody can make any

204
00:12:13,268 --> 00:12:14,686
data set that says that you can't do

205
00:12:14,708 --> 00:12:17,358
that. And then there's how that least

206
00:12:17,444 --> 00:12:20,254
squares regression works on empirical

207
00:12:20,302 --> 00:12:22,770
data. So they're saying for chapter five

208
00:12:22,840 --> 00:12:26,466
we're going to look at with all

209
00:12:26,488 --> 00:12:28,850
the architecture, developed a few

210
00:12:28,920 --> 00:12:32,374
specific neural systems and talk about

211
00:12:32,412 --> 00:12:35,480
how they're the best current

212
00:12:36,730 --> 00:12:39,094
understanding that they have of how

213
00:12:39,132 --> 00:12:42,146
these neural systems can be modeled with

214
00:12:42,268 --> 00:12:45,370
models of the structures like we've seen

215
00:12:45,440 --> 00:12:49,142
before. And they're

216
00:12:49,286 --> 00:12:50,586
saying, we're not trying to write a

217
00:12:50,608 --> 00:12:54,380
neuro textbook here, but to touch

218
00:12:54,770 --> 00:12:56,494
kind of like with both feet, the

219
00:12:56,532 --> 00:12:58,270
empirical modeling.

220
00:13:00,050 --> 00:13:02,254
And then the systems that they are going

221
00:13:02,292 --> 00:13:06,506
to model are like effector systems.

222
00:13:06,618 --> 00:13:10,734
So motor control subcortical structures

223
00:13:10,782 --> 00:13:13,090
like the thalamus and basal ganglia.

224
00:13:15,670 --> 00:13:19,166
So these are more like functional

225
00:13:19,198 --> 00:13:20,680
outcomes of the nervous system.

226
00:13:21,050 --> 00:13:23,526
Specific anatomical structures of

227
00:13:23,548 --> 00:13:25,906
interest, modulation of synaptic

228
00:13:25,938 --> 00:13:29,062
efficiency or efficacy, which is like a

229
00:13:29,116 --> 00:13:31,606
micro anatomical or like a

230
00:13:31,628 --> 00:13:35,686
neurophysiological mechanism of

231
00:13:35,708 --> 00:13:38,566
interest and something that is an

232
00:13:38,588 --> 00:13:40,202
important, like, leverage point and

233
00:13:40,256 --> 00:13:41,946
something that is being modified and

234
00:13:41,968 --> 00:13:43,002
found to be changed in different

235
00:13:43,056 --> 00:13:46,494
situations. And then the

236
00:13:46,532 --> 00:13:48,094
relationship between decision making and

237
00:13:48,132 --> 00:13:50,814
movement generation, which is also

238
00:13:50,852 --> 00:13:54,894
something that has come up in those 46

239
00:13:55,012 --> 00:13:57,566
live streams on like motor active

240
00:13:57,598 --> 00:13:58,878
inference, decision making, active

241
00:13:58,894 --> 00:13:59,730
inference.

242
00:14:07,110 --> 00:14:08,738
Let's check if there's any questions

243
00:14:08,824 --> 00:14:09,570
written.

244
00:14:11,450 --> 00:14:12,200
Okay.

245
00:14:15,850 --> 00:14:19,890
What could anyone say about the cortical

246
00:14:19,970 --> 00:14:23,820
layers or what was in figure 5.1?

247
00:14:28,310 --> 00:14:31,554
Mike. I was

248
00:14:31,592 --> 00:14:35,458
just observing that in the

249
00:14:35,464 --> 00:14:36,786
start of chapter four, they said, well,

250
00:14:36,808 --> 00:14:38,410
you can skip this chapter if you don't

251
00:14:38,430 --> 00:14:40,534
want to get deep into the math. And then

252
00:14:40,652 --> 00:14:43,954
here we are at section 52 in chapter

253
00:14:44,002 --> 00:14:46,326
five, I think, and they refer back to

254
00:14:46,348 --> 00:14:50,134
the message passing structure

255
00:14:50,182 --> 00:14:51,980
that was set up in chapter four.

256
00:14:54,190 --> 00:14:56,140
Yes, good point.

257
00:15:02,110 --> 00:15:05,680
And it's like, well, if you can skip the

258
00:15:06,690 --> 00:15:09,006
details of the formalism to look at the

259
00:15:09,028 --> 00:15:11,390
examples or you could skip the examples.

260
00:15:14,210 --> 00:15:18,286
Any linear text, 140 characters

261
00:15:18,318 --> 00:15:20,466
or textbook or a live stream or

262
00:15:20,488 --> 00:15:21,906
anything, it's always going to be some

263
00:15:21,928 --> 00:15:24,740
sort of linear presentation question.

264
00:15:25,510 --> 00:15:30,358
And with a densely linked and

265
00:15:30,444 --> 00:15:33,206
interdisciplinary area, then the

266
00:15:33,228 --> 00:15:36,422
linearity becomes challenging. So maybe

267
00:15:36,476 --> 00:15:40,522
with more with some notebooks or

268
00:15:40,576 --> 00:15:43,802
some other rendering or educational way

269
00:15:43,856 --> 00:15:47,098
to have the ordering or have,

270
00:15:47,184 --> 00:15:48,602
of course, the connections between

271
00:15:48,656 --> 00:15:50,540
sections be a little bit different.

272
00:15:52,030 --> 00:15:54,666
The first system that they're focusing

273
00:15:54,698 --> 00:15:58,350
on is the cortical column. Does anyone

274
00:15:58,420 --> 00:16:02,394
have anything to add on cortical layers

275
00:16:02,442 --> 00:16:04,638
or the role of the cortex, even if it's

276
00:16:04,644 --> 00:16:06,260
just something that they've heard about?

277
00:16:23,450 --> 00:16:27,346
Well, I think that this Menta

278
00:16:27,458 --> 00:16:31,142
line of AI and many

279
00:16:31,196 --> 00:16:33,660
of the other Ali go for it. Yes.

280
00:16:36,510 --> 00:16:40,266
I want to say that for

281
00:16:40,288 --> 00:16:43,950
the past couple of decades, or probably

282
00:16:44,100 --> 00:16:47,134
several decades, cortex has

283
00:16:47,172 --> 00:16:49,694
traditionally been thought of as the

284
00:16:49,732 --> 00:16:53,290
seat of both consciousness intelligence

285
00:16:53,370 --> 00:16:55,650
and also, of course, cognition. But

286
00:16:55,800 --> 00:16:57,794
recent studies have shown that

287
00:16:57,912 --> 00:17:01,234
especially studies such as

288
00:17:01,272 --> 00:17:04,818
Mark Som's research has shown that in

289
00:17:04,824 --> 00:17:08,440
fact, consciousness actually stems from

290
00:17:09,290 --> 00:17:11,800
literally the brain stem, not

291
00:17:13,210 --> 00:17:16,326
necessarily the cortex. So there are

292
00:17:16,348 --> 00:17:18,870
some challenges about the exact function

293
00:17:18,940 --> 00:17:22,922
of cortex, and the

294
00:17:22,976 --> 00:17:24,860
debate goes on.

295
00:17:29,650 --> 00:17:33,054
Nice. Okay, here's a little bit on the

296
00:17:33,092 --> 00:17:36,802
cortex. So it is the outer frontal part

297
00:17:36,856 --> 00:17:39,410
of the mammalian style brain.

298
00:17:40,070 --> 00:17:42,770
Insects don't have cortex,

299
00:17:44,310 --> 00:17:45,682
though they share a lot of the same

300
00:17:45,736 --> 00:17:48,102
architectures and so on. So this is like

301
00:17:48,156 --> 00:17:51,414
neuron tracing. And there's kind of two

302
00:17:51,452 --> 00:17:53,654
levels of organization that people are

303
00:17:53,692 --> 00:17:56,294
modeling in the cortical models. The

304
00:17:56,332 --> 00:17:59,362
first is based upon the histological

305
00:17:59,426 --> 00:18:01,610
observation of the layers.

306
00:18:02,430 --> 00:18:05,098
These are six layers of cells, and

307
00:18:05,104 --> 00:18:06,986
there's a lot of development and all

308
00:18:07,088 --> 00:18:08,458
different functionality between the

309
00:18:08,464 --> 00:18:11,146
different layers. One important thing to

310
00:18:11,168 --> 00:18:13,626
note is it's not that they're like the

311
00:18:13,648 --> 00:18:16,014
layers of a Bayesian hierarchical model.

312
00:18:16,212 --> 00:18:18,318
It's not like each one is like up and

313
00:18:18,324 --> 00:18:19,838
down, up and down. So this isn't like a

314
00:18:19,844 --> 00:18:21,434
predictive processing architecture

315
00:18:21,482 --> 00:18:24,970
happening simply with these six layers.

316
00:18:25,050 --> 00:18:28,482
This is not a six layer model. In fact,

317
00:18:28,536 --> 00:18:30,382
they're connected to each other sparsely

318
00:18:30,446 --> 00:18:32,514
within a column, as it's shown here in

319
00:18:32,552 --> 00:18:36,050
5.1. So that's like the micro anatomical

320
00:18:36,550 --> 00:18:39,206
structure of the cortical column. And

321
00:18:39,228 --> 00:18:40,518
it's called a column because it's like

322
00:18:40,524 --> 00:18:43,254
the layers are also arranged in this

323
00:18:43,292 --> 00:18:46,566
repeating way. And there's just like a

324
00:18:46,588 --> 00:18:50,282
lot of different layouts for

325
00:18:50,336 --> 00:18:54,294
different regions of this cortical

326
00:18:54,342 --> 00:18:58,470
tissue type. And in certain situations,

327
00:18:58,550 --> 00:19:02,454
it is organized like linear call

328
00:19:02,512 --> 00:19:06,334
nerve structures, which is often seen as

329
00:19:06,452 --> 00:19:10,442
one of the evolutionary local maxima

330
00:19:10,586 --> 00:19:14,394
of depth of processing and sparsity

331
00:19:14,442 --> 00:19:16,878
of connections laterally. So those are

332
00:19:16,884 --> 00:19:18,594
the two levels of analysis that are

333
00:19:18,632 --> 00:19:20,610
being and as early mentioned, people

334
00:19:20,680 --> 00:19:21,982
yes, have gone to the consciousness

335
00:19:22,046 --> 00:19:24,306
angle or they've just argued that this

336
00:19:24,328 --> 00:19:25,486
is kind of like the massively

337
00:19:25,518 --> 00:19:28,162
paralyzable, but also like deep

338
00:19:28,226 --> 00:19:32,530
recurrent contextual, et cetera.

339
00:19:32,610 --> 00:19:34,806
The anagrams like the patterns that

340
00:19:34,828 --> 00:19:37,106
could be activated. The dimensionality

341
00:19:37,138 --> 00:19:38,678
is potentially super high, so it could

342
00:19:38,684 --> 00:19:41,290
play a role in memory signal processing.

343
00:19:42,270 --> 00:19:44,794
And the two levels that people look at,

344
00:19:44,832 --> 00:19:46,890
the connections between, like,

345
00:19:46,960 --> 00:19:49,962
anatomically by taking these images or

346
00:19:50,016 --> 00:19:52,300
by doing like, stainings and stuff.

347
00:19:53,090 --> 00:19:56,222
Anatomically and functionally is within

348
00:19:56,276 --> 00:19:58,266
the column where there's certain kinds

349
00:19:58,298 --> 00:20:00,478
of relationships, and then across

350
00:20:00,564 --> 00:20:02,302
columns where there are certain kinds of

351
00:20:02,356 --> 00:20:03,470
relationships.

352
00:20:06,690 --> 00:20:09,102
Any thoughts or questions on that? But

353
00:20:09,156 --> 00:20:10,866
that's just why the cortex is being

354
00:20:10,888 --> 00:20:12,066
studied. And that's like a little bit of

355
00:20:12,088 --> 00:20:15,026
how the neuroscientists have been

356
00:20:15,048 --> 00:20:17,358
approaching this and why this is one of

357
00:20:17,384 --> 00:20:18,886
the important systems with a lot of

358
00:20:18,908 --> 00:20:20,914
theoretical modeling and empirical

359
00:20:20,962 --> 00:20:23,560
evidence and relevance as well.

360
00:20:24,330 --> 00:20:27,638
JF I remember

361
00:20:27,724 --> 00:20:30,634
many years ago taking a course in

362
00:20:30,752 --> 00:20:34,906
physiology on the visual cortex and the

363
00:20:34,928 --> 00:20:37,626
whole notion that the brain has some

364
00:20:37,648 --> 00:20:40,826
kind of structure. Always thought it was

365
00:20:40,848 --> 00:20:43,726
fascinating because I feel that the

366
00:20:43,748 --> 00:20:46,506
brain is a huge hack, patches upon

367
00:20:46,538 --> 00:20:48,350
patches upon patches, broadened by

368
00:20:48,420 --> 00:20:50,734
evolution and that there would be some

369
00:20:50,772 --> 00:20:54,494
structure in it is

370
00:20:54,532 --> 00:20:56,066
interesting. But within those

371
00:20:56,088 --> 00:20:59,346
structures, this picture shows

372
00:20:59,528 --> 00:21:01,870
it's very messy. I would never implement

373
00:21:01,950 --> 00:21:05,070
a system with this kind of wild

374
00:21:05,150 --> 00:21:10,226
interconnectivity. So I'm

375
00:21:10,258 --> 00:21:14,118
very curious about how much we can

376
00:21:14,284 --> 00:21:18,440
infer from what is really a

377
00:21:19,130 --> 00:21:21,938
mildly structured but highly messy

378
00:21:22,114 --> 00:21:26,022
architecture in terms of process theory

379
00:21:26,086 --> 00:21:30,646
that we're trying to elucidate

380
00:21:30,838 --> 00:21:33,726
from anatomy and the functionality of

381
00:21:33,748 --> 00:21:37,150
the brain. Nice. Thank you. Mike.

382
00:21:39,170 --> 00:21:41,278
Yeah. That makes me think that some of

383
00:21:41,284 --> 00:21:43,854
that messiness is in support of

384
00:21:43,892 --> 00:21:47,826
redundancy. And so how do we think about

385
00:21:47,928 --> 00:21:50,462
redundancies in systems in the context

386
00:21:50,526 --> 00:21:52,210
of active inference?

387
00:21:55,350 --> 00:21:57,058
Yeah. And like, neural systems, of

388
00:21:57,064 --> 00:21:59,174
course, have amazing, in some

389
00:21:59,212 --> 00:22:01,314
dimensions, ability to have redundancy.

390
00:22:01,362 --> 00:22:03,174
Other times, seemingly, there's points

391
00:22:03,212 --> 00:22:06,790
of failure. Jeff okay.

392
00:22:06,940 --> 00:22:10,082
All right. So just on the left side

393
00:22:10,156 --> 00:22:13,814
sorry. On the comment

394
00:22:13,862 --> 00:22:15,846
about redundancy. I agree. But it's

395
00:22:15,878 --> 00:22:19,706
worse than that. Every part often

396
00:22:19,808 --> 00:22:22,470
plays many different roles and

397
00:22:22,560 --> 00:22:24,362
participate in different functions,

398
00:22:24,426 --> 00:22:27,614
which makes it quite a tangle in terms

399
00:22:27,652 --> 00:22:30,958
of functional analysis of parts of the

400
00:22:30,964 --> 00:22:33,390
brain and what they do and whatnot.

401
00:22:35,830 --> 00:22:40,258
So five one is showing a

402
00:22:40,424 --> 00:22:44,174
more like pure Bayes

403
00:22:44,222 --> 00:22:48,214
graph with

404
00:22:48,252 --> 00:22:51,190
the annotation of the kinds of cells

405
00:22:51,610 --> 00:22:54,454
that are in the anatomical layer. So

406
00:22:54,492 --> 00:22:57,606
this is like a visualization of the

407
00:22:57,628 --> 00:22:59,494
anatomy based upon the regions that it

408
00:22:59,532 --> 00:23:01,978
connects, gets inputs and outputs from,

409
00:23:02,144 --> 00:23:05,494
and then the micro anatomy labeled

410
00:23:05,542 --> 00:23:10,506
according to cell types. Then with

411
00:23:10,688 --> 00:23:13,526
a similar but not exactly concordant.

412
00:23:13,558 --> 00:23:15,274
There's not a statistical test proposed

413
00:23:15,322 --> 00:23:17,518
for how concordant these are. It's not a

414
00:23:17,524 --> 00:23:19,546
statistical argument. It's not exclusive

415
00:23:19,578 --> 00:23:21,706
of other framings of what this anatomy

416
00:23:21,738 --> 00:23:24,762
is doing. Here are labeled with

417
00:23:24,836 --> 00:23:27,966
different parameters from the Bayes

418
00:23:27,998 --> 00:23:29,666
graph architectures that have been

419
00:23:29,688 --> 00:23:31,438
explored in the previous chapters,

420
00:23:31,614 --> 00:23:33,806
compatible with message passing

421
00:23:33,918 --> 00:23:36,274
implementations that other papers have

422
00:23:36,312 --> 00:23:38,886
addressed that aren't here. These are

423
00:23:38,908 --> 00:23:41,670
like architectures that recapitulate

424
00:23:42,410 --> 00:23:46,594
some of the functional and macro,

425
00:23:46,722 --> 00:23:50,190
structural and microstructural aspects.

426
00:23:50,370 --> 00:23:51,910
So this is like computational

427
00:23:51,990 --> 00:23:55,578
neuroscience, and it's using

428
00:23:55,664 --> 00:23:58,026
these models that actually have an

429
00:23:58,048 --> 00:24:01,686
underlying structure that is providing

430
00:24:01,718 --> 00:24:05,674
utility and interesting reframings

431
00:24:05,722 --> 00:24:07,070
of the anatomy.

432
00:24:09,410 --> 00:24:12,714
And as the model statistical

433
00:24:12,762 --> 00:24:14,838
architecture begins to recapitulate

434
00:24:14,874 --> 00:24:18,930
aspects of the Cyto architecture,

435
00:24:19,750 --> 00:24:21,986
there's like no specific threshold where

436
00:24:22,008 --> 00:24:23,154
it's like, oh, well, now it's like an

437
00:24:23,192 --> 00:24:25,460
argument that it's doing that function.

438
00:24:26,950 --> 00:24:30,722
Like people get tantalized

439
00:24:30,786 --> 00:24:32,854
by it having some, oh, well, we made

440
00:24:32,892 --> 00:24:35,266
this network structured like a brain,

441
00:24:35,378 --> 00:24:37,510
or we made this network structured like

442
00:24:37,580 --> 00:24:40,754
a mushroom, or we did the ant colony

443
00:24:40,802 --> 00:24:43,938
optimization. So just because

444
00:24:44,044 --> 00:24:46,566
this works for what it does, doesn't

445
00:24:46,598 --> 00:24:49,946
mean this works for what anyone wants it

446
00:24:49,968 --> 00:24:52,814
to do. It's just in this huge space of

447
00:24:52,852 --> 00:24:55,230
bioinspired model architectures.

448
00:24:59,010 --> 00:25:02,654
In five,

449
00:25:02,692 --> 00:25:04,286
two, they move a little bit from the

450
00:25:04,308 --> 00:25:06,734
consideration of the columnar

451
00:25:06,782 --> 00:25:08,450
architecture, which are cell

452
00:25:08,520 --> 00:25:12,434
populations, to looking now

453
00:25:12,472 --> 00:25:14,594
like still the superficial to deep are

454
00:25:14,632 --> 00:25:18,146
the six layers of the cortex. But now a

455
00:25:18,168 --> 00:25:20,354
few of the variables are highlighted and

456
00:25:20,392 --> 00:25:24,520
their relationships. And so the

457
00:25:26,970 --> 00:25:28,706
ascending and descending prediction

458
00:25:28,738 --> 00:25:30,406
error in a predictive processing

459
00:25:30,438 --> 00:25:32,582
framework which is often graphically

460
00:25:32,646 --> 00:25:35,466
seen going up and down, bottom up and

461
00:25:35,488 --> 00:25:38,634
top down effects. Here is being

462
00:25:38,672 --> 00:25:41,210
shown in the context of the columnar

463
00:25:41,710 --> 00:25:45,606
cortex where like errors

464
00:25:45,798 --> 00:25:49,760
from one. Let's just go to where they

465
00:25:51,250 --> 00:25:55,602
the E's are the errors and

466
00:25:55,656 --> 00:26:00,580
the G's are predictions and

467
00:26:01,350 --> 00:26:03,154
I guess we can find out what Mu is. But

468
00:26:03,192 --> 00:26:05,038
basically, like, this architecture

469
00:26:05,134 --> 00:26:08,774
within and between columns could

470
00:26:08,812 --> 00:26:12,070
be like this being like the base

471
00:26:12,140 --> 00:26:14,934
variable being estimated and a

472
00:26:14,972 --> 00:26:16,838
hierarchical nested model of that. And a

473
00:26:16,844 --> 00:26:19,698
hierarchical model of that. So there's

474
00:26:19,714 --> 00:26:21,382
like a generalization statistical

475
00:26:21,446 --> 00:26:24,758
architecture that has compatibility

476
00:26:24,854 --> 00:26:26,666
with the neural architecture of the

477
00:26:26,688 --> 00:26:29,766
brain and it does like a pure

478
00:26:29,798 --> 00:26:32,758
statistical function. And that pure

479
00:26:32,774 --> 00:26:34,634
statistical function has resemblance

480
00:26:34,682 --> 00:26:36,570
with some things that the brain region

481
00:26:36,650 --> 00:26:40,446
is believed to do. So that

482
00:26:40,628 --> 00:26:42,814
allows this statistical model to be

483
00:26:42,852 --> 00:26:45,950
explaining and predicting and useful

484
00:26:46,110 --> 00:26:48,034
about the brain, which is like what

485
00:26:48,072 --> 00:26:49,860
computational neuroscience does.

486
00:26:55,810 --> 00:27:06,706
So that was the first one

487
00:27:06,728 --> 00:27:09,940
of the systems that they focus on then.

488
00:27:10,790 --> 00:27:15,554
Yeah, I guess this was then

489
00:27:15,592 --> 00:27:17,266
the factor systems. Okay, let's see if

490
00:27:17,288 --> 00:27:19,222
we can kind of quickly look at all the

491
00:27:19,276 --> 00:27:20,150
systems.

492
00:27:25,320 --> 00:27:28,836
What did anyone see or what would

493
00:27:28,858 --> 00:27:30,532
they like to say about figure five?

494
00:27:30,586 --> 00:27:33,736
Three neuroanatomy associated with

495
00:27:33,758 --> 00:27:35,716
active inference in modulating spinal

496
00:27:35,748 --> 00:27:37,080
motor reflexes.

497
00:27:52,830 --> 00:27:55,942
Okay, so five one

498
00:27:56,016 --> 00:27:59,054
was the columnar architecture and that

499
00:27:59,092 --> 00:28:01,822
was described in terms of what cell

500
00:28:01,876 --> 00:28:05,406
types were in it. Here they're going

501
00:28:05,428 --> 00:28:08,038
to pick up on one of those cell types,

502
00:28:08,234 --> 00:28:10,366
which is like the computational role.

503
00:28:10,478 --> 00:28:14,482
The expectations encoded by this

504
00:28:14,616 --> 00:28:18,110
cell type that's found in this layer

505
00:28:18,270 --> 00:28:22,102
of the motor cortex. And so different

506
00:28:22,156 --> 00:28:24,040
regions of the cortex have different

507
00:28:24,410 --> 00:28:28,146
apparent functions asterisk,

508
00:28:28,178 --> 00:28:30,598
asterisk, asterisk, but there's like a

509
00:28:30,604 --> 00:28:32,566
visual cortex and a motor cortex and so

510
00:28:32,588 --> 00:28:35,354
on. So this is in a motor region of

511
00:28:35,392 --> 00:28:38,586
cortical architecture that plays a

512
00:28:38,608 --> 00:28:40,460
certain biological function.

513
00:28:43,790 --> 00:28:45,946
The expectations are subtracted from the

514
00:28:45,968 --> 00:28:49,374
incoming proprioceptive input in

515
00:28:49,412 --> 00:28:51,662
the horn of a spinal cord. This is like

516
00:28:51,716 --> 00:28:53,598
lateral cut through a spinal cord. The

517
00:28:53,604 --> 00:28:56,270
horns are like the butterfly parts.

518
00:28:58,370 --> 00:29:00,546
And so there's a difference in between

519
00:29:00,648 --> 00:29:04,446
the incoming intensity of proprioception

520
00:29:04,638 --> 00:29:08,850
and the brain expected expectations

521
00:29:09,670 --> 00:29:11,550
and then the error drives muscle

522
00:29:11,630 --> 00:29:14,134
activity in the direction of

523
00:29:14,172 --> 00:29:17,526
suppression. So the motor activity is,

524
00:29:17,548 --> 00:29:20,066
like, reducing the divergence based upon

525
00:29:20,098 --> 00:29:25,530
the sign and the intensity of

526
00:29:25,680 --> 00:29:28,694
the compromise between the brain's

527
00:29:28,742 --> 00:29:32,326
expectations potentially arising

528
00:29:32,358 --> 00:29:34,042
within, like, layer five from these bet

529
00:29:34,096 --> 00:29:38,186
cells and the incoming sensory

530
00:29:38,298 --> 00:29:40,734
information, which can be modeled as,

531
00:29:40,772 --> 00:29:41,680
like, why?

532
00:29:45,680 --> 00:29:47,612
I think Mu is probably the mean of that

533
00:29:47,666 --> 00:29:48,540
expectation.

534
00:29:52,240 --> 00:29:54,450
I don't know what part it was mentioned.

535
00:29:55,060 --> 00:29:58,336
And then here's the expectation, the

536
00:29:58,518 --> 00:30:00,736
difference between these two. It's like

537
00:30:00,758 --> 00:30:02,304
a causal system flow, but, like a little

538
00:30:02,342 --> 00:30:05,216
different. You're getting a five out of

539
00:30:05,238 --> 00:30:07,104
ten pressure, you're expecting a five

540
00:30:07,142 --> 00:30:09,396
out of ten pressure. The motor reflex is

541
00:30:09,418 --> 00:30:11,556
not engaged. You're getting a seven out

542
00:30:11,578 --> 00:30:13,204
of ten pressure, you're expecting five

543
00:30:13,242 --> 00:30:15,684
out of ten. There's, like a negative two

544
00:30:15,722 --> 00:30:17,816
difference or whichever way you want to

545
00:30:17,838 --> 00:30:19,848
be subtracting, there's like a two or a

546
00:30:19,854 --> 00:30:21,992
negative two difference. And then that

547
00:30:22,046 --> 00:30:24,776
triggers some motor neuron units to

548
00:30:24,798 --> 00:30:28,404
fire. And then that proportionally

549
00:30:28,532 --> 00:30:32,220
brings the expectation

550
00:30:32,640 --> 00:30:34,700
into alignment with the measurement.

551
00:30:41,150 --> 00:30:44,318
Um, they're gonna just like that example

552
00:30:44,404 --> 00:30:47,662
hinged from a cortical layer. And cell

553
00:30:47,716 --> 00:30:50,954
type here is going to be hinging

554
00:30:51,002 --> 00:30:53,658
on the cortex and looking to an output

555
00:30:53,754 --> 00:30:55,390
region of the cortex,

556
00:30:56,690 --> 00:31:00,526
which is the striatum. And then they're

557
00:31:00,558 --> 00:31:02,738
going to do a more detailed model of a

558
00:31:02,744 --> 00:31:04,894
basal ganglia because it's been modeled

559
00:31:04,942 --> 00:31:06,626
a lot more and then also have, like,

560
00:31:06,648 --> 00:31:08,998
just a textual treatment of the

561
00:31:09,004 --> 00:31:13,282
thalamus. There's multiple

562
00:31:13,346 --> 00:31:16,502
papers on dopamine and

563
00:31:16,556 --> 00:31:21,764
active inference and

564
00:31:21,802 --> 00:31:25,828
so from 2012 and then

565
00:31:25,994 --> 00:31:29,512
2015. This is a really

566
00:31:29,566 --> 00:31:33,592
interesting area of research with

567
00:31:33,646 --> 00:31:36,636
Dopamine because Dopamine is,

568
00:31:36,658 --> 00:31:39,356
like, classically described as the

569
00:31:39,378 --> 00:31:42,636
reward molecule. More reward, more

570
00:31:42,658 --> 00:31:45,260
dopamine, lower reward, lower dopamine.

571
00:31:46,640 --> 00:31:49,950
So isn't the whole

572
00:31:50,560 --> 00:31:53,216
meme inactive that we replace the

573
00:31:53,238 --> 00:31:56,080
reinforcement reward learning paradigm

574
00:31:56,420 --> 00:32:00,372
with a different imperative that

575
00:32:00,426 --> 00:32:02,432
has elements that reflect pragmatic

576
00:32:02,496 --> 00:32:07,380
value, but that isn't the overarching

577
00:32:09,560 --> 00:32:11,924
imperative for policy selection. And so

578
00:32:11,962 --> 00:32:14,984
these papers show how, like in the

579
00:32:15,022 --> 00:32:18,792
context of a generative model with

580
00:32:18,846 --> 00:32:20,792
expectations and preferences and

581
00:32:20,846 --> 00:32:23,816
Dopamine signaling something related to

582
00:32:23,838 --> 00:32:25,980
the predictive processing of stimuli

583
00:32:26,560 --> 00:32:29,784
under a mildly optimistic

584
00:32:29,832 --> 00:32:33,384
world model, good events and surprising

585
00:32:33,432 --> 00:32:34,796
events are still associated with

586
00:32:34,818 --> 00:32:36,140
Dopamine release.

587
00:32:37,700 --> 00:32:39,056
And things that are going worse than

588
00:32:39,078 --> 00:32:40,640
expected are still associated with

589
00:32:40,710 --> 00:32:45,360
Dopamine drops. But that

590
00:32:45,430 --> 00:32:47,616
actually is, like, a more unified way to

591
00:32:47,638 --> 00:32:52,180
talk about Dopamine's empirical outcomes

592
00:32:53,080 --> 00:32:55,572
as opposed to the reward learning,

593
00:32:55,626 --> 00:32:58,884
which has to hypothesize all of these

594
00:32:59,082 --> 00:33:01,216
modules that translate different kinds

595
00:33:01,248 --> 00:33:03,540
of things into reward. Jessica.

596
00:33:05,960 --> 00:33:08,436
Yeah, I think similarly to these I don't

597
00:33:08,468 --> 00:33:12,664
remember where I read this, but the

598
00:33:12,702 --> 00:33:15,428
brain in regards to the dopamine

599
00:33:15,524 --> 00:33:17,772
comment, it's also, like the

600
00:33:17,826 --> 00:33:21,740
anticipation of doing something

601
00:33:21,810 --> 00:33:23,484
and the fact that you're going to get

602
00:33:23,522 --> 00:33:24,940
that Dopamine kick.

603
00:33:27,600 --> 00:33:29,372
Basically, you get a release by

604
00:33:29,426 --> 00:33:32,368
anticipating something. And that maybe a

605
00:33:32,374 --> 00:33:35,116
little bit connects also with the active

606
00:33:35,148 --> 00:33:37,072
inference, the fact that you are

607
00:33:37,126 --> 00:33:41,252
anticipating something. You expect that

608
00:33:41,306 --> 00:33:43,792
to happen. And so you get that release

609
00:33:43,856 --> 00:33:46,356
of the dopamine in anticipation of the

610
00:33:46,378 --> 00:33:49,616
event happening. I don't

611
00:33:49,648 --> 00:33:51,812
know much, but I'm thinking it could be

612
00:33:51,866 --> 00:33:55,076
connected with having a predictive

613
00:33:55,188 --> 00:33:57,450
unexpected free energy or something.

614
00:33:58,380 --> 00:34:01,000
Nice. Good insight, Rohan.

615
00:34:03,580 --> 00:34:07,164
Yeah, well,

616
00:34:07,202 --> 00:34:09,724
I'm not a biologist, but okay, so I just

617
00:34:09,762 --> 00:34:13,176
want to clarify. There are other systems

618
00:34:13,208 --> 00:34:15,864
in the body apart from just the brain

619
00:34:15,912 --> 00:34:18,284
alone, right? So you have like the

620
00:34:18,322 --> 00:34:21,536
autonomous or what is

621
00:34:21,558 --> 00:34:24,224
it, parasympathetic nervous system that

622
00:34:24,262 --> 00:34:26,784
controls your heart rate, your

623
00:34:26,822 --> 00:34:28,450
aspiration and other things.

624
00:34:29,800 --> 00:34:32,996
Also you have stuff like adrenaline and

625
00:34:33,018 --> 00:34:37,300
noradrenaline that do produce responses

626
00:34:37,800 --> 00:34:40,064
and other hormones also that produce

627
00:34:40,112 --> 00:34:43,096
responses like for hunger or

628
00:34:43,198 --> 00:34:46,904
satisfaction. And we basically have

629
00:34:46,942 --> 00:34:48,632
figured out how to modulate these things

630
00:34:48,686 --> 00:34:52,504
to solve modern issues for things

631
00:34:52,542 --> 00:34:54,152
like obesity or something like that.

632
00:34:54,206 --> 00:34:56,108
And there are treatments available that

633
00:34:56,194 --> 00:34:59,150
modify these hormones levels. Right. So

634
00:35:00,320 --> 00:35:02,872
is this not a very limiting perspective

635
00:35:02,936 --> 00:35:06,092
to look at dopamine alone as the only

636
00:35:06,146 --> 00:35:08,732
thing? And my other question would be

637
00:35:08,786 --> 00:35:12,216
how does that convert into, say, motor

638
00:35:12,248 --> 00:35:14,504
commands? So I just increased dopamine

639
00:35:14,552 --> 00:35:17,100
levels without any stimulus whatsoever.

640
00:35:17,600 --> 00:35:20,036
Let's say someone's taking a drug. It

641
00:35:20,058 --> 00:35:23,520
would. So that does not necessarily

642
00:35:23,600 --> 00:35:25,844
translate to a motor command. Right. So

643
00:35:25,882 --> 00:35:28,676
how does it do this? Is there like a

644
00:35:28,698 --> 00:35:31,604
specialized system that figures out

645
00:35:31,642 --> 00:35:35,636
okay, so here's the previous action

646
00:35:35,748 --> 00:35:38,084
here's increase in dopamine and here's

647
00:35:38,132 --> 00:35:40,644
how we modulate to further increase

648
00:35:40,692 --> 00:35:43,752
dopamine. And where exactly do you set

649
00:35:43,806 --> 00:35:46,270
limits on this process?

650
00:35:46,880 --> 00:35:49,100
Okay, the two questions were about

651
00:35:49,170 --> 00:35:51,356
interacting physiological systems and

652
00:35:51,378 --> 00:35:53,464
the second one was about dopamine's role

653
00:35:53,512 --> 00:35:57,052
in motor selection. Blue, go ahead

654
00:35:57,106 --> 00:36:00,048
if it's related or if you want to

655
00:36:00,054 --> 00:36:02,096
address anything. Yeah, no, I just

656
00:36:02,118 --> 00:36:05,292
wanted to respond. The dopamine response

657
00:36:05,356 --> 00:36:08,896
is there are a lot

658
00:36:08,918 --> 00:36:10,336
of interactions that are happening in

659
00:36:10,358 --> 00:36:12,948
the nervous system. Dopamine is one of

660
00:36:12,954 --> 00:36:15,108
the best understood, I think it's one of

661
00:36:15,114 --> 00:36:17,076
the ones that we've studied for a long

662
00:36:17,098 --> 00:36:20,644
time. And if there's an

663
00:36:20,682 --> 00:36:23,844
overload of dopamine, the action can

664
00:36:23,882 --> 00:36:25,928
actually be nonspecific. And that's what

665
00:36:25,934 --> 00:36:27,988
we see in Parkinson's. Right, so it's

666
00:36:28,004 --> 00:36:30,648
like an overload of dopamine into that

667
00:36:30,814 --> 00:36:33,816
system and it fries it out and then you

668
00:36:33,838 --> 00:36:37,612
get nonspecific action in

669
00:36:37,666 --> 00:36:41,384
the nervous system, motor action,

670
00:36:41,432 --> 00:36:44,844
the tremors and stuff. Yes.

671
00:36:45,042 --> 00:36:49,996
Good call. And that question about non

672
00:36:50,028 --> 00:36:52,016
purposeful behavior and dopamine on the

673
00:36:52,038 --> 00:36:53,344
positive and on the negative, like

674
00:36:53,382 --> 00:36:56,092
failure to engage, initiate action

675
00:36:56,236 --> 00:36:58,416
relating in like catatonic behavior and

676
00:36:58,438 --> 00:37:00,704
then like hypermotor activity associated

677
00:37:00,752 --> 00:37:03,956
with repetitive motions of

678
00:37:03,978 --> 00:37:07,476
various kinds. Dopamine is

679
00:37:07,498 --> 00:37:09,204
known to be different in people who are

680
00:37:09,242 --> 00:37:10,612
experiencing that differently and

681
00:37:10,666 --> 00:37:12,792
modified by drugs that target that

682
00:37:12,926 --> 00:37:16,424
system. But to the first question about

683
00:37:16,542 --> 00:37:18,772
pluralism with respect to physiological

684
00:37:18,836 --> 00:37:21,864
systems, for sure this model does not

685
00:37:21,902 --> 00:37:24,920
exclude that, in fact, its flexibility

686
00:37:25,340 --> 00:37:28,028
is its advantage because the inputs to a

687
00:37:28,034 --> 00:37:30,108
brain region now we could say, well, at

688
00:37:30,114 --> 00:37:31,996
this time scale it's electrochemical and

689
00:37:32,018 --> 00:37:34,270
at this time scale it's going to be just

690
00:37:34,880 --> 00:37:36,812
noradrenaline. And someone says, well,

691
00:37:36,946 --> 00:37:38,716
how could you only model noradrenaline?

692
00:37:38,748 --> 00:37:40,256
Say, okay, let's look at the model with

693
00:37:40,278 --> 00:37:42,096
Noradrenaline and this other one and an

694
00:37:42,118 --> 00:37:45,712
unmodeled component so it will

695
00:37:45,766 --> 00:37:48,624
allow integration formally of

696
00:37:48,822 --> 00:37:51,016
physiological mechanisms that genuinely

697
00:37:51,068 --> 00:37:53,204
interact and as to why people write

698
00:37:53,242 --> 00:37:54,980
like, specific papers about specific

699
00:37:55,130 --> 00:37:59,156
hormone systems. It's just like what is

700
00:37:59,178 --> 00:38:01,396
chunked off in that fractal? And then

701
00:38:01,418 --> 00:38:03,304
also one important note is like,

702
00:38:03,502 --> 00:38:06,024
Colombo and Wright have written about

703
00:38:06,062 --> 00:38:09,256
how we don't need a monolithic theory of

704
00:38:09,278 --> 00:38:10,916
any neurotransmitter or any brain

705
00:38:10,948 --> 00:38:13,304
region. There might be like, features or

706
00:38:13,342 --> 00:38:16,428
components of Dopaminergic systems that

707
00:38:16,514 --> 00:38:18,444
it just explains and predicts that they

708
00:38:18,482 --> 00:38:21,084
do reward, taken lightly, that the

709
00:38:21,122 --> 00:38:22,604
explanation is just, of course, our

710
00:38:22,642 --> 00:38:24,510
explanation of a biological system.

711
00:38:26,560 --> 00:38:28,176
And also you raise like, beyond the

712
00:38:28,198 --> 00:38:31,664
brain there's also glia and other cell

713
00:38:31,702 --> 00:38:34,736
types. So, yeah, the cool thing would be

714
00:38:34,758 --> 00:38:37,436
a framework where we don't a priori

715
00:38:37,468 --> 00:38:40,356
exclude factors that are important, but

716
00:38:40,378 --> 00:38:42,836
just to kind of go quickly through the

717
00:38:42,858 --> 00:38:47,440
example and get to that motor action.

718
00:38:47,600 --> 00:38:50,432
So this is an output from some putative

719
00:38:50,496 --> 00:38:52,604
processing that happened in the cortex

720
00:38:52,752 --> 00:38:55,336
and now it's projecting into some

721
00:38:55,358 --> 00:38:59,460
Dopaminergic regions in the subcortical

722
00:38:59,540 --> 00:39:02,440
area, like the basal ganglia.

723
00:39:04,460 --> 00:39:07,160
It's going to be a model involving

724
00:39:07,240 --> 00:39:10,156
outcomes. O, the difference between the

725
00:39:10,178 --> 00:39:11,944
preferred and the expected outcomes.

726
00:39:12,072 --> 00:39:14,972
The sigma squiggle expected free energy

727
00:39:15,026 --> 00:39:18,152
evaluated for a policy and the posterior

728
00:39:18,216 --> 00:39:23,084
over policies. The bold pi the

729
00:39:23,122 --> 00:39:25,136
figure is like shown after a lot of the

730
00:39:25,158 --> 00:39:29,280
description, but here

731
00:39:29,350 --> 00:39:30,996
is where they refer to the high and low

732
00:39:31,018 --> 00:39:33,812
Dopamine state. So also the movie book

733
00:39:33,866 --> 00:39:37,750
Awakenings is about people who have

734
00:39:38,120 --> 00:39:39,988
atypical Dopamine signaling and then

735
00:39:39,994 --> 00:39:41,908
they're given L DOPA and they come and

736
00:39:41,994 --> 00:39:43,704
get reinvived with life and stuff.

737
00:39:43,822 --> 00:39:44,760
Rohan.

738
00:39:47,580 --> 00:39:51,016
Yeah, well, this is a

739
00:39:51,038 --> 00:39:54,184
little more general, but okay, so we

740
00:39:54,222 --> 00:39:56,316
have the Marco blanket and there are

741
00:39:56,338 --> 00:39:58,360
some internal states. And the Marco

742
00:39:58,440 --> 00:40:00,956
blanket basically connects us to the

743
00:40:00,978 --> 00:40:04,808
external states. Right. Or samples

744
00:40:04,824 --> 00:40:06,540
from the external states and then

745
00:40:06,690 --> 00:40:08,208
modulates the internal states

746
00:40:08,294 --> 00:40:10,800
accordingly. Okay,

747
00:40:10,870 --> 00:40:14,704
so my question is, I think if

748
00:40:14,742 --> 00:40:18,140
the first imperative is survival

749
00:40:18,300 --> 00:40:22,004
and the first imperative is to keep this

750
00:40:22,042 --> 00:40:24,432
system in homeostasis, which is composed

751
00:40:24,496 --> 00:40:27,424
of multiple interlocking and interacting

752
00:40:27,472 --> 00:40:29,110
complex components, right?

753
00:40:31,880 --> 00:40:35,160
How exactly would you translate these

754
00:40:35,230 --> 00:40:38,792
multiple signaling modalities with

755
00:40:38,846 --> 00:40:42,244
multiple hormones into maintaining

756
00:40:42,292 --> 00:40:43,864
homeostasis with something like free

757
00:40:43,902 --> 00:40:46,956
energy? Because some of these things are

758
00:40:47,058 --> 00:40:50,476
compatible entirely. You would have

759
00:40:50,498 --> 00:40:52,136
to have some sort of translation

760
00:40:52,168 --> 00:40:54,412
mechanism. Right? So let's say that

761
00:40:54,466 --> 00:40:57,564
adrenaline is jumping really high and

762
00:40:57,602 --> 00:40:59,884
into dangerously high levels, but we

763
00:40:59,922 --> 00:41:02,144
only know it's dangerous because there

764
00:41:02,182 --> 00:41:04,524
is some system that is able to predict

765
00:41:04,572 --> 00:41:07,104
that. Okay, it should not go above this

766
00:41:07,142 --> 00:41:08,624
level because it's going to screw up

767
00:41:08,662 --> 00:41:11,590
something else in the system. Right.

768
00:41:12,920 --> 00:41:15,572
Multi scale optimization and not over

769
00:41:15,626 --> 00:41:17,956
optimizing one lower level parameter at

770
00:41:17,978 --> 00:41:19,984
the cost of some higher order parameter.

771
00:41:20,112 --> 00:41:22,536
Yeah, but then you come to the curse of

772
00:41:22,558 --> 00:41:25,432
dimensionality. So how many different

773
00:41:25,486 --> 00:41:26,952
things are you going to take up before

774
00:41:27,006 --> 00:41:28,600
it comes completely useless?

775
00:41:29,260 --> 00:41:31,204
Absolutely. Good question. Empirical

776
00:41:31,252 --> 00:41:33,892
question about what computational

777
00:41:33,956 --> 00:41:35,928
hardware, what measurement data sets?

778
00:41:36,024 --> 00:41:38,828
What sparsity of system graph? What

779
00:41:38,914 --> 00:41:41,772
extent of application of heuristics how

780
00:41:41,826 --> 00:41:43,756
accurate you need that model to be in

781
00:41:43,778 --> 00:41:46,524
the empirical setting. None of it in

782
00:41:46,562 --> 00:41:51,324
principle addressed

783
00:41:51,372 --> 00:41:54,364
by just the equations, all of it related

784
00:41:54,412 --> 00:41:56,336
to how they're actually implemented at

785
00:41:56,358 --> 00:41:59,264
what scale, just to quickly complete

786
00:41:59,382 --> 00:42:02,116
through here though, this is about the

787
00:42:02,138 --> 00:42:06,180
depletion of dopamine is being observed

788
00:42:06,520 --> 00:42:08,950
creating this akinesia failure to move

789
00:42:09,400 --> 00:42:11,296
and exogenous dopamine promotes

790
00:42:11,328 --> 00:42:12,884
impulsive behaviors of multiple

791
00:42:12,932 --> 00:42:14,440
different kinds.

792
00:42:16,780 --> 00:42:19,370
This is what it looks like.

793
00:42:20,700 --> 00:42:23,784
Dopamine, as again stated here is

794
00:42:23,982 --> 00:42:26,428
balancing modulating the balance as a

795
00:42:26,434 --> 00:42:29,436
neuromodulator between inferring what to

796
00:42:29,458 --> 00:42:33,388
do and what not to do. And so these two

797
00:42:33,474 --> 00:42:37,080
graphs, both of them are getting

798
00:42:37,250 --> 00:42:40,960
outcomes from the cerebral cortex of

799
00:42:41,030 --> 00:42:43,216
the observations expected under a

800
00:42:43,238 --> 00:42:45,436
policy. So those could be considered

801
00:42:45,468 --> 00:42:47,724
like predictions about future sensory

802
00:42:47,772 --> 00:42:51,110
states here.

803
00:42:52,520 --> 00:42:56,528
And the gamma is this uncertainty

804
00:42:56,704 --> 00:42:59,300
that's being represented by Dopamine.

805
00:43:00,840 --> 00:43:02,936
In this uncertainty function of

806
00:43:02,958 --> 00:43:03,880
Dopamine.

807
00:43:07,340 --> 00:43:10,376
In. The direct pathway, the policies and

808
00:43:10,398 --> 00:43:12,180
the difference between the preferences

809
00:43:12,260 --> 00:43:14,888
and expectations sigma squiggle with a

810
00:43:14,894 --> 00:43:18,556
tilde are being evaluated as part of the

811
00:43:18,578 --> 00:43:20,968
expected free energy of future policies

812
00:43:21,144 --> 00:43:23,224
and that is resulting in the selection

813
00:43:23,272 --> 00:43:25,948
of policies. So that could be like

814
00:43:26,034 --> 00:43:27,568
thinking through all the chess moves and

815
00:43:27,574 --> 00:43:29,324
then picking the one with the lowest

816
00:43:29,372 --> 00:43:32,876
expected free energy. Here the output

817
00:43:32,908 --> 00:43:36,224
in the indirect pathway feeds into the

818
00:43:36,262 --> 00:43:41,092
prior vector e habit and

819
00:43:41,146 --> 00:43:45,380
then that influences policy through this

820
00:43:45,530 --> 00:43:47,556
acting anatomically proposed through

821
00:43:47,578 --> 00:43:49,748
this other region not defined with a

822
00:43:49,754 --> 00:43:51,428
specific variable. So again, this is not

823
00:43:51,434 --> 00:43:53,576
like saying necessarily even just what

824
00:43:53,598 --> 00:43:55,000
it's doing. This isn't the full model.

825
00:43:55,070 --> 00:43:58,312
The papers read more but that's like the

826
00:43:58,366 --> 00:44:00,984
two pathways of action selection and

827
00:44:01,022 --> 00:44:02,692
it's compatible with the empirical

828
00:44:02,756 --> 00:44:05,016
evidence from pathology and from

829
00:44:05,038 --> 00:44:07,116
pharmacology and genetic studies in

830
00:44:07,138 --> 00:44:11,116
animals other than humans. And this is

831
00:44:11,298 --> 00:44:12,924
how it could be modeled with a base

832
00:44:12,962 --> 00:44:14,924
graph that recapitulates some of the

833
00:44:14,962 --> 00:44:18,608
architecture and the function. Then they

834
00:44:18,694 --> 00:44:20,672
describe the roles of some different

835
00:44:20,726 --> 00:44:24,332
neurotransmitters that have been modeled

836
00:44:24,396 --> 00:44:28,336
in active and

837
00:44:28,358 --> 00:44:31,828
like what kinds of phenomena those

838
00:44:31,914 --> 00:44:35,988
measurements have been used in

839
00:44:36,074 --> 00:44:37,060
models.

840
00:44:39,960 --> 00:44:43,784
And then one last important part,

841
00:44:43,902 --> 00:44:45,236
it was in the section with the basal

842
00:44:45,268 --> 00:44:49,016
ganglia that was talking about

843
00:44:49,118 --> 00:44:51,448
this. So they show the graph of the

844
00:44:51,454 --> 00:44:54,730
basal ganglia and then only in this last

845
00:44:55,040 --> 00:44:57,512
paragraph do they describe the thalamus.

846
00:44:57,656 --> 00:44:59,612
So just say we're just going to do one

847
00:44:59,666 --> 00:45:02,156
paragraph on it but basically the

848
00:45:02,178 --> 00:45:05,564
thalamus has these two divisions and

849
00:45:05,602 --> 00:45:10,060
then they provide the interpretation

850
00:45:10,220 --> 00:45:13,276
that these two divisions of the thalamus

851
00:45:13,468 --> 00:45:16,560
could reflect first and second order

852
00:45:16,630 --> 00:45:22,128
statistics on other types

853
00:45:22,144 --> 00:45:24,340
of senses and policies.

854
00:45:25,640 --> 00:45:30,484
So that's like a

855
00:45:30,522 --> 00:45:33,460
unique prediction that potentially

856
00:45:33,540 --> 00:45:36,904
modeling observed neural responses or

857
00:45:37,022 --> 00:45:40,164
the bold signal from the blood oxygen

858
00:45:40,212 --> 00:45:43,944
use in that region. You'll make

859
00:45:43,982 --> 00:45:46,652
a better model if you fit into these

860
00:45:46,706 --> 00:45:49,452
categories rather than reward or rather

861
00:45:49,506 --> 00:45:51,724
than familiarity or any number of other

862
00:45:51,762 --> 00:45:54,076
criteria. So just simply fitting better

863
00:45:54,178 --> 00:45:57,492
is not the whole substance of validating

864
00:45:57,576 --> 00:46:01,104
the formalisms described earlier but

865
00:46:01,222 --> 00:46:04,480
it's part of the empirical grounding and

866
00:46:04,550 --> 00:46:06,416
examples of unique predictions and

867
00:46:06,438 --> 00:46:08,256
explanations. That are provided by

868
00:46:08,278 --> 00:46:11,248
active inference. But that was the

869
00:46:11,254 --> 00:46:14,980
thalmus part. And then in

870
00:46:15,050 --> 00:46:19,204
this very short section 56, they talk

871
00:46:19,242 --> 00:46:24,408
about how a lot of our interfaces are

872
00:46:24,494 --> 00:46:28,244
continuous like sensory apparatus

873
00:46:28,292 --> 00:46:30,740
and motor apparatus have continuous

874
00:46:30,900 --> 00:46:34,804
aspects. But then in the

875
00:46:34,862 --> 00:46:38,300
cognitive and decision making domains

876
00:46:39,040 --> 00:46:41,720
there's often much more discreteness.

877
00:46:41,800 --> 00:46:43,736
Even if there's multi scale discreteness

878
00:46:43,768 --> 00:46:46,024
resulting in a very finely graded

879
00:46:46,072 --> 00:46:48,832
continuum of alternatives, still there

880
00:46:48,886 --> 00:46:51,840
is discreteness involved.

881
00:46:52,420 --> 00:46:56,080
And this was explored a lot more

882
00:46:56,150 --> 00:46:59,584
fully in the 46 live

883
00:46:59,622 --> 00:47:01,844
streams. Active inference models do not

884
00:47:01,882 --> 00:47:04,612
contradict folk psychology where they

885
00:47:04,746 --> 00:47:07,408
really clarify. This is motor active

886
00:47:07,424 --> 00:47:09,088
inference in the continuous domain.

887
00:47:09,184 --> 00:47:11,056
This is decision making active inference

888
00:47:11,088 --> 00:47:13,048
in the discrete domain. Here's what a

889
00:47:13,054 --> 00:47:15,160
hybrid model looks like. Blue.

890
00:47:18,540 --> 00:47:20,360
Oh, do I still have my hand up? Sorry,

891
00:47:20,510 --> 00:47:24,024
just been up. Yeah. So then they just

892
00:47:24,062 --> 00:47:27,656
basically say some of these models

893
00:47:27,688 --> 00:47:30,364
dealt with continuous phenomena like

894
00:47:30,402 --> 00:47:32,750
specifically the reflex arc example

895
00:47:34,960 --> 00:47:37,596
hashtag active incontinence time,

896
00:47:37,698 --> 00:47:40,192
figure four, three, et cetera. And then

897
00:47:40,246 --> 00:47:42,320
other models presented in this chapter

898
00:47:42,820 --> 00:47:44,764
are compatible with discrete

899
00:47:44,812 --> 00:47:46,700
alternatives like discrete variables,

900
00:47:46,780 --> 00:47:49,776
for example, policy selections. If

901
00:47:49,798 --> 00:47:51,764
there's two modeled policy outcomes then

902
00:47:51,802 --> 00:47:54,116
this is like a discrete model or the

903
00:47:54,138 --> 00:47:55,924
observations could be happening through

904
00:47:55,962 --> 00:47:57,524
discrete time. So there's like different

905
00:47:57,562 --> 00:48:00,390
opportunities for discreteness and

906
00:48:01,000 --> 00:48:04,424
continuous models and variables to be

907
00:48:04,462 --> 00:48:08,650
integrated in

908
00:48:09,340 --> 00:48:13,064
these architectures. Then in

909
00:48:13,102 --> 00:48:16,668
summary, they're outlining the points of

910
00:48:16,674 --> 00:48:18,620
connection between the message passing

911
00:48:18,960 --> 00:48:20,636
implied by the generative models of

912
00:48:20,658 --> 00:48:23,724
chapter four which we asked you not to

913
00:48:23,762 --> 00:48:27,224
read gently, and the

914
00:48:27,282 --> 00:48:29,824
neurobiology of inference, action and

915
00:48:29,862 --> 00:48:32,576
planning. And then here is going to be

916
00:48:32,598 --> 00:48:36,080
like a summary figure for the chapter.

917
00:48:38,660 --> 00:48:41,590
The top row is showing some

918
00:48:42,280 --> 00:48:45,780
computational motifs that are

919
00:48:45,850 --> 00:48:48,052
plausible or compatible with different

920
00:48:48,186 --> 00:48:51,060
subsets of cells and regions in cortex.

921
00:48:51,560 --> 00:48:54,376
The bottom region are showing some

922
00:48:54,478 --> 00:48:58,344
extracortical structures. On the left is

923
00:48:58,382 --> 00:49:01,288
the basal ganglia shown from one of the

924
00:49:01,294 --> 00:49:03,844
previous figures. So it's a subcortical

925
00:49:03,892 --> 00:49:06,796
structure within the brain. Here is a

926
00:49:06,818 --> 00:49:10,940
spinal cord cross section and

927
00:49:11,010 --> 00:49:13,912
one can imagine that other structures

928
00:49:13,976 --> 00:49:16,360
within the brain and outside the brain

929
00:49:16,520 --> 00:49:18,752
would be amenable to also this kind of

930
00:49:18,806 --> 00:49:21,856
graph and they're just doing like kind

931
00:49:21,878 --> 00:49:24,610
of linking now even the models together

932
00:49:26,260 --> 00:49:28,544
and then showing the difference in

933
00:49:28,582 --> 00:49:30,548
planning. Like on the left side the

934
00:49:30,554 --> 00:49:33,072
basal ganglia is getting this preference

935
00:49:33,136 --> 00:49:35,968
difference is connecting to the expected

936
00:49:35,984 --> 00:49:38,836
free energy. So future policies are

937
00:49:38,858 --> 00:49:41,188
being, policies are being evaluated on

938
00:49:41,194 --> 00:49:42,856
the basis of their future ability to

939
00:49:42,878 --> 00:49:46,440
align with preferences. In this pathway

940
00:49:47,420 --> 00:49:51,432
here that's planning habits are

941
00:49:51,486 --> 00:49:57,820
when the preference versus expectation

942
00:49:58,480 --> 00:50:02,268
difference but the outcomes themselves

943
00:50:02,354 --> 00:50:05,436
are going to e and habits are

944
00:50:05,458 --> 00:50:07,368
being followed which could be seen as

945
00:50:07,394 --> 00:50:10,652
multiscale habits and that's influencing

946
00:50:10,716 --> 00:50:14,896
policy. And then here's where that

947
00:50:14,998 --> 00:50:17,392
kind of continuous decision and

948
00:50:17,446 --> 00:50:21,072
modulated handoff

949
00:50:21,136 --> 00:50:22,964
between more planning like and more

950
00:50:23,002 --> 00:50:26,260
habitual is being related

951
00:50:27,240 --> 00:50:31,172
to the motor implementation of the

952
00:50:31,226 --> 00:50:34,016
expectations of the proprioceptive

953
00:50:34,048 --> 00:50:37,364
loops. So like I want to be sitting

954
00:50:37,412 --> 00:50:40,536
still and then all of your muscles in a

955
00:50:40,558 --> 00:50:44,084
healthy situation are not moving versus

956
00:50:44,132 --> 00:50:46,536
like, I want my leg again, speaking like

957
00:50:46,558 --> 00:50:49,916
loosely with it. I want type word, but

958
00:50:49,938 --> 00:50:52,252
just like, I want to lift my leg. That

959
00:50:52,306 --> 00:50:55,500
model, the expectations have to be

960
00:50:55,570 --> 00:50:59,068
updated to allow the leg to realize

961
00:50:59,164 --> 00:51:02,972
being up using a non.

962
00:51:03,036 --> 00:51:04,176
We don't have to say, well, it's more

963
00:51:04,198 --> 00:51:07,376
rewarding for the leg to be up. We can

964
00:51:07,398 --> 00:51:09,692
just say this is a computational

965
00:51:09,756 --> 00:51:13,440
architecture that facilitated that and

966
00:51:13,510 --> 00:51:16,836
generalizes to multi step planning. And

967
00:51:16,858 --> 00:51:18,708
then there's been multiple papers 2017

968
00:51:18,714 --> 00:51:22,464
and beyond that summarized and

969
00:51:22,522 --> 00:51:25,130
elaborated on different aspects of this

970
00:51:26,540 --> 00:51:29,332
more complex continuous architectures,

971
00:51:29,396 --> 00:51:32,004
more complex motor and discrete

972
00:51:32,052 --> 00:51:34,244
interfacing, more complex decision

973
00:51:34,292 --> 00:51:36,044
making, active inference, of course.

974
00:51:36,162 --> 00:51:37,100
Rohan.

975
00:51:39,840 --> 00:51:42,204
Yeah, I'm just wondering because a lot

976
00:51:42,242 --> 00:51:45,452
of this has to do with high level, more

977
00:51:45,506 --> 00:51:47,644
abstract behaviors or kind of abstract

978
00:51:47,692 --> 00:51:50,208
behaviors. Right. So is there any

979
00:51:50,294 --> 00:51:53,152
attempt been made to apply this to

980
00:51:53,206 --> 00:51:55,680
something simpler like the autonomous

981
00:51:56,580 --> 00:51:59,164
nervous system? Because not every signal

982
00:51:59,212 --> 00:52:00,828
goes through to the brain, right. Some

983
00:52:00,854 --> 00:52:02,836
of them just go to the spinal cord. And

984
00:52:02,858 --> 00:52:05,008
we know this because if the spinal

985
00:52:05,024 --> 00:52:08,420
damage, sometimes people can't walk

986
00:52:08,490 --> 00:52:10,596
or they have trouble rebreathing and so

987
00:52:10,618 --> 00:52:14,244
on, or in other animals,

988
00:52:14,292 --> 00:52:16,570
like the cuttlefish, for example, that

989
00:52:16,940 --> 00:52:20,104
changes in the pigmentation of the

990
00:52:20,302 --> 00:52:23,956
skin is not dependent on brain

991
00:52:23,988 --> 00:52:26,750
movement, on brain activity. It's just

992
00:52:27,680 --> 00:52:30,252
completely autonomous, right.

993
00:52:30,306 --> 00:52:34,332
So has there been any attempt made

994
00:52:34,386 --> 00:52:37,550
to apply this to much more

995
00:52:39,300 --> 00:52:42,610
those kind of systems? Well,

996
00:52:42,980 --> 00:52:45,650
how simple or complex a system is, is

997
00:52:46,660 --> 00:52:48,476
kind of like how complexly we approach

998
00:52:48,508 --> 00:52:49,976
it, because people have been modeling

999
00:52:50,028 --> 00:52:52,980
single cell graphs,

1000
00:52:53,720 --> 00:52:55,216
if that could be seen as the simplest

1001
00:52:55,248 --> 00:52:57,892
electrochemical decision maker as well

1002
00:52:57,946 --> 00:53:00,900
as morphological computing.

1003
00:53:01,880 --> 00:53:05,272
And yeah, there's probably a paucity of

1004
00:53:05,326 --> 00:53:08,996
published models on autonomic

1005
00:53:09,028 --> 00:53:11,428
nervous system, active inference models.

1006
00:53:11,604 --> 00:53:13,944
So there are many opportunities because

1007
00:53:13,982 --> 00:53:16,488
they cited a huge amount of the neural

1008
00:53:16,584 --> 00:53:19,804
empirical work here, with the goal being

1009
00:53:19,842 --> 00:53:21,356
to summarize sort of the tip of the

1010
00:53:21,378 --> 00:53:26,808
iceberg. But there aren't models

1011
00:53:26,984 --> 00:53:30,064
like this for every single function or

1012
00:53:30,102 --> 00:53:33,296
region or anything, nor even if there

1013
00:53:33,318 --> 00:53:34,896
were, would it be the end of research in

1014
00:53:34,918 --> 00:53:37,856
that area. So, yeah, there's a lot of

1015
00:53:37,958 --> 00:53:40,316
open space to build specific models,

1016
00:53:40,348 --> 00:53:42,608
which is exactly what section six and

1017
00:53:42,614 --> 00:53:44,416
beyond and part two will take us to,

1018
00:53:44,518 --> 00:53:46,096
which is to go from, like, identifying

1019
00:53:46,128 --> 00:53:47,856
it, we can quickly find out whether it's

1020
00:53:47,888 --> 00:53:50,772
been published or not and then build

1021
00:53:50,826 --> 00:53:52,676
that model with the inputs and outputs

1022
00:53:52,708 --> 00:53:54,836
that people are seeing as relevance.

1023
00:53:55,028 --> 00:53:58,776
Rowan yeah, I'm sorry for

1024
00:53:58,958 --> 00:54:01,784
monopolizing this question time.

1025
00:54:01,982 --> 00:54:04,312
So I'm just curious, has this been

1026
00:54:04,366 --> 00:54:07,768
applied to non biological systems

1027
00:54:07,784 --> 00:54:09,884
in any way? Because that seems to be

1028
00:54:10,002 --> 00:54:11,884
something that we could easily do,

1029
00:54:11,922 --> 00:54:14,876
right? Because we have plenty of data

1030
00:54:15,058 --> 00:54:18,304
right now. Is there anything like a

1031
00:54:18,342 --> 00:54:21,644
better vision model than a convolutional

1032
00:54:21,692 --> 00:54:25,056
neural net, for example, or some sort of

1033
00:54:25,078 --> 00:54:28,748
swarm robotics attempt

1034
00:54:28,844 --> 00:54:31,830
using something like this or even like

1035
00:54:32,200 --> 00:54:34,276
game playing or something? Because I

1036
00:54:34,298 --> 00:54:36,310
would be interested to read.

1037
00:54:37,480 --> 00:54:40,912
Many of these things have been sketched

1038
00:54:40,976 --> 00:54:43,380
or are in progress. We have our project

1039
00:54:43,450 --> 00:54:46,010
ideas in these, like, last minutes.

1040
00:54:46,860 --> 00:54:50,424
There's a lot of room for

1041
00:54:50,622 --> 00:54:53,064
building projects, and there's a huge

1042
00:54:53,102 --> 00:54:56,696
value to creative ideation of areas

1043
00:54:56,728 --> 00:54:59,420
where it could be applied and also value

1044
00:54:59,490 --> 00:55:01,996
for checking literature for where it

1045
00:55:02,018 --> 00:55:04,236
might have been like a model could be

1046
00:55:04,258 --> 00:55:07,084
reused. Like a visual foraging model

1047
00:55:07,282 --> 00:55:09,404
that was from about cultural acquisition

1048
00:55:09,452 --> 00:55:12,144
of pattern preference was repurposed for

1049
00:55:12,182 --> 00:55:15,008
our ant stigma G model just by adding a

1050
00:55:15,014 --> 00:55:17,696
pheromone trace so there isn't like a

1051
00:55:17,718 --> 00:55:20,132
cookbook on what is out there or how

1052
00:55:20,186 --> 00:55:23,476
models could be modified. We hope that

1053
00:55:23,498 --> 00:55:26,390
with active block, for instance, and

1054
00:55:26,760 --> 00:55:29,156
documentation, it'll be clearer and

1055
00:55:29,178 --> 00:55:32,236
clearer for people to build generative

1056
00:55:32,288 --> 00:55:33,684
models and compose them and explore

1057
00:55:33,732 --> 00:55:36,856
different modules. So it should just be

1058
00:55:36,878 --> 00:55:37,450
done.

1059
00:55:39,900 --> 00:55:41,690
Yeah. Okay, thank you.

1060
00:55:44,300 --> 00:55:46,556
Any last thoughts or questions on

1061
00:55:46,578 --> 00:55:48,888
chapter five? And then next week, we'll

1062
00:55:48,984 --> 00:55:51,950
return to the more specific questions.

1063
00:55:57,140 --> 00:55:59,008
Ali, and then anyone else would like a

1064
00:55:59,014 --> 00:56:00,530
closing thought on chapter five?

1065
00:56:03,140 --> 00:56:05,724
Yeah, I just want to mention Thomas

1066
00:56:05,772 --> 00:56:08,480
Parr's speech.

1067
00:56:09,380 --> 00:56:13,300
I think it was a few weeks ago in center

1068
00:56:13,370 --> 00:56:15,552
for Cognitive Neuroscience, Berlin,

1069
00:56:15,696 --> 00:56:18,612
which I'm putting the link here in which

1070
00:56:18,746 --> 00:56:21,556
he explained most of these topics and

1071
00:56:21,658 --> 00:56:25,460
some more in perhaps more accessible

1072
00:56:25,540 --> 00:56:28,824
way. So if anyone wants to yes,

1073
00:56:28,862 --> 00:56:31,624
that's it. If anyone wants to watch it,

1074
00:56:31,662 --> 00:56:34,736
I think that can help in understanding

1075
00:56:34,788 --> 00:56:36,380
the content of this chapter.

1076
00:56:37,680 --> 00:56:41,500
Nice, thank you. Yes, looks like a good

1077
00:56:41,570 --> 00:56:44,172
one to watch. And using the same

1078
00:56:44,226 --> 00:56:47,464
figures, maybe we could annotate,

1079
00:56:47,512 --> 00:56:49,084
like the figures say, at this time,

1080
00:56:49,122 --> 00:56:51,180
step here's where it's described.

1081
00:56:52,720 --> 00:56:56,412
Okay. So those who want to, feel free to

1082
00:56:56,466 --> 00:56:59,952
stay in this room for tools.

1083
00:57:00,136 --> 00:57:02,308
Otherwise, thanks for joining and see

1084
00:57:02,314 --> 00:57:03,270
you next week.


