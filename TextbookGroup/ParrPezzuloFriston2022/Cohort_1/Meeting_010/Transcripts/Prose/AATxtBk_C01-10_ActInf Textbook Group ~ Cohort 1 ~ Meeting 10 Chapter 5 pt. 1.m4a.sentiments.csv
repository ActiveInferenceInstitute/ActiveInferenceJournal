start	end	speaker	sentiment	confidence	text
1050	1646	A	0.5208579897880554	Hello.
1828	5534	A	0.9100316166877747	It is July 7, 2022.
5732	10960	A	0.9340673089027405	It is cohort One textbook group week ten, chapter five.
12210	15838	A	0.8983628749847412	So we're having the first discussion of chapter five.
15924	18958	A	0.870180070400238	We'll have two weeks of discussing chapter five.
19124	41290	A	0.5871395468711853	Then in our last two weeks of July, talk about more general thoughts that we have on chapters one through five and look forward to the second half of the book here.
41440	44330	A	0.7772043943405151	There's two new columns.
44990	55440	A	0.8825166821479797	This first one is if you'd like to join for chapters one through five, cohort two beginning in September 22.
56210	62666	A	0.9274005889892578	And that will be in parallel with also this first cohort continuing for chapters six through ten.
62788	65938	A	0.8565261363983154	So just put a check mark if you want to stay in.
66024	70050	A	0.5845063328742981	Otherwise we won't include you in that cohort.
73780	83830	A	0.8105705976486206	Okay, so there's only a few questions prepared for chapter five.
84360	96330	A	0.9177626967430115	So let's start with any general thoughts that people had about chapter five, like how is this chapter similar or different from the previous ones?
96780	99770	A	0.8609046936035156	And what is the function of chapter five here?
101360	107020	A	0.9042156338691711	Or what did they think was an important overall aspect of this chapter?
109040	114636	A	0.7471396923065186	And then of course, anyone who can capture questions that people are asking here, just add them.
114818	139460	A	0.7042048573493958	But other than that, it would be awesome to hear like, what did people think chapter five was doing or what did they wonder about the material or related to it Ali and then anyone else?
142550	156390	B	0.5151141285896301	I think chapter five needs a lot of Neurobiological background and without necessary requisites, it can be probably Daunting chapter.
157370	184990	B	0.8021605014801025	And unlike other chapters, which are at least the previous chapters, which concern themselves with mathematical formalisms, here in chapter five, for the very first time we encounter some empirical evidence or the empirical reasons behind modeling active inference as such.
185060	197780	B	0.4941629469394684	So it's a very important chapter in my opinion, but at the same time, without any prior Neurobiological background, it could be a really daunting chapter as well.
199610	200358	A	0.7344964742660522	Nice.
200524	203110	A	0.8623128533363342	Thanks for the summary, Mike.
208170	224780	C	0.7660155296325684	Yeah, it was an interesting choice to go all the way to the human brain to illustrate how some of these concepts would map to biological systems, as opposed to starting with more simplistic organisms and kind of working up from there.
231670	233780	A	0.9140397310256958	Yeah, very nice point.
245760	258800	A	0.9033364653587341	Any other overview thoughts and then we can just scan through it and look at the order of a few things and then continue to write questions again as you're hearing them or as you're just wondering.
259300	267680	A	0.9122691750526428	But let's hear any other general thoughts if anyone wants to raise their hand and then look at the order of the chapter.
270620	289720	A	0.8798078298568726	Okay, well, the chapter is titled message Passing in Neurobiology.
292080	319790	A	0.8447487950325012	Message Passing was brought up in a previous chapter in this box 4.1, in a formal yet slightly nonstandard notation without examples, just generally the quote.
319950	330950	A	0.851904571056366	Anyone have any thoughts on JF?
333930	336630	D	0.7986010313034058	Yes, I kind of disagree with the quote.
336990	346854	D	0.5188202857971191	I think recently we've learned that plants actually sense and act on what they detect in the environment.
346902	376354	D	0.5167011618614197	For example, certain trees when they're being munched on by, say, like giraffes, will emit molecules that will disperse, and other trees that sense these essentially an alert signal will start producing compounds in the leafs that make the leaves taste very bitter and thus discouraging foraging and so forth and so on.
376392	393100	D	0.7213255763053894	And also, I think it's clear that plants sense and act, respond to their environment and act in order to maintain their integrity or as individuals or as as groups in the example I just mentioned.
400920	401380	A	0.7344964742660522	Nice.
401450	402260	A	0.5331682562828064	Agreed.
404200	413480	A	0.7096505761146545	Also, the quote might have, like, a little bit of hyperbole comedy, like two types of animals, plants.
413980	417976	A	0.7687200903892517	So it's about nervous systems.
418008	418780	A	0.6077884435653687	Ali.
424000	424364	B	0.5491447448730469	Yeah.
424402	445168	B	0.9290238618850708	And one other thing about Rodolfo Linus is in one of his most famous books, eye of the Cortex from Neurons, the Self, actually, he describes thinking as an internalized movement, and it's a very interesting way to describe thinking, in my opinion.
445264	451008	B	0.8478164672851562	And it directly relates to this active inference framework.
451104	457480	B	0.5095949172973633	So putting his quotation here might be quite relevant.
458780	459192	A	0.84200119972229	Cool.
459246	467560	A	0.8817232251167297	And then I added 2017 paper with Friston and Calvo about plant and predictive processing framework.
468060	480280	A	0.8676632046699524	And then here's, like a non active paper, but about more on the behavioral side, which is kind of the view from the outside without denying the view from the inside as well.
480450	483840	A	0.7515135407447815	But it's just related to behavioral modeling.
484580	485136	A	0.584351658821106	Okay.
485238	505850	A	0.7174679040908813	In the introduction, they write, let us take a step back from the technical material of chapter four, which, as Ali and others have reminded us, was like, even at the beginning, was like, you can bypass this chapter if you don't want technical detail.
506460	515268	A	0.7195307016372681	So maybe somebody had read it, even 1235, and maybe they did or didn't.
515284	516440	A	0.738635778427124	Look at the appendix.
517920	531880	A	0.8921599388122559	Turn to the process theories accompanying active inference, drawing a distinction between a principle and a process theory.
535510	537940	A	0.8456329107284546	Does anyone have any thoughts on that?
538710	545250	A	0.8684095740318298	Like how, as they're reading the book, are they thinking about where free energy principle is related to active inference?
546650	562650	A	0.8967128396034241	How does introducing that kind of broad map territory principle process distinction here help transition the book towards focusing on these empirical cases?
571630	574220	A	0.89699387550354	Ali with a hand raised or anyone else?
579150	582138	A	0.5986106991767883	Okay, just one yeah, go for it.
582304	582934	B	0.5491447448730469	Yeah.
583072	583518	B	0.509212851524353	Sorry.
583604	599860	B	0.7824682593345642	Just one thing I forgot to mention about that quotation is an interesting research has been emerging that kind of bestow consciousness to plants as well.
600250	608870	B	0.6431362628936768	One of the articles, one of the early articles for that is insights into plant consciousness.
609290	619510	B	0.8547516465187073	So, in fact, we don't necessarily limit it to just human or even animal consciousness.
619590	627514	B	0.8931058049201965	And we are beginning to relate consciousness or any other aspects of nervous system to plants as well.
627552	630874	B	0.8975171446800232	So just one additional remarks about that previous code.
630912	631500	A	0.509212851524353	Sorry.
632930	633390	A	0.5491447448730469	Yeah.
633460	646210	A	0.7720075249671936	And the mathematical frameworks for behavior and consciousness that are integrative will allow comparisons of different kinds of behavioral systems, and then that leads to people wondering about consciousness and all these other areas.
647350	650020	A	0.8813501596450806	So mike and then anyone else?
652250	652710	C	0.5491447448730469	Yeah.
652780	660454	C	0.9261675477027893	So tying that back to the part of the chapter that you were on previously in terms of moving from principle to process.
660652	668778	C	0.6259362101554871	And you had highlighted that the latter allows us to develop hypotheses that are answerable to empirical data.
668944	690446	C	0.673259973526001	So I think this is the first instance in the book where they are making a serious effort to tie out to real world observations as opposed to saying, here's a framework for how things might work and how the pieces might be connected.
690558	704390	C	0.8707714676856995	Now we're going to take that framework and think about can we identify things that we see in real systems, in this case in the human brain and tie those back into the ideas that we put forth previously.
705850	706310	A	0.6283750534057617	Thanks.
706380	707206	A	0.570740818977356	Totally agree.
707308	712514	A	0.5168786644935608	It's like partitioning off the principles from the earlier chapters.
712562	719754	A	0.701600193977356	Like in principle, those two sides of the equation are equal because of how the axioms of math are.
719872	731530	A	0.8609305024147034	Or like in principle one could do this with a Bayesian graph and then that is like in principle you could do a linear regression with a least squares error minimization.
731690	735326	A	0.6160264015197754	Nobody can make any data set that says that you can't do that.
735508	740850	A	0.7580046057701111	And then there's how that least squares regression works on empirical data.
741000	766060	A	0.5911476016044617	So they're saying for chapter five we're going to look at with all the architecture, developed a few specific neural systems and talk about how they're the best current understanding that they have of how these neural systems can be modeled with models of the structures like we've seen before.
767710	778270	A	0.7972184419631958	And they're saying, we're not trying to write a neuro textbook here, but to touch kind of like with both feet, the empirical modeling.
780050	786506	A	0.7879893183708191	And then the systems that they are going to model are like effector systems.
786618	793090	A	0.8763203620910645	So motor control subcortical structures like the thalamus and basal ganglia.
795670	800680	A	0.7942261099815369	So these are more like functional outcomes of the nervous system.
801050	824038	A	0.8705928921699524	Specific anatomical structures of interest, modulation of synaptic efficiency or efficacy, which is like a micro anatomical or like a neurophysiological mechanism of interest and something that is an important, like, leverage point and something that is being modified and found to be changed in different situations.
824214	839730	A	0.88344407081604	And then the relationship between decision making and movement generation, which is also something that has come up in those 46 live streams on like motor active inference, decision making, active inference.
847110	849570	A	0.8624950647354126	Let's check if there's any questions written.
851450	852200	A	0.584351658821106	Okay.
855850	863820	A	0.908180296421051	What could anyone say about the cortical layers or what was in figure 5.1?
868310	869170	A	0.5794492959976196	Mike.
871030	879842	C	0.6026799082756042	I was just observing that in the start of chapter four, they said, well, you can skip this chapter if you don't want to get deep into the math.
879906	891980	C	0.9233526587486267	And then here we are at section 52 in chapter five, I think, and they refer back to the message passing structure that was set up in chapter four.
894190	896140	A	0.8650348782539368	Yes, good point.
902110	911390	A	0.6944959163665771	And it's like, well, if you can skip the details of the formalism to look at the examples or you could skip the examples.
914210	924740	A	0.8191840648651123	Any linear text, 140 characters or textbook or a live stream or anything, it's always going to be some sort of linear presentation question.
925510	935570	A	0.6701465845108032	And with a densely linked and interdisciplinary area, then the linearity becomes challenging.
935730	950540	A	0.8829197287559509	So maybe with more with some notebooks or some other rendering or educational way to have the ordering or have, of course, the connections between sections be a little bit different.
952030	956910	A	0.861430823802948	The first system that they're focusing on is the cortical column.
957730	966260	A	0.8981694579124451	Does anyone have anything to add on cortical layers or the role of the cortex, even if it's just something that they've heard about?
983450	993066	A	0.709215521812439	Well, I think that this Menta line of AI and many of the other Ali go for it.
993088	993660	A	0.46103888750076294	Yes.
996510	1014990	B	0.8111212849617004	I want to say that for the past couple of decades, or probably several decades, cortex has traditionally been thought of as the seat of both consciousness intelligence and also, of course, cognition.
1015070	1034882	B	0.8172650337219238	But recent studies have shown that especially studies such as Mark Som's research has shown that in fact, consciousness actually stems from literally the brain stem, not necessarily the cortex.
1034946	1044860	B	0.5979070067405701	So there are some challenges about the exact function of cortex, and the debate goes on.
1049650	1050398	A	0.7344964742660522	Nice.
1050564	1054010	A	0.8330789804458618	Okay, here's a little bit on the cortex.
1054170	1059410	A	0.8644499778747559	So it is the outer frontal part of the mammalian style brain.
1060070	1067166	A	0.6775327920913696	Insects don't have cortex, though they share a lot of the same architectures and so on.
1067288	1069430	A	0.8419338464736938	So this is like neuron tracing.
1069930	1075938	A	0.8198948502540588	And there's kind of two levels of organization that people are modeling in the cortical models.
1076034	1081610	A	0.8430176377296448	The first is based upon the histological observation of the layers.
1082430	1089370	A	0.7923507690429688	These are six layers of cells, and there's a lot of development and all different functionality between the different layers.
1089950	1096014	A	0.7674124240875244	One important thing to note is it's not that they're like the layers of a Bayesian hierarchical model.
1096212	1099054	A	0.6076579093933105	It's not like each one is like up and down, up and down.
1099092	1104970	A	0.6336681842803955	So this isn't like a predictive processing architecture happening simply with these six layers.
1105050	1106820	A	0.5321854948997498	This is not a six layer model.
1107990	1113442	A	0.86814284324646	In fact, they're connected to each other sparsely within a column, as it's shown here in 5.1.
1113576	1118802	A	0.8658058643341064	So that's like the micro anatomical structure of the cortical column.
1118946	1124440	A	0.8327556848526001	And it's called a column because it's like the layers are also arranged in this repeating way.
1124890	1135340	A	0.7914916276931763	And there's just like a lot of different layouts for different regions of this cortical tissue type.
1136430	1156090	A	0.8836694955825806	And in certain situations, it is organized like linear call nerve structures, which is often seen as one of the evolutionary local maxima of depth of processing and sparsity of connections laterally.
1156250	1172530	A	0.7379812002182007	So those are the two levels of analysis that are being and as early mentioned, people yes, have gone to the consciousness angle or they've just argued that this is kind of like the massively paralyzable, but also like deep recurrent contextual, et cetera.
1172610	1175890	A	0.8332230448722839	The anagrams like the patterns that could be activated.
1176050	1181290	A	0.5156104564666748	The dimensionality is potentially super high, so it could play a role in memory signal processing.
1182270	1192300	A	0.8758716583251953	And the two levels that people look at, the connections between, like, anatomically by taking these images or by doing like, stainings and stuff.
1193090	1203470	A	0.8791249990463257	Anatomically and functionally is within the column where there's certain kinds of relationships, and then across columns where there are certain kinds of relationships.
1206690	1208846	A	0.8293914794921875	Any thoughts or questions on that?
1208868	1211134	A	0.7817099690437317	But that's just why the cortex is being studied.
1211182	1223560	A	0.6263243556022644	And that's like a little bit of how the neuroscientists have been approaching this and why this is one of the important systems with a lot of theoretical modeling and empirical evidence and relevance as well.
1224330	1238810	D	0.8568341732025146	JF I remember many years ago taking a course in physiology on the visual cortex and the whole notion that the brain has some kind of structure.
1239710	1254986	D	0.8943960070610046	Always thought it was fascinating because I feel that the brain is a huge hack, patches upon patches upon patches, broadened by evolution and that there would be some structure in it is interesting.
1255108	1260574	D	0.7984642386436462	But within those structures, this picture shows it's very messy.
1260622	1266450	D	0.8620073199272156	I would never implement a system with this kind of wild interconnectivity.
1268170	1294510	D	0.7944846749305725	So I'm very curious about how much we can infer from what is really a mildly structured but highly messy architecture in terms of process theory that we're trying to elucidate from anatomy and the functionality of the brain.
1295170	1295678	A	0.7344964742660522	Nice.
1295764	1296302	A	0.8529649972915649	Thank you.
1296356	1297150	A	0.5794492959976196	Mike.
1299170	1299726	A	0.5491447448730469	Yeah.
1299828	1304774	C	0.7525892853736877	That makes me think that some of that messiness is in support of redundancy.
1304922	1312210	C	0.8412711024284363	And so how do we think about redundancies in systems in the context of active inference?
1315350	1315714	A	0.5491447448730469	Yeah.
1315752	1321314	A	0.7433841228485107	And like, neural systems, of course, have amazing, in some dimensions, ability to have redundancy.
1321362	1323762	A	0.5337616801261902	Other times, seemingly, there's points of failure.
1323826	1326790	A	0.49351051449775696	Jeff okay.
1326940	1327366	A	0.4896697998046875	All right.
1327388	1330780	A	0.5638197064399719	So just on the left side sorry.
1332990	1334582	D	0.6253421902656555	On the comment about redundancy.
1334646	1335130	D	0.6408694386482239	I agree.
1335200	1336940	D	0.9255751371383667	But it's worse than that.
1337710	1353390	D	0.8139853477478027	Every part often plays many different roles and participate in different functions, which makes it quite a tangle in terms of functional analysis of parts of the brain and what they do and whatnot.
1355830	1373970	A	0.8938511610031128	So five one is showing a more like pure Bayes graph with the annotation of the kinds of cells that are in the anatomical layer.
1374130	1387530	A	0.8856263756752014	So this is like a visualization of the anatomy based upon the regions that it connects, gets inputs and outputs from, and then the micro anatomy labeled according to cell types.
1388190	1393526	A	0.7734259366989136	Then with a similar but not exactly concordant.
1393558	1396894	A	0.6049309968948364	There's not a statistical test proposed for how concordant these are.
1397012	1398714	A	0.5943173766136169	It's not a statistical argument.
1398762	1402480	A	0.8818928599357605	It's not exclusive of other framings of what this anatomy is doing.
1402850	1417960	A	0.8488782644271851	Here are labeled with different parameters from the Bayes graph architectures that have been explored in the previous chapters, compatible with message passing implementations that other papers have addressed that aren't here.
1418330	1430190	A	0.8477062582969666	These are like architectures that recapitulate some of the functional and macro, structural and microstructural aspects.
1430370	1447070	A	0.7058874368667603	So this is like computational neuroscience, and it's using these models that actually have an underlying structure that is providing utility and interesting reframings of the anatomy.
1449410	1465460	A	0.69538414478302	And as the model statistical architecture begins to recapitulate aspects of the Cyto architecture, there's like no specific threshold where it's like, oh, well, now it's like an argument that it's doing that function.
1466950	1481670	A	0.7555753588676453	Like people get tantalized by it having some, oh, well, we made this network structured like a brain, or we made this network structured like a mushroom, or we did the ant colony optimization.
1482890	1490746	A	0.5408363938331604	So just because this works for what it does, doesn't mean this works for what anyone wants it to do.
1490928	1495230	A	0.5211631655693054	It's just in this huge space of bioinspired model architectures.
1499010	1517198	A	0.8587431311607361	In five, two, they move a little bit from the consideration of the columnar architecture, which are cell populations, to looking now like still the superficial to deep are the six layers of the cortex.
1517374	1522070	A	0.8575979471206665	But now a few of the variables are highlighted and their relationships.
1522570	1536810	A	0.6604946255683899	And so the ascending and descending prediction error in a predictive processing framework which is often graphically seen going up and down, bottom up and top down effects.
1537150	1546940	A	0.7759853601455688	Here is being shown in the context of the columnar cortex where like errors from one.
1547410	1562946	A	0.7008204460144043	Let's just go to where they the E's are the errors and the G's are predictions and I guess we can find out what Mu is.
1562968	1576534	A	0.8806143403053284	But basically, like, this architecture within and between columns could be like this being like the base variable being estimated and a hierarchical nested model of that.
1576572	1578440	A	0.7634273171424866	And a hierarchical model of that.
1579130	1591340	A	0.7532348036766052	So there's like a generalization statistical architecture that has compatibility with the neural architecture of the brain and it does like a pure statistical function.
1591790	1598080	A	0.8974441885948181	And that pure statistical function has resemblance with some things that the brain region is believed to do.
1599010	1609860	A	0.621902585029602	So that allows this statistical model to be explaining and predicting and useful about the brain, which is like what computational neuroscience does.
1615810	1629940	A	0.8739842176437378	So that was the first one of the systems that they focus on then.
1630790	1636446	A	0.7146453261375427	Yeah, I guess this was then the factor systems.
1636478	1640150	A	0.8113387823104858	Okay, let's see if we can kind of quickly look at all the systems.
1645320	1650532	A	0.9254850149154663	What did anyone see or what would they like to say about figure five?
1650586	1657080	A	0.8931030631065369	Three neuroanatomy associated with active inference in modulating spinal motor reflexes.
1672830	1683200	A	0.9081565737724304	Okay, so five one was the columnar architecture and that was described in terms of what cell types were in it.
1684290	1690366	A	0.8889467120170593	Here they're going to pick up on one of those cell types, which is like the computational role.
1690478	1700850	A	0.8454220294952393	The expectations encoded by this cell type that's found in this layer of the motor cortex.
1701210	1713014	A	0.8344970345497131	And so different regions of the cortex have different apparent functions asterisk, asterisk, asterisk, but there's like a visual cortex and a motor cortex and so on.
1713132	1720460	A	0.8901700377464294	So this is in a motor region of cortical architecture that plays a certain biological function.
1723790	1730938	A	0.6880034804344177	The expectations are subtracted from the incoming proprioceptive input in the horn of a spinal cord.
1731034	1733402	A	0.744052529335022	This is like lateral cut through a spinal cord.
1733466	1736270	A	0.8278263807296753	The horns are like the butterfly parts.
1738370	1755110	A	0.5959096550941467	And so there's a difference in between the incoming intensity of proprioception and the brain expected expectations and then the error drives muscle activity in the direction of suppression.
1756090	1781680	A	0.7675758600234985	So the motor activity is, like, reducing the divergence based upon the sign and the intensity of the compromise between the brain's expectations potentially arising within, like, layer five from these bet cells and the incoming sensory information, which can be modeled as, like, why?
1785680	1788540	A	0.7277474999427795	I think Mu is probably the mean of that expectation.
1792240	1794450	A	0.6299365758895874	I don't know what part it was mentioned.
1795060	1800352	A	0.767366886138916	And then here's the expectation, the difference between these two.
1800406	1802930	A	0.8016536235809326	It's like a causal system flow, but, like a little different.
1803620	1808208	A	0.6247680187225342	You're getting a five out of ten pressure, you're expecting a five out of ten pressure.
1808304	1810304	A	0.6669313311576843	The motor reflex is not engaged.
1810432	1814070	A	0.6408496499061584	You're getting a seven out of ten pressure, you're expecting five out of ten.
1814440	1821096	A	0.6027253866195679	There's, like a negative two difference or whichever way you want to be subtracting, there's like a two or a negative two difference.
1821278	1825370	A	0.6421041488647461	And then that triggers some motor neuron units to fire.
1825900	1834700	A	0.8498309850692749	And then that proportionally brings the expectation into alignment with the measurement.
1841150	1847226	A	0.6592673063278198	Um, they're gonna just like that example hinged from a cortical layer.
1847258	1858350	A	0.9042475819587708	And cell type here is going to be hinging on the cortex and looking to an output region of the cortex, which is the striatum.
1859270	1869910	A	0.868782103061676	And then they're going to do a more detailed model of a basal ganglia because it's been modeled a lot more and then also have, like, just a textual treatment of the thalamus.
1872410	1887030	A	0.888909637928009	There's multiple papers on dopamine and active inference and so from 2012 and then 2015.
1888620	1900780	A	0.9557844996452332	This is a really interesting area of research with Dopamine because Dopamine is, like, classically described as the reward molecule.
1901600	1905260	A	0.5636336207389832	More reward, more dopamine, lower reward, lower dopamine.
1906640	1931408	A	0.6621540188789368	So isn't the whole meme inactive that we replace the reinforcement reward learning paradigm with a different imperative that has elements that reflect pragmatic value, but that isn't the overarching imperative for policy selection.
1931504	1956140	A	0.7298325896263123	And so these papers show how, like in the context of a generative model with expectations and preferences and Dopamine signaling something related to the predictive processing of stimuli under a mildly optimistic world model, good events and surprising events are still associated with Dopamine release.
1957700	1962160	A	0.9197463393211365	And things that are going worse than expected are still associated with Dopamine drops.
1962740	1982512	A	0.7717138528823853	But that actually is, like, a more unified way to talk about Dopamine's empirical outcomes as opposed to the reward learning, which has to hypothesize all of these modules that translate different kinds of things into reward.
1982576	1983540	A	0.6628338694572449	Jessica.
1985960	2004940	E	0.7534000277519226	Yeah, I think similarly to these I don't remember where I read this, but the brain in regards to the dopamine comment, it's also, like the anticipation of doing something and the fact that you're going to get that Dopamine kick.
2007600	2011084	E	0.7851850986480713	Basically, you get a release by anticipating something.
2011202	2018610	E	0.8600521683692932	And that maybe a little bit connects also with the active inference, the fact that you are anticipating something.
2020100	2021876	E	0.5090770125389099	You expect that to happen.
2021978	2027430	E	0.5642372965812683	And so you get that release of the dopamine in anticipation of the event happening.
2028120	2037450	E	0.828138530254364	I don't know much, but I'm thinking it could be connected with having a predictive unexpected free energy or something.
2038380	2038984	A	0.7344964742660522	Nice.
2039102	2041000	A	0.8031595349311829	Good insight, Rohan.
2043580	2051208	F	0.7385643720626831	Yeah, well, I'm not a biologist, but okay, so I just want to clarify.
2051304	2056524	F	0.802229642868042	There are other systems in the body apart from just the brain alone, right?
2056562	2068450	F	0.8684900403022766	So you have like the autonomous or what is it, parasympathetic nervous system that controls your heart rate, your aspiration and other things.
2069800	2084388	F	0.8320295214653015	Also you have stuff like adrenaline and noradrenaline that do produce responses and other hormones also that produce responses like for hunger or satisfaction.
2084564	2094152	F	0.8056347966194153	And we basically have figured out how to modulate these things to solve modern issues for things like obesity or something like that.
2094206	2097976	F	0.7905998826026917	And there are treatments available that modify these hormones levels.
2098008	2098396	F	0.5664746165275574	Right.
2098498	2106556	F	0.6096035242080688	So is this not a very limiting perspective to look at dopamine alone as the only thing?
2106658	2112936	F	0.811739444732666	And my other question would be how does that convert into, say, motor commands?
2113048	2117100	F	0.6316174268722534	So I just increased dopamine levels without any stimulus whatsoever.
2117600	2119584	F	0.5167768001556396	Let's say someone's taking a drug.
2119752	2120630	F	0.6848124265670776	It would.
2121320	2125024	F	0.6246221661567688	So that does not necessarily translate to a motor command.
2125072	2125476	A	0.5664746165275574	Right.
2125578	2127796	F	0.7658570408821106	So how does it do this?
2127818	2141572	F	0.7324931025505066	Is there like a specialized system that figures out okay, so here's the previous action here's increase in dopamine and here's how we modulate to further increase dopamine.
2141716	2146270	F	0.7159527540206909	And where exactly do you set limits on this process?
2146880	2155288	A	0.8678441643714905	Okay, the two questions were about interacting physiological systems and the second one was about dopamine's role in motor selection.
2155464	2160992	A	0.8742477893829346	Blue, go ahead if it's related or if you want to address anything.
2161126	2163200	G	0.691485583782196	Yeah, no, I just wanted to respond.
2163540	2171350	G	0.7839882373809814	The dopamine response is there are a lot of interactions that are happening in the nervous system.
2171800	2177670	G	0.9566007256507874	Dopamine is one of the best understood, I think it's one of the ones that we've studied for a long time.
2178200	2185396	G	0.6907557845115662	And if there's an overload of dopamine, the action can actually be nonspecific.
2185428	2187316	G	0.596389889717102	And that's what we see in Parkinson's.
2187348	2202750	G	0.6757105588912964	Right, so it's like an overload of dopamine into that system and it fries it out and then you get nonspecific action in the nervous system, motor action, the tremors and stuff.
2204000	2204844	A	0.46103888750076294	Yes.
2205042	2205820	A	0.8771420121192932	Good call.
2205890	2225140	A	0.5245088934898376	And that question about non purposeful behavior and dopamine on the positive and on the negative, like failure to engage, initiate action relating in like catatonic behavior and then like hypermotor activity associated with repetitive motions of various kinds.
2226600	2233610	A	0.5960847735404968	Dopamine is known to be different in people who are experiencing that differently and modified by drugs that target that system.
2234540	2255736	A	0.7339312434196472	But to the first question about pluralism with respect to physiological systems, for sure this model does not exclude that, in fact, its flexibility is its advantage because the inputs to a brain region now we could say, well, at this time scale it's electrochemical and at this time scale it's going to be just noradrenaline.
2255768	2258716	A	0.5698999166488647	And someone says, well, how could you only model noradrenaline?
2258748	2276176	A	0.8169352412223816	Say, okay, let's look at the model with Noradrenaline and this other one and an unmodeled component so it will allow integration formally of physiological mechanisms that genuinely interact and as to why people write like, specific papers about specific hormone systems.
2276208	2280896	A	0.6348528861999512	It's just like what is chunked off in that fractal?
2281008	2291620	A	0.7756885886192322	And then also one important note is like, Colombo and Wright have written about how we don't need a monolithic theory of any neurotransmitter or any brain region.
2291780	2304510	A	0.8129753470420837	There might be like, features or components of Dopaminergic systems that it just explains and predicts that they do reward, taken lightly, that the explanation is just, of course, our explanation of a biological system.
2306560	2312076	A	0.8293099403381348	And also you raise like, beyond the brain there's also glia and other cell types.
2312108	2327440	A	0.6318679451942444	So, yeah, the cool thing would be a framework where we don't a priori exclude factors that are important, but just to kind of go quickly through the example and get to that motor action.
2327600	2342440	A	0.858746349811554	So this is an output from some putative processing that happened in the cortex and now it's projecting into some Dopaminergic regions in the subcortical area, like the basal ganglia.
2344460	2347864	A	0.8790490031242371	It's going to be a model involving outcomes.
2347912	2351944	A	0.7797393202781677	O, the difference between the preferred and the expected outcomes.
2352072	2358952	A	0.8519008755683899	The sigma squiggle expected free energy evaluated for a policy and the posterior over policies.
2359016	2371812	A	0.8919181823730469	The bold pi the figure is like shown after a lot of the description, but here is where they refer to the high and low Dopamine state.
2371866	2383704	A	0.7474623918533325	So also the movie book Awakenings is about people who have atypical Dopamine signaling and then they're given L DOPA and they come and get reinvived with life and stuff.
2383822	2384760	A	0.7415806651115417	Rohan.
2387580	2397452	F	0.7476894855499268	Yeah, well, this is a little more general, but okay, so we have the Marco blanket and there are some internal states.
2397586	2401708	F	0.8589988350868225	And the Marco blanket basically connects us to the external states.
2401794	2402430	A	0.5664746165275574	Right.
2403520	2409280	F	0.8632135987281799	Or samples from the external states and then modulates the internal states accordingly.
2410340	2429110	F	0.8694910407066345	Okay, so my question is, I think if the first imperative is survival and the first imperative is to keep this system in homeostasis, which is composed of multiple interlocking and interacting complex components, right?
2431880	2444490	F	0.9165644645690918	How exactly would you translate these multiple signaling modalities with multiple hormones into maintaining homeostasis with something like free energy?
2444960	2448940	F	0.6936497092247009	Because some of these things are compatible entirely.
2449840	2452664	F	0.8065411448478699	You would have to have some sort of translation mechanism.
2452712	2452972	A	0.7360090017318726	Right?
2453026	2464832	F	0.6213049292564392	So let's say that adrenaline is jumping really high and into dangerously high levels, but we only know it's dangerous because there is some system that is able to predict that.
2464886	2470804	F	0.9395301342010498	Okay, it should not go above this level because it's going to screw up something else in the system.
2470922	2471590	A	0.5664746165275574	Right.
2472920	2479984	A	0.7339054346084595	Multi scale optimization and not over optimizing one lower level parameter at the cost of some higher order parameter.
2480112	2483332	F	0.5003225803375244	Yeah, but then you come to the curse of dimensionality.
2483396	2488600	F	0.7180391550064087	So how many different things are you going to take up before it comes completely useless?
2489260	2489816	A	0.4650449752807617	Absolutely.
2489918	2490568	A	0.6243525743484497	Good question.
2490654	2495928	A	0.8327447772026062	Empirical question about what computational hardware, what measurement data sets?
2496024	2498232	A	0.836746335029602	What sparsity of system graph?
2498376	2505100	A	0.8635838031768799	What extent of application of heuristics how accurate you need that model to be in the empirical setting.
2505680	2534440	A	0.5169309973716736	None of it in principle addressed by just the equations, all of it related to how they're actually implemented at what scale, just to quickly complete through here though, this is about the depletion of dopamine is being observed creating this akinesia failure to move and exogenous dopamine promotes impulsive behaviors of multiple different kinds.
2536780	2539370	A	0.6928882598876953	This is what it looks like.
2540700	2550910	A	0.8649663329124451	Dopamine, as again stated here is balancing modulating the balance as a neuromodulator between inferring what to do and what not to do.
2551280	2563904	A	0.8202537298202515	And so these two graphs, both of them are getting outcomes from the cerebral cortex of the observations expected under a policy.
2564102	2571110	A	0.9127053022384644	So those could be considered like predictions about future sensory states here.
2572520	2579300	A	0.5739283561706543	And the gamma is this uncertainty that's being represented by Dopamine.
2580840	2583880	A	0.738014817237854	In this uncertainty function of Dopamine.
2587340	2587656	B	0.5416930317878723	In.
2587678	2604440	A	0.8959627747535706	The direct pathway, the policies and the difference between the preferences and expectations sigma squiggle with a tilde are being evaluated as part of the expected free energy of future policies and that is resulting in the selection of policies.
2604600	2610624	A	0.6399849653244019	So that could be like thinking through all the chess moves and then picking the one with the lowest expected free energy.
2610822	2630560	A	0.899727463722229	Here the output in the indirect pathway feeds into the prior vector e habit and then that influences policy through this acting anatomically proposed through this other region not defined with a specific variable.
2630640	2633944	A	0.7460570931434631	So again, this is not like saying necessarily even just what it's doing.
2633982	2635000	A	0.6472527384757996	This isn't the full model.
2635070	2648904	A	0.7265982627868652	The papers read more but that's like the two pathways of action selection and it's compatible with the empirical evidence from pathology and from pharmacology and genetic studies in animals other than humans.
2649032	2656510	A	0.8806988596916199	And this is how it could be modeled with a base graph that recapitulates some of the architecture and the function.
2657220	2677060	A	0.9097367525100708	Then they describe the roles of some different neurotransmitters that have been modeled in active and like what kinds of phenomena those measurements have been used in models.
2679960	2689768	A	0.8369832634925842	And then one last important part, it was in the section with the basal ganglia that was talking about this.
2689934	2697512	A	0.8462501764297485	So they show the graph of the basal ganglia and then only in this last paragraph do they describe the thalamus.
2697656	2724340	A	0.9040781855583191	So just say we're just going to do one paragraph on it but basically the thalamus has these two divisions and then they provide the interpretation that these two divisions of the thalamus could reflect first and second order statistics on other types of senses and policies.
2725640	2742280	A	0.8721352815628052	So that's like a unique prediction that potentially modeling observed neural responses or the bold signal from the blood oxygen use in that region.
2743020	2752536	A	0.5810248851776123	You'll make a better model if you fit into these categories rather than reward or rather than familiarity or any number of other criteria.
2752648	2767164	A	0.7563396692276001	So just simply fitting better is not the whole substance of validating the formalisms described earlier but it's part of the empirical grounding and examples of unique predictions and explanations.
2767292	2769360	A	0.8464521169662476	That are provided by active inference.
2770580	2772390	A	0.7426067590713501	But that was the thalmus part.
2772840	2791960	A	0.8140732645988464	And then in this very short section 56, they talk about how a lot of our interfaces are continuous like sensory apparatus and motor apparatus have continuous aspects.
2792940	2801720	A	0.5578744411468506	But then in the cognitive and decision making domains there's often much more discreteness.
2801800	2811840	A	0.5762033462524414	Even if there's multi scale discreteness resulting in a very finely graded continuum of alternatives, still there is discreteness involved.
2812420	2820284	A	0.7010213136672974	And this was explored a lot more fully in the 46 live streams.
2820412	2826192	A	0.7148387432098389	Active inference models do not contradict folk psychology where they really clarify.
2826336	2829088	A	0.8710871934890747	This is motor active inference in the continuous domain.
2829184	2832316	A	0.8772690296173096	This is decision making active inference in the discrete domain.
2832448	2834328	A	0.8779345750808716	Here's what a hybrid model looks like.
2834414	2835160	A	0.6215739846229553	Blue.
2838540	2839816	G	0.8150837421417236	Oh, do I still have my hand up?
2839838	2841610	G	0.4940619170665741	Sorry, just been up.
2841980	2842632	A	0.5491447448730469	Yeah.
2842766	2859532	A	0.8700484037399292	So then they just basically say some of these models dealt with continuous phenomena like specifically the reflex arc example hashtag active incontinence time, figure four, three, et cetera.
2859676	2868960	A	0.5280486941337585	And then other models presented in this chapter are compatible with discrete alternatives like discrete variables, for example, policy selections.
2869460	2876740	A	0.8864783644676208	If there's two modeled policy outcomes then this is like a discrete model or the observations could be happening through discrete time.
2876810	2891240	A	0.775520920753479	So there's like different opportunities for discreteness and continuous models and variables to be integrated in these architectures.
2891980	2910640	A	0.8075491189956665	Then in summary, they're outlining the points of connection between the message passing implied by the generative models of chapter four which we asked you not to read gently, and the neurobiology of inference, action and planning.
2911300	2916080	A	0.9006891250610352	And then here is going to be like a summary figure for the chapter.
2918660	2931060	A	0.7775261402130127	The top row is showing some computational motifs that are plausible or compatible with different subsets of cells and regions in cortex.
2931560	2937108	A	0.8376784920692444	The bottom region are showing some extracortical structures.
2937284	2942468	A	0.9097960591316223	On the left is the basal ganglia shown from one of the previous figures.
2942644	2945280	A	0.7682689428329468	So it's a subcortical structure within the brain.
2945460	2969244	A	0.7765550017356873	Here is a spinal cord cross section and one can imagine that other structures within the brain and outside the brain would be amenable to also this kind of graph and they're just doing like kind of linking now even the models together and then showing the difference in planning.
2969372	2976820	A	0.882780909538269	Like on the left side the basal ganglia is getting this preference difference is connecting to the expected free energy.
2976970	2984280	A	0.8795763254165649	So future policies are being, policies are being evaluated on the basis of their future ability to align with preferences.
2984780	3011330	A	0.8916041851043701	In this pathway here that's planning habits are when the preference versus expectation difference but the outcomes themselves are going to e and habits are being followed which could be seen as multiscale habits and that's influencing policy.
3013220	3034900	A	0.8773763179779053	And then here's where that kind of continuous decision and modulated handoff between more planning like and more habitual is being related to the motor implementation of the expectations of the proprioceptive loops.
3035480	3048628	A	0.584495484828949	So like I want to be sitting still and then all of your muscles in a healthy situation are not moving versus like, I want my leg again, speaking like loosely with it.
3048654	3051644	A	0.6800374388694763	I want type word, but just like, I want to lift my leg.
3051842	3062972	A	0.8224809169769287	That model, the expectations have to be updated to allow the leg to realize being up using a non.
3063036	3066130	A	0.5919740200042725	We don't have to say, well, it's more rewarding for the leg to be up.
3066900	3075940	A	0.6123963594436646	We can just say this is a computational architecture that facilitated that and generalizes to multi step planning.
3076520	3096044	A	0.7210603356361389	And then there's been multiple papers 2017 and beyond that summarized and elaborated on different aspects of this more complex continuous architectures, more complex motor and discrete interfacing, more complex decision making, active inference, of course.
3096162	3097100	A	0.7415806651115417	Rohan.
3099840	3108284	F	0.7913230061531067	Yeah, I'm just wondering because a lot of this has to do with high level, more abstract behaviors or kind of abstract behaviors.
3108332	3108928	F	0.5664746165275574	Right.
3109094	3117456	F	0.8989943265914917	So is there any attempt been made to apply this to something simpler like the autonomous nervous system?
3117558	3120624	F	0.6371751427650452	Because not every signal goes through to the brain, right.
3120662	3122496	F	0.5243163108825684	Some of them just go to the spinal cord.
3122608	3145764	F	0.5006628036499023	And we know this because if the spinal damage, sometimes people can't walk or they have trouble rebreathing and so on, or in other animals, like the cuttlefish, for example, that changes in the pigmentation of the skin is not dependent on brain movement, on brain activity.
3145812	3150252	F	0.6912877559661865	It's just completely autonomous, right.
3150306	3160800	F	0.8892871141433716	So has there been any attempt made to apply this to much more those kind of systems?
3161860	3180900	A	0.7708982825279236	Well, how simple or complex a system is, is kind of like how complexly we approach it, because people have been modeling single cell graphs, if that could be seen as the simplest electrochemical decision maker as well as morphological computing.
3181880	3191428	A	0.488258421421051	And yeah, there's probably a paucity of published models on autonomic nervous system, active inference models.
3191604	3202280	A	0.7405608296394348	So there are many opportunities because they cited a huge amount of the neural empirical work here, with the goal being to summarize sort of the tip of the iceberg.
3202440	3215730	A	0.6764662265777588	But there aren't models like this for every single function or region or anything, nor even if there were, would it be the end of research in that area.
3216100	3234836	A	0.7088207602500916	So, yeah, there's a lot of open space to build specific models, which is exactly what section six and beyond and part two will take us to, which is to go from, like, identifying it, we can quickly find out whether it's been published or not and then build that model with the inputs and outputs that people are seeing as relevance.
3235028	3241784	F	0.7912718057632446	Rowan yeah, I'm sorry for monopolizing this question time.
3241982	3248156	F	0.8767745494842529	So I'm just curious, has this been applied to non biological systems in any way?
3248178	3252460	F	0.6007369756698608	Because that seems to be something that we could easily do, right?
3252610	3256030	F	0.5968475937843323	Because we have plenty of data right now.
3256800	3273732	F	0.7206881642341614	Is there anything like a better vision model than a convolutional neural net, for example, or some sort of swarm robotics attempt using something like this or even like game playing or something?
3273866	3276310	F	0.8604656457901001	Because I would be interested to read.
3277480	3282288	A	0.9117721319198608	Many of these things have been sketched or are in progress.
3282384	3286010	A	0.8146176338195801	We have our project ideas in these, like, last minutes.
3286860	3304888	A	0.8035220503807068	There's a lot of room for building projects, and there's a huge value to creative ideation of areas where it could be applied and also value for checking literature for where it might have been like a model could be reused.
3304984	3321620	A	0.85826575756073	Like a visual foraging model that was from about cultural acquisition of pattern preference was repurposed for our ant stigma G model just by adding a pheromone trace so there isn't like a cookbook on what is out there or how models could be modified.
3322840	3334920	A	0.7870511412620544	We hope that with active block, for instance, and documentation, it'll be clearer and clearer for people to build generative models and compose them and explore different modules.
3335820	3337450	A	0.7418882846832275	So it should just be done.
3339900	3340360	A	0.5491447448730469	Yeah.
3340430	3341690	F	0.7883908748626709	Okay, thank you.
3344300	3347404	A	0.9041950106620789	Any last thoughts or questions on chapter five?
3347522	3351950	A	0.9012652039527893	And then next week, we'll return to the more specific questions.
3357140	3360530	A	0.9170708060264587	Ali, and then anyone else would like a closing thought on chapter five?
3363140	3368480	B	0.7477020621299744	Yeah, I just want to mention Thomas Parr's speech.
3369380	3385832	B	0.5315176844596863	I think it was a few weeks ago in center for Cognitive Neuroscience, Berlin, which I'm putting the link here in which he explained most of these topics and some more in perhaps more accessible way.
3385886	3389432	B	0.4972480237483978	So if anyone wants to yes, that's it.
3389486	3396380	B	0.6547710299491882	If anyone wants to watch it, I think that can help in understanding the content of this chapter.
3397680	3399244	A	0.9560856223106384	Nice, thank you.
3399442	3402636	A	0.9649882316589355	Yes, looks like a good one to watch.
3402738	3411180	A	0.8727630376815796	And using the same figures, maybe we could annotate, like the figures say, at this time, step here's where it's described.
3412720	3413468	A	0.584351658821106	Okay.
3413634	3419952	A	0.8118475675582886	So those who want to, feel free to stay in this room for tools.
3420136	3423270	A	0.926535427570343	Otherwise, thanks for joining and see you next week.
