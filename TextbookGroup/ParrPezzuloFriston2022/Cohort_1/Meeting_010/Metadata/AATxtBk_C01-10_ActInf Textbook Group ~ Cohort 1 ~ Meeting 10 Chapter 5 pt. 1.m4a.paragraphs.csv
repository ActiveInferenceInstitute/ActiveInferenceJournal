start	end	paragNum	speaker	confidence	startTime	wordCount	text
1050	18958	1	A	0.99998	00:01	33	Hello. It is July 7, 2022. It is cohort One textbook group week ten, chapter five. So we're having the first discussion of chapter five. We'll have two weeks of discussing chapter five.
19124	65938	2	A	0.99974	00:19	85	Then in our last two weeks of July, talk about more general thoughts that we have on chapters one through five and look forward to the second half of the book here. There's two new columns. This first one is if you'd like to join for chapters one through five, cohort two beginning in September 22. And that will be in parallel with also this first cohort continuing for chapters six through ten. So just put a check mark if you want to stay in.
66024	70050	3	A	0.97752	01:06	8	Otherwise we won't include you in that cohort.
73780	107020	4	A	0.76004	01:13	58	Okay, so there's only a few questions prepared for chapter five. So let's start with any general thoughts that people had about chapter five, like how is this chapter similar or different from the previous ones? And what is the function of chapter five here? Or what did they think was an important overall aspect of this chapter?
109040	139460	5	A	1.0	01:49	53	And then of course, anyone who can capture questions that people are asking here, just add them. But other than that, it would be awesome to hear like, what did people think chapter five was doing or what did they wonder about the material or related to it Ali and then anyone else?
142550	203110	6	B	0.94	02:22	95	I think chapter five needs a lot of Neurobiological background and without necessary requisites, it can be probably Daunting chapter. And unlike other chapters, which are at least the previous chapters, which concern themselves with mathematical formalisms, here in chapter five, for the very first time we encounter some empirical evidence or the empirical reasons behind modeling active inference as such. So it's a very important chapter in my opinion, but at the same time, without any prior Neurobiological background, it could be a really daunting chapter as well. Nice. Thanks for the summary, Mike.
208170	224780	7	C	0.61	03:28	42	Yeah, it was an interesting choice to go all the way to the human brain to illustrate how some of these concepts would map to biological systems, as opposed to starting with more simplistic organisms and kind of working up from there.
231670	233780	8	A	0.83	03:51	4	Yeah, very nice point.
245760	267680	9	A	0.99007	04:05	60	Any other overview thoughts and then we can just scan through it and look at the order of a few things and then continue to write questions again as you're hearing them or as you're just wondering. But let's hear any other general thoughts if anyone wants to raise their hand and then look at the order of the chapter.
270620	289720	10	A	0.27119	04:30	10	Okay, well, the chapter is titled message Passing in Neurobiology.
292080	330950	11	A	0.99856	04:52	32	Message Passing was brought up in a previous chapter in this box 4.1, in a formal yet slightly nonstandard notation without examples, just generally the quote. Anyone have any thoughts on JF?
333930	393100	12	D	0.99886	05:33	115	Yes, I kind of disagree with the quote. I think recently we've learned that plants actually sense and act on what they detect in the environment. For example, certain trees when they're being munched on by, say, like giraffes, will emit molecules that will disperse, and other trees that sense these essentially an alert signal will start producing compounds in the leafs that make the leaves taste very bitter and thus discouraging foraging and so forth and so on. And also, I think it's clear that plants sense and act, respond to their environment and act in order to maintain their integrity or as individuals or as as groups in the example I just mentioned.
400920	418780	13	A	0.99993	06:40	26	Nice. Agreed. Also, the quote might have, like, a little bit of hyperbole comedy, like two types of animals, plants. So it's about nervous systems. Ali.
424000	459192	14	B	0.97	07:04	63	Yeah. And one other thing about Rodolfo Linus is in one of his most famous books, eye of the Cortex from Neurons, the Self, actually, he describes thinking as an internalized movement, and it's a very interesting way to describe thinking, in my opinion. And it directly relates to this active inference framework. So putting his quotation here might be quite relevant. Cool.
459246	505850	15	A	0.55	07:39	102	And then I added 2017 paper with Friston and Calvo about plant and predictive processing framework. And then here's, like a non active paper, but about more on the behavioral side, which is kind of the view from the outside without denying the view from the inside as well. But it's just related to behavioral modeling. Okay. In the introduction, they write, let us take a step back from the technical material of chapter four, which, as Ali and others have reminded us, was like, even at the beginning, was like, you can bypass this chapter if you don't want technical detail.
506460	531880	16	A	0.96847	08:26	36	So maybe somebody had read it, even 1235, and maybe they did or didn't. Look at the appendix. Turn to the process theories accompanying active inference, drawing a distinction between a principle and a process theory.
535510	562650	17	A	1.0	08:55	50	Does anyone have any thoughts on that? Like how, as they're reading the book, are they thinking about where free energy principle is related to active inference? How does introducing that kind of broad map territory principle process distinction here help transition the book towards focusing on these empirical cases?
571630	574220	18	A	0.98874	09:31	8	Ali with a hand raised or anyone else?
579150	608870	19	A	0.99971	09:39	51	Okay, just one yeah, go for it. Yeah. Sorry. Just one thing I forgot to mention about that quotation is an interesting research has been emerging that kind of bestow consciousness to plants as well. One of the articles, one of the early articles for that is insights into plant consciousness.
609290	633390	20	B	0.96268	10:09	44	So, in fact, we don't necessarily limit it to just human or even animal consciousness. And we are beginning to relate consciousness or any other aspects of nervous system to plants as well. So just one additional remarks about that previous code. Sorry. Yeah.
633460	650020	21	A	1.0	10:33	40	And the mathematical frameworks for behavior and consciousness that are integrative will allow comparisons of different kinds of behavioral systems, and then that leads to people wondering about consciousness and all these other areas. So mike and then anyone else?
652250	704390	22	C	0.53	10:52	125	Yeah. So tying that back to the part of the chapter that you were on previously in terms of moving from principle to process. And you had highlighted that the latter allows us to develop hypotheses that are answerable to empirical data. So I think this is the first instance in the book where they are making a serious effort to tie out to real world observations as opposed to saying, here's a framework for how things might work and how the pieces might be connected. Now we're going to take that framework and think about can we identify things that we see in real systems, in this case in the human brain and tie those back into the ideas that we put forth previously.
705850	731530	23	A	1.0	11:45	63	Thanks. Totally agree. It's like partitioning off the principles from the earlier chapters. Like in principle, those two sides of the equation are equal because of how the axioms of math are. Or like in principle one could do this with a Bayesian graph and then that is like in principle you could do a linear regression with a least squares error minimization.
731690	786506	24	A	0.99973	12:11	113	Nobody can make any data set that says that you can't do that. And then there's how that least squares regression works on empirical data. So they're saying for chapter five we're going to look at with all the architecture, developed a few specific neural systems and talk about how they're the best current understanding that they have of how these neural systems can be modeled with models of the structures like we've seen before. And they're saying, we're not trying to write a neuro textbook here, but to touch kind of like with both feet, the empirical modeling. And then the systems that they are going to model are like effector systems.
786618	793090	25	A	0.99263	13:06	11	So motor control subcortical structures like the thalamus and basal ganglia.
795670	839730	26	A	0.99402	13:15	90	So these are more like functional outcomes of the nervous system. Specific anatomical structures of interest, modulation of synaptic efficiency or efficacy, which is like a micro anatomical or like a neurophysiological mechanism of interest and something that is an important, like, leverage point and something that is being modified and found to be changed in different situations. And then the relationship between decision making and movement generation, which is also something that has come up in those 46 live streams on like motor active inference, decision making, active inference.
847110	852200	27	A	0.7871	14:07	8	Let's check if there's any questions written. Okay.
855850	863820	28	A	0.99989	14:15	14	What could anyone say about the cortical layers or what was in figure 5.1?
868310	891980	29	A	0.74316	14:28	59	Mike. I was just observing that in the start of chapter four, they said, well, you can skip this chapter if you don't want to get deep into the math. And then here we are at section 52 in chapter five, I think, and they refer back to the message passing structure that was set up in chapter four.
894190	896140	30	A	0.9996	14:54	3	Yes, good point.
902110	911390	31	A	0.84	15:02	24	And it's like, well, if you can skip the details of the formalism to look at the examples or you could skip the examples.
914210	966260	32	A	0.99996	15:14	103	Any linear text, 140 characters or textbook or a live stream or anything, it's always going to be some sort of linear presentation question. And with a densely linked and interdisciplinary area, then the linearity becomes challenging. So maybe with more with some notebooks or some other rendering or educational way to have the ordering or have, of course, the connections between sections be a little bit different. The first system that they're focusing on is the cortical column. Does anyone have anything to add on cortical layers or the role of the cortex, even if it's just something that they've heard about?
983450	993660	33	A	0.90268	16:23	19	Well, I think that this Menta line of AI and many of the other Ali go for it. Yes.
996510	1044860	34	B	0.81	16:36	79	I want to say that for the past couple of decades, or probably several decades, cortex has traditionally been thought of as the seat of both consciousness intelligence and also, of course, cognition. But recent studies have shown that especially studies such as Mark Som's research has shown that in fact, consciousness actually stems from literally the brain stem, not necessarily the cortex. So there are some challenges about the exact function of cortex, and the debate goes on.
1049650	1069430	35	A	0.99994	17:29	43	Nice. Okay, here's a little bit on the cortex. So it is the outer frontal part of the mammalian style brain. Insects don't have cortex, though they share a lot of the same architectures and so on. So this is like neuron tracing.
1069930	1099054	36	A	1.0	17:49	78	And there's kind of two levels of organization that people are modeling in the cortical models. The first is based upon the histological observation of the layers. These are six layers of cells, and there's a lot of development and all different functionality between the different layers. One important thing to note is it's not that they're like the layers of a Bayesian hierarchical model. It's not like each one is like up and down, up and down.
1099092	1124440	37	A	0.99998	18:19	66	So this isn't like a predictive processing architecture happening simply with these six layers. This is not a six layer model. In fact, they're connected to each other sparsely within a column, as it's shown here in 5.1. So that's like the micro anatomical structure of the cortical column. And it's called a column because it's like the layers are also arranged in this repeating way.
1124890	1181290	38	A	0.99	18:44	118	And there's just like a lot of different layouts for different regions of this cortical tissue type. And in certain situations, it is organized like linear call nerve structures, which is often seen as one of the evolutionary local maxima of depth of processing and sparsity of connections laterally. So those are the two levels of analysis that are being and as early mentioned, people yes, have gone to the consciousness angle or they've just argued that this is kind of like the massively paralyzable, but also like deep recurrent contextual, et cetera. The anagrams like the patterns that could be activated. The dimensionality is potentially super high, so it could play a role in memory signal processing.
1182270	1203470	39	A	0.81	19:42	48	And the two levels that people look at, the connections between, like, anatomically by taking these images or by doing like, stainings and stuff. Anatomically and functionally is within the column where there's certain kinds of relationships, and then across columns where there are certain kinds of relationships.
1206690	1254986	40	A	0.99997	20:06	112	Any thoughts or questions on that? But that's just why the cortex is being studied. And that's like a little bit of how the neuroscientists have been approaching this and why this is one of the important systems with a lot of theoretical modeling and empirical evidence and relevance as well. JF I remember many years ago taking a course in physiology on the visual cortex and the whole notion that the brain has some kind of structure. Always thought it was fascinating because I feel that the brain is a huge hack, patches upon patches upon patches, broadened by evolution and that there would be some structure in it is interesting.
1255108	1296302	41	D	0.99905	20:55	64	But within those structures, this picture shows it's very messy. I would never implement a system with this kind of wild interconnectivity. So I'm very curious about how much we can infer from what is really a mildly structured but highly messy architecture in terms of process theory that we're trying to elucidate from anatomy and the functionality of the brain. Nice. Thank you.
1296356	1297150	42	A	0.70753	21:36	1	Mike.
1299170	1312210	43	A	1.0	21:39	31	Yeah. That makes me think that some of that messiness is in support of redundancy. And so how do we think about redundancies in systems in the context of active inference?
1315350	1327366	44	A	0.98	21:55	27	Yeah. And like, neural systems, of course, have amazing, in some dimensions, ability to have redundancy. Other times, seemingly, there's points of failure. Jeff okay. All right.
1327388	1330780	45	A	0.51834	22:07	7	So just on the left side sorry.
1332990	1353390	46	D	0.81931	22:12	46	On the comment about redundancy. I agree. But it's worse than that. Every part often plays many different roles and participate in different functions, which makes it quite a tangle in terms of functional analysis of parts of the brain and what they do and whatnot.
1355830	1398714	47	A	0.88455	22:35	80	So five one is showing a more like pure Bayes graph with the annotation of the kinds of cells that are in the anatomical layer. So this is like a visualization of the anatomy based upon the regions that it connects, gets inputs and outputs from, and then the micro anatomy labeled according to cell types. Then with a similar but not exactly concordant. There's not a statistical test proposed for how concordant these are. It's not a statistical argument.
1398762	1447070	48	A	0.99996	23:18	87	It's not exclusive of other framings of what this anatomy is doing. Here are labeled with different parameters from the Bayes graph architectures that have been explored in the previous chapters, compatible with message passing implementations that other papers have addressed that aren't here. These are like architectures that recapitulate some of the functional and macro, structural and microstructural aspects. So this is like computational neuroscience, and it's using these models that actually have an underlying structure that is providing utility and interesting reframings of the anatomy.
1449410	1495230	49	A	1.0	24:09	98	And as the model statistical architecture begins to recapitulate aspects of the Cyto architecture, there's like no specific threshold where it's like, oh, well, now it's like an argument that it's doing that function. Like people get tantalized by it having some, oh, well, we made this network structured like a brain, or we made this network structured like a mushroom, or we did the ant colony optimization. So just because this works for what it does, doesn't mean this works for what anyone wants it to do. It's just in this huge space of bioinspired model architectures.
1499010	1562946	50	A	0.99998	24:59	117	In five, two, they move a little bit from the consideration of the columnar architecture, which are cell populations, to looking now like still the superficial to deep are the six layers of the cortex. But now a few of the variables are highlighted and their relationships. And so the ascending and descending prediction error in a predictive processing framework which is often graphically seen going up and down, bottom up and top down effects. Here is being shown in the context of the columnar cortex where like errors from one. Let's just go to where they the E's are the errors and the G's are predictions and I guess we can find out what Mu is.
1562968	1609860	51	A	0.99999	26:02	99	But basically, like, this architecture within and between columns could be like this being like the base variable being estimated and a hierarchical nested model of that. And a hierarchical model of that. So there's like a generalization statistical architecture that has compatibility with the neural architecture of the brain and it does like a pure statistical function. And that pure statistical function has resemblance with some things that the brain region is believed to do. So that allows this statistical model to be explaining and predicting and useful about the brain, which is like what computational neuroscience does.
1615810	1640150	52	A	0.99965	26:55	37	So that was the first one of the systems that they focus on then. Yeah, I guess this was then the factor systems. Okay, let's see if we can kind of quickly look at all the systems.
1645320	1657080	53	A	0.56525	27:25	25	What did anyone see or what would they like to say about figure five? Three neuroanatomy associated with active inference in modulating spinal motor reflexes.
1672830	1720460	54	A	0.92818	27:52	98	Okay, so five one was the columnar architecture and that was described in terms of what cell types were in it. Here they're going to pick up on one of those cell types, which is like the computational role. The expectations encoded by this cell type that's found in this layer of the motor cortex. And so different regions of the cortex have different apparent functions asterisk, asterisk, asterisk, but there's like a visual cortex and a motor cortex and so on. So this is in a motor region of cortical architecture that plays a certain biological function.
1723790	1736270	55	A	1.0	28:43	32	The expectations are subtracted from the incoming proprioceptive input in the horn of a spinal cord. This is like lateral cut through a spinal cord. The horns are like the butterfly parts.
1738370	1781680	56	A	1.0	28:58	74	And so there's a difference in between the incoming intensity of proprioception and the brain expected expectations and then the error drives muscle activity in the direction of suppression. So the motor activity is, like, reducing the divergence based upon the sign and the intensity of the compromise between the brain's expectations potentially arising within, like, layer five from these bet cells and the incoming sensory information, which can be modeled as, like, why?
1785680	1788540	57	A	1.0	29:45	10	I think Mu is probably the mean of that expectation.
1792240	1810304	58	A	0.69	29:52	51	I don't know what part it was mentioned. And then here's the expectation, the difference between these two. It's like a causal system flow, but, like a little different. You're getting a five out of ten pressure, you're expecting a five out of ten pressure. The motor reflex is not engaged.
1810432	1834700	59	A	0.97312	30:10	59	You're getting a seven out of ten pressure, you're expecting five out of ten. There's, like a negative two difference or whichever way you want to be subtracting, there's like a two or a negative two difference. And then that triggers some motor neuron units to fire. And then that proportionally brings the expectation into alignment with the measurement.
1841150	1869910	60	A	0.67031	30:41	70	Um, they're gonna just like that example hinged from a cortical layer. And cell type here is going to be hinging on the cortex and looking to an output region of the cortex, which is the striatum. And then they're going to do a more detailed model of a basal ganglia because it's been modeled a lot more and then also have, like, just a textual treatment of the thalamus.
1872410	1956140	61	A	0.99973	31:12	123	There's multiple papers on dopamine and active inference and so from 2012 and then 2015. This is a really interesting area of research with Dopamine because Dopamine is, like, classically described as the reward molecule. More reward, more dopamine, lower reward, lower dopamine. So isn't the whole meme inactive that we replace the reinforcement reward learning paradigm with a different imperative that has elements that reflect pragmatic value, but that isn't the overarching imperative for policy selection. And so these papers show how, like in the context of a generative model with expectations and preferences and Dopamine signaling something related to the predictive processing of stimuli under a mildly optimistic world model, good events and surprising events are still associated with Dopamine release.
1957700	1983540	62	A	1.0	32:37	52	And things that are going worse than expected are still associated with Dopamine drops. But that actually is, like, a more unified way to talk about Dopamine's empirical outcomes as opposed to the reward learning, which has to hypothesize all of these modules that translate different kinds of things into reward. Jessica.
1985960	2004940	63	E	0.97	33:05	41	Yeah, I think similarly to these I don't remember where I read this, but the brain in regards to the dopamine comment, it's also, like the anticipation of doing something and the fact that you're going to get that Dopamine kick.
2007600	2037450	64	E	0.99996	33:27	67	Basically, you get a release by anticipating something. And that maybe a little bit connects also with the active inference, the fact that you are anticipating something. You expect that to happen. And so you get that release of the dopamine in anticipation of the event happening. I don't know much, but I'm thinking it could be connected with having a predictive unexpected free energy or something.
2038380	2041000	65	A	0.99998	33:58	4	Nice. Good insight, Rohan.
2043580	2094152	66	F	0.95	34:03	98	Yeah, well, I'm not a biologist, but okay, so I just want to clarify. There are other systems in the body apart from just the brain alone, right? So you have like the autonomous or what is it, parasympathetic nervous system that controls your heart rate, your aspiration and other things. Also you have stuff like adrenaline and noradrenaline that do produce responses and other hormones also that produce responses like for hunger or satisfaction. And we basically have figured out how to modulate these things to solve modern issues for things like obesity or something like that.
2094206	2117100	67	F	1.0	34:54	52	And there are treatments available that modify these hormones levels. Right. So is this not a very limiting perspective to look at dopamine alone as the only thing? And my other question would be how does that convert into, say, motor commands? So I just increased dopamine levels without any stimulus whatsoever.
2117600	2127796	68	F	0.9981	35:17	25	Let's say someone's taking a drug. It would. So that does not necessarily translate to a motor command. Right. So how does it do this?
2127818	2163200	69	F	0.53918	35:27	78	Is there like a specialized system that figures out okay, so here's the previous action here's increase in dopamine and here's how we modulate to further increase dopamine. And where exactly do you set limits on this process? Okay, the two questions were about interacting physiological systems and the second one was about dopamine's role in motor selection. Blue, go ahead if it's related or if you want to address anything. Yeah, no, I just wanted to respond.
2163540	2202750	70	G	1.0	36:03	90	The dopamine response is there are a lot of interactions that are happening in the nervous system. Dopamine is one of the best understood, I think it's one of the ones that we've studied for a long time. And if there's an overload of dopamine, the action can actually be nonspecific. And that's what we see in Parkinson's. Right, so it's like an overload of dopamine into that system and it fries it out and then you get nonspecific action in the nervous system, motor action, the tremors and stuff.
2204000	2255736	71	A	0.99971	36:44	119	Yes. Good call. And that question about non purposeful behavior and dopamine on the positive and on the negative, like failure to engage, initiate action relating in like catatonic behavior and then like hypermotor activity associated with repetitive motions of various kinds. Dopamine is known to be different in people who are experiencing that differently and modified by drugs that target that system. But to the first question about pluralism with respect to physiological systems, for sure this model does not exclude that, in fact, its flexibility is its advantage because the inputs to a brain region now we could say, well, at this time scale it's electrochemical and at this time scale it's going to be just noradrenaline.
2255768	2304510	72	A	1.0	37:35	125	And someone says, well, how could you only model noradrenaline? Say, okay, let's look at the model with Noradrenaline and this other one and an unmodeled component so it will allow integration formally of physiological mechanisms that genuinely interact and as to why people write like, specific papers about specific hormone systems. It's just like what is chunked off in that fractal? And then also one important note is like, Colombo and Wright have written about how we don't need a monolithic theory of any neurotransmitter or any brain region. There might be like, features or components of Dopaminergic systems that it just explains and predicts that they do reward, taken lightly, that the explanation is just, of course, our explanation of a biological system.
2306560	2342440	73	A	1.0	38:26	80	And also you raise like, beyond the brain there's also glia and other cell types. So, yeah, the cool thing would be a framework where we don't a priori exclude factors that are important, but just to kind of go quickly through the example and get to that motor action. So this is an output from some putative processing that happened in the cortex and now it's projecting into some Dopaminergic regions in the subcortical area, like the basal ganglia.
2344460	2383704	74	A	0.99894	39:04	90	It's going to be a model involving outcomes. O, the difference between the preferred and the expected outcomes. The sigma squiggle expected free energy evaluated for a policy and the posterior over policies. The bold pi the figure is like shown after a lot of the description, but here is where they refer to the high and low Dopamine state. So also the movie book Awakenings is about people who have atypical Dopamine signaling and then they're given L DOPA and they come and get reinvived with life and stuff.
2383822	2384760	75	A	0.97584	39:43	1	Rohan.
2387580	2429110	76	F	1.0	39:47	82	Yeah, well, this is a little more general, but okay, so we have the Marco blanket and there are some internal states. And the Marco blanket basically connects us to the external states. Right. Or samples from the external states and then modulates the internal states accordingly. Okay, so my question is, I think if the first imperative is survival and the first imperative is to keep this system in homeostasis, which is composed of multiple interlocking and interacting complex components, right?
2431880	2464832	77	F	1.0	40:31	70	How exactly would you translate these multiple signaling modalities with multiple hormones into maintaining homeostasis with something like free energy? Because some of these things are compatible entirely. You would have to have some sort of translation mechanism. Right? So let's say that adrenaline is jumping really high and into dangerously high levels, but we only know it's dangerous because there is some system that is able to predict that.
2464886	2488600	78	F	0.99733	41:04	65	Okay, it should not go above this level because it's going to screw up something else in the system. Right. Multi scale optimization and not over optimizing one lower level parameter at the cost of some higher order parameter. Yeah, but then you come to the curse of dimensionality. So how many different things are you going to take up before it comes completely useless?
2489260	2505100	79	A	0.98448	41:29	36	Absolutely. Good question. Empirical question about what computational hardware, what measurement data sets? What sparsity of system graph? What extent of application of heuristics how accurate you need that model to be in the empirical setting.
2505680	2534440	80	A	0.98318	41:45	55	None of it in principle addressed by just the equations, all of it related to how they're actually implemented at what scale, just to quickly complete through here though, this is about the depletion of dopamine is being observed creating this akinesia failure to move and exogenous dopamine promotes impulsive behaviors of multiple different kinds.
2536780	2579300	81	A	0.99998	42:16	74	This is what it looks like. Dopamine, as again stated here is balancing modulating the balance as a neuromodulator between inferring what to do and what not to do. And so these two graphs, both of them are getting outcomes from the cerebral cortex of the observations expected under a policy. So those could be considered like predictions about future sensory states here. And the gamma is this uncertainty that's being represented by Dopamine.
2580840	2583880	82	A	0.9998	43:00	6	In this uncertainty function of Dopamine.
2587340	2633944	83	B	0.99993	43:07	110	In. The direct pathway, the policies and the difference between the preferences and expectations sigma squiggle with a tilde are being evaluated as part of the expected free energy of future policies and that is resulting in the selection of policies. So that could be like thinking through all the chess moves and then picking the one with the lowest expected free energy. Here the output in the indirect pathway feeds into the prior vector e habit and then that influences policy through this acting anatomically proposed through this other region not defined with a specific variable. So again, this is not like saying necessarily even just what it's doing.
2633982	2677060	84	A	0.99994	43:53	87	This isn't the full model. The papers read more but that's like the two pathways of action selection and it's compatible with the empirical evidence from pathology and from pharmacology and genetic studies in animals other than humans. And this is how it could be modeled with a base graph that recapitulates some of the architecture and the function. Then they describe the roles of some different neurotransmitters that have been modeled in active and like what kinds of phenomena those measurements have been used in models.
2679960	2752536	85	A	0.99	44:39	136	And then one last important part, it was in the section with the basal ganglia that was talking about this. So they show the graph of the basal ganglia and then only in this last paragraph do they describe the thalamus. So just say we're just going to do one paragraph on it but basically the thalamus has these two divisions and then they provide the interpretation that these two divisions of the thalamus could reflect first and second order statistics on other types of senses and policies. So that's like a unique prediction that potentially modeling observed neural responses or the bold signal from the blood oxygen use in that region. You'll make a better model if you fit into these categories rather than reward or rather than familiarity or any number of other criteria.
2752648	2801720	86	A	0.71593	45:52	84	So just simply fitting better is not the whole substance of validating the formalisms described earlier but it's part of the empirical grounding and examples of unique predictions and explanations. That are provided by active inference. But that was the thalmus part. And then in this very short section 56, they talk about how a lot of our interfaces are continuous like sensory apparatus and motor apparatus have continuous aspects. But then in the cognitive and decision making domains there's often much more discreteness.
2801800	2832316	87	A	0.99998	46:41	64	Even if there's multi scale discreteness resulting in a very finely graded continuum of alternatives, still there is discreteness involved. And this was explored a lot more fully in the 46 live streams. Active inference models do not contradict folk psychology where they really clarify. This is motor active inference in the continuous domain. This is decision making active inference in the discrete domain.
2832448	2835160	88	A	0.95148	47:12	8	Here's what a hybrid model looks like. Blue.
2838540	2868960	89	G	0.91	47:18	62	Oh, do I still have my hand up? Sorry, just been up. Yeah. So then they just basically say some of these models dealt with continuous phenomena like specifically the reflex arc example hashtag active incontinence time, figure four, three, et cetera. And then other models presented in this chapter are compatible with discrete alternatives like discrete variables, for example, policy selections.
2869460	2916080	90	A	0.96392	47:49	91	If there's two modeled policy outcomes then this is like a discrete model or the observations could be happening through discrete time. So there's like different opportunities for discreteness and continuous models and variables to be integrated in these architectures. Then in summary, they're outlining the points of connection between the message passing implied by the generative models of chapter four which we asked you not to read gently, and the neurobiology of inference, action and planning. And then here is going to be like a summary figure for the chapter.
2918660	2969244	91	A	1.0	48:38	102	The top row is showing some computational motifs that are plausible or compatible with different subsets of cells and regions in cortex. The bottom region are showing some extracortical structures. On the left is the basal ganglia shown from one of the previous figures. So it's a subcortical structure within the brain. Here is a spinal cord cross section and one can imagine that other structures within the brain and outside the brain would be amenable to also this kind of graph and they're just doing like kind of linking now even the models together and then showing the difference in planning.
2969372	3048628	92	A	0.73567	49:29	144	Like on the left side the basal ganglia is getting this preference difference is connecting to the expected free energy. So future policies are being, policies are being evaluated on the basis of their future ability to align with preferences. In this pathway here that's planning habits are when the preference versus expectation difference but the outcomes themselves are going to e and habits are being followed which could be seen as multiscale habits and that's influencing policy. And then here's where that kind of continuous decision and modulated handoff between more planning like and more habitual is being related to the motor implementation of the expectations of the proprioceptive loops. So like I want to be sitting still and then all of your muscles in a healthy situation are not moving versus like, I want my leg again, speaking like loosely with it.
3048654	3096044	93	A	1.0	50:48	101	I want type word, but just like, I want to lift my leg. That model, the expectations have to be updated to allow the leg to realize being up using a non. We don't have to say, well, it's more rewarding for the leg to be up. We can just say this is a computational architecture that facilitated that and generalizes to multi step planning. And then there's been multiple papers 2017 and beyond that summarized and elaborated on different aspects of this more complex continuous architectures, more complex motor and discrete interfacing, more complex decision making, active inference, of course.
3096162	3097100	94	A	0.98654	51:36	1	Rohan.
3099840	3122496	95	F	1.0	51:39	61	Yeah, I'm just wondering because a lot of this has to do with high level, more abstract behaviors or kind of abstract behaviors. Right. So is there any attempt been made to apply this to something simpler like the autonomous nervous system? Because not every signal goes through to the brain, right. Some of them just go to the spinal cord.
3122608	3191428	96	F	1.0	52:02	126	And we know this because if the spinal damage, sometimes people can't walk or they have trouble rebreathing and so on, or in other animals, like the cuttlefish, for example, that changes in the pigmentation of the skin is not dependent on brain movement, on brain activity. It's just completely autonomous, right. So has there been any attempt made to apply this to much more those kind of systems? Well, how simple or complex a system is, is kind of like how complexly we approach it, because people have been modeling single cell graphs, if that could be seen as the simplest electrochemical decision maker as well as morphological computing. And yeah, there's probably a paucity of published models on autonomic nervous system, active inference models.
3191604	3248156	97	A	0.99961	53:11	145	So there are many opportunities because they cited a huge amount of the neural empirical work here, with the goal being to summarize sort of the tip of the iceberg. But there aren't models like this for every single function or region or anything, nor even if there were, would it be the end of research in that area. So, yeah, there's a lot of open space to build specific models, which is exactly what section six and beyond and part two will take us to, which is to go from, like, identifying it, we can quickly find out whether it's been published or not and then build that model with the inputs and outputs that people are seeing as relevance. Rowan yeah, I'm sorry for monopolizing this question time. So I'm just curious, has this been applied to non biological systems in any way?
3248178	3282288	98	F	0.99988	54:08	71	Because that seems to be something that we could easily do, right? Because we have plenty of data right now. Is there anything like a better vision model than a convolutional neural net, for example, or some sort of swarm robotics attempt using something like this or even like game playing or something? Because I would be interested to read. Many of these things have been sketched or are in progress.
3282384	3337450	99	A	0.60088	54:42	130	We have our project ideas in these, like, last minutes. There's a lot of room for building projects, and there's a huge value to creative ideation of areas where it could be applied and also value for checking literature for where it might have been like a model could be reused. Like a visual foraging model that was from about cultural acquisition of pattern preference was repurposed for our ant stigma G model just by adding a pheromone trace so there isn't like a cookbook on what is out there or how models could be modified. We hope that with active block, for instance, and documentation, it'll be clearer and clearer for people to build generative models and compose them and explore different modules. So it should just be done.
3339900	3341690	100	A	0.93	55:39	4	Yeah. Okay, thank you.
3344300	3351950	101	A	0.97232	55:44	19	Any last thoughts or questions on chapter five? And then next week, we'll return to the more specific questions.
3357140	3360530	102	A	0.81617	55:57	13	Ali, and then anyone else would like a closing thought on chapter five?
3363140	3399244	103	B	1.0	56:03	74	Yeah, I just want to mention Thomas Parr's speech. I think it was a few weeks ago in center for Cognitive Neuroscience, Berlin, which I'm putting the link here in which he explained most of these topics and some more in perhaps more accessible way. So if anyone wants to yes, that's it. If anyone wants to watch it, I think that can help in understanding the content of this chapter. Nice, thank you.
3399442	3423270	104	A	0.55483	56:39	53	Yes, looks like a good one to watch. And using the same figures, maybe we could annotate, like the figures say, at this time, step here's where it's described. Okay. So those who want to, feel free to stay in this room for tools. Otherwise, thanks for joining and see you next week.
