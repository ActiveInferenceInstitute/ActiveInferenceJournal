start	end	startTime	summary	headline	gist
170	139960	00:00	We're in our second discussion on chapter six. Distinction between the interceptive extraceptive modalities which have been mentioned in box 6.1. Paper might be relevant for anyone who wants to model these modalities with the aid of active inference framework.	We're in our second discussion on chapter six on active textbook group	Active Inference 6, Discussions
141370	1039200	02:21	What distinguishes exteriorceptive proprioceptive and interoceptive modalities? What is the appropriate form for the generative model? How do we set up a generative process?	What distinguishes exteriorceptive proprioceptive and interoceptive modalities	The heart rhythm and the Interoception
1041190	1284310	17:21	What is not in this paper here is a graphical layout of the POMDP. Yet in the application, what is specified is not the loopy situation. What needs to be specified is chapter six, not chapter one. I find it very interesting, open to hearing what people think.	What is not in this paper is a graphical layout of the POMDP	Markov Blankets and the Cybernetic loop
1295060	1764612	21:35	Markup blanket is a way of thinking about basically the ontology of the system that we're about to model. The reason for not using the Schematic model of markup is because of this kind of, let's say nonphysical or nontangible relationship among the different components.	Jessica: Why not use Cybernetic model of markup instead of Schematic model	Markup Blanket and the Cognition of IT
1764666	2040560	29:24	In this generative model, there is a kind of unification, or kind of integration of interceptive and extraceptive modalities. The visual has to do with what are you trying to convey in that moment. In 20 minutes, we're going to be heading into chapter seven.	In this generative model, there is integration of interceptive and extraceptive modalities	The neural network: a generative model
2040630	2334910	34:00	 chapter seven is about perceptual processing. We use hidden Markov models for dynamic perception. This is analogous to a Coleman filter or any other number of General Bayesian filtering schemes. There's a resonance between this chapter and Step by Step, which is model stream one.	Chapter seven addresses perceptual processing and model parameter depth	Bayesian Perceptual Processing, Chapter 7
2335990	2804310	38:55	We move from a hidden Markov model crotching tiger to a partially observable Markov decision process. The key piece here is the introduction of the decision. To flesh out this POMDP, we turn to a classic par and Friston example, which is the teammase.	A hidden Markov model is a partially observable Markov decision process	An Ordinary Markov Decision Process
2805130	2940820	46:45	Learning a Novelty 7.5: We have priors on the hidden states which are themselves equipped with prior beliefs. A conjugate prior means that when used to perform Bayesian inference, the posterior belief will be the same type of distribution. Exploring these potentially open ended Bayesian graph structures is why it's so important to have structure learning.	We have priors on the hidden states which are themselves equipped with prior beliefs	Learning a Novelty 7.2: Conjugate Preors
2943510	3293740	49:03	 chapter seven describes the discrete state models. Chapter nine describes using empirical data for model driven data analysis. Chapter ten is a summary. Does anyone have any thoughts or questions? How are they going to tackle chapter seven?	Chapter six describes discrete state models. Chapter seven describes continuous time models	Post-Bayesian Learning: Chapter 7
