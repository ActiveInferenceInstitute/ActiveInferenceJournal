start	end	paragNum	speaker	confidence	startTime	wordCount	text
1210	15920	1	A	0.99979	00:01	27	Hey everyone. It is October 21, 2022. We're in cohort one of the textbook group. It's meeting 21 and we're having our first discussion on chapter nine.
19570	27800	2	A	0.44797	00:19	16	Chapter nine is model based Data analysis. Let's look at what the section the headers are.
30250	96810	3	A	0.99674	00:30	117	There's a short introduction, a discussion of metabasian methods, which is going to be very interesting and in some ways is even like an entry point to thinking about entity modeling in active inference. And so that'll be kind of fun. We'll return to variational LaPlace resonating with our just completed discussion on chapter four. And LaPlace then section 9.49.5 are going to help us see where data in terms of like gigabytes of actual good day, Yakup, actual data from measurements and so on, where these come into play with models. So how does one go from a furnished trainable model to a parameterized specified model, which actually is explaining variance in real world data sets?
97150	124420	4	A	1.0	01:37	44	And then there's some examples of GMs and some models of false inference. Well, I added only one general question from a lighter reading. I think as we all here move through this, we can generate a lot of other key points and questions.
128170	132760	5	A	0.9794	02:08	16	Ultimately, the models described in this book are only useful if they can answer scientific questions.
139670	173340	6	A	0.98356	02:19	63	We could rehearse the introduction again, but let's just go into it. So, metabasian methods. This chapter deals with the utility of active inference formulations in analyzing data from behavioral experiments so one could imagine all kinds of bodily, verbal, digital behavior. This goes beyond proof of principle simulations we've seen in previous chapters and instead exploits active inference in answering scientific questions.
176190	184240	7	A	0.9929	02:56	22	Broadly speaking, there's two related reasons for fitting a computational model to observe behavior. The first is to estimate parameters of interest.
187090	190610	8	A	1.0	03:07	7	The second is to compare alternative hypotheses.
193780	259030	9	A	0.99929	03:13	112	So to parameterize from data is one opportunity, that is to make some model of brain function and then understand within one person or one group or two groups how you can consider those parameterizations to be phenotypes. Phenotype is something of a biological organism or system that's measurable. So like femur length is a phenotype, but also a phenotype doesn't have to just be something that's measurable on the body with a ruler. Like phenotype might be distance ran in the first 50 seconds after the hawk flies through the sky on a cloudy day. And so then that is still a measurement that could be inferred or discussed or made.
259960	285020	10	A	0.56	04:19	44	And we're talking about computational phenotyping because the data and observations for sure are like a basal phenotype, like the button being clicked was measurable phenot to show. But also we could talk about the precision variables in our cognitive model as being phenotypic.
287120	335470	11	A	1.0	04:47	90	And also model comparison can be used. So whereas this first modality of parameterization is like the data set is fixed, we collected 240 fMRI data sets. Now we're going to parameterize. So we're going to give some plasticity to our model and we're going to fit parameters so that our model is like the best resembling it can to these 240 fMRI data sets we have. In the second modality, we're treating in some ways the models as fixed and then evaluating to what extent different models stack up.
336800	357750	12	A	1.0	05:36	48	And that can be used at a very fine scale to look for different models that fit better to a given data set. But also, this is where we can talk about actual biological explanations and predictions. So, like to give an example from yes, please, Ali. First.
360520	416664	13	B	0.99409	06:00	90	Sorry, a related question to this whole discussion is I think it was in Section 9.2, it says this goes beyond the proof of principle simulations we have seen in previous chapters and instead exploits active inference in answering scientific questions. I didn't quite understand this statement here because in the previous chapters, we were also engaged with modeling the real scientific phenomena. Right. So what does proof of principle simulation here exactly mean and how does it differ from the approach from answering real scientific questions? Yeah, good question.
416862	419690	14	A	0.99949	06:56	14	Does anyone want to give a thought? Or I can give a thought, too.
422780	455990	15	C	1.0	07:02	57	I mean, literally, just these following that the first and second reasons to use active inference in this way. Instead of just modeling something and saying, oh, that looks like what we intended to model, or oh, gosh, it looks really predictive, or whatever getting more rigorous with it to specifically enumerate parameters for a particular model.
458280	489070	16	C	0.68	07:38	66	And then compare multiple models. Like trying to say which one is more precise. That's a different thing than what was being done in the book previously. Like, we're just building up the model and seeing how it kind of worked before, and now we're like talking about putting it into a machinery that's going to select on models like which one's best fit or whatever.
492950	495460	17	A	0.99815	08:12	6	Well said. Yeah, I totally agree.
497910	552260	18	A	0.98861	08:17	112	Although arguably, like the chapter five Neurobiology, the tables of examples were answering scientific questions, but those generative models were not largely presented, but in the papers, one could have gone in. But yes, the previous generative models were like, built from the ground up and then like, oh, look at this intersting behavior. Now we're building the machinery to take in real data and fit that. And then there's the two uses of parameterization or the two uses of data fitting to find the best parameters for a given data set and model, and also to compare models, model comparison. All right, now we get to the very excellent figure 9.1.
553270	564230	19	A	0.99824	09:13	6	So 9.1 is the metabasian inference.
566730	570620	20	A	0.99964	09:26	7	What does anyone see in this figure?
577280	578300	21	A	0.77281	09:37	1	Ali.
582000	630830	22	B	0.99899	09:42	70	Well, as pointed out in the text, the inner box somehow represents the generative model of the phenomena we're observing, but the outer dashed box is somehow our generative model as the observers. So the term metabasian, I think used here to denote this kind of change of perspective to a higher level of viewpoint to add another layer of hierarchy to the already hierarchical generative models we had before.
633780	662250	23	A	0.91844	10:33	55	Yeah, great. Well said. We could have had an arbitrarily nested. Well, just to make a simple point, this is the discrete time formulation POMDP, Figure 4.3. And that can be nested in an arbitrary way and composed and metabasian is like putting the wrapping paper on the gift because this outermost layer is us.
663900	664680	24	A	0.62089	11:03	1	Brock.
669020	698160	25	C	0.55608	11:09	47	Um, so the last time this came up was in the context. I think it was in the other cohort. But we were talking about the provenance of the model, the impetus for it being as a tool for diagnosis of patients for nontypical sort of neuron.
701720	755380	26	C	0.96	11:41	102	I guess I'm curious maybe if there's a simple way to understand it from that perspective. But I also have another question, I guess, which is if this is us modeling, it seems like it would be like infinitely recursive because every time you add another layer, then there's another layer that's not being modeled of how we're actually modeling it. And therefore we would have to but then if we accounted for that, then there would be another outer. I don't know if that's just infinite regression towards the hidden state, one or the other or that's nonsense. Yeah, it's not.
755450	793890	27	A	0.69	12:35	66	I think let's talk about the setting of the clinical neuroimaging. So the inner model is going to be the cognitive behavioral model of the patient just speaking of the participant, the recipient of action as the patient. They're selecting green or blue coins or whatever. They're doing some behavioral paradigm isolating or choice or decision making. We're modeling their action, perception, attention and so on.
796120	827620	28	A	0.876	13:16	32	Whether we formalize it or not, the experimenter's behavior is influencing the parameterization of the patients. Like, we are choosing populations and sampling patients here is like the parameterization of the experiment.
829640	849230	29	A	0.51167	13:49	43	We'll have 20 people. They'll come in for two sessions. We're going to do eleven of this. And here's, like the data coming out of so this O here is the observation that the patient sees and their inference on what they're seeing.
855180	867820	30	A	0.40935	14:15	24	Experimental stimuli are actually an action from the experimenter. We're pushing the O to their screen. So this O tilde is their O sequence.
870000	874540	31	A	0.99539	14:30	6	We're getting data from the experiment.
879030	917370	32	A	0.99567	14:39	49	We could choose to be ignorant or implicit about our parameterization or maybe even this is a nested model. We made a governance decision in the lab to decide who gets to decide this. And the constraints were the cost and the availability nested modeling of the outer loop.
920730	951550	33	A	1.0	15:20	59	And what about infinite recursion? And I think one silver lining or saving grace or whatever, or just strength of the Bayesian graph or active inference framework is we know we can always dive in and build from a node or we can just treat the edges of our base graph as like a Markov blanket with the unknown.
954050	981274	34	A	0.99982	15:54	64	So we could say we made a simple model of decision making here and then this could be a multi agent simulation and each of those could have another nested model and then we could. Then maybe it's irrelevant or maybe we want to know anyways. But what good will it I don't know or it doesn't fit. We do want to know. Yeah.
981312	1011540	35	A	0.99282	16:21	58	Let's just say that the Pragmatic value for us is high statistical power and sensitivity for diagnosis of a neuro condition. So we want the inner loop to be in the point. We don't want to be spending money beyond diminishing returns on our experiment. We want to actually diagnose and help the people in this limited situation.
1013670	1040090	36	A	0.99999	16:53	71	Then one could do model comparison with just I'm ignoring all of this. I'm just going to parameterize I'm going to call it like I see it. Then one could have another. But if one were to engage in a research program where we collected one data set, then yeah, let's just call like we see it. But now we have the opportunity to design a second cohort of fMRI experiments.
1041070	1065330	37	A	1.0	17:21	46	Should we do two people for 100 sessions or 100 people for two sessions? Who should those hundred people be? So at that point, having a policy selection outer loop enabling seems pretty relevant. Now, we could make that simple. Maybe we always pick 30 participants.
1066150	1086490	38	A	0.99991	17:46	49	Maybe it's we either do a small experiment with three or we do a big one with 30. It's just simpler. Those are the two pathways we have. Or maybe it's et cetera. But then you could do model comparison and evaluation on those increasingly complex outer loop models.
1087870	1133900	39	A	0.99588	18:07	70	None of that would be influencing the structure of the cognitive model of the patient. So for all you block, for instance, heads in the chat, one could imagine that there's human fMRI cognitive model. This is a versionable cognitive model, open source. And then different lab groups could have open or closed models with open or closed data around their decision making about how they're using a core model.
1140420	1159240	40	A	0.99999	19:00	44	This is also just on a more qualitative point. And then I'll leave. This is where we can start to talk about moving beyond implicit biases. Not just like purging implicit biases or anything like that. It's just like we're doing investigation and exploration.
1159820	1202660	41	A	0.54264	19:19	95	We're externalizing and exteriorizing our priors and we're working such that the relevant features that are in the box are all externalized in terms of the scientific apparatuses parameterization and that's at least something where we can move towards. And someone could say, well, you haven't made your hyper hyper hyper priors explicit, but isn't that a better conversation to have than you didn't say why you chose this many people for the experiment. It could be like you didn't state the meta governance of how you came to the decision to do 30 participants.
1205800	1237100	42	C	1.0	20:05	58	It makes it really a lot easier to think about comparing and counting, showing that you accounted for your methods. And it's the same you're doing the exact same experiment, right? Might be able to move the needle a little bit on some of the reproduced earth replication crisis, things like in that vein. Yeah, great point, Ollie.
1241680	1346880	43	B	0.98344	20:41	148	Adding to what well, just mentioned. As a side note, I think approaching this kind of I mean, this approach to model based or better, the model based data analysis takes the infinitism stance as an implicit, somehow philosophical stance. Because if we don't think in terms of infinitism, I don't think we were able to model adequately these kind of metabasian reasoning because we'll get at some point to, as Brock said, just infinite regressive reasons. So at least in my opinion, it somehow implicitly takes the infinitism stance here as proposed by Peter Klein, at least in large part because, as infinitism claims, will need somehow the subjectively and objectively available reasons to model or to construct justify true belief. In other words, the reason must be non repeatingly and infinitely available to us in order for us to be able to construct that true belief.
1347040	1371980	44	B	0.99033	22:27	34	So I'm not quite sure about it, but it looks very similar to infinitism stance. Yeah. Interesting introduction. Wasn't familiar with this area. Like approximate Bayesian computation, bounded rationality, the composability of Bayes graphs.
1372320	1411880	45	A	0.5514	22:52	88	These are we get to eat our slice of cake and recognize that there's the rest of the cake and the table and the world outside of the restaurant and so on. Like we can just say the GM that we made was the thermometer and a temperature value. And someone can say, but what about humidity? And it's like there's a composability, but we're not within the Positivist or the falsificationist. Like, well, my model of temperature and thermometer is positive evidence that that's all that's happening.
1411950	1428540	46	A	0.53437	23:31	36	Or it's the best model we have. We're just waiting for it to be disproven. We can have like a Bayesian portfolio of models and all of them can be understood as maps, as composable maps.
1435940	1461780	47	A	0.99941	23:55	52	Could this lead to Bayes optimal experimental design of research programs like statistical power? The famous statistics quotation is like something about an autopsy. Like the statistician is not going to diagnose it. They come in and they tell you what went wrong with the autopsy. But that's not fundamental to statistics.
1461860	1505220	48	A	0.66047	24:21	90	That's actually just a little bit of like a joke about the practice of research, which is like the biostatistician. Just speaking from my own research experience, they're called in for assistance on a complex, already collected data set. And so it's like, well, we had three mice in March and then we had six mice in April. How do we balance this versus the Upfront conversation to help design a high statistical power experiment? And so, like statistics Upfront, it's going to increase the reproducibility and alignability of experiments.
1505880	1511770	49	A	1.0	25:05	19	It is a sanity check, if not a formal verification that the experiment is going to tell you something.
1514300	1523150	50	A	1.0	25:14	13	And it allows for replicating experiments, selecting experiments based upon their statistical power.
1527870	1544080	51	A	0.99624	25:27	41	Okay, following sections, unpack an example of generic inference that may be used for metabasian inference, the variational LaPlace with hierarchical models. Then there's going to be a simple recipe that's related to one of the other questions up here. Okay.
1549560	1603248	52	A	0.73822	25:49	104	Variational LaPlace may be used for more generic likelihood functions than those encountered earlier, which were defined as Gaussian. So previously, the family of functions that we are doing variational inference with was Gaussians. Now, we can generalize beyond using only Gaussian distributions by saying, whatever it is, we're going to do a Laplacian approximation. So even if it's like something very strange, and as mentioned in cohort two discussion just an hour ago, LaPlace approximation has two parameters the mode, the center of the bell, and just the width of the parabola. It's guaranteed to capture some of the variance of the distribution.
1603424	1628460	53	A	1.0	26:43	60	For distributions with a central tendency, gaussian or otherwise, it can do well for distributions that are like multimodal. It does not do well because it gets tricked to finding the mode, which may only capture, like, a minority of the overall bulk. And again, the SPM textbook lays out side by side LaPlace variational bays, non parametric sampling approaches.
1634470	1661770	54	A	0.99999	27:14	50	From those Laplacian approximations, we're going to do variational inference. So the real distribution might be unfactorizable or not. We don't know what family of functions it even is. But we know that the LaPlace approximation that we make on those distributions for sure will be amenable to variational inference.
1665810	1708190	55	A	1.0	27:45	63	And because of the quadratic nature, we can do gradient ascent. So just like the ball going to the bottom of the bowl, this is just an inverted parabola. So it's just gradient ascent on the mountain. All right, parametric empirical baseage of a matrix to represent the experimental layout is heavily used in SPM. This is looking a lot like a regression.
1712610	1716720	56	A	0.99993	28:32	11	This is actually a little bit of a short section 9.4.
1723910	1739110	57	A	0.99888	28:43	34	This part here comparing the evidence for a model where the second element is allowed to deviate from zero or the precise belief at zero, that is actually very much again like regression testing.
1741530	1809420	58	A	0.99996	29:01	131	If you're testing for the effect of a given factor on height that is related to the p value you get for height is related to the model that includes height and the model that doesn't include height, and then their sum of squares is compared within the appropriate statistical test, family t test, z, test, F score, all giving you a p value. So this is very much like statistics on regressions. One thing, maybe there's a deeper reading where this is clearer, but one way to talk about parametric empirical Bayes, is that, well, first off, it's parametric. You're dealing with parameters, so sometimes that's not too helpful. But the empirical part means, like, the way we're going to get our D matrix, our prior, is from the data.
1810830	1838162	59	A	0.90982	30:10	76	So let's just say that we're measuring height in the classroom. We might be able to use chapter six to specify and furnish the model. But then as soon as we make that first and then we might set our prior, we say, well let's have a super loose prior. Let's say that it could be like uniform across all but of course who knows what the maximum height is. Maybe it's not a human classroom.
1838306	1872106	60	A	0.99996	30:38	72	So we can't just specify a uniform distribution across every finite value. And so a way to kind of break that. A priori challenge where you want your prior to be loose enough to accommodate the full range of the possible data but also sharp enough so that you're not just like starting on like it's just an absurdly uninformative prior. All priors are informative. Even a uniform prior is still informative.
1872298	1924260	61	A	1.0	31:12	121	The thing that matters is the strength, the weakness of the prior and the family of the prior. So what you could do instead would be you could measure ten heights or even one and then use the mean and the variance of that sample empirically to set your prior. So set just the mean of the prior on height as the mean that you got from ten and then you could just over disperse the variance. So if there's somebody who's outside of that bound now it's like you can be more confident. So this is widely used to take an empirical data set and then use the data set's empirical values and summary statistics to parameterize the generative model.
1924630	1967330	62	A	1.0	32:04	77	And then the ball goes from there and also the expectation maximization algorithm where you have a given data set and you update the parameters in the generative model and then you generate data compatible with that model and continue. That is very close to PEB. Okay, 9.5 instructions for model based analysis. So let's copy these out because the question was like how is this figure 9.2? I guess section 9.5 and it's summarized in 9.2.
1970580	1972240	63	A	0.99973	32:50	4	Here's the six steps.
1981400	2007200	64	A	0.96	33:01	66	Oh, someone added a great okay, so this is a little bit of a review of the textbook but we're starting with data collection. Maybe the data already have been collected. So we're putting aside the situation where we're doing the meta modeling on ourself and then doing experimental design and then collecting the data. We're just going to take it from the data are collected.
2009860	2039900	65	A	0.96	33:29	46	A POMDP again discrete time in this case is structurally prepared according to the recipe in chapter six. Pumdps would we say are equivalent to specifying a likelihood function or they embody or they entail a likelihood function. What is the arrow between two and three?
2042990	2054780	66	A	0.95912	34:02	21	Does merely constructing a POMDP in this format uniquely identify a likelihood function or what work has to happen right here?
2060660	2064530	67	A	0.99987	34:20	8	Just a thought we can learn. Go ahead.
2066600	2120150	68	B	1.0	34:26	79	I don't think these arrows necessarily mean that this particular component of the modeling process necessarily translates perfectly to the other stage. I think they're more likely to show the dependencies among each steps. So in the case of the third stage or the likelihood, the construction of the likelihood function, obviously it depends on what our PMDP model functions. So I'm not sure if we can if they were 100% isomorphic, I guess they would be redundant. Right?
2120520	2129290	69	B	0.53598	35:20	14	So yeah, I think those arrows show dependencies rather than translating into each other.
2133130	2138300	70	A	0.99981	35:33	6	Thanks. I think I broadly agree.
2141890	2145950	71	A	1.0	35:41	15	And there might also be some other ways to draw it, like the prior beliefs.
2152360	2153780	72	A	0.81462	35:52	3	Is this theta.
2156140	2164840	73	A	0.62	35:56	15	I think this is using the figure nine one ontology this theta is big theta.
2168310	2178890	74	A	0.99994	36:08	14	These are the experimenters parameters. The model is the cognitive model of the entity.
2184210	2197300	75	A	0.94488	36:24	21	Italic u tilde is the observed data. So here's the observed data getting passed with the POMDP and associated likelihood function.
2202630	2252290	76	A	0.61135	36:42	94	We can the likelihood, okay, the PMDP describes variables in their relationships. The likelihood function allows us to create p, which is the distribution of observed behavior u tilde conditioned upon experimental parameters, theta observations, which are in this case the ones that are provided the stimuli, experimental stimuli and the model. Then the parametric empirical Bayes comes in when we actually get the data, it comes in in six. But we're getting there, we're on the path. When we have the data flowing from the experiment, we can then do the model inversion.
2253350	2339518	77	A	0.99999	37:33	128	Rather than describing the distribution of behavior that would be generated by theta o m, we're going to invert it so we can talk about the distribution of parameters. Experimental parameters conditioned upon MoU Bayesian equation allows us to have a proportionality between what we really want to know this top line and a I don't know if I can call it a joint distribution, but these two multiplied distributions, which is the probability of the experimental parameters given the model and separating out the probability of U conditioned on all the rest. So this is leveraging the sparsity of the inverted model to facilitate a form that is amenable to linear regression type equations. This is like y equals MX plus B. It's not, but it is.
2339604	2380700	78	A	0.99959	38:59	77	This is like the same structure y MX plus b, but then these bars and their associated variances which come from LaPlace, this is the p value and the effect size. So for this third modality, the effect size is zero and the variance is such and such. And then for this one we could say the p value or the base factor for this factor mattering, it's high. The evidence for this mattering is extremely high.
2383920	2411130	79	A	0.99894	39:43	70	So this is like if this were a bar chart and if we were in frequent statistics land and it were like ten plus or minus one, then we have a z score of ten. We're ten standard deviations away from zero. So the p value of the effect size being greater than zero is whatever it is for a p value of a z score of ten, very low.
2428000	2448020	80	A	0.94329	40:28	27	Again, this is like where the real data collection is going to be happening and interfacing. So now, here's their description. Collect behavioral data. Formulate the POMDP.
2450200	2493180	81	A	1.0	40:50	42	It takes parameters as input outputs a fully specified but not yet solved POMDP specify likely likelihood function, specify prior beliefs. Often these will be centered on zero with precisions reflecting plausible ranges. That's interesting. Note solve for posterior and model evidence.
2499120	2529800	82	A	0.94	41:39	55	Newton is probably a reference there to some gradient derivative based gradient method. I'm not exactly sure. Group level Analysis treating the estimated parameters for each individual as if they were generated by a second level model. This is exactly structurally ANOVA the group level analysis of variance. Like we had people throw the ball.
2530540	2559840	83	A	1.0	42:10	61	There was type one and type two a person and then whether type two is there an effective type. You make two models. One of them is a model without type. One of them is a model with two categories of type. Then those two models can be compared in terms in the frequentist world, in terms of their hierarchical likelihood.
2561060	2591320	84	A	0.99993	42:41	55	In the Bayesian world, however, a limitation of the hierarchical likelihood ratio test is that the models must be strictly structurally nested. They have to reflect direct, simplifications or elaborations of each other. In contrast, Bayesian modeling allows us to use the Bayes factor, which can compare models that don't need to be strictly nested.
2594000	2605920	85	A	0.99992	43:14	20	So you could test very structurally different models against each other. It's kind of like information as a common currency.
2608100	2651710	86	A	0.84791	43:28	108	In the Bayesian approach, I considered variable one, two and three. And then someone else could compare variable four, five, six. And you can be like, well, how, how much good are those two different models against what we care about in terms of informational criterion? AIC BIC the Bayes factor. Whereas if somebody said, well, I did model with one, two, three and the p value was zero one and I did this with four, five, six and the p value is zero one, those can't be directly compared because the p value is against like a local null hypothesis and there's just like, probably other issues.
2652720	2655120	87	A	0.991	44:12	8	So it's one huge advantage of the Bayesian.
2657220	2688520	88	A	0.9998	44:17	63	We're 50 years past the rubicon or 400 or whatever on Bayes. But Bayesian formulations allow for the generative recognition model, the tail of two densities. So you can specify something that generates and recognizes data. That's one advantage. Another advantage is that you have access to all the statistical tools of frequent statistics and you can also access this like informational statistics.
2689580	2718020	89	A	0.99983	44:49	65	I'm sure there's way more rabbit holes there. But like, broadly speaking, instead of taking experimental observations in frequentism and then mapping them onto a t distribution only and then saying well now, because of the p value, let me publish this paper. In the Bayes world, there are richer comparisons and more nuanced penalization functions of how many parameters versus how much variance explained.
2721880	2733000	90	A	0.9335	45:21	22	Just for example, if anyone thought Bayesians were too confident or if it wasn't the leading modern strategy for dealing with uncertainty.
2735580	2760560	91	A	0.51258	45:35	41	This design matrix for a linear model, the SPM design matrices are like very interesting looking. So the textbook has many, many of these matrices. They're encoded on a gray scale. So like, what's happening here? Here are images through time.
2760630	2781610	92	A	1.0	46:00	47	Each row is an image, could be an image in a time series, could be like different static images. Here, third column is time. So this is time .0,123,456. And then here's condition one and two. First condition, whether one is white and black, it doesn't matter.
2782300	2802328	93	A	0.99767	46:22	44	Here condition, let's just say white is one. Condition one was in effect, condition two is not, and vice versa. But you could have overlapping conditions. So it's like a graphical representation. And this is also common to see this kind of like waterfall.
2802504	2830360	94	A	0.99667	46:42	40	Here's patient 12345. Here's the three conditions in a randomized order for the 12345 patients. Here's their global blood flow, here's some other measurements, et cetera. But it turns out with so this summarizes the total design of the experiment.
2832460	2863360	95	A	1.0	47:12	48	And it turns out like you just smash it like a matrix multiplication, like the design matrix multiplied by the observations. And one can imagine, like if the observations have no relationship with the design matrix, there's a null hypothesis that you could get from random matrix theory.
2865460	2901940	96	A	0.78978	47:45	45	If the experimental design strongly influences the observations, there's some informational. Outcome 96 in our final few minutes, examples of generative models, two experiments outlined in nine five. The details are not important. Oh, but it's two isocating models. This is a continuous time left.
2902790	2927380	97	A	0.99985	48:22	28	Tracking a moving target right was a categorical eye tracking, as we've mentioned and discussed, doing some kind of a webcam eye tracking cognitive model would be massive.
2930040	2984550	98	A	0.95978	48:50	94	It's also very sensitive technology, I think, because it would be able to determine somebody's cognitive model and their attention in different ways. But it would be interesting. I was going to say they actually already do that specifically for championship, like first person shooter games to try to catch people using Aim bots. So they try to predict where your eyes are going to be based on the data in the game. And if you are shooting or you're acquiring the target faster than your eyes could have acquired the target, then, wow.
2986300	3002030	99	A	0.8944	49:46	30	Yeah, interesting. Maybe even some of the behaviors already are out there. So it's not like this is maybe the data already exists. It's like that moving target one. Yeah.
3005360	3040290	100	A	1.0	50:05	51	And interpreting this as like an Occupancy density, but then having a cognitive model where that is like an uncertainty reduction or a salience or relevance observation, which is implicitly what these usages are. Disney trailers, models of false inference, julius Caesar, we had the Obama, now we have the Caesar.
3042870	3098620	101	A	0.99997	50:42	78	Discussion of phase optimality and disorders, different pathological and neurodiverse conditions, addiction, impulsivity, compulsivity, delusions, hallucinations, interpersonal personality disorders, ocular motor syndromes, pharmacotherapy prefrontal syndromes, visual neglect, disorders of interoceptive inference. So if there's a parameters set that works, well, there's going to be various parameter sets that exhibit different outcomes. And then, as per Foucault, society is the definer of madness and all of that. And the DSM asterisk but broadly speaking, these are models of pathology.
3102660	3131080	102	A	0.99967	51:42	56	We outlined an approach that uses theoretical models described in previous chapters to pose questions to empirical data. This lets us use active inference as a non invasive tool to probe the computational processes that individuals use to make decisions. So funny. Well, the model is not invasive, okay? I don't think any model is invasive.
3132860	3142740	103	A	0.99967	52:12	13	Ultimately, the six steps in Figure 9.1 but it's not. That's an error.
3145320	3183110	104	A	0.99104	52:25	29	It's Figure 9.26. Steps in Figure 9.2 provide a generic method for designing experiments to non invasively, interrogate, implicit generative models people or other systems use to drive behavior.
3186920	3196670	105	A	0.99565	53:06	31	That's an opportunity to answer questions about the function of the nervous system in health and indices. All right, thank you, fellows. Looking forward to the conversation next week as well.
3198880	3201020	106	B	0.99946	53:18	4	Thank you. Peace. Bye.
