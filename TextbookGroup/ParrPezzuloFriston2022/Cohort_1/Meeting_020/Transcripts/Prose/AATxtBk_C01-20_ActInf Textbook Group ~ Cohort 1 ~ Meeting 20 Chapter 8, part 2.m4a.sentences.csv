start	end	sentNum	speaker	confidence	text
90	640	1	A	0.12549	You.
1170	2142	2	A	0.94924	Hello everyone.
2276	5840	3	A	0.98709	It's october 14, 2022.
6690	14940	4	A	0.9136	We're in meeting 20.
15310	17930	5	A	0.98263	We're in our second discussion of chapter eight.
18080	44966	6	A	0.99992	We have a few topics and points in chapter eight and then maybe we can preview some chapter nine and have a lot of space for any other foster questions people are having so we can jump to the questions and look at the written chapter eight questions.
45068	60980	7	A	0.99986	Or does anyone want to suggest a point for us to go to last time?
61050	71400	8	A	0.81416	We know that some of the areas we wanted to pick up on involved learning and hierarchical modeling and hybrid modeling.
96020	114760	9	A	0.96	One question that came up, I think here, but maybe we can revisit is the birdsong model is widely pointed at as an example of how communication is modeled in active inference or for active inference entities.
115500	119140	10	A	0.99999	However, it's quite literally singing from the same hymn sheet.
119300	129870	11	A	1.0	And the turn taking is based upon a joint expectation of that song being sung that way.
130880	146050	12	A	1.0	And then the actions that the birds can take, the kind of turn taking that they enact is again related to whether it's like, well, somebody has to say it is it going to be me or is it going to be them?
146660	161540	13	A	0.99987	So how do you think we would broaden that scope of communication to account for situations where there isn't a prescripted song?
165580	183660	14	A	0.96879	How do other frameworks for communication cybernetic ish or otherwise deal with the semantics of conversation, improvisation, open endedness in conversation?
193470	207630	15	B	0.99887	Actually, I had somewhat more general question about the bird songs and its relation to these particular systems that they've developed in the textbook.
208610	230622	16	B	0.99611	You see, some researchers believe that I'm sure you're much qualified to talk about this than me, but there are lots of research going around about the territorialization function of birdsong.
230766	263678	17	B	0.99925	So if we take a bird song as its territorializing mechanism, at least one of its territorializing mechanism, can we somehow put the dynamic I mean, the dynamic boundary of the markup blanket, I think would be affected from this point of view.
263844	275810	18	B	0.64	And then I'm not sure how that would translate into this specific model if we take that dynamic nature of the markup blanket boundary.
282070	287730	19	C	0.9991	Yeah, I guess I would just build on that and say that communication serves a purpose.
287810	296934	20	C	0.98	And so I think a model should incorporate what that purpose is and how it's served by the communication.
296982	306250	21	C	1.0	And then whether it happens to be syncing up with some predefined pattern or whatever is a follow on consideration.
311580	322680	22	A	0.61	The generative model in the singing from the same hymn sheet is very much like the sheet music example provided in the textbook.
324000	336610	23	A	0.55662	There's a known sheet music script such that even when there's like an error in the playing of the music, still the sheet music can be heard.
338100	345760	24	A	0.75741	So just coarsely what generative models?
347860	359300	25	A	1.0	I think it's pretty straightforward to see how a generative model could have the notation or the sheet music and then use the sheet music as its prior to kind of converge reality.
361260	364570	26	A	1.0	To what extent is communication that way?
367020	369572	27	A	0.99991	Is it totally disparate and differently structured?
369636	371252	28	A	0.99997	Or is it a little bit like a hybrid?
371316	380110	29	A	0.99144	Like you're doing inference on the sheet music that they're about to say and then you use your inference about what they're about to say to converge what they do say?
382560	386652	30	C	0.98775	Well, you asked a good question, which is, well, what are some alternative frameworks?
386716	393952	31	C	0.53	And I know, I know some or should know some, and they're not clean to mind.
394086	405750	32	C	0.99995	What comes to mind most immediately in this example is a phase lock loop in electronics which is simply a way of synchronizing one circuit's oscillation with another.
406280	410340	33	C	1.0	And this is like a phase lock loop with a bigger vocabulary.
410700	418570	34	C	0.99774	So figure out where we are in the pattern and then synchronize with it.
422880	426380	35	C	1.0	But the question of what other frameworks?
431200	437760	36	C	0.94	I mean, there's this whole field of conversation analysis.
439540	440290	37	A	0.64091	Which.
442100	445388	38	C	0.76	The field is actually called CA conversation analysis.
445564	462244	39	C	1.0	And they have identified patterns of how people communicate through certain structure of I guess we call them rhetorical devices for achieving the purpose of the conversation.
462372	467640	40	C	0.99618	So the purpose of the communication is kind of bedrock.
468300	474190	41	C	1.0	And there are multiple purposes, some of which are instrumental, some are which are social.
477280	486200	42	C	0.76	And then they have identified patterns for the way human conversation tends to proceed which are culturally influenced.
486280	491040	43	C	0.41188	There's some cross cultural aspects, but then there are certain different cultures that have different takes on it.
491110	495420	44	C	0.99998	So they identify things like, okay, now we're in the conversation opening phase.
495580	501104	45	C	0.57	Now we're in a phase of where we're exchanging information and we have turntaking.
501232	508660	46	C	0.87	Now we have notions of epistemic leadership or epistemic authority.
509740	511240	47	C	0.92701	Who's the person who's asking?
511310	516420	48	C	0.99668	Who's the person who's answering or taking those roles in the conversation?
516580	519930	49	C	0.96	And there are certain rhetorical stances that are taken.
522640	534940	50	C	0.99752	That's a pretty well worked out, I guess, even formalized system because there are well identified patterns.
535440	544976	51	C	0.98796	It's not strictly worked out because it seems like every domain a conversation analyst goes to and every every group has their own kind of flavor of it.
545078	556880	52	C	1.0	But it does have this aspect of synchronizing with respect to the underlying known patterns of each of the parties in the conversation.
572810	576160	53	A	0.47023	Bird Song is also ollie, please.
577810	578560	54	B	0.54008	Sorry.
578930	615050	55	B	0.99986	Adding to what Eric just mentioned that reminded me of a mechanism on a much smaller scale, namely the scale of cells and so on, and particularly the model proposed by Stuart Kaufman because he talks about the pluripotent, potent nature of cells and how they communicate with each other in the context of phenomena of induction, biological induction.
616350	632334	56	B	0.76	I mean, in the embryological development stage of the cells, almost all cells are pluripotent and they're capable of becoming any of the different types of cells which characterize the adult individual.
632452	659160	57	B	0.57535	So that also, from Kaufman's model perspective, these kind of inductive signals, or so to speak, communicative signals between cells can act as a kind of nonspecific stimulus which switch a cell among a variety of internally available stable states.
664990	681440	58	B	0.98731	Or let's put it this way the basic idea in this model is that the regulatory genes within a cell form a complex network in which genes interacting by their products can turn one another on or off.
684130	694302	59	B	0.99947	These patterns exhibit the kind of homeostatic stability associated with attractors of the systems.
694366	701750	60	B	0.44628	So I think that translates perfectly into this scale as well.
701820	702680	61	B	0.61744	This is small.
705050	705800	62	A	0.99613	Yeah.
707130	718250	63	A	1.0	The mapping of communication as generalized synchrony may be compatible with a variety of communication mechanisms.
718910	741620	64	A	1.0	And so it abstracts us from the media of communication per se because we can talk about the informational synchronizations between, for example, the two internal states of the two entities or multilateral synchronizations with environmental states or so on.
742550	755510	65	A	0.6034	Um, like thinking about the Bayesian mechanics, Bayesian physics, the synchronizing metronomes.
758570	762620	66	A	0.99859	They don't have a hymn sheet, they don't have sheet music.
763310	774490	67	A	0.99662	Their embodiment and coupling enables synchronization.
777490	791540	68	C	0.89	One thing I might note, I think you asked a good question here, which is how would you translate something like conversation analysis or human conversation into an active inference model?
793590	810200	69	C	0.99182	That kind of reminds me that the continuous valued models because they're limited by what you can do in these differential equations, they seem to be fairly simple.
811130	837890	70	C	0.81829	Whereas if I were to do something like thinking about human conversation in terms of active inference, I would want something more a very highly high dimensional or multistate type of system where I can have more complex patterns and they may not make these loops, these voltera loops.
838710	840638	71	C	0.93437	Is that what they call voltera?
840654	841026	72	B	0.99999	Is that right?
841048	843762	73	C	0.72522	Or is this Lawrence something?
843816	859410	74	C	0.56801	That dynamics and the Lawrence yeah, so they may not make those continuous loops, but you'd still get good structured patterns out of discrete systems.
859490	876240	75	C	0.99966	So I'd kind of be curious and I think this chapter would be cool if it had something about communication and synchrony, pattern synchrony, but in terms of discrete valued active inference models instead of the continuous valued ones.
877490	880800	76	A	0.99586	Yeah, very interesting.
881570	883306	77	A	0.45582	That's what I was wondering.
883338	892340	78	A	0.54721	Which is why is communication continuous time models are argued to be a natural fit for motor control?
893350	899300	79	A	0.66254	Are communication situations naturally fit for one or the other?
900570	905110	80	A	0.99982	Seems like no, you could imagine it either way.
905260	913322	81	A	0.98	And then also the synchronization means the internal state of one creature should come to resolve the resemble internal state of another.
913376	916060	82	A	1.0	A primitive kind of theory of mind, I think.
916830	928970	83	A	0.99992	Not as a fatal critique, but these examples put the rabbit in the hat a little bit too keenly.
929130	933242	84	A	0.9956	Like the planning example we explored wasn't truly planning.
933306	943150	85	A	0.99999	It was like a parameterized subspace where single step optimization emulated planning.
943230	958470	86	A	0.51	Now, one could argue that they believe that that's actually like a better approach than true explicit planning, but that's not what was on the COVID And then similarly, theory of mind, though qualitatively, may be a framing for communication.
959370	965660	87	A	0.99269	We're talking still about the birdsong where they have the same shared a prior regenerative model.
966190	986320	88	A	0.59997	So this doesn't in other words, theory of mind is axiomatically and implicitly embedded within this model, rather than active inference being used as in a priori first principles to generate some realized computational theory of mind.
986710	1003794	89	C	0.62	I feel like, yeah, it's like another aspect of the continuous valued formulations is there's really not that many degrees of freedom, but when you're communicating anything other than a fixed song, there's a lot of degrees of freedom.
1003842	1006146	90	C	0.74	And that's why we have symbol systems.
1006258	1013160	91	C	1.0	But symbol systems is where you would use a discrete model framework for not a continuous value to win.
1018080	1028748	92	A	0.99815	Okay, let's talk about hybrid models, discrete and continuous models and learning and updating.
1028844	1030492	93	A	0.99992	So these are two features.
1030636	1071870	94	A	0.99992	Chapter eight is within a continuous time framework, just like chapter seven, layered in these kind of patterns or archetypes of discrete time models in chapter eight, analogously, the most kernel continuous time formalism is introduced with movement control and then we're going to see some kind of extensions or patterns like design patterns that include continuous time.
1074960	1078400	95	A	0.99997	This is the message passing.
1086720	1099650	96	A	0.99922	Okay, so missing line here, but we have here, this top half is like the bottom of figure 4.3, or the top, I guess, discrete time.
1100100	1102684	97	A	0.9181	So we have B matrix as a transition matrix.
1102732	1108580	98	A	1.0	We have discrete time and we have discrete time.
1108650	1110164	99	A	1.0	T plus one, t minus one.
1110282	1145170	100	A	1.0	But within each time point we see the continuous time e whatever we want to call this motif where the B transition matrix in discrete time is functionally substituted with a derivative map such that rather than actually retro or forecasting state values through time.
1145620	1166950	101	A	1.0	This is much more like a Taylor Series approximation, where extrapolation from the present, under the auspices of slower changing causes v, which play a functional role of policies, higher derivatives capture more and more variance further and further from the origin.
1173100	1178570	102	A	0.99952	What is the Ita doing?
1187910	1210220	103	A	0.99546	It's playing some functional role to g again, allowing for a line here in the sense that it is selecting policy, but it's not policy that's being selected or discussed this way, but these slower changing factors that influence how the derivatives are made.
1212910	1216670	104	A	0.81	But is EDA a free energy variable?
1219090	1243210	105	A	0.97713	Let's just ask, okay, what do people think about this type of hybrid modeling?
1245630	1265460	106	A	0.972	How does this align with the previous decades of analog digital signals engineering and the interfaces, the digitalization of analog noise and signals and so on?
1271510	1276680	107	C	0.99637	Well, I'll lay off one thought, if it's all right.
1279770	1301870	108	C	0.86886	So one of the things that active inference lets you do is look at a past trajectory and figure out how to interpret it in terms of your variable, your state variables.
1303810	1325154	109	C	0.96084	So essentially, you look for the probability distribution over variables that optimizes the free energy and that allows you to look back in time and reinterpret evidence because you get something new.
1325192	1338134	110	C	0.6	And in light of new evidence and in some of the earlier chapters, they had this kind of example and they had the example of a dynamic programming kind of a model for this.
1338252	1344226	111	C	0.99958	So I would expect that to be the case also in communication systems.
1344258	1352080	112	C	0.84	And I guess I'm going back again to communication where to some extent you're able to reinterpret what you thought you heard before.
1353650	1356910	113	C	0.99484	It's kind of rare in language, but it happens.
1356980	1374254	114	C	0.84	There are garden path sentences, but usually most communication systems try to be relatively hierarchical in that once you interpret your continuous value signal, then you don't leave a lot of ambiguity.
1374302	1379590	115	C	0.99971	You kind of fix on that and then you have to deal with it later and sometimes you go back and do repair.
1380010	1390998	116	C	0.99989	So I'm wondering if this figure 8.6, if that allows that kind of dynamics where you're kind of tracking something at the continuous value level, you're tracking a signal.
1391174	1391562	117	C	0.53965	Why?
1391616	1412720	118	C	0.84902	Effectively by making predictions of what you're going to hear, what you observe and then is that able in this framework to go and influence the symbol level, the S variables above and how far back in time is it able to do that?
1414230	1414980	119	A	0.9899	Nice.
1415830	1421010	120	A	0.99897	That makes me think about phonemes down here and audio.
1421990	1426546	121	A	1.0	And then here are the spellings.
1426738	1441186	122	A	0.99969	So in a language or someone is speaking unclearly or you're not super familiar with a language, then you really are like doing inference on the whole time series.
1441298	1450750	123	A	0.86832	It's like that kind of retrocasting which can include even revisionism and delusions and false memories and all of that.
1450900	1473540	124	A	1.0	Now casting including the tension between representing things quote as they are versus like having delusions in the presence and then anticipation, which of course hasn't even happened unless you have a vision of time as something that always was or however.
1474070	1495050	125	A	0.98528	So it's really interesting that although this time T is an index, we are doing inference across these and maybe it would speak to some measure of information processing and memory and anticipation.
1496830	1511566	126	A	1.0	The extent to which meaning is able to be the closer meaning is to a critical point.
1511668	1522478	127	A	0.97341	Like the more this graph structure if someone says but I was just kidding, you would want that to apply to be like oh, I didn't know I was in Apprentices.
1522574	1525060	128	A	1.0	And now that they were just kidding about that.
1527530	1546490	129	A	0.99933	So it's actually like delineating those structural markers and then reinterpreting meaning is perhaps moving towards the kind of linguistic modeling.
1548030	1550720	130	A	0.87279	So yeah, to come back to it.
1552770	1554510	131	A	0.99974	So this could be a waveform.
1555170	1561710	132	A	1.0	The observables down here could be just a Fourier analysis or a pure auditory waveform.
1569940	1572832	133	C	0.99165	Yeah, I think phonemes is that's what comes to mind?
1572886	1573490	134	C	0.9997	Also.
1581250	1581950	135	A	0.81246	Okay.
1582100	1584110	136	A	0.74708	Ocular motor tasks.
1587890	1597650	137	A	0.99983	So selecting a target location and using motor behavior functionally eyes to fove eight the target.
1599910	1600930	138	A	0.95584	Figure 87.
1601000	1606680	139	A	0.98416	Okay, so figure eight seven is a hybrid or mixed generative model.
1610350	1615930	140	A	0.99618	Higher level is this is kind of like the decision making motor active inference fusion.
1625110	1635300	141	A	0.99958	Here we have a little bit of the italics and bold, which we could dive into, but don't need to do so at this moment.
1637510	1645080	142	C	0.93131	So my recollection for last week was that that corresponded to generative model versus process model.
1645450	1646966	143	C	0.89796	You think that might map again here?
1646988	1650620	144	C	1.0	I know you didn't want to dive into it.
1651070	1652026	145	A	0.85	I believe it does.
1652048	1654934	146	A	0.96128	Let's just remind ourselves where it came up earlier in the chapter.
1654982	1665710	147	A	0.72896	Yeah, it was always the very beginning right here with italics versus process in bold model in italics.
1669490	1670720	148	A	0.75385	So 87.
1672450	1679730	149	A	0.98071	So now here the discrete model is on a time period of 200 milliseconds.
1680630	1683010	150	A	0.99996	Continuous model operates continuously.
1684310	1693670	151	A	1.0	I think this speaks to how biological knowledge can be encoded in the model structure.
1694410	1702506	152	A	0.64	I mean, a more comprehensive approach would have done parameter sweeps for what the optimal number of milliseconds is to do a discrete model on.
1702688	1712602	153	A	0.99997	However, one could say, like, well, the physiology that we're interested in is accomplished with a gamma EEG cycle.
1712746	1716110	154	A	1.0	The gamma EEG cycle is this many milliseconds.
1716450	1723146	155	A	0.99995	So we're just going to treat that as like a discrete rhythm.
1723258	1733570	156	A	0.74805	Like, one can imagine if the discrete time were one millisecond here, you would be losing computational advantage and you'd be kind of like overslicing.
1734630	1752170	157	A	0.99997	Because if eye movement does happen on a timescale of hundreds of milliseconds, discretizing to one millisecond is going to be too fine, and discretizing to 1 second is not going to enable multiple actions to be taken within that frame.
1754190	1768750	158	A	0.99819	So timescale and spatial scale of a system might be able to be encoded at the phase of its construction or structure learning more generally.
1771090	1781730	159	A	0.94986	Okay, doubtsian mixture model and the hierarchical.
1782310	1793814	160	C	0.90042	Yeah, sorry, before we move on, just about the isochods, I don't understand what is gained by an active inference model for this.
1793852	1798600	161	C	0.73	I mean, why not just say you got a controller and it's a control loop and that's good enough?
1804600	1805350	162	A	0.81446	Yes.
1806680	1818120	163	A	1.0	In live stream number 50, which we're just preparing for, it's like very classical cybernetic control loop, homeostatic dynamics.
1818780	1827400	164	A	0.79	And it's interesting to ask again, what makes the model active inference?
1829440	1841600	165	A	1.0	One could say that there's a Markov blanket, but between every one of these variables, it is a model of action and perception, like so many other models of action and perception.
1842900	1890860	166	A	0.9999	So what is being shown here is it that the single imperative that energy based imperatives just speaking narrowly here, energy based imperatives can mediate decision making in discrete continuous hybrid models, and that it's possible to have a categorical decision making model in feedback with a continuous ocular motor model.
1899160	1911640	167	A	1.0	At the very least, it places this type of model within the domain and grammar of active inference modeling.
1932450	1933514	168	A	0.63683	Data clustering.
1933562	1942900	169	A	0.99966	We may have touched upon also hierarchical Gaussian filter that I know some people have worked on.
1946710	1950790	170	A	0.99753	Okay, let's look at some of the summary advances in continuous time models.
1951530	1953026	171	A	0.99588	Synthetic birdsong.
1953138	1954520	172	A	0.99999	We talked about this.
1956570	1965490	173	A	0.9985	Ocular motor delays conditioned reflex.
1966390	1968550	174	A	0.98852	Okay, so this is in the chapter.
1968970	1970498	175	A	0.9997	This is in the chapter.
1970674	1980758	176	A	1.0	I don't know about this exact paper, perhaps, but Ocular motor is in the chapter and smooth eye pursuits, conditioned reflexes, that is in this chapter.
1980854	1988762	177	A	1.0	The blank, the conditioned and the unconditioned stimuli building on the songbird model.
1988816	1990940	178	A	1.0	But the songbird model was in 2015.
1996490	1999270	179	A	0.70173	False inference from suboptimal prior beliefs.
2000570	2003190	180	A	0.5414	Can prior beliefs be suboptimal?
2005470	2006170	181	B	0.998	Sorry.
2006320	2017180	182	B	0.99967	Actually, Friston has talked about bird songs before 2015 in one of his papers, I think from 2013 or twelve.
2017790	2025534	183	B	0.71168	Yeah, it's from 2013, which is co authored with his son, I guess.
2025652	2026846	184	B	0.93651	Dominic A.
2026868	2033300	185	B	0.26138	Friston 2015 paper was not the first paper.
2033750	2039694	186	B	1.0	The name of the paper is the Free Energy Formulation of Music Generation and Perception.
2039822	2040740	187	A	0.94674	Thank you.
2041110	2041858	188	A	0.76279	Thank you.
2041944	2042580	189	A	0.54942	Yeah.
2043290	2043750	190	A	0.9996	Wow.
2043820	2046470	191	A	0.99733	Yeah, good find reminder.
2047450	2048200	192	A	0.74766	Interesting.
2050250	2053910	193	A	0.80126	Looks very much like the textbook, you know, opening quotes.
2055390	2061260	194	A	0.68	I can see how this is related to your researching too.
2063390	2064140	195	A	0.92139	Okay.
2064990	2066714	196	A	0.99981	Maybe even 2009.
2066832	2069034	197	A	0.81974	Birdsong chaotic Attractors.
2069082	2069680	198	A	0.79527	Wow.
2071490	2077870	199	A	0.51338	It's ten plus years on the birdsong paradigm.
2081270	2092690	200	A	0.97874	Okay, so deviations in perception, more eye movement.
2093050	2093894	201	A	0.63306	It's kind of fun.
2093932	2099590	202	A	0.9996	Like how we've talked about babbling and that across different domains like cicading.
2100570	2105270	203	A	0.6	Now there's the Ocular motor cicade, but are there other kinds of cicadings?
2108350	2116262	204	A	0.99997	For example, I think that knowledge management niches facilitate semantic cicading.
2116326	2116650	205	A	0.99997	Yes.
2116720	2123600	206	A	0.97092	Enabled by visual cicading as well because you have to be like looking around on the page, but it's just like what was chapter four?
2124290	2127294	207	A	0.86221	Okay, that's what we were talking about, chapter four.
2127492	2128682	208	A	0.99537	What's notation?
2128826	2133266	209	A	0.5	I think it's just sort of like the analog to scanning around a little.
2133288	2141300	210	C	0.9819	Bit, but just have in conversational analysis that's a very important topic is topic control.
2146410	2151000	211	C	0.99897	If you look at any, most conversations have multiple threads going.
2151930	2155282	212	C	0.99863	So it's like a fugue in Bach.
2155346	2157420	213	C	0.99425	Okay, which voice is this?
2157870	2163530	214	C	0.99984	Every note is in a voice and the voice has got some topic and they intertwine.
2166750	2173620	215	A	1.0	In Godel, usherbach, prelude, ant fugue.
2176440	2176900	216	A	0.99963	Nice.
2176970	2199960	217	A	0.99998	This is very interesting and I think it starts to plant some seeds towards, again, semantic circading, computational conversation analysis and generation adaptive knowledge environments like visual accessibility is one topic.
2200120	2206204	218	A	0.99788	If somebody has a visual difference, then making sure that they can see it is the enabling system.
2206402	2211040	219	A	1.0	But let's just assume that we're within a space where we can talk about what is being seen.
2211190	2218130	220	A	0.9996	So then how does someone get a clear picture of what we're talking about?
2218900	2233060	221	A	1.0	That would be through some sort of circade where you would recognize more uncertainty at the periphery and the phobia in this case is paying attention to the conversation.
2233560	2241828	222	A	1.0	And that's why with a language we're unfamiliar with, we get a little bit lost because our cicade, we're too slow, we don't have the fluency to circade.
2241844	2245470	223	A	1.0	And so the video is moving too fast to track.
2245840	2249500	224	A	0.94776	So we're just kind of like randomly listening and trying to compute.
2251360	2257840	225	A	1.0	But what if somebody were on a guided cicade journey through their semantic landscape.
2258900	2271808	226	C	0.49	I mean, just to take this a little bit further, this is also maybe it's a critical element of cognitive architecture, which is the ability to topic switch.
2271984	2276612	227	C	1.0	And in psychology and cognitive science, there's this notion of executive control.
2276666	2281984	228	C	1.0	And one of the fundamentals of executive control is to be able to topic switch.
2282032	2287764	229	C	0.99998	So you're on some task, you get an interrupt, you have to put that on a stack, deal with your interrupt.
2287892	2295096	230	C	1.0	Then when you're done, maybe the interrupt is a goal, it could be a sub goal, it could be some other topic that comes in, something you have to deal with.
2295198	2300988	231	C	1.0	Then when you're done, you have to be able to pull that back, push that back off the stack and get back to where you were.
2301074	2320324	232	C	0.99919	So all that context switching is really I mean, there's measures of how people do this and there's debates about whether people can multitask or not, whether they're actually really multitasking or they're just multithreading, but they're dividing the amount of computational process by the number of processes you have going.
2320362	2325510	233	C	0.72645	So you're actually not doing multiple things at once as effectively as if you just stuck with one.
2328680	2333720	234	A	0.89	And then it's like, do we have that intel hyperthreading capacity?
2334620	2337960	235	A	0.99997	Is it a virtualized hyper thread?
2338300	2340040	236	A	0.68333	On one thread?
2340620	2343240	237	A	0.99998	Are there actually different threads?
2347760	2359952	238	A	0.94001	Yeah, I mean the conversation analysis, other than us being right in the thick of it and it being highly engaging, support an area.
2360006	2362290	239	A	0.65182	Let's just continue through this cases here.
2362820	2364640	240	A	0.74591	Action observation.
2365060	2365904	241	A	0.58056	Okay.
2366102	2367600	242	A	0.83331	Mirror neurons.
2370420	2380100	243	A	0.99999	This may be very much related to the birdsong singing from the same hymn sheet or whatever and then doing the same dance.
2380840	2381700	244	A	0.97625	Attention.
2383900	2408770	245	A	0.99943	This is a super fascinating area and I think a lot of notebooks and applications like just taking a trace of somebody's browsing on Wikipedia or across websites and then reconstructing components of their generative model based upon their salience revealed choice is a huge area.
2409380	2442440	246	A	1.0	And then doing again, that with Ocular motor, with Webcams, and doing it with semantic landscapes, hybrid modeling, self organization, arguably with some pretty interesting advances in the last several months and days from Fields, Levin and others on the And Forestaged earlier, but on the morphogenesis as Bayesian inference.
2448510	2456720	247	A	0.58024	Okay, in our last few minutes here, let's just look ahead to nine because I think this is setting us up well.
2464050	2482150	248	A	0.87048	Okay, model based data analysis or databased modeling, or however we want to say this is about parameterizing structured models with observations.
2482970	2491898	249	A	0.63482	So rather than just by fiat dictate saying this is the structure of the model and it spits out observations like so and so.
2492064	2508282	250	A	0.99993	We want to be able to actually run it backwards, not as a generative model, but as a recognition model, so to speak, in this expectation maximization framework and parameterize our generative model from sparse or dense observations.
2508426	2520980	251	A	0.6	And that's also called parametric empirical base because you're parameterizing the prior based upon the mean invariance and patterns of some empirical data.
2523750	2524270	252	A	0.92213	Okay?
2524360	2531110	253	A	0.98	The metabasian approach, base theorem.
2533450	2541690	254	A	0.99998	This may even be something that could be introduced earlier, even though it's also meta.
2543870	2558720	255	A	0.99991	This is like the map territory fallacy, fallacy graphical abstract, which is we're making a map here's us in the bigger box, even though there's a dashed box even beyond us.
2559090	2568100	256	A	0.6626	We're making a map of a cognitive entity in its map making of its generative process.
2569350	2581400	257	A	0.87	And that was the subject also of some very rich discussion several days ago with Yaakov and Dali and Dalton Ali, anything to add on this?
2587190	2588466	258	B	0.9968	No, nothing much.
2588568	2589220	259	C	1.0	But.
2591050	2622574	260	B	0.5	One general comment I wanted to make about chapter nine is that, you see, because of my project that I've been working on for the past several months, this chapter nine has been quite helpful in developing some of my ideas around how to exactly model my music emotional recognition system that I've been working on.
2622692	2654440	261	B	1.0	But I wanted to point out one small caveat here, which is that you see, at least in my opinion, chapter nine, or this so called model based data analysis, is not conducive to generate on every model that's been described throughout the book.
2654830	2659478	262	B	0.93777	It's just focused on some specific kinds of models.
2659654	2668030	263	B	0.99993	So it might not be generalizable to every kind of model that we've seen throughout all the previous chapters.
2671170	2672160	264	A	0.99986	Good point.
2672530	2683890	265	A	0.99997	Some models might be just plug and play, so to speak, and other ones might take a little bit more work to get to use empirically.
2685910	2690758	266	A	0.99971	Okay, let's just continued in our last minutes to scan through so metabasian process.
2690844	2693560	267	A	0.94233	We're drawing inferences about an inferential process.
2696330	2698870	268	A	0.98339	It's a key point.
2699020	2701102	269	A	0.52	And that's the two levels of mapping.
2701186	2725870	270	A	0.6922	It's like the map of the map variational, LaPlace variational, bayes factorized models for computational simplicity and interpretability based upon the sparsity of coupling of variables in a Bayes graph.
2726390	2742290	271	A	0.64	And LaPlace using a parabolic approximator of the mode and a variance to ensure a simple optimizable heuristic.
2742870	2758090	272	A	1.0	Not that it perfectly recapitulates capitulates the shape of the posterior, which doesn't have to be inverted quadratic, but the LaPlace approximation is smoothly optimizable for both the mode and the variance.
2758830	2772640	273	A	1.0	And here's where they mentioned that's the parametric empirical Bayesian approach and basically LaPlace approximation can be thought of as making a commitment to the quadratic form.
2773250	2790580	274	A	0.56162	So choosing the family that your prior is going to be of and then bootstrapping your initial prior with your observed data bootstrapping not in the resampling sense, but in the starting oneself out sense.
2792410	2831380	275	A	0.99997	This was explored more in other works, but you have some likelihood function of all the parameters l of data and optimizing action involves computing beliefs about policy such that policies are proportionally taking up slices of the pie monotonically with respect to their free energy.
2832150	2846040	276	A	1.0	And then there's a precision on action parameter where you can turn it all the way down to sort of like don't know, don't care, where even large differences in free energy between policies get equilibrated out.
2846890	2849206	277	A	0.73483	That's like hot decision making.
2849388	2859050	278	A	0.85	And then absolute zero decision making would be a policy that's even 51% more likely would be always selected.
2859710	2868874	279	A	0.99985	So the variation of free energy, expected free energy, it's a bound on surprise due to Jensen's inequality and evidence lower bound.
2868922	2871230	280	A	1.0	And all this other work in variational inference.
2871650	2879890	281	A	1.0	And then that pi slicing can be tuned up or down with a shaky hand parameter.
2881110	2883170	282	A	0.99839	Soft max temperature parameter.
2887990	2892230	283	A	0.99999	If the soft max is one, the pie is undistorted.
2893850	2902150	284	A	0.99999	If the soft max is large, you have a relentless bias for better policies.
2903470	2905260	285	A	0.99905	Or it can be less than one.
2907710	2910890	286	A	0.77556	Here's some technical details of the LaPlace approximation.
2914190	2922990	287	A	0.99917	Parametric empirical base, generalized linear modeling, hashtag SPM.
2926370	2927354	288	A	0.88128	Here's recipe.
2927402	2930702	289	A	0.99943	So this is kind of like chapter six, but now it's model based data analysis.
2930766	2932180	290	A	0.99879	Collect behavioral data.
2933430	2935134	291	A	0.99989	Maybe the data has already been collected.
2935182	2938340	292	A	0.99998	Maybe there's some data sets that we already can use.
2939430	2941162	293	A	0.99355	Formulate a POMDP.
2941326	2944680	294	A	1.0	I wonder if this is as chapter six, not as chapter seven.
2945450	2947014	295	A	0.7021	It could be chapter seven as well.
2947052	2968742	296	A	0.99999	If it's discrete time, specify likelihood, perhaps we can, in the coming weeks, check out SPM Mdpvx, and they mention the scripts, data.
2968816	2969760	297	A	0.9879	This is nice.
2971330	2972560	298	A	0.99967	This will be fun.
2973250	2974014	299	A	0.99149	Chapter seven.
2974052	2978740	300	A	0.72	I mean, it is the correct if they're using this type four.
2980310	2981218	301	A	0.99567	Chapter seven.
2981304	2982260	302	A	0.99968	Chapter four.
2983350	2988210	303	A	0.9929	So this looks pretty cool, pretty interesting.
2988360	2990930	304	A	0.99248	We could walk through some examples.
2998500	3003040	305	A	0.96623	False inference, computational pathology.
3005220	3011060	306	A	0.99996	So it kind of ends like chapter eight with a table of references and a summary.
3011640	3031960	307	A	0.99827	So it's a pretty short chapter and has some formalisms, but it's only from page 179 of the PDF to 196, so it's less than 20 pages.
3035360	3038524	308	B	0.98	The next chapter, I think, is the longest chapter in the book.
3038642	3039996	309	A	0.99957	Which one is chapter ten?
3040098	3042110	310	A	0.63491	Chapter ten, 197.
3046180	3046592	311	A	0.88792	Yeah.
3046646	3048400	312	A	0.99949	That one's over 30 pages.
3049460	3055230	313	A	0.55877	Yeah, but it ends on a high note.
3060390	3066638	314	A	0.81276	All right, well, interesting conversations.
3066814	3068340	315	A	0.9987	Thanks for this.
3068790	3087930	316	A	0.99977	We will come back to chapter nine, look through it, and then peep into ten, go through ten, and really solidify our understanding of the map and I guess indirectly of the territory.
3088750	3098618	317	A	1.0	And then for those who want to join, we'll probably continue the discussion and especially start looking towards those project ideas again.
3098704	3108650	318	A	0.96716	Like we talked just a little earlier about making a dot zero sessions for the textbook.
3109110	3112494	319	C	0.36189	It so I have to apologize.
3112622	3117650	320	C	0.9979	I'm traveling for a few weeks, so I'm going to miss the next several sessions.
3118310	3119154	321	A	0.9991	It's all good.
3119192	3120130	322	A	0.99987	Thank you, Eric.
3121110	3124370	323	A	0.99998	Any other comments people want to make or I'll close the recording.
3129560	3131330	324	A	0.98681	Okay, thank you.
