start	end	speaker	sentiment	confidence	text
90	640	A	0.546256959438324	You.
1170	2142	A	0.5579421520233154	Hello everyone.
2276	5840	A	0.9091634750366211	It's october 14, 2022.
6690	14940	A	0.8457604050636292	We're in meeting 20.
15310	17930	A	0.8882363438606262	We're in our second discussion of chapter eight.
18080	44966	A	0.7225601077079773	We have a few topics and points in chapter eight and then maybe we can preview some chapter nine and have a lot of space for any other foster questions people are having so we can jump to the questions and look at the written chapter eight questions.
45068	60980	A	0.8836457133293152	Or does anyone want to suggest a point for us to go to last time?
61050	71400	A	0.7676457762718201	We know that some of the areas we wanted to pick up on involved learning and hierarchical modeling and hybrid modeling.
96020	114760	A	0.8744188547134399	One question that came up, I think here, but maybe we can revisit is the birdsong model is widely pointed at as an example of how communication is modeled in active inference or for active inference entities.
115500	119140	A	0.7241834998130798	However, it's quite literally singing from the same hymn sheet.
119300	129870	A	0.8826647400856018	And the turn taking is based upon a joint expectation of that song being sung that way.
130880	146050	A	0.830154299736023	And then the actions that the birds can take, the kind of turn taking that they enact is again related to whether it's like, well, somebody has to say it is it going to be me or is it going to be them?
146660	161540	A	0.8177711367607117	So how do you think we would broaden that scope of communication to account for situations where there isn't a prescripted song?
165580	183660	A	0.8909786939620972	How do other frameworks for communication cybernetic ish or otherwise deal with the semantics of conversation, improvisation, open endedness in conversation?
193470	207630	B	0.8923155665397644	Actually, I had somewhat more general question about the bird songs and its relation to these particular systems that they've developed in the textbook.
208610	230622	B	0.656520426273346	You see, some researchers believe that I'm sure you're much qualified to talk about this than me, but there are lots of research going around about the territorialization function of birdsong.
230766	263678	B	0.8640387058258057	So if we take a bird song as its territorializing mechanism, at least one of its territorializing mechanism, can we somehow put the dynamic I mean, the dynamic boundary of the markup blanket, I think would be affected from this point of view.
263844	275810	B	0.5958938598632812	And then I'm not sure how that would translate into this specific model if we take that dynamic nature of the markup blanket boundary.
282070	287730	C	0.5658717751502991	Yeah, I guess I would just build on that and say that communication serves a purpose.
287810	296934	C	0.7976447343826294	And so I think a model should incorporate what that purpose is and how it's served by the communication.
296982	306250	C	0.9016143083572388	And then whether it happens to be syncing up with some predefined pattern or whatever is a follow on consideration.
311580	322680	A	0.7609703540802002	The generative model in the singing from the same hymn sheet is very much like the sheet music example provided in the textbook.
324000	336610	A	0.7953140139579773	There's a known sheet music script such that even when there's like an error in the playing of the music, still the sheet music can be heard.
338100	345760	A	0.8235119581222534	So just coarsely what generative models?
347860	359300	A	0.675452470779419	I think it's pretty straightforward to see how a generative model could have the notation or the sheet music and then use the sheet music as its prior to kind of converge reality.
361260	364570	A	0.7877871990203857	To what extent is communication that way?
367020	369572	A	0.8669441342353821	Is it totally disparate and differently structured?
369636	371252	A	0.9011276364326477	Or is it a little bit like a hybrid?
371316	380110	A	0.8064810633659363	Like you're doing inference on the sheet music that they're about to say and then you use your inference about what they're about to say to converge what they do say?
382560	386652	C	0.6847633719444275	Well, you asked a good question, which is, well, what are some alternative frameworks?
386716	393952	C	0.5550642013549805	And I know, I know some or should know some, and they're not clean to mind.
394086	405750	C	0.847115695476532	What comes to mind most immediately in this example is a phase lock loop in electronics which is simply a way of synchronizing one circuit's oscillation with another.
406280	410340	C	0.6498869061470032	And this is like a phase lock loop with a bigger vocabulary.
410700	418570	C	0.8325698375701904	So figure out where we are in the pattern and then synchronize with it.
422880	426380	C	0.844606339931488	But the question of what other frameworks?
431200	437760	C	0.8262690305709839	I mean, there's this whole field of conversation analysis.
439540	440290	A	0.5689515471458435	Which.
442100	445388	C	0.8932985067367554	The field is actually called CA conversation analysis.
445564	462244	C	0.8851454854011536	And they have identified patterns of how people communicate through certain structure of I guess we call them rhetorical devices for achieving the purpose of the conversation.
462372	467640	C	0.8443121910095215	So the purpose of the communication is kind of bedrock.
468300	474190	C	0.8556610345840454	And there are multiple purposes, some of which are instrumental, some are which are social.
477280	486200	C	0.8947637677192688	And then they have identified patterns for the way human conversation tends to proceed which are culturally influenced.
486280	491040	C	0.8706862926483154	There's some cross cultural aspects, but then there are certain different cultures that have different takes on it.
491110	495420	C	0.7306647300720215	So they identify things like, okay, now we're in the conversation opening phase.
495580	501104	C	0.8783146142959595	Now we're in a phase of where we're exchanging information and we have turntaking.
501232	508660	C	0.7921328544616699	Now we have notions of epistemic leadership or epistemic authority.
509740	511240	C	0.7940564751625061	Who's the person who's asking?
511310	516420	C	0.8217036128044128	Who's the person who's answering or taking those roles in the conversation?
516580	519930	C	0.851984441280365	And there are certain rhetorical stances that are taken.
522640	534940	C	0.844533383846283	That's a pretty well worked out, I guess, even formalized system because there are well identified patterns.
535440	544976	C	0.6538712978363037	It's not strictly worked out because it seems like every domain a conversation analyst goes to and every every group has their own kind of flavor of it.
545078	556880	C	0.8869636654853821	But it does have this aspect of synchronizing with respect to the underlying known patterns of each of the parties in the conversation.
572810	576160	A	0.6924048662185669	Bird Song is also ollie, please.
577810	578560	B	0.509212851524353	Sorry.
578930	615050	B	0.802312433719635	Adding to what Eric just mentioned that reminded me of a mechanism on a much smaller scale, namely the scale of cells and so on, and particularly the model proposed by Stuart Kaufman because he talks about the pluripotent, potent nature of cells and how they communicate with each other in the context of phenomena of induction, biological induction.
616350	632334	B	0.7399969100952148	I mean, in the embryological development stage of the cells, almost all cells are pluripotent and they're capable of becoming any of the different types of cells which characterize the adult individual.
632452	659160	B	0.8811928629875183	So that also, from Kaufman's model perspective, these kind of inductive signals, or so to speak, communicative signals between cells can act as a kind of nonspecific stimulus which switch a cell among a variety of internally available stable states.
664990	681440	B	0.8645410537719727	Or let's put it this way the basic idea in this model is that the regulatory genes within a cell form a complex network in which genes interacting by their products can turn one another on or off.
684130	694302	B	0.8106814026832581	These patterns exhibit the kind of homeostatic stability associated with attractors of the systems.
694366	701750	B	0.8260173797607422	So I think that translates perfectly into this scale as well.
701820	702680	B	0.5974540710449219	This is small.
705050	705800	A	0.5491447448730469	Yeah.
707130	718250	A	0.537307620048523	The mapping of communication as generalized synchrony may be compatible with a variety of communication mechanisms.
718910	741620	A	0.7834833860397339	And so it abstracts us from the media of communication per se because we can talk about the informational synchronizations between, for example, the two internal states of the two entities or multilateral synchronizations with environmental states or so on.
742550	755510	A	0.8247841000556946	Um, like thinking about the Bayesian mechanics, Bayesian physics, the synchronizing metronomes.
758570	762620	A	0.5923510789871216	They don't have a hymn sheet, they don't have sheet music.
763310	774490	A	0.5352116823196411	Their embodiment and coupling enables synchronization.
777490	791540	C	0.6717370748519897	One thing I might note, I think you asked a good question here, which is how would you translate something like conversation analysis or human conversation into an active inference model?
793590	810200	C	0.5151596665382385	That kind of reminds me that the continuous valued models because they're limited by what you can do in these differential equations, they seem to be fairly simple.
811130	837890	C	0.6853108406066895	Whereas if I were to do something like thinking about human conversation in terms of active inference, I would want something more a very highly high dimensional or multistate type of system where I can have more complex patterns and they may not make these loops, these voltera loops.
838710	840638	C	0.8484797477722168	Is that what they call voltera?
840654	841026	B	0.7965733408927917	Is that right?
841048	843762	C	0.7485347390174866	Or is this Lawrence something?
843816	859410	C	0.6330159306526184	That dynamics and the Lawrence yeah, so they may not make those continuous loops, but you'd still get good structured patterns out of discrete systems.
859490	876240	C	0.7076796293258667	So I'd kind of be curious and I think this chapter would be cool if it had something about communication and synchrony, pattern synchrony, but in terms of discrete valued active inference models instead of the continuous valued ones.
877490	880800	A	0.8810969591140747	Yeah, very interesting.
881570	883306	A	0.8398717641830444	That's what I was wondering.
883338	892340	A	0.8664034008979797	Which is why is communication continuous time models are argued to be a natural fit for motor control?
893350	899300	A	0.8716556429862976	Are communication situations naturally fit for one or the other?
900570	905110	A	0.5882102251052856	Seems like no, you could imagine it either way.
905260	913322	A	0.8757665753364563	And then also the synchronization means the internal state of one creature should come to resolve the resemble internal state of another.
913376	916060	A	0.6776377558708191	A primitive kind of theory of mind, I think.
916830	928970	A	0.49265962839126587	Not as a fatal critique, but these examples put the rabbit in the hat a little bit too keenly.
929130	933242	A	0.5420121550559998	Like the planning example we explored wasn't truly planning.
933306	943150	A	0.8354277610778809	It was like a parameterized subspace where single step optimization emulated planning.
943230	958470	A	0.6886837482452393	Now, one could argue that they believe that that's actually like a better approach than true explicit planning, but that's not what was on the COVID And then similarly, theory of mind, though qualitatively, may be a framing for communication.
959370	965660	A	0.8789660930633545	We're talking still about the birdsong where they have the same shared a prior regenerative model.
966190	986320	A	0.7704558968544006	So this doesn't in other words, theory of mind is axiomatically and implicitly embedded within this model, rather than active inference being used as in a priori first principles to generate some realized computational theory of mind.
986710	1003794	C	0.7102711200714111	I feel like, yeah, it's like another aspect of the continuous valued formulations is there's really not that many degrees of freedom, but when you're communicating anything other than a fixed song, there's a lot of degrees of freedom.
1003842	1006146	C	0.7944492101669312	And that's why we have symbol systems.
1006258	1013160	C	0.6947084069252014	But symbol systems is where you would use a discrete model framework for not a continuous value to win.
1018080	1028748	A	0.7024301290512085	Okay, let's talk about hybrid models, discrete and continuous models and learning and updating.
1028844	1030492	A	0.8227314949035645	So these are two features.
1030636	1071870	A	0.8754425644874573	Chapter eight is within a continuous time framework, just like chapter seven, layered in these kind of patterns or archetypes of discrete time models in chapter eight, analogously, the most kernel continuous time formalism is introduced with movement control and then we're going to see some kind of extensions or patterns like design patterns that include continuous time.
1074960	1078400	A	0.7732507586479187	This is the message passing.
1086720	1099650	A	0.8075238466262817	Okay, so missing line here, but we have here, this top half is like the bottom of figure 4.3, or the top, I guess, discrete time.
1100100	1102684	A	0.8641301989555359	So we have B matrix as a transition matrix.
1102732	1108580	A	0.8458987474441528	We have discrete time and we have discrete time.
1108650	1110164	A	0.7661805748939514	T plus one, t minus one.
1110282	1145170	A	0.8747199177742004	But within each time point we see the continuous time e whatever we want to call this motif where the B transition matrix in discrete time is functionally substituted with a derivative map such that rather than actually retro or forecasting state values through time.
1145620	1166950	A	0.7656067609786987	This is much more like a Taylor Series approximation, where extrapolation from the present, under the auspices of slower changing causes v, which play a functional role of policies, higher derivatives capture more and more variance further and further from the origin.
1173100	1178570	A	0.83913654088974	What is the Ita doing?
1187910	1210220	A	0.8476429581642151	It's playing some functional role to g again, allowing for a line here in the sense that it is selecting policy, but it's not policy that's being selected or discussed this way, but these slower changing factors that influence how the derivatives are made.
1212910	1216670	A	0.8614060282707214	But is EDA a free energy variable?
1219090	1243210	A	0.8657980561256409	Let's just ask, okay, what do people think about this type of hybrid modeling?
1245630	1265460	A	0.8698225021362305	How does this align with the previous decades of analog digital signals engineering and the interfaces, the digitalization of analog noise and signals and so on?
1271510	1276680	C	0.7695335149765015	Well, I'll lay off one thought, if it's all right.
1279770	1301870	C	0.8783703446388245	So one of the things that active inference lets you do is look at a past trajectory and figure out how to interpret it in terms of your variable, your state variables.
1303810	1325154	C	0.6059573292732239	So essentially, you look for the probability distribution over variables that optimizes the free energy and that allows you to look back in time and reinterpret evidence because you get something new.
1325192	1338134	C	0.8872508406639099	And in light of new evidence and in some of the earlier chapters, they had this kind of example and they had the example of a dynamic programming kind of a model for this.
1338252	1344226	C	0.8279768824577332	So I would expect that to be the case also in communication systems.
1344258	1352080	C	0.816565990447998	And I guess I'm going back again to communication where to some extent you're able to reinterpret what you thought you heard before.
1353650	1356910	C	0.6978096961975098	It's kind of rare in language, but it happens.
1356980	1374254	C	0.7816058397293091	There are garden path sentences, but usually most communication systems try to be relatively hierarchical in that once you interpret your continuous value signal, then you don't leave a lot of ambiguity.
1374302	1379590	C	0.7907489538192749	You kind of fix on that and then you have to deal with it later and sometimes you go back and do repair.
1380010	1390998	C	0.9020921587944031	So I'm wondering if this figure 8.6, if that allows that kind of dynamics where you're kind of tracking something at the continuous value level, you're tracking a signal.
1391174	1391562	C	0.6120101809501648	Why?
1391616	1412720	C	0.8898605108261108	Effectively by making predictions of what you're going to hear, what you observe and then is that able in this framework to go and influence the symbol level, the S variables above and how far back in time is it able to do that?
1414230	1414980	A	0.7344964742660522	Nice.
1415830	1421010	A	0.8496373295783997	That makes me think about phonemes down here and audio.
1421990	1426546	A	0.6348748803138733	And then here are the spellings.
1426738	1441186	A	0.5422726273536682	So in a language or someone is speaking unclearly or you're not super familiar with a language, then you really are like doing inference on the whole time series.
1441298	1450750	A	0.8273098468780518	It's like that kind of retrocasting which can include even revisionism and delusions and false memories and all of that.
1450900	1473540	A	0.5736077427864075	Now casting including the tension between representing things quote as they are versus like having delusions in the presence and then anticipation, which of course hasn't even happened unless you have a vision of time as something that always was or however.
1474070	1495050	A	0.8912819027900696	So it's really interesting that although this time T is an index, we are doing inference across these and maybe it would speak to some measure of information processing and memory and anticipation.
1496830	1511566	A	0.8526508212089539	The extent to which meaning is able to be the closer meaning is to a critical point.
1511668	1522478	A	0.6290079355239868	Like the more this graph structure if someone says but I was just kidding, you would want that to apply to be like oh, I didn't know I was in Apprentices.
1522574	1525060	A	0.7087670564651489	And now that they were just kidding about that.
1527530	1546490	A	0.8794557452201843	So it's actually like delineating those structural markers and then reinterpreting meaning is perhaps moving towards the kind of linguistic modeling.
1548030	1550720	A	0.664013147354126	So yeah, to come back to it.
1552770	1554510	A	0.8662935495376587	So this could be a waveform.
1555170	1561710	A	0.8596745729446411	The observables down here could be just a Fourier analysis or a pure auditory waveform.
1569940	1572832	C	0.7801603078842163	Yeah, I think phonemes is that's what comes to mind?
1572886	1573490	C	0.5566182732582092	Also.
1581250	1581950	A	0.584351658821106	Okay.
1582100	1584110	A	0.708634078502655	Ocular motor tasks.
1587890	1597650	A	0.8841827511787415	So selecting a target location and using motor behavior functionally eyes to fove eight the target.
1599910	1600930	A	0.7273249626159668	Figure 87.
1601000	1606680	A	0.9109857082366943	Okay, so figure eight seven is a hybrid or mixed generative model.
1610350	1615930	A	0.8802170157432556	Higher level is this is kind of like the decision making motor active inference fusion.
1625110	1635300	A	0.7739259600639343	Here we have a little bit of the italics and bold, which we could dive into, but don't need to do so at this moment.
1637510	1645080	C	0.8998725414276123	So my recollection for last week was that that corresponded to generative model versus process model.
1645450	1646966	C	0.892195463180542	You think that might map again here?
1646988	1650620	C	0.4909289479255676	I know you didn't want to dive into it.
1651070	1652026	A	0.5529681444168091	I believe it does.
1652048	1654934	A	0.8559202551841736	Let's just remind ourselves where it came up earlier in the chapter.
1654982	1665710	A	0.8604089021682739	Yeah, it was always the very beginning right here with italics versus process in bold model in italics.
1669490	1670720	A	0.7202816605567932	So 87.
1672450	1679730	A	0.8660599589347839	So now here the discrete model is on a time period of 200 milliseconds.
1680630	1683010	A	0.8114473223686218	Continuous model operates continuously.
1684310	1693670	A	0.7987266778945923	I think this speaks to how biological knowledge can be encoded in the model structure.
1694410	1702506	A	0.8009754419326782	I mean, a more comprehensive approach would have done parameter sweeps for what the optimal number of milliseconds is to do a discrete model on.
1702688	1712602	A	0.8948021531105042	However, one could say, like, well, the physiology that we're interested in is accomplished with a gamma EEG cycle.
1712746	1716110	A	0.800632655620575	The gamma EEG cycle is this many milliseconds.
1716450	1723146	A	0.8815628886222839	So we're just going to treat that as like a discrete rhythm.
1723258	1733570	A	0.5618782639503479	Like, one can imagine if the discrete time were one millisecond here, you would be losing computational advantage and you'd be kind of like overslicing.
1734630	1752170	A	0.5493320226669312	Because if eye movement does happen on a timescale of hundreds of milliseconds, discretizing to one millisecond is going to be too fine, and discretizing to 1 second is not going to enable multiple actions to be taken within that frame.
1754190	1768750	A	0.8887645602226257	So timescale and spatial scale of a system might be able to be encoded at the phase of its construction or structure learning more generally.
1771090	1781730	A	0.7925525903701782	Okay, doubtsian mixture model and the hierarchical.
1782310	1793814	C	0.6515254378318787	Yeah, sorry, before we move on, just about the isochods, I don't understand what is gained by an active inference model for this.
1793852	1798600	C	0.533689022064209	I mean, why not just say you got a controller and it's a control loop and that's good enough?
1804600	1805350	A	0.46103888750076294	Yes.
1806680	1818120	A	0.8642309904098511	In live stream number 50, which we're just preparing for, it's like very classical cybernetic control loop, homeostatic dynamics.
1818780	1827400	A	0.559390127658844	And it's interesting to ask again, what makes the model active inference?
1829440	1841600	A	0.8410546183586121	One could say that there's a Markov blanket, but between every one of these variables, it is a model of action and perception, like so many other models of action and perception.
1842900	1890860	A	0.7602797150611877	So what is being shown here is it that the single imperative that energy based imperatives just speaking narrowly here, energy based imperatives can mediate decision making in discrete continuous hybrid models, and that it's possible to have a categorical decision making model in feedback with a continuous ocular motor model.
1899160	1911640	A	0.8597740530967712	At the very least, it places this type of model within the domain and grammar of active inference modeling.
1932450	1933514	A	0.6864212155342102	Data clustering.
1933562	1942900	A	0.8920264840126038	We may have touched upon also hierarchical Gaussian filter that I know some people have worked on.
1946710	1950790	A	0.697209358215332	Okay, let's look at some of the summary advances in continuous time models.
1951530	1953026	A	0.6755592823028564	Synthetic birdsong.
1953138	1954520	A	0.7825935482978821	We talked about this.
1956570	1965490	A	0.7578531503677368	Ocular motor delays conditioned reflex.
1966390	1968550	A	0.8600350618362427	Okay, so this is in the chapter.
1968970	1970498	A	0.8503966927528381	This is in the chapter.
1970674	1980758	A	0.8564372658729553	I don't know about this exact paper, perhaps, but Ocular motor is in the chapter and smooth eye pursuits, conditioned reflexes, that is in this chapter.
1980854	1988762	A	0.8508734107017517	The blank, the conditioned and the unconditioned stimuli building on the songbird model.
1988816	1990940	A	0.8675956726074219	But the songbird model was in 2015.
1996490	1999270	A	0.5282722115516663	False inference from suboptimal prior beliefs.
2000570	2003190	A	0.6574554443359375	Can prior beliefs be suboptimal?
2005470	2006170	B	0.509212851524353	Sorry.
2006320	2017180	B	0.9061474204063416	Actually, Friston has talked about bird songs before 2015 in one of his papers, I think from 2013 or twelve.
2017790	2025534	B	0.8954879641532898	Yeah, it's from 2013, which is co authored with his son, I guess.
2025652	2026846	B	0.7284960150718689	Dominic A.
2026868	2033300	B	0.841806948184967	Friston 2015 paper was not the first paper.
2033750	2039694	B	0.9052329063415527	The name of the paper is the Free Energy Formulation of Music Generation and Perception.
2039822	2040740	A	0.8529649972915649	Thank you.
2041110	2041858	A	0.8529649972915649	Thank you.
2041944	2042580	A	0.5491447448730469	Yeah.
2043290	2043750	A	0.7093686461448669	Wow.
2043820	2046470	A	0.7849494218826294	Yeah, good find reminder.
2047450	2048200	A	0.7792782783508301	Interesting.
2050250	2053910	A	0.6092076897621155	Looks very much like the textbook, you know, opening quotes.
2055390	2061260	A	0.856833279132843	I can see how this is related to your researching too.
2063390	2064140	A	0.584351658821106	Okay.
2064990	2066714	A	0.8192470669746399	Maybe even 2009.
2066832	2069034	A	0.5845975875854492	Birdsong chaotic Attractors.
2069082	2069680	A	0.7093686461448669	Wow.
2071490	2077870	A	0.8164032101631165	It's ten plus years on the birdsong paradigm.
2081270	2092690	A	0.8282662034034729	Okay, so deviations in perception, more eye movement.
2093050	2093894	A	0.9419089555740356	It's kind of fun.
2093932	2099590	A	0.88665372133255	Like how we've talked about babbling and that across different domains like cicading.
2100570	2105270	A	0.900309145450592	Now there's the Ocular motor cicade, but are there other kinds of cicadings?
2108350	2116262	A	0.677026629447937	For example, I think that knowledge management niches facilitate semantic cicading.
2116326	2116650	A	0.46103888750076294	Yes.
2116720	2123600	A	0.8040295243263245	Enabled by visual cicading as well because you have to be like looking around on the page, but it's just like what was chapter four?
2124290	2127294	A	0.8583004474639893	Okay, that's what we were talking about, chapter four.
2127492	2128682	A	0.7751763463020325	What's notation?
2128826	2133266	A	0.8358027935028076	I think it's just sort of like the analog to scanning around a little.
2133288	2141300	C	0.5588502287864685	Bit, but just have in conversational analysis that's a very important topic is topic control.
2146410	2151000	C	0.8378073573112488	If you look at any, most conversations have multiple threads going.
2151930	2155282	C	0.7006551027297974	So it's like a fugue in Bach.
2155346	2157420	C	0.8532519340515137	Okay, which voice is this?
2157870	2163530	C	0.8573570847511292	Every note is in a voice and the voice has got some topic and they intertwine.
2166750	2173620	A	0.8370595574378967	In Godel, usherbach, prelude, ant fugue.
2176440	2176900	A	0.7344964742660522	Nice.
2176970	2199960	A	0.9618068337440491	This is very interesting and I think it starts to plant some seeds towards, again, semantic circading, computational conversation analysis and generation adaptive knowledge environments like visual accessibility is one topic.
2200120	2206204	A	0.8242418169975281	If somebody has a visual difference, then making sure that they can see it is the enabling system.
2206402	2211040	A	0.8266180753707886	But let's just assume that we're within a space where we can talk about what is being seen.
2211190	2218130	A	0.6188826560974121	So then how does someone get a clear picture of what we're talking about?
2218900	2233060	A	0.5947023034095764	That would be through some sort of circade where you would recognize more uncertainty at the periphery and the phobia in this case is paying attention to the conversation.
2233560	2241828	A	0.8468363285064697	And that's why with a language we're unfamiliar with, we get a little bit lost because our cicade, we're too slow, we don't have the fluency to circade.
2241844	2245470	A	0.4996693432331085	And so the video is moving too fast to track.
2245840	2249500	A	0.8315784335136414	So we're just kind of like randomly listening and trying to compute.
2251360	2257840	A	0.8730354309082031	But what if somebody were on a guided cicade journey through their semantic landscape.
2258900	2271808	C	0.7647819519042969	I mean, just to take this a little bit further, this is also maybe it's a critical element of cognitive architecture, which is the ability to topic switch.
2271984	2276612	C	0.8241817355155945	And in psychology and cognitive science, there's this notion of executive control.
2276666	2281984	C	0.8481166958808899	And one of the fundamentals of executive control is to be able to topic switch.
2282032	2287764	C	0.626186192035675	So you're on some task, you get an interrupt, you have to put that on a stack, deal with your interrupt.
2287892	2295096	C	0.7172223329544067	Then when you're done, maybe the interrupt is a goal, it could be a sub goal, it could be some other topic that comes in, something you have to deal with.
2295198	2300988	C	0.8429524898529053	Then when you're done, you have to be able to pull that back, push that back off the stack and get back to where you were.
2301074	2320324	C	0.679008424282074	So all that context switching is really I mean, there's measures of how people do this and there's debates about whether people can multitask or not, whether they're actually really multitasking or they're just multithreading, but they're dividing the amount of computational process by the number of processes you have going.
2320362	2325510	C	0.5758220553398132	So you're actually not doing multiple things at once as effectively as if you just stuck with one.
2328680	2333720	A	0.7654913663864136	And then it's like, do we have that intel hyperthreading capacity?
2334620	2337960	A	0.896598219871521	Is it a virtualized hyper thread?
2338300	2340040	A	0.8390560746192932	On one thread?
2340620	2343240	A	0.8908659815788269	Are there actually different threads?
2347760	2359952	A	0.5313003659248352	Yeah, I mean the conversation analysis, other than us being right in the thick of it and it being highly engaging, support an area.
2360006	2362290	A	0.8013662099838257	Let's just continue through this cases here.
2362820	2364640	A	0.7218683362007141	Action observation.
2365060	2365904	A	0.584351658821106	Okay.
2366102	2367600	A	0.7901282906532288	Mirror neurons.
2370420	2380100	A	0.6541515588760376	This may be very much related to the birdsong singing from the same hymn sheet or whatever and then doing the same dance.
2380840	2381700	A	0.713154137134552	Attention.
2383900	2408770	A	0.9274895787239075	This is a super fascinating area and I think a lot of notebooks and applications like just taking a trace of somebody's browsing on Wikipedia or across websites and then reconstructing components of their generative model based upon their salience revealed choice is a huge area.
2409380	2442440	A	0.8569325804710388	And then doing again, that with Ocular motor, with Webcams, and doing it with semantic landscapes, hybrid modeling, self organization, arguably with some pretty interesting advances in the last several months and days from Fields, Levin and others on the And Forestaged earlier, but on the morphogenesis as Bayesian inference.
2448510	2456720	A	0.9354086518287659	Okay, in our last few minutes here, let's just look ahead to nine because I think this is setting us up well.
2464050	2482150	A	0.8693532943725586	Okay, model based data analysis or databased modeling, or however we want to say this is about parameterizing structured models with observations.
2482970	2491898	A	0.8219988346099854	So rather than just by fiat dictate saying this is the structure of the model and it spits out observations like so and so.
2492064	2508282	A	0.7598755955696106	We want to be able to actually run it backwards, not as a generative model, but as a recognition model, so to speak, in this expectation maximization framework and parameterize our generative model from sparse or dense observations.
2508426	2520980	A	0.8836451768875122	And that's also called parametric empirical base because you're parameterizing the prior based upon the mean invariance and patterns of some empirical data.
2523750	2524270	A	0.7123860716819763	Okay?
2524360	2531110	A	0.7919321656227112	The metabasian approach, base theorem.
2533450	2541690	A	0.5509747862815857	This may even be something that could be introduced earlier, even though it's also meta.
2543870	2558720	A	0.5237582325935364	This is like the map territory fallacy, fallacy graphical abstract, which is we're making a map here's us in the bigger box, even though there's a dashed box even beyond us.
2559090	2568100	A	0.7988675236701965	We're making a map of a cognitive entity in its map making of its generative process.
2569350	2581400	A	0.5072957277297974	And that was the subject also of some very rich discussion several days ago with Yaakov and Dali and Dalton Ali, anything to add on this?
2587190	2588466	B	0.6263958811759949	No, nothing much.
2588568	2589220	C	0.6056497097015381	But.
2591050	2622574	B	0.9356358647346497	One general comment I wanted to make about chapter nine is that, you see, because of my project that I've been working on for the past several months, this chapter nine has been quite helpful in developing some of my ideas around how to exactly model my music emotional recognition system that I've been working on.
2622692	2654440	B	0.5977246165275574	But I wanted to point out one small caveat here, which is that you see, at least in my opinion, chapter nine, or this so called model based data analysis, is not conducive to generate on every model that's been described throughout the book.
2654830	2659478	B	0.8085419535636902	It's just focused on some specific kinds of models.
2659654	2668030	B	0.7372950315475464	So it might not be generalizable to every kind of model that we've seen throughout all the previous chapters.
2671170	2672160	A	0.7077426314353943	Good point.
2672530	2683890	A	0.7657492756843567	Some models might be just plug and play, so to speak, and other ones might take a little bit more work to get to use empirically.
2685910	2690758	A	0.8508632183074951	Okay, let's just continued in our last minutes to scan through so metabasian process.
2690844	2693560	A	0.8765723705291748	We're drawing inferences about an inferential process.
2696330	2698870	A	0.693165123462677	It's a key point.
2699020	2701102	A	0.7367135286331177	And that's the two levels of mapping.
2701186	2725870	A	0.7709508538246155	It's like the map of the map variational, LaPlace variational, bayes factorized models for computational simplicity and interpretability based upon the sparsity of coupling of variables in a Bayes graph.
2726390	2742290	A	0.7812243103981018	And LaPlace using a parabolic approximator of the mode and a variance to ensure a simple optimizable heuristic.
2742870	2758090	A	0.6282092332839966	Not that it perfectly recapitulates capitulates the shape of the posterior, which doesn't have to be inverted quadratic, but the LaPlace approximation is smoothly optimizable for both the mode and the variance.
2758830	2772640	A	0.8737388849258423	And here's where they mentioned that's the parametric empirical Bayesian approach and basically LaPlace approximation can be thought of as making a commitment to the quadratic form.
2773250	2790580	A	0.8919971585273743	So choosing the family that your prior is going to be of and then bootstrapping your initial prior with your observed data bootstrapping not in the resampling sense, but in the starting oneself out sense.
2792410	2831380	A	0.796242356300354	This was explored more in other works, but you have some likelihood function of all the parameters l of data and optimizing action involves computing beliefs about policy such that policies are proportionally taking up slices of the pie monotonically with respect to their free energy.
2832150	2846040	A	0.6631112694740295	And then there's a precision on action parameter where you can turn it all the way down to sort of like don't know, don't care, where even large differences in free energy between policies get equilibrated out.
2846890	2849206	A	0.5347756147384644	That's like hot decision making.
2849388	2859050	A	0.6234026551246643	And then absolute zero decision making would be a policy that's even 51% more likely would be always selected.
2859710	2868874	A	0.7910385131835938	So the variation of free energy, expected free energy, it's a bound on surprise due to Jensen's inequality and evidence lower bound.
2868922	2871230	A	0.8150095343589783	And all this other work in variational inference.
2871650	2879890	A	0.8780876994132996	And then that pi slicing can be tuned up or down with a shaky hand parameter.
2881110	2883170	A	0.8256257176399231	Soft max temperature parameter.
2887990	2892230	A	0.8204753398895264	If the soft max is one, the pie is undistorted.
2893850	2902150	A	0.5971507430076599	If the soft max is large, you have a relentless bias for better policies.
2903470	2905260	A	0.7473216652870178	Or it can be less than one.
2907710	2910890	A	0.9044063687324524	Here's some technical details of the LaPlace approximation.
2914190	2922990	A	0.8684752583503723	Parametric empirical base, generalized linear modeling, hashtag SPM.
2926370	2927354	A	0.793427050113678	Here's recipe.
2927402	2930702	A	0.8498609662055969	So this is kind of like chapter six, but now it's model based data analysis.
2930766	2932180	A	0.8507646918296814	Collect behavioral data.
2933430	2935134	A	0.8417515158653259	Maybe the data has already been collected.
2935182	2938340	A	0.7225111722946167	Maybe there's some data sets that we already can use.
2939430	2941162	A	0.7409015893936157	Formulate a POMDP.
2941326	2944680	A	0.8395788073539734	I wonder if this is as chapter six, not as chapter seven.
2945450	2947014	A	0.8426178693771362	It could be chapter seven as well.
2947052	2968742	A	0.892695426940918	If it's discrete time, specify likelihood, perhaps we can, in the coming weeks, check out SPM Mdpvx, and they mention the scripts, data.
2968816	2969760	A	0.9823256134986877	This is nice.
2971330	2972560	A	0.965087354183197	This will be fun.
2973250	2974014	A	0.7534810304641724	Chapter seven.
2974052	2978740	A	0.713277280330658	I mean, it is the correct if they're using this type four.
2980310	2981218	A	0.7534810304641724	Chapter seven.
2981304	2982260	A	0.7385165095329285	Chapter four.
2983350	2988210	A	0.990407407283783	So this looks pretty cool, pretty interesting.
2988360	2990930	A	0.8597418069839478	We could walk through some examples.
2998500	3003040	A	0.4992190897464752	False inference, computational pathology.
3005220	3011060	A	0.8864588737487793	So it kind of ends like chapter eight with a table of references and a summary.
3011640	3031960	A	0.7260866761207581	So it's a pretty short chapter and has some formalisms, but it's only from page 179 of the PDF to 196, so it's less than 20 pages.
3035360	3038524	B	0.6683200597763062	The next chapter, I think, is the longest chapter in the book.
3038642	3039996	A	0.903985857963562	Which one is chapter ten?
3040098	3042110	A	0.8565765023231506	Chapter ten, 197.
3046180	3046592	A	0.5491447448730469	Yeah.
3046646	3048400	A	0.535873293876648	That one's over 30 pages.
3049460	3055230	A	0.7581192851066589	Yeah, but it ends on a high note.
3060390	3066638	A	0.8109741806983948	All right, well, interesting conversations.
3066814	3068340	A	0.9442082047462463	Thanks for this.
3068790	3087930	A	0.7270110249519348	We will come back to chapter nine, look through it, and then peep into ten, go through ten, and really solidify our understanding of the map and I guess indirectly of the territory.
3088750	3098618	A	0.5204094648361206	And then for those who want to join, we'll probably continue the discussion and especially start looking towards those project ideas again.
3098704	3108650	A	0.8984781503677368	Like we talked just a little earlier about making a dot zero sessions for the textbook.
3109110	3112494	C	0.48679396510124207	It so I have to apologize.
3112622	3117650	C	0.8579114079475403	I'm traveling for a few weeks, so I'm going to miss the next several sessions.
3118310	3119154	A	0.8811412453651428	It's all good.
3119192	3120130	A	0.9119052290916443	Thank you, Eric.
3121110	3124370	A	0.8208767771720886	Any other comments people want to make or I'll close the recording.
3129560	3131330	A	0.7883908748626709	Okay, thank you.
