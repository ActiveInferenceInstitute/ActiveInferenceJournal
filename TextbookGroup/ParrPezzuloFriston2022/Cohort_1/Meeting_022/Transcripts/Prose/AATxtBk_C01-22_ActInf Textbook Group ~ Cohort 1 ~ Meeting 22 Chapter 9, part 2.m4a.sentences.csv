start	end	sentNum	speaker	confidence	text
1428	1918	2	B	0.79864	Hello.
2004	3962	3	B	0.99999	Thanks for all joining.
4106	13550	4	B	0.83615	It's active textbook group cohort one meeting 22, chapter nine on October 28.
16750	29170	5	B	0.99	Okay, we're in the second discussion on chapter nine, model based data analysis.
32430	49710	6	B	0.62706	Would anyone like to add anything they want or mention how the generative model discussion from the previous 1 hour relates to model based data analysis?
50130	52800	7	B	0.99996	How does chapter four relate to chapter nine?
67330	70320	8	B	0.99838	What does chapter nine address?
72530	77070	9	B	0.99953	What do chapters six and nine address that chapter four doesn't?
84810	102340	10	A	0.40854	Um, I mean, six is about thinking about applying it in, like, incredibly kind of simplified step by step kind of way.
103670	112840	11	A	0.91	And nine is very specifically about answering scientific questions with it and doing that with.
116170	117670	12	C	0.99719	This metabasian.
118330	121370	13	C	0.62971	It's like almost nested.
124460	127400	14	A	0.72502	Sort of schema of active inference.
128700	142556	15	A	0.68724	So, I mean, that's the through line, I guess, but I'm not sure more.
142578	144030	16	C	0.99983	Than that what to say.
144740	146892	17	B	0.80644	That's really insightful.
146956	148320	18	B	0.99998	Thank you, Ali.
151540	166912	19	D	1	Yeah, actually, I would compare it to a kind of learning how to solve problems in, I don't know, mathematics or other physics or other areas.
167056	190348	20	D	0.99999	For example, in chapter four, we acquired some necessary knowledge or prerequisite about how to think about the phenomena or the problem we're dealing with.
190514	206450	21	D	0.94115	Chapter six kind of outlines a roadmap a roadmap about how exactly we should proceed to solve that problem in a kind of formulaic way.
207000	226536	22	D	1	And chapter nine, actually, in chapter nine, we get our hands dirty and try to solve some of the actual or empirical problems with the tools or techniques we had learned in chapter four and six.
226718	247100	23	D	0.9945	So in this case, I somehow think of chapter nine as a kind of case of study well, kind of case of studies or a kind of solved problem section of this textbook.
247260	255440	24	D	0.99	And, yeah, I don't know how much that captures their nature.
256420	257588	25	B	0.90989	That's great.
257754	258468	26	B	0.81724	Wow.
258634	260336	27	B	0.98584	Great thoughts.
260528	261910	28	B	1	I totally agree.
265240	267780	29	B	0.99544	Let's look at the table of contents.
270220	273332	30	B	0.63597	Chapter one, special overview.
273396	276852	31	B	0.92886	Chapter mirror symmetry.
276996	278730	32	B	1	Same, but different with ten.
280300	320200	33	B	0.99923	So now in the middle eight chapters, two chapters on the low road and the high road, helping two different approaches which can be developed, like in a lot more detail, to approach active inference from two fascinating and non controversial starting points Bayesian inference from the low road free energy principle and the repeated measurement persistence imperative.
324780	329800	34	B	0.81692	Chapter four is the first chapter on active inference.
330620	337420	35	B	0.99988	Active inference is about the generative models that are being specified and how they're being computed.
339760	356560	36	B	0.99998	After just one chapter on active inference, it goes to the area where the most research and modeling has been done in active inference, which is computational manalian neuroanatomy.
358520	364180	37	B	1	One chapter on active, one chapter on the primary domain.
366200	372940	38	B	1	First half of the book, second half of the book.
373470	383210	39	B	0.52913	This is the part where you're going to be in parallel, perhaps on your first, but perhaps not on your first reading.
383650	393230	40	B	0.98106	You're going to be doing playing through these applied aspects of modeling.
393970	397970	41	B	1	First is the recipe for designing active inference models.
398470	405540	42	B	0.99997	In Chapter Six, as both of you have, very nicely set.
408070	426838	43	B	1	Then the Figure 4.3 Dialectic discrete Continuous Time is revisited in two chapters because it probably it's one key difference.
426924	428566	44	B	0.32625	It's a minimum of two.
428748	431974	45	B	0.99989	So it prevents, like any like, oh, well, it has to be a PMDP.
432022	433820	46	B	0.99943	It's like, well, obviously not.
435090	456930	47	B	0.78546	So it keeps the space of generative modeling open and it allows for discussion of the very interesting topic of hybrid active inference nested models with continuous actuators, for example, but discrete decision making apparatus.
460070	468598	48	B	0.99989	So it just is like wanting to cover these two key types of models in a bit more detail than was addressed in Chapter Four.
468764	473978	49	B	0.99514	But this was the first possible moment to address it after 4.3.
474064	474886	50	B	1	Just kidding.
474998	476060	51	B	0.99994	Maybe not.
477550	489920	52	B	0.88	Then Chapter Nine, yeah, where we are now, which is just, okay, you've built your pure discrete time pure continuous time or hybrid generative model.
490690	495440	53	B	0.99997	If it's a toy model, you can just generate data and just do whatever you want.
495890	515878	54	B	1	Or you might have data from sensors or real world or however that's in the data format that your generative model expected to receive, which was part of your design process, you could have determined what structure literally the data is going to be in.
516044	526106	55	B	0.99794	Is it going to be like, yes, data can be reshaped, but just broadly, is it like 256 sensors in a row of one?
526208	528380	56	B	1	Or is it like eight by eight?
528750	530700	57	B	1	Just those kinds of questions.
531390	556900	58	B	0.91412	So that when the data start coming in for the experiment, whether you generated the data from the generative model or whether you're using it in a purely recognition model capacity on real world data, what does it look like to do statistical modeling with these statistical models that we've been using?
558970	561640	59	B	0.92	And then chapter ten is a review.
562490	577450	60	B	0.94	It restates what each chapter does, provides some further thoughts, and just summarizes the unifying capacity of active inference modeling.
582500	588670	61	B	0.98	Then there are the appendices Ali.
591190	621050	62	D	0.67524	Also one in my opinion, very interesting section of Chapter Nine is the section on models of false inference, section 9.7, in which there's an interesting definition of the disorders, I mean the mental disorders, and how we can actually computationally model those different disorders.
622510	622970	63	D	0.52206	Sorry.
623040	632202	64	D	1	It says that here the disorder does not necessarily imply that the inferential mechanism is flawed.
632346	639410	65	D	0.99831	In most of the studies, the inferential mechanism operates normally but based on a flawed generative model.
639560	658790	66	D	0.99981	So that's basically what we had learned about how we can somehow update our beliefs or correct our perceptions based on either refining our generative model or modifying our generative model.
658860	670950	67	D	1	Or somehow, sometimes we can just well, act upon those errors and try to reduce our uncertainties.
671110	689120	68	D	1	But in this case, it's a very interesting point on the case of computational pathologies because oftentimes people ask, well, what does active inference actually explain?
689910	702182	69	D	0.99954	So I think this is a very good example of its very meaningful and significant application in any sense of the word.
702316	730782	70	D	0.78923	So if we can somehow computationally model these kind of disorders, we'll most probably have a much better understanding of its origin and the way to probable treatments of those disorders and many other applications can comes to mind.
730916	747060	71	D	0.728	But yeah, I think this part of the chapter nine is something that was not addressed quite explicitly in the previous chapters and in my opinion is the most interesting part of this one.
749270	749874	72	B	0.99997	Great.
749992	750610	73	B	0.78639	Awesome.
750760	751326	74	B	0.67	Yeah.
751448	758310	75	B	1	It reminds me of the table in chapter four, or sorry, chapter five with the neurotransmitters.
758730	763560	76	B	0.99945	So they were still at the organ systems level in chapter five.
764350	779694	77	B	0.98248	But five is very much related to nine, I guess in that sense as well, because it's like, here's what dopamine does, here's what acetylcholine does just at the computational model level.
779892	797314	78	B	1	And then here it's like that computational model was fit, like between the phenomena, like attention or policy precision or however phenomena to a molecule in chapter five.
797512	805080	79	B	1	Here, the phenomena is being connected to a real human clinical application.
808800	822530	80	B	0.99989	So it's not that we're saying or anyone is saying or anything like that, that the molecule is being directly linked to this paper, even if it's mentioned.
823220	844520	81	B	1	The direct linkage approach is people in group X have more molecule, have less molecule, and even the neuroimaging approach can be seen as a variant of that, which is people in group X have more brain activation pattern.
847500	858030	82	B	0.99988	In computational pathology, those kinds of biochemical measurements and neuroimaging measurements can, and they are used.
859760	875280	83	B	0.99999	However, this type of computational modeling is referring to parametric modeling, where the parameters are related to the pathology.
877060	882630	84	B	0.99992	So it's not an a priori classification of those with and without.
883320	892040	85	B	1	And then descriptive statistics showing that a biochemical or a brain imaging pattern are differentially expressed.
893020	895268	86	B	0.99908	That's descriptive statistics.
895444	897700	87	B	0.77438	It's not computational pathology.
897780	911180	88	B	1	It might be precision pathology, but it could still be precision or big data or however, with just like purely doing data summaries, doing a random forest model to diagnose.
912000	923948	89	B	0.99998	These models have a cognitive structural hypothesis about the nature of these phenomena, like the ocular motor syndromes.
924044	926608	90	B	0.99995	Again, it's not just people with the diagnosis and without.
926774	932660	91	B	0.94345	It's a neurocognitive model of eye behavior.
934920	954140	92	B	1	And then explanations can be made from clinical data by rendering various aspects of the generative model conditionally independent of others, ocular motor syndrome, such as intranuclear optipomilegias, may be induced.
956080	967040	93	B	0.99961	So if you just were diagnosing these as different conditions, maybe they have similar ideologies how the condition arises, maybe they have different, maybe they have multiple.
968180	983380	94	B	0.99998	But these two conditions computationally can be understood as parametric modulating in a computational model of ocular motor behavior.
986120	1001240	95	B	0.91905	This isn't people with internuclear opto, DA, DA, DA have higher glucose or lower glucose or this brain region or this aspect of them, those are all absolutely valid approaches.
1002300	1009192	96	B	0.99985	That's like scientific methodological pluralism, which is like, it's okay that people want to do different approaches.
1009256	1040470	97	B	0.77793	Everybody's contributing to a common people who care about this and are creating high quality reproducible data, their data will always be useful and their perspectives are valid and we don't want to have a discourse space on inter nuclear optipomygia that's saying that one model is like simply the only correct model.
1042780	1073200	98	B	0.98981	This paper makes a positive contribution and points to some new ways of thinking about various pathologies and thinking beyond the ways that they've been worked on before, where one can imagine that before 2000 and so on, you had what health records.
1073700	1076320	99	B	1	And you have some double blind experiments.
1077460	1085140	100	B	1	And so you might do a meta analysis to find correlations with features of people and all of those things that we've been describing.
1085960	1096360	101	B	1	But it was not plausible to actually implement computational models of these phenomena.
1097420	1121280	102	B	1	Now, interestingly, that's something that can be worked on by researchers directly, and then somebody can a doctor could download Ocular motor syndromes programming, whatever it is, but this can be developed in a pure research context.
1122100	1144530	103	B	1	And the Generative Model is like the interface for the kind of information that might not be available to the person developing the Generative Model because it relates to a lot of problems and issues about data availability.
1148470	1152594	104	B	0.95281	That's one kind of just side note, but dilly.
1152642	1166810	105	B	0.99987	Thanks for raising that point that I just wanted to emphasize and unpack, which is that this table, which is taking up two and a half pages of a pretty short book is describing.
1169090	1177786	106	B	0.99997	These are like the cases that can be brought up, which they're providing in a helpful table for what active inference describes.
1177978	1190100	107	B	0.99439	So if the principle of least action, gauge theory, et cetera, sophistication does not interest one, these are more pragmatic value.
1190790	1205660	108	B	0.55	Now that will probably move the goalpost to show me where the computational modeling helped somebody with delusions and that's a fine place to want to go.
1207470	1216890	109	B	0.99998	But it's also a standard and an approach that it's not related to the substance of the theoretical development.
1223400	1228724	110	A	0.84	I mean, I think you could probably the response to that question might be.
1228762	1256060	111	C	0.99995	Something like the difficulty of implementing that model in a way that provides actionable real time affordances to address the aberrant priors in a way that's causally.
1257280	1260830	112	C	0.97051	It's going to actually affect that system.
1262740	1272420	113	C	0.99996	We need either more compute or a particular kind of algorithmic medicine that doesn't exist yet or et cetera.
1272840	1284570	114	C	0.99747	But that's not a problem with the particular approach, it's just an insufficiency of ability to enact it, I guess.
1286300	1297464	115	C	0.7612	But I wanted to ask a question about specifically this aberrant prior beliefs.
1297512	1301048	116	C	0.98	It says ultimately the pathology is a consequence of aberrant prior beliefs.
1301144	1303980	117	C	0.89119	It's not the Generative Model, it's aberrant prior beliefs.
1307360	1321556	118	C	0.99	I think this is like Ellie's point and everything that you just went through is correct that this is kind of where the rubber really meets the road for its value in demonstrating or whatever.
1321738	1325670	119	C	0.9999	But I'm wondering also.
1327480	1334200	120	A	0.87	To me that there's like an easy confusion thing there about beliefs and priors.
1336220	1338250	121	C	0.96976	If they just believed the right thing.
1339340	1343384	122	A	0.99	Then they wouldn't have these that's not.
1343422	1345370	123	C	0.99999	Really what that means though, right?
1346880	1350620	124	A	0.80342	Is another way of saying this, like in the Ocular motor.
1352560	1365168	125	C	0.96475	Disorder case, like a kind of neurobiological bias in some kinds of cells or whatever, right.
1365334	1383108	126	C	0.99919	That's pathologically different than normal or whatever, like some receptor for a particular chemical or whatever, is that a kind of thing?
1383194	1388650	127	A	0.88	That the way of saying that differently in that particular case that is.
1391420	1391784	128	D	0.95	More.
1391822	1394010	129	C	0.91349	Commensurate with what they're actually saying there.
1394540	1412850	130	C	0.66	Or like not more commensurate, but just not relying on jargon and or domain knowledge specific for what they mean by beliefs and priors or is that not right?
1415920	1418540	131	B	0.61	Yeah, well, there's a lot there.
1418690	1442230	132	B	0.63345	Are you talking about the comparison of the terms beliefs and priors in relationship to the way people might naturally interpret such beliefs to be, and they may indeed be people's beliefs about the world in the conversational sense?
1444360	1454810	133	B	0.96684	Like some beliefs are just your retinal states but other states of the world, as if or really are your states on other things.
1456460	1457210	134	C	0.6644	Right?
1457580	1496620	135	C	0.71	Yeah, I guess I'm asking if beliefs is in some cases it is beliefs, but it's also another way of stating if another way of stating that is a structural systemic bias for one thing or another or whatever in that context, is that physical or informational kind of non folk psychology?
1497520	1501710	136	C	0.99945	Is that commensurate with what they mean by beliefs there?
1504640	1509330	137	B	0.66	Okay, let's try to yeah, Ali, please, first, sorry.
1510340	1516032	138	D	0.96642	I'm sorry, but you mean the statistical use of the word belief?
1516096	1526600	139	D	1	Because in statistics and in folk psychology, as far as I know, this term is used in quite different ways.
1526750	1535812	140	D	0.87978	So I guess that what you're talking about is the statistical sense of the word belief.
1535876	1546590	141	D	0.95	And if it maps onto the folk psychological sense of this term or am I missing something here?
1550000	1553120	142	A	0.92988	Well, let's just take two steps back for a second.
1553190	1573572	143	C	0.79	And just in the text it says at the bottom of page 185 here at the top of that yeah, it says the infertile mechanism operates normally but based on a flawed generative model.
1573706	1577800	144	C	0.99999	This means that ultimately pathology is a consequence of aberrant prior beliefs.
1578620	1579370	145	B	0.99	Yeah.
1580460	1591564	146	C	0.99	And I'm asking a kind of just to explicate different whatever right there in.
1591602	1595576	147	A	1	The context of psychological disorders, which is not necessarily pathology.
1595608	1609810	148	C	0.9997	But I'm just you know, if you tell somebody, oh, yeah, it helps with or is the impetus or whatever for this whole thing was to think about specifically like schizophrenia and other but that.
1610980	1613956	149	A	0.85012	Immediately kind of puts it in that.
1613978	1617072	150	C	0.63331	Category or that context of definitions.
1617136	1621990	151	C	0.99	And so just to kind of.
1624040	1626970	152	A	0.99315	Nuance the term their beliefs a little bit.
1628940	1629690	153	B	0.91	Yeah.
1630300	1652370	154	C	0.99973	Is it commensurate with the rest of the text to say in the case of this specifically of this oculine motor disorder category, like you're saying beliefs in the retina or something that is like cones, like being sensitive to something.
1652980	1663764	155	C	0.63892	Well, it's just what they are sensitive to and in this particular person they're just sensitive to or whatever the relevant structure is there.
1663802	1667108	156	C	0.99996	But it's sensitive to something.
1667274	1667700	157	C	0.98358	Right.
1667770	1671670	158	C	1	And that's its belief in some sense.
1674920	1684056	159	C	0.98714	I'm not looking for what's the statistical definition or anything like that, but just is that completely off track or is.
1684078	1688410	160	B	1	That I have a thought, but Ali, if you want to make a response please.
1690620	1691332	161	D	0.93	Yeah.
1691486	1711392	162	D	0.91	I think that this term belief and its different meanings in different contexts actually sort of bleed into each other and there cannot possibly be separated cleanly from each other.
1711446	1736280	163	D	0.83304	So in this particular case I believe that the word belief partly is this folk psychological sense of the word and partly it's based on the kind of philosophical epistemological sense of this word.
1736350	1755760	164	D	0.99976	Because especially in epistemology when philosophers talk about belief, usually they don't mean just the folk psychological sense of this term, although it relates to that concept, but it's much more nuanced than that.
1755830	1781130	165	D	0.99788	So in the case of Oculomotor pathology well, I believe that the word belief somehow can be interpreted in a little more abstract philosophical sense of or epistemological sense of this word than our folks psychological sense of it.
1782540	1793310	166	D	0.984	But again, I think it also has some overlappings with the folk psychological sense of it as well.
1795920	1802000	167	B	0.99334	Great thought just to kind of restate that then say what I was planning to before.
1802070	1816020	168	B	0.99962	So here it's situational where people talk commonly about don't talk about beliefs like the eye, like where it believes it should be looking, people don't talk about that.
1816090	1835640	169	B	0.7108	But there might be another cognitive model that does align very well with an expressed felt cognitive belief and everything in between and bundles that are mixed like people who believe that they're accurate on a task but actually are low accuracy.
1836380	1842152	170	B	0.99998	So it's going to be very model specific, I think how it maps to different people's understanding.
1842296	1862800	171	B	0.99161	But that was what Ali's response kind of made me think about and that's why I didn't choose an example like Delusions to focus on because that is related to a felt or experienced or reported phenomena.
1865060	1884490	172	B	0.65	Okay, so beliefs and priors and this question of disorders of inference which as Brock mentioned was like part of the early impetus in relating to studying for example, schizophrenia and fristin's earlier and continued work.
1888320	1904364	173	B	0.91571	Maybe there's a part of missing and maybe it's not the right context or way, but I think first we can narrowly interpret what they use to mean disorder and then have a more broad perspective.
1904412	1913036	174	B	0.70374	So I read this does not necessarily imply the inferential mechanisms flawed.
1913148	1924820	175	B	0.98252	Like the CPU has the right number of cycles, the machinery are not flawed, the car is operating at normal burning temperature.
1926380	1944430	176	B	0.99989	Given its generative model as specified hashtag chapter four it is doing appropriate variational, message passing, belief propagation, approximate Bayesian computation, Bayesian brain however you want to see it.
1944960	1954240	177	B	0.99954	Given what this person has experienced and their parameterization, it's not the case that they're making a fallacious estimate.
1955860	1961330	178	B	1	Now that's sort of in their situation where it's like, yeah, okay, but you're going to say that for whatever they do do.
1962420	1964912	179	B	0.99991	But that's kind of that tautology.
1965056	1990204	180	B	0.54558	It's like, right, that's our best estimate of the system as it is is just how it is in most of the studies reviewed in Table 9.1, which is to say the pathologies that are identified in Table 9.1, the inferential mechanism operates normally as per the previous meaning, but based upon a flawed generative model.
1990402	1992780	181	B	1	And it's literally like there's the rub.
1993600	1996332	182	B	0.96564	Aberrant prior beliefs is like, what?
1996466	2004428	183	B	0.91	And so that is where I would say there's two ways to zoom out from that and contextualize that statement.
2004524	2005516	184	B	1	The first is aberrant.
2005548	2014560	185	B	0.98248	Prior beliefs are not intrinsically aberrant, whether they're subconsciously or consciously held.
2014720	2017540	186	B	0.99379	Belief in itself is not aberrant.
2017880	2025296	187	B	0.5596	But there's the niche and especially just the human cultural when we're talking about these felt beliefs.
2025488	2032040	188	B	0.99986	So in the niche, it's like there is ant colonies that were high foraging and low foraging.
2032620	2035764	189	B	0.92072	Those are not aberrances of foraging behavior.
2035892	2040940	190	B	0.73029	That's variation in foraging behavior with respect to variation in weather.
2041440	2045230	191	B	1	And there was probably decades where one was better than the other.
2046720	2049100	192	B	1	And that's why there's evolution.
2050720	2053476	193	B	0.79213	So it's like, what's the purpose?
2053528	2078090	194	B	0.84	Okay, so level one of aberrant is in a niche context and then especially for these expressively human experienced settings, that's where I think there's an opportunity, again, not saying that this paragraph is the right place in this textbook, but that's where it's important to also bring in.
2081660	2091000	195	B	0.99711	I'm not expert in this area, but like Foucault social descriptions of mental illness diagnosis.
2095260	2098110	196	A	0.95111	Are only crazy if majority of people.
2101920	2105744	197	B	0.9995	This book, which I've mentioned on live streams before.
2105862	2108256	198	B	0.99988	If I could just describe why I bring it.
2108278	2128068	199	B	1	Up and, like, how I think it's relevant to chapter nine is just like she's saying there's different methods and there's different theoretical interpretations and it's very clear and it's very pluralist.
2128244	2135416	200	B	0.84	And though guided, everybody will also, I think, see like deeper aspects too.
2135438	2154290	201	B	0.79352	But just I studied with Helen in Stanford and she was just very like it was very interesting to see that coming from philosophy because in the scientific domains it's like not framed that way.
2158230	2180570	202	B	0.99977	We could have a generative model for these conditions and scenarios that integrates different types of information in a situational way with the sparse model and we could all work on that and then different people could have different data sets or different public or private data sets.
2184890	2222850	203	B	0.98587	But that requires not just sort of like operational coordination and ontology driven design and other features, but it also requires basically personally held commitment to pluralism, at least in practice because there's too many methods and methods are too last mile to dictate models of phenomena.
2223430	2230610	204	B	0.99994	These are not measurements, but they're generated alongside and with and from measurements.
2233820	2266980	205	B	0.99	And so that's not descriptive statistics per se and that's a major difference in what you can do with the tail of two densities approaches these situations differently than one might see in a health journal showing the population level factors associated with a disease.
2268840	2279320	206	B	0.99996	This is a different kind of study but it could be done in a population context which has been done extensively in SPM and Neuroimaging.
2283310	2293070	207	B	0.99913	So you can still bring in features of the people and understand how different features of people are quite literally associated with the diagnosis.
2293810	2303140	208	B	1	And that is seen as a label on a neurocognitive model, a generative model.
2303510	2305620	209	B	1	Now what's the generative model?
2306550	2322550	210	B	0.99987	Chapter Four chapter Six and then it's like, okay, we're just going to say that all of the people's ocular motor circuitry are structurally the same and we're going to explore how the two groups differ in the parameter estimates of these different features.
2322970	2328998	211	B	0.57	Or you could say I'm studying a situation where this region has been severed.
2329174	2344590	212	B	0.99971	So the hypothesis I'm testing is actually whether this connectivity versus this connectivity is going to have this observable difference that's testing a structural hypothesis.
2345170	2352242	213	B	0.58562	So you could test parametric hypotheses within a generative model and or structural hypotheses across.
2352376	2361570	214	B	0.99999	But to kind of return to this point those are these two ways that the model can be quote in in their, you know, way aberrant or flawed.
2362010	2374806	215	B	0.99473	Quite literally it could be a parametric estimate that's aberrant which as discussed does not mean intrinsically bad number 4.2 or three 7.3 is not bad.
2374988	2380220	216	B	0.99975	It's about its relationship within a niche and a fitness context and like all of that.
2380590	2393098	217	B	0.99992	So it could be a parametric aberrance with respect to a state estimator like an expectation on a variable or precision.
2393274	2395390	218	B	0.99992	So that's the LaPlace approximation.
2395890	2413414	219	B	0.99658	It's the hierarchical predictive processing approximation structure, expectation variance, mean variance, mode variance, center of the path, width of the path those are the two.
2413452	2416706	220	B	0.79795	Gaussian distribution takes two parameters.
2416818	2419270	221	B	0.50035	LaPlace approximation takes two parameters.
2420090	2434570	222	B	0.53562	Hierarchical message passing has these kinds of variables or it can be structural differences which is quite open ended.
2437490	2438910	223	B	0.99997	How is this useful?
2440930	2445978	224	B	0.99	An example is provided here, potentially.
2446074	2450260	225	B	1	For example, let's just say that there's people who do and do not have a certain situation.
2451990	2454930	226	B	0.99994	Some moths go towards the light and some don't.
2455430	2475320	227	B	0.99521	Is that because of differences in their behavior where the statistical variance gets loaded onto differences in their realized preference vector or their habit e?
2476190	2499486	228	B	0.99967	So there could be a behavioral setup that would do the fibonacci pattern of variability or just whatever it happened to be which is extensively described in SPM how to time different behavioral stimuli, some natural observational setting or controlled behavioral setting both of which have pros and cons.
2499668	2503406	229	B	0.99973	Both quote controlled conditions in the lab and natural observation.
2503438	2504674	230	B	0.99756	They have pros and cons.
2504872	2515080	231	B	0.88334	But the idea in model based analysis is that those can be the observables and you may or may not control the observations, but at least you know what they are.
2515530	2537840	232	B	1	And then you can explore whether differences in behavior end up being reflected in statistically differentiable parameter estimates for prior preference or for prior d or for the fixed form term e.
2543070	2544010	233	B	0.77323	Ali.
2547710	2548170	234	D	1	Yes.
2548240	2565294	235	D	0.99994	For what it's worth, I also put a quote from this recent paper by Car Pristen from a couple of months ago, which is, by the way, is a great overview of this whole field of computation psychiatry through the lens of active inference.
2565422	2576126	236	D	1	And here it provides a clear and explicit definition of the term belief used in this area.
2576248	2581880	237	D	0.99985	So I thought that might be helpful here.
2582410	2586354	238	D	0.98	The kind of beliefs here are Bayesian beliefs.
2586402	2590860	239	D	1	And then it goes on to describe what Bayesian beliefs mean.
2594600	2595350	240	B	0.99968	Awesome.
2600120	2602420	241	A	0.56619	Um cool.
2602570	2605492	242	A	0.99	That was super clarifying.
2605636	2609610	243	A	0.99	I think it makes a lot of sense.
2616000	2616750	244	A	0.99635	Maybe.
2617360	2627310	245	A	0.93	I don't know if the answer was already given exactly, or I'll just ask it a different, slightly different way about.
2628900	2632140	246	C	0.62	The separation between the generative model and the priors.
2632220	2651810	247	C	1	Here in this toy frog jumping example are the aberrant priors, the frog apple distribution on that belief beforehand, and.
2654780	2655288	248	A	0.82	The.
2655374	2662212	249	C	0.99003	Observation, the updating, all of that being the generative model is working as intended.
2662356	2690480	250	C	0.99987	But it's just that the priors were so out of whack that when the generative model kind of observes and steps through or whatever, that it just ends up in the wrong state and or is the likelihood model I'm not sure.
2690550	2693060	251	A	1	I guess in the toy example there.
2693210	2696132	252	C	0.70214	How you could have how it would be.
2696266	2699908	253	A	0.8	I guess the part that's missing there is the context, maybe.
2699994	2715240	254	A	0.98046	But yeah, like if I had a prior belief that was different than your prior belief, but we didn't have a disorder or whatever, I would imagine our priors wouldn't be the same, but they would still kind of converge.
2718160	2723992	255	A	0.99225	So I'm not sure how you get there without an outside prior belief.
2724056	2727390	256	A	1	Or something about the environment that's totally wrong, right?
2728000	2734850	257	A	0.87	Or something else about the environment or the likelihood model is somehow really wrong.
2736580	2737440	258	B	0.94	Yeah, thanks.
2737510	2738544	259	B	0.98424	Great question.
2738662	2741008	260	B	0.99996	Those are exactly the two greetings.
2741024	2741396	261	B	0.99945	Welcome back.
2741418	2744308	262	B	0.44112	Ali those are exactly like the two.
2744394	2746980	263	B	0.9999	Let me unpack that in the pathology example.
2747130	2759288	264	B	0.85715	So society expects us and or we actually die or have consequences with when the frog when it's a frog, you're not supposed to eat it.
2759374	2761610	265	B	0.99992	Apples are okay to eat.
2763580	2767580	266	B	1	Now, if you turn down too many apples, you starve.
2768080	2770792	267	B	0.99986	If you eat too many frogs, you die.
2770936	2785916	268	B	0.69473	So you have to balance your type one and type two false positive and false negative error rates in this eat, do not eat, jump, does not jump observation setting.
2786108	2789504	269	B	0.99923	Because these are idle classifiers here.
2789622	2793488	270	B	0.99998	But we can imagine these as more action oriented classifiers.
2793664	2795072	271	B	0.93236	Apples are for eating.
2795136	2797300	272	B	0.89979	Frogs are for throwing.
2800120	2824350	273	B	1	Now, society and or the niche defines aberrant behavior as one that does not conform to expectations or to a thriving state in the niche while recognizing that all parameter values that are actually observed are at least there.
2825360	2827756	274	B	1	Now, that doesn't mean you want them to be there, they want them.
2827778	2832880	275	B	0.99973	But also then that's a belief an agent has about another system that also exists.
2835700	2842580	276	B	0.999	So there would be many ways to see that aberrant behavior.
2843400	2863290	277	B	0.95425	So if you like speaking to the person who discards too many apples, maybe they believe that they have a strong prior on frogs 0.5 or their likelihood, which is also a parametric belief, is different.
2864540	2866480	278	B	0.5455	They have a different action mapping.
2866580	2867612	279	B	0.69	Now that here's the question.
2867666	2872940	280	B	1	Now you put them in the lab and you have jumping and non jumping frogs and apples.
2874320	2893030	281	B	0.96	And then you can use those experimental techniques on a computational model narrowly to determine do they simply expect frogs to appear but they know what frogs and apples do?
2894520	2908360	282	B	1	Or do they have an appropriate belief about the likelihood a priori of frogs and apples but they have an incorrect action mapping?
2909020	2912276	283	B	0.7	I hope I said it correctly, but I think you get the picture.
2912388	2936450	284	B	0.94	The point is you could then use experiments to determine whether groups of people who had effective or ineffective behavior and then if somebody, for example, had an overestimate of frogs, then the message to pass is frogs are not as common as you think.
2938260	2962490	285	B	0.99502	Whereas if there was somebody with a variance interpretable variance here in the likelihood model difference with some other preference again, keeping in mind that that's still like it's like outlier detection and attracting which isn't even necessarily a preferable thing.
2962940	2973390	286	B	0.99781	But just pointing out, just statistically, this person's model would be updated by saying it's not known that apples can jump, but actually they can.
2974080	2978670	287	B	0.55792	It's possible that apples jump, so next time something jumps, don't just throw it away.
2980580	3002688	288	B	1	And those are very different points to convey and this is a very simple example, but it's helpful to think about because those are the kinds of parameter if this was your model of schizophrenia, those would be your levers or your knobs.
3002864	3011876	289	B	1	If you had a more complex model and the models are more complex, then there's a lot more associated challenge.
3011908	3012840	290	B	0.94	Yeah, Brock.
3013500	3017500	291	A	0.44	Oh, no, I was just going to say that was really helpful.
3021040	3025070	292	A	0.7	I don't even know, it seems good.
3025520	3030160	293	A	0.99994	Obviously I know next to nothing, I guess, about psychiatry.
3033060	3036690	294	C	0.59	I don't know how you do it though, without something like this.
3039220	3056344	295	C	0.97	I guess they were doing something kind of like this approximately informally to some degree, in some cases, but it would seem like just guessing almost, I don't know.
3056382	3062410	296	A	0.62	Yeah, well, I could infer about schizophrenia without something like this.
3064380	3080976	297	B	0.99937	Well, to simplify a complex area, there was studies that associated either a biomolecule or a genetic variant, but especially biomolecules in brain imaging directly to a diagnosis which from a health record perspective exactly makes sense.
3080998	3082240	298	B	0.93895	It's the data you have.
3082390	3088944	299	B	0.99999	However, this is an unobserved model of.
3088982	3121996	300	B	1	The phenomena itself that can incorporate measurements, including health records, and that allows the development of an actual understanding of the ethiology and the causation and therefore could be used to justify traditionally understood interventions or suggest different behavior and interventions like maybe you don't just, oh, you're low on this, just take this thing that raises it.
3122018	3124076	301	B	0.72355	It's like maybe that's not exactly the.
3124098	3131088	302	C	0.78561	Move, but just more precise affordance to do that.
3131254	3136096	303	B	0.97	Yeah, including the counterfactuals, like in a clinical setting that is going to be quite interesting.
3136198	3147700	304	B	0.97	All right, let's just in the last minutes look to Ten Minsky active inference as a unified theory of sentient behavior.
3149480	3171640	305	B	0.99993	If anybody wants to do a little like Twitter thread recap on the sentient the sentience discourse over the last few weeks, I'm sure we can find some funny tweets, but with the sentient pong playing neurons and just wave after wave of semantic discussion about the term sentient.
3173280	3182288	306	B	0.59157	In this chapter we wrap up active inference main theoretical points from the first part of the book, chapter one through five, and its practical implementations from the second part six through ten.
3182374	3183840	307	B	1	Then we connect the dots.
3184260	3193010	308	B	0.99999	We abstract away from the specific active inference models discussed in previous chapters to focus on integrative aspects of the framework benefits of activ.
3194760	3209208	309	B	0.75178	Summary of the book 10.2, chapter one, chapter two, chapter three, chapter 4567 and eight, no love chapter nine.
3209374	3210810	310	B	0.99988	You just read it.
3211500	3212890	311	B	0.99474	Go read it again.
3214620	3215684	312	B	0.68792	Connecting the dots.
3215732	3226810	313	B	0.68	The integrative perspective on active inference, interestingly framed in terms of some early dennett work.
3229440	3260390	314	B	0.67	A call to model the whole iguana a complete cognitive creature, perhaps a simple one, and an environmental niche for it to cope with rather than single dimensional analyses and measurements on a complex system just too much like a Whirlwind to just measure and oh, well, brain regions correlated with this and this region is correlated with that.
3260760	3278730	315	B	0.99985	Those kinds of structural and behavioral, morphological any given measurement does not ever get at the underlying causal structure unless you specifically model it that way.
3280640	3288350	316	B	0.84452	Active inference helps with that issue by offering a first principle account of the ways in which organisms solve their adaptive problems.
3289040	3306980	317	B	0.99997	So by framing attention, memory, anticipation under common computational framings and a unified imperative it's possible to integrate different kinds of phenomena.
3307320	3313300	318	B	0.99865	Memory attention can be thought of as optimizing the same objective.
3317900	3321240	319	B	0.89	Ten four predictive brains, predictive minds and predictive processing.
3323500	3327480	320	B	0.99992	Kind of a provocative selection.
3332160	3352864	321	B	0.99886	Active inference creatures, or their brains are probabilistic inference machines connecting to the kind of focus of predictive mind, predictive brain, predictive processing, coding area, which is like the real time and anticipatory, especially real.
3352902	3390504	322	B	0.89832	Time unfolding anticipation self evidencing prediction predictive processing specifically Livestream 43 perception section 10.5 helmholtz perception is unconscious inference then how that was implemented in Bayesian brain Bayesian brain the inactive turn the pragmatic turn action control bringing action in end of Livestream.
3390552	3391612	323	B	1	43 End of paper.
3391666	3417960	324	B	1	43 Idea motor, cybernetic, some other ontologies that are kind of like easily functionally equated with parts of active idea motor theory, cybernetics, optimal control theory, utility, decision making, Bayesian decision, reinforcement, learning, planning as inference, behavior and bounded rationality.
3418700	3441500	325	B	1	And then, specifically, what free energy brings into bounded rationality, valence, emotion, motivation, homeostasis alistasis and terraceptive processing, attention, salience, epistemic dynamics, rural learning, causal inference, fast generalization and next steps social machine learning and robotics.
3442160	3443032	326	B	0.99975	Summary.
3443176	3449230	327	B	0.35197	Lord of the Rings, we are confident that you will continue to pursue active inference in some form.
3452720	3454272	328	B	0.99994	So it's a quite long chap.
3454376	3455670	329	B	0.95874	There's a lot in it.
3457400	3459670	330	B	0.9183	We'll talk about it next time.
3460120	3461540	331	B	0.99946	Thank you, fellas.
3462520	3462880	332	B	0.53296	Bye.
